1
00:00:00,000 --> 00:00:03,020
i mean look at things we going through you know the actual

2
00:00:03,060 --> 00:00:06,520
know i was reading one of the articles in time magazine i think

3
00:00:06,630 --> 00:00:10,520
this had only five people destroyed destroying the whole world

4
00:00:10,560 --> 00:00:13,820
all of them came from harvard business school

5
00:00:16,090 --> 00:00:19,560
and one of them is george bush and i'm surprised how the hell you could

6
00:00:19,560 --> 00:00:20,460
go to

7
00:00:20,500 --> 00:00:22,170
however to do MBA

8
00:00:23,040 --> 00:00:25,150
somebody told me that there is a rule

9
00:00:25,190 --> 00:00:29,690
if your father if your parents went to how would you can go to how

10
00:00:29,710 --> 00:00:33,610
and is all you need is your mum and dad to be lower than you

11
00:00:33,790 --> 00:00:35,880
make sure that happens

12
00:00:36,020 --> 00:00:41,000
what kind of property that but for that's why because his father into howard so

13
00:00:41,000 --> 00:00:44,820
you could go to any couldn't get any without mission

14
00:00:44,860 --> 00:00:48,320
and they get some time in all of the hard work and all of them

15
00:00:48,320 --> 00:00:53,250
to the economy either making the regulations very easy or

16
00:00:55,070 --> 00:00:55,770
you know

17
00:00:55,820 --> 00:00:57,770
straightforward corruption

18
00:00:57,820 --> 00:00:59,020
i agree

19
00:01:00,520 --> 00:01:04,880
so anyway the comes to these intrusion detection very small number of things to do

20
00:01:04,880 --> 00:01:08,730
that and you have to catch them know these are like all players if you

21
00:01:08,730 --> 00:01:12,840
think about it if you put of all this data together intrusion could be seen

22
00:01:12,840 --> 00:01:17,940
as the player so the idea here is that many times outlier detections are very

23
00:01:17,940 --> 00:01:23,650
difficult because you don't have enough sufficient statistics for building them in obvious way is

24
00:01:23,650 --> 00:01:25,500
much harder

25
00:01:25,790 --> 00:01:28,820
click-through data sets are also raised

26
00:01:29,440 --> 00:01:34,420
so what we have done is CART quite simple and what you do is that

27
00:01:34,420 --> 00:01:37,110
first of all your mind congress patterns

28
00:01:37,130 --> 00:01:40,190
and then use these things as like seeds

29
00:01:40,230 --> 00:01:43,670
you know for example you can apply your favorite

30
00:01:43,710 --> 00:01:46,750
you know genetic algorithms you sees these patterns

31
00:01:46,800 --> 00:01:49,750
and then you do do the crossing

32
00:01:49,750 --> 00:01:51,460
instead of mutations

33
00:01:51,480 --> 00:01:55,090
what you do is you look at some of the dominant features and the new

34
00:01:55,090 --> 00:01:58,500
and the mean to these things and that's all we did it

35
00:01:58,500 --> 00:02:00,570
and we were able to show that

36
00:02:00,610 --> 00:02:06,500
i can build much robust classifiers like decision trees and other things using these rate

37
00:02:06,520 --> 00:02:08,920
cancer dataset so here is an example

38
00:02:08,940 --> 00:02:10,320
i know you're given

39
00:02:11,150 --> 00:02:13,360
emerging patterns e one e two e three

40
00:02:13,360 --> 00:02:15,730
you do some kind of combinations of these

41
00:02:15,750 --> 00:02:16,770
and then let's say

42
00:02:16,800 --> 00:02:19,790
we we know that value for is very

43
00:02:19,840 --> 00:02:26,110
a high growth rate for the attribute for then you we synthesised entirely new sets

44
00:02:26,110 --> 00:02:30,460
of points by using u one u two u three and therefore you generate these

45
00:02:30,460 --> 00:02:32,860
things you can use very clever

46
00:02:32,920 --> 00:02:34,440
you know some kind of genetic

47
00:02:35,020 --> 00:02:36,790
hybrid icing

48
00:02:39,070 --> 00:02:40,840
and cross

49
00:02:41,340 --> 00:02:46,230
breeding or whatever you can do that and you build them new patterns and once

50
00:02:46,230 --> 00:02:50,770
you feel this pattern make sure that doesn't contradict your positive instances so that means

51
00:02:50,770 --> 00:02:54,610
you build an instance and it is too close to one of the positive instances

52
00:02:54,610 --> 00:02:56,770
you might try this because it could be

53
00:02:56,770 --> 00:03:00,750
correcting information so to make sure that the instance is created

54
00:03:00,770 --> 00:03:02,380
not contradict with the

55
00:03:02,630 --> 00:03:07,420
the major class

56
00:03:07,440 --> 00:03:09,590
so the idea what i told you is the

57
00:03:09,690 --> 00:03:14,630
decision trees the weighted decision trees based on emerging patterns is basically

58
00:03:14,650 --> 00:03:18,060
you give weights that is how important these instances

59
00:03:19,130 --> 00:03:21,380
in a in a in a strange way

60
00:03:21,400 --> 00:03:24,820
what we're doing is we're doing it kind of classification already

61
00:03:24,840 --> 00:03:27,040
because we are finding school

62
00:03:27,040 --> 00:03:31,420
but what we're doing is instead entirely relying on that we are basically telling how

63
00:03:31,420 --> 00:03:35,730
significant it is in terms of confidence because if the scores are very close to

64
00:03:35,730 --> 00:03:39,540
both sides may be should not play a role in the decision tree building and

65
00:03:39,540 --> 00:03:45,270
that's what the underlying model was and this is given as a very good results

66
00:03:45,360 --> 00:03:49,820
and his father then KNN because can looks at all the features that is this

67
00:03:49,820 --> 00:03:53,540
one looks set subspaces and that's why it's very very practical

68
00:03:53,540 --> 00:03:58,290
and one more thing is that can only looks at the k nearest ones because

69
00:03:58,290 --> 00:04:00,920
you do the sub-surface projection

70
00:04:00,940 --> 00:04:05,540
you can see many more instances rather than just the neighborhood

71
00:04:14,860 --> 00:04:19,270
thank you

72
00:04:19,320 --> 00:04:22,250
i will be

73
00:04:24,750 --> 00:04:27,150
so he's trying to say goodbye to

74
00:04:27,190 --> 00:04:29,880
he didn't want to do publicly

75
00:04:29,880 --> 00:04:32,250
so k nearest neighbour

76
00:04:32,440 --> 00:04:35,900
you know probably have non you know you try to find the distance between two

77
00:04:35,900 --> 00:04:38,880
points and typically you do they all the features

78
00:04:38,940 --> 00:04:44,840
so here we can actually selectively project based on emerging patterns only those values were

79
00:04:44,840 --> 00:04:46,570
looking at and that's where the

80
00:04:46,920 --> 00:04:50,500
the strength comes for for these things

81
00:04:50,650 --> 00:04:55,940
so maybe we won't have time to this one that you sign up for those

82
00:04:55,940 --> 00:04:56,820
people who

83
00:04:56,880 --> 00:04:58,630
work in databases

84
00:04:58,630 --> 00:05:03,400
the red lines i really surfaces this three-dimensional you have to rotate the whole thing

85
00:05:03,400 --> 00:05:04,940
about the vertical

86
00:05:04,960 --> 00:05:06,920
these surfaces

87
00:05:06,930 --> 00:05:12,370
and the red ones are positive potential services and the blue one's negative potential services

88
00:05:12,590 --> 00:05:16,180
that is not important but the green lines of field lines

89
00:05:16,210 --> 00:05:19,060
and notice if i take for instance this field lines

90
00:05:19,110 --> 00:05:26,210
perpendicular view to read perpendicular there perpendicular there perpendicular there perpendicular year perpendicular here coming

91
00:05:26,210 --> 00:05:29,130
in a perpendicular perpendicular perpendicular

92
00:05:29,130 --> 00:05:31,750
everywhere you look on this graph you'll see

93
00:05:31,760 --> 00:05:32,950
the field lines

94
00:05:32,960 --> 00:05:34,260
are perpendicular

95
00:05:34,290 --> 00:05:35,070
to the

96
00:05:35,080 --> 00:05:36,370
the potential

97
00:05:36,380 --> 00:05:38,050
and that is something that we now

98
00:05:38,060 --> 00:05:41,740
i fully understand

99
00:05:41,790 --> 00:05:43,090
the situation

100
00:05:43,110 --> 00:05:46,560
means then that if you release a charge

101
00:05:46,570 --> 00:05:48,320
at zero speed

102
00:05:48,370 --> 00:05:51,990
that would always start to move perpendicular

103
00:05:52,000 --> 00:05:56,670
uniquely potential surface because it always starts to move in the direction of the field

104
00:05:57,450 --> 00:06:03,320
plus charge in the direction of the field line minor charge in the opposite direction

105
00:06:03,370 --> 00:06:05,220
so if you in space

106
00:06:05,260 --> 00:06:10,920
you release it charted zero screen it always takes off perpendicular to its potential

107
00:06:10,960 --> 00:06:12,610
we have something similar

108
00:06:12,670 --> 00:06:14,120
with gravity

109
00:06:14,190 --> 00:06:15,110
if you

110
00:06:15,140 --> 00:06:18,270
look at maps of mountaineers

111
00:06:18,290 --> 00:06:20,050
contours of equal

112
00:06:22,170 --> 00:06:25,160
people height

113
00:06:25,170 --> 00:06:26,890
if you started skiing

114
00:06:26,900 --> 00:06:28,600
he studied at that point

115
00:06:28,610 --> 00:06:30,790
you started with zero speed

116
00:06:30,800 --> 00:06:32,860
you would always take off

117
00:06:34,170 --> 00:06:35,760
the potentials

118
00:06:35,770 --> 00:06:37,970
this is the direction in which start

119
00:06:37,980 --> 00:06:40,270
well if you start off with zero

120
00:06:45,370 --> 00:06:47,390
and i want to give you some

121
00:06:49,140 --> 00:06:51,970
feeling of the connection between potential

122
00:06:52,040 --> 00:06:53,920
and electric fields

123
00:06:53,960 --> 00:06:55,730
and i want you to follow me

124
00:06:55,790 --> 00:06:57,120
very closely

125
00:06:57,140 --> 00:06:58,480
it's that

126
00:06:58,510 --> 00:07:00,080
but i make one two

127
00:07:00,090 --> 00:07:02,240
follow me

128
00:07:03,450 --> 00:07:04,790
i am

129
00:07:04,810 --> 00:07:09,910
somewhere in space at position

130
00:07:09,920 --> 00:07:13,700
at that position p there is a potential one unique potential

131
00:07:13,720 --> 00:07:14,930
the offspring

132
00:07:14,990 --> 00:07:16,240
to give them

133
00:07:16,290 --> 00:07:18,400
and there is an electric field that

134
00:07:18,410 --> 00:07:20,930
location where i am

135
00:07:21,010 --> 00:07:22,660
and now what i'm going to do

136
00:07:22,670 --> 00:07:27,740
i'm going to make an extremely small step only in the x direction

137
00:07:27,760 --> 00:07:31,800
more wine lynsey only in the x direction

138
00:07:31,840 --> 00:07:35,950
if i measure no change in the potential

139
00:07:35,960 --> 00:07:38,350
over that little step

140
00:07:38,410 --> 00:07:39,680
it means that the

141
00:07:39,790 --> 00:07:43,660
component of the electric field in the direction x

142
00:07:43,710 --> 00:07:46,370
is zero

143
00:07:46,390 --> 00:07:50,560
if i do measure the difference in potential

144
00:07:51,870 --> 00:07:54,350
the components

145
00:07:55,030 --> 00:07:58,120
the x component of the

146
00:07:58,180 --> 00:07:59,810
electric fields

147
00:07:59,850 --> 00:08:01,780
the magnitude of that

148
00:08:01,820 --> 00:08:03,980
it would be that little sites

149
00:08:04,020 --> 00:08:07,930
step that i have made x

150
00:08:07,990 --> 00:08:10,950
it will be the potential difference that i measure

151
00:08:11,060 --> 00:08:13,800
divided by the total sites there

152
00:08:13,810 --> 00:08:15,600
and i keep y

153
00:08:15,610 --> 00:08:17,170
and the constant

154
00:08:17,210 --> 00:08:20,170
and these are magnitudes

155
00:08:20,220 --> 00:08:23,520
that's why put vertical bars here

156
00:08:23,560 --> 00:08:27,860
equally if i made small sidestepping the y direction

157
00:08:27,870 --> 00:08:31,660
and i measure a potential difference delta v

158
00:08:31,760 --> 00:08:34,100
being x and z constant

159
00:08:34,160 --> 00:08:36,400
that would then be

160
00:08:37,700 --> 00:08:39,740
of the electric field

161
00:08:39,770 --> 00:08:44,020
in the wider

162
00:08:44,060 --> 00:08:50,020
earlier we wrote down for me as a unit new note newtons coulomb

163
00:08:50,090 --> 00:08:53,400
from now on we almost always will write down

164
00:08:53,410 --> 00:08:55,440
forty unit of electric fields

165
00:08:55,530 --> 00:08:57,170
volt meter

166
00:08:57,270 --> 00:09:01,060
it exactly the same thing as new kinds of cornwall there's no difference

167
00:09:01,100 --> 00:09:03,980
this gives you a little bit more inside

168
00:09:04,040 --> 00:09:05,650
you're making little sidestep

169
00:09:05,660 --> 00:09:07,070
in metres

170
00:09:07,080 --> 00:09:10,740
you measure how much the potential changes its faults

171
00:09:10,770 --> 00:09:11,590
i mean this

172
00:09:11,600 --> 00:09:13,290
is it a potential change

173
00:09:13,300 --> 00:09:16,430
over the distance

174
00:09:16,470 --> 00:09:19,860
so now i can write down the connection between

175
00:09:19,870 --> 00:09:22,850
electric field and potential

176
00:09:22,860 --> 00:09:25,010
in cartesian coordinates

177
00:09:25,060 --> 00:09:25,970
it looks

178
00:09:25,980 --> 00:09:27,510
much more scary

179
00:09:27,690 --> 00:09:28,720
the nice

180
00:09:28,730 --> 00:09:31,410
weighted i could write it down there

181
00:09:31,450 --> 00:09:32,460
when i had

182
00:09:33,490 --> 00:09:35,030
a function of

183
00:09:35,060 --> 00:09:36,840
systems are

184
00:09:36,900 --> 00:09:39,770
and so in cartesian coordinates we now get the

185
00:09:39,840 --> 00:09:45,030
equals minus the minus sign we discussed at length

186
00:09:45,040 --> 00:09:46,960
now we get

187
00:09:48,900 --> 00:09:50,840
the dx

188
00:09:50,850 --> 00:09:53,050
times x roof

189
00:09:53,160 --> 00:09:55,030
because the

190
00:09:56,580 --> 00:09:58,150
and why

191
00:09:58,290 --> 00:09:59,930
would be

192
00:10:01,620 --> 00:10:05,200
i do

193
00:10:05,260 --> 00:10:08,670
and what you see here in first term here

194
00:10:08,720 --> 00:10:11,620
including of course the minus sign

195
00:10:11,670 --> 00:10:12,470
that is e

196
00:10:12,480 --> 00:10:13,820
of x

197
00:10:13,910 --> 00:10:15,620
and this term

198
00:10:15,680 --> 00:10:17,940
including the minus sign

199
00:10:19,040 --> 00:10:22,270
of y and so on

200
00:10:22,320 --> 00:10:23,900
and the fact that you see these

201
00:10:23,910 --> 00:10:26,810
girls these partial derivatives

202
00:10:26,850 --> 00:10:31,780
that means when you do this derivative you keep xeon why constant when you do

203
00:10:31,780 --> 00:10:32,940
this derivative

204
00:10:32,940 --> 00:10:36,070
you do actually constant and so on

205
00:10:36,120 --> 00:10:37,580
and so this is the

206
00:10:41,140 --> 00:10:43,100
four which in eighteen o two

207
00:10:43,120 --> 00:10:45,660
you will learn or maybe you already have learned

208
00:10:45,730 --> 00:10:48,560
we would write it e equals minus

209
00:10:48,590 --> 00:10:52,270
the gradient of this is a vector function

210
00:10:52,290 --> 00:10:57,220
this is a scalar function and this is just as a different notation

211
00:10:57,230 --> 00:10:59,200
just a amount of words

212
00:10:59,220 --> 00:11:01,640
for this mathematical

213
00:11:04,310 --> 00:11:06,350
you get that was eighteen eighteen o two

214
00:11:06,350 --> 00:11:08,390
and now the

215
00:11:08,410 --> 00:11:13,410
these are the parameters of the estimation just

216
00:11:13,410 --> 00:11:15,710
there is a big random parameters

217
00:11:15,730 --> 00:11:17,290
from one division

218
00:11:17,350 --> 00:11:19,060
the because random the parameters

219
00:11:20,980 --> 00:11:23,580
we look at the point in a a cluster

220
00:11:23,580 --> 00:11:29,620
and then we compute the likelihood is product of public land paper that

221
00:11:30,620 --> 00:11:32,560
the former

222
00:11:32,580 --> 00:11:34,960
OK in the likelihood of the parameters

223
00:11:37,540 --> 00:11:41,200
and so it and then we multiply this

224
00:11:41,200 --> 00:11:43,730
like function would is

225
00:11:43,790 --> 00:11:45,330
with the right

226
00:11:45,350 --> 00:11:49,710
so basically modulate the likelihood function to towards

227
00:11:51,040 --> 00:11:55,710
and this is not normalized probabilities of together through

228
00:11:55,730 --> 00:12:00,230
probably because we have normalize and this is the function from which we sample the

229
00:12:00,230 --> 00:12:02,430
distribution of the sample

230
00:12:02,440 --> 00:12:05,270
it's called the posterior distribution of

231
00:12:05,270 --> 00:12:08,910
one of the parameters given the data and last

232
00:12:10,430 --> 00:12:16,660
now how you how hard it is depends on the form of these from users

233
00:12:16,710 --> 00:12:20,890
sometimes you have to the monte carlo because you can sample from the distribution

234
00:12:20,960 --> 00:12:25,680
so it's really easy and for example in the case where f and g lugosi

235
00:12:25,680 --> 00:12:30,600
and the public before any number of nodes is still a gaussian distribution so

236
00:12:30,620 --> 00:12:33,660
it's really easy to get the new sample from the distribution

237
00:12:34,210 --> 00:12:37,850
generalized case of the girls is what's called conjugate priors

238
00:12:37,850 --> 00:12:39,830
so for certain functions

239
00:12:39,930 --> 00:12:43,080
you can choose the two zero so that all resistance

240
00:12:43,100 --> 00:12:46,290
and that's called conjugate priors

241
00:12:46,410 --> 00:12:49,140
and so if you have to

242
00:12:49,160 --> 00:12:50,020
if the

243
00:12:50,080 --> 00:12:54,640
you know the conjugate has actually is actually acceptable for

244
00:12:54,660 --> 00:12:58,210
the kind of data that you have with the kind of problem that you then

245
00:12:58,250 --> 00:13:00,330
the sampling is very

246
00:13:00,350 --> 00:13:01,850
in this case it's just

247
00:13:01,870 --> 00:13:04,230
closed for example

248
00:13:04,270 --> 00:13:08,350
of course in any case if you some from the posterior given the data

249
00:13:08,370 --> 00:13:10,330
so you get new parameters for cluster

250
00:13:10,350 --> 00:13:16,040
o back can you find the points and so on

251
00:13:16,040 --> 00:13:18,600
and you're on this algorithm four

252
00:13:18,620 --> 00:13:21,540
for a few thousand iterations

253
00:13:21,580 --> 00:13:27,430
and then you start looking at what kind of people of european cluster cluster labels

254
00:13:27,440 --> 00:13:29,160
have been and so on

255
00:13:29,270 --> 00:13:31,250
and it's actually two

256
00:13:31,270 --> 00:13:35,160
how do you get what you want really is one class

257
00:13:35,160 --> 00:13:38,000
in in our case of clustering so it's not

258
00:13:38,060 --> 00:13:41,390
quite a simple problem to get one clustering from this you are going to get

259
00:13:41,390 --> 00:13:43,890
the last some bad some good

260
00:13:43,940 --> 00:13:47,580
but before we discussed this

261
00:13:47,580 --> 00:13:50,310
i just want to mention one thing about the posterior

262
00:13:50,330 --> 00:13:53,410
some of you know it i'm sure

263
00:13:53,430 --> 00:13:56,730
but if you don't know it it is worth to mention

264
00:13:56,750 --> 00:14:03,660
what happens here you're multiplying one function with

265
00:14:04,870 --> 00:14:06,430
with the product

266
00:14:06,440 --> 00:14:08,100
so if there are

267
00:14:08,890 --> 00:14:12,830
usually this is more a citizen what led functions so it doesn't have a strong

268
00:14:12,830 --> 00:14:14,940
preference for

269
00:14:16,250 --> 00:14:20,730
many of press should have a strong preference for the parameter because actually it has

270
00:14:20,770 --> 00:14:23,980
be that this are in the next to the centre of the data so they

271
00:14:23,980 --> 00:14:27,000
are but better be close to the data and not far away

272
00:14:27,120 --> 00:14:29,910
so if you have

273
00:14:29,930 --> 00:14:33,620
only one point in one class and then they will be somewhere near that point

274
00:14:33,620 --> 00:14:35,520
but not all

275
00:14:36,980 --> 00:14:38,960
but one of randomly around the

276
00:14:40,460 --> 00:14:46,230
but if you have many points in one cluster solution of large clusters

277
00:14:46,230 --> 00:14:48,460
o point close together

278
00:14:48,480 --> 00:14:53,430
then these are the close together very strongly to the

279
00:14:54,080 --> 00:14:58,980
and so because there are many this this prior to be almost wiped out

280
00:14:58,980 --> 00:15:01,010
these it

281
00:15:01,170 --> 00:15:04,950
russians behind the agreement

282
00:15:06,800 --> 00:15:09,490
we call this

283
00:15:11,070 --> 00:15:13,190
i find myself

284
00:15:13,230 --> 00:15:24,330
the which that if we don't do it if

285
00:15:24,330 --> 00:15:27,180
the fundamental reform is doesn't it

286
00:15:27,370 --> 00:15:30,930
and we say that

287
00:15:31,010 --> 00:15:32,270
i find myself

288
00:15:32,280 --> 00:15:35,080
is good if

289
00:15:35,740 --> 00:15:40,490
this about one these

290
00:15:45,730 --> 00:15:51,870
and the net

291
00:15:52,030 --> 00:15:53,140
we're fine

292
00:15:54,210 --> 00:15:56,490
because o the thing

293
00:15:56,550 --> 00:15:58,140
but this good money for

294
00:16:00,980 --> 00:16:02,630
and it is known that such

295
00:16:02,630 --> 00:16:03,880
the connection

296
00:16:03,890 --> 00:16:09,030
well in description in the project to be from

297
00:16:09,080 --> 00:16:17,600
casual this proposal for user

298
00:16:17,610 --> 00:16:21,830
fundamental structural equations of

299
00:16:23,260 --> 00:16:24,690
a bus facility

300
00:16:24,700 --> 00:16:31,980
the the city

301
00:16:32,670 --> 00:16:35,780
the manifold is simply connected

302
00:16:35,790 --> 00:16:37,780
and doing well actually

303
00:16:37,820 --> 00:16:39,640
the predictive throughout day

304
00:16:40,400 --> 00:16:41,520
it of course it up

305
00:16:41,540 --> 00:16:46,870
i find myself which disease

306
00:16:46,880 --> 00:16:51,580
well that this government with being white space

307
00:16:51,690 --> 00:17:00,440
the naked let us define contrast function

308
00:17:07,820 --> 00:17:14,070
five muscle is known it on the clear

309
00:17:14,800 --> 00:17:16,250
they don't the like

310
00:17:16,260 --> 00:17:18,570
artist of input iceland

311
00:17:19,910 --> 00:17:22,660
vector space of

312
00:17:22,710 --> 00:17:26,640
or in breslau

313
00:17:27,540 --> 00:17:28,550
the brain

314
00:17:28,720 --> 00:17:37,120
but it is going go bed with these vector spaces

315
00:17:37,160 --> 00:17:39,530
then we can define the

316
00:17:39,550 --> 00:17:40,840
the bottom up

317
00:17:41,750 --> 00:17:42,840
i famous

318
00:17:47,400 --> 00:17:48,170
they really

319
00:17:48,180 --> 00:17:49,540
one them up

320
00:17:49,600 --> 00:17:51,030
is a lot of money

321
00:17:51,170 --> 00:17:53,520
no no picked over the

322
00:17:53,540 --> 00:17:54,980
and player

323
00:17:56,300 --> 00:17:57,880
doesn't assume

324
00:17:57,920 --> 00:17:59,190
the majority

325
00:17:59,240 --> 00:18:01,230
all that the space

326
00:18:02,870 --> 00:18:03,930
the model is

327
00:18:04,010 --> 00:18:07,270
called the moment

328
00:18:07,340 --> 00:18:12,730
and we can define

329
00:18:12,780 --> 00:18:16,520
the function that by this function

330
00:18:17,670 --> 00:18:19,640
this formula

331
00:18:28,610 --> 00:18:29,680
so if

332
00:18:29,690 --> 00:18:34,490
the statistical manifold is about

333
00:18:34,500 --> 00:18:37,460
in this case

334
00:18:39,580 --> 00:18:41,980
the geometric divergence point and we

335
00:18:42,000 --> 00:18:44,380
the canonical divergence

336
00:18:44,380 --> 00:18:45,770
but if want a

337
00:18:48,360 --> 00:18:49,740
but the soul

338
00:18:53,370 --> 00:18:59,650
and one for that is about this good morning there

339
00:18:59,690 --> 00:19:00,970
o thing

340
00:19:00,990 --> 00:19:03,860
potential function

341
00:19:03,900 --> 00:19:06,190
in this case

342
00:19:07,190 --> 00:19:12,030
his final match

343
00:19:12,030 --> 00:19:13,440
is one point three

344
00:19:13,440 --> 00:19:15,020
six six

345
00:19:15,040 --> 00:19:17,080
so p two

346
00:19:17,180 --> 00:19:22,300
one point three six sixty five one now this page

347
00:19:22,330 --> 00:19:25,060
is an overpressure gauge therefore

348
00:19:25,110 --> 00:19:27,780
you're not going to see this number but you're going to see the difference was

349
00:19:27,780 --> 00:19:28,990
one atmosphere

350
00:19:28,990 --> 00:19:30,990
so what the gates will show was

351
00:19:31,050 --> 00:19:33,000
is o point three

352
00:19:33,040 --> 00:19:34,600
six six

353
00:19:34,610 --> 00:19:36,680
times one atmosphere

354
00:19:36,750 --> 00:19:40,000
and since it is calibrated in

355
00:19:40,040 --> 00:19:41,740
pounds per square inch

356
00:19:41,760 --> 00:19:44,240
is o point three six six

357
00:19:44,290 --> 00:19:46,690
i'm fifty

358
00:19:46,690 --> 00:19:47,990
on the screen

359
00:19:48,080 --> 00:19:51,240
and that's about something like five point four

360
00:19:53,730 --> 00:19:56,640
that's what i predict

361
00:19:56,650 --> 00:19:59,930
and we'll see how close we get

362
00:19:59,940 --> 00:20:01,530
you're going to see this

363
00:20:01,550 --> 00:20:06,250
it all works well

364
00:20:06,830 --> 00:20:09,010
there is

365
00:20:09,140 --> 00:20:15,690
one is said to the light situation a little better for you

366
00:20:15,700 --> 00:20:16,960
i can even make it

367
00:20:17,020 --> 00:20:19,030
little dog

368
00:20:26,000 --> 00:20:28,000
this gauge

369
00:20:28,050 --> 00:20:31,040
as noted is zero even noticing

370
00:20:31,080 --> 00:20:34,480
i swore i opened this valve is opened

371
00:20:34,560 --> 00:20:40,250
so it is zero because it measures only of pressure

372
00:20:40,310 --> 00:20:44,580
now we're going to close this fell

373
00:20:44,630 --> 00:20:47,390
now there is now closed

374
00:20:47,670 --> 00:20:50,490
we're going to

375
00:20:50,500 --> 00:20:52,540
i think it here is this

376
00:20:52,650 --> 00:20:56,420
object that is the volume

377
00:20:56,560 --> 00:21:00,700
like the bathroom floated mean toilet flush that's what is probably

378
00:21:00,750 --> 00:21:03,920
and now goes into boiling water

379
00:21:03,960 --> 00:21:05,980
now look at pressure and go free

380
00:21:06,030 --> 00:21:07,270
three and a half

381
00:21:09,190 --> 00:21:11,600
all the pressure in pounds per square inch

382
00:21:11,650 --> 00:21:15,850
four and a half

383
00:21:16,080 --> 00:21:17,830
is given a little bit more time

384
00:21:17,850 --> 00:21:21,270
take a while of course because gases are very good

385
00:21:21,320 --> 00:21:22,730
insulators so

386
00:21:22,820 --> 00:21:25,910
may take awhile for the gas in the

387
00:21:25,950 --> 00:21:28,270
in the copper bowl two

388
00:21:28,330 --> 00:21:31,390
so really close to five

389
00:21:31,460 --> 00:21:34,450
we don't have to wait of course for the thing to become

390
00:21:34,460 --> 00:21:36,240
all the way five point five

391
00:21:36,280 --> 00:21:38,630
five point four

392
00:21:38,740 --> 00:21:41,990
but it will probably go up if we wait

393
00:21:42,070 --> 00:21:45,230
now five

394
00:21:45,230 --> 00:21:47,100
not much sense in waiting

395
00:21:47,150 --> 00:21:49,950
what i want you to

396
00:21:50,000 --> 00:21:52,700
i realize what happens or i want to ask you actually what happens if open

397
00:21:52,700 --> 00:21:56,490
the valve now

398
00:22:01,380 --> 00:22:03,720
so if i open developed in one atmosphere

399
00:22:03,730 --> 00:22:05,860
some of the high-pressure stuff

400
00:22:05,880 --> 00:22:06,760
that's out

401
00:22:06,780 --> 00:22:08,680
one atmosphere settles inside

402
00:22:08,720 --> 00:22:11,140
so since this one is a

403
00:22:11,150 --> 00:22:13,780
overpressure gates it will be zero

404
00:22:13,930 --> 00:22:16,090
so i know

405
00:22:19,810 --> 00:22:23,190
that's fine with me that's very close that was in a percent

406
00:22:23,340 --> 00:22:27,050
is class we had five point three but we were a little bit more patient

407
00:22:27,110 --> 00:22:29,200
i will often develop now

408
00:22:29,200 --> 00:22:31,930
and watch what happens

409
00:22:31,940 --> 00:22:33,340
goes back to zero

410
00:22:33,400 --> 00:22:37,390
some animals that out because the pressure inside

411
00:22:38,570 --> 00:22:40,000
was higher than

412
00:22:43,600 --> 00:22:45,430
so we see the tests

413
00:22:45,500 --> 00:22:47,000
reasonable test

414
00:22:47,100 --> 00:22:49,670
the first application of

415
00:22:51,380 --> 00:22:57,920
the ideal gas law

416
00:23:00,060 --> 00:23:03,130
can turn into a liquid and the liquid can become solid

417
00:23:03,130 --> 00:23:04,670
that depends entirely

418
00:23:04,680 --> 00:23:06,760
on the

419
00:23:06,830 --> 00:23:08,890
kind of substance the temperature

420
00:23:08,890 --> 00:23:10,170
the pressure

421
00:23:10,180 --> 00:23:12,020
that we have

422
00:23:12,080 --> 00:23:13,670
and this brings us to the

423
00:23:13,690 --> 00:23:16,440
field of what we call

424
00:23:16,480 --> 00:23:18,310
based on the ground

425
00:23:18,360 --> 00:23:23,970
i'll show you first commerical of phase diagram which is also on the web

426
00:23:23,980 --> 00:23:26,380
user interface that very

427
00:23:26,430 --> 00:23:28,920
in two it is pressure

428
00:23:31,740 --> 00:23:34,310
imagine that we have a similar

429
00:23:34,330 --> 00:23:37,410
and we put gas in that seven that we put the person on top

430
00:23:37,450 --> 00:23:39,170
and we push it down

431
00:23:39,220 --> 00:23:40,820
slowly pushing it down

432
00:23:40,910 --> 00:23:43,710
so we started with gas

433
00:23:43,750 --> 00:23:46,300
and in particular temperature which we're not going to change

434
00:23:46,310 --> 00:23:48,720
and we slowly pushed the piston down

435
00:23:48,750 --> 00:23:52,050
in this trajectory the ideal gas law would hold

436
00:23:52,060 --> 00:23:53,960
the temperature remains constant

437
00:23:53,980 --> 00:23:55,800
if you look at the gas law

438
00:23:55,860 --> 00:23:56,670
if e

439
00:23:56,670 --> 00:24:00,540
remains constant that's called OIL is low by the way that the product of

440
00:24:00,610 --> 00:24:03,060
pressure and volume remains constant

441
00:24:03,140 --> 00:24:06,180
so the pressure in the gas goes up the volume goes down pressure goes up

442
00:24:06,180 --> 00:24:08,130
volume goes down pressure goes up

443
00:24:08,170 --> 00:24:10,650
until i had this point

444
00:24:10,660 --> 00:24:12,160
and now

445
00:24:12,230 --> 00:24:14,760
liquid is going to be four

446
00:24:14,830 --> 00:24:16,750
the depression is not high enough

447
00:24:16,760 --> 00:24:20,130
this temperature to form liquid

448
00:24:20,170 --> 00:24:22,270
if i push further

449
00:24:22,330 --> 00:24:24,020
the pressure will not go up

450
00:24:24,080 --> 00:24:28,520
all the gas will first turn into liquid all of it until the last

451
00:24:29,940 --> 00:24:32,800
and not until everything has become liquid

452
00:24:32,820 --> 00:24:35,480
can i pushed even further on liquid

453
00:24:35,480 --> 00:24:38,530
to increase the pressure on the liquid may be silly thing to do but i

454
00:24:38,530 --> 00:24:39,350
could do that

455
00:24:39,400 --> 00:24:40,630
you're not going to

456
00:24:40,640 --> 00:24:42,930
compress it very much which you can try

457
00:24:42,940 --> 00:24:44,590
and in some cases

458
00:24:44,610 --> 00:24:49,340
if you put a tremendous pressure on it you may turn the liquid into solid

459
00:24:49,430 --> 00:24:51,240
and then you read this domain

460
00:24:51,290 --> 00:24:53,580
where you have a solid

461
00:24:53,630 --> 00:24:55,360
what is much less intuitive

462
00:24:55,380 --> 00:24:58,210
that if you did it at a lower temperature

463
00:24:58,260 --> 00:25:01,860
and you squeeze the volume the pressure will go up

464
00:25:01,910 --> 00:25:05,610
but you may now reached the point here in this phase diagram by no liquid

465
00:25:05,610 --> 00:25:06,860
is formed

466
00:25:06,880 --> 00:25:10,710
no condensation of liquid but you get immediate the formation of crystals

467
00:25:10,730 --> 00:25:14,450
so you go from the gas phase immediately into the solid phase

468
00:25:14,490 --> 00:25:17,540
if you push further down the piston

469
00:25:17,590 --> 00:25:19,000
the pressure will not go up

470
00:25:19,040 --> 00:25:21,140
to all the gas has become

471
00:25:22,070 --> 00:25:24,160
and then i will continue

472
00:25:24,230 --> 00:25:26,590
to go further

473
00:25:26,630 --> 00:25:30,010
suppose this one atmosphere here

474
00:25:30,060 --> 00:25:34,730
and i took some ice we can take a piece of iron one atmosphere

475
00:25:34,730 --> 00:25:37,510
and it's a very low temperature solid

476
00:25:37,530 --> 00:25:39,500
and i started reading it up and keep

477
00:25:39,540 --> 00:25:41,310
the pressure one atmosphere

478
00:25:41,360 --> 00:25:43,440
the solid still the solid

479
00:25:43,480 --> 00:25:45,900
at this point it begins to melt

480
00:25:45,910 --> 00:25:48,490
this will be the melting point

481
00:25:48,540 --> 00:25:52,330
and when i keep eating its temperature will not go up until all the solid

482
00:25:52,330 --> 00:25:53,550
has been melted

483
00:25:53,560 --> 00:25:54,880
in two liquid

484
00:25:54,890 --> 00:25:57,160
then i can increase the temperature

485
00:25:57,170 --> 00:25:59,140
then the liquid will get hotter

486
00:25:59,250 --> 00:26:01,450
until you reach this line

487
00:26:01,500 --> 00:26:03,090
and when you read this line

488
00:26:03,110 --> 00:26:05,880
some of the liquid will turn into gas

489
00:26:07,060 --> 00:26:10,000
one of the few you'll see it boils

490
00:26:10,000 --> 00:26:11,820
you can increase the temperature

491
00:26:11,850 --> 00:26:15,350
if you do want to stay on the degrees centigrade there's nothing you can do

492
00:26:15,390 --> 00:26:18,130
until all the liquid has become gas

493
00:26:18,160 --> 00:26:19,420
we call it one of a

494
00:26:19,520 --> 00:26:21,150
then after that

495
00:26:21,160 --> 00:26:23,130
the temperature can be further increased

496
00:26:23,230 --> 00:26:26,320
so this point point will be melting point four

497
00:26:26,380 --> 00:26:28,160
i see war

498
00:26:28,170 --> 00:26:29,960
and this would be the boarding point

499
00:26:30,000 --> 00:26:31,970
at one atmosphere so that's the idea

500
00:26:32,020 --> 00:26:33,640
behind the phase diagram

501
00:26:33,640 --> 00:26:35,100
and we're going to use them

502
00:26:35,130 --> 00:26:36,960
today for some of our

503
00:26:39,410 --> 00:26:41,580
i have here

504
00:26:41,580 --> 00:26:45,370
i i

505
00:26:45,390 --> 00:26:48,580
just like that because there's only one thing the gamma function only comes in when

506
00:26:48,580 --> 00:26:49,890
you have multiple

507
00:26:52,700 --> 00:26:56,950
it would be the same thing but this is this is this is this is

508
00:26:56,950 --> 00:26:59,930
fine and that's pretty cheap

509
00:26:59,950 --> 00:27:02,700
these slides

510
00:27:07,040 --> 00:27:12,620
o by overly confused you by correcting my equations variant

511
00:27:12,640 --> 00:27:18,520
so in this case actually i think this is not more expensive than the other

512
00:27:18,520 --> 00:27:20,810
one this will be cheap

513
00:27:20,830 --> 00:27:22,310
so this better

514
00:27:22,330 --> 00:27:25,980
OK so good habit is to assess the convergence of the chain and one way

515
00:27:25,980 --> 00:27:29,680
to do that is to monitor the log probability of the state and observations for

516
00:27:29,680 --> 00:27:31,790
example by plotting autocorrelation

517
00:27:31,810 --> 00:27:36,140
and know that when you exponentially that quantity that is proportional to the posterior so

518
00:27:36,140 --> 00:27:39,620
even though you don't have access to the normalizing constant of the posterior you do

519
00:27:39,620 --> 00:27:43,080
have access to something proportional to it and you can monitor that to see where

520
00:27:43,080 --> 00:27:46,060
chain is on the surface of the posterior

521
00:27:46,060 --> 00:27:49,120
and so for example

522
00:27:49,200 --> 00:27:50,480
with the the

523
00:27:50,480 --> 00:27:51,970
with the collapse

524
00:27:51,980 --> 00:27:53,080
gibbs sampler

525
00:27:53,080 --> 00:27:55,310
here i took a document from cora

526
00:27:55,330 --> 00:27:59,580
and i ran the collapsed gibbs sampler and here i plotted the log probability of

527
00:27:59,580 --> 00:28:04,640
the hidden and observed variables as a function of iteration and you can see that

528
00:28:04,640 --> 00:28:08,290
we started here and we climbed inclined inclined

529
00:28:08,310 --> 00:28:12,200
up to their actually this including the topics this is the whole core dataset but

530
00:28:12,200 --> 00:28:15,830
it's the same principle it's the same score and we are

531
00:28:15,850 --> 00:28:20,210
climbing in the posterior and then flattening out somewhere

532
00:28:22,370 --> 00:28:25,060
and if you zoom in on

533
00:28:25,080 --> 00:28:29,100
i iteration i think two hundred on the five hundred you can see that we're

534
00:28:29,100 --> 00:28:33,430
kind of jumping all around the posterior and it's more or less flat

535
00:28:33,430 --> 00:28:37,660
this is not an exact science i know there are

536
00:28:37,680 --> 00:28:42,560
other heuristics that you can use more computational heuristics to assess convergence but the point

537
00:28:42,560 --> 00:28:45,430
is that it's a good habit to do something rather than just to run for

538
00:28:45,430 --> 00:28:47,270
some number of iterations

539
00:28:47,290 --> 00:28:49,520
and stop there

540
00:28:55,020 --> 00:28:57,230
just say no

541
00:28:57,310 --> 00:29:00,290
slides are mass this

542
00:29:00,310 --> 00:29:05,790
this is the collapsed gibbs sampler with this equation gone this and this the collapsed

543
00:29:05,790 --> 00:29:07,060
gibbs sampling

544
00:29:07,080 --> 00:29:08,430
when i was thinking

545
00:29:14,560 --> 00:29:16,230
OK so

546
00:29:16,290 --> 00:29:20,870
the next thing i want to talk about is variational inference for LDA

547
00:29:21,020 --> 00:29:24,000
any remaining questions about gibbs sampling

548
00:29:26,700 --> 00:29:34,390
now this is the borders right

549
00:29:34,410 --> 00:29:38,270
the board i love the board i hate the slots

550
00:29:42,540 --> 00:29:43,910
get this is fine

551
00:29:43,930 --> 00:29:53,430
well so there is so in the collapse good question the change is just the

552
00:29:53,450 --> 00:29:55,270
so if you want to estimate of theta

553
00:29:55,290 --> 00:29:58,850
for particular state of the chain then what you do is you take the disease

554
00:29:58,850 --> 00:30:01,890
and you look at the post your seriously given those is

555
00:30:01,910 --> 00:30:03,910
and that gives you are

556
00:30:03,950 --> 00:30:08,020
oppose the an estimate of the distribution of data given that state the chain

557
00:30:08,020 --> 00:30:09,350
thanks sense

558
00:30:09,540 --> 00:30:14,080
you do whatever you want with that distribution you can take the map you take

559
00:30:14,100 --> 00:30:14,930
the mean

560
00:30:17,560 --> 00:30:19,980
other questions it's good question

561
00:30:20,000 --> 00:30:26,100
yes we will learning data

562
00:30:26,180 --> 00:30:28,040
yeah i'll talk about that

563
00:30:30,310 --> 00:30:38,540
OK so variational methods variational methods are a deterministic alternative to MCMC and you've seen

564
00:30:38,540 --> 00:30:45,220
them already so in general if we have x the observations and zeevi any latent

565
00:30:45,220 --> 00:30:50,730
variables our goal is to compute this posterior and this is not easy to compute

566
00:30:50,750 --> 00:30:52,560
OK so

567
00:30:52,560 --> 00:30:56,520
but for the test data they do tell you the annexe

568
00:30:56,550 --> 00:31:00,040
and they're going to tell you the annexe at test time as well the training

569
00:31:00,040 --> 00:31:04,000
time then why bother learning anything about the axis

570
00:31:17,390 --> 00:31:19,490
i think

571
00:31:19,550 --> 00:31:22,630
i think i think the short answer your question is yes

572
00:31:24,950 --> 00:31:31,020
so let me let me to explain a little bit so you know imagine that

573
00:31:31,070 --> 00:31:34,820
so we talk about supervised learning so we think of x being the input is

574
00:31:34,820 --> 00:31:39,380
being the output and so your input x might be english sentence on the output

575
00:31:39,390 --> 00:31:42,120
y might be a french sentence

576
00:31:44,540 --> 00:31:46,810
this action is of so

577
00:31:47,360 --> 00:31:49,650
let me

578
00:31:55,630 --> 00:31:59,640
the scenario

579
00:31:59,650 --> 00:32:05,430
it's actually cause english sentence

580
00:32:05,480 --> 00:32:09,600
y equals french sentence

581
00:32:09,640 --> 00:32:13,040
you have training

582
00:32:13,050 --> 00:32:16,800
you have x y pairs

583
00:32:16,830 --> 00:32:19,100
and then for test

584
00:32:19,120 --> 00:32:20,060
you have

585
00:32:20,150 --> 00:32:21,850
x given

586
00:32:21,930 --> 00:32:24,940
why and

587
00:32:24,960 --> 00:32:28,510
and what you want to

588
00:32:28,520 --> 00:32:32,310
you need a function

589
00:32:32,330 --> 00:32:34,930
probability of y given x

590
00:32:34,940 --> 00:32:39,510
and then in principle you could do translation by choosing

591
00:32:39,520 --> 00:32:43,230
the nice o output

592
00:32:43,270 --> 00:32:45,370
why that is

593
00:32:47,670 --> 00:32:49,960
p of y given x

594
00:32:56,870 --> 00:33:00,050
now what's the language model

595
00:33:00,240 --> 00:33:01,760
i think

596
00:33:02,200 --> 00:33:09,920
a language model

597
00:33:09,950 --> 00:33:11,370
is a

598
00:33:11,370 --> 00:33:12,810
the problem is

599
00:33:12,820 --> 00:33:16,040
i guess technically polymaths functions

600
00:33:16,080 --> 00:33:19,990
that p of y

601
00:33:20,040 --> 00:33:25,460
and so if y is french sentences then this would be a probability function that

602
00:33:25,460 --> 00:33:28,690
tells you which french sentence is unlikely

603
00:33:28,700 --> 00:33:33,820
which would be correct sentences and then which french sentence is unlikely that would be

604
00:33:33,820 --> 00:33:39,960
incorrect sentences and they would have low probability and more when you're choosing a y

605
00:33:40,000 --> 00:33:41,670
to be your output

606
00:33:41,710 --> 00:33:46,010
if you really wanted to satisfy two criteria you wanted to

607
00:33:46,020 --> 00:33:50,600
i have a high probability given the input english sentence and he also wanted to

608
00:33:50,600 --> 00:33:52,630
be a good french sentence

609
00:33:52,690 --> 00:33:55,060
so language models

610
00:33:56,350 --> 00:34:01,380
so language models actually used to

611
00:34:01,390 --> 00:34:04,890
to tell you the probability of the output sentence being good sentence

612
00:34:04,900 --> 00:34:09,690
in the output language and if i have this formula so this is just a

613
00:34:09,690 --> 00:34:13,770
simple formula probability theory and i can also write it

614
00:34:13,800 --> 00:34:14,750
p of y

615
00:34:14,750 --> 00:34:18,360
times p of x given y

616
00:34:21,600 --> 00:34:26,760
well then actually the statistical approach to machine translation

617
00:34:28,440 --> 00:34:30,370
building a language model somehow

618
00:34:30,380 --> 00:34:31,720
which is

619
00:34:31,760 --> 00:34:33,540
a model of p of y

620
00:34:33,550 --> 00:34:37,750
and then really building an inverse

621
00:34:37,760 --> 00:34:39,720
well you could call an inverse

622
00:34:39,730 --> 00:34:41,200
translation model

623
00:34:41,280 --> 00:34:45,640
which is the probability of the english sentence given the french sentence

624
00:34:52,580 --> 00:34:55,020
i guess some

625
00:34:55,140 --> 00:34:57,760
and there are reasons why

626
00:34:57,780 --> 00:34:59,130
they do it this way

627
00:34:59,140 --> 00:35:01,480
rather than doing it this way

628
00:35:01,500 --> 00:35:03,220
and more

629
00:35:03,240 --> 00:35:06,750
i think you know we if you did it this way

630
00:35:06,750 --> 00:35:09,410
then you have people doing all your eggs in one basket you need to learn

631
00:35:09,420 --> 00:35:12,650
of very good morning p of y given x and if you do it this

632
00:35:12,650 --> 00:35:14,760
way your from

633
00:35:14,780 --> 00:35:18,180
it said it to divide and conquer approach to the problem you can try to

634
00:35:18,180 --> 00:35:22,750
make this model good you can also separate try to make this model could but

635
00:35:22,750 --> 00:35:25,000
i'm not an expert on

636
00:35:25,010 --> 00:35:28,260
must statistical

637
00:35:28,260 --> 00:35:32,950
because it would seem weird they were before my data points are completely independent then

638
00:35:32,950 --> 00:35:36,650
i'm not going to learn anything so i think the noise being i think so

639
00:35:36,670 --> 00:35:40,350
if we make this IID assumption that noise is coming independently each time then we

640
00:35:40,350 --> 00:35:42,050
can write down

641
00:35:42,090 --> 00:35:46,670
independence allows us to write the joint distribution of y is just the product of

642
00:35:46,670 --> 00:35:51,510
the marginals so we can write that down in apple and that's the standard sort

643
00:35:51,520 --> 00:35:56,350
assumption for a regression problem and that means that we have the likelihood of this

644
00:35:57,130 --> 00:36:01,510
so the likelihood is the joint distribution of these counts things now what we're going

645
00:36:01,510 --> 00:36:03,550
to do is click through here

646
00:36:03,550 --> 00:36:05,600
we're going look at that and say

647
00:36:05,620 --> 00:36:10,080
OK this time but it's not depend on these parameters that i was fifteen before

648
00:36:10,080 --> 00:36:13,210
so i'm going to ignore it and i'm just going to say this is proportional

649
00:36:13,210 --> 00:36:17,110
to that that was the constant proportionality to keep this kind of one so i'm

650
00:36:17,170 --> 00:36:19,210
going to drop

651
00:36:19,230 --> 00:36:22,890
now look at the product and say well i can pull up look inside the

652
00:36:22,890 --> 00:36:28,080
exponential productivity exponentials is the same as the exponential of the sum

653
00:36:28,150 --> 00:36:29,540
so i'm going do that

654
00:36:29,550 --> 00:36:33,590
then i'm going to look at the exponential and say well i can remove that

655
00:36:33,590 --> 00:36:35,930
by putting the logarithm on the other side

656
00:36:35,990 --> 00:36:38,150
so now i've got something of this form

657
00:36:38,980 --> 00:36:40,860
by constant proportionality

658
00:36:40,860 --> 00:36:44,460
now becomes an additive constant here

659
00:36:44,470 --> 00:36:47,860
now look at that and say well OK

660
00:36:49,600 --> 00:36:52,040
a scalable

661
00:36:52,050 --> 00:36:55,160
that is equal to the error function i defined before

662
00:36:59,400 --> 00:37:02,040
we were minimizing the error function

663
00:37:02,050 --> 00:37:06,300
but now we can see that our function is equivalent to a negative

664
00:37:08,440 --> 00:37:11,780
OK negative so if i minimize

665
00:37:11,780 --> 00:37:16,170
something and then take negative by maximizing the negative so in fact if i minimize

666
00:37:16,170 --> 00:37:18,980
the error function on maximizing the log likelihood

667
00:37:19,050 --> 00:37:23,330
many important thing about the log is a monotonic function i never got that power

668
00:37:23,330 --> 00:37:25,220
to deny

669
00:37:25,520 --> 00:37:27,880
well i draw them

670
00:37:27,890 --> 00:37:30,640
if i think that the log is a monotonic function

671
00:37:30,650 --> 00:37:32,740
so you've got a monotonic function

672
00:37:32,770 --> 00:37:35,650
if you maximize something

673
00:37:35,680 --> 00:37:38,780
and then you might and then you put it through monotonic function

674
00:37:38,780 --> 00:37:43,960
it doesn't change the ordering of things so if i you can think about that

675
00:37:43,960 --> 00:37:47,130
in the discrete case

676
00:37:47,150 --> 00:37:50,780
if i take the logarithm of a discrete set of numbers and then i want

677
00:37:50,780 --> 00:37:53,600
to find the function so i have something

678
00:37:53,600 --> 00:37:55,990
not explained very well

679
00:37:56,020 --> 00:38:01,810
because is a monotonic function if i maximize the

680
00:38:01,810 --> 00:38:05,430
log this i'm also maximizing that itself

681
00:38:05,490 --> 00:38:08,980
so i can take the negative log likelihood i can minimise the negative log likelihood

682
00:38:08,980 --> 00:38:12,760
on effectively maximizing the like

683
00:38:12,800 --> 00:38:16,820
so the probabilistic interpretation of the error function is the negative log likelihood

684
00:38:16,870 --> 00:38:21,170
and minimize the error function is equivalent to maximizing the log likelihood to maximize the

685
00:38:21,170 --> 00:38:26,130
log likelihood is equivalent to maximizing the likelihood because log is monotonic so

686
00:38:26,700 --> 00:38:29,810
the this is the probabilistic interpretation of the error function

687
00:38:29,810 --> 00:38:33,280
it's basically there

688
00:38:33,290 --> 00:38:38,010
minimize the error function is equivalent to maximizing likelihood with respect the

689
00:38:38,030 --> 00:38:39,550
so this is called max what

690
00:38:39,560 --> 00:38:41,360
so everything we saw before

691
00:38:41,390 --> 00:38:46,890
can be reinterpreted in that way now there was a question in

692
00:38:46,930 --> 00:38:50,630
the break after spoke last time is it true that every error functions

693
00:38:50,640 --> 00:38:54,030
can be interpreted as

694
00:38:54,070 --> 00:38:56,540
and maximum likelihood and the answer is no

695
00:38:56,550 --> 00:39:01,120
because you can imagine error functions the you can't normalize and if you can't see

696
00:39:01,130 --> 00:39:04,180
when you take the exponential

697
00:39:04,200 --> 00:39:05,680
the error function

698
00:39:05,690 --> 00:39:09,590
you can't actually normalized result and if that's the case you can't think of is

699
00:39:09,590 --> 00:39:10,970
maximal likelihood

700
00:39:11,020 --> 00:39:15,860
because we don't have this property of the probability distribution so normalisation is vital for

701
00:39:15,860 --> 00:39:17,810
to find something

702
00:39:20,310 --> 00:39:23,790
but most things that people are using typically

703
00:39:23,810 --> 00:39:27,910
can be treated that way i the example that was given was an example model

704
00:39:28,020 --> 00:39:31,680
but the most sort of standard things people using is error functions you can interpret

705
00:39:31,690 --> 00:39:33,850
as likely

706
00:39:34,440 --> 00:39:38,710
if the data was really generated according to model we specify that like you really

707
00:39:38,710 --> 00:39:41,220
had calcium noise plus that

708
00:39:41,460 --> 00:39:45,440
a weighted linear some of basis functions then what you can say is that the

709
00:39:45,440 --> 00:39:50,010
current parameters will be converted in the limit as n goes to infinity personally this

710
00:39:50,010 --> 00:39:52,300
is you know the a consistency proof

711
00:39:52,300 --> 00:39:57,420
i don't remember the last time someone gave me infinite data so i'm not sure

712
00:39:57,420 --> 00:40:02,030
how much i care about these proofs personally it's not missing is the rate of

713
00:40:02,030 --> 00:40:04,180
convergence is actually quite important

714
00:40:04,200 --> 00:40:08,440
but in some sense i really am interested in very low data rate areas so

715
00:40:08,860 --> 00:40:12,630
it's true you know i a lot of what's a google are doing with very

716
00:40:12,630 --> 00:40:16,230
large datasets is relying on this you know got limited number of parameters lot of

717
00:40:16,230 --> 00:40:20,380
data and things work really well in that region and you can prove that this

718
00:40:20,380 --> 00:40:24,400
is the case by and using the law of large numbers and i'm showing that

719
00:40:24,400 --> 00:40:29,170
what you're doing is is more minimizing what's called the kullback lieber divergence between the

720
00:40:29,170 --> 00:40:34,760
true distribution and your approximation and this is like a mainstay of classical statistics although

721
00:40:34,770 --> 00:40:39,840
i is credited to fisher law i'd really read the papers but you know you

722
00:40:39,840 --> 00:40:44,540
can go back to gases explanation of least squares what i've described to you in

723
00:40:44,540 --> 00:40:49,540
this error function is least squares and i think it talking gases so we explanation

724
00:40:49,550 --> 00:40:52,920
what the squares was because he didn't invent it then you're going back to something

725
00:40:52,920 --> 00:40:54,540
like eighteen ten

726
00:40:54,560 --> 00:40:58,350
the physicists were doing this so this is why i keep looking up is is

727
00:40:58,360 --> 00:41:03,090
something of a little bit ahead of machine learning people they just didn't have the

728
00:41:03,090 --> 00:41:09,060
computer so they that was their interpretation that was gases interpretation and claims that he

729
00:41:09,060 --> 00:41:14,020
found that planet series or whatever it's called the dwarf planet he re found where

730
00:41:14,020 --> 00:41:16,730
it was through applying this

731
00:41:16,790 --> 00:41:21,650
basically in the fact that he made that claim in order to justify he invented

732
00:41:21,650 --> 00:41:25,020
least squares for so that might be a bit dodgy

733
00:41:25,350 --> 00:41:27,710
the germans and french

734
00:41:27,730 --> 00:41:29,920
well there is is that it

735
00:41:29,930 --> 00:41:33,040
so this is the likelihood the the regression and the suggestion is to maximize its

736
00:41:33,040 --> 00:41:36,590
with respect to w that's what we've been doing in the last time that can

737
00:41:36,590 --> 00:41:40,120
be done with a gradient based optimisation of the log likelihood

738
00:41:41,220 --> 00:41:45,930
there's an alternative approach and this is the bayesian approach to the alternative approach is

739
00:41:45,930 --> 00:41:48,330
not two optimizes w

740
00:41:48,360 --> 00:41:50,960
but to integrate it out

741
00:41:51,020 --> 00:41:54,550
and this is where the controversy starts

742
00:41:56,020 --> 00:42:00,270
what we can do is effectively considered the expected values of all the likelihood under

743
00:42:00,290 --> 00:42:04,890
range of potential w that we believe so when i was talking before about

744
00:42:04,920 --> 00:42:09,640
prior knowledge of functions this effectively how in this model year introduced prior knowledge is

745
00:42:10,740 --> 00:42:13,110
i'm going to have a distribution

746
00:42:13,110 --> 00:42:13,840
for w

747
00:42:13,850 --> 00:42:16,470
so i purposefully right

748
00:42:16,490 --> 00:42:20,370
my parameters is conditioning as if they are random variables

749
00:42:20,380 --> 00:42:24,680
and that means i can think of p w and then use some rule to

750
00:42:24,680 --> 00:42:29,160
integrate and that's what goes on in the bayesian approach

751
00:42:29,930 --> 00:42:33,680
we can use bayes rule to implement bayes approach

752
00:42:33,730 --> 00:42:39,480
but bayesian is not named after bayes rule is very common confusion if you don't

753
00:42:39,480 --> 00:42:40,790
use bayes rule

754
00:42:40,790 --> 00:42:47,010
two inverse probability you're just wrong you're not being frequentist

755
00:42:47,030 --> 00:42:48,330
bayesian refers

756
00:42:48,350 --> 00:42:49,430
to something different

757
00:42:49,450 --> 00:42:54,390
what they refers to is this thing that i'm doing here treating the parameters of

758
00:42:54,390 --> 00:42:59,060
algorithms for training that have this adaptive learning rate

759
00:42:59,500 --> 00:43:03,020
property but a basic thing to do which tends to work well

760
00:43:03,510 --> 00:43:06,210
is to have a schedule which works as follows

761
00:43:06,400 --> 00:43:10,850
so use set the learning rate maybe to be fairly large initially

762
00:43:10,860 --> 00:43:14,370
to make big steps and train fairly rapidly initially say zero

763
00:43:14,380 --> 00:43:17,530
point one and then you keep track on the validation set

764
00:43:18,680 --> 00:43:20,790
what is the error what's the performance

765
00:43:20,920 --> 00:43:24,560
when it stops improving then you divide the learning rate by to

766
00:43:24,570 --> 00:43:27,990
continue training but also encourage if possible to go back

767
00:43:28,000 --> 00:43:31,060
to the point before it you know became worse

768
00:43:31,410 --> 00:43:35,450
and that's schedule i found works pretty well in practice

769
00:43:36,520 --> 00:43:41,830
yeah so so i guess you question is you know there is working optimization

770
00:43:41,840 --> 00:43:45,050
that would suggests sort of metrics to keep track of

771
00:43:45,490 --> 00:43:50,740
to determine schedule yeah i think might be used by some people

772
00:43:50,740 --> 00:43:53,790
for sure but i found much like early stopping for some reason is

773
00:43:53,790 --> 00:43:56,450
very effective of getting rid of the regularizer

774
00:43:56,970 --> 00:44:00,880
again validation set performance tracking is very useful

775
00:44:00,890 --> 00:44:03,530
signal for knowing when you learning rates to high

776
00:44:04,020 --> 00:44:07,920
so there might be things that are slightly better but this is just

777
00:44:07,930 --> 00:44:13,730
like impressively you know effective procedure yes

778
00:44:31,920 --> 00:44:35,640
yes so as i guess the question is you know you mentioned that

779
00:44:36,180 --> 00:44:39,350
sometimes even if the error gets worse on the validation set

780
00:44:39,350 --> 00:44:44,940
might become better later on for instance we know that the optimization

781
00:44:44,940 --> 00:44:47,900
problem when training neural that is really in nonconvex optimization

782
00:44:47,900 --> 00:44:52,860
problem so it is possible to draw a line in in non-convex function

783
00:44:52,990 --> 00:44:55,450
and where you would go up but then goal down

784
00:44:55,980 --> 00:44:59,510
lower later on because you were in a local minimum and maybe later

785
00:44:59,520 --> 00:45:02,520
on each other better local maybe global optimum

786
00:45:02,800 --> 00:45:06,810
that this is a that is not like that can happen

787
00:45:07,160 --> 00:45:10,170
because of this like you can deftly construct cases where

788
00:45:10,330 --> 00:45:16,450
this happens but it's hard to i don't have any good advice to like

789
00:45:16,450 --> 00:45:19,360
when should you then ignored validation set for a while

790
00:45:19,400 --> 00:45:23,180
look ahead can play this role bits so you can say ok i'm actually

791
00:45:23,190 --> 00:45:28,120
going to weight you know just not if the if it if it gets worse

792
00:45:28,130 --> 00:45:30,940
the next step actually like the x ten steps

793
00:45:31,170 --> 00:45:34,500
maybe goes back down and then you just you're back to as if you

794
00:45:34,500 --> 00:45:39,040
didn't stop and this is partly why i tend to use a look ahead of

795
00:45:39,040 --> 00:45:42,230
a few iterations so this will partially addressed this like it

796
00:45:42,230 --> 00:45:45,950
doesn't matter if it goes up if it eventually goes down better lower

797
00:45:45,960 --> 00:45:49,470
number than which found so far before the look ahead you've given

798
00:45:49,700 --> 00:45:53,340
you're training procedure you will cover that situation

799
00:45:55,610 --> 00:45:59,340
maybe one rk yeah let's go yeah good

800
00:46:16,940 --> 00:46:21,160
yes so so yes so the question is mentioning this

801
00:46:21,470 --> 00:46:25,860
result that states that stochastic gradient descent

802
00:46:26,270 --> 00:46:31,100
will converge if the sum of the learning rates using a schedule

803
00:46:32,430 --> 00:46:34,940
eventually actually divergence

804
00:46:35,130 --> 00:46:38,360
to infinity but the sum of the square of the learning rate

805
00:46:38,600 --> 00:46:41,850
actually converges is convergence some that are in the

806
00:46:41,860 --> 00:46:46,080
early called result in terms of converging over the training problem

807
00:46:46,680 --> 00:46:49,950
again the big advantage of using the validation set it's not

808
00:46:49,960 --> 00:46:53,960
just to measure its indirectly measure are good you're doing optimising

809
00:46:53,970 --> 00:46:56,830
but it's mostly measure good you're doing generalizing

810
00:46:56,830 --> 00:47:01,760
and that is like it's big value so so i think this

811
00:47:01,910 --> 00:47:05,240
this result essentially just guarantees convergence not to sell

812
00:47:05,240 --> 00:47:09,140
the fass converge like it has a complexity associated with that

813
00:47:09,770 --> 00:47:12,530
this statement here about this know decay

814
00:47:12,710 --> 00:47:15,460
schedule is something that in practice been found to

815
00:47:15,640 --> 00:47:18,540
work really well and i don't know how much

816
00:47:18,690 --> 00:47:22,020
theory there is behind like this schedule just in practice it's

817
00:47:22,020 --> 00:47:22,760
very effective

818
00:47:26,450 --> 00:47:29,880
i mean that's yes so the question is about new normalizing

819
00:47:29,890 --> 00:47:34,900
does always work i guess so there might be better normalization

820
00:47:34,910 --> 00:47:38,460
so for instance you can do that ca whitening

821
00:47:39,030 --> 00:47:42,820
removing also second orders correlations between the dimensions

822
00:47:42,830 --> 00:47:43,830
and i can also help

823
00:47:46,220 --> 00:47:48,120
because depends who you mean by word

824
00:47:48,120 --> 00:47:51,160
to avoid possible misunderstandings

825
00:47:51,190 --> 00:47:55,800
my lectures start nine thirty eastern standard time which is different

826
00:47:55,890 --> 00:47:59,010
from lobby seven times you may have noticed

827
00:47:59,010 --> 00:48:01,980
o the clock and will be seventy seven minutes long

828
00:48:02,040 --> 00:48:05,240
today we're going to cover coupled oscillators

829
00:48:05,300 --> 00:48:08,260
this is a big part in eight three

830
00:48:08,300 --> 00:48:13,400
though we leave out them in order to afford major complications

831
00:48:14,450 --> 00:48:15,800
that i have

832
00:48:18,580 --> 00:48:21,050
thanks al mass and

833
00:48:21,060 --> 00:48:23,200
and have

834
00:48:23,230 --> 00:48:24,680
also mass and

835
00:48:24,690 --> 00:48:26,480
the length l

836
00:48:26,520 --> 00:48:27,870
and i connect

837
00:48:27,910 --> 00:48:29,230
the spring

838
00:48:29,400 --> 00:48:31,400
three dimensions see there

839
00:48:31,460 --> 00:48:36,710
spring constant k

840
00:48:36,760 --> 00:48:39,820
imagine our time t equals zero

841
00:48:39,980 --> 00:48:42,010
that i

842
00:48:42,020 --> 00:48:47,290
if this object which i call object number one and this is object number two

843
00:48:47,350 --> 00:48:49,210
given a certain position

844
00:48:49,210 --> 00:48:53,050
given a certain velocity so i e four choices

845
00:48:53,070 --> 00:48:55,460
and that the system go

846
00:48:55,480 --> 00:48:59,410
what you're going to see is something extremely chaotic

847
00:48:59,430 --> 00:49:01,710
on our task today is

848
00:49:01,730 --> 00:49:03,350
to predict

849
00:49:03,400 --> 00:49:06,680
what the position of this one is at any moment in time

850
00:49:06,680 --> 00:49:11,270
what the position the position of that one is at any moment in time

851
00:49:11,400 --> 00:49:14,130
to show you how chaotic that motion is

852
00:49:14,130 --> 00:49:16,480
i'll just

853
00:49:16,490 --> 00:49:17,630
so it is

854
00:49:17,650 --> 00:49:19,600
so i take this one

855
00:49:19,660 --> 00:49:24,260
this displace it from a colombian i displays this one from equilibrium at time t

856
00:49:24,260 --> 00:49:26,380
equals zero i'll give the one

857
00:49:26,400 --> 00:49:29,490
my left hand just as a certain velocity

858
00:49:29,540 --> 00:49:31,400
and if you look at the

859
00:49:31,480 --> 00:49:34,710
position of the individual objects

860
00:49:34,720 --> 00:49:35,740
it would

861
00:49:35,780 --> 00:49:38,060
see nearly impossible

862
00:49:38,110 --> 00:49:40,970
to come with a analytic solution

863
00:49:41,020 --> 00:49:44,930
which tells you what these motions are you will see it amplitudes build up

864
00:49:44,950 --> 00:49:49,220
of certain ones amplitude goes down this one is hardly moving at all now not

865
00:49:49,220 --> 00:49:50,670
speaking up again

866
00:49:50,720 --> 00:49:52,890
so our task today is

867
00:49:52,930 --> 00:49:55,500
to work on with

868
00:49:55,550 --> 00:49:59,180
what is by no means obvious but i'll show that to you

869
00:49:59,220 --> 00:50:00,780
that any motion

870
00:50:00,800 --> 00:50:03,090
no matter how you started off

871
00:50:03,110 --> 00:50:05,270
it's going to be the superposition

872
00:50:05,270 --> 00:50:06,520
of two

873
00:50:06,560 --> 00:50:09,770
normal mode solutions

874
00:50:09,810 --> 00:50:11,470
anyway you started

875
00:50:11,490 --> 00:50:14,000
can always be written

876
00:50:14,960 --> 00:50:20,150
the superposition of two normal mode solutions what is a normal mode and normal mode

877
00:50:20,150 --> 00:50:23,050
is in this case that both objects

878
00:50:23,060 --> 00:50:25,220
i have exactly the same frequency

879
00:50:25,280 --> 00:50:28,000
it is fundamental to normal mode

880
00:50:28,860 --> 00:50:32,640
that they either in phase with each other or out of phase with each other

881
00:50:32,650 --> 00:50:34,060
nothing in between

882
00:50:34,080 --> 00:50:37,930
because there's no damping so it's either in phase or out of phase

883
00:50:37,990 --> 00:50:40,770
that is the normal mode

884
00:50:40,830 --> 00:50:43,200
in other words if i call

885
00:50:43,210 --> 00:50:48,550
one of those frequencies omega minus minus means it is the lowest frequency there are

886
00:50:48,560 --> 00:50:52,300
two frequencies in this system because the two objects

887
00:50:52,310 --> 00:50:54,430
omega minor cycle that

888
00:50:54,430 --> 00:50:56,640
the lowest frequency

889
00:50:56,680 --> 00:50:58,310
then it would mean

890
00:50:58,330 --> 00:50:59,500
if they are

891
00:50:59,550 --> 00:51:01,770
in freeze was it's over the two

892
00:51:01,830 --> 00:51:05,110
that country will hold the same moment in time

893
00:51:05,150 --> 00:51:08,430
that means in phase and in the same direction

894
00:51:08,470 --> 00:51:11,530
so to come to all the same moment in time

895
00:51:11,580 --> 00:51:14,680
in the same direction and they have the same frequency

896
00:51:14,780 --> 00:51:19,030
if then i have another frequency which is higher

897
00:51:19,120 --> 00:51:22,800
there are two normal modes because we have two objects we have three objects there

898
00:51:22,800 --> 00:51:25,460
are three normal modes

899
00:51:25,520 --> 00:51:26,840
if we go to

900
00:51:26,860 --> 00:51:30,120
higher normal motor higher frequency

901
00:51:30,120 --> 00:51:31,810
they have the same frequency

902
00:51:31,830 --> 00:51:34,620
but they are on the eighty degrees out of phase

903
00:51:34,680 --> 00:51:36,960
so when one comes to a whole year

904
00:51:36,960 --> 00:51:38,840
other one comes to the whole there

905
00:51:38,860 --> 00:51:43,210
that's what it means on the eighty degrees out of phase

906
00:51:43,210 --> 00:51:45,020
i can excite

907
00:51:45,020 --> 00:51:46,850
and i will excite

908
00:51:46,960 --> 00:51:51,020
this system into its normal modes only i can excite

909
00:51:51,090 --> 00:51:57,900
this normal mode along and this normal modes along if i choose the correct initial

910
00:52:00,630 --> 00:52:02,060
so for any

911
00:52:02,100 --> 00:52:03,660
randomly chosen

912
00:52:03,670 --> 00:52:06,210
initial condition

913
00:52:06,210 --> 00:52:08,610
the motion of each object

914
00:52:08,650 --> 00:52:10,350
can be written as a linear

915
00:52:10,390 --> 00:52:12,880
combination of these two modes

916
00:52:12,920 --> 00:52:13,940
if you take

917
00:52:13,950 --> 00:52:17,960
my work for that for now but of course i will demonstrate you and i

918
00:52:17,960 --> 00:52:19,590
will prove that to you

919
00:52:19,650 --> 00:52:21,530
it would mean that

920
00:52:23,420 --> 00:52:26,170
o channel time

921
00:52:26,190 --> 00:52:30,360
can then be written as having some kind of an amplitude x zero i give

922
00:52:30,360 --> 00:52:35,270
you the minus sign because it's related to that the normal mode frequencies

923
00:52:35,280 --> 00:52:36,820
times the cosine

924
00:52:36,830 --> 00:52:38,400
of omega minus

925
00:52:38,970 --> 00:52:43,090
class some five minus

926
00:52:44,210 --> 00:52:47,710
some of the amplitude which i call x zero plus

927
00:52:47,760 --> 00:52:50,670
which is going to be related to this frequency

928
00:52:50,760 --> 00:52:52,270
times of science

929
00:52:52,340 --> 00:52:53,960
of omega class

930
00:52:55,690 --> 00:52:57,900
five class

931
00:52:57,960 --> 00:52:59,150
let's look

932
00:53:00,290 --> 00:53:04,440
let's try to see through this what this means

933
00:53:04,450 --> 00:53:05,600
it means

934
00:53:07,710 --> 00:53:09,880
if i know my initial conditions

935
00:53:09,890 --> 00:53:11,720
i can determine

936
00:53:11,770 --> 00:53:13,900
this amplitude i can determine

937
00:53:13,910 --> 00:53:19,520
this phase i can from this amplitude that i can determine this for

938
00:53:19,520 --> 00:53:21,540
there have to be four

939
00:53:22,700 --> 00:53:28,020
constant because i have the choice between the positions at the zero and the velocity

940
00:53:28,020 --> 00:53:30,440
so there must be four

941
00:53:30,460 --> 00:53:33,040
what you see is that all we good minus

942
00:53:33,070 --> 00:53:34,860
and omega plus

943
00:53:34,910 --> 00:53:40,840
which ideas normal mode frequencies are independent of the initial conditions

944
00:53:40,970 --> 00:53:42,910
and i'm going to write down

945
00:53:43,000 --> 00:53:47,330
the position in time for object number two

946
00:53:47,330 --> 00:53:49,850
functions it wouldn't

947
00:53:49,870 --> 00:53:55,300
it is meaningful to many of you i wish watershed intuition another sort of you

948
00:53:55,300 --> 00:53:59,440
know sort of reason to switch to state action values versus of was the state

949
00:53:59,440 --> 00:54:04,040
value the following even if i give you state values

950
00:54:04,050 --> 00:54:11,010
even if i give you the star just to compute the optimal action model

951
00:54:11,060 --> 00:54:12,880
well if i give you q star

952
00:54:12,890 --> 00:54:16,960
then to compute the optimal action i don't need more

953
00:54:16,960 --> 00:54:18,230
the reason

954
00:54:18,280 --> 00:54:19,150
if you like

955
00:54:19,860 --> 00:54:21,580
switch to state action values

956
00:54:21,590 --> 00:54:27,750
so this seemingly simple notational switch from state values state action values

957
00:54:27,810 --> 00:54:33,210
was critical in allowing us to develop a direct methods for the optimal control problem

958
00:54:33,250 --> 00:54:34,460
which one of them

959
00:54:34,480 --> 00:54:37,180
four pride prior to this

960
00:54:37,220 --> 00:54:40,270
seemingly very simple switch were putting values not on

961
00:54:40,320 --> 00:54:42,420
nodes but the edges

962
00:54:42,430 --> 00:54:48,630
like in this in that sense really made me distinctive OK swap back to how

963
00:54:48,630 --> 00:54:55,010
was any questions

964
00:55:06,360 --> 00:55:09,130
where you have to do is not to be

965
00:55:09,180 --> 00:55:11,400
i used to listen to compute the

966
00:55:12,960 --> 00:55:20,100
not sure the question but let me try to answer it anyway

967
00:55:20,120 --> 00:55:23,100
we live me answer by summarizing where we

968
00:55:23,110 --> 00:55:25,470
so you still have questions

969
00:55:33,040 --> 00:55:40,390
stepping back define two things define the policy evaluation problem and the optimal control problem

970
00:55:40,390 --> 00:55:42,710
in the context of markov processes

971
00:55:43,610 --> 00:55:48,360
the planning version of these algorithms problems and the learning version of

972
00:55:49,380 --> 00:55:53,810
and find the optimality equation for these two problems

973
00:55:53,920 --> 00:55:55,350
the planning case

974
00:55:55,360 --> 00:55:58,530
we've given the transition probability what functions you know

975
00:55:58,530 --> 00:56:01,300
solving this problem solving systems of equations

976
00:56:01,330 --> 00:56:05,190
there are many many different ways of solving systems of equations and perhaps what you

977
00:56:05,190 --> 00:56:06,180
are alluding to

978
00:56:06,210 --> 00:56:09,940
is that why not some other way of solving the system of equations

979
00:56:09,950 --> 00:56:11,740
and there will be just fine

980
00:56:11,820 --> 00:56:15,720
we just fine in fact i'm not going to talk about these things but there

981
00:56:15,720 --> 00:56:20,280
are also things like policy iteration methods for solving the system of equations and in

982
00:56:20,280 --> 00:56:24,220
the case of policy evaluation is actually a linear system of equations

983
00:56:24,490 --> 00:56:26,710
so can use matrix inversion

984
00:56:26,760 --> 00:56:30,670
to solve for the value function for a fixed policy

985
00:56:30,750 --> 00:56:32,020
it's worth writing this

986
00:56:32,040 --> 00:56:34,320
so the the

987
00:56:34,370 --> 00:56:38,190
and making hard time to the current this by the way

988
00:56:38,200 --> 00:56:39,280
is this right

989
00:56:39,310 --> 00:56:41,750
i don't want to

990
00:56:41,750 --> 00:56:43,500
your permanent marker

991
00:56:45,080 --> 00:56:46,740
OK so the

992
00:56:46,850 --> 00:56:49,210
recall the development the

993
00:56:49,280 --> 00:56:54,480
but policy evaluation problem the system equations was like this right for all pilots or

994
00:56:54,480 --> 00:56:56,190
pilots gamma

995
00:56:56,240 --> 00:56:58,040
some more or less prime p

996
00:57:00,120 --> 00:57:02,290
as prime given as high as

997
00:57:02,470 --> 00:57:07,630
the highest price right

998
00:57:07,670 --> 00:57:10,450
you can solve this equation how you want

999
00:57:10,490 --> 00:57:13,210
one way to solve it is the matrix inversion for

1000
00:57:13,230 --> 00:57:16,460
which is or enqueued event the number of states

1001
00:57:17,020 --> 00:57:23,230
operation to solve the system of equations and value iteration is or m squared each

1002
00:57:24,130 --> 00:57:27,860
depending how large n is how many iterations you have to do you want to

1003
00:57:27,860 --> 00:57:29,850
value iteration so

1004
00:57:29,860 --> 00:57:34,490
you know there are many different ways of solving

1005
00:57:34,520 --> 00:57:39,320
the policy evaluation from the optimal control problem the non-linear system of equations because the

1006
00:57:39,320 --> 00:57:40,690
max in there

1007
00:57:40,780 --> 00:57:41,730
and that

1008
00:57:41,780 --> 00:57:44,200
makes it for much fewer much

1009
00:57:44,210 --> 00:57:48,600
smaller choice of algorithms and value iteration is the outcome of choice

1010
00:57:48,620 --> 00:57:51,240
for solving for the optimal control

1011
00:57:51,770 --> 00:57:55,090
off policy that that's your question

1012
00:57:55,770 --> 00:57:57,930
let me

1013
00:57:57,960 --> 00:57:59,870
let me now

1014
00:58:00,030 --> 00:58:04,960
basically covered the very foundations the very basics of reinforcement so i'm about to die

1015
00:58:04,960 --> 00:58:09,310
would do more interesting and

1016
00:58:09,370 --> 00:58:12,010
sort of more new material so

1017
00:58:12,010 --> 00:58:15,590
let me just might not be apparent you why

1018
00:58:15,650 --> 00:58:19,780
why q learning is advance what real way is in advance so let me spend

1019
00:58:19,780 --> 00:58:21,460
a little bit of time

1020
00:58:21,500 --> 00:58:23,760
talking about that

1021
00:58:24,130 --> 00:58:26,340
the first observation to make is

1022
00:58:26,350 --> 00:58:31,540
q learning doesn't learn more what i mean models or m squared quantities right the

1023
00:58:31,540 --> 00:58:35,830
map from state actions the next state so states number is the number of states

1024
00:58:35,830 --> 00:58:39,640
and the roughly order and square quantities

1025
00:58:39,690 --> 00:58:42,920
you're trying to learn something or in square

1026
00:58:42,980 --> 00:58:47,780
value function of the other in order and

1027
00:58:47,830 --> 00:58:51,950
so q learning by the learner and squared quantity by indirect methods do

1028
00:58:51,990 --> 00:58:53,700
so you might think that

1029
00:58:54,510 --> 00:58:56,960
therefore q learning can be much more efficient

1030
00:58:57,010 --> 00:59:02,130
try to find learn more directly nor insert a newly less data as you might

1031
00:59:02,130 --> 00:59:07,280
think that learning is actually more efficient than the indirect method as a result that

1032
00:59:07,280 --> 00:59:13,030
that's one into the way of saying why q learning is is the p is

1033
00:59:14,010 --> 00:59:17,790
let me give you another intuition as to why q is purely think back to

1034
00:59:17,790 --> 00:59:23,150
the planning out what were we doing we were sweeping through the state space

1035
00:59:23,200 --> 00:59:27,730
at each iteration updating every stage

1036
00:59:27,800 --> 00:59:30,940
q learning runs around the world

1037
00:59:30,980 --> 00:59:36,240
and update state as you've seen

1038
00:59:37,000 --> 00:59:40,820
it leads to really important obvious simple point which is that

1039
00:59:40,880 --> 00:59:43,040
q learning in a sense

1040
00:59:43,060 --> 00:59:45,420
automatically focuses

1041
00:59:45,420 --> 00:59:47,890
updates on things that happened

1042
00:59:47,920 --> 00:59:49,290
on things that

1043
00:59:49,310 --> 00:59:53,560
hopefully means hopefully that means on things that matter

1044
00:59:53,570 --> 00:59:57,350
drive home the point a little bit you know in a more elaborate way but

1045
00:59:58,380 --> 01:00:01,210
reinforcement learning has nice property

1046
01:00:01,220 --> 01:00:06,450
that's because your learning from experience rather than to our model

1047
01:00:06,500 --> 01:00:10,540
in some sense experience is more immediately relevant

1048
01:00:10,600 --> 01:00:14,630
then learning to simulation model because

1049
01:00:14,730 --> 01:00:16,740
these are driven by

1050
01:00:16,790 --> 01:00:20,240
my experience that this is very vague and fuzzy and make this a bit more

1051
01:00:20,240 --> 01:00:21,490
how to current

1052
01:00:21,620 --> 01:00:23,230
cover image from the

1053
01:00:25,690 --> 01:00:27,010
six and

1054
01:00:29,330 --> 01:00:33,070
well in the in the

1055
01:00:33,120 --> 01:00:38,710
sender and actually we use the is quite a simple IQ linear strategy two

1056
01:00:39,750 --> 01:00:41,450
rather than to here

1057
01:00:41,530 --> 01:00:42,790
pixel colours

1058
01:00:42,810 --> 01:00:45,930
it's basically falstaff

1059
01:00:45,990 --> 01:00:47,900
firstly we start with this

1060
01:00:47,910 --> 01:00:49,550
just random draw

1061
01:00:51,580 --> 01:00:52,910
pixel labels

1062
01:00:52,930 --> 01:00:55,510
that we will build up

1063
01:00:55,520 --> 01:00:57,570
semi supervised learning model

1064
01:00:57,630 --> 01:01:00,850
and the value of the prediction results because in the

1065
01:01:00,900 --> 01:01:01,700
in there is

1066
01:01:01,730 --> 01:01:05,170
centre and we do have access to the truth

1067
01:01:05,300 --> 01:01:11,630
that we stop meets certain criteria

1068
01:01:15,620 --> 01:01:19,630
that is the sort of thing so how vigorously with some

1069
01:01:19,900 --> 01:01:22,390
catalytic example some some pollen

1070
01:01:26,040 --> 01:01:29,980
several in europe and

1071
01:01:30,030 --> 01:01:34,780
rather than simply so

1072
01:01:34,800 --> 01:01:37,410
labels from the pixels

1073
01:01:37,460 --> 01:01:40,120
then we can go through

1074
01:01:40,240 --> 01:01:42,610
step two and the totally

1075
01:01:44,290 --> 01:01:45,390
so basically

1076
01:01:45,410 --> 01:01:48,670
that's that's all i was in for the

1077
01:01:48,680 --> 01:01:50,670
sender around

1078
01:01:57,310 --> 01:02:00,120
so the implementation

1079
01:02:00,140 --> 01:02:03,690
a bit further technicality we actually we workings

1080
01:02:05,910 --> 01:02:09,040
luminance and chrominance space so

1081
01:02:09,060 --> 01:02:10,510
one space

1082
01:02:10,750 --> 01:02:13,480
and so says

1083
01:02:13,490 --> 01:02:15,070
the colours are

1084
01:02:15,100 --> 01:02:16,060
well the

1085
01:02:16,080 --> 01:02:17,580
three tunnels are more

1086
01:02:22,490 --> 01:02:26,440
then the and in RGB space and the we predict the colour

1087
01:02:26,460 --> 01:02:31,990
channels such that is you into the battles independently

1088
01:02:32,030 --> 01:02:36,690
and also we build the feature graph building some sliding windows

1089
01:02:37,800 --> 01:02:39,360
tamara the

1090
01:02:39,380 --> 01:02:41,770
to measure the similarity of clothing is

1091
01:02:41,780 --> 01:02:43,110
we all the

1092
01:02:43,130 --> 01:02:44,640
yes in our value

1093
01:02:44,650 --> 01:02:47,900
which is quite standard in image compression

1094
01:02:54,030 --> 01:02:56,660
in the following i'm going to show several

1095
01:02:56,710 --> 01:03:00,580
in the example the first example is

1096
01:03:02,350 --> 01:03:03,910
assume we we how

1097
01:03:03,920 --> 01:03:07,370
this is a different site in a similar way how

1098
01:03:08,100 --> 01:03:10,410
only access to the

1099
01:03:10,420 --> 01:03:13,750
risk image and the force

1100
01:03:13,760 --> 01:03:16,010
pixels here

1101
01:03:16,050 --> 01:03:20,580
some lines we help cell to the color labels

1102
01:03:23,550 --> 01:03:25,310
given this tool

1103
01:03:26,620 --> 01:03:28,530
by multi only the

1104
01:03:28,580 --> 01:03:30,030
from that

1105
01:03:30,040 --> 01:03:34,390
receiver on the algorithm caltech something like this

1106
01:03:34,410 --> 01:03:35,660
which is actually

1107
01:03:35,750 --> 01:03:41,180
quite the visual can pleasing

1108
01:03:42,440 --> 01:03:44,430
so this is just example to show

1109
01:03:44,440 --> 01:03:47,110
it actually works

1110
01:03:49,700 --> 01:03:52,240
well so let me explain

1111
01:03:53,160 --> 01:03:55,520
this is the second example

1112
01:03:55,750 --> 01:04:00,400
in this setting we go back to the compression and the

1113
01:04:00,410 --> 01:04:01,880
from the centre

1114
01:04:01,910 --> 01:04:06,460
he how exactly the ground force which is a colour image

1115
01:04:06,480 --> 01:04:09,490
then he signed the

1116
01:04:09,530 --> 01:04:13,250
illness china which is the way it handled

1117
01:04:14,660 --> 01:04:16,200
as well as

1118
01:04:16,530 --> 01:04:20,850
four so this middle column this example

1119
01:04:20,870 --> 01:04:22,320
he signed over

1120
01:04:22,980 --> 01:04:26,210
human annotated labels

1121
01:04:28,740 --> 01:04:33,150
the receiver on the other hand the internet actually can recover something like this

1122
01:04:34,180 --> 01:04:36,910
your using the current algorithm

1123
01:04:36,950 --> 01:04:40,780
but so here

1124
01:04:40,790 --> 01:04:44,010
basically the how some those selected

1125
01:04:45,260 --> 01:04:46,790
picked by

1126
01:04:46,800 --> 01:04:50,300
which means that the pixel picked i could never love

1127
01:04:50,450 --> 01:04:52,210
i can't see this

1128
01:04:56,250 --> 01:05:00,910
the algorithm this understanding with scale as well as this

1129
01:05:04,310 --> 01:05:09,520
this the the receiver actually can our something which is quite close to the

1130
01:05:09,610 --> 01:05:12,150
ground truth

1131
01:05:12,200 --> 01:05:15,030
to the original source data

1132
01:05:15,040 --> 01:05:19,790
so here also shows the look as well as the

1133
01:05:19,810 --> 01:05:21,520
number of a

1134
01:05:21,530 --> 01:05:25,120
labeled pixels

1135
01:05:25,130 --> 01:05:28,990
and still the image compression setting

1136
01:05:29,030 --> 01:05:32,630
sanders how this and he sent

1137
01:05:33,710 --> 01:05:35,540
well the

1138
01:05:36,440 --> 01:05:39,320
intended in

1139
01:05:39,380 --> 01:05:42,830
as well as this column is

1140
01:05:42,850 --> 01:05:45,730
hume is actually we draw a random sample

1141
01:05:48,310 --> 01:05:53,540
around close to switzerland

1142
01:05:54,680 --> 01:05:57,170
this column labels that actually

1143
01:05:57,230 --> 01:06:02,920
of ten this result and if we to learn you actually can focus hard part

1144
01:06:02,930 --> 01:06:04,680
the image and will ten

1145
01:06:04,700 --> 01:06:07,040
so that the

1146
01:06:07,100 --> 01:06:11,390
receiver and actually can recover something like this

1147
01:06:14,070 --> 01:06:18,410
it is the number the test bed clothes but actually if you look closely can

1148
01:06:20,300 --> 01:06:21,500
for the face

1149
01:06:21,510 --> 01:06:22,830
the official color

1150
01:06:23,420 --> 01:06:27,650
this line is quite different as well as for the

1151
01:06:29,570 --> 01:06:30,890
especially for the

1152
01:06:30,890 --> 01:06:34,000
a long time since i did not you

1153
01:06:34,040 --> 01:06:42,600
before moving on to the panama about this is most likely to have generated discussion

1154
01:06:42,990 --> 01:06:44,930
have more

1155
01:06:45,000 --> 01:06:51,250
finally glacially one at the end but so some of the teachers requested me

1156
01:06:51,390 --> 01:06:55,620
to have a place to small amount of like for this week already because some

1157
01:06:55,620 --> 01:06:59,870
of them will not be here for the next friday and the

1158
01:06:59,930 --> 01:07:05,440
you know if you want to give lectures units some feedback of what's going on

1159
01:07:05,440 --> 01:07:08,840
and to what extent do really communicating

1160
01:07:08,880 --> 01:07:12,110
so i would like to go one by one through

1161
01:07:12,830 --> 01:07:16,450
well events and ask you for come show

1162
01:07:16,470 --> 01:07:17,470
a lot

1163
01:07:18,050 --> 01:07:23,550
questions so went for questions are fairly well question

1164
01:07:26,410 --> 01:07:31,440
i would like to ask you for to choose one of the three and for

1165
01:07:31,440 --> 01:07:38,700
whether you are profiting for each course maybe not so much maybe yes

1166
01:07:38,720 --> 01:07:40,000
maybe i like

1167
01:07:40,360 --> 01:07:42,550
and then for school

1168
01:07:42,560 --> 01:07:45,860
that two things were not so much

1169
01:07:46,000 --> 01:07:48,690
i would like to know whether it

1170
01:07:48,700 --> 01:07:53,810
because it is the maybe the level is too high for the above-ground maybe just

1171
01:07:53,860 --> 01:07:57,120
allow for the environment therefore you are not perfect of it because you know it

1172
01:07:57,120 --> 01:08:00,810
already or maybe subevent onto something else

1173
01:08:00,890 --> 01:08:06,750
so and this is essentially an excuse to try to happen

1174
01:08:06,770 --> 01:08:09,120
any one of main know anything

1175
01:08:09,310 --> 01:08:14,190
and now it's easier to show hands and then just start speaking so maybe if

1176
01:08:14,190 --> 01:08:18,390
we start by showing and somebody will also speak but if you have a if

1177
01:08:18,480 --> 01:08:20,190
you have anything to say

1178
01:08:20,200 --> 01:08:22,500
this is a moment for it

1179
01:08:24,080 --> 01:08:31,800
who would show hands for a lot of profit for recording scores

1180
01:08:31,810 --> 01:08:37,000
four how many would say

1181
01:08:38,670 --> 01:08:47,270
it's very simple because it is a the interaction mrna

1182
01:08:51,490 --> 01:08:57,100
the court held many would say it's not so much

1183
01:08:59,980 --> 01:09:04,420
the reason is the level was too high level was too low you new everything

1184
01:09:07,730 --> 01:09:14,540
how to make a last lectures

1185
01:09:14,810 --> 01:09:17,130
a lot of profit

1186
01:09:19,480 --> 01:09:22,170
if it is about profit from it

1187
01:09:25,680 --> 01:09:30,080
and maybe not so much

1188
01:09:30,100 --> 01:09:36,150
and then do a lot with them while you knew it already

1189
01:09:36,170 --> 01:09:42,990
now we want to know whether it so from now on just answer about

1190
01:09:43,010 --> 01:09:45,070
however the seven score

1191
01:09:45,110 --> 01:09:46,880
a lot of profit

1192
01:09:46,890 --> 01:09:53,110
thank you

1193
01:09:53,110 --> 01:09:56,270
yes profit

1194
01:09:57,980 --> 01:10:01,480
so only one left for not so much

1195
01:10:01,490 --> 01:10:04,830
thank you

1196
01:10:07,290 --> 01:10:11,640
a lot of profit from parking structure

1197
01:10:13,520 --> 01:10:16,360
some benefit from lecture

1198
01:10:16,420 --> 01:10:19,760
enough of it

1199
01:10:19,770 --> 01:10:23,300
not so much

1200
01:10:23,300 --> 01:10:30,100
and then there's this material that some of you know and let me ask jointly

1201
01:10:30,100 --> 01:10:37,010
the four supposedly for the laps on spider and a bit of a slap shot

1202
01:10:37,180 --> 01:10:38,110
because they were

1203
01:10:38,150 --> 01:10:42,580
such a heavy but the deficit to have different

1204
01:10:42,610 --> 01:10:47,180
feeling with the rest of course it was it was it put face in this

1205
01:10:47,180 --> 01:10:52,350
way the you think that it was so where they have have the laps

1206
01:10:52,380 --> 01:10:54,620
and i said to complement the

1207
01:10:54,620 --> 01:10:55,780
which is mapping

1208
01:10:55,790 --> 01:10:59,660
from what to what

1209
01:11:01,330 --> 01:11:03,110
states and actions to

1210
01:11:06,620 --> 01:11:08,060
some real valued

1211
01:11:09,460 --> 01:11:12,320
one zero ten one hundred point one

1212
01:11:12,330 --> 01:11:15,080
native hundred

1213
01:11:16,930 --> 01:11:21,280
to define model you should know the six things secondly you should know whether these

1214
01:11:21,280 --> 01:11:22,690
are known or unknown

1215
01:11:22,700 --> 01:11:27,620
actually the transition function activation function the reward function

1216
01:11:27,640 --> 01:11:30,610
OK what you've done this you've done

1217
01:11:30,620 --> 01:11:32,460
sixty percent of the problem

1218
01:11:32,510 --> 01:11:37,020
it's formalising formalise problem at the right level of abstraction

1219
01:11:37,040 --> 01:11:38,780
it is often quite hard

1220
01:11:38,920 --> 01:11:40,940
what you have done that

1221
01:11:40,990 --> 01:11:45,310
then you can characterizes the solution to these problems officially find them in you're luck

1222
01:11:45,310 --> 01:11:48,440
because most the colour models and solutions are known

1223
01:11:48,490 --> 01:11:52,240
this is just a matter of getting the problem into the right model

1224
01:11:52,790 --> 01:11:57,780
so for example for every other application i discussed is already full model with known

1225
01:11:57,780 --> 01:12:02,050
ways to derive solution and properties of that solution so clearly the problem here is

1226
01:12:02,710 --> 01:12:04,510
model the problem

1227
01:12:04,530 --> 01:12:09,750
now recently gave the talk i i i i do a lot of things in

1228
01:12:09,750 --> 01:12:12,790
my job one of the recent research projects

1229
01:12:12,810 --> 01:12:14,640
is on city traffic control

1230
01:12:14,650 --> 01:12:16,870
and i received talk and i realize

1231
01:12:16,940 --> 01:12:19,850
people really care lot traffic

1232
01:12:19,920 --> 01:12:25,570
it was great i mean i had this discussion to search took on its own

1233
01:12:25,720 --> 01:12:28,970
is life and i just saw some back

1234
01:12:28,990 --> 01:12:33,310
i didn't talk much people really people really care about traffic you really care about

1235
01:12:33,310 --> 01:12:36,120
how long you wait stop lights

1236
01:12:36,160 --> 01:12:42,710
and so on so it might be nice to quickly formalise what traffic control problem

1237
01:12:42,720 --> 01:12:44,300
would look like

1238
01:12:44,310 --> 01:12:48,380
and again if you've got a piece of paper or the placing notes things to

1239
01:12:48,380 --> 01:12:49,220
help you

1240
01:12:49,270 --> 01:12:53,820
with the rest lecture

1241
01:13:14,110 --> 01:13:17,610
traffic control

1242
01:13:23,380 --> 01:13:24,710
OK let's

1243
01:13:24,740 --> 01:13:32,220
let's sum for simplicity let's assume that she was stoplights

1244
01:13:33,110 --> 01:13:34,100
in here

1245
01:13:34,110 --> 01:13:37,300
but this is

1246
01:13:37,350 --> 01:13:41,050
these are one-way roads

1247
01:13:41,060 --> 01:13:43,420
that's three roads here

1248
01:13:44,040 --> 01:13:49,970
OK so every intersection is going to have

1249
01:13:49,980 --> 01:13:54,260
two stop lights went retraction

1250
01:13:55,130 --> 01:13:56,860
what the state

1251
01:13:56,870 --> 01:14:03,950
i said look like

1252
01:14:07,910 --> 01:14:11,410
thank you

1253
01:14:12,850 --> 01:14:15,650
it's like this orange light coming late

1254
01:14:16,160 --> 01:14:18,560
for the embers well

1255
01:14:24,080 --> 01:14:27,920
we have what the state of to stop quite right

1256
01:14:27,930 --> 01:14:30,360
so we have

1257
01:14:39,550 --> 01:14:41,870
the cross product twice

1258
01:14:41,920 --> 01:14:44,500
by one one three points

1259
01:14:51,850 --> 01:14:55,580
if i see square then you publish and i mean this

1260
01:14:55,590 --> 01:14:58,520
right now

1261
01:14:58,530 --> 01:15:00,670
as part of the state

1262
01:15:00,710 --> 01:15:02,620
get more stiffness that

1263
01:15:02,630 --> 01:15:04,770
what you care about

1264
01:15:04,880 --> 01:15:07,230
say that a simple problem

1265
01:15:07,320 --> 01:15:12,170
is the thing OK get

1266
01:15:12,180 --> 01:15:15,940
but does more seats the problem in this does more see upon what you want

1267
01:15:15,940 --> 01:15:17,860
to conditioning your actions

1268
01:15:19,460 --> 01:15:22,470
so how had in this stuff like really work

1269
01:15:22,540 --> 01:15:24,970
percent state

1270
01:15:27,390 --> 01:15:29,630
actually these inductive loop brain

1271
01:15:29,680 --> 01:15:31,660
actually actually right

1272
01:15:31,960 --> 01:15:36,310
OK good OK and so that destroyed text the presence or absence of the car

1273
01:15:37,460 --> 01:15:41,950
OK so i think the current state of the state would be

1274
01:15:41,960 --> 01:15:43,460
OK let's

1275
01:15:43,470 --> 01:15:45,210
i call this

1276
01:15:45,350 --> 01:15:46,950
that's what i'm sorry

1277
01:15:47,020 --> 01:15:49,830
q one

1278
01:15:49,870 --> 01:15:51,910
you think you can really make use

1279
01:15:53,070 --> 01:15:56,300
q two

1280
01:15:56,310 --> 01:15:59,070
q three

1281
01:15:59,120 --> 01:16:02,800
and q four

1282
01:16:03,970 --> 01:16:08,930
and with the current traffic centers either no

1283
01:16:08,960 --> 01:16:12,150
weather traffic is on that sense or not

1284
01:16:12,350 --> 01:16:16,090
now it's actually you can do more than that for example in sydney

1285
01:16:16,150 --> 01:16:21,970
they use the rate of traffic flow sensors to try to invite capabilities let let's

1286
01:16:21,980 --> 01:16:23,180
think the pretty simple

1287
01:16:23,190 --> 01:16:28,300
OK so i have four here i'm just going to have a boy in state

1288
01:16:28,300 --> 01:16:31,760
space is true or false to four

1289
01:16:31,770 --> 01:16:34,020
p ten p times b and b

1290
01:16:36,300 --> 01:16:38,840
this will be a very simple problem

1291
01:16:38,900 --> 01:16:42,260
this is really cool so one thing this is is doing now is the mounting

1292
01:16:42,260 --> 01:16:45,450
traffic cameras on top of every stop

1293
01:16:45,460 --> 01:16:50,580
and he showed his vision is to build hard problem but when when when you

1294
01:16:50,580 --> 01:16:53,340
when the camera one traffic

1295
01:16:53,360 --> 01:16:56,670
OK and you know really markings are you know the geometry

1296
01:16:56,690 --> 01:16:58,130
seven earthquakes

1297
01:16:58,240 --> 01:17:00,250
the jump doesn't change

1298
01:17:00,260 --> 01:17:01,820
there's actually

1299
01:17:01,830 --> 01:17:06,110
fairly soul vision tasks to say there are these cars this linear system any we've

1300
01:17:06,110 --> 01:17:09,160
got bias we've got so on

1301
01:17:09,570 --> 01:17:13,710
and so actually so the next generation challenge you will see into the next ten

1302
01:17:13,710 --> 01:17:19,660
years are sensors that can say there's bussiness later buses were forty people

1303
01:17:19,670 --> 01:17:21,100
is worth forty cars

1304
01:17:21,110 --> 01:17:22,250
or twenty cars

1305
01:17:22,260 --> 01:17:25,100
so i'm going to give priority to this past to go through

1306
01:17:25,110 --> 01:17:29,220
so the problem can be a lot more complex if you allow things like that

1307
01:17:29,220 --> 01:17:32,690
and this is what we're actually we're we're looking at our research

1308
01:17:32,740 --> 01:17:33,780
but right now

1309
01:17:33,790 --> 01:17:35,500
two thousand nine

1310
01:17:35,910 --> 01:17:40,960
we just have centers saying there is a car here is prior OK so how

1311
01:17:40,960 --> 01:17:50,460
many distinct states do we have based on this model

1312
01:17:50,550 --> 01:17:54,160
three times three

1313
01:17:54,170 --> 01:17:56,930
times how many states here

1314
01:17:58,210 --> 01:18:00,650
sixteen to the fourth

1315
01:18:02,370 --> 01:18:07,840
nine time sixteen accounting enough we had a one

1316
01:18:07,890 --> 01:18:10,670
o forty four the

1317
01:18:12,020 --> 01:18:16,130
so the size of the state space is one hundred forty four states

1318
01:18:16,140 --> 01:18:18,490
this problem

1319
01:18:18,530 --> 01:18:26,310
now imagine we have twenty traffic lights three lanes in each direction two-way traffic

1320
01:18:26,360 --> 01:18:30,080
we know whether buses in queue lengths

1321
01:18:30,240 --> 01:18:31,860
lower OK

1322
01:18:31,880 --> 01:18:37,540
clearly how model state really influences how to solve the problem is very simple

1323
01:18:37,550 --> 01:18:40,510
what's the action space

1324
01:18:40,520 --> 01:18:42,240
precup control

1325
01:18:42,290 --> 01:18:43,670
so let's assume

1326
01:18:44,660 --> 01:18:49,150
OK so so for traffic there are minimum time delay can be in the cycle

1327
01:18:49,240 --> 01:18:55,950
there are issues about how on one last few red one x like can green

1328
01:18:55,950 --> 01:18:57,120
with respect

1329
01:18:57,200 --> 01:19:00,590
the target density the idea

1330
01:19:00,640 --> 01:19:03,200
OK i want to sample from p

1331
01:19:03,260 --> 01:19:06,620
come to the nearest to the distribution

1332
01:19:06,620 --> 01:19:08,990
check with this racial here

1333
01:19:09,010 --> 01:19:10,930
OK if we increase

1334
01:19:13,320 --> 01:19:15,140
we have a high value here

1335
01:19:15,200 --> 01:19:17,780
and if we have decreased the most probably have

1336
01:19:17,930 --> 01:19:19,280
low value

1337
01:19:19,320 --> 01:19:23,260
this is just a correction to take into account

1338
01:19:23,320 --> 01:19:26,910
density we use to sample

1339
01:19:27,410 --> 01:19:29,490
and there are probably things

1340
01:19:29,640 --> 01:19:31,570
the reason for that

1341
01:19:31,590 --> 01:19:36,410
got the candidates is going to be accepted or rejected

1342
01:19:36,470 --> 01:19:39,090
it is going to be at you

1343
01:19:39,090 --> 01:19:42,160
this one is larger than the one we always accept

1344
01:19:42,160 --> 01:19:43,740
and if it's more than one

1345
01:19:43,760 --> 01:19:45,740
with what

1346
01:19:45,780 --> 01:19:48,050
we accepted or rejected

1347
01:19:48,210 --> 01:19:51,140
it is high that is a good improvement

1348
01:19:51,180 --> 01:19:54,720
then very probably will as new can

1349
01:19:54,740 --> 01:19:56,550
but this is know

1350
01:19:56,720 --> 01:19:59,800
is change in any way we

1351
01:19:59,860 --> 01:20:03,010
but we must probably be rejected

1352
01:20:05,390 --> 01:20:07,360
and then we iterate

1353
01:20:09,120 --> 01:20:11,340
OK so

1354
01:20:11,390 --> 01:20:13,760
now to have

1355
01:20:13,780 --> 01:20:17,760
and so this is a very generic categories and we want to apply it to

1356
01:20:17,800 --> 01:20:20,320
the problem of harmony kind

1357
01:20:20,340 --> 01:20:21,550
so i

1358
01:20:21,570 --> 01:20:26,530
present you i we can build the MCMC algorithm for this page

1359
01:20:26,530 --> 01:20:27,410
OK so

1360
01:20:27,430 --> 01:20:29,340
we have different levels

1361
01:20:29,340 --> 01:20:33,160
at the level of individual powerful we have

1362
01:20:33,180 --> 01:20:36,050
the amplitude frequency of the possible

1363
01:20:37,780 --> 01:20:42,280
at the level of nodes node is composed of fundamental frequency and the bottles

1364
01:20:43,120 --> 01:20:46,470
we have a structure parameter which is the number of partials

1365
01:20:46,490 --> 01:20:48,160
so we want to estimate

1366
01:20:48,220 --> 01:20:51,410
and the overall scale we have the music

1367
01:20:51,430 --> 01:20:53,200
one node to another

1368
01:20:53,220 --> 01:20:58,100
and i have a

1369
01:20:58,120 --> 01:21:00,070
see additive noise variance

1370
01:21:00,090 --> 01:21:01,180
so we have three

1371
01:21:01,200 --> 01:21:03,550
three different

1372
01:21:03,570 --> 01:21:05,120
in this case

1373
01:21:05,180 --> 01:21:07,490
for the problem

1374
01:21:08,970 --> 01:21:11,010
and a very important thing about

1375
01:21:11,030 --> 01:21:12,780
the dimension of the

1376
01:21:13,570 --> 01:21:16,660
is varying with the parameters so that's why we implement

1377
01:21:17,570 --> 01:21:21,090
and so i think all the time

1378
01:21:21,140 --> 01:21:23,780
lecture about anyway

1379
01:21:23,780 --> 01:21:25,300
and the problem

1380
01:21:26,200 --> 01:21:27,070
OK so

1381
01:21:27,090 --> 01:21:28,470
this is very very

1382
01:21:28,640 --> 01:21:30,120
because this is the theory

1383
01:21:30,180 --> 01:21:34,860
we want to estimate the parameters of the music by designing a markov chain

1384
01:21:34,870 --> 01:21:37,570
so the problem when you want to apply

1385
01:21:37,720 --> 01:21:39,620
how long is it going to take

1386
01:21:39,620 --> 01:21:42,680
it's not finished in one million years it was

1387
01:21:42,680 --> 01:21:47,010
so under the constraint is that we need to implement the first

1388
01:21:49,570 --> 01:21:51,870
this is why we need to very carefully

1389
01:21:51,890 --> 01:21:56,910
think about the markov condition cannot which is used to build a markov chain fast

1390
01:21:57,950 --> 01:21:59,700
and i would be the most

1391
01:21:59,720 --> 01:22:04,550
and think most important constraint problem

1392
01:22:06,260 --> 01:22:07,740
now let's see how it

1393
01:22:07,740 --> 01:22:08,660
it can be

1394
01:22:09,590 --> 01:22:11,620
so we have unionization

1395
01:22:11,640 --> 01:22:13,950
we have to be a piece of music

1396
01:22:13,970 --> 01:22:15,590
and we have a model we use

1397
01:22:15,590 --> 01:22:16,570
some notes

1398
01:22:16,660 --> 01:22:17,970
we cannot accept

1399
01:22:18,050 --> 01:22:18,930
we want to

1400
01:22:18,950 --> 01:22:21,180
initialize the things we want to

1401
01:22:21,240 --> 01:22:26,910
they select an initial number of nodes and initial number of each node and initial

1402
01:22:29,600 --> 01:22:31,360
because that we do we here

1403
01:22:31,360 --> 01:22:33,490
we sample say

1404
01:22:33,510 --> 01:22:35,280
we don't know anything about it

1405
01:22:35,700 --> 01:22:37,370
so we're going to say well

1406
01:22:37,370 --> 01:22:38,890
it's not for

1407
01:22:39,070 --> 01:22:44,820
we already know the number of nodes here to simplify

1408
01:22:44,930 --> 01:22:47,910
and for each of possible

1409
01:22:47,910 --> 01:22:51,490
from from initial frequency

1410
01:22:51,530 --> 01:22:52,660
so we can

1411
01:22:52,680 --> 01:22:54,260
have a look at that

1412
01:22:54,280 --> 01:22:58,700
just look at this picture from we might have some frequencies that uses to sample

1413
01:22:59,100 --> 01:23:02,140
unusual set frequencies

1414
01:23:03,390 --> 01:23:05,490
we need also

1415
01:23:05,510 --> 01:23:08,260
initial value for the variance parameter

1416
01:23:08,320 --> 01:23:09,140
right so

1417
01:23:09,160 --> 01:23:11,570
it's somewhat unusual value for that

1418
01:23:11,590 --> 01:23:14,930
and it's very nice because we have the conditional posterior

1419
01:23:14,950 --> 01:23:17,840
so as have already sampled from this

1420
01:23:17,840 --> 01:23:18,530
we can

1421
01:23:18,530 --> 01:23:22,120
have the

1422
01:23:22,170 --> 01:23:24,500
imagine any

1423
01:23:24,790 --> 01:23:28,610
connection to machine learning and nonparametric

1424
01:23:28,620 --> 01:23:34,290
i simply summarized the sum

1425
01:23:35,140 --> 01:23:40,730
phenomena for a product of random variables

1426
01:23:40,750 --> 01:23:44,980
which is essentially a prize peak was

1427
01:23:45,050 --> 01:23:46,910
or any

1428
01:23:46,930 --> 01:23:52,150
as our or any financial product

1429
01:23:52,200 --> 01:23:57,220
i will use and much more

1430
01:24:00,940 --> 01:24:03,900
maybe i already assumed

1431
01:24:07,050 --> 01:24:10,030
sequences of three vector

1432
01:24:12,370 --> 01:24:15,480
but the process i only assume

1433
01:24:15,510 --> 01:24:19,990
that the or the multidimensional distribution of the process

1434
01:24:20,020 --> 01:24:25,090
is invariant under the time she any

1435
01:24:25,140 --> 01:24:28,220
time if you look at the segment of the

1436
01:24:28,230 --> 01:24:29,830
market process

1437
01:24:29,840 --> 01:24:35,110
then the distribution we are not depend on the actual location of the

1438
01:24:35,110 --> 01:24:36,770
the fact that

1439
01:24:38,000 --> 01:24:40,970
i will show you

1440
01:24:41,550 --> 01:24:43,590
very important

1441
01:24:43,610 --> 01:24:46,030
previously all one is the

1442
01:24:46,140 --> 01:24:49,880
nonparametric regression estimate

1443
01:24:49,890 --> 01:24:55,190
and the other one is from actually learning for machine learning

1444
01:24:55,200 --> 01:24:58,470
how to aggregate estimates

1445
01:24:58,480 --> 01:25:04,360
died that it could be costly for very general market price

1446
01:25:05,140 --> 01:25:06,050
so that

1447
01:25:06,060 --> 01:25:09,830
the party is is very similar

1448
01:25:09,890 --> 01:25:12,420
two wednesday

1449
01:25:12,450 --> 01:25:17,530
the main difference is that year i love that you

1450
01:25:17,580 --> 01:25:22,920
training data you're in each day

1451
01:25:23,390 --> 01:25:27,590
in the morning when i

1452
01:25:27,660 --> 01:25:31,590
fix the actual portfolio that are

1453
01:25:31,590 --> 01:25:35,960
the portfolio vector may depend on the path

1454
01:25:35,990 --> 01:25:38,030
return vector

1455
01:25:38,030 --> 01:25:43,190
in the first day had no history of the for the first day

1456
01:25:43,210 --> 01:25:46,310
the portfolio vector can be arbitrary

1457
01:25:46,370 --> 01:25:53,540
and maybe remember that if there is the initial that for initial capital

1458
01:25:53,560 --> 01:25:55,560
for the first day

1459
01:25:56,660 --> 01:25:59,070
at the end of the day

1460
01:25:59,090 --> 01:26:04,090
the the amount of money what i have is the product of the

1461
01:26:04,130 --> 01:26:10,510
initial capital and the the inner product of the first portfolio over or under four

1462
01:26:11,220 --> 01:26:12,840
returned back

1463
01:26:12,870 --> 01:26:15,440
so the next day

1464
01:26:15,460 --> 01:26:16,720
for the second day

1465
01:26:16,840 --> 01:26:20,410
one is the new initial capital here

1466
01:26:21,560 --> 01:26:24,490
he has or at very

1467
01:26:24,500 --> 01:26:30,000
well the by the way the first the return vector for the portfolio vector may

1468
01:26:30,000 --> 01:26:34,060
depend on the first the return vector

1469
01:26:34,070 --> 01:26:35,500
and then

1470
01:26:36,820 --> 01:26:39,060
back at the end of the second day

1471
01:26:39,060 --> 01:26:40,680
the amount of money

1472
01:26:40,690 --> 01:26:42,970
it is the product of

1473
01:26:47,470 --> 01:26:50,540
and at the day and

1474
01:26:50,700 --> 01:26:55,560
the story is the plot the return vector so on your mind one

1475
01:26:55,990 --> 01:26:58,380
but the portfolio vector or

1476
01:26:58,440 --> 01:27:04,160
can be an arbitrary function of that part the reason that source

1477
01:27:04,180 --> 01:27:08,840
in this case the amount of money what i have is the

1478
01:27:08,870 --> 01:27:10,810
product of the

1479
01:27:10,840 --> 01:27:16,240
initial capital and the product of in inner product

1480
01:27:17,070 --> 01:27:19,190
at the i

1481
01:27:19,210 --> 01:27:24,740
the portfolio vector may depend on the preview the return vector

1482
01:27:24,750 --> 01:27:32,030
maybe remember that on wednesday afternoon i mentioned that is that of looking at died

1483
01:27:32,030 --> 01:27:36,190
at the and then it is reasonable to to look at

1484
01:27:36,200 --> 01:27:38,120
average growth rate

1485
01:27:38,130 --> 01:27:46,010
the rate the exponent which shows how fast these there

1486
01:27:46,450 --> 01:27:50,860
captain goes to infinity the what is the time and the

1487
01:27:50,870 --> 01:27:53,360
in the exponent it is

1488
01:27:53,370 --> 01:27:54,800
the average

1489
01:27:54,810 --> 01:27:56,060
of course

1490
01:27:56,120 --> 01:27:58,290
log there is

1491
01:27:58,330 --> 01:28:00,400
and this will be the

1492
01:28:01,100 --> 01:28:07,170
quantity which is on the one hand can be handled

1493
01:28:08,810 --> 01:28:11,830
and on the other hand characterizes the

1494
01:28:11,900 --> 01:28:18,620
a growth rate of our investment strategy

1495
01:28:21,710 --> 01:28:26,730
in contrast to one of the afternoon here i assume that the sequence of three

1496
01:28:28,350 --> 01:28:30,400
is stationary

1497
01:28:30,430 --> 01:28:34,050
and regarding

1498
01:28:34,060 --> 01:28:38,310
but the process if you don't know what would it means never mind i will

1499
01:28:38,310 --> 01:28:39,460
not use

1500
01:28:39,480 --> 01:28:49,400
just remember that stationary means that the thickness visionary award the institutions are invariant under

1501
01:28:49,450 --> 01:28:53,360
the banshee

1502
01:28:53,400 --> 01:28:57,230
and then the good portfolio vector

1503
01:28:57,250 --> 01:29:05,000
if the sequence of three vectorw is not independent identically distributed then

1504
01:29:05,000 --> 01:29:11,020
choosing values of x and then evaluating this green curve which is a sinusoidal function

1505
01:29:11,580 --> 01:29:13,460
and then adding guassian

1506
01:29:13,480 --> 01:29:16,850
zero mean gas noise to get the data points the data points are sort of

1507
01:29:16,850 --> 01:29:22,040
noisy observations from this green sinusoidal curves

1508
01:29:22,100 --> 01:29:25,250
and let's model is a simple linear model

1509
01:29:25,270 --> 01:29:29,160
so we can use a model

1510
01:29:29,190 --> 01:29:34,160
children by y of x parametrized by w which is going to be linear in

1511
01:29:34,160 --> 01:29:38,660
the parameters of the linear combination of some fixed functions of x these functions could

1512
01:29:38,660 --> 01:29:43,390
be non-linear but the fixed we call this the linear model is linear in the

1513
01:29:43,390 --> 01:29:45,060
unknown parameters

1514
01:29:48,190 --> 01:29:53,250
distribution for t then is the gas distribution whose mean is this function y of

1515
01:29:54,060 --> 01:29:56,600
and it has some inverse

1516
01:29:57,100 --> 01:30:02,440
some variants beta inverse beta the precision of the noise

1517
01:30:02,460 --> 01:30:08,690
the likelihood function is the product of these evaluated of the observations

1518
01:30:08,710 --> 01:30:12,870
so here's an example of the choice of basis functions is some fixed knowledge base

1519
01:30:12,870 --> 01:30:14,710
function in this case the polynomial

1520
01:30:14,770 --> 01:30:19,660
so this is x the power one that x squared and so on so it

1521
01:30:19,790 --> 01:30:28,310
sitting model which is an expansion in powers of x

1522
01:30:28,310 --> 01:30:32,930
now want to introduce a conjugate prior is unknown parameters in the conjugate prior is

1523
01:30:32,930 --> 01:30:36,960
going to be a guassian because y is linear in x

1524
01:30:36,980 --> 01:30:40,750
and so the mean of this distribution is linear in w

1525
01:30:41,890 --> 01:30:46,310
the functional form of this with respect to w is e to the minus the

1526
01:30:46,310 --> 01:30:48,140
quadratic function of w

1527
01:30:48,170 --> 01:30:50,690
so the conjugate prior for that is against you

1528
01:30:52,040 --> 01:30:56,690
so we define gas in w which is zero mean controlled by some parameter alpha

1529
01:30:58,230 --> 01:30:59,980
and so we multiply

1530
01:31:00,000 --> 01:31:05,210
the likelihood function by the prior because its conjugate again we get gas distribution and

1531
01:31:05,210 --> 01:31:10,080
if you work it out it's takes this form this is the mean and the

1532
01:31:10,110 --> 01:31:13,080
covariance s is the covariance

1533
01:31:13,640 --> 01:31:16,540
this the multivariate gamma distribution

1534
01:31:16,610 --> 01:31:19,620
and capital phi here system matrix

1535
01:31:19,620 --> 01:31:24,100
of observations to the NJ elements of this matrix

1536
01:31:24,100 --> 01:31:29,660
it is the j th basis function evaluated for the and observation details don't really

1537
01:31:29,660 --> 01:31:33,750
matter the point is this is a gas distribution

1538
01:31:35,360 --> 01:31:38,670
let's suppose will have look at a really simple case of a special case of

1539
01:31:38,670 --> 01:31:43,460
this let's imagine that is the moment instead of the sinusoidal source the data we

1540
01:31:43,460 --> 01:31:47,170
just a straight line

1541
01:31:47,200 --> 01:31:51,580
so let's generate some data from a straight line a plus b x

1542
01:31:51,610 --> 01:31:58,870
and will add some guassian noise to the observations

1543
01:31:58,890 --> 01:32:02,480
and somebody kindly told us that this is a straight line so we know what

1544
01:32:02,700 --> 01:32:04,950
to fit going to fit

1545
01:32:04,960 --> 01:32:08,820
this simple model which is linear in in w and linear x that is the

1546
01:32:08,820 --> 01:32:13,240
two parameter model w nor plus w one x so the goal is to

1547
01:32:13,250 --> 01:32:18,850
find w norton w one given some observations

1548
01:32:18,850 --> 01:32:24,490
so we have against him prior distribution this is now to the prior for this

1549
01:32:24,490 --> 01:32:27,860
is the two parameter space w norton w one of the two

1550
01:32:27,910 --> 01:32:31,150
parameters that we're trying to learn

1551
01:32:31,170 --> 01:32:38,150
and this is the prior distribution guassian centered on the origin and we can

1552
01:32:38,190 --> 01:32:43,060
we can visualize this by drawing samples so if we draw samples from this prior

1553
01:32:43,060 --> 01:32:47,910
distribution each sample is the value of w or w one therefore defines a straight

1554
01:32:47,910 --> 01:32:52,110
line to import that in data space this is why this is x so each

1555
01:32:53,000 --> 01:32:56,890
it is a pair of parameters which define a straight line if you draw samples

1556
01:32:56,890 --> 01:33:00,570
from the prior we can see we got a whole bunch of straight lines that's

1557
01:33:00,570 --> 01:33:05,610
quite a nice way sometimes of gaining insight into your into your prior assumptions is

1558
01:33:05,620 --> 01:33:06,310
to draw

1559
01:33:06,610 --> 01:33:10,390
draw fictitious data points to see what they actually look like and see if there

1560
01:33:10,730 --> 01:33:12,670
are reasonable

1561
01:33:12,690 --> 01:33:17,670
so the prior now let's observe one data point

1562
01:33:17,690 --> 01:33:20,500
so just observe this data point here

1563
01:33:20,520 --> 01:33:24,040
so we can compute its likelihood function and this is the

1564
01:33:24,070 --> 01:33:29,650
the likelihood function for that one data point and so its highest in the middle

1565
01:33:29,700 --> 01:33:33,700
so so the dark red is is a high value falls off to the blue

1566
01:33:33,700 --> 01:33:36,600
which is close to zero

1567
01:33:36,610 --> 01:33:41,490
what i want to hear white cross that white cross there is the true

1568
01:33:41,500 --> 01:33:45,440
value for w norton w one which of course we don't know

1569
01:33:46,860 --> 01:33:48,870
a straight line effectively

1570
01:33:49,020 --> 01:33:52,850
so a single data point constraints provides one constraint on the straight line so there

1571
01:33:52,850 --> 01:33:59,290
are there is a whole continues straight lines which pass through one data point because

1572
01:33:59,310 --> 01:34:02,980
we know the data point is noisy so it's sort of soft constraint

1573
01:34:03,030 --> 01:34:07,030
so the likelihood function has the strong correlation points

1574
01:34:07,030 --> 01:34:10,870
points and this is the parameter space w w one points along here

1575
01:34:10,890 --> 01:34:16,030
all correspond to straight lines that go close to the state point points out here

1576
01:34:16,060 --> 01:34:18,690
straight lines that miss the data points

1577
01:34:19,990 --> 01:34:22,700
we take this likelihood function and we

1578
01:34:22,990 --> 01:34:28,490
multiplied by this poster multiply by that posterior distribution by this likelihood function the normalized

1579
01:34:28,700 --> 01:34:33,520
and you can see we get this elongated gas this correlated down

1580
01:34:33,700 --> 01:34:37,170
and if we draw samples from this posterior distribution

1581
01:34:37,190 --> 01:34:41,830
and plot we see that indeed they are straight lines and they all

1582
01:34:41,860 --> 01:34:43,440
pass close to

1583
01:34:43,450 --> 01:34:44,670
this data point

1584
01:34:44,700 --> 01:34:48,750
close to is defined by that beta noise

1585
01:34:48,770 --> 01:34:54,580
so that's the effect of observing one data point and course bayesian learning is sequential

1586
01:34:54,580 --> 01:34:59,020
so this is now a prior distribution preserving the second data point is the second

1587
01:34:59,020 --> 01:35:00,210
data point

1588
01:35:00,240 --> 01:35:06,610
his it's likelihood function so it two defines the soft relationship between w norton w

1589
01:35:07,530 --> 01:35:10,790
this form

1590
01:35:10,810 --> 01:35:13,460
and so we take this likelihood function

1591
01:35:13,490 --> 01:35:16,040
multiplied by this prior

1592
01:35:16,060 --> 01:35:21,650
and we get this posterior distribution again guesstimates it's time much more compact because two

1593
01:35:21,670 --> 01:35:27,640
data points two points define line these noisy data points but nevertheless it constrains them

1594
01:35:28,210 --> 01:35:31,890
in this software so we now have quite compact posterior distribution and if we draw

1595
01:35:31,890 --> 01:35:35,530
samples from this distribution we say they are indeed all straight lines of going close

1596
01:35:35,530 --> 01:35:38,330
to those two data points

1597
01:35:38,350 --> 01:35:41,110
and that if we observe twenty data points

1598
01:35:41,120 --> 01:35:45,120
the this is the likelihood function for the twentieth data point we solve all of

1599
01:35:45,120 --> 01:35:47,520
those likelihood functions the

1600
01:35:47,520 --> 01:35:48,650
mister dispute

1601
01:35:48,670 --> 01:35:51,490
distribution is becoming more and more compact is the same

1602
01:35:51,500 --> 01:35:55,650
less and less uncertain and if we were to observe an infinite number of data

1603
01:35:55,650 --> 01:36:00,070
points this eventually would become delta function centred on the true value

1604
01:36:00,120 --> 01:36:02,810
because all models are correct model

1605
01:36:02,810 --> 01:36:05,050
hidden layers

1606
01:36:05,060 --> 01:36:06,610
and of course

1607
01:36:06,620 --> 01:36:10,710
we know that these are not convex optimization problems but for the more it looks

1608
01:36:10,710 --> 01:36:14,140
like it gets worse as we have more like

1609
01:36:14,170 --> 01:36:20,040
so the traditional approach to train neural nets is with random initial parameters and then

1610
01:36:20,040 --> 01:36:23,680
choose tune the parameters with stochastic gradient descent

1611
01:36:23,690 --> 01:36:28,440
what happens when if we don't really know

1612
01:36:28,500 --> 01:36:30,810
training doesn't progress with me well

1613
01:36:30,830 --> 01:36:32,440
the gradient is small

1614
01:36:32,450 --> 01:36:38,730
it means you either in a local minimum or you are in fact

1615
01:36:38,750 --> 01:36:43,100
there are some units that seem to be

1616
01:36:43,120 --> 01:36:46,330
trainable even if there are deep in the code convolutional nets and i'm going to

1617
01:36:46,330 --> 01:36:47,860
say much more about that but

1618
01:36:47,870 --> 01:36:51,980
but again we don't really understand why these are exceptions to these are specialized vision

1619
01:36:56,070 --> 01:36:59,010
two thousand six something happened

1620
01:36:59,040 --> 01:37:03,050
hinton osindero and ten published

1621
01:37:04,290 --> 01:37:07,980
calls asking for deep belief nets

1622
01:37:07,990 --> 01:37:10,640
and there's an idea in there which

1623
01:37:10,690 --> 01:37:15,020
it turns out to be useful for other types of deep networks

1624
01:37:15,180 --> 01:37:19,380
he is trying to do network radio two

1625
01:37:19,390 --> 01:37:21,750
user kind of greedy approach

1626
01:37:21,750 --> 01:37:27,230
so i'm going to try to find an unsupervised network which he sees the input

1627
01:37:28,830 --> 01:37:31,760
training layer by layer

1628
01:37:31,770 --> 01:37:35,420
adding one layer on top of each other

1629
01:37:35,430 --> 01:37:38,550
each layer is going to be restricted boltzmann machine which is something i'm not going

1630
01:37:38,580 --> 01:37:40,390
explain but it's

1631
01:37:40,400 --> 01:37:47,850
it's a kind of nonlinear PCA or ICA or whatever which are in representation of

1632
01:37:47,850 --> 01:37:50,850
its input is part of the learning process

1633
01:37:51,080 --> 01:37:55,830
unlike PCA and ICA the representation can have more components than the actual input

1634
01:37:55,860 --> 01:38:01,190
there's no constraint whether it doesn't have to be bigger or smaller

1635
01:38:01,200 --> 01:38:03,150
so when you try

1636
01:38:04,250 --> 01:38:06,000
you get a

1637
01:38:06,010 --> 01:38:10,890
both model of the inputs and way transformed input and the newer presentation

1638
01:38:11,700 --> 01:38:15,420
actually we don't really have a clear idea of why this decision should be better

1639
01:38:15,420 --> 01:38:19,800
than the original one but when we use this representation instead of the original one

1640
01:38:21,070 --> 01:38:26,680
input features for SC SVM or nearest neighbour got process we find usually we get

1641
01:38:26,680 --> 01:38:28,000
better classification

1642
01:38:28,020 --> 01:38:32,480
so what you do is you add layer by layer like this

1643
01:38:32,490 --> 01:38:35,420
and the and put on a supervised learning

1644
01:38:35,430 --> 01:38:42,640
your preferred classifier or whatever you want to do regression and this is a pretty

1645
01:38:42,640 --> 01:38:44,800
good but then you can get even better by taking this

1646
01:38:45,300 --> 01:38:48,280
i think that and

1647
01:38:48,750 --> 01:38:50,370
and the whole thing

1648
01:38:50,380 --> 01:38:56,460
by gradient descent on the supervised cost so you can find this big networks

1649
01:38:56,480 --> 01:39:02,710
and what happens is basically means used this device layerwise really thing as a very

1650
01:39:02,710 --> 01:39:04,960
sophisticated initialisation for

1651
01:39:04,970 --> 01:39:07,010
are being that

1652
01:39:09,210 --> 01:39:13,570
why is this working i'll say more about that but at least one thing that's

1653
01:39:13,570 --> 01:39:17,890
clear is that when we do this initialisation we the optimisation is done

1654
01:39:17,910 --> 01:39:21,910
locally within each layer so we try all these weights and they don't have to

1655
01:39:21,910 --> 01:39:28,460
look at what's happening above essentially below there are no interactions we know that training

1656
01:39:28,540 --> 01:39:30,040
a small model is

1657
01:39:30,070 --> 01:39:37,730
presumably easier than the big ones for the and also it looks like that education

1658
01:39:37,730 --> 01:39:42,100
completion of gradients when you do so many years introduce something that makes the gradient

1659
01:39:42,100 --> 01:39:46,100
less useful so in nineteen twenty one layer at a time

1660
01:39:46,110 --> 01:39:48,840
maybe it's easier

1661
01:39:53,040 --> 01:39:58,160
so now i'm going to say something about online learning

1662
01:39:58,180 --> 01:40:01,150
can you give me time

1663
01:40:09,290 --> 01:40:13,760
thirty four minutes twenty five i got

1664
01:40:14,970 --> 01:40:16,980
my friend leon bottou

1665
01:40:16,990 --> 01:40:23,130
the nice piece of work the online learning among those

1666
01:40:23,140 --> 01:40:27,040
something that is important for me because i'm interested in learning

1667
01:40:27,070 --> 01:40:30,480
very large scale problems

1668
01:40:30,490 --> 01:40:34,750
this paper with you can NIPS two-thousand three

1669
01:40:34,770 --> 01:40:38,640
that brings an argument which

1670
01:40:38,660 --> 01:40:40,720
on the face of it is obvious

1671
01:40:40,740 --> 01:40:45,510
when you training with abundant training data and they symbolically with the amount of data

1672
01:40:45,510 --> 01:40:47,210
is infinity

1673
01:40:47,220 --> 01:40:50,280
online learning

1674
01:40:50,300 --> 01:40:55,950
asymptotically outperforms batch learning simply because

1675
01:40:56,040 --> 01:41:00,530
that's something we have to eat right multiple times through the data

1676
01:41:00,540 --> 01:41:05,320
and while i was writing the second third and ten times the online learning could

1677
01:41:05,320 --> 01:41:07,520
have looked at more data as

1678
01:41:07,540 --> 01:41:08,760
and those

1679
01:41:08,780 --> 01:41:14,200
larger and larger that advantage in terms of generalization becomes bigger now it's not totally

1680
01:41:14,200 --> 01:41:19,010
obvious because one converges faster to to the optimal training error and the other and

1681
01:41:22,480 --> 01:41:24,580
there are some trade to be study and

1682
01:41:24,740 --> 01:41:28,120
this year's paper continues on the same track

1683
01:41:28,140 --> 01:41:32,090
look centralization here which is usually

1684
01:41:32,110 --> 01:41:36,120
studied in terms of the trade off between approximation error because we have a cost

1685
01:41:36,170 --> 01:41:38,070
function it's too restricted to small

1686
01:41:38,170 --> 01:41:41,780
and estimation error variance because the closest large

1687
01:41:41,790 --> 01:41:45,110
and we don't have enough data

1688
01:41:45,210 --> 01:41:51,880
that night introduces third which is the effect due to the optimisation because optimisation is

1689
01:41:51,880 --> 01:41:53,820
not perfect

1690
01:41:53,830 --> 01:41:58,670
usually we stop optimizing when we find that are close enough to a local minimum

1691
01:41:58,700 --> 01:42:01,450
but what is the effect of this

1692
01:42:01,460 --> 01:42:07,120
and basically needed to study it introduces a very nice idea which is

1693
01:42:07,140 --> 01:42:09,160
we have to

1694
01:42:09,170 --> 01:42:12,730
constraints to consider when we trained learning

1695
01:42:12,770 --> 01:42:15,600
one is how much

1696
01:42:16,320 --> 01:42:20,280
we have and the other is how many examples we can afford

1697
01:42:20,280 --> 01:42:22,420
the objects to be clustered

1698
01:42:22,440 --> 01:42:25,880
the edges represent similarity

1699
01:42:25,940 --> 01:42:30,460
relations and the weights on the edges represent the similarity

1700
01:42:30,530 --> 01:42:33,170
wanted to simply to

1701
01:42:33,250 --> 01:42:34,210
so we have

1702
01:42:34,230 --> 01:42:35,490
technically speaking

1703
01:42:35,500 --> 01:42:40,610
atleast this part of the talk we have an undirected weighted graph and we we

1704
01:42:40,620 --> 01:42:42,850
assume that the weights are nonnegative

1705
01:42:43,770 --> 01:42:45,320
but then are equal to c

1706
01:42:45,360 --> 01:42:49,920
a common way to represent

1707
01:42:50,110 --> 01:42:56,430
and directed weighted graph edge weighted graph is by using this weighted adjacency matrix

1708
01:42:56,530 --> 01:43:00,620
this is an n by n matrix where n is the number of vertices in

1709
01:43:00,620 --> 01:43:01,380
the graph

1710
01:43:01,390 --> 01:43:05,740
and at the intersection of the rule number i and column j

1711
01:43:05,800 --> 01:43:07,650
just find similarity

1712
01:43:07,670 --> 01:43:09,890
between i and j

1713
01:43:09,920 --> 01:43:13,020
we assume that the that the main diagonal of this

1714
01:43:13,030 --> 01:43:16,130
memetics is zero

1715
01:43:16,140 --> 01:43:22,310
OK so let's start from a very simple and realistic scenario

1716
01:43:22,370 --> 01:43:25,990
let's try to answer our original question what is the cluster

1717
01:43:26,090 --> 01:43:31,430
when the similarities between the objects are binary

1718
01:43:31,470 --> 01:43:32,690
so in this case

1719
01:43:32,730 --> 01:43:36,250
we have just that two objects are either similar

1720
01:43:36,300 --> 01:43:42,310
or the similarly we are not allowing intermediate values of similarity

1721
01:43:42,320 --> 01:43:43,490
in other words

1722
01:43:45,640 --> 01:43:47,020
the graph

1723
01:43:47,350 --> 01:43:52,220
is it in a weighted graph is an undirected weighted and the adjacent semantics is

1724
01:43:52,220 --> 01:43:56,500
just the zero one matrix so let's ask yourself

1725
01:43:56,560 --> 01:44:02,270
of what is the sort of structure in this graph that satisfies two criteria the

1726
01:44:02,270 --> 01:44:04,230
internal and external

1727
01:44:04,270 --> 01:44:08,270
the answer is very classical notion in graph theory

1728
01:44:08,280 --> 01:44:10,640
the notion of a maximal clique yesterday

1729
01:44:10,650 --> 01:44:14,070
we had talked richard hardly talk about the notion of the week

1730
01:44:14,110 --> 01:44:15,690
from different

1731
01:44:15,700 --> 01:44:17,240
but what i can just

1732
01:44:17,250 --> 01:44:21,100
nine what is really what is the maximum

1733
01:44:21,180 --> 01:44:22,600
give you a graph

1734
01:44:22,600 --> 01:44:26,990
example this one

1735
01:44:28,100 --> 01:44:29,890
OK so it's c

1736
01:44:29,900 --> 01:44:33,950
it's just a subset of mutually adjacent but

1737
01:44:34,000 --> 01:44:36,770
then we have the notion of the maximum

1738
01:44:36,930 --> 01:44:42,520
maximal clique is a clique which is not contained in any larger so for example

1739
01:44:42,600 --> 01:44:45,230
this is why

1740
01:44:45,230 --> 01:44:46,850
physically of course

1741
01:44:46,960 --> 01:44:48,720
and is also max

1742
01:44:48,970 --> 01:44:51,460
this one also we

1743
01:44:51,470 --> 01:44:53,210
and is also the maximum

1744
01:44:56,520 --> 01:44:58,190
this one is a clique

1745
01:44:58,190 --> 01:45:02,180
but is not maximum because it is contained a large

1746
01:45:02,230 --> 01:45:07,300
well it's not written that we have fight the notion

1747
01:45:07,350 --> 01:45:12,270
the notion of the maximum clique

1748
01:45:12,400 --> 01:45:16,540
to distinguish it from the notion of the maximal cliques and maximal clique is a

1749
01:45:16,540 --> 01:45:18,870
clique having largest garden

1750
01:45:18,930 --> 01:45:21,330
there is no large so in this case

1751
01:45:21,450 --> 01:45:25,220
there is only one maximal clique and this is one

1752
01:45:25,230 --> 01:45:27,320
this is this one is maximum

1753
01:45:27,330 --> 01:45:28,870
and it's not max

1754
01:45:28,950 --> 01:45:31,990
of course any maximal clique is also maximal

1755
01:45:32,040 --> 01:45:35,870
but the opposite is not true for example in this case

1756
01:45:35,910 --> 01:45:38,810
the maximum clique which is max

1757
01:45:38,870 --> 01:45:40,630
we also have a notion which

1758
01:45:42,080 --> 01:45:43,430
can't believe

1759
01:45:43,470 --> 01:45:44,410
it's called the

1760
01:45:44,420 --> 01:45:48,130
strictly maximum we just mentioned

1761
01:45:48,400 --> 01:45:52,860
because strictly

1762
01:45:56,190 --> 01:46:00,120
this is a clique which has the following property

1763
01:46:01,140 --> 01:46:03,410
if this is a maximal clique

1764
01:46:03,460 --> 01:46:06,230
all that is outside it

1765
01:46:06,280 --> 01:46:08,750
can we have

1766
01:46:08,800 --> 01:46:11,730
more than two edges

1767
01:46:11,740 --> 01:46:14,220
incidentally those because

1768
01:46:14,270 --> 01:46:17,180
if this verdict here which is outside the clique

1769
01:46:17,180 --> 01:46:20,480
it has three edges incident to this one

1770
01:46:20,570 --> 01:46:23,560
this will not be m

1771
01:46:23,560 --> 01:46:25,010
this gave me the world

1772
01:46:25,060 --> 01:46:29,890
to get to my note so it it's fully characterizes the note OK

1773
01:46:30,060 --> 01:46:35,790
so for example here

1774
01:46:35,810 --> 01:46:38,950
the outliers if you like the address of this nodes

1775
01:46:43,100 --> 01:46:45,510
so i finite words

1776
01:46:45,660 --> 01:46:47,660
over the alphabet

1777
01:46:47,720 --> 01:46:49,510
zero one

1778
01:46:54,080 --> 01:46:55,260
so i give you

1779
01:46:55,280 --> 01:46:58,370
a finite ordered here it gives me a node in the tree

1780
01:46:58,390 --> 01:47:01,720
so the support to carry out an not

1781
01:47:01,810 --> 01:47:03,660
carry on something

1782
01:47:05,060 --> 01:47:07,410
frame the frame

1783
01:47:07,410 --> 01:47:11,680
of the tree and well anyway you the tree would say

1784
01:47:11,680 --> 01:47:15,810
it is composed of nodes but simply given by the address

1785
01:47:15,830 --> 01:47:19,620
and how do i move from one node to its chinese i simply at the

1786
01:47:19,640 --> 01:47:22,970
end of this adversely either you if one the left

1787
01:47:23,930 --> 01:47:26,930
one effect on the right shape

1788
01:47:27,030 --> 01:47:29,970
that's that's tree very simple

1789
01:47:31,310 --> 01:47:34,120
and if i have made no move

1790
01:47:34,140 --> 01:47:35,410
from the top

1791
01:47:35,430 --> 01:47:38,640
the MT what is epsilon and that's the root of the tree

1792
01:47:40,350 --> 01:47:41,950
so it's written like this

1793
01:47:41,950 --> 01:47:44,850
that means that the sequence of the other one

1794
01:47:44,890 --> 01:47:48,560
is the empty word and it's the address of the root of the tree

1795
01:47:48,580 --> 01:47:52,080
now if i wanted to decorate my

1796
01:47:54,390 --> 01:47:58,740
information michael sigma of the set of information that i'm using

1797
01:47:58,850 --> 01:48:02,350
and in general see mistaken finite

1798
01:48:02,390 --> 01:48:06,120
but of course i mean there are few is that extends

1799
01:48:08,260 --> 01:48:11,330
trees of infinite alphabets but we

1800
01:48:11,350 --> 01:48:13,470
we don't need it here

1801
01:48:13,490 --> 01:48:15,180
so i will

1802
01:48:15,240 --> 01:48:18,080
label my notes with sigma

1803
01:48:18,180 --> 01:48:20,100
elements of sigma and the

1804
01:48:20,120 --> 01:48:24,740
trees sigma of the definition the full binary trees

1805
01:48:25,660 --> 01:48:32,990
labels on those that are elements of c OK

1806
01:48:33,050 --> 01:48:37,350
so in general

1807
01:48:37,370 --> 01:48:40,990
what people would take this is what i have explained to you here

1808
01:48:41,060 --> 01:48:42,160
if you want

1809
01:48:42,160 --> 01:48:47,990
to come from programs propositions about the labels of each node would be as the

1810
01:48:47,990 --> 01:48:51,910
subset of propositions that toward state

1811
01:48:51,970 --> 01:48:55,140
so remember that you

1812
01:48:56,350 --> 01:48:59,490
a given node

1813
01:48:59,490 --> 01:49:04,600
may correspond i mean several nodes in the tree may correspond to the same

1814
01:49:04,600 --> 01:49:08,580
current state in the problem

1815
01:49:08,830 --> 01:49:14,720
because look at this the way of unravelled this thing here

1816
01:49:14,850 --> 01:49:20,030
i mean in this notes the current state here is as two

1817
01:49:20,120 --> 01:49:21,700
here's is as one

1818
01:49:21,700 --> 01:49:23,240
so here as well

1819
01:49:24,910 --> 01:49:29,430
what is also very important that we really do not exploit

1820
01:49:29,450 --> 01:49:33,870
here in in this setting is that in the tree when i choose an note

1821
01:49:33,930 --> 01:49:36,660
and if this node corresponds to

1822
01:49:36,680 --> 01:49:42,410
note is the tree corresponds to an unraveling of some famous structure operational structure

1823
01:49:42,410 --> 01:49:44,990
in this have information of the current state

1824
01:49:45,010 --> 01:49:49,620
but there's have also information about the past

1825
01:49:49,620 --> 01:49:52,080
which tells me we have reached this state

1826
01:49:52,180 --> 01:49:57,740
so here and both them in both cases i mean state one s one

1827
01:49:57,760 --> 01:49:59,060
but here

1828
01:49:59,080 --> 01:50:05,140
after this instruction which maybe i don't know maybe to increment survival in my problem

1829
01:50:05,140 --> 01:50:06,910
whatever two

1830
01:50:06,930 --> 01:50:12,100
to ask the user to give me another value of you can see that here

1831
01:50:12,140 --> 01:50:15,640
i mean the state where i asked the guy i mean one

1832
01:50:15,660 --> 01:50:19,970
to give me the value of primitive ones and he had twice

1833
01:50:20,010 --> 01:50:22,760
so the trees very very powerful

1834
01:50:22,780 --> 01:50:24,120
regarding the

1835
01:50:24,120 --> 01:50:28,410
execu shows of the problem

1836
01:50:29,560 --> 01:50:33,560
so now we enter the logic the mu calculus

1837
01:50:33,640 --> 01:50:39,240
just to start to define itself it's you you fed for the first lecture at

1838
01:50:39,240 --> 01:50:40,810
this with the main objective

1839
01:50:42,470 --> 01:50:45,200
what is important to note to remember

1840
01:50:45,260 --> 01:50:47,890
although we will not really

1841
01:50:47,890 --> 01:50:49,810
c will have elements

1842
01:50:49,830 --> 01:50:54,810
see why i claim that this logic is so powerful but actually bit

1843
01:50:54,830 --> 01:50:56,450
is that

1844
01:50:56,600 --> 01:51:00,260
the formalism i give you will subsume i mean

1845
01:51:00,280 --> 01:51:02,950
the temple logics

1846
01:51:02,970 --> 01:51:05,600
you can think of volume you may

1847
01:51:05,660 --> 01:51:06,350
you may

1848
01:51:06,370 --> 01:51:07,680
and countering your

1849
01:51:07,680 --> 01:51:09,370
scientific life

1850
01:51:09,470 --> 01:51:11,160
it's it's assumed

1851
01:51:11,160 --> 01:51:14,910
all the possible logic you can think of

1852
01:51:14,930 --> 01:51:19,660
actually it has exactly the same power as monadic second order logic

1853
01:51:19,810 --> 01:51:21,790
very very powerful

1854
01:51:21,810 --> 01:51:23,310
other the trees

1855
01:51:24,870 --> 01:51:29,200
this is x half of the lecture but you should remember that the mu calculus

1856
01:51:29,200 --> 01:51:30,370
that they present you

1857
01:51:30,470 --> 01:51:33,140
whatever you can you would be able to

1858
01:51:34,120 --> 01:51:36,140
on the full binary tree

1859
01:51:36,140 --> 01:51:40,870
with monadic second order logic so you have second quantification it's alot lot

1860
01:51:40,930 --> 01:51:44,280
whatever you may be able to express in this logic

1861
01:51:44,280 --> 01:51:47,280
this can also be told in the new calculus but only

1862
01:51:47,330 --> 01:51:49,510
on tree structures

1863
01:51:49,560 --> 01:51:53,930
if i take more complicated things like greets

1864
01:51:53,950 --> 01:51:57,830
that things that they can express the MSO monadic second order logic that will not

1865
01:51:57,830 --> 01:51:58,720
be able to

1866
01:51:59,830 --> 01:52:01,430
express the mu calculus

1867
01:52:01,430 --> 01:52:05,100
for the good reason that the mu calculus

1868
01:52:05,100 --> 01:52:09,640
is it logical talk about etiquette executions and future of the execution so it means

1869
01:52:09,640 --> 01:52:14,180
that can make a difference between the great or some unravelling of the weight as

1870
01:52:14,200 --> 01:52:15,280
the tree

1871
01:52:15,330 --> 01:52:20,870
so the logical gonna use is insensitive to unravelling

1872
01:52:20,950 --> 01:52:27,890
so whereas monadic second order logic is it is undecidable reads

1873
01:52:27,910 --> 01:52:32,740
you can because when we made decidable because actually doesn't talk about read

1874
01:52:32,790 --> 01:52:34,950
it talks about

1875
01:52:34,990 --> 01:52:37,790
the tree that underlies

1876
01:52:37,810 --> 01:52:41,530
the operational model it is described by green

1877
01:52:41,560 --> 01:52:43,470
OK so it's really

1878
01:52:43,490 --> 01:52:48,260
it's not for that that and so what if i choose my models as trees

1879
01:52:48,370 --> 01:52:52,120
it's as powerful as this

1880
01:52:55,450 --> 01:52:58,620
what is nice for the mu calculus is that you can

1881
01:52:58,640 --> 01:53:00,510
you have you can build in

1882
01:53:02,410 --> 01:53:04,930
your favourite modality

1883
01:53:04,930 --> 01:53:07,490
so let me explain

1884
01:53:07,870 --> 01:53:11,850
just to introduce fixed points because it is based on fixed point

1885
01:53:12,950 --> 01:53:14,990
i just consider

1886
01:53:14,990 --> 01:53:19,180
the city formula actually that is a city cell formula but i could sit cl

1887
01:53:19,180 --> 01:53:22,620
because it it's in well known fragments

1888
01:53:22,640 --> 01:53:25,030
cgn which is a bit simpler

1889
01:53:25,080 --> 01:53:26,830
so the constraints and

1890
01:53:26,850 --> 01:53:28,810
siegel r

1891
01:53:28,810 --> 01:53:30,050
well the chicken is

1892
01:53:30,060 --> 01:53:34,780
polynomial time city sorry peace be peace space-time be space

1893
01:53:34,830 --> 01:53:36,870
the space time the space

1894
01:53:38,240 --> 01:53:42,470
so the city is a very nice gentle logic people like

1895
01:53:42,530 --> 01:53:46,600
and that's mostly what you find in checkers like

1896
01:53:47,510 --> 01:53:49,100
news and the whatever

1897
01:53:49,120 --> 01:53:53,950
all the tools that have been developed this last twenty years which would which have

1898
01:53:54,120 --> 01:53:55,390
led me

1899
01:53:55,430 --> 01:53:59,890
edmund clark and the MSO amounts to the civic is to have the

1900
01:53:59,990 --> 01:54:02,100
during award last year

1901
01:54:02,120 --> 01:54:04,990
you know is only is in between

1902
01:54:06,510 --> 01:54:09,530
and we and what's that

1903
01:54:09,850 --> 01:54:12,410
OK so CTL

1904
01:54:12,450 --> 01:54:17,740
is can that you can tell something that existed before eventually

1905
01:54:17,760 --> 01:54:21,120
proposition p holds

1906
01:54:21,140 --> 01:54:22,850
this is fine you

1907
01:54:22,870 --> 01:54:26,490
that means that from the roots of military


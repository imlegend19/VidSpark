1
00:00:00,000 --> 00:00:04,200
so we have this energy band diagram which is the plot of allowed that is

2
00:00:04,200 --> 00:00:08,970
important electron energy states in the material is function of position

3
00:00:09,140 --> 00:00:11,030
along a certain direction

4
00:00:11,050 --> 00:00:12,790
and you see

5
00:00:13,700 --> 00:00:17,020
there is a band gap between the

6
00:00:18,300 --> 00:00:24,720
energy of electrons in valence band and the minimum energy of the conduction band

7
00:00:24,730 --> 00:00:28,650
and this is a very important semiconductor parameter

8
00:00:28,650 --> 00:00:35,990
in silicon this band gap is one point one electron

9
00:00:36,070 --> 00:00:43,620
and the room temperature we can calculate what the concentration of electrons and holes are

10
00:00:43,750 --> 00:00:45,920
occupying these energy states

11
00:00:45,930 --> 00:00:51,410
it is one point five times ten to ten square centimeters so for

12
00:00:51,450 --> 00:00:57,930
people who work in semiconductors silicon this is one of the most important numbers they

13
00:00:57,930 --> 00:00:59,560
should know

14
00:00:59,620 --> 00:01:05,780
so you see we are talking about the energy bands so many energy levels here

15
00:01:05,800 --> 00:01:07,900
and now of course we want to know

16
00:01:07,910 --> 00:01:13,010
which of them are occupied by electrons because they are not occupied

17
00:01:13,040 --> 00:01:14,040
all the time

18
00:01:14,060 --> 00:01:16,480
i discussed already when we are at

19
00:01:16,510 --> 00:01:17,460
let's say

20
00:01:17,460 --> 00:01:19,470
zero kelvin temperature

21
00:01:19,480 --> 00:01:24,330
we have no electron in the conduction band all are in the bones so actually

22
00:01:24,360 --> 00:01:26,960
or are in the valence band

23
00:01:28,080 --> 00:01:33,980
as a function of temperature we see that we start occupying it's still more and

24
00:01:33,980 --> 00:01:40,620
more of these conduction band energy states and the function that describes this occupation is

25
00:01:40,620 --> 00:01:42,150
so-called fermi dirac

26
00:01:42,160 --> 00:01:44,250
distribution function

27
00:01:44,270 --> 00:01:50,170
and then using this function i'm not going into details there is a formula that

28
00:01:50,170 --> 00:01:56,190
finally we can calculate what the concentration of electrons and holes in such as semiconductor

29
00:01:56,190 --> 00:01:57,590
material is

30
00:01:57,680 --> 00:02:04,330
and using this formula we can calculate it and these are again important semiconductor material

31
00:02:04,340 --> 00:02:08,130
parameters that we use to calculate the concentration

32
00:02:08,170 --> 00:02:11,210
at a certain temperature

33
00:02:11,250 --> 00:02:13,540
and this is again numbers for

34
00:02:13,560 --> 00:02:17,790
silicon crystalline silicon

35
00:02:17,810 --> 00:02:20,560
so now to give you some examples

36
00:02:20,570 --> 00:02:23,440
how the situation changes when we

37
00:02:23,480 --> 00:02:29,520
go to the doping so for example you see we have

38
00:02:29,570 --> 00:02:31,780
though please

39
00:02:31,830 --> 00:02:38,170
this is phosphorus atoms so we are making the material and that we have no

40
00:02:38,170 --> 00:02:39,510
more electrons

41
00:02:39,530 --> 00:02:40,990
then holes

42
00:02:41,000 --> 00:02:42,450
we call

43
00:02:42,450 --> 00:02:44,440
these electrons when they are

44
00:02:44,450 --> 00:02:47,280
in larger concentration than intrinsic

45
00:02:47,320 --> 00:02:50,440
situation majority carriers

46
00:02:50,480 --> 00:02:54,430
and why majority carriers now i want to explain it to you

47
00:02:54,450 --> 00:02:57,180
so you see let's look at the

48
00:02:57,190 --> 00:02:58,250
how many

49
00:02:58,310 --> 00:03:03,780
phosphorus atoms we introduced in the silicon

50
00:03:04,870 --> 00:03:06,330
so let's say

51
00:03:06,390 --> 00:03:11,220
in this case i took an example of ten to seventeen in cubic

52
00:03:12,580 --> 00:03:17,630
now of course to realize what it means you should know how many silicon atoms

53
00:03:17,840 --> 00:03:22,930
in intrinsic silicon in cubic centimeter you have an idea

54
00:03:22,960 --> 00:03:24,540
what it is

55
00:03:24,570 --> 00:03:26,450
what is this number

56
00:03:26,460 --> 00:03:29,180
so we take a cubic centimeter of

57
00:03:30,500 --> 00:03:33,120
crystalline silicon is this one

58
00:03:33,130 --> 00:03:40,260
and how many silicon atoms do we find in one cubic centimeter

59
00:03:40,680 --> 00:03:43,860
how many

60
00:03:43,860 --> 00:03:52,020
well our current numbers

61
00:03:52,030 --> 00:03:53,790
twenty two

62
00:03:54,500 --> 00:03:56,490
so it's five times

63
00:03:56,500 --> 00:03:58,430
ten to twenty two

64
00:03:59,790 --> 00:04:05,700
now we when we take ten to seventeen phosphorus atoms to introduce it into

65
00:04:05,710 --> 00:04:10,650
the let is so we have five times ten to twenty two

66
00:04:10,660 --> 00:04:12,270
and ten to seventeen

67
00:04:12,290 --> 00:04:17,980
so it's flawless six orders of magnitude so it means

68
00:04:17,980 --> 00:04:23,650
we have to have one million silicon atoms and one million we just

69
00:04:23,660 --> 00:04:25,700
substitute one

70
00:04:25,760 --> 00:04:31,650
that's what we are doing with this level of doping

71
00:04:31,650 --> 00:04:33,070
is it clear

72
00:04:34,970 --> 00:04:36,510
in million

73
00:04:36,570 --> 00:04:41,730
silicon atoms we are substituting just one

74
00:04:41,780 --> 00:04:45,740
so not many

75
00:04:45,750 --> 00:04:51,290
and you can see what it means

76
00:04:56,270 --> 00:05:02,360
i did not say it but when we introduce this phosphorus or boron atoms

77
00:05:02,370 --> 00:05:07,120
i always mentioned the room temperature that's already enough to the

78
00:05:07,220 --> 00:05:11,930
that's a fifth electron on the hole in the case of boron atom

79
00:05:11,970 --> 00:05:13,160
you can move

80
00:05:13,210 --> 00:05:16,490
can be liberated from the eight

81
00:05:16,520 --> 00:05:18,950
so it means the room temperature

82
00:05:18,950 --> 00:05:21,880
the concentration of these majority

83
00:05:24,700 --> 00:05:26,080
is equal

84
00:05:26,170 --> 00:05:31,270
to the concentration of dopant atoms that we introduce into the lattice

85
00:05:31,290 --> 00:05:33,220
so when we take

86
00:05:33,270 --> 00:05:36,790
ten to seventeen phosphorus atoms as in this case

87
00:05:36,840 --> 00:05:40,510
then we know that the concentration of the

88
00:05:40,540 --> 00:05:43,180
electrons will be ten to seventeen

89
00:05:43,180 --> 00:05:46,020
now compare it to the situation

90
00:05:46,170 --> 00:05:48,810
intrinsic materials

91
00:05:48,820 --> 00:05:51,680
it was ten to ten

92
00:05:51,720 --> 00:05:55,870
so we have increased the concentration of electrons

93
00:05:55,910 --> 00:05:58,340
in the order of ten to seven

94
00:05:58,400 --> 00:06:00,210
so enormously

95
00:06:00,230 --> 00:06:06,230
so instead of having i would say one electron now we have ten to seven

96
00:06:07,930 --> 00:06:11,660
so orders of magnitude

97
00:06:11,670 --> 00:06:14,420
how we manipulated

98
00:06:14,430 --> 00:06:17,010
and because the product of

99
00:06:17,070 --> 00:06:18,190
b and n

100
00:06:18,200 --> 00:06:20,560
in the material has to be

101
00:06:20,640 --> 00:06:21,940
always the same

102
00:06:21,960 --> 00:06:27,990
it means that we also manipulate the concentration of falls

103
00:06:28,000 --> 00:06:31,030
so in total it has to be two times

104
00:06:31,070 --> 00:06:32,480
ten to twenty

105
00:06:32,480 --> 00:06:36,510
so you can easily calculate what the concentration of horses

106
00:06:36,530 --> 00:06:37,370
so now

107
00:06:37,380 --> 00:06:42,560
in this situation when we don't is phosphorus was ten to seventeen

108
00:06:42,580 --> 00:06:46,390
phosphorus atoms in cubic centimeter

109
00:06:46,390 --> 00:06:48,780
we have a completely different

110
00:06:48,800 --> 00:06:51,530
concentration of of electrons and holes

111
00:06:53,400 --> 00:06:56,810
the intrinsic materials we have ten to seventeen

112
00:06:56,860 --> 00:07:00,460
electrons and then to free holes

113
00:07:00,480 --> 00:07:02,240
so almost no holes there

114
00:07:02,250 --> 00:07:04,680
is it clear so

115
00:07:04,920 --> 00:07:09,610
properties like electrical conductivity

116
00:07:09,610 --> 00:07:12,540
this weekend you want to sign up before you go sign up early but don't

117
00:07:12,540 --> 00:07:15,400
sign up often because you only need one section

118
00:07:15,420 --> 00:07:19,340
if you're CPT student every once in a while you hear me refer to as

119
00:07:19,340 --> 00:07:23,280
cpt students that stands for stanford center for professional development they are the folks in

120
00:07:23,280 --> 00:07:25,360
industry you actually take this class

121
00:07:25,360 --> 00:07:29,550
of the broadcast internet CPT student you're automatically enrolled for sections so you don't actually

122
00:07:29,550 --> 00:07:33,220
need to do this in your section will meet so far as CPT and if

123
00:07:33,220 --> 00:07:37,990
you're wondering whether the student is you're not one case so as CPT section needs

124
00:07:39,360 --> 00:07:44,570
from one fifteen to apply it needs live if you want to go there by

125
00:07:44,570 --> 00:07:46,200
instilling auditorium

126
00:07:46,220 --> 00:07:50,050
but if you want to promote meets on channel

127
00:07:50,090 --> 00:07:54,980
it seems we are same needs on channel and what does that mean meet simon

128
00:07:54,980 --> 00:08:00,640
meets on generally two that is grammatically correct way of saying are so

129
00:08:00,650 --> 00:08:01,960
there's a little bit of

130
00:08:01,970 --> 00:08:07,010
more administrative kind of stuff now textbooks right experts there's nothing quite like the extortionate

131
00:08:07,010 --> 00:08:09,180
is textbooks so

132
00:08:09,220 --> 00:08:13,030
there's two textbooks that are required for this class one the course return textbooks course

133
00:08:13,030 --> 00:08:16,570
readers called kill the robot learning job you can pick it up at the bookstore

134
00:08:16,570 --> 00:08:21,210
it's relatively cheap was actually written by eric roberts here and surprisingly enough the textbook

135
00:08:21,210 --> 00:08:24,230
for the class was also written by eric roberts the art and science of job

136
00:08:24,230 --> 00:08:28,650
which is available now in your local bookstore including the bookstore on-campus so you can

137
00:08:28,650 --> 00:08:31,970
go and pick up a copy of this so both these things you actually want

138
00:08:31,970 --> 00:08:34,940
to have because they were part of the class will go through all of them

139
00:08:34,940 --> 00:08:38,650
will go through basically everything except the last chapter of this book so should get

140
00:08:38,650 --> 00:08:41,110
your money's worth we're just going to do it a little bit out of order

141
00:08:41,110 --> 00:08:43,110
but will go through the whole thing

142
00:08:43,890 --> 00:08:45,310
so email

143
00:08:45,320 --> 00:08:47,630
how many of you have email account

144
00:08:47,650 --> 00:08:51,420
i have to respect is anything at this point some people just don't want to

145
00:08:51,420 --> 00:08:55,440
put up their hands how many people don't have email accounts

146
00:08:55,460 --> 00:08:59,630
on how that is not the complement of the folks at the hands up previously

147
00:08:59,670 --> 00:09:03,930
emailed required for this class chances by being at stanford you've already got email account

148
00:09:03,930 --> 00:09:06,240
for your son i d but if you don't have an email i can get

149
00:09:06,250 --> 00:09:08,730
an email account that i will stay in contact with us that's how will stay

150
00:09:08,730 --> 00:09:12,240
in contact with you except possibly with you live in person on the email is

151
00:09:12,250 --> 00:09:16,300
kind of the general math communications manufacturer first assignment part of your first assignment is

152
00:09:16,300 --> 00:09:20,250
to send us an email just because we love you and we don't get enough

153
00:09:20,250 --> 00:09:23,080
emails it is so you need to have an email account to be able to

154
00:09:23,080 --> 00:09:25,260
do that so if you have not already been trying to get ahead of the

155
00:09:25,260 --> 00:09:27,990
game and go set up your email account i don't where you get the first

156
00:09:27,990 --> 00:09:31,940
summer next time still get like two days of breathing space before something goes up

157
00:09:31,960 --> 00:09:35,750
there's not going to be lots of an atom cluster b given out in class

158
00:09:35,950 --> 00:09:38,840
they will be given a possible answer post them online in case you missed

159
00:09:39,720 --> 00:09:42,500
and how much real work to do in this class is always kind of an

160
00:09:42,500 --> 00:09:47,170
interesting question so let's talk a little bit about assignments a little bit of other

161
00:09:47,240 --> 00:09:48,630
just call things

162
00:09:48,640 --> 00:09:56,810
so assignments what's called the dreaded signs there are seven programming assignments

163
00:09:56,820 --> 00:09:59,490
and if you look at the syllabus and number two it tells you one of

164
00:09:59,490 --> 00:10:02,730
them or do all the way through by day so you can plan your whole

165
00:10:02,730 --> 00:10:05,100
quarter it's just that much fun

166
00:10:05,850 --> 00:10:10,510
and the seven programming assignments are weighted slightly more toward the last simon because this

167
00:10:10,510 --> 00:10:13,650
image will tend to get more complicated that doesn't necessarily mean there will be more

168
00:10:13,650 --> 00:10:17,990
programming it just means conceptually they'll become more complicated so we tend to weigh the

169
00:10:18,000 --> 00:10:21,980
more towards the end of the class later sam's count more than early assignments

170
00:10:22,140 --> 00:10:28,790
how do actually doing programming is using a little tool called eclipse and eclipse thankfully

171
00:10:28,790 --> 00:10:32,130
is free so you don't have to pay for it is manufactured and download from

172
00:10:32,130 --> 00:10:34,630
the CS one of six a website and if you're wondering how you do that

173
00:10:34,630 --> 00:10:37,970
don't worry we'll give you a hand out next last explains to the whole

174
00:10:38,050 --> 00:10:42,380
ruling process of downloading and installing eclipse and you can use this either on the

175
00:10:42,380 --> 00:10:47,210
mac or PC so if you have your own computer you can certainly work on

176
00:10:47,210 --> 00:10:50,710
this ship yourself you just downloaded your own machine will explain the whole process in

177
00:10:50,710 --> 00:10:55,330
and out if you don't have to compute the public computer clusters on campus will

178
00:10:55,330 --> 00:10:58,360
have eclipse installed on them and so you can use eclipse there so you should

179
00:10:58,360 --> 00:10:59,860
have happy to go either way

180
00:10:59,880 --> 00:11:01,250
OK now

181
00:11:01,280 --> 00:11:04,700
the important thing to mention the whole notion of software engineering in the class and

182
00:11:04,700 --> 00:11:08,070
that's something we take really seriously so seriously net effect on you turn your assignment

183
00:11:08,070 --> 00:11:12,470
what they do take assignments and just kind of you know look at the interesting

184
00:11:13,200 --> 00:11:14,730
there you go thanks for playing

185
00:11:14,740 --> 00:11:18,710
and you learn a whole lot from that so in in order to actually learn

186
00:11:18,720 --> 00:11:21,470
a lot from your assignments we could take the assignment to write a whole bunch

187
00:11:21,470 --> 00:11:24,870
comments on and handed back to even that's kind of not enough

188
00:11:24,910 --> 00:11:28,800
we're really is a little bit more that makes some more fun is every week

189
00:11:28,810 --> 00:11:32,410
after train your assignment in your section it looks it over and grades it you'll

190
00:11:32,410 --> 00:11:36,150
actually meet with your section leader for about ten to fifteen minutes every week or

191
00:11:36,150 --> 00:11:39,590
every time an assignment is due to actually go over and something referred to as

192
00:11:39,590 --> 00:11:42,970
interactive creating and the chance to sit there and talk in an actual human being

193
00:11:43,160 --> 00:11:46,480
about what's good in your assignment where some of things you need to work on

194
00:11:46,480 --> 00:11:49,850
what are some of the software engineering principles you need to develop and that way

195
00:11:49,850 --> 00:11:54,300
you can really sort of get more detailed information and be able to ask questions

196
00:11:54,460 --> 00:11:58,230
to develop yourself as the programmer as well i get help if you need help

197
00:11:58,240 --> 00:12:01,430
OK and that's in addition to go in the section on the class and all

198
00:12:01,430 --> 00:12:05,540
that stuff so another fifteen minutes week you'll actually schedule that time with your section

199
00:12:05,540 --> 00:12:10,030
leader on a regular basis when you have interactive rating or just a fraction affectionately

200
00:12:10,030 --> 00:12:14,150
referred to as IG's because at stanford you know everything just short we just can't

201
00:12:14,150 --> 00:12:16,840
say like you know psychology that's like so

202
00:12:16,850 --> 00:12:19,150
it's i g just remember that

203
00:12:19,180 --> 00:12:22,150
all right and then how are these things great so the other thing we could

204
00:12:22,150 --> 00:12:25,010
do is so i told you could describe being handed back to you

205
00:12:25,060 --> 00:12:28,280
but we found that that's not really great because people get all wrapped around the

206
00:12:28,280 --> 00:12:32,460
axle about the grade and so far we did numbers in real icon what we

207
00:12:32,460 --> 00:12:36,160
give a number between one and twenty and so what happens there people get all

208
00:12:36,160 --> 00:12:40,650
wrapped around the axle about numbers so we thought how was a happier time when

209
00:12:40,650 --> 00:12:41,660
we were in school

210
00:12:41,690 --> 00:12:45,150
i remember when we were in school and we used get back assignments and they

211
00:12:45,150 --> 00:12:49,480
have like smiley faces on them what we can do that and you know it

212
00:12:49,480 --> 00:12:51,720
doesn't appear to be rigorous stanford class

213
00:12:53,080 --> 00:12:56,730
instead of the smiley face we come up with something else

214
00:12:56,760 --> 00:12:59,340
which look surprisingly like this

215
00:12:59,410 --> 00:13:02,830
it's kind of involved actually draws finitary support

216
00:13:07,380 --> 00:13:10,850
that's kind of the beginning of our grading scale OK and the way of grading

217
00:13:10,850 --> 00:13:13,800
scale works if we start off with the check in the middle

218
00:13:13,810 --> 00:13:17,510
which is this is a pretty solid program you know it meets all the requirements

219
00:13:17,510 --> 00:13:21,630
for the program maybe it's got a little problem here there but it to check

220
00:13:21,820 --> 00:13:25,420
we have sort of two grades on the two sides to check plus and cheque

221
00:13:25,420 --> 00:13:28,090
minus check plus is like

222
00:13:28,890 --> 00:13:34,120
you did a great job you got everything right things look good nice time on

223
00:13:34,120 --> 00:13:39,280
your programme nice software engineering and the program works flawlessly good job this is like

224
00:13:39,280 --> 00:13:41,570
you know whole way a

225
00:13:41,580 --> 00:13:46,130
chuck is kind of like you know there's a minus b plus maybe on some

226
00:13:47,510 --> 00:13:50,070
but it's kind of like you know it's pretty good work you're in pretty good

227
00:13:50,070 --> 00:13:53,770
shape here and so a lot of great in this class ends up being checked

228
00:13:53,770 --> 00:13:57,140
pluses and checks and if that's the case you're perfectly fine grained white

229
00:13:57,150 --> 00:14:01,880
check minus you can imagine this is kind of thinking about the minus yeah there

230
00:14:01,890 --> 00:14:06,090
are some slightly more you know significant problems with your programme but that's where it

231
00:14:06,090 --> 00:14:09,450
so he is now

232
00:14:10,220 --> 00:14:11,180
he of the

233
00:14:11,190 --> 00:14:13,020
in machine learning

234
00:14:13,030 --> 00:14:19,480
and what their group in southampton and before that he was a full professor at

235
00:14:19,590 --> 00:14:20,040
a whole

236
00:14:20,050 --> 00:14:24,740
holloway college london and basically i mean he's probably one of the people who you

237
00:14:24,740 --> 00:14:30,480
would have encountered at some point anyway doing machine learning statistical learning theory in europe

238
00:14:30,480 --> 00:14:33,900
seven he's been around at least as long as i can remember even though you

239
00:14:33,900 --> 00:14:38,990
don't look like it and OK of spatial data that we have the better to

240
00:14:38,990 --> 00:14:50,110
present this OK thanks

241
00:14:50,120 --> 00:15:04,430
OK so thank you to the organizers for

242
00:15:04,660 --> 00:15:07,930
this very on by this invitation to

243
00:15:08,040 --> 00:15:10,890
presented the summer school

244
00:15:10,940 --> 00:15:16,310
so when i was asked to talk about basic statistical learning theory

245
00:15:16,330 --> 00:15:19,200
i was trying to think

246
00:15:19,220 --> 00:15:21,910
what i couldn't hope to

247
00:15:21,920 --> 00:15:23,760
do for you in this

248
00:15:23,780 --> 00:15:29,720
a period of time allotted and what you might be able to take away from

249
00:15:31,960 --> 00:15:34,050
a set of lectures

250
00:15:35,460 --> 00:15:41,590
and suddenly came to mind was a series of books that are actually sold in

251
00:15:41,590 --> 00:15:42,740
the UK

252
00:15:42,750 --> 00:15:45,160
known as the bluffer's guide to

253
00:15:46,010 --> 00:15:50,300
and you can get a bluffer's guide for all sorts of topics from

254
00:15:50,320 --> 00:15:52,020
psycho analysis

255
00:15:54,160 --> 00:15:55,560
two schemes

256
00:15:57,670 --> 00:16:02,220
philosophy or whatever and the idea of bluffer's guide to apply for somebody sort of

257
00:16:02,220 --> 00:16:06,460
makes his way by not really knowing what's going on that has the right terminology

258
00:16:06,460 --> 00:16:09,010
and can sort of get by the cocktail party

259
00:16:09,080 --> 00:16:14,980
so the bluffer's guide book gives you all the key to this and tells you

260
00:16:14,980 --> 00:16:15,560
you know

261
00:16:15,580 --> 00:16:17,830
how to use them in the right context

262
00:16:18,070 --> 00:16:21,000
so for instance you know if you

263
00:16:21,020 --> 00:16:22,460
start talking in

264
00:16:22,470 --> 00:16:26,420
statistical learning theory about the ghost sample

265
00:16:26,430 --> 00:16:29,060
you know you should know that is the

266
00:16:29,070 --> 00:16:32,800
the dataset used in your last submission

267
00:16:33,340 --> 00:16:38,980
on the double sample triggers is not actually something to do with cards and

268
00:16:38,990 --> 00:16:40,020
and so on

269
00:16:40,030 --> 00:16:45,970
concentration is not about the level of alcohol in your blood and so on

270
00:16:47,960 --> 00:16:53,090
my intention and i mean i mean that's joking aside i think these books actually

271
00:16:53,090 --> 00:16:57,790
also are quite destructive in this surprisingly informative give you

272
00:16:57,830 --> 00:17:03,110
the sort of levels strategic level view of that subject but often it's very hard

273
00:17:03,130 --> 00:17:04,120
to get

274
00:17:04,130 --> 00:17:08,630
from a textbook which will go into more detail a lot more

275
00:17:08,650 --> 00:17:09,940
of the

276
00:17:09,960 --> 00:17:13,510
you get lost in the detail you don't get a sort of overview so in

277
00:17:13,510 --> 00:17:17,200
a sense that the first level i would like to try and

278
00:17:17,220 --> 00:17:22,970
reach the people come away from this with a sense of what i was statistical

279
00:17:22,970 --> 00:17:25,550
learning theory is attempting to achieve

280
00:17:25,570 --> 00:17:29,430
what is this sort of contribution to i want to bring to the table

281
00:17:29,440 --> 00:17:30,790
of machine learning

282
00:17:31,830 --> 00:17:37,270
to what extent it successful in doing that and to what extent it it fails

283
00:17:37,280 --> 00:17:39,150
or needs to be further

284
00:17:43,470 --> 00:17:47,710
i suppose in a sense putting it in the context of of the research that

285
00:17:47,720 --> 00:17:51,410
you might be doing and how it relates to that search

286
00:17:51,460 --> 00:17:54,910
so if you like that will be the level i would hope everybody might take

287
00:17:54,910 --> 00:17:56,560
away from this

288
00:17:57,180 --> 00:18:02,880
i think also i would you know also hope that many of you might take

289
00:18:02,880 --> 00:18:08,180
a little bit more than that in that i will hope to cover

290
00:18:08,190 --> 00:18:09,810
some of the

291
00:18:13,250 --> 00:18:16,710
theorems and

292
00:18:16,740 --> 00:18:19,540
ideas behind the theory

293
00:18:19,890 --> 00:18:23,310
in a way that i hope will if you see that there's actually a lot

294
00:18:23,310 --> 00:18:27,530
of interesting things in that theory and a lot of nice ideas that fun to

295
00:18:27,530 --> 00:18:28,490
work with

296
00:18:28,590 --> 00:18:32,800
so in a sense i like to hope that some of you will actually feel

297
00:18:33,160 --> 00:18:36,320
that's really interesting that's something i you know

298
00:18:36,350 --> 00:18:39,540
didn't know now have have learned

299
00:18:39,560 --> 00:18:42,890
and finally you know also i might

300
00:18:42,900 --> 00:18:43,700
i hope that

301
00:18:44,770 --> 00:18:46,560
many of you will take

302
00:18:46,960 --> 00:18:51,170
an inspiration from this to try and apply some of the ideas to research you're

303
00:18:52,190 --> 00:18:52,830
so what

304
00:18:52,840 --> 00:18:53,940
in this sense

305
00:18:53,980 --> 00:18:59,300
that would be the major goal will be to see that yes OK that actually

306
00:18:59,300 --> 00:19:02,670
applies to one thing it can help me understand

307
00:19:02,690 --> 00:19:08,720
all further illuminate the actual algorithms i'm working with the process the techniques of music

308
00:19:08,720 --> 00:19:13,070
in my research and and actually those techniques could be applied area

309
00:19:13,250 --> 00:19:15,650
so the idea is to use the sort of three

310
00:19:16,120 --> 00:19:18,540
o levels and striving for

311
00:19:19,020 --> 00:19:24,460
but certainly i don't want to get lost in a lot of detail and i

312
00:19:24,460 --> 00:19:28,090
want to try but i want to try and give you some of the enthusiasm

313
00:19:28,090 --> 00:19:29,460
for some of the key

314
00:19:29,470 --> 00:19:33,400
ideas so on that note of forward

315
00:19:34,860 --> 00:19:39,030
and give you an overview of the basic structure that i'm hoping things i'm hoping

316
00:19:39,030 --> 00:19:40,010
to cover

317
00:19:40,010 --> 00:19:44,320
particular 1 but this is a pretty natural way

318
00:19:48,030 --> 00:19:50,110
free variables

319
00:19:54,560 --> 00:19:59,850
since those free variables are the guys that can be anything

320
00:19:59,880 --> 00:20:02,390
the most convenient choice is 0

321
00:20:05,320 --> 00:20:09,390
X equals

322
00:20:09,410 --> 00:20:10,750
for the

323
00:20:10,770 --> 00:20:14,110
pivot variables

324
00:20:14,180 --> 00:20:19,990
so what does that mean in this example which are the 3 variables

325
00:20:20,100 --> 00:20:24,750
which which is the variables that we can assign freely and then then then there

326
00:20:24,940 --> 00:20:28,200
1 and only 1 way to find the pivot

327
00:20:28,220 --> 00:20:29,340
there x 2

328
00:20:29,990 --> 00:20:32,820
and so X 2 is 0

329
00:20:32,840 --> 00:20:39,770
presented no column without a pivot the 2nd column has no pivot and

330
00:20:39,840 --> 00:20:41,630
what's the other 1

331
00:20:41,680 --> 00:20:43,370
the 4 x 4

332
00:20:43,580 --> 00:20:44,600
is 0

333
00:20:44,720 --> 00:20:49,910
because that those are the free 1

334
00:20:49,960 --> 00:20:54,100
0 0 and the columns with no pivots so you see what might is so

335
00:20:54,110 --> 00:20:58,580
when I'm not 1 x 2 Annex 4 0

336
00:20:58,700 --> 00:21:00,730
I'm left with them

337
00:21:01,220 --> 00:21:07,060
the book or 1 of my left with here and just left with

338
00:21:07,110 --> 00:21:12,990
the now I'm not using the to free columns I'm only using the pivot columns

339
00:21:12,990 --> 00:21:18,650
so I'm really left with X 1 the 1st equation is just X 1 and

340
00:21:18,650 --> 00:21:23,220
2 x 3 should be the right hand side which we take to be a

341
00:21:24,250 --> 00:21:27,630
and the 2nd equation is 2 x 3

342
00:21:27,730 --> 00:21:30,100
as it happened turned out to be

343
00:21:30,870 --> 00:21:35,440
I necessary

344
00:21:35,490 --> 00:21:38,560
of guidance right and again here

345
00:21:38,580 --> 00:21:43,340
with X 2 and the explored knocked out since set them to 0 and you

346
00:21:43,340 --> 00:21:46,560
see that we're we're back in the normal case

347
00:21:46,600 --> 00:21:50,410
of having back we're back substitution will do it so x 3

348
00:21:50,910 --> 00:21:53,730
is 3 halves

349
00:21:53,820 --> 00:21:56,780
and then we go back up and X ones

350
00:21:56,820 --> 00:22:02,870
is 1 minus 2 x 3 that's probably minus 2

351
00:22:04,060 --> 00:22:10,130
so now we have the solution x particular is the vector of

352
00:22:10,230 --> 00:22:12,100
minus 2

353
00:22:12,150 --> 00:22:15,630
0 3 halves

354
00:22:19,820 --> 00:22:23,940
that's 1 particular solution and we show

355
00:22:23,960 --> 00:22:27,940
could plug it into the original system

356
00:22:27,960 --> 00:22:32,250
that really have on the quiz please that's a good thing to do

357
00:22:32,320 --> 00:22:37,200
this up so we did all this is these their role operations

358
00:22:37,580 --> 00:22:42,700
but this is supposed to solve the original system and I think it

359
00:22:44,150 --> 00:22:47,250
so that's effects particularly

360
00:22:47,270 --> 00:22:48,390
which we got

361
00:22:48,440 --> 00:22:52,910
so that is that that's like what's new today

362
00:22:52,940 --> 00:22:58,850
the particular solution comes 1st you check that you have 0 equals 0 so your

363
00:22:58,850 --> 00:23:01,480
OK on the last equations

364
00:23:01,530 --> 00:23:03,700
and then you

365
00:23:03,770 --> 00:23:08,130
set them free variables that 0 solve for the pivot variables

366
00:23:08,150 --> 00:23:10,390
and you've got a particular solution

367
00:23:10,460 --> 00:23:14,720
the particular solution that has 0 free variables

368
00:23:17,030 --> 00:23:22,510
but that's only 1 solution and now I'm looking for all

369
00:23:22,590 --> 00:23:23,980
so how do I find the rest

370
00:23:24,780 --> 00:23:28,860
the point is I can add on to

371
00:23:28,880 --> 00:23:34,220
add on X anything out of the null space

372
00:23:36,980 --> 00:23:39,750
we know how to find the vectors in the null space

373
00:23:39,820 --> 00:23:43,720
because we didn't last time but I'll remember remind you what we got

374
00:23:43,770 --> 00:23:45,530
and then

375
00:23:45,580 --> 00:23:48,060
all add

376
00:23:48,150 --> 00:23:52,440
so the final result will be

377
00:23:52,480 --> 00:23:57,200
that the complete solution this is now the complete Guide

378
00:23:57,220 --> 00:24:06,100
the complete solution is this 1 particular solution plus any any vector

379
00:24:06,130 --> 00:24:09,960
all different vectors out of the null space

380
00:24:09,980 --> 00:24:16,850
xxx on OK why why this pattern because as patterns shows up through all of

381
00:24:16,850 --> 00:24:22,270
mathematics close it shows up everywhere we have linear equations

382
00:24:22,320 --> 00:24:25,630
let me just put here that the reason

383
00:24:29,840 --> 00:24:32,100
so that takes particular

384
00:24:32,110 --> 00:24:35,390
so what is a x particular again

385
00:24:35,410 --> 00:24:38,560
that gives the correct right hand side the

386
00:24:38,560 --> 00:24:44,040
and what is a times and X in the null space here

387
00:24:45,370 --> 00:24:47,760
so I

388
00:24:47,870 --> 00:24:51,500
and I born in parentheses

389
00:24:51,500 --> 00:24:55,890
so xp + x

390
00:24:55,910 --> 00:24:58,410
it the + 0 which is being

391
00:24:58,520 --> 00:25:00,100
so far

392
00:25:00,100 --> 00:25:03,080
0 what am I saying that he does say it in words

393
00:25:03,100 --> 00:25:07,450
if I have 1 solutions

394
00:25:07,690 --> 00:25:12,000
1 solution I can add on anything in the null space

395
00:25:12,040 --> 00:25:14,470
goes anything in the null space

396
00:25:14,500 --> 00:25:18,650
has a 0 right hand side and and I still have the correct right hand

397
00:25:18,650 --> 00:25:20,300
side b

398
00:25:20,320 --> 00:25:23,820
so that's my system that's my complete solution

399
00:25:23,840 --> 00:25:27,540
no let me write out what that will be for this example

400
00:25:28,320 --> 00:25:31,470
so in this example in this example

401
00:25:31,520 --> 00:25:40,930
experts X general X completes the complete solution is x particulars

402
00:25:41,020 --> 00:25:42,430
which is

403
00:25:42,450 --> 00:25:45,910
minus 2 0 0 3 0

404
00:25:45,950 --> 00:25:51,750
with those zeros in the free variable plus remember the reverse special solutions in the

405
00:25:51,760 --> 00:25:52,930
null space

406
00:25:52,930 --> 00:25:54,800
well i think they can show it

407
00:25:54,800 --> 00:25:56,470
show here brick

408
00:26:04,320 --> 00:26:08,230
so the interesting thing in this example is this is the danger of being entry

409
00:26:08,230 --> 00:26:11,100
in freebase and you know his types

410
00:26:11,120 --> 00:26:13,490
the type of entity that is this is the person

411
00:26:13,510 --> 00:26:15,180
and also deceased person

412
00:26:15,200 --> 00:26:17,660
and separately his profession

413
00:26:17,740 --> 00:26:19,490
is politician

414
00:26:19,510 --> 00:26:21,950
now if you want to connect this to

415
00:26:21,970 --> 00:26:28,010
the rest of of words the ontology to know the politicians are kind of

416
00:26:28,050 --> 00:26:32,620
sort of a national roller something like this to other kinds of things with that

417
00:26:32,620 --> 00:26:36,260
then you can just to the mapping at the level of the type you have

418
00:26:36,260 --> 00:26:41,600
to the new level that feels similarly there will be entries where the

419
00:26:42,600 --> 00:26:44,890
if someone

420
00:26:44,910 --> 00:26:49,390
you know there's gender someone we can double-click and added here

421
00:26:49,430 --> 00:26:51,910
you know we can say oh he's male

422
00:26:51,950 --> 00:26:57,800
OK i just updated freebase in real time so the genders male

423
00:26:57,800 --> 00:27:02,180
but if you want to connect the two what men did something well that all

424
00:27:02,180 --> 00:27:04,050
the the concept of men

425
00:27:04,140 --> 00:27:07,760
is you know is an is a hierarchy and here you know male is an

426
00:27:07,760 --> 00:27:10,760
attribute of this this thing so

427
00:27:10,780 --> 00:27:15,850
what we've done is basically make a kind of cross mapping said across mapping knowledge

428
00:27:16,140 --> 00:27:17,970
that maps from the

429
00:27:17,990 --> 00:27:23,470
either from the types or from the attributes of different roles into the corresponding word

430
00:27:23,470 --> 00:27:29,890
category and some of that is manual manually done knowledge some of that semiautomatically because

431
00:27:29,890 --> 00:27:34,760
you can take some guesses based on this thing and other kinds of clues so

432
00:27:34,780 --> 00:27:38,600
so we've done that kind of work and some that's quite interesting and more generally

433
00:27:38,600 --> 00:27:41,660
as you start doing more and more kinds of integration of resources i think these

434
00:27:41,700 --> 00:27:48,030
really interesting challenging problems it will be figuring out how to do better

435
00:27:49,220 --> 00:27:52,280
sure first of i marked could

436
00:27:53,930 --> 00:27:58,890
so the question is about word in fact extraction and it looks like we might

437
00:27:58,890 --> 00:28:02,070
be extracting triples how far beyond triples can we go

438
00:28:02,140 --> 00:28:05,550
and actually were really extracting far more than triples

439
00:28:05,570 --> 00:28:12,890
right now in some of these things that i was showing you here

440
00:28:12,930 --> 00:28:16,240
this is second one

441
00:28:16,300 --> 00:28:20,850
yes you actually got to you got the subjects and you've got relations you've got

442
00:28:20,850 --> 00:28:25,510
objects you've got the when of something you've got the where

443
00:28:25,600 --> 00:28:28,120
you actually will have reasons for it

444
00:28:28,140 --> 00:28:34,490
you actually have about some things about embedded in that context we also extract out

445
00:28:35,680 --> 00:28:40,850
some other kinds of sentiment features and in general

446
00:28:40,870 --> 00:28:44,680
the we have this huge set information that's extracted out into our semantics

447
00:28:44,740 --> 00:28:48,620
and one of the interesting question is how much of that makes it actually into

448
00:28:48,620 --> 00:28:52,550
our index for efficient retrieval of large scales but there's already an awful lot of

449
00:28:52,550 --> 00:28:59,030
information in these systems more than just a small table

450
00:28:59,120 --> 00:29:02,970
OK so the question is how we deal with knowledge on the one hand and

451
00:29:02,970 --> 00:29:04,870
trust on the other hand

452
00:29:04,950 --> 00:29:11,090
so context and trust so super context there's multiple

453
00:29:11,100 --> 00:29:16,850
ways that context plays in one simple way is with things like word sense

454
00:29:18,300 --> 00:29:22,210
as you know if you have some ambiguity in word sense one word can multiple

455
00:29:22,210 --> 00:29:25,780
concepts which won the right concept we want to be able to tell the user

456
00:29:25,780 --> 00:29:31,530
how we're going to rank prioritize we are employing were sense disambiguation can take advantage

457
00:29:31,530 --> 00:29:36,010
of the local context around these kinds of things similarly we have to do anaphora

458
00:29:37,070 --> 00:29:40,800
so if it says he knowing this actually doing paying how do you do that

459
00:29:40,890 --> 00:29:46,870
multiple choices again their contextual approach is that the work on their

460
00:29:46,890 --> 00:29:52,550
and there's also specialized national context here which is certain facts may only be true

461
00:29:52,550 --> 00:29:54,700
within certain contexts so

462
00:29:54,740 --> 00:29:59,350
only in someone ambiguous reading this certain factor where some of the things are true

463
00:29:59,350 --> 00:30:05,820
in all contexts or something maybe in the context of a believed thing or stated

464
00:30:05,910 --> 00:30:08,450
o thing or negated context so

465
00:30:08,450 --> 00:30:12,950
there's many context and you know it we take advantage of them here on the

466
00:30:12,950 --> 00:30:15,120
theme of trust in the current model

467
00:30:15,740 --> 00:30:20,870
we're not addressing trust you saw the stacks they showed you are extracted you know

468
00:30:20,870 --> 00:30:26,010
it's it's equally trusting everything but actually is able to use some statistics when sorting

469
00:30:26,010 --> 00:30:30,490
organised the results to say well you know how how often is this kind of

470
00:30:30,490 --> 00:30:31,760
fact repeated

471
00:30:31,820 --> 00:30:36,970
now there are some really nice work on using trust and confidence from the level

472
00:30:36,970 --> 00:30:39,240
of documents and being combined

473
00:30:39,680 --> 00:30:43,390
i just recently read the paper about not go

474
00:30:43,390 --> 00:30:45,580
the principal components

475
00:30:45,620 --> 00:30:48,500
by introducing nonlinearity you get something else

476
00:30:49,550 --> 00:30:53,330
which somehow means that when you stack these you get something nonlinear that turns out

477
00:30:53,340 --> 00:30:55,730
to be useful

478
00:30:55,730 --> 00:30:58,330
once you've stacked a bunch of them

479
00:30:58,360 --> 00:30:59,450
you can

480
00:30:59,450 --> 00:31:04,550
you can tag list logistic regression on top and then optimize

481
00:31:04,570 --> 00:31:08,180
all the parameters go from input to those predictions

482
00:31:08,710 --> 00:31:10,020
in a supervised way

483
00:31:10,030 --> 00:31:12,560
so actually doing this is very simple

484
00:31:15,050 --> 00:31:21,080
not as well as IBM's but much better than training a deep architecture from scratch

485
00:31:21,120 --> 00:31:26,130
there is another variant that is interesting it doesn't work as well but still works

486
00:31:26,130 --> 00:31:28,320
better than

487
00:31:28,330 --> 00:31:30,570
trained from scratch in a supervised way

488
00:31:32,550 --> 00:31:36,250
say something about the power of just having a local criteria

489
00:31:36,290 --> 00:31:40,080
so you could train regular one hidden layer neural network predicts

490
00:31:40,090 --> 00:31:43,150
your classes given some inputs

491
00:31:43,210 --> 00:31:46,240
and once you've training you can throw away those parameters that

492
00:31:46,290 --> 00:31:48,770
go from the intermediate code two

493
00:31:48,780 --> 00:31:49,710
the prediction

494
00:31:49,720 --> 00:31:50,920
and just keep the

495
00:31:50,930 --> 00:31:52,350
first level parameters

496
00:31:52,380 --> 00:31:56,430
and then as we did for the autoencoder you can take that as input for

497
00:31:57,320 --> 00:31:58,340
next level

498
00:31:58,350 --> 00:32:02,050
train the second one he that

499
00:32:02,100 --> 00:32:03,480
and you can do that

500
00:32:03,480 --> 00:32:08,360
several times and then just two logistic regression at the end and then fine tune

501
00:32:09,710 --> 00:32:11,290
and that

502
00:32:11,370 --> 00:32:16,730
is really worse than using autoencoders but is really better than trying from scratch

503
00:32:18,740 --> 00:32:21,780
so there's supervisors unsupervised

504
00:32:21,790 --> 00:32:25,020
part of the unsupervised component is important

505
00:32:25,690 --> 00:32:31,860
but having something just local also by itself gives benefits yes

506
00:32:32,060 --> 00:32:39,830
so that's a good question so it here you don't care with anyone in supervised

507
00:32:39,830 --> 00:32:42,510
but in your could you would think that if you had

508
00:32:42,530 --> 00:32:46,900
more notes than inputs then could just learn the identity and would be very useful

509
00:32:46,920 --> 00:32:49,810
now in practice for some reason it doesn't happen

510
00:32:49,870 --> 00:32:56,010
because you start from small weights and you would need very large which the identity

511
00:32:56,050 --> 00:32:58,540
and also because you're tying the weights of the

512
00:32:58,590 --> 00:33:01,190
and called apart the decoder part

513
00:33:01,190 --> 00:33:04,520
in any case

514
00:33:04,530 --> 00:33:05,970
it doesn't seem to be an issue

515
00:33:05,980 --> 00:33:07,380
but that

516
00:33:07,440 --> 00:33:12,030
but other versions of autoencoders i'll talk about the sparse ones and denoising ones i'll

517
00:33:12,060 --> 00:33:13,110
talk about

518
00:33:14,240 --> 00:33:16,770
i don't have this problem that they can learn the identity

519
00:33:16,820 --> 00:33:23,510
so it's reassuring but it's something one should worry about in the first place

520
00:33:43,170 --> 00:33:46,490
why in principle you could

521
00:33:59,650 --> 00:34:04,820
yes yes yes

522
00:34:04,860 --> 00:34:07,300
actually that's exactly what

523
00:34:07,360 --> 00:34:10,230
collobert weston have done in their language modeling

524
00:34:11,270 --> 00:34:13,250
to predict the next

525
00:34:14,290 --> 00:34:15,960
given the previous work

526
00:34:15,980 --> 00:34:20,730
and it works very well

527
00:34:20,750 --> 00:34:24,460
i don't know if anyone's tried

528
00:34:24,480 --> 00:34:28,400
but i don't see any reason why not

529
00:34:28,440 --> 00:34:31,070
yeah in general use

530
00:34:31,110 --> 00:34:36,070
you can use predicting the next thing is very powerful wants the y signal here

531
00:34:36,130 --> 00:34:40,750
and someone should try it for images

532
00:34:42,770 --> 00:34:47,400
one thing i want to mention is that kind of bomber in these experiments is

533
00:34:47,400 --> 00:34:48,440
that it looks like

534
00:34:48,500 --> 00:34:51,230
you do need this final fine tuning

535
00:34:53,900 --> 00:34:57,630
to get the better results so this curve shows

536
00:34:57,670 --> 00:34:59,460
classication error

537
00:34:59,460 --> 00:35:03,880
on some task on digit classification task where

538
00:35:04,440 --> 00:35:07,650
for the first part of training we just two

539
00:35:07,650 --> 00:35:10,710
unsupervised learning out of the lower levels

540
00:35:10,750 --> 00:35:12,380
and then at some point

541
00:35:13,650 --> 00:35:17,460
we introduce supervised learning and we can do in various ways one way which works

542
00:35:17,460 --> 00:35:21,460
best this is purely supervised so we've completely removed the surprise

543
00:35:21,500 --> 00:35:23,630
component of the gradient

544
00:35:23,670 --> 00:35:30,000
and in one way just remain unsupervised and an intermediate ways involved

545
00:35:30,020 --> 00:35:32,110
combining the two

546
00:35:32,800 --> 00:35:35,710
these need experiments it looks like

547
00:35:35,710 --> 00:35:37,500
fine tuning gives an edge

548
00:35:37,500 --> 00:35:40,070
and when we do understand that is very simple we're here

549
00:35:40,090 --> 00:35:43,880
in the end we're interested in the classification task and if we add the two

550
00:35:43,880 --> 00:35:46,210
criteria ideas rise in the rise

551
00:35:46,250 --> 00:35:47,480
well again

552
00:35:47,520 --> 00:35:49,630
makes a compromise between the two

553
00:35:50,130 --> 00:35:51,070
if we

554
00:35:51,070 --> 00:35:55,940
are low data regime maybe that's useful a regularizer about

555
00:35:56,000 --> 00:35:59,340
otherwise it might actually hurt

556
00:36:00,190 --> 00:36:01,730
that comes

557
00:36:34,020 --> 00:36:35,460
most of it might be useful

558
00:36:45,750 --> 00:36:51,250
well you you would think you would think that you could have a lot of

559
00:36:51,320 --> 00:36:54,520
a lot of these are useful for classification but let's see some of the more

560
00:36:54,520 --> 00:37:00,060
faces that express the squalor the corruption of the smug carnality of the bourgeois

561
00:37:00,060 --> 00:37:06,210
world that was to become the most docile supporter of the dictatorship

562
00:37:06,210 --> 00:37:12,560
in the dada movement the attraction of ugliness emerged through an appeal to grotesque

563
00:37:12,650 --> 00:37:18,980
propensity for disturbing situations and mostrous images is evident in the surrealist

564
00:37:18,980 --> 00:37:21,590
manifesto of nineteen twenty four

565
00:37:21,630 --> 00:37:26,540
and in films like bunuel un chien andalou where we see

566
00:37:27,190 --> 00:37:34,170
repugnant operations like the vivisection of an eye bataille immortalized big toe

567
00:37:34,920 --> 00:37:38,730
and flowers as objects of disguist

568
00:37:39,310 --> 00:37:45,080
later the informal movement was to reassess what had until then been seen

569
00:37:45,080 --> 00:37:51,290
as unrepresentable in other words the more inaccessible deaths of matter moulds

570
00:37:51,290 --> 00:37:57,880
dust and mud new realism rediscovered the detritus of the industrial world and

571
00:37:57,880 --> 00:38:05,170
fragment of destroyed objects exponents of pop art like warhol appealed for an aesthetic

572
00:38:05,170 --> 00:38:11,190
an aesthetic recyling of waste and pierro manzoni presented in the

573
00:38:11,190 --> 00:38:17,580
gallery and sold at the very high price heart is shit merda d'artista

574
00:38:17,590 --> 00:38:25,130
today we recognize as artistically beautiful all those works that had horrified our

575
00:38:25,130 --> 00:38:31,670
fathers the ugliness of the avantgarde has been accepted as a new model for beauty

576
00:38:31,670 --> 00:38:35,730
and has given rise to a new commercial circuirt

577
00:38:36,130 --> 00:38:41,440
certainly in contemporary art the borderline between beautiful and ugly

578
00:38:41,440 --> 00:38:43,340
has been canceled

579
00:38:44,960 --> 00:38:51,170
contemporary art doesn't seem still interested in producing beautiful objects

580
00:38:51,190 --> 00:38:53,670
but rather in producing

581
00:38:53,710 --> 00:38:57,500
forms of provocative behavior

582
00:38:57,770 --> 00:38:59,690
but it has been said that

583
00:38:59,730 --> 00:39:02,560
the borderline between

584
00:39:02,690 --> 00:39:05,610
beautiful and ugly has

585
00:39:05,650 --> 00:39:11,440
by now disappeared also in our everyday life we today coexist with

586
00:39:11,440 --> 00:39:18,420
contrasting models because the opposition beautiful ugly has no longer any

587
00:39:18,440 --> 00:39:20,110
aesthetic value

588
00:39:20,520 --> 00:39:25,580
ugly and beautiful would be two possible options to be

589
00:39:25,580 --> 00:39:28,290
experienced neutrally

590
00:39:28,400 --> 00:39:29,920
it seems so

591
00:39:30,400 --> 00:39:37,560
if we consider that monster can be ugly in many science fiction movies or in

592
00:39:37,580 --> 00:39:42,840
the various nights of the living deads but oders are certainly lovable

593
00:39:43,340 --> 00:39:50,880
or like ET or the extraterrestrials of Star Wars and fascinate not only children who

594
00:39:50,880 --> 00:39:52,440
are also fond

595
00:39:52,480 --> 00:39:59,610
of dinosaurs or pokemon and other deformed creatures but also adults who

596
00:39:59,610 --> 00:40:02,650
relax in front of splatter movies

597
00:40:02,880 --> 00:40:07,480
where brains are reduced to pulp and blood spurts onto the walls

598
00:40:07,940 --> 00:40:12,250
or amuse themselves by reading horror stories

599
00:40:12,520 --> 00:40:18,040
but the same person do not seem to have lost the traditional sense of beauty

600
00:40:18,170 --> 00:40:25,630
since they still take aesthetic pleasure in a fine landscape a handsome child or a flat screen that

601
00:40:25,630 --> 00:40:28,860
shows the cannons of the golden section

602
00:40:29,270 --> 00:40:35,020
the same people today accept ideas of furnishing design teams of hotel

603
00:40:35,020 --> 00:40:42,230
architecture and of entire tourist industry which sells classically pleasing forms

604
00:40:42,880 --> 00:40:47,960
see the las vegas versions of venetial palazzi ancient roman dining

605
00:40:47,960 --> 00:40:51,090
rooms or moorish architecture

606
00:40:51,460 --> 00:40:58,040
and at the same chose restaurant or hotel ennobled by twentieth century avantgarde

607
00:40:58,130 --> 00:41:04,630
paintings genuine or reproduction that their grandparents would have considered the negation of

608
00:41:04,630 --> 00:41:08,380
the ideals of classical antiquity

609
00:41:08,380 --> 00:41:10,790
the cinema television and magazine

610
00:41:10,960 --> 00:41:18,540
advertising and fashion all propose models of beauty that are not different from the ancient ones

611
00:41:18,860 --> 00:41:20,730
and we could easily

612
00:41:20,750 --> 00:41:28,110
imagine the face of richard gere or nicole kidman portrayed by Renaissance painter

613
00:41:28,480 --> 00:41:36,150
but at the same time people identify with these aesthetic or sexual ideals

614
00:41:36,460 --> 00:41:39,170
also go into raptures

615
00:41:39,250 --> 00:41:45,560
over rock singers whose features would have struck renaissance man as repellent

616
00:41:45,590 --> 00:41:49,580
and the same youngster often make themselves up

617
00:41:49,580 --> 00:41:56,190
tattoo themselves up they tattoo themselves and they pierce their flesh with pins so

618
00:41:56,190 --> 00:42:02,310
they look more like marlyn manson that like marilyn monroe

619
00:42:03,130 --> 00:42:09,900
see a comparison between a contemporary example of piercing and two faces painted

620
00:42:09,920 --> 00:42:14,840
by Hieronymus Bosch

621
00:42:15,750 --> 00:42:18,080
but bosch wanted to portray

622
00:42:18,080 --> 00:42:24,610
the enemies of Christ and so he painted the them as people of these

623
00:42:24,610 --> 00:42:28,190
days conceived as barbarians

624
00:42:28,210 --> 00:42:29,230
or pirates

625
00:42:29,270 --> 00:42:30,020
and that's

626
00:42:30,360 --> 00:42:35,610
let us not forget that as late as the nineteenth century psychiatrists

627
00:42:35,610 --> 00:42:42,190
saw tatoos as a sign of degeneracy

628
00:42:42,250 --> 00:42:49,060
today piercing and tattoos are thought to be a generational challenge at most but they

629
00:42:49,060 --> 00:42:54,860
are certainly not seen by the majority as a criminal choice and a girl with a

630
00:42:54,860 --> 00:43:01,270
tongue stud or a tattooed dragoon on her exposed belly can take part in

631
00:43:01,270 --> 00:43:06,270
in a march for peace or for starving children in Africa

632
00:43:06,810 --> 00:43:11,920
neither the young nor the old seem to find the these contradiction

633
00:43:11,920 --> 00:43:13,920
a dramatic one

634
00:43:13,960 --> 00:43:17,520
the late nineteenth century aesthete

635
00:43:17,590 --> 00:43:20,210
who favoured cadaverous beauty

636
00:43:20,210 --> 00:43:22,940
i wanted to say goodbye

637
00:43:22,940 --> 00:43:24,760
the support spring school

638
00:43:24,780 --> 00:43:32,170
postcondition not put a personality discovery on

639
00:43:32,200 --> 00:43:35,340
got abundances logo yet

640
00:43:35,360 --> 00:43:39,550
which we call a comedy movie comedy show in operation can be just as there

641
00:43:39,550 --> 00:43:44,730
was twenty moment if you know what little but stop when in fact the more

642
00:43:44,730 --> 00:43:50,510
data problem you puzzle making the kitchen could because they don't fit anything product get

643
00:43:50,800 --> 00:43:57,230
in but the the typical took k partition OK so so much easier probably a

644
00:43:57,330 --> 00:44:01,900
little more than about the support of atkinson camomile that's the only among the hyperlink

645
00:44:01,900 --> 00:44:07,480
in the losses they bought tickets to to propose that local mcmullin will put up

646
00:44:07,510 --> 00:44:09,800
the control of course e

647
00:44:09,800 --> 00:44:14,980
that's avoiding there is also a of parts of speech but has been much talk

648
00:44:15,040 --> 00:44:18,020
consolidating means so was made apple designs

649
00:44:18,980 --> 00:44:20,620
look call

650
00:44:20,760 --> 00:44:22,410
OK well

651
00:44:22,440 --> 00:44:25,240
similar internet not just like in was the

652
00:44:25,270 --> 00:44:31,050
before on the route request because the company mawkish now so probably polyester class get

653
00:44:31,600 --> 00:44:36,930
caught up in the midst of all so interacting in kind as kind of there

654
00:44:36,930 --> 00:44:39,040
is year

655
00:44:39,130 --> 00:44:45,520
so anxious was the most effective committee available a team of tallest building in one

656
00:44:46,240 --> 00:44:48,210
the end

657
00:44:49,350 --> 00:44:55,100
but upon arrival as a collection of because of school there was something strange in

658
00:44:55,100 --> 00:44:59,430
constable constable my passion for each percussionist within mostly

659
00:44:59,540 --> 00:45:03,020
lockwood one listener asking with the leader in quaking because now we delete all of

660
00:45:03,240 --> 00:45:07,880
which are more common within its academic motherboards within that i look at the time

661
00:45:07,880 --> 00:45:10,070
interval that could kind of course the problem

662
00:45:10,100 --> 00:45:13,460
is a

663
00:45:13,480 --> 00:45:16,800
it's about grammar monocyte because of me

664
00:45:16,820 --> 00:45:19,910
also connection on is always uses the challenge the

665
00:45:19,930 --> 00:45:25,290
but could do she the in those sorts stories of people because of course it

666
00:45:25,290 --> 00:45:31,400
is a graph in the next step is so much in my more portuguese solid

667
00:45:31,490 --> 00:45:35,520
performers are made in the image which can be so they that activity outdoor was

668
00:45:35,520 --> 00:45:39,550
not called up for the energy and in

669
00:45:39,560 --> 00:45:45,900
this so so it's is crucial for documents output input is a specialized studios in

670
00:45:45,900 --> 00:45:52,330
graph cutci problems in this essay the support of other parties lmage new major supposedly

671
00:45:52,860 --> 00:45:57,830
second look on cell behavioral as they book can while my one

672
00:45:57,840 --> 00:46:03,300
right because the title of catch you put them on the wild bunch

673
00:46:03,310 --> 00:46:09,120
model which only on can also the manual approach in a big question is nominally

674
00:46:09,120 --> 00:46:14,220
set of topics those mankind in the yugoslavia

675
00:46:14,270 --> 00:46:18,890
the fictional brush on his about justice promoting or the oil city and you will

676
00:46:18,890 --> 00:46:24,200
see LC but because satanic only just about the same time to try forge cult

677
00:46:24,200 --> 00:46:26,150
by guy says goodbye

678
00:46:26,180 --> 00:46:31,060
i will make you organize oxygen in and it mark nemo was the bigger cox

679
00:46:31,060 --> 00:46:36,800
you what they organise serious problem and it's impossible to accomplish on the pressure on

680
00:46:37,020 --> 00:46:42,330
a maximum of public by your nobody it by simple legend of believe that there

681
00:46:42,430 --> 00:46:45,930
they a cintron sometimes which logical sort

682
00:46:46,700 --> 00:46:54,200
socialist which

683
00:46:54,390 --> 00:46:58,550
we can use

684
00:47:00,120 --> 00:47:03,090
should should

685
00:47:04,090 --> 00:47:05,720
OK so

686
00:47:06,470 --> 00:47:13,500
and OK now so this is the sort of the questions that that were used

687
00:47:13,500 --> 00:47:17,150
to ask what we can ask for smaller networks what is for for example more

688
00:47:17,150 --> 00:47:21,210
more interesting ask for bigger parties like how many nodes going to remove from the

689
00:47:21,210 --> 00:47:26,110
network so the network like can be separated into two pieces or something like that

690
00:47:26,340 --> 00:47:30,110
right so would be like a different type of questions that starts to make to

691
00:47:30,110 --> 00:47:34,210
make sense and you have a much larger network right and what we want to

692
00:47:34,210 --> 00:47:38,560
do now is basically want to develop some kind of statistical tools and statistical methods

693
00:47:38,560 --> 00:47:41,420
to study these big network site

694
00:47:41,450 --> 00:47:45,810
and the whole problem comes from the fact that we can not the kind of

695
00:47:45,810 --> 00:47:48,330
draw these things right and

696
00:47:48,380 --> 00:47:52,650
what there are basically three two three two three goals we have first this can

697
00:47:52,650 --> 00:47:59,040
be can be find analyse quantified is a statistical properties of large networks can be

698
00:47:59,040 --> 00:48:00,710
modeled can be like

699
00:48:00,760 --> 00:48:05,140
can find simple generative models that would be able to generate this type of properties

700
00:48:05,140 --> 00:48:06,020
and then

701
00:48:06,030 --> 00:48:09,960
even the models then the next step is to predict what will happen and things

702
00:48:09,960 --> 00:48:11,150
like that

703
00:48:11,200 --> 00:48:14,880
and so here is the outline of the rest of the talk

704
00:48:17,280 --> 00:48:21,940
i've spent some time now into using these properties of real world networks that i

705
00:48:21,940 --> 00:48:25,840
want to talk about kronecker graphs show

706
00:48:25,850 --> 00:48:27,450
some properties of them

707
00:48:27,920 --> 00:48:33,270
and then present how to feed them in real graphs and present experimental results

708
00:48:33,320 --> 00:48:37,010
OK so for example here is a list of

709
00:48:37,160 --> 00:48:41,150
properties that can be fired funding

710
00:48:41,160 --> 00:48:43,880
the real world networks and so for example the first one is like a small

711
00:48:43,880 --> 00:48:47,720
small world effect they call it so it means that the diameter of the network

712
00:48:47,730 --> 00:48:51,790
is very small even if the network itself is very large so i'll explain about

713
00:48:51,790 --> 00:48:57,270
it's more like the other the other properties like the transitivity or clustering which in

714
00:48:57,270 --> 00:49:02,040
social networks means that if i have two friends that probably different friends themselves also

715
00:49:02,280 --> 00:49:05,590
of this we like create triangle i have a friend here come from here and

716
00:49:05,590 --> 00:49:10,020
then there are also friends of this this this is called sensitivity of testing then

717
00:49:10,020 --> 00:49:13,950
a different statistical process

718
00:49:13,960 --> 00:49:18,170
let's take a closer look by considering samples

719
00:49:18,180 --> 00:49:23,160
this is the case of mister hadlum versus missus hadlum which was discussed by barnett

720
00:49:24,000 --> 00:49:29,800
very interesting paper on of section was was point so yeah the birth of a

721
00:49:29,800 --> 00:49:31,130
child to missus hadlum

722
00:49:31,140 --> 00:49:38,150
happened strangely three hundred forty nine days after mister hadlum left military service

723
00:49:38,200 --> 00:49:43,150
and if you consider that the average human is a station period is about forty

724
00:49:43,150 --> 00:49:45,780
weeks o two hundred eighty days

725
00:49:45,800 --> 00:49:47,740
mister hadlum has

726
00:49:47,750 --> 00:49:49,490
obviously some

727
00:49:49,680 --> 00:49:58,140
that feelings with this and of course i thought that this baby is not

728
00:49:59,670 --> 00:50:04,900
and the court has to decide if it's possible or not

729
00:50:04,920 --> 00:50:07,280
and interestingly the

730
00:50:07,300 --> 00:50:11,340
the judges did was they asked doctors is it possible

731
00:50:11,390 --> 00:50:13,570
from at some point of view is possible

732
00:50:13,570 --> 00:50:17,180
that this baby is most of the baby

733
00:50:17,230 --> 00:50:19,960
and the doctor said theoretically

734
00:50:20,010 --> 00:50:21,150
it could happen

735
00:50:21,940 --> 00:50:27,710
what the judges did was to reject mister hadlum objective

736
00:50:28,010 --> 00:50:30,320
barnett in seventy eight

737
00:50:30,340 --> 00:50:32,810
so thirty years ago thirty years later

738
00:50:32,840 --> 00:50:35,550
pick that up and

739
00:50:35,570 --> 00:50:39,570
analyse this by some statistics what we did was

740
00:50:39,570 --> 00:50:41,380
just to

741
00:50:41,390 --> 00:50:42,990
take some

742
00:50:43,010 --> 00:50:49,650
three thirty thousand thirteen so something sorry observations of

743
00:50:49,680 --> 00:50:51,310
the station periods

744
00:50:51,320 --> 00:50:54,830
the station periods are plotted here by histogram

745
00:50:54,860 --> 00:50:56,490
and you see that this is

746
00:50:56,500 --> 00:51:01,640
this follows quite nicely gaussian distribution around

747
00:51:02,080 --> 00:51:05,190
the normal meaning of forty weeks

748
00:51:05,960 --> 00:51:12,300
in the case of helen was elements fifty weeks so from statistical sense statistical point

749
00:51:12,300 --> 00:51:15,880
of view this is clearly an outlier but as i said the doctor said

750
00:51:15,990 --> 00:51:18,170
it's theoretically possible so

751
00:51:18,210 --> 00:51:20,670
we cannot

752
00:51:20,690 --> 00:51:22,030
make a difference so

753
00:51:22,590 --> 00:51:27,140
taking a closer look to put it in the in the direction of

754
00:51:27,150 --> 00:51:32,440
hawkins definition what do we have here so we have the statistical basis of

755
00:51:32,450 --> 00:51:36,550
thirteen thousand observations of the station areas

756
00:51:36,570 --> 00:51:37,710
in blue

757
00:51:38,590 --> 00:51:40,500
histogram and green

758
00:51:40,560 --> 00:51:43,880
is caution distribution fitted to the histogram

759
00:51:43,890 --> 00:51:45,510
so this is the

760
00:51:45,530 --> 00:51:49,380
the underlying process the generating mechanism

761
00:51:49,390 --> 00:51:51,260
and you see it

762
00:51:51,270 --> 00:51:53,010
with the very low probability

763
00:51:53,030 --> 00:51:55,170
for the birth of mister missus hadlum

764
00:51:55,190 --> 00:51:57,750
helen strands child for being

765
00:51:57,800 --> 00:52:01,140
generated by this mechanism or in other words to be

766
00:52:01,190 --> 00:52:03,920
produced by mister mister

767
00:52:03,930 --> 00:52:06,740
and in rats this is the assumption of mister hadlum

768
00:52:06,780 --> 00:52:10,580
what was the assumption of him he said that then

769
00:52:15,130 --> 00:52:17,650
what's trending generated by this mechanism

770
00:52:17,740 --> 00:52:18,950
which means that

771
00:52:19,030 --> 00:52:22,460
in this case if you if you have this mechanism here

772
00:52:22,490 --> 00:52:28,830
different from this mechanism here is is however a very high probability

773
00:52:28,880 --> 00:52:31,270
of this gas station

774
00:52:31,940 --> 00:52:34,230
what once again we have

775
00:52:34,250 --> 00:52:38,430
what concerns one generating mechanism

776
00:52:38,440 --> 00:52:41,530
modelled here by gaussian distribution in green

777
00:52:41,580 --> 00:52:44,240
and the old was

778
00:52:44,250 --> 00:52:46,440
produced by a different mechanism

779
00:52:46,440 --> 00:52:50,930
in this case around the right questions to

780
00:52:52,580 --> 00:52:55,940
obviously nowadays there are

781
00:52:55,950 --> 00:52:57,300
better ways to

782
00:52:58,340 --> 00:53:01,190
if one is the father of the child or not

783
00:53:01,200 --> 00:53:06,240
not only have limitations but genetic tests of course so all the other applications for

784
00:53:06,240 --> 00:53:10,150
the detection of course there are so many

785
00:53:10,330 --> 00:53:13,920
applications for text just to name a few

786
00:53:13,930 --> 00:53:21,320
so fraud detection for example you can before you try to detect credit card abuse

787
00:53:21,400 --> 00:53:24,250
by looking at the at the

788
00:53:24,270 --> 00:53:27,310
purchasing behavior of users

789
00:53:27,340 --> 00:53:29,240
in medicine for example

790
00:53:29,250 --> 00:53:34,870
you could have unusual symptoms test results that may indicate some

791
00:53:34,880 --> 00:53:37,270
diseases potential problems whatever

792
00:53:37,330 --> 00:53:42,200
in this case it's interesting that not only the measurement itself the nominal value of

793
00:53:42,200 --> 00:53:43,600
the measurement itself

794
00:53:43,610 --> 00:53:48,770
it is important to decide if it's another model is

795
00:53:48,790 --> 00:53:52,110
the potential health problem or not but also other

796
00:53:52,120 --> 00:53:55,520
the features of the patient for example gender age or whatever

797
00:53:55,580 --> 00:53:57,970
could be interesting so

798
00:53:58,010 --> 00:54:00,360
you have to be more than one

799
00:54:00,380 --> 00:54:05,960
variable more than one attribute for objectification of one

800
00:54:05,970 --> 00:54:11,830
public health is also very common application for example the occurrence of a particular disease

801
00:54:11,880 --> 00:54:14,450
scattered across various hospitals of city

802
00:54:14,470 --> 00:54:19,330
may indicate some problems corresponding nation program

803
00:54:19,340 --> 00:54:21,220
again here

804
00:54:22,560 --> 00:54:25,170
usually have to consider spatially

805
00:54:25,200 --> 00:54:26,680
frequency correlations

806
00:54:26,710 --> 00:54:29,490
not only the measurement itself but also other

807
00:54:29,510 --> 00:54:36,170
features are important to decide whether another is really on outliers is really signal

808
00:54:36,180 --> 00:54:37,830
sports statistics

809
00:54:40,650 --> 00:54:45,250
very familiar with that so many sports was various parameters are measured

810
00:54:45,290 --> 00:54:47,950
four players and you can relate

811
00:54:48,000 --> 00:54:52,600
performances as outstanding positive and negative sense of course

812
00:54:54,960 --> 00:55:00,270
in this case sometimes players should show only only exceptional views

813
00:55:00,310 --> 00:55:03,400
the negative sense only a subset of

814
00:55:03,410 --> 00:55:09,210
four of those combinations of is not all parameters not all

815
00:55:09,250 --> 00:55:10,410
values are

816
00:55:10,450 --> 00:55:12,270
important here

817
00:55:12,330 --> 00:55:17,520
another very important for application of that section is a measurement error detection

818
00:55:18,510 --> 00:55:24,480
for example in sensor data usually have a lot of measurement errors

819
00:55:24,490 --> 00:55:28,890
and here in the case of the detection could

820
00:55:28,920 --> 00:55:30,840
indicate measurement error so

821
00:55:30,850 --> 00:55:34,520
you can remove for example measurement so you can

822
00:55:34,580 --> 00:55:36,350
make something out of it whatever

823
00:55:37,330 --> 00:55:41,390
special treatment on on the these measurements

824
00:55:41,460 --> 00:55:45,630
but this is something like two sides of male because

825
00:55:45,760 --> 00:55:50,670
yeah this is a very famous statement one person's noise could be another one was

826
00:55:50,680 --> 00:55:52,050
the signal that means

827
00:55:52,100 --> 00:55:57,260
if you detect an outlier and say this noise another person could say no no

828
00:55:57,270 --> 00:56:00,960
it's not nice this is a clear signal for this is

829
00:56:00,970 --> 00:56:02,880
knowledge which i want to know

830
00:56:03,000 --> 00:56:04,990
remove it or whatever so

831
00:56:05,250 --> 00:56:07,290
now the sections quite quite

832
00:56:07,310 --> 00:56:10,670
subject is not really object

833
00:56:10,700 --> 00:56:15,430
and it heavily depends on the application domains and applications

834
00:56:15,460 --> 00:56:16,280
if the

835
00:56:17,560 --> 00:56:22,760
signal detected outliers are really interesting and

836
00:56:23,720 --> 00:56:29,130
coming back to the basic inclusion of hawkins in light of these applications

837
00:56:29,180 --> 00:56:34,600
then we have to see that data is usually multidimensional so you have a lot

838
00:56:34,600 --> 00:56:36,110
of measures are

839
00:56:36,130 --> 00:56:38,240
object point

840
00:56:38,250 --> 00:56:42,550
and if you recall in in the basic model you just have a one-dimensional

841
00:56:42,610 --> 00:56:44,010
dataset so

842
00:56:44,020 --> 00:56:47,100
the case of helen was you just measure the

843
00:56:47,140 --> 00:56:49,010
the length of the station period

844
00:56:49,020 --> 00:56:51,630
just one measure for each

845
00:56:53,010 --> 00:56:57,880
and but usually is not the case usually multivariate

846
00:56:59,720 --> 00:57:08,700
usually you of the basic intuition also assumes that you have just one normal

847
00:57:08,710 --> 00:57:14,360
generating process so in this case only the green processes process that

848
00:57:14,380 --> 00:57:15,670
generates the normal

849
00:57:15,680 --> 00:57:17,010
objects normally

850
00:57:17,010 --> 00:57:18,570
that can be understood

851
00:57:18,590 --> 00:57:21,760
through a series of models that have not had time to present to you with

852
00:57:21,760 --> 00:57:23,090
a a large body of

853
00:57:23,130 --> 00:57:26,650
a theoretical work that developing trying to try to put this

854
00:57:26,650 --> 00:57:28,430
mechanism to work

855
00:57:28,490 --> 00:57:30,340
and that we need to blocked

856
00:57:30,360 --> 00:57:31,530
and we think

857
00:57:31,610 --> 00:57:33,800
are partly developed novel metrics

858
00:57:33,800 --> 00:57:35,970
to monitor the development of arts

859
00:57:36,010 --> 00:57:41,010
one thing i'm not at all discussed is extremely important that not the same in

860
00:57:42,030 --> 00:57:46,630
either of us are more as which i think it we discuss privately between us

861
00:57:46,650 --> 00:57:47,610
the core

862
00:57:47,630 --> 00:57:50,920
of the fundamental systemic instability of the french market

863
00:57:50,990 --> 00:57:53,530
let me finish with two predictions

864
00:57:53,610 --> 00:57:55,780
illustrating the methodology

865
00:57:55,800 --> 00:58:00,900
one was a prediction that we actually

866
00:58:00,920 --> 00:58:05,900
published actually it was communicated to hedge-fund conference in stockholm

867
00:58:05,920 --> 00:58:10,490
in early september i was invited to be the kind speaker two and a lot

868
00:58:10,510 --> 00:58:14,090
of hits from managers the better manage in the world

869
00:58:14,170 --> 00:58:18,240
i said to myself should to present something that would excite the interest

870
00:58:18,260 --> 00:58:20,200
so we did study and we

871
00:58:20,240 --> 00:58:24,670
by looking at the super exponential exeter and of the

872
00:58:24,700 --> 00:58:26,900
chinese means the market

873
00:58:26,920 --> 00:58:33,280
we identified that by the turn of two thousand and two thousand six seven seven

874
00:58:33,360 --> 00:58:35,090
two thousand eight

875
00:58:35,090 --> 00:58:39,860
so i refuse generative because it we should have a big collection

876
00:58:39,880 --> 00:58:43,090
we should have actually changing channel regime

877
00:58:43,090 --> 00:58:47,720
one i presented this prediction to this panel of experts who

878
00:58:47,720 --> 00:58:51,670
where there exists a successful investors the autonomy

879
00:58:52,990 --> 00:58:54,380
you are wrong

880
00:58:54,400 --> 00:58:55,740
it's impossible

881
00:58:56,670 --> 00:59:02,150
the chinese market does not continue for trajectory

882
00:59:02,170 --> 00:59:05,780
on until after the olympic games

883
00:59:05,800 --> 00:59:10,150
impossible that's was one hundred person convention

884
00:59:10,200 --> 00:59:15,070
happily for me crap and i believe because it my prediction was actually incorrect in

885
00:59:15,070 --> 00:59:18,030
the exact timing the crash occurred in the

886
00:59:18,090 --> 00:59:22,030
you might remember it twenty percent drop and then subsequently i mean

887
00:59:22,170 --> 00:59:26,110
if you have invested in china china united so such which

888
00:59:26,130 --> 00:59:30,670
because the market has going going down continuously with very severe

889
00:59:30,740 --> 00:59:35,900
this is an example where show that the exact timing very precise it was indeed

890
00:59:35,930 --> 00:59:37,220
stochastic event

891
00:59:37,220 --> 00:59:38,320
but there are

892
00:59:39,430 --> 00:59:40,420
but we can do

893
00:59:41,700 --> 00:59:47,720
first above second have some idea of the time spent remain some idea not exactly

894
00:59:48,820 --> 00:59:53,720
there's a lot of serie that can rationalize why it is of course of stochastic

895
00:59:53,740 --> 00:59:56,510
morrison prediction i would finish with this one

896
00:59:56,530 --> 00:59:58,700
wars it's a big debate

897
00:59:58,720 --> 01:00:02,090
all right OK or price the question is

898
01:00:02,110 --> 01:00:05,950
why all has gone from thirty

899
01:00:05,970 --> 01:00:12,090
below a barrel in two thousand six to grows to one hundred fifty dollars a

900
01:00:13,090 --> 01:00:15,420
just a few months ago with the peak

901
01:00:17,450 --> 01:00:19,200
big debate

902
01:00:19,220 --> 01:00:22,200
paul krugman my best adversary

903
01:00:22,650 --> 01:00:28,720
his famous economist you know writing in new york's time very famous economist was adamant

904
01:00:28,720 --> 01:00:31,700
that there was absolutely no global no speculation

905
01:00:32,090 --> 01:00:34,280
towards pure and simple

906
01:00:36,050 --> 01:00:38,780
supplied very interesting

907
01:00:38,780 --> 01:00:43,980
how rationalisation my mind comes about when you see the data and and real real

908
01:00:43,980 --> 01:00:47,050
options stories for the new into the technology was

909
01:00:47,090 --> 01:00:48,030
to the full

910
01:00:48,030 --> 01:00:52,700
so what we did with data analysis and summarizing about what if analysis because

911
01:00:52,700 --> 01:00:59,200
here i felt quite an adventurous water to stick my neck out with this very

912
01:00:59,200 --> 01:01:03,380
important issues but nevertheless we should actually in may

913
01:01:04,880 --> 01:01:09,400
showing that first yes we believe there is a degree of speculation with a superbly

914
01:01:09,420 --> 01:01:12,550
component in their position of the order of

915
01:01:12,610 --> 01:01:14,610
secondly this is not sustainable

916
01:01:14,630 --> 01:01:16,570
the peak is going to be rich

917
01:01:17,530 --> 01:01:20,610
and of two in july

918
01:01:20,610 --> 01:01:22,690
OK so that he once again

919
01:01:22,700 --> 01:01:27,570
so these should again that we have a degree of predictability of the

920
01:01:28,300 --> 01:01:29,590
my main message

921
01:01:29,590 --> 01:01:32,190
are those that try to tell you about

922
01:01:32,190 --> 01:01:36,560
for some reason may be typing you as humans we look at this and we

923
01:01:36,560 --> 01:01:40,810
even if we don't know the answer the question we know that's not the answer

924
01:01:40,910 --> 01:01:46,830
so we're calling that stupid but what's what i'm starting to think of is maybe

925
01:01:46,830 --> 01:01:48,910
we need to change are

926
01:01:48,920 --> 01:01:53,210
our notions because you know there are some tasks that at least those of us

927
01:01:53,210 --> 01:01:55,910
in the AI community are very familiar with

928
01:01:55,960 --> 01:01:59,680
they are considered a i complete these are the problems that in order to have

929
01:01:59,680 --> 01:02:05,460
a comprehensive solution to requires an AI and we don't have it we don't know

930
01:02:05,460 --> 01:02:11,040
how to build nobody really has any ideas except that you know mluleki in

931
01:02:11,080 --> 01:02:13,310
occurs while

932
01:02:13,410 --> 01:02:15,830
i think they know how this is how it's going to happen but it hasn't

933
01:02:15,830 --> 01:02:18,620
happened yet so these are some problems that

934
01:02:18,710 --> 01:02:22,620
you know the machine vision problem it's the kind of thing speech natural these are

935
01:02:22,620 --> 01:02:28,230
problems that humans don't think to solve you know we just solve

936
01:02:28,270 --> 01:02:31,100
if you look at the picture and you see what's in it

937
01:02:31,140 --> 01:02:38,810
there's no processing is no computational complexity somehow just works

938
01:02:38,910 --> 01:02:43,190
but there are problems that we are terrible at and that if computers could talk

939
01:02:43,190 --> 01:02:44,290
they probably say

940
01:02:44,440 --> 01:02:49,330
you forgot your appointment was at twelve o'clock what's the matter with you don't you

941
01:02:49,330 --> 01:02:51,140
have a clock

942
01:02:51,140 --> 01:02:55,770
computers and so that you

943
01:02:55,890 --> 01:02:58,480
have the tortious voice in mind

944
01:02:58,520 --> 01:03:01,980
telling me when i miss my appointment

945
01:03:02,540 --> 01:03:05,460
so there are a whole bunch of things that

946
01:03:05,460 --> 01:03:06,120
you know

947
01:03:06,210 --> 01:03:09,640
computational systems are really good at

948
01:03:09,690 --> 01:03:13,790
maybe we need to change our notion of what stupid

949
01:03:13,810 --> 01:03:17,910
and what's intelligent

950
01:03:17,920 --> 01:03:22,350
and i think that in collaborate you know the kind of collaboration that now seems

951
01:03:22,350 --> 01:03:23,980
to happen on the web

952
01:03:23,980 --> 01:03:27,660
so this is the story of captures if you have haven't heard of the captures

953
01:03:27,660 --> 01:03:28,390
of these

954
01:03:28,520 --> 01:03:30,440
again these images that you have to

955
01:03:30,500 --> 01:03:34,460
type in what letters are skewed by some photoshop effect and you have to type

956
01:03:35,060 --> 01:03:38,790
the letters in there and you know it was used as a way to prevent

957
01:03:38,790 --> 01:03:42,350
spambots from getting free email accounts that was the initial

958
01:03:42,870 --> 01:03:44,290
use case for them

959
01:03:44,290 --> 01:03:48,020
and about a year i think after they were developed

960
01:03:49,770 --> 01:03:52,330
there is somebody broke

961
01:03:52,390 --> 01:03:56,310
and the guys who develop the capture storage oh my god you know spammers solve

962
01:03:56,310 --> 01:04:00,540
the machine vision problem you know they built systems that are reading the the the

963
01:04:00,540 --> 01:04:05,290
characters in these skewed images and what it turned out was really happening was that

964
01:04:05,290 --> 01:04:10,770
porn sites were downloading the the big if images of the capture

965
01:04:10,810 --> 01:04:15,000
and popping up onto the screen of somebody that was browsing the pawnshop site at

966
01:04:15,000 --> 01:04:17,710
that time and say hey you want to see more free-form what does this say

967
01:04:18,460 --> 01:04:20,940
and then they would take the answer and send it back and fill out the

968
01:04:20,940 --> 01:04:25,870
form and they had enough people browsing the web site that they can get like

969
01:04:25,870 --> 01:04:31,600
a thousand free meals in minutes or an hour whatever the rate

970
01:04:31,620 --> 01:04:38,480
that's great just fantastic if only we could find more appropriate ways to motivate people

971
01:04:39,890 --> 01:04:41,230
to do work

972
01:04:41,250 --> 01:04:43,660
or maybe not enough

973
01:04:45,410 --> 01:04:47,250
what makes the problems

974
01:04:48,370 --> 01:04:53,210
to solve that were possible for this combination of

975
01:04:53,270 --> 01:04:57,000
you know entities that can solve the left column and entities that can solve the

976
01:04:57,000 --> 01:04:59,810
right problem and put them together

977
01:04:59,830 --> 01:05:02,270
so that's what i wanted to

978
01:05:02,270 --> 01:05:06,030
and then you have this what i call what people call heavy tails that means

979
01:05:06,370 --> 01:05:10,810
you have what it is not really visible on this image but it means that

980
01:05:10,810 --> 01:05:13,240
the pdf will be relatively large

981
01:05:13,260 --> 01:05:18,290
very far from zero so you will have seen much

982
01:05:18,300 --> 01:05:23,580
a larger probability of having the larger values nanoparticles in this section

983
01:05:23,580 --> 01:05:24,800
the first is

984
01:05:24,830 --> 01:05:27,590
really nothing different than what

985
01:05:27,640 --> 01:05:29,780
i call super gaussianity

986
01:05:31,950 --> 01:05:34,930
forty slides

987
01:05:34,940 --> 01:05:38,420
thirty five slides ago

988
01:05:39,800 --> 01:05:45,420
in other words it is this kind of behavior is typical of distributions that have

989
01:05:45,420 --> 01:05:48,000
a strongly positive

990
01:05:48,020 --> 01:05:53,380
so from the point of statistical modeling we see that sparseness is really the same

991
01:05:53,380 --> 01:05:58,600
thing as super gaussianity well it's not just because it is also the property that

992
01:05:58,630 --> 01:06:05,020
the distributions are well in the in the basic case distributions are symmetric with respect

993
01:06:05,030 --> 01:06:13,140
to zero and then you see strongly about

994
01:06:16,060 --> 01:06:19,370
if we formulate linear sparse coding

995
01:06:19,370 --> 01:06:23,870
so that we want to find this representation that we have seen a hundred times

996
01:06:24,650 --> 01:06:29,470
and we want to find we want to determine this mixing matrix of the basis

997
01:06:29,470 --> 01:06:36,020
vectors a so that the components is i as fast as possible

998
01:06:36,050 --> 01:06:40,090
now if we do this we will see that well this is

999
01:06:40,090 --> 01:06:45,400
this is just the same as in all of this thing in your model is

1000
01:06:45,400 --> 01:06:46,880
just the same as with ICA

1001
01:06:47,370 --> 01:06:49,020
and when we say that

1002
01:06:49,040 --> 01:06:53,300
the components must be as sparse as possible while it's the same thing as saying

1003
01:06:53,300 --> 01:06:57,410
that they must be as well it's almost the same thing as saying that there

1004
01:06:57,410 --> 01:06:59,970
must be as non gaussian as possible so we see

1005
01:07:01,380 --> 01:07:06,310
finding a linear sparse called maximally sparse code is just the same thing as doing

1006
01:07:11,390 --> 01:07:13,790
with one reservation

1007
01:07:13,810 --> 01:07:19,560
well if you think about maximisation nongaussianity as maximisation of the absolute value of kurtosis

1008
01:07:20,030 --> 01:07:25,000
then if all the kurtosis are positive then of course the maximisation of of kurtosis

1009
01:07:25,000 --> 01:07:30,610
is the same thing as maximizing some of us so that it is so if

1010
01:07:30,950 --> 01:07:36,460
the maximum everything of maximisation of nongaussianity as maximisation of the the absolute value ten

1011
01:07:38,900 --> 01:07:44,170
if the kurtosis always positive then of course the maximisation of the absolute value is

1012
01:07:44,170 --> 01:07:50,100
the same as maximisation of those itself so in that case maximisation of sparseness is

1013
01:07:50,100 --> 01:07:52,870
the same thing as maximisation of nongaussianity

1014
01:07:52,880 --> 01:07:57,270
of course it might happen that if you have that you have distributions which are

1015
01:07:57,270 --> 01:08:03,970
negative kurtosis and in that case maximisation nongaussianity will be just the opposite as maximisation

1016
01:08:03,970 --> 01:08:09,240
of fast but that is not what usually happens in images you always have distributions

1017
01:08:09,240 --> 01:08:12,020
which have positive kurtosis and therefore

1018
01:08:12,040 --> 01:08:19,600
maximisation sparseness is the same as maximisation of number ten

1019
01:08:19,660 --> 01:08:21,120
OK but

1020
01:08:21,140 --> 01:08:24,400
sparse coding is not just ICA has one

1021
01:08:24,420 --> 01:08:32,170
it has an extremely extremely important interpretation which was actually the motivation for sparse coding

1022
01:08:32,170 --> 01:08:35,730
in in vision modelling in the first place

1023
01:08:35,760 --> 01:08:36,700
which is that

1024
01:08:36,990 --> 01:08:39,200
now when you

1025
01:08:39,240 --> 01:08:41,080
it takes one input points

1026
01:08:41,080 --> 01:08:46,390
and it's a neural representation the ENS is four

1027
01:08:46,410 --> 01:08:47,760
for that particular

1028
01:08:47,860 --> 01:08:49,290
a data point

1029
01:08:49,380 --> 01:08:52,020
then because the distributions of s

1030
01:08:52,040 --> 01:08:55,260
as such that they are usually very close to zero

1031
01:08:55,300 --> 01:09:00,900
and only occasionally gets significant values that are significantly different from zero then it follows

1032
01:09:00,900 --> 01:09:04,990
that for any given as most of these days i will be very close to

1033
01:09:04,990 --> 01:09:08,690
zero so what it means that you are basically representing

1034
01:09:08,700 --> 01:09:14,830
each of your data points using only a small number of active components as

1035
01:09:14,870 --> 01:09:20,580
and this is really what sparse coding originally meant so that the the representation for

1036
01:09:21,260 --> 01:09:26,290
for each data point is sparse in the sense of using only a small number

1037
01:09:26,290 --> 01:09:28,260
of active components

1038
01:09:28,270 --> 01:09:32,420
and check the next OK and so

1039
01:09:32,420 --> 01:09:37,310
always open people can just grab it they think you know willows an invading inning

1040
01:09:37,310 --> 01:09:42,520
grabbed the stack and and take over as the the innovator so that forces us

1041
01:09:42,520 --> 01:09:48,020
to keep on running red sold so the the goal willows to foster an industry

1042
01:09:48,020 --> 01:09:56,900
not just the company uh so that we're we're looking at potentially spinning off companies

1043
01:09:56,900 --> 01:10:02,380
in vertical niches you know like maybe whatever you want to picking elderly care but

1044
01:10:02,380 --> 01:10:07,360
not to own the whole industry to really founded industry the reason that wealthy founders

1045
01:10:07,360 --> 01:10:11,960
want this is because they want to see robotics happen before their old adept at

1046
01:10:11,960 --> 01:10:16,600
bid and then so sold the idea is to foster it and build it in

1047
01:10:16,680 --> 01:10:26,880
the article the Foundation a case so far so Ross is that the robot operating

1048
01:10:26,880 --> 01:10:33,600
system is driving this easy recombination we practices by having these Sprint's internally so people

1049
01:10:33,600 --> 01:10:37,180
come up with an idea make the robot play pool and you for 1 week

1050
01:10:37,180 --> 01:10:41,480
1 week you know to make it do that and often these become all those

1051
01:10:41,770 --> 01:10:46,640
on that often the people who were then working on that are the primary process

1052
01:10:46,640 --> 01:10:51,670
so the motor control person might take division role and the vision person might take

1053
01:10:51,680 --> 01:10:59,620
the motor control rolled the ideas can the software support people just rapidly innovative and

1054
01:10:59,690 --> 01:11:08,020
spend that's like this standing on the shoulders of giants that accept notes Geico a

1055
01:11:08,020 --> 01:11:14,640
case of going over a little bit of Ross Ross was a robot operating system

1056
01:11:14,640 --> 01:11:19,680
and it's nothing new this has been reinvented like 20 times Microsoft Robotics Studio is

1057
01:11:19,680 --> 01:11:25,340
similar they're all similar they're basically not quite an OS that's a bit transport system

1058
01:11:25,340 --> 01:11:32,010
so Ross's the man in robotics these had genius distributed systems and the idea is

1059
01:11:32,020 --> 01:11:37,380
to make it easy to work over that and uh so as to what we

1060
01:11:37,380 --> 01:11:45,300
have is slated to cement operating system is basically how to move data around and

1061
01:11:45,530 --> 01:11:50,720
be able to run on multiple platforms across multiple things was appear to that's are

1062
01:11:50,720 --> 01:11:56,380
other product which is teller presence robot the ball from Ross at Alan to agree

1063
01:11:56,380 --> 01:12:00,780
when you're working on the appears to some of it might be running head internal

1064
01:12:00,780 --> 01:12:05,880
to appears to offer and some of its brain is running on your own computer

1065
01:12:05,890 --> 01:12:11,000
or someone else's computer maybe 3 or 4 people's computers they're all running parts of

1066
01:12:11,000 --> 01:12:16,120
its brain and we also have a a cluster that that's starting to run many

1067
01:12:16,120 --> 01:12:20,240
of things and the robot and this is just invisible to use it's trivial to

1068
01:12:20,240 --> 01:12:27,660
run across anyhow also so so what grosses a publish subscribe model is producers and

1069
01:12:27,660 --> 01:12:33,200
consumers that are rise up in the distributed fast and someone might produce saying I

1070
01:12:33,200 --> 01:12:38,520
can produce images and another person might that another node might say I wanna images

1071
01:12:38,530 --> 01:12:43,030
so there's a master know that coordinates that and of images are being produced and

1072
01:12:43,030 --> 01:12:47,960
someone wants of then there's a connection that's established there and then and so there

1073
01:12:47,960 --> 01:12:52,840
is this Ross master that coordinates all that right now it's a single point of

1074
01:12:52,840 --> 01:12:57,080
failure the rest can go up and also offer when you work in the robot

1075
01:12:57,080 --> 01:13:00,510
all the time mode most of the brains of but you're taking apart down and

1076
01:13:00,510 --> 01:13:04,760
up and the rest of its just running because it images go away than the

1077
01:13:04,760 --> 01:13:10,250
things that use images go the rest robot as runs right and messages Golway than

1078
01:13:10,250 --> 01:13:15,380
the things that need those messages go into that no idle loops and then when

1079
01:13:15,380 --> 01:13:22,200
they're instantiated all comes back together that's that's what Ross does of course we're now

1080
01:13:22,200 --> 01:13:27,060
looking at distributing the master had so that multiple robots can work together off of

1081
01:13:27,060 --> 01:13:33,620
multiple masters so this is that it's a message-passing system is a talker and listen

1082
01:13:33,620 --> 01:13:38,800
there there's also things like services so knows that only come alive when you ask

1083
01:13:38,800 --> 01:13:42,720
something of a could be in addition node stages to numbers what are they and

1084
01:13:42,720 --> 01:13:47,000
it'll it'll give you a message back to this to models 1 that's always listening

1085
01:13:47,000 --> 01:13:54,980
and talking and and this service requests than and service replied there's also another action

1086
01:13:54,980 --> 01:13:59,120
model that says that I want you to do something and tell me here tell

1087
01:13:59,120 --> 01:14:03,380
me if you could achieve that goal so like move an arm to certain location

1088
01:14:03,380 --> 01:14:09,210
it might not be able to achieve a full report back then so this is

1089
01:14:09,210 --> 01:14:13,700
there's a talker was there in the right Mastin coordinates them after that they just

1090
01:14:13,700 --> 01:14:22,870
talk amongst themselves like that Saturday Saturday Night Live skit if you know that so

1091
01:14:22,870 --> 01:14:28,830
this everything that is that just going over Ross again it's a BEST model opened

1092
01:14:28,830 --> 01:14:34,160
and easy to use it allows easy distribution not different than a lot of that

1093
01:14:34,180 --> 01:14:37,400
it's of the flavor of many of the things people put together the only difference

1094
01:14:37,400 --> 01:14:43,380
here as it opens commercially or or privately we like BEST because we want drive

1095
01:14:43,380 --> 01:14:46,800
business so we don't wanna have to force you to open you just use it

1096
01:14:46,810 --> 01:14:54,600
we wanna make progress Chen demand Ross is run by these messages that there's a

1097
01:14:54,600 --> 01:14:59,300
lot of details the messages can be expensive the passive here in images something so

1098
01:14:59,300 --> 01:15:03,600
we we have that allow you to work in shared-memory you can declare that this

1099
01:15:03,600 --> 01:15:09,720
message must be the residing on the same machine and and then just pointers are

1100
01:15:09,720 --> 01:15:14,180
passed back and 4 other than that it looks exactly the same as anything else

1101
01:15:14,180 --> 01:15:19,400
so through a few parameters you can get all this behavior although the underlying code

1102
01:15:19,400 --> 01:15:23,740
as the same so it makes it very modular and easy to recombine things and

1103
01:15:23,880 --> 01:15:28,020
this is possibly 1 model of how you can do a plug and play with

1104
01:15:28,020 --> 01:15:34,200
open-source so over a bill this is a complex model but a so that it

1105
01:15:34,300 --> 01:15:39,180
Gross's organizers packages and stacks and trying to make a coherent that Ochoa this effect

1106
01:15:39,180 --> 01:15:45,000
spoken CD but but the stack circle here processing things so there's an object recognition

1107
01:15:45,000 --> 01:15:50,080
stack and there's a arm you know the motion planning stack and then everything there

1108
01:15:50,210 --> 01:15:55,430
sort of coherent and that talks with the same data structures and say messages and

1109
01:15:55,430 --> 01:15:59,120
and this is something and trying to bring an open CD so that it to

1110
01:15:59,120 --> 01:16:05,880
end on the right story these are the existing repositories as of today so there's

1111
01:16:05,880 --> 01:16:10,580
there's know about 20 of them around the world this is independent repositories for people

1112
01:16:10,580 --> 01:16:14,760
running things and there's a master search engine so I've been working in Ross and

1113
01:16:14,760 --> 01:16:18,880
then we don't use fire wire campus where we are because turns up their fleet

1114
01:16:18,880 --> 01:16:25,020
you need the fire watch able slated for distributing the data it when it flexes

1115
01:16:25,020 --> 01:16:28,780
and whatever they can the break so but I think I had a our Khamenei

1116
01:16:28,780 --> 01:16:33,640
after I need to use it's not just the driver but actually and that that

1117
01:16:33,640 --> 01:16:36,820
puts time stamps in all kinds of stuff on and so I just go on

1118
01:16:36,820 --> 01:16:42,260
the Ross repository searched someone and Pittsburgh or something had written this note I just

1119
01:16:42,260 --> 01:16:46,950
pulled and since all repositories always build themselves all the time you know it just

1120
01:16:46,950 --> 01:16:50,700
works so that I pull the code builds its working as a node I'm often

1121
01:16:50,700 --> 01:16:56,220
running you know that's the the positive side of this it's just you know easy

1122
01:16:56,220 --> 01:17:04,020
to share recombined parts of different stacks the other worked so that's the dismiss as

1123
01:17:04,060 --> 01:17:08,000
you know this is somewhat a model for a perhaps finer grain like I needed

1124
01:17:08,000 --> 01:17:12,100
that particular driver to work with a particular thing a search of the world I

1125
01:17:12,100 --> 01:17:18,800
got it added pulling their repository just that just a one-note okay so moving on

1126
01:17:18,800 --> 01:17:21,200
look like from these two partitions

1127
01:17:21,210 --> 01:17:25,260
now the problem is is that in practice we don't have that much training data

1128
01:17:25,310 --> 01:17:27,280
so what's actually going to happen is

1129
01:17:27,300 --> 01:17:32,610
when we use history and fit medians to each cell in the corresponding partition we

1130
01:17:32,610 --> 01:17:36,540
get estimates that look like this and you see movies here and these are cycling

1131
01:17:36,540 --> 01:17:39,460
over different realizations of training i think they are

1132
01:17:39,460 --> 01:17:42,230
a few hundred training points in this example

1133
01:17:42,280 --> 01:17:46,860
and what you see is that the the crude estimate at the top there very

1134
01:17:46,870 --> 01:17:47,800
a little bit

1135
01:17:47,840 --> 01:17:51,480
based on the training data every once in a while certain block turns white or

1136
01:17:52,320 --> 01:17:53,720
but the more

1137
01:17:53,770 --> 01:17:58,700
detailed partition the finer partition has a lot more variability associated with it because we

1138
01:17:58,700 --> 01:18:00,730
have some very small cells there

1139
01:18:00,740 --> 01:18:04,550
and there's not so much data and they are so different realizations of training data

1140
01:18:04,560 --> 01:18:07,810
might give you a very different majority votes in those tiny little cells and you

1141
01:18:07,810 --> 01:18:10,540
can see all the fluctuations caused by

1142
01:18:10,550 --> 01:18:15,130
this is really what we mean when we talk about overfitting it's this variability associated

1143
01:18:15,130 --> 01:18:16,780
with giving your model

1144
01:18:16,860 --> 01:18:20,590
more degrees of freedom then you really have the right to use because you don't

1145
01:18:20,590 --> 01:18:26,460
have enough data to support accurately estimating all those three three parameters in the model

1146
01:18:26,460 --> 01:18:31,190
so this is this is a picture and idea clear

1147
01:18:33,420 --> 01:18:37,230
so this is just the same picture again but a lot of time especially in

1148
01:18:37,230 --> 01:18:40,210
regression problems is called the bias variance trade

1149
01:18:40,260 --> 01:18:44,040
and we might say that here with the coarse partition we have a low bias

1150
01:18:45,250 --> 01:18:49,530
so rather large bias being a poor approximation

1151
01:18:49,540 --> 01:18:53,800
with the finer partition we have smaller bias meaning better approximation

1152
01:18:53,820 --> 01:18:58,270
but at the same time the course partition gives lower variance

1153
01:18:58,310 --> 01:19:04,180
and find partition gives higher variance so it's not clear which of these two partitions

1154
01:19:04,210 --> 01:19:07,720
entries would be better in this type of problem do we want to go with

1155
01:19:07,720 --> 01:19:10,690
that kind of crude approximation but very stable

1156
01:19:10,740 --> 01:19:14,560
or do we want to go with the good approximation but very variable depending on

1157
01:19:14,560 --> 01:19:17,550
the outcome of the training data we happen to see

1158
01:19:17,570 --> 01:19:21,770
and so you have to strike a balance between these two issues we can have

1159
01:19:21,770 --> 01:19:28,090
a better approximation but more variability or poor approximation and more stability

1160
01:19:29,070 --> 01:19:33,740
to be a little bit more careful about describing is i'm going to

1161
01:19:33,740 --> 01:19:37,240
refer to the various estimation are sometimes

1162
01:19:37,250 --> 01:19:40,030
and the biases approximation error

1163
01:19:40,040 --> 01:19:42,810
and to give you an idea of what's going on with such as had t

1164
01:19:42,810 --> 01:19:45,380
denote the classification or regression

1165
01:19:45,400 --> 01:19:47,590
rules associated with the treaty

1166
01:19:47,600 --> 01:19:51,480
using empirical median mean fits on each cell

1167
01:19:51,520 --> 01:19:56,440
and let f seven p denote the the classification regression rules associated with the treaty

1168
01:19:56,440 --> 01:20:01,980
using the true median means the true with respect to the underlying probability law p

1169
01:20:02,000 --> 01:20:03,540
and each cell

1170
01:20:03,590 --> 01:20:04,550
and we can now

1171
01:20:04,570 --> 01:20:08,440
look at this and ultimately what we're interested in we'd like to know what's the

1172
01:20:08,440 --> 01:20:10,550
rest of our empirical rule

1173
01:20:10,560 --> 01:20:14,320
relative to the smallest risk we could achieve

1174
01:20:14,380 --> 01:20:16,980
this would be say the bayes classification

1175
01:20:17,000 --> 01:20:19,960
probability of varying classifications

1176
01:20:19,960 --> 01:20:22,800
and then we can decompose this difference

1177
01:20:22,820 --> 01:20:26,940
in the two terms one term is the difference between the risk of that happened

1178
01:20:26,940 --> 01:20:28,420
the risk of

1179
01:20:29,420 --> 01:20:30,270
and then

1180
01:20:30,420 --> 01:20:35,400
the second is is the difference between the risk of after he and the minimum

1181
01:20:37,090 --> 01:20:40,900
and the first term is called the estimation error which is essentially the part that

1182
01:20:40,920 --> 01:20:45,480
stochastic the part various because it involves the training data and this

1183
01:20:46,590 --> 01:20:53,320
prediction rules derived from training data so that training data random that risk was random

1184
01:20:53,340 --> 01:20:57,460
and the second term is the approximation error which serves as well how good using

1185
01:20:57,460 --> 01:21:01,070
this stream this partition could i principle approximate the

1186
01:21:01,130 --> 01:21:03,520
the optimal

1187
01:21:03,540 --> 01:21:05,440
the optimal prediction

1188
01:21:05,460 --> 01:21:09,820
so the two terms are one is stochastic one is not stochastic one is deterministic

1189
01:21:09,940 --> 01:21:15,770
approximation rules deterministic estimation are stochastic and so that's that's stochastic term gives rise to

1190
01:21:15,770 --> 01:21:17,920
the variance

1191
01:21:17,980 --> 01:21:18,840
so what we

1192
01:21:18,860 --> 01:21:24,150
look at this estimation error kind carefully in the regression classification case

1193
01:21:24,210 --> 01:21:29,210
i'm not going to bother you with this will derivation here because it would probably

1194
01:21:29,210 --> 01:21:32,210
take more time to go through is very elementary the main

1195
01:21:32,270 --> 01:21:33,750
i have

1196
01:21:33,750 --> 01:21:37,540
o point that you need to recognise is that the expected value that has equal

1197
01:21:37,540 --> 01:21:39,250
to f t in regression

1198
01:21:39,300 --> 01:21:45,480
so what that ultimately leads to is the variance if you well in this case

1199
01:21:45,480 --> 01:21:49,210
is just the expected squared error between f and

1200
01:21:49,500 --> 01:21:54,590
that's what the variance term ends up looking like the variance being the estimation error

1201
01:21:54,820 --> 01:21:59,020
so you you the slide we post and you can look at this in a

1202
01:21:59,020 --> 01:22:03,980
very very ask questions about this little calculation we can talk about offline but i

1203
01:22:03,980 --> 01:22:05,800
don't want to bore you with

1204
01:22:05,920 --> 01:22:08,230
in the classification case

1205
01:22:09,150 --> 01:22:12,900
we're looking at the expected value of that estimation here again

1206
01:22:12,900 --> 01:22:15,190
we can break data into the two

1207
01:22:15,210 --> 01:22:20,480
components this is the risk of f had this is the risk as

1208
01:22:20,480 --> 01:22:25,960
just using a little triangle inequality here we get that that as the expected estimation

1209
01:22:25,960 --> 01:22:28,730
error variance is bounded by the

1210
01:22:28,730 --> 01:22:34,380
absolute error in expectation is the difference being one case in regression it was the

1211
01:22:34,380 --> 01:22:35,630
squared error

1212
01:22:35,630 --> 01:22:37,710
in this case is the absolute here

1213
01:22:37,730 --> 01:22:42,190
and saying variance in quotations because normally we associate variance in the way i was

1214
01:22:42,190 --> 01:22:46,590
using the regression case here i'm just sort of using the word variance to mean

1215
01:22:46,590 --> 01:22:52,070
variability but technically we would we call the estimation error not variance in the classification

1216
01:22:53,500 --> 01:22:55,540
OK so

1217
01:22:55,590 --> 01:22:56,650
let me now

1218
01:22:56,710 --> 01:23:00,270
kind of explaining the overfitting problem with this picture

1219
01:23:00,300 --> 01:23:03,190
so what i'm showing you here is the empirical risk

1220
01:23:03,210 --> 01:23:06,250
this horizontal axis is the

1221
01:23:06,270 --> 01:23:09,520
number of leaves in the partition this is the size of the partition of the

1222
01:23:09,520 --> 01:23:12,320
complexity of the number of cells in the partition

1223
01:23:12,380 --> 01:23:13,590
which other notice

1224
01:23:13,590 --> 01:23:17,980
the cardinality of t that will mean the number of cells in the partition

1225
01:23:18,090 --> 01:23:20,920
equivalently the number of leaves in the tree

1226
01:23:20,940 --> 01:23:23,170
so as i increase the

1227
01:23:23,190 --> 01:23:26,250
number of cells in the partition of course i can fit the data better and

1228
01:23:26,250 --> 01:23:30,340
better and so the empirical risk just tends to go down to zero

1229
01:23:30,360 --> 01:23:33,940
on the other hand if we really knew what the true risk functional looked like

1230
01:23:33,940 --> 01:23:38,260
degree larger point five that seems not very painful so they can do is you

1231
01:23:38,260 --> 01:23:43,200
can sort of go back and to find a couple of border constraints i've done

1232
01:23:43,200 --> 01:23:44,580
that you can

1233
01:23:44,600 --> 01:23:50,820
look for the william extreme cases say OK what about if it belongs to

1234
01:23:50,840 --> 01:23:54,610
the old people to a degree of zero really doesn't belong to the set of

1235
01:23:54,620 --> 01:23:58,300
old what would you think down here i mean if it doesn't belong to the

1236
01:23:58,300 --> 01:24:02,140
old people at all it really shouldn't belong to the old and tall people also

1237
01:24:02,140 --> 01:24:06,820
down here you should definitely have zero up here same argument if it doesn't belong

1238
01:24:06,820 --> 01:24:10,040
at all to the tall people should is up here and of course if it

1239
01:24:10,040 --> 01:24:13,360
doesn't belong to the old and or to the tall people on both of these

1240
01:24:13,360 --> 01:24:16,020
abuses european also expect

1241
01:24:16,180 --> 01:24:18,820
the same is true for the one i mean if you if you have the

1242
01:24:18,840 --> 01:24:22,760
degree of membership here of one and here of one then long

1243
01:24:22,780 --> 01:24:26,220
there's also a degree of membership of one to the set of old people up

1244
01:24:26,220 --> 01:24:30,640
here you would assume that this has has one and then you can sort of

1245
01:24:31,960 --> 01:24:34,970
and this is just one example of doing it very simple all the sort of

1246
01:24:34,970 --> 01:24:38,360
the line of people that belong to the old and tall people to point seven

1247
01:24:38,360 --> 01:24:41,960
is probably somewhere here point five goes down here so you have sort of this

1248
01:24:41,960 --> 01:24:46,580
program done but the the extreme cases you definitely want to observe them if this

1249
01:24:46,580 --> 01:24:48,620
is zero for the

1250
01:24:48,640 --> 01:24:52,420
for mu old for the old people you definitely want a degree of membership to

1251
01:24:52,420 --> 01:24:57,000
the to the conjunction of zero small said mister here and this corner pieces of

1252
01:24:57,150 --> 01:24:58,840
definitely needs to be true

1253
01:24:59,550 --> 01:25:03,560
i'll get back to formalising that a little bit in the second we can do

1254
01:25:03,560 --> 01:25:07,500
the same of course with the disjunction between the or

1255
01:25:07,580 --> 01:25:11,320
and we can do the same argument you but what would you expect if one

1256
01:25:11,320 --> 01:25:15,840
of them is one and the other one is something not to force would definitely

1257
01:25:15,840 --> 01:25:20,100
expect a degree of membership to the destruction of these sets to be oneself if

1258
01:25:20,100 --> 01:25:21,380
both are zero

1259
01:25:21,400 --> 01:25:24,820
you would expect a zero if both are one you definitely expect one so you

1260
01:25:24,820 --> 01:25:27,720
get a sort of inverse picture

1261
01:25:27,840 --> 01:25:31,660
all the way on this line would definitely expect a degree of membership of one

1262
01:25:31,660 --> 01:25:35,400
to the structure of these sets down here is that the case we would expect

1263
01:25:35,410 --> 01:25:38,660
a degree of zero and then you sort of get these lines four point five

1264
01:25:38,660 --> 01:25:44,780
point but you formalise this is a little bit better but that is not proposed

1265
01:25:44,780 --> 01:25:46,200
to do

1266
01:25:46,420 --> 01:25:52,180
is he proposed to use the so-called mean marks very you define conjunction and i

1267
01:25:52,180 --> 01:25:57,360
hope form pops up yes that they define the conjunction of two fuzzy sets a

1268
01:25:57,360 --> 01:25:59,240
and b

1269
01:25:59,700 --> 01:26:04,600
that's the minimum of the degrees of memberships of these individual sex so the conjunction

1270
01:26:04,600 --> 01:26:07,760
here is defined as the minimum of the degree of membership to set a and

1271
01:26:07,760 --> 01:26:09,500
the degree of membership to set b

1272
01:26:09,620 --> 01:26:14,000
i down here just a little examples this would be our the blue is the

1273
01:26:14,060 --> 01:26:18,180
membership function for my set a and the green line is the membership function for

1274
01:26:18,190 --> 01:26:19,360
set b

1275
01:26:19,500 --> 01:26:23,640
popped up but only the minimum which essentially be is zero line here it's all

1276
01:26:23,640 --> 01:26:28,560
there is zero then starts declining agreement that going to just get this little rectangle

1277
01:26:28,560 --> 01:26:32,780
here this just make sense but it's want to belong to both sets you have

1278
01:26:32,790 --> 01:26:38,300
to belong to both sets the maximum so this suggests what the the operator for

1279
01:26:38,300 --> 01:26:42,220
the disjunction is still take the maximum of the and i mean note how it

1280
01:26:42,220 --> 01:26:45,060
works right for the disjunction up here we do if one of them is zero

1281
01:26:45,060 --> 01:26:48,180
because if both are one we get a one so the extremes of the the

1282
01:26:48,490 --> 01:26:53,340
extreme case we we exactly the way you want them to do the same is

1283
01:26:53,340 --> 01:26:56,380
true for the maximum if one of them is one will end up getting a

1284
01:26:56,380 --> 01:26:59,820
one if both are zero newfangled we get a zero and if both are one

1285
01:26:59,830 --> 01:27:03,720
we also so in that case the maximum you essentially follow sort of the the

1286
01:27:03,720 --> 01:27:07,680
whole of these two groups opted to go back up here that would be sort

1287
01:27:07,680 --> 01:27:08,480
of the

1288
01:27:08,500 --> 01:27:12,040
the structure of of these two sets and then we can also define indication what

1289
01:27:12,040 --> 01:27:16,100
would be sort of the degree of membership to the set not

1290
01:27:16,120 --> 01:27:20,050
and will define this by using one minus and again the works nicely for the

1291
01:27:20,050 --> 01:27:23,460
willing cases it was you're you're end up getting a one if you want to

1292
01:27:23,460 --> 01:27:28,340
get this is converted nicely in all sorts of intermediate cases i think can again

1293
01:27:28,520 --> 01:27:29,740
this is the

1294
01:27:31,720 --> 01:27:38,060
the red line here is the disjunction and not a this the special and so

1295
01:27:38,070 --> 01:27:41,580
not a is true essentially all the way out there and all the way out

1296
01:27:41,580 --> 01:27:48,000
there and just declines and here in the core region of my set a it's

1297
01:27:48,130 --> 01:27:52,220
OK so this works nicely

1298
01:27:52,330 --> 01:27:56,900
became defined different operators just to demonstrate that this is not the only way of

1299
01:27:56,900 --> 01:28:00,460
doing it actually many around you really want to go into the the book describes

1300
01:28:00,460 --> 01:28:06,960
some more there's the so-called product bounded sum norm the conjuction conjunction is defined as

1301
01:28:07,040 --> 01:28:10,340
simply the product of these two membership functions again if you look at that if

1302
01:28:10,340 --> 01:28:13,940
one of them is zero it is zero if both are one you get once

1303
01:28:13,940 --> 01:28:16,900
the most extreme cases work

1304
01:28:16,960 --> 01:28:18,360
the disjunction is

1305
01:28:18,400 --> 01:28:21,800
this expression again you can place one so what happens if one of them is

1306
01:28:21,800 --> 01:28:24,480
one if one of them is zero that's fine

1307
01:28:24,520 --> 01:28:28,100
and the negation stays the same

1308
01:28:28,120 --> 01:28:30,620
and this time we'll get

1309
01:28:30,960 --> 01:28:34,420
well since the product it's not quite as high as this one and this is

1310
01:28:34,500 --> 01:28:38,640
actually already and also previous conjunction was an example for fuzzy set that has the

1311
01:28:38,640 --> 01:28:44,220
height of not one right behind in this case the two point two five the

1312
01:28:44,220 --> 01:28:46,240
the nice thing here is that the

1313
01:28:46,260 --> 01:28:50,740
this is the disjunction is little bit higher here because you end up in the

1314
01:28:50,740 --> 01:28:52,680
news practical difference here

1315
01:28:52,720 --> 01:28:55,480
and the negation stays the same

1316
01:28:55,500 --> 01:28:59,860
talking find knows that playing with these things

1317
01:29:00,740 --> 01:29:06,280
this is probably but if you want to formalise this more you would start stumbling

1318
01:29:06,280 --> 01:29:10,370
across but i don't want to do that today and brilliant minds he would stumble

1319
01:29:10,370 --> 01:29:14,360
across the notions of t norms and s norms which is from data describing different

1320
01:29:14,360 --> 01:29:18,220
so what is that it's the last two

1321
01:29:18,240 --> 01:29:22,730
each player thai fighters rocking you choose rock player one chooses row

1322
01:29:22,750 --> 01:29:25,430
thirty two the columns if we tie

1323
01:29:25,450 --> 01:29:26,800
the book is zero

1324
01:29:26,880 --> 01:29:31,040
if i choose paper you choose rock with backwards that i should get one and

1325
01:29:31,040 --> 01:29:32,820
you should get minus one

1326
01:29:32,860 --> 01:29:36,870
if i choose paper newspaper we get a zero ppt scissors

1327
01:29:36,880 --> 01:29:40,790
should be one minus one and this is minus one

1328
01:29:40,840 --> 01:29:46,130
so it's not rock paper scissors OK but anyway that's the model of just the

1329
01:29:46,140 --> 01:29:48,880
standard game written in normal form

1330
01:29:50,450 --> 01:29:54,060
any game that involves multiple stages can always be converted to one of the simple

1331
01:29:54,060 --> 01:29:58,520
tables even chance you could conceivably write although in a very practical in one of

1332
01:29:58,520 --> 01:30:03,360
these fables in repeated game playing the same game over and over let's say we

1333
01:30:03,360 --> 01:30:05,690
just had two players to be simple

1334
01:30:07,100 --> 01:30:09,570
what do we get we have these rounds each round

1335
01:30:09,580 --> 01:30:14,530
the players are simultaneously choosing an action i choose arose the column and then we

1336
01:30:14,530 --> 01:30:16,380
find out usually what

1337
01:30:16,440 --> 01:30:18,020
our path is

1338
01:30:18,040 --> 01:30:20,680
what do you find out what the action of the other player was

1339
01:30:20,690 --> 01:30:22,850
and you get payoff

1340
01:30:22,900 --> 01:30:24,850
the goal of course is to maximize

1341
01:30:25,060 --> 01:30:29,370
average long-run average equivalently along with total payoff

1342
01:30:29,380 --> 01:30:32,600
i mean this is the natural setting for learning rate you don't have to know

1343
01:30:32,600 --> 01:30:34,440
your opponent and you don't have to know

1344
01:30:34,450 --> 01:30:37,680
and actually in in the models we consider you need to know your point is

1345
01:30:37,690 --> 01:30:40,370
in fact you don't even need to know what the game you're playing is you

1346
01:30:40,370 --> 01:30:42,180
can find out as you go along

1347
01:30:42,190 --> 01:30:45,790
we only feed back into is you know which actions you have

1348
01:30:45,810 --> 01:30:47,400
each time you choose an action

1349
01:30:47,410 --> 01:30:52,650
and for simplicity we can even get by with less feedback the feedback you get

1350
01:30:52,680 --> 01:30:54,190
is just you know

1351
01:30:54,200 --> 01:30:55,660
how much you made

1352
01:30:55,680 --> 01:30:57,250
and how much you would have made

1353
01:30:57,260 --> 01:31:00,030
had you chosen any of the other actions

1354
01:31:01,340 --> 01:31:04,720
so this could actually be very big table that many players but all your feedback

1355
01:31:04,720 --> 01:31:08,010
you really need to know is for each of your actions how much made that

1356
01:31:08,010 --> 01:31:11,710
time you play and how much she would have made had played anything else

1357
01:31:11,730 --> 01:31:14,640
so this is very much like the online setting

1358
01:31:14,650 --> 01:31:18,870
because you're going on online and now you really do have an adversary so the

1359
01:31:18,870 --> 01:31:20,710
adversary way of looking at things

1360
01:31:20,730 --> 01:31:22,250
is very natural

1361
01:31:22,270 --> 01:31:24,380
for this setting

1362
01:31:24,400 --> 01:31:27,480
and the questions

1363
01:31:27,500 --> 01:31:32,330
to do understand mostly what the repeated game model is playing this game of an

1364
01:31:32,330 --> 01:31:36,690
overactive is we see what the opponent did and we're trying to do

1365
01:31:36,710 --> 01:31:41,530
of course we all know that in rock paper scissors

1366
01:31:41,580 --> 01:31:44,520
the best thing to do is to choose according to the distribution

1367
01:31:44,570 --> 01:31:47,860
to randomize well we don't all the

1368
01:31:47,870 --> 01:31:49,870
but it turns out that if you can

1369
01:31:49,890 --> 01:31:53,860
if you're going play this game a long time you better best of enemies actually

1370
01:31:53,880 --> 01:31:54,700
really need

1371
01:31:54,750 --> 01:31:59,440
programme i've seen that will play it will be you in rock paper scissors i

1372
01:31:59,440 --> 01:32:02,710
don't know i forget where i saw this but it's program you play it and

1373
01:32:02,710 --> 01:32:06,370
it will almost always be true in rock paper scissors and the point is that

1374
01:32:06,820 --> 01:32:09,550
people are very bad at minimizing definitely coin

1375
01:32:12,160 --> 01:32:15,660
basically this program will be able to predict better predict what you're going to do

1376
01:32:15,660 --> 01:32:18,050
with probability better than the third and the u

1377
01:32:18,060 --> 01:32:21,400
more often than not very frustrating

1378
01:32:31,490 --> 01:32:35,050
yes i was thinking the same

1379
01:32:37,200 --> 01:32:42,870
well i mean the simplest thing to think about it you see what your opponent

1380
01:32:42,880 --> 01:32:46,080
we can get by with less than that let's just say OK i thought i

1381
01:32:46,080 --> 01:32:49,060
play rock paper but i knew the game

1382
01:32:49,080 --> 01:32:51,890
i thought what he did

1383
01:32:52,060 --> 01:32:56,240
that's fine

1384
01:32:56,260 --> 01:32:59,830
so if i choose an action a each time he chooses a one a two

1385
01:32:59,830 --> 01:33:05,070
a three b one b two b three i choose it around i have seen

1386
01:33:05,110 --> 01:33:07,840
a one b one b one a two b two

1387
01:33:07,850 --> 01:33:08,890
up until

1388
01:33:08,900 --> 01:33:14,580
a i minus one minus one as well as this matrix here

1389
01:33:22,140 --> 01:33:24,110
as i said the

1390
01:33:24,130 --> 01:33:28,000
in some sense the best way the equilibrium of this game would be the randomized

1391
01:33:28,030 --> 01:33:29,140
so you want

1392
01:33:29,190 --> 01:33:34,110
the column player which is you know some distribution which again represented new

1393
01:33:34,120 --> 01:33:39,120
and some other distribute the row player has to choose another distribution maybe the same

1394
01:33:39,120 --> 01:33:45,170
in anyone guess what distribution this is

1395
01:33:45,180 --> 01:33:48,070
this is mu because you know you got them you just like move

1396
01:33:48,080 --> 01:33:52,430
what distribution do you think this is anyone's guess

1397
01:33:52,450 --> 01:33:58,080
you get this is that the greek letter news

1398
01:33:58,100 --> 01:34:02,260
this is new OK anyway thank OK so

1399
01:34:02,310 --> 01:34:05,210
the opponent chooses from a distribution

1400
01:34:05,230 --> 01:34:11,010
basically the same and that and since we all know what nash equilibrium is this

1401
01:34:11,010 --> 01:34:15,650
is a mixed strategy nash equilibrium means that given the information about what distribution you're

1402
01:34:16,530 --> 01:34:19,100
my distribution has to be the best in response

1403
01:34:19,110 --> 01:34:20,760
and vice versa

1404
01:34:21,860 --> 01:34:27,080
and equilibria always exist even if the game is not zero sum

1405
01:34:27,100 --> 01:34:31,020
so what is the zero-sum game of the this is a zero-sum game meaning that

1406
01:34:31,020 --> 01:34:32,560
whatever i make you lose

1407
01:34:32,580 --> 01:34:33,820
so there is no

1408
01:34:33,840 --> 01:34:37,450
money coming out of nowhere else and always add up to zero

1409
01:34:37,470 --> 01:34:39,110
so i guess

1410
01:34:39,120 --> 01:34:42,470
i looked first appears notes i wasn't here when he gives lecture but i guess

1411
01:34:42,470 --> 01:34:45,710
he didn't cover boosting in games

1412
01:34:45,730 --> 01:34:48,100
something like nobody OK well

1413
01:34:48,150 --> 01:34:49,860
grouping and so

1414
01:34:49,900 --> 01:34:52,870
this is some of his research that

1415
01:34:52,880 --> 01:34:56,690
so suppose we write this zero-sum game we can we actually have to tell you

1416
01:34:56,690 --> 01:34:58,730
one of the entries the payoff to player one

1417
01:34:58,790 --> 01:35:01,400
if it is zero sum game because payoff to player two is

1418
01:35:01,450 --> 01:35:05,090
the opposite the negative so they have to play one is a i j if

1419
01:35:05,090 --> 01:35:06,710
player one plays rho

1420
01:35:06,840 --> 01:35:09,710
i n player two plays column j

1421
01:35:09,730 --> 01:35:12,630
the payoff to player two is minus the i j

1422
01:35:13,680 --> 01:35:16,870
going first is disadvantage in this situation

1423
01:35:16,920 --> 01:35:19,710
of course if the disadvantaged have to go first if point can see what you

1424
01:35:20,450 --> 01:35:25,840
we think that we're playing simultaneously just a second imagine going first

1425
01:35:26,020 --> 01:35:30,250
many of you have seen this minimax how many using the minimax theorem

1426
01:35:30,270 --> 01:35:34,780
good so this is going to be very simple proof of the minimax theorem using

1427
01:35:34,780 --> 01:35:36,470
the weighted majority algorithm

1428
01:35:36,490 --> 01:35:39,750
i'll go through the proof but i give you the basic idea

1429
01:35:39,790 --> 01:35:43,480
so if you go first to do more stuff if you go first that means

1430
01:35:43,480 --> 01:35:45,700
that i get to choose

1431
01:35:45,720 --> 01:35:46,670
it's a bit

1432
01:35:46,680 --> 01:35:50,000
the column player and i have to go first

1433
01:35:50,020 --> 01:35:53,800
that means that you youtube i magna choose some column and after to use the

1434
01:35:53,810 --> 01:35:55,680
colony going to zero

1435
01:35:56,910 --> 01:35:59,210
the payoff to player one will be this value

1436
01:35:59,220 --> 01:36:00,290
it's going to be

1437
01:36:00,310 --> 01:36:03,540
less than of player one has to go first and he chooses

1438
01:36:03,550 --> 01:36:08,070
rowan then player two can get were based on whatever choice

1439
01:36:08,080 --> 01:36:09,240
player one

1440
01:36:09,290 --> 01:36:13,410
makes player two can choose a column to to minimize

1441
01:36:14,020 --> 01:36:17,360
anyway if if if you don't want to get into detail in all is going

1442
01:36:17,360 --> 01:36:20,670
first is disadvantage

1443
01:36:22,190 --> 01:36:26,690
now you can also talk about the same statement with mixed strategies for that strategy

1444
01:36:26,750 --> 01:36:29,870
and then the opponent chooses a mixed strategy

1445
01:36:29,930 --> 01:36:33,020
so i tell you how i'm going to randomize in rock paper scissors and then

1446
01:36:33,020 --> 01:36:35,620
you get to choose how you're going to minimize

1447
01:36:35,620 --> 01:36:38,040
thanks much for the invitation i guess the

1448
01:36:38,070 --> 01:36:40,940
the programme as far as i missed that this morning was

1449
01:36:40,950 --> 01:36:43,490
excellent i mean score and

1450
01:36:43,510 --> 01:36:45,170
and the monk presented

1451
01:36:45,180 --> 01:36:47,640
and very interesting work in egypt prior get

1452
01:36:50,320 --> 01:36:53,400
for this talk was kind of quite three of these if my integration will be

1453
01:36:53,400 --> 01:36:54,860
an event related

1454
01:36:56,110 --> 01:36:59,590
she would probably know on the event related potentials

1455
01:36:59,840 --> 01:37:03,680
in cognitive neuroscience this is what i'm working with my interest

1456
01:37:03,800 --> 01:37:04,980
with that

1457
01:37:06,940 --> 01:37:12,250
the talking a bit ways of putting the guys together so we have g and

1458
01:37:12,250 --> 01:37:13,840
then predict the fmri

1459
01:37:13,860 --> 01:37:19,920
four UVF nine hundred to or you can go down to the

1460
01:37:20,190 --> 01:37:24,050
black box like neural signal that is at the bottom of the death of the

1461
01:37:24,060 --> 01:37:27,090
of the signal that be looking at uniform mind try to

1462
01:37:27,170 --> 01:37:30,540
come with diffusion model are common generative model that

1463
01:37:30,560 --> 01:37:31,510
it gives you

1464
01:37:32,310 --> 01:37:39,570
the idea of how these types of signals

1465
01:37:40,240 --> 01:37:43,530
for any one of you who hasn't been in norway this is a very good

1466
01:37:43,530 --> 01:37:45,460
research environment there's also

1467
01:37:45,470 --> 01:37:50,440
scenery this is a mountain in bergen about ten minutes from my house this is

1468
01:37:50,440 --> 01:37:53,740
my view from my belt balcony and pentecost

1469
01:37:53,750 --> 01:37:58,080
eleven PM i didn't do anything to the colours here just this is how it

1470
01:37:58,080 --> 01:38:02,680
looks like there a small church was small house is a small town close to

1471
01:38:03,980 --> 01:38:07,050
so it's all in all of a nice place to be

1472
01:38:07,070 --> 01:38:09,340
we are

1473
01:38:09,360 --> 01:38:12,910
calling to national competence centre i don't know how much it means no is four

1474
01:38:12,910 --> 01:38:16,170
point five million inhabitants berlin has five or

1475
01:38:16,180 --> 01:38:18,800
something like that you have

1476
01:38:18,910 --> 01:38:20,290
given take so

1477
01:38:21,350 --> 01:38:27,100
we're kind of collecting competence for my research in EEG research and method development in

1478
01:38:27,100 --> 01:38:32,560
that direction were part of a different bunch of networks not centre of excellence is

1479
01:38:32,560 --> 01:38:34,380
something integrate across

1480
01:38:34,390 --> 01:38:37,310
sweden finland denmark

1481
01:38:37,330 --> 01:38:41,480
with say helsinki and all of work

1482
01:38:41,920 --> 01:38:46,270
two things i have to put this slide in here

1483
01:38:47,120 --> 01:38:50,610
neural activity which is the black box to me

1484
01:38:50,620 --> 01:38:54,810
and the sort of the signal which is easy and therefore i have something to

1485
01:38:54,810 --> 01:38:57,390
to do with cognitive neuroscience how we can

1486
01:38:57,410 --> 01:39:01,020
use these signals to make inferences about human cognition

1487
01:39:02,030 --> 01:39:06,270
it has to do with the practical aspects of things so

1488
01:39:06,330 --> 01:39:10,950
e g you use because it's all around everybody has one

1489
01:39:11,000 --> 01:39:14,370
i got four amplifiers wanna take you home with me but when i one of

1490
01:39:14,370 --> 01:39:19,650
to play play around with EEG and my daughters easy very cheap you can do

1491
01:39:19,650 --> 01:39:22,170
it in humans you can do it all the time no side effects and are

1492
01:39:22,170 --> 01:39:24,140
known is not invasive

1493
01:39:24,150 --> 01:39:25,450
the widely available

1494
01:39:25,460 --> 01:39:30,300
and the temporal resolution is instantaneous so so you don't lose much of the

1495
01:39:31,560 --> 01:39:33,620
temporal resolution of the gene

1496
01:39:33,630 --> 01:39:36,090
of the of the brain's sorry

1497
01:39:36,140 --> 01:39:37,980
on the other hand you have

1498
01:39:37,990 --> 01:39:44,140
no spatial resolution and you have to heavy undersampling and you have the inverse problem

1499
01:39:44,140 --> 01:39:46,010
and then

1500
01:39:46,030 --> 01:39:49,060
that can be solved with the from my where you have good spatial resolution you

1501
01:39:49,060 --> 01:39:52,540
can do in humans you can repeat it a couple of times is no known

1502
01:39:52,540 --> 01:39:55,320
side effects to speak of if you will

1503
01:39:55,330 --> 01:39:58,590
it becomes even cheaper

1504
01:39:58,610 --> 01:40:00,210
it's invasive and

1505
01:40:00,220 --> 01:40:02,550
well every hospital has one and

1506
01:40:02,560 --> 01:40:06,950
you can do it from ryan almost any machine while on the other hand to

1507
01:40:06,960 --> 01:40:11,610
get to real neural activity in humans is chronically difficult need an epileptic patient or

1508
01:40:11,610 --> 01:40:14,980
someone else whose skull open or can be opened

1509
01:40:15,060 --> 01:40:17,940
and that restricts your

1510
01:40:17,970 --> 01:40:20,020
sample to sick people

1511
01:40:20,680 --> 01:40:26,400
or two subhuman species it's pretty expensive if you will compared to these guys

1512
01:40:26,420 --> 01:40:29,880
and you can't repeated or you have to do one chronic

1513
01:40:30,910 --> 01:40:33,730
it's invasive

1514
01:40:33,750 --> 01:40:37,970
and there are side effects to humans due to surgery

1515
01:40:37,990 --> 01:40:44,090
and and flexia infections in its restricted pretty much specialised centres in human study it

1516
01:40:51,320 --> 01:40:53,640
what i'm interested in going back here

1517
01:40:53,740 --> 01:40:56,080
my my my education

1518
01:40:56,090 --> 01:41:00,390
it was mostly easy so what i'm interested in this type of waveforms

1519
01:41:00,410 --> 01:41:03,190
which looks really nice to me i don't know

1520
01:41:03,210 --> 01:41:05,080
who shares that impression

1521
01:41:05,090 --> 01:41:11,820
this is an oddball so-called super simplest paradigm that you can do well second simplest

1522
01:41:11,820 --> 01:41:15,590
paradigm that you can do with it was invented easy takes a two tones one

1523
01:41:15,590 --> 01:41:18,590
is high and one low and the little one is rare or freak and the

1524
01:41:18,590 --> 01:41:22,700
other one is frequent is held subjects will push button to that tone which is

1525
01:41:22,700 --> 01:41:27,010
thickened or not so what about to the to the town rare gives up to

1526
01:41:27,010 --> 01:41:30,900
the task and something to discriminate and when they do that

1527
01:41:30,900 --> 01:41:36,640
well well

1528
01:41:36,660 --> 01:41:41,090
a lot

1529
01:41:41,100 --> 01:41:48,350
the people are of

1530
01:41:56,260 --> 01:42:04,540
that's right

1531
01:42:54,730 --> 01:43:01,960
of our

1532
01:43:11,090 --> 01:43:14,570
the problem here

1533
01:43:14,590 --> 01:43:15,650
this is

1534
01:43:43,230 --> 01:43:46,490
as a

1535
01:43:50,090 --> 01:43:55,770
you have a problem of

1536
01:44:05,690 --> 01:44:07,540
there are

1537
01:44:25,020 --> 01:44:31,480
i had a little

1538
01:44:38,140 --> 01:44:57,700
he played

1539
01:45:07,310 --> 01:45:10,310
i i

1540
01:46:31,290 --> 01:46:34,360
one one way a

1541
01:46:45,440 --> 01:46:49,960
which is life

1542
01:49:04,220 --> 01:49:06,240
there are

1543
01:49:06,240 --> 01:49:10,730
so neither of these sorts of ways of analyzing things the perfect what i'm really

1544
01:49:10,730 --> 01:49:12,730
saying is

1545
01:49:12,740 --> 01:49:16,530
you can carry out comparative studies in classification methods detection methods

1546
01:49:16,550 --> 01:49:18,230
in this sort of context

1547
01:49:18,230 --> 01:49:20,650
but don't put too much

1548
01:49:21,090 --> 01:49:25,370
value on the precise numerical results

1549
01:49:25,380 --> 01:49:29,320
you should imagine them with larger bounds not just due to

1550
01:49:29,380 --> 01:49:31,300
statistical area sampling error

1551
01:49:31,320 --> 01:49:32,290
but due to

1552
01:49:32,300 --> 01:49:37,490
all sorts of other things you don't know about changing economic conditions and so on

1553
01:49:37,530 --> 01:49:40,910
so here is the just to illustrate

1554
01:49:41,320 --> 01:49:47,280
given the cautionary notes that i just mentioned just on the random performed just on

1555
01:49:47,280 --> 01:49:48,370
the split

1556
01:49:48,420 --> 01:49:51,830
not the the thing changing over time just because i know that some of you

1557
01:49:51,830 --> 01:49:55,190
would want to know which of those methods is better but as i say i

1558
01:49:55,190 --> 01:49:57,110
think you should be interpreted cautiously

1559
01:49:57,110 --> 01:49:59,660
you probably can't see we've got

1560
01:50:00,280 --> 01:50:03,840
the blue bar is a single transaction

1561
01:50:03,870 --> 01:50:05,280
rate is

1562
01:50:05,300 --> 01:50:07,740
activity records averaged over one day

1563
01:50:07,740 --> 01:50:13,160
three days seven days down using a cost measure t one is the down is

1564
01:50:14,570 --> 01:50:16,020
lower scores are better

1565
01:50:16,030 --> 01:50:19,340
lower parser better

1566
01:50:19,370 --> 01:50:20,590
this first

1567
01:50:20,610 --> 01:50:26,280
a set of policies random forests a random forests evaluated on single transactions activity records

1568
01:50:26,280 --> 01:50:28,910
over one day three day seven day

1569
01:50:29,000 --> 01:50:30,240
random forests

1570
01:50:30,260 --> 01:50:31,730
logistic regression

1571
01:50:31,730 --> 01:50:34,570
support vector machines

1572
01:50:34,580 --> 01:50:37,670
the naive bayes and so the cart

1573
01:50:37,700 --> 01:50:39,620
this is nearest neighbour

1574
01:50:40,660 --> 01:50:42,150
in this case

1575
01:50:43,370 --> 01:50:45,290
these three of the best

1576
01:50:45,420 --> 01:50:48,490
random forests support vector machines

1577
01:50:48,580 --> 01:50:51,870
logistic regression but as i say

1578
01:50:51,880 --> 01:50:53,650
you should not stick

1579
01:50:53,660 --> 01:50:59,120
too much face on the precise numerical values

1580
01:50:59,330 --> 01:51:01,880
i haven't bothered to show you the

1581
01:51:02,050 --> 01:51:05,520
future performance very similar sorts of plot

1582
01:51:05,520 --> 01:51:08,090
what is clear from this is the performance

1583
01:51:08,160 --> 01:51:09,620
gets better

1584
01:51:09,630 --> 01:51:12,750
as you increase the length of the activity record

1585
01:51:12,760 --> 01:51:15,480
but probably the three days in seven days

1586
01:51:15,490 --> 01:51:19,300
are of about equal so somewhere in that sort of ballpark figure is probably an

1587
01:51:19,300 --> 01:51:23,210
appropriate length of activity record to years

1588
01:51:23,230 --> 01:51:25,690
this measure of course cost measure here

1589
01:51:25,700 --> 01:51:29,570
it takes time this into account and the way i described

1590
01:51:30,950 --> 01:51:34,150
i've already referred to some limitations of these are just like two

1591
01:51:34,200 --> 01:51:38,660
raise some sort of cautionary notes because in all of these comparative studies

1592
01:51:38,670 --> 01:51:39,690
it is in

1593
01:51:39,690 --> 01:51:43,330
OK in the academic literature in the data mining conferences and so you see lots

1594
01:51:43,330 --> 01:51:49,840
of papers describing these things and they basically uncritically interpret the results of this

1595
01:51:49,870 --> 01:51:54,870
i think represents a serious gap between what goes on in the academic world and

1596
01:51:54,910 --> 01:51:57,020
what goes on in reality

1597
01:51:57,460 --> 01:52:01,690
so just some limitations of these sorts of comparative studies here

1598
01:52:03,410 --> 01:52:04,950
the real world

1599
01:52:05,250 --> 01:52:06,880
is different from

1600
01:52:06,940 --> 01:52:08,840
the laboratory

1601
01:52:08,900 --> 01:52:10,690
in the laboratory

1602
01:52:10,740 --> 01:52:16,260
in our case for example we eliminated all those accounts which only had one transaction

1603
01:52:16,480 --> 01:52:18,460
during the course of that time period

1604
01:52:18,480 --> 01:52:21,260
couldn't do much more with a simple model so we're done here you could do

1605
01:52:21,260 --> 01:52:25,320
much else with random effects models and more advanced statistical models you can do something

1606
01:52:25,550 --> 01:52:27,860
but in the study on describing here

1607
01:52:27,880 --> 01:52:31,260
if something had one more in the field of transactions

1608
01:52:31,280 --> 01:52:33,420
it's not included in this analysis

1609
01:52:33,450 --> 01:52:36,210
but in the real world you would want to include

1610
01:52:36,240 --> 01:52:39,150
you'd use different kinds of methods

1611
01:52:39,150 --> 01:52:41,190
we also have two

1612
01:52:41,210 --> 01:52:45,660
consider what's meant by method now i listed methods i said random forest support vector

1613
01:52:45,660 --> 01:52:49,630
machines nearest neighbour method and so on

1614
01:52:49,650 --> 01:52:53,160
but what i didn't tell you because you know when you go two hours not

1615
01:52:53,160 --> 01:52:55,550
three weeks i didn't say

1616
01:52:55,580 --> 01:53:00,670
in my definition of the methods did i including the method the pre data preprocessing

1617
01:53:00,800 --> 01:53:03,830
transformation that i take a lot of amount for example

1618
01:53:03,870 --> 01:53:07,070
she should regarded that as part of the method or not

1619
01:53:07,260 --> 01:53:10,900
i didn't say anything about variable selection i just told you know eighty seven variables

1620
01:53:10,900 --> 01:53:12,700
per activity records

1621
01:53:12,740 --> 01:53:15,490
is variable selection part of the method

1622
01:53:15,580 --> 01:53:17,090
or what

1623
01:53:17,110 --> 01:53:21,300
i didn't talk about optimisation methods

1624
01:53:21,320 --> 01:53:23,400
i didn't talk about numbers of layers in in

1625
01:53:23,410 --> 01:53:26,370
in the neural network and so on

1626
01:53:26,400 --> 01:53:30,450
i didn't tell you what we did about missing values missing values are right in

1627
01:53:30,450 --> 01:53:34,380
this area as in any other area involving human beings

1628
01:53:34,410 --> 01:53:36,840
another issue is who will use the method the

1629
01:53:36,870 --> 01:53:43,170
people working on this particular study know about these classification methods are experts

1630
01:53:43,580 --> 01:53:47,880
but when you move this into a bank you can't really assume that

1631
01:53:47,900 --> 01:53:50,950
the guy working in the bank was in knows lot about thank you will know

1632
01:53:51,020 --> 01:53:54,860
about neural networks random forest

1633
01:53:54,950 --> 01:53:57,620
there is also this issue about what is meant by

1634
01:53:57,630 --> 01:54:01,240
best of the higher level and i think again every club mention the same sort

1635
01:54:01,240 --> 01:54:02,280
of thing

1636
01:54:02,330 --> 01:54:06,540
we might find some method method usually ranks first

1637
01:54:06,580 --> 01:54:11,960
but sometimes lasting method they always ranked second or third which is better

1638
01:54:11,990 --> 01:54:18,490
and obviously may vary between application domains datasets also things different kinds of fraud

1639
01:54:18,490 --> 01:54:23,400
so it is take a message if you like it's meaningless to evaluate methods as

1640
01:54:24,870 --> 01:54:25,790
you have to

1641
01:54:25,790 --> 01:54:28,670
really worked closely with in this case the bankers

1642
01:54:28,760 --> 01:54:31,610
to decide what is appropriate

1643
01:54:31,620 --> 01:54:33,990
OK let me switch to

1644
01:54:33,990 --> 01:54:35,550
the other classes

1645
01:54:35,580 --> 01:54:38,620
this is what i want to give you an example of

1646
01:54:38,630 --> 01:54:39,610
as i said

1647
01:54:39,610 --> 01:54:42,050
given the number of bits you have

1648
01:54:42,050 --> 01:54:45,050
and if and typically we use thirty two bits and so that means that the

1649
01:54:45,050 --> 01:54:46,420
period would be

1650
01:54:46,670 --> 01:54:50,360
whatever to the thirty two four billion or something like that now four billion is

1651
01:54:51,340 --> 01:54:57,090
that's not a long enough period so the algorithms that people really use has much

1652
01:54:57,090 --> 01:54:59,400
longer periods i mention this

1653
01:54:59,400 --> 01:55:03,380
t random three generator which is based on something called the

1654
01:55:03,400 --> 01:55:05,050
msn twister

1655
01:55:05,050 --> 01:55:09,570
algorithm that has a period of something like ten to the six thousand

1656
01:55:09,590 --> 01:55:10,710
which is

1657
01:55:10,720 --> 01:55:12,780
absurdly long

1658
01:55:12,780 --> 01:55:16,440
how many nano seconds have there been since the big bang only something like ten

1659
01:55:16,440 --> 01:55:22,920
to the twenty seven something she attended six thousand before you repeat sequence

1660
01:55:22,920 --> 01:55:28,170
the problem with something like two random three algorithm and this is typical of many

1661
01:55:28,170 --> 01:55:32,590
of the algorithms that have longer periods is that the state of the generator is

1662
01:55:33,710 --> 01:55:37,880
defined by the single valued by many values in the case of the random three

1663
01:55:38,070 --> 01:55:42,280
forget something like six hundred numbers so if you want to stop the sequence and

1664
01:55:42,530 --> 01:55:43,320
recorded stated

1665
01:55:43,420 --> 01:55:47,760
generator and then restart say in a separate calculation with the same sequence you would

1666
01:55:47,760 --> 01:55:50,820
have to write down something like six hundred numbers

1667
01:55:50,840 --> 01:55:54,550
which is for computer for you to do so it's not a problem

1668
01:55:54,550 --> 01:55:58,970
but so there are many deterministic algorithms i didn't i think a mention briefly the

1669
01:55:58,970 --> 01:56:03,800
idea of actually using a physical process as the basis of a random number generator

1670
01:56:04,130 --> 01:56:08,570
and sometimes those can have very specialized applications like in cryptography or something where you

1671
01:56:08,570 --> 01:56:10,360
might use thermal noise

1672
01:56:10,380 --> 01:56:11,470
in the circuit

1673
01:56:11,470 --> 01:56:13,610
it's the basis of a random number but the

1674
01:56:13,610 --> 01:56:22,570
it's certainly in particle physics that's not really an application we're coming interested in

1675
01:56:23,130 --> 01:56:27,190
the idea is

1676
01:56:27,220 --> 01:56:37,610
she goes to

1677
01:56:41,840 --> 01:56:48,320
to this

1678
01:56:48,530 --> 01:56:53,470
OK so

1679
01:56:53,490 --> 01:57:00,260
so we talked about for example using a linear discriminating function you have some number

1680
01:57:00,260 --> 01:57:01,590
of input variables

1681
01:57:01,590 --> 01:57:04,740
and the idea is to write down

1682
01:57:06,970 --> 01:57:13,450
something i think

1683
01:57:16,090 --> 01:57:18,590
the idea is that you have some

1684
01:57:18,610 --> 01:57:20,400
number of

1685
01:57:20,400 --> 01:57:22,840
input variables

1686
01:57:22,860 --> 01:57:27,260
the components of this vector represent different measurable quantities for each event

1687
01:57:27,300 --> 01:57:32,760
whatever the jet energy and so forth and recall that the example that i showed

1688
01:57:32,780 --> 01:57:35,550
with the fisher discriminant is to say to you

1689
01:57:36,780 --> 01:57:38,990
simply a linear combination

1690
01:57:39,490 --> 01:57:46,300
the idea behind the neural network is to allow for a non-linear decision boundary between

1691
01:57:46,300 --> 01:57:50,940
the two classes if you use this you're discriminating function that would be equivalent to

1692
01:57:50,970 --> 01:57:56,380
having a hyperplane is the is is the decision boundary so here's the idea is

1693
01:57:56,380 --> 01:57:58,130
that you say that what we can

1694
01:57:58,130 --> 01:58:02,190
represent the best is a sort of diagram u u

1695
01:58:02,210 --> 01:58:05,880
draw a layer of nodes and each node represents

1696
01:58:05,940 --> 01:58:10,260
one of the input variables x one x two x three and so forth

1697
01:58:10,280 --> 01:58:11,630
now i draw

1698
01:58:11,690 --> 01:58:13,920
was called the hidden layer

1699
01:58:13,940 --> 01:58:17,920
and i associate now value with each one of these

1700
01:58:17,950 --> 01:58:20,760
nodes in the hidden layer

1701
01:58:20,760 --> 01:58:24,220
which is related to the values in the input layer

1702
01:58:24,240 --> 01:58:28,050
and what you take for the value in the hidden layer

1703
01:58:28,050 --> 01:58:29,920
is the following

1704
01:58:29,920 --> 01:58:32,130
is you take this linear combination

1705
01:58:32,150 --> 01:58:36,420
and you use it as the argument in nonlinear function

1706
01:58:36,440 --> 01:58:44,940
and this nonlinear function is typically taken to be a sigmoid function is function which

1707
01:58:44,950 --> 01:58:47,420
look something like this

1708
01:58:47,440 --> 01:58:49,210
has some sort of

1709
01:58:49,220 --> 01:58:53,240
a linear term nonlinear turn on the goes from zero

1710
01:58:53,260 --> 01:58:54,720
o to one

1711
01:58:54,740 --> 01:58:57,510
and that will give you some numerical value

1712
01:58:57,550 --> 01:58:59,800
at each node of the hidden layer

1713
01:59:00,070 --> 01:59:03,550
and then you do the same thing you have an output node the value of

1714
01:59:03,550 --> 01:59:08,320
the output node is obtained in a similar way you take a linear combination

1715
01:59:08,340 --> 01:59:10,360
of the values in the hidden layer

1716
01:59:10,380 --> 01:59:14,950
and you use that as the argument of nonlinear activation function

1717
01:59:14,970 --> 01:59:19,170
so that's the basic idea you can generalize very easily to an arbitrary number of

1718
01:59:19,170 --> 01:59:20,800
nodes in the hidden layer

1719
01:59:20,820 --> 01:59:23,130
you could also have more than one hidden layer

1720
01:59:23,150 --> 01:59:25,860
although most often you typically only have one

1721
01:59:25,860 --> 01:59:29,650
there's some theorem that says that if you only have one hidden layer but with

1722
01:59:29,650 --> 01:59:33,880
an an arbitrarily large number of nodes and that can approximate

1723
01:59:33,900 --> 01:59:38,990
arbitrarily well this optimal solution which is given by the likelihood ratio that's what you

1724
01:59:38,990 --> 01:59:40,090
would like to have

1725
01:59:40,090 --> 01:59:40,880
but but we

1726
01:59:40,900 --> 01:59:42,860
you don't have to explicitly

1727
01:59:42,880 --> 01:59:46,800
so that's the way that the neural networks basically work when you then need to

1728
01:59:46,800 --> 01:59:49,240
do is to take samples of training data

1729
01:59:49,280 --> 01:59:51,920
which are obtained safer monte carlo models

1730
01:59:51,920 --> 01:59:57,360
and use those to optimally determine the parameters of the network which are basically the

1731
01:59:57,670 --> 02:00:04,240
coefficients of these linear combinations so every line in this diagram represents an adjustable parameters

1732
02:00:04,240 --> 02:00:05,720
which you have to determine

1733
02:00:05,720 --> 02:00:07,590
the actual

1734
02:00:07,610 --> 02:00:10,420
so carrying out that calculation is used

1735
02:00:10,440 --> 02:00:14,090
it can be numerically challenging their tools to do that

1736
02:00:14,110 --> 02:00:17,030
strong networks take a look at the TMVA

1737
02:00:18,170 --> 02:00:21,470
it's a good place to start for more information

1738
02:00:21,470 --> 02:00:24,650
you that something about how those are used in

1739
02:00:24,670 --> 02:00:31,650
i mean so so they are actually very convenient to use nowadays

1740
02:00:31,670 --> 02:00:36,800
it it takes you like dave moved to get started on something and you train

1741
02:00:36,940 --> 02:00:42,450
then you get some reside the difficulty in terms of experimental analysis is

1742
02:00:42,470 --> 02:00:45,510
that it's rather than transparent what it does

1743
02:00:45,530 --> 02:00:46,240
you know

1744
02:00:46,280 --> 02:00:50,010
if i have got to digest mass and i see a peak

1745
02:00:50,030 --> 02:00:53,740
in that on some top some background and i believe OK

1746
02:00:53,760 --> 02:00:58,530
that looks like really is sigma with the neural network uses some sort of band

1747
02:00:58,530 --> 02:01:01,780
in the high school region what is called one

1748
02:01:02,630 --> 02:01:04,210
you don't know

1749
02:01:04,220 --> 02:01:10,630
i mean less intuitive it could have exploited something in the data that looks different

1750
02:01:10,840 --> 02:01:15,650
to your estimate background you've used to training and by chance that looks like a

1751
02:01:15,650 --> 02:01:21,050
sigma but isn't really the signal so so so typically these techniques are

1752
02:01:21,090 --> 02:01:25,050
more applied to really mature experiments so they were applied at the end of lap

1753
02:01:25,050 --> 02:01:28,510
there now apply to the temperature when people have already gained a lot of understanding

1754
02:01:28,510 --> 02:01:32,860
and that of the data is very controversial to to apply them in the beginning

1755
02:01:33,280 --> 02:01:36,130
for instance at the LHC because it's harder

1756
02:01:36,150 --> 02:01:41,340
to really understand because some sort of arbitrary me OK not arbitrary but it's it's

1757
02:01:41,420 --> 02:01:46,550
it's in and transparent function could be what it does and we don't

1758
02:01:46,570 --> 02:01:49,690
no what does this mean that the plot of the into put variables make sure


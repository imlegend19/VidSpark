1
00:00:00,000 --> 00:00:04,830
i'm going to turn only then the graph here

2
00:00:04,880 --> 00:00:08,230
and the then graph created electric field

3
00:00:08,250 --> 00:00:11,400
so we have the vendor graph here

4
00:00:11,460 --> 00:00:13,440
let's suppose that this vendor graphs

5
00:00:13,440 --> 00:00:18,360
creates positive charge sometimes and graph creates positive charge on the dome others can be

6
00:00:18,360 --> 00:00:22,170
designed to create negative charge on the

7
00:00:22,170 --> 00:00:26,000
remember from now lies on the positive

8
00:00:26,040 --> 00:00:28,020
what will happen

9
00:00:28,090 --> 00:00:30,350
electrons want to go in this election

10
00:00:30,440 --> 00:00:32,080
so this becomes negative

11
00:00:33,440 --> 00:00:35,440
the positive charge stays behind

12
00:00:35,480 --> 00:00:38,250
but that becomes through induction the dipole

13
00:00:38,270 --> 00:00:40,040
because i have connected

14
00:00:40,040 --> 00:00:42,500
i have been connected with these metal bars

15
00:00:42,520 --> 00:00:45,350
so these electrons can flow through his bar

16
00:00:45,360 --> 00:00:46,830
and up here

17
00:00:47,880 --> 00:00:49,920
i removed the bar

18
00:00:49,920 --> 00:00:51,730
so when i removed the bar

19
00:00:51,830 --> 00:00:53,380
i have created now

20
00:00:54,830 --> 00:00:57,230
i have here

21
00:00:57,230 --> 00:00:59,860
insulating thread then the fishing rod

22
00:00:59,880 --> 00:01:01,790
and at the end of my fishing rod

23
00:01:01,830 --> 00:01:05,090
i have no permanent dipole

24
00:01:05,150 --> 00:01:06,880
with a permanent dipole

25
00:01:06,940 --> 00:01:11,560
i'm not going to probe the electric field around this then the graph

26
00:01:11,560 --> 00:01:14,590
i could have chosen the same then the graph but there's a reason why i

27
00:01:14,590 --> 00:01:15,770
think this one

28
00:01:15,790 --> 00:01:18,250
and as i walk around this when the graph

29
00:01:18,270 --> 00:01:19,480
you will see

30
00:01:19,500 --> 00:01:24,070
that this fishing rod at the end is this dipole that the dipole always wanted

31
00:01:24,070 --> 00:01:28,130
to go radially inwards or outwards depending on how you look at it on this

32
00:01:28,150 --> 00:01:32,230
field i can probe this field and make you see for the first time that

33
00:01:32,230 --> 00:01:33,330
there is indeed

34
00:01:33,350 --> 00:01:36,040
somewhere here a strong radio field

35
00:01:36,060 --> 00:01:37,880
going in or out of the

36
00:01:37,900 --> 00:01:39,710
then the graph

37
00:01:39,710 --> 00:01:43,310
and now comes something very interesting which i found out this morning for the first

38
00:01:43,310 --> 00:01:47,210
time when i did this experiment

39
00:01:47,270 --> 00:01:49,230
if the other than the graph

40
00:01:50,520 --> 00:01:53,940
it is also positive when i run it

41
00:01:53,940 --> 00:01:57,350
how do you think this dipole is going to align them

42
00:01:57,380 --> 00:01:59,060
if i walk into it

43
00:01:59,060 --> 00:02:01,880
will the negative pole

44
00:02:01,880 --> 00:02:07,880
the closer to the then graph although the positive one go closer to defend ground

45
00:02:07,920 --> 00:02:11,060
so i give you thirty seconds to think about it so i make the dipole

46
00:02:11,060 --> 00:02:14,810
as it is here let's assume this one is positive this pentagram

47
00:02:14,850 --> 00:02:16,350
so this site becomes

48
00:02:18,000 --> 00:02:20,810
call it a this site becomes

49
00:02:20,830 --> 00:02:25,880
positive that's been i now walk which is

50
00:02:25,880 --> 00:02:27,860
type libraries in this field

51
00:02:27,860 --> 00:02:31,960
let's assume that one is also positive we don't know that yet

52
00:02:31,980 --> 00:02:35,150
however the dipole line now will go

53
00:02:35,170 --> 00:02:38,190
in words or will they go out for

54
00:02:38,310 --> 00:02:40,850
o things a goes in words

55
00:02:40,850 --> 00:02:43,630
very good who says a goes outwards

56
00:02:43,650 --> 00:02:45,380
OK able going work

57
00:02:46,630 --> 00:02:48,360
the two when the grass

58
00:02:48,360 --> 00:02:49,900
have the same polarity

59
00:02:50,000 --> 00:02:51,920
so if that doesn't happen

60
00:02:52,000 --> 00:02:56,400
that doesn't mean that physics doesn't work it means the two then the ground have

61
00:02:56,400 --> 00:02:59,440
different polarities we'll see what happens

62
00:02:59,460 --> 00:03:01,790
so let me first then create

63
00:03:01,830 --> 00:03:04,090
a dipole

64
00:03:04,150 --> 00:03:05,130
so here is the

65
00:03:05,150 --> 00:03:06,730
the dipole

66
00:03:06,750 --> 00:03:09,520
it's sorted out now

67
00:03:09,520 --> 00:03:10,980
i turn on the

68
00:03:11,040 --> 00:03:13,040
this been the graph

69
00:03:13,060 --> 00:03:15,690
two induction takes place remember that the yellow

70
00:03:15,750 --> 00:03:18,350
is pointing towards the then the graph

71
00:03:18,350 --> 00:03:23,790
and that the audience is away from the van graph

72
00:03:25,020 --> 00:03:26,830
so i induces dipole

73
00:03:26,850 --> 00:03:29,150
i really should we do that

74
00:03:29,190 --> 00:03:33,960
i don't know what happens when it

75
00:03:34,000 --> 00:03:36,230
after we moved field first

76
00:03:37,210 --> 00:03:40,020
yellow was inside right was that the weight was

77
00:03:41,000 --> 00:03:43,810
yellow inside

78
00:03:43,850 --> 00:03:46,540
there we go

79
00:03:46,580 --> 00:03:54,520
about creating dipole through these metal boy

80
00:03:54,580 --> 00:03:56,960
and i break contacts

81
00:03:56,980 --> 00:03:59,610
and this should now be that

82
00:03:59,610 --> 00:04:01,110
now i turn on the

83
00:04:01,130 --> 00:04:05,000
field of the

84
00:04:05,000 --> 00:04:07,420
so if the polarity is the same

85
00:04:07,500 --> 00:04:15,250
yellow going

86
00:04:15,250 --> 00:04:16,750
i will try to swing in little

87
00:04:16,750 --> 00:04:22,040
i noticed two things going to line up beautifully radially

88
00:04:22,090 --> 00:04:23,730
but the yellow

89
00:04:23,750 --> 00:04:25,590
it's not in yellow without

90
00:04:25,610 --> 00:04:28,580
there two hundred about have different polarities

91
00:04:28,610 --> 00:04:31,000
you see they rotate nicely

92
00:04:31,020 --> 00:04:34,210
and they and the beautiful radio

93
00:04:34,290 --> 00:04:39,000
when i go all the way around here

94
00:04:41,520 --> 00:04:44,560
i may swing a little they may also made a little bit through them think

95
00:04:44,560 --> 00:04:46,400
they will come to all

96
00:04:46,440 --> 00:04:48,500
look the field is indeed

97
00:04:48,520 --> 00:04:50,060
beautiful radio

98
00:04:50,080 --> 00:04:52,110
and the and always

99
00:04:52,110 --> 00:04:54,440
so to speak on the wrong side

100
00:04:54,480 --> 00:04:55,980
two when the graph

101
00:04:56,020 --> 00:04:59,860
have different polarities

102
00:04:59,880 --> 00:05:02,850
so you see how we can create dipole

103
00:05:02,860 --> 00:05:04,250
and you've also seen

104
00:05:04,270 --> 00:05:05,420
how we often

105
00:05:05,440 --> 00:05:08,060
can make statements about

106
00:05:08,110 --> 00:05:17,060
the specific polarity

107
00:05:17,170 --> 00:05:21,020
i can probably electric field

108
00:05:21,020 --> 00:05:27,040
using grass seeds in all

109
00:05:27,080 --> 00:05:29,420
grass seeds

110
00:05:31,690 --> 00:05:34,830
and when i photographed scenes in an electric field

111
00:05:34,920 --> 00:05:39,690
it will become polarized there's nothing you can do about it using grassy

112
00:05:39,730 --> 00:05:42,770
and the electric field is like so

113
00:05:42,770 --> 00:05:50,330
and so the electrons one goes far away in this direction is they can induction

114
00:05:50,360 --> 00:05:54,560
and so this site remains positive and so what is this grassy going to do

115
00:05:54,610 --> 00:05:55,920
going to rotate

116
00:05:55,940 --> 00:05:58,770
it's going to line up with the electric field

117
00:05:58,770 --> 00:06:02,910
is an object that is floating in the liquid in water

118
00:06:02,920 --> 00:06:06,240
and if if i pushed a little further in

119
00:06:06,280 --> 00:06:08,670
let it go

120
00:06:10,220 --> 00:06:15,900
and there is a very unique frequency that you will be able to calculate

121
00:06:15,950 --> 00:06:18,180
eight o three

122
00:06:18,220 --> 00:06:21,350
there unique period of one complete oscillation

123
00:06:21,400 --> 00:06:23,160
as this object

124
00:06:23,160 --> 00:06:26,400
goes up and down

125
00:06:26,450 --> 00:06:28,720
even when steady winds

126
00:06:28,740 --> 00:06:31,210
can generate

127
00:06:31,280 --> 00:06:37,110
periodic almost periodic motions which all of you have experience you walk outside

128
00:06:37,200 --> 00:06:38,760
the wind in your hair

129
00:06:38,780 --> 00:06:39,900
goes like this

130
00:06:39,900 --> 00:06:44,970
that doesn't go about like this always has this tendency just like a flag does

131
00:06:44,970 --> 00:06:46,470
the same thing

132
00:06:46,540 --> 00:06:49,580
if i generally do in here

133
00:06:49,630 --> 00:06:52,530
and i have used similar

134
00:06:52,640 --> 00:06:53,800
you'll see

135
00:06:53,890 --> 00:06:55,510
that this went

136
00:06:55,520 --> 00:06:58,130
doesn't make the aluminum just go

137
00:07:00,590 --> 00:07:11,090
well there's a certain period to that

138
00:07:11,140 --> 00:07:13,130
after work

139
00:07:13,170 --> 00:07:17,150
if you want to have some fun

140
00:07:17,200 --> 00:07:19,530
what is more fun

141
00:07:20,270 --> 00:07:22,040
writing your own

142
00:07:27,410 --> 00:07:31,950
that's the periodic motion

143
00:07:31,970 --> 00:07:36,470
falling in love can be periodic events

144
00:07:36,480 --> 00:07:38,540
now i don't do it too often

145
00:07:38,550 --> 00:07:40,970
because most of you know

146
00:07:40,980 --> 00:07:43,700
quite exhausting

147
00:07:43,710 --> 00:07:45,730
the motion of electrons

148
00:07:45,780 --> 00:07:46,840
out of this

149
00:07:48,840 --> 00:07:52,300
periodic an oscillatory

150
00:07:52,350 --> 00:07:53,660
the motion of the moon

151
00:07:53,700 --> 00:07:56,190
the planets and the stars

152
00:07:57,620 --> 00:08:00,630
all symmetry

153
00:08:01,810 --> 00:08:05,190
is a beautiful example

154
00:08:05,250 --> 00:08:10,320
i produce sound

155
00:08:10,400 --> 00:08:14,740
i produce sound by oscillating my vocal cords

156
00:08:14,850 --> 00:08:20,660
i use thereby pressure waves my vocal cords whose only air circle the air push

157
00:08:20,660 --> 00:08:21,560
on the air

158
00:08:21,620 --> 00:08:25,130
which produces a pressure wave and the pressure wave propagates out

159
00:08:25,170 --> 00:08:26,650
in the lecture hall

160
00:08:26,660 --> 00:08:29,980
reaches UEFA euro start to

161
00:08:30,000 --> 00:08:31,660
move back and forth

162
00:08:31,710 --> 00:08:32,520
and you

163
00:08:32,530 --> 00:08:34,320
your brains tell you

164
00:08:34,330 --> 00:08:36,150
that you here

165
00:08:36,190 --> 00:08:39,620
a sound

166
00:08:39,690 --> 00:08:42,280
i have you tuning fork

167
00:08:42,360 --> 00:08:45,950
which is designed so that if i give it a bit

168
00:08:46,030 --> 00:08:49,390
at the problems move two hundred fifty six times per second

169
00:08:49,430 --> 00:08:52,370
recall that two hundred fifty six hertz

170
00:08:52,530 --> 00:08:56,620
works is one oscillations per second

171
00:08:56,770 --> 00:09:05,960
on the or you can hear them russia where you generate and we will deal

172
00:09:05,960 --> 00:09:08,260
with them and they don't three

173
00:09:09,510 --> 00:09:13,670
forty air reaches you draw your own starts to shape this is a high frequency

174
00:09:13,670 --> 00:09:15,140
four hundred forty words

175
00:09:15,260 --> 00:09:24,660
most human beings

176
00:09:24,710 --> 00:09:26,010
can you hear

177
00:09:26,050 --> 00:09:28,490
in the range from twenty words

178
00:09:28,530 --> 00:09:30,230
twenty kilometres

179
00:09:30,240 --> 00:09:32,660
animals who can go beyond

180
00:09:32,680 --> 00:09:36,540
twenty kilometres

181
00:09:36,560 --> 00:09:37,680
and to be nice

182
00:09:37,690 --> 00:09:40,640
you for the first time this first lecture

183
00:09:40,670 --> 00:09:45,980
i would like to test your hearing and that will be free of charge

184
00:09:46,030 --> 00:09:50,180
i'm not so much interested in knowing what your lowest frequency is but what your

185
00:09:50,180 --> 00:09:54,120
highest frequencies

186
00:09:54,160 --> 00:09:58,510
i'm going to generate here sound i'll start with hundred

187
00:09:58,530 --> 00:10:01,780
they will go up higher and higher and then we'll see

188
00:10:01,790 --> 00:10:06,660
where you ewing stops

189
00:10:06,670 --> 00:10:09,860
so let's start with hundred hertz

190
00:10:09,880 --> 00:10:17,410
i'm not going to ask you can hear it because clearly all of you can

191
00:10:17,640 --> 00:10:18,430
now go

192
00:10:18,460 --> 00:10:32,400
a bit of a thousand or so like my that not

193
00:10:32,400 --> 00:10:35,900
changed my

194
00:10:35,900 --> 00:10:40,930
four thousand

195
00:10:40,940 --> 00:10:43,860
you know

196
00:10:43,870 --> 00:10:47,380
there little less

197
00:10:52,780 --> 00:11:00,410
six thousand

198
00:11:00,500 --> 00:11:02,270
one of my own

199
00:11:09,030 --> 00:11:19,540
while i i was

200
00:11:19,640 --> 00:11:29,790
agent using the heuristic really first of all

201
00:11:29,930 --> 00:11:40,300
more the case as

202
00:11:42,710 --> 00:11:46,870
forty thousand dollars a year hands you can your

203
00:11:47,610 --> 00:11:48,820
you can not here

204
00:11:48,830 --> 00:11:50,060
forty thousand

205
00:11:50,140 --> 00:11:54,770
don't be ashamed of it's not your fault

206
00:11:54,810 --> 00:11:56,930
forty thousand

207
00:11:57,010 --> 00:12:03,750
all right this photo about fifty thousand coconut you raise your hands first of all

208
00:12:03,790 --> 00:12:06,800
you're getting all

209
00:12:06,930 --> 00:12:11,390
sixty thousand

210
00:12:11,440 --> 00:12:14,850
we cannot sixty is of course the ones we already raised and you don't have

211
00:12:14,850 --> 00:12:16,060
to raise your hand

212
00:12:16,080 --> 00:12:19,280
o canal sixty thousand coconuts

213
00:12:19,300 --> 00:12:23,560
seventeen thousand

214
00:12:23,640 --> 00:12:26,780
eighteen thousand

215
00:12:26,860 --> 00:12:30,710
OK so now we're going to change and i want you to raise your hands

216
00:12:30,740 --> 00:12:33,480
if you can hear it

217
00:12:33,490 --> 00:12:35,380
so i first go

218
00:12:36,240 --> 00:12:38,910
twenty thousand

219
00:12:38,920 --> 00:12:44,530
ninety thousand hundred ninety thousand or so

220
00:12:44,640 --> 00:12:47,850
i was only on by factor of ten

221
00:12:47,860 --> 00:12:51,900
ninety thousand will can

222
00:12:51,920 --> 00:12:53,450
but that's the

223
00:12:53,460 --> 00:12:58,100
twenty thousand

224
00:12:58,150 --> 00:13:00,750
twenty one

225
00:13:01,990 --> 00:13:03,360
the outcome of

226
00:13:03,400 --> 00:13:04,570
very short

227
00:13:04,660 --> 00:13:07,210
twenty two

228
00:13:07,240 --> 00:13:08,400
very good

229
00:13:08,410 --> 00:13:10,400
twenty two

230
00:13:10,400 --> 00:13:14,820
twenty three

231
00:13:14,830 --> 00:13:19,500
twenty five

232
00:13:19,540 --> 00:13:22,070
twenty seven

233
00:13:23,360 --> 00:13:25,120
so of you have an amazing

234
00:13:25,170 --> 00:13:29,830
because i really talking about twenty one thousand

235
00:13:30,080 --> 00:13:45,030
all right

236
00:13:46,350 --> 00:13:50,030
absolutely key in this course will be simple

237
00:13:50,030 --> 00:13:52,400
harmonic oscillations

238
00:13:52,410 --> 00:13:54,150
because they are extremely common

239
00:13:54,160 --> 00:13:56,730
in nature

240
00:13:56,740 --> 00:14:00,440
the simple harmonic oscillation

241
00:14:00,440 --> 00:14:05,340
our dictionary and forcing things at least up to huge

242
00:14:05,370 --> 00:14:07,110
what we decided to do

243
00:14:07,120 --> 00:14:10,830
we decided to be as much as possible in memory

244
00:14:11,410 --> 00:14:14,330
creating a dump on all these

245
00:14:14,340 --> 00:14:17,680
all this temporary part of inverted index

246
00:14:17,770 --> 00:14:19,740
and then merge

247
00:14:20,770 --> 00:14:23,240
this temporary index

248
00:14:23,280 --> 00:14:26,080
and this is exactly what we are doing

249
00:14:28,120 --> 00:14:32,470
created all modelling memory something like this

250
00:14:32,560 --> 00:14:34,710
fourteen two

251
00:14:34,740 --> 00:14:38,790
imagine that we are building viagra more

252
00:14:38,850 --> 00:14:44,260
or OK let's start this unigram model building unigram model and the

253
00:14:44,260 --> 00:14:45,020
i have

254
00:14:45,070 --> 00:14:48,240
the whole memory filled with our dictionary

255
00:14:48,280 --> 00:14:49,990
what are doing

256
00:14:50,050 --> 00:14:54,110
this simply setting this

257
00:14:54,160 --> 00:14:56,850
this information file

258
00:14:56,860 --> 00:14:59,100
started by

259
00:15:01,340 --> 00:15:02,330
it will be

260
00:15:02,340 --> 00:15:08,710
a a then count how many times so first more than worthy this etcetera etcetera

261
00:15:08,710 --> 00:15:10,580
after the

262
00:15:11,620 --> 00:15:13,220
the whole

263
00:15:13,260 --> 00:15:16,600
the whole collection

264
00:15:16,650 --> 00:15:20,790
we can merge this file using of the way in which all there is a

265
00:15:21,960 --> 00:15:25,700
and create all the models

266
00:15:25,750 --> 00:15:28,330
so far so rules so

267
00:15:28,350 --> 00:15:30,900
wait using this approach

268
00:15:30,940 --> 00:15:32,510
we can process

269
00:15:32,560 --> 00:15:38,080
and any number of documents for building of our models

270
00:15:38,120 --> 00:15:44,030
how why and say why and talking not about probabilities but about content

271
00:15:44,050 --> 00:15:46,170
why we need to save only

272
00:15:47,500 --> 00:15:49,300
abduction festival

273
00:15:49,320 --> 00:15:52,860
if it's safe probabilities during the

274
00:15:52,940 --> 00:15:55,160
we kent updated

275
00:15:56,750 --> 00:16:01,060
it's not so we need also to know the whole number of documents

276
00:16:01,090 --> 00:16:01,870
you can

277
00:16:01,880 --> 00:16:04,010
try to do this simple math

278
00:16:04,030 --> 00:16:04,840
if you

279
00:16:05,530 --> 00:16:07,340
one hundred documents

280
00:16:07,350 --> 00:16:09,490
and you have

281
00:16:09,530 --> 00:16:13,600
five documents really that with this work

282
00:16:14,910 --> 00:16:16,250
you are added

283
00:16:16,260 --> 00:16:22,610
one hundred one document and you see this word sokol can calculate probability if you

284
00:16:24,070 --> 00:16:25,860
o point zero five

285
00:16:25,920 --> 00:16:29,910
i don't know what to do it you need to multiply it again to the

286
00:16:29,910 --> 00:16:34,750
whole counter this number so you need to you need to say i can't

287
00:16:34,760 --> 00:16:37,350
and finally merging indexes

288
00:16:37,410 --> 00:16:39,840
also it's much simpler to keep

289
00:16:39,880 --> 00:16:45,680
can't because it's simply and one column to another gratings inside

290
00:16:45,680 --> 00:16:49,470
and you don't need to do any other irishmen

291
00:16:49,480 --> 00:16:55,320
when we have result probabilistic model in memory when we already created it in good

292
00:16:55,320 --> 00:16:56,780
one to use

293
00:16:57,200 --> 00:17:00,060
and want to use this probability

294
00:17:00,090 --> 00:17:02,170
it's always

295
00:17:02,170 --> 00:17:07,380
better to use not real probabilities but lottery

296
00:17:07,490 --> 00:17:11,170
because of these probabilities in real life

297
00:17:11,190 --> 00:17:14,170
are extremely small numbers

298
00:17:14,190 --> 00:17:19,610
and if you combine the small number especially when you multiply these numbers

299
00:17:19,670 --> 00:17:21,360
you can easily get

300
00:17:21,380 --> 00:17:24,510
on the floor you can easily get zero

301
00:17:25,420 --> 00:17:28,470
in my experience it is extremely

302
00:17:28,480 --> 00:17:30,100
common situation

303
00:17:30,120 --> 00:17:34,210
when people are creating some probabilistic algorithms

304
00:17:34,210 --> 00:17:37,260
they calculated probabilities for small model

305
00:17:37,310 --> 00:17:39,280
everything works fine

306
00:17:39,290 --> 00:17:41,810
then this this stuff

307
00:17:41,860 --> 00:17:43,730
the government

308
00:17:44,860 --> 00:17:49,670
at this moment suddenly the model became very strange and they don't understand what's going

309
00:17:50,690 --> 00:17:54,610
and usually because of underfloor

310
00:17:54,630 --> 00:17:55,940
if you are working with

311
00:17:57,310 --> 00:18:00,760
the most common operation is multiplication

312
00:18:00,800 --> 00:18:04,260
because usually have assumptions about independence

313
00:18:04,270 --> 00:18:07,410
and look there is a presentation is extremely

314
00:18:07,460 --> 00:18:11,190
good for this type of operation

315
00:18:11,240 --> 00:18:15,170
what we need to do any single image

316
00:18:15,240 --> 00:18:19,000
need to some our probability

317
00:18:21,030 --> 00:18:24,420
sometimes we need to some probability

318
00:18:24,440 --> 00:18:26,610
when we again have

319
00:18:27,050 --> 00:18:31,790
independence assumptions have assumption that this event network

320
00:18:31,850 --> 00:18:36,720
i care together and we want to calculate the probability

321
00:18:36,730 --> 00:18:38,280
in this case

322
00:18:40,160 --> 00:18:42,620
senior programmers doing

323
00:18:42,670 --> 00:18:43,820
he taken

324
00:18:43,840 --> 00:18:44,730
some blue

325
00:18:44,730 --> 00:18:46,240
unlike the rest

326
00:18:46,250 --> 00:18:50,190
and his writing some form like this

327
00:18:51,200 --> 00:18:53,570
again during

328
00:18:53,630 --> 00:18:57,500
are usually during the and it some presentations

329
00:18:57,500 --> 00:19:01,700
capital and which is the number of molecules divided by the volume is also

330
00:19:01,730 --> 00:19:03,760
the divided by katie

331
00:19:03,850 --> 00:19:05,580
so this is a

332
00:19:05,590 --> 00:19:06,930
five by katie

333
00:19:06,940 --> 00:19:09,790
times and

334
00:19:11,040 --> 00:19:12,490
i take this

335
00:19:12,500 --> 00:19:16,170
creation and i say i

336
00:19:17,860 --> 00:19:21,340
equals minus

337
00:19:22,010 --> 00:19:25,420
divided by katie

338
00:19:27,810 --> 00:19:31,840
i'm going to be on the here and i think to divide there

339
00:19:31,850 --> 00:19:33,850
so we get the

340
00:19:33,890 --> 00:19:35,650
divided by p

341
00:19:35,700 --> 00:19:37,670
equals minus

342
00:19:39,450 --> 00:19:41,150
defined by kt

343
00:19:41,350 --> 00:19:43,280
some kind of constant

344
00:19:43,320 --> 00:19:45,780
and the y

345
00:19:45,830 --> 00:19:48,920
first talk about that constant

346
00:19:48,980 --> 00:19:51,530
constant must have the dimensions

347
00:19:51,620 --> 00:19:53,800
one divided by meteors

348
00:19:53,820 --> 00:19:57,530
because this is the mention this pressure divided by pressure no mention

349
00:19:57,580 --> 00:19:59,820
the y has dimension of length

350
00:19:59,870 --> 00:20:03,300
but this must have that i mentioned one of length

351
00:20:03,350 --> 00:20:05,680
in fact i can calculate

352
00:20:05,740 --> 00:20:07,220
what katy

353
00:20:07,220 --> 00:20:08,850
over g

354
00:20:08,890 --> 00:20:12,100
but you don't have the dimension of length

355
00:20:12,100 --> 00:20:13,910
i know OK

356
00:20:13,930 --> 00:20:18,390
i know t i take zero degrees centigrade so these two seventy three

357
00:20:18,430 --> 00:20:20,320
i know which is

358
00:20:20,370 --> 00:20:22,870
what i take for the molecule

359
00:20:22,930 --> 00:20:26,390
a molecule of air was an animal well

360
00:20:26,450 --> 00:20:27,370
we have

361
00:20:27,450 --> 00:20:29,660
twenty percent oxygen

362
00:20:29,680 --> 00:20:31,950
we have eighty percent nitrogen

363
00:20:31,950 --> 00:20:34,030
the atomic mass number of

364
00:20:34,080 --> 00:20:35,680
up to thirty two

365
00:20:35,720 --> 00:20:37,870
nitrogen twenty eight

366
00:20:37,930 --> 00:20:40,050
but really there is more nitrogen than

367
00:20:41,200 --> 00:20:43,050
so take twenty nine

368
00:20:43,100 --> 00:20:48,800
as a reasonable atomic mass number four mean mass of a molecule and show you

369
00:20:48,800 --> 00:20:51,050
get them that is roughly twenty nine

370
00:20:51,100 --> 00:20:53,550
times the one point six six

371
00:20:53,570 --> 00:20:56,660
i'm standing minus twenty seven kilogram

372
00:20:56,760 --> 00:21:00,200
he stayed in that equation you can be too far off

373
00:21:00,220 --> 00:21:01,990
and what you find

374
00:21:01,990 --> 00:21:04,800
this is a thousand metres

375
00:21:05,300 --> 00:21:06,490
has unit length

376
00:21:06,510 --> 00:21:08,760
or it is a two kilometres

377
00:21:08,800 --> 00:21:10,320
and we call this

378
00:21:10,340 --> 00:21:13,640
eight zero

379
00:21:13,700 --> 00:21:19,870
so i will rewrite so little

380
00:21:19,930 --> 00:21:22,660
what always was done with the integration

381
00:21:22,720 --> 00:21:24,970
i rewrite

382
00:21:24,990 --> 00:21:28,870
created and introduced for that constant

383
00:21:28,950 --> 00:21:31,760
one of the eight zero

384
00:21:31,970 --> 00:21:35,580
hmm i turned upside down there to get links

385
00:21:35,600 --> 00:21:37,600
so we have the p

386
00:21:37,620 --> 00:21:39,260
over the

387
00:21:39,280 --> 00:21:42,470
one minus one of eight zero

388
00:21:44,200 --> 00:21:45,340
i integrate

389
00:21:45,470 --> 00:21:48,570
two zero which is sea level

390
00:21:48,620 --> 00:21:51,370
and he at some altitude h

391
00:21:51,370 --> 00:21:52,320
so the y

392
00:21:52,340 --> 00:21:54,200
these are all the sea level

393
00:21:54,220 --> 00:21:55,970
altitude h

394
00:21:55,970 --> 00:21:57,640
that's an easy integral

395
00:21:57,680 --> 00:21:58,700
so i get

396
00:21:58,700 --> 00:22:00,580
l m

397
00:22:03,200 --> 00:22:04,910
altitude h

398
00:22:04,990 --> 00:22:09,240
divided by p zero

399
00:22:09,240 --> 00:22:11,030
he calls

400
00:22:11,070 --> 00:22:12,930
minus eight

401
00:22:12,950 --> 00:22:18,030
five by zero because the integral of the y from zero to eighty simply age

402
00:22:18,070 --> 00:22:19,890
so i find no

403
00:22:20,850 --> 00:22:22,300
the pressure at

404
00:22:22,350 --> 00:22:24,260
altitude h

405
00:22:24,280 --> 00:22:26,660
because two because he zero

406
00:22:26,680 --> 00:22:29,820
i'm the mines h

407
00:22:29,850 --> 00:22:30,890
divided by eight

408
00:22:33,700 --> 00:22:36,680
this is the altitude in the atmosphere

409
00:22:36,680 --> 00:22:40,780
and if you take this page then this is the altitude kilometres h zero down

410
00:22:43,700 --> 00:22:46,010
so if you use this equation

411
00:22:46,050 --> 00:22:49,930
you can calculate what the pressure is at various altitudes general atmosphere and that's not

412
00:22:49,930 --> 00:22:50,870
a bad

413
00:22:50,910 --> 00:22:54,970
approximation error is a point nine kilometres high

414
00:22:55,030 --> 00:22:59,910
uses equation you will find that the atmospheric pressure is there only one-third

415
00:22:59,930 --> 00:23:01,340
of what we have here

416
00:23:01,390 --> 00:23:04,050
none of oxygen to live

417
00:23:04,100 --> 00:23:07,200
i did quite a bit of observing and

418
00:23:08,050 --> 00:23:12,160
observatory in chile which was at an altitude of twenty four hundred metres

419
00:23:12,160 --> 00:23:16,530
so you can feel that so this is the same as the probability of observing

420
00:23:16,530 --> 00:23:19,800
infinitely many more given finite limit one

421
00:23:19,860 --> 00:23:23,390
if you compute the probability in the baseline plus models

422
00:23:23,510 --> 00:23:26,560
you get identically zero

423
00:23:27,990 --> 00:23:30,780
you may argue that that there because i mean

424
00:23:30,830 --> 00:23:34,600
it's pretty unlikely that the road will exist forever

425
00:23:36,720 --> 00:23:40,200
that would mean that on the contrary the probability that a lot

426
00:23:40,210 --> 00:23:42,600
infinity given one b is one

427
00:23:42,610 --> 00:23:46,290
so you will be absolutely sure that the world exists whatever

428
00:23:46,300 --> 00:23:48,660
and this seems like a ridiculous statement

429
00:23:50,010 --> 00:23:53,520
so the baseline plus model

430
00:23:53,540 --> 00:23:55,390
cannot cope with the situation

431
00:23:55,470 --> 00:23:56,910
and this is yet

432
00:23:56,920 --> 00:24:01,580
phrase terms of raven paradox you observed in black ravens you ask whether all ravens

433
00:24:01,580 --> 00:24:02,970
are black

434
00:24:02,970 --> 00:24:06,560
and the basic plus one you get identically zero

435
00:24:06,580 --> 00:24:07,540
which is

436
00:24:09,060 --> 00:24:10,660
to most people

437
00:24:10,670 --> 00:24:14,330
why if you choose uniform is universal prior

438
00:24:14,340 --> 00:24:16,850
you can show that rapidly converges to one

439
00:24:16,850 --> 00:24:21,100
with the rate which seems reasonable

440
00:24:21,150 --> 00:24:24,900
well solved the black ravens paradox

441
00:24:24,930 --> 00:24:26,510
the main reason is

442
00:24:26,520 --> 00:24:29,720
in the baseline plus model prior density

443
00:24:29,720 --> 00:24:31,350
so the probability

444
00:24:31,360 --> 00:24:33,370
of ten to equal one is

445
00:24:35,110 --> 00:24:40,020
and you start with zero prior going here this in discrete models having non-zero prior

446
00:24:40,020 --> 00:24:41,240
for all

447
00:24:41,290 --> 00:24:44,770
compute the hypothesis

448
00:24:44,810 --> 00:24:50,650
then parameterisation environment is very important which i mentioned before you go from ten the

449
00:24:50,650 --> 00:24:54,170
ten square you would not like you know to get different answers

450
00:24:54,180 --> 00:24:55,450
jeffreys prior

451
00:24:56,140 --> 00:24:58,220
but this problem in small spaces

452
00:24:58,220 --> 00:24:59,350
and you can show

453
00:24:59,390 --> 00:25:03,220
that the universe proprietary power station in four

454
00:25:03,300 --> 00:25:05,990
is large space

455
00:25:06,010 --> 00:25:08,560
then there the so-called problem of all evidence

456
00:25:11,660 --> 00:25:14,740
you have your data before you start modelling

457
00:25:14,780 --> 00:25:20,060
and then you could cheat mean either consciousness lead or unconsciously so you you bias

458
00:25:20,060 --> 00:25:22,040
everything to what your data

459
00:25:22,090 --> 00:25:24,550
and then things go wrong

460
00:25:24,560 --> 00:25:27,420
but if you take is universal prior

461
00:25:27,450 --> 00:25:29,480
even if you know your data

462
00:25:29,490 --> 00:25:32,150
before you start i mean you know the price of two to the ninth the

463
00:25:32,150 --> 00:25:34,600
commonwealth complexity of hypothesis

464
00:25:34,670 --> 00:25:39,480
whatever you are now try to cheat although by assume all my model you sort

465
00:25:39,480 --> 00:25:42,420
of to the data you can do that but then i mean you get a

466
00:25:42,420 --> 00:25:44,700
complex model and you get paid for

467
00:25:44,710 --> 00:25:47,280
there is no way of treating anymore

468
00:25:48,790 --> 00:25:53,280
another problem which is formally solved often when you start with the patient

469
00:25:53,490 --> 00:25:57,160
you start them on the class and then you make some observations then you see

470
00:25:57,160 --> 00:26:01,830
OK this multiclass class was small micro outside and then you make some adaptation

471
00:26:01,910 --> 00:26:04,520
if you start with the big class of new

472
00:26:04,530 --> 00:26:09,670
you never fall outside except the discovers and computer was

473
00:27:00,490 --> 00:27:08,480
so you argument this class may be unnecessarily large so

474
00:27:08,610 --> 00:27:15,660
what things

475
00:27:20,170 --> 00:27:21,400
but OK

476
00:27:26,670 --> 00:27:35,990
it is what does it mean the last and maybe there's not computable physics but

477
00:27:35,990 --> 00:27:39,230
as long as it's computer but it's in the class but

478
00:27:39,570 --> 00:27:43,080
so there is no evidence of course i mean you know we can never be

479
00:27:43,080 --> 00:27:44,680
sure so

480
00:27:45,380 --> 00:27:49,740
what if we detect uncomputable physics then you know many things break down i mean

481
00:27:49,740 --> 00:27:53,140
all the concept i mean of of universal turing machines

482
00:27:53,340 --> 00:27:56,270
the true church doing and all these things

483
00:27:56,760 --> 00:27:59,480
i guess

484
00:27:59,550 --> 00:28:03,690
the main things can be rescued i mean at least i mean if this extend

485
00:28:03,690 --> 00:28:07,640
the class which includes uncomputable physics i mean that you just don't do the same

486
00:28:07,640 --> 00:28:09,740
thing with this larger class

487
00:28:10,430 --> 00:28:13,910
of course then you can say OK i mean look here extending model i mean

488
00:28:13,910 --> 00:28:17,060
like everybody else does it gets bigger and bigger

489
00:28:17,800 --> 00:28:20,710
i mean at least for you know a couple of hundred years now

490
00:28:20,740 --> 00:28:23,180
this computational hypothesis is

491
00:28:24,510 --> 00:28:25,930
i mean of course you can never be

492
00:28:25,980 --> 00:28:31,740
sure and in any case is the largest multiclass anybody uses

493
00:28:31,780 --> 00:28:36,420
except for a few exotic doing things you there might be some uncomputable physics and

494
00:28:36,420 --> 00:28:38,090
so on

495
00:29:06,040 --> 00:29:14,900
these are mainly to criticism in one way the biological system popular physical over there

496
00:29:14,940 --> 00:29:17,050
something else so i don't believe that

497
00:29:17,060 --> 00:29:21,890
and the other question is the problem of separating the observer from the system which

498
00:29:21,890 --> 00:29:25,630
is quite interesting because if you say the universe you know you can simulate you

499
00:29:25,630 --> 00:29:26,910
know any computable way

500
00:29:26,940 --> 00:29:33,160
well now you have to carve out somehow this AI system from the environment and

501
00:29:33,190 --> 00:29:37,040
and that gets really tricky especially in the maximum which explain later because they assume

502
00:29:37,040 --> 00:29:40,410
that the rows computable but the model itself is not computable i mean that should

503
00:29:40,410 --> 00:29:44,320
not be the case it's in our universe and yet the issues

504
00:29:45,310 --> 00:29:47,420
but it's

505
00:29:47,800 --> 00:29:53,330
but nevertheless i compared to what people assume normally this is really i mean

506
00:29:53,390 --> 00:29:54,940
enormously we

507
00:29:54,950 --> 00:29:56,950
and i can't see it or any

508
00:29:56,960 --> 00:30:03,680
reason at the moment you to make it more week

509
00:30:07,150 --> 00:30:09,540
and what we can also show finally so

510
00:30:09,550 --> 00:30:12,280
in the case of of of continuous model

511
00:30:12,310 --> 00:30:16,910
i said you only assign non-zero probability two

512
00:30:18,330 --> 00:30:19,960
a discrete subset

513
00:30:19,980 --> 00:30:24,680
and from the physics perspective is good enough i mean maybe you think of this

514
00:30:24,680 --> 00:30:28,860
calling independent and why should know the bias b computable

515
00:30:28,900 --> 00:30:32,330
but if you think about it if everything is computable then also the bias computer

516
00:30:32,330 --> 00:30:37,200
but many statisticians don't like to say OK i mean you know even if it

517
00:30:37,200 --> 00:30:40,500
may be philosophically true i mean it's you know

518
00:30:40,500 --> 00:30:43,040
any more observations

519
00:30:43,120 --> 00:30:44,280
can proceed

520
00:30:44,290 --> 00:30:48,370
OK so let's proceed to the

521
00:30:48,800 --> 00:30:51,090
the second part which is really

522
00:30:51,110 --> 00:30:54,240
when we start looking in more detail above

523
00:30:54,280 --> 00:30:57,470
into a graphical model

524
00:31:02,650 --> 00:31:05,010
in order to make some

525
00:31:05,100 --> 00:31:07,940
progress here we will need to

526
00:31:07,990 --> 00:31:09,150
to define a few

527
00:31:09,170 --> 00:31:11,860
a little bit of notation OK

528
00:31:13,280 --> 00:31:14,850
very straightforward

529
00:31:15,020 --> 00:31:16,490
i will be talking

530
00:31:16,500 --> 00:31:22,210
most of the time about some random variables x and is run viable is basically

531
00:31:22,210 --> 00:31:24,050
a random field is a set of

532
00:31:24,100 --> 00:31:26,170
individual run via k

533
00:31:26,170 --> 00:31:27,740
like for example

534
00:31:27,800 --> 00:31:31,030
potential image is around five

535
00:31:31,100 --> 00:31:36,000
can be seen as the prior has a running yield where the random variables comic

536
00:31:36,030 --> 00:31:38,280
violence because for

537
00:31:38,340 --> 00:31:45,220
and the lower case x will just north of particular realisation of that run randomized

538
00:31:45,360 --> 00:31:47,640
so for example an image

539
00:31:47,690 --> 00:31:53,080
generic image genetic one megabyte image for example can here and the environment

540
00:31:53,100 --> 00:31:57,410
in the particular one mega image of

541
00:31:57,440 --> 00:32:03,210
you've taken by me with a given cameras particularly is one possible element of the

542
00:32:03,210 --> 00:32:05,520
huge space of possible image

543
00:32:05,550 --> 00:32:06,420
well that

544
00:32:06,440 --> 00:32:08,100
particular element is

545
00:32:08,110 --> 00:32:10,030
lowercase x

546
00:32:12,830 --> 00:32:16,140
if the set of all possible realizations

547
00:32:16,170 --> 00:32:19,350
which is huge of course in this example i just gave

548
00:32:22,550 --> 00:32:25,630
capitol access to create a

549
00:32:29,130 --> 00:32:30,600
random field cont

550
00:32:30,640 --> 00:32:34,330
restricted to only the subset of articles

551
00:32:34,390 --> 00:32:36,990
indexed by the indexer

552
00:32:37,030 --> 00:32:41,350
OK this is only a subset of the random

553
00:32:41,390 --> 00:32:42,910
next a killed

554
00:32:42,920 --> 00:32:43,990
is basically

555
00:32:44,000 --> 00:32:46,800
the random vector composed of all the other virus

556
00:32:46,820 --> 00:32:47,580
other than

557
00:32:50,770 --> 00:32:52,110
this is important

558
00:32:52,170 --> 00:32:55,950
because we all the time be talking about

559
00:32:55,990 --> 00:32:57,770
on par set of variable

560
00:32:57,840 --> 00:33:00,460
subset of the entire set of articles

561
00:33:00,480 --> 00:33:02,330
the completion of that

562
00:33:06,360 --> 00:33:11,140
so basically have here is basically the set of all possible station

563
00:33:11,140 --> 00:33:18,640
and p of x is the probability that reliable ax assumes particular realisation lower case

564
00:33:21,300 --> 00:33:25,390
just notation i mean we need to support for while this

565
00:33:25,390 --> 00:33:27,590
flood because all the rest

566
00:33:27,640 --> 00:33:28,950
of of the

567
00:33:28,960 --> 00:33:30,370
four course will be

568
00:33:30,390 --> 00:33:35,050
basically using this and the venetians and

569
00:33:35,760 --> 00:33:39,710
of course you have some basic properties of probabilities

570
00:33:39,770 --> 00:33:43,740
the first fact is any probability between zero and one for any event in your

571
00:33:46,580 --> 00:33:50,640
and the sum of all possible realizations

572
00:33:50,670 --> 00:33:53,390
in the set of all the

573
00:33:53,390 --> 00:33:54,860
i will give you one

574
00:33:55,840 --> 00:33:57,610
all familiar concepts

575
00:33:57,680 --> 00:33:59,170
i'm sure there are no

576
00:33:59,170 --> 00:34:03,670
major problems here but i mean if you have any questions

577
00:34:03,710 --> 00:34:06,480
you can

578
00:34:06,620 --> 00:34:09,210
welcome to us

579
00:34:13,300 --> 00:34:14,870
but are two

580
00:34:15,110 --> 00:34:17,140
in fact that you will

581
00:34:17,180 --> 00:34:18,610
all the time

582
00:34:18,640 --> 00:34:21,150
when you talk about graphical model

583
00:34:21,170 --> 00:34:23,920
the probabilities all that OK

584
00:34:24,110 --> 00:34:27,590
you can just think of them as rules but i mean

585
00:34:27,830 --> 00:34:32,840
what you really doing here is basically defined kind of defining conditional probabilities

586
00:34:32,860 --> 00:34:36,710
we have a joint probability distribution on two sets of reliable

587
00:34:38,790 --> 00:34:40,490
the probability of

588
00:34:40,510 --> 00:34:43,510
these are the bible conditioned on these

589
00:34:43,550 --> 00:34:45,620
and here we have the probability

590
00:34:45,640 --> 00:34:47,110
of only one

591
00:34:47,210 --> 00:34:51,700
i should say that these are lower case axis is of particular instantiations of the

592
00:34:52,700 --> 00:34:56,640
not a reliable really

593
00:34:56,690 --> 00:35:00,000
it is defined for p of x being greater than c

594
00:35:00,230 --> 00:35:02,080
yes question

595
00:35:08,220 --> 00:35:11,960
that's true i mean it's just that in general you defined

596
00:35:12,010 --> 00:35:15,520
this thing by dividing this thing but that

597
00:35:15,570 --> 00:35:19,720
so this thing only be well defined at least in the simple formalism i mean

598
00:35:20,010 --> 00:35:23,220
you can both more complex probability formalisms

599
00:35:23,250 --> 00:35:25,410
i don't really requires things

600
00:35:25,450 --> 00:35:28,140
but that's far beyond what

601
00:35:31,450 --> 00:35:33,340
so marginalisation well

602
00:35:33,350 --> 00:35:37,100
now these calls his very critical moment before

603
00:35:37,130 --> 00:35:39,020
extremely familiar with this

604
00:35:39,020 --> 00:35:42,790
what surprised many people were not so i mean we need to make sure that

605
00:35:43,210 --> 00:35:45,910
everyone understands the marginalisation

606
00:35:45,960 --> 00:35:49,160
so basically we already given example before

607
00:35:49,190 --> 00:35:54,140
we had the probability distribution any viable and we want to compute the marginal probability

608
00:35:54,140 --> 00:35:55,710
for x y

609
00:35:55,730 --> 00:35:59,040
in order to achieve that we need to compute

610
00:35:59,700 --> 00:36:01,720
when you have some

611
00:36:01,770 --> 00:36:04,400
the probabilities of all

612
00:36:04,480 --> 00:36:08,870
realizations where the critical value of x one

613
00:36:11,470 --> 00:36:13,030
we do that

614
00:36:13,190 --> 00:36:18,330
if we need to sum over all realizations of that particular value hold

615
00:36:18,390 --> 00:36:22,330
it doesn't matter the value of the order so we need to sum over all

616
00:36:22,330 --> 00:36:23,950
the value of

617
00:36:25,410 --> 00:36:28,690
this is exactly what this is saying if we want to compute the

618
00:36:28,700 --> 00:36:33,960
probability that a given set of random variables has a particular realization will need to

619
00:36:34,910 --> 00:36:37,070
sum over all

620
00:36:37,130 --> 00:36:39,850
realizations with that the whole

621
00:36:39,930 --> 00:36:42,590
nothing holds the semantic web the rest

622
00:36:42,640 --> 00:36:46,830
what happens with the other five to sum over the entire list

623
00:36:47,750 --> 00:36:51,390
all the time variation of the rest of the lives

624
00:36:51,400 --> 00:36:53,680
that's exactly what is here is a

625
00:36:53,720 --> 00:36:55,000
i mean

626
00:36:55,040 --> 00:36:58,810
i'm just being picky here because of all this calls is

627
00:36:58,820 --> 00:37:00,770
scanning the simple

628
00:37:00,780 --> 00:37:01,450
i mean

629
00:37:01,460 --> 00:37:03,850
it's also

630
00:37:03,940 --> 00:37:06,090
the basis of

631
00:37:06,200 --> 00:37:08,180
almost everything doing so

632
00:37:08,190 --> 00:37:09,950
we need to

633
00:37:09,960 --> 00:37:10,960
the photos

634
00:37:11,790 --> 00:37:13,840
on this concept

635
00:37:16,120 --> 00:37:20,880
the funny thing is that we do this all the time

636
00:37:20,950 --> 00:37:23,820
compute marginals in our minds and

637
00:37:23,850 --> 00:37:27,330
even without noticing that we can do that for example if

638
00:37:27,400 --> 00:37:29,770
if i if i if i troll

639
00:37:29,820 --> 00:37:31,290
two point

640
00:37:32,100 --> 00:37:34,310
OK let's assume that the

641
00:37:34,380 --> 00:37:37,850
two events are independent i thought point

642
00:37:38,520 --> 00:37:41,640
and then i what's the probability that after

643
00:37:41,690 --> 00:37:43,700
growing according

644
00:37:45,330 --> 00:37:48,660
the first outcome

645
00:37:53,810 --> 00:37:56,280
that's the question

646
00:37:57,350 --> 00:37:59,730
i have a quite improbable plots

647
00:37:59,830 --> 00:38:02,890
what's the probability that in the first part

648
00:38:02,900 --> 00:38:04,980
the outcome was there

649
00:38:05,030 --> 00:38:07,950
so obviously fifty percent

650
00:38:07,950 --> 00:38:13,220
this was a member of the french the gear had invented halide photography so someone

651
00:38:13,220 --> 00:38:15,410
in france offered to x-ray

652
00:38:15,430 --> 00:38:17,300
the human soul

653
00:38:17,350 --> 00:38:18,950
this is very good

654
00:38:19,390 --> 00:38:23,930
i'm ashamed to say what happened in the united states the new york city college

655
00:38:23,930 --> 00:38:25,740
of physicians and surgeons

656
00:38:25,740 --> 00:38:27,680
o announced that they would use

657
00:38:27,680 --> 00:38:29,550
x-rays to project

658
00:38:30,870 --> 00:38:37,180
anatomical diagrams from textbooks on to the brains of medical students thereby creating and i

659
00:38:37,180 --> 00:38:39,950
quote an enduring impression

660
00:38:39,970 --> 00:38:46,990
and i want somebody offered to extract copper pennies and thereby turning them into gold

661
00:38:47,030 --> 00:38:48,910
so that's that's

662
00:38:48,990 --> 00:38:53,220
but seriously what would really did happen very quickly was the use of x-rays is

663
00:38:53,220 --> 00:38:55,160
the diagnostic tool

664
00:38:55,160 --> 00:38:57,560
already in february of

665
00:38:57,580 --> 00:39:00,410
eighty ninety six there was a scottish physician

666
00:39:00,410 --> 00:39:04,050
who used x-rays and look it's simple it's just that you could do this in

667
00:39:04,080 --> 00:39:04,990
high school

668
00:39:05,010 --> 00:39:08,490
i mean what is it you know it's just a gas discharge tube

669
00:39:08,490 --> 00:39:10,780
a pair of electrodes feed through

670
00:39:11,830 --> 00:39:15,260
he's got thirty five thousand volts and that's kind of stuff that comes after chelsea

671
00:39:15,260 --> 00:39:15,870
of your

672
00:39:15,890 --> 00:39:17,200
a television set

673
00:39:17,200 --> 00:39:19,060
this is trivial stuff

674
00:39:19,100 --> 00:39:20,140
so people off

675
00:39:20,160 --> 00:39:24,450
with these things everywhere there's offices and an open view

676
00:39:24,450 --> 00:39:26,330
nobody knew

677
00:39:26,390 --> 00:39:27,910
so this position

678
00:39:28,180 --> 00:39:32,350
had seamstress come to him she was involved in an industrial accident in mill

679
00:39:32,370 --> 00:39:35,850
a needle broke off in her hand now how would you find the needle in

680
00:39:37,870 --> 00:39:41,200
x-ray they identified the location of the new

681
00:39:41,240 --> 00:39:44,450
perform the surgery for dental applications it was

682
00:39:44,470 --> 00:39:48,820
immediately adopted were already using in eighteen ninety nine is the form of treatment for

683
00:39:50,600 --> 00:39:52,330
very interesting article

684
00:39:52,350 --> 00:39:55,990
so what's the relative physics what's going on here

685
00:39:57,320 --> 00:39:59,780
where do we have to go i say we have to look at the animal

686
00:39:59,850 --> 00:40:04,240
because that's where the electrons are crashing into that's the site of the collision isn't

687
00:40:04,260 --> 00:40:06,390
something's happening about arnold

688
00:40:06,430 --> 00:40:08,600
so let's look inside the anode

689
00:40:08,620 --> 00:40:12,580
suppose it's copper what can we say about it

690
00:40:12,580 --> 00:40:14,910
an old

691
00:40:14,930 --> 00:40:16,260
this is where the

692
00:40:16,370 --> 00:40:18,680
electron collisions

693
00:40:18,720 --> 00:40:20,010
that's the maximum

694
00:40:20,100 --> 00:40:21,700
impact isn't it

695
00:40:23,330 --> 00:40:26,990
let's just see what might be going on and through the power of estimation

696
00:40:27,760 --> 00:40:29,560
how far

697
00:40:29,620 --> 00:40:31,700
how far down i've shown you that

698
00:40:31,720 --> 00:40:34,970
with nitrogen at six hundred sixty eight

699
00:40:35,030 --> 00:40:39,890
electron volts to get to the initial electrons what about in the case of the

700
00:40:39,890 --> 00:40:44,640
an old well what's going on there like and say what's the energy of the

701
00:40:44,640 --> 00:40:49,910
one as electron in copper twenty eight plus that's one electron system

702
00:40:50,600 --> 00:40:54,760
and you know that in real copper with all of its electrons this value is

703
00:40:54,760 --> 00:40:55,680
going to be

704
00:40:55,760 --> 00:40:59,910
and overestimate because the presence of all the other electrons is going to set up

705
00:40:59,910 --> 00:41:01,950
some of the proton nick

706
00:41:01,990 --> 00:41:06,760
coulombic force of this will be an upper bound on what that you could be

707
00:41:06,760 --> 00:41:10,740
we know that simply equal to the energy of the one as in hydrogen

708
00:41:13,180 --> 00:41:14,780
z squared

709
00:41:14,780 --> 00:41:17,800
so if i take thirteen point six electron volts

710
00:41:17,830 --> 00:41:19,780
times twenty nine

711
00:41:19,800 --> 00:41:21,620
squared i get

712
00:41:21,640 --> 00:41:24,430
eleven point four

713
00:41:24,490 --> 00:41:29,890
thousand electron volts which is still less than the thirty five thousand electron volts the

714
00:41:29,890 --> 00:41:33,350
ranking has around can is running

715
00:41:33,430 --> 00:41:39,320
huge bowling alley here he's able to knock out one as electrons from copper

716
00:41:39,320 --> 00:41:43,700
and what happens when you knock out electrons into shell electrons

717
00:41:43,760 --> 00:41:46,410
what's the next thing that happens

718
00:41:46,410 --> 00:41:48,740
now let's look at an energy level diagram

719
00:41:50,100 --> 00:41:52,160
let's let's suppose this is

720
00:41:52,280 --> 00:41:54,220
the anode so this is

721
00:41:54,260 --> 00:41:56,910
the anode in the gas two

722
00:41:56,950 --> 00:42:00,100
energy level diagram so this is going to be and

723
00:42:00,190 --> 00:42:01,830
equals infinity

724
00:42:01,870 --> 00:42:04,930
and i to do a few of them so this is an equals four

725
00:42:05,120 --> 00:42:06,490
equals three

726
00:42:06,510 --> 00:42:07,680
n equals two

727
00:42:07,700 --> 00:42:10,970
and equals one not to scale and try to show that there are a little

728
00:42:10,970 --> 00:42:15,260
bit farther apart as you go lower and lower and so this is ground state

729
00:42:15,260 --> 00:42:17,530
energy e one this is

730
00:42:17,600 --> 00:42:20,620
n equals two shell any equals three shell

731
00:42:20,660 --> 00:42:23,930
he calls for shellingout here is zero isn't

732
00:42:23,930 --> 00:42:25,970
and so what i have got some

733
00:42:25,990 --> 00:42:29,490
the incident electron comes zooming in here

734
00:42:29,490 --> 00:42:31,550
zooming in here this is

735
00:42:33,320 --> 00:42:37,800
this is the one that's been accelerated writes the energy of the electrons all kinetic

736
00:42:37,830 --> 00:42:39,870
and that's the product of the charge

737
00:42:39,870 --> 00:42:41,740
on the electron which is

738
00:42:41,850 --> 00:42:43,890
elemental e

739
00:42:43,930 --> 00:42:48,050
time supply voltage which is thirty five thousand volts that i get thirty five thousand

740
00:42:48,050 --> 00:42:50,600
electron volts is the energy

741
00:42:50,660 --> 00:42:54,120
and it can come in and we just showing that it's got enough energy that

742
00:42:54,120 --> 00:42:58,100
it can even knock out an inner shell electron

743
00:42:58,100 --> 00:43:01,180
it can even dislodging english shell electron

744
00:43:01,240 --> 00:43:03,800
so let's see what would happen if that were the case

745
00:43:03,850 --> 00:43:07,640
it is large is an inner shell electron what's the next thing

746
00:43:07,640 --> 00:43:13,020
this was the sort of a long story in what follows

747
00:43:13,020 --> 00:43:14,390
looking at some

748
00:43:14,440 --> 00:43:17,000
rather nontrivial minutes so

749
00:43:17,020 --> 00:43:18,750
this is actually useful for anything

750
00:43:18,810 --> 00:43:20,640
it is useful for something

751
00:43:20,680 --> 00:43:22,270
because it tells you

752
00:43:22,290 --> 00:43:24,190
tell you doesn't just give you

753
00:43:24,190 --> 00:43:24,640
the the

754
00:43:24,790 --> 00:43:28,040
function that the line would give you enough to tells you something about what the

755
00:43:29,060 --> 00:43:30,620
of these predictions

756
00:43:30,680 --> 00:43:33,290
i think the whole distribution over functions

757
00:43:33,310 --> 00:43:37,920
so we have also shown you two random functions from distribution

758
00:43:38,000 --> 00:43:39,940
interestingly the random functions

759
00:43:39,960 --> 00:43:41,160
from the distribution

760
00:43:41,180 --> 00:43:43,940
i'm not actually will not

761
00:43:44,140 --> 00:43:46,600
actually some of these little red

762
00:43:46,980 --> 00:43:52,040
o o o if you don't like these functions then maybe you shouldn't be using

763
00:43:54,250 --> 00:43:55,680
the nice thing here is to get

764
00:43:55,730 --> 00:43:58,140
you get out of the three

765
00:43:58,250 --> 00:43:59,520
this is something you don't get

766
00:43:59,710 --> 00:44:02,660
think of lines being lines but i think about being a prof

767
00:44:02,850 --> 00:44:04,060
when you get them for free

768
00:44:04,100 --> 00:44:08,680
and actually get the other thing you get free is you can automatically

769
00:44:08,690 --> 00:44:10,980
find out what the noise that would the data

770
00:44:11,000 --> 00:44:12,270
but the most likely

771
00:44:12,330 --> 00:44:15,540
the level of the noise because you can optimize the much like

772
00:44:15,600 --> 00:44:20,500
this is something that also in the traditional find framework but there isn't really a

773
00:44:20,500 --> 00:44:22,120
particularly good answers

774
00:44:22,160 --> 00:44:24,620
in one dimension it's pretty easy to see

775
00:44:24,660 --> 00:44:26,640
despite expecting OK

776
00:44:33,460 --> 00:44:39,060
OK so the kernel

777
00:44:39,060 --> 00:44:41,500
looks like this

778
00:44:41,500 --> 00:44:45,460
this is just a function of x and x right

779
00:44:45,480 --> 00:44:48,480
and you have to you have to use it in the limit where

780
00:44:48,520 --> 00:44:49,940
so i go infinity

781
00:44:49,940 --> 00:44:51,980
it has one free parameter

782
00:44:52,000 --> 00:44:53,560
which is

783
00:44:53,640 --> 00:44:56,040
which is the

784
00:44:56,100 --> 00:44:58,520
which it would tell us something about the magnitude

785
00:44:58,600 --> 00:45:00,730
and then you will typically have also

786
00:45:00,730 --> 00:45:08,100
another contribution to the grounds which which would be taking care of

787
00:45:08,140 --> 00:45:20,040
the the question is how does this blind kernel compared to the gulf kernel well

788
00:45:20,040 --> 00:45:21,560
that depends

789
00:45:21,660 --> 00:45:26,920
that depends on on what data looks like could data actually

790
00:45:26,940 --> 00:45:30,440
looks like that with that these kind of functions then

791
00:45:30,980 --> 00:45:34,140
the plain kernel would seem to be a better idea i presumably would give you

792
00:45:34,140 --> 00:45:39,010
a higher value of much like if it if the data really come from very

793
00:45:39,010 --> 00:45:43,710
very smooth functions then this doesn't seem to be the appropriate right OK if have

794
00:45:43,710 --> 00:45:46,580
ten data points spaced far apart

795
00:45:46,710 --> 00:45:50,660
the data does not to tell you have a lot of that but the marginal

796
00:45:50,660 --> 00:45:55,140
likelihood probably extremely close to each other

797
00:46:39,350 --> 00:46:48,290
so the question is how robust the half approaches do if you just specify you

798
00:46:48,290 --> 00:46:53,480
know one kind of one kind of kernel you get away with that just one

799
00:46:55,580 --> 00:47:02,580
people have been wondering about this and i think this is certain degree of

800
00:47:02,640 --> 00:47:08,870
robustness in this in this kind of approach is so

801
00:47:08,910 --> 00:47:14,190
for example that showed before we wish we had this periodic components etc et cetera

802
00:47:14,210 --> 00:47:15,190
of course

803
00:47:15,190 --> 00:47:19,760
you know i'm really injecting some valuable information that case vital so so presumably i

804
00:47:19,760 --> 00:47:20,620
wouldn't do

805
00:47:20,660 --> 00:47:23,830
as well and that kind of stuff like but if you look at

806
00:47:24,440 --> 00:47:28,790
the problem is that of typical in the machine learning literature that it turns out

807
00:47:28,790 --> 00:47:30,080
that actually

808
00:47:30,080 --> 00:47:32,350
the squared exponential kernel

809
00:47:32,370 --> 00:47:34,660
often does a pretty good job

810
00:47:34,690 --> 00:47:38,850
and this is the same experience people have been work and support vector machine they

811
00:47:38,850 --> 00:47:43,600
almost exclusively use the kernel and they typically only have a single

812
00:47:43,660 --> 00:47:47,640
with parameter that they worry about they don't even use the notion of a rt

813
00:47:48,000 --> 00:47:49,960
of having one with parameter for dimension

814
00:47:49,980 --> 00:47:54,580
and the reason why they don't do that because they don't have a nice way

815
00:47:54,580 --> 00:47:56,830
of choosing the from the truth

816
00:47:56,830 --> 00:48:01,250
for the next four years

817
00:48:01,740 --> 00:48:04,890
they had to

818
00:48:06,570 --> 00:48:07,640
thank you

819
00:48:07,900 --> 00:48:10,320
and the good morning everybody

820
00:48:10,370 --> 00:48:17,730
i come from the department of intelligent systems of this institute and has already announced

821
00:48:17,800 --> 00:48:26,140
talk about stochastic search methods but before we start some organizational issues handouts for this

822
00:48:26,140 --> 00:48:31,130
presentation were distributed around so if there is still some of them using this material

823
00:48:31,160 --> 00:48:32,260
is that

824
00:48:33,050 --> 00:48:35,340
for several additional copies here

825
00:48:35,370 --> 00:48:39,300
anybody still needs these

826
00:48:39,310 --> 00:48:47,160
the second

827
00:48:47,180 --> 00:48:48,120
o thing is

828
00:48:48,120 --> 00:48:53,580
if you agree about twelve o'clock i would make a short break of of five

829
00:48:53,580 --> 00:48:58,260
to to seven minutes they told me this would be a good idea

830
00:48:58,270 --> 00:49:00,500
and the last announcement

831
00:49:00,510 --> 00:49:03,010
during my talk

832
00:49:03,030 --> 00:49:06,370
if there are questions if there is something unclear

833
00:49:07,090 --> 00:49:09,280
as you can ask your question

834
00:49:09,300 --> 00:49:10,260
so we

835
00:49:10,280 --> 00:49:14,670
make it clear once not to wait until the end or wherever so

836
00:49:14,700 --> 00:49:16,800
you are encouraged to us

837
00:49:16,810 --> 00:49:19,230
during the presentation

838
00:49:21,450 --> 00:49:24,860
if we start

839
00:49:24,870 --> 00:49:27,750
our presentation will

840
00:49:27,780 --> 00:49:34,190
consists of consists of three parts the first make a short introduction or an overview

841
00:49:34,220 --> 00:49:37,730
of this field of the stochastic search methodology

842
00:49:37,750 --> 00:49:39,080
and if you

843
00:49:39,090 --> 00:49:41,170
go into detail

844
00:49:41,220 --> 00:49:48,450
regarding two methodologies that fit into this call this is simulated annealing which is

845
00:49:48,580 --> 00:49:49,340
right now

846
00:49:49,360 --> 00:49:56,590
traditional rather popular stochastic search methods and then into the field of evolutionary computation

847
00:49:56,590 --> 00:50:00,760
we will discuss evolution and is

848
00:50:02,720 --> 00:50:07,850
first about the motivation for this technique

849
00:50:09,250 --> 00:50:15,340
summer school is on knowledge discovery so we have to relate to the field of

850
00:50:15,340 --> 00:50:17,750
stochastic search it

851
00:50:17,770 --> 00:50:19,370
knowledge discovery

852
00:50:20,240 --> 00:50:27,270
we should first say that in knowledge discovery we are often faced with problems of

853
00:50:27,310 --> 00:50:33,460
performing search in high dimensional and multi modal search spaces

854
00:50:33,470 --> 00:50:35,400
how to make this clear

855
00:50:35,430 --> 00:50:40,210
what means high dimensional i think everybody knows

856
00:50:40,310 --> 00:50:43,180
if you have a problem that depends on the certain

857
00:50:43,190 --> 00:50:48,710
parameters of variables because there are many many say this problem is high dimensional

858
00:50:48,720 --> 00:50:53,070
so what is multimodal problems

859
00:50:53,120 --> 00:50:54,590
if you imagine

860
00:50:55,280 --> 00:50:57,120
function surface

861
00:50:57,160 --> 00:50:59,130
a lot of certain functions

862
00:50:59,160 --> 00:51:01,720
it is multimodal if it has

863
00:51:01,900 --> 00:51:04,180
multiple local optima

864
00:51:06,940 --> 00:51:10,680
one can of course imagine that searching

865
00:51:10,690 --> 00:51:12,630
in uniform all the

866
00:51:12,650 --> 00:51:16,560
so space is easier than in multi mode

867
00:51:18,440 --> 00:51:20,530
finding the global optimum

868
00:51:20,540 --> 00:51:21,940
in such

869
00:51:22,940 --> 00:51:26,130
is computationally expensive it is

870
00:51:26,150 --> 00:51:33,310
demanding so we of course need effective and efficient search methods

871
00:51:34,960 --> 00:51:41,270
catagory of these methods that will fit into the scope is also stochastic search methods

872
00:51:41,280 --> 00:51:47,320
regarding the search techniques there are

873
00:51:47,340 --> 00:51:48,470
many of them

874
00:51:49,810 --> 00:51:58,030
four different purposes over time in different periods but just to mention few groups we

875
00:51:58,030 --> 00:51:58,850
of course

876
00:51:58,870 --> 00:52:01,440
we don't have time to go into details

877
00:52:01,470 --> 00:52:09,030
so the traditional approaches calculus based like gradient methods i think we are all aware

878
00:52:10,160 --> 00:52:16,090
then there's enumerate you search techniques like exhaustive search for dynamic programming

879
00:52:16,150 --> 00:52:20,960
and finally the whole group of methods that are discussed today

880
00:52:20,970 --> 00:52:22,590
this is stochastic

881
00:52:22,590 --> 00:52:30,290
search methods examples are want to colour search taboo search evolution witness has already said

882
00:52:30,340 --> 00:52:35,780
thatcher illusion area which was not discussed the other things but

883
00:52:35,860 --> 00:52:43,350
just for those more interested in stochastic search there's a number of good sources of

884
00:52:45,170 --> 00:52:47,610
and in the literature there is a

885
00:52:47,630 --> 00:52:54,400
there are some references like the book new ideas in optimisation but i really recommend

886
00:52:54,400 --> 00:52:58,930
to all of those really interested in these techniques

887
00:52:58,960 --> 00:53:00,290
there are also other

888
00:53:00,320 --> 00:53:04,480
sources only refer to later

889
00:53:06,420 --> 00:53:11,920
of course if we discuss search techniques they have different properties one thing is degree

890
00:53:11,920 --> 00:53:14,160
of specialization

891
00:53:14,170 --> 00:53:20,090
some techniques are very specialized which means they are dedicated that they were developed to

892
00:53:20,090 --> 00:53:22,290
solve certain types of problems

893
00:53:22,290 --> 00:53:24,370
and the right here in the error function

894
00:53:24,430 --> 00:53:28,360
newsprint everything air which is like c and it's just designed for error handling

895
00:53:28,380 --> 00:53:31,540
and call exit minus one which says what this program

896
00:53:31,550 --> 00:53:35,820
reports are the operating system and we're done

897
00:53:35,860 --> 00:53:39,370
this is it this is all that is contained in germany and the only two

898
00:53:39,370 --> 00:53:43,150
important to this one right here including the string for class and using the standard

899
00:53:43,150 --> 00:53:46,580
name space and if you do that and you get right down

900
00:53:46,580 --> 00:53:49,800
european for leadership

901
00:53:49,830 --> 00:53:53,670
now german is probably one easier want but what about some of these other heterogeneous

902
00:53:54,820 --> 00:53:57,530
well i could go into some detail about all these but i just don't have

903
00:53:57,530 --> 00:54:00,670
time and i really wish i could show you how this works shows how this

904
00:54:00,670 --> 00:54:03,580
works but i just kind of give you a quick overview today

905
00:54:03,590 --> 00:54:05,860
just to show you what you need to know if you want to get off

906
00:54:05,870 --> 00:54:07,950
these libraries

907
00:54:08,000 --> 00:54:10,090
the first one historian tells that h

908
00:54:10,150 --> 00:54:13,580
this is the one that gives you strength integer integer string string to real madrid

909
00:54:13,580 --> 00:54:15,950
uppercase lowercase et cetera

910
00:54:15,970 --> 00:54:19,500
behind the scenes most of this stuff is back to this classical the strings string

911
00:54:19,810 --> 00:54:23,820
you've seen it streams fifteen streams you've seen c after all streams into less and

912
00:54:23,820 --> 00:54:26,170
less than you great and greater than

913
00:54:26,180 --> 00:54:29,530
the point of the string streamer does the same thing it said that rights to

914
00:54:29,530 --> 00:54:34,240
a string buffer so you can take some integer dump into a string that's here

915
00:54:34,240 --> 00:54:36,050
integer string function right there

916
00:54:36,100 --> 00:54:38,960
there's a couple other things you can do with that we use for doing i

917
00:54:39,060 --> 00:54:42,410
conversion between strings and other data types like integers

918
00:54:42,420 --> 00:54:45,820
so you might want to look into that if you play around

919
00:54:45,850 --> 00:54:48,180
as for convert application converts to lower case

920
00:54:48,190 --> 00:54:51,520
there's a function to upper and two lower the take individual characters and convert them

921
00:54:51,520 --> 00:54:53,560
to uppercase and converted to lower case

922
00:54:53,570 --> 00:54:57,490
just for the of string call that function every time presto your string is an

923
00:54:57,490 --> 00:55:00,090
upper case that was pretty straightforward

924
00:55:00,400 --> 00:55:03,960
in case you're interested in politics that we actually read some of these functions if

925
00:55:03,960 --> 00:55:07,150
you want to have a working implementation of street that if you go to the

926
00:55:07,150 --> 00:55:10,610
sea as one of the website under the code section there is a working implementation

927
00:55:10,610 --> 00:55:13,270
are so if you want to keep using these things just go down the that

928
00:55:13,280 --> 00:55:17,720
file take a look at it play around the world

929
00:55:17,730 --> 00:55:20,940
so we want to set

930
00:55:23,060 --> 00:55:24,080
the next machine

931
00:55:24,090 --> 00:55:28,080
it doesn't have any understanding the see story

932
00:55:28,100 --> 00:55:32,300
you know it's some users only possible to compile everywhere

933
00:55:32,850 --> 00:55:35,270
and it works pretty well i mean i think we only to find a few

934
00:55:35,270 --> 00:55:37,930
of them but you can see how they work and you can define for we

935
00:55:37,930 --> 00:55:41,100
give you string integer you can do bring up or string to real parties by

936
00:55:41,100 --> 00:55:43,510
changing contacts

937
00:55:46,760 --> 00:55:51,490
this is the big winner miss empire that age have you've ever played around with

938
00:55:51,590 --> 00:55:55,140
the ross sea possible simple functions before

939
00:55:56,140 --> 00:55:59,230
they're kind of nasty i've always thought that this thing called in which is the

940
00:55:59,230 --> 00:56:02,390
counterpart of the at the input is kind of like a rose which is it's

941
00:56:02,410 --> 00:56:06,620
very sweet it's very delicate but the second you break it down to the foreign

942
00:56:06,650 --> 00:56:08,060
and it hurts a lot

943
00:56:08,100 --> 00:56:11,990
really you have to think of this as probably one of the most powerful one

944
00:56:11,990 --> 00:56:15,610
of the hardest user input libraries and have any programming language see

945
00:56:15,620 --> 00:56:18,490
so we give you this entire library just to take care of all these things

946
00:56:18,490 --> 00:56:20,820
for you don't have to worry about it

947
00:56:20,820 --> 00:56:23,820
it turns out that the way it works every member get one you can use

948
00:56:23,820 --> 00:56:25,780
it really one of the file

949
00:56:25,820 --> 00:56:29,340
we can use line on the sea stream to do incorporating reading

950
00:56:29,360 --> 00:56:33,120
real as text strings can be converted to an integer

951
00:56:33,130 --> 00:56:37,000
plus or minus a couple of things that get injured again if you go to

952
00:56:37,000 --> 00:56:40,810
see as one six website there's a working plantation of this if you do want

953
00:56:40,810 --> 00:56:45,050
to consider doing people must be and this is actually pretty good input functions you'd

954
00:56:45,050 --> 00:56:49,100
be surprised how many people don't actually know how to write these things so got

955
00:56:49,120 --> 00:56:52,730
around the have some find see what they do and that way you can continue

956
00:56:52,730 --> 00:56:58,580
using the coding conventions you've seen by using only standard c plus plus

957
00:57:00,810 --> 00:57:07,030
the random functions in c plus plus are pretty simple others two functions random strand

958
00:57:07,040 --> 00:57:10,190
random and see the randomizer again

959
00:57:10,210 --> 00:57:13,900
consonants are expensive dolls are expensive and

960
00:57:13,920 --> 00:57:16,750
randy gives you a random integers in the range zero

961
00:57:16,750 --> 00:57:20,060
to round max so if you want to get around w one to get around

962
00:57:20,070 --> 00:57:23,810
integer random boolean just take the number in that range scale it down to zero

963
00:57:23,810 --> 00:57:26,470
one feels back translated etcetera

964
00:57:26,520 --> 00:57:29,300
it turns out this is probably the easiest one to rewrite from scratch is just

965
00:57:29,300 --> 00:57:32,430
have to be able to careful how you do your bounds checking but it's not

966
00:57:32,430 --> 00:57:36,030
so bad the header file for that c standard library but you can find all

967
00:57:36,050 --> 00:57:38,710
the one of is simply

968
00:57:38,760 --> 00:57:42,550
what you actually are going to be missing is this one

969
00:57:42,610 --> 00:57:44,990
graphics dilation extended graphics

970
00:57:45,000 --> 00:57:49,530
unfortunately c plus plus does not have a standard graphics library this doesn't exist and

971
00:57:49,530 --> 00:57:53,560
there's a couple reasons one it's very hard to standardize traffic you have to make

972
00:57:53,560 --> 00:57:56,820
sure something it works on every single platform which is very hard to do

973
00:57:56,910 --> 00:58:00,540
no so if you're writing c plus plus good from microprocessor where you know that

974
00:58:00,540 --> 00:58:04,400
you know have traffic to kind of be difficult to support the library

975
00:58:04,460 --> 00:58:08,080
so there's no standard c plus plus equivalent but i'm back to this program that

976
00:58:08,080 --> 00:58:10,530
i'm using right now is written in c plus plus very got some kind of

977
00:58:10,530 --> 00:58:14,980
so what i mean by that is rather than a lot of situations

978
00:58:14,990 --> 00:58:18,900
you don't just want to predict whether an example is positive or negative

979
00:58:18,920 --> 00:58:24,330
you have reason to believe that the outcome the actual labels probabilistic so instead what

980
00:58:24,340 --> 00:58:26,120
you want to do is one to predict

981
00:58:26,130 --> 00:58:27,500
the probability

982
00:58:27,510 --> 00:58:28,890
of an example being

983
00:58:28,900 --> 00:58:30,590
positive and negative

984
00:58:30,640 --> 00:58:33,600
so it turns out that there's a principled way

985
00:58:34,040 --> 00:58:35,670
taking the output

986
00:58:35,720 --> 00:58:37,600
a boosting

987
00:58:37,620 --> 00:58:44,170
and converting it into a probability estimate the conditional probability estimates

988
00:58:44,220 --> 00:58:49,450
OK so these are all the good things about viewing boosting as loss minimisation algorithm

989
00:58:49,450 --> 00:58:53,270
but now i want to add a very important caveat

990
00:58:54,000 --> 00:58:56,060
there's a temptation to say

991
00:58:56,080 --> 00:59:01,090
now i understand adaboost all it's doing is minimizing exponential loss

992
00:59:01,140 --> 00:59:04,540
and so exponential loss must be a great loss to use

993
00:59:04,580 --> 00:59:08,490
but i've got this toolbox that tells me

994
00:59:08,510 --> 00:59:13,710
you know ten different ways of minimising any function certainly any convex function and a

995
00:59:13,710 --> 00:59:15,970
lot of them are a lot faster than adaboost

996
00:59:16,010 --> 00:59:18,720
so i'm just going to use one of these other algorithms which is going to

997
00:59:18,720 --> 00:59:22,810
be much faster than adaboost and minimizing exponential loss

998
00:59:22,820 --> 00:59:25,820
so let me say that i think that it's a mistake to work can be

999
00:59:25,820 --> 00:59:29,140
in this might be a big win possible that that would be the way

1000
00:59:29,180 --> 00:59:32,160
but it's possible that that's not going to work at all

1001
00:59:32,210 --> 00:59:36,530
and a because i think it's wrong to view adaboost as just an algorithm for

1002
00:59:36,530 --> 00:59:38,820
minimizing exponential loss

1003
00:59:38,840 --> 00:59:42,170
and the reason is that you can construct other algorithms

1004
00:59:42,180 --> 00:59:45,430
we're minimizing the same exponential loss

1005
00:59:45,450 --> 00:59:48,530
which will provably give very poor performance

1006
00:59:48,550 --> 00:59:52,890
so you will construct examples it's really not that hard

1007
00:59:52,930 --> 00:59:56,820
in which you have some other algorithm that minimizes exponential loss

1008
00:59:56,830 --> 01:00:01,700
but the performance is much much worse than adaboost arbitrarily bad

1009
01:00:02,520 --> 01:00:04,340
what this means is that this

1010
01:00:04,350 --> 01:00:09,450
explanation of adaboost as an algorithm for minimizing exponential loss

1011
01:00:09,500 --> 01:00:14,190
is useful it's a useful way of thinking about the algorithm and has its benefits

1012
01:00:14,200 --> 01:00:16,300
but it's not

1013
01:00:16,320 --> 01:00:19,310
it's not a complete explanation about adaboost

1014
01:00:19,360 --> 01:00:20,350
and it's not

1015
01:00:20,370 --> 01:00:24,490
necessarily going to guide us to better algorithms

1016
01:00:26,530 --> 01:00:27,620
OK so

1017
01:00:27,630 --> 01:00:30,300
i'll skip the

1018
01:00:30,320 --> 01:00:34,600
OK so there are other ways of thinking about adaboost so which i'm not talking

1019
01:00:35,340 --> 01:00:38,180
even the ones i'm talking about are not talking about i guess

1020
01:00:39,030 --> 01:00:43,640
so one of these ways is more recently thinking about adaboost which is to view

1021
01:00:43,650 --> 01:00:46,270
adaboost as a dynamical system

1022
01:00:46,280 --> 01:00:50,630
and here let me give applied for cynthia rudin talk tomorrow at two

1023
01:00:50,640 --> 01:00:56,150
so where she's going to describe how you can you adaboost as a dynamical system

1024
01:00:56,170 --> 01:01:00,590
and she promises that the talk will be accessible to everybody certainly the students seen

1025
01:01:00,670 --> 01:01:01,720
talk so

1026
01:01:01,730 --> 01:01:04,290
you can believe her when she promises that

1027
01:01:06,440 --> 01:01:09,730
there's also been working on the statistics literature

1028
01:01:09,760 --> 01:01:15,860
showing that adaboost is consistent algorithm in the statistical sense of consistency

1029
01:01:15,870 --> 01:01:21,380
and so statisticians are very sad people like leo prime are extremely satisfied with this

1030
01:01:21,380 --> 01:01:24,980
particular explanation of adaboost which are not going to talk about

1031
01:01:24,990 --> 01:01:30,270
and there are also some very interesting connections between adaboost and maximum entropy so

1032
01:01:30,320 --> 01:01:32,980
one way of thinking about adaboost is

1033
01:01:33,020 --> 01:01:38,170
as a special case back from entropy or other modification of maximum entropy

1034
01:01:38,190 --> 01:01:40,070
where you remove some of the

1035
01:01:40,070 --> 01:01:44,070
normalisation requirements the normalisation constraint

1036
01:01:44,080 --> 01:01:48,750
and so again i can't we talk about this here but i can certainly give

1037
01:01:48,750 --> 01:01:51,980
you pointers

1038
01:01:51,990 --> 01:01:55,190
OK so let me move on to the last part of this tutorial

1039
01:01:55,210 --> 01:02:00,130
which is on experiments applications and extensions

1040
01:02:01,410 --> 01:02:05,320
i'm going to talk about some basic experiments that were done on adaboost just to

1041
01:02:05,320 --> 01:02:07,360
see if it works at all

1042
01:02:07,410 --> 01:02:09,060
then i'll talk about

1043
01:02:09,100 --> 01:02:10,380
multi class

1044
01:02:10,410 --> 01:02:12,910
the multiclass version of boosting

1045
01:02:12,950 --> 01:02:17,730
and i'll talk about confidence rated predictions which give the big win in practice

1046
01:02:17,830 --> 01:02:19,120
using boosting

1047
01:02:19,180 --> 01:02:24,130
i'll talk about some applications to text categorisation and spoken dialog systems

1048
01:02:24,140 --> 01:02:29,580
and by time i'll talk about how to incorporate prior knowledge human knowledge into boosting

1049
01:02:29,620 --> 01:02:35,980
using boosting with active learning and then finally an application to face detection

1050
01:02:35,980 --> 01:02:36,920
OK so

1051
01:02:36,950 --> 01:02:40,160
the parking lot about the theory of boosting and i want to switch gears and

1052
01:02:40,160 --> 01:02:42,080
talk about the practical side

1053
01:02:42,080 --> 01:02:46,340
so let's start with the good stuff so

1054
01:02:46,630 --> 01:02:49,120
why is that was the good algorithm

1055
01:02:49,140 --> 01:02:50,670
well first of all it

1056
01:02:50,680 --> 01:02:51,920
fairly fast

1057
01:02:52,210 --> 01:02:56,670
it's a very simple algorithm in any case it's very easy to program

1058
01:02:56,900 --> 01:03:00,510
there are no parameters to tune the only parameter is

1059
01:03:00,560 --> 01:03:05,610
the number of rounds of boosting but because boosting tends not to overfit

1060
01:03:05,640 --> 01:03:09,890
i never said that it never can overfit but it tends not to overfit

1061
01:03:09,910 --> 01:03:12,870
because of that the

1062
01:03:12,880 --> 01:03:17,250
the number of rounds of boosting often is not so critical

1063
01:03:18,530 --> 01:03:22,850
let's see boosting is very flexible algorithm is flexible in the sense they can combine

1064
01:03:22,850 --> 01:03:27,130
with any learning algorithm any weak learning algorithm

1065
01:03:27,180 --> 01:03:30,840
you don't need to have any prior knowledge about the weak learner it just like

1066
01:03:30,840 --> 01:03:33,860
in whatever weak learning algorithm you want

1067
01:03:33,910 --> 01:03:37,100
adaboost is provably effective

1068
01:03:37,120 --> 01:03:41,130
comes with these provable guarantees that we talked about provided that

1069
01:03:41,150 --> 01:03:46,310
the weak learning assumption are roughly holds so provided you can consistently find these rough

1070
01:03:46,310 --> 01:03:48,350
rules apply

1071
01:03:48,370 --> 01:03:51,540
and so this might lead to a kind of shift in mindset the way you

1072
01:03:51,560 --> 01:03:53,630
think about designing algorithms

1073
01:03:53,670 --> 01:03:57,340
because usually think about designing an algorithm which is going to do really well over

1074
01:03:57,820 --> 01:03:59,880
the entire space of examples

1075
01:03:59,900 --> 01:04:02,310
now instead we can just think about

1076
01:04:02,310 --> 01:04:06,400
designing a learning algorithm the weak learning algorithm which is just a little bit better

1077
01:04:06,400 --> 01:04:11,010
than random guessing so maybe that's easier to think about

1078
01:04:11,050 --> 01:04:14,010
on adaboost is personal algorithm you can use that

1079
01:04:14,100 --> 01:04:19,790
with data that's textual numeric discrete whatever it's been extended to

1080
01:04:19,800 --> 01:04:21,250
learning problems

1081
01:04:21,260 --> 01:04:24,480
he on binary classification things like regression

1082
01:04:25,610 --> 01:04:27,170
all kinds of stuff

1083
01:04:27,180 --> 01:04:31,340
so that's the positive side with the negative side whatever caveats

1084
01:04:31,360 --> 01:04:36,570
well you know like any learning algorithm adaboost depends on the data that you're actually

1085
01:04:36,570 --> 01:04:40,170
and you will see that this force now you must be in the direction of

1086
01:04:40,180 --> 01:04:42,750
i one cross with b two

1087
01:04:42,760 --> 01:04:48,020
and that's exactly what i predicted to wires go towards each other

1088
01:04:50,210 --> 01:04:54,890
if i leave everything to say but i reverse the direction of i two

1089
01:04:54,930 --> 01:04:57,900
now to two current sign opposite direction

1090
01:04:57,910 --> 01:04:59,690
then the forces will flip over

1091
01:04:59,800 --> 01:05:01,920
so now the two wires

1092
01:05:04,010 --> 01:05:11,440
and i will demonstrate that to you

1093
01:05:11,530 --> 01:05:13,200
i have a

1094
01:05:13,290 --> 01:05:15,340
those two y is here

1095
01:05:15,400 --> 01:05:18,160
you will see them there on the screen

1096
01:05:18,180 --> 01:05:19,790
i will

1097
01:05:19,800 --> 01:05:24,560
explain what you're looking at in some detail

1098
01:05:24,610 --> 01:05:28,580
the two wires run vertically

1099
01:05:28,640 --> 01:05:31,480
this is one y

1100
01:05:31,540 --> 01:05:35,050
this is the outline

1101
01:05:35,050 --> 01:05:38,710
and when i run the current

1102
01:05:38,800 --> 01:05:42,480
in the same direction

1103
01:05:44,310 --> 01:05:46,160
they will attract each other

1104
01:05:46,190 --> 01:05:48,430
you will see that shortly

1105
01:05:48,440 --> 01:05:51,210
three two one zero

1106
01:05:51,220 --> 01:05:54,040
they go to at each other

1107
01:05:54,050 --> 01:05:55,220
i'll do it again

1108
01:05:58,340 --> 01:06:01,150
i run the currents in opposite directions

1109
01:06:01,190 --> 01:06:02,560
they will

1110
01:06:02,610 --> 01:06:04,010
repel each other

1111
01:06:04,050 --> 01:06:07,750
and i run them in opposite directions

1112
01:06:07,890 --> 01:06:10,200
everybody can do it again

1113
01:06:10,980 --> 01:06:12,560
one zero

1114
01:06:15,410 --> 01:06:19,330
the reason why i showed you this demonstration is the different one

1115
01:06:19,340 --> 01:06:21,510
well i want you to appreciate

1116
01:06:21,550 --> 01:06:23,770
if i

1117
01:06:23,810 --> 01:06:25,570
i have this conducting

1118
01:06:25,580 --> 01:06:27,260
played of alumina

1119
01:06:28,640 --> 01:06:33,030
and i put that in between the two wires and i repeat the experiment exactly

1120
01:06:33,030 --> 01:06:35,270
the same thing will happen

1121
01:06:35,280 --> 01:06:38,180
and that tells you that magnetic field

1122
01:06:38,220 --> 01:06:40,780
really very different from electric fields

1123
01:06:40,790 --> 01:06:45,310
because the electric field will be heavily affected by conducting

1124
01:06:45,330 --> 01:06:46,780
she would like to

1125
01:06:46,790 --> 01:06:48,540
very few of them up

1126
01:06:48,590 --> 01:06:51,200
so what i'm going to do now is i'm going to put this played in

1127
01:06:53,190 --> 01:06:54,600
and then

1128
01:06:54,610 --> 01:06:58,750
i'm going to again put the current in opposite directions so as know why is

1129
01:06:58,760 --> 01:06:59,970
repel each other

1130
01:07:00,010 --> 01:07:01,880
as if the played one of their

1131
01:07:03,180 --> 01:07:04,640
one zero

1132
01:07:04,690 --> 01:07:08,020
there you go

1133
01:07:08,030 --> 01:07:11,390
the magnetic fields

1134
01:07:11,400 --> 01:07:13,010
very interesting

1135
01:07:13,050 --> 01:07:15,640
story to tell

1136
01:07:18,330 --> 01:07:20,000
and magnetism

1137
01:07:26,510 --> 01:07:30,190
how do we define the strength of the magnetic field

1138
01:07:30,230 --> 01:07:32,100
his electricity

1139
01:07:32,130 --> 01:07:34,840
we define the strength of electric field

1140
01:07:34,860 --> 01:07:36,870
in the following way

1141
01:07:37,800 --> 01:07:39,520
measure the force

1142
01:07:39,600 --> 01:07:41,230
electric force

1143
01:07:41,250 --> 01:07:44,060
on the charge on electric charge

1144
01:07:44,090 --> 01:07:45,830
and then electric force

1145
01:07:45,840 --> 01:07:51,340
if the charge the electric field that determines the strength of the electric field

1146
01:07:51,360 --> 01:07:52,920
be nice

1147
01:07:52,980 --> 01:07:54,460
if we could now

1148
01:07:55,650 --> 01:07:57,500
the magnetic force

1149
01:07:59,560 --> 01:08:01,630
the magnetic charge

1150
01:08:04,000 --> 01:08:07,750
so that would then define the magnitude of the field

1151
01:08:07,800 --> 01:08:09,040
it would be nice

1152
01:08:09,050 --> 01:08:11,390
but we haven't found a magnetic monopole

1153
01:08:11,820 --> 01:08:12,950
we can do it

1154
01:08:12,970 --> 01:08:16,610
if you come with the magnetic monopole tomorrow i can do it

1155
01:08:16,630 --> 01:08:18,580
but we have no magnetic monopole

1156
01:08:18,670 --> 01:08:22,010
and so it cannot be done this way

1157
01:08:22,050 --> 01:08:24,550
how is magnetic field then defines

1158
01:08:24,600 --> 01:08:26,960
well is defined in the following way

1159
01:08:27,000 --> 01:08:27,900
i take

1160
01:08:27,920 --> 01:08:29,650
an electric charge

1161
01:08:29,700 --> 01:08:31,120
and the electric charge

1162
01:08:33,190 --> 01:08:35,030
and if the electric charge

1163
01:08:35,070 --> 01:08:38,350
moves with the velocity v

1164
01:08:38,400 --> 01:08:40,560
and that is the magnetic field where

1165
01:08:40,630 --> 01:08:43,070
electric charge is moving

1166
01:08:43,120 --> 01:08:45,890
that is an experimental facts

1167
01:08:45,950 --> 01:08:48,640
that's the forces

1168
01:08:48,700 --> 01:08:51,060
is always perpendicular

1169
01:08:53,210 --> 01:08:55,030
if you want to call that

1170
01:08:55,090 --> 01:08:57,810
the magnetic indication that's fine

1171
01:08:57,810 --> 01:09:01,740
it is the magnetic field of the charge is moving with velocity and is the

1172
01:09:01,740 --> 01:09:04,590
force on that charge which is always perpendicular

1173
01:09:04,640 --> 01:09:05,960
two feet

1174
01:09:05,970 --> 01:09:08,950
the magnitude of that force

1175
01:09:09,010 --> 01:09:10,620
is proportional

1176
01:09:10,640 --> 01:09:12,990
due to speed of the particle

1177
01:09:13,030 --> 01:09:15,290
and it is also proportional

1178
01:09:15,300 --> 01:09:18,210
due to charge itself if i don't know the charge

1179
01:09:18,310 --> 01:09:19,650
the force doubles

1180
01:09:19,700 --> 01:09:21,450
if i double the speed

1181
01:09:21,460 --> 01:09:23,280
then the force doubles

1182
01:09:23,400 --> 01:09:27,450
so the way that we define out

1183
01:09:28,500 --> 01:09:30,300
field strength

1184
01:09:31,300 --> 01:09:33,670
this way

1185
01:09:33,700 --> 01:09:36,350
force and i give it to be to remind you

1186
01:09:36,380 --> 01:09:39,310
magnetic is a few electric charge

1187
01:09:39,350 --> 01:09:42,070
he was the velocity of the electric charge

1188
01:09:42,090 --> 01:09:43,550
cross product

1189
01:09:43,560 --> 01:09:45,790
we've been

1190
01:09:45,820 --> 01:09:49,600
you see that the force is always perpendicular to the

1191
01:09:49,660 --> 01:09:53,940
and that is linearly proportional to be linearly proportional

1192
01:09:53,940 --> 01:09:56,580
because the charge q and is often called

1193
01:09:56,640 --> 01:09:57,840
lawrence four

1194
01:09:58,860 --> 01:10:00,260
the dutch

1195
01:10:01,530 --> 01:10:04,740
this equation is completely signed sensitive

1196
01:10:04,750 --> 01:10:08,510
if you change from the positive charge to negative charge

1197
01:10:08,550 --> 01:10:10,490
then the force flips over

1198
01:10:10,510 --> 01:10:16,900
on the degrees change direction of the e force slips over the interaction of b

1199
01:10:16,920 --> 01:10:19,970
four completely signed sensitive

1200
01:10:23,170 --> 01:10:25,270
four magnetic field frank

1201
01:10:25,270 --> 01:10:27,270
it follows from this equation

1202
01:10:27,320 --> 01:10:28,600
this is not and

1203
01:10:28,780 --> 01:10:31,470
q is cool

1204
01:10:31,480 --> 01:10:34,040
and these meters per second

1205
01:10:34,050 --> 01:10:37,560
so this would be the unit for magnetic field strength no one would ever say

1206
01:10:37,560 --> 01:10:39,980
this one this one and this one

1207
01:10:40,020 --> 01:10:41,450
and the message

1208
01:10:41,470 --> 01:10:43,820
that i accelerated discharge

1209
01:10:43,840 --> 01:10:46,520
i could not possibly have reached

1210
01:10:46,570 --> 01:10:51,060
this location in space because that message can only travel with the speed of light

1211
01:10:51,120 --> 01:10:53,010
sorry electric field here

1212
01:10:53,020 --> 01:10:56,100
it's exactly the same as it was

1213
01:10:56,110 --> 01:10:57,150
but it was

1214
01:10:57,160 --> 01:11:01,290
still here so when the object is here the electric field must still be like

1215
01:11:01,290 --> 01:11:04,630
this year and it must be like this year and it must be like this

1216
01:11:05,870 --> 01:11:07,120
the message hasn't

1217
01:11:07,130 --> 01:11:09,390
reach that point

1218
01:11:09,430 --> 01:11:14,280
but now look at this charge which is now here at time t delta t

1219
01:11:14,320 --> 01:11:16,760
now the electric field

1220
01:11:16,770 --> 01:11:18,090
like so

1221
01:11:18,100 --> 01:11:19,360
like so

1222
01:11:19,370 --> 01:11:22,770
and it's like so

1223
01:11:22,780 --> 01:11:24,510
so this field lines

1224
01:11:24,530 --> 01:11:28,680
must somehow meet up with this one is one and the same field line

1225
01:11:28,730 --> 01:11:32,640
and what does that mean that somewhere there there must be a kink in the

1226
01:11:32,640 --> 01:11:34,450
electric field

1227
01:11:34,500 --> 01:11:37,240
and there must be a king here

1228
01:11:37,290 --> 01:11:41,170
notice there's no king here which is interesting

1229
01:11:41,390 --> 01:11:43,660
and so

1230
01:11:43,700 --> 01:11:46,380
it is the collection of these kinks

1231
01:11:46,400 --> 01:11:50,360
the propagate outwards with the speed of light

1232
01:11:50,370 --> 01:11:53,040
and they produce an electromagnetic

1233
01:11:53,100 --> 01:11:55,650
disturbance a change

1234
01:11:55,660 --> 01:11:58,350
if you're out in space here

1235
01:11:58,360 --> 01:12:04,640
and if for instance i would also laid this charge back and forth

1236
01:12:04,690 --> 01:12:07,250
you see these games go by all the time

1237
01:12:07,260 --> 01:12:09,420
he breaks in the electric field

1238
01:12:09,440 --> 01:12:11,190
you would experience that

1239
01:12:11,200 --> 01:12:13,230
as an electromagnetic wave

1240
01:12:13,270 --> 01:12:15,510
if there is a changing electric fields

1241
01:12:15,520 --> 01:12:18,900
according to maxwell's equations has to be also changing

1242
01:12:18,950 --> 01:12:21,120
magnetic fields

1243
01:12:21,230 --> 01:12:24,400
but the interesting thing is

1244
01:12:24,450 --> 01:12:27,770
even though it is an extremely simple picture

1245
01:12:28,900 --> 01:12:32,020
that in this direction if you were here

1246
01:12:32,060 --> 01:12:34,070
you will not see any kinks

1247
01:12:34,130 --> 01:12:38,700
so it is no electromagnetic radiation going in this direction nor is there any going

1248
01:12:38,700 --> 01:12:39,890
in this direction

1249
01:12:39,900 --> 01:12:43,520
and the maximum is going in this direction and something in between is going in

1250
01:12:43,520 --> 01:12:47,790
that direction it's not much of a plane wave for that matter

1251
01:12:47,870 --> 01:12:51,400
i mean anything it's more like a spherical wave

1252
01:12:51,400 --> 01:12:57,320
but it's a very special spherical is not the same strength in all directions

1253
01:12:57,370 --> 01:13:00,320
so even though it is a rather classical picture

1254
01:13:00,380 --> 01:13:02,480
it helps me at least c

1255
01:13:02,490 --> 01:13:03,520
how these

1256
01:13:04,940 --> 01:13:09,300
electric fields and therefore so should be fields are formed by charges

1257
01:13:09,350 --> 01:13:11,140
that we accelerate

1258
01:13:11,140 --> 01:13:13,180
and i have a two minutes

1259
01:13:14,870 --> 01:13:17,040
that shows that also

1260
01:13:17,100 --> 01:13:20,980
in a slightly more detailed weight and i was able to do

1261
01:13:20,990 --> 01:13:23,300
so let's look at that movie

1262
01:13:23,350 --> 01:13:24,970
marcus you're ready for that

1263
01:13:25,020 --> 01:13:28,490
OK then you can start that

1264
01:13:28,510 --> 01:13:32,110
so this is a computer-generated movie whereby we

1265
01:13:33,000 --> 01:13:34,740
accelerate charges

1266
01:13:34,750 --> 01:13:38,180
this is a constant speed now we're going to stop it stopping means is an

1267
01:13:38,180 --> 01:13:42,850
acceleration right you may call it the deceleration but stopping is an acceleration

1268
01:13:42,870 --> 01:13:45,630
it's going to be stopped using all these things

1269
01:13:45,680 --> 01:13:48,340
and they propagate outwards the speed of light and

1270
01:13:48,370 --> 01:13:50,390
this was electromagnetic radiation

1271
01:13:50,400 --> 01:13:54,350
you can see several times you get another chance

1272
01:13:54,520 --> 01:14:00,320
charges now to stop using magnetic electric field lines coming out and being accelerated

1273
01:14:00,330 --> 01:14:02,400
you see these here

1274
01:14:02,410 --> 01:14:06,060
moving out with the speed of light

1275
01:14:06,090 --> 01:14:08,860
going to see more

1276
01:14:08,870 --> 01:14:10,280
there is

1277
01:14:10,450 --> 01:14:13,620
to accelerate during acceleration

1278
01:14:13,630 --> 01:14:18,750
only during acceleration do you see the formation of the king's when gold was constant

1279
01:14:19,720 --> 01:14:20,880
no longer

1280
01:14:20,900 --> 01:14:22,900
only do it notes stopped

1281
01:14:22,970 --> 01:14:26,580
stop means an acceleration there you see

1282
01:14:26,620 --> 01:14:31,640
this will be from moving out

1283
01:14:31,650 --> 01:14:33,280
the bit more you can

1284
01:14:35,040 --> 01:14:37,790
the oscillating effect

1285
01:14:37,910 --> 01:14:39,660
you have already have seen this

1286
01:14:41,220 --> 01:14:42,410
here is the

1287
01:14:43,580 --> 01:14:46,400
stop the mean deceleration

1288
01:14:46,500 --> 01:14:47,810
you see

1289
01:14:47,810 --> 01:14:49,780
we from

1290
01:14:49,830 --> 01:14:51,320
and when it's sitting still

1291
01:14:51,340 --> 01:14:56,160
or when is going with constant speed and is no electromagnetic wave

1292
01:14:58,750 --> 01:15:01,000
now we're going to see some oscillating charges

1293
01:15:01,010 --> 01:15:04,560
which is more realistic when you have an antenna you have currents going up and

1294
01:15:04,560 --> 01:15:06,330
down with frequency omega

1295
01:15:06,340 --> 01:15:08,600
you obviously have

1296
01:15:08,740 --> 01:15:12,250
stops and starts to oscillate back and forth and that's what you see now i

1297
01:15:12,250 --> 01:15:15,740
look at beautiful

1298
01:15:16,460 --> 01:15:21,390
weights going out always going out only during acceleration there's one going out

1299
01:15:21,390 --> 01:15:24,530
there's one going out so you accelerated

1300
01:15:24,580 --> 01:15:30,710
backwards forwards backwards forwards

1301
01:15:30,900 --> 01:15:35,760
i think that's fine

1302
01:15:35,780 --> 01:15:38,700
thank you marcos

1303
01:15:38,760 --> 01:15:40,450
so the classic picture

1304
01:15:40,460 --> 01:15:44,900
even though it has lots of limitations it's not the quantum mechanical treatment

1305
01:15:44,910 --> 01:15:46,780
it's still very useful

1306
01:15:46,820 --> 01:15:49,100
as for instance if we

1307
01:15:49,140 --> 01:15:51,170
think of a

1308
01:15:51,310 --> 01:15:55,090
an antenna straight wire with current

1309
01:15:56,050 --> 01:15:58,610
up and down the high frequency

1310
01:15:58,660 --> 01:16:02,100
could be seventy megahertz could be gigahertz

1311
01:16:02,140 --> 01:16:04,410
you produce electromagnetic radiation

1312
01:16:04,430 --> 01:16:05,500
and you are

1313
01:16:05,630 --> 01:16:10,650
accelerating charges up and down by having current going like this

1314
01:16:10,700 --> 01:16:13,070
that from this classical picture

1315
01:16:13,070 --> 01:16:17,110
we know that no radiation will go on in this direction

1316
01:16:17,120 --> 01:16:20,040
but we also know that in that direction

1317
01:16:21,410 --> 01:16:22,700
during acceleration

1318
01:16:22,710 --> 01:16:26,850
that is in this direction wt acceleration was like so

1319
01:16:26,880 --> 01:16:29,410
and in the direction of the acceleration

1320
01:16:29,430 --> 01:16:33,660
no electromagnetic waves go out so nothing goes out here nothing goes out there but

1321
01:16:33,660 --> 01:16:37,890
in the plane perpendicular to a which in this case the blackboard

1322
01:16:37,940 --> 01:16:39,670
is the whole plane like this

1323
01:16:39,680 --> 01:16:44,640
and in this case of the internet is the horizontal plane you we have maximum

1324
01:16:44,650 --> 01:16:46,710
radiation going out

1325
01:16:46,810 --> 01:16:50,430
everywhere in this place and in between somewhere

1326
01:16:50,430 --> 01:16:53,680
you don't have observable but you have had

1327
01:16:53,690 --> 01:16:55,520
to have no

1328
01:16:55,520 --> 01:16:57,120
but immediately when you

1329
01:16:57,130 --> 01:17:00,140
when you make these observations

1330
01:17:00,410 --> 01:17:02,890
because this person

1331
01:17:02,940 --> 01:17:04,660
so basically what

1332
01:17:04,880 --> 01:17:08,130
what's happening here is that you need to

1333
01:17:08,140 --> 01:17:10,340
remember that

1334
01:17:10,390 --> 01:17:15,770
whenever u

1335
01:17:15,780 --> 01:17:20,790
the tricky thing here is about the head to head nodes

1336
01:17:22,140 --> 01:17:22,930
if you

1337
01:17:22,960 --> 01:17:26,910
the not observed

1338
01:17:27,010 --> 01:17:29,260
the head to head nodes

1339
01:17:29,300 --> 01:17:33,260
the parents are independent but this one is you observe the head head nodes

1340
01:17:33,270 --> 01:17:36,120
have that connection

1341
01:17:40,990 --> 01:17:44,740
let's proceed

1342
01:17:44,750 --> 01:17:46,460
the separation

1343
01:17:46,560 --> 01:17:48,890
it's the critical concepts to define

1344
01:17:48,930 --> 01:17:52,250
this is the critical calls to the foreign

1345
01:17:52,290 --> 01:17:54,480
conditional independence

1346
01:17:54,490 --> 01:17:56,620
on bayesian networks OK

1347
01:17:56,670 --> 01:17:58,350
so that's

1348
01:17:58,400 --> 01:18:02,780
three important calls

1349
01:18:02,790 --> 01:18:04,280
so basically

1350
01:18:04,350 --> 01:18:07,140
this separation uses the definitions of

1351
01:18:07,170 --> 01:18:08,870
look at that

1352
01:18:13,060 --> 01:18:17,350
a set of nodes a is said to be d separated from another set of

1353
01:18:17,350 --> 01:18:22,300
nodes b

1354
01:18:24,660 --> 01:18:26,440
not from again

1355
01:18:26,460 --> 01:18:28,350
given a set of nodes c

1356
01:18:28,390 --> 01:18:31,860
the second from to given

1357
01:18:31,900 --> 01:18:36,820
if every path from a to b is blocked when c is in is in

1358
01:18:36,820 --> 01:18:39,400
the conditioning set

1359
01:18:47,070 --> 01:18:49,990
this probably best by by

1360
01:18:50,060 --> 01:18:51,640
by steps

1361
01:18:51,650 --> 01:18:54,410
from may just do this by by

1362
01:18:54,470 --> 01:18:55,760
sorry for this

1363
01:18:58,270 --> 01:19:02,690
so the pens is said to be d separated from a set of

1364
01:19:07,810 --> 01:19:15,990
the set of old

1365
01:19:16,000 --> 01:19:19,500
this separated from a set of rules be

1366
01:19:22,710 --> 01:19:27,320
set of nodes c

1367
01:19:29,520 --> 01:19:32,260
if every pair

1368
01:19:32,270 --> 01:19:34,250
from a to b

1369
01:19:35,390 --> 01:19:36,800
when c

1370
01:19:36,840 --> 01:19:41,110
is in the conditioning set when seasonal

1371
01:19:41,180 --> 01:19:44,610
so let's look at this sort of the OK

1372
01:19:44,650 --> 01:19:48,910
we assume that c is in the conditioning set

1373
01:19:48,930 --> 01:19:52,850
this is a subset of the conditions that may be the entire conditions

1374
01:19:52,890 --> 01:19:57,170
king particularly to subsets OK

1375
01:19:58,050 --> 01:20:03,760
if every possible path from these between these two sets

1376
01:20:05,690 --> 01:20:08,490
is block

1377
01:20:08,510 --> 01:20:11,360
when the condition c

1378
01:20:11,370 --> 01:20:12,990
then we say that

1379
01:20:13,030 --> 01:20:15,490
a is d separated

1380
01:20:15,530 --> 01:20:17,260
but from b by c

1381
01:20:17,260 --> 01:20:21,010
so why is the separate this is just the notion of what we call graph

1382
01:20:21,040 --> 01:20:24,040
separation for directed graphs

1383
01:20:24,130 --> 01:20:25,490
and it's tricky

1384
01:20:25,500 --> 01:20:29,940
because exactly have directed graphs when we see that for markov random fields

1385
01:20:29,990 --> 01:20:33,920
undirected graph to want to take all of the very

1386
01:20:33,940 --> 01:20:35,870
very intuitive

1387
01:20:35,880 --> 01:20:37,230
but in this case

1388
01:20:37,240 --> 01:20:40,910
it's a little bit tricky but you need to keep in mind that this is

1389
01:20:40,910 --> 01:20:42,650
the definition

1390
01:20:44,350 --> 01:20:45,630
in other words

1391
01:20:45,680 --> 01:20:47,150
you need to check

1392
01:20:47,170 --> 01:20:49,020
every single

1393
01:20:49,030 --> 01:20:52,560
from set a to set b

1394
01:20:52,610 --> 01:20:56,590
given the conditions set c and ask whether that that is what

1395
01:20:56,600 --> 01:20:59,550
if every he's blocked

1396
01:20:59,570 --> 01:21:01,740
then you have

1397
01:21:01,740 --> 01:21:03,000
d separation

1398
01:21:03,030 --> 01:21:05,260
then the sets of be separated

1399
01:21:05,320 --> 01:21:06,350
by c

1400
01:21:07,540 --> 01:21:08,390
so now

1401
01:21:08,390 --> 01:21:09,940
here's an exercise

1402
01:21:10,000 --> 01:21:12,810
you have these bayesian networks

1403
01:21:12,870 --> 01:21:16,300
and the question is

1404
01:21:16,380 --> 01:21:21,860
whether x three is the separated

1405
01:21:22,720 --> 01:21:24,790
x six

1406
01:21:24,850 --> 01:21:27,860
when the conditions set is x one

1407
01:21:27,910 --> 01:21:30,870
and x five

1408
01:21:35,260 --> 01:21:37,820
this is basically

1409
01:21:37,840 --> 01:21:40,000
the question

1410
01:21:42,270 --> 01:21:46,520
we observe x one x five

1411
01:21:46,570 --> 01:21:49,400
we have this observation

1412
01:21:49,470 --> 01:21:51,380
and we want to

1413
01:21:51,400 --> 01:21:53,530
no whether

1414
01:21:53,590 --> 01:21:55,520
these viable

1415
01:21:55,520 --> 01:21:58,250
and these viable supported

1416
01:21:58,260 --> 01:22:04,490
if we observe x one x five

1417
01:22:04,500 --> 01:22:09,440
so any guesses

1418
01:22:09,510 --> 01:22:10,660
why not

1419
01:22:10,800 --> 01:22:17,700
thing and

1420
01:22:20,630 --> 01:22:27,530
it is separated or not for that question

1421
01:22:27,580 --> 01:22:30,720
so you need to check every path from here

1422
01:22:30,730 --> 01:22:33,940
so here every number of bands

1423
01:22:33,950 --> 01:22:35,380
from here to here

1424
01:22:35,470 --> 01:22:36,880
for every band

1425
01:22:36,900 --> 01:22:37,750
you need to

1426
01:22:37,760 --> 01:22:39,370
assume that these

1427
01:22:39,380 --> 01:22:43,320
and the the also

1428
01:22:43,320 --> 01:22:46,810
that any

1429
01:22:46,950 --> 01:22:48,830
and so i

1430
01:22:49,150 --> 01:22:53,640
i think that's the question you want to sort of be asking yourself in my

1431
01:22:53,640 --> 01:22:56,260
practical i'm going to try and

1432
01:22:56,270 --> 01:22:58,750
get you to sort of look at the problem where do monte carlo actually makes

1433
01:22:58,750 --> 01:23:03,920
some sense this other practical sort of will be looking at other methods in NLP

1434
01:23:03,920 --> 01:23:08,690
looking problems appropriate so the question is really it's monte carlo the right approach feed

1435
01:23:08,940 --> 01:23:12,560
for you and maybe the way to find out have to implement it and compare

1436
01:23:12,560 --> 01:23:15,390
you do sanity cheque whether the numbers in the right ballpark and then you go

1437
01:23:15,510 --> 01:23:20,190
fast method or you go to this because it's the only thing

1438
01:23:21,120 --> 01:23:26,820
this actually in another motivation for during samples we concentrate alot on sort of numerical

1439
01:23:26,820 --> 01:23:32,080
computation because the concrete thing today but i just examples are pretty say this is

1440
01:23:32,080 --> 01:23:33,170
a figure from

1441
01:23:33,180 --> 01:23:39,130
david mackay's textbook and this isn't machine learning applications there are people who interested in

1442
01:23:39,250 --> 01:23:44,940
tiling shapes in this the whole sort of feel the geometrical combinatorics and this is

1443
01:23:45,190 --> 01:23:50,230
the problem we packed lozenges inside a hexagon you randomly sort of create you can

1444
01:23:50,230 --> 01:23:53,460
think of this as the whole the whole breaks the sort of the pile telling

1445
01:23:53,460 --> 01:23:57,320
out if you can see that optical illusion and this is the random sort of

1446
01:23:57,320 --> 01:24:01,190
way of stacking bricks into hard

1447
01:24:01,200 --> 01:24:05,060
and when you just glance at this you can see that sort of the circle

1448
01:24:06,390 --> 01:24:11,520
and the whole literature on describing the properties of the circle the minor notice it

1449
01:24:11,520 --> 01:24:15,630
was there unless you just looked at samples e

1450
01:24:15,650 --> 01:24:19,460
you could have found this article exists and describe properties of it just by doing

1451
01:24:19,460 --> 01:24:22,700
mathematics but you know is something you should go and look for by just one

1452
01:24:22,700 --> 01:24:23,760
single the sample

1453
01:24:23,770 --> 01:24:26,960
and for r

1454
01:24:26,980 --> 01:24:31,160
i think if you can visualize what you probabilistic model is doing and you can

1455
01:24:31,160 --> 01:24:34,250
draw samples and might give you hints the sort of things that should go away

1456
01:24:34,290 --> 01:24:40,550
you should do so his his really simple example it's sort of it by now

1457
01:24:40,550 --> 01:24:44,000
that the toy problem in machine learning but

1458
01:24:44,010 --> 01:24:45,140
here are some

1459
01:24:45,150 --> 01:24:48,360
very low resolution binary images of digits

1460
01:24:48,390 --> 01:24:55,140
and these are samples drawn from probabilistic models that have been fitted to the dutch

1461
01:24:55,150 --> 01:24:56,280
so the

1462
01:24:56,290 --> 01:25:01,330
these here are sixteen samples drawn from the model which the mixture model suburban areas

1463
01:25:01,330 --> 01:25:04,910
say this to the probabilistic model that basically says

1464
01:25:04,970 --> 01:25:07,620
the way i am going to generate an image is i'm going to pick

1465
01:25:07,630 --> 01:25:11,220
some templated for example are image and i can add a bit of noise to

1466
01:25:11,790 --> 01:25:14,870
and then that's going to be able to out the way you explain any the

1467
01:25:14,870 --> 01:25:18,150
image you see you say this is a bit like one of my templates and

1468
01:25:18,150 --> 01:25:20,900
it's a bit different so i'll explain why not

1469
01:25:20,970 --> 01:25:22,770
and then you draw samples

1470
01:25:22,780 --> 01:25:26,270
you see the really noisy and so that immediately tells you that the sort of

1471
01:25:26,270 --> 01:25:31,210
model and if it's you can't explain all the variations by just a hundred templates

1472
01:25:31,210 --> 01:25:34,330
which is what was fitted here you need to have some more flexible model that

1473
01:25:34,330 --> 01:25:38,620
can capture all of the invariances is that you get in an image

1474
01:25:38,760 --> 01:25:45,840
this is actually a long history of this sort of just eyeballing things and seeing

1475
01:25:45,840 --> 01:25:50,370
how things turn out so is monte carlo methods really took off in the fifties

1476
01:25:50,370 --> 01:25:55,450
one of the first computers but before that for me who was the physicist was

1477
01:25:55,780 --> 01:25:58,010
standing his colleagues because he

1478
01:25:58,020 --> 01:26:01,050
would come in and he would say oh i think that this neutron experiment will

1479
01:26:01,050 --> 01:26:05,160
come out like and he was often write and he is answers in the right

1480
01:26:05,160 --> 01:26:08,170
ball park and it's because he was up at night with the hand adding machine

1481
01:26:08,180 --> 01:26:14,360
running monte carlo simulations on his desk without computer and now we've got the computing

1482
01:26:14,360 --> 01:26:19,740
power we can just do these things trivially so you know we really should

1483
01:26:19,750 --> 01:26:24,700
so for us if we written down our model is a directed graph rather than

1484
01:26:24,790 --> 01:26:29,350
the sort of through the dynamical equations for new neutrons we should know how to

1485
01:26:29,400 --> 01:26:34,020
sample from a model and if we've gone the rate writing down directed graphical model

1486
01:26:34,020 --> 01:26:36,650
or bayes net some people call and then

1487
01:26:36,670 --> 01:26:40,360
the algorithm is really simple and i'm sorry i missed even lectures i don't know

1488
01:26:40,360 --> 01:26:42,630
if you want to say

1489
01:26:42,680 --> 01:26:46,660
the way that you would sample from this base that which was in

1490
01:26:46,670 --> 01:26:52,470
we've been applied the running example if the first just sample all of the parents

1491
01:26:52,470 --> 01:26:55,770
right at the top and we know what the distribution is because when

1492
01:26:55,780 --> 01:27:00,470
this graph is giving up the joint distribution which tells us what these distributions

1493
01:27:00,480 --> 01:27:03,610
and then we sample all the children once we know what the parents are just

1494
01:27:03,610 --> 01:27:06,090
from the conditional distributions that we've written out

1495
01:27:06,110 --> 01:27:09,800
so this graph to give this natural generative structure and that's one of the reasons

1496
01:27:09,800 --> 01:27:13,450
the great modeling the once gone the effort we never and then see what it

1497
01:27:13,450 --> 01:27:18,830
does and it captured the things we wanted to

1498
01:27:20,080 --> 01:27:21,950
so how do we actually

1499
01:27:21,990 --> 01:27:26,100
implement that how do we do this ancestral pass and rule these variables and the

1500
01:27:26,100 --> 01:27:29,380
short answer is that you know we just is not what we we use whatever

1501
01:27:29,430 --> 01:27:33,410
computing environment provides because it's going to have implemented in it already

1502
01:27:33,420 --> 01:27:36,230
a lot of the standard distributions that we used to drink from the prior is

1503
01:27:36,230 --> 01:27:38,990
going to be simple and if

1504
01:27:39,010 --> 01:27:41,450
you're likely to provide these functions and the

1505
01:27:41,460 --> 01:27:45,020
good book which i understand that explains how a lot of these algorithms work under

1506
01:27:45,030 --> 01:27:49,520
the hood so this is sort of old established stuff

1507
01:27:49,540 --> 01:27:54,730
we can have to understand how a couple of these library routines actually work because

1508
01:27:54,760 --> 01:27:56,360
that's going to sort of

1509
01:27:56,380 --> 01:28:00,140
tell us how we can improve on them and that's unless you really know what's

1510
01:28:00,140 --> 01:28:02,950
going on in coming forward from that

1511
01:28:02,970 --> 01:28:08,040
so here's a really standard way of drawing samples from a distribution

1512
01:28:08,100 --> 01:28:11,670
you have some probability density

1513
01:28:13,050 --> 01:28:17,990
you just sampled uniformly point underneath the area from this curve just

1514
01:28:18,030 --> 01:28:23,450
the area here and you just choose something randomly from inside and then if you

1515
01:28:23,450 --> 01:28:29,200
read off the location in the input space you're interested in that's your sample

1516
01:28:29,220 --> 01:28:32,900
so the reason this works is just that

1517
01:28:32,910 --> 01:28:38,550
if the coherence twice as high than here then like much area and efficiency are

1518
01:28:38,550 --> 01:28:41,880
twice as likely to sample it's respect the distribution

1519
01:28:41,900 --> 01:28:45,130
and the way you implement that is you notice that

1520
01:28:45,170 --> 01:28:46,490
so this point here

1521
01:28:46,500 --> 01:28:47,740
has about

1522
01:28:47,750 --> 01:28:50,310
half of the probability mass to its left

1523
01:28:50,330 --> 01:28:52,170
and this point here has a

1524
01:28:52,180 --> 01:28:55,830
six of the probability mass was left to this amount of mass is to the

1525
01:28:55,830 --> 01:28:58,590
left hand side of the point is actually

1526
01:28:58,600 --> 01:29:00,480
a uniform random variable

1527
01:29:00,490 --> 01:29:03,850
the implemented by drawing uniform random variable and working out

1528
01:29:03,860 --> 01:29:06,750
how far through the cave should be

1529
01:29:06,790 --> 01:29:11,530
so mathematically what you do is you work out the cumulative distribution of the curve

1530
01:29:11,560 --> 01:29:15,240
you draw a uniform random variable and the new shops that through the inverse cumulative

1531
01:29:15,430 --> 01:29:20,270
so i say in my grandkids point seven i read across to this cumulative curve

1532
01:29:20,370 --> 01:29:23,230
i read down on sample

1533
01:29:23,290 --> 01:29:26,750
and that's great as long as we can actually

1534
01:29:26,770 --> 01:29:31,330
compute the blue curve and inverted which we can do for gaussians and exponential some

1535
01:29:31,380 --> 01:29:33,450
simple one d

1536
01:29:33,460 --> 01:29:36,680
distributions that we can't always do

1537
01:29:36,870 --> 01:29:41,750
so if you look inside the source code for something like again random number generator

1538
01:29:41,750 --> 01:29:45,010
depending on which label or you're looking at it might do a series of horrendously

1539
01:29:45,010 --> 01:29:48,250
complicated things depending on which parameter regime you're

1540
01:29:48,260 --> 01:29:51,900
and one of the things that might do for some of the promontory genes is

1541
01:29:51,910 --> 01:29:54,310
rejection sampling

1542
01:29:57,370 --> 01:30:01,490
we want to sample point underneath the blue curve for distribution

1543
01:30:01,510 --> 01:30:04,660
and we don't know how to do that because we don't have to compute this

1544
01:30:04,660 --> 01:30:06,160
cumulative and that's it

1545
01:30:06,180 --> 01:30:09,760
but we do know how to sample from a bunch of other distributions like gaussians

1546
01:30:09,760 --> 01:30:15,830
uniform distributions piece wise uniform distributions so we get some of the distribution

1547
01:30:15,840 --> 01:30:19,870
that we do not have some of from like get in and we scale

1548
01:30:19,880 --> 01:30:24,250
the function such that it always above the blue curve

1549
01:30:24,290 --> 01:30:26,660
then we sample

1550
01:30:27,470 --> 01:30:29,670
the green distribution the q distribution

1551
01:30:29,670 --> 01:30:32,330
and so writers of options

1552
01:30:34,640 --> 01:30:37,320
hoping that they expire

1553
01:30:37,360 --> 01:30:38,960
on exercise

1554
01:30:38,970 --> 01:30:40,740
and that's when they make money

1555
01:30:40,750 --> 01:30:42,280
write an option

1556
01:30:42,350 --> 01:30:45,210
and the buyer of the option

1557
01:30:45,220 --> 01:30:49,260
pays the money up front and then you never hear from the buyer again

1558
01:30:49,310 --> 01:30:50,360
and here

1559
01:30:50,370 --> 01:30:52,580
that's that's the way you like it

1560
01:30:52,600 --> 01:30:56,150
so you make money by writing options

1561
01:30:56,540 --> 01:31:01,810
and hoping that they don't get exercise

1562
01:31:02,740 --> 01:31:06,390
and of course you can write a put option

1563
01:31:06,700 --> 01:31:08,440
and that means

1564
01:31:08,450 --> 01:31:14,400
if you write a put option you are signing a contract that says that whenever

1565
01:31:14,400 --> 01:31:17,530
this other guy on the other side of the virus

1566
01:31:17,550 --> 01:31:19,080
decides to

1567
01:31:20,030 --> 01:31:21,780
the guy will

1568
01:31:22,830 --> 01:31:25,520
i will sell you a hundred shares

1569
01:31:25,570 --> 01:31:27,570
at the specified price

1570
01:31:30,950 --> 01:31:35,640
again you're laying yourself open to whatever this guy wants to you've got to receive

1571
01:31:35,650 --> 01:31:37,120
a hundred years

1572
01:31:39,050 --> 01:31:41,300
and pay the money

1573
01:31:46,590 --> 01:31:48,020
these kinds of

1574
01:31:48,030 --> 01:31:49,660
context our

1575
01:31:49,670 --> 01:31:51,230
very old

1576
01:31:51,250 --> 01:31:53,820
and in fact

1577
01:31:53,830 --> 01:31:55,200
we had a conference

1578
01:31:55,210 --> 01:31:58,950
over the weekend at the yale school of management

1579
01:32:01,440 --> 01:32:03,770
it was very interesting never

1580
01:32:03,820 --> 01:32:06,530
experience is anything quite like it

1581
01:32:06,610 --> 01:32:10,150
they i should put the website

1582
01:32:13,550 --> 01:32:14,820
it's called the

1583
01:32:24,090 --> 01:32:26,220
seventeen twenty

1584
01:32:26,340 --> 01:32:28,190
about the stock market

1585
01:32:28,200 --> 01:32:31,290
and the by nicky rare book library

1586
01:32:31,310 --> 01:32:32,960
he has a copy of it

1587
01:32:33,010 --> 01:32:34,630
they are very rare

1588
01:32:34,640 --> 01:32:40,470
about the stock market crash of seventeen twenty

1589
01:32:40,490 --> 01:32:44,410
did you know that there was a big stock market crash in the years seventeen

1590
01:32:45,680 --> 01:32:49,420
what was happening in new haven in seventeen twenty

1591
01:32:49,440 --> 01:32:52,620
well i know one thing that was happening in seventeen twenty

1592
01:32:52,640 --> 01:32:54,540
you you've in new haven

1593
01:32:54,560 --> 01:32:58,800
i'm guessing pretty pretty sure you has some pretty angry investors

1594
01:32:59,030 --> 01:33:01,760
who lost everything in the stock market

1595
01:33:01,780 --> 01:33:05,870
but it could have been the US stock market which wasn't created yet

1596
01:33:07,520 --> 01:33:09,670
the crash of seventeen twenty

1597
01:33:09,720 --> 01:33:12,430
was primarily in paris

1598
01:33:12,500 --> 01:33:15,360
in london

1599
01:33:20,740 --> 01:33:27,910
those with the financial centres of the world's i'm speculating there must have been someone

1600
01:33:27,910 --> 01:33:29,620
here in new haven

1601
01:33:29,920 --> 01:33:35,320
probably yale university he lost in this crash i don't know

1602
01:33:35,360 --> 01:33:40,090
busman's someone here who lost it was a huge and devastating stock market and this

1603
01:33:40,090 --> 01:33:41,980
is the first one actually

1604
01:33:42,030 --> 01:33:44,470
the first stock market crash

1605
01:33:44,490 --> 01:33:48,490
and so we have a lot of fun at this conference and this relates to

1606
01:33:48,490 --> 01:33:52,900
after the taiwan relates options because people writing options

1607
01:33:52,910 --> 01:33:56,710
galore in seventeen twenty and

1608
01:33:59,870 --> 01:34:01,290
the book the great

1609
01:34:01,310 --> 01:34:04,670
so does it work if you search on great mirror of quality

1610
01:34:04,860 --> 01:34:06,740
on the web

1611
01:34:06,790 --> 01:34:08,680
it come up with our conference

1612
01:34:08,880 --> 01:34:12,550
and you see and says this book

1613
01:34:12,560 --> 01:34:15,530
you know copyrights expire after

1614
01:34:15,540 --> 01:34:19,710
but complicated formula but in less than a century so

1615
01:34:19,790 --> 01:34:22,990
this is all public domain so has it up on the web you can read

1616
01:34:22,990 --> 01:34:24,100
the whole book

1617
01:34:24,120 --> 01:34:25,800
unfortunately it's written in dutch

1618
01:34:27,070 --> 01:34:29,000
which might deter some of you

1619
01:34:29,010 --> 01:34:35,370
but lots of pictures and we had great fun so at this conference the

1620
01:34:35,420 --> 01:34:39,430
it was the most interdisciplinary conference ever seen

1621
01:34:39,850 --> 01:34:41,290
because we had

1622
01:34:41,300 --> 01:34:43,090
professors from

1623
01:34:43,170 --> 01:34:44,940
we are history

1624
01:34:44,960 --> 01:34:46,640
comparative literature

1625
01:34:46,680 --> 01:34:53,090
finance economics psychology and we had scholars from all over the world who knew

1626
01:34:53,160 --> 01:34:55,990
about the year seventeen twenty

1627
01:34:56,030 --> 01:34:59,300
including a lot of that the dutchman who are here

1628
01:35:00,920 --> 01:35:04,900
but anyway that the highlight of it was they were a highlight for me

1629
01:35:04,920 --> 01:35:06,620
was it had to

1630
01:35:06,640 --> 01:35:09,000
we saw a picture of an option

1631
01:35:09,010 --> 01:35:10,700
from this time

1632
01:35:10,740 --> 01:35:14,460
an option contract to buy stocks

1633
01:35:14,480 --> 01:35:16,010
from amsterdam

1634
01:35:16,020 --> 01:35:20,580
and it showed it was a printed form

1635
01:35:20,630 --> 01:35:24,240
they had printed forms back now this in holland it's open to open it up

1636
01:35:24,240 --> 01:35:28,130
with blanks to fill in as a place to fill in the exercise price

1637
01:35:28,170 --> 01:35:31,970
and they exercised a i don't know whether it was american or european

1638
01:35:31,980 --> 01:35:35,460
at the time but i'm sure if it was american they didn't call it an

1639
01:35:35,460 --> 01:35:39,910
american option in seventeen twenty they don't even call them options because it's on dutch

1640
01:35:39,920 --> 01:35:41,310
so i don't know

1641
01:35:41,360 --> 01:35:44,380
it was some other word not options

1642
01:35:44,390 --> 01:35:51,420
but i'm just saying this because the ability to think about seventeen twenty is that

1643
01:35:51,650 --> 01:35:57,010
they didn't make the same distinction between investing in gambling that we do now

1644
01:35:57,030 --> 01:35:58,680
right now

1645
01:35:58,690 --> 01:36:01,780
anyone on wall street is very close to be

1646
01:36:01,860 --> 01:36:03,440
any suggestions

1647
01:36:04,680 --> 01:36:06,580
connection with gambling

1648
01:36:06,600 --> 01:36:07,620
and so

1649
01:36:07,790 --> 01:36:08,980
back then

1650
01:36:09,020 --> 01:36:10,200
they didn't care

1651
01:36:10,260 --> 01:36:14,280
so lots of socks would have lotteries attached to

1652
01:36:14,290 --> 01:36:17,420
there would be all kinds of something called the time team

1653
01:36:18,880 --> 01:36:22,540
a group of investors would invest in something and

1654
01:36:22,540 --> 01:36:27,210
one hypothesis one make a large error in estimating the generalisation error

1655
01:36:27,230 --> 01:36:32,680
all the hypothesis to make large error has been generalization error and so on

1656
01:36:33,270 --> 01:36:36,330
and so by the union bound with the left foot to

1657
01:36:43,270 --> 01:36:48,520
which is therefore less than equal to

1658
01:36:58,520 --> 01:37:05,520
subsequent to that

1659
01:37:05,770 --> 01:37:30,230
and so on

1660
01:37:30,250 --> 01:37:36,370
then just take one minus both sides

1661
01:37:36,390 --> 01:37:40,600
the creation of the previous one then we take one minus both sides

1662
01:37:40,620 --> 01:37:43,480
the probability that does not exist

1663
01:37:47,600 --> 01:37:49,560
such that

1664
01:37:56,770 --> 01:38:01,270
on the property that does not exist a hypothesis i which i make a large

1665
01:38:01,270 --> 01:38:08,210
error in this estimate of this is equal to the probability that for all hypotheses

1666
01:38:12,290 --> 01:38:13,620
i mean

1667
01:38:15,870 --> 01:38:19,640
camera unless the generalisation error

1668
01:38:19,660 --> 01:38:25,250
on and taking one minus the right hand side again

1669
01:38:26,190 --> 01:38:27,790
he two

1670
01:38:27,790 --> 01:38:30,390
gamma describe them

1671
01:38:33,830 --> 01:38:34,810
and so

1672
01:38:34,830 --> 01:38:39,540
on the side of the inequality flat because i took one minus both the minus

1673
01:38:39,540 --> 01:38:42,480
sign the sign of quality

1674
01:38:45,520 --> 01:38:48,370
so what we've shown is that

1675
01:38:49,520 --> 01:38:51,020
with probability

1676
01:38:51,020 --> 01:38:53,810
abbreviated to WP with probability

1677
01:38:53,810 --> 01:38:58,290
one minus the two chemistry

1678
01:38:58,290 --> 01:39:00,710
we have that

1679
01:39:00,710 --> 01:39:03,230
on left one half of each

1680
01:39:05,870 --> 01:39:07,040
will be

1681
01:39:07,080 --> 01:39:14,810
moving camera moves on

1682
01:39:14,830 --> 01:39:22,730
simultaneously for all

1683
01:39:22,810 --> 01:39:25,100
hypotheses in r

1684
01:39:27,080 --> 01:39:34,410
and so on

1685
01:39:34,430 --> 01:39:40,180
just to get this name was just to get this result the name this is

1686
01:39:42,750 --> 01:39:50,560
on this is one instance of what's called uniform convergence results on and

1687
01:39:50,560 --> 01:39:56,570
that the term uniform convergence this so these the fact that all the shows as

1688
01:39:56,570 --> 01:39:58,270
n becomes large

1689
01:39:58,290 --> 01:40:05,790
o then these eps long hats what all simultaneously converge to absolute pitch that

1690
01:40:05,830 --> 01:40:13,180
training error will become very close to generalisation error simultaneously for all hypotheses h that's

1691
01:40:13,180 --> 01:40:15,040
what does the term uniform

1692
01:40:15,080 --> 01:40:19,350
refers to the fact that this converges for all hypotheses h and not just one

1693
01:40:20,540 --> 01:40:24,600
so what shown is one example of uniform convergence

1694
01:40:24,790 --> 01:40:29,180
so let me clean a couple more ports to come back and ask questions you

1695
01:40:29,180 --> 01:40:32,460
have about this was taken look at this initial unmixed

1696
01:40:39,410 --> 01:41:16,040
what questions you have about this

1697
01:41:16,080 --> 01:41:18,980
i value of

1698
01:41:20,540 --> 01:41:22,330
right so let's see

1699
01:41:22,520 --> 01:41:27,020
chris has gamma how the value of gamma computed so for this purpose for the

1700
01:41:27,020 --> 01:41:31,960
purposes of this of gamma is a constant imagine the gamma some constant we chose

1701
01:41:31,960 --> 01:41:35,480
in advance and this is the bound holds true for

1702
01:41:35,480 --> 01:41:38,140
any fixed value of gamma

1703
01:41:38,190 --> 01:41:40,500
on later on as we

1704
01:41:40,500 --> 01:41:46,210
take this bound and develop this result further on which is specific values of gamma

1705
01:41:46,210 --> 01:41:53,460
support this analysis imagine that prove this holds true for any value

1706
01:41:59,270 --> 01:42:04,040
have the hypothesis spaces and so this this simple result will work in its present

1707
01:42:04,040 --> 01:42:09,410
form the which generalizes on very won't get to today but will generalize this at

1708
01:42:09,410 --> 01:42:12,390
the beginning of the next letter to the hypothesis

1709
01:42:18,250 --> 01:42:21,500
his theory practice linear

1710
01:42:21,520 --> 01:42:25,890
i might get a little more of that later today i will talk critically about

1711
01:42:25,890 --> 01:42:27,080
our problems

1712
01:42:27,100 --> 01:42:28,870
that's the consequences of a

1713
01:42:28,890 --> 01:42:33,100
the understanding these things to you in the next lectures well

1714
01:42:35,230 --> 01:42:38,890
his raise your hand if things are true so far make sense

1715
01:42:39,060 --> 01:42:40,710
cool great

1716
01:42:44,270 --> 01:42:48,480
all right then just take this uniform convergence bound and

1717
01:42:48,520 --> 01:42:50,910
we write it in a couple of other forms

1718
01:42:55,080 --> 01:42:59,520
it's sort of the bound on probability this is saying suppose pacific training set and

1719
01:42:59,610 --> 01:43:04,330
typically transit fixed by my threshold by air pressure gamma

1720
01:43:04,330 --> 01:43:10,390
of what is the probability that uniform convergence holds and well that's that's formula gives

1721
01:43:10,390 --> 01:43:13,250
the answer is the probability of something happening

1722
01:43:15,300 --> 01:43:21,080
so they actually three parameters of interest one is one of the pub what probability

1723
01:43:21,100 --> 01:43:26,080
the other parameters was the training set size and and the third parameter as the

1724
01:43:26,080 --> 01:43:29,710
value of this error threshold gamma

1725
01:43:29,710 --> 01:43:31,160
on on on the ground

1726
01:43:31,180 --> 01:43:34,000
that very painful for these purposes

1727
01:43:34,020 --> 01:43:38,910
this suggests two other because forms the bounds on which is so you can ask

1728
01:43:41,500 --> 01:43:47,310
and this is what we propose giving gamma given and what is the probability of

1729
01:43:47,310 --> 01:43:49,660
uniform convergence

1730
01:43:49,690 --> 01:43:52,730
on the other because forms are

1731
01:43:52,730 --> 01:43:55,950
so given camera

1732
01:43:57,460 --> 01:44:00,730
the probability delta of making a large error

1733
01:44:05,100 --> 01:44:08,330
how large training set size you need in order to give

1734
01:44:08,390 --> 01:44:10,890
a bound on on

1735
01:44:10,910 --> 01:44:15,210
uh how much harder publish a society need

1736
01:44:15,230 --> 01:44:19,390
to give a uniform convergence bound with apprentice cameron delta

1737
01:44:19,410 --> 01:44:20,270
and so

1738
01:44:22,290 --> 01:44:28,770
so he said delta to be able to to cater to demonstrate that this that

1739
01:44:28,770 --> 01:44:30,390
all i had on the left

1740
01:44:30,450 --> 01:44:33,060
and strong

1741
01:44:33,100 --> 01:44:39,810
four and what you find is that on there an equivalent form of this result

1742
01:44:39,830 --> 01:44:42,120
says that

1743
01:44:42,190 --> 01:44:48,120
so long as you training size and weight

1744
01:44:48,140 --> 01:44:52,310
and this is the formula that get by solving for n

1745
01:44:52,730 --> 01:44:58,040
so long emissary to do this

1746
01:44:58,040 --> 01:45:01,040
then the graph would break into two or more pieces

1747
01:45:01,120 --> 01:45:04,870
so it's a if you cut those out then the graph breaks apart

1748
01:45:04,880 --> 01:45:08,360
so we're going to see is that these two things these two notion cliques

1749
01:45:08,780 --> 01:45:15,750
and cutsets these play an important role in how we describe undirected graphical models

1750
01:45:20,770 --> 01:45:24,490
the way these graphical models work is that what you're doing is you're using the

1751
01:45:25,490 --> 01:45:31,190
describe what you believe about the dependencies that you see in your random variables

1752
01:45:31,200 --> 01:45:36,480
right in many applications is again the notion of locality if if you have a

1753
01:45:36,480 --> 01:45:42,140
collection of sensors your intuition is that censorship interact local in the spatial sense the

1754
01:45:42,170 --> 01:45:46,500
censor here should interact with one here but it shouldn't interact directly with something on

1755
01:45:46,500 --> 01:45:49,460
the other side of the room which interact with its neighbours

1756
01:45:49,470 --> 01:45:53,830
and so the graph here is is specifying this neighborhood structure

1757
01:45:56,280 --> 01:46:00,270
in a more precise sense use the graph to impose constraints on the random vector

1758
01:46:00,270 --> 01:46:04,370
and there's two different ways to do this they seem different first but they turn

1759
01:46:04,380 --> 01:46:05,780
out to be equivalent

1760
01:46:05,780 --> 01:46:10,710
in the first is by the notion of markov properties

1761
01:46:10,730 --> 01:46:12,480
so you say that

1762
01:46:12,750 --> 01:46:18,120
the random vector x all the random variables its markov if

1763
01:46:18,680 --> 01:46:24,320
the subsets of variables x a and x b become conditionally independent whenever you have

1764
01:46:24,320 --> 01:46:26,270
a vertex cut set

1765
01:46:26,270 --> 01:46:29,340
so what this means is that

1766
01:46:29,370 --> 01:46:33,090
if you observe the the values of the random variables here

1767
01:46:33,100 --> 01:46:35,520
right your conditioning on then when you observe them

1768
01:46:35,520 --> 01:46:37,520
then it says that

1769
01:46:37,530 --> 01:46:43,110
this subset of variables x eighty a becomes conditionally independent of the subset

1770
01:46:43,130 --> 01:46:47,670
so it's sort of capturing the fact that when you condition that's breaking the graph

1771
01:46:47,780 --> 01:46:53,070
and in terms of the random variables it's breaking them apart because they become independent

1772
01:46:53,090 --> 01:46:56,210
see all

1773
01:46:56,330 --> 01:46:59,770
you will have heard last time from sam about the simple example when you have

1774
01:46:59,770 --> 01:47:01,290
an HMM

1775
01:47:01,300 --> 01:47:05,880
this is the simplest example of the markov property if you think about the present

1776
01:47:06,860 --> 01:47:09,830
and this is the future and this is the past

1777
01:47:09,840 --> 01:47:13,060
so if you condition on the present that the cuts that that will break the

1778
01:47:13,060 --> 01:47:18,380
graph into two then as m told us the past and the future become conditionally

1779
01:47:19,490 --> 01:47:24,060
some kind of mystical but that's just a special case of of the markov property

1780
01:47:24,060 --> 01:47:25,350
that i just stated

1781
01:47:25,480 --> 01:47:30,590
so this is something past and future and present that's a special case of this

1782
01:47:30,590 --> 01:47:34,940
poor interested in this actually for more general graphs and you get much richer markov

1783
01:47:34,940 --> 01:47:42,250
properties in more general graphs

1784
01:47:42,260 --> 01:47:46,310
so that's the markov property that's one way that you can use the graph to

1785
01:47:46,310 --> 01:47:49,190
constrain the form of the distribution

1786
01:47:50,010 --> 01:47:52,790
the other way constrain the form of the distribution is

1787
01:47:52,820 --> 01:47:58,050
is in terms of how the distribution might factorize so let's get back to this

1788
01:47:58,050 --> 01:48:01,630
example let's imagine that you had

1789
01:48:01,670 --> 01:48:06,750
binary variables so variables that took value zero and one zero one one zero and

1790
01:48:06,750 --> 01:48:10,180
one that every one of these nodes

1791
01:48:10,650 --> 01:48:11,440
right so

1792
01:48:11,440 --> 01:48:15,450
in general how many numbers would you need to represent the distribution over that set

1793
01:48:15,450 --> 01:48:27,840
of random variables

1794
01:48:27,860 --> 01:48:33,350
right so to do the seven minus one

1795
01:48:33,370 --> 01:48:38,820
right because you've got to do seven possible configurations in your whole graph

1796
01:48:38,920 --> 01:48:43,970
but then probability distributions have to some to once you lose one degree of freedom

1797
01:48:43,990 --> 01:48:47,180
right so to do the seven this is a toy problem again this this is

1798
01:48:47,180 --> 01:48:52,560
not something practical it's already getting big if you thought about something that for instance

1799
01:48:52,560 --> 01:48:57,450
modelling in images to binary image that was a four hundred by four hundred you'd

1800
01:48:57,450 --> 01:48:59,940
be looking at two to four hundred square

1801
01:49:00,030 --> 01:49:05,370
that's a very big number that's an understatement that's

1802
01:49:05,430 --> 01:49:10,180
that's more than the number of atoms in the entire universe the entire visible universe

1803
01:49:10,380 --> 01:49:14,280
so it saying is that unless you start exporting structure there's no way you could

1804
01:49:14,280 --> 01:49:18,630
ever even store you can store vector that has two to four hundred square elements

1805
01:49:19,210 --> 01:49:23,480
if you can then i'd like a version of your computer please

1806
01:49:25,730 --> 01:49:29,180
so the point here is that we're going to use the graph to constrain the

1807
01:49:29,180 --> 01:49:33,290
form of the distribution we going to impose the to be local

1808
01:49:33,320 --> 01:49:36,010
so it's going to drop the number of degrees of freedom

1809
01:49:36,020 --> 01:49:41,690
so we're losing something in doing that we're losing we can express all distributions anymore

1810
01:49:41,700 --> 01:49:44,850
but we're getting a lot because we can actually do things with this model we

1811
01:49:44,850 --> 01:49:49,180
can store it we can apply it and we can do inference and the way

1812
01:49:49,180 --> 01:49:51,360
we constrain is by saying things have to

1813
01:49:51,380 --> 01:49:58,070
decompose into local functions these are called compatibility functions are potential functions and these functions

1814
01:49:58,070 --> 01:50:01,830
are local in the sense that they depend only on the random variables in the

1815
01:50:01,830 --> 01:50:04,690
cliques of be function for one two three

1816
01:50:04,760 --> 01:50:11,430
a function for three four five et cetera local product of functions

1817
01:50:11,450 --> 01:50:15,730
so just look at a simple example lets go back to this image model that

1818
01:50:15,730 --> 01:50:20,650
we had before now i'm trying to model about boone

1819
01:50:20,680 --> 01:50:25,920
and again i'm using this the simple lattice model and thinking about these being grayscale

1820
01:50:25,920 --> 01:50:30,460
values might be zero one or they might be zero one to two hundred fifty

1821
01:50:31,860 --> 01:50:35,800
so what you want to think about is the cliques here the maximal cliques are

1822
01:50:35,800 --> 01:50:38,010
just edges just pairs of nodes

1823
01:50:38,050 --> 01:50:42,670
so what it means is that you're sort of allow function of pairwise interaction term

1824
01:50:42,670 --> 01:50:46,430
that's going to sit on every one of these edges and that term is going

1825
01:50:46,430 --> 01:50:50,100
to tell you how is this pixel value related to this pixel value

1826
01:50:50,150 --> 01:50:54,290
so simple case if i just had three grey scales

1827
01:50:54,310 --> 01:50:56,790
number three by three matrix

1828
01:50:56,810 --> 01:51:01,170
i might look at an interaction of this form i could have one number a

1829
01:51:01,210 --> 01:51:03,010
along the diagonal

1830
01:51:03,020 --> 01:51:05,850
and then be on the off diagonal

1831
01:51:05,880 --> 01:51:09,830
and so this would be two parameters here and if i said a larger than

1832
01:51:10,880 --> 01:51:15,040
what they would tell you is that you're more likely to have their values on

1833
01:51:15,040 --> 01:51:17,210
the diagonal values are equal

1834
01:51:17,210 --> 01:51:21,710
the values on the off diagonal so this would start imposing kind of smoothness constraint

1835
01:51:21,750 --> 01:51:22,490
would say

1836
01:51:22,500 --> 01:51:25,850
pixels that are nearby like pixels on this knows

1837
01:51:25,870 --> 01:51:28,860
are likely to have close grayscale values

1838
01:51:28,880 --> 01:51:32,980
so it's a very simple kind of thing that imposing but it let's start

1839
01:51:32,990 --> 01:51:37,950
so that's how compatibility functions work they sort to tell you about local interactions between

1840
01:51:40,640 --> 01:51:47,040
OK so let me say something briefly about directed graphical models again this recapping what

1841
01:51:47,190 --> 01:51:50,580
sam did

1842
01:51:50,610 --> 01:51:55,300
for directed models you have now arrows on the edges and the semantics are somewhat

1843
01:51:57,640 --> 01:52:02,010
you really think about the parents for instance by focus on the blue note here

1844
01:52:02,020 --> 01:52:07,370
its parents are these red nodes and you think about the factorisation is taking place

1845
01:52:07,800 --> 01:52:11,520
over conditional distributions of the child's given its parents

1846
01:52:11,520 --> 01:52:19,210
so in some ways it's it's a kind of parent to child it's generational factorizations

1847
01:52:19,210 --> 01:52:22,040
the child conditioned on its parents

1848
01:52:22,070 --> 01:52:25,060
so these models are useful for

1849
01:52:25,080 --> 01:52:31,810
they can express certain kinds of causal relations sam mentions something called explaining away phenomenon

1850
01:52:31,820 --> 01:52:36,730
so the certain kinds of things that directed graphical models can express the undirected ones

1851
01:52:36,730 --> 01:52:37,670
can not

1852
01:52:37,730 --> 01:52:42,210
but vice versa there are some things that undirected models can express the directed ones

1853
01:52:44,610 --> 01:52:46,590
one model is not better than the other

1854
01:52:46,950 --> 01:52:49,870
it really depends on what kind of application you're looking at

1855
01:52:49,920 --> 01:52:54,010
and it takes experience and intuition to sort of figure out what's most appropriate for

1856
01:52:54,090 --> 01:52:56,240
what you're trying to model

1857
01:52:56,290 --> 01:53:00,040
for the purposes of this talk

1858
01:53:00,080 --> 01:53:04,240
i'm going to focus mainly on undirected models as i mentioned before

1859
01:53:04,250 --> 01:53:08,740
and the reason being that when it comes time to doing inference

1860
01:53:08,750 --> 01:53:10,550
the first step

1861
01:53:10,600 --> 01:53:15,920
when you're given a directed graphical models actually to convert it to an undirected model

1862
01:53:16,210 --> 01:53:18,430
so from the computational point of view

1863
01:53:18,430 --> 01:53:23,310
if you're given a directed model you typically converted first to an undirected model

1864
01:53:23,450 --> 01:53:27,500
and since all be talking primarily about computation in the later part of the talk

1865
01:53:27,500 --> 01:53:30,820
all sort of assume that you've converted this directed model

1866
01:53:30,880 --> 01:53:35,300
if you remember sam mentioned this it has a quirky name the procedure is called

1867
01:53:36,840 --> 01:53:40,790
because what you do is you marry all the parents the parents have had an

1868
01:53:40,870 --> 01:53:42,440
illegitimate child

1869
01:53:42,440 --> 01:53:44,700
modern convex it's fine

1870
01:53:44,720 --> 01:53:48,660
and it's not just every line segment defined by two points but the entire line

1871
01:53:48,660 --> 01:53:53,860
defined by only two points in the set is included in that find mindset

1872
01:53:53,900 --> 01:53:55,480
the set of linear inequalities

1873
01:53:55,490 --> 01:53:57,730
the finds are convex sets

1874
01:53:57,810 --> 01:54:00,070
one point here in

1875
01:54:00,100 --> 01:54:06,530
and i use this notation with this inequality to denote componentwise inequality between vector

1876
01:54:06,610 --> 01:54:12,130
this is a component inequality between vector x in effective b

1877
01:54:12,140 --> 01:54:17,060
norm balls the set of vectors x with normal is then given there are is

1878
01:54:17,530 --> 01:54:18,900
always convex

1879
01:54:18,900 --> 01:54:23,910
as for any norm that's follows from the definition of norms

1880
01:54:23,930 --> 01:54:27,340
and there is a related set known as normal college

1881
01:54:27,390 --> 01:54:32,740
then we look at factors xt is some vector in r and t is the

1882
01:54:33,900 --> 01:54:38,810
and the norm cone is defined as this point xt

1883
01:54:39,060 --> 01:54:41,510
the norm of x is necessary to fifty

1884
01:54:41,520 --> 01:54:45,480
so that's the con because every positive multiple of xt that lies in this set

1885
01:54:45,480 --> 01:54:46,900
is also in the set

1886
01:54:46,940 --> 01:54:50,770
and you can also show it's convex if this is the norm

1887
01:54:50,770 --> 01:54:53,750
and that's true for any type of norms

1888
01:54:53,820 --> 01:54:58,910
and i will also encounter the set of positive semidefinite matrices and that some notation

1889
01:54:58,920 --> 01:55:00,600
so in

1890
01:55:00,640 --> 01:55:02,720
n denotes the order of the

1891
01:55:04,490 --> 01:55:06,730
press stands for positive semi definite

1892
01:55:06,740 --> 01:55:09,880
and then i'll use again this generalized inequality

1893
01:55:10,920 --> 01:55:15,130
in the case of the matrix of the node positive semidefiniteness so this means that

1894
01:55:15,130 --> 01:55:18,170
the symmetric matrix is positive semidefinite

1895
01:55:18,230 --> 01:55:19,170
and it's also

1896
01:55:19,200 --> 01:55:21,800
convex sets

1897
01:55:21,810 --> 01:55:27,850
and then there are some simple properties that you can use to show that to

1898
01:55:27,850 --> 01:55:30,740
drive convex sets from simple convex sets

1899
01:55:30,750 --> 01:55:34,040
so if you take the image of a convex set under a linear transformation you

1900
01:55:34,040 --> 01:55:36,150
obtain a convex set

1901
01:55:36,160 --> 01:55:40,090
and that's easy to see because line segments are mapped to line segments by a

1902
01:55:40,090 --> 01:55:42,260
linear transformation

1903
01:55:42,270 --> 01:55:45,530
so for the inverse image under a linear transformation

1904
01:55:45,590 --> 01:55:49,480
and also the intersection of any number of convex sets is convex

1905
01:55:49,520 --> 01:55:52,630
that's follows directly from the definition if you

1906
01:55:52,670 --> 01:55:54,790
think about the definition

1907
01:55:54,810 --> 01:55:55,610
and that's

1908
01:55:55,630 --> 01:55:58,180
a very useful property

1909
01:55:58,290 --> 01:56:02,780
allows you for example to immediately see that this set is convex without even applying

1910
01:56:02,780 --> 01:56:05,670
the definition

1911
01:56:05,680 --> 01:56:09,820
so here i define a set c of vectors in rn

1912
01:56:09,850 --> 01:56:14,360
and the vectors the components of x are the coefficients of course a polynomial of

1913
01:56:14,360 --> 01:56:15,820
order n

1914
01:56:15,900 --> 01:56:20,300
x one course antiques to call center t and so on so every set of

1915
01:56:20,300 --> 01:56:23,060
every vector x defines a course in polynomial

1916
01:56:23,120 --> 01:56:27,000
and this shows three is very visible but this shows three

1917
01:56:27,220 --> 01:56:30,140
of course some apologise for

1918
01:56:30,150 --> 01:56:31,370
choice of x

1919
01:56:31,590 --> 01:56:37,030
then define set c as the polynomial coefficients of a polynomial

1920
01:56:37,310 --> 01:56:40,640
for which this polynomial is between one and negative one

1921
01:56:40,640 --> 01:56:41,660
on the interval

1922
01:56:41,700 --> 01:56:44,810
of t between zero and pi over three

1923
01:56:44,840 --> 01:56:50,610
so these three example satisfy this property so the columns corresponding coefficient vectors or in

1924
01:56:52,150 --> 01:56:55,770
well this set c is always convex and that follows from the

1925
01:56:55,790 --> 01:56:58,680
is easily seen from the intersection property

1926
01:56:58,700 --> 01:56:59,910
because if you

1927
01:56:59,930 --> 01:57:02,840
look at this condition for a fixed e

1928
01:57:02,850 --> 01:57:06,550
then the condition that p of t is between

1929
01:57:06,560 --> 01:57:10,930
one negative one defines two linear inequalities in the coefficients x

1930
01:57:10,940 --> 01:57:12,600
if t is fixed

1931
01:57:12,610 --> 01:57:13,900
so it defines two

1932
01:57:14,790 --> 01:57:16,640
half spaces

1933
01:57:16,660 --> 01:57:22,160
and the solution set for fixed is actually a slab between two parallel has spaces

1934
01:57:23,240 --> 01:57:24,890
and then in this definition be

1935
01:57:24,900 --> 01:57:30,520
define x the set c is intersection of infinitely and infinitely many of those convex

1936
01:57:32,840 --> 01:57:39,170
so this is convex because it's intersection of in this case infinitely many convex sets

1937
01:57:39,190 --> 01:57:43,240
and so in an example for hours two it looks like the intersection of all

1938
01:57:43,240 --> 01:57:46,850
those as spaces

1939
01:57:46,890 --> 01:57:52,630
and t it's convex

1940
01:57:52,640 --> 01:57:55,740
so that's all i say about convex sets

1941
01:57:55,790 --> 01:57:59,430
so then next that can define convex functions

1942
01:57:59,460 --> 01:58:03,200
so the function f is convex if first of all its domain is convex so

1943
01:58:03,200 --> 01:58:06,590
the set of points experts define convex

1944
01:58:06,760 --> 01:58:11,550
and on its domain it satisfies this inequality is jensen's inequality

1945
01:58:11,590 --> 01:58:15,010
so this is that if you take two points x o y

1946
01:58:15,030 --> 01:58:18,760
then on the line segment if you consider function on the lines seem defined by

1947
01:58:18,760 --> 01:58:20,030
x and y

1948
01:58:20,050 --> 01:58:25,150
the graph of the function is below the linear interpolation between the function values at

1949
01:58:25,170 --> 01:58:26,400
x and y

1950
01:58:26,410 --> 01:58:29,070
so the graph of the function lies below this

1951
01:58:29,220 --> 01:58:31,610
linear segments

1952
01:58:31,620 --> 01:58:34,030
so function satisfies is is convex

1953
01:58:34,040 --> 01:58:39,180
and if mine f satisfies it's the function is concave

1954
01:58:39,240 --> 01:58:43,350
so you can also related to the theory of convex sets

1955
01:58:43,350 --> 01:58:47,470
so the epigraph of the function f in in general is defined as a set

1956
01:58:47,470 --> 01:58:52,760
in fact xt so in dimension but dimension one higher than the

1957
01:58:52,790 --> 01:58:54,700
the main office

1958
01:58:54,730 --> 01:58:57,680
and the point xt is an epigraph if

1959
01:58:57,730 --> 01:59:00,510
f of x is less than or equal to t

1960
01:59:00,560 --> 01:59:05,280
so it's a graph of the function and everything above the ground at school because

1961
01:59:07,040 --> 01:59:10,430
so this is the graph of a function that's obviously not convex

1962
01:59:10,450 --> 01:59:14,900
but for convex functions we have the property that the

1963
01:59:14,900 --> 01:59:18,180
epigraph is also convex in s if and only if

1964
01:59:18,180 --> 01:59:21,990
marginalize integrate over the parameters and hyperparameters

1965
01:59:22,020 --> 01:59:24,020
that's ultimately what we want to do

1966
01:59:24,880 --> 01:59:28,990
and once we do that well we can be simple monte carlo approximation

1967
01:59:29,020 --> 01:59:31,720
right where the samples

1968
01:59:31,740 --> 01:59:34,380
i generated by markov chains

1969
01:59:34,390 --> 01:59:38,390
with the stationary distribution which is the posterior distribution of our model parameters

1970
01:59:38,420 --> 01:59:39,630
it's just this

1971
01:59:39,650 --> 01:59:41,550
general setup for

1972
01:59:41,780 --> 01:59:47,240
o doing inference in the directed graphical models

1973
01:59:48,440 --> 01:59:57,080
in our implementation we use gibbs sampling to generate samples but corsican use any other

1974
01:59:57,080 --> 02:00:00,530
markov chain monte carlo procedure and of course you can see the due to the

1975
02:00:00,530 --> 02:00:05,190
conjugate priors the conditional distributions are easy to sample from so that was our initial

1976
02:00:06,620 --> 02:00:11,650
one other thing to notice is that the posterior distribution of the movie and user

1977
02:00:11,720 --> 02:00:13,820
confusion matrices decoupled

1978
02:00:14,670 --> 02:00:19,530
they become as the product of individual user features so you can sterilize

1979
02:00:19,570 --> 02:00:23,400
in other words you can make it efficient in that for that particular graphical model

1980
02:00:23,420 --> 02:00:24,450
that we consider

1981
02:00:24,560 --> 02:00:27,080
and you can see from

1982
02:00:27,710 --> 02:00:32,580
this graph here is that conditional on these values in these values

1983
02:00:32,630 --> 02:00:34,760
the posterior distribution of the

1984
02:00:36,010 --> 02:00:39,080
user features decouple the same as for the movie features

1985
02:00:41,940 --> 02:00:47,680
so we do is standard example which is to say that conditional on

1986
02:00:47,720 --> 02:00:52,200
more features we can update we can get sample from a sample from the posterior

1987
02:00:52,200 --> 02:00:53,940
or with these latent variables

1988
02:00:54,000 --> 02:00:59,140
and same is for those guys and then for each feature vector

1989
02:00:59,150 --> 02:01:00,970
for each

1990
02:01:01,000 --> 02:01:06,010
we get sample for each morning feature vector by conditioning on the user feature vectors

1991
02:01:06,010 --> 02:01:09,240
five so that's just a standard gibbs sampling

1992
02:01:09,280 --> 02:01:13,440
so that was conditional on this random variable in these in the variables

1993
02:01:13,500 --> 02:01:18,070
we just get samples from those guys and alternate so now

1994
02:01:18,080 --> 02:01:20,490
this is all very standard and

1995
02:01:20,510 --> 02:01:22,510
i haven't told you anything you

1996
02:01:24,360 --> 02:01:27,940
one of the the things that we were looking at initially with sort of playing

1997
02:01:27,940 --> 02:01:30,960
with the netflix dataset as a huge dataset

1998
02:01:30,970 --> 02:01:33,070
and the main

1999
02:01:33,120 --> 02:01:34,590
question was that

2000
02:01:34,630 --> 02:01:38,510
how do we deal with this regularisation things and what we typically do is we

2001
02:01:38,510 --> 02:01:43,260
ran cross validation we try to figure out what the appropriate hyperparameters should be

2002
02:01:43,440 --> 02:01:47,210
in just to give you the player the netflix dataset is very large it contains

2003
02:01:47,210 --> 02:01:52,740
hundred million ratings contains half a million users and a about eighteen thousand movies

2004
02:01:52,750 --> 02:01:54,490
there's a validation set

2005
02:01:54,550 --> 02:01:57,930
and there is a test set for which must be predicting

2006
02:01:57,970 --> 02:01:59,700
user movie ratings

2007
02:01:59,750 --> 02:02:03,120
in the dataset itself is very imbalanced so

2008
02:02:03,150 --> 02:02:06,330
you know other users could give only one rating in the users would be fifteen

2009
02:02:06,330 --> 02:02:08,080
hundred ratings

2010
02:02:08,140 --> 02:02:10,990
and the performance is also says by

2011
02:02:11,030 --> 02:02:12,950
you know you make predictions you submit it

2012
02:02:12,960 --> 02:02:15,650
to the netflix and then give you the results so

2013
02:02:15,660 --> 02:02:19,570
it's one of those things that's hard to cheat on who accidentally you

2014
02:02:20,690 --> 02:02:24,970
now one of the things that

2015
02:02:25,020 --> 02:02:26,190
you know the question is

2016
02:02:26,200 --> 02:02:31,000
the nice thing about probabilistic matrix factorisation doing map version of forensic medical situations that

2017
02:02:31,000 --> 02:02:34,360
very efficient and you can do it fast and

2018
02:02:34,370 --> 02:02:39,420
initially we were thinking well actually take a fully bayesian approach you have hundred million

2019
02:02:39,420 --> 02:02:41,500
ratings big data

2020
02:02:42,470 --> 02:02:44,480
and typically if you look at

2021
02:02:44,490 --> 02:02:49,080
attitudes of all the people that you know MCMC methods are

2022
02:02:49,150 --> 02:02:51,440
really really for small problems

2023
02:02:51,490 --> 02:02:56,120
and what really work in this particular context

2024
02:02:56,240 --> 02:03:00,800
and we actually with surprise that

2025
02:03:00,820 --> 02:03:05,190
indeed it does work

2026
02:03:05,230 --> 02:03:08,220
so here the results that showing you

2027
02:03:08,280 --> 02:03:10,220
this is the SVD one

2028
02:03:10,240 --> 02:03:14,700
which is basically probabilistic matrix factorisation model but without any regularisation

2029
02:03:14,740 --> 02:03:19,200
this is probabilistic matrix factorisation model this is a slightly different version of probabilistic matrix

2030
02:03:19,200 --> 02:03:20,390
factorisation model

2031
02:03:20,430 --> 02:03:23,180
and here's what bayesian PMF gives you

2032
02:03:25,320 --> 02:03:27,230
it gives you much better

2033
02:03:27,240 --> 02:03:31,310
root mean squared error so it gives much better predictions compared to the MAP estimate

2034
02:03:32,230 --> 02:03:37,500
and to us that was a little bit surprising and the surprising thing is that

2035
02:03:37,580 --> 02:03:40,660
you know you can actually run these models

2036
02:03:40,700 --> 02:03:44,680
with third dimensional feature vectors of sixty dimensional feature vectors

2037
02:03:44,690 --> 02:03:47,090
which are quite big models in

2038
02:03:47,100 --> 02:03:48,220
you know

2039
02:03:48,230 --> 02:03:51,670
these are the times about eleven hours maybe forty seven hours

2040
02:03:51,750 --> 02:03:53,420
a couple of days

2041
02:03:56,280 --> 02:04:00,940
and you can see that the gap between those models is actually quite large

2042
02:04:01,960 --> 02:04:03,290
what's going on

2043
02:04:07,440 --> 02:04:10,940
right so here the results by showing that

2044
02:04:10,950 --> 02:04:15,540
is you increase the feature dimensionality which is to say that as you make your

2045
02:04:15,540 --> 02:04:17,900
model bigger

2046
02:04:17,910 --> 02:04:20,890
what happens with the bayesian PMF

2047
02:04:20,910 --> 02:04:22,030
the error

2048
02:04:22,440 --> 02:04:25,620
the performance improves which is was

2049
02:04:25,700 --> 02:04:30,440
you know sort of a good result for us because it basically says that you

2050
02:04:30,440 --> 02:04:35,150
know the the bayesian approach doesn't really require you limiting the complexity of the model

2051
02:04:35,190 --> 02:04:37,120
based on the training data

2052
02:04:37,150 --> 02:04:40,720
which is not the case for the map based models we we actually trying to

2053
02:04:40,720 --> 02:04:42,580
learn the parameters of the model

2054
02:04:42,640 --> 02:04:47,410
and you know for the three hundred dimensional feature vectors and half a million users

2055
02:04:47,450 --> 02:04:50,720
thank you have about seventy five million parameters in your model so if you had

2056
02:04:50,730 --> 02:04:54,190
so many parameters in your model and you don't have nearly enough data

2057
02:04:54,200 --> 02:04:58,790
fitting those models becomes really challenging or regularizing the model becomes

2058
02:04:58,830 --> 02:05:01,320
a very challenging task

2059
02:05:02,790 --> 02:05:06,350
so again the the the i guess the

2060
02:05:06,360 --> 02:05:10,860
the main idea here is that as you make your model bigger

2061
02:05:10,870 --> 02:05:12,580
for this real task

2062
02:05:12,590 --> 02:05:17,550
the bayesian methods actually give you a better performance of the performance improves

2063
02:05:20,770 --> 02:05:23,690
one of the other good things about

2064
02:05:23,820 --> 02:05:28,330
you know finding or getting samples from the posterior distribution is that you can take

2065
02:05:28,330 --> 02:05:30,310
uncertainty into account


1
00:00:00,000 --> 00:00:04,350
my problem matrix with the random matrix of plus minus one and the target was

2
00:00:04,350 --> 00:00:06,170
just the first column

3
00:00:08,370 --> 00:00:11,510
if you two linear least squares

4
00:00:11,520 --> 00:00:15,720
then you have only small weights to stay around the good weight is going to

5
00:00:15,720 --> 00:00:18,000
pick up very slowly

6
00:00:18,040 --> 00:00:19,690
if you enforce

7
00:00:19,700 --> 00:00:23,130
just nonnegativity constraints alone

8
00:00:23,140 --> 00:00:25,560
then you learn about two

9
00:00:25,610 --> 00:00:29,740
you make take it takes about half as many examples is still have this cloud

10
00:00:29,790 --> 00:00:30,970
small weights

11
00:00:31,020 --> 00:00:35,410
and the good weight is picked up at about the halfway point

12
00:00:37,430 --> 00:00:38,980
now however

13
00:00:39,000 --> 00:00:45,540
if you enforce nonnegativity constraints and sum to one constraints

14
00:00:45,550 --> 00:00:50,200
then you know you do with the multiplicative problems to your home and you go

15
00:00:50,200 --> 00:00:55,140
very fast you pick up the weight of the logarithmically many examples intuitively

16
00:00:55,190 --> 00:00:57,550
hugh constrain the one norm

17
00:00:57,560 --> 00:01:02,280
it's the black thing it's similar

18
00:01:03,710 --> 00:01:07,490
so he applied in various norms

19
00:01:07,500 --> 00:01:09,240
of the weight vector

20
00:01:09,970 --> 00:01:13,120
people in this tutorial so we'll talk a lot about norms

21
00:01:13,140 --> 00:01:16,850
regularizations various norms

22
00:01:16,900 --> 00:01:19,470
OK sold

23
00:01:21,140 --> 00:01:23,170
here's a plot

24
00:01:23,180 --> 00:01:24,010
in blue

25
00:01:24,020 --> 00:01:29,140
the two norm of the LS LS algorithm it goes up very slowly

26
00:01:29,150 --> 00:01:32,250
however the one norm which is the dotted line

27
00:01:32,270 --> 00:01:34,340
is very big

28
00:01:34,870 --> 00:01:37,480
so what happens is the two norm

29
00:01:37,490 --> 00:01:40,830
uses a lot of small weights this cloud of different weights

30
00:01:42,270 --> 00:01:45,200
which doesn't have the to know because you square it but

31
00:01:45,250 --> 00:01:49,650
if you can help if you look at the one norm it's huge

32
00:01:50,640 --> 00:01:53,290
if you constrain the weights to be nonnegative

33
00:01:53,300 --> 00:01:55,460
the two norm goes up a little bit

34
00:01:55,470 --> 00:02:00,600
faster but the one norm is still rather large

35
00:02:00,610 --> 00:02:05,070
these are the arguments to constrain the one norm black one for instance

36
00:02:05,120 --> 00:02:06,650
and the

37
00:02:08,210 --> 00:02:10,280
much better

38
00:02:10,290 --> 00:02:13,110
and then you see here the generalisation performance

39
00:02:13,850 --> 00:02:15,720
once to constrain the one norm

40
00:02:15,730 --> 00:02:18,840
very often very quickly the error goes down to zero

41
00:02:19,700 --> 00:02:23,520
for the other ones it goes down only very slowly

42
00:02:23,570 --> 00:02:27,250
after seeing half of the examples you are still

43
00:02:33,100 --> 00:02:39,760
outside information is very important constraints are very important

44
00:02:39,780 --> 00:02:41,960
the kernel algorithms

45
00:02:42,010 --> 00:02:44,640
i have no constraints simplicity

46
00:02:44,720 --> 00:02:46,910
is a multiplicative algorithms

47
00:02:46,930 --> 00:02:51,510
they have these implicit constraints of nonnegativity and something to one essentially of one norm

48
00:02:52,910 --> 00:02:54,980
and in the part of my problem

49
00:02:55,000 --> 00:02:57,250
they have radically different behavior

50
00:03:00,120 --> 00:03:00,980
to make

51
00:03:01,000 --> 00:03:04,920
to make the point that outside information is hard i'm going to give you a

52
00:03:04,920 --> 00:03:06,190
problem matrix

53
00:03:07,720 --> 00:03:10,600
the multiplicative algorithm is not good

54
00:03:10,660 --> 00:03:13,090
can be beaten very easily

55
00:03:13,140 --> 00:03:19,560
so here's the following situation the instances of the n rows and the possible targets

56
00:03:23,290 --> 00:03:26,310
so if you see one of the instances

57
00:03:26,320 --> 00:03:30,090
you know exactly what target is because the bits give it away

58
00:03:30,140 --> 00:03:32,020
and you're done

59
00:03:32,030 --> 00:03:35,340
so a single example gives the target away

60
00:03:37,030 --> 00:03:41,540
dg algorithm would still have this kind of performance

61
00:03:41,560 --> 00:03:45,330
it wouldn't exploit this so it's all about outside information

62
00:03:45,380 --> 00:03:49,350
you always want to take care of as much outside information as possible

63
00:03:49,400 --> 00:03:52,400
included as much as possible

64
00:03:52,410 --> 00:03:53,900
it turns out

65
00:03:57,160 --> 00:04:00,350
these constraint c

66
00:04:00,400 --> 00:04:04,420
which is sort of sparsity constraint

67
00:04:04,470 --> 00:04:05,740
they very nice

68
00:04:05,750 --> 00:04:07,370
the very natural

69
00:04:09,260 --> 00:04:12,650
they don't lend themselves to kernelize ability

70
00:04:12,700 --> 00:04:15,970
intuitively the if you add those constraints did not

71
00:04:15,980 --> 00:04:22,230
the problem is not rotation invariant anymore

72
00:04:29,190 --> 00:04:37,140
general discussion which metrics characterizes the problem many people use the kernel matrix

73
00:04:37,150 --> 00:04:42,920
which is the dot product between the instances of the expanded instances

74
00:04:43,030 --> 00:04:44,630
i wanted to

75
00:04:44,650 --> 00:04:47,140
posted to use

76
00:04:47,150 --> 00:04:52,100
the problem matrix which would be instances rows targets as columns

77
00:04:53,950 --> 00:04:57,580
if the eigenspectrum of the kernel matrix has and heavy tail

78
00:04:57,590 --> 00:04:59,320
and this kernel isn't useful

79
00:04:59,370 --> 00:05:03,590
so that means you picked the wrong kernel your problem is too hard

80
00:05:03,600 --> 00:05:08,460
but what we showed with spectrum of the problem matrix has an heavy tail

81
00:05:08,690 --> 00:05:12,110
then it's not learnable

82
00:05:12,120 --> 00:05:13,160
we showed that

83
00:05:13,170 --> 00:05:14,990
the heart of my problem

84
00:05:15,030 --> 00:05:19,430
matrix has and heavy tailed and ending random features i didn't show up but discuss

85
00:05:19,440 --> 00:05:21,340
it off a little bit

86
00:05:21,380 --> 00:05:27,030
and makes the tail heavy

87
00:05:29,800 --> 00:05:33,100
some sense the kernel matrix only

88
00:05:33,150 --> 00:05:37,620
only encodes half of problem it doesn't connect with the target if you really want

89
00:05:37,620 --> 00:05:43,940
to see what's going on you need to do the problem is the problem matrix

90
00:05:44,050 --> 00:05:49,050
so we gave a problem that cannot be learned by kernel based algorithms

91
00:05:49,670 --> 00:05:55,940
the question is what is the optimal kernel for a given problem

92
00:05:55,960 --> 00:06:01,250
and what is the corresponding hard problem for the multiplicative updates there must be one

93
00:06:01,270 --> 00:06:07,520
can multiplicative oglesby kernelized

94
00:06:07,530 --> 00:06:10,230
if you could

95
00:06:10,250 --> 00:06:14,530
then you would be very very famous y

96
00:06:14,580 --> 00:06:18,840
multiplicative items they had this logarithmic dependence on dimension

97
00:06:18,890 --> 00:06:21,290
remember learn disjunctions for instance

98
00:06:24,090 --> 00:06:26,430
this loss of k log n

99
00:06:26,430 --> 00:06:38,390
i also

100
00:07:07,710 --> 00:07:09,690
so is

101
00:08:17,690 --> 00:08:24,700
one so

102
00:08:51,600 --> 00:09:11,970
i i

103
00:10:12,840 --> 00:10:20,690
or something

104
00:11:01,940 --> 00:11:17,820
i mean

105
00:11:17,820 --> 00:11:22,380
and you only use a subset of a single period of the sequence

106
00:11:22,380 --> 00:11:24,340
now i thought i had written down here

107
00:11:24,590 --> 00:11:28,780
yes OK so i get to other generators in just a second

108
00:11:28,800 --> 00:11:32,420
so this idea of having a long period is an important property but it is

109
00:11:32,420 --> 00:11:36,300
clearly not the only property that we interested in we want

110
00:11:36,360 --> 00:11:40,970
number numbers we get to be uniformly distributed between zero and one

111
00:11:41,050 --> 00:11:45,490
well what you do you simply take the and of values and you divide

112
00:11:47,090 --> 00:11:51,010
the largest possible value which will be close to this model and that will give

113
00:11:51,010 --> 00:11:54,510
you her number that's that is in the interval between zero and one

114
00:11:54,510 --> 00:11:57,360
but that doesn't necessarily mean the random

115
00:11:57,360 --> 00:12:02,880
and the idea is then to choose the multiplier modules such that the resulting sequence

116
00:12:03,170 --> 00:12:07,240
of passes various tests of randomness and for example

117
00:12:07,260 --> 00:12:11,320
if you choose this value for the multiplier and this value for the modulus is

118
00:12:11,320 --> 00:12:15,990
what's been suggested by creating you can find it indeed the

119
00:12:16,440 --> 00:12:21,470
distribution comes up very close to be uniform between zero and one of only generated

120
00:12:21,510 --> 00:12:22,420
very small

121
00:12:22,420 --> 00:12:25,700
sample here you could generate much larger samples

122
00:12:25,720 --> 00:12:29,380
and you also want for example there could be no correlations between

123
00:12:29,440 --> 00:12:33,990
in a particular pair of points as opposed to the points came out the first

124
00:12:33,990 --> 00:12:34,940
one was there

125
00:12:34,950 --> 00:12:37,670
the second one was in the bin just to its right the third one just

126
00:12:37,670 --> 00:12:38,610
to its right

127
00:12:38,630 --> 00:12:40,280
and so forth and on line

128
00:12:40,320 --> 00:12:44,400
and then back to the beginning well that would be give uniform distribution between zero

129
00:12:44,400 --> 00:12:45,380
and one

130
00:12:45,400 --> 00:12:50,150
but the principle because between neighbours and so one of the other tests that you

131
00:12:50,150 --> 00:12:54,070
could look at for example would be to make a scatterplot of here is also

132
00:12:54,990 --> 00:12:56,450
verses are

133
00:12:56,470 --> 00:12:58,760
i so so i plus one

134
00:12:58,970 --> 00:13:04,090
so you can see that there is no particular pattern there is no particular correlation

135
00:13:04,130 --> 00:13:08,180
between neighboring points and you would not want to have correlations between any

136
00:13:08,280 --> 00:13:10,630
a pair of points

137
00:13:10,820 --> 00:13:17,700
so this is for this EM lcg the multiplicative linear conventional generator in practice we

138
00:13:17,700 --> 00:13:22,820
don't use it we use much more sophisticated algorithms that have in fact much longer

139
00:13:22,820 --> 00:13:29,030
periods and if you're familiar with this fifty random class in the room package it's

140
00:13:29,170 --> 00:13:33,110
the generated human three in fact

141
00:13:33,130 --> 00:13:36,070
has an enormously long period two to the

142
00:13:36,090 --> 00:13:41,540
twenty thousand something which is a is the mind-bogglingly large number when you consider that

143
00:13:42,150 --> 00:13:43,450
i have only been

144
00:13:43,450 --> 00:13:48,440
there's only ten tended the sixty years something protons in the in the observable universe

145
00:13:48,550 --> 00:13:52,360
his and then the whatever six thousand or so

146
00:13:52,420 --> 00:13:57,280
random numbers so it's trivially easy to place yourself within a single

147
00:13:57,360 --> 00:13:59,990
periods of that sequence

148
00:14:00,010 --> 00:14:05,920
there's a couple of interesting references both these there's a paper by james from nineteen

149
00:14:05,920 --> 00:14:09,900
ninety that describes i think a lot of the mathematics behind these these algorithms and

150
00:14:09,920 --> 00:14:14,880
very understandable fashion and also chapter four in the book by sigmund part i think

151
00:14:14,880 --> 00:14:21,650
describes the mathematics behind random number generation in a very accessible readable way

152
00:14:21,670 --> 00:14:24,470
OK let's start to wrap up

153
00:14:24,840 --> 00:14:26,590
one of few more things

154
00:14:26,630 --> 00:14:28,970
that was actually just step one

155
00:14:29,200 --> 00:14:32,820
deriving the sequence of uniformly distributed values

156
00:14:34,070 --> 00:14:36,650
so uniformly distributed between zero and one

157
00:14:36,670 --> 00:14:41,860
given that sequence we now want to find a second sequence x one x two

158
00:14:41,880 --> 00:14:44,820
the fall a different pdf

159
00:14:44,840 --> 00:14:46,590
f of x which we specify

160
00:14:48,180 --> 00:14:51,720
a number of ways of doing that and the first way i want to discuss

161
00:14:51,720 --> 00:14:54,650
is what is called the transformation method

162
00:14:54,670 --> 00:14:59,860
the idea is the following suppose that is the PDF x that we're interested in

163
00:14:59,880 --> 00:15:02,510
and here's the uniform pdf

164
00:15:02,510 --> 00:15:05,090
we used to generate the first sequence

165
00:15:05,110 --> 00:15:10,130
and the idea of this transformation method is the following if i consider specific

166
00:15:10,150 --> 00:15:12,550
o value of one

167
00:15:12,590 --> 00:15:17,300
uniformly distributed variables are so let me call that all prime

168
00:15:17,320 --> 00:15:20,320
what i would like to do is i would like to find a function x

169
00:15:20,320 --> 00:15:23,360
of or so that would be ten x of our prime there

170
00:15:23,420 --> 00:15:28,450
such that when i evaluate this function with our values it immediately gives me

171
00:15:28,470 --> 00:15:32,260
the desired x values such that x follows

172
00:15:32,280 --> 00:15:33,700
this distribution

173
00:15:33,840 --> 00:15:36,940
so if i can find that function i have an easy way of going from

174
00:15:36,940 --> 00:15:41,400
my first sequence of our values to the second sequence of x values i simply

175
00:15:41,400 --> 00:15:43,510
evaluate that function

176
00:15:43,530 --> 00:15:47,950
so how do i find that function well if that is all prime then what

177
00:15:47,950 --> 00:15:50,760
i want to insist on is that the

178
00:15:50,780 --> 00:15:54,720
area to the left of that so the integral from minus infinity

179
00:15:54,740 --> 00:15:58,780
from from zero in this case to all prime that should also be the equal

180
00:15:58,780 --> 00:15:59,800
to the area

181
00:15:59,820 --> 00:16:01,170
to the left of

182
00:16:01,180 --> 00:16:05,340
x of or prime so i want to find the function x of r

183
00:16:05,360 --> 00:16:09,670
such that i have that property and that will guarantee that this distribution

184
00:16:09,700 --> 00:16:14,090
will the exit four will follow always distribution

185
00:16:14,110 --> 00:16:18,470
so here's what i need to require and the probability that are is less than

186
00:16:18,470 --> 00:16:23,050
or prime should be equal to the probability that x is less than x of

187
00:16:23,050 --> 00:16:24,130
our prime

188
00:16:24,220 --> 00:16:27,510
but what is that that is simply the cumulative distribution

189
00:16:27,530 --> 00:16:29,050
corresponding to this

190
00:16:29,070 --> 00:16:31,610
uniform pdf

191
00:16:31,700 --> 00:16:35,440
so i can do that in the rule because g bar is simply a constant

192
00:16:35,440 --> 00:16:37,150
it's simply equal to one

193
00:16:37,170 --> 00:16:40,880
so that rule is just equal to our pride

194
00:16:40,900 --> 00:16:45,260
and then here on the right-hand side i have the cumulative distribution

195
00:16:45,280 --> 00:16:46,550
corresponding to

196
00:16:46,570 --> 00:16:48,110
f of x

197
00:16:48,130 --> 00:16:50,090
so i write that capital

198
00:16:50,150 --> 00:16:51,470
of x so far

199
00:16:51,490 --> 00:16:53,300
so i have all the time

200
00:16:53,320 --> 00:16:57,880
is equal to the cumulative distribution of x of our prior

201
00:16:57,900 --> 00:17:01,780
OK so now we drop the prime and i can simply write that are is

202
00:17:01,780 --> 00:17:05,550
equal to the cumulative distribution of x so that's the that's the equation that i

203
00:17:05,550 --> 00:17:07,180
have to write down

204
00:17:07,200 --> 00:17:09,630
and i simply saw that equation for x

205
00:17:09,650 --> 00:17:10,820
and that would give me

206
00:17:10,840 --> 00:17:11,860
the desired

207
00:17:13,720 --> 00:17:15,110
and two

208
00:17:15,150 --> 00:17:17,650
to show that we're here is an example

209
00:17:17,670 --> 00:17:20,320
so let me consider exponential pdf

210
00:17:20,320 --> 00:17:21,150
that's what we saw

211
00:17:21,220 --> 00:17:22,740
just a bit earlier

212
00:17:22,780 --> 00:17:23,590
and so on

213
00:17:23,650 --> 00:17:26,490
what is my prescription i have to compute the

214
00:17:26,510 --> 00:17:28,070
cumulative distribution

215
00:17:28,110 --> 00:17:30,470
corresponding to the exponential pdf

216
00:17:30,490 --> 00:17:32,200
that's given by this integral

217
00:17:32,220 --> 00:17:34,010
and i simply said that

218
00:17:34,130 --> 00:17:35,670
equal to or

219
00:17:35,700 --> 00:17:38,630
and in this case it's a very simple it also i can do it i

220
00:17:38,630 --> 00:17:43,530
can solve the equation and i find that active r is equal to minus c

221
00:17:43,550 --> 00:17:44,740
from the launch

222
00:17:44,740 --> 00:17:46,070
of one minus r

223
00:17:46,090 --> 00:17:47,740
so that gives me the desired

224
00:17:49,780 --> 00:17:51,240
now if you think about it

225
00:17:51,840 --> 00:17:55,610
if are always a uniform distribution between zero and one

226
00:17:55,630 --> 00:17:59,380
what is the distribution of one minus are

227
00:17:59,380 --> 00:18:03,110
i think clearly don't have to be uniform between zero and one and so in

228
00:18:03,110 --> 00:18:06,130
fact if you look at the computer programs that would implement this unit you will

229
00:18:06,130 --> 00:18:09,860
see that this is something like that because it works just as well as you

230
00:18:09,860 --> 00:18:13,380
know why why why one minus or you could just write are

231
00:18:13,550 --> 00:18:18,670
so here this illustrates that really works there is an histogram of our values

232
00:18:18,680 --> 00:18:22,740
and then for each value if i evaluate this function and put it in the

233
00:18:24,010 --> 00:18:25,010
and i find

234
00:18:25,030 --> 00:18:27,180
this histogram here

235
00:18:27,200 --> 00:18:30,490
following an exponential pdf so it really works

236
00:18:30,490 --> 00:18:35,900
and then but then the big question is how how to how to compromise

237
00:18:36,140 --> 00:18:38,800
well if i if i do this with willing to

238
00:18:39,510 --> 00:18:43,990
say about is just the transition model

239
00:18:44,010 --> 00:18:46,170
but i agree with

240
00:18:51,360 --> 00:18:52,720
in this part

241
00:18:52,720 --> 00:18:53,920
this is

242
00:18:55,740 --> 00:18:57,880
four four four this five

243
00:18:57,900 --> 00:19:00,630
as it is now i think i have an idea how to do it

244
00:19:01,490 --> 00:19:04,240
for this part

245
00:19:04,320 --> 00:19:05,450
i would like to think

246
00:19:05,550 --> 00:19:12,130
o here right or all so what i what i already know how to do

247
00:19:12,130 --> 00:19:15,940
is this despite trying so given the graph i can estimate this one

248
00:19:15,990 --> 00:19:17,510
right and then and then

249
00:19:17,510 --> 00:19:22,050
all of what what what we need to define is this transition modern houses

250
00:19:22,090 --> 00:19:23,800
parameters can change

251
00:19:23,840 --> 00:19:27,490
and then we should be able to estimate the i mean it's sort of a

252
00:19:27,490 --> 00:19:29,420
complicated hmm

253
00:19:29,420 --> 00:19:32,190
i don't

254
00:19:32,190 --> 00:19:35,280
that's the i think something that we have to

255
00:19:36,510 --> 00:19:38,470
i know

256
00:19:38,570 --> 00:19:41,280
deal with so right now the idea is to

257
00:19:41,280 --> 00:19:44,050
to generate the whole graph even if this is not

258
00:19:44,650 --> 00:19:46,590
entirely through

259
00:19:46,590 --> 00:19:48,970
the case

260
00:19:49,440 --> 00:19:57,970
what we could try to do is

261
00:19:57,990 --> 00:19:59,630
actually we could try to

262
00:20:00,110 --> 00:20:02,630
two seems to be no

263
00:20:02,630 --> 00:20:08,400
basically one part here is also to estimate kind of node correspondences so we could

264
00:20:08,420 --> 00:20:12,380
go on then madden ultimately here so that that would also be doable but in

265
00:20:12,380 --> 00:20:14,150
some kind of approximate set

266
00:20:14,170 --> 00:20:16,630
right so i i i mean it's

267
00:20:16,630 --> 00:20:21,530
inside the model that and victoria part comes from matching the nodes in the synthetic

268
00:20:21,530 --> 00:20:23,740
graph with nodes of the real graph

269
00:20:23,760 --> 00:20:25,420
so then i could go

270
00:20:25,420 --> 00:20:28,940
this way and also have a matching between the nodes

271
00:20:29,030 --> 00:20:32,150
across but again it will be it would be

272
00:20:32,150 --> 00:20:34,650
you are right in the sense that it would be a sample from the parameter

273
00:20:34,650 --> 00:20:36,070
but on the other hand

274
00:20:36,440 --> 00:20:39,970
in an email network right i can i can do that

275
00:20:40,090 --> 00:20:42,780
because you're just an on and off

276
00:20:42,800 --> 00:20:45,650
so i think that would be the more realistic so for example in an email

277
00:20:46,550 --> 00:20:48,050
i could use

278
00:20:48,050 --> 00:20:50,240
just go up and again down to to the

279
00:20:50,260 --> 00:20:51,970
node correspondences

280
00:20:51,990 --> 00:20:53,110
and samples

281
00:20:53,110 --> 00:20:55,190
just independent

282
00:21:01,110 --> 00:21:06,550
what you

283
00:21:06,570 --> 00:21:11,070
one of the things that you or someone

284
00:21:14,050 --> 00:21:16,570
the issue

285
00:21:16,610 --> 00:21:20,880
it seems to be the

286
00:21:21,050 --> 00:21:25,280
i want to read the book for

287
00:21:25,670 --> 00:21:28,820
the definition

288
00:21:28,820 --> 00:21:31,840
if you want to do that

289
00:21:31,860 --> 00:21:33,070
so far

290
00:21:33,130 --> 00:21:37,940
so i think it should be should be specification because

291
00:21:37,970 --> 00:21:39,030
the the

292
00:21:39,050 --> 00:21:44,190
no no notification would mean that the constant aerial or a constant fraction of all

293
00:21:44,190 --> 00:21:47,740
possible edges is that we're we're

294
00:21:47,760 --> 00:21:51,710
and that's because

295
00:21:51,710 --> 00:21:57,800
the thing is people so that users are able to run away

296
00:22:03,970 --> 00:22:07,450
the other is much more

297
00:22:14,420 --> 00:22:16,190
what's interesting

298
00:22:16,190 --> 00:22:18,550
i'm not sure

299
00:22:26,070 --> 00:22:29,210
is a

300
00:22:29,240 --> 00:22:32,820
thank pasteurisation

301
00:22:32,840 --> 00:22:35,550
my guess is

302
00:22:35,570 --> 00:22:37,670
this was

303
00:22:38,160 --> 00:22:39,220
can find

304
00:22:42,860 --> 00:22:46,030
well actually

305
00:22:46,050 --> 00:22:49,090
change size

306
00:22:49,240 --> 00:22:54,010
in addition

307
00:22:57,090 --> 00:22:58,590
less one

308
00:23:02,170 --> 00:23:05,800
this is part

309
00:23:05,820 --> 00:23:11,070
while region a linear time you start see

310
00:23:11,090 --> 00:23:13,510
jealously time

311
00:23:16,280 --> 00:23:20,110
now you shall

312
00:23:20,130 --> 00:23:25,650
here is how organization

313
00:23:25,650 --> 00:23:29,340
that is what we see

314
00:23:33,280 --> 00:23:35,050
starting close

315
00:23:35,070 --> 00:23:36,920
these are actually

316
00:23:36,940 --> 00:23:42,150
trying to model always start around

317
00:23:42,990 --> 00:23:46,510
inside the station

318
00:23:46,610 --> 00:23:49,950
one of the is

319
00:23:54,650 --> 00:23:56,240
he is how

320
00:23:56,260 --> 00:24:00,360
cost of changes

321
00:24:04,840 --> 00:24:06,570
five hundred

322
00:24:06,570 --> 00:24:07,650
well o

323
00:24:11,340 --> 00:24:13,220
and also

324
00:24:13,240 --> 00:24:21,880
right while at the same time

325
00:24:21,880 --> 00:24:27,000
the class of probability distributions that can be represented as vision that

326
00:24:27,000 --> 00:24:31,470
the class probability distribution might feel

327
00:24:31,490 --> 00:24:34,410
so we see that the graphs

328
00:24:34,420 --> 00:24:36,480
he said to be the man

329
00:24:36,490 --> 00:24:39,970
four dependency of the distribution

330
00:24:39,990 --> 00:24:55,010
we have essentially

331
00:24:55,020 --> 00:24:57,680
graph g

332
00:24:57,740 --> 00:24:59,410
it is the

333
00:25:04,320 --> 00:25:05,690
distribution it

334
00:25:05,720 --> 00:25:06,560
graph g

335
00:25:06,580 --> 00:25:09,300
is the map for distribution p

336
00:25:09,350 --> 00:25:15,780
if every conditional independence statement satisfied by the distribution

337
00:25:15,860 --> 00:25:22,760
is reflected in the graph

338
00:25:23,760 --> 00:25:26,920
conditional independence day

339
00:25:38,410 --> 00:25:44,060
that the

340
00:26:14,280 --> 00:26:16,540
a graph is said to be an i map

341
00:26:16,600 --> 00:26:18,480
before independence map

342
00:26:18,490 --> 00:26:20,080
of distribution

343
00:26:20,100 --> 00:26:24,840
if every conditional independence statement implied by the graph is satisfied

344
00:26:24,880 --> 00:26:27,260
the distribution

345
00:26:29,250 --> 00:26:31,520
it is my

346
00:26:36,080 --> 00:26:38,050
it lies every

347
00:26:38,060 --> 00:26:39,440
all right

348
00:26:39,530 --> 00:26:40,470
well you

349
00:26:40,520 --> 00:26:46,470
slipping you should make you

350
00:26:46,690 --> 00:26:52,250
four all conditional independence

351
00:26:52,300 --> 00:26:53,460
for all

352
00:27:02,110 --> 00:27:06,320
associated g

353
00:27:06,490 --> 00:27:07,700
graph separation

354
00:27:33,120 --> 00:27:37,660
a graph g

355
00:27:37,720 --> 00:27:45,410
it is up to par effect map

356
00:27:45,430 --> 00:27:46,940
four p

357
00:27:47,030 --> 00:27:48,870
if it's all

358
00:27:48,920 --> 00:27:50,120
if it's

359
00:27:50,170 --> 00:27:52,720
the map

360
00:28:03,040 --> 00:28:07,170
said to be an p map for perfect map of a distribution it's more than

361
00:28:07,170 --> 00:28:10,360
the map and an i map for

362
00:28:13,250 --> 00:28:18,470
why definitions well because the commission will allow us to see when remarkable interview how

363
00:28:18,470 --> 00:28:23,330
mark fields in vision that to

364
00:28:25,990 --> 00:28:29,300
if all conditional independence statements associated

365
00:28:29,360 --> 00:28:31,270
with a given graph

366
00:28:31,320 --> 00:28:34,790
are reflected in p

367
00:28:34,800 --> 00:28:36,580
the is one

368
00:28:36,630 --> 00:28:38,040
that's the that

369
00:28:38,050 --> 00:28:41,540
that's on my map

370
00:28:48,420 --> 00:28:52,860
there's one graph on n nodes

371
00:28:52,920 --> 00:28:56,250
this an i map for all probability distributions

372
00:28:56,300 --> 00:29:07,610
which that is this

373
00:29:15,130 --> 00:29:22,450
the graph which is fully connected

374
00:29:22,530 --> 00:29:24,160
there is no conditioning

375
00:29:24,420 --> 00:29:31,970
so what you say is that all conditioned offices you are reflected in p

376
00:29:31,980 --> 00:29:35,030
if there is no conditional independence statements

377
00:29:35,900 --> 00:29:37,520
it will always be the case

378
00:29:40,960 --> 00:29:42,150
you don't have

379
00:29:42,230 --> 00:29:45,300
on the other hand same likewise

380
00:29:45,400 --> 00:29:49,090
there's one graph

381
00:29:49,130 --> 00:29:53,210
which is of the map

382
00:29:53,230 --> 00:29:55,210
for all

383
00:29:58,840 --> 00:30:04,960
the natural

384
00:30:06,570 --> 00:30:08,380
every conditional

385
00:30:08,420 --> 00:30:11,340
take any probability distribution

386
00:30:14,230 --> 00:30:17,880
they all the set of conditional independence assumptions that

387
00:30:18,840 --> 00:30:20,920
that probably

388
00:30:20,980 --> 00:30:22,520
all those

389
00:30:22,590 --> 00:30:27,780
condition samples will hold will use it to witchcraft

390
00:30:27,840 --> 00:30:31,110
graph with no edges so basically

391
00:30:31,130 --> 00:30:48,480
know it's

392
00:30:53,000 --> 00:30:55,030
now comes

393
00:30:55,030 --> 00:30:56,530
the important

394
00:31:04,340 --> 00:31:10,170
is the set of all distributions on y

395
00:31:11,840 --> 00:31:12,940
is the set

396
00:31:12,940 --> 00:31:16,030
of all distributions virus

397
00:31:16,050 --> 00:31:20,480
that can be represented as a perfect map

398
00:31:21,480 --> 00:31:26,070
vision that by that

399
00:31:26,800 --> 00:31:31,710
is the set of distributions by that can be represented as a perfect map

400
00:31:36,030 --> 00:31:38,400
so what you see is the full

401
00:31:38,400 --> 00:31:40,170
there exists a set

402
00:31:40,170 --> 00:31:44,090
which is the intersection of these two sets

403
00:31:44,150 --> 00:31:49,980
that can be written this set of distributions can be represented as a perfect map

404
00:31:50,000 --> 00:31:58,400
ball like bayesian networks and markov

405
00:31:58,420 --> 00:32:02,440
and there is a set which is outside

406
00:32:02,480 --> 00:32:04,750
which can not be represented as opposed

407
00:32:05,300 --> 00:32:11,360
the web is enough to know about life

408
00:32:11,420 --> 00:32:14,880
but this is only for maps

409
00:32:14,880 --> 00:32:20,760
that means that the usually essentially i copied the same argument as

410
00:32:20,810 --> 00:32:22,940
for the first example

411
00:32:22,960 --> 00:32:25,610
how can be

412
00:32:25,660 --> 00:32:28,390
prove the factor base

413
00:32:28,620 --> 00:32:35,830
the the law of large numbers were i showed that the average

414
00:32:37,060 --> 00:32:40,300
growth rate

415
00:32:40,310 --> 00:32:46,640
it is close to the fact that the log return before the reason that using

416
00:32:46,660 --> 00:32:49,650
because the portfolio vector b

417
00:32:49,700 --> 00:32:51,610
the average growth rate

418
00:32:53,250 --> 00:32:56,000
the expected log return

419
00:32:56,070 --> 00:33:01,640
but if you choose that positive that part

420
00:33:01,650 --> 00:33:04,460
any positive there are

421
00:33:07,920 --> 00:33:10,360
and large enough

422
00:33:10,370 --> 00:33:14,010
these even has large probability

423
00:33:14,050 --> 00:33:16,970
very close to one

424
00:33:17,040 --> 00:33:21,970
of camp

425
00:33:22,150 --> 00:33:29,530
which means that the the average growth rate

426
00:33:29,550 --> 00:33:33,270
is between four numbers

427
00:33:33,360 --> 00:33:35,650
if you make order

428
00:33:38,160 --> 00:33:41,880
arrangement than the amount of money

429
00:33:41,900 --> 00:33:44,440
in between these

430
00:33:44,460 --> 00:33:46,590
two numbers

431
00:33:46,610 --> 00:33:48,100
which means

432
00:33:48,150 --> 00:33:56,570
that that the center is approximately equal to ten times the expected log return

433
00:33:56,610 --> 00:33:58,600
the large profits

434
00:33:58,610 --> 00:34:06,180
but then is close to you could be ten times expected log return

435
00:34:06,200 --> 00:34:10,250
this is one part of the calculation

436
00:34:10,370 --> 00:34:14,420
the other one is the calculation of the

437
00:34:14,440 --> 00:34:17,590
expectation of the capital

438
00:34:17,600 --> 00:34:20,300
at the time

439
00:34:20,400 --> 00:34:26,080
remember that the amount of money at the time and is the product of inner

440
00:34:26,080 --> 00:34:31,820
products of the portfolio vector the return vector

441
00:34:31,830 --> 00:34:39,820
while x starting are independent identically distributed so the expectation of the product is equal

442
00:34:39,910 --> 00:34:44,080
to the product of the expectation

443
00:34:44,150 --> 00:34:49,840
so you may be right he e to the end times the locality

444
00:34:49,850 --> 00:34:52,390
of the inner product of b

445
00:34:52,400 --> 00:34:53,340
and the

446
00:34:53,350 --> 00:34:58,520
aspect you read there

447
00:34:58,540 --> 00:35:02,070
you know that ten is close to this number

448
00:35:02,120 --> 00:35:04,950
you either side of the library

449
00:35:04,960 --> 00:35:08,710
and the expectation of f then it is here where

450
00:35:08,910 --> 00:35:10,600
the expectation

451
00:35:11,960 --> 00:35:14,220
the logo

452
00:35:14,320 --> 00:35:20,150
so i can show that and then close with expectation

453
00:35:20,170 --> 00:35:26,070
if i can verify that these exponent in the exponential expression in

454
00:35:26,090 --> 00:35:29,630
not close to this one

455
00:35:29,650 --> 00:35:35,020
which means that the expected log return

456
00:35:35,070 --> 00:35:43,470
it is and the and the local authority of these expectations are different

457
00:35:43,480 --> 00:35:44,990
but you can use the

458
00:35:45,010 --> 00:35:48,070
the the the and so you know what

459
00:35:54,810 --> 00:36:02,680
if you have a concave function

460
00:36:02,770 --> 00:36:06,170
and your your called where

461
00:36:06,740 --> 00:36:11,100
the concave function as an expectation

462
00:36:11,110 --> 00:36:18,460
and compare it with the fact that the the expectation of the function at random

463
00:36:20,730 --> 00:36:28,050
you make a decreasing it because they have you know what it is formulated for

464
00:36:28,050 --> 00:36:29,550
convex functions

465
00:36:29,600 --> 00:36:30,620
which means

466
00:36:30,630 --> 00:36:31,520
that the

467
00:36:31,550 --> 00:36:34,720
comment function as an expectation is smaller

468
00:36:34,740 --> 00:36:38,300
then the expectation of the convex function

469
00:36:38,310 --> 00:36:42,610
this is for four recall if so you have just the

470
00:36:42,630 --> 00:36:44,310
the river

471
00:36:44,320 --> 00:36:46,020
which means

472
00:36:47,320 --> 00:36:52,310
the exponent here

473
00:36:52,370 --> 00:36:53,760
is larger

474
00:36:53,780 --> 00:36:59,010
that the exponent here

475
00:36:59,030 --> 00:37:04,640
which has the consequence that the s and is much much less

476
00:37:04,690 --> 00:37:07,180
then its expectation

477
00:37:07,200 --> 00:37:08,730
in our example of

478
00:37:09,100 --> 00:37:11,200
these had the

479
00:37:11,230 --> 00:37:12,710
value was the

480
00:37:17,430 --> 00:37:19,140
the large probability

481
00:37:19,160 --> 00:37:22,690
and the the expectation had an exponential

482
00:37:26,050 --> 00:37:32,230
and why i i told you all of these one

483
00:37:32,240 --> 00:37:38,990
because the naive approach for portfolio selection

484
00:37:39,420 --> 00:37:41,700
could be

485
00:37:41,700 --> 00:37:44,300
you want to find an optimum weight

486
00:37:44,300 --> 00:37:46,620
column bases of the matrix

487
00:37:46,640 --> 00:37:47,860
you simply

488
00:37:47,890 --> 00:37:52,200
or the columns in order of nondecreasing way

489
00:37:52,220 --> 00:37:56,680
and choose one after the other so that what you choose

490
00:37:56,740 --> 00:38:00,760
she maintains independence

491
00:38:00,760 --> 00:38:03,090
when you can add any more

492
00:38:03,990 --> 00:38:07,050
what you have is a

493
00:38:07,070 --> 00:38:09,200
most valuable basis

494
00:38:10,890 --> 00:38:14,720
but of course the same thing works for any matroid right

495
00:38:14,720 --> 00:38:22,030
and the same thing works for any polymatroid and that's what this is saying and

496
00:38:22,030 --> 00:38:24,510
that's how

497
00:38:24,590 --> 00:38:25,800
i mean the they

498
00:38:25,890 --> 00:38:28,070
true for matroids

499
00:38:28,070 --> 00:38:29,660
it is the

500
00:38:31,530 --> 00:38:33,840
a polymatroid

501
00:38:33,860 --> 00:38:38,700
here's the thing and the vertices of the pollinator

502
00:38:38,780 --> 00:38:40,260
vectors at a

503
00:38:40,300 --> 00:38:41,300
this form

504
00:38:41,300 --> 00:38:43,880
we've we order

505
00:38:43,880 --> 00:38:46,160
we've ordered the

506
00:38:48,050 --> 00:38:51,740
the e in an arbitrary order at all

507
00:38:51,740 --> 00:38:54,200
any or or at all

508
00:38:54,200 --> 00:38:56,640
a survived means

509
00:38:57,200 --> 00:39:02,490
initial subsequent of i am

510
00:39:02,510 --> 00:39:06,430
now we get a vertex

511
00:39:06,530 --> 00:39:08,530
express it this way

512
00:39:08,550 --> 00:39:14,200
if you restrict yourself to the rank function of a matroid

513
00:39:14,200 --> 00:39:16,590
this is exactly you know

514
00:39:16,590 --> 00:39:17,970
this this is

515
00:39:17,970 --> 00:39:20,010
this is all this is the one

516
00:39:20,010 --> 00:39:22,860
in other words

517
00:39:22,890 --> 00:39:29,880
element one goes in independence that this is the one right

518
00:39:29,890 --> 00:39:34,570
the rank for matroid rank is only going to go up by one

519
00:39:35,930 --> 00:39:37,410
this is going to be a one

520
00:39:37,470 --> 00:39:42,800
i mean you're element goes in your and your chosen independence

521
00:39:42,840 --> 00:39:45,860
so this is exactly

522
00:39:45,880 --> 00:39:50,360
the greedy algorithm for nature as we describe it a moment ago

523
00:39:50,430 --> 00:39:53,110
except that it works as well

524
00:39:54,780 --> 00:39:57,720
polymatroids by saying

525
00:39:57,720 --> 00:40:03,680
all right you want to know how do we prove that these are the vertices

526
00:40:03,760 --> 00:40:07,070
talking and what i show again

527
00:40:07,110 --> 00:40:07,970
the way

528
00:40:07,990 --> 00:40:09,590
he is shown

529
00:40:09,640 --> 00:40:12,300
a set of vectors is the vertices

530
00:40:12,320 --> 00:40:13,360
it is to show

531
00:40:14,220 --> 00:40:17,640
they are what optimize any linear function

532
00:40:17,640 --> 00:40:18,970
over the public

533
00:40:20,660 --> 00:40:22,530
a point

534
00:40:22,590 --> 00:40:24,390
that's feasible

535
00:40:24,430 --> 00:40:26,090
is a vertex

536
00:40:26,140 --> 00:40:28,680
it can only have

537
00:40:28,700 --> 00:40:32,880
you can find a linear function that's optimize over the polytopes

538
00:40:32,890 --> 00:40:38,510
only by that point

539
00:40:39,220 --> 00:40:45,570
it's simply the greedy algorithm that's proving that those are the vertices of the parliamentary

540
00:40:45,700 --> 00:40:48,360
in particular that those are the vertices

541
00:40:48,380 --> 00:40:50,070
of the matrix

542
00:40:50,120 --> 00:40:51,760
all the time

543
00:40:52,840 --> 00:40:54,380
so here we have

544
00:40:55,680 --> 00:41:01,220
look at the linear programme maximize an arbitrary linear functions

545
00:41:02,220 --> 00:41:05,660
are there

546
00:41:05,740 --> 00:41:08,390
of our pollinate right

547
00:41:08,410 --> 00:41:12,030
there's are polymatroid defined by are

548
00:41:12,050 --> 00:41:14,590
polymatroid set functions

549
00:41:14,660 --> 00:41:19,760
we a order the coordinates in the order nondecreasing

550
00:41:21,110 --> 00:41:25,160
the coefficients of the objective function

551
00:41:25,180 --> 00:41:32,490
an ace of i simply means initial subsequences

552
00:41:33,180 --> 00:41:43,300
so something like that

553
00:41:43,360 --> 00:41:45,090
oh yeah OK

554
00:41:45,140 --> 00:41:47,800
we're solving the LP

555
00:41:47,820 --> 00:41:51,640
we're also going to solve the double LP

556
00:41:51,680 --> 00:41:54,390
we're going match that this is this is this

557
00:41:55,880 --> 00:41:57,990
this is the LP do

558
00:41:58,010 --> 00:42:01,470
of this primal LP maximise this

559
00:42:01,490 --> 00:42:04,090
so due to the

560
00:42:04,090 --> 00:42:04,840
the deal

561
00:42:05,720 --> 00:42:10,090
minimize that you see we have a dual variables we have at the variable for

562
00:42:11,550 --> 00:42:15,720
any quality here

563
00:42:15,740 --> 00:42:18,260
here we say

564
00:42:18,260 --> 00:42:23,090
and this is the number of parameters unit with

565
00:42:23,130 --> 00:42:26,190
some of you are nothing but the good news is that we we can do

566
00:42:29,080 --> 00:42:30,630
OK so

567
00:42:30,670 --> 00:42:34,590
of course if you try to estimate it from the likelihood then you will have

568
00:42:34,590 --> 00:42:37,850
to be resolved if you just maximize likelihood

569
00:42:37,860 --> 00:42:42,490
it will be you will have a thousand nodes and one partial funding to the

570
00:42:42,490 --> 00:42:47,580
solution will be completely stupid so you have to penalize this kind of solutions that's

571
00:42:48,810 --> 00:42:52,520
we selected we can select a bayesian model that is you will be my stupid

572
00:42:52,520 --> 00:42:55,540
solutions by putting a prior which is high

573
00:42:55,560 --> 00:42:59,240
and the nice solutions

574
00:42:59,310 --> 00:43:00,480
OK i think every

575
00:43:03,290 --> 00:43:17,130
right OK

576
00:43:18,400 --> 00:43:20,100
bayesian inference

577
00:43:20,110 --> 00:43:21,360
so we have here

578
00:43:21,360 --> 00:43:23,490
the likelihood which is written here

579
00:43:23,490 --> 00:43:27,660
going to multiplied by the prior to the two avoid to be

580
00:43:27,670 --> 00:43:32,330
and so we end up with the posterior distribution of the parameter

581
00:43:34,460 --> 00:43:37,710
how to select the prime

582
00:43:37,730 --> 00:43:39,450
for example we want

583
00:43:39,490 --> 00:43:41,530
to avoid having one so the

584
00:43:41,670 --> 00:43:45,040
so we put a prior on the number of nodes which will

585
00:43:46,220 --> 00:43:48,100
a small number of

586
00:43:48,260 --> 00:43:50,640
with this kind of things we can

587
00:43:50,750 --> 00:43:53,840
select a good set of priors

588
00:43:53,850 --> 00:43:55,460
OK but in fact

589
00:43:55,470 --> 00:43:57,030
as i mentioned earlier the

590
00:43:57,200 --> 00:44:01,390
the way you select the priors is not only inspired by the physics and by

591
00:44:01,610 --> 00:44:06,000
common sense but it's also inspired by the easiness of the computation

592
00:44:06,020 --> 00:44:11,910
so as mentioned by chris bishop earlier we try to select a conjugate priors

593
00:44:11,970 --> 00:44:15,900
which are much much easier to use

594
00:44:16,740 --> 00:44:20,370
for example here assume that the number of nodes is no

595
00:44:20,380 --> 00:44:24,380
but we could also assume it's not

596
00:44:24,440 --> 00:44:29,060
OK so now i added some of the priors which can be used and explain

597
00:44:29,090 --> 00:44:30,980
why selecting

598
00:44:31,020 --> 00:44:32,970
this is the real problem

599
00:44:33,280 --> 00:44:34,460
the amplitude

600
00:44:34,640 --> 00:44:37,170
we want them not to be to be

601
00:44:37,190 --> 00:44:38,510
because if we have

602
00:44:38,630 --> 00:44:39,620
very big

603
00:44:39,660 --> 00:44:44,100
no it with very high amplitude than probably the mother we try to put another

604
00:44:45,000 --> 00:44:46,860
exactly the same place was

605
00:44:46,860 --> 00:44:49,710
the corresponding very high amplitude stories

606
00:44:49,760 --> 00:44:50,990
you see what i mean

607
00:44:51,020 --> 00:44:56,860
if to create an artificial with the amplitude and the opposite artificial severe high amplitude

608
00:44:56,870 --> 00:45:00,450
so we want to avoid this says that's why we constraints the amplitude to be

609
00:45:01,270 --> 00:45:03,830
and what we do this is to us

610
00:45:03,880 --> 00:45:06,200
location distribution for example

611
00:45:07,750 --> 00:45:10,340
that the remark amplitudes here can be negative

612
00:45:10,340 --> 00:45:11,440
and positive

613
00:45:11,460 --> 00:45:14,160
because we have assigned to them the cosine

614
00:45:14,170 --> 00:45:18,520
we have no initial phase that sense

615
00:45:18,520 --> 00:45:20,270
OK so

616
00:45:20,310 --> 00:45:23,950
the dimension of the prior distribution

617
00:45:24,020 --> 00:45:25,730
let's say it has

618
00:45:25,780 --> 00:45:27,060
the diagonal

619
00:45:27,070 --> 00:45:32,310
covariance matrix with them and they will all just an idea to

620
00:45:32,390 --> 00:45:36,010
and it's i mentioned depending on of course the the number of partials

621
00:45:36,010 --> 00:45:37,910
so this prior

622
00:45:37,940 --> 00:45:41,810
is not always fixed

623
00:45:41,810 --> 00:45:47,730
i two

624
00:45:47,760 --> 00:45:54,150
i'm going to talk about it my side two is what we call a heap

625
00:45:55,050 --> 00:45:56,870
parameters are

626
00:45:58,060 --> 00:45:59,480
frequencies and so on

627
00:45:59,510 --> 00:46:01,810
but in defining the prior

628
00:46:01,820 --> 00:46:05,430
you may need to define to another parameter

629
00:46:06,100 --> 00:46:08,890
if you say well the prior distribution is a gaussian

630
00:46:08,950 --> 00:46:11,770
with mean zero and variance one

631
00:46:11,780 --> 00:46:17,110
in fact you could say it's a gaussian distribution with mean zero and variance sigma

632
00:46:17,660 --> 00:46:19,790
this variance

633
00:46:19,800 --> 00:46:22,090
it is nice if you know that

634
00:46:22,100 --> 00:46:26,860
here we assume don't know that this parameters so we defined the priors but we

635
00:46:26,860 --> 00:46:29,480
don't know everything about crime

636
00:46:29,510 --> 00:46:35,120
so i'm sure can we can learn about the prime himself

637
00:46:35,140 --> 00:46:36,260
OK so

638
00:46:36,260 --> 00:46:39,590
this was for example now how to build

639
00:46:39,640 --> 00:46:41,350
model fuzzy

640
00:46:41,350 --> 00:46:43,660
frequency of

641
00:46:43,780 --> 00:46:46,190
as you so this is the frequency

642
00:46:46,200 --> 00:46:47,570
no number k

643
00:46:47,580 --> 00:46:49,820
and partial and then

644
00:46:49,840 --> 00:46:53,230
so we know from the physics very close

645
00:46:53,290 --> 00:46:56,650
the fundamental frequency of the note multiply

646
00:46:56,680 --> 00:46:59,050
by the number of the partial

647
00:47:00,070 --> 00:47:04,170
but you know it's not exactly so for example we can have the correcting parameter

648
00:47:04,480 --> 00:47:05,510
that here

649
00:47:05,560 --> 00:47:11,260
which will allow it to be a bit beside the true predictive

650
00:47:11,280 --> 00:47:16,010
and we can also select this kind of trial but it is just an example

651
00:47:16,030 --> 00:47:17,460
in which you have

652
00:47:17,480 --> 00:47:22,610
an independent prior for the fundamental frequency and the tuning parameters

653
00:47:23,620 --> 00:47:25,680
so we select can select this

654
00:47:25,710 --> 00:47:29,170
because it's more easy to compute

655
00:47:29,180 --> 00:47:34,210
so again is a compromise between reality and the closeness physics

656
00:47:34,220 --> 00:47:37,860
and the easiness of implementation

657
00:47:37,910 --> 00:47:42,130
so this is another kind of prior you can use for the fundamental frequency imagine

658
00:47:42,130 --> 00:47:43,430
you're playing the piano

659
00:47:43,590 --> 00:47:47,120
some notes you can play show in between two

660
00:47:47,120 --> 00:47:48,840
the kids you can

661
00:47:49,810 --> 00:47:52,890
put it into the primary model for the frequencies

662
00:47:54,180 --> 00:47:58,300
for a small motion on each other possible frequency

663
00:47:58,840 --> 00:47:59,610
and the

664
00:47:59,620 --> 00:48:02,780
people want to share with the tuning of the

665
00:48:02,830 --> 00:48:05,060
the fact that

666
00:48:05,080 --> 00:48:09,530
so we can use both of these within the right

667
00:48:09,590 --> 00:48:16,900
OK so and there important parameter is the number of bottles

668
00:48:18,880 --> 00:48:20,960
this is the model

669
00:48:21,030 --> 00:48:24,250
this is guaranteed to find the size of the model for this is if we

670
00:48:24,250 --> 00:48:29,920
now going against it selected going into the electrical gradients but that's not the end

671
00:48:29,920 --> 00:48:31,400
of the story

672
00:48:33,610 --> 00:48:35,090
what they are also

673
00:48:35,170 --> 00:48:38,750
two other interesting functions one

674
00:48:38,790 --> 00:48:41,710
after a certain amount of time

675
00:48:41,750 --> 00:48:45,250
after a very brief time interval

676
00:48:45,270 --> 00:48:54,320
this channel also has the property that close

677
00:48:54,360 --> 00:49:02,790
so now when it closes what's going to happen

678
00:49:02,790 --> 00:49:07,880
the postal start work again re-establish are negative fifty

679
00:49:07,940 --> 00:49:09,880
it's going to take too long

680
00:49:09,880 --> 00:49:12,550
i mean the happen you get back to minus fifty this can take a long

681
00:49:15,420 --> 00:49:20,020
it's good to the channel that the voltage gated sodium channel closed but

682
00:49:20,030 --> 00:49:23,000
even better

683
00:49:23,050 --> 00:49:27,000
nature is arranged to have a voltage gated

684
00:49:27,020 --> 00:49:30,340
the last century

685
00:49:35,380 --> 00:49:40,880
and what happens to the golden gate gated potassium channel is around plus thirty million

686
00:49:42,170 --> 00:49:43,520
it opens

687
00:49:43,590 --> 00:49:46,210
and admits capacity

688
00:49:46,270 --> 00:49:52,550
now instead of having to wait for the relatively slow ATP driven pumps

689
00:49:52,550 --> 00:49:55,960
what happens when i potassium

690
00:49:58,320 --> 00:50:04,800
if the cell is positive on the inside negative on the outside

691
00:50:04,820 --> 00:50:11,980
what happens for potassium

692
00:50:12,030 --> 00:50:14,790
potassium starts coming out

693
00:50:14,800 --> 00:50:18,500
because there's more potassium on the inside

694
00:50:18,550 --> 00:50:21,840
and there's also favorable electrical gradient

695
00:50:21,900 --> 00:50:23,670
so passive

696
00:50:23,710 --> 00:50:29,570
explosively starts rushing out

697
00:50:31,020 --> 00:50:34,360
rapidly re-establishes

698
00:50:34,460 --> 00:50:38,290
the resting potential

699
00:50:38,340 --> 00:50:41,530
all this happening in the middlesex

700
00:50:41,590 --> 00:50:43,090
very impressive

701
00:50:43,150 --> 00:50:47,050
so in something like one millisecond

702
00:50:47,090 --> 00:50:53,840
we open up the potassium channels now if this had happened that the channels go

703
00:50:54,000 --> 00:50:56,480
in the first place had to get to minus fifty

704
00:50:56,500 --> 00:51:00,920
that's the work of these dendrites the dendrites integrating a signal from all the things

705
00:51:00,920 --> 00:51:04,170
impacting on it will get the solar minus fifty

706
00:51:04,190 --> 00:51:07,650
but once the cell gets minus fifty and attacks on him

707
00:51:07,670 --> 00:51:10,150
being the the action potential fires

708
00:51:10,320 --> 00:51:14,730
the cell is itself plus fifty in a big rush of sodium is

709
00:51:14,770 --> 00:51:17,900
and then zips down to minus seven again

710
00:51:17,920 --> 00:51:19,920
in a big rush of passengers

711
00:51:28,090 --> 00:51:31,690
remember as it was only like one part in ten to the fifth the ions

712
00:51:31,750 --> 00:51:35,840
to trivial actual the number of ions necessary to set up these little things such

713
00:51:35,840 --> 00:51:41,960
a tiny fraction of concentration the through this whole thing those concentrations not noticeably change

714
00:51:41,980 --> 00:51:43,150
that's what's so cool

715
00:51:43,190 --> 00:51:44,920
is there are different regimes

716
00:51:45,710 --> 00:51:48,820
those that they do change they change by one partner ten to the fifth of

717
00:51:48,820 --> 00:51:50,320
those numbers

718
00:51:50,340 --> 00:51:55,170
it's really cool that we haven't screwed up or concentration gradient we move tiny numbers

719
00:51:55,170 --> 00:51:57,320
of ions to accomplish all this

720
00:51:57,340 --> 00:51:59,360
this is a very clever engineering

721
00:51:59,420 --> 00:52:01,320
very clever engineer now

722
00:52:01,380 --> 00:52:05,860
how we managed to transmit the signal down the cells

723
00:52:07,650 --> 00:52:10,550
let's talk about how we properly i think this is really cool is one of

724
00:52:10,550 --> 00:52:13,090
the truly great mechanisms the

725
00:52:13,150 --> 00:52:15,820
it was invented

726
00:52:15,840 --> 00:52:20,270
transmitting an action potential

727
00:52:31,500 --> 00:52:37,270
suppose i transmit my actions suppose i have neuron here

728
00:52:37,320 --> 00:52:40,920
and over here

729
00:52:41,110 --> 00:52:43,670
the axon hillock

730
00:52:43,690 --> 00:52:50,070
i transient we depolarized so minus fifty

731
00:52:50,750 --> 00:52:53,110
then i fire

732
00:52:53,130 --> 00:52:54,840
and fire

733
00:52:54,880 --> 00:52:56,550
what happens is this

734
00:52:56,590 --> 00:52:58,190
part of the cell

735
00:52:58,190 --> 00:53:03,360
it was originally minus minus minus plus plus plus

736
00:53:03,400 --> 00:53:06,500
it becomes possible to temporarily

737
00:53:06,550 --> 00:53:10,840
right it now becomes

738
00:53:15,380 --> 00:53:17,170
plus plus plus

739
00:53:17,170 --> 00:53:19,960
so it's good minus along the whole cell here

740
00:53:20,070 --> 00:53:23,670
plus plus plus plus plus

741
00:53:26,920 --> 00:53:31,440
so little patch of membrane

742
00:53:31,460 --> 00:53:33,690
at the beginning of the axis

743
00:53:33,710 --> 00:53:37,480
it has become positive inside

744
00:53:38,320 --> 00:53:40,590
because whatever local effect here

745
00:53:40,630 --> 00:53:43,590
cause this to flip

746
00:53:43,630 --> 00:53:47,630
if this becomes positive this part of the memory

747
00:53:47,710 --> 00:53:55,030
what happens to the negative charges over here a little bit further down the axon

748
00:53:55,050 --> 00:53:58,090
some of them will be pulled over

749
00:53:58,090 --> 00:53:59,710
so the positive

750
00:53:59,790 --> 00:54:01,520
whole whole

751
00:54:01,590 --> 00:54:06,650
some negative charges get pulled over

752
00:54:06,690 --> 00:54:09,960
but what happens when some of those negative charges get pulled over to my mind

753
00:54:10,000 --> 00:54:13,000
seventeen syllables

754
00:54:13,020 --> 00:54:15,400
is it is negative as it was before

755
00:54:15,920 --> 00:54:17,670
no becomes minus

756
00:54:17,690 --> 00:54:21,980
minus fifteen ovals

757
00:54:23,340 --> 00:54:27,940
what happens when this becomes minus fifty models

758
00:54:28,030 --> 00:54:29,880
there's actually potential

759
00:54:31,000 --> 00:54:34,030
what happens is

760
00:54:34,110 --> 00:54:39,670
here's my ackson i fire an action i have an action potential here and in

761
00:54:39,670 --> 00:54:45,270
the course of that i pull over some some negative charge

762
00:54:45,270 --> 00:54:48,980
that of course trains the depolarized here

763
00:54:49,000 --> 00:54:51,300
and causes an action potential

764
00:54:51,360 --> 00:54:55,520
that of course this becomes positive which pulls over some negative charge

765
00:54:55,570 --> 00:54:58,530
which causes the action potential fire here

766
00:54:58,590 --> 00:55:00,650
etcetera etcetera

767
00:55:02,670 --> 00:55:05,710
so if i can manage to get things started

768
00:55:05,750 --> 00:55:11,170
with my dendrites causing a transient depolarisation from minus seventy minus fifty

769
00:55:11,210 --> 00:55:15,630
then the action potential itself will draw over some charge

770
00:55:15,650 --> 00:55:19,480
and start the process of the next patch remembering the next patch next memory the

771
00:55:19,480 --> 00:55:22,290
expansion the membrane on the expansion memory

772
00:55:22,290 --> 00:55:24,250
and it gets all the way down here

773
00:55:24,290 --> 00:55:26,300
to brilliant mechanism

774
00:55:26,480 --> 00:55:28,650
we can calculate

775
00:55:28,650 --> 00:55:31,540
these i'm not flat surfaces there are trees

776
00:55:31,600 --> 00:55:35,370
he on the ground building on the ground which i like sharp point where the

777
00:55:35,370 --> 00:55:37,620
electric field will be locally higher

778
00:55:37,630 --> 00:55:39,720
and so you will get to discharge

779
00:55:39,760 --> 00:55:41,650
at the sharp points first

780
00:55:41,660 --> 00:55:44,900
and that means the potential difference between the cloud

781
00:55:44,950 --> 00:55:48,260
and you could then be less than the three billion that we have

782
00:55:48,340 --> 00:55:50,370
calculated here

783
00:55:50,410 --> 00:55:54,600
but it's only a back-of-the-envelope calculation

784
00:55:54,610 --> 00:55:58,100
the details of the physics of the discharge very complicated

785
00:55:58,150 --> 00:55:59,360
but i want to

786
00:55:59,420 --> 00:56:00,840
share with you some

787
00:56:00,910 --> 00:56:02,230
facts without giving

788
00:56:02,250 --> 00:56:04,480
detailed explanations

789
00:56:04,490 --> 00:56:06,410
the start of the lightning

790
00:56:07,330 --> 00:56:09,240
i went back tones begin to flow

791
00:56:09,250 --> 00:56:11,710
from the cloud to the

792
00:56:11,760 --> 00:56:15,790
therefore follow which is about one to ten meters in diameter

793
00:56:15,810 --> 00:56:19,050
and we call that the step later

794
00:56:19,060 --> 00:56:21,750
the seventy the most about hundred miles

795
00:56:21,750 --> 00:56:22,820
a second

796
00:56:22,900 --> 00:56:26,400
so it comes down to about five millisecond

797
00:56:26,440 --> 00:56:28,360
five millisecond from here to here

798
00:56:28,410 --> 00:56:30,500
and it takes about half cool

799
00:56:30,510 --> 00:56:31,920
to the earth

800
00:56:31,940 --> 00:56:37,310
topic long for about five millisecond that means the current is about one hundred and

801
00:56:40,030 --> 00:56:42,590
this template creates a channel

802
00:56:42,600 --> 00:56:48,350
of ionized air four lions and electrons which is an extremely good conductors

803
00:56:48,360 --> 00:56:50,550
and was when this step leader

804
00:56:50,600 --> 00:56:51,990
reaches the ground

805
00:56:51,990 --> 00:56:52,870
there is this

806
00:56:52,900 --> 00:56:54,940
highly conductive channel

807
00:56:54,990 --> 00:56:57,660
and the electrons can now very quickly flow

808
00:56:57,680 --> 00:56:58,880
from this channel

809
00:56:58,910 --> 00:56:59,940
to ground

810
00:56:59,950 --> 00:57:02,560
and that starts first right here

811
00:57:02,580 --> 00:57:06,570
at the surface of the earth that's very electrons will first

812
00:57:06,580 --> 00:57:08,420
go to the earth

813
00:57:08,420 --> 00:57:09,560
and then

814
00:57:11,220 --> 00:57:16,150
electrons which are higher up in the channel will make it down to your

815
00:57:16,160 --> 00:57:18,020
and so you're going to see

816
00:57:19,730 --> 00:57:21,120
going through the channel

817
00:57:21,150 --> 00:57:22,150
the earth

818
00:57:22,170 --> 00:57:23,910
the first electrons i

819
00:57:23,920 --> 00:57:24,800
closer to the

820
00:57:24,830 --> 00:57:26,470
and the electrons far away

821
00:57:26,480 --> 00:57:27,220
and then

822
00:57:27,230 --> 00:57:29,320
even farther away

823
00:57:29,380 --> 00:57:32,580
and this is actually where most of the action of course the

824
00:57:32,600 --> 00:57:34,820
current is now enormously high

825
00:57:34,870 --> 00:57:36,120
ten thousand two

826
00:57:36,130 --> 00:57:38,010
some hundred thousand amperes

827
00:57:38,010 --> 00:57:39,910
and you heat the air

828
00:57:39,920 --> 00:57:42,170
get a tremendous amount of

829
00:57:42,220 --> 00:57:44,240
light ions

830
00:57:45,610 --> 00:57:46,950
and you get

831
00:57:46,960 --> 00:57:50,110
pressure he conclusions pressure and there comes

832
00:57:50,900 --> 00:57:51,870
from there

833
00:57:51,930 --> 00:57:53,690
so most of the action

834
00:57:53,700 --> 00:57:54,900
is not in the

835
00:57:54,910 --> 00:57:59,810
leader but is in this second phenomenon which we call the return stroke

836
00:57:59,870 --> 00:58:01,290
which is from the earth

837
00:58:02,450 --> 00:58:03,760
the club

838
00:58:03,780 --> 00:58:07,260
and the speed of the return stroke is about ten to twenty percent of the

839
00:58:07,260 --> 00:58:10,210
speed of light

840
00:58:10,210 --> 00:58:14,560
during the return stroke is about five school exchange between the cloud

841
00:58:14,580 --> 00:58:18,210
and the earth and five can always a sizeable fraction of the total charge

842
00:58:18,250 --> 00:58:24,150
that was on the glass on the cloud first which is to start with

843
00:58:24,190 --> 00:58:27,770
after the return stroke maybe twenty millisecond later

844
00:58:27,790 --> 00:58:30,050
this whole process can start again

845
00:58:30,060 --> 00:58:31,550
you can get to that later

846
00:58:31,560 --> 00:58:35,780
you can get the return stroke however the step will now follow exactly the same

847
00:58:36,690 --> 00:58:38,180
that was made

848
00:58:38,190 --> 00:58:42,130
before because that's where the air is ionized so that's where the conductivity is very

849
00:58:42,820 --> 00:58:44,550
that's the easiest way to go

850
00:58:44,560 --> 00:58:49,170
and this process can recur five ten maybe fifteen times

851
00:58:49,210 --> 00:58:52,790
so what appears to you s one lightning bolts

852
00:58:52,830 --> 00:58:54,780
in fact could be ten

853
00:58:54,830 --> 00:58:56,370
flashes back and forth

854
00:58:56,420 --> 00:58:58,970
between the cloud and you're

855
00:58:59,010 --> 00:59:03,820
and the real life is not in the step leader that's very little i realized

856
00:59:03,880 --> 00:59:05,510
is in the

857
00:59:05,520 --> 00:59:10,020
so that can return stroke which may be twenty thirty forty millisecond apart

858
00:59:10,060 --> 00:59:11,090
here to you

859
00:59:11,130 --> 00:59:13,510
and to me only has one flash

860
00:59:13,570 --> 00:59:16,930
which will take place may be in as little as a tenth of a second

861
00:59:16,960 --> 00:59:18,490
and during these

862
00:59:18,500 --> 00:59:20,740
five or ten return strokes

863
00:59:20,760 --> 00:59:24,290
you exchange between the cloud and you may be a total of twenty five to

864
00:59:24,290 --> 00:59:25,660
fifty cool

865
00:59:25,680 --> 00:59:28,260
and then of course the lower the potential difference

866
00:59:28,320 --> 00:59:30,770
and if the potential difference becomes too low

867
00:59:30,790 --> 00:59:32,620
then the process stops

868
00:59:32,630 --> 00:59:33,780
you have to wait now

869
00:59:33,820 --> 00:59:36,020
forty clouds to charge up again

870
00:59:36,030 --> 00:59:40,800
and then lightning will strike again and that can take anywhere from a before

871
00:59:40,880 --> 00:59:42,740
o five ten twenty seconds

872
00:59:42,740 --> 00:59:44,050
and then you get another

873
00:59:44,070 --> 00:59:47,470
lightning bolt

874
00:59:47,480 --> 00:59:50,210
the study of the

875
00:59:50,280 --> 00:59:53,810
of this process of the step leader and of the return stroke

876
00:59:53,880 --> 00:59:55,020
can be done

877
00:59:55,040 --> 00:59:56,720
with a

878
00:59:56,760 --> 00:59:59,450
camera which is called the borders camera

879
00:59:59,450 --> 01:00:01,420
let me first explain to you

880
01:00:01,440 --> 01:00:04,240
detail in principle how it works

881
01:00:04,270 --> 01:00:06,380
this is the

882
01:00:06,400 --> 01:00:07,590
every year

883
01:00:07,650 --> 01:00:10,680
on the film is exposed by your comments

884
01:00:10,720 --> 01:00:14,960
suppose that i move the film very high speed to the left

885
01:00:15,010 --> 01:00:19,440
and suppose this that comes down and see some light from the step leader

886
01:00:19,450 --> 01:00:20,720
then i may see

887
01:00:20,730 --> 01:00:21,850
on the

888
01:00:21,870 --> 01:00:23,710
the film this

889
01:00:23,750 --> 01:00:25,190
the light

890
01:00:25,240 --> 01:00:27,820
and from here to here

891
01:00:27,920 --> 01:00:29,450
or ten b

892
01:00:29,530 --> 01:00:31,190
five millisecond

893
01:00:31,230 --> 01:00:35,020
which takes the step needed to go from the cloud studio

894
01:00:35,070 --> 01:00:37,220
now the return stroke

895
01:00:37,270 --> 01:00:39,610
takes place was way higher speed

896
01:00:39,660 --> 01:00:42,990
so i see a tremendous amount of light because there's a lot of light into

897
01:00:43,230 --> 01:00:45,280
one stroke and of course this

898
01:00:45,290 --> 01:00:46,720
very steep

899
01:00:46,750 --> 01:00:49,320
because it goes on the times faster

900
01:00:49,380 --> 01:00:51,760
then this template looking down

901
01:00:51,800 --> 01:00:54,510
so you can measure these times and so you can get the speed of the

902
01:00:54,510 --> 01:00:56,440
return stroke

903
01:00:56,440 --> 01:01:00,010
and then later in time maybe thirty forty seconds later on the film

904
01:01:00,020 --> 01:01:02,080
you may see another return stroke

905
01:01:02,090 --> 01:01:03,900
you may see another one

906
01:01:03,900 --> 01:01:08,510
so you can see then how long time was between the return strokes

907
01:01:08,560 --> 01:01:10,660
and you can also calculate

908
01:01:10,700 --> 01:01:13,550
their speeds

909
01:01:13,650 --> 01:01:16,930
with the real camera it's not really the film that is moving but at the

910
01:01:17,230 --> 01:01:18,990
moment that is moving

911
01:01:19,020 --> 01:01:20,180
and the way it is

912
01:01:20,190 --> 01:01:21,570
pictures are taken

913
01:01:21,590 --> 01:01:23,040
i'll show you one

914
01:01:23,220 --> 01:01:25,370
this is the photographic plate

915
01:01:25,380 --> 01:01:29,110
then it is the camera moves over the place

916
01:01:29,160 --> 01:01:31,540
with a very high

917
01:01:31,580 --> 01:01:32,780
speed about

918
01:01:32,790 --> 01:01:33,850
three thousand

919
01:01:33,870 --> 01:01:35,520
revolutions per minute

920
01:01:35,530 --> 01:01:37,510
and so you would get these

921
01:01:37,550 --> 01:01:39,560
this information than not

922
01:01:39,570 --> 01:01:41,920
horizontally but you get it right

923
01:01:41,920 --> 01:01:42,850
of the

924
01:01:42,870 --> 01:01:48,670
phil but you get the same information you can calculate speeds and times

925
01:01:48,720 --> 01:01:51,350
during the past decade

926
01:01:51,410 --> 01:01:54,590
a new forms of lightning have been discovered

927
01:01:54,610 --> 01:01:56,580
which occur way above

928
01:01:56,600 --> 01:01:58,880
the clouds

929
01:01:58,950 --> 01:02:01,840
where a hierarchy

930
01:02:01,900 --> 01:02:07,540
red colors have been seen red sprites they're called also blogettes

931
01:02:07,570 --> 01:02:09,650
the light is very faint

932
01:02:09,650 --> 01:02:12,480
because only for a very short amount of time

933
01:02:12,480 --> 01:02:16,910
first of all very quickly walked out of the heterotic strings well heterotic strings are

934
01:02:16,910 --> 01:02:22,000
closed and oriented like the type to believe everyone in space

935
01:02:22,010 --> 01:02:26,880
the are close things there are no the brains they don't get stuck anywhere

936
01:02:26,880 --> 01:02:30,940
and they have the degrees of freedom now that's the novelty compared to what i

937
01:02:30,940 --> 01:02:36,050
said yesterday it turns out that you can take half it was on extreme than

938
01:02:36,060 --> 01:02:37,940
half superstring

939
01:02:37,960 --> 01:02:42,950
and put them together and still make a consistent string theory now that sounds awkward

940
01:02:43,040 --> 01:02:47,370
but remember that waves moving on the left and the right to this thing were

941
01:02:47,370 --> 01:02:53,200
totally independent never interacted therefore why not take half-and-half

942
01:02:53,210 --> 01:02:58,490
that reduces the supersymmetry of the theory already in the critical dimension but that's OK

943
01:02:58,490 --> 01:03:02,210
we don't need so much seemed to start with

944
01:03:02,260 --> 01:03:05,810
so in practice this means that one has the use of any

945
01:03:05,820 --> 01:03:08,330
coordinates of the superstring

946
01:03:08,340 --> 01:03:13,480
the film munich partners of the which are now only left move right moving you

947
01:03:14,240 --> 01:03:19,640
so i forgot to cite them use that were there yesterday which were left movers

948
01:03:19,650 --> 01:03:23,680
and instead of the left i have an extra sixteen four minutes to go up

949
01:03:23,680 --> 01:03:27,040
to twenty six as required by the masonic string

950
01:03:27,130 --> 01:03:32,510
however it is more convenient for many purposes to think of these sixteen

951
01:03:32,540 --> 01:03:35,710
two dimensional bosnians as thirty two

952
01:03:35,730 --> 01:03:38,000
two dimensional family owns

953
01:03:38,060 --> 01:03:42,440
two dimensions is very special is is that there is no spin there is really

954
01:03:43,410 --> 01:03:50,490
basic distinction between bosons and fermions there's something called personalisation feminisation you can the borders

955
01:03:50,490 --> 01:03:55,590
and for two fermions or derivative of abortion far from your

956
01:03:55,640 --> 01:03:59,640
so that's simply technical details

957
01:03:59,690 --> 01:04:01,250
OK now

958
01:04:01,260 --> 01:04:06,460
you can go through the same steps as yesterday and construct spectrum of these theories

959
01:04:06,510 --> 01:04:11,490
and here in our goal much faster here are basically the massless states you get

960
01:04:11,580 --> 01:04:15,930
after projecting out so as yesterday

961
01:04:15,940 --> 01:04:20,500
so first of all by applying the oscillators say new

962
01:04:20,510 --> 01:04:25,840
and eighteen that these remember what it was on the coordinates x new the left

963
01:04:25,840 --> 01:04:27,930
moving excitations

964
01:04:27,940 --> 01:04:31,380
so by doing by considering the states

965
01:04:31,390 --> 01:04:37,790
you get as before the graviton and all replacement company up in ten dimensions except

966
01:04:37,790 --> 01:04:40,860
this supersymmetric company slightly reduced now

967
01:04:40,870 --> 01:04:43,390
there is only one gravitino actually

968
01:04:43,450 --> 01:04:47,990
and the reason is that the supersymmetry is not maximally it's half maximal because we

969
01:04:48,030 --> 01:04:50,840
cut out one half of the superstrings

970
01:04:50,840 --> 01:04:55,850
so it's what one calls in one one supergravity in ten dimensions

971
01:04:55,920 --> 01:05:03,000
but there are some extra states what instead of taking the left moving excitations from

972
01:05:03,000 --> 01:05:05,530
the coordinates of spacetime

973
01:05:05,530 --> 01:05:12,580
eighteen then you using this extra degrees of freedom of the boys on explaining which

974
01:05:12,580 --> 01:05:17,160
i found my own eyes and when you work this out a little carefully you

975
01:05:17,160 --> 01:05:23,280
see that this precisely creates a thirty two gauge fields disaffected two because there are

976
01:05:23,280 --> 01:05:24,200
thirty two

977
01:05:24,260 --> 01:05:29,830
in family here and they have to be anti-semitic prize because is fair use

978
01:05:29,840 --> 01:05:34,900
so you get this gets fields plus the support partners which are going to mention

979
01:05:36,480 --> 01:05:42,360
so by the similar steps to yesterday one gets an effective theory in ten dimensions

980
01:05:42,360 --> 01:05:47,150
what are the massless modes are in about one supergravity coupled to equal one super

981
01:05:47,150 --> 01:05:51,870
yang mills with gauge group which is either fifty two or that is the second

982
01:05:51,870 --> 01:05:54,240
possibility turns out which is

983
01:05:54,260 --> 01:06:00,000
an exception group a cruciate is out of the only two possibilities that if consistent

984
01:06:00,210 --> 01:06:02,920
anomalies theories in ten dimensions

985
01:06:02,930 --> 01:06:06,560
this is the famous kannan schwartzman

986
01:06:06,560 --> 01:06:09,350
that they want to explain

987
01:06:09,360 --> 01:06:14,360
now let's go very directly down o four so that's our basic theory

988
01:06:14,390 --> 01:06:19,290
we need to get the standard model out so obviously we have to compactify six

989
01:06:19,290 --> 01:06:23,550
of the ten dimensions and you have to do may be all sorts of things

990
01:06:23,550 --> 01:06:27,400
you know there are known background fields in this compact space and so on and

991
01:06:27,400 --> 01:06:32,390
so forth it doesn't matter so much what they want to focus is what the

992
01:06:33,640 --> 01:06:38,900
theory we look at in four dimensions well he had his first of all the

993
01:06:38,900 --> 01:06:44,330
effective field in n dimensions if you compute it it has the einstein action this

994
01:06:44,330 --> 01:06:46,890
is the curvature in ten dimensions

995
01:06:46,910 --> 01:06:50,610
this is the end thank you both hearing and dimensions

996
01:06:50,650 --> 01:06:53,620
and this for dimensionality zones

997
01:06:53,620 --> 01:06:58,440
has a quite efficient in front which has powers of most of the aid

998
01:06:58,470 --> 01:07:04,950
in four dimensions you get massive square that's one of urging you to newton's constant

999
01:07:05,110 --> 01:07:10,390
independent mentions you get more powers you get eight hours and i defined this to

1000
01:07:10,390 --> 01:07:12,490
be the string scale to be a

1001
01:07:12,560 --> 01:07:17,130
and then there is also here is the coupling constant of this closed strings which

1002
01:07:17,130 --> 01:07:21,990
is a free parameter in string theory and which sentence has one of the existing

1003
01:07:21,990 --> 01:07:28,110
square and then using here some conventions that get rid of numerical factors

1004
01:07:28,180 --> 01:07:34,360
now likewise the young men's theory in ten dimensions for dimensionality zones has

1005
01:07:34,410 --> 01:07:36,300
a master the six

1006
01:07:36,300 --> 01:07:40,760
and it has also existing squared the factor that the factor between the two is

1007
01:07:41,860 --> 01:07:46,800
one crucial point and one that will come back tomorrow again in the more important

1008
01:07:46,800 --> 01:07:48,320
maybe even way

1009
01:07:48,340 --> 01:07:54,630
is that here we have a calculable theory of quantum gravity so these numbers are

1010
01:07:54,630 --> 01:07:58,070
calculable you know you don't have to wait your hands you can just go ahead

1011
01:07:59,320 --> 01:08:04,490
three or four point amplitudes are measured this company mentioned compute this happening in ten

1012
01:08:04,490 --> 01:08:08,570
dimensions so these are absolutely calculable from the theory

1013
01:08:08,570 --> 01:08:10,110
now we go down

1014
01:08:10,140 --> 01:08:11,740
from ten to four

1015
01:08:11,740 --> 01:08:15,430
so there is some compact six dimensional space

1016
01:08:15,450 --> 01:08:20,860
if we do naive dimensional reduction what will happen if you see here there is

1017
01:08:20,860 --> 01:08:26,890
an integral over ten dimensions it will become an integral over four dimensions that the

1018
01:08:26,890 --> 01:08:30,930
volume of the compact space i is v six

1019
01:08:30,970 --> 01:08:34,910
likewise here you get the volume of the compact space

1020
01:08:34,930 --> 01:08:38,800
it turns out you can also get an integer here some

1021
01:08:38,820 --> 01:08:40,400
natural numbers

1022
01:08:40,410 --> 01:08:43,090
because by going down from ten to four

1023
01:08:43,110 --> 01:08:47,630
you may actually decide to embed the gauge group in a different way in the

1024
01:08:47,630 --> 01:08:51,880
original this offensive toward a cruciate and this gives

1025
01:08:51,880 --> 01:08:55,050
just the natural numbers that the kids here

1026
01:08:55,240 --> 01:09:00,110
and of course this out of the coefficients now often very little einstein hilbert action

1027
01:09:00,130 --> 01:09:05,610
the one that matters for us in our experiment if you wish this we usually

1028
01:09:05,610 --> 01:09:10,800
call one of two times the gravitational coupling constant or one of sixteen five times

1029
01:09:10,820 --> 01:09:12,910
newton's constant g

1030
01:09:12,910 --> 01:09:15,640
so this we know from the experiment

1031
01:09:15,660 --> 01:09:20,930
and this is the coefficient of the young mills theory and that's what we define

1032
01:09:20,930 --> 01:09:23,030
as one of the largest quite young men

1033
01:09:23,030 --> 01:09:29,580
at each

1034
01:14:54,130 --> 01:15:00,400
i mean

1035
01:15:00,400 --> 01:15:01,720
we're pretty good

1036
01:15:01,730 --> 01:15:06,360
at modeling relational data but we're not so hard to doing that with spatial and

1037
01:15:06,360 --> 01:15:10,370
temporal information and many of the social systems are deeply

1038
01:15:11,780 --> 01:15:15,040
there have lots of dynamics which we need to come up with ways of being

1039
01:15:15,040 --> 01:15:16,860
able to effectively model

1040
01:15:16,880 --> 01:15:22,510
but key problem there is feedback really what we what we

1041
01:15:22,960 --> 01:15:27,280
are headed toward are trying to learn full simulation models

1042
01:15:27,850 --> 01:15:34,100
they can express the dynamics of these systems as they move through space and time

1043
01:15:34,120 --> 01:15:39,700
we also have challenges of understanding even the algorithms we currently have

1044
01:15:39,890 --> 01:15:44,370
one of my realizations of over the years has been that it often takes a

1045
01:15:44,370 --> 01:15:47,020
very long time to fully understand how

1046
01:15:47,060 --> 01:15:53,320
an algorithm really functions we've got to start with some of these relational learning algorithms

1047
01:15:53,330 --> 01:15:58,720
there's been work on collective inference about how it is that these algorithms actually do

1048
01:15:58,720 --> 01:16:05,290
their work and infer collectively across the whole set of entities but deep understanding of

1049
01:16:05,290 --> 01:16:10,340
these systems and new algorithms can be really challenging two examples one is that in

1050
01:16:10,340 --> 01:16:14,390
this community don't work association rules for a very long time

1051
01:16:14,400 --> 01:16:22,070
and i was just amazed when at KDD a few years ago geoff webb and

1052
01:16:22,070 --> 01:16:25,180
and then some a team including hiking manila

1053
01:16:25,560 --> 01:16:31,260
shows results which said that many of these algorithms will produce large numbers of association

1054
01:16:31,260 --> 01:16:37,180
rules even when there is absolutely no associations to find in the data

1055
01:16:37,190 --> 01:16:44,200
both of these papers take a stab at having a statistical hypothesis test of the

1056
01:16:44,210 --> 01:16:49,780
associations that association rules find and it was really the first time that that kind

1057
01:16:49,780 --> 01:16:54,080
of work is being done and been done kind of the general way

1058
01:16:54,190 --> 01:16:58,560
two months and i did some work on classification trees some forty years after this

1059
01:16:58,560 --> 01:17:06,170
technique was first developed and published where we discovered the basic performance basic behaviour of

1060
01:17:06,170 --> 01:17:12,540
those algorithms which was that the size of those classification trees continues to go on

1061
01:17:12,570 --> 01:17:17,230
with the size of the dataset even when there's no additional signal to detect so

1062
01:17:17,230 --> 01:17:21,280
the size of the tree that depends on the size of the dataset not on

1063
01:17:21,280 --> 01:17:24,860
the complexity of the underlying distribution

1064
01:17:25,190 --> 01:17:29,550
finally in this area i think there's a there's an issue about acceptance by social

1065
01:17:30,830 --> 01:17:36,540
we regularly develop new techniques and new technologies and it's great for us to develop

1066
01:17:36,540 --> 01:17:40,810
one technique one year new technique the next year we're constantly changing our representations in

1067
01:17:40,810 --> 01:17:45,080
our algorithms and that's fantastic social scientists have their heads

1068
01:17:45,230 --> 01:17:47,740
when we come up to them and say oh by the way all the social

1069
01:17:47,740 --> 01:17:51,940
science you learn all you also need to learn all the stuff were doing and

1070
01:17:51,940 --> 01:17:55,640
we just did last year that stuff you learn the year before now that's really

1071
01:17:55,640 --> 01:17:58,020
not relevant anymore

1072
01:17:58,040 --> 01:18:01,540
we need to talk with the social scientists and try to figure out what it

1073
01:18:01,540 --> 01:18:04,940
is they need because frankly

1074
01:18:04,950 --> 01:18:09,070
there so the only votes that count in terms of whether stuff gets used within

1075
01:18:09,070 --> 01:18:11,680
social science

1076
01:18:11,760 --> 01:18:15,090
OK so now when we talk a little bit about causal analysis

1077
01:18:15,300 --> 01:18:18,130
well that's no need to infer

1078
01:18:18,140 --> 01:18:22,120
well the only new set of variables that were associated with cholera

1079
01:18:22,140 --> 01:18:25,780
but what he wanted to know was what caused

1080
01:18:25,780 --> 01:18:29,010
and needed to do that without doing an experiment you need to do it from

1081
01:18:29,010 --> 01:18:30,760
observational data

1082
01:18:31,180 --> 01:18:36,990
now what i mean when i say causality well causality is really about manipulation

1083
01:18:37,000 --> 01:18:41,050
that is i want to be able to say if i change facts

1084
01:18:41,070 --> 01:18:43,300
why will change

1085
01:18:43,310 --> 01:18:47,530
that is at the core of what we mean by cause and effect is this

1086
01:18:47,530 --> 01:18:49,040
kind of remote control

1087
01:18:49,050 --> 01:18:54,040
i change one variable and if it's causal for another the other one will change

1088
01:18:54,320 --> 01:18:57,920
why would you want to focus on causality is an association good enough we've been

1089
01:18:57,920 --> 01:18:59,710
doing that for a long time

1090
01:18:59,720 --> 01:19:02,080
well correlation or

1091
01:19:02,110 --> 01:19:08,870
i'm i'm going to say statistical dependence unfortunately under determines causality it's not that it's

1092
01:19:08,870 --> 01:19:10,080
not the it's not

1093
01:19:10,130 --> 01:19:14,230
necessary for but it is not sufficient for causation

1094
01:19:14,230 --> 01:19:22,120
statistical association alone is insufficient to distinguish among a set of different causal models if

1095
01:19:22,120 --> 01:19:27,180
a and b are correlated or dependent but it could be either a causes b

1096
01:19:27,190 --> 01:19:32,020
because as a some third variable c causes both a and b or even that

1097
01:19:32,020 --> 01:19:35,900
a and b have common effect on which we have condition

1098
01:19:35,930 --> 01:19:41,770
all right so often unknowingly well conditional on third variable it will render those two

1099
01:19:44,430 --> 01:19:47,190
and what we want to do is the fact p

1100
01:19:47,870 --> 01:19:52,650
these different models have radically different applications but do that

1101
01:19:52,670 --> 01:19:57,570
now this point you may be saying well can we actually even figure out causality

1102
01:19:57,570 --> 01:20:00,930
from observational data and the answer is yes there is a well-developed theory of how

1103
01:20:00,930 --> 01:20:06,030
to do this just as an example if we know that acts

1104
01:20:07,840 --> 01:20:14,050
why are conditionally independent given some other variables that don't include e

1105
01:20:14,060 --> 01:20:19,360
then there is only one causal structure

1106
01:20:19,370 --> 01:20:21,970
but can result in this pattern of association

1107
01:20:22,320 --> 01:20:27,280
this isn't generally true there are many patterns associations that you cannot disambiguate but this

1108
01:20:27,280 --> 01:20:33,470
is one of them that you can under some some reasonable assumptions

1109
01:20:33,490 --> 01:20:34,690
so there no

1110
01:20:34,710 --> 01:20:39,940
the idea of developments in causal analysis the really you know most frequently cited in

1111
01:20:39,940 --> 01:20:44,460
groundbreaking work by pearl and is also has a new edition of his book out

1112
01:20:44,460 --> 01:20:49,670
just now on causal inference has been set of really great work by a team

1113
01:20:49,670 --> 01:20:54,990
at CMU spirit is clearly more in china is also two editions of their book

1114
01:20:55,170 --> 01:21:01,850
on how to develop algorithms to find in data construct causal models for this dataset

1115
01:21:01,870 --> 01:21:05,800
and then there's a set of work in social science that i've been reading lately

1116
01:21:05,800 --> 01:21:09,800
about quasi experimental designs and i'll talk a little bit more about this

1117
01:21:09,840 --> 01:21:14,090
but i think it's really a wonderful opportunity for us in machine learning and data

1118
01:21:15,260 --> 01:21:18,740
so it's not was asked to do what he calls what was people called the

1119
01:21:18,740 --> 01:21:21,970
crucial experiment or experimental increases

1120
01:21:22,290 --> 01:21:26,150
they said in order to figure out which of the hypothesis is right you have

1121
01:21:26,150 --> 01:21:29,520
to do this experiment basically you in fact somebody with color when they're not in

1122
01:21:32,210 --> 01:21:33,710
that's really not ethical

1123
01:21:33,720 --> 01:21:36,580
it's not the sort of the kind of thing doctors going to do

1124
01:21:36,600 --> 01:21:41,750
but fortunately snow found in the massive data sets that had access to

1125
01:21:42,020 --> 01:21:48,290
a subsample with exactly the conditions needed to essentially perform an experiment what he did

1126
01:21:48,290 --> 01:21:51,300
was to find what amounted quasi experiment

1127
01:21:51,670 --> 01:21:56,320
in the work that william far produced in one of his his weekly returns

1128
01:21:56,330 --> 01:21:57,850
he had a footnote

1129
01:21:58,040 --> 01:21:59,280
the footnote ready

1130
01:21:59,330 --> 01:22:00,790
in three cases

1131
01:22:00,810 --> 01:22:03,840
the same districts are supplied by two

1132
01:22:03,860 --> 01:22:05,810
different water companies

1133
01:22:06,040 --> 01:22:12,540
the same geographic region the same socioeconomic class the same that share the same elevation

1134
01:22:12,540 --> 01:22:17,010
supplied by two different water companies and snow happen to know

1135
01:22:17,020 --> 01:22:22,590
those two different water companies drew their water from two different places on the thames

1136
01:22:22,760 --> 01:22:24,450
one company

1137
01:22:24,470 --> 01:22:29,650
through the water upstream of all of the sewage the other through their water from

1138
01:22:30,800 --> 01:22:36,870
he said it was the perfect experiment was an experiment on the grandest scale he

1139
01:22:36,870 --> 01:22:41,390
had three hundred thousand people that were drinking water

1140
01:22:41,820 --> 01:22:46,890
often not knowing where the water came from and with essentially no rhyme or reason

1141
01:22:46,890 --> 01:22:48,280
OK so

1142
01:22:48,320 --> 01:22:51,090
i was defining

1143
01:22:51,960 --> 01:22:54,510
previous slide was this one with defining the

1144
01:22:54,520 --> 01:22:59,870
various type of analysis and now that we have to defined all these concepts

1145
01:22:59,900 --> 01:23:02,990
i want to give you an example

1146
01:23:02,990 --> 01:23:07,330
again these bayesian inference and as i told you so if you look at all

1147
01:23:07,330 --> 01:23:12,490
these items the third generation for the called number that you can

1148
01:23:12,500 --> 01:23:13,310
i have

1149
01:23:13,330 --> 01:23:17,920
a bayesian version of them doesn't mean that patients would accept all of these as

1150
01:23:17,920 --> 01:23:20,760
the definition of bayesian inference but

1151
01:23:22,080 --> 01:23:23,010
these are

1152
01:23:23,040 --> 01:23:25,400
bayesian evaluation of all of them

1153
01:23:25,430 --> 01:23:28,180
so for the generation of the data

1154
01:23:28,190 --> 01:23:30,760
as i told you before you can assume

1155
01:23:30,780 --> 01:23:33,860
you don't have to but you can assume that this function is sampled from some

1156
01:23:33,860 --> 01:23:35,750
prior and the data is sampled

1157
01:23:35,760 --> 01:23:37,680
and labeled according to this function

1158
01:23:37,690 --> 01:23:41,940
you typically have some kind of offline

1159
01:23:41,960 --> 01:23:46,160
protocol where all the given the examples are given and then you want to

1160
01:23:46,180 --> 01:23:48,720
the function to predict the next example

1161
01:23:48,850 --> 01:23:55,440
the last measure is typically the expected there because you have the probability measures so

1162
01:23:55,440 --> 01:23:58,210
you can take expectation and the this probability measure

1163
01:23:59,270 --> 01:24:02,720
and the type of analysis also typically can be

1164
01:24:02,740 --> 01:24:05,680
the average under the prior that's why you

1165
01:24:05,690 --> 01:24:08,860
make this assumption that the function is sampled from some prior

1166
01:24:08,880 --> 01:24:13,050
it's only for the united states

1167
01:24:13,380 --> 01:24:15,800
and sometimes you have all you have also

1168
01:24:15,820 --> 01:24:18,210
other assumptions on how the

1169
01:24:18,220 --> 01:24:20,300
labels are

1170
01:24:20,300 --> 01:24:23,160
corrupted by noise

1171
01:24:23,160 --> 01:24:26,190
OK and of course you don't have to

1172
01:24:26,210 --> 01:24:31,080
take all of them as it as the definition of bayesian inference and you can

1173
01:24:31,940 --> 01:24:34,040
make all sorts of combinations where you can

1174
01:24:34,050 --> 01:24:40,350
make an average case analysis in a setting where in the different protocol or with

1175
01:24:40,350 --> 01:24:43,410
the different was measured it is that i mean there's no

1176
01:24:43,440 --> 01:24:46,100
the reason to see that to see

1177
01:24:47,160 --> 01:24:48,350
distinctions so

1178
01:24:48,380 --> 01:24:51,330
you can combine all these things in different ways but the important point is to

1179
01:24:51,330 --> 01:24:54,660
see or to understand what you are combining

1180
01:24:54,700 --> 01:24:57,880
and what it means to combine

1181
01:24:57,950 --> 01:24:59,390
so in

1182
01:24:59,410 --> 01:25:04,750
in my case i will be interested mainly in the worst case analysis

1183
01:25:04,760 --> 01:25:07,220
because i want to provide guarantees that

1184
01:25:07,250 --> 01:25:09,570
i hold no matter what

1185
01:25:09,590 --> 01:25:12,290
the problem that you're looking in

1186
01:25:12,310 --> 01:25:14,500
that you're looking at is

1187
01:25:15,570 --> 01:25:17,870
try to avoid assumptions as much as possible

1188
01:25:19,170 --> 01:25:19,950
of course

1189
01:25:19,970 --> 01:25:23,760
under these conditions look for the best algorithm so

1190
01:25:23,780 --> 01:25:25,190
the kind of quantity that

1191
01:25:25,200 --> 01:25:28,850
i want to investigate is this one

1192
01:25:28,870 --> 01:25:34,290
so i have to say predictor of learning algorithm i have a problem i can

1193
01:25:34,290 --> 01:25:39,350
characterize the loss of this predictor on on this problem can be a function that

1194
01:25:39,350 --> 01:25:40,500
i cannot

1195
01:25:40,530 --> 01:25:43,070
actually measured can be expected error

1196
01:25:43,160 --> 01:25:46,090
but is something that i cannot is approximate

1197
01:25:46,100 --> 01:25:48,250
and i want to

1198
01:25:48,260 --> 01:25:50,130
i don't want to make assumption about

1199
01:25:50,130 --> 01:25:53,260
what the problem is actually because i don't know i just at beta i don't

1200
01:25:53,260 --> 01:25:54,310
know what

1201
01:25:54,370 --> 01:25:57,440
where this data comes from the comes from

1202
01:25:57,850 --> 01:26:01,030
so i think the maximum over all possible problems

1203
01:26:01,070 --> 01:26:02,940
and hopefully

1204
01:26:02,950 --> 01:26:09,450
i would like to have another reason that minimizes this quantity here

1205
01:26:09,470 --> 01:26:12,790
and the question is whether this is possible

1206
01:26:12,880 --> 01:26:15,220
and reasonable

1207
01:26:17,290 --> 01:26:18,760
they like this

1208
01:26:18,780 --> 01:26:23,780
it's not really possible you we can show and i give examples of serums that

1209
01:26:23,780 --> 01:26:25,920
show that you cannot do that or

1210
01:26:25,970 --> 01:26:29,600
you can do this this minimum will be always trivial

1211
01:26:29,620 --> 01:26:36,160
and the point is that you can always construct problems that will make your algorithm

1212
01:26:36,160 --> 01:26:39,690
thing no matter which algorithm that you're using

1213
01:26:44,690 --> 01:26:48,290
again it's again amount of point of view but i think

1214
01:26:48,310 --> 01:26:52,160
hopefully it will be the last time i talk about point of view and then

1215
01:26:52,160 --> 01:26:52,970
i get to

1216
01:26:53,000 --> 01:26:55,440
actual formalisation

1217
01:26:55,450 --> 01:26:59,820
i think it's important to understand this distinction

1218
01:27:01,030 --> 01:27:02,820
rewriting this quantity that day

1219
01:27:02,830 --> 01:27:05,630
shown on the previous slide

1220
01:27:07,260 --> 01:27:11,840
several ways of looking at it one way the so-called minimax point of view

1221
01:27:11,860 --> 01:27:15,810
the main point of view is to say well if i can do

1222
01:27:17,800 --> 01:27:22,170
if this doesn't make sense when i take the maximum over all problems there

1223
01:27:22,180 --> 01:27:26,590
i can just restrict the class of problems that i'm allowed

1224
01:27:26,610 --> 01:27:31,260
to consider and then have a quantity that makes sense

1225
01:27:32,050 --> 01:27:34,370
it's perfectly fine to do that i see

1226
01:27:34,440 --> 01:27:38,010
i just rewrite the same thing but now i restrict my problem to be in

1227
01:27:38,010 --> 01:27:42,450
a certain class so i make a certain number of assumptions on how the data

1228
01:27:42,450 --> 01:27:46,680
is generated how the noise behaves how the

1229
01:27:47,060 --> 01:27:51,280
how small is my function is and so on and they say well

1230
01:27:51,300 --> 01:27:56,300
given the worst such function or the worst such debates are

1231
01:27:56,320 --> 01:28:03,200
how what is the best algorithm what the algorithm that minimizes the worst ever

1232
01:28:03,510 --> 01:28:07,460
and there are two versions you can also consider

1233
01:28:07,480 --> 01:28:11,730
this quantity here where you subtract the best loss

1234
01:28:12,320 --> 01:28:15,870
so some kind of the the best predictor that you could have obtained if you

1235
01:28:15,870 --> 01:28:18,130
knew the problem entirely

1236
01:28:18,360 --> 01:28:22,070
and this is why we can i mean

1237
01:28:22,080 --> 01:28:23,240
there is of

1238
01:28:24,570 --> 01:28:27,760
domain of study the minimax estimation

1239
01:28:27,760 --> 01:28:32,170
serie where you can improve results about such quantities

1240
01:28:32,300 --> 01:28:38,840
another related to point of view is the so-called learnability point of view

1241
01:28:39,920 --> 01:28:42,840
again you assume that the function that you're

1242
01:28:42,870 --> 01:28:48,280
trying to approximate or your so called target function function that does labelled examples

1243
01:28:48,310 --> 01:28:50,130
belong to some class

1244
01:28:50,130 --> 01:28:52,740
and then the question is whether

1245
01:28:52,760 --> 01:28:53,510
you can

1246
01:28:53,530 --> 01:28:59,820
learn this class in and learning the class means being able to identify any of

1247
01:28:59,840 --> 01:29:04,880
the functions in this class with enough examples of given enough examples you can construct

1248
01:29:04,880 --> 01:29:08,010
an reason that will learn

1249
01:29:08,420 --> 01:29:10,630
any function in this class

1250
01:29:10,640 --> 01:29:15,530
which means that the minimax error that they should previously we go to zero when

1251
01:29:15,530 --> 01:29:17,900
the sample size increases

1252
01:29:18,090 --> 01:29:23,380
OK and again this means you make assumptions you assume that your target function belongs

1253
01:29:23,380 --> 01:29:26,370
to some class so that your data is generated in a certain way

1254
01:29:26,380 --> 01:29:28,000
and if it's not the case

1255
01:29:28,020 --> 01:29:30,980
then your result does not hold any more

1256
01:29:31,820 --> 01:29:35,090
they are not useful anymore if this is not the case and the problem is

1257
01:29:35,620 --> 01:29:37,440
can never

1258
01:29:37,500 --> 01:29:40,000
for almost never be sure

1259
01:29:40,010 --> 01:29:43,500
that your assumptions are correct

1260
01:29:43,520 --> 01:29:45,070
in practice you cannot say

1261
01:29:45,080 --> 01:29:48,330
whether the noise is gaussian or not gaussians

1262
01:29:48,340 --> 01:29:52,030
it is it seems like it is just

1263
01:29:52,080 --> 01:29:54,990
we have no way to prove that the noises as a certain form

1264
01:29:55,120 --> 01:29:59,780
another point of view which is about even worse in my

1265
01:29:59,840 --> 01:30:03,140
my opinion

1266
01:30:03,150 --> 01:30:06,360
it is the so-called model identification

1267
01:30:06,380 --> 01:30:11,450
so in this case you don't want to minimize the error you want to identify

1268
01:30:11,820 --> 01:30:17,380
the function itself so what you look at is the distance between the function constructed

1269
01:30:17,380 --> 01:30:20,930
by organism and the true function

1270
01:30:20,940 --> 01:30:22,210
if it exists

1271
01:30:22,230 --> 01:30:25,270
and usually you cannot define it but

1272
01:30:25,320 --> 01:30:27,300
fine in certain key i mean you can

1273
01:30:28,500 --> 01:30:29,770
make statements

1274
01:30:29,770 --> 01:30:33,280
to meet the check that you right at at the end of next month

1275
01:30:33,280 --> 01:30:35,780
they only start to care

1276
01:30:35,800 --> 01:30:40,080
when they feel that there's something in it for them

1277
01:30:40,120 --> 01:30:45,330
so you need to know them inside out so that you can position what you're

1278
01:30:46,100 --> 01:30:48,430
in the context of what they'll get from it

1279
01:30:48,540 --> 01:30:53,580
so one of the critical thing if you want to engage people every charismatic leader

1280
01:30:53,910 --> 01:30:57,100
the the lowest and the highest simply

1281
01:30:57,120 --> 01:31:01,510
translates and interprets the vision that they have

1282
01:31:01,560 --> 01:31:06,580
in the terms of the interests of people that work for them

1283
01:31:06,700 --> 01:31:12,810
it's an interesting thing it's worth reading about if you've read about o thing called

1284
01:31:12,810 --> 01:31:18,200
emotional contagion and we we touched on this morning when we spoke about smiling

1285
01:31:18,200 --> 01:31:22,990
and here's here's what built into you as i say into the reptilian brain we

1286
01:31:22,990 --> 01:31:28,620
automatically mimic the body language of the people around us we automatically mimic when they

1287
01:31:28,620 --> 01:31:32,830
when they smile we find ourselves smiling you feel like an idiot sometimes

1288
01:31:32,850 --> 01:31:36,870
i don't know about you sometimes and watching the TV and very susceptible watching TV

1289
01:31:36,870 --> 01:31:39,910
and somebody comes and a big smile i'm sitting there with a grin on my

1290
01:31:39,910 --> 01:31:42,350
face because africa TV

1291
01:31:42,390 --> 01:31:46,850
and i got this big smile and and you smile and then somebody else miles

1292
01:31:46,850 --> 01:31:48,240
and so on and so forth

1293
01:31:48,260 --> 01:31:53,640
in two zero sum is one of those emotions is one of those behaviour which

1294
01:31:53,640 --> 01:31:57,450
is just so extraordinarily

1295
01:31:59,470 --> 01:32:02,720
it goes around the room like this let me ask you

1296
01:32:02,740 --> 01:32:05,100
let's go to the dark side from

1297
01:32:05,200 --> 01:32:07,830
does anybody know someone

1298
01:32:07,850 --> 01:32:10,220
don't shout out any names

1299
01:32:10,240 --> 01:32:12,390
who when they walk into the room

1300
01:32:12,450 --> 01:32:14,780
socks all the good out of the room

1301
01:32:14,910 --> 01:32:18,330
as they say in the states sucks the oxygen out of rule when they go

1302
01:32:18,330 --> 01:32:21,370
in the movie goes down does anybody know someone like that is not going to

1303
01:32:21,370 --> 01:32:22,890
ask you for names

1304
01:32:22,910 --> 01:32:27,580
there are people sirbasku used to call them psychic vampires

1305
01:32:27,620 --> 01:32:30,790
he said they walk around with an umbilical cord

1306
01:32:30,830 --> 01:32:34,680
attach them and just look at the plug to you and so every bit of

1307
01:32:34,680 --> 01:32:39,330
motivation and positivity that they possibly can out of you because

1308
01:32:39,430 --> 01:32:43,640
as the expressions as misery loves company

1309
01:32:43,810 --> 01:32:49,700
when you're really feeling as miserable as negative is that then they feel OK

1310
01:32:49,720 --> 01:32:51,290
it's not just me

1311
01:32:51,310 --> 01:32:54,370
but the reality is the location is just the

1312
01:32:54,390 --> 01:32:56,180
you walk into a room

1313
01:32:56,200 --> 01:32:57,890
as the leader of people

1314
01:32:57,910 --> 01:33:02,490
not only is smiling and you're using a language that suggests that you're at least

1315
01:33:02,490 --> 01:33:06,430
enjoying yourself which are genuinely energetic and enthusiastic

1316
01:33:06,430 --> 01:33:08,560
it costs nothing

1317
01:33:08,580 --> 01:33:13,350
and it has an extraordinary impact on people you watch yourself next time around somebody

1318
01:33:13,350 --> 01:33:17,470
into CSD what you find yourself doing is mimicking the

1319
01:33:17,470 --> 01:33:23,220
you can't help but because that little reptilian part of your brain says whatever god

1320
01:33:23,220 --> 01:33:27,160
i like and i want some of it and you start to mimic and whatever

1321
01:33:27,160 --> 01:33:28,220
they are doing

1322
01:33:28,220 --> 01:33:30,020
the interesting thing is

1323
01:33:30,040 --> 01:33:33,790
when you may make it actually causes you to feel the same feelings and so

1324
01:33:33,790 --> 01:33:38,310
you get that as i say that contagion this is critical

1325
01:33:38,330 --> 01:33:39,660
if you

1326
01:33:39,720 --> 01:33:44,870
are enthusiastic and energetic you will and susan energize people over time

1327
01:33:44,890 --> 01:33:47,700
not the first time

1328
01:33:47,740 --> 01:33:51,260
if you're one of these people is really not that terribly enthusiastic

1329
01:33:51,350 --> 01:33:53,970
i don't expect when you go back to the office to go to the boys

1330
01:33:53,970 --> 01:33:56,290
are back let's go let's have a great day

1331
01:33:56,310 --> 01:34:00,010
but obviously got OK OK boss let's do it

1332
01:34:00,040 --> 01:34:03,410
it takes a little bit of time for people to trust but the first time

1333
01:34:03,410 --> 01:34:10,100
that you start becoming enthusiastic letting people see your enthusiasm

1334
01:34:10,160 --> 01:34:14,890
i mean sometimes my mother used to say to you know if are you happy

1335
01:34:14,890 --> 01:34:17,790
yes i am well please tell your face

1336
01:34:17,890 --> 01:34:22,640
you know if you're happy if you're enthusiastic let other people see it share it

1337
01:34:22,640 --> 01:34:27,060
with other people it'll spread through the extraordinary impact upon people

1338
01:34:27,100 --> 01:34:32,890
and it was one of the things that came out highly rated by our four

1339
01:34:32,890 --> 01:34:35,240
hundred thousand followers they said

1340
01:34:36,220 --> 01:34:41,140
are turned on by people who are excited and enthusiastic about the things that they're

1341
01:34:41,140 --> 01:34:44,790
doing it as i say it doesn't cost the centre

1342
01:34:44,830 --> 01:34:48,870
and if you can be enthusiastic about what you're doing you're either in the wrong

1343
01:34:49,890 --> 01:34:52,120
well you've lost your way a little bit

1344
01:34:52,180 --> 01:34:54,640
and here's how you know if you lost your way

1345
01:34:54,740 --> 01:35:00,640
if you don't have for yourself some pretty clear idea of what you're doing what

1346
01:35:00,640 --> 01:35:01,450
you're doing today

1347
01:35:01,930 --> 01:35:05,830
and what is going to mean for you this time next year personally well then

1348
01:35:05,830 --> 01:35:07,790
you're slightly off the track

1349
01:35:07,810 --> 01:35:09,970
and the way you get that enthusiasm back

1350
01:35:10,080 --> 01:35:14,830
you get yourself engaged for a set of personal goals that are aligned ideally with

1351
01:35:14,830 --> 01:35:18,740
the business schools or find another job that our language are business school which i

1352
01:35:18,740 --> 01:35:24,290
have to be enthusiastic you can't take it

1353
01:35:24,330 --> 01:35:26,560
we've be telling people forever

1354
01:35:26,580 --> 01:35:28,600
no in fact let me go back a little bit further

1355
01:35:29,100 --> 01:35:34,160
if you go back to when i first started working which is used to

1356
01:35:34,260 --> 01:35:36,260
about thirty years ago

1357
01:35:36,390 --> 01:35:41,310
these are the traditional role of the leader was really kind of policemen

1358
01:35:41,350 --> 01:35:44,910
it is job our job was to catch you doing something wrong and then smack

1359
01:35:44,910 --> 01:35:45,810
your heart

1360
01:35:45,830 --> 01:35:49,560
you know is like the spanish police at the the the football matches step out

1361
01:35:49,560 --> 01:35:51,040
of line you crack your skull

1362
01:35:51,120 --> 01:35:55,160
and then fifteen years ago probably blanchard and those sort of people started writing books

1363
01:35:55,160 --> 01:35:56,950
is that i got an idea

1364
01:35:56,950 --> 01:36:00,200
what if we catch people doing something right

1365
01:36:00,240 --> 01:36:04,370
what if we go around catcher people doing some and we say a great job

1366
01:36:04,390 --> 01:36:06,060
i wonder what that work

1367
01:36:06,080 --> 01:36:09,760
so since then we've been telling people recognition

1368
01:36:09,790 --> 01:36:11,020
is critically

1369
01:36:12,890 --> 01:36:16,990
now recognition is important not just because

1370
01:36:17,010 --> 01:36:18,560
it's a nice thing to do

1371
01:36:18,580 --> 01:36:20,890
but because it has the same effect

1372
01:36:20,910 --> 01:36:26,160
as even smiling were talking about earlier on their two critical effect in recognition

1373
01:36:26,160 --> 01:36:27,540
the first one is

1374
01:36:27,540 --> 01:36:33,240
when you give somebody some positive feedback on something that they've done when you give

1375
01:36:33,240 --> 01:36:36,930
them a genuine recognition for something positive they done

1376
01:36:37,010 --> 01:36:38,330
you cause

1377
01:36:38,350 --> 01:36:42,240
an injection a little squirt dopamine in the brain

1378
01:36:42,830 --> 01:36:44,850
dopamine is the chemical

1379
01:36:44,870 --> 01:36:46,700
that those of you

1380
01:36:46,700 --> 01:36:50,640
who get really pleasurable sensation from chuck

1381
01:36:50,680 --> 01:36:53,780
when chocolate of

1382
01:36:53,830 --> 01:36:55,790
that's dopamine

1383
01:36:55,790 --> 01:36:58,850
it's what people get from sexual intercourse

1384
01:36:58,870 --> 01:37:01,330
it's what it is like a

1385
01:37:01,330 --> 01:37:05,370
anybody here run or cycle you know do vigorous exercise

1386
01:37:05,390 --> 01:37:07,700
there must be somebody this is not a trick question mark

1387
01:37:07,720 --> 01:37:12,180
OK so you know what i'm talking about when i talk about the runners high

1388
01:37:12,240 --> 01:37:16,020
you know you finish run if you just feel like god i could take on

1389
01:37:16,020 --> 01:37:19,580
but you see the past alive rather than digging it out and see the bones

1390
01:37:19,580 --> 01:37:23,280
of dinosaurs and so when you look at the light from the sun it comes

1391
01:37:23,280 --> 01:37:26,840
from as it was eight minutes ago although the four times to come out from

1392
01:37:26,840 --> 01:37:30,900
the centre of the sun all the way out two million but you don't want

1393
01:37:30,910 --> 01:37:35,060
to get to the surface to you it takes eight minutes and we are not

1394
01:37:35,060 --> 01:37:38,960
sitting in the center of our galaxy we are seeking about a particular but six

1395
01:37:38,960 --> 01:37:40,800
out and so

1396
01:37:41,000 --> 01:37:44,040
when we see the light from the centre of the galaxies to twenty eight

1397
01:37:44,600 --> 01:37:47,040
two twenty metres does

1398
01:37:47,040 --> 01:37:52,740
twenty thousand years ago and when you see a nearby galaxy like andromeda

1399
01:37:52,750 --> 01:37:58,670
we see slide as it was as you started from there was admitted about two

1400
01:37:58,670 --> 01:38:01,030
million years ago and one c

1401
01:38:01,080 --> 01:38:04,880
the large-scale distribution of galaxies you have seen the universe as he was about to

1402
01:38:04,910 --> 01:38:09,990
three billion years ago

1403
01:38:10,040 --> 01:38:14,340
so when we see these very nice pictures for example you probably have seen this

1404
01:38:14,340 --> 01:38:19,920
picture even in t-shirts like this is an image from the hubble space telescope it's

1405
01:38:19,920 --> 01:38:23,560
an image of the stellar nursery where start a more

1406
01:38:23,610 --> 01:38:30,410
now this is a beautiful this column of dust and here the stars main created

1407
01:38:30,460 --> 01:38:33,780
these are not direct useful cosmology

1408
01:38:33,830 --> 01:38:39,110
because these things is some structure that is you know some small-scale structure inside our

1409
01:38:39,180 --> 01:38:44,590
galaxy is a member of most of cosmology scalar galaxies that point but cosmology is

1410
01:38:44,590 --> 01:38:47,420
very interested in exploding stars

1411
01:38:47,430 --> 01:38:52,110
exploding stars cause supernovae this are very useful and we see at the very end

1412
01:38:52,110 --> 01:38:57,070
why basically because when this kind of stuff this for a very short time there

1413
01:38:57,070 --> 01:39:01,590
as bright as an entire galaxy and so you can see them are truly cosmological

1414
01:39:01,590 --> 01:39:04,630
distances you can see them almost to the edge of the universe

1415
01:39:04,640 --> 01:39:08,300
so that's really good way to work cell unit test

1416
01:39:08,340 --> 01:39:12,570
how do you know what is the geometry and the distribution of that universe

1417
01:39:12,590 --> 01:39:17,570
but just to see some poetry we are stardust

1418
01:39:17,590 --> 01:39:22,470
because as we see the primordial universe was made very light elements

1419
01:39:22,480 --> 01:39:27,480
so all the elements that make you me and everything you see around were created

1420
01:39:27,480 --> 01:39:34,150
inside stars and it's thanks to exploding stars that all this material was generating starts

1421
01:39:34,360 --> 01:39:41,890
with three distributed and then ended up forming galaxies planets you accept x

1422
01:39:41,940 --> 01:39:43,760
so just to get an idea

1423
01:39:43,820 --> 01:39:48,770
about the structure of galaxies are galaxies collection of you know between ten to the

1424
01:39:48,770 --> 01:39:51,130
eleventh the twelve start

1425
01:39:52,000 --> 01:39:56,530
and so this is the schematic view of the galaxy like our own milky way

1426
01:39:56,550 --> 01:39:57,960
so sold

1427
01:39:57,970 --> 01:40:00,530
there is typically about in the

1428
01:40:00,600 --> 01:40:03,600
and then there is that these on

1429
01:40:03,640 --> 01:40:08,130
and the that starts living here and here around

1430
01:40:08,600 --> 01:40:16,340
these in the bottom there are these blobs blob representing globular clusters these clusters of

1431
01:40:16,340 --> 01:40:22,560
about ten to the sixth stars and we're gonna see globular clusters again later on

1432
01:40:22,690 --> 01:40:28,510
this kind of scale is going to come out naturally from some of the arguments

1433
01:40:30,660 --> 01:40:36,980
these blocks you could here represent nearly spherical halo of dark matter

1434
01:40:37,840 --> 01:40:42,810
i'm showing these because today we know that most of the mathematics of the universe

1435
01:40:42,810 --> 01:40:49,080
is that it's not even made like stuff like me use computer stable and one

1436
01:40:49,080 --> 01:40:51,110
of the first evidences for the

1437
01:40:51,530 --> 01:40:56,110
the existence of a lot of unseen dark matter came actually from the study of

1438
01:40:56,110 --> 01:41:02,480
galaxies so that's why i'm going to show this here to introduce the concept

1439
01:41:07,520 --> 01:41:11,510
and nice image of the galaxy as we have seen before this could be not

1440
01:41:11,930 --> 01:41:13,610
too different from our own

1441
01:41:13,700 --> 01:41:18,450
and but there are also galaxies are much more irregular than than that this is

1442
01:41:18,450 --> 01:41:24,580
the learning cloud is this moment cloud but there are also galaxies that clearly undisturbed

1443
01:41:24,580 --> 01:41:28,970
in this case you see these tidal tail is probably underwent an interaction with some

1444
01:41:28,970 --> 01:41:34,880
other galaxy reputation interaction probably galaxies pass by and then formed identity love

1445
01:41:34,980 --> 01:41:37,190
of gas and stars

1446
01:41:37,230 --> 01:41:42,400
and here is another famous one distant galaxy because it looks like a sombrero and

1447
01:41:42,400 --> 01:41:44,050
this is the something of dust

1448
01:41:45,930 --> 01:41:47,340
and now

1449
01:41:47,380 --> 01:41:53,510
going to larger scale so this is a schematic representation of our local group is

1450
01:41:53,510 --> 01:41:55,730
our galaxy local neighborhood

1451
01:41:57,130 --> 01:42:02,610
so remember this galaxy was seen before in this graph just points and now when

1452
01:42:02,610 --> 01:42:07,690
we talk about this kind of scale we're entering the regime of of cosmology

1453
01:42:10,440 --> 01:42:16,080
so groups of galaxies is an example of a group of galaxies held together gravitational

1454
01:42:16,080 --> 01:42:17,330
you you know

1455
01:42:17,340 --> 01:42:20,330
three or four of those

1456
01:42:20,390 --> 01:42:21,570
but then

1457
01:42:21,570 --> 01:42:22,520
in a way

1458
01:42:22,540 --> 01:42:24,000
it is really

1459
01:42:24,020 --> 01:42:28,420
it's really this thing of of sampling from your posterior OK sort of looking what

1460
01:42:28,430 --> 01:42:31,520
are all the possible values of pi that you believe in

1461
01:42:31,570 --> 01:42:34,310
after you've combine your prior with the likelihood

1462
01:42:34,380 --> 01:42:37,650
now solving this integral for the two models we have to remember

1463
01:42:38,040 --> 01:42:40,210
this guy was the guy with the flat prior

1464
01:42:40,230 --> 01:42:43,200
and this guy was guy there was a bit more

1465
01:42:43,260 --> 01:42:48,110
optimistic in thinking that there might not be cheating right let's just remind ourselves what

1466
01:42:48,110 --> 01:42:50,500
model a and b is

1467
01:42:50,530 --> 01:42:53,340
so what so what do you expect which

1468
01:42:53,420 --> 01:42:55,010
which of the two models

1469
01:42:55,010 --> 01:42:56,550
do you think

1470
01:42:56,570 --> 01:42:58,680
is going to think that on average

1471
01:42:58,700 --> 01:43:01,150
OK let me try from the question but

1472
01:43:01,170 --> 01:43:04,200
which of the two models is going to give approach

1473
01:43:04,220 --> 01:43:10,860
of pi that is closest to one

1474
01:43:18,720 --> 01:43:20,290
it is

1475
01:43:20,290 --> 01:43:21,980
so so b

1476
01:43:22,020 --> 01:43:25,320
is more is still closer to half right

1477
01:43:25,370 --> 01:43:26,530
in other words

1478
01:43:26,550 --> 01:43:31,680
so we need a sort of but it's not an overwhelming difference right

1479
01:43:31,750 --> 01:43:33,840
so the whole thing here is that you

1480
01:43:33,840 --> 01:43:37,120
you have only observed one head but you don't believe that the probability

1481
01:43:37,150 --> 01:43:40,680
of heads is is is one just because you have done one experiment and came

1482
01:43:40,690 --> 01:43:43,670
out once right you believe something in the middle

1483
01:43:43,730 --> 01:43:45,540
now how quickly

1484
01:43:45,540 --> 01:43:49,540
you're gonna update your beliefs depends on how vague prior was

1485
01:43:49,560 --> 01:43:50,550
all right

1486
01:43:50,560 --> 01:43:58,910
so it's it's just nice to have this machinery available basically

1487
01:43:59,040 --> 01:44:01,580
OK so let me see

1488
01:44:01,600 --> 01:44:04,130
how we kind we have

1489
01:44:04,150 --> 01:44:06,190
three more slides about the coin

1490
01:44:06,210 --> 01:44:09,370
before we move on to something else rather quickly so

1491
01:44:09,620 --> 01:44:15,150
i think i'm going to skip this

1492
01:44:15,230 --> 01:44:20,460
because otherwise we don't manage to go through the rest of the

1493
01:44:20,540 --> 01:44:24,200
the thing is you can also have

1494
01:44:24,210 --> 01:44:28,330
this this prior things you can also have priors over models so instead of having

1495
01:44:28,330 --> 01:44:30,520
to choose between model and b

1496
01:44:30,530 --> 01:44:31,720
you could also say

1497
01:44:31,750 --> 01:44:34,390
on choosing you know i'm going to say that

1498
01:44:34,410 --> 01:44:39,010
i believe with a certain probability that that the model is correct and i believe

1499
01:44:39,010 --> 01:44:42,770
with some probability that will be correct what i mean with model is aiming the

1500
01:44:42,770 --> 01:44:47,120
prior that i'm choosing so imagine now two very extreme priors OK this is a

1501
01:44:47,120 --> 01:44:52,150
very very extreme prior this is the delta on zero five so this guy

1502
01:44:52,160 --> 01:44:54,760
it's completely convinced that the coin is fair

1503
01:44:54,770 --> 01:44:57,870
and actually the data to him is not going to is not going to matter

1504
01:44:57,870 --> 01:45:01,800
much right because when you compute the posterior is not going to change his opinion

1505
01:45:01,800 --> 01:45:07,060
right this prior cannot be changing anything by by by observing data

1506
01:45:07,080 --> 01:45:11,530
and this is our agnostic guy from the beginning who actually turns out not to

1507
01:45:11,530 --> 01:45:14,860
be some gnostic it's guy who sort of things that you know

1508
01:45:14,880 --> 01:45:16,610
there's a fair chance of the

1509
01:45:17,600 --> 01:45:18,500
it's bent

1510
01:45:18,520 --> 01:45:19,670
and now we observed

1511
01:45:19,700 --> 01:45:23,100
we make ten tosses and we observe two heads and eight tails

1512
01:45:24,000 --> 01:45:26,370
so now if i didn't want to choose one thing i could do is i

1513
01:45:26,370 --> 01:45:29,430
could either go with smaller i can go with this model but the other thing

1514
01:45:29,430 --> 01:45:31,880
i could do is i could actually say well

1515
01:45:31,900 --> 01:45:32,800
you know

1516
01:45:32,810 --> 01:45:37,080
if i if i have a prior that sort of says

1517
01:45:37,090 --> 01:45:39,560
that we the the probability

1518
01:45:42,010 --> 01:45:43,280
zero point eight

1519
01:45:43,300 --> 01:45:47,300
the coin is fair and then i have this of the guide the bendigo was

1520
01:45:47,300 --> 01:45:49,870
sort of things with twenty percent probability

1521
01:45:49,920 --> 01:45:51,080
it could be anything

1522
01:45:51,170 --> 01:45:54,400
i could not actually update

1523
01:45:54,410 --> 01:45:58,230
the i could basically i'm going to go through this quickly because there was never

1524
01:45:58,230 --> 01:46:01,350
going to make it to lunch OK so let's let's jump directly to this equation

1525
01:46:02,040 --> 01:46:03,650
so what i can do now

1526
01:46:03,680 --> 01:46:05,810
it's like i can actually compute

1527
01:46:05,850 --> 01:46:09,370
what my posterior belief on the on the model is OK

1528
01:46:09,430 --> 01:46:12,880
this isn't normalised so basically if you want to normalise it

1529
01:46:12,950 --> 01:46:15,080
what you get is you have to add

1530
01:46:15,080 --> 01:46:18,200
the two so this guide this will be two-thirds and this will be one third

1531
01:46:18,200 --> 01:46:22,380
so after observing the sequence we've seen

1532
01:46:22,400 --> 01:46:24,730
i now believe with probability

1533
01:46:24,750 --> 01:46:30,160
two thirds the coin is fair and with probability one third it's not fair anything

1534
01:46:30,160 --> 01:46:33,200
i wanted to make a prediction what i would do is i would combine the

1535
01:46:33,200 --> 01:46:34,160
two models

1536
01:46:34,220 --> 01:46:37,110
by waiting what they're going to say

1537
01:46:37,130 --> 01:46:40,890
by my posterior belief on the model itself being correct

1538
01:46:40,900 --> 01:46:44,100
so how does it work as it was two-thirds and one-third

1539
01:46:44,100 --> 01:46:48,370
and this is what both models would say the model that that has the piquancy

1540
01:46:48,480 --> 01:46:52,810
five is always going to say zero five right and the other one would say

1541
01:46:52,850 --> 01:46:56,120
three twelve and if you want later we can we can sort of work out

1542
01:46:56,120 --> 01:46:59,750
why if a toss the coin ten times and observe two heads and how this

1543
01:46:59,750 --> 01:47:03,570
flat prior how do i compute that number how do i get the the three

1544
01:47:03,570 --> 01:47:06,100
twelve OK and this is basically

1545
01:47:06,120 --> 01:47:08,620
the prediction i would make so what i want is

1546
01:47:08,670 --> 01:47:11,870
the point i want to make here is that

1547
01:47:11,870 --> 01:47:12,860
very often

1548
01:47:12,860 --> 01:47:18,460
in in bayesian modeling you end up being a hierarchy of priors on things OK

1549
01:47:18,460 --> 01:47:19,560
you sort of say

1550
01:47:19,570 --> 01:47:22,570
i have a prior on the number of

1551
01:47:22,590 --> 01:47:25,940
hidden units or whatever and then i have a prior on

1552
01:47:25,970 --> 01:47:29,460
once i have fixed that have a prior on on the values of the weights

1553
01:47:29,540 --> 01:47:31,870
and i can i can always sort of

1554
01:47:31,920 --> 01:47:36,180
average over those things eventually so i've been posteriors and i average over all these

1555
01:47:38,870 --> 01:47:42,870
OK so now i'm going to try to show some pictures before we go

1556
01:47:42,920 --> 01:47:44,290
for lunch

1557
01:47:44,500 --> 01:47:47,360
OK so

1558
01:47:47,390 --> 01:47:52,120
this is borrowed or stolen from radford neal's two thousand four

1559
01:47:53,330 --> 01:47:55,100
on bayesian

1560
01:47:55,110 --> 01:47:58,180
learning let's just give this slide because it's unpleasant let's move on to the slide

1561
01:47:58,180 --> 01:47:59,950
which is more pleasant

1562
01:48:00,020 --> 01:48:04,110
what the previous slide said was in equations what these slides so it's much better

1563
01:48:04,120 --> 01:48:05,550
to look at this level of zero

1564
01:48:05,660 --> 01:48:07,270
OK what does this slides

1565
01:48:07,280 --> 01:48:08,530
the slices says

1566
01:48:08,530 --> 01:48:12,330
and to do this innovation we need to understand how

1567
01:48:12,350 --> 01:48:14,210
so documents

1568
01:48:14,240 --> 01:48:17,420
and here see some progress in time

1569
01:48:17,420 --> 01:48:21,600
the time for a during

1570
01:48:21,600 --> 01:48:24,380
and in ancient egypt

1571
01:48:24,450 --> 01:48:27,440
what they had had only

1572
01:48:27,490 --> 01:48:30,410
presentation oriented text format

1573
01:48:30,410 --> 01:48:35,580
what does that mean it means that representation of the document was

1574
01:48:38,770 --> 01:48:41,420
it was some layout of the document

1575
01:48:41,430 --> 01:48:44,700
this layout is somehow connected real

1576
01:48:44,710 --> 01:48:49,210
information that we want to extract but it can be not connected with this information

1577
01:48:49,230 --> 01:48:50,560
at all

1578
01:48:50,570 --> 01:48:55,140
like in this example we have to call on document

1579
01:48:55,150 --> 01:48:57,650
we don't need to extract more

1580
01:48:57,660 --> 01:49:03,400
as one line what i call on everyone to extract it felt were from one

1581
01:49:03,400 --> 01:49:06,410
column then switch to another

1582
01:49:07,430 --> 01:49:10,580
presentation oriented former months and this is

1583
01:49:10,580 --> 01:49:12,540
all graphical format

1584
01:49:12,560 --> 01:49:14,710
and many old formats from

1585
01:49:14,740 --> 01:49:16,360
text processing

1586
01:49:16,360 --> 01:49:19,160
it's RTM it it's

1587
01:49:19,660 --> 01:49:22,400
talk format

1588
01:49:22,420 --> 01:49:26,210
PDF is a good example of this format

1589
01:49:26,230 --> 01:49:27,620
you you need to

1590
01:49:27,630 --> 01:49:33,540
you need additional special rules to to extract the linear form of document

1591
01:49:37,810 --> 01:49:43,940
later people discover that for computer presentation we don't need to be connected to with

1592
01:49:44,850 --> 01:49:49,880
we can be connected but it is not mandatory more in their lives

1593
01:49:50,530 --> 01:49:55,890
and you're four months they usually structure and so they presented some structure of the

1594
01:49:55,900 --> 01:49:58,210
document and

1595
01:49:58,250 --> 01:50:03,730
as far as i know the first popular format this as jimmy wales and

1596
01:50:03,740 --> 01:50:06,360
and to those of the former fish them out

1597
01:50:06,390 --> 01:50:07,960
x amount

1598
01:50:07,990 --> 01:50:13,350
and in this form until you have some some structure of the document

1599
01:50:13,350 --> 01:50:14,760
and usually

1600
01:50:14,780 --> 01:50:19,080
is it to the linearisation extraction war from

1601
01:50:19,090 --> 01:50:25,440
specific field with specific attributes from structure are in

1602
01:50:26,760 --> 01:50:31,590
but there are such people as web designer

1603
01:50:31,590 --> 01:50:35,030
they don't like people who the information available

1604
01:50:35,060 --> 01:50:36,690
and therefore

1605
01:50:36,710 --> 01:50:42,750
in their life in a game against different examples of of all this stuff

1606
01:50:42,870 --> 01:50:44,870
OK so we extract

1607
01:50:44,910 --> 01:50:49,680
works and we need to present them in memory of a computer or maybe they

1608
01:50:49,730 --> 01:50:55,630
related represented in our document but we need to put it into our in the

1609
01:50:55,640 --> 01:50:56,900
and for

1610
01:50:56,920 --> 01:50:59,810
index first of all we want to present all

1611
01:50:59,830 --> 01:51:02,070
letters of the alphabet

1612
01:51:02,120 --> 01:51:05,210
what this for this particular collection

1613
01:51:05,240 --> 01:51:06,420
and then

1614
01:51:06,420 --> 01:51:12,090
of course it's possible situation that in the whole collection there i five

1615
01:51:12,100 --> 01:51:13,920
usage of

1616
01:51:13,950 --> 01:51:15,410
the word naive

1617
01:51:15,410 --> 01:51:20,180
that is the reason these i was double doors and it's not relevant for you

1618
01:51:20,180 --> 01:51:22,320
and you can replace it is

1619
01:51:22,340 --> 01:51:24,770
even is wonderful it is OK

1620
01:51:24,830 --> 01:51:28,830
but usually you want to keep all letters of the alphabet

1621
01:51:28,840 --> 01:51:32,850
but for many languages in

1622
01:51:32,900 --> 01:51:36,640
four for many human languages for on communism

1623
01:51:36,650 --> 01:51:41,060
people are doing something more and more complex and so

1624
01:51:41,240 --> 01:51:44,260
theoretically they invented this case

1625
01:51:44,310 --> 01:51:51,090
to make life of information retrieval developed simply because using case theoretically we can easily

1626
01:51:51,090 --> 01:51:54,410
extract the beginning of the sentences

1627
01:51:54,420 --> 01:51:59,510
and beginning of the named entities because this is the name of somebody from capital

1628
01:52:00,600 --> 01:52:03,560
but in real life first of all

1629
01:52:04,850 --> 01:52:07,080
i don't know why but they're putting

1630
01:52:07,090 --> 01:52:09,890
capital and lowercase but there a

1631
01:52:10,830 --> 01:52:15,630
therefore usually people doing information they will simply ignore this attribute for church

1632
01:52:15,650 --> 01:52:18,440
but for information extraction they usually use it

1633
01:52:21,220 --> 01:52:24,670
for some languages again from for non reason

1634
01:52:24,680 --> 01:52:26,490
they decided that

1635
01:52:26,500 --> 01:52:28,640
there is no such simple rules

1636
01:52:28,660 --> 01:52:33,450
that what can be in capital cases in case in this case in its input

1637
01:52:33,450 --> 01:52:36,760
to replace this character this character

1638
01:52:38,580 --> 01:52:40,090
thinking that it should be

1639
01:52:41,110 --> 01:52:42,950
complex kalai two

1640
01:52:42,970 --> 01:52:45,240
and this is correlation

1641
01:52:45,290 --> 01:52:47,420
and correlation rules is

1642
01:52:47,470 --> 01:52:50,390
such a german-language for example you that

1643
01:52:50,400 --> 01:52:53,790
all this to all this round of

1644
01:52:53,820 --> 01:52:56,710
a one

1645
01:52:56,730 --> 01:53:02,170
it's one one letter and can replacing the one we can replace all there is

1646
01:53:02,170 --> 01:53:04,440
for example small

1647
01:53:04,450 --> 01:53:06,900
for some languages it it became

1648
01:53:06,910 --> 01:53:08,000
a disaster

1649
01:53:08,030 --> 01:53:09,720
for example for a bit

1650
01:53:09,750 --> 01:53:11,920
language of this long string

1651
01:53:11,920 --> 01:53:14,400
and well

1652
01:53:14,400 --> 01:53:18,460
we train on network layout which actually like that

1653
01:53:18,470 --> 01:53:22,130
the network of all wikipedia during about four weeks

1654
01:53:22,150 --> 01:53:25,210
was an increase in detroit size

1655
01:53:25,210 --> 01:53:27,340
and a lot of things

1656
01:53:27,360 --> 01:53:29,110
and after four weeks

1657
01:53:29,130 --> 01:53:35,710
we took the buildings produced and we initialize the second which model that we train

1658
01:53:36,700 --> 01:53:39,230
well wikipedia plus white

1659
01:53:39,240 --> 01:53:43,760
and it was against sri additional weeks of training

1660
01:53:44,030 --> 01:53:46,210
so after all this time

1661
01:53:46,230 --> 01:53:47,690
we looked at

1662
01:53:47,730 --> 01:53:49,740
the walls buildings

1663
01:53:49,760 --> 01:53:54,970
and they look actually pretty great the networks into really touch automatically you know some

1664
01:53:54,970 --> 01:53:57,070
good semantic there

1665
01:53:57,090 --> 01:53:59,190
so we just like

1666
01:53:59,210 --> 01:54:00,960
dogs is one of the things

1667
01:54:00,990 --> 01:54:05,530
the initial list of networks for the task you know like

1668
01:54:05,550 --> 01:54:06,420
part of speech

1669
01:54:06,440 --> 01:54:08,670
drinking water during shown

1670
01:54:08,690 --> 01:54:12,590
some ontologies and just train as usual i was

1671
01:54:12,590 --> 01:54:15,970
just by initializing by semantics

1672
01:54:17,760 --> 01:54:30,550
it's just a domain

1673
01:54:30,630 --> 01:54:35,280
but by the time is not that expensive because it's basically like to talk to

1674
01:54:35,280 --> 01:54:38,070
match the computational small because

1675
01:54:38,110 --> 01:54:42,360
it's due to the is almost one billion of examples

1676
01:54:43,780 --> 01:54:52,050
you could actually polarise it's usual did some know try to colonize it but you

1677
01:54:52,050 --> 01:54:56,820
know we we didn't want to mess with basically it's just place to train on

1678
01:54:56,820 --> 01:54:58,240
one computer

1679
01:54:58,460 --> 01:55:05,300
we have time today the computer slightly faster than ten years ago

1680
01:55:08,740 --> 01:55:13,970
so here we applied this things like two

1681
01:55:13,990 --> 01:55:17,150
on natural language processing task of interest

1682
01:55:17,150 --> 01:55:20,740
and as you can see it flight for

1683
01:55:20,740 --> 01:55:24,300
for all the test was really like a huge boost

1684
01:55:24,380 --> 01:55:29,570
we have an additional boost mainly on animosity entity organisation for the second

1685
01:55:29,590 --> 01:55:32,730
i mean the larger language model

1686
01:55:32,740 --> 01:55:38,070
this is not really surprising because when we look at the world gradually

1687
01:55:38,090 --> 01:55:40,150
again a lot with the second

1688
01:55:40,150 --> 01:55:41,800
so the language model

1689
01:55:41,840 --> 01:55:44,690
we may want to challenge

1690
01:55:44,690 --> 01:55:47,070
so well

1691
01:55:47,090 --> 01:55:50,840
we thought is always what it was it would start

1692
01:55:51,470 --> 01:55:55,130
but still you know we've got to see the whole presentation which like seemed to

1693
01:55:55,130 --> 01:55:57,590
work pretty well on all tasks so now knowledge

1694
01:55:57,590 --> 01:56:03,340
you know the next question is why no training everything together and see what happens

1695
01:56:03,360 --> 01:56:05,460
so that's what we did

1696
01:56:06,470 --> 01:56:08,960
squadron during training which does came

1697
01:56:09,010 --> 01:56:14,030
it it has been used a lot of the networks and you can find a

1698
01:56:14,030 --> 01:56:19,550
good value for our networks in ritz-carlton disease in ninety seven

1699
01:56:19,570 --> 01:56:21,860
it's again quite

1700
01:56:21,880 --> 01:56:26,150
basically what we are doing here is that we are considering for example to task

1701
01:56:27,050 --> 01:56:30,860
we all the networks two thousand and

1702
01:56:30,880 --> 01:56:34,630
so these networks can receive you know different inputs they like

1703
01:56:34,650 --> 01:56:36,400
but the parliament house

1704
01:56:36,400 --> 01:56:38,150
going to be shown

1705
01:56:38,150 --> 01:56:41,260
that is the parliament of this look at the words are the same than parliament

1706
01:56:41,260 --> 01:56:42,690
of statistical because they

1707
01:56:42,710 --> 01:56:45,920
and the obama does of the first hidden layer are going to be the same

1708
01:56:45,920 --> 01:56:46,990
as well

1709
01:56:47,010 --> 01:56:51,990
the idea so that i also like to get you know independent but the first

1710
01:56:51,990 --> 01:56:54,240
they also reassured

1711
01:56:54,260 --> 01:56:55,460
so we trained

1712
01:56:56,730 --> 01:56:58,990
is based ranking on any alltogether

1713
01:56:59,010 --> 01:57:01,590
and we have a look at what it

1714
01:57:02,340 --> 01:57:04,050
what does that

1715
01:57:04,050 --> 01:57:08,820
and basically what it does is that it gives a kind of significant boost for

1716
01:57:09,820 --> 01:57:13,460
and linguists would tell you that it's not surprising because

1717
01:57:13,630 --> 01:57:17,760
part of speech is often used as a good future for change

1718
01:57:17,780 --> 01:57:24,470
the other that he doesn't change anything because

1719
01:57:27,190 --> 01:57:31,170
now we have like a quite reasonable results for all tasks

1720
01:57:31,190 --> 01:57:32,570
but it's

1721
01:57:32,590 --> 01:57:34,780
of course you know there is always like

1722
01:57:34,840 --> 01:57:36,190
the temptation

1723
01:57:41,360 --> 01:57:45,360
we can always do likewise of people you know try to see if you know

1724
01:57:45,360 --> 01:57:49,570
if we this part of speech into this drinking does it help the if we

1725
01:57:49,570 --> 01:57:55,820
put the change into the semantic labeling just how simply so that's what we did

1726
01:58:00,110 --> 01:58:03,900
we consider actually like stemming as

1727
01:58:03,900 --> 01:58:08,230
good future for part of speech it's of you know it's always is actually part

1728
01:58:08,230 --> 01:58:09,090
of speech

1729
01:58:10,860 --> 01:58:14,340
we use only like the talk of a tool as characters

1730
01:58:15,400 --> 01:58:18,280
each one has an additional feature

1731
01:58:18,300 --> 01:58:23,780
we try to actually to use three or you know prefixes if was also exist

1732
01:58:23,780 --> 01:58:25,730
but did

1733
01:58:25,740 --> 01:58:27,490
it's mainly like that

1734
01:58:27,490 --> 01:58:30,860
two characters which were important to let's go

1735
01:58:30,880 --> 01:58:36,860
we consider actually get it tells that is like a list of names it's kind

1736
01:58:36,860 --> 01:58:41,530
of cheating i think node could everybody does that so we consider that form they

1737
01:58:41,550 --> 01:58:43,300
wanted the organisation

1738
01:58:43,570 --> 01:58:53,280
and there there is like about its eight thousand locations specimen organisations given actually by

1739
01:58:53,280 --> 01:58:58,510
the core and the challenge itself so you know everybody else use this

1740
01:58:58,570 --> 01:59:01,230
they that's i mean some years

1741
01:59:01,240 --> 01:59:04,920
the idea that but we stick to this simple one

1742
01:59:05,490 --> 01:59:10,510
we also tried part of speech as a future for drinking on them onto your

1743
01:59:10,510 --> 01:59:17,060
and so maybe

1744
01:59:17,090 --> 01:59:20,970
i got myself and committed to giving this talk

1745
01:59:21,030 --> 01:59:23,800
he told you told me that it's always like this

1746
01:59:24,130 --> 01:59:30,710
most of you heard of guantanamo he did all the studies with mister ski on

1747
01:59:30,800 --> 01:59:33,650
indicating that people don't reason normative

1748
01:59:33,670 --> 01:59:37,330
he won the nobel prize in two thousand two for prospect theory

1749
01:59:38,050 --> 01:59:39,280
give talk

1750
01:59:39,810 --> 01:59:41,310
two years ago

1751
01:59:41,330 --> 01:59:44,780
and the title of the talk to people really happy here in california

1752
01:59:44,820 --> 01:59:47,280
because of the weather and

1753
01:59:47,450 --> 01:59:51,130
now by see the weather here i think might be true is great weather

1754
01:59:51,140 --> 01:59:54,180
the talk was

1755
01:59:54,200 --> 01:59:55,700
it was very similar to the

1756
01:59:55,710 --> 01:59:59,780
the stuff did and with the people reason rationally wanted to know if

1757
01:59:59,840 --> 02:00:05,980
if people's reported happiness was the consistent with the actual experience of happiness and of

1758
02:00:05,980 --> 02:00:08,950
course he found that wasn't the case for instance

1759
02:00:08,990 --> 02:00:15,010
this research showed that divorced women tend to actually be happier married when know they

1760
02:00:15,010 --> 02:00:17,400
reported that were not as happy

1761
02:00:17,560 --> 02:00:23,290
you can think about cancer research obviously installing because i hate giving powerpoint presentations the

1762
02:00:23,350 --> 02:00:25,480
on the second one

1763
02:00:25,540 --> 02:00:29,150
the first one band miserable even though i had a lot of

1764
02:00:29,180 --> 02:00:33,540
animation and voice and everything is just i don't like the medium but let's let's

1765
02:00:33,540 --> 02:00:35,460
see how it goes

1766
02:00:35,600 --> 02:00:42,570
there's talk is called statistical causality and that's me that's my website

1767
02:00:42,680 --> 02:00:47,090
i could be talking about quite a notion of causality

1768
02:00:47,130 --> 02:00:51,790
and it's the notion that developed and these texts and other places to i just

1769
02:00:51,840 --> 02:00:55,290
you know found some places that i know about

1770
02:00:55,310 --> 02:00:58,980
it concerns variables influencing other variables

1771
02:00:59,040 --> 02:01:03,620
and since the smoking causes lung cancer so what do we mean by variables influencing

1772
02:01:03,620 --> 02:01:04,680
other variables

1773
02:01:04,700 --> 02:01:07,400
yes in population in this case people

1774
02:01:07,400 --> 02:01:13,930
is a random variable the population smoking is another random variable lung cancer

1775
02:01:13,930 --> 02:01:14,870
the more

1776
02:01:14,870 --> 02:01:16,600
people tend to smoke

1777
02:01:16,620 --> 02:01:22,170
as you indicate the more they get lung cancer so the value of one variable

1778
02:01:22,230 --> 02:01:25,110
probabilistic effect on the value of another

1779
02:01:25,170 --> 02:01:29,830
right that's that's the kind of causality etc etc so probably lung cancer driven by

1780
02:01:31,540 --> 02:01:37,100
smokesa being you manipulate them to smoke greater than the probability that they do not

1781
02:01:37,170 --> 02:01:41,330
it does not concern token causality which has to do with one-time events we have

1782
02:01:41,330 --> 02:01:43,130
no population

1783
02:01:43,140 --> 02:01:46,800
a classic example is the the gopher running into my golf will cause it to

1784
02:01:46,800 --> 02:01:48,300
go in the hole

1785
02:01:48,320 --> 02:01:52,410
they we don't have any population there is one golfing and

1786
02:01:52,420 --> 02:01:56,760
you know by balls going this way conference into goes in the hole and walked

1787
02:01:56,760 --> 02:02:01,550
right but is that is that the causal for use on skull token causality and

1788
02:02:01,550 --> 02:02:07,130
that's not what i'm discussing discussing the first time

1789
02:02:07,190 --> 02:02:08,730
here's what matters

1790
02:02:09,720 --> 02:02:12,200
what i was talking about a minute ago about

1791
02:02:12,230 --> 02:02:15,570
what kind of personality this is an formalizes

1792
02:02:15,630 --> 02:02:19,500
it's a common way to to always learn causality even if we don't find it

1793
02:02:19,510 --> 02:02:21,050
this way

1794
02:02:21,100 --> 02:02:23,350
and manipulation experiments

1795
02:02:23,410 --> 02:02:27,820
drug manufacturers to this all the time you take

1796
02:02:27,860 --> 02:02:32,020
seven people you put have to them in one group and half in the other

1797
02:02:32,070 --> 02:02:34,350
that's the manipulation in other words

1798
02:02:34,420 --> 02:02:38,630
the probability of being manipulated to be in one group is point five probably be

1799
02:02:38,640 --> 02:02:41,770
manipulated to be in the other group is point five

1800
02:02:41,820 --> 02:02:44,980
so you've got this people broken up into two groups

1801
02:02:45,050 --> 02:02:47,190
everybody in group one

1802
02:02:47,200 --> 02:02:48,860
you make small

1803
02:02:48,910 --> 02:02:52,420
the probability smoking given you one is one

1804
02:02:52,440 --> 02:02:57,300
everybody here knows this notation conditional probability

1805
02:02:57,420 --> 02:03:01,980
it's the probability of this event given that this one takes the value

1806
02:03:02,800 --> 02:03:07,750
and the problem smoking given that smoking this with the two stands for example

1807
02:03:07,760 --> 02:03:11,330
giving your in group is zero so everyone everyone smokes

1808
02:03:11,350 --> 02:03:13,230
everyone in group two

1809
02:03:13,230 --> 02:03:15,510
it was not small

1810
02:03:17,630 --> 02:03:20,010
smoking causes lung cancer

1811
02:03:20,020 --> 02:03:21,170
group one

1812
02:03:21,170 --> 02:03:25,010
we have a higher incidence of lung cancer in group two

1813
02:03:25,040 --> 02:03:27,240
and the more that's true

1814
02:03:27,250 --> 02:03:30,270
the greater the extent to which group one has

1815
02:03:30,370 --> 02:03:34,260
and this the incidence of lung cancer the more we believe smoking causes

1816
02:03:34,270 --> 02:03:35,830
one can search

1817
02:03:35,860 --> 02:03:41,550
so that's classically learning causation and that's how drug companies do it all the time

1818
02:03:41,550 --> 02:03:44,430
they want to see if the drug is across the

1819
02:03:44,470 --> 02:03:49,010
and some cure and they do manipulation experiment

1820
02:03:49,030 --> 02:03:52,120
i know we don't really want to manipulate people and make them smoke i mean

1821
02:03:52,120 --> 02:03:52,820
there's a certain

1822
02:03:53,270 --> 02:03:56,250
kinds of experiments you really don't want to do

1823
02:03:56,300 --> 02:04:02,200
especially in this country trying to eliminate smoking almost no no i can't smoke anywhere

1824
02:04:02,200 --> 02:04:04,640
starting january first

1825
02:04:04,650 --> 02:04:06,110
virtually no

1826
02:04:06,120 --> 02:04:11,330
so can we learn something about causal influences from passive data some people have other

1827
02:04:11,330 --> 02:04:13,890
words for the i passive data means

1828
02:04:13,930 --> 02:04:17,450
data you just mine data that you don't

1829
02:04:17,520 --> 02:04:20,820
purposely created in anyway

1830
02:04:20,830 --> 02:04:23,630
also smoking example again

1831
02:04:23,750 --> 02:04:25,320
from passive data

1832
02:04:25,360 --> 02:04:29,710
we've learned that smoking and lung cancer are correlated

1833
02:04:31,050 --> 02:04:36,020
and that's the zero here this line here means correlation

1834
02:04:36,030 --> 02:04:39,640
now that could be due to smoking causes lung cancer

1835
02:04:39,700 --> 02:04:44,440
right so much smoking causes lung cancer like i just said they would be correlated

1836
02:04:44,490 --> 02:04:46,650
so from this data

1837
02:04:46,720 --> 02:04:50,750
i want to conclude that smoking causes lung cancer

1838
02:04:52,370 --> 02:04:57,490
is smoking and lung cancer correlated it could be the reverse

1839
02:04:57,510 --> 02:05:01,150
people go along cancer that kind pick of smoking

1840
02:05:01,180 --> 02:05:04,990
because of the domain that seems so all right that this was just x and

1841
02:05:05,640 --> 02:05:07,780
what seems so slowly

1842
02:05:07,800 --> 02:05:12,470
i don't know of one case of is actually from the man and woman who

1843
02:05:12,510 --> 02:05:17,250
have one cancer and quit smoking but then she found out she was terminal

1844
02:05:17,300 --> 02:05:21,650
which is an amazing out smoking and so in her case the

1845
02:05:21,740 --> 02:05:26,220
she really care no advanced lung cancer she started smoking so in that case it

1846
02:05:26,240 --> 02:05:30,490
can actually cause the a small token almost all

1847
02:05:30,500 --> 02:05:33,440
but the point is that this is just the x and y from the correlation

1848
02:05:34,470 --> 02:05:39,090
smoking causes lung cancer lung cancer smoking we don't know

1849
02:05:39,110 --> 02:05:44,510
and the other common explanation is that could have a hidden common cause

1850
02:05:45,550 --> 02:05:51,570
the understanding of why this would correlate smoking and lung cancer is essential to understanding

1851
02:05:51,570 --> 02:05:53,010
this talk

1852
02:05:53,070 --> 02:05:57,640
if two events have a hidden common cause they tend to be correlated

1853
02:05:57,720 --> 02:06:00,830
why is that because if you smoke

1854
02:06:00,890 --> 02:06:05,340
it makes it more probable you have this causes which makes it more probably would

1855
02:06:05,340 --> 02:06:07,070
also have one cancer

1856
02:06:07,120 --> 02:06:11,410
so there might be correlated through this through this change


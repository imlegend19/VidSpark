1
00:00:00,000 --> 00:00:04,840
the different and discount factor is a side effect

2
00:00:05,000 --> 00:00:06,680
that's a

3
00:00:06,720 --> 00:00:08,800
it in effect is not the goal

4
00:00:08,830 --> 00:00:12,390
the goal is to be able to express knowledge

5
00:00:12,410 --> 00:00:16,060
of actions that these very different time scales

6
00:00:16,090 --> 00:00:17,410
that's the goal

7
00:00:17,410 --> 00:00:24,310
because it allows us to then planned more efficiently and that few medical reason where

8
00:00:24,770 --> 00:00:30,240
by planning can be out converge faster is that we in fact get

9
00:00:30,260 --> 00:00:31,960
people look ahead

10
00:00:31,970 --> 00:00:33,810
is one way of saying it

11
00:00:33,830 --> 00:00:36,630
saying it is we get a bigger discount

12
00:00:36,650 --> 00:00:39,720
because this kind of the point where we can always discount

13
00:00:39,730 --> 00:00:41,170
more mean s

14
00:00:41,180 --> 00:00:44,670
this county on the goal is in effect

15
00:00:44,690 --> 00:00:48,120
i hope i answered that i hope that made sense that makes sense

16
00:00:49,700 --> 00:00:51,460
you can ask the question you have to be

17
00:00:51,480 --> 00:00:53,210
you have to accept the answer can

18
00:00:53,210 --> 00:00:55,160
you can challenge and

19
00:01:07,770 --> 00:01:14,710
he said there is that the main difference is actually the a one to

20
00:01:14,730 --> 00:01:18,580
that's that's the critical difference the effect of

21
00:01:18,590 --> 00:01:20,730
is a big attraction

22
00:01:20,740 --> 00:01:22,910
but i think that was

23
00:01:22,910 --> 00:01:28,970
one want is the ability to represent actually different time scales

24
00:01:29,000 --> 00:01:32,460
have yes i do believe that

25
00:01:32,470 --> 00:01:34,240
so we should do

26
00:01:34,260 --> 00:01:36,730
you understand the reason is not

27
00:01:39,140 --> 00:01:41,320
you are

28
00:01:43,730 --> 00:01:47,700
max q is always interesting

29
00:01:47,700 --> 00:01:49,390
structure and extraction

30
00:01:49,880 --> 00:01:56,310
you start with your comments about that we want to talk about that here so

31
00:01:56,310 --> 00:02:02,710
you can also ask you must skeptical of here is different from

32
00:02:02,730 --> 00:02:07,220
a different perspective this landscape hierarchies is is that

33
00:02:07,250 --> 00:02:09,460
it's a very anthropomorphic way

34
00:02:09,470 --> 00:02:13,500
or language use

35
00:02:13,510 --> 00:02:14,480
so we think

36
00:02:15,170 --> 00:02:18,780
if the was we have

37
00:02:18,790 --> 00:02:27,060
like the country to see i have yet to see any reason to need

38
00:02:27,070 --> 00:02:29,580
very little promotion yes

39
00:02:29,630 --> 00:02:31,320
that is

40
00:02:31,340 --> 00:02:34,400
so profound was

41
00:02:34,410 --> 00:02:37,280
all is if

42
00:02:37,330 --> 00:02:38,780
the intuition that

43
00:02:38,800 --> 00:02:43,270
we just to quickly apparent is really asking

44
00:02:45,260 --> 00:02:47,390
one of my

45
00:02:47,400 --> 00:02:53,930
nine OK i don't spend enough come back you so only a few minutes left

46
00:02:54,120 --> 00:02:58,610
a do

47
00:02:58,660 --> 00:03:01,660
is to see an example

48
00:03:01,710 --> 00:03:02,760
with that

49
00:03:04,180 --> 00:03:06,990
the goal of holistic education now

50
00:03:07,020 --> 00:03:10,410
he goes on holiday to the state of the

51
00:03:12,820 --> 00:03:16,140
so what happens often and preventive actions

52
00:03:16,870 --> 00:03:25,200
the evaluation first people that intuition this now hold a state

53
00:03:25,220 --> 00:03:28,020
i always say that you know

54
00:03:28,040 --> 00:03:34,420
i you can you get by with so it's not constraint has caused a lot

55
00:03:34,440 --> 00:03:35,110
of people

56
00:03:35,110 --> 00:03:39,380
the target state one of goals the options yes

57
00:03:45,550 --> 00:03:48,860
OK very

58
00:03:48,860 --> 00:03:52,670
very much so i should say this

59
00:03:52,690 --> 00:03:55,580
this is sufficient so

60
00:03:56,000 --> 00:03:59,450
if we plan

61
00:04:00,970 --> 00:04:05,930
with both primitive actions and options and the choice is based on the value of

62
00:04:05,930 --> 00:04:10,660
the change because of the actions which is

63
00:04:12,220 --> 00:04:17,200
if we plan only after the total weight of the actions

64
00:04:19,270 --> 00:04:21,230
it depends on how much how

65
00:04:21,240 --> 00:04:24,440
what range of choices the option

66
00:04:24,440 --> 00:04:26,150
make of it

67
00:04:26,170 --> 00:04:28,370
right so

68
00:04:28,390 --> 00:04:33,220
so if you keep the action choice assessed

69
00:04:33,230 --> 00:04:40,920
the expanded accidental by adding options then of course that policies

70
00:04:41,040 --> 00:04:45,780
we can probably not be able to find the space the on policy in the

71
00:04:45,780 --> 00:04:48,660
space of four by just

72
00:04:53,390 --> 00:04:56,090
i think it's a hoax was a hoax

73
00:04:56,120 --> 00:05:00,460
is that i've been talking about optimal control have been talking about what you get

74
00:05:01,910 --> 00:05:03,320
first course

75
00:05:03,340 --> 00:05:05,030
that's just a prince

76
00:05:05,050 --> 00:05:09,730
it's not really expected it is that the behaviour of

77
00:05:09,750 --> 00:05:11,720
that's the principle

78
00:05:11,720 --> 00:05:17,240
i call it common misconception reinforcement learning is in his house

79
00:05:17,260 --> 00:05:20,400
some people dismiss people

80
00:05:20,400 --> 00:05:23,080
this firm by conjugate prior

81
00:05:23,800 --> 00:05:27,160
but i'm assuming exponential families

82
00:05:27,960 --> 00:05:29,600
so you could do all this

83
00:05:29,610 --> 00:05:33,100
without the exponential families that's fine

84
00:05:34,020 --> 00:05:37,680
but the thing is as soon as you go to some linear function class

85
00:05:37,720 --> 00:05:41,240
in the exponent of four you hammersley clifford theorem

86
00:05:42,350 --> 00:05:46,470
well this is actually this exponential family notation is a very convenient way of writing

87
00:05:48,490 --> 00:05:53,520
but of course you can play with this norm

88
00:05:53,650 --> 00:05:55,010
so i mean

89
00:05:55,050 --> 00:05:59,030
there are lots of ways how to generalize this to make it much more complicated

90
00:05:59,040 --> 00:06:01,870
just trying to convey the simple case

91
00:06:01,960 --> 00:06:03,860
and it's very easy to

92
00:06:03,880 --> 00:06:10,080
make it more general more complicated and fill up the slide the equations but

93
00:06:13,050 --> 00:06:14,010
all right

94
00:06:17,670 --> 00:06:18,580
to recap

95
00:06:18,590 --> 00:06:23,070
this in the product between of x and y so you explain it to you

96
00:06:23,090 --> 00:06:25,720
for the y and y plus one

97
00:06:25,780 --> 00:06:27,120
and well

98
00:06:27,140 --> 00:06:29,240
similar expression here

99
00:06:29,440 --> 00:06:34,360
we want to compute in approach between a given four x y x t y

100
00:06:35,370 --> 00:06:37,690
and the expectation

101
00:06:40,740 --> 00:06:42,330
then this is just

102
00:06:42,340 --> 00:06:45,940
the expectation here over the kernel function

103
00:06:45,990 --> 00:06:48,260
given x

104
00:06:48,270 --> 00:06:54,670
and expectation go like t

105
00:06:54,690 --> 00:06:57,450
so that's why we can get away with

106
00:06:57,460 --> 00:07:04,560
a rather simple terms even though the overall expression might look a little bit daunting

107
00:07:04,580 --> 00:07:07,920
it was

108
00:07:08,180 --> 00:07:10,470
one line

109
00:07:13,130 --> 00:07:14,820
is that he

110
00:07:15,900 --> 00:07:19,610
x y yes

111
00:07:19,620 --> 00:07:22,980
and the subscript x y min

112
00:07:29,990 --> 00:07:31,410
this one

113
00:07:34,410 --> 00:07:40,130
no that shouldn't be subscript that's just the joint feature map

114
00:07:40,250 --> 00:07:41,100
but then

115
00:07:41,120 --> 00:07:41,990
if i look

116
00:07:42,000 --> 00:07:46,310
into that specific model that had on the previous slide

117
00:07:46,330 --> 00:07:49,380
let's go back one more

118
00:07:49,430 --> 00:07:51,230
to that model

119
00:07:51,280 --> 00:07:52,350
we had

120
00:07:52,360 --> 00:07:53,700
phi x y

121
00:07:53,700 --> 00:07:57,770
and phi y phi x six but just picked up on that very same notation

122
00:08:02,010 --> 00:08:06,170
i mean to be more specific my father x and y

123
00:08:06,180 --> 00:08:08,180
it looks as

124
00:08:15,850 --> 00:08:16,820
so this

125
00:08:16,840 --> 00:08:18,400
one big long vector

126
00:08:18,400 --> 00:08:19,680
of phi

127
00:08:19,690 --> 00:08:22,110
x y

128
00:08:22,130 --> 00:08:24,200
of x i

129
00:08:24,200 --> 00:08:26,600
while i

130
00:08:27,860 --> 00:08:29,460
x y

131
00:08:29,500 --> 00:08:32,290
x plus one

132
00:08:32,320 --> 00:08:35,720
why i plus one

133
00:08:35,720 --> 00:08:39,410
after the end of the sequence and then we have some more terms

134
00:08:41,100 --> 00:08:43,810
why why

135
00:08:44,910 --> 00:08:46,690
why i

136
00:08:46,710 --> 00:08:48,670
why i plus one

137
00:08:48,860 --> 00:08:51,680
and then we have

138
00:08:52,880 --> 00:08:54,560
one why

139
00:08:54,570 --> 00:08:56,940
of y r plus one

140
00:08:57,030 --> 00:09:00,210
why are plus two

141
00:09:00,210 --> 00:09:04,430
and so on and so on

142
00:09:04,450 --> 00:09:07,800
and if they want to compute the conditional expectation

143
00:09:07,820 --> 00:09:10,870
of the big east here

144
00:09:10,880 --> 00:09:13,050
then i can do that

145
00:09:15,780 --> 00:09:19,430
now componentwise the problem is actually easy

146
00:09:19,470 --> 00:09:23,130
it is this component only depends on the y i love this one

147
00:09:23,340 --> 00:09:25,380
this one only depends on the well

148
00:09:25,410 --> 00:09:28,400
so only need the marginal probabilities

149
00:09:28,410 --> 00:09:30,900
even though the overall expression here

150
00:09:30,940 --> 00:09:34,060
involves the entire sequence

151
00:09:34,080 --> 00:09:39,210
so that means that i'm bringing the computation down from something that could be exponential

152
00:09:39,280 --> 00:09:41,300
this is an exponential number of flies

153
00:09:41,490 --> 00:09:48,000
something to fling it

154
00:09:48,010 --> 00:09:49,810
does that answer question

155
00:09:59,350 --> 00:10:00,460
and now

156
00:10:00,470 --> 00:10:01,340
we get

157
00:10:01,360 --> 00:10:03,560
the subspace representer theorem

158
00:10:03,760 --> 00:10:07,770
and the subspaces the representer theorem is the

159
00:10:07,830 --> 00:10:09,690
expansion equivalent

160
00:10:09,690 --> 00:10:13,640
i'm not going to touch those but i was emphasizing that

161
00:10:13,690 --> 00:10:15,200
that it's there

162
00:10:18,060 --> 00:10:24,320
that's moving is there and and actually i have

163
00:10:24,350 --> 00:10:25,450
well i have us

164
00:10:25,460 --> 00:10:28,910
the problem too

165
00:10:29,260 --> 00:10:32,040
about maybe i'll mention this about smoothing

166
00:10:32,060 --> 00:10:34,210
the only been mentioned

167
00:10:35,530 --> 00:10:37,350
can i say this about smoothing

168
00:10:37,360 --> 00:10:38,470
which is

169
00:10:38,520 --> 00:10:42,110
and then i'll come back to the heart of the subject which is here

170
00:10:42,120 --> 00:10:44,020
so smoothing involves also

171
00:10:44,040 --> 00:10:45,980
you know going back up

172
00:10:46,000 --> 00:10:50,530
and probably most people don't have to pay a lot of attention to it

173
00:10:51,280 --> 00:10:52,770
so i get

174
00:10:54,550 --> 00:10:57,660
things about problems in matrices

175
00:10:57,670 --> 00:10:58,920
often from the

176
00:10:58,930 --> 00:11:03,110
from sort of area of people who work in linear algebra

177
00:11:03,130 --> 00:11:05,160
well the problem appeared

178
00:11:05,730 --> 00:11:10,270
that i'll stay here and i'll put it on into the lecture notes

179
00:11:10,280 --> 00:11:11,250
for this

180
00:11:12,710 --> 00:11:17,320
and the right away offer prize for solution

181
00:11:17,340 --> 00:11:20,160
because when i saw the problem

182
00:11:20,200 --> 00:11:23,150
so was put in by a friend of mine from berkeley

183
00:11:24,810 --> 00:11:27,200
i don't know where he came up with it

184
00:11:27,210 --> 00:11:32,450
but i realize it's gotta be intimately connected to the kalman filter

185
00:11:32,490 --> 00:11:33,690
OK i thought

186
00:11:33,730 --> 00:11:39,090
well these guys the readers of this this journal or like experts in in linear

187
00:11:39,090 --> 00:11:41,510
algebra they'll solve this problem

188
00:11:41,520 --> 00:11:42,620
twenty ways

189
00:11:42,620 --> 00:11:44,770
but that didn't happen

190
00:11:44,840 --> 00:11:48,460
the problem one month after month unsolved until

191
00:11:48,630 --> 00:11:52,690
the idea that the copy i have here of the problem

192
00:11:52,690 --> 00:11:56,090
it is said would somebody please send an answer

193
00:11:56,630 --> 00:12:04,820
and for me that was so striking a an example

194
00:12:04,880 --> 00:12:05,720
in real

195
00:12:05,760 --> 00:12:10,810
time so to speak of the of the

196
00:12:10,820 --> 00:12:18,420
cut the the separation between so much of linear algebra and what we're doing here

197
00:12:20,220 --> 00:12:25,850
course it's not totally separated the people in numerical linear algebra no efficient ways to

198
00:12:25,850 --> 00:12:29,350
do this and let me remark

199
00:12:29,410 --> 00:12:31,150
well on one

200
00:12:31,310 --> 00:12:33,370
he's general comments

201
00:12:33,380 --> 00:12:35,100
that as always

202
00:12:35,110 --> 00:12:38,680
we have a choice with this system what's our choice here

203
00:12:38,700 --> 00:12:41,360
and how to solve that system

204
00:12:41,420 --> 00:12:45,640
we have a choice of solving it by elimination

205
00:12:45,690 --> 00:12:46,870
or by

206
00:12:46,900 --> 00:12:49,670
you are my orthogonalisation

207
00:12:49,710 --> 00:12:51,960
you know if you remember that choice

208
00:12:52,010 --> 00:12:56,930
and that choice in this world is called this is the square root filters

209
00:12:57,660 --> 00:13:00,210
this is a here we got a square

210
00:13:00,220 --> 00:13:06,370
so the formulas i'm writing down are the classical formulas that involve

211
00:13:06,440 --> 00:13:09,280
things about eight times a day

212
00:13:09,300 --> 00:13:15,950
but for super stability and sometimes for speed or sometimes you lose speed

213
00:13:16,610 --> 00:13:22,280
those are those are the crucial issues probably gain little stability and lose a little

214
00:13:22,280 --> 00:13:25,660
speed if you change this

215
00:13:25,670 --> 00:13:26,680
if if you

216
00:13:27,710 --> 00:13:29,590
express a

217
00:13:29,590 --> 00:13:32,800
i'm just going to put it up here do nothing with it

218
00:13:32,820 --> 00:13:35,140
a as hugh

219
00:13:36,500 --> 00:13:40,180
and of course you to compute q are recursively

220
00:13:41,610 --> 00:13:44,120
new rows are added to a

221
00:13:44,670 --> 00:13:47,130
new things are computed here

222
00:13:47,190 --> 00:13:54,390
so this would be this would this would give the square root filters

223
00:13:55,230 --> 00:13:58,970
it was like a bombshell in in the commons

224
00:13:58,980 --> 00:14:00,430
common world

225
00:14:00,460 --> 00:14:02,450
as an alternative

226
00:14:02,450 --> 00:14:04,940
and i'm not the

227
00:14:04,950 --> 00:14:06,750
it at all

228
00:14:07,810 --> 00:14:10,500
able to report on

229
00:14:10,630 --> 00:14:13,150
the current state of that battle

230
00:14:13,160 --> 00:14:14,960
now i was going to

231
00:14:14,980 --> 00:14:16,200
i tell you this

232
00:14:18,190 --> 00:14:21,090
so this is this is the problem

233
00:14:22,370 --> 00:14:27,380
so i have a try diagonal matrix

234
00:14:27,400 --> 00:14:31,060
i tried a google matrix let me what what can i call it here t

235
00:14:31,060 --> 00:14:34,040
four try diag

236
00:14:36,710 --> 00:14:38,090
and it

237
00:14:38,110 --> 00:14:40,270
factors into

238
00:14:43,940 --> 00:14:46,430
yes a lower

239
00:14:46,440 --> 00:14:51,140
the usual lower lower with ones on the diagonal

240
00:14:51,190 --> 00:14:56,240
pavements and upper and one of the what's the information about the we have about

241
00:14:57,220 --> 00:15:00,950
l has to die this has three diagonal

242
00:15:01,000 --> 00:15:02,920
l has two diagonals

243
00:15:02,920 --> 00:15:05,980
he has diagonal you has

244
00:15:06,050 --> 00:15:10,100
dial above and i'm not going to assume in this problem that the matrix is

245
00:15:10,100 --> 00:15:11,960
symmetric positive definite

246
00:15:11,980 --> 00:15:13,900
just try diagonals all

247
00:15:13,900 --> 00:15:16,790
there's no all for all objects z

248
00:15:16,830 --> 00:15:20,880
the robot is an holdings in that situation so that first feature since the robot

249
00:15:22,090 --> 00:15:24,180
find the robot

250
00:15:24,380 --> 00:15:28,010
and the object x is not heavy

251
00:15:28,020 --> 00:15:29,650
and the robot is next to

252
00:15:29,690 --> 00:15:33,090
the object so i can sort of

253
00:15:33,190 --> 00:15:36,570
so that's the preconditioned action rama can pick the thing up

254
00:15:36,610 --> 00:15:39,370
if it's not holding anything if things that to

255
00:15:39,380 --> 00:15:42,330
and it's next to it

256
00:15:42,350 --> 00:15:47,500
now all the terms he like for instance you see are SSL not qualified they

257
00:15:47,500 --> 00:15:53,180
implicitly universally quantified but since there was implicitly all implicitly universally quantified we drop the

258
00:15:54,920 --> 00:15:57,480
so this is this is true for all this

259
00:15:57,480 --> 00:16:00,960
it's true for all that for all x

260
00:16:01,060 --> 00:16:04,480
OK now let's look at what the actions do normally we distinguish two types of

261
00:16:04,480 --> 00:16:06,260
fixed positive effects

262
00:16:06,330 --> 00:16:07,560
the negative effects

263
00:16:07,680 --> 00:16:11,040
like the lecture from from the fact that

264
00:16:11,330 --> 00:16:14,670
OK so the first one says is the positive effect and it says that if

265
00:16:14,670 --> 00:16:16,050
x is fragile

266
00:16:16,120 --> 00:16:20,110
then it's going to be broken after the robot drops

267
00:16:20,250 --> 00:16:25,850
and negative effects might be that well it becomes not broken if the robot does

268
00:16:25,850 --> 00:16:28,440
the repair action on the object

269
00:16:28,620 --> 00:16:39,390
you perfect so their preconditions for the repair action and maybe you can only do

270
00:16:39,390 --> 00:16:43,260
it if if it's not broken you might want to do that probably would want

271
00:16:43,260 --> 00:16:46,000
to do that but in some cases you might just learn do it and no

272
00:16:46,010 --> 00:16:48,630
change in the state situation

273
00:16:48,690 --> 00:16:52,560
that's that's a really good question

274
00:16:52,580 --> 00:16:55,510
other domain constraints cetera we're not really going to talk to much about the main

275
00:16:55,510 --> 00:16:58,290
constraints but let's look at some possibilities

276
00:16:58,330 --> 00:17:01,860
so the first one in blue this is excess on the table if and only

277
00:17:01,860 --> 00:17:03,480
if it's notable

278
00:17:03,540 --> 00:17:07,230
so the main constraints religious put some restrictions on the domain usually they make the

279
00:17:07,230 --> 00:17:08,750
reasoning a little bit easier

280
00:17:08,830 --> 00:17:13,250
in the situation calculus usually don't have domain constraints

281
00:17:13,260 --> 00:17:16,270
i just put it there because in a lot in some of the formalism you

282
00:17:16,270 --> 00:17:19,010
do have these constraints

283
00:17:19,110 --> 00:17:25,070
uh huh

284
00:17:27,180 --> 00:17:30,800
now the idea here is going to be the following

285
00:17:30,810 --> 00:17:33,370
what we're going to do is we're going to take all this stuff so we're

286
00:17:33,370 --> 00:17:34,540
going to take

287
00:17:34,560 --> 00:17:38,100
the axioms that say something about what's true

288
00:17:38,150 --> 00:17:39,980
initially it is zero

289
00:17:40,020 --> 00:17:42,110
this is called series stuff

290
00:17:42,130 --> 00:17:44,140
plus we're going to

291
00:17:44,150 --> 00:17:47,430
the prospect seems to say what's possible

292
00:17:47,440 --> 00:17:51,810
plus we're gonna the effect that seems both negative and positive

293
00:17:54,890 --> 00:17:58,050
hopefully that will allow us to answer the question

294
00:17:58,090 --> 00:18:01,280
you know is some flaw f

295
00:18:11,010 --> 00:18:13,490
so there is some flaw if true

296
00:18:13,510 --> 00:18:16,470
at the the situation

297
00:18:27,380 --> 00:18:31,170
OK so basically when we read this from right to left we're going to do

298
00:18:31,170 --> 00:18:34,190
a one and a two three four all the way to you

299
00:18:34,300 --> 00:18:37,930
and what i want to be able to reason about is whether some properties true

300
00:18:38,020 --> 00:18:40,210
after i do all these actions

301
00:18:40,230 --> 00:18:42,530
and obviously if i do that for all of the ones that i have i

302
00:18:42,530 --> 00:18:45,560
can work at exactly what's true in this

303
00:18:45,580 --> 00:18:49,670
now the question is well if i just take my initially

304
00:18:49,720 --> 00:18:52,020
my position the state initially

305
00:18:52,070 --> 00:18:53,680
if i take the

306
00:18:55,090 --> 00:18:56,740
the facts about my

307
00:18:56,740 --> 00:18:58,160
actions so

308
00:18:58,190 --> 00:19:00,210
the preconditions

309
00:19:00,210 --> 00:19:01,820
and their effects

310
00:19:01,870 --> 00:19:04,860
at the beginning of the lecture we sort of agree that was enough

311
00:19:04,910 --> 00:19:08,470
so now i should have enough enough material

312
00:19:08,510 --> 00:19:12,230
to be able to answer this question whether it's true or false

313
00:19:14,570 --> 00:19:18,030
so one happy so that

314
00:19:18,100 --> 00:19:20,310
just look at the end

315
00:19:20,620 --> 00:19:23,390
i can now

316
00:19:23,420 --> 00:19:25,930
then we come up to this now going to come to the sort of point

317
00:19:25,970 --> 00:19:29,010
i want to try and make which is about this thing called the frame problem

318
00:19:29,010 --> 00:19:30,060
many of

319
00:19:30,070 --> 00:19:32,500
that particular if you don't

320
00:19:32,780 --> 00:19:36,860
any i sort of classes

321
00:19:36,920 --> 00:19:39,570
all the things that we've described so far

322
00:19:39,590 --> 00:19:41,600
in the initial state the

323
00:19:41,620 --> 00:19:43,330
preconditions effects

324
00:19:43,330 --> 00:19:47,840
all they do is they describe what changes they tell us when actions can be

325
00:19:47,840 --> 00:19:50,550
applied and they tell us what those actions do

326
00:19:50,590 --> 00:19:53,960
so they tell us about the things that change

327
00:19:54,000 --> 00:19:57,590
what they don't tell us anything about is the things that don't change

328
00:19:57,620 --> 00:20:00,120
and you would think that that's right

329
00:20:00,130 --> 00:20:02,770
i don't have to write stuff dan about what doesn't change i just want to

330
00:20:02,770 --> 00:20:03,870
have to write

331
00:20:03,880 --> 00:20:07,480
down stuff about things change

332
00:20:07,510 --> 00:20:13,160
and the problem is that if we don't say anything about what doesn't change

333
00:20:13,180 --> 00:20:16,250
then we can reason about

334
00:20:16,280 --> 00:20:18,460
so he is one example

335
00:20:18,560 --> 00:20:20,470
going to come down to the colours

336
00:20:20,530 --> 00:20:22,170
suppose i have

337
00:20:22,660 --> 00:20:23,810
cold colours

338
00:20:23,810 --> 00:20:28,000
and it tells me that the color of an object x is c

339
00:20:28,010 --> 00:20:31,690
so this might be a y block for instance

340
00:20:31,710 --> 00:20:35,210
in situation s

341
00:20:35,290 --> 00:20:40,040
if i picked this subject up

342
00:20:40,050 --> 00:20:44,000
well if we go back a couple of slides

343
00:20:44,050 --> 00:20:49,150
and we have a look at the african i this precondition

344
00:20:49,210 --> 00:20:50,560
four pickups

345
00:20:50,640 --> 00:20:52,680
so it tells me that i can pick it up got nothing to do with

346
00:20:52,680 --> 00:20:53,520
the color

347
00:20:53,690 --> 00:20:59,440
and presumably also the effect of picking up means that is now in my hand

348
00:20:59,440 --> 00:21:01,020
these antibiotics

349
00:21:01,030 --> 00:21:02,610
how close

350
00:21:04,940 --> 00:21:10,780
relate to those nature they what you will find that the index and the approximation

351
00:21:10,810 --> 00:21:12,390
OK then you can grab some

352
00:21:12,410 --> 00:21:15,260
something from nature then you try to

353
00:21:15,280 --> 00:21:19,980
to train and in some way you probably can find new antibiotics because that's the

354
00:21:20,810 --> 00:21:24,540
but the trick is what he wants is the search

355
00:21:24,570 --> 00:21:29,290
so this one is a huge nature in some kind of a german

356
00:21:29,390 --> 00:21:36,270
they want to find this antibiotics whether it contains something very similar structure in nature

357
00:21:36,350 --> 00:21:39,520
that's what they what they say they want search rather my

358
00:21:39,560 --> 00:21:43,130
but search everybody knows search

359
00:21:43,140 --> 00:21:47,200
you probably want to have index just thinking about will go if if you google

360
00:21:47,320 --> 00:21:50,450
no index how do search the web there's no way you can search the web

361
00:21:50,640 --> 00:21:55,660
google using indexes in ranking so index is the most important thing for anything to

362
00:21:55,660 --> 00:21:56,860
search large

363
00:21:57,540 --> 00:22:00,830
but if we think about this the

364
00:22:00,880 --> 00:22:03,870
graphs how to search the graph database

365
00:22:03,880 --> 00:22:08,120
OK even this one is not mining your findings very charming

366
00:22:08,130 --> 00:22:10,520
the reason is the structure

367
00:22:10,530 --> 00:22:15,980
you need of course you may have the subgraph isomorphism test which is NP hard

368
00:22:15,990 --> 00:22:21,990
cases but the the major bad news is that it is so huge graph could

369
00:22:21,990 --> 00:22:22,880
be big

370
00:22:22,890 --> 00:22:28,290
and you go there you fetch everyone do this i some testing is not

371
00:22:28,310 --> 00:22:30,990
it's not really working because it's so slow

372
00:22:30,990 --> 00:22:38,050
so the important thing is indexed there are a few indexing structure available because even

373
00:22:38,060 --> 00:22:43,960
here yesterday mention about this they like to stay light the graphs graph was done

374
00:22:43,960 --> 00:22:46,780
by dennis shasha publishing parts

375
00:22:46,800 --> 00:22:48,110
and there are several

376
00:22:48,140 --> 00:22:53,390
things but the interesting thing is all these once they are not really using graph

377
00:22:53,410 --> 00:22:57,280
the sea they do graph indexing they're using packs

378
00:22:57,290 --> 00:23:02,320
using the longest pass to the index of course why they don't use graph you

379
00:23:02,320 --> 00:23:07,710
pretend to stand because the possibly enumeration of the subgraph easy explanation OK you can

380
00:23:07,710 --> 00:23:10,670
not index explanation search space

381
00:23:10,670 --> 00:23:13,590
OK that's the reason they use class

382
00:23:13,610 --> 00:23:15,740
now we think about

383
00:23:15,780 --> 00:23:16,940
for the

384
00:23:16,960 --> 00:23:22,550
for the query graph the whole process to try to find similar structures this eugenia

385
00:23:22,620 --> 00:23:23,880
query graph

386
00:23:23,940 --> 00:23:25,310
this is my

387
00:23:26,530 --> 00:23:29,330
chemical compounds i go to the nature

388
00:23:29,340 --> 00:23:32,910
i want to find something similar of course not exactly the whole thing

389
00:23:32,980 --> 00:23:36,520
is you find the subset we say the subgraph

390
00:23:36,530 --> 00:23:40,700
you want to find this one compaign this up somehow get

391
00:23:40,860 --> 00:23:42,670
OK so

392
00:23:42,680 --> 00:23:46,020
you need to construct index if you have index on this one

393
00:23:46,030 --> 00:23:51,360
you probably OK but the problem is how many such subgraphs you get if you

394
00:23:51,360 --> 00:23:55,280
get a big graph this one union one of them is exponential

395
00:23:55,380 --> 00:24:00,070
so if we think about the whole search space

396
00:24:00,090 --> 00:24:01,170
we were saying

397
00:24:01,170 --> 00:24:06,260
first we can swap index on the structures that then we do query processing we

398
00:24:06,260 --> 00:24:08,960
take this structure we enumerate

399
00:24:09,360 --> 00:24:10,140
there we

400
00:24:10,240 --> 00:24:15,230
check those force possibly cut that we find the core the matching OK

401
00:24:15,240 --> 00:24:18,740
but the problem we were looking at is we know

402
00:24:18,760 --> 00:24:21,670
if we want to index all things it's impossible

403
00:24:21,780 --> 00:24:25,460
but oh well we can look at the cost with you where is the problem

404
00:24:25,460 --> 00:24:29,640
why we do this graph indexing could be very expensive

405
00:24:29,660 --> 00:24:31,020
the first thing is

406
00:24:31,060 --> 00:24:37,840
of course if you have index entry this entry serves may have cost ireland CPU

407
00:24:37,860 --> 00:24:40,970
but then you take the index to coincide

408
00:24:41,730 --> 00:24:44,120
you may find some candidates

409
00:24:44,160 --> 00:24:45,820
this is your candidate set

410
00:24:45,960 --> 00:24:50,990
then you may find for each candidate whom effect the real graph

411
00:24:51,010 --> 00:24:54,330
and they you do have some of the testing whether it's real graph is the

412
00:24:54,330 --> 00:24:55,560
one you need

413
00:24:55,580 --> 00:25:00,630
but the key part if you want to reduce the cost he parties make this

414
00:25:00,630 --> 00:25:01,750
one small

415
00:25:01,760 --> 00:25:08,480
thinking about this a in davis here we know there's one car mike stonebraker quite

416
00:25:08,520 --> 00:25:10,760
often using this once example of

417
00:25:10,930 --> 00:25:16,350
mike stonebraker is the one who invented the first relational database system called in greece

418
00:25:16,520 --> 00:25:18,770
he was a professor at UC berkeley

419
00:25:18,780 --> 00:25:26,070
there are two ways to index one the index mike another is index still break

420
00:25:26,090 --> 00:25:27,770
which one do you prefer

421
00:25:27,770 --> 00:25:32,050
i think everybody was index will break around the index mark

422
00:25:32,110 --> 00:25:36,160
the reason a is if you index mike you go to the your phone book

423
00:25:36,170 --> 00:25:41,050
how many might have never have hundreds of thousands of might and so if you

424
00:25:41,050 --> 00:25:42,730
take kind of south

425
00:25:42,820 --> 00:25:47,440
this set this candidate that would be really huge they you have to search every

426
00:25:47,480 --> 00:25:51,120
page of the form book to see whether this mike is mike stonebraker this might

427
00:25:51,160 --> 00:25:52,610
is not like stonebraker

428
00:25:52,630 --> 00:25:56,780
so that that's too costly but it gets stonebraker

429
00:25:56,780 --> 00:25:58,230
the set is much smaller

430
00:25:59,580 --> 00:26:00,350
you do this

431
00:26:00,360 --> 00:26:05,020
the remaining task even it may still take some cost was only could have better

432
00:26:05,020 --> 00:26:05,930
than that

433
00:26:05,930 --> 00:26:07,820
so if we know this

434
00:26:07,850 --> 00:26:10,320
we probably do the same thing

435
00:26:10,340 --> 00:26:15,710
so the interesting thing is previous people also think about this they don't index everything

436
00:26:15,710 --> 00:26:18,990
they say i pick up graphs

437
00:26:19,210 --> 00:26:23,630
pick up the parks take up the longest pass i want to index some so

438
00:26:23,680 --> 00:26:25,440
then i'm i'm OK

439
00:26:27,440 --> 00:26:31,670
the previous approach including the commercial daylight what they do is they say

440
00:26:31,680 --> 00:26:37,440
search the longest pass lens one installing three you enumerate all these passing index you

441
00:26:37,440 --> 00:26:39,550
can do the search

442
00:26:39,610 --> 00:26:44,020
but the problem i can give you one simple example you see this past may

443
00:26:44,020 --> 00:26:46,140
not really work OK

444
00:26:47,090 --> 00:26:50,480
i give you this core group they find in the chemical

445
00:26:50,870 --> 00:26:54,830
compon database try to find something campaign the structure

446
00:26:54,840 --> 00:26:58,680
so you think i for this point two longest pass was the longest part i

447
00:26:58,680 --> 00:26:59,490
can get

448
00:26:59,500 --> 00:27:03,920
it's carbon carbon carbon carbon get for commons of lands three

449
00:27:03,930 --> 00:27:09,120
go to the database suppose these are the three databases

450
00:27:09,180 --> 00:27:10,700
do get all of them

451
00:27:10,720 --> 00:27:12,780
are they get what you need

452
00:27:12,800 --> 00:27:14,770
OK so c

453
00:27:14,780 --> 00:27:18,670
this last fall have also the stuff has four commons former team

454
00:27:18,680 --> 00:27:21,790
to get everybody is more like a user might

455
00:27:21,850 --> 00:27:25,270
to search mike stonebraker is basically get everybody out

456
00:27:25,280 --> 00:27:28,240
OK that's not effective and efficient

457
00:27:28,250 --> 00:27:30,860
it's but if you use the structure

458
00:27:30,890 --> 00:27:34,940
if you use the whole structure OK they go inside if you see there is

459
00:27:34,940 --> 00:27:41,190
only one answer that one you're taking up so very obviously you want to use

460
00:27:41,210 --> 00:27:44,310
bigger structures rather than just the longest pass

461
00:27:45,500 --> 00:27:47,970
now we give you the example

462
00:27:48,770 --> 00:27:50,800
the interesting thing is

463
00:27:50,820 --> 00:27:54,380
what is the structure you want to use if you want to use all the

464
00:27:54,390 --> 00:28:03,850
substructures is explanation so that's the interesting thing happens is way too frequent substructure mining

465
00:28:05,620 --> 00:28:11,260
that means what we really want to find the general philosophy is first identify frequent

466
00:28:11,260 --> 00:28:15,470
substructure using the frequent graph might

467
00:28:17,240 --> 00:28:21,870
the interesting thing another interesting thing is we say we don't want to use all

468
00:28:21,870 --> 00:28:24,950
the frequent substructure is because it's is exponential

469
00:28:24,970 --> 00:28:32,790
and we want to use discriminant substructures what's discriminant discriminant means it's my structure

470
00:28:32,850 --> 00:28:35,040
is rather different from yours

471
00:28:35,060 --> 00:28:38,870
mine would be the candidate if we have very similar

472
00:28:38,890 --> 00:28:40,640
like you are not sure

473
00:28:40,760 --> 00:28:43,260
that's the independent in our philosophy

474
00:28:44,330 --> 00:28:46,560
so if you think about this philosophy

475
00:28:46,560 --> 00:28:50,910
what if god is a originally about the whole structure is all structure can be

476
00:28:50,930 --> 00:28:56,330
doing index you get millions of them they use only one to find frequent one

477
00:28:56,350 --> 00:28:59,870
i can reduce the least one automatically it if i say i want to find

478
00:28:59,870 --> 00:29:01,500
so this is

479
00:29:01,520 --> 00:29:02,580
written in

480
00:29:02,600 --> 00:29:03,750
the sense for

481
00:29:03,780 --> 00:29:08,740
for the first life form organism being so these are the types of nodes in

482
00:29:09,610 --> 00:29:13,540
in this structure you can see

483
00:29:14,360 --> 00:29:15,120
we have

484
00:29:15,130 --> 00:29:23,050
almost hundred thousand nouns spend thousands of workers twenty thousand adjectives in almost five thousand

485
00:29:24,390 --> 00:29:25,630
so this would be

486
00:29:25,660 --> 00:29:30,940
well type of structure which would that will be so let's see if we have

487
00:29:30,940 --> 00:29:35,270
a sense for words but

488
00:29:35,500 --> 00:29:38,370
and then we would be

489
00:29:38,380 --> 00:29:39,390
so was

490
00:29:39,410 --> 00:29:42,220
he said but so it's vital for

491
00:29:42,640 --> 00:29:44,220
but are

492
00:29:44,700 --> 00:29:46,990
hall could be again

493
00:29:47,030 --> 00:29:54,030
you say you know he's a relationship to and then having is relationship part of

494
00:29:54,040 --> 00:29:57,800
so i think is part of the boat and

495
00:29:57,810 --> 00:30:02,220
i mean can be also part of airplane for instance and so on so these

496
00:30:02,220 --> 00:30:06,390
are the relationships so all the senses so each node is one sentence and all

497
00:30:06,390 --> 00:30:09,100
the senses are connected to it

498
00:30:09,110 --> 00:30:13,840
with the edges and he'd each edge is labeled which is type of relationship

499
00:30:13,930 --> 00:30:17,930
we have twenty six relationships and now if we look at a couple of them

500
00:30:19,350 --> 00:30:21,310
one is hypernym

501
00:30:21,360 --> 00:30:26,040
this would be his from lower to higher concepts like breakfast meal

502
00:30:28,290 --> 00:30:29,940
i mean would be hypernym of

503
00:30:30,770 --> 00:30:37,120
breakfast hypernym is from concept to subordinates meal lunch so just

504
00:30:37,160 --> 00:30:42,020
has member so this is one of the important type of relationship so from groups

505
00:30:42,020 --> 00:30:47,430
to their members faculty professor in this kind of relationship or member of

506
00:30:47,440 --> 00:30:48,830
opposite was it called

507
00:30:48,890 --> 00:30:52,670
from members to their groups so copilot crew

508
00:30:52,700 --> 00:30:55,750
o has parts so they lack or

509
00:30:56,480 --> 00:31:01,670
we saw bird bird being called same

510
00:31:01,670 --> 00:31:06,830
and so the opposite course meal antonym would be opposites leader follower so

511
00:31:06,850 --> 00:31:11,960
two opposite concepts and we have twenty six such relationship so

512
00:31:11,980 --> 00:31:13,750
in that sense this is

513
00:31:13,790 --> 00:31:17,620
quite reach reach database which is used quite often

514
00:31:17,940 --> 00:31:24,980
in text analytics are mainly for this indication of text or even for so

515
00:31:24,980 --> 00:31:27,170
some other tasks

516
00:31:29,520 --> 00:31:30,940
OK so this would be

517
00:31:30,980 --> 00:31:38,290
simple lexical relationships now we go to little bit more sophisticated ones which syntactic

518
00:31:39,100 --> 00:31:44,460
representations were made stop here in this vector space model

519
00:31:44,500 --> 00:31:47,420
are maybe a little bit less relevant

520
00:31:47,440 --> 00:31:49,580
so vector space model is

521
00:31:49,650 --> 00:31:55,770
the most popular in representation in text mining physically most of the algorithms most of

522
00:31:55,770 --> 00:31:58,960
the tasks use this presentation

523
00:31:58,980 --> 00:32:01,600
basically a

524
00:32:01,600 --> 00:32:05,310
what's behind this vector space model so

525
00:32:06,790 --> 00:32:12,620
it takes a document and transform it into sparse american actor and spice american actor

526
00:32:12,620 --> 00:32:16,810
means that it's in a big vector of all possible words which can appear in

527
00:32:16,810 --> 00:32:23,560
the document but its nonzero components non-zero elements of this vector

528
00:32:23,580 --> 00:32:25,250
just for the words which

529
00:32:25,250 --> 00:32:29,440
which actually appear in documents this would be kind of short explanation

530
00:32:29,440 --> 00:32:35,040
and why is this interesting because having such representation we can use

531
00:32:36,540 --> 00:32:37,420
you are

532
00:32:37,440 --> 00:32:39,620
japan operation so we can do

533
00:32:39,630 --> 00:32:45,350
well kind of metrics and vector operations on top of this which more or less

534
00:32:45,350 --> 00:32:47,420
correspond to what text mining

535
00:32:47,440 --> 00:32:49,670
in the most cases

536
00:32:49,690 --> 00:32:54,150
having this kind of representation

537
00:32:54,190 --> 00:32:58,560
it means that the completely forget about the linguistic structure within the text but since

538
00:32:58,580 --> 00:33:04,290
the text has a lot of redundancy is a good in itself this does doesn't

539
00:33:04,400 --> 00:33:05,330
just watch

540
00:33:09,000 --> 00:33:10,540
so another

541
00:33:10,540 --> 00:33:14,630
kind of synonym for this vector space model which is used in

542
00:33:14,690 --> 00:33:20,000
text mining or information to its better first presentation because it's really back of

543
00:33:21,460 --> 00:33:23,600
a difficult task would be

544
00:33:23,620 --> 00:33:28,190
classification clustering visualisation and so on which seems to be

545
00:33:28,230 --> 00:33:30,790
so how does look like

546
00:33:30,810 --> 00:33:35,060
looks like so it's we have documented evidence simply

547
00:33:35,100 --> 00:33:36,480
into vector

548
00:33:37,620 --> 00:33:40,920
prices for this particular

549
00:33:40,940 --> 00:33:48,460
documents because the elements listed journal appears three times and then the right number three

550
00:33:48,540 --> 00:33:52,040
in front of the driver and so on this

551
00:33:52,130 --> 00:33:58,480
having such a vector then we perform linear algebra operations and this works quite well

552
00:33:58,480 --> 00:34:03,870
again i want to to go too much into the details here actually d and

553
00:34:03,900 --> 00:34:07,870
we don't have just these numbers frequency numbers but some other numbers which we call

554
00:34:07,890 --> 00:34:09,630
TFIDF which

555
00:34:09,650 --> 00:34:12,400
tell a little bit more is very simple formula which

556
00:34:12,400 --> 00:34:17,440
calculates this weights and is a little bit more efficient

557
00:34:17,440 --> 00:34:19,790
o and

558
00:34:19,790 --> 00:34:21,940
in the end we have something like this so

559
00:34:21,960 --> 00:34:27,400
if this is original text original document which we get that after this

560
00:34:27,540 --> 00:34:29,230
formation we get

561
00:34:29,260 --> 00:34:31,400
vector like this but

562
00:34:31,400 --> 00:34:33,190
some numbers which

563
00:34:35,350 --> 00:34:40,650
scores and with this vector then we go in the algorithms

564
00:34:40,650 --> 00:34:46,040
for learning clustering cancer

565
00:34:46,370 --> 00:34:50,560
OK skip this

566
00:34:50,620 --> 00:34:56,730
language more this is another representation of text which is quite popular for certain tasks

567
00:34:56,730 --> 00:35:03,520
like machine translation and so on but again i was keep this so busy basically

568
00:35:03,520 --> 00:35:10,500
here the whole intuition is that we are able to predict the next words from

569
00:35:10,500 --> 00:35:15,940
the previous words so this is the whole the whole idea and having this

570
00:35:15,960 --> 00:35:20,000
statistical models which is able to predict the next word means that we may be

571
00:35:20,310 --> 00:35:25,210
able to solve certain tasks like speech recognition would be

572
00:35:25,210 --> 00:35:30,870
uh would benefit out of this mess out of this statistical model or

573
00:35:30,870 --> 00:35:36,540
OCR optical character recognition again handwriting recognition machine translation and spelling correction so

574
00:35:36,540 --> 00:35:38,250
so this is

575
00:35:38,290 --> 00:35:42,370
type of bike of approach which which is used for

576
00:35:42,370 --> 00:35:45,580
modeling the text

577
00:35:45,600 --> 00:35:48,440
full parsing missed another level

578
00:35:48,440 --> 00:35:50,050
so the algorithms are

579
00:35:50,060 --> 00:35:55,400
but we can do in polynomial time using linear programming we can also use value

580
00:35:55,400 --> 00:36:02,060
iteration policy iteration which tend to be more efficient but these algorithms are polynomial time

581
00:36:02,070 --> 00:36:04,510
in the number of states and actions

582
00:36:04,540 --> 00:36:06,500
and that's not really

583
00:36:06,510 --> 00:36:07,570
so good

584
00:36:07,580 --> 00:36:11,820
unless you're domain where you can really engineer the problem to have a small number

585
00:36:11,820 --> 00:36:16,310
of states so so it's nice result but

586
00:36:16,330 --> 00:36:20,230
for this talk is going to be interested in the case where the states space

587
00:36:20,230 --> 00:36:24,210
is exponentially large in terms of the problem encoding size so

588
00:36:24,620 --> 00:36:26,310
in the real world has

589
00:36:26,320 --> 00:36:31,290
very very many states and we're going to try to get algorithms that work in

590
00:36:31,290 --> 00:36:35,850
the real world right so you can't apply these directly

591
00:36:35,870 --> 00:36:39,690
so what can you do if you have a large world

592
00:36:39,700 --> 00:36:44,010
one approach would be what are called the model based approach

593
00:36:44,110 --> 00:36:47,900
there's a lot of work on this and what you do is you the final

594
00:36:47,900 --> 00:36:55,190
language that can compact the bribe very large mdps now there there are several ways

595
00:36:55,190 --> 00:36:59,710
you can do this but one way would be to use a dynamic bayesian network

596
00:36:59,710 --> 00:37:04,860
you don't have to know the details of this or probabilistic strips to describe the

597
00:37:04,860 --> 00:37:11,900
transition and reward functions so so these languages can be used to describe MDP is

598
00:37:11,900 --> 00:37:17,230
it exponentially larger than their their encoding size in terms of the language

599
00:37:17,270 --> 00:37:22,220
then you have to design a planning algorithm that can deal with that language in

600
00:37:22,240 --> 00:37:25,870
a lot of you here know how hard that can be for example with DB

601
00:37:25,870 --> 00:37:30,870
ends are probabilistic strips so of

602
00:37:30,880 --> 00:37:33,510
so this is what i'm going to call the other

603
00:37:33,530 --> 00:37:39,120
model based approach and there are some problems with this i don't want to kill

604
00:37:39,120 --> 00:37:42,980
research in this area because it's very interesting

605
00:37:42,990 --> 00:37:48,180
and useful but but one problem is if you take a random application that you

606
00:37:48,180 --> 00:37:53,120
care about and try to encode it in one of these languages is always going

607
00:37:53,120 --> 00:37:57,150
to be some feature of the usually an important feature that you can't quite

608
00:37:57,270 --> 00:38:02,150
fit in the language and that there could be a couple of reasons for that

609
00:38:02,150 --> 00:38:04,240
it could be because

610
00:38:04,760 --> 00:38:09,620
problem size in the encoding will blow up for some reason to give you an

611
00:38:09,620 --> 00:38:14,780
example of that in a moment or it could be there's some fundamental representational shortcomings

612
00:38:14,780 --> 00:38:20,000
of these models for example you want to exaggerate his events like nine one one

613
00:38:20,000 --> 00:38:24,790
calls but these languages cannot handle them nicely so

614
00:38:24,800 --> 00:38:28,240
so this is the problem when you are faced with an application and there are

615
00:38:28,240 --> 00:38:33,120
some planners out here that the all these languages but you can't use them because

616
00:38:33,120 --> 00:38:39,870
your problem isn't described nicely in those languages so so that's where monte-carlo the monte

617
00:38:39,870 --> 00:38:45,800
carlo approach comes and goes as opposed to the model based approach so so in

618
00:38:45,800 --> 00:38:48,170
these cases when when you can't this

619
00:38:48,180 --> 00:38:49,210
problem i

620
00:38:49,230 --> 00:38:52,850
compactly in language that exists

621
00:38:52,890 --> 00:38:57,200
you can often write a simulator for that domain so you can you can use

622
00:38:57,200 --> 00:39:02,240
your language could be the c programming language and you could write simulator that takes

623
00:39:02,240 --> 00:39:03,120
an action

624
00:39:03,130 --> 00:39:07,260
interstate and spits out the next state and reward

625
00:39:07,280 --> 00:39:10,910
so you can evaluate you can do this for

626
00:39:10,960 --> 00:39:15,340
pretty much anything you can imagine if you spend enough time

627
00:39:16,400 --> 00:39:18,970
a couple of examples if you try to encode

628
00:39:18,990 --> 00:39:19,830
the simple

629
00:39:19,840 --> 00:39:22,890
well seemingly simple problem of klondike solitaire

630
00:39:24,380 --> 00:39:31,990
probabilistic PDDL you'll find ways i can't find a compact way to do it so

631
00:39:31,990 --> 00:39:37,180
that you can use the existing planners and you could model is is is upon

632
00:39:37,180 --> 00:39:42,410
DP partially observable MDP but those planners don't really scale

633
00:39:43,270 --> 00:39:47,220
when we were interested in trying to solve this problem we were sort of stuff

634
00:39:47,220 --> 00:39:52,040
but it is really easy to write a simulator for klondike solitaire you have a

635
00:39:52,040 --> 00:39:58,120
particular situation you take an action you distill card same thing with another application i

636
00:39:58,120 --> 00:40:04,040
was involved with fire and emergency response here we interested in sort of routing multiple

637
00:40:04,090 --> 00:40:05,900
vehicles around town

638
00:40:06,120 --> 00:40:10,670
placing them in places to be ready for emergencies in response to nine one one

639
00:40:10,670 --> 00:40:16,620
calls it emerge and this is a very exciting this domain its arginase events in

640
00:40:16,620 --> 00:40:20,880
terms of traffic patterns and the nine one one calls the comment hard to model

641
00:40:20,880 --> 00:40:21,490
if not

642
00:40:22,490 --> 00:40:23,120
what was it

643
00:40:25,870 --> 00:40:27,770
andy then they can be of why

644
00:40:29,640 --> 00:40:33,580
that is summerbee events you get a teaching post at the first you get the end

645
00:40:34,450 --> 00:40:35,330
of at

646
00:40:36,580 --> 00:40:38,710
for finding out is the question mark or something else

647
00:40:42,600 --> 00:40:45,280
with probability one minus something else

648
00:40:46,280 --> 00:40:47,580
and then you get the entropy

649
00:40:48,550 --> 00:40:53,250
all finding out whether it's zero one given that you know that it's not a question mark

650
00:40:53,870 --> 00:40:57,880
and the probability is zero or one if you know it's not a question mark this come out

651
00:40:58,380 --> 00:41:00,660
it is just the same as and peay the same

652
00:41:01,230 --> 00:41:02,810
ratio so the at

653
00:41:04,840 --> 00:41:05,830
it should not

654
00:41:09,120 --> 00:41:09,710
so that's

655
00:41:10,360 --> 00:41:12,960
in any textbook as well if you want to read up front

656
00:41:13,650 --> 00:41:14,920
clarify what i just told you

657
00:41:15,530 --> 00:41:17,900
you can make life easy four yourself by

658
00:41:18,360 --> 00:41:22,620
being smart about how compute entries so this is looking harry but it's not too

659
00:41:22,620 --> 00:41:23,650
hairy when we do not way

660
00:41:24,600 --> 00:41:26,980
so we have become very useful information

661
00:41:27,730 --> 00:41:28,470
it is equal to

662
00:41:29,050 --> 00:41:30,370
this loss which is eight

663
00:41:34,160 --> 00:41:35,240
plus one minus the

664
00:41:37,100 --> 00:41:37,290
you know

665
00:41:39,300 --> 00:41:40,240
minus this thing

666
00:41:42,560 --> 00:41:45,490
we have a grand cancellation innovator who's over s

667
00:41:45,960 --> 00:41:50,490
and left woman suffrage to be not as we had before when you maximize that's the capacity

668
00:41:52,000 --> 00:41:53,600
this is actually set capacity

669
00:41:54,930 --> 00:41:55,530
one was at

670
00:41:57,620 --> 00:41:59,150
so we found the capacity

671
00:42:00,920 --> 00:42:05,480
i want to go back to this diagram everything we talk about the noisy channel coding said

672
00:42:05,980 --> 00:42:07,560
let's imagine we got a noisy channel

673
00:42:08,370 --> 00:42:10,950
we're going to slap clathrin coated on the front that adds redundancy

674
00:42:11,600 --> 00:42:13,500
well good at the club decoder doesn't

675
00:42:13,550 --> 00:42:15,690
inference to infer what the input was

676
00:42:16,580 --> 00:42:20,790
how fast can we communicate and we were actually solve the noisy channel coding theorem

677
00:42:21,770 --> 00:42:25,440
all this particular family answer is you can communicate at a rate

678
00:42:28,980 --> 00:42:31,620
one minus with essentially zero errors

679
00:42:32,630 --> 00:42:33,320
that's achievable

680
00:42:38,520 --> 00:42:40,800
that's what we had introduced a completely different topic

681
00:42:42,960 --> 00:42:49,130
noisy channel coding with feedback so i'm gonna changes diagram now ongoing imagine a completely different diagram

682
00:42:49,690 --> 00:42:51,410
where everything that comes out the channel

683
00:42:52,450 --> 00:42:53,080
gets back

684
00:42:53,860 --> 00:42:54,670
and is available

685
00:42:56,890 --> 00:42:57,550
the encoder

686
00:42:58,690 --> 00:42:59,640
a different diagram

687
00:43:00,490 --> 00:43:02,500
it's got an extra communication link

688
00:43:03,210 --> 00:43:07,180
back from the end of the channel to the encoder encoder knows exactly what's going on

689
00:43:07,760 --> 00:43:08,970
so if the encoder

690
00:43:09,440 --> 00:43:11,200
stands for example

691
00:43:11,870 --> 00:43:14,310
one zero one zero one

692
00:43:16,760 --> 00:43:18,160
and what comes out the shower

693
00:43:19,260 --> 00:43:19,570
i have some

694
00:43:20,130 --> 00:43:21,130
question marks in one

695
00:43:21,570 --> 00:43:22,850
there question mark

696
00:43:24,710 --> 00:43:25,500
one question mark

697
00:43:29,930 --> 00:43:34,140
what the answer to the question how fast can communicate over this channel given that

698
00:43:34,140 --> 00:43:37,470
you've got feedback available to them i completely changed the game right

699
00:43:38,510 --> 00:43:43,070
because the sort of encoding trick you could now uses you could just say well i'm gonna listen

700
00:43:43,600 --> 00:43:45,710
my output whenever the question mark

701
00:43:46,150 --> 00:43:48,260
i will retransmit the thing was just lost

702
00:43:48,880 --> 00:43:50,530
because i know that they didn't receive anything

703
00:43:51,350 --> 00:43:53,760
so i'll just retransmit so you wouldn't

704
00:43:55,780 --> 00:44:00,790
this story can you if you had a question mark trying to send one around

705
00:44:02,440 --> 00:44:03,690
what you would send would be

706
00:44:07,450 --> 00:44:08,210
this is the original

707
00:44:11,320 --> 00:44:12,580
and then the transmission

708
00:44:15,760 --> 00:44:20,830
would be assuming that a question mark happened at these or ann bomb

709
00:44:23,510 --> 00:44:25,410
what we transmit transmit

710
00:44:27,060 --> 00:44:32,180
zero zero one minute friends and one again because the question what happens then you keep on going zero one

711
00:44:32,650 --> 00:44:33,010
and then

712
00:44:35,350 --> 00:44:37,360
think in the next one is a one

713
00:44:38,150 --> 00:44:38,730
but i guess

714
00:44:39,280 --> 00:44:40,980
lost is not a question mark there

715
00:44:42,240 --> 00:44:43,140
say transmit again

716
00:44:44,290 --> 00:44:46,770
i think that's stating words clearer one hundred on the ball

717
00:44:48,290 --> 00:44:48,850
you keep on

718
00:44:50,490 --> 00:44:53,030
transmitting a symbol until it is correctly received

719
00:44:54,830 --> 00:44:59,390
what's the rate you're gonna be able to achieve with clever skin making use this feedback

720
00:44:59,950 --> 00:45:00,830
habitat geneva

721
00:45:07,950 --> 00:45:10,140
what rate can you communicate at

722
00:45:10,870 --> 00:45:12,560
if you reduce the red feedback link

723
00:45:14,160 --> 00:45:14,720
on average

724
00:45:25,140 --> 00:45:30,020
you just imagine how much time you spend successfully communicating its whenever the wrong question

725
00:45:30,020 --> 00:45:31,830
marks you've got a little bit over the channel

726
00:45:32,500 --> 00:45:33,360
there's a question mark

727
00:45:33,870 --> 00:45:34,310
coming out

728
00:45:34,810 --> 00:45:36,880
you want achieving reliable communication at all

729
00:45:38,030 --> 00:45:40,220
and the fraction of time are question marks is at

730
00:45:41,100 --> 00:45:44,440
so the rate at which you're communicating using the feedback link

731
00:45:46,910 --> 00:45:47,360
one minus

732
00:45:49,820 --> 00:45:51,010
any questions anyone

733
00:45:52,310 --> 00:45:52,970
not clear on this

734
00:45:52,970 --> 00:45:57,380
this is the case i mean the discrete time domain

735
00:45:57,400 --> 00:45:58,970
the discrete time

736
00:46:06,680 --> 00:46:09,290
all minus two

737
00:46:09,300 --> 00:46:11,210
minus one all

738
00:46:11,230 --> 00:46:14,150
major undertaking the

739
00:46:14,170 --> 00:46:17,020
sampling period to be one for

740
00:46:18,640 --> 00:46:23,710
so i've samples at all integer times

741
00:46:23,730 --> 00:46:28,360
and i act on those with this filter h which in

742
00:46:28,940 --> 00:46:29,890
which is

743
00:46:29,900 --> 00:46:32,360
which advises ax of zero by

744
00:46:32,380 --> 00:46:35,570
h of zero

745
00:46:37,400 --> 00:46:42,190
these of course we everybody says

746
00:46:42,210 --> 00:46:45,980
i mean i even highlighted with yellow this fact that

747
00:46:46,010 --> 00:46:49,760
we've got k two indices at this one

748
00:46:49,770 --> 00:46:51,650
it's a convolution

749
00:46:51,650 --> 00:46:56,210
it's time linear time invariant i could try to put all this down

750
00:46:56,220 --> 00:46:59,320
this is an phi are it's also

751
00:46:59,360 --> 00:47:03,920
and linear time in well i'm squeezing

752
00:47:05,070 --> 00:47:06,150
facts but

753
00:47:06,170 --> 00:47:07,710
there are all evident here

754
00:47:07,720 --> 00:47:10,830
OK i just want to complete this

755
00:47:13,850 --> 00:47:15,520
so why have zero nature

756
00:47:15,530 --> 00:47:17,090
writes of zero

757
00:47:17,090 --> 00:47:20,010
h one n nodes

758
00:47:20,020 --> 00:47:23,490
it's going to be lower triangular

759
00:47:23,520 --> 00:47:24,850
and templates

760
00:47:24,880 --> 00:47:29,340
as well anticipate what's coming

761
00:47:31,090 --> 00:47:33,070
on that

762
00:47:33,090 --> 00:47:35,770
hmm zero

763
00:47:35,820 --> 00:47:38,420
multiplies acts of and

764
00:47:38,450 --> 00:47:42,510
when when k is zero agent zero mode the next event

765
00:47:42,530 --> 00:47:47,230
h one multiplies x of n minus one

766
00:47:47,960 --> 00:47:52,780
features are also on the main diagonal line

767
00:47:52,790 --> 00:47:57,590
x of tutor give the wives to contribute to why two

768
00:47:57,590 --> 00:48:01,400
but then they will be in each of one

769
00:48:01,410 --> 00:48:04,800
on this diagonal

770
00:48:04,820 --> 00:48:07,030
as you see that

771
00:48:07,080 --> 00:48:11,830
eight one multiplying eq some minus one into y of zero

772
00:48:11,840 --> 00:48:15,710
h one multiplying eq severo contributes to y one

773
00:48:15,710 --> 00:48:18,820
h one x o one contribute to y two

774
00:48:21,900 --> 00:48:24,900
the matrix is tough but

775
00:48:24,970 --> 00:48:29,740
and we can understand

776
00:48:29,760 --> 00:48:32,230
and the matrix is completely

777
00:48:32,260 --> 00:48:33,980
but let's quit

778
00:48:34,770 --> 00:48:40,660
that's quite well read that too

779
00:48:40,700 --> 00:48:44,900
suppose suppose suppose i just have to tap agent zero

780
00:48:44,900 --> 00:48:47,190
h one

781
00:48:47,400 --> 00:48:48,790
let's take short

782
00:48:49,990 --> 00:48:51,700
crude felt

783
00:48:51,710 --> 00:48:53,260
what could be achieved

784
00:48:56,520 --> 00:48:59,800
two tap filter

785
00:49:01,840 --> 00:49:07,600
so so so so that felt so right now to for a while and

786
00:49:08,580 --> 00:49:11,360
agent zero active and

787
00:49:11,410 --> 00:49:13,490
class h one n one

788
00:49:13,510 --> 00:49:16,730
x n minus one and that's all we're doing

789
00:49:16,750 --> 00:49:19,390
so there's two tap

790
00:49:21,220 --> 00:49:23,100
and therefore just

791
00:49:23,120 --> 00:49:29,710
two diagonals in the matrix

792
00:49:29,730 --> 00:49:33,180
how should we understand the action of such

793
00:49:33,220 --> 00:49:35,760
convolution that is the convolution

794
00:49:35,790 --> 00:49:40,180
as the convolution of something that only has two components a

795
00:49:40,200 --> 00:49:41,670
was something that has

796
00:49:41,690 --> 00:49:43,330
doubly infinite

797
00:49:44,730 --> 00:49:46,090
but what does it do

798
00:49:46,090 --> 00:49:49,750
what does it do for example let's just take examples

799
00:49:52,380 --> 00:49:57,510
suppose both equal have

800
00:49:57,520 --> 00:50:01,360
eight people are killed components are both

801
00:50:01,380 --> 00:50:02,580
so so

802
00:50:02,590 --> 00:50:05,480
so why have and

803
00:50:05,540 --> 00:50:10,620
a is one half x and

804
00:50:10,640 --> 00:50:16,770
and one half of x one three percent

805
00:50:16,940 --> 00:50:20,230
are running average

806
00:50:20,240 --> 00:50:28,760
can we just

807
00:50:28,820 --> 00:50:30,220
consider that

808
00:50:30,240 --> 00:50:36,040
example because it's really very useful one concern

809
00:50:42,040 --> 00:50:46,660
actually look at that

810
00:50:48,610 --> 00:50:50,180
its natural as

811
00:50:51,960 --> 00:50:53,190
i can hardly

812
00:50:53,200 --> 00:50:58,170
avoid going into the fourier in the fourier domain looking to see

813
00:50:58,220 --> 00:51:00,310
because it's constant coefficients

814
00:51:00,320 --> 00:51:03,450
looking to see what it does to exponentials

815
00:51:03,460 --> 00:51:05,570
can i do that

816
00:51:08,420 --> 00:51:11,420
well first of all what did what does it do to

817
00:51:12,140 --> 00:51:16,370
zero frequency to the DCG terms suppose the input

818
00:51:17,090 --> 00:51:19,820
oppose the input

819
00:51:19,860 --> 00:51:21,680
it is

820
00:51:21,720 --> 00:51:24,200
x all one

821
00:51:24,210 --> 00:51:27,510
has DCG input

822
00:51:27,520 --> 00:51:30,050
what's the output

823
00:51:30,060 --> 00:51:34,080
the same thing

824
00:51:36,680 --> 00:51:43,760
i'm saying this as a low pass filter because this is this is

825
00:51:43,770 --> 00:51:46,350
well maybe equals zero

826
00:51:55,340 --> 00:51:57,060
with no

827
00:51:57,100 --> 00:51:59,710
no corruption

828
00:51:59,720 --> 00:52:00,250
o making

829
00:52:00,430 --> 00:52:01,950
o zero on

830
00:52:01,990 --> 00:52:04,270
introduce omega properly but

831
00:52:04,300 --> 00:52:07,470
zero frequency certainly corresponds to that

832
00:52:09,590 --> 00:52:11,810
tell me the other extreme

833
00:52:11,820 --> 00:52:14,200
what input

834
00:52:14,210 --> 00:52:15,240
it would be

835
00:52:15,260 --> 00:52:20,640
wiped out by this filter

836
00:52:20,710 --> 00:52:25,110
alternating one input so the second input of

837
00:52:25,120 --> 00:52:26,840
special interest

838
00:52:26,850 --> 00:52:28,260
is that all

839
00:52:33,340 --> 00:52:36,670
one minus one one minus one

840
00:52:36,690 --> 00:52:38,340
that leads to y

841
00:52:39,420 --> 00:52:40,660
what's the

842
00:52:40,680 --> 00:52:42,730
output for that

843
00:52:42,770 --> 00:52:45,470
of course that continues forever

844
00:52:45,480 --> 00:52:48,970
so it doesn't spoil our duty

845
00:52:50,090 --> 00:52:52,800
o why comes out as

846
00:52:58,950 --> 00:53:01,960
OK and what frequency

847
00:53:01,970 --> 00:53:03,050
now let's

848
00:53:03,060 --> 00:53:06,500
allow that word frequency to be in the sneak in

849
00:53:06,520 --> 00:53:07,720
even more

850
00:53:07,950 --> 00:53:11,670
this to me is the frequency on me pi

851
00:53:11,680 --> 00:53:16,710
and that's the fastest oscillation the highest frequency i can have

852
00:53:16,720 --> 00:53:18,580
i fourier transforms

853
00:53:18,590 --> 00:53:20,560
or also

854
00:53:20,570 --> 00:53:22,240
it's also

855
00:53:27,230 --> 00:53:30,090
those two are identical

856
00:53:30,100 --> 00:53:31,210
in other words

857
00:53:31,230 --> 00:53:32,540
i'm using the

858
00:53:32,550 --> 00:53:35,470
the discrete time fourier transform

859
00:53:35,490 --> 00:53:36,950
that takes

860
00:53:36,960 --> 00:53:40,540
well let's just so is the discrete time

861
00:53:40,550 --> 00:53:47,510
so in the frequency domain

862
00:53:47,540 --> 00:53:50,000
i use capital ex

863
00:53:50,010 --> 00:53:51,410
for the transform

864
00:53:51,470 --> 00:53:54,410
of the input little axe

865
00:53:54,410 --> 00:53:55,660
up to the end of august

866
00:53:56,210 --> 00:53:57,190
and then there was this

867
00:53:57,710 --> 00:54:01,090
big turns so the crossover and then the sentiment

868
00:54:01,610 --> 00:54:02,490
remained negative

869
00:54:03,280 --> 00:54:04,440
throughout the rest of the year

870
00:54:05,280 --> 00:54:06,760
and the important thing

871
00:54:07,710 --> 00:54:08,890
notice here is that

872
00:54:09,430 --> 00:54:10,660
the sentiment crossover

873
00:54:11,400 --> 00:54:13,290
happens actually before this

874
00:54:15,030 --> 00:54:15,920
price lunch

875
00:54:18,180 --> 00:54:21,150
this was like the first nice thing to see when we

876
00:54:21,890 --> 00:54:25,320
plotted this chart and then we went on to computing

877
00:54:26,180 --> 00:54:30,310
causality tests so basically we wanted to see whether the sentiment

878
00:54:31,230 --> 00:54:34,180
helps predicting the price are the price

879
00:54:34,630 --> 00:54:36,570
basically helps predicting the sentiment

880
00:54:37,810 --> 00:54:45,050
the preliminary results but they are all very polluted preliminary they showed that actually the did the sentiment

881
00:54:45,510 --> 00:54:49,330
would predict would help predicting the price and not vice versa

882
00:54:50,990 --> 00:54:52,180
so but before r

883
00:54:53,660 --> 00:54:55,300
before we all get very rich

884
00:54:56,900 --> 00:55:01,790
by selling your this technology because we don't want to play with our money on the stock market

885
00:55:03,930 --> 00:55:04,930
we of course need to do

886
00:55:05,470 --> 00:55:06,160
some more

887
00:55:07,670 --> 00:55:08,840
large scale tests

888
00:55:10,560 --> 00:55:11,300
if this is true

889
00:55:12,640 --> 00:55:14,300
currently what we believe is that

890
00:55:14,750 --> 00:55:15,280
in some

891
00:55:15,690 --> 00:55:18,850
cases this is true so we can actually

892
00:55:20,240 --> 00:55:22,690
predicting the price by looking at the sentiment

893
00:55:23,260 --> 00:55:24,790
about which cases these are

894
00:55:25,230 --> 00:55:27,680
this is not completely clear right now

895
00:55:29,790 --> 00:55:31,450
okay so i will conclude here

896
00:55:32,600 --> 00:55:33,240
so what

897
00:55:33,850 --> 00:55:35,300
i will just recap what i was

898
00:55:35,750 --> 00:55:36,840
talking about right now so

899
00:55:37,980 --> 00:55:43,540
on twitter people are definitely expressing opinions about stocks extensively right

900
00:55:44,080 --> 00:55:45,920
we acquire these tweets

901
00:55:46,320 --> 00:55:50,570
and we analyze the vocabulary to see whether it's positive or negative

902
00:55:51,110 --> 00:55:53,860
and then we can display the results along the timeline

903
00:55:54,250 --> 00:55:56,860
and observe sentiment trends through time

904
00:55:57,790 --> 00:56:00,860
and yet our preliminary because all the tests are

905
00:56:04,280 --> 00:56:04,690
that's it

906
00:56:05,320 --> 00:56:06,410
thank you for your attention

907
00:56:10,280 --> 00:56:13,380
i just wanted to understand whether this platform

908
00:56:14,330 --> 00:56:20,800
is aimed is being rolled out on various languages because you're saying that you only taking into account in english

909
00:56:21,520 --> 00:56:27,000
which is certainly the most spoken in this but most spoken language in the world

910
00:56:27,000 --> 00:56:34,110
but i planning to include also let's say spanish are offered in french or german

911
00:56:35,000 --> 00:56:39,600
yeah the technology that we are currently using is based on statistics

912
00:56:40,340 --> 00:56:44,130
and statistics with this kind of methods how it helps to have

913
00:56:44,630 --> 00:56:45,940
a lot of data right

914
00:56:47,300 --> 00:56:47,740
when we

915
00:56:48,460 --> 00:56:51,700
go far uist stocks and for english we kind of get

916
00:56:52,200 --> 00:56:53,130
quite a lot of data

917
00:56:54,170 --> 00:56:55,410
which is not the case

918
00:56:56,290 --> 00:56:58,170
if we go for some other markets

919
00:57:00,700 --> 00:57:03,330
i would expect debt we wouldn't

920
00:57:03,890 --> 00:57:05,660
this so successful

921
00:57:07,010 --> 00:57:11,840
researching this week with other markets but it's definitely something that we could try

922
00:57:13,300 --> 00:57:16,570
because in the end the technology that we employ is

923
00:57:17,310 --> 00:57:22,950
quite language independent so it's not a problem to process spanish-language are italian language and

924
00:57:22,950 --> 00:57:26,500
it's not a problem the problem is just in the amount of data

925
00:57:27,230 --> 00:57:27,980
end having

926
00:57:28,500 --> 00:57:33,420
something that we call the training set the training base which means a lot of tweets

927
00:57:33,900 --> 00:57:35,050
in a particular language

928
00:57:35,490 --> 00:57:37,770
already in manually are somehow

929
00:57:38,190 --> 00:57:40,850
incredibly labelled as positive and negative

930
00:57:41,730 --> 00:57:43,930
so for english we have all these things

931
00:57:46,540 --> 00:57:47,930
use technology like these

932
00:57:48,550 --> 00:57:53,750
flow to me should stay in opinion of the obvious social community about the company

933
00:57:54,880 --> 00:57:59,320
doing needed to have somebody in a company in my company

934
00:57:59,870 --> 00:58:00,380
to teach

935
00:58:00,830 --> 00:58:03,200
the technology about slayings

936
00:58:03,820 --> 00:58:04,220
and the

937
00:58:04,800 --> 00:58:05,570
how we humans

938
00:58:06,300 --> 00:58:08,390
uses all humans communicate

939
00:58:09,170 --> 00:58:10,560
the short toward the

940
00:58:14,260 --> 00:58:15,330
want to uh

941
00:58:15,410 --> 00:58:15,890
for this

942
00:58:16,530 --> 00:58:19,430
i think in this particular case that the technology that was

943
00:58:20,060 --> 00:58:20,820
employed here

944
00:58:21,330 --> 00:58:22,630
it is based on machine learning

945
00:58:23,150 --> 00:58:25,720
which means that you don't need somebody to more

946
00:58:26,350 --> 00:58:27,590
the vocabulary or are

947
00:58:28,400 --> 00:58:28,960
you know the

948
00:58:28,960 --> 00:58:30,630
binomial distribution around you

949
00:58:35,780 --> 00:58:36,060
very good

950
00:58:37,140 --> 00:58:38,800
if you look at the binomial distribution

951
00:58:40,170 --> 00:58:41,170
andits it's got me

952
00:58:43,420 --> 00:58:47,210
all end times he where he hear is at

953
00:58:50,930 --> 00:58:52,950
at its covariance event q

954
00:58:53,530 --> 00:58:55,470
here is other thing is one minus

955
00:58:56,650 --> 00:58:59,810
all right so you can look at and then you know what variance means

956
00:59:00,330 --> 00:59:04,270
how they relate to well roughly plus and minus you know thousands of minus what

957
00:59:04,500 --> 00:59:08,700
so this is the mean it's ten thousand five point one two thousand

958
00:59:09,310 --> 00:59:10,740
the variances nine hundred

959
00:59:12,090 --> 00:59:16,990
but what does that mean the meaning and the variance is the square of the standard deviation

960
00:59:18,040 --> 00:59:18,960
so this is

961
00:59:20,850 --> 00:59:22,450
the square and the standard deviation

962
00:59:23,310 --> 00:59:24,450
you take the square root of it

963
00:59:24,810 --> 00:59:25,370
which is

964
00:59:26,960 --> 00:59:27,320
the tree

965
00:59:27,880 --> 00:59:31,050
and tells you roughly how many bits in the way

966
00:59:31,710 --> 00:59:32,620
you reflect okay

967
00:59:33,150 --> 00:59:37,690
now the binomial distribution is pretty much the only bidder mathematics you need to know

968
00:59:37,690 --> 00:59:39,820
for this course and i do encourage you to

969
00:59:40,270 --> 00:59:44,500
review the binomial distribution and get good at working with it because we are going to use it

970
00:59:44,930 --> 00:59:45,840
over and over

971
00:59:47,350 --> 00:59:50,550
this topic in other topics in information theory as well

972
00:59:52,170 --> 00:59:53,510
so we have an answer

973
00:59:55,760 --> 00:59:57,330
thousand plus and minus thirty

974
00:59:58,170 --> 00:59:58,720
thanks to

975
00:59:59,210 --> 01:00:00,780
mister binomially and inter

976
01:00:01,150 --> 01:00:02,810
the distribution that that's his name

977
01:00:07,530 --> 01:00:08,580
we've got this drive

978
01:00:10,450 --> 01:00:11,460
we launched the company

979
01:00:13,710 --> 01:00:16,330
are we going have a happy customer and reseller the first

980
01:00:16,880 --> 01:00:17,460
this right

981
01:00:18,970 --> 01:00:19,670
any opinions

982
01:00:21,380 --> 01:00:22,090
know why

983
01:00:24,770 --> 01:00:27,040
it is slightly too many flips isn't it

984
01:00:27,900 --> 01:00:29,890
if someone storing important information

985
01:00:31,040 --> 01:00:31,990
so the question take

986
01:00:34,870 --> 01:00:36,940
you have a salable described

987
01:00:40,370 --> 01:00:40,720
very little

988
01:00:41,160 --> 01:00:42,250
one giga bytes

989
01:00:44,510 --> 01:00:44,990
this right

990
01:00:50,190 --> 01:00:51,720
if it were disk-drive

991
01:00:52,380 --> 01:00:56,540
this a binary symmetric channel how small would have to be for you to be

992
01:00:56,540 --> 01:00:58,730
able to make a successful business

993
01:01:00,940 --> 01:01:01,560
how small

994
01:01:03,080 --> 01:01:04,140
the flip probability

995
01:01:08,100 --> 01:01:08,370
to be

996
01:01:09,470 --> 01:01:10,570
these into neighbour

997
01:01:11,280 --> 01:01:12,630
and have a chat about this question

998
01:01:24,120 --> 01:01:28,730
answers has all they need your after have a salable this drive

999
01:01:30,330 --> 01:01:31,250
a viable company

1000
01:01:34,570 --> 01:01:35,700
ten to minus thirty

1001
01:01:36,860 --> 01:01:37,620
another answers

1002
01:01:42,810 --> 01:01:43,760
and the minus five

1003
01:01:51,440 --> 01:01:51,970
that's true

1004
01:01:52,740 --> 01:01:53,360
many people

1005
01:01:54,040 --> 01:01:58,300
need twenty about despite these lecture notes are about three years old so

1006
01:02:01,040 --> 01:02:02,900
put a little star had to say

1007
01:02:02,900 --> 01:02:04,740
independent things like this

1008
01:02:04,820 --> 01:02:10,150
you you can test whether this is true right so given the graph on the

1009
01:02:12,740 --> 01:02:14,090
the exponentially many

1010
01:02:14,110 --> 01:02:17,730
of these kinds of independence statements through

1011
01:02:17,780 --> 01:02:21,990
the the the the the the the semantics of the graph right so we did

1012
01:02:21,990 --> 01:02:23,230
a prose kind of

1013
01:02:23,300 --> 01:02:25,740
the first to do is establish these

1014
01:02:25,740 --> 01:02:28,530
very strong correspondences between

1015
01:02:28,550 --> 01:02:32,030
writing these kind of statements their equations

1016
01:02:32,050 --> 01:02:37,530
and what do they mean in terms of graphs and what is the crisp on

1017
01:02:37,530 --> 01:02:42,170
between statements and graphs

1018
01:02:42,190 --> 01:02:47,340
OK so we're going to get too deep into that but i would want to

1019
01:02:47,340 --> 01:02:52,470
undirected graphical models which i call them arrives early in the talk

1020
01:02:53,730 --> 01:03:01,340
they are the the undirected can because the way they define distributions is not true

1021
01:03:02,110 --> 01:03:04,530
conditional probabilities but was called

1022
01:03:04,530 --> 01:03:07,340
potential functions so let's

1023
01:03:07,340 --> 01:03:12,170
i worry about the same set of variables alarm burglars earthquakes

1024
01:03:12,190 --> 01:03:16,880
now we want to define say the same kind of distribution over these five variables

1025
01:03:17,090 --> 01:03:22,490
it turns out we can define you know

1026
01:03:22,510 --> 01:03:25,550
for any business we can define a distribution

1027
01:03:26,570 --> 01:03:32,210
well something very similar in this network using this this this kind of presentation so

1028
01:03:32,260 --> 01:03:35,760
instead of these kinds of tables we just

1029
01:03:35,780 --> 01:03:41,170
factors that called or potentials that specify a nonnegative values

1030
01:03:41,190 --> 01:03:42,970
for each

1031
01:03:44,380 --> 01:03:47,460
you know the assignment of the variables came here

1032
01:03:47,470 --> 01:03:48,800
for each possible

1033
01:03:48,800 --> 01:03:50,900
joint defended this

1034
01:03:53,880 --> 01:03:58,420
normalisation factor make sure that this whole thing sums to one

1035
01:03:58,780 --> 01:04:01,740
just the some or all the variables of the product

1036
01:04:01,800 --> 01:04:07,130
it is called partition function normalisation function a other things and

1037
01:04:07,150 --> 01:04:11,420
this is the thing that's actually hard right to this one of major difference between

1038
01:04:11,460 --> 01:04:16,300
business and market networks is in a basin that if somebody asked what's the probability

1039
01:04:16,300 --> 01:04:18,760
of this observation and it gives you all

1040
01:04:18,760 --> 01:04:19,990
say a five

1041
01:04:19,990 --> 01:04:23,650
values i just look at our multiplied together number

1042
01:04:24,320 --> 01:04:28,490
if you think question mark network it's much harder question because you don't know

1043
01:04:28,510 --> 01:04:32,070
this one risi i mean you can look at this part

1044
01:04:32,110 --> 01:04:33,960
but one was is the hard part

1045
01:04:34,030 --> 01:04:39,650
and for some classes of graphical models we can do this efficiently we can compute

1046
01:04:39,650 --> 01:04:41,400
this ze efficiently so

1047
01:04:41,460 --> 01:04:44,780
now used to

1048
01:04:45,110 --> 01:04:47,400
used to do nasty a

1049
01:04:47,400 --> 01:04:49,860
roughly something like this in hmm

1050
01:04:51,880 --> 01:04:54,630
when things become grids

1051
01:04:54,650 --> 01:04:57,800
i've been doing vision

1052
01:04:57,840 --> 01:04:59,320
the partition function

1053
01:05:01,300 --> 01:05:06,260
intractable so even if we had just very simple connections the graph is this thing

1054
01:05:06,260 --> 01:05:09,280
this right it turns out that

1055
01:05:09,300 --> 01:05:12,300
coupling the partition function is intractable

1056
01:05:17,030 --> 01:05:18,780
OK so

1057
01:05:20,150 --> 01:05:23,900
that the potentials do not mean the same thing as

1058
01:05:24,130 --> 01:05:27,240
conditional distributions which right so there

1059
01:05:27,260 --> 01:05:32,510
in some ways harder to interpret in harder to get from people right there are

1060
01:05:32,510 --> 01:05:35,760
sort of these kind of compatibility functions you can think of a fair

1061
01:05:35,780 --> 01:05:39,940
if there over several variables the number for each of those things is that the

1062
01:05:39,940 --> 01:05:44,630
sum to anything it's kind of hard to interpret and people are very good at

1063
01:05:44,630 --> 01:05:49,520
interpreting conditional probabilities when they have to do with causal causes and effects right what's

1064
01:05:49,520 --> 01:05:53,090
probability of me having already knows if i have the flu

1065
01:05:53,090 --> 01:06:00,130
actually it's much harder to say the other way around what's the probability of of

1066
01:06:02,090 --> 01:06:04,260
flu right

1067
01:06:05,340 --> 01:06:06,280
because you need to

1068
01:06:06,300 --> 01:06:09,130
you need to incorporate other possible

1069
01:06:09,130 --> 01:06:11,070
explanations for conservatives

1070
01:06:13,240 --> 01:06:14,460
right so so

1071
01:06:14,490 --> 01:06:19,260
the prose interpretation of each local factor is not there for us

1072
01:06:19,280 --> 01:06:24,260
but it is actually much more flexibility and it's used in

1073
01:06:24,320 --> 01:06:27,760
for example in models and it's very hard to try to find some kind of

1074
01:06:27,760 --> 01:06:30,150
conditional distributions and the great right to do

1075
01:06:30,190 --> 01:06:33,900
pixels of whatever it's very hard to make it directed in the direction of the

1076
01:06:33,900 --> 01:06:36,240
that you still have the same

1077
01:06:40,090 --> 01:06:41,410
so that's why

1078
01:06:41,490 --> 01:06:46,990
one the framework is very convenient and

1079
01:06:47,040 --> 01:06:47,960
in a way

1080
01:06:47,970 --> 01:06:51,610
you don't lose anything by making these assumptions because you get the same results if

1081
01:06:51,610 --> 01:06:52,810
you don't make it

1082
01:06:52,890 --> 01:06:57,800
so that's why it's it's fine to keep working in this setting

1083
01:06:57,810 --> 01:07:00,590
of course it would be nice to understand their

1084
01:07:00,610 --> 01:07:01,910
and that's not

1085
01:07:01,920 --> 01:07:05,250
the case of the moment to understand better the relationship between the idea sitting in

1086
01:07:05,250 --> 01:07:09,570
this setting

1087
01:07:09,760 --> 01:07:13,460
OK now back to the bounds

1088
01:07:13,470 --> 01:07:15,610
that real things

1089
01:07:15,630 --> 01:07:17,570
one thing is that

1090
01:07:17,580 --> 01:07:21,480
it's all of the case that these bounds are

1091
01:07:21,500 --> 01:07:22,810
very far

1092
01:07:23,520 --> 01:07:25,520
the actual error that we make

1093
01:07:25,530 --> 01:07:28,560
so if you compute these quantities

1094
01:07:28,610 --> 01:07:30,570
i mean one function is

1095
01:07:30,570 --> 01:07:34,290
it won't be too bad and that's what i shown you with this curve these

1096
01:07:34,300 --> 01:07:38,180
bernoulli distribution and you have the the bound it's OK it's not very close but

1097
01:07:38,180 --> 01:07:39,660
it's not too far

1098
01:07:39,680 --> 01:07:42,650
now when you introduce these

1099
01:07:42,660 --> 01:07:50,120
covering numbers or all these geometric quantities than the bound become very big very fast

1100
01:07:51,580 --> 01:07:53,300
and often they go

1101
01:07:53,310 --> 01:07:55,400
much higher than one so may often

1102
01:07:55,410 --> 01:07:58,780
the bound your thing when you put here the covering numbers

1103
01:07:58,790 --> 01:08:01,080
four you set of functions

1104
01:08:01,130 --> 01:08:03,150
if you set the function is not

1105
01:08:03,160 --> 01:08:05,110
completely simple

1106
01:08:05,130 --> 01:08:08,450
then the bot will be much larger than one engine

1107
01:08:08,470 --> 01:08:09,480
whereas this

1108
01:08:09,500 --> 01:08:10,350
you know

1109
01:08:10,370 --> 01:08:12,060
it is less than one

1110
01:08:13,110 --> 01:08:16,820
it's a bit annoying to have completely trivial bound in the sense that it it

1111
01:08:16,820 --> 01:08:18,810
doesn't tell you anything

1112
01:08:18,820 --> 01:08:23,030
well it's still tell you something because it tells you that with enough data

1113
01:08:23,030 --> 01:08:25,760
the band goes to zero so that's already

1114
01:08:25,780 --> 01:08:31,010
not too bad but for any reasonable sample size the bound will be

1115
01:08:31,030 --> 01:08:32,770
maybe a hundred

1116
01:08:32,790 --> 01:08:35,710
so OK

1117
01:08:37,380 --> 01:08:40,130
together so the point is

1118
01:08:40,620 --> 01:08:45,630
in the course of the writing these bounds we have done something non-trivial

1119
01:08:45,650 --> 01:08:48,270
and what was nontrivial was not

1120
01:08:48,280 --> 01:08:55,580
the holding or been bernstein party it's the geometric sink

1121
01:08:57,430 --> 01:09:01,200
so how to use

1122
01:09:01,200 --> 01:09:03,180
these bounds so if if value

1123
01:09:03,230 --> 01:09:04,660
is non sense

1124
01:09:04,680 --> 01:09:08,040
what can we do with it so here i am i mean there are other

1125
01:09:08,040 --> 01:09:11,420
ways to use but i give you here three

1126
01:09:11,520 --> 01:09:14,770
i call that's three levels of the of using the bounds

1127
01:09:14,810 --> 01:09:19,110
one is the quantitative level which is what i just said using it to estimate

1128
01:09:19,110 --> 01:09:20,210
the error

1129
01:09:20,210 --> 01:09:23,110
and it's not possible because most often

1130
01:09:23,140 --> 01:09:26,570
at least so far the bonds that exist so far

1131
01:09:26,580 --> 01:09:31,040
are very large and do not give you any meaningful information about what is really

1132
01:09:31,040 --> 01:09:33,570
there that you make the second

1133
01:09:33,820 --> 01:09:35,510
level is to use them

1134
01:09:35,520 --> 01:09:36,850
to do model selection

1135
01:09:36,880 --> 01:09:40,070
so you don't care about the value you care only about the relative value so

1136
01:09:40,070 --> 01:09:44,110
you compare to algorithms you compute the bound for one algorithm and the bound for

1137
01:09:44,270 --> 01:09:45,540
another reason

1138
01:09:45,550 --> 01:09:48,630
and if one is smaller than the other even if they are one hundred and

1139
01:09:48,630 --> 01:09:51,150
two hundred you would still prefer

1140
01:09:51,180 --> 01:09:54,030
the one that is one hundred

1141
01:09:54,040 --> 01:09:56,050
and the last one is

1142
01:09:56,100 --> 01:10:00,460
not to worry at all about the values that your thing when you compute these

1143
01:10:00,460 --> 01:10:03,810
bounds but rather try to understand

1144
01:10:03,810 --> 01:10:09,480
what you can do with this geometry

1145
01:10:09,480 --> 01:10:11,760
so kids of the first level

1146
01:10:11,800 --> 01:10:14,210
as i said

1147
01:10:14,220 --> 01:10:16,640
the problem is these are

1148
01:10:16,670 --> 01:10:21,570
a a little bit messy mathematics right binomial there is there are not very easy

1149
01:10:21,570 --> 01:10:23,590
to control or two

1150
01:10:23,600 --> 01:10:27,890
to get a nice expressions of of it these geometry

1151
01:10:27,930 --> 01:10:33,030
again it's hard to really capture well and there was also this problem that we

1152
01:10:33,030 --> 01:10:38,860
have the supremum but most often the the algorithm does not that been the supreme

1153
01:10:38,870 --> 01:10:42,660
so all these reason make the bounds not very short

1154
01:10:44,920 --> 01:10:46,840
and if we want to have

1155
01:10:46,860 --> 01:10:49,770
better bounds it was we would have

1156
01:10:49,810 --> 01:10:55,720
expressions that cannot be computed or that complete that are completely unreadable so

1157
01:10:56,890 --> 01:11:01,410
there is no point in trying to use the value of the bond directly and

1158
01:11:01,460 --> 01:11:02,150
the best

1159
01:11:02,170 --> 01:11:05,570
mister use cross validation if you really want to estimate the air

1160
01:11:05,570 --> 01:11:07,370
a guys

1161
01:11:07,390 --> 01:11:09,930
now for the second level so

1162
01:11:09,970 --> 01:11:13,610
doing model selection

1163
01:11:13,630 --> 01:11:16,520
the only thing you need to know what is that

1164
01:11:17,290 --> 01:11:18,810
the minimum of the bound

1165
01:11:18,830 --> 01:11:21,070
it is located at the right place

1166
01:11:22,340 --> 01:11:26,620
if you have an algorithm that depends on the song parameter c alpha

1167
01:11:27,270 --> 01:11:28,890
and you compute the bound that

1168
01:11:28,910 --> 01:11:32,960
correspond to each value of this parameter and you get something like this

1169
01:11:32,960 --> 01:11:34,760
even if this

1170
01:11:34,830 --> 01:11:38,560
is c one hundred whereas the so that's the bound

1171
01:11:38,570 --> 01:11:42,610
and the jury something like

1172
01:11:42,630 --> 01:11:44,810
like this

1173
01:11:44,820 --> 01:11:52,270
where this is at most one even if you have such a picture

1174
01:11:52,290 --> 01:11:56,310
what matters is that the minimum here is smallest at the same place as the

1175
01:11:56,310 --> 01:11:57,530
minimum here

1176
01:11:57,550 --> 01:12:00,600
and that's that would be fine if you if you get this kind of behavior

1177
01:12:00,600 --> 01:12:01,980
for you about

1178
01:12:02,000 --> 01:12:04,420
you perfectly happy because you can select

1179
01:12:04,450 --> 01:12:06,550
you're parameter alpha

1180
01:12:06,570 --> 01:12:09,970
from the bone itself and you don't need extra validation

1181
01:12:12,070 --> 01:12:13,790
but OK

1182
01:12:14,230 --> 01:12:15,580
i would say in general

1183
01:12:15,610 --> 01:12:18,290
it doesn't work that's nicely

1184
01:12:18,620 --> 01:12:19,760
so again

1185
01:12:19,800 --> 01:12:21,770
i would recommend not to use it

1186
01:12:25,240 --> 01:12:27,340
so then comes the last

1187
01:12:27,840 --> 01:12:32,540
the last hope for you making and use of these bounds which is the quantitative

1188
01:12:33,830 --> 01:12:35,510
and again it's very

1189
01:12:35,530 --> 01:12:42,470
difficult to actually make use of it because you can very easily make very easily

1190
01:12:44,160 --> 01:12:47,890
misled but by what you think

1191
01:12:48,390 --> 01:12:52,260
OK so the goal is somehow to use what's

1192
01:12:52,310 --> 01:12:54,300
appears in the bound

1193
01:12:54,310 --> 01:12:59,390
to get in spirit inspiration for making new algorithm or for modifying your i mean

1194
01:12:59,390 --> 01:13:00,910
the way such that it

1195
01:13:00,930 --> 01:13:03,050
performs better

1196
01:13:03,070 --> 01:13:07,080
but in general it won't give you

1197
01:13:07,160 --> 01:13:10,370
the optimal value for the alpha was things like this

1198
01:13:11,140 --> 01:13:12,200
it will only

1199
01:13:12,350 --> 01:13:14,640
somehow tell you

1200
01:13:14,660 --> 01:13:16,760
how the

1201
01:13:16,800 --> 01:13:21,120
OK where the complexity comes from or where

1202
01:13:21,200 --> 01:13:23,350
is it that your class of function

1203
01:13:23,370 --> 01:13:25,180
miss may overfit

1204
01:13:25,240 --> 01:13:29,620
why is it that your cluster function may overfit and it will explain

1205
01:13:29,620 --> 01:13:34,280
this in terms of what is the relevance structure of this class that

1206
01:13:34,350 --> 01:13:38,240
it controls the complexity and the overfitting behaviour so for example

1207
01:13:38,640 --> 01:13:40,530
if you take

1208
01:13:40,550 --> 01:13:44,600
function class that does that is parametrized by center number of parameter you would say

1209
01:13:44,600 --> 01:13:50,060
well let's not use too many parameters because maybe it becomes too complex and i

1210
01:13:50,060 --> 01:13:53,490
i might overfit but then when you compute

1211
01:13:53,530 --> 01:13:55,850
these geometry quantities for this

1212
01:13:55,850 --> 01:13:59,740
function class it may very well up on that

1213
01:13:59,760 --> 01:14:04,950
after some number of parameters the complexity does not grow very much if you add

1214
01:14:04,950 --> 01:14:10,160
someone got behind will alter hit a metal pipe

1215
01:14:10,180 --> 01:14:13,100
strong pi allowed set

1216
01:14:15,550 --> 01:14:18,550
a little over began to associate

1217
01:14:18,560 --> 01:14:22,500
that sounds like noise with the appearance of

1218
01:14:22,520 --> 01:14:23,900
the white rabbit

1219
01:14:23,910 --> 01:14:27,680
well white rat is not even fear

1220
01:14:27,700 --> 01:14:31,180
but what about the sound from the part that scary

1221
01:14:31,910 --> 01:14:37,670
yes a lot all this part of natural for a very long was there was

1222
01:14:37,670 --> 01:14:43,090
allowed and that room all of this would be great of which only somewhere here

1223
01:14:43,480 --> 01:14:44,320
in that district

1224
01:14:44,810 --> 01:14:46,570
however as well

1225
01:14:46,580 --> 01:14:49,510
and so the the

1226
01:14:49,660 --> 01:14:54,250
exposure to this once

1227
01:14:54,270 --> 01:15:01,330
produced a few reactions our because it coincided with the appearance of the white rat

1228
01:15:01,430 --> 01:15:04,060
that studio substitution

1229
01:15:04,070 --> 01:15:07,710
i began to her and so the experience of a rat

1230
01:15:07,730 --> 01:15:09,820
began to

1231
01:15:09,830 --> 01:15:15,520
you both that the response in the lower so we just like to how what

1232
01:15:15,520 --> 01:15:20,600
happiness to the substitution three so that you take away the

1233
01:15:20,610 --> 01:15:22,520
take away a lot of noise

1234
01:15:22,530 --> 01:15:24,530
three the white rat

1235
01:15:24,550 --> 01:15:26,060
what happens

1236
01:15:26,080 --> 01:15:29,590
we started

1237
01:15:29,970 --> 01:15:32,800
you can start your brain

1238
01:15:32,800 --> 01:15:36,830
because john watts

1239
01:15:36,850 --> 01:15:39,300
has shown

1240
01:15:39,320 --> 01:15:41,730
that he and producer

1241
01:15:41,740 --> 01:15:46,560
an emotional reaction conditions little baby

1242
01:15:46,590 --> 01:15:48,490
two theory

1243
01:15:48,500 --> 01:15:52,260
or be delighted any object that we wish

1244
01:15:52,280 --> 01:15:56,350
to history ability

1245
01:15:56,370 --> 01:16:03,740
we've talked about stimulus generalization wasn't simply white rat produced reaction by

1246
01:16:03,740 --> 01:16:06,260
watson found the

1247
01:16:06,280 --> 01:16:08,650
fear generalize to other

1248
01:16:08,670 --> 01:16:11,380
so stimuli such as

1249
01:16:11,400 --> 01:16:14,970
rabbi dog for club for

1250
01:16:14,970 --> 01:16:17,980
in the same cluster that if you see in that video

1251
01:16:18,690 --> 01:16:21,020
john what his beer

1252
01:16:21,030 --> 01:16:24,550
five if you're thinking about same one

1253
01:16:24,650 --> 01:16:25,890
i see

1254
01:16:25,910 --> 01:16:28,730
he has appeared on the scene allow this

1255
01:16:28,740 --> 01:16:30,550
really afraid

1256
01:16:30,570 --> 01:16:31,990
is acquired

1257
01:16:32,000 --> 01:16:34,880
here the prior to both

1258
01:16:35,630 --> 01:16:36,730
like that

1259
01:16:36,750 --> 01:16:40,670
in two that with the part

1260
01:16:40,700 --> 01:16:46,520
and the possible for just the second series

1261
01:16:46,530 --> 01:16:49,280
questions have come to rest

1262
01:16:53,590 --> 01:16:56,550
during world

1263
01:17:00,050 --> 01:17:09,010
the in cident so you know said yes so that's the case

1264
01:17:09,020 --> 01:17:17,960
exactly right so the question is is this a case stimulus generalization it is because

1265
01:17:17,990 --> 01:17:21,390
he was condition with white rat in that

1266
01:17:21,420 --> 01:17:24,080
conditioning generalize to

1267
01:17:24,400 --> 01:17:30,710
objects that in some way or similar to what they white wine

1268
01:17:30,710 --> 01:17:32,960
so same the reaction

1269
01:17:32,990 --> 01:17:34,860
was generated

1270
01:17:37,870 --> 01:17:39,050
we it our

1271
01:17:40,800 --> 01:17:44,420
OK so that's why

1272
01:17:47,270 --> 01:17:51,060
watson was simply interested in

1273
01:17:51,100 --> 01:17:53,800
making these from

1274
01:17:53,830 --> 01:17:56,290
i mean my life

1275
01:17:56,300 --> 01:18:05,510
he was interested also in the in the philosophical importance of what he was doing

1276
01:18:08,070 --> 01:18:14,470
to him the experimental album said something

1277
01:18:14,480 --> 01:18:18,310
you know what i said was that

1278
01:18:18,340 --> 01:18:20,650
really human beings are

1279
01:18:20,670 --> 01:18:22,250
pretty mountain

1280
01:18:22,260 --> 01:18:25,400
to produce

1281
01:18:25,460 --> 01:18:28,790
when we try to understand ourselves in

1282
01:18:28,790 --> 01:18:32,330
why we are where we are personalities

1283
01:18:32,360 --> 01:18:35,890
our behavior our emotions and so on

1284
01:18:35,970 --> 01:18:39,790
we often wonder you know is

1285
01:18:39,800 --> 01:18:42,960
is our biology articles

1286
01:18:44,510 --> 01:18:47,380
has our experience for us

1287
01:18:47,410 --> 01:18:49,190
to be who we are

1288
01:18:49,220 --> 01:18:52,370
or the way we talk about that

1289
01:18:52,370 --> 01:18:58,400
the phone content is provided by MIT opencourseware under a creative commons license

1290
01:18:58,480 --> 01:19:07,300
additional information about relations and MIT opencourseware in general is available OCW MIT you

1291
01:19:07,320 --> 01:19:15,270
last time we were talking about the valence bond model for describing the bonding in

1292
01:19:15,270 --> 01:19:18,000
particular the binding

1293
01:19:18,010 --> 01:19:22,540
between the atoms in the polyatomic molecules

1294
01:19:22,550 --> 01:19:25,070
and we saw that the key

1295
01:19:25,120 --> 01:19:27,610
after this description

1296
01:19:27,660 --> 01:19:29,420
was allowing the

1297
01:19:29,430 --> 01:19:33,510
i wavefunctions individual wavefunctions

1298
01:19:33,530 --> 01:19:35,750
and after

1299
01:19:35,760 --> 01:19:37,630
two constructively

1300
01:19:38,900 --> 01:19:41,510
interfere themselves

1301
01:19:41,580 --> 01:19:46,740
form some hybrid wave functions or some hybrid orbitals

1302
01:19:46,750 --> 01:19:50,430
and then it goes hybrid wave functions

1303
01:19:50,450 --> 01:19:58,670
that overlap with the wave functions of another atom to form a chemical bond

1304
01:19:58,680 --> 01:20:02,590
and in particular what we treated last time

1305
01:20:02,610 --> 01:20:04,700
is this at e three

1306
01:20:05,750 --> 01:20:07,610
wave functions

1307
01:20:07,660 --> 01:20:09,960
there were centered on carbon

1308
01:20:09,970 --> 01:20:14,020
percent nitrogen that was centered on oxygen

1309
01:20:14,030 --> 01:20:16,090
and we saw that

1310
01:20:16,140 --> 01:20:23,700
he says the three functions for this linear combination or this destructive and constructive between

1311
01:20:23,700 --> 01:20:26,410
the best way function

1312
01:20:26,420 --> 01:20:28,380
and the three

1313
01:20:28,430 --> 01:20:36,650
two the wave functions form these as the three functions correspondingly these as three states

1314
01:20:36,660 --> 01:20:41,980
and as i said we saw the carbon we saw the nitrogen so that are

1315
01:20:44,300 --> 01:20:46,680
and those with functions

1316
01:20:46,690 --> 01:20:48,880
and being appointed

1317
01:20:48,890 --> 01:20:54,890
to the corner to the vertex of the factor graph worthy at all

1318
01:20:54,900 --> 01:20:58,850
i was at the centre that that would drawn so in the case of nothing

1319
01:21:00,060 --> 01:21:03,610
you find the hydrogen to each one of those

1320
01:21:03,620 --> 01:21:08,780
sp three hybrid wavefunctions what you get is

1321
01:21:08,840 --> 01:21:12,740
a tetrahedral geometry around the harbour

1322
01:21:12,790 --> 01:21:14,910
if you hear nitrogen

1323
01:21:14,930 --> 01:21:16,740
where does

1324
01:21:16,750 --> 01:21:22,410
as the freeway functions around new find to three hydrogens

1325
01:21:22,430 --> 01:21:24,090
and you've got trick and all

1326
01:21:24,140 --> 01:21:30,350
pyramid and the geometry of the ammonia molecule with those two long hair sticking out

1327
01:21:31,750 --> 01:21:36,730
at the end another per vertex of the factor in front but remember we talked

1328
01:21:36,730 --> 01:21:39,530
about the shape of the molecule

1329
01:21:39,550 --> 01:21:44,950
it has being described by the positions of the atoms and not the positions of

1330
01:21:46,630 --> 01:21:51,100
and we talked about water water sp three hybridized

1331
01:21:51,110 --> 01:21:55,980
we have two hydrogens to what we want to find the plane then

1332
01:21:56,030 --> 01:22:01,190
and then we have two long here electron sticking out of the oxygen those going

1333
01:22:01,190 --> 01:22:02,550
to play a big role

1334
01:22:02,570 --> 01:22:06,980
in some binding we're going to look at the end of the lecture today

1335
01:22:07,000 --> 01:22:09,160
right so

1336
01:22:09,210 --> 01:22:14,040
we've got to move on and we got to talking about another kind of hybridization

1337
01:22:14,040 --> 01:22:17,470
which we started to talk about their time which is the s

1338
01:22:18,020 --> 01:22:22,140
two hybridisation we talked about for i

1339
01:22:22,150 --> 01:22:24,780
and we saw the PSP two

1340
01:22:26,350 --> 01:22:28,800
and being in the plane

1341
01:22:28,850 --> 01:22:34,400
which in the case of four we then bonded hydrogen to those at two wavefunctions

1342
01:22:34,400 --> 01:22:38,800
functions we got plane molecule or on h three

1343
01:22:38,850 --> 01:22:41,010
carbon can also undergo

1344
01:22:41,020 --> 01:22:44,520
there is sp two hybridization

1345
01:22:44,570 --> 01:22:47,780
so let's take a look at it now

1346
01:22:47,830 --> 01:22:50,050
right so i

1347
01:22:50,070 --> 01:22:54,440
in the case of carbon we have to do this electron promotion that we talked

1348
01:22:54,440 --> 01:22:58,790
about also in the case of the sp three hybridization

1349
01:22:58,840 --> 01:23:01,150
and then we let now

1350
01:23:01,200 --> 01:23:06,090
one of the two s wave functions in two of the two p wave functions

1351
01:23:06,090 --> 01:23:08,340
hybridize constructively in

1352
01:23:08,390 --> 01:23:10,970
destructively interfere

1353
01:23:11,020 --> 01:23:13,190
and the result is three

1354
01:23:13,200 --> 01:23:17,090
the two wavefunctions or three SP two stay

1355
01:23:17,100 --> 01:23:19,560
one electron in each one of them

1356
01:23:19,610 --> 01:23:20,860
and then

1357
01:23:20,910 --> 01:23:25,460
one of those p orbitals are those p wave functions and the carbon is sometimes

1358
01:23:25,860 --> 01:23:32,390
that's just the atomic wave function the atomic orbital on carbon

1359
01:23:32,410 --> 01:23:36,140
and if we if we look at the

1360
01:23:36,160 --> 01:23:39,630
picture of all of those wavefunctions functions here it is

1361
01:23:39,650 --> 01:23:45,500
this is the two as on the current easy to see why

1362
01:23:45,560 --> 01:23:50,340
what we do is we let these three for example

1363
01:23:50,390 --> 01:23:57,780
these three constructively and destructively interfere to form these three sp two hybrid orbitals

1364
01:23:57,800 --> 01:24:00,160
or hybrid functions

1365
01:24:00,210 --> 01:24:03,480
the result is that they look like this

1366
01:24:03,500 --> 01:24:06,430
the result is they all have

1367
01:24:06,450 --> 01:24:08,960
a large positive

1368
01:24:08,980 --> 01:24:12,780
and then to the constructive interference

1369
01:24:12,790 --> 01:24:16,140
and they all have a small negative role

1370
01:24:16,180 --> 01:24:19,670
and all the rest of the pictures that we're going to draw we're not going

1371
01:24:19,670 --> 01:24:24,540
to draw that small negative or is it just makes it hard to draw

1372
01:24:25,990 --> 01:24:31,670
but the bottom line is that these three low-flying plane

1373
01:24:31,680 --> 01:24:37,190
and then of course we still have that PY atomic wavefunctions centered on the carbon

1374
01:24:37,210 --> 01:24:40,020
that is designed for

1375
01:24:40,070 --> 01:24:41,760
right now i'm going to do

1376
01:24:43,760 --> 01:24:46,530
i'm going to put all of these three wave function and

1377
01:24:46,560 --> 01:24:47,800
same plant

1378
01:24:47,810 --> 01:24:50,730
since they all have the same origin

1379
01:24:50,810 --> 01:24:51,650
so on

1380
01:24:51,670 --> 01:24:53,380
that's what i'm doing right there

1381
01:24:53,400 --> 01:24:55,360
here it is for the carbon

1382
01:24:55,360 --> 01:25:00,120
it's clear that the brain uses unlabeled data in quite quite effective

1383
01:25:00,140 --> 01:25:00,930
well we

1384
01:25:00,960 --> 01:25:03,180
with things that effective in any case

1385
01:25:04,850 --> 01:25:05,760
OK so

1386
01:25:05,780 --> 01:25:09,370
now what does this have to do is john

1387
01:25:09,380 --> 01:25:12,700
there are two assumptions which can be made

1388
01:25:12,880 --> 01:25:16,580
which one of them is completely in line

1389
01:25:16,590 --> 01:25:19,570
what we discussed in the other one is

1390
01:25:21,320 --> 01:25:22,580
quite a bit

1391
01:25:22,590 --> 01:25:25,930
in line with maybe

1392
01:25:26,020 --> 01:25:31,850
more broadly of the manifold as having a geometric structure in the data so the

1393
01:25:31,850 --> 01:25:34,900
manifold assumption basically if as

1394
01:25:36,790 --> 01:25:39,680
for data

1395
01:25:39,690 --> 01:25:41,560
so it comes

1396
01:25:41,570 --> 01:25:43,160
from the manifold

1397
01:25:43,190 --> 01:25:46,680
and the distance along the manifold is the natural

1398
01:25:46,700 --> 01:25:49,750
a measure of how close

1399
01:25:49,770 --> 01:25:50,860
the point

1400
01:25:51,010 --> 01:25:56,040
i'll i'll discuss and the cluster assumption is basically saying that there are some clusters

1401
01:25:56,040 --> 01:25:57,910
in the data in

1402
01:25:58,930 --> 01:26:02,830
arguably the clusters also geometric objects

1403
01:26:10,100 --> 01:26:21,190
let's look at the intuition though if i just give you two to label point

1404
01:26:21,190 --> 01:26:23,430
this is read by the way it's not a black ink

1405
01:26:23,460 --> 01:26:27,560
looks black but we know that red doesn't exist

1406
01:26:27,560 --> 01:26:35,670
so there is red points and there is

1407
01:26:35,670 --> 01:26:37,850
the point

1408
01:26:40,880 --> 01:26:45,330
this still a labelled points right if we just have those two points

1409
01:26:45,340 --> 01:26:46,960
that presumably

1410
01:26:47,020 --> 01:26:49,000
the natural way would be to

1411
01:26:49,020 --> 01:26:52,930
i have the bound which is like this

1412
01:26:53,460 --> 01:26:59,990
most of us would agree probably now here's the question well if i have already

1413
01:26:59,990 --> 01:27:03,950
pointed out well this is not the black point is are at points and the

1414
01:27:03,960 --> 01:27:08,720
blue point here but i tell you well all my data leaves on the manifold

1415
01:27:08,720 --> 01:27:13,920
which is a union of two circles which is a one-dimensional manifold

1416
01:27:13,940 --> 01:27:18,730
well bound doesn't seem natural anymore

1417
01:27:18,740 --> 01:27:21,140
something like this seems far better

1418
01:27:21,180 --> 01:27:22,610
so basically

1419
01:27:22,610 --> 01:27:27,920
what does it say there's a the geometry of the data changes our notion of

1420
01:27:27,950 --> 01:27:33,110
you know where the boundary should be at which point similar from our think before

1421
01:27:33,140 --> 01:27:36,950
we thought that basically it's all based on the distance in the euclidean space

1422
01:27:37,350 --> 01:27:42,700
the only thing that basically are all based on the fact that this

1423
01:27:42,710 --> 01:27:44,620
two circles

1424
01:27:44,620 --> 01:27:48,590
i have well effectively clusters right this is classed the middle

1425
01:27:48,640 --> 01:27:53,890
class there is a small circle and the fact that there are two connected component

1426
01:27:53,910 --> 01:27:56,540
if you wish

1427
01:27:57,360 --> 01:28:02,340
here is is something similar but in a slightly different set

1428
01:28:02,360 --> 01:28:07,180
so you have to read point black point and blue points

1429
01:28:07,230 --> 01:28:11,620
and there is an unknown point of this is the question mark point OK

1430
01:28:22,600 --> 01:28:26,340
this is really an anti-communist

1431
01:28:30,250 --> 01:28:33,580
that bad

1432
01:28:33,580 --> 01:28:36,620
it's so

1433
01:28:37,160 --> 01:28:43,720
how would you classify this point well if you don't have any information radio classifier

1434
01:28:43,720 --> 01:28:44,680
is blue

1435
01:28:44,680 --> 01:28:48,710
presumably well it's kind of cool to to the blue points and if you have

1436
01:28:48,710 --> 01:28:53,760
a linear separator is probably somewhere like in the middle between those reported to the

1437
01:28:53,760 --> 01:28:58,710
blue points out if i tell you about all the data lies on this manifold

1438
01:28:58,720 --> 01:29:03,490
suddenly it seems more natural to classify this point as belonging to one of those

1439
01:29:03,490 --> 01:29:04,990
two points right

1440
01:29:06,610 --> 01:29:08,240
the point here

1441
01:29:10,020 --> 01:29:14,640
probably one of those because this is the proximity on the manifold that itself so

1442
01:29:14,640 --> 01:29:20,870
we kind of saying that the proximity on the manifold probably gives us about the

1443
01:29:20,870 --> 01:29:25,360
idea that the euclidean proximity so euclidean proximity would be the distance between this point

1444
01:29:25,360 --> 01:29:29,580
and this is clearly the smallest distance but somehow breaking

1445
01:29:29,590 --> 01:29:33,230
so the outer space doesn't seem to be the right thing to do and this

1446
01:29:33,230 --> 01:29:36,760
is the intuition that may be completely wrong it may actually be that this is

1447
01:29:36,760 --> 01:29:41,590
the correct thing to do in this curve is completely irrelevant we don't know this

1448
01:29:41,680 --> 01:29:43,400
this the

1449
01:29:45,580 --> 01:29:50,100
this event both intuition and to some degree an empirical fact

1450
01:29:50,160 --> 01:29:55,430
that this actually is the right thing to do to go along the

1451
01:29:55,480 --> 01:30:01,920
OK so the sort of implies that this is an empirical fact this is

1452
01:30:01,920 --> 01:30:04,220
what you do if you just used so

1453
01:30:04,240 --> 01:30:05,580
imagine i have

1454
01:30:05,580 --> 01:30:12,040
digits the ones i showed you and they live in the seven hundred basically each

1455
01:30:12,060 --> 01:30:15,120
picture has seven hundred something pixels

1456
01:30:15,190 --> 01:30:21,100
and really when this several hundred dimensional space now i can do two things

1457
01:30:21,120 --> 01:30:26,080
i can feel the classifier so i have a bunch of labelled examples

1458
01:30:26,100 --> 01:30:30,640
like if i get maybe thirty for each pixel and i just think the nearest

1459
01:30:30,640 --> 01:30:35,030
for new point four new in which i just think the nearest distance is based

1460
01:30:35,030 --> 01:30:38,880
on the pixels represents and

1461
01:30:38,890 --> 01:30:40,420
i look

1462
01:30:40,500 --> 01:30:44,980
then cheque whether this distance is you know what is the class of the point

1463
01:30:45,240 --> 01:30:47,510
which is closest to that point

1464
01:30:47,530 --> 01:30:51,810
so if it's a seven labelled this seven right nearest neighbour classifier is a simple

1465
01:30:51,810 --> 01:30:54,360
one of the simplest possible classifiers

1466
01:30:55,730 --> 01:31:01,640
that's one thing that alternative to that is the geodesic nearest neighbours when i take

1467
01:31:01,650 --> 01:31:03,630
a bunch unlabeled points

1468
01:31:03,650 --> 01:31:05,250
i construct the graph

1469
01:31:05,410 --> 01:31:09,410
and i look for the shortest distance on this graph

1470
01:31:10,480 --> 01:31:15,150
so i constructed graph using my unlabelled data for the first one nearest neighbour only

1471
01:31:15,150 --> 01:31:18,030
uses labelled data the second one on the users

1472
01:31:18,190 --> 01:31:23,410
uses both labeled and unlabeled so the second basically tells me that well instead of

1473
01:31:23,410 --> 01:31:28,260
looking for distances and the euclidean space we will look for distances on the ground

1474
01:31:28,280 --> 01:31:33,660
well what happens

1475
01:31:33,710 --> 01:31:37,880
it turns out that if you do this basically use unlabelled data to construct a

1476
01:31:37,880 --> 01:31:40,590
better notion of distance

1477
01:31:42,540 --> 01:31:46,910
the error rate so misclassification rate goes down

1478
01:31:47,860 --> 01:31:49,460
quite significantly

1479
01:31:51,920 --> 01:31:54,000
not quite effective tool but

1480
01:31:54,020 --> 01:31:55,910
close to that

1481
01:31:55,910 --> 01:32:00,910
so by just incorporating this unlabelled data into the equation

1482
01:32:00,940 --> 01:32:06,100
you can sometimes get a lot of improvement and

1483
01:32:06,120 --> 01:32:08,310
in classifier and

1484
01:32:08,310 --> 01:32:11,280
and if i said so i i be

1485
01:32:12,910 --> 01:32:18,800
so this constraint is essentially saying that everything is correctly classified in fact this right

1486
01:32:18,800 --> 01:32:22,490
hand side is equal to zero that means every point was correctly classified if it

1487
01:32:22,490 --> 01:32:26,450
is equal to one that means every point is correctly classified this margin one

1488
01:32:26,450 --> 01:32:30,920
and so i the slack variables where you don't want every single point to be

1489
01:32:30,920 --> 01:32:33,080
correctly classified with this margin

1490
01:32:33,140 --> 01:32:37,370
OK so that's i i is actually exactly the hinge loss

1491
01:32:37,380 --> 01:32:41,860
measured at every data point x i

1492
01:32:41,910 --> 01:32:43,820
then one can show

1493
01:32:43,870 --> 01:32:47,190
that the optimal solution w star for this

1494
01:32:47,190 --> 01:32:51,090
well actually have an expansion in terms of the data points exercise

1495
01:32:51,120 --> 01:32:53,580
summation and phi x i

1496
01:32:53,590 --> 01:32:55,400
there are many ways to see this

1497
01:32:55,450 --> 01:32:59,840
we will see this using the property of reproducing kernel hilbert spaces and using the

1498
01:32:59,960 --> 01:33:02,110
so-called represented here

1499
01:33:02,920 --> 01:33:05,980
so then you can go to what is called the dual setting where you see

1500
01:33:05,980 --> 01:33:10,440
the w star does this thing replace this over there and you have this whole

1501
01:33:10,440 --> 01:33:18,150
entire optimisation in terms of alpha first and then solve the optimisation of around us

1502
01:33:22,340 --> 01:33:25,530
is actually a good point

1503
01:33:26,970 --> 01:33:28,700
say something

1504
01:33:30,640 --> 01:33:32,550
minimum norm

1505
01:33:32,560 --> 01:33:36,870
so what you are trying to do with support vector machines is actually minimize the

1506
01:33:36,870 --> 01:33:40,070
norm of the function www

1507
01:33:41,900 --> 01:33:43,120
this last

1508
01:33:43,140 --> 01:33:44,390
the of the blue

1509
01:33:46,550 --> 01:33:49,610
so this corresponds directly more or less

1510
01:33:49,630 --> 01:33:51,980
regularized least squares

1511
01:33:51,980 --> 01:33:57,050
where we have replaced the least squares loss by the hinge loss

1512
01:33:57,080 --> 01:34:00,470
is that a correspondence to the minimum norm solution

1513
01:34:00,470 --> 01:34:01,580
you might ask

1514
01:34:04,980 --> 01:34:10,760
this is how the standard development of support vector machines goals

1515
01:34:10,780 --> 01:34:20,940
the problem is that you have a bunch of data points like this

1516
01:34:20,980 --> 01:34:23,520
you are data points

1517
01:34:23,540 --> 01:34:27,150
and some of them are labeled plus some of them are labeled minus

1518
01:34:27,230 --> 01:34:31,850
and you want to come up with a linear classifier that separates the data right

1519
01:34:31,890 --> 01:34:37,460
support such a linear classifier exists that means there is w which would correctly classify

1520
01:34:37,460 --> 01:34:39,250
all your data points correctly

1521
01:34:39,890 --> 01:34:43,870
obviously if there is one w there are many w because you can move the

1522
01:34:43,950 --> 01:34:48,550
w just a little bit and you would still get correct classification

1523
01:34:48,600 --> 01:34:53,720
so then you can solve the following problem minimize

1524
01:34:54,630 --> 01:34:56,460
doctor w

1525
01:34:56,460 --> 01:34:58,750
subject to

1526
01:34:58,800 --> 01:35:01,140
why i times

1527
01:35:01,200 --> 01:35:03,130
w dot x i

1528
01:35:03,150 --> 01:35:04,990
plus b

1529
01:35:05,030 --> 01:35:07,850
greater than or equal to one

1530
01:35:07,880 --> 01:35:10,820
this is often called

1531
01:35:10,900 --> 01:35:12,890
this thing is often called

1532
01:35:12,940 --> 01:35:16,640
the support vector machine for the separable case

1533
01:35:16,660 --> 01:35:17,760
OK so you say

1534
01:35:17,760 --> 01:35:21,680
as assume have a finite number of data points and assume these data points are

1535
01:35:21,680 --> 01:35:26,150
separable i want to find the linear classifier that separates my data there are too

1536
01:35:26,150 --> 01:35:28,850
many linear classifiers separate my data

1537
01:35:28,880 --> 01:35:33,210
the solution space is not unique because doesn't have a single element

1538
01:35:33,210 --> 01:35:36,130
and so let me take the minimum norm solution

1539
01:35:36,150 --> 01:35:40,140
so let me minimize www subject to these constraints

1540
01:35:41,040 --> 01:35:44,140
particular problem seems to have a geometric

1541
01:35:44,190 --> 01:35:47,310
interpretation in terms of something called the margins

1542
01:35:47,320 --> 01:35:49,370
the margin being the distance

1543
01:35:50,060 --> 01:35:55,550
each w which is a candidate classifier the distance to the nearest point

1544
01:35:57,940 --> 01:36:03,640
so in some sense this is really like taking the minimum norm solution

1545
01:36:05,540 --> 01:36:08,950
you again in the usual setting in our and if you do that points live

1546
01:36:08,950 --> 01:36:10,660
in rk

1547
01:36:10,720 --> 01:36:12,560
you know that very soon

1548
01:36:14,580 --> 01:36:16,190
well not be achievable

1549
01:36:16,200 --> 01:36:20,230
because data points going to be linearly separable if you have lots of data point

1550
01:36:20,250 --> 01:36:24,730
so is this feasible set will become empty very soon

1551
01:36:24,750 --> 01:36:25,860
and so

1552
01:36:25,920 --> 01:36:31,120
what people suggested for example that makes that them that's what a slack variable xi

1553
01:36:32,760 --> 01:36:35,690
and this i i

1554
01:36:38,310 --> 01:36:39,610
so that

1555
01:36:39,620 --> 01:36:42,990
if this is you know that means the point is correctly classified as this is

1556
01:36:42,990 --> 01:36:47,950
nonzero the point may be misclassified as so trying to minimise this surprise trying to

1557
01:36:47,950 --> 01:36:50,270
minimize the number of classification

1558
01:36:50,270 --> 01:36:53,480
and this is of course to the north

1559
01:36:56,020 --> 01:37:01,960
if you look at the presentation in many places the way this is justified

1560
01:37:01,990 --> 01:37:03,360
is the following

1561
01:37:03,420 --> 01:37:04,940
they were first tell you

1562
01:37:04,960 --> 01:37:06,830
the right thing to do

1563
01:37:07,670 --> 01:37:11,250
use the maximum margin classifier

1564
01:37:11,250 --> 01:37:12,790
if data is separable

1565
01:37:12,800 --> 01:37:17,130
it's a well defined problem there the maximum margin classifier which corresponds to the minimum

1566
01:37:17,130 --> 01:37:19,340
norm solution

1567
01:37:19,390 --> 01:37:22,550
but we live in a world where data may not be separable or at least

1568
01:37:22,550 --> 01:37:27,280
linearly separable so let's do something about it let's add slack variables and converted into

1569
01:37:27,280 --> 01:37:28,720
this problem this seems

1570
01:37:29,900 --> 01:37:34,040
and this is the algorithm that then gets used

1571
01:37:34,050 --> 01:37:36,010
now what is pathological

1572
01:37:36,010 --> 01:37:39,550
this is a lecture five in linear algebra

1573
01:37:41,030 --> 01:37:42,710
it will complete

1574
01:37:42,730 --> 01:37:46,600
this chapter of the book

1575
01:37:46,620 --> 01:37:50,980
so the last section of this chapter is two point seven

1576
01:37:52,050 --> 01:37:54,800
talks about permutations

1577
01:37:54,800 --> 01:37:56,350
which finished

1578
01:37:56,370 --> 01:37:57,850
the previous lecture

1579
01:37:57,860 --> 01:38:01,570
and transposase which also came in the previous lecture

1580
01:38:01,640 --> 01:38:04,530
there's a little more to do with those guys

1581
01:38:04,560 --> 01:38:07,890
permutations and transposase

1582
01:38:07,890 --> 01:38:11,900
but then the heart of the lecture will be

1583
01:38:11,960 --> 01:38:17,380
the beginning of what you could say is the beginning of linear algebra

1584
01:38:17,390 --> 01:38:21,810
the beginning of real linear algebra which is

1585
01:38:21,820 --> 01:38:28,890
seeing a bigger picture with vector spaces not just vectors but the basis vectors

1586
01:38:28,920 --> 01:38:31,680
and subspaces of those spaces

1587
01:38:31,680 --> 01:38:32,730
so we're

1588
01:38:32,730 --> 01:38:35,760
a little ahead of the syllabus

1589
01:38:35,790 --> 01:38:39,140
which is good because we're coming to the place where

1590
01:38:39,890 --> 01:38:42,010
there's a lot to do

1591
01:38:43,900 --> 01:38:47,390
to begin with permutation

1592
01:38:47,400 --> 01:38:48,620
can i just

1593
01:38:51,890 --> 01:38:54,240
so the permutations

1594
01:38:56,980 --> 01:38:59,430
the matrices b

1595
01:38:59,480 --> 01:39:02,140
and they execute

1596
01:39:02,150 --> 01:39:05,210
croix state

1597
01:39:08,900 --> 01:39:13,900
we may need them we may have a perfectly good matrix of perfect matrix a

1598
01:39:13,900 --> 01:39:19,060
that is invertible that we can solve a x equal b

1599
01:39:19,060 --> 01:39:20,510
but to do it

1600
01:39:20,540 --> 01:39:22,850
i've got

1601
01:39:22,930 --> 01:39:28,310
to allow myself that extra freedom that ever zero shows up in the pivot position

1602
01:39:28,320 --> 01:39:30,060
i move it away

1603
01:39:30,060 --> 01:39:31,730
i get a non zero

1604
01:39:31,740 --> 01:39:33,750
i get a proper pivot there

1605
01:39:34,370 --> 01:39:37,460
exchanging from the row below

1606
01:39:37,490 --> 01:39:39,310
and you've seen that already

1607
01:39:39,340 --> 01:39:43,180
and i just want to collect the ideas together

1608
01:39:43,190 --> 01:39:44,430
and in in

1609
01:39:44,460 --> 01:39:49,750
principle i could even have have to do that two times or more times

1610
01:39:49,780 --> 01:39:52,280
so i have to allow

1611
01:39:52,280 --> 01:39:54,310
to complete the

1612
01:39:54,340 --> 01:39:55,720
the theory

1613
01:39:55,780 --> 01:39:59,330
the possibility that i take my matrix a

1614
01:39:59,370 --> 01:40:03,560
i start elimination i find out that i need ro exchanges

1615
01:40:03,590 --> 01:40:06,560
and i do it and continue i finish

1616
01:40:09,830 --> 01:40:12,090
i want to do is say

1617
01:40:12,110 --> 01:40:16,030
and i will make a big project out of this

1618
01:40:16,080 --> 01:40:19,310
what happens to a parallel u

1619
01:40:19,340 --> 01:40:22,150
so a typical value

1620
01:40:23,280 --> 01:40:24,550
l u

1621
01:40:24,560 --> 01:40:25,840
this was

1622
01:40:25,860 --> 01:40:31,710
matrix al with ones on the diagonal and zeros above and

1623
01:40:32,020 --> 01:40:36,960
multipliers below and this we you know we know

1624
01:40:37,020 --> 01:40:41,960
with zero down here

1625
01:40:41,960 --> 01:40:49,000
that's only possible that that description of elimination assumes that we don't have p

1626
01:40:49,120 --> 01:40:51,500
we don't have any rho exchange

1627
01:40:51,500 --> 01:40:52,210
and now

1628
01:40:52,240 --> 01:40:54,340
i just want to say OK

1629
01:40:54,380 --> 01:40:58,990
how to account for o exchanges because that does

1630
01:40:59,000 --> 01:41:00,430
the p

1631
01:41:00,430 --> 01:41:02,030
in this

1632
01:41:02,080 --> 01:41:05,000
factorisation is the identity matrix

1633
01:41:05,030 --> 01:41:09,090
the rows are in good order we left them there

1634
01:41:09,150 --> 01:41:12,030
maybe i just add a little moment of

1635
01:41:12,080 --> 01:41:13,400
reality two

1636
01:41:15,060 --> 01:41:19,780
how matlab actually does elimination

1637
01:41:19,800 --> 01:41:26,780
matlab not only checks whether that payment is not zero as has every human would

1638
01:41:27,750 --> 01:41:34,400
it checks for is that big enough because it doesn't like very very small payments

1639
01:41:34,400 --> 01:41:36,870
events close to zero are

1640
01:41:36,900 --> 01:41:38,530
numerically bad

1641
01:41:38,580 --> 01:41:43,290
so actually if we ask matlab to solve the system it will do some elimination

1642
01:41:43,520 --> 01:41:45,830
some some rho exchanges

1643
01:41:45,880 --> 01:41:51,260
which we don't think it's necessary algebra doesn't say the necessary but

1644
01:41:52,930 --> 01:41:56,570
numerical accuracy says they are

1645
01:41:56,620 --> 01:41:58,560
well we're doing algebra

1646
01:42:00,260 --> 01:42:02,810
here we will say well what would

1647
01:42:02,820 --> 01:42:06,880
what the row exchanges do but we won't do them unless we have to

1648
01:42:07,240 --> 01:42:10,310
but we may have to

1649
01:42:10,370 --> 01:42:12,560
and there

1650
01:42:12,560 --> 01:42:15,310
the result is

1651
01:42:15,360 --> 01:42:16,830
it's hiding here

1652
01:42:16,850 --> 01:42:18,070
it's the

1653
01:42:18,120 --> 01:42:21,000
the main factor

1654
01:42:21,050 --> 01:42:25,160
this is the description of elimination with rho exchanges

1655
01:42:25,190 --> 01:42:29,410
so a equal value becomes

1656
01:42:33,800 --> 01:42:40,770
this act so that p is a matrix that does the row exchanges and actually

1657
01:42:41,010 --> 01:42:43,040
it does them

1658
01:42:43,190 --> 01:42:45,870
it gets the rose into the right order

1659
01:42:45,920 --> 01:42:48,750
in the good order where payments will not

1660
01:42:48,810 --> 01:42:53,290
one zero one appear in the pivot position where l

1661
01:42:53,310 --> 01:42:54,010
and you

1662
01:42:54,020 --> 01:42:57,660
we'll come out right as as a appear

1663
01:42:57,700 --> 01:43:01,440
so that's the that's the point

1664
01:43:01,450 --> 01:43:04,620
actually i don't want to labour the point

1665
01:43:04,810 --> 01:43:08,110
a permutation matrix

1666
01:43:08,110 --> 01:43:09,790
a is just ordered

1667
01:43:09,810 --> 01:43:14,680
which is very nice and traditionally the relations are specified in advance for us they

1668
01:43:14,840 --> 01:43:21,630
discovered automatically and that results in the output traditionally is relation specific whereas stress the

1669
01:43:21,630 --> 01:43:24,430
output is a relation independent

1670
01:43:24,450 --> 01:43:30,410
so textrunner which we actually unveiled back in its k seven is the first one

1671
01:43:30,470 --> 01:43:36,010
was the first web scale open a system by now it's extracted easily over a

1672
01:43:36,010 --> 01:43:43,070
billion distinct extractions at its peak it achieves about point nine precision which is quite

1673
01:43:43,070 --> 01:43:45,920
good but that's very low levels of recall

1674
01:43:47,010 --> 01:43:51,500
it definitely has a challenge in terms of recall and then when you when you're

1675
01:43:51,500 --> 01:43:54,390
dealing with the web you might allow us

1676
01:43:54,390 --> 01:43:59,170
some latitude in saying OK i didn't extracted from this sentence at this page how

1677
01:43:59,170 --> 01:44:01,340
about getting it from the next page

1678
01:44:01,350 --> 01:44:02,040
right so

1679
01:44:02,050 --> 01:44:06,300
but that is one of the trade offs in in text so how does textrunner

1680
01:44:06,300 --> 01:44:11,860
work well it uses fairly simple heuristics to identify

1681
01:44:11,890 --> 01:44:12,950
what the

1682
01:44:12,990 --> 01:44:18,430
proper nouns are what the entities are in the sentence the really hard part and

1683
01:44:18,430 --> 01:44:20,780
the real innovation is how do we get the

1684
01:44:20,800 --> 01:44:25,580
relation and so if we have tim berners-lee and the web

1685
01:44:25,720 --> 01:44:29,880
and we have a number of intervening words the the question is which of those

1686
01:44:29,880 --> 01:44:35,340
denote the relation is that the entire set of words is just the verb invented

1687
01:44:35,340 --> 01:44:39,730
and how do we do this in general right that's that's the technical question here

1688
01:44:39,750 --> 01:44:45,250
how do we figure out what the relation is and the mechanism textrunner use actually

1689
01:44:45,250 --> 01:44:49,700
was original paper use naivebayes but more recently we've shifted to

1690
01:44:49,720 --> 01:44:55,260
using a conditional random field CRF the basic idea is to view this problem as

1691
01:44:55,260 --> 01:44:57,840
a sequence labeling task we go

1692
01:44:57,850 --> 01:45:02,090
we start with the entity on the left in berners-lee and then we go word

1693
01:45:02,090 --> 01:45:05,970
by word in this era tells us OK this word is not part of the

1694
01:45:05,970 --> 01:45:10,140
relation this one is not this one is not the relation starts here

1695
01:45:10,160 --> 01:45:13,470
and then ends with the second entity so

1696
01:45:13,870 --> 01:45:18,040
this the CRF is learned and general

1697
01:45:18,050 --> 01:45:25,590
relation independent level and the reason this works is because it turns out that our

1698
01:45:25,590 --> 01:45:32,330
are relation independent close to tell us how people express relations in english

1699
01:45:32,560 --> 01:45:37,700
so this is what the system looks like we actually used distant supervision techniques i

1700
01:45:37,700 --> 01:45:43,340
won't go into that to automatically generate a hundred and eighty thousand training examples we

1701
01:45:43,340 --> 01:45:47,630
fed those to the CRF it learns an extractor and then we feed into web

1702
01:45:47,630 --> 01:45:55,150
corpus it produces it uses rather the learned model of relations that avoids any specific

1703
01:45:55,150 --> 01:46:01,000
nouns or verbs and that outputs a set of rock samples of this form

1704
01:46:01,030 --> 01:46:10,110
we then count the topples identify synonyms and index that output in lucene which in

1705
01:46:10,110 --> 01:46:13,910
turn allows us to do a set of of relational queries and i'll show you

1706
01:46:13,910 --> 01:46:18,650
a demo in a few minutes i just want to tell you first about what

1707
01:46:18,650 --> 01:46:22,350
happened after we came up with with textrunner

1708
01:46:22,360 --> 01:46:27,320
well first of all we we're excited that the system worked at all but it

1709
01:46:27,340 --> 01:46:32,120
certainly had plenty of errors so let me talk about two types of extraction errors

1710
01:46:32,400 --> 01:46:36,830
the first one is let's say we encounter the sentence al gore invented the internet

1711
01:46:37,280 --> 01:46:44,340
textrunner happily extract invented al gore internet and so we call this a sound correction

1712
01:46:44,340 --> 01:46:49,950
of a sound extraction rather of an incorrect facts right garbage in garbage out there's

1713
01:46:49,960 --> 01:46:57,420
a lot of incorrect information over on the web in textrunner happily extracts these incorrect

1714
01:46:57,420 --> 01:47:00,430
facts or or opinions

1715
01:47:00,450 --> 01:47:04,680
another kind of error that we see is actually an unsound extractions of if the

1716
01:47:04,710 --> 01:47:09,110
sentence is the cost of the war against iraq has risen above five hundred dollars

1717
01:47:09,110 --> 01:47:15,180
there i five hundred billion dollars five hundred trillion dollars then above the iraq five

1718
01:47:15,180 --> 01:47:19,700
hundred billion dollars is is really not sound extraction and our work is focused on

1719
01:47:21,590 --> 01:47:25,650
unsound extractions of this challenge is interesting as well

1720
01:47:26,500 --> 01:47:31,490
how do you filter unsound extractions one of the key idea is that we used

1721
01:47:31,490 --> 01:47:34,450
which is the one i want to highlight is using redundancy

1722
01:47:34,840 --> 01:47:39,860
over a massive corpus like the web it turns out that the more redundancy you

1723
01:47:40,640 --> 01:47:47,210
the more distinct clues you're able to find like barcelona mayor and downtown barcelona the

1724
01:47:47,210 --> 01:47:52,240
more distinct clues i have it's effectively like co training right i'm getting clues from

1725
01:47:52,240 --> 01:47:59,120
different angles leading me to be more and more confident than in fact extraction is

1726
01:47:59,130 --> 01:48:02,330
is sound and the other thing we can do is we can look at the

1727
01:48:02,330 --> 01:48:06,980
proportion of clues are among the mentions of the word so we can ask what

1728
01:48:06,980 --> 01:48:12,480
fraction of the times that i've seen barcelona say do i see clues that suggest

1729
01:48:12,480 --> 01:48:13,890
not to wild oats

1730
01:48:13,950 --> 01:48:18,680
it is a means of separating the data points to clusters which might be still

1731
01:48:18,680 --> 01:48:20,720
in and overlapping here

1732
01:48:20,720 --> 01:48:24,810
perfect is i mean in the ideal case it is perfectly if separated in this

1733
01:48:24,830 --> 01:48:28,350
part here it's simply means to

1734
01:48:28,370 --> 01:48:29,500
improve are

1735
01:48:29,520 --> 01:48:33,910
to work out the structure of the clustering structure but it's it's not i mean

1736
01:48:33,930 --> 01:48:35,000
could see how this

1737
01:48:35,020 --> 01:48:39,330
works in the next slides but it's not obvious

1738
01:48:47,410 --> 01:48:50,850
one thing which i already mentioned here we will see that later on

1739
01:48:51,140 --> 01:48:55,080
more closely is that in this case like the example we had it contains three

1740
01:48:55,080 --> 01:48:56,980
very clear clusters

1741
01:48:57,000 --> 01:48:59,290
now plot the i values of here

1742
01:48:59,600 --> 01:49:03,250
of the graph laplacian what will happen is so what plot here is that you

1743
01:49:03,250 --> 01:49:05,770
have hundred data points probably so and so

1744
01:49:05,830 --> 01:49:08,620
my matrix contains one hundred i values

1745
01:49:08,620 --> 01:49:10,470
that all of them next to each other

1746
01:49:10,500 --> 01:49:11,450
so what we see

1747
01:49:11,480 --> 01:49:14,580
you probably can see very low but

1748
01:49:14,620 --> 01:49:18,120
it is in fact he what he sees we have three i can which are

1749
01:49:18,140 --> 01:49:20,270
very very close to zero

1750
01:49:20,450 --> 01:49:23,020
there's a huge gap and then they are all the other ones

1751
01:49:23,080 --> 01:49:25,500
actually one can use that

1752
01:49:25,520 --> 01:49:30,200
at least in theory to predict the number of clusters so you you just look

1753
01:49:30,200 --> 01:49:34,180
at the i values and show look at how many small line happened and we

1754
01:49:34,180 --> 01:49:39,100
have gap and then it's OK mister clusters but that's just

1755
01:49:39,140 --> 01:49:42,100
i mean people do it but it doesn't work that way well

1756
01:49:49,020 --> 01:49:57,930
OK so i try to before the break just try to get the first interpretation

1757
01:49:57,930 --> 01:50:00,200
by spectral clustering works

1758
01:50:00,220 --> 01:50:04,680
that's my favorite one actually there are spectral clustering it's actually not new i mean

1759
01:50:04,680 --> 01:50:05,850
people have done it

1760
01:50:05,910 --> 01:50:09,650
already in the model in the seventies actually but nobody really noticed it and it

1761
01:50:09,650 --> 01:50:11,180
became really very

1762
01:50:11,220 --> 01:50:15,640
well spread like many people use it seems like two thousand one two thousand two

1763
01:50:15,640 --> 01:50:19,580
there not to have lots of papers but it is it's nothing new so there

1764
01:50:19,700 --> 01:50:22,470
are very many different ways of could derive

1765
01:50:22,480 --> 01:50:26,770
why spectral clustering works but i think this is the what the one

1766
01:50:26,770 --> 01:50:28,680
which i find most interesting

1767
01:50:29,970 --> 01:50:32,660
that's the we have all the data graph

1768
01:50:32,680 --> 01:50:35,040
we set clustering is something which

1769
01:50:35,040 --> 01:50:38,350
make sure the points which are in the same cluster similar to each other

1770
01:50:38,390 --> 01:50:41,890
points which are in different clusters are not so similar to each other

1771
01:50:44,140 --> 01:50:46,410
OK we need to i mean if you want to to

1772
01:50:46,430 --> 01:50:49,660
seven other to do that is someone to do or the easiest way is to

1773
01:50:49,660 --> 01:50:51,700
derive a mathematical criterion

1774
01:50:51,750 --> 01:50:53,200
which tells you

1775
01:50:53,240 --> 01:50:55,290
but you can optimize i mean

1776
01:50:55,310 --> 01:50:58,020
OK that's what people usually

1777
01:50:58,660 --> 01:51:03,140
so the idea of what spectral clustering

1778
01:51:03,520 --> 01:51:06,480
or what you want to look at this we say OK what we want is

1779
01:51:06,560 --> 01:51:11,180
we forget about the this within clusters we just look at distances between clusters and

1780
01:51:11,200 --> 01:51:11,950
we say

1781
01:51:12,060 --> 01:51:13,270
we want that

1782
01:51:13,270 --> 01:51:17,400
two clusters of things where the connections between the two clusters are very powerful and

1783
01:51:17,400 --> 01:51:19,200
very low weight

1784
01:51:19,310 --> 01:51:23,160
so we want to and then we define the things we say

1785
01:51:23,180 --> 01:51:26,750
the cut between two groups of points a and b

1786
01:51:26,750 --> 01:51:31,330
it's just so we sum over the points in the different clusters are similarities so

1787
01:51:31,330 --> 01:51:36,270
we say we define what the cut between those two groups this is actually a

1788
01:51:36,330 --> 01:51:38,140
the sum of this in the search

1789
01:51:38,160 --> 01:51:40,370
like the weights of those two images

1790
01:51:40,370 --> 01:51:44,430
it was a great we already done we minimize cut we

1791
01:51:44,430 --> 01:51:49,500
we have an objective criteria we use it for clustering

1792
01:51:49,520 --> 01:51:51,910
OK and actually for

1793
01:51:51,930 --> 01:51:55,120
i mean for minimising cut it can even be done in more or less efficient

1794
01:51:55,120 --> 01:52:00,750
way it's surprisingly not NP hard but it's there's this min cut max flow theorem

1795
01:52:00,750 --> 01:52:04,980
many maybe some people know it so you can really do that

1796
01:52:06,890 --> 01:52:08,520
but now there's a problem

1797
01:52:08,540 --> 01:52:09,890
and this problem is

1798
01:52:09,890 --> 01:52:11,640
shows up if you look at this

1799
01:52:11,660 --> 01:52:16,370
the vertex here so what happens very often is

1800
01:52:16,600 --> 01:52:18,970
you have one out there that point

1801
01:52:18,970 --> 01:52:22,480
and then you just to minimize cut and say OK great if i want to

1802
01:52:22,480 --> 01:52:25,220
have to tools in this graph just cut here

1803
01:52:25,240 --> 01:52:28,290
because you just cut one that interest to cut two inches

1804
01:52:30,850 --> 01:52:34,810
the problem is not of course that this is not what you wanted clustering so

1805
01:52:34,810 --> 01:52:36,500
i mean somehow we

1806
01:52:36,540 --> 01:52:39,770
we don't want to identify outliers i mean that's sounds something would like to do

1807
01:52:39,770 --> 01:52:42,450
but that's not what we want to do we want to find

1808
01:52:42,470 --> 01:52:46,520
groups in the data and those groups should be more or less reasonable size

1809
01:52:49,220 --> 01:52:53,250
and that's why people came up with different objective functions which try to incorporate the

1810
01:52:53,250 --> 01:52:55,950
size of the state of the different clusters

1811
01:52:56,000 --> 01:53:00,350
and essentially there are two different ways

1812
01:53:00,370 --> 01:53:05,000
which are two something very similar so ratiocut what it does

1813
01:53:05,000 --> 01:53:07,660
we say OK so in general what we do is we want to define a

1814
01:53:07,660 --> 01:53:08,970
balanced cut that is

1815
01:53:09,540 --> 01:53:10,450
we say we

1816
01:53:10,470 --> 01:53:14,250
we have two objectives we want to minimize the cut but we also want to

1817
01:53:14,250 --> 01:53:16,200
make sure that the rules are more or less

1818
01:53:16,240 --> 01:53:18,430
if the same size

1819
01:53:18,450 --> 01:53:20,120
that's ratiocut that's so

1820
01:53:20,140 --> 01:53:22,240
so we're going to minimize later on so

1821
01:53:22,250 --> 01:53:25,240
we have term which incorporates cut

1822
01:53:25,240 --> 01:53:26,640
but have also

1823
01:53:26,660 --> 01:53:29,180
which incorporates the

1824
01:53:29,200 --> 01:53:31,290
the balance between the two clusters

1825
01:53:31,310 --> 01:53:33,470
and what's actually going on there

1826
01:53:33,520 --> 01:53:35,430
it's very simple to see

1827
01:53:36,000 --> 01:53:40,720
so this term

1828
01:53:40,740 --> 01:53:42,480
one over a

1829
01:53:42,500 --> 01:53:47,470
one the so remember the absolute value of a is just the number of points

1830
01:53:47,480 --> 01:53:50,560
the number of vertices in a if know

1831
01:53:50,560 --> 01:53:55,850
so just look like negative charges of we say for example a and b if

1832
01:53:55,850 --> 01:53:56,950
they are both

1833
01:53:56,970 --> 01:53:58,390
the same size

1834
01:53:58,430 --> 01:54:01,330
and this term will be just one or

1835
01:54:01,430 --> 01:54:05,620
and half plus one and half years

1836
01:54:05,770 --> 01:54:07,850
four over and

1837
01:54:07,850 --> 01:54:12,000
which is pretty small if ten is large then if we have another case for

1838
01:54:12,020 --> 01:54:15,160
example is an outlier and just contains one point

1839
01:54:15,350 --> 01:54:19,270
and the content the other and minus one point we have something like one of

1840
01:54:19,290 --> 01:54:21,330
one plus one or

1841
01:54:21,350 --> 01:54:23,020
and minus one

1842
01:54:23,040 --> 01:54:25,970
which is which is i mean roughly one so here we have something in the

1843
01:54:25,970 --> 01:54:29,790
order of one or and here we have something in the order of one so

1844
01:54:29,790 --> 01:54:31,830
it shows that if you manage to

1845
01:54:31,850 --> 01:54:36,790
get hoops smallest having the ecosystem this term will be much smaller

1846
01:54:36,810 --> 01:54:40,330
so that's so now what we do is we just take the product of those

1847
01:54:40,350 --> 01:54:41,290
two terms

1848
01:54:41,330 --> 01:54:44,180
it's a pretty arbitrary way of doing it but

1849
01:54:44,200 --> 01:54:46,810
that's how we start

1850
01:54:47,350 --> 01:54:52,390
there's another way of doing it so that's called ratiocut this is called normalized cuts

1851
01:54:52,560 --> 01:54:57,830
so very something instead of taking the number of points and it's will you take

1852
01:54:57,850 --> 01:55:01,250
the volume which was the way to each school

1853
01:55:01,390 --> 01:55:03,580
but with the same reasons

1854
01:55:03,600 --> 01:55:08,790
so how

1855
01:55:10,980 --> 01:55:11,830
and are

1856
01:55:12,680 --> 01:55:16,060
a bit OK i mean that's where we're going to talk about that so that's

1857
01:55:16,060 --> 01:55:18,910
the problem of course i mean aim

1858
01:55:18,930 --> 01:55:22,160
OK so so far we just define our objective function now we want to minimize

1859
01:55:22,160 --> 01:55:26,450
the course it's very difficult problem that's exactly the point so we can just look


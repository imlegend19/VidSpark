1
00:00:00,000 --> 00:00:01,510
the simplest possible

2
00:00:01,700 --> 00:00:03,040
but the problem is

3
00:00:03,280 --> 00:00:05,260
you can't really defined

4
00:00:08,430 --> 00:00:11,660
first of all you can't really justify that this is this will give you the

5
00:00:11,660 --> 00:00:13,400
best answer

6
00:00:13,420 --> 00:00:16,950
as again as i said before you can justify these

7
00:00:17,020 --> 00:00:21,300
postulates right there is no proof that the simplest answer is the correct one

8
00:00:21,350 --> 00:00:23,890
and second of all

9
00:00:23,930 --> 00:00:24,700
you can't

10
00:00:24,710 --> 00:00:25,990
define simplicity

11
00:00:26,020 --> 00:00:28,440
because it's not objective there are many

12
00:00:28,450 --> 00:00:32,020
the ways in which you could you could measure it and everyone would have different

13
00:00:33,420 --> 00:00:38,170
i mean some people tend to say that the the right notion of simplicity is

14
00:00:38,170 --> 00:00:40,640
what is called come come over complexity

15
00:00:40,690 --> 00:00:44,160
which is a measure of the length of the shortest programme

16
00:00:44,430 --> 00:00:45,530
that can

17
00:00:46,150 --> 00:00:50,100
you know generates a sequence or that kind of stuff

18
00:00:50,100 --> 00:00:53,830
if there is some function but even that

19
00:00:53,870 --> 00:00:57,860
is not completely objective because when you define the length of the shortest programme you

20
00:00:57,860 --> 00:01:00,600
first have to define in which programming language

21
00:01:00,620 --> 00:01:02,040
you're right before

22
00:01:02,880 --> 00:01:07,370
which means that every programming language would give rise to different notion of them

23
00:01:08,040 --> 00:01:08,810
even though

24
00:01:08,830 --> 00:01:11,120
you can prove that asymptotically

25
00:01:11,160 --> 00:01:13,210
they are all equivalent

26
00:01:13,220 --> 00:01:15,620
at least in the languages

27
00:01:15,660 --> 00:01:17,570
complete during combat

28
00:01:18,020 --> 00:01:22,460
in practice on finite sequences each programming language would give you a different notion of

29
00:01:23,440 --> 00:01:27,040
so if i if you observe a finite sequence as we did before

30
00:01:27,100 --> 00:01:28,940
there is again no

31
00:01:29,480 --> 00:01:34,710
no reason to choose one or another

32
00:01:35,290 --> 00:01:38,030
it seems that we are doing right

33
00:01:38,050 --> 00:01:43,600
i'm just saying i i keep saying OK we can't do anything so

34
00:01:43,600 --> 00:01:44,530
what's the point

35
00:01:44,680 --> 00:01:49,030
well let's see maybe we can do something about

36
00:01:49,110 --> 00:01:53,960
it means we first have to kind lower our expectations we want to prove that

37
00:01:53,970 --> 00:01:55,270
something is

38
00:01:55,370 --> 00:01:57,690
the right thing to do or i mean we want to prove that there is

39
00:01:57,690 --> 00:01:58,540
an optimal

40
00:01:58,550 --> 00:02:03,060
one way of doing induction but we can at least try to get some more

41
00:02:06,020 --> 00:02:07,460
so let me now defined

42
00:02:07,470 --> 00:02:11,940
probability and discuss a bit about what probability means because you've heard a lot

43
00:02:11,940 --> 00:02:13,610
probably before in

44
00:02:13,620 --> 00:02:18,580
previous lecture about probabilities maybe you're also used that a lot

45
00:02:18,660 --> 00:02:20,860
but i want to

46
00:02:21,010 --> 00:02:25,830
if you make use think again about what is probability and what it means

47
00:02:25,850 --> 00:02:27,960
the probability

48
00:02:28,190 --> 00:02:33,280
to me is just the way to formalise reasoning under this convenience

49
00:02:33,330 --> 00:02:35,670
we define two assigned numbers three

50
00:02:35,780 --> 00:02:38,470
and it relies on on these

51
00:02:38,480 --> 00:02:40,140
simple actions

52
00:02:40,180 --> 00:02:43,000
the probability of an event negative

53
00:02:43,030 --> 00:02:46,370
probability of certain events is one

54
00:02:46,380 --> 00:02:47,650
and then you have these

55
00:02:49,360 --> 00:02:54,430
like these documents probability that some event if there is some intersection you can just

56
00:02:55,970 --> 00:02:59,720
and while generally you can introduce this

57
00:02:59,740 --> 00:03:05,120
and sigma additivity of the problems probability but it's not really relevant to understand

58
00:03:06,750 --> 00:03:08,620
OK so that that's pretty simple

59
00:03:08,630 --> 00:03:10,640
three convenience can

60
00:03:10,660 --> 00:03:12,770
make it easy computation with these things

61
00:03:12,790 --> 00:03:15,750
but the question is what does it mean

62
00:03:16,720 --> 00:03:20,950
more precisely how you can measure these numbers or how can you decide which is

63
00:03:20,950 --> 00:03:23,300
the right number one

64
00:03:25,390 --> 00:03:30,940
there are a number of ways to interpret these numbers and interpretation here means assigning

65
00:03:30,970 --> 00:03:32,960
meaning to a given number

66
00:03:34,200 --> 00:03:38,170
one of the simplest one is the so-called frequentist interpretation

67
00:03:38,180 --> 00:03:40,530
the the frequentist interpretation

68
00:03:40,710 --> 00:03:44,450
probabilities are relative frequencies

69
00:03:45,170 --> 00:03:45,870
you know

70
00:03:45,880 --> 00:03:48,180
how many times a certain event occurs

71
00:03:48,650 --> 00:03:52,650
divided by how many times you try this

72
00:03:53,080 --> 00:03:55,290
and will get into detail

73
00:03:55,350 --> 00:03:58,880
objectivism is

74
00:03:58,880 --> 00:04:02,210
one is the same and you can say

75
00:04:02,290 --> 00:04:07,320
the probability still frequency but now this because he is not observed as what is

76
00:04:07,320 --> 00:04:11,410
an but it's kind of hostility that something that exists

77
00:04:11,410 --> 00:04:16,200
and you have the subjectivist point of view which is that well probabilities are just

78
00:04:16,260 --> 00:04:20,210
believe is just something that we think is true but there is no way to

79
00:04:20,210 --> 00:04:22,500
prove that it's true

80
00:04:23,900 --> 00:04:27,510
so probability as frequencies

81
00:04:27,560 --> 00:04:29,850
so what you do is that as i said

82
00:04:29,850 --> 00:04:31,240
that's natural

83
00:04:31,670 --> 00:04:34,430
you repeat a given experiment and times

84
00:04:34,470 --> 00:04:36,920
and in the event of interest occurs

85
00:04:37,190 --> 00:04:40,770
times then he overran is your estimate of the probability

86
00:04:40,800 --> 00:04:44,680
and you can even define the probability of the seven as

87
00:04:44,680 --> 00:04:46,040
the game

88
00:04:48,800 --> 00:04:53,730
you can say well if i were to repeat these experiments infinity in number of

89
00:04:53,730 --> 00:04:58,960
times eventually these limit might want summer and this is how i define problem

90
00:04:59,030 --> 00:05:03,380
OK that's kind of clear easy but the problem is

91
00:05:03,430 --> 00:05:07,010
you can't always repeat experiments and also you

92
00:05:07,030 --> 00:05:11,990
i really can be infinitely experiment so you cannot really

93
00:05:12,030 --> 00:05:17,700
i have a measure of these numbers by experimenting because you you can't really read

94
00:05:17,700 --> 00:05:21,820
all right so let's just look at this this prior issue because it actually is

95
00:05:21,840 --> 00:05:26,830
a great great thing to add constraint on i think it's good that people are

96
00:05:26,850 --> 00:05:28,930
you were asking about that

97
00:05:28,940 --> 00:05:31,560
and we've got this notion

98
00:05:31,580 --> 00:05:33,060
over prior

99
00:05:33,080 --> 00:05:34,520
which is

100
00:05:34,580 --> 00:05:37,950
which of these hypotheses which of these lines

101
00:05:37,970 --> 00:05:42,180
do we think are likely before we see any data

102
00:05:42,810 --> 00:05:44,340
we've got some space

103
00:05:44,360 --> 00:05:45,840
we're expecting

104
00:05:45,860 --> 00:05:48,650
the two different classes to appear somewhere in this space and for the to be

105
00:05:48,650 --> 00:05:50,230
some line which

106
00:05:50,820 --> 00:05:52,820
which bisects are classes

107
00:05:52,830 --> 00:05:55,430
then where should they be in are

108
00:05:55,440 --> 00:05:57,170
are kind of

109
00:05:57,180 --> 00:06:00,720
the distribution over those different ways before seeing any data is what we call the

110
00:06:01,900 --> 00:06:04,710
so it's kind of generated from

111
00:06:04,750 --> 00:06:06,050
from a prior

112
00:06:06,080 --> 00:06:09,890
i just realized here i've got an old version of the code doesn't actually do

113
00:06:09,890 --> 00:06:11,420
this quite right so we can

114
00:06:11,430 --> 00:06:14,480
one thing we can do is see what happens when you sample from the wrong

115
00:06:18,850 --> 00:06:24,820
i have code which samples from prior that takes these points defining line uniformly

116
00:06:24,840 --> 00:06:28,370
in a square region including the data

117
00:06:28,390 --> 00:06:32,580
so if

118
00:06:33,390 --> 00:06:37,920
if we run prior to the data points in europe just ignore them

119
00:06:37,980 --> 00:06:43,370
this is i think a hundred different lines samples from our prior and you can

120
00:06:43,370 --> 00:06:45,360
already can see there's this

121
00:06:45,370 --> 00:06:48,720
for empty space in the middle which doesn't really seem

122
00:06:48,730 --> 00:06:51,000
quite what we're interested in we want to have

123
00:06:51,010 --> 00:06:52,750
lines everywhere

124
00:06:52,760 --> 00:06:58,590
and if we

125
00:06:58,610 --> 00:07:00,230
if we put a few more

126
00:07:00,260 --> 00:07:05,670
let's try to thousand of those guys

127
00:07:05,700 --> 00:07:12,390
all right now we can see is definitely something up with this prior

128
00:07:14,250 --> 00:07:20,080
it's under representing lines which which cut of this region here so this is this

129
00:07:20,080 --> 00:07:22,480
is the the mean of our data point right so this is

130
00:07:22,480 --> 00:07:25,670
really the region where we most wanted to be lines and is the bit where

131
00:07:25,670 --> 00:07:27,300
we're neglected

132
00:07:27,320 --> 00:07:28,350
so i

133
00:07:28,360 --> 00:07:31,230
and apparently innocuous decision

134
00:07:31,260 --> 00:07:33,790
so just taking these points

135
00:07:33,790 --> 00:07:39,570
uniform is well taken points uniformly across the whole field and wrong the

136
00:07:39,580 --> 00:07:42,670
worked out the line based on the

137
00:07:42,700 --> 00:07:45,200
the problem the vector perpendicular from this

138
00:07:45,240 --> 00:07:47,300
i mean of the data to that point

139
00:07:47,320 --> 00:07:50,010
actually we that part of the input space there

140
00:07:50,040 --> 00:07:52,640
so we just had this version with the broken

141
00:07:53,050 --> 00:07:56,760
prior to show you but if you look online to find the code samples from

142
00:07:56,760 --> 00:07:59,140
the great

143
00:07:59,190 --> 00:08:06,320
OK so more tricky than it seems getting getting the right product but getting the

144
00:08:06,320 --> 00:08:09,080
right prior is crucial to

145
00:08:09,080 --> 00:08:11,790
being able to this integration

146
00:08:12,480 --> 00:08:13,850
over the

147
00:08:13,860 --> 00:08:21,860
over the whole space of parameters and getting this this nice posterior distribution

148
00:08:21,880 --> 00:08:26,730
all right we could

149
00:08:26,790 --> 00:08:29,410
well we've had so far is

150
00:08:29,450 --> 00:08:32,160
a fairly simple model

151
00:08:32,290 --> 00:08:41,880
and you might notice some shortcomings with this model

152
00:08:41,890 --> 00:08:45,660
so let's think first example for

153
00:08:45,670 --> 00:08:48,640
an example of the failure mode of this particular model

154
00:08:48,700 --> 00:08:52,390
what if the data was not linearly separable

155
00:08:52,790 --> 00:08:55,170
what we mean by linear we separable

156
00:08:55,190 --> 00:08:56,950
it is

157
00:08:56,980 --> 00:08:58,940
this is are

158
00:08:58,950 --> 00:09:00,230
our input space

159
00:09:00,230 --> 00:09:03,740
and we've got to draw the

160
00:09:03,760 --> 00:09:06,200
class one zeros

161
00:09:07,610 --> 00:09:12,050
so there's the nose nose the axes

162
00:09:12,070 --> 00:09:14,390
an example we saw here

163
00:09:14,410 --> 00:09:17,040
it turns out we can draw several lines

164
00:09:17,380 --> 00:09:21,260
in between but what if we've got some outliers

165
00:09:21,270 --> 00:09:23,380
on both sides

166
00:09:23,450 --> 00:09:26,510
all right in this previous example i showed you

167
00:09:26,540 --> 00:09:29,010
there's not going to be any single line

168
00:09:29,010 --> 00:09:30,860
with positive likely it

169
00:09:30,980 --> 00:09:33,570
every single line we can draw

170
00:09:33,630 --> 00:09:37,830
is going to you might nearly separate the two classes

171
00:09:37,850 --> 00:09:39,280
but not completely

172
00:09:39,300 --> 00:09:42,180
so every single sample from our prior

173
00:09:42,200 --> 00:09:45,390
we'll have zero likelihood and we will be able to make any

174
00:09:45,410 --> 00:09:49,910
any progress and inference with that was that likelihood function

175
00:09:50,820 --> 00:09:53,640
the issue here is that

176
00:09:53,650 --> 00:09:58,550
we've got

177
00:10:01,900 --> 00:10:03,210
for all of the

178
00:10:03,220 --> 00:10:06,030
data points

179
00:10:06,060 --> 00:10:07,600
when we're looking at the

180
00:10:07,620 --> 00:10:10,510
the probability of that line

181
00:10:10,520 --> 00:10:12,140
given some data

182
00:10:14,070 --> 00:10:16,680
i'm going to call that

183
00:10:16,690 --> 00:10:18,620
d for the distance

184
00:10:18,640 --> 00:10:19,690
to the

185
00:10:19,700 --> 00:10:21,890
decision boundary

186
00:10:21,900 --> 00:10:24,950
and the likelihood that we have

187
00:10:25,820 --> 00:10:28,620
that we have so far

188
00:10:28,650 --> 00:10:32,280
that is the likelihood of some line

189
00:10:34,490 --> 00:10:36,960
given that distance

190
00:10:36,970 --> 00:10:40,680
actually by the distance

191
00:10:41,410 --> 00:10:47,530
OK sure list let's keep their distance just remember that the distance is given

192
00:10:47,550 --> 00:10:48,940
by a

193
00:10:48,950 --> 00:10:51,870
for some

194
00:10:51,950 --> 00:10:57,350
some input space and some for some

195
00:10:57,370 --> 00:11:00,900
hypothesis some critical line w and b

196
00:11:02,580 --> 00:11:04,430
that distances

197
00:11:04,450 --> 00:11:07,580
going to be given

198
00:11:07,700 --> 00:11:13,530
by the way xt busby positive one side negative on the other

199
00:11:16,020 --> 00:11:17,700
if we

200
00:11:17,710 --> 00:11:20,300
take the prior we have at the moment that's basically

201
00:11:20,360 --> 00:11:22,870
the step function

202
00:11:22,880 --> 00:11:28,840
and we can kind of makes science work and if we

203
00:11:28,870 --> 00:11:33,450
define every class to be o one or negative one say the yes is our

204
00:11:33,450 --> 00:11:35,970
ones know is the negative ones

205
00:11:37,240 --> 00:11:39,770
then this d

206
00:11:39,780 --> 00:11:40,600
if we

207
00:11:40,630 --> 00:11:43,150
multiply all that by the class

208
00:11:43,150 --> 00:11:43,500
this one?

209
00:11:45,210 --> 00:11:45,530
this one?

210
00:11:47,180 --> 00:11:48,140
a little more uncertainly there.

211
00:11:48,610 --> 00:11:50,390
that's OK because we've got a probabilistic

212
00:11:51,460 --> 00:11:55,600
models here. so so what's going on? think this as as a math problem, right.

213
00:11:55,600 --> 00:11:59,410
there's this infinite set of all objects, and it's truly infinite because we generated with the

214
00:11:59,410 --> 00:12:00,170
generative programme,

215
00:12:00,640 --> 00:12:06,170
and somewhere in this infinite space of all objects is an infinite but very constrained subset that you could call the tufas.

216
00:12:07,470 --> 00:12:11,520
and somehow you're able to pick out the boundaries of that set. not perfectly but roughly

217
00:12:11,520 --> 00:12:14,010
from just these few points randomly sampled within it.

218
00:12:15,070 --> 00:12:16,730
and we we work on these kinds of problems

219
00:12:17,300 --> 00:12:21,550
whether we're thinking about the  they often arise in language, or, for example, causal learning,

220
00:12:22,000 --> 00:12:22,730
right. so you know again

221
00:12:23,410 --> 00:12:26,190
it's it's a great time to be addressing an AI audience

222
00:12:27,080 --> 00:12:28,370
because of you know the the the

223
00:12:29,230 --> 00:12:35,230
very broad recognition of the work of Judea Pearl that's that's not only revolutionized AI but also

224
00:12:35,650 --> 00:12:36,720
many other fields.

225
00:12:37,640 --> 00:12:43,120
and so we're all familiar now with various kinds principles that can be used to learn causal structure from

226
00:12:43,580 --> 00:12:45,480
observational and interventional data.

227
00:12:46,010 --> 00:12:47,090
but think about the way

228
00:12:47,650 --> 00:12:51,970
that children often learn cause causal structure. sometimes they get it wrong but, you know,

229
00:12:52,140 --> 00:12:54,190
quite quite often get it right

230
00:12:54,620 --> 00:12:58,780
from just, not not even enough data to sort of compute the parents of conditional dependence

231
00:12:58,780 --> 00:13:04,640
and independence that're at the heart of classic Bayesian causal structure learning algorithms, but even

232
00:13:04,640 --> 00:13:08,110
just a few, again, a few data points that aren't even enough to establish a

233
00:13:08,110 --> 00:13:11,010
reliab a reliable pattern of statistical dependence or correlation.

234
00:13:11,510 --> 00:13:13,780
right, like the right kind of spatial temporal coincidence.

235
00:13:15,030 --> 00:13:16,690
how how how are children able to do that?

236
00:13:18,390 --> 00:13:22,480
I would say that the most exciting thing that we're that we're getting at here is

237
00:13:23,220 --> 00:13:28,010
larger scale systems of knowledge, what are sometimes called intuitive theories. not just learning a

238
00:13:28,010 --> 00:13:33,670
single concept but systems of concepts that together describe some common sense domain, like common sense physics or

239
00:13:33,730 --> 00:13:37,470
common sense psychology. so just to illustrate this a little bit, i'm talking about these kinds

240
00:13:37,520 --> 00:13:38,290
of problems and you'll see,

241
00:13:38,760 --> 00:13:40,820
I think, hopefully, the AI relevance of these problems.

242
00:13:41,290 --> 00:13:44,260
let's say we're interested in understanding a visual scene like the one in the upper

243
00:13:44,260 --> 00:13:47,820
left. we don't just want to know what is where to recognize objects and localize them but we

244
00:13:47,820 --> 00:13:52,330
wanna understand what's going on in terms of the physics, like this table of supporting those objects

245
00:13:52,330 --> 00:13:56,270
or certain objects appra must be pro very likely to be attached to the back wall but

246
00:13:56,270 --> 00:13:59,330
you couldn't move them. others are hanging there so they're not gonna fall but you

247
00:13:59,330 --> 00:13:59,960
could lift them up.

248
00:14:00,500 --> 00:14:01,780
right, or looking at that

249
00:14:02,800 --> 00:14:06,470
looking at the at the construction scene, how do you know which of those planks of wood

250
00:14:06,470 --> 00:14:10,410
you could move or which are which, you know, which are free, which are attached, which

251
00:14:10,410 --> 00:14:12,120
are absolutely vital to supporting the structure.

252
00:14:12,680 --> 00:14:14,620
we use this kind of intuitive physical knowledge

253
00:14:15,040 --> 00:14:17,120
to diagnose situations that are

254
00:14:17,610 --> 00:14:21,140
maybe accidents waiting to happen or requiring special care, like this stack of dishes.

255
00:14:21,670 --> 00:14:25,300
and then think about social interaction between people. how do we look at the scene

256
00:14:25,300 --> 00:14:28,410
whether we're just an observer watching one of these scenes or a participant?

257
00:14:28,850 --> 00:14:32,660
and just get instantly what's going on, what what the what the different people in the scene are

258
00:14:32,750 --> 00:14:36,480
thinking, what they want, what they're feeling? how do we get at their

259
00:14:36,480 --> 00:14:37,260
their mental states

260
00:14:37,700 --> 00:14:40,250
from their actions? that's a kind of intuitive psychology.

261
00:14:41,360 --> 00:14:44,280
these are hard problems. if we could solve this, you know, we'd pretty much be done

262
00:14:45,340 --> 00:14:48,030
and this. but these are the these are the problems that we're setting our sights on.

263
00:14:48,560 --> 00:14:54,050
we we wanna get there by backing off to some easier problems. and many AI researchers

264
00:14:54,050 --> 00:14:56,700
as well as cognitive scientists have pointed out that you could get at a lot of these

265
00:14:56,730 --> 00:15:01,370
basic kind of common sense physics and psychology by just studying what small children

266
00:15:01,370 --> 00:15:06,420
do with stacks of blocks on their own building up things or in combination. and

267
00:15:06,420 --> 00:15:09,660
i'll show you some research that's really trying to get this but you can start

268
00:15:09,710 --> 00:15:13,230
even simpler let me show you a couple to other demos but i think are

269
00:15:13,230 --> 00:15:14,530
some of the nicest way stacy

270
00:15:14,930 --> 00:15:20,870
these corps common sense into the physical intuitive psychological theories that work and again show

271
00:15:20,880 --> 00:15:24,590
you these these these mines remarkable ability to make inferences from sparse data

272
00:15:25,240 --> 00:15:27,190
so here are a couple of little movies the first one

273
00:15:27,740 --> 00:15:32,650
is by south gingerbread to developmental psychologists it's from a study with thirteen month-old infants

274
00:15:33,000 --> 00:15:34,880
so just watch this all played a couple of times

275
00:15:35,420 --> 00:15:36,270
and you can see here

276
00:15:37,420 --> 00:15:39,790
well what do you see you see two balls a blue ball

277
00:15:40,190 --> 00:15:41,590
displayed again and a red ball

278
00:15:42,050 --> 00:15:45,830
and the rolling on a green surface with some kind bij obstacles right

279
00:15:46,710 --> 00:15:49,720
but if you want to describe this what's the most natural way to describe what's going on

280
00:15:52,170 --> 00:15:55,690
chasing right yeah that's that's i heard a few different people it looks like the

281
00:15:55,690 --> 00:15:58,260
blue ball is chasing the red ball and the red trying to get away

282
00:15:58,800 --> 00:16:02,950
and while the it's it's an interesting kind chasing because it's also kind of a

283
00:16:02,950 --> 00:16:07,030
slightly dumb chasing right the blue ball thinks he can fit through those holes that

284
00:16:07,040 --> 00:16:11,940
you can't actually write anything stepped back out and go around so you attributing a

285
00:16:11,940 --> 00:16:15,200
goal to the blue ball and also to the red the rebels trying to get

286
00:16:15,990 --> 00:16:19,610
a kind desire as well as a belief may be a false belief in this case

287
00:16:20,000 --> 00:16:22,580
that's he thinks he can fix some holes which you can as well as some

288
00:16:22,580 --> 00:16:26,580
over loss functions to the right delta

289
00:16:26,600 --> 00:16:30,270
OK so that's kind of the core problem the decision tree interface

290
00:16:30,310 --> 00:16:34,130
all right well you get two arguments that functions could be two perspectives on how

291
00:16:34,130 --> 00:16:37,620
to get rid of the unknown you start with the delta x or you start

292
00:16:37,620 --> 00:16:39,320
with the data

293
00:16:39,380 --> 00:16:43,020
and those two percent recall frequentist and bayesian

294
00:16:43,040 --> 00:16:45,940
and that's been my arguments for why there are two of them because only two

295
00:16:45,940 --> 00:16:47,480
arguments of loss functions

296
00:16:50,810 --> 00:16:53,220
so the sum of the frequencies one first so

297
00:16:53,240 --> 00:16:56,620
the frequencies looks at the loss functions as well you get two unknowns there let's

298
00:16:56,620 --> 00:16:59,820
start with the x one try to do something about turning that random acts

299
00:16:59,880 --> 00:17:02,480
into a

300
00:17:02,490 --> 00:17:04,650
into a number somehow

301
00:17:04,930 --> 00:17:08,220
well ran the internet whenever we think its expectation

302
00:17:08,240 --> 00:17:10,770
let's take an expectation of this quantity

303
00:17:10,940 --> 00:17:14,200
the second especially the export

304
00:17:14,980 --> 00:17:18,970
well expected with what respect what problem distribution

305
00:17:19,060 --> 00:17:23,150
well it use the same fate to take our expectation as is the the loss

306
00:17:24,930 --> 00:17:27,950
OK so i don't need to know the truth upper right to say whatever the

307
00:17:27,950 --> 00:17:31,210
truth is i think especially that of this for all theta o look at all

308
00:17:31,210 --> 00:17:32,950
possible true

309
00:17:32,970 --> 00:17:37,280
so we get a risk functional three-quarters risk riskier the function of data i've picked

310
00:17:37,280 --> 00:17:40,600
which state opera or is the truth

311
00:17:41,730 --> 00:17:45,530
but this quantity here this is the data is the expectation

312
00:17:45,540 --> 00:17:49,650
under the distribution indexed by data and its expression over x o x goes away

313
00:17:49,650 --> 00:17:52,850
and we just get paid on the left-hand side i that's the key so if

314
00:17:52,850 --> 00:17:56,750
you need the definition of frequent this is probably good as any that this is

315
00:17:56,760 --> 00:17:59,190
kind of one message i want to get permission a lot of people in machine

316
00:17:59,190 --> 00:18:03,310
learning are frequentist a lot of the work is at least frequentist but you never

317
00:18:03,310 --> 00:18:06,150
see there were frequent there are people people talk about the definition of what it

318
00:18:06,150 --> 00:18:10,360
means to be frequencies i'll hear it is this is the here here's what it

319
00:18:10,360 --> 00:18:15,330
means you take expectation of perfect stated what i was to act and doing that

320
00:18:15,330 --> 00:18:19,780
what you're you're being not bayesian that point you are taking expectations expected other axes

321
00:18:19,780 --> 00:18:21,920
are over the entire sample space

322
00:18:21,940 --> 00:18:23,280
not the exit you saw

323
00:18:23,290 --> 00:18:28,220
but other actors you might see

324
00:18:28,290 --> 00:18:32,200
OK so that's what these difficulties you're looking other possible data could have gone to

325
00:18:32,200 --> 00:18:37,720
the unconditional perspective that's what every right down e in equation and its need to

326
00:18:37,720 --> 00:18:38,860
average over x

327
00:18:38,880 --> 00:18:43,740
you just very with bayesian right you're going towards the frequency of that's clear

328
00:18:43,760 --> 00:18:50,640
OK so that's what the frequentist does get started now this function are

329
00:18:50,650 --> 00:18:54,510
and they said well i don't know what truth is it could be any data

330
00:18:54,540 --> 00:18:57,500
and now i need still converges thing to a single number

331
00:18:57,520 --> 00:19:00,550
how do i convert that to a single number

332
00:19:00,570 --> 00:19:05,540
OK and now there's many possibilities and has been huge literature fifty years the kind

333
00:19:05,540 --> 00:19:09,360
of work on ways to think about turning this into a single number the one

334
00:19:09,360 --> 00:19:11,400
probably the most about is many max

335
00:19:11,400 --> 00:19:13,620
we'll take the

336
00:19:13,660 --> 00:19:18,120
the maximum of the of this frequentist risk overall theta and find the procedure that

337
00:19:18,120 --> 00:19:20,520
has the minimum of the maximum risk

338
00:19:20,560 --> 00:19:24,360
a lot of good work has come out the minimax perspective that's one way to

339
00:19:24,360 --> 00:19:28,200
take the fate apart by taking the maximum over all things and then taking the

340
00:19:28,200 --> 00:19:32,600
minimum minimax but there are other ways to do this if you take subclasses of

341
00:19:32,600 --> 00:19:37,810
procedures you also delta x could be a subclass maybe all unbiased estimators or or

342
00:19:37,810 --> 00:19:41,130
some other in varying or invariant

343
00:19:41,170 --> 00:19:48,150
estimators one and that subclass this or fate might actually have a

344
00:19:48,180 --> 00:19:51,990
a simple characterization you can actually get a single number over some subclasses

345
00:19:52,000 --> 00:19:54,990
and there are many other kind of ways trying to approach i think it ready

346
00:19:55,290 --> 00:19:57,000
be the average over theta

347
00:19:57,010 --> 00:20:00,970
right but when you average over theta you get average some distribution on theta at

348
00:20:00,970 --> 00:20:03,760
that point you become bayesian

349
00:20:03,770 --> 00:20:08,220
OK i tried to think about distribution play so the frequencies are willing to do

350
00:20:08,220 --> 00:20:08,480
so all

351
00:20:24,010 --> 00:20:26,610
you are

352
00:20:29,440 --> 00:20:30,020
you more

353
00:20:44,820 --> 00:20:45,480
all right

354
00:21:01,030 --> 00:21:01,430
they were

355
00:21:04,790 --> 00:21:06,140
so i

356
00:21:26,280 --> 00:21:27,630
now let

357
00:21:31,210 --> 00:21:34,310
i are

358
00:21:36,270 --> 00:21:40,980
one which i

359
00:21:41,440 --> 00:21:43,090
you all

360
00:21:46,290 --> 00:21:47,200
you know which

361
00:22:29,330 --> 00:22:30,330
all it

362
00:22:41,090 --> 00:22:41,710
if you

363
00:22:49,260 --> 00:22:52,960
and you get data

364
00:22:55,330 --> 00:22:57,450
and by

365
00:23:04,770 --> 00:23:05,750
so the the

366
00:23:07,530 --> 00:23:08,190
and these two

367
00:23:08,740 --> 00:23:09,260
it's not

368
00:23:09,780 --> 00:23:10,900
so reason the

369
00:23:11,230 --> 00:23:12,260
can alter the

370
00:23:15,660 --> 00:23:16,510
in the paper

371
00:23:20,410 --> 00:23:21,920
and we across

372
00:23:22,690 --> 00:23:23,590
the model

373
00:23:24,270 --> 00:23:25,150
you time

374
00:23:28,990 --> 00:23:32,170
so they can continue to

375
00:23:35,150 --> 00:23:36,460
they are all the

376
00:23:37,810 --> 00:23:39,250
they not here

377
00:23:40,330 --> 00:23:40,990
first one

378
00:23:47,780 --> 00:23:48,920
and to the war

379
00:23:52,740 --> 00:23:53,240
the was

380
00:23:56,740 --> 00:23:58,950
there are the people or the million

381
00:24:01,020 --> 00:24:01,660
and the

382
00:24:03,040 --> 00:24:03,860
and you

383
00:24:05,830 --> 00:24:07,310
that's nine

384
00:24:08,960 --> 00:24:10,330
hours per iteration

385
00:24:11,470 --> 00:24:11,820
we've done

386
00:24:12,810 --> 00:24:14,550
that's the themes of this search

387
00:24:15,740 --> 00:24:17,130
and i

388
00:24:22,960 --> 00:24:23,610
you here

389
00:24:24,270 --> 00:24:26,960
more and more and you you know

390
00:24:27,640 --> 00:24:28,760
i'm in early on

391
00:24:32,220 --> 00:24:33,150
the latter

392
00:24:34,220 --> 00:24:34,700
from the

393
00:24:37,050 --> 00:24:38,480
they find in red

394
00:24:40,980 --> 00:24:45,280
are you indeed collection today which is human

395
00:24:49,360 --> 00:24:50,750
and then you

396
00:24:51,070 --> 00:24:52,420
well mean

397
00:24:58,220 --> 00:24:58,630
it's here

398
00:25:19,070 --> 00:25:20,350
and you

399
00:25:28,730 --> 00:25:31,140
it's time

400
00:25:42,680 --> 00:25:44,080
you that

401
00:25:54,450 --> 00:25:56,030
and all of

402
00:25:57,330 --> 00:25:57,770
i know

403
00:26:21,670 --> 00:26:22,390
we're only

404
00:26:41,380 --> 00:26:42,010
and you

405
00:26:58,810 --> 00:27:01,010
so why you want to

406
00:27:15,190 --> 00:27:16,490
on other hand

407
00:27:23,880 --> 00:27:24,840
but if you

408
00:27:31,750 --> 00:27:33,440
this is just great

409
00:27:33,440 --> 00:27:35,230
of the american public

410
00:27:35,240 --> 00:27:37,390
continued to take the position

411
00:27:37,450 --> 00:27:40,640
it states are entitled to to use force

412
00:27:40,650 --> 00:27:42,640
quoting if there is

413
00:27:42,650 --> 00:27:48,090
only if there is strong evidence that the country is in imminent danger of being

414
00:27:49,590 --> 00:27:53,510
so a large majority rejected the

415
00:27:53,530 --> 00:27:54,790
a bipartisan

416
00:27:55,960 --> 00:27:58,880
so-called pre-emptive war

417
00:27:58,930 --> 00:28:06,470
and i agree with the recent united nations panel and incidentally also agree with the

418
00:28:06,470 --> 00:28:14,600
former non-aligned movement the governments of the eighty percent of the world's populations but there

419
00:28:14,600 --> 00:28:15,980
are of course

420
00:28:15,990 --> 00:28:17,530
ignore the

421
00:28:17,550 --> 00:28:20,270
dismissed with reason

422
00:28:20,290 --> 00:28:27,010
the legitimacy of these force is not the only issue

423
00:28:27,020 --> 00:28:29,870
on which public opinion in the united states

424
00:28:29,890 --> 00:28:35,340
diverges sharply from elite political culture

425
00:28:35,350 --> 00:28:38,390
to take another current example

426
00:28:38,460 --> 00:28:41,360
which also raises issues of survival

427
00:28:41,370 --> 00:28:49,390
it's commonly reported that the united states refused to sign the kyoto treaty months ago

428
00:28:49,400 --> 00:28:56,300
that's true only if the phrase united states excludes population

429
00:28:56,400 --> 00:29:00,240
who overwhelmingly supported ratification of the treaty

430
00:29:00,290 --> 00:29:03,140
so enthusiastically in fact

431
00:29:03,160 --> 00:29:05,950
the majority of bush voters

432
00:29:05,970 --> 00:29:11,510
i believe that he agreed with the united states should join

433
00:29:11,550 --> 00:29:14,720
large majorities also believe

434
00:29:14,820 --> 00:29:16,650
the united states should

435
00:29:16,670 --> 00:29:22,450
accept the jurisdiction of the international criminal court and the world works

436
00:29:22,490 --> 00:29:28,470
and should rely on the united nations to take the lead in international crises

437
00:29:28,480 --> 00:29:35,920
including issues of security reconstruction and political transition in iraq

438
00:29:35,940 --> 00:29:38,550
most of the population

439
00:29:38,570 --> 00:29:41,750
even believe that the united states

440
00:29:41,760 --> 00:29:45,020
should abandon its security council veto

441
00:29:45,090 --> 00:29:48,860
accepting majority rule

442
00:29:48,880 --> 00:29:51,550
true on other issues

443
00:29:51,570 --> 00:29:55,640
large majorities believe that the united states

444
00:29:55,650 --> 00:29:59,420
should rely on diplomatic and economic measures

445
00:29:59,430 --> 00:30:01,450
more than military ones

446
00:30:01,470 --> 00:30:04,260
in the so-called war on terror

447
00:30:04,270 --> 00:30:07,500
an overwhelming majorities in the past

448
00:30:07,560 --> 00:30:10,570
favor increased government spending

449
00:30:10,580 --> 00:30:14,070
on health care education and other

450
00:30:14,090 --> 00:30:21,920
social spending all of this is in sharp opposition to public policy

451
00:30:21,970 --> 00:30:24,590
studies revealing this fact

452
00:30:24,600 --> 00:30:30,450
were released by the most prestigious institutions that monitor public attitudes

453
00:30:30,460 --> 00:30:32,620
shortly before the

454
00:30:32,630 --> 00:30:34,920
november two thousand four

455
00:30:34,980 --> 00:30:37,140
presidential elections

456
00:30:37,250 --> 00:30:42,380
plainly there of critical importance to functioning democracy

457
00:30:42,400 --> 00:30:44,500
the studies reveal

458
00:30:44,510 --> 00:30:50,600
that both political parties are far to the right of the population and many of

459
00:30:50,600 --> 00:30:52,730
the most crucial issues

460
00:30:52,770 --> 00:30:55,690
they were scarcely recorded

461
00:30:55,710 --> 00:30:59,030
not mentioned in national press

462
00:30:59,050 --> 00:31:03,430
these observations unfortunately generalise

463
00:31:03,450 --> 00:31:08,780
lending further weight to the judgement of the strategic analysts

464
00:31:08,830 --> 00:31:10,350
i quoted earlier

465
00:31:10,360 --> 00:31:13,930
about the crisis of western democracy

466
00:31:13,940 --> 00:31:16,000
a crisis is serious

467
00:31:16,010 --> 00:31:17,630
that turning to

468
00:31:17,640 --> 00:31:21,340
china to rescue us from disaster

469
00:31:21,350 --> 00:31:27,240
washington's unilateral resort to force

470
00:31:27,250 --> 00:31:31,660
was articulated publicly by the bush administration

471
00:31:31,670 --> 00:31:35,680
and its national security strategy member

472
00:31:35,690 --> 00:31:37,960
in two thousand two

473
00:31:37,980 --> 00:31:41,630
breaking no new ground however

474
00:31:41,640 --> 00:31:45,860
even before the two thousand election

475
00:31:45,880 --> 00:31:48,750
condoleeza rice writing

476
00:31:48,760 --> 00:31:50,490
foreign affairs

477
00:31:50,500 --> 00:31:54,590
and establishing journal condemned what she called

478
00:31:54,600 --> 00:32:01,110
the reflexive appeal to notions of international law and norms and the belief that the

479
00:32:01,110 --> 00:32:07,540
support of many states or even better of institutions like the united nations is essential

480
00:32:07,540 --> 00:32:11,030
to the legitimate exercise of power

481
00:32:11,050 --> 00:32:13,700
that she says is completely wrong

482
00:32:13,720 --> 00:32:18,420
referring of course to exercise of power by the united states

483
00:32:18,470 --> 00:32:19,730
the usual

484
00:32:19,810 --> 00:32:22,730
except in real

485
00:32:23,650 --> 00:32:25,450
extremist positions

486
00:32:25,460 --> 00:32:29,480
has long been conventional among the powerful

487
00:32:29,530 --> 00:32:36,180
illustrate of the key to the liberal end of the spectrum in the united states

488
00:32:36,200 --> 00:32:42,650
take one case elder statesman kennedy advisedby matches

489
00:32:42,670 --> 00:32:46,450
in form the american society of international law

490
00:32:46,500 --> 00:32:48,700
in nineteen sixty three

491
00:32:48,730 --> 00:32:55,210
that no legal issue arises when the united states response to a challenge to its

492
00:32:56,550 --> 00:32:58,540
our and christy

493
00:32:58,560 --> 00:33:04,080
he was speaking shortly after the cuban missile crisis

494
00:33:04,100 --> 00:33:08,130
which brought the world to the brink of of nuclear war

495
00:33:08,140 --> 00:33:09,520
two months earlier

496
00:33:09,540 --> 00:33:14,800
as a result in large part of the s international terrorism

497
00:33:14,930 --> 00:33:21,230
turning to the nineteen nineties the clinton doctrine was that the united states has the

498
00:33:22,770 --> 00:33:28,020
according to resort to unilateral use of military power

499
00:33:28,040 --> 00:33:30,370
to defend vital interests

500
00:33:30,380 --> 00:33:34,320
such as ensuring uninhibited access

501
00:33:34,340 --> 00:33:39,020
the key markets energy supplies and strategic resources

502
00:33:39,040 --> 00:33:44,940
is even without the pretext was later revised

503
00:33:44,950 --> 00:33:46,810
taken literally

504
00:33:46,860 --> 00:33:52,430
the clinton doctrine is more expensive than bush's national security strategy

505
00:33:52,440 --> 00:33:54,520
which aroused enormous

506
00:33:54,530 --> 00:33:57,000
here concern around the world

507
00:33:57,020 --> 00:34:06,020
and elicited very harsh criticism even within the foreign policy establishment in the united states

508
00:34:06,020 --> 00:34:08,110
so that the charge cannot easily no

509
00:34:08,150 --> 00:34:10,290
no no no

510
00:34:10,350 --> 00:34:13,110
we don't want any accidents just sit there

511
00:34:14,150 --> 00:34:18,410
OK now make sure that your feet always on this plate

512
00:34:18,460 --> 00:34:20,500
because we need very good

513
00:34:20,510 --> 00:34:22,900
in some way not on the wood

514
00:34:28,530 --> 00:34:29,680
every question

515
00:34:29,690 --> 00:34:34,400
alex alex alex alex is going to hold this in his hand which are ten

516
00:34:35,790 --> 00:34:38,100
you hold a higher

517
00:34:38,160 --> 00:34:39,540
and when eric

518
00:34:39,540 --> 00:34:40,690
when alex

519
00:34:40,700 --> 00:34:42,580
get charged

520
00:34:42,600 --> 00:34:46,060
you will see that the ten cells also get charged

521
00:34:46,070 --> 00:34:47,530
you should hold the

522
00:34:47,570 --> 00:34:50,960
the the tenth of themselves in your hand the metal yes

523
00:34:50,970 --> 00:34:55,230
and so the ten will get charged with equal charges repel each other and so

524
00:34:55,230 --> 00:34:58,580
you will see that the ten cells will start doing this

525
00:34:58,610 --> 00:35:01,080
so that will tell you then that alex's

526
00:35:01,090 --> 00:35:03,070
going to get charged

527
00:35:03,140 --> 00:35:07,090
and i also have ten cells in my hands and so you'll see that i

528
00:35:07,090 --> 00:35:08,900
also get charged

529
00:35:09,040 --> 00:35:11,710
you might be able to tell that this charge

530
00:35:11,760 --> 00:35:15,010
it's the opposite charge of mean that's the conservation

531
00:35:15,060 --> 00:35:17,840
of charge

532
00:35:17,880 --> 00:35:20,510
then i'll touch alex

533
00:35:20,550 --> 00:35:21,990
and we'll see whether

534
00:35:21,990 --> 00:35:25,220
there's any reason to believe that indeed

535
00:35:25,240 --> 00:35:28,100
there is charge moving between us that means

536
00:35:28,140 --> 00:35:30,660
an electric current

537
00:35:30,720 --> 00:35:32,970
you're ready for this

538
00:35:34,680 --> 00:35:36,240
you still not nervous yet

539
00:35:36,290 --> 00:35:41,600
OK man i gotta get a nice bit of piece of cat fur

540
00:35:41,680 --> 00:35:46,870
is a good one

541
00:35:46,870 --> 00:35:52,310
and i will join you

542
00:35:52,330 --> 00:35:54,280
funny you know there

543
00:35:54,330 --> 00:35:56,530
but i am

544
00:35:58,350 --> 00:36:00,810
this is dangerous stuff

545
00:36:01,950 --> 00:36:05,370
OK so holding like test

546
00:36:06,430 --> 00:36:07,430
there we go

547
00:36:17,600 --> 00:36:20,850
ten cells i should have i should have had mine with

548
00:36:22,760 --> 00:36:24,640
i'll get my i'll get mine

549
00:36:24,700 --> 00:36:26,390
just stay a you are right

550
00:36:26,410 --> 00:36:54,030
OK you see and also charged

551
00:36:54,050 --> 00:36:55,390
these charts

552
00:36:55,410 --> 00:36:58,200
look at me look at me

553
00:36:58,220 --> 00:36:59,810
look at me look at me

554
00:36:59,810 --> 00:37:02,160
look at me about this you know

555
00:37:02,180 --> 00:37:08,950
one of the torture knows we have to do this again

556
00:37:14,390 --> 00:37:16,870
you have to do it again

557
00:37:19,180 --> 00:37:30,430
OK turned to me

558
00:37:41,140 --> 00:37:44,100
the way one

559
00:37:46,140 --> 00:37:49,030
going to make it worse

560
00:37:49,050 --> 00:37:54,080
give me to ten cells

561
00:37:55,080 --> 00:38:02,200
i have here

562
00:38:02,240 --> 00:38:03,950
neon flesh two

563
00:38:04,010 --> 00:38:10,470
we've seen this before

564
00:38:10,510 --> 00:38:13,550
now i want you to hold it in your hand

565
00:38:13,600 --> 00:38:16,680
under no circumstances no matter what happened

566
00:38:16,720 --> 00:38:17,810
let it go

567
00:38:17,870 --> 00:38:20,790
because it will break and they very expensive

568
00:38:20,870 --> 00:38:24,280
good all this in your hand

569
00:38:24,330 --> 00:38:27,780
and now i'm going to beat you again

570
00:38:27,790 --> 00:38:31,100
and instead of touching you know

571
00:38:31,100 --> 00:38:34,760
i will not hold i'll talk to the other side

572
00:38:34,810 --> 00:38:38,680
and if no current is flowing strongly enough

573
00:38:38,720 --> 00:38:40,700
between him and me

574
00:38:40,740 --> 00:38:43,220
you may see some light

575
00:38:43,310 --> 00:38:46,890
that tells you then that indeed

576
00:38:46,910 --> 00:38:48,640
that that comes later alex

577
00:38:51,760 --> 00:38:56,850
you patients you perfect MIT students

578
00:38:57,060 --> 00:39:01,010
so while i told that that your hand and i'm not joking when i say

579
00:39:01,030 --> 00:39:02,560
don't drop that

580
00:39:03,310 --> 00:39:04,640
i have to set the

581
00:39:04,640 --> 00:39:08,030
the light in a very special way so that we have

582
00:39:10,220 --> 00:39:13,220
i'm going to turn off

583
00:39:13,280 --> 00:39:18,720
make sure i have the

584
00:39:18,790 --> 00:39:22,530
michael's maybe you could help that i will be first

585
00:39:22,530 --> 00:39:24,510
and then at the very last minute

586
00:39:24,530 --> 00:39:30,140
before we do the discharge through the neon that you then turn all the lights

587
00:39:30,140 --> 00:39:33,280
you should well you could do worse but you shouldn't

588
00:39:33,300 --> 00:39:37,550
you don't need to because you just memorize you start to fill in the table

589
00:39:37,550 --> 00:39:38,490
in your head

590
00:39:38,530 --> 00:39:41,930
and so this is some of the things that we can quickly have that kind

591
00:39:41,930 --> 00:39:44,970
of form two you just basically fill in the table as you find out what

592
00:39:44,970 --> 00:39:47,950
the right answer is you you know it and you can write down

593
00:39:52,590 --> 00:39:56,120
they could actually the not not input that would have been five function to learn

594
00:40:00,070 --> 00:40:03,570
why do you say that because you said i don't know twice you've you had

595
00:40:03,570 --> 00:40:05,280
you said i don't know if it is zero and you said i don't know

596
00:40:05,280 --> 00:40:07,120
for the one

597
00:40:10,320 --> 00:40:14,300
it is use

598
00:40:14,320 --> 00:40:17,820
the reason why

599
00:40:23,970 --> 00:40:27,120
so the function that i was just doing is deterministic is that is that fix

600
00:40:31,930 --> 00:40:36,730
and also i let that example off saying it's a function from to be to

601
00:40:36,730 --> 00:40:40,300
cut its sorry i was that when you say constant human you mean like

602
00:40:40,490 --> 00:40:44,630
every time its input is zero it's always one yet to deterministic function in that

603
00:40:44,630 --> 00:40:49,280
example if it was a probabilistic function you could learn the probabilities this two probabilities

604
00:40:49,930 --> 00:40:54,160
well for each one you run a separate copy of this algorithm right so you

605
00:40:54,160 --> 00:40:57,720
keep count of when you've heard zero is an input how many successes how many

606
00:40:57,720 --> 00:41:01,510
failures one her one is an input how many systemic so even though this feels

607
00:41:01,510 --> 00:41:04,740
for silly because you say you know i don't know thirty times in a row

608
00:41:04,740 --> 00:41:08,490
and you know it it's a little more interesting if there's an input involved right

609
00:41:08,490 --> 00:41:11,240
so if i tell you zero you have to learn the probability for zero and

610
00:41:11,240 --> 00:41:14,590
you have to learn probably for one year keeping two separate counts and so you

611
00:41:14,590 --> 00:41:17,820
might say i don't know for a while and then start knowing one of them

612
00:41:17,820 --> 00:41:21,030
and then start saying i don't know again when i give you different parts

613
00:41:22,530 --> 00:41:25,820
it starts of simple but as you start to compose these laws it gets more

614
00:41:25,820 --> 00:41:26,930
and more interesting

615
00:41:26,950 --> 00:41:28,390
i did see hand

616
00:41:28,450 --> 00:41:33,200
partial hands there's a whole here go

617
00:41:54,320 --> 00:42:01,160
so so the game here is if if if we're trying to predict the probability

618
00:42:01,240 --> 00:42:04,590
the thing is supposed to output to me is the probability

619
00:42:04,660 --> 00:42:08,570
right so that probability can be arbitrarily close to the true answer even though none

620
00:42:08,570 --> 00:42:12,370
of the examples you get so you know if it's fair coin eventually should learn

621
00:42:12,370 --> 00:42:15,570
to see something like a half but none of your data was the half right

622
00:42:15,570 --> 00:42:19,470
i give you just zeros and ones is an example as is the case example

623
00:42:19,490 --> 00:42:22,550
right so yes so i could define this more formally but

624
00:42:23,840 --> 00:42:26,370
i'm being forced to do so gradually part

625
00:42:27,140 --> 00:42:29,490
for their hands so we can OK so

626
00:42:29,530 --> 00:42:33,370
so so this is a couple things that we can quickly learn effectively so far

627
00:42:33,370 --> 00:42:36,050
we can just a single coin and

628
00:42:36,430 --> 00:42:38,840
a single coin

629
00:42:38,850 --> 00:42:43,340
conditioned on a small set up a finer fight sort of inputs for example

630
00:42:43,350 --> 00:42:45,550
we separately

631
00:42:45,590 --> 00:42:49,320
we could learn a let's say that the output

632
00:42:49,370 --> 00:42:52,570
this is no input but the output is a bunch of numbers which are

633
00:42:53,050 --> 00:42:57,010
the probabilities and all the examples that i give you are

634
00:42:57,030 --> 00:42:58,350
draws from that

635
00:42:58,370 --> 00:43:03,140
vector so you like it like something

636
00:43:03,160 --> 00:43:06,930
like a bunch of coins almost bunch with coins and coin one is the probability

637
00:43:06,930 --> 00:43:11,160
quite two has from quite probability point three is the probability and the examples that

638
00:43:11,160 --> 00:43:15,030
i give for training are what conflict those coins and tell you which ones came

639
00:43:15,030 --> 00:43:18,120
up heads and which ones tails on each trial but you can start to pull

640
00:43:18,120 --> 00:43:22,120
those statistics and in the same way again so if the output is the vector

641
00:43:22,180 --> 00:43:24,370
r each component is probability

642
00:43:24,430 --> 00:43:28,450
then is always you can look quickly each of the components of the vector you

643
00:43:28,450 --> 00:43:30,470
can quickly learn the entire vector

644
00:43:30,490 --> 00:43:35,220
if the function you're trying to learn is a mapping from a big input space

645
00:43:35,620 --> 00:43:40,050
is partitioned in some way and each within each partition you have to learn

646
00:43:40,090 --> 00:43:45,870
some quick learnable class then you can learn the whole class because you just running

647
00:43:45,870 --> 00:43:48,840
a separate quick learner for each piece of that partition

648
00:43:48,840 --> 00:43:52,780
so these seem like really kind of simple obvious examples but what's nice is that

649
00:43:52,780 --> 00:43:56,180
this is exactly what you need to make a standard transition function in

650
00:43:56,200 --> 00:43:59,200
reinforcement learning right so all that is it's a mapping

651
00:43:59,260 --> 00:44:03,410
which takes SNA is input which to partition the space and then we get to

652
00:44:03,410 --> 00:44:07,570
observe are these these outcomes in was state s seven it came up as a

653
00:44:07,570 --> 00:44:08,950
result yes or no

654
00:44:09,640 --> 00:44:12,800
just with the pieces that we have so far we can quickly learn a transition

655
00:44:12,800 --> 00:44:16,200
function and because we can quickly transition function we're going to be able to make

656
00:44:16,200 --> 00:44:19,850
a PAC MDP algorithm that people already knew how to do that with any quick

657
00:44:19,850 --> 00:44:23,970
learning mumbo-jumbo in between but we're going to start composing them in more interesting ways

658
00:44:23,970 --> 00:44:27,530
and get some new algorithms that had been

659
00:44:27,570 --> 00:44:28,780
discovered before

660
00:44:28,800 --> 00:44:33,590
another thing you can also quickly and the union of two kwik learnable classes to

661
00:44:33,680 --> 00:44:39,210
various ways of composing these things that are that all work out

662
00:44:39,220 --> 00:44:42,960
OK more less this i think already that

663
00:44:43,000 --> 00:44:47,500
they are max algorithm for boston internal what it does lead to say that this

664
00:44:47,500 --> 00:44:49,630
way but we can you can think of it as what they're doing is a

665
00:44:49,630 --> 00:44:54,420
quick learner transition function t and for anything it's not known it assumes that the

666
00:44:54,420 --> 00:44:58,390
q values for the state action pairs have maximum reward anything that doesn't know about

667
00:44:58,390 --> 00:45:02,780
yet because it has visited enough times is assumed to be really high reward nothing

668
00:45:02,780 --> 00:45:05,880
could be higher and so what it does is it goes and visits those if

669
00:45:05,880 --> 00:45:09,500
it can and if we can then it stays among the states that can visit

670
00:45:09,500 --> 00:45:11,410
and gets near optimal reward

671
00:45:11,420 --> 00:45:15,430
so it's a very simple elegant out all it's doing is counting the number of

672
00:45:15,430 --> 00:45:19,920
times it tried to each state action pair when count goes over threshold it uses

673
00:45:19,920 --> 00:45:23,000
the empirical distribution it is found as true

674
00:45:23,000 --> 00:45:27,930
before that point it just uses some optimistic value that doesn't even try to estimate

675
00:45:27,930 --> 00:45:29,380
the probability

676
00:45:29,500 --> 00:45:31,460
all right so

677
00:45:31,470 --> 00:45:35,840
ooh that works to get your PAC MDP bound and the total mistake to the

678
00:45:35,840 --> 00:45:37,740
bounded ahead of before

679
00:45:37,780 --> 00:45:40,140
and that were yes

680
00:45:44,640 --> 00:45:49,740
right so so in this in this particular case what is the transition function well

681
00:45:49,740 --> 00:45:51,280
for some state like

682
00:45:51,280 --> 00:45:52,780
you know

683
00:45:52,790 --> 00:45:55,430
the robot is thirty degrees

684
00:45:55,490 --> 00:45:59,470
so it's discretized so thirty degrees and it's going to try some action

685
00:45:59,500 --> 00:46:04,450
left and we were trying to estimate the probability that actually goes left say well

686
00:46:04,450 --> 00:46:06,460
we've only tried it six times

687
00:46:06,690 --> 00:46:09,820
that's mostly gone left but we're going to try it four more times before we

688
00:46:09,820 --> 00:46:13,160
can say we've estimated that probability with extremely high

689
00:46:13,160 --> 00:46:18,570
convert this state into something that you can apply only to learn

690
00:46:18,590 --> 00:46:20,680
in the based techniques

691
00:46:20,700 --> 00:46:28,120
you basically have to extract finite length sliding window from test sequence so

692
00:46:28,180 --> 00:46:30,280
basically you may correct

693
00:46:31,450 --> 00:46:34,120
for example if your sequences long let's say

694
00:46:34,120 --> 00:46:35,780
one hundred

695
00:46:35,820 --> 00:46:37,180
data instances

696
00:46:37,220 --> 00:46:40,930
and you choose to hear sliding window of ten

697
00:46:40,970 --> 00:46:41,930
you're going

698
00:46:41,930 --> 00:46:46,370
the sliding window then and new according to sequencing ninety one

699
00:46:46,390 --> 00:46:50,570
they so basically this sequence is represented with the new

700
00:46:50,590 --> 00:46:52,620
data set of sequences

701
00:46:54,090 --> 00:46:58,550
for every sliding intervened you basically trying to find

702
00:46:58,600 --> 00:47:01,620
its frequency in the training data sets

703
00:47:01,720 --> 00:47:07,410
and basically using this frequency has to measure for anomaly so inverse of this frequencies

704
00:47:07,410 --> 00:47:11,510
basically the anomaly score if you see in this frequency more

705
00:47:11,550 --> 00:47:16,340
that means that probably correspond to majority became an inverse of frequencies low so it

706
00:47:16,340 --> 00:47:17,870
has long core

707
00:47:17,890 --> 00:47:22,090
and then you finally combined is serving the anomaly score to obtain

708
00:47:23,470 --> 00:47:27,760
anomaly detection score for all those sequences so basically since u

709
00:47:28,700 --> 00:47:32,530
the entire sequence to this sliding windows combining everything two

710
00:47:32,530 --> 00:47:35,240
have the final anomaly score for that for that

711
00:47:35,280 --> 00:47:39,910
for the sequence

712
00:47:41,640 --> 00:47:44,870
can just got everything

713
00:47:44,930 --> 00:47:46,840
so in markovian techniques

714
00:47:46,840 --> 00:47:49,620
more you are trying to use

715
00:47:49,680 --> 00:47:51,320
the information

716
00:47:51,320 --> 00:47:56,450
about transitions from one state to another this is also called state based approaches

717
00:47:56,450 --> 00:47:58,180
so basically

718
00:47:58,990 --> 00:48:00,430
the basics of any

719
00:48:00,430 --> 00:48:03,450
the more common technique trying to estimate the probability

720
00:48:03,510 --> 00:48:07,050
of transitioning between one state and another state

721
00:48:07,070 --> 00:48:10,970
so in this case you think this estimate for the probability of each event of

722
00:48:10,970 --> 00:48:12,180
the test sequence

723
00:48:12,180 --> 00:48:14,840
conditioned on the previously observed steps

724
00:48:16,410 --> 00:48:20,720
i usually try to combine the pre event probabilities to obtain an overall anomaly scores

725
00:48:20,740 --> 00:48:24,300
what about how this exactly work so basically

726
00:48:24,490 --> 00:48:27,240
again here

727
00:48:28,010 --> 00:48:32,450
events so you sequence is combined of serious of events

728
00:48:32,450 --> 00:48:36,320
so right now in the standard final state alternate

729
00:48:37,700 --> 00:48:40,370
event probability is conditioned on previous

730
00:48:40,530 --> 00:48:43,180
minus events so basically for every serious events

731
00:48:43,200 --> 00:48:44,390
you're looking

732
00:48:44,450 --> 00:48:48,390
if i can simple a and inaccessible b and c trying to see from the

733
00:48:49,240 --> 00:48:51,200
how many times i have

734
00:48:51,220 --> 00:48:53,570
the observation eight

735
00:48:53,620 --> 00:48:57,950
if a leads to b and actually be is followed by a or something so

736
00:48:57,950 --> 00:49:02,010
basically from these data trying to compute this transitional probabilities

737
00:49:02,070 --> 00:49:04,820
and then the forces of these events

738
00:49:04,860 --> 00:49:07,680
you have city actually series of transitions

739
00:49:07,700 --> 00:49:09,180
and then you're computing

740
00:49:10,760 --> 00:49:15,430
probable to have this serious of transitions from this kind of probability matrix that you

741
00:49:15,430 --> 00:49:17,030
construct it from the history

742
00:49:17,050 --> 00:49:18,510
so that's

743
00:49:18,570 --> 00:49:22,260
that's typical of a to construct is kind of a markovian

744
00:49:22,280 --> 00:49:23,100
the model

745
00:49:23,120 --> 00:49:27,140
so this standard find state automated you have

746
00:49:27,140 --> 00:49:30,990
if previous l minus events do not occur in training data

747
00:49:31,010 --> 00:49:34,390
that means the event is ignored because you don't have this information in the people

748
00:49:34,390 --> 00:49:37,640
that are constructed because if you encounter new

749
00:49:37,700 --> 00:49:44,050
music if you go to this transition probability matrix you have this information we cannot

750
00:49:45,070 --> 00:49:48,860
what's the probability that so you can just say that this event is ignored i'm

751
00:49:48,860 --> 00:49:51,640
not saying this is normal or anomalous

752
00:49:51,820 --> 00:49:55,590
there are several modifications of this finite state automaton

753
00:49:55,600 --> 00:49:59,280
in his face if it's easy

754
00:49:59,860 --> 00:50:02,700
the main idea is the same as here so

755
00:50:02,700 --> 00:50:08,240
basically but previous l minus one minus events are treated in different ways

756
00:50:08,340 --> 00:50:12,410
if this previous minus one events do not occur in training data

757
00:50:12,510 --> 00:50:17,050
the event probability is zero so that means

758
00:50:17,050 --> 00:50:20,410
it's anomaly because because

759
00:50:21,070 --> 00:50:22,820
so there is another approach

760
00:50:22,840 --> 00:50:24,970
probabilistic suffix trees

761
00:50:24,990 --> 00:50:27,680
again very similar to final state

762
00:50:27,700 --> 00:50:33,760
approaches and the only difference between the support base how they consider this

763
00:50:33,760 --> 00:50:36,410
previous l minus one event

764
00:50:36,470 --> 00:50:40,240
in this case if previous elements events do not occur in the training data

765
00:50:40,240 --> 00:50:42,470
sufficient number of times

766
00:50:42,530 --> 00:50:48,600
very pleased by the largest suffix which occurs more than three some pre specified threshold

767
00:50:48,660 --> 00:50:51,050
so that means

768
00:50:51,120 --> 00:50:55,180
if you have a sequence of symbols that are not occur all from the history

769
00:50:55,280 --> 00:50:57,360
then you're trying to find the

770
00:50:57,410 --> 00:51:02,390
some subsequence of this that occur from the past then for the subsequence you're trying

771
00:51:02,390 --> 00:51:04,590
to go to school

772
00:51:04,640 --> 00:51:08,140
transition probability matrix and find the problem

773
00:51:09,200 --> 00:51:11,660
in this approach we provide frankly

774
00:51:11,700 --> 00:51:13,950
so stop from colombia

775
00:51:13,970 --> 00:51:19,340
they're using this previous elements events do not occur in the training data

776
00:51:19,340 --> 00:51:22,720
sufficient number of times and then replaced with the largest subset

777
00:51:22,760 --> 00:51:27,180
it's not necessarily the subsequent so it can be any combination of the events

778
00:51:27,240 --> 00:51:30,620
and there are replaced their again going to the

779
00:51:30,620 --> 00:51:34,430
this is the first skipping the second which is sort of the same right the

780
00:51:35,370 --> 00:51:40,140
it's the same only the some of the positive terms OK let me just

781
00:51:40,160 --> 00:51:45,080
in all this one not

782
00:51:45,200 --> 00:51:51,060
so this is the difference between those terms and take the product with this difference

783
00:51:51,080 --> 00:51:54,830
so i have full terms in this dot product price one is this times this

784
00:51:55,520 --> 00:51:57,520
this and this and the two

785
00:51:57,520 --> 00:51:59,870
cross terms and

786
00:51:59,890 --> 00:52:02,410
the two questions are actually the same

787
00:52:04,520 --> 00:52:11,290
what you get is the dot product between five x five x

788
00:52:11,310 --> 00:52:12,700
this is the first

789
00:52:12,790 --> 00:52:17,500
then you get mixed with just two over two

790
00:52:17,680 --> 00:52:24,950
times the sun and then the dot product between five x five x i

791
00:52:24,970 --> 00:52:28,490
this is a bit small and then you have the lost

792
00:52:28,500 --> 00:52:29,830
which is

793
00:52:29,870 --> 00:52:33,660
one over m two square at

794
00:52:33,680 --> 00:52:36,620
and then we have a double sum

795
00:52:36,640 --> 00:52:38,410
well i and j

796
00:52:38,430 --> 00:52:41,270
and here we have filed x i

797
00:52:41,290 --> 00:52:47,370
and phi five x

798
00:52:47,430 --> 00:52:52,080
OK so five x five x in the mixed certain two and two

799
00:52:52,600 --> 00:52:55,540
it is the sum over five x come five x i

800
00:52:55,560 --> 00:52:59,470
and the last term is one of them will attempt to square and here we

801
00:52:59,470 --> 00:53:02,270
have the double sum five x i five x j

802
00:53:02,330 --> 00:53:07,200
and then we have three more terms of this form that correspond to the second

803
00:53:07,200 --> 00:53:09,430
part so within the first part now

804
00:53:10,470 --> 00:53:13,120
so if you then

805
00:53:15,120 --> 00:53:20,240
we're going

806
00:53:20,410 --> 00:53:23,520
so if you continue with this

807
00:53:23,540 --> 00:53:25,000
what you get is

808
00:53:25,310 --> 00:53:29,100
you get a five x five x but actually we will have the same thing

809
00:53:29,100 --> 00:53:32,240
again in the second term so that's going to cancel

810
00:53:32,270 --> 00:53:33,890
OK so this one

811
00:53:33,970 --> 00:53:36,890
we can ignore it cancelled with the

812
00:53:36,910 --> 00:53:38,850
corresponding part in the second term

813
00:53:39,080 --> 00:53:41,270
however what we have left is

814
00:53:41,370 --> 00:53:47,100
this term here

815
00:53:47,290 --> 00:53:55,660
this is sum of all negative points and all right this is k come i

816
00:53:55,660 --> 00:53:59,270
x i we know how to compute the product we just substitute the kernel

817
00:53:59,410 --> 00:54:04,520
so this is k of x come i x i

818
00:54:04,560 --> 00:54:06,600
then we have the same

819
00:54:08,100 --> 00:54:11,450
from the second distance right the distance to the positive class

820
00:54:11,950 --> 00:54:16,350
however with the different sign up here we would have another term like this

821
00:54:16,370 --> 00:54:18,930
the plus

822
00:54:18,950 --> 00:54:20,930
and with one

823
00:54:21,350 --> 00:54:25,490
and with some being over the positive points

824
00:54:26,850 --> 00:54:31,160
and here we have the same thing day of x come i x i

825
00:54:31,240 --> 00:54:34,620
and now we have this term here

826
00:54:34,680 --> 00:54:42,500
again all right this in terms of the kernel

827
00:54:42,620 --> 00:54:45,350
so is the sum of all

828
00:54:45,370 --> 00:54:47,520
i and j ranging over all

829
00:54:47,540 --> 00:54:49,810
negative points

830
00:54:49,830 --> 00:54:52,520
so here i have k of text

831
00:54:55,370 --> 00:54:57,160
and then i have the same thing again

832
00:54:57,180 --> 00:55:02,100
of the other class again with the different signs so i have one over n

833
00:55:02,120 --> 00:55:03,870
one square

834
00:55:04,100 --> 00:55:08,890
now the sum of all positive pairs of points

835
00:55:08,910 --> 00:55:11,470
x i x j

836
00:55:11,520 --> 00:55:17,000
OK now let's see whether this is correct

837
00:55:17,410 --> 00:55:20,540
if you compare this to the

838
00:55:20,580 --> 00:55:24,520
combination here on the blackboard

839
00:55:24,540 --> 00:55:27,220
you can see that

840
00:55:27,220 --> 00:55:28,330
OK so here

841
00:55:28,370 --> 00:55:32,680
here we have minus two over two times this kernel expansion it's up to a

842
00:55:32,680 --> 00:55:35,350
factor of two we have this term here

843
00:55:35,540 --> 00:55:39,490
here we have a plus two and one times the kernel expansion

844
00:55:39,500 --> 00:55:43,200
so again up to a factor of two we have this thing here

845
00:55:43,240 --> 00:55:46,890
and down here we have one of two squares

846
00:55:47,640 --> 00:55:49,640
the negative ones

847
00:55:49,660 --> 00:55:51,970
so this this one

848
00:55:52,060 --> 00:55:53,160
and we have

849
00:55:53,200 --> 00:55:55,790
minus one over one squared

850
00:55:55,810 --> 00:55:59,410
some of the positive and again we have this factor of two

851
00:55:59,490 --> 00:56:01,990
which is different so up to a factor of two

852
00:56:02,000 --> 00:56:05,080
in the argument of the decision function

853
00:56:05,120 --> 00:56:09,430
we have the same and of course this decision function is invariant to scaling with

854
00:56:09,430 --> 00:56:13,890
the positive number so multiplying here with the factor of two

855
00:56:13,890 --> 00:56:16,350
this thing the

856
00:56:16,950 --> 00:56:20,410
signed function will not notice it so we have the same solutions

857
00:56:20,680 --> 00:56:24,600
OK so

858
00:56:24,620 --> 00:56:26,890
that's actually see

859
00:56:26,930 --> 00:56:31,180
so now that we've spent quite a bit of time this let's see

860
00:56:31,580 --> 00:56:35,330
let's see how this kind of classifier actually does

861
00:56:35,330 --> 00:56:36,640
so it's

862
00:56:36,660 --> 00:56:41,060
i hope you will agree it's a very simple type of classifier we're just mapping

863
00:56:41,060 --> 00:56:42,330
all points

864
00:56:42,350 --> 00:56:45,810
into some other space and then we compute the mean of the two classes and

865
00:56:45,810 --> 00:56:51,450
take where point is close to the one after the other one yes

866
00:56:51,540 --> 00:56:54,080
OK i'll tell you out in the second

867
00:56:54,200 --> 00:56:59,760
the good question is why is it called thousand windows

868
00:57:18,270 --> 00:57:20,870
OK so

869
00:57:20,890 --> 00:57:22,330
how so little demo

870
00:57:22,330 --> 00:57:23,730
parameters which do

871
00:57:23,730 --> 00:57:27,620
i mean that we learn the structure of them to some extent

872
00:57:27,680 --> 00:57:33,010
and one could use some kind of nonparametric learning in a bayesian set up to

873
00:57:33,620 --> 00:57:39,250
if you really wanted to learn something within about f and g within this framework

874
00:57:39,320 --> 00:57:43,470
so there the the model will be using them to state evolution density

875
00:57:43,480 --> 00:57:49,290
and the observation density in this i'm using this symbol to denote the random variable

876
00:57:49,290 --> 00:57:51,310
to the left is drawn as the sample

877
00:57:51,580 --> 00:57:56,980
is drawn from the density on the right

878
00:57:57,000 --> 00:58:02,700
and because of the independence assumption that i've made the conditional independence assumptions we can

879
00:58:02,700 --> 00:58:04,200
write the joint

880
00:58:04,210 --> 00:58:05,290
density for

881
00:58:05,310 --> 00:58:08,270
all of the states from not t

882
00:58:08,280 --> 00:58:12,550
and all of the data in terms of an initial state density

883
00:58:12,560 --> 00:58:15,270
f of x not to get things started

884
00:58:15,310 --> 00:58:18,550
and then using the probability chain rule we can change in all of the conditional

885
00:58:19,720 --> 00:58:21,720
the state dynamics

886
00:58:22,920 --> 00:58:28,040
times all the observation densities overall times from nought to take

887
00:58:28,050 --> 00:58:31,960
so we can we have this this thing is fully specified so in actually what

888
00:58:31,960 --> 00:58:36,060
questions do need to answer the the the the if we if we want to

889
00:58:36,060 --> 00:58:41,560
look at the conditional distribution for x given some set of observations y

890
00:58:41,590 --> 00:58:46,060
then we won't anything in general about the properties of this joint density even though

891
00:58:46,060 --> 00:58:52,270
we can write it down we know things about its moments and the other countries

892
00:58:52,270 --> 00:58:58,280
that we want to estimate except in special cases like the linear gaussians model

893
00:58:58,290 --> 00:59:02,640
also sometimes use the notation x nor

894
00:59:03,670 --> 00:59:06,020
to be the collect the vector of

895
00:59:06,070 --> 00:59:12,460
data points from north through t similarly the sort vector states wine authority to be

896
00:59:12,470 --> 00:59:15,600
the vector of observations not routine

897
00:59:17,180 --> 00:59:23,600
and represented in a sort of graphical model type thing was so we have the

898
00:59:23,610 --> 00:59:26,330
hidden state sequence proceeding through time

899
00:59:27,340 --> 00:59:30,650
by the dynamics f

900
00:59:30,660 --> 00:59:35,730
so there's a stochastic model connecting each of these conditional on one another and then

901
00:59:35,730 --> 00:59:41,370
you've got the observations hanging of those five observation density g

902
00:59:41,420 --> 00:59:47,920
so just to look at two very simple examples of how you would set up

903
00:59:47,920 --> 00:59:51,530
a linear autoregressive model observed in noise

904
00:59:52,360 --> 00:59:56,110
the the hidden state process i'm going to call z so that two

905
00:59:56,390 --> 01:00:01,460
linear autoregressive model is what is made up of the linear weighted sum of previous

906
01:00:02,720 --> 01:00:04,990
some noise to of t

907
01:00:05,000 --> 01:00:06,840
the observations y

908
01:00:07,810 --> 01:00:12,000
that hidden states that t plus noise w

909
01:00:12,050 --> 01:00:17,520
i will say that a if wt are independently distributed for the sake of argument

910
01:00:17,520 --> 01:00:19,370
argument there is zero mean

911
01:00:19,400 --> 01:00:22,460
gaussians the simplest possible that i guess

912
01:00:22,470 --> 01:00:28,820
just about and variances sigma risk sigma w respectively

913
01:00:28,840 --> 01:00:33,970
those effects and we're not doing parameter learning for this particular state space model set

914
01:00:33,970 --> 01:00:37,760
up although one could in principle append

915
01:00:37,790 --> 01:00:41,900
extra parameters on the state vector within the particle filtering framework

916
01:00:41,930 --> 01:00:43,200
so the is by

917
01:00:43,200 --> 01:00:46,970
they are coefficients the weights on that predictions

918
01:00:47,580 --> 01:00:52,300
and these are also fixed and known just for this set up here we observe

919
01:00:53,540 --> 01:00:57,510
and the unknown is a single set

920
01:00:57,520 --> 01:01:01,380
so former state vector we had to do that by

921
01:01:01,400 --> 01:01:04,260
augmenting z with some previous

922
01:01:04,620 --> 01:01:11,560
state values as in standard sort of state space deterministic state space model

923
01:01:11,620 --> 01:01:15,620
and then we can set up the state space model in the required form

924
01:01:15,670 --> 01:01:17,490
by saying that x t

925
01:01:17,520 --> 01:01:22,910
the the matrix times the previous activities that's the one study zt minus one plus

926
01:01:22,910 --> 01:01:27,770
the noise nets along of t which is a slightly modified version of the beauty

927
01:01:30,570 --> 01:01:34,210
why t the observation that is in there is is is is a matrix b

928
01:01:34,210 --> 01:01:38,050
times the state x plus the noise term w o t

929
01:01:38,060 --> 01:01:42,820
where the matrix a the required

930
01:01:42,820 --> 01:01:44,220
this thing here

931
01:01:45,250 --> 01:01:46,200
put together

932
01:01:46,210 --> 01:01:48,300
so the top row

933
01:01:48,310 --> 01:01:49,790
get it defines the

934
01:01:49,800 --> 01:01:51,080
the fundamental equation

935
01:01:51,140 --> 01:01:55,750
the autoregressive model and then the remaining rows

936
01:01:55,790 --> 01:02:00,430
to people in the previous elements of x to the next timepoint

937
01:02:01,080 --> 01:02:02,080
the observation

938
01:02:02,100 --> 01:02:06,370
the function that is is is is in fact a row vector just putting in

939
01:02:06,370 --> 01:02:12,860
the first element of the state vector x it's the observation

940
01:02:12,880 --> 01:02:20,330
and finally the noise term has the covariance matrix like so so just there's only

941
01:02:20,330 --> 01:02:26,460
one non-zero covariance elements corresponding to the deity that require the model

942
01:02:26,540 --> 01:02:31,610
now we can put that directly then into the former you need to evaluate density

943
01:02:31,610 --> 01:02:33,650
functions and so on because

944
01:02:33,670 --> 01:02:35,990
the density function for the dynamics

945
01:02:36,060 --> 01:02:37,240
is just a normal

946
01:02:37,260 --> 01:02:38,540
density function

947
01:02:38,560 --> 01:02:43,540
t plus one with me given by eight a times the previous state text and

948
01:02:43,540 --> 01:02:45,660
covariance given by

949
01:02:45,750 --> 01:02:47,250
capital sigma

950
01:02:47,270 --> 01:02:51,380
so for excellence and the observation function g of y

951
01:02:51,400 --> 01:02:55,210
given x another normal function centered on bx

952
01:02:55,250 --> 01:02:58,090
with variance sigma w square

953
01:02:58,120 --> 01:03:03,860
so this is the simplest nice most benign type of state space model linear gaussians

954
01:03:03,860 --> 01:03:08,010
state space model well i guess the that's the hidden markov model is just benign

955
01:03:08,010 --> 01:03:12,790
images on the discrete state space but in a continuous state space is the simplest

956
01:03:15,530 --> 01:03:21,560
it's an important special case of the state space model is used extensively to construct

957
01:03:21,560 --> 01:03:24,150
algorithms even in the long nonlinear

958
01:03:24,170 --> 01:03:28,600
OK with things like extended kalman filters and in the northern gulf in case things

959
01:03:28,600 --> 01:03:31,200
like the blackwellized particle filters

960
01:03:31,200 --> 01:03:36,320
these linear models will be a fundamental building block in some particle filters

961
01:03:36,370 --> 01:03:38,620
although we can look at fully nonlinear

962
01:03:39,330 --> 01:03:42,600
this is a sort of benchmark test model was used as a lot of the

963
01:03:42,600 --> 01:03:48,780
early papers in this area so here we can reconstruct some arbitrary nonlinear function of

964
01:03:48,780 --> 01:03:53,740
the previous state to predict the current status and add some noise onto it noise

965
01:03:53,740 --> 01:03:57,380
doesn't have to be added to the you can calculate the you can sample from

966
01:03:57,380 --> 01:03:59,160
the transition density

967
01:03:59,280 --> 01:04:03,050
here it is additive the observation function again can be so

968
01:04:03,100 --> 01:04:07,410
arbitrary pretty well arbitrary linear function of the state

969
01:04:07,430 --> 01:04:12,560
and things will still work and here i just specify the to be

970
01:04:12,670 --> 01:04:14,900
gas w to be independent

971
01:04:14,920 --> 01:04:16,320
galaxy with particular

972
01:04:18,510 --> 01:04:22,000
that's very easy to put into the state space formerly required

973
01:04:22,020 --> 01:04:29,320
basic formulation the TF function the dynamical model is again a normal distribution centered upon

974
01:04:29,350 --> 01:04:31,150
this laser pointers bit

975
01:04:32,700 --> 01:04:37,870
but to keep dying centred upon the function of x

976
01:04:37,920 --> 01:04:43,740
the variance sigma squares and the gene function the observation function as a normal distribution

977
01:04:43,750 --> 01:04:49,290
centered upon the nonlinear function b interacts with some variance sigma w scratch

978
01:04:49,290 --> 01:04:51,790
OK so that's all simple

979
01:04:51,800 --> 01:04:56,060
just a simple example of how to set up the state space model for this

980
01:04:56,060 --> 01:05:02,040
this this scenario the estimation tasks well let's suppose we've seen all the observations

981
01:05:02,050 --> 01:05:05,460
from some time up to the current president time t

982
01:05:05,470 --> 01:05:10,380
i wish to infer the hidden states so the sequence of hidden states running from

983
01:05:10,380 --> 01:05:17,510
not to assure thinking

984
01:05:17,570 --> 01:05:23,230
nice so we only have some hidden states x not through t

985
01:05:23,240 --> 01:05:28,120
and some of the tasks you might want to do with the monte carlo filtering

986
01:05:28,120 --> 01:05:34,430
setubal filtering itself is concerned with the marginal distribution of the current state x t

987
01:05:34,430 --> 01:05:35,730
given all the data

988
01:05:35,740 --> 01:05:37,660
from north korean t

989
01:05:37,660 --> 01:05:39,870
april predictability

990
01:05:40,540 --> 01:05:43,470
regular behaviour

991
01:05:43,480 --> 01:05:46,020
and so

992
01:05:46,030 --> 01:05:48,740
what i'd like to do is to make it through

993
01:05:48,770 --> 01:05:51,360
i'm not going to end up with

994
01:05:53,900 --> 01:05:58,710
as much as with some questions but i would like to point out a few

995
01:06:00,280 --> 01:06:02,800
features of the system

996
01:06:02,810 --> 01:06:04,920
that may be of benefit

997
01:06:05,000 --> 01:06:08,540
two the complexity science professionals

998
01:06:11,230 --> 01:06:14,430
perhaps stimulating them to use the tools

999
01:06:14,840 --> 01:06:18,280
in in ways that they have been considered before

1000
01:06:18,290 --> 01:06:24,810
the system in this sense is

1001
01:06:24,840 --> 01:06:27,270
has the features of turing machines

1002
01:06:27,290 --> 01:06:31,330
it gets in as an input

1003
01:06:31,470 --> 01:06:34,280
type of information in the in that

1004
01:06:34,290 --> 01:06:40,430
it is the start of the body with the infection trying on pleasure aging

1005
01:06:40,450 --> 01:06:41,770
all these

1006
01:06:42,250 --> 01:06:44,200
bits of information

1007
01:06:44,210 --> 01:06:46,690
that relate the start of the body

1008
01:06:46,730 --> 01:06:48,600
and the

1009
01:06:48,610 --> 01:06:55,230
this goes in to the immune system and comes the state of the immune response

1010
01:06:55,910 --> 01:06:58,350
the immune system is converting

1011
01:06:58,360 --> 01:06:59,890
one source

1012
01:07:00,100 --> 01:07:02,830
of information tapes

1013
01:07:02,850 --> 01:07:04,430
the state of the

1014
01:07:04,460 --> 01:07:06,750
issues the body into another

1015
01:07:06,770 --> 01:07:11,730
outputs a set of information states

1016
01:07:11,750 --> 01:07:15,070
which is the state of the system that makes it even more

1017
01:07:18,060 --> 01:07:23,940
so way superior to turing machine is that the output of the system

1018
01:07:23,980 --> 01:07:25,640
is designed

1019
01:07:26,850 --> 01:07:30,080
or at least leads to change

1020
01:07:30,100 --> 01:07:32,130
in the input

1021
01:07:32,360 --> 01:07:35,300
information in other words the way

1022
01:07:35,320 --> 01:07:43,100
as you see the when it comes to blows he dynamically the situation changes every

1023
01:07:44,070 --> 01:07:49,690
as the inflammatory response itself is orchestrated so the output

1024
01:07:49,810 --> 01:07:55,840
changes the input in this circular manner and even more power

1025
01:07:55,870 --> 01:07:59,100
complicated and complex is that the

1026
01:07:59,100 --> 01:08:00,680
turing machine

1027
01:08:00,700 --> 01:08:03,480
changes itself the goals

1028
01:08:03,480 --> 01:08:08,530
so the we have an input we have an output but the output then feeds

1029
01:08:08,530 --> 01:08:13,010
back on the input and actually feeds back on the system you can kind of

1030
01:08:13,100 --> 01:08:14,680
learning whatever

1031
01:08:16,100 --> 01:08:17,860
throughout life

1032
01:08:18,230 --> 01:08:23,070
system is learning from experience and that the brain is so then how does this

1033
01:08:24,110 --> 01:08:28,890
computation take place and what might it be able to

1034
01:08:28,910 --> 01:08:30,450
teach us about

1035
01:08:31,080 --> 01:08:37,000
some of the things that were interested in from the point of view complex systems

1036
01:08:37,020 --> 01:08:40,060
it's clear that the interactions

1037
01:08:41,960 --> 01:08:43,580
it's clear that there

1038
01:08:43,590 --> 01:08:47,010
they they sort themselves out into networks

1039
01:08:47,030 --> 01:08:53,230
and these interactions related to or create

1040
01:08:54,430 --> 01:08:56,900
now in

1041
01:08:56,950 --> 01:09:03,200
it's only an approach that medical science paradigmatic science we

1042
01:09:03,810 --> 01:09:13,120
like like in an engineer look for one-to-one relationships and we look for the world

1043
01:09:14,210 --> 01:09:16,620
in discrete causes and effects

1044
01:09:16,640 --> 01:09:20,270
but when we look at show what i mean we look at what the immune

1045
01:09:20,270 --> 01:09:21,960
system is doing

1046
01:09:21,970 --> 01:09:25,860
it is organising patterns

1047
01:09:25,880 --> 01:09:33,520
and not depending on the one-to-one relationships in fact one-to-one relationship really don't exist in

1048
01:09:33,520 --> 01:09:35,850
the face of the degeneracy

1049
01:09:36,070 --> 01:09:38,180
if there is something

1050
01:09:38,460 --> 01:09:40,280
quite simple

1051
01:09:40,300 --> 01:09:41,580
looking at

1052
01:09:41,590 --> 01:09:46,140
the architecture of the network architecture of the system

1053
01:09:46,360 --> 01:09:49,630
all along from

1054
01:09:49,640 --> 01:09:54,930
the weights one complex systems and invited the students

1055
01:09:54,950 --> 01:09:56,620
a master student

1056
01:09:56,640 --> 01:10:03,000
i think that the cells in the immune system organised

1057
01:10:03,250 --> 01:10:05,000
according to

1058
01:10:05,050 --> 01:10:09,910
so the occurrence of kinds of molecules that are produced by one so

1059
01:10:09,930 --> 01:10:11,360
and in fact

1060
01:10:11,380 --> 01:10:13,480
the story than others

1061
01:10:13,490 --> 01:10:15,850
and what we did was simply

1062
01:10:15,930 --> 01:10:22,880
take cells as nodes and we take the various cytokines

1063
01:10:22,970 --> 01:10:24,880
reduce them in way

1064
01:10:25,720 --> 01:10:27,980
edges of only

1065
01:10:28,000 --> 01:10:31,050
a one b single

1066
01:10:31,060 --> 01:10:32,430
i the mutual

1067
01:10:32,440 --> 01:10:37,850
and in which direction they go from one user to another immune cells from immune

1068
01:10:37,850 --> 01:10:44,130
cell two bodies from the bodies another body from bodies itself immune cells whether would

1069
01:10:47,610 --> 01:10:49,600
it was clear that

1070
01:10:49,600 --> 01:11:00,280
probably the trustees of to

1071
01:11:02,510 --> 01:11:05,740
so the key

1072
01:11:06,790 --> 01:11:10,610
it's not for

1073
01:11:21,830 --> 01:11:25,840
he a

1074
01:11:26,470 --> 01:11:28,520
the problem

1075
01:11:28,530 --> 01:11:32,240
while she

1076
01:11:38,800 --> 01:11:41,400
he's not just for you

1077
01:11:43,570 --> 01:11:44,970
it was you

1078
01:11:47,930 --> 01:11:53,620
and that's what

1079
01:12:01,710 --> 01:12:06,220
for more than

1080
01:12:17,970 --> 01:12:21,610
right at all

1081
01:12:21,820 --> 01:12:24,490
so goal

1082
01:12:24,500 --> 01:12:26,750
the small

1083
01:12:54,570 --> 01:13:02,230
can you

1084
01:13:02,260 --> 01:13:07,480
so i think that

1085
01:13:24,740 --> 01:13:30,810
it what want you get

1086
01:13:31,040 --> 01:13:32,650
so right

1087
01:13:42,690 --> 01:13:44,260
get your

1088
01:13:47,170 --> 01:13:49,840
the right

1089
01:13:49,970 --> 01:13:53,000
he moved

1090
01:13:56,770 --> 01:14:00,530
and so on

1091
01:14:09,880 --> 01:14:16,370
you get

1092
01:14:26,480 --> 01:14:30,740
you see

1093
01:14:36,670 --> 01:14:40,220
and from

1094
01:14:41,370 --> 01:14:42,430
this is

1095
01:14:59,680 --> 01:15:10,520
the decision

1096
01:15:18,080 --> 01:15:24,050
so we get

1097
01:15:25,410 --> 01:15:26,760
you should be

1098
01:15:37,830 --> 01:15:39,560
you it

1099
01:15:48,410 --> 01:15:50,290
when you

1100
01:15:50,290 --> 01:15:54,260
thank you for inviting me to never seen before i went quantum computing i actually

1101
01:15:54,260 --> 01:15:58,550
started out my first year perfectly as a machine learning person so i get to

1102
01:15:58,840 --> 01:16:04,620
experience my in an alternate life trajectory here different branch of the wave function so

1103
01:16:04,620 --> 01:16:06,380
i'm looking forward to learning a lot

1104
01:16:07,220 --> 01:16:07,990
but you know i did

1105
01:16:08,490 --> 01:16:11,850
presented them in terms of what i should talk about because you know i could

1106
01:16:11,850 --> 01:16:17,460
just give a standard technical talk about quantum computing theory but i wanted to somehow

1107
01:16:17,460 --> 01:16:18,700
related more to naps

1108
01:16:20,450 --> 01:16:23,290
yeah quantum information in the brain so

1109
01:16:23,890 --> 01:16:28,880
my challenge is going to be to speak for forty five minutes about an intersection

1110
01:16:28,880 --> 01:16:31,250
of two fields that might be the empty set

1111
01:16:32,690 --> 01:16:38,180
however we don't know for certain that it is the empty set and therefore i have something to talk about

1112
01:16:39,610 --> 01:16:40,320
okay so

1113
01:16:40,790 --> 01:16:44,930
often you know thee case that you know quantum mechanics might have something to do

1114
01:16:45,170 --> 01:16:50,230
with our cognition is parodied as the argument from two mysteries you know the mind

1115
01:16:50,230 --> 01:16:55,340
is mysterious quantum mechanics is also mysterious ergo they might be related somehow

1116
01:16:56,290 --> 01:17:02,760
okay so you might wonder you know what kind of scientifically irresponsible ignoramus you know would even toy

1117
01:17:03,360 --> 01:17:07,240
with such a you know and and obviously silly idea

1118
01:17:07,920 --> 01:17:08,540
so okay

1119
01:17:12,000 --> 01:17:15,870
right so so you know you've made you probably heard about roger penrose he actually

1120
01:17:16,160 --> 01:17:18,010
think something you know a hundred times

1121
01:17:18,890 --> 01:17:22,660
more radical than this the you know the brain is not merely a quantum computer

1122
01:17:22,930 --> 01:17:25,530
he thinks that the quantum gravitational computer

1123
01:17:25,920 --> 01:17:31,820
which could use sort of exotic new physics solve touring uncomputable problems okay but moving

1124
01:17:31,820 --> 01:17:36,370
on to serve the relative conservatives in this list right so i mean arthur eddington

1125
01:17:36,370 --> 01:17:38,970
you know wrote a great deal about you know how

1126
01:17:39,270 --> 01:17:43,470
maybe you know the uncertainty principle is relevant to sort of the free will and

1127
01:17:43,470 --> 01:17:46,800
determinism discussion you know as did a continent

1128
01:17:47,870 --> 01:17:54,090
please you several other these people alan turing maybe surprisingly was hugely influenced by adding

1129
01:17:54,620 --> 01:17:59,270
throughout his life and surely wrote you know several times about how maybe the uncertainty

1130
01:17:59,270 --> 01:18:04,630
principle you present some fundamental obstacle to scanning the state of the brain into a

1131
01:18:07,000 --> 01:18:07,480
okay so

1132
01:18:08,060 --> 01:18:10,480
you know even if you know the sort of connection is

1133
01:18:11,420 --> 01:18:14,860
ultimately rejected it's clear that you know at least worth considering

1134
01:18:15,910 --> 01:18:18,800
you know on the other hand as soon as we start thinking about this you

1135
01:18:18,800 --> 01:18:24,810
know we noticed an obvious problem left scale so here is a set three qubits

1136
01:18:24,810 --> 01:18:26,770
in an ion trap quantum computer

1137
01:18:27,190 --> 01:18:32,010
okay and so with less than one millimeter cross you know and that this is

1138
01:18:32,010 --> 01:18:35,360
a regime where quantum effects are predominant eyewear

1139
01:18:35,990 --> 01:18:38,000
you know that in fact these ions

1140
01:18:38,490 --> 01:18:42,690
i don't even have no definite locations so to speak you know there's just the

1141
01:18:42,690 --> 01:18:47,800
wavefunction describing them okay you consider only you know approximately make a picture like this

1142
01:18:48,440 --> 01:18:51,700
so you know and then on the other hand here is the neuron

1143
01:18:52,340 --> 01:18:58,120
you know and maybe something like ten thousand nanometers across okay and this is any regime r

1144
01:18:58,520 --> 01:19:00,190
decoherence predominate so

1145
01:19:00,600 --> 01:19:04,050
you know they are the neuron is in a bass it sort of in

1146
01:19:04,760 --> 01:19:11,930
contact with the external environment and that's constantly for forcing down its quantum state into a classical state

1147
01:19:13,140 --> 01:19:17,960
you know this is decoherence is the basic reason why we don't experience shrouding cats

1148
01:19:17,960 --> 01:19:19,420
in the realm of everyday life

1149
01:19:20,040 --> 01:19:24,500
now there's an intermediate regime i mean if you look at the synaptic junction that's

1150
01:19:24,510 --> 01:19:28,870
you know maybe a few nanometers across and in fact there have been arguments that

1151
01:19:28,870 --> 01:19:32,180
quantum effects are important for the you know modelling me

1152
01:19:32,620 --> 01:19:37,730
opening and closing of the sodium ion channels are being and the hodgkin huxley equation

1153
01:19:38,150 --> 01:19:44,530
okay but you know even then you know there's also a huge problem of timing so the physicist max tegmark

1154
01:19:45,080 --> 01:19:49,810
the calculation of you know what is the sort of longest possible time the quantum

1155
01:19:49,990 --> 01:19:55,460
superposition might be able to remain coherence is sort of the hot wet environment of

1156
01:19:55,460 --> 01:20:00,400
the brain right another generous assumptions you know maybe it could last for about ten

1157
01:20:00,400 --> 01:20:02,000
to the minus thirteen segments

1158
01:20:02,450 --> 01:20:02,930
okay so

1159
01:20:03,360 --> 01:20:04,850
if you look at you know the name

1160
01:20:04,940 --> 01:20:08,490
neuron firing rate right and that is orders of magnitude different

1161
01:20:09,010 --> 01:20:12,090
you know here looking at you know maybe ten to the minus three circuits

1162
01:20:13,520 --> 01:20:18,780
finally last but not least there's the problem of cringeworthy claims so i mean if

1163
01:20:18,780 --> 01:20:23,910
u on you know if you think that it's even worth started discussing you know

1164
01:20:23,910 --> 01:20:27,940
whether there's a connection between you know the mysteries of quantum mechanics and have

1165
01:20:28,410 --> 01:20:31,370
and if thought knew immediately find your allies

1166
01:20:31,950 --> 01:20:33,070
are people who

1167
01:20:33,680 --> 01:20:36,360
i think that quantum mechanics means that you know you can

1168
01:20:37,100 --> 01:20:42,410
create reality by by wishing you can channel some thirty thousand year-old the

1169
01:20:43,130 --> 01:20:48,130
cave woman in romford something you know this is from the movie was called what

1170
01:20:48,130 --> 01:20:50,060
the bleep do we know which by the way

1171
01:20:50,570 --> 01:20:52,380
quantum mechanics doesn't mean those things

1172
01:20:53,060 --> 01:20:54,460
okay so far

1173
01:20:55,050 --> 01:21:00,650
my view is that barring scientific revolution you know debates about quantum mechanics and mind

1174
01:21:00,790 --> 01:21:04,130
you know will just continue popping up like you whack-a-mole

1175
01:21:04,650 --> 01:21:06,940
and it's not even obvious that they shouldn't

1176
01:21:07,550 --> 01:21:14,540
because you asshole discuss you know i think that are genuinely is something profound that we don't understand about how

1177
01:21:14,960 --> 01:21:17,380
quantum mechanics can give rise to

1178
01:21:17,790 --> 01:21:22,850
be you know thee definite world that we subjectively perceive you know many people have

1179
01:21:22,850 --> 01:21:27,110
claimed to understand that over the last hundred years but you know it's questionable

1180
01:21:27,500 --> 01:21:28,490
if any of them have

1181
01:21:29,010 --> 01:21:31,390
okay so my modest goal

1182
01:21:31,890 --> 01:21:33,930
in this talk very modest talk

1183
01:21:34,370 --> 01:21:39,120
okay is going to be to explain you know various discoveries in the fields of

1184
01:21:39,120 --> 01:21:44,760
quantum computing and information that might bear on these debates now along the way also

1185
01:21:44,760 --> 01:21:49,930
discuss how a quantum computer could help or not help with fewer you know applied

1186
01:21:49,930 --> 01:21:54,870
machine learning tasks i could focus the whole talk around that's but you know i

1187
01:21:55,650 --> 01:22:00,720
frankly that the application of quantum computing is iterative already oversold as it is i

1188
01:22:00,720 --> 01:22:03,180
didn't want sort fan the flames anymore

1189
01:22:04,470 --> 01:22:11,310
then also discuss how in my own research concepts from machine learning have actually helped in quantum computing theory

1190
01:22:11,310 --> 01:22:18,050
the posterior and the marginal distributions are tractable and can be computed easily okay

1191
01:22:18,310 --> 01:22:22,350
and this is what's meant by conjugacy here okay basically it allows us to

1192
01:22:22,350 --> 01:22:27,400
to compute the posterior easily com allows us to compute the marginal easily okay

1193
01:22:28,120 --> 01:22:32,790
so coming back to our finite mixture model we can now make use of this conjugacy

1194
01:22:32,850 --> 01:22:37,650
to actually derive a Gibbs sampler for this so I guess Peter Green has

1195
01:22:37,670 --> 01:22:42,710
talked quite a bit about Gibbs sampling already Thursday and Friday right so this

1196
01:22:42,710 --> 01:22:43,480
should be ea

1197
01:22:43,480 --> 01:22:45,500
easy to for you so

1198
01:22:46,040 --> 01:22:47,850
if you do Gibbs sampling so

1199
01:22:47,870 --> 01:22:51,560
what we'd like to do is to a basically compute

1200
01:22:51,560 --> 01:22:54,850
posterior over the parameters and the latent variables

1201
01:22:54,900 --> 01:22:56,520
given observed z i

1202
01:22:56,580 --> 01:23:04,400
observed variables x i okay and Gibbs sampler is basically a Markov chain Monte Carlo sampler

1203
01:23:04,400 --> 01:23:06,850
in which we update each

1204
01:23:06,900 --> 01:23:13,850
unobserved variables by computing its conditional distribution given everything else sampling from that conditional distribution

1205
01:23:13,850 --> 01:23:15,830
and then repeating this over all

1206
01:23:15,850 --> 01:23:22,020
unobserved variables and just repeating this until you've converged to the posterior okay

1207
01:23:22,640 --> 01:23:26,060
so you can we can derive the

1208
01:23:26,100 --> 01:23:29,250
post the conditional distribution of z i

1209
01:23:29,330 --> 01:23:35,000
given all the other variables and you can see you can derive that the conditional probability of z

1210
01:23:35,000 --> 01:23:37,460
i taking on value k

1211
01:23:37,460 --> 01:23:40,770
is gonna be proportional to two terms

1212
01:23:40,940 --> 01:23:44,350
it's gonna be proportional to pi k

1213
01:23:44,400 --> 01:23:45,640
which is the

1214
01:23:45,650 --> 01:23:52,940
basically the conditional prior that's z i takes on value k times a conditional likelihood term

1215
01:23:52,940 --> 01:23:56,420
which tells us how likely is it that we observe x i

1216
01:23:56,560 --> 01:23:59,290
given that it belongs to cluster k

1217
01:23:59,750 --> 01:24:06,920
okay and if you normalize this you're gonna get the the basically the responsibility

1218
01:24:06,960 --> 01:24:09,370
of cluster k for data item i

1219
01:24:09,560 --> 01:24:15,480
okay and this is the conditional distribution for every i for every k you can compute this and you can update

1220
01:24:15,480 --> 01:24:17,140
each of the z ies

1221
01:24:17,230 --> 01:24:21,640
easily by just doing that and given the z ies we

1222
01:24:21,690 --> 01:24:26,650
would like to also get con the conditional distributions of the parameters as well and you

1223
01:24:26,650 --> 01:24:27,900
can see that

1224
01:24:27,900 --> 01:24:33,880
for the pies because of the Dirichlet multinominal conjugacy the conditional distribution of pi

1225
01:24:34,120 --> 01:24:37,420
given all the other random variables is gonna be Dirichlet as well it's

1226
01:24:37,420 --> 01:24:40,850
gonna be given by this Dirichlet with updated parameters

1227
01:24:41,770 --> 01:24:44,710
while the conditional distribution of theta

1228
01:24:44,770 --> 01:24:46,310
of theta k

1229
01:24:46,350 --> 01:24:49,290
given all the other variables is gonna be the prior

1230
01:24:49,330 --> 01:24:52,940
times the likelihood of all the data items that

1231
01:24:52,940 --> 01:24:56,350
is currently assigned to cluster k okay

1232
01:24:56,620 --> 01:25:01,830
that's other than this Gibbs sampler is actually not as efficient

1233
01:25:01,850 --> 01:25:03,460
as another

1234
01:25:03,540 --> 01:25:09,620
Gibbs sampler where colla collapsed Gibbs sampler and this Gibbs sampler works by basically

1235
01:25:09,620 --> 01:25:11,230
taking this model

1236
01:25:11,250 --> 01:25:14,120
marginalizing out pi and theta

1237
01:25:14,150 --> 01:25:16,460
and then just updating

1238
01:25:16,460 --> 01:25:19,710
the only variables that are left which is the zets okay

1239
01:25:19,730 --> 01:25:23,140
and if you look at the collapsed Gibbs sampler

1240
01:25:23,150 --> 01:25:28,790
basically their conditional probability of z i given all the other variables is of this fall

1241
01:25:28,790 --> 01:25:35,940
again we have a conditional prior times a conditional likelihood where the conditional prior has changed from

1242
01:25:35,940 --> 01:25:41,810
pi k to to to this form here because we've integrated the pi k

1243
01:25:42,040 --> 01:25:49,290
integrated out the pi vector and this conditional prior is kind of quite intuitive it just says that

1244
01:25:49,420 --> 01:25:51,640
it's gonna be proportional to

1245
01:25:51,670 --> 01:25:53,810
alpha divided by k

1246
01:25:53,850 --> 01:25:57,110
so that's coming from the prior on pi

1247
01:25:58,600 --> 01:26:03,420
the number of data items that were currently assigned to cluster k if you

1248
01:26:03,420 --> 01:26:06,230
don't count data item i itself okay

1249
01:26:06,270 --> 01:26:10,250
so the idea is that a cluster that has lots of different data items assigned

1250
01:26:10,270 --> 01:26:13,920
to it will a higher probability of being

1251
01:26:13,920 --> 01:26:18,480
of taking responsibility for this data item i

1252
01:26:19,870 --> 01:26:23,480
and then we also have a conditional

1253
01:26:23,480 --> 01:26:29,270
likelihood of data item x i given that its assigned to cluster k

1254
01:26:29,290 --> 01:26:35,460
and this term here is basically a bit given by the

1255
01:26:35,460 --> 01:26:39,960
predictive probability of x i given

1256
01:26:40,000 --> 01:26:44,370
given all the data items that were cur that are currently assigned to cluster

1257
01:26:45,080 --> 01:26:50,020
except for data item i okay and you can compute this in in the following way

1258
01:26:50,560 --> 01:26:55,420
and if you assume that the prior distribution h is conjugate to our

1259
01:26:55,460 --> 01:27:01,500
f distribution then this can be computed efficiently as well just as the Dirichlet

1260
01:27:01,560 --> 01:27:06,210
multinominal conjugacy allows us to compute all the probabilities efficiently

1261
01:27:06,230 --> 01:27:10,210
if we assume that h is conjugated to f we have also assumed that this can be computed

1262
01:27:10,210 --> 01:27:11,600
efficiently too okay

1263
01:27:11,640 --> 01:27:15,500
so this gives us Gibbs collapsed Gibbs updates

1264
01:27:15,540 --> 01:27:20,500
for the z i variables integrated out both pi and theta from this model

1265
01:27:24,640 --> 01:27:26,350
as I say

1266
01:27:26,400 --> 01:27:31,230
we can obtain the Dirichlet distribution by basically taking this infinite limit of a Gibbs

1267
01:27:31,250 --> 01:27:35,290
sampler and particularly of this collapsed Gibbs sampler

1268
01:27:35,310 --> 01:27:40,080
well perhaps I should say why we might want to do this okay so we might

1269
01:27:40,080 --> 01:27:45,210
want to do this because

1270
01:27:48,040 --> 01:27:49,080
we may not

1271
01:27:49,120 --> 01:27:53,920
want to make any assumption about the number of clusters in our data set right so

1272
01:27:54,460 --> 01:27:55,750
it could be that

1273
01:27:55,770 --> 01:28:01,620
when we do clustering as we see more and more data we might see more and more clusters

1274
01:28:01,670 --> 01:28:03,790
and the more data

1275
01:28:03,810 --> 01:28:04,900
items we see

1276
01:28:05,140 --> 01:28:08,870
the more clusters there might be in them okay so what that says is that

1277
01:28:08,870 --> 01:28:09,640
in the

1278
01:28:09,650 --> 01:28:15,170
true underlying generative process there might not be a fixed finite number of clusters there

1279
01:28:15,170 --> 01:28:20,140
really is a infinite number of clusterrs is just given a certain small data set

1280
01:28:20,140 --> 01:28:26,120
you only see a finite number of the of them okay so this by taking this

1281
01:28:26,150 --> 01:28:30,040
infinite limit of k going to infinity we are basically making that

1282
01:28:30,040 --> 01:28:33,770
assumption that there really is an infinite number of clusters

1283
01:28:33,830 --> 01:28:39,140
that generated our data but it's just that you know given that if you observe

1284
01:28:39,140 --> 01:28:43,020
only a finite number of data items you only see

1285
01:28:43,020 --> 01:28:44,270
less than a

1286
01:28:44,270 --> 01:28:52,390
the volume on this axis pressure on this axis

1287
01:28:52,430 --> 01:28:54,080
one year

1288
01:28:54,230 --> 01:28:56,080
the two here

1289
01:28:56,080 --> 01:28:58,200
there's p one here

1290
01:28:58,230 --> 01:28:59,430
two here

1291
01:28:59,450 --> 01:29:06,850
so i'm starting at p one p one and stuff like here

1292
01:29:06,870 --> 01:29:09,560
and and and and

1293
01:29:09,600 --> 01:29:11,770
right here

1294
01:29:11,890 --> 01:29:16,750
shall find that there are many ways i can get from one state to the

1295
01:29:16,770 --> 01:29:20,230
draw any sort of line

1296
01:29:20,980 --> 01:29:23,310
there are a couple of years one

1297
01:29:23,450 --> 01:29:26,520
we can talk to the which we're going to do

1298
01:29:27,290 --> 01:29:29,120
the first obvious one

1299
01:29:29,810 --> 01:29:31,200
is too

1300
01:29:31,250 --> 01:29:33,350
v one two v two

1301
01:29:42,100 --> 01:29:44,120
so take this back here

1302
01:29:44,180 --> 01:29:48,930
if you want to be too first keeping the pressure constant p one

1303
01:29:48,970 --> 01:29:51,120
ninety eight

1304
01:29:51,180 --> 01:29:54,290
he wanted two keeping divine constant

1305
01:29:54,350 --> 01:29:55,730
all this

1306
01:30:00,230 --> 01:30:02,390
one two

1307
01:30:02,410 --> 01:30:08,870
ISO ballot process followed by

1308
01:30:09,120 --> 01:30:12,290
cost nine

1309
01:30:12,350 --> 01:30:15,830
you could also do with different that could do

1310
01:30:22,770 --> 01:30:23,640
my initial

1311
01:30:23,680 --> 01:30:25,540
final state here

1312
01:30:25,720 --> 01:30:27,580
to take

1313
01:30:27,580 --> 01:30:30,180
first i can change the pressure

1314
01:30:30,180 --> 01:30:32,700
and then changed my

1315
01:30:32,700 --> 01:30:34,520
the second process

1316
01:30:34,520 --> 01:30:37,430
you said you wanted to

1317
01:30:39,640 --> 01:30:41,020
and then you take

1318
01:30:48,180 --> 01:30:49,430
this is

1319
01:30:49,600 --> 01:30:54,330
both are perfectly fine cats and i'm going to assume that these patterns are also

1320
01:30:56,310 --> 01:30:58,640
let's assume that both are

1321
01:30:58,660 --> 01:31:03,430
reversible meaning that i'm doing this very slowly

1322
01:31:03,450 --> 01:31:04,960
so as a

1323
01:31:05,020 --> 01:31:09,140
change let's say i'm changing my volunteer one to v two

1324
01:31:09,250 --> 01:31:10,930
it's happening

1325
01:31:10,980 --> 01:31:13,350
pressing it slowly slowly slowly so that

1326
01:31:13,370 --> 01:31:16,160
at any point to reverse the process without

1327
01:31:17,980 --> 01:31:22,410
without losing energy

1328
01:31:22,410 --> 01:31:24,540
always an equilibrium

1329
01:31:24,560 --> 01:31:31,620
all right i can calculate the work

1330
01:31:31,640 --> 01:31:35,980
that's involved with these two processes

1331
01:31:35,980 --> 01:31:37,480
remember that

1332
01:31:37,500 --> 01:31:39,730
the external pressure support

1333
01:31:39,770 --> 01:31:43,310
in this case because it's a reversible process

1334
01:31:43,350 --> 01:31:46,080
external pressure turns out to be

1335
01:31:46,140 --> 01:31:49,100
four is the same as the internal pressure all

1336
01:31:49,770 --> 01:31:53,660
i mean external

1337
01:31:53,770 --> 01:31:59,520
was doing very slowly so i'm always in equilibrium between external question internal

1338
01:31:59,520 --> 01:32:03,180
can go back and forth

1339
01:32:04,100 --> 01:32:06,460
so let's calculate w one

1340
01:32:06,560 --> 01:32:09,000
the word for path one

1341
01:32:09,100 --> 01:32:12,160
the first thing is change the volume from p one to p two

1342
01:32:12,230 --> 01:32:16,330
external pressure is kept constant p one minus the integral

1343
01:32:18,180 --> 01:32:20,100
one two

1344
01:32:24,040 --> 01:32:26,890
and then the next step here is

1345
01:32:26,930 --> 01:32:29,040
i'm going from

1346
01:32:29,160 --> 01:32:32,270
this for the pressure is changing and going from

1347
01:32:34,790 --> 01:32:36,770
two the two

1348
01:32:38,730 --> 01:32:41,640
we think this integral is

1349
01:32:41,700 --> 01:32:44,100
right so this is a far easier

1350
01:32:44,120 --> 01:32:47,930
this one is also pretty minus key ones

1351
01:32:48,000 --> 01:32:51,640
two what one

1352
01:32:51,660 --> 01:32:55,430
we want to do minus one well that turned out to be

1353
01:32:55,450 --> 01:32:58,950
this area

1354
01:32:59,140 --> 01:33:01,450
one might time minus me two

1355
01:33:01,500 --> 01:33:03,640
times p one

1356
01:33:03,660 --> 01:33:05,810
this is

1357
01:33:05,850 --> 01:33:08,480
one year

1358
01:33:08,580 --> 01:33:10,560
we can rewrite this as

1359
01:33:11,310 --> 01:33:13,910
one times one minus two

1360
01:33:13,930 --> 01:33:17,500
getting rid of this negative side

1361
01:33:17,520 --> 01:33:19,560
now the

1362
01:33:19,560 --> 01:33:24,980
one is bigger than v two so this is possible

1363
01:33:25,020 --> 01:33:27,480
so i am compressing

1364
01:33:27,500 --> 01:33:30,460
i'm doing work to the system

1365
01:33:30,480 --> 01:33:31,580
positive work

1366
01:33:31,580 --> 01:33:34,930
everything is for the convention

1367
01:33:34,930 --> 01:33:36,950
where the poles and

1368
01:33:36,970 --> 01:33:38,800
the system

1369
01:33:38,820 --> 01:33:41,780
right at the beginning which is here

1370
01:33:41,890 --> 01:33:43,200
then we will show you

1371
01:33:43,220 --> 01:33:45,240
the poles

1372
01:33:45,260 --> 01:33:47,090
at the end of the line

1373
01:33:48,050 --> 01:33:50,700
and then we show it to you again

1374
01:33:50,700 --> 01:33:52,430
as it comes back

1375
01:33:52,450 --> 01:33:54,890
so you're going to see three times

1376
01:33:54,910 --> 01:33:58,370
you do

1377
01:33:58,370 --> 01:34:00,120
and this is the now

1378
01:34:00,180 --> 01:34:04,050
is close to the end

1379
01:34:04,100 --> 01:34:07,100
all right thank you mark very thoughtful

1380
01:34:07,240 --> 01:34:10,600
so he was the post that goes in

1381
01:34:10,600 --> 01:34:14,970
and one point three micro seconds later between this lines

1382
01:34:14,990 --> 01:34:18,620
and this line is a market which is one point three microsecond

1383
01:34:18,640 --> 01:34:21,760
the mountain has returned as value

1384
01:34:21,800 --> 01:34:23,550
this is the the polls

1385
01:34:23,570 --> 01:34:24,720
and this

1386
01:34:24,740 --> 01:34:25,550
and then

1387
01:34:25,570 --> 01:34:28,030
when it has come back

1388
01:34:28,100 --> 01:34:29,600
but now

1389
01:34:29,640 --> 01:34:31,120
i'm going to

1390
01:34:31,120 --> 01:34:32,780
make it an open and

1391
01:34:32,830 --> 01:34:34,930
all right so here we see the

1392
01:34:35,030 --> 01:34:37,300
incoming calls

1393
01:34:37,370 --> 01:34:40,510
you see the one that comes back is no one point two nine microsecond big

1394
01:34:41,720 --> 01:34:44,100
mountain comes back as a mountain

1395
01:34:44,120 --> 01:34:45,930
now to something very interesting

1396
01:34:45,990 --> 01:34:48,830
at the end of the cable way is open

1397
01:34:48,850 --> 01:34:49,990
you see twice

1398
01:34:51,410 --> 01:34:54,760
we understand that

1399
01:34:54,820 --> 01:34:59,390
i see someone say yes why do we see twice

1400
01:34:59,470 --> 01:35:03,180
remember the open street

1401
01:35:03,180 --> 01:35:08,100
now the reflecting waves and the incident wave have the same polarity so at the

1402
01:35:08,100 --> 01:35:12,450
end they end up together and they give double the amplitude that was exactly the

1403
01:35:12,450 --> 01:35:16,720
same situation with the string when we drove in the polls on the string when

1404
01:35:16,720 --> 01:35:18,570
the and was open remember

1405
01:35:18,590 --> 01:35:23,070
and moved up by twice the amplitude of the individual poles

1406
01:35:23,120 --> 01:35:24,550
you see that to you

1407
01:35:24,640 --> 01:35:30,680
he has twice the amplitude of this is right at the end

1408
01:35:30,800 --> 01:35:32,830
now it is even more

1409
01:35:32,850 --> 01:35:35,910
which i discovered purely by accident

1410
01:35:35,970 --> 01:35:38,050
well not so much of next

1411
01:35:38,430 --> 01:35:42,510
do some consistency checks to see whether physics works

1412
01:35:42,530 --> 01:35:44,350
and so i said to myself OK

1413
01:35:44,370 --> 01:35:46,640
one point three micro seconds

1414
01:35:46,660 --> 01:35:47,910
that's what it takes

1415
01:35:47,930 --> 01:35:48,570
the go

1416
01:35:48,570 --> 01:35:52,390
make a round-trip through the

1417
01:35:52,450 --> 01:35:54,260
for the wire

1418
01:35:54,280 --> 01:35:57,620
so it was all the confidence that i have in physics i said well

1419
01:35:57,640 --> 01:35:58,660
two l

1420
01:35:58,680 --> 01:35:59,950
divided by c

1421
01:35:59,970 --> 01:36:02,240
l being on the twenty seven years

1422
01:36:02,260 --> 01:36:03,700
should therefore be

1423
01:36:03,700 --> 01:36:08,970
one point three seconds because it goes with the speed of light

1424
01:36:09,030 --> 01:36:11,050
but when i calculated this

1425
01:36:11,090 --> 01:36:12,450
i found

1426
01:36:12,470 --> 01:36:13,660
that this is

1427
01:36:13,660 --> 01:36:17,370
only o point eight four microsecond

1428
01:36:17,490 --> 01:36:18,870
then i said to myself

1429
01:36:18,950 --> 01:36:24,320
why is it slower speed than the speed of light

1430
01:36:24,370 --> 01:36:27,260
and i decided to ask you

1431
01:36:27,320 --> 01:36:28,830
i see and

1432
01:36:28,890 --> 01:36:34,490
why is this being substantially lower this is only remember we observe one point three

1433
01:36:35,970 --> 01:36:37,490
that's what we observe

1434
01:36:37,590 --> 01:36:41,430
so this is only sixty five percent of the speed of light

1435
01:36:41,430 --> 01:36:45,280
and one of the as well

1436
01:36:45,300 --> 01:36:46,740
i don't blame you

1437
01:36:46,870 --> 01:36:50,890
we also two seconds before i realized it

1438
01:36:50,950 --> 01:36:52,390
we also know them

1439
01:36:52,510 --> 01:36:57,600
OK among the

1440
01:36:59,700 --> 01:37:01,470
but it's better to try to that you don't

1441
01:37:10,950 --> 01:37:13,070
the new me let me know

1442
01:37:13,120 --> 01:37:14,510
expressed in the

1443
01:37:16,010 --> 01:37:17,600
effective way

1444
01:37:17,640 --> 01:37:19,640
you remember what do we not

1445
01:37:19,660 --> 01:37:21,370
that we discussed

1446
01:37:21,390 --> 01:37:22,780
that the

1447
01:37:22,820 --> 01:37:24,780
speed of propagation v

1448
01:37:24,800 --> 01:37:26,930
you seem divided by the square root

1449
01:37:26,950 --> 01:37:28,090
of the

1450
01:37:28,120 --> 01:37:30,800
index of refraction of the

1451
01:37:30,820 --> 01:37:32,640
the dielectric constant

1452
01:37:32,680 --> 01:37:34,100
remember that

1453
01:37:34,140 --> 01:37:35,530
i did one point

1454
01:37:35,550 --> 01:37:36,950
i even showed you how

1455
01:37:37,010 --> 01:37:41,590
the dielectric constant is a strong function of frequency of water

1456
01:37:41,640 --> 01:37:46,280
well when i look at the dielectric constant of the material that is in here

1457
01:37:46,300 --> 01:37:50,010
i found that the dielectric constant kappa e

1458
01:37:50,030 --> 01:37:53,220
it is about two point three

1459
01:37:53,240 --> 01:37:57,240
and if you calculate one divided by the square root of two point three it

1460
01:37:57,240 --> 01:38:01,410
happens to be o point six five so that's why the speed

1461
01:38:01,410 --> 01:38:04,780
sixty five percent of the speed of light so you see

1462
01:38:04,800 --> 01:38:09,990
also the effect of the dielectric constant which is quite one

1463
01:38:10,010 --> 01:38:13,780
remember discriminative company was also called the

1464
01:38:13,830 --> 01:38:15,700
the index of refraction

1465
01:38:15,740 --> 01:38:25,550
OK this is a nice moment for break we'll reconvene in four minutes

1466
01:38:25,550 --> 01:38:29,570
i would like to bring to test now what we have learned

1467
01:38:29,600 --> 01:38:33,470
so you get a chance to

1468
01:38:33,620 --> 01:38:38,370
some thinking for change

1469
01:38:38,390 --> 01:38:41,410
i have here

1470
01:38:41,470 --> 01:38:45,370
the electromagnetic wave

1471
01:38:45,390 --> 01:38:49,700
linearly polarized

1472
01:38:49,870 --> 01:38:53,010
vector in this direction

1473
01:38:53,030 --> 01:38:56,600
going to propagate in this direction

1474
01:38:56,700 --> 01:38:59,510
and it set up here

1475
01:38:59,760 --> 01:39:03,300
the average radiation radar

1476
01:39:03,350 --> 01:39:04,620
ten gigahertz

1477
01:39:04,660 --> 01:39:11,430
well that's about three centimeters

1478
01:39:11,450 --> 01:39:14,100
it's is going to be polarized in this direction you have to take my word

1479
01:39:14,100 --> 01:39:15,410
for that

1480
01:39:15,430 --> 01:39:18,140
as the the right here

1481
01:39:18,850 --> 01:39:22,180
receiver is set so that we see the radiation

1482
01:39:22,200 --> 01:39:26,450
in this direction i rotated ninety degrees then it doesn't receive the

1483
01:39:26,470 --> 01:39:32,510
that's the different demonstration which we did before

1484
01:39:34,640 --> 01:39:37,800
i have a peculiar comb

1485
01:39:37,820 --> 01:39:39,030
this is the code

1486
01:39:39,070 --> 01:39:41,120
of metal

1487
01:39:41,140 --> 01:39:45,640
these bars are not connected you just never bars

1488
01:39:45,820 --> 01:39:49,390
going to put it here at the end

1489
01:39:49,470 --> 01:39:52,930
i'm going to do it in two different ways

1490
01:39:52,970 --> 01:39:58,260
in one situation the con was like this

1491
01:39:58,300 --> 01:40:00,530
and then you have the situation

1492
01:40:00,570 --> 01:40:06,450
comm is going to be like this

1493
01:40:06,510 --> 01:40:08,760
so in both cases

1494
01:40:08,870 --> 01:40:10,600
real electric field

1495
01:40:10,640 --> 01:40:14,370
of the way that comes in the in this direction

1496
01:40:14,370 --> 01:40:23,390
stereo maybe I'll secured stereo if you have a perfectly aligned rig if it ends

1497
01:40:23,390 --> 01:40:28,890
up just being finding depth from somewhere triangles very simple math so the story of

1498
01:40:28,890 --> 01:40:37,470
stereos really because you cannot get this mechanically to mathematically aligning the 2 cameras to

1499
01:40:37,470 --> 01:40:42,310
convert to this problem and then you have another problem of finding the correspondence between

1500
01:40:42,310 --> 01:40:47,410
points and that's Saudis shown here this is the processing yet wrought distorted images you

1501
01:40:47,410 --> 01:40:53,810
undistorted view align them you crop to the common visibility points so you can see

1502
01:40:53,810 --> 01:40:59,130
here that features become a line-by-line so so that point is not aligned with this

1503
01:40:59,150 --> 01:41:04,430
the same point in the other camera but after this mathematical processing their exactly so

1504
01:41:04,550 --> 01:41:10,550
the the correspondence which points maps becomes the one research that's what makes for real-time

1505
01:41:10,550 --> 01:41:14,290
stereo and that's what we use all the robot but this is not this is

1506
01:41:14,290 --> 01:41:19,250
an open Stevie it's I think it's the state-of-the-art anywhere you won't find a commercial

1507
01:41:19,250 --> 01:41:27,670
product of does a better this is just getting into some recognition gesture control using

1508
01:41:27,670 --> 01:41:39,110
histogram intersection just controlling a video and stop there this is the has actually my

1509
01:41:39,110 --> 01:41:44,230
father and his 90th birthday taking of glider flying but it's really just matching his

1510
01:41:44,230 --> 01:41:51,790
nose so in different techniques of cross-correlation and and somewhat squared difference that you can

1511
01:41:51,790 --> 01:41:58,430
see his nose standing up for that this is an example I use this to

1512
01:41:58,430 --> 01:42:03,630
the phase detector which a lot of people use a rejection Cascade technique maybe you're

1513
01:42:03,630 --> 01:42:07,810
all familiar with this basically it's that you want but you know we have a

1514
01:42:07,810 --> 01:42:12,780
classifier to make a perfect say grandmother detector you can have a classifier that just

1515
01:42:12,800 --> 01:42:16,630
identifies everything is grandmother and it will never miss a grandmother but would be totally

1516
01:42:16,630 --> 01:42:21,110
useless so that's what these notes are almost totally useless but they never miss a

1517
01:42:21,110 --> 01:42:26,250
grandmother in this case there was a face but they do rejected the few faces

1518
01:42:26,250 --> 01:42:30,590
and as you cascade them you know 20 deep you could you get something that's

1519
01:42:30,590 --> 01:42:38,190
mostly face at the bottom and so yeah here is an example run that day

1520
01:42:38,190 --> 01:42:44,190
Disneyland per family that looks very much like but if that they get her face

1521
01:42:44,190 --> 01:42:50,630
Kansas to kill that I only traded on operate faces but so that's the quick

1522
01:42:50,630 --> 01:42:58,690
tour but take on new in open seas had and move it to steepest plus

1523
01:42:58,690 --> 01:43:06,350
interfaces see lots of allocations worrying about image tied to the steeple sponsored about anything

1524
01:43:06,600 --> 01:43:11,990
allocations no snoring about image type go simplest what is the message and trying to

1525
01:43:11,990 --> 01:43:16,930
shift people over because I got huge user base on CD but symbols was a

1526
01:43:16,930 --> 01:43:20,990
much better we also know we of resources were actually doing software engineering so we're

1527
01:43:20,990 --> 01:43:26,470
putting and unit test build test and all kinds of stuff and these are the

1528
01:43:26,470 --> 01:43:34,810
growing coverage of of functions that have unit test directory structure because they were about

1529
01:43:34,810 --> 01:43:43,910
about two-and-a-half million downloads so the new structure of open CD is that there's core

1530
01:43:43,910 --> 01:43:49,470
functionality that is now a bit got corrupted but now it's pure the structures and

1531
01:43:49,470 --> 01:43:55,930
other things that are needed above that's image processing and now every day as it

1532
01:43:55,930 --> 01:44:01,780
were trying to start a aligning everything into coherent processing modules least so object recognition

1533
01:44:01,780 --> 01:44:06,970
is going to be a stack of all these other things are coming image stitching

1534
01:44:06,970 --> 01:44:12,550
that's of Google summer code into visual dormitory room how camera moves and reconstructing is

1535
01:44:12,560 --> 01:44:19,850
motions turning to the treaty and treating of to be features along the side is

1536
01:44:19,850 --> 01:44:26,670
these helper libraries of them and then and a graphical user interface interface for Ohio

1537
01:44:26,970 --> 01:44:30,990
TV itself doesn't care about how you get the image just processes of these are

1538
01:44:30,990 --> 01:44:36,210
helper functions on the side that helped get the image we have this machine learning

1539
01:44:36,210 --> 01:44:42,790
library that's for recognition that we're interfacing now have a bunch of other interfaces a

1540
01:44:42,790 --> 01:44:47,930
full python interfaces replacing the Swig 1 with the handcrafted by phone and then there's

1541
01:44:47,940 --> 01:44:51,670
others that are on their way and then again there is that we do we

1542
01:44:51,670 --> 01:45:01,230
optimize this library so there's optimizations and SSC optimization soon and GPU up the opposition

1543
01:45:01,270 --> 01:45:06,370
than have this user contribute area that I'm gonna model after MATLAB central this is

1544
01:45:06,370 --> 01:45:11,750
where you can put in your proprietary patented technique it'll be clearly this explained there

1545
01:45:11,750 --> 01:45:14,830
and you only full decision in the sea make file if you say I want

1546
01:45:14,830 --> 01:45:19,690
that and then we need that because there's some retains like said that everybody compares

1547
01:45:19,690 --> 01:45:24,610
against and it's happened so so now we're separated out you pull and then you

1548
01:45:24,610 --> 01:45:28,190
can compare against it but you know if you want use it go talk to

1549
01:45:28,190 --> 01:45:33,950
them on their new know whatever deal they wonna make tone I've said this but

1550
01:45:33,950 --> 01:45:42,230
we're we're organizing this processing things that plug and play architecture that makes it easy

1551
01:45:42,240 --> 01:45:47,510
to give a coherent frame and and easy way of plugging in algorithms this is

1552
01:45:47,510 --> 01:45:52,490
a way that perhaps open-source could take part someone has a better Delaney trying another

1553
01:45:52,490 --> 01:45:57,230
library I could pull within in this way is dynamically it might be a better

1554
01:45:57,230 --> 01:46:02,090
way to combine open-source libraries so here's an example of the start of this the

1555
01:46:02,090 --> 01:46:07,450
processing stacked with features to be envision there is this method where you get features

1556
01:46:07,450 --> 01:46:11,010
and the description of them so as I move around like a quarter of that

1557
01:46:11,010 --> 01:46:17,110
that the air-conditioner I can identified in different views this can be quite a hard

1558
01:46:17,110 --> 01:46:21,810
problem but there are solutions so we have detectors these are the names of supported

1559
01:46:21,810 --> 01:46:26,700
right now but you can easily write your own and descriptors so you episode made

1560
01:46:26,700 --> 01:46:32,450
this interface very simple if you wanna detector which finds it just pointed a simple

1561
01:46:32,450 --> 01:46:36,650
implement 1 algorithm there are others you cannibal man or you take the default but

1562
01:46:36,650 --> 01:46:41,690
not all you have to do is 1 algorithm and same Florida the descriptors that's

1563
01:46:41,690 --> 01:46:47,730
the detector there's the descriptor again and there's pretty much 1 algorithm that you need

1564
01:46:47,740 --> 01:46:53,470
to implement for a descriptor and and then you can the other function it you

1565
01:46:53,470 --> 01:46:56,950
need it we have the falls for old or you can write your own there's

1566
01:46:56,950 --> 01:47:00,430
a you know how to match these things we have a brute force manager a

1567
01:47:00,430 --> 01:47:04,330
couple other matching techniques but here you can pour out all of machine learning we

1568
01:47:04,330 --> 01:47:08,930
just provided basic interfaced this is where you might provide a much more sophisticated interface

1569
01:47:08,930 --> 01:47:14,490
for matching but base it you know these are the basic functions that you get

1570
01:47:14,490 --> 01:47:19,830
you compute the descriptors you Adam to the pile vectors and then you can match

1571
01:47:19,830 --> 01:47:24,930
them and so you can replace all these defaults by whatever you want and then

1572
01:47:24,930 --> 01:47:30,230
what you get is the use nice charge so hoping Computervision that whatever people do

1573
01:47:30,230 --> 01:47:32,090
so what i can do look up

1574
01:47:32,110 --> 01:47:34,310
in the graph

1575
01:47:34,350 --> 01:47:38,420
so that's that's OK that's directed i

1576
01:47:38,460 --> 01:47:39,910
basically graph

1577
01:47:39,930 --> 01:47:41,120
well this one

1578
01:47:42,700 --> 01:47:46,270
it's not the direct sick

1579
01:47:46,280 --> 01:47:50,560
the graph and will not be considered as probabilistic

1580
01:47:50,600 --> 01:47:53,870
that's mother

1581
01:47:53,880 --> 01:47:55,730
so the

1582
01:47:55,740 --> 01:47:59,570
the thing that we have seen in the examples

1583
01:47:59,580 --> 01:48:00,680
is that

1584
01:48:00,700 --> 01:48:04,590
if i have a set of random variables

1585
01:48:04,610 --> 01:48:06,810
and that i ordered them such

1586
01:48:06,850 --> 01:48:12,790
but in the graph any child has higher numbering than any of of his parents

1587
01:48:12,800 --> 01:48:16,320
then the joint probability p x

1588
01:48:16,340 --> 01:48:21,070
the of the set of random variables can be decomposed as a product

1589
01:48:21,100 --> 01:48:22,400
of the

1590
01:48:22,410 --> 01:48:23,820
conditional probability

1591
01:48:23,840 --> 01:48:25,770
of each of the

1592
01:48:25,780 --> 01:48:27,020
random variables

1593
01:48:28,110 --> 01:48:30,960
although his parents in the graph

1594
01:48:32,450 --> 01:48:35,490
the fact that that that i can always order

1595
01:48:35,500 --> 01:48:37,460
the random variables

1596
01:48:38,040 --> 01:48:39,810
in this in this way

1597
01:48:39,830 --> 01:48:46,160
comes from the fact that i'm on considering direct a cyclic graphs

1598
01:48:46,170 --> 01:48:46,920
so that

1599
01:48:46,940 --> 01:48:48,790
i always have

1600
01:48:48,800 --> 01:48:55,190
that the child has always lower numbering than any of his not that the

1601
01:48:55,230 --> 01:48:58,840
parents has always lower numbering their any of china

1602
01:48:58,850 --> 01:49:03,120
OK let's give an example

1603
01:49:04,630 --> 01:49:07,480
much more complex graph that shows

1604
01:49:07,500 --> 01:49:09,190
john i the

1605
01:49:09,230 --> 01:49:13,190
taking the joint probability will only be taking

1606
01:49:15,080 --> 01:49:17,320
the higher notes and then

1607
01:49:17,330 --> 01:49:18,230
taking the

1608
01:49:18,240 --> 01:49:21,710
the law was not it's conditioned on

1609
01:49:21,730 --> 01:49:23,040
their parents

1610
01:49:23,050 --> 01:49:24,370
and so on

1611
01:49:24,380 --> 01:49:26,610
think another concrete examples

1612
01:49:26,620 --> 01:49:28,490
well it's now say that

1613
01:49:28,550 --> 01:49:32,980
this one i'm going to use for the conditional independence

1614
01:49:33,000 --> 01:49:36,600
now say that i'm leaving in the morning

1615
01:49:36,650 --> 01:49:38,870
and they have neighbours that have

1616
01:49:40,500 --> 01:49:44,680
sprinklers so this seems that for what the loans

1617
01:49:46,670 --> 01:49:50,420
i come back and i see that the grass is what

1618
01:49:50,490 --> 01:49:53,130
and i don't know whether it has range

1619
01:49:53,830 --> 01:49:59,280
if it's the the sprinkler who has what if they have put the sprinkler

1620
01:49:59,320 --> 01:50:01,590
so that gives me

1621
01:50:01,600 --> 01:50:05,470
four random variables model which i have

1622
01:50:05,530 --> 01:50:09,080
if i leave in the morning and it is it's cloudy or not i i

1623
01:50:09,100 --> 01:50:13,960
will i would suppose that that will influence the fact that my neighbours put another

1624
01:50:13,960 --> 01:50:15,350
sprinkler on

1625
01:50:15,360 --> 01:50:20,180
and of course that we influence if it's raining or not

1626
01:50:20,200 --> 01:50:23,050
so i have this this graph was the

1627
01:50:23,070 --> 01:50:24,950
here it is it's cloudy or not

1628
01:50:24,960 --> 01:50:29,050
is the sprinkler on or not is it is the

1629
01:50:29,070 --> 01:50:30,300
as a train or not

1630
01:50:30,990 --> 01:50:32,110
is the the

1631
01:50:32,160 --> 01:50:35,680
the grass which are not

1632
01:50:35,720 --> 01:50:40,650
and if order in this way CRS w

1633
01:50:40,980 --> 01:50:45,530
and as you can see i can and as we saw before i decompose it

1634
01:50:48,710 --> 01:50:52,950
as the fact of this factorisation was

1635
01:50:54,470 --> 01:51:00,230
the children already depending on the on the parents

1636
01:51:00,240 --> 01:51:05,910
so let's not talk about what is conditional independence and it's various ways you work

1637
01:51:05,920 --> 01:51:06,950
going to

1638
01:51:06,960 --> 01:51:09,200
to see them in this graphical

1639
01:51:12,770 --> 01:51:17,770
let's take a set of subgraphs of the one i just talk about

1640
01:51:20,050 --> 01:51:26,090
is it clearly are not easy train not is still rests with or not

1641
01:51:26,100 --> 01:51:31,960
if i take the time variety of only is a class the of cloudy and

1642
01:51:31,960 --> 01:51:33,700
wet grass

1643
01:51:33,750 --> 01:51:39,110
and so that's for doing that i marginalize over

1644
01:51:39,120 --> 01:51:40,900
over i some

1645
01:51:40,910 --> 01:51:42,130
i some out

1646
01:51:42,190 --> 01:51:43,470
the range

1647
01:51:43,480 --> 01:51:46,530
and this gives me the probability

1648
01:51:48,240 --> 01:51:51,520
times the probability of what just given cloudy

1649
01:51:51,530 --> 01:51:53,420
and we see that

1650
01:51:53,500 --> 01:51:56,020
that's not there are not independent

1651
01:51:56,070 --> 01:51:58,690
the cloud the clouds and the

1652
01:51:58,700 --> 01:52:01,600
and the web address are not independent

1653
01:52:01,620 --> 01:52:03,730
however if i observe

1654
01:52:03,750 --> 01:52:06,460
has training or not

1655
01:52:06,470 --> 01:52:09,520
and so i look at the probability of

1656
01:52:09,530 --> 01:52:11,460
cloudy and wet

1657
01:52:11,470 --> 01:52:13,820
given that it has trained or not

1658
01:52:15,830 --> 01:52:17,430
it can be decomposed

1659
01:52:17,440 --> 01:52:18,770
in this way

1660
01:52:18,780 --> 01:52:20,610
using is

1661
01:52:21,730 --> 01:52:24,060
here again his

1662
01:52:24,080 --> 01:52:26,160
based on this

1663
01:52:26,170 --> 01:52:30,240
we see that we have what is called a conditional independence

1664
01:52:30,250 --> 01:52:33,630
because we can decompose this temporary

1665
01:52:33,650 --> 01:52:35,340
by the product of

1666
01:52:35,350 --> 01:52:40,790
the probability of finding things the probability of the conditions

1667
01:52:40,820 --> 01:52:43,820
and on the range

1668
01:52:55,170 --> 01:53:00,810
here you mean

1669
01:53:03,660 --> 01:53:06,120
directly mean

1670
01:53:15,740 --> 01:53:20,220
this human this is not true for any

1671
01:53:20,320 --> 01:53:25,950
this it's not equal to this

1672
01:53:26,000 --> 01:53:31,200
it can be equally in some particular cases but in general is not true

1673
01:53:31,210 --> 01:53:32,960
why would it be

1674
01:53:32,980 --> 01:53:37,190
OK OK i mean way

1675
01:53:37,220 --> 01:53:39,110
could have been because

1676
01:53:39,160 --> 01:53:42,430
we cannot have the feeling from that graph that

1677
01:53:42,440 --> 01:53:44,930
they are not connected

1678
01:53:45,080 --> 01:53:46,540
did directly

1679
01:53:47,630 --> 01:53:48,580
we would like

1680
01:53:48,590 --> 01:53:53,160
to see that there their independent they in fact

1681
01:53:53,170 --> 01:53:57,710
as as is just writing down the did deal what is obvious

1682
01:53:57,790 --> 01:53:58,790
is that

1683
01:53:58,800 --> 01:54:04,520
all that i it's apparent of of wet grass

1684
01:54:04,540 --> 01:54:09,330
it's just to put it in in relation with that if i observed the range

1685
01:54:09,400 --> 01:54:11,300
then they become independent

1686
01:54:11,300 --> 01:54:15,430
i mean

1687
01:54:18,500 --> 01:54:21,650
well no big deal

1688
01:54:21,780 --> 01:54:26,640
you know that

1689
01:54:28,700 --> 01:54:32,960
and what you might be able to

1690
01:54:35,540 --> 01:54:40,740
well when i was told one by

1691
01:54:42,870 --> 01:54:54,820
what there in what was going on what i call the by now

1692
01:54:54,830 --> 01:54:57,040
and so on

1693
01:54:58,820 --> 01:55:05,430
can i don't want to remain

1694
01:55:07,620 --> 01:55:09,580
well y

1695
01:55:09,600 --> 01:55:12,660
one friend

1696
01:55:17,520 --> 01:55:20,270
from from

1697
01:55:20,280 --> 01:55:31,010
how many i can remember all the rest of

1698
01:55:45,940 --> 01:55:52,240
from here to here well maybe we can all learn

1699
01:55:52,250 --> 01:55:56,440
o for change

1700
01:55:56,490 --> 01:56:00,920
but all the so

1701
01:56:01,030 --> 01:56:03,670
well maybe

1702
01:56:03,690 --> 01:56:06,570
so i hope

1703
01:56:06,580 --> 01:56:11,590
about where

1704
01:56:14,180 --> 01:56:20,740
if i were that that's the would because

1705
01:56:20,760 --> 01:56:27,570
because the number of their hundred square number so

1706
01:56:27,570 --> 01:56:32,110
and all that is going to grow

1707
01:56:32,130 --> 01:56:35,450
so we're

1708
01:56:36,300 --> 01:56:40,180
now what

1709
01:56:40,190 --> 01:56:44,650
the role of i

1710
01:56:47,230 --> 01:56:52,900
there are all some

1711
01:56:56,390 --> 01:56:58,210
roughly one

1712
01:56:58,230 --> 01:56:59,290
if there

1713
01:56:59,340 --> 01:57:00,910
first of

1714
01:57:04,880 --> 01:57:07,880
what really work

1715
01:57:07,900 --> 01:57:11,590
so the call

1716
01:57:17,740 --> 01:57:23,590
four hundred ninety

1717
01:57:23,610 --> 01:57:26,570
right well are

1718
01:57:26,900 --> 01:57:29,070
but now we're

1719
01:57:29,090 --> 01:57:32,990
and i found the benign

1720
01:57:32,990 --> 01:57:37,280
right we're going to run where

1721
01:57:37,300 --> 01:57:38,900
forty five

1722
01:57:41,320 --> 01:57:48,860
the big river near to the number of

1723
01:57:50,840 --> 01:57:52,300
one that

1724
01:57:54,450 --> 01:57:59,280
and where they are and what the

1725
01:57:59,570 --> 01:58:01,320
my where

1726
01:58:01,800 --> 01:58:08,990
really where where one

1727
01:58:13,820 --> 01:58:19,110
we have

1728
01:58:23,240 --> 01:58:29,760
and that's where

1729
01:58:29,780 --> 01:58:32,900
that's a pretty

1730
01:58:33,090 --> 01:58:39,030
and then we will have everything i write about

1731
01:58:40,880 --> 01:58:45,200
right here right

1732
01:58:45,200 --> 01:58:48,280
and one

1733
01:58:48,300 --> 01:58:50,920
OK now

1734
01:58:50,990 --> 01:58:52,590
were coming

1735
01:58:55,420 --> 01:58:58,110
quite right

1736
01:58:58,260 --> 01:59:03,260
they allow me a

1737
01:59:03,280 --> 01:59:07,700
so i'm gonna get you

1738
01:59:07,720 --> 01:59:10,280
and so we will

1739
01:59:12,650 --> 01:59:14,300
the right call

1740
01:59:14,300 --> 01:59:26,880
for that by where i live where where were only two were we're

1741
01:59:26,900 --> 01:59:31,220
one one one one

1742
01:59:36,320 --> 01:59:40,090
if there were no

1743
01:59:48,300 --> 01:59:51,720
with term with

1744
01:59:51,740 --> 01:59:54,400
more terms

1745
02:00:05,570 --> 02:00:09,510
the more

1746
02:00:15,920 --> 02:00:22,450
and this where the word will be

1747
02:00:27,420 --> 02:00:33,780
one or two

1748
02:00:33,800 --> 02:00:35,920
and how

1749
02:00:38,670 --> 02:00:46,280
how one per day

1750
02:00:50,700 --> 02:00:55,380
one more in terms of the

1751
02:00:57,990 --> 02:01:02,220
well you were one

1752
02:01:02,280 --> 02:01:07,680
in the

1753
02:01:07,700 --> 02:01:12,550
so how many many now

1754
02:01:16,510 --> 02:01:20,170
now i don't

1755
02:01:25,110 --> 02:01:30,760
what we want

1756
02:01:33,700 --> 02:01:37,550
so in the

1757
02:01:38,440 --> 02:01:42,180
so we're

1758
02:01:44,490 --> 02:01:46,940
one hundred

1759
02:01:48,450 --> 02:01:53,570
so from one of way

1760
02:01:53,590 --> 02:01:58,470
of course if you be one per

1761
02:01:58,490 --> 02:02:01,400
and correct for all of

1762
02:02:01,420 --> 02:02:05,650
one o one

1763
02:02:05,720 --> 02:02:09,780
i wonder how you know

1764
02:02:19,300 --> 02:02:22,400
three of the sort

1765
02:02:24,300 --> 02:02:26,840
let me say one thing about


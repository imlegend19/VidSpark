1
00:00:00,000 --> 00:00:01,640
so from illegal to eleven

2
00:00:02,750 --> 00:00:04,090
this is still the optimal

3
00:00:05,470 --> 00:00:07,140
and now we can reduce uniform

4
00:00:07,860 --> 00:00:11,330
and the course the nice thing about all this is that we're trying to reduce muta zero

5
00:00:11,720 --> 00:00:15,110
because that's how we perturb things and we'd like to get rid of the perturbation

6
00:00:16,100 --> 00:00:19,910
and so we've made some good progress here hand what do we have to do next

7
00:00:20,370 --> 00:00:22,680
well now we see that four is the blocking

8
00:00:24,750 --> 00:00:28,710
inequality because it gives us the force the blocking inequality which is the last one

9
00:00:29,030 --> 00:00:30,910
that corresponds to this role here

10
00:00:31,470 --> 00:00:33,290
the w forty equals minus four but

11
00:00:36,150 --> 00:00:38,870
at mu equals four everything is good

12
00:00:39,290 --> 00:00:39,730
and this

13
00:00:41,090 --> 00:00:44,990
right hand side value is equal to zero and ghost a tiny bit less

14
00:00:45,600 --> 00:00:49,240
this becomes a negative number where everything else is still good

15
00:00:50,650 --> 00:00:57,190
and therefore is just doing eight dual-pivot were identified this as the leaving variable i

16
00:00:57,190 --> 00:00:59,550
look across here for entering variables

17
00:01:00,120 --> 00:01:00,340
and so

18
00:01:01,580 --> 00:01:03,490
let's say i did look for things with a plus sign

19
00:01:04,260 --> 00:01:07,670
here because i don't have the text box with a minus in front of it

20
00:01:07,940 --> 00:01:11,410
so looking for things with a plus sign so i look at both of these

21
00:01:11,750 --> 00:01:14,290
and i didn't do this little racial kinda thing

22
00:01:15,210 --> 00:01:19,790
this is at fourteen going at a rate of three

23
00:01:20,460 --> 00:01:22,760
and so i can go a little bit less than five

24
00:01:23,320 --> 00:01:24,220
this one's at

25
00:01:26,790 --> 00:01:27,610
one minus

26
00:01:28,830 --> 00:01:32,930
forces minus two and if forget the minus sign because negative transpose it to

27
00:01:33,970 --> 00:01:35,930
two minus mu is to in the dual

28
00:01:36,590 --> 00:01:37,280
and new equals

29
00:01:37,760 --> 00:01:38,310
four r

30
00:01:38,550 --> 00:01:40,570
this was to going rate five

31
00:01:41,010 --> 00:01:43,600
so this is going fast rate doesn't have referred go

32
00:01:44,000 --> 00:01:45,210
so this is gonna be easy

33
00:01:45,850 --> 00:01:49,490
entering variable so is exactly the same thing that i've already shoyu

34
00:01:51,750 --> 00:01:52,490
they you identify

35
00:01:52,910 --> 00:01:58,080
you are leaving or entering variable by these new inequalities you identify the other variable

36
00:01:58,510 --> 00:01:59,820
the corresponding one

37
00:02:01,980 --> 00:02:06,230
but these racial kind of calculations that we were doing befor you get a pair

38
00:02:06,250 --> 00:02:10,810
entering and leaving variable and then you just rearranged equations together to a new dictionary

39
00:02:11,510 --> 00:02:12,490
so if we do that here

40
00:02:14,650 --> 00:02:18,180
here it is all this is the same dictionary isn't it

41
00:02:18,760 --> 00:02:20,030
those are the same numbers right

42
00:02:23,730 --> 00:02:25,950
so i have tool that illustrate this

43
00:02:27,180 --> 00:02:30,090
in fact maybe i should do somebody's on the pivot tool

44
00:02:30,760 --> 00:02:32,310
i think it's a little bit of fun

45
00:02:37,550 --> 00:02:39,550
that's it was generate a random problem

46
00:02:41,440 --> 00:02:42,320
so here we have it

47
00:02:43,900 --> 00:02:46,540
and the this is the advanced version of the pivotal

48
00:02:46,910 --> 00:02:49,250
which has that extra column and the extra regio

49
00:02:49,950 --> 00:02:51,610
an extra column here next to the right

50
00:02:52,200 --> 00:02:55,360
can sign extra role here under the objective wrote

51
00:02:55,970 --> 00:02:58,610
this is exactly the same as we had in the two phase

52
00:02:59,690 --> 00:03:02,660
simplex methods i'm just interpreting different now

53
00:03:03,100 --> 00:03:03,570
differently now

54
00:03:04,230 --> 00:03:06,510
i'm interpreting it as this times new

55
00:03:07,010 --> 00:03:12,350
this times new this time et cetera i alright the news here because they use the same tool

56
00:03:12,740 --> 00:03:14,270
for all these different algorithms

57
00:03:14,730 --> 00:03:16,180
so when doing that

58
00:03:16,980 --> 00:03:20,640
this version of the algorithm i think these numbers is multiplying new and i think

59
00:03:20,720 --> 00:03:24,030
the second wrote all these numbers maltby multiplying new

60
00:03:26,590 --> 00:03:27,090
and trying the

61
00:03:27,490 --> 00:03:33,340
do this parametric methods and in fact the tool shows me here what range in new values are optimal

62
00:03:33,990 --> 00:03:36,270
one thousand is my abbreviation for infinity

63
00:03:36,760 --> 00:03:39,030
because just like i didn't know how to make an epsilon

64
00:03:40,830 --> 00:03:44,510
in java i didn't know how to make an infinity symbol here so

65
00:03:44,950 --> 00:03:47,490
i just put thousand anyway e

66
00:03:48,480 --> 00:03:51,520
so there's the initial dictionary it goes down to o

67
00:03:51,580 --> 00:03:53,680
the initial range music goes down to eleven

68
00:03:54,310 --> 00:03:58,570
eleven is obviously generated by this variable here getting blocked

69
00:03:59,550 --> 00:04:03,680
eleven minus mu is possibly less recall are which means mu is critical to eleven

70
00:04:04,610 --> 00:04:07,170
so it's this is becomes my entering variable

71
00:04:08,050 --> 00:04:11,050
i do the usual thing i look forward negative

72
00:04:11,670 --> 00:04:15,440
so you look for positive numbers inside the text fields and the whole thing is negative

73
00:04:15,980 --> 00:04:19,190
so that's a zero this is negative just going down the road to

74
00:04:19,780 --> 00:04:20,840
starting at

75
00:04:21,300 --> 00:04:23,820
ten plus one times eleven

76
00:04:24,360 --> 00:04:27,040
so starting at twenty one going down the road to

77
00:04:28,970 --> 00:04:30,660
starting at some

78
00:04:31,430 --> 00:04:35,590
seventeen going down right three okay that's cannot zero quicker

79
00:04:36,690 --> 00:04:38,880
this one is a negative sign sort of throughout this one

80
00:04:39,570 --> 00:04:45,690
this one's uh twenty three going right five that's the fastest one that's going had

81
00:04:45,690 --> 00:04:48,770
zero first s twenty three causes twelve plus eleven

82
00:04:49,280 --> 00:04:53,150
so this is the one is zero first i do all those ratio calculations in

83
00:04:53,150 --> 00:04:56,350
my head evaluating them at the current value of new

84
00:04:57,870 --> 00:04:58,860
so it's the last

85
00:04:59,650 --> 00:05:01,630
and it's the second column i do that

86
00:05:03,000 --> 00:05:07,760
and it shows me automatically the new range new values that does all those ratios that

87
00:05:08,200 --> 00:05:09,120
you have in there

88
00:05:09,670 --> 00:05:14,420
that this kind of certain operations that is these inequalities to get the range new values

89
00:05:15,360 --> 00:05:19,470
and so now it's determined that u equals three is the smallest one

90
00:05:20,090 --> 00:05:21,670
whereas the u equals three

91
00:05:22,070 --> 00:05:22,920
coming from

92
00:05:23,470 --> 00:05:26,080
the new graphical three it's coming from i believe

93
00:05:26,550 --> 00:05:31,440
this inequality here the number looks three times bigger than the number that's one doesn't look like it

94
00:05:31,860 --> 00:05:35,690
and now it doesn't look like it by the way i only have to look at the purple ones

95
00:05:36,120 --> 00:05:38,110
because all the ones are not purple

96
00:05:38,680 --> 00:05:42,130
i have an inequality that satisfied with mu equals zero

97
00:05:42,710 --> 00:05:44,820
so those are all happy and u equals zero

98
00:05:45,400 --> 00:05:45,680
and so

99
00:05:46,270 --> 00:05:48,250
the ones that are don't have a purple

100
00:05:48,250 --> 00:05:49,870
the language

101
00:05:49,880 --> 00:05:54,130
so we want learning algorithms trying to learn how to use that knowledge

102
00:05:54,150 --> 00:05:58,280
we're not going to give it local rules we wanted to learn those

103
00:05:59,100 --> 00:06:02,010
disambiguating rules

104
00:06:04,890 --> 00:06:05,800
this is

105
00:06:05,810 --> 00:06:09,900
we can in our problem we're going to be able to disambiguate these kind of

106
00:06:10,910 --> 00:06:16,670
where the word in red is the one to be distinctly disambiguated so for example

107
00:06:16,690 --> 00:06:21,400
no here there could be several cartons of milk in the world each with their

108
00:06:21,400 --> 00:06:25,720
own symbol and the ones on the table ones in the fridge

109
00:06:25,740 --> 00:06:27,710
and so on

110
00:06:29,560 --> 00:06:33,370
so we think this problem is challenging

111
00:06:33,980 --> 00:06:37,120
if you try learning from scratch now i could probably

112
00:06:37,120 --> 00:06:40,570
make given my data so i could make a bunch of

113
00:06:40,580 --> 00:06:46,070
a handcrafted rules like features life e to my classifier and you could probably do

114
00:06:46,070 --> 00:06:51,400
well but we want to do here is try to discover this these things from

115
00:06:51,400 --> 00:06:55,540
raw data such that if we had more realistic data set

116
00:06:55,560 --> 00:06:59,960
then this in our algorithm is going to scale to that realistic dates and learn

117
00:06:59,980 --> 00:07:06,900
realistic rules rather than just the fake handcrafted onsite are made for the toy problems

118
00:07:06,950 --> 00:07:10,800
but first we just going to look at what's the simplest thing we could do

119
00:07:10,800 --> 00:07:17,280
to do that and we need to do some kind of structured output prediction

120
00:07:17,290 --> 00:07:22,960
because without putting a sequence of concept tags right for the whole sentence so the

121
00:07:22,960 --> 00:07:28,140
classic way of doing that over the last years is to use this kind of

122
00:07:28,160 --> 00:07:31,310
argmax function so this function g

123
00:07:31,310 --> 00:07:39,960
it takes the input x and the concepts y dash and and the universe knowledge

124
00:07:39,960 --> 00:07:41,570
and it's is good news

125
00:07:41,580 --> 00:07:45,600
producer large score he thinks that well matched and then you're going to take the

126
00:07:45,600 --> 00:07:47,410
maximum possible

127
00:07:47,450 --> 00:07:49,050
concept labeling

128
00:07:50,400 --> 00:07:52,950
we could try and train that

129
00:07:52,980 --> 00:07:55,390
so in

130
00:07:55,420 --> 00:07:58,300
indeed made a little simulations

131
00:07:58,330 --> 00:08:04,780
i just showed you the some examples from before includes some actors and some rooms

132
00:08:04,780 --> 00:08:11,580
in some pieces of furniture and fifteen verbs and simulation that makes these characters around

133
00:08:11,580 --> 00:08:15,180
the world picking up objects and giving to each other

134
00:08:15,210 --> 00:08:17,380
and we

135
00:08:18,360 --> 00:08:25,900
made kind of grammar that generates natural language sentences that paired with those actions in

136
00:08:25,900 --> 00:08:30,550
this way we could generate training data

137
00:08:30,560 --> 00:08:31,820
that is

138
00:08:31,830 --> 00:08:34,970
how sentences the concept labelled

139
00:08:34,990 --> 00:08:37,560
and we tried just training

140
00:08:37,570 --> 00:08:42,320
svm struct without without doing any feature engineering so we just use of words

141
00:08:42,330 --> 00:08:46,830
and we don't do too well

142
00:08:46,840 --> 00:08:49,260
if we add the

143
00:08:49,700 --> 00:08:51,710
the concept relations

144
00:08:51,730 --> 00:08:56,860
as well as by features then we do a little better so using the world

145
00:08:56,860 --> 00:09:03,540
knowledge helped this is just the word per tag right

146
00:09:05,240 --> 00:09:06,660
to say so

147
00:09:06,700 --> 00:09:12,740
using world knowledge helps but can we learn hidden representations and do that

148
00:09:12,790 --> 00:09:15,460
i'm going to try and do that with neural networks

149
00:09:16,610 --> 00:09:17,600
what you

150
00:09:20,870 --> 00:09:23,620
there are no actually it's

151
00:09:23,650 --> 00:09:29,400
is the number of full sentences you got wrong i think number full sentences

152
00:09:29,430 --> 00:09:36,060
so if you get any tag wrong in the sentence that's says that's in there

153
00:09:36,060 --> 00:09:38,530
yeah exactly

154
00:09:40,420 --> 00:09:45,690
you have to get the whole white correct here otherwise it's an error

155
00:09:48,230 --> 00:09:52,850
was so we can begin to make a neural network

156
00:09:52,850 --> 00:09:55,970
so this it's going to take the

157
00:09:56,120 --> 00:09:59,240
the sentence and the world

158
00:09:59,260 --> 00:10:00,900
representation u

159
00:10:00,910 --> 00:10:03,440
and it's going to try and produce school

160
00:10:03,630 --> 00:10:08,000
in in between it's going to try and learn some hidden representations both of the

161
00:10:08,000 --> 00:10:12,480
words and concepts the symbols in the world

162
00:10:12,540 --> 00:10:17,450
OK and then those things are going to be actually some

163
00:10:17,460 --> 00:10:22,410
some low dimensional vectors just like in the previous two parts of this

164
00:10:22,430 --> 00:10:23,390
she tutorial

165
00:10:23,390 --> 00:10:29,050
and the final function is looks like this is going to be a sum of

166
00:10:29,060 --> 00:10:30,960
over sliding windows

167
00:10:31,140 --> 00:10:36,150
so g i is is sliding windows into the word i

168
00:10:36,170 --> 00:10:43,590
and it's going to take all the predictions that you've made so far apart from

169
00:10:43,600 --> 00:10:45,300
the ice one

170
00:10:45,660 --> 00:10:48,700
and produced an dimensional vectors

171
00:10:49,390 --> 00:10:51,140
for the for

172
00:10:51,150 --> 00:10:56,110
for the input and then there's another neuron network on the other side function h

173
00:10:56,110 --> 00:10:59,800
which is going to take the concept you're predicting

174
00:10:59,840 --> 00:11:05,430
plus the world knowledge about it and produce another vector the same dimensional and then

175
00:11:05,430 --> 00:11:06,540
we can take the

176
00:11:06,560 --> 00:11:10,730
dot product that some over windows and that's the function g

177
00:11:10,760 --> 00:11:16,190
just like in the previous slide and we're going to train that thing

178
00:11:16,640 --> 00:11:19,210
and i've got a picture to show it

179
00:11:20,010 --> 00:11:21,470
this is the

180
00:11:21,980 --> 00:11:24,140
the GI function

181
00:11:24,720 --> 00:11:25,850
it takes

182
00:11:25,860 --> 00:11:27,410
the window

183
00:11:27,820 --> 00:11:29,760
around the text

184
00:11:32,260 --> 00:11:34,980
a window around the

185
00:11:34,990 --> 00:11:39,430
concepts that we've so far predicted we're going to predict

186
00:11:40,430 --> 00:11:43,310
the concept labels iteratively shave

187
00:11:43,400 --> 00:11:48,960
in the next slide and it first represents those things is

188
00:11:48,990 --> 00:11:53,600
as vectors and those things are going to be trained those representations

189
00:11:58,480 --> 00:12:03,010
concatenate all those vectors into another linear map to get your final representation for the

190
00:12:03,010 --> 00:12:06,900
whole window do on the other side the same thing

191
00:12:06,920 --> 00:12:11,100
h function is going to be the concept that we're predicting

192
00:12:11,140 --> 00:12:12,150
for this

193
00:12:13,440 --> 00:12:15,940
so this for this center

194
00:12:16,100 --> 00:12:20,360
all right so this is the function g i and then do the same thing

195
00:12:20,360 --> 00:12:22,620
and then there's dot product

196
00:12:22,630 --> 00:12:23,640
so that's

197
00:12:23,660 --> 00:12:25,390
our model

198
00:12:25,440 --> 00:12:30,200
and then to do inference we're going to use less so

199
00:12:30,220 --> 00:12:33,890
kind of less so type model actually where

200
00:12:33,890 --> 00:12:40,560
we do you want free inference so we can assume first all the positions are

201
00:12:40,580 --> 00:12:43,390
unlabelled then we can compute

202
00:12:43,950 --> 00:12:45,160
we're going to try

203
00:12:45,170 --> 00:12:49,620
and compute the score for each possible concept in each possible position

204
00:12:49,630 --> 00:12:54,840
take the largest ones are the most confident in and then repeat until with labeled

205
00:12:54,840 --> 00:12:57,400
everything i'm going to train

206
00:12:57,630 --> 00:12:58,700
our model

207
00:12:58,700 --> 00:13:06,660
in other words the important thing is that this is paying attention to particular position

208
00:13:06,680 --> 00:13:09,330
it's only the sort of the right

209
00:13:11,010 --> 00:13:18,040
so this is one of the three sequences three four five and this four five

210
00:13:19,810 --> 00:13:25,930
but these days don't know whether the position three in the centre position-by-position twenty two

211
00:13:28,410 --> 00:13:30,470
so in the background model

212
00:13:30,490 --> 00:13:34,620
the tribunal is what's called the stationary model which means that the probabilities are the

213
00:13:34,620 --> 00:13:37,660
same and every time

214
00:13:37,800 --> 00:13:42,640
as these numbers the probability of by x fifteen

215
00:13:42,680 --> 00:13:48,060
x thirteen x fourteen is the same as x five x three x four

216
00:13:48,160 --> 00:13:50,540
and what we have to show that

217
00:13:50,560 --> 00:13:53,780
so let's see how we can get there using the kind of manipulation and so

218
00:13:54,910 --> 00:13:59,760
and it's going to change the notation of

219
00:13:59,850 --> 00:14:01,120
so what i don't know

220
00:14:01,140 --> 00:14:05,200
it's exactly the same thing instead of three four five

221
00:14:07,640 --> 00:14:13,810
i'm saying i minus two one minus one and also saying i equals five

222
00:14:13,830 --> 00:14:17,010
this is exactly the same if i is

223
00:14:18,060 --> 00:14:20,310
i minus two which is three are

224
00:14:20,330 --> 00:14:22,850
annex i minus one x fours s

225
00:14:22,870 --> 00:14:27,760
what's the probability that x i x five will be

226
00:14:27,780 --> 00:14:31,470
so i haven't changed anything all these numbers are still the same

227
00:14:31,490 --> 00:14:33,990
the result is still the same but what can i do now that i changed

228
00:14:39,140 --> 00:14:42,970
i can back off

229
00:14:42,990 --> 00:14:46,800
so i can said let's ignore the position

230
00:14:46,810 --> 00:14:50,390
so now this probability model is asking for the probability of

231
00:14:51,120 --> 00:14:55,760
four overall is that if x minus two is our next minus one is as

232
00:14:56,120 --> 00:14:58,410
the next letter would be

233
00:14:58,430 --> 00:15:04,040
and now see how much surprise how much better estimates we can get the probabilities

234
00:15:04,060 --> 00:15:07,870
we now have twelve thousand examples of our best

235
00:15:07,910 --> 00:15:12,280
and before i was a little less than ten percent now it's considerably more than

236
00:15:12,280 --> 00:15:15,370
ten percent of those are being followed by

237
00:15:15,390 --> 00:15:18,220
so this is just back off you know these probabilities could go up or down

238
00:15:18,220 --> 00:15:24,100
some of them probably when some probably went there but the more reliable estimates there

239
00:15:24,100 --> 00:15:26,200
when we say that now i can tell you what i mean when we say

240
00:15:26,200 --> 00:15:29,810
that these estimates have high variance

241
00:15:29,810 --> 00:15:31,540
what it means is that

242
00:15:31,560 --> 00:15:34,930
these estimates are based on the brown corpus now suppose we also had to say

243
00:15:34,930 --> 00:15:36,780
the green caucus

244
00:15:36,810 --> 00:15:39,800
which is the same kind of text and the yellow corpus

245
00:15:39,810 --> 00:15:42,870
all of these are based on just a small amount of data

246
00:15:42,890 --> 00:15:46,870
so that the these ratios will probably very alive

247
00:15:46,890 --> 00:15:50,700
from corpus corpus that's what we mean by high variance it means that were sort

248
00:15:50,700 --> 00:15:56,260
of being enslaved by the particular training data that we got

249
00:15:56,280 --> 00:15:59,990
and if you know another to we trust the training data we may get an

250
00:15:59,990 --> 00:16:05,410
inaccurate estimate the variance decreases and you get more and more training and instead of

251
00:16:05,410 --> 00:16:09,120
three or four hundred eighty five numbers get multiplied by ten to one hundred or

252
00:16:09,120 --> 00:16:13,350
something then as we start to get more data will zero in on the correct

253
00:16:14,100 --> 00:16:19,680
but the brown corpus is big enough for us to really trust these numbers

254
00:16:19,700 --> 00:16:23,950
if on the other hand we back now these numbers are big enough that that

255
00:16:23,950 --> 00:16:25,540
we don't have to be so

256
00:16:25,560 --> 00:16:28,240
OK and notice that our estimate is not very different

257
00:16:28,260 --> 00:16:31,870
it's going up by nearly three orders of magnitude

258
00:16:31,870 --> 00:16:33,030
so now this is

259
00:16:33,080 --> 00:16:40,280
instead of less than one billion into less than one

260
00:16:40,280 --> 00:16:44,560
and that's only because our estimates are no more reliable i believe this answer more

261
00:16:44,560 --> 00:16:48,350
than personal abilities as one

262
00:16:48,370 --> 00:16:50,830
just because these numbers were too small

263
00:16:50,890 --> 00:16:53,800
we can find out by trying some other corporate

264
00:16:53,970 --> 00:16:57,660
for example we could use the web that's really big corpus but how

265
00:16:57,680 --> 00:17:02,330
how likely is it is the story forces

266
00:17:02,330 --> 00:17:04,870
but i would put my money on this one well

267
00:17:04,930 --> 00:17:09,080
now there are better ways to build models you can play some tracks were you

268
00:17:09,080 --> 00:17:11,660
interpolates between this model and

269
00:17:11,660 --> 00:17:14,830
so we're with this model has updated you trust

270
00:17:14,850 --> 00:17:18,890
and really doesn't then you start gradually moved towards this

271
00:17:18,890 --> 00:17:22,580
i don't want to go into that this morning we don't have to be just

272
00:17:24,970 --> 00:17:30,180
OK so i'm going to change the notation a little bit

273
00:17:31,030 --> 00:17:35,120
people often right i mean this kind of the right way to write using variable

274
00:17:35,120 --> 00:17:40,680
equals value other people often abbreviated this again this is a problem with making their

275
00:17:40,700 --> 00:17:42,030
lives convenience

276
00:17:42,080 --> 00:17:43,970
i know it's less clear

277
00:17:44,700 --> 00:17:49,040
this is probability of each given or as in you're supposed to understand from context

278
00:17:49,350 --> 00:17:57,140
that this means the probability that you will follow RS

279
00:17:58,220 --> 00:18:02,160
in order to eliminate the notation at the time

280
00:18:02,180 --> 00:18:07,060
let's use this beginning of sensible so i mentioned in the sentence before the beginning

281
00:18:07,060 --> 00:18:09,260
of so asking whether

282
00:18:09,260 --> 00:18:13,180
now these all look like try probabilities we imagine that we've started out with the

283
00:18:13,180 --> 00:18:17,330
whole road beginning of certain symbols and then what's the probability that the next one

284
00:18:18,480 --> 00:18:21,700
and once we got to the beginning of the sentence the next thing will be

285
00:18:22,390 --> 00:18:24,200
we've now forgot

286
00:18:24,200 --> 00:18:27,420
for the rest is the beginning of sentence so everybody has a little bit of

287
00:18:27,420 --> 00:18:29,700
like context two characters

288
00:18:29,720 --> 00:18:34,280
and the first public characters when they look at the two characters are context left

289
00:18:35,040 --> 00:18:36,830
there are kind of the

290
00:18:36,850 --> 00:18:40,740
in this version of beginning of sense and this is the no man's land before

291
00:18:40,740 --> 00:18:44,370
this starts

292
00:18:44,620 --> 00:18:47,700
trains the notation one more time

293
00:18:49,560 --> 00:18:56,010
this is making the same assumptions about language as these try ground distance

294
00:18:56,030 --> 00:18:58,530
and by putting this together

295
00:18:58,540 --> 00:19:02,540
by multiplying these together we estimate or well

296
00:19:02,560 --> 00:19:06,720
we estimate the true probability of course is we define

297
00:19:06,720 --> 00:19:08,370
this function key

298
00:19:08,390 --> 00:19:11,330
which is of particular as

299
00:19:11,350 --> 00:19:13,100
in this particular function p

300
00:19:13,120 --> 00:19:14,490
is probability

301
00:19:14,510 --> 00:19:17,490
that we're using we hope it's close to the

302
00:19:17,510 --> 00:19:20,030
of course is really trying to model

303
00:19:20,030 --> 00:19:21,160
no it isn't

304
00:19:21,240 --> 00:19:24,140
so this is just an essay

305
00:19:24,140 --> 00:19:28,040
it's just that this is what people use it

306
00:19:28,060 --> 00:19:32,480
there were will be technical reasons as well but i'm not sure precisely what they

307
00:19:32,480 --> 00:19:35,380
are not impolite

308
00:19:35,400 --> 00:19:38,340
OK so

309
00:19:39,240 --> 00:19:41,830
do i not spend ages looking at

310
00:19:41,840 --> 00:19:47,260
autocovariance is and precise procedures the reason is basically i don't trust them very much

311
00:19:48,130 --> 00:19:53,470
of this problem that you could run a check that never seems to new distribution

312
00:19:53,480 --> 00:19:56,850
you could do all of the analysis you want on the time series the places

313
00:19:56,850 --> 00:19:58,420
he visited here

314
00:19:58,470 --> 00:20:02,390
and that analysis can't know that in fact you've messed up the mister that half

315
00:20:02,390 --> 00:20:03,400
the distribution

316
00:20:10,120 --> 00:20:12,730
all over the world

317
00:20:12,740 --> 00:20:15,340
what to do

318
00:20:15,550 --> 00:20:22,320
so the question is why might be that some parameters look as though there was

319
00:20:22,320 --> 00:20:29,340
that they reach their equilibrium distribution marginally according to variance in some parameters with

320
00:20:29,350 --> 00:20:31,820
it can just be that if you measure some property

321
00:20:31,830 --> 00:20:36,920
if your state space it's the same everywhere and other properties are different i mean

322
00:20:36,920 --> 00:20:40,540
i don't i don't know about the precise details of this example but imagine that

323
00:20:40,540 --> 00:20:42,630
we were doing something in this space

324
00:20:42,680 --> 00:20:46,490
now in fact is made to completely equivalent because any pretty if we're in this

325
00:20:46,490 --> 00:20:50,840
mode the predictions we would make exactly the same as everywhere in this model made

326
00:20:50,840 --> 00:20:54,690
so if we were plotting properties to do prediction then it would say

327
00:20:54,740 --> 00:20:56,440
it makes finding that would be true

328
00:20:56,460 --> 00:20:58,500
if that was your application

329
00:20:58,520 --> 00:21:00,840
if you approach plotting properties about

330
00:21:00,850 --> 00:21:04,330
the value of me one it would identify the with the problem if you hold

331
00:21:04,330 --> 00:21:07,150
if you did manage to actually help across the night and so you've got to

332
00:21:07,150 --> 00:21:10,690
not only look at these plots but also question what you care about what you're

333
00:21:10,690 --> 00:21:13,360
trying to do so it's hard

334
00:21:13,370 --> 00:21:17,310
so what do i actually do

335
00:21:17,360 --> 00:21:20,890
i think the the most important thing is just to

336
00:21:20,940 --> 00:21:24,460
do some basic sanity consistency checks that

337
00:21:24,520 --> 00:21:25,790
give you some

338
00:21:25,820 --> 00:21:29,480
reason to think you're likely to get the right answer so i mean the first

339
00:21:29,480 --> 00:21:32,490
thing to do when you can do anything with the probability model is just try

340
00:21:32,490 --> 00:21:36,300
it on the tiniest smaller version of your problems well often you can compute things

341
00:21:36,300 --> 00:21:40,800
exactly by brute force and see whether it actually returns the right answer say

342
00:21:40,810 --> 00:21:44,090
that might not have necessarily so it's going to work when you scale things up

343
00:21:44,090 --> 00:21:46,300
because it will be hard to make but it does

344
00:21:46,310 --> 00:21:49,220
that is not just written about in your head

345
00:21:49,240 --> 00:21:54,120
which none of these convergence analysis are going to tell you might say

346
00:21:54,930 --> 00:21:59,980
hands up who has coded up gradients at some time to put into conjugate gradients

347
00:21:59,980 --> 00:22:03,650
lbfgs or some gradient optimizer to optimize the cost function

348
00:22:03,660 --> 00:22:07,270
OK now keep your hands up if

349
00:22:08,330 --> 00:22:13,930
also check those gradients against when perturbing numerically to see that you've got right

350
00:22:13,940 --> 00:22:17,420
now keep your hands up if when you've done that

351
00:22:17,430 --> 00:22:19,590
they're always right

352
00:22:23,580 --> 00:22:27,270
it's the same with MCMC like most the time you can take it up nontrivial

353
00:22:27,270 --> 00:22:30,460
you're going to get it wrong i do all the time and

354
00:22:30,510 --> 00:22:33,060
it would be insane not to test you just haven't got it wrong and i

355
00:22:33,060 --> 00:22:36,770
think that is often overlooked in the literature because it's nice to get into technical

356
00:22:36,770 --> 00:22:41,830
details of like whether this thing is converging looking taking functions things but

357
00:22:41,840 --> 00:22:43,890
that's one of the most important thing

358
00:22:43,910 --> 00:22:47,390
that's one for future what's another sanity cheque

359
00:22:48,330 --> 00:22:52,320
we just written detailed probabilistic model if it was directed model and it will be

360
00:22:52,320 --> 00:22:56,120
this is how we think how data is generated so just written down what we

361
00:22:56,120 --> 00:22:58,430
think datasets again

362
00:22:58,440 --> 00:23:00,740
so we can do is just draw

363
00:23:00,750 --> 00:23:05,320
fantasy synthetic datasets onto real data and then we know the ground truth about data

364
00:23:05,320 --> 00:23:08,310
we know exactly how they were generated we know what all the names when withdrew

365
00:23:08,320 --> 00:23:12,090
from prior then we can run that inference algorithms

366
00:23:12,100 --> 00:23:16,660
which will make predictions and we can see whether those predictions actually match ground truth

367
00:23:16,670 --> 00:23:19,420
because the federal government and going to work on synthetic data that is not going

368
00:23:19,420 --> 00:23:21,470
to work on real data that probably has

369
00:23:21,510 --> 00:23:25,320
added extra complications and and the internet model

370
00:23:26,770 --> 00:23:30,320
and this an example of this when i visited fermilab just because i have some

371
00:23:30,320 --> 00:23:32,490
friends who to particle physics and

372
00:23:32,540 --> 00:23:34,310
there are explained to me that

373
00:23:34,320 --> 00:23:35,450
they're writing

374
00:23:35,470 --> 00:23:37,900
tens of thousands of lines c plus plus to

375
00:23:37,910 --> 00:23:41,530
trying to help prevent so if you're doing something like nick looking for new particle

376
00:23:41,860 --> 00:23:42,970
you have to

377
00:23:42,990 --> 00:23:46,930
still to all these tons of data and the idea then do statistics and identify

378
00:23:47,870 --> 00:23:51,280
statistically significant evidence that this new particle exists here

379
00:23:51,990 --> 00:23:56,700
when the graduate students go away and write that kate they're not let anywhere near

380
00:23:56,710 --> 00:24:00,110
the real data this is my understanding of it because they're just going to tweak

381
00:24:00,110 --> 00:24:02,990
the code until it seems to work so

382
00:24:03,000 --> 00:24:04,210
they're not allowed

383
00:24:04,220 --> 00:24:08,420
the real data until they can demonstrate that code would work on synthetic you want

384
00:24:08,420 --> 00:24:12,560
to call generated simulations simulated data and that's i think exactly what we should be

385
00:24:12,560 --> 00:24:16,100
doing as well because if you're going to go away and make recommendations based on

386
00:24:16,100 --> 00:24:19,950
the data that you want to be really sure that you actually do anything

387
00:24:19,960 --> 00:24:26,360
this is the more sophisticated version of this idea generation synthetic data infer in this

388
00:24:26,360 --> 00:24:29,840
paper which i given your reference for i love the title of the paper getting

389
00:24:29,840 --> 00:24:33,900
it right and it's one of the points that he has some tests were not

390
00:24:33,900 --> 00:24:37,290
just going has convergence just going to test that you have messed up

391
00:24:37,310 --> 00:24:43,380
and his exceedingly honestly say he says i've got these tests where i'm just going

392
00:24:43,380 --> 00:24:45,350
to show consistency my sampling

393
00:24:45,360 --> 00:24:49,410
and then i pulled out the old fortran code that i ran for these papers

394
00:24:49,410 --> 00:24:50,720
in this that's journals

395
00:24:50,740 --> 00:24:54,470
and he'd also claimed the random seeding the generator so he could rerun the code

396
00:24:54,750 --> 00:24:58,940
and reproduce results in paperback with a new that he was doing the same thing

397
00:24:58,940 --> 00:25:02,540
that claim to do in those papers and many many consistency checks and if and

398
00:25:02,540 --> 00:25:06,810
of course the were right and he made six cadence you fix those we ran

399
00:25:07,060 --> 00:25:11,380
came to different conclusions this is one of the most important thing to get right

400
00:25:11,380 --> 00:25:12,440
does not

401
00:25:12,490 --> 00:25:17,590
messing up and i think used a lot of people came and asked me about

402
00:25:17,590 --> 00:25:19,970
convergence which is important but this is

403
00:25:20,020 --> 00:25:24,430
equally if not more important

404
00:25:24,450 --> 00:25:28,330
OK so a

405
00:25:28,380 --> 00:25:29,870
that's the end of my

406
00:25:29,870 --> 00:25:33,550
all of these robots are going to be done in parallel without any synchronization right

407
00:25:33,550 --> 00:25:37,130
sharing and then inside that there's going to be threads

408
00:25:38,480 --> 00:25:43,050
which run arbitrarily they can synchronize are truly they share data

409
00:25:43,110 --> 00:25:46,430
and the programmer then writes one of those parallel threads

410
00:25:47,470 --> 00:25:51,460
and thinks about having this thread being launched in the context where you know million

411
00:25:51,460 --> 00:25:57,150
other brands that's that's how it works OK so enough talking about

412
00:25:57,160 --> 00:26:02,740
esoteric GPU stuff on on to the actual machine learning problems that we're dealing with

413
00:26:03,300 --> 00:26:06,150
we're looking at SVM training

414
00:26:07,400 --> 00:26:10,750
CSD variant and were training the dual

415
00:26:10,760 --> 00:26:16,230
so as people have have mentioned in the talk previously none of this would be

416
00:26:16,230 --> 00:26:19,120
a surprise you we we have

417
00:26:19,130 --> 00:26:24,040
alpha variables that were optimizing and the number of alpha variables we have is equal

418
00:26:24,040 --> 00:26:26,670
to the number of training points trying to build up a classifier

419
00:26:27,070 --> 00:26:30,470
by learning the alpha variables for each of these training points

420
00:26:32,800 --> 00:26:38,740
we also have labelled data so that we can we can perform this and we

421
00:26:39,690 --> 00:26:44,300
the standard kernel functions in our talk today we're actually going be focusing on the

422
00:26:44,300 --> 00:26:49,530
gaussians kernel function since that's the one that we use them

423
00:26:50,410 --> 00:26:56,010
the main algorithm that we're using for SVM training is the classic sequential minimal optimization

424
00:26:56,030 --> 00:27:00,790
algorithm was invented by plant in nineteen ninety nine almost a decade ago

425
00:27:00,810 --> 00:27:02,260
and that

426
00:27:02,270 --> 00:27:03,490
despite the name

427
00:27:03,500 --> 00:27:06,330
sequential minimal optimization is actually quite apparent

428
00:27:06,370 --> 00:27:11,900
at each iteration what this algorithm does is just

429
00:27:11,910 --> 00:27:16,200
exactly two of the variables and we have all variables were always the number of

430
00:27:16,200 --> 00:27:21,690
training points and because we're addressing only two of the variables at the time the

431
00:27:21,690 --> 00:27:24,960
entire space that we're looking at collapses into

432
00:27:25,000 --> 00:27:29,270
the one dimensional problem we've got two variables in a box and then we've got

433
00:27:29,270 --> 00:27:35,010
a one-dimensional we've got constraint linking that makes the space effectively one-dimensional so the actual

434
00:27:35,010 --> 00:27:37,600
optimisation step is is quite trivial

435
00:27:38,970 --> 00:27:43,770
the other good thing about this algorithm is that computing the full kernel matrix between

436
00:27:43,770 --> 00:27:46,600
all these points is not required and we

437
00:27:46,610 --> 00:27:50,820
basically generated on the fly as as necessary

438
00:27:50,860 --> 00:27:55,330
the computation is dominated by KKT optimality condition update

439
00:27:55,370 --> 00:27:58,100
and this can be done in parallel

440
00:27:59,270 --> 00:28:03,140
i mean talk a little about the variable selection heuristics

441
00:28:03,200 --> 00:28:06,890
so the job of the variable selection heuristic is actually quite important we have to

442
00:28:06,890 --> 00:28:10,830
choose the two variables that we're going to be updating edits that

443
00:28:10,840 --> 00:28:13,600
which is the wrong ones and we're converges very slowly

444
00:28:14,760 --> 00:28:16,130
so the first order

445
00:28:16,150 --> 00:28:20,500
selection heuristic that we use proposed by here b in two thousand one

446
00:28:20,560 --> 00:28:26,460
is basically constructing this as a vector where the length of of the vector ten

447
00:28:26,460 --> 00:28:30,010
is the length of the number of training points

448
00:28:30,110 --> 00:28:32,850
and for for every training point we

449
00:28:33,680 --> 00:28:35,860
we construct this vector iteratively

450
00:28:35,870 --> 00:28:40,130
and at every iteration we're going to be searching among we're going to update this

451
00:28:40,150 --> 00:28:45,110
vector based on the optimisation step that we just taken were then going to search

452
00:28:45,110 --> 00:28:46,390
among this vector

453
00:28:46,400 --> 00:28:52,210
according to these subsets in order to find the maximal violating pair from this factor

454
00:28:52,210 --> 00:28:58,400
and the maximum violin pair is showing which which two points

455
00:28:58,410 --> 00:29:02,430
i have the steepest gradient in in the functional which if we if we needed

456
00:29:02,430 --> 00:29:06,640
to choosing two points is the same thing is choosing interactions with its finding steep

457
00:29:07,900 --> 00:29:12,780
and doing this is required order of complexity for each step

458
00:29:12,990 --> 00:29:17,630
however the first order heuristic can be confused by steep gradients which ultimately lead to

459
00:29:17,640 --> 00:29:21,390
marginal improvements on the objective and

460
00:29:21,400 --> 00:29:22,900
so to overcome this

461
00:29:22,910 --> 00:29:27,860
on at all in in two thousand five for a second order heuristic which selects

462
00:29:27,890 --> 00:29:33,220
the variables according to the actual change in the objective function or trying to avoid

463
00:29:33,220 --> 00:29:37,800
situations like this where the grain is pointing in the direction it's very steep but

464
00:29:37,800 --> 00:29:41,530
ultimately rather shallow we want to choose a direction

465
00:29:41,540 --> 00:29:46,450
potentially that might have a gentler gradient but overall leads to a bigger improvement in

466
00:29:46,450 --> 00:29:51,640
our objective function if we're going to do this in the most general way actually

467
00:29:51,640 --> 00:29:55,510
requires a lot more work because we have to look at all the different pairs

468
00:29:55,510 --> 00:29:59,030
to see which pairs cause most change in the objective function so instead of doing

469
00:29:59,030 --> 00:30:03,970
that we we choose one of the variables in the same way that was done

470
00:30:03,970 --> 00:30:09,930
in the first order heuristic and then the second one is chosen by

471
00:30:09,970 --> 00:30:11,290
checking the change

472
00:30:11,320 --> 00:30:13,180
in the in the

473
00:30:13,190 --> 00:30:16,450
objective function or if we were to choose that as the other part of the

474
00:30:17,280 --> 00:30:18,860
for all and

475
00:30:18,930 --> 00:30:26,080
variables which actually lead to progression towards the constrained optimisation problem

476
00:30:26,880 --> 00:30:28,980
to sketch the implementation

477
00:30:29,360 --> 00:30:31,520
the first order

478
00:30:31,580 --> 00:30:34,500
in every iteration that we use the first order heuristic

479
00:30:34,510 --> 00:30:39,200
basically it has a single mapreduce that where we can we compute the the new

480
00:30:39,200 --> 00:30:44,260
value of the vector for every point and then we reduce over that factor according

481
00:30:44,260 --> 00:30:49,640
to the subset that were defined with the KKT conditions to find the maximal violating

482
00:30:49,710 --> 00:30:55,110
the second order heuristics requires about twice as much work we have two mapreduce that's

483
00:30:55,110 --> 00:30:59,230
where we are the first one is similar we update and then we compute

484
00:30:59,270 --> 00:31:03,780
one is one of the variables by searching over it and then we have to

485
00:31:03,780 --> 00:31:05,980
do another mapreduce that where we

486
00:31:06,010 --> 00:31:10,820
compute the change in the gradient if we were to choose that variable as the

487
00:31:10,820 --> 00:31:15,820
second half of the pair and then finally reduce over that fine

488
00:31:16,140 --> 00:31:18,000
the variable we're going to be using

489
00:31:20,230 --> 00:31:26,110
some other implementation details we use kernel caching as presented by keynes in nineteen ninety

490
00:31:26,110 --> 00:31:30,860
nine we managed to cache on the CPU and keep the rows of the cash

491
00:31:30,860 --> 00:31:35,390
in GPU memory so basically this soak up all the GPU memory news that the

492
00:31:36,160 --> 00:31:41,890
and we also space pay special attention to ensure efficient memory access patterns keeping the

493
00:31:41,890 --> 00:31:47,680
memory access coherence meaning that were accessing large pieces of memory once and making use

494
00:31:47,680 --> 00:31:52,790
of GPU local stores which are basically the the on chip cache

495
00:31:56,040 --> 00:32:00,520
the second order heuristic can be rather expensive like this so it can be about

496
00:32:00,520 --> 00:32:04,140
twice as much work in the geometric mean are tests that about

497
00:32:04,150 --> 00:32:09,080
twice as much work per iteration and so we actually made an adaptive heuristic which

498
00:32:09,400 --> 00:32:14,370
periodically estimates the convergence rate measured by the gap in the optimality gap as a

499
00:32:14,370 --> 00:32:20,410
function of wall clock time and then chooses the one heuristic that's progressing most productively

500
00:32:20,410 --> 00:32:21,640
towards the optimal

501
00:32:21,700 --> 00:32:25,880
and the important thing to note is that this adaptive heuristic performs

502
00:32:25,890 --> 00:32:31,140
close to the best heuristics on our test so there there are certain cases like

503
00:32:31,140 --> 00:32:32,130
for example

504
00:32:32,180 --> 00:32:35,430
on this dataset where the second order heuristic does really well

505
00:32:35,880 --> 00:32:39,740
in terms of runtime you know it's it's reduce runtime by a factor three and

506
00:32:39,740 --> 00:32:44,030
there's other other places where the second order heuristic of increased are run time by

507
00:32:44,030 --> 00:32:45,650
almost a factor of two

508
00:32:45,680 --> 00:32:47,440
whereas the

509
00:32:47,460 --> 00:32:48,840
the adaptive

510
00:32:48,840 --> 00:32:51,470
i extend this spring

511
00:32:51,540 --> 00:32:53,420
i extended over certain

512
00:32:53,430 --> 00:32:56,840
i'm not certain distance in unimportant how much

513
00:32:56,870 --> 00:32:57,930
i know

514
00:32:58,050 --> 00:32:59,420
when i do that

515
00:32:59,570 --> 00:33:01,720
there will be appalled

516
00:33:04,650 --> 00:33:07,460
i put mass and one year

517
00:33:08,130 --> 00:33:09,360
and i measure

518
00:33:10,980 --> 00:33:15,440
that is full courses on these mass immediately after i believe i can measure that

519
00:33:15,470 --> 00:33:17,630
so i measure acceleration a one

520
00:33:17,800 --> 00:33:21,350
now i replaced this object

521
00:33:21,420 --> 00:33:23,600
mass and two

522
00:33:23,670 --> 00:33:25,660
but the extension is the same

523
00:33:25,670 --> 00:33:28,240
so the pool must be the same bring doesn't know

524
00:33:28,300 --> 00:33:30,430
what the masses at the other end right

525
00:33:30,440 --> 00:33:32,030
the same

526
00:33:32,070 --> 00:33:34,480
i put into their different mass

527
00:33:34,490 --> 00:33:35,600
and i

528
00:33:35,650 --> 00:33:38,240
national no acceleration a two

529
00:33:38,320 --> 00:33:40,880
it is now an experimental facts

530
00:33:40,920 --> 00:33:42,960
that one a one

531
00:33:42,970 --> 00:33:48,780
he calls and two a two

532
00:33:48,790 --> 00:33:50,650
and this product

533
00:33:51,420 --> 00:33:53,150
a we call

534
00:33:53,190 --> 00:33:55,400
the force that is our definition

535
00:33:55,410 --> 00:33:57,490
of force

536
00:33:57,520 --> 00:33:59,300
so the same pool

537
00:33:59,350 --> 00:34:01,680
on the ten times larger mass

538
00:34:01,690 --> 00:34:03,120
i would give it ten times

539
00:34:07,430 --> 00:34:08,710
the second law

540
00:34:08,790 --> 00:34:11,540
i'll read to you

541
00:34:11,550 --> 00:34:12,950
the force action

542
00:34:12,960 --> 00:34:15,990
on the body gives it the next generation

543
00:34:16,040 --> 00:34:19,810
which is in the direction of the force that's also important

544
00:34:19,870 --> 00:34:22,430
correlations in the direction of the force

545
00:34:22,490 --> 00:34:26,130
and has a magnitude given by m a

546
00:34:26,300 --> 00:34:28,550
it is the magnitude and the direction

547
00:34:28,620 --> 00:34:30,000
is the direction

548
00:34:30,070 --> 00:34:31,040
of the force

549
00:34:31,080 --> 00:34:33,070
so now we will write this

550
00:34:33,080 --> 00:34:35,350
in all glories

551
00:34:35,410 --> 00:34:38,550
detailed this is the second law

552
00:34:38,600 --> 00:34:40,940
i note and

553
00:34:42,100 --> 00:34:44,070
perhaps the most important

554
00:34:45,750 --> 00:34:47,240
all of physics

555
00:34:47,330 --> 00:34:49,250
certainly in all of

556
00:34:49,380 --> 00:34:50,500
it one

557
00:34:52,280 --> 00:34:53,720
m a

558
00:34:53,780 --> 00:34:56,570
units of this force

559
00:34:59,040 --> 00:35:00,300
times meters

560
00:35:00,450 --> 00:35:05,000
a second squared in honour of of the great man

561
00:35:05,040 --> 00:35:09,190
we call that will not

562
00:35:09,210 --> 00:35:11,630
like the first law the second law

563
00:35:11,640 --> 00:35:16,370
only holds in inertial reference frames

564
00:35:16,420 --> 00:35:19,630
and the first law the second law be proven

565
00:35:21,170 --> 00:35:23,010
i do we believe in it

566
00:35:23,950 --> 00:35:25,470
i do believe in it

567
00:35:25,520 --> 00:35:30,750
because all experiments and all measurements within the uncertainty of the measurements

568
00:35:31,530 --> 00:35:32,590
in agreement

569
00:35:34,050 --> 00:35:37,510
the second floor

570
00:35:37,550 --> 00:35:39,380
now you may object

571
00:35:39,530 --> 00:35:41,250
you may say

572
00:35:41,260 --> 00:35:43,750
this is strange what you've been doing

573
00:35:43,790 --> 00:35:46,660
how can you ever the tournament bass

574
00:35:46,670 --> 00:35:48,630
if there is no for somewhere

575
00:35:48,640 --> 00:35:51,930
because if you want to minimize maybe put it on scale

576
00:35:51,970 --> 00:35:54,950
and we put it on the scale to determine the mass you make use of

577
00:35:54,950 --> 00:35:59,010
the gravitational force so it's not some kind of a circular argument that you use

578
00:35:59,030 --> 00:36:02,950
the answer is no

579
00:36:03,000 --> 00:36:06,160
i can be somewhere in in outer space where there is no gravity

580
00:36:06,170 --> 00:36:07,430
i have to

581
00:36:07,440 --> 00:36:11,910
pieces of cheese they are identical in size these genes without holes by the way

582
00:36:11,970 --> 00:36:14,880
they are identical in size

583
00:36:14,930 --> 00:36:16,120
some of the two

584
00:36:16,130 --> 00:36:18,310
has double the mass of one

585
00:36:18,320 --> 00:36:22,140
mass is determined by how many molecules how many atoms i have i don't need

586
00:36:22,140 --> 00:36:26,630
gravity to have relative scale of mass is so i can determine the relative scale

587
00:36:26,630 --> 00:36:28,850
of these masses without ever

588
00:36:28,900 --> 00:36:30,300
using the force

589
00:36:31,220 --> 00:36:33,160
this is a very legitimate way

590
00:36:36,210 --> 00:36:38,040
checking up on the

591
00:36:38,060 --> 00:36:43,930
second law

592
00:36:44,010 --> 00:36:46,200
since all objects

593
00:36:46,210 --> 00:36:47,500
in this lecture hall

594
00:36:47,510 --> 00:36:49,030
and the earth

595
00:36:49,040 --> 00:36:50,270
four is the

596
00:36:50,280 --> 00:36:53,210
constant acceleration which is g

597
00:36:53,300 --> 00:36:54,680
we can write down

598
00:36:54,740 --> 00:36:58,220
that the gravitational force

599
00:36:58,410 --> 00:36:59,800
would be an

600
00:36:59,810 --> 00:37:04,920
time this acceleration g normally right in a free but i make an exceptional because

601
00:37:05,720 --> 00:37:07,340
i call it

602
00:37:07,350 --> 00:37:12,260
gravitational force and so you see that the gravitational force

603
00:37:12,420 --> 00:37:14,870
to the earth on a particular mass

604
00:37:14,880 --> 00:37:18,040
is linearly proportional risk the math

605
00:37:18,100 --> 00:37:20,460
if the mass becomes ten times larger

606
00:37:20,470 --> 00:37:22,430
then the force

607
00:37:23,740 --> 00:37:28,030
was up by a factor of ten

608
00:37:28,040 --> 00:37:29,780
what i have here

609
00:37:29,810 --> 00:37:32,650
the softball in my hand

610
00:37:33,680 --> 00:37:35,560
the reference frame

611
00:37:35,580 --> 00:37:39,540
twenty six one hundred we will accept to be an inertial reference frame

612
00:37:39,570 --> 00:37:42,640
it's not being accelerated in our reference frame

613
00:37:42,710 --> 00:37:44,690
that means

614
00:37:44,750 --> 00:37:47,160
the force on it must be zero

615
00:37:47,200 --> 00:37:48,990
so here

616
00:37:49,000 --> 00:37:51,170
is that ball

617
00:37:51,170 --> 00:37:53,090
we know it has mass m

618
00:37:53,150 --> 00:37:55,790
which in this case is about half a kilogram

619
00:37:56,460 --> 00:37:58,140
there must be a force here

620
00:37:58,150 --> 00:37:59,210
and g

621
00:37:59,270 --> 00:38:00,720
which is about

622
00:38:00,870 --> 00:38:02,140
five not

623
00:38:02,180 --> 00:38:03,930
half kilogram

624
00:38:03,990 --> 00:38:05,630
but the net force

625
00:38:08,370 --> 00:38:10,070
it is very clear

626
00:38:10,080 --> 00:38:12,710
i will follow it must

627
00:38:12,720 --> 00:38:14,420
push up

628
00:38:14,420 --> 00:38:16,190
with a force

629
00:38:16,380 --> 00:38:18,000
my hand to the ball

630
00:38:18,010 --> 00:38:19,140
which is about

631
00:38:19,150 --> 00:38:21,550
the same which is exactly the same five

632
00:38:21,560 --> 00:38:24,080
newton's is only now is there

633
00:38:24,090 --> 00:38:25,880
no acceleration

634
00:38:25,920 --> 00:38:27,810
so i can write down

635
00:38:30,910 --> 00:38:32,170
walter lewin

636
00:38:33,590 --> 00:38:35,490
the force of gravity

637
00:38:35,510 --> 00:38:36,780
well zero

638
00:38:36,850 --> 00:38:39,750
because it's the one dimensional problem you could say

639
00:38:39,800 --> 00:38:41,760
that the force of doing

640
00:38:41,820 --> 00:38:43,130
equals minus

641
00:38:48,690 --> 00:38:50,600
vehicles have a

642
00:38:52,410 --> 00:38:55,450
that there is no statement made

643
00:38:55,460 --> 00:38:57,810
on velocity or speed

644
00:38:57,820 --> 00:38:59,670
so long as you know f

645
00:38:59,710 --> 00:39:01,300
and as long as you know and

646
00:39:01,310 --> 00:39:06,460
eight is uniquely specified no information is needed on the speed

647
00:39:06,470 --> 00:39:07,750
but that would mean

648
00:39:07,790 --> 00:39:10,770
if we take gravity an object falling down

649
00:39:10,810 --> 00:39:13,200
with five meters per second

650
00:39:13,210 --> 00:39:15,590
that the law would hold

651
00:39:15,670 --> 00:39:17,170
if it would fall down

652
00:39:17,280 --> 00:39:20,890
with five thousand meters per second

653
00:39:20,900 --> 00:39:22,960
it will also hold

654
00:39:23,020 --> 00:39:25,120
will always hold

655
00:39:28,390 --> 00:39:29,560
you speed

656
00:39:29,620 --> 00:39:31,520
approaches the speed of light

657
00:39:31,620 --> 00:39:33,760
newtonian mechanics no longer works

658
00:39:33,770 --> 00:39:37,290
then you have to use einstein's theory of special relativity

659
00:39:37,370 --> 00:39:40,250
so it is only valid as long as we have

660
00:39:40,300 --> 00:39:43,180
speeds that are substantially smaller

661
00:39:43,190 --> 00:39:44,570
say then the

662
00:39:44,590 --> 00:39:47,490
speed of light

663
00:39:47,560 --> 00:39:48,810
now we come

664
00:39:48,820 --> 00:39:50,290
two newton's

665
00:39:53,400 --> 00:39:55,010
if one object

666
00:39:55,080 --> 00:39:58,670
exerts a force on another

667
00:39:58,680 --> 00:40:04,800
the other exerts the same force in opposite directions on the one

668
00:40:04,880 --> 00:40:09,470
i read again if one object exerts a force

669
00:40:09,500 --> 00:40:11,940
on another

670
00:40:11,950 --> 00:40:15,300
the other actors the same force in opposite directions

671
00:40:15,310 --> 00:40:16,810
on the one

672
00:40:16,870 --> 00:40:20,420
and i normally

673
00:40:20,420 --> 00:40:22,960
summarize that

674
00:40:23,040 --> 00:40:24,310
as follows

675
00:40:24,310 --> 00:40:26,100
and the results

676
00:40:26,230 --> 00:40:29,690
i have to admit what i see this still shocked that works well

677
00:40:29,860 --> 00:40:32,310
the results are pretty impressive considering

678
00:40:32,510 --> 00:40:34,950
are relatively small tool kit

679
00:40:35,230 --> 00:40:36,570
to make all this work

680
00:40:36,910 --> 00:40:41,860
so if you measure with the top five accuracy metric used for the imagenet challenge

681
00:40:42,070 --> 00:40:43,820
to get about eighty five percent

682
00:40:44,020 --> 00:40:50,000
but what are sort of qualitatively look at some of these results so here they're getting the right answers to predict

683
00:40:50,020 --> 00:40:51,650
that this is a motor scooter leopard

684
00:40:51,890 --> 00:40:53,750
but the one i think pretty interesting

685
00:40:53,990 --> 00:40:57,220
things like this where are the correct answer was grille

686
00:40:57,820 --> 00:40:59,520
turns out that top

687
00:40:59,690 --> 00:41:02,200
match for neural network is actually convertible

688
00:41:04,060 --> 00:41:06,760
and calling as dalmatians seems pretty understandable

689
00:41:08,130 --> 00:41:12,700
this one i couldn't understand how people here know the word garrick means agaric

690
00:41:13,140 --> 00:41:15,420
i i didn't know how to go look up on wikipedia

691
00:41:15,570 --> 00:41:17,830
and a on wikipedia you see this picture

692
00:41:18,560 --> 00:41:23,130
so i was pretty surprised by stuff like this that words i don't know

693
00:41:23,280 --> 00:41:25,000
this neural network of figure out

694
00:41:25,230 --> 00:41:27,350
using these fairly simple components

695
00:41:27,570 --> 00:41:30,280
how to how to say that this might be a garrick

696
00:41:30,440 --> 00:41:31,240
or mushroom

697
00:41:31,610 --> 00:41:33,340
whatever the difference between those as

698
00:41:34,430 --> 00:41:35,770
so this is pretty neat

699
00:41:35,950 --> 00:41:40,860
system and the basic ideas we've been talking about so far actually enough to make something like this work

700
00:41:42,880 --> 00:41:49,010
so when i say briefly something about other vision applications i wanted to do a little more on

701
00:41:49,030 --> 00:41:49,660
this but

702
00:41:49,850 --> 00:41:52,280
but for the time we've got just say a few words

703
00:41:52,610 --> 00:41:54,800
if you want to do something like segmentation

704
00:41:56,180 --> 00:41:58,170
if you can recast any problem

705
00:41:58,360 --> 00:42:01,570
as a supervised learning problem you've got a bunch of labelled data

706
00:42:01,980 --> 00:42:04,930
you can make progress using all the tools we just talked about

707
00:42:05,120 --> 00:42:07,070
so for something like segmentation

708
00:42:07,520 --> 00:42:09,920
if you think that each pixel is the label

709
00:42:10,040 --> 00:42:13,880
and i need to say for example yes or know if this is

710
00:42:14,140 --> 00:42:17,510
an membrane between two different regions in some tissue

711
00:42:17,960 --> 00:42:21,400
you can think of that as a supervised learning problem to use all the algorithms

712
00:42:21,420 --> 00:42:22,410
that we use so far

713
00:42:22,740 --> 00:42:23,390
and danchi

714
00:42:24,130 --> 00:42:25,890
has done some cool stuff with us

715
00:42:26,110 --> 00:42:29,850
if you want to do segmentation scenes in different types

716
00:42:30,020 --> 00:42:32,060
of surfaces and you have labels

717
00:42:32,400 --> 00:42:34,930
you can think about is the problem i want to predict

718
00:42:35,110 --> 00:42:37,170
the material that a certain pixel

719
00:42:39,520 --> 00:42:44,520
another way of approaching this is to segment your image first using off the shelf computer vision software

720
00:42:44,820 --> 00:42:47,250
and then for every super pixel each sort of a

721
00:42:47,370 --> 00:42:48,400
block region

722
00:42:48,700 --> 00:42:49,890
i'm trying to predict

723
00:42:50,060 --> 00:42:53,010
what is the material that dominates in that super pixel

724
00:42:53,620 --> 00:42:58,970
and using these sort of simple recast of each of these vision problems you can keep using

725
00:42:58,990 --> 00:43:00,040
all the same tools

726
00:43:00,270 --> 00:43:03,210
are of course if you sliding-window you can build detectors

727
00:43:03,360 --> 00:43:05,810
out of supervised classification function

728
00:43:06,070 --> 00:43:11,080
so pierre sermanet as work on worked on things like pedestrian detection some pretty cool results

729
00:43:11,370 --> 00:43:12,500
and some sort of

730
00:43:13,270 --> 00:43:16,720
a novel results from unlikely these group which students

731
00:43:16,950 --> 00:43:19,010
this one from rss this year

732
00:43:19,150 --> 00:43:20,610
so you do some pretty

733
00:43:21,630 --> 00:43:28,160
cool vision related things where the task is not to classify an object or a segment or do some vision task

734
00:43:28,220 --> 00:43:31,410
but fact to figure out where is it located grasp a coffee mug

735
00:43:33,090 --> 00:43:37,810
so you're basically using neural network to rank how good are different grasp points

736
00:43:38,000 --> 00:43:41,410
there's pretty cool videos on the web so as if you guys a chance at

737
00:43:41,420 --> 00:43:42,950
some point to go through that link

738
00:43:43,320 --> 00:43:45,650
afterward the results are pretty impressive

739
00:43:47,300 --> 00:43:52,250
ross take a couple slides to say something about debugging tips because if you get this

740
00:43:52,260 --> 00:43:55,320
far when you go home you go implementing tutorial somewhere

741
00:43:55,590 --> 00:43:59,240
chances are you going to get to point to say you know this deep learning thing doesn't

742
00:44:01,370 --> 00:44:06,530
and so it's true that sooner or later you get trouble and

743
00:44:06,960 --> 00:44:11,150
it's a little bit like computer programming and that no one can tell you how to debug computer

744
00:44:11,170 --> 00:44:12,540
program you just sort of got a

745
00:44:12,950 --> 00:44:18,390
grid and there it goes through it but there are some tips that that make it a little less painful

746
00:44:18,760 --> 00:44:19,700
one is

747
00:44:19,910 --> 00:44:22,080
don't forget to check your gradient numerically

748
00:44:22,580 --> 00:44:24,310
this is a simple thing to do

749
00:44:24,570 --> 00:44:25,960
pick some random parameters

750
00:44:26,370 --> 00:44:27,760
perturb them a little bit

751
00:44:27,920 --> 00:44:28,750
and then just

752
00:44:29,160 --> 00:44:32,710
guess compute gradient from those perturbed parameters numerically

753
00:44:33,030 --> 00:44:35,720
and compare it to the one you computed with backprop

754
00:44:36,040 --> 00:44:38,920
and if they're wildly far off you know something is wrong

755
00:44:41,050 --> 00:44:42,530
so finally

756
00:44:43,040 --> 00:44:47,330
you can verify on small training set the objective function decreases so

757
00:44:47,520 --> 00:44:50,480
because we often have to implement our own optimizers for

758
00:44:50,670 --> 00:44:53,200
the scale of problems the type of problem we're working on

759
00:44:53,470 --> 00:44:55,700
we want to make sure that the optimizers by g

760
00:44:55,970 --> 00:45:00,310
and so if you can just create a sort of small problem make sure the objective function is going

761
00:45:01,030 --> 00:45:02,690
to make sure that your gradient as right

762
00:45:02,860 --> 00:45:06,970
make sure that you didn't forget to use the negative gradient of the positive gradient

763
00:45:07,260 --> 00:45:08,180
which comes up a lot

764
00:45:10,070 --> 00:45:11,560
and sort of related to this

765
00:45:11,740 --> 00:45:14,080
is if you can create a small dataset

766
00:45:14,210 --> 00:45:17,480
where you think it should be possible to get a hundred percent accuracy

767
00:45:17,640 --> 00:45:21,300
should check that you can actually train neural net that gets a hundred percent accuracy

768
00:45:21,640 --> 00:45:22,910
if you can do that

769
00:45:23,640 --> 00:45:27,370
doesn't necessarily mean that something's wrong but it's worth asking why you can't

770
00:45:27,640 --> 00:45:28,760
maybe it's the case

771
00:45:28,990 --> 00:45:34,090
that you have some functional form for neural network that just is able to represent a good

772
00:45:34,110 --> 00:45:36,270
decision function you should think again about

773
00:45:36,480 --> 00:45:38,540
maybe what sorts of non-linear jersey

774
00:45:39,460 --> 00:45:40,420
and finally

775
00:45:40,640 --> 00:45:41,970
again if you can afford it

776
00:45:42,150 --> 00:45:47,280
using optimizer they use a second order information requires a new method

777
00:45:47,520 --> 00:45:48,830
like l-bfgs

778
00:45:49,380 --> 00:45:53,050
these optimizers are now available off the shelf in matlab

779
00:45:53,240 --> 00:45:55,470
all over the place and they're really well to and

780
00:45:56,930 --> 00:46:02,530
you can jettison all your own optimization code temporarily to make sure that your neural network is working

781
00:46:02,970 --> 00:46:05,260
so that you don't have to deal with the optimizer

782
00:46:06,600 --> 00:46:10,160
and finally just some advice from the machine learning world

783
00:46:10,440 --> 00:46:12,830
let's say you've got optimizer working

784
00:46:13,030 --> 00:46:14,070
gradient is right

785
00:46:14,350 --> 00:46:17,690
or you get some minimum and you still get horrible results

786
00:46:19,010 --> 00:46:23,040
then the standard pipeline for debugging these things is actually to look at

787
00:46:23,160 --> 00:46:25,060
the training error in the testing error

788
00:46:25,250 --> 00:46:29,220
so if you look at the training data and you're neural network is making bad predictions

789
00:46:29,240 --> 00:46:30,470
even on the training data

790
00:46:30,960 --> 00:46:32,410
more data can help you

791
00:46:32,790 --> 00:46:36,220
if you're not fitting the data you've already got more data can picture problem

792
00:46:36,220 --> 00:46:41,300
what we lack last access who's from cornell in the army command and pumpkins and

793
00:46:41,300 --> 00:46:46,370
they were all released in the summer and what talk about is how the social

794
00:46:46,370 --> 00:46:51,280
networks one right so they evolve by additions of nodes and deletions of nodes and

795
00:46:51,280 --> 00:46:56,340
edges and for example as we saw in the previous talk right usually how is

796
00:46:56,350 --> 00:47:00,250
how do we study this is a series of light snapshots of of graphs of

797
00:47:00,250 --> 00:47:06,770
for example taken network and they use natural so the point is that very few

798
00:47:06,770 --> 00:47:11,890
of study will usually all sorts of using snapshots nobody has actually seen how individual

799
00:47:11,890 --> 00:47:16,220
nodes nodes and edges in the networks so basically the topic of this talk be

800
00:47:16,230 --> 00:47:21,090
exactly so we will have large online social networks when we know exact node and

801
00:47:21,090 --> 00:47:27,320
edge arrival sequences so these animations showed down here we know exactly when nodes which

802
00:47:27,320 --> 00:47:31,790
edges they created so we know both basically atomic events of network

803
00:47:31,810 --> 00:47:34,810
and there are two two important points all sorts of things that you can do

804
00:47:34,810 --> 00:47:35,940
if you have

805
00:47:35,950 --> 00:47:37,770
so the first one is you can

806
00:47:37,780 --> 00:47:43,250
test series or models of individual and i can see how individual disappear one after

807
00:47:43,250 --> 00:47:47,220
another in the network from the first edge to thirty million OK so for example

808
00:47:47,220 --> 00:47:51,610
you can ask what is causing the AC power law degree distributions because there are

809
00:47:51,610 --> 00:47:56,950
many different mechanisms that you have institutions and the other important point is that you

810
00:47:57,500 --> 00:48:01,280
given the model you can calculate the likelihood of the model meaning you can calculate

811
00:48:01,280 --> 00:48:05,280
what's the probability that under that model i would observe my network so instead of

812
00:48:05,580 --> 00:48:10,840
comparing the quality of the model but we are like summary summary statistics for example

813
00:48:10,840 --> 00:48:16,310
saying oh my model can produce power law degreedistribution actually comparing the probability that model

814
00:48:16,350 --> 00:48:21,240
with generate so this is be sort of the points the points of the the

815
00:48:23,030 --> 00:48:24,330
and to go

816
00:48:24,330 --> 00:48:28,410
so i was setting is this and by network evolution if you think what we

817
00:48:28,410 --> 00:48:29,640
need to specify

818
00:48:29,640 --> 00:48:33,810
completely describe the how the graph was there are processes that first you need to

819
00:48:33,810 --> 00:48:37,670
say how are you know the right so what what i was of new nodes

820
00:48:38,190 --> 00:48:40,550
the second process is then

821
00:48:40,580 --> 00:48:44,600
what we call the edge initiation process where the question is when two nodes wake

822
00:48:44,600 --> 00:48:48,720
up and say oh i want to create an entry the setting would all creates

823
00:48:48,720 --> 00:48:52,190
an edge goes to sleep and wakes up another point and says oh i want

824
00:48:52,190 --> 00:48:54,180
to create another and then

825
00:48:54,220 --> 00:48:56,280
this leads to the process that says

826
00:48:56,340 --> 00:48:59,730
when i wake up and i say i want to create next edge where way

827
00:48:59,730 --> 00:49:04,560
we're going to OK and the data we had with these four online social networks

828
00:49:04,880 --> 00:49:09,070
so flickr delicious answers and the same for all of them we had data for

829
00:49:09,100 --> 00:49:15,530
about three years to two year they are all quite large meaning for my seven

830
00:49:15,600 --> 00:49:20,040
hundred thousand nodes through eight million nodes and the number of edges goes to millions

831
00:49:20,040 --> 00:49:22,840
and for all of them basically we see that we have that they can complete

832
00:49:22,840 --> 00:49:26,480
solution for the first that is fifty million four

833
00:49:26,530 --> 00:49:31,310
OK so basically the plan for the rest of the talk is to describe this

834
00:49:31,310 --> 00:49:33,470
process is show you

835
00:49:33,480 --> 00:49:37,590
what our findings show experiments and sort of the model one iteration

836
00:49:37,600 --> 00:49:42,500
so first is how and all the nodes are i hope you understand the sort

837
00:49:42,500 --> 00:49:46,480
of to our surprise this is very different so for example what i'm showing you

838
00:49:46,480 --> 00:49:50,650
here is time and the number of nodes in the networks in the network over

839
00:49:50,720 --> 00:49:54,410
time and what you can see is that for example for africa after this initial

840
00:49:54,410 --> 00:49:59,910
period you get exponential so flickr is growing exponentially on the other hand delicious which

841
00:49:59,910 --> 00:50:05,660
is basically a social network of how people share bookmarks grows linearly with the number

842
00:50:05,660 --> 00:50:10,650
of new users grows linearly with time for yahoo answers which is a question answering

843
00:50:10,660 --> 00:50:16,600
a social networking website grow sublinearly over which is sort of a bit worrying and

844
00:50:16,620 --> 00:50:21,220
they you look at least in it grows quadratically with the number of music videos

845
00:50:21,220 --> 00:50:26,030
contract sort of the conclusion you can make it is not very satisfactory one but

846
00:50:26,030 --> 00:50:30,340
not the arrival process seems to be network dependent depends on the main weapon network

847
00:50:30,350 --> 00:50:31,210
comes from

848
00:50:31,940 --> 00:50:36,430
then the next question you go and ask is what is life what is the

849
00:50:36,430 --> 00:50:40,840
time span of an old rates when it created the first and the last that

850
00:50:42,410 --> 00:50:47,530
if you go measure this for all four networks find the node lifetimes exponential so

851
00:50:47,530 --> 00:50:51,930
if i ask you about the distribution of not node lifetimes which is the probability

852
00:50:51,940 --> 00:50:58,220
i find i find that it follows an exponential distribution and here basically this

853
00:50:58,340 --> 00:51:02,340
the beginning of distribution of people who get invited to the system created the first

854
00:51:03,610 --> 00:51:07,840
so the conclusion here is a node lifetimes follow exponential distribution

855
00:51:07,900 --> 00:51:11,300
so basically what we know so far so for another i was you know that

856
00:51:11,300 --> 00:51:15,180
and in fact much of it was formulated before there was a good microscopic model

857
00:51:15,180 --> 00:51:20,430
of matter before the atomic theory of matter and molecules and so forth was

858
00:51:20,490 --> 00:51:22,290
well worked out

859
00:51:25,390 --> 00:51:29,670
it's incredible how how powerful the whole formalism is

860
00:51:29,690 --> 00:51:31,390
in some sense

861
00:51:31,390 --> 00:51:34,470
although it may seem like like

862
00:51:34,490 --> 00:51:39,030
neglecting what we now know to be an important part of nature

863
00:51:39,070 --> 00:51:42,630
actually part of its powers of empiricism

864
00:51:42,890 --> 00:51:49,690
the there are these very small number of fundamental laws from which everything else follows

865
00:51:49,740 --> 00:51:54,720
and at this point of course there's just enormous confidence in that small number ones

866
00:51:54,720 --> 00:51:58,270
because of their being verified in so many contexts

867
00:52:00,020 --> 00:52:02,630
but at the same time we do now

868
00:52:02,690 --> 00:52:07,380
about the atomic theory of matter we know there are atoms and molecules

869
00:52:07,380 --> 00:52:09,320
so it ought to be possible

870
00:52:09,430 --> 00:52:11,130
at least in principle

871
00:52:11,150 --> 00:52:13,730
to start from a purely microscopic

872
00:52:13,780 --> 00:52:15,860
approach to nature

873
00:52:16,550 --> 00:52:18,150
just based on

874
00:52:18,210 --> 00:52:22,190
figuring out the proper the microscopic properties

875
00:52:22,200 --> 00:52:26,970
and then say well OK my macroscopic stuff is just a collection of those microscopic

876
00:52:28,790 --> 00:52:32,720
i should also be able to figure out macroscopic around

877
00:52:32,780 --> 00:52:35,890
i should be able to start from my microscopic picture

878
00:52:35,900 --> 00:52:39,240
and get the macroscopic thermodynamic results

879
00:52:39,450 --> 00:52:45,850
and in fact that is possible and the theoretical formulation for is what's called statistical

880
00:52:45,850 --> 00:52:51,850
mechanics called that because of course it you will be surprised to learn that

881
00:52:51,900 --> 00:52:57,370
it's going to require statistical treatment right to be dealing with walls of material but

882
00:52:57,390 --> 00:53:02,650
now we're going to be trying to think about their microscopic properties and that and

883
00:53:02,650 --> 00:53:04,210
so will be feeling

884
00:53:04,210 --> 00:53:08,980
not with and number of moles but we can to the twenty fourth number of

885
00:53:08,980 --> 00:53:11,190
molecules or atoms

886
00:53:11,210 --> 00:53:15,140
and you know we won't be able to keep track of every one of their

887
00:53:15,140 --> 00:53:17,850
individual states all the prime

888
00:53:17,870 --> 00:53:21,120
right we may be able to do a terrific calculation of

889
00:53:21,210 --> 00:53:26,150
the quantum mechanics of the count classical mechanics to describe the states that they could

890
00:53:27,650 --> 00:53:33,080
but there's no way in practice but were either experimentally or theoretically keep track of

891
00:53:33,080 --> 00:53:35,020
all of that

892
00:53:35,040 --> 00:53:39,170
so we're going to at some point have to introduce statistics

893
00:53:39,210 --> 00:53:43,460
to take what we know about the the microscopic properties and try to go from

894
00:53:43,460 --> 00:53:47,650
there to the macroscopic results from around the seen so far

895
00:53:47,650 --> 00:53:50,980
and that's the statistical mechanics is all about

896
00:53:55,400 --> 00:54:13,420
so let's try to introduce a little bit

897
00:54:13,420 --> 00:54:21,830
of statistical mechanics we're going to go from from what we know about the microscopic

898
00:54:21,830 --> 00:54:26,790
properties all the way to macroscopic thermodynamics that's our objective

899
00:54:32,000 --> 00:54:34,000
so let's start

900
00:54:34,000 --> 00:54:37,560
by just trying to calculate

901
00:54:37,620 --> 00:54:41,690
energies of individual molecules are individual particles

902
00:54:41,750 --> 00:54:44,480
and what's the probability

903
00:54:45,770 --> 00:54:50,390
some molecule one of the oxygen molecules somewhere in this room

904
00:54:50,400 --> 00:54:52,400
it in a certain energy states

905
00:54:53,900 --> 00:54:55,750
and what our strategy is going to be

906
00:54:55,770 --> 00:54:57,230
is to determine

907
00:54:57,250 --> 00:55:01,520
one of the probability is that molecules are in certain states

908
00:55:01,540 --> 00:55:03,350
with certain energy

909
00:55:03,400 --> 00:55:07,350
and if we can determine that for all the possible states

910
00:55:07,350 --> 00:55:09,810
then we can average over those

911
00:55:09,810 --> 00:55:13,940
so without keeping track of every individual molecule

912
00:55:13,980 --> 00:55:18,290
we could then calculate on average energy which is what you would measure for and

913
00:55:18,310 --> 00:55:21,900
when you look at the whole collection and measure what we call you

914
00:55:21,960 --> 00:55:24,710
right of course we're really averaging over

915
00:55:24,770 --> 00:55:29,310
disparate energies of lots of different atoms or molecules right they don't all have the

916
00:55:29,310 --> 00:55:31,750
same molecular energy

917
00:55:31,750 --> 00:55:34,230
and we don't try to measure the individual entries

918
00:55:35,420 --> 00:55:38,650
so that's what we'd like to calculate and so we we

919
00:55:38,670 --> 00:55:42,130
i like to be able to know what all these probabilities

920
00:55:42,210 --> 00:55:44,330
of different energy states

921
00:55:44,350 --> 00:55:46,080
and then from that

922
00:55:46,120 --> 00:55:48,150
statistically averaging

923
00:55:48,170 --> 00:55:53,190
what are the macroscopic average energy and other macroscopic one

924
00:55:54,600 --> 00:55:57,690
let's start their probability

925
00:56:05,060 --> 00:56:05,600
you no

926
00:56:13,120 --> 00:56:15,960
specific as possible as in

927
00:56:23,560 --> 00:56:27,920
he i and right now we're not even going to specify the nature of the

928
00:56:27,920 --> 00:56:34,870
state we could be worrying about translational energy right what state is how fast this

929
00:56:34,890 --> 00:56:36,310
was around the room

930
00:56:36,370 --> 00:56:41,000
we can worry about its vibrational world rotational energy or electronic state

931
00:56:41,020 --> 00:56:43,190
for now let's not even specified

932
00:56:43,230 --> 00:56:47,330
let's just say it is the only thing we're really specify about the state

933
00:56:47,350 --> 00:56:51,190
is it has some energy that we know that we only know

934
00:56:58,670 --> 00:56:59,830
what we like

935
00:56:59,850 --> 00:57:03,480
is the no functional form for the probability

936
00:57:03,480 --> 00:57:05,960
we don't know one a or

937
00:57:07,870 --> 00:57:10,290
let's just think about

938
00:57:10,290 --> 00:57:12,120
two molecules

939
00:57:12,130 --> 00:57:12,980
and there

940
00:57:12,980 --> 00:57:18,980
the probability that one of them has energy by another one has energy e j

941
00:57:19,000 --> 00:57:23,020
it also let me say would be sufficient to think about even one molecule and

942
00:57:23,020 --> 00:57:27,540
say well let's think about independent parts of its energy let's translational energy in this

943
00:57:27,540 --> 00:57:30,020
direction in orthogonal direction

944
00:57:30,080 --> 00:57:33,000
what matters is we're thinking about two

945
00:57:35,170 --> 00:57:38,560
energy could be separate molecules are in interacting

946
00:57:38,620 --> 00:57:42,150
or independent degrees of freedom on the same molecule

947
00:57:42,150 --> 00:57:44,730
but let's let's just consider it

948
00:57:46,080 --> 00:57:47,920
so molecules in

949
00:57:47,940 --> 00:57:49,540
they i

950
00:57:57,310 --> 00:58:01,080
it in the

951
00:58:06,870 --> 00:58:08,250
u j

952
00:58:08,270 --> 00:58:11,650
right so what we're going to calculate is the

953
00:58:11,670 --> 00:58:17,330
joint probability that they were in the two molecules are in those states so

954
00:58:17,390 --> 00:58:19,560
we want the probability

955
00:58:19,560 --> 00:58:22,120
this one will call

956
00:58:23,650 --> 00:58:25,650
i vi ii

957
00:58:25,710 --> 00:58:27,580
this would be

958
00:58:27,620 --> 00:58:29,500
p j

959
00:58:31,670 --> 00:58:35,000
and this probability together will be p on

960
00:58:39,230 --> 00:58:42,900
i could just write the ikarma EJ but the energy that

961
00:58:42,960 --> 00:58:45,270
and that's crucial

962
00:58:48,830 --> 00:58:53,250
since the molecules are completely independent this should just be the product of the separate

963
00:59:03,370 --> 00:59:05,540
two completely independent

964
00:59:05,540 --> 00:59:10,690
the answer these things with probability one german together

965
00:59:12,330 --> 00:59:15,830
that suggests the really simple functional form because

966
00:59:15,830 --> 00:59:18,240
introduces a new prior so remember

967
00:59:19,520 --> 00:59:23,040
there are different kinds of priors we can put in enough to not be talking

968
00:59:23,040 --> 00:59:25,100
about these very broad priors like smoothness

969
00:59:25,720 --> 00:59:26,890
like having multiple

970
00:59:27,450 --> 00:59:29,080
factors in the representation

971
00:59:30,430 --> 00:59:31,270
like having depth

972
00:59:33,350 --> 00:59:38,290
in an an one extra priors this sparsity prior and the sparsity prior says that

973
00:59:39,370 --> 00:59:39,890
i've already

974
00:59:40,490 --> 00:59:42,680
factors that could explain important

975
00:59:43,330 --> 00:59:44,100
only a small

976
00:59:44,560 --> 00:59:48,350
subset that are relevant for any particular example for any particular input

977
00:59:48,990 --> 00:59:52,270
that makes a lot of sense as a prior if you think about it

978
00:59:52,310 --> 00:59:52,950
this notion of

979
00:59:53,430 --> 00:59:56,430
explanatory factors i talked about this and think factors

980
00:59:57,770 --> 01:00:02,200
one nice thing about sparse representation that enforces the representations to

981
01:00:03,160 --> 01:00:04,100
to make some choices

982
01:00:05,430 --> 01:00:06,660
representation parts

983
01:00:07,080 --> 01:00:07,540
if u

984
01:00:08,520 --> 01:00:14,060
i do i is redwood projection of the data to random mutation of it is not part so

985
01:00:15,180 --> 01:00:16,620
when you have a sparse representation

986
01:00:18,370 --> 01:00:21,140
different units are kind of forced to take on some particular meaning

987
01:00:23,720 --> 01:00:29,080
so in quite a bit of work in representation learning with sparse representations but be

988
01:00:29,930 --> 01:00:31,640
he came out as one of these e

989
01:00:31,890 --> 01:00:33,450
ingredients that seem to help

990
01:00:34,140 --> 01:00:34,930
in deep learning

991
01:00:36,140 --> 01:00:38,220
around two thousand ten two thousand eleven

992
01:00:41,370 --> 01:00:43,950
so what happens is shown in the lower left picture

993
01:00:44,680 --> 01:00:46,640
where you see the neural nets

994
01:00:46,970 --> 01:00:49,390
wear only a few units really

995
01:00:49,810 --> 01:00:51,370
are used for any particular example

996
01:00:52,240 --> 01:00:54,270
so the centre have that that

997
01:00:54,620 --> 01:00:55,330
are activated

998
01:00:56,080 --> 01:00:56,930
contribute to

999
01:00:57,600 --> 01:01:01,600
to output into the air and alleles will be modified for a particular example

1000
01:01:05,160 --> 01:01:07,540
now as in this illustration that's

1001
01:01:08,200 --> 01:01:09,750
backprop can sometimes fail

1002
01:01:11,450 --> 01:01:12,370
this e

1003
01:01:12,450 --> 01:01:15,240
the problem that one my students work on was

1004
01:01:16,010 --> 01:01:16,620
presented at

1005
01:01:17,100 --> 01:01:18,890
i see conference i clear

1006
01:01:19,470 --> 01:01:19,950
last year

1007
01:01:20,580 --> 01:01:27,200
wear all of the machine learning methods that we tried and true including shallow networks these networks with training

1008
01:01:28,010 --> 01:01:28,810
is he ends

1009
01:01:29,180 --> 01:01:30,520
decision trees boosting

1010
01:01:30,930 --> 01:01:31,720
they all failed

1011
01:01:32,830 --> 01:01:34,040
got fifty percent error

1012
01:01:34,560 --> 01:01:35,290
on test set

1013
01:01:37,790 --> 01:01:41,680
four further those like neural nets which don't tend to overfit has as easily they

1014
01:01:41,810 --> 01:01:44,870
wouldn't you wouldn't be able to get even training error to to go down very

1015
01:01:46,510 --> 01:01:47,080
so it

1016
01:01:47,830 --> 01:01:49,350
so that was kind of intriguing

1017
01:01:49,870 --> 01:01:51,580
but it turns out that for this task

1018
01:01:52,310 --> 01:01:53,640
if you break down the problem

1019
01:01:54,060 --> 01:01:58,620
into two problems and train first network that's all the first task and then

1020
01:01:59,140 --> 01:02:00,350
we initialize the

1021
01:02:01,810 --> 01:02:05,740
you've got to initialize deep network you can sort out so it's kind of cheating

1022
01:02:06,010 --> 01:02:10,220
but if you can guide training by providing some kind of hints of what intermediate

1023
01:02:10,220 --> 01:02:12,810
level should be doing some problems which seemed

1024
01:02:13,270 --> 01:02:15,180
impossible suddenly become feasible

1025
01:02:16,370 --> 01:02:19,680
we know that as an optimization problem because if you initialize properly

1026
01:02:20,200 --> 01:02:21,220
you can solve this problem

1027
01:02:22,700 --> 01:02:25,640
so there are things that don't work well with backprop in

1028
01:02:26,560 --> 01:02:29,120
and maybe there are no solutions but hopefully there are solutions

1029
01:02:29,890 --> 01:02:32,490
one thing we discovered recently is kind of making us

1030
01:02:33,220 --> 01:02:33,850
i believe

1031
01:02:34,310 --> 01:02:36,100
be more hopeful than a few years ago

1032
01:02:37,020 --> 01:02:42,740
is done on this idea that neural nets are plagued by local minima maybe may be wrong

1033
01:02:43,640 --> 01:02:44,180
so is some

1034
01:02:46,270 --> 01:02:46,930
papers from

1035
01:02:48,160 --> 01:02:49,620
statistical physics and

1036
01:02:49,830 --> 01:02:52,890
the applied math and random matrices matrices

1037
01:02:54,490 --> 01:02:58,270
suggest that's when you consider high dimensional random function

1038
01:02:59,040 --> 01:03:01,330
is gonna be very unlikely that has

1039
01:03:02,510 --> 01:03:05,010
in a bad local minima meaning local minima

1040
01:03:05,470 --> 01:03:06,910
corresponding to a very bad calls

1041
01:03:07,910 --> 01:03:08,850
and you can think of it like

1042
01:03:12,240 --> 01:03:14,520
the critical point place where derivatives cancel

1043
01:03:15,830 --> 01:03:16,410
in order to be

1044
01:03:17,100 --> 01:03:18,120
i y local minimum

1045
01:03:18,520 --> 01:03:18,970
has to be

1046
01:03:19,470 --> 01:03:22,180
i have positive curvature in all directions

1047
01:03:24,390 --> 01:03:27,060
in if you have a lot of directions you know what's the chance of this

1048
01:03:27,060 --> 01:03:30,490
happening there's gonna be some direction aware it's going down and then you have a

1049
01:03:30,490 --> 01:03:31,180
set of points

1050
01:03:31,870 --> 01:03:35,100
you have cell so what happens is that there is exponentially more subtle points

1051
01:03:35,620 --> 01:03:38,240
then local minima except near the bottom where you have

1052
01:03:38,720 --> 01:03:40,790
both the global minimum and some local minima

1053
01:03:42,540 --> 01:03:47,850
so so if this is true and we have experiments suggesting that it seems to be true in deep nets

1054
01:03:48,250 --> 01:03:49,200
then that means that

1055
01:03:50,270 --> 01:03:53,600
the idea that we get stuck because local minimize wrong we're getting stuck

1056
01:03:54,160 --> 01:03:58,370
because the derivatives are flat yes that's be saddlepoint which means

1057
01:03:59,120 --> 01:04:01,310
if are smarter about optimization

1058
01:04:01,790 --> 01:04:04,040
you could find these directions going down

1059
01:04:04,600 --> 01:04:06,830
these these directions of negative curvature

1060
01:04:07,750 --> 01:04:11,490
maybe it's a needle in a haystack but it is rare it's not an impossible task

1061
01:04:12,540 --> 01:04:15,830
whereas if you if you think that you are stuck in a local minimum there's

1062
01:04:15,830 --> 01:04:18,080
nothing you can do short of using

1063
01:04:19,330 --> 01:04:20,060
something like

1064
01:04:20,850 --> 01:04:25,200
genetic algorithms or some something else that's global optimization as much harder

1065
01:04:26,350 --> 01:04:30,700
so that's kind of interesting and we've done some experiments to explore this hypothesis

1066
01:04:32,770 --> 01:04:33,350
where we

1067
01:04:34,660 --> 01:04:35,180
tried to

1068
01:04:40,270 --> 01:04:43,270
traditional newton methods so that they can go down when there is

1069
01:04:45,520 --> 01:04:46,830
when they are negative curvatures

1070
01:04:47,430 --> 01:04:51,330
basically what we do is we basically do newton except that we take the absolute

1071
01:04:51,330 --> 01:04:53,560
values of these i values the has been

1072
01:04:54,600 --> 01:04:55,890
and thanks to this we can

1073
01:04:56,310 --> 01:04:57,010
we can show that

1074
01:04:57,660 --> 01:05:01,010
in places where you are stochastic gradient descent or r

1075
01:05:01,810 --> 01:05:02,390
more traditional

1076
01:05:04,220 --> 01:05:05,810
quasi newton methods get stuck

1077
01:05:06,720 --> 01:05:07,620
you can actually escape

1078
01:05:13,600 --> 01:05:15,060
more even more recently

1079
01:05:15,510 --> 01:05:16,720
we're looking at

1080
01:05:19,010 --> 01:05:21,950
maybe even more drastic as change to

1081
01:05:24,270 --> 01:05:26,120
go around the limitations of background

1082
01:05:26,490 --> 01:05:31,060
so the reason why backdrop is problematic is not is relying on

1083
01:05:32,540 --> 01:05:35,120
are gradients derivatives and

1084
01:05:36,140 --> 01:05:39,680
derivatives make a lot of sense so long as the function you're trying to optimise

1085
01:05:39,680 --> 01:05:43,520
is very small as i explained earlier when you train very deep in there

1086
01:05:44,680 --> 01:05:46,510
very recurrent nett over many steps

1087
01:05:47,290 --> 01:05:49,470
you're trying to learn a function that's almost discrete

1088
01:05:50,390 --> 01:05:53,510
and if the function trying to learn is is very nonlinear discrete

1089
01:05:53,510 --> 01:05:55,520
this nonlinearity here

1090
01:05:55,540 --> 01:05:59,040
but this is that when there are too many people they start to compete for

1091
01:05:59,040 --> 01:06:01,160
the resources for the square

1092
01:06:01,180 --> 01:06:03,520
and this gives rise to an initial

1093
01:06:03,520 --> 01:06:06,040
exponential one this is negligible when the bush

1094
01:06:06,060 --> 01:06:08,270
and then the saturation

1095
01:06:08,290 --> 01:06:10,910
this is called negative feedback

1096
01:06:10,930 --> 01:06:15,600
too many rabbits eating grass that there are some groups of the population not enough

1097
01:06:15,600 --> 01:06:17,290
for a start either

1098
01:06:17,390 --> 01:06:20,510
the cross-strait levels

1099
01:06:20,560 --> 01:06:23,510
actually what is missing in this description

1100
01:06:23,540 --> 01:06:25,930
the possibility for positive feedback

1101
01:06:25,950 --> 01:06:28,520
possibly could prosecute

1102
01:06:28,540 --> 01:06:32,790
and the thing again the logistic equation it is called the frame it in the

1103
01:06:32,790 --> 01:06:35,620
case of lists population rules of price

1104
01:06:35,660 --> 01:06:38,160
same viable name

1105
01:06:38,930 --> 01:06:41,990
in population growth constant here

1106
01:06:41,990 --> 01:06:45,220
which cannot be of the past because of course when the population

1107
01:06:45,240 --> 01:06:49,410
goes to KK minus p goes to zero the rate of change becomes zero and

1108
01:06:49,430 --> 01:06:51,310
you this plateau

1109
01:06:51,370 --> 01:06:55,040
carrying case called the carrying capacity of the planet

1110
01:06:55,060 --> 01:06:56,970
so that's according to

1111
01:06:56,990 --> 01:06:58,200
but what

1112
01:06:58,240 --> 01:07:01,580
endogenous growth economies i've come to learn

1113
01:07:01,700 --> 01:07:05,660
that actually the carrying capacity of the planet has grown itself as a function of

1114
01:07:06,450 --> 01:07:07,790
due to innovations

1115
01:07:07,810 --> 01:07:09,330
research and development

1116
01:07:09,370 --> 01:07:13,250
growth of population list two exploration of new niches

1117
01:07:14,270 --> 01:07:16,870
invasion of new territories so

1118
01:07:17,750 --> 01:07:22,410
carrying capacity of the planet has grown itself was population to make a simple and

1119
01:07:23,220 --> 01:07:28,600
assuming that the carrying capacity also grows as the power of population to reflect simple

1120
01:07:30,580 --> 01:07:32,870
positive feedback of population on

1121
01:07:32,890 --> 01:07:35,930
on the extension of the carrying capacity open

1122
01:07:35,970 --> 01:07:40,290
your your then this equation we can neglect this if that thousand one

1123
01:07:40,330 --> 01:07:42,720
this is a nonlinear equation which is

1124
01:07:45,180 --> 01:07:46,970
in terms of the dynamics

1125
01:07:46,970 --> 01:07:49,450
because it leads to behavior

1126
01:07:49,470 --> 01:07:53,890
which most of scientists natural and social they don't like

1127
01:07:53,930 --> 01:07:57,060
give rise to finite time singularity

1128
01:07:57,100 --> 01:07:59,490
it means that there is no stationary solution

1129
01:07:59,490 --> 01:08:02,680
you cannot have existence proof for infinite time

1130
01:08:02,700 --> 01:08:07,720
if you can prove that in finite time solutions blows either go to infinity or

1131
01:08:07,720 --> 01:08:11,990
the rate of growth of course to infinity to infinity so this is for example

1132
01:08:12,010 --> 01:08:14,350
solutions really simple to calculate

1133
01:08:14,430 --> 01:08:15,510
this is

1134
01:08:15,510 --> 01:08:17,040
the blue

1135
01:08:17,060 --> 01:08:18,970
let's look at the data so

1136
01:08:18,970 --> 01:08:22,140
i'm looking at this problem with some

1137
01:08:22,160 --> 01:08:24,600
the hunt is on the population dynamics because it

1138
01:08:24,620 --> 01:08:27,950
i think it express very well the concept of positive feedback

1139
01:08:28,010 --> 01:08:32,970
but i want to push forward the underlying mechanism behind here i go back to

1140
01:08:34,890 --> 01:08:39,270
there a reconstructed over two thousand years

1141
01:08:39,270 --> 01:08:41,270
OK well writen somewhere here

1142
01:08:41,290 --> 01:08:45,950
and i took of course when one reconstructed world population

1143
01:08:45,970 --> 01:08:49,180
and the other one is the world's GDP

1144
01:08:49,330 --> 01:08:54,180
again i stress that automate is in log scale

1145
01:08:54,220 --> 01:08:56,120
log scale in our scale

1146
01:08:56,140 --> 01:08:58,830
an exponential growth is a straight line

1147
01:08:58,930 --> 01:09:01,540
this great like this occur

1148
01:09:01,720 --> 01:09:05,370
maybe here maybe here and the one sort one

1149
01:09:05,410 --> 01:09:10,330
OK so if you do an econometric work you need three of four exponential to

1150
01:09:10,330 --> 01:09:11,330
fit the data

1151
01:09:11,330 --> 01:09:17,020
it turns out that it's much more parsimonious and more efficient just fit this singular

1152
01:09:17,020 --> 01:09:19,120
behaviour which is the remarkable

1153
01:09:19,120 --> 01:09:21,410
description of the data

1154
01:09:21,430 --> 01:09:22,490
so actually

1155
01:09:22,490 --> 01:09:25,250
what we see here is that the population of the earth

1156
01:09:25,270 --> 01:09:26,370
of humans

1157
01:09:26,370 --> 01:09:29,580
group super exponentially over the

1158
01:09:29,600 --> 01:09:30,790
you see is

1159
01:09:30,810 --> 01:09:32,660
last five hundred years

1160
01:09:32,680 --> 01:09:34,830
and this is probably

1161
01:09:34,830 --> 01:09:36,430
the result of these

1162
01:09:36,870 --> 01:09:40,410
positive feedback of population carrying capacity and we can

1163
01:09:40,430 --> 01:09:42,430
summarise the situation i think

1164
01:09:42,600 --> 01:09:44,020
is was an optimist

1165
01:09:44,120 --> 01:09:49,450
the problem is not exponential growth problem is super exponential and this review is really

1166
01:09:49,470 --> 01:09:50,540
very clearly

1167
01:09:50,620 --> 01:09:53,100
the positive feedback phenomenon now

1168
01:09:53,120 --> 01:09:58,040
in market because we are dealing with financial market what can be the positive feedback

1169
01:09:58,040 --> 01:09:59,930
that give rise to this

1170
01:09:59,930 --> 01:10:02,180
girls of instability

1171
01:10:02,200 --> 01:10:06,270
community get crackdown many actually not going to spend time

1172
01:10:06,620 --> 01:10:12,090
telling any of them but just for the sake of completeness there are of the

1173
01:10:12,090 --> 01:10:15,950
technical and rational type and they are of the behaviour

1174
01:10:17,100 --> 01:10:19,950
a lot of of the modern instruments

1175
01:10:19,970 --> 01:10:25,620
they require for their risk contolled actually

1176
01:10:25,620 --> 01:10:26,850
two had to risk

1177
01:10:26,850 --> 01:10:30,450
two dimensional subspace of our

1178
01:10:32,400 --> 01:10:34,610
the fact that they work in

1179
01:10:34,610 --> 01:10:39,580
you're seeing that we we have some idea of dependence or independence is is in

1180
01:10:39,580 --> 01:10:40,870
our future

1181
01:10:41,570 --> 01:10:44,130
not to speak about

1182
01:10:45,380 --> 01:10:46,490
vector space

1183
01:10:49,650 --> 01:10:53,110
so again i'm getting a little ahead

1184
01:10:53,110 --> 01:10:57,400
because of this in section three point two but that

1185
01:10:57,430 --> 01:11:00,940
all right now i'm reading from the north

1186
01:11:00,980 --> 01:11:04,340
to keep the same metric

1187
01:11:04,340 --> 01:11:10,650
and this is going to be different totally different

1188
01:11:14,610 --> 01:11:19,760
so let me make the page down here comes a completely different

1189
01:11:19,820 --> 01:11:25,980
the north

1190
01:11:29,350 --> 01:11:33,540
what is it

1191
01:11:33,590 --> 01:11:36,190
it contains

1192
01:11:36,250 --> 01:11:39,230
not right inside the

1193
01:11:39,250 --> 01:11:42,500
it contains at

1194
01:11:42,550 --> 01:11:46,870
it contains all x's that's all there were no

1195
01:11:48,180 --> 01:11:50,290
and that's the key word here

1196
01:11:50,330 --> 01:11:51,740
maybe zero

1197
01:11:51,760 --> 01:11:53,560
so this campaign

1198
01:11:53,560 --> 01:11:55,370
this is all

1199
01:12:00,280 --> 01:12:05,890
and of course taxes are vectors x one x two and x three

1200
01:12:07,240 --> 01:12:09,000
the equations

1201
01:12:13,600 --> 01:12:16,240
well for quite

1202
01:12:16,260 --> 01:12:17,220
because we get

1203
01:12:17,230 --> 01:12:19,360
so you see what i'm doing

1204
01:12:19,400 --> 01:12:21,010
i'm now saying

1205
01:12:21,030 --> 01:12:23,150
OK problems were great

1206
01:12:23,210 --> 01:12:27,500
columns space we understood now i'm interested in

1207
01:12:29,140 --> 01:12:33,650
i'm not the only be uninterested in hours the BM all the right hand side

1208
01:12:33,840 --> 01:12:36,180
mount zero

1209
01:12:36,240 --> 01:12:41,290
and i'm interested in some of

1210
01:12:42,580 --> 01:12:47,850
whereas the novel's for this example

1211
01:12:47,870 --> 01:12:49,970
these are

1212
01:12:49,990 --> 01:12:52,800
i have three components

1213
01:12:52,800 --> 01:12:56,750
so the null space is the subspace we still have to show it is a

1214
01:12:56,750 --> 01:12:59,550
subspace of are

1215
01:13:01,290 --> 01:13:04,200
so this is an and we will show

1216
01:13:04,230 --> 01:13:08,630
so these factors that this is an

1217
01:13:08,680 --> 01:13:10,280
are three

1218
01:13:14,070 --> 01:13:16,290
the columns space was then

1219
01:13:16,330 --> 01:13:19,080
are for our

1220
01:13:19,260 --> 01:13:22,110
and in different n by n matrix

1221
01:13:22,130 --> 01:13:24,450
this is an

1222
01:13:24,470 --> 01:13:27,510
and this is an

1223
01:13:27,560 --> 01:13:34,110
the number of columns and tell me how many unknowns how many x multiply those

1224
01:13:34,130 --> 01:13:36,180
so it tells me that

1225
01:13:36,200 --> 01:13:37,510
big space

1226
01:13:37,530 --> 01:13:39,640
in this case are reason i mean

1227
01:13:40,570 --> 01:13:43,150
tell me why don't we figure out what the note

1228
01:13:43,180 --> 01:13:47,060
spaces for this example

1229
01:13:47,060 --> 01:13:48,330
just by

1230
01:13:48,390 --> 01:13:50,880
well i mean that's the

1231
01:13:50,890 --> 01:13:54,470
beauty of small examples

1232
01:13:54,530 --> 01:13:58,280
that's my official way to find no spaces

1233
01:13:58,280 --> 01:14:01,150
and column bases and

1234
01:14:01,170 --> 01:14:03,110
get all the facts right

1235
01:14:03,150 --> 01:14:04,580
it would be

1236
01:14:04,580 --> 01:14:06,600
elimination and will do that

1237
01:14:06,610 --> 01:14:11,080
but with a small example we can see that see what's going on without

1238
01:14:11,150 --> 01:14:14,060
going through the mechanics of elimination so

1239
01:14:14,070 --> 01:14:17,720
so there no

1240
01:14:17,750 --> 01:14:21,010
talking about the again

1241
01:14:21,030 --> 01:14:23,380
let me copy and the matrix

1242
01:14:23,420 --> 01:14:28,340
one two three four

1243
01:14:28,380 --> 01:14:33,260
one one one one two three four five

1244
01:14:33,330 --> 01:14:34,300
what's going on

1245
01:14:34,310 --> 01:14:37,720
so i'm i'm eighty eight times the

1246
01:14:37,740 --> 01:14:40,790
right again

1247
01:14:40,790 --> 01:14:42,970
and i want you to solve

1248
01:14:42,990 --> 01:14:48,610
o four price

1249
01:14:48,710 --> 01:14:53,410
in fact i want to find all solutions to those four ways

1250
01:14:53,460 --> 01:14:57,600
well actually the first of all what i'd like to ask you for all

1251
01:14:57,600 --> 01:15:02,100
tell me one what can only one solution that you don't even have to

1252
01:15:02,110 --> 01:15:05,560
after a look at the matrix no one solution to this

1253
01:15:05,580 --> 01:15:08,860
that way and it is

1254
01:15:09,610 --> 01:15:13,080
whatever that matrix

1255
01:15:14,130 --> 01:15:15,990
they contain

1256
01:15:16,010 --> 01:15:16,890
because a

1257
01:15:16,910 --> 01:15:18,880
find zero vectors are given

1258
01:15:18,890 --> 01:15:21,180
zero right hand side

1259
01:15:21,200 --> 01:15:24,580
so the knowledge base contains the

1260
01:15:25,070 --> 01:15:26,090
so it's going to change

1261
01:15:26,140 --> 01:15:29,280
the vector space and will turn out

1262
01:15:31,090 --> 01:15:33,370
tell me another

1263
01:15:33,390 --> 01:15:35,730
so this particular space

1264
01:15:35,790 --> 01:15:38,080
and of course i'm going to call it and a

1265
01:15:38,690 --> 01:15:43,620
it contains

1266
01:15:43,620 --> 01:15:47,200
well we already located zero vector

1267
01:15:47,230 --> 01:15:49,170
and now you tell me

1268
01:15:49,180 --> 01:15:53,560
another factor that in the bayes another another

1269
01:15:55,500 --> 01:16:00,080
you see what i'm asking for is a combination of those columns what i'm of

1270
01:16:00,130 --> 01:16:02,420
what combinations of

1271
01:16:02,470 --> 01:16:06,250
but now i'm looking at the

1272
01:16:06,290 --> 01:16:08,930
the the the way

1273
01:16:08,990 --> 01:16:12,060
the coefficients in the combination so tell me

1274
01:16:12,120 --> 01:16:15,800
i could set numbers the point in

1275
01:16:16,450 --> 01:16:19,580
one one one

1276
01:16:19,600 --> 01:16:22,380
one might say

1277
01:16:22,430 --> 01:16:24,420
one one minus

1278
01:16:24,470 --> 01:16:28,390
so there's fact that

1279
01:16:29,140 --> 01:16:33,880
but i got a space at this point certainly not right

1280
01:16:33,890 --> 01:16:35,680
i got a couple of vectors

1281
01:16:35,830 --> 01:16:38,010
there's no way they make a subspace

1282
01:16:38,050 --> 01:16:38,910
tell me

1283
01:16:38,930 --> 01:16:42,130
actually what i jumped the whole way now

1284
01:16:42,130 --> 01:16:44,070
tell me

1285
01:16:44,110 --> 01:16:47,530
only one more solutions

1286
01:16:47,550 --> 01:16:52,200
one more expert woodworkers

1287
01:16:52,260 --> 01:16:52,910
two two

1288
01:16:52,970 --> 01:16:54,700
get two

1289
01:16:54,700 --> 01:16:55,730
all these distances

1290
01:16:56,700 --> 01:17:00,550
and the reason is because if you look at the similarity matrix are shown before

1291
01:17:02,420 --> 01:17:04,290
this is the squared distance yeah

1292
01:17:05,270 --> 01:17:09,090
and the similarity these basis function the way we set up the diagonal is always worn

1293
01:17:09,710 --> 01:17:14,240
because it's zero distance between the two data points and it's e to the minus distance squared

1294
01:17:14,920 --> 01:17:17,510
so the diagonal these guys all matrices are ones

1295
01:17:17,950 --> 01:17:19,080
and if you are dissimilar

1296
01:17:19,520 --> 01:17:23,470
this can in the middle is user so the squared distance is basically to

1297
01:17:24,830 --> 01:17:26,920
and this where that's is square root of two

1298
01:17:27,700 --> 01:17:31,880
so i don't quite know what's going on my column at but all these distances

1299
01:17:32,130 --> 01:17:36,720
but dissimilar points are the square root two the only not square root two very

1300
01:17:36,720 --> 01:17:37,770
much along the diagonal

1301
01:17:38,410 --> 01:17:39,370
now what was

1302
01:17:40,850 --> 01:17:41,570
error function

1303
01:17:43,380 --> 01:17:44,930
classical multidimensional scaling

1304
01:17:45,680 --> 01:17:51,240
and it's important to use this error function to understand why things go wrong from a dimensionality reduction perspective

1305
01:17:52,230 --> 01:17:57,740
yeah function was mean absolute error of distances in latent space versus distances in data

1306
01:17:57,740 --> 01:18:01,470
space this is now a new set of distances in data space although it is

1307
01:18:02,930 --> 01:18:04,800
related space that we're computing things on

1308
01:18:05,730 --> 01:18:09,330
so when we try and do the visualization what we trying to do we trying

1309
01:18:09,330 --> 01:18:13,330
to minimize the mean absolute error between the distances we compute and these distances here

1310
01:18:13,490 --> 01:18:14,170
on which

1311
01:18:15,380 --> 01:18:16,370
only order

1312
01:18:16,970 --> 01:18:17,970
three hundred sixty

1313
01:18:18,370 --> 01:18:23,530
distances are not equal to the square root to all the distances are equal to

1314
01:18:23,530 --> 01:18:25,940
the square root of two so what's the embedding trying to do

1315
01:18:26,550 --> 01:18:27,820
it's trying to embed them

1316
01:18:30,300 --> 01:18:31,010
is to apart

1317
01:18:33,020 --> 01:18:34,730
can you do design a low dimensional space

1318
01:18:35,770 --> 01:18:36,650
we give on the from

1319
01:18:37,170 --> 01:18:41,150
can you embed if i want embed three hundred sixty data points

1320
01:18:41,880 --> 01:18:45,240
square root to apart what size space to i need to do there

1321
01:18:51,980 --> 01:18:55,780
so i'm gonna wanna by every data point has to be square root to apart

1322
01:18:55,780 --> 01:18:58,180
from each other which is more extreme than what i've got here

1323
01:18:59,460 --> 01:19:00,990
how how was space to any

1324
01:19:01,470 --> 01:19:03,300
that's put in three hundred sixty dimensional space

1325
01:19:04,280 --> 01:19:05,180
i can't do any other way

1326
01:19:06,660 --> 01:19:08,700
otherwise some other data points will be close together

1327
01:19:09,970 --> 01:19:13,780
so in the base case if all data points are similar they will all be

1328
01:19:14,570 --> 01:19:17,800
in a three hundred sixty dimensional space and in fact you can see that's gonna

1329
01:19:17,800 --> 01:19:20,470
be the case because the rank of this matrix here

1330
01:19:21,620 --> 01:19:26,610
is actually three hundred sixty minus one because in this century because the kernel matrix

1331
01:19:27,030 --> 01:19:27,990
is full rank

1332
01:19:29,280 --> 01:19:30,570
so actually when you do they

1333
01:19:31,380 --> 01:19:37,170
i can decomposition on this you'll find that it's dimensionality is not dimensionality expansion here

1334
01:19:37,170 --> 01:19:39,970
because we've got three six thousand three thousand six hundred

1335
01:19:40,680 --> 01:19:44,490
input dimensions going down for three hundred sixty dimensional data space but if you have

1336
01:19:44,490 --> 01:19:46,090
three data points it would still be

1337
01:19:47,180 --> 01:19:48,950
three there so if you had if u

1338
01:19:49,530 --> 01:19:54,220
so if you had five features in the data it would still be a three hundred sixty dimensional data space

1339
01:19:55,050 --> 01:19:59,240
so can appreciate is actually doing something different what it's doing is feature extraction

1340
01:20:00,140 --> 01:20:05,010
and it's mapping data to a high-dimensional data space certainly with this covariance function hand

1341
01:20:05,110 --> 01:20:09,050
because the way these functions are set up with pretty much any covariance function you

1342
01:20:09,050 --> 01:20:13,490
can think of which is the true covariance function we start making these things matrices

1343
01:20:13,490 --> 01:20:15,660
as we'll see later not covariance functions

1344
01:20:16,760 --> 01:20:17,390
things change

1345
01:20:18,990 --> 01:20:22,180
in this case you doing dimensionality expansion

1346
01:20:23,530 --> 01:20:26,140
and this is the result of embeddings this is the classic

1347
01:20:26,890 --> 01:20:30,550
i think this is what john platt once i need to ask john plant about

1348
01:20:30,550 --> 01:20:33,910
this but before i understood this effect well

1349
01:20:35,590 --> 01:20:39,890
john flowers saying i think he's dealing with salt taffy effect like sort of effect

1350
01:20:40,120 --> 01:20:44,820
i said he said well you know where where the arms and the embedding get

1351
01:20:44,820 --> 01:20:47,590
pulled out because of happy there any americans here

1352
01:20:49,030 --> 01:20:50,820
explain what sell taffy how you make it

1353
01:20:52,030 --> 01:20:53,890
you pull it so some sort of e

1354
01:20:54,990 --> 01:20:56,820
you pull it may still the seaside

1355
01:20:58,470 --> 01:21:00,490
so you pull salt happy to make the

1356
01:21:00,990 --> 01:21:04,700
o thing you're pulling it all strings out so this is all taffy effect

1357
01:21:06,380 --> 01:21:10,620
and why they doing now because okay these data points are actually similar because they're

1358
01:21:10,620 --> 01:21:14,840
that this as we go around this thing here we're going around the rotation and

1359
01:21:14,860 --> 01:21:15,990
the rotated sixes

1360
01:21:16,470 --> 01:21:20,010
so these guys are actually similar they're not embedded queries to apart

1361
01:21:20,490 --> 01:21:23,300
but this guy is trying to be square root apart from this guy

1362
01:21:23,820 --> 01:21:26,840
i'm going to pass from this guy and so on and so forth so the

1363
01:21:26,840 --> 01:21:28,160
way you tend do there is you go

1364
01:21:28,800 --> 01:21:32,550
in and out of dimensions your neighbors the ones who are genuinely close u

1365
01:21:33,360 --> 01:21:36,610
you stay close to them so when you look at this embedding in all its

1366
01:21:36,610 --> 01:21:40,680
dimensions it just keeps going out this is the angle between these is about ninety

1367
01:21:40,680 --> 01:21:45,490
degrees it goes and same here same here so goes out and back and back

1368
01:21:45,680 --> 01:21:46,760
and a ninety degree angle

1369
01:21:47,180 --> 01:21:50,570
and the fact that these things are sort the length one keeps everything swearing too far

1370
01:21:53,050 --> 01:21:56,280
but each of these things can actually be seen as an dimensionality

1371
01:21:56,880 --> 01:22:02,320
reduction this is a dimensionality risk expansion and you can visualize what these basic features are

1372
01:22:02,860 --> 01:22:04,880
and they're like features all the six

1373
01:22:05,260 --> 01:22:09,860
this one may be responding to the tail being at the top you that's all

1374
01:22:10,280 --> 01:22:14,340
so you've got all these features the six coming on a different time and so

1375
01:22:14,340 --> 01:22:18,410
is a feature extraction methods that you can do good classification and something people used

1376
01:22:18,410 --> 01:22:23,030
to do we can appreciate it you can appreciate and into linear classifiers and other

1377
01:22:23,030 --> 01:22:27,240
way of getting a nonlinear classifier but it's not a dimensionality reduction technique and just

1378
01:22:27,300 --> 01:22:30,550
show you give visualization about shape i've sort of

1379
01:22:30,990 --> 01:22:32,910
but a couple of random permutations on it

1380
01:22:34,280 --> 01:22:35,930
other any questions about back

1381
01:22:42,550 --> 01:22:43,220
well is

1382
01:22:44,760 --> 01:22:45,590
and he said

1383
01:22:58,640 --> 01:22:59,820
you could do you

1384
01:23:02,640 --> 01:23:05,740
and now makes you it doesn't make any difference on a computer with infinite precision

1385
01:23:07,610 --> 01:23:10,200
i don't think it doesn't matter if you're right you should

1386
01:23:11,680 --> 01:23:12,610
so it shouldn't

1387
01:23:14,220 --> 01:23:17,930
you should use your right that you should try and normalized data in order to

1388
01:23:17,930 --> 01:23:22,090
keep the computer operating in the regime where it's got most precision but i mean

1389
01:23:22,090 --> 01:23:23,180
for this example it doesn't

1390
01:23:24,070 --> 01:23:24,970
make that much difference

1391
01:23:29,800 --> 01:23:30,820
that's can appreciate

1392
01:23:31,970 --> 01:23:33,970
hi excellent just arrived she

1393
01:23:35,240 --> 01:23:36,380
don't tell them what i said

1394
01:23:42,910 --> 01:23:46,720
what i wanna do next is talk about spectral techniques

1395
01:23:47,340 --> 01:23:50,010
i got so ten minutes before i to the break so we'll see for how

1396
01:23:50,010 --> 01:23:53,410
far i get through these examples but be um

1397
01:23:53,780 --> 01:23:59,050
spectral approach dimensionality reduction the first example that in machine learning is canopy piece see

1398
01:24:01,640 --> 01:24:06,180
but the way these other techniques are quite well known isomap locally linear embeddings the

1399
01:24:06,220 --> 01:24:09,450
question i can maps maximum variance unfolding operator is

1400
01:24:10,030 --> 01:24:15,990
somewhat different to you and they do leads to a reduced dimensional representation rather than this expanded

1401
01:24:17,380 --> 01:24:17,860
feature set

1402
01:24:19,450 --> 01:24:20,740
so my favorite example

1403
01:24:21,180 --> 01:24:24,320
start with is classical multidimensional scaling so

1404
01:24:24,760 --> 01:24:27,180
again that's just a review of the sea and stuff

1405
01:24:27,930 --> 01:24:34,070
what i want to do is talk about isomap because i be really closely related to that's city distance example

1406
01:24:35,010 --> 01:24:36,740
so in the city distance example

1407
01:24:37,160 --> 01:24:38,970
we computed the distance between

1408
01:24:40,340 --> 01:24:41,090
all on

1409
01:24:41,780 --> 01:24:47,200
the cities in europe the forty eight that we had and we did classical multidimensional scaling on the

1410
01:24:48,070 --> 01:24:49,360
resulting distance matrix

1411
01:24:49,360 --> 01:24:51,230
and do lots and lots of things in between

1412
01:24:51,270 --> 01:24:55,930
so this is a list of the but all the characteristic length scale that here

1413
01:24:56,070 --> 01:24:58,590
things start to happen in function

1414
01:24:58,640 --> 01:25:02,140
so now we can see that we can all get if we use the modelling

1415
01:25:02,140 --> 01:25:07,330
scales then we have functions that are very much more rapidly

1416
01:25:07,350 --> 01:25:11,050
and if we choose one small in scale and one large lengthscale

1417
01:25:11,090 --> 01:25:13,010
you can see we have a function that varies

1418
01:25:13,060 --> 01:25:18,320
very rapidly as a function of this terrible and only slowly the variable

1419
01:25:18,370 --> 01:25:22,480
OK so this is a very useful effect sometimes called a rt

1420
01:25:22,550 --> 01:25:24,370
automatic relevance determination

1421
01:25:24,430 --> 01:25:26,560
so imagine a regression task

1422
01:25:26,600 --> 01:25:29,890
we have a bunch of input but you don't actually know exactly which of these

1423
01:25:29,890 --> 01:25:35,060
were inputs might be relevant to your prediction which might not

1424
01:25:35,100 --> 01:25:38,720
one way of addressing that problem would be to say well let's try to use

1425
01:25:38,720 --> 01:25:43,660
this kind of red function let's try to learn the length scale parameter by optimizing

1426
01:25:44,340 --> 01:25:45,980
marginal likelihood

1427
01:25:45,980 --> 01:25:49,720
and it happens that some of the links parameters go to very large very large

1428
01:25:50,850 --> 01:25:54,750
that corresponds to the function being insensitive to the exact same thing

1429
01:25:55,750 --> 01:25:59,120
both particularly those at the corner of the input

1430
01:25:59,180 --> 01:26:03,230
that correspond to that input being ignored

1431
01:26:03,230 --> 01:26:06,310
conversely if the but if the value of the

1432
01:26:06,540 --> 01:26:10,520
link for particular input it's very small this saying all

1433
01:26:10,560 --> 01:26:13,860
one of the function seems to to be extremely sensitive to the exact value of

1434
01:26:14,530 --> 01:26:15,790
the from

1435
01:26:15,860 --> 01:26:18,090
by doing that you can learn about

1436
01:26:18,150 --> 01:26:20,730
and then what you're trying to model then you look at the height of the

1437
01:26:20,730 --> 01:26:23,640
the length scale parameter they all you know

1438
01:26:23,650 --> 01:26:30,180
variable number sixteen increase a very very important and these five variables they happen you

1439
01:26:30,180 --> 01:26:32,230
know not have much

1440
01:26:32,230 --> 01:26:33,540
this is an example

1441
01:26:33,550 --> 01:26:35,110
of how you can

1442
01:26:35,180 --> 01:26:38,650
use the your understanding of the properties of the function

1443
01:26:38,660 --> 01:26:40,790
how that depends on the parameters

1444
01:26:40,830 --> 01:26:46,770
but you learn something about the property of the data

1445
01:26:46,950 --> 01:26:53,580
let's look at some other end so there lots of covariance function

1446
01:26:53,670 --> 01:26:59,250
so in the in the kernel machine literature usually use the gaussians in

1447
01:26:59,290 --> 01:27:02,070
kernel function of the polynomial kernel

1448
01:27:02,120 --> 01:27:06,610
actually lots and lots of of possibilities out there and some of them have

1449
01:27:06,660 --> 01:27:11,180
give rise to function interesting properties just list the few here

1450
01:27:11,200 --> 01:27:15,350
not any function can be chosen to be correct because remember

1451
01:27:15,400 --> 01:27:16,750
when you

1452
01:27:16,790 --> 01:27:19,940
when you write down the covariances

1453
01:27:19,990 --> 01:27:22,320
you have to get the matrix which is which

1454
01:27:22,370 --> 01:27:26,520
which is going to be used as the covariance of these scouts variables

1455
01:27:26,520 --> 01:27:29,420
and covariance pages have to be positive definite

1456
01:27:29,440 --> 01:27:32,030
or they can have negative eigenvalues

1457
01:27:32,670 --> 01:27:34,650
so these functions have the property

1458
01:27:34,670 --> 01:27:40,400
the call positive definite functions functions that have no matter what values of x i

1459
01:27:40,400 --> 01:27:44,050
chose the the covariance matrix must be

1460
01:27:44,080 --> 01:27:45,840
you must have known by

1461
01:27:45,900 --> 01:27:49,390
let's put some restrictions on the

1462
01:27:49,450 --> 01:27:50,790
on the ground

1463
01:27:50,810 --> 01:27:55,240
here's an article they the rational quadratic

1464
01:27:55,440 --> 01:27:56,730
covariance function

1465
01:27:56,840 --> 01:27:59,910
are here is is just the difference of x x prime

1466
01:28:01,920 --> 01:28:06,280
covariance functions that only depend on the difference between x and x prime of stationary

1467
01:28:06,340 --> 01:28:08,670
around because the covariances

1468
01:28:08,680 --> 01:28:12,270
don't depend on the absolute location o x will depend on the data on the

1469
01:28:12,830 --> 01:28:14,160
that means that

1470
01:28:14,220 --> 01:28:19,940
statistically the function looks the same all over the place

1471
01:28:20,420 --> 01:28:26,830
so the russian rather function looks like this would again be this square

1472
01:28:26,870 --> 01:28:31,560
divided by the length scale here we had one that raises some

1473
01:28:31,560 --> 01:28:33,920
power out there

1474
01:28:33,950 --> 01:28:34,880
one way of of

1475
01:28:34,890 --> 01:28:37,280
constructing a rational quadratic

1476
01:28:37,790 --> 01:28:41,290
covariance function is to start off with

1477
01:28:41,300 --> 01:28:43,050
the squared exponential

1478
01:28:43,060 --> 01:28:45,570
one function or gas in various functions

1479
01:28:45,580 --> 01:28:50,410
and then they look at large massacre in functions with a particular

1480
01:28:50,880 --> 01:28:52,870
values of the length scale

1481
01:28:52,930 --> 01:28:55,740
and then some together or integrate together

1482
01:28:55,830 --> 01:28:58,590
covariance functions with different length scales

1483
01:28:58,650 --> 01:29:00,390
OK and if you choose this

1484
01:29:00,400 --> 01:29:04,430
distribution over length scales are

1485
01:29:04,450 --> 01:29:08,310
the the inverse of the square scale

1486
01:29:08,380 --> 01:29:10,450
the ballot form here

1487
01:29:10,470 --> 01:29:16,350
then you get an interval cannot be solved you get this particular function

1488
01:29:16,480 --> 01:29:21,100
this kernel function of the brain functions embed somehow the idea that

1489
01:29:21,120 --> 01:29:26,900
the covariances act like a mixture of gaussians with different scales

1490
01:29:27,140 --> 01:29:31,580
so you don't have just one lengthscale signal is not expected just one link but

1491
01:29:31,580 --> 01:29:33,120
it expected to have

1492
01:29:33,180 --> 01:29:36,510
a different range of length scales that added together

1493
01:29:36,510 --> 01:29:42,280
and what the actual range is depends on the parameters of the distribution

1494
01:29:42,330 --> 01:29:45,220
OK so i show up

1495
01:29:45,240 --> 01:29:47,230
airport what the

1496
01:29:47,740 --> 01:29:51,130
what those what that covariance function looks like so just

1497
01:29:51,310 --> 01:29:55,840
the covariance the value of k here is just the function of the this part

1498
01:29:55,840 --> 01:29:57,270
of this

1499
01:29:57,270 --> 01:30:03,480
part of this and three different values alpha now this function has one extra problem

1500
01:30:03,490 --> 01:30:07,980
as alpha goes to infinity you get back the squared exponential growth

1501
01:30:08,020 --> 01:30:09,810
that's what i think we have

1502
01:30:09,850 --> 01:30:13,910
if alpha is about tool and you get this function

1503
01:30:13,920 --> 01:30:17,350
and the smaller value function here

1504
01:30:17,370 --> 01:30:19,400
you can sort of see that small

1505
01:30:19,490 --> 01:30:23,500
function our together different kinds of links

1506
01:30:23,590 --> 01:30:28,000
let's that will function so here again i drawn three random

1507
01:30:28,050 --> 01:30:31,220
that's all from account of this

1508
01:30:31,230 --> 01:30:34,810
function and the color the colour coding same

1509
01:30:34,820 --> 01:30:38,540
so the the green line here for four

1510
01:30:38,680 --> 01:30:39,690
the gulf

1511
01:30:39,730 --> 01:30:40,610
because see we

1512
01:30:40,610 --> 01:30:42,920
c square you know g you can look up

1513
01:30:42,920 --> 01:30:46,800
and so we find that the radius is about one centimeter

1514
01:30:46,900 --> 01:30:50,820
so if you could squeeze the first which is present radius of six thousand four

1515
01:30:50,820 --> 01:30:55,920
hundred kilometres if you could squeeze into one centimeter then you would have created a

1516
01:30:55,920 --> 01:30:57,320
black hole but of course

1517
01:30:58,210 --> 01:31:00,980
problematic to do that

1518
01:31:01,030 --> 01:31:03,570
if you take the sum

1519
01:31:03,610 --> 01:31:05,500
which by definition

1520
01:31:05,570 --> 01:31:08,920
there's one solar mass so you put in you the mass of the sun which

1521
01:31:08,920 --> 01:31:10,650
you can look up in your book

1522
01:31:10,710 --> 01:31:12,190
then you will find that the

1523
01:31:12,230 --> 01:31:16,250
radius of the event horizon is three kilometres

1524
01:31:16,300 --> 01:31:21,630
if you take a five solar mass black hole

1525
01:31:21,670 --> 01:31:25,110
there you will find that the radius of the event horizon

1526
01:31:25,130 --> 01:31:26,940
it is fifteen kilometres

1527
01:31:26,980 --> 01:31:29,570
notice it scales linearly with m

1528
01:31:29,630 --> 01:31:32,790
that's what you see here is linearly upstairs

1529
01:31:32,790 --> 01:31:34,710
so if you go from one solar mass

1530
01:31:34,730 --> 01:31:36,190
two five solar masses

1531
01:31:36,210 --> 01:31:38,300
the radius of the event horizon

1532
01:31:38,300 --> 01:31:42,340
scales linearly

1533
01:31:42,420 --> 01:31:45,980
in nineteen seventy one

1534
01:31:46,000 --> 01:31:48,800
astronomers stumbled

1535
01:31:48,800 --> 01:31:52,030
and merlin investor

1536
01:31:52,050 --> 01:31:54,210
king was the daring statement

1537
01:31:54,250 --> 01:31:56,730
that one of these systems

1538
01:31:56,790 --> 01:31:59,670
was the black hole binary

1539
01:31:59,690 --> 01:32:02,710
they looked at the spectrum of the donor

1540
01:32:02,770 --> 01:32:08,360
and they concluded that it probably wasn't twenty thirty mass solar star

1541
01:32:08,420 --> 01:32:09,770
and then they made the

1542
01:32:09,820 --> 01:32:14,550
but the shift measurements of the absorption lines in the spectrum of the donor

1543
01:32:14,570 --> 01:32:17,170
and so they went exactly sort of reasoning

1544
01:32:17,170 --> 01:32:20,500
that i showed you earlier which i think has been raised now

1545
01:32:20,550 --> 01:32:22,290
and they came up with the facts

1546
01:32:22,290 --> 01:32:24,340
that the creator

1547
01:32:24,420 --> 01:32:25,550
had to mass

1548
01:32:25,570 --> 01:32:26,650
of about

1549
01:32:26,670 --> 01:32:28,440
fifteen solar masses

1550
01:32:28,460 --> 01:32:30,520
so they came to the conclusion

1551
01:32:30,530 --> 01:32:33,210
that since it was an x-ray source u

1552
01:32:33,250 --> 01:32:37,130
that the creator was very small otherwise you couldn't get these high temperatures in the

1553
01:32:38,090 --> 01:32:43,500
so they made a daring statements that you created was probably a black hole

1554
01:32:43,550 --> 01:32:47,590
this had an enormous impact on the astronomical community

1555
01:32:47,630 --> 01:32:50,920
and a lot of people emotionally couldn't handle it

1556
01:32:51,000 --> 01:32:53,210
and there are lots of publications

1557
01:32:53,210 --> 01:32:57,340
four years to come arguing that it was all nonsense the black holes didn't exist

1558
01:32:57,500 --> 01:33:02,190
the data was misinterpreted the k was all kinds of other weird explanations

1559
01:33:02,960 --> 01:33:04,880
the black hole

1560
01:33:04,880 --> 01:33:06,940
still stands and

1561
01:33:06,980 --> 01:33:09,250
most same astronomers

1562
01:33:09,290 --> 01:33:12,840
that doesn't mean that all astronomers the saying but most saying astronomers

1563
01:33:12,880 --> 01:33:15,000
the believe that sickness x one

1564
01:33:15,320 --> 01:33:18,840
is a black hole and we now know of about two dozen of these systems

1565
01:33:18,900 --> 01:33:20,610
web idea creator

1566
01:33:20,630 --> 01:33:21,940
it's a black hole

1567
01:33:21,960 --> 01:33:25,840
and i decided to make sigma x one part of your problem set

1568
01:33:25,860 --> 01:33:27,420
so you have some

1569
01:33:27,480 --> 01:33:29,960
time to wrestle was it

1570
01:33:29,960 --> 01:33:33,480
i wanted to see a picture of sickness x one it is

1571
01:33:33,530 --> 01:33:35,130
not very

1572
01:33:35,130 --> 01:33:39,840
dramatic but i wanted to see it for emotional reasons you will just see star

1573
01:33:39,860 --> 01:33:41,880
you can see the black hole

1574
01:33:42,020 --> 01:33:45,150
just is star and that's all

1575
01:33:45,170 --> 01:33:47,880
but at least you can tell your parents that

1576
01:33:47,900 --> 01:33:50,690
we've seen it started is in orbit with the black hole

1577
01:33:50,710 --> 01:33:52,480
so if we can

1578
01:33:52,500 --> 01:33:54,420
get the first slide

1579
01:33:54,480 --> 01:33:57,690
the only slide i think i have

1580
01:33:57,730 --> 01:33:59,170
and we should be able

1581
01:33:59,190 --> 01:34:01,030
the show you a

1582
01:34:02,480 --> 01:34:06,230
it's the negative in astronomy we almost always work with negatives

1583
01:34:06,250 --> 01:34:09,770
so the cars the stars itself blackened the sky is white

1584
01:34:09,820 --> 01:34:12,210
and it is this star here

1585
01:34:12,210 --> 01:34:13,750
that is the

1586
01:34:13,800 --> 01:34:14,860
i don't know

1587
01:34:14,900 --> 01:34:18,480
it's quite bright you cannot see with naked eye for those of you are familiar

1588
01:34:18,480 --> 01:34:21,820
with magnitudes of stars it's nine magnitude star

1589
01:34:21,900 --> 01:34:25,630
and it is in orbit the black hole itself has a mass of about twenty

1590
01:34:25,630 --> 01:34:28,320
to thirty solar masses and the black hole

1591
01:34:28,400 --> 01:34:31,550
has about a mass of about fifteen so

1592
01:34:31,590 --> 01:34:33,000
and all of this

1593
01:34:33,050 --> 01:34:35,570
is the result of doppler shift measurements

1594
01:34:35,590 --> 01:34:39,020
profound far-reaching consequences

1595
01:34:39,020 --> 01:34:42,070
i think it is a wonderful moment to have a break

1596
01:34:42,170 --> 01:34:45,980
and i know that most of UK here not to listen to my lecture but

1597
01:34:45,980 --> 01:34:47,710
to take the the chris

1598
01:34:47,730 --> 01:34:48,480
and so

1599
01:34:48,480 --> 01:34:51,020
let's do that now then

1600
01:34:51,030 --> 01:35:00,750
so if you can help handing these out

1601
01:35:00,750 --> 01:35:09,320
for those of you

1602
01:35:09,320 --> 01:35:13,070
who come only forty many quiz i have some advice

1603
01:35:13,130 --> 01:35:14,690
you may have noticed

1604
01:35:14,710 --> 01:35:20,050
the question that i ask on the many queries on tuesday almost always goes back

1605
01:35:20,050 --> 01:35:21,920
to the previous lecture on thursday

1606
01:35:21,980 --> 01:35:23,550
think about that

1607
01:35:24,420 --> 01:35:27,460
so if you can help me handing these out

1608
01:35:28,210 --> 01:35:31,790
the biggest impact

1609
01:35:31,790 --> 01:35:35,910
is that it allows very simply to assess the what we call the goodness of

1610
01:35:35,910 --> 01:35:40,370
fit that is to say you can make some quantitative statement as to how well

1611
01:35:40,390 --> 01:35:42,520
the curve passes through the points

1612
01:35:42,540 --> 01:35:46,040
you can imagine a situation if i go back here

1613
01:35:46,060 --> 01:35:47,870
what's wrong way

1614
01:35:49,910 --> 01:35:52,500
it these are my data points

1615
01:35:52,600 --> 01:35:57,430
but this horizontal curves no matter what value y pick it simply doesn't describe the

1616
01:35:57,430 --> 01:36:01,520
data very well it doesn't have a very good goodness of fit whereas this line

1617
01:36:01,520 --> 01:36:06,620
with slope seems to describe the data better how can i quantify that

1618
01:36:06,640 --> 01:36:10,410
all the way that you can quantify is by simply using the

1619
01:36:10,430 --> 01:36:14,580
the value of the numerical value of the consequent function at its minimum

1620
01:36:14,600 --> 01:36:18,350
because if you look at this function what does it represents it represents the measured

1621
01:36:18,350 --> 01:36:20,950
value minus the fitted values

1622
01:36:20,960 --> 01:36:24,350
divided by the standard deviation the whole thing squared

1623
01:36:24,370 --> 01:36:27,430
so you can imagine that if the model is good

1624
01:36:27,450 --> 01:36:31,460
if the model this is the correct model you would expect the typical difference between

1625
01:36:31,460 --> 01:36:32,660
the measured values

1626
01:36:32,680 --> 01:36:35,950
and the predictive value to be on the order of

1627
01:36:35,960 --> 01:36:40,120
the standard deviation roughly the same size as there are and so you would expect

1628
01:36:40,120 --> 01:36:42,080
the contribution roughly one

1629
01:36:42,100 --> 01:36:43,640
per data point

1630
01:36:43,680 --> 01:36:47,830
whereas if you have a very large discrepancies between the measurements in the predicted value

1631
01:36:47,850 --> 01:36:51,040
we get some numbers bigger than one

1632
01:36:51,060 --> 01:36:52,980
now what you can show

1633
01:36:53,000 --> 01:36:55,640
is that if the hypothesis is correct

1634
01:36:55,660 --> 01:36:59,460
then this statistic the function of the data

1635
01:36:59,480 --> 01:37:05,520
under the assumption that the hypothesis is correct then it will fall archives squared distribution

1636
01:37:05,540 --> 01:37:08,930
that is to say this is the distribution that we saw i think on the

1637
01:37:08,930 --> 01:37:10,020
second day

1638
01:37:10,080 --> 01:37:13,710
so this is the case for distribution for a certain number of degrees of freedom

1639
01:37:14,180 --> 01:37:16,960
and the appropriate number of degrees of freedom in this case

1640
01:37:16,980 --> 01:37:19,120
is equal to the number of data points

1641
01:37:19,120 --> 01:37:21,960
minus the number of fitted parameters

1642
01:37:21,980 --> 01:37:24,870
so you can simply use

1643
01:37:25,310 --> 01:37:29,520
those features in order to compute a p value

1644
01:37:31,060 --> 01:37:34,600
quantify the level of agreement between measuring points

1645
01:37:34,600 --> 01:37:37,060
and the hypothesized functional form

1646
01:37:37,080 --> 01:37:39,190
of the current you're trying to fit

1647
01:37:39,210 --> 01:37:40,350
that is to say

1648
01:37:40,350 --> 01:37:42,040
you can compute the probability

1649
01:37:42,060 --> 01:37:44,540
to get a case where mean value

1650
01:37:44,560 --> 01:37:46,060
as large as you've got

1651
01:37:46,080 --> 01:37:47,230
or larger

1652
01:37:47,250 --> 01:37:51,430
because of course the larger the value of course would mean that means you have

1653
01:37:51,480 --> 01:37:52,870
worse agreement

1654
01:37:52,890 --> 01:37:57,410
between the data and the hypothesized functional form

1655
01:37:57,960 --> 01:38:01,830
so in the previous example with this first of all first order polynomial

1656
01:38:01,830 --> 01:38:03,890
that is to say that was the

1657
01:38:03,910 --> 01:38:05,180
straight line with with

1658
01:38:05,980 --> 01:38:09,620
it happened to give the mean of three point nine nine

1659
01:38:09,660 --> 01:38:15,140
there were five data points and two adjustable parameters the offset slope

1660
01:38:15,160 --> 01:38:17,140
so that means three degrees of freedom

1661
01:38:17,160 --> 01:38:19,060
so if i put three in there

1662
01:38:19,080 --> 01:38:25,120
integrate the cascade distribution from that value to infinity and i get p value of

1663
01:38:25,140 --> 01:38:27,180
o point two six three

1664
01:38:27,230 --> 01:38:32,160
moderately large values that means that if that hypothesis is correct

1665
01:38:32,190 --> 01:38:37,230
there's twenty six point three percent chance of getting a crisp value that high

1666
01:38:37,270 --> 01:38:38,330
or higher

1667
01:38:38,350 --> 01:38:41,790
now it it will typically be regarded as has an acceptable

1668
01:38:41,810 --> 01:38:44,350
level of goodness of fit

1669
01:38:44,370 --> 01:38:48,370
on the other hand if you consider the zeroth order polynomial that was that was

1670
01:38:48,370 --> 01:38:52,770
on the line that had high square value of its and its minimum of forty

1671
01:38:52,770 --> 01:38:54,410
five point five

1672
01:38:54,430 --> 01:38:58,390
that the number of degrees of freedom is in five points minus one free parameters

1673
01:38:59,210 --> 01:39:03,750
so i put four in there and integrate from forty five point five

1674
01:39:03,770 --> 01:39:07,430
to infinity and i get three times ten to the minus nine

1675
01:39:07,580 --> 01:39:09,580
so of course it's possible that

1676
01:39:09,620 --> 01:39:14,960
the hypothesis of horizontal line is correct but if you were correct you would expect

1677
01:39:14,960 --> 01:39:16,620
to get high scrap value

1678
01:39:16,640 --> 01:39:18,620
that high or higher

1679
01:39:18,640 --> 01:39:21,790
only with the probability three times ten to the minus nine

1680
01:39:21,830 --> 01:39:25,250
so that would that would be regarded as you probably say well that's unlikely to

1681
01:39:25,250 --> 01:39:30,790
therefore the horizontal line hypothesis is strongly disfavored

1682
01:39:30,810 --> 01:39:34,020
OK so fine running out of time so i want to get to a final

1683
01:39:34,870 --> 01:39:38,330
so that was all i wanted to say about parameter estimation that's certainly a very

1684
01:39:38,330 --> 01:39:43,000
important part of statistical analysis but there's one other aspect of

1685
01:39:43,000 --> 01:39:44,410
parameter estimation

1686
01:39:46,000 --> 01:39:51,080
in addition to getting actual numerical value for the parameter sometimes if it's important to

1687
01:39:52,350 --> 01:39:53,580
an interval

1688
01:39:53,580 --> 01:39:57,930
which will bracket a parameter with a certain probability

1689
01:39:57,980 --> 01:39:59,290
and that boils down to

1690
01:39:59,730 --> 01:40:03,580
in particle physics very often setting limits

1691
01:40:03,580 --> 01:40:04,520
such that

1692
01:40:04,530 --> 01:40:06,320
you can just imagine

1693
01:40:07,760 --> 01:40:10,990
one the this so

1694
01:40:11,000 --> 01:40:14,320
you created this gives you is one of the

1695
01:40:15,380 --> 01:40:22,690
this the slide official stated data mining problem usually computation is additional to

1696
01:40:23,440 --> 01:40:28,870
function and its competes smooth with nice of course you can so function any

1697
01:40:30,470 --> 01:40:33,780
so you should computations

1698
01:40:33,860 --> 01:40:36,950
but this is just an illustration of what's going on so what we see is

1699
01:40:36,950 --> 01:40:40,390
just the different colours is that this is

1700
01:40:40,490 --> 01:40:43,080
so the area that this

1701
01:40:43,140 --> 01:40:47,800
the more you get that a lot of money is the crosses

1702
01:40:47,870 --> 01:40:51,680
and this some here the parameters x one x are correlated

1703
01:40:51,680 --> 01:40:53,160
you can see that

1704
01:40:53,210 --> 01:40:56,530
like you know that's going like this

1705
01:40:56,560 --> 01:40:59,790
the landscape towards the development of these yellow here

1706
01:40:59,910 --> 01:41:03,980
these individuals not as we have genetic diagram here

1707
01:41:03,990 --> 01:41:06,970
that's patients

1708
01:41:07,000 --> 01:41:09,510
coming from a mutation crossover

1709
01:41:09,560 --> 01:41:14,210
this is place you want to use

1710
01:41:14,320 --> 01:41:15,080
is design

1711
01:41:15,090 --> 01:41:20,730
the global optimum which is this the best thing to do

1712
01:41:20,850 --> 01:41:23,440
comes close to me

1713
01:41:23,490 --> 01:41:29,080
since the accuracy of the we already talking about

1714
01:41:29,090 --> 01:41:32,700
generation one thousand four hundred one hundred individuals you

1715
01:41:32,740 --> 01:41:34,530
but there's not really much call

1716
01:41:34,560 --> 01:41:35,120
any more

1717
01:41:35,140 --> 01:41:41,100
so we are quite stuck this part of course asking for your results in some

1718
01:41:41,100 --> 01:41:46,020
cases of course such as the results i can also tell you about this kind

1719
01:41:46,020 --> 01:41:51,510
of you it's a very simple simplistic implementation but can do horrible things GA's choosing

1720
01:41:51,520 --> 01:41:54,610
the wrong operators which is the parameters to tune

1721
01:41:54,720 --> 01:41:58,660
this kind of classic GHT

1722
01:41:59,860 --> 01:42:04,710
we're not going to make it work very nicely in most cases

1723
01:42:04,740 --> 01:42:07,630
one the features of this problem is not very successful

1724
01:42:07,710 --> 01:42:12,740
it's c so one of the problems in genetic algorithms as well as well as

1725
01:42:12,740 --> 01:42:15,460
what musicians you have to do usually love of gravity before

1726
01:42:15,540 --> 01:42:17,280
that's what was on

1727
01:42:17,320 --> 01:42:22,000
of course because there are many problems you don't know the last but the optimisation

1728
01:42:22,000 --> 01:42:27,350
problem looks like what kind of characteristics we cannot afford to make a time prematurely

1729
01:42:27,460 --> 01:42:31,740
so that's definitely we use the difference in genetic changes

1730
01:42:33,370 --> 01:42:35,360
so my favourite algorithm

1731
01:42:35,530 --> 01:42:39,120
it's good for a moment p is also demonstrate D's

1732
01:42:39,140 --> 01:42:42,320
he hardly requires an inference we get all

1733
01:42:42,330 --> 01:42:45,960
and actually to my surprise i figured out that with one set

1734
01:42:46,010 --> 01:42:49,930
of parameters that find this you can take really

1735
01:42:49,940 --> 01:42:54,480
it used to define america problem by saying is what he does for you

1736
01:42:54,550 --> 01:42:57,300
and it looks like she is very sweet

1737
01:42:58,820 --> 01:43:01,940
exactly what you see

1738
01:43:02,040 --> 01:43:08,190
global optimum problem the funny usually hates make sort of online demonstrations of the program

1739
01:43:08,190 --> 01:43:12,090
surely the representation because you should never works the more you try to demonstrate that

1740
01:43:12,090 --> 01:43:17,300
d i can tell you this is no experimental random solutions generated a community sure

1741
01:43:17,330 --> 01:43:22,280
it will give me the result want to demonstrate absolutely fascinating so if we do

1742
01:43:22,280 --> 01:43:25,580
a little bit back in time here

1743
01:43:25,600 --> 01:43:28,580
just recalled this

1744
01:43:28,640 --> 01:43:31,050
i'm sure this again

1745
01:43:32,080 --> 01:43:34,800
you can see that after a few iterations

1746
01:43:34,810 --> 01:43:40,360
and why he chose parameters according to actually it turns out he is particularly useful

1747
01:43:40,520 --> 01:43:44,980
when they have problems we have correlated parameters this is all because this this difference

1748
01:43:49,790 --> 01:43:52,450
a famous a forward comes into the solution

1749
01:43:52,820 --> 01:43:58,190
so you don't have this fuzzy kind of trying to hold monthly meetings around the

1750
01:43:58,190 --> 01:44:03,140
genetic algorithms a lot of exploration always candidate solutions lots of them just to be

1751
01:44:03,140 --> 01:44:04,950
sure what is the dual

1752
01:44:05,050 --> 01:44:09,160
in this case you of course it's useless to have so much random exploration random

1753
01:44:09,160 --> 01:44:10,530
directions because

1754
01:44:10,550 --> 01:44:16,760
this problem is usually more difficult to find the exact location because the coalition parameters

1755
01:44:16,760 --> 01:44:21,410
and those of you that a little bit about the evolutionary computation as evolutionary strategies

1756
01:44:21,410 --> 01:44:26,450
have nice also to solve problems like this and they will find them in problem

1757
01:44:26,510 --> 01:44:31,140
like the two d problem but if you try dimension of a lot problems also

1758
01:44:31,290 --> 01:44:36,970
evolutionary strategies with he these seem to work beautifully also high dimensional problems

1759
01:44:37,000 --> 01:44:41,350
but before i go on the show you just one of example to illustrate that

1760
01:44:41,380 --> 01:44:43,170
because again

1761
01:44:43,970 --> 01:44:46,510
particularly nice again you know

1762
01:44:48,890 --> 01:44:52,290
again this is one of five

1763
01:44:53,960 --> 01:44:59,210
she is actually more like looks like in picture and if you run

1764
01:44:59,220 --> 01:45:00,540
the GA on this

1765
01:45:00,560 --> 01:45:03,210
can see

1766
01:45:03,480 --> 01:45:06,260
one more try

1767
01:45:06,270 --> 01:45:10,250
so it's very site was moved

1768
01:45:10,450 --> 01:45:12,030
all right

1769
01:45:12,960 --> 01:45:14,600
just the opposite action

1770
01:45:17,210 --> 01:45:25,280
and then again a lot of exploration anybody making any particular progress in the field

1771
01:45:25,310 --> 01:45:29,990
there was no way with minus thirteen

1772
01:45:30,000 --> 01:45:32,470
let me just show you one

1773
01:45:32,480 --> 01:45:34,850
the good old

1774
01:45:34,870 --> 01:45:38,050
particle swarm optimization would do with this pattern small

1775
01:45:38,060 --> 01:45:39,050
quite fine

1776
01:45:39,070 --> 01:45:45,320
when you use fact these parameters for these weights how much of the action

1777
01:45:45,970 --> 01:45:48,540
but it's is also quite sensitive especially if

1778
01:45:48,550 --> 01:45:51,880
the problem is very much more like this one

1779
01:45:51,890 --> 01:45:53,370
some problems

1780
01:45:53,390 --> 01:45:56,500
we find that acceptable like in this case

1781
01:45:56,570 --> 01:46:00,120
but the problem with this motivation because of the way

1782
01:46:00,200 --> 01:46:03,540
and the sometimes works and sometimes it doesn't

1783
01:46:03,600 --> 01:46:08,040
in this case was find people like to see

1784
01:46:08,050 --> 01:46:10,510
but this time because he said

1785
01:46:10,660 --> 01:46:12,230
local optimum

1786
01:46:12,600 --> 01:46:15,970
there is another this morning

1787
01:46:16,020 --> 01:46:20,050
so this is the classic implementation of particle swarm optimization of course you can find

1788
01:46:20,050 --> 01:46:25,100
extensions so i can get a lot of parameter tuning difficult to get anywhere but

1789
01:46:25,630 --> 01:46:27,830
let me show you what he does for you

1790
01:46:27,840 --> 01:46:29,500
because again this is

1791
01:46:29,540 --> 01:46:33,260
it's actually very impressive

1792
01:46:33,300 --> 01:46:36,460
run differential evolution on this slide seven of this

1793
01:46:36,620 --> 01:46:41,620
OK i don't think tank with best solutions to clients states the

1794
01:46:41,910 --> 01:46:43,990
this is

1795
01:46:44,090 --> 01:46:47,860
if the jump right into the middle as if the

1796
01:46:47,950 --> 01:46:51,020
is if the algorithm would have an idea where the ottomans waiting

1797
01:46:51,180 --> 01:46:52,380
so the only

1798
01:46:52,540 --> 01:46:58,300
trying to capture the science because of course because it is symmetric

1799
01:46:58,310 --> 01:47:02,430
all these problems are symmetric consolidating

1800
01:47:02,440 --> 01:47:06,520
but still you see the big difference in between the g p the

1801
01:47:06,560 --> 01:47:07,970
with he can tell

1802
01:47:09,690 --> 01:47:10,950
the middle

1803
01:47:10,960 --> 01:47:11,890
and again

1804
01:47:12,990 --> 01:47:16,390
so straightforward holes in for the right solution

1805
01:47:17,310 --> 01:47:20,170
just to give you a taste of what the

1806
01:47:20,240 --> 01:47:23,240
is capable of doing for you

1807
01:47:23,410 --> 01:47:29,030
OK now let's see what the boy in the case that we have the following

1808
01:47:29,030 --> 01:47:30,670
going to talk about

1809
01:47:31,750 --> 01:47:34,670
some new concepts

1810
01:47:34,700 --> 01:47:36,260
and that's the concept

1811
01:47:36,300 --> 01:47:41,710
of electrostatic

1812
01:47:45,310 --> 01:47:49,260
potential energy

1813
01:47:49,280 --> 01:47:52,220
for which we will use

1814
01:47:52,300 --> 01:47:54,280
this symbol u

1815
01:47:54,300 --> 01:47:58,220
and independently

1816
01:47:58,240 --> 01:48:00,470
electric potential

1817
01:48:00,470 --> 01:48:05,950
which is very different from which we will use the symbol v

1818
01:48:10,570 --> 01:48:13,300
that i have

1819
01:48:13,400 --> 01:48:15,720
a charge

1820
01:48:15,720 --> 01:48:19,200
q one here

1821
01:48:19,250 --> 01:48:20,430
and that's plus

1822
01:48:20,440 --> 01:48:23,510
plus charge and here I have the charge

1823
01:48:23,550 --> 01:48:27,720
plus q two and they have the distance and distance are apart

1824
01:48:27,730 --> 01:48:31,550
and that is point p

1825
01:48:31,570 --> 01:48:33,060
it's very clear

1826
01:48:33,200 --> 01:48:36,620
thatin order to bring these charges at this distance from each other i had

1827
01:48:36,620 --> 01:48:39,650
to do work to bring them there because they repel each other

1828
01:48:39,700 --> 01:48:41,780
it's like pushing in this spring

1829
01:48:41,840 --> 01:48:45,170
if you release the spring get the energy back if they were

1830
01:48:45,170 --> 01:48:47,500
they were connected with a little string

1831
01:48:47,560 --> 01:48:49,080
string would be stretched

1832
01:48:49,140 --> 01:48:52,670
takesscissorscut the string,they fly apart again

1833
01:48:52,750 --> 01:48:54,230
so i have put work

1834
01:48:54,250 --> 01:48:57,540
in there and that's what we call electrostatic

1835
01:49:01,860 --> 01:49:06,750
so let's work this out in some detail how much work i have to do

1836
01:49:08,720 --> 01:49:11,250
we first put q one year

1837
01:49:11,300 --> 01:49:13,230
ifspace is empty

1838
01:49:13,280 --> 01:49:17,060
this doesn't take any work to place q one here

1839
01:49:17,080 --> 01:49:21,590
but now i come from very far away we always thinkof that asinfinitely far away

1840
01:49:21,610 --> 01:49:25,480
cause that's the exaggeration and we bring this charge q two

1841
01:49:25,500 --> 01:49:26,640
from infinity

1842
01:49:26,640 --> 01:49:28,150
to that point p

1843
01:49:28,170 --> 01:49:30,890
and I Walter Lewin have to do work I have to push

1844
01:49:31,190 --> 01:49:34,830
and push and push and the closer i get the hard i have to push

1845
01:49:34,830 --> 01:49:37,050
and finally i reached that point

1846
01:49:39,460 --> 01:49:41,510
suppose i am here

1847
01:49:41,610 --> 01:49:43,610
and this separation

1848
01:49:45,430 --> 01:49:47,230
I reached that point

1849
01:49:47,290 --> 01:49:49,730
then the force on me

1850
01:49:49,740 --> 01:49:52,130
the electric force is outward

1851
01:49:52,140 --> 01:49:56,960
and so i have to overcome that force

1852
01:49:57,040 --> 01:49:58,670
so my force

1853
01:49:58,680 --> 01:49:59,980
fWalter Lewin

1854
01:49:59,990 --> 01:50:01,730
in in this direction

1855
01:50:01,830 --> 01:50:04,230
so you can seeIdo positive work

1856
01:50:04,270 --> 01:50:05,640
the force and the

1857
01:50:05,660 --> 01:50:12,510
direction in whichI'mmovingare in thesame directionI dopositive work

1858
01:50:13,210 --> 01:50:17,640
the work that i do can be calculated

1859
01:50:17,700 --> 01:50:18,740
the work

1860
01:50:18,760 --> 01:50:21,550
that Walter Lewinis doing

1861
01:50:21,610 --> 01:50:24,040
in going all the way from infinity

1862
01:50:24,050 --> 01:50:26,430
to that location p

1863
01:50:26,460 --> 01:50:27,540
is the integral

1864
01:50:27,540 --> 01:50:30,430
going from an infinity toradiusr

1865
01:50:30,480 --> 01:50:33,010
of the force

1866
01:50:33,050 --> 01:50:34,330
of Walter Lewin

1867
01:50:35,330 --> 01:50:37,740
the r

1868
01:50:37,820 --> 01:50:38,980
but of course

1869
01:50:38,990 --> 01:50:41,540
that work is exactly the same

1870
01:50:41,610 --> 01:50:43,480
you one is fine

1871
01:50:43,540 --> 01:50:44,830
to take

1872
01:50:44,830 --> 01:50:46,330
the electric force

1873
01:50:46,350 --> 01:50:49,830
in going from r to infinity

1874
01:50:49,890 --> 01:50:51,100
doty r

1875
01:50:51,140 --> 01:50:54,380
because the force the electric force in waterloo force i

1876
01:50:54,390 --> 01:50:57,450
the same in magnitude but opposite direction

1877
01:50:57,450 --> 01:51:00,890
so by flipping over going from infinity two are

1878
01:51:00,950 --> 01:51:02,490
two are to infinity

1879
01:51:02,540 --> 01:51:03,450
this is the same

1880
01:51:03,460 --> 01:51:07,330
this one and the same thing

1881
01:51:07,360 --> 01:51:10,670
let's calculate this integral because that's

1882
01:51:10,680 --> 01:51:11,740
louise easy

1883
01:51:11,760 --> 01:51:14,290
we know what the electric force this

1884
01:51:14,330 --> 01:51:15,540
school of law

1885
01:51:15,550 --> 01:51:16,800
it's repelling

1886
01:51:16,820 --> 01:51:20,640
so the force and we are now in the same direction so the angle theta

1887
01:51:20,640 --> 01:51:23,910
between them is zero to the cosine of data is one

1888
01:51:23,920 --> 01:51:26,360
so we can forget about all defectors

1889
01:51:26,430 --> 01:51:27,330
and so

1890
01:51:27,330 --> 01:51:30,730
we would get then that this equals

1891
01:51:30,790 --> 01:51:32,600
q one

1892
01:51:32,610 --> 01:51:34,040
q two

1893
01:51:34,100 --> 01:51:37,180
divided by four pi epsilon zero

1894
01:51:37,260 --> 01:51:40,410
now i have downstairs here and are square

1895
01:51:40,460 --> 01:51:42,700
so i have the integral now

1896
01:51:42,790 --> 01:51:43,830
the are

1897
01:51:43,920 --> 01:51:45,980
divided by squared

1898
01:51:46,040 --> 01:51:49,910
capitol are two infinity

1899
01:51:49,920 --> 01:51:52,050
and this integral

1900
01:51:52,060 --> 01:51:54,430
his minus one of or

1901
01:51:54,440 --> 01:51:57,170
which i have to evaluate between are

1902
01:51:57,170 --> 01:51:59,020
n infinity

1903
01:51:59,030 --> 01:52:00,980
and when i do that becomes plus

1904
01:52:00,990 --> 01:52:02,990
one of the capital are

1905
01:52:03,070 --> 01:52:04,560
right indigo

1906
01:52:04,610 --> 01:52:07,540
of the are of our squared i'm sure you can although do it is minus

1907
01:52:07,540 --> 01:52:09,020
one of our

1908
01:52:09,110 --> 01:52:11,480
i valuated between are infinity

1909
01:52:11,550 --> 01:52:13,110
and so you get plus

1910
01:52:13,180 --> 01:52:14,300
one of our

1911
01:52:14,310 --> 01:52:15,190
and so

1912
01:52:15,910 --> 01:52:19,600
which is the energy that the work that i have to do to bring this

1913
01:52:19,600 --> 01:52:22,610
charge at that position

1914
01:52:22,650 --> 01:52:24,860
that you is nokia one

1915
01:52:24,910 --> 01:52:27,620
and q two

1916
01:52:27,650 --> 01:52:30,610
divided by four pi epsilon zero

1917
01:52:30,730 --> 01:52:35,210
divided by the capitol are

1918
01:52:35,220 --> 01:52:36,790
and this

1919
01:52:36,840 --> 01:52:39,620
courses scale of his work

1920
01:52:39,670 --> 01:52:42,540
the number of jewels

1921
01:52:42,550 --> 01:52:44,860
if q one and q two

1922
01:52:44,980 --> 01:52:46,360
both positive

1923
01:52:46,360 --> 01:52:52,870
almost never negative i do positive work you can see that minus signs plus

1924
01:52:52,920 --> 01:52:57,060
because then they repel each other if one is positive and the other is negative

1925
01:52:57,090 --> 01:52:59,040
that i do eighty four

1926
01:52:59,040 --> 01:53:02,790
best players are released not

1927
01:54:43,770 --> 01:54:45,710
the right

1928
01:54:45,730 --> 01:54:50,070
so i got from the

1929
01:54:50,180 --> 01:54:53,880
well the

1930
01:54:53,920 --> 01:54:56,680
at the time that

1931
01:55:04,790 --> 01:55:08,110
one of

1932
01:55:08,160 --> 01:55:11,950
i want to

1933
01:55:19,230 --> 01:55:21,630
one the

1934
01:55:31,000 --> 01:55:35,170
o five

1935
01:55:35,320 --> 01:55:38,350
but if you have a

1936
01:55:45,760 --> 01:55:48,480
the world

1937
01:55:48,780 --> 01:55:59,300
the article was

1938
01:55:59,440 --> 01:56:08,640
what about the the

1939
01:56:24,790 --> 01:56:27,610
it's very

1940
01:56:28,170 --> 01:56:34,050
i have affair

1941
01:56:48,380 --> 01:56:52,200
around the world

1942
01:57:00,440 --> 01:57:02,820
i because

1943
01:57:07,780 --> 01:57:08,670
from that

1944
01:57:43,810 --> 01:57:45,580
the first

1945
01:57:45,590 --> 01:57:47,720
all right

1946
01:57:54,120 --> 01:58:00,610
most of the carbon through all

1947
01:58:05,250 --> 01:58:08,980
that the

1948
01:58:08,990 --> 01:58:14,230
the parts of the

1949
01:58:14,670 --> 01:58:21,730
first of all road salt

1950
01:58:21,730 --> 01:58:26,520
a lot of so

1951
01:58:26,640 --> 01:58:29,600
that's it

1952
01:58:30,100 --> 01:58:34,870
there are a lot of

1953
01:58:39,590 --> 01:58:43,140
one of the

1954
01:58:46,540 --> 01:58:49,540
so far

1955
01:58:51,540 --> 01:58:57,550
so what you are

1956
01:59:03,540 --> 01:59:06,720
well couple

1957
01:59:06,770 --> 01:59:13,230
well that's sort of

1958
01:59:47,160 --> 01:59:49,030
about four

1959
01:59:52,280 --> 01:59:54,060
the sign

1960
01:59:54,090 --> 02:00:02,980
one of the

1961
02:00:02,980 --> 02:00:04,710
going whether it's the business

1962
02:00:04,750 --> 02:00:06,400
or a product or your life

1963
02:00:06,420 --> 02:00:08,150
you have to put more in

1964
02:00:08,240 --> 02:00:11,170
and you can get called the learning in

1965
02:00:11,180 --> 02:00:14,210
and i think still often very exciting

1966
02:00:14,300 --> 02:00:16,330
in the end things go

1967
02:00:16,400 --> 02:00:17,210
i'm sorry

1968
02:00:17,210 --> 02:00:19,230
the business does go down

1969
02:00:19,280 --> 02:00:20,690
politics to pay

1970
02:00:20,740 --> 02:00:22,540
and your life

1971
02:00:22,560 --> 02:00:24,670
it i will take away

1972
02:00:24,670 --> 02:00:26,480
until you die

1973
02:00:26,530 --> 02:00:27,610
and of course

1974
02:00:27,620 --> 02:00:28,680
the answer

1975
02:00:28,690 --> 02:00:31,040
conceptually to that

1976
02:00:31,100 --> 02:00:32,530
it is very obvious

1977
02:00:32,610 --> 02:00:40,110
chris too quickly

1978
02:00:40,130 --> 02:00:42,220
i go back

1979
02:00:42,220 --> 02:00:45,340
you draw second life

1980
02:00:45,400 --> 02:00:48,300
and you are very careful to start the second line

1981
02:00:48,310 --> 02:00:52,760
before the first line peaks so that you have some of the resources

1982
02:00:52,830 --> 02:00:55,140
there is some money or time skills

1983
02:00:55,150 --> 02:00:58,780
on the first in order to start the second

1984
02:00:58,790 --> 02:01:00,240
the concept

1985
02:01:00,240 --> 02:01:01,760
it's not difficult

1986
02:01:01,770 --> 02:01:04,450
i can use it is in two minutes

1987
02:01:05,400 --> 02:01:09,400
and you don't need a great degree in order to understand

1988
02:01:09,420 --> 02:01:11,690
it is very important

1989
02:01:11,700 --> 02:01:17,460
the problem however is not understanding the concept

1990
02:01:17,480 --> 02:01:19,920
the problem is

1991
02:01:19,940 --> 02:01:20,920
how do you know

1992
02:01:20,930 --> 02:01:22,120
the dot is

1993
02:01:22,140 --> 02:01:24,250
on that curve how do you know

1994
02:01:24,250 --> 02:01:27,740
way to start to say

1995
02:01:27,860 --> 02:01:33,440
most people don't actually know where it is until way down the hill

1996
02:01:33,460 --> 02:01:35,220
on the other side

1997
02:01:35,230 --> 02:01:39,760
and they can look back ruefully as a of course

1998
02:01:39,770 --> 02:01:44,140
that's when we should have changed that's when we had the energy that's when we

1999
02:01:44,140 --> 02:01:45,870
have the resources

2000
02:01:45,990 --> 02:01:47,950
the point halfway down the hill

2001
02:01:47,970 --> 02:01:52,200
it's when they bring in the consultants you that's when they sacked the chief executive

2002
02:01:52,240 --> 02:01:54,620
and get rid of thirty percent of the company

2003
02:01:54,680 --> 02:01:59,590
and reorganize and struggle to get themselves up as far as they can to the

2004
02:01:59,590 --> 02:02:03,370
second thing you come in with your case writers

2005
02:02:03,790 --> 02:02:06,260
and write these wonderful cases

2006
02:02:06,270 --> 02:02:07,180
and were a

2007
02:02:07,190 --> 02:02:11,010
you meet someone says haha hopefully were not to have changed

2008
02:02:11,060 --> 02:02:12,530
two years ago

2009
02:02:12,530 --> 02:02:16,960
how do you know that parties

2010
02:02:16,980 --> 02:02:21,030
well you don't do it by logic

2011
02:02:21,080 --> 02:02:24,450
you do it by some kind of intuition

2012
02:02:24,450 --> 02:02:28,080
and that's something that you can't teach

2013
02:02:28,140 --> 02:02:29,940
you have to learn some

2014
02:02:29,940 --> 02:02:31,310
they practice

2015
02:02:31,330 --> 02:02:37,100
my wife and i have been married and have been business partners now for many

2016
02:02:37,100 --> 02:02:40,170
many long years ever since we met in singapore

2017
02:02:40,170 --> 02:02:44,240
like all great partnerships we argue a lot of the time

2018
02:02:44,260 --> 02:02:46,180
we are good very deeply

2019
02:02:46,190 --> 02:02:48,270
last night about something

2020
02:02:48,280 --> 02:02:50,740
now i

2021
02:02:50,780 --> 02:02:55,390
on the left brain man i studied logic and philosophy

2022
02:02:55,450 --> 02:03:00,670
i like the reason for everything highlighting the need boxes like an argument i'd like

2023
02:03:00,670 --> 02:03:03,330
to be able to say so therefore

2024
02:03:03,350 --> 02:03:04,480
we do this

2025
02:03:04,520 --> 02:03:10,580
my wife's is very much on the right hand side of the head and sometimes

2026
02:03:10,580 --> 02:03:11,330
i think

2027
02:03:11,350 --> 02:03:12,550
around here

2028
02:03:12,810 --> 02:03:16,110
so last night as so often

2029
02:03:16,250 --> 02:03:20,530
she eventually gave in to my larger alright he said

2030
02:03:22,710 --> 02:03:24,060
but i am right

2031
02:03:24,080 --> 02:03:32,090
and i have to tell you she nearly always is

2032
02:03:32,140 --> 02:03:34,290
and i have to learn

2033
02:03:34,370 --> 02:03:39,830
for instance she doesn't know anything about economics of business

2034
02:03:39,850 --> 02:03:44,450
but when you're at the sloan school MIT we are on very minor

2035
02:03:44,450 --> 02:03:51,560
minimal government grant so to supplement our income we had a little import business tiny

2036
02:03:51,560 --> 02:03:54,070
important business of

2037
02:03:54,130 --> 02:03:58,020
brass rubbing is now you may not know what brass rubbing is embedded in the

2038
02:03:58,020 --> 02:03:59,130
english churches

2039
02:03:59,230 --> 02:04:05,040
they have these brass on top of the tombs of some of

2040
02:04:05,060 --> 02:04:08,580
distinguished ancestors way back

2041
02:04:08,600 --> 02:04:13,640
fifty eight hundred forty eight hundred people rather the

2042
02:04:13,650 --> 02:04:19,220
on two onto parchment and they come out this sort of

2043
02:04:19,220 --> 02:04:21,220
my print really

2044
02:04:21,270 --> 02:04:24,220
so we got some friends in england to do this

2045
02:04:24,240 --> 02:04:27,150
and they wrote about the past sheets and the ship them off to america and

2046
02:04:27,150 --> 02:04:30,360
we put the made images from there are about six long

2047
02:04:30,420 --> 02:04:31,720
hang on walls

2048
02:04:31,730 --> 02:04:36,630
we thought the americans would love to buy and there's about going to act as

2049
02:04:36,630 --> 02:04:41,030
the marketing director for our little tiny business and go around selling them while i

2050
02:04:41,030 --> 02:04:42,540
was studying business

2051
02:04:42,560 --> 02:04:44,960
on the MBA course at the flow schools

2052
02:04:45,100 --> 02:04:47,020
and he said well

2053
02:04:47,020 --> 02:04:48,110
we've enterprise

2054
02:04:48,140 --> 02:04:49,470
and i said don't worry

2055
02:04:49,470 --> 02:04:51,010
i mean the marketing manager shelf

2056
02:04:51,020 --> 02:04:52,230
i know about that

2057
02:04:52,300 --> 02:04:54,010
what's the landed cost

2058
02:04:54,030 --> 02:04:58,350
and it worked out the cost actually not very much about two dollars

2059
02:04:58,370 --> 02:05:05,180
well i said we could be extravagant normally shall we on fifty percent i think

2060
02:05:05,270 --> 02:05:09,740
we've got an of fifty percent we could charge these three dollars

2061
02:05:09,840 --> 02:05:11,090
she said

2062
02:05:11,110 --> 02:05:13,650
i think you're wrong

2063
02:05:13,700 --> 02:05:15,270
i said that

2064
02:05:15,280 --> 02:05:17,190
i think this is

2065
02:05:17,200 --> 02:05:20,770
i was the marketing manager shell international she said

2066
02:05:20,790 --> 02:05:24,560
i just have an idea why don't we give is the project

2067
02:05:24,680 --> 02:05:28,000
to one of the groups in your business school and the marketing calls

2068
02:05:28,830 --> 02:05:30,020
she did that

2069
02:05:30,100 --> 02:05:32,290
and they came back and they said

2070
02:05:32,290 --> 02:05:38,850
you should so this is a luxury product we suggest you to forty two dollars

2071
02:05:38,920 --> 02:05:43,600
so we did i said that absolutely ridiculous outrageous it's immoral

2072
02:05:44,220 --> 02:05:46,990
so anyway we prices in the under twenty dollars

2073
02:05:47,000 --> 02:05:50,570
and he said more secret indeed the price fifty two

2074
02:05:52,220 --> 02:05:55,050
i tell you something in some situations

2075
02:05:55,140 --> 02:05:57,300
the brain is here

2076
02:05:57,330 --> 02:05:58,610
is much better

2077
02:05:58,620 --> 02:06:01,560
and the brain

2078
02:06:02,240 --> 02:06:02,960
the here


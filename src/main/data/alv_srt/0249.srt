1
00:00:00,000 --> 00:00:01,750
you should click

2
00:00:01,770 --> 00:00:04,430
so we get things like professor in HCI

3
00:00:04,530 --> 00:00:09,550
and lecturer taking four courses these new terms in the computer science ontology

4
00:00:09,570 --> 00:00:11,280
and also i want to

5
00:00:11,300 --> 00:00:14,340
it's like the type of computer science students

6
00:00:14,350 --> 00:00:20,620
i actually communities across individually was selected something press this button here

7
00:00:20,630 --> 00:00:23,810
i can add it to the list of selected items

8
00:00:23,840 --> 00:00:24,690
on the

9
00:00:24,700 --> 00:00:26,660
right hand side

10
00:00:26,720 --> 00:00:29,200
and now i want to add in

11
00:00:29,250 --> 00:00:34,480
so classes of students and classes as students so we've got CS students and i

12
00:00:34,480 --> 00:00:40,130
students system taking courses and a students

13
00:00:40,130 --> 00:00:41,530
and one of them this

14
00:00:41,550 --> 00:00:45,180
first continue this is going to be my signature from my module

15
00:00:45,280 --> 00:00:48,010
could actually have properties if i wanted to

16
00:00:48,740 --> 00:00:55,010
and other items but were just like terms from concepts now

17
00:00:55,020 --> 00:00:58,100
so i press continue and it computes

18
00:00:58,100 --> 00:01:00,690
module for me

19
00:01:00,700 --> 00:01:05,500
it is updated with appreciate what you see here on the left hand side is

20
00:01:05,500 --> 00:01:09,410
the signature that was selected with some check boxes and we can experiment with this

21
00:01:09,410 --> 00:01:13,700
new moment and on the right-hand side you see all the axioms of a preview

22
00:01:13,770 --> 00:01:16,710
of the axioms that will end up in the

23
00:01:17,220 --> 00:01:21,870
much also he was saying look got for thirty three axioms

24
00:01:21,870 --> 00:01:24,590
if you recall

25
00:01:24,600 --> 00:01:27,040
the original ontology

26
00:01:27,060 --> 00:01:31,750
i can't see how the solutions that have about fifty axioms and this corresponds in

27
00:01:31,750 --> 00:01:35,640
our case two fifty eight percent of the at the ontology

28
00:01:35,710 --> 00:01:39,900
now if i wasn't so sure about what i wanted i could experiments at this

29
00:01:39,900 --> 00:01:44,760
stage and checking this checkbox is here so if you didn't want to talk about

30
00:01:44,760 --> 00:01:46,500
his students taking courses

31
00:01:46,520 --> 00:01:49,110
i could uncheck any we compute module

32
00:01:49,110 --> 00:01:53,480
and now you see some axioms of cross-taiwan this shows the effect of taking turns

33
00:01:53,480 --> 00:01:58,730
out the signature was chosen you could maybe have little players out sometime and see

34
00:01:58,730 --> 00:02:00,880
how this is the actual module

35
00:02:00,940 --> 00:02:03,780
that's affected by signature

36
00:02:03,890 --> 00:02:08,250
so i'm fairly happy with that just before carry on the whole just to show

37
00:02:08,250 --> 00:02:11,820
you that it's not just doing something stupid and pulling in the

38
00:02:11,850 --> 00:02:16,120
you have to follow is but just to show is that this means stupid and

39
00:02:16,120 --> 00:02:21,550
point in the whole subtree if just selects one term here faculty

40
00:02:21,560 --> 00:02:28,320
we compute module and we actually get an empty module here

41
00:02:28,540 --> 00:02:35,820
so where no entailments because just like the ones here was nine thomas will be

42
00:02:35,820 --> 00:02:40,190
ninety amazon this model any questions about that

43
00:02:43,510 --> 00:02:46,970
OK so i just restored the submission i wanted

44
00:02:47,050 --> 00:02:55,980
so continue OK i'm happy with much now

45
00:02:56,180 --> 00:03:00,040
continuing now i just have to be a few mechanics to specify what wants to

46
00:03:00,510 --> 00:03:03,640
so i want to put these axioms into a new ontology

47
00:03:03,690 --> 00:03:11,020
and going to call this ontology cs modules all ontologies in out of your eyes

48
00:03:11,040 --> 00:03:17,440
this will be used to identify ontology and then imported into university bench ontology

49
00:03:17,440 --> 00:03:19,140
so continue again

50
00:03:19,150 --> 00:03:22,720
we can specify what i want to say that skip over that now

51
00:03:22,740 --> 00:03:28,680
and now can either like to copy axioms from the source ontologies into OWL module

52
00:03:28,740 --> 00:03:32,700
could actually pull out axioms in case you actually might want to be facts pull

53
00:03:32,700 --> 00:03:38,280
out the module completely but will go with the default option which is copy axioms

54
00:03:38,290 --> 00:03:40,140
so i click finish

55
00:03:40,140 --> 00:03:44,160
and the marginal extracted and you can see here

56
00:03:44,200 --> 00:03:49,550
that we've got a new ontology alister ontologies top and this is a module

57
00:03:49,570 --> 00:03:52,230
you want to go and browse the ontology

58
00:03:52,250 --> 00:03:55,340
and you see we've got the terms that wanted

59
00:03:55,380 --> 00:04:00,870
and a small part of the ontology

60
00:04:00,880 --> 00:04:02,100
so now

61
00:04:02,110 --> 00:04:05,490
one simple this module back into university

62
00:04:05,510 --> 00:04:07,350
bench ontology

63
00:04:07,350 --> 00:04:10,220
so i go back university styles

64
00:04:10,460 --> 00:04:16,090
now i go down to the pain at the bottom here

65
00:04:16,090 --> 00:04:18,430
i want to add an important

66
00:04:18,440 --> 00:04:22,030
we've already got the ontology and memories of it already loaded so it selects the

67
00:04:22,030 --> 00:04:26,020
second option here importantly be loaded

68
00:04:26,040 --> 00:04:34,800
press continue make sure let's the CS module that was just created

69
00:04:34,850 --> 00:04:36,790
and when it and found

70
00:04:36,870 --> 00:04:39,690
the system of checks and things that are loaded

71
00:04:39,700 --> 00:04:42,800
i do that and then it's imported

72
00:04:42,890 --> 00:04:45,520
these class counts going to become more active

73
00:04:45,540 --> 00:04:48,900
in ontology

74
00:04:48,900 --> 00:04:59,480
any questions so far

75
00:05:23,900 --> 00:05:28,340
right so that was passed modularity and the tools

76
00:05:28,460 --> 00:05:38,470
you can use to extract modules and now we're going to go into explanation

77
00:05:38,500 --> 00:05:39,380
OK so

78
00:05:39,780 --> 00:05:41,440
what i want you to do now

79
00:05:41,450 --> 00:05:46,850
it is with the on univ bench ontology

80
00:05:46,860 --> 00:05:48,060
and the

81
00:05:49,130 --> 00:05:50,530
are imported module

82
00:05:50,590 --> 00:05:55,310
i want you to now selective is for the purposes of this demo are going

83
00:05:55,310 --> 00:05:56,700
to select palates

84
00:05:56,700 --> 00:05:59,660
so from the reason menu choose power

85
00:05:59,670 --> 00:06:02,590
this will classify the ontology

86
00:06:02,660 --> 00:06:09,660
computer class hierarchy in computer any in unsatisfiable classes

87
00:06:09,670 --> 00:06:13,540
if you switch over to the entities top

88
00:06:13,550 --> 00:06:16,870
and then you can switch over to the for class hierarchy

89
00:06:16,900 --> 00:06:24,250
if we expand it we notice actually ontology contains some unsatisfiable classes

90
00:06:24,270 --> 00:06:27,200
so you recall from ralph said this morning

91
00:06:27,210 --> 00:06:29,190
this usually is the modelling error

92
00:06:29,190 --> 00:06:33,730
unsatisfiable classes are interpreters and that in all models

93
00:06:33,760 --> 00:06:36,570
and usually don't want them your ontology

94
00:06:37,450 --> 00:06:39,630
it would be nice to find out the reasons why

95
00:06:39,640 --> 00:06:42,370
these classes unsatisfiable

96
00:06:42,380 --> 00:06:44,030
and take some action

97
00:06:44,100 --> 00:06:47,170
to repair the ontology

98
00:07:05,410 --> 00:07:13,600
here is the classifier ontology which is the reason to classify the

99
00:07:13,610 --> 00:07:17,460
and come up with some unsatisfiable classes

100
00:07:17,480 --> 00:07:21,110
and we want to know why this is the case

101
00:07:21,360 --> 00:07:27,070
but first of all you notice several unsatisfiable classes in the ontology and if you

102
00:07:27,070 --> 00:07:29,190
want to start preparing the ontology

103
00:07:29,190 --> 00:07:30,230
they work

104
00:07:30,350 --> 00:07:35,580
very differently

105
00:07:37,600 --> 00:07:42,270
hose or pipe

106
00:07:42,270 --> 00:07:45,140
and there's every year

107
00:07:45,160 --> 00:07:48,460
as a certain length

108
00:07:48,480 --> 00:07:50,890
and on one side i blow air

109
00:07:50,960 --> 00:07:58,750
later we can discuss how you have to blow

110
00:07:58,790 --> 00:08:03,660
but as for now think of it that we have here

111
00:08:03,710 --> 00:08:05,060
a five rating

112
00:08:08,440 --> 00:08:11,600
the changes its frequency from very low

113
00:08:11,600 --> 00:08:13,180
very high

114
00:08:13,180 --> 00:08:14,770
something similar will happen

115
00:08:14,790 --> 00:08:16,440
happened to restrain

116
00:08:16,480 --> 00:08:19,830
at certain frequencies it will do nothing

117
00:08:19,870 --> 00:08:21,940
and then all of a sudden

118
00:08:21,980 --> 00:08:23,190
it's very happy

119
00:08:23,210 --> 00:08:24,620
it produces the tongue

120
00:08:24,640 --> 00:08:26,850
recall that the first harmonic

121
00:08:26,850 --> 00:08:30,660
higher frequency second harmonic even higher frequency

122
00:08:30,750 --> 00:08:32,730
come on

123
00:08:32,770 --> 00:08:34,120
you may think now

124
00:08:34,140 --> 00:08:35,830
that's the part

125
00:08:35,850 --> 00:08:37,520
that is vibrating

126
00:08:37,580 --> 00:08:40,660
because the strings vibrating so you think it's the

127
00:08:40,690 --> 00:08:43,980
that is not true because the air inside the park

128
00:08:44,040 --> 00:08:48,250
it starts to oscillate in a way that is extremely hard to imagine not only

129
00:08:48,250 --> 00:08:51,040
for you but also for me

130
00:08:51,040 --> 00:08:52,270
but except for now

131
00:08:52,330 --> 00:08:56,910
that is the air column inside that is actually going to post it so to

132
00:08:57,940 --> 00:09:00,390
and it is then at certain frequencies

133
00:09:01,330 --> 00:09:02,230
you will

134
00:09:02,230 --> 00:09:04,100
here the

135
00:09:04,220 --> 00:09:08,270
harmonics the resonance frequencies and i'll give you an example

136
00:09:08,350 --> 00:09:11,180
if the length of this by

137
00:09:11,180 --> 00:09:13,370
it is one fought

138
00:09:13,440 --> 00:09:15,560
and two inches

139
00:09:15,580 --> 00:09:18,250
notice how precise i am

140
00:09:18,310 --> 00:09:21,690
the first harmonic

141
00:09:21,710 --> 00:09:23,390
it would be five hundred hertz

142
00:09:23,480 --> 00:09:27,250
and that's it

143
00:09:27,270 --> 00:09:29,870
you cannot change that

144
00:09:29,890 --> 00:09:31,140
you don't have the

145
00:09:32,620 --> 00:09:36,890
strange you can change the attention you can change the length there's no such thing

146
00:09:36,890 --> 00:09:38,270
as changing attention

147
00:09:38,330 --> 00:09:41,620
he is no such a thing as changing the weight

148
00:09:41,640 --> 00:09:43,710
per unit length you can do that here

149
00:09:43,710 --> 00:09:45,660
so you really stuck

150
00:09:45,710 --> 00:09:48,890
with length

151
00:09:50,330 --> 00:09:52,910
is common however is also very happy

152
00:09:53,040 --> 00:09:55,230
to produce a second harmonic

153
00:09:55,290 --> 00:09:58,270
which i will do a thousand hertz

154
00:09:58,330 --> 00:10:02,310
and it is very happy producing a third harmonic which it will do

155
00:10:02,350 --> 00:10:04,370
fifteen hundred

156
00:10:04,410 --> 00:10:05,980
similar to the string

157
00:10:05,980 --> 00:10:07,600
remember one two

158
00:10:12,410 --> 00:10:13,410
if you make

159
00:10:14,680 --> 00:10:17,350
twice as short as this one

160
00:10:17,370 --> 00:10:19,790
to make it shorter now

161
00:10:19,850 --> 00:10:21,750
exactly half the length

162
00:10:21,750 --> 00:10:23,500
then the first harmonic

163
00:10:23,640 --> 00:10:24,940
go up

164
00:10:25,080 --> 00:10:26,730
become thousand her

165
00:10:26,770 --> 00:10:28,850
so the second will become two thousand

166
00:10:28,870 --> 00:10:31,020
and the third one will become three thousand

167
00:10:31,020 --> 00:10:33,540
the length is the crucial thing

168
00:10:33,580 --> 00:10:35,480
no longer the instruments

169
00:10:37,350 --> 00:10:38,850
surely the

170
00:10:38,870 --> 00:10:40,520
the higher the fruit

171
00:10:40,540 --> 00:10:41,810
very short

172
00:10:41,870 --> 00:10:46,810
which is very high tones to be produced is very low to

173
00:10:46,920 --> 00:10:50,560
notice the complication

174
00:10:50,620 --> 00:10:53,960
the complication is the following

175
00:10:53,980 --> 00:10:55,420
you can

176
00:10:57,560 --> 00:10:59,980
design an instrument

177
00:11:00,790 --> 00:11:02,770
you close it on one end

178
00:11:02,810 --> 00:11:06,520
provides not open on both ends

179
00:11:06,520 --> 00:11:08,850
and when you do that

180
00:11:08,920 --> 00:11:13,910
if the length of the two are the same

181
00:11:13,940 --> 00:11:16,410
you first harmonic

182
00:11:16,420 --> 00:11:18,850
is half this frequency

183
00:11:18,850 --> 00:11:21,730
so it becomes two hundred fifty

184
00:11:21,730 --> 00:11:24,540
so you have exactly the same length one foot

185
00:11:24,540 --> 00:11:25,810
and two

186
00:11:27,230 --> 00:11:29,810
and i use this symbol now

187
00:11:29,870 --> 00:11:32,730
now you get here two hundred and fifty

188
00:11:32,790 --> 00:11:36,830
what do you think you're going to get you know

189
00:11:36,890 --> 00:11:40,870
that's what i call you would say that's not true

190
00:11:42,250 --> 00:11:44,270
centre run for this

191
00:11:44,290 --> 00:11:47,230
i told you that is really a complication here

192
00:11:47,250 --> 00:11:48,770
it turns out it now

193
00:11:48,790 --> 00:11:53,290
the next one is three times this which is seven fifty and the next one

194
00:11:53,290 --> 00:11:54,730
is five times this

195
00:11:54,790 --> 00:11:56,890
which is twelve

196
00:11:56,940 --> 00:12:00,480
so now you don't get the sequence one two three four five six seven but

197
00:12:00,480 --> 00:12:04,520
you get one three five seven and some you may forget that if you prefer

198
00:12:07,790 --> 00:12:11,390
since we are going to release in three installments and since we want to get

199
00:12:11,390 --> 00:12:12,890
the feeling now

200
00:12:13,020 --> 00:12:15,460
four what tones one can produce

201
00:12:16,870 --> 00:12:18,440
wind instruments

202
00:12:18,460 --> 00:12:19,660
i give you here

203
00:12:19,710 --> 00:12:21,870
the scheme which will help you for the rest

204
00:12:21,890 --> 00:12:23,710
all this talk

205
00:12:23,870 --> 00:12:26,100
you see there in white

206
00:12:26,120 --> 00:12:30,180
only the first harmonic

207
00:12:30,230 --> 00:12:33,080
and the numbers given in hertz

208
00:12:33,120 --> 00:12:34,750
and this is the length

209
00:12:34,770 --> 00:12:37,290
of the instrument is open open

210
00:12:37,310 --> 00:12:41,140
and this is closed open

211
00:12:41,210 --> 00:12:44,020
now notice if you have one inch

212
00:12:44,040 --> 00:12:46,560
this short only

213
00:12:46,600 --> 00:12:48,500
then you will be able to produce

214
00:12:48,500 --> 00:12:52,180
sixty seven hundred hertz

215
00:12:52,180 --> 00:12:52,940
and you're

216
00:12:53,000 --> 00:12:54,330
second harmonic

217
00:12:54,350 --> 00:12:57,870
i would then be twice that

218
00:12:57,890 --> 00:13:00,390
if you make it for instance

219
00:13:00,410 --> 00:13:05,230
the frequency goes down by exactly factor for is four times more than that

220
00:13:05,230 --> 00:13:06,620
twelve inches

221
00:13:06,620 --> 00:13:07,960
three times slower

222
00:13:07,980 --> 00:13:12,520
forty inches was be ten times lower than four inches you see that is the

223
00:13:13,560 --> 00:13:15,940
one hundred inches of course is amongst the

224
00:13:15,940 --> 00:13:17,040
it is this big

225
00:13:17,040 --> 00:13:20,730
you'll get sixty seven hits and this will be the second harmonic only put the

226
00:13:20,730 --> 00:13:22,020
second harmonic

227
00:13:22,060 --> 00:13:24,390
in the first and the last is now

228
00:13:24,410 --> 00:13:29,620
with the same length you go to this system notice that these values half

229
00:13:29,660 --> 00:13:30,680
is half

230
00:13:30,690 --> 00:13:33,890
this is half is half this half

231
00:13:33,910 --> 00:13:36,350
and two police this gentleman

232
00:13:36,370 --> 00:13:40,590
the second harmonic is three times higher so this number is three times this this

233
00:13:40,590 --> 00:13:42,060
are not incoherent

234
00:13:42,070 --> 00:13:48,670
and as a result they yield instabilities when you want to do classification out of

235
00:13:48,670 --> 00:13:51,790
this sparse per out

236
00:13:51,810 --> 00:13:54,590
now there may be way around but let's say that that is the state of

237
00:13:54,610 --> 00:13:55,350
the art

238
00:13:55,370 --> 00:13:57,870
so the question is what to do when

239
00:13:57,890 --> 00:14:02,520
when you look at the current location vision you observe that people now begin to

240
00:14:02,520 --> 00:14:07,500
be able to do some kind of classification and they use the scriptures

241
00:14:07,520 --> 00:14:12,650
and these descriptors are constructed by grouping coefficients out of

242
00:14:12,670 --> 00:14:15,980
basic wavelet representations

243
00:14:16,050 --> 00:14:22,670
so what is this idea of SIFT bag of features also called back for OK

244
00:14:22,750 --> 00:14:24,460
it is the following

245
00:14:24,480 --> 00:14:26,630
you have your original image

246
00:14:26,640 --> 00:14:32,640
and the first stage you make decomposition in wavelet basis and then you get some

247
00:14:32,640 --> 00:14:36,050
sparse right corresponds to zero emissions

248
00:14:36,050 --> 00:14:39,140
these are four different ways that orientation

249
00:14:39,170 --> 00:14:41,860
which basically extracts four

250
00:14:41,870 --> 00:14:43,790
directions of your

251
00:14:43,800 --> 00:14:48,150
and then the key idea is to say i'm not going to work on independent

252
00:14:48,180 --> 00:14:52,850
wavelet coefficients a lot of algorithms in the nineties for texture discrimination

253
00:14:53,340 --> 00:14:58,800
try to build the vectors of single-track wavelet coefficients and that didn't really work so

254
00:14:59,440 --> 00:15:03,960
the idea here is instead of looking up with the sufficient independently you look at

255
00:15:03,960 --> 00:15:06,430
the block of with fish

256
00:15:06,440 --> 00:15:12,190
so these small loops where simultaneously in all directions

257
00:15:12,210 --> 00:15:14,480
so these this are

258
00:15:14,520 --> 00:15:16,000
i love

259
00:15:17,580 --> 00:15:19,460
now in each of these blocks

260
00:15:19,480 --> 00:15:23,580
you have something like sixteen by sixteen crayfish

261
00:15:24,190 --> 00:15:25,980
one never be

262
00:15:26,210 --> 00:15:27,900
the need for also

263
00:15:28,100 --> 00:15:31,330
sixty six different one by

264
00:15:31,350 --> 00:15:37,210
so present problem or or is it can be by this sense

265
00:15:37,960 --> 00:15:41,330
in two thousand and the idea of these elementary cells is that you want to

266
00:15:41,330 --> 00:15:44,270
have some kind of robustness with respect to translation

267
00:15:44,290 --> 00:15:46,370
and they get one measurement these

268
00:15:46,400 --> 00:15:48,940
elementary cells and in this case

269
00:15:48,960 --> 00:15:53,560
to get simply the energy this summer in which each other

270
00:15:54,480 --> 00:15:57,230
so that for each other

271
00:15:57,250 --> 00:16:03,370
now you get this picture which has sixty four coefficients OK

272
00:16:03,420 --> 00:16:09,500
now this the scriptures lives in a space of dimension sixty four hours

273
00:16:09,520 --> 00:16:12,040
and what you want is to group

274
00:16:12,080 --> 00:16:15,000
these scriptures in our sixty four

275
00:16:15,000 --> 00:16:19,190
if you count the number of descriptors you have to became this image is of

276
00:16:19,190 --> 00:16:25,710
the order of two thousand four thousand two translated all of

277
00:16:25,750 --> 00:16:30,330
you do your came in algorithm so you try to find clusters and the centre

278
00:16:30,330 --> 00:16:32,390
of the clusters

279
00:16:32,400 --> 00:16:34,920
and then you do basic histogram

280
00:16:34,940 --> 00:16:39,460
which counts how many elements you have each of the clusters

281
00:16:39,480 --> 00:16:43,600
and people have been trying to to classify images out of this histogram

282
00:16:43,670 --> 00:16:44,670
and it works

283
00:16:44,710 --> 00:16:46,060
really pretty nice

284
00:16:46,330 --> 00:16:51,440
it works nicely but there is something of a bit of black magic because look

285
00:16:51,650 --> 00:16:54,020
that's our sixty four

286
00:16:54,420 --> 00:16:56,420
you have very few

287
00:16:58,270 --> 00:17:04,830
i mean these four points they're completely lonely in this huge space and building clusters

288
00:17:04,830 --> 00:17:07,600
in this huge based on its

289
00:17:07,620 --> 00:17:09,650
something which is not so

290
00:17:10,080 --> 00:17:12,060
clear to understand

291
00:17:12,670 --> 00:17:13,520
let me

292
00:17:13,560 --> 00:17:16,940
try to get the different interpretation of

293
00:17:16,940 --> 00:17:20,040
that kind of file great and i'm going to make it link

294
00:17:20,060 --> 00:17:21,710
with respect to these

295
00:17:21,730 --> 00:17:24,540
presentation of money for that well done yesterday

296
00:17:27,290 --> 00:17:29,080
so one review

297
00:17:29,100 --> 00:17:32,100
of how to structure dates

298
00:17:32,690 --> 00:17:34,870
is to say well

299
00:17:34,920 --> 00:17:38,900
if there is some structure these data should belong to some kind of manifold now

300
00:17:38,920 --> 00:17:44,730
think of these patches vectors in dimension are sixty four hopefully these patches belong to

301
00:17:44,730 --> 00:17:46,330
some kind of benefit

302
00:17:46,710 --> 00:17:52,000
and the very beautiful tools that were presented show that you may look at this

303
00:17:52,000 --> 00:17:53,850
manifold by

304
00:17:53,870 --> 00:17:58,810
looking at the heat kernel which is associated with the legislation try to define the

305
00:17:58,810 --> 00:18:01,770
idea of function of the form

306
00:18:01,790 --> 00:18:07,060
the difficulty at least from my understanding of these techniques is that it's difficult to

307
00:18:07,060 --> 00:18:11,150
work in the space of dimension sixty four which is absolutely huge when you have

308
00:18:11,230 --> 00:18:17,310
a very very very sparse data only four thousand in very very large so

309
00:18:17,330 --> 00:18:19,370
this may be a little bit ambitious

310
00:18:19,390 --> 00:18:21,230
when you have so little

311
00:18:21,250 --> 00:18:25,440
another thing that you could do is to think OK something very

312
00:18:25,440 --> 00:18:27,390
i'm going to take my data

313
00:18:27,400 --> 00:18:33,920
project my data of a linear space and let me choose almost randomly my space

314
00:18:33,920 --> 00:18:36,170
and try to find a new space

315
00:18:36,190 --> 00:18:40,690
which absorbs a maximum energy when i do this projection

316
00:18:40,710 --> 00:18:44,000
well in two d how does it look like well if you find the linear

317
00:18:44,000 --> 00:18:46,770
space which is of the most energy

318
00:18:46,790 --> 00:18:49,210
it looks like the tangent space

319
00:18:49,920 --> 00:18:54,330
but the problem is that the number of linear space i have is a tremendous

320
00:18:54,330 --> 00:18:57,990
something to constraints on the choice of the space but that's the idea the the

321
00:18:57,990 --> 00:19:02,520
idea is let's try to optimize the energy of the projection and they may not

322
00:19:02,520 --> 00:19:05,540
be too far too notion of space

323
00:19:05,560 --> 00:19:13,650
and the idea is therefore identified indirectly the manifold through projections on the inner space

324
00:19:13,670 --> 00:19:16,060
OK so let me relate that

325
00:19:16,080 --> 00:19:20,850
and that's the work done by john blown up and you said one

326
00:19:20,870 --> 00:19:21,750
the company

327
00:19:21,850 --> 00:19:25,620
so let me relate that to what i just said so

328
00:19:25,650 --> 00:19:27,480
i had these vectors

329
00:19:27,520 --> 00:19:31,210
of sixty four energy

330
00:19:31,940 --> 00:19:34,670
maybe long hopefully to some kind of

331
00:19:34,690 --> 00:19:37,060
and let me make projection

332
00:19:37,080 --> 00:19:40,880
on this manifold now what do i know i know that my representation is sparks

333
00:19:41,560 --> 00:19:45,080
the fact that it's means that may be able to do projection in the low

334
00:19:45,080 --> 00:19:46,560
dimensional space

335
00:19:46,630 --> 00:19:49,330
and still carry most of the image

336
00:19:49,370 --> 00:19:51,520
so how does the project

337
00:19:51,600 --> 00:19:54,120
the project trajectory based keeps energy

338
00:19:54,250 --> 00:19:56,690
one cells and removed from the

339
00:19:56,710 --> 00:19:59,620
so project or around the projector

340
00:19:59,750 --> 00:20:02,710
dimension p is equivalent to the

341
00:20:02,730 --> 00:20:06,250
one out of sixty four in around the way

342
00:20:06,500 --> 00:20:08,230
so far to project

343
00:20:08,290 --> 00:20:13,040
however the project you just have have to do to select only the white element

344
00:20:13,040 --> 00:20:16,440
to some of the energy and you get the amount of two project

345
00:20:16,460 --> 00:20:22,040
now if i look use these blocks space projectors harmony the i

346
00:20:22,060 --> 00:20:24,900
in nineteen sixty four and a huge number

347
00:20:24,920 --> 00:20:29,830
let's signposted are spots and as far as a teacher

348
00:20:29,850 --> 00:20:31,600
sixty four

349
00:20:31,790 --> 00:20:37,710
sixty four that people stand for example you have about ten to the pahlavi project

350
00:20:37,710 --> 00:20:40,130
is this is still quite

351
00:20:40,150 --> 00:20:43,500
now of course you don't want to use one project to another one which looks

352
00:20:43,500 --> 00:20:48,060
too much like so if you impose a little bit of differences between these projectors

353
00:20:48,080 --> 00:20:51,960
for example that three of the damage and should be different then you go back

354
00:20:51,960 --> 00:20:56,790
to to the managing member like fifty thousand project OK

355
00:20:58,420 --> 00:21:01,710
the idea is basically to do that

356
00:21:01,730 --> 00:21:05,440
same kind of spirit of what i described and how does it relate to what

357
00:21:05,440 --> 00:21:06,500
i described

358
00:21:06,520 --> 00:21:10,850
what i'm going here basically what i'm going to do is to learn the dictionary

359
00:21:10,850 --> 00:21:14,500
of block spaces by doing these random projection

360
00:21:15,080 --> 00:21:16,770
let me show

361
00:21:16,810 --> 00:21:18,900
a simple example

362
00:21:18,920 --> 00:21:20,750
this is a texture

363
00:21:20,750 --> 00:21:24,320
in the use of for forty eight hours

364
00:21:24,330 --> 00:21:26,030
the learning are there

365
00:21:26,090 --> 00:21:27,500
it's called the

366
00:21:27,620 --> 00:21:32,250
even ecological and learning are there

367
00:21:32,300 --> 00:21:34,270
if don't the w

368
00:21:35,990 --> 00:21:37,330
which is the

369
00:21:37,340 --> 00:21:41,860
you time in the input time allen

370
00:21:41,870 --> 00:21:45,690
the money he

371
00:21:45,750 --> 00:21:48,020
think is large

372
00:21:48,030 --> 00:21:51,470
if minus one is large

373
00:21:51,480 --> 00:21:59,090
and more if ten minus one at specification and you more

374
00:22:02,440 --> 00:22:07,700
is easier to see if it applies equal to add because then the

375
00:22:07,730 --> 00:22:10,470
weight is just proportional to

376
00:22:10,490 --> 00:22:11,470
with the money

377
00:22:11,520 --> 00:22:16,580
what you had

378
00:22:16,580 --> 00:22:19,870
i think the normalisation

379
00:22:19,880 --> 00:22:24,490
and then think the according to to these the

380
00:22:26,210 --> 00:22:31,180
for any fixed and over here and that is the probability distribution because it is

381
00:22:31,180 --> 00:22:33,160
the normalized

382
00:22:33,830 --> 00:22:37,690
it is linear combination

383
00:22:37,750 --> 00:22:39,120
all of the

384
00:22:39,340 --> 00:22:42,470
experts portfolio selection

385
00:22:43,840 --> 00:22:45,230
is large

386
00:22:45,250 --> 00:22:50,630
it is OK and performed well and the small

387
00:22:50,640 --> 00:22:56,170
actually zero otherwise

388
00:23:01,920 --> 00:23:08,510
but it has a much better interpretation might should be very proficient but it means

389
00:23:08,510 --> 00:23:15,230
that the you know the the of the your your training but not in fact

390
00:23:15,230 --> 00:23:20,800
the you just show me each of you have a monitor and i can see

391
00:23:20,820 --> 00:23:24,350
or you want to make an aggregation

392
00:23:24,390 --> 00:23:27,690
according to the minus one OK

393
00:23:27,750 --> 00:23:32,420
it has a better interpretation let's calculate the

394
00:23:32,430 --> 00:23:39,430
aggregated amount of money what i

395
00:23:39,430 --> 00:23:40,540
it is the the

396
00:23:40,800 --> 00:23:46,670
the product of you know product for my portfolio selection and i stopped it towards

397
00:23:46,700 --> 00:23:48,790
the end of the piece of i

398
00:23:48,800 --> 00:23:53,580
the definition of the aggregate it portfolio selection

399
00:23:56,340 --> 00:23:59,260
it is the definition

400
00:23:59,330 --> 00:24:01,840
and the product

401
00:24:01,880 --> 00:24:05,240
of s i minus one

402
00:24:06,470 --> 00:24:09,200
the inner product

403
00:24:09,210 --> 00:24:10,610
if you just s

404
00:24:10,610 --> 00:24:11,540
so by

405
00:24:11,710 --> 00:24:20,870
and then if you look at these product then we ought to err

406
00:24:20,920 --> 00:24:22,710
cancers are

407
00:24:22,730 --> 00:24:26,030
if the initial capital is one dollar

408
00:24:27,630 --> 00:24:30,430
combination combined

409
00:24:30,470 --> 00:24:32,450
amount of money

410
00:24:32,520 --> 00:24:36,390
is the theme of

411
00:24:36,430 --> 00:24:40,320
what is the interpretation of these results

412
00:24:40,340 --> 00:24:42,120
it means

413
00:24:42,130 --> 00:24:45,170
that at the very beginning

414
00:24:45,170 --> 00:24:47,040
the kind of the intuition that we

415
00:24:47,060 --> 00:24:51,210
we carried out here as well to see if we can get a whole bunch

416
00:24:51,210 --> 00:24:52,890
of these weak use

417
00:24:52,940 --> 00:24:55,500
and have the computer guess

418
00:24:55,540 --> 00:25:01,370
the elimination for the scene so this is our upcoming ICC paper

419
00:25:01,390 --> 00:25:06,560
and here basically we are producing a probability map of where

420
00:25:06,600 --> 00:25:13,190
all that kind of viewing hemisphere the sun might be so this is the

421
00:25:13,210 --> 00:25:16,310
because of the map the way you look at it you just look up into

422
00:25:16,310 --> 00:25:17,020
the sky

423
00:25:17,940 --> 00:25:22,080
the black frame is basically frame of the image and this is your whole hemisphere

424
00:25:22,080 --> 00:25:23,000
of the sky

425
00:25:23,020 --> 00:25:26,210
and you can see the red is is where the sound is more likely to

426
00:25:27,540 --> 00:25:31,870
so it's a kind of a very very soft probabilistic map of where do we

427
00:25:31,870 --> 00:25:35,580
think the elimination might be coming from and of course once we have that we

428
00:25:35,580 --> 00:25:37,480
could actually synthesized

429
00:25:37,500 --> 00:25:43,020
synthetic sky using a parametric model that we have and then use that in in

430
00:25:43,020 --> 00:25:50,560
computer graphics framework to insert a synthetic three d object in the scene so that

431
00:25:50,580 --> 00:25:53,940
we insert the statue that that is three d

432
00:25:53,940 --> 00:26:00,230
three d object all that with the environment map that we have just recovered and

433
00:26:00,230 --> 00:26:04,870
you can see that it looks mostly mostly OK within the city

434
00:26:04,890 --> 00:26:09,790
OK so what's the algorithm for doing this well first we compute

435
00:26:09,830 --> 00:26:13,210
a bunch of very weak cues from three sources

436
00:26:13,230 --> 00:26:14,690
first the sky

437
00:26:14,710 --> 00:26:18,960
the shadows on the ground and the shading on vertical surfaces

438
00:26:19,040 --> 00:26:24,350
second we integrate all of these information with a data driven prior on

439
00:26:24,390 --> 00:26:25,600
basically what

440
00:26:25,620 --> 00:26:29,140
types of images what types of photos people take

441
00:26:29,190 --> 00:26:34,620
and first third step is hoping for the best because all of these cues again

442
00:26:34,620 --> 00:26:39,900
very very weak so you're not going to get anything anything definite definitive but what

443
00:26:39,920 --> 00:26:41,690
we have seen is that

444
00:26:41,730 --> 00:26:43,000
it seems that

445
00:26:43,000 --> 00:26:46,960
more for most of the image is one of those cues is is able to

446
00:26:46,960 --> 00:26:52,190
give us something something useful at least as useful as something that a human would

447
00:26:52,190 --> 00:26:55,790
be able to to infer from and image again this is really all we are

448
00:26:55,790 --> 00:26:59,850
interesting in here is interesting here is that the idea for this project it is

449
00:26:59,870 --> 00:27:04,100
the follow-up to this project is to see if we can use this illumination estimation

450
00:27:04,330 --> 00:27:05,730
as the way to

451
00:27:05,810 --> 00:27:09,980
to help you see interpretation two two two

452
00:27:10,060 --> 00:27:12,770
help us understand

453
00:27:12,790 --> 00:27:17,290
better the objects in the and services within the city right then and for that

454
00:27:17,290 --> 00:27:19,920
we probably don't need to be very exact

455
00:27:19,940 --> 00:27:22,210
OK so here's here's some of the

456
00:27:22,210 --> 00:27:23,890
some of the queue so that

457
00:27:23,890 --> 00:27:26,190
the first cue is the sky

458
00:27:26,210 --> 00:27:28,850
we have a parametric model of the sky and basically the idea is that we

459
00:27:29,540 --> 00:27:33,120
we the size of parametric more parametric sky at every

460
00:27:33,120 --> 00:27:35,160
possible some position over there

461
00:27:35,170 --> 00:27:38,120
the hemisphere and then we see which one of those

462
00:27:38,200 --> 00:27:43,850
parametric skies words are better and better explain our our data

463
00:27:43,900 --> 00:27:48,440
and then basically we have that those that

464
00:27:48,440 --> 00:27:51,420
the position of the best explains the data is the ones that get a high

465
00:27:51,440 --> 00:27:57,790
probability if this of course was only for clear sky images if you have a

466
00:27:57,790 --> 00:28:01,920
kind of an english an overcast sky than it's it's very easy you just have

467
00:28:01,920 --> 00:28:06,480
a classifier this overcast you don't need to do do is some prediction the tricky

468
00:28:06,480 --> 00:28:11,310
bit is is what if you have some sky some

469
00:28:11,350 --> 00:28:15,350
sky and some clouds at the same time so we have no a mechanism for

470
00:28:15,350 --> 00:28:20,620
segmenting out a sky cloud layer and that only working on the clear sky pixels

471
00:28:20,620 --> 00:28:26,040
for OK so this is this is this kind information that we're using

472
00:28:26,100 --> 00:28:31,190
the second cue is shadows on the ground so here we are

473
00:28:31,250 --> 00:28:35,940
try to detect shadows on the ground plane and then hoping that the shadows actually

474
00:28:35,940 --> 00:28:42,080
are coming from vertical objects and then using that to basically boat using kind of

475
00:28:42,370 --> 00:28:47,330
half transformed i think vote for possible some directions and of course you know here

476
00:28:47,330 --> 00:28:50,040
because it's going to be symmetric we don't know where the sound is coming from

477
00:28:50,040 --> 00:28:53,250
it could be you know from the left or the right of that of the

478
00:28:53,250 --> 00:28:57,310
line and of course a lot of the time the

479
00:28:57,330 --> 00:29:00,390
they the lines on the ground will not be shadow lines and some of the

480
00:29:00,390 --> 00:29:02,120
time the shadow lines will be

481
00:29:02,230 --> 00:29:06,290
in fact not from vertical objects so is a lot of noise in this process

482
00:29:06,290 --> 00:29:12,140
also but again we are kind of combining it all together and forming a kind

483
00:29:12,140 --> 00:29:15,690
of the distribution of where the elimination could be

484
00:29:15,730 --> 00:29:18,420
and the third q is

485
00:29:18,480 --> 00:29:23,920
shading from objects so here we are looking at

486
00:29:23,960 --> 00:29:28,600
again all of this is of course comes from the the scene layout work the

487
00:29:28,600 --> 00:29:29,420
the sky

488
00:29:29,460 --> 00:29:36,120
horizontal services vertical services here we're looking at the different vertical services of different orientations

489
00:29:36,120 --> 00:29:42,580
and looking very coarsely whether one services are rendered in one way are much brighter

490
00:29:42,580 --> 00:29:47,920
and services or another way and that information if there's a huge variation in brightness

491
00:29:48,000 --> 00:29:51,940
that cannot be explained by just albedo changes if there's a huge variation in brightness

492
00:29:52,000 --> 00:29:58,040
there might be a possibility that you know the element comes from that particular direction

493
00:29:58,060 --> 00:30:02,540
OK again it's very very coarse in very rough but that's what all we're looking

494
00:30:02,540 --> 00:30:07,270
for so we here we get a bunch of estimates for for where the sun

495
00:30:07,270 --> 00:30:13,640
could be the budget probability maps were combined together with a prior one what

496
00:30:13,660 --> 00:30:21,040
what are the sun positions are more likely for for human photographs and you we

497
00:30:21,040 --> 00:30:25,690
use a data set of six million geotagged flickr images

498
00:30:25,690 --> 00:30:28,620
so we have the geo tagged with at the time of day

499
00:30:28,940 --> 00:30:32,370
and the data so we are able to predict exactly where the sun is so

500
00:30:32,370 --> 00:30:36,370
we basically statistics of where the sun is in

501
00:30:36,390 --> 00:30:42,150
people's photos OK unfortunately we don't have the compass direction now that is i and

502
00:30:42,150 --> 00:30:46,020
we're looking forward to using that so here this is only for the elevation information

503
00:30:46,080 --> 00:30:47,750
to get the prior like this

504
00:30:47,770 --> 00:30:52,360
OK for that so basically it says that there are very very few photos with

505
00:30:52,360 --> 00:30:56,560
them with the sun on the disease OK

506
00:30:56,830 --> 00:31:02,230
and we combine it all together this multiply all this probability map and here's here's

507
00:31:02,230 --> 00:31:08,480
some of the qualitative results really quickly and you can we render little red stick

508
00:31:08,480 --> 00:31:11,440
with the shadows so you can see if you agree with

509
00:31:11,980 --> 00:31:12,810
with them

510
00:31:12,830 --> 00:31:17,980
with illumination direction that that we guess and look at some quantitative results as well

511
00:31:17,980 --> 00:31:22,210
and you're welcome to see the paper the papers online already and will be presented

512
00:31:22,210 --> 00:31:23,390
to you

513
00:31:23,390 --> 00:31:28,310
for your cellphones you have parallel processing what people do is is not the serial

514
00:31:28,310 --> 00:31:33,520
order what they do is every round every processors just updating all the time

515
00:31:33,560 --> 00:31:38,290
this is nice because it's a completely distributed algorithm and it's inherently parallel

516
00:31:38,300 --> 00:31:42,040
but in some ways it's wasteful on the tree because you're sending more messages than

517
00:31:42,040 --> 00:31:43,300
you have to there's

518
00:31:43,340 --> 00:31:47,560
you know every round everybody is sending a message on on every edge actually two

519
00:31:47,560 --> 00:31:49,630
two messages per edge

520
00:31:50,160 --> 00:31:51,430
so that's the choice

521
00:31:51,450 --> 00:31:57,800
the other reason the parallel muscle message scheduling sort of interesting to someone was asking

522
00:31:57,820 --> 00:32:02,880
yesterday if you have a graph with cycles how do you apply this algorithm

523
00:32:02,900 --> 00:32:06,300
right that's actually where a lot of the modern interest is is applying this algorithm

524
00:32:06,300 --> 00:32:07,780
to graph with cycles

525
00:32:07,820 --> 00:32:10,470
if you have cycles then

526
00:32:10,590 --> 00:32:14,410
so if you look for instance like this then there is no natural way of

527
00:32:14,410 --> 00:32:18,190
defining the route but there's no route if you have a graph with cycles

528
00:32:18,250 --> 00:32:22,160
so there is no natural way of having to pass sweep up and down you

529
00:32:22,160 --> 00:32:26,490
can talk about leaves and roots but if you don't think of the two past

530
00:32:26,490 --> 00:32:30,560
form if you just think of the parallel form everybody just doing their own thing

531
00:32:30,560 --> 00:32:34,800
right the parallel form doesn't care to happen to be an extra edge there

532
00:32:34,880 --> 00:32:39,120
yes this node will pass messages along that edge but it's you know there's nothing

533
00:32:39,130 --> 00:32:43,390
in the parallel form that that needs to know to tree

534
00:32:51,540 --> 00:33:01,500
that's a good question so when you've cycles

535
00:33:01,540 --> 00:33:05,460
OK so i'm getting a bit ahead of myself let me just say the basic

536
00:33:05,460 --> 00:33:09,720
stuff first come back to this in one minute OK so the basic stuff is

537
00:33:09,990 --> 00:33:11,730
that on the tree

538
00:33:11,740 --> 00:33:18,430
whatever ordering of messages use use any reasonable ordering this algorithm will converge in essentially

539
00:33:18,430 --> 00:33:23,880
the diameter of the tree iterations most diameter this means the length of the longest

540
00:33:23,880 --> 00:33:25,040
path in the tree

541
00:33:25,080 --> 00:33:28,340
right so you need a number of iterations if i had a long path here

542
00:33:28,340 --> 00:33:32,150
i need enough iterations this guy can reach the sky that they have to be

543
00:33:32,150 --> 00:33:33,800
able to talk

544
00:33:33,810 --> 00:33:37,800
right but it's a finite number of iterations to find a number of steps if

545
00:33:37,800 --> 00:33:42,250
you implemented the messages will be fixed they won't change any more

546
00:33:42,260 --> 00:33:44,780
right so it means if you're running this update

547
00:33:44,820 --> 00:33:47,680
exactly this local update here

548
00:33:47,680 --> 00:33:51,470
it will be such that you have a set of messages and starring put them

549
00:33:51,470 --> 00:33:56,630
in here you do this operation you get back and start fixed point

550
00:33:56,800 --> 00:34:00,150
and an entry there's only one of those fixed points it's you can show that

551
00:34:00,150 --> 00:34:03,380
is always unique and they always find it

552
00:34:03,440 --> 00:34:06,020
and when you find it a you plug it into

553
00:34:06,080 --> 00:34:07,870
this other equation here

554
00:34:07,880 --> 00:34:14,020
then you always compute the correct marginal distributions it's always exact on the tree

555
00:34:14,020 --> 00:34:18,460
right so that's that's a very important result because

556
00:34:18,460 --> 00:34:21,610
if you remember when we spoke about the

557
00:34:21,830 --> 00:34:25,630
you know the naive complexity of solving these problems is exponential

558
00:34:25,680 --> 00:34:28,360
because you have to be something or exponentially many

559
00:34:29,970 --> 00:34:34,980
whereas if we look at the complexity of this algorithm that we've done

560
00:34:34,990 --> 00:34:48,630
right so that the naive complexity of some asian and marginalization

561
00:34:49,220 --> 00:34:51,800
as we've discussed would be order

562
00:34:51,810 --> 00:34:56,830
and two the and were and is number of nodes

563
00:34:56,850 --> 00:35:00,700
and am if we're looking at discrete variables is the number of states with the

564
00:35:00,710 --> 00:35:02,330
number of different types

565
00:35:02,350 --> 00:35:04,800
number of levels of the discrete variable

566
00:35:04,890 --> 00:35:13,270
right so that's huge message passing complexity let's just as a little calculation

567
00:35:13,320 --> 00:35:17,050
what would the message passing complexity be how much does it cost me to do

568
00:35:17,050 --> 00:35:29,630
one of these updates

569
00:35:29,910 --> 00:35:34,160
right so and here is the number of states be maximizing over

570
00:35:34,180 --> 00:35:37,960
so how much would it cost to compute this vector this is an you have

571
00:35:37,960 --> 00:35:39,070
to compute

572
00:35:39,130 --> 00:35:42,630
just roughly order of magnitude

573
00:35:47,400 --> 00:35:50,060
as an exponential is cubic

574
00:35:50,110 --> 00:35:55,700
what is a

575
00:35:55,700 --> 00:36:02,060
close i think it's if you think about it m squared

576
00:36:02,150 --> 00:36:04,280
because you have to do this

577
00:36:04,310 --> 00:36:08,260
you fix an access you have to do this operation

578
00:36:08,270 --> 00:36:11,050
this is like a matrix multiply roughly so

579
00:36:11,100 --> 00:36:14,200
it's going to be order and for each one of these order m squared per

580
00:36:15,790 --> 00:36:19,650
and you have to do is roughly the number of edges that are tree so

581
00:36:19,650 --> 00:36:21,780
how many edges we have an entry

582
00:36:21,850 --> 00:36:26,100
as a function of and the number of nodes

583
00:36:26,190 --> 00:36:28,340
it's always n minus one so

584
00:36:28,390 --> 00:36:29,950
the complexity of

585
00:36:29,950 --> 00:36:35,070
of message passing is order m squared times and roughly

586
00:36:35,090 --> 00:36:39,140
right so that's that's significant that linear in the number of nodes

587
00:36:39,220 --> 00:36:41,930
quadratic in the number of states

588
00:36:42,450 --> 00:36:46,460
sometimes the quadratic can be a problem if you do problems in computer vision let's

589
00:36:47,050 --> 00:36:50,300
people will discretize if you had continuous things

590
00:36:50,370 --> 00:36:53,760
a natural thing to do would be to discretize the to break the continuous space

591
00:36:53,760 --> 00:36:56,100
into many bends into bins

592
00:36:56,160 --> 00:37:01,300
so if i was like ten thousand square could be problematic and sometimes the techniques

593
00:37:01,300 --> 00:37:03,780
to even make it faster than m squared

594
00:37:03,780 --> 00:37:06,520
but what you want to take away initially is that this is the key that

595
00:37:06,530 --> 00:37:11,540
the thing the and the number of nodes drop down from the exponent to being

596
00:37:12,750 --> 00:37:16,660
i mean that's really why this algorithm is used all the time linear time is

597
00:37:16,660 --> 00:37:17,600
is nice

598
00:37:17,730 --> 00:37:19,900
oup sorry guys can't see that

599
00:37:19,910 --> 00:37:23,770
should let me know if it's not properly right so what i was saying is

600
00:37:23,770 --> 00:37:29,620
the key is that the the number of nodes has dropped from exponential to linear

601
00:37:29,800 --> 00:37:35,270
OK so that's for trees it's all this exact stuff so far for trees

602
00:37:35,350 --> 00:37:39,520
but getting back to his question a lot of the modern interest in this algorithm

603
00:37:40,120 --> 00:37:44,850
just because it's such a simple algorithm you can in principle apply to any graphical

604
00:37:46,410 --> 00:37:50,370
and historically i think the first person to do that one of the first was

605
00:37:50,370 --> 00:37:53,380
probably bob gallagher in the nineteen fifties

606
00:37:53,470 --> 00:37:57,530
in his thesis work at MIT he worked on those codes that i showed yesterday

607
00:37:57,530 --> 00:38:02,330
member that that sort of image denoising coding problem that i showed you

608
00:38:02,800 --> 00:38:04,390
he invented those codes

609
00:38:04,400 --> 00:38:07,680
i guess in the nineteen sixties nineteen sixty two

610
00:38:07,730 --> 00:38:12,800
but sort of history's funny back then people didn't have powerful enough computers to actually

611
00:38:12,800 --> 00:38:15,900
you know simulator look at these things behaved in practice

612
00:38:15,960 --> 00:38:20,200
so everybody basically just ignore his work from a b thirty plus years

613
00:38:20,250 --> 00:38:23,620
until turbo codes are we were rediscovered in the nineties

614
00:38:23,640 --> 00:38:27,810
and then people realized oh this is all very connected and these ideas were were

615
00:38:27,810 --> 00:38:31,570
deciding what

616
00:38:31,620 --> 00:38:34,550
another class of quality that are

617
00:38:34,590 --> 00:38:38,880
look at in the literature are actually i think i models from physics

618
00:38:38,930 --> 00:38:41,920
i'm not going to talk about those essentially the idea there is that there is

619
00:38:41,920 --> 00:38:45,520
some inherent energy in the system in the system

620
00:38:45,530 --> 00:38:50,110
essentially goes to distribution that minimizes the energy

621
00:38:50,130 --> 00:38:56,630
so this probabilistic models the important advantages that they have or sometimes an advantage is

622
00:38:56,630 --> 00:39:01,600
that predictive compared to the game theoretic models and again and again to model usually

623
00:39:01,600 --> 00:39:06,250
look at the concept of equilibrium and are often more than one could

624
00:39:06,250 --> 00:39:09,610
which is sometimes good sometimes bad

625
00:39:09,650 --> 00:39:13,100
the systems often have more than one could for example

626
00:39:13,140 --> 00:39:17,450
weather yahoo messenger becomes popular with gold park

627
00:39:17,470 --> 00:39:22,860
becomes popular both of these you could think of us two different conceivable that could

628
00:39:22,860 --> 00:39:24,330
be afterward

629
00:39:26,270 --> 00:39:29,690
if you just have to model you can predict which of the two is going

630
00:39:29,690 --> 00:39:33,620
to have a probabilistic models are more predictive in the sense that

631
00:39:34,020 --> 00:39:38,550
given that you make about the model about the system

632
00:39:38,600 --> 00:39:42,060
you're going to get the distribution for what happens in the

633
00:39:43,660 --> 00:39:47,570
and as a result we can try to do optimisation for example if you want

634
00:39:47,570 --> 00:39:50,670
to do marketing can find the best seed set two

635
00:39:50,690 --> 00:39:56,050
fine to coarse cynical on tools that in order to maximize the yield of your

636
00:39:56,060 --> 00:39:58,400
marketing campaign

637
00:39:58,420 --> 00:40:03,550
or you could also allows you to fit the data in order to estimate parameters

638
00:40:03,550 --> 00:40:09,840
of the the system is also an important feature of c so the model that

639
00:40:09,840 --> 00:40:11,320
i'm going to talk about

640
00:40:11,350 --> 00:40:15,280
it's going to be a probabilistic model and also includes the element of time

641
00:40:15,290 --> 00:40:16,510
so the the

642
00:40:16,600 --> 00:40:18,870
a few models that i mentioned in the previous

643
00:40:19,030 --> 00:40:20,900
it's like the

644
00:40:20,950 --> 00:40:26,250
i don't really consider the element of time is essentially is essentially static models but

645
00:40:26,260 --> 00:40:30,460
with the because the element of time because one feature that we have in our

646
00:40:33,190 --> 00:40:35,210
maybe a little more precise

647
00:40:35,220 --> 00:40:39,010
i'm assuming that i have a social network that schema as a graph g

648
00:40:39,050 --> 00:40:40,780
and i'm observing

649
00:40:40,790 --> 00:40:47,450
the social network over time period from year o to t and discretizing

650
00:40:48,110 --> 00:40:54,190
at any time period a number of agents can become active

651
00:40:54,210 --> 00:40:57,900
and at the end of the time period of time t

652
00:40:58,100 --> 00:41:00,360
we let w be the set of factor eight

653
00:41:01,390 --> 00:41:05,270
so not

654
00:41:05,330 --> 00:41:07,370
for influence models

655
00:41:07,430 --> 00:41:09,520
we assume that in each time

656
00:41:09,560 --> 00:41:11,730
each agent becomes active

657
00:41:11,790 --> 00:41:15,610
with probability with some probability p of a where a is the number of active

658
00:41:15,610 --> 00:41:17,910
friends that this agent already

659
00:41:18,770 --> 00:41:24,220
the probability of an agent becoming active is going to depend on number of factors

660
00:41:25,900 --> 00:41:29,720
and notice that i'm assuming here that this is done independently in time times so

661
00:41:29,720 --> 00:41:33,870
essentially i mean if you say if the number of for this guy doesn't have

662
00:41:34,280 --> 00:41:36,680
that this guy has doesn't change over time

663
00:41:36,700 --> 00:41:41,040
essentially this is going to be like apply process to determine what the name of

664
00:41:41,130 --> 00:41:43,870
that this is going come

665
00:41:43,890 --> 00:41:45,210
and one

666
00:41:45,230 --> 00:41:50,630
choice to be used for the function p of a is the logistic regression function

667
00:41:50,630 --> 00:41:53,710
which is the kind of thing

668
00:41:53,760 --> 00:41:56,170
estimating problem

669
00:41:56,800 --> 00:42:01,320
that means that the estimating log after the larger function of p of a which

670
00:42:01,320 --> 00:42:03,980
is a lot of one

671
00:42:04,000 --> 00:42:06,520
as a linear function of the

672
00:42:06,570 --> 00:42:10,810
explanatory value but you have and valuable

673
00:42:10,870 --> 00:42:14,620
are taking here is the log of the number of active friends plus one

674
00:42:14,640 --> 00:42:18,880
there is an you're taking logo sort of like number of active friends itself is

675
00:42:18,880 --> 00:42:24,260
that this is providing a better fit slightly benefit relatively consis that's not going to

676
00:42:24,260 --> 00:42:25,870
make much of a difference

677
00:42:25,870 --> 00:42:33,020
essentially all of the extra funding from the linear function of the same words

678
00:42:33,250 --> 00:42:38,050
because that means that are assuming that the function p of a set of this

679
00:42:38,050 --> 00:42:39,950
form of funding two

680
00:42:41,590 --> 00:42:43,730
and essentially this coefficient of

681
00:42:43,760 --> 00:42:45,870
it's something that measure social

682
00:42:45,900 --> 00:42:50,940
correlation because if alpha is larger that means that if you have more

683
00:42:50,950 --> 00:42:54,640
friends that increases the likelihood of becoming active

684
00:42:57,640 --> 00:43:01,210
OK so

685
00:43:01,980 --> 00:43:04,470
in order to estimate the

686
00:43:04,480 --> 00:43:07,530
social correlation the systemic just

687
00:43:07,570 --> 00:43:12,930
compute maximum likelihood estimates for the parameters of the data and alpha is going to

688
00:43:14,010 --> 00:43:18,830
somehow indicate how much social correlation having system

689
00:43:19,980 --> 00:43:21,370
to be more precise

690
00:43:21,370 --> 00:43:24,270
but the maximum like problem

691
00:43:24,480 --> 00:43:29,880
and why of denote the number of pairs of the user and i'm pretty user

692
00:43:29,880 --> 00:43:31,000
this came from

693
00:43:31,030 --> 00:43:32,640
writing that this is

694
00:43:32,710 --> 00:43:34,910
you will log of one minus

695
00:43:37,430 --> 00:43:39,870
but we're assuming you know that b is

696
00:43:39,930 --> 00:43:44,320
minor constituent here select is a small number

697
00:43:45,110 --> 00:43:50,350
so this is roughly equal to minus

698
00:43:50,640 --> 00:43:52,040
and that's just

699
00:43:54,400 --> 00:43:56,910
over and a plus

700
00:43:56,930 --> 00:43:58,380
and b

701
00:43:58,540 --> 00:44:02,190
and since then b is much smaller than in a this is approximately equal to

702
00:44:03,380 --> 00:44:05,060
and the

703
00:44:08,420 --> 00:44:11,550
so we're going to make this substitution

704
00:44:13,040 --> 00:44:18,150
this quantity the smaller volume of a at at the over

705
00:44:18,180 --> 00:44:20,640
the pure liquid

706
00:44:20,640 --> 00:44:22,140
since then since

707
00:44:22,150 --> 00:44:24,250
the concentration of b is low

708
00:44:24,260 --> 00:44:28,300
we can assume that this is just the molar volume of

709
00:44:28,340 --> 00:44:31,820
a general so in other words we can write

710
00:44:32,410 --> 00:44:34,860
a a

711
00:44:35,530 --> 00:44:38,530
star we can just write it is

712
00:44:38,580 --> 00:44:44,530
the a bar that that is we're not going to worry about changes in the

713
00:44:44,530 --> 00:44:49,550
molar volume either as a function of pressure a function of concentration at the low

714
00:44:49,560 --> 00:44:52,390
concentrations that were working

715
00:44:52,400 --> 00:44:53,590
and then

716
00:44:53,600 --> 00:44:55,950
note that in a times

717
00:44:56,060 --> 00:44:59,780
the eighty per mole

718
00:44:59,780 --> 00:45:01,740
it's just the total mileage

719
00:45:01,760 --> 00:45:03,560
not far

720
00:45:03,570 --> 00:45:08,610
not optimal query this is the more quantity multiplied by the number of rules

721
00:45:08,620 --> 00:45:13,560
so just gives a the total volume occupied by a

722
00:45:13,610 --> 00:45:14,390
all right

723
00:45:14,400 --> 00:45:15,570
and using

724
00:45:15,580 --> 00:45:17,370
these two

725
00:45:21,290 --> 00:45:23,610
then we have that our

726
00:45:24,690 --> 00:45:26,650
can't negative and b

727
00:45:26,790 --> 00:45:29,410
over a

728
00:45:29,430 --> 00:45:31,390
this result

729
00:45:32,200 --> 00:45:35,280
b over a

730
00:45:35,280 --> 00:45:36,450
times clause i

731
00:45:36,480 --> 00:45:40,320
is equal to zero

732
00:45:40,360 --> 00:45:41,970
and they will cancel

733
00:45:41,990 --> 00:45:43,230
and finally

734
00:45:44,890 --> 00:45:50,170
almost all the volume is due to a again because b is the minor constituent

735
00:45:50,190 --> 00:45:58,290
we can approximate further that the a is approximately equal to the

736
00:45:58,320 --> 00:45:59,030
all right

737
00:45:59,050 --> 00:46:02,090
so finally getting rid of the

738
00:46:02,100 --> 00:46:03,940
and a on the denominators

739
00:46:03,960 --> 00:46:05,210
so we're left with

740
00:46:05,220 --> 00:46:07,570
a simple expression

741
00:46:07,570 --> 00:46:09,590
finds the

742
00:46:09,600 --> 00:46:10,800
these are

743
00:46:11,330 --> 00:46:16,910
and b

744
00:46:18,540 --> 00:46:20,680
so in a very simple expression

745
00:46:20,700 --> 00:46:25,900
which is called the band harvick equation and expression in and look at how it

746
00:46:25,900 --> 00:46:31,590
resembles the ideal gas law right this is the pressure times volume equals the number

747
00:46:31,590 --> 00:46:33,420
of moles times RT

748
00:46:33,430 --> 00:46:37,110
of course really it's the change in pressure

749
00:46:37,150 --> 00:46:43,410
and this number of moles is the number of moles of gas constituent in solution

750
00:46:44,580 --> 00:46:48,560
but it has the same form familiar with

751
00:46:49,900 --> 00:46:52,210
we also sometimes it's convenient

752
00:46:53,900 --> 00:46:56,400
since and b

753
00:46:56,420 --> 00:46:57,680
over the

754
00:46:57,690 --> 00:46:59,920
that's just the concentration

755
00:46:59,920 --> 00:47:13,870
burn yes sir well then but

756
00:47:14,560 --> 00:47:18,840
1st of all of this is for those of you who were working on June

757
00:47:18,940 --> 00:47:23,060
C 4 year project I spoke with

758
00:47:23,680 --> 00:47:28,240
feel hiatus from draper lab who's going to be giving the lecture hall and you

759
00:47:28,420 --> 00:47:34,020
can see but he's not giving a lecture until the 3rd of November no that's

760
00:47:34,220 --> 00:47:38,660
the kind of late and so I asked him if he would be willing to

761
00:47:38,660 --> 00:47:43,100
meet with all of you who were working on June just so you could talk

762
00:47:43,100 --> 00:47:45,920
with him and ask questions

763
00:47:46,260 --> 00:47:50,330
you know if you want to give you the short version of his presentation is

764
00:47:50,330 --> 00:47:56,600
can be given November you can do that but I don't think he's our in-house

765
00:47:56,600 --> 00:48:01,420
resident expert and I figured it's better if you get a chance to talk to

766
00:48:01,610 --> 00:48:08,600
early so he is he has time freedom moral and here's sometime next week is

767
00:48:09,140 --> 00:48:14,760
out of 10 through today but if I know we have 2 teams working you

768
00:48:14,820 --> 00:48:19,510
and see if if you guys wanna get together and find out of their sometimes

769
00:48:19,510 --> 00:48:20,720
when you control

770
00:48:20,860 --> 00:48:26,260
it fill I'll give his contact information systems happy to do it would be much

771
00:48:26,260 --> 00:48:28,310
more convenient from his point of view if you could

772
00:48:29,000 --> 00:48:32,700
seem at the same time and talk about it OK

773
00:48:32,860 --> 00:48:39,230
I cylinder would you come up but I can say things happen and the 2nd

774
00:48:39,230 --> 00:48:40,640
thing want

775
00:48:41,800 --> 00:48:47,980
there was an interview printed in USA Today which posted on the class website with

776
00:48:47,980 --> 00:48:55,500
microphone the administrator of it says administrator says spatial was a mistake and so the

777
00:48:55,730 --> 00:48:59,560
question was you know what what do we intend to do about that in this

778
00:48:59,560 --> 00:49:00,950
class will let me actually

779
00:49:01,730 --> 00:49:08,100
read this specific words that Griffin uses because I think that's important Griffin said my

780
00:49:08,100 --> 00:49:13,860
opinion is that the shuttle was a design which was extremely aggressive and just barely

781
00:49:13,860 --> 00:49:21,480
possible and and and that's actually I think a slightly different way of looking at

782
00:49:21,480 --> 00:49:27,450
this meeting I would also say that Apollo was that was a project which was

783
00:49:27,450 --> 00:49:33,770
extremely aggressive and just barely possible and I think that it's actually NASA's business to

784
00:49:33,770 --> 00:49:38,990
do things which are aggressive and just barely possible now whether whether it was the

785
00:49:38,990 --> 00:49:47,700
right decisions for the country to abandon the exploration program after Apollo and and do

786
00:49:47,700 --> 00:49:52,170
the shovel and then later on the space station that's more in the thinking the

787
00:49:52,170 --> 00:49:57,580
political realm and as I think you've heard of both from Myers and and John

788
00:49:57,580 --> 00:50:04,140
long that of it in fact there were political determining factors which in fact which

789
00:50:04,140 --> 00:50:08,730
didn't really give us a lot of choices of just to remind you the the

790
00:50:08,730 --> 00:50:15,980
basic point of this course is is not the political and economic history of the

791
00:50:15,980 --> 00:50:21,640
show it's a technical exploration of how we did the shall also

792
00:50:22,340 --> 00:50:27,600
I think we would all agree that the concept of the show was extremely aggressive

793
00:50:27,760 --> 00:50:32,880
and the technology was being structures to it and it was just barely possible and

794
00:50:32,880 --> 00:50:34,540
yet we didn't have

795
00:50:34,550 --> 00:50:39,810
the the idea of this course is to understand how we didn't how the systems

796
00:50:39,810 --> 00:50:44,610
work I think it will be interesting when we get towards the end of the

797
00:50:44,610 --> 00:50:50,700
course that will sit down and relax and instead of having people there's there's to

798
00:50:51,050 --> 00:50:54,570
kind of open sessions towards the end of the thinking about what we want to

799
00:50:54,570 --> 00:50:58,330
do this in 1 of them I think we would maybe just talk a little

800
00:50:58,330 --> 00:51:04,150
bit of reflect on what we've learned and that'll give us an opportunity to discuss

801
00:51:04,520 --> 00:51:10,060
issues like this so that's all you can say about the site propose that we

802
00:51:10,060 --> 00:51:13,670
will discuss this further today because we really

803
00:51:13,700 --> 00:51:20,930
fortunate to have readily and code is going to introduce informally I'll just say that

804
00:51:21,020 --> 00:51:26,430
when I was at Johnson Space Center last spring and and that 1 of the

805
00:51:26,430 --> 00:51:31,350
older managers there and I was telling about our plans for this course and hardware

806
00:51:31,350 --> 00:51:35,510
and was going to be a visiting professor here and we inviting some of the

807
00:51:35,520 --> 00:51:39,150
the experts in the early design of the shuttle and he said well there's 1

808
00:51:39,150 --> 00:51:45,210
guy you absolutely have to get past well we've gotten were very very fortunate the

809
00:51:45,340 --> 00:51:49,210
error all 3 you and let you explain a little bit more why we're so

810
00:51:53,400 --> 00:52:03,230
what that same problem have found inside of our time find best lives in a

811
00:52:03,230 --> 00:52:09,970
place called Smithfield Texas and Splitsville Texas he said when people ask until Texas is

812
00:52:09,980 --> 00:52:14,730
he said it's it's about a few minutes after you pass reasons speak so it's

813
00:52:14,730 --> 00:52:19,460
not it's not overall the place I finally fell best and he is truly an

814
00:52:19,460 --> 00:52:28,250
outstanding character in the thing that's so important is that Annex to me is from

815
00:52:28,250 --> 00:52:35,630
my vantage point is really the linchpin you might say putting the system together aerodynamics

816
00:52:35,630 --> 00:52:40,300
and makes the system come alive and as you can hear from the various speakers

817
00:52:40,300 --> 00:52:45,300
from tom moser and from the you and we we talked about about the guides

818
00:52:45,300 --> 00:52:50,630
navigation control it's important for the structures evidences brought for the structures that support for

819
00:52:50,630 --> 00:52:52,230
the hydrophilic space

820
00:52:52,300 --> 00:52:56,130
this is called the lipid bilayer and obviously it's highly effective

821
00:52:56,140 --> 00:52:58,930
separating these two aqueous compartments

822
00:52:58,950 --> 00:53:02,010
in eukaryotic cells as i mentioned last time

823
00:53:02,020 --> 00:53:04,120
there's an enormous

824
00:53:04,120 --> 00:53:08,630
premium placed on separating and segregating different aqueous compartments

825
00:53:08,650 --> 00:53:11,130
which is invariably achieve

826
00:53:11,140 --> 00:53:15,130
through the device of constructing these lipid bilayers

827
00:53:15,160 --> 00:53:16,400
here's the vesicle

828
00:53:16,410 --> 00:53:20,710
the vesicle is more complicated than myself because if you look at the membrane lining

829
00:53:20,710 --> 00:53:21,910
the vesicle

830
00:53:21,920 --> 00:53:26,420
you see it's actually lipid bilayer but one in three dimensional space is actually a

831
00:53:27,510 --> 00:53:31,530
in the case of this vesicle we can well imagine that on the inside of

832
00:53:31,530 --> 00:53:32,500
the vesicle

833
00:53:32,510 --> 00:53:37,670
water is kept can be stored on the outside of vesicle water can be stored

834
00:53:37,770 --> 00:53:40,120
in many of the membranes that we see

835
00:53:40,130 --> 00:53:46,090
within the cytoplasm of cells are actually constructed on this kind of design

836
00:53:46,160 --> 00:53:49,940
so here we could so when we draw for example in this case the gold

837
00:53:49,990 --> 00:53:54,090
apparatus which i mentioned you in passing last time we met

838
00:53:54,140 --> 00:53:58,210
each one of these membranes here it's obviously drawn double line but whenever you see

839
00:53:58,210 --> 00:54:01,610
a membrane indicated implicit in that drawing

840
00:54:01,660 --> 00:54:05,630
it is the fact that each one of these membranes is actually a bilayer

841
00:54:05,680 --> 00:54:10,460
they're not there are never any monolayers of lipids in living cells

842
00:54:10,470 --> 00:54:14,810
each one of these vesicles you see here is actually lipid bilayer with an aqueous

843
00:54:14,810 --> 00:54:18,100
inside and once again aqueous on the outside

844
00:54:18,100 --> 00:54:24,730
again much to of the thermodynamic stability that allows these vesicles to remain intact rather

845
00:54:24,730 --> 00:54:26,450
than just few support

846
00:54:26,470 --> 00:54:33,670
it is created by these hydrophilic and hydrophobic phobic forces which ties such molecules together

847
00:54:33,670 --> 00:54:36,710
or will rip them apart

848
00:54:36,720 --> 00:54:42,670
now in truth there are yet other kinds of forces that govern the affinity of

849
00:54:42,670 --> 00:54:45,590
molecules to one another

850
00:54:45,630 --> 00:54:47,560
for example

851
00:54:47,580 --> 00:54:53,190
let's imagine a situation where we have a and ionize

852
00:54:53,210 --> 00:54:57,340
i had a city group of the so we just talked about before

853
00:54:58,110 --> 00:55:01,540
by the way here but still draw the negative charge on one of these two

854
00:55:01,540 --> 00:55:03,700
oxygen is if you can see that

855
00:55:03,750 --> 00:55:06,930
but the truth is that the electrons are swarming back and forth

856
00:55:06,980 --> 00:55:12,310
so the negative charge is is shared equally the net negative one electron charge is

857
00:55:12,310 --> 00:55:14,920
shared equally between these two oxygen atoms

858
00:55:14,970 --> 00:55:19,480
and this is obviously an area of great electoral negativity

859
00:55:19,530 --> 00:55:25,640
independent of that let's imagine up here we have a basic group

860
00:55:25,730 --> 00:55:28,920
let's see and the mean group over here

861
00:55:28,950 --> 00:55:31,590
and the fact of the matter is a main groups

862
00:55:31,590 --> 00:55:34,160
NH two groups that's what i mean is

863
00:55:34,170 --> 00:55:40,340
here's the main group this is the carboxylic group and the main group which is

864
00:55:40,340 --> 00:55:44,160
used very often in biochemistry

865
00:55:44,160 --> 00:55:49,450
it actually has an affinity it has an unpaired set of electrons on the nitrogen

866
00:55:49,660 --> 00:55:53,130
and so he likes to attract protons to it

867
00:55:53,140 --> 00:55:55,820
which makes it cause it to be called basic

868
00:55:55,830 --> 00:55:59,040
and this attraction scavenging of protons

869
00:55:59,090 --> 00:56:02,350
perhaps from the water will obviously give this

870
00:56:02,480 --> 00:56:04,340
the whole group here

871
00:56:04,340 --> 00:56:07,710
and that positive charge charge equal to the charge of one

872
00:56:10,430 --> 00:56:14,430
here once again we can imagine this is hydrophilic because

873
00:56:15,130 --> 00:56:20,650
charge group can once again also associate quite intimately with aqueous solvent

874
00:56:20,670 --> 00:56:23,380
now independent of

875
00:56:23,380 --> 00:56:26,100
any other forces that might exist here

876
00:56:26,110 --> 00:56:29,930
indeed one could imagine situations where there is the sharing of the proton and therefore

877
00:56:29,950 --> 00:56:32,670
hydrogen bonds form between these two

878
00:56:32,690 --> 00:56:38,390
independent of that is the simple electrostatic interaction of these two groups

879
00:56:38,390 --> 00:56:43,250
that is the charge the mutual attraction of positive and negative groups one to the

880
00:56:44,790 --> 00:56:47,860
and electrostatic interactions you can quantify

881
00:56:47,860 --> 00:56:51,060
exactly how many killer calories them all there is because

882
00:56:51,070 --> 00:56:56,370
the the energetic value electrostatic interactions

883
00:56:56,370 --> 00:57:00,630
sixty is the first support group which is not a crime

884
00:57:02,620 --> 00:57:04,630
so i mean you can be fooled

885
00:57:04,640 --> 00:57:09,550
but i mean i you know that now you get going to an IQ test

886
00:57:09,590 --> 00:57:12,360
well you answer sixty one sixty

887
00:57:14,170 --> 00:57:15,530
sixty one

888
00:57:15,530 --> 00:57:20,130
i mean this case because of the much more familiar concepts and you would say

889
00:57:20,130 --> 00:57:22,050
OK i mean

890
00:57:22,070 --> 00:57:25,580
the the guy who came up with a sequence probably thought about prime numbers and

891
00:57:25,590 --> 00:57:27,770
simple groups

892
00:57:27,770 --> 00:57:32,970
if i have time i mean so so there we have some bias towards culture

893
00:57:34,120 --> 00:57:38,090
or maybe not maybe prime numbers are much more fundamental than groups

894
00:57:38,100 --> 00:57:41,290
but maybe it's just because of our culture

895
00:57:41,400 --> 00:57:47,800
and i will tell you briefly how to put this cultural bias in this universe

896
00:57:47,800 --> 00:57:50,170
OK so this nice website

897
00:57:50,190 --> 00:57:52,920
they can

898
00:57:52,940 --> 00:57:56,690
just type in the beginning of some sequences and it is the rule

899
00:57:56,710 --> 00:57:58,510
large rule

900
00:57:58,620 --> 00:58:02,040
based on some seem is my algorithms

901
00:58:02,080 --> 00:58:08,400
for finding the patron behind the sequence and are often if you do research

902
00:58:08,420 --> 00:58:12,790
you it a force for any one two two three four you get some numbers

903
00:58:12,800 --> 00:58:17,220
and you want to find the general rule behind it which can be quite complex

904
00:58:17,870 --> 00:58:20,370
if you had the rule to prove it is much easier to find the rules

905
00:58:20,380 --> 00:58:23,410
so you can just type in the numbers five two rules and then afterwards to

906
00:58:23,410 --> 00:58:26,570
prove what you want to prove often much easier

907
00:58:27,060 --> 00:58:31,020
i mean it's sort of smart because i mean if you look twice the prime

908
00:58:31,270 --> 00:58:35,350
i mean very recognised first from

909
00:58:41,460 --> 00:58:43,430
after this example the question

910
00:58:43,520 --> 00:58:45,570
this is there a unique principle

911
00:58:45,630 --> 00:58:48,140
which allows us to formally arrive

912
00:58:48,180 --> 00:58:50,030
if the prediction which

913
00:58:50,060 --> 00:58:52,280
they coincide

914
00:58:52,330 --> 00:58:55,210
most of the time with our intuitive guess

915
00:58:55,220 --> 00:58:56,250
or even better

916
00:58:56,260 --> 00:58:58,230
which gives us in some sense

917
00:58:58,270 --> 00:59:02,980
most likely the best or correct answer whatever that means

918
00:59:04,820 --> 00:59:08,380
and luckily the answer is yes and this is a common phrase

919
00:59:08,410 --> 00:59:12,770
and all countries is a very simple principle it just tells you

920
00:59:13,860 --> 00:59:18,130
you have many explanations for your data which are equally good take the most simple

921
00:59:21,460 --> 00:59:22,690
so and

922
00:59:22,810 --> 00:59:24,820
amazing things the work

923
00:59:24,870 --> 00:59:26,570
and you can prove that

924
00:59:26,600 --> 00:59:29,120
and i mean if you look at the previous example

925
00:59:29,190 --> 00:59:30,380
makes sense

926
00:59:30,390 --> 00:59:32,440
in all cases

927
00:59:32,490 --> 00:59:35,330
maybe the sunrise the tricky

928
00:59:35,420 --> 00:59:37,860
so actually

929
00:59:37,940 --> 00:59:42,350
occam's razor can serve as a foundation of machine learning

930
00:59:42,400 --> 00:59:44,130
some would disagree

931
00:59:44,590 --> 00:59:48,460
i think you could go even further it

932
00:59:48,570 --> 00:59:51,000
the fundamental principle in science

933
00:59:51,020 --> 00:59:52,330
i would even go

934
00:59:52,350 --> 00:59:56,850
further i would say that the definition of science straight from the what we try

935
00:59:56,880 --> 01:00:03,120
to do we try to understand our world understanding our world means collecting data

936
01:00:03,130 --> 01:00:05,380
and finding regularities in them

937
01:00:05,390 --> 01:00:10,440
regularities means finding models which are simple that simpler than the data themselves

938
01:00:11,210 --> 01:00:15,110
the symbol the model as long as it equally good

939
01:00:15,170 --> 01:00:22,520
always finished so the symbol the model that

940
01:00:23,570 --> 01:00:27,280
the more typically got attracted to it so you live

941
01:00:27,290 --> 01:00:28,380
o comes

942
01:00:28,400 --> 01:00:30,710
maybe even unconsciously

943
01:00:57,330 --> 01:00:59,910
but what you

944
01:00:59,920 --> 01:01:01,430
what you could do

945
01:01:01,480 --> 01:01:03,970
you know just just to we camera

946
01:01:04,070 --> 01:01:07,830
and place it wherever you want to

947
01:01:07,840 --> 01:01:12,000
and i mean take i mean it in physics and chemistry i mean small molecules

948
01:01:12,000 --> 01:01:16,330
or something i special measures by biology medicine or whatever say

949
01:01:16,330 --> 01:01:21,680
let's be out in the optical space take the camera and move around and just

950
01:01:21,680 --> 01:01:23,030
sequence of data

951
01:01:23,080 --> 01:01:26,740
without any pre processing and then you ask you know built simple models from that

952
01:01:26,740 --> 01:01:27,580
with which

953
01:01:27,630 --> 01:01:31,570
i you typically doing in a uniform way but you are use think deeply about

954
01:01:31,570 --> 01:01:34,490
the data to try to extract and so on but you can ask i mean

955
01:01:34,500 --> 01:01:35,820
is there a formal way

956
01:01:35,830 --> 01:01:37,830
what is what's behind what you're doing

957
01:01:51,800 --> 01:01:57,060
no no no no no you can do that and if it makes things simpler

958
01:01:57,370 --> 01:01:58,590
so for instance

959
01:01:58,590 --> 01:02:03,280
so what i mean here so now think about the

960
01:02:04,040 --> 01:02:09,030
the o's as the output at each timestep as representing a probability

961
01:02:09,040 --> 01:02:12,540
distribution for example the probabilities for each of the symbols

962
01:02:12,550 --> 01:02:17,720
that x can take at each timestep and then what we can be

963
01:02:17,730 --> 01:02:24,990
doing is we can be able to use a recurrent net to generate a sequence

964
01:02:25,160 --> 01:02:29,050
so the daughter arrows here this figure mean that we can sample

965
01:02:29,510 --> 01:02:32,150
when we use a recurrent net in its generative mode

966
01:02:32,580 --> 01:02:35,970
his to be just free-running it's going to produce its own inputs

967
01:02:35,970 --> 01:02:40,480
so at time t is going to produce a probability distribution

968
01:02:40,490 --> 01:02:45,890
over the random variable x t plus one given hold previous ones

969
01:02:46,350 --> 01:02:50,090
and we can be able to draw samples for example pick a a a the

970
01:02:50,100 --> 01:02:54,540
next character given the distribution represented by t so

971
01:02:54,550 --> 01:02:57,620
you can imagine achieving a softmax overall a the

972
01:02:58,170 --> 01:03:03,080
symbol values and we drop particular symbol now that becomes

973
01:03:03,090 --> 01:03:07,040
the next input now i talked about symbols but

974
01:03:07,040 --> 01:03:10,370
could be vectors real vectors it could be kind random variables

975
01:03:10,800 --> 01:03:14,250
so what we doing here when we train this with maximum likelihood

976
01:03:14,260 --> 01:03:19,190
is saying we're given a sequence x one to xt and would like

977
01:03:19,680 --> 01:03:23,730
that are network gives a high probability that sequence we can

978
01:03:23,740 --> 01:03:27,300
decompose the joint probability of the sequence x one to xt as a

979
01:03:27,310 --> 01:03:29,980
product of conditionals so that's what you see on

980
01:03:30,020 --> 01:03:32,410
on the right hand side of the equation on top

981
01:03:33,150 --> 01:03:36,500
and each conditional is of the form p of the next symbol or the

982
01:03:36,510 --> 01:03:40,340
next observation that have the symbol

983
01:03:40,760 --> 01:03:44,410
given all previous ones of course we multiply all these probabilities

984
01:03:44,410 --> 01:03:48,240
and you know it's just the standard the composition of joint

985
01:03:48,250 --> 01:03:51,680
into a product of conditionals where the order here

986
01:03:52,290 --> 01:03:55,990
is that temporal order that is usually the natural thing to consider

987
01:03:56,300 --> 01:04:01,240
for sequential data so the training objective will just be

988
01:04:01,520 --> 01:04:04,890
minus the log of the the thing on the top which means that it's

989
01:04:04,900 --> 01:04:09,020
some of negative log probabilities for these conditionals

990
01:04:09,030 --> 01:04:13,290
so we're trying to predict that actually observed next

991
01:04:14,040 --> 01:04:16,000
symbol given all the previous symbols

992
01:04:16,780 --> 01:04:20,500
and and we maximize the probability of of getting that thing

993
01:04:20,500 --> 01:04:23,040
right so it's just like a classification problem

994
01:04:23,040 --> 01:04:26,460
at each timestep and of course replace classification by regression

995
01:04:26,460 --> 01:04:29,320
if it's real valued or any other kind of of types of random

996
01:04:29,320 --> 01:04:35,190
variable so that's the that's the sense in which recurrent nets

997
01:04:35,200 --> 01:04:37,310
can be thought about as a generative

998
01:04:37,590 --> 01:04:41,020
model and if you think about it now in terms of graphical models

999
01:04:41,030 --> 01:04:43,400
for those of you who know bit about that

1000
01:04:44,410 --> 01:04:48,520
we're thinking what you see is that there are no latent variables

1001
01:04:48,890 --> 01:04:52,990
are least know stochastically variables you can think of the s

1002
01:04:52,990 --> 01:04:55,420
is as a very special kinds of latent variables

1003
01:04:56,180 --> 01:04:58,450
but they're determinist the functions of of

1004
01:04:58,570 --> 01:05:01,900
everything else so the esses are deterministic functions of the

1005
01:05:01,900 --> 01:05:06,880
previous as of the previous x's through the equation we saw in the

1006
01:05:07,420 --> 01:05:10,860
previous slide right so the s t here's a completely deterministic

1007
01:05:10,860 --> 01:05:15,940
function of all previous x's and so you can actually think of

1008
01:05:15,950 --> 01:05:19,890
this as as in different ways from graphical model point of view

1009
01:05:19,900 --> 01:05:23,860
but if we ignore as is as as latent variables because they're

1010
01:05:23,870 --> 01:05:26,610
kind of deterministic then it's a fully observed

1011
01:05:27,810 --> 01:05:32,980
model where which means that we can just apply max like you very

1012
01:05:32,980 --> 01:05:36,330
ways and compute the tractable gradient and everything is easy and

1013
01:05:36,330 --> 01:05:39,650
simple and we can model the joint distribution

1014
01:05:39,680 --> 01:05:43,010
you can also think of s as latent variables but as i said there

1015
01:05:43,010 --> 01:05:46,660
are deterministic and the the role to play a is to make the

1016
01:05:47,550 --> 01:05:51,460
graphical model both statistically and computationally

1017
01:05:51,470 --> 01:05:55,300
more tractable so what you notice is that through this

1018
01:05:56,500 --> 01:05:59,730
through this equation defines as in terms of the previous x's

1019
01:06:01,970 --> 01:06:05,410
you you actually have a full dependency

1020
01:06:05,600 --> 01:06:09,710
of all the previous x's conditioning the next one so you

1021
01:06:09,710 --> 01:06:12,370
know it's not a graph model where we have removed any of the

1022
01:06:12,370 --> 01:06:15,470
arcs is fully connected directed graph model right so there's

1023
01:06:15,470 --> 01:06:18,580
no assumption know in the conditional independence assumption

1024
01:06:18,580 --> 01:06:23,220
you can model and this bution however in general for graphical

1025
01:06:23,220 --> 01:06:25,560
model you think that if you have this fully connected thing it

1026
01:06:25,560 --> 01:06:28,840
would be very expensive the number of parameters could blow up

1027
01:06:28,840 --> 01:06:30,620
to welcome to my mighty

1028
01:06:31,520 --> 01:06:32,250
tom friedman

1029
01:06:32,920 --> 01:06:37,030
who you know the foreign affairs columnist for the new york times

1030
01:06:37,890 --> 01:06:43,300
i will admit up front that's one of the few columns i read with great regularity

1031
01:06:44,110 --> 01:06:48,750
finding the content always stimulating whether or not i agree with one hundred percent

1032
01:06:49,290 --> 01:06:50,810
but as i told him earlier today

1033
01:06:51,940 --> 01:06:54,240
his titles are the best in the world

1034
01:06:54,780 --> 01:06:55,940
anybody who could write

1035
01:06:56,450 --> 01:06:57,580
dancing alone

1036
01:06:58,290 --> 01:07:00,630
war last week broccoli

1037
01:07:01,250 --> 01:07:04,700
all which enables you to remember brussels sprouts

1038
01:07:05,250 --> 01:07:05,850
whatever it is

1039
01:07:06,340 --> 01:07:07,960
i thought

1040
01:07:12,720 --> 01:07:17,020
i think it is you know he has won three pulitzer prizes

1041
01:07:18,090 --> 01:07:22,000
three blocks that's all the snow very well from beirut to jerusalem

1042
01:07:22,550 --> 01:07:27,390
the lexus and the olive tree which i remember alex darvill of introduced me to a couple years ago

1043
01:07:28,080 --> 01:07:29,210
a little more recently

1044
01:07:29,780 --> 01:07:31,430
longitude and latitude

1045
01:07:32,240 --> 01:07:36,180
he is a graduate the hour neighboring institution brand ice university

1046
01:07:36,690 --> 01:07:38,290
in mediterranean studies

1047
01:07:38,930 --> 01:07:43,540
and then got a master's degree in middle east studies at oxford university

1048
01:07:44,750 --> 01:07:46,110
so the reason is here today

1049
01:07:46,680 --> 01:07:47,860
i'm going to tell you the truth

1050
01:07:48,550 --> 01:07:51,230
i was in a hotel somewhere rather late at night

1051
01:07:52,270 --> 01:07:56,470
doing what i usually do hotels is lying in bed flipping through channels

1052
01:07:57,080 --> 01:08:00,690
anne i came across the last few minutes for the charlie rose show

1053
01:08:01,770 --> 01:08:02,980
and charlie was

1054
01:08:03,370 --> 01:08:08,770
interviewing tom they are having a great discussion these are talking about all these flatness and listening

1055
01:08:09,370 --> 01:08:11,960
and also i recognised with a star

1056
01:08:13,270 --> 01:08:15,400
here is really important

1057
01:08:15,910 --> 01:08:17,790
powerful public voice

1058
01:08:18,650 --> 01:08:20,440
in a very articulate manner

1059
01:08:21,030 --> 01:08:25,200
speaking the things that are very important to us here at the mighty

1060
01:08:26,200 --> 01:08:28,720
things such as these values of openness

1061
01:08:29,650 --> 01:08:33,380
andy things such as the importance of science and technology

1062
01:08:34,130 --> 01:08:39,480
and the importance of young men and women being educated in these fields to the future of this country

1063
01:08:40,190 --> 01:08:41,500
in addition of course

1064
01:08:42,050 --> 01:08:45,120
to the fundamental hypothesis fundamental mission

1065
01:08:46,040 --> 01:08:47,680
helping us to understand

1066
01:08:48,260 --> 01:08:53,740
a little more clearly some of the most important trends going on in the world he was of-course

1067
01:08:54,440 --> 01:08:56,750
discussing his new book the world is flat

1068
01:08:57,270 --> 01:09:01,960
which is in its second week i guess is number one on the new york times bestseller list

1069
01:09:03,440 --> 01:09:06,790
in just a moment in time is going to address this is gonna take a

1070
01:09:06,790 --> 01:09:08,380
little q and eighty and that's

1071
01:09:08,790 --> 01:09:11,420
well things of just about five o'clock

1072
01:09:12,000 --> 01:09:15,040
but thereafter are starting at five fifteen

1073
01:09:15,690 --> 01:09:20,050
there will be a reception high school how many people food is planned for

1074
01:09:20,760 --> 01:09:21,960
and they book-signing

1075
01:09:22,430 --> 01:09:28,020
downstairs and they washroom ten one o five times welcomed mighty

1076
01:09:44,110 --> 01:09:45,390
so thank you very much further

1077
01:09:45,850 --> 01:09:51,350
having me it's a it's a tree and an honor to be here enormously stimulating day

1078
01:09:52,120 --> 01:09:54,930
already so i look forward to this conversation

1079
01:09:55,920 --> 01:10:01,640
thank you also for getting my book titles right you know i've often been introduces the of from beirut lebanon

1080
01:10:06,540 --> 01:10:09,160
the lexus the palm tree that's the problem

1081
01:10:10,400 --> 01:10:13,930
end on latitudes and attitudes is not a jimmy buffett's song

1082
01:10:16,510 --> 01:10:20,500
end and thank you also for noting that i i i my book ascended to

1083
01:10:20,500 --> 01:10:24,480
number one this week and the new york times bestsellers i finally made it had

1084
01:10:24,570 --> 01:10:25,230
jane fonda

1085
01:10:27,960 --> 01:10:34,740
because i was gonna retire my book flat world flat abs if i didn't say so but i i

1086
01:10:37,540 --> 01:10:38,530
i'm itself

1087
01:10:39,280 --> 01:10:43,270
so i thought i'd talk for the next thirty minutes or so and just the origins of this book and

1088
01:10:43,750 --> 01:10:47,620
they accidental weight came about and don't give you a sense that the court pieces

1089
01:10:47,630 --> 01:10:49,990
and really look forward to dialog

1090
01:10:51,550 --> 01:10:52,710
this book really was

1091
01:10:53,520 --> 01:10:54,680
an accident on

1092
01:10:55,330 --> 01:10:59,440
but those u remark on know that i'm really i became a foreign affairs columnist

1093
01:10:59,440 --> 01:11:01,210
in january nineteen ninety five and

1094
01:11:01,640 --> 01:11:05,490
between nineteen ninety five and d of september tenth two thousand one

1095
01:11:05,940 --> 01:11:11,570
my column really oscillated between what i would call access issues and olive tree issues

1096
01:11:12,200 --> 01:11:14,420
issues about trade technology finance

1097
01:11:14,910 --> 01:11:18,070
on many issues about geopolitics and ethnic conflict

1098
01:11:18,590 --> 01:11:22,730
and on my was really in the kind-of oscillation mode they say right up until

1099
01:11:23,530 --> 01:11:26,180
september eleventh when applied what happened that day

1100
01:11:26,610 --> 01:11:29,320
i really dropped the whole x story like a stone

1101
01:11:29,840 --> 01:11:35,040
and went off and covered the all three wars common really spent three years after nine eleven

1102
01:11:35,570 --> 01:11:40,380
traveling almost exclusively in the air muslim world trying to understand the roots nine eleven and

1103
01:11:40,870 --> 01:11:43,370
covering the war in afghanistan and in

1104
01:11:45,030 --> 01:11:49,510
and i was really in that mode on right up to the last january january

1105
01:11:49,540 --> 01:11:51,620
two thousand four but sixteen months ago

1106
01:11:54,300 --> 01:11:59,240
i started doing documentaries recently for the discovery channel we don't want the roots nine eleven

1107
01:11:59,730 --> 01:12:03,320
we did one on the on the wall potentials built in in the in the

1108
01:12:03,320 --> 01:12:08,950
west bank and in january two thousand four we're sitting around with our discovery of

1109
01:12:09,010 --> 01:12:09,910
new york times team

1110
01:12:10,310 --> 01:12:12,830
trying to figure out what to do are next documentary on

1111
01:12:13,470 --> 01:12:17,330
and at the time the issue of america's standing in the world america's low standing

1112
01:12:17,330 --> 01:12:19,050
in the world was a very hot issue

1113
01:12:19,620 --> 01:12:21,910
and so i had this idea i said why don't we

1114
01:12:22,390 --> 01:12:25,190
when we got a call centers all over the world

1115
01:12:26,080 --> 01:12:31,630
an interview young people who spend their days imitating americans on what they think of america

1116
01:12:32,400 --> 01:12:35,130
after make fun can have almost double mirror

1117
01:12:35,480 --> 01:12:41,330
and we are literally a budget that's show when on certain presidential democratic hopeful named

1118
01:12:41,330 --> 01:12:44,530
john carry on came out with his blast against

1119
01:12:45,270 --> 01:12:47,720
benedict arnold executives who outsource

1120
01:12:49,180 --> 01:12:52,380
as you recall the whole issue outsourcing just exploded

1121
01:12:52,870 --> 01:12:54,020
onto the world stage

1122
01:12:54,490 --> 01:12:59,740
endowment front pages a business week and fortune and forums and the new york times and the wall street journal

1123
01:13:00,230 --> 01:13:01,990
so i said no time timeout wider

1124
01:13:02,820 --> 01:13:04,520
why don't we just go to bangalore

1125
01:13:05,120 --> 01:13:06,730
he outsourcing capital of india

1126
01:13:07,270 --> 01:13:12,360
end on our the silicon valley of india and do a documentary called others side

1127
01:13:12,360 --> 01:13:16,240
about outsourcing where we look at this phenomenon from the ground up

1128
01:13:16,960 --> 01:13:18,900
and that's what we what we did

1129
01:13:19,470 --> 01:13:20,170
and so in

1130
01:13:20,850 --> 01:13:26,090
on february fifteen two thousand four set of to bangalore with are discovery crew

1131
01:13:27,450 --> 01:13:29,810
we shot about sixty hours of interviews

1132
01:13:30,280 --> 01:13:32,480
and in the course over ten eleven days

1133
01:13:33,130 --> 01:13:36,500
and over the course of those sixty hours of interviews i got

1134
01:13:38,650 --> 01:13:40,080
six hour and search

1135
01:13:41,380 --> 01:13:42,660
and it was not the food

1136
01:13:45,070 --> 01:13:45,600
it was

1137
01:13:46,180 --> 01:13:49,120
the sense i got with each passing it

1138
01:13:50,920 --> 01:13:52,640
while i had been sleeping

1139
01:13:53,300 --> 01:13:54,910
while i have been of covering

1140
01:13:55,500 --> 01:13:56,510
the nine eleven wars

1141
01:13:57,380 --> 01:14:02,150
something really big it happened in this globalization story

1142
01:14:02,990 --> 01:14:03,590
and i had

1143
01:14:03,990 --> 01:14:04,860
completely missed

1144
01:14:07,650 --> 01:14:09,450
thought hit me somewhere between

1145
01:14:09,450 --> 01:14:11,390
good afternoon everyone

1146
01:14:11,440 --> 01:14:19,880
after i have to admit that introducing frank wilczek makes me a little nervous

1147
01:14:19,940 --> 01:14:25,470
so so i went to the web

1148
01:14:25,510 --> 01:14:28,670
and i looked at one of his

1149
01:14:28,690 --> 01:14:33,940
enormous number of prices and and decided to read

1150
01:14:33,970 --> 01:14:38,830
the citation or the least the press release from

1151
01:14:38,900 --> 01:14:40,260
the lawrence medal

1152
01:14:40,270 --> 01:14:45,720
which was awarded to him in the fall of two thousand two

1153
01:14:45,730 --> 01:14:50,760
and then i'll add a few remarks as i go along with that and i'm

1154
01:14:50,760 --> 01:14:53,300
not reading all of

1155
01:14:53,330 --> 01:14:57,020
lawrence medal awarded to american physicist frank wilczek

1156
01:14:57,090 --> 01:15:02,970
professor wilczek is one of the most influential theoretical physicist of his generation he was

1157
01:15:02,970 --> 01:15:08,300
an instrumental figure in the discovery of the phenomenon known as asymptotic freedom

1158
01:15:08,320 --> 01:15:12,380
this is the phenomenon whereby the building blocks which make up the nucleus of an

1159
01:15:12,380 --> 01:15:17,910
atom cork's behave free particles when they are close together but become more strongly attracted

1160
01:15:17,930 --> 01:15:22,910
to each other as the distance between them increases this theory forms the key to

1161
01:15:22,910 --> 01:15:29,820
the interpretation of almost all experimental studies involving modern particle accelerators in the view of

1162
01:15:29,820 --> 01:15:35,540
the academy will will checks for is characterized by both its breath and step

1163
01:15:35,580 --> 01:15:39,990
professor well wilczek studied at the university of chicago

1164
01:15:40,010 --> 01:15:41,940
i should cause there

1165
01:15:41,960 --> 01:15:45,740
i got my bachelor's degree at the university of chicago

1166
01:15:45,800 --> 01:15:52,850
a couple years before frank and jerry friedman got his bachelor's degree in chicago larry

1167
01:15:52,850 --> 01:15:55,290
rosen sent so

1168
01:15:55,300 --> 01:16:01,010
we are chary and larry and i in good company

1169
01:16:01,080 --> 01:16:03,770
then he went on to princeton

1170
01:16:03,770 --> 01:16:10,980
it says where he obtained his doctorate in nineteen seventy four he later became professor

1171
01:16:10,980 --> 01:16:16,780
of physics at princeton and the university of california santa barbara since two thousand he

1172
01:16:16,780 --> 01:16:20,310
has held firm in freshwater chair at MIT

1173
01:16:20,330 --> 01:16:25,270
he is a member of the american the american national academy of sciences and how

1174
01:16:25,270 --> 01:16:30,210
has received the dirac medal and the michaelson morley prize

1175
01:16:30,230 --> 01:16:32,780
many others are the

1176
01:16:32,800 --> 01:16:37,550
press release goes on to point out that many winners of the lawrence medal have

1177
01:16:37,550 --> 01:16:44,250
later gone on to win the nobel prize examples include max plank wolfgang pauli

1178
01:16:44,270 --> 01:16:46,000
petrus to buy

1179
01:16:46,020 --> 01:16:51,680
and then there are a few more recent ones kawai mcnair cornell

1180
01:16:51,700 --> 01:16:53,090
here to share and

1181
01:16:53,110 --> 01:16:57,590
during character after that that tries to win

1182
01:16:58,020 --> 01:17:04,360
about the same time maybe a few months later we learn that frank won the

1183
01:17:04,360 --> 01:17:06,140
lillian fell prize

1184
01:17:06,210 --> 01:17:09,210
the american physical society in this prize is given

1185
01:17:09,240 --> 01:17:13,890
to someone who has done great things in physics but also is an outstanding communicator

1186
01:17:13,890 --> 01:17:19,250
in the citation reads for his role in the development of asymptotic freedom in other

1187
01:17:19,250 --> 01:17:22,180
aspects of quantum chromodynamics

1188
01:17:22,200 --> 01:17:27,760
a cornerstone of the standard model for his remarkable versatility and research in condensed matter

1189
01:17:27,760 --> 01:17:33,520
in astrophysics as well as particle physics and for his outstanding ability to lecture and

1190
01:17:33,520 --> 01:17:36,980
write with clarity profundity and enthusiasm

1191
01:17:37,020 --> 01:17:41,890
and anyone who has read his articles in physics today will certainly agree with the

1192
01:17:41,890 --> 01:17:44,500
latter when

1193
01:17:45,200 --> 01:17:46,550
bob shafi

1194
01:17:46,590 --> 01:17:51,990
and i worked together with operational to bring frank to princeton

1195
01:17:52,060 --> 01:17:58,360
i certainly felt was one of the greatest and most successful collaborations of my career

1196
01:17:58,370 --> 01:18:04,620
and i'm really proud that we have here as as bob cathy once said frank

1197
01:18:04,620 --> 01:18:07,750
is the luminary and i hope he will illuminate as

1198
01:18:07,770 --> 01:18:19,980
well thank you that's not an easy introduction to live up to and i i

1199
01:18:19,980 --> 01:18:21,930
do expect larger

1200
01:18:22,040 --> 01:18:26,430
we're trying to do for

1201
01:18:26,680 --> 01:18:35,950
in the first part of this lecture i'm going to explain the origin of mass

1202
01:18:35,980 --> 01:18:43,640
you laugh and you may think that's an oversight overselling what i'm going to do

1203
01:18:43,690 --> 01:18:46,490
and let me first admit that i am

1204
01:18:46,810 --> 01:18:50,590
i'm only going to explain the origin of most mass

1205
01:18:50,600 --> 01:18:55,360
astronomers recently have taught us that most of the mass in the universe as a

1206
01:18:57,980 --> 01:18:59,160
it is in some

1207
01:18:59,170 --> 01:19:03,260
mysterious form that we call dark energy and we really have very little idea what

1208
01:19:03,280 --> 01:19:04,010
it is

1209
01:19:04,100 --> 01:19:06,180
it's very odd properties it's

1210
01:19:06,200 --> 01:19:11,800
most notably it exerts negative pressure

1211
01:19:11,880 --> 01:19:15,490
and that produces that seventy percent of the universe

1212
01:19:15,490 --> 01:19:19,540
of the mass of the universe averaged over very large distances

1213
01:19:20,040 --> 01:19:23,320
roughly twenty seven percent

1214
01:19:23,370 --> 01:19:27,910
isn't was something that's also mysterious

1215
01:19:27,950 --> 01:19:31,550
so called dark matter

1216
01:19:31,620 --> 01:19:34,760
this we also don't know what it is although there are some very good ideas

1217
01:19:34,760 --> 01:19:37,060
about it

1218
01:19:37,070 --> 01:19:39,420
it doesn't exert any pressure at all

1219
01:19:41,410 --> 01:19:44,570
i'm not going to be explaining either of those kinds of mass

1220
01:19:44,910 --> 01:19:49,470
the kinds of mass i'm going to explain most of or the mass of you

1221
01:19:49,470 --> 01:19:53,370
and me and our immediate neighbourhood the master dominates

1222
01:19:53,430 --> 01:19:58,360
on earth in the solar system in in fact part of the galaxy

1223
01:19:58,370 --> 01:20:02,680
even though this familiar form of matter

1224
01:20:02,690 --> 01:20:05,720
based on protons neutrons and electrons

1225
01:20:05,740 --> 01:20:07,240
only constitutes

1226
01:20:07,310 --> 01:20:10,340
about three percent of the mass of the universe as a whole

1227
01:20:10,360 --> 01:20:13,110
i hope you'll agree that is a particularly significant

1228
01:20:13,160 --> 01:20:15,060
a part of the mass

1229
01:20:15,070 --> 01:20:18,730
and i will be explaining quantitatively in in detail

1230
01:20:18,740 --> 01:20:29,060
the origin of nineteen ninety percent or more of the mass of ordinary matter

1231
01:20:29,070 --> 01:20:31,840
just because you can say the words doesn't mean

1232
01:20:31,880 --> 01:20:36,260
and they make grammatical sense doesn't mean it makes any sense conceptually

1233
01:20:36,280 --> 01:20:41,290
what does it mean to talk about the origin of mass

1234
01:20:41,300 --> 01:20:46,700
in newtonian mechanics it really wouldn't mean anything at all

1235
01:20:46,750 --> 01:20:48,340
in o one two

1236
01:20:48,370 --> 01:20:53,090
i i teach students the the first three laws of the three laws of motion

1237
01:20:53,090 --> 01:20:58,420
and newton's three laws but before that we discuss the zeroth law

1238
01:20:58,430 --> 01:21:02,680
and the zeroth law of mechanics of classical mechanics is

1239
01:21:02,740 --> 01:21:04,550
that mass is conserved

1240
01:21:04,600 --> 01:21:07,390
that mass doesn't change

1241
01:21:07,390 --> 01:21:12,220
the axis of the examples actually catch that margin are called support vectors that's what

1242
01:21:12,220 --> 01:21:15,530
i call the support vector machine it turns out

1243
01:21:15,530 --> 01:21:16,760
you can write

1244
01:21:18,120 --> 01:21:21,850
this you can rewrite this formula the sign of some

1245
01:21:21,880 --> 01:21:25,650
linear vector u in in practice you x you can

1246
01:21:25,660 --> 01:21:27,340
rewrite that

1247
01:21:28,140 --> 01:21:31,860
a weighted sum of the inner product of the support vector x so another way

1248
01:21:31,860 --> 01:21:36,600
of thinking about the support vector is basically some sort of fancy weighted nearest neighbour

1249
01:21:36,600 --> 01:21:40,730
OK so you're looking at the distance the inner product between x and y axes

1250
01:21:40,730 --> 01:21:45,520
the sort of distance between these two and you're weighting the different examples differently

1251
01:21:45,650 --> 01:21:48,010
and finally you're taking the sign of all that

1252
01:21:49,910 --> 01:21:52,820
this is another way of thinking about support vector machine

1253
01:21:53,840 --> 01:21:56,310
one thing that nice about this formulation

1254
01:21:56,310 --> 01:21:58,980
is that these inner products right here

1255
01:21:59,010 --> 01:22:03,810
and replaced with more general class of distance functions called kernels

1256
01:22:03,840 --> 01:22:08,520
so that gives you some additional flexibility in how the algorithm behave because you can

1257
01:22:08,520 --> 01:22:10,310
change the distance function

1258
01:22:10,310 --> 01:22:13,530
and in fact support vector machines are one of the

1259
01:22:13,550 --> 01:22:19,950
standard techniques for using are for for for handling topical to classification

1260
01:22:20,050 --> 01:22:22,480
techniques these are sort of the arm

1261
01:22:22,530 --> 01:22:26,220
you know on the brand x method that you always try to be a research

1262
01:22:26,220 --> 01:22:31,470
papers these are sort of the the baseline competitive markets here again some kind of

1263
01:22:31,470 --> 01:22:35,950
old results but these were from a very influential paper back in nineteen ninety eight

1264
01:22:37,190 --> 01:22:40,630
this is the naive bayes and these are on kind of the categories from the

1265
01:22:40,630 --> 01:22:42,470
supporters data that i showed you

1266
01:22:42,480 --> 01:22:47,920
OK and there's a bunch of different variants of support vector machine based on this

1267
01:22:47,920 --> 01:22:50,000
different distance functions

1268
01:22:50,020 --> 01:22:55,410
but the simplest distance function is basically just an inner product OK and you know

1269
01:22:55,420 --> 01:22:58,350
the micro averaged accuracy here

1270
01:22:58,410 --> 01:23:03,250
one which is some way with measuring the average of these ten categories is eighty

1271
01:23:03,250 --> 01:23:04,370
four point two

1272
01:23:05,010 --> 01:23:09,090
well for naive bayes seventy two point so you can sort of see we're getting

1273
01:23:09,090 --> 01:23:15,080
a little bit of extra performance for the extra work for doing this optimisation

1274
01:23:18,460 --> 01:23:21,800
in this picture a couple of other albums here which also do pretty well so

1275
01:23:21,800 --> 01:23:23,160
there's roadkill here

1276
01:23:23,190 --> 01:23:25,030
this k nearest neighbour

1277
01:23:25,040 --> 01:23:28,800
o talk about c four point five talk briefly about these other two

1278
01:23:28,810 --> 01:23:32,690
right so these other two albums are simpler algorithms

1279
01:23:32,700 --> 01:23:34,030
that are

1280
01:23:34,040 --> 01:23:35,400
are based on

1281
01:23:35,420 --> 01:23:41,280
a particular representation for documents and the representation of very active this this factor that

1282
01:23:41,280 --> 01:23:42,520
i showed you

1283
01:23:44,360 --> 01:23:49,570
we started out with the vector where each component was the frequency

1284
01:23:49,590 --> 01:23:51,040
in other words

1285
01:23:51,570 --> 01:23:55,970
so the number like one two three four five right so

1286
01:23:55,980 --> 01:24:01,750
the idea in this representation the change these numbers to represent some sort of statistical

1287
01:24:01,750 --> 01:24:03,100
weight of the word

1288
01:24:03,130 --> 01:24:06,510
some measure of the importance of that word so

1289
01:24:06,860 --> 01:24:10,720
a formula which is a rather ad hoc working formula but seems to work quite

1290
01:24:11,640 --> 01:24:16,300
is to wait words higher if there infrequent OK so if there words that appear

1291
01:24:16,300 --> 01:24:19,330
infrequently in the document so if only appears in you know

1292
01:24:19,340 --> 01:24:20,100
you know

1293
01:24:20,120 --> 01:24:24,540
and documents and the entire collection image have a high weight weighted towards it appears

1294
01:24:24,540 --> 01:24:27,220
many times in the document will have a lower weight

1295
01:24:27,230 --> 01:24:32,100
right and this is no extension things that appear frequently enough are stop would you

1296
01:24:32,100 --> 01:24:33,210
just throw away

1297
01:24:33,260 --> 01:24:35,730
all right the other thing you want to do is you want in

1298
01:24:35,780 --> 01:24:40,240
increase the weight of words that are frequent turns out taking those things and has

1299
01:24:40,240 --> 01:24:44,050
been through a lot seems to work better than just using the frequency

1300
01:24:45,240 --> 01:24:49,280
so this is just the formula for change in the way to these documents so

1301
01:24:49,550 --> 01:24:53,150
a kind of common thing to do is to use these weights and scalable vector

1302
01:24:53,160 --> 01:24:54,610
so they have like one

1303
01:24:56,170 --> 01:24:59,350
so this is called the TFIDF representation

1304
01:24:59,370 --> 01:25:04,880
it is a very simple idea and it turned out to be very surprising useful

1305
01:25:04,880 --> 01:25:06,840
thing in a lot of different situations

1306
01:25:06,970 --> 01:25:09,600
so this is an old trick from information retrieval

1307
01:25:09,620 --> 01:25:12,750
and to give you some example

1308
01:25:12,750 --> 01:25:16,620
here's another very very simple algorithm so

1309
01:25:16,650 --> 01:25:20,690
given an example of vector you want to classify just find the k closest things

1310
01:25:20,910 --> 01:25:24,050
the factors that are nearest to where would have the closest

1311
01:25:24,070 --> 01:25:29,210
largest inner product and then we're going to predict by basically looking at a weighted

1312
01:25:29,210 --> 01:25:33,160
sum of these factors the case we define the class so that if i look

1313
01:25:33,160 --> 01:25:37,520
at all the things that the class in some the distances it'll be some very

1314
01:25:37,700 --> 01:25:42,140
into products small from the similarities with the highest score

1315
01:25:42,160 --> 01:25:45,880
OK so close to a lot of positive things far away from the negative things

1316
01:25:45,880 --> 01:25:48,570
will give positive way otherwise twenty nine

1317
01:25:48,620 --> 01:25:53,900
so that's k nearest neighbour in TFIDF space right another maybe even a little sum

1318
01:25:53,900 --> 01:25:58,810
for his will take the positive examples and more animals will take all the examples

1319
01:25:58,810 --> 01:26:03,600
and will subtract one from the couple waiting here alphabet equals one is not a

1320
01:26:03,600 --> 01:26:04,520
bad idea

1321
01:26:04,530 --> 01:26:11,810
and then we'll just taken as are classifiers so if you like we're looking at

1322
01:26:11,810 --> 01:26:15,480
things that are close to the part of the centre of the positive examples and

1323
01:26:15,480 --> 01:26:17,590
far from the centre of the negative examples

1324
01:26:17,610 --> 01:26:20,240
so these two albums are rocchio

1325
01:26:20,240 --> 01:26:23,670
and k nearest neighbour and TFIDF space and using these are actually doing quite well

1326
01:26:24,530 --> 01:26:30,910
so therefore there you know microaverage performances up close to a duel but

1327
01:26:31,060 --> 01:26:36,120
so these are some other competitive algorithms one of the nice things about the k

1328
01:26:36,120 --> 01:26:38,520
nearest neighbor algorithm

1329
01:26:38,530 --> 01:26:42,280
ah well actually two nice things about k nearest neighbor algorithm

1330
01:26:42,300 --> 01:26:47,190
so getting neighbours close neighbours of the documents sounds like it might be a hard

1331
01:26:47,190 --> 01:26:51,030
thing to do is OK but in fact that's exactly what

1332
01:26:51,080 --> 01:26:56,250
when i are search engine is designed to do so traditional ranked retrieval engines basically

1333
01:26:56,270 --> 01:26:59,830
try and find things that are most similar in this TFIDF space

1334
01:27:00,900 --> 01:27:04,760
finding these papers if you have a search engine lying around the to question making

1335
01:27:04,760 --> 01:27:06,040
one call

1336
01:27:06,320 --> 01:27:10,230
i think that's about this is when you find the nearest neighbors

1337
01:27:10,240 --> 01:27:15,310
and that these similarities you end up with scores for every class and it doesn't

1338
01:27:15,310 --> 01:27:17,050
matter how many classes you have

1339
01:27:17,070 --> 01:27:19,070
you still get scores for every class

1340
01:27:19,090 --> 01:27:22,490
so this the very efficient thing to do if you have say a hundred classes

1341
01:27:22,490 --> 01:27:24,520
are hundred thousand classes

1342
01:27:28,670 --> 01:27:33,550
one last thing which shows the TFIDF is sort of a surprisingly useful thing to

1343
01:27:33,560 --> 01:27:37,770
do so a couple of years ago i think in two thousand two or three

1344
01:27:37,770 --> 01:27:39,630
jason running at MIT

1345
01:27:39,700 --> 01:27:45,050
the paperwork evaluate naive bayes with TFIDF weighting of factors

1346
01:27:45,060 --> 01:27:49,020
which are probabilistic point of view doesn't really make any sense whatsoever

1347
01:27:49,050 --> 01:27:52,530
right and the other little trick is used on the complement of the data rather

1348
01:27:52,530 --> 01:27:54,830
than the original class that's kind of a little detail

1349
01:27:54,890 --> 01:27:58,330
so this is the multinomial naive bayes

1350
01:27:58,340 --> 01:27:59,610
and this is

1351
01:27:59,620 --> 01:28:05,480
his TFIDF weighted complement naive bayes and you can sort of see a fairly large

1352
01:28:05,480 --> 01:28:09,150
performance improvement on several different problems here

1353
01:28:09,170 --> 01:28:12,690
and in fact what you end up with something is quite competitive with support vector

1354
01:28:16,710 --> 01:28:18,820
so what

1355
01:28:18,840 --> 01:28:24,360
i'm not talk briefly about some other fast discriminative methods in fact that just with

1356
01:28:24,360 --> 01:28:28,070
through this very quickly because i want to spend a the of time on

1357
01:28:28,090 --> 01:28:31,290
some of the other things in part two when we got off to a little

1358
01:28:31,290 --> 01:28:32,710
bit of late start

1359
01:28:32,710 --> 01:28:33,820
machine learning

1360
01:28:33,850 --> 01:28:36,870
where you don't want to do all the data back to a central site you

1361
01:28:36,870 --> 01:28:41,610
want to locally quantizer or some other kind of compression and send a small bit

1362
01:28:41,610 --> 01:28:44,570
rate back to a central site do something sophisticated

1363
01:28:44,660 --> 01:28:48,730
so how can we solve the problem in in the theoretically satisfying way kind of

1364
01:28:48,730 --> 01:28:53,230
set up this problem where the risk functional is the probability of error or you

1365
01:28:53,280 --> 01:28:56,340
label was different than the when you predicted

1366
01:28:56,350 --> 01:29:00,790
and the decision now it's got two parts to its both the experiment design quantizer

1367
01:29:00,790 --> 01:29:05,900
and discriminant functions and we want to find the discriminant function and quantized to minimize

1368
01:29:05,900 --> 01:29:07,740
the probability there

1369
01:29:08,300 --> 01:29:13,370
and i talked about kind of literature two main literature that focused on half the

1370
01:29:13,370 --> 01:29:17,710
problem and the whole problem either you some q is known try to find a

1371
01:29:17,710 --> 01:29:20,230
discriminant that's kind of machine learning

1372
01:29:20,290 --> 01:29:24,530
this stick to processing assumes that everything all the probabilities are known so you could

1373
01:29:24,530 --> 01:29:26,980
actually get the discriminative by bayes rule

1374
01:29:27,000 --> 01:29:31,160
but they focus on getting q

1375
01:29:31,170 --> 01:29:35,040
and what you get q then you do actually use bayes rule together the quantizer

1376
01:29:35,050 --> 01:29:36,730
OK so so the

1377
01:29:36,740 --> 01:29:42,730
the single processing focused on these things known as f divergences mars morris's heuristic you

1378
01:29:42,730 --> 01:29:44,870
want to push distributions apart

1379
01:29:44,920 --> 01:29:49,780
and these are measures of how close distributions are interview maximizes divergences you're pushing them

1380
01:29:49,780 --> 01:29:53,310
apart and that's the way to get principle of how to choose the quantizer or

1381
01:29:53,310 --> 01:29:55,170
the experimental design general

1382
01:29:55,190 --> 01:29:57,730
OK so there's a list of some of them there are many of them any

1383
01:29:57,750 --> 01:29:59,910
convex function of the likelihood ratio

1384
01:29:59,920 --> 01:30:02,150
average defines afterwards

1385
01:30:02,160 --> 01:30:06,380
and then there was the theorem we need blackwell that sort of said that after

1386
01:30:06,380 --> 01:30:11,460
versions used to rank procedures in terms of risk i e probability there

1387
01:30:11,480 --> 01:30:17,860
for some unknown prior so that motivated people to looking at literature look after

1388
01:30:17,880 --> 01:30:21,970
and then the machine learning perspective was to have a decision theoretic story for you

1389
01:30:21,970 --> 01:30:24,290
develop the surrogate loss functions

1390
01:30:24,300 --> 01:30:27,940
and they are there for like boost in support vector machine logistic regression so on

1391
01:30:27,940 --> 01:30:31,100
their upper bounds on this intractable zero one loss

1392
01:30:31,120 --> 01:30:32,810
and then there's a theory

1393
01:30:35,140 --> 01:30:36,890
says that if i

1394
01:30:36,900 --> 01:30:41,770
you basically have a year surrogate loss is differentiable zero and has a negative strictly

1395
01:30:41,770 --> 01:30:46,320
negative derivative the origin then that's necessary and sufficient for bayes consistency so me i

1396
01:30:46,320 --> 01:30:50,080
didn't actually to find these consistency yesterday but i mean what you expect to mean

1397
01:30:50,580 --> 01:30:52,800
means the number of data points gets large

1398
01:30:52,800 --> 01:30:56,740
but you converge to making the probability very close to zero or for the base

1399
01:30:56,740 --> 01:30:59,430
rate the best you can do

1400
01:31:01,270 --> 01:31:04,620
so in this case is that the functional estimation problem it's not just the parameter

1401
01:31:04,620 --> 01:31:06,820
estimation problem

1402
01:31:06,830 --> 01:31:10,750
OK so i think we're getting close to rest yesterday

1403
01:31:10,770 --> 01:31:16,540
so we're trying to define this notion of universal equivalence among surrogate loss functions

1404
01:31:16,580 --> 01:31:19,330
and i had a little notation and

1405
01:31:19,670 --> 01:31:24,150
if you know the the main of notation is that for a given circuit loss

1406
01:31:24,150 --> 01:31:29,250
function for not zero one loss in general but maybe we have an argument which

1407
01:31:29,250 --> 01:31:29,570
is the

1408
01:31:30,010 --> 01:31:34,800
but but the sources of reporters risk and just expanding out you get

1409
01:31:35,250 --> 01:31:40,180
probability under a y was one and probably otherwise equal to minus one and then

1410
01:31:40,180 --> 01:31:43,270
we started the averaging respect diseases we have two

1411
01:31:43,290 --> 01:31:47,300
that expectation is location both y and z data has the wine is the component

1412
01:31:47,380 --> 01:31:51,000
the classification problem we did one of the average is not the other and that's

1413
01:31:51,000 --> 01:31:52,850
what the risk looks like

1414
01:31:53,330 --> 01:31:58,450
OK then we profile we do this frequencies sort of well for one thing is

1415
01:31:58,530 --> 01:32:02,040
the thing to do and then you try to prove the frequency you it's OK

1416
01:32:02,490 --> 01:32:08,080
you the right thing so we take the infimum over the discriminant function

1417
01:32:08,090 --> 01:32:11,070
and so we did that for zero one loss and we've turned out that the

1418
01:32:11,070 --> 01:32:17,080
zero one risk profile zero one risk was the negative of a after versions in

1419
01:32:17,080 --> 01:32:20,680
particular the variational distance and then we did that for a bunch of other examples

1420
01:32:20,680 --> 01:32:23,430
and we found was the general stories seem to be emerging

1421
01:32:23,440 --> 01:32:31,410
which was that profiled risks of of surrogate loss functions always were equals the negative

1422
01:32:31,410 --> 01:32:32,570
of a

1423
01:32:32,710 --> 01:32:34,870
i mean after versions

1424
01:32:34,890 --> 01:32:38,030
OK so that's a new result that's not been present in the literature for all

1425
01:32:38,030 --> 01:32:39,820
these forty years or something

1426
01:32:39,830 --> 01:32:44,020
and i want the new results to prove the theorem about it the theorem tells

1427
01:32:44,020 --> 01:32:49,150
you there's this many to one link between surrogate loss functions defined in this way

1428
01:32:49,190 --> 01:32:54,270
now just loss functions with a special class of surrogate loss functions and after taxes

1429
01:32:54,300 --> 01:32:58,420
and so the proof needed to define a notion of the

1430
01:32:58,500 --> 01:33:04,930
how social contextuality and here's the first theorem which we went through yesterday which can

1431
01:33:04,970 --> 01:33:09,920
go in one direction given a large enough divergence was easy and then backwards given

1432
01:33:09,920 --> 01:33:15,340
after versions you get a whole family of loss functions and the family was parameterised

1433
01:33:15,340 --> 01:33:19,670
here it is by a three degree of freedom this function f

1434
01:33:20,440 --> 01:33:25,830
the house is there has to be to simply increasing continuous and convex sets him

1435
01:33:25,830 --> 01:33:30,800
and here are some examples of different choices of g gives you a bunch of

1436
01:33:30,800 --> 01:33:35,400
different loss functions all of which lead to the hellinger distance

1437
01:33:35,420 --> 01:33:39,400
and then you do this is by doing the conjugate duality calculation here's a bunch

1438
01:33:39,950 --> 01:33:44,070
f or g functions that lead to loss functions include the hinge loss

1439
01:33:44,090 --> 01:33:47,210
all of which yields variational distance

1440
01:33:47,240 --> 01:33:49,430
and then KL divergence

1441
01:33:49,490 --> 01:33:52,460
OK so here was our problem and we're going try to solve which is that

1442
01:33:52,460 --> 01:33:56,040
we're going to try to get bayes consistency for choosing both the quantizer and the

1443
01:33:56,040 --> 01:33:57,670
discriminant function

1444
01:33:57,680 --> 01:34:01,120
and now i'm going to draw another picture the

1445
01:34:01,130 --> 01:34:02,580
well the losses

1446
01:34:02,600 --> 01:34:05,660
so thirteen losses something special kind of losses

1447
01:34:05,700 --> 01:34:10,540
and since

1448
01:34:10,580 --> 01:34:15,850
and we've got this characterization theorem that says that for every version certain region over

1449
01:34:15,850 --> 01:34:17,180
here the born

1450
01:34:18,270 --> 01:34:19,540
OK so the

1451
01:34:19,550 --> 01:34:22,550
the theorem that the the more down statistical it's kind of this a bit of

1452
01:34:22,550 --> 01:34:24,180
convex analysis really

1453
01:34:24,200 --> 01:34:28,760
the statistical theorem now says that what you need to do is to start with

1454
01:34:28,760 --> 01:34:32,790
zero one loss so here's a particular zero one loss and one regions and go

1455
01:34:32,790 --> 01:34:36,910
over to the the corresponding f divergence and now take an expansion of that given

1456
01:34:37,580 --> 01:34:42,330
so there's the variational distance and many of you one that is the function that

1457
01:34:42,330 --> 01:34:44,420
gives you variational distance

1458
01:34:44,790 --> 01:34:46,380
o point here

1459
01:34:46,380 --> 01:34:49,530
precipitate on the dust particles of the smoke

1460
01:34:49,530 --> 01:34:51,660
and therefore they will grow

1461
01:34:51,700 --> 01:34:54,370
and it's not possible to smoke

1462
01:34:54,420 --> 01:34:56,110
there will be very small

1463
01:34:56,110 --> 01:34:57,190
what are

1464
01:34:57,200 --> 01:34:58,750
drop in that

1465
01:34:59,700 --> 01:35:02,820
but there are much larger than the small particles

1466
01:35:02,870 --> 01:35:04,860
and you will clearly see

1467
01:35:05,630 --> 01:35:07,450
the light that reaches q

1468
01:35:07,580 --> 01:35:09,280
has been can now

1469
01:35:09,290 --> 01:35:11,570
of small in my lungs

1470
01:35:11,610 --> 01:35:13,620
distinctly wider

1471
01:35:13,630 --> 01:35:16,080
then this

1472
01:35:16,090 --> 01:35:17,440
you're ready for that

1473
01:35:17,440 --> 01:35:18,570
just remember

1474
01:35:18,620 --> 01:35:24,740
first this color

1475
01:35:24,770 --> 01:35:36,420
OK here we go

1476
01:35:36,450 --> 01:35:46,160
color change

1477
01:35:46,170 --> 01:35:47,710
so it was blue

1478
01:35:47,870 --> 01:35:57,070
the first time

1479
01:35:57,150 --> 01:35:59,520
i mentioned

1480
01:35:59,530 --> 01:36:00,690
this guy

1481
01:36:00,740 --> 01:36:04,190
the sky is blue

1482
01:36:04,910 --> 01:36:07,020
the sky is blue for the same reason

1483
01:36:07,120 --> 01:36:09,630
that the smokies broome

1484
01:36:10,500 --> 01:36:13,710
in the earth's atmosphere

1485
01:36:13,870 --> 01:36:18,570
many very small dust particles

1486
01:36:18,570 --> 01:36:21,540
and even if those small dust particles

1487
01:36:21,570 --> 01:36:25,150
one of their

1488
01:36:25,200 --> 01:36:28,740
in the atmosphere itself

1489
01:36:28,750 --> 01:36:35,080
there are small fluctuations of the density of the air

1490
01:36:35,130 --> 01:36:37,200
and so if i put q

1491
01:36:37,250 --> 01:36:38,780
at the bottom

1492
01:36:38,900 --> 01:36:43,750
of the earth's atmosphere which is a big blank areas

1493
01:36:43,770 --> 01:36:46,450
we're here

1494
01:36:46,460 --> 01:36:51,520
and the sunlight comes from from the direction

1495
01:36:51,530 --> 01:36:54,080
so very far away

1496
01:36:54,090 --> 01:36:56,480
by the fact that

1497
01:36:56,580 --> 01:36:59,160
coming in like so

1498
01:36:59,210 --> 01:37:03,770
six straight on the thing to do that is when the sun is

1499
01:37:06,540 --> 01:37:07,560
the there

1500
01:37:07,590 --> 01:37:09,440
not there

1501
01:37:09,490 --> 01:37:11,270
what you see

1502
01:37:11,530 --> 01:37:15,560
OK i ever reach

1503
01:37:15,630 --> 01:37:18,620
can these find that support

1504
01:37:18,660 --> 01:37:19,950
so what is the colour

1505
01:37:20,770 --> 01:37:21,740
because blue

1506
01:37:21,750 --> 01:37:23,530
we forward scattering

1507
01:37:24,630 --> 01:37:26,660
violet either one

1508
01:37:26,710 --> 01:37:29,530
kind way more than random or

1509
01:37:29,560 --> 01:37:31,570
so when you look

1510
01:37:31,580 --> 01:37:33,290
right there

1511
01:37:39,330 --> 01:37:44,820
same reason why this focus

1512
01:37:45,060 --> 01:37:50,230
is it possible may be that some of the sunlight

1513
01:37:50,240 --> 01:37:52,980
that's carriers of dust in the sky

1514
01:37:52,980 --> 01:37:55,710
scanners at ninety degrees if that's the case

1515
01:37:55,730 --> 01:37:56,840
i mean business

1516
01:37:56,860 --> 01:37:59,780
i go with my little polarizes i look at this guy

1517
01:37:59,800 --> 01:38:03,370
and i can convince myself that that part of the sky was a hundred percent

1518
01:38:04,880 --> 01:38:06,450
of course

1519
01:38:06,500 --> 01:38:07,730
there's a whole

1520
01:38:07,910 --> 01:38:10,570
is no matter where the sum is

1521
01:38:10,580 --> 01:38:12,740
this is about the rise

1522
01:38:12,740 --> 01:38:15,130
there's a whole

1523
01:38:15,200 --> 01:38:19,410
o ninety degrees away from the sun so there

1524
01:38:19,410 --> 01:38:22,560
this is all ninety degrees away from the

1525
01:38:22,560 --> 01:38:24,020
the sun is there

1526
01:38:24,150 --> 01:38:26,360
all ninety degrees away from

1527
01:38:26,360 --> 01:38:28,740
just like this single year

1528
01:38:28,840 --> 01:38:30,480
thank you

1529
01:38:30,520 --> 01:38:33,200
and so if i look at this guy

1530
01:38:33,250 --> 01:38:35,490
not only is this guy blue which i now

1531
01:38:35,490 --> 01:38:37,610
perhaps understand the little

1532
01:38:37,620 --> 01:38:39,330
but you don't get the direction

1533
01:38:39,380 --> 01:38:42,490
which is ninety degrees away from the direction of the sun

1534
01:38:42,500 --> 01:38:44,620
no matter where i do

1535
01:38:44,710 --> 01:38:47,980
with my little polarizer that you have now in your pocket

1536
01:38:48,030 --> 01:38:49,580
you can convince yourself

1537
01:38:49,780 --> 01:38:50,980
this guy

1538
01:38:51,000 --> 01:38:52,460
is hundred percent

1539
01:38:56,950 --> 01:38:58,290
are some

1540
01:38:59,780 --> 01:39:01,940
so beautiful

1541
01:39:03,370 --> 01:39:07,380
that you should be able to and so now for yourself

1542
01:39:07,520 --> 01:39:10,900
the sun

1543
01:39:10,910 --> 01:39:13,950
all right

1544
01:39:13,950 --> 01:39:15,230
you are here

1545
01:39:15,240 --> 01:39:20,330
here is rank of air

1546
01:39:20,420 --> 01:39:22,860
anderson is very low in the horizon

1547
01:39:22,870 --> 01:39:25,780
the sunlight

1548
01:39:25,780 --> 01:39:28,580
comes in this way

1549
01:39:28,660 --> 01:39:32,030
because the sun is so low in the sky

1550
01:39:33,690 --> 01:39:35,650
so in that

1551
01:39:35,660 --> 01:39:37,650
how much atmosphere

1552
01:39:37,700 --> 01:39:40,530
this light has to go through

1553
01:39:40,620 --> 01:39:42,520
the light

1554
01:39:42,700 --> 01:39:45,370
like that wants to scatter

1555
01:39:45,420 --> 01:39:49,230
and then there comes a time that all the light being scattered about that there

1556
01:39:49,230 --> 01:39:51,530
is no blue light anymore

1557
01:39:51,530 --> 01:39:54,990
well there may maybe some of the

1558
01:39:54,990 --> 01:39:57,070
i started get

1559
01:39:57,080 --> 01:40:00,560
and and maybe some of the light field camera

1560
01:40:00,560 --> 01:40:01,450
and then all

1561
01:40:01,480 --> 01:40:04,730
these colors have been removed from the white sunlight

1562
01:40:04,780 --> 01:40:07,120
what remains is red

1563
01:40:07,300 --> 01:40:09,020
so it is the lights

1564
01:40:09,030 --> 01:40:14,030
that penetrates very deep into the atmosphere that makes it all the way to here

1565
01:40:14,120 --> 01:40:16,280
that has no anymore in

1566
01:40:16,290 --> 01:40:18,160
no green

1567
01:40:18,200 --> 01:40:19,980
not even yellow

1568
01:40:20,450 --> 01:40:22,060
it therefore

1569
01:40:22,070 --> 01:40:25,610
is red that happens to be cloutier

1570
01:40:25,660 --> 01:40:27,330
specially made

1571
01:40:27,340 --> 01:40:28,730
so far away

1572
01:40:28,790 --> 01:40:31,330
it was the red light strikes the cloud

1573
01:40:31,370 --> 01:40:32,870
so therefore

1574
01:40:32,910 --> 01:40:36,120
the same reason why the sky is blue

1575
01:40:36,190 --> 01:40:39,070
is the reason why the sun is red when it set

1576
01:40:39,120 --> 01:40:42,780
all the sunlight now must go through an enormous

1577
01:40:42,790 --> 01:40:45,380
layer of atmosphere

1578
01:40:45,520 --> 01:40:47,730
light gone

1579
01:40:47,740 --> 01:40:49,290
real light is gone

1580
01:40:49,300 --> 01:40:50,780
what you end up with

1581
01:40:52,780 --> 01:40:57,700
what is left over maybe some of you

1582
01:40:57,740 --> 01:40:59,990
that's what i want to demonstrate

1583
01:41:00,000 --> 01:41:03,330
you have my last

1584
01:41:03,370 --> 01:41:06,870
i want to catch was my last demonstration

1585
01:41:06,910 --> 01:41:09,780
i want to catch kill three birds

1586
01:41:09,830 --> 01:41:12,620
with one stone

1587
01:41:12,690 --> 01:41:15,700
and the three but i want to kill

1588
01:41:15,710 --> 01:41:18,030
i number one

1589
01:41:18,080 --> 01:41:19,660
that the sky is blue

1590
01:41:19,700 --> 01:41:22,690
i'm going to make a blue sky

1591
01:41:22,740 --> 01:41:24,240
number two

1592
01:41:24,330 --> 01:41:25,910
but if you look at this guy

1593
01:41:25,940 --> 01:41:28,440
ninety degrees away from the sun

1594
01:41:28,440 --> 01:41:34,690
in and f in generalisation of boosting to the structured learning problem

1595
01:41:34,710 --> 01:41:37,080
browne talks sorry

1596
01:41:37,100 --> 01:41:43,040
we do this all round yesterday talked in detail about bursting cells just go very

1597
01:41:43,040 --> 01:41:47,140
fast one thing i need to point out is that i have changed annotation love

1598
01:41:47,140 --> 01:41:53,220
it here instead of the W's over the features now i'm using actually landers

1599
01:41:54,450 --> 01:42:00,780
boosting the basic idea we combine weak learners features

1600
01:42:02,410 --> 01:42:04,880
to get our ensemble

1601
01:42:05,590 --> 01:42:11,440
and we're only in in other words we're walking around with each repeat feature so

1602
01:42:11,440 --> 01:42:15,700
that we minimize empirical error and then we we

1603
01:42:15,980 --> 01:42:19,740
find its optimal weight update delta

1604
01:42:20,790 --> 01:42:22,640
so this is the approach

1605
01:42:22,650 --> 01:42:31,150
o this iterative optimisation approaches gives features questions property and another key idea of boosting

1606
01:42:31,150 --> 01:42:37,580
is that we maintain a weight distribution over examples so that it each we focus

1607
01:42:37,580 --> 01:42:40,700
more on the misclassified examples

1608
01:42:40,710 --> 01:42:45,830
all right so in india original adaboost do optimisation function

1609
01:42:45,850 --> 01:42:50,550
optimized the optimisation function considered is the exponential loss

1610
01:42:50,560 --> 01:42:58,310
so our our classifier are some world is going to be penalised for every training

1611
01:42:58,310 --> 01:43:00,700
instance that is not the correct one

1612
01:43:02,040 --> 01:43:04,590
we're going to be penalized exponentially

1613
01:43:04,630 --> 01:43:06,440
for the ones

1614
01:43:06,450 --> 01:43:11,640
there are ranked higher than the current one so if if the

1615
01:43:11,650 --> 01:43:16,200
compatibility score of this leaving this label

1616
01:43:16,470 --> 01:43:20,630
sigma is higher than this guy this is going to be a positive so it's

1617
01:43:20,630 --> 01:43:24,420
going to be large and if it's negative it's going to be a small in

1618
01:43:29,830 --> 01:43:35,490
yes we know that boosting actually optimizes the l one norm of the

1619
01:43:35,500 --> 01:43:39,510
margin and that we're gonna use later on

1620
01:43:39,520 --> 01:43:41,450
that information we're gonna use later

1621
01:43:42,510 --> 01:43:43,960
now how do we do

1622
01:43:43,970 --> 01:43:45,460
structured boosting

1623
01:43:45,490 --> 01:43:51,460
let's consider the loss function again we're gonna use exponential loss so it's going to

1624
01:43:51,460 --> 01:43:55,430
be the same but now instead of the observation

1625
01:43:55,510 --> 01:44:01,600
labelled pairs we have is structured instances in which means that the sum over all

1626
01:44:01,600 --> 01:44:06,990
labels is going to be a sum over some is something that the exponential

1627
01:44:07,780 --> 01:44:13,150
again this is a convex optimisation problem right so we can use a gradient based

1628
01:44:13,150 --> 01:44:18,120
optimisation technique in order to compute in order to

1629
01:44:18,130 --> 01:44:24,490
four from this optimisation exactly and this will be based on the gradients which is

1630
01:44:24,490 --> 01:44:26,580
a actually a function of far

1631
01:44:27,270 --> 01:44:30,020
a function of far

1632
01:44:30,030 --> 01:44:32,180
expectations of features

1633
01:44:32,550 --> 01:44:38,500
and we know that we can we can compute these using a forward backward algorithm

1634
01:44:38,540 --> 01:44:40,520
and the scale si in

1635
01:44:40,540 --> 01:44:44,600
in sequences they scale linearly so we're good

1636
01:44:44,610 --> 01:44:51,260
we can do this optimisation problem exactly by performing a dynamic programming which scales linearly

1637
01:44:51,280 --> 01:44:59,890
and what about a adaboost version of this problem so

1638
01:44:59,950 --> 01:45:03,890
so the the same the same

1639
01:45:03,900 --> 01:45:08,290
the same key ideas will follow as well we're going to maintain a weight or

1640
01:45:08,290 --> 01:45:14,020
are training instances in this case the training instances is there is an observation

1641
01:45:14,060 --> 01:45:19,000
paired with the possible labellings so we're going to consider all possible labellings and at

1642
01:45:19,000 --> 01:45:20,160
each iteration

1643
01:45:20,170 --> 01:45:21,230
we're gonna

1644
01:45:21,250 --> 01:45:27,660
update our weight so that we focus on the misclassified examples and how was the

1645
01:45:27,790 --> 01:45:30,520
obvious here so we're going to say

1646
01:45:30,540 --> 01:45:35,880
we see that the this term is going to be no this term is going

1647
01:45:35,880 --> 01:45:40,350
to be large for for the ones that we have misclassified because this is going

1648
01:45:40,350 --> 01:45:45,260
to be a positive time so we will be focusing more on the misclassified examples

1649
01:45:45,270 --> 01:45:47,060
the same is the same as before

1650
01:45:47,070 --> 01:45:53,880
same as incentivising right so now we are working on it and we're working with

1651
01:45:53,880 --> 01:45:58,700
iterations each it is at each iteration we're going to pick a feature that minimizes

1652
01:45:58,700 --> 01:46:06,120
the weighted empirical error and this this actually can that the is given by this

1653
01:46:06,120 --> 01:46:07,380
giant beast here

1654
01:46:07,420 --> 01:46:14,730
so we're going to find the optimal weight by minimizing the normalisation constant here

1655
01:46:14,740 --> 01:46:21,050
the normalisation function here partition function here and if you look at it it's not

1656
01:46:21,260 --> 01:46:24,760
the details of this this

1657
01:46:24,770 --> 01:46:29,790
formula is not all that important wanting to point out that is really important is

1658
01:46:29,790 --> 01:46:34,910
that this is now not only here in terms of the features for all possible

1659
01:46:36,010 --> 01:46:41,350
because this time might be very and this is problematic because now we we do

1660
01:46:41,350 --> 01:46:44,930
not have the dynamic programming approach to compute the

1661
01:46:45,410 --> 01:46:49,480
optimal weights for all possible features

1662
01:46:49,500 --> 01:46:53,730
well we will have to do is pointed out by the original CRF paper we

1663
01:46:53,850 --> 01:46:59,470
have to perform in dynamic programming for each training instance of sorry for each feature

1664
01:46:59,470 --> 01:47:03,890
and obviously this is not going to be possible when we have many many features

1665
01:47:03,910 --> 01:47:05,830
right and this is bad

1666
01:47:06,320 --> 01:47:11,080
and will be because of this property did this approach has been you know that

1667
01:47:11,400 --> 01:47:13,780
it is intractable problem

1668
01:47:13,800 --> 01:47:17,270
the simple idea we had was to

1669
01:47:17,360 --> 01:47:20,780
use the convexity of the exponential loss

1670
01:47:20,800 --> 01:47:23,820
which is actually using in itself in boosting

1671
01:47:23,830 --> 01:47:30,260
all problems so cynics financial losses upper bounded by the senior function here and the

1672
01:47:30,260 --> 01:47:32,300
inequalities given here

1673
01:47:32,310 --> 01:47:35,680
so in fact if i use this inequality

1674
01:47:35,680 --> 01:47:36,920
three thousand

1675
01:47:36,930 --> 01:47:38,020
nine hundred

1676
01:47:38,030 --> 01:47:41,120
and a eight

1677
01:47:41,220 --> 01:47:45,080
and the nice thing about this demonstration is that the difference between the motions is

1678
01:47:45,080 --> 01:47:46,700
twenty four hours

1679
01:47:46,750 --> 01:47:50,630
and you can very easily here that

1680
01:47:50,690 --> 01:47:52,940
so here is this tuning fork

1681
01:47:52,950 --> 01:47:56,270
four thousand four is

1682
01:47:57,810 --> 01:48:01,360
you know we go

1683
01:48:01,740 --> 01:48:04,880
a few times now we try to do because

1684
01:48:05,930 --> 01:48:08,300
i gave them preferential treatment

1685
01:48:14,080 --> 01:48:18,670
he gives

1686
01:48:18,690 --> 01:48:22,030
higher pitch when i come to you clearly

1687
01:48:25,260 --> 01:48:29,670
this is about twenty four hours

1688
01:48:29,680 --> 01:48:32,670
suppose now

1689
01:48:32,700 --> 01:48:35,030
that i rotate

1690
01:48:35,050 --> 01:48:37,770
a sound source in a circuit

1691
01:48:37,950 --> 01:48:40,950
rotated around

1692
01:48:40,970 --> 01:48:42,700
like so

1693
01:48:42,710 --> 01:48:45,390
angular velocity omega

1694
01:48:45,400 --> 01:48:47,860
radius are

1695
01:48:47,880 --> 01:48:49,430
this is where you are

1696
01:48:49,460 --> 01:48:57,120
and let the circum ferentials pvt zero

1697
01:48:57,130 --> 01:48:59,920
goes around with constant speed

1698
01:48:59,960 --> 01:49:01,340
so v zero

1699
01:49:01,360 --> 01:49:06,280
omega or

1700
01:49:06,300 --> 01:49:09,380
and the sound sources frequency f

1701
01:49:09,420 --> 01:49:14,330
so it's clear that it moves away from human effort primarily smaller than

1702
01:49:14,530 --> 01:49:16,450
have prime will be f

1703
01:49:16,460 --> 01:49:17,640
f prime

1704
01:49:17,690 --> 01:49:20,720
will be larger than

1705
01:49:20,740 --> 01:49:22,010
so as you listen

1706
01:49:22,020 --> 01:49:23,900
this sound

1707
01:49:23,930 --> 01:49:26,380
you will hear the sound change

1708
01:49:26,400 --> 01:49:31,940
in a sinusoidal wave because what matters is not the speed of sound

1709
01:49:31,960 --> 01:49:36,640
but the rate the speed of the source but the radial component new directions and

1710
01:49:36,640 --> 01:49:39,670
the radial component here is for the zero

1711
01:49:40,810 --> 01:49:44,260
he away from you with the radial component is zero

1712
01:49:44,280 --> 01:49:48,880
so if you arbitrarily cold this time equals zero here

1713
01:49:50,370 --> 01:49:52,440
the velocity radio

1714
01:49:53,990 --> 01:49:57,200
the components you are actually is that these zero

1715
01:49:57,250 --> 01:50:01,820
times the sign of omega t

1716
01:50:01,830 --> 01:50:04,380
so if you recall

1717
01:50:04,390 --> 01:50:08,550
not only listen but if you actually record

1718
01:50:08,560 --> 01:50:10,630
as a function of time

1719
01:50:10,640 --> 01:50:12,940
the frequency that you here

1720
01:50:12,940 --> 01:50:16,700
then you hear something like this

1721
01:50:16,750 --> 01:50:18,310
and this then

1722
01:50:18,360 --> 01:50:22,010
is the mean value af which is

1723
01:50:22,010 --> 01:50:25,260
transmitted by the sound source

1724
01:50:25,260 --> 01:50:29,550
now you can ask yourself the question what you learn from this

1725
01:50:29,690 --> 01:50:33,610
is amazing what you do is you can close your eyes and just record the

1726
01:50:33,610 --> 01:50:36,990
sound signal as a function of time

1727
01:50:37,010 --> 01:50:38,960
the first thing that you learn from it

1728
01:50:38,990 --> 01:50:41,820
is the period t which is by

1729
01:50:42,200 --> 01:50:44,400
divided by omega

1730
01:50:44,430 --> 01:50:46,370
so you know the period

1731
01:50:46,380 --> 01:50:49,300
of rotation you know omega

1732
01:50:49,550 --> 01:50:51,840
but you also records

1733
01:50:51,860 --> 01:50:54,050
whatever prime maximum is

1734
01:50:54,070 --> 01:50:57,850
and you also recorded crime in

1735
01:50:57,970 --> 01:51:00,290
so was the doppler shift equation

1736
01:51:00,300 --> 01:51:01,720
that we have here

1737
01:51:01,730 --> 01:51:04,820
you can easily calculate what these errors

1738
01:51:04,820 --> 01:51:08,940
and so you know also v zero

1739
01:51:09,050 --> 01:51:13,580
but since he is only are you also know are

1740
01:51:13,600 --> 01:51:18,710
so just imagine by recording that sound signal as a function of time you can

1741
01:51:18,710 --> 01:51:20,270
determine the periods

1742
01:51:20,290 --> 01:51:22,460
of rotation is omega

1743
01:51:22,480 --> 01:51:26,240
this breed in a circular orbit and

1744
01:51:26,270 --> 01:51:29,700
the rate is even

1745
01:51:29,710 --> 01:51:33,690
so i will to demonstrate this to you just qualitatively

1746
01:51:33,700 --> 01:51:34,920
so i have here

1747
01:51:35,890 --> 01:51:40,340
i don't even know what frequencies produces maybe it's a mixture of many frequencies

1748
01:51:40,360 --> 01:51:43,040
that's not so much the point

1749
01:51:43,080 --> 01:51:46,990
i want you to hear

1750
01:51:47,110 --> 01:51:52,610
if i told you about now it's no longer the metal highlow highlow highlow now

1751
01:51:52,610 --> 01:51:55,550
is a gradual change to a height h

1752
01:51:55,560 --> 01:51:56,570
no page

1753
01:51:56,570 --> 01:52:00,080
and then you see this industry

1754
01:52:00,120 --> 01:52:05,540
it is we really don't know

1755
01:52:05,550 --> 01:52:10,410
it is really high time slower

1756
01:52:10,450 --> 01:52:18,920
but his nose sinusoidal change call signs all changes sign

1757
01:52:18,930 --> 01:52:22,960
so keep in mind which is going to be important in what follows today

1758
01:52:24,030 --> 01:52:27,250
from this you can determine the periods

1759
01:52:27,280 --> 01:52:28,730
the speed

1760
01:52:28,740 --> 01:52:32,570
and the radius

1761
01:52:32,610 --> 01:52:35,350
no electromagnetic radiation

1762
01:52:36,500 --> 01:52:39,240
showstopper shift

1763
01:52:39,400 --> 01:52:40,660
that means

1764
01:52:40,700 --> 01:52:44,890
if you move towards the source of electromagnetic radiation

1765
01:52:44,940 --> 01:52:47,140
you will

1766
01:52:47,150 --> 01:52:51,150
we caught a higher frequency than was transmitting

1767
01:52:51,160 --> 01:52:54,690
and if the source of radiation comes to you but also

1768
01:52:54,700 --> 01:52:56,650
record high frequency

1769
01:52:56,670 --> 01:53:01,720
and if you move away from each other your record lower frequency

1770
01:53:01,780 --> 01:53:04,250
and the doppler shift equation four

1771
01:53:04,270 --> 01:53:09,280
electromagnetic radiation is not so easy to derive you need special relativity for that

1772
01:53:09,320 --> 01:53:11,750
but i will give you the result

1773
01:53:11,820 --> 01:53:13,590
i want you to appreciate

1774
01:53:14,740 --> 01:53:19,470
there is no such thing as a velocity of the receiver and the separate velocity

1775
01:53:19,470 --> 01:53:22,480
of the transmitter now because in special relativity

1776
01:53:22,540 --> 01:53:25,930
the only thing that matters is the relative velocity between the two

1777
01:53:25,940 --> 01:53:28,690
it is an illegal question even to ask

1778
01:53:28,740 --> 01:53:30,280
who is moving towards home

1779
01:53:30,290 --> 01:53:33,600
and was moving away from home so there's only one velocity

1780
01:53:33,610 --> 01:53:36,330
in special relativity

1781
01:53:36,390 --> 01:53:37,590
so let this be

1782
01:53:37,600 --> 01:53:38,830
the transmitter

1783
01:53:38,870 --> 01:53:41,180
of electromagnetic radiation

1784
01:53:41,190 --> 01:53:43,410
and there's been a receiver

1785
01:53:43,450 --> 01:53:47,080
and this is the relative velocity v

1786
01:53:47,140 --> 01:53:49,440
and this angle to say that

1787
01:53:49,440 --> 01:53:52,530
i'm not trying to tell you that it is this object that is moving in

1788
01:53:52,530 --> 01:53:56,070
this direction it could be this one that is moving in this direction this is

1789
01:53:56,070 --> 01:53:58,670
the relative velocity between

1790
01:53:58,700 --> 01:53:59,340
the two

1791
01:53:59,350 --> 01:54:02,430
in the line of sight

1792
01:54:02,490 --> 01:54:03,460
so the

1793
01:54:03,480 --> 01:54:08,240
component of the velocity which we call the radial component which plays an important role

1794
01:54:08,240 --> 01:54:09,340
that two

1795
01:54:09,400 --> 01:54:10,900
so this component

1796
01:54:10,950 --> 01:54:11,980
is the

1797
01:54:11,990 --> 01:54:15,300
cosine theta

1798
01:54:15,340 --> 01:54:17,970
and with this picture in mind

1799
01:54:17,990 --> 01:54:19,300
if this one

1800
01:54:21,070 --> 01:54:22,960
the wavelength lambda

1801
01:54:23,030 --> 01:54:24,700
which frequency f

1802
01:54:24,710 --> 01:54:28,070
and this one receives wavelength lambda prime

1803
01:54:28,140 --> 01:54:30,900
with frequency as prime

1804
01:54:30,910 --> 01:54:34,290
then lambda one lambda prime is

1805
01:54:34,330 --> 01:54:36,810
c divided by f crime

1806
01:54:36,820 --> 01:54:37,950
and lambda

1807
01:54:37,980 --> 01:54:41,210
c divided by f

1808
01:54:41,220 --> 01:54:46,640
i will give you the results of the doppler shift equation in terms of land

1809
01:54:46,690 --> 01:54:48,250
and then you can always

1810
01:54:48,280 --> 01:54:51,650
use that relationship to do it in terms of f

1811
01:54:51,650 --> 01:54:58,930
it's given when you really loved this made significant technical innovations in the field had

1812
01:54:58,930 --> 01:55:05,060
been transferred to practice in significant ways has significantly influenced the direction of the research

1813
01:55:05,180 --> 01:55:11,670
and development team in this also includes a black knowledge

1814
01:55:11,670 --> 01:55:18,470
the best innovation award in his friedman like manila due you

1815
01:55:18,580 --> 01:55:20,560
nations cup

1816
01:55:20,600 --> 01:55:33,390
and pleasure to announce c is mission one is something

1817
01:55:40,880 --> 01:55:47,380
the award is given very seven contributions to machine learning and data mining algorithms that

1818
01:55:47,380 --> 01:55:53,810
scales to large commercial database systems and for applications in mining massive data sets the

1819
01:55:54,080 --> 01:55:59,190
to fundamentally new scientific discoveries and citation links

1820
01:55:59,250 --> 01:56:00,020
forty two

1821
01:56:00,030 --> 01:56:01,490
so vv

1822
01:56:01,500 --> 01:56:03,330
phd from michigan

1823
01:56:03,330 --> 01:56:08,840
chief data officer executive vice president for research and strategic solutions

1824
01:56:08,890 --> 01:56:15,720
founder and chairman DMX group functions e g is currently fellow ACM and finally to

1825
01:56:15,720 --> 01:56:17,810
their and all words

1826
01:56:17,830 --> 01:56:23,660
he got to service award in two thousand three from and as born maybe five

1827
01:56:23,660 --> 01:56:26,470
minutes exceptional achievement nineteen ninety four

1828
01:56:26,520 --> 01:56:30,990
and you can see lead one products maybe three

1829
01:56:31,030 --> 01:56:34,490
four security cell is currently

1830
01:56:34,500 --> 01:56:40,110
the secretary treasurer and he was awarded that from nineteen ninety two thousand five singh

1831
01:56:40,110 --> 01:56:43,190
was the founding editor in chief of security

1832
01:56:43,200 --> 01:56:45,200
explorations and also the

1833
01:56:46,250 --> 01:56:54,140
and which key ninety five post-conference john ninety six german in nineteen

1834
01:56:54,160 --> 01:56:55,460
he just two

1835
01:56:55,470 --> 01:57:04,040
kdd and not something like a chance of additional papers and fifty medications and thirty

1836
01:57:04,400 --> 01:57:06,930
two twenty

1837
01:57:08,840 --> 01:57:09,730
this is the one

1838
01:57:09,750 --> 01:57:11,540
like it looks like

1839
01:57:13,370 --> 01:57:14,380
thank you

1840
01:57:25,500 --> 01:57:26,850
thank you for me

1841
01:57:26,900 --> 01:57:28,680
i agree in

1842
01:57:29,150 --> 01:57:31,600
everyone this is a

1843
01:57:31,620 --> 01:57:33,180
i agree to

1844
01:57:33,220 --> 01:57:35,980
let me start with

1845
01:57:36,000 --> 01:57:39,600
but actually

1846
01:57:39,620 --> 01:57:40,850
thank you some people

1847
01:57:40,870 --> 01:57:44,180
i know this is a long list and i don't mean to

1848
01:57:44,410 --> 01:57:46,120
and a lot of it

1849
01:57:46,160 --> 01:57:51,910
it's very humbling to be awarded the award

1850
01:57:51,940 --> 01:57:57,560
it is a big deal to me and i apologize for called by some congested

1851
01:57:57,560 --> 01:57:59,060
forgive me

1852
01:57:59,500 --> 01:58:01,680
first and foremost thank my family

1853
01:58:01,690 --> 01:58:03,880
my wife kristina

1854
01:58:03,900 --> 01:58:06,780
my four kids three of which are in the audience

1855
01:58:09,440 --> 01:58:14,340
and my parents actually like to dedicate this lecture to memory of my mother passed

1856
01:58:14,340 --> 01:58:15,470
away your

1857
01:58:15,500 --> 01:58:18,570
know she would be proud of the

1858
01:58:18,620 --> 01:58:24,320
a lot of people have influenced my work throughout the years and are listed some

1859
01:58:24,320 --> 01:58:29,150
of them are like that you don't want to read everything before that

1860
01:58:29,680 --> 01:58:31,220
but the point of

1861
01:58:32,970 --> 01:58:37,870
i really don't deserve all the credit three a a lot of people who

1862
01:58:37,980 --> 01:58:41,900
i happen to be fortunate enough that they a crossed my line

1863
01:58:41,940 --> 01:58:44,530
and we are extremely helpful

1864
01:58:44,540 --> 01:58:46,650
in getting to this point

1865
01:58:47,910 --> 01:58:49,000
so i mean

1866
01:58:49,070 --> 01:58:52,250
introduced me was actually on my

1867
01:58:52,810 --> 01:58:54,030
he was my first

1868
01:58:54,060 --> 01:58:55,460
summer job

1869
01:58:55,470 --> 01:58:58,210
in general more research

1870
01:58:58,260 --> 01:59:02,910
and actually introduced me to what eventually became my phd topic

1871
01:59:02,960 --> 01:59:04,970
at the time when you're working with

1872
01:59:04,980 --> 01:59:11,040
with data on automobile

1873
01:59:11,050 --> 01:59:14,650
automobile repairs as GM likes to call it not false

1874
01:59:15,530 --> 01:59:21,470
and since then he has been very instrumental in

1875
01:59:21,660 --> 01:59:23,460
helping out my career

1876
01:59:23,470 --> 01:59:25,600
same degree

1877
01:59:25,610 --> 01:59:29,540
shortly thereafter offered me another summer jobs in an effort to put him but i

1878
01:59:29,540 --> 01:59:30,950
want to

1879
01:59:30,960 --> 01:59:33,100
GPL which also changed my life

1880
01:59:33,100 --> 01:59:38,870
there's a lot of people and i'm extremely thankful to them and forced most recently

1881
01:59:38,870 --> 01:59:41,470
my colleagues

1882
01:59:41,520 --> 01:59:43,300
so i thought i'd do today

1883
01:59:43,320 --> 01:59:45,970
and we try to keep it short

1884
01:59:47,280 --> 01:59:49,930
i happen to be in a very unusual

1885
01:59:50,390 --> 01:59:56,050
w or i guess it's going to be giving a lecture on tuesday morning as

1886
01:59:56,110 --> 01:59:58,230
invited talks

1887
01:59:58,240 --> 02:00:01,240
and what i wanted to do is leave the two

1888
02:00:02,340 --> 02:00:04,670
be very different

1889
02:00:04,740 --> 02:00:05,790
i one two

1890
02:00:05,830 --> 02:00:07,910
make this one a bit more personal

1891
02:00:07,910 --> 02:00:09,490
since it's about

1892
02:00:09,510 --> 02:00:10,920
getting an award and

1893
02:00:10,930 --> 02:00:17,220
about how i got here so it's really i call a data miner's story

1894
02:00:17,220 --> 02:00:19,990
o open is going to have a happy ending

1895
02:00:20,450 --> 02:00:26,240
but mostly personal observations about what we are frankly i introduced to

1896
02:00:26,330 --> 02:00:30,620
the grand challenges of the talking some more about the technical grand challenges today i'll

1897
02:00:30,620 --> 02:00:33,220
talk about the pragmatic once and for all

1898
02:00:33,230 --> 02:00:35,960
basically on my experience

1899
02:00:35,970 --> 02:00:37,300
through field

1900
02:00:37,490 --> 02:00:41,820
on these so hopefully this will be useful and interesting

1901
02:00:41,830 --> 02:00:46,910
so i think we'll just give you understanding why data mining is a must

1902
02:00:49,990 --> 02:00:54,260
throughout my story at least some of the challenges that i think it's very important

1903
02:00:54,360 --> 02:00:56,830
for the pragmatic perspective

1904
02:00:56,870 --> 02:00:58,670
and some case studies

1905
02:00:58,700 --> 02:01:00,800
well including

1906
02:01:00,820 --> 02:01:03,410
so let's start with the

1907
02:01:03,420 --> 02:01:09,280
with the again why people being a lot of attention to

1908
02:01:09,280 --> 02:01:11,180
data mining

1909
02:01:12,210 --> 02:01:13,530
one right

1910
02:01:13,540 --> 02:01:16,590
eighteen months we double processing speed

1911
02:01:16,600 --> 02:01:22,990
this story to according to many and estimates including jim gray doubles every nine months

1912
02:01:23,020 --> 02:01:24,300
so you get

1913
02:01:24,320 --> 02:01:26,220
double the amount


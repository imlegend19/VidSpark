1
00:00:00,000 --> 00:00:05,070
is the way to represent the entire application in terms of an abstract more than

2
00:00:05,100 --> 00:00:06,890
it will be basically

3
00:00:06,930 --> 00:00:08,280
this stuff

4
00:00:09,080 --> 00:00:13,890
so it will talk about whatever it will be possible to do with applications in

5
00:00:13,890 --> 00:00:16,690
terms of abstract way of using it

6
00:00:16,720 --> 00:00:20,280
on the other side here you have the more the better

7
00:00:20,840 --> 00:00:23,440
try to address the content

8
00:00:23,710 --> 00:00:28,990
so i brought it here ontology but actually my have multiple ontologies in our case

9
00:00:28,990 --> 00:00:34,330
we will have an ontology for musicmoz anybody from musicbrainz an ontology for EV

10
00:00:34,340 --> 00:00:35,130
OK so

11
00:00:35,130 --> 00:00:36,810
all of these will

12
00:00:36,870 --> 00:00:38,530
the representation

13
00:00:38,560 --> 00:00:41,820
of that series in the semantic models

14
00:00:41,870 --> 00:00:47,160
right and we develop than before we started writing the court

15
00:00:47,170 --> 00:00:50,840
because this is part of the development process you start from the more than you

16
00:00:50,840 --> 00:00:53,940
use the more the all from the way down to the implementation

17
00:00:54,130 --> 00:00:58,870
and you said step which is important i believe which is don't forget that you

18
00:00:58,870 --> 00:01:00,230
need the data

19
00:01:00,280 --> 00:01:05,750
so that's the state it's time to try to model the data from different sources

20
00:01:05,790 --> 00:01:10,710
in these models and see their feet because data on you will have to write

21
00:01:10,710 --> 00:01:14,620
to the way you start to the data and the like these you will have

22
00:01:14,620 --> 00:01:19,570
them represented already in terms of their

23
00:01:19,620 --> 00:01:21,010
of the ontologies

24
00:01:22,970 --> 00:01:29,470
when you have done all these you can design application as the court

25
00:01:29,520 --> 00:01:31,730
when developing an ontology

26
00:01:31,730 --> 00:01:33,440
of course you should follow

27
00:01:35,300 --> 00:01:40,810
all engineer process to do that we would normally follow them it on the methontology

28
00:01:40,810 --> 00:01:46,710
upholstered unbiased some governments parents at you but one can use it in a different

29
00:01:46,710 --> 00:01:52,240
approach that you might like the idea is first of voice things about reusing

30
00:01:52,280 --> 00:01:56,740
so there are tons of terminologies outside in the web don't do it again

31
00:01:57,880 --> 00:02:01,740
normally you cannot find one single more than that satisfy you so you have to

32
00:02:01,740 --> 00:02:02,790
merge them

33
00:02:02,840 --> 00:02:05,270
the different more that you want to reuse

34
00:02:05,280 --> 00:02:10,000
and sometimes they don't satisfy even when you merge them all you need so you

35
00:02:10,000 --> 00:02:15,900
have to extend but basically these three steps should be enough to develop the ontology

36
00:02:15,900 --> 00:02:21,040
even if it is the application ontology of the content on the page

37
00:02:21,050 --> 00:02:22,890
i would try to show them

38
00:02:22,890 --> 00:02:23,600
during the

39
00:02:23,750 --> 00:02:24,850
the tutorial

40
00:02:24,870 --> 00:02:30,700
then we got implementation and we broke down implementation in four steps you know the

41
00:02:30,700 --> 00:02:32,260
first two of them

42
00:02:32,320 --> 00:02:38,470
the importance first step is to implement the initial knowledge base so what you want

43
00:02:38,470 --> 00:02:39,200
to do

44
00:02:39,240 --> 00:02:42,830
as i said you have an ontology here

45
00:02:42,840 --> 00:02:44,190
ontology here

46
00:02:44,190 --> 00:02:48,770
and here so you try to develop these ontology

47
00:02:48,830 --> 00:02:52,330
and to put them together and see if they fit together

48
00:02:52,400 --> 00:02:56,450
and you put the this simple scene and you try to show to show you

49
00:02:56,450 --> 00:03:01,120
said that you're not going to derive the knowledge that you are not expected

50
00:03:01,130 --> 00:03:05,930
i mean the things that you inferring things that you are not expecting or you

51
00:03:05,930 --> 00:03:10,060
are also trying to show yourself that all of the knowledge that you want to

52
00:03:10,060 --> 00:03:14,480
give it from the congo requirement is represented down here

53
00:03:14,490 --> 00:03:17,090
if you do when you have done your

54
00:03:17,740 --> 00:03:22,980
two these input and implementing integrated model which means that connect connected

55
00:03:23,030 --> 00:03:26,660
all these interpretative abstract more than you have the complete more than

56
00:03:26,690 --> 00:03:31,240
you can start writing queries and checking the more that works without any java called

57
00:03:31,240 --> 00:03:35,970
around just brightest under greedy century cave or the police are working properly

58
00:03:35,980 --> 00:03:41,330
all the data that expect that coming out using this simple content

59
00:03:41,350 --> 00:03:48,450
and here i stress that this first approach so you've right all the testing of

60
00:03:48,450 --> 00:03:53,300
and then you keep trying them because every time you change one of these things

61
00:03:53,310 --> 00:03:57,560
something broke down so if you have the tests you can find them and check

62
00:03:57,560 --> 00:04:02,170
if everything is keeping working on this standard software engineering approach

63
00:04:02,210 --> 00:04:06,980
and here i come with the last two implementation things which are about how you

64
00:04:06,980 --> 00:04:08,460
extract the data

65
00:04:08,470 --> 00:04:15,420
from your sources you i call it choose content annotation methods because in the old

66
00:04:15,420 --> 00:04:20,530
semantic web days we we're expecting to extract the most of information for web pages

67
00:04:20,560 --> 00:04:22,670
so it was a way to

68
00:04:23,740 --> 00:04:26,820
get annotation from content

69
00:04:26,870 --> 00:04:33,390
as an extended meaning or extracting data from a database we call it a content

70
00:04:33,390 --> 00:04:39,400
annotation but i mean you you can see choose the extraction methods as as it

71
00:04:39,550 --> 00:04:41,510
different label for start

72
00:04:41,570 --> 00:04:46,450
and when you have done all this real data coming out from the your sources

73
00:04:46,450 --> 00:04:50,200
and so you can implement application as well as

74
00:04:50,240 --> 00:04:51,740
of course the spiral

75
00:04:51,850 --> 00:04:52,690
so you go

76
00:04:52,690 --> 00:04:53,980
and validation

77
00:04:55,100 --> 00:04:56,240
you start the game

78
00:04:57,160 --> 00:04:59,830
what we see this tutorial just one

79
00:05:01,480 --> 00:05:05,500
we cannot go free for many many times

80
00:05:05,560 --> 00:05:11,710
what we did was user needs analysis is a the style you give me events

81
00:05:13,660 --> 00:05:15,770
so what i'm going to show now

82
00:05:15,800 --> 00:05:18,970
is the requirement analysis from content

83
00:05:22,400 --> 00:05:24,010
as i said

84
00:05:24,340 --> 00:05:30,780
the content will be extracted from existing sources we selective the event that bayes and

85
00:05:30,780 --> 00:05:36,960
these two musical databases sources

86
00:05:37,570 --> 00:05:45,370
if is a quite famous i guess application i guess the today's called eventful and

87
00:05:46,100 --> 00:05:50,700
i believe these are all like one but i might be wrong is owned by

88
00:05:50,700 --> 00:05:52,210
you know when not coming

89
00:05:52,240 --> 00:05:54,810
it's the one boy born by like google

90
00:05:54,830 --> 00:05:56,980
what you can do

91
00:05:56,980 --> 00:05:57,920
it's these

92
00:06:00,690 --> 00:06:03,160
go to

93
00:06:03,340 --> 00:06:06,550
page right as i did up here

94
00:06:06,680 --> 00:06:09,720
a query

95
00:06:09,980 --> 00:06:12,090
these query

96
00:06:18,170 --> 00:06:21,480
i don't believe you can read it but in any case he said i want

97
00:06:21,480 --> 00:06:24,070
to events in san diego

98
00:06:24,070 --> 00:06:29,370
if it is it occasionally ventures so it is described as educational events in the

99
00:06:29,370 --> 00:06:33,060
schema then we throw it away because we don't want it to be there

100
00:06:33,140 --> 00:06:36,990
of things like that so if there is edit information in down so we use

101
00:06:36,990 --> 00:06:37,520
the that

102
00:06:37,530 --> 00:06:41,440
information to fill things away but in the end whatever is there

103
00:06:41,450 --> 00:06:42,480
we think it

104
00:06:42,520 --> 00:06:43,350
OK so

105
00:06:43,360 --> 00:06:47,550
after his transformation which is pretty easy

106
00:06:47,560 --> 00:06:48,650
what you do

107
00:06:48,690 --> 00:06:50,180
is creating a

108
00:06:50,230 --> 00:06:52,270
with the constant query

109
00:06:52,330 --> 00:06:53,810
OK the leagues

110
00:06:53,860 --> 00:06:59,830
so again using sparql this time we are using to construct the triples so we

111
00:06:59,830 --> 00:07:03,860
know which that we were asking if he did before

112
00:07:03,870 --> 00:07:07,560
we know they then that come back we feel that some of them but this

113
00:07:07,560 --> 00:07:12,610
is as i said to reveal in the way we did it in very difficult

114
00:07:12,610 --> 00:07:13,640
as the problem

115
00:07:13,770 --> 00:07:17,480
and then what you do is basically saying OK you got any event

116
00:07:18,280 --> 00:07:21,020
say it is related to the performance

117
00:07:21,060 --> 00:07:23,980
that i was asking for

118
00:07:24,030 --> 00:07:26,010
so the sparql query

119
00:07:26,020 --> 00:07:27,760
it is actually the way

120
00:07:27,770 --> 00:07:30,400
we implement these might be good

121
00:07:30,430 --> 00:07:36,320
these last the linking here

122
00:07:36,700 --> 00:07:39,550
so this is again linking

123
00:07:39,560 --> 00:07:42,850
but unlikely is one that was done

124
00:07:42,860 --> 00:07:47,470
by the people that knows what they were doing and they correctly we have a

125
00:07:47,520 --> 00:07:53,640
right which is with some person that's correct them with some other not connected to

126
00:07:53,680 --> 00:07:58,440
OK these guessing that is link and not the fact that the reality because out

127
00:07:58,440 --> 00:08:04,050
there and if you go and look up to bp your work you will learn

128
00:08:04,740 --> 00:08:07,190
in the dance of these

129
00:08:07,230 --> 00:08:12,650
i mean they wrote down some the interesting query that tries to draw links out

130
00:08:12,650 --> 00:08:15,950
of information unstructured information which is

131
00:08:15,970 --> 00:08:17,680
inside wikipedia

132
00:08:17,690 --> 00:08:21,690
i can give it is in the PD

133
00:08:21,690 --> 00:08:26,140
a lot of things everyone in reason is you can you cannot really know

134
00:08:26,190 --> 00:08:31,270
if a link is not asserted if the link exists you must write down a

135
00:08:31,320 --> 00:08:33,770
piece of code that try to guess it

136
00:08:33,830 --> 00:08:35,310
and then you

137
00:08:35,360 --> 00:08:38,140
check if this was a good at guessing

138
00:08:38,190 --> 00:08:41,220
so linking is probably big problem

139
00:08:42,530 --> 00:08:45,270
rather than the

140
00:08:45,360 --> 00:08:49,610
one is just looking

141
00:08:49,620 --> 00:08:55,260
a long long time ago this

142
00:08:58,360 --> 00:08:59,680
OK sorry

143
00:08:59,910 --> 00:09:02,120
do you know what rest is

144
00:09:06,200 --> 00:09:10,770
i will not accept and

145
00:09:14,280 --> 00:09:17,610
so you may know that some years ago

146
00:09:17,620 --> 00:09:20,110
w three c came up with this stuff so

147
00:09:20,110 --> 00:09:22,860
you have a simple object access protocol

148
00:09:22,860 --> 00:09:28,700
which is the way to exchange messages between services in XML

149
00:09:28,730 --> 00:09:31,230
then they came up with don't

150
00:09:31,360 --> 00:09:36,370
which is a way to describe the services and then they came after we've it's

151
00:09:36,370 --> 00:09:39,980
played of other standards

152
00:09:40,020 --> 00:09:45,140
that i about security addressing

153
00:09:46,620 --> 00:09:50,510
so far and this is called the web

154
00:09:54,150 --> 00:09:56,100
thank you know

155
00:09:56,870 --> 00:09:58,260
it's cool stuff

156
00:09:58,260 --> 00:10:05,180
it was very well inside the organisation

157
00:10:05,190 --> 00:10:08,550
it really works

158
00:10:08,610 --> 00:10:15,020
but when these this was claimed to be web services OK so people should have

159
00:10:15,030 --> 00:10:16,660
use it on the web

160
00:10:16,690 --> 00:10:22,700
but actually what came out from the developer's web two o was

161
00:10:22,720 --> 00:10:24,510
why are we doing this

162
00:10:24,530 --> 00:10:26,010
we have

163
00:10:27,390 --> 00:10:28,660
plain XML

164
00:10:28,740 --> 00:10:35,180
and we need that the very very senior year of service description which looks like

165
00:10:56,770 --> 00:11:00,860
it's a page right is written for your money

166
00:11:01,830 --> 00:11:04,310
may learn about

167
00:11:04,360 --> 00:11:06,810
different queries but they can do

168
00:11:06,870 --> 00:11:15,110
and it's community forest as the one that we are using this one search

169
00:11:15,120 --> 00:11:17,440
as a bunch of parameters

170
00:11:18,470 --> 00:11:20,310
the location the

171
00:11:20,310 --> 00:11:22,100
for a random variable

172
00:11:22,290 --> 00:11:24,130
of f of x

173
00:11:24,190 --> 00:11:28,110
and so it defined as above there

174
00:11:28,120 --> 00:11:33,740
so far so that for for the discrete viable expectation of f of x is

175
00:11:33,740 --> 00:11:40,280
the sum of the exciting f of x times by i

176
00:11:43,250 --> 00:11:50,540
not admissible decision theory that i really easy for bernoulli variables

177
00:11:52,000 --> 00:11:59,000
p one is the probability of can being one piece you is the probability of

178
00:11:59,000 --> 00:12:00,310
x being zero

179
00:12:00,320 --> 00:12:06,720
you by applying the previous formulas you see that the expectation is p and the

180
00:12:06,720 --> 00:12:11,060
variance is actually p tends to one minus p

181
00:12:11,150 --> 00:12:20,390
and expectation of any function of x is is this one

182
00:12:21,220 --> 00:12:25,060
it is instead of having

183
00:12:25,110 --> 00:12:29,270
of observing only one converse you observe two of them then

184
00:12:29,320 --> 00:12:31,690
we may define random viable

185
00:12:31,740 --> 00:12:36,020
that takes values two

186
00:12:36,070 --> 00:12:38,380
that takes values that are

187
00:12:39,580 --> 00:12:40,990
two dimensional

188
00:12:44,040 --> 00:12:47,410
so zero zero and the two concepts

189
00:12:49,440 --> 00:12:50,410
ten is

190
00:12:50,420 --> 00:12:55,980
zero one was the first one is there and the second one is its

191
00:12:56,100 --> 00:12:57,910
once you're

192
00:12:57,920 --> 00:12:59,820
and in one one

193
00:12:59,830 --> 00:13:04,270
o are the possible outcomes of of the random variable y

194
00:13:04,280 --> 00:13:09,820
so why has to according to random vectors

195
00:13:09,860 --> 00:13:14,770
and you can define its expertise its expectation

196
00:13:15,600 --> 00:13:17,730
you can write a few right

197
00:13:18,920 --> 00:13:22,860
the vector x one x two

198
00:13:22,870 --> 00:13:30,080
with x one x two to two bernoulli distribution the two bernoulli parable corresponding to

199
00:13:30,090 --> 00:13:31,830
the two going to assess

200
00:13:31,850 --> 00:13:36,380
the expectation of y is the vector made of

201
00:13:36,390 --> 00:13:39,110
the expectation of x one

202
00:13:39,120 --> 00:13:42,240
and the expectation of x two

203
00:13:46,630 --> 00:13:49,700
the and the variance of y

204
00:13:51,210 --> 00:13:57,500
a little bit more tricky to define actually you have to represent volumes by the

205
00:13:57,500 --> 00:13:59,590
covariance matrix

206
00:13:59,600 --> 00:14:06,150
it's the rating matrix so in this case it's the two by two matrix

207
00:14:06,210 --> 00:14:13,780
and the its entries are its diagonal entries are the volumes of of each of

208
00:14:13,780 --> 00:14:15,390
the coordinates there

209
00:14:15,450 --> 00:14:17,880
so the diagonal entries here

210
00:14:17,890 --> 00:14:22,990
well the covariance of y are the values of its one divided into fixed too

211
00:14:23,000 --> 00:14:25,260
and on the other hand on

212
00:14:25,270 --> 00:14:27,650
outside of the day i goal

213
00:14:27,660 --> 00:14:35,820
the entries of the covariance matrix of similar she senior former as

214
00:14:35,830 --> 00:14:41,450
the variance it's an expectation of x one x i x j minus the product

215
00:14:41,450 --> 00:14:43,040
of the expectation

216
00:14:43,060 --> 00:14:49,040
right so if i is equal to j then you find again the variance

217
00:14:49,070 --> 00:14:54,020
so it's it's a measure of

218
00:14:54,030 --> 00:14:58,620
how similar are the two random variable x i and x j

219
00:14:58,740 --> 00:15:03,650
i think i did the computation for the very latest revision again

220
00:15:03,730 --> 00:15:06,990
you have the expectations of the

221
00:15:07,040 --> 00:15:08,630
of the

222
00:15:08,640 --> 00:15:17,440
two distributions and the covariance matrix if the two acquaintances are independent

223
00:15:17,450 --> 00:15:18,490
so i

224
00:15:18,500 --> 00:15:20,950
come back to independence afterwards

225
00:15:20,960 --> 00:15:25,940
but you don't necessarily have zeros on the diagonal here you have used because they

226
00:15:26,020 --> 00:15:30,190
assume that the two going to is independent

227
00:15:34,790 --> 00:15:42,970
OK then know there says independence implies correlation but the inverse is true so the

228
00:15:42,970 --> 00:15:46,600
correlation is the fact that the covariance between two

229
00:15:46,610 --> 00:15:49,190
really random variable is you

230
00:15:50,150 --> 00:15:59,790
and then of course i'll come back to that later as well

231
00:15:59,830 --> 00:16:02,000
if instead of

232
00:16:02,130 --> 00:16:06,110
taking values in into discrete then x

233
00:16:06,160 --> 00:16:08,150
these values in in

234
00:16:08,260 --> 00:16:13,270
three line for example then you get a continuous random variable

235
00:16:17,580 --> 00:16:22,960
well what you could see is that

236
00:16:23,020 --> 00:16:27,570
there's not much sense in in saying what is the probability of x

237
00:16:27,580 --> 00:16:34,670
being exactly is equal to the value small acts but more

238
00:16:34,720 --> 00:16:40,610
the what the when and the probability is going to be able to measure is

239
00:16:40,640 --> 00:16:44,030
axes easy actually in interval

240
00:16:54,070 --> 00:17:00,530
let's let's talk about the expectations the expectation is defined as before on on omega

241
00:17:00,610 --> 00:17:03,380
so it's the integral of x of omega

242
00:17:03,390 --> 00:17:04,900
the appeal again

243
00:17:04,920 --> 00:17:07,760
and in few

244
00:17:07,760 --> 00:17:11,650
transport people to the real line through px

245
00:17:11,670 --> 00:17:16,040
and you find that the expectation of x the integral of x p of x

246
00:17:17,030 --> 00:17:24,520
so that would be only annotation now what happens is that east you can write

247
00:17:24,520 --> 00:17:27,160
these these probability

248
00:17:29,650 --> 00:17:37,940
a product of positive and negative function times delivering measure so the living measure is

249
00:17:37,980 --> 00:17:43,880
is usually your usual measure when you right into walls on on on the real

250
00:17:44,670 --> 00:17:50,980
then x is said to have a probability density function f of x

251
00:17:51,000 --> 00:17:57,870
and so this expectation there is nothing more than the integral of

252
00:17:58,870 --> 00:18:01,820
times f x of x dx

253
00:18:08,810 --> 00:18:13,450
now for any measurable function you can you can define the expectation of f of

254
00:18:13,450 --> 00:18:16,540
x and you can also define the variance of

255
00:18:16,630 --> 00:18:18,290
of x

256
00:18:18,290 --> 00:18:19,780
which has the the

257
00:18:19,790 --> 00:18:23,360
same in the same format as before

258
00:18:23,370 --> 00:18:28,370
we OK

259
00:18:28,470 --> 00:18:35,460
so here are two really is really common distribution on underlying the first one is

260
00:18:35,460 --> 00:18:39,010
the uniform distribution on on this thing and a b

261
00:18:39,050 --> 00:18:40,900
so you can

262
00:18:40,920 --> 00:18:44,130
definitely easily see that the pdf of

263
00:18:44,170 --> 00:18:51,400
the uniform is aware is o one divided by the main this is the stuff

264
00:18:52,720 --> 00:18:57,640
the indicates the indicator of x being in

265
00:18:57,640 --> 00:19:01,120
here's the gambit that's how you're going to solve these problems to go through this

266
00:19:01,160 --> 00:19:03,180
the set of operations

267
00:19:03,220 --> 00:19:06,100
go through the set of operations so just to recap

268
00:19:06,160 --> 00:19:08,990
if you go to look at this simple cubic

269
00:19:09,010 --> 00:19:12,160
the hkl sequences one two

270
00:19:12,180 --> 00:19:13,700
three four

271
00:19:13,760 --> 00:19:15,580
five six

272
00:19:17,600 --> 00:19:20,740
because there's no sum of integers that will give you

273
00:19:20,790 --> 00:19:23,770
seven if you some squares of integers

274
00:19:24,470 --> 00:19:26,850
so give you all the lines but this is

275
00:19:26,890 --> 00:19:31,830
eight squared plus k squared plus elsewhere in ascending value

276
00:19:31,870 --> 00:19:34,060
right body centered cubic

277
00:19:34,100 --> 00:19:35,950
body centered cubic has to be

278
00:19:35,970 --> 00:19:37,770
two four six

279
00:19:37,790 --> 00:19:41,760
eight ten twelve fourteen sixteen

280
00:19:41,870 --> 00:19:46,620
but when you first do this you don't know because you divide by the first

281
00:19:46,660 --> 00:19:50,560
sine square and so you don't know it's two four six eight you can end

282
00:19:50,560 --> 00:19:52,140
up with one two

283
00:19:52,200 --> 00:19:56,810
three four now that we have a problem simple cubic is going one two three

284
00:19:57,620 --> 00:20:02,830
and body centered cubic is going one two three four but watch this perseverance

285
00:20:02,890 --> 00:20:08,540
half of ten is five half of twelve six have of fourteen seven

286
00:20:10,140 --> 00:20:12,410
so if you guessed that something

287
00:20:12,410 --> 00:20:15,910
when you divide through you get a sequence that gives you one two three four

288
00:20:15,910 --> 00:20:17,430
five six seven

289
00:20:17,470 --> 00:20:21,350
you know that it can't be simple cubic because there is no some of

290
00:20:21,370 --> 00:20:26,030
integer squares to give you seven the seven in fact must be fourteen divided by

291
00:20:26,760 --> 00:20:28,510
this is body centered cubic

292
00:20:28,530 --> 00:20:32,850
face centered cubic is the easiest one to pick off because it gives you three

293
00:20:33,870 --> 00:20:35,240
eight eleven

294
00:20:35,270 --> 00:20:39,230
twelve and i just need to see three four and i always check for fifty

295
00:20:39,230 --> 00:20:40,700
cc first

296
00:20:40,700 --> 00:20:43,470
always check for FCC first

297
00:20:43,510 --> 00:20:45,080
so was that's how

298
00:20:45,080 --> 00:20:48,830
that's how different commentary works and it allows you to index

299
00:20:48,850 --> 00:20:53,330
crystals in determining crystal structure more broadly speaking there's database

300
00:20:53,330 --> 00:20:55,850
all sorts of

301
00:20:55,870 --> 00:20:58,310
minerals and compounds and so on

302
00:20:58,470 --> 00:21:03,010
let's look at the second technique the second technique is called allowing the fraction

303
00:21:03,010 --> 00:21:08,180
allowing the fraction named after max von who got the nobel prize

304
00:21:08,180 --> 00:21:11,600
he was the first person to demonstrate x-ray

305
00:21:11,600 --> 00:21:16,510
identification of crystal structure that the nobel in nineteen twelve

306
00:21:16,530 --> 00:21:18,100
nineteen twelve for this

307
00:21:18,120 --> 00:21:23,890
and in lower we fix the angle specimen is stationary and

308
00:21:25,600 --> 00:21:27,120
variable with

309
00:21:27,120 --> 00:21:31,600
radiation so how do we get variable wavelength radiation look at that spectrum up there

310
00:21:31,600 --> 00:21:36,310
you see the bremsstrahlung branch round gives you a range of wavelengths

311
00:21:37,200 --> 00:21:40,490
well we're how do we get monochromatic radiation

312
00:21:40,490 --> 00:21:44,970
how do we get monochromatic x-rays don't tell me big by an x-ray laser

313
00:21:45,010 --> 00:21:47,530
how do we get monochromatic x-rays

314
00:21:48,530 --> 00:21:50,220
it's really cool what you do

315
00:21:50,240 --> 00:21:52,740
if you take

316
00:21:52,790 --> 00:21:53,890
you take this

317
00:21:53,950 --> 00:21:55,260
brahms strauss

318
00:21:55,290 --> 00:21:58,930
with everything on

319
00:21:58,950 --> 00:22:01,930
and you presented to a single crystal

320
00:22:01,930 --> 00:22:03,970
you presented to single crystal

321
00:22:03,970 --> 00:22:08,470
and the new park over here this is the entrance slit you're different armor

322
00:22:08,560 --> 00:22:11,600
what will go through that inference split

323
00:22:11,620 --> 00:22:12,720
there's only one

324
00:22:12,740 --> 00:22:17,910
wavelength will go through that inference and that's the wavelength that satisfies the bragg condition

325
00:22:17,910 --> 00:22:19,760
for this lattice spacing

326
00:22:19,810 --> 00:22:20,990
this angle

327
00:22:20,990 --> 00:22:22,390
so what i can do

328
00:22:22,390 --> 00:22:27,770
as i can make a single crystal monochrome under the basically takes

329
00:22:29,040 --> 00:22:34,260
characteristic spectrum on top of the gram strong sense that in

330
00:22:34,310 --> 00:22:36,220
i present single crystal

331
00:22:36,220 --> 00:22:38,220
and there's only one

332
00:22:38,220 --> 00:22:42,810
the wavelength of light that will come out of fear that satisfies the bragg condition

333
00:22:42,810 --> 00:22:45,490
for this the spacing and this angle

334
00:22:45,510 --> 00:22:48,700
so the single crystal axis of monochrome

335
00:22:48,720 --> 00:22:49,930
very cool

336
00:22:49,950 --> 00:22:53,240
very cool so this is called a single

337
00:22:53,290 --> 00:22:55,390
the crystal

338
00:22:56,830 --> 00:23:04,490
just use regular that's all on this case we just we take the whole

339
00:23:04,490 --> 00:23:05,540
the whole mass

340
00:23:06,600 --> 00:23:11,740
and here's what the specimen looks like the specimen goes into a

341
00:23:11,740 --> 00:23:13,580
a darkened

342
00:23:13,760 --> 00:23:17,470
box is called a camera obscura

343
00:23:17,490 --> 00:23:20,370
camera obscura

344
00:23:20,410 --> 00:23:24,100
and what happens is i can put the specimen on the frontier

345
00:23:24,120 --> 00:23:27,970
the specimen is on the front to some crystal

346
00:23:27,970 --> 00:23:29,290
relatively thin

347
00:23:29,290 --> 00:23:31,890
and i put film on the back

348
00:23:31,950 --> 00:23:34,430
films on the back so i have

349
00:23:34,450 --> 00:23:39,290
the film is sensitive to x-rays and now i send the being in

350
00:23:39,290 --> 00:23:42,030
so this is why x-ray

351
00:23:42,080 --> 00:23:47,770
y x y x meaning it's variable wavelengths the whole spectrum

352
00:23:48,390 --> 00:23:49,720
and what happens is

353
00:23:49,720 --> 00:23:51,510
the white x-ray

354
00:23:51,540 --> 00:23:53,680
interact with the specimen

355
00:23:53,700 --> 00:23:57,390
and shoots off at different angles because of the different

356
00:23:57,430 --> 00:24:02,660
initial wavelengths so each wavelength will be diffracted at its own special angle

357
00:24:02,680 --> 00:24:06,010
and so what happens is we end up with a spot pattern

358
00:24:06,040 --> 00:24:08,370
on the film

359
00:24:08,410 --> 00:24:10,970
we end up with a spot pattern and

360
00:24:11,040 --> 00:24:19,060
spot pattern spot pattern is the output and the symmetry

361
00:24:19,100 --> 00:24:20,490
on the spot

362
00:24:20,540 --> 00:24:23,430
and i'm going to take you into k space and so on but i we

363
00:24:23,430 --> 00:24:27,350
simply tell you that all you need to appreciate at this point is that the

364
00:24:27,350 --> 00:24:31,490
symmetry in the spot pattern is imitators

365
00:24:31,510 --> 00:24:33,930
was imitator of

366
00:24:33,950 --> 00:24:35,540
the symmetry

367
00:24:35,560 --> 00:24:36,640
in the crystal

368
00:24:36,700 --> 00:24:41,970
symmetry in the crystal

369
00:24:42,010 --> 00:24:45,620
so when we say something about atomic symmetry

370
00:24:45,640 --> 00:24:49,810
and this is based on the time years rotational symmetry because we're looking at something

371
00:24:49,810 --> 00:24:53,430
on edge so for example if i gave you the

372
00:24:53,450 --> 00:24:55,560
all all one plane

373
00:24:55,580 --> 00:24:59,490
if i give you the all one claiming cubic crystal looks like this

374
00:24:59,510 --> 00:25:06,010
right so now what i want to do is look at rotation rotation about

375
00:25:06,040 --> 00:25:09,830
a normal access

376
00:25:09,850 --> 00:25:13,740
rotation about all axes somewhere to put a normal axis right here at the centre

377
00:25:14,060 --> 00:25:17,930
and rotate this one actually the question how

378
00:25:17,950 --> 00:25:20,450
from one angle do i have to rotate this

379
00:25:20,450 --> 00:25:22,430
in order to get this back

380
00:25:22,430 --> 00:25:25,720
so if you close your eyes and i start rotating suppose i rotated forty five

381
00:25:26,540 --> 00:25:29,870
you open your eyes are going to see that you going know something's move

382
00:25:29,910 --> 00:25:33,640
how many degrees you have to rotate before i get this back

383
00:25:33,700 --> 00:25:37,870
nine by rotating ninety degrees i will end up with

384
00:25:37,890 --> 00:25:41,240
this and these are indistinguishable so ninety degrees

385
00:25:41,270 --> 00:25:45,850
here's what i need to rotate and the crystallography first instead of talking about the

386
00:25:45,850 --> 00:25:47,760
angle of rotation

387
00:25:48,430 --> 00:25:52,810
restore what you're looking at the talk about fall

388
00:25:52,810 --> 00:25:56,810
node c so in both the notes c is going to store like one and

389
00:25:56,810 --> 00:26:00,790
nobody's going to store link to but in addition that like most the past that

390
00:26:00,790 --> 00:26:01,960
they use

391
00:26:02,060 --> 00:26:05,690
so now what's going to happen is that each of CNT is going to during

392
00:26:05,690 --> 00:26:11,340
the next advertisment step c india and also advertising information they have about the

393
00:26:11,360 --> 00:26:14,170
links in the notes they can reach in the network

394
00:26:14,190 --> 00:26:18,750
so i'm only showing advertisments for node easier course at the same time c and

395
00:26:18,750 --> 00:26:22,560
d are also advertising the fact that they can reach themselves and maybe the ability

396
00:26:22,560 --> 00:26:26,230
to reach other nodes in the network shelter just looking at you but their mind

397
00:26:26,290 --> 00:26:29,790
all the advertising is being done for all the time

398
00:26:30,860 --> 00:26:34,570
c send an advertisment this says i can reach no e and the way to

399
00:26:34,590 --> 00:26:40,360
do it is to centre and i can reach node c via c and then

400
00:26:40,460 --> 00:26:44,540
and similarly he sends out a message says i can reach no d five d

401
00:26:44,540 --> 00:26:45,880
and e

402
00:26:45,900 --> 00:26:49,460
so OK that's so up to this point we haven't really seen anything very interesting

403
00:26:49,460 --> 00:26:54,230
but now during the next iteration step we see that these two nodes b and

404
00:26:55,060 --> 00:26:59,710
now have now have heard in advertising to give them a path that allows them

405
00:26:59,710 --> 00:27:01,860
to reach node c

406
00:27:02,710 --> 00:27:05,980
now every node has a path that allows them to reach node you but this

407
00:27:05,980 --> 00:27:08,070
advertisment and

408
00:27:08,090 --> 00:27:11,460
integrations process is going to keep going on so for example

409
00:27:11,480 --> 00:27:12,960
nodes a and b

410
00:27:12,980 --> 00:27:16,980
we're going to advertise that they can also reach node e to their neighbors

411
00:27:16,980 --> 00:27:20,690
and in this case it's probably unlikely that either

412
00:27:20,710 --> 00:27:25,000
any of the nose would like to switch to a new route so for example

413
00:27:25,020 --> 00:27:29,960
it's it's not clear that there there is no reason for example the eight would

414
00:27:29,960 --> 00:27:34,750
want to forward it's mass is probably unlikely a one for its messages

415
00:27:34,770 --> 00:27:35,810
through b

416
00:27:35,840 --> 00:27:37,940
to reach the right because

417
00:27:37,940 --> 00:27:39,480
that's going to to

418
00:27:39,690 --> 00:27:42,980
it's going to be longer happen for a to send its messages simply three c

419
00:27:42,980 --> 00:27:46,980
and e but if the but he doesn't actually know whether or not a knows

420
00:27:46,980 --> 00:27:47,310
about the

421
00:27:47,830 --> 00:27:50,960
so it needs to continue to broadcast this information out

422
00:27:51,420 --> 00:27:55,060
so this is very this this is this is pretty simple it's pretty clear how

423
00:27:55,060 --> 00:27:58,940
this works and once this process has been running for a while you can see

424
00:27:59,020 --> 00:28:04,340
the network is going to converge into state where every node has a pattern if

425
00:28:04,340 --> 00:28:07,540
the long is the network is connected it will converge into a state where every

426
00:28:07,540 --> 00:28:10,110
node has a path to node

427
00:28:10,670 --> 00:28:13,540
and the amount of time it will take for that to happen is equal to

428
00:28:13,540 --> 00:28:17,790
sort of the number of hops the maximum number of any node is away from

429
00:28:19,650 --> 00:28:24,690
once this notice converge now we can trivially build up our forwarding table simply by

430
00:28:24,690 --> 00:28:29,380
pulling out the link number from from each one of these nodes so for example

431
00:28:29,380 --> 00:28:33,770
we can see that he sends either these four in table simply says for each

432
00:28:33,770 --> 00:28:38,210
node in center my and and layer these four people would say to reach node

433
00:28:38,210 --> 00:28:40,400
you send it over my like two

434
00:28:40,440 --> 00:28:44,520
season four in table would say to reach node is the overall one

435
00:28:44,560 --> 00:28:50,250
b forty table would say to reach node is sent over my one so going

436
00:28:50,270 --> 00:28:54,880
so it's once we've done this path vector routing at the end of this process

437
00:28:54,880 --> 00:28:58,480
we all know which links will built up four in table you can use for

438
00:28:58,480 --> 00:29:01,020
saying links

439
00:29:01,360 --> 00:29:05,880
so this is a very simple process but now let's look what happens when something

440
00:29:06,420 --> 00:29:10,750
what we said here is just that each advertiser step we're going and after each

441
00:29:10,750 --> 00:29:13,360
advertisment we're going to go and do integration

442
00:29:13,420 --> 00:29:17,480
integration basically we're going to do is try and pick the best in some way

443
00:29:17,480 --> 00:29:22,310
we've shown here simply taking the shortest path or we the shortest possible path for

444
00:29:22,330 --> 00:29:24,090
every node to reach node

445
00:29:24,090 --> 00:29:28,630
and in case it wasn't clear i didn't explicitly stated states state is important to

446
00:29:28,630 --> 00:29:33,290
realize that nodes are going to ignore advertisments with their own address in the vector

447
00:29:33,380 --> 00:29:36,000
space so if for example

448
00:29:36,020 --> 00:29:39,570
so for example when node e here's no d

449
00:29:39,590 --> 00:29:45,130
advertising that can reach node you know he's going to say oh well i i

450
00:29:45,150 --> 00:29:48,090
am no d i don't actually need to pick up this pattern i don't need

451
00:29:48,090 --> 00:29:51,860
to send my to myself through node you obviously do

452
00:29:51,880 --> 00:29:54,560
now we create a routing loop which is something we presume we don't want to

453
00:29:54,570 --> 00:29:57,750
do so this is a simple way using these sparse vectors we can use to

454
00:29:57,750 --> 00:30:01,460
avoid creating

455
00:30:01,480 --> 00:30:04,810
OK so now let's look at what happened something a little bit more interesting let's

456
00:30:04,810 --> 00:30:07,980
look and see what happens when for example there's a failure so this is just

457
00:30:07,980 --> 00:30:10,380
exactly the same network and i showed you

458
00:30:10,440 --> 00:30:14,420
but suppose for example that the link between d and fails

459
00:30:14,480 --> 00:30:15,750
OK so now

460
00:30:15,770 --> 00:30:17,290
the network

461
00:30:17,310 --> 00:30:21,650
no longer has now note the no longer has around to node

462
00:30:21,690 --> 00:30:25,840
remember the way that describe this is that this advertisment process is just going to

463
00:30:25,840 --> 00:30:29,130
continue going on in the background rate so what's going to happen is that at

464
00:30:29,130 --> 00:30:33,730
some point nobody is going to realize that it's linked to note he went down

465
00:30:34,670 --> 00:30:35,900
is gonna

466
00:30:35,900 --> 00:30:39,960
across the stable table out of its into it so nobody is going to

467
00:30:39,960 --> 00:30:42,860
basically stopped hearing advertisments from node

468
00:30:42,860 --> 00:30:45,460
when it stops hearing advertisers from node e

469
00:30:45,480 --> 00:30:50,400
actually it's going to do something it's basically going to expire entry from its link

470
00:30:50,860 --> 00:30:55,270
so after hasn't heard advertisers finally for while that entry

471
00:30:55,290 --> 00:30:59,400
and then some time later it will hear an advertising from node c saying i

472
00:30:59,400 --> 00:31:01,040
know how to get to know you

473
00:31:01,730 --> 00:31:06,690
node node node d can go ahead and integrate this new pattern to right

474
00:31:06,730 --> 00:31:09,900
now notice that this process is just going to propagate through the network so once

475
00:31:09,900 --> 00:31:14,920
nobody stops hearing advertisments for how to reach node e is going to stop sending

476
00:31:14,920 --> 00:31:16,880
advertising for how to reach node c

477
00:31:16,920 --> 00:31:22,090
so similarly we're gonna because b is also routing its information

478
00:31:24,290 --> 00:31:28,730
had previously been routing packets to reach node c by where he is going to

479
00:31:28,730 --> 00:31:32,440
we have

480
00:31:33,850 --> 00:31:36,150
going back to

481
00:31:36,180 --> 00:31:40,550
rotating objects

482
00:31:40,610 --> 00:31:42,350
i have an object here

483
00:31:43,630 --> 00:31:45,250
has a certain velocity

484
00:31:48,930 --> 00:31:52,350
it's going around with the angular velocity omega

485
00:31:52,370 --> 00:31:53,750
and a little later

486
00:31:53,750 --> 00:31:55,370
the angle has increased

487
00:31:55,480 --> 00:31:57,030
bynum among theta

488
00:31:57,050 --> 00:31:58,620
and then the velocity

489
00:31:58,620 --> 00:32:00,950
is here

490
00:32:01,000 --> 00:32:02,350
we may now

491
00:32:02,360 --> 00:32:04,540
do something we haven't done before

492
00:32:04,570 --> 00:32:06,180
we could

493
00:32:06,240 --> 00:32:10,570
if this object in this circle and acceleration

494
00:32:10,610 --> 00:32:13,710
so we don't have to keep the speed constant

495
00:32:13,750 --> 00:32:17,640
v equals omega are

496
00:32:17,670 --> 00:32:21,360
so that equals state of times are

497
00:32:21,380 --> 00:32:24,100
and i can take now the first derivative of this

498
00:32:24,110 --> 00:32:27,430
that i get the tangential acceleration

499
00:32:27,450 --> 00:32:28,710
which would be

500
00:32:28,750 --> 00:32:30,680
only dot times are

501
00:32:30,700 --> 00:32:34,250
which is paid out double dots are

502
00:32:34,260 --> 00:32:36,110
and we call failed w dot

503
00:32:36,120 --> 00:32:37,430
we call this are five

504
00:32:37,480 --> 00:32:38,650
and of five

505
00:32:38,680 --> 00:32:41,150
is the angular

506
00:32:42,870 --> 00:32:44,790
which is in radiance

507
00:32:44,810 --> 00:32:47,640
a second square

508
00:32:47,730 --> 00:32:54,730
do not confuse ever the tangential acceleration which is along this conference with a centripetal

509
00:32:54,730 --> 00:32:56,810
acceleration the two

510
00:32:56,820 --> 00:33:01,950
both there of course this is the one that makes the speed change along the

511
00:33:04,060 --> 00:33:07,060
if we compare our knowledge of the past

512
00:33:07,090 --> 00:33:08,670
of linear motion

513
00:33:08,710 --> 00:33:10,010
and we want to

514
00:33:10,010 --> 00:33:11,900
transfer it now too

515
00:33:11,900 --> 00:33:13,370
circular motion

516
00:33:13,400 --> 00:33:16,840
then you can use all your creations from the past

517
00:33:16,900 --> 00:33:18,790
if you convert x

518
00:33:22,460 --> 00:33:23,500
and a

519
00:33:23,540 --> 00:33:25,590
two of

520
00:33:25,650 --> 00:33:29,200
and the well known equations that i'm sure you remember

521
00:33:29,230 --> 00:33:31,650
can then all be used for instance

522
00:33:31,710 --> 00:33:33,340
the equation

523
00:33:33,370 --> 00:33:35,950
x equals x zero

524
00:33:36,040 --> 00:33:38,420
let's be zero t

525
00:33:38,480 --> 00:33:39,820
was one half

526
00:33:39,880 --> 00:33:41,380
eighty square and

527
00:33:41,390 --> 00:33:44,200
simply becomes for circular motion

528
00:33:46,230 --> 00:33:47,080
he calls

529
00:33:47,100 --> 00:33:48,760
data zero

530
00:33:48,800 --> 00:33:50,450
it was only god

531
00:33:50,450 --> 00:33:51,830
zero t

532
00:33:52,050 --> 00:33:53,350
one half

533
00:33:53,350 --> 00:33:54,050
of five

534
00:33:54,070 --> 00:33:57,700
the square that simple omega zero is then the

535
00:33:57,700 --> 00:34:00,260
angular velocity at time t equals zero

536
00:34:00,260 --> 00:34:01,550
and theta zero

537
00:34:01,610 --> 00:34:03,020
is the angle

538
00:34:03,070 --> 00:34:07,260
at time t equals zero relative to some reference point

539
00:34:07,330 --> 00:34:09,260
and the velocity

540
00:34:09,320 --> 00:34:11,480
what's the zero plus eighteen

541
00:34:11,570 --> 00:34:13,170
that now becomes

542
00:34:13,230 --> 00:34:14,320
that the

543
00:34:14,350 --> 00:34:16,890
velocity goes to bangalore

544
00:34:16,890 --> 00:34:18,550
velocity omega

545
00:34:18,600 --> 00:34:20,730
people's omega zero

546
00:34:20,770 --> 00:34:22,540
plus of

547
00:34:22,540 --> 00:34:24,390
it is really not much and it

548
00:34:24,390 --> 00:34:26,470
in terms of

549
00:34:26,510 --> 00:34:30,570
remembering equations

550
00:34:30,610 --> 00:34:33,040
if i have a rotating disk

551
00:34:33,070 --> 00:34:36,850
i can ask myself the question of which we have never done before

552
00:34:36,860 --> 00:34:42,020
what kind of kinetic energy how much kinetic energy is there in a rotating disk

553
00:34:42,070 --> 00:34:46,390
we only dealt with linear emotions was one half MV squared which we never consider

554
00:34:46,510 --> 00:34:48,010
rotating objects

555
00:34:48,020 --> 00:34:50,700
and the energy that they contain

556
00:34:50,740 --> 00:34:52,190
so let's work on that a little

557
00:34:52,200 --> 00:34:54,160
i have here this

558
00:34:54,200 --> 00:34:56,940
and the centre of the disc c

559
00:34:56,950 --> 00:35:03,140
and this this is rotating with angular velocity omega that could change in time

560
00:35:03,200 --> 00:35:05,580
and that this has mass and

561
00:35:05,640 --> 00:35:08,320
and the disk has a radius are

562
00:35:08,410 --> 00:35:12,720
and i want to know at this moment how much kinetic energy of rotation is

563
00:35:12,720 --> 00:35:15,610
stored in that this

564
00:35:15,670 --> 00:35:17,890
i take a little mass element here

565
00:35:18,970 --> 00:35:19,800
m of i

566
00:35:19,820 --> 00:35:23,720
and this is radius equals are of i

567
00:35:23,730 --> 00:35:27,410
and the kinetic energy of the element i lung

568
00:35:27,420 --> 00:35:29,080
because one have

569
00:35:29,130 --> 00:35:30,550
and of i

570
00:35:30,610 --> 00:35:32,640
times your of i squared

571
00:35:32,690 --> 00:35:34,320
in view of life

572
00:35:34,350 --> 00:35:37,610
is this philosophy is angle of ninety degrees

573
00:35:37,640 --> 00:35:39,790
this is for your

574
00:35:39,790 --> 00:35:45,420
now vehicles omega are that always holds for these rotating objects and so i prefer

575
00:35:45,420 --> 00:35:46,620
to write this

576
00:35:46,630 --> 00:35:47,980
as one have

577
00:35:47,990 --> 00:35:50,870
and the phi omega

578
00:35:52,730 --> 00:35:54,420
of high screen

579
00:35:54,470 --> 00:35:58,600
the nice thing about writing it this way is that only god the angular velocity

580
00:35:58,600 --> 00:36:02,540
is the same for all points of the disc whereas the velocity is not

581
00:36:02,550 --> 00:36:06,650
because the velocity of the point very close to the centre is very low

582
00:36:06,670 --> 00:36:08,490
the velocity is very high

583
00:36:08,520 --> 00:36:10,420
so by going to make

584
00:36:11,240 --> 00:36:13,880
i don't have that problem anymore

585
00:36:13,930 --> 00:36:16,060
so what is now to kinetic energy

586
00:36:16,080 --> 00:36:17,410
of rotation

587
00:36:17,460 --> 00:36:19,350
of the disc

588
00:36:19,400 --> 00:36:20,810
the entire this

589
00:36:20,850 --> 00:36:23,210
so we have to make a summation

590
00:36:23,250 --> 00:36:24,720
and so that is

591
00:36:24,730 --> 00:36:27,960
only gas created over two

592
00:36:28,000 --> 00:36:30,180
find the sun

593
00:36:30,230 --> 00:36:31,900
of the five

594
00:36:31,900 --> 00:36:35,060
is how to get the best c value now because

595
00:36:35,080 --> 00:36:39,780
you are in this area we have the same plot the number of features here

596
00:36:39,830 --> 00:36:43,910
and see values

597
00:36:43,990 --> 00:36:48,570
that's the same kind of features and and si value

598
00:36:48,600 --> 00:36:53,290
but just to display something is this was the population of bounded support vectors

599
00:36:53,310 --> 00:36:55,640
now we displace the performance

600
00:36:56,310 --> 00:36:59,710
well was the best performance so you want to know

601
00:36:59,720 --> 00:37:03,930
these are around what kind of surveyors we provide you the best performance and then

602
00:37:03,930 --> 00:37:04,580
you see

603
00:37:04,610 --> 00:37:06,460
this is something with which is

604
00:37:06,470 --> 00:37:08,750
you get high performance

605
00:37:08,780 --> 00:37:12,780
for one particular sitting i don't tell you just use one or one because it

606
00:37:12,780 --> 00:37:14,910
depends if you dataset

607
00:37:14,910 --> 00:37:19,050
a few problem but i just because that's what i see in practice

608
00:37:20,460 --> 00:37:25,480
the tendency is to have a linguistic values to to to provide the best performing

609
00:37:27,580 --> 00:37:30,220
so that's one thing

610
00:37:30,220 --> 00:37:33,610
and besides we also

611
00:37:33,620 --> 00:37:37,330
this questioning and and that's why we are still working on it because

612
00:37:37,420 --> 00:37:38,830
we have also these

613
00:37:38,900 --> 00:37:43,310
should a very large feature vectors you might get worse performance than what you would

614
00:37:43,310 --> 00:37:45,960
get here if you were selected features

615
00:37:45,970 --> 00:37:48,060
so we don't know it yet it

616
00:37:48,070 --> 00:37:50,580
what's what's really happening

617
00:37:56,340 --> 00:37:57,420
we observed

618
00:37:57,420 --> 00:37:59,190
a performance dip

619
00:37:59,200 --> 00:38:05,860
for SVM we gave we try to give some some explaination because we spoke about

620
00:38:05,860 --> 00:38:10,810
everyone around two or three but we didn't speak so far about the performance dip

621
00:38:10,870 --> 00:38:14,670
and we observe in between two and three

622
00:38:14,780 --> 00:38:18,510
there are two and three and

623
00:38:18,540 --> 00:38:19,620
and what

624
00:38:19,620 --> 00:38:24,790
we did is just plot as the proportion of bounded support vectors

625
00:38:26,440 --> 00:38:29,460
the proportion to the number of support vectors

626
00:38:29,470 --> 00:38:31,360
so here we have a

627
00:38:31,380 --> 00:38:36,450
if you have this four cells and documents four thousand lines in your metrics

628
00:38:36,690 --> 00:38:44,190
you might have a maximum force cells and involved documents feature vectors in your solution

629
00:38:44,210 --> 00:38:48,940
so we should start at about seventy five percent here three thousand

630
00:38:48,980 --> 00:38:53,760
and you the total number of support vectors which decrease in which you increase again

631
00:38:53,820 --> 00:38:55,320
what's happening

632
00:38:55,630 --> 00:38:59,070
we have the number of features below

633
00:38:59,160 --> 00:39:05,020
what's happening in between it just enabled by the support vectors which is dropping

634
00:39:05,050 --> 00:39:06,230
to minimize

635
00:39:06,240 --> 00:39:10,320
that's what we saw here during interest rates so you have less and less and

636
00:39:10,320 --> 00:39:13,960
less and less about the support vectors and on the other hand

637
00:39:13,970 --> 00:39:15,640
you have more regular

638
00:39:15,770 --> 00:39:17,780
support vectors

639
00:39:17,910 --> 00:39:20,870
a new solution

640
00:39:20,910 --> 00:39:22,300
and fortunately

641
00:39:22,330 --> 00:39:30,080
for us this much approximatively as the performance dip of as SVM

642
00:39:30,130 --> 00:39:34,160
another and comment on this figure

643
00:39:34,180 --> 00:39:35,490
is this

644
00:39:35,510 --> 00:39:37,930
now we have rather regular

645
00:39:37,940 --> 00:39:45,640
solution was very small number of bounded support vectors what's interesting is to observe this

646
00:39:45,660 --> 00:39:50,220
so if i continue increasing the size of my feature vector

647
00:39:50,230 --> 00:39:53,660
solution which are

648
00:39:53,670 --> 00:39:58,360
which involve more and more and more

649
00:39:58,380 --> 00:40:02,040
more more training points of my data set

650
00:40:02,070 --> 00:40:08,340
anyway i have less sparse solution other increases the feature space the size of the

651
00:40:08,340 --> 00:40:09,930
feature space

652
00:40:10,590 --> 00:40:12,800
that's quite expected since

653
00:40:12,810 --> 00:40:14,620
with dimensionality

654
00:40:14,620 --> 00:40:20,640
the more you increase the dimension of few of your problem more points will lie

655
00:40:20,640 --> 00:40:21,940
in the boundary

656
00:40:21,960 --> 00:40:25,270
if you're a few of your problem

657
00:40:25,330 --> 00:40:28,120
it is it to to see for everybody and because

658
00:40:28,150 --> 00:40:30,500
but i'm quite familiar with it but

659
00:40:30,520 --> 00:40:35,460
it's just an illustration of circus of dimension eighty here

660
00:40:35,470 --> 00:40:38,230
you you we need more and more points

661
00:40:38,730 --> 00:40:43,200
the more damaging thank you will be more and more points to

662
00:40:43,200 --> 00:40:46,700
to make the boundary of your class concept so you have a class you have

663
00:40:46,700 --> 00:40:48,260
two classes

664
00:40:48,280 --> 00:40:52,570
the boundary of each of each class

665
00:40:52,580 --> 00:40:54,860
and then you will be more and more documents to

666
00:40:54,860 --> 00:40:56,780
to more it

667
00:40:58,510 --> 00:41:02,970
you expect from has been have sparse solution but here we

668
00:41:03,050 --> 00:41:05,440
in practice we see that

669
00:41:05,670 --> 00:41:11,260
even in high dimension you have more and more the commence involved in the solution

670
00:41:11,260 --> 00:41:13,900
so that's a nice illustration also

671
00:41:14,070 --> 00:41:20,530
if it's good or not i don't know what is very specialist but that's racing

672
00:41:20,530 --> 00:41:21,880
in practice

673
00:41:21,880 --> 00:41:25,150
is is specific to text classification

674
00:41:25,210 --> 00:41:30,210
i'm working with biologist have big data set it in the times ten thousand

675
00:41:30,230 --> 00:41:35,760
it's very similar to text mining we have zero one two values in the data

676
00:41:35,820 --> 00:41:42,110
and actually i could be produced as the performance dip result in

677
00:41:44,240 --> 00:41:45,780
you do not have

678
00:41:49,900 --> 00:41:51,590
this performance dip

679
00:41:53,780 --> 00:41:57,400
you don't have these one but you have to

680
00:41:57,400 --> 00:42:00,090
we have a case

681
00:42:00,090 --> 00:42:04,130
OK so let's do case analysis

682
00:42:04,340 --> 00:42:15,820
in this case one

683
00:42:17,690 --> 00:42:21,690
i minus one is an exact

684
00:42:27,520 --> 00:42:29,400
so the i had

685
00:42:29,440 --> 00:42:31,520
is equal to

686
00:42:31,550 --> 00:42:35,500
all CI is now just i

687
00:42:35,500 --> 00:42:36,820
that's the case

688
00:42:36,840 --> 00:42:42,650
and then we have the rest there plus to minus two ceiling log i

689
00:42:42,690 --> 00:42:46,670
minus two ceiling of log on this one

690
00:42:46,820 --> 00:42:53,480
that's equal to

691
00:42:53,480 --> 00:42:56,500
five plus two

692
00:42:58,000 --> 00:43:00,320
let's see

693
00:43:00,360 --> 00:43:08,380
if i minus one is an exact power of two what does this term

694
00:43:08,420 --> 00:43:18,340
i minus one is an exact power of two

695
00:43:19,940 --> 00:43:22,420
thank you

696
00:43:22,500 --> 00:43:36,210
that that

697
00:43:36,230 --> 00:43:39,150
good as doing we say because for

698
00:43:39,280 --> 00:43:46,590
that is so there is actually y and being a pretty good

699
00:43:48,190 --> 00:43:50,230
theoreticians because i

700
00:43:50,230 --> 00:43:53,460
because i don't ever trust what i've written down

701
00:43:53,480 --> 00:43:57,840
as i write down in a way that i can verify it because otherwise i

702
00:43:57,840 --> 00:44:01,750
just i'm not smart enough to carry through five equations and rowan

703
00:44:01,750 --> 00:44:03,260
i expected every

704
00:44:03,280 --> 00:44:08,960
one is going be transformed appropriately

705
00:44:09,030 --> 00:44:12,360
so you write it down so i always write down so i can verify that

706
00:44:12,380 --> 00:44:17,380
fortunately has the side benefit than other people can understand what i've done as well

707
00:44:17,750 --> 00:44:24,500
OK so what is this one

708
00:44:24,570 --> 00:44:28,230
this is two to the longer by minus one

709
00:44:28,280 --> 00:44:29,760
because the ceiling

710
00:44:29,800 --> 00:44:31,880
this is an exact power of two

711
00:44:40,400 --> 00:44:43,780
then ceiling of logo by minus one is just

712
00:44:43,820 --> 00:44:47,130
what of i minus one so this is to to the log by minus one

713
00:44:47,130 --> 00:44:48,730
which is

714
00:44:48,780 --> 00:44:51,110
i minus one

715
00:45:03,050 --> 00:45:06,110
things that are too then log is

716
00:45:08,940 --> 00:45:11,840
right so taking the ceiling air that matter

717
00:45:11,940 --> 00:45:13,380
during the ceiling

718
00:45:13,400 --> 00:45:17,940
this one however is not an exact power of two

719
00:45:17,940 --> 00:45:21,530
but what is it

720
00:45:21,590 --> 00:45:25,980
it's just one more than this guy

721
00:45:26,030 --> 00:45:26,940
you know

722
00:45:26,960 --> 00:45:30,000
i must one is not an exact purchase is going to be

723
00:45:30,020 --> 00:45:31,920
the next bigger one

724
00:45:33,110 --> 00:45:38,090
so that means this is what

725
00:45:45,960 --> 00:45:50,380
this is going to be

726
00:45:50,480 --> 00:45:55,650
these two compare

727
00:45:55,690 --> 00:45:58,780
how much bigger is this one and this one

728
00:45:58,780 --> 00:46:00,530
twice the size

729
00:46:00,610 --> 00:46:03,380
you know this one is

730
00:46:03,420 --> 00:46:09,030
they reasoning from first principles

731
00:46:09,090 --> 00:46:10,320
this is going to be

732
00:46:10,380 --> 00:46:11,900
a lot of

733
00:46:11,920 --> 00:46:16,520
i minus one plus one

734
00:46:18,300 --> 00:46:21,370
in reduced to this

735
00:46:21,400 --> 00:46:24,490
i think i think about those floors and ceilings right

736
00:46:24,500 --> 00:46:27,240
like what's happening in the round off their

737
00:46:27,790 --> 00:46:30,800
so now we can simplify this

738
00:46:30,860 --> 00:46:36,450
OK so what we have here we have

739
00:46:36,500 --> 00:46:38,790
OK so so i have

740
00:46:38,830 --> 00:46:43,320
i multiply this through i have an archive plus two

741
00:46:43,380 --> 00:46:46,150
minus two y

742
00:46:48,210 --> 00:46:51,800
plus i minus this one

743
00:46:52,540 --> 00:46:55,630
a lot of people i know a lot of your ninety percent you want to

744
00:46:55,660 --> 00:46:57,730
this that

745
00:46:57,740 --> 00:47:00,660
you go directly from the step to the last step

746
00:47:00,660 --> 00:47:02,610
and that's where

747
00:47:02,620 --> 00:47:04,660
thirty percent of you some number

748
00:47:04,680 --> 00:47:06,200
we get it wrong

749
00:47:06,330 --> 00:47:08,210
OK so let me encourage you

750
00:47:08,240 --> 00:47:09,950
to do that so that

751
00:47:09,960 --> 00:47:12,700
OK it's easier to find your box

752
00:47:12,700 --> 00:47:15,370
OK if you if you take it slow

753
00:47:15,370 --> 00:47:18,610
it actually taking it slow is faster in the long run

754
00:47:18,660 --> 00:47:20,700
hard to teach

755
00:47:20,700 --> 00:47:24,720
give this is the best one but i'm not a graphics person so

756
00:47:24,820 --> 00:47:31,340
nice couple of my story ends there were marred mitsubishi electric research laboratory in that

757
00:47:31,340 --> 00:47:34,590
they do both vision and graphics very well so

758
00:47:34,590 --> 00:47:39,280
they're looking at this paper and extending it to briefly mention that OK so let

759
00:47:39,280 --> 00:47:44,700
me briefly mention what's in here at all basis of the data and the reflectance

760
00:47:44,700 --> 00:47:46,990
function you know characterisation this is the

761
00:47:47,440 --> 00:47:50,150
transfer functions and this is the lighting conditions

762
00:47:50,240 --> 00:47:53,200
and this is the intensity profile so you

763
00:47:53,220 --> 00:47:55,450
you you have this guy

764
00:47:55,470 --> 00:48:00,380
and the way you collect this is using random projections OK and then you are

765
00:48:00,380 --> 00:48:04,970
concatenated all of these guys and make a matrix c

766
00:48:04,990 --> 00:48:10,160
as i have indicated here and then you can have some basis be transposed because

767
00:48:10,160 --> 00:48:13,320
the orthogonal basis and therefore

768
00:48:13,340 --> 00:48:18,380
you can put this problem in a very nice you know compressive sensing framework so

769
00:48:18,380 --> 00:48:24,380
you're trying to figure out d from c and l is how you would get

770
00:48:24,380 --> 00:48:31,030
a list random patterns that you use to generate c our

771
00:48:31,050 --> 00:48:32,070
OK so

772
00:48:32,090 --> 00:48:36,360
they describe and i set for how they construct to use the camera to collect

773
00:48:36,420 --> 00:48:39,010
the CRT monitor is used as the control of

774
00:48:39,070 --> 00:48:46,240
high resolution light field there and how they think they use gauss

775
00:48:46,740 --> 00:48:53,360
random projections and represented in the hoc basis and that's how they create the patterns

776
00:48:53,360 --> 00:48:56,860
and in fact this is somewhat similar to what is done in the single pixel

777
00:48:56,860 --> 00:49:03,180
camera and some acquiring compressive measurements and then they take you know photograph and then

778
00:49:03,240 --> 00:49:09,970
given methods so this is an example taken from their from compressive measurements and this

779
00:49:09,970 --> 00:49:13,780
is actually the ground truth and so forth so this is a great example of

780
00:49:13,780 --> 00:49:18,450
a practical example of using compressive sensing for graphics power so my story and said

781
00:49:18,450 --> 00:49:24,240
well reflectance functions are not just are going to be sparse maybe that compression over

782
00:49:24,530 --> 00:49:30,530
so they basically added another component to it i'm going to some rush through the

783
00:49:30,530 --> 00:49:33,590
grid and i'll show you how

784
00:49:33,610 --> 00:49:34,670
OK so

785
00:49:34,670 --> 00:49:38,380
so they have a way of characterising sparsity

786
00:49:38,380 --> 00:49:45,630
as subspace compressibility i feel most images will probably fall as as vote not just

787
00:49:45,630 --> 00:49:50,990
sparsity because i'm not sure if we really have a really good signals that we

788
00:49:50,990 --> 00:49:54,740
just have to cater things in some basis and poof day away i mean it

789
00:49:54,740 --> 00:50:01,340
is not possible in fact is something on power law in what if if signals

790
00:50:01,340 --> 00:50:05,570
are not case possibility but they will be something and has power law in as

791
00:50:05,570 --> 00:50:12,420
as the variance goes down the value here is is this and they are greater

792
00:50:12,420 --> 00:50:18,110
than everything here that that's the power law most images don't will be that so

793
00:50:18,110 --> 00:50:22,380
but the IP properties good firepower loss signals also

794
00:50:22,400 --> 00:50:28,490
anyway so my story and said well let's not just do the the sparsity thing

795
00:50:28,490 --> 00:50:33,320
l one r will also add an under the l two norm and they put

796
00:50:33,340 --> 00:50:38,760
together and so on so it's some minor modification to what is being done in

797
00:50:38,780 --> 00:50:42,240
they work from here at the top and these are my two store and you

798
00:50:42,260 --> 00:50:45,950
know they're working on it and have made some

799
00:50:45,950 --> 00:50:47,740
i guess is in terms of how

800
00:50:47,740 --> 00:50:55,130
measurements you need to take because you're doing joint consideration of sparsity as well compressibility

801
00:50:55,150 --> 00:50:56,490
OK so

802
00:50:56,550 --> 00:51:00,860
this is the set up they did in march and this is the kind of

803
00:51:00,860 --> 00:51:05,400
the the matrix they use the random projection matrix they used to collect and all

804
00:51:05,420 --> 00:51:07,200
measurements using this camera

805
00:51:07,220 --> 00:51:08,970
and the scene is over here

806
00:51:08,990 --> 00:51:14,030
and they collect whatever the number is needed by the theory and they do the

807
00:51:15,050 --> 00:51:20,700
using the criterion function i mentioned and this is still ongoing work

808
00:51:20,740 --> 00:51:21,800
in there

809
00:51:21,820 --> 00:51:22,840
OK so so

810
00:51:22,840 --> 00:51:27,970
the relighting pattern using this this is really terrible it is even in vision person

811
00:51:27,990 --> 00:51:29,670
shows the graphics

812
00:51:29,680 --> 00:51:32,630
paper makes it looks even worse

813
00:51:32,650 --> 00:51:37,590
whereas the vision period graphics we will make our results look better

814
00:51:37,610 --> 00:51:42,700
somehow when we show so i guess session shows anymore sorry OK

815
00:51:42,720 --> 00:51:45,990
right so i have ten minutes and i want to keep is five minutes for

816
00:51:45,990 --> 00:51:48,360
a discussion of the next two slides

817
00:51:48,400 --> 00:51:51,610
this lot more going on that i have not talked about you know c is

818
00:51:51,610 --> 00:51:57,380
for background subtraction can look at ECCV paper and professor larry karen due is this

819
00:51:57,380 --> 00:52:00,400
talking about compressive sensing and particle filters

820
00:52:00,440 --> 00:52:03,820
this is kind of the conference is going to be here and you can think

821
00:52:03,820 --> 00:52:05,220
in september

822
00:52:05,240 --> 00:52:09,470
statistical signal processing workshop somebody knows about that

823
00:52:12,030 --> 00:52:17,920
last week i'm sorry OK so there's this paper and we can show our data

824
00:52:17,920 --> 00:52:24,470
behaviour with me and for mcclellan how is useful for bearing estimation and

825
00:52:24,490 --> 00:52:28,650
have but i support this and this is there to will be able to rise

826
00:52:28,650 --> 00:52:34,570
to on c espinosa damaging historian who knows bit the works are and we looked

827
00:52:34,570 --> 00:52:36,550
at it in

828
00:52:36,610 --> 00:52:39,220
i'm sure there are more here that have not

829
00:52:41,220 --> 00:52:45,610
as i said i started my career in nineteen eighty one is almost like twenty

830
00:52:45,610 --> 00:52:49,090
eight is something you know

831
00:52:49,090 --> 00:52:50,910
the great one

832
00:52:50,920 --> 00:52:54,580
the fact that make you go through your entire life story and a number of

833
00:52:54,580 --> 00:52:58,940
parties and then the dark matter that makes sense OK so

834
00:52:58,990 --> 00:53:02,420
background knowledge is very important if you want to learn from very small number of

835
00:53:02,420 --> 00:53:08,340
examples OK so one question of course is how do you use the background knowledge

836
00:53:08,340 --> 00:53:12,250
of end about ontology is not complete no problem in the learning you're trying to

837
00:53:12,250 --> 00:53:15,910
get the background knowledge about the same time if it is already there

838
00:53:16,010 --> 00:53:19,740
everything that you need to learn in the closure so one of the interesting kinds

839
00:53:19,750 --> 00:53:21,510
of ideas would be

840
00:53:21,520 --> 00:53:26,550
two x two sort of characterising what parts of explanation

841
00:53:26,730 --> 00:53:31,150
well you know i it's not the concept you are sure what parts you're not

842
00:53:32,330 --> 00:53:33,450
OK so

843
00:53:33,450 --> 00:53:37,310
and the idea is that i might not know everything about how that's what i

844
00:53:37,310 --> 00:53:42,210
want my knowledge about specific sub assemblies of god my company

845
00:53:42,230 --> 00:53:43,750
that's when i give you

846
00:53:43,850 --> 00:53:49,510
part of the explanation meeting was that subassembly of the card then in sense actually

847
00:53:49,510 --> 00:53:53,730
and complete and so there is this whole notion of

848
00:53:53,760 --> 00:53:58,230
characterizing local completeness of your knowledge

849
00:53:58,260 --> 00:54:03,200
and using that to decide how much of your rather than say explanation company correct

850
00:54:03,250 --> 00:54:05,280
not completely correct i can see

851
00:54:05,300 --> 00:54:09,480
here is the explanation these plots i'm completely sure is but i'm not sure

852
00:54:09,480 --> 00:54:13,600
and then you can use that in a much more interesting feature selection

853
00:54:13,630 --> 00:54:18,900
i think that's a good direction for and in general the values dbl here is

854
00:54:18,900 --> 00:54:19,770
that some of

855
00:54:19,820 --> 00:54:25,140
there are various terms have been used in the machine learning literature including BBL KBL

856
00:54:25,140 --> 00:54:30,800
on the relevance this learning knowledge base learning exploration based i just mentality and i

857
00:54:30,800 --> 00:54:34,250
use the word is here

858
00:54:34,260 --> 00:54:36,430
additionally adhered to stand for alone

859
00:54:40,880 --> 00:54:46,620
that gets me so i'm basically looking at this picture and i learned rules to

860
00:54:46,620 --> 00:54:48,750
try to find vanity that using

861
00:54:48,750 --> 00:54:52,680
explicit policies that i want to say a couple of things about this and this

862
00:54:52,680 --> 00:54:54,650
and then go to the other side

863
00:54:56,260 --> 00:55:00,740
i have been mentioning earlier that one of the you can improve the performances to

864
00:55:00,740 --> 00:55:03,700
remember plans remember all plans

865
00:55:03,720 --> 00:55:08,540
the number pieces of wood plants and when the new problem comes along either you

866
00:55:08,540 --> 00:55:12,830
know you basically just starting from scratch and try to use this flat

867
00:55:12,860 --> 00:55:17,180
there's a whole bunch of work that's been done in this area many many different

868
00:55:17,180 --> 00:55:20,010
ways of doing this sort of reuse

869
00:55:20,020 --> 00:55:22,110
and i

870
00:55:22,150 --> 00:55:27,010
cannot possibly explain you all the possible finer distinctions so instead i'll just give you

871
00:55:27,180 --> 00:55:33,910
some of the main dimensions along which this sort of the first and so one

872
00:55:33,910 --> 00:55:37,560
of course is the structure is being used so if you're talking about using plans

873
00:55:37,790 --> 00:55:42,650
are you talking about the using opaque plan that means if you take the whole

874
00:55:42,650 --> 00:55:45,250
take you don't change anything in the

875
00:55:45,260 --> 00:55:47,470
OK i dual averaging

876
00:55:47,500 --> 00:55:50,260
idea allowed to modify the pieces of the plant

877
00:55:50,280 --> 00:55:53,230
OK so if you're loving too much if you're allowed to modify the piece of

878
00:55:53,230 --> 00:55:55,990
the planets in a sense i think the first five steps of the old man

879
00:55:55,990 --> 00:56:01,310
at the more things and add some more new steps and then bring back supply

880
00:56:01,330 --> 00:56:06,590
so it turns out that one is called macro operators that land use and similarly

881
00:56:06,610 --> 00:56:12,040
do you just using the solution which is the plan that has been stored and

882
00:56:12,040 --> 00:56:17,490
are using the following process to the ones that additions that were made in generating

883
00:56:19,590 --> 00:56:24,490
and finally it's so and and the second issue is whether these plans are given

884
00:56:24,490 --> 00:56:27,870
to you by hand by humans outside of the loop

885
00:56:27,880 --> 00:56:32,550
OK i these are plans to the planet has generated in the past you story

886
00:56:32,750 --> 00:56:37,270
and this is an interesting dimension because if it's not automatically according the sense you

887
00:56:37,270 --> 00:56:42,260
solve these problems in the past was then at least you know exactly why plan

888
00:56:42,310 --> 00:56:45,260
to correct because you have enough my knowledge

889
00:56:45,260 --> 00:56:49,310
explain whereas these are given by humans

890
00:56:49,460 --> 00:56:55,190
three times in fact in real world use occurs because we don't actually know all

891
00:56:55,190 --> 00:56:59,690
are how to make this plan from scratch so you think something that somebody else

892
00:56:59,690 --> 00:57:04,620
has made and we make smart weeks and hold that local warm effect the correctness

893
00:57:05,340 --> 00:57:09,520
so that's the kind of way i changed my car and i might change itself

894
00:57:09,530 --> 00:57:12,550
i don't know how to make it from scratch but i might change my problem

895
00:57:12,570 --> 00:57:16,920
the car assuming that one change too much OK so

896
00:57:16,980 --> 00:57:22,360
that's the important thing so in in the area of what case based planning board

897
00:57:22,370 --> 00:57:26,680
have been considered so bought the issue of war

898
00:57:26,690 --> 00:57:33,470
humans giving it outside what says automatically acquired and it turns out that

899
00:57:36,770 --> 00:57:39,870
so it turns out that if you are interested in the human in sense the

900
00:57:39,870 --> 00:57:41,380
planet doesn't even

901
00:57:41,420 --> 00:57:45,580
have come doesn't even need to have the company domain knowledge

902
00:57:45,610 --> 00:57:50,620
and then in terms of mechanism use if you use these operators that are using

903
00:57:50,620 --> 00:57:55,160
them as multiple plans and if you have multiple plants coming coming out of the

904
00:57:55,160 --> 00:57:57,250
library how are you going to do

905
00:57:57,310 --> 00:57:58,860
put them into the

906
00:57:58,910 --> 00:58:05,940
extension process OK is just an example i mean often the kinds of work that's

907
00:58:05,940 --> 00:58:11,630
been done on use this is because i am familiar with it so the in

908
00:58:11,630 --> 00:58:16,750
this particular case you are using the additional traces which are officially not only the

909
00:58:16,750 --> 00:58:19,600
plan but the decisions that were taken

910
00:58:19,620 --> 00:58:21,160
to get that class

911
00:58:21,160 --> 00:58:22,900
OK and

912
00:58:22,950 --> 00:58:26,840
furthermore when you have a long planned you don't necessarily want and that plan is

913
00:58:26,840 --> 00:58:31,770
the single case if this plan was let's supporting fifteen goals you want achieve in

914
00:58:32,490 --> 00:58:36,350
and it turns out that those goals of all independent that means and if you

915
00:58:36,350 --> 00:58:41,640
actually what each of the all separately are the plants that are concatenated to solve

916
00:58:41,640 --> 00:58:45,570
all the people that it makes no sense to him and work plan but due

917
00:58:45,700 --> 00:58:48,700
the g fifteen another plant what you wanted you fourteen of plant but you want

918
00:58:48,800 --> 00:58:53,020
keep thirteen and so on it makes much more sense to discuss the planning pieces

919
00:58:53,020 --> 00:58:59,180
which are twenty two independent subproblems so you could generalize people do that independent problem

920
00:58:59,180 --> 00:59:03,790
analysis again using explanations of why the planets correct c

921
00:59:03,850 --> 00:59:10,610
rather the explanation are interacting explanation product was independent subgoals setting

922
00:59:10,620 --> 00:59:17,180
OK and then finally stalled the plan in the library and it's been achieved if

923
00:59:17,190 --> 00:59:22,200
in fact are you won't try to start with that plan the next like extended

924
00:59:22,200 --> 00:59:26,210
and brand speed that you have to come out of it then you try to

925
00:59:26,210 --> 00:59:31,980
analyse why the land that they and remember to sign up and will rule saying

926
00:59:32,430 --> 00:59:33,380
that these

927
00:59:33,400 --> 00:59:37,750
conditions under these conditions don't know what the previous plan again

928
00:59:37,770 --> 00:59:42,170
OK which is sort of like this that central activities like italy will control so

929
00:59:42,170 --> 00:59:45,910
we think these plans would not be here the

930
00:59:47,020 --> 00:59:51,630
one thing to mention i guess in terms of the EBL and the use of

931
00:59:51,630 --> 00:59:54,230
so the two individuals with that property

932
00:59:54,250 --> 00:59:56,340
they got the DNA they did this stuff

933
00:59:56,360 --> 00:59:58,150
and they plotted them into d

934
00:59:58,170 --> 01:00:01,550
so if you think about what that two deep what might look like

935
01:00:01,590 --> 01:00:04,380
the answer is it looks like a map of of europe

936
01:00:05,650 --> 01:00:07,860
i'd like to emphasise that

937
01:00:07,880 --> 01:00:09,980
nothing about their analysis

938
01:00:10,010 --> 01:00:16,050
new where these people came from they would just literally given vector saying these are

939
01:00:17,260 --> 01:00:21,170
whether there this normal type of the sun normal type in the DNA these locations

940
01:00:23,260 --> 01:00:26,130
then if you do that and you apply PCA

941
01:00:26,130 --> 01:00:27,630
a new project in two d

942
01:00:27,650 --> 01:00:31,300
and draw scatterplot then this person came from italy

943
01:00:31,320 --> 01:00:35,470
and the and all the brown people came from italy and the central people is

944
01:00:36,690 --> 01:00:38,340
and similarly

945
01:00:38,340 --> 01:00:42,210
all of the colours represent which country people came from and if you look at

946
01:00:42,210 --> 01:00:47,530
the topological arrangement of it is very very closely that matches map here

947
01:00:47,590 --> 01:00:52,730
so even though this is like a horrendously large problem to deal with these features

948
01:00:52,730 --> 01:00:56,570
when you have many more than people it's quite possible to pull out

949
01:00:56,570 --> 01:00:58,980
like real structure the way the

950
01:01:00,300 --> 01:01:04,820
we evolved is that people moved out across europe and as they did the DNA

951
01:01:04,820 --> 01:01:11,730
changed and at least in this dataset was carefully selected the main dominant feature of

952
01:01:11,730 --> 01:01:13,190
the DNA is

953
01:01:13,190 --> 01:01:15,380
at the location they picked

954
01:01:15,400 --> 01:01:17,130
what's the sort of

955
01:01:17,400 --> 01:01:25,990
nematic process across here

956
01:01:26,980 --> 01:01:30,800
so i thought that picture was really dramatic i can really believe it when i

957
01:01:30,800 --> 01:01:32,480
saw it but

958
01:01:35,440 --> 01:01:39,590
the important thing it tells you is always plot whatever you're doing because you might

959
01:01:39,590 --> 01:01:43,760
see something interesting actually they they've people knew that that was going to happen they

960
01:01:43,760 --> 01:01:46,650
had to had to model a there pretty sure that they going to get a

961
01:01:46,650 --> 01:01:50,420
map it and expected to be that good but they expect expected to get

962
01:01:50,480 --> 01:01:53,090
but whatever you're doing

963
01:01:53,150 --> 01:01:56,980
try and come up with lots of what you're doing is you're going to project into

964
01:01:57,010 --> 01:02:01,280
down into some dimensions have a look at this and see whether

965
01:02:01,280 --> 01:02:05,820
you can see anything obvious popping out may be able to identify the big outliers

966
01:02:05,820 --> 01:02:08,960
that are likely to secure analysis that you might want to toss so you might

967
01:02:08,960 --> 01:02:11,190
want to model you might want to look at

968
01:02:11,460 --> 01:02:17,340
and that will help you make a machine learning system that works but there is

969
01:02:17,340 --> 01:02:20,090
insights can also be valuable

970
01:02:20,110 --> 01:02:22,150
in themselves so

971
01:02:22,190 --> 01:02:24,750
if your consulting for someone

972
01:02:24,800 --> 01:02:27,710
if you want you to solve a particular problem you turn around so you know

973
01:02:27,710 --> 01:02:31,320
this is actually interesting stuff i saw in your data it might be stuff they

974
01:02:31,320 --> 01:02:34,800
don't know and it might be useful to them as well as a system that

975
01:02:34,800 --> 01:02:37,070
does what they actually are

976
01:02:43,170 --> 01:02:48,260
i have laundry list of things to do for visualization where

977
01:02:49,030 --> 01:02:52,260
time say

978
01:02:52,280 --> 01:02:53,800
visualization is a whole

979
01:02:53,800 --> 01:02:57,190
research topic of its own and to be honest it's not something that i'm an

980
01:02:57,190 --> 01:03:01,210
expert in but it is something i do whenever given the dataset so i always

981
01:03:01,210 --> 01:03:05,150
just a bunch of very simple stuff i put histograms of every single feature and

982
01:03:05,150 --> 01:03:08,510
label out and look at the list does not millions of

983
01:03:08,510 --> 01:03:14,210
i draw scatterplots of lots of pairs of features or the features and the out

984
01:03:14,210 --> 01:03:18,190
idea scatterplots based on PCA i might also be random projections look at all these

985
01:03:18,190 --> 01:03:21,340
plots and you know it might only take twenty minutes to look through a whole

986
01:03:21,340 --> 01:03:26,640
bunch of pages what that could tell you something that you wouldn't notice in weeks

987
01:03:26,640 --> 01:03:31,630
passion your head again sort of just applying algorithms without looking at what they're doing

988
01:03:32,210 --> 01:03:36,780
there's a piece of software which is really neat called you gave me that

989
01:03:36,820 --> 01:03:40,760
does a lot of this stuff so one one of the things it does is

990
01:03:41,260 --> 01:03:45,670
it takes if it does fly through tolls of your data so it will randomly

991
01:03:45,670 --> 01:03:49,370
projected to two d and show you the data and then it slowly tilts the

992
01:03:49,370 --> 01:03:53,280
projection it's using so that that you get a movie review data set that sort

993
01:03:53,280 --> 01:03:56,130
of tumble for high dimensional space so

994
01:03:56,150 --> 01:03:59,920
if you imagine it keeps spinning your listing that animation you can you can look

995
01:03:59,920 --> 01:04:02,550
at it keep spinning on a two d screen and you have an idea of

996
01:04:02,570 --> 01:04:07,210
the three d q gave software that will tumble high dimensional spaces and maybe with

997
01:04:07,210 --> 01:04:11,170
some practice you can actually get some idea of what these high dimensional spaces look

998
01:04:12,250 --> 01:04:17,050
this figure doesn't show that what this figure shows is that you gave you have

999
01:04:17,050 --> 01:04:20,750
lots of different ways of visualizing the data and it has the

1000
01:04:20,760 --> 01:04:25,800
trie told can do things like ringo dataset in one representation and it will colour

1001
01:04:25,900 --> 01:04:30,510
in all the other different representation so you might see outliers in one projection you

1002
01:04:30,510 --> 01:04:35,330
so what do we do next will be bigger

1003
01:04:35,360 --> 01:04:37,720
like two

1004
01:04:37,770 --> 01:04:43,150
might have four months wise were wise words why would be some nice three i

1005
01:04:46,400 --> 01:04:48,030
my right

1006
01:04:48,050 --> 01:04:50,630
that somehow we can

1007
01:04:50,640 --> 01:04:53,250
if x is really a giant

1008
01:04:53,270 --> 01:04:55,040
what's y

1009
01:04:55,050 --> 01:04:57,570
most of the time right

1010
01:04:57,620 --> 01:05:02,410
almost the same as x right but not but slightly less because the square is

1011
01:05:02,410 --> 01:05:04,880
forced one so so

1012
01:05:04,910 --> 01:05:10,330
is that i think i'd rather asymptotes like this the forty five degree line here

1013
01:05:10,480 --> 01:05:12,290
the minus forty five

1014
01:05:12,500 --> 01:05:15,570
and i think this curve

1015
01:05:15,580 --> 01:05:19,570
is something like that

1016
01:05:19,580 --> 01:05:21,890
not bad

1017
01:05:21,900 --> 01:05:25,130
it's not a parabola looks like one

1018
01:05:25,140 --> 01:05:27,340
but it's a hyperbole

1019
01:05:28,360 --> 01:05:31,030
and now for changes to it too

1020
01:05:32,900 --> 01:05:35,040
l started swearing to

1021
01:05:35,080 --> 01:05:38,490
again another hyperbolic

1022
01:05:38,500 --> 01:05:40,400
it also works i want

1023
01:05:41,190 --> 01:05:43,550
don't get out near that guy

1024
01:05:43,570 --> 01:05:46,320
but at all

1025
01:05:46,370 --> 01:05:50,160
something like that

1026
01:05:53,150 --> 01:05:57,480
this is all there all approaching at forty five degree as an

1027
01:05:58,480 --> 01:06:01,210
and of course could be smaller

1028
01:06:01,220 --> 01:06:02,330
what have

1029
01:06:02,480 --> 01:06:04,920
and get somebody in here

1030
01:06:04,930 --> 01:06:08,920
so i got a whole family of curves

1031
01:06:12,860 --> 01:06:14,700
so it looks to me like this

1032
01:06:14,700 --> 01:06:16,040
this all

1033
01:06:16,060 --> 01:06:19,810
now one the so those were the equipotentials

1034
01:06:19,820 --> 01:06:28,470
now one the other curve other family of curves drawn

1035
01:06:28,470 --> 01:06:33,580
the streamline streamlines come from the stream function

1036
01:06:33,610 --> 01:06:38,430
so i want to drive those as equals

1037
01:06:38,440 --> 01:06:40,420
two x y

1038
01:06:40,430 --> 01:06:42,210
equals cuts

1039
01:06:44,200 --> 01:06:46,520
i i meant to

1040
01:06:46,540 --> 01:06:49,530
make a little note as i usually do

1041
01:06:49,540 --> 01:06:50,980
which sections

1042
01:06:51,000 --> 01:06:53,030
of the

1043
01:06:56,840 --> 01:06:58,570
lecture connects two

1044
01:06:58,610 --> 01:07:03,240
section three three is specifically about the possible equation

1045
01:07:03,280 --> 01:07:05,990
section four point four

1046
01:07:06,030 --> 01:07:10,880
it's about the complex variables stuff and then there's one page

1047
01:07:10,920 --> 01:07:14,880
you have no

1048
01:07:14,900 --> 01:07:17,300
here the one page

1049
01:07:17,300 --> 01:07:21,510
two seven seven i think that has a formula

1050
01:07:21,510 --> 01:07:22,900
that will

1051
01:07:22,920 --> 01:07:24,380
touch OK

1052
01:07:24,400 --> 01:07:25,860
right now think

1053
01:07:26,240 --> 01:07:32,530
OK i'm going to try and the the equal the streamlines and just complete that

1054
01:07:32,530 --> 01:07:37,340
point so this is what kind of a curve is two x y constant equal

1055
01:07:37,340 --> 01:07:38,960
one that's

1056
01:07:38,960 --> 01:07:40,900
so let the concept b one

1057
01:07:40,960 --> 01:07:46,650
anybody recognise that kind of a curve two acts like one it's also a hyperbola

1058
01:07:46,670 --> 01:07:48,880
so by a total

1059
01:07:48,990 --> 01:07:54,210
i like chance here we've got two hyperbolas and if i try to acts like

1060
01:07:54,210 --> 01:07:58,550
one of those that hyperbolas are swung around by

1061
01:07:58,590 --> 01:08:00,690
ninety degrees or something

1062
01:08:02,440 --> 01:08:05,030
these hyperbolas go

1063
01:08:05,070 --> 01:08:07,510
right through

1064
01:08:07,570 --> 01:08:13,990
perpendicular had like like x y one of like x x y one is if

1065
01:08:13,990 --> 01:08:19,070
x is big why small effects is small is being in between

1066
01:08:19,220 --> 01:08:21,900
they crossed where x equals y

1067
01:08:21,940 --> 01:08:22,800
so they

1068
01:08:22,820 --> 01:08:28,090
you see how those things are going the next one will be steeper

1069
01:08:28,110 --> 01:08:29,550
but it will never

1070
01:08:29,570 --> 01:08:35,960
touch the axis of their asymptotic to the axes were the first guys were asymptotic

1071
01:08:35,960 --> 01:08:37,630
to the forty five degrees

1072
01:08:37,650 --> 01:08:42,110
OK and the beauty of the whole thing is that this is these are all

1073
01:08:42,110 --> 01:08:47,360
right angles everywhere they meet is a right angle

1074
01:08:47,420 --> 01:08:49,650
and that comes from

1075
01:08:50,150 --> 01:08:56,690
these crucial equations which i'd better write down she named after carl she who was

1076
01:08:56,760 --> 01:08:59,920
a great french mathematician

1077
01:08:59,940 --> 01:09:02,570
and every man who was greater

1078
01:09:02,590 --> 01:09:11,320
when he was one of the the great mathematicians of all time and the two

1079
01:09:11,320 --> 01:09:13,320
equations connect

1080
01:09:13,320 --> 01:09:15,920
the real part you

1081
01:09:15,920 --> 01:09:20,090
with the imaginary part as its riverview

1082
01:09:20,110 --> 01:09:23,300
agrees with the y derivative of s

1083
01:09:23,320 --> 01:09:27,090
and that actually comes from our now are raced

1084
01:09:27,110 --> 01:09:28,510
the first derivative

1085
01:09:28,510 --> 01:09:31,670
because like first derivative and

1086
01:09:32,610 --> 01:09:34,820
the other one is duty y

1087
01:09:34,840 --> 01:09:37,650
comes out as minus the

1088
01:09:37,670 --> 01:09:40,090
other great equation

1089
01:09:43,780 --> 01:09:50,710
and they come directly for any as the real and imaginary parts from our first

1090
01:09:53,460 --> 01:09:57,070
they tell us that these

1091
01:09:57,090 --> 01:10:02,170
occurrences of the curve as equal costs these are the streamlines

1092
01:10:02,220 --> 01:10:11,240
and these were the potentials and those equations would tell us that they need writing

1093
01:10:11,280 --> 01:10:15,550
so it's the the geometry is test

1094
01:10:15,570 --> 01:10:17,460
and that will still be true

1095
01:10:17,490 --> 01:10:22,070
even for these curves which would not be

1096
01:10:22,130 --> 01:10:27,070
so easy to draw well i could draw the easiest one would be one if

1097
01:10:27,090 --> 01:10:31,880
the streamlines if it if the potential function is x

1098
01:10:31,920 --> 01:10:36,220
let's should look at that he really is the case if the potential function u

1099
01:10:36,220 --> 01:10:38,420
of x y is just x

1100
01:10:38,440 --> 01:10:41,260
what are the equipotentials

1101
01:10:41,260 --> 01:10:44,590
just lexical concerts vertical line

1102
01:10:44,590 --> 01:10:47,720
and if this stream function is why

1103
01:10:47,740 --> 01:10:53,090
what are the streamlines whereas white constant there the horizontal lines and of course was

1104
01:10:53,090 --> 01:10:54,590
made writing

1105
01:10:54,610 --> 01:10:59,630
so that x and y this is the the case when the flow

1106
01:10:59,650 --> 01:11:00,690
it's just like

1107
01:11:00,710 --> 01:11:06,490
like on the mississippi or something that flow is just following the streamlined

1108
01:11:06,490 --> 01:11:07,530
one straight

1109
01:11:07,550 --> 01:11:10,130
well maybe the mississippi

1110
01:11:10,150 --> 01:11:14,920
it doesn't go straight but out in the middle of pretty

1111
01:11:14,920 --> 01:11:18,570
and then it's a valid codeword

1112
01:11:18,610 --> 01:11:22,190
i can show you the code afterwards is just a little tricks i i took

1113
01:11:22,190 --> 01:11:22,570
the image

1114
01:11:22,960 --> 01:11:27,820
you're correct i made a codeword that's tricky and then i added some some redundancy

1115
01:11:27,820 --> 01:11:32,090
bits in the czech and what we're running with some product

1116
01:11:33,360 --> 01:11:34,960
right so it's doing about

1117
01:11:35,010 --> 01:11:39,490
it is not optimized for doing ten iterations on something like fifteen thousand nodes and

1118
01:11:39,490 --> 01:11:41,630
you can see it's reasonably fast people

1119
01:11:41,690 --> 01:11:45,360
to use this algorithm in practice

1120
01:11:45,550 --> 01:11:47,670
OK so

1121
01:11:47,710 --> 01:11:58,150
those are some applications i just happened to cherry-pick those there's many others right natural

1122
01:11:58,150 --> 01:12:03,170
language processing things like parts of speech tagging graphical models are used all the time

1123
01:12:03,710 --> 01:12:08,070
statistical image processing computer vision things like image denoising

1124
01:12:08,090 --> 01:12:13,190
image segmentation image disparity computation people use graphs all the time

1125
01:12:13,190 --> 01:12:18,550
there they actually use grids like this often because those are good for modeling spatial

1126
01:12:19,420 --> 01:12:22,320
what are some other examples

1127
01:12:22,320 --> 01:12:29,280
phylogenetics computational biology genomics these all use graphical models as well

1128
01:12:29,460 --> 01:12:34,480
so there's there's many applications in the applications depend both on somehow the

1129
01:12:34,490 --> 01:12:38,380
simplicity that we get from the graph structure and also these algorithms that i'll talk

1130
01:12:38,380 --> 01:12:39,780
about tomorrow

1131
01:12:39,980 --> 01:12:47,510
what i'd like to do in this last part is

1132
01:12:47,530 --> 01:12:53,070
i'd like to come back to the hammersley clifford theorem i'd like to drill down

1133
01:12:53,070 --> 01:12:55,960
into that a little bit more sort of been high level but i'd like to

1134
01:12:57,150 --> 01:13:02,710
why it is the case that if you have something that factorizes like this

1135
01:13:02,710 --> 01:13:06,800
it must satisfy all these conditional independence properties

1136
01:13:06,800 --> 01:13:10,920
so let's let's start drilling down a little bit to understand that

1137
01:13:10,940 --> 01:13:16,530
right so if you remember the statement the statement says if you start with the

1138
01:13:17,550 --> 01:13:20,010
whatever undirected graph you want

1139
01:13:20,090 --> 01:13:22,570
and you build the distribution

1140
01:13:22,570 --> 01:13:26,170
that factorizes over the cliques of the graph

1141
01:13:27,940 --> 01:13:31,110
that's the same as if you start with the graph and said that you had

1142
01:13:31,110 --> 01:13:34,050
all these markov properties holdings

1143
01:13:34,780 --> 01:13:35,610
so let's

1144
01:13:35,610 --> 01:13:40,050
let's work through that one direction of that argument

1145
01:13:40,210 --> 01:13:44,420
any questions before i i sort segway into that

1146
01:13:44,480 --> 01:13:49,210
hammersley clifford

1147
01:13:49,210 --> 01:13:57,240
so they were so probabilis at oxford on the original papers actually unpublished

1148
01:13:57,260 --> 01:14:01,210
i think you can get your hands on scanned version of the body has never

1149
01:14:01,210 --> 01:14:06,420
been published so there are probably and they were sort of interested in essentially generalizations

1150
01:14:06,420 --> 01:14:10,900
markov processes on chains play such an important role in probability

1151
01:14:10,940 --> 01:14:14,820
and they were interested in these kinds of generalisations to graphs

1152
01:14:14,920 --> 01:14:18,570
so i think one of the first published proofs was by julian besag

1153
01:14:18,630 --> 01:14:23,780
unfortunately passed away i think last year but he did a lot of the pioneering

1154
01:14:24,490 --> 01:14:27,030
early work in the seventies and graphical models

1155
01:14:27,220 --> 01:14:31,440
among other things he was very good naming his papers he had a great paper

1156
01:14:31,440 --> 01:14:34,740
called the statistical analysis of dirty pictures

1157
01:14:34,800 --> 01:14:39,940
by which is meant image denoising exactly what i did with codes that you pictures

1158
01:14:39,940 --> 01:14:43,360
that are corrupted and he was going to noise and with the graphical model

1159
01:14:44,320 --> 01:14:49,240
it did i think the british kind of naughty sense of humor they like those

1160
01:14:49,240 --> 01:14:51,690
kinds of jokes

1161
01:14:51,710 --> 01:14:57,190
americans are just more crude more direct about another nice proof i think was the

1162
01:14:57,190 --> 01:15:01,900
student granite in seventy three had a very nice proof i believe he was a

1163
01:15:01,900 --> 01:15:05,070
student of one of the two i don't remember

1164
01:15:05,070 --> 01:15:10,590
so let's let's do one direction

1165
01:15:10,610 --> 01:15:12,260
anything else

1166
01:15:12,300 --> 01:15:17,190
that's a good question i don't know that to be honest i always wonder i

1167
01:15:17,190 --> 01:15:18,740
feel it has to be an american

1168
01:15:18,760 --> 01:15:23,800
it's not a scandinavian because scandinavians are not you know scandalized by

1169
01:15:23,800 --> 01:15:25,760
unmarried parents having children

1170
01:15:26,990 --> 01:15:32,490
maybe pearl but i don't want to cast aspersions

1171
01:15:32,510 --> 01:15:39,050
someone could search and find out i'm sure

1172
01:15:39,090 --> 01:15:42,920
OK so let's let me just walk through just because i think it's useful to

1173
01:15:42,990 --> 01:15:47,110
do some some of the technical work so let's show the following that show the

1174
01:15:47,110 --> 01:15:52,880
factorisation property implies the markov property on any graph

1175
01:15:52,900 --> 01:15:55,820
so i'm not writing this statement and the world trying to show is is one

1176
01:15:55,820 --> 01:15:57,740
direction of this

1177
01:15:57,760 --> 01:16:01,280
so what i'm going to assume is that you've got distribution that factorizes in the

1178
01:16:01,280 --> 01:16:02,630
way we've written there

1179
01:16:02,630 --> 01:16:07,690
is we don't have these basis functions at all we can use arbitrary functions

1180
01:16:07,710 --> 01:16:10,250
interested to know it and polynomials

1181
01:16:10,300 --> 01:16:14,780
i'll skip forward

1182
01:16:14,820 --> 01:16:18,500
so let's cheat

1183
01:16:19,230 --> 01:16:22,400
these basis functions

1184
01:16:22,420 --> 01:16:25,190
so i x and convex

1185
01:16:25,190 --> 01:16:26,690
thank you

1186
01:16:26,750 --> 01:16:29,650
the actual model came from signing let's be

1187
01:16:29,710 --> 01:16:31,130
they realistic

1188
01:16:31,130 --> 01:16:35,010
and let's say we're looking for sinusoidal functions we should include sign cars

1189
01:16:35,030 --> 01:16:37,420
take account of all possible phase

1190
01:16:37,440 --> 01:16:41,730
so something isn't a long here because there's no width parameter are

1191
01:16:41,820 --> 01:16:44,730
o going result i straight away

1192
01:16:44,980 --> 01:16:47,630
so i don't like it here because there's no are

1193
01:16:47,690 --> 01:16:48,770
i just simply

1194
01:16:48,780 --> 01:16:52,920
a this basis function in

1195
01:16:52,960 --> 01:16:55,610
and so this is far more probable

1196
01:16:55,630 --> 01:16:57,030
the reassuringly

1197
01:16:57,050 --> 01:16:59,510
and then all these basis function models

1198
01:16:59,570 --> 01:17:02,920
model actually contains the true sin x

1199
01:17:02,920 --> 01:17:05,210
it is more probable

1200
01:17:05,250 --> 01:17:09,570
you have be price price at all to see on the error

1201
01:17:10,780 --> 01:17:13,670
this model also gives there

1202
01:17:13,980 --> 01:17:15,530
of that

1203
01:17:15,590 --> 01:17:18,000
because as one more model

1204
01:17:18,050 --> 01:17:21,110
if we really were going to cheat

1205
01:17:21,150 --> 01:17:26,780
you might be interested to know what is actually sin x on the same line

1206
01:17:26,800 --> 01:17:27,980
well what

1207
01:17:28,000 --> 01:17:29,570
and about that

1208
01:17:29,630 --> 01:17:31,530
that's even more probable

1209
01:17:31,570 --> 01:17:33,840
and that of course is what you would expect

1210
01:17:33,880 --> 01:17:36,280
because if we had a bit of concepts into the model

1211
01:17:36,320 --> 01:17:38,090
noise means

1212
01:17:38,090 --> 01:17:42,880
data means that we're going to find a little bit of cossacks random

1213
01:17:42,920 --> 01:17:47,730
and so this model was the either is probable my clients is good prediction

1214
01:17:47,780 --> 01:17:49,800
so the trace

1215
01:17:51,000 --> 01:17:52,900
is the most probable

1216
01:17:54,150 --> 01:17:55,460
course gives us

1217
01:17:55,480 --> 01:17:59,630
the lowest there

1218
01:18:02,070 --> 01:18:05,900
take home message from this in this application

1219
01:18:05,940 --> 01:18:08,250
it's likely that you can see

1220
01:18:08,370 --> 01:18:11,010
a certain amount of evidence for the fact

1221
01:18:11,070 --> 01:18:13,920
calculating these marginalized probabilities

1222
01:18:14,860 --> 01:18:19,820
offers the potential for doing some quite interesting experiments with model selection

1223
01:18:19,880 --> 01:18:22,190
using models without having to

1224
01:18:22,190 --> 01:18:23,670
before many validation

1225
01:18:23,690 --> 01:18:26,030
or use any extra data for testing

1226
01:18:26,050 --> 01:18:27,340
it's purely based

1227
01:18:27,360 --> 01:18:30,980
on these marginalized basing quantities

1228
01:18:31,000 --> 01:18:34,250
so this if this looks too good to be true

1229
01:18:34,270 --> 01:18:37,650
there is one of the function is the challenge the audience

1230
01:18:39,000 --> 01:18:42,420
can anyone think of another function has as much probability

1231
01:18:42,440 --> 01:18:43,730
it is probable

1232
01:18:43,780 --> 01:18:47,650
as sin x

1233
01:18:47,750 --> 01:18:51,050
the engineers new orleans signal processing people

1234
01:18:51,070 --> 01:18:54,800
many with nitrous there

1235
01:18:56,610 --> 01:19:01,770
now the but also think about aliasing

1236
01:19:01,780 --> 01:19:04,860
these samples are equally spaced

1237
01:19:06,590 --> 01:19:10,570
and the band

1238
01:19:10,590 --> 01:19:16,670
signed fifteen x

1239
01:19:16,730 --> 01:19:18,320
just show is

1240
01:19:18,380 --> 01:19:22,050
you can't just attack the problem with you talk it would actually thinking about what

1241
01:19:22,050 --> 01:19:23,440
you're doing

1242
01:19:23,480 --> 01:19:27,320
i'm quite happy to show this thing falling over battle

1243
01:19:27,320 --> 01:19:29,820
if we take sign fifty x

1244
01:19:30,690 --> 01:19:34,480
because the sampling theorem the fact that the samples are equally spaced

1245
01:19:35,590 --> 01:19:40,050
smaller basis functions perspective you can't tell the difference between sin x sin fifteen x

1246
01:19:40,050 --> 01:19:41,340
where we sample

1247
01:19:42,400 --> 01:19:46,590
this function has to high frequency across something frequency

1248
01:19:46,610 --> 01:19:48,280
across the x axis

1249
01:19:48,280 --> 01:19:50,590
so far the data is concerned

1250
01:19:50,650 --> 01:19:55,750
it looks exactly the same as in a different sin x phi matrix is identical

1251
01:19:55,770 --> 01:19:57,530
it looks just as probable

1252
01:19:57,550 --> 01:20:01,340
if we evaluate the test error of course it's totally rubbish

1253
01:20:01,500 --> 01:20:04,340
because the test error when evaluating in between

1254
01:20:04,380 --> 01:20:05,780
so this isn't a failure

1255
01:20:05,780 --> 01:20:10,300
good it is on the fact that you've never seen and this is another question

1256
01:20:10,320 --> 01:20:14,050
and most of the time in fact you want to solve the two problems at

1257
01:20:14,050 --> 01:20:16,760
the same time we want to find the best function

1258
01:20:16,760 --> 01:20:18,900
according to some data that you have

1259
01:20:18,900 --> 01:20:23,070
and to know how good or how bad it will be even though that you've

1260
01:20:23,070 --> 01:20:27,970
never seen but it's important to see that these are very different questions and

1261
01:20:27,990 --> 01:20:30,130
if you only want to use two

1262
01:20:30,150 --> 01:20:32,010
to find the best model

1263
01:20:32,030 --> 01:20:35,550
and you're not interested in knowing how good or bad it's going to go to

1264
01:20:35,550 --> 01:20:39,360
be then you need to do what we call model selection but when you do

1265
01:20:39,360 --> 01:20:42,110
that you don't know how good is going to be you just know that you

1266
01:20:42,110 --> 01:20:44,280
have the best function

1267
01:20:44,300 --> 01:20:47,130
if you need to do the two

1268
01:20:47,130 --> 01:20:51,150
so if you make the risk of a given function then you have to estimate

1269
01:20:51,150 --> 01:20:54,860
the risk often you need to do both of them at the same time and

1270
01:20:54,860 --> 01:21:00,990
other very values practical ways to do that going to quickly summarize

1271
01:21:01,010 --> 01:21:05,320
evaluation and cause variation but of course there are other ways

1272
01:21:05,340 --> 01:21:09,130
these are the most useful ones

1273
01:21:09,220 --> 01:21:11,530
so this is the formal

1274
01:21:11,550 --> 01:21:17,440
explanation of valuation and going to try to explain it in words so

1275
01:21:17,450 --> 01:21:21,070
let's suppose that you want to find the best model

1276
01:21:21,630 --> 01:21:24,800
and you have you are given a training set of m examples

1277
01:21:24,800 --> 01:21:28,360
and you want to find the best model according to the training set

1278
01:21:28,380 --> 01:21:31,780
what you are going to do is going to divide your training set of examples

1279
01:21:31,780 --> 01:21:33,170
into two parts

1280
01:21:33,170 --> 01:21:38,800
one of them you are again going to keep the training part and the other

1281
01:21:38,800 --> 01:21:42,010
one you're going to call it evaluation part

1282
01:21:42,030 --> 01:21:44,950
so they have to be disjoint

1283
01:21:44,970 --> 01:21:48,780
and basically what you're going to do now

1284
01:21:48,820 --> 01:21:54,940
is that over your training part of the training set you are going to select

1285
01:21:54,940 --> 01:21:58,130
the best function

1286
01:21:58,150 --> 01:22:01,320
and over the evaluation part

1287
01:22:01,340 --> 01:22:02,940
you are going to estimate

1288
01:22:04,690 --> 01:22:10,030
there the risk so you're going to compute the are you you do on examples

1289
01:22:10,030 --> 01:22:15,170
that were not seen why you try to find the best function for these examples

1290
01:22:15,170 --> 01:22:20,880
somehow you can see locally known for giving them all the time as examples you've

1291
01:22:20,880 --> 01:22:23,490
never seen why you selected the function

1292
01:22:23,510 --> 01:22:27,970
so they are very similar are two examples that are in the set that you've

1293
01:22:27,970 --> 01:22:31,800
never seen in fact they are the same there are just sample of them and

1294
01:22:31,800 --> 01:22:33,280
we know that this

1295
01:22:33,280 --> 01:22:39,260
is an unbiased estimate of the expected risk while computing the risk and those one

1296
01:22:39,260 --> 01:22:43,240
would be advised to estimate so that's why we separate them

1297
01:22:43,260 --> 01:22:45,690
so far so basically we are going to

1298
01:22:45,690 --> 01:22:49,690
two for several value of what we call hyperparameters

1299
01:22:50,820 --> 01:22:52,990
for instance should i use a set of

1300
01:22:53,010 --> 01:22:55,880
polynomials of order two three four five

1301
01:22:55,900 --> 01:22:59,210
the question i have well i'm going to

1302
01:22:59,220 --> 01:23:00,610
to search for

1303
01:23:00,630 --> 01:23:05,690
two three four and five four for each value two three four and five so

1304
01:23:05,690 --> 01:23:08,530
far too for instance for all the sets of function for me

1305
01:23:08,650 --> 01:23:13,070
for the two i'm going to search for the best function according to training part

1306
01:23:13,110 --> 01:23:17,340
of the training set and estimate the value of polynomials of order two on the

1307
01:23:17,340 --> 01:23:19,570
validation by

1308
01:23:19,690 --> 01:23:23,470
and i'm going to do that for polynomials of order two three four and five

1309
01:23:23,570 --> 01:23:29,090
and now i'm going to compare these values the one estimated the initialisation part and

1310
01:23:29,090 --> 01:23:31,570
i'm going to decide whether we should use the

1311
01:23:31,570 --> 01:23:37,880
polynomial over the two three four and five according to the minimum of the values

1312
01:23:37,880 --> 01:23:42,400
of this to make a good and that's what i'm going to return to and

1313
01:23:42,400 --> 01:23:46,610
again i get the best of polynomial of order

1314
01:23:46,630 --> 01:23:48,880
two three four and five

1315
01:23:48,900 --> 01:23:52,670
and i can tell you whether it's good or bad because i you all the

1316
01:23:52,670 --> 01:23:58,130
data to decide to take this decision so i don't have any more fresh data

1317
01:23:58,150 --> 01:24:02,420
to tell you how good it is because any of these to make now

1318
01:24:02,440 --> 01:24:05,940
globally are going to be biased because i think

1319
01:24:06,030 --> 01:24:07,840
good decision using the

1320
01:24:07,880 --> 01:24:14,880
so it was used in large sense as training

1321
01:24:16,630 --> 01:24:18,720
cross validation now

1322
01:24:18,720 --> 01:24:22,510
it's when you don't have enough data to take your whole they don't cut it

1323
01:24:22,510 --> 01:24:26,280
into two because when you cut the data set of course that means that you're

1324
01:24:26,280 --> 01:24:30,240
going to have less data to train so it's often bad so sometimes you don't

1325
01:24:30,240 --> 01:24:33,490
have enough data to cut it to two so what you

1326
01:24:33,510 --> 01:24:34,840
we do is to

1327
01:24:34,860 --> 01:24:39,710
to cut it into more than two strange but that there is going to give

1328
01:24:39,710 --> 01:24:46,090
you more data because you're going to decipher system to capture to case separate

1329
01:24:46,110 --> 01:24:49,320
distinctive subset

1330
01:24:49,400 --> 01:24:51,240
and for each subset

1331
01:24:51,440 --> 01:24:53,110
i'm going to use the rest

1332
01:24:53,130 --> 01:24:54,450
train your data

1333
01:24:54,470 --> 01:25:00,030
estimate the value on the subset that you never used and you're going to to

1334
01:25:00,030 --> 01:25:03,010
do that for all the subsets of for each of the subset i think the

1335
01:25:03,780 --> 01:25:07,630
for training and i use that subset to estimate the value they do that for

1336
01:25:07,630 --> 01:25:10,970
all possible subsets

1337
01:25:11,030 --> 01:25:14,630
in fact i cannot go into that but is going to give the same idea

1338
01:25:14,630 --> 01:25:17,710
and i'm going to estimate the value of the

1339
01:25:17,710 --> 01:25:24,420
the of a given function with given the hyperparameter by summing all the years of

1340
01:25:24,420 --> 01:25:30,540
the semantics of this one by induction given the the semantics of this one

1341
01:25:32,060 --> 01:25:36,450
simply mainly this i imagine i have mapping that takes

1342
01:25:36,450 --> 01:25:38,940
o point

1343
01:25:38,950 --> 01:25:40,500
in my latest

1344
01:25:40,520 --> 01:25:42,100
and this is another point

1345
01:25:44,020 --> 01:25:47,220
remember my memories here the points for us all

1346
01:25:47,270 --> 01:25:49,080
o point of the poster

1347
01:25:49,100 --> 01:25:49,870
it is

1348
01:25:49,880 --> 01:25:52,020
so i called

1349
01:25:52,040 --> 01:25:53,970
a mapping

1350
01:25:53,980 --> 01:25:56,990
what is now in annual it is monotonic

1351
01:25:57,000 --> 01:25:58,890
if it preserves the order

1352
01:25:58,940 --> 01:26:01,330
so he was leading

1353
01:26:01,390 --> 01:26:03,780
and you can imagine canada mapping

1354
01:26:04,030 --> 01:26:05,980
i want to associate to the next

1355
01:26:05,990 --> 01:26:08,360
six like relation

1356
01:26:08,420 --> 01:26:13,280
when will be monotonic because if i if i take two sets one embedded into

1357
01:26:13,280 --> 01:26:14,190
the other

1358
01:26:14,240 --> 01:26:17,520
the for this so the first one will be embedded in the predecessors of the

1359
01:26:18,420 --> 01:26:22,910
if the mapping is just give me the predecessor

1360
01:26:22,920 --> 01:26:24,420
the this is so

1361
01:26:25,810 --> 01:26:27,280
so here

1362
01:26:28,130 --> 01:26:32,550
that's what i call my lecture on the fixed point

1363
01:26:32,560 --> 01:26:34,980
you can define the fixed point of every mapping

1364
01:26:39,640 --> 01:26:42,290
point the defendant unless

1365
01:26:42,350 --> 01:26:44,000
mappings are

1366
01:26:44,000 --> 01:26:46,010
your mapping is monotone

1367
01:26:46,020 --> 01:26:48,130
this is a mathematical one

1368
01:26:48,140 --> 01:26:50,020
to define something

1369
01:26:50,030 --> 01:26:53,110
well relevant men that meaningful

1370
01:26:56,110 --> 01:26:58,570
but you have to keep in mind is that if you have a lot of

1371
01:26:58,570 --> 01:27:00,080
the new function

1372
01:27:00,450 --> 01:27:02,290
you have

1373
01:27:02,310 --> 01:27:03,570
an element OK

1374
01:27:03,590 --> 01:27:04,930
whatever you take

1375
01:27:04,940 --> 01:27:08,250
can be called the fixed point if it maps onto itself

1376
01:27:08,260 --> 01:27:10,350
the fixed point

1377
01:27:11,030 --> 01:27:14,540
i don't mean that you need not be to define fixed point

1378
01:27:14,570 --> 01:27:16,310
this but clearly defined

1379
01:27:16,360 --> 01:27:18,950
x is mapped onto itself

1380
01:27:20,830 --> 01:27:25,380
if i not just introduce innovations is how many times a f

1381
01:27:25,390 --> 01:27:27,580
before the

1382
01:27:29,540 --> 01:27:31,770
with the new function i mean

1383
01:27:31,770 --> 01:27:34,700
composing monotonic functions remain monotonic

1384
01:27:34,720 --> 01:27:35,780
the problem

1385
01:27:35,800 --> 01:27:39,010
and now comes the big big big hero

1386
01:27:39,020 --> 01:27:41,780
that's the one that is always

1387
01:27:41,780 --> 01:27:44,930
mean always the one you need when you're in

1388
01:27:44,980 --> 01:27:50,840
very standard settings so that you have is that the early eighties

1389
01:27:50,860 --> 01:27:55,960
and in general i mean that the medical journal based across related

1390
01:27:56,020 --> 01:27:59,440
you need some extra property which to be complete

1391
01:27:59,450 --> 01:28:01,000
what it means

1392
01:28:02,780 --> 01:28:07,960
the objects when you can combine as king the

1393
01:28:07,970 --> 01:28:09,540
meet all the joint

1394
01:28:09,570 --> 01:28:11,520
it would still be

1395
01:28:11,610 --> 01:28:16,020
this is not always the case

1396
01:28:16,040 --> 01:28:23,300
again to make electronic databases and computer completely this is so just i mean

1397
01:28:23,320 --> 01:28:24,300
nearly four

1398
01:28:24,320 --> 01:28:27,930
oppose that basically this

1399
01:28:27,930 --> 01:28:32,970
their complete because the significance of this intersection of two sets and the union of

1400
01:28:32,970 --> 01:28:34,200
two sets

1401
01:28:34,220 --> 01:28:37,210
that's fine

1402
01:28:41,120 --> 01:28:44,120
in middle ages

1403
01:28:44,140 --> 01:28:46,060
this is always defined

1404
01:28:46,100 --> 01:28:49,070
for every time i mean

1405
01:28:51,100 --> 01:28:54,800
points in the latest to take aways that you need

1406
01:28:54,810 --> 01:28:58,540
low to exist of a bunch train test

1407
01:28:58,550 --> 01:29:02,100
it's full of apoptosis

1408
01:29:02,170 --> 01:29:04,120
and if you take

1409
01:29:04,210 --> 01:29:08,440
all points altogether due to you take the

1410
01:29:08,450 --> 01:29:13,340
the love of you get the element which belongs to the to the latest so

1411
01:29:13,340 --> 01:29:15,470
we have to open but on

1412
01:29:15,520 --> 01:29:20,380
four sets of positive construction and bottom is the empty set and t

1413
01:29:20,420 --> 01:29:22,270
subset of

1414
01:29:22,270 --> 01:29:25,300
so this one

1415
01:29:41,780 --> 01:29:45,540
i think it is

1416
01:30:40,150 --> 01:30:52,690
this example or this

1417
01:30:55,300 --> 01:30:59,100
it is

1418
01:31:11,120 --> 01:31:13,070
the other side

1419
01:31:56,530 --> 01:31:59,910
we use

1420
01:32:02,900 --> 01:32:07,270
so much for sure

1421
01:32:10,200 --> 01:32:11,560
this what

1422
01:32:17,480 --> 01:32:19,950
sure it

1423
01:32:19,960 --> 01:32:22,870
this is

1424
01:32:23,640 --> 01:32:27,590
when you buy

1425
01:32:49,030 --> 01:32:51,280
if you wish

1426
01:33:02,270 --> 01:33:05,380
she also

1427
01:34:10,750 --> 01:34:14,270
and reason

1428
01:34:35,210 --> 01:34:41,630
well i

1429
01:35:18,710 --> 01:35:20,230
it was

1430
01:35:48,540 --> 01:35:52,540
so the patient

1431
01:36:13,710 --> 01:36:16,020
this was

1432
01:36:19,330 --> 01:36:21,480
search engine

1433
01:36:21,500 --> 01:36:29,150
it's not just the rest of

1434
01:36:29,170 --> 01:36:31,730
just read

1435
01:36:33,380 --> 01:36:36,650
and this was actually

1436
01:36:41,650 --> 01:36:43,150
the lines

1437
01:36:44,000 --> 01:36:45,710
o one

1438
01:36:49,690 --> 01:36:53,330
he is

1439
01:36:53,330 --> 01:36:57,060
to pick the right parts of the probability of choosing the right boxes so if

1440
01:36:57,160 --> 01:37:00,410
these two distributions are very similar it's going to be

1441
01:37:00,430 --> 01:37:01,350
very hard

1442
01:37:01,370 --> 01:37:03,140
so this probability is going to be

1443
01:37:03,160 --> 01:37:05,500
large otherwise to easy

1444
01:37:05,640 --> 01:37:12,070
what's the cost of being wrong well if you're wrong you'll pick and again notation

1445
01:37:12,070 --> 01:37:15,580
easily messed up here you picked the wrong

1446
01:37:15,600 --> 01:37:20,640
base classifier you'll say OK base classifiers the interval from delta one self from zero

1447
01:37:20,640 --> 01:37:24,660
to one or vice versa so what's the price you pay wild preservation given by

1448
01:37:24,660 --> 01:37:26,540
these because

1449
01:37:26,540 --> 01:37:31,480
OK even if you picked the wrong since it is close to level one half

1450
01:37:31,480 --> 01:37:34,580
you don't pay that bit of price so the

1451
01:37:34,770 --> 01:37:38,180
the cost of being wrong is on the order of tell race to the cap

1452
01:37:38,190 --> 01:37:41,640
OK because of this

1453
01:37:44,230 --> 01:37:46,060
you can look OK what's it

1454
01:37:46,100 --> 01:37:50,540
what's the kullback leibler divergence in this case was given by this expression where n

1455
01:37:50,540 --> 01:37:53,520
is the number of data points to collect and

1456
01:37:53,540 --> 01:37:55,180
it appears here to tell

1457
01:37:55,190 --> 01:37:59,560
it especially to do with that gap between the level one half zero so if

1458
01:37:59,560 --> 01:38:02,540
and as doing exactly this

1459
01:38:02,560 --> 01:38:06,910
same here so it's the squared pretty much

1460
01:38:06,930 --> 01:38:11,790
OK so from the tower in order for this to be a constant so

1461
01:38:11,810 --> 01:38:15,270
just because of that if you multiply these two terms these are the only known

1462
01:38:15,270 --> 01:38:20,830
constant terms here don't have the constant means that the probability of being wrong is

1463
01:38:21,680 --> 01:38:22,910
your point one

1464
01:38:22,960 --> 01:38:25,120
it's bounded away from zero

1465
01:38:25,950 --> 01:38:28,040
then we can put all this together

1466
01:38:28,060 --> 01:38:29,730
and because this

1467
01:38:29,750 --> 01:38:33,020
for this particular problem doesn't depend on the estimated that we know what the best

1468
01:38:33,020 --> 01:38:35,600
thing is so the probability of

1469
01:38:35,620 --> 01:38:37,870
yes DSS risk being greater

1470
01:38:38,910 --> 01:38:40,370
the same

1471
01:38:40,390 --> 01:38:42,370
just replacing tau there

1472
01:38:42,390 --> 01:38:46,790
it's going to be greater than zero point one are created and the across

1473
01:38:46,790 --> 01:38:49,350
so very have our

1474
01:38:49,410 --> 01:38:50,790
lower bound

1475
01:38:50,810 --> 01:38:54,750
this is not exactly the form we've seen before

1476
01:38:54,790 --> 01:38:56,980
if you want to get in the final before

1477
01:38:57,000 --> 01:38:58,290
you'll have to use

1478
01:38:58,310 --> 01:39:02,370
i markov inequality and i don't see this may be a point of going through

1479
01:39:02,370 --> 01:39:04,020
this in very detailed

1480
01:39:04,040 --> 01:39:05,560
so we just showed this

1481
01:39:05,580 --> 01:39:11,210
you can use markov inequality that's inequality that characterizes what happens to non negative

1482
01:39:11,230 --> 01:39:16,410
random variables tells you a relationship between the tail behaviour in the expectation of the

1483
01:39:17,810 --> 01:39:21,810
so if you put this all together what you get is

1484
01:39:21,830 --> 01:39:25,620
something else about the same but now it's in terms of the expected risk it

1485
01:39:25,620 --> 01:39:31,080
tells you the expected risk and not that faster than that constant times

1486
01:39:33,910 --> 01:39:36,770
so that's the way you prove to lower bounds here so

1487
01:39:36,790 --> 01:39:41,430
such as the seeds may be a little bit hard to digest at first because

1488
01:39:41,430 --> 01:39:44,050
you're are used to think about upper bounds of the time so you see the

1489
01:39:44,050 --> 01:39:46,140
inequalities going the wrong way

1490
01:39:48,390 --> 01:39:52,060
but there's the question of what happens in passive learning ways passive learning so so

1491
01:39:56,410 --> 01:39:57,600
let's just

1492
01:39:57,620 --> 01:40:00,540
please exactly the same game but for passive learning

1493
01:40:02,270 --> 01:40:04,290
now not take samples everywhere

1494
01:40:04,310 --> 01:40:05,250
OK you don't know

1495
01:40:05,290 --> 01:40:11,230
what i policies find distinguish the only possibility sample somewhat uniformly over the domain so

1496
01:40:11,230 --> 01:40:13,500
you're taking samples like this

1497
01:40:13,500 --> 01:40:15,480
so only a fraction

1498
01:40:15,500 --> 01:40:19,870
tau of the samples are informative right on the samples that land on this interval

1499
01:40:20,100 --> 01:40:22,120
informative all the other ones are rubbish

1500
01:40:24,180 --> 01:40:27,730
if you look at the kullback leibler divergence in this case the difference between the

1501
01:40:27,730 --> 01:40:31,080
two distributions is going to be exactly the same what we had before

1502
01:40:31,160 --> 01:40:32,910
but there's this actually culture

1503
01:40:32,930 --> 01:40:36,190
because it is saying is that it is only a fraction of the samples are

1504
01:40:38,850 --> 01:40:41,480
we just have to play exactly the same

1505
01:40:41,850 --> 01:40:46,370
the same game and that you see where what's changes in the phone itself having

1506
01:40:46,370 --> 01:40:49,950
two k minus two now we have two k minus one that's that was a

1507
01:40:49,950 --> 01:40:51,500
big difference

1508
01:40:51,520 --> 01:40:53,450
so you see that

1509
01:40:53,460 --> 01:40:57,750
the lower bounds for passive to the only difference is this is that you're collecting

1510
01:40:57,750 --> 01:41:01,640
samples in place so you don't get any information

1511
01:41:05,390 --> 01:41:08,060
now we're going to generalize this would be true

1512
01:41:08,080 --> 01:41:10,160
multiple dimensions

1513
01:41:11,960 --> 01:41:15,620
let's make just big break if there's any questions or so

1514
01:41:15,640 --> 01:41:17,290
before we start

1515
01:41:17,310 --> 01:41:19,640
a little bit of time to prove so

1516
01:41:19,640 --> 01:41:24,290
as any questions at this point

1517
01:41:48,230 --> 01:41:53,710
so the question is what if the class the underlying class of problems is different

1518
01:41:53,710 --> 01:41:59,730
than this one so maybe there's two transitions and you don't know that well then

1519
01:42:00,140 --> 01:42:03,540
this procedure for active learning is going to do properly

1520
01:42:04,560 --> 01:42:10,060
four lyricist we don't know exactly what it does but the passive learning procedures might

1521
01:42:10,060 --> 01:42:15,250
do better if you say use empirical risk minimization or something like that

1522
01:42:16,690 --> 01:42:21,580
that's the problem but the task here at hand was actually trying to understand what

1523
01:42:21,580 --> 01:42:23,350
active learning can do for you not

1524
01:42:24,040 --> 01:42:27,850
that's what i said that maybe the problems of contract but it tells

1525
01:42:27,870 --> 01:42:32,640
it it gives an indication of what that one can buy free by you all

1526
01:42:32,640 --> 01:42:36,250
should you go about doing it it doesn't really tell you to solve it in

1527
01:42:37,140 --> 01:42:41,350
it's unfortunate but it doesn't tell you that it just gives you a better understanding

1528
01:42:41,370 --> 01:42:43,290
what are the trade offs

1529
01:42:43,310 --> 01:42:45,080
there are some ways

1530
01:42:45,080 --> 01:42:50,690
so in this case you be made the object was to performance comparison between these

1531
01:42:51,020 --> 01:42:52,520
two heuristics that i

1532
01:42:53,350 --> 01:42:57,320
so this has been used to forward to think about this case i want to

1533
01:42:57,870 --> 01:43:00,740
which he also do a good job in this case

1534
01:43:00,740 --> 01:43:02,670
so what we should do

1535
01:43:02,810 --> 01:43:07,070
it is which is all always cost

1536
01:43:08,780 --> 01:43:09,800
the they get

1537
01:43:09,810 --> 01:43:10,600
can be

1538
01:43:10,610 --> 01:43:14,060
so it's a good way of

1539
01:43:14,080 --> 01:43:16,510
well verifying experiments

1540
01:43:16,560 --> 01:43:17,990
we have some

1541
01:43:18,280 --> 01:43:20,200
machine repository

1542
01:43:20,640 --> 01:43:23,950
so we could be introduced the study

1543
01:43:24,030 --> 01:43:25,840
a differential equation

1544
01:43:25,870 --> 01:43:32,040
the top of the of also search space so simply try randomly

1545
01:43:32,090 --> 01:43:33,890
the points the search space

1546
01:43:33,910 --> 01:43:37,310
and if you check the best for your answer

1547
01:43:37,340 --> 01:43:39,960
so if you lot of

1548
01:43:40,020 --> 01:43:41,870
there should be

1549
01:43:41,890 --> 01:43:47,170
you don't have any heuristic is just trying point

1550
01:43:47,300 --> 01:43:49,180
there's always some of launch

1551
01:43:49,300 --> 01:43:55,540
and you know it you can use cases with very simple iterative local search which

1552
01:43:55,540 --> 01:43:59,580
can be used clustering algorithms it is

1553
01:43:59,640 --> 01:44:03,630
two things to say very often because is deterministic

1554
01:44:03,770 --> 01:44:06,700
this is just some random points

1555
01:44:07,030 --> 01:44:08,910
it is this is what you get

1556
01:44:09,780 --> 01:44:11,980
so if you have many many times

1557
01:44:13,280 --> 01:44:15,640
what's the best is again

1558
01:44:15,710 --> 01:44:22,600
so was that you can you several times also because of be but still have

1559
01:44:22,610 --> 01:44:27,070
to make it to be competitive with

1560
01:44:27,090 --> 01:44:31,890
so what we did is that if you give all these

1561
01:44:31,910 --> 01:44:36,690
among of candidate solutions for evaluation because they always the true

1562
01:44:36,710 --> 01:44:42,230
currency to measure for search heuristics how much you have to try to find a

1563
01:44:42,250 --> 01:44:45,570
solution because it usually the combination

1564
01:44:45,590 --> 01:44:49,300
OK so

1565
01:44:49,460 --> 01:44:53,180
just put a lot of pictures

1566
01:44:53,230 --> 01:44:55,850
we just as want these days

1567
01:44:57,290 --> 01:45:03,160
in the challenge posed the clustering problem regarding the whole

1568
01:45:03,160 --> 01:45:04,420
number of clusters

1569
01:45:04,430 --> 01:45:05,680
what is

1570
01:45:05,700 --> 01:45:07,420
oh yes and no

1571
01:45:07,470 --> 01:45:11,340
but they basically generated based in

1572
01:45:11,550 --> 01:45:14,270
number distribution

1573
01:45:14,410 --> 01:45:15,970
so noise simple

1574
01:45:15,970 --> 01:45:17,450
let's on

1575
01:45:20,320 --> 01:45:21,410
we took the classic

1576
01:45:21,410 --> 01:45:23,890
which is what

1577
01:45:24,000 --> 01:45:27,940
you wouldn't believe how many papers find the status

1578
01:45:28,050 --> 01:45:32,490
and which is the most the status of

1579
01:45:33,230 --> 01:45:34,870
the is usually

1580
01:45:37,280 --> 01:45:39,940
so to

1581
01:45:40,050 --> 01:45:43,020
more this is one of the best

1582
01:45:43,070 --> 01:45:46,690
wisconsin state is which

1583
01:45:49,870 --> 01:45:53,210
this sort of different chemical properties of china

1584
01:45:53,240 --> 01:45:54,970
the trust

1585
01:45:55,170 --> 01:45:58,430
one of the support station

1586
01:45:58,440 --> 01:46:02,160
you to g OK so these problems to

1587
01:46:02,820 --> 01:46:04,660
the problem you can get

1588
01:46:04,720 --> 01:46:08,340
so talk about this is very difficult to analyse

1589
01:46:08,430 --> 01:46:13,890
it states that very difficult to discriminate is close to neutral

1590
01:46:15,200 --> 01:46:16,380
this one be

1591
01:46:17,930 --> 01:46:19,910
i think this is a very simple

1592
01:46:19,980 --> 01:46:27,770
OK this human speech is the official there's no

1593
01:46:28,050 --> 01:46:30,410
you have to

1594
01:46:31,300 --> 01:46:34,060
this to show that this criteria

1595
01:46:34,080 --> 01:46:38,250
he married traces the space to

1596
01:46:40,210 --> 01:46:42,040
i think the all numbers

1597
01:46:42,360 --> 01:46:46,430
these were results was be

1598
01:46:47,130 --> 01:46:51,470
compared to the other evidence so you

1599
01:46:51,510 --> 01:46:54,440
the me the best of

1600
01:46:54,500 --> 01:46:56,670
she she's just be

1601
01:46:56,870 --> 01:46:58,490
some statistics about

1602
01:46:59,710 --> 01:47:02,800
results are

1603
01:47:02,830 --> 01:47:04,280
just to chime with over

1604
01:47:04,320 --> 01:47:06,860
and as you can see this

1605
01:47:06,870 --> 01:47:09,660
and it's community only

1606
01:47:10,790 --> 01:47:11,870
so we have

1607
01:47:11,880 --> 01:47:18,230
there is that there is any but so far is

1608
01:47:18,230 --> 01:47:20,410
we need to go to the set

1609
01:47:20,420 --> 01:47:22,270
the price it

1610
01:47:22,440 --> 01:47:23,920
but can see

1611
01:47:23,940 --> 01:47:26,690
it depends on the use

1612
01:47:26,700 --> 01:47:28,430
do it for you

1613
01:47:28,460 --> 01:47:32,750
also satisfied with increasing difficulty

1614
01:47:32,790 --> 01:47:40,140
the challenge dataset you can see here so we can do it you have to

1615
01:47:41,090 --> 01:47:43,240
he became the performance

1616
01:47:43,270 --> 01:47:44,290
and the end

1617
01:47:44,370 --> 01:47:47,630
decency clearly like this

1618
01:47:49,520 --> 01:47:58,970
one of the ways of using the french revolution and somewhere here we'll to get

1619
01:47:58,970 --> 01:48:00,730
this is in data

1620
01:48:00,800 --> 01:48:04,040
section also use of search

1621
01:48:04,250 --> 01:48:07,080
in this case we use one hundred thousand population

1622
01:48:10,270 --> 01:48:15,190
what we get is actually quite time sure that so we actually with much fewer

1623
01:48:15,190 --> 01:48:17,960
sheet of paper just to work through and see that it does

1624
01:48:18,010 --> 01:48:19,590
i have an intuition for that

1625
01:48:19,600 --> 01:48:22,650
i don't have an institution of i one by tomorrow morning i'll let you know

1626
01:48:22,770 --> 01:48:31,020
any other questions and place the very place have questions by the way

1627
01:48:31,040 --> 01:48:32,070
OK so

1628
01:48:32,830 --> 01:48:37,420
we've got we put priors all the promises so we know what a bayesian mixture

1629
01:48:37,430 --> 01:48:39,090
of gaussians

1630
01:48:40,610 --> 01:48:43,560
we're interested in doing things like finding

1631
01:48:43,600 --> 01:48:47,140
posterior distributions of these parameters for example

1632
01:48:47,160 --> 01:48:48,140
or in

1633
01:48:49,010 --> 01:48:52,390
evaluating the model evidence

1634
01:48:52,450 --> 01:48:56,400
the problem now is that the models now become sufficiently complex that exact

1635
01:48:56,420 --> 01:48:58,370
bayesian inference is intractable

1636
01:48:58,380 --> 01:49:00,870
we can't simultaneously marginalized

1637
01:49:02,700 --> 01:49:06,280
over all of these latent variables and all of these parameters we can't do that

1638
01:49:07,730 --> 01:49:09,360
so we have to resort to some

1639
01:49:09,370 --> 01:49:10,980
one approximation

1640
01:49:11,020 --> 01:49:14,950
i think by now you're all experts on markov chain monte carlo methods

1641
01:49:16,060 --> 01:49:19,860
they have a lot of advantages i got a major advantage is that the only

1642
01:49:19,860 --> 01:49:24,060
approximation which one generally makes ice i suspect is really the computational one in other

1643
01:49:24,060 --> 01:49:27,650
words one is forced to resort to analytical approximations

1644
01:49:27,660 --> 01:49:29,820
but it's sometimes difficult to know

1645
01:49:29,860 --> 01:49:33,690
whether it's giving the right answer not and certainly computationally expensive

1646
01:49:33,700 --> 01:49:37,500
so i'm going to talk about variational inference which is quite different philosophy the idea

1647
01:49:37,500 --> 01:49:40,130
is to make some analytical approximations rather than

1648
01:49:40,150 --> 01:49:41,480
numerical ones

1649
01:49:43,380 --> 01:49:46,450
it has some some nice advantages i think one is that is applicable to much

1650
01:49:46,450 --> 01:49:48,150
larger scale problems

1651
01:49:48,160 --> 01:49:53,880
and in markov chain monte carlo seems to be and i think it also provides

1652
01:49:53,880 --> 01:49:56,810
a lot of insight you get a lot of mathematical insight into the structure of

1653
01:49:56,810 --> 01:49:58,620
the model in the form of the solution

1654
01:49:58,670 --> 01:50:00,450
and an approximation

1655
01:50:00,460 --> 01:50:03,310
so obviously we lose something in the process

1656
01:50:03,390 --> 01:50:06,000
but police were able to say a little bit about what it is that we've

1657
01:50:06,000 --> 01:50:10,310
lost what the effect of the approximation is going to be

1658
01:50:10,430 --> 01:50:16,010
variational inference i think could be of could refer to very large class of sort

1659
01:50:16,010 --> 01:50:18,380
of analytical approximation schemes

1660
01:50:18,390 --> 01:50:19,440
but also

1661
01:50:19,450 --> 01:50:23,630
it is sometimes called variational bayes in which case it applies to represent a rather

1662
01:50:23,630 --> 01:50:27,760
more restricted class of approximation schemes and that's the one that i'm going to discuss

1663
01:50:27,770 --> 01:50:32,410
and there are there are other variational like schemes such as expectation propagation

1664
01:50:32,420 --> 01:50:37,040
which are which are different and have different strengths and weaknesses time

1665
01:50:37,200 --> 01:50:41,560
and so we have chance to discuss those

1666
01:50:41,570 --> 01:50:46,350
and even within the variational framework partial focus on a particular special case of a

1667
01:50:46,360 --> 01:50:49,060
very interesting one

1668
01:50:49,100 --> 01:50:52,480
so i'm going to use the notation z now to denote all of the latent

1669
01:50:52,480 --> 01:50:57,610
variables in the parameters in the model so i apologize here switching station slightly but

1670
01:50:57,730 --> 01:51:02,420
so i give you a heads-up get confused server moment also i'm going to think

1671
01:51:02,430 --> 01:51:06,560
that is being everything them in the gas mixture modeling with latent variables and all

1672
01:51:06,560 --> 01:51:09,200
the parameters are all hidden variables in the model

1673
01:51:09,270 --> 01:51:12,160
a little bit later again all switch back to the special special case of the

1674
01:51:12,160 --> 01:51:16,320
gas in mixture with just represents the latent variables hopefully get confused if you feel

1675
01:51:16,320 --> 01:51:20,380
confused stop and ask

1676
01:51:20,430 --> 01:51:25,450
so let me remind you of this this slide that we had this morning because

1677
01:51:25,450 --> 01:51:26,510
this is the

1678
01:51:26,520 --> 01:51:31,570
this is it really this is this is variational inference in sort of one equation

1679
01:51:31,580 --> 01:51:33,850
so understanding this is quite important

1680
01:51:33,860 --> 01:51:35,320
so we call

1681
01:51:36,770 --> 01:51:41,790
the same as just in a slightly different context i fully bayesian context z is

1682
01:51:41,790 --> 01:51:42,960
the set of all

1683
01:51:42,980 --> 01:51:46,770
latent variables and parameters in our model

1684
01:51:46,810 --> 01:51:51,390
and recall that he wrote the log of the marginal probability of the data something

1685
01:51:51,390 --> 01:51:55,400
which show call the model evidence for reasons that will discuss later

1686
01:51:55,420 --> 01:51:59,160
that can be decomposed into the sum of two terms which are given by this

1687
01:51:59,160 --> 01:52:03,870
term in this and call this morning that by applying the product rule to this

1688
01:52:03,880 --> 01:52:07,820
joint distribution here we we prove this decomposition

1689
01:52:07,830 --> 01:52:11,900
we prove the decomposition holds for any choice of q and z

1690
01:52:11,950 --> 01:52:16,400
as long as q that is a valid probability distribution to be nonnegative and sum

1691
01:52:16,400 --> 01:52:18,490
or integrate to one

1692
01:52:18,530 --> 01:52:20,890
and again i use use integrals

1693
01:52:20,940 --> 01:52:27,140
but if these are discrete variables placed into my some

1694
01:52:28,280 --> 01:52:31,160
i said a little bit about the kullback leibler divergence on to go back and

1695
01:52:31,160 --> 01:52:33,250
look at the kullback leibler divergence

1696
01:52:33,260 --> 01:52:36,590
in a little bit more detail recall from this morning

1697
01:52:36,640 --> 01:52:37,960
but the

1698
01:52:37,980 --> 01:52:40,410
if we maximize the lower bound

1699
01:52:40,420 --> 01:52:44,550
or equivalently minimize the kullback leibler divergence with respect to q said we get is

1700
01:52:44,570 --> 01:52:48,780
true posterior qz would equal the true posterior distribution

1701
01:52:48,830 --> 01:52:51,030
so look at that in a bit more detail

1702
01:52:51,050 --> 01:52:54,770
again this was the picture that we had we decompose log

1703
01:52:54,780 --> 01:52:57,460
model evidence into classical badly

1704
01:53:01,790 --> 01:53:05,120
so if you have a closer look at the kullback leibler divergence

1705
01:53:05,170 --> 01:53:08,440
the kullback leibler divergence between

1706
01:53:08,450 --> 01:53:11,180
q and p

1707
01:53:11,190 --> 01:53:13,740
it is minus the integral

1708
01:53:13,750 --> 01:53:16,850
qz long

1709
01:53:19,640 --> 01:53:23,860
just writers pz this condition on the data so just look at the KL divergence

1710
01:53:23,860 --> 01:53:27,230
in general from moment

1711
01:53:27,280 --> 01:53:29,410
so that's the KL divergence

1712
01:53:29,420 --> 01:53:33,550
and the first property it has is that it nonnegative

1713
01:53:33,560 --> 01:53:37,310
so to see what's nonnegative we just need to recall the

1714
01:53:37,320 --> 01:53:39,150
the loss function is

1715
01:53:39,160 --> 01:53:40,750
convex functions

1716
01:53:40,760 --> 01:53:42,870
that z

1717
01:53:42,940 --> 01:53:45,210
lord z looks like this it's sort of

1718
01:53:45,250 --> 01:53:47,760
it always occurs in that direction

1719
01:53:49,020 --> 01:53:51,680
the definition of convexity is that

1720
01:53:52,210 --> 01:53:55,890
if i take two point on that curve and joined by straight line

1721
01:53:55,900 --> 01:53:57,760
and any points on the straight line

1722
01:53:57,800 --> 01:53:59,140
is always

1723
01:53:59,150 --> 01:54:01,750
below the curve except at the endpoints

1724
01:54:01,770 --> 01:54:06,860
so i've expressed that mathematically by saying that if i if i take these two

1725
01:54:07,940 --> 01:54:10,920
i think these two point

1726
01:54:11,020 --> 01:54:15,960
over a convex combination of sort of lambda this one minus lambda that there will

1727
01:54:15,960 --> 01:54:17,640
be a point on this

1728
01:54:18,660 --> 01:54:21,850
o point on the straight line

1729
01:54:21,870 --> 01:54:24,180
can generalize that slightly i can say that

1730
01:54:24,190 --> 01:54:29,650
if i have a bunch of nonnegative parameters lambda i which sum to one

1731
01:54:29,660 --> 01:54:32,150
a bit like policies if you like

1732
01:54:32,200 --> 01:54:34,020
then the someone i

1733
01:54:36,320 --> 01:54:38,570
lambda i times

1734
01:54:38,620 --> 01:54:41,120
this convex function which this case is z

1735
01:54:41,170 --> 01:54:42,960
long that i

1736
01:54:42,980 --> 01:54:46,440
is less than or equal to the log

1737
01:54:46,520 --> 01:54:52,600
the someone i lambda i said i

1738
01:54:52,640 --> 01:54:54,410
so that's just saying that the

1739
01:54:54,420 --> 01:54:58,440
the linear combination of the logs which is this point here

1740
01:54:58,450 --> 01:55:00,430
lies on or below

1741
01:55:00,480 --> 01:55:03,940
the log the linear combination which is this point here just by saying that the

1742
01:55:03,950 --> 01:55:06,630
convex function

1743
01:55:06,670 --> 01:55:11,290
and then if you allow me the liberty of replacing the sum by an integration

1744
01:55:11,340 --> 01:55:12,860
weighted by

1745
01:55:12,870 --> 01:55:15,470
probability density so nonnegative

1746
01:55:15,480 --> 01:55:17,690
function which integrates to one

1747
01:55:19,250 --> 01:55:23,000
then we have the following properties the intricate of q

1748
01:55:23,040 --> 01:55:25,070
log of p of q

1749
01:55:25,160 --> 01:55:28,190
minus that in general dz


1
00:00:00,000 --> 00:00:00,880
doesn't work

2
00:00:00,900 --> 00:00:03,670
repels water

3
00:00:03,680 --> 00:00:06,940
suppose now

4
00:00:08,100 --> 00:00:10,810
take a piece of plastic which i can do

5
00:00:10,860 --> 00:00:12,760
and i put

6
00:00:12,770 --> 00:00:18,780
the negative charge on the plastic on one side and i put the positive charge

7
00:00:18,780 --> 00:00:22,210
on the plastic on the other side

8
00:00:22,220 --> 00:00:23,960
i can do that

9
00:00:23,980 --> 00:00:26,220
i can have another piece of plastic

10
00:00:27,980 --> 00:00:35,370
the positive charges also here and negative

11
00:00:37,860 --> 00:00:40,330
what i think will attract negative

12
00:00:40,350 --> 00:00:47,780
but clearly if i rotate them around negative will repel negative positive really help us

13
00:00:47,890 --> 00:00:50,990
so now you think there is an enormous parallel

14
00:00:51,030 --> 00:00:54,620
between magnetism and electric charge and that

15
00:00:54,630 --> 00:00:55,960
it is a misconception

16
00:00:57,580 --> 00:00:59,620
this i take the soul

17
00:00:59,720 --> 00:01:02,150
and i cut this in the middle

18
00:01:02,210 --> 00:01:03,380
the left side

19
00:01:03,390 --> 00:01:04,930
of that piece of plastic

20
00:01:04,970 --> 00:01:07,380
is only positively charged

21
00:01:07,460 --> 00:01:08,960
so here it is

22
00:01:08,970 --> 00:01:15,180
and the right side is only negative charge

23
00:01:15,360 --> 00:01:17,040
now i take an axe

24
00:01:17,130 --> 00:01:18,930
and i cut the

25
00:01:18,990 --> 00:01:22,170
magnets in the middle and what we have now

26
00:01:22,180 --> 00:01:24,710
i think i have the south pole on the left side

27
00:01:24,730 --> 00:01:27,920
and the north part on the right side the answer is no you end up

28
00:01:29,640 --> 00:01:31,800
magnets which did

29
00:01:31,860 --> 00:01:33,250
i have a

30
00:01:33,290 --> 00:01:37,010
north pole and south pole and this part also

31
00:01:37,100 --> 00:01:39,380
as the north pole and the south

32
00:01:39,420 --> 00:01:41,750
so there is no such thing

33
00:01:41,760 --> 00:01:45,730
it's coming in magnets and then having one piece which is only the south pole

34
00:01:45,770 --> 00:01:49,510
and one piece which is only the north pole

35
00:01:49,510 --> 00:01:53,650
so you always have was a magnet know whether how often you break it

36
00:01:53,710 --> 00:01:55,250
you always have

37
00:01:55,290 --> 00:01:56,360
two polls

38
00:01:56,380 --> 00:01:59,080
we call those dipoles in physics

39
00:01:59,130 --> 00:02:00,970
died stands for two

40
00:02:01,030 --> 00:02:05,010
the dialogue is the discussion between two people

41
00:02:05,060 --> 00:02:06,940
you could make

42
00:02:07,000 --> 00:02:12,760
one piece of magnetic material only the south pole we would call that a monopole

43
00:02:12,760 --> 00:02:14,890
modo stands for one

44
00:02:14,970 --> 00:02:20,130
monologue monologue is one person talking like now

45
00:02:20,160 --> 00:02:23,030
so less electric monopoles exist

46
00:02:23,090 --> 00:02:29,440
the positive charges monopole electric positive charges are more of a negative electric charges

47
00:02:31,430 --> 00:02:33,660
but then the magnetic monopole

48
00:02:33,670 --> 00:02:37,090
do not exist

49
00:02:37,140 --> 00:02:39,830
someone in my audience

50
00:02:39,930 --> 00:02:44,050
may find a magnetic monopole in the future and if you do

51
00:02:44,110 --> 00:02:45,650
you will definitely get

52
00:02:45,660 --> 00:02:46,960
the nobel prize

53
00:02:46,980 --> 00:02:48,130
four physics

54
00:02:49,650 --> 00:02:52,870
physicists have tried for decades

55
00:02:52,880 --> 00:02:55,290
and still trying to

56
00:02:55,420 --> 00:02:57,770
because from a theoretical point of view

57
00:02:57,790 --> 00:03:03,550
there's no reason why they shouldn't exist except we've never seen one

58
00:03:03,630 --> 00:03:05,250
so here is the task

59
00:03:05,260 --> 00:03:09,880
for you

60
00:03:10,000 --> 00:03:14,290
the electric charges are exceedingly small

61
00:03:16,020 --> 00:03:17,580
they can move

62
00:03:17,620 --> 00:03:21,350
you see it i could move them from the positively charged rule i could bring

63
00:03:21,350 --> 00:03:23,470
them onto the

64
00:03:23,490 --> 00:03:25,820
due to bloom

65
00:03:25,820 --> 00:03:30,310
now the negative charges which have the name we call those electrons

66
00:03:30,360 --> 00:03:35,930
a much smaller and they are much lighter than the positive charges

67
00:03:35,980 --> 00:03:43,640
and so the negative charges can therefore move much easier than the positive charge

68
00:03:43,670 --> 00:03:48,790
and when electric charges move it's almost always

69
00:03:48,790 --> 00:03:50,600
the electrons that move

70
00:03:50,690 --> 00:03:52,150
and when that happens

71
00:03:52,190 --> 00:03:56,660
when electric charges move recall that we give the name we call that an electric

72
00:04:00,480 --> 00:04:04,200
electrons can very easily move in metals

73
00:04:04,220 --> 00:04:06,140
copper ore buyer and

74
00:04:06,150 --> 00:04:07,140
on one

75
00:04:07,150 --> 00:04:09,640
silver gold

76
00:04:09,690 --> 00:04:12,240
metals conduct electricity

77
00:04:12,250 --> 00:04:14,380
very well

78
00:04:14,500 --> 00:04:16,380
take porcelain

79
00:04:16,390 --> 00:04:17,870
the glass

80
00:04:17,910 --> 00:04:19,800
plastic rubber

81
00:04:19,800 --> 00:04:25,580
OK so this tutorial will be on

82
00:04:25,590 --> 00:04:30,010
something which we can say introduction to network analysis will cover a couple of topics

83
00:04:30,020 --> 00:04:37,370
and it will remain about network analysis of social network analysis of

84
00:04:37,370 --> 00:04:39,140
i will try to show

85
00:04:39,160 --> 00:04:42,460
things from the basics

86
00:04:43,030 --> 00:04:45,570
still about some some applications which

87
00:04:45,600 --> 00:04:47,910
we did in the recent times so

88
00:04:47,920 --> 00:04:52,310
joint work with doing i and parts of the presentation were taken from the

89
00:04:52,320 --> 00:04:55,080
tutorial on

90
00:04:55,150 --> 00:04:58,530
networks from new telescopes

91
00:04:59,930 --> 00:05:00,650
our guy

92
00:05:00,670 --> 00:05:02,000
i think it's

93
00:05:02,070 --> 00:05:03,520
at the moment

94
00:05:13,580 --> 00:05:16,850
let's see physically first

95
00:05:17,700 --> 00:05:20,000
introduction what networks are

96
00:05:20,040 --> 00:05:24,220
very basic and the go briefly through the network properties

97
00:05:24,240 --> 00:05:27,890
what relevant information what are what's

98
00:05:27,910 --> 00:05:32,220
interesting information about the networks which we need to do it

99
00:05:32,240 --> 00:05:36,910
if you want to do network analysis and two applications the and so on is

100
00:05:36,910 --> 00:05:42,000
mining of email server logs some some sick people would know about this already and

101
00:05:42,000 --> 00:05:49,550
mining MSN messenger graphs so some recent work from you would have actually

102
00:05:49,580 --> 00:05:53,130
so first

103
00:05:53,140 --> 00:05:55,240
how to locate network

104
00:05:55,270 --> 00:05:58,690
analysis are complex networks

105
00:06:00,960 --> 00:06:05,190
so let's see if if the context is computer science then we would

106
00:06:05,210 --> 00:06:09,530
put complex network somewhere between machine learning data mining

107
00:06:09,550 --> 00:06:16,020
theory for sure so lot of theoretical computer scientists would work with network statistics

108
00:06:16,020 --> 00:06:19,140
the stations are involved in this as well

109
00:06:19,160 --> 00:06:22,160
and general computer systems but well

110
00:06:22,250 --> 00:06:25,690
it's a our position are

111
00:06:25,720 --> 00:06:28,960
among our work with with approach mainly from this

112
00:06:29,010 --> 00:06:31,180
from this side and maybe a little bit from

113
00:06:31,180 --> 00:06:37,080
theory now if we put this context of computer science into the context of science

114
00:06:37,080 --> 00:06:43,740
then of course dealing with networks is our the network analysis would appear in several

115
00:06:43,740 --> 00:06:50,990
other areas especially social sciences social sciences will be the social network analysis biology physics

116
00:06:50,990 --> 00:06:59,640
and industrial applications so this is some of their social network analysis would be placed

117
00:06:59,680 --> 00:07:02,270
OK now what is the net

118
00:07:05,180 --> 00:07:11,680
network first type of objects in the network or graph will be just nodes or

119
00:07:14,260 --> 00:07:17,480
the next stage we add links

120
00:07:19,240 --> 00:07:20,990
so which just connect this

121
00:07:21,010 --> 00:07:23,080
not something else

122
00:07:23,120 --> 00:07:28,260
and so the next feature which we might be interested in is

123
00:07:28,270 --> 00:07:30,210
the direction of the notes

124
00:07:30,230 --> 00:07:34,330
so each node of the links for each link have

125
00:07:38,050 --> 00:07:39,640
so let's see if this would be

126
00:07:39,960 --> 00:07:42,140
sending email is so

127
00:07:42,200 --> 00:07:45,020
these nodes and numerical this guy

128
00:07:49,370 --> 00:07:51,810
if introduced led probabilities

129
00:07:51,830 --> 00:07:53,770
so that information would be

130
00:07:53,810 --> 00:08:02,170
distributed over the neighbours and then this could be kind of probabilistic methods and one

131
00:08:02,170 --> 00:08:04,580
more level

132
00:08:04,640 --> 00:08:08,120
would be dynamic networks so now we are coming to this

133
00:08:08,560 --> 00:08:12,090
notorious thermal properties

134
00:08:12,110 --> 00:08:17,540
buzzwords using eq two so dynamic network so this would be

135
00:08:17,580 --> 00:08:22,010
dynamic never would be something that all the elements in the network changing through time

136
00:08:22,050 --> 00:08:25,430
so this means that we would introduce either

137
00:08:25,450 --> 00:08:32,020
her new nodes are some of the existing nodes would disappear that edges are appearing

138
00:08:32,020 --> 00:08:37,540
and disappearing through time would see an example in in the second and maybe these

139
00:08:37,540 --> 00:08:42,590
probabilities of transitions what would change through time

140
00:08:42,680 --> 00:08:46,740
and this dealing with dynamic

141
00:08:46,750 --> 00:08:51,610
networks is really an active research topic so this is not something where it was

142
00:08:51,620 --> 00:08:56,650
possible to say well that's what these are set of methods and is problems and

143
00:08:56,650 --> 00:09:00,860
that's it so this is still a very active active research topic in

144
00:09:00,920 --> 00:09:04,410
some of these areas which are made for

145
00:09:05,610 --> 00:09:09,850
let's see now an example of dynamic network so dynamic that is really hard to

146
00:09:09,850 --> 00:09:12,750
visualize because because it has this dynamic

147
00:09:12,800 --> 00:09:15,850
dynamic dimension

148
00:09:15,900 --> 00:09:19,000
so basically the demo

149
00:09:19,000 --> 00:09:24,130
we already

150
00:10:03,210 --> 00:10:09,910
here there

151
00:10:18,500 --> 00:10:29,590
you know

152
00:11:00,660 --> 00:11:11,260
where you

153
00:11:18,200 --> 00:11:26,350
you get

154
00:11:26,360 --> 00:11:27,700
i said

155
00:11:33,790 --> 00:11:39,850
all of these

156
00:12:51,630 --> 00:12:53,260
a very

157
00:13:01,730 --> 00:13:02,480
there are

158
00:13:22,410 --> 00:13:24,630
this is a not very

159
00:13:38,150 --> 00:13:45,440
and i don't see

160
00:13:57,290 --> 00:14:00,250
it well

161
00:14:12,520 --> 00:14:23,610
people are

162
00:14:23,610 --> 00:14:25,250
of the angular momentum

163
00:14:25,260 --> 00:14:27,110
i calculated about c

164
00:14:27,120 --> 00:14:28,810
which is the centre of mass

165
00:14:28,880 --> 00:14:31,450
is simply equation number six

166
00:14:31,460 --> 00:14:33,120
it is the moment of inertia

167
00:14:33,130 --> 00:14:36,380
about that point c which is the centre of mass

168
00:14:36,470 --> 00:14:37,820
times omega

169
00:14:37,830 --> 00:14:39,320
about the centre of mass

170
00:14:39,330 --> 00:14:40,090
so c

171
00:14:40,340 --> 00:14:42,180
centre of mass and c are

172
00:14:42,230 --> 00:14:43,450
the same point

173
00:14:43,460 --> 00:14:47,880
what is the moment of inertia of rotation about the centre of mass that is

174
00:14:47,880 --> 00:14:50,120
my one twelve ML squared

175
00:14:50,140 --> 00:14:52,700
so now i have one class

176
00:14:52,740 --> 00:14:53,860
else create

177
00:14:53,870 --> 00:14:56,910
the kind domain that is not intrinsic

178
00:14:56,970 --> 00:14:58,690
spin angular momentum

179
00:14:58,710 --> 00:15:01,010
and it is the same for any point

180
00:15:01,020 --> 00:15:04,630
that you choose even if i chose to point here in space

181
00:15:04,640 --> 00:15:08,180
we can prove that is still the same

182
00:15:08,230 --> 00:15:11,890
and the moment

183
00:15:11,950 --> 00:15:15,700
now we're going to look at our application very huge number of applications and the

184
00:15:15,720 --> 00:15:19,020
next four five lectures we'll go through many of them

185
00:15:19,110 --> 00:15:21,220
in some cases you will see you

186
00:15:21,260 --> 00:15:23,200
yeah that's intuitive that's obvious

187
00:15:23,220 --> 00:15:24,950
in some cases you will say

188
00:15:25,200 --> 00:15:29,020
not so intuitive and in some cases you will fall off your chair

189
00:15:29,080 --> 00:15:33,720
it's completely bizarre it is so nonintuitive that you don't even believe it you won't

190
00:15:33,720 --> 00:15:35,680
believe it until actually show you

191
00:15:35,690 --> 00:15:38,400
with the demonstration but that's the way nature works

192
00:15:38,460 --> 00:15:41,930
that comes later not today

193
00:15:41,980 --> 00:15:44,620
on assignment number seven

194
00:15:44,660 --> 00:15:46,700
i give you a problem

195
00:15:46,740 --> 00:15:48,520
problem seven nine

196
00:15:48,580 --> 00:15:50,660
in which i have a rule or rods

197
00:15:50,720 --> 00:15:54,200
on the frictionless horizontal tables

198
00:15:54,280 --> 00:15:56,770
the ruler has amassed l

199
00:15:56,780 --> 00:15:59,850
mass and has a length l

200
00:15:59,850 --> 00:16:03,230
and here is the centre of mass c

201
00:16:03,230 --> 00:16:04,990
and i hit that

202
00:16:05,000 --> 00:16:07,560
ruler i give impulse

203
00:16:08,840 --> 00:16:10,210
two the direction

204
00:16:10,220 --> 00:16:14,220
of the rule i give in input force acts upon it for a certain amount

205
00:16:14,220 --> 00:16:15,510
of time

206
00:16:15,570 --> 00:16:18,120
and that this distance

207
00:16:19,280 --> 00:16:23,820
i think i call it deep in your problem

208
00:16:23,900 --> 00:16:28,190
that's friction as they

209
00:16:28,200 --> 00:16:29,100
i do this

210
00:16:30,580 --> 00:16:32,530
very short hit

211
00:16:32,550 --> 00:16:37,110
and now the question is what will these objects do

212
00:16:37,110 --> 00:16:39,630
one issue instinct tell you

213
00:16:39,690 --> 00:16:41,390
you will say well

214
00:16:41,480 --> 00:16:46,060
sure it will move in this direction parameters frictionless so whatever happens after the it

215
00:16:46,080 --> 00:16:48,690
happens forever never never never stops

216
00:16:48,730 --> 00:16:51,860
so you'll say well is going to move in this direction that's very vague but

217
00:16:51,860 --> 00:16:53,110
that's true

218
00:16:53,280 --> 00:16:55,300
how about rotation

219
00:16:55,310 --> 00:16:56,970
well it rotates

220
00:16:57,080 --> 00:17:00,230
and if it rotates about which points

221
00:17:00,310 --> 00:17:04,730
so you might say well maybe where the point of rotation may depend on where

222
00:17:04,730 --> 00:17:06,400
i hated

223
00:17:06,470 --> 00:17:09,500
it would be reasonable intuition that is not true

224
00:17:09,600 --> 00:17:14,550
it must rotate about the centre of mass cannot rotate about any of the point

225
00:17:14,600 --> 00:17:18,460
i suppose is rotated about this point just for sake of argument so after the

226
00:17:18,460 --> 00:17:21,430
hit it rotated about this point

227
00:17:21,490 --> 00:17:23,740
that would mean that the centre of mass

228
00:17:23,750 --> 00:17:26,330
we then do this

229
00:17:26,360 --> 00:17:29,720
and that's not allowed because the centre of mass behaved

230
00:17:29,730 --> 00:17:31,140
like the point

231
00:17:31,150 --> 00:17:33,640
in which all the mass is concentrated

232
00:17:33,730 --> 00:17:36,270
f equals a hold for the centre of mass

233
00:17:36,330 --> 00:17:38,220
and so as the

234
00:17:38,230 --> 00:17:41,470
a single point because them at the centre of mass can always be considered to

235
00:17:41,470 --> 00:17:45,230
be a single point was aldermaston at that point can never do this it would

236
00:17:45,230 --> 00:17:46,350
be absurd

237
00:17:46,410 --> 00:17:48,850
so from that reasoning alone

238
00:17:48,850 --> 00:17:50,390
you must conclude

239
00:17:50,400 --> 00:17:52,590
that's the only way

240
00:17:52,590 --> 00:17:53,940
that nature

241
00:17:55,070 --> 00:17:57,360
digest that impulse

242
00:17:58,240 --> 00:17:59,560
by giving

243
00:17:59,600 --> 00:18:01,130
the centre of mass

244
00:18:01,150 --> 00:18:03,840
a certain velocity

245
00:18:03,840 --> 00:18:05,680
in this direction

246
00:18:05,710 --> 00:18:07,390
which will never change

247
00:18:07,440 --> 00:18:08,550
in addition

248
00:18:08,560 --> 00:18:09,810
it will give it

249
00:18:09,880 --> 00:18:14,560
and angular velocity about the centre of mass and if there is no friction that

250
00:18:14,570 --> 00:18:16,270
will never change

251
00:18:16,360 --> 00:18:20,320
so a little later in time

252
00:18:20,320 --> 00:18:23,400
the centre of mass will still be on this line

253
00:18:23,420 --> 00:18:28,090
and it may have rotated one or two or three rotations that depends that depends

254
00:18:28,090 --> 00:18:29,600
on a large eyes

255
00:18:29,600 --> 00:18:32,010
and that depends on the distance d

256
00:18:32,110 --> 00:18:33,310
let's assume

257
00:18:33,360 --> 00:18:36,280
it is now like so

258
00:18:36,320 --> 00:18:40,600
and then is happily rotating with angular velocity

259
00:18:41,640 --> 00:18:43,500
and continues all the time

260
00:18:43,500 --> 00:18:46,760
with that velocity the centre of mass

261
00:18:47,590 --> 00:18:51,650
in their problem i'm asking you to calculate the velocity of the centre of mass

262
00:18:51,700 --> 00:18:52,970
and to calculate

263
00:18:53,030 --> 00:18:56,040
the angular velocity about the centre of mass

264
00:18:56,090 --> 00:18:58,490
i'll help you a little bit

265
00:18:58,510 --> 00:19:01,790
and i hope that it will help you a little more

266
00:19:01,870 --> 00:19:03,610
for the centre of mass

267
00:19:03,680 --> 00:19:08,380
what must always holds the centre of mass acts like a point source

268
00:19:08,390 --> 00:19:11,790
so it was always hold that have equal and

269
00:19:11,790 --> 00:19:13,790
eighty of the centre of mass

270
00:19:13,840 --> 00:19:18,310
that is really one of the major characteristics of the centre of mass

271
00:19:19,350 --> 00:19:24,410
if we look at magnitude if delta t equals

272
00:19:24,460 --> 00:19:26,670
and a centre of mass delta t

273
00:19:26,690 --> 00:19:31,580
the force acts for a certain amount of time and that's the impulse

274
00:19:34,040 --> 00:19:35,840
but if you before i hit

275
00:19:35,850 --> 00:19:38,430
if this velocity is zero

276
00:19:38,440 --> 00:19:40,210
then a thirty

277
00:19:40,220 --> 00:19:44,170
is obviously the velocity of the centre of mass afterwards

278
00:19:44,240 --> 00:19:45,850
he calls eighty right

279
00:19:45,870 --> 00:19:48,010
he was zero to start with

280
00:19:48,040 --> 00:19:50,360
so you see now immediately

281
00:19:50,610 --> 00:19:52,880
i that is the

282
00:19:52,930 --> 00:19:54,300
in polls

283
00:19:54,340 --> 00:19:55,290
he calls

284
00:19:56,130 --> 00:19:59,040
and the velocity of the centre of mass

285
00:19:59,040 --> 00:20:01,490
so the velocity of the centre of mass

286
00:20:01,510 --> 00:20:04,050
because i divided by

287
00:20:04,100 --> 00:20:06,000
and so i have sold for you

288
00:20:06,050 --> 00:20:07,110
the first part

289
00:20:07,130 --> 00:20:08,620
one of the problems

290
00:20:08,630 --> 00:20:10,570
what is remarkable

291
00:20:10,600 --> 00:20:16,320
that's independent of the the story we call the the it's completely independent of the

292
00:20:16,330 --> 00:20:17,930
when you hit here

293
00:20:17,950 --> 00:20:22,910
with the very same impulse or hit there makes no difference the centre of mass

294
00:20:22,920 --> 00:20:25,810
behaves like a point source vehicles i may

295
00:20:26,720 --> 00:20:28,490
the velocity of the centre of mass

296
00:20:28,530 --> 00:20:30,340
only depends on i

297
00:20:30,350 --> 00:20:35,120
and on the mass of the larger i the larger the velocity that's of course

298
00:20:35,130 --> 00:20:36,390
quite intuitive

299
00:20:36,510 --> 00:20:40,350
and the larger the mass the lower the velocity

300
00:20:40,400 --> 00:20:44,320
but now comes the hardest part and i will leave you largely was the hardest

301
00:20:44,320 --> 00:20:47,050
part but give you a few clothes

302
00:20:47,090 --> 00:20:49,130
because they i want you to calculate

303
00:20:49,160 --> 00:20:52,450
omega about the centre of mass

304
00:20:52,490 --> 00:20:55,990
and now you have to choose an origin because you're dealing with sports

305
00:20:56,110 --> 00:20:58,080
you're dealing with

306
00:20:58,090 --> 00:20:59,920
changing angular momentum

307
00:20:59,940 --> 00:21:04,070
and so you would probably choose CHU origin

308
00:21:04,110 --> 00:21:05,780
and you will say OK

309
00:21:05,780 --> 00:21:08,160
let's think about what the

310
00:21:08,180 --> 00:21:11,190
angular momentum is relative to point c

311
00:21:11,200 --> 00:21:15,280
before the collision after the collision if you call the the collision

312
00:21:15,280 --> 00:21:17,110
what is the story

313
00:21:17,150 --> 00:21:19,830
a relative to point c

314
00:21:19,830 --> 00:21:23,200
well the talk relative to point c

315
00:21:23,270 --> 00:21:25,850
there is here the position vector

316
00:21:27,030 --> 00:21:28,910
of c

317
00:21:28,930 --> 00:21:31,250
and the toilet is are cross have

318
00:21:31,250 --> 00:21:35,960
OK of prime one point is the problem is exactly the in case in case

319
00:21:35,990 --> 00:21:41,340
prime so this is what was in right because he finally signed five weeks prior

320
00:21:41,340 --> 00:21:43,180
to this is value for money for

321
00:21:43,200 --> 00:21:45,510
the convergence of the and how you approach

322
00:21:45,510 --> 00:21:46,480
formerly that

323
00:21:46,490 --> 00:21:49,860
and the kernel can be written as an inner product and you see that in

324
00:21:49,860 --> 00:21:50,790
this case

325
00:21:50,850 --> 00:21:55,890
the he especially chickens it's not really is based on victor is a finite dimensional

326
00:21:56,830 --> 00:22:00,050
of functions that you can do that this is this is one of the basic

327
00:22:00,310 --> 00:22:01,830
that human space no

328
00:22:01,840 --> 00:22:06,730
it case i just like generalisation of euclidean space but actually to infinite dimensions so

329
00:22:06,730 --> 00:22:08,590
here is the infinite dimensional

330
00:22:08,680 --> 00:22:12,250
but for many problems that the converse

331
00:22:12,390 --> 00:22:17,130
now it turns out that the human properties that i want to mention about RKHS

332
00:22:19,520 --> 00:22:23,350
there is an interesting thing that we use the term

333
00:22:23,360 --> 00:22:27,520
four kinds and grass which is that RKHS can be characterized

334
00:22:27,520 --> 00:22:32,100
almost independently from but what is already so if you give me

335
00:22:32,670 --> 00:22:39,070
so there are facilities around gives you a way to change even given hilbert space

336
00:22:39,070 --> 00:22:41,350
of functions and these are just some not

337
00:22:41,360 --> 00:22:45,560
well i can also remember that each of the rest unique RKHS

338
00:22:45,610 --> 00:22:48,380
now suppose me

339
00:22:48,760 --> 00:22:55,880
a function is a function sorry is a space of functions as basis of functions

340
00:22:56,090 --> 00:22:59,180
how can i tell you whether it is the edges of the number of the

341
00:22:59,180 --> 00:23:03,490
camels where there is a simple decision given by the rain

342
00:23:03,500 --> 00:23:04,730
we say that

343
00:23:04,770 --> 00:23:06,310
OK changes

344
00:23:06,370 --> 00:23:08,480
capitalisation can OK

345
00:23:08,530 --> 00:23:13,060
it is in fact the unique about space which satisfies the properties of the first

346
00:23:13,060 --> 00:23:17,630
one is that your page must contain all

347
00:23:17,650 --> 00:23:20,260
functions of the four on the from case

348
00:23:20,270 --> 00:23:23,320
OK so you have to change that as fixed point east was the

349
00:23:25,120 --> 00:23:28,180
which is the fraction of all of this has to be in your space of

350
00:23:28,180 --> 00:23:30,540
functions otherwise it can be the RKHS

351
00:23:30,580 --> 00:23:33,640
and the properties is that you can show that

352
00:23:33,740 --> 00:23:37,910
as the features and function and any point east of the

353
00:23:37,930 --> 00:23:40,000
the property that the sequel

354
00:23:40,000 --> 00:23:42,730
if that's the case

355
00:23:42,740 --> 00:23:48,570
you can change conditions you also turned on your space inside rkhss is associated to

356
00:23:48,570 --> 00:23:49,850
the gap

357
00:23:49,880 --> 00:23:55,170
so this is something we will use later to to deal with is typically in

358
00:23:55,170 --> 00:23:59,030
the space of functions in which show that it is RKHS things to these this

359
00:23:59,030 --> 00:24:03,560
and therefore we have accounts because you can rather than that

360
00:24:03,560 --> 00:24:08,040
we can have important properties and and this is a

361
00:24:08,410 --> 00:24:13,930
i think what you quite easy to to to derive quite important that you might

362
00:24:13,930 --> 00:24:19,380
want to give some intuition of what he how can interpret the number of edges

363
00:24:19,380 --> 00:24:22,850
incident because the number of patients the central and

364
00:24:23,010 --> 00:24:26,300
so what is the number of edges how can you

365
00:24:26,310 --> 00:24:29,490
what can you say about functions with a small number of big now

366
00:24:29,500 --> 00:24:34,050
well there something simple that can support you have an account on the space so

367
00:24:34,050 --> 00:24:40,640
you have space you can OK and together with this kind of RKHS page

368
00:24:40,700 --> 00:24:45,360
now suppose you take any function f in RKHS in any two points

369
00:24:45,380 --> 00:24:47,430
in your space of points

370
00:24:47,440 --> 00:24:51,040
now if you could simply the different

371
00:24:51,050 --> 00:24:53,610
between the values of f on the two point so you have it's in his

372
00:24:53,630 --> 00:24:57,490
prime you compute everything to be prime

373
00:24:57,590 --> 00:25:01,040
the get that you want to estimate how big or small this can be

374
00:25:01,210 --> 00:25:06,900
here you can use a few properties of the occasions to have simple on the

375
00:25:07,380 --> 00:25:11,340
so that by because this RKHS you know that have all these

376
00:25:11,410 --> 00:25:13,700
is equal to the cakes

377
00:25:13,710 --> 00:25:15,040
this was

378
00:25:15,040 --> 00:25:18,890
back to the first one of the properties of each other with equal to the

379
00:25:18,890 --> 00:25:21,770
inner product between cakes

380
00:25:21,790 --> 00:25:23,580
so here you've ever piece

381
00:25:23,600 --> 00:25:30,460
you have been trying to each other the case and the case prime and because

382
00:25:30,480 --> 00:25:35,730
the other is is linear in each argument this is equal to

383
00:25:35,740 --> 00:25:38,740
that's case and the case right

384
00:25:38,750 --> 00:25:42,550
OK i didn't do anything here this is history to what you just said that

385
00:25:43,030 --> 00:25:46,300
function can see in the dark ages

386
00:25:46,310 --> 00:25:49,790
now the location these spaces the product

387
00:25:49,810 --> 00:25:56,570
and like all species within the data usually quite which is called cases filed which

388
00:25:56,570 --> 00:25:57,880
you probably know four

389
00:25:57,910 --> 00:26:02,040
euclidean space is it turns that when you take the inner product between two vectors

390
00:26:02,040 --> 00:26:06,230
the inner product is always smaller than the product of the norms of the victims

391
00:26:06,240 --> 00:26:10,930
OK think of off to the initial victories you know that AWB is one of

392
00:26:10,930 --> 00:26:16,320
the number of times the normal so in fact it is only also also RKHS

393
00:26:16,340 --> 00:26:19,040
just a small businesses

394
00:26:19,340 --> 00:26:23,330
space was enough for that so this is enough for the smaller than the number

395
00:26:23,330 --> 00:26:25,860
of seen as pointed out chess

396
00:26:25,910 --> 00:26:30,920
times the normal k expand case primarily RKHS

397
00:26:31,840 --> 00:26:38,070
so now we because this is something want to be and try understand what is

398
00:26:38,420 --> 00:26:41,940
not RKHS of k explain case prime

399
00:26:41,960 --> 00:26:48,790
one member that's one way to justify their actions say we used are just the

400
00:26:48,790 --> 00:26:49,990
right to say that

401
00:26:50,030 --> 00:26:53,300
in fact this is one of the space

402
00:26:53,310 --> 00:26:59,540
that correspond to matching being twenty two twenty perspectives where the initial space is embedded

403
00:26:59,550 --> 00:27:03,010
i said that when you start from your space itself point

404
00:27:03,020 --> 00:27:05,200
then you can embed each point

405
00:27:05,260 --> 00:27:07,900
east to the function case

406
00:27:07,920 --> 00:27:08,920
and then

407
00:27:08,930 --> 00:27:10,870
the inner product between

408
00:27:10,880 --> 00:27:14,960
o point into the space between functions case in case trying to get people to

409
00:27:14,960 --> 00:27:20,060
the camel so you know when i was thinking about it i think about design

410
00:27:20,070 --> 00:27:21,350
in that

411
00:27:21,380 --> 00:27:26,810
this means that in this picture here are i said that you can imagine space

412
00:27:27,070 --> 00:27:29,160
in the space on the right thing

413
00:27:30,770 --> 00:27:34,230
OK and the point these here is not the case

414
00:27:34,250 --> 00:27:39,120
and now we we what we have now is the norm between the differences so

415
00:27:39,120 --> 00:27:41,860
the knowledge of the difference in case in case prior

416
00:27:41,890 --> 00:27:44,610
so this seems like is exactly the distance

417
00:27:44,630 --> 00:27:48,060
induced the euclidean distance induced by the kernel

418
00:27:48,100 --> 00:27:50,420
OK well mean that

419
00:27:50,600 --> 00:27:51,640
well the

420
00:27:51,740 --> 00:27:56,080
the way to that is to say that can all induces a structure in your

421
00:27:57,040 --> 00:28:01,130
so that's what i think this is all you can you can can not between

422
00:28:01,150 --> 00:28:03,300
two points between two sequences

423
00:28:03,320 --> 00:28:07,460
and this is exactly what you are

424
00:28:07,490 --> 00:28:09,180
the the

425
00:28:09,200 --> 00:28:13,460
this thing which is the norm in the space of the between phi of minus

426
00:28:13,460 --> 00:28:18,290
five is prime so i think the distance between two points

427
00:28:18,290 --> 00:28:21,010
induced by the camera

428
00:28:22,090 --> 00:28:27,240
so if i give you can also use everything gives you directly not between your

429
00:28:27,240 --> 00:28:34,320
initial between points you should focus on sequences and you can sequences anyone non between

430
00:28:34,320 --> 00:28:37,660
sequences which i call the k of prime

431
00:28:37,710 --> 00:28:42,330
it also gives you know weather i conditions not

432
00:28:42,330 --> 00:28:44,860
so now we have which to that

433
00:28:44,880 --> 00:28:47,270
whenever you give me to point six n is prime

434
00:28:47,270 --> 00:28:53,170
well very

435
00:29:04,570 --> 00:29:05,730
it is

436
00:29:14,160 --> 00:29:17,950
right well

437
00:29:17,970 --> 00:29:22,230
right well took a short break against really racial one and then we'll go through

438
00:29:22,270 --> 00:29:26,050
a got the point i want to reach hunting at about five

439
00:29:27,870 --> 00:29:37,620
OK so thanks well that's my internal there's still air version three still so

440
00:29:37,630 --> 00:29:39,970
we had

441
00:29:39,980 --> 00:29:44,970
some fun getting up the slides i don't get the opportunity to schools every year

442
00:29:45,010 --> 00:29:48,620
i don't work in universities at the moment you may have noticed you

443
00:29:48,640 --> 00:29:51,950
two various presenters profiles and things like that

444
00:29:52,830 --> 00:29:55,550
no unless i'm extremely pleased to be here

445
00:29:55,590 --> 00:29:59,340
i hope you'll forgive the occasional rustiness on the slides which i

446
00:29:59,390 --> 00:30:02,510
have presented before that these things always changed little bit

447
00:30:03,170 --> 00:30:04,780
and i might just

448
00:30:04,830 --> 00:30:10,340
just catch on a couple of things i hope not too many things and gets

449
00:30:11,560 --> 00:30:15,090
so anyway this is kind of part two of course the johns already started this

450
00:30:16,220 --> 00:30:20,450
and therefore it's the kind of you once we know what logic is and what

451
00:30:20,450 --> 00:30:21,670
you could do it

452
00:30:21,670 --> 00:30:23,670
here's some stuff that was done with it

453
00:30:23,720 --> 00:30:26,560
actually in the mid nineteen

454
00:30:26,640 --> 00:30:28,770
around the nineteen thirties

455
00:30:29,510 --> 00:30:34,800
which is very strong negative results actually around the usefulness of logic in

456
00:30:34,830 --> 00:30:36,700
carrying forward big program

457
00:30:39,200 --> 00:30:43,890
arithmetic and mathematics generally inside logic that that would be

458
00:30:44,000 --> 00:30:49,170
because process of the program called always program makes that a couple of minutes

459
00:30:50,330 --> 00:30:54,420
that program is still on the way the because of these results everyone has to

460
00:30:54,420 --> 00:30:58,800
train extremely carefully around what happens you died assume originally

461
00:30:59,210 --> 00:31:03,770
it was sort of a piece of hard work and know some of these work

462
00:31:03,860 --> 00:31:08,420
so i called the computability logic and girls remarkable theorem we want be

463
00:31:08,460 --> 00:31:12,610
we'll be heading to that girl theorem things tomorrow i will say what it is

464
00:31:14,850 --> 00:31:16,420
and the course

465
00:31:16,430 --> 00:31:18,990
this is the sort of course instructions

466
00:31:19,070 --> 00:31:23,790
is based on a book by boolos and jeffrey and that's what i've sort of

467
00:31:24,770 --> 00:31:28,640
i mean if i that stuff and to and said things around book

468
00:31:28,650 --> 00:31:29,740
that's just me

469
00:31:29,760 --> 00:31:33,730
but i'm intending to follow the general process of this

470
00:31:33,790 --> 00:31:35,450
quite find text

471
00:31:35,460 --> 00:31:39,080
this is the third edition which was nineteen eighty nine

472
00:31:39,140 --> 00:31:42,770
but in honor of doing this course i went off to amazon

473
00:31:42,820 --> 00:31:44,580
and found the fifth edition

474
00:31:44,640 --> 00:31:47,950
now the new author john burgess as well because sadly

475
00:31:48,050 --> 00:31:49,650
lost jeffrey

476
00:31:49,670 --> 00:31:52,130
passed on so

477
00:31:52,170 --> 00:31:55,770
and when i looked into it i thought oh my god they change the chapters

478
00:31:55,770 --> 00:32:02,020
is moved around the cabinet secretary sir i haven't actually crime taken stuff from this

479
00:32:02,020 --> 00:32:06,260
book exactly if you're looking at after this is not something it's going to

480
00:32:06,390 --> 00:32:10,050
make any difference whatsoever to the course the talking we doing today

481
00:32:10,050 --> 00:32:11,050
but it's

482
00:32:11,050 --> 00:32:14,730
it would make a difference after that if you trying possibly i don't really refer

483
00:32:14,770 --> 00:32:18,110
to page numbers or chapters or anything like that

484
00:32:18,130 --> 00:32:22,170
i've got another book you just show you admin

485
00:32:22,180 --> 00:32:26,830
OK so let's kind of get started and all distract yourself with the slides and

486
00:32:26,830 --> 00:32:28,460
see what they say and

487
00:32:28,480 --> 00:32:29,920
so the right thing

488
00:32:31,210 --> 00:32:34,580
the first part of learning about logic

489
00:32:34,640 --> 00:32:38,860
can be dealing with these sorts of topics i'm not sure john's chosen this particular

490
00:32:38,860 --> 00:32:41,230
selection this year or not because it is

491
00:32:41,290 --> 00:32:43,230
the vast range of topics in

492
00:32:44,390 --> 00:32:46,860
first order logic and predicate logic

493
00:32:46,880 --> 00:32:50,880
and the various metatheorems around those systems

494
00:32:50,900 --> 00:32:53,420
what we're doing is following on from that

495
00:32:54,260 --> 00:32:58,370
being up and this idea of could we reference in some wire embedded in some

496
00:32:59,450 --> 00:33:01,560
ideas of computability

497
00:33:01,580 --> 00:33:04,010
all finite computability

498
00:33:04,010 --> 00:33:07,390
and there was a historical reason for this the people worrying about

499
00:33:08,780 --> 00:33:12,130
so i will be talking about for quite a long time to die

500
00:33:12,140 --> 00:33:13,340
the concept of

501
00:33:13,350 --> 00:33:17,580
expressing in first order logic may be actually a few different ways

502
00:33:17,740 --> 00:33:20,270
the concept of expressing in first order logic

503
00:33:20,280 --> 00:33:22,340
the idea of computing function

504
00:33:22,390 --> 00:33:27,770
or having some sort of definite procedure for evaluating the result of function

505
00:33:27,780 --> 00:33:30,350
there could be a things you want to do pretty similar

506
00:33:30,370 --> 00:33:32,320
it was to speak on that one

507
00:33:32,370 --> 00:33:35,830
then we're hoping to get to today

508
00:33:35,910 --> 00:33:42,350
the first kind of result from our perspective is that this approach may two

509
00:33:42,780 --> 00:33:47,870
a sort of unfair result that first order logic which all set out on

510
00:33:47,900 --> 00:33:51,890
actually there is in the end effective procedure which completely

511
00:33:51,890 --> 00:33:55,470
categorizers every formula is either true

512
00:33:55,490 --> 00:33:57,150
valid or not valid

513
00:33:57,200 --> 00:33:59,200
OK so it's undecidable

514
00:34:00,320 --> 00:34:05,410
semi decidable techniques are things we can do to turn things that our theory is

515
00:34:06,570 --> 00:34:11,880
but we can't apply this tree techniques or variations of

516
00:34:11,910 --> 00:34:14,040
truth tables and things like that

517
00:34:14,070 --> 00:34:18,900
and always hard to get an answer that's really bad so it's pretty interesting that

518
00:34:18,900 --> 00:34:21,690
that's the case and look how that works

519
00:34:23,270 --> 00:34:24,700
we're looking at

520
00:34:24,700 --> 00:34:29,010
particular sort of computing notion partial recursive functions

521
00:34:29,020 --> 00:34:32,580
and we'll see by sort of amount kind of computer

522
00:34:32,640 --> 00:34:36,080
and then we'll jump school here

523
00:34:36,080 --> 00:34:36,970
OK so

524
00:34:36,990 --> 00:34:39,630
sort of saying this stuff again one

525
00:34:39,640 --> 00:34:42,700
give this a go through this page in detail

526
00:34:42,710 --> 00:34:44,630
so here's the a whole of topics which

527
00:34:44,640 --> 00:34:46,260
well skip through

528
00:34:46,310 --> 00:34:50,490
and some of them and go into a bit more detail than others

529
00:34:50,530 --> 00:34:53,970
usually my choice and going into a little bit more detail

530
00:34:54,010 --> 00:34:58,690
it is not necessary that it's actually key because i think it might just

531
00:34:58,740 --> 00:35:04,220
show you the idea of the style of reasoning people use in this particular disc

532
00:35:04,240 --> 00:35:05,970
in this field

533
00:35:06,010 --> 00:35:10,270
OK so it certainly simple enough to present in a few short hours

534
00:35:10,270 --> 00:35:14,120
but it's sort of follows the style i think which is then used to make

535
00:35:15,000 --> 00:35:18,990
so no way how do i set myself the goal of trying to

536
00:35:19,020 --> 00:35:22,030
come up with any halfway decent proof of

537
00:35:22,080 --> 00:35:25,200
the theorem is the main theorems in this in this area

538
00:35:25,320 --> 00:35:29,960
but i will point to them and will say these techniques these strategies

539
00:35:29,990 --> 00:35:32,570
this is the body of knowledge which have to build up

540
00:35:32,600 --> 00:35:35,060
and so on

541
00:35:36,190 --> 00:35:39,510
i put in the page just showing you some books that

542
00:35:39,590 --> 00:35:44,240
so that we would use so there is that

543
00:35:44,280 --> 00:35:46,740
book by boolos and jeffrey

544
00:35:47,440 --> 00:35:49,660
at the bottom there outside the top there

545
00:35:49,690 --> 00:35:52,640
and if you that that i thought that there are lots and lots and lots

546
00:35:52,640 --> 00:35:54,270
and lots of books OK

547
00:35:54,270 --> 00:35:58,250
a book that sort of just kind of came to my attention again

548
00:35:58,260 --> 00:36:00,560
in the last few months because i was

549
00:36:00,600 --> 00:36:02,060
preparing for this course

550
00:36:02,070 --> 00:36:03,470
like last year

551
00:36:03,520 --> 00:36:06,650
thing about it and found sky in cambridge

552
00:36:06,660 --> 00:36:08,540
and these are not semester course

553
00:36:08,560 --> 00:36:13,690
on girls there and he's got his book an introduction to girls their

554
00:36:13,740 --> 00:36:17,320
absolutely underlines inputs involved in emphasizes

555
00:36:17,350 --> 00:36:20,940
so we could hope to get through always results in a few hours

556
00:36:20,990 --> 00:36:24,240
but certainly i would recommend this kind

557
00:36:24,310 --> 00:36:27,520
what i would do is leave these books here in the right if you just

558
00:36:27,520 --> 00:36:30,890
want to house and someone else have a look at them

559
00:36:30,940 --> 00:36:35,220
of the counting in checking bags they can that place

560
00:36:35,250 --> 00:36:37,890
feel free to have a look at them now flick through the

561
00:36:39,500 --> 00:36:42,200
later on you know then you know what to look for in the library or

562
00:36:42,200 --> 00:36:45,880
something like that as a few other books there some of these are pretty all

563
00:36:45,880 --> 00:36:50,650
this lot anyway you guys in this anymore right you go to wikipedia

564
00:36:50,650 --> 00:36:55,530
the samples here in training get point two three going to a small

565
00:36:57,950 --> 00:36:59,920
well i tested

566
00:36:59,970 --> 00:37:03,550
these new samples i get point three eight hundred rather worse so i thought i

567
00:37:03,550 --> 00:37:06,030
was doing so it's illustrative there

568
00:37:07,620 --> 00:37:09,180
this this fact that

569
00:37:10,460 --> 00:37:13,710
it's not unsurprising that you get very small

570
00:37:13,720 --> 00:37:16,320
the training set errors because

571
00:37:16,340 --> 00:37:20,240
what you're trying to do is minimized the the training set error

572
00:37:20,280 --> 00:37:25,500
self-fulfilling prophecy really so the only thing you're interested in is the what we call

573
00:37:25,500 --> 00:37:27,090
the out of sample error

574
00:37:27,140 --> 00:37:28,780
OK that is the

575
00:37:28,820 --> 00:37:32,400
these these new points these on previously unseen point

576
00:37:32,450 --> 00:37:34,340
and doing rather poorly

577
00:37:37,880 --> 00:37:43,370
however what we've got is a scheme which allows allows us to work blind

578
00:37:43,380 --> 00:37:48,010
OK because whilst we can still see things i do that for

579
00:37:48,010 --> 00:37:51,730
obvious reasons given presentation

580
00:37:51,880 --> 00:37:54,990
you can still do that now without

581
00:37:56,000 --> 00:37:56,780
to c

582
00:37:56,790 --> 00:37:58,080
the pictures

583
00:37:58,130 --> 00:37:59,760
OK just purely

584
00:37:59,760 --> 00:38:02,990
computational things that you can compute

585
00:38:03,060 --> 00:38:06,810
so that's one way of going forward it's still widely used by lots of people

586
00:38:06,810 --> 00:38:08,110
in applications

587
00:38:08,140 --> 00:38:12,450
OK so we hold out a small part of a percentage p percent

588
00:38:15,140 --> 00:38:16,870
we have to make those choices

589
00:38:17,680 --> 00:38:22,600
it's very wasteful because you only get

590
00:38:22,650 --> 00:38:26,320
one minus paper so hundred minus p percent

591
00:38:26,370 --> 00:38:27,770
for training

592
00:38:27,800 --> 00:38:29,320
your sample

593
00:38:29,600 --> 00:38:32,210
using all of the data you possibly can

594
00:38:32,440 --> 00:38:34,170
so that might

595
00:38:36,000 --> 00:38:38,650
finally the quality of the final estimate

596
00:38:40,280 --> 00:38:44,650
it's sample dependent if i were to choose a different five to train

597
00:38:44,650 --> 00:38:47,500
the different five to test i get

598
00:38:47,570 --> 00:38:49,230
a different answer

599
00:38:50,110 --> 00:38:52,270
five ten million data points

600
00:38:52,360 --> 00:38:56,130
and i chose half-and-half differently it would make much difference

601
00:38:57,070 --> 00:38:58,230
we have to think

602
00:38:58,270 --> 00:38:59,150
it in

603
00:38:59,170 --> 00:39:03,400
the kinds of problems will likely to be looking at we will not have

604
00:39:03,460 --> 00:39:04,840
a lot of data

605
00:39:04,940 --> 00:39:06,690
have a little data

606
00:39:06,750 --> 00:39:11,400
in some sense

607
00:39:11,460 --> 00:39:14,170
a better way forward

608
00:39:14,170 --> 00:39:17,500
in terms of using making use of your data

609
00:39:17,500 --> 00:39:18,440
comes through

610
00:39:18,460 --> 00:39:20,670
cross validation

611
00:39:20,670 --> 00:39:21,880
and the most

612
00:39:23,500 --> 00:39:29,820
discussed version of this is called the leave one out cross validation strategy

613
00:39:29,820 --> 00:39:32,650
which says you train

614
00:39:33,860 --> 00:39:37,420
estimator on every

615
00:39:37,420 --> 00:39:39,820
sample except for one

616
00:39:39,920 --> 00:39:41,670
you leave out

617
00:39:41,710 --> 00:39:43,690
as in the hold out case

618
00:39:43,730 --> 00:39:46,880
and then you put it back in taking another one

619
00:39:46,880 --> 00:39:49,110
and you train all again

620
00:39:49,150 --> 00:39:51,440
eight stage you test

621
00:39:53,050 --> 00:39:54,590
trained estimator

622
00:39:54,650 --> 00:39:57,480
gather up all that information

623
00:39:57,480 --> 00:39:59,130
OK by doing it

624
00:39:59,150 --> 00:40:00,960
n times

625
00:40:00,980 --> 00:40:03,590
you compute your a performance measure

626
00:40:06,570 --> 00:40:08,210
it's a very simple idea

627
00:40:08,300 --> 00:40:13,840
course you've got to train n estimators which might

628
00:40:13,860 --> 00:40:16,250
in carolina work

629
00:40:16,300 --> 00:40:19,670
in the specific case of sum of squares

630
00:40:19,670 --> 00:40:23,500
with linear in the parameter models you can actually do the whole thing

631
00:40:25,920 --> 00:40:29,210
i matrix manipulation which is no worse

632
00:40:29,230 --> 00:40:30,800
then the

633
00:40:31,150 --> 00:40:35,020
conventional pseudoinverse

634
00:40:36,320 --> 00:40:39,340
OK but there's a very special situation

635
00:40:40,210 --> 00:40:42,420
so for instance you can do this

636
00:40:42,420 --> 00:40:47,020
many times with different values of the regularisation parameter rho

637
00:40:47,070 --> 00:40:49,460
and choose

638
00:40:49,480 --> 00:40:53,690
rho which corresponds to the best

639
00:40:53,710 --> 00:40:57,190
the value of your

640
00:40:57,250 --> 00:40:58,460
performance measure

641
00:40:58,460 --> 00:41:01,170
but you've done over your cross validation

642
00:41:04,340 --> 00:41:05,590
something that is

643
00:41:06,880 --> 00:41:08,630
more frequently use now

644
00:41:08,630 --> 00:41:12,130
is m fold many fold cross validation

645
00:41:12,190 --> 00:41:16,750
where you do the same sort of thing except you divide your sample up into

646
00:41:18,460 --> 00:41:22,860
m is an integer obviously non overlapping sets

647
00:41:22,920 --> 00:41:27,050
OK you proceed as above so you take out one of these sets

648
00:41:27,110 --> 00:41:28,750
we train

649
00:41:28,860 --> 00:41:33,340
estimator you test it using the set that you've removed

650
00:41:33,360 --> 00:41:35,630
when you put that setback in

651
00:41:35,690 --> 00:41:39,070
take another set and do this

652
00:41:39,090 --> 00:41:43,500
the advantage of these techniques is that all of the data gets used for training

653
00:41:43,500 --> 00:41:45,840
and testing

654
00:41:46,920 --> 00:41:53,280
it's obviously a lot more work

655
00:41:53,320 --> 00:41:57,400
ten fold cross validation strategy you have to do m

656
00:41:57,440 --> 00:41:59,860
lots of training

657
00:41:59,900 --> 00:42:03,190
in the one you do and lots of training

658
00:42:03,320 --> 00:42:10,360
but what you get is much closer estimate of the the so-called generalization error

659
00:42:13,190 --> 00:42:14,900
more loosely just

660
00:42:14,980 --> 00:42:19,050
performance has going to perform in the real world as opposed to how it performs

661
00:42:19,780 --> 00:42:21,770
the data used to train

662
00:42:22,550 --> 00:42:31,800
and we use it very often to to choose these hyperparameters here my hyperparameter itself

663
00:42:31,800 --> 00:42:37,040
is rho but you could use it for tuning the width of your radial basis

664
00:42:37,040 --> 00:42:39,400
functions off for finding the

665
00:42:39,400 --> 00:42:41,190
degree of your polynomial

666
00:42:42,300 --> 00:42:43,730
or some other

667
00:42:43,770 --> 00:42:48,170
parameter that exists within approach

668
00:42:48,170 --> 00:42:49,630
the number of

669
00:42:49,630 --> 00:42:51,900
basis functions etcetera

670
00:42:51,920 --> 00:42:53,500
so that's what

671
00:42:53,610 --> 00:42:56,270
his another

672
00:42:56,270 --> 00:43:01,050
the powerpoint wizardry case just to put that into pictures

673
00:43:01,130 --> 00:43:05,860
cuisine we've got all the training data the x's and the z

674
00:43:05,860 --> 00:43:08,300
and there's ads can be multidimensional

675
00:43:08,440 --> 00:43:10,520
we typically talk about

676
00:43:11,860 --> 00:43:15,340
target but we could have multidimensional target

677
00:43:15,380 --> 00:43:19,630
we break them up in this case the five fold cross validation strategy so we

678
00:43:19,630 --> 00:43:22,380
break them up into five non overlapping

679
00:43:23,940 --> 00:43:27,440
labelled an obvious way

680
00:43:27,550 --> 00:43:31,070
OK so i'm going to look at the fourth stage of this process so we've

681
00:43:31,070 --> 00:43:33,630
already been through we've taken

682
00:43:33,690 --> 00:43:36,090
x y and z one

683
00:43:36,960 --> 00:43:41,920
our estimator produced the outputs from the estimator that's why one

684
00:43:41,960 --> 00:43:43,520
we've done that all the way up to the

685
00:43:43,520 --> 00:43:45,490
so in that situation

686
00:43:45,510 --> 00:43:49,290
it just means that will even if you use the really fancy model

687
00:43:49,340 --> 00:43:52,070
you wouldn't be able to separate things

688
00:43:52,150 --> 00:43:55,330
but since you only have a finite amount of data

689
00:43:55,340 --> 00:43:59,050
it's very hard to tell whether you here of there

690
00:43:59,130 --> 00:44:02,440
in some ways how when you plot the learning curve since on at least for

691
00:44:02,680 --> 00:44:05,800
a given model class tell which is you are

692
00:44:05,810 --> 00:44:11,820
but overall it's really hard

693
00:44:11,870 --> 00:44:13,800
here's an example well

694
00:44:13,840 --> 00:44:19,610
well clear nice several align will not be able to separate right from green

695
00:44:19,700 --> 00:44:21,580
the so called because of problem

696
00:44:21,630 --> 00:44:23,440
if you ever hear of that

697
00:44:23,520 --> 00:44:24,740
this is what it is

698
00:44:24,760 --> 00:44:28,860
if an algorithm argues it's good because it can solve the exact problem

699
00:44:30,020 --> 00:44:32,720
don't read that paper

700
00:44:34,340 --> 00:44:37,030
is a really simple implementation of this

701
00:44:37,080 --> 00:44:39,400
not saying this is efficient anything

702
00:44:39,410 --> 00:44:42,800
all this does is it just computes the product

703
00:44:42,800 --> 00:44:44,450
if the sign is wrong

704
00:44:44,560 --> 00:44:47,260
update things otherwise did nothing

705
00:44:47,420 --> 00:44:54,320
perceptron if offline suffices

706
00:44:54,370 --> 00:44:56,600
with any questions here

707
00:45:04,980 --> 00:45:07,300
if you keep on living through about

708
00:45:07,610 --> 00:45:09,320
it'll just average

709
00:45:09,440 --> 00:45:13,310
so there is actually a wonderful example of where this happened in reality

710
00:45:15,140 --> 00:45:20,110
has anybody of you played the game black-and-white at some point

711
00:45:21,780 --> 00:45:25,700
so you've probably noticed that at some point it gets really hard to

712
00:45:25,720 --> 00:45:28,350
deal with the avatar

713
00:45:28,750 --> 00:45:33,320
and the avatar just starts doing weird things and you cannot be controlled it anymore

714
00:45:33,330 --> 00:45:34,910
is exactly what happened

715
00:45:35,870 --> 00:45:39,040
OK i need to explain people black and white this so is a game where

716
00:45:39,040 --> 00:45:43,440
you play called and you need to get the adoration of people

717
00:45:43,480 --> 00:45:48,840
and amongst other things you have some avatar which happens to be among european or

718
00:45:49,020 --> 00:45:53,990
line or some other piece which will do things trying to mimic you can rewarded

719
00:45:54,040 --> 00:45:55,820
can punish it and so on

720
00:45:55,870 --> 00:45:58,170
and overall the idea is you

721
00:45:58,200 --> 00:46:02,050
train this avatar to do things on your behalf

722
00:46:04,260 --> 00:46:05,580
the people who

723
00:46:05,690 --> 00:46:08,790
built this data set up a machine learning is really cool

724
00:46:08,850 --> 00:46:14,040
so let us use a really kick-ass machine learning algorithm namely the perceptron

725
00:46:16,120 --> 00:46:18,040
and so i thought you know

726
00:46:18,050 --> 00:46:23,120
given all the environmental conditions if the creator does something that is not supposed to

727
00:46:23,150 --> 00:46:29,230
the new planetary reward it you would just to an update like these life

728
00:46:30,420 --> 00:46:35,760
and trouble is that maybe during different stages in the game player may because they

729
00:46:35,760 --> 00:46:39,320
are not terribly consistent you actually might end up

730
00:46:39,320 --> 00:46:45,140
not closing a fully separable problems maybe because the parameterisation is insufficient

731
00:46:45,260 --> 00:46:48,690
so what happened is that the way to make just keeps on increasing

732
00:46:48,950 --> 00:46:50,970
so always keep on updating

733
00:46:50,990 --> 00:46:54,910
so things just average in the end which means that at that point three much

734
00:46:54,910 --> 00:46:56,370
no matter what you do

735
00:46:56,430 --> 00:46:59,610
the beast is not going to change is be a very much anymore

736
00:46:59,620 --> 00:47:02,630
essentially what they did not include is the learning rate

737
00:47:02,730 --> 00:47:07,090
and what they did not include the is anyway decaying regularisation

738
00:47:07,150 --> 00:47:11,690
so to ensure that the parameter range doesn't really completely go a bar

739
00:47:11,700 --> 00:47:15,880
they had included is the fact that would have been a lot more playable

740
00:47:16,080 --> 00:47:22,040
is simple example where about machine learning algorithm can actually win the game

741
00:47:23,490 --> 00:47:27,920
so how do we make things separately even if they shouldn't be

742
00:47:30,040 --> 00:47:33,020
the problem is linear functions often really boring so

743
00:47:33,030 --> 00:47:35,190
well how can we get non linear

744
00:47:35,260 --> 00:47:39,990
i could for instance go and map x into for fixed in some feature maps

745
00:47:40,110 --> 00:47:42,300
i solve the problem

746
00:47:42,320 --> 00:47:45,090
so this will be actually very easy all have to do is just the query

747
00:47:46,080 --> 00:47:50,670
of in it for the next next framework of the project

748
00:47:50,690 --> 00:47:53,430
this works really well the principal documents

749
00:47:53,440 --> 00:47:57,370
quite often it doesn't make much sense to go beyond bi grandson tri grams

750
00:47:57,390 --> 00:47:59,170
so you might actually be able to

751
00:47:59,180 --> 00:48:02,530
code but that out explicitly

752
00:48:02,560 --> 00:48:07,310
now what have we gained well all the sun now we have non linear classifiers

753
00:48:07,320 --> 00:48:08,490
the solution just

754
00:48:08,500 --> 00:48:12,540
depends on what type of exam picking

755
00:48:12,690 --> 00:48:15,050
here's a simple example

756
00:48:15,050 --> 00:48:23,450
four that have had forced to close of the rest of this is that we

757
00:48:23,600 --> 00:48:27,550
one us to die in the US

758
00:48:30,050 --> 00:48:35,290
well as that i have got to come up with this for the particular case

759
00:48:35,300 --> 00:48:36,670
so i

760
00:48:37,050 --> 00:48:40,390
and very strong position

761
00:48:41,260 --> 00:48:44,720
stop this information to

762
00:48:44,890 --> 00:48:47,270
and this is where

763
00:48:47,290 --> 00:48:54,270
it is typical for this kind of innovation that's what i like because i know

764
00:48:56,080 --> 00:48:58,460
so first

765
00:49:52,880 --> 00:49:56,480
he is

766
00:49:56,660 --> 00:50:14,790
there seems to be you know the of business and does not hold is about

767
00:50:16,350 --> 00:50:20,670
the station to this stored that causes should be

768
00:50:23,580 --> 00:50:32,870
what we might

769
00:50:33,040 --> 00:50:43,170
distribution over the last

770
00:50:45,260 --> 00:50:48,750
of course of

771
00:50:49,430 --> 00:50:51,060
she would

772
00:50:52,270 --> 00:50:54,590
the above all

773
00:50:54,640 --> 00:50:57,980
well i think about what i was told us not to do

774
00:50:58,000 --> 00:51:00,670
but contrary to what is now

775
00:51:02,100 --> 00:51:03,460
the part the

776
00:51:03,630 --> 00:51:07,590
church and all could come into nothing more

777
00:51:13,980 --> 00:51:18,690
the one concept because process from scope in some way

778
00:51:18,710 --> 00:51:19,790
put within by

779
00:51:19,800 --> 00:51:23,800
cooperation against according to which what i want understand how

780
00:51:23,830 --> 00:51:25,840
but is it the

781
00:51:25,890 --> 00:51:29,420
and i just want to come what is the what

782
00:51:29,430 --> 00:51:33,210
what will show

783
00:51:33,590 --> 00:51:36,160
vision simulcast below

784
00:51:36,170 --> 00:51:42,380
thank you for listening to belonging to

785
00:51:44,540 --> 00:51:50,180
traditional what has to be critical soccer would get with the kind of media attention

786
00:51:50,180 --> 00:51:53,130
forces from the republic in one of the two of them

787
00:51:53,180 --> 00:51:55,130
second without cash from

788
00:51:55,140 --> 00:51:57,260
the introduction

789
00:51:57,390 --> 00:52:01,970
a book in which a somewhat remarkable common characters

790
00:52:02,010 --> 00:52:04,510
could it could be called to one

791
00:52:05,420 --> 00:52:08,920
the talk and it was could around because you can trust

792
00:52:08,930 --> 00:52:14,090
OK this is not a good thing we only report was one of them

793
00:52:14,090 --> 00:52:18,260
it's impossible to be sure that because the question what about all of the above

794
00:52:18,260 --> 00:52:19,540
does not

795
00:52:19,600 --> 00:52:22,190
so this is not

796
00:52:22,220 --> 00:52:24,340
what is the point

797
00:52:24,420 --> 00:52:27,920
but in china just responsible computer

798
00:52:27,930 --> 00:52:30,390
the initial proposal was

799
00:52:32,020 --> 00:52:34,660
experts have also put down

800
00:52:34,770 --> 00:52:43,470
but much longer companies and support for the rules regarding the current parameter so one

801
00:52:43,470 --> 00:52:45,330
of the things support

802
00:52:45,360 --> 00:52:51,850
and then you should be sure that you to put all those

803
00:52:54,220 --> 00:53:00,050
what we do

804
00:53:00,090 --> 00:53:04,810
but i thought it was to because support trust this

805
00:53:04,840 --> 00:53:11,630
just so that you can make it could the learn about the exorcist because the

806
00:53:11,630 --> 00:53:16,730
programs to get some the structure is not just the result of the compiler is

807
00:53:16,790 --> 00:53:18,450
is that it was

808
00:53:18,460 --> 00:53:20,260
this is the just the

809
00:53:20,270 --> 00:53:24,980
the reason for the block problem some because it is so

810
00:53:26,380 --> 00:53:32,190
it was intimately connected with one or two possible progress was a political practical similar

811
00:53:32,220 --> 00:53:36,910
in shape to the world it is that would have

812
00:53:46,300 --> 00:53:47,970
this point

813
00:53:48,130 --> 00:53:50,670
OK well before the occupant attraction

814
00:53:50,680 --> 00:53:54,590
the british monarch it's same

815
00:53:54,660 --> 00:54:01,580
they thought it was interesting to watch competition for that it was performed in

816
00:54:01,730 --> 00:54:08,050
so to start with a simple parental forces could also simple from to

817
00:54:09,330 --> 00:54:15,220
the probability of being caught one more drive to windows and elsewhere

818
00:54:15,300 --> 00:54:17,120
well spotted

819
00:54:17,130 --> 00:54:20,020
it was intended to respond to integer

820
00:54:20,050 --> 00:54:21,840
you might not

821
00:54:21,850 --> 00:54:27,140
well also because it was like going to the reference point is

822
00:54:27,180 --> 00:54:33,340
this is the direction of the talk about it will come up with a lot

823
00:54:33,340 --> 00:54:39,000
about what i wanted to make the combined in the coat thickness what about the

824
00:54:39,010 --> 00:54:42,910
the people who come because need the balance

825
00:54:44,870 --> 00:54:47,480
which in one of the books one

826
00:54:47,500 --> 00:54:58,380
two of the on the twenty three

827
00:54:59,890 --> 00:55:03,590
to the next

828
00:55:18,920 --> 00:55:20,590
so those

829
00:55:21,300 --> 00:55:22,430
i mean

830
00:55:23,850 --> 00:55:25,290
he goes

831
00:55:25,290 --> 00:55:31,110
i mean we're are inputs are unordered sets of features in this will provide us

832
00:55:31,220 --> 00:55:35,670
this kernel talk about provides the weighted very efficiently compare them in terms of their

833
00:55:39,500 --> 00:55:43,610
when we're learning something from an image of course you have to choose the representation

834
00:55:43,620 --> 00:55:46,880
and one way would be to look at the image of the whole and former

835
00:55:46,890 --> 00:55:51,820
global representation so a single vector for every image that might be something as simple

836
00:55:51,880 --> 00:55:57,280
stacking up the pixels in every image or computing the color histograms on

837
00:55:57,300 --> 00:56:02,070
and in cases where you have some nicely aligned images such as these this will

838
00:56:02,070 --> 00:56:03,640
give you a meaningful

839
00:56:04,170 --> 00:56:10,850
description these images however we have real world real world scenarios where we have variation

840
00:56:10,850 --> 00:56:12,880
in object pose or

841
00:56:12,900 --> 00:56:19,520
changes in illumination and significant inclusion in clutter things like this the global representation is

842
00:56:19,520 --> 00:56:21,820
known to break down

843
00:56:22,470 --> 00:56:24,080
more recently

844
00:56:24,090 --> 00:56:30,120
researchers in the vision community are exploring local feature representations we decompose each image into

845
00:56:30,120 --> 00:56:34,660
some number of parts are local patch region features

846
00:56:34,680 --> 00:56:37,680
and then describe it in terms of that set

847
00:56:37,690 --> 00:56:41,190
and so a lot of work has been done to develop salient interest operators where

848
00:56:41,190 --> 00:56:45,190
you find some salient points of interest in image and then each of those points

849
00:56:45,190 --> 00:56:47,050
extract the descriptor

850
00:56:47,070 --> 00:56:51,430
and some nice descriptors have been developed that will give you variance too part of

851
00:56:51,570 --> 00:56:56,610
transformations such as rotations scaling translation and so on

852
00:56:56,620 --> 00:57:02,920
so now reason for this set representation where we have very numbers of features percent

853
00:57:02,930 --> 00:57:08,340
because each image will detect the different number of points potentially and there's no order

854
00:57:08,340 --> 00:57:10,640
among those features

855
00:57:10,680 --> 00:57:14,910
so it's common representation in fact in vision

856
00:57:14,920 --> 00:57:21,570
we have already mentioned these intercepted operators an invariant descriptor also for representing shapes you

857
00:57:21,570 --> 00:57:27,030
can consider two d contours in terms of local shape descriptors one example of the

858
00:57:27,040 --> 00:57:31,480
shape context histogram which is like pulling jamie find each

859
00:57:31,500 --> 00:57:38,860
contour point that counts up where the local counter points of that player following

860
00:57:38,880 --> 00:57:42,350
and thinking of even higher level features we could have a set of features that

861
00:57:42,350 --> 00:57:46,430
was representing a single object class or single object

862
00:57:46,450 --> 00:57:50,100
so for face recognition maybe we want to have this set b examples of a

863
00:57:50,100 --> 00:57:54,130
person's face under different viewing conditions in that way we could cover the space of

864
00:57:54,160 --> 00:57:59,330
how they want to appear in terms of facial expression or illumination things like that

865
00:57:59,830 --> 00:58:03,990
and what we really focused on vision problems it's interesting to think of some other

866
00:58:03,990 --> 00:58:08,380
scenarios where you also have set of features say looking in gene expression data we

867
00:58:08,380 --> 00:58:09,850
have sets of

868
00:58:09,960 --> 00:58:12,820
data from different nations

869
00:58:13,790 --> 00:58:18,240
in text processing we consider a document quite often as a bag of words again

870
00:58:18,320 --> 00:58:20,480
on orders

871
00:58:21,120 --> 00:58:22,750
even if you want to

872
00:58:22,770 --> 00:58:24,980
potentially analyse code

873
00:58:25,190 --> 00:58:27,260
for optimizing compilers

874
00:58:27,270 --> 00:58:32,410
you could consider each method in terms of a set of instructions

875
00:58:32,460 --> 00:58:37,650
so it's quite relevant tation we're most interested in some vision applications where we'd like

876
00:58:37,650 --> 00:58:40,080
to use these local features

877
00:58:40,090 --> 00:58:43,100
so now in this work well we're going to do is propose the kernel that

878
00:58:43,100 --> 00:58:47,060
will let us efficiently compare the sets and then

879
00:58:47,100 --> 00:58:51,100
with the hope that we can plug into these existing kernel methods and do all

880
00:58:51,100 --> 00:58:53,710
kinds of interesting things such as image retrieval or

881
00:58:53,740 --> 00:59:01,240
regression for parameter inference about an object or recognition of classes

882
00:59:01,290 --> 00:59:05,850
and some previous work has been done to develop some kernels for sets

883
00:59:05,870 --> 00:59:10,700
the standard for the different sort of categories these approaches can be described as those

884
00:59:10,700 --> 00:59:16,680
that look for the model to fit to each that typically parametric distribution and then

885
00:59:16,680 --> 00:59:22,470
compare those distributions within existing distance such as KL divergence

886
00:59:22,480 --> 00:59:26,790
and these are nice and that you are allowed to have an order among features

887
00:59:26,790 --> 00:59:30,500
and they can vary in size but they do have the restriction potentially that you

888
00:59:30,500 --> 00:59:34,210
need to choose that distribution no that's a good fit for data that is that

889
00:59:34,360 --> 00:59:38,840
large enough to make a meaningful estimate of those parameters

890
00:59:38,860 --> 00:59:43,710
another general type approaches to look at the pairwise similarity between all the features into

891
00:59:43,710 --> 00:59:48,040
sets and then take some weighted combination of those scores

892
00:59:48,070 --> 00:59:50,840
to be the overall similarity

893
00:59:50,850 --> 00:59:54,170
and here it's model for example approach however

894
00:59:54,330 --> 01:00:00,130
you if you're allowing feature ones that map to multiple features in another you've lost

895
01:00:00,130 --> 01:00:04,280
the description of the distribution of features of the whole

896
01:00:04,290 --> 01:00:06,990
and also with most of these methods

897
01:00:07,000 --> 01:00:10,500
really the complexity of the issue and it comes into play especially when we have

898
01:00:10,500 --> 01:00:13,850
these images with easily thousands features

899
01:00:13,890 --> 01:00:15,380
and so

900
01:00:15,390 --> 01:00:19,310
typically these methods will take quadratically in cubic time in the number of features and

901
01:00:19,310 --> 01:00:24,720
this is detrimental in practice for object recognition when we want to handle images about

902
01:00:24,720 --> 01:00:29,370
the features and lots of images

903
01:00:29,940 --> 01:00:34,640
we like to compare sets of features in terms of partial matching

904
01:00:34,650 --> 01:00:39,610
which means we want to take two sets and find correspondence between some subset

905
01:00:39,620 --> 01:00:41,730
from each of those sets

906
01:00:41,780 --> 01:00:48,040
so what we're hearing how this correspondence would be useful for morphing between similar objects

907
01:00:48,040 --> 01:00:53,480
use here we're going to use the measure of correspondence to say how similar objects

908
01:00:53,480 --> 01:00:55,050
might be

909
01:00:55,070 --> 01:01:00,190
and so the pattern matching were taken set of target features a set of observed

910
01:01:00,190 --> 01:01:04,480
features and find the best way to map some subset of have observed features to

911
01:01:04,480 --> 01:01:09,610
that target or if you can assume you have a threshold on how similar point

912
01:01:09,610 --> 01:01:15,540
you're going to match must be then you can imagine a subset from each set

913
01:01:15,560 --> 01:01:16,580
in vision

914
01:01:16,600 --> 01:01:21,710
when we're dealing with images ignoring these extra features without any penalty to the similarity

915
01:01:21,710 --> 01:01:25,470
score is very useful because this is what allows us to ignore

916
01:01:25,510 --> 01:01:33,930
explicitly the background changes are clutter and segmentation errors that occur in images

917
01:01:34,680 --> 01:01:38,050
now at all partial matching which would maximise the similarity

918
01:01:38,070 --> 01:01:39,630
between them as points

919
01:01:39,640 --> 01:01:40,770
is expensive

920
01:01:40,780 --> 01:01:44,950
so here representing this pyramid match kernel that will allow us to do this very

921
01:01:46,740 --> 01:01:51,210
so we have these two sets that going to match remember each point here is

922
01:01:51,210 --> 01:01:55,030
depicting some d dimensional vector descriptor

923
01:01:55,200 --> 01:01:59,660
such as the SIFT descriptor for familiar

924
01:01:59,670 --> 01:02:04,650
so the basic idea of the pyramid match is two four multiresolution pyramid over these

925
01:02:04,660 --> 01:02:06,200
features that

926
01:02:06,210 --> 01:02:11,690
and then walk through these pyramids using a weighted intersection measure to count matches and

927
01:02:11,700 --> 01:02:14,530
in this way approximate overall similarity

928
01:02:14,540 --> 01:02:19,600
about optimal partial matching

929
01:02:19,640 --> 01:02:24,730
and the way we use histogram pyramids to get a measure of correspondence is by

930
01:02:24,730 --> 01:02:30,460
looking for matches from fine to course levels in the histograms

931
01:02:31,040 --> 01:02:37,340
if we consider the spectrum of resolution levels in this histogram over the feature space

932
01:02:37,340 --> 01:02:41,570
process that is able to take a small graph adjacency matrix and the like

933
01:02:42,560 --> 01:02:46,560
in the sense that to get the adjacency matrices

934
01:02:46,570 --> 01:02:52,400
nice nice structure and what the result is that these is on alaska scale fits

935
01:02:52,400 --> 01:02:56,120
networks were so such a process of networks

936
01:02:56,300 --> 01:03:00,870
very important is on a global scale of millions of nodes below thirty

937
01:03:02,830 --> 01:03:06,770
so that's the first one hundred forty one and we can do

938
01:03:06,800 --> 01:03:11,640
the second part is about diffusion and cascades so what i mean here is about

939
01:03:11,640 --> 01:03:16,880
the processes that spread that it's so for example the first question is how does

940
01:03:16,880 --> 01:03:18,660
information propagate

941
01:03:18,710 --> 01:03:23,070
and what i'm showing you can actually his a picture from the paper and presented

942
01:03:23,070 --> 01:03:27,950
on tuesday and it's about automatically in one of the

943
01:03:27,960 --> 01:03:32,240
so here you get one million blog posts per day

944
01:03:32,780 --> 01:03:38,760
this is over the three months ago when it was basically the US presidential campaign

945
01:03:38,830 --> 01:03:42,740
and with this is automatically generated and you can for example be nice to see

946
01:03:42,780 --> 01:03:45,430
what people talking on each day

947
01:03:45,510 --> 01:03:50,070
what the most popular phrases on the web today and for example you can see

948
01:03:50,120 --> 01:03:53,030
lipstick on a pig and things like that times by

949
01:03:54,710 --> 01:03:56,190
the interesting thing is that

950
01:03:56,200 --> 01:03:57,970
the overall volume

951
01:03:57,990 --> 01:04:02,450
of people talking is about constant over time but still you get this huge spikes

952
01:04:02,450 --> 01:04:04,740
of activity when sort of the whole

953
01:04:04,750 --> 01:04:05,440
the whole

954
01:04:05,450 --> 01:04:09,830
that's whole system concentrates on particular topics of particle phrases

955
01:04:09,860 --> 01:04:13,310
so as i have as i can see things like that then i can ask

956
01:04:13,310 --> 01:04:16,860
what how should i think about what is a model and for example it turns

957
01:04:16,860 --> 01:04:21,570
out that such a topical burstiness can be nice thought of as a random walk

958
01:04:21,580 --> 01:04:25,260
in the light and basically develop among the people of zero crossing model that can

959
01:04:25,260 --> 01:04:31,720
actually capture both let's take the logical and structural properties of this information propagation works

960
01:04:31,740 --> 01:04:33,370
and once they have

961
01:04:33,380 --> 01:04:38,780
the modern understanding then i can ask what is the best and the task the

962
01:04:38,780 --> 01:04:43,280
identified here was the the question how to find influential nodes and epidemics and that

963
01:04:43,310 --> 01:04:44,810
so basically what happened network

964
01:04:44,910 --> 01:04:48,740
which nodes should be that we wanted to that the days

965
01:04:48,960 --> 01:04:51,780
you this is of information that

966
01:04:51,800 --> 01:04:53,670
so what this picture here shows

967
01:04:53,680 --> 01:04:54,540
is there

968
01:04:56,500 --> 01:04:59,310
for every dot on this network is is a blog

969
01:04:59,340 --> 01:05:02,010
and what to show sort of the the

970
01:05:02,020 --> 01:05:08,620
sequence of how the algorithm selects influential bloggers so here these visualisations is going towards

971
01:05:08,620 --> 01:05:10,640
the close the two

972
01:05:10,760 --> 01:05:12,930
report on similar topics

973
01:05:12,960 --> 01:05:16,500
so for example if i did the first one not to cover the whole lot

974
01:05:16,500 --> 01:05:19,210
blogosphere so you can think of this as kind of

975
01:05:19,220 --> 01:05:23,970
any of influence but but the public things very far away some sort of

976
01:05:23,990 --> 01:05:27,090
detect those things lots of doing this

977
01:05:27,100 --> 01:05:35,380
according to develop the call itself operates it selects influential blogs in a sequential manner

978
01:05:35,380 --> 01:05:37,960
and you can see how like you

979
01:05:37,970 --> 01:05:39,260
blogs holding

980
01:05:39,270 --> 01:05:45,480
covered neighborhoods around around blocks and if i go and is up to them what

981
01:05:45,520 --> 01:05:46,660
not nicely

982
01:05:46,980 --> 01:05:48,630
basically the whole the whole

983
01:05:49,140 --> 01:05:50,860
o lots there some sense

984
01:05:50,880 --> 01:05:55,010
so this is sort of a quick overview of the two parts

985
01:05:55,010 --> 01:05:58,760
and then the other

986
01:05:58,760 --> 01:06:02,630
o team of the network was basically the benefits of working with large so we

987
01:06:02,630 --> 01:06:09,690
work with some of the largest social and information networks that be examined so far

988
01:06:09,690 --> 01:06:14,390
so particular the whole user base of microsoft instant messenger

989
01:06:14,620 --> 01:06:17,010
water for billions of people and

990
01:06:17,020 --> 01:06:20,250
two hundred fifty five billion exchanged messages per month

991
01:06:21,400 --> 01:06:22,270
the other thing

992
01:06:22,280 --> 01:06:27,760
one was explicit communication networks from a large on line retailer based

993
01:06:27,810 --> 01:06:34,900
sixteen million sixty five commendations and awards showing the blogs that basically nothing more than

994
01:06:34,940 --> 01:06:38,060
a year hundreds of millions of

995
01:06:38,970 --> 01:06:44,270
but lots of things so what is the benefit and the benefit is basically by

996
01:06:44,410 --> 01:06:46,300
working with large data basically you

997
01:06:46,390 --> 01:06:48,140
c and find

998
01:06:48,180 --> 01:06:51,510
let's properties and patterns of basic invisible or

999
01:06:51,740 --> 01:06:57,310
statistically undetectable at small scales so on one one is the the

1000
01:06:57,380 --> 01:07:02,270
can this is basically we're looking at the community of clustering structure of large networks

1001
01:07:02,270 --> 01:07:05,860
and what the result is the same as in small networks to find these good

1002
01:07:06,010 --> 01:07:09,710
dense clusters that you can then lets extracted

1003
01:07:09,730 --> 01:07:14,080
call them community detection graph partitioning methods it turns out that when you look at

1004
01:07:14,100 --> 01:07:17,900
networks it just don't see such substructure something like networks

1005
01:07:17,920 --> 01:07:22,530
clusters find their own hundred nodes and everything else is big mass so the question

1006
01:07:22,530 --> 01:07:24,840
here is that this is some companies

1007
01:07:24,850 --> 01:07:26,890
why big networks

1008
01:07:26,910 --> 01:07:30,360
as as it seems fundamentally different from small

1009
01:07:30,670 --> 01:07:32,540
so what does sort of the

1010
01:07:33,080 --> 01:07:37,710
reflections on what what the questions and what the consequences of the disease so basically

1011
01:07:37,720 --> 01:07:38,490
the whole

1012
01:07:38,500 --> 01:07:43,080
the whole the main question was why are networks the way they are and how

1013
01:07:43,080 --> 01:07:48,970
can we use use this something each of these it will also nicely connects to

1014
01:07:48,990 --> 01:07:54,590
especially social sciences in the sense that only since recently basic properties of this network

1015
01:07:55,030 --> 01:07:59,890
has been observed on a large scale and many times this sort of conference

1016
01:07:59,910 --> 01:08:06,150
so social science intuitions and goals some other question so here i see

1017
01:08:06,170 --> 01:08:08,310
a good a fruitful area

1018
01:08:08,310 --> 01:08:13,790
those are promising trends water some were some problems that i see i i don't

1019
01:08:13,790 --> 01:08:16,660
want to say things aren't going to work

1020
01:08:16,710 --> 01:08:18,730
that's one of the lessons learned

1021
01:08:18,770 --> 01:08:22,680
but i do see some problems one problem we have in software development for the

1022
01:08:22,680 --> 01:08:27,520
semantic web is that you know you we can exchange data in RDF but

1023
01:08:27,580 --> 01:08:31,410
if i write some software for doing RDF that there's really not a good way

1024
01:08:31,410 --> 01:08:34,830
to write software way that's independent to the RDF

1025
01:08:34,870 --> 01:08:36,750
API that you're using

1026
01:08:36,810 --> 01:08:40,580
be great if we could have some work towards standardizing the

1027
01:08:40,640 --> 01:08:43,850
the different AP eyes

1028
01:08:43,910 --> 01:08:47,140
i actually think the most important problem for

1029
01:08:47,160 --> 01:08:51,830
from the perspective of the work that i've been doing and have been exposed to

1030
01:08:52,060 --> 01:08:54,390
at IBM and its customers

1031
01:08:54,390 --> 01:08:59,230
is this all idea in linguistics of connotation versus denotation connotations

1032
01:08:59,330 --> 01:09:00,640
kind of

1033
01:09:00,710 --> 01:09:03,890
without giving you a three hour lecture

1034
01:09:03,930 --> 01:09:06,890
connotation is sort of what reason do now the

1035
01:09:06,910 --> 01:09:11,750
connotation is sort of the what what symbols you can conclude from other symbols

1036
01:09:11,850 --> 01:09:16,940
whereas denotation is this murky connection to the real world between those symbols and what

1037
01:09:16,940 --> 01:09:19,230
they denote

1038
01:09:19,290 --> 01:09:21,080
this is actually of a

1039
01:09:21,120 --> 01:09:24,410
problem in industry

1040
01:09:24,430 --> 01:09:29,180
your eyes are nice idea i as i said i didn't really understand it when

1041
01:09:29,250 --> 01:09:31,020
it was first presented

1042
01:09:31,040 --> 01:09:32,710
that is the

1043
01:09:32,770 --> 01:09:34,290
it wasn't the

1044
01:09:34,290 --> 01:09:38,500
the k are in the semantic web was novel was the web

1045
01:09:38,580 --> 01:09:41,810
that was novel adding that aspect too

1046
01:09:41,830 --> 01:09:46,830
what we're doing in k are for twenty years really really was an innovation

1047
01:09:46,910 --> 01:09:49,040
that we're just beginning to

1048
01:09:50,790 --> 01:09:54,430
and this is one of the problems that technology creates a your eyes give you

1049
01:09:54,430 --> 01:09:58,480
an identifier but it's it's you still have an identity problem on the web and

1050
01:09:58,480 --> 01:10:00,750
we run into this all the time

1051
01:10:00,750 --> 01:10:03,870
really run into this problem space

1052
01:10:03,890 --> 01:10:07,520
significantly limiting a lot of the work done

1053
01:10:08,030 --> 01:10:15,710
as i already said i think this community is really weak on experimental methodology i

1054
01:10:15,710 --> 01:10:18,210
think a lot of times we published results

1055
01:10:18,210 --> 01:10:20,140
we don't really understand what they mean

1056
01:10:20,160 --> 01:10:21,440
if they are useful

1057
01:10:21,460 --> 01:10:22,830
anyone cares

1058
01:10:22,850 --> 01:10:25,910
how significant it is

1059
01:10:25,940 --> 01:10:30,580
i really think we need to do a better job we're supposed to be scientists

1060
01:10:30,580 --> 01:10:33,270
not just hackers

1061
01:10:33,270 --> 01:10:33,980
i mean it

1062
01:10:34,000 --> 01:10:37,600
talk i think if i have time about this notion of the very long tail

1063
01:10:37,600 --> 01:10:42,980
and how it impacts the semantic web i think it's very important

1064
01:10:42,980 --> 01:10:44,620
and you know how

1065
01:10:44,640 --> 01:10:49,060
how important is reasoning on the semantic web is a big problem that we have

1066
01:10:49,060 --> 01:10:51,330
i think and could put that there

1067
01:10:51,350 --> 01:10:55,520
the structure of the cut there

1068
01:10:55,520 --> 01:11:02,020
but i guess i do believe the ontology qualities is pretty important

1069
01:11:03,440 --> 01:11:08,850
i'm not very good sales but because of my

1070
01:11:08,890 --> 01:11:11,230
it's that

1071
01:11:11,230 --> 01:11:12,210
in the

1072
01:11:12,230 --> 01:11:17,520
the semantic web world at IBM i get asked questions about OWL and RDF all

1073
01:11:17,520 --> 01:11:18,960
the time

1074
01:11:23,620 --> 01:11:28,120
you know my murky explication of what the semantic web is

1075
01:11:29,640 --> 01:11:30,770
most people

1076
01:11:30,790 --> 01:11:32,700
i don't understand

1077
01:11:32,730 --> 01:11:36,350
whether they need reasoning and if so

1078
01:11:36,370 --> 01:11:40,160
even if they believed they needed a lot of people who believe they needed don't

1079
01:11:40,160 --> 01:11:42,080
really know why

1080
01:11:43,870 --> 01:11:46,060
i've had a very difficult time

1081
01:11:46,080 --> 01:11:48,250
selling the idea of reasons

1082
01:11:48,390 --> 01:11:51,560
what is reasoning really is solution to

1083
01:11:51,580 --> 01:11:54,850
i'm not saying there are none there are a couple of of these cases that

1084
01:11:55,750 --> 01:11:59,100
most people use reasoning if they use it all

1085
01:11:59,160 --> 01:12:04,560
to check the validity of their ontologies and that's it done with reasoning from that

1086
01:12:07,750 --> 01:12:12,020
the users who do want reasoning that i'm encountering again i don't i'm not talking

1087
01:12:12,020 --> 01:12:14,870
about people in the research community

1088
01:12:14,910 --> 01:12:18,000
we're already convinced that we need reasoning

1089
01:12:18,080 --> 01:12:22,370
certainly i mean this group of things reasoning is very important but i have a

1090
01:12:22,370 --> 01:12:24,700
hard time saying why

1091
01:12:24,700 --> 01:12:29,080
what most users i encounter one day they seem to get the idea of some

1092
01:12:29,080 --> 01:12:32,790
kind of simple taxonomic inheritance

1093
01:12:32,810 --> 01:12:38,080
they seem to get the idea of constraints although their mind boggled by

1094
01:12:38,100 --> 01:12:39,330
this sort of way

1095
01:12:39,330 --> 01:12:42,750
our processes constraints which is to say that you know if

1096
01:12:42,770 --> 01:12:47,270
if you say the domain of enjoyable experience if you say the domain and range

1097
01:12:47,290 --> 01:12:49,730
of some properties of person

1098
01:12:49,790 --> 01:12:54,120
and you put something in that's not a person the result is that

1099
01:12:54,160 --> 01:12:56,790
the result of reasoning that is the person

1100
01:12:58,120 --> 01:13:01,600
as opposed to something saying hey it's got to be a person this is an

1101
01:13:01,600 --> 01:13:06,750
invalid valid what people find that confusing

1102
01:13:08,180 --> 01:13:09,270
and then people

1103
01:13:09,290 --> 01:13:13,790
everyone i talked to seem to want very simple rules

1104
01:13:13,810 --> 01:13:14,730
very simple

1105
01:13:14,750 --> 01:13:18,100
rules over their RDF data

1106
01:13:18,120 --> 01:13:23,060
there are certainly another class of users think that OWL DL is not enough for

1107
01:13:23,060 --> 01:13:26,770
even OWL full just not enough does allow me to say the things i want

1108
01:13:26,770 --> 01:13:32,080
to say about my data and my semantics not because they care about reasoning just

1109
01:13:32,080 --> 01:13:36,480
because i have a pretty complicated semantics i wanna write it in english

1110
01:13:36,560 --> 01:13:38,680
so there is this

1111
01:13:38,730 --> 01:13:44,700
big class of users that are convinced they need ontologies as way to communicate the

1112
01:13:44,700 --> 01:13:47,700
semantics of their data

1113
01:13:47,770 --> 01:13:50,600
but they are not interested in reasoning at all

1114
01:13:50,620 --> 01:13:52,500
they just look at this

1115
01:13:52,520 --> 01:13:57,890
but in some kind of special language for writing documentation

1116
01:13:57,890 --> 01:14:02,390
fifteen years and you can see that article text is increasing exponentially

1117
01:14:02,410 --> 01:14:03,980
in the

1118
01:14:03,980 --> 01:14:07,910
vulnerability of your computer metrics is also increasing

1119
01:14:07,920 --> 01:14:10,290
on the other hand

1120
01:14:10,290 --> 01:14:13,400
this graph shows basically

1121
01:14:13,440 --> 01:14:18,060
what kind of philosophical station attackers have to have in order to perform and yet

1122
01:14:18,060 --> 01:14:22,110
the the tag earlier in the computers basically

1123
01:14:22,160 --> 01:14:25,650
appeared in the market basically not all nineteen eighty

1124
01:14:25,660 --> 01:14:27,660
there are only few

1125
01:14:27,670 --> 01:14:29,340
the number of attacks

1126
01:14:29,360 --> 01:14:34,500
in the level of sophistication in order to perform this attack was relatively high

1127
01:14:35,670 --> 01:14:38,550
this also correspond to the number of

1128
01:14:38,570 --> 01:14:43,140
tools that you can see that there are available to perform the computer attacks

1129
01:14:43,210 --> 01:14:45,880
and over time the number of tools

1130
01:14:45,890 --> 01:14:47,880
and the number of tax increases

1131
01:14:47,920 --> 01:14:52,040
one of the biggest sophistication of attackers actually the amount of the knowledge of the

1132
01:14:52,040 --> 01:14:54,920
celtic to have in order to perform detector significantly

1133
01:14:55,170 --> 01:14:58,840
so basically today almost every high school kid

1134
01:14:58,900 --> 01:15:02,520
can use some of the those from the internet and try to perform some attacking

1135
01:15:02,530 --> 01:15:04,710
the denial-of-service attack

1136
01:15:07,120 --> 01:15:10,190
scanning attack it's quite easy

1137
01:15:10,810 --> 01:15:13,520
people are trying to defend against these things

1138
01:15:13,560 --> 01:15:17,410
and security mechanisms usually have some kind of

1139
01:15:17,450 --> 01:15:19,540
inevitable vulnerabilities

1140
01:15:19,550 --> 01:15:22,620
and firewalls are typically not sufficient

1141
01:15:22,660 --> 01:15:28,500
to sure one hundred percent security in computer networks

1142
01:15:29,520 --> 01:15:32,180
what it actually intrusion

1143
01:15:32,190 --> 01:15:34,990
as i said earlier inference

1144
01:15:35,000 --> 01:15:37,440
OK let's have

1145
01:15:37,500 --> 01:15:43,920
OK so intrusions

1146
01:15:43,970 --> 01:15:48,270
actually that attempt to bypass security mechanisms

1147
01:15:54,200 --> 01:15:56,990
OK so you see these guys trying to scan the network

1148
01:15:57,000 --> 01:16:01,070
and when you find some computer that is vulnerable of his trying to launch

1149
01:16:01,120 --> 01:16:04,360
thank you for type two

1150
01:16:04,370 --> 01:16:12,260
OK so when is trying to find computer title and the second is computer and

1151
01:16:12,270 --> 01:16:14,880
he's trying to attack this specific computer

1152
01:16:14,920 --> 01:16:19,140
so first his can the natural for the vulnerabilities of some security calls

1153
01:16:19,150 --> 01:16:21,160
and then when he finds the computer

1154
01:16:21,160 --> 01:16:26,880
then he will here trying to launch attack on this specific computer the typical scenario

1155
01:16:26,880 --> 01:16:29,030
how through jean detection

1156
01:16:31,070 --> 01:16:33,040
is occurring

1157
01:16:33,040 --> 01:16:34,630
as i mentioned briefly earlier

1158
01:16:34,840 --> 01:16:41,290
intrusion detection systems are typically combination of software and hardware tools

1159
01:16:41,330 --> 01:16:44,320
and their goal is to detect intrusions of course

1160
01:16:44,380 --> 01:16:45,340
and they

1161
01:16:45,360 --> 01:16:49,090
raise the alarm every time certain suspicious activity

1162
01:16:49,120 --> 01:16:51,420
is occurring

1163
01:16:51,420 --> 01:16:56,390
i mentioned we also the traditional intrusion detection systems are based on signatures and they

1164
01:16:56,400 --> 01:17:00,300
work in a similar way like virus can make a field or

1165
01:17:00,310 --> 01:17:02,240
or or or not

1166
01:17:03,080 --> 01:17:06,370
and basically this here we show example

1167
01:17:06,380 --> 01:17:09,310
of signature of one of the

1168
01:17:09,370 --> 01:17:15,000
forms that are detected in computer networks basically every time and finishing bayesint interest text

1169
01:17:15,000 --> 01:17:16,910
is to find this combination

1170
01:17:16,950 --> 01:17:19,050
to to raise an alarm

1171
01:17:22,110 --> 01:17:23,670
this image should be used

1172
01:17:23,710 --> 01:17:28,560
intrusion detection systems have limitations and they cannot detect these new types of there's new

1173
01:17:28,560 --> 01:17:30,290
computer attacks

1174
01:17:30,300 --> 01:17:33,990
and also there is

1175
01:17:34,790 --> 01:17:39,110
because every time and it is a new attack you have to revise this manually

1176
01:17:39,160 --> 01:17:40,960
and then to update the database

1177
01:17:40,970 --> 01:17:43,560
and then you can take this new attacks so basically

1178
01:17:43,640 --> 01:17:46,060
there is hope that

1179
01:17:46,120 --> 01:17:51,280
anomaly detection techniques can alleviate some of these are so this a the problem because

1180
01:17:51,280 --> 01:17:52,670
they can affect

1181
01:17:52,720 --> 01:17:56,070
new emerging behavior

1182
01:17:58,080 --> 01:17:58,970
there are two

1183
01:17:58,990 --> 01:18:01,660
types of approaches that people can do in

1184
01:18:01,670 --> 01:18:05,360
intrusion detection using data mining techniques

1185
01:18:05,370 --> 01:18:10,330
the first was the first one is misuse detection

1186
01:18:10,390 --> 01:18:15,420
mean you basically have the knowledge about what normal in the network and

1187
01:18:15,430 --> 01:18:19,060
novelist and again this is similar to classification techniques

1188
01:18:19,150 --> 01:18:22,830
when you try to build different types of classifiers

1189
01:18:22,890 --> 01:18:27,940
but again they have they can have really high accuracy in detecting these intrusions but

1190
01:18:27,940 --> 01:18:31,640
also they may have problems with attacking this new emerging behavior

1191
01:18:31,650 --> 01:18:34,770
on the other hand you have anomaly detection techniques

1192
01:18:34,780 --> 01:18:35,790
as you know the

1193
01:18:37,550 --> 01:18:41,160
can be detected using this technique says deviation from the norm

1194
01:18:41,200 --> 01:18:47,180
but they suffer from potential high false alarm rate

1195
01:18:47,200 --> 01:18:50,950
OK so this is the typical kind of data says that you get from the

1196
01:18:50,950 --> 01:18:52,530
network intrusion detection

1197
01:18:53,660 --> 01:18:55,690
this is the source IP address

1198
01:18:55,760 --> 01:19:00,740
this nation for the destination IP this nation of ulysses source for this initial IP

1199
01:19:00,740 --> 01:19:01,960
destination port

1200
01:19:01,970 --> 01:19:03,330
number of bytes

1201
01:19:03,340 --> 01:19:08,040
depending on the level of information you have it dealing with network traffic back it's

1202
01:19:08,050 --> 01:19:13,740
all you're doing using their drawback it's you make an informational support from the back

1203
01:19:13,800 --> 01:19:16,680
the raw data and then the number of features can be

1204
01:19:16,770 --> 01:19:19,060
significantly higher

1205
01:19:20,030 --> 01:19:23,760
depending on what time to do it in different if using mutual defection

1206
01:19:23,800 --> 01:19:26,290
you have the labels here

1207
01:19:26,300 --> 01:19:28,780
he that something is back

1208
01:19:28,870 --> 01:19:32,370
i mean computer technology and then you're trying to train the model

1209
01:19:32,390 --> 01:19:34,710
from training set trying to learn the classifier

1210
01:19:34,720 --> 01:19:40,800
and then to apply these classifying it as they can get with the labels

1211
01:19:40,890 --> 01:19:43,930
OK so you what the labels here so far

1212
01:19:43,940 --> 01:19:46,700
if you're doing anomaly detection

1213
01:19:46,710 --> 01:19:50,320
let's say this is the data thing two dimensional space just for

1214
01:19:50,380 --> 01:19:51,780
just for simplicity

1215
01:19:51,790 --> 01:19:56,590
you're trying to define what can you normally hear

1216
01:19:56,830 --> 01:20:11,220
OK so far so good humour to detect anomalies all these points here that far

1217
01:20:11,220 --> 01:20:12,660
from everything else

1218
01:20:12,680 --> 01:20:14,530
and finally

1219
01:20:14,560 --> 01:20:17,160
you we do some summarisation of the network

1220
01:20:17,240 --> 01:20:19,770
i think using association rules

1221
01:20:20,690 --> 01:20:22,540
for example

1222
01:20:22,540 --> 01:20:27,310
all of this that connections if they have something in common you may apply some

1223
01:20:27,310 --> 01:20:29,390
standard association rules to detect two

1224
01:20:31,160 --> 01:20:33,920
replace all this data that is has to see

1225
01:20:33,930 --> 01:20:36,950
and replaced with carol's i'll explain a little bit

1226
01:20:37,000 --> 01:20:39,650
o this later

1227
01:20:39,660 --> 01:20:41,470
so this is

1228
01:20:41,550 --> 01:20:43,440
slide shows that

1229
01:20:43,500 --> 01:20:46,770
the system that was applied in the university minnesota

1230
01:20:46,810 --> 01:20:50,950
when applied to the anomaly detection techniques to detect real

1231
01:20:52,030 --> 01:20:54,580
intrusions in network that we have

1232
01:20:56,040 --> 01:20:57,490
here we here

1233
01:20:57,500 --> 01:21:00,210
the network we have

1234
01:21:00,260 --> 01:21:03,790
several tools to to collect the data they use the net flow tools

1235
01:21:03,790 --> 01:21:06,380
to collect only the packet header information

1236
01:21:06,420 --> 01:21:09,130
or you can use it you can also use this to be done

1237
01:21:09,180 --> 01:21:13,320
tool to collect those the rollback it information because emperor package information

1238
01:21:13,330 --> 01:21:15,090
if you're writing the main

1239
01:21:15,110 --> 01:21:17,430
it can contain exactly what you wrote

1240
01:21:17,470 --> 01:21:18,560
in the email

1241
01:21:19,330 --> 01:21:21,870
if you if you want to this information

1242
01:21:21,890 --> 01:21:24,040
there are some privacy issues as well

1243
01:21:24,080 --> 01:21:28,760
the netflix goes only contain information about the connection comes from that going

1244
01:21:28,770 --> 01:21:32,330
and what to the number of bytes in some cases reflects

1245
01:21:32,360 --> 01:21:38,170
so right now we have the feelings that the basically our computer security analyst is

1246
01:21:38,220 --> 01:21:40,020
light is basically

1247
01:21:40,020 --> 01:21:44,960
so that relates the two area of convex sets with convex functions

1248
01:21:44,970 --> 01:21:48,530
this definition the sublevel set of a function f

1249
01:21:48,580 --> 01:21:53,030
is the set of all vectors x that have the function value

1250
01:21:53,040 --> 01:21:57,550
as i recall two given numbers

1251
01:21:57,570 --> 01:22:02,080
and convex functions have the property that all the sublevel sets are convex

1252
01:22:02,130 --> 01:22:04,280
but the converse is not true

1253
01:22:04,300 --> 01:22:09,230
so fraction can have convex sublevel sets but it's not necessarily convex

1254
01:22:09,250 --> 01:22:17,050
so these are some basic examples or examples i will encounter of convex functions

1255
01:22:17,070 --> 01:22:20,790
well first of all the variables can just look at the graph of the function

1256
01:22:20,790 --> 01:22:23,750
and see the convex for example the exponential

1257
01:22:23,770 --> 01:22:25,730
or minus log x is convex

1258
01:22:25,740 --> 01:22:27,000
convex functions

1259
01:22:27,010 --> 01:22:29,510
certain powers of x are convex

1260
01:22:29,520 --> 01:22:32,140
so x to the power of five of his

1261
01:22:32,140 --> 01:22:33,670
greater than one

1262
01:22:33,690 --> 01:22:38,440
and you restrict access the positive real axis

1263
01:22:39,320 --> 01:22:45,520
some negative powers for example one over x is convex for positive x

1264
01:22:45,570 --> 01:22:50,010
this is a very useful function quadratic over linear so if you take a cesspools

1265
01:22:51,890 --> 01:22:53,270
defined by t

1266
01:22:53,290 --> 01:22:55,960
thirty is restricted to be positive

1267
01:22:56,110 --> 01:22:59,360
then this is an convex function xmt

1268
01:22:59,370 --> 01:23:01,940
joint in xnt

1269
01:23:01,950 --> 01:23:06,550
the geometric mean of n vectors is concave

1270
01:23:07,980 --> 01:23:11,680
log of the determined of a positive definite matrix is a concave function that will

1271
01:23:14,880 --> 01:23:18,400
the log of a sum of exponentials is convex

1272
01:23:18,460 --> 01:23:23,360
norms are always convex linear functions always convex and so on

1273
01:23:23,370 --> 01:23:31,460
four differentiable functions are some of

1274
01:23:31,470 --> 01:23:33,190
other characterizations

1275
01:23:33,190 --> 01:23:37,400
so the function is twice differentiable then it's session is always positive semi definite attraction

1276
01:23:37,410 --> 01:23:39,390
is symmetric matrix with partial

1277
01:23:39,440 --> 01:23:41,160
second partial derivatives

1278
01:23:41,170 --> 01:23:42,190
that's always

1279
01:23:42,220 --> 01:23:45,330
positive semidefinite

1280
01:23:45,350 --> 01:23:49,500
so that's probably the best known characterisation of convex functions but it assumes that f

1281
01:23:49,500 --> 01:23:51,880
is differentiable twice differentiable

1282
01:23:53,940 --> 01:23:58,670
four function you can also there's also property only uses the first derivative so if

1283
01:23:58,670 --> 01:24:03,720
the gradients with great i mean the vector of the first partial derivatives

1284
01:24:03,750 --> 01:24:05,050
so the gradient of

1285
01:24:05,080 --> 01:24:10,970
any function f defines a linear approximation a local linear approximation around x

1286
01:24:10,990 --> 01:24:13,780
so if you've elevates at some point x the function

1287
01:24:13,790 --> 01:24:15,440
and its gradient

1288
01:24:15,480 --> 01:24:17,410
then the

1289
01:24:17,410 --> 01:24:22,250
the straight line the first order approximation is the local

1290
01:24:22,310 --> 01:24:24,710
linear approximation to the function value

1291
01:24:24,710 --> 01:24:28,450
if a function is convex then this approximation also has the property

1292
01:24:28,510 --> 01:24:32,470
that's a lower bound on the function value everywhere

1293
01:24:32,480 --> 01:24:34,350
and not just the local

1294
01:24:36,120 --> 01:24:41,220
and that's if and only if if the function is differentiable

1295
01:24:41,270 --> 01:24:47,240
practice if you try to use convex formulations in applications

1296
01:24:47,260 --> 01:24:53,010
it's useful to have a sort of a set of techniques for

1297
01:24:53,060 --> 01:24:56,580
proving convexity or easily establishing convexity of functions

1298
01:24:56,600 --> 01:25:01,190
and so there are several techniques we can use so on this

1299
01:25:01,670 --> 01:25:04,300
we can just use the definition that works

1300
01:25:04,330 --> 01:25:06,220
the chances inequality

1301
01:25:06,220 --> 01:25:08,620
that works in

1302
01:25:08,680 --> 01:25:12,920
in some cases in some cases it's quite complicated

1303
01:25:12,960 --> 01:25:18,640
you can use for defensible twice differentiable functions can take the haitian is positive semidefinite

1304
01:25:18,650 --> 01:25:21,160
but also that can be quite painful

1305
01:25:23,990 --> 01:25:26,350
this session is complicated

1306
01:25:26,390 --> 01:25:32,110
and there are also set of techniques that often allow you to easily show convexity

1307
01:25:33,220 --> 01:25:36,390
by showing that the function is derived from simpler functions

1308
01:25:36,400 --> 01:25:38,540
nevertheless additional slides ago

1309
01:25:38,560 --> 01:25:41,010
and some basic

1310
01:25:41,020 --> 01:25:42,530
calculus rules for

1311
01:25:42,570 --> 01:25:45,450
that preserve convexity

1312
01:25:45,460 --> 01:25:49,450
so i'll go through these different rules

1313
01:25:49,470 --> 01:25:51,400
with some examples

1314
01:25:51,450 --> 01:25:56,620
so the first one is quite straightforward if f is convex then positive or negative

1315
01:25:56,620 --> 01:25:58,510
multiple is convex

1316
01:25:58,550 --> 01:26:02,180
or some of the convex functions is convex

1317
01:26:02,220 --> 01:26:06,650
or if you have a function is convex and replace its arguments with linear mapping

1318
01:26:06,700 --> 01:26:08,020
of some variable

1319
01:26:08,080 --> 01:26:09,700
then the resulting

1320
01:26:09,700 --> 01:26:11,440
a function is convex in x

1321
01:26:12,460 --> 01:26:15,110
so in some examples of this are for example

1322
01:26:15,110 --> 01:26:18,400
the normal express b is always convex

1323
01:26:18,420 --> 01:26:24,280
and that's true for any norm because norms are convex and uses property

1324
01:26:25,360 --> 01:26:29,460
the function is known as the logarithmic barrier function in your programming is convex

1325
01:26:29,480 --> 01:26:32,520
because minus log x is convex

1326
01:26:32,530 --> 01:26:34,630
here we replace the argument of

1327
01:26:34,630 --> 01:26:38,510
the function by linear or not find functions work is is a convex function

1328
01:26:38,530 --> 01:26:42,960
and then we have this functions for i want

1329
01:26:42,970 --> 01:26:45,040
so that's automatically convex

1330
01:26:45,730 --> 01:26:46,940
you need to

1331
01:26:46,950 --> 01:26:51,910
worry about the haitian order derivatives to establish convexity

1332
01:26:51,960 --> 01:26:55,830
this is one of the most useful

1333
01:26:55,890 --> 01:26:58,280
these characters rules

1334
01:26:58,300 --> 01:27:00,210
pointwise maximum of

1335
01:27:00,210 --> 01:27:05,670
a set of convex functions is convex if f one through ephemeral convex in x

1336
01:27:05,720 --> 01:27:08,500
and i define f of x as

1337
01:27:08,560 --> 01:27:12,770
a new function that has the maximum of this function values

1338
01:27:12,790 --> 01:27:16,720
and that new function is convex

1339
01:27:16,730 --> 01:27:22,660
and this is an example of this suppose i defined for vector in rn

1340
01:27:22,670 --> 01:27:24,890
a function is the sum of the are

1341
01:27:24,910 --> 01:27:28,270
the largest components in x

1342
01:27:28,330 --> 01:27:32,030
so it's easy to compute its a well-defined function of x can be computed by

1343
01:27:32,030 --> 01:27:35,640
sorting the components of x in descending order

1344
01:27:35,650 --> 01:27:39,300
and then just adding to our leading coefficients

1345
01:27:39,430 --> 01:27:42,310
so it's easy to compute it's a well-defined function of x

1346
01:27:42,360 --> 01:27:48,190
and is also convex and that's easy to see from this max maximum rule

1347
01:27:48,200 --> 01:27:52,490
because i can also write it as a maximum of a very large number of

1348
01:27:52,490 --> 01:27:55,170
linear functions of x

1349
01:27:55,190 --> 01:27:56,230
so take all

1350
01:27:56,250 --> 01:27:58,490
groups of our subsets

1351
01:27:58,500 --> 01:28:00,400
of coefficients of x

1352
01:28:00,400 --> 01:28:02,720
for each subset that exist some

1353
01:28:02,750 --> 01:28:06,410
and then if i take the maximum of all these some standard be the maximum

1354
01:28:06,410 --> 01:28:12,880
this some of our largest for that's so the practical expression for computing f of

1355
01:28:13,650 --> 01:28:17,780
because it's a maximal very large number of linear functions but this shows that it's

1356
01:28:18,990 --> 01:28:26,830
so the maximum component of f is convex to some of the largest two and

1357
01:28:26,830 --> 01:28:28,860
so on

1358
01:28:28,880 --> 01:28:33,990
this also extends to an infinite maximisation so here we have a finite maximum of

1359
01:28:36,220 --> 01:28:38,670
and so on

1360
01:28:38,710 --> 01:28:44,220
o notation to use the super supremum for maximisation of set that's infinite

1361
01:28:44,230 --> 01:28:47,680
or possibly infinite it's not specified

1362
01:28:47,680 --> 01:28:50,540
so here i define a function g

1363
01:28:50,560 --> 01:28:52,020
of x

1364
01:28:52,040 --> 01:28:58,270
as an so take a function f of two variables x and y

1365
01:28:58,280 --> 01:29:03,770
and f has the property that for fixed why the function is convex in x

1366
01:29:03,820 --> 01:29:07,030
and define a function and maximize over y

1367
01:29:07,030 --> 01:29:08,470
i have to some

1368
01:29:08,480 --> 01:29:11,500
over z

1369
01:29:11,510 --> 01:29:15,290
the effects

1370
01:29:15,330 --> 01:29:17,410
given z

1371
01:29:17,420 --> 01:29:21,890
he said

1372
01:29:21,950 --> 01:29:23,850
so multiply this by this

1373
01:29:23,860 --> 01:29:25,280
and then we have to some

1374
01:29:25,290 --> 01:29:27,400
over all possible choices

1375
01:29:27,430 --> 01:29:31,820
of the vector z so i have to sum up and after some the case

1376
01:29:31,820 --> 01:29:33,680
was z is one zero zero

1377
01:29:33,750 --> 01:29:36,740
plus the pastry zero one zero

1378
01:29:36,750 --> 01:29:40,180
plus the case for zero zero one

1379
01:29:40,300 --> 01:29:43,380
adult those three contributions

1380
01:29:43,440 --> 01:29:46,180
the first would just pick out

1381
01:29:46,200 --> 01:29:48,300
the mixing coefficients pi one

1382
01:29:48,310 --> 01:29:51,330
and guassian and new one sigma one

1383
01:29:51,550 --> 01:29:55,200
and the second component the second term in this sum will pick out the second

1384
01:29:55,200 --> 01:29:56,480
component so on

1385
01:29:56,500 --> 01:30:00,630
so what i'm left with is the sum of the components k

1386
01:30:00,680 --> 01:30:02,010
of pi k

1387
01:30:02,020 --> 01:30:06,690
times and that's given parameters nu k sigma k

1388
01:30:06,710 --> 01:30:12,660
so the marginal distribution is just are familiar mixture of gaussians

1389
01:30:12,700 --> 01:30:14,360
so this is an example

1390
01:30:15,210 --> 01:30:16,520
how we have

1391
01:30:16,530 --> 01:30:23,210
constructed a complex probability distribution which is not of the exponential family much more general

1392
01:30:23,220 --> 01:30:29,350
using the graphical model which the building blocks of exponential family distributions

1393
01:30:29,360 --> 01:30:31,060
so very trivial example

1394
01:30:31,070 --> 01:30:33,230
of very general approach to

1395
01:30:33,580 --> 01:30:43,590
solving machine learning problems

1396
01:30:43,610 --> 01:30:45,400
now we actually have an entire

1397
01:30:45,410 --> 01:30:48,510
data set of observations

1398
01:30:48,550 --> 01:30:52,800
and so the graphical model for the for the complete data set for the entire

1399
01:30:52,800 --> 01:30:54,310
dataset can be written

1400
01:30:55,560 --> 01:30:56,880
as this

1401
01:30:56,900 --> 01:30:59,020
so this is all plate notation

1402
01:30:59,030 --> 01:31:01,280
and this is the capital and

1403
01:31:01,290 --> 01:31:06,220
replicas of what's inside the plates well there's an observation xn and there corresponding latent

1404
01:31:06,220 --> 01:31:08,920
variables and

1405
01:31:08,940 --> 01:31:15,100
and i used this notation these parameters are the parameters not random variables we don't

1406
01:31:15,100 --> 01:31:16,850
have nodes

1407
01:31:16,870 --> 01:31:21,990
so just indicated them with symbols without any circles

1408
01:31:22,100 --> 01:31:25,580
but the shared by all of the components in the mixture so they live outside

1409
01:31:25,580 --> 01:31:26,680
the plate

1410
01:31:26,760 --> 01:31:33,600
so i hope that this notation is reasonably clear

1411
01:31:33,610 --> 01:31:37,430
OK let's go back to this problem of complete or the problem of

1412
01:31:37,880 --> 01:31:41,960
of the fact that we would not observe the latent variables so suppose for a

1413
01:31:41,960 --> 01:31:44,400
minute that somebody kindly gave us

1414
01:31:45,380 --> 01:31:49,420
datasets with the observations of supposing that z

1415
01:31:49,430 --> 01:31:54,030
it was also observed in other words a hundred dataset and say please for mixture

1416
01:31:54,030 --> 01:31:55,440
of gaussians to this

1417
01:31:55,450 --> 01:31:57,120
but really very kind today

1418
01:31:57,130 --> 01:32:06,180
i'm gonna colour in the data points according to which garrison generated that data points

1419
01:32:06,870 --> 01:32:11,880
you have what we call complete data now you have values not only for x

1420
01:32:12,020 --> 01:32:13,270
also for z

1421
01:32:13,280 --> 01:32:16,480
so now you can write down the likelihood function that's the probability of the data

1422
01:32:16,480 --> 01:32:18,240
given the parameters

1423
01:32:20,460 --> 01:32:23,350
we know we know what that is we know not the joint distribution is

1424
01:32:23,390 --> 01:32:24,540
i think the log

1425
01:32:25,330 --> 01:32:29,210
i have the product of these two guys and the logs will become will turn

1426
01:32:29,220 --> 01:32:30,810
the products into sums

1427
01:32:30,850 --> 01:32:35,140
so what i have then is the following sum of the data points

1428
01:32:35,190 --> 01:32:37,310
some of the components

1429
01:32:37,320 --> 01:32:40,650
znk that was in the in the that was an experiment that's come down in

1430
01:32:40,650 --> 01:32:42,820
front of the log on i got log pi k

1431
01:32:42,870 --> 01:32:44,720
on log n

1432
01:32:44,740 --> 01:32:46,330
and this is what happens now

1433
01:32:46,340 --> 01:32:48,800
is that by knowing z

1434
01:32:48,890 --> 01:32:53,170
this some appears outside the log so that the sum of the components the log

1435
01:32:53,170 --> 01:32:56,520
acting directly on the gaussians

1436
01:32:56,570 --> 01:33:02,360
so by observing z interchange mathematical to change the log on the summation nasty problems

1437
01:33:02,360 --> 01:33:05,780
gone away and i now have trivial solution i think you can

1438
01:33:05,830 --> 01:33:08,900
sort of see in your in your head without doing any that even using a

1439
01:33:08,900 --> 01:33:13,920
piece of paper that when i maximize this likelihood function what's going to happen is

1440
01:33:14,790 --> 01:33:16,250
each component

1441
01:33:16,260 --> 01:33:18,230
so remember this summer over

1442
01:33:18,240 --> 01:33:20,180
the sum over k

1443
01:33:20,200 --> 01:33:22,680
all these coefficients zero

1444
01:33:22,990 --> 01:33:25,420
except for the term

1445
01:33:25,470 --> 01:33:29,400
except for the component which generated that particular data points

1446
01:33:29,410 --> 01:33:33,610
OK so what's going to happen is and this is just the log likelihood for

1447
01:33:33,610 --> 01:33:38,080
single galaxy and so what happens then is that i just do the obvious thing

1448
01:33:38,080 --> 01:33:41,750
i think the red component to the reading blue and blue ink

1449
01:33:41,760 --> 01:33:44,020
and i don't need to

1450
01:33:44,280 --> 01:33:45,940
there is no coupling between them

1451
01:33:45,940 --> 01:33:47,730
if i have a collection

1452
01:33:47,810 --> 01:33:50,960
of charges pluses and minuses

1453
01:33:51,010 --> 01:33:53,880
no has only one value

1454
01:33:53,890 --> 01:33:57,340
it is the work that i have to do is to put all these crazy

1455
01:33:57,340 --> 01:34:00,090
charges exactly where they are

1456
01:34:00,150 --> 01:34:05,620
but the electric potential is different here from their from there to their if you're

1457
01:34:05,620 --> 01:34:09,970
very close to apply charge you can be sure that the potential is positive if

1458
01:34:09,970 --> 01:34:12,520
you really close to with the negative charge

1459
01:34:12,570 --> 01:34:14,740
you can be sure that the potential negative

1460
01:34:14,910 --> 01:34:19,170
you is only one number one values they're both scalars

1461
01:34:19,190 --> 01:34:20,620
don't confuse one

1462
01:34:20,620 --> 01:34:23,410
with the other

1463
01:34:23,470 --> 01:34:26,650
in a gravitational field

1464
01:34:27,420 --> 01:34:29,740
like a piece of chalk

1465
01:34:29,790 --> 01:34:31,220
i wants to go from

1466
01:34:31,240 --> 01:34:32,550
high potential

1467
01:34:32,550 --> 01:34:35,900
low potential if i just deleted with zero speed

1468
01:34:35,910 --> 01:34:36,950
then goes

1469
01:34:36,960 --> 01:34:38,980
i potential to low potential

1470
01:34:38,990 --> 01:34:40,270
in analogy

1471
01:34:40,320 --> 01:34:41,810
positive charges

1472
01:34:41,820 --> 01:34:45,100
we also go from a higher electric potential

1473
01:34:45,180 --> 01:34:47,430
willow electric potential

1474
01:34:47,490 --> 01:34:48,630
and of course

1475
01:34:48,630 --> 01:34:50,550
this is unique for electricity

1476
01:34:50,560 --> 01:34:53,700
negative charges will go from low potential

1477
01:34:53,720 --> 01:34:55,110
two and a high

1478
01:35:01,840 --> 01:35:04,100
suppose i have a

1479
01:35:04,180 --> 01:35:05,650
position a

1480
01:35:05,700 --> 01:35:07,260
in space

1481
01:35:07,320 --> 01:35:09,450
and i had another position

1482
01:35:11,050 --> 01:35:12,620
and i specify

1483
01:35:12,700 --> 01:35:14,690
the potential

1484
01:35:14,700 --> 01:35:16,370
so here

1485
01:35:16,370 --> 01:35:18,960
we have a

1486
01:35:20,120 --> 01:35:24,450
a and here we have point b

1487
01:35:24,480 --> 01:35:25,680
the potential

1488
01:35:29,950 --> 01:35:32,390
by definition

1489
01:35:32,390 --> 01:35:34,870
the potential

1490
01:35:34,920 --> 01:35:37,430
of the

1491
01:35:37,450 --> 01:35:39,200
as we discussed

1492
01:35:41,000 --> 01:35:45,360
is in the world

1493
01:35:45,400 --> 01:35:46,770
by the way these are

1494
01:35:46,830 --> 01:35:48,650
separated by some

1495
01:35:48,740 --> 01:35:52,070
random distance or whatever you want

1496
01:35:52,070 --> 01:35:54,400
so the potential of a

1497
01:35:55,450 --> 01:35:57,160
defined as

1498
01:35:57,170 --> 01:36:00,060
goal going from a to infinity

1499
01:36:00,140 --> 01:36:02,050
of e

1500
01:36:04,170 --> 01:36:09,310
that is the definition of the potential of a

1501
01:36:10,740 --> 01:36:14,450
which is four unit charge

1502
01:36:14,500 --> 01:36:16,260
so it is not working

1503
01:36:16,270 --> 01:36:19,700
if they were forced the i'll be work but it is for a unit charged

1504
01:36:19,700 --> 01:36:22,520
that makes it easier

1505
01:36:22,560 --> 01:36:25,140
so the potential of being

1506
01:36:25,190 --> 01:36:26,310
the definition

1507
01:36:26,900 --> 01:36:28,590
indeed well

1508
01:36:29,880 --> 01:36:31,120
to infinity

1509
01:36:33,340 --> 01:36:34,450
they are

1510
01:36:36,670 --> 01:36:38,150
so therefore

1511
01:36:38,170 --> 01:36:39,950
the potential difference

1512
01:36:40,870 --> 01:36:45,570
o point a and b

1513
01:36:45,620 --> 01:36:47,090
v eight

1514
01:36:49,660 --> 01:36:51,320
because in the world

1515
01:36:51,380 --> 01:36:53,070
from a to b

1516
01:36:53,130 --> 01:36:54,010
of e

1517
01:36:58,170 --> 01:37:01,130
and for reasons that

1518
01:37:01,170 --> 01:37:05,920
i still don't understand after having been in this business for a long time

1519
01:37:05,960 --> 01:37:08,060
books will always tell you

1520
01:37:08,100 --> 01:37:14,500
they reversed a and b so to give you beam minus

1521
01:37:14,560 --> 01:37:17,190
and then they say well we have to put a minus sign in front of

1522
01:37:18,310 --> 01:37:20,310
the integral of the same thing

1523
01:37:20,320 --> 01:37:22,670
the books always give it to you in this for

1524
01:37:28,320 --> 01:37:30,900
but it is exactly the same

1525
01:37:30,910 --> 01:37:32,550
i hope you realize that

1526
01:37:32,550 --> 01:37:37,910
this is the two equations that i have here

1527
01:37:39,220 --> 01:37:42,440
the same for a minus b b is the integral from a to b if

1528
01:37:42,440 --> 01:37:44,260
you got the article

1529
01:37:44,300 --> 01:37:46,070
if i flip is over

1530
01:37:46,110 --> 01:37:48,470
all i have to do is put a minus sign here

1531
01:37:48,490 --> 01:37:52,210
and the two are identical

1532
01:37:52,230 --> 01:37:56,580
notice that if there is no electric field between a and b

1533
01:37:56,620 --> 01:37:58,600
they have the same potential of course

1534
01:37:58,610 --> 01:38:02,100
the new march from a to b which the charter your pocket no work is

1535
01:38:02,100 --> 01:38:03,750
done sort of potential

1536
01:38:04,840 --> 01:38:08,570
the same

1537
01:38:08,580 --> 01:38:10,380
i will change this the or

1538
01:38:10,400 --> 01:38:14,770
two different symbol which i call the l

1539
01:38:14,790 --> 01:38:16,910
the would mean

1540
01:38:17,000 --> 01:38:21,390
that we go from a to infinity along the straight line

1541
01:38:21,390 --> 01:38:22,860
and then we go from b

1542
01:38:22,880 --> 01:38:24,060
to infinity

1543
01:38:24,080 --> 01:38:25,850
along the straight line

1544
01:38:26,700 --> 01:38:29,520
it makes no difference how you go

1545
01:38:29,650 --> 01:38:32,180
you go from a to b

1546
01:38:32,240 --> 01:38:38,390
this potential difference and you go in this way

1547
01:38:38,460 --> 01:38:42,800
and we a minus b is not going to change

1548
01:38:42,810 --> 01:38:45,110
so if now i introduced here

1549
01:38:47,690 --> 01:38:49,630
elements dl

1550
01:38:49,630 --> 01:38:51,720
small vector

1551
01:38:51,770 --> 01:38:54,970
and if the local effect here

1552
01:38:54,980 --> 01:38:56,360
it's like so

1553
01:38:56,370 --> 01:38:58,950
at this point here

1554
01:39:00,420 --> 01:39:02,140
the miners

1555
01:39:02,150 --> 01:39:04,820
is then the integral of e dot

1556
01:39:05,750 --> 01:39:08,190
in other words i can replace the are

1557
01:39:08,200 --> 01:39:09,620
by an l

1558
01:39:09,620 --> 01:39:12,760
and you may choose any past

1559
01:39:12,820 --> 01:39:14,270
that you prefer

1560
01:39:14,330 --> 01:39:15,520
and that's the way

1561
01:39:15,580 --> 01:39:18,210
we will show you this equation most of the time

1562
01:39:18,320 --> 01:39:21,990
so it makes no difference how you march because we are dealing here with conservative

1563
01:39:25,270 --> 01:39:27,150
let's not make the assumption

1564
01:39:27,190 --> 01:39:30,150
thirty eight hundred fifty four

1565
01:39:30,240 --> 01:39:33,980
and that be for instance is fifty four

1566
01:39:34,020 --> 01:39:40,940
so it's a very specific example

1567
01:39:41,040 --> 01:39:43,420
what does it mean

1568
01:39:43,470 --> 01:39:45,790
it means that if i

1569
01:39:45,830 --> 01:39:48,790
but prosecutor charged in my pocket

1570
01:39:48,850 --> 01:39:51,270
and i come all the way from b seven

1571
01:39:51,310 --> 01:39:54,620
and i woke up to point b

1572
01:39:54,640 --> 01:39:56,710
walter lewin

1573
01:39:56,770 --> 01:39:58,750
plus q charge in his pocket

1574
01:39:58,810 --> 01:40:03,270
goes from lobby b seven

1575
01:40:03,310 --> 01:40:06,730
two point b

1576
01:40:06,770 --> 01:40:08,850
i have to do work

1577
01:40:08,890 --> 01:40:10,540
and the work i have to do

1578
01:40:10,540 --> 01:40:13,080
it is the product of my charge q

1579
01:40:13,080 --> 01:40:15,440
with the potential so that is q

1580
01:40:15,530 --> 01:40:17,210
the work i have to do

1581
01:40:17,310 --> 01:40:18,650
is q

1582
01:40:18,730 --> 01:40:23,290
time of the

1583
01:40:23,310 --> 01:40:27,290
so in this case it's fifty times q whatever that

1584
01:40:28,390 --> 01:40:29,960
that i have in mind

1585
01:40:30,020 --> 01:40:32,370
is in joules

1586
01:40:33,920 --> 01:40:36,120
i go from lobby seven

1587
01:40:36,170 --> 01:40:39,230
two point eight

1588
01:40:39,250 --> 01:40:42,020
have to do more work

1589
01:40:42,040 --> 01:40:43,440
i have to do

1590
01:40:43,480 --> 01:40:45,750
one hundred fifty

1591
01:40:45,810 --> 01:40:50,000
hugh joseph of work

1592
01:40:50,020 --> 01:40:52,690
you can think of it i first come to a to b

1593
01:40:52,770 --> 01:40:54,310
already exhausted

1594
01:40:54,330 --> 01:40:55,980
i have supported

1595
01:40:56,040 --> 01:40:57,710
work to get all the way

1596
01:40:57,710 --> 01:41:01,680
it does

1597
01:41:01,730 --> 01:41:04,490
and now

1598
01:41:04,510 --> 01:41:09,340
the magic trick is the rules with differentials are i can pick what ninety theta

1599
01:41:09,350 --> 01:41:12,110
is and calculate the corresponding the

1600
01:41:12,130 --> 01:41:13,550
the food

1601
01:41:13,570 --> 01:41:14,530
so now

1602
01:41:14,550 --> 01:41:18,270
what i do here as i say that's my

1603
01:41:18,270 --> 01:41:21,310
that's the be vector i want to multiply by the haitian

1604
01:41:21,330 --> 01:41:24,030
in in order to multiply by the haitian

1605
01:41:24,030 --> 01:41:27,910
i apply the vs the perturbation to my parameters

1606
01:41:27,950 --> 01:41:35,390
and i propagate that differential is an infinitesimal per perturbation i propagate through the system

1607
01:41:35,410 --> 01:41:39,600
that takes my parameter value and calculates the gradient

1608
01:41:39,620 --> 01:41:45,700
obviously i have called for doing this calculation lying around because i'm using gradient method

1609
01:41:45,700 --> 01:41:47,520
to optimize the system

1610
01:41:47,580 --> 01:41:53,580
so somewhere i have code that given the parameter value will calculate your data

1611
01:41:53,600 --> 01:41:57,100
i now need to augment the code to take

1612
01:41:57,120 --> 01:42:02,020
the differential an infinitesimal perturbation and propagate that as well

1613
01:42:03,460 --> 01:42:07,760
and that the output i get the haitian product with with that

1614
01:42:10,580 --> 01:42:12,630
this various ways to actually

1615
01:42:12,640 --> 01:42:18,730
implement this one thing for instance is there c plus plus classes out there

1616
01:42:18,770 --> 01:42:20,520
we're actually if you're

1617
01:42:20,530 --> 01:42:26,280
if you function that computes the gradient is coded in c plus plus using doubles

1618
01:42:26,330 --> 01:42:28,190
you can just

1619
01:42:28,230 --> 01:42:30,980
change all the doubles two

1620
01:42:31,030 --> 01:42:33,580
this special class

1621
01:42:33,590 --> 01:42:35,120
and include the

1622
01:42:35,130 --> 01:42:39,510
the declaration filed for that class and what that class does is it overloads the

1623
01:42:39,510 --> 01:42:46,290
entire math library to propagate perturbations alongside it just includes all these basic rules that

1624
01:42:46,630 --> 01:42:50,710
you know the derivative of sine is cosine and all that stuff

1625
01:42:50,710 --> 01:42:53,200
so it's really under the hood

1626
01:42:53,310 --> 01:42:57,720
nothing fancy going on but it's very convenient thing to happen

1627
01:42:57,740 --> 01:43:01,470
so that means and this is something that even in the field very few people

1628
01:43:01,470 --> 01:43:04,750
know if you have code to compute the gradient

1629
01:43:04,760 --> 01:43:06,440
with very little effort

1630
01:43:06,450 --> 01:43:10,320
you can get code to compute hash vector products out

1631
01:43:10,340 --> 01:43:15,040
and this can be done in the same time it takes for two to three

1632
01:43:15,050 --> 01:43:20,720
gradient evaluations because the code inherits the structure of the gradient computation

1633
01:43:20,750 --> 01:43:23,600
so it's the same order cost

1634
01:43:23,620 --> 01:43:29,110
and there's a constant factor of two to three that's more complex

1635
01:43:29,230 --> 01:43:30,270
so this is

1636
01:43:30,290 --> 01:43:36,270
these kinds of techniques are our research in the field called algorithmic differentiation which is

1637
01:43:36,500 --> 01:43:40,610
one of these interesting applied fields nowadays

1638
01:43:40,660 --> 01:43:43,890
and they have tools out there so you can actually just sort of use that

1639
01:43:43,890 --> 01:43:45,250
and plug it in

1640
01:43:45,270 --> 01:43:49,870
you don't have to actually called up the session vector product yourself

1641
01:43:50,800 --> 01:43:52,920
this looks like a huge problem

1642
01:43:52,930 --> 01:43:55,090
if you don't know this trick

1643
01:43:55,120 --> 01:43:59,060
but in fact it's it's not difficult at all

1644
01:43:59,140 --> 01:44:02,200
with the right tools and the right tricks this comes for free

1645
01:44:04,800 --> 01:44:05,710
so now

1646
01:44:05,720 --> 01:44:10,310
the whole algorithm is is not that hard to do

1647
01:44:10,330 --> 01:44:14,110
you have the parameter update you have the update for the game vector and you

1648
01:44:14,110 --> 01:44:15,800
have the update for the

1649
01:44:15,820 --> 01:44:20,590
and all you need is this session vector product that you get automatically from given

1650
01:44:20,590 --> 01:44:21,740
the right tools

1651
01:44:21,770 --> 01:44:27,450
there's another trick i don't think i'll have time for it but

1652
01:44:27,460 --> 01:44:30,240
you can actually do this if you're

1653
01:44:30,260 --> 01:44:34,840
programming in matlab you can call up the complex arithmetic to do the haitian vector

1654
01:44:34,840 --> 01:44:36,590
product for you

1655
01:44:36,620 --> 01:44:40,030
so that's another neat neat way to do it

1656
01:44:40,050 --> 01:44:43,470
in that case you don't have to change your code at all

1657
01:44:43,480 --> 01:44:46,660
because matlab code already takes complex numbers

1658
01:44:46,710 --> 01:44:51,260
all right

1659
01:44:54,500 --> 01:44:59,770
OK some more analysis of this update i think of a skip over that rather

1660
01:45:01,970 --> 01:45:05,760
you can start copying now that's all that

1661
01:45:05,770 --> 01:45:07,490
the risk here

1662
01:45:07,500 --> 01:45:14,790
if we pretend we keep the gradient and the haitian and the parameters and the

1663
01:45:14,790 --> 01:45:19,710
town everything else constant and we just iterate our be update

1664
01:45:19,720 --> 01:45:23,110
it would converge to the fixed point

1665
01:45:23,170 --> 01:45:28,130
and this fixed point looks like a levenberg marquardt gradient step so this slide is

1666
01:45:28,130 --> 01:45:32,550
actually only of interest to people in a little bit of optimisation

1667
01:45:32,570 --> 01:45:36,370
if you've heard of levenberg marquardt and what it does

1668
01:45:36,390 --> 01:45:42,350
looking back mark but basically multiplies the gradient by the inverse of the curvature matrix

1669
01:45:42,390 --> 01:45:46,320
and the curvature matrix is a mixture of the haitian

1670
01:45:46,330 --> 01:45:48,270
and the diagonal matrix

1671
01:45:48,310 --> 01:45:51,370
it also scales like the haitian

1672
01:45:51,390 --> 01:45:53,610
on the diagonal

1673
01:45:53,630 --> 01:45:58,500
and the funny thing is this fixed point actually has exactly the structure

1674
01:45:59,410 --> 01:46:04,040
what that means is that my algorithm to some extent is a stochastic approximation of

1675
01:46:04,070 --> 01:46:07,460
levenberg marquardt gradient procedure

1676
01:46:07,470 --> 01:46:12,250
of course it's not exact because i only iterate this ones

1677
01:46:12,260 --> 01:46:16,440
and then i update the parameters in the games before it to the next iteration

1678
01:46:16,450 --> 01:46:20,050
so this never actually converges

1679
01:46:20,080 --> 01:46:22,080
two to a fixed point

1680
01:46:22,090 --> 01:46:26,310
it it's keeps getting jostled around too much to do that but it's sort of

1681
01:46:26,310 --> 01:46:30,280
reassuring to know that if i were to iterate this more often

1682
01:46:30,280 --> 01:46:35,140
and this means so this is the interesting this is the same

1683
01:46:35,180 --> 01:46:38,320
this is the impossibility of

1684
01:46:38,340 --> 01:46:42,220
at least according to and this is the interesting machine because it means that the

1685
01:46:43,050 --> 01:46:44,510
popular algorithms

1686
01:46:45,860 --> 01:46:47,820
is still not explaining all the information

1687
01:46:54,090 --> 01:46:57,490
so this is the clustering is interesting summary

1688
01:46:58,110 --> 01:46:59,840
by the way these numbers

1689
01:46:59,860 --> 01:47:03,890
like when the regime change depends on how the problems like also that

1690
01:47:05,530 --> 01:47:09,970
so it's an expert in a number depends on the know how many dimensions how

1691
01:47:09,970 --> 01:47:15,090
many clusters and how separated and it gets harder motivate dimensions with more

1692
01:47:15,110 --> 01:47:16,300
i would love separation

1693
01:47:21,030 --> 01:47:24,550
if want

1694
01:47:24,680 --> 01:47:29,590
so we remember when my first thought about some of it is that the current

1695
01:47:29,630 --> 01:47:31,280
find out

1696
01:47:32,340 --> 01:47:38,030
i suspect some of you want to ask me how about this result was installed

1697
01:47:38,200 --> 01:47:41,410
that is

1698
01:47:41,430 --> 01:47:46,260
this separation that these problems you are much harder than the problems that can be

1699
01:47:46,260 --> 01:47:48,840
solved by the computer science

1700
01:47:48,860 --> 01:47:52,570
if you look at these and so on

1701
01:47:52,590 --> 01:47:58,110
basically they didn't want to the results online and then look at what

1702
01:47:58,130 --> 01:48:04,010
all these and are less so quickly after two you can find

1703
01:48:05,300 --> 01:48:07,200
not really benefit from

1704
01:48:07,430 --> 01:48:12,220
this approach much more than what was promised by the

1705
01:48:12,260 --> 01:48:14,070
this meant

1706
01:48:14,140 --> 01:48:19,410
so you know that of course one can those and practical what so there is

1707
01:48:19,410 --> 01:48:23,860
information that much when the clusters are much closer

1708
01:48:23,860 --> 01:48:28,680
of course that they expect computer science would catch up and get better

1709
01:48:28,700 --> 01:48:34,930
get the answer but i got it will actually allow for error and and make

1710
01:48:36,180 --> 01:48:40,490
situation more realistic

1711
01:48:41,260 --> 01:48:44,410
question because every new pages a different conditions song

1712
01:48:44,430 --> 01:48:49,280
this is the first question

1713
01:48:51,820 --> 01:48:55,260
stability is another

1714
01:48:56,860 --> 01:48:57,840
as i said

1715
01:49:00,490 --> 01:49:05,070
people use stability to find the number of clusters

1716
01:49:06,300 --> 01:49:07,800
the solution is not stable

1717
01:49:07,800 --> 01:49:10,720
you should be somewhat suspicious

1718
01:49:10,760 --> 01:49:20,240
and this is the stability means i have defined the previous

1719
01:49:20,260 --> 01:49:24,510
so basically if you find the that

1720
01:49:24,700 --> 01:49:26,200
clustering is

1721
01:49:26,260 --> 01:49:30,260
as stable to to small perturbations in here the this is one of the things

1722
01:49:30,260 --> 01:49:31,260
that you saw

1723
01:49:31,280 --> 01:49:36,240
like to classification error or the idea is that

1724
01:49:36,280 --> 01:49:37,510
four actually

1725
01:49:37,530 --> 01:49:39,950
so that

1726
01:49:39,970 --> 01:49:43,030
you're calling the clustering stable and you called the

1727
01:49:43,090 --> 01:49:45,840
there's a lot of

1728
01:49:46,990 --> 01:49:49,840
but people have confidence that if the solution is

1729
01:49:49,860 --> 01:49:54,660
but this is recovering some structure and so it's telling me what how many clusters

1730
01:49:54,720 --> 01:49:55,530
and that's

1731
01:49:55,570 --> 01:49:57,800
practice a

1732
01:49:59,180 --> 01:50:04,390
here are some very new results two thousand six or just a few months old

1733
01:50:04,390 --> 01:50:08,570
so what

1734
01:50:08,720 --> 01:50:12,740
basically this is a technical result in this is that apply to class

1735
01:50:12,820 --> 01:50:17,760
and they say so that the cost function by l

1736
01:50:18,140 --> 01:50:20,320
and i

1737
01:50:20,360 --> 01:50:24,180
i have a lot of so these were all in the limit of large data

1738
01:50:24,240 --> 01:50:27,640
but this plan for the first

1739
01:50:28,280 --> 01:50:34,570
they the following it to my data by some by

1740
01:50:34,590 --> 01:50:39,550
less than one of the world

1741
01:50:39,630 --> 01:50:43,260
then the expect to see in for example

1742
01:50:46,340 --> 01:50:50,550
is more than one was quite lot of

1743
01:50:50,550 --> 01:50:54,720
so any perturbation that smaller than the square root of n

1744
01:50:56,470 --> 01:51:00,800
i also has a very small effect on the

1745
01:51:00,820 --> 01:51:02,280
and for any k

1746
01:51:02,370 --> 01:51:02,950
so what

1747
01:51:03,030 --> 01:51:05,720
because level

1748
01:51:05,740 --> 01:51:07,930
so a particular version interpreter

1749
01:51:07,950 --> 01:51:13,930
result saying it doesn't matter what kaye's my cost like those not always be stable

1750
01:51:14,990 --> 01:51:17,070
no matter the cost

1751
01:51:17,910 --> 01:51:23,450
whereas this here we're saying for some k find similar results for some other cases

1752
01:51:23,450 --> 01:51:26,070
i find unstable results actions

1753
01:51:26,090 --> 01:51:28,470
there's difference one case with the other one is that

1754
01:51:28,660 --> 01:51:31,990
this i see no think about

1755
01:51:32,140 --> 01:51:36,570
or the structure of the day doesn't always make it so you see is that

1756
01:51:36,570 --> 01:51:38,370
it is one is

1757
01:51:38,390 --> 01:51:39,110
so have nothing to

1758
01:51:39,140 --> 01:51:42,470
with that distribution

1759
01:51:42,490 --> 01:51:45,640
and probably have to do with the initialisation

1760
01:51:49,200 --> 01:51:51,410
this is called summer look love

1761
01:51:51,410 --> 01:51:55,390
the which is the building main

1762
01:51:55,510 --> 01:51:58,260
however i i think it's the end of the story

1763
01:51:58,280 --> 01:52:05,990
because in particular is assumed actually finding the minimal in resulting in a very small

1764
01:52:08,280 --> 01:52:10,890
and it applies to many many more things

1765
01:52:11,160 --> 01:52:12,610
whole world

1766
01:52:12,640 --> 01:52:16,430
if you talk about clustering this assumes that you all to the minimum of the

1767
01:52:17,390 --> 01:52:18,840
and what do we have

1768
01:52:18,860 --> 01:52:20,780
most of the time you look for them

1769
01:52:22,410 --> 01:52:25,010
and so many other things that way

1770
01:52:25,070 --> 01:52:27,660
and the interplay that they actually do it

1771
01:52:27,660 --> 01:52:29,630
on the structure

1772
01:52:29,700 --> 01:52:34,840
like in particular you find something we something is stable with respect

1773
01:52:34,860 --> 01:52:36,530
then there is something

1774
01:52:36,550 --> 01:52:38,390
that you can make

1775
01:52:38,640 --> 01:52:41,030
you only be performed

1776
01:52:41,110 --> 01:52:45,910
correct number of clusters but there is something that that is to come

1777
01:52:52,280 --> 01:52:56,340
this is the last but one slide

1778
01:52:56,360 --> 01:53:00,550
by the way i haven't talked about lots of things like hierarchical clustering

1779
01:53:00,550 --> 01:53:05,640
i haven't talked about others other things that people do that are like clustering but

1780
01:53:05,640 --> 01:53:06,470
i'm not

1781
01:53:07,990 --> 01:53:13,630
classical clustering like clustering by subsets of attributes of finding

1782
01:53:13,640 --> 01:53:16,780
extracting clusters one by one from data

1783
01:53:16,800 --> 01:53:18,630
and the most of the times

1784
01:53:18,630 --> 01:53:19,910
on clusters

1785
01:53:19,930 --> 01:53:23,340
think the background and other things

1786
01:53:23,360 --> 01:53:26,640
but is something interesting is motivated by

1787
01:53:29,640 --> 01:53:31,610
basically practical issues

1788
01:53:32,110 --> 01:53:35,280
one of the exploration the end of one

1789
01:53:35,300 --> 01:53:42,280
you're many algorithms many times you try also the parameters of the doing

1790
01:53:42,360 --> 01:53:43,630
and then you go

1791
01:53:43,630 --> 01:53:45,590
a few hundred classics

1792
01:53:45,640 --> 01:53:49,590
and the i'm other going to promote some of them

1793
01:53:49,610 --> 01:53:52,070
maybe it doesn't make sense to me

1794
01:53:52,130 --> 01:53:55,680
o everything and keep just one cluster

1795
01:53:55,700 --> 01:53:59,890
which is the solution this these people try to solve the problem which is the

1796
01:53:59,890 --> 01:54:01,930
best class

1797
01:54:02,130 --> 01:54:04,010
it doesn't have to be that way

1798
01:54:04,030 --> 01:54:05,550
four one

1799
01:54:05,570 --> 01:54:07,700
you don't know anything about the

1800
01:54:07,700 --> 01:54:12,780
then maybe there is more than one meaningful way of thinking

1801
01:54:12,800 --> 01:54:17,410
like think of the people in this room can them depending on the intended use

1802
01:54:17,410 --> 01:54:20,930
you're going to get different clusterings

1803
01:54:20,950 --> 01:54:23,410
and if you if you not

1804
01:54:23,410 --> 01:54:33,220
the one two

1805
01:54:43,200 --> 01:54:47,230
so i'll move on to so something very well

1806
01:54:47,250 --> 01:54:54,450
move on so so basically models the people statistics will be used to model data

1807
01:54:54,460 --> 01:54:57,580
so let's go from there

1808
01:54:57,600 --> 01:55:00,150
and we

1809
01:55:00,210 --> 01:55:02,720
looking at

1810
01:55:02,750 --> 01:55:09,070
two main areas in terms of modelling which is a generalized linear model and

1811
01:55:09,830 --> 01:55:14,680
all topics are suppose special topic unusual bits

1812
01:55:14,710 --> 01:55:16,850
and then

1813
01:55:16,860 --> 01:55:25,060
they will look at so called multivariate analysis which is more exploratory trying to find

1814
01:55:25,060 --> 01:55:26,360
out what's going on or

1815
01:55:27,040 --> 01:55:28,910
trying to

1816
01:55:31,270 --> 01:55:32,580
the data into

1817
01:55:32,600 --> 01:55:34,100
more sustainable forms

1818
01:55:34,110 --> 01:55:36,990
continent so

1819
01:55:37,000 --> 01:55:40,250
take the regression and generalized linear model

1820
01:55:41,220 --> 01:55:43,210
well that's

1821
01:55:43,220 --> 01:55:46,880
what's called linear models to the first

1822
01:55:46,910 --> 01:55:52,100
politicians for the regression is

1823
01:55:52,580 --> 01:55:56,830
the simplest form of linear model

1824
01:55:56,830 --> 01:55:59,600
the linear model comes with the whole

1825
01:55:59,640 --> 01:56:06,300
battery of methods for working out what's the right model

1826
01:56:06,300 --> 01:56:12,220
and the basic idea is called the analysis of the silicon and then

1827
01:56:12,240 --> 01:56:13,350
well at

1828
01:56:13,390 --> 01:56:20,770
this is called generalized linear model based that's linear models these generalized linear models look

1829
01:56:21,070 --> 01:56:28,470
as well so so just john and mention analysis survival data but it was really

1830
01:56:28,490 --> 01:56:31,560
special case one of the other methods

1831
01:56:32,470 --> 01:56:36,530
so that's the first time so i want to talk about this because i think

1832
01:56:37,590 --> 01:56:38,570
if you

1833
01:56:38,590 --> 01:56:43,160
what to do any statistical course but involve modelling these are the models to be

1834
01:56:43,970 --> 01:56:48,600
i have to use and particularly bits of the first one regression model

1835
01:56:48,620 --> 01:56:52,910
so these are really heavily used models in statistics world

1836
01:56:52,940 --> 01:56:55,820
and essentially what you're trying to do

1837
01:56:55,820 --> 01:57:02,160
it is estimated what's called the trend in one variable based on the values taken

1838
01:57:02,160 --> 01:57:08,560
by the variables so we have the trend of what we call the output based

1839
01:57:09,290 --> 01:57:11,870
values for several input variables

1840
01:57:12,030 --> 01:57:13,220
so what

1841
01:57:16,320 --> 01:57:17,840
well here is

1842
01:57:17,850 --> 01:57:22,440
more formally we have

1843
01:57:22,470 --> 01:57:28,070
what we're looking at in regression is the question of how is a variable y

1844
01:57:28,220 --> 01:57:29,850
this one

1845
01:57:29,870 --> 01:57:32,780
related to

1846
01:57:32,790 --> 01:57:37,780
several variables colon one x two two xm so that's

1847
01:57:37,790 --> 01:57:40,820
could be any number we want really

1848
01:57:42,920 --> 01:57:45,700
just lost its

1849
01:57:49,870 --> 01:57:51,730
to create something back

1850
01:57:59,260 --> 01:58:05,650
the world to the y variable and we try to find out what's related to

1851
01:58:05,660 --> 01:58:08,010
build this is

1852
01:58:08,030 --> 01:58:10,230
generally called the response

1853
01:58:10,250 --> 01:58:15,150
all the dependent variable of the output so response because

1854
01:58:15,170 --> 01:58:20,000
the idea is that you alter the variable x variables and see how the y

1855
01:58:20,000 --> 01:58:22,590
value response to this variation

1856
01:58:22,600 --> 01:58:24,570
as political response

1857
01:58:24,600 --> 01:58:29,380
and request is the same idea

1858
01:58:29,410 --> 01:58:31,030
but basically i think so

1859
01:58:31,030 --> 01:58:32,660
this is the

1860
01:58:32,690 --> 01:58:36,190
i'm assuming that your computer science based on stops space

1861
01:58:38,090 --> 01:58:43,530
so use the frame the the terms used in electrical engineering from this sort of

1862
01:58:43,530 --> 01:58:48,860
thing which is the output and inputs so the axes are input variables otherwise the

1863
01:58:48,860 --> 01:58:52,680
output why do we want to do this

1864
01:58:52,760 --> 01:58:57,860
pierre for standard reasons for wanting to do

1865
01:58:57,890 --> 01:59:01,450
find the relationship between the output and inputs

1866
01:59:03,430 --> 01:59:06,810
the woman sort springs to mind actually is

1867
01:59:06,840 --> 01:59:08,210
it is this last one

1868
01:59:08,220 --> 01:59:10,970
but we think there is actually a model

1869
01:59:10,990 --> 01:59:16,640
relating the inputs the output the causal link between the two so

1870
01:59:16,680 --> 01:59:18,530
so that might be

1871
01:59:18,540 --> 01:59:22,330
an example of that sort of situation where there is a causal link between the

1872
01:59:22,350 --> 01:59:24,550
two is what's the temperature

1873
01:59:24,660 --> 01:59:26,470
and water ice cream sales

1874
01:59:26,480 --> 01:59:32,010
the temperature goes up screen cells go and process

1875
01:59:32,050 --> 01:59:36,710
and also means that there is the sum in many situations in natural way to

1876
01:59:36,710 --> 01:59:41,200
decide which is the output which is the input in that particular example

1877
01:59:41,210 --> 01:59:45,610
it would be stupid to have the temperature is the output

1878
01:59:45,640 --> 01:59:46,870
because it's not

1879
01:59:46,870 --> 01:59:51,240
so then you can so now we have we have have ostensibly group constant into

1880
01:59:52,930 --> 01:59:54,170
atomic terms

1881
01:59:54,250 --> 01:59:56,120
and then you can for the wrong we can

1882
01:59:56,170 --> 01:59:58,080
use these sentences

1883
01:59:59,900 --> 02:00:04,040
it even larger sentences and

1884
02:00:04,220 --> 02:00:10,360
using the logical connectives and you can at priors on the cars

1885
02:00:10,400 --> 02:00:11,740
so long

1886
02:00:12,520 --> 02:00:15,790
the standard logical operators AND OR NOT implies

1887
02:00:15,830 --> 02:00:19,930
all traffic to function value is

1888
02:00:19,980 --> 02:00:23,120
the is get is using this operator

1889
02:00:23,210 --> 02:00:25,280
but their arguments

1890
02:00:25,330 --> 02:00:27,540
the arguments of these operators can be

1891
02:00:27,770 --> 02:00:29,930
cycl sentences

1892
02:00:31,350 --> 02:00:33,720
so human operator and

1893
02:00:33,810 --> 02:00:35,490
the first arguement is

1894
02:00:36,550 --> 02:00:38,940
an argument is the other understand

1895
02:00:39,100 --> 02:00:41,290
this is this

1896
02:00:41,300 --> 02:00:42,970
this is true

1897
02:00:44,750 --> 02:00:48,440
and singles four or not and implies

1898
02:00:48,460 --> 02:00:55,310
o thing mentioned these quantifiers of quantification so we can have our universe

1899
02:00:55,330 --> 02:00:58,170
and you can have existential quantifiers

1900
02:00:59,180 --> 02:01:01,600
example of you know

1901
02:01:01,610 --> 02:01:04,350
these things are english should see every all

1902
02:01:04,370 --> 02:01:05,850
all this stuff like that

1903
02:01:06,010 --> 02:01:07,840
for example of

1904
02:01:07,840 --> 02:01:10,080
all of be

1905
02:01:10,100 --> 02:01:12,540
universal quantifier or

1906
02:01:12,560 --> 02:01:13,900
all course

1907
02:01:13,900 --> 02:01:18,730
every person in this room is alive so for each expert it's person

1908
02:01:18,750 --> 02:01:20,940
and he is alive

1909
02:01:20,940 --> 02:01:23,400
is for all x this would be

1910
02:01:23,410 --> 02:01:26,220
universal want quantifiers

1911
02:01:26,240 --> 02:01:28,350
we can write this in

1912
02:01:28,360 --> 02:01:30,520
i think like this

1913
02:01:30,580 --> 02:01:32,680
so this is

1914
02:01:32,690 --> 02:01:36,160
like using universal quantification

1915
02:01:36,170 --> 02:01:38,650
so in the one to tell the all orthodox here

1916
02:01:38,670 --> 02:01:40,460
i would say it all

1917
02:01:42,880 --> 02:01:44,780
was there

1918
02:01:44,830 --> 02:01:46,330
auc is

1919
02:01:46,390 --> 02:01:48,220
belongs to collection dong

1920
02:01:48,290 --> 02:01:49,720
then the

1921
02:01:51,610 --> 02:01:54,140
so anatomical body part

1922
02:01:54,170 --> 02:01:56,930
this so this is that like

1923
02:01:56,940 --> 02:01:58,880
four orthodox it is just

1924
02:01:58,930 --> 02:02:00,670
as it can be anything

1925
02:02:00,720 --> 02:02:03,420
and then you go in

1926
02:02:03,430 --> 02:02:05,850
implies so this from this first thing so if

1927
02:02:05,860 --> 02:02:08,110
dog belongs to this collection then

1928
02:02:08,130 --> 02:02:10,590
this sort

1929
02:02:10,640 --> 02:02:12,110
this is another

1930
02:02:12,540 --> 02:02:15,630
a bit more complex rules

1931
02:02:15,690 --> 02:02:17,790
can you say put all persons so is the

1932
02:02:17,810 --> 02:02:20,900
every person in this room is alive so here is a

1933
02:02:21,130 --> 02:02:22,890
this implies

1934
02:02:23,030 --> 02:02:25,580
and then it will connect things together first

1935
02:02:25,620 --> 02:02:28,120
that person is actually

1936
02:02:28,130 --> 02:02:30,370
the second constraint is the person

1937
02:02:30,420 --> 02:02:32,510
obj is found in this room

1938
02:02:32,530 --> 02:02:35,930
so if this

1939
02:02:36,080 --> 02:02:37,930
all these things are true

1940
02:02:37,970 --> 02:02:42,210
then this assertion cause is like this would be


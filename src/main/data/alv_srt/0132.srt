1
00:00:00,000 --> 00:00:01,770
it could be a collection of

2
00:00:01,770 --> 00:00:06,250
you know i don't know batting averages of somebody rather it could be arbitrary collections

3
00:00:06,250 --> 00:00:09,520
that you've come up with another ways before is again going to let you walk

4
00:00:09,520 --> 00:00:13,500
through them so it doesn't have to be something that could be described

5
00:00:15,040 --> 00:00:19,830
such as and wanted to to the previous element it could be any arbitrary collection

6
00:00:19,850 --> 00:00:22,270
you have already use that again i just put it on your hand i could

7
00:00:22,270 --> 00:00:25,540
go back and rewrite the thing that i had previously for finding the the the

8
00:00:25,700 --> 00:00:30,020
the square root of the perfect squares just using the for loop

9
00:00:31,100 --> 00:00:36,120
and i want to do that was go on to tertiary go back to

10
00:00:36,120 --> 00:00:38,270
my advisor examples

11
00:00:38,330 --> 00:00:42,410
conservative could try again i got to number one find the devices right now what

12
00:00:42,410 --> 00:00:44,750
my code is doing is is printing for me

13
00:00:44,770 --> 00:00:46,500
which is useful

14
00:00:46,540 --> 00:00:49,470
but imagine i actually wanted to gather them together

15
00:00:49,520 --> 00:00:52,480
i wanted to collect so i could do something with

16
00:00:52,540 --> 00:00:55,850
one out of my mind multiplying together might want to do that know something else

17
00:00:55,850 --> 00:00:59,770
with find common divisors of things by looking at them

18
00:00:59,830 --> 00:01:03,140
i need in fact a way to make explicit what i can do that with

19
00:01:03,140 --> 00:01:07,040
ranges i need a way to collect things together

20
00:01:07,080 --> 00:01:10,250
and that's going to be the first of our more compound data structures and we

21
00:01:10,250 --> 00:01:12,430
have exactly such a structure

22
00:01:12,430 --> 00:01:17,810
it's called a tuple

23
00:01:17,810 --> 00:01:30,290
this is an ordered sequence

24
00:01:32,350 --> 00:01:34,950
now i'm going to actually add something to it it's gonna make sense in a

25
00:01:34,950 --> 00:01:37,080
little while or couple lectures

26
00:01:37,100 --> 00:01:39,730
which is it is immutable

27
00:01:41,640 --> 00:01:45,250
meaning i cannot change it will see why that's important later on but for now

28
00:01:45,270 --> 00:01:46,120
to pull

29
00:01:46,950 --> 00:01:49,750
this ordered sequence of structures

30
00:01:49,770 --> 00:01:52,160
and how do i create them

31
00:01:52,210 --> 00:01:56,250
well the representation is

32
00:01:58,330 --> 00:01:59,770
square brackets

33
00:01:59,790 --> 00:02:10,000
followed by a sequence of elements separated by commas followed by close square brackets

34
00:02:10,100 --> 00:02:13,700
that's really what i said it is an ordered sequence of elements

35
00:02:13,710 --> 00:02:15,560
you can see where they are

36
00:02:15,580 --> 00:02:19,560
OK so let me do a little example of this i go back over here

37
00:02:19,560 --> 00:02:24,330
let's define

38
00:02:24,430 --> 00:02:31,930
a type type

39
00:02:32,010 --> 00:02:34,310
we can look at the value of test

40
00:02:34,350 --> 00:02:35,970
in the ordered sequence

41
00:02:35,980 --> 00:02:37,850
i need to get elements out of it

42
00:02:37,890 --> 00:02:40,730
so again i have a way of doing that in particular

43
00:02:40,810 --> 00:02:42,700
i can ask for

44
00:02:42,750 --> 00:02:48,270
the zero element of test notice and putting square brackets around it

45
00:02:48,290 --> 00:02:49,790
it gives me

46
00:02:49,790 --> 00:02:56,520
i know this sounds confusing but this is a long tradition it gives me yes

47
00:02:56,560 --> 00:03:04,230
so i

48
00:03:04,250 --> 00:03:07,370
i created list here and thank you

49
00:03:07,370 --> 00:03:12,160
and you guys are on top of your saying i want

50
00:03:15,910 --> 00:03:18,080
OK so i

51
00:03:18,100 --> 00:03:20,850
you can see why this was mistaken little well i did not want to make

52
00:03:20,850 --> 00:03:23,560
a list i wanted to create a tuple thank you for catching and i want

53
00:03:23,600 --> 00:03:26,140
my friends not square brackets there

54
00:03:26,180 --> 00:03:29,430
also see well why both of these things work this way but is not what

55
00:03:29,430 --> 00:03:30,390
i wanted

56
00:03:31,500 --> 00:03:34,830
so i guess i should go back and let me do this correctly this way

57
00:03:34,950 --> 00:03:44,390
you can look at test

58
00:03:44,410 --> 00:03:48,250
i guess test now if only get the element notes

59
00:03:48,310 --> 00:03:49,560
angle bracket are

60
00:03:49,560 --> 00:03:53,500
we're broadcaster one square brackets what i thought OK

61
00:03:53,520 --> 00:03:56,230
now can go back to where i was which is a strange piece of history

62
00:03:56,230 --> 00:03:59,080
which is we start counting at zero

63
00:03:59,080 --> 00:04:00,330
so the

64
00:04:00,390 --> 00:04:05,200
hate sits with the first element of this to pull his position zero or index

65
00:04:05,200 --> 00:04:10,620
zero OK so i can get the zero one out i can get

66
00:04:10,660 --> 00:04:14,270
i do to get the third thing out because it was zero one two

67
00:04:14,270 --> 00:04:17,710
notice however if i do

68
00:04:17,730 --> 00:04:20,910
something that tries to go outside

69
00:04:20,950 --> 00:04:23,520
the length of the two but complaints

70
00:04:25,270 --> 00:04:28,640
two balls also have another nice structure which is i can go the other direction

71
00:04:28,640 --> 00:04:32,980
which is if i want to get the last element

72
00:04:32,980 --> 00:04:34,140
of the two people

73
00:04:34,220 --> 00:04:37,700
i give it a negative index imagine you think about as starting right just before

74
00:04:37,700 --> 00:04:39,120
the beginning of the thing

75
00:04:39,230 --> 00:04:41,350
i give it to zero is going to take the first one of the other

76
00:04:41,350 --> 00:04:43,980
one is going to take the next one but go the other direction if i

77
00:04:43,980 --> 00:04:46,100
give it a minus one

78
00:04:46,230 --> 00:04:49,040
except the last element of the two form

79
00:04:49,120 --> 00:04:52,450
again i can go minus two

80
00:04:53,750 --> 00:04:56,430
so this is what we would call selection

81
00:04:56,450 --> 00:05:01,270
we can do things like ooh

82
00:05:03,140 --> 00:05:04,410
get out

83
00:05:06,660 --> 00:05:08,580
i can also pick up pieces

84
00:05:08,600 --> 00:05:11,020
of the two people

85
00:05:11,060 --> 00:05:14,620
you know i want to show you the format here if i

86
00:05:14,660 --> 00:05:17,250
give it this strange expression

87
00:05:17,370 --> 00:05:22,060
this is saying i want to get the pieces the tuple starting at index one

88
00:05:22,080 --> 00:05:28,040
the the second element and going up to but not including index three

89
00:05:28,080 --> 00:05:29,660
gives me back

90
00:05:29,680 --> 00:05:30,870
that piece

91
00:05:30,870 --> 00:05:32,790
actually copied that piece

92
00:05:32,830 --> 00:05:33,930
the two people

93
00:05:34,230 --> 00:05:36,750
this is called slicing

94
00:05:36,750 --> 00:05:49,850
and just to complete this to other nice things you can do with slices

95
00:05:49,910 --> 00:05:53,540
or you can get the beginning of the end

96
00:05:53,580 --> 00:05:54,580
the two people

97
00:05:54,600 --> 00:05:57,410
so for example if i say test and i don't give it to start to

98
00:05:57,410 --> 00:05:58,270
give it

99
00:05:58,330 --> 00:06:00,370
and then it gives me all the elements

100
00:06:00,370 --> 00:06:01,040
up to

101
00:06:01,060 --> 00:06:02,790
o point

102
00:06:02,930 --> 00:06:09,700
and i can obviously do the other direction which is

103
00:06:09,790 --> 00:06:12,160
i can say skip two

104
00:06:12,160 --> 00:06:16,880
then the compound under these things

105
00:06:16,990 --> 00:06:22,600
the idea is of course you can translate all the implications and things into the

106
00:06:24,050 --> 00:06:30,070
the conjunction and disjunction and then you can drive negation inside everything else

107
00:06:30,700 --> 00:06:32,680
so if you take you have

108
00:06:32,720 --> 00:06:38,070
something of the form not a and b you can transform it into not a

109
00:06:38,080 --> 00:06:42,270
or not be where the negation has been driven down inside

110
00:06:42,320 --> 00:06:45,700
and you can keep doing that until the negations if if any

111
00:06:45,780 --> 00:06:48,360
are of atoms

112
00:06:48,370 --> 00:06:50,580
and that's

113
00:06:50,630 --> 00:06:51,860
a useful

114
00:06:51,880 --> 00:06:54,110
normal form

115
00:06:54,120 --> 00:06:56,790
we can do more

116
00:06:56,840 --> 00:06:59,970
we can insist for example

117
00:06:59,980 --> 00:07:02,300
that's in this

118
00:07:02,420 --> 00:07:05,460
formula in this form

119
00:07:05,470 --> 00:07:08,790
the so-called and all graphs

120
00:07:09,680 --> 00:07:11,960
for example all the

121
00:07:12,010 --> 00:07:18,460
all the conjunctions are inside the disjunctions of experts the disjunction is inside the conjunctions

122
00:07:18,560 --> 00:07:23,480
and that gives it a couple of other normal forms conjunctive normal form

123
00:07:23,560 --> 00:07:28,280
disjunctive normal form

124
00:07:28,330 --> 00:07:29,150
of which can

125
00:07:29,160 --> 00:07:32,270
the most important for now

126
00:07:35,130 --> 00:07:37,110
on form

127
00:07:39,410 --> 00:07:47,180
a formula in conjunctive normal form

128
00:07:47,280 --> 00:07:50,320
is a conjunction

129
00:07:50,370 --> 00:07:56,340
possibly with several conjunction conjunction is associative commutative and so on so this is all

130
00:07:57,910 --> 00:08:00,690
the to conjunction and each of the formula here

131
00:08:00,700 --> 00:08:05,510
is the disjunction

132
00:08:05,520 --> 00:08:08,570
and each of the formula here

133
00:08:09,640 --> 00:08:11,780
an atom

134
00:08:11,840 --> 00:08:16,900
or a negated atoms

135
00:08:17,080 --> 00:08:18,710
OK and that's

136
00:08:18,750 --> 00:08:24,430
useful normal form this is stated for propositional logic but it works for first order

137
00:08:24,430 --> 00:08:27,240
logic as well you can have variables and things

138
00:08:27,250 --> 00:08:28,550
in there

139
00:08:28,560 --> 00:08:31,980
and in some ways you can get rid of the quantifiers are not going to

140
00:08:31,980 --> 00:08:37,470
talk about that today i think peter baumgartner is going to talk about it later

141
00:08:37,480 --> 00:08:40,980
in the week

142
00:08:41,000 --> 00:08:47,480
this is

143
00:08:47,560 --> 00:08:49,520
formula in this

144
00:08:51,770 --> 00:08:54,130
can really be thought of as

145
00:08:54,140 --> 00:08:56,260
equivalent to a set of

146
00:08:56,310 --> 00:08:59,570
formulae can you can take these conjuncts here

147
00:08:59,590 --> 00:09:02,420
and the only thing that matters about them is set

148
00:09:02,600 --> 00:09:07,500
it doesn't matter what order they come in something like that

149
00:09:07,570 --> 00:09:13,900
so you can think of the formulas having an equivalent

150
00:09:13,910 --> 00:09:17,070
consisting of a set of these

151
00:09:17,110 --> 00:09:19,840
primitive disjunctions

152
00:09:19,890 --> 00:09:23,510
sort of conjoined clear certain

153
00:09:23,520 --> 00:09:26,740
and so you can do the same again this set of primitive

154
00:09:26,750 --> 00:09:29,590
this is this this is the disjunction here

155
00:09:29,600 --> 00:09:35,560
because disjunction is also associative commutative idempotent all those things

156
00:09:35,570 --> 00:09:38,040
this also you can think of it just as i said the only thing that

157
00:09:38,040 --> 00:09:42,640
matters about it is the set of atoms and the set of negated atoms

158
00:09:42,680 --> 00:09:46,530
so a convenient way to think about it in fact has two sets the positive

159
00:09:46,530 --> 00:09:49,720
stuff and the negative stuff

160
00:09:49,770 --> 00:09:52,790
and that's me two sets of atoms

161
00:09:55,260 --> 00:10:04,350
ignoring the apparatus of quantifiers and variables for the moment just just thinking about propositional

162
00:10:06,030 --> 00:10:07,990
we can represent

163
00:10:08,220 --> 00:10:10,940
all formulae therefore

164
00:10:10,990 --> 00:10:13,460
in that kind of form

165
00:10:14,760 --> 00:10:16,630
i'm going to say

166
00:10:16,650 --> 00:10:18,680
but this is this is

167
00:10:18,720 --> 00:10:20,170
this is

168
00:10:20,210 --> 00:10:21,970
quest quite important for

169
00:10:21,980 --> 00:10:24,430
especially for automated reasoning

170
00:10:24,440 --> 00:10:28,720
i'm going to say that the clause

171
00:10:32,600 --> 00:10:34,420
a pair of sets

172
00:10:34,430 --> 00:10:38,250
of app of atoms in atomic formulae

173
00:10:39,480 --> 00:10:42,690
it's the pair

174
00:10:42,700 --> 00:10:44,360
the college

175
00:10:44,510 --> 00:10:48,880
positive and negative

176
00:10:50,870 --> 00:10:52,540
of sets

177
00:10:52,730 --> 00:10:59,350
of atomic formulae

178
00:10:59,520 --> 00:11:04,890
so no no connectives in here at all just atoms

179
00:11:05,120 --> 00:11:09,080
and we really thinking of it is the disjunction

180
00:11:09,130 --> 00:11:11,270
OK with a with these things

181
00:11:11,320 --> 00:11:16,940
negated in these things not negate

182
00:11:16,990 --> 00:11:18,470
all right

183
00:11:20,210 --> 00:11:25,790
we can think of any formula is equivalent to a set of clauses

184
00:11:25,800 --> 00:11:29,070
OK the this one this one this one this one

185
00:11:30,030 --> 00:11:33,100
and that's important for automated deduction because there's some

186
00:11:34,280 --> 00:11:39,710
machine oriented reasoning that you can do unpleasant

187
00:11:41,260 --> 00:11:44,390
what i mentioned that say i was talking about proof theory

188
00:11:44,450 --> 00:11:47,850
well because i want to think about algorithm

189
00:11:49,730 --> 00:11:52,410
an algorithm for taking any formula

190
00:11:52,420 --> 00:11:54,850
or a set of formulae

191
00:11:54,860 --> 00:11:58,220
and reducing it to close form

192
00:12:02,580 --> 00:12:06,580
this is going to go through an ocean

193
00:12:06,590 --> 00:12:10,820
the generalized clause

194
00:12:10,900 --> 00:12:14,830
which is just going to be a pair

195
00:12:17,280 --> 00:12:18,570
of sets

196
00:12:19,760 --> 00:12:23,100
of formulae

197
00:12:23,170 --> 00:12:28,280
not necessarily atoms

198
00:12:32,410 --> 00:12:37,360
the idea is that this is the disjunction of some of the negated some of

199
00:12:37,360 --> 00:12:39,170
them not negated

200
00:12:39,180 --> 00:12:43,130
and we're going to reduce our

201
00:12:43,140 --> 00:12:45,580
a formula we start with

202
00:12:46,310 --> 00:12:51,990
well we can think of it as set of general general clauses generalized clauses and

203
00:12:51,990 --> 00:12:55,930
we're going to reduce it to simpler and simpler ones until they eventually we have

204
00:12:59,130 --> 00:13:01,920
so how does the algorithm goal

205
00:13:01,930 --> 00:13:06,980
we've got the original formula a which has got all sorts of

206
00:13:07,030 --> 00:13:09,220
connected and stuff in it

207
00:13:09,270 --> 00:13:10,750
might have any arrows

208
00:13:10,760 --> 00:13:12,110
corners and

209
00:13:12,120 --> 00:13:16,140
other stuff in it

210
00:13:18,350 --> 00:13:22,580
we think of that

211
00:13:24,090 --> 00:13:26,170
as g clause

212
00:13:26,220 --> 00:13:28,310
in which the positive set

213
00:13:28,320 --> 00:13:30,700
just consists i

214
00:13:30,710 --> 00:13:32,390
and the negative set

215
00:13:32,410 --> 00:13:34,820
is empty

216
00:13:35,040 --> 00:13:37,360
all right

217
00:13:37,460 --> 00:13:39,780
and that's our first

218
00:13:39,900 --> 00:13:43,490
so first state were well it's just that set

219
00:13:43,620 --> 00:13:46,260
it consists of exactly one

220
00:13:46,260 --> 00:13:49,050
this function is very curved

221
00:13:49,050 --> 00:13:53,280
it's like this

222
00:13:53,290 --> 00:13:55,410
then so that's high curvature

223
00:13:55,420 --> 00:13:58,320
then you want to take a small step

224
00:13:58,390 --> 00:14:04,930
and even low curvature then you want to take a big step and

225
00:14:05,730 --> 00:14:08,320
you would

226
00:14:08,630 --> 00:14:10,610
but it

227
00:14:10,630 --> 00:14:13,790
you put the second derivative into this formula also

228
00:14:13,810 --> 00:14:17,710
but computationally

229
00:14:17,760 --> 00:14:23,880
second derivative methods very tricky

230
00:14:23,900 --> 00:14:25,960
the second derivative can be

231
00:14:25,980 --> 00:14:33,060
it can be difficult to compute it can be numerically unstable and it's got another

232
00:14:33,060 --> 00:14:36,120
disadvantage that i'll mention in

233
00:14:36,130 --> 00:14:37,420
a few minutes

234
00:14:45,200 --> 00:14:49,240
look almost whatever method we want to use to

235
00:14:49,290 --> 00:14:55,200
maximize conditional likelihood on training just to go question we need to compute this derivative

236
00:14:55,270 --> 00:14:59,210
divide the data of the log conditional likelihood so

237
00:14:59,230 --> 00:15:03,820
my now that's what i'm going to

238
00:15:03,870 --> 00:15:06,660
evaluate and it turns out to have

239
00:15:11,210 --> 00:15:15,480
it comes out to be a very elegant expressions which it comes out to be

240
00:15:15,480 --> 00:15:20,650
something very similar for the general case of log linear models

241
00:15:23,200 --> 00:15:24,740
OK so

242
00:15:25,930 --> 00:15:29,740
i have my parameters

243
00:15:31,180 --> 00:15:34,120
and they don't want

244
00:15:34,160 --> 00:15:35,790
debated d

245
00:15:35,850 --> 00:15:36,660
so now

246
00:15:36,680 --> 00:15:40,660
first in the simplify

247
00:15:40,710 --> 00:15:41,460
trying to

248
00:15:43,460 --> 00:15:44,880
alpha equals

249
00:15:44,900 --> 00:15:47,020
later zero

250
00:15:49,150 --> 00:15:51,120
let x zero

251
00:15:51,140 --> 00:15:52,840
equals one

252
00:15:52,840 --> 00:15:55,050
for every

253
00:15:55,060 --> 00:15:56,680
x far

254
00:15:59,210 --> 00:16:01,610
the expression that i had was

255
00:16:01,670 --> 00:16:03,310
alpha plus

256
00:16:03,330 --> 00:16:06,090
some from i corps one

257
00:16:06,120 --> 00:16:07,550
to die

258
00:16:08,300 --> 00:16:12,080
jake was one the debated jxj

259
00:16:12,120 --> 00:16:16,770
and so now this simplification that is going to be

260
00:16:16,810 --> 00:16:19,430
some from j equals zero

261
00:16:19,440 --> 00:16:20,720
to d

262
00:16:20,770 --> 00:16:23,610
of beta jxj

263
00:16:25,430 --> 00:16:27,440
i can

264
00:16:27,490 --> 00:16:31,460
i don't have to tweak our first separately from the vedas i can just read

265
00:16:31,460 --> 00:16:34,110
all the data is the same

266
00:16:38,280 --> 00:16:39,770
so now

267
00:16:43,970 --> 00:16:47,590
i want to evaluate

268
00:16:47,640 --> 00:16:50,120
so dividing data

269
00:16:51,360 --> 00:16:54,800
of the log conditional likelihood

270
00:16:54,810 --> 00:16:58,270
for all j

271
00:17:01,190 --> 00:17:04,440
like conditional likelihood

272
00:17:04,460 --> 00:17:06,520
this the sum

273
00:17:06,530 --> 00:17:08,690
i equals

274
00:17:08,710 --> 00:17:11,310
one to n

275
00:17:13,240 --> 00:17:16,430
the probability of why i given

276
00:17:16,430 --> 00:17:18,650
x y

277
00:17:21,520 --> 00:17:25,250
the they parameters

278
00:17:31,490 --> 00:17:36,720
really clear why this is the log conditional likelihood

279
00:17:38,900 --> 00:17:41,430
i'm going to separate these out into two parts

280
00:17:41,440 --> 00:17:43,520
so the

281
00:17:43,560 --> 00:17:48,080
such that y equals one

282
00:17:52,220 --> 00:17:55,400
they are such that y i

283
00:17:55,460 --> 00:17:57,620
equals zero

284
00:17:58,310 --> 00:18:00,310
every training example

285
00:18:00,320 --> 00:18:02,870
has a particular value for y i

286
00:18:02,920 --> 00:18:06,370
and that particular value is going to be either zero or one

287
00:18:06,370 --> 00:18:10,170
so i can just group the training examples according to the value of the y

288
00:18:11,700 --> 00:18:13,880
and so

289
00:18:13,930 --> 00:18:19,640
this will probably be one given x i

290
00:18:19,740 --> 00:18:23,010
and then the probability is zero

291
00:18:25,240 --> 00:18:28,200
x y

292
00:18:28,250 --> 00:18:29,980
data OK

293
00:18:29,990 --> 00:18:37,530
and the reason i'm doing this separation is that you know the formula for probably

294
00:18:38,880 --> 00:18:41,930
is different from the formula for public of zero

295
00:18:41,940 --> 00:18:46,300
so i'm going to treat these separately

296
00:19:04,380 --> 00:19:06,060
by debated j

297
00:19:06,080 --> 00:19:08,950
a lot conditional likelihood

298
00:19:08,980 --> 00:19:11,700
so remember that the derivative of the some

299
00:19:11,730 --> 00:19:15,120
it is the sum of the derivatives

300
00:19:16,990 --> 00:19:18,200
this is

301
00:19:18,220 --> 00:19:22,750
so some from my such that y equals one

302
00:19:23,970 --> 00:19:26,930
by david j

303
00:19:31,510 --> 00:19:36,240
so what i forgot to log in here

304
00:19:36,250 --> 00:19:39,680
the likely the likelihood would be the product of the probabilities

305
00:19:39,690 --> 00:19:43,450
and the log likelihood is the sum of the log probability

306
00:19:44,620 --> 00:19:46,860
i need

307
00:19:46,910 --> 00:19:51,200
to put in these locks

308
00:19:51,200 --> 00:19:52,680
she formation

309
00:19:53,470 --> 00:19:55,790
not sure what we

310
00:19:55,840 --> 00:19:58,000
the company

311
00:19:58,020 --> 00:20:00,310
to solve the problem

312
00:20:01,980 --> 00:20:03,700
it's is

313
00:20:03,710 --> 00:20:09,330
so this is the last twenty years not

314
00:20:09,350 --> 00:20:13,920
the first is that the child child

315
00:20:14,350 --> 00:20:18,060
so the notion of this

316
00:20:18,060 --> 00:20:21,140
this is a

317
00:20:21,230 --> 00:20:22,700
these are just

318
00:20:22,710 --> 00:20:24,560
o control

319
00:20:24,570 --> 00:20:26,540
could say

320
00:20:26,560 --> 00:20:28,060
this is so

321
00:20:29,020 --> 00:20:29,890
this small

322
00:20:35,360 --> 00:20:38,780
interesting is also

323
00:20:38,790 --> 00:20:42,280
can be elliptical

324
00:20:42,280 --> 00:20:44,710
can you say

325
00:20:48,950 --> 00:20:52,360
she which variety of

326
00:20:53,730 --> 00:20:56,320
and most of this two

327
00:20:56,340 --> 00:20:59,010
short scale so to

328
00:20:59,010 --> 00:21:02,280
these are some of the system

329
00:21:02,290 --> 00:21:05,150
so this

330
00:21:05,180 --> 00:21:10,100
so that's the of the

331
00:21:10,120 --> 00:21:11,540
it's one

332
00:21:11,580 --> 00:21:15,870
the first is that the first

333
00:21:15,900 --> 00:21:17,560
and also

334
00:21:17,570 --> 00:21:18,820
the complexity

335
00:21:18,820 --> 00:21:21,480
for instance

336
00:21:21,510 --> 00:21:25,730
she was the first on

337
00:21:25,730 --> 00:21:30,570
so far we consider for instance for it was

338
00:21:31,730 --> 00:21:35,290
this is just to

339
00:21:35,420 --> 00:21:37,150
two meetings of

340
00:21:41,200 --> 00:21:47,730
precision which so you can't sell three three

341
00:21:49,650 --> 00:21:51,540
when one thousand five

342
00:21:51,590 --> 00:21:57,250
we use this information in is the first

343
00:21:57,260 --> 00:21:58,970
even is that

344
00:21:59,820 --> 00:22:04,160
in fact results from places such actually special

345
00:22:06,100 --> 00:22:08,440
the solution is

346
00:22:08,450 --> 00:22:11,100
three hundred of thousands of

347
00:22:15,480 --> 00:22:18,070
this is

348
00:22:18,250 --> 00:22:21,160
the this is because

349
00:22:21,170 --> 00:22:22,800
this a

350
00:22:22,820 --> 00:22:25,130
for some reason

351
00:22:25,140 --> 00:22:30,380
and this is florida which is both

352
00:22:30,630 --> 00:22:38,360
and the ricci as above plus the just pull it

353
00:22:38,420 --> 00:22:39,980
the extent

354
00:22:40,160 --> 00:22:41,980
so i guess

355
00:22:42,010 --> 00:22:43,510
it was

356
00:22:43,510 --> 00:22:51,320
this is the reason is that system

357
00:22:51,330 --> 00:22:54,130
this is all

358
00:22:54,160 --> 00:22:55,770
of course such

359
00:22:57,130 --> 00:22:59,660
a lot of people

360
00:23:00,480 --> 00:23:02,880
four thousand

361
00:23:05,260 --> 00:23:09,350
this should be done

362
00:23:09,580 --> 00:23:11,720
this is just

363
00:23:11,890 --> 00:23:17,510
is a small just

364
00:23:18,500 --> 00:23:20,540
we see some

365
00:23:21,670 --> 00:23:22,790
he he

366
00:23:25,890 --> 00:23:28,420
six months

367
00:23:29,750 --> 00:23:36,100
obviously so any this image that is not the first to

368
00:23:38,350 --> 00:23:40,770
in the previous

369
00:23:40,820 --> 00:23:45,850
so you don't have to make it is

370
00:23:45,910 --> 00:23:50,730
structure dawkins the construction which

371
00:23:50,850 --> 00:23:54,500
that's what i want to write

372
00:23:55,350 --> 00:23:57,820
this is one of the

373
00:23:57,820 --> 00:24:01,670
the most complex structure in

374
00:24:02,040 --> 00:24:07,120
although both sides of of the best business schools in my

375
00:24:07,890 --> 00:24:11,430
she should shown

376
00:24:11,450 --> 00:24:13,900
we see

377
00:24:16,110 --> 00:24:18,260
so this part

378
00:24:18,280 --> 00:24:20,430
the final decision function

379
00:24:20,450 --> 00:24:24,870
this is in contrast to

380
00:24:24,890 --> 00:24:28,190
and this is the

381
00:24:28,200 --> 00:24:30,280
this is

382
00:24:30,380 --> 00:24:31,620
at each

383
00:24:35,310 --> 00:24:38,360
he was

384
00:24:38,380 --> 00:24:40,500
so many of his friends

385
00:24:40,510 --> 00:24:44,200
this is just one

386
00:24:44,200 --> 00:24:47,410
and in order in which should

387
00:24:48,040 --> 00:24:51,710
i wasn't sure what is the user right as

388
00:24:51,730 --> 00:24:54,260
but some of this

389
00:24:54,270 --> 00:24:56,020
six thousand range

390
00:24:56,040 --> 00:24:59,400
four seconds or so for the

391
00:24:59,400 --> 00:25:03,850
there no standard deviation the tree

392
00:25:03,860 --> 00:25:07,670
and here is the username and things they

393
00:25:07,680 --> 00:25:09,130
this is summary

394
00:25:09,150 --> 00:25:13,250
so we allow these two

395
00:25:14,970 --> 00:25:18,140
and will

396
00:25:18,150 --> 00:25:18,910
on the

397
00:25:19,600 --> 00:25:25,690
people who were in the image systems to make

398
00:25:33,090 --> 00:25:34,130
he was

399
00:25:41,770 --> 00:25:43,670
the tail

400
00:25:43,680 --> 00:25:45,230
o two two one

401
00:25:45,250 --> 00:25:47,350
average called precision

402
00:25:47,380 --> 00:25:50,000
recall and precision

403
00:25:50,020 --> 00:25:51,620
which is the calculated

404
00:25:51,620 --> 00:25:55,470
call among first in the images and this is the first

405
00:25:57,860 --> 00:26:00,070
if you want to

406
00:26:00,190 --> 00:26:04,680
with the same

407
00:26:08,750 --> 00:26:10,020
the measure

408
00:26:14,120 --> 00:26:15,510
and another way to

409
00:26:15,530 --> 00:26:17,990
this is called

410
00:26:18,010 --> 00:26:20,960
and this

411
00:26:20,960 --> 00:26:22,940
well call me

412
00:26:23,460 --> 00:26:24,180
you have

413
00:26:24,220 --> 00:26:26,590
the surrounding country

414
00:26:38,000 --> 00:26:40,490
there and back to make

415
00:26:40,500 --> 00:26:42,450
one of the major

416
00:26:42,490 --> 00:26:47,210
as a user you've made some of the system and you

417
00:26:47,250 --> 00:26:49,100
this is main

418
00:26:49,130 --> 00:26:51,810
and they were correctly

419
00:26:51,840 --> 00:26:54,220
so they try to

420
00:26:54,240 --> 00:26:55,730
weight training

421
00:26:56,520 --> 00:26:58,950
so this would be nation

422
00:26:59,070 --> 00:27:02,260
and use it as a measure of

423
00:27:02,350 --> 00:27:03,730
but in this system

424
00:27:03,770 --> 00:27:07,200
it is how many times to

425
00:27:08,760 --> 00:27:12,200
before you get the image

426
00:27:12,200 --> 00:27:13,450
so many

427
00:27:13,570 --> 00:27:16,200
the collection

428
00:27:16,250 --> 00:27:22,160
there was a and you have to get the image so you provide some sketches

429
00:27:22,160 --> 00:27:23,140
in which

430
00:27:23,180 --> 00:27:27,360
and it turns some results which are in this case

431
00:27:28,880 --> 00:27:30,280
just chat

432
00:27:30,310 --> 00:27:32,200
what is one

433
00:27:32,210 --> 00:27:33,460
we are looking for

434
00:27:33,460 --> 00:27:39,000
this is the only it into where they might

435
00:27:39,090 --> 00:27:40,200
you model

436
00:27:40,200 --> 00:27:42,720
and the you use

437
00:27:43,140 --> 00:27:45,750
this is the right to

438
00:27:45,800 --> 00:27:48,560
you find the killer

439
00:27:48,610 --> 00:27:51,960
so this is because when you have such that much

440
00:27:53,000 --> 00:27:56,380
well know which one to use a so

441
00:27:56,380 --> 00:28:00,160
before you find your image

442
00:28:00,170 --> 00:28:01,450
and i

443
00:28:06,880 --> 00:28:14,550
no natural images which divided by the images and this

444
00:28:14,610 --> 00:28:17,120
so this

445
00:28:21,550 --> 00:28:23,960
she also used for

446
00:28:24,570 --> 00:28:26,200
should actually is

447
00:28:26,220 --> 00:28:27,190
the name

448
00:28:27,200 --> 00:28:37,000
precision and recall depending on the amount of retrieved images

449
00:28:37,020 --> 00:28:40,510
graph where

450
00:28:40,800 --> 00:28:42,530
is the classical precision

451
00:28:42,540 --> 00:28:44,990
precision recall

452
00:28:45,030 --> 00:28:49,490
so what's the point that you recall

453
00:28:49,530 --> 00:28:50,880
and that it was

454
00:28:55,020 --> 00:28:56,230
and all of them

455
00:28:56,450 --> 00:28:58,620
it also

456
00:28:58,630 --> 00:29:02,480
he examples

457
00:29:02,500 --> 00:29:05,380
precision recall so

458
00:29:05,380 --> 00:29:08,420
there are several layers

459
00:29:09,520 --> 00:29:10,730
just a name

460
00:29:10,740 --> 00:29:13,200
like the way

461
00:29:13,210 --> 00:29:14,200
you can do it

462
00:29:14,200 --> 00:29:16,610
you what

463
00:29:20,110 --> 00:29:21,820
i was you

464
00:29:21,960 --> 00:29:26,040
the reason recall so it should have the mop

465
00:29:26,290 --> 00:29:28,270
the graph

466
00:29:28,290 --> 00:29:30,490
the first is the more higher

467
00:29:30,540 --> 00:29:33,480
and for this flow

468
00:29:33,500 --> 00:29:34,410
we have

469
00:29:35,890 --> 00:29:39,890
one of course where

470
00:29:39,900 --> 00:29:42,170
and the second one

471
00:29:43,000 --> 00:29:44,700
so called

472
00:29:44,710 --> 00:29:46,480
number of image so

473
00:29:46,970 --> 00:29:48,230
four this

474
00:29:50,040 --> 00:29:51,440
the graph shows

475
00:29:53,390 --> 00:29:58,380
and if you go to specific interests usually such

476
00:30:04,590 --> 00:30:06,870
to measure the of

477
00:30:07,140 --> 00:30:08,920
it's so about

478
00:30:12,750 --> 00:30:17,090
OK so far too quickly

479
00:30:17,100 --> 00:30:23,230
and to use this image actually has a query and they

480
00:30:23,260 --> 00:30:24,680
see the position of

481
00:30:24,810 --> 00:30:26,380
which is a

482
00:30:28,370 --> 00:30:34,090
of course there was no we assume that this image is the first

483
00:30:34,110 --> 00:30:35,420
if we had one

484
00:30:35,430 --> 00:30:36,710
problem is this

485
00:30:36,730 --> 00:30:38,380
well known

486
00:30:38,390 --> 00:30:40,570
i want to be

487
00:30:47,970 --> 00:30:50,050
the define measures

488
00:30:50,630 --> 00:30:53,050
actually correspond to each

489
00:30:56,240 --> 00:30:58,230
i could be seen

490
00:30:58,280 --> 00:31:00,220
using different measures

491
00:31:00,270 --> 00:31:01,930
so the first one

492
00:31:04,650 --> 00:31:05,900
performance measure

493
00:31:05,910 --> 00:31:09,270
percentage similar similar in

494
00:31:09,300 --> 00:31:10,760
it was about

495
00:31:10,770 --> 00:31:14,540
comparing with the brain

496
00:31:14,620 --> 00:31:16,060
the fact

497
00:31:18,530 --> 00:31:23,620
you can see according to what i want

498
00:31:25,760 --> 00:31:29,090
you have a higher percentage of users

499
00:31:29,090 --> 00:31:33,600
and this is one model the right answer for this

500
00:31:35,820 --> 00:31:37,440
who makes it

501
00:31:37,450 --> 00:31:38,920
the because this time

502
00:31:39,210 --> 00:31:40,530
but the first

503
00:31:40,620 --> 00:31:41,850
but the precision

504
00:31:41,860 --> 00:31:44,660
for the same

505
00:31:46,740 --> 00:31:50,600
what have actually

506
00:31:50,630 --> 00:31:56,040
so you were because we can measure

507
00:31:56,060 --> 00:31:57,150
the measure

508
00:31:58,390 --> 00:31:59,810
during this is

509
00:32:01,100 --> 00:32:03,000
for example

510
00:32:03,020 --> 00:32:04,430
we have

511
00:32:04,500 --> 00:32:06,130
all right

512
00:32:06,140 --> 00:32:07,440
this is

513
00:32:07,450 --> 00:32:09,200
the second one

514
00:32:09,230 --> 00:32:11,160
two of

515
00:32:13,370 --> 00:32:17,430
it is the first because all his right is the second one

516
00:32:17,430 --> 00:32:21,620
in cancer already may not be in the right in the right class you are

517
00:32:21,620 --> 00:32:25,690
still in six three three minutes you wondering what happened to the indian guy normally

518
00:32:25,690 --> 00:32:27,840
lectures is sitting there

519
00:32:28,050 --> 00:32:33,740
we're trading off lectures for the next director of the class do about the next

520
00:32:33,900 --> 00:32:39,260
lectures up until spring break and hurried back to my sam and feel free to

521
00:32:39,260 --> 00:32:41,450
address question of like me

522
00:32:41,470 --> 00:32:45,010
so we're going to keep today we're going to be talking about this concept of

523
00:32:45,010 --> 00:32:48,300
enforcing modularity we started talking about last time

524
00:32:54,770 --> 00:33:01,220
so last time we saw how we can use this notion of the client service

525
00:33:01,220 --> 00:33:05,890
model in order to separate two in order to separate i

526
00:33:05,900 --> 00:33:08,830
that is separate to modules from each other so

527
00:33:08,940 --> 00:33:13,020
the idea was that we could have we could by running the client service on

528
00:33:13,020 --> 00:33:16,400
separate machines we can isolate these two things from each other so we can make

529
00:33:16,400 --> 00:33:21,460
it so that the for example one the client wants to invoke some operation on

530
00:33:21,460 --> 00:33:28,460
the server the server is can verify can verify the request that the claims made

531
00:33:28,460 --> 00:33:31,440
to make sure that the client is asking to do something malicious

532
00:33:31,540 --> 00:33:34,460
similarly we can

533
00:33:35,270 --> 00:33:38,740
this is what we saw last time with client service model

534
00:33:39,990 --> 00:33:43,850
and this has been the it's the other benefit the client service model was meant

535
00:33:43,850 --> 00:33:47,900
that we can decouple the client from this from the surface so it meant that

536
00:33:47,900 --> 00:33:54,020
when the client issued a request against the service it was possible for the it

537
00:33:54,020 --> 00:33:59,290
didn't necessarily mean that the client service failed when the client issued the request it

538
00:33:59,290 --> 00:34:04,320
wasn't necessarily the case the client would also fail so the server could my my

539
00:34:04,320 --> 00:34:07,760
tracks excluding request and the client would get a timeout and would be able to

540
00:34:07,760 --> 00:34:13,770
retry and similarly if the server fail if if the client failed the server could

541
00:34:13,770 --> 00:34:18,520
continue handling requests on behalf of our clients that was and i separation the ability

542
00:34:18,520 --> 00:34:20,410
to split the client from the the

543
00:34:20,430 --> 00:34:23,960
so far apart from each other that there was that's a good thing

544
00:34:23,960 --> 00:34:27,750
but the problem with this approach is that we had to have two separate machines

545
00:34:27,750 --> 00:34:31,080
right away we presented this was the the client was running on one computer and

546
00:34:31,080 --> 00:34:35,060
the server was running on another computer and this is a little bit if you

547
00:34:35,060 --> 00:34:38,030
think about this this is this is exactly what we want right because i mean

548
00:34:38,030 --> 00:34:42,340
suppose we want to build up a big complicated computer system is composed of multiple

549
00:34:42,340 --> 00:34:46,670
at multiple different modules if we have to run each one of those modules on

550
00:34:46,670 --> 00:34:50,740
a separate computer that's not really very ideal right it's going to mean if we

551
00:34:51,180 --> 00:34:54,390
to build up a big service going a whole lot of computers and clearly that's

552
00:34:54,390 --> 00:34:58,180
not the way the computer systems that we actually interact with work

553
00:34:58,270 --> 00:35:05,480
so what we've seen so far is this notion we have a module

554
00:35:05,530 --> 00:35:07,530
per computer

555
00:35:07,680 --> 00:35:12,300
OK and we're going to do today is going to see how we can generalize

556
00:35:12,300 --> 00:35:17,370
this instead of having one module per computer we can instead have multiple models running

557
00:35:17,370 --> 00:35:20,870
with within a single computer but when we do that we still want to maintain

558
00:35:20,870 --> 00:35:24,900
these nice spend these nice sort of protection benefits that we had between the client

559
00:35:24,900 --> 00:35:28,300
service when these two things are running on separate computers

560
00:35:28,420 --> 00:35:30,520
so the way they going to do that is by

561
00:35:30,560 --> 00:35:36,780
do creating something we call it virtual computer so

562
00:35:36,800 --> 00:35:48,640
we're we're going to do is we're going to create this notion of virtual multiple

563
00:35:48,640 --> 00:35:52,430
virtual computers they're all running on one single computer and then we're going to run

564
00:35:52,430 --> 00:35:54,990
each one of these models within a virtual computer

565
00:35:55,030 --> 00:35:59,140
and i'll talk about more about what i mean by a virtual computer throughout the

566
00:35:59,140 --> 00:36:03,470
next couple lectures but the idea is that virtual computer has this sort of see

567
00:36:03,470 --> 00:36:08,650
exactly the same to to the two programs running on a virtual computer looks just

568
00:36:08,650 --> 00:36:12,870
like one of these kind of server computers might have worked and in particular virtual

569
00:36:12,870 --> 00:36:18,740
computer has the same sort of abstractions that we studied in the previous lectures available

570
00:36:18,740 --> 00:36:23,930
to the real computer has so virtual computer has a virtual memory

571
00:36:25,750 --> 00:36:31,730
and virtual processor

572
00:36:36,860 --> 00:36:40,010
today we're talking about is this notion of virtual memory

573
00:36:40,060 --> 00:36:44,340
and this virtual so you've already you guys have already probably seen the term virtual

574
00:36:44,340 --> 00:36:47,560
memory and sixty four so the word should be familiar to you and we're gonna

575
00:36:47,570 --> 00:36:49,600
use exactly the same abstraction

576
00:36:49,620 --> 00:36:53,470
we used in sixty four so we're just going to show how this attraction can

577
00:36:53,470 --> 00:36:58,290
be used to provide this protection between the client server that we want to things

578
00:36:58,290 --> 00:37:02,120
we're also can introduce today this notion of something called the kernel

579
00:37:03,360 --> 00:37:07,860
and the kernel is something that's in charge basically of managing all of these different

580
00:37:07,860 --> 00:37:11,990
virtual computers they're running on our one physical computer so the kernel is going to

581
00:37:11,990 --> 00:37:14,800
be the sort of system that knows about is going to be a piece of

582
00:37:14,800 --> 00:37:18,750
the system that actually knows that there are multiple virtual computers running on the system

583
00:37:21,320 --> 00:37:26,810
i want to start out by first just talk about why we wanna virtualized memory

584
00:37:26,810 --> 00:37:30,500
why visualizing memory is a good thing so

585
00:37:31,380 --> 00:37:36,940
abbreviate virtual memory SVM so

586
00:37:36,970 --> 00:37:39,930
why would we want to virtual memory well so let's see what let's let's see

587
00:37:39,930 --> 00:37:43,500
what might happen if we built a computer system with multiple models running on at

588
00:37:43,500 --> 00:37:47,560
the same time that they didn't have a virtualized memory

589
00:37:47,570 --> 00:37:49,990
so suppose we have some

590
00:37:51,710 --> 00:37:55,800
and we have some memory

591
00:37:55,820 --> 00:38:00,060
and within this memory

592
00:38:00,550 --> 00:38:01,540
we have

593
00:38:01,550 --> 00:38:03,350
the data for a a couple of the

594
00:38:03,360 --> 00:38:08,340
code and data for a couple of different modules is stored the same model a

595
00:38:08,420 --> 00:38:10,640
and model b

596
00:38:10,660 --> 00:38:16,010
and this is the data that this is the things like the code

597
00:38:16,040 --> 00:38:21,800
and the data that these models are using the currently executing so

598
00:38:21,810 --> 00:38:26,490
in this environment suppose module a execute some instructions

599
00:38:28,560 --> 00:38:33,180
so so so let's revisit this if you think this is memory let's say that

600
00:38:33,180 --> 00:38:37,620
module a begins at to address a year and model b begins at address b

601
00:38:37,620 --> 00:38:38,490
b here

602
00:38:40,350 --> 00:38:44,350
suppose that model a execute some instruction like

603
00:38:45,640 --> 00:38:48,740
and some value are one

604
00:38:48,750 --> 00:38:51,640
in memory address be OK

605
00:38:51,670 --> 00:38:56,530
so the model a rights into memory address b here so

606
00:38:56,530 --> 00:38:58,180
and they're going to want this

607
00:38:58,200 --> 00:39:02,910
i want them to know that if they get this it's going to be hard

608
00:39:02,920 --> 00:39:07,290
and i want them when they finish negotiated with me and they squeezed out of

609
00:39:07,290 --> 00:39:10,230
me i wanted to feel like they got this

610
00:39:10,270 --> 00:39:13,890
i want them to feel like they work for it and was worth getting and

611
00:39:13,890 --> 00:39:17,240
they can go back to the people say i couldn't have gotten

612
00:39:17,260 --> 00:39:20,700
any more and that he that's how i start to get them angry so how

613
00:39:20,700 --> 00:39:23,910
do you do that always services

614
00:39:23,930 --> 00:39:26,410
these easy easy everyone

615
00:39:26,420 --> 00:39:30,130
response exactly the same way so that don't listen to it

616
00:39:30,200 --> 00:39:34,630
to go into the first meeting is an asset not shuffle some papers look around

617
00:39:34,630 --> 00:39:40,660
make few notes taken by blackberry while the talk and send few smss you said

618
00:39:40,660 --> 00:39:44,110
and maybe time alas now look back at celje i'm sorry

619
00:39:44,200 --> 00:39:45,460
what we're saying

620
00:39:45,480 --> 00:39:49,430
it to round three rounds about thank you said they just explode they leave the

621
00:39:49,430 --> 00:39:55,150
room mission accomplished phase one phase two was started and and you know regardless of

622
00:39:55,150 --> 00:39:58,420
what you subscribed to another here's the bottom line the

623
00:39:58,440 --> 00:40:00,730
a single best way

624
00:40:00,780 --> 00:40:04,320
to sap to suck out somebody self-esteem

625
00:40:04,380 --> 00:40:08,590
to really get them angry is to deny them your attention

626
00:40:08,600 --> 00:40:11,960
and on the other side of things our research said

627
00:40:11,980 --> 00:40:17,710
that three of the most powerful things that you can do what you've been told

628
00:40:17,710 --> 00:40:22,170
since day one in every book you ever read about leadership and that was for

629
00:40:22,170 --> 00:40:24,360
god sakes list

630
00:40:24,400 --> 00:40:25,910
and i don't mean

631
00:40:26,060 --> 00:40:28,310
fake listening

632
00:40:28,350 --> 00:40:33,350
i've done the courses you've done the courses i can fake listening better than anybody

633
00:40:33,360 --> 00:40:36,620
i can turn on autopilot and say so what you mean is and that's what

634
00:40:37,020 --> 00:40:41,320
her you know in fact the research says if you're if you if you want

635
00:40:41,320 --> 00:40:44,710
to listen is different for a woman and the man but if you want to

636
00:40:44,710 --> 00:40:47,650
convince the manual listening all you have to do

637
00:40:47,670 --> 00:40:50,760
johann eugen make monkey sounds

638
00:40:50,760 --> 00:40:52,220
so is that

639
00:40:52,460 --> 00:40:59,600
the other technique where they talk about feeding back and also what you mean is

640
00:40:59,880 --> 00:41:04,510
is more effective with females for reason i don't know but but is the point

641
00:41:04,510 --> 00:41:06,100
the night people

642
00:41:06,110 --> 00:41:10,470
nine people your full attention and they go not give them your full attention but

643
00:41:10,470 --> 00:41:16,460
more importantly then be seen to act upon what they feed to you

644
00:41:16,490 --> 00:41:20,520
we seem to do something about it take to feed back and do something about

645
00:41:20,520 --> 00:41:25,990
it and you will raise their self-esteem and you raise your charisma with

646
00:41:26,040 --> 00:41:31,650
forty six of the the behaviors are in there were in around the whole area

647
00:41:31,980 --> 00:41:37,650
of simply listening to people actively soliciting their input

648
00:41:37,670 --> 00:41:42,540
and then doing something about it is the least expensive motivation will ever get

649
00:41:42,730 --> 00:41:47,040
thing is common courtesy who's who is one of the things we found in our

650
00:41:47,050 --> 00:41:51,820
search dreadfully dreadfully missing in people when they became managers

651
00:41:51,830 --> 00:41:54,510
when they became leaders they started to feel

652
00:41:54,580 --> 00:42:00,080
that saying sorry saying please and say thank you should certain weakness

653
00:42:00,120 --> 00:42:03,370
you know i wonder what your mind doing that for me please

654
00:42:03,390 --> 00:42:04,860
and you get people say

655
00:42:04,860 --> 00:42:06,890
we should i say please to get paid

656
00:42:06,910 --> 00:42:08,970
to do it it's their job

657
00:42:08,990 --> 00:42:11,640
you know why should i say thank you to get the thank you at the

658
00:42:11,640 --> 00:42:14,630
end of each month OK to get thirty percent of the thank you at the

659
00:42:14,630 --> 00:42:19,440
end of each month thirty five percent of why should i say sorry you should

660
00:42:19,440 --> 00:42:23,480
say it because simple simple courses like

661
00:42:23,840 --> 00:42:27,320
saying sorry saying please saying thank you

662
00:42:29,010 --> 00:42:32,060
this is one of the critical one just being responsive

663
00:42:32,080 --> 00:42:34,060
you get these emails from people

664
00:42:34,070 --> 00:42:37,260
you don't have time to respond on one line that says i'm just up to

665
00:42:37,260 --> 00:42:38,530
my neck right now

666
00:42:38,550 --> 00:42:41,390
i will get back on this thanks

667
00:42:41,420 --> 00:42:44,010
make some major major difference can

668
00:42:44,050 --> 00:42:45,630
please and thank you

669
00:42:45,650 --> 00:42:47,910
hold your tongue

670
00:42:48,030 --> 00:42:52,630
this is just this is nothing this incomparable research this is a good old-fashioned dale

671
00:42:53,560 --> 00:42:57,460
and it's just classic other side of listening stuff

672
00:42:57,580 --> 00:43:02,680
it's just when you get into one of those heated situations where things get really

673
00:43:02,680 --> 00:43:07,870
really bad and you just want to let them have full barrel of oil barrels

674
00:43:08,230 --> 00:43:12,380
and you the boss so you can do even better than anybody else you stop

675
00:43:12,380 --> 00:43:14,130
button just hold back

676
00:43:14,140 --> 00:43:18,430
and that strength of character just hold back and currently used to say

677
00:43:18,480 --> 00:43:21,220
right all down on a piece of paper put it in a drawer and go

678
00:43:21,220 --> 00:43:25,480
back to the following day and see if you still want to say it one

679
00:43:25,480 --> 00:43:30,480
on one communications the most important thing listening to the second one just showing some

680
00:43:30,480 --> 00:43:32,550
positive regard for the people

681
00:43:33,320 --> 00:43:36,680
public speaking did figure in this and we do that there are different there were

682
00:43:36,680 --> 00:43:39,630
some of the behaviors were associated with that and i'm going to just touch really

683
00:43:39,630 --> 00:43:43,440
really quickly on some of the things that you can do to improve your public

684
00:43:43,440 --> 00:43:46,920
speaking when you stand in front of people this is not speaking course the first

685
00:43:46,920 --> 00:43:48,920
one is look like a ten

686
00:43:48,980 --> 00:43:52,320
now you know i have a mirror in my house

687
00:43:52,350 --> 00:43:58,440
so i know i don't look like a ten i j jim sirbasku is called

688
00:43:58,440 --> 00:44:02,920
himself short fat ugly little man i call myself medium height tall guy what kind

689
00:44:02,920 --> 00:44:07,590
of beaky nose and thinning hair and and i know that i know that i'm

690
00:44:07,590 --> 00:44:11,650
not of brad pitt or any those are the guys but when you go to

691
00:44:11,650 --> 00:44:21,110
absolutely stunning electricity California in this problem all i so I'm not claiming that's most

692
00:44:21,110 --> 00:44:31,530
general that this problem would fit every need no other actors have multiple sources and

693
00:44:31,530 --> 00:44:40,920
sinks and make the problem more general but more difficult

694
00:44:41,150 --> 00:44:48,030
true true true and had

695
00:44:49,320 --> 00:45:05,960
yeah so could be phone calls it will but if that if you're calling 1

696
00:45:05,960 --> 00:45:10,920
person in California then you're sending a packet here which can get split up in

697
00:45:10,920 --> 00:45:13,400
different ways and gets in fact network

698
00:45:13,560 --> 00:45:19,510
what contain he's doing that's taking your phone message splitting up in the packets sending

699
00:45:19,510 --> 00:45:21,080
and cheap way

700
00:45:21,090 --> 00:45:26,450
and of course it's and the other packets at the same time so there there's

701
00:45:26,450 --> 00:45:34,510
another generalization we've got a bunch of different sourcing appears simultaneously trying to get there

702
00:45:34,610 --> 00:45:36,720
a message through

703
00:45:36,950 --> 00:45:40,470
and then there's was

704
00:45:41,510 --> 00:45:47,820
and right yeah that's my network

705
00:45:47,860 --> 00:45:57,610
yes right put together it whatever it is that network why isn't perfect because somebody

706
00:45:57,610 --> 00:46:03,470
paid extra for this paper extra capacity that can be used at all yeah that's

707
00:46:03,470 --> 00:46:08,320
right but actually in reality that happens all the time right of menu pipeline is

708
00:46:08,320 --> 00:46:15,240
built from from Morocco to through Turkey wherever it adds more capacity will then it

709
00:46:15,240 --> 00:46:20,800
turns out that that maybe you know they got excess capacity but the

710
00:46:20,880 --> 00:46:26,860
minimal cut is what's determining how much slow gets you know from the oil fields

711
00:46:26,880 --> 00:46:34,710
to the refinery here and I could add a cost per node to 2 2

712
00:46:34,780 --> 00:46:41,220
goes through that node 0 you can imagine that I as long as stage linear

713
00:46:41,220 --> 00:46:46,720
and I can make these things for general here so I mean this is a

714
00:46:46,720 --> 00:46:50,590
really good discussion and this is the model problem but

715
00:46:50,640 --> 00:46:56,680
but if we think about natural ways to make it closer and closer to reality

716
00:46:57,080 --> 00:46:59,480
we still stay with

717
00:46:59,490 --> 00:47:04,300
we still stay with this linear programming framework

718
00:47:04,740 --> 00:47:08,540
we can we can get a lot as well in a way that I have

719
00:47:08,540 --> 00:47:11,580
decided that multipurpose

720
00:47:11,880 --> 00:47:18,360
you know so optimizing from multiple users there that's that is really a different problem

721
00:47:18,360 --> 00:47:24,600
you know however if I'm optimizing if I'm choosing the axes that optimizes some function

722
00:47:24,600 --> 00:47:30,880
for several purposes of optimize several functions at once in some way so that that

723
00:47:31,460 --> 00:47:31,940
there are

724
00:47:32,650 --> 00:47:36,720
caring and you know that a by the way game series

725
00:47:37,420 --> 00:47:43,860
it is another example of linear programming and 1 and discovered that slightly before

726
00:47:43,880 --> 00:47:48,720
of linear programming we discovered that almost the same time and people in the 1st

727
00:47:48,740 --> 00:47:54,560
years even when alignment didn't instantly know and he is willing to every other that

728
00:47:54,560 --> 00:47:56,170
it was the same

729
00:47:56,240 --> 00:48:00,320
and you have to do you remember the name of the fundamentals what I could

730
00:48:00,320 --> 00:48:07,530
talk about game theory I mean excitement you wanted among other problems but the fundamental

731
00:48:07,530 --> 00:48:13,450
duality there is called the minimax theorem there's a minimax equals the maximum

732
00:48:14,120 --> 00:48:18,940
in the in the world of game theory proved by 1 on the minimax theorem

733
00:48:19,260 --> 00:48:24,980
the minimum of the maximum of something is the maximum of the minimum of some

734
00:48:25,020 --> 00:48:33,220
and the end to end the two-person game theory that 1 alignment was

735
00:48:35,540 --> 00:48:46,520
that would match linear so that would match a linear program I could think

736
00:48:46,530 --> 00:48:49,740
this is probably not means

737
00:48:50,240 --> 00:48:56,920
yeah well yeah like well

738
00:48:57,650 --> 00:49:02,460
the answer is yes there's a duality and nonlinear programs

739
00:49:02,490 --> 00:49:05,760
there is but to tell you what that if you tell me 1 of the

740
00:49:05,760 --> 00:49:07,900
functions to tell you what the other is

741
00:49:07,950 --> 00:49:13,710
it's going to take next week to do it but it's not just like UCI

742
00:49:13,710 --> 00:49:17,940
I I came up with the dual problem out of the blue really and but

743
00:49:17,940 --> 00:49:22,820
it wasn't totally out of the blue there was a there was a method there

744
00:49:22,820 --> 00:49:26,400
that could apply a nonlinear cases but not obvious

745
00:49:27,100 --> 00:49:31,900
anyway Game Theory two-person game theory would fit this

746
00:49:32,900 --> 00:49:37,840
set up and so the minimax theorem is that is the duality theory 3 per

747
00:49:37,840 --> 00:49:39,220
cent gain

748
00:49:39,240 --> 00:49:44,630
you know that's what John Nash won the Nobel Prize for

749
00:49:44,650 --> 00:49:49,530
the wrote a thesis so I didn't mention the other key names that this optimality

750
00:49:49,530 --> 00:49:55,110
condition is associated with Conan talk and now written down the Greek names in this

751
00:49:56,180 --> 00:49:59,660
and then at John Nash who were

752
00:50:00,900 --> 00:50:08,160
rodents PhD thesis at Princeton under Tucker to everybody's surprise Nash was real character of

753
00:50:08,160 --> 00:50:15,680
you you know this book the beautiful a beautiful mind about John match through its

754
00:50:15,680 --> 00:50:22,740
it may become a movie also movies movie rights have been bought purchase of its

755
00:50:22,750 --> 00:50:28,380
by Sylvia Nasar are and it was on the best seller systems a biography of

756
00:50:28,380 --> 00:50:34,000
john nash called a Beautiful Mind along

757
00:50:35,300 --> 00:50:40,160
so he won the Nobel Prize in a few years ago

758
00:50:40,380 --> 00:50:47,380
but his life was a track tragic story so well he was brilliant and actually

759
00:50:47,380 --> 00:50:53,030
for most mathematicians for all mathematicians that this is what you get that his PhD

760
00:50:53,030 --> 00:50:57,360
thesis that he got the nobel prize for was not in any way that most

761
00:50:57,360 --> 00:51:01,090
deepened difficult work he did he went on

762
00:51:02,620 --> 00:51:07,260
effects in a high dimensional analysis

763
00:51:08,760 --> 00:51:15,280
and then schizophrenia but took over so we had many many years when he was

764
00:51:15,690 --> 00:51:20,720
1st around the MIT math department in and around the longest time around the Princeton

765
00:51:20,720 --> 00:51:24,300
math department but really out of that

766
00:51:25,040 --> 00:51:34,060
communication with people and was difficult and then incredibly and recovered so he gave a

767
00:51:34,060 --> 00:51:41,900
lecture at MIT a few weeks ago in fact which worry had a standing-room-only audience

768
00:51:41,900 --> 00:51:44,480
so far we have not seen any ground

769
00:51:44,560 --> 00:51:49,080
later we will see the connection of these graph

770
00:51:49,140 --> 00:51:54,980
so the key message

771
00:52:00,710 --> 00:52:02,360
the key messages that

772
00:52:02,360 --> 00:52:05,040
when we introduce conditional independencies

773
00:52:05,060 --> 00:52:07,590
we generate factorizations of the

774
00:52:10,290 --> 00:52:13,230
think you've learned is met

775
00:52:13,320 --> 00:52:16,110
the question is is this useful for

776
00:52:16,240 --> 00:52:19,840
remember of tasks for four questions for complex

777
00:52:19,880 --> 00:52:22,230
joint distribution

778
00:52:22,250 --> 00:52:26,630
the to have conditioning as well if they have condition independence they will be able

779
00:52:26,630 --> 00:52:28,420
to be factorized in some way

780
00:52:28,440 --> 00:52:30,150
is useful for

781
00:52:30,190 --> 00:52:32,380
well let's investigate

782
00:52:32,380 --> 00:52:35,040
let's see an example

783
00:52:35,170 --> 00:52:38,270
so we want to compute the marginalisation for p of x you we need to

784
00:52:38,270 --> 00:52:41,630
sum over x one x three of these

785
00:52:41,630 --> 00:52:43,670
so that

786
00:52:43,730 --> 00:52:47,940
now if we don't have a position what's the complexity of

787
00:52:48,790 --> 00:52:50,730
it's just exponential the

788
00:52:50,750 --> 00:52:54,500
the basis of every one of them because they need to search through all possible

789
00:52:54,500 --> 00:52:56,040
entries on this table

790
00:52:56,040 --> 00:52:59,500
if i assume that i'm assuming just for simplicity have

791
00:52:59,520 --> 00:53:02,520
a discrete state space forever by

792
00:53:02,610 --> 00:53:07,620
so that that's the order of the size of the first that space second that

793
00:53:07,620 --> 00:53:09,840
all of them equal clinical equal to us

794
00:53:09,860 --> 00:53:13,250
we have something SQL

795
00:53:13,310 --> 00:53:16,130
now let's assume that we have a position

796
00:53:16,150 --> 00:53:18,040
the same expression here

797
00:53:18,060 --> 00:53:22,290
but instead we have the fact position as mentioned previously

798
00:53:22,420 --> 00:53:25,880
these functionalities factorize into three pieces

799
00:53:27,040 --> 00:53:28,690
we have following

800
00:53:31,130 --> 00:53:35,040
this is key operation that we're going to

801
00:53:35,090 --> 00:53:37,210
learning the first part of course

802
00:53:37,230 --> 00:53:39,840
the session is the distributive law

803
00:53:39,880 --> 00:53:44,690
i have some of to violence

804
00:53:44,690 --> 00:53:48,130
and here i have some fun

805
00:53:48,190 --> 00:53:49,020
all i

806
00:53:49,190 --> 00:53:55,170
these factors

807
00:53:55,190 --> 00:53:57,060
x two x three

808
00:53:57,170 --> 00:53:58,400
the next three

809
00:53:58,440 --> 00:54:00,310
these problems

810
00:54:00,360 --> 00:54:03,460
o is constant with respect

811
00:54:03,590 --> 00:54:08,400
to this summation in x y

812
00:54:10,320 --> 00:54:14,920
if i'm something of x one these entire that musicals

813
00:54:14,980 --> 00:54:19,670
so what i am

814
00:54:19,690 --> 00:54:22,500
if i have a

815
00:54:25,900 --> 00:54:27,040
the quality

816
00:54:27,060 --> 00:54:28,190
only black

817
00:54:28,210 --> 00:54:29,860
i have

818
00:54:33,770 --> 00:54:39,520
plus a c that's exactly what happens i have a form factor

819
00:54:39,580 --> 00:54:43,060
in the summer

820
00:54:43,110 --> 00:54:45,130
the fact

821
00:54:45,150 --> 00:54:49,520
p of x given xt you fixed it is common to all the elements of

822
00:54:49,520 --> 00:54:53,230
the sum over x y

823
00:54:53,250 --> 00:54:56,690
so how can i write this one

824
00:54:56,730 --> 00:54:59,750
i can write this quantity as a

825
00:54:59,790 --> 00:55:02,650
multiplying the policy

826
00:55:04,590 --> 00:55:07,500
this is called the distributive law

827
00:55:07,560 --> 00:55:11,040
he had three operations these operations

828
00:55:11,090 --> 00:55:15,000
and these two problems have three free

829
00:55:15,020 --> 00:55:16,980
you have only two or three

830
00:55:17,040 --> 00:55:20,840
his brother and this up

831
00:55:20,900 --> 00:55:24,380
so by going from here to here again

832
00:55:24,400 --> 00:55:26,340
so let's do do the same

833
00:55:26,440 --> 00:55:29,630
let's put in evidence these facts

834
00:55:29,690 --> 00:55:32,230
let's put it outside

835
00:55:32,250 --> 00:55:34,730
of these sums

836
00:55:36,590 --> 00:55:41,860
that's what i pull this factor outside of the some x

837
00:55:41,900 --> 00:55:49,840
then i saw this on how much is this

838
00:55:49,880 --> 00:55:52,560
o thing in

839
00:55:52,690 --> 00:55:56,520
because you want

840
00:56:07,420 --> 00:56:13,710
how much is here

841
00:56:13,750 --> 00:56:18,960
which is summing over all the values of x y

842
00:56:19,060 --> 00:56:22,630
the probability function is the function

843
00:56:22,670 --> 00:56:24,920
if the probability function fx

844
00:56:24,940 --> 00:56:29,040
six x two

845
00:56:29,190 --> 00:56:32,440
how much it is

846
00:56:32,610 --> 00:56:36,500
this is just one right because this is

847
00:56:36,500 --> 00:56:39,310
pretty close estimation

848
00:56:40,640 --> 00:56:44,460
when we use the estimation of initial way

849
00:56:44,480 --> 00:56:47,020
you need less iterations

850
00:56:47,060 --> 00:56:48,580
if are using

851
00:56:51,480 --> 00:56:57,330
presentation of which run as i said this is again vector of all matrix

852
00:56:57,350 --> 00:56:58,190
you can

853
00:56:58,190 --> 00:57:02,210
look at this metrics i don't know how like this

854
00:57:02,230 --> 00:57:04,000
sheet of paper

855
00:57:04,000 --> 00:57:06,940
and this is our

856
00:57:07,020 --> 00:57:12,390
of course this again vector will be some normal vector to the sheet of paper

857
00:57:12,410 --> 00:57:13,520
so our

858
00:57:13,560 --> 00:57:16,170
metric in this space

859
00:57:16,230 --> 00:57:20,310
because we did some small number of changes to update

860
00:57:20,940 --> 00:57:27,440
usually change not a lot so we don't need to move this vector significantly

861
00:57:27,460 --> 00:57:31,870
and because of this we can assume that our previous israeli of this vector is

862
00:57:31,890 --> 00:57:34,290
very good estimation

863
00:57:35,100 --> 00:57:42,790
actually using previous israeli of pagerank one exposure to reduce number of collisions significant

864
00:57:42,870 --> 00:57:45,080
another thing that we can do

865
00:57:46,310 --> 00:57:49,730
try to apply some fertilization

866
00:57:49,770 --> 00:57:54,290
so we can try to distribute calculation of our plagiarized

867
00:57:54,330 --> 00:57:56,500
or a number of boxes

868
00:57:56,500 --> 00:57:58,830
in OWL class

869
00:57:58,890 --> 00:58:01,330
so how can we do this

870
00:58:01,350 --> 00:58:03,710
and we can do this using this

871
00:58:05,330 --> 00:58:07,500
first of all we decided that

872
00:58:07,520 --> 00:58:13,830
our source while our compressed segmentation of matrix is pretty small

873
00:58:13,850 --> 00:58:15,140
so we can

874
00:58:15,140 --> 00:58:16,190
fits it's

875
00:58:16,210 --> 00:58:18,770
in two

876
00:58:20,540 --> 00:58:22,370
we can see that in tour

877
00:58:22,390 --> 00:58:24,370
every box

878
00:58:24,420 --> 00:58:26,670
also we can

879
00:58:26,690 --> 00:58:30,250
will the things that these results

880
00:58:30,890 --> 00:58:33,230
result of previous iteration

881
00:58:33,270 --> 00:58:36,870
is always not so the and we have enough

882
00:58:36,920 --> 00:58:40,000
the capacity of our network

883
00:58:40,640 --> 00:58:42,770
i mean this exchange

884
00:58:42,770 --> 00:58:47,020
to call the results of previous iterations all boxes

885
00:58:48,120 --> 00:58:51,850
the simplest approach again but what we are doing here

886
00:58:51,870 --> 00:58:53,830
do some iteration

887
00:58:53,850 --> 00:58:55,730
every box now

888
00:58:55,770 --> 00:59:00,910
has some part of pagerank some new results in part of measuring

889
00:59:00,920 --> 00:59:06,170
then the doing some exchange between boxes so not all boxes again

890
00:59:06,190 --> 00:59:11,580
i have the full presentation of metrics and the whole of the whole data the

891
00:59:11,580 --> 00:59:17,170
previous iteration now they everybody in calculating some part

892
00:59:17,210 --> 00:59:19,500
for some some part of this

893
00:59:19,790 --> 00:59:22,890
o this page i'm can be doing this is changing again

894
00:59:22,920 --> 00:59:28,310
there are a number of much more sophisticated algorithms how to implement this but this

895
00:59:28,350 --> 00:59:34,000
very simple and naive approach usually works well

896
00:59:34,080 --> 00:59:37,480
and of course we can we can do a lot of different

897
00:59:37,520 --> 00:59:43,140
much more sophisticated algorithms that are based on this

898
00:59:43,140 --> 00:59:47,910
idea that our matrix is not only very far

899
00:59:47,920 --> 00:59:52,120
but actually the density of this matrix is not uniform

900
00:59:52,170 --> 00:59:54,040
usually they have some

901
00:59:54,040 --> 00:59:58,790
lots of internet graph where they have a lot of links

902
00:59:58,850 --> 01:00:00,350
and some

903
01:00:00,410 --> 01:00:01,620
well they have

904
01:00:02,330 --> 01:00:05,810
or don't have anything activity between them

905
01:00:05,850 --> 01:00:07,870
so what we can do

906
01:00:07,920 --> 01:00:12,350
we can divide our metrics into this part

907
01:00:12,350 --> 01:00:14,670
calculate separate radius

908
01:00:15,620 --> 01:00:18,770
you understand that if you have a lot of links to have a lot of

909
01:00:18,770 --> 01:00:21,370
exchange between all of them

910
01:00:21,440 --> 01:00:25,270
what if we don't have links sexually one way

911
01:00:25,330 --> 01:00:28,540
so we can all we can do this calculation

912
01:00:29,620 --> 01:00:34,580
and then provide to the rest of the matrix metrics only one way to

913
01:00:34,690 --> 01:00:36,230
that's it

914
01:00:36,250 --> 01:00:40,620
but it's much more complex approach there are a number of articles people try to

915
01:00:40,620 --> 01:00:44,210
optimize you trying to find this this

916
01:00:45,140 --> 01:00:46,730
blocks of

917
01:00:46,730 --> 01:00:49,520
a lot of internal links in the graph

918
01:00:50,310 --> 01:00:54,710
actually they can increase speed of this calculation significantly

919
01:00:54,750 --> 01:00:56,750
but as ordinary

920
01:00:56,750 --> 01:01:00,650
when the main aim of those was that they would act as a very good

921
01:01:00,650 --> 01:01:04,770
classifier when we want to distinguish between the classes like

922
01:01:04,810 --> 01:01:06,350
that's the person read

923
01:01:06,380 --> 01:01:08,480
evening news yes or no

924
01:01:08,480 --> 01:01:14,580
and we should provide such a classification as accurate as possible also we decision trees

925
01:01:14,610 --> 01:01:20,130
that's say that somebody read and then yes or no so then we want to

926
01:01:20,130 --> 01:01:23,590
optimize the classification accuracy of such an induced models

927
01:01:23,730 --> 01:01:31,400
here we are not optimizing accuracy because actually our data can be such that we

928
01:01:31,400 --> 01:01:32,240
don't even

929
01:01:32,240 --> 01:01:37,470
this thing is that our goal is not even distinguishing between the classes but just

930
01:01:37,490 --> 01:01:44,700
find some interesting associations are between the items

931
01:01:45,100 --> 01:01:50,280
so here we evaluate ruled by its support and confidence measure it is the conditional

932
01:01:50,280 --> 01:01:51,750
probability that

933
01:01:53,600 --> 01:01:58,810
x and y called jointly and the confidence is the

934
01:01:58,840 --> 01:02:00,410
the conditional

935
01:02:00,420 --> 01:02:02,100
the probability of y

936
01:02:02,120 --> 01:02:03,920
given x

937
01:02:03,970 --> 01:02:07,930
and we evaluated by the number of samples for which

938
01:02:07,980 --> 01:02:13,000
x and y is true at the same time and well if we compute this

939
01:02:13,000 --> 01:02:18,300
probability by the relative frequency computed from the data set it is the number of

940
01:02:18,300 --> 01:02:24,550
instances for which x called the black holes divided by the number of items it

941
01:02:25,030 --> 01:02:28,720
by the number by the popular the entire population

942
01:02:28,730 --> 01:02:34,910
whereas here the confidence would be the conditional probability of y given x which would

943
01:02:34,910 --> 01:02:41,570
be the support of x y divided by the support of x itself so let's

944
01:02:41,580 --> 01:02:47,520
see some this association rules let's and

945
01:02:47,710 --> 01:02:54,020
discovered association rule would be if somebody reads love stories magazine then

946
01:02:54,380 --> 01:03:02,920
the first slovenian use surprising slovenian scan of it

947
01:03:02,930 --> 01:03:05,390
support would be a comma five

948
01:03:05,410 --> 01:03:09,880
which means we come of five of the whole percent of the code

949
01:03:09,900 --> 01:03:12,260
the population reason both

950
01:03:12,300 --> 01:03:17,010
a love story magazine and can lead and confidence is

951
01:03:17,050 --> 01:03:23,360
sixty one percent which means sixty one percent of those reading love stories magazine thirty

952
01:03:23,360 --> 01:03:28,830
it's also slow things can be to which is an interesting piece of information

953
01:03:28,950 --> 01:03:36,560
let's look at another association rules here we are simplifying the form of association rules

954
01:03:37,100 --> 01:03:40,700
in such a way that we have just one item in the condition

955
01:03:40,750 --> 01:03:44,560
and one item in the conclusion because we have decided so

956
01:03:44,620 --> 01:03:49,460
but in general we could have a conjunction of items in the condition and the

957
01:03:49,460 --> 01:03:51,910
conjunction of items in the conclusion

958
01:03:51,920 --> 01:03:55,730
so well known example of

959
01:03:55,770 --> 01:04:03,790
which i don't have here well-known example of association rules would be let's say somebody

960
01:04:03,790 --> 01:04:09,310
buys beer and coke in the magazine then he also buys

961
01:04:10,770 --> 01:04:17,610
so this was funny finding and then people who analyse

962
01:04:17,630 --> 01:04:25,540
people buying habits would then put all these things in the store together so that

963
01:04:25,540 --> 01:04:31,300
let's say whenever you go in liberia also grab peanuts and then that's how people

964
01:04:31,300 --> 01:04:35,200
organised the magazines having fun such association rules

965
01:04:35,210 --> 01:04:39,510
trying to analyse the buying habits of people

966
01:04:39,520 --> 01:04:44,140
so for instance this was interesting we were trying to find the readers of the

967
01:04:44,250 --> 01:04:50,860
based on the pro or other eating habits and we could find that people do

968
01:04:50,880 --> 01:04:55,490
law if they also read marketing magazine if they read financial news

969
01:04:55,560 --> 01:04:57,870
so prof in

970
01:04:57,900 --> 01:05:03,560
if they read the views money and VIP

971
01:05:03,570 --> 01:05:10,530
and all these rules have quite strong support and confidence so what we could interpreted

972
01:05:10,530 --> 01:05:14,820
this set of rules like most readers of marketing magazine financial news

973
01:05:14,870 --> 01:05:17,850
he was money and the power also readers of the

974
01:05:17,870 --> 01:05:23,500
and that's that was pretty interesting for the media not

975
01:05:27,160 --> 01:05:32,280
is doing this is to this

976
01:05:32,280 --> 01:05:33,740
information when

977
01:05:33,750 --> 01:05:39,500
you can always transform the decision tree into a set of classification rules

978
01:05:39,550 --> 01:05:41,700
vice versa is a bit more tricky

979
01:05:41,700 --> 01:05:43,660
with fantastic precision

980
01:05:44,590 --> 01:05:49,050
experimenters hoped to get nobel prizes for finding deviations from this and they try to

981
01:05:49,050 --> 01:05:50,850
do it for decades now

982
01:05:50,870 --> 01:05:54,260
but really haven't

983
01:05:54,320 --> 01:06:00,820
well maybe there's an exception here one

984
01:06:00,820 --> 01:06:03,840
so we should do so the nature has spoken this is a large part of

985
01:06:03,840 --> 01:06:07,220
the truth about fundamental action interactions in nature

986
01:06:07,280 --> 01:06:09,570
so we should take this very seriously

987
01:06:09,590 --> 01:06:14,220
and in particular take its aesthetic flaws remain very seriously

988
01:06:14,260 --> 01:06:18,820
and if we by the highest aesthetic standards clearly something is missing here

989
01:06:18,890 --> 01:06:20,010
we have

990
01:06:20,030 --> 01:06:21,550
partial symmetry

991
01:06:22,110 --> 01:06:27,570
things fall apart into unrelated groups here five different unrelated groups are also three families

992
01:06:27,590 --> 01:06:29,050
that's another story

993
01:06:30,300 --> 01:06:32,950
three different symmetries that are unconnected

994
01:06:34,660 --> 01:06:38,910
in recent years we've learned that the standard model also gives a rather lame account

995
01:06:38,930 --> 01:06:44,410
of neutrino masses that have been discovered

996
01:06:44,410 --> 01:06:46,610
so we want to do something better

997
01:06:47,700 --> 01:06:50,840
this a great idea for doing something better that is

998
01:06:50,840 --> 01:06:54,590
all these theories of QCD

999
01:06:55,390 --> 01:07:00,340
QED which of which is the vast generalisation and the weak interactions are based on

1000
01:07:00,340 --> 01:07:04,620
cemeteries among color charge is called gauge symmetry

1001
01:07:06,240 --> 01:07:08,570
what's suggested is to consider

1002
01:07:08,620 --> 01:07:12,430
just making a bigger symmetry of want all those images would be

1003
01:07:13,890 --> 01:07:18,410
and if you do that you for find things really click into place very beautifully

1004
01:07:18,450 --> 01:07:21,320
there are a number of ways to do it but probably the most beautiful is

1005
01:07:21,320 --> 01:07:23,620
based on the group so ten

1006
01:07:23,620 --> 01:07:27,800
you to know anything about ten and it's been representation you have to know anything

1007
01:07:27,800 --> 01:07:29,090
about that either

1008
01:07:29,090 --> 01:07:31,470
but what i want to convey here

1009
01:07:31,510 --> 01:07:32,800
and i'm not kidding

1010
01:07:32,890 --> 01:07:34,800
is that if you

1011
01:07:34,820 --> 01:07:39,110
look at that extended symmetry now among five different colours

1012
01:07:39,240 --> 01:07:44,010
you can find all the particles that used to be in scattered multiplets

1013
01:07:44,050 --> 01:07:48,320
come together all of them can be transformed into one another by the symmetries of

1014
01:07:48,340 --> 01:07:52,910
by larger cemeteries so their one indivisible unit like the different sides of the dye

1015
01:07:53,930 --> 01:07:57,470
four of an icosahedron

1016
01:07:57,530 --> 01:08:00,720
and for all the different possibilities occur

1017
01:08:00,720 --> 01:08:03,430
according to the group theory

1018
01:08:04,220 --> 01:08:07,720
this charge assignments that are plus or minus the half you

1019
01:08:08,800 --> 01:08:10,950
of these different five different color

1020
01:08:13,110 --> 01:08:15,910
all all possible combinations of

1021
01:08:15,930 --> 01:08:23,570
charges occur subject just to the limitation of the number of positive charges is even

1022
01:08:23,590 --> 01:08:27,760
so this gives a much more coherent account of why the standard model is the

1023
01:08:27,760 --> 01:08:28,910
way it is

1024
01:08:28,910 --> 01:08:31,430
why the particles we see are what they are

1025
01:08:31,470 --> 01:08:33,010
if we didn't know

1026
01:08:33,030 --> 01:08:36,120
the properties are names of these particles over here

1027
01:08:36,160 --> 01:08:37,340
in advance

1028
01:08:37,350 --> 01:08:38,890
just from knowing

1029
01:08:39,620 --> 01:08:42,550
mathematical characterizations

1030
01:08:42,590 --> 01:08:46,450
we would be able to reconstruct most of what we know in fact from

1031
01:08:46,490 --> 01:08:51,220
hundreds of years of experiments about these particles and the foundations of physics

1032
01:08:51,240 --> 01:08:54,740
furthermore those funny numbers those charges also come out

1033
01:08:55,410 --> 01:08:56,840
not unrelated

1034
01:08:56,870 --> 01:09:02,120
not independent of the strong and weak charges but a certain function of them

1035
01:09:02,140 --> 01:09:03,870
which again

1036
01:09:05,370 --> 01:09:10,160
arbitrary but dictated by the overall symmetry in the theory

1037
01:09:10,160 --> 01:09:12,640
so it seems to be a very good idea

1038
01:09:13,570 --> 01:09:17,930
take the standard model seriously and if you do it cries out for

1039
01:09:17,950 --> 01:09:20,280
a large amount of symmetry

1040
01:09:20,320 --> 01:09:22,200
like this

1041
01:09:22,260 --> 01:09:27,340
but there's a big flying the alignment apparently

1042
01:09:27,430 --> 01:09:31,070
that is this the reason that the weak interactions are called weak compared to the

1043
01:09:31,070 --> 01:09:32,470
strong interactions

1044
01:09:32,470 --> 01:09:35,470
and y atoms are much bigger than nuclei

1045
01:09:35,490 --> 01:09:39,990
it's because the different interactions have different powers the strong interaction really is much stronger

1046
01:09:39,990 --> 01:09:46,140
than electromagnetism that's why pulls quarks together whereas atoms can nuclei whereas atoms can be

1047
01:09:46,140 --> 01:09:47,510
much bigger

1048
01:09:47,530 --> 01:09:53,450
because they don't feel strong interaction electromagnetism and the weak interaction is turns out fundamentally

1049
01:09:53,450 --> 01:09:57,490
kind of in between

1050
01:09:57,530 --> 01:09:59,590
whereas complete symmetry

1051
01:09:59,620 --> 01:10:05,470
would require that all these interactions have exactly the same strength

1052
01:10:06,200 --> 01:10:08,780
as a matter of fact

1053
01:10:08,820 --> 01:10:10,120
from experiment

1054
01:10:10,140 --> 01:10:16,320
our dreams of symmetry seem to be disappointed

1055
01:10:22,510 --> 01:10:31,840
in the first

1056
01:10:31,910 --> 01:10:33,240
but we remind you

1057
01:10:33,410 --> 01:10:34,700
one of the main

1058
01:10:34,740 --> 01:10:36,930
lessons we learned from the standard model

1059
01:10:36,950 --> 01:10:38,890
from QCD in particular

1060
01:10:38,890 --> 01:10:42,820
is that the strength of interaction you see depends on where you look at in

1061
01:10:42,820 --> 01:10:51,410
particular what distance you look

1062
01:10:51,430 --> 01:10:56,010
so by taking that very same kind of calculation

1063
01:10:56,070 --> 01:10:57,390
which as we see is

1064
01:10:57,450 --> 01:10:59,010
was brilliantly

1065
01:10:59,010 --> 01:11:01,110
validated by experiment

1066
01:11:01,120 --> 01:11:02,490
and extrapolating it

1067
01:11:02,550 --> 01:11:04,570
to higher energies

1068
01:11:04,640 --> 01:11:05,720
we can see

1069
01:11:05,740 --> 01:11:09,850
if the primary interactions which is supposed to be at smaller distances

1070
01:11:09,870 --> 01:11:14,840
are you could be equal even though the interactions we measure small and large distances

1071
01:11:14,890 --> 01:11:21,280
because of the distorting effects of these clouds the build up might be unequal

1072
01:11:21,280 --> 01:11:25,800
and again with the stroke of the pen we can extend those calculations the so-called

1073
01:11:25,800 --> 01:11:32,800
renormalisation group calculation to see if you see what happens smaller distance

1074
01:11:32,840 --> 01:11:36,700
and if we do that using just the particles that are actually in the standard

1075
01:11:38,280 --> 01:11:41,910
we find that it almost works but not quite

1076
01:11:41,950 --> 01:11:43,950
this calculation of

1077
01:11:44,010 --> 01:11:45,410
how the

1078
01:11:45,450 --> 01:11:50,180
strong coupling there is this is actually the same graph is what i showed

1079
01:11:50,180 --> 01:11:51,660
just now

1080
01:11:51,760 --> 01:11:57,390
in different in different format is the inverse coupling that's plotted so actually increases with

1081
01:11:58,780 --> 01:12:05,820
and it's a logarithmic scale so the running becomes approximately logarithmic of the inverse coupling

1082
01:12:05,870 --> 01:12:09,340
if that's but it's the same calculation

1083
01:12:09,390 --> 01:12:10,740
and the same results

1084
01:12:10,970 --> 01:12:14,700
then we can also do this a similar thing for the weak interactions and the

1085
01:12:16,070 --> 01:12:18,390
basically electromagnetism

1086
01:12:18,390 --> 01:12:20,410
and we find that

1087
01:12:20,450 --> 01:12:25,210
with the uncertainties that we have from experiment which are indicated by the width of

1088
01:12:25,210 --> 01:12:26,530
these lines

1089
01:12:26,530 --> 01:12:27,850
down low energies

1090
01:12:27,910 --> 01:12:32,800
the extrapolation almost but not work quite work we don't quite find unification

1091
01:12:32,800 --> 01:12:35,060
due to

1092
01:12:36,540 --> 01:12:39,180
so what you get

1093
01:12:39,180 --> 01:12:40,450
all only other

1094
01:12:40,470 --> 01:12:43,370
document as one of the carbon chain

1095
01:12:43,390 --> 01:12:47,140
and then you count the occurrence of

1096
01:12:47,470 --> 01:12:50,350
so in that large

1097
01:12:50,350 --> 01:12:53,680
that large objects that you have

1098
01:12:53,760 --> 01:12:55,800
well actually you don't

1099
01:12:56,240 --> 01:13:01,410
of feature will take into account

1100
01:13:04,180 --> 01:13:12,260
this is to compute its conditional probability you counts the number of occurrences of that

1101
01:13:12,410 --> 01:13:16,160
normalized by the number of occurrences of the term

1102
01:13:16,200 --> 01:13:17,990
the class

1103
01:13:18,010 --> 01:13:22,390
you might want you would like to to

1104
01:13:22,410 --> 01:13:23,760
because of two

1105
01:13:23,780 --> 01:13:26,910
my occur in an object

1106
01:13:26,930 --> 01:13:30,120
class labels

1107
01:13:31,190 --> 01:13:34,260
and when you

1108
01:13:34,260 --> 01:13:39,140
so you can actually if you if it's not very clear there

1109
01:13:39,160 --> 01:13:41,850
you have not been made

1110
01:13:41,850 --> 01:13:43,310
if you want

1111
01:13:46,220 --> 01:13:50,220
and then

1112
01:13:50,240 --> 01:13:54,100
that that which you have to classify

1113
01:13:54,100 --> 01:13:55,280
you expect

1114
01:13:55,330 --> 01:14:00,120
the features of the tokens from that that i think that

1115
01:14:01,200 --> 01:14:02,970
and then for each class

1116
01:14:03,080 --> 01:14:08,890
you compute the probability that your that example belongs to class

1117
01:14:08,950 --> 01:14:13,370
so your computer core which is composed of a lot of the prior

1118
01:14:13,390 --> 01:14:15,680
but you have computed the

1119
01:14:16,740 --> 01:14:22,870
like a lot of this problem for each you also have the score

1120
01:14:23,080 --> 01:14:27,390
i look it from the conditional probability of that

1121
01:14:29,700 --> 01:14:30,430
and then

1122
01:14:31,720 --> 01:14:34,850
the core that maximize

1123
01:14:34,890 --> 01:14:37,660
the probability of class

1124
01:14:39,540 --> 01:14:43,930
three days

1125
01:14:43,990 --> 01:14:48,280
he with told quality that compared

1126
01:14:48,330 --> 01:14:51,700
the two models

1127
01:14:51,970 --> 01:15:02,180
here we take the multinomial model

1128
01:15:02,200 --> 01:15:09,310
we take into account multiple occurrences of the features which we do not individually

1129
01:15:11,800 --> 01:15:15,910
you want you have life completed

1130
01:15:21,430 --> 01:15:22,100
if you

1131
01:15:22,510 --> 01:15:25,100
do not remove stop words

1132
01:15:25,810 --> 01:15:27,060
and you

1133
01:15:27,080 --> 01:15:30,160
classified documents can be bought

1134
01:15:30,160 --> 01:15:33,370
the work that might talk

1135
01:15:33,430 --> 01:15:35,660
probably occurs

1136
01:15:35,680 --> 01:15:37,520
every document

1137
01:15:37,600 --> 01:15:41,400
so you have a probability of one the

1138
01:15:41,430 --> 01:15:43,190
close to one

1139
01:15:44,440 --> 01:15:46,470
the multinomial model

1140
01:15:59,800 --> 01:16:04,930
and i said to find the key probably let's use case one

1141
01:16:04,940 --> 01:16:09,400
classic my

1142
01:16:09,410 --> 01:16:10,980
that you have seen

1143
01:16:11,020 --> 01:16:13,070
or you could go on

1144
01:16:13,180 --> 01:16:15,110
some threshold

1145
01:16:15,110 --> 01:16:22,110
although this is made more difficult because the disadvantage of this method

1146
01:16:22,140 --> 01:16:25,980
that actually have to me

1147
01:16:26,040 --> 01:16:29,890
are not very accurate they

1148
01:16:30,660 --> 01:16:33,930
if you have many many pages with

1149
01:16:33,940 --> 01:16:35,850
two of

1150
01:16:40,410 --> 01:16:44,570
probability become very small you come close

1151
01:16:44,570 --> 01:16:46,760
and if you

1152
01:16:47,110 --> 01:16:52,640
the winning comes close to one of the probability

1153
01:16:55,690 --> 01:16:59,440
when expressed in the field robert e

1154
01:16:59,520 --> 01:17:12,390
let i call it we can go

1155
01:17:12,700 --> 01:17:16,300
otherwise may

1156
01:17:19,930 --> 01:17:24,200
classification which quite well

1157
01:17:24,260 --> 01:17:30,220
in natural language processing is much the maximum entropy

1158
01:17:30,270 --> 01:17:33,100
one might models

1159
01:17:33,110 --> 01:17:38,020
and i going to talk about the maximum entropy really

1160
01:17:38,040 --> 01:17:39,860
so we tried to

1161
01:17:40,230 --> 01:17:43,110
so we have to

1162
01:17:46,480 --> 01:17:49,140
because of the two

1163
01:17:49,260 --> 01:17:54,260
you choose the one with maximum like and

1164
01:17:54,270 --> 01:17:56,830
and this is used

1165
01:17:56,830 --> 01:18:00,490
logical implication is logical consequence

1166
01:18:07,460 --> 01:18:09,570
a couple of lemmas that's a

1167
01:18:09,620 --> 01:18:14,160
look at the relationship had a world between implication

1168
01:18:14,170 --> 01:18:16,140
and logical consequence

1169
01:18:16,150 --> 01:18:18,650
so what this is saying is that

1170
01:18:22,150 --> 01:18:23,950
a world makes

1171
01:18:23,990 --> 01:18:25,560
five true

1172
01:18:25,610 --> 01:18:28,670
and the world makes five splice site

1173
01:18:28,720 --> 01:18:30,990
in the world has to make site through

1174
01:18:31,000 --> 01:18:33,430
that's exactly the reasoning that we used here

1175
01:18:34,000 --> 01:18:35,780
if the world makes

1176
01:18:36,780 --> 01:18:40,060
an implication true and it makes the antecedent true

1177
01:18:40,130 --> 01:18:43,610
and it has to make the consequent true we got a contradiction here because of

1178
01:18:43,620 --> 01:18:45,070
the the set up

1179
01:18:45,320 --> 01:18:47,590
so what it's saying is that

1180
01:18:47,620 --> 01:18:48,670
something like

1181
01:18:48,680 --> 01:18:49,640
you know

1182
01:18:49,660 --> 01:18:55,070
phi and phi life cycle gives you cited works at world

1183
01:18:55,080 --> 01:19:00,180
you can use your classical stable it's all the same

1184
01:19:00,200 --> 01:19:03,150
then for any model

1185
01:19:06,210 --> 01:19:10,960
all of the members of phi and phi implies sire true everywhere

1186
01:19:10,970 --> 01:19:13,550
in size true everywhere

1187
01:19:13,600 --> 01:19:19,620
now i'm shifting all i'm doing on keeping these guys say

1188
01:19:19,630 --> 01:19:23,990
but i'm replacing the world the model

1189
01:19:23,990 --> 01:19:25,620
why is that well

1190
01:19:25,640 --> 01:19:28,850
what this says he's five string everywhere

1191
01:19:28,870 --> 01:19:31,570
five splice sites straight away

1192
01:19:32,420 --> 01:19:35,700
if that's the case then go to a particular well and you will be able

1193
01:19:35,700 --> 01:19:38,850
to do this step and you will be able to get the size throughout the

1194
01:19:40,030 --> 01:19:43,140
and this guy just this side through everywhere

1195
01:19:43,370 --> 01:19:47,860
beginning world you like and you can do that recently

1196
01:19:51,630 --> 01:19:53,320
part of the deduction

1197
01:19:55,480 --> 01:20:00,420
one half of the deduction theorem says

1198
01:20:01,950 --> 01:20:03,810
five implies

1199
01:20:03,920 --> 01:20:06,900
site so whenever

1200
01:20:06,910 --> 01:20:08,730
gamma is true everywhere

1201
01:20:08,740 --> 01:20:11,060
find size true everywhere

1202
01:20:11,080 --> 01:20:12,500
that holds

1203
01:20:12,500 --> 01:20:16,910
they in

1204
01:20:16,970 --> 01:20:19,850
size the logical consequence of these guys

1205
01:20:19,870 --> 01:20:22,780
so what's the same is you've got to model

1206
01:20:22,820 --> 01:20:25,210
and suppose gamma is true everywhere

1207
01:20:25,240 --> 01:20:29,270
and whenever you have that phi implies size to everywhere

1208
01:20:29,280 --> 01:20:31,320
that's your model that

1209
01:20:31,340 --> 01:20:32,600
now you say

1210
01:20:33,490 --> 01:20:39,590
suppose that you go to a model whereby bias gamma and phi is true everywhere

1211
01:20:39,670 --> 01:20:40,900
to you pick

1212
01:20:40,950 --> 01:20:42,390
sub model here

1213
01:20:42,400 --> 01:20:45,480
and you say well five true everywhere as well

1214
01:20:45,480 --> 01:20:48,510
well then size going to be true in a small part one

1215
01:20:49,450 --> 01:20:52,300
what this is is that the implication

1216
01:20:52,350 --> 01:20:56,750
is true everywhere so at this at all of these points in fact everywhere we

1217
01:20:56,750 --> 01:20:59,080
know that the implication holds

1218
01:20:59,090 --> 01:21:01,950
and then at this point the implication gets fired

1219
01:21:01,990 --> 01:21:05,600
and concise i becomes true

1220
01:21:05,620 --> 01:21:10,040
so one half deduction theorem says you can move

1221
01:21:10,070 --> 01:21:12,600
the phi across the our across this

1222
01:21:12,620 --> 01:21:14,590
it turns out to the left

1223
01:21:14,600 --> 01:21:16,210
i can't do it the other way

1224
01:21:16,210 --> 01:21:18,800
that's the point of this slide

1225
01:21:19,860 --> 01:21:23,110
in normal classical logic what you can do is you can also

1226
01:21:23,120 --> 01:21:25,800
go that way

1227
01:21:25,820 --> 01:21:28,240
but the modal logic fails

1228
01:21:31,530 --> 01:21:32,990
we know that

1229
01:21:33,030 --> 01:21:37,400
box p nor is a logical consequence of p

1230
01:21:37,490 --> 01:21:40,810
i wrote that i can remember one of the first examples i showed you was

1231
01:21:40,810 --> 01:21:46,180
box p nor is a logical consequence of p no

1232
01:21:48,170 --> 01:21:56,880
box p nor was the logical consequence of p know why

1233
01:21:57,930 --> 01:22:00,520
if the model makes p true everywhere

1234
01:22:00,560 --> 01:22:05,060
in any particular world the successes of the world may be not true right so

1235
01:22:05,060 --> 01:22:07,380
that's going to be true

1236
01:22:07,430 --> 01:22:09,450
but i claim that

1237
01:22:09,450 --> 01:22:10,590
you can't

1238
01:22:11,270 --> 01:22:13,910
i'm sitting here

1239
01:22:13,930 --> 01:22:17,800
and if i wanted to go up here i would move the phi across

1240
01:22:17,800 --> 01:22:19,340
so what i want to do

1241
01:22:19,360 --> 01:22:20,390
it is

1242
01:22:20,400 --> 01:22:26,720
i want to ask this question

1243
01:22:26,720 --> 01:22:28,770
we know that tells

1244
01:22:28,840 --> 01:22:33,200
does this whole you know which is true in any model

1245
01:22:33,270 --> 01:22:36,890
it's not the case because look take model

1246
01:22:37,970 --> 01:22:40,000
let's try and falsified his

1247
01:22:40,050 --> 01:22:43,950
how do we force flight find we make this tremendous falls

1248
01:22:43,960 --> 01:22:45,630
so we take a world

1249
01:22:45,700 --> 01:22:47,250
p is true

1250
01:22:47,270 --> 01:22:50,680
and box pino is false

1251
01:22:50,700 --> 01:22:53,220
can we do that well this is

1252
01:22:53,230 --> 01:22:57,950
it's not the case that every successor makes or true

1253
01:22:58,780 --> 01:23:01,810
all we have is the successor that makes peano false

1254
01:23:01,840 --> 01:23:03,600
we hope

1255
01:23:03,640 --> 01:23:07,070
so we were able to falsify this

1256
01:23:07,070 --> 01:23:08,240
there was a model

1257
01:23:08,260 --> 01:23:10,630
which made this falls

1258
01:23:11,260 --> 01:23:13,340
the claim is

1259
01:23:13,400 --> 01:23:14,790
if this is going to be

1260
01:23:15,000 --> 01:23:17,720
logical consequence if this is going to be of validity

1261
01:23:17,770 --> 01:23:21,200
then no model should do that and we were able to construct models

1262
01:23:21,300 --> 01:23:22,540
so this whole

1263
01:23:22,550 --> 01:23:25,700
but you can't take it across the implication

1264
01:23:25,720 --> 01:23:30,480
and here is a form of the deduction theorem but it's more complicated it's is

1265
01:23:30,480 --> 01:23:32,270
sort of this form

1266
01:23:32,280 --> 01:23:33,330
it says

1267
01:23:33,360 --> 01:23:37,400
if ci is a logical consequence of gamma com five

1268
01:23:37,450 --> 01:23:39,430
so in other words whenever

1269
01:23:39,460 --> 01:23:43,150
gamma com five true everywhere size true everywhere

1270
01:23:43,170 --> 01:23:45,070
if that hold

1271
01:23:46,580 --> 01:23:52,970
for some finite in which you can compute

1272
01:23:53,000 --> 01:23:56,810
the model that may gamma true make this implication true

1273
01:23:56,830 --> 01:23:58,700
and the implication is

1274
01:23:58,730 --> 01:24:02,200
five with no boxes in front of the phi with one box in front of

1275
01:24:02,200 --> 01:24:04,770
the phi with two box in front of up to

1276
01:24:04,780 --> 01:24:07,760
five million boxes in front

1277
01:24:07,780 --> 01:24:09,810
and that has to apply some

1278
01:24:09,830 --> 01:24:12,030
if you want to know how to compute in

1279
01:24:12,040 --> 01:24:14,720
look at the book by marcus krug in your

1280
01:24:15,450 --> 01:24:17,240
which is you know the

1281
01:24:17,250 --> 01:24:19,570
and i just don't have time to go

1282
01:24:19,590 --> 01:24:22,070
go into the details

1283
01:24:22,070 --> 01:24:26,350
well i want to say is the normal deduction theorem in which holds for classical

1284
01:24:26,350 --> 01:24:31,200
logic says whenever you have you whenever you have this you have this and whenever

1285
01:24:31,200 --> 01:24:33,250
you have this you have this

1286
01:24:33,320 --> 01:24:36,520
doesn't hold for modal logic one direction hold

1287
01:24:36,700 --> 01:24:38,400
this direction breaks down

1288
01:24:38,420 --> 01:24:39,560
that's the country

1289
01:24:39,600 --> 01:24:42,810
four to simple there are many

1290
01:24:46,530 --> 01:24:48,090
where am i

1291
01:24:48,150 --> 01:24:48,970
this is

1292
01:24:48,970 --> 01:24:52,340
end of lecture

1293
01:24:52,390 --> 01:24:55,570
the first lecture case a little bit of

1294
01:24:55,570 --> 01:24:58,090
started by defining formulae

1295
01:24:58,100 --> 01:25:00,850
i define what logical consequence was

1296
01:25:00,860 --> 01:25:05,040
and i showed you some properties of logical consequence

1297
01:25:05,050 --> 01:25:06,890
how did i do it well

1298
01:25:06,910 --> 01:25:12,850
the formula was just using this park is now four right this

1299
01:25:12,870 --> 01:25:15,500
specifies how formulaic construct

1300
01:25:15,540 --> 01:25:19,400
and i said that the models

1301
01:25:21,100 --> 01:25:24,150
logic consists of graphs which are framed

1302
01:25:24,240 --> 01:25:26,510
w are

1303
01:25:26,600 --> 01:25:27,410
and then

1304
01:25:27,420 --> 01:25:29,560
paid we have a valuation

1305
01:25:29,570 --> 01:25:34,930
so that's just w and evaluation at each world that's what the model looks like

1306
01:25:34,930 --> 01:25:36,040
sixty seven

1307
01:25:36,090 --> 01:25:38,190
was proposed by bregman

1308
01:25:38,250 --> 01:25:44,790
and he proposed that in order to solve this optimisation problem you would they have

1309
01:25:44,790 --> 01:25:49,530
this effect distance bregman divergence and you have not only one equation but you have

1310
01:25:49,530 --> 01:25:51,420
several equality equations

1311
01:25:52,640 --> 01:25:58,280
equality constraints so like one constraint for every hypothesis

1312
01:25:58,280 --> 01:26:01,680
then you do the following so you start off with the

1313
01:26:02,020 --> 01:26:05,410
initially the you project to the first half plane

1314
01:26:05,420 --> 01:26:10,070
OK then the project to the second half plane try to draw the somehow then

1315
01:26:10,080 --> 01:26:14,300
you choose another hyperplane and so on this converges to the

1316
01:26:14,380 --> 01:26:17,800
o point which is on the intersection of all hyperplanes

1317
01:26:17,850 --> 01:26:23,940
and which is closest to the to the original point in that metric

1318
01:26:23,990 --> 01:26:28,280
OK just go on protecting these things and then converges

1319
01:26:28,290 --> 01:26:33,550
that's what collaboration leveraging stream but due to me this completely equivalent to the according

1320
01:26:33,550 --> 01:26:36,080
to send is just a different view on

1321
01:26:36,250 --> 01:26:41,190
the problem the problem is just this one so this is the common properties

1322
01:26:41,240 --> 01:26:45,950
and he did according to sit in this function g is the convex conjugate function

1323
01:26:45,950 --> 01:27:10,050
to this calligraphy she

1324
01:27:20,840 --> 01:27:23,020
so it was

1325
01:27:24,840 --> 01:27:27,360
of the c

1326
01:27:27,370 --> 01:27:31,320
the difference

1327
01:27:43,900 --> 01:27:47,660
so you want

1328
01:27:48,060 --> 01:27:51,990
the only

1329
01:27:59,810 --> 01:28:06,150
less than five hundred one of the most

1330
01:28:11,930 --> 01:28:14,940
why is that

1331
01:28:16,170 --> 01:28:18,460
of those are the only

1332
01:28:28,380 --> 01:28:30,390
this is for

1333
01:28:35,540 --> 01:28:38,200
there's no no

1334
01:28:39,890 --> 01:28:41,540
these sites

1335
01:28:47,040 --> 01:28:52,360
and a

1336
01:28:57,410 --> 01:29:06,840
well these days

1337
01:29:14,690 --> 01:29:16,640
to know how

1338
01:29:20,620 --> 01:29:24,910
so all

1339
01:29:25,050 --> 01:29:29,370
the other stuff all

1340
01:29:29,540 --> 01:29:33,160
and also

1341
01:29:33,170 --> 01:29:39,160
he is

1342
01:29:51,850 --> 01:29:53,910
he was

1343
01:29:53,940 --> 01:29:58,860
i have in mind

1344
01:29:58,900 --> 01:30:01,300
national of

1345
01:30:02,830 --> 01:30:04,930
by so

1346
01:30:16,270 --> 01:30:17,820
o five

1347
01:30:17,830 --> 01:30:29,690
o thing

1348
01:30:29,700 --> 01:30:31,640
a that's all

1349
01:31:16,100 --> 01:31:19,470
little methods interior point methods

1350
01:31:19,940 --> 01:31:24,320
and well so we can simply apply this to this problem

1351
01:31:24,320 --> 01:31:28,550
so now the problem is that the number of hypotheses can be very large or

1352
01:31:28,550 --> 01:31:33,160
even infinite so and house boosting solving this task so how is this related to

1353
01:31:33,510 --> 01:31:35,170
to these methods

1354
01:31:36,140 --> 01:31:41,530
so i'm claiming this is very much related to very optimisation can introduce very optimisation

1355
01:31:41,680 --> 01:31:44,220
so the idea of very optimisation is that you

1356
01:31:44,270 --> 01:31:48,650
then you have to solve this optimisation problem so minimize g with respect to to

1357
01:31:49,040 --> 01:31:54,690
constraints and constraints in terms of peter which are greater than zero for instance

1358
01:31:54,860 --> 01:31:59,290
then you are minimizing so this a constrained optimization problem then the idea is to

1359
01:31:59,290 --> 01:32:04,650
minimize a unconstrained optimization problems they minimalist your feet plus

1360
01:32:05,710 --> 01:32:07,640
which depends on c

1361
01:32:07,640 --> 01:32:08,880
of theta

1362
01:32:08,900 --> 01:32:12,250
and here we have this function cup beta

1363
01:32:12,300 --> 01:32:14,320
that's very function k

1364
01:32:14,360 --> 01:32:21,230
and that has the idea that pushes away this these CNC away from zero so

1365
01:32:21,230 --> 01:32:27,470
it should not pass zero so essentially it might be having the shape so everything

1366
01:32:27,470 --> 01:32:31,900
which is on this site is not satisfying the constraint and everything on this i

1367
01:32:31,900 --> 01:32:35,220
said find the constraint it has maybe this shape so it could be for instance

1368
01:32:35,470 --> 01:32:37,090
the log function or something

1369
01:32:37,170 --> 01:32:40,530
and posting it's actually the exponential function so

1370
01:32:40,570 --> 01:32:43,800
so this is one way so there's a lot of area this leads to interior

1371
01:32:43,800 --> 01:32:45,030
point method

1372
01:32:45,050 --> 01:32:49,020
and i'm showing you the this function here so this beta

1373
01:32:49,070 --> 01:32:54,700
e to the minus t over beta this exponential very and this leads to boosting

1374
01:32:54,720 --> 01:33:00,610
OK so the idea is that you let peter go to zero

1375
01:33:00,620 --> 01:33:05,880
OK and for every beta you minimize this EP to

1376
01:33:06,970 --> 01:33:11,480
then as you let people go beta to zero this converges to the optimal parameter

1377
01:33:11,590 --> 01:33:14,210
in the optimal solution is one

1378
01:33:14,980 --> 01:33:21,330
so solving this optimisation problem with a prolific speed it's just normal gradient i mean

1379
01:33:21,330 --> 01:33:23,340
you can use the normal gradient method

1380
01:33:23,340 --> 01:33:26,230
because this is just an unconstrained optimization problem OK

1381
01:33:26,350 --> 01:33:29,120
and idea is that you solve this for fixed beta

1382
01:33:29,140 --> 01:33:35,210
then decrease peter and start the previous solution that you need to the live this

1383
01:33:35,770 --> 01:33:42,110
OK and the new arrive at the optimal solution

1384
01:33:42,160 --> 01:33:43,250
OK so

1385
01:33:44,620 --> 01:33:48,640
let's do this flower maxmargin margin

1386
01:33:48,670 --> 01:33:53,680
so we would like to just rewrite the max margin problem in that way OK

1387
01:33:53,750 --> 01:33:55,240
so we would like to minimize

1388
01:33:55,340 --> 01:34:03,700
minus role so much maestro and such that the margin of the end for example

1389
01:34:03,710 --> 01:34:06,530
is greater than wrote that means

1390
01:34:06,540 --> 01:34:08,930
rho n minus role quickly because you

1391
01:34:08,990 --> 01:34:10,030
OK in the

1392
01:34:10,150 --> 01:34:14,560
barrier function just looks like this i put in the

1393
01:34:14,570 --> 01:34:20,540
objective here and this is the sea and i just put this into in here

1394
01:34:23,030 --> 01:34:24,890
OK now let's

1395
01:34:24,950 --> 01:34:28,290
use the exponential barrier for the function

1396
01:34:28,290 --> 01:34:31,050
this is this one here

1397
01:34:31,060 --> 01:34:34,520
OK so i just plugged in the the barrier function

1398
01:34:34,520 --> 01:34:37,700
to to do this very low level correction

1399
01:34:40,160 --> 01:34:46,600
and then of course every experiment every biological experiments different the difficulty of comparing different

1400
01:34:46,600 --> 01:34:51,680
measurement for you to see measurement again you get different results and how

1401
01:34:51,730 --> 01:34:54,780
do you make these results

1402
01:34:54,810 --> 01:34:59,380
so there are few other techniques like you if you are which is a hundred

1403
01:34:59,380 --> 01:35:07,160
quantitative polymerase chain reaction very accurate for measuring inflation mps page we can look up

1404
01:35:07,160 --> 01:35:09,790
on wikipedia

1405
01:35:09,840 --> 01:35:15,890
OK so you can also measure the expression of proteins and metabolites points in what

1406
01:35:15,890 --> 01:35:18,250
you see here years to the

1407
01:35:18,260 --> 01:35:26,920
feel like races so where you separate proteins in two directions according to one two

1408
01:35:26,930 --> 01:35:31,480
properties like size and maybe

1409
01:35:31,530 --> 01:35:36,870
whatever sort of the property and then you see the point that i concentration of

1410
01:35:37,820 --> 01:35:43,610
these proteins you can then have a look at more detail either you know which

1411
01:35:43,610 --> 01:35:45,060
could and should be there

1412
01:35:45,110 --> 01:35:49,110
or even if you don't know then you can analyse with the last thing try

1413
01:35:49,340 --> 01:35:52,870
and put which proteins are really

1414
01:35:52,870 --> 01:35:58,420
so in the end we get a metric which is has size i mean you

1415
01:35:58,420 --> 01:36:02,590
analyse different temple you look at large number of different genes

1416
01:36:02,620 --> 01:36:04,870
so what you would like to see it

1417
01:36:07,130 --> 01:36:08,970
which points to have a certain

1418
01:36:10,180 --> 01:36:15,790
maybe when you're having a look at the disease sample points in the people with

1419
01:36:15,790 --> 01:36:20,370
the disease you would expect that certain genes are one and you will be able

1420
01:36:20,370 --> 01:36:23,330
to identify the here

1421
01:36:23,340 --> 01:36:24,790
so for example

1422
01:36:24,800 --> 01:36:26,770
you see that gene

1423
01:36:27,480 --> 01:36:33,410
are all next year when he was used some clustering techniques to find out which

1424
01:36:33,410 --> 01:36:36,850
are the groups in

1425
01:36:36,890 --> 01:36:39,650
while which genes are really charming

1426
01:36:42,690 --> 01:36:47,090
so this also three d structure mentioned

1427
01:36:48,120 --> 01:36:52,330
essentially what we have there is that what we get is the three d structure

1428
01:36:52,340 --> 01:36:55,440
of every atom in the protein

1429
01:36:56,370 --> 01:37:00,260
and if you know the protein structure then we can we can try to infer

1430
01:37:00,270 --> 01:37:03,030
the function of the protein

1431
01:37:03,040 --> 01:37:05,950
so there are two basic techniques one and on

1432
01:37:06,010 --> 01:37:12,610
and one in x-ray crystallography this one is better for small molecules and this one

1433
01:37:13,520 --> 01:37:19,020
much more difficult only works for those proteins which in this life

1434
01:37:19,550 --> 01:37:24,790
but you can also do what i i

1435
01:37:28,000 --> 01:37:32,000
so then you been that protein interactions

1436
01:37:32,000 --> 01:37:36,440
and there are several ways of measuring these interactions i want to go into detail

1437
01:37:36,440 --> 01:37:39,910
i some people being already so

1438
01:37:40,050 --> 01:37:43,710
the main idea is that you consider one protein and then you try to find

1439
01:37:43,730 --> 01:37:49,540
out where the protein which parts of the protein in that case i mean to

1440
01:37:49,540 --> 01:37:53,270
either DNA or you can fish out of water

1441
01:37:53,330 --> 01:37:54,710
that's fine too

1442
01:37:57,000 --> 01:38:03,150
this is good for transcriptional regulation and four on a processing regulation of the full

1443
01:38:05,560 --> 01:38:14,580
OK so so there are many other data types available protein DNA actually subsidies localization

1444
01:38:14,600 --> 01:38:18,710
protein sequence itself we can sequences but but but but

1445
01:38:18,830 --> 01:38:22,150
protein modifications by mass spectrometry

1446
01:38:22,150 --> 01:38:24,270
mass spectrometry military

1447
01:38:24,330 --> 01:38:30,380
and also i who was winning which is usually used in some statistics

1448
01:38:30,400 --> 01:38:34,940
many more data exist and they actually the

1449
01:38:34,960 --> 01:38:37,560
mean the techniques for generating new data

1450
01:38:37,560 --> 01:38:41,420
constantly being invented

1451
01:38:41,440 --> 01:38:45,610
so why should we have a look at the data set

1452
01:38:46,330 --> 01:38:49,350
first of all most these techniques are not

1453
01:38:49,370 --> 01:38:55,710
o three i mean because money right so and if you can find prediction to

1454
01:38:55,710 --> 01:38:57,520
replace measurement

1455
01:38:57,580 --> 01:38:59,730
then i mean based on other

1456
01:38:59,790 --> 01:39:02,670
then of course there's a lot of money

1457
01:39:02,730 --> 01:39:05,900
so this is to a quite so if the

1458
01:39:05,900 --> 01:39:07,790
the second if people

1459
01:39:07,810 --> 01:39:13,860
model because able to model data said well then we can based on these models

1460
01:39:13,960 --> 01:39:15,960
also try to understand biology

1461
01:39:15,980 --> 01:39:21,230
i mean so you can point since try to reconstruct the whole underlying the biological

1462
01:39:23,130 --> 01:39:26,610
OK so based on

1463
01:39:26,630 --> 01:39:30,310
eight analysis as you can also try to reconstruct the past twenty

1464
01:39:30,330 --> 01:39:36,270
what when you analyse genome you can try to infer how have these genomes evolve

1465
01:39:36,270 --> 01:39:39,230
so we construct like evolution

1466
01:39:39,330 --> 01:39:42,770
and of course we would like to predict the future so for instance we would

1467
01:39:42,770 --> 01:39:47,130
like to to predict whether a certain compound which is used for treatment of the

1468
01:39:47,130 --> 01:39:49,580
disease but this is going to be

1469
01:39:50,750 --> 01:39:57,190
useful for treating this disease or whether it's interfering with other

1470
01:39:57,500 --> 01:40:00,270
proteins which it shouldn't interfere with and so on

1471
01:40:00,650 --> 01:40:02,350
and of course

1472
01:40:02,370 --> 01:40:07,810
maybe also try to improve organism point and this is what people

1473
01:40:07,830 --> 01:40:10,850
with the only thing that appear

1474
01:40:13,380 --> 01:40:17,060
so there are lots of different specialized problems

1475
01:40:17,610 --> 01:40:24,380
so for instance find structure which is stored somehow nineteen eighty four predict properties of

1476
01:40:24,670 --> 01:40:32,310
proteins or relate molecular with microscopic they that what be data and i mentioned that

1477
01:40:32,310 --> 01:40:38,290
one of the problems by image analysis measurement normalisation sequence processing and so on

1478
01:40:38,420 --> 01:40:44,160
i just give you a few more examples here for instance fact finding structure and

1479
01:40:44,160 --> 01:40:48,040
DNA that could be we have just the sequence

1480
01:40:48,060 --> 01:40:50,190
and now compare

1481
01:40:50,210 --> 01:40:51,940
several people

1482
01:40:52,060 --> 01:40:54,210
we can see that the evolutionary history

1483
01:40:54,310 --> 01:41:01,580
we find rearrangement and application between several of the whole population

1484
01:41:01,630 --> 01:41:06,920
you can also try to reconstruct the phylogeny of species we can try to find

1485
01:41:06,940 --> 01:41:11,560
out how one species is related to another of how close are the

1486
01:41:11,580 --> 01:41:13,900
we can both trees and so on

1487
01:41:13,900 --> 01:41:17,290
on the other hand you can try to find genes and i'm going to talk

1488
01:41:17,290 --> 01:41:21,130
about what the result is the gene structure

1489
01:41:21,750 --> 01:41:24,100
one part of what

1490
01:41:24,130 --> 01:41:26,520
trying to then transcriptional regulation

1491
01:41:26,520 --> 01:41:32,960
when certain genes which on the edge of the measurement data with the expression measurements

1492
01:41:32,960 --> 01:41:36,540
and give the conditions very much of the data and then you can try to

1493
01:41:36,540 --> 01:41:38,250
relate the sequence

1494
01:41:38,330 --> 01:41:40,000
the UK

1495
01:41:41,040 --> 01:41:46,060
the expression pattern and try to predict the expression than just

1496
01:41:46,170 --> 01:41:51,330
and the same you can identify life-sized identify coding sequences

1497
01:41:51,330 --> 01:41:57,900
you can identify items despising what i mentioned so when this intron spliced out winners

1498
01:41:57,900 --> 01:42:03,060
by in one there's a lot of the machinery of

1499
01:42:06,960 --> 01:42:10,110
you can also predict protein properties

1500
01:42:10,110 --> 01:42:13,630
pencil the direction of the current

1501
01:42:13,710 --> 01:42:15,070
so now

1502
01:42:15,120 --> 01:42:19,320
he put around the solenoid

1503
01:42:19,370 --> 01:42:23,630
a look

1504
01:42:23,630 --> 01:42:26,060
let's call this the number two

1505
01:42:26,190 --> 01:42:27,980
it was around the solenoid

1506
01:42:28,020 --> 01:42:30,900
and that's called this number one

1507
01:42:30,950 --> 01:42:36,000
o which the solenoid is part

1508
01:42:36,050 --> 01:42:39,430
when i was the current number one

1509
01:42:39,480 --> 01:42:42,560
he never managed to see the current number two

1510
01:42:42,570 --> 01:42:46,130
if there is a current going number one that is the magnetic fields

1511
01:42:46,210 --> 01:42:50,070
and the metrics needed field is seen of course by

1512
01:42:50,070 --> 01:42:52,550
the conductor number two by that look

1513
01:42:52,560 --> 01:42:54,380
never any

1514
01:42:54,390 --> 01:42:58,260
so he concluded that a steady magnetic fields

1515
01:42:58,260 --> 01:42:59,630
as produced by

1516
01:42:59,640 --> 01:43:01,640
the solenoid

1517
01:43:01,700 --> 01:43:04,280
circuit one does not produce

1518
01:43:04,300 --> 01:43:05,820
the steady current

1519
01:43:05,880 --> 01:43:06,880
in number two

1520
01:43:06,930 --> 01:43:09,070
but then one day

1521
01:43:09,120 --> 01:43:10,380
you notice

1522
01:43:10,430 --> 01:43:11,690
but as he

1523
01:43:11,700 --> 01:43:13,580
close to switch

1524
01:43:13,590 --> 01:43:15,750
these are current number two

1525
01:43:15,840 --> 01:43:17,580
open to switch

1526
01:43:17,630 --> 01:43:20,630
again he saw current number two

1527
01:43:20,680 --> 01:43:22,840
and therefore he now concluded

1528
01:43:22,920 --> 01:43:25,090
changing magnetic fields

1529
01:43:25,150 --> 01:43:26,200
is causing

1530
01:43:26,210 --> 01:43:31,960
the current not a steady magnetic field but the changing magnetic field

1531
01:43:32,070 --> 01:43:35,060
and this was the profound discovery

1532
01:43:35,130 --> 01:43:37,210
which changed our world

1533
01:43:37,230 --> 01:43:39,230
and it contributed largely

1534
01:43:39,240 --> 01:43:40,860
two technological

1535
01:43:42,190 --> 01:43:46,500
of the late nineteenth and early twentieth century

1536
01:43:46,530 --> 01:43:48,260
the current

1537
01:43:48,260 --> 01:43:52,690
therefore an electric field can be produced by changing

1538
01:43:52,740 --> 01:43:55,000
the magnetic field

1539
01:43:55,050 --> 01:43:57,210
and that phenomenon is called

1540
01:43:57,230 --> 01:43:59,420
electromagnetic induction

1541
01:43:59,430 --> 01:44:00,860
and and that phenomenon

1542
01:44:00,870 --> 01:44:04,180
runs our economy as you will see

1543
01:44:04,230 --> 01:44:05,150
in the next

1544
01:44:05,180 --> 01:44:11,950
few lectures

1545
01:44:12,020 --> 01:44:15,000
i have here a conducting wire

1546
01:44:16,380 --> 01:44:18,590
i could have chosen any other shape

1547
01:44:18,620 --> 01:44:21,380
try to make you see three-dimensional

1548
01:44:21,420 --> 01:44:23,480
and i approached this

1549
01:44:23,490 --> 01:44:25,230
conducting wire

1550
01:44:25,270 --> 01:44:27,800
was obama by magnets

1551
01:44:27,890 --> 01:44:30,250
as a magnetic field

1552
01:44:30,280 --> 01:44:31,750
running like so

1553
01:44:31,850 --> 01:44:36,260
as i approach that

1554
01:44:37,090 --> 01:44:39,080
that conducting wire

1555
01:44:39,130 --> 01:44:43,880
moving the bar magnet that's essential i can hold it still have to move it

1556
01:44:43,890 --> 01:44:46,850
if i come down from above and i moved it down

1557
01:44:46,860 --> 01:44:48,840
we're going to see your current going

1558
01:44:49,630 --> 01:44:52,480
this look

1559
01:44:52,500 --> 01:44:54,420
and that current

1560
01:44:55,050 --> 01:44:57,180
go into such direction

1561
01:44:57,200 --> 01:44:59,240
that it opposes

1562
01:44:59,250 --> 01:45:02,090
the change of the magnetic fields

1563
01:45:02,130 --> 01:45:05,920
the magnetic field is in down direction and it is increasing as i move the

1564
01:45:05,920 --> 01:45:08,790
bar magnet in then this current loop

1565
01:45:08,800 --> 01:45:10,630
it will produce a magnetic field

1566
01:45:10,640 --> 01:45:15,590
which is in this direction and when you look from below

1567
01:45:15,630 --> 01:45:17,520
currently go clockwise

1568
01:45:17,530 --> 01:45:19,000
producing a

1569
01:45:19,880 --> 01:45:22,450
magnetic field in this direction

1570
01:45:22,460 --> 01:45:25,770
if you move the bar magnet out

1571
01:45:25,780 --> 01:45:27,340
then the magnetic

1572
01:45:27,420 --> 01:45:28,310
field is

1573
01:45:28,330 --> 01:45:29,750
going down here

1574
01:45:29,760 --> 01:45:31,720
then the current will reverse

1575
01:45:31,760 --> 01:45:32,910
the current

1576
01:45:32,920 --> 01:45:35,430
he wants to oppose the change

1577
01:45:35,490 --> 01:45:38,000
in the magnetic field

1578
01:45:38,010 --> 01:45:40,200
and that's called lens law

1579
01:45:40,210 --> 01:45:43,080
it is the most human law in physics

1580
01:45:43,170 --> 01:45:45,700
because this inertia in all of us

1581
01:45:46,500 --> 01:45:50,730
o fight change at some level

1582
01:45:50,770 --> 01:45:52,000
lenses law

1583
01:45:52,030 --> 01:45:56,790
is extremely powerful in always determining in which direction

1584
01:45:56,840 --> 01:45:58,580
these induced currents

1585
01:45:58,590 --> 01:45:59,450
i will

1586
01:46:00,220 --> 01:46:02,300
it is not a quantitative law

1587
01:46:02,310 --> 01:46:03,730
you cannot calculate

1588
01:46:03,740 --> 01:46:05,880
how strong the current will be

1589
01:46:05,920 --> 01:46:08,450
but it's very useful as you will see today

1590
01:46:09,260 --> 01:46:10,180
the direction

1591
01:46:10,200 --> 01:46:11,430
of that current

1592
01:46:11,450 --> 01:46:13,850
get you out of all kinds of problems

1593
01:46:13,860 --> 01:46:19,150
with minus signs

1594
01:46:19,160 --> 01:46:21,630
i now want to do demonstration

1595
01:46:21,670 --> 01:46:23,720
which is very much like

1596
01:46:23,760 --> 01:46:26,720
what you see here

1597
01:46:26,760 --> 01:46:32,000
i have here

1598
01:46:32,010 --> 01:46:33,510
a look

1599
01:46:33,520 --> 01:46:35,930
that is discredit you see there except

1600
01:46:35,950 --> 01:46:38,120
that's not one loop

1601
01:46:38,160 --> 01:46:44,260
but as many of them

1602
01:46:44,260 --> 01:46:49,240
hundreds doesn't matter

1603
01:46:49,280 --> 01:46:51,180
and what we're going to show you

1604
01:46:52,760 --> 01:46:55,980
and and near

1605
01:46:56,020 --> 01:47:00,520
that is connected sort is somewhere in the circuit in and here

1606
01:47:00,580 --> 01:47:02,040
however by making it

1607
01:47:02,050 --> 01:47:03,780
and i'm going to approach

1608
01:47:03,840 --> 01:47:06,250
this conducting look

1609
01:47:06,250 --> 01:47:09,060
to bring together actually

1610
01:47:09,070 --> 01:47:16,570
very interesting work has been going on in more probability pascal probabilities into learning theory

1611
01:47:16,570 --> 01:47:17,850
so there's been

1612
01:47:17,860 --> 01:47:23,220
a lot of study of the behavior of distributions

1613
01:47:23,230 --> 01:47:26,940
and in particular when they are so-called concentrated

1614
01:47:29,940 --> 01:47:36,860
this has become seen as and very shown to be very relevant in

1615
01:47:36,870 --> 01:47:41,370
trying to analyse learning systems in this statistical learning framework so i want to give

1616
01:47:41,370 --> 01:47:44,070
you a flavor that and in particular the

1617
01:47:44,080 --> 01:47:48,610
the main sort of gold today is to be true to rademacher complexity

1618
01:47:48,620 --> 01:47:51,720
which i think has

1619
01:47:51,720 --> 01:47:54,350
once you get the hang of it is actually law

1620
01:47:56,070 --> 01:47:57,560
easier to work with

1621
01:47:57,560 --> 01:48:02,300
and potentially i think something that people might pick up and use in particular

1622
01:48:02,310 --> 01:48:06,340
applications in and analysis is so i'm hoping to give you a sort of if

1623
01:48:06,340 --> 01:48:13,870
you like user's guide to how to apply the rademacher complexity in the hope that

1624
01:48:13,870 --> 01:48:15,720
you might find this useful

1625
01:48:15,730 --> 01:48:17,940
but i think also

1626
01:48:19,510 --> 01:48:23,940
i believe you know some of the things we saw yesterday i think you'll enjoy

1627
01:48:24,790 --> 01:48:29,390
some of the ideas and techniques that have been developed to you to apply these

1628
01:48:29,390 --> 01:48:34,090
ideas in learning so hopefully you know will be there will be some fun to

1629
01:48:34,090 --> 01:48:35,330
be had on the way

1630
01:48:35,350 --> 01:48:39,710
maybe some applications that you might make this stuff later

1631
01:48:40,210 --> 01:48:44,160
and of course you know you you get a few more words into your vocabulary

1632
01:48:44,160 --> 01:48:45,050
that can

1633
01:48:45,070 --> 01:48:51,970
use this cocktail party so OK so

1634
01:48:51,980 --> 01:48:57,640
if we're looking at statistical learning is concerned with reliability and stability of inferences made

1635
01:48:57,640 --> 01:49:01,350
from a random sample that's sort of where we started yesterday and if you remember

1636
01:49:01,350 --> 01:49:05,540
those this

1637
01:49:05,610 --> 01:49:11,680
distribution functions like plotted when looking at the size of the sample for learning parzen

1638
01:49:11,680 --> 01:49:16,370
windows and how they sort of started very very concentrated very tight and then as

1639
01:49:16,370 --> 01:49:21,860
i took a smaller and smaller sample a sort of got more and more sloppy

1640
01:49:21,860 --> 01:49:27,740
in the way they behaved and eventually you know became very unreliable to infer anything

1641
01:49:27,740 --> 01:49:34,400
concentration is precisely that property of having a distribution that is concentrated in the sense

1642
01:49:34,400 --> 01:49:36,570
focused around the mean

1643
01:49:36,600 --> 01:49:38,230
of distribution

1644
01:49:38,230 --> 01:49:41,990
and this is said to have been the subject of study for

1645
01:49:43,960 --> 01:49:49,400
as you know very classical result actually is of her thing is exactly of this

1646
01:49:49,400 --> 01:49:54,480
type so i wanted to just briefly remind you of that if all you know

1647
01:49:54,480 --> 01:49:59,920
show you it if you're not familiar with it and it leads very nicely into

1648
01:49:59,920 --> 01:50:01,550
into the sort of

1649
01:50:01,610 --> 01:50:08,520
next perhaps slightly more advanced concentration inequality that i'd like to show you but his

1650
01:50:08,520 --> 01:50:11,850
her things results it relates to

1651
01:50:11,860 --> 01:50:14,250
the mean of

1652
01:50:14,330 --> 01:50:16,880
a set of random variables x one it

1653
01:50:16,910 --> 01:50:20,440
up two x and which are assumed to be independent which i failed to put

1654
01:50:20,440 --> 01:50:22,860
on this slide but

1655
01:50:22,870 --> 01:50:27,710
if you go to pan right independent down there

1656
01:50:29,910 --> 01:50:35,440
basically the assumption about the variables is really quite we call we assume is that

1657
01:50:35,440 --> 01:50:40,530
they are are bounded within range AI two by each independent i mean the different

1658
01:50:40,540 --> 01:50:45,810
it does not seem to be the same identical in that sense of the independent

1659
01:50:45,810 --> 01:50:48,180
but not necessarily identical

1660
01:50:48,190 --> 01:50:51,000
and the inequality bounds the

1661
01:50:51,000 --> 01:50:54,590
the probability that the particular

1662
01:50:55,230 --> 01:50:58,900
instantiation of this random variable as a

1663
01:50:58,920 --> 01:51:02,970
so in order to compute and we pick a random x one

1664
01:51:03,120 --> 01:51:07,190
random x two to random access we add them up and we die by and

1665
01:51:07,230 --> 01:51:09,670
we get about so imagine

1666
01:51:09,690 --> 01:51:13,140
you know one possibility would be you've got a sort of

1667
01:51:13,180 --> 01:51:18,900
a one-dimensional input and you just computing its mean so you've taken and dimensional sample

1668
01:51:19,340 --> 01:51:21,490
and compute the mean and

1669
01:51:21,490 --> 01:51:26,520
that's that's sn for you OK and what this is trying to do is compute

1670
01:51:26,530 --> 01:51:27,860
the probability

1671
01:51:29,970 --> 01:51:34,830
that means in particular

1672
01:51:36,260 --> 01:51:39,710
is significantly different from its expected value

1673
01:51:39,720 --> 01:51:41,180
so in those

1674
01:51:41,210 --> 01:51:45,150
plots i showed you if you remember i had the mean is a little circle

1675
01:51:45,250 --> 01:51:49,330
and then the distribution so this is precisely computing the probability

1676
01:51:49,380 --> 01:51:55,290
but you can have samples significantly deviated from that circle

1677
01:51:55,300 --> 01:51:59,740
and what this is saying is that the probability of being greater than or equal

1678
01:51:59,740 --> 01:52:03,280
to epsilon is less than or equal to some

1679
01:52:03,300 --> 01:52:06,620
exponentially decaying function

1680
01:52:06,650 --> 01:52:10,870
and notice that the exponential decay

1681
01:52:10,880 --> 01:52:12,720
depends on epsilon so

1682
01:52:12,720 --> 01:52:15,390
as epsilon goes away were going to get

1683
01:52:15,410 --> 01:52:17,550
it's more and smaller values

1684
01:52:17,560 --> 01:52:22,660
m squared now that m squared actually is a bit deceptive because there's some two

1685
01:52:22,660 --> 01:52:24,270
and on the bottom here

1686
01:52:24,280 --> 01:52:29,000
so if you imagine these all being the same when you get this some equal

1687
01:52:29,000 --> 01:52:31,360
to m time some constants

1688
01:52:31,390 --> 01:52:34,550
one of the ends will cancel but they still being among the top here so

1689
01:52:34,550 --> 01:52:42,160
as the sample size increases it's going to shrink the the range of that display

1690
01:52:42,160 --> 01:52:46,830
in the in the distribution and it's coming gonna become concentrated around that the

1691
01:52:47,890 --> 01:52:51,120
so that that's the sort of flavor that we're looking for

1692
01:52:51,130 --> 01:52:55,420
exponential decay away from the mean of the distribution

1693
01:52:56,760 --> 01:52:57,940
OK so

1694
01:52:57,970 --> 01:53:00,850
with that flavour let's move to

1695
01:53:02,160 --> 01:53:04,340
how concentration can help

1696
01:53:04,350 --> 01:53:06,470
statistical learning theory

1697
01:53:06,470 --> 01:53:12,620
and the results come from what are known as concentration inequalities again as a really

1698
01:53:12,620 --> 01:53:17,110
good phrase to use i thought about the concentration inequality

1699
01:53:17,110 --> 01:53:20,250
conjugate gradients are completely hopeless

1700
01:53:20,270 --> 01:53:25,090
with stochastic approximation never tried to do that it's just

1701
01:53:25,110 --> 01:53:26,860
can't work

1702
01:53:26,860 --> 01:53:31,750
the other algorithms typically what happens is that too expensive so they mark court for

1703
01:53:31,750 --> 01:53:34,360
instance order in q

1704
01:53:34,360 --> 01:53:38,590
you don't want to run an audi q algorithms

1705
01:53:38,610 --> 01:53:43,080
on so little evidence you just have sort of a little patch of current data

1706
01:53:43,210 --> 01:53:45,270
and you don't really want to do this

1707
01:53:45,300 --> 01:53:50,040
brings heavy machinery to bear on this data because the minimum that you'll find will

1708
01:53:50,040 --> 01:53:51,440
be a different one

1709
01:53:51,460 --> 01:53:54,650
every time depending on which data you happen to have

1710
01:53:54,710 --> 01:53:56,460
and it's very costly

1711
01:53:56,480 --> 01:53:58,110
it's very expensive

1712
01:53:58,130 --> 01:54:02,770
so those algorithms pretty much out of the question

1713
01:54:02,770 --> 01:54:04,900
and now

1714
01:54:04,940 --> 01:54:09,270
what we're left with is basically no simple methods and then things like common field

1715
01:54:09,440 --> 01:54:13,340
use it as a generic term for these sort of second order

1716
01:54:13,360 --> 01:54:17,540
online maximum likelihood methods from signal processing

1717
01:54:19,070 --> 01:54:24,980
those work they explicitly incorporate a model of the stochastic nature of the data

1718
01:54:25,000 --> 01:54:30,170
but they typically make strong assumptions about what the nature of the data is

1719
01:54:30,170 --> 01:54:34,980
so if you actual data violates these assumptions they don't work anymore

1720
01:54:35,000 --> 01:54:38,270
so if you if you have a good knowledge of how you data looks like

1721
01:54:38,270 --> 01:54:40,000
this may be the way to go

1722
01:54:40,090 --> 01:54:43,610
however these things are ordained square

1723
01:54:43,650 --> 01:54:48,320
and so if you and gets big if you parameter space gets gets very large

1724
01:54:48,360 --> 01:54:52,090
then you can't use it either

1725
01:54:52,150 --> 01:54:54,540
and so then you just left with those two

1726
01:54:54,550 --> 01:54:55,960
and now finally

1727
01:54:55,980 --> 01:54:58,920
i explained why i do the research and doing

1728
01:55:00,550 --> 01:55:03,840
if you set it up just right if you set up your problem just right

1729
01:55:03,840 --> 01:55:08,110
then this is the best thing on earth

1730
01:55:08,130 --> 01:55:11,250
and what i'm working on is trying to make this

1731
01:55:11,280 --> 01:55:14,230
converge faster

1732
01:55:14,230 --> 01:55:16,880
so one key problem that you have

1733
01:55:16,900 --> 01:55:18,500
with first order

1734
01:55:19,540 --> 01:55:21,110
gradient descent

1735
01:55:21,130 --> 01:55:23,300
is that it can be very very slow

1736
01:55:23,300 --> 01:55:26,840
it can take many iterations to converge

1737
01:55:28,840 --> 01:55:33,050
actually i think i have that picture later so

1738
01:55:33,360 --> 01:55:38,380
i'll show you later why exactly so what i'm working on is is methods to

1739
01:55:38,380 --> 01:55:41,670
to speed that up

1740
01:55:41,750 --> 01:55:46,280
OK here this is actually the same thing in words

1741
01:55:47,670 --> 01:55:52,630
particular conjugate directions break down so this is the reason there's no technical reason why

1742
01:55:52,630 --> 01:55:55,130
conjugate gradient methods don't work

1743
01:55:55,300 --> 01:55:57,670
with stochastic approximation

1744
01:55:57,690 --> 01:56:00,210
the other ones are just simply too expensive

1745
01:56:02,780 --> 01:56:08,960
this leaves evolutionary algorithm is very inefficient and simple gradient descent slightly less inefficient

1746
01:56:09,000 --> 01:56:11,270
i would say

1747
01:56:11,300 --> 01:56:13,480
OK now let's go into

1748
01:56:13,500 --> 01:56:15,880
techniques for speeding up

1749
01:56:15,920 --> 01:56:18,500
gradient descent

1750
01:56:18,520 --> 01:56:20,360
all rights on this one

1751
01:56:21,730 --> 01:56:23,670
this this you can copy already

1752
01:56:28,750 --> 01:56:32,400
so here's a just set up the notation out of

1753
01:56:32,420 --> 01:56:34,880
o called the gradient at time t

1754
01:56:36,440 --> 01:56:38,380
and what i mean by that is

1755
01:56:38,380 --> 01:56:42,110
it's the gradient of the loss

1756
01:56:42,150 --> 01:56:46,040
on the current parameter values and the current data

1757
01:56:46,050 --> 01:56:50,980
so this is a stochastic quantity even at the same point in parameter space if

1758
01:56:50,980 --> 01:56:55,040
i pick some fresh data i would get a different answer came

1759
01:56:55,130 --> 01:56:57,920
think of it as a stochastic function

1760
01:56:58,020 --> 01:57:02,230
nondeterministic functions it gives me a different answer every time

1761
01:57:02,230 --> 01:57:08,880
but somehow over time these answers all average out because if you average all these

1762
01:57:09,900 --> 01:57:11,980
and you keep the parameters fixed

1763
01:57:12,800 --> 01:57:14,420
in the limit

1764
01:57:14,420 --> 01:57:16,510
so when a is a subset of b

1765
01:57:18,200 --> 01:57:20,930
can be decomposed as a plus

1766
01:57:21,000 --> 01:57:24,460
the complement of a in b

1767
01:57:24,520 --> 01:57:28,780
so you can write appeal be as p of a plus b of

1768
01:57:28,800 --> 01:57:32,800
the b-minus in the set notation

1769
01:57:32,810 --> 01:57:36,790
and because of the nonnegativity again you get this one

1770
01:57:37,970 --> 01:57:42,340
well this is just a matter of rewriting things so usually it's convenient

1771
01:57:43,320 --> 01:57:46,200
when you have a deviation inequality

1772
01:57:46,210 --> 01:57:47,780
well know that

1773
01:57:47,790 --> 01:57:51,240
the probability that x is larger than some quantity is less than some function of

1774
01:57:51,240 --> 01:57:52,360
this quantity

1775
01:57:52,370 --> 01:57:55,030
it's convenient to see

1776
01:57:55,930 --> 01:57:57,680
the confidence value

1777
01:57:57,690 --> 01:58:01,180
so given us this treshold that town

1778
01:58:01,230 --> 01:58:04,390
how how large can be

1779
01:58:04,390 --> 01:58:06,160
this one this from the bible

1780
01:58:08,250 --> 01:58:09,380
i could

1781
01:58:09,380 --> 01:58:13,870
OK so you want to guarantee that there is a large probability

1782
01:58:14,920 --> 01:58:20,290
x is less than some quantity and to obtain this you just inverts this function

1783
01:58:20,320 --> 01:58:25,730
yes yes yes

1784
01:58:25,740 --> 01:58:26,720
yes sorry

1785
01:58:26,740 --> 01:58:33,950
well this of course is one of

1786
01:58:35,030 --> 01:58:37,440
the problem may not be

1787
01:58:39,780 --> 01:58:40,970
OK this one

1788
01:58:42,770 --> 01:58:47,380
the trick is to use integration by parts to write what the expectation is expectation

1789
01:58:47,380 --> 01:58:48,900
is the integral

1790
01:58:51,130 --> 01:58:53,450
the value thank the probability

1791
01:58:55,530 --> 01:58:58,270
p of x

1792
01:58:58,310 --> 01:59:01,460
and then you integration by parts

1793
01:59:01,470 --> 01:59:05,910
so this is OK you assume that x is larger than zero

1794
01:59:05,920 --> 01:59:11,240
so this is sufficient from zero to infinity of x of XTX

1795
01:59:13,200 --> 01:59:14,070
so you

1796
01:59:14,100 --> 01:59:16,600
differentiate these integrate that

1797
01:59:16,650 --> 01:59:20,820
integration of p of x gives you

1798
01:59:22,480 --> 01:59:24,140
distribution function

1799
01:59:24,150 --> 01:59:25,850
and when you differentiate x

1800
01:59:25,860 --> 01:59:27,230
gives you one

1801
01:59:27,310 --> 01:59:29,260
gives you this country

1802
01:59:33,350 --> 01:59:35,710
another set of

1803
01:59:35,720 --> 01:59:37,350
interesting results

1804
01:59:37,350 --> 01:59:55,670
again i choose five seconds at five minutes to think about it

1805
01:59:55,840 --> 01:59:58,710
the first one is more or less the definition

1806
01:59:58,720 --> 02:00:18,810
there is some sort of keywords

1807
02:00:18,890 --> 02:00:31,710
for the second one i can give you

1808
02:00:35,140 --> 02:00:37,170
you have to use

1809
02:00:37,430 --> 02:00:42,180
the simple fact that expect the story

1810
02:00:44,800 --> 02:00:45,960
of an event

1811
02:00:45,970 --> 02:00:49,260
is equal to the expected value

1812
02:00:49,270 --> 02:00:53,450
the indicator function of that event

1813
02:00:53,710 --> 02:01:19,560
that's full markov seen equality

1814
02:01:29,190 --> 02:01:35,280
convexity anyone

1815
02:01:35,340 --> 02:01:36,710
OK so

1816
02:01:36,730 --> 02:01:39,250
actually it's it's

1817
02:01:39,260 --> 02:01:40,840
it's a bit tricky too

1818
02:01:40,840 --> 02:01:45,420
actually prove this statement because it requires some additional assumption that they not

1819
02:01:45,440 --> 02:01:46,380
but here

1820
02:01:46,400 --> 02:01:49,890
it's this statement would be true

1821
02:01:51,400 --> 02:01:53,340
for finite spaces

1822
02:01:54,360 --> 02:02:00,220
remember the the convexity of a function means that the function is always smaller

1823
02:02:02,090 --> 02:02:05,240
OK so you have it means that the function looks like this essentially and if

1824
02:02:05,240 --> 02:02:06,930
you take two points on

1825
02:02:06,980 --> 02:02:09,670
the graph of the function

1826
02:02:09,810 --> 02:02:12,400
draw the line between those two points

1827
02:02:13,660 --> 02:02:16,750
the function being convex means that

1828
02:02:16,800 --> 02:02:19,590
the function is always smaller than this one

1829
02:02:19,590 --> 02:02:22,010
you can write it as

1830
02:02:22,300 --> 02:02:24,650
and that's the definition of convex functions

1831
02:02:24,670 --> 02:02:26,280
f of

1832
02:02:27,300 --> 02:02:29,800
x plus one minus five

1833
02:02:31,300 --> 02:02:33,160
is less than alpha

1834
02:02:33,160 --> 02:02:34,650
f of x

1835
02:02:34,700 --> 02:02:38,020
this one minus alpha f of y

1836
02:02:38,650 --> 02:02:40,340
and this for any alpha

1837
02:02:40,420 --> 02:02:41,770
between zero and one

1838
02:02:45,470 --> 02:02:50,790
actually when you see that you notice that this is already an expectation

1839
02:02:50,800 --> 02:02:53,110
this is the expectation

1840
02:02:53,120 --> 02:02:58,220
of a random variable with that would take value x with probability alpha and value

1841
02:02:58,220 --> 02:03:00,930
y with probability one minus alpha

1842
02:03:01,290 --> 02:03:03,050
and by

1843
02:03:03,070 --> 02:03:06,700
repeating this argument you can show that

1844
02:03:06,700 --> 02:03:08,550
the same is true for any

1845
02:03:08,610 --> 02:03:12,910
a number of possible values so if you have f of some

1846
02:03:12,960 --> 02:03:14,920
of p i x i

1847
02:03:14,920 --> 02:03:19,390
which would be the expected value of the function of a random variable that takes

1848
02:03:19,390 --> 02:03:23,760
the value x i with probability p i whether by sum to one

1849
02:03:25,270 --> 02:03:26,980
by repeating this inequality

1850
02:03:27,090 --> 02:03:29,180
you get that this is less

1851
02:03:29,350 --> 02:03:30,730
the summer

1852
02:03:30,760 --> 02:03:33,550
of the i f of x i

1853
02:03:33,560 --> 02:03:35,590
which is exactly the same as saying

1854
02:03:35,630 --> 02:03:43,090
function applied to the expectation is less than the expectation of the function

1855
02:03:43,110 --> 02:03:43,880
now the

1856
02:03:43,920 --> 02:03:45,590
the trick is that

1857
02:03:45,610 --> 02:03:49,220
for this to be true for arbitrary continuous spaces

1858
02:03:49,280 --> 02:03:50,790
you need

1859
02:03:50,810 --> 02:03:53,340
some notion of continuity of this function

1860
02:03:53,340 --> 02:04:00,170
actually it's called lower semicontinuous so the function has to be such that that's to

1861
02:04:00,170 --> 02:04:02,290
be equal to the maximum

1862
02:04:02,360 --> 02:04:07,350
of all the functions that are linear and below this function so if you draw

1863
02:04:07,360 --> 02:04:09,820
all the lines

1864
02:04:09,840 --> 02:04:14,260
that are below the function

1865
02:04:14,280 --> 02:04:16,460
and at each point sorry

1866
02:04:16,470 --> 02:04:18,460
this should not cross

1867
02:04:18,470 --> 02:04:23,740
and at each point you take the maximum value obtained by any such line then

1868
02:04:23,740 --> 02:04:26,230
it has to be equal to the value of the function


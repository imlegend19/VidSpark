1
00:00:00,000 --> 00:00:04,710
then the people who take the celebrant right another way of saying it is there

2
00:00:04,710 --> 00:00:07,170
isn't random assignment

3
00:00:07,190 --> 00:00:10,670
of the subjects to the two conditions in the in the study

4
00:00:10,670 --> 00:00:14,540
that's no random assignment experiment

5
00:00:14,540 --> 00:00:20,230
you by not randomly assign people to these two conditions you may be capturing just

6
00:00:20,230 --> 00:00:23,040
individual differences in the kind of person

7
00:00:23,060 --> 00:00:25,730
who when there's a perfectly stable

8
00:00:25,750 --> 00:00:30,270
save low bridge says one that bridge

9
00:00:30,400 --> 00:00:33,190
you want to go the bridge rather with my life

10
00:00:33,210 --> 00:00:35,830
to get the class

11
00:00:35,850 --> 00:00:39,630
and then surprises that that's the kind of person who would

12
00:00:39,650 --> 00:00:44,170
call perfect stranger on the telephone and writer sexy story give to

13
00:00:44,310 --> 00:00:48,130
we're not so surprising so what we have to do of course is taken into

14
00:00:48,130 --> 00:00:49,190
the lab

15
00:00:50,940 --> 00:00:53,170
do this in a more systematic way

16
00:00:53,170 --> 00:00:55,460
with random assignment this is how

17
00:00:55,480 --> 00:00:57,060
i want to finish up

18
00:00:57,060 --> 00:01:01,000
today we have to to until two forty five three forty five

19
00:01:01,710 --> 00:01:03,710
three of take about

20
00:01:03,730 --> 00:01:06,210
five or better to finish up now give us some time for

21
00:01:07,540 --> 00:01:09,500
so how do you do this

22
00:01:09,500 --> 00:01:11,380
in the lab

23
00:01:12,960 --> 00:01:13,980
you can

24
00:01:14,000 --> 00:01:16,480
bring people into the lab

25
00:01:16,520 --> 00:01:20,650
and i can present you with a confederate

26
00:01:20,670 --> 00:01:24,830
who said let's say you are all in condition one everybody on this side of

27
00:01:24,830 --> 00:01:25,650
the room

28
00:01:25,670 --> 00:01:27,670
and i can say to all of you

29
00:01:27,710 --> 00:01:29,790
please weight here

30
00:01:29,810 --> 00:01:32,130
will begin experiment

31
00:01:32,170 --> 00:01:33,750
in a moment

32
00:01:33,810 --> 00:01:36,670
while waiting please fill out this form

33
00:01:36,670 --> 00:01:41,060
and the form includes how attractive how attractive you are

34
00:01:41,080 --> 00:01:42,560
so the experiment

35
00:01:42,580 --> 00:01:44,400
to me

36
00:01:44,420 --> 00:01:46,670
i can do the same thing over here

37
00:01:46,670 --> 00:01:50,330
i can so i can give you the form that's due to rate how attractive

38
00:01:50,330 --> 00:01:51,500
you think i am

39
00:01:51,520 --> 00:01:55,120
and i can give you the same instruction with the crucial

40
00:01:56,420 --> 00:01:59,190
please wait here

41
00:01:59,250 --> 00:02:03,120
we will begin the painful shock experiment

42
00:02:03,130 --> 00:02:05,480
in one

43
00:02:05,500 --> 00:02:07,770
please fill out this form is widely

44
00:02:07,830 --> 00:02:09,250
what happens

45
00:02:09,270 --> 00:02:12,000
the people who got a painful shock

46
00:02:13,350 --> 00:02:16,250
or more likely to find the confederate

47
00:02:16,310 --> 00:02:17,880
the trial

48
00:02:19,040 --> 00:02:20,380
well there sitting there

49
00:02:20,400 --> 00:02:24,420
thinking about painful shock it's making the heart beat faster

50
00:02:24,440 --> 00:02:26,580
it's making their homes well

51
00:02:26,600 --> 00:02:28,980
make you breathe harder maybe

52
00:02:28,980 --> 00:02:33,060
and even though it's fairly obvious what's doing that there is no

53
00:02:33,080 --> 00:02:35,580
this attribute that arousal two

54
00:02:35,630 --> 00:02:37,900
i must be falling in love

55
00:02:37,900 --> 00:02:39,540
even with that obvious

56
00:02:39,560 --> 00:02:44,080
a even with that obvious instruction

57
00:02:44,150 --> 00:02:46,500
you can do this in other ways you can bring

58
00:02:46,520 --> 00:02:49,060
here here here is one of my favorite ones

59
00:02:49,080 --> 00:02:53,420
you bring people in the lab lets will will make the control group this time

60
00:02:53,500 --> 00:02:56,830
we bring you were not web we say this group of people

61
00:02:56,850 --> 00:02:58,230
please weight here

62
00:02:58,250 --> 00:03:00,380
i will begin experiment in a moment

63
00:03:00,420 --> 00:03:04,600
you can follow these forms in the meantime the forms ask how attracted you are

64
00:03:04,620 --> 00:03:06,710
to the experimenter

65
00:03:06,960 --> 00:03:09,520
now the experimental group and i say

66
00:03:10,810 --> 00:03:12,460
weight here

67
00:03:12,480 --> 00:03:17,020
it will begin experiment moment are going to ask you for lots some farms but

68
00:03:17,020 --> 00:03:21,310
first to get ready for this experiment likely to get on the treadmill

69
00:03:21,330 --> 00:03:23,770
and run for ten minutes

70
00:03:23,830 --> 00:03:25,580
so you run on the treadmill

71
00:03:25,600 --> 00:03:30,150
you've just sat around the people run on the treadmill even when that that arousal

72
00:03:30,170 --> 00:03:34,330
is fairly obvious you've got you do a little bit of aerobic exercise

73
00:03:34,350 --> 00:03:36,310
you still find

74
00:03:36,350 --> 00:03:38,020
the experimenter

75
00:03:38,020 --> 00:03:39,670
more attractive

76
00:03:39,690 --> 00:03:48,250
this is why the fourth floor of payne whitney gym is such a dangerous place

77
00:03:48,270 --> 00:03:50,480
and i urge you as your dean

78
00:03:50,540 --> 00:03:53,250
to be very careful

79
00:03:54,380 --> 00:03:58,480
it's the combination of robotic exercise in spandex

80
00:03:59,650 --> 00:04:00,880
leads to trouble

81
00:04:00,900 --> 00:04:06,960
now here's the final experiment i apologize for this it is a bit sexist in

82
00:04:06,980 --> 00:04:09,400
two thousand and seven

83
00:04:10,810 --> 00:04:14,440
let me explain and we could never do this one could never do this experiment

84
00:04:14,520 --> 00:04:15,710
that let me

85
00:04:15,710 --> 00:04:20,130
let me let me go through with you and you apologize for its

86
00:04:20,130 --> 00:04:22,630
some of its qualities

87
00:04:22,650 --> 00:04:26,580
in this experiment male subjects were brought

88
00:04:26,600 --> 00:04:28,080
into the lab

89
00:04:28,130 --> 00:04:32,060
and they were asked to look at falls from playboy magazine

90
00:04:32,060 --> 00:04:36,500
so these are essentially photographs of naked women

91
00:04:36,500 --> 00:04:40,420
and they are wearing headphones

92
00:04:40,420 --> 00:04:43,440
that amplify their heart

93
00:04:43,540 --> 00:04:46,210
and they are asked among other things

94
00:04:46,210 --> 00:04:49,270
how attracted or

95
00:04:49,270 --> 00:04:51,310
to the centerfold

96
00:04:51,310 --> 00:04:53,190
photograph that they're looking

97
00:04:53,210 --> 00:04:56,850
maybe i don't remember how many they look at maybe it's about

98
00:04:56,860 --> 00:04:59,290
so these slides are coming out

99
00:04:59,330 --> 00:05:01,270
got the headphones on

100
00:05:01,330 --> 00:05:04,880
the headphones amplifying their heart heartbeat

101
00:05:04,880 --> 00:05:09,020
and the slides are moving one after another from

102
00:05:09,020 --> 00:05:11,630
a few seconds each slot

103
00:05:11,710 --> 00:05:12,830
and that was it

104
00:05:12,850 --> 00:05:16,130
to their heart

105
00:05:16,150 --> 00:05:19,900
slide one

106
00:05:19,980 --> 00:05:21,060
slide two

107
00:05:21,100 --> 00:05:25,920
slide three

108
00:05:25,940 --> 00:05:28,440
slide four

109
00:05:28,480 --> 00:05:30,580
slide five

110
00:05:30,600 --> 00:05:37,000
slide six

111
00:05:37,000 --> 00:05:40,440
and then there which one did you find most attractive

112
00:05:40,460 --> 00:05:42,830
with what you most attractive

113
00:05:42,850 --> 00:05:45,540
slide five absolutely

114
00:05:45,560 --> 00:05:48,400
she's she's the woman i want to marry

115
00:05:49,380 --> 00:05:51,100
what's happened is

116
00:05:51,120 --> 00:05:52,440
they're using this

117
00:05:52,460 --> 00:05:56,040
bodily q of their heart beating

118
00:05:56,080 --> 00:05:58,900
to infer that that's what they find

119
00:05:58,940 --> 00:06:00,400
more attractive

120
00:06:00,420 --> 00:06:02,750
now here's the twist

121
00:06:02,770 --> 00:06:04,790
they not actually listening

122
00:06:04,850 --> 00:06:07,170
so there are

123
00:06:07,210 --> 00:06:09,580
they're listening to a tape recording

124
00:06:09,600 --> 00:06:11,230
of the heart beat

125
00:06:11,290 --> 00:06:15,810
and the experimenters back there with the speed and are

126
00:06:15,850 --> 00:06:22,330
at random intervals just speeds up take their hard

127
00:06:22,380 --> 00:06:24,330
and then slows it down

128
00:06:24,350 --> 00:06:27,080
and it doesn't matter which lie

129
00:06:28,170 --> 00:06:29,730
speeds up the

130
00:06:29,920 --> 00:06:32,880
tape of the heartbeat on that's the one

131
00:06:32,900 --> 00:06:35,360
the subject is more likely to think

132
00:06:36,710 --> 00:06:40,670
the person of the person attractor

133
00:06:40,730 --> 00:06:47,120
so here you can this attribute real arousal you can even this attribute

134
00:06:47,130 --> 00:06:48,500
forty around

135
00:06:48,580 --> 00:06:53,270
arousal that isn't even coming from your body just coming that's just

136
00:06:53,440 --> 00:06:55,350
it's just a place to you

137
00:06:55,360 --> 00:06:57,350
random you can even

138
00:06:57,360 --> 00:07:02,560
this attribute OK i these experiments are pure

139
00:07:02,560 --> 00:07:07,820
which is a provides a humane way of looking at the antibodies in the bad

140
00:07:07,820 --> 00:07:10,780
we don't have to believe the babies we just

141
00:07:10,830 --> 00:07:13,140
after collect blood from

142
00:07:13,160 --> 00:07:17,410
the sentences that appear after the baby is born

143
00:07:17,420 --> 00:07:23,640
and the class of antibody that goes from the mother to the baby we can

144
00:07:23,640 --> 00:07:24,540
look at

145
00:07:25,030 --> 00:07:27,710
OK a kind of three-dimensional

146
00:07:27,740 --> 00:07:31,710
principal component analysis and see that each baby

147
00:07:31,730 --> 00:07:33,760
has more or less

148
00:07:33,760 --> 00:07:34,710
the same

149
00:07:36,920 --> 00:07:41,780
antibodies in this IDG classes the mother that's not surprising

150
00:07:41,780 --> 00:07:44,910
because the mother is transporting to the baby

151
00:07:44,970 --> 00:07:46,680
her experience

152
00:07:46,730 --> 00:07:49,260
but if we look at another set

153
00:07:49,270 --> 00:07:55,930
of antibody molecules such that is not transported from mother to baby we see a

154
00:07:55,930 --> 00:07:58,020
totally different picture

155
00:07:58,040 --> 00:08:03,110
instead of each mother and baby being a correlated per what we see here in

156
00:08:03,110 --> 00:08:08,800
this IGN is that all babies are correlated it's human beings

157
00:08:08,820 --> 00:08:10,090
are born

158
00:08:10,110 --> 00:08:13,150
with a similar training sort

159
00:08:13,180 --> 00:08:14,960
every activities

160
00:08:14,980 --> 00:08:23,160
and the mothers then have different factors of development over there healthy experience

161
00:08:24,120 --> 00:08:27,540
so let's of antibodies

162
00:08:27,560 --> 00:08:29,800
that we begin life with

163
00:08:29,810 --> 00:08:34,580
in which we take of our mothers immune experience

164
00:08:34,600 --> 00:08:39,820
other sensory activities we begin life with in common

165
00:08:40,030 --> 00:08:45,700
we do not partake of mothers experience but we have the basis for developing their

166
00:08:45,710 --> 00:08:48,610
own experience and then each of us

167
00:08:48,660 --> 00:08:53,240
as exemplified by the divergence of the model with this we can assume that the

168
00:08:54,430 --> 00:08:56,260
also began in this

169
00:08:57,970 --> 00:08:59,800
of repertoire

170
00:08:59,810 --> 00:09:04,270
the immune system and then each one in their own healthy weight

171
00:09:04,280 --> 00:09:05,860
goes off

172
00:09:05,870 --> 00:09:10,530
in an individual kind of the development so we see

173
00:09:10,660 --> 00:09:15,100
patterns of development associated with her

174
00:09:15,120 --> 00:09:20,060
but using the same kind of technology we can see patterns in diseases such as

175
00:09:20,060 --> 00:09:22,900
multiple sclerosis and here we're looking up

176
00:09:22,930 --> 00:09:28,880
instead of principal component analysis for here kind of about

177
00:09:28,960 --> 00:09:30,720
every activities

178
00:09:30,780 --> 00:09:38,850
a thousand different activities and we can see that the colour-coded according to their intensity

179
00:09:38,860 --> 00:09:41,100
we can see those are called

180
00:09:41,190 --> 00:09:44,590
shared by all the healthy individuals

181
00:09:44,610 --> 00:09:49,620
but if the groups of individual come down with different types

182
00:09:49,640 --> 00:09:51,470
of multiple sclerosis

183
00:09:51,510 --> 00:09:59,380
have different barcodes different patterns of reactivity that are shared by these individuals alike

184
00:09:59,380 --> 00:10:00,840
with their

185
00:10:01,700 --> 00:10:05,110
real activities that are individualized

186
00:10:05,860 --> 00:10:08,380
the immune system begins

187
00:10:08,720 --> 00:10:13,890
it begins life with individual patterns back from the mother

188
00:10:13,910 --> 00:10:20,060
with species are so human patterns

189
00:10:20,070 --> 00:10:22,800
develop in utero

190
00:10:22,810 --> 00:10:28,190
by the way the system is looking at itself and we can

191
00:10:28,600 --> 00:10:34,180
using this kind of a pathogen microarray approach

192
00:10:34,190 --> 00:10:36,780
we can see that the immune system

193
00:10:36,780 --> 00:10:40,990
adjusts within this city of individual

194
00:10:41,010 --> 00:10:44,350
information and just

195
00:10:44,360 --> 00:10:46,800
patterns that are indicative

196
00:10:48,470 --> 00:10:54,230
a disease and its subdivisions but also patterns that will help us predict the response

197
00:10:54,230 --> 00:10:55,900
to treatment

198
00:10:55,930 --> 00:10:58,880
so here we get we go back to the

199
00:10:59,700 --> 00:11:03,050
the utilitarian

200
00:11:03,060 --> 00:11:07,330
aspects of looking at how the immune system deals with

201
00:11:07,350 --> 00:11:09,350
the complexity of the body

202
00:11:09,370 --> 00:11:10,830
when we look at the

203
00:11:10,850 --> 00:11:15,720
complexity the immune system in response to what's going on in the body

204
00:11:15,740 --> 00:11:20,040
we can use the immune system has a slow growth

205
00:11:22,280 --> 00:11:23,660
for predicting

206
00:11:23,690 --> 00:11:27,090
say the response to treatment in multiple sclerosis

207
00:11:27,090 --> 00:11:31,000
which actually does have quite a lot of the structure in the data and it is even got

208
00:11:31,640 --> 00:11:33,810
those little ninety degrees things which we can see

209
00:11:35,050 --> 00:11:39,670
the extra noise ninety degrees it even got those features it we just two features

210
00:11:40,420 --> 00:11:43,480
it said how many that take before thousand features

211
00:11:44,290 --> 00:11:49,500
because the basis so high-dimensional all not so fantastic rotations you can upon finding this

212
00:11:49,500 --> 00:11:54,590
rotation is just summing up all right pixels give you interesting structure in the data

213
00:11:55,740 --> 00:11:56,860
you perform much better

214
00:11:57,560 --> 00:11:59,880
i mean absolute error is rule really really small

215
00:12:00,340 --> 00:12:00,810
and then

216
00:12:01,260 --> 00:12:02,980
as you increase the number dimensions

217
00:12:04,460 --> 00:12:09,400
it just goes to zero again zero three sixty one is a to zero three sixty anyone

218
00:12:15,290 --> 00:12:18,730
three six-degrees-of-freedom yet again well i put it in the way i would put it is

219
00:12:19,390 --> 00:12:20,460
because the data set

220
00:12:21,570 --> 00:12:24,490
only has three hundred sixty data points the covariance

221
00:12:25,610 --> 00:12:27,070
will be rank three sixty

222
00:12:27,510 --> 00:12:31,210
so you discarding all the igon values there are actually another arm

223
00:12:32,340 --> 00:12:36,190
three six four minus three sixty igon values if you think about the covariance matrix

224
00:12:36,190 --> 00:12:38,350
here it's three six four eight by three six four

225
00:12:39,040 --> 00:12:40,260
but it's made up

226
00:12:42,490 --> 00:12:44,090
in a proactive uh

227
00:12:44,090 --> 00:12:46,970
o operator go a long way back to find the creation again when i

228
00:12:47,690 --> 00:12:48,620
is made up all

229
00:12:49,860 --> 00:12:53,120
or home

230
00:12:54,610 --> 00:12:55,810
naive and that's made up over

231
00:13:01,220 --> 00:13:03,070
in my notation is this you

232
00:13:03,780 --> 00:13:04,710
and in this case

233
00:13:07,490 --> 00:13:08,140
this is the

234
00:13:12,400 --> 00:13:14,890
three six four eight why is that why have

235
00:13:15,710 --> 00:13:16,810
so this guy here

236
00:13:17,160 --> 00:13:18,840
it is and this is like three sixty

237
00:13:19,510 --> 00:13:21,730
so this guy he is a three sixty three

238
00:13:22,210 --> 00:13:22,960
six four right

239
00:13:23,880 --> 00:13:25,030
by three six four eight

240
00:13:25,970 --> 00:13:28,400
matrix but his rank is only three hundred sixty

241
00:13:29,820 --> 00:13:33,710
once you've got three hundred sixty dimensions that's all information the reason the data

242
00:13:37,650 --> 00:13:38,570
that's a little bit old

243
00:13:43,200 --> 00:13:44,040
there's a problem here

244
00:13:46,350 --> 00:13:50,740
i just use the sample covariance matrix to solve the problem

245
00:13:52,250 --> 00:13:55,840
by the data being presented in terms of distance interpoint distance

246
00:13:56,710 --> 00:13:59,450
so what happened you can't necessarily

247
00:13:59,990 --> 00:14:03,480
computer science like ubuntu interpoint distances how do you know what the sample

248
00:14:06,530 --> 00:14:10,250
well that's another nice trick which has been known for a long time in statistics

249
00:14:10,490 --> 00:14:15,400
and underpins some material from tomorrow so i wanna show you exact in some detail

250
00:14:15,560 --> 00:14:19,640
so i understand the problem and i said with these methods is class methods on

251
00:14:19,650 --> 00:14:22,210
being given the squared distance matrix for the data

252
00:14:22,720 --> 00:14:26,530
but the digits i can compute because i had the original data but imagine someone

253
00:14:26,530 --> 00:14:27,840
just gives me the squared distance

254
00:14:28,710 --> 00:14:30,360
and they don't tell me the original data

255
00:14:31,510 --> 00:14:36,420
when i went define the direction of maximum variance how did i find at given

256
00:14:36,430 --> 00:14:40,100
i don't have the covariance which piece yeah relies on you

257
00:14:41,040 --> 00:14:46,980
well this is the final bit principal coordinate analysis which you don't actually need the covariance you can deal with

258
00:14:48,030 --> 00:14:50,050
the interpoint distance matrix directly

259
00:14:50,780 --> 00:14:54,260
in order to solve these problems a squared distance matrix which i'm going right

260
00:14:54,960 --> 00:14:58,140
baldi i can't write told of try to like that

261
00:14:59,330 --> 00:15:01,490
i write these things as

262
00:15:02,110 --> 00:15:02,870
in this form

263
00:15:06,450 --> 00:15:08,750
so this is i'm assuming alliance entered here

264
00:15:13,440 --> 00:15:15,110
i'll explain what i'm trying to do here

265
00:15:17,120 --> 00:15:17,610
the moment

266
00:15:20,670 --> 00:15:23,350
so in my other notation in the slide there's got hats on

267
00:15:24,170 --> 00:15:24,640
that's all

268
00:15:32,110 --> 00:15:32,880
okay so this

269
00:15:33,570 --> 00:15:38,760
notation hear is in the matrix when expressing squared distances so in the normal way

270
00:15:38,760 --> 00:15:41,320
of expressing square distances would say um

271
00:15:41,930 --> 00:15:43,390
between why and why jay

272
00:15:44,040 --> 00:15:45,980
it's de-iced data point why

273
00:15:46,570 --> 00:15:49,390
minus two times while i transpose why jay

274
00:15:52,380 --> 00:15:53,700
why jay transpose

275
00:15:54,330 --> 00:15:54,790
why jay

276
00:15:55,330 --> 00:15:57,800
which is simply the multiplying out the original

277
00:15:58,200 --> 00:15:59,910
euclidean squared distance formula

278
00:16:03,080 --> 00:16:07,420
that's one way of writing it this the squared l two norm or whatever so it's that's

279
00:16:07,900 --> 00:16:11,220
now right in matrix form i need to take the diagonal

280
00:16:11,720 --> 00:16:14,760
of this thing along the diagonals all those elements hear

281
00:16:15,820 --> 00:16:20,000
and then i multiply him by ones on the outside to do the same for

282
00:16:20,000 --> 00:16:23,680
the why jay-z i have to do the same thing transposed so that's just a

283
00:16:24,530 --> 00:16:27,800
i'm using metric because it leads to a nice little proof

284
00:16:28,300 --> 00:16:29,720
but how you can compute

285
00:16:30,390 --> 00:16:31,710
thing you want so here

286
00:16:32,450 --> 00:16:36,360
this is the inner product matrix of centred inner product matrix i talked about before

287
00:16:36,360 --> 00:16:38,740
so we've been using why transpose why

288
00:16:39,220 --> 00:16:42,690
and we don't have access to it so the first stage which is the bit

289
00:16:42,820 --> 00:16:47,140
somehow has disappeared from my slides in the proof is to show you that you

290
00:16:47,140 --> 00:16:47,760
can get

291
00:16:48,290 --> 00:16:51,480
this why why transpose from this distance matrix

292
00:16:52,900 --> 00:16:56,870
so i said i'm using sensors why in fact it doesn't matter because these are

293
00:16:57,150 --> 00:16:59,160
distances so the centring doesn't matter

294
00:17:00,500 --> 00:17:02,210
have you guys heard centring matrices

295
00:17:03,380 --> 00:17:04,630
he's a magical devices

296
00:17:07,300 --> 00:17:12,000
so this is vectors ones is my notation for vector of ones and this is a centering matrix

297
00:17:12,730 --> 00:17:13,910
what is the centering matrix

298
00:17:15,110 --> 00:17:18,370
centering matrix if i multiply why by age

299
00:17:18,870 --> 00:17:19,820
it gives me why

300
00:17:21,350 --> 00:17:22,870
so it's minus plus

301
00:17:25,070 --> 00:17:26,920
why times the vector ones

302
00:17:28,310 --> 00:17:28,850
over and

303
00:17:29,800 --> 00:17:30,710
one transpose

304
00:17:31,250 --> 00:17:34,950
so what's on the vector ones is just the sum of all the reason why

305
00:17:35,480 --> 00:17:35,950
divided by

306
00:17:36,690 --> 00:17:37,920
so that's the matrix m u

307
00:17:38,690 --> 00:17:42,120
and then multiply by this one transpose just give me why

308
00:17:43,550 --> 00:17:46,060
mu mu mu mu yeah

309
00:17:46,790 --> 00:17:52,880
so it senses my dataset it's a very nice useful matrix because it also has the property that if i

310
00:17:54,820 --> 00:17:56,690
multiply by any constant vector

311
00:17:57,630 --> 00:17:59,810
so let's multiplied by the vector of ones

312
00:18:00,530 --> 00:18:04,930
this is one minus one overran times one times one transpose what

313
00:18:05,360 --> 00:18:06,040
so that's

314
00:18:06,230 --> 00:18:09,610
ends up one transpose one and so the equals zero

315
00:18:10,250 --> 00:18:14,340
so it's gone now space the constant i can vector now that's important

316
00:18:18,240 --> 00:18:19,050
run out of space

317
00:18:20,460 --> 00:18:21,230
that's important

318
00:18:21,650 --> 00:18:23,010
going back to this equation hear

319
00:18:23,870 --> 00:18:28,400
so if i print postmultiply this equation by the centering matrix age

320
00:18:31,420 --> 00:18:32,330
what i get is

321
00:18:33,680 --> 00:18:36,360
times the deed center distance matrix age

322
00:18:36,900 --> 00:18:37,710
is equal to

323
00:18:38,690 --> 00:18:42,640
okay so the premultiply on this diet isn't gonna do anything

324
00:18:43,110 --> 00:18:44,210
but the postmultiply

325
00:18:44,620 --> 00:18:47,140
on the one transpose is gonna give me zero

326
00:18:47,140 --> 00:18:51,100
so is

327
00:18:53,220 --> 00:18:55,460
we had some technical problems

328
00:18:55,520 --> 00:18:57,610
which now so so

329
00:18:58,690 --> 00:19:00,500
the result of the

330
00:19:00,520 --> 00:19:01,070
introduction to

331
00:19:02,100 --> 00:19:05,120
this is

332
00:19:05,140 --> 00:19:07,870
is of the part

333
00:19:08,390 --> 00:19:10,300
a very young girl who

334
00:19:10,350 --> 00:19:11,870
is one

335
00:19:11,910 --> 00:19:14,300
forces in this field

336
00:19:15,660 --> 00:19:20,150
she was not see in normal

337
00:19:20,160 --> 00:19:23,300
two thousand should be could be

338
00:19:24,470 --> 00:19:26,330
group leader of opposition

339
00:19:26,340 --> 00:19:27,760
i grew in the and

340
00:19:27,770 --> 00:19:30,050
the most of the men

341
00:19:30,050 --> 00:19:31,370
but the problems

342
00:19:32,480 --> 00:19:33,580
so i don't think any more

343
00:19:33,590 --> 00:19:35,120
time from the truth

344
00:19:38,120 --> 00:19:39,400
thank you

345
00:19:39,440 --> 00:19:44,090
so it's a great pleasure for me to be here so i'm going to

346
00:19:44,120 --> 00:19:47,770
he knew four lectures on nuclear physics

347
00:19:47,800 --> 00:19:50,660
so just to start

348
00:19:50,670 --> 00:19:52,840
these are three

349
00:19:52,860 --> 00:19:54,870
questions that seems to be

350
00:19:54,890 --> 00:19:57,670
quite easy to and to answer

351
00:19:57,700 --> 00:20:00,020
that which are quite tricky

352
00:20:00,030 --> 00:20:03,890
so the you know what is the heaviest nucleus

353
00:20:04,220 --> 00:20:06,560
that do exist on earth

354
00:20:06,580 --> 00:20:09,450
you know how many nuclei do do exist

355
00:20:09,450 --> 00:20:12,220
and what about the shapes of the nuclei

356
00:20:12,220 --> 00:20:15,640
so it is something real meant that can help for

357
00:20:15,640 --> 00:20:20,720
interpreting the experiments or is it completely and that is from the fact that we

358
00:20:20,720 --> 00:20:22,360
are dealing with quantum

359
00:20:26,170 --> 00:20:30,580
just to give you a flavor of nuclear physics this is what we call the

360
00:20:30,580 --> 00:20:31,940
nuclear charts

361
00:20:32,780 --> 00:20:35,640
i will tell you in five minutes that the

362
00:20:35,670 --> 00:20:38,830
a nucleus is made of the proton and neutron

363
00:20:38,840 --> 00:20:40,080
and you you

364
00:20:40,090 --> 00:20:41,420
i have here

365
00:20:41,440 --> 00:20:43,140
in yellow

366
00:20:43,160 --> 00:20:48,030
two hundred ninety one stable nuclei that do exist on paris

367
00:20:48,050 --> 00:20:49,520
but then you see that

368
00:20:49,560 --> 00:20:50,920
two and

369
00:20:51,830 --> 00:20:56,480
artificial nuclei have have been synthesized in the laboratory

370
00:20:56,510 --> 00:21:02,050
and what about predictions so many prediction predicts that more than five thousand

371
00:21:02,230 --> 00:21:04,360
two seven thousand

372
00:21:04,400 --> 00:21:07,890
bound exotic nuclei could be discovered so

373
00:21:07,920 --> 00:21:12,950
at to what we call these three lines here this the limit of existence

374
00:21:13,110 --> 00:21:17,830
this is what we call that they could so a lot of nuclear i have

375
00:21:17,850 --> 00:21:21,300
to be discovered in the future

376
00:21:21,320 --> 00:21:25,890
concerning the shape only is the same just to have the flavor of what is

377
00:21:26,650 --> 00:21:31,450
this theoretical prediction from the ground state nuclear deformation

378
00:21:31,460 --> 00:21:36,270
so this is predicted by what we call the hartree fock bogoliubov method

379
00:21:36,320 --> 00:21:41,050
which is a mean field based approach i will explain that in the second course

380
00:21:41,070 --> 00:21:46,680
just to know it's what we call microscopic approach where the basic ingredients are the

381
00:21:46,680 --> 00:21:48,740
nucleons proton and neutron

382
00:21:48,760 --> 00:21:53,360
and the interaction so do not consider macroscopic through

383
00:21:53,400 --> 00:21:57,450
but really consider the nucleons as a basic ingredient

384
00:21:57,480 --> 00:21:59,380
and and these are the results

385
00:21:59,390 --> 00:22:03,020
and you have here is the number of protons here the number of neutrons and

386
00:22:03,040 --> 00:22:07,800
you have these mean deformation better here but i mean information

387
00:22:07,830 --> 00:22:12,480
and you see that for great color you have only a few nuclei

388
00:22:12,530 --> 00:22:17,020
that are predicted to be spherical so these are very cold

389
00:22:17,040 --> 00:22:18,670
this correspond to what

390
00:22:18,680 --> 00:22:20,080
you will learn

391
00:22:20,100 --> 00:22:22,890
there are magic numbers

392
00:22:22,900 --> 00:22:25,140
twenty twenty eight fifty

393
00:22:25,150 --> 00:22:28,020
eighty to one hundred twenty six

394
00:22:28,050 --> 00:22:30,140
make sure here you have

395
00:22:30,150 --> 00:22:32,860
they form prolates nuclei

396
00:22:32,880 --> 00:22:35,640
and on a few number of nuclei

397
00:22:35,640 --> 00:22:37,890
light and heavy one hour

398
00:22:38,180 --> 00:22:41,820
predicted to be oblate

399
00:22:41,830 --> 00:22:48,460
so now the idea of a few of my lectures so first we talk about

400
00:22:48,480 --> 00:22:53,580
some features about the nucleus discovery radius binding energy

401
00:22:53,580 --> 00:22:56,050
lifetime storage activity

402
00:22:56,080 --> 00:22:59,390
and applications of nuclear physics

403
00:22:59,420 --> 00:23:03,720
then second course will be devoted to the modeling of the nucleus

404
00:23:03,790 --> 00:23:07,900
i that what we call the liquid drop so benefit concert and the nucleus is

405
00:23:07,990 --> 00:23:10,080
equal chance liquid drop

406
00:23:10,100 --> 00:23:12,010
it's the macroscopic approach

407
00:23:12,020 --> 00:23:15,010
that gives the was feature of the nuclei

408
00:23:15,060 --> 00:23:17,180
two other approaches

409
00:23:17,200 --> 00:23:23,560
she more than i mean field which are because competing approaches

410
00:23:23,580 --> 00:23:27,890
then i will give you many examples of recent studies that have made all the

411
00:23:27,890 --> 00:23:29,900
were some adherents

412
00:23:29,930 --> 00:23:36,760
so concerning these exotic nuclei so all these new experiments or calculations concerning

413
00:23:36,760 --> 00:23:40,760
these new nuclear that are newly synthesized

414
00:23:40,780 --> 00:23:43,080
concerning isomer

415
00:23:43,090 --> 00:23:47,760
they are in the nuclei in many metastable states that do exist

416
00:23:47,820 --> 00:23:50,700
so they are very interesting to know about the

417
00:23:50,720 --> 00:23:52,790
the physics

418
00:23:52,820 --> 00:23:58,520
ship systems so there are some nuclei where different states are obtained

419
00:23:58,530 --> 00:24:02,680
and seems to correspond to different shape of the nuclei

420
00:24:02,750 --> 00:24:04,930
and concerning to

421
00:24:04,950 --> 00:24:07,220
and then the last

422
00:24:07,250 --> 00:24:10,680
course will be devoted to the description of the fission process

423
00:24:10,690 --> 00:24:15,930
because many progress has been made recently concerning this subject

424
00:24:16,740 --> 00:24:19,470
concerning some features including

425
00:24:19,490 --> 00:24:23,460
so you may know that the structure of the atom was first brought in the

426
00:24:23,460 --> 00:24:27,290
beginning of the twentieth century by russir fold

427
00:24:27,320 --> 00:24:31,220
so in this experiment you had this rule

428
00:24:31,280 --> 00:24:36,200
frightened of of alpha particles with radioactive decay of radium

429
00:24:36,280 --> 00:24:41,060
that was collimated and that was directed into a sheet of very thin

430
00:24:41,140 --> 00:24:42,880
gold five

431
00:24:42,910 --> 00:24:44,700
then after clustering

432
00:24:44,700 --> 00:24:48,270
these particles were detected here on the screen

433
00:24:48,280 --> 00:24:50,880
this is that some back here

434
00:24:50,890 --> 00:24:55,830
and i will show you that unexpected results demonstrated the existence of the atomic nuclei

435
00:24:58,200 --> 00:25:03,720
because before the this experiment people thought that all the alpha particles should be

436
00:25:03,760 --> 00:25:06,700
if elected only by if you read

437
00:25:06,720 --> 00:25:12,750
but the observed particles that were deflected back and was angles much larger than ninety

438
00:25:14,390 --> 00:25:18,150
so the rest of fraud after this experiment is interpreted that

439
00:25:18,160 --> 00:25:21,350
in the fact that an was almost empty

440
00:25:21,380 --> 00:25:24,530
except here of scattering center

441
00:25:24,540 --> 00:25:27,690
containing most of the part of the

442
00:25:27,720 --> 00:25:30,000
this is what we call the atomic nuclei

443
00:25:30,020 --> 00:25:35,130
nuclear physics dealing with the thing here

444
00:25:35,130 --> 00:25:36,830
is higher than a certain level

445
00:25:36,870 --> 00:25:38,070
the bones

446
00:25:38,160 --> 00:25:39,890
will break

447
00:25:40,960 --> 00:25:42,140
one animal

448
00:25:42,180 --> 00:25:46,350
not to break its bones when the math goes up by a certain factor is

449
00:25:46,350 --> 00:25:47,770
a factor of four

450
00:25:47,820 --> 00:25:49,860
in order for bowlers not to break

451
00:25:49,870 --> 00:25:54,100
the square was also go up by a factor of four that's the key argument

452
00:25:54,100 --> 00:25:57,920
in this case you really have to think that through careful

453
00:25:57,970 --> 00:25:59,350
therefore i would argue

454
00:25:59,520 --> 00:26:00,700
the mass

455
00:26:00,730 --> 00:26:02,410
must be proportional

456
00:26:02,560 --> 00:26:05,600
the square this is the breaking arg

457
00:26:05,610 --> 00:26:07,980
now compare these two

458
00:26:08,020 --> 00:26:10,720
the mass is proportional to the length of the femur

459
00:26:10,760 --> 00:26:12,250
the power three

460
00:26:12,300 --> 00:26:15,230
into the thickness of the femur to the power to

461
00:26:16,870 --> 00:26:20,640
the thickness of the people he worked to the power to must be proportional to

462
00:26:20,670 --> 00:26:21,900
the length l

463
00:26:22,010 --> 00:26:24,060
and therefore the thickness of the femur

464
00:26:24,070 --> 00:26:25,750
must be proportional

465
00:26:25,760 --> 00:26:28,490
the output power we

466
00:26:28,500 --> 00:26:30,600
very interesting

467
00:26:31,690 --> 00:26:33,340
what is this result

468
00:26:33,390 --> 00:26:34,570
telling you

469
00:26:34,610 --> 00:26:35,980
it tells you

470
00:26:36,020 --> 00:26:37,970
and if i have to animals

471
00:26:37,980 --> 00:26:41,050
and one is ten times larger than the other

472
00:26:41,170 --> 00:26:43,340
as is ten times larger

473
00:26:43,350 --> 00:26:44,600
the length of the

474
00:26:44,650 --> 00:26:46,660
leg ten times larger

475
00:26:47,530 --> 00:26:48,140
that this

476
00:26:48,150 --> 00:26:49,400
the thickness of

477
00:26:49,410 --> 00:26:50,510
the film more

478
00:26:50,660 --> 00:26:52,680
thirty five four

479
00:26:52,720 --> 00:26:57,290
because it is helpful to our half if i were to compare models was analysis

480
00:26:57,390 --> 00:27:00,760
elephant is about a hundred times larger in size

481
00:27:00,770 --> 00:27:04,390
for the length of the femur of the elephant behind hundred the times larger than

482
00:27:04,390 --> 00:27:08,750
that of models but the thickness of the more would have to be

483
00:27:09,980 --> 00:27:12,140
thousand times

484
00:27:13,560 --> 00:27:16,420
they have convinced galileo galilei

485
00:27:16,430 --> 00:27:18,420
that's the reason why

486
00:27:18,430 --> 00:27:19,400
the largest

487
00:27:19,410 --> 00:27:21,610
animals as large as the eye because

488
00:27:21,660 --> 00:27:23,960
clearly if you increase the mass

489
00:27:24,040 --> 00:27:25,410
now comes the time

490
00:27:25,470 --> 00:27:27,450
that the thickness of the bones

491
00:27:27,580 --> 00:27:29,530
the same as the length of the bones

492
00:27:29,580 --> 00:27:32,690
we all made of bone that is biologically

493
00:27:32,730 --> 00:27:35,490
not feasible soda is a limit somewhere

494
00:27:35,540 --> 00:27:36,920
set by this

495
00:27:36,970 --> 00:27:39,860
scaling law

496
00:27:40,820 --> 00:27:43,080
i really i want to bring this to test

497
00:27:43,180 --> 00:27:45,350
after all i broke my grandmother

498
00:27:45,360 --> 00:27:49,710
statement to test the why bringing galileo a statement with us

499
00:27:49,760 --> 00:27:50,700
and so

500
00:27:50,720 --> 00:27:52,480
i went to

501
00:27:53,440 --> 00:27:55,310
where they have a beautiful collection

502
00:27:55,320 --> 00:27:56,770
of famous

503
00:27:56,770 --> 00:27:59,150
and i

504
00:27:59,200 --> 00:28:03,070
ask them for the femur of a record and horse

505
00:28:03,210 --> 00:28:05,350
record is this big

506
00:28:06,780 --> 00:28:08,540
about four times bigger

507
00:28:09,320 --> 00:28:10,280
the length

508
00:28:10,320 --> 00:28:13,760
one of the few more of course must be about four times the length

509
00:28:13,800 --> 00:28:16,540
of the record

510
00:28:17,980 --> 00:28:20,460
i will not surprise

511
00:28:21,320 --> 00:28:23,320
i measured the thickness

512
00:28:23,390 --> 00:28:26,210
and i said to my

513
00:28:27,050 --> 00:28:29,310
the length is four times higher

514
00:28:29,330 --> 00:28:30,640
the thickness

515
00:28:30,670 --> 00:28:31,790
has to be

516
00:28:31,830 --> 00:28:34,170
eight times higher if this holds

517
00:28:34,310 --> 00:28:38,040
and what i'm going to court for you you will see that shortly

518
00:28:38,060 --> 00:28:40,320
is the divided by l

519
00:28:40,380 --> 00:28:41,550
missus out

520
00:28:41,550 --> 00:28:43,530
and that of course must be proportional

521
00:28:43,540 --> 00:28:46,950
alpha the problem i think one l year

522
00:28:47,600 --> 00:28:48,970
if i compare the horse

523
00:28:48,970 --> 00:28:50,750
and i compared the recall

524
00:28:50,760 --> 00:28:52,010
i would argue that

525
00:28:53,340 --> 00:28:55,160
divided by the length of the femur

526
00:28:55,180 --> 00:28:56,380
before the horse

527
00:28:56,390 --> 00:28:58,540
must be the square root of four

528
00:28:59,330 --> 00:29:02,300
as much as that of the recall

529
00:29:02,330 --> 00:29:05,230
so i was very anxious to that

530
00:29:05,230 --> 00:29:06,870
and i did that

531
00:29:06,930 --> 00:29:09,700
and i show you the results

532
00:29:10,470 --> 00:29:11,860
my first

533
00:29:16,660 --> 00:29:20,810
we see their d of l explain to you why i prefer that

534
00:29:20,910 --> 00:29:23,210
and you see the link

535
00:29:23,240 --> 00:29:24,650
you see here to recall

536
00:29:24,740 --> 00:29:25,890
you see the horse

537
00:29:25,950 --> 00:29:27,380
and if you look carefully

538
00:29:27,420 --> 00:29:31,240
then the deal fell for the horses only about one and half times larger than

539
00:29:31,240 --> 00:29:32,210
the raccoon

540
00:29:32,220 --> 00:29:34,870
well i wasn't too disappointed

541
00:29:34,890 --> 00:29:38,540
one and a half is not but is in the right direction horse clearly have

542
00:29:38,540 --> 00:29:40,540
larger value for p of l

543
00:29:42,660 --> 00:29:44,970
i realized i needed more data

544
00:29:45,010 --> 00:29:47,140
so i went back to our i said well

545
00:29:47,160 --> 00:29:51,840
i need a small animal also maybe maybe rats maybe miles

546
00:29:51,890 --> 00:29:53,710
and they said OK

547
00:29:53,750 --> 00:29:55,420
they gave me

548
00:29:55,450 --> 00:29:57,330
three more about

549
00:29:57,350 --> 00:30:00,920
they gave me an antelope which is actually a bit larger than the recall

550
00:30:01,040 --> 00:30:03,070
and they gave me awesome

551
00:30:03,120 --> 00:30:04,810
and they gave me

552
00:30:04,820 --> 00:30:06,430
a month

553
00:30:08,080 --> 00:30:09,410
is the

554
00:30:09,800 --> 00:30:12,770
of the

555
00:30:12,800 --> 00:30:14,540
and the world

556
00:30:14,640 --> 00:30:17,050
year is the one

557
00:30:17,090 --> 00:30:19,720
one of the

558
00:30:20,960 --> 00:30:22,310
here is the one

559
00:30:22,350 --> 00:30:24,470
of the opossum

560
00:30:24,540 --> 00:30:26,880
no you won't believe this

561
00:30:26,930 --> 00:30:28,420
this is so

562
00:30:32,430 --> 00:30:34,570
there is the money

563
00:30:34,620 --> 00:30:36,040
isn't that beautiful

564
00:30:36,040 --> 00:30:41,910
he's about to leave he knew little more

565
00:30:41,970 --> 00:30:44,400
and now it is

566
00:30:44,460 --> 00:30:46,430
and i am

567
00:30:46,510 --> 00:30:47,580
i'm a lot

568
00:30:47,600 --> 00:30:51,240
and if you look at what would look like

569
00:30:52,100 --> 00:31:00,590
what is

570
00:31:00,610 --> 00:31:03,320
i was shocked

571
00:31:03,330 --> 00:31:05,700
i was really shocked

572
00:31:05,740 --> 00:31:07,000
because look

573
00:31:07,020 --> 00:31:11,290
or fifty times larger in size than the model

574
00:31:11,320 --> 00:31:15,020
the difference in db is only a factor of two

575
00:31:15,030 --> 00:31:16,320
i expected

576
00:31:17,420 --> 00:31:19,230
more like factor

577
00:31:20,800 --> 00:31:24,390
and so in d of hell where expect the factor of seven i only see

578
00:31:26,050 --> 00:31:30,160
so i said to myself oh my goodness why didn't they i ask them for

579
00:31:30,160 --> 00:31:31,370
an elephant

580
00:31:31,420 --> 00:31:34,020
the real clincher would be dead because

581
00:31:34,060 --> 00:31:37,820
if that goes way of scale maybe we can still rescue

582
00:31:37,930 --> 00:31:40,060
statement by galileo galilei

583
00:31:40,060 --> 00:31:41,750
and so i went back

584
00:31:41,800 --> 00:31:44,010
and they said OK we'll give you

585
00:31:44,020 --> 00:31:47,090
the theme of an elephant they also gave me one of the most believe it

586
00:31:47,090 --> 00:31:49,310
or not i think they want to get rid of me by that time to

587
00:31:49,460 --> 00:31:50,560
the rank of u

588
00:31:51,470 --> 00:31:55,660
is the the more of an elephant

589
00:31:55,700 --> 00:31:57,020
and then measure the

590
00:31:57,030 --> 00:31:58,430
the length

591
00:31:58,490 --> 00:32:00,000
and the thickness

592
00:32:00,000 --> 00:32:05,300
usually this is represent the ideas presented so that when x is x is what

593
00:32:05,300 --> 00:32:10,920
i don't know why i still very high dimensional vector giving an image

594
00:32:10,930 --> 00:32:15,370
so it is around is random vector because we can assume that you know if

595
00:32:15,380 --> 00:32:19,750
a if we posted the random vector then it means that we elect to looking

596
00:32:19,760 --> 00:32:25,640
at the class of all images in the set in a certain environment

597
00:32:25,650 --> 00:32:30,290
people talk about for example in natural images which means that you know if i

598
00:32:30,290 --> 00:32:34,630
just if i take the images that i see seen my ordinary arrive or perhaps

599
00:32:34,630 --> 00:32:39,990
that you know came and so in in their ordinary lives then you know that

600
00:32:39,990 --> 00:32:44,520
that is the probability distribution for in the image space and that's a random vector

601
00:32:44,520 --> 00:32:46,260
of natural

602
00:32:46,270 --> 00:32:47,520
but what people

603
00:32:47,530 --> 00:32:51,010
you hear people usually decompose this

604
00:32:51,030 --> 00:32:56,680
this linear transformation like this so that you multiply each of the columns of y

605
00:32:56,690 --> 00:32:59,870
by the corresponding element of this

606
00:32:59,880 --> 00:33:03,890
because the point is that this is called the mixing matrix they and they are

607
00:33:03,890 --> 00:33:07,420
now part of images or they are but i mean they were there in the

608
00:33:07,420 --> 00:33:09,220
same space as images

609
00:33:09,230 --> 00:33:13,270
so you will see that each image is represented as the sum of certain kinds

610
00:33:13,810 --> 00:33:18,700
elements which will call them features

611
00:33:18,710 --> 00:33:21,850
o it while mathematically of the basis

612
00:33:21,870 --> 00:33:25,440
so this is this kind of ideas have been used in image processing for a

613
00:33:25,440 --> 00:33:30,720
long time it what people do is they choose these basis vectors using some

614
00:33:30,740 --> 00:33:38,450
some nice mathematical theories so they choose fixed basis vectors using the mathematical theory for

615
00:33:38,450 --> 00:33:43,120
example if you use mathematics for its use fourier analysis you would see that well

616
00:33:43,120 --> 00:33:47,880
this basis vectors should be signed sinusoids are called cosine functions

617
00:33:47,890 --> 00:33:53,150
and the related that you can't use the discrete cosine transformation basis functions which are

618
00:33:53,150 --> 00:33:57,940
very similar of if you if you go a bit further in the history i

619
00:33:57,940 --> 00:34:01,490
mean if you go a bit forward in the history of mathematics you will find

620
00:34:01,490 --> 00:34:06,000
things like wavelet all gabor functions to be used as

621
00:34:07,480 --> 00:34:13,240
but another question that we post when we do i see a and b and

622
00:34:13,240 --> 00:34:17,930
sparse coding modelling is that's what are actually the best basis vectors

623
00:34:17,990 --> 00:34:21,950
again this has to be defined in some way so the idea is that what

624
00:34:22,140 --> 00:34:28,690
the statistically best basis vectors for a set of basis vectors they have some nice

625
00:34:28,690 --> 00:34:32,470
properties of their own but there's no reason to think that they would be really

626
00:34:32,470 --> 00:34:37,320
statistically the best basis vectors

627
00:34:37,340 --> 00:34:44,110
so it's just an illustration of what kind of basis vectors are typically used for

628
00:34:44,150 --> 00:34:48,780
this because i transformed vectors so they are two different from

629
00:34:48,790 --> 00:34:55,730
from sinusoidal functions and here are some way that basis functions which have the property

630
00:34:55,730 --> 00:35:00,860
of being usually very localized so you get the idea is that great is in

631
00:35:00,860 --> 00:35:05,140
each of these small so we know we are modelling only very small patches of

632
00:35:05,140 --> 00:35:09,040
images in all of this size and each of these

633
00:35:09,050 --> 00:35:11,710
but she here is one basis vector where

634
00:35:11,740 --> 00:35:16,770
great is zero and black and white than positive or negative values for the for

635
00:35:16,770 --> 00:35:21,160
the coefficients so that the nice thing in this in this case

636
00:35:21,200 --> 00:35:27,680
kind of representation that's the way i actually images and conditional

637
00:35:27,690 --> 00:35:31,310
so we go got to the idea of sparse coding which

638
00:35:31,320 --> 00:35:35,000
we will see later is almost the same thing as i see it

639
00:35:35,020 --> 00:35:39,940
but sparse coding and decided to do sparseness were proposed in vision research

640
00:35:40,670 --> 00:35:43,220
before ICA invented actually

641
00:35:43,230 --> 00:35:50,120
at least in seventy two although some there was an influential papers on the subject

642
00:35:50,120 --> 00:35:51,680
and maybe was actually

643
00:35:51,690 --> 00:35:54,520
now before that

644
00:35:54,530 --> 00:35:58,180
so we inside when we go above i see if you can say that sparse

645
00:35:58,190 --> 00:36:01,860
is actually one form of nongaussianity

646
00:36:01,900 --> 00:36:07,100
that is typical of natural signals especially in natural images

647
00:36:07,740 --> 00:36:12,910
higher order structure means something that goes exactly the high you when we talk about

648
00:36:12,910 --> 00:36:18,410
higher order we can refer for example to cumulants in the sense that it is

649
00:36:18,410 --> 00:36:20,660
something that is not in the covariance

650
00:36:20,730 --> 00:36:25,260
well actually highly organised is is widely used but it actually has many different meanings

651
00:36:25,260 --> 00:36:30,550
of maybe who wish for which we've talked about that

652
00:36:30,560 --> 00:36:36,550
so what what's past this means is that variable is active only area where active

653
00:36:36,550 --> 00:36:41,370
means that is significantly different from zero

654
00:36:41,390 --> 00:36:47,150
so the idea is that here we have some random samples from a gaussian variable

655
00:36:47,170 --> 00:36:51,440
so the time structure is not of importance actually there is no time structure is

656
00:36:51,440 --> 00:36:54,240
are just random samples from a gaussian distribution

657
00:36:54,260 --> 00:36:55,860
but you see

658
00:36:56,020 --> 00:36:58,300
you can see the difference to this

659
00:36:58,570 --> 00:37:01,090
a random sample from a sparse

660
00:37:02,660 --> 00:37:06,960
well the mean the median is well the mean what is given here by the

661
00:37:06,960 --> 00:37:13,040
horizontal line and actually also the variances of these two distributions are exactly the same

662
00:37:13,050 --> 00:37:15,430
so that but this difference

663
00:37:15,840 --> 00:37:21,180
is is therefore difference in nongaussianity

664
00:37:21,220 --> 00:37:26,090
well what you see is that in the sparse case where you have sometimes very

665
00:37:26,090 --> 00:37:30,200
large values much larger than what you have in the gaussian case but then on

666
00:37:30,200 --> 00:37:35,170
the other hand much of the time you are extremely close to zero

667
00:37:35,180 --> 00:37:37,640
so close to zero that you can't really

668
00:37:37,660 --> 00:37:42,230
see the difference

669
00:37:42,280 --> 00:37:43,580
so on the

670
00:37:44,200 --> 00:37:49,110
in other words if you take the histogram of that of the be estimated you

671
00:37:49,130 --> 00:37:53,450
get the PDF of the kind of response variable it should be something where you

672
00:37:53,450 --> 00:37:56,300
have a high peak at zero

673
00:37:56,300 --> 00:37:59,530
and our set of

674
00:37:59,560 --> 00:38:05,910
solutions to second order homogeneous differential equations the one we've seen just before is of

675
00:38:05,910 --> 00:38:08,150
dimension two as well

676
00:38:08,150 --> 00:38:12,140
and i said two of our

677
00:38:12,160 --> 00:38:15,510
is is actually of infinite dimension

678
00:38:16,590 --> 00:38:24,620
some subspace that may be useful are hyperplanes and they are defined as subspaces of

679
00:38:24,630 --> 00:38:27,230
of the original vector space

680
00:38:27,270 --> 00:38:31,190
which have a separate elementary of dimension exactly one

681
00:38:31,930 --> 00:38:33,200
so in rd

682
00:38:33,220 --> 00:38:38,280
any subspace of dimension d minus one is the height of the tree

683
00:38:38,990 --> 00:38:44,570
the reason why we define hyperplanes through their supplement there is a that if if

684
00:38:44,570 --> 00:38:49,830
you have a separate set is infinite dimension at the beginning

685
00:38:49,890 --> 00:38:55,490
then the appropriate and still has an infinite dimension so you can't really say the

686
00:38:55,500 --> 00:38:57,520
hyperplane dimension

687
00:38:57,550 --> 00:38:59,180
minus one

688
00:38:59,180 --> 00:39:03,450
the dimension of the original space three that's what you think about

689
00:39:03,920 --> 00:39:18,400
now there is the basis of of his face is generative and linearly independent i

690
00:39:18,400 --> 00:39:20,030
mean subspace

691
00:39:20,100 --> 00:39:23,070
they all have exactly the same cardinal

692
00:39:23,140 --> 00:39:31,010
and they use the unique decomposition for any x in this subspace

693
00:39:31,720 --> 00:39:34,450
in rd we've seen that the

694
00:39:34,460 --> 00:39:36,060
vectors there

695
00:39:38,200 --> 00:39:43,440
those vectors there are two you the basis

696
00:39:43,540 --> 00:39:48,470
in know in two of the issue of two pi so the set of functions

697
00:39:48,470 --> 00:39:52,750
that are square in trying to go to war in this interval zero

698
00:39:52,760 --> 00:39:53,870
he o two pi

699
00:39:53,900 --> 00:39:56,150
then you can show that the set of

700
00:39:56,550 --> 00:40:00,850
function cosine and t and sign to fall

701
00:40:00,860 --> 00:40:02,930
possible integers

702
00:40:04,040 --> 00:40:06,000
is the basis as well

703
00:40:06,220 --> 00:40:10,230
so that will tell you that if you have a square integrable function

704
00:40:10,590 --> 00:40:17,750
on you to find and you can extract decomposes as as such as some

705
00:40:17,750 --> 00:40:22,380
where the nndm are unique coefficients

706
00:40:23,650 --> 00:40:27,980
so that enables you to see a function as a sum of

707
00:40:30,030 --> 00:40:31,930
signs here

708
00:40:32,020 --> 00:40:36,760
of cosines and sines for which you know the from the properties right those those

709
00:40:36,760 --> 00:40:40,840
of simple functions which you can see really easy

710
00:40:43,210 --> 00:40:47,310
what's next

711
00:40:47,400 --> 00:40:54,890
it in our tool for example we talked about projection just before and we also

712
00:40:54,900 --> 00:40:57,060
talk about the project so

713
00:40:57,520 --> 00:41:01,200
actually the next question is that if you have such an composition how are you

714
00:41:01,200 --> 00:41:03,740
going to find the m in the end

715
00:41:03,790 --> 00:41:06,750
right how are you going to find the coefficients

716
00:41:06,770 --> 00:41:09,510
in front of your disease vectors

717
00:41:09,530 --> 00:41:14,110
and so an easy way to do that is that is when you're vector space

718
00:41:14,190 --> 00:41:20,110
as on top of having the addition and multiplication motives here

719
00:41:20,190 --> 00:41:22,750
also has the product

720
00:41:23,330 --> 00:41:27,530
in our these you're the use of the product produced in before

721
00:41:27,740 --> 00:41:32,020
and it's going to euclidean norm in rd

722
00:41:32,180 --> 00:41:36,520
and you can see the dot product has

723
00:41:36,580 --> 00:41:39,140
a measure of how

724
00:41:39,200 --> 00:41:44,320
of what is the angle between x tool two vectors x and y

725
00:41:44,380 --> 00:41:46,180
OK so

726
00:41:46,180 --> 00:41:50,520
if you have a vector space with the product than any subspace of it has

727
00:41:50,520 --> 00:41:53,760
a unique orthogonal supplementary which means

728
00:41:53,850 --> 00:41:55,680
is that the

729
00:41:55,680 --> 00:41:59,550
two sets s and it's also one of their

730
00:41:59,570 --> 00:42:13,550
where which means that the disagreement areas this the spatial properties that if x is

731
00:42:13,550 --> 00:42:21,390
in s and and y is in the supplementary then you are you automatically have

732
00:42:21,400 --> 00:42:23,820
that the dot product is equal to zero

733
00:42:23,850 --> 00:42:25,060
on that too

734
00:42:25,080 --> 00:42:28,940
elements of s and f of the orthogonal

735
00:42:28,940 --> 00:42:30,960
OK so that private beings you

736
00:42:30,970 --> 00:42:34,780
you should think about this as the two vectors being also one of

737
00:42:35,710 --> 00:42:37,040
and so on

738
00:42:39,300 --> 00:42:43,440
now that you know if you have a unique supplementary then what you can do

739
00:42:43,440 --> 00:42:47,710
is that it is easy the decompose

740
00:42:47,710 --> 00:42:53,920
vectors and you have relations between the norm of the different parts of your vectors

741
00:42:55,260 --> 00:42:56,950
and that's what's written here

742
00:42:56,960 --> 00:43:00,610
if you have two separate there's spaces then

743
00:43:00,690 --> 00:43:05,680
the norm of x is the squared is equal to the number of

744
00:43:05,730 --> 00:43:11,220
it's part on on the subspace as implicit support on the the wall space

745
00:43:11,230 --> 00:43:15,000
which is only saying that for example

746
00:43:15,080 --> 00:43:21,970
the norm of this vector is the square of the slang this ranks right

747
00:43:22,020 --> 00:43:24,790
this ranks is

748
00:43:24,810 --> 00:43:29,360
this would be the the projection of a on your subspace

749
00:43:29,370 --> 00:43:34,670
this would be the projection of a on your six space is orthogonal

750
00:43:34,680 --> 00:43:38,840
so the norm of this vector square this vector square

751
00:43:38,860 --> 00:43:44,870
i don't know this was that's your particular into right

752
00:43:46,610 --> 00:43:49,990
i just remind you what it all means of their

753
00:43:50,090 --> 00:43:53,570
and i'm not going to tell you again what is

754
00:43:55,130 --> 00:43:59,990
so again as an oil spill also referred in only if they are the products

755
00:43:59,990 --> 00:44:03,810
is zero and

756
00:44:03,860 --> 00:44:09,430
so the last efficient mission i want to give is what is a hilbert space

757
00:44:09,440 --> 00:44:11,990
so here space is a vector space

758
00:44:12,000 --> 00:44:13,930
where you have the dot product

759
00:44:13,950 --> 00:44:21,180
and additionally this basis closed for the norm that is used by the dot product

760
00:44:21,190 --> 00:44:24,210
so again in two of our

761
00:44:24,260 --> 00:44:28,790
such as the stress it's a vector space is the product of two functions is

762
00:44:28,790 --> 00:44:32,550
the in the integration of the product of two functions

763
00:44:32,570 --> 00:44:36,990
and these units and all which is the norm which he

764
00:44:37,030 --> 00:44:43,420
the integration of squaring the square root of the interval of of square

765
00:44:43,420 --> 00:44:45,940
and if you

766
00:44:45,950 --> 00:44:51,960
again the fact that the space is closed means that if you have a sequence

767
00:44:51,960 --> 00:44:54,780
of vector in h that converges tenure

768
00:44:54,800 --> 00:45:07,150
sure that the limit is in it as well

769
00:45:07,240 --> 00:45:13,580
so once you have your for going OTT you may look for so basis

770
00:45:13,640 --> 00:45:21,520
and obviously usual visiting our these are not small enough so normal basis basis is

771
00:45:21,520 --> 00:45:27,980
also normally if the dot product between two any two vector businesses is either one

772
00:45:27,980 --> 00:45:32,750
we obtain this as the best horses so this classifies this at the wrong place

773
00:45:32,750 --> 00:45:36,210
at the wrong but it is much better than this one because this is what

774
00:45:36,600 --> 00:45:38,690
misclassified is too big

775
00:45:39,580 --> 00:45:45,090
do this several times now increasingly for those

776
00:45:45,170 --> 00:45:46,640
do this again

777
00:45:46,950 --> 00:45:49,360
then we chose this hypothesis

778
00:45:50,200 --> 00:45:52,020
then this one k

779
00:45:52,050 --> 00:45:56,310
in in the end you just add those policies and you see some hard by

780
00:45:56,330 --> 00:46:01,860
the colour you see essentially how positive the region came many put the threshold theorem

781
00:46:02,240 --> 00:46:07,000
and that would mean this one here so this is the decision

782
00:46:09,330 --> 00:46:12,330
OK this is just a linear combination of these

783
00:46:12,340 --> 00:46:16,560
especially structure that functions

784
00:46:16,570 --> 00:46:19,880
OK this upon the decision boundary

785
00:46:19,960 --> 00:46:21,870
OK so

786
00:46:22,320 --> 00:46:28,710
in know somebody for binary classification we have the hypotheses we have this hypothesis class

787
00:46:28,720 --> 00:46:34,670
and we positive class and b essentially based on which can generate these functions of

788
00:46:34,680 --> 00:46:36,190
the positive class

789
00:46:36,210 --> 00:46:41,250
and we have these weights alpha one twelve t t is always the number of

790
00:46:43,340 --> 00:46:50,880
so in the classification output is simply the majority of all these things forces invaded

791
00:46:50,880 --> 00:46:57,670
majority so simply take this summer and then put it put this sign signals

792
00:46:57,720 --> 00:46:59,870
this here

793
00:46:59,880 --> 00:47:04,220
OK so how can you find the hypotheses and also the right

794
00:47:04,290 --> 00:47:08,990
so there are several methods one this the first one thing was supporting the filtering

795
00:47:09,470 --> 00:47:15,010
later there was a method by trying to ninety five forty by majority only prime

796
00:47:15,080 --> 00:47:19,250
came up with something he called bagging similar

797
00:47:19,320 --> 00:47:25,460
but the it's always constant and then later ninety six there was adaboost so like

798
00:47:25,460 --> 00:47:26,760
ten years old

799
00:47:30,590 --> 00:47:36,230
so the idea of boosting the training was to run the weak learner on different

800
00:47:36,650 --> 00:47:42,420
so that was the idea of having different some examples so he generated they generated

801
00:47:43,140 --> 00:47:48,020
different versions of training sets of points and OCR the just generated different versions of

802
00:47:48,020 --> 00:47:53,140
let us by rotating or something and then they had just modification of the training

803
00:47:53,140 --> 00:47:56,530
set and and then they looked at

804
00:47:56,550 --> 00:47:59,240
they use the current function to filter out some of the

805
00:47:59,250 --> 00:48:03,380
examples and then the combined somehow complexlly

806
00:48:03,390 --> 00:48:05,200
to show the

807
00:48:05,210 --> 00:48:11,480
performance guarantee on the other hand required knowledge on the performance of the baseline beginning

808
00:48:11,730 --> 00:48:20,410
similar was foreseen by majority proposed ninety five he the main difference was that they

809
00:48:20,410 --> 00:48:26,180
are linearly combined so the combination with simple but all the required knowledge on the

810
00:48:26,180 --> 00:48:29,190
performance of the learner

811
00:48:29,200 --> 00:48:34,480
prime proposed ninety six bagging and that is

812
00:48:34,510 --> 00:48:39,710
quite a different idea but it looks quite similar

813
00:48:39,720 --> 00:48:44,170
so and the idea is to run the base learner on different versions of the

814
00:48:44,170 --> 00:48:50,510
training set so one simply creates bootstrap replicates of the training set one simply with

815
00:48:50,880 --> 00:48:56,330
one sample from the training set with replacement so once takes subset essentially training set

816
00:48:56,670 --> 00:49:00,690
and runs the base learner and that someone that way we get different hypotheses

817
00:49:00,700 --> 00:49:04,380
but here the

818
00:49:04,390 --> 00:49:11,280
i alpha t this property was simply one over t so these based these functions

819
00:49:11,420 --> 00:49:15,430
simply averaged OK so there is no adaptation really going on

820
00:49:15,440 --> 00:49:18,800
and and we can actually show its

821
00:49:18,830 --> 00:49:22,360
quite i mean behaving quite differently from from adaboost

822
00:49:22,580 --> 00:49:25,610
this is not emphasizing the difficult examples

823
00:49:25,700 --> 00:49:26,970
i was not posting

824
00:49:26,990 --> 00:49:28,780
i'm showing you

825
00:49:28,790 --> 00:49:35,250
OK so this is actually the other side so that is the one which generated

826
00:49:35,480 --> 00:49:37,700
these pictures both

827
00:49:37,710 --> 00:49:40,420
OK let's go through this in the detail

828
00:49:40,440 --> 00:49:45,690
so we i mean this is the algorithm which we are talking about four OK

829
00:49:45,710 --> 00:49:48,670
so we have an examples so

830
00:49:48,730 --> 00:49:52,990
x x one y and y one two x and y and n to be

831
00:49:52,990 --> 00:49:58,340
have this rating on these examples and initially this weighting is just uniform every example

832
00:49:58,340 --> 00:50:00,240
has the same weight

833
00:50:00,250 --> 00:50:06,220
OK and is illustrated you OK so we have a look at t iterations capability

834
00:50:06,430 --> 00:50:12,080
iterations and we have the the basis which we call

835
00:50:12,090 --> 00:50:15,730
so the first step we call this base learner and we tried to get a

836
00:50:15,730 --> 00:50:23,110
function which somehow considers this distribution and we obtain process that classifies points into a

837
00:50:23,110 --> 00:50:25,660
plus or minus one simplicity

838
00:50:25,660 --> 00:50:31,440
then we can simply compute the weighted error epsilon t that that's just some

839
00:50:31,450 --> 00:50:39,080
all those rates of points which are misclassified case x h not htx and is

840
00:50:39,090 --> 00:50:41,020
not equal to y

841
00:50:42,550 --> 00:50:45,930
this should be smaller than high otherwise it will be when it OK

842
00:50:45,940 --> 00:50:50,890
then compute the hypothesis may so we get this function here offered he's just this

843
00:50:50,890 --> 00:50:56,170
quantity here and essentially this is large this weighted error is small

844
00:50:56,190 --> 00:50:59,680
OK to give more weight to the function which is which is good i mean

845
00:50:59,680 --> 00:51:01,030
which is classifying web

846
00:51:01,060 --> 00:51:06,750
in the end we update the example distribution is the most important the most important

847
00:51:06,750 --> 00:51:07,530
step you

848
00:51:07,560 --> 00:51:13,080
OK so let's have a look at that so so the example distribution

849
00:51:13,220 --> 00:51:17,960
so the weight of the example in the t plus first iteration is simply the

850
00:51:17,960 --> 00:51:22,690
rate of the end the example in the teeth iterations times e to the minus

851
00:51:23,110 --> 00:51:28,220
alpha t y and htxn OK so this is a y and h two x

852
00:51:28,960 --> 00:51:33,690
that is minus one if the example is mis classified because then the the science

853
00:51:33,690 --> 00:51:40,020
don't match and plus one it's correctly classified OK so and we simply when it's

854
00:51:40,020 --> 00:51:45,170
correctly classified then this e to the minus something up it is positive OK so

855
00:51:45,170 --> 00:51:50,260
this is download it and if this is negative here then this term here is

856
00:51:50,910 --> 00:51:56,640
something which is large and one case it upgraded and we divided by the sum

857
00:51:56,640 --> 00:51:57,700
of all those

858
00:51:59,200 --> 00:52:03,140
so at the distribution so this sums up to one

859
00:52:04,370 --> 00:52:06,630
OK we iterate this several times

860
00:52:06,640 --> 00:52:11,370
and in every iteration we we generate one of these functions here and then combine

861
00:52:11,370 --> 00:52:14,790
them in the end with with with some

862
00:52:16,410 --> 00:52:18,640
any christian for that to be

863
00:52:18,670 --> 00:52:20,290
it should be very clear

864
00:52:28,310 --> 00:52:31,630
so what are so we use the use the space

865
00:52:32,390 --> 00:52:35,970
we have to assume something on the space

866
00:52:35,980 --> 00:52:39,090
so at least we should have some which is what this page should

867
00:52:39,140 --> 00:52:42,210
so it should somehow

868
00:52:42,230 --> 00:52:48,540
generate simple hypotheses so that means it should be used as a small base hypothesis

869
00:52:48,540 --> 00:52:52,090
because the most amazing factor two there when they happen to be

870
00:52:54,450 --> 00:52:59,000
so now it is all this is really easy this is a one square

871
00:52:59,100 --> 00:53:01,110
he was an

872
00:53:01,130 --> 00:53:02,700
so one

873
00:53:02,720 --> 00:53:04,650
is the square root of n

874
00:53:08,380 --> 00:53:11,580
so the cost that i'm getting over here l one class l two or l

875
00:53:11,580 --> 00:53:16,880
one is the square n plus an over ten which is again and i get

876
00:53:16,880 --> 00:53:19,340
to read

877
00:53:19,340 --> 00:53:24,100
search cost

878
00:53:24,120 --> 00:53:28,030
and caring about the costs and here because it will matter in a moment

879
00:53:28,070 --> 00:53:30,340
two square to that

880
00:53:30,400 --> 00:53:35,660
not caring about the additive constant for the multiplicative constant i care about

881
00:53:37,350 --> 00:53:38,520
that seems

882
00:53:38,540 --> 00:53:42,110
good we started with a linked list that search in

883
00:53:42,130 --> 00:53:47,120
and time data and time per operation now we have two linked lists search and

884
00:53:47,120 --> 00:53:49,060
data retention time

885
00:53:49,100 --> 00:53:52,610
seems pretty good this is what the structure looks like we have

886
00:53:52,620 --> 00:53:55,610
return guys here

887
00:53:56,360 --> 00:53:57,260
this is in n

888
00:53:57,270 --> 00:53:59,100
the local line

889
00:53:59,120 --> 00:54:04,610
and we have one express stop which represents that then we have another it and

890
00:54:07,210 --> 00:54:08,770
values in the

891
00:54:08,780 --> 00:54:10,630
local line we have one

892
00:54:10,660 --> 00:54:14,150
express stopped represents that these two are aligned

893
00:54:14,200 --> 00:54:15,410
and so on

894
00:54:27,810 --> 00:54:30,940
but that's in there

895
00:54:31,040 --> 00:54:35,190
OK so they're each of these trunks has length through and and the number of

896
00:54:35,190 --> 00:54:40,350
representatives up here is greater than the number of express stops discriminative that so clearly

897
00:54:40,350 --> 00:54:43,910
things are balanced now i search for most worried about up here that i search

898
00:54:44,020 --> 00:54:45,890
one of these was from elsewhere that

899
00:54:45,970 --> 00:54:47,900
for every search takes them two

900
00:54:51,130 --> 00:54:53,530
what should we do next

901
00:54:53,530 --> 00:54:57,690
it's again ignore insertions and deletions i wanna make searches fastica scriven is not so

902
00:54:57,690 --> 00:55:05,540
far as we know

903
00:55:06,700 --> 00:55:08,210
more lines

904
00:55:08,290 --> 00:55:10,880
what's at super express line

905
00:55:10,900 --> 00:55:12,870
with that another linked list

906
00:55:12,890 --> 00:55:14,830
this was to

907
00:55:14,840 --> 00:55:17,580
one two three

908
00:55:23,550 --> 00:55:25,810
so we started with the sorted linked lists

909
00:55:25,830 --> 00:55:31,260
then we went to two

910
00:55:31,310 --> 00:55:33,900
this gave us to swearing

911
00:55:34,570 --> 00:55:35,810
i one three

912
00:55:35,840 --> 00:55:39,150
sorted linked lists

913
00:55:41,610 --> 00:55:45,070
any guesses what the running time might be

914
00:55:45,120 --> 00:55:48,410
this is just guesswork don't think

915
00:55:48,460 --> 00:55:54,570
from two square and you would go to

916
00:55:54,610 --> 00:55:57,550
thank you

917
00:55:57,570 --> 00:56:04,870
two square to force through and that's on the right track

918
00:56:04,890 --> 00:56:08,330
both the constant and the rule change

919
00:56:08,370 --> 00:56:11,750
but not quite sufficiently

920
00:56:11,790 --> 00:56:14,400
three times the cube good

921
00:56:14,420 --> 00:56:16,990
intuition is very helpful here

922
00:56:17,040 --> 00:56:19,900
the matter whether the answers intuition

923
00:56:20,000 --> 00:56:22,030
now you can prove that it's not so hard

924
00:56:22,040 --> 00:56:25,490
you know have three lists and what you want to balance are

925
00:56:25,540 --> 00:56:29,800
the length of the topless the ratio between the top two layers and the ratio

926
00:56:29,800 --> 00:56:31,320
between the bottom two lists

927
00:56:31,440 --> 00:56:32,850
see what these three

928
00:56:32,870 --> 00:56:34,940
two multiply out

929
00:56:36,920 --> 00:56:38,130
because that i mean

930
00:56:38,190 --> 00:56:42,180
top times the ratio times the ratio that's legal and

931
00:56:42,200 --> 00:56:45,890
and so that's where you get the cube of each of these should be equal

932
00:56:45,910 --> 00:56:49,870
this that because the cost is the sum of those three things

933
00:56:49,890 --> 00:56:52,860
he said each of the collaborative and there are three

934
00:56:52,900 --> 00:56:54,690
check it at home

935
00:56:54,770 --> 00:56:55,600
if you want

936
00:56:55,610 --> 00:56:58,120
to be more sure

937
00:56:58,740 --> 00:57:03,060
obviously we want a few more so think about k sorted lists k

938
00:57:03,070 --> 00:57:06,220
so this will be a k times the case through the

939
00:57:06,250 --> 00:57:09,100
will be just that are now

940
00:57:09,110 --> 00:57:17,780
so what should we set k two

941
00:57:17,850 --> 00:57:20,020
i don't want the exact minimum just

942
00:57:20,170 --> 00:57:22,350
what's a good value

943
00:57:22,360 --> 00:57:24,920
OK and

944
00:57:25,000 --> 00:57:27,940
and it's kind of nice because and through and is just one

945
00:57:28,150 --> 00:57:29,850
it's now that's and so

946
00:57:30,020 --> 00:57:32,990
this is why i care about the lead constant because it's

947
00:57:33,040 --> 00:57:41,040
going to grow as i had more or less

948
00:57:41,060 --> 00:57:45,780
was the biggest reasonable value of k that i could use

949
00:57:45,860 --> 00:57:47,790
log n

950
00:57:47,910 --> 00:57:52,780
because how k out out there certainly don't is more than one and so on

951
00:57:52,780 --> 00:57:57,170
log n times the log inference is a little hard to draw

952
00:57:59,080 --> 00:58:01,700
now it is the log in through the event

953
00:58:01,760 --> 00:58:02,690
that's the hero

954
00:58:02,810 --> 00:58:11,850
he about

955
00:58:11,910 --> 00:58:19,170
what is the log entry of n minus two

956
00:58:19,210 --> 00:58:28,220
one of these good questions whose answers

957
00:58:28,270 --> 00:58:30,340
the the definition of a word

958
00:58:30,350 --> 00:58:34,410
OK is and so the one to reward and

959
00:58:35,420 --> 00:58:37,680
however the definition of having a power

960
00:58:37,690 --> 00:58:38,900
in the b

961
00:58:38,920 --> 00:58:39,640
it's like

962
00:58:39,650 --> 00:58:42,340
two the power of the game

963
00:58:43,600 --> 00:58:45,150
so this is

964
00:58:46,060 --> 00:58:48,390
so the log n

965
00:58:48,420 --> 00:58:50,530
but hello again

966
00:58:50,540 --> 00:58:53,550
which is

967
00:58:53,600 --> 00:58:57,710
if you can get at this point

968
00:59:01,320 --> 00:59:06,140
log entries and minus two is zero my favorite answer

969
00:59:07,460 --> 00:59:08,440
this is too

970
00:59:08,460 --> 00:59:11,340
so this whole thing is too long and

971
00:59:11,380 --> 00:59:16,140
pretty nifty so you can be a little fancier sweet this little bit but to

972
00:59:16,140 --> 00:59:18,590
log is planning good for me

973
00:59:18,600 --> 00:59:21,120
clearly don't want to use a more less

974
00:59:21,140 --> 00:59:23,550
log and la sounds pretty good i get now

975
00:59:23,560 --> 00:59:25,080
logarithmic search

976
00:59:25,090 --> 00:59:29,040
let's cheque i mean we said did this all intuitively let's draw what the list

977
00:59:29,040 --> 00:59:29,950
looks like

978
00:59:29,970 --> 00:59:31,680
but work

979
00:59:44,670 --> 00:59:47,550
i gonna region

980
00:59:47,550 --> 00:59:49,420
this example shows

981
00:59:49,440 --> 00:59:51,050
you have to also

982
00:59:52,420 --> 00:59:56,520
so let's redesign the new york city subway system

983
00:59:56,520 --> 01:00:00,100
i want to leave or three blank lines up here

984
01:00:02,660 --> 01:00:05,280
so far

985
01:00:05,420 --> 01:00:06,870
this cameras now

986
01:00:06,900 --> 01:00:11,460
i don't

987
01:00:11,550 --> 01:00:19,720
so we're not want to change the focal lines

988
01:00:19,780 --> 01:00:22,990
it would be nice

989
01:00:22,990 --> 01:00:28,900
example of uniform univariate entities like what like like explanation is it is all of

990
01:00:28,900 --> 01:00:32,070
those things it is so what other people have been talking about this is all

991
01:00:32,070 --> 01:00:39,680
about multivariate statistics which is again cause much more complicated than one-dimensional statistical model

992
01:00:39,700 --> 01:00:45,130
and then i talk about baseball component analysis which is some kind of ancestor we

993
01:00:45,280 --> 01:00:51,770
independent component analysis and then of the very important principle of statistical independence was when

994
01:00:51,770 --> 01:00:56,990
we talk about independent component analysis it is not perhaps it's certainly very surprising that

995
01:00:57,060 --> 01:00:59,190
statistical independence will be

996
01:00:59,210 --> 01:01:02,570
many imports

997
01:01:02,590 --> 01:01:08,230
so just some basic notation so we have a random variables random variables are variables

998
01:01:08,230 --> 01:01:12,450
will take random values or something like that well there i think some somewhat more

999
01:01:12,450 --> 01:01:16,250
rigorous definitions available but

1000
01:01:16,270 --> 01:01:20,880
i didn't forget them so random variables

1001
01:01:21,060 --> 01:01:23,550
the distribution of the random variable

1002
01:01:23,680 --> 01:01:27,000
he is often described by a density function

1003
01:01:27,020 --> 01:01:30,890
well in in that case which is this possible in the case where where we

1004
01:01:30,890 --> 01:01:35,430
have a random variables which take which they collect

1005
01:01:35,450 --> 01:01:39,210
all kinds of values on the real axis for example we are not going to

1006
01:01:39,210 --> 01:01:44,170
talk about anything that takes discrete values in this in this lecture so it is

1007
01:01:44,170 --> 01:01:48,330
no we are never going to have something like the probability that a random variable

1008
01:01:48,330 --> 01:01:54,400
equals zero or the typical one everything is always continuous valued and actually based in

1009
01:01:54,400 --> 01:02:01,360
basically all cases these random variables can take all values on the real axis

1010
01:02:01,380 --> 01:02:02,250
and so

1011
01:02:02,290 --> 01:02:07,480
then in that case we can express the probability distribution function using the density function

1012
01:02:07,550 --> 01:02:13,780
and then of in particular we will be talking about random vectors which is simply

1013
01:02:13,780 --> 01:02:16,560
that we have a large number of of

1014
01:02:16,590 --> 01:02:20,020
random random variables

1015
01:02:20,040 --> 01:02:26,050
so it's like kind of a circle with multi dimensional random variable but usually random

1016
01:02:26,050 --> 01:02:32,700
variables on the variable here is restricted to one dimensional

1017
01:02:32,720 --> 01:02:36,720
and yes again you can then

1018
01:02:36,740 --> 01:02:39,800
you can express the distribution of

1019
01:02:40,460 --> 01:02:46,610
continuous valued random variables using a probability distribution function

1020
01:02:46,910 --> 01:02:48,540
well here

1021
01:02:50,080 --> 01:02:53,180
michael what gives has shows how

1022
01:02:53,370 --> 01:02:59,140
the distribution of the density function is related to the cumulative distribution function which is

1023
01:02:59,140 --> 01:03:05,030
well well-known stuff in in basics basics probability theory but well let's

1024
01:03:05,790 --> 01:03:07,490
going to that

1025
01:03:12,280 --> 01:03:22,190
well after this stuff these things like densities and so on certainly the most fundamental

1026
01:03:22,190 --> 01:03:26,790
thing in probability theory and statistics is the expectation

1027
01:03:28,950 --> 01:03:31,930
is a station

1028
01:03:31,950 --> 01:03:35,600
well in the in the basic case we talk about the mean

1029
01:03:35,610 --> 01:03:39,710
which is the expectation of a random it's

1030
01:03:39,800 --> 01:03:47,010
and while there are different kinds of technologies available but then people often talk about

1031
01:03:47,010 --> 01:03:53,080
expectation when they talk about some kind of the expectation of some of some function

1032
01:03:53,080 --> 01:03:56,950
of the size of the space of this random vector

1033
01:03:56,960 --> 01:04:02,830
the expectations are computed basically by an integral where you have well first this function

1034
01:04:02,840 --> 01:04:04,920
of x and then multiplied by

1035
01:04:05,440 --> 01:04:12,980
the probability density function and then well that's integrated all over the n dimensional space

1036
01:04:12,990 --> 01:04:16,230
as of the most interesting expectations in addition to me

1037
01:04:17,550 --> 01:04:22,850
correlations well well-backed licence so most interesting ones but let's say the most basic ones

1038
01:04:22,850 --> 01:04:27,590
actually i see one of the points in ICA is that is that these correlations

1039
01:04:27,590 --> 01:04:32,560
are just like the first step in analyzing random variables or random vectors and you

1040
01:04:32,560 --> 01:04:37,790
should not be just using the correlations

1041
01:04:40,920 --> 01:04:46,660
i have to explain what is actually the mean

1042
01:04:46,690 --> 01:04:50,760
of correlations

1043
01:04:50,770 --> 01:04:53,290
well correlations basically

1044
01:04:53,300 --> 01:04:57,980
tell you something about linear dependencies of its variables

1045
01:04:58,020 --> 01:05:00,950
so to say that we want to predict

1046
01:05:00,960 --> 01:05:03,470
x two

1047
01:05:03,530 --> 01:05:05,150
by x one

1048
01:05:05,180 --> 01:05:10,830
so this is a classic expressed as a linear regression model that i'm sure you've

1049
01:05:10,830 --> 01:05:14,000
all seen somewhere we have coefficients a here

1050
01:05:14,010 --> 01:05:19,120
and then we have some kind of noise or is it just to this trend

1051
01:05:19,340 --> 01:05:20,770
so the point is that

1052
01:05:20,780 --> 01:05:22,170
it tells us

1053
01:05:22,200 --> 01:05:23,850
well it's this

1054
01:05:23,890 --> 01:05:28,230
these are called the correlation between x one and x two well if it's if

1055
01:05:28,230 --> 01:05:30,070
it's positive and large

1056
01:05:30,780 --> 01:05:36,930
in some sense then it tells you that that's that when that's x two in

1057
01:05:36,930 --> 01:05:39,080
the same way follows x y

1058
01:05:39,100 --> 01:05:42,540
so that's when x one is large in this one will be large in the

1059
01:05:42,540 --> 01:05:46,110
next one is small this one will be be large now it turns out that

1060
01:05:46,430 --> 01:05:49,370
if we normalize these variables properly

1061
01:05:49,380 --> 01:05:52,010
then we will see

1062
01:05:52,010 --> 01:05:56,240
actually if we normalize them so if we normalized so that the variances of x

1063
01:05:56,240 --> 01:06:01,280
one and x two

1064
01:06:01,320 --> 01:06:03,280
both equal to one

1065
01:06:03,290 --> 01:06:06,360
well just

1066
01:06:06,360 --> 01:06:09,950
for those of you who don't remember i will i will remind you of the

1067
01:06:09,950 --> 01:06:13,820
definition of variance which is which is a measure of the the spread of the

1068
01:06:13,820 --> 01:06:17,620
random variable

1069
01:06:17,640 --> 01:06:25,030
so now what happens is that under these conditions this equals the correlation

1070
01:06:25,040 --> 01:06:27,520
it it equals expectation x

1071
01:06:27,540 --> 01:06:29,800
one times x two

1072
01:06:29,800 --> 01:06:33,530
is is that the hybrid is and is not in issue the book the different

1073
01:06:33,530 --> 01:06:36,100
chapters written by different authors so

1074
01:06:36,110 --> 01:06:38,570
again as above that's well worth looking at

1075
01:06:39,170 --> 01:06:43,830
more recent book by jensen is also very good and neapolitan book something else that

1076
01:06:43,830 --> 01:06:45,430
i recommend as well

1077
01:06:45,820 --> 01:06:48,640
he had a very good but back in the nineteen sixties which had been out

1078
01:06:48,640 --> 01:06:51,230
of print but i think the idea are this new book

1079
01:06:51,250 --> 01:06:57,600
nine times of books cover graphical models and variational methods from a learning perspective machine

1080
01:06:57,600 --> 01:07:00,180
and perspective there are there are very few

1081
01:07:00,200 --> 01:07:04,540
this is the first one is an edited book is the proceedings of the NATO

1082
01:07:04,840 --> 01:07:09,280
ASI edited by michael jordan was originally published by clue

1083
01:07:09,490 --> 01:07:12,790
but for those of you not multi millionaires you'll be pleased to know that it

1084
01:07:12,790 --> 01:07:17,340
was republished by MIT press in paperback and you can afford it for much less

1085
01:07:17,340 --> 01:07:20,520
than the price of family car so

1086
01:07:20,570 --> 01:07:25,000
i recommend the paperback version from MIT for that one

1087
01:07:26,420 --> 01:07:29,980
so that's an edited book so there are some tutorial type chapters in the beginning

1088
01:07:29,980 --> 01:07:33,920
of a whole bunch of research papers but it's it's it's very nice book this

1089
01:07:33,950 --> 01:07:35,160
sort of snapshot

1090
01:07:35,210 --> 01:07:40,560
this estimator workshop which might organised was actually very good because he deliberately bought together

1091
01:07:40,570 --> 01:07:44,760
twenty people from machine learning community twenty people from graphical models community and i was

1092
01:07:44,760 --> 01:07:46,610
lucky enough to be to get to go

1093
01:07:47,070 --> 01:07:50,300
and so i met all these people from this new community that i had no

1094
01:07:50,300 --> 01:07:55,110
idea that community existed and whole of stuff about graphical models simple this is really

1095
01:07:55,110 --> 01:08:00,610
interesting and really useful so might a fantastic job bringing those communities together

1096
01:08:00,660 --> 01:08:06,090
this book by brendan frey i think is really sort of his phd thesis is

1097
01:08:06,090 --> 01:08:07,110
published by

1098
01:08:07,130 --> 01:08:11,240
the MIT press it's quite tutorial and really really quite good so given that there

1099
01:08:11,240 --> 01:08:14,890
aren't any sort of great books around on this field i would recommend reading the

1100
01:08:16,260 --> 01:08:19,510
michael jordan himself the last few years has been writing a book i'm not sure

1101
01:08:19,510 --> 01:08:21,670
what his title going to be something

1102
01:08:21,680 --> 01:08:23,640
something that for models in the title

1103
01:08:23,650 --> 01:08:27,480
i think when this book is published it will be the sort of definitive book

1104
01:08:27,480 --> 01:08:31,850
on graphical models but you know textbooks take a long time to write

1105
01:08:33,470 --> 01:08:36,470
i think most of it exists in draft format i've no idea when it will

1106
01:08:36,470 --> 01:08:39,500
actually appear in print but do watch out for him but he is deaf to

1107
01:08:39,590 --> 01:08:42,170
get it will be very very good and

1108
01:08:42,280 --> 01:08:46,490
it's really quite introductory but also because all the way through to some very advanced

1109
01:08:48,510 --> 01:08:54,470
david mackay's book is not really biographical models or variational methods i think you know

1110
01:08:54,480 --> 01:08:57,770
touches on both but it's just a very good up-to-date book in the field so

1111
01:08:57,770 --> 01:08:58,680
i mentioned it as well

1112
01:08:59,110 --> 01:09:00,090
and then

1113
01:09:00,100 --> 01:09:01,800
three modesty to the wind

1114
01:09:02,250 --> 01:09:07,320
mention also writing a new book myself this but will have a chapter on graphical

1115
01:09:07,320 --> 01:09:12,010
models the chapter on variational methods and all of material that i'm presenting in here

1116
01:09:12,010 --> 01:09:14,830
is taken from the book in in the sentence

1117
01:09:14,900 --> 01:09:17,150
i'm not publishing

1118
01:09:17,200 --> 01:09:22,460
publishing with springer but even so i've got them to write into the contract that

1119
01:09:22,460 --> 01:09:25,920
the price will be kept low so that a maximum price and the maximum annual

1120
01:09:25,920 --> 01:09:30,490
increase the price of the locked into price furthermore more so six hundred pages hardback

1121
01:09:30,490 --> 01:09:32,040
it'll be in full color

1122
01:09:32,110 --> 01:09:36,920
it should be sort of student price not to not lower-priced

1123
01:09:37,030 --> 01:09:40,240
and then lots of great stuff to go with it

1124
01:09:40,260 --> 01:09:43,710
and this is the further from the front cover a pattern you can see if

1125
01:09:43,710 --> 01:09:46,260
you can recognise

1126
01:09:46,310 --> 01:09:48,410
OK so let's start to

1127
01:09:48,430 --> 01:09:50,220
talk about graphical models

1128
01:09:50,230 --> 01:09:56,380
so the idea of graphical models is to augment probability theory with some pictures

1129
01:09:56,420 --> 01:10:01,500
so everything that we're going to do with graphical models we could do without the

1130
01:10:01,500 --> 01:10:03,150
pictures we could

1131
01:10:03,160 --> 01:10:04,940
just take the

1132
01:10:04,960 --> 01:10:07,150
sum and product rule of probability

1133
01:10:07,150 --> 01:10:11,100
and just manipulate expressions using those rules just

1134
01:10:11,120 --> 01:10:12,940
large sheets of paper

1135
01:10:12,960 --> 01:10:14,660
grinding through all the mathematics

1136
01:10:14,670 --> 01:10:20,220
but we're going to

1137
01:10:20,250 --> 01:10:21,040
i have little

1138
01:10:21,760 --> 01:10:28,110
pictorial representations of probability distributions and that's going to give us in practice lot of

1139
01:10:30,710 --> 01:10:35,730
most people so perhaps not stuff interesting but i think most of us find drawing

1140
01:10:35,730 --> 01:10:40,740
pictures of things helps if know to explain the big pile of complicated mathematics

1141
01:10:40,790 --> 01:10:42,310
and so on

1142
01:10:42,330 --> 01:10:45,370
the drawing these pictures will

1143
01:10:45,390 --> 01:10:50,190
first of all was new insights into models that we already know and love

1144
01:10:50,190 --> 01:10:51,720
and that's already very useful

1145
01:10:51,730 --> 01:10:54,620
you can help motivate new models will see you

1146
01:10:54,650 --> 01:10:58,130
once you understand how models are represented graphically immediately say

1147
01:10:58,150 --> 01:11:01,080
well if this only depends on that can i just add another link to the

1148
01:11:01,080 --> 01:11:06,160
graph matching linked to the graph specifies certain things in terms of probability distributions tells

1149
01:11:06,160 --> 01:11:10,160
you how to construct the model of trying to give you some examples of this

1150
01:11:10,160 --> 01:11:12,510
how easy it is to go from

1151
01:11:12,510 --> 01:11:15,850
to take a model and then also the variance of that model

1152
01:11:15,870 --> 01:11:19,940
according to the particular application you have in mind so it's a wonderful life of

1153
01:11:19,940 --> 01:11:22,340
generating new models

1154
01:11:22,360 --> 01:11:24,500
and even more than that so said already

1155
01:11:24,510 --> 01:11:27,290
it gives this graph based algorithms for doing

1156
01:11:27,300 --> 01:11:31,300
calculation and even computation

1157
01:11:31,310 --> 01:11:34,480
so i think it's a very powerful framework i think anybody machine learning should really

1158
01:11:34,480 --> 01:11:35,650
understand this

1159
01:11:35,660 --> 01:11:38,490
this the basics of the field

1160
01:11:38,530 --> 01:11:40,330
so this hopefully is

1161
01:11:40,360 --> 01:11:43,050
painfully familiar to everybody

1162
01:11:43,100 --> 01:11:45,450
so the probability theory these two

1163
01:11:45,450 --> 01:11:49,960
very simple innocuous looking equations that's really all we need all we can do is

1164
01:11:49,960 --> 01:11:59,850
take the sum and product rule probability applied inconsistently to to learning problems

1165
01:11:59,880 --> 01:12:01,110
so just by

1166
01:12:01,130 --> 01:12:03,720
manipulating the product rule of course we obtain

1167
01:12:03,730 --> 01:12:08,010
bayes theorem the normalisation in bayes theorem

1168
01:12:08,030 --> 01:12:12,490
can be expressed the denominator expressed in terms of marginalization of the numerator so that

1169
01:12:12,640 --> 01:12:18,350
is equivalent

1170
01:12:18,380 --> 01:12:22,890
so you take the sum product rule probability now start to draw pictures of down

1171
01:12:23,910 --> 01:12:27,580
so we try to begin with directed

1172
01:12:30,430 --> 01:12:37,090
try to motivate the directed graph by considering this simple case we've got joint

1173
01:12:37,120 --> 01:12:41,260
probability distribution over three variables x y and z

1174
01:12:42,270 --> 01:12:44,050
we can simply apply

1175
01:12:45,310 --> 01:12:47,360
the chain rule of probability

1176
01:12:47,600 --> 01:12:53,840
apply the proper probability in the sort of in succession so p of x

1177
01:12:53,850 --> 01:12:55,800
y and z

1178
01:12:55,820 --> 01:12:59,500
we can write as p of x

1179
01:12:59,500 --> 01:13:03,010
the same color right so i don't know if the example that i did have

1180
01:13:03,680 --> 01:13:07,110
passenger being read or not but in general the passenger is whatever color

1181
01:13:07,120 --> 01:13:10,500
it one of the destination it wants to go to so the yellow circle wants

1182
01:13:10,500 --> 01:13:13,520
to go to the yellow square like that and if you do this if you

1183
01:13:13,690 --> 01:13:18,570
figured out probably if you did it twice get it but it turns out not

1184
01:13:19,380 --> 01:13:23,690
and in fact it's really interesting to see what normal is that to this kind

1185
01:13:23,690 --> 01:13:27,930
of very clever exploration is not is not the norm i think people and definitely

1186
01:13:27,930 --> 01:13:30,970
not in the program to talk about either so even the people in the model

1187
01:13:30,970 --> 01:13:34,750
did can significantly better in some ways than learning how we're going to tell you

1188
01:13:34,750 --> 01:13:35,890
about so

1189
01:13:36,920 --> 01:13:40,690
they get stuck more learning algorithms lisa ones and i tell you about are very

1190
01:13:40,690 --> 01:13:44,750
effective at actually figuring out what they have been tried yet and try new things

1191
01:13:44,960 --> 01:13:47,690
people i got into this mode where they would they would decide what it is

1192
01:13:47,690 --> 01:13:50,900
that they wanted to decide how it was going to work and they would just

1193
01:13:50,900 --> 01:13:51,950
stick to that

1194
01:13:52,190 --> 01:13:56,880
matter how long it was data so good so that is why do we play

1195
01:13:56,900 --> 01:14:00,640
this game other than it was sort of a fun way to break the ice

1196
01:14:00,690 --> 01:14:04,310
then i would say that this is an example of reinforcement learning environment so basically

1197
01:14:04,310 --> 01:14:07,050
you had task there was some kind of reward signal that you're trying to get

1198
01:14:07,050 --> 01:14:10,870
which was finishing the game you had actions that you could use that left out

1199
01:14:10,870 --> 01:14:16,730
of grade b and it possibly a sequence of actions was necessary to get higher

1200
01:14:16,730 --> 01:14:19,250
award in this case you need to get all through the sequence of steps to

1201
01:14:19,250 --> 01:14:23,010
win and you have some kind of state representation of some kind of information about

1202
01:14:23,010 --> 01:14:27,120
what the current state is on which to base your decisions

1203
01:14:27,130 --> 01:14:31,580
so there's other problems that fit into this setting as well this is an example

1204
01:14:31,580 --> 01:14:33,900
that we played with in the lab a couple years ago where we've got an

1205
01:14:34,000 --> 01:14:38,170
eyeball robot and what it's trying to do is decide it's just two choices it's

1206
01:14:38,170 --> 01:14:40,820
got a and b which in this case correspond to turning a little bit left

1207
01:14:40,820 --> 01:14:42,440
and turning on the right

1208
01:14:42,460 --> 01:14:44,460
and it's goal

1209
01:14:44,480 --> 01:14:47,760
in this case instead of dropping off the passenger was making visual contact with the

1210
01:14:47,760 --> 01:14:48,940
pink ball

1211
01:14:48,940 --> 01:14:53,450
OK so in some ways very simple task but otherwise it's real right it's actually

1212
01:14:53,450 --> 01:14:57,840
moving around in physical space and implementing these things it's not some kind of you

1213
01:14:57,840 --> 01:15:02,800
know theoretical data structure rather theoreticians in the robot but it's actually taking actions in

1214
01:15:02,800 --> 01:15:06,580
the real world and that's the data that's it using for its decision making

1215
01:15:06,600 --> 01:15:09,200
so again this is this is another

1216
01:15:09,230 --> 01:15:14,670
example that shows the different elements of the reinforcement learning problem maybe not in commercially

1217
01:15:14,670 --> 01:15:17,910
significant problem the turning around to see the pink ball problem i think is well

1218
01:15:17,910 --> 01:15:22,210
solved by the technology at the moment but it has all the pieces in and

1219
01:15:22,210 --> 01:15:24,650
it's and it was is

1220
01:15:24,720 --> 01:15:29,450
good first to experiment with with using noisy data as opposed to the standard simulated

1221
01:15:29,460 --> 01:15:31,070
very clean data

1222
01:15:31,120 --> 01:15:35,020
so when one is trying to trying to create a reinforcement learning system that's going

1223
01:15:35,020 --> 01:15:38,070
to solve one of these task i would say that there are three major pieces

1224
01:15:38,070 --> 01:15:41,050
at least in the model based perspective there's these three major pieces that have to

1225
01:15:41,050 --> 01:15:45,790
be addressed but the first one is using the knowledge that is gained from experience

1226
01:15:46,160 --> 01:15:50,520
r and applying it to new situations generalizing it so that actually applies to situations

1227
01:15:50,520 --> 01:15:55,580
that the decision-maker has necessarily seen before and that's really the learning problem that that's

1228
01:15:55,580 --> 01:15:59,620
the core problem in our community we have lots of different technologies that we can

1229
01:15:59,620 --> 01:16:01,530
use to solve problems like this

1230
01:16:01,540 --> 01:16:04,820
on the other side of things is what is not just about learning about the

1231
01:16:04,820 --> 01:16:09,320
environment it's about acting well in the environment and to do that the agent has

1232
01:16:09,850 --> 01:16:13,980
carry out sequential decision making access to take steps in the world

1233
01:16:14,000 --> 01:16:17,040
so so when we were playing on little taxi game

1234
01:16:17,070 --> 01:16:19,420
o it's called it's called the tax applied by the was introduced by time t

1235
01:16:19,420 --> 01:16:21,110
check a number of years ago

1236
01:16:21,120 --> 01:16:24,150
like three hundred some my papers i was able to find that the talk about

1237
01:16:24,150 --> 01:16:25,830
the problem because

1238
01:16:25,840 --> 01:16:28,410
anyway so all

1239
01:16:28,510 --> 01:16:32,120
what are the actions that you took to give you any kind of immediate

1240
01:16:32,130 --> 01:16:35,990
four didn't win the game because you chose left at a certain point with only

1241
01:16:36,010 --> 01:16:39,670
meeting together all those actions they got you to the final and so in this

1242
01:16:39,670 --> 01:16:46,870
particular case dealing with this delayed gratification is the planning problem it's sequencing actions to

1243
01:16:46,870 --> 01:16:52,530
achieve some kind of goal or map you maximizing water minimizing cost and that's actually

1244
01:16:52,530 --> 01:16:56,620
very well studied problem is what to get these two nice fairly well studied problems

1245
01:16:56,950 --> 01:17:01,990
that the piece that kind of use together and gives reinforcement learning its own the

1246
01:17:02,840 --> 01:17:06,160
problem to focus on is how do you put those two together how do you

1247
01:17:06,160 --> 01:17:11,160
do action choices in planning so that you get the right information out of the

1248
01:17:11,160 --> 01:17:15,570
learning so that you can apply that do well on the planet so solving this

1249
01:17:15,570 --> 01:17:17,370
exploration exploitation

1250
01:17:17,380 --> 01:17:19,550
balance is

1251
01:17:19,570 --> 01:17:22,460
one of the problems that makes reinforcement learning i think a lot of fun to

1252
01:17:22,460 --> 01:17:25,020
think about a lot of fun to work on and it's really significant a lot

1253
01:17:25,020 --> 01:17:28,700
of these problems are difficult to solve if the agent does figure out how to

1254
01:17:28,700 --> 01:17:32,890
explore and gain the data they need

1255
01:17:32,910 --> 01:17:35,750
all right so that the the formal model

1256
01:17:35,880 --> 01:17:40,020
that underpins a lot of work in reinforcement learning is the markov decision process here

1257
01:17:40,820 --> 01:17:44,300
this was introduced a number of years ago actually did not go over line said

1258
01:17:44,460 --> 01:17:48,800
i do people like me we devoted our lives to build and i don't think

1259
01:17:48,800 --> 01:17:52,600
that's quite true but the sense in which it is true is the introduced these

1260
01:17:52,600 --> 01:17:57,800
models a lot of what goes into solving reinforcement learning problems is about

1261
01:17:57,820 --> 01:18:01,460
solving what's known as the bellman equation this this q equation here at the bottom

1262
01:18:01,460 --> 01:18:04,470
so to just to set up for you imagine that the environment consists of some

1263
01:18:04,470 --> 01:18:08,850
member states called and in this case some set of actions that the agent gets

1264
01:18:08,850 --> 01:18:12,920
to choose among some discount factor which is controlling how important is it to get

1265
01:18:12,980 --> 01:18:17,390
reward now versus reward in the future the discount factor is very close to one

1266
01:18:17,390 --> 01:18:21,780
then words matter all throughout time it's the discount factor is closer to zero then

1267
01:18:21,850 --> 01:18:26,360
there was no really significant but you know who cares about later leaders later

1268
01:18:26,750 --> 01:18:30,480
i mean step time city the agent informed about its current state is what's the

1269
01:18:30,480 --> 01:18:33,250
state of the environment and gets to choose an action

1270
01:18:33,250 --> 01:18:35,580
from that it receives payoff or city

1271
01:18:35,600 --> 01:18:41,270
and the expected value which is determined by what's called the reward function reinforcement function

1272
01:18:41,280 --> 01:18:45,860
and then there's the transition to NXT in that transition it is governed by this

1273
01:18:45,860 --> 01:18:50,000
this t function the transition function which says that the probability that if you're in

1274
01:18:50,000 --> 01:18:54,820
some state s st and action eighty the probability and the next in status prime

1275
01:18:54,820 --> 01:18:57,170
is that expression

1276
01:18:58,640 --> 01:19:02,850
schematically we've got an agent environment having this conversation back and forth environments is the

1277
01:19:02,850 --> 01:19:07,140
state the aging gives the action the environment gives back toward the next day and

1278
01:19:07,150 --> 01:19:08,420
the game continues

1279
01:19:08,450 --> 01:19:12,000
now how do you solve a problem like this how do you decide what actions

1280
01:19:12,000 --> 01:19:16,350
take if you know the transition and reward function then this bellman equation here i

1281
01:19:16,350 --> 01:19:17,890
have one point

1282
01:19:18,140 --> 01:19:25,660
call this equation i should produce the point right to this equation right here gives

1283
01:19:25,660 --> 01:19:28,660
us a way of determining what to actually do so what this says years we're

1284
01:19:28,670 --> 01:19:32,110
going to determine this this thing called the q function that the q value of

1285
01:19:32,110 --> 01:19:35,790
being in some state s and taking some action a is

1286
01:19:35,820 --> 01:19:40,260
semantically what it is is how much reward you get aging get if it starts

1287
01:19:40,260 --> 01:19:44,050
off in state s choose action a and from then on does whatever the the

1288
01:19:44,050 --> 01:19:47,500
optimal thing is to do whatever maximizes expected reward

1289
01:19:47,540 --> 01:19:51,280
and we're going to move to compute that is by saying well we can get

1290
01:19:51,280 --> 01:19:54,320
that by saying what's going to get some immediate reward determined by the reward function

1291
01:19:54,700 --> 01:19:57,360
and then it's going to make a transition to a new state

1292
01:19:57,380 --> 01:20:02,710
and the transition probability that that state as prime is t s a s prime

1293
01:20:02,720 --> 01:20:06,040
want to get that new state is going to choose the optimal action

1294
01:20:06,080 --> 01:20:08,670
but in this case it's for pretending that we know what this q function is

1295
01:20:08,950 --> 01:20:10,100
is whichever

1296
01:20:10,120 --> 01:20:13,640
action in that state has the highest value

1297
01:20:13,660 --> 01:20:14,660
OK so

1298
01:20:15,270 --> 01:20:18,540
for now we look over all possible next states this is the weighted by the

1299
01:20:18,540 --> 01:20:21,940
this is still to be found out there on how to do this

1300
01:20:22,960 --> 01:20:25,590
i talked to little about event type hierarchy

1301
01:20:25,610 --> 01:20:30,210
you can see here that ontology reuse is being done there is a class event

1302
01:20:30,250 --> 01:20:35,380
which is a subclass of the dolce ontology event where we create events for the

1303
01:20:35,380 --> 01:20:41,810
domains that are needed like facebook event at facebook status feed which is very simple

1304
01:20:41,810 --> 01:20:47,460
hierarchical and hierarchy me and this is all RDF so everyone can go and extend

1305
01:20:47,710 --> 01:20:49,860
on each of these branches

1306
01:20:51,860 --> 01:20:55,840
rdf introduction here you can see

1307
01:20:55,860 --> 01:20:57,230
event example

1308
01:20:57,250 --> 01:20:59,330
in the format that came up with

1309
01:20:59,650 --> 01:21:04,690
so we created a system already to process these events on the fly in real

1310
01:21:04,690 --> 01:21:09,020
time by looking at RDF event properties

1311
01:21:09,020 --> 01:21:10,500
and this is how

1312
01:21:10,540 --> 01:21:16,440
we currently formalising these properties so the subject of the event is an IDE

1313
01:21:16,440 --> 01:21:21,330
and it's typed saying it's the average temperature event having a start time and end

1314
01:21:21,330 --> 01:21:28,690
time using the well-known XML datatypes this event can have members so it's linking

1315
01:21:28,690 --> 01:21:32,230
two other events so immediately we're combining

1316
01:21:32,250 --> 01:21:35,590
real time data with historic events which happened earlier

1317
01:21:35,610 --> 01:21:38,340
and this event has its source

1318
01:21:38,770 --> 01:21:39,610
which is

1319
01:21:39,630 --> 01:21:44,360
could be a device that could be service and this event has stream this is

1320
01:21:44,360 --> 01:21:49,090
the the interesting URL if you do reference this you will get more events of

1321
01:21:49,090 --> 01:21:50,190
the same type

1322
01:21:50,230 --> 01:21:56,020
which are happening right now so this is like a subscription referencing this URL

1323
01:21:56,060 --> 01:22:02,150
and then there are some payload data from arbitrary namespaces like the pedia talking about

1324
01:22:02,150 --> 01:22:06,840
the city of nice in france and its average temperature of twenty five degrees

1325
01:22:06,840 --> 01:22:10,190
and being

1326
01:22:10,230 --> 01:22:13,000
being correlated

1327
01:22:13,000 --> 01:22:18,840
with this measurement so the temperature of twenty five is only specific for this event

1328
01:22:18,840 --> 01:22:23,940
you won and not for the next obviously so this is a data modelling issue

1329
01:22:23,940 --> 01:22:29,040
here that we're not stating that a nice always has temperature twenty five but this

1330
01:22:29,040 --> 01:22:34,060
is just one measurement of along stream of endless data

1331
01:22:34,070 --> 01:22:40,730
what is important here is that an event ontology taxonomy of types is used

1332
01:22:40,750 --> 01:22:45,570
where average temperature event is inheriting from an upper class of events which gives us

1333
01:22:45,570 --> 01:22:53,290
the timestamps for example and and which can be specialized these events support interval based

1334
01:22:53,790 --> 01:22:59,630
modeling so i can have events which are just defined on time point

1335
01:22:59,710 --> 01:23:00,860
like a tweet

1336
01:23:00,880 --> 01:23:01,840
it is

1337
01:23:01,840 --> 01:23:07,590
posted a fixed time but i can also define longo ongoing events like i one

1338
01:23:08,130 --> 01:23:10,840
discover the

1339
01:23:10,880 --> 01:23:16,130
i don't know the average twitter frequency for keyword x over the last ten minutes

1340
01:23:16,150 --> 01:23:20,380
and this event should not have just one timestamp but this event should be modelled

1341
01:23:20,380 --> 01:23:26,060
over the last ten minutes because if this event is again going into computation in

1342
01:23:26,060 --> 01:23:34,630
another event pattern i need to take care that nested operators will not to use

1343
01:23:34,630 --> 01:23:36,290
these events in the wrong order

1344
01:23:36,290 --> 01:23:40,440
so overlapping intervals are dangerous way of

1345
01:23:40,520 --> 01:23:45,060
breaking the temporal semantics so this is why these interval based events are useful way

1346
01:23:45,420 --> 01:23:50,750
of fixing your notion of what sequence which two events are strictly in sequence and

1347
01:23:50,750 --> 01:23:51,710
which are not

1348
01:23:51,730 --> 01:23:54,610
many events

1349
01:23:54,650 --> 01:23:59,360
link to each other so events that average temp vendors linking to to all the

1350
01:23:59,400 --> 01:24:02,500
events and we are linking to the stream

1351
01:24:02,520 --> 01:24:08,560
and we chose a nice name of event processing dot org which is not project

1352
01:24:08,560 --> 01:24:13,880
relevance so we're hoping will live quite awhile longer than the research project in which

1353
01:24:13,880 --> 01:24:19,520
we're doing this for we're trying to create an ontology here to be reused for

1354
01:24:19,520 --> 01:24:26,150
event processing systems so we're trying to do this in a sustainable modelling way

1355
01:24:26,170 --> 01:24:31,210
the mail this was about events

1356
01:24:31,230 --> 01:24:34,250
and next thing is how do a query those events how do i write a

1357
01:24:35,170 --> 01:24:36,400
to combine

1358
01:24:36,420 --> 01:24:39,110
two or more of these events

1359
01:24:39,110 --> 01:24:42,250
the query language should obviously fit the RDF data model

1360
01:24:42,270 --> 01:24:46,770
and we want to carry real time and historic events

1361
01:24:46,790 --> 01:24:52,250
like also supported by this paper in the event processing conference this year and we

1362
01:24:52,250 --> 01:24:57,420
want to support typical temporal operators because events are always about timestamps about happening when

1363
01:24:59,840 --> 01:25:07,190
here alan in nineteen eighty one proposed most simple relationships with all possible relationships between

1364
01:25:07,190 --> 01:25:11,860
two and a lot of time and we want to support that for a minute

1365
01:25:11,880 --> 01:25:16,960
so this is where event processing sparql comes in you've heard a lot about sparql

1366
01:25:16,980 --> 01:25:24,920
the sparql protocol and RDF query language for static data and we're extending the syntax

1367
01:25:24,920 --> 01:25:29,710
of sparql so i'm very sorry not everything in real time can be done in

1368
01:25:29,710 --> 01:25:34,650
the same syntax so these are not strictly compatible but we're trying to model this

1369
01:25:34,650 --> 01:25:40,420
so that everyone who can do sequels or can do sparql will somehow find this

1370
01:25:40,420 --> 01:25:47,460
familiar so we extend the language by these temporal operators such as sequence or temporal

1371
01:25:47,460 --> 01:25:54,440
overlap which is called equals and time windows like a number of events inside

1372
01:25:54,810 --> 01:25:57,860
the range of ten minutes for example

1373
01:25:57,880 --> 01:26:02,310
this was first discussed in that paper and we extended to support more expressive events

1374
01:26:02,310 --> 01:26:07,330
which i'm going to detail and to use the useful function from x path

1375
01:26:07,340 --> 01:26:08,440
and two

1376
01:26:08,460 --> 01:26:14,190
deal with real time and historic parts you can see a rough patch of what

1377
01:26:14,190 --> 01:26:17,040
such core example could look like so we

1378
01:26:17,110 --> 01:26:19,540
using the constructor dialect

1379
01:26:19,590 --> 01:26:23,400
where we create a new triple which is the complex event

1380
01:26:23,400 --> 01:26:27,880
and we have lots of triples going in which is the simple events so there's

1381
01:26:27,880 --> 01:26:29,690
streams of events coming in

1382
01:26:29,710 --> 01:26:32,520
and this is the output of the query

1383
01:26:34,270 --> 01:26:36,040
there is a real time part

1384
01:26:36,070 --> 01:26:38,610
which is denoted by the event keywords

1385
01:26:38,630 --> 01:26:41,690
and by these temporal operators that are newly introduced

1386
01:26:41,690 --> 01:26:47,210
and there is a historic part which is a standard sparql so here you can

1387
01:26:49,880 --> 01:26:51,590
updates from

1388
01:26:51,610 --> 01:26:53,400
from your twitter feeds

1389
01:26:53,420 --> 01:27:00,130
with fixed data from the local triple store so so you can have in one

1390
01:27:00,130 --> 01:27:01,150
thank you

1391
01:27:04,470 --> 01:27:07,970
hello everybody it's a pleasure to be here

1392
01:27:08,020 --> 01:27:10,830
i haven't been in jerusalem in thirty years

1393
01:27:10,880 --> 01:27:16,670
it's changed quite a bit of feminism change quite a bit in thirty years it's

1394
01:27:16,670 --> 01:27:21,150
quite amazing and when i was here in jerusalem the last time thirty years ago

1395
01:27:21,200 --> 01:27:25,600
i stayed in the belgian house actually lived in the house

1396
01:27:26,350 --> 01:27:29,520
it's delightful to be here again we have

1397
01:27:29,610 --> 01:27:35,490
we're having a meeting on complexity and it's a very broad meaning on complexity and

1398
01:27:35,520 --> 01:27:41,910
broad enough that they've asked me to give a talk so my subject is most

1399
01:27:41,910 --> 01:27:46,240
of you are concerned with physics economics biology you know

1400
01:27:46,260 --> 01:27:48,480
more practical kinds of complexity

1401
01:27:48,490 --> 01:27:53,330
i'd like to talk about conceptual complexity complexity of ideas

1402
01:27:53,350 --> 01:27:55,110
and the main application

1403
01:27:55,130 --> 01:28:02,400
of these concepts are is actually and metamathematics it's in talking about incompleteness and the

1404
01:28:02,400 --> 01:28:06,870
limits of the limits of possibilities of of pure for pure reason

1405
01:28:08,240 --> 01:28:11,730
that's the sort of an unusual area to complexity

1406
01:28:11,750 --> 01:28:14,910
but but it's there

1407
01:28:14,930 --> 01:28:18,010
so i think complexity is very basic concept

1408
01:28:18,050 --> 01:28:24,850
you know normally people think fundamental physics is either very small right

1409
01:28:24,930 --> 01:28:29,800
particle physics high-energy physics are also very large cosmology and in the middle we have

1410
01:28:29,800 --> 01:28:35,510
complex systems like us to represent information and computer and interestingly enough also in pure

1411
01:28:35,510 --> 01:28:39,860
mathematics in the world of pure ideas there's a lot of complexity that's my

1412
01:28:39,910 --> 01:28:45,700
my subject and also i decided that message so that i have to take home

1413
01:28:45,700 --> 01:28:47,320
messages for you too

1414
01:28:47,370 --> 01:28:54,000
things take on one is that message that pure mathematics contains irreducible infinite complexity or

1415
01:28:54,000 --> 01:28:59,530
and also that the complexity of course when it becomes a successful subject you start

1416
01:28:59,530 --> 01:29:01,720
looking back precursors

1417
01:29:01,770 --> 01:29:05,290
and i would like to let you know that light and it's in my opinion

1418
01:29:05,290 --> 01:29:07,490
is an important name

1419
01:29:07,510 --> 01:29:11,550
in complexity theory this may come as a surprise

1420
01:29:11,560 --> 01:29:14,410
so i'd like to tell you some of that story today

1421
01:29:14,420 --> 01:29:17,500
and i have two other lectures later this week

1422
01:29:21,010 --> 01:29:24,770
so this is the prehistory of complexity and the way i heard about this was

1423
01:29:24,770 --> 01:29:26,360
reading herman viola

1424
01:29:27,040 --> 01:29:33,210
is a was mathematicians student of hilbert and mathematical physicist hermann von has a number

1425
01:29:33,230 --> 01:29:37,610
of books on mathematics the number of books on physics and two books on philosophy

1426
01:29:37,630 --> 01:29:41,810
and his smaller velocity is called the open world and they were lectures he gave

1427
01:29:41,810 --> 01:29:43,950
in nineteen thirty two years

1428
01:29:43,960 --> 01:29:45,740
university in new haven

1429
01:29:45,790 --> 01:29:46,890
and there

1430
01:29:47,550 --> 01:29:51,920
talks about how important an idea of leiden it's about complexity is he says it's

1431
01:29:53,420 --> 01:29:54,640
an essential

1432
01:29:54,650 --> 01:30:01,050
concept complexity in the philosophy of science in understanding what causality is or what law

1433
01:30:01,050 --> 01:30:03,390
of of nature is or what all a of physics is

1434
01:30:03,450 --> 01:30:07,300
and the way the term about what it is very dramatic this he could

1435
01:30:07,310 --> 01:30:11,570
this idea of light member formulated like this is a

1436
01:30:11,580 --> 01:30:15,400
if you allow arbitrarily complicated laws

1437
01:30:15,410 --> 01:30:21,430
then the concept of law becomes vacuous because there's always along this is about it

1438
01:30:21,470 --> 01:30:25,180
you see that what you're trying to distinguish between data that follow the law and

1439
01:30:25,180 --> 01:30:26,800
data that is lawless

1440
01:30:26,850 --> 01:30:29,390
so you want to understand what is this concept of the law what does it

1441
01:30:29,390 --> 01:30:32,460
mean to say how can we distinguish a world which follows LA

1442
01:30:32,930 --> 01:30:35,610
from the world which doesn't follow law

1443
01:30:35,620 --> 01:30:39,370
what so what is a law what does it mean to say that something about

1444
01:30:39,440 --> 01:30:44,550
law and what happens is if you allow arbitrary complicated laws there's always the law

1445
01:30:44,560 --> 01:30:46,250
and and then the notion of laws

1446
01:30:46,310 --> 01:30:48,240
it becomes meaningless

1447
01:30:48,470 --> 01:30:53,050
so i think that's a good point now how does

1448
01:30:53,100 --> 01:30:58,360
how does life put it like it's put it a little differently like it discusses

1449
01:30:59,230 --> 01:31:03,280
in you know most alignments are very interesting man most of whose work was not

1450
01:31:03,280 --> 01:31:07,520
published during his lifetime it was found long after his death in his private papers

1451
01:31:07,520 --> 01:31:13,670
or their letters to other intellectuals like this has a a a text called the

1452
01:31:13,680 --> 01:31:15,250
school the metaphysics

1453
01:31:15,260 --> 01:31:19,150
which is not the name the landscape he didn't given name this was an editor

1454
01:31:19,150 --> 01:31:24,100
who founded more than a century after died and let's throw the disc the metaphysical

1455
01:31:24,130 --> 01:31:25,880
sixteen eighty six

1456
01:31:25,920 --> 01:31:32,630
and the items five and six paragraphs five and six of the the metaphysics lightning

1457
01:31:32,630 --> 01:31:36,850
talks about complexity he really talks about simplicity in french

1458
01:31:37,820 --> 01:31:42,750
i speak a little french it's this french is very close to modern french

1459
01:31:43,190 --> 01:31:46,560
unfortunately it's not in latin i don't know any latin you can actually go and

1460
01:31:46,560 --> 01:31:52,340
look at this text in french the paragraphs five and six on complexity and the

1461
01:31:52,340 --> 01:31:56,210
light is not actually use the word complexity but he don't use the word simplicity

1462
01:31:56,220 --> 01:32:01,310
and for complexity he says for composing

1463
01:32:01,360 --> 01:32:02,680
which i think is

1464
01:32:02,730 --> 01:32:04,670
you know the opposite of sam

1465
01:32:04,680 --> 01:32:08,770
the sampler is for composite so that is

1466
01:32:08,780 --> 01:32:10,580
translated as complexity

1467
01:32:10,590 --> 01:32:14,170
but if you look at the original text i think it's important to say well

1468
01:32:14,170 --> 01:32:15,940
that's what is so

1469
01:32:15,950 --> 01:32:18,920
so one idea of alignments

1470
01:32:18,930 --> 01:32:24,370
the idea of life it is is is very simple and here how it goes

1471
01:32:24,410 --> 01:32:29,800
let's take a piece of paper and with a quill pen just put splattered with

1472
01:32:29,800 --> 01:32:32,190
things so you have a finite set of points

1473
01:32:32,200 --> 01:32:36,930
on the plane on this sheet of paper which are your experimental data

1474
01:32:37,900 --> 01:32:42,510
and now the question is what is it seems me to say that these points

1475
01:32:42,510 --> 01:32:43,990
follow or

1476
01:32:43,990 --> 01:32:50,610
let's go to the next valence girth

1477
01:32:50,670 --> 01:32:55,590
and cages low valence that sometimes called degree

1478
01:32:55,640 --> 01:33:00,240
four valency which we call it fearless

1479
01:33:01,220 --> 01:33:03,330
so what is of valence

1480
01:33:04,670 --> 01:33:09,210
o vertex valence of the vertex the number

1481
01:33:09,260 --> 01:33:11,430
of edges

1482
01:33:12,570 --> 01:33:18,170
that incident with that vertex where more precisely or

1483
01:33:18,190 --> 01:33:20,350
intuitively what we do

1484
01:33:20,360 --> 01:33:22,120
think of

1485
01:33:22,130 --> 01:33:24,450
during the little circles

1486
01:33:24,480 --> 01:33:29,610
around each vertex and then just count the number of edges emanating from the vertex

1487
01:33:29,610 --> 01:33:30,950
and cutting that

1488
01:33:32,590 --> 01:33:34,710
there's the valence

1489
01:33:34,840 --> 01:33:38,020
four simple graphs there is no problem with that

1490
01:33:38,050 --> 01:33:40,020
but if the graph is not simple

1491
01:33:42,090 --> 01:33:46,350
we may have problems that may show you here

1492
01:33:48,200 --> 01:33:49,680
how we call that

1493
01:33:49,760 --> 01:33:53,670
in this case

1494
01:33:53,710 --> 01:34:02,420
for instance in this case

1495
01:34:02,430 --> 01:34:04,250
four vertex one

1496
01:34:05,710 --> 01:34:08,740
according to this rule

1497
01:34:08,860 --> 01:34:13,640
the very

1498
01:34:13,650 --> 01:34:15,060
it would be

1499
01:34:15,070 --> 01:34:19,320
one two

1500
01:34:20,140 --> 01:34:21,900
four five

1501
01:34:21,920 --> 01:34:26,250
so the valence of one five

1502
01:34:26,450 --> 01:34:30,590
but we not

1503
01:34:30,600 --> 01:34:32,690
interested in this

1504
01:34:34,000 --> 01:34:36,730
situation right now because we're talking about

1505
01:34:36,740 --> 01:34:38,880
simple graph

1506
01:34:38,900 --> 01:34:43,860
lowercase delta g denotes the minimum of valence

1507
01:34:44,850 --> 01:34:45,850
upper case

1508
01:34:45,870 --> 01:34:47,100
that the g

1509
01:34:47,110 --> 01:34:50,350
you knows the maximal balance

1510
01:34:50,360 --> 01:34:51,510
over graphs

1511
01:34:51,570 --> 01:34:56,570
this means for instance in this case the minimum balances to and maximum analysis three

1512
01:34:56,570 --> 01:34:59,740
for this

1513
01:35:04,680 --> 01:35:09,430
the two values is the minimum and maximum the same

1514
01:35:09,550 --> 01:35:12,040
this means that all the edges of the same

1515
01:35:12,060 --> 01:35:16,460
and the graph in this case is called regular

1516
01:35:16,470 --> 01:35:18,860
for k regular

1517
01:35:20,140 --> 01:35:22,990
we've seen already some examples of regular graphs

1518
01:35:23,000 --> 01:35:25,750
complete graph is regular

1519
01:35:25,790 --> 01:35:27,710
cycle is regular

1520
01:35:27,710 --> 01:35:31,400
complete bipartite graph is regular if and it was an

1521
01:35:33,680 --> 01:35:38,450
other examples which are not regular for instance b and partha advertisements if n is

1522
01:35:38,450 --> 01:35:43,950
greater than two complete graphs complete bipartite graph is an different

1523
01:35:43,960 --> 01:35:45,880
they are not regular

1524
01:35:45,890 --> 01:35:50,730
so one vaillant two valence graphs are very simple

1525
01:35:50,770 --> 01:35:53,350
the first example

1526
01:35:53,400 --> 01:35:56,030
of let's a nontrivial

1527
01:35:56,030 --> 01:36:03,380
regular graphs are trivalent graphs or sometimes called cubic graphs were realistic was three

1528
01:36:03,400 --> 01:36:08,010
for instance here we have an example of a trivalent graphs

1529
01:36:08,020 --> 01:36:08,910
so each

1530
01:36:10,870 --> 01:36:13,360
valence three right

1531
01:36:13,370 --> 01:36:20,920
and this for instance in this particular case there's the graph

1532
01:36:23,350 --> 01:36:25,140
of the prison

1533
01:36:25,160 --> 01:36:28,210
triangular prisms

1534
01:36:28,380 --> 01:36:33,980
any questions

1535
01:36:33,990 --> 01:36:36,360
OK go

1536
01:36:36,420 --> 01:36:38,280
so god

1537
01:36:38,320 --> 01:36:39,790
g of g

1538
01:36:39,830 --> 01:36:41,260
of graph g

1539
01:36:41,290 --> 01:36:43,830
is the number of vertices

1540
01:36:43,850 --> 01:36:45,850
of the shortest cycle in g

1541
01:36:45,860 --> 01:36:49,070
so if g has no cycles

1542
01:36:49,080 --> 01:36:55,690
it's good is infinity

1543
01:36:58,640 --> 01:36:59,430
let me

1544
01:36:59,480 --> 01:37:07,390
maybe you some examples first

1545
01:37:09,170 --> 01:37:10,740
let's look at this

1546
01:37:10,840 --> 01:37:12,490
is here

1547
01:37:12,560 --> 01:37:14,850
so what would be

1548
01:37:14,920 --> 01:37:18,640
because of this graph here

1549
01:37:23,780 --> 01:37:28,950
we know what the right of the graph is

1550
01:37:30,830 --> 01:37:32,600
maybe this kind of graph

1551
01:37:32,630 --> 01:37:34,530
it's bipartite graph

1552
01:37:34,570 --> 01:37:37,080
it's a living off of configuration

1553
01:37:37,100 --> 01:37:39,550
has it occurred cannot be

1554
01:37:39,550 --> 01:37:43,100
must be sixty six

1555
01:37:43,120 --> 01:37:45,030
the other

1556
01:37:50,420 --> 01:37:52,990
are designed graph

1557
01:37:52,990 --> 01:37:57,490
you you get you can do that over the weekend

1558
01:38:06,860 --> 01:38:09,200
next family of graphs cages

1559
01:38:09,210 --> 01:38:14,290
what is a g cage

1560
01:38:15,490 --> 01:38:19,890
it is defined in the following way

1561
01:38:19,940 --> 01:38:23,090
we're talking about prevailing graphs of cubic graphs

1562
01:38:23,100 --> 01:38:25,090
that has girth g

1563
01:38:25,330 --> 01:38:28,850
they have the least number of vertices

1564
01:38:28,870 --> 01:38:32,790
among the graphs satisfying conditions one and two

1565
01:38:32,790 --> 01:38:35,030
such a graph is called good

1566
01:38:35,030 --> 01:38:37,210
so let me in this section

1567
01:38:37,290 --> 01:38:42,110
hoping to convince you that this is why there is essentially a goldmine

1568
01:38:42,130 --> 01:38:44,380
for two reasons one is

1569
01:38:44,390 --> 01:38:45,810
it increases the

1570
01:38:45,810 --> 01:38:51,330
so might be surprised advertising so so virtuous cycle

1571
01:38:51,350 --> 01:38:55,030
so that the search and i talked about brand that's

1572
01:38:55,050 --> 01:38:57,850
and i want to share with you is the results of the study we did

1573
01:38:57,850 --> 01:38:59,120
this very interesting

1574
01:38:59,140 --> 01:39:02,410
it actually shows me as to what this talk to you about

1575
01:39:02,430 --> 01:39:03,270
in this system the

1576
01:39:04,480 --> 01:39:07,830
are much more related than anybody

1577
01:39:07,830 --> 01:39:09,810
so here is how it goes

1578
01:39:09,830 --> 01:39:13,780
this is working with the company direct

1579
01:39:13,800 --> 01:39:20,480
people are shown these kinds of on properties like finance yahoo mail my

1580
01:39:20,550 --> 01:39:24,320
so imagine what we normally do

1581
01:39:24,340 --> 01:39:25,150
which is

1582
01:39:25,170 --> 01:39:26,190
if you that

1583
01:39:26,200 --> 01:39:29,960
i think you actually ask for example ask questions

1584
01:39:30,040 --> 01:39:32,850
you feel it is that you know how to

1585
01:39:32,860 --> 01:39:38,960
that's what it is and what is your favourite and these are the objects the

1586
01:39:38,970 --> 01:39:40,210
respectable numbers mean

1587
01:39:40,220 --> 01:39:41,630
people who so these

1588
01:39:41,640 --> 01:39:45,520
people who were in the the members of the police on you

1589
01:39:45,560 --> 01:39:46,750
this list

1590
01:39:46,930 --> 01:39:51,000
so that's how try to establish because this is the stuff works

1591
01:39:51,020 --> 01:39:53,010
but what i'm about to show you

1592
01:39:53,020 --> 01:39:57,580
this is good numbers but i'm about to show you actually blows my mind

1593
01:39:57,830 --> 01:40:01,090
i'm about to show is we decided to extend this to a bit for

1594
01:40:01,210 --> 01:40:03,410
so we have a a group of people who so that we have a group

1595
01:40:03,410 --> 01:40:08,110
of people we know that in the absence settlers continued to follow the behaviour of

1596
01:40:08,110 --> 01:40:12,020
a week later and see what they want search

1597
01:40:12,030 --> 01:40:15,910
so sure if you want to search sixty percent

1598
01:40:15,930 --> 01:40:20,890
more likely to search on that category just because they saw the

1599
01:40:20,910 --> 01:40:25,030
sixty percent to begin but it gets

1600
01:40:25,030 --> 01:40:29,890
forty percent more clicks on algorithmic results

1601
01:40:29,920 --> 01:40:34,010
two hundred fifty percent forty nine percent more click-through

1602
01:40:34,050 --> 01:40:38,540
on sponsored links that's what makes someone who is

1603
01:40:38,560 --> 01:40:42,430
two and a half times more likely to click on

1604
01:40:42,460 --> 01:40:43,910
one is sponsored links

1605
01:40:43,920 --> 01:40:47,020
because of graphical up to a week before

1606
01:40:47,040 --> 01:40:51,820
i don't want anyone in the world basically get ninety one percent

1607
01:40:51,870 --> 01:40:56,780
more activity that matters meaning conversions things like that as the

1608
01:40:56,890 --> 01:41:01,390
so this is very powerful ever again market

1609
01:41:01,420 --> 01:41:05,550
right well i have no idea that i just think about i spend a particular

1610
01:41:05,620 --> 01:41:06,600
i k

1611
01:41:06,610 --> 01:41:09,550
i don't think about the fact that when i spent i could actually enhance my

1612
01:41:09,550 --> 01:41:11,520
spent by a factor of two and

1613
01:41:11,560 --> 01:41:16,510
if i just thought about putting up some branding stuff to go with my search

1614
01:41:16,560 --> 01:41:21,340
that's not because the data that's what the markets had as it head

1615
01:41:21,350 --> 01:41:26,460
companies like extended to benefit a lot because you can you can make whole story

1616
01:41:26,460 --> 01:41:27,500
more complete

1617
01:41:27,520 --> 01:41:29,900
again all of this is based on the fact that

1618
01:41:29,920 --> 01:41:33,130
you can learn lot from the data

1619
01:41:33,150 --> 01:41:35,550
so we talk about advertising

1620
01:41:35,560 --> 01:41:38,230
after shameless advertising break

1621
01:41:38,320 --> 01:41:39,480
we are hiring people

1622
01:41:39,500 --> 01:41:41,370
so i going to the outside

1623
01:41:41,390 --> 01:41:44,130
if you are interested in your mind

1624
01:41:44,150 --> 01:41:48,250
they start to time

1625
01:41:48,350 --> 01:41:52,290
this should be

1626
01:41:52,340 --> 01:41:57,860
and the social media for the next twenty five

1627
01:41:57,870 --> 01:42:00,390
well you know what this means

1628
01:42:00,420 --> 01:42:03,300
but basically there is a huge change in the way

1629
01:42:03,310 --> 01:42:10,070
something new is happening something very different and actually extremely data mining really

1630
01:42:10,080 --> 01:42:12,930
example social media blog

1631
01:42:12,950 --> 01:42:17,410
sharing sites like flickr photo social search

1632
01:42:17,430 --> 01:42:17,960
i was about

1633
01:42:17,970 --> 01:42:21,570
some of these migrants we answers and so forth

1634
01:42:21,580 --> 01:42:24,100
web communities groups

1635
01:42:24,110 --> 01:42:26,650
the ocean

1636
01:42:26,670 --> 01:42:28,050
like youtube

1637
01:42:31,530 --> 01:42:33,190
and what's happening is

1638
01:42:33,210 --> 01:42:40,220
it's it's a new culture holding it's very compelling this set of new users are

1639
01:42:40,230 --> 01:42:42,110
using its

1640
01:42:42,130 --> 01:42:46,760
you know a lot about two point all which enables these things cultural participation user-generated

1641
01:42:47,680 --> 01:42:52,210
wisdom of the crowds to talk about some of them

1642
01:42:52,230 --> 01:42:54,050
and really moving beyond

1643
01:42:54,080 --> 01:42:55,310
right in all publishing

1644
01:42:55,310 --> 01:42:58,530
which states that if you have

1645
01:42:58,670 --> 01:43:02,080
as a strictly positive probability distribution

1646
01:43:02,100 --> 01:43:05,360
it's an arbitrary otherwise

1647
01:43:05,430 --> 01:43:06,980
probability distribution

1648
01:43:06,990 --> 01:43:10,800
the effects of all x

1649
01:43:11,680 --> 01:43:12,500
it is

1650
01:43:12,510 --> 01:43:14,810
distribution satisfies

1651
01:43:14,830 --> 01:43:20,560
the conditional independence statements implied by graph separation in the given graph

1652
01:43:20,580 --> 01:43:24,320
then it also factorizes according

1653
01:43:24,370 --> 01:43:26,480
what that means

1654
01:43:26,540 --> 01:43:35,300
if you have a graph like this

1655
01:43:35,360 --> 01:43:36,800
a b

1656
01:43:36,810 --> 01:43:38,690
c and d

1657
01:43:46,030 --> 01:43:47,450
if i give them

1658
01:43:47,470 --> 01:43:51,330
probability distribution

1659
01:43:54,650 --> 01:43:58,940
conditional independence statements implied by graph separation you for example

1660
01:44:00,070 --> 01:44:03,130
it is independent of the

1661
01:44:03,260 --> 01:44:05,200
even see right

1662
01:44:05,270 --> 01:44:08,170
eight is independent of the given c

1663
01:44:08,230 --> 01:44:13,510
because every path from a to b has to go to sea

1664
01:44:13,550 --> 01:44:17,920
this one conditional independence statements that directly

1665
01:44:17,980 --> 01:44:21,050
you can actually read from this graph

1666
01:44:21,100 --> 01:44:23,150
from graphs to play

1667
01:44:23,190 --> 01:44:27,660
another one is a is independent of the union

1668
01:44:29,450 --> 01:44:32,600
sign of b

1669
01:44:32,620 --> 01:44:34,380
given c

1670
01:44:34,390 --> 01:44:37,540
you need be

1671
01:44:37,640 --> 01:44:39,350
another one is

1672
01:44:41,800 --> 01:44:43,900
you know a

1673
01:44:44,040 --> 01:44:46,820
is condition depends on the

1674
01:44:50,780 --> 01:44:56,510
you can lead to a bunch of conditional independence statements corresponding to these

1675
01:44:56,550 --> 01:44:58,650
what he's doing says

1676
01:44:58,740 --> 01:45:00,650
is that if i have

1677
01:45:01,880 --> 01:45:03,830
probability distribution

1678
01:45:04,640 --> 01:45:07,120
respects the conditional

1679
01:45:07,130 --> 01:45:14,060
independence state as read from graph separation in the graph e

1680
01:45:14,150 --> 01:45:16,870
then the distribution can be written

1681
01:45:16,910 --> 01:45:22,160
as the product of functions over cliques of the

1682
01:45:22,220 --> 01:45:24,410
may seem a little bit abstract

1683
01:45:24,420 --> 01:45:31,150
but you will see why this is so important

1684
01:45:31,180 --> 01:45:33,750
well can look at the proof of this

1685
01:45:33,790 --> 01:45:39,900
before explaining what is important that should prove interesting

1686
01:45:45,490 --> 01:45:48,310
the three we use something called the using version

1687
01:45:50,070 --> 01:45:52,150
are made using version

1688
01:45:52,190 --> 01:45:55,170
which is this statement

1689
01:45:55,180 --> 01:45:57,200
the technical but still

1690
01:45:57,290 --> 01:46:02,330
i find it interesting that you can still write the proof of concept for a

1691
01:46:03,390 --> 01:46:04,870
the single slide

1692
01:46:04,880 --> 01:46:06,080
so this is

1693
01:46:06,110 --> 01:46:07,030
the image is

1694
01:46:07,040 --> 01:46:09,920
inversion lemma

1695
01:46:10,920 --> 01:46:13,640
the objects we have

1696
01:46:16,810 --> 01:46:18,030
the set

1697
01:46:19,580 --> 01:46:20,430
you should

1698
01:46:20,480 --> 01:46:22,870
think of

1699
01:46:22,900 --> 01:46:26,810
the collection of the run by the

1700
01:46:26,820 --> 01:46:30,530
a b and c are just subset of the rule of law

1701
01:46:30,580 --> 01:46:34,540
such that b is a c c e

1702
01:46:36,270 --> 01:46:37,820
this function

1703
01:46:37,880 --> 01:46:39,620
is the function that

1704
01:46:39,630 --> 01:46:42,030
from the power set of s

1705
01:46:42,040 --> 01:46:44,070
with the real ones

1706
01:46:44,230 --> 01:46:48,120
it's the powerset of the set

1707
01:46:48,120 --> 01:46:54,130
so what's the powerset of the set of nodes

1708
01:46:54,140 --> 01:46:58,680
yes the powerset of the set of all subsets

1709
01:47:00,120 --> 01:47:03,470
so for every subset of

1710
01:47:03,500 --> 01:47:04,800
i will

1711
01:47:04,820 --> 01:47:08,640
associate really

1712
01:47:12,590 --> 01:47:14,440
well in this case

1713
01:47:14,450 --> 01:47:18,440
it is well in this case you have a finite set up here

1714
01:47:18,490 --> 01:47:19,910
in this case

1715
01:47:19,920 --> 01:47:23,010
that's the power set defined just

1716
01:47:23,060 --> 01:47:24,390
all possible

1717
01:47:25,490 --> 01:47:30,340
it's not sufficient fuzzy

1718
01:47:30,800 --> 01:47:34,910
this is just the powerset

1719
01:47:39,570 --> 01:47:43,160
we going to define this function is a function that assigns

1720
01:47:43,270 --> 01:47:47,440
every element the person

1721
01:47:47,450 --> 01:47:48,810
so therefore

1722
01:47:48,860 --> 01:47:50,590
this function can be

1723
01:47:50,670 --> 01:47:54,510
applied to lightweight can be applied to be can be applied to see right

1724
01:47:54,510 --> 01:47:59,230
because this function can be applied to any subset of s

1725
01:47:59,240 --> 01:48:00,530
but for us

1726
01:48:00,550 --> 01:48:05,790
also these functions actually yes it probably from itself

1727
01:48:05,840 --> 01:48:07,770
it's actually logo

1728
01:48:07,810 --> 01:48:10,410
the negative logarithm of the like

1729
01:48:10,420 --> 01:48:12,480
the marginal probability

1730
01:48:14,610 --> 01:48:15,870
continue to

1731
01:48:16,050 --> 01:48:18,700
she will be fined as

1732
01:48:18,700 --> 01:48:24,220
he which is located in this case the finance just eleven he

1733
01:48:24,230 --> 01:48:27,020
and compute the in the some of the case

1734
01:48:27,030 --> 01:48:30,490
of the case where b is not the

1735
01:48:30,530 --> 01:48:31,990
so basically

1736
01:48:33,760 --> 01:48:35,920
you can also proved this lemma is not

1737
01:48:36,080 --> 01:48:37,850
people with the

1738
01:48:37,910 --> 01:48:41,500
let's just take forever for the

1739
01:48:41,550 --> 01:48:44,660
this is what this is saying is that

1740
01:48:44,670 --> 01:48:47,970
i can write these function of the time set

1741
01:48:48,020 --> 01:48:50,720
as as the sum of

1742
01:48:50,730 --> 01:48:51,960
this function

1743
01:48:52,030 --> 01:48:53,830
of the

1744
01:48:56,700 --> 01:48:59,880
with the proper signed for

1745
01:48:59,910 --> 01:49:02,910
the evolution of the function this subset

1746
01:49:02,960 --> 01:49:04,270
this is sign

1747
01:49:06,370 --> 01:49:12,110
the kind of knowledge of the difference is that

1748
01:49:13,270 --> 01:49:16,720
now what we're going to do this to show that whenever

1749
01:49:16,770 --> 01:49:18,550
we have

1750
01:49:19,680 --> 01:49:22,110
whenever he is not a clique

1751
01:49:22,130 --> 01:49:25,660
whenever the set b is not unique

1752
01:49:25,700 --> 01:49:28,270
we will have

1753
01:49:30,210 --> 01:49:33,380
this function is used

1754
01:49:33,440 --> 01:49:38,080
in other words it is sum over all subsets

1755
01:49:38,140 --> 01:49:41,690
and the sum for all subsets are not logically

1756
01:49:41,730 --> 01:49:43,200
what is zero

1757
01:49:43,210 --> 01:49:45,170
so the resulting sum

1758
01:49:45,180 --> 01:49:48,730
effective so we only over the

1759
01:49:48,770 --> 01:49:51,700
well suited the the clique is a subset

1760
01:49:52,980 --> 01:49:56,460
two types of subsets of variables given graph

1761
01:49:56,500 --> 01:49:59,380
you have to all subsets form a clique

1762
01:49:59,440 --> 01:50:02,250
and all subsets of items that do not

1763
01:50:03,410 --> 01:50:06,940
so what are going to see is that when we evaluate the function

1764
01:50:06,990 --> 01:50:10,410
in all those sets of another clique we get

1765
01:50:10,420 --> 01:50:13,930
so what remains is only

1766
01:50:13,980 --> 01:50:15,660
so sorry

1767
01:50:16,830 --> 01:50:19,290
the greeks

1768
01:50:19,310 --> 01:50:20,460
the conditional

1769
01:50:20,460 --> 01:50:26,510
independence state so let's see what the conditional independence day let's assume that there exist

1770
01:50:26,510 --> 01:50:29,450
two nodes in b the not connected

1771
01:50:29,560 --> 01:50:34,110
since we assume it back on traditional assumed to be is not case

1772
01:50:34,120 --> 01:50:36,700
it's just assume that is not

1773
01:50:36,700 --> 01:50:39,160
the subset of features

1774
01:50:39,180 --> 01:50:42,180
and then he choose

1775
01:50:42,230 --> 01:50:46,910
the words basically for me that was to express that a particular

1776
01:50:48,140 --> 01:50:49,750
and then he says something

1777
01:50:49,750 --> 01:50:51,790
bad good o

1778
01:50:51,830 --> 01:50:53,750
if i may not know basically

1779
01:50:53,760 --> 01:50:55,440
becomes a sort of

1780
01:50:57,190 --> 01:50:58,890
so this is essentially the model

1781
01:50:58,940 --> 01:51:00,330
decision among how

1782
01:51:00,350 --> 01:51:01,140
how this

1783
01:51:01,950 --> 01:51:03,230
it's not like

1784
01:51:03,310 --> 01:51:07,620
but of course is the simplified model this in case you can't catch for example

1785
01:51:07,700 --> 01:51:12,320
that these two things you can catch sometimes people talk about features relationship two features

1786
01:51:12,320 --> 01:51:13,390
for example you can see

1787
01:51:13,490 --> 01:51:14,840
the the the

1788
01:51:14,930 --> 01:51:18,290
the lens of his camera is still too close to the

1789
01:51:18,360 --> 01:51:20,400
to view fund

1790
01:51:20,440 --> 01:51:22,310
so he's talking about two things

1791
01:51:22,320 --> 01:51:26,240
and i think this is not being capturing is it's the

1792
01:51:26,260 --> 01:51:27,210
it's a degree

1793
01:51:27,260 --> 01:51:31,190
sometimes i really hate sex i mean something maybe to say this is

1794
01:51:31,260 --> 01:51:33,780
fine but you can improve certain aspects

1795
01:51:33,820 --> 01:51:37,320
but that's you can't get

1796
01:51:37,330 --> 01:51:41,690
so let me end this talk about opinion task hardly put these things

1797
01:51:41,770 --> 01:51:45,780
people have been doing into that model came to the them world

1798
01:51:45,890 --> 01:51:48,710
so that using spearing doing the first thing is

1799
01:51:48,720 --> 01:51:54,180
what is called sentiment analysis which is a canopy researchers been doing that for

1800
01:51:54,230 --> 01:51:56,200
a couple of years

1801
01:51:56,330 --> 01:52:00,890
so what i'm doing is basically tried to classify each document each review is a

1802
01:52:00,890 --> 01:52:03,300
positive review always an active view

1803
01:52:03,310 --> 01:52:05,770
o sometimes they have neutral as well

1804
01:52:05,780 --> 01:52:09,160
the classes so essentially classification problem

1805
01:52:09,420 --> 01:52:11,980
the cost of positive negative and neutral

1806
01:52:12,050 --> 01:52:15,210
so what is assumption assumption basic says

1807
01:52:15,280 --> 01:52:17,890
he focusing on a single object

1808
01:52:17,910 --> 01:52:20,950
so this document has been focusing on the same object

1809
01:52:20,960 --> 01:52:23,560
and they come from a single person

1810
01:52:23,700 --> 01:52:28,410
if he's talking about the model object they can't do this can do this

1811
01:52:28,450 --> 01:52:29,560
and then this

1812
01:52:29,570 --> 01:52:30,680
this is sort of

1813
01:52:30,780 --> 01:52:31,720
why this is

1814
01:52:31,740 --> 01:52:33,540
is in the model because

1815
01:52:33,590 --> 01:52:36,230
essentially the opinions about objects

1816
01:52:36,460 --> 01:52:39,760
this is the top the the the root node of the tree

1817
01:52:39,770 --> 01:52:43,580
so the centre castigation essentially try to find opening

1818
01:52:43,600 --> 01:52:45,200
about objects of

1819
01:52:45,260 --> 01:52:49,020
because we see also the object is feature

1820
01:52:49,080 --> 01:52:53,330
and then analyse the sentence level we've been dealing with sentences so this is something

1821
01:52:53,330 --> 01:52:54,580
sort of

1822
01:52:54,630 --> 01:52:57,480
sort of floating somewhere

1823
01:52:57,490 --> 01:52:59,680
it's not really

1824
01:52:59,720 --> 01:53:04,520
the feeling the model because it's itself it's sort of medium medium level

1825
01:53:04,530 --> 01:53:06,880
OK so this doesn't really tell you

1826
01:53:06,890 --> 01:53:10,090
what is it is and this is an active

1827
01:53:10,150 --> 01:53:11,940
the negative about what

1828
01:53:11,990 --> 01:53:13,410
negative what

1829
01:53:15,210 --> 01:53:18,030
so the issue here is

1830
01:53:18,100 --> 01:53:19,690
both of these things

1831
01:53:20,200 --> 01:53:25,310
is that the really tell you people like what people like or dislike

1832
01:53:25,330 --> 01:53:28,460
there were people like dislike

1833
01:53:28,510 --> 01:53:32,600
so now we we we go be further to be further there is actually what

1834
01:53:32,610 --> 01:53:34,160
it called the feature level

1835
01:53:34,180 --> 01:53:36,700
we go to the future

1836
01:53:36,820 --> 01:53:39,540
then what other tasks one of the task

1837
01:53:39,570 --> 01:53:42,310
so if you have obviously this fitting the model

1838
01:53:42,480 --> 01:53:44,090
so it has to be a success

1839
01:53:45,180 --> 01:53:47,020
and extract features

1840
01:53:47,030 --> 01:53:48,740
like extract features

1841
01:53:48,770 --> 01:53:54,050
and this is a difficult problem information extraction extraction so the second thing is if

1842
01:53:54,050 --> 01:53:55,220
you got the features

1843
01:53:55,240 --> 01:53:56,710
now what is

1844
01:53:56,720 --> 01:53:57,950
the opinion

1845
01:53:57,970 --> 01:54:00,580
what is your opinion on that particular feature

1846
01:54:00,660 --> 01:54:01,810
pretty feature

1847
01:54:01,890 --> 01:54:02,940
that of course

1848
01:54:02,960 --> 01:54:04,200
we have an to

1849
01:54:04,560 --> 01:54:06,760
pretty difficult task discard

1850
01:54:06,770 --> 01:54:07,730
the synapse

1851
01:54:07,740 --> 01:54:11,600
how do you know something is and so

1852
01:54:11,680 --> 01:54:15,940
because the next they wanted to us right because i remember when i first flight

1853
01:54:15,950 --> 01:54:19,800
we do the same you have to do some the summary you can't just let

1854
01:54:19,800 --> 01:54:20,690
people read it

1855
01:54:20,700 --> 01:54:25,960
so i did some reunion nordisk nonsense otherwise

1856
01:54:26,060 --> 01:54:28,760
picture the photo and image though

1857
01:54:28,770 --> 01:54:32,260
if you put in a different place and and i'm sure you've gonna laugh at

1858
01:54:33,880 --> 01:54:37,940
so in this particular work we focus on only task two

1859
01:54:37,940 --> 01:54:39,310
task two

1860
01:54:39,360 --> 01:54:40,680
so we assume

1861
01:54:40,690 --> 01:54:42,630
task one has been done

1862
01:54:42,720 --> 01:54:44,560
it's been so

1863
01:54:44,670 --> 01:54:46,310
if you're interested

1864
01:54:46,360 --> 01:54:47,830
you can take a look at the

1865
01:54:47,920 --> 01:54:52,090
how do you do the task one one

1866
01:54:52,100 --> 01:54:57,710
so what do we mean by summary apologising to some people are is in this

1867
01:54:57,710 --> 01:54:59,910
slide because this talk a few times

1868
01:54:59,920 --> 01:55:01,190
in various places

1869
01:55:01,210 --> 01:55:07,610
so what i mean by summary in this case in this case

1870
01:55:07,630 --> 01:55:08,700
if you read this

1871
01:55:08,710 --> 01:55:12,310
amazon review i did a lot of research last year before i bought this camera

1872
01:55:12,310 --> 01:55:14,070
kind person behind my

1873
01:55:14,170 --> 01:55:18,440
eleven mekong blah blah they're going to italy and something smaller and digital

1874
01:55:18,550 --> 01:55:22,440
and they say a picture coming out of this camera some amazing all the feature

1875
01:55:22,440 --> 01:55:24,690
takes great pictures most of the time and was digital

1876
01:55:25,080 --> 01:55:27,520
i don't want to waste your film in the picture

1877
01:55:27,530 --> 01:55:31,030
it doesn't come up something so we read this hosting

1878
01:55:31,040 --> 01:55:36,390
i mean who who cares where you're going to not so what interesting basically that's

1879
01:55:36,390 --> 01:55:39,740
only two words here which is terribly important

1880
01:55:39,860 --> 01:55:41,860
the first part we'll be

1881
01:55:41,920 --> 01:55:45,380
the pictures coming out of this thing is really amazing

1882
01:55:45,420 --> 01:55:48,660
OK so this is the part is terribly important and that of course to also

1883
01:55:51,890 --> 01:55:54,650
so how do we extract is two words

1884
01:55:54,660 --> 01:55:56,340
and then figure out

1885
01:55:56,350 --> 01:55:57,470
people like

1886
01:55:57,480 --> 01:55:59,060
in this case

1887
01:55:59,290 --> 01:56:01,100
people like

1888
01:56:01,190 --> 01:56:02,700
so that you can

1889
01:56:02,710 --> 01:56:04,170
producer summary

1890
01:56:04,180 --> 01:56:06,800
w summary summary of the like

1891
01:56:06,810 --> 01:56:09,520
for the picture i say twelve people like

1892
01:56:09,520 --> 01:56:15,060
we'll discuss velocities and accelerations

1893
01:56:15,100 --> 01:56:17,390
i'll start with something simple

1894
01:56:17,400 --> 01:56:19,310
i have a

1895
01:56:19,380 --> 01:56:21,950
motion of an object along the straight line

1896
01:56:21,960 --> 01:56:24,480
recall that one-dimensional motion

1897
01:56:24,590 --> 01:56:27,900
and i'll tell you that the object is here at time t one

1898
01:56:27,930 --> 01:56:31,230
time t two it's here at time t three is there

1899
01:56:31,290 --> 01:56:34,320
ninety four it here and the time t five it's back

1900
01:56:34,360 --> 01:56:35,950
when it was it t one

1901
01:56:36,000 --> 01:56:37,380
and here you see the

1902
01:56:37,380 --> 01:56:39,160
positions in x

1903
01:56:40,130 --> 01:56:41,200
it is

1904
01:56:41,220 --> 01:56:43,070
located at that moment

1905
01:56:43,080 --> 01:56:46,470
in time

1906
01:56:46,530 --> 01:56:49,000
i will define this

1907
01:56:49,010 --> 01:56:51,530
to be the increasing value of x

1908
01:56:51,540 --> 01:56:56,240
it's my free choice but i've chosen this now

1909
01:56:57,180 --> 01:56:58,960
we will introduce

1910
01:56:58,970 --> 01:57:02,170
what we call the average velocity

1911
01:57:02,180 --> 01:57:03,750
i could borrow over it

1912
01:57:03,760 --> 01:57:05,400
that stands for average

1913
01:57:05,460 --> 01:57:07,780
between time warner time t two

1914
01:57:07,820 --> 01:57:10,140
that we define in physics

1915
01:57:10,140 --> 01:57:12,510
at x s ninety two

1916
01:57:12,570 --> 01:57:13,690
mine x

1917
01:57:13,690 --> 01:57:15,130
at time t one

1918
01:57:15,160 --> 01:57:16,350
divided by

1919
01:57:16,500 --> 01:57:18,660
two minus the one

1920
01:57:18,710 --> 01:57:20,820
that is our definition

1921
01:57:20,830 --> 01:57:22,630
in our case

1922
01:57:22,690 --> 01:57:26,630
because of the way that i defined the increasing value of ax

1923
01:57:26,630 --> 01:57:28,080
this is larger

1924
01:57:28,130 --> 01:57:29,770
and zero

1925
01:57:31,240 --> 01:57:32,860
if i take

1926
01:57:32,910 --> 01:57:33,900
the average

1927
01:57:33,910 --> 01:57:36,710
velocity between t one and t five

1928
01:57:36,740 --> 01:57:39,660
that would be zero because they are the same

1929
01:57:41,570 --> 01:57:43,130
upstairs is zero

1930
01:57:43,180 --> 01:57:44,970
if i had

1931
01:57:45,020 --> 01:57:46,410
chosen t four

1932
01:57:46,490 --> 01:57:50,410
and t two average velocity between time t two and t four

1933
01:57:50,460 --> 01:57:51,520
you would have seen

1934
01:57:51,520 --> 01:57:52,800
that that

1935
01:57:52,820 --> 01:57:54,770
is negative because the upstairs

1936
01:57:57,630 --> 01:58:02,410
notice that i haven't told you where i choose my zero on my x axis

1937
01:58:03,750 --> 01:58:07,850
unimportant for the average velocity it makes no difference

1938
01:58:09,050 --> 01:58:10,940
if i had chosen

1939
01:58:10,960 --> 01:58:12,300
this to be the

1940
01:58:12,320 --> 01:58:14,460
direction of increasing access

1941
01:58:15,240 --> 01:58:17,270
of course the signs would flip

1942
01:58:17,290 --> 01:58:18,930
then this would be negative

1943
01:58:18,930 --> 01:58:21,080
and and this would have been positive

1944
01:58:21,120 --> 01:58:23,890
so the direction that you are free to choose

1945
01:58:23,930 --> 01:58:25,560
determines the science

1946
01:58:25,580 --> 01:58:28,180
the location where you put your zero

1947
01:58:28,240 --> 01:58:30,370
is not important but signs

1948
01:58:30,390 --> 01:58:32,240
in physics do matter

1949
01:58:32,300 --> 01:58:34,200
signs are important

1950
01:58:34,210 --> 01:58:37,550
whether you owe me money or all you money

1951
01:58:37,560 --> 01:58:39,810
the difference is only a minus sign

1952
01:58:39,830 --> 01:58:44,030
but i think it's important for you

1953
01:58:44,140 --> 01:58:46,200
now i will give you

1954
01:58:46,240 --> 01:58:47,610
not only

1955
01:58:47,670 --> 01:58:49,060
the positions

1956
01:58:49,080 --> 01:58:53,340
as i did here on the x axis at the discrete moment in time

1957
01:58:53,430 --> 01:58:54,960
but i'm going to

1958
01:58:55,010 --> 01:58:59,140
tell you exactly where the object is at any moment in time

1959
01:58:59,300 --> 01:59:02,150
you see in xt diagram

1960
01:59:02,240 --> 01:59:03,950
so you see that t one

1961
01:59:03,960 --> 01:59:06,300
the object is at position

1962
01:59:06,370 --> 01:59:07,460
xt one

1963
01:59:07,460 --> 01:59:11,080
this is the road of the object is is the straight line with moving

1964
01:59:11,120 --> 01:59:12,430
it starts here

1965
01:59:12,450 --> 01:59:14,240
and it goes to this position

1966
01:59:14,240 --> 01:59:16,990
he goes to this one it comes back to t four and it comes back

1967
01:59:18,080 --> 01:59:19,930
i'll tell you now

1968
01:59:21,870 --> 01:59:28,800
moment in time in between

1969
01:59:29,050 --> 01:59:33,710
it goes

1970
01:59:35,430 --> 01:59:36,530
this is now

1971
01:59:36,550 --> 01:59:38,640
information that is way more

1972
01:59:38,640 --> 01:59:42,020
you have the information at any moment in time notice

1973
01:59:42,050 --> 01:59:44,310
that i now did choose

1974
01:59:44,330 --> 01:59:45,990
x equal zero

1975
01:59:46,030 --> 01:59:48,210
i chose it somewhere here

1976
01:59:48,270 --> 01:59:50,980
but i could have chosen at any other points

1977
01:59:51,010 --> 01:59:54,960
whatever follows you will see that it makes no difference so i have chosen zero

1978
01:59:54,960 --> 01:59:58,180
points sort i can make a graph

1979
01:59:58,200 --> 01:59:59,150
and no

1980
01:59:59,170 --> 02:00:01,640
we will look at the average velocity

1981
02:00:01,650 --> 02:00:03,710
in a somewhat different ways

1982
02:00:03,780 --> 02:00:06,030
say i choose my time t two

1983
02:00:07,360 --> 02:00:09,550
three i draw here now

1984
02:00:09,550 --> 02:00:17,490
this line

1985
02:00:17,550 --> 02:00:20,990
and this angle i call of five

1986
02:00:21,010 --> 02:00:22,700
and this

1987
02:00:22,710 --> 02:00:25,530
or it here

1988
02:00:25,540 --> 02:00:27,530
i call delta x

1989
02:00:27,540 --> 02:00:29,770
and this year

1990
02:00:29,830 --> 02:00:31,060
is delta t

1991
02:00:32,470 --> 02:00:34,520
so you could right now

1992
02:00:34,570 --> 02:00:37,190
if you careful about you sign convention

1993
02:00:37,200 --> 02:00:38,520
you could write down now

1994
02:00:38,530 --> 02:00:40,260
that the average velocity

1995
02:00:40,270 --> 02:00:41,830
he called delta x

1996
02:00:41,900 --> 02:00:43,960
dividing by delta t

1997
02:00:43,960 --> 02:00:49,330
physical chemistry and reasoned that if the fatty phase could be broken down to a

1998
02:00:49,330 --> 02:00:51,290
finer particle size

1999
02:00:51,300 --> 02:00:55,950
then the buoyancy forces would dominate the gravity forces

2000
02:00:57,010 --> 02:01:00,980
it wouldn't separate so homogenised milk is simply milk

2001
02:01:01,000 --> 02:01:06,850
in which the fatty phase has been reduced input clothing cluster size two of value

2002
02:01:06,850 --> 02:01:07,890
so small

2003
02:01:07,950 --> 02:01:09,550
that by the time

2004
02:01:09,590 --> 02:01:14,520
the gravity field is able to dominate the buoyancy feel the product is spoiled anyway

2005
02:01:14,530 --> 02:01:19,310
so for practical shelf-life of the product you don't have to deal with starting

2006
02:01:19,330 --> 02:01:24,300
by taking the milk out of the fridge and shaking it in order to get

2007
02:01:24,320 --> 02:01:25,320
good mixing

2008
02:01:25,360 --> 02:01:26,690
that's a good example

2009
02:01:27,040 --> 02:01:32,120
so in the case of something like blood the cluster size is far too large

2010
02:01:32,120 --> 02:01:34,860
for that to happen and so it's not

2011
02:01:34,880 --> 02:01:42,160
i homogeneous under illumination it's easy to filter and it will separate the gravity field

2012
02:01:43,070 --> 02:01:46,030
what we're seeing here is a demonstration of

2013
02:01:46,040 --> 02:01:50,600
the competition between the gravitational forces in the interfacial forces

2014
02:01:50,690 --> 02:01:52,510
interfacial forces are

2015
02:01:52,540 --> 02:01:55,130
the function of the kinds of bonds

2016
02:01:56,570 --> 02:01:57,870
so it's a

2017
02:01:57,890 --> 02:02:02,540
it's all there it's all there and lastly this colloid is i want you to

2018
02:02:02,540 --> 02:02:06,140
be aware of the definitions here i'm not going to quiz you on this i

2019
02:02:06,140 --> 02:02:09,790
simply wanted to have it so that it some point you might want to

2020
02:02:09,790 --> 02:02:14,170
go back and refer to what i'm not going to test your memory

2021
02:02:14,190 --> 02:02:20,810
but this this breaks down the the entire taxonomy of of colloids where we see

2022
02:02:20,810 --> 02:02:26,820
that there's a difference between what happens in a liquid dispersive medium i gas dispersive

2023
02:02:26,820 --> 02:02:30,370
medium in a solid this person opinion and you can see many of the common

2024
02:02:30,370 --> 02:02:37,170
products that we know are in fact these dual phase mixtures that involve very very

2025
02:02:37,170 --> 02:02:44,460
fine particles on the order of some hundreds of nanometers that we use in common

2026
02:02:47,280 --> 02:02:51,440
so much for the for the taxonomy but now want to turn to the question

2027
02:02:51,440 --> 02:02:53,250
of miss ability

2028
02:02:53,300 --> 02:02:58,830
and in order to do that i want you to consider this

2029
02:02:58,890 --> 02:03:00,700
example which have

2030
02:03:00,710 --> 02:03:05,250
actually taken from your reading i want to look at dissolution of

2031
02:03:05,250 --> 02:03:07,720
substances in a

2032
02:03:07,770 --> 02:03:14,550
liquid bilayer sort of put two vessels side-by-side and each will contain the same

2033
02:03:14,570 --> 02:03:17,820
liquid bilayer

2034
02:03:17,840 --> 02:03:22,540
the liquid bilayer is going to consist of the bottom layer and both vessels is

2035
02:03:22,540 --> 02:03:25,150
carbon capture chloride

2036
02:03:25,180 --> 02:03:29,910
and the upper layer is water

2037
02:03:30,780 --> 02:03:35,890
first of all let's ask why these don't mix they're both liquid at room temperature

2038
02:03:35,900 --> 02:03:41,280
why don't they mix well let's take a look at the electronic structure and bonding

2039
02:03:41,280 --> 02:03:43,670
whenever i asked why

2040
02:03:43,690 --> 02:03:47,690
got test coming up a week from now when i asked why try to work

2041
02:03:47,690 --> 02:03:50,380
something into the answer that speaks to

2042
02:03:50,790 --> 02:03:52,960
electronic structure

2043
02:03:53,020 --> 02:03:54,460
because that's the clue

2044
02:03:54,480 --> 02:04:01,160
that's the clue so what we know about carbon tax chloride it's not polar

2045
02:04:01,180 --> 02:04:05,360
it's not in polar so why does one carbon center chloride born other carbon tax

2046
02:04:05,420 --> 02:04:10,830
chloride and please don't tell me something to do with the electronegativity difference between carbon

2047
02:04:10,830 --> 02:04:14,910
and chlorine let's forget about that it's not always all we've got is weak van

2048
02:04:14,910 --> 02:04:18,850
der waals forces so we have the van der waals liquid

2049
02:04:18,860 --> 02:04:21,650
on the bottom it's density is about

2050
02:04:21,700 --> 02:04:25,100
one point four so it's

2051
02:04:25,140 --> 02:04:27,070
why under water

2052
02:04:27,070 --> 02:04:32,150
and water on the other hand in contrast to be non polar it's polar

2053
02:04:32,170 --> 02:04:33,390
and it has

2054
02:04:33,410 --> 02:04:35,630
hydrogen bonding capability

2055
02:04:37,760 --> 02:04:42,110
these are very different substances and they don't have the capacity to link to one

2056
02:04:42,960 --> 02:04:44,720
so they don't they choose

2057
02:04:44,730 --> 02:04:46,060
forces of

2058
02:04:46,060 --> 02:04:48,900
cohesion over forces of adhesion

2059
02:04:48,920 --> 02:04:52,840
so we have two separate layers so now i'm we're going to ask what happens

2060
02:04:52,850 --> 02:04:54,350
if we introduce

2061
02:04:54,400 --> 02:04:59,460
candidates all you so we really have a by layer of solvents

2062
02:04:59,480 --> 02:05:00,440
now we're going to

2063
02:05:00,450 --> 02:05:06,180
introduce one case where going to put in solid crystalline iodine in the other case

2064
02:05:06,350 --> 02:05:10,420
put in solid crystalline potassium manganese

2065
02:05:10,430 --> 02:05:12,070
why did we choose these

2066
02:05:12,070 --> 02:05:18,110
well first of all both solid solid going into liquid and secondly the both purple

2067
02:05:18,120 --> 02:05:20,770
both purple very important both purple

2068
02:05:20,780 --> 02:05:24,010
what happens is if we drop iodine into this

2069
02:05:24,060 --> 02:05:29,300
bilayer stir vigorously makes everything up and then wait

2070
02:05:29,310 --> 02:05:33,350
the two liquids will face separating the gravity field and then we'll find at the

2071
02:05:33,350 --> 02:05:39,190
end of the experiment we have a solution here iodine

2072
02:05:39,220 --> 02:05:41,090
carbon chloride

2073
02:05:42,930 --> 02:05:44,300
mixed at the

2074
02:05:44,330 --> 02:05:45,900
a molecular level

2075
02:05:45,970 --> 02:05:47,660
on the other side

2076
02:05:48,790 --> 02:05:51,610
vigorously wafer system two

2077
02:05:51,620 --> 02:05:53,340
equal break

2078
02:05:53,380 --> 02:05:55,880
layers phase separate now

2079
02:05:55,890 --> 02:05:57,100
here we have

2080
02:05:57,110 --> 02:06:02,360
a solution of potassium manganese water

2081
02:06:02,380 --> 02:06:05,880
we can see with the naked eye the upper layer is purple the lower layer

2082
02:06:05,880 --> 02:06:07,380
is clear and colorless

2083
02:06:07,430 --> 02:06:11,910
in this case the upper layer is clear and colourless the lower layer for

2084
02:06:12,610 --> 02:06:13,710
it's clear that

2085
02:06:13,730 --> 02:06:19,340
the idea has a strong affinity for carbon centre chloride potassium manganese has a strong

2086
02:06:19,340 --> 02:06:20,620
affinity for

2087
02:06:20,670 --> 02:06:25,170
water so what's going on let's look at the structure of the candidates of what's

2088
02:06:25,170 --> 02:06:27,770
iodine iodine is

2089
02:06:27,820 --> 02:06:30,800
a diatomic molecule

2090
02:06:30,860 --> 02:06:35,440
and it's not polar symmetric so it's event of all solid

2091
02:06:35,470 --> 02:06:38,500
then all solid

2092
02:06:38,550 --> 02:06:46,020
and the van waals solid dissolves in the van der waals liquid because together they

2093
02:06:46,020 --> 02:06:51,690
got fluctuating dipole interactions that can allow them to one to one another and former

2094
02:06:51,700 --> 02:06:53,670
solution was with water

2095
02:06:53,690 --> 02:06:54,630
it's less

2096
02:06:54,640 --> 02:06:55,750
less favoured

2097
02:06:55,790 --> 02:06:59,400
in this case potassium for manganese is an ionic compound

2098
02:06:59,420 --> 02:07:01,640
four potassium cations

2099
02:07:01,810 --> 02:07:04,710
and to rank in a an alliance

2100
02:07:04,730 --> 02:07:06,580
so we have

2101
02:07:06,650 --> 02:07:09,340
in ionic solid

2102
02:07:09,340 --> 02:07:13,340
ionic solid dissolving in a polar liquids

2103
02:07:14,570 --> 02:07:18,050
the polar liquid is it is able to attract

2104
02:07:18,090 --> 02:07:21,150
the positive and of the dipole attracts the

2105
02:07:21,250 --> 02:07:24,360
and i am the negative at the end of the dipole

2106
02:07:24,370 --> 02:07:26,270
tracks the cat

2107
02:07:26,320 --> 02:07:28,050
if you if you read the

2108
02:07:28,120 --> 02:07:34,330
the typical chemistry textbooks they don't go into such an elaborate solutions discussion they like

2109
02:07:34,350 --> 02:07:36,600
to simplify it

2110
02:07:36,610 --> 02:07:39,550
the slogan taglines

2111
02:07:39,560 --> 02:07:43,730
so you'll see this

2112
02:07:43,830 --> 02:07:47,080
i hope you don't see that hope to see it spelled correctly you'll see like

2113
02:07:47,120 --> 02:07:49,950
dissolves like

2114
02:07:49,970 --> 02:07:53,550
i look at that as it's too simplistic going to give you some examples of

2115
02:07:53,550 --> 02:07:55,120
where that doesn't happen

2116
02:07:55,120 --> 02:07:58,530
the size of this is i don't know what to look at that i wonder

2117
02:07:58,530 --> 02:08:11,220
if i'm reading something from california noted that the like dissolves like you know

2118
02:08:11,250 --> 02:08:15,620
ten year means never having to say you're sorry switches


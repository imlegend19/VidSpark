1
00:00:00,000 --> 00:00:01,000
new cluster

2
00:00:01,020 --> 00:00:08,440
well it's basically just doing gibbs sampling sizes is exploring the posterior and

3
00:00:08,460 --> 00:00:13,710
when does not so remember this diagram where you have like

4
00:00:13,710 --> 00:00:15,770
i think this is from

5
00:00:16,480 --> 00:00:19,750
carl's lecture one right

6
00:00:28,940 --> 00:00:32,030
so you can for

7
00:00:32,050 --> 00:00:34,550
small model class then it will explain

8
00:00:34,570 --> 00:00:36,000
a small set of

9
00:00:36,020 --> 00:00:37,500
a small

10
00:00:37,550 --> 00:00:41,500
set of data sets very well and they for large model classes

11
00:00:41,520 --> 00:00:45,550
explain the largest datasets but then of course is for us to spread the probability

12
00:00:46,570 --> 00:00:51,520
so so this thing is kind similar if you have a small number of data

13
00:00:52,360 --> 00:00:54,590
then it is it will decide that

14
00:00:54,610 --> 00:00:55,520
if e

15
00:00:55,550 --> 00:00:57,170
you just use a small number of

16
00:00:57,170 --> 00:00:59,000
michelle components

17
00:00:59,020 --> 00:01:02,270
to explain that particular

18
00:01:02,290 --> 00:01:07,210
they well and in crete as you increase the number of data points you

19
00:01:07,380 --> 00:01:10,270
then realizes that it cannot actually use

20
00:01:10,320 --> 00:01:13,440
a small number of clusters to explain it so it just increase the number of

21
00:01:13,440 --> 00:01:16,770
clusters and this kind of doing this automatically

22
00:01:18,520 --> 00:01:27,340
the posterior of the prior

23
00:01:28,210 --> 00:01:29,630
yes you

24
00:01:29,650 --> 00:01:36,710
yes OK it turns out that it turns out that the prior problem the prior

25
00:01:36,710 --> 00:01:38,790
distribution over clusters

26
00:01:38,800 --> 00:01:41,730
over the number of clusters that the model was to use

27
00:01:41,860 --> 00:01:43,710
if you only tell it

28
00:01:43,730 --> 00:01:45,320
and data points

29
00:01:45,320 --> 00:01:48,290
it is going to scale as alpha timeslot

30
00:01:49,210 --> 00:01:50,460
the mean of the number

31
00:01:50,480 --> 00:01:59,190
there is a perfect form in fact well it it looks like

32
00:01:59,210 --> 00:02:02,550
it looks a bit like

33
00:02:02,630 --> 00:02:08,400
something so there's no BLP a lot and

34
00:02:08,400 --> 00:02:10,520
it's not

35
00:02:10,530 --> 00:02:12,460
it's not of the standard format all

36
00:02:21,440 --> 00:02:24,790
it also depends on the parameter alpha so

37
00:02:24,840 --> 00:02:26,900
this private telephone fax is

38
00:02:26,920 --> 00:02:28,920
the larger alpha

39
00:02:29,960 --> 00:02:30,880
the more

40
00:02:30,900 --> 00:02:32,000
it expects

41
00:02:32,030 --> 00:02:33,150
to use

42
00:02:33,550 --> 00:02:37,880
the more the number of components and expects to use

43
00:02:37,920 --> 00:02:39,570
and you can kind of see this

44
00:02:41,630 --> 00:02:42,880
from the slide

45
00:02:44,940 --> 00:02:50,900
this light so it's basically saying that the chance of

46
00:02:50,940 --> 00:02:56,300
any data item starting its own clusters can be large and if have much of

47
00:02:56,320 --> 00:02:58,770
and so you you see more

48
00:03:00,400 --> 00:03:03,360
in in mission model in your post

49
00:03:03,570 --> 00:03:06,070
question yes

50
00:03:12,060 --> 00:03:22,590
yes i guess you could think of it as a kind of model averaging except

51
00:03:24,900 --> 00:03:27,800
the easiest way of of a thing

52
00:03:27,820 --> 00:03:31,250
thinking about this model is not as model averaging

53
00:03:31,250 --> 00:03:33,570
but as

54
00:03:34,300 --> 00:03:38,880
simply have one single model with a very large number of clusters

55
00:03:38,880 --> 00:03:42,750
and then when you run your gibbs sampler it decides not to use most of

56
00:03:42,750 --> 00:03:44,800
the clusters just decide to use

57
00:03:44,820 --> 00:03:48,030
a small subset of the clusters

58
00:03:59,270 --> 00:04:01,400
but that's come

59
00:04:01,420 --> 00:04:03,860
similar to

60
00:04:03,880 --> 00:04:08,650
this car similar to causal processes to right so you're saying that as the number

61
00:04:08,650 --> 00:04:10,130
of datapoints grows

62
00:04:10,770 --> 00:04:12,840
i expect that to be more

63
00:04:14,210 --> 00:04:16,190
information in your data set

64
00:04:16,210 --> 00:04:17,150
so you

65
00:04:17,170 --> 00:04:20,940
i do want to use more and more clusters to explain the data sets

66
00:04:21,800 --> 00:04:23,800
the number of clusters to

67
00:04:24,570 --> 00:04:26,480
in this case it was a lot

68
00:04:30,690 --> 00:04:31,820
any more questions

69
00:04:32,610 --> 00:04:34,340
yes yes

70
00:04:37,020 --> 00:04:38,050
it is

71
00:04:38,070 --> 00:04:42,230
but i think that's what we mean by number of

72
00:04:50,480 --> 00:04:57,290
the number of ways of one one of the is this one

73
00:04:57,300 --> 00:05:02,020
where number of those who might actually be on the

74
00:05:02,380 --> 00:05:06,190
the population of the

75
00:05:08,020 --> 00:05:12,210
so what

76
00:05:12,230 --> 00:05:15,400
the person you're going to

77
00:05:22,650 --> 00:05:24,630
one person

78
00:05:24,650 --> 00:05:26,070
one of

79
00:05:26,290 --> 00:05:29,190
we do that

80
00:05:29,590 --> 00:05:33,750
OK so it's when we said number of

81
00:05:33,750 --> 00:05:36,460
components discussing

82
00:05:36,480 --> 00:05:41,500
not the number of components that is in the whole population but only among the

83
00:05:41,670 --> 00:05:43,710
data points that we see

84
00:05:43,710 --> 00:05:45,800
only among the people that you see

85
00:05:46,090 --> 00:05:50,880
yes i was

86
00:05:51,090 --> 00:05:56,770
you are in the court i just fixed alpha but you can fact place the

87
00:05:56,770 --> 00:06:02,500
priority of individuals so in fact this model is quite sensitive to the to the

88
00:06:02,500 --> 00:06:08,050
setting of and in practice i always put up round of sample that

89
00:06:08,110 --> 00:06:13,210
people typically use the common prior on of

90
00:06:13,230 --> 00:06:14,550
he has

91
00:06:14,570 --> 00:06:15,840
because of the work

92
00:06:15,840 --> 00:06:17,570
pretty well

93
00:06:19,940 --> 00:06:23,840
so that you can imaging model right

94
00:06:25,400 --> 00:06:28,420
actually i should

95
00:06:29,250 --> 00:06:33,960
plus the sum of the covered dirichlet process so

96
00:06:33,960 --> 00:06:38,880
and i will present two approaches that can somehow deal with this problem one is

97
00:06:38,880 --> 00:06:42,840
based on the concept approximation inference

98
00:06:42,920 --> 00:06:48,740
another one in front and the second one is the so-called good common subsumer influence

99
00:06:48,800 --> 00:06:53,220
which is close relative to the least common substrings OK this is what we are

100
00:06:53,360 --> 00:06:55,530
heading for

101
00:06:57,470 --> 00:07:00,370
first of all let's let's recall what the

102
00:07:00,460 --> 00:07:06,980
top down approach for building ontologies actually meant so usually

103
00:07:07,180 --> 00:07:08,140
she read

104
00:07:08,150 --> 00:07:09,340
i mean

105
00:07:09,400 --> 00:07:13,860
early papers on how to design ontology so i would suggest often times that you

106
00:07:13,860 --> 00:07:18,840
start to model your your knowledge base some concepts and putting them in the t

107
00:07:18,840 --> 00:07:19,740
box two

108
00:07:19,760 --> 00:07:24,710
build up your terminology and then when you some confident facility box and think you

109
00:07:24,720 --> 00:07:29,270
sufficiently model covered your domain then you're trying to the a box and populate the

110
00:07:29,270 --> 00:07:32,800
books with instances of three years old

111
00:07:32,850 --> 00:07:35,780
individuals from the application domain

112
00:07:35,800 --> 00:07:41,280
this is in principle fine it's also in the first part

113
00:07:41,280 --> 00:07:47,990
this way of proceeding to fill your ontologies is actually not supported by a standard

114
00:07:47,990 --> 00:07:49,390
reasoner so you can

115
00:07:49,430 --> 00:07:52,640
check whether box is satisfiable you can do

116
00:07:52,660 --> 00:07:56,480
insensitive and you can growing in a box so this is

117
00:07:56,490 --> 00:08:01,570
so the infrastructure for proceeding in this may matrix very good but the made

118
00:08:01,610 --> 00:08:03,900
the drawback of this way of

119
00:08:03,910 --> 00:08:08,530
filling your of the method of filling your knowledge bases

120
00:08:08,550 --> 00:08:15,660
actually quite quite good knowledge of description logics on knowledge representation systems in general so

121
00:08:15,660 --> 00:08:18,040
the user has already too

122
00:08:18,070 --> 00:08:22,680
be quite fluent in description logics in order to

123
00:08:22,720 --> 00:08:26,340
capture the notions that you go into the t watson to go into the a

124
00:08:26,340 --> 00:08:31,410
box in the competent way

125
00:08:32,670 --> 00:08:33,890
but if one

126
00:08:33,900 --> 00:08:35,420
look at the situation

127
00:08:35,450 --> 00:08:41,110
but we have when people actually building the knowledge bases then we have

128
00:08:41,160 --> 00:08:47,030
often the case that the people building the ontologies are actually not experts in description

129
00:08:47,030 --> 00:08:53,030
logics or knowledge representation of the people that are experts in their domain in medicine

130
00:08:53,050 --> 00:08:57,480
biology and fears of course

131
00:08:57,510 --> 00:08:59,920
and for these

132
00:08:59,970 --> 00:09:03,220
if users of the systems it often happens

133
00:09:03,270 --> 00:09:05,180
that the knowledge engineer

134
00:09:05,210 --> 00:09:08,470
as some whole notion in mind what you would like to have the concept in

135
00:09:08,470 --> 00:09:10,280
the t box but

136
00:09:10,280 --> 00:09:15,520
can someone try down description can not not cold the notion you have in mind

137
00:09:15,850 --> 00:09:18,920
and somehow introduced a concept description

138
00:09:18,930 --> 00:09:21,340
for this notion

139
00:09:21,460 --> 00:09:23,280
in in

140
00:09:23,280 --> 00:09:27,910
application that we had a couple of years ago and chemical process engineering we saw

141
00:09:27,910 --> 00:09:30,390
that people actually did not see the way

142
00:09:30,430 --> 00:09:35,440
the other papers suggested many in the top down approach but the people from that

143
00:09:37,200 --> 00:09:41,060
started with populating the a box because they found it more

144
00:09:41,100 --> 00:09:49,430
easy to actually describe individuals for instance instances that they can observe and application domain

145
00:09:49,450 --> 00:09:54,770
and once that kind of sufficient set of individuals and a box they group these

146
00:09:56,550 --> 00:09:57,690
and try to

147
00:09:57,950 --> 00:10:04,350
come up with category for these four similar individuals and what these users did is

148
00:10:04,590 --> 00:10:08,460
they look very closely at what they had in the able which kind of concepts

149
00:10:08,510 --> 00:10:09,800
attached to the

150
00:10:09,820 --> 00:10:13,090
the individual there and

151
00:10:13,100 --> 00:10:15,600
holly into interrelation of the individual

152
00:10:15,650 --> 00:10:20,040
is in the able and then try to come up with concept description that captures

153
00:10:21,150 --> 00:10:26,180
these kind of individuals by hand

154
00:10:28,240 --> 00:10:34,360
people were actually already proceeding to build ontologies in but in that bottom-up pressure many

155
00:10:34,360 --> 00:10:39,720
by starting from the individual but they were doing this in order to handcrafted all

156
00:10:39,900 --> 00:10:43,710
the concept description they wanted to introduce sanity t box

157
00:10:43,720 --> 00:10:48,650
the idea is now to support this this way of proceeding in an automatic or

158
00:10:48,650 --> 00:10:50,670
semi-automatic way

159
00:10:50,720 --> 00:10:52,680
how can this be done of

160
00:10:52,700 --> 00:10:54,260
doesn't look in practice

161
00:10:55,220 --> 00:10:56,700
what would happen

162
00:10:57,240 --> 00:11:02,040
during the bottom up approach is OK the user will select somewhat similar

163
00:11:02,110 --> 00:11:04,510
able to able to individual

164
00:11:04,540 --> 00:11:09,970
something like this and then in the second step

165
00:11:10,480 --> 00:11:13,250
these individuals to pick

166
00:11:13,260 --> 00:11:17,150
i generalized for each of these kinds of descriptions generalise

167
00:11:17,170 --> 00:11:21,610
each of these individual sorry is generalized into one concept descriptions so we see it

168
00:11:22,200 --> 00:11:26,230
a knowledge engineer has found three individuals that are from all like

169
00:11:26,550 --> 00:11:29,980
and system

170
00:11:29,990 --> 00:11:34,590
abstracts from these individuals and generate a concept description

171
00:11:34,620 --> 00:11:38,250
this is not just find name in the box but you generate

172
00:11:38,400 --> 00:11:42,580
the best fitting concept description for these individuals

173
00:11:42,600 --> 00:11:43,630
and then

174
00:11:43,690 --> 00:11:44,980
in the next steps

175
00:11:44,990 --> 00:11:48,970
the obtained concept

176
00:11:49,010 --> 00:11:52,350
then generalised introducing the concept descriptions

177
00:11:57,100 --> 00:12:00,460
happening or

178
00:12:00,470 --> 00:12:01,440
and this

179
00:12:01,450 --> 00:12:04,190
the concept description then subsumes

180
00:12:04,200 --> 00:12:06,170
all of the input concepts

181
00:12:06,180 --> 00:12:07,600
the more general

182
00:12:07,690 --> 00:12:12,210
then the next thing is that this concept description is displayed to the user the

183
00:12:12,210 --> 00:12:13,250
user can

184
00:12:13,310 --> 00:12:16,760
look at the a concept description c without actually

185
00:12:16,800 --> 00:12:21,470
is roughly what he expected always the concept description like you can edit the concept

186
00:12:21,470 --> 00:12:26,370
description and if you like what is obtained then you can decide to name

187
00:12:26,390 --> 00:12:32,240
and thus added the new concept in the terminology

188
00:12:33,310 --> 00:12:39,310
the idea is that the description logics services actually provide a concept description that captures

189
00:12:39,340 --> 00:12:43,670
object instances of individuals

190
00:12:44,480 --> 00:12:49,330
five is automatically and the user can then decide whether to introduce this into the

191
00:12:49,330 --> 00:12:53,060
ontology or not

192
00:12:53,630 --> 00:13:02,360
so the first step of this bottom-up construction the user selects the a box individuals

193
00:13:02,430 --> 00:13:06,960
is not the place actually the domain knowledge of the knowledge engineer comes into play

194
00:13:06,960 --> 00:13:09,220
in picking

195
00:13:09,240 --> 00:13:13,420
f of individuals that are actually like that forms

196
00:13:13,460 --> 00:13:16,570
good candidates to form meaningful

197
00:13:16,600 --> 00:13:21,480
category in in the application domain

198
00:13:22,190 --> 00:13:27,840
the second step if you look a little closer at how it is realized

199
00:13:27,840 --> 00:13:32,460
named is is this generalization into concept descriptions

200
00:13:32,540 --> 00:13:36,440
then we would like to employ description logic reasoning system and

201
00:13:36,460 --> 00:13:39,240
reasoning so that

202
00:13:39,250 --> 00:13:45,420
exactly use of such concept description is called the most specific concept

203
00:13:47,000 --> 00:13:49,240
let's first look at that

204
00:13:49,250 --> 00:13:51,520
the definition of this kind of inference

205
00:13:51,540 --> 00:13:55,940
the most specific concept of an individual

206
00:13:56,560 --> 00:13:59,340
i can be

207
00:13:59,340 --> 00:14:03,940
so the most concept of an individual a and enable

208
00:14:03,960 --> 00:14:05,200
of course a

209
00:14:05,440 --> 00:14:09,880
is the concept of the concept descriptions such that

210
00:14:09,890 --> 00:14:12,130
two kind of conditions hold

211
00:14:13,670 --> 00:14:16,690
it follows from the labelled set a is an instance of c so we want

212
00:14:16,690 --> 00:14:18,860
to have this relationship here

213
00:14:19,880 --> 00:14:23,210
we also want to make sure that some of the best fitting concept description can

214
00:14:23,210 --> 00:14:24,960
obtain the for each

215
00:14:24,970 --> 00:14:28,310
other concept description that we

216
00:14:28,310 --> 00:14:33,570
the dark matter we know the annihilation cross section the dark matter shouldn`t

217
00:14:33,570 --> 00:14:41,810
accreet in the sun the earth the center of the galaxy annihilated producing

218
00:14:41,810 --> 00:14:48,110
perhaps some signal that is distinctive enough that we would know it's way very

219
00:14:48,110 --> 00:14:55,570
high energy neutrinos positrons anti-protons and gamma rays so this would be indirectly detection this

220
00:14:55,570 --> 00:15:01,270
depends upon the annihilation cross section and this is being looked for many ways

221
00:15:01,270 --> 00:15:09,770
today finally there's accelerator production and I know a year from now the cold thermal relic

222
00:15:09,770 --> 00:15:19,160
will be discovered that the LHC let me say a word about indirect detection but

223
00:15:19,180 --> 00:15:24,670
you can look at neutrinos from the sun of the earth anomalous cosmic using gamma rays

224
00:15:24,670 --> 00:15:31,830
from galactic halos neutrinos gamma rays radio waves from our own galactic center one of the

225
00:15:31,830 --> 00:15:40,690
difficulties that is astro physical difficulty in predicting what you would see and that's again

226
00:15:40,690 --> 00:15:46,130
related to the role of halos substructure so if there is dark matter in the

227
00:15:46,130 --> 00:15:53,770
center of the galaxy the annihilation rate is proportional to the density square so uncertainty

228
00:15:53,770 --> 00:15:59,930
about the density actually at the center of our galaxy is very important because it

229
00:15:59,930 --> 00:16:08,290
is proportional to the density square this is an example of three possibilities I should`ve

230
00:16:08,290 --> 00:16:13,550
labeled them I'm sorry I didn't of the density of dark matter in our

231
00:16:13,550 --> 00:16:19,910
galaxy divided by some rho zero this would be the density profile as

232
00:16:19,910 --> 00:16:26,190
that of function of distance and here`s the radius in parsec so for indirect detection

233
00:16:26,190 --> 00:16:31,990
we're interested in the density here and for the same total dark matter mass in our

234
00:16:32,040 --> 00:16:39,430
galaxies there's uncertainty in the density in the center of the galaxy here by a

235
00:16:39,430 --> 00:16:49,070
very large factor this is squared in predicting the indirect detection rate

236
00:16:49,070 --> 00:16:53,850
so you see that it's very uncertain and difficult to predict what the dark matter detection

237
00:16:53,850 --> 00:17:02,470
rate would be so the local favorite if you poll people in Geneva poll people

238
00:17:02,470 --> 00:17:07,730
on the street aside in Geneva and ask them what's their favored cold thermal relic they

239
00:17:07,730 --> 00:17:15,470
would say the neutralino and they say it`s a neutralino because we study constraint minimal

240
00:17:15,480 --> 00:17:22,630
supersymmetric standard models so you don't have to deal with the hundred and five parameters now what

241
00:17:22,630 --> 00:17:29,270
you discover when you do that is that typical Susy models are condemned are consistent

242
00:17:29,270 --> 00:17:39,470
with collided data and another precision experiments have two small annihilation cross section what's wrong

243
00:17:39,470 --> 00:17:45,790
with you people you push the Susy scale to such so high that the annihilation

244
00:17:45,790 --> 00:17:52,470
cross section is low and in generally generically would produce two value to large

245
00:17:52,470 --> 00:17:59,870
valuable of Omega was a terrible thing to do we should never done experiments so

246
00:17:59,870 --> 00:18:05,150
you need some sort of chicanery to increase the annihilation cross section and in fact this may be

247
00:18:05,150 --> 00:18:10,410
telling us something about Susy models so how how can you increase the annihilation cross

248
00:18:10,410 --> 00:18:17,470
section well you can go through s channel residences like through light higgs and z poles

249
00:18:17,470 --> 00:18:22,330
so perhaps as telling us that the minimal supersymmetric standard model the mass of

250
00:18:22,340 --> 00:18:27,710
the neutralino should be close to the s channel residence of light higgs and z

251
00:18:27,720 --> 00:18:34,430
it couldn't co-annihilated with the stow or the stop

252
00:18:34,430 --> 00:18:39,690
there are models if you have a large tension pheta then you can have questionable annihilation

253
00:18:39,690 --> 00:18:48,050
through broad a residences high values of m zero the Universal scalar mass the LSP

254
00:18:48,050 --> 00:18:54,030
the neutralino with Higgsino like and annihilates into W and Z pairs

255
00:18:54,030 --> 00:18:58,810
this is known as the focus point region or perhaps the minimal model is

256
00:18:58,810 --> 00:19:05,230
points generated independently and identically from galaxy and with mean mu and standard deviation sigma

257
00:19:05,250 --> 00:19:10,520
so the joint distribution over everything i've mentioned here is x one through x then

258
00:19:10,520 --> 00:19:16,830
the datapoints mu for the mean and sigma for the standard deviation we can imagine

259
00:19:16,830 --> 00:19:18,290
a model where

260
00:19:18,310 --> 00:19:21,380
we have mu and sigma in the model

261
00:19:21,420 --> 00:19:26,270
and then the the data points x one through x and are generated independently given

262
00:19:26,270 --> 00:19:27,310
mu and sigma

263
00:19:27,400 --> 00:19:32,500
note that that's the graphical model for independence given mu and sigma because

264
00:19:32,500 --> 00:19:35,060
there's no edge between x one x two

265
00:19:35,080 --> 00:19:36,980
david mu and sigma

266
00:19:36,980 --> 00:19:42,250
x one x two it any other axes are independent of each other so that

267
00:19:42,830 --> 00:19:47,170
the graph corresponding to that little bit here this is i i d

268
00:19:49,460 --> 00:19:53,730
and because it's tedious to write x one x two dot dot dot x and

269
00:19:53,750 --> 00:19:58,690
we have this plate notation where we just set x subbands with some

270
00:20:00,040 --> 00:20:05,330
indicator here index so little and goes from say one to begin

271
00:20:09,080 --> 00:20:15,400
so here's the answer the question on the expressive power of directed undirected graphs

272
00:20:15,480 --> 00:20:20,880
so i've already shown you that no undirected graph or factor graph exactly over these

273
00:20:20,880 --> 00:20:27,020
three variables can capture the the independence the dependence structure is captured by the graph

274
00:20:28,420 --> 00:20:31,190
now this graph here

275
00:20:31,210 --> 00:20:33,100
over four variables

276
00:20:33,170 --> 00:20:35,210
is an example of

277
00:20:35,250 --> 00:20:39,630
the graph with no directed graph

278
00:20:39,690 --> 00:20:41,960
over four variables

279
00:20:41,960 --> 00:20:43,380
can represent

280
00:20:43,600 --> 00:20:48,650
these and only these independencies OK so the independencies we have in this rap are

281
00:20:50,880 --> 00:20:51,520
you know

282
00:20:51,580 --> 00:20:57,790
let's call this north and south are independent given east and west right and vice

283
00:20:57,790 --> 00:21:01,980
versa east and west are independent given north and south

284
00:21:02,750 --> 00:21:05,580
and we can do that by

285
00:21:05,580 --> 00:21:09,250
putting in directed edges in any way contrived but you fail

286
00:21:09,270 --> 00:21:14,060
yes it is a big there's going

287
00:21:14,080 --> 00:21:15,330
so you

288
00:21:15,350 --> 00:21:16,190
can use

289
00:21:17,230 --> 00:21:20,920
directed graphs are basically que

290
00:21:21,170 --> 00:21:24,130
in other words you can never have a loop

291
00:21:24,190 --> 00:21:31,710
that follows all the directions of the arrows and also people find that unsatisfactory because

292
00:21:31,710 --> 00:21:37,210
they want to model dynamical systems or something like that but in the dynamical system

293
00:21:37,350 --> 00:21:41,560
variable doesn't depend on itself the valuable at the point at the next point in

294
00:21:41,560 --> 00:21:46,940
time depends on the that variable the previous one time so we we really don't

295
00:21:46,940 --> 00:21:49,040
have loops

296
00:21:49,060 --> 00:21:50,810
we don't need groups

297
00:21:50,830 --> 00:21:58,400
we can always represent things temporarily as chris it for the chest example by

298
00:21:58,420 --> 00:22:00,480
taking time and

299
00:22:00,580 --> 00:22:03,920
writing out the variables in sequence

300
00:22:05,750 --> 00:22:06,830
all right so

301
00:22:07,020 --> 00:22:09,920
i'm going to summarize the first

302
00:22:11,210 --> 00:22:12,940
of this lecture

303
00:22:14,770 --> 00:22:15,500
so we

304
00:22:15,540 --> 00:22:18,060
i should be three different kinds of graphs

305
00:22:18,080 --> 00:22:21,150
i talked about marginal conditional independence

306
00:22:21,170 --> 00:22:26,310
markov boundaries and d separation and differences between directed and undirected graphs

307
00:22:26,350 --> 00:22:31,670
we could take like not a break where everybody goes away

308
00:22:31,670 --> 00:22:32,620
but a

309
00:22:32,620 --> 00:22:37,920
two or three minutes stretch break and that all go into talking about exact inference

310
00:22:37,920 --> 00:22:39,810
and propagation algorithms

311
00:22:39,830 --> 00:22:46,900
and then in following lectures on tuesday i'm going to introduce a parameter and structure

312
00:22:46,900 --> 00:22:50,750
learning graphs and then i'm going to go to slightly more advanced

313
00:22:51,830 --> 00:22:56,400
which will bring together ideas from a non parametric bayesian learning in graphical models and

314
00:22:56,400 --> 00:23:03,460
so on just to give you more interesting flavor of current research in graphical models

315
00:23:03,650 --> 00:23:07,190
that be

316
00:23:10,980 --> 00:23:13,560
one a

317
00:23:13,620 --> 00:23:20,940
now we have

318
00:23:23,770 --> 00:23:27,120
if you region graph

319
00:23:33,710 --> 00:23:35,940
so i think it

320
00:23:35,940 --> 00:23:40,570
OK and the function is a black box

321
00:23:40,610 --> 00:23:51,160
which is an engineer engineering technology applied to to impose two inputs to obtain an

322
00:23:53,500 --> 00:23:54,750
we defined

323
00:23:54,760 --> 00:23:58,020
the output in this way

324
00:23:58,040 --> 00:24:02,070
this function is

325
00:24:02,090 --> 00:24:05,360
as a function of a which we will call

326
00:24:05,380 --> 00:24:15,920
total factor productivity of quito capital of total employment this is a measure of how

327
00:24:16,870 --> 00:24:21,540
increases in k in the in an impact

328
00:24:22,900 --> 00:24:23,830
on output

329
00:24:23,850 --> 00:24:28,350
OK so we are interested in the technology matrix

330
00:24:28,370 --> 00:24:34,070
OK this is a measure of the of canals

331
00:24:37,880 --> 00:24:39,480
it is independent

332
00:24:41,460 --> 00:24:47,470
the most famous production function economics is the so-called come down

333
00:24:47,490 --> 00:24:55,750
from the name of the discovery that the something like this is very simple

334
00:24:55,830 --> 00:25:01,820
OK so alpha is not depend from knn

335
00:25:02,060 --> 00:25:03,600
is not from knn

336
00:25:04,850 --> 00:25:06,630
the sum of these two

337
00:25:06,650 --> 00:25:10,580
exponent is equal to one

338
00:25:10,600 --> 00:25:15,070
this function displays constant returns to scale

339
00:25:15,090 --> 00:25:20,440
it is of much in of degree one from OK is this is some is

340
00:25:21,110 --> 00:25:24,560
greater than one we have increasing returns

341
00:25:24,640 --> 00:25:26,580
to scale

342
00:25:27,400 --> 00:25:33,630
and if this sum is lower than what we had increasing returns to scale

343
00:25:33,640 --> 00:25:35,430
now suppose that we have

344
00:25:35,440 --> 00:25:40,880
constant returns to scale if you take the logarithm of this expression and you have

345
00:25:40,880 --> 00:25:44,880
data for k four and four beta four alpha

346
00:25:44,900 --> 00:25:46,570
and for some

347
00:25:46,570 --> 00:25:49,210
you can have an estimate of

348
00:25:49,260 --> 00:25:51,660
so you can build

349
00:25:51,720 --> 00:25:53,000
time series

350
00:25:53,010 --> 00:25:55,320
of this parameter

351
00:25:55,340 --> 00:26:00,370
which is measuring how technology is applied to that fact

352
00:26:00,380 --> 00:26:03,310
OK and this

353
00:26:03,400 --> 00:26:07,730
this time series is a lot

354
00:26:07,740 --> 00:26:11,750
so we have here is a list of opportunities grazing and there's a a list

355
00:26:11,750 --> 00:26:19,070
of triple tt is decreasing and we are able to have two to understand how

356
00:26:19,070 --> 00:26:22,830
the economy copes with the sharks to the

357
00:26:22,850 --> 00:26:25,130
in terms of the rates of

358
00:26:25,960 --> 00:26:29,590
of of this total factor productivity

359
00:26:30,320 --> 00:26:37,280
and the magic of all the story is that people who

360
00:26:37,860 --> 00:26:45,210
has won the nobel prize look at some and so was able to show that

361
00:26:45,420 --> 00:26:51,440
we have we can model an economy buffeted by a

362
00:26:51,460 --> 00:26:53,100
shocks to technology

363
00:26:53,130 --> 00:26:56,860
which is always in equilibrium

364
00:26:57,920 --> 00:27:01,330
aggregate fluctuations are just the result

365
00:27:01,330 --> 00:27:04,440
of optimal responses

366
00:27:04,460 --> 00:27:06,560
of rational agents

367
00:27:06,570 --> 00:27:07,760
the shock

368
00:27:07,780 --> 00:27:09,820
they face

369
00:27:09,830 --> 00:27:11,780
OK this is the idea

370
00:27:11,860 --> 00:27:15,890
so the business cycle is basically an equilibrium phenomenon

371
00:27:15,930 --> 00:27:18,160
it's not that does not include at

372
00:27:18,260 --> 00:27:20,930
this is termed the economic

373
00:27:20,940 --> 00:27:23,230
basic classical economics

374
00:27:23,230 --> 00:27:24,810
everything is inequality

375
00:27:24,830 --> 00:27:26,280
because people

376
00:27:26,290 --> 00:27:30,090
rationale they are able to respond rationally

377
00:27:30,120 --> 00:27:34,240
two to the environment and the

378
00:27:34,250 --> 00:27:36,800
adaptive behavior

379
00:27:36,840 --> 00:27:41,840
optimally to incentives coming from from

380
00:27:41,850 --> 00:27:44,900
from from the environment

381
00:27:44,920 --> 00:27:51,800
and so what remains is just an equilibrium an equilibrium results

382
00:27:51,870 --> 00:27:59,920
OK so this is the mainstream economics i'm not asking you to accept it but

383
00:28:00,740 --> 00:28:03,100
maybe is it's it's interesting to note

384
00:28:03,120 --> 00:28:09,130
OK this is the mainstream by this problem

385
00:28:09,150 --> 00:28:15,300
suppose we are assuming that these shocks to pretty

386
00:28:15,300 --> 00:28:17,220
are i i d

387
00:28:17,230 --> 00:28:22,830
as soon as we have a large number of individuals

388
00:28:22,960 --> 00:28:25,710
idea fluctuation

389
00:28:25,720 --> 00:28:28,510
fluctuations tend to become lashing

390
00:28:29,410 --> 00:28:34,260
as soon as we increase the number of individuals by the law of large numbers

391
00:28:34,270 --> 00:28:39,530
so that's why is standard macroeconomics we are assuming that there are just one common

392
00:28:40,880 --> 00:28:45,500
getting hold all the agents of the same time

393
00:28:46,010 --> 00:28:51,550
what's the definition of like a shock while the center responses or shock

394
00:28:51,600 --> 00:28:59,230
but we have no shock at least every ten or fifteen years

395
00:28:59,230 --> 00:29:06,160
so it's difficult to explain standard our fluctuations just in time of war

396
00:29:06,180 --> 00:29:08,330
of shocks

397
00:29:08,330 --> 00:29:15,330
so we have to find some different answers to this to this question one possible

398
00:29:15,330 --> 00:29:18,120
answer has been

399
00:29:18,150 --> 00:29:24,570
and applied by a soviet bayesian paper in two thousand five which is called the

400
00:29:24,570 --> 00:29:32,410
ground or origin of irish fluctuations insisting this paper is still working paper no

401
00:29:32,430 --> 00:29:38,280
it's not common economics that you know this guy is publishing the best journals

402
00:29:38,280 --> 00:29:40,240
well different personalities

403
00:29:41,130 --> 00:29:43,970
well we were raised by different parents

404
00:29:44,010 --> 00:29:45,920
and we have different genes

405
00:29:45,940 --> 00:29:47,590
we can tell

406
00:29:47,590 --> 00:29:49,610
my my brother

407
00:29:49,630 --> 00:29:50,800
and me

408
00:29:50,800 --> 00:29:53,400
might share all sorts of things in common

409
00:29:53,420 --> 00:29:55,360
we have the same parents

410
00:29:55,400 --> 00:29:59,820
and the same genes fifty percent same so how do we tell what's causing us

411
00:29:59,820 --> 00:30:01,030
to be like

412
00:30:01,050 --> 00:30:03,900
so to do to pull these things apart

413
00:30:03,920 --> 00:30:05,590
you need to be clever

414
00:30:05,610 --> 00:30:11,440
you need to use the tools of behavioral genetics and to use these tools you

415
00:30:11,440 --> 00:30:17,280
have to exploit certain regularities about genes and the environment

416
00:30:17,300 --> 00:30:19,130
one thing is this

417
00:30:19,130 --> 00:30:21,090
some people are clones

418
00:30:21,110 --> 00:30:26,970
one i got twins are genetic duplicate they share hundred percent the same genes

419
00:30:27,010 --> 00:30:29,130
that's kind of interest

420
00:30:29,170 --> 00:30:31,420
dies i got the twins

421
00:30:31,440 --> 00:30:32,780
are not clones

422
00:30:32,780 --> 00:30:37,010
they share fifty fifty they're just like regular what's

423
00:30:37,800 --> 00:30:42,860
adopted siblings have no special genetic overlap

424
00:30:42,900 --> 00:30:44,490
that's zero percent

425
00:30:44,490 --> 00:30:47,760
above and beyond randomness

426
00:30:47,780 --> 00:30:48,840
those three

427
00:30:48,860 --> 00:30:51,530
groups then become rather interesting

428
00:30:52,240 --> 00:30:55,760
particularly when we keep in mind that by definition

429
00:30:55,780 --> 00:30:59,880
two people raising in the same house by the same parents have a hundred percent

430
00:30:59,880 --> 00:31:04,530
the same share environment

431
00:31:04,610 --> 00:31:05,460
so now

432
00:31:05,470 --> 00:31:07,530
we start to answer these questions

433
00:31:07,550 --> 00:31:12,570
suppose you find my i got the twins are much more similar than dies i

434
00:31:12,570 --> 00:31:13,990
got it twins

435
00:31:13,990 --> 00:31:18,030
well i would suggest that there is a large role of genes

436
00:31:18,070 --> 00:31:21,920
in those traits that you are interested in it wouldn't since the matter

437
00:31:21,970 --> 00:31:26,260
because there are other factors that were for instance models i got twins

438
00:31:26,320 --> 00:31:27,820
look more like

439
00:31:27,880 --> 00:31:32,190
then dies i got twins and maybe they have different and they have more similar

440
00:31:32,190 --> 00:31:37,590
environments because of this similarity in appearance

441
00:31:37,610 --> 00:31:41,760
our minors got it which is the similar-sized about twenty if

442
00:31:41,820 --> 00:31:46,880
and we showed that all that extra overlapping genes doesn't really matter

443
00:31:46,940 --> 00:31:50,130
so i would suggest low role of heredity

444
00:31:50,150 --> 00:31:55,970
are adopted children highly similar to the brothers and sisters

445
00:31:55,970 --> 00:31:57,110
if so

446
00:31:57,110 --> 00:32:01,860
and there's a high role of share environment supposed to bloom children

447
00:32:01,880 --> 00:32:04,090
and there's seven of

448
00:32:04,110 --> 00:32:07,690
all have an IQ of one hundred four

449
00:32:07,690 --> 00:32:10,130
and we adopt three kids

450
00:32:10,130 --> 00:32:14,170
and then attended a those three each have an IQ of one hundred four

451
00:32:14,190 --> 00:32:18,550
that would suggest that and we do this over and over again across different families

452
00:32:18,840 --> 00:32:21,920
that would suggest or something about the bloom family

453
00:32:21,920 --> 00:32:23,340
being raised

454
00:32:23,340 --> 00:32:24,490
by me

455
00:32:24,510 --> 00:32:28,420
that gives you an IQ of one hundred four

456
00:32:28,440 --> 00:32:32,990
on the other hand if the IQ of the topic is had no relationship

457
00:32:33,920 --> 00:32:38,760
those of the biological children it was suggested being raised by me has no effect

458
00:32:38,760 --> 00:32:42,050
really in your IQ is sort of separate

459
00:32:42,110 --> 00:32:45,030
a separate a second final

460
00:32:45,030 --> 00:32:47,440
contrast which is the thing

461
00:32:47,470 --> 00:32:49,920
that psychologists love

462
00:32:50,630 --> 00:32:53,300
identical twins reared apart

463
00:32:53,320 --> 00:32:55,050
that's the gold standard

464
00:32:55,170 --> 00:33:00,760
but you know these people were clones but they are raised in different families and

465
00:33:00,780 --> 00:33:02,030
to the extent

466
00:33:02,070 --> 00:33:06,720
there they are similar this suggests the similarity of their genes

467
00:33:06,740 --> 00:33:08,990
and in fact

468
00:33:09,010 --> 00:33:14,110
one of the one of the most surprising findings in behavioral genetics and the caption

469
00:33:14,110 --> 00:33:18,740
here separated at birth malabar twins meet accidentally

470
00:33:18,740 --> 00:33:22,170
and at the patent office with the same device

471
00:33:22,170 --> 00:33:27,050
one of usually surprising findings from behavioural genetics is how alike

472
00:33:27,070 --> 00:33:29,400
identical twins reared apart are

473
00:33:29,420 --> 00:33:32,470
they seem to have similar attitudes to death penalty

474
00:33:32,470 --> 00:33:38,070
to religion into modern music there have similar rates of behavior in crime gambling and

475
00:33:38,170 --> 00:33:43,220
force they often have been found to have bizarre similarities

476
00:33:43,220 --> 00:33:48,030
they meet after being separated at birth and immediate aged thirty and then it turns

477
00:33:48,030 --> 00:33:49,380
out that be both

478
00:33:49,400 --> 00:33:52,990
given to a lot of trouble because they pretend sneeze and elevators

479
00:33:53,460 --> 00:33:58,650
there was one one pair twins study by and behavioral geneticists were known as the

480
00:33:58,650 --> 00:34:00,110
giggle twins

481
00:34:00,130 --> 00:34:04,190
because they were both would always legally burst into giggles at every moment

482
00:34:04,570 --> 00:34:08,860
even though it couldn't be environment because they were raised together

483
00:34:09,150 --> 00:34:11,670
more objectively

484
00:34:11,690 --> 00:34:13,860
the brain scans

485
00:34:13,880 --> 00:34:17,920
of identical twins reared apart

486
00:34:17,940 --> 00:34:23,050
show that their brains are so similar in many cases you can tell whose brains

487
00:34:24,260 --> 00:34:28,010
i could tell your brain from my brain from the brain scan and my my

488
00:34:28,010 --> 00:34:31,820
brother's brain from my brain from brain scan but if i would have an identical

489
00:34:31,820 --> 00:34:35,720
twin would be very difficult to tell whose brain assumes even if we had no

490
00:34:35,720 --> 00:34:38,570
environment in common

491
00:34:38,590 --> 00:34:43,300
so this leads to too surprising findings of behavioral genetics

492
00:34:43,440 --> 00:34:46,320
this is the first one

493
00:34:46,550 --> 00:34:50,010
high heritability for almost everything

494
00:34:50,030 --> 00:34:52,110
four intelligence

495
00:34:52,110 --> 00:34:56,920
her personality for how happy you are how religious you are

496
00:34:56,970 --> 00:34:59,650
four europe political orientation

497
00:34:59,670 --> 00:35:02,010
there are three your sexual orientation

498
00:35:02,090 --> 00:35:07,570
there's high heritability there's a high effective genes for just about everything

499
00:35:09,780 --> 00:35:13,190
actually not the controversial thing i'm going to tell you

500
00:35:13,240 --> 00:35:17,820
but before getting to the more controversial thing i want to raise another issue which

501
00:35:17,820 --> 00:35:20,780
often gets discussed and has good treatment textbook

502
00:35:20,800 --> 00:35:26,570
this suggests that individual differences within this within group have genetic causes

503
00:35:26,590 --> 00:35:28,740
does that mean that group differences

504
00:35:28,760 --> 00:35:30,150
are largely

505
00:35:30,170 --> 00:35:32,470
the result of genetic causes

506
00:35:32,490 --> 00:35:33,900
so we know

507
00:35:33,920 --> 00:35:38,490
there are clear differences in IQ scores among american racial groups

508
00:35:38,510 --> 00:35:43,150
between whites and asians african-americans ashkenazi jews

509
00:35:43,220 --> 00:35:48,320
it is clear reliable IQ differences as well as some other differences

510
00:35:49,220 --> 00:35:50,630
to some extent

511
00:35:50,650 --> 00:35:53,740
these groups are partially socially constructed

512
00:35:54,110 --> 00:35:57,520
and what this means is that whether or not you fall into the into a

513
00:35:57,520 --> 00:36:03,630
group is not entirely determined by your genetic makeup is often determined by social decisions

514
00:36:03,630 --> 00:36:09,280
so whether or not you can institute for instance depends not entirely on genetic factors

515
00:36:09,340 --> 00:36:14,920
but also on factors such as whether you're reformed orthodox and whether you so whether

516
00:36:14,920 --> 00:36:19,820
you would accept that the child of a jewish man a non-jewish woman

517
00:36:19,860 --> 00:36:21,010
is jewish

518
00:36:21,030 --> 00:36:28,240
similarly categories the african-american and white and asian often overlap right genetic categories and they

519
00:36:28,240 --> 00:36:29,510
don't make

520
00:36:29,510 --> 00:36:31,510
fully coherent genetic sense

521
00:36:31,530 --> 00:36:34,470
at the same time though

522
00:36:34,530 --> 00:36:37,780
there's plainly some genetic differences across human groups

523
00:36:37,800 --> 00:36:43,610
and i said with regard to vulnerability to disease ashkenazi jews for instance are vulnerable

524
00:36:43,610 --> 00:36:44,780
to taste sex

525
00:36:44,780 --> 00:36:48,800
and in fact it had this sort of genetic vulnerability suggested to some sort of

526
00:36:48,800 --> 00:36:50,900
reality to these groups

527
00:36:50,920 --> 00:36:53,460
so you have to ask the question now

528
00:36:53,470 --> 00:36:56,050
to what extent

529
00:36:56,070 --> 00:36:58,030
does the high heritability

530
00:36:58,050 --> 00:36:59,440
in individuals

531
00:36:59,440 --> 00:37:04,760
i mean it has to be heritable explanation across groups and the answer is

532
00:37:04,820 --> 00:37:07,260
not at all

533
00:37:07,280 --> 00:37:10,780
i'm not saying that this means that there is no genetic explanation for human group

534
00:37:10,780 --> 00:37:17,820
differences all i'm saying is the question of the phenomenon of within group genetic differences

535
00:37:17,840 --> 00:37:21,470
does not mean that there's across groups

536
00:37:21,490 --> 00:37:23,860
genetic trait between groups

537
00:37:23,860 --> 00:37:35,420
and so forth okay okay so that process that I've just described basically takes a tree and

538
00:37:35,420 --> 00:37:40,340
then interpreted it as a sequence of partitions where each partition in the sequence it's

539
00:37:40,340 --> 00:37:46,880
a refinement or a  fragmentation of the of the previous partition okay so we started

540
00:37:46,980 --> 00:37:51,300
off with the trivial partition we broke it we broke it up into three

541
00:37:51,330 --> 00:37:57,720
different clusters we broke this one up into two this one into two and so forth until

542
00:37:57,720 --> 00:38:03,980
until every species belongs to its own cluster so this describes a tree as a sequence

543
00:38:03,980 --> 00:38:12,510
of fragmenting partitions so we can construct a prior over trees if you can construct

544
00:38:12,520 --> 00:38:21,130
a prior over such a sequence of partitions we might actually look at that in the other

545
00:38:21,160 --> 00:38:26,560
way think of a linkage algorithm where you start off with all the different species

546
00:38:26,560 --> 00:38:31,900
in this own cluster and then we iteratively merge two clusters two clusters

547
00:38:31,900 --> 00:38:38,880
together into one so this reverse process is a sequence of partitions again but is

548
00:38:38,880 --> 00:38:45,420
now gonna be a sequence of coagulated partitions so each step of this sequence will

549
00:38:45,420 --> 00:38:51,440
take two or more clusters and merge them into one single cluster and this forms a

550
00:38:51,440 --> 00:38:56,960
tree but now in the bottom up fashion so again this is a sequence of partitions

551
00:38:56,960 --> 00:39:03,060
but now is going in the other direction and again if we can define

552
00:39:03,060 --> 00:39:08,860
a prior over this sort of sequence of coagulating partitions we'll again have a prior over

553
00:39:08,860 --> 00:39:18,610
trees so the best nice which I'll tell about is how we might construct this sort

554
00:39:18,610 --> 00:39:28,540
of random coagulations and random fragmentations to do that let's think

555
00:39:28,540 --> 00:39:35,400
a bit more about what coagulations are and what fragmentations are so let's imagine that

556
00:39:35,400 --> 00:39:44,800
we start off with some partition like this okay a fragmentation is one where

557
00:39:44,810 --> 00:39:50,870
a coagulation is one where we might take a few of these clusters and

558
00:39:50,880 --> 00:39:58,360
merge them together okay so and we can describe a coagulation using a partition

559
00:39:58,360 --> 00:40:06,720
as well but now it's a partition where the elements of the partition are the clusters in this

560
00:40:06,720 --> 00:40:11,580
in in  row one okay so the elements here are A B C D

561
00:40:11,600 --> 00:40:17,220
where A is this cluster B is that cluster C is that cluster and D is that cluster and

562
00:40:17,220 --> 00:40:24,440
what this partition describes is a coagulation where we basically merge A and B so this

563
00:40:24,440 --> 00:40:34,940
produces a coagulated partition where A and B has been merged here the reverse process is fragmentation

564
00:40:34,940 --> 00:40:42,000
and what this fragmentation do is basically takes each of this clusters and possibly fragmenting

565
00:40:42,000 --> 00:40:47,560
it up into multiple clusters so the reverse process here can also be described in

566
00:40:47,560 --> 00:40:53,920
terms of partitions but now it's gonna be one partition for every cluster in C

567
00:40:53,920 --> 00:41:01,840
okay so here we've described this fragmentation process as three different partitions one for this

568
00:41:01,880 --> 00:41:06,280
cluster one for that cluster and one for that cluster  in this case the only

569
00:41:06,370 --> 00:41:18,180
non trivial fragmentation is in this cluster here well these two are basically trivial fragmentations so

570
00:41:18,180 --> 00:41:26,500
those are coagulation and fragmentation operators and basically we see that both coagulations and fragmentations can

571
00:41:26,500 --> 00:41:34,260
be described in terms of of partitons themselves and since we already know some prior

572
00:41:34,260 --> 00:41:40,100
over partitions particularly the Chinese restaurant process we can reuse those priors to build random

573
00:41:40,100 --> 00:41:46,200
coagulations and random fragmentations so that is defined what is a random fragmentation

574
00:41:46,380 --> 00:41:54,560
a random fragmentation is simply the following so given C we'd like to build a random fragmentation

575
00:41:54,600 --> 00:42:00,560
row one of C where F one F two and F three are basically partitions

576
00:42:00,560 --> 00:42:04,940
which are drawn from a CRP with parameters D and alpha and if that's the

577
00:42:04,940 --> 00:42:10,880
case then   we say that row one is a fragmentation of a random fragmentation of C

578
00:42:10,880 --> 00:42:17,680
with parameters D and alpha okay so this producers for us a random fragmentation of this partition

579
00:42:17,690 --> 00:42:29,540
C similarly a random coagulation now going from row one to C is gonna be

580
00:42:29,540 --> 00:42:38,520
one where the partition which describes the the coagulation is drawn from a CRP with

581
00:42:38,520 --> 00:42:43,840
parameters D and alpha in that case  we call C a random coagulation of

582
00:42:43,840 --> 00:42:50,600
row one with parameters D and alpha and and and that's it so now with random coagulations

583
00:42:50,600 --> 00:42:58,440
and fragmentations we can now look at random trees by construct them by constructing

584
00:42:58,440 --> 00:43:05,520
these sort of sequences where this might be a sequence of random coagulations and this

585
00:43:05,520 --> 00:43:12,220
might be a sequence of random fragmentations and if you do that then you can

586
00:43:12,220 --> 00:43:22,520
get basically a random trees out of these things any questions on this yes

587
00:43:22,540 --> 00:43:31,120
yeah you kind of have to choose either to look at it in a top-down

588
00:43:31,120 --> 00:43:41,420
manner or buttom up manner so I guess I won't really go into detail for

589
00:43:41,420 --> 00:43:45,660
for the various processes but just kind of  give you a few examples okay so

590
00:43:45,660 --> 00:43:52,760
here's an example called the nested Chinese restaurant process by Dave Blei and this

591
00:43:52,760 --> 00:44:01,860
Chinese restaurant process works as follows so at the top of this hierarchy you have

592
00:44:01,860 --> 00:44:09,140
a number of customers and you sit  the customers around a bunch of tables

593
00:44:09,160 --> 00:44:15,260
right so this is  the usual Chinese restaurant process here we have five customers

594
00:44:15,260 --> 00:44:22,940
we sit them around three tables you take each of the tables in our restaurant

595
00:44:22,940 --> 00:44:29,900
so this one and we will send the customers sitting around that table to

596
00:44:29,900 --> 00:44:37,140
another restaurants where they might sit around a certain number of tables again so we send

597
00:44:37,140 --> 00:44:41,920
this two customers to this restaurant and they sit in different tables we send this two

598
00:44:41,920 --> 00:44:46,620
problem matrix vector product kind thing so that's eight transpose eight times x

599
00:44:47,390 --> 00:44:48,580
so you get this equation

600
00:44:51,750 --> 00:44:54,320
the matrix a transpose they should be invertible

601
00:44:55,030 --> 00:44:57,140
that would be an assumption i guess to do this regression

602
00:44:57,830 --> 00:44:59,420
and you can then solve for x x-bar

603
00:45:00,070 --> 00:45:06,170
is a transposing inverse transpose be that's probably a formula you've all seen before i'm guessing if you've taken

604
00:45:06,640 --> 00:45:08,790
regression coarsening guessing most if you have

605
00:45:12,330 --> 00:45:12,910
support i'm

606
00:45:13,470 --> 00:45:14,850
presume that that's familiar r

607
00:45:16,490 --> 00:45:18,270
let's talk about least absolute deviations

608
00:45:18,980 --> 00:45:19,870
it's similar

609
00:45:20,580 --> 00:45:23,480
to the kind-of pearl we had with means and medians

610
00:45:24,270 --> 00:45:28,170
so now we have the sum of the absolute values instead of the sum of the squares

611
00:45:30,080 --> 00:45:34,220
so we dusty el one norm if you like so we can write that way

612
00:45:37,010 --> 00:45:40,490
and so it is the function of which is the sum of the absolute deviations

613
00:45:41,540 --> 00:45:43,760
i do exactly like before i take the derivative

614
00:45:45,210 --> 00:45:48,070
but now i'm taking the derivative of the absolute value function

615
00:45:48,560 --> 00:45:50,520
and chosen the right there in this way

616
00:45:51,070 --> 00:45:53,550
the derivative of the absolute value of x

617
00:45:56,300 --> 00:45:56,950
the derivative

618
00:45:58,580 --> 00:45:59,790
the absolute value x

619
00:46:00,410 --> 00:46:05,360
can be written as x divided by the value of x cosmetics pos positive that's one

620
00:46:05,780 --> 00:46:09,530
when x is negative that's minus one and we're not going to worry about

621
00:46:10,060 --> 00:46:12,010
little places where the drug doesn't exist

622
00:46:16,220 --> 00:46:17,140
this is the derivative

623
00:46:17,820 --> 00:46:21,910
the sum of the derivative at which is this expression here and by the chain

624
00:46:21,910 --> 00:46:25,990
rule would take the derivative inside were looking through the spectre x kay

625
00:46:26,730 --> 00:46:30,380
this is a concept that doesn't have that gives us nothing that we get the

626
00:46:30,380 --> 00:46:32,910
minus sign and as i take this someone jay

627
00:46:33,500 --> 00:46:37,620
all these are zero because the x jay-z except for the one jay-z equal decay

628
00:46:38,060 --> 00:46:43,620
and then i get a-okay so that's right here is the derivative inside the sum with respect to x kay

629
00:46:44,080 --> 00:46:47,080
so we want this derivative to be equal to zero

630
00:46:47,530 --> 00:46:50,960
the value of x that achieves that's cortex hat

631
00:46:51,370 --> 00:46:52,970
to distinguish it from x-bar

632
00:46:53,930 --> 00:46:59,320
so there will be leaving analog and the median will be the least absolute deviation regression coefficients

633
00:47:00,530 --> 00:47:01,840
that's what get with x hat

634
00:47:02,580 --> 00:47:06,550
end again we break this up into the two pieces just like i did before r

635
00:47:06,680 --> 00:47:08,290
the beast stuff on one side only

636
00:47:09,030 --> 00:47:13,620
and any x jay stuff on the either side and i get an equation that looks like this

637
00:47:17,160 --> 00:47:18,250
kind of good and bad

638
00:47:19,230 --> 00:47:23,690
it's good and it almost looks like the equation we had before r and in fact

639
00:47:24,160 --> 00:47:27,980
if we are careful all i should say these epsilon denominator

640
00:47:28,420 --> 00:47:33,670
are just these absolute value expressions here so i just summarize that's as abseil on

641
00:47:34,220 --> 00:47:35,110
i guess i forgot that

642
00:47:36,300 --> 00:47:37,610
mentioned on the slide here

643
00:47:40,370 --> 00:47:44,380
except for those abseil on this is exactly the same thing we had before r

644
00:47:45,820 --> 00:47:49,670
and if i write this a matrix notation this is how this appears to be

645
00:47:49,680 --> 00:47:55,200
epsilon i because this depends on i goes between me and the baby

646
00:47:55,740 --> 00:48:01,430
because that's eight transpose kay i that distance be i i and similarly

647
00:48:01,930 --> 00:48:04,350
o i forgot they either to titles

648
00:48:04,970 --> 00:48:05,410
yeah thanks

649
00:48:06,320 --> 00:48:07,000
this is supposed to be

650
00:48:07,600 --> 00:48:10,930
epsilon so i also and it goes between e eight

651
00:48:11,370 --> 00:48:14,290
okay i transpose they i j goes in the air

652
00:48:15,030 --> 00:48:18,560
and so if we write this in matrix notation it's eight transpose

653
00:48:19,790 --> 00:48:20,990
that's had times be

654
00:48:21,990 --> 00:48:27,240
were effects had is a diagonal matrix with these apps epsilons along the diagonal

655
00:48:27,690 --> 00:48:29,210
is the inverse the matrix

656
00:48:29,870 --> 00:48:34,560
as the diameter one over epsilon s on the diagonal that's exactly accounting for

657
00:48:35,110 --> 00:48:40,530
this factor here and the same thing appears on the right-hand side it appears between a transpose and they

658
00:48:41,510 --> 00:48:46,810
so again assuming that the matrix multiplying by x is invertible in this case it's this thing

659
00:48:47,240 --> 00:48:48,790
we can solve for x hat

660
00:48:49,680 --> 00:48:56,030
x hat should be equal to the inverse matrix times a transpose e all x had known

661
00:48:56,670 --> 00:48:57,610
that's the problem isn't it

662
00:48:58,030 --> 00:49:00,370
x have appears on the right hand on the left

663
00:49:01,410 --> 00:49:04,280
and i suppose this is part of the reason why statisticians like

664
00:49:04,850 --> 00:49:07,170
least-squares better than least absolute deviations

665
00:49:07,770 --> 00:49:12,710
we don't get a simple formula here we get of well we don't get an equation we get a formula

666
00:49:13,160 --> 00:49:14,930
this formula must be satisfied

667
00:49:15,950 --> 00:49:19,470
but unfortunately it's not equation doesn't say x at equal something

668
00:49:20,450 --> 00:49:22,370
that doesn't involve x at rather

669
00:49:22,870 --> 00:49:23,890
this is just some

670
00:49:24,310 --> 00:49:25,710
something that's true and

671
00:49:26,180 --> 00:49:31,440
equation is true we are fine you except that satisfies this there's two is defined

672
00:49:32,240 --> 00:49:33,960
i'll give you a simple algorithmic way

673
00:49:34,360 --> 00:49:36,890
and also tell how defined by linear programming

674
00:49:39,000 --> 00:49:40,430
and we can debate which way is better

675
00:49:42,580 --> 00:49:45,680
so here's this simple methods that

676
00:49:46,790 --> 00:49:48,760
avoids directly using linear programming

677
00:49:51,090 --> 00:49:53,350
it's called the methods successive approximations

678
00:49:54,530 --> 00:49:54,960
comes up

679
00:49:56,030 --> 00:49:59,090
many many many places on

680
00:49:59,960 --> 00:50:01,470
whenever you have something like

681
00:50:04,030 --> 00:50:07,660
equals some function of x some implicit function like this

682
00:50:08,620 --> 00:50:11,740
you can always consider solving this equation

683
00:50:13,130 --> 00:50:16,350
saying okay i'm gonna start with x being equal the sum gas

684
00:50:16,780 --> 00:50:17,850
what's the simplest gas

685
00:50:18,280 --> 00:50:19,120
anything you like

686
00:50:20,000 --> 00:50:20,980
i'll just say zero

687
00:50:21,600 --> 00:50:22,830
this will be my first guess

688
00:50:23,710 --> 00:50:25,440
and then i can update this guess

689
00:50:26,300 --> 00:50:27,130
i can say well look

690
00:50:29,090 --> 00:50:32,300
maybe that's a better guess x one let x one be apathetic zero

691
00:50:33,590 --> 00:50:36,940
you have to prove that it's better might not be but it's certainly reasonable

692
00:50:37,420 --> 00:50:37,890
thing to do

693
00:50:38,270 --> 00:50:39,140
data suggest

694
00:50:39,730 --> 00:50:42,840
and then maybe if you keep doing this maybe gets better and better

695
00:50:45,100 --> 00:50:46,190
keep doing this forever

696
00:50:46,680 --> 00:50:47,510
and take the limit

697
00:50:50,170 --> 00:50:54,560
and if f is continuous at the limit the x's exists

698
00:50:54,980 --> 00:50:55,690
then you would have

699
00:50:56,210 --> 00:50:56,930
this equation

700
00:50:57,540 --> 00:51:00,090
which we say that x infinity is the thing that you want

701
00:51:00,840 --> 00:51:04,180
so requires us to assume that f is a continuous function

702
00:51:04,630 --> 00:51:09,310
requires just assume that we can prove that the sequence of limit and if you

703
00:51:09,630 --> 00:51:12,860
can prove those two statements that this process gives u

704
00:51:12,860 --> 00:51:18,550
was given by this expression and this also is a way to specify time

705
00:51:18,750 --> 00:51:24,940
now the expansion rate of the universe is a key quantity

706
00:51:24,940 --> 00:51:29,860
and again let me emphasize that the expansion rate of the universe comes from the

707
00:51:29,870 --> 00:51:33,390
zero zero component of the Einstein equations

708
00:51:34,140 --> 00:51:38,220
and In terms of a ratio to a critical density

709
00:51:38,250 --> 00:51:44,990
we can write the Friedmann equation expression expressing this expansion rate as a function

710
00:51:44,990 --> 00:51:49,960
of redshift in terms of a couple of parameters which we can measure

711
00:51:51,880 --> 00:51:56,960
so one thing we can measure today is the present value of the expansion rate or Hubble's

712
00:51:58,140 --> 00:52:00,310
that would be value

713
00:52:02,940 --> 00:52:06,310
now how it scales with

714
00:52:06,360 --> 00:52:07,790
with redshift

715
00:52:08,180 --> 00:52:10,460
there will be a contribution

716
00:52:10,480 --> 00:52:15,070
of Omega radiation which scales as one plus Z to the fourth

717
00:52:15,400 --> 00:52:20,530
a contribution to matter which scales as one plus Z Q

718
00:52:20,550 --> 00:52:25,140
a curvature contribution which scales as one plus Z squared

719
00:52:25,360 --> 00:52:28,860
the contribution in radiation

720
00:52:28,860 --> 00:52:35,640
can be very accurately measured from measurements of the cosmic microwave background radiation

721
00:52:35,950 --> 00:52:39,090
Omega in matter can be

722
00:52:39,180 --> 00:52:46,530
tolerably well measured by several methods looking at large scale structure in the universe

723
00:52:46,750 --> 00:52:52,720
this curvature turn one minus omega total can be measured to pretty good accuracy from the

724
00:52:54,310 --> 00:53:00,830
then there's this other turn which looks like a fudge factor

725
00:53:00,880 --> 00:53:07,120
so this is the expression for the expansion rate in terms of things we know

726
00:53:08,090 --> 00:53:12,900
if this doesn't fit the data then you add another term and call it dark

727
00:53:14,900 --> 00:53:22,790
naming is not explaining so the origin of this term is you measure H of Z

728
00:53:22,790 --> 00:53:27,640
and if you can't fit it with these three terms you add another term and you

729
00:53:27,640 --> 00:53:29,860
say you've discovered dark energy

730
00:53:29,990 --> 00:53:37,180
and I've already described the equation of state parameter

731
00:53:37,400 --> 00:53:44,030
now in terms of dark energy and acceleration

732
00:53:45,840 --> 00:53:49,450
they enter into

733
00:53:49,460 --> 00:53:54,230
the dark energy ventures into the acceleration

734
00:53:54,330 --> 00:54:01,460
recall the dynamical equation for the acceleration A double dot over A

735
00:54:01,460 --> 00:54:07,290
it depends on the energy density plus three-times the pressure

736
00:54:07,770 --> 00:54:14,220
so there is a Newtonian contribution the acceleration is equal to minus G rho

737
00:54:14,280 --> 00:54:19,480
is just a Newtonian result that's what you would expect in a Newtonian world

738
00:54:20,030 --> 00:54:22,720
however there is a relativistic

739
00:54:22,730 --> 00:54:25,810
correction that involves the pressure

740
00:54:26,420 --> 00:54:30,070
and you can think of the origin of this

741
00:54:30,090 --> 00:54:35,730
by the idea that pressure is related to kinetic energy density

742
00:54:35,770 --> 00:54:41,790
and Einstein says not only does rest mass energy contribute to the stress energy

743
00:54:41,830 --> 00:54:44,900
but kinetic Energy does also

744
00:54:45,400 --> 00:54:51,140
so the acceleration is not minus G times rho as you would expect in a Newtonian world

745
00:54:51,960 --> 00:54:55,550
but it is minus G times rho plus three P

746
00:54:56,510 --> 00:55:02,060
now in the standard cosmology before nineteen ninety eight

747
00:55:02,700 --> 00:55:09,830
expected the universe to emerge from a bang thirteen point seven eight billion years ago last

748
00:55:11,570 --> 00:55:18,360
and to evolve in such a way with the accelerate with the scale factor decelerating

749
00:55:18,360 --> 00:55:21,490
so it is curved in this direction

750
00:55:21,570 --> 00:55:25,940
because A double dot is minus G times rho

751
00:55:25,940 --> 00:55:29,850
if you would expect rho plus three P to be positive

752
00:55:30,180 --> 00:55:36,420
so you would have A double dot negative you would have a deceleration

753
00:55:36,460 --> 00:55:42,550
however if you measure evidence for an acceleration of the universe A double dot greater than

754
00:55:43,960 --> 00:55:49,480
within this framework you found evidence for rho plus three P to be negative

755
00:55:49,570 --> 00:55:54,660
and to do this you require that the universe is dominated today

756
00:55:54,900 --> 00:55:56,810
by a fluid

757
00:55:57,750 --> 00:56:00,050
In equation of state parameter

758
00:56:00,090 --> 00:56:03,200
P over rho smaller than one-third

759
00:56:03,660 --> 00:56:08,530
here are some

760
00:56:08,560 --> 00:56:12,860
solutions for a flat model for K equal to zero

761
00:56:12,860 --> 00:56:19,070
for whith showing a universe without a cosmological constant just with matter in purple

762
00:56:19,230 --> 00:56:25,790
and whith values of a cosmological constant that has omega lambda of point seven or

763
00:56:25,810 --> 00:56:28,790
omega lambda of point nine

764
00:56:28,840 --> 00:56:36,090
so if you can somehow look out in space back in time you can trace the

765
00:56:37,680 --> 00:56:45,140
between these different types of solutions to see whether the universe is accelerating or decelerating

766
00:56:45,190 --> 00:56:49,810
and within this framework you can find evidence for omega lambda

767
00:56:50,310 --> 00:56:53,490
you can also do this by looking into the future

768
00:56:53,510 --> 00:56:58,590
but that requires a lot of patience so if you can look out in space

769
00:56:58,620 --> 00:57:00,790
back in time far enough

770
00:57:00,830 --> 00:57:05,380
you can see the difference in these types of solutions to see whether there is

771
00:57:05,380 --> 00:57:13,720
evidence of a cosmological constant and you see if there is a cosmological constant dominating the universe

772
00:57:13,720 --> 00:57:16,250
is accelerating

773
00:57:16,290 --> 00:57:19,660
also notice for future

774
00:57:19,750 --> 00:57:24,980
the age of the universe depends upon the value of lambda

775
00:57:24,990 --> 00:57:28,980
if there is no cosmological constant

776
00:57:28,980 --> 00:57:31,390
for a spatially flat universe

777
00:57:31,440 --> 00:57:35,330
the page is less than ten billion years

778
00:57:35,460 --> 00:57:40,740
this will be other evidence that there should be a cosmological constant to push the

779
00:57:40,750 --> 00:57:42,810
age of the universe

780
00:57:43,720 --> 00:57:48,160
so the program we want to have is to look out in space back in time

781
00:57:48,160 --> 00:57:50,770
to see which track we're on

782
00:57:50,790 --> 00:57:59,380
to see whether there is dark energy and this program was started by a

783
00:57:59,380 --> 00:58:02,360
University of Chicago alumn

784
00:58:02,360 --> 00:58:06,010
so I'll talk a little bit about our university of Chicago alumn

785
00:58:06,590 --> 00:58:12,960
and I went into the archives at Chicago and red descriptions in letters of recommendation

786
00:58:12,960 --> 00:58:19,400
of this famous University of Chicago alumn and the description of this person written

787
00:58:19,420 --> 00:58:27,120
by the professors at Chicago are pretty strange they talk about his physique they say physically he is

788
00:58:27,120 --> 00:58:31,970
a splendid specimen he has a magnificent physique he's manly and he has a

789
00:58:31,970 --> 00:58:38,270
lovable character now I know when you think of a University of Chicago alumn

790
00:58:38,360 --> 00:58:46,290
that this describes you immediately think of Jack Steinberger but in fact it's also Jack of course

791
00:58:46,400 --> 00:58:50,790
what's actually is description in letters of recommendation of Edwin Hubble

792
00:58:51,080 --> 00:58:58,120
who was manly in fact he was a basketball player at the University of Chicago

793
00:58:58,120 --> 00:59:04,180
a member of the last decent athletic team that the University of Chicago the

794
00:59:04,190 --> 00:59:08,400
nineteen-o-nine national championship basketball team

795
00:59:08,490 --> 00:59:15,830
and Hubble measured the veloc the present velocity of the universe and this is a graph

796
00:59:15,830 --> 00:59:21,640
from his discovery paper of the expansion of the universe in nineteen twenty-nine

797
00:59:21,860 --> 00:59:27,810
so you notice a couple of amazing things about this paper first of all

798
00:59:27,830 --> 00:59:36,460
the units for velocity are wrong he was at basketball practice that day when they talked about the units for

799
00:59:36,460 --> 00:59:38,450
run times

800
00:59:38,450 --> 00:59:40,220
this is an old algorithm that

801
00:59:40,240 --> 00:59:43,520
so all the ends like formulation directly and i can see

802
00:59:43,600 --> 00:59:48,490
the number of constraints keeps growing with the number of training examples

803
00:59:48,500 --> 00:59:52,710
and the new formulation not only the bound tells you us a constant number

804
00:59:52,760 --> 00:59:55,920
but actually empirically pretty constant numbers one

805
00:59:55,960 --> 00:59:59,970
and you can see the here we have to solve quadratic programs in the old

806
00:59:59,970 --> 01:00:02,540
formulation like hundred of brain

807
01:00:02,600 --> 01:00:04,710
years of is less than

808
01:00:04,780 --> 01:00:05,710
even before

809
01:00:05,710 --> 01:00:11,970
this is one HMM state part of speech tagging problem like almost a million words

810
01:00:11,970 --> 01:00:13,470
and if you look at runtime

811
01:00:13,490 --> 01:00:20,980
compared to the number of training examples new actually really has linear

812
01:00:22,700 --> 01:00:23,720
we have

813
01:00:23,970 --> 01:00:28,940
very efficient way of solving it

814
01:00:30,980 --> 01:00:32,430
step back again

815
01:00:32,490 --> 01:00:34,270
so not only do we have

816
01:00:34,500 --> 01:00:40,550
formulation is probably also have a very general out

817
01:00:40,570 --> 01:00:43,400
in particular if i wanted to apply

818
01:00:43,900 --> 01:00:46,670
this method to a new set of problems

819
01:00:46,680 --> 01:00:49,380
also in terms of implementation

820
01:00:49,390 --> 01:00:51,660
i can we use lot of work

821
01:00:51,680 --> 01:00:55,790
comes from the general framework although we have to implement a new loss function

822
01:00:55,850 --> 01:00:57,690
a new representation

823
01:00:58,860 --> 01:01:02,470
methods for solving these two are not a problem to me is actually

824
01:01:02,540 --> 01:01:03,490
this is doing

825
01:01:03,510 --> 01:01:09,730
fiction this is we're doing this separation oracle find the most violated constraint

826
01:01:10,500 --> 01:01:12,780
and all the rest is just a c

827
01:01:12,930 --> 01:01:17,600
if you want to try to actually is the general grows on my my webpage

828
01:01:17,610 --> 01:01:19,560
called SVM struct

829
01:01:22,220 --> 01:01:25,250
so in a sense it's kind of the place at the right

830
01:01:25,320 --> 01:01:29,310
and we want to demonstrate in the rest of the talk is how we can

831
01:01:29,310 --> 01:01:32,110
take this general was and just like in

832
01:01:35,230 --> 01:01:40,660
by keeping actually most of the code the same

833
01:01:40,710 --> 01:01:42,830
so the article i want to talk about these three

834
01:01:43,730 --> 01:01:47,750
sequence alignment classification of search results unsupervised clustering

835
01:01:47,770 --> 01:01:48,480
and so

836
01:01:48,520 --> 01:01:56,060
what i have to do for each phi loss function specify representation and that you

837
01:01:56,930 --> 01:02:01,230
let's start with the sequence alignment problem and see how it goes there

838
01:02:01,790 --> 01:02:03,770
the holy grail

839
01:02:03,790 --> 01:02:10,600
one of the holy grail in bioinformatics is

840
01:02:10,640 --> 01:02:15,870
given the sequence of amino acids predict what this structure

841
01:02:15,930 --> 01:02:19,580
well it would be nice if you could directly solve the structured prediction problem but

842
01:02:19,580 --> 01:02:21,040
i don't know how to do that

843
01:02:21,060 --> 01:02:26,930
the problem is that the search space structures is really big what we have a

844
01:02:26,930 --> 01:02:28,790
good understanding of physics

845
01:02:28,790 --> 01:02:32,730
it's just too expensive to do is search directly

846
01:02:32,750 --> 01:02:34,230
so what people typically do

847
01:02:34,310 --> 01:02:39,200
one of the methods that uses what's called content modelling

848
01:02:39,870 --> 01:02:43,680
you have a set of known structures and it turns out that proteins

849
01:02:43,730 --> 01:02:46,350
i've come in families and they don't really fall into

850
01:02:46,620 --> 01:02:49,060
a folding arbitrary structures like

851
01:02:49,100 --> 01:02:52,180
kind of a couple of ten plates that can fold into

852
01:02:52,390 --> 01:02:54,770
a few thousand

853
01:02:57,200 --> 01:02:58,540
the way that you can

854
01:02:58,540 --> 01:03:03,000
do structured prediction then is an efficient way is

855
01:03:03,000 --> 01:03:04,790
the first kind of trying to predict

856
01:03:04,850 --> 01:03:08,770
which family the structure this sequence like

857
01:03:08,810 --> 01:03:11,930
that a binary classification problem

858
01:03:12,750 --> 01:03:14,270
you take the sequence

859
01:03:14,310 --> 01:03:16,040
and you try to read it

860
01:03:16,080 --> 01:03:17,560
into the structure

861
01:03:17,600 --> 01:03:19,890
how best fit

862
01:03:20,040 --> 01:03:24,120
and then hopefully gives you good enough starting point to do local search from there

863
01:03:24,330 --> 01:03:27,230
and actually find the correct

864
01:03:27,230 --> 01:03:29,410
so what i want to talk about

865
01:03:29,430 --> 01:03:32,230
here is the second task

866
01:03:32,290 --> 01:03:34,290
given the sequence and structure

867
01:03:34,290 --> 01:03:36,390
predict how they

868
01:03:36,410 --> 01:03:40,430
related to each other online

869
01:03:42,830 --> 01:03:45,270
this becomes an line problems so

870
01:03:45,310 --> 01:03:49,060
and just a quick reminder on sequence alignment

871
01:03:49,120 --> 01:03:53,410
typically formulated again as argmax over linear scoring function

872
01:03:53,910 --> 01:03:57,500
let's say we have two sequences s and he

873
01:03:58,890 --> 01:04:04,370
if we align them in in this way so that the line it was the

874
01:04:04,410 --> 01:04:06,560
was a he was he

875
01:04:08,330 --> 01:04:11,160
the way the alignment scores computed is

876
01:04:11,180 --> 01:04:15,250
we have a matrix that tells us what's the score of lining in a within

877
01:04:15,250 --> 01:04:17,100
a ten

878
01:04:18,100 --> 01:04:20,020
here realigning and a with b

879
01:04:20,080 --> 01:04:22,140
look it up the people of that neuron

880
01:04:22,160 --> 01:04:25,580
he within a that's zero

881
01:04:25,640 --> 01:04:27,180
he with the

882
01:04:27,290 --> 01:04:28,910
given score ten

883
01:04:28,970 --> 01:04:30,680
and the with the

884
01:04:30,730 --> 01:04:33,020
gives score minus

885
01:04:33,060 --> 01:04:38,910
so the overall score of this alignment some of those and it will be zero

886
01:04:38,950 --> 01:04:42,520
here's another alignment that have gaps in it so that we have a score of

887
01:04:42,540 --> 01:04:44,980
line he with the gap

888
01:04:45,040 --> 01:04:47,200
the gap mine five

889
01:04:47,200 --> 01:04:48,750
and so on

890
01:04:49,890 --> 01:04:51,710
over all possible alignments

891
01:04:51,730 --> 01:04:56,520
we solve the argmax problem the score and returned line has the highest score

892
01:04:56,560 --> 01:04:58,000
and again to cancel that not

893
01:05:01,480 --> 01:05:02,230
well that's

894
01:05:02,250 --> 01:05:06,350
straightforward sequence alignment will just the character sequence

895
01:05:06,430 --> 01:05:13,210
but the alignment problem in this reading problem we're reading sequence infrastructure is more complicated

896
01:05:13,230 --> 01:05:16,850
because what we actually lime lining here is

897
01:05:17,120 --> 01:05:19,480
sequences of feature vectors

898
01:05:19,600 --> 01:05:23,480
so for example we have sequence here that describe each

899
01:05:24,750 --> 01:05:26,410
in our structure

900
01:05:27,830 --> 01:05:30,100
what's the amino acid

901
01:05:30,140 --> 01:05:33,750
what's the exposed surface area

902
01:05:33,810 --> 01:05:36,560
what's the secondary structure that

903
01:05:37,640 --> 01:05:38,810
position in the

904
01:05:38,830 --> 01:05:40,250
doctor and so on so we

905
01:05:40,270 --> 01:05:42,040
just have a single

906
01:05:43,500 --> 01:05:46,060
character but we have these features

907
01:05:46,060 --> 01:05:48,520
the same thing for the sequence

908
01:05:48,560 --> 01:05:52,430
what's the predicted secondary structure position one

909
01:05:52,480 --> 01:05:54,160
we really aligning

910
01:05:54,160 --> 01:05:56,370
feature vector

911
01:05:56,390 --> 01:05:58,330
and then it becomes

912
01:05:58,370 --> 01:06:01,600
kind of hard to describe down on the table

913
01:06:01,600 --> 01:06:04,980
know of alignment for

914
01:06:06,000 --> 01:06:09,770
we need something more general scoring

915
01:06:09,770 --> 01:06:15,830
let's start with rapport

916
01:06:15,900 --> 01:06:19,340
i think of it i think the time

917
01:06:19,340 --> 01:06:22,270
and your own experience where you were

918
01:06:23,360 --> 01:06:25,030
in synchronization

919
01:06:25,040 --> 01:06:26,730
with another person totally

920
01:06:26,770 --> 01:06:29,570
connected with another person

921
01:06:29,580 --> 01:06:30,860
how does that feel

922
01:06:30,880 --> 01:06:34,480
it feels

923
01:06:36,780 --> 01:06:38,540
you feel confident here

924
01:06:38,680 --> 01:06:40,840
how also fail

925
01:06:47,450 --> 01:06:51,540
because this is what rapport is rapport is when you feel in synchronization with another

926
01:06:53,590 --> 01:06:56,700
and you almost start feeling

927
01:06:56,730 --> 01:06:59,200
and i want to get to sort of

928
01:06:59,650 --> 01:07:06,360
this existential lauzen like almost are feeling you know at one with the other person

929
01:07:06,380 --> 01:07:10,580
and this is this is my belief my belief is

930
01:07:10,590 --> 01:07:14,220
that if you don't have rapport

931
01:07:14,270 --> 01:07:16,150
with another person

932
01:07:16,200 --> 01:07:21,080
then whatever you're doing with this person whatever your communicating however you're trying to persuade

933
01:07:21,080 --> 01:07:22,080
this person

934
01:07:22,090 --> 01:07:24,090
is pointless

935
01:07:24,270 --> 01:07:29,070
you could you could go into a meeting a business meeting and have the best

936
01:07:31,280 --> 01:07:32,610
on the situation

937
01:07:32,630 --> 01:07:35,450
if you don't connect with the other person

938
01:07:35,460 --> 01:07:38,280
it all amounts to zero

939
01:07:38,330 --> 01:07:44,340
so the overall quality of communication is is equal to the quality content yes

940
01:07:44,350 --> 01:07:45,920
multiplied by

941
01:07:45,930 --> 01:07:49,320
the amount of reports of the rapport is zero the overall

942
01:07:49,330 --> 01:07:51,030
equation is zero

943
01:07:51,080 --> 01:08:00,540
oppose important and i and i hope to be able to prove the city

944
01:08:02,520 --> 01:08:04,830
rapport sur connection

945
01:08:04,880 --> 01:08:05,880
we feel

946
01:08:05,890 --> 01:08:08,220
in sync with another person

947
01:08:08,400 --> 01:08:09,970
so without looking at the

948
01:08:09,980 --> 01:08:12,580
the notes that you're given beforehand

949
01:08:12,590 --> 01:08:14,640
how how do you do this

950
01:08:14,650 --> 01:08:15,710
how do

951
01:08:15,770 --> 01:08:17,640
you build rapport

952
01:08:17,660 --> 01:08:19,420
with another person

953
01:08:19,470 --> 01:08:25,050
OK you try to understand them

954
01:08:25,100 --> 01:08:26,270
how else

955
01:08:26,280 --> 01:08:28,770
do build rapport with people

956
01:08:28,820 --> 01:08:33,160
just be yourself don't try to act

957
01:08:36,580 --> 01:08:39,490
OK so looking for mutual things too

958
01:08:39,510 --> 01:08:40,340
talk about

959
01:08:40,580 --> 01:08:42,480
neutral subjects

960
01:08:44,310 --> 01:08:45,750
i was to build rapport

961
01:08:45,760 --> 01:08:56,610
the connection

962
01:09:04,920 --> 01:09:08,530
yes you've got to be very sensitive to what's coming back at you

963
01:09:08,570 --> 01:09:12,730
both verbally what the person saying that all the other things that we talked a

964
01:09:12,730 --> 01:09:16,100
as visually vocal just just sense what's coming back

965
01:09:21,530 --> 01:09:25,940
being just a little bit of a careful of not being too conditioned by by

966
01:09:25,940 --> 01:09:29,560
the first impression i think is an important is it

967
01:09:29,570 --> 01:09:34,850
is it easy not to be conditioned by his vision it's quite difficult isn't it

968
01:09:34,860 --> 01:09:39,630
and again research suggests that we split we it takes is very short amount of

969
01:09:39,630 --> 01:09:41,200
time to

970
01:09:41,210 --> 01:09:43,650
decide to make a decision on another person

971
01:09:43,690 --> 01:09:46,810
whether we like them or not very short amount of time usually

972
01:09:46,870 --> 01:09:48,520
we use intuition

973
01:09:48,530 --> 01:09:49,200
a lot

974
01:09:49,330 --> 01:10:04,240
but we've got to be just mindful that sometimes it's not right

975
01:10:22,030 --> 01:10:22,920
it is

976
01:10:36,100 --> 01:10:37,380
yes it you

977
01:10:37,390 --> 01:10:41,530
and it comes back to being appropriate and maybe in a business setting and what

978
01:10:41,530 --> 01:10:44,900
in talking about relationships and forming relationships over time

979
01:10:44,900 --> 01:10:48,150
it's a step sequence so you know first meeting

980
01:10:48,160 --> 01:10:51,780
let's just try to achieve this second meeting let's go a little bit and when

981
01:10:51,780 --> 01:10:55,400
you get to know people that then it starts opening up

982
01:10:55,410 --> 01:10:58,020
to be a little bit realistic about the

983
01:10:58,180 --> 01:11:01,770
the border where you are

984
01:11:04,030 --> 01:11:09,230
you mentioned we find something common to talk about you can have to forgive me

985
01:11:09,230 --> 01:11:13,070
now a gross generalization one men

986
01:11:13,080 --> 01:11:15,230
who've never met each other talk about two

987
01:11:15,240 --> 01:11:19,360
to build a connection with each other

988
01:11:19,370 --> 01:11:23,880
sport come along of course

989
01:11:23,890 --> 01:11:27,740
did you see that they can kick of maison

990
01:11:27,760 --> 01:11:31,260
and we have sports teams that we go mad about and we

991
01:11:31,270 --> 01:11:34,990
what do women talk about gross generalizations

992
01:11:38,030 --> 01:11:49,860
whatever whatever you find something that's the important thing but you already had one in

993
01:11:49,860 --> 01:11:54,070
the UK where the terrible we don't have any fashion sense so we do talk

994
01:11:54,070 --> 01:11:55,400
about the weather

995
01:11:55,410 --> 01:12:02,050
you find common something common to talk about now in a business setting usually you

996
01:12:02,050 --> 01:12:06,640
have something common to talk about you both have an objective but verbally we need

997
01:12:07,920 --> 01:12:11,500
but is it you can go beyond verbal

998
01:12:11,520 --> 01:12:15,900
what i want you to do is to have a look at these three

999
01:12:17,690 --> 01:12:19,490
and then

1000
01:12:19,510 --> 01:12:21,370
choose which house

1001
01:12:21,390 --> 01:12:58,940
you prefer

1002
01:12:58,990 --> 01:13:01,450
there is no right answer but

1003
01:13:04,050 --> 01:13:08,300
so the preferred if you had to choose one if you had to choose one

1004
01:13:08,350 --> 01:13:11,480
who which is house number one

1005
01:13:11,530 --> 01:13:15,700
OK interesting who would have to choose house number two if you had to pick

1006
01:13:17,250 --> 01:13:19,890
and who which is house number three

1007
01:13:19,930 --> 01:13:22,530
he had become OK it's got nice

1008
01:13:22,540 --> 01:13:24,450
nice mixture in the

1009
01:13:24,460 --> 01:13:26,280
in the room

1010
01:13:26,320 --> 01:13:27,940
when you talk to

1011
01:13:27,980 --> 01:13:29,000
to people

1012
01:13:29,100 --> 01:13:30,780
you can

1013
01:13:30,830 --> 01:13:32,780
pick up what we call

1014
01:13:33,410 --> 01:13:37,050
representational channel the preference

1015
01:13:37,100 --> 01:13:41,660
four representational channel there are three primary channels are actually five six but the primary

1016
01:13:41,660 --> 01:13:44,300
representational channels are

1017
01:13:46,270 --> 01:13:48,140
something that we call auditory

1018
01:13:48,140 --> 01:13:51,270
good morning

1019
01:13:51,290 --> 01:13:55,270
i introduced myself yesterday many the

1020
01:13:55,600 --> 01:13:59,870
i will be teaching a course on multiple regression analysis

1021
01:13:59,880 --> 01:14:02,880
you got some details were

1022
01:14:02,930 --> 01:14:05,480
we're currently located

1023
01:14:05,660 --> 01:14:06,620
all the

1024
01:14:06,640 --> 01:14:09,210
yes the details you might be interested in will

1025
01:14:09,340 --> 01:14:11,530
give to the group that

1026
01:14:11,570 --> 01:14:12,190
i will

1027
01:14:12,210 --> 01:14:14,800
join me tomorrow

1028
01:14:15,280 --> 01:14:18,520
thank you for coming for being interested in addition to

1029
01:14:18,710 --> 01:14:20,410
this course

1030
01:14:27,110 --> 01:14:29,980
here's the thing you are asking

1031
01:14:30,050 --> 01:14:35,050
he teaching assistants the courses taken the course last year was put off but decided

1032
01:14:36,870 --> 01:14:44,080
do it again but now in more to change the way

1033
01:14:44,090 --> 01:14:46,950
great thank you very much

1034
01:14:49,110 --> 01:14:50,480
and six

1035
01:14:51,340 --> 01:14:53,870
well that was in the next one of ours

1036
01:14:59,190 --> 01:15:04,440
so here is a tendency to one

1037
01:15:06,780 --> 01:15:10,160
and the conditioning will be fixed or not

1038
01:15:10,220 --> 01:15:22,560
so what is multiple regression about

1039
01:15:23,340 --> 01:15:28,830
many people are using it and if you take

1040
01:15:28,890 --> 01:15:30,700
any the issue of

1041
01:15:30,700 --> 01:15:35,420
one of the well known political science journals of sociology journals

1042
01:15:35,470 --> 01:15:40,020
you will find that about fifty percent of all articles published in their use some

1043
01:15:40,020 --> 01:15:43,700
variant of regression analysis

1044
01:15:43,730 --> 01:15:47,970
and it's one of the most important tools

1045
01:15:48,750 --> 01:15:52,970
the but most important the most widely used tools in the social sciences

1046
01:15:53,030 --> 01:15:59,240
and being the most widely used tool it's also one of the most misused tools

1047
01:15:59,260 --> 01:16:03,450
and the aim of the course will be to be able to judge

1048
01:16:05,430 --> 01:16:07,760
and misuse

1049
01:16:07,790 --> 01:16:10,950
so what is multiple regression about

1050
01:16:10,960 --> 01:16:13,050
it's an art

1051
01:16:13,130 --> 01:16:15,900
to summarize relationships

1052
01:16:15,960 --> 01:16:17,150
this is another way

1053
01:16:17,170 --> 01:16:19,230
summarizing relationships

1054
01:16:19,350 --> 01:16:20,880
but it will not be

1055
01:16:21,040 --> 01:16:23,170
regression analysis

1056
01:16:23,170 --> 01:16:27,300
taking this past this is more something for the our friends at the grounded theory

1057
01:16:28,770 --> 01:16:31,180
or interpretive

1058
01:16:31,260 --> 01:16:33,700
picture analysis

1059
01:16:34,740 --> 01:16:43,820
and you can probably tell a very very long story about this simple situation

1060
01:16:43,860 --> 01:16:46,730
we do the same thing

1061
01:16:48,550 --> 01:16:52,430
i talked about fitting a straight line to open an

1062
01:16:52,450 --> 01:16:56,330
this is the solution

1063
01:16:56,390 --> 01:17:00,760
you simply look at your object from a variety of angles

1064
01:17:00,820 --> 01:17:03,380
this one angle

1065
01:17:03,420 --> 01:17:06,380
from which it really looks like

1066
01:17:06,430 --> 01:17:10,080
being representable by a straight line

1067
01:17:11,110 --> 01:17:14,800
from which perspective should you look

1068
01:17:15,990 --> 01:17:17,670
what would you consider

1069
01:17:17,730 --> 01:17:21,700
when taking that perspective

1070
01:17:21,730 --> 01:17:26,480
and what lenses should use

1071
01:17:27,240 --> 01:17:35,480
the course about

1072
01:17:35,480 --> 01:17:40,260
so normally we just we don't just take a banana

1073
01:17:40,420 --> 01:17:45,050
for the straight line or take any

1074
01:17:45,080 --> 01:17:49,110
out of a straight line

1075
01:17:49,130 --> 01:17:50,580
the doing of it

1076
01:17:55,110 --> 01:17:56,550
the plot

1077
01:17:57,730 --> 01:18:01,830
in panel data set with

1078
01:18:01,860 --> 01:18:07,680
nationally aggregated data services each dot represents a country

1079
01:18:07,690 --> 01:18:12,560
at a certain moment in time a year

1080
01:18:13,830 --> 01:18:15,490
we study

1081
01:18:15,500 --> 01:18:22,290
the replacement rate already effective to replacement rate on employment in private consumer services

1082
01:18:22,430 --> 01:18:28,390
so what is the replacement rate the replacement rate is the percentage of

1083
01:18:28,410 --> 01:18:33,870
you're income you receive after getting unemployed

1084
01:18:33,880 --> 01:18:35,950
the percentage is the number

1085
01:18:37,030 --> 01:18:39,900
zero and one hundred

1086
01:18:39,950 --> 01:18:45,330
so this is normalized to zero one

1087
01:18:45,430 --> 01:18:49,280
and you see that there's variety

1088
01:18:51,000 --> 01:18:53,370
country time units

1089
01:18:53,380 --> 01:18:56,160
where people hardly receive anything

1090
01:18:56,190 --> 01:19:03,640
and country time units were to get more than ninety percent

1091
01:19:03,650 --> 01:19:07,000
and here is a former prime consumer services resistance

1092
01:19:07,000 --> 01:19:11,700
it's just lines like that's right so basically it's just your neighbors you can make your neighbours

1093
01:19:13,160 --> 01:19:14,600
so definitely there the same

1094
01:19:16,890 --> 01:19:18,060
one dimensional input

1095
01:19:18,560 --> 01:19:22,500
the energy bill then you optimize over these axes and new learn the structure you'll

1096
01:19:22,500 --> 01:19:26,750
learn the neighborhood structure which is the hard thing that was point one you completely

1097
01:19:26,750 --> 01:19:28,790
ignore and spectral methods you just take the data

1098
01:19:30,620 --> 01:19:36,000
but they're very related from their perspective and also we then visualized x directly we

1099
01:19:36,000 --> 01:19:38,330
don't need to do and i can value problem we just look at the x

1100
01:19:38,330 --> 01:19:41,810
we have we don't need to do any visualization and the graph structure

1101
01:19:42,200 --> 01:19:46,020
there you suggest a graph structure parameterised and visualize it hear

1102
01:19:46,680 --> 01:19:49,620
you could derive a graph structure from the late positions you get

1103
01:19:50,330 --> 01:19:53,680
but you've already got visualization new short-circuit the visualization part

1104
01:19:55,120 --> 01:19:58,270
but because the learning the neighborhood it's lots of local minima

1105
01:19:59,660 --> 01:20:01,310
and then the last thing i'd like to just show you

1106
01:20:05,540 --> 01:20:07,040
the guy lots of things i could show you

1107
01:20:11,520 --> 01:20:12,100
is this one

1108
01:20:14,890 --> 01:20:18,580
i don't think that manifolds along other right way modeling things

1109
01:20:19,160 --> 01:20:22,290
i think that manifolds class conditional independencies

1110
01:20:23,750 --> 01:20:24,620
now would be the right way

1111
01:20:25,330 --> 01:20:27,620
so this is the main altar what they send deep learning

1112
01:20:29,000 --> 01:20:31,040
i don't think deep learning the be all and end all

1113
01:20:32,040 --> 01:20:33,220
i think but i think it's right

1114
01:20:35,040 --> 01:20:37,480
the broad sense that actually what you need to do

1115
01:20:37,980 --> 01:20:39,540
is land the structure of your data

1116
01:20:40,350 --> 01:20:41,000
by on

1117
01:20:41,470 --> 01:20:45,430
trying i figure out what's connected to what so the problem with those walking examples

1118
01:20:45,600 --> 01:20:48,450
i mean i think there i still say if they are that you will be

1119
01:20:48,450 --> 01:20:51,750
among those data i'm not an expert in vision but as far as i know

1120
01:20:51,750 --> 01:20:52,750
nothing beats that's

1121
01:20:54,720 --> 01:20:59,470
so that's great but those models have real trouble if i'm walking along if someone then waves

1122
01:21:01,720 --> 01:21:04,640
back confuses the model because it's never seen someone waving before

1123
01:21:05,600 --> 01:21:07,790
so you could learn on data with people waving fine

1124
01:21:08,310 --> 01:21:11,830
but what if someone might be either are okay data on any other run

1125
01:21:12,290 --> 01:21:15,600
but what if someone decided other john cleese city water

1126
01:21:17,350 --> 01:21:20,500
you know you know all those things in natural why do you think that's natural

1127
01:21:20,790 --> 01:21:22,370
you see me waving like that's

1128
01:21:22,850 --> 01:21:23,750
you know you could learn

1129
01:21:24,450 --> 01:21:29,430
if you see me if you see if you miss individually walking like you can learn these are natural motions

1130
01:21:30,200 --> 01:21:32,430
you also don't mind if i want anway way

1131
01:21:33,720 --> 01:21:36,600
okay i'll call over if i continue but you get the idea

1132
01:21:37,470 --> 01:21:42,930
what's going on is really bad arm can live on a manifold in terms the natural things it can do

1133
01:21:43,750 --> 01:21:46,060
i would say what it can't do without my painful

1134
01:21:47,100 --> 01:21:47,720
but i

1135
01:21:48,180 --> 01:21:50,830
it still is on a manifold so that's the manifold here

1136
01:21:51,720 --> 01:21:55,140
and the headlines on a manifold and the left arm moves on the manifold and then

1137
01:21:57,000 --> 01:22:01,120
they're being controlled by something else and the different motions they're being coordinates in different ways so

1138
01:22:01,740 --> 01:22:02,540
i had this idea

1139
01:22:03,080 --> 01:22:08,290
my students andrew more the hierarchical decomposition of the body and actually works really nice

1140
01:22:08,430 --> 01:22:11,080
i don't think i can run the devil trying a moment

1141
01:22:11,450 --> 01:22:15,290
i don't think i can run the demo here but it's basically you have to specify the structure

1142
01:22:17,000 --> 01:22:20,120
but we working on learning this structure which i think would be really cool

1143
01:22:21,890 --> 01:22:26,100
so u this this guy guy's modelling a little manifold learning the right on this

1144
01:22:26,100 --> 01:22:28,700
guy on the left on this a very similar but they

1145
01:22:29,430 --> 01:22:32,620
they only know about each other through their shared mother of the body

1146
01:22:33,220 --> 01:22:34,850
shared body what

1147
01:22:35,390 --> 01:22:37,060
model the body is and what he did you know

1148
01:22:39,040 --> 01:22:39,560
that's the money

1149
01:22:41,220 --> 01:22:41,910
and this is the

1150
01:22:45,540 --> 01:22:48,830
so these legs and you you've got me banned

1151
01:22:49,430 --> 01:22:53,790
two motion so there's walk and run right and so the war is green and the running red

1152
01:22:54,240 --> 01:22:56,540
so not surprisingly the walks sits inside the run

1153
01:22:57,410 --> 01:22:58,580
but the sharing information

1154
01:22:59,160 --> 01:23:01,390
about how humans naturally so this

1155
01:23:02,830 --> 01:23:03,250
doesn't know

1156
01:23:03,740 --> 01:23:07,970
about walk and run it just knows what is being told today from about what seen below

1157
01:23:08,970 --> 01:23:12,350
and when it gets old from above a slightly different form walk and run so

1158
01:23:12,640 --> 01:23:16,250
learns about leg motions in general you switch in the walk and run model

1159
01:23:18,330 --> 01:23:21,580
and then if you want to locate this is bound not to work because i

1160
01:23:21,580 --> 01:23:24,180
didn't test this so let's have a good faith here

1161
01:23:25,560 --> 01:23:29,080
i don't even remember the name and the demo is but let's see if we can find the demo

1162
01:23:41,790 --> 01:23:45,890
i think it's not here now at amazon goddamn away you can move around controlling

1163
01:23:45,950 --> 01:23:48,450
for those parts separately by having run in a while

1164
01:23:49,290 --> 01:23:52,160
and i think that's why model is really the sort of thing you want to

1165
01:23:52,160 --> 01:23:56,790
be doing and the suggestion is that you could even back so basically you've these

1166
01:23:56,790 --> 01:23:58,520
models the some parts of the body

1167
01:23:59,140 --> 01:24:02,750
hand if you see what someone's doing you try model with something at the top

1168
01:24:02,750 --> 01:24:06,450
but it doesn't work you just replace those controlling model something more diffuse

1169
01:24:07,810 --> 01:24:11,200
until the the worst case you've got several models what legs to

1170
01:24:11,720 --> 01:24:12,850
arms to and had to

1171
01:24:13,810 --> 01:24:14,600
and we had a paper

1172
01:24:15,160 --> 01:24:15,790
be and see

1173
01:24:17,750 --> 01:24:20,240
on doing not news tracking so

1174
01:24:21,470 --> 01:24:25,770
you don't use use the hierarchy to back down say okay well if he's walking

1175
01:24:26,060 --> 01:24:28,060
i can i can model this level here

1176
01:24:28,540 --> 01:24:32,310
but then if he's doing a roly-poly then i've never seen before so i'm all

1177
01:24:32,390 --> 01:24:37,250
this level here i mean that's not very much so the deep learning type provided

1178
01:24:37,500 --> 01:24:40,040
and we we know how to do with at

1179
01:24:42,020 --> 01:24:46,770
we think and learn structural we've got a way of doing that's we don't know if it's gonna work

1180
01:24:47,390 --> 01:24:52,410
but hopefully it will so that's that's what the that's what my student unrest damian

1181
01:24:52,410 --> 01:24:53,660
you can take are

1182
01:24:53,720 --> 01:24:56,090
o point one metres

1183
01:24:56,130 --> 01:24:59,650
and then the field strength of the b field right at the centre of this

1184
01:25:01,100 --> 01:25:05,980
but i found is in six times ten to the minus four test lab

1185
01:25:06,030 --> 01:25:08,120
and that would be

1186
01:25:08,130 --> 01:25:13,130
six gauss

1187
01:25:13,150 --> 01:25:15,880
it's clear that if you want to put in some

1188
01:25:15,930 --> 01:25:18,340
field lines

1189
01:25:18,350 --> 01:25:21,330
magnetic field lines the result of this

1190
01:25:21,350 --> 01:25:23,740
current going around in circles

1191
01:25:23,820 --> 01:25:28,020
that the fuller center there would be if you like so

1192
01:25:28,070 --> 01:25:31,770
if you're very close to the wire here which goes into the blackboard want you

1193
01:25:31,810 --> 01:25:34,110
to see this three-dimensional

1194
01:25:34,110 --> 01:25:36,430
then the magnetic field go like this

1195
01:25:37,930 --> 01:25:39,980
the current comes to you

1196
01:25:40,030 --> 01:25:42,900
so will be counterclockwise

1197
01:25:42,910 --> 01:25:45,810
if the magnetic field lines you like so

1198
01:25:45,830 --> 01:25:47,520
and you have it to scroll up

1199
01:25:47,550 --> 01:25:49,980
and clearly i expect them to be here

1200
01:25:50,020 --> 01:25:52,240
sort of like so

1201
01:25:52,250 --> 01:25:54,330
like so

1202
01:25:54,350 --> 01:25:55,640
like so

1203
01:25:55,650 --> 01:25:57,560
this is the kind of

1204
01:25:57,620 --> 01:26:01,480
magnetic field line configuration that i would expect them

1205
01:26:01,480 --> 01:26:03,350
in the vicinity of

1206
01:26:03,370 --> 01:26:05,190
such a

1207
01:26:05,210 --> 01:26:10,300
current loop

1208
01:26:10,400 --> 01:26:19,120
i want to show this to you in a little bit more detail

1209
01:26:19,180 --> 01:26:22,110
i have here

1210
01:26:24,910 --> 01:26:26,230
you see there

1211
01:26:26,240 --> 01:26:27,490
on the right side

1212
01:26:28,830 --> 01:26:33,110
goes into the paper here comes out of the paper is circular

1213
01:26:33,110 --> 01:26:35,800
you see the field like configuration

1214
01:26:35,850 --> 01:26:38,260
after different whatever the blackboard there

1215
01:26:38,270 --> 01:26:40,690
very close to the wire is of course

1216
01:26:40,730 --> 01:26:42,760
you get circles

1217
01:26:42,980 --> 01:26:44,450
one of our

1218
01:26:44,530 --> 01:26:49,030
dominates there is so close to the wire that the one of our relationship

1219
01:26:49,120 --> 01:26:51,760
make it come out like circles and here too

1220
01:26:51,830 --> 01:26:53,300
but then

1221
01:26:53,350 --> 01:26:56,390
far away you get configurations

1222
01:26:56,450 --> 01:27:00,230
like i i have there

1223
01:27:00,300 --> 01:27:02,480
when you very far away

1224
01:27:02,480 --> 01:27:04,740
from a current loop

1225
01:27:05,940 --> 01:27:07,200
magnetic field

1226
01:27:08,730 --> 01:27:13,140
is very similar to that of an electric dipole

1227
01:27:13,230 --> 01:27:14,600
i can show you that

1228
01:27:14,610 --> 01:27:17,180
in the following way

1229
01:27:17,230 --> 01:27:20,250
let's first look at the electric dipole that you see

1230
01:27:20,430 --> 01:27:23,980
there is is the positive charges the negative charge

1231
01:27:24,030 --> 01:27:26,110
don't look anywhere near

1232
01:27:26,120 --> 01:27:30,370
the charges don't look in between the charges look far away

1233
01:27:30,480 --> 01:27:33,090
using electric field lines

1234
01:27:35,340 --> 01:27:37,210
now look at your current loop here

1235
01:27:37,220 --> 01:27:39,590
the current is going into the paper here

1236
01:27:39,600 --> 01:27:43,000
out of the paper is a

1237
01:27:43,060 --> 01:27:45,910
i hope you see the same configuration

1238
01:27:45,970 --> 01:27:47,230
field lines

1239
01:27:48,450 --> 01:27:49,970
this goes like so

1240
01:27:50,010 --> 01:27:51,780
this one goes like so

1241
01:27:51,840 --> 01:27:54,330
here the electric field lines coming in

1242
01:27:54,360 --> 01:27:56,390
magnetic field lines are coming in

1243
01:27:56,400 --> 01:27:58,410
electric field lines are going out

1244
01:27:58,430 --> 01:28:00,690
that field lines are going

1245
01:28:00,700 --> 01:28:05,050
they look very similar

1246
01:28:05,100 --> 01:28:09,050
gauss law tells me that the close to the surface integral of the

1247
01:28:09,110 --> 01:28:13,990
electric flux is the charge inside the box divided by epsilon zero and so if

1248
01:28:13,990 --> 01:28:16,460
you have a closed surface here

1249
01:28:16,500 --> 01:28:19,350
looks like a line but i meant to resurface

1250
01:28:19,430 --> 01:28:22,880
then that closed surface interval of electric flux is not zero

1251
01:28:22,940 --> 01:28:25,550
because the charge inside the box

1252
01:28:25,610 --> 01:28:27,370
no matter where

1253
01:28:27,380 --> 01:28:29,450
in the magnetic fields

1254
01:28:29,490 --> 01:28:32,460
you make closed surface there's never

1255
01:28:33,190 --> 01:28:35,650
magnetic flux going through

1256
01:28:35,710 --> 01:28:36,960
that surface

1257
01:28:36,970 --> 01:28:42,160
never unless you come into twenty six one hundred and and show me the magnetic

1258
01:28:42,220 --> 01:28:43,220
one of

1259
01:28:43,230 --> 01:28:48,000
only then will the be magnetic flux coming out of a closer

1260
01:28:48,010 --> 01:28:51,630
if we put the magnetic monopole inside

1261
01:28:51,690 --> 01:28:53,140
this now

1262
01:28:53,230 --> 01:28:54,380
brings us

1263
01:28:55,190 --> 01:28:59,190
the second of the four maxwell's equations

1264
01:28:59,200 --> 01:29:00,840
the first one being

1265
01:29:00,870 --> 01:29:02,050
gauss law

1266
01:29:02,100 --> 01:29:03,490
the second one

1267
01:29:03,520 --> 01:29:07,710
is that the closed surface

1268
01:29:07,750 --> 01:29:10,100
closed surface

1269
01:29:11,730 --> 01:29:14,080
of the don't the a

1270
01:29:14,090 --> 01:29:17,860
always zero

1271
01:29:17,950 --> 01:29:20,230
unless you come with the magnetic

1272
01:29:31,970 --> 01:29:36,460
so we now have two of maxwell's four equations in place

1273
01:29:36,470 --> 01:29:41,870
historic day

1274
01:29:41,930 --> 01:29:43,620
i want to show you the

1275
01:29:43,690 --> 01:29:45,030
magnetic field

1276
01:29:45,050 --> 01:29:46,450
in the vicinity

1277
01:29:46,460 --> 01:29:49,310
all the while like this

1278
01:29:49,360 --> 01:29:52,850
i have to use a few hundred and useful wire

1279
01:29:52,850 --> 01:29:57,840
i told you why because magnetic field falls of clyde rapidly

1280
01:29:57,850 --> 01:30:01,110
and i did was i one file

1281
01:30:01,110 --> 01:30:04,370
but i will sprinkle around the wire and these magnifies

1282
01:30:04,410 --> 01:30:06,350
o orient themselves

1283
01:30:06,390 --> 01:30:09,110
in that the magnetic field

1284
01:30:09,110 --> 01:30:13,380
and then i will try to also make you see this field configuration

1285
01:30:13,400 --> 01:30:15,850
by having won why going into

1286
01:30:15,890 --> 01:30:20,160
the paper in one coming out of the paper

1287
01:30:20,210 --> 01:30:24,300
so let's first look at the

1288
01:30:24,300 --> 01:30:31,150
their behavior

1289
01:30:31,190 --> 01:30:35,310
so they they were looking at how people behave and they started making themselves and

1290
01:30:35,310 --> 01:30:38,310
modeling their behavior and what they found was

1291
01:30:38,330 --> 01:30:40,700
they became successful as well

1292
01:30:40,750 --> 01:30:42,770
if you look at someone what they do

1293
01:30:42,810 --> 01:30:47,040
and you really get a detailed idea of what they're doing and you start doing

1294
01:30:47,040 --> 01:30:49,020
it you have the same results

1295
01:30:49,020 --> 01:30:50,930
this is the finding

1296
01:30:50,950 --> 01:30:58,030
and out of this finding the whole field of neuro-linguistic programming has has grown

1297
01:30:58,070 --> 01:30:59,350
and this is the model

1298
01:30:59,390 --> 01:31:02,150
what they found that these people do firstly

1299
01:31:02,150 --> 01:31:05,180
these people very effective communicators

1300
01:31:05,220 --> 01:31:10,690
firstly they know what they're trying to achieve in interaction very clear

1301
01:31:10,750 --> 01:31:11,580
one of their

1302
01:31:13,680 --> 01:31:17,050
in the last role-play

1303
01:31:17,180 --> 01:31:19,260
clary you were

1304
01:31:19,320 --> 01:31:21,430
about what you're trying to achieve

1305
01:31:21,680 --> 01:31:25,400
the more likely you are to get the result you want

1306
01:31:25,420 --> 01:31:27,500
and that's why i kept on pushing

1307
01:31:27,530 --> 01:31:32,160
you know your reservation price no you'll know when you're going to walk away know

1308
01:31:32,160 --> 01:31:34,690
what volume you really would love

1309
01:31:34,740 --> 01:31:38,690
get clear as you possibly can before interaction

1310
01:31:38,710 --> 01:31:40,100
and you're more likely to get

1311
01:31:40,110 --> 01:31:45,440
make sure that your your goal is stated positively all the time

1312
01:31:45,460 --> 01:31:48,160
it's not a negative goal positive goals

1313
01:31:48,190 --> 01:31:49,850
so don't go into

1314
01:31:49,860 --> 01:31:56,520
a negotiation with the goal right i mustn't i mustn't fail

1315
01:31:57,740 --> 01:31:58,710
that's not to go

1316
01:31:58,990 --> 01:32:02,980
because as i mentioned yesterday if that's what you're thinking about that's what's going to

1317
01:32:02,980 --> 01:32:06,430
happen your brain won't register the word mustn't

1318
01:32:06,470 --> 01:32:09,470
it will only register the word fail

1319
01:32:09,490 --> 01:32:12,180
so be very clear about you goal we all of you

1320
01:32:12,190 --> 01:32:14,470
clear in the role-play what your was

1321
01:32:15,020 --> 01:32:16,380
you knew exactly

1322
01:32:16,410 --> 01:32:21,770
your reservation price minimum price in exactly the volume that you want to yes

1323
01:32:21,820 --> 01:32:25,700
should have been you should have been clearly had long enough to prepare

1324
01:32:25,740 --> 01:32:30,630
the other three things that that will class communicators do

1325
01:32:30,630 --> 01:32:32,810
they build rapport

1326
01:32:32,830 --> 01:32:35,840
with people that are communicating with

1327
01:32:35,890 --> 01:32:40,240
i think we mention this word yesterday as well just remind me what

1328
01:32:40,330 --> 01:32:42,080
does this would mean

1329
01:32:49,170 --> 01:32:52,240
if you had to guess if i if i say you know we've got a

1330
01:32:52,240 --> 01:32:55,020
good rapport what does that mean

1331
01:32:55,050 --> 01:32:58,400
relationship and at an even simpler level

1332
01:32:58,450 --> 01:33:01,020
rapport means the connection

1333
01:33:01,080 --> 01:33:04,020
when you have a connection with someone

1334
01:33:04,020 --> 01:33:05,080
so a b

1335
01:33:05,090 --> 01:33:08,230
when you feel mutual sort of sense

1336
01:33:08,980 --> 01:33:12,110
some people have a rapport with some people you just

1337
01:33:12,140 --> 01:33:14,060
you know you've all the people

1338
01:33:14,080 --> 01:33:18,030
you know you shaking their hands and there's just nothing is known

1339
01:33:18,050 --> 01:33:20,590
mutual feeling at all

1340
01:33:20,610 --> 01:33:25,550
and so you do not in rap also to good communicators have rapport this two

1341
01:33:25,550 --> 01:33:29,770
other things are good communicators to firstly they make it that they

1342
01:33:29,780 --> 01:33:33,610
i spent a lot of time understanding the other person

1343
01:33:33,640 --> 01:33:37,770
all the other people so listening and understanding and was going to talk about that

1344
01:33:37,840 --> 01:33:42,020
and the final thing will class communications doing will cost persuaders

1345
01:33:42,050 --> 01:33:43,020
they are

1346
01:33:44,390 --> 01:33:46,930
they behave flexibly they are not

1347
01:33:50,360 --> 01:33:51,780
you can't really

1348
01:33:51,830 --> 01:33:54,710
get anywhere if you are so we can use this model i would like to

1349
01:33:54,710 --> 01:33:57,080
do is i'm going to go through each of these i'm going to leave the

1350
01:33:57,780 --> 01:34:01,330
because the goal was very situation depends what you're trying to cheat i want to

1351
01:34:01,330 --> 01:34:02,990
focus on the other three

1352
01:34:03,010 --> 01:34:05,270
and we'll see how you can become better

1353
01:34:05,370 --> 01:34:08,980
these three things to building rapport with people

1354
01:34:08,990 --> 01:34:15,240
improving how you listen and understand people and finally improving how you behave flexibly

1355
01:34:15,240 --> 01:34:16,270
with people

1356
01:34:16,310 --> 01:34:21,840
one of the few small role plays and exercises as we go through

1357
01:34:21,890 --> 01:34:24,740
any before continuing to comment on this

1358
01:34:24,860 --> 01:34:25,890
very simple

1359
01:34:25,920 --> 01:34:29,170
straightforward model

1360
01:34:30,620 --> 01:34:32,710
simple and straightforward

1361
01:34:32,800 --> 01:34:35,110
let me let me give you an example of

1362
01:34:35,120 --> 01:34:37,670
someone who doesn't do this

1363
01:34:37,710 --> 01:34:40,640
the sort of person who doesn't

1364
01:34:40,650 --> 01:34:42,780
following this model is the typical

1365
01:34:42,790 --> 01:34:44,920
english person who is traveling

1366
01:34:44,940 --> 01:34:46,070
two new country

1367
01:34:46,080 --> 01:34:51,890
and of course being english we don't speak many foreign languages so imagine an english

1368
01:34:51,890 --> 01:34:55,960
man who goes to france he gets lost in the french countryside doesn't know where

1369
01:34:55,960 --> 01:34:58,910
he is and he sees the french farmer you with the error in a few

1370
01:34:58,910 --> 01:35:04,480
onions around his neck and he calls the farmer over and he says the farmer

1371
01:35:04,500 --> 01:35:06,030
excuse me

1372
01:35:06,040 --> 01:35:08,410
where is the railway station

1373
01:35:08,590 --> 01:35:11,150
and the farmer says

1374
01:35:11,200 --> 01:35:13,810
chen composed by merchants

1375
01:35:13,820 --> 01:35:16,730
what does englishmen do

1376
01:35:17,520 --> 01:35:21,640
louder slow where

1377
01:35:22,220 --> 01:35:23,750
it is yes

1378
01:35:23,770 --> 01:35:29,460
he didn't understand first time what what do you think is going to understand seconds

1379
01:35:32,590 --> 01:35:34,220
this this

1380
01:35:34,230 --> 01:35:37,510
this english full is is not

1381
01:35:37,560 --> 01:35:40,070
doing this he didn't listen

1382
01:35:40,120 --> 01:35:44,060
and understand the response to the french farmer

1383
01:35:45,200 --> 01:35:47,900
he didn't behave flexibly all did

1384
01:35:50,030 --> 01:35:52,270
the behaviour that he had this time right

1385
01:35:52,290 --> 01:35:53,540
just a little bit more

1386
01:35:53,560 --> 01:35:56,150
a bit slower and louder

1387
01:35:56,210 --> 01:36:01,080
whereas if he had seen and listened to the responsible former

1388
01:36:01,090 --> 01:36:02,580
just about

1389
01:36:02,600 --> 01:36:07,580
he could have what can be done instead of speaking slower and louder

1390
01:36:08,720 --> 01:36:09,760
two true

1391
01:36:09,770 --> 01:36:12,620
well i guess we

1392
01:36:13,590 --> 01:36:16,810
be a flexibly and is it's not that easy to do because we are also

1393
01:36:16,810 --> 01:36:20,450
used to behave in the way we do

1394
01:36:20,450 --> 01:36:25,050
some nifty ways that we actually use a big o notation

1395
01:36:26,760 --> 01:36:38,910
is using the semantic

1396
01:36:38,960 --> 01:36:41,440
by the way and we have a lot to cover today and so i'm going

1397
01:36:41,440 --> 01:36:45,770
to go relatively fast if anything is unclear to stop questions that i will slow

1398
01:36:45,770 --> 01:36:49,640
down otherwise i'll take this is all completely obvious and i can

1399
01:36:49,650 --> 01:36:50,840
going at full speed

1400
01:36:50,850 --> 01:36:54,490
OK so the convention

1401
01:36:54,500 --> 01:36:58,640
this is

1402
01:36:58,760 --> 01:37:01,460
intuitive i guess if you do

1403
01:37:01,520 --> 01:37:05,310
macro programming or something

1404
01:37:05,320 --> 01:37:07,620
but it's a bit more mathematical

1405
01:37:15,150 --> 01:37:21,980
so we define big o notation and the equals big something

1406
01:37:21,990 --> 01:37:25,750
and so we only to find they go

1407
01:37:26,490 --> 01:37:29,340
on the equal sign we had to go some function

1408
01:37:29,360 --> 01:37:32,910
but it's useful to have some general expression on the right hand side that involves

1409
01:37:33,680 --> 01:37:35,050
so for example

1410
01:37:35,060 --> 01:37:37,380
let's say we have

1411
01:37:37,390 --> 01:37:43,120
after there is an q plus four square

1412
01:37:45,910 --> 01:37:50,590
this is attempting to get error bounds say fn is basically and q but there's

1413
01:37:50,590 --> 01:37:53,350
these lower-order terms that are big o of n squares

1414
01:37:53,370 --> 01:37:55,840
so this means

1415
01:37:55,850 --> 01:37:59,900
there there's function

1416
01:38:04,620 --> 01:38:08,790
shorthand for function h of and which is in

1417
01:38:08,800 --> 01:38:10,890
the golden square

1418
01:38:10,930 --> 01:38:16,470
four equals golden square

1419
01:38:16,550 --> 01:38:20,270
such that f of and calls and q

1420
01:38:20,320 --> 01:38:22,700
class h

1421
01:38:24,340 --> 01:38:26,350
so saying there's some lower order

1422
01:38:26,360 --> 01:38:31,610
terms that are bounded above by some constant times square for sufficiently large n and

1423
01:38:31,610 --> 01:38:35,870
that's what's here and then f of x equals now this is the true equality

1424
01:38:36,090 --> 01:38:38,330
and q plus that character

1425
01:38:38,350 --> 01:38:43,910
so this is very useful here essentially expressing what the customers is in the same

1426
01:38:44,120 --> 01:38:46,480
other stuff and is almost square

1427
01:38:46,500 --> 01:38:50,290
but saying that f of and therefore is also order and q but it's a

1428
01:38:50,290 --> 01:38:52,170
bit weaker state

1429
01:38:52,180 --> 01:38:56,870
this is a bit more refined what he chooses to often but it's useful sometimes

1430
01:38:56,910 --> 01:39:00,500
seem like in my class we even had a big o inside summation so you

1431
01:39:00,500 --> 01:39:03,850
can use them all over the place the players to represent some function

1432
01:39:03,940 --> 01:39:06,350
in that sense

1433
01:39:06,360 --> 01:39:08,710
a bit less intuitive

1434
01:39:08,730 --> 01:39:11,010
this is more subtle

1435
01:39:11,030 --> 01:39:16,900
is what it means to be go on the left-hand side

1436
01:39:16,920 --> 01:39:19,410
it means the same thing but

1437
01:39:20,810 --> 01:39:23,220
there some convention what quality

1438
01:39:24,090 --> 01:39:25,890
can this is what call sign

1439
01:39:25,930 --> 01:39:27,720
is asymmetric

1440
01:39:28,400 --> 01:39:32,190
he calls means it should really calls like is

1441
01:39:32,230 --> 01:39:36,820
so is means that everything over here is

1442
01:39:36,840 --> 01:39:38,310
something over here

1443
01:39:38,330 --> 01:39:41,740
so there's an implicit for all on the left side there exist some

1444
01:39:41,790 --> 01:39:45,610
right hand side this is a true statement anything that is an squared plus bigger

1445
01:39:45,610 --> 01:39:48,340
than is also the golden square

1446
01:39:48,360 --> 01:39:54,190
but not the other way around this is a bit is symmetric

1447
01:39:54,210 --> 01:39:58,170
this if you think about this is pretty intuitive

1448
01:39:58,170 --> 01:40:00,860
i want to be compensated for their work

1449
01:40:00,900 --> 01:40:02,000
if i climb

1450
01:40:02,020 --> 01:40:03,810
this mountain

1451
01:40:03,850 --> 01:40:07,070
if i climb five thousand feet

1452
01:40:07,080 --> 01:40:09,310
and i have to do extra work

1453
01:40:09,320 --> 01:40:11,460
which is ten two six two

1454
01:40:11,520 --> 01:40:13,960
you gotta eat more

1455
01:40:14,010 --> 01:40:17,550
now you would think that you have to eat only ten percent more than you

1456
01:40:18,960 --> 01:40:22,460
because you say ten two six is only ten percent of ten to the seven

1457
01:40:22,510 --> 01:40:25,890
but that's not true you have to eat a lot more because the conversion from

1458
01:40:26,630 --> 01:40:30,310
two mechanical work is very poor something like twenty percent

1459
01:40:30,350 --> 01:40:34,050
so you may have to eat forty or fifty percent more you normally do

1460
01:40:34,100 --> 01:40:39,330
in one day

1461
01:40:39,380 --> 01:40:43,300
suppose i wanted to take it back and i want to calculate how much

1462
01:40:43,370 --> 01:40:44,660
energy it takes

1463
01:40:44,670 --> 01:40:46,260
to read about

1464
01:40:46,310 --> 01:40:47,460
a wonderful thing

1465
01:40:47,480 --> 01:40:48,430
to have

1466
01:40:48,440 --> 01:40:50,690
well we know how to do that

1467
01:40:50,800 --> 01:40:52,930
q is the number of calories

1468
01:40:53,980 --> 01:40:55,120
times c

1469
01:40:55,120 --> 01:40:56,400
times delta t

1470
01:40:56,450 --> 01:40:58,390
that's equation

1471
01:40:58,430 --> 01:41:00,520
about half will contain about

1472
01:41:00,560 --> 01:41:02,160
a hundred kilograms

1473
01:41:02,290 --> 01:41:03,720
of what

1474
01:41:03,760 --> 01:41:06,160
that is about twenty eight gallons

1475
01:41:06,200 --> 01:41:09,400
and let us assume that the temperature increase

1476
01:41:09,410 --> 01:41:10,920
is about fifty

1477
01:41:10,970 --> 01:41:13,150
degrees centigrade which is the same

1478
01:41:13,150 --> 01:41:16,390
as fifty degrees kelvin

1479
01:41:16,400 --> 01:41:18,690
we have water and so you'll find

1480
01:41:18,760 --> 01:41:20,190
q then

1481
01:41:20,210 --> 01:41:21,750
becomes roughly

1482
01:41:21,770 --> 01:41:23,670
five thousand

1483
01:41:23,720 --> 01:41:28,130
you look at least that's how much energy it takes which is two times

1484
01:41:28,160 --> 01:41:29,520
and two to seven

1485
01:41:31,850 --> 01:41:34,160
so that's the energy that is needed

1486
01:41:34,210 --> 01:41:35,680
to heat up

1487
01:41:36,660 --> 01:41:37,890
and joy

1488
01:41:37,890 --> 01:41:39,730
that pleasure

1489
01:41:39,750 --> 01:41:41,070
go back to this

1490
01:41:41,070 --> 01:41:42,850
that's very shortly

1491
01:41:42,890 --> 01:41:44,750
there are many forms of energy

1492
01:41:44,800 --> 01:41:47,670
as we all familiar with there is electric energy

1493
01:41:47,710 --> 01:41:49,460
this chemical energy

1494
01:41:49,510 --> 01:41:53,860
i mention that already gasoline burning there is mechanical energy when we

1495
01:41:53,860 --> 01:41:56,140
move things gravitational field

1496
01:41:56,200 --> 01:41:57,230
and there is

1497
01:41:57,290 --> 01:41:59,900
nuclear energy

1498
01:41:59,950 --> 01:42:01,770
a waterfall

1499
01:42:01,850 --> 01:42:04,050
his mechanical energy MGH

1500
01:42:04,070 --> 01:42:05,980
you can convert that

1501
01:42:07,760 --> 01:42:09,050
you can convert it

1502
01:42:09,050 --> 01:42:10,180
two heats

1503
01:42:11,260 --> 01:42:12,300
will power

1504
01:42:12,300 --> 01:42:13,430
coffee machine

1505
01:42:13,450 --> 01:42:15,170
it will power your TV

1506
01:42:16,150 --> 01:42:18,520
if CRU electric toothbrush

1507
01:42:18,570 --> 01:42:22,450
everything it may power your electric blankets if you have one

1508
01:42:22,480 --> 01:42:23,810
electric blankets

1509
01:42:23,810 --> 01:42:25,900
is only fifty watts

1510
01:42:25,910 --> 01:42:28,080
compare that with human beings

1511
01:42:28,080 --> 01:42:29,210
on the what

1512
01:42:29,230 --> 01:42:31,130
what's nicer

1513
01:42:31,180 --> 01:42:34,080
have a human being which you in bed then one

1514
01:42:34,130 --> 01:42:38,890
electric blanket believe me

1515
01:42:38,900 --> 01:42:40,070
nuclear energy

1516
01:42:40,070 --> 01:42:42,370
can be converted into heat

1517
01:42:42,420 --> 01:42:45,100
and that can be converted into mechanical energy

1518
01:42:45,100 --> 01:42:47,620
and again into electricity

1519
01:42:47,660 --> 01:42:50,090
chemical energy

1520
01:42:51,230 --> 01:42:52,720
fossil fuels

1521
01:42:52,770 --> 01:42:54,190
can be burnt

1522
01:42:54,240 --> 01:42:55,390
converted to heat

1523
01:42:56,450 --> 01:42:59,930
two electricity

1524
01:42:59,970 --> 01:43:01,760
i have here device

1525
01:43:02,650 --> 01:43:04,380
allows me to convert

1526
01:43:04,390 --> 01:43:05,900
mechanical energy

1527
01:43:06,580 --> 01:43:08,520
electric energy

1528
01:43:08,580 --> 01:43:11,450
and i would like to invite a student

1529
01:43:11,470 --> 01:43:14,640
to come up here volunteer he or she

1530
01:43:14,680 --> 01:43:16,560
we going to going to show

1531
01:43:16,560 --> 01:43:19,340
how he or she can convert

1532
01:43:19,350 --> 01:43:20,670
mechanical energy

1533
01:43:20,690 --> 01:43:22,000
in two

1534
01:43:22,040 --> 01:43:23,410
electric energy

1535
01:43:23,510 --> 01:43:24,600
will have the

1536
01:43:24,600 --> 01:43:28,370
special like conditions so that we can see it well

1537
01:43:28,420 --> 01:43:30,410
so who wants to do that

1538
01:43:30,480 --> 01:43:34,120
please come

1539
01:43:34,160 --> 01:43:39,060
there's twenty watt light bulb here you've got you will see it very shortly

1540
01:43:39,110 --> 01:43:40,160
and this man

1541
01:43:40,170 --> 01:43:42,630
as a lot of power i can tell

1542
01:43:42,660 --> 01:43:45,200
more than hundred watts

1543
01:43:45,210 --> 01:43:46,560
go ahead

1544
01:43:46,560 --> 01:43:51,820
but with a twenty watt light bulb with your foot on the

1545
01:43:51,900 --> 01:43:56,600
it is easy a

1546
01:43:56,600 --> 01:43:58,860
quite impressive

1547
01:43:58,870 --> 01:44:01,910
OK now will the not so little new

1548
01:44:01,930 --> 01:44:04,120
here we have six of them

1549
01:44:04,160 --> 01:44:04,830
so now

1550
01:44:04,840 --> 01:44:06,570
go ahead and now you are

1551
01:44:06,580 --> 01:44:08,310
trying to generate hundreds

1552
01:44:09,260 --> 01:44:10,500
watts of power

1553
01:44:10,570 --> 01:44:11,790
things you can do it

1554
01:44:17,340 --> 01:44:22,150
they look really them to be

1555
01:44:27,350 --> 01:44:34,230
non-linear keep going and keep going

1556
01:44:34,310 --> 01:44:39,160
you're not even at the level of on the twenty watts

1557
01:44:39,230 --> 01:44:40,550
it's hopeless

1558
01:44:40,550 --> 01:44:42,020
it's hopeless

1559
01:44:42,080 --> 01:44:43,050
you can do it

1560
01:44:43,060 --> 01:44:45,190
and even if you could do it

1561
01:44:45,240 --> 01:44:48,210
you would have to do this for forty eight hours in a row

1562
01:44:48,260 --> 01:44:49,920
two he did my best

1563
01:44:49,930 --> 01:44:52,260
think about this one back

1564
01:44:52,270 --> 01:44:55,160
forty eight hours but you can even do it on the twenty what is too

1565
01:44:56,340 --> 01:45:09,400
i don't blame you i can do with either

1566
01:45:09,490 --> 01:45:10,720
there are better is

1567
01:45:10,730 --> 01:45:12,540
batteries convert

1568
01:45:12,580 --> 01:45:14,120
chemical energy

1569
01:45:14,220 --> 01:45:16,870
two electricity directly

1570
01:45:16,900 --> 01:45:19,920
we use these fancy dry cells

1571
01:45:20,020 --> 01:45:23,370
but in the old days and still nowadays in your car

1572
01:45:23,370 --> 01:45:25,480
there acid batteries

1573
01:45:25,540 --> 01:45:28,090
if i have here beaker was as it

1574
01:45:28,130 --> 01:45:31,210
which most commonly used sulfuric acid

1575
01:45:31,230 --> 01:45:34,060
and i put here in

1576
01:45:35,080 --> 01:45:36,710
why i here in

1577
01:45:36,710 --> 01:45:37,940
copper wire

1578
01:45:37,960 --> 01:45:39,790
then this is a better

1579
01:45:39,830 --> 01:45:44,000
i believe this side of the better is positive and negative

1580
01:45:44,660 --> 01:45:46,810
we have them here we have this

1581
01:45:46,830 --> 01:45:49,640
so if you as it and we have zinc and we've got but if we

1582
01:45:49,640 --> 01:45:51,460
use only one cell

1583
01:45:51,460 --> 01:45:54,310
then i won't be able to light small

1584
01:45:55,290 --> 01:45:56,120
just like

1585
01:45:56,120 --> 01:45:59,980
we see you flashlights that you have at home you sometimes have to put in

1586
01:45:59,980 --> 01:46:02,080
several cells in series

1587
01:46:02,100 --> 01:46:05,170
to get a higher voltage so that you can power

1588
01:46:05,310 --> 01:46:08,290
it's more like the light bulb that we have here

1589
01:46:09,080 --> 01:46:12,540
only a few watts it's almost nothing

1590
01:46:12,600 --> 01:46:14,190
i will still try

1591
01:46:14,230 --> 01:46:17,960
to get it lit which is not so easy because these battery

1592
01:46:18,000 --> 01:46:21,140
has a self-destruct in at the moment and i put this

1593
01:46:21,140 --> 01:46:22,460
zinc in there

1594
01:46:22,480 --> 01:46:25,370
i get very violent chemical reactions

1595
01:46:25,390 --> 01:46:29,370
the fumes are awful you may actually smell it the first row very awful

1596
01:46:29,390 --> 01:46:32,000
and the better it works only maybe four

1597
01:46:32,000 --> 01:46:38,520
lives in according to its distribution function and just and just evaluating g at that

1598
01:46:39,820 --> 01:46:44,020
so the basic stochastic approximation scheme it you just take a step in the direction

1599
01:46:44,020 --> 01:46:46,230
of big g

1600
01:46:46,260 --> 01:46:47,150
that's it

1601
01:46:48,150 --> 01:46:52,170
notice by the way i get again the critical issues had choose the alpha just

1602
01:46:52,170 --> 01:46:56,000
as it was only and we're going to talk about how to do that

1603
01:46:56,030 --> 01:46:59,000
i just noticed in passing here that the

1604
01:46:59,420 --> 01:47:04,110
obviously it's time run this you gonna get different results because you're going to be

1605
01:47:04,110 --> 01:47:07,550
sampling and picking a random because i k every time

1606
01:47:07,550 --> 01:47:11,900
and obviously xk plus one depends on all the size you've encountered so far so

1607
01:47:11,900 --> 01:47:13,320
it's a random variable

1608
01:47:13,420 --> 01:47:18,380
it depends on all those eyes encountered so far

1609
01:47:18,400 --> 01:47:22,380
now here have actually been adventurous and against the advice of my students left the

1610
01:47:22,380 --> 01:47:23,820
analysis in here

1611
01:47:23,980 --> 01:47:26,170
i figure that even if you could follow

1612
01:47:26,170 --> 01:47:30,760
in real time if you're interested you could go back and look at it

1613
01:47:30,800 --> 01:47:33,940
the reason i left it in is it because it's so simple really literally fits

1614
01:47:33,940 --> 01:47:35,650
into three slides

1615
01:47:35,670 --> 01:47:37,670
and so i thought it was worth putting up

1616
01:47:37,710 --> 01:47:41,300
now what we can analyse in this case is is the expectation

1617
01:47:41,320 --> 01:47:43,150
of the error in hex

1618
01:47:43,150 --> 01:47:45,710
so i define this little a k to be the

1619
01:47:45,730 --> 01:47:49,650
two norm x came under six task with the expectation that

1620
01:47:49,670 --> 01:47:54,030
the assumption is going to make is that my subgradient estimate is inside has sort

1621
01:47:54,030 --> 01:47:55,520
of bounded variance

1622
01:47:55,530 --> 01:47:59,900
OK and this can be guaranteed lot of cases of interest that if i take

1623
01:47:59,900 --> 01:48:04,860
the expectation of the square geo site has bounded by some m squared

1624
01:48:06,190 --> 01:48:10,840
now let's analyse it converges to remember this is the step taken here

1625
01:48:10,860 --> 01:48:15,880
so i'm going to look at what happens with the areas that xk plus one

1626
01:48:15,880 --> 01:48:18,840
so i'm going from here to here i'm just plugging in the definition of xk

1627
01:48:18,840 --> 01:48:20,440
plus one

1628
01:48:20,460 --> 01:48:24,420
and now i'm just expanding out that two norm squared to and i get xk

1629
01:48:24,420 --> 01:48:26,400
minus six start term here

1630
01:48:26,400 --> 01:48:28,360
i get this

1631
01:48:28,400 --> 01:48:31,840
which is a cross between x came under six dark energy term

1632
01:48:31,860 --> 01:48:36,450
and then i get alpha squared times the two norm g well just had bound

1633
01:48:36,450 --> 01:48:40,460
that an expectation so when i take the expectation of both sides

1634
01:48:40,500 --> 01:48:44,090
this gets bounded by m squared that's easy

1635
01:48:44,090 --> 01:48:47,400
the slightly tricky one is the expectation of this middle tier

1636
01:48:48,250 --> 01:48:51,250
and this is where you have to be a little bit careful because as i

1637
01:48:51,250 --> 01:48:56,420
pointed out earlier the xk depends on all those random variables like you've encountered so

1638
01:48:57,750 --> 01:49:02,380
and the expectation of g with respect to xi k is in the subgradient so

1639
01:49:02,380 --> 01:49:04,780
you can sort of use those two facts

1640
01:49:05,020 --> 01:49:06,400
some conditional

1641
01:49:06,420 --> 01:49:10,400
expectations again you know really not

1642
01:49:10,460 --> 01:49:13,170
to figure out of down on the middle middleton

1643
01:49:13,170 --> 01:49:15,690
now it turns out to be to be the critical thing

1644
01:49:15,710 --> 01:49:18,900
and once you get down in the middle term you find out that

1645
01:49:19,380 --> 01:49:20,400
going back here

1646
01:49:20,400 --> 01:49:22,980
we find that i k plus one is just a k

1647
01:49:22,980 --> 01:49:24,960
minor something nice here

1648
01:49:24,980 --> 01:49:29,820
in fact that something nice is just to mute times alpha k times a k

1649
01:49:29,860 --> 01:49:31,360
you can show

1650
01:49:31,380 --> 01:49:35,500
and then we got this last alpha k squared times m squared

1651
01:49:35,520 --> 01:49:36,980
so i've got a nice

1652
01:49:37,000 --> 01:49:40,360
o thing here which kinda gives us some hope that a k is getting smaller

1653
01:49:40,610 --> 01:49:44,380
the expectation here is going down here you can see this multiple here is less

1654
01:49:44,380 --> 01:49:48,530
than one so provided this isn't too big i'm going to be able to decrease

1655
01:49:48,530 --> 01:49:50,590
a k at every step

1656
01:49:50,590 --> 01:49:53,960
so the critical point is how do i choose is often case to make that

1657
01:49:55,150 --> 01:49:58,460
well it turns out the magic way to define alpha k is one of the

1658
01:49:58,460 --> 01:50:00,050
k times mu

1659
01:50:00,090 --> 01:50:04,530
where mu is the modulus of convexity in case the iteration number

1660
01:50:04,550 --> 01:50:07,650
so this is where i believe this is an exercise for you

1661
01:50:07,650 --> 01:50:09,710
if you want this into this

1662
01:50:09,730 --> 01:50:13,800
and do about four in could go through a sequence of four very very simple

1663
01:50:13,800 --> 01:50:18,500
inequalities you can show that a k is bounded by some constant over two times

1664
01:50:19,550 --> 01:50:22,400
with constant depends on the initial error

1665
01:50:22,480 --> 01:50:27,110
bound on the variance in the modulus of convexity so you get in expectation you

1666
01:50:27,110 --> 01:50:30,920
get sublinear convergence but to one of the k right

1667
01:50:30,940 --> 01:50:34,960
now that's really pretty amazing because when we right back at the start of the

1668
01:50:35,960 --> 01:50:40,150
i gave you steepest descent short step steepest descent method

1669
01:50:40,170 --> 01:50:41,980
they go to one of the k right

1670
01:50:42,630 --> 01:50:45,500
and here we get a one of the akira even with this

1671
01:50:45,530 --> 01:50:49,000
very crude estimate of the gradient we don't even need an exact gradient

1672
01:50:49,050 --> 01:50:52,710
we do however need strong convexity in this case

1673
01:50:52,710 --> 01:50:55,190
but we're still getting the same right

1674
01:50:56,710 --> 01:51:00,550
OK so what happens if we don't know newfie don't have a good estimate or

1675
01:51:00,550 --> 01:51:03,860
if we're not even dealing with strongly convex function what can we do in that

1676
01:51:05,050 --> 01:51:09,530
well it turns out that we can patch up what the method i just described

1677
01:51:09,570 --> 01:51:14,570
and factors this paper by nemirovski and yudin ski appear on land that appeared last

1678
01:51:14,570 --> 01:51:15,980
year and so

1679
01:51:16,000 --> 01:51:19,690
where they describe this and you can recover one of the squares k right so

1680
01:51:19,690 --> 01:51:22,480
i mean

1681
01:51:22,540 --> 01:51:28,170
i have three and five regional

1682
01:51:28,170 --> 01:51:30,230
but i

1683
01:51:48,220 --> 01:51:51,580
i can

1684
01:51:53,880 --> 01:51:55,910
what not

1685
01:51:56,170 --> 01:52:02,830
really like

1686
01:52:12,810 --> 01:52:17,350
it's a lot

1687
01:52:33,050 --> 01:52:36,540
shot and

1688
01:52:42,270 --> 01:52:50,970
you know i

1689
01:53:07,920 --> 01:53:09,060
in fact

1690
01:53:12,110 --> 01:53:15,870
project ten

1691
01:53:27,690 --> 01:53:30,150
and as

1692
01:53:44,690 --> 01:53:49,530
it's going

1693
01:53:57,270 --> 01:54:00,380
you can a

1694
01:54:00,460 --> 01:54:02,600
i mean that

1695
01:54:02,750 --> 01:54:05,530
the picture

1696
01:54:10,490 --> 01:54:16,780
the rate at

1697
01:54:40,740 --> 01:54:45,960
unlike anything

1698
01:54:46,040 --> 01:54:50,490
i'm sure one

1699
01:55:00,300 --> 01:55:06,790
that's how can

1700
01:55:32,180 --> 01:55:36,250
OK i checked out

1701
01:55:41,130 --> 01:55:49,230
but i want to

1702
01:55:50,930 --> 01:55:52,230
you can

1703
01:56:11,730 --> 01:56:18,640
you can

1704
01:56:22,000 --> 01:56:24,430
things like

1705
01:56:35,720 --> 01:56:38,520
the character

1706
01:56:45,020 --> 01:56:48,790
and if i can do

1707
01:56:48,810 --> 01:56:52,390
you can try to bring

1708
01:57:05,460 --> 01:57:13,770
we should satisfy

1709
01:57:24,910 --> 01:57:29,200
i will try i to can

1710
01:57:36,500 --> 01:57:39,460
i actually

1711
01:57:43,480 --> 01:57:50,080
that's right back

1712
01:57:50,080 --> 01:57:54,160
you see some activity building up

1713
01:57:54,180 --> 01:57:55,060
and if you

1714
01:57:57,020 --> 01:58:00,950
look at this is the left index finger and this is the right index finger

1715
01:58:00,970 --> 01:58:04,140
so you see that it's control lateral on this hemisphere

1716
01:58:04,180 --> 01:58:10,430
this is the right foot and just this

1717
01:58:10,470 --> 01:58:14,750
so if you

1718
01:58:14,770 --> 01:58:18,640
now look at

1719
01:58:18,660 --> 01:58:23,450
this plot here then it's much more so so you if you so to say

1720
01:58:23,450 --> 01:58:29,290
a few on on different hemispheres then things are easier but if you're starting to

1721
01:58:29,290 --> 01:58:32,220
be in the same hemisphere it would

1722
01:58:32,220 --> 01:58:34,680
much more complicated

1723
01:58:39,100 --> 01:58:40,620
as an example

1724
01:58:40,700 --> 01:58:41,560
if we

1725
01:58:41,580 --> 01:58:43,430
goal really in the middle

1726
01:58:43,450 --> 01:58:50,100
to this fisher his you i don't know how to pronounce it in english

1727
01:58:50,310 --> 01:58:51,970
this word here

1728
01:58:53,240 --> 01:58:55,830
and fisheries so it's not

1729
01:58:55,870 --> 01:59:02,180
the fisher from fisher discriminant but the other so anyway will go into this

1730
01:59:02,200 --> 01:59:07,370
and look at the left foot on the right foot the very close together

1731
01:59:07,370 --> 01:59:08,290
and you see

1732
01:59:08,290 --> 01:59:12,430
these activities may be i

1733
01:59:17,330 --> 01:59:18,120
so it's

1734
01:59:18,140 --> 01:59:19,490
very close by

1735
01:59:19,520 --> 01:59:26,390
and it's so if you would like to distinguish between left foot right foot then

1736
01:59:26,390 --> 01:59:31,640
this is average data so you see that is very blurry and that on the

1737
01:59:31,660 --> 01:59:34,100
single trial level this might be

1738
01:59:34,120 --> 01:59:36,390
very difficult to see

1739
01:59:41,600 --> 01:59:48,580
another thing is discriminating between the fingers so now not

1740
01:59:48,640 --> 01:59:51,720
between thing is different

1741
01:59:51,740 --> 01:59:56,720
hands but on the same hand

1742
01:59:58,430 --> 02:00:03,770
so singapore again thing thing two again finger five

1743
02:00:05,310 --> 02:00:07,890
you see that is

1744
02:00:07,950 --> 02:00:11,370
quite blurred

1745
02:00:11,370 --> 02:00:15,250
the way that it activity builds up

1746
02:00:16,160 --> 02:00:23,430
he compared to the other finger so the representations of very close by

1747
02:00:23,430 --> 02:00:24,620
so maybe

1748
02:00:24,660 --> 02:00:28,010
centimeter or less than a centimeter apart

1749
02:00:28,020 --> 02:00:32,810
and e g only has the resolution of centimetre so for this reason if you

1750
02:00:32,810 --> 02:00:36,930
classify on a single trial basis not on the on the average then you get

1751
02:00:36,930 --> 02:00:40,580
only thirty percent

1752
02:00:40,600 --> 02:00:45,520
the then you get thirty percent error instead of what we had so far five

1753
02:00:45,520 --> 02:00:48,700
or ten percent

1754
02:00:48,700 --> 02:00:50,220
so just to

1755
02:00:50,250 --> 02:00:53,160
show you this

1756
02:00:53,270 --> 02:00:58,990
there's a difference but you can see that it's it's only small

1757
02:00:58,990 --> 02:01:02,790
but if we would like to two

1758
02:01:02,830 --> 02:01:05,200
you know i understand

1759
02:01:05,220 --> 02:01:09,810
you know if whether somebody's typing something into what what thing is he's using but

1760
02:01:09,830 --> 02:01:13,310
the essential question that we should be asking

1761
02:01:21,060 --> 02:01:23,830
well it's not really

1762
02:01:23,830 --> 02:01:29,410
subset i mean it's these two fingers so you know if you have to do

1763
02:01:29,430 --> 02:01:34,490
thank you like that

1764
02:01:34,520 --> 02:01:38,740
i mean it's it's just that the representation representations very close

1765
02:01:38,750 --> 02:01:43,910
and this is one individual so you know the image is slightly different seems to

1766
02:01:43,910 --> 02:01:48,240
me it looks like that but it's not

1767
02:01:48,250 --> 02:01:50,540
it's not true

1768
02:01:57,100 --> 02:01:58,950
one i

1769
02:01:59,830 --> 02:02:03,040
well i mean i think it depends on

1770
02:02:03,040 --> 02:02:07,560
depends on the subject i find it very complicated to actually

1771
02:02:07,640 --> 02:02:09,600
you know

1772
02:02:09,620 --> 02:02:13,680
this figure fell in this

1773
02:02:13,990 --> 02:02:17,990
but anyway so so you see that

1774
02:02:18,010 --> 02:02:23,350
well the limits of this to me in fact

1775
02:02:23,370 --> 02:02:28,450
this is just this is really movements still

1776
02:02:28,450 --> 02:02:33,060
so this is the right side of the story is easy to get a letter

1777
02:02:36,350 --> 02:02:42,120
so some slight differences in the extent to this region

1778
02:02:42,180 --> 02:02:45,700
but again it's thirty percent error

1779
02:02:47,510 --> 02:02:54,350
the one of the questions that i raised was was in the beginning was can

1780
02:02:54,350 --> 02:02:55,890
we actually do

1781
02:02:55,930 --> 02:02:59,270
do something with this paradigm for

1782
02:02:59,310 --> 02:03:02,040
we have billy tation

1783
02:03:02,060 --> 02:03:04,520
and then there was the study

1784
02:03:05,080 --> 02:03:10,520
it so so maybe you don't find all these these pictures in you

1785
02:03:10,520 --> 02:03:15,720
in in you know it's this because they are rather recent results and some of

1786
02:03:15,720 --> 02:03:17,890
them are not even published

1787
02:03:19,370 --> 02:03:21,350
this is just you can

1788
02:03:21,370 --> 02:03:27,680
relax and enjoy the results so so the one of the things was one of

1789
02:03:27,680 --> 02:03:31,180
the the paradigms that we followed

1790
02:03:31,270 --> 02:03:35,120
and the more clinical setting was weird arm amputee is

1791
02:03:37,540 --> 02:03:40,810
so they would do finger movement

1792
02:03:40,830 --> 02:03:43,250
with the one on that they still had

1793
02:03:43,310 --> 02:03:47,680
and with the other are on that was norm

1794
02:03:47,700 --> 02:03:51,830
they they were thinking about this movement while they were intending it

1795
02:03:51,870 --> 02:03:54,580
but of course they could move anything

1796
02:03:54,600 --> 02:03:56,850
and the question which was

1797
02:03:56,870 --> 02:03:59,520
not really solved to this

1798
02:03:59,600 --> 02:04:02,350
o point was was whether

1799
02:04:02,390 --> 02:04:04,890
this representation that we've seen

1800
02:04:04,890 --> 02:04:06,640
with the by tufts potential


1
00:00:00,000 --> 00:00:02,400
if i were to say that

2
00:00:02,410 --> 00:00:05,810
g like two like sport

3
00:00:05,810 --> 00:00:09,400
you look as though you really like something like cricket

4
00:00:09,460 --> 00:00:12,080
you know like cricket rugby

5
00:00:13,550 --> 00:00:15,910
is there any point

6
00:00:15,930 --> 00:00:19,130
in continuing talking about cricket

7
00:00:19,130 --> 00:00:22,280
o point what's the point in time so so the first thing you need to

8
00:00:22,280 --> 00:00:25,110
do is find some sort of common ground

9
00:00:25,130 --> 00:00:28,800
something that the other person has mutually interested and what you do

10
00:00:28,830 --> 00:00:32,400
then you can be very clever about the way you communicate with people if you

11
00:00:32,400 --> 00:00:36,240
can pick up certain things about their their representational

12
00:00:36,730 --> 00:00:41,800
channels and incidentally before i go into the body language stuff how can you tell

13
00:00:41,800 --> 00:00:43,360
if i'm talking to you

14
00:00:43,400 --> 00:00:44,600
how do we know

15
00:00:44,640 --> 00:00:48,080
what preference you've whether your visual auditory organizers

16
00:00:48,120 --> 00:00:50,440
how do i find this out

17
00:00:50,470 --> 00:00:56,600
because you probably don't know yourself

18
00:00:56,640 --> 00:01:05,450
some feedback what sort of either

19
00:01:05,500 --> 00:01:10,070
OK so so if they start to get interested what else should i do what

20
00:01:10,070 --> 00:01:11,870
else can i do to find your

21
00:01:15,700 --> 00:01:19,420
listen to

22
00:01:19,440 --> 00:01:21,230
what using

23
00:01:21,240 --> 00:01:25,680
because whatever you are you're probably going to start using the word

24
00:01:25,690 --> 00:01:28,950
and this works in your own respective languages as well

25
00:01:28,970 --> 00:01:30,940
so the best ways to listen

26
00:01:30,960 --> 00:01:35,540
to what's coming about the words are they using how to express themselves

27
00:01:35,540 --> 00:01:38,900
with the what's another thing you

28
00:01:58,600 --> 00:02:01,140
so you can you can

29
00:02:01,530 --> 00:02:05,530
storytelling and you can try different stories to see which one

30
00:02:05,560 --> 00:02:07,150
the person latches onto

31
00:02:07,370 --> 00:02:11,210
absolutely another thing you can you can try and be very careful with this

32
00:02:11,250 --> 00:02:18,380
research suggests that depending on whether your visual auditory can aesthetic your eyes move in

33
00:02:18,380 --> 00:02:19,920
different directions

34
00:02:20,150 --> 00:02:25,810
so visual thinkers so to those of you chose number one

35
00:02:25,850 --> 00:02:30,400
house number one your eyes tend to do this when you're thinking

36
00:02:30,420 --> 00:02:31,390
if you look up

37
00:02:31,400 --> 00:02:36,040
because wider visual people tend to look up

38
00:02:36,060 --> 00:02:41,210
the picturing them imagining the picture if they carry on looking down this too much

39
00:02:41,210 --> 00:02:45,600
noise so they look up to to imagine the picture you know when you're in

40
00:02:45,600 --> 00:02:49,730
school and the teachers asking you to spell a word

41
00:02:49,740 --> 00:02:54,450
and you do this and the teacher will my teaches they it's the answer not

42
00:02:54,460 --> 00:02:55,600
there you know

43
00:02:55,610 --> 00:02:58,400
well actually the visual thinkers it is

44
00:02:58,420 --> 00:03:02,800
that's exactly what the answer is because they need to look up to to imagine

45
00:03:02,800 --> 00:03:04,950
the word to visual look thinkers

46
00:03:04,960 --> 00:03:07,430
have a look at people's eyes when you're talking to them do they often do

47
00:03:07,430 --> 00:03:09,830
this when they thinking

48
00:03:09,830 --> 00:03:14,380
and the probably visual auditory thinkers tend to look straight ahead

49
00:03:14,400 --> 00:03:16,120
when they thinking

50
00:03:16,130 --> 00:03:20,230
so have all the other is going to pull down the straight ahead there could

51
00:03:20,230 --> 00:03:21,230
be auditory

52
00:03:21,260 --> 00:03:24,240
and can static thinkers guess where they look

53
00:03:24,260 --> 00:03:26,540
to get in touch with their feelings

54
00:03:28,290 --> 00:03:31,820
they can assess it tends to look down when that when they're thinking so now

55
00:03:31,820 --> 00:03:34,340
you can take this to the next level

56
00:03:34,360 --> 00:03:39,140
this research also suggests that your eyes go left or right

57
00:03:39,190 --> 00:03:40,280
depending on

58
00:03:40,280 --> 00:03:44,860
when what you're thinking about in terms of time

59
00:03:44,900 --> 00:03:46,380
most people

60
00:03:46,390 --> 00:03:47,910
not everyone most people

61
00:03:47,930 --> 00:03:50,780
when you are looking to the past

62
00:03:50,820 --> 00:03:53,380
your eyes tend to go to your

63
00:03:55,580 --> 00:03:57,440
so if you think about the past

64
00:03:57,500 --> 00:03:59,870
your eyes tend to go to the left

65
00:03:59,910 --> 00:04:02,330
because when you when you're looking this way

66
00:04:02,330 --> 00:04:04,850
that's the past and that's the future

67
00:04:06,150 --> 00:04:10,080
and most people when they are thinking about the future tend to look to the

68
00:04:12,290 --> 00:04:17,980
this is quite interesting because if you're asking someone let's say you're in an interview

69
00:04:17,980 --> 00:04:21,150
and you're interviewing a person and on their

70
00:04:22,330 --> 00:04:23,300
they've put

71
00:04:23,360 --> 00:04:27,560
they've experienced building business in ten million dollar business

72
00:04:27,620 --> 00:04:29,320
ask them questions

73
00:04:29,340 --> 00:04:31,750
but also how did you do this

74
00:04:31,840 --> 00:04:35,640
and see whether i if their eyes go to the left

75
00:04:35,760 --> 00:04:38,740
maybe true because the thinking remembering

76
00:04:38,750 --> 00:04:41,100
if they go to the right

77
00:04:41,100 --> 00:04:42,320
because of

78
00:04:42,340 --> 00:04:46,450
the talking about the past and yet the riser going forward into in time this

79
00:04:46,450 --> 00:04:49,760
is where the term is more of an american expression

80
00:04:50,480 --> 00:04:54,240
the american expression is that a downright lie

81
00:04:54,300 --> 00:04:56,860
or you're a downright lie

82
00:04:56,870 --> 00:04:58,390
down right

83
00:04:58,420 --> 00:05:02,210
you get in touch with feelings and you get a very creative you line

84
00:05:02,220 --> 00:05:06,500
that's where the phrase comes from so but don't don't take this as red it's

85
00:05:06,500 --> 00:05:10,800
not true just because someone is looking to the right of the line it's just

86
00:05:11,100 --> 00:05:14,650
a generalization that people tend to look to the right when they're thinking in the

87
00:05:15,400 --> 00:05:19,140
the temple st

88
00:05:20,900 --> 00:05:22,330
if i had to

89
00:05:22,330 --> 00:05:24,710
if i had to say yes or no

90
00:05:24,730 --> 00:05:27,000
for this picture i would say yes

91
00:05:27,050 --> 00:05:28,660
they're in rapport if i had to

92
00:05:28,670 --> 00:05:32,390
but there are a few things are a little bit worrying still the facial expressions

93
00:05:32,390 --> 00:05:36,850
on exactly and he does look a little bit concerned but you can have rapport

94
00:05:36,850 --> 00:05:38,950
talking about something very serious

95
00:05:39,010 --> 00:05:41,760
you can have rapport talking about someone you know is

96
00:05:42,420 --> 00:05:45,820
basically dynamic you can still have rapport

97
00:05:45,870 --> 00:05:49,470
you don't have to be laughing

98
00:05:49,490 --> 00:05:51,330
OK so

99
00:05:51,330 --> 00:05:55,040
a number of ways we can do this we have really mentioned vocal yet we've

100
00:05:55,040 --> 00:05:55,850
mentioned the verbal

101
00:05:56,300 --> 00:05:58,940
we mention visual you can start looking

102
00:05:58,990 --> 00:06:00,880
people who are not post

103
00:06:00,920 --> 00:06:03,630
the start looking like each other which is very interesting

104
00:06:05,570 --> 00:06:06,720
you can have rapport

105
00:06:06,740 --> 00:06:10,100
when you match the other person's voice

106
00:06:10,100 --> 00:06:13,370
people are pulling someone's talking slowly

107
00:06:13,380 --> 00:06:15,850
the other person tends to talk slowly

108
00:06:15,860 --> 00:06:17,760
if someone's quiet

109
00:06:17,870 --> 00:06:20,240
the other person tends to be quiet as well

110
00:06:20,260 --> 00:06:23,030
if they've got that connection and that report

111
00:06:23,160 --> 00:06:27,320
can is that it's an interesting one

112
00:06:27,360 --> 00:06:29,310
can aesthetic rapport

113
00:06:29,360 --> 00:06:33,130
you can even have rapport in terms of breathing

114
00:06:33,140 --> 00:06:35,850
one when people are really

115
00:06:35,870 --> 00:06:37,940
in synchronization with each other

116
00:06:37,970 --> 00:06:40,540
they start breeding at the same rate

117
00:06:40,550 --> 00:06:42,830
as well

118
00:06:42,850 --> 00:06:44,970
i i didn't experiments

119
00:06:46,640 --> 00:06:52,890
ten years ago i didn't experiment at the time i had a nephews about six

120
00:06:52,890 --> 00:06:55,130
six seven eight months old

121
00:06:55,140 --> 00:06:56,560
names of irony

122
00:06:56,570 --> 00:07:01,470
and i was looking after doing a bit of babysitting for my sister and he

123
00:07:01,470 --> 00:07:03,720
wouldn't stop crying

124
00:07:03,840 --> 00:07:09,240
and i remember this thing that read somewhere about breathing levels and how you can

125
00:07:09,240 --> 00:07:12,510
essentially what we end up in learning

126
00:07:12,530 --> 00:07:16,650
he is this problem probabilities for the topics

127
00:07:16,650 --> 00:07:17,360
and now

128
00:07:17,380 --> 00:07:22,720
we can do recognition using the model we have learned we give

129
00:07:22,740 --> 00:07:24,170
a novel image

130
00:07:24,170 --> 00:07:26,220
we represented

131
00:07:27,150 --> 00:07:30,360
we represented as a bag of words

132
00:07:30,470 --> 00:07:34,780
and then we take these models we have learned and select

133
00:07:34,840 --> 00:07:40,150
the most probable topic which corresponds to the category in the PLSA case

134
00:07:40,200 --> 00:07:50,140
in LDA case we actually to select the most probable category marginalized likelihood for the

135
00:07:51,300 --> 00:07:58,570
viable so in any case this is the overall structure system of these

136
00:07:58,610 --> 00:08:06,050
algorithms of course we have to from of visual object categorisation point of view we

137
00:08:06,050 --> 00:08:10,430
have to go back and think about some of the issues we we talked about

138
00:08:10,450 --> 00:08:16,030
in the beginning such issues are scale and rotation we don't have explicit scale and

139
00:08:16,030 --> 00:08:23,450
rotation in in in the model models what we have it is implicit so the

140
00:08:23,490 --> 00:08:30,700
just detectors and descriptors we know how do we take of inclusion i believe this

141
00:08:30,700 --> 00:08:40,260
is actually quite relatively robust model for occlusion because it uses these broken down broken

142
00:08:40,260 --> 00:08:45,430
down patches it doesn't really force you to have the entire image as long as

143
00:08:45,430 --> 00:08:49,400
it has enough enough

144
00:08:49,820 --> 00:08:55,700
enough patches to represent your object category that's fine and also in theory we can

145
00:08:55,700 --> 00:09:02,010
think about actually built in this knowledge into the different latent themes or topics

146
00:09:02,030 --> 00:09:07,240
how do we encode translation while that of words model

147
00:09:07,280 --> 00:09:09,780
i don't have translation issue at all

148
00:09:10,780 --> 00:09:12,970
but there are people who have

149
00:09:13,010 --> 00:09:17,220
i attempted to deal with translation by adding a reference

150
00:09:18,340 --> 00:09:20,220
and then we

151
00:09:20,240 --> 00:09:25,170
how do we deal with viewpoint variations again

152
00:09:25,200 --> 00:09:31,380
its implicit in the descriptor and detector but again you can think of in theory

153
00:09:31,690 --> 00:09:36,110
it's nobody has tested this yet but in theory you can put this into the

154
00:09:36,590 --> 00:09:40,050
latent topics and

155
00:09:40,110 --> 00:09:44,760
so what is the properties of this bag of words model was very intuitive it's

156
00:09:44,780 --> 00:09:48,070
analogous to documents and

157
00:09:48,110 --> 00:09:50,740
it's actually very

158
00:09:50,780 --> 00:09:53,340
and very nice way of

159
00:09:53,380 --> 00:09:57,450
of setting up the problem so that we can use a lot of these useful

160
00:09:57,490 --> 00:10:04,450
generative models and and it's very convenient a because ten the power of generative models

161
00:10:04,450 --> 00:10:08,720
some of the some of the power is you can use it for unsupervised training

162
00:10:08,720 --> 00:10:12,950
or weakly supervised training you could incorporate prior information

163
00:10:12,950 --> 00:10:14,220
you can just

164
00:10:14,240 --> 00:10:21,010
i have a lot of expressive power for your data space and then

165
00:10:21,190 --> 00:10:28,530
the learning and recognition is relatively fast compared to many other methods

166
00:10:28,550 --> 00:10:33,570
but what some of the weaknesses of the model the one of the really most

167
00:10:33,570 --> 00:10:37,880
salient weakness is the lack of geometric information

168
00:10:38,820 --> 00:10:45,320
we really ought to think about how do we feel that information in test whether

169
00:10:45,610 --> 00:10:51,220
how much it adds to the to the model and then it's so far the

170
00:10:51,220 --> 00:10:57,700
models are not tested extensively for all these invariances and of course

171
00:10:57,720 --> 00:11:02,380
if you believe in understanding image include

172
00:11:02,400 --> 00:11:08,200
after segmentation then this model is not clear yet how we can use that as

173
00:11:08,200 --> 00:11:10,200
of now to do segmentation

174
00:11:10,280 --> 00:11:13,320
this is actually the first point

175
00:11:13,340 --> 00:11:18,320
no rigorous geometric information brings us to the second

176
00:11:18,340 --> 00:11:22,630
and the last model i'm going to talk about today which is part based model

177
00:11:24,880 --> 00:11:28,950
so we've seen in the bag of words model here bag of words model is

178
00:11:28,950 --> 00:11:35,990
basically we represent images like this but you know i think it's really a face

179
00:11:35,990 --> 00:11:39,400
here the images truly like this

180
00:11:39,430 --> 00:11:42,630
the bag of words model was say yes there is a face

181
00:11:42,630 --> 00:11:49,220
it's really not phases of scrambled phase which is not realistic instead

182
00:11:49,260 --> 00:11:50,720
if we see

183
00:11:50,740 --> 00:11:51,970
this dispatches

184
00:11:51,990 --> 00:11:58,110
right arranged like let's in the image we have the better believe stronger believe that

185
00:11:58,110 --> 00:12:00,130
and this is the y direction

186
00:12:00,150 --> 00:12:03,170
and this is the next

187
00:12:03,230 --> 00:12:04,590
and i'm going to

188
00:12:04,630 --> 00:12:07,000
every wave coming in from the left

189
00:12:07,040 --> 00:12:10,670
it's called the incident rays

190
00:12:10,690 --> 00:12:12,150
and so i will give

191
00:12:13,380 --> 00:12:15,270
moving in this direction

192
00:12:15,290 --> 00:12:16,290
and then

193
00:12:16,300 --> 00:12:18,020
there will be a reflection

194
00:12:18,040 --> 00:12:19,420
which i call are

195
00:12:19,420 --> 00:12:21,130
something may come back

196
00:12:21,200 --> 00:12:23,480
this direction

197
00:12:23,520 --> 00:12:25,770
of the one

198
00:12:29,440 --> 00:12:32,840
and then something is being transmitted

199
00:12:32,960 --> 00:12:36,300
into the second medium get that structure

200
00:12:36,320 --> 00:12:39,540
we are

201
00:12:39,630 --> 00:12:40,570
and that

202
00:12:40,570 --> 00:12:45,020
it's going into media number two

203
00:12:45,090 --> 00:12:50,300
and that's what i want to evaluate

204
00:12:50,320 --> 00:12:53,940
i have boundary conditions that actually call zero i told you earlier

205
00:12:53,960 --> 00:12:58,690
all of the three things together wave equations and boundary conditions

206
00:12:58,730 --> 00:13:00,090
that's true

207
00:13:00,110 --> 00:13:03,210
the boundary condition is that x equals zero

208
00:13:03,230 --> 00:13:05,920
why we must be two

209
00:13:06,920 --> 00:13:08,610
the string breaks

210
00:13:08,630 --> 00:13:10,230
why right here

211
00:13:10,290 --> 00:13:12,920
must be the same as the y right there otherwise there will be a break

212
00:13:12,920 --> 00:13:14,190
of the string

213
00:13:14,250 --> 00:13:15,690
but not only that

214
00:13:15,710 --> 00:13:17,500
y one

215
00:13:18,750 --> 00:13:20,070
it must also be

216
00:13:20,130 --> 00:13:23,020
the y two dx

217
00:13:23,090 --> 00:13:24,860
if that were not the case

218
00:13:24,860 --> 00:13:26,610
that would be kink

219
00:13:26,610 --> 00:13:29,590
in the

220
00:13:29,650 --> 00:13:31,250
role at the

221
00:13:34,000 --> 00:13:35,440
his attention here

222
00:13:35,470 --> 00:13:39,590
there tension here which would be a net force down

223
00:13:39,630 --> 00:13:40,380
but the

224
00:13:40,520 --> 00:13:43,150
the junction itself has zero mass

225
00:13:43,190 --> 00:13:47,460
so to give an infinite acceleration so you can never have king

226
00:13:47,520 --> 00:13:52,770
in a strange not even when it is connected like this was not history

227
00:13:52,790 --> 00:13:55,460
so it must be something that is always

228
00:13:55,540 --> 00:13:58,250
here that

229
00:13:58,290 --> 00:14:00,840
could be like that cannot be like this

230
00:14:00,920 --> 00:14:03,270
and so that's on the condition that the

231
00:14:03,320 --> 00:14:07,190
the relative the spatial derivative from the left must be the same as on the

232
00:14:07,190 --> 00:14:09,540
right side

233
00:14:09,590 --> 00:14:11,320
for a start

234
00:14:11,340 --> 00:14:14,980
with an incident wave

235
00:14:15,060 --> 00:14:17,250
comes from the left

236
00:14:17,380 --> 00:14:18,670
so why why one

237
00:14:18,710 --> 00:14:20,710
why i

238
00:14:20,710 --> 00:14:23,480
i incident

239
00:14:23,480 --> 00:14:28,500
some amplitude a of identity and the incident one

240
00:14:28,500 --> 00:14:30,650
times science

241
00:14:30,650 --> 00:14:34,650
i'm going to write is now we can write it in many different ways right

242
00:14:35,630 --> 00:14:37,590
there's only one

243
00:14:39,630 --> 00:14:41,380
e one x

244
00:14:41,420 --> 00:14:45,060
that's clearly traveling wave that moves in the plus direction

245
00:14:45,110 --> 00:14:48,020
because the signs are different

246
00:14:48,090 --> 00:14:49,130
now i have

247
00:14:51,360 --> 00:14:52,170
we have

248
00:14:52,420 --> 00:14:54,360
it's a reflected

249
00:14:54,380 --> 00:14:55,670
times the size

250
00:14:56,690 --> 00:14:58,250
the same frequency

251
00:14:58,270 --> 00:14:59,900
now i got a plus

252
00:14:59,960 --> 00:15:01,170
OK one

253
00:15:02,250 --> 00:15:04,440
what is the difference in size

254
00:15:04,460 --> 00:15:06,130
this one is going this way

255
00:15:06,170 --> 00:15:08,420
this one is coming back

256
00:15:08,440 --> 00:15:10,920
amplitudes i different

257
00:15:10,920 --> 00:15:13,110
but the case and the same

258
00:15:13,130 --> 00:15:16,650
because the wavelength in medium one is the same

259
00:15:16,670 --> 00:15:18,570
case two pi overlap

260
00:15:18,630 --> 00:15:21,820
that wavelength is is not going to change for this wave as it is for

261
00:15:21,820 --> 00:15:23,190
this one

262
00:15:23,270 --> 00:15:26,170
so now i get to transmit one

263
00:15:26,190 --> 00:15:27,790
its amplitude

264
00:15:30,070 --> 00:15:31,790
times the size

265
00:15:31,790 --> 00:15:34,630
of the same omega

266
00:15:34,690 --> 00:15:36,480
because if this junction

267
00:15:36,500 --> 00:15:40,900
she looks up and down with frequency omega that's the same for both media

268
00:15:40,940 --> 00:15:45,630
so omega is given you can change omega can omega is different from the right

269
00:15:45,630 --> 00:15:48,130
side of this for the left side

270
00:15:48,150 --> 00:15:49,190
in other words

271
00:15:49,190 --> 00:15:51,000
omega one

272
00:15:51,020 --> 00:15:53,920
is the one time scale

273
00:15:53,920 --> 00:15:55,060
but it is also

274
00:15:56,300 --> 00:15:59,570
times k to disable maker

275
00:15:59,650 --> 00:16:01,320
so i get here

276
00:16:04,290 --> 00:16:10,360
x goes into the second medium the minus sign indicates there's going in this direction

277
00:16:10,360 --> 00:16:12,980
that the k two is different

278
00:16:13,000 --> 00:16:15,540
because the speed

279
00:16:15,610 --> 00:16:16,860
is different

280
00:16:16,960 --> 00:16:21,690
because the two is different from v one so with the same frequency i get

281
00:16:21,730 --> 00:16:23,090
a different value

282
00:16:25,340 --> 00:16:29,690
so now i go to my boundary conditions by one equals y two

283
00:16:29,690 --> 00:16:31,750
what you see here

284
00:16:31,820 --> 00:16:33,770
then i get there that

285
00:16:33,860 --> 00:16:35,320
a of y

286
00:16:35,320 --> 00:16:38,070
a of i

287
00:16:39,940 --> 00:16:41,460
x equals zero

288
00:16:41,560 --> 00:16:43,840
any moment in time

289
00:16:43,860 --> 00:16:46,860
i must know that condition so a of i

290
00:16:46,920 --> 00:16:48,670
as a or

291
00:16:48,690 --> 00:16:49,770
must be

292
00:16:50,880 --> 00:16:52,270
you are

293
00:16:52,290 --> 00:16:53,820
if not then the string

294
00:16:53,820 --> 00:16:56,270
or break

295
00:16:56,320 --> 00:16:59,840
i can now take the derivative of my function

296
00:16:59,880 --> 00:17:02,730
the y one b x

297
00:17:02,730 --> 00:17:05,110
this is the case

298
00:17:05,130 --> 00:17:08,500
of these one not small

299
00:17:08,520 --> 00:17:09,940
you find

300
00:17:17,440 --> 00:17:18,810
now also here

301
00:17:18,810 --> 00:17:22,110
more like it's a lot

302
00:17:22,190 --> 00:17:24,840
i don't know to can

303
00:17:24,920 --> 00:17:28,650
the correct this is the last version of the time with

304
00:17:28,650 --> 00:17:31,040
on the side

305
00:17:33,690 --> 00:17:38,340
and now for something because you might want to what

306
00:17:38,360 --> 00:17:43,750
what can i do with this information extraction

307
00:17:46,170 --> 00:17:49,750
the book you want

308
00:17:49,770 --> 00:17:54,690
but if you look at the relationship between two entities

309
00:17:54,710 --> 00:18:01,750
if you think it could be that like the example i did yesterday that

310
00:18:01,770 --> 00:18:05,650
companies merging with another company you want to find

311
00:18:05,710 --> 00:18:11,920
relationship or you might want to find other relationship like this example of

312
00:18:11,940 --> 00:18:16,840
the of stories published here two thousand four

313
00:18:17,210 --> 00:18:21,330
so you want to find one

314
00:18:21,340 --> 00:18:23,290
the entities through

315
00:18:23,310 --> 00:18:26,630
and the other secret

316
00:18:26,650 --> 00:18:29,790
in one of the form

317
00:18:29,810 --> 00:18:32,730
you might be full kind of movement

318
00:18:35,790 --> 00:18:39,420
so we can build upon from

319
00:18:39,440 --> 00:18:43,340
this event

320
00:18:43,340 --> 00:18:46,480
r from the centre of things

321
00:18:46,530 --> 00:18:48,920
you see the

322
00:18:48,920 --> 00:18:54,330
note the words in the past and each one

323
00:18:54,340 --> 00:18:58,520
it is described by a number of features

324
00:18:58,560 --> 00:19:04,000
and you have all the the parts of the relationship you far more than the

325
00:19:08,440 --> 00:19:10,000
i have a dependence

326
00:19:11,480 --> 00:19:15,830
so were

327
00:19:15,840 --> 00:19:21,570
each is easy part of speech can be used the

328
00:19:21,590 --> 00:19:25,020
twenty four value which means that

329
00:19:25,040 --> 00:19:26,860
the bank

330
00:19:26,880 --> 00:19:29,790
so far features that now

331
00:19:29,880 --> 00:19:32,630
proper nouns

332
00:19:32,650 --> 00:19:38,940
you might use is maybe a bit of a new champion you

333
00:19:42,540 --> 00:19:48,020
well it when you have a part of speech tags to a few words of

334
00:19:48,210 --> 00:19:49,520
a sentence

335
00:19:49,570 --> 00:19:53,940
general will lie group of would gather

336
00:19:53,940 --> 00:19:55,330
like the

337
00:19:55,750 --> 00:19:59,230
so if you

338
00:19:59,270 --> 00:20:01,250
the log

339
00:20:04,130 --> 00:20:08,340
the large land the city of new york

340
00:20:10,090 --> 00:20:15,630
ten is the large map of the the city of new york so the three

341
00:20:15,710 --> 00:20:17,830
not sure

342
00:20:17,840 --> 00:20:19,880
so think of words

343
00:20:19,900 --> 00:20:22,040
if you take the word

344
00:20:22,230 --> 00:20:24,630
to get point

345
00:20:25,770 --> 00:20:31,570
but there is no no dependency when you show

346
00:20:31,610 --> 00:20:33,690
there are no bad

347
00:20:34,070 --> 00:20:36,790
i recommend you

348
00:20:36,810 --> 00:20:38,310
it's just that you

349
00:20:38,330 --> 00:20:42,400
the sentence in set b

350
00:20:42,420 --> 00:20:50,810
here is the time

351
00:20:50,850 --> 00:20:53,830
a person

352
00:20:55,650 --> 00:20:58,670
also the geo-political and

353
00:20:58,690 --> 00:21:01,880
so i also think it entity

354
00:21:01,900 --> 00:21:02,630
so you

355
00:21:02,630 --> 00:21:05,710
it's supposed that you have to be

356
00:21:05,710 --> 00:21:07,730
that gives

357
00:21:07,750 --> 00:21:10,360
this kind of information

358
00:21:10,380 --> 00:21:12,090
or you might think

359
00:21:12,150 --> 00:21:15,000
in the classification

360
00:21:15,020 --> 00:21:19,380
well you would need to accomplish

361
00:21:19,650 --> 00:21:21,730
also the entity

362
00:21:21,750 --> 00:21:25,360
so now can be a like to create

363
00:21:25,360 --> 00:21:26,400
it can be

364
00:21:26,400 --> 00:21:29,270
just announce like two

365
00:21:29,340 --> 00:21:33,110
it can be of what could be

366
00:21:33,480 --> 00:21:35,500
some of

367
00:21:35,750 --> 00:21:44,810
and then also the argument that all schools are where the degree of

368
00:21:44,840 --> 00:21:47,730
so here you've read the

369
00:21:47,900 --> 00:21:49,960
it is actually

370
00:21:50,090 --> 00:21:52,940
the acts

371
00:21:52,980 --> 00:21:56,000
what people are the and the

372
00:21:57,400 --> 00:22:01,090
another second arguement is not affected by

373
00:22:01,110 --> 00:22:04,110
an argument with this

374
00:22:04,130 --> 00:22:05,440
so you can

375
00:22:05,440 --> 00:22:06,310
you have

376
00:22:06,330 --> 00:22:10,290
a more accurate representation of

377
00:22:10,330 --> 00:22:12,270
your data

378
00:22:12,330 --> 00:22:18,290
you don't have to let back to new york city and each node of the

379
00:22:18,290 --> 00:22:23,960
thing that you can define also the values

380
00:22:24,210 --> 00:22:29,750
and then

381
00:22:30,930 --> 00:22:34,790
when you're actually willing to compare

382
00:22:34,810 --> 00:22:37,540
the similarity of three

383
00:22:37,540 --> 00:22:39,670
if you have a

384
00:22:39,710 --> 00:22:43,540
the support vector machine when you

385
00:22:43,900 --> 00:22:47,330
so you will compare the similarity to

386
00:22:47,360 --> 00:22:49,750
between each pair of j

387
00:22:49,810 --> 00:22:52,980
but also when you will find you

388
00:22:53,040 --> 00:23:00,960
you will that will come similarity of q of you use with the model

389
00:23:00,980 --> 00:23:02,480
the model

390
00:23:02,500 --> 00:23:06,590
the support vectors that you have

391
00:23:06,610 --> 00:23:16,610
so what is really computer

392
00:23:16,630 --> 00:23:17,900
the old

393
00:23:17,900 --> 00:23:20,980
by criminals

394
00:23:25,330 --> 00:23:29,500
the actual text i think you to

395
00:23:29,560 --> 00:23:32,480
which is defined in the u

396
00:23:32,480 --> 00:23:34,750
good morning

397
00:23:34,790 --> 00:23:36,350
so i see we have

398
00:23:36,370 --> 00:23:40,590
a lot of parents here how many parents we got here

399
00:23:40,680 --> 00:23:42,380
welcome to the parents

400
00:23:42,400 --> 00:23:44,370
how many of the parents have done the reading

401
00:23:45,790 --> 00:23:48,410
so good design work on the parents to

402
00:23:48,680 --> 00:23:50,480
will see that

403
00:23:53,640 --> 00:23:56,260
we've talked about

404
00:23:56,360 --> 00:24:00,820
this diagram i keep coming back to if you want to study biological function the

405
00:24:00,830 --> 00:24:04,520
two traditional ways to do that we're looking genetics

406
00:24:04,570 --> 00:24:10,590
world biochemistry genetics the study of an organism with one broken components those components being

407
00:24:10,590 --> 00:24:13,180
genes biochemistry

408
00:24:13,200 --> 00:24:19,850
the study of the purification of individual components from an organism away from the organism

409
00:24:19,850 --> 00:24:23,690
particularly the most important such components being proteins what they have to do to each

410
00:24:23,690 --> 00:24:25,720
other the unification

411
00:24:25,800 --> 00:24:31,170
in molecular biology that occurred in the middle of the century from nineteen fifties and

412
00:24:31,170 --> 00:24:37,220
the sixties and really up to nineteen seventy or so we came to a conceptual

413
00:24:37,220 --> 00:24:39,510
understanding that

414
00:24:39,520 --> 00:24:45,410
genes encode proteins and therefore these different ways of looking at the organism organism minus

415
00:24:45,440 --> 00:24:51,010
component components mine organisms were complementary point of view and in theory you could go

416
00:24:51,020 --> 00:24:56,460
from the gene sequence protein sequence and protein sequence back to gene sequence you could

417
00:24:56,460 --> 00:24:59,720
go for gene sequences functions functions with protein

418
00:24:59,740 --> 00:25:04,020
except for one tiny detail

419
00:25:04,040 --> 00:25:06,460
this was all just conceptual

420
00:25:06,510 --> 00:25:08,760
conceptually we understood

421
00:25:08,770 --> 00:25:11,440
by the nineteen seventy that the

422
00:25:11,450 --> 00:25:16,920
DNA may RNA made the protein the protein carried out the function

423
00:25:16,940 --> 00:25:18,620
but as of then

424
00:25:18,700 --> 00:25:19,990
you couldn't

425
00:25:20,000 --> 00:25:22,700
individually work with our purify

426
00:25:22,710 --> 00:25:26,570
the DNA corresponding to any particular gene

427
00:25:26,580 --> 00:25:35,390
all the inferences indirect inferences indirect inferences from bacterial genetics better regulation or missiles small

428
00:25:35,410 --> 00:25:41,450
experiments in all sorts of interesting indirect ways working at the genetic code but the

429
00:25:41,530 --> 00:25:42,100
o thing

430
00:25:42,120 --> 00:25:44,830
this is the problem

431
00:25:45,070 --> 00:25:49,930
some people in the late nineteen sixties said great molecular biology is over we understand

432
00:25:49,930 --> 00:25:53,440
the principle how life works now let's go understand how the brain works

433
00:25:53,450 --> 00:25:57,320
and there was an exodus of some people from molecular biology and neurobiology to now

434
00:25:57,320 --> 00:26:02,610
go the brain figured out fewer than ten years or so but in fact

435
00:26:04,030 --> 00:26:10,160
people began to focus on how you can get to work with individuals specific genes

436
00:26:10,360 --> 00:26:13,500
now what's so hard about that mean it's not very hard to crack open red

437
00:26:13,500 --> 00:26:19,700
blood cell and purify different proteins purified hemoglobin you can provide even enzymes chemistry allows

438
00:26:19,700 --> 00:26:24,210
you to purify different components from each other want fine enzyme let's crack open the

439
00:26:25,110 --> 00:26:29,560
separate proteins over some column that separates them based on their size and their charge

440
00:26:29,560 --> 00:26:33,450
money pure inter fractions all or as a traction to see which one has the

441
00:26:33,450 --> 00:26:39,080
enzymatic activity but they use the physical chemical properties of the protein to separate them

442
00:26:39,080 --> 00:26:42,080
into different pockets why not do that would say

443
00:26:42,100 --> 00:26:46,740
human DNA and purify out the gene for beta globin codes

444
00:26:46,890 --> 00:26:49,780
he would the beta component hemoglobin

445
00:26:49,830 --> 00:26:54,150
what would be the problem of just using physical chemical purification to purify one human

446
00:26:54,150 --> 00:26:57,470
gene from another

447
00:26:57,670 --> 00:27:01,130
is one very big molecule

448
00:27:01,220 --> 00:27:04,880
well i could be sure that may be able to break it up

449
00:27:04,900 --> 00:27:08,680
now let's purified beta globin containing part

450
00:27:08,730 --> 00:27:11,830
it looks the same it's just the

451
00:27:11,840 --> 00:27:15,590
it's one chemical palmer was pretty boring properties

452
00:27:15,600 --> 00:27:20,290
and they're not very different any particular DNA sequence in any other DNA sequence basically

453
00:27:20,290 --> 00:27:23,780
about the same molecular weights and charges there's nothing to separate by how you gonna

454
00:27:23,790 --> 00:27:28,380
purify better

455
00:27:28,400 --> 00:27:30,530
that was the problem

456
00:27:30,660 --> 00:27:35,720
that's where all coming in DNA came in which were common DNA was a remarkable

457
00:27:35,720 --> 00:27:39,870
and totally different way of purifying individual components

458
00:27:40,000 --> 00:27:44,370
and the basis of it was this notion of cloning

459
00:27:44,440 --> 00:27:48,310
if i want to purify out from the human genome having human genome

460
00:27:48,380 --> 00:27:50,930
human genomes about

461
00:27:50,980 --> 00:27:53,560
three billion bases long

462
00:27:53,580 --> 00:27:58,560
if i want to purify particular gene what's a beta globin or some other gene

463
00:27:58,560 --> 00:28:00,280
typical gene

464
00:28:00,460 --> 00:28:04,180
might be

465
00:28:04,190 --> 00:28:05,520
on the order of

466
00:28:05,530 --> 00:28:09,460
thirty thousand letters long

467
00:28:09,480 --> 00:28:12,500
this is one part in ten to fifteen

468
00:28:12,510 --> 00:28:14,340
purification of go to achieve

469
00:28:14,370 --> 00:28:17,150
any given gene is only one part in ten to the fifth of the human

470
00:28:17,150 --> 00:28:20,200
genome and then what about a typical mutation

471
00:28:20,220 --> 00:28:23,390
maybe the mutation that causes

472
00:28:23,400 --> 00:28:29,090
the chemical that causes sickle-cell anaemia by changing a single nucleotide beta globin well that's

473
00:28:29,090 --> 00:28:31,330
one base pair

474
00:28:31,340 --> 00:28:32,970
so that means

475
00:28:32,970 --> 00:28:35,310
the surface built by decision tree

476
00:28:35,320 --> 00:28:39,610
you can think of it as a constant these

477
00:28:39,740 --> 00:28:43,750
estimated cost and so that means in the region he had

478
00:28:43,760 --> 00:28:47,840
and this is the indicator function if ec if your input is in this region

479
00:28:47,840 --> 00:28:48,960
so m

480
00:28:50,220 --> 00:28:54,820
it's someone else to zero and multiplied by the constant in the tree model

481
00:28:54,830 --> 00:28:59,640
can be thought of as the sum of all these regions

482
00:28:59,660 --> 00:29:03,650
so these regions are defined by different levels

483
00:29:03,670 --> 00:29:11,580
and they're hyperrectangles

484
00:29:12,250 --> 00:29:14,080
the trees allow for

485
00:29:14,100 --> 00:29:18,820
different scoring criteria the two most famous the two most used are square

486
00:29:18,870 --> 00:29:23,340
where there is the ideal constant is the mean

487
00:29:23,390 --> 00:29:27,820
and the absolute there were no constant is the median of the population

488
00:29:27,840 --> 00:29:34,110
so one of these two loss functions that is averaged over the data and they

489
00:29:34,110 --> 00:29:37,150
share your risk

490
00:29:37,170 --> 00:29:40,190
so you want to find the tree with the lowest prediction risk

491
00:29:40,210 --> 00:29:46,420
so you searching over the space of these constants in regions too

492
00:29:46,440 --> 00:29:48,150
minimize squared error

493
00:29:48,160 --> 00:29:49,690
for instance

494
00:29:52,160 --> 00:29:54,080
this is a tree model

495
00:29:54,090 --> 00:29:56,720
and to do this in unrestricted way

496
00:29:56,720 --> 00:30:00,140
it's extraordinarily difficult

497
00:30:03,980 --> 00:30:07,310
universal technique is to restrict the regions to be

498
00:30:07,320 --> 00:30:12,060
disjoint to cover the space to be simple in some way so here's one we

499
00:30:12,060 --> 00:30:16,920
can define a region in an ordered way and so another region behind

500
00:30:16,940 --> 00:30:20,130
we would show up but the typical way is to

501
00:30:21,760 --> 00:30:24,040
is too

502
00:30:24,080 --> 00:30:25,560
provide splits

503
00:30:25,580 --> 00:30:29,080
their independence and conditional previous

504
00:30:34,380 --> 00:30:40,320
justice with stepwise linear regression which is the greedy iterative procedure for deciding which inputs

505
00:30:40,320 --> 00:30:42,470
to use regression format

506
00:30:42,470 --> 00:30:46,310
that's the the typical way that decision trees down

507
00:30:46,430 --> 00:30:48,120
so you start with all the data

508
00:30:49,220 --> 00:30:53,530
we check each each possible split value and

509
00:30:53,530 --> 00:30:58,380
define a score function that tells how the quality of the split

510
00:30:58,400 --> 00:31:01,060
how much you reduce the variance using square

511
00:31:01,060 --> 00:31:02,410
how much should use the

512
00:31:02,850 --> 00:31:04,500
the least absolute deviation

513
00:31:04,510 --> 00:31:06,300
if is an absolutely

514
00:31:06,310 --> 00:31:10,980
so you choose the input and the split that improve the fit the most you

515
00:31:10,980 --> 00:31:15,220
again greatly the single that improves the most with no regard to what's going to

516
00:31:15,220 --> 00:31:19,240
happen subsequently and then you replace here

517
00:31:19,290 --> 00:31:25,080
original regions with these two new regions into it recursively again

518
00:31:25,100 --> 00:31:29,780
so the big question is when should we stop and if you go to tree

519
00:31:29,830 --> 00:31:34,470
talks and support people argue about whether we should use case going to stop or

520
00:31:34,470 --> 00:31:37,260
if we should overfitting then used car sales

521
00:31:37,300 --> 00:31:44,270
carter technique for instance overfits intensely and then decide how far back to prove

522
00:31:44,390 --> 00:31:48,160
and to reabsorbed cuts and so forth so

523
00:31:49,100 --> 00:31:53,900
this simple algorithm can probably could i one i could up to my first tree

524
00:31:53,900 --> 00:31:58,820
algorithm is one or two pages of seeker is all it takes but of course

525
00:31:58,820 --> 00:32:02,610
to handle real data and category data missing values and so forth

526
00:32:02,810 --> 00:32:08,210
would take hundreds and sometimes thousands of lines

527
00:32:09,120 --> 00:32:13,690
some of the great strengths that can deal with irrelevant inputs

528
00:32:13,750 --> 00:32:18,640
input is shows up in the tree or does so naturally does variable selection

529
00:32:19,150 --> 00:32:23,540
and you can you can do anything you can measure you can use it can

530
00:32:23,540 --> 00:32:27,980
is categorical variables ordinal variables and numeric support

531
00:32:28,110 --> 00:32:30,900
and you you get a an important school

532
00:32:30,960 --> 00:32:35,110
better tree algorithms will tell you how useful variables were

533
00:32:37,920 --> 00:32:41,150
monotonic transformations won't affect

534
00:32:41,150 --> 00:32:44,090
so you don't have have problems with outliers

535
00:32:44,110 --> 00:32:48,710
if the value is three point one four or three thousand one hundred it's greater

536
00:32:48,710 --> 00:32:54,040
than three so the questions being asked are insensitive to outliers in your in your

537
00:32:54,040 --> 00:32:57,080
input there's not much output

538
00:32:58,960 --> 00:33:01,250
they're very fast compared to

539
00:33:01,310 --> 00:33:03,360
other iterative techniques

540
00:33:03,480 --> 00:33:07,540
missing values can be handled the cup of different ways either

541
00:33:07,590 --> 00:33:11,940
in circuit split is hell cart doesn't work comes up with substitute split in case

542
00:33:11,940 --> 00:33:16,900
the first variables unknown what variables will best replicated this the splitting of the data

543
00:33:17,170 --> 00:33:21,770
that you might know so sort of a stack of questions you ask any state

544
00:33:21,770 --> 00:33:25,130
very clever way handling missing data other techniques other

545
00:33:25,150 --> 00:33:27,900
algorithms creating new class called missing

546
00:33:27,960 --> 00:33:32,310
but maybe it may not be missing man random there may be information in its

547
00:33:32,310 --> 00:33:35,980
missing this and so that this might be a good way to split

548
00:33:36,000 --> 00:33:42,230
off the shelf the future and will parameters you can use and within minutes of

549
00:33:42,230 --> 00:33:43,290
learning about them

550
00:33:44,190 --> 00:33:48,340
if you have a single tree it's very interpretable this too few levels you can

551
00:33:48,340 --> 00:33:53,290
say the state of the question which is very useful when you're doing consulting to

552
00:33:53,290 --> 00:33:55,360
be able to interpret required where

553
00:33:55,380 --> 00:33:57,440
the problems are coming from or where the

554
00:33:57,460 --> 00:33:59,590
the best clients are

555
00:33:59,810 --> 00:34:01,650
so four

556
00:34:01,670 --> 00:34:03,960
now they have severe limitations

557
00:34:04,270 --> 00:34:08,810
if you're trying to fit a trend piecewise constant served very

558
00:34:08,860 --> 00:34:13,790
four way to do that so you also need a lot of data it exponentially

559
00:34:13,790 --> 00:34:15,920
each through your data by splitting

560
00:34:15,980 --> 00:34:17,230
splitting data

561
00:34:17,230 --> 00:34:22,610
so in high dimensions especially data is already very sparse

562
00:34:25,480 --> 00:34:31,150
if there is little interaction in your underlying another small river trent then

563
00:34:31,210 --> 00:34:36,170
a and b can the thing then this have a very hard time finding a

564
00:34:36,170 --> 00:34:38,860
plane where regression is very good

565
00:34:39,690 --> 00:34:43,690
you can already see an idea here where aggression is terrible trees are good maybe

566
00:34:43,690 --> 00:34:46,290
we should combine in some way

567
00:34:47,420 --> 00:34:50,230
if there dependent on many variables

568
00:34:50,320 --> 00:34:52,130
also have trouble

569
00:34:52,150 --> 00:34:59,000
also because the greedy search strategy there's high variance you can change one data point

570
00:34:59,000 --> 00:35:04,380
in your dataset get a completely different tree i've seen that happen and so that

571
00:35:05,310 --> 00:35:09,940
can be can look like a completely different route may have very very similar performance

572
00:35:09,960 --> 00:35:11,860
but typically in your data

573
00:35:11,880 --> 00:35:14,900
real data you variables are very correlated anyway

574
00:35:14,920 --> 00:35:16,690
so the fact that split on

575
00:35:16,690 --> 00:35:18,690
agents instead of high

576
00:35:18,690 --> 00:35:21,980
i might have been just barely

577
00:35:22,000 --> 00:35:26,380
the a second best and therefore when you change one data point it changes and

578
00:35:27,340 --> 00:35:30,790
that's sort of the butterfly effect thing happens here propagate

579
00:35:30,860 --> 00:35:33,580
then the whole tree looks different now in the

580
00:35:33,650 --> 00:35:38,460
in the estimated values may not be as different as the apparent difference by looking

581
00:35:38,460 --> 00:35:40,670
so those are my names for

582
00:35:40,690 --> 00:35:43,090
heads and tails

583
00:35:45,630 --> 00:35:49,250
and so we have a and its

584
00:35:49,260 --> 00:35:56,150
the discrete distribution

585
00:35:56,230 --> 00:35:58,730
so it's a probability mass function

586
00:35:58,750 --> 00:36:01,690
as opposed to probability density function

587
00:36:03,150 --> 00:36:07,710
so the probability of x equals x

588
00:36:07,760 --> 00:36:11,210
he calls so here is the random variable x

589
00:36:11,230 --> 00:36:15,260
and here's it's possible outcomes which either zero or one

590
00:36:18,710 --> 00:36:21,630
can somebody tell me what's the formal way of

591
00:36:23,180 --> 00:36:34,440
the probability of the different outcomes for the new institution with parameter theta

592
00:36:34,490 --> 00:36:42,440
OK so as i say that if x equals one and one minus the data

593
00:36:42,460 --> 00:36:46,190
if x equals zero so you could put it the other way around but this

594
00:36:46,190 --> 00:36:47,650
is what's in my notes

595
00:36:50,280 --> 00:36:55,860
and so now already going to do the trick

596
00:36:57,010 --> 00:36:58,920
i'm going to write this as

597
00:37:00,550 --> 00:37:10,400
stated to the power x times one minus data to the power one minus x

598
00:37:11,990 --> 00:37:17,920
this is really just saying the same thing is this it's just that this says

599
00:37:17,920 --> 00:37:23,170
that in the notation it's going to be more convenient for future use

600
00:37:24,860 --> 00:37:26,760
if x equals one

601
00:37:26,760 --> 00:37:29,190
then stated to the power one is data

602
00:37:29,190 --> 00:37:31,940
and one minus stated to the power zero

603
00:37:31,960 --> 00:37:33,510
it is one

604
00:37:33,550 --> 00:37:38,320
so this is stated times one if x six x equals one and if x

605
00:37:38,320 --> 00:37:39,760
equals zero

606
00:37:39,840 --> 00:37:44,400
then here we go one times one minus state so this is the same thing

607
00:37:44,400 --> 00:37:45,480
as this

608
00:37:45,510 --> 00:37:49,010
it's just a notational

609
00:37:49,030 --> 00:37:51,150
the trick

610
00:37:52,190 --> 00:37:58,550
so now let's suppose we have a training set

611
00:38:01,280 --> 00:38:03,550
training set

612
00:38:03,550 --> 00:38:04,840
x one

613
00:38:04,880 --> 00:38:07,030
two x and

614
00:38:07,130 --> 00:38:09,260
and h

615
00:38:09,280 --> 00:38:11,730
x y

616
00:38:11,780 --> 00:38:13,710
is either zero

617
00:38:25,320 --> 00:38:33,940
i want to maximize the likelihood function so i need to write it down

618
00:38:33,960 --> 00:38:38,170
the likelihood of the data given x one to x

619
00:38:38,170 --> 00:38:40,260
it is

620
00:38:47,440 --> 00:38:50,570
what cycle function

621
00:38:50,590 --> 00:38:55,920
this is the likelihood of the log likelihood

622
00:38:57,170 --> 00:38:59,530
tell me the formula for the like

623
00:39:10,300 --> 00:39:11,960
so that's the survivors so

624
00:39:11,980 --> 00:39:18,760
the dark definition of likelihood if the examples independent is the product of the probabilities

625
00:39:18,760 --> 00:39:22,250
so product of data to the power x

626
00:39:22,320 --> 00:39:26,260
one minus stated to the power one minus x i

627
00:39:26,320 --> 00:39:29,900
and then this is

628
00:39:30,070 --> 00:39:33,210
stated to the power

629
00:39:36,630 --> 00:39:39,420
times one minus dataset

630
00:39:39,440 --> 00:39:41,380
to the power and

631
00:39:41,380 --> 00:39:44,250
times one minus data to the power

632
00:39:44,260 --> 00:39:45,780
minus h

633
00:39:45,800 --> 00:39:46,980
where h

634
00:39:46,990 --> 00:39:48,940
it is the sum of the exercise

635
00:39:48,990 --> 00:39:51,070
so what

636
00:39:51,070 --> 00:39:53,110
c four

637
00:39:54,320 --> 00:39:55,940
so there are three

638
00:39:55,960 --> 00:39:59,920
there are three things in here this stated the power oxide is one minus stated

639
00:39:59,920 --> 00:40:03,920
to the power one and this one minus stated to power minus x

640
00:40:06,300 --> 00:40:08,670
when i take

641
00:40:08,690 --> 00:40:10,780
all those products in there

642
00:40:10,800 --> 00:40:15,630
again each of those three things and times so one minus stated power one

643
00:40:15,650 --> 00:40:19,050
and times i get one minus stated to the power and

644
00:40:19,090 --> 00:40:20,440
and here

645
00:40:20,440 --> 00:40:21,800
these exercise

646
00:40:21,820 --> 00:40:25,480
some of them equal one in which case they get the status of them equal

647
00:40:25,480 --> 00:40:27,960
zero in which case i get is just

648
00:40:27,980 --> 00:40:30,030
a one in the product so

649
00:40:30,050 --> 00:40:32,670
what i end up with this data to the power of the some of the

650
00:40:33,920 --> 00:40:38,840
and similarly here is one minus the power minus the sum of the exercise

651
00:40:43,110 --> 00:40:46,800
so now

652
00:40:46,820 --> 00:40:50,480
data that is the argmax

653
00:40:53,070 --> 00:40:55,900
this thing which is stated to the power age

654
00:40:55,900 --> 00:40:58,360
and one minus data

655
00:40:58,380 --> 00:41:01,030
to the power n minus h

656
00:41:05,130 --> 00:41:08,420
we have zero

657
00:41:08,480 --> 00:41:10,750
is this thing to say to let it go one

658
00:41:11,480 --> 00:41:12,570
this is

659
00:41:12,570 --> 00:41:16,670
a little bit of an awkwardness of so the parameters theta

660
00:41:16,920 --> 00:41:20,190
it's not allowed to be any real number it has to be a real number

661
00:41:20,190 --> 00:41:26,550
between zero and one and so this maximisation problem it's not an unconstrained optimization problems

662
00:41:26,550 --> 00:41:28,530
are constrained optimization problems

663
00:41:28,550 --> 00:41:33,070
and generally speaking constrained optimization problems are hard to

664
00:41:33,090 --> 00:41:42,380
you have to introduce multipliers or other technicalities to solve this particular problem can be

665
00:41:42,380 --> 00:41:49,190
solved rather directly but still whenever you whenever you doing maximum likelihood one thing you

666
00:41:49,190 --> 00:41:53,820
need to pay attention to is whether it's an unconstrained optimisation problem constrained

667
00:41:57,030 --> 00:41:58,780
what's the

668
00:41:58,840 --> 00:42:00,490
simplest possible

669
00:42:00,530 --> 00:42:05,260
the way of solving mathematical optimisation problems

670
00:42:05,300 --> 00:42:12,880
that you typically learn as a freshman

671
00:42:13,110 --> 00:42:17,440
take the derivative and then y

672
00:42:17,460 --> 00:42:18,800
and so does it

673
00:42:19,650 --> 00:42:24,480
you strategy it doesn't always work but it's a good

674
00:42:24,490 --> 00:42:25,960
first attempt

675
00:42:26,820 --> 00:42:28,880
and since

676
00:42:28,880 --> 00:42:34,480
i'm talking about machine learning which i view as being part of computer science and

677
00:42:34,480 --> 00:42:39,670
go into as opposed to part of mathematics and going to call this algorithm

678
00:42:39,670 --> 00:42:44,210
and here we will present accuracy as a function of the number of genes

679
00:42:44,250 --> 00:42:47,160
and some people in the cadres of asked me

680
00:42:47,220 --> 00:42:51,530
do you see an optimum when you feel you vary the number of genes

681
00:42:51,540 --> 00:42:56,100
here the authors have tried in a number of strategies on how to build the

682
00:42:56,100 --> 00:43:02,200
multiclass classifier and so some of them so this is the one of the top

683
00:43:02,200 --> 00:43:07,230
is the support vector machine using all being which is one versus the other a

684
00:43:07,230 --> 00:43:11,030
multiclass classification and you various other possibilities

685
00:43:11,040 --> 00:43:14,360
and as you can see on this graph when you vary the number of genes

686
00:43:14,360 --> 00:43:17,030
sometimes you also an optimum

687
00:43:17,040 --> 00:43:18,460
and sometimes

688
00:43:18,480 --> 00:43:23,360
you actually level off or or you keep increasing the accuracy as you increase the

689
00:43:23,360 --> 00:43:28,350
number of features or genes

690
00:43:28,370 --> 00:43:31,550
so we'll have to find a way of determining

691
00:43:31,560 --> 00:43:33,900
what is the optimal number of genes

692
00:43:33,910 --> 00:43:36,410
of features

693
00:43:36,410 --> 00:43:42,410
for some practical purpose sometimes even though using all the features gives you the best

694
00:43:43,730 --> 00:43:47,610
you might want to use fewer features because only at the expense of say ten

695
00:43:47,610 --> 00:43:53,740
percent irritation of performance you can have a hundred thousand times less

696
00:43:54,910 --> 00:43:58,300
and this may mean you know more efficacy or

697
00:43:58,310 --> 00:44:02,790
easier explanation of data

698
00:44:02,930 --> 00:44:10,730
on this example we're looking now the problem of drug discovery

699
00:44:10,750 --> 00:44:12,780
in this case

700
00:44:12,790 --> 00:44:18,540
people have been screening compounds for their ability to bind to a target site which

701
00:44:18,540 --> 00:44:23,430
is trom being sick key receptor in blood clotting

702
00:44:23,460 --> 00:44:27,740
and the training set consisted of a number of compounds that were active in the

703
00:44:27,770 --> 00:44:29,830
number of inactive compounds

704
00:44:29,910 --> 00:44:34,100
and we had to predict for the test set which compounds were going to be

705
00:44:34,500 --> 00:44:36,580
binding the features

706
00:44:36,600 --> 00:44:44,450
used were some very low level three-dimensional properties of the molecule

707
00:44:45,220 --> 00:44:49,310
the president's you know the group movement which is oriented in a certain way and

708
00:44:51,580 --> 00:44:53,690
and in that case again

709
00:44:53,700 --> 00:44:56,460
you can see as we vary the number of features

710
00:44:56,500 --> 00:45:02,120
then the success rate of prediction go through an optimum

711
00:45:02,130 --> 00:45:03,900
and in fact you know of these

712
00:45:03,920 --> 00:45:07,920
hundreds of thousands of features here the axis you know he's got that one hundred

713
00:45:08,260 --> 00:45:11,260
but it goes up to one hundred thousand

714
00:45:11,310 --> 00:45:18,950
you have a fuse on the twenty or so you have the optimum already

715
00:45:18,990 --> 00:45:25,950
here's another example of feature selection in completely different domain it's index filtering

716
00:45:25,990 --> 00:45:31,060
the answers using some non-core from the rioters

717
00:45:31,080 --> 00:45:33,750
got newswire the twenty news group

718
00:45:33,850 --> 00:45:36,620
and the data set of web pages

719
00:45:36,700 --> 00:45:40,960
in a very simple representation of data which is called the bag of word perform

720
00:45:40,970 --> 00:45:42,170
these experiments

721
00:45:42,400 --> 00:45:46,530
so what that word means is that you're representing the document

722
00:45:47,200 --> 00:45:52,300
the features that are frequencies of words in the document

723
00:45:52,350 --> 00:45:57,130
so here you have about you know a hundred thousand features two hundred thousand words

724
00:45:57,130 --> 00:45:58,600
were retained

725
00:45:58,690 --> 00:46:02,690
and of course it's very sparse representation because many of the words never

726
00:46:02,730 --> 00:46:06,110
occur in some documents

727
00:46:06,230 --> 00:46:11,680
by performing feature selection the things some of the interesting results here for these are

728
00:46:11,680 --> 00:46:17,580
for the news groups so in the news group alt it is the most representative

729
00:46:17,580 --> 00:46:20,630
features autism at this in more morality

730
00:46:20,650 --> 00:46:24,550
the other three first ones know for conduct graphics

731
00:46:24,600 --> 00:46:29,430
and you can see that for space on that also makes sense you have space

732
00:46:29,430 --> 00:46:30,770
now signed orbit

733
00:46:31,800 --> 00:46:37,220
religion god church and saying politics of the middle east you have these are armenian

734
00:46:37,220 --> 00:46:41,870
turkish and and for you know this this other news group which is slightly different

735
00:46:41,870 --> 00:46:43,550
from this one has

736
00:46:44,610 --> 00:46:46,450
keywords but

737
00:46:46,490 --> 00:46:47,890
this allows you to

738
00:46:47,900 --> 00:46:55,740
o to characterize groups of texts in terms of the most prominent keywords

739
00:46:55,760 --> 00:47:00,890
here's another application of face recognition

740
00:47:00,900 --> 00:47:01,970
the authors of

741
00:47:02,130 --> 00:47:03,550
of the paper

742
00:47:03,560 --> 00:47:08,930
try to apply to different feature selection algorithms to determine in the image what other

743
00:47:08,930 --> 00:47:10,950
parts that are

744
00:47:10,970 --> 00:47:16,280
the most useful to recognise faces and here it was the discrimination simply between male

745
00:47:16,300 --> 00:47:18,800
and female

746
00:47:18,820 --> 00:47:22,440
with the relief over the if they used a hundred features they found this part

747
00:47:22,440 --> 00:47:27,980
of the next most you know important with five hundred features they started having some

748
00:47:27,980 --> 00:47:33,280
part of the i and with features you see that there is you know more

749
00:47:33,280 --> 00:47:37,340
there are more details that are being picked up by the algorithm

750
00:47:37,350 --> 00:47:40,350
for life is an algorithm that

751
00:47:40,360 --> 00:47:41,640
does not

752
00:47:41,670 --> 00:47:43,550
filter redundancy

753
00:47:43,560 --> 00:47:45,480
in the feature set

754
00:47:45,490 --> 00:47:50,210
so as you can notice that features are selected on both sides of the face

755
00:47:50,210 --> 00:47:50,980
even though

756
00:47:50,990 --> 00:47:53,810
they might be redundant because the face is symmetric

757
00:47:53,850 --> 00:47:56,770
so they propose another algorithm called simba

758
00:47:56,800 --> 00:48:02,990
which eliminates redundancy and so that algorithm picks up features only on half of the

759
00:48:02,990 --> 00:48:09,170
face and does not repeat them on the other

760
00:48:09,180 --> 00:48:13,680
so let's now dive into not to reviewed some of the examples of feature selection

761
00:48:13,680 --> 00:48:16,460
to dive into the reason themselves

762
00:48:16,500 --> 00:48:20,430
and the first so introduce some nomenclature

763
00:48:20,440 --> 00:48:23,090
so we first so that there is

764
00:48:23,100 --> 00:48:26,600
the simplest method is also called univariate methods

765
00:48:26,610 --> 00:48:31,610
and they consider one variable at a time and see where that variable is predictive

766
00:48:31,610 --> 00:48:33,710
of the target

767
00:48:33,720 --> 00:48:38,870
on the contrary multivariate methods considers subsets of variables that together

768
00:48:38,930 --> 00:48:41,930
predict well the target

769
00:48:41,950 --> 00:48:47,420
people in this field also make a distinction between filter methods and wrapper methods

770
00:48:47,430 --> 00:48:54,480
filter methods rank features or subsets of features independently of the predictor of the classifier

771
00:48:54,710 --> 00:48:56,570
have criteria

772
00:48:56,630 --> 00:48:59,270
that's work on their own

773
00:48:59,280 --> 00:49:04,370
whereas wrapper methods used the classifier of the learning machine to assess

774
00:49:04,430 --> 00:49:09,670
the features of the feature subsets

775
00:49:09,680 --> 00:49:11,070
so first

776
00:49:11,090 --> 00:49:18,400
we're going to review some very simple univariate filter methods

777
00:49:18,420 --> 00:49:22,490
so what is individual feature relevance

778
00:49:22,510 --> 00:49:23,600
so again

779
00:49:23,600 --> 00:49:26,980
you know in in an example four of

780
00:49:27,030 --> 00:49:34,230
disease diagnosis you may have features characterizing patient he's with his age number of kids

781
00:49:34,240 --> 00:49:40,190
medical history in some measurements made in blood

782
00:49:40,210 --> 00:49:42,730
and let's say that we have here one feature

783
00:49:42,780 --> 00:49:44,840
that is the age of

784
00:49:44,850 --> 00:49:49,320
and we want to discriminate between patients who are at risk of heart disease or

785
00:49:49,320 --> 00:49:51,350
patients for a healthy

786
00:49:51,360 --> 00:49:55,080
well if we if it turns out that we have the distribution of the two

787
00:49:55,080 --> 00:49:59,360
patients which are completely related

788
00:49:59,460 --> 00:50:04,430
then we going to say that that feature is useless we can't make a separation

789
00:50:04,430 --> 00:50:09,730
between the two populations of interest based on that feature so there is all reason

790
00:50:09,850 --> 00:50:11,840
to discard it

791
00:50:13,050 --> 00:50:15,740
if the joint probability

792
00:50:15,800 --> 00:50:16,780
of the

793
00:50:16,830 --> 00:50:21,050
the variable of interest and the target viable

794
00:50:21,090 --> 00:50:22,270
is equal

795
00:50:22,280 --> 00:50:27,990
to the probability of the individual variables then there is independence between the variables in

796
00:50:27,990 --> 00:50:30,150
the target

797
00:50:30,200 --> 00:50:32,120
or equivalently

798
00:50:32,120 --> 00:50:33,260
thing vanishes

799
00:50:33,280 --> 00:50:36,390
so we're left with the first part

800
00:50:36,410 --> 00:50:42,660
we can see here is the result will be independent of the orthogonal parts this

801
00:50:43,680 --> 00:50:50,830
of of overall cost of the objective function will not be affected by f perpendicular

802
00:50:50,910 --> 00:50:52,600
how what the second part

803
00:50:52,660 --> 00:50:55,410
how would this be affected by a perpendicular

804
00:50:55,430 --> 00:50:57,680
in any idea

805
00:50:57,810 --> 00:51:02,930
it would increase exactly so the first part i will not be affected by a

806
00:51:02,930 --> 00:51:06,950
particular the second part turns out since

807
00:51:06,950 --> 00:51:11,810
i think i strictly positive strictly monotonically increasing you can only increase

808
00:51:11,830 --> 00:51:17,830
if we add in particular part so therefore it is cheapest frost to just take

809
00:51:18,350 --> 00:51:21,740
f which lies in the span of the training points anything off from that we

810
00:51:21,740 --> 00:51:25,700
might want to add it can only increase this thing over here

811
00:51:25,720 --> 00:51:27,350
that's already the proof

812
00:51:27,370 --> 00:51:29,660
so therefore there for the minimum

813
00:51:29,700 --> 00:51:34,490
can be expressed in terms of the training points

814
00:51:34,490 --> 00:51:38,760
so you should ask you should also get the point here

815
00:51:38,790 --> 00:51:41,030
my point

816
00:51:41,050 --> 00:51:46,100
which was what you need

817
00:51:48,950 --> 00:51:52,310
because the show shorthand

818
00:51:53,220 --> 00:51:58,510
so someone said yes they actually should be getting two points because he saw the

819
00:51:58,510 --> 00:52:02,620
first problem is to some extent that's true that was particularly courageous

820
00:52:04,140 --> 00:52:10,200
but then his his post of already sinking which he has an advantage to begin

821
00:52:10,200 --> 00:52:12,620
with intellectual advantage so

822
00:52:12,640 --> 00:52:18,060
i think we should take away one

823
00:52:22,370 --> 00:52:24,700
so long

824
00:52:24,740 --> 00:52:29,110
this represented theorem gives me a nice way of showing you what's the support vector

825
00:52:29,110 --> 00:52:33,990
machine without spending much time when it a support vector machine is simply the special

826
00:52:35,780 --> 00:52:36,560
we are

827
00:52:37,200 --> 00:52:41,930
all labels of plus minus one so support vector classifier lim sup plus minus one

828
00:52:41,930 --> 00:52:44,770
and we use this particular cost function

829
00:52:46,070 --> 00:52:51,030
it's a cost function that only depends on the point through

830
00:52:51,050 --> 00:52:52,470
the function and

831
00:52:52,490 --> 00:52:57,610
it's this is something called the soft margin cost function and

832
00:52:57,650 --> 00:53:01,890
maybe i shouldn't spend too much time when it's not but that particular case and

833
00:53:01,890 --> 00:53:06,690
then the solution by the representer theorem can be written in this way and it's

834
00:53:06,690 --> 00:53:08,930
this of course support vector expansion

835
00:53:08,940 --> 00:53:12,720
and these points that have the ones that have non-zero far they are the support

836
00:53:13,660 --> 00:53:22,490
so that's one application you can also have other examples one bayesian maximum a posteriori

837
00:53:23,370 --> 00:53:24,490
in that case

838
00:53:24,510 --> 00:53:28,700
you can interpret these terms as likelihood of the data and prior over the set

839
00:53:28,700 --> 00:53:29,860
of functions

840
00:53:29,870 --> 00:53:33,680
you can also write kernel PCA

841
00:53:33,690 --> 00:53:38,720
as one example of an algorithm with the representer theorem applies

842
00:53:38,740 --> 00:53:43,400
it's kind of interesting because in that case you need a cost function that jointly

843
00:53:43,400 --> 00:53:44,850
depends on

844
00:53:44,860 --> 00:53:46,940
the training points

845
00:53:50,100 --> 00:53:54,360
maybe just just briefly so you've seen that pieces of the idea and kernel PCA

846
00:53:54,360 --> 00:53:56,200
is you

847
00:53:56,230 --> 00:54:00,050
like can support vector machines you maps or in any comments on your map the

848
00:54:00,050 --> 00:54:01,680
training points

849
00:54:01,690 --> 00:54:07,060
two a feature space in the feature space into something linear irony i in this

850
00:54:07,060 --> 00:54:12,720
case you look for directions of large variance and if you do that

851
00:54:15,480 --> 00:54:18,850
that i was going to show you

852
00:54:24,570 --> 00:54:29,440
just so it is also seen a support vector machine in action so this is

853
00:54:29,600 --> 00:54:34,980
a little video ones made of the solution of support vector machine as you change

854
00:54:34,980 --> 00:54:41,220
the nonlinearity so here i am starting with the relatively small nonlinearity this is almost

855
00:54:41,430 --> 00:54:42,940
a separating hyperplane

856
00:54:42,940 --> 00:54:47,300
and as i so i mean in fact this is a gaussian kernel again like

857
00:54:47,300 --> 00:54:50,910
in most examples is gaussian income that's quite broad it turns out you can prove

858
00:54:50,910 --> 00:54:55,980
that in the limit when they brought with the incoming becomes infinite it's the same

859
00:54:55,980 --> 00:55:00,690
as using a linear code and you turn on the nonlinearities we make the kernel

860
00:55:00,860 --> 00:55:05,270
this brought you see the solution becoming

861
00:55:05,270 --> 00:55:09,390
more nonlinear

862
00:55:09,400 --> 00:55:18,400
and i was asked leave before in the break something about gaussian kernels someone asked

863
00:55:18,440 --> 00:55:21,410
actually for that was the queen what was the question

864
00:55:21,440 --> 00:55:23,390
because it was you here

865
00:55:25,100 --> 00:55:32,700
right question can there is good because in kernel better than the other comes and

866
00:55:32,720 --> 00:55:37,820
cannot always separate i cannot separate all datasets and the answer is in principle yes

867
00:55:38,060 --> 00:55:43,290
goes income can separate all datasets and the reason we've seen yesterday the day before

868
00:55:43,440 --> 00:55:44,480
with today

869
00:55:44,480 --> 00:55:48,180
it was probably today

870
00:55:48,770 --> 00:55:53,820
well it seems to some extent in both cases the reason is that goes in

871
00:55:53,820 --> 00:55:59,570
kernel induces a strictly always induces is strictly positive definite matrix

872
00:55:59,570 --> 00:56:04,650
so i'm i'm making the assumption that points are pairwise distinct or in fact crucial

873
00:56:04,650 --> 00:56:09,530
assumption is there's no point of the positive set which is on top of point

874
00:56:09,600 --> 00:56:10,610
the negative set

875
00:56:10,660 --> 00:56:14,740
in that case of course you cannot separate the data sets you have conflicting labels

876
00:56:14,740 --> 00:56:19,370
but that's not the case all even say all the points of different

877
00:56:19,390 --> 00:56:24,690
then the gaussian kernel will always mapped them into a feature space where all points

878
00:56:24,690 --> 00:56:26,490
are linearly independent

879
00:56:26,520 --> 00:56:30,860
so in a way that if we have m points you mapped into an n

880
00:56:30,860 --> 00:56:36,230
dimensional subspaces and dimensional space in that space you will always be able to separate

881
00:56:36,230 --> 00:56:41,330
them but of course in support vector machines if you have a cost function that

882
00:56:41,330 --> 00:56:42,470
i showed you before

883
00:56:42,470 --> 00:56:47,030
chromosomes the paired up with each other homologous chromosomes

884
00:56:47,080 --> 00:56:48,850
and big g

885
00:56:48,860 --> 00:56:49,930
little g

886
00:56:49,940 --> 00:56:54,890
were carried on a different pair of homologous chromosomes in my meiosis pictures

887
00:56:57,580 --> 00:56:58,950
if that was the case

888
00:57:00,460 --> 00:57:02,920
when these chromosomes segregated

889
00:57:04,750 --> 00:57:10,040
the first meiosis step meiosis one it might be the big are indeed you are

890
00:57:10,040 --> 00:57:13,650
on the left side ninety big our little jewel of side it might be that

891
00:57:13,650 --> 00:57:16,780
that little are one one side centre

892
00:57:16,830 --> 00:57:21,360
because these different chromosomes they could have chosen to line up and in different ways

893
00:57:21,430 --> 00:57:27,720
that's all cool so many goals law of independent assortment is consistent

894
00:57:27,730 --> 00:57:32,150
with the chromosomal theory

895
00:57:33,800 --> 00:57:38,900
he pointed out last time except

896
00:57:39,130 --> 00:57:41,350
big are in big g

897
00:57:41,400 --> 00:57:42,360
we're on

898
00:57:42,410 --> 00:57:44,830
the same chromosome

899
00:57:44,840 --> 00:57:46,920
then we have some explaining to do

900
00:57:48,090 --> 00:57:49,930
maybe medals was just lucky

901
00:57:50,090 --> 00:57:52,990
and big are in big g

902
00:57:53,060 --> 00:57:55,060
happen to be on different chromosomes

903
00:57:55,070 --> 00:57:57,340
what takes the third trait

904
00:58:00,100 --> 00:58:03,690
maybe the reason you got once once one for those traits was it was also

905
00:58:03,690 --> 00:58:07,140
on different chromosomes fourth-straight city-state how many traits

906
00:58:07,150 --> 00:58:09,560
seven traits

907
00:58:09,570 --> 00:58:12,300
if they all gave once once once one assortment

908
00:58:12,310 --> 00:58:15,900
they all have to be on different chromosomes

909
00:58:15,940 --> 00:58:21,320
how many chromosomes the peas have how many pairs of chromosomes the PS have

910
00:58:22,860 --> 00:58:28,780
very interesting he might have just got lucky

911
00:58:28,790 --> 00:58:29,810
in fact he did

912
00:58:29,820 --> 00:58:32,530
we know that there are different chromosomes

913
00:58:32,780 --> 00:58:37,600
makes you wonder whether maybe hadn't if trade that something funny decided

914
00:58:37,650 --> 00:58:41,050
not to put it in this paper i don't know it's interesting

915
00:58:41,100 --> 00:58:45,910
i guess it's choice involved in what you want to report it at what point

916
00:58:45,910 --> 00:58:48,960
here so suppose we instead

917
00:58:49,000 --> 00:58:49,970
i had

918
00:58:49,980 --> 00:58:51,650
big are

919
00:58:51,660 --> 00:58:52,950
and being g

920
00:58:52,970 --> 00:58:58,830
are little g happen to have been on the same chromosome then they would have

921
00:58:58,830 --> 00:59:03,780
been inherited from common from the common parents here it's a from here into the

922
00:59:03,780 --> 00:59:06,440
f one f one

923
00:59:06,480 --> 00:59:07,720
would look like this

924
00:59:08,350 --> 00:59:11,520
there are different from some sort of like this from the same chromosome would look

925
00:59:11,520 --> 00:59:13,240
like this and now

926
00:59:13,250 --> 00:59:17,220
let's make a little scorecard what's gonna get passed on to the next generation

927
00:59:17,270 --> 00:59:21,670
we've got the possibility that it will pass on

928
00:59:21,710 --> 00:59:23,830
this one could pass on

929
00:59:23,990 --> 00:59:29,040
o let's let's keep score big are big she could get passed on little are

930
00:59:29,040 --> 00:59:32,760
little she passed on big are little g could be passed on and little or

931
00:59:32,760 --> 00:59:34,440
big g could be passed on

932
00:59:34,500 --> 00:59:36,310
and if they are on

933
00:59:36,320 --> 00:59:40,810
different chromosomes

934
00:59:40,830 --> 00:59:45,690
we expect water

935
00:59:46,840 --> 00:59:48,600
water water

936
00:59:48,610 --> 00:59:51,800
but if they are on the same chromosome

937
00:59:51,850 --> 00:59:56,820
what we expect

938
00:59:56,840 --> 00:59:59,650
what will come out of this

939
00:59:59,700 --> 01:00:02,670
even if you're going to get this one in which case you get both the

940
01:00:02,670 --> 01:00:05,520
garden g or you're going to get this one in which case little are little

941
01:00:05,530 --> 01:00:10,290
g have a half zero zero

942
01:00:10,310 --> 01:00:12,420
all that's very different

943
01:00:12,440 --> 01:00:18,170
what does mendoza of independent assortment say

944
01:00:18,280 --> 01:00:21,620
it favors this

945
01:00:21,710 --> 01:00:26,000
but mendoza law of independent assortment can't possibly be right

946
01:00:26,100 --> 01:00:28,250
if we see this

947
01:00:28,260 --> 01:00:32,630
so many people didn't observe this

948
01:00:32,700 --> 01:00:37,460
but if we really believe this chromosomal theory we'd expect to see it eventually

949
01:00:37,470 --> 01:00:38,970
so who is going to be right

950
01:00:38,980 --> 01:00:43,620
mendel or chromosomal here

951
01:00:43,640 --> 01:00:45,190
if you vote for both

952
01:00:45,350 --> 01:00:47,770
i and even for mental

953
01:00:47,890 --> 01:00:49,950
i mean the chromosomal theory

954
01:00:50,130 --> 01:00:52,330
how for

955
01:00:52,350 --> 01:00:55,390
how you have both the data to be contradictory how to have a vote for

956
01:00:58,000 --> 01:01:00,210
OK fine

957
01:01:00,220 --> 01:01:08,040
so we have very different predictions

958
01:01:08,060 --> 01:01:09,790
notice that these

959
01:01:09,810 --> 01:01:15,310
i the parental types of chromosomes

960
01:01:15,330 --> 01:01:20,570
they the ones that went into the cross in the first place big are big

961
01:01:20,570 --> 01:01:23,880
g these are the non parental types

962
01:01:23,890 --> 01:01:25,970
of chromosomes

963
01:01:25,990 --> 01:01:30,990
they're the ones there combinations of bigger and bigger didn't match either of the two

964
01:01:30,990 --> 01:01:34,130
parents would have that new combination

965
01:01:35,320 --> 01:01:38,940
it took a while before folks sorted this out

966
01:01:38,950 --> 01:01:41,230
and it was eventually sorted out

967
01:01:41,280 --> 01:01:42,810
in fruit flies

968
01:01:43,890 --> 01:01:47,720
it is of course

969
01:01:48,790 --> 01:01:54,910
the case

970
01:01:57,320 --> 01:01:59,190
neither mendel

971
01:01:59,200 --> 01:02:03,830
nor district prediction from the chromosomal theory turns out to be correct

972
01:02:03,950 --> 01:02:06,940
members law of independent assortment does not hold

973
01:02:06,940 --> 01:02:09,240
and if none of them raise their hands

974
01:02:10,830 --> 01:02:13,610
you can minimize more

975
01:02:13,620 --> 01:02:17,140
have any information

976
01:02:17,150 --> 01:02:20,430
OK so that's one against all

977
01:02:20,440 --> 01:02:22,240
and then

978
01:02:22,290 --> 01:02:25,430
if you go and you analyse the mathematics of this

979
01:02:25,470 --> 01:02:28,520
what you discover is that this failure mode

980
01:02:29,560 --> 01:02:32,610
significantly less severe than this value

981
01:02:32,660 --> 01:02:35,090
because you still have an even chance of picking the right guy in this kind

982
01:02:36,640 --> 01:02:40,440
but that they can cannot go on this happens there

983
01:02:40,520 --> 01:02:43,470
much worse one k

984
01:02:43,520 --> 01:02:47,780
so you can take advantage of that you can create instead of reducing two

985
01:02:47,870 --> 01:02:51,330
binary classification you can reduce to

986
01:02:51,380 --> 01:02:53,120
importance weighted classification

987
01:02:53,130 --> 01:02:54,710
so the importance

988
01:02:54,720 --> 01:02:59,700
the reason your hand is supposed to is larger than otherwise

989
01:02:59,750 --> 01:03:01,870
and you set about classification

990
01:03:01,920 --> 01:03:04,240
we compare these two methods

991
01:03:04,290 --> 01:03:05,700
it turns out that

992
01:03:05,740 --> 01:03:08,870
this week one against all

993
01:03:09,800 --> 01:03:12,060
always better

994
01:03:12,100 --> 01:03:14,900
this is the accuracy so things above the line

995
01:03:14,960 --> 01:03:17,330
irwin's for weighted one is

996
01:03:17,340 --> 01:03:19,260
is bunch of different

997
01:03:19,320 --> 01:03:21,980
learning algorithms and i wanted different datasets in

998
01:03:22,000 --> 01:03:24,370
i guess one town slightly worse

999
01:03:24,470 --> 01:03:26,510
but every time

1000
01:03:26,600 --> 01:03:32,520
the better is attempting to deliver

1001
01:03:32,570 --> 01:03:38,730
to the some other race in terms of working

1002
01:03:38,820 --> 01:03:42,980
another motivation is sort code wise

1003
01:03:42,990 --> 01:03:46,360
reduction to sort of inhaling larger

1004
01:03:47,080 --> 01:03:50,510
what we do not keep the insight into the workings of learning our them so

1005
01:03:50,510 --> 01:03:53,200
we do not need it yes

1006
01:03:59,650 --> 01:04:05,950
only one is reduction the reduction is from multiclass classification to binary classification

1007
01:04:05,960 --> 01:04:07,640
so in a sense

1008
01:04:07,700 --> 01:04:11,630
so we were editing from multiclass to binary

1009
01:04:11,650 --> 01:04:14,490
you can do it directly with this one against all

1010
01:04:14,530 --> 01:04:17,410
or you can go from multiclass two

1011
01:04:18,360 --> 01:04:22,160
importance weighted binary then to binary

1012
01:04:22,170 --> 01:05:03,530
so i was comparing

1013
01:05:16,240 --> 01:05:17,430
the the

1014
01:05:19,320 --> 01:05:24,510
the important of binary is an intriguing for its environment that

1015
01:05:24,570 --> 01:05:27,940
other taxes and talking about a black box productions

1016
01:05:27,950 --> 01:05:30,700
he even apply them to any classification our them

1017
01:05:30,790 --> 01:05:32,510
and you can apply them

1018
01:05:32,710 --> 01:05:38,070
just were given some standard interface to all classification there are no special prior things

1019
01:05:38,070 --> 01:05:40,330
or anything like that

1020
01:05:40,940 --> 01:05:44,200
i was comparing this direct approach

1021
01:05:44,270 --> 01:05:46,770
we're doing one

1022
01:05:46,850 --> 01:05:49,140
verses are

1023
01:05:55,250 --> 01:05:57,900
verses of

1024
01:05:57,950 --> 01:05:59,260
compose with

1025
01:05:59,300 --> 01:06:02,330
so we'll talk about later which is this

1026
01:06:27,800 --> 01:06:31,410
so one thing which is important is the

1027
01:06:31,490 --> 01:06:34,290
reductions in not competing with themselves right

1028
01:06:34,300 --> 01:06:36,620
these are two different productions

1029
01:06:36,630 --> 01:06:40,930
the one versus on the way to one versus all those discussing

1030
01:06:41,410 --> 01:06:43,920
but what you really want to compare with

1031
01:06:43,950 --> 01:06:49,090
is the weighted multiclass classification right because you want is the best way

1032
01:06:49,150 --> 01:06:50,930
the comparison is not done right here

1033
01:06:51,000 --> 01:07:02,370
it's time for some of the other things are present later

1034
01:07:03,000 --> 01:07:05,570
so modularity

1035
01:07:09,610 --> 01:07:11,040
no parameter tweaking

1036
01:07:11,850 --> 01:07:15,750
we're just thinking about the classification of the sum of the particular type

1037
01:07:15,800 --> 01:07:19,500
or just using it as you would use things that type would actually

1038
01:07:19,510 --> 01:07:24,250
dealing with any primaries the classification error

1039
01:07:24,310 --> 01:07:27,430
you can reuse your old learning algorithms

1040
01:07:27,450 --> 01:07:28,910
the these reductions

1041
01:07:28,920 --> 01:07:29,890
right so

1042
01:07:29,980 --> 01:07:32,060
that from

1043
01:07:32,080 --> 01:07:34,530
now having to think so much viewpoint

1044
01:07:34,570 --> 01:07:36,800
in particular

1045
01:07:36,850 --> 01:07:39,100
i think there may be

1046
01:07:39,150 --> 01:07:43,230
it is fifty classification algorithms have been invented

1047
01:07:43,250 --> 01:07:46,270
it is pretty impressive because

1048
01:07:46,290 --> 01:07:48,890
mrna fifty cover datasets

1049
01:07:51,550 --> 01:07:52,480
if you can

1050
01:07:52,490 --> 01:07:55,140
former reduction to classification

1051
01:07:56,660 --> 01:07:59,620
you fifty are supplied whatever

1052
01:07:59,630 --> 01:08:01,440
one problem you have

1053
01:08:01,490 --> 01:08:06,630
it takes awhile fifty hours

1054
01:08:06,640 --> 01:08:08,180
and then

1055
01:08:08,200 --> 01:08:12,510
you can actually in addition to using the learning outcomes because entirely black box you

1056
01:08:12,510 --> 01:08:40,010
distinguished guests participants of the

1057
01:08:40,020 --> 01:08:42,120
bled forum on europe

1058
01:08:42,200 --> 01:08:45,150
this year with the debate

1059
01:08:45,150 --> 01:08:49,080
about culture and its relation to knowledge society

1060
01:08:49,110 --> 01:08:54,140
it is my honor and the real pleasure to introduce slavoj zizek

1061
01:08:54,150 --> 01:08:56,250
who will give us a view

1062
01:08:56,260 --> 01:09:00,970
radical thinking about the future of europe

1063
01:09:00,980 --> 01:09:02,670
mister slower

1064
01:09:17,760 --> 01:09:19,450
i think the

1065
01:09:20,390 --> 01:09:24,420
i think the negation we are

1066
01:09:24,480 --> 01:09:27,890
what's know i going on to engage in peace

1067
01:09:27,920 --> 01:09:31,450
in which we can take

1068
01:09:33,360 --> 01:09:35,860
the man who is a chance

1069
01:09:49,810 --> 01:09:53,040
those of you

1070
01:10:25,660 --> 01:10:36,290
the years is

1071
01:10:41,850 --> 01:10:46,040
this is

1072
01:11:04,160 --> 01:11:06,550
this is nice

1073
01:11:11,660 --> 01:11:16,080
in eight

1074
01:11:23,580 --> 01:11:34,200
so i mean that

1075
01:11:34,200 --> 01:11:37,170
we can

1076
01:11:55,790 --> 01:11:58,460
there are

1077
01:13:01,500 --> 01:13:05,540
so use

1078
01:13:12,090 --> 01:13:16,810
it it

1079
01:13:25,530 --> 01:13:28,280
you know

1080
01:13:31,190 --> 01:13:39,180
he is a

1081
01:14:03,130 --> 01:14:05,780
instead of

1082
01:14:23,930 --> 01:14:26,930
and you use

1083
01:14:27,840 --> 01:14:35,250
in the US

1084
01:14:55,060 --> 01:14:56,940
there is

1085
01:14:56,980 --> 01:15:02,290
he is

1086
01:15:33,570 --> 01:15:37,520
eight of

1087
01:15:45,340 --> 01:15:53,360
we should

1088
01:16:11,730 --> 01:16:13,220
the problem is

1089
01:16:32,750 --> 01:16:34,770
is are

1090
01:16:42,940 --> 01:16:49,080
this list

1091
01:16:52,440 --> 01:16:55,070
so rich

1092
01:17:00,190 --> 01:17:03,380
this is

1093
01:17:17,050 --> 01:17:19,960
more and more

1094
01:17:25,380 --> 01:17:28,020
so this

1095
01:17:30,400 --> 01:17:32,960
well the

1096
01:17:38,790 --> 01:17:43,800
of course all these

1097
01:17:52,900 --> 01:17:57,600
what we

1098
01:17:57,870 --> 01:18:00,720
one of the

1099
01:18:11,320 --> 01:18:14,430
this it's

1100
01:18:48,780 --> 01:18:53,880
he is

1101
01:19:09,450 --> 01:19:10,930
you of many

1102
01:19:10,950 --> 01:19:12,570
there you know

1103
01:19:30,550 --> 01:19:37,290
this is

1104
01:19:40,930 --> 01:19:44,160
a few

1105
01:19:44,170 --> 01:19:47,460
are you

1106
01:19:57,640 --> 01:20:05,400
that is

1107
01:20:20,270 --> 01:20:22,970
this is all

1108
01:20:42,500 --> 01:20:45,670
he not

1109
01:20:45,670 --> 01:20:49,760
here also

1110
01:20:54,620 --> 01:21:00,220
all this was this

1111
01:21:05,400 --> 01:21:08,290
the main

1112
01:21:08,300 --> 01:21:09,580
both of these

1113
01:21:25,220 --> 01:21:28,790
o o

1114
01:21:37,170 --> 01:21:43,310
one is

1115
01:22:08,650 --> 01:22:11,750
well he is

1116
01:22:25,950 --> 01:22:29,440
it means

1117
01:22:33,170 --> 01:22:39,550
it it's

1118
01:22:44,100 --> 01:22:49,200
i think

1119
01:22:49,280 --> 01:22:54,970
the crucial for the production of that it's no longer just so it can see

1120
01:22:54,990 --> 01:22:58,450
reasons for the changes

1121
01:22:58,530 --> 01:23:03,340
the place precise about the facts

1122
01:23:03,350 --> 01:23:06,650
so let's first

1123
01:23:06,690 --> 01:23:10,710
the first split you see one

1124
01:23:14,920 --> 01:23:21,520
for you use black star i can't message do not

1125
01:23:21,760 --> 01:23:24,370
four of the country

1126
01:23:24,380 --> 01:23:26,950
so tried to live until

1127
01:23:27,740 --> 01:23:31,100
all of you not about what the image

1128
01:23:31,120 --> 01:23:32,920
the first is

1129
01:23:32,930 --> 01:23:34,920
look over

1130
01:23:34,930 --> 01:23:35,920
for the right

1131
01:23:37,030 --> 01:23:41,490
you can forget about the problem of good

1132
01:23:43,030 --> 01:23:45,700
so the problem

1133
01:23:47,330 --> 01:23:53,810
i think it's going to be very to the point of view

1134
01:23:53,810 --> 01:24:01,870
stochastic if they can be a number of possible states given by some distribution

1135
01:24:04,380 --> 01:24:07,950
episodic versus sequential episodic means

1136
01:24:10,780 --> 01:24:15,560
it's literally just one episode and finished the whole thing repeated again for example you

1137
01:24:15,560 --> 01:24:16,350
could have

1138
01:24:16,400 --> 01:24:18,310
a camera that's on the production line

1139
01:24:18,320 --> 01:24:22,370
looking at it affects the coming past might have defects

1140
01:24:22,380 --> 01:24:23,640
on the other side is

1141
01:24:23,650 --> 01:24:26,930
the artifact arrives in front of the camera the camera looks at it

1142
01:24:26,930 --> 01:24:31,040
besides with this effect not makes simple decision yes or no

1143
01:24:31,130 --> 01:24:34,580
the numbers on this forgotten you start all over again

1144
01:24:34,630 --> 01:24:37,440
so in a sense it's pretty simple situation

1145
01:24:37,440 --> 01:24:39,300
one action time

1146
01:24:39,320 --> 01:24:42,470
and in this one is not connected one before

1147
01:24:42,920 --> 01:24:45,750
a more typical situation sequential way

1148
01:24:45,770 --> 01:24:48,920
you're trying to achieve something it takes the number of actions to achieve and then

1149
01:24:48,920 --> 01:24:49,520
you anybody

1150
01:24:49,540 --> 01:24:55,770
continue on to something else

1151
01:24:55,970 --> 01:24:58,310
static versus dynamic

1152
01:24:58,320 --> 01:25:00,600
for static environment

1153
01:25:00,650 --> 01:25:03,490
while you're what to do next

1154
01:25:04,650 --> 01:25:07,270
doesn't change

1155
01:25:07,270 --> 01:25:08,650
and dynamic

1156
01:25:08,670 --> 01:25:12,060
if while deliberating

1157
01:25:12,080 --> 01:25:14,570
the environment can change

1158
01:25:14,620 --> 01:25:16,630
so in

1159
01:25:16,680 --> 01:25:18,070
in chess

1160
01:25:18,220 --> 01:25:20,280
it's essentially static except for

1161
01:25:20,330 --> 01:25:21,350
one case

1162
01:25:21,530 --> 01:25:24,020
is when

1163
01:25:24,030 --> 01:25:26,570
you play the clock

1164
01:25:26,890 --> 01:25:28,640
could not dead

1165
01:25:28,690 --> 01:25:33,170
but otherwise i suppose also rules that have been first forty moves something in

1166
01:25:33,270 --> 01:25:36,970
can roughly speaking it is static

1167
01:25:36,980 --> 01:25:38,300
but typically

1168
01:25:39,740 --> 01:25:43,170
environment the dynamics of things are happening all the time when you rating and that

1169
01:25:43,170 --> 01:25:46,140
may be very important set playing football

1170
01:25:46,210 --> 01:25:49,500
try to get the ball trying to sell what to do well

1171
01:25:49,510 --> 01:25:50,850
can't wait for long

1172
01:25:51,120 --> 01:25:56,600
discrete versus continuous

1173
01:25:59,100 --> 01:26:00,090
this is

1174
01:26:00,100 --> 01:26:02,840
reference to with this discrete

1175
01:26:03,900 --> 01:26:07,810
or there's some sort of continuity sites and some sort of measurement with the real

1176
01:26:14,590 --> 01:26:15,790
if you've

1177
01:26:15,800 --> 01:26:17,280
well chess stresses

1178
01:26:17,720 --> 01:26:20,900
is discrete event street

1179
01:26:21,040 --> 01:26:24,800
this could be board sixty four squares

1180
01:26:24,850 --> 01:26:26,790
and the pieces and so on

1181
01:26:26,930 --> 01:26:29,750
continuous case with the

1182
01:26:30,290 --> 01:26:31,420
and i this

1183
01:26:31,460 --> 01:26:35,520
it's driving a taxi

1184
01:26:35,560 --> 01:26:39,780
OK so you you know we've got autonomous vehicles vehicles that can drive around the

1185
01:26:39,820 --> 01:26:41,850
how is afraid doesn't get back to that

1186
01:26:41,860 --> 01:26:43,570
the finishing line

1187
01:26:43,670 --> 01:26:48,340
and maybe now they can drive through the environment is that the grand challenge

1188
01:26:48,350 --> 01:26:49,630
but imagine

1189
01:26:49,730 --> 01:26:51,360
taxi driver that

1190
01:26:51,370 --> 01:26:54,370
not only can do all that they can they can talk to the passengers negotiate

1191
01:26:54,370 --> 01:26:56,260
phase in all sorts of other things

1192
01:26:56,980 --> 01:27:01,570
well there's lots of lots of continuous things there it's been continuous and

1193
01:27:01,590 --> 01:27:05,850
breaking precious continuous and lots of things are continuous

1194
01:27:05,860 --> 01:27:09,590
single agent versus multi agent

1195
01:27:10,240 --> 01:27:15,150
in some sense situation is just a single agent environment that's it

1196
01:27:15,170 --> 01:27:19,420
but typically we're multiagent situation and the two basic kinds of things that can be

1197
01:27:20,370 --> 01:27:23,340
one of them is the other agents can be your friends

1198
01:27:23,390 --> 01:27:26,030
and you're trying to achieve something

1199
01:27:26,060 --> 01:27:29,630
so notice that in the space missions that

1200
01:27:29,680 --> 01:27:31,230
the the talking about

1201
01:27:31,240 --> 01:27:32,750
instead of building one

1202
01:27:34,430 --> 01:27:36,730
the robot robots going to go off and do something

1203
01:27:36,880 --> 01:27:39,230
lots of small and just let the

1204
01:27:39,280 --> 01:27:42,230
and if you lose someone idealism that's fine but they

1205
01:27:42,280 --> 01:27:46,450
communicating that together in order to achieve some task

1206
01:27:46,450 --> 01:27:48,530
and also military applications like that

1207
01:27:48,580 --> 01:27:50,430
where there are swarms of

1208
01:27:50,470 --> 01:27:53,950
you have these all other other artifacts

1209
01:27:54,000 --> 01:27:56,280
performing some mission

1210
01:27:56,450 --> 01:28:01,280
the other kind of thing that can happen is that the other agency registries

1211
01:28:01,280 --> 01:28:04,460
so for example during the war and you got the rights on the other side

1212
01:28:04,460 --> 01:28:05,650
or your

1213
01:28:05,670 --> 01:28:08,020
in some kind of action trying to

1214
01:28:08,070 --> 01:28:09,570
you could be doing something

1215
01:28:09,620 --> 01:28:12,030
now the other agents are trying to get more cheaply

1216
01:28:12,100 --> 01:28:14,510
good instead of you

1217
01:28:14,540 --> 01:28:21,040
so typically one is in multi agent situation

1218
01:28:21,090 --> 01:28:23,040
so i guess i jumped ahead of them

1219
01:28:23,380 --> 01:28:33,040
right so the sum of because the first part

1220
01:28:33,050 --> 01:28:38,000
so this in words at the bottom there that come up in the islands community

1221
01:28:38,530 --> 01:28:43,570
so you can

1222
01:28:43,670 --> 01:28:47,150
talk about whether right so i was cooperating with one another

1223
01:28:47,150 --> 01:28:51,600
i will get exponentially more confident

1224
01:28:52,360 --> 01:28:54,240
this is great

1225
01:28:54,310 --> 01:28:55,600
he would think well

1226
01:28:55,610 --> 01:28:58,780
problem is solved and we can just write this corollary

1227
01:28:59,980 --> 01:29:02,130
we've done

1228
01:29:02,140 --> 01:29:06,230
and that's pretty much what we thought at the beginning and we implemented it

1229
01:29:06,240 --> 01:29:09,460
and it didn't work

1230
01:29:10,550 --> 01:29:15,370
or shall we say it only works for a lot of data

1231
01:29:15,410 --> 01:29:17,920
and i mean this is what people typically two

1232
01:29:17,930 --> 01:29:20,290
uniform convergence reasoning

1233
01:29:20,480 --> 01:29:22,360
so if you read any

1234
01:29:22,390 --> 01:29:27,750
recent paper and uniform convergence theory and distribution free bounds and all that

1235
01:29:27,760 --> 01:29:30,610
that's basically what will happen

1236
01:29:30,660 --> 01:29:33,870
and this in a lot of alarm bells ringing because i mean have also been

1237
01:29:33,870 --> 01:29:37,620
doing that for the past eight to nine years

1238
01:29:37,630 --> 01:29:40,220
and i guess i was for the first time where we actually sat down and

1239
01:29:40,220 --> 01:29:46,430
tried it out and realize how how awful it was

1240
01:29:46,440 --> 01:29:48,280
not say

1241
01:29:49,480 --> 01:29:51,550
examples of that

1242
01:29:51,650 --> 01:29:55,470
but i cannot first focus on the good things

1243
01:29:55,580 --> 01:29:57,310
the good thing is well

1244
01:29:57,320 --> 01:30:00,710
if you solve this for epsilon so if you fix some probability

1245
01:30:00,740 --> 01:30:05,370
level delta news sources for epsilon it just means that

1246
01:30:05,420 --> 01:30:09,700
so i will behave like one of was square in

1247
01:30:09,750 --> 01:30:13,320
so we can show that our estimator is consistent so this is usually the holy

1248
01:30:13,320 --> 01:30:15,190
grail and so

1249
01:30:15,270 --> 01:30:15,930
you know

1250
01:30:15,940 --> 01:30:19,730
should be just fine and we should be able to finish here

1251
01:30:19,740 --> 01:30:22,690
we can also use this as a taste

1252
01:30:22,830 --> 01:30:25,430
and we just say well

1253
01:30:26,820 --> 01:30:30,050
we observe a certain deviation epsilon

1254
01:30:30,090 --> 01:30:33,170
what does that mean in terms of the confidence level so we just like that

1255
01:30:33,170 --> 01:30:35,660
if someone in here

1256
01:30:35,680 --> 01:30:38,720
and compute this quantity

1257
01:30:38,770 --> 01:30:40,740
if this quantity is

1258
01:30:40,760 --> 01:30:42,190
very very small

1259
01:30:42,200 --> 01:30:43,040
we know

1260
01:30:43,170 --> 01:30:44,320
that well

1261
01:30:44,360 --> 01:30:46,560
it's very likely

1262
01:30:46,580 --> 01:30:48,860
that people's q

1263
01:30:48,970 --> 01:30:50,410
it's very large

1264
01:30:50,420 --> 01:30:54,150
it's quite likely that is not able to keep

1265
01:31:02,040 --> 01:31:04,240
really nice things affecting about

1266
01:31:04,250 --> 01:31:08,970
fifteen years before he proved that found improved another result

1267
01:31:09,020 --> 01:31:10,550
say proved

1268
01:31:10,560 --> 01:31:14,450
that for also those who statistics

1269
01:31:14,600 --> 01:31:18,820
this quantity here that we compute is asymptotically normal

1270
01:31:18,840 --> 01:31:22,430
and the variance can very easily computed

1271
01:31:22,480 --> 01:31:23,370
as you can

1272
01:31:23,380 --> 01:31:24,430
to an improved

1273
01:31:24,500 --> 01:31:26,730
computational that

1274
01:31:26,740 --> 01:31:30,870
so what's really happening here is here taking the expectation of the second term

1275
01:31:30,920 --> 01:31:36,490
here taking it both so this is like the standard way i'll compute the variance

1276
01:31:36,500 --> 01:31:38,810
just here we have two random variables but

1277
01:31:39,930 --> 01:31:42,150
not so much different

1278
01:31:42,170 --> 01:31:46,180
you can really do that easily with the fall of

1279
01:31:46,190 --> 01:31:50,770
so what you can do is to estimate the variance from the top and it

1280
01:31:50,770 --> 01:31:56,260
turns out that the convergence for the estimate of the variance itself is very fast

1281
01:31:56,620 --> 01:31:57,700
and then

1282
01:31:59,140 --> 01:32:00,910
since we know

1283
01:32:01,970 --> 01:32:03,500
the distribution

1284
01:32:03,550 --> 01:32:06,230
often means

1285
01:32:06,250 --> 01:32:09,390
is going to behave like this

1286
01:32:09,440 --> 01:32:12,780
four people's q

1287
01:32:12,790 --> 01:32:16,890
normal distribution we know that variance

1288
01:32:16,950 --> 01:32:20,240
now all we need to do is we just need to integrate over the mass

1289
01:32:20,250 --> 01:32:23,080
but since that's the normal distribution we can just look it up

1290
01:32:23,180 --> 01:32:26,890
we don't even have to do any work select tricks always to avoid doing the

1291
01:32:32,170 --> 01:32:32,840
and then

1292
01:32:32,850 --> 01:32:36,490
this is exactly the kind of distribution here

1293
01:32:36,540 --> 01:32:42,740
this orbital delta and that gives us the taste

1294
01:32:45,300 --> 01:32:46,790
so basically

1295
01:32:46,840 --> 01:32:49,900
that will give us the little outputs of every delta we can solve for now

1296
01:32:49,900 --> 01:32:50,920
for you

1297
01:32:50,960 --> 01:32:53,160
and this will be artists

1298
01:32:56,540 --> 01:32:58,310
and that works amazingly well

1299
01:32:58,320 --> 01:33:05,250
and even more amazing thing is already works amazingly well if five six observations

1300
01:33:05,300 --> 01:33:06,390
we compare

1301
01:33:06,440 --> 01:33:10,040
two the asymptotic to the uniform convergence reasoning

1302
01:33:10,200 --> 01:33:13,680
and it turned out that we need about one hundred times as many observations for

1303
01:33:13,700 --> 01:33:18,740
the uniform convergence reasoning as we needed for the asymptotic tests

1304
01:33:18,770 --> 01:33:21,680
that story

1305
01:33:22,360 --> 01:33:25,410
this was all of the theory are going to here for the rest of this

1306
01:33:26,570 --> 01:33:28,670
and i can lean back and enjoy

1307
01:33:28,820 --> 01:33:32,330
all the applications

1308
01:33:32,350 --> 01:33:37,150
let's start with something very simple dot integration

1309
01:33:37,160 --> 01:33:38,930
so that's like

1310
01:33:38,980 --> 01:33:41,810
get the data from various sources and we want to know whether we can combine

1311
01:33:42,590 --> 01:33:46,030
we compare and compare compare a couple of methods

1312
01:33:46,030 --> 01:33:47,670
the only the

1313
01:33:47,700 --> 01:33:50,350
yes some in two unfortunately

1314
01:33:51,610 --> 01:33:55,830
because the reason for that is because you know learning within

1315
01:33:55,850 --> 01:33:59,980
how well that's going to be hard because even have to solve these other problems

1316
01:33:59,980 --> 01:34:04,300
as well as vision problems speech understanding problems and motor control as well as the

1317
01:34:05,480 --> 01:34:10,540
understanding part which are actually interested in so we're just gonna look kind of

1318
01:34:10,580 --> 01:34:16,620
the simplest thing we can hear a text adventure game type situation

1319
01:34:19,720 --> 01:34:25,680
taken the atomic actions in the game might get move give shoot and the physical

1320
01:34:26,820 --> 01:34:30,660
in the game like character one key one key two

1321
01:34:30,680 --> 01:34:33,360
now here's a different instances of the key

1322
01:34:33,360 --> 01:34:39,370
p one and key two they have different labels and we we can then just

1323
01:34:39,370 --> 01:34:42,410
treat these symbols as the

1324
01:34:43,160 --> 01:34:47,020
so why are we going to represent the world and this you can see as

1325
01:34:47,020 --> 01:34:53,170
a pre processed versions of the visual signal learner situated in this world might have

1326
01:34:53,230 --> 01:34:56,320
sirin is going to be easier for us

1327
01:34:56,330 --> 01:35:00,350
so with that in mind we can then

1328
01:35:00,370 --> 01:35:05,200
define what we call the concept labeling task so the task is to map any

1329
01:35:05,200 --> 01:35:10,790
natural language sentence x to its labeling in terms of concepts y that's going to

1330
01:35:10,790 --> 01:35:13,810
be like this concept straight on the previous slide

1331
01:35:13,820 --> 01:35:19,200
so and to train it we can be given training triples

1332
01:35:19,740 --> 01:35:25,640
x while URI to excise the sentence y is the concepts in this URI call

1333
01:35:25,640 --> 01:35:30,440
it the universe it's the current state of the world that you know and it's

1334
01:35:30,440 --> 01:35:31,980
going to be the set of

1335
01:35:32,000 --> 01:35:38,000
of concepts that you know about and their relations and their relations are just a

1336
01:35:38,080 --> 01:35:40,980
pairwise relations on concepts so

1337
01:35:40,990 --> 01:35:42,280
this picture

1338
01:35:42,280 --> 01:35:48,810
maybe explains it more clearly here's a typical training triple OK so you put the

1339
01:35:48,820 --> 01:35:50,850
sentence he cooks the rice

1340
01:35:50,860 --> 01:35:52,230
this is the

1341
01:35:52,250 --> 01:35:55,040
output y that we actually

1342
01:35:55,050 --> 01:35:57,490
want to learn how to map

1343
01:35:58,070 --> 01:36:02,400
the that's the concept labeling so this so here

1344
01:36:02,430 --> 01:36:09,380
the symbol rights in the angle brackets is actually the the symbol for the

1345
01:36:09,380 --> 01:36:11,600
the concept the physical

1346
01:36:11,650 --> 01:36:16,220
o thing right in the world right so you have to actually learned this word

1347
01:36:16,920 --> 01:36:22,470
maps to to that concept you don't there's these labels by the way

1348
01:36:22,480 --> 01:36:25,610
they're just for you to understand i mean that could be

1349
01:36:25,610 --> 01:36:28,930
it's not like the computer knows what's the word right

1350
01:36:28,960 --> 01:36:30,690
and then

1351
01:36:30,710 --> 01:36:32,120
the universe here

1352
01:36:32,140 --> 01:36:36,040
is the set of all concepts so things like mark golden hat and so on

1353
01:36:36,040 --> 01:36:38,810
plus the relations between so here

1354
01:36:38,820 --> 01:36:40,950
we just got two kinds of relations

1355
01:36:41,130 --> 01:36:51,500
location and contained by and for example john has location kitchen and wels content rice

1356
01:36:51,530 --> 01:36:55,550
is contained by gene so that means gene carrying rice

1357
01:36:55,560 --> 01:37:01,150
so we can represent a world like that and the idea

1358
01:37:01,170 --> 01:37:01,990
it is

1359
01:37:02,000 --> 01:37:05,840
yes i mean that consider the

1360
01:37:05,840 --> 01:37:09,340
war over the course of the brain

1361
01:37:11,490 --> 01:37:12,720
i'm going to say

1362
01:37:12,730 --> 01:37:17,780
yes indeed i'm going to take a data set that looks like this

1363
01:37:18,100 --> 01:37:20,910
and it's kind of small wireless to try to do something

1364
01:37:20,930 --> 01:37:28,060
so indeed my data is going to look like this kind of sentences

1365
01:37:28,060 --> 01:37:32,880
and there's going to be ambiguity here so he can see she goes from the

1366
01:37:32,880 --> 01:37:36,840
bedroom to the kitchen that she should be labelled with the concert mother

1367
01:37:36,850 --> 01:37:39,140
so you don't have to disambiguate she

1368
01:37:39,190 --> 01:37:42,070
and if we go back to our example

1369
01:37:42,080 --> 01:37:44,220
when you're doing that disambiguation

1370
01:37:44,250 --> 01:37:49,020
you can use the universe to do that is because if didn't have the world

1371
01:37:49,030 --> 01:37:51,090
knowledge here the she

1372
01:37:51,380 --> 01:37:56,220
it's going to be impossible to disambiguate if you happen to have

1373
01:37:56,250 --> 01:38:01,820
when you're decoding this if you know that the word rights correspond to the concept

1374
01:38:01,830 --> 01:38:03,330
rice which is

1375
01:38:03,340 --> 01:38:08,390
let's go back to the all the concert rice which is located in the kitchen

1376
01:38:08,840 --> 01:38:13,470
and you know that he here is then cooking

1377
01:38:13,500 --> 01:38:17,900
the rise which is in the kitchen you might be able to disambiguate the heated

1378
01:38:17,900 --> 01:38:23,110
john because jones location is also the kitchen so you can see that you could

1379
01:38:23,110 --> 01:38:26,420
try and use this world knowledge to disambiguate

1380
01:38:26,420 --> 01:38:28,840
the isomorphism

1381
01:38:28,850 --> 01:38:33,600
going from this vector space to the direct sum of vector spaces

1382
01:38:33,910 --> 01:38:37,660
is usually called the fourier transform but the representation of it

1383
01:38:43,030 --> 01:38:46,890
the isomorphism of algebras here

1384
01:38:46,920 --> 01:38:49,220
that takes this

1385
01:38:49,420 --> 01:38:54,220
the product of

1386
01:38:54,230 --> 01:38:59,850
the space is this parties in cartesian product into the direct sum of full cartesian

1387
01:38:59,850 --> 01:39:01,720
products of smaller dimension

1388
01:39:01,780 --> 01:39:04,950
OK and equivalently it could take

1389
01:39:05,170 --> 01:39:06,860
filter matrix

1390
01:39:06,940 --> 01:39:13,680
and split it into a direct sum of meat dishes that means write it

1391
01:39:13,700 --> 01:39:19,680
that makes it corresponds to a block diagonal matrix in the four

1392
01:39:19,700 --> 01:39:23,270
domain to make

1393
01:39:23,280 --> 01:39:25,420
yes there are irreducible

1394
01:39:25,430 --> 01:39:27,710
can assume that there is

1395
01:39:28,620 --> 01:39:30,990
and the spectrum of the signal

1396
01:39:31,180 --> 01:39:34,550
will be just

1397
01:39:34,560 --> 01:39:38,710
a function that takes all these in this in this is

1398
01:39:38,720 --> 01:39:42,360
and essentially it will perform

1399
01:39:42,370 --> 01:39:44,860
what we've seen in the beginning that

1400
01:39:45,120 --> 01:39:46,620
polynomial violation

1401
01:39:51,360 --> 01:39:57,460
a corresponding to do this this isomorphism so each of these things quite belongs to

1402
01:39:57,460 --> 01:39:58,700
one of the

1403
01:40:00,230 --> 01:40:04,300
smaller vector spaces OK

1404
01:40:06,360 --> 01:40:09,780
give you as a running example

1405
01:40:12,710 --> 01:40:17,490
algebra brother corresponds to the usual fourier transform

1406
01:40:17,620 --> 01:40:18,860
for instance

1407
01:40:18,870 --> 01:40:23,590
the notion of algebras i said before is in general a vector space clustering as

1408
01:40:23,590 --> 01:40:28,100
an example we could have the complex numbers the polynomials and so on and so

1409
01:40:28,900 --> 01:40:30,990
a polynomial algebra

1410
01:40:31,040 --> 01:40:32,470
to define that we

1411
01:40:32,490 --> 01:40:37,220
choose a polynomial amount of money polynomial of degree n

1412
01:40:37,220 --> 01:40:38,850
and as an example

1413
01:40:38,860 --> 01:40:41,410
we could see this one right here

1414
01:40:41,470 --> 01:40:44,810
and we defined

1415
01:40:44,850 --> 01:40:47,910
polynomial algebra corresponding to this polynomial

1416
01:40:47,930 --> 01:40:54,460
as all the and the set of all polynomials with degree smaller than that

1417
01:40:54,540 --> 01:40:58,380
OK and the is the example we can have here

1418
01:40:58,510 --> 01:41:02,930
and there

1419
01:41:05,150 --> 01:41:08,640
the same set but actually the

1420
01:41:08,650 --> 01:41:11,980
all the bananas are computing more modular

1421
01:41:12,240 --> 01:41:13,650
x minus one

1422
01:41:13,660 --> 01:41:16,130
all right that dimension of this

1423
01:41:16,140 --> 01:41:18,000
of this

1424
01:41:18,010 --> 01:41:23,130
polynomial algebra as a vector space is an which is exactly the degree of the

1425
01:41:23,150 --> 01:41:24,880
of pn

1426
01:41:24,920 --> 01:41:28,160
and we could choose the basis for

1427
01:41:28,160 --> 01:41:32,920
such a vector space and we could choose the canonical one this is the simplest

1428
01:41:32,920 --> 01:41:36,370
form to choose but that's not necessarily

1429
01:41:36,470 --> 01:41:38,000
the only one

1430
01:41:40,360 --> 01:41:42,480
now the boundary condition

1431
01:41:44,880 --> 01:41:46,900
what should be

1432
01:41:47,650 --> 01:41:50,050
representation of x to the end

1433
01:41:51,740 --> 01:41:53,370
our vector space so

1434
01:41:53,380 --> 01:41:57,540
that means we need to find some coefficients corresponding to

1435
01:41:57,580 --> 01:42:00,330
these vectors in the basis that

1436
01:42:00,380 --> 01:42:06,330
o correspond to two this exit here this doesn't belong to the algebra because it's

1437
01:42:06,590 --> 01:42:08,870
degree is an

1438
01:42:09,840 --> 01:42:12,900
in the case when our polynomial is x

1439
01:42:12,960 --> 01:42:19,740
minus one then we see that this is exactly one which is the first

1440
01:42:20,420 --> 01:42:24,460
the first element in the basis so essentially

1441
01:42:24,810 --> 01:42:27,710
this reduces to the cyclic boundary condition

1442
01:42:27,730 --> 01:42:31,410
and the signal extension refers to what correspond to

1443
01:42:34,740 --> 01:42:36,660
o module

1444
01:42:36,700 --> 01:42:37,780
of x

1445
01:42:37,820 --> 01:42:40,950
and this is obvious that

1446
01:42:41,000 --> 01:42:46,700
as n grows it will simply repeat go through all these elements of the basis

1447
01:42:47,460 --> 01:42:50,980
OK the convolution is just the product

1448
01:42:51,020 --> 01:42:53,320
of a field there

1449
01:42:53,330 --> 01:42:55,560
and signal

1450
01:42:56,560 --> 01:42:57,930
you know effect so here

1451
01:42:57,940 --> 01:43:05,890
the algebra and module are identical and the model is called in this case regular

1452
01:43:06,700 --> 01:43:14,020
well this exactly correspond to secure circular convolution in the case of x minus one

1453
01:43:14,070 --> 01:43:15,830
and the spectral

1454
01:43:17,840 --> 01:43:19,580
exactly the roots

1455
01:43:19,590 --> 01:43:21,660
one of the and of x

1456
01:43:21,680 --> 01:43:25,750
and there are some and this thing and you will see why that makes sense

1457
01:43:25,750 --> 01:43:26,870
in a second

1458
01:43:26,890 --> 01:43:33,080
and just to note is that here they are the interests of unity

1459
01:43:33,140 --> 01:43:37,230
OK so

1460
01:43:37,240 --> 01:43:38,920
this is the spectrum

1461
01:43:38,930 --> 01:43:40,410
the fourier transform

1462
01:43:40,460 --> 01:43:44,900
is the isomorphism between this algebra

1463
01:43:44,900 --> 01:43:47,320
and our colleagues these vertical things groups

1464
01:43:47,340 --> 01:43:48,650
i would circle the

1465
01:43:48,670 --> 01:43:50,510
and i did that in my notes but the

1466
01:43:50,530 --> 01:43:54,420
things get really messy if you start circling this diagram is going to get really

1467
01:43:54,420 --> 01:43:56,650
fall just to warn you

1468
01:43:56,670 --> 01:44:00,260
by the end of the almost unintelligible but hey

1469
01:44:00,280 --> 01:44:02,010
there it is

1470
01:44:03,550 --> 01:44:04,860
here really

1471
01:44:04,880 --> 01:44:09,320
feeling bored you can draw this a few times and you can draw the how

1472
01:44:09,320 --> 01:44:12,280
it grows

1473
01:44:13,050 --> 01:44:15,670
so there are the groups political groups of five

1474
01:44:18,590 --> 01:44:25,820
the second step is to recurse

1475
01:44:25,880 --> 01:44:29,220
this is where things are a bit unusual

1476
01:44:30,400 --> 01:44:34,720
even more unusual

1477
01:44:36,800 --> 01:44:39,260
i really should have had the line in between one and two

1478
01:44:39,300 --> 01:44:42,090
so going to have this down

1479
01:44:42,110 --> 01:44:43,900
concerted here

1480
01:44:43,940 --> 01:44:49,360
also in step one want to find the median of each group

1481
01:44:49,380 --> 01:44:59,050
OK so

1482
01:44:59,510 --> 01:45:03,130
what i like to do is just imagine this figure each of the five elements

1483
01:45:03,130 --> 01:45:07,900
in each group gets reorganized so the the middle one is the median so i

1484
01:45:07,940 --> 01:45:10,610
call these the median of each group

1485
01:45:10,630 --> 01:45:13,240
o five elements of the median

1486
01:45:13,260 --> 01:45:16,100
right in the middle these two elements less than the median to on great in

1487
01:45:16,100 --> 01:45:16,940
the media

1488
01:45:16,970 --> 01:45:19,920
again we're all elements are distinct

1489
01:45:19,940 --> 01:45:28,150
OK so that they are computer how long is that take me

1490
01:45:28,170 --> 01:45:36,670
and over five groups each with five elements compute the median of each one

1491
01:45:40,780 --> 01:45:45,400
at times over five state and that's going to

1492
01:45:45,420 --> 01:45:49,820
the i mean you're coming comparisons which is good because definitely

1493
01:45:51,260 --> 01:45:56,220
the point is within each group only have to do because the number of comparisons

1494
01:45:56,220 --> 01:46:00,260
because of cost number of elements doesn't matter you could use randomized selects for all

1495
01:46:00,260 --> 01:46:04,360
i care no matter what you do can only take constant number of comparisons as

1496
01:46:04,360 --> 01:46:07,440
long as you don't make a person more than once

1497
01:46:07,470 --> 01:46:08,460
thanks so

1498
01:46:08,470 --> 01:46:09,840
this is easy

1499
01:46:09,860 --> 01:46:10,990
is any

1500
01:46:11,090 --> 01:46:14,900
you could sort because sort the five numbers and then look at the third one

1501
01:46:16,590 --> 01:46:20,650
this is only five it

1502
01:46:20,670 --> 01:46:24,670
so that's one of the idea already we have some elements that are sort of

1503
01:46:24,670 --> 01:46:25,780
vaguely in the middle

1504
01:46:25,780 --> 01:46:27,720
but just of the group

1505
01:46:27,760 --> 01:46:30,010
and we've only done when your work

1506
01:46:30,610 --> 01:46:33,720
doing well so far

1507
01:46:34,690 --> 01:46:37,650
now we get to the second step which starred core

1508
01:46:37,670 --> 01:46:41,260
well we curse

1509
01:47:00,340 --> 01:47:08,550
the next idea is well we have these four over five medians

1510
01:47:08,570 --> 01:47:11,760
i'm going to compute the median of those medians

1511
01:47:11,780 --> 01:47:16,820
so i'm imagining that i rearranged these and unfortunately it's an even number six about

1512
01:47:16,820 --> 01:47:19,150
but are rearranged

1513
01:47:19,150 --> 01:47:20,510
so this guy

1514
01:47:21,190 --> 01:47:23,820
from the second box is the median

1515
01:47:23,820 --> 01:47:27,860
these elements that these two elements are strictly less than the sky these three elements

1516
01:47:27,860 --> 01:47:29,470
are strictly greater than this guy

1517
01:47:29,510 --> 01:47:32,130
now that doesn't directly tell me anything

1518
01:47:32,150 --> 01:47:35,510
it would it would seem that doesn't directly tell me about and the elements that

1519
01:47:36,280 --> 01:47:39,880
we'll come back to that in fact does tell us about some of the elements

1520
01:47:39,990 --> 01:47:43,490
right now this element is just the medium of these guys each of these guys

1521
01:47:43,840 --> 01:47:45,670
is the median of five elements

1522
01:47:45,750 --> 01:47:47,690
that's all we know

1523
01:47:47,700 --> 01:47:49,510
do that recursively

1524
01:47:49,510 --> 01:47:54,010
this is going to take team event over five times

1525
01:47:54,880 --> 01:47:58,070
so far so good we can afford to recursion a problem of size n over

1526
01:47:59,170 --> 01:48:01,800
and linear work we know that works out to linear

1527
01:48:03,570 --> 01:48:09,650
OK but there's more promising not done yet

1528
01:48:09,780 --> 01:48:19,740
the next step is part axes are partition element partition there the rest of the

1529
01:48:19,740 --> 01:48:25,110
algorithm is just like randomise partition so we're going to define k

1530
01:48:25,220 --> 01:48:27,420
to be the rank of x

1531
01:48:27,470 --> 01:48:31,190
and this can be done i mean it's and minus are plus one or whatever

1532
01:48:31,920 --> 01:48:35,570
i'm not going to write how to do that because we're higher level here

1533
01:48:35,590 --> 01:48:37,740
but it can be done

1534
01:48:37,760 --> 01:48:43,630
and then we have the three way branching so if i happens to equal k

1535
01:48:43,650 --> 01:48:47,590
we're happy the pivot element is the element we're looking for

1536
01:48:47,610 --> 01:48:49,690
but more likely

1537
01:48:49,720 --> 01:48:51,590
i xi less than k

1538
01:48:51,610 --> 01:48:55,340
or it's bigger than k

1539
01:48:55,340 --> 01:48:58,650
and then we just make the appropriate recursive call

1540
01:48:58,670 --> 01:49:00,220
so here

1541
01:49:02,300 --> 01:49:05,940
it's like the i th smallest element

1542
01:49:05,970 --> 01:49:16,260
in the lower part of the year

1543
01:49:16,280 --> 01:49:19,170
the left of the partition element

1544
01:49:19,170 --> 01:49:22,440
and otherwise we recursively select the

1545
01:49:22,440 --> 01:49:24,570
i minus case

1546
01:49:24,570 --> 01:49:27,260
the smallest element

1547
01:49:27,340 --> 01:49:32,130
and the upper part of the era

1548
01:49:32,130 --> 01:49:36,220
OK so this is not writing sort of high-level because we've already seen all of

1549
01:49:36,220 --> 01:49:38,630
this is the same

1550
01:49:38,700 --> 01:49:43,070
as the last couple steps randomized select

1551
01:49:50,320 --> 01:49:51,650
that's the algorithm

1552
01:49:51,880 --> 01:49:56,320
the real question is why does it work why is this linear time

1553
01:49:57,300 --> 01:49:58,530
so the

1554
01:49:58,530 --> 01:50:01,860
first questions what the recurrence we can quite right down here

1555
01:50:01,880 --> 01:50:05,610
because we don't know how big these recursive subproblems could be

1556
01:50:05,650 --> 01:50:09,010
we're gonna the recursion the lower part of the upper part this just like before

1557
01:50:09,030 --> 01:50:12,670
if we're lucky we have split like zero and minus one this is going to

1558
01:50:12,670 --> 01:50:17,070
be a quadratic time out with the claim is this this partition element is guaranteed

1559
01:50:17,070 --> 01:50:19,880
to be pretty good and good enough

1560
01:50:19,900 --> 01:50:25,510
this will the running time of this thing will be t of something times n

1561
01:50:25,530 --> 01:50:29,420
we don't know what the something is

1562
01:50:29,440 --> 01:50:32,170
how big could it be

1563
01:50:34,470 --> 01:50:39,860
i could ask you but sort of indirect result of tell you we've already recursive

1564
01:50:39,860 --> 01:50:42,050
called here and over five

1565
01:50:42,070 --> 01:50:43,190
it better be

1566
01:50:43,190 --> 01:50:46,030
the whatever constants is going to be something

1567
01:50:46,050 --> 01:50:51,220
times and better be that constant is strictly less than four-fifths

1568
01:50:51,280 --> 01:50:53,190
if it's equal to four

1569
01:50:53,190 --> 01:50:57,050
then you're not splitting up the problem enough you get an organ running time

1570
01:50:57,050 --> 01:51:00,340
if it's strictly less than four-fifths

1571
01:51:00,380 --> 01:51:03,990
then you're reducing the problem by at least a constant factor

1572
01:51:04,010 --> 01:51:07,150
in this sense if you add up all the recursive subproblems and over five and

1573
01:51:07,150 --> 01:51:09,030
something times and

1574
01:51:09,050 --> 01:51:12,510
you get something that is a constant strictly less than one times and

1575
01:51:12,510 --> 01:51:16,650
that forces the work to be geometric this geometric you're going to get linear time

1576
01:51:16,650 --> 01:51:19,400
this intuition but it's the right thing to wish

1577
01:51:19,420 --> 01:51:24,650
OK so whenever an earlier time keep that in mind you want to get the

1578
01:51:24,650 --> 01:51:29,990
proper if you're doing divine concrete got to get the tall subproblem size to be

1579
01:51:29,990 --> 01:51:33,960
some constant less than one times and

1580
01:51:34,010 --> 01:51:35,590
that will work

1581
01:51:38,260 --> 01:51:39,900
we got work at this

1582
01:51:39,900 --> 01:51:43,090
costs in here

1583
01:51:43,150 --> 01:51:45,880
and we're going to use this figure

1584
01:51:47,630 --> 01:51:51,570
which so far looks surprisingly uncluttered

1585
01:51:51,570 --> 01:51:54,900
now we will make it cluttered

1586
01:51:54,920 --> 01:51:57,990
what i would like to do is drawn error

1587
01:51:58,010 --> 01:52:00,460
between two vertices

1588
01:52:00,460 --> 01:52:06,250
we're going to start today with the cities of lecture and nuclear physics

1589
01:52:06,310 --> 01:52:09,820
the basics of so it introduction it is

1590
01:52:09,830 --> 01:52:13,740
the appreciate to introduce you prefer so is good

1591
01:52:13,780 --> 01:52:17,920
she started a few years ago as a phd you

1592
01:52:17,970 --> 01:52:25,230
and then should become very quickly one of the difference in these things especially in

1593
01:52:25,640 --> 01:52:29,460
the french institute for nuclear research CA

1594
01:52:29,480 --> 01:52:30,830
where should we can

1595
01:52:30,840 --> 01:52:32,550
since two thousand

1596
01:52:33,480 --> 01:52:36,790
group leader of the to conduct nuclear

1597
01:52:36,880 --> 01:52:41,630
structural studies and also the many body problems which is now located in the need

1598
01:52:44,960 --> 01:52:47,060
believe it was just asked

1599
01:52:47,080 --> 01:52:49,130
the microphone

1600
01:52:49,170 --> 01:52:52,550
good morning i'm very happy to be here so

1601
01:52:52,570 --> 01:52:55,130
i'm working on nuclear physics so

1602
01:52:55,170 --> 01:53:00,270
i'm now working again which is convex and that the illness you know you'll lu

1603
01:53:00,310 --> 01:53:02,880
it's located in common

1604
01:53:02,900 --> 01:53:05,450
and so it

1605
01:53:05,500 --> 01:53:10,650
it's not as you just we with nuclear physics we are dealing with things that

1606
01:53:13,840 --> 01:53:15,690
make money

1607
01:53:15,710 --> 01:53:17,120
this smaller

1608
01:53:18,860 --> 01:53:23,650
we are dealing with MTV of energy we are dealing

1609
01:53:23,690 --> 01:53:25,270
with experiments

1610
01:53:25,280 --> 01:53:29,220
we ten or twenty people so what i'm going to

1611
01:53:29,230 --> 01:53:33,730
to teach you is what is nuclear physics what are the main features what are

1612
01:53:33,730 --> 01:53:38,490
the experiment from nowadays and what are the theoretical development

1613
01:53:38,540 --> 01:53:40,830
that have been undertaken

1614
01:53:40,850 --> 01:53:46,320
but before starting just three questions that seems to be very easy but

1615
01:53:46,400 --> 01:53:50,130
that are very tricky the you know what is the heaviest nucleus

1616
01:53:50,170 --> 01:53:52,050
in the universe

1617
01:53:52,070 --> 01:53:55,990
do you know how many nuclei do exist just think about one

1618
01:53:56,040 --> 01:53:58,550
one number

1619
01:53:58,560 --> 01:54:00,550
how many nuclei do exist

1620
01:54:00,570 --> 01:54:03,180
and what about the shapes of the nuclei

1621
01:54:03,200 --> 01:54:06,700
because we are dealing with the quantum system and

1622
01:54:06,710 --> 01:54:09,470
you will see that shape is something very

1623
01:54:09,490 --> 01:54:12,500
important to interpret experiments that

1624
01:54:12,550 --> 01:54:14,930
it in contradiction with the fact that you are

1625
01:54:14,940 --> 01:54:18,120
dealing with one something so

1626
01:54:18,140 --> 01:54:18,890
these are

1627
01:54:19,030 --> 01:54:21,170
tricky question also

1628
01:54:22,130 --> 01:54:25,730
how many nuclei do exist just to give you a flavor

1629
01:54:25,740 --> 01:54:30,170
this is the nuclear charge so

1630
01:54:30,480 --> 01:54:35,390
so you have the neutron number and put another here

1631
01:54:35,410 --> 01:54:39,280
so all these big cell represents one nucleus

1632
01:54:39,300 --> 01:54:43,850
so in yellow you see that you have two hundred ninety one stable nuclei that

1633
01:54:43,850 --> 01:54:45,980
do exist on earth

1634
01:54:46,030 --> 01:54:50,530
but there are many other nuclei that have been fantasizing laboratories here at

1635
01:54:50,540 --> 01:54:55,450
these are the sale or again you know you know the places to do

1636
01:54:55,460 --> 01:55:01,050
one thousand artificial nuclei have been found is sites that

1637
01:55:01,190 --> 01:55:07,060
there are many many predictions that to seven thousand bound exotic nuclei may so you

1638
01:55:07,060 --> 01:55:09,740
see that there are a lot of discoveries

1639
01:55:11,470 --> 01:55:16,110
new discoveries are made every day and there are a lot of places was the

1640
01:55:16,120 --> 01:55:20,390
future seven thousand exotic nuclei have to be discovered

1641
01:55:22,030 --> 01:55:23,950
you know one are

1642
01:55:23,970 --> 01:55:28,280
these are stable nuclei that are here now on earth

1643
01:55:28,310 --> 01:55:29,450
all these

1644
01:55:29,470 --> 01:55:31,080
i do that

1645
01:55:31,200 --> 01:55:33,690
to the lines

1646
01:55:33,810 --> 01:55:36,660
OK to the lines

1647
01:55:38,010 --> 01:55:40,270
doesn't here and all that one

1648
01:55:40,290 --> 01:55:45,840
other i'm going to that we are searching for now

1649
01:55:45,890 --> 01:55:47,470
concerning the

1650
01:55:47,480 --> 01:55:51,800
concerning the deformation these are some theoretical predictions

1651
01:55:52,470 --> 01:55:53,920
i will explain you know

1652
01:55:53,940 --> 01:55:57,320
course what these hartree fock bogoliubov approach

1653
01:55:58,210 --> 01:56:04,140
it's a theoretical approach so we are dealing with a nucleus made and made with

1654
01:56:04,140 --> 01:56:05,580
neutrons protons

1655
01:56:05,630 --> 01:56:10,960
and it's very difficult to study because it's the many body problem so many constituents

1656
01:56:11,080 --> 01:56:12,390
do interact

1657
01:56:12,410 --> 01:56:15,950
and we don't know how to solve that it's not specific at all

1658
01:56:15,970 --> 01:56:18,630
nuclear physics is common to all the

1659
01:56:18,640 --> 01:56:22,450
type of physical whatever you're starting when you have many many courses showing that do

1660
01:56:22,450 --> 01:56:25,220
interact you don't know how to solve that exactly

1661
01:56:25,270 --> 01:56:28,330
so you do some approximation for example you have the right

1662
01:56:28,350 --> 01:56:31,660
so you do what we call the mean field of these are prediction from these

1663
01:56:33,220 --> 01:56:34,940
and what is not here

1664
01:56:35,110 --> 01:56:40,860
what is needed here is the main information better mean deformation and you see that

1665
01:56:40,860 --> 01:56:43,860
they close to zero correspond to spherical shape

1666
01:56:43,870 --> 01:56:47,530
and you have only a few spherical nuclei

1667
01:56:47,550 --> 01:56:51,420
do correspond to magic numbers what we call the magic numbers

1668
01:56:51,460 --> 01:56:53,780
eight twenty twenty eight

1669
01:56:53,790 --> 01:56:56,810
fifty eighty two is the same

1670
01:56:56,830 --> 01:57:01,290
a kind of magic number of an atomic nucleus the value is not the same

1671
01:57:01,290 --> 01:57:02,500
but you have also

1672
01:57:02,520 --> 01:57:06,030
magic numbers when you are dealing with it from

1673
01:57:06,050 --> 01:57:11,550
but you see that many many nuclei are poorly so the formation of deformation in

1674
01:57:12,520 --> 01:57:16,420
and in the range so it means that in the intrinsic frame

1675
01:57:16,440 --> 01:57:19,640
they are like that or oblate here

1676
01:57:19,690 --> 01:57:22,560
so i mean that it's quite difficult to

1677
01:57:22,610 --> 01:57:27,180
to study in because you have many new components that are on different orbitals so

1678
01:57:27,180 --> 01:57:28,490
when you average

1679
01:57:28,510 --> 01:57:32,840
and when you consider the average there is the average of the the formation

1680
01:57:32,850 --> 01:57:34,000
then you have

1681
01:57:34,010 --> 01:57:36,900
something which can be very cold deform

1682
01:57:36,940 --> 01:57:39,400
april literally

1683
01:57:39,460 --> 01:57:42,980
so now the value of my lectures after this introduction

1684
01:57:42,990 --> 01:57:46,810
so today will be devoted to some features about the nucleus

1685
01:57:46,820 --> 01:57:48,940
i'm going to talk about the discovery

1686
01:57:48,960 --> 01:57:51,070
with the research thought experiment

1687
01:57:51,090 --> 01:57:54,450
and some properties radius binding energy

1688
01:57:54,460 --> 01:57:56,960
the interaction between nucleons

1689
01:57:56,970 --> 01:58:04,830
lifetime bridge activity in some application for it's in our for electricity

1690
01:58:04,880 --> 01:58:07,020
and energy production

1691
01:58:07,070 --> 01:58:11,830
so tomorrow will be devoted to modeling of the nucleus i will explain different approaches

1692
01:58:11,850 --> 01:58:17,670
so i macroscopic one where you are dealing with liquid you consider that and you

1693
01:58:17,670 --> 01:58:21,370
can easily with and then you can calculate many properties

1694
01:58:22,230 --> 01:58:25,410
front because cooking approaches where you really treat

1695
01:58:25,980 --> 01:58:29,050
nuclear one degree of freedom

1696
01:58:29,100 --> 01:58:33,440
that then the lecturers will be devoted to a number of recent study

1697
01:58:33,480 --> 01:58:37,240
concerning the discovery of these exotic nuclei

1698
01:58:37,280 --> 01:58:42,490
the isomers isomers are metastable states that do exist

1699
01:58:42,540 --> 01:58:47,850
in different nuclei so metastable states excited states which means that you can produce images

1700
01:58:47,860 --> 01:58:51,430
in an excited state that state it will stay

1701
01:58:51,430 --> 01:58:53,930
so if you construct your own kernels

1702
01:58:54,020 --> 01:59:00,800
and you want to show that is a valid kernel to do that is

1703
01:59:00,840 --> 01:59:04,910
everything is valid actually if you want to show that is a positive definite kernel

1704
01:59:05,200 --> 01:59:08,260
or if you want to or in other words you want to say two to

1705
01:59:08,260 --> 01:59:15,150
show that it fulfills mercer's property you just have to show that

1706
01:59:16,380 --> 01:59:22,110
give rise to a gram matrices that have no negative i can values

1707
01:59:22,170 --> 01:59:26,740
it's not always the the the the easier way to to prove that the kernel

1708
01:59:26,740 --> 01:59:28,950
is is a mercer kernel but

1709
01:59:28,990 --> 01:59:30,450
these away

1710
01:59:35,280 --> 01:59:41,950
and these input contains a few results that can be used if you want to

1711
01:59:41,950 --> 01:59:44,340
construct kernels from kernels

1712
01:59:44,360 --> 01:59:47,630
if you take the power for kernel

1713
01:59:47,630 --> 01:59:53,610
imagine that k one and k two are two mercer kernels them

1714
01:59:53,630 --> 01:59:59,220
OK want to the is also a mercer kernel and if you take the positive

1715
01:59:59,220 --> 02:00:00,720
combination of two kernel

1716
02:00:00,760 --> 02:00:07,180
it's still look mercer kernel issued take them to the if you take k one

1717
02:00:07,180 --> 02:00:09,610
times k two it's also

1718
02:00:09,720 --> 02:00:11,860
mercer kernels

1719
02:00:11,880 --> 02:00:17,490
so this is usually long and exercise that give when i teach

1720
02:00:18,030 --> 02:00:25,280
kernel methods and this is usually an exercise that nobody is able to do

1721
02:00:25,280 --> 02:00:27,300
so we're not going to do it

1722
02:00:27,400 --> 02:00:33,340
so here is a partial conclusion

1723
02:00:33,360 --> 02:00:35,320
so the kernel trick

1724
02:00:35,340 --> 02:00:39,450
there is this the first thing that you have to to to remember

1725
02:00:39,470 --> 02:00:44,180
it is the kernel trick you pick your favourite linear learn classifiers

1726
02:00:44,180 --> 02:00:46,470
and you could analyse it

1727
02:00:46,490 --> 02:00:51,570
and you you end up with a nonlinear classifier against criminalizing

1728
02:00:51,590 --> 02:00:57,630
linear or even just consists in replacing all dot products by kernel

1729
02:00:57,630 --> 02:01:00,720
and you're done

1730
02:01:00,760 --> 02:01:04,900
then we talked to beat about the mercer's condition

1731
02:01:04,970 --> 02:01:13,970
mercer's condition is is is the thing on the positive and negative organ values and

1732
02:01:13,990 --> 02:01:19,590
it's are i'd like to to stress so that it means that if you have

1733
02:01:19,590 --> 02:01:23,930
a kernel that feels mercer's condition that means that it's

1734
02:01:23,950 --> 02:01:29,070
there exist mapping phi said that when you compute k of UV it's equal to

1735
02:01:29,340 --> 02:01:33,200
the dot product between phi of u and five feet

1736
02:01:33,240 --> 02:01:36,220
there are a few

1737
02:01:36,220 --> 02:01:37,450
existing kernels so

1738
02:01:37,470 --> 02:01:39,470
that i showed you

1739
02:01:40,430 --> 02:01:47,970
actually there again one that is the two that are very popular the RBF kernels

1740
02:01:47,990 --> 02:01:50,700
and polynomial kernels

1741
02:01:50,860 --> 02:01:54,170
and a very important thing

1742
02:01:54,260 --> 02:02:01,220
uh that i'm going to talk about more later on is that

1743
02:02:01,280 --> 02:02:06,880
doing classification with structured data such as trees graphs sequences

1744
02:02:09,010 --> 02:02:10,720
is made possible

1745
02:02:10,740 --> 02:02:12,820
by the idea of kernel

1746
02:02:12,880 --> 02:02:15,700
in kernel methods mean that

1747
02:02:15,720 --> 02:02:19,680
the only the only thing that you have to worry about is to define

1748
02:02:19,740 --> 02:02:22,900
the proper kernel if you want to classify

1749
02:02:23,930 --> 02:02:25,700
you just have to define

1750
02:02:25,740 --> 02:02:27,610
mercer kernel on graphs

1751
02:02:27,610 --> 02:02:29,820
and you can use these very silly

1752
02:02:29,840 --> 02:02:35,030
dumb algorithm that i showed you and you can do classification graphs

1753
02:02:35,050 --> 02:02:38,670
if you want to do classification sequences you just have to derive

1754
02:02:38,680 --> 02:02:43,800
a new kernel sequences and then use any linear classic algorithm that you know for

1755
02:02:43,800 --> 02:02:47,800
instance the perceptron algorithm that you can show due monday

1756
02:02:47,910 --> 02:02:52,180
can use it you can customize it and you will end up with a nonlinear

1757
02:02:52,610 --> 02:02:54,570
with the a classifier for

1758
02:02:58,170 --> 02:03:02,930
the the the important thing that is that we the kernel method

1759
02:03:02,930 --> 02:03:05,860
trying to two

1760
02:03:05,860 --> 02:03:13,740
tackle problems were that involve structured data is is a model to the problem of

1761
02:03:13,740 --> 02:03:16,930
of finding a good kernel

1762
02:03:19,930 --> 02:03:25,340
exists there's no no no no need to worry about algorithms the the questions that

1763
02:03:25,740 --> 02:03:28,970
go with with the kernel trick is

1764
02:03:29,010 --> 02:03:31,990
and i'm not going to answer these because

1765
02:03:31,990 --> 02:03:34,170
i don't exactly know how to

1766
02:03:34,180 --> 02:03:35,340
two and

1767
02:03:35,410 --> 02:03:38,720
it is how you choose the right kind

1768
02:03:38,720 --> 02:03:41,930
because it's difficult

1769
02:03:41,950 --> 02:03:47,650
how you can combine kernels so there are a lot of works that

1770
02:03:47,650 --> 02:03:52,380
i'd read the problem of combining kernels usually the combination of kernels made as a

1771
02:03:52,380 --> 02:03:56,720
convex combination that is it's almost like the combination i talk to you about

1772
02:03:57,430 --> 02:04:02,570
these communication here

1773
02:04:02,590 --> 02:04:04,090
we've that we there

1774
02:04:04,740 --> 02:04:07,720
convex constraint on the

1775
02:04:07,740 --> 02:04:10,180
the coefficients

1776
02:04:10,240 --> 02:04:15,910
then there's the question of building kernels for structured data

1777
02:04:15,930 --> 02:04:20,900
and there's another question i don't if it's a question or something that i didn't

1778
02:04:20,950 --> 02:04:27,130
say much about is what kind of algorithm that you can use or you can

1779
02:04:27,130 --> 02:04:32,590
use us as the kernel algorithm so she here here's a list of very

1780
02:04:32,610 --> 02:04:34,130
of some other in

1781
02:04:34,130 --> 02:04:39,240
so it's ridge regression the kernel ridge regression and if you know what is regression

1782
02:04:39,260 --> 02:04:42,410
it's just the square regression where you want to

1783
02:04:42,430 --> 02:04:46,010
to predict a real value from x

1784
02:04:46,070 --> 02:04:48,260
four from some input data x

1785
02:04:48,280 --> 02:04:50,840
and you use square

1786
02:04:50,860 --> 02:04:55,630
the least square method and you do you have you add some regularisation and gives

1787
02:04:55,630 --> 02:04:57,170
you a ridge regression

1788
02:04:57,220 --> 02:05:03,300
and you can catalyze these you can two very closely related

1789
02:05:04,590 --> 02:05:07,700
algorithm which is a kernel fisher discriminant

1790
02:05:07,700 --> 02:05:10,090
you can do to kernel PCA

1791
02:05:10,090 --> 02:05:16,470
so it's principal component analysis it's an unsupervised method that you can use and you

1792
02:05:16,470 --> 02:05:18,800
can do as the

1793
02:05:18,820 --> 02:05:21,070
there is support vector machines

1794
02:05:21,070 --> 02:05:24,550
and this is the topic of the next the

1795
02:05:24,610 --> 02:05:25,800
the next

1796
02:05:25,800 --> 02:05:28,300
fifty minutes

1797
02:05:33,490 --> 02:05:37,260
how good

1798
02:05:37,300 --> 02:05:42,700
OK so it's a multi asked me asks me if if if you you have

1799
02:05:42,700 --> 02:05:44,800
some kind of knowledge

1800
02:05:44,820 --> 02:05:50,430
as how the chosen kernel is going to to make your data

1801
02:05:50,450 --> 02:05:52,220
so the problem that

1802
02:05:54,490 --> 02:05:59,260
can i say except that if you work in specific domains

1803
02:05:59,320 --> 02:06:05,220
usually if you know that the the kernel that you derive is

1804
02:06:05,280 --> 02:06:06,880
it is

1805
02:06:07,840 --> 02:06:12,380
it makes sense for for the experts of of the domain then

1806
02:06:12,380 --> 02:06:13,510
you have good chance

1807
02:06:14,630 --> 02:06:20,050
more probable that you can have separation but otherwise you cannot say that's why i

1808
02:06:20,050 --> 02:06:23,380
say that the truth in the right kernel is an issue

1809
02:06:23,400 --> 02:06:26,180
it is very difficult and you can not even know

1810
02:06:26,220 --> 02:06:31,930
with a good to the directional regions the very totally wrong kernel so there is

1811
02:06:32,510 --> 02:06:34,450
no answers

1812
02:06:37,800 --> 02:06:40,470
thank you

1813
02:06:40,470 --> 02:06:45,010
you'll see that there's usually there's just one section of the paper

1814
02:06:45,010 --> 02:06:51,760
that describe the bulk of the the and the strategy they used to compute everything

1815
02:06:51,760 --> 02:06:54,780
usually it's really nice it's really really elegant

1816
02:06:55,970 --> 02:07:01,510
it's there's it's there's just one part of it is that is

1817
02:07:01,550 --> 02:07:04,510
not new but very very

1818
02:07:08,110 --> 02:07:10,820
so for the mismatch string kernel

1819
02:07:10,860 --> 02:07:14,380
the only difference we've we've

1820
02:07:14,440 --> 02:07:18,990
with the previous kernel the spectrum kernel is that you low

1821
02:07:19,030 --> 02:07:21,440
low four four

1822
02:07:21,490 --> 02:07:22,530
this matches

1823
02:07:22,550 --> 02:07:29,440
that is that if two subsequences are not precisely equal you want to say that

1824
02:07:29,440 --> 02:07:32,530
they are totally different you want to say that the value of the similarity of

1825
02:07:32,530 --> 02:07:35,530
the subsequence is is equal to zero you will

1826
02:07:35,570 --> 02:07:37,320
and of course

1827
02:07:37,340 --> 02:07:40,760
down weight there are similarities

1828
02:07:40,800 --> 02:07:43,470
but you're not going to say that is zero

1829
02:07:43,650 --> 02:07:48,240
and again it's too if you write down and if you think a moment of

1830
02:07:48,740 --> 02:07:51,090
on on the problem you may think that

1831
02:07:51,110 --> 02:07:55,320
allowing for mismatches may

1832
02:07:55,340 --> 02:07:58,940
you imply a lot of different

1833
02:07:58,970 --> 02:08:03,610
algorithmic problems but they were able to two two two two

1834
02:08:03,610 --> 02:08:10,690
to use the same suffix tree structure to efficiently compute the mismatch string kernel again

1835
02:08:10,740 --> 02:08:14,960
just go see the papers he there nice

1836
02:08:14,970 --> 02:08:16,670
and then using this kernel

1837
02:08:16,700 --> 02:08:17,990
there were

1838
02:08:18,030 --> 02:08:20,380
able to two

1839
02:08:20,420 --> 02:08:24,840
two up if a performed the result that the results that they have in the

1840
02:08:24,840 --> 02:08:30,760
spectrum kernel and and they compared favorably to several state of the

1841
02:08:30,800 --> 02:08:33,090
our method using svms

1842
02:08:33,130 --> 02:08:36,360
so the the thing that is very important here is that

1843
02:08:37,260 --> 02:08:44,340
leslie and her coauthors only focused on the on

1844
02:08:44,340 --> 02:08:50,070
the design of the kernel they didn't really care about what kind of algorithm that

1845
02:08:50,070 --> 02:08:51,690
they were going to use

1846
02:08:51,920 --> 02:08:56,650
they were just worried about having good kernel

1847
02:08:56,670 --> 02:09:02,470
and and is very important because for all all or other kinds of methods like

1848
02:09:02,470 --> 02:09:05,530
neural networks and

1849
02:09:05,550 --> 02:09:08,700
bayes networks some sometimes everything is

1850
02:09:09,610 --> 02:09:12,510
you have both the outgoing

1851
02:09:12,590 --> 02:09:19,820
the modelling and inference everything is entangled is is very very hard to to see

1852
02:09:19,820 --> 02:09:21,170
the difference between

1853
02:09:24,130 --> 02:09:27,110
part and the algorithm part in and everything

1854
02:09:27,220 --> 02:09:32,650
four kernels you just kernel methods usually for specific promise you have to design a

1855
02:09:32,650 --> 02:09:37,320
kernel and then once you the current you can use

1856
02:09:37,340 --> 02:09:39,630
what you want

1857
02:09:39,630 --> 02:09:43,280
and fisher kernels

1858
02:09:43,300 --> 02:09:46,110
this is something that

1859
02:09:46,170 --> 02:09:53,220
is interesting is it's not i don't think it's very easy to to implement because

1860
02:09:53,240 --> 02:09:57,860
because of the remarks that i may make here but the idea is is is

1861
02:09:57,860 --> 02:10:01,510
the following imagine that you're you have classification problem

1862
02:10:01,570 --> 02:10:07,070
and you consider all the classification problem on sequences

1863
02:10:07,090 --> 02:10:13,440
and you have to be positive sequences for instance x one to x and and

1864
02:10:13,440 --> 02:10:15,920
watch the first the first thing to do

1865
02:10:16,190 --> 02:10:20,610
you do is to model the probability distribution of the sequences

1866
02:10:20,720 --> 02:10:25,630
in order to do that you can use a hidden markov models or can any

1867
02:10:25,630 --> 02:10:28,700
kind of models that silly talk to you about yesterday

1868
02:10:28,780 --> 02:10:32,670
that is appropriate to model

1869
02:10:35,780 --> 02:10:41,690
it is something very special is that you're going to compute the feature vector u

1870
02:10:41,690 --> 02:10:46,150
x for some value x as

1871
02:10:46,190 --> 02:10:48,010
he is famous for

1872
02:10:49,380 --> 02:10:55,550
you have a moral these forces and HMM an HMM is defined by parameters

1873
02:10:55,590 --> 02:11:00,820
and it defines a probability distribution and you can a

1874
02:11:01,220 --> 02:11:05,400
differentiation differentiate with respect to all the parameters

1875
02:11:05,470 --> 02:11:08,780
and this is what you do you compute the gradient with respect to all the

1876
02:11:08,780 --> 02:11:14,820
printer that you define your your model european local model for instance and then you

1877
02:11:14,820 --> 02:11:19,400
take the gradient and you see what i what what is its value at at

1878
02:11:19,900 --> 02:11:22,700
at the precise x that you consider

1879
02:11:24,280 --> 02:11:27,340
is the meaning of that

1880
02:11:27,360 --> 02:11:29,110
and you have the vector

1881
02:11:29,130 --> 02:11:32,630
so the size of the vectors is precisely the size of the number of these

1882
02:11:32,630 --> 02:11:37,470
is the number of parameters that you have the define the define your in the

1883
02:11:37,470 --> 02:11:42,400
define your your model the thing that you use to define the to model the

1884
02:11:42,940 --> 02:11:45,590
probability distribution on your data

1885
02:11:48,470 --> 02:11:53,190
there are many question actually if you were can be done on on fisher kernels

1886
02:11:53,190 --> 02:12:00,110
you can and you you want to tackle some specific applications i i UU your

1887
02:12:00,840 --> 02:12:06,990
capitol of reaching very good results but there are a few questions that see that

1888
02:12:06,990 --> 02:12:12,590
that are very difficult to handle when you do official kernels like

1889
02:12:12,630 --> 02:12:15,650
how you choose the adequate model for p

1890
02:12:15,670 --> 02:12:19,240
there is that the dish the how you're going to

1891
02:12:19,260 --> 02:12:23,340
estimate the probability distributions of your data

1892
02:12:23,360 --> 02:12:25,220
so these are these problems

1893
02:12:25,240 --> 02:12:30,220
there's another problem that is a which is that you're going to do two steps

1894
02:12:30,220 --> 02:12:32,760
of learning the first step is to learn

1895
02:12:32,760 --> 02:12:34,070
these models

1896
02:12:34,090 --> 02:12:38,420
and the second step is the the learning that the class

1897
02:12:38,420 --> 02:12:44,840
learning of the classification function and so it's usually very difficult to do it's not

1898
02:12:44,840 --> 02:12:47,800
it's not recommended due to do

1899
02:12:48,690 --> 02:12:51,530
tasks if you want to do one thousand

1900
02:12:51,530 --> 02:12:54,780
if you want to do classification just to classification

1901
02:12:54,800 --> 02:13:01,280
sometimes you cannot avoid to avoid doing so another task but if you can spare

1902
02:13:01,920 --> 02:13:05,340
the the the

1903
02:13:05,940 --> 02:13:12,200
the the learning of of something else did of doing density estimation then you should

1904
02:13:12,200 --> 02:13:16,090
do that because the problem that you have for classification

1905
02:13:16,090 --> 02:13:21,150
all classifications you have them for density estimation so you have

1906
02:13:21,150 --> 02:13:25,880
two problems and you have a kind of a pipeline and it's very difficult to

1907
02:13:25,880 --> 02:13:28,380
deal with this is despite by my

1908
02:13:28,400 --> 02:13:35,780
and so there's there's

1909
02:13:35,820 --> 02:13:43,300
there are the the things about modern marginalized kernels and sequences these

1910
02:13:43,360 --> 02:13:49,720
OK now i want to enter into the details but if you want to derive

1911
02:13:49,820 --> 02:13:51,190
another view of

1912
02:13:51,200 --> 02:13:53,630
the fisher kernels and to

1913
02:13:53,630 --> 02:13:59,470
actually they make just they make a connection between their kind of of kernels which


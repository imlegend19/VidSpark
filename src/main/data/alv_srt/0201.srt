1
00:00:00,000 --> 00:00:01,360
OK so

2
00:00:01,370 --> 00:00:06,240
but let's use the chain rule to understand how

3
00:00:06,600 --> 00:00:09,900
F depends on the C 1 y is held constant

4
00:00:10,920 --> 00:00:18,440
so that 1st Fibre Chernobyl locally and then when I corners what's going on so

5
00:00:18,440 --> 00:00:22,180
you can just use the version that they have a fair as a template to

6
00:00:22,180 --> 00:00:29,440
see what's going on with the job that I'm going to explain it

7
00:00:29,860 --> 00:00:31,630
not just for

8
00:00:32,800 --> 00:00:39,220
but but but but but but but but but but but but but but but

9
00:00:39,540 --> 00:00:45,440
but but but but but but but but that's OK so that's the most

10
00:00:45,740 --> 00:00:47,500
mechanical and

11
00:00:48,710 --> 00:00:55,840
mindless way of life and number and the same here let's say that conveying z

12
00:00:55,840 --> 00:00:59,560
keeping why constant may want to know how I've changes as well as might change

13
00:00:59,560 --> 00:01:06,140
because x might change what might why might change and z might know how quickly

14
00:01:06,140 --> 00:01:11,040
does exchange and well the rate of change of X in this situation is partial

15
00:01:11,050 --> 00:01:12,920
expert z with white constant

16
00:01:14,160 --> 00:01:19,150
so if I change x at this rate than if will change at that time

17
00:01:20,960 --> 00:01:23,440
now otherwise might change

18
00:01:23,530 --> 00:01:27,080
so the rate of change of why would be like the change of life perspective

19
00:01:27,100 --> 00:01:32,050
z according white constant that wait a 2nd if y is held constant then why

20
00:01:32,050 --> 00:01:35,950
doesn't change so it going is evil and the didn't really have to write that

21
00:01:37,280 --> 00:01:42,360
but I voted just to be systematic OK if wife had been somehow able to

22
00:01:42,360 --> 00:01:48,650
change something like that but we have closed after to change at it because it

23
00:01:48,660 --> 00:01:51,940
is held constant so if y is held constant then nothing happens here

24
00:01:52,440 --> 00:01:58,460
and finally where z is changing something of a perspective this 1

25
00:01:59,040 --> 00:02:03,700
and that causes after change at that time and then we add the effects to

26
00:02:04,360 --> 00:02:09,340
this seeds nothing but we would all channel just put these extra substrates to tell

27
00:02:09,340 --> 00:02:12,660
us what is held constant and what is

28
00:02:13,460 --> 00:02:19,560
OK now of course we can simplify to the small because here how quickly does

29
00:02:19,960 --> 00:02:24,780
change differentiating this is where the weight of tendency with respect to itself is just

30
00:02:24,780 --> 00:02:30,580
1 OK

31
00:02:30,800 --> 00:02:32,600
so in fact that really

32
00:02:32,840 --> 00:02:37,380
mysterious part of this is the 1 here which is the rate of change of

33
00:02:37,380 --> 00:02:44,220
x with respect to and to find that we have to understand the constant

34
00:02:44,920 --> 00:02:48,140
so how can we find the rate of change of expert perspectives z where we

35
00:02:48,140 --> 00:02:52,080
could use different forms liquid in here but we can also keep using the change

36
00:02:52,680 --> 00:03:01,700
it but it it it thank you

37
00:03:10,280 --> 00:03:17,060
going do that when I can just look at how gene would change with respect

38
00:03:17,060 --> 00:03:23,560
to the delays has so I just do the same thing relations between genes that

39
00:03:25,600 --> 00:03:33,580
but before I do it so let's ask ourselves 1st what this report well if

40
00:03:33,580 --> 00:03:39,720
G is held constant then when we very easy keeping why constant unchanging xxx well

41
00:03:40,060 --> 00:03:48,970
just the doesn't change its held constant but but but also in the fact that

42
00:03:48,970 --> 00:03:52,580
it doesn't give it if we just say that when again when and where to

43
00:03:52,590 --> 00:04:00,000
get vector so let's see how we can compute factors interchangeable where the Chernobyl tells

44
00:04:00,000 --> 00:04:03,220
us in g changes because x y and z change

45
00:04:03,960 --> 00:04:08,640
OK how does it change because of x y and the possibility of X times

46
00:04:08,660 --> 00:04:13,640
the rate of change of expression that how does it change because of the wide

47
00:04:13,900 --> 00:04:17,720
where the authority for wife but thanks to the rate of change of wine but

48
00:04:17,720 --> 00:04:21,120
of course it just not then you don't need to actually find this 1 because

49
00:04:21,120 --> 00:04:23,140
ways has constant

50
00:04:24,220 --> 00:04:33,580
the convention because the rate of change because the changes and how quickly z changes

51
00:04:33,580 --> 00:04:38,100
here of course is what you get

52
00:04:38,680 --> 00:04:47,260
so out of this you get that when entail of I think pathology dutiful experimenters

53
00:04:47,270 --> 00:04:53,800
white a piece of text and partial expert so this is a white constant press

54
00:04:53,890 --> 00:05:05,540
genes and and this and now we found however dependency in the case of lexical

55
00:05:05,550 --> 00:05:11,040
from the with white has constant is negative the gist of the scene of the

56
00:05:11,240 --> 00:05:12,320
adjacent access

57
00:05:13,060 --> 00:05:16,520
no we plug this into that and we get

58
00:05:17,300 --> 00:05:23,100
this goes on the way here

59
00:05:24,160 --> 00:05:28,740
OK and then we get the answer but I'm not going to work in a

60
00:05:28,740 --> 00:05:30,180
2nd but

61
00:05:35,540 --> 00:05:48,180
so there will support X times this value in the case of the probabilities of

62
00:05:48,180 --> 00:05:55,640
X plus a cover letter from and you can observe that this is exactly the

63
00:05:55,640 --> 00:06:01,500
same formula that we had over in fact let's compare this to statements

64
00:06:02,020 --> 00:06:05,660
I claim with exactly the same thing just with different notation

65
00:06:05,660 --> 00:06:15,600
amazing customer service thank you

66
00:06:22,130 --> 00:06:30,120
OK OK big screen isn't working today there can be things smaller species there actually

67
00:06:30,120 --> 00:06:34,430
because i i think in this room just got a new project that

68
00:06:35,440 --> 00:06:37,540
someone sent an exciting email

69
00:06:37,540 --> 00:06:42,440
was it just on friday saying which is a new project in this the set

70
00:06:42,600 --> 00:06:47,430
of four thousand to one something rather brightness ratio and some some was very excited

71
00:06:47,430 --> 00:06:50,200
about the new project in this room you will see that we see that in

72
00:06:50,200 --> 00:06:52,870
operation on wednesday

73
00:06:55,150 --> 00:06:59,540
stop it or what machine learning is on one this one this machine learning

74
00:06:59,540 --> 00:07:01,160
she has a

75
00:07:01,180 --> 00:07:05,340
she can we can we detect up raise your hand if if the text on

76
00:07:05,340 --> 00:07:08,160
the small spines is legible

77
00:07:08,210 --> 00:07:13,870
OK call mostly there so just read out on so

78
00:07:13,880 --> 00:07:15,580
what is machine learning

79
00:07:15,580 --> 00:07:19,630
way back in about nineteen fifty nine after samuel

80
00:07:19,690 --> 00:07:25,860
this is a defined machine learning informally as the the study that gives computers to

81
00:07:25,860 --> 00:07:33,360
learn on the this study tickets computers the ability to learn without being explicitly programmed

82
00:07:33,400 --> 00:07:35,050
so obvious tamil

83
00:07:35,050 --> 00:07:37,520
so we that history machine learning actually

84
00:07:37,530 --> 00:07:40,280
this is something

85
00:07:40,290 --> 00:07:42,710
very cool which was on

86
00:07:42,770 --> 00:07:44,640
he really checkers program

87
00:07:44,700 --> 00:07:48,330
which would take into checkers against itself

88
00:07:49,260 --> 00:07:51,100
and so because

89
00:07:51,370 --> 00:07:57,690
computer can play thousands of games since his itself rather quickly on office and has

90
00:07:57,690 --> 00:08:03,790
program thousands of games against itself and over time we start to learn to recognise

91
00:08:03,790 --> 00:08:09,340
patterns which led to wins and patterns which led to losses over time and things

92
00:08:09,340 --> 00:08:13,070
like that you know g if i get a lot of my pieces taken by

93
00:08:13,070 --> 00:08:17,530
the opponent then are more likely to use and when you a my piece instances

94
00:08:17,530 --> 00:08:22,170
the position the especially likely to win rather

95
00:08:22,240 --> 00:08:25,540
so over time the sanyo

96
00:08:25,560 --> 00:08:27,520
the checkers for and they will actually learn

97
00:08:27,540 --> 00:08:33,130
to play checkers by learning whether the support positions that tend to be associated with

98
00:08:33,230 --> 00:08:37,940
what the board positions tend to be associated losses on

99
00:08:37,940 --> 00:08:42,770
and way back in nineteen around nineteen fifty nine the amazing thing about this was

100
00:08:42,770 --> 00:08:49,110
that on his program actually learned to play checkers much better than arthur samuel himself

101
00:08:50,960 --> 00:08:55,210
even today there are some people that say you know what computers can't do anything

102
00:08:55,210 --> 00:09:00,630
that are not explicitly programmed two and after samuel's checkers program was on may be

103
00:09:00,630 --> 00:09:01,980
the first

104
00:09:02,000 --> 00:09:08,650
i think really convincing refutation direct refutation of this claim are mainly on other sami

105
00:09:08,650 --> 00:09:13,610
manager at checkers program they could play checkers much better than he personally and as

106
00:09:13,610 --> 00:09:18,100
an instance of the computers learning to do things that they really were not problem

107
00:09:21,420 --> 00:09:22,330
here the more

108
00:09:22,360 --> 00:09:28,580
the reason the more modern more formal definition of machine learning due to tom mitchell

109
00:09:28,600 --> 00:09:34,830
who says that will pose learning problems on this is defined as follows she says

110
00:09:36,230 --> 00:09:41,730
a computer programme is said to learn from experience e with respect to some tossed

111
00:09:42,610 --> 00:09:44,690
and some performance measure p

112
00:09:44,710 --> 00:09:49,830
if this performance on t as measured by p improves with experience e so not

113
00:09:49,830 --> 00:09:54,730
only is the definition of rhymes on

114
00:09:54,730 --> 00:10:00,860
so for example in the case of chequers on the experience he e that the

115
00:10:00,860 --> 00:10:07,110
program has would be on the experience of playing once against attackers against itself say

116
00:10:07,130 --> 00:10:12,270
the toasty were is is the task of playing checkers and performance measure p will

117
00:10:12,270 --> 00:10:16,340
be something like you know the fraction games wins against certain set of human opponents

118
00:10:16,810 --> 00:10:21,040
and by this definition will say that after samuels on

119
00:10:21,040 --> 00:10:23,830
check this program has learned to play checkers

120
00:10:25,810 --> 00:10:28,380
as an overview of what we're going to

121
00:10:28,400 --> 00:10:34,900
doing discourse on this process of organised into four major sections on one

122
00:10:34,900 --> 00:10:38,060
o point four major topics and this class the first of which is

123
00:10:38,130 --> 00:10:40,310
on supervisor

124
00:10:40,330 --> 00:10:45,190
we give an example of that

125
00:10:50,960 --> 00:10:58,310
suppose you collect a dataset holding prices and quality is that ramesh actually collected the

126
00:10:58,310 --> 00:11:04,270
data set last week to to use an example later on this suppose that are

127
00:11:04,370 --> 00:11:08,440
good to go to collected collect

128
00:11:08,480 --> 00:11:13,690
of statistics about how much houses cost is a certain geographic area and that the

129
00:11:13,690 --> 00:11:17,500
t collected data from housing prices in portland oregon

130
00:11:18,670 --> 00:11:22,360
so what you can do is that's a part

131
00:11:24,710 --> 00:11:27,360
you know the square footage of the holes

132
00:11:27,380 --> 00:11:28,690
against the

133
00:11:28,730 --> 00:11:31,080
this price the whole space

134
00:11:31,100 --> 00:11:36,880
so you get the bit data back to this

135
00:11:36,900 --> 00:11:42,340
the second dataset like this poses different sizes that you know this different amounts of

136
00:11:43,330 --> 00:11:48,940
now let's say that i'm trying to sell holes in

137
00:11:48,980 --> 00:11:54,020
the same areas portland organism with the data comes from the on this i have

138
00:11:54,020 --> 00:11:57,400
the whole you know the size in square footage

139
00:11:58,380 --> 00:12:02,170
and i want an album to tell me about how much should i expect my

140
00:12:02,170 --> 00:12:03,730
whole the cell for

141
00:12:04,060 --> 00:12:07,080
so the loss away to do this

142
00:12:07,150 --> 00:12:11,520
so in summary you may have seen elements of what i'm about to say before

143
00:12:12,360 --> 00:12:16,460
so what you can do is look at the data and the history ninety eight

144
00:12:16,460 --> 00:12:20,310
and then you know this is my whole

145
00:12:20,330 --> 00:12:24,290
made an industry i think

146
00:12:24,310 --> 00:12:27,020
my house is going to go for damage

147
00:12:29,290 --> 00:12:33,080
and other decisions committee which which we'll talk about later which is

148
00:12:33,130 --> 00:12:38,110
well whether i don't want to straight line maybe actually shoot the quadratic function to

149
00:12:38,130 --> 00:12:39,710
be that data little bit better

150
00:12:40,150 --> 00:12:44,400
you notice if you do that depends school so that is

151
00:12:47,480 --> 00:12:52,080
and this sort the learning problem of learning to predict housing prices is an example

152
00:12:52,080 --> 00:12:54,480
of what's called the supervised learning problem

153
00:12:54,560 --> 00:12:59,580
on and the reason is called supervised learning is because we're providing the algorithm a

154
00:12:59,580 --> 00:13:00,520
data set

155
00:13:00,540 --> 00:13:06,290
a bunch of square footage in the budget housing sizes and as well as the

156
00:13:06,290 --> 00:13:09,900
right answer what the actual prizes

157
00:13:09,920 --> 00:13:11,710
of the number of houses were

158
00:13:11,750 --> 00:13:16,340
it is called the supervised learning because was supervising the album when the words were

159
00:13:16,340 --> 00:13:20,060
giving the album on the quote right answer

160
00:13:20,060 --> 00:13:21,980
well i think it's very different

161
00:13:22,000 --> 00:13:27,540
from things like web two point o websites which can be built in six months

162
00:13:27,540 --> 00:13:29,190
and can achieve notoriety

163
00:13:29,780 --> 00:13:34,990
o fame notoriety or whatever and in eighteen months there in bringing lots of money

164
00:13:34,990 --> 00:13:38,330
and be sold to somebody so that's the sort of the venture capitalist dream who

165
00:13:38,480 --> 00:13:43,240
looking for a short return on investment i think that in fact they're not used

166
00:13:43,840 --> 00:13:49,840
so certainly off the dotcom bust when it became very because very reasonably very careful

167
00:13:49,900 --> 00:13:52,960
not used to look at something where we're putting down every two years we make

168
00:13:52,960 --> 00:13:56,580
a new building block now i think what we've got the building blocks and i

169
00:13:56,580 --> 00:14:01,760
think sparql actually which is now coming to fruition i think sparql is really important

170
00:14:01,760 --> 00:14:05,960
building blocks of this query language suddenly you know now we have systematically recruited language

171
00:14:07,110 --> 00:14:09,550
using databases without without sequel

172
00:14:09,710 --> 00:14:13,610
so it's really is almost unthinkable so now we move to a situation where whoever

173
00:14:13,610 --> 00:14:19,390
has a large amount of data computer sparql endpoint on it and they can be

174
00:14:19,490 --> 00:14:22,920
queried with with this new sparql language

175
00:14:22,930 --> 00:14:26,550
that makes a huge step so that the semantic web really is not something that

176
00:14:26,550 --> 00:14:31,160
the venture capitalist investor themselves they'll investing in people who use it and more and

177
00:14:31,160 --> 00:14:35,540
more i think we'll see semantic web technology creep into web two point their applications

178
00:14:35,750 --> 00:14:40,190
creep into desktop applications creep into

179
00:14:40,200 --> 00:14:42,760
enterprise and applications particularly

180
00:14:42,770 --> 00:14:46,390
this would be kind of one side but later dataset would be the big companies

181
00:14:46,390 --> 00:14:50,090
like google microsoft yahoo

182
00:14:50,150 --> 00:14:52,930
maybe some other like documents

183
00:14:53,860 --> 00:14:57,850
my impression is but let's say this is still a question my impression is that

184
00:14:57,880 --> 00:15:02,690
it's a cool what's change landscape of semantic web for the semantic technologies a couple

185
00:15:02,690 --> 00:15:07,550
of relatively simple decisions a lot but still some

186
00:15:07,560 --> 00:15:09,120
they're not to act like

187
00:15:09,260 --> 00:15:12,930
microsoft the other so cannot comment on this

188
00:15:12,990 --> 00:15:19,300
of course the triple-a i conference to peter norvig was actively questioning the semantic web

189
00:15:19,300 --> 00:15:20,710
suggesting that people

190
00:15:20,760 --> 00:15:26,700
wouldn't have time for it various arguments against it so we cannot ask even though

191
00:15:26,700 --> 00:15:32,440
there are people with google people what google interest in the semantic web we can

192
00:15:32,440 --> 00:15:39,900
ask what the attitude so why what is it that is this possible that peter

193
00:15:40,030 --> 00:15:41,960
in a i person really

194
00:15:42,020 --> 00:15:46,960
it's still thinks of ontologies as being like cyclic huge monolithic things doesn't and he

195
00:15:46,960 --> 00:15:53,050
doesn't understand the fractal nature of the semantic web and how many interconnected many on

196
00:15:53,060 --> 00:15:58,810
ontologies indicated the edges or or maybe working can only i didn't get a lot

197
00:15:58,810 --> 00:16:04,280
of time to talk to about wales questions so we can only wonder perhaps is

198
00:16:04,280 --> 00:16:08,710
that google really makes that what they do well is they make

199
00:16:10,060 --> 00:16:13,050
by making order out of chaos

200
00:16:13,210 --> 00:16:16,260
they've got this algorithm which looks at the castle links on the web and to

201
00:16:16,360 --> 00:16:19,320
produces sort finds young vectors and

202
00:16:19,390 --> 00:16:22,950
while there is chaos out there then you have a business model

203
00:16:23,150 --> 00:16:26,410
if if in fact the web there was a lot of data out there which

204
00:16:26,410 --> 00:16:31,150
was reliable we're all from reliable sources and the assistance of finding for finding which

205
00:16:31,150 --> 00:16:37,270
sources were reliable for difference of data with the provenance this stuff that we have

206
00:16:37,270 --> 00:16:38,500
and then

207
00:16:38,680 --> 00:16:44,390
and the systems that which across much more complicated queries and get a really sophisticated

208
00:16:44,390 --> 00:16:49,980
answers which relevant queries which is is so the google engine just really will work

209
00:16:49,980 --> 00:16:56,400
for toll which involves relationships between people and so on and maybe the this would

210
00:16:56,460 --> 00:17:01,300
be a threat to current business model perhaps that's what company and like most accomplished

211
00:17:01,300 --> 00:17:04,870
looking at alternative ways of looking at ways in which they can use the data

212
00:17:04,970 --> 00:17:07,960
and i've got a and i think they make

213
00:17:07,980 --> 00:17:13,220
they may find it very useful to have metadata about how different pages relate on

214
00:17:13,220 --> 00:17:16,930
the web for example they may start with that and then moved to i think

215
00:17:16,930 --> 00:17:20,910
what question just as he thought that he said well what is it is because

216
00:17:20,910 --> 00:17:24,750
it's metadata metadata that can never be trusted but in fact the spider webs but

217
00:17:24,750 --> 00:17:28,430
data and only some of the data and metadata the large amounts of data out

218
00:17:28,430 --> 00:17:32,190
there maybe google want one detector while

219
00:17:32,730 --> 00:17:35,800
and maybe so it will be weakness and maybe there will be other companies will

220
00:17:35,800 --> 00:17:41,040
come in index the data and provide you and due to the semantic web but

221
00:17:41,040 --> 00:17:44,810
google it to the web who knows who can say semantic web would be kind

222
00:17:44,810 --> 00:17:50,560
of interplay between the state of the art technologies and so what i wanted to

223
00:17:50,560 --> 00:17:55,820
be one step so but it's very much biased stopped so i remember two years

224
00:17:56,480 --> 00:18:00,830
so tell me what you got was what's the matter with plans to talk to

225
00:18:00,840 --> 00:18:02,910
because it's the e

226
00:18:02,930 --> 00:18:07,890
logic so machine learning the mining technologies wouldn't have so much place it it should

227
00:18:07,890 --> 00:18:13,650
have guess my make this thing by top-down and bottom-up so of would be letting

228
00:18:13,650 --> 00:18:18,990
my my perspective logic based on our style ontologies

229
00:18:19,050 --> 00:18:23,340
which are mainly manual called it one of the three would be this

230
00:18:23,350 --> 00:18:26,390
emergent semantics one

231
00:18:26,500 --> 00:18:32,400
semantics search would come out of the data and only one with

232
00:18:32,420 --> 00:18:36,290
check the conference i well there's not much from this

233
00:18:36,420 --> 00:18:42,120
although the whole of the talk in the corridors about mapping databases industry track about

234
00:18:42,130 --> 00:18:43,100
how you

235
00:18:43,360 --> 00:18:48,220
take a relational database and information and put it on the semantic web

236
00:18:48,230 --> 00:18:52,810
so when you do that you end up with default ontology which is the first

237
00:18:53,160 --> 00:18:58,050
which is what was in the database to mind when he decided that he or

238
00:18:58,050 --> 00:19:01,660
she decided it was so you have to then

239
00:19:01,660 --> 00:19:04,670
you can look at that and

240
00:19:04,690 --> 00:19:05,920
take a look at random

241
00:19:05,930 --> 00:19:12,920
programme over the design of schema that which will try and work out what the

242
00:19:12,920 --> 00:19:16,080
database and was thinking of certain extent you can do quite a good job of

243
00:19:16,080 --> 00:19:19,760
that and then you can elaborate that an end up building up what you call

244
00:19:19,780 --> 00:19:26,460
bottom-up ontology there are so many databases out there with valuable information and the enterprise

245
00:19:26,470 --> 00:19:30,460
is obviously lots of lots of data and with some so we've done this for

246
00:19:30,460 --> 00:19:31,540
we know

247
00:19:33,800 --> 00:19:35,390
we were

248
00:19:41,040 --> 00:19:43,110
this site

249
00:19:54,540 --> 00:19:58,370
he goes

250
00:20:01,880 --> 00:20:07,060
or we can

251
00:20:07,110 --> 00:20:11,800
very few people

252
00:21:20,510 --> 00:21:23,460
you're in for her

253
00:21:54,280 --> 00:21:56,430
all right

254
00:22:07,350 --> 00:22:15,140
you can

255
00:22:24,230 --> 00:22:25,460
we will be

256
00:22:35,690 --> 00:22:38,980
you are

257
00:22:55,000 --> 00:22:59,430
when we the

258
00:23:01,310 --> 00:23:08,250
and the whole or

259
00:23:08,270 --> 00:23:12,790
you all

260
00:23:12,850 --> 00:23:19,190
because you

261
00:23:19,390 --> 00:23:23,140
well you know

262
00:23:23,160 --> 00:23:25,580
he call

263
00:23:45,810 --> 00:23:47,890
it's not really

264
00:23:48,710 --> 00:23:49,830
all right

265
00:23:58,930 --> 00:24:03,330
all right

266
00:24:16,430 --> 00:24:21,750
no one

267
00:24:23,810 --> 00:24:30,870
i mean there is a lot people

268
00:24:36,000 --> 00:24:38,270
i mean

269
00:24:43,100 --> 00:24:47,750
who is it

270
00:24:48,910 --> 00:24:52,750
i i

271
00:24:54,450 --> 00:24:56,750
i told you about one

272
00:24:56,770 --> 00:24:59,100
for example

273
00:25:31,560 --> 00:25:36,600
he is

274
00:25:49,500 --> 00:25:52,190
in britain

275
00:25:52,230 --> 00:25:56,850
he was

276
00:25:56,910 --> 00:25:57,890
i care

277
00:26:02,980 --> 00:26:05,310
i would also

278
00:26:05,310 --> 00:26:11,500
estimates on

279
00:26:34,250 --> 00:26:36,930
or whatever

280
00:26:43,350 --> 00:26:46,060
what we call

281
00:26:46,080 --> 00:26:48,410
you are

282
00:26:58,620 --> 00:27:01,520
in the

283
00:27:05,410 --> 00:27:08,980
one right one

284
00:27:40,600 --> 00:27:44,450
he he

285
00:27:44,450 --> 00:27:48,300
two destroying previously created en

286
00:27:48,350 --> 00:27:53,440
to use MIT phrase the reversibility is intuitively obvious because if you are able to

287
00:27:56,910 --> 00:27:59,290
i would still use that we use in the

288
00:27:59,340 --> 00:28:03,200
well i don't know so

289
00:28:03,210 --> 00:28:09,500
by contraction must be reversible because for example this polymerization were irreversible

290
00:28:09,510 --> 00:28:12,860
and all the protein that was ever size of the surface of the planet over

291
00:28:12,860 --> 00:28:18,070
the last three years would accumulate progressively and obviously that doesn't happen in there for

292
00:28:18,070 --> 00:28:20,310
all macromolecular synthesis

293
00:28:20,870 --> 00:28:25,090
proceed forward obviously must go in the other direction as well

294
00:28:25,150 --> 00:28:30,940
and the resulting concentration of complete protein is known as for its steady state

295
00:28:30,950 --> 00:28:33,300
so we might make the protein

296
00:28:33,360 --> 00:28:38,900
one rate and break down at the same rate and its steady-state concentrations

297
00:28:39,090 --> 00:28:44,230
represents a compromise between these two i knew the concentration of protein

298
00:28:44,310 --> 00:28:47,240
so we might observe at any one point in time

299
00:28:47,280 --> 00:28:48,480
indeed the term

300
00:28:48,490 --> 00:28:51,480
could be expanded due to any process in which is in

301
00:28:51,530 --> 00:28:54,510
so this is and is the breakdown of something

302
00:28:54,520 --> 00:29:01,620
and the equilibrium concentration which results is once again called the steady state of that

303
00:29:03,030 --> 00:29:06,140
now let's go down to the nitty gritty which is

304
00:29:07,330 --> 00:29:10,860
something which we can avoid for very long which is to say they are i

305
00:29:11,010 --> 00:29:12,860
side chains

306
00:29:12,910 --> 00:29:17,730
once again here we see an arbitrary artifact of very early

307
00:29:17,740 --> 00:29:19,600
evolution in the biosphere

308
00:29:19,610 --> 00:29:26,350
because there are in fact twenty different side chains creating set twenty distinct amino acid

309
00:29:26,360 --> 00:29:31,090
which are used to proteins by organisms on this planet

310
00:29:31,100 --> 00:29:33,230
again there are rare exceptions

311
00:29:33,240 --> 00:29:38,390
certain funky in certain bacteria are able to make unusual amino acid

312
00:29:38,400 --> 00:29:42,790
these are the basic building blocks of virtually all life forms on the planet

313
00:29:42,840 --> 00:29:46,430
ninety nine point nine nine percent of all the protein drug

314
00:29:46,700 --> 00:29:51,870
he site for the liberalisation of these twenty amino acids

315
00:29:52,420 --> 00:29:56,530
and by the way i wanted the amino acids lysine

316
00:29:56,540 --> 00:29:58,790
over here you see right here

317
00:29:58,800 --> 00:30:01,750
violates this rule of chirality

318
00:30:01,760 --> 00:30:07,990
and in you recall before i said because there are four distinct amino acid

319
00:30:08,000 --> 00:30:11,460
for sightings around the central carbon

320
00:30:11,480 --> 00:30:15,930
sometimes called the alpha carbon you always have handedness of amino acids

321
00:30:16,010 --> 00:30:20,340
but indicated this kind of this notion can not be respected in the things of

322
00:30:21,430 --> 00:30:23,180
not here

323
00:30:23,220 --> 00:30:28,180
simply because we don't have four distinct carbon run according with the red

324
00:30:28,230 --> 00:30:31,030
and here these two hydrogens or

325
00:30:31,100 --> 00:30:36,880
equivalent to one another not for distinct changes only three distinct surprising violates this rule

326
00:30:37,090 --> 00:30:39,270
chirality of left and right

327
00:30:40,530 --> 00:30:41,870
here by the way

328
00:30:41,890 --> 00:30:42,990
side chain

329
00:30:43,000 --> 00:30:47,330
which all of these cases is depicted as extending off to the right of each

330
00:30:47,330 --> 00:30:48,240
amino acid

331
00:30:48,260 --> 00:30:53,710
so i think we need proton hydrogen

332
00:30:53,750 --> 00:30:56,390
in fact what we see about these

333
00:30:56,670 --> 00:31:02,650
amino acid is is that the side chains have quite distinct biochemical properties

334
00:31:02,670 --> 00:31:06,800
and that begins to impress us with the notion of proteins

335
00:31:06,850 --> 00:31:09,160
and their biochemical attributes

336
00:31:09,170 --> 00:31:10,450
can be extended

337
00:31:11,120 --> 00:31:14,870
the identities of the amino acids are used to construct the

338
00:31:14,880 --> 00:31:17,600
we can talk about the notion of non polar

339
00:31:17,610 --> 00:31:20,960
versus polar amino acids i

340
00:31:21,010 --> 00:31:25,350
i mean i which have four affinity for water

341
00:31:25,430 --> 00:31:30,710
they don't have a separation plus and minus charges

342
00:31:30,760 --> 00:31:32,240
and as a consequence

343
00:31:33,090 --> 00:31:37,210
there are little bit or quite a bit hydrophobic

344
00:31:37,260 --> 00:31:41,480
now you see how can they be hydrophobic because here they are this charge and

345
00:31:41,490 --> 00:31:42,700
here this i mean this

346
00:31:43,210 --> 00:31:46,330
i thought that would make it highly hydrophilic

347
00:31:46,450 --> 00:31:49,650
keep in mind when talking about amino acid

348
00:31:49,670 --> 00:31:53,850
i'm not talking about them when they in a single amino acid form i'm talking

349
00:31:53,850 --> 00:31:59,320
about the properties once they have been polymerize interesting

350
00:31:59,370 --> 00:32:02,610
and once their collaboration with things like this

351
00:32:03,430 --> 00:32:06,120
the NH two and COOH charge

352
00:32:06,130 --> 00:32:09,210
that is the charge here and the charge you become irrelevant

353
00:32:09,220 --> 00:32:13,800
because this oxygen and this means movable type of covalent bonds

354
00:32:13,820 --> 00:32:16,040
and the acquisition of the proton

355
00:32:16,160 --> 00:32:19,710
in this setting of of proton over here

356
00:32:19,760 --> 00:32:25,340
not occur because both of these o and and are involved in covalent bonds

357
00:32:25,350 --> 00:32:28,220
so therefore we talk about

358
00:32:28,230 --> 00:32:30,540
nine four and four minutes

359
00:32:30,560 --> 00:32:36,160
keep in mind we're focusing on the biochemical properties of the side chains because the

360
00:32:36,160 --> 00:32:39,490
central backbone of the of the polypeptide

361
00:32:39,530 --> 00:32:44,630
and this article is defined quite clearly areas central backbone using

362
00:32:44,670 --> 00:32:46,810
quite repeating structure

363
00:32:46,950 --> 00:32:52,420
NCC NCC NCC this is invariant

364
00:32:52,500 --> 00:32:56,920
what what changes what defines the biochemical

365
00:32:56,940 --> 00:32:59,300
attributes of this all the time

366
00:32:59,350 --> 00:33:04,860
or a polypeptide are the identities of the which again are are plotted on this

367
00:33:04,860 --> 00:33:07,540
particular graph to have a different version in your book

368
00:33:07,550 --> 00:33:09,320
to the right

369
00:33:09,360 --> 00:33:13,470
you see we have the proton metal group vale

370
00:33:13,490 --> 00:33:16,400
lucene and isoleucine

371
00:33:16,450 --> 00:33:19,790
and the differences between this suggests these are all quite

372
00:33:22,680 --> 00:33:30,930
quite similar to the propane and and the that we talked about last time relaxing

373
00:33:30,930 --> 00:33:34,040
then say these are quite hydrophobic side

374
00:33:34,130 --> 00:33:35,290
and as such

375
00:33:35,300 --> 00:33:37,300
if were polypeptide

376
00:33:37,390 --> 00:33:38,580
we can imagine

377
00:33:38,580 --> 00:33:43,280
it's an adventure start let's hope the presentation will be smoother

378
00:33:43,300 --> 00:33:48,540
i'd like to thank the organisers for inviting me like talk about the recent work

379
00:33:48,540 --> 00:33:55,650
on polyhedral approximation is convex optimisation we're basically we have perhaps difficult optimisation problem and

380
00:33:55,650 --> 00:34:01,400
we make polyhedral approximations piecewise linear approximations to solve the cost functions with some of

381
00:34:01,400 --> 00:34:05,120
the constraints so as to get an easier problem and then have to get the

382
00:34:05,120 --> 00:34:06,690
solution to these problems

383
00:34:06,830 --> 00:34:13,240
we define the approximation and in the end we converge to the solution

384
00:34:13,380 --> 00:34:15,240
so my

385
00:34:15,250 --> 00:34:21,730
i'd like to talk about a flexible and unified framework for polyhedral approximation

386
00:34:21,740 --> 00:34:27,070
which includes the classical methods that i'm sure you know the cutting plane method which

387
00:34:27,070 --> 00:34:32,000
involves out linear decision from below and simplicity composition

388
00:34:32,100 --> 00:34:36,560
which involves in real linear innovation from within

389
00:34:36,570 --> 00:34:39,930
so these methods can classical methods are part of this framework

390
00:34:39,980 --> 00:34:44,770
but there are new methods that included in new verges or extensions of the old

391
00:34:45,640 --> 00:34:47,640
of the old methods

392
00:34:47,660 --> 00:34:50,440
and the vehicle for this is duality

393
00:34:50,470 --> 00:34:52,200
and conjugacy

394
00:34:52,250 --> 00:34:57,860
it's well known that in the in other linear station are connected by conjugacy

395
00:34:57,880 --> 00:34:59,380
if you cover function

396
00:34:59,390 --> 00:35:03,640
convex and you consider an outer linear decision by subgradients

397
00:35:03,770 --> 00:35:08,640
r and consider the conjugate function of this which i call h

398
00:35:10,960 --> 00:35:16,050
conjugate of the outer linear decision is an intermediate station

399
00:35:16,060 --> 00:35:19,440
for the break points correspond to the subgradients here

400
00:35:19,530 --> 00:35:24,220
and anniversary from one innovation we obtain an outer linear position

401
00:35:24,270 --> 00:35:25,360
where the

402
00:35:25,530 --> 00:35:30,640
the the slopes here determine the points of of contact

403
00:35:30,660 --> 00:35:36,030
so this is known but how exactly in and out of the notation is connected

404
00:35:36,030 --> 00:35:41,470
not make clear i'm going to explain that in in my talk

405
00:35:41,520 --> 00:35:42,610
the vehicle

406
00:35:42,610 --> 00:35:45,800
is a form of

407
00:35:45,810 --> 00:35:52,770
i a flexible and brought form of convex programming called extended one traffic programming

408
00:35:52,790 --> 00:35:58,300
here the vector x of optimisation involves components x one x two x m

409
00:35:58,320 --> 00:36:04,520
in the cost function is additive involves components and each component depends of f

410
00:36:05,110 --> 00:36:07,700
depends on the corresponding component of x

411
00:36:07,710 --> 00:36:12,360
in the f i here extended real valued convex functions

412
00:36:12,420 --> 00:36:15,930
and s is the subspace

413
00:36:15,950 --> 00:36:18,420
now this problem has

414
00:36:18,430 --> 00:36:20,770
a dual that has the same form

415
00:36:20,770 --> 00:36:22,670
because this form here

416
00:36:22,710 --> 00:36:24,300
the valuable so why

417
00:36:24,300 --> 00:36:27,510
otherwise leave in the orthogonal subspace to s

418
00:36:27,520 --> 00:36:29,300
and the edges are

419
00:36:29,320 --> 00:36:34,930
the conjugate functions of the full symmetry between the two dual problems

420
00:36:34,950 --> 00:36:36,960
the primal and the dual

421
00:36:36,960 --> 00:36:42,420
and the algorithmic idea which my framework is based

422
00:36:42,450 --> 00:36:46,800
two in the linear i some of these functions that are linear in some of

423
00:36:46,800 --> 00:36:49,960
these functions leave some other functions

424
00:36:49,990 --> 00:36:51,300
some other terms

425
00:36:52,830 --> 00:36:53,830
and then

426
00:36:53,840 --> 00:36:56,010
so the corresponding

427
00:36:56,020 --> 00:37:00,260
polyhedral approximated extended monodromy programming problem

428
00:37:00,270 --> 00:37:06,650
and we find the linear decision by using duality and the interplay between these two

429
00:37:06,700 --> 00:37:11,820
now the features of it out station in this framework is their first of combine

430
00:37:11,930 --> 00:37:13,830
the same algorithm

431
00:37:13,920 --> 00:37:18,990
these may involve some that in some of the other simultaneously

432
00:37:19,040 --> 00:37:23,700
their roles are reversed in the dual problem because of the conjugacy involved here

433
00:37:25,920 --> 00:37:29,370
i was thinking be apply to the prime or the book but

434
00:37:29,490 --> 00:37:34,260
the two algorithms are mathematically equivalent and basically to do all faces of the same

435
00:37:38,860 --> 00:37:44,760
i published a paper recently on the duality aspects of the EMP formulation

436
00:37:44,990 --> 00:37:48,170
the material is going to be in the text because i'm very

437
00:37:48,180 --> 00:37:50,200
in this work was motivated

438
00:37:50,210 --> 00:37:54,720
by an application machine learning some colleagues at the university of helsinki

439
00:37:54,750 --> 00:37:56,900
jane you and you will see

440
00:37:58,270 --> 00:38:00,180
it's still in progress

441
00:38:00,460 --> 00:38:04,690
in that application so that you can make the connection to machine learning

442
00:38:04,700 --> 00:38:07,520
we have a cost function that's of this form

443
00:38:07,530 --> 00:38:10,820
as of x x is the optimisation variables

444
00:38:10,870 --> 00:38:13,390
are so that is the regularisation term

445
00:38:13,470 --> 00:38:16,320
and here we have a set of functions

446
00:38:16,810 --> 00:38:18,460
each one

447
00:38:18,510 --> 00:38:21,020
depends on x

448
00:38:21,030 --> 00:38:23,520
in corresponds to

449
00:38:23,530 --> 00:38:28,390
a block of data about of data so we have lots and lots of data

450
00:38:28,440 --> 00:38:34,100
this functions here not application of polyhedral but very complicated because they correspond to complicated

451
00:38:34,100 --> 00:38:38,320
batches of data and they are very difficult to deal with

452
00:38:38,330 --> 00:38:40,830
so there are amenable to simplification

453
00:38:40,830 --> 00:38:44,010
by outer or inner approximation

454
00:38:44,020 --> 00:38:48,440
so this components below the point where they some regularisation function which is not linear

455
00:38:48,440 --> 00:38:50,270
ice or linear

456
00:38:50,330 --> 00:38:52,960
and that's the problem that we had

457
00:38:53,100 --> 00:38:55,840
and we look at the the

458
00:38:55,880 --> 00:38:59,340
do all of this problem and apply

459
00:38:59,390 --> 00:39:04,980
simplicial decomposition which is in early initiation do correspond to other linear decision of the

460
00:39:04,980 --> 00:39:06,770
primal and the

461
00:39:07,830 --> 00:39:13,340
it's a challenging problem in the results have been promising so far

462
00:39:13,390 --> 00:39:18,580
i'll come back to this sum to this attitude cost functions a later

463
00:39:18,630 --> 00:39:22,390
so here is the outline of my talk like to talk about what kind of

464
00:39:22,390 --> 00:39:25,350
approximation in general give some terminology

465
00:39:25,400 --> 00:39:30,900
review existing methodologies particularly in the area of cutting plane its implicit decomposition methods

466
00:39:31,080 --> 00:39:34,620
then i'm going to introduce extended when proper programming

467
00:39:34,700 --> 00:39:39,950
the duality theory in biology this is the central point of the story and then

468
00:39:39,950 --> 00:39:42,270
we discuss special cases of the algorithm

469
00:39:42,290 --> 00:39:46,380
how the classical methods are obtained from it and how you can also obtain new

470
00:39:46,380 --> 00:39:49,440
methods in this way

471
00:39:49,520 --> 00:39:57,580
OK let me remind you the definition of subgradient of an extended

472
00:39:57,620 --> 00:40:02,660
real valued convex function is a vector y my subgradients are going to be wise

473
00:40:02,660 --> 00:40:05,750
and my primal variables are going to be ex

474
00:40:05,770 --> 00:40:09,450
so for a point x is a subgradient is one for which

475
00:40:09,460 --> 00:40:13,680
this is a linear function of z lies below

476
00:40:15,220 --> 00:40:17,680
f four rosie

477
00:40:17,690 --> 00:40:21,690
and the set of all subgradients is called the subdifferential is denoted by the partial

478
00:40:21,690 --> 00:40:23,340
f of x

479
00:40:23,400 --> 00:40:29,270
in the graphic interpretation is that the subgradient can be identified with unknown vertical supporting

480
00:40:29,270 --> 00:40:32,230
hyperplane to the epigraph

481
00:40:32,250 --> 00:40:34,250
of this convex functions

482
00:40:34,340 --> 00:40:38,200
so you have a slow why i call them slopes even though they are subgradients

483
00:40:38,270 --> 00:40:42,700
and you fit a hyper plane that slope to the epigraph and

484
00:40:46,020 --> 00:40:51,010
any slope like this the substrate of the corresponding point of contact

485
00:40:51,020 --> 00:40:56,080
so the subgradient why the subgradient at the point x where the hyperplane that should

486
00:40:56,090 --> 00:41:00,630
be happy

487
00:41:00,660 --> 00:41:02,630
now the linear decision

488
00:41:02,650 --> 00:41:06,260
corresponds to approximating the epigraph of functions

489
00:41:07,160 --> 00:41:10,120
subgradients the maximum of linear

490
00:41:10,270 --> 00:41:12,850
a function is defined by subgradients

491
00:41:12,870 --> 00:41:15,890
so we have a number of points x zero

492
00:41:15,910 --> 00:41:18,210
up to xk

493
00:41:18,270 --> 00:41:22,140
and we have a subgradient at these points otherwise

494
00:41:22,150 --> 00:41:25,520
in each one of those is the function like that

495
00:41:25,620 --> 00:41:28,910
and we take the maximum of those in that defines

496
00:41:28,930 --> 00:41:36,720
o point here that all that's the general idea of to linear section

497
00:41:37,580 --> 00:41:43,450
and then you should corresponds to approximation by subgradient in a linear decision corresponds to

498
00:41:43,450 --> 00:41:46,250
approximation by convex hulls

499
00:41:47,520 --> 00:41:48,790
the convex hull

500
00:41:49,590 --> 00:41:52,450
four points that in an approximate

501
00:41:52,450 --> 00:41:53,740
is the sum of all that

502
00:41:54,210 --> 00:41:54,560
we might

503
00:41:56,890 --> 00:41:58,680
so after time capital city

504
00:42:00,250 --> 00:42:02,470
this the wrong at the time

505
00:42:04,020 --> 00:42:06,110
is a similar need

506
00:42:09,420 --> 00:42:09,960
plus one

507
00:42:10,580 --> 00:42:14,380
well minus one or it could be zero if we do reject any where we are

508
00:42:15,710 --> 00:42:16,560
let's start with

509
00:42:17,540 --> 00:42:19,410
in the middle and were not doing any

510
00:42:19,990 --> 00:42:22,410
let's actually neglect wall made life

511
00:42:23,420 --> 00:42:24,620
easy and the of

512
00:42:26,730 --> 00:42:29,520
and then there are only the first one one variables

513
00:42:31,320 --> 00:42:32,270
and we're interested in

514
00:42:33,150 --> 00:42:34,680
the variance developed at

515
00:42:36,740 --> 00:42:37,540
well there is

516
00:42:38,140 --> 00:42:39,680
polytunnel are interested in

517
00:42:40,490 --> 00:42:41,330
how wide

518
00:42:41,900 --> 00:42:44,630
the region is look the very x

519
00:42:46,210 --> 00:42:48,040
average about red

520
00:42:50,830 --> 00:42:55,450
the fact that the sum of independent random variables and so at so

521
00:42:56,200 --> 00:42:58,990
the bank at the sum of the variances

522
00:43:00,130 --> 00:43:01,160
i that's

523
00:43:02,190 --> 00:43:05,640
take a single step is performed by one that means the value

524
00:43:06,080 --> 00:43:08,680
one when was all these things i want

525
00:43:09,560 --> 00:43:10,760
also the variance

526
00:43:13,510 --> 00:43:13,920
is he

527
00:43:20,870 --> 00:43:21,840
if you want

528
00:43:23,340 --> 00:43:24,760
the typical distance you've got

529
00:43:26,290 --> 00:43:27,170
be elsewhere

530
00:43:28,870 --> 00:43:29,710
then you need

531
00:43:34,770 --> 00:43:36,230
to run the chain time

532
00:43:39,310 --> 00:43:44,030
that's a long square root and i want show you how this scaling in general

533
00:43:44,780 --> 00:43:45,310
in general

534
00:43:46,340 --> 00:43:47,920
in that case one one

535
00:43:48,530 --> 00:43:53,610
you get what i want know what the mean squared what he at once

536
00:43:55,030 --> 00:43:56,130
the equal

537
00:43:57,670 --> 00:43:59,080
the key element of

538
00:44:00,570 --> 00:44:02,520
all right but not you scaling

539
00:44:03,180 --> 00:44:07,440
it's getting quadratically with the ratio of five they live there

540
00:44:09,180 --> 00:44:09,870
and so

541
00:44:10,410 --> 00:44:12,180
it's not that this example

542
00:44:13,350 --> 00:44:18,210
but think is a hundred or a hundred or something like that to be the answer question

543
00:44:19,670 --> 00:44:20,270
the question right

544
00:44:21,660 --> 00:44:23,230
and now the first one is maybe

545
00:44:24,280 --> 00:44:25,700
one of those not quite clear

546
00:44:28,000 --> 00:44:29,670
so let's be running things

547
00:44:32,690 --> 00:44:34,630
so what iterations are the

548
00:44:35,590 --> 00:44:36,460
six iterations

549
00:44:37,240 --> 00:44:38,200
eighty iterations

550
00:44:39,600 --> 00:44:40,640
after a hundred iterations

551
00:44:41,520 --> 00:44:46,190
we have three wall so in that particular run hundred was very good yes

552
00:44:47,310 --> 00:44:47,980
i keep on going

553
00:44:48,870 --> 00:44:52,020
non-blocking again when everybody again was made in

554
00:44:52,940 --> 00:44:53,380
o them

555
00:44:53,840 --> 00:44:55,290
right we weren't allowed

556
00:44:55,850 --> 00:44:57,580
if you going to the right

557
00:44:58,920 --> 00:45:02,110
reported it directly back hitting the same ball

558
00:45:03,060 --> 00:45:03,670
three hundred

559
00:45:04,870 --> 00:45:05,440
four hundred

560
00:45:06,010 --> 00:45:06,750
four hundred forty

561
00:45:08,000 --> 00:45:09,750
and then we got a proposal

562
00:45:10,310 --> 00:45:12,080
at the four hundred iterations

563
00:45:13,380 --> 00:45:18,740
it unreasonably in agreement with what you said and the reason that one four hundred

564
00:45:19,240 --> 00:45:20,110
three notable

565
00:45:22,430 --> 00:45:26,680
that's rule from back-of-the-envelope methods as

566
00:45:27,460 --> 00:45:28,600
what looks like that

567
00:45:29,250 --> 00:45:30,020
we keep on running

568
00:45:30,890 --> 00:45:33,380
come back again and again and again

569
00:45:34,240 --> 00:45:34,920
and maybe

570
00:45:36,500 --> 00:45:40,010
four hundred iterations later was still available and then we have a around

571
00:45:40,860 --> 00:45:41,920
program the outside

572
00:45:42,290 --> 00:45:44,710
nine hundred of the four hundred iterations

573
00:45:45,970 --> 00:45:46,450
five hundred

574
00:45:47,040 --> 00:45:48,400
well but the thing that this will

575
00:45:50,990 --> 00:45:53,850
so that's what happens when you run the same

576
00:45:55,110 --> 00:45:55,940
so it takes

577
00:45:56,780 --> 00:45:58,350
thousands of iterations

578
00:45:58,940 --> 00:46:00,760
you get good independent points

579
00:46:04,620 --> 00:46:10,150
what other way visualizing this is to imagine that histogram where we have been during the simulation

580
00:46:10,660 --> 00:46:12,650
so here's the histogram what iterations

581
00:46:13,200 --> 00:46:15,200
eighty hundred and no

582
00:46:15,920 --> 00:46:17,820
this is the simulation we just did

583
00:46:19,920 --> 00:46:27,120
so at all hundred iterations by the man hit the wall still histogram where we being

584
00:46:27,420 --> 00:46:27,880
it's quite

585
00:46:28,250 --> 00:46:29,790
it will be it'll be and i'm even

586
00:46:31,350 --> 00:46:35,840
so this is the point at which you might say i've actually got one independent samples from this

587
00:46:37,850 --> 00:46:39,440
about five hundred iterations what

588
00:46:42,690 --> 00:46:45,030
so that's the wrong i'm not saying

589
00:46:45,490 --> 00:46:49,640
that when you run a metropolis like this you should throw away all the point

590
00:46:49,680 --> 00:46:53,020
while one is the where we collect the points

591
00:46:54,540 --> 00:47:00,350
effective number independent we've got running along with the operation is probably only one of

592
00:47:01,680 --> 00:47:02,450
just one pass

593
00:47:03,740 --> 00:47:04,680
what i found that

594
00:47:04,680 --> 00:47:07,130
comparison in the degree distribution

595
00:47:07,270 --> 00:47:13,040
so suppose we had a graph that then we know that the average degree is

596
00:47:13,040 --> 00:47:17,160
around three point three and we want to be able to pick pick another random

597
00:47:17,160 --> 00:47:20,640
and guess what this degree was well we might say that

598
00:47:20,660 --> 00:47:25,800
we might assume that it follows some surplus on gaussians distribution and that the

599
00:47:25,810 --> 00:47:29,260
at that the average degree is equivalent to the motor

600
00:47:29,610 --> 00:47:33,960
the mode of the degree distribution but this is actually not the case in real

601
00:47:33,960 --> 00:47:37,010
graphs the the motives one most

602
00:47:37,030 --> 00:47:40,160
most nodes have very small small degree

603
00:47:40,170 --> 00:47:48,160
and so the mean is meaningless and because we have a very skewed distribution

604
00:47:48,170 --> 00:47:54,270
but what exact pattern degreed is the real graphs follow

605
00:47:54,330 --> 00:47:55,670
we find that

606
00:47:55,680 --> 00:47:58,150
most real graphs to display power law degree

607
00:47:58,160 --> 00:48:02,150
the degree distribution and we can measure this with the rank exponent are if we

608
00:48:02,150 --> 00:48:06,880
took the if we rank the degree of of all nodes in the network like

609
00:48:06,900 --> 00:48:08,910
the top the one with

610
00:48:08,930 --> 00:48:11,790
pies can activity is ranked

611
00:48:12,010 --> 00:48:15,870
rank one and so on in the

612
00:48:15,950 --> 00:48:18,020
then we would follow power law with

613
00:48:18,080 --> 00:48:20,760
with in this case an exponent minus

614
00:48:20,770 --> 00:48:26,100
o point eight two in this in internet domains they find the highest

615
00:48:26,110 --> 00:48:30,860
the highest can connected one is eighty in teaneck is IBM and so on and

616
00:48:30,870 --> 00:48:32,410
while most

617
00:48:33,080 --> 00:48:37,810
most have very very low conductivity

618
00:48:37,840 --> 00:48:43,540
this is this is all in log log scale of course

619
00:48:43,590 --> 00:48:47,310
so does does have the power of hold over time and

620
00:48:47,330 --> 00:48:48,560
do they hold on

621
00:48:48,620 --> 00:48:50,980
the graphs and domains

622
00:48:51,000 --> 00:48:53,130
the answer to both these questions is yes

623
00:48:53,140 --> 00:48:56,910
for that siganos et all showed

624
00:48:56,920 --> 00:49:01,840
showed that on the internet domain this rank exponent hold constant and

625
00:49:01,860 --> 00:49:05,380
this is also o so also shown on other graphs in domains that they other

626
00:49:05,380 --> 00:49:10,830
graphs also displayed power laws

627
00:49:10,850 --> 00:49:16,700
so here's here's applauded the rank exponent are over time it remains confident about point

628
00:49:16,730 --> 00:49:18,390
point eight two

629
00:49:18,930 --> 00:49:20,700
this is over

630
00:49:20,720 --> 00:49:24,270
over series of several months

631
00:49:24,280 --> 00:49:26,510
this is somewhat surprising

632
00:49:26,530 --> 00:49:29,580
because we might expect that

633
00:49:29,600 --> 00:49:30,430
but the

634
00:49:30,450 --> 00:49:33,040
hubs made has made change in

635
00:49:33,050 --> 00:49:40,870
how they attract links but is actually pretty consistent power law

636
00:49:40,880 --> 00:49:46,010
and this is also shown in the peer-to-peer topology topology joe jovanovic and all showed

637
00:49:47,900 --> 00:49:52,840
the degree of the gnutella network also follow a power law

638
00:49:52,850 --> 00:49:57,130
and richardson and domingos showed the epinions com also

639
00:49:57,140 --> 00:50:02,200
also had the power law degree distribution and out degree

640
00:50:03,400 --> 00:50:05,880
so next going to look at the

641
00:50:06,290 --> 00:50:11,710
the patterns and connect components in real graphs

642
00:50:11,860 --> 00:50:16,710
so the basic graph generator is an artist and graph which means that for and

643
00:50:16,710 --> 00:50:20,880
we we pick n vertices and we just decided to draw to connect any two

644
00:50:20,880 --> 00:50:25,460
nodes in the network with probability p this is some of the first study on

645
00:50:26,010 --> 00:50:28,620
the probably be for a random graphs

646
00:50:28,630 --> 00:50:30,300
and they had it

647
00:50:30,350 --> 00:50:35,410
this editor new renyi random graph has many provable properties including including the emergence of

648
00:50:35,410 --> 00:50:37,620
and that the giant connected component

649
00:50:37,700 --> 00:50:40,720
the degree distribution does not

650
00:50:40,730 --> 00:50:45,110
it does not reflect that of real graphs but this property of giant connected component

651
00:50:47,270 --> 00:50:51,700
that is that we find that nearly all networks have a giant connected component emerge

652
00:50:51,720 --> 00:50:54,720
and it was also shown in some recent work by

653
00:50:55,220 --> 00:50:56,670
kumar et al

654
00:50:56,700 --> 00:51:01,210
the social media graphs often have middle region they did some experiments with flickr and

655
00:51:01,210 --> 00:51:04,560
with the other three sixty groups and they show that there is the middle region

656
00:51:05,450 --> 00:51:08,130
not not giant but

657
00:51:08,130 --> 00:51:11,740
it's component sizes larger than one

658
00:51:11,780 --> 00:51:16,580
this the behaviour of this was that they rarely have really connected to each other

659
00:51:16,580 --> 00:51:21,580
to form a larger components they would usually connect into the gigantic connected component or

660
00:51:21,580 --> 00:51:25,960
take on singletons

661
00:51:27,100 --> 00:51:32,900
so now now introduce some properties of static graphs and but in an active research

662
00:51:32,900 --> 00:51:36,490
area is looking at the evolution of graphs over time and it's very useful for

663
00:51:36,490 --> 00:51:42,240
some the applications that will talk talk about later

664
00:51:42,280 --> 00:51:46,340
so how do graphs of graphs evolve and we know that the degree exponent seems

665
00:51:46,340 --> 00:51:51,230
constant we show have constant rank exponent

666
00:51:51,250 --> 00:51:53,350
for degree distribution

667
00:51:53,380 --> 00:52:00,630
but are there any other consistent patterns so we can identify

668
00:52:00,640 --> 00:52:03,490
so what about the evolution of diameter we have the

669
00:52:03,490 --> 00:52:08,720
so some prior analysis some parallel like graphs hence the diameter slowly increases with time

670
00:52:08,720 --> 00:52:12,570
that if you if they took random graphs that would generate power laws with the

671
00:52:12,570 --> 00:52:16,990
diameter would also tend to tend to increase with log n log log n and

672
00:52:16,990 --> 00:52:19,680
i'm using citations as an example but of course you could do this with with

673
00:52:19,680 --> 00:52:24,990
anything else and then you have the infield predicates this is the predicate that does

674
00:52:24,990 --> 00:52:26,260
the segmentation

675
00:52:26,270 --> 00:52:29,600
it says this position in the citation is in this field

676
00:52:29,640 --> 00:52:33,260
like so you know this piece here is arthur or or whatever

677
00:52:33,350 --> 00:52:36,970
announcing field and some citation to the into resolution

678
00:52:37,040 --> 00:52:40,240
these formulas of the HMM

679
00:52:40,270 --> 00:52:42,140
what do they say

680
00:52:42,140 --> 00:52:45,970
well if you have this talk and in this position this positions in this field

681
00:52:46,010 --> 00:52:50,200
so this is the observation matrix word tokens are observations and fields

682
00:52:50,200 --> 00:52:51,990
i states

683
00:52:51,990 --> 00:52:56,370
now here's my transition matrix it says that if i'm in this field in this

684
00:52:56,370 --> 00:52:59,740
position then i'm in this field in the next position

685
00:52:59,760 --> 00:53:03,770
in fact in practice we actually don't need to build a complete matrix here we

686
00:53:03,770 --> 00:53:07,580
just want to capture the regularity that usually stay in the same field as you

687
00:53:07,580 --> 00:53:10,990
go along and that's what i'm actually doing it but because just as easily have

688
00:53:10,990 --> 00:53:12,760
put on the full hmm

689
00:53:12,810 --> 00:53:14,700
now notice

690
00:53:14,720 --> 00:53:17,140
in most information extraction problems

691
00:53:17,140 --> 00:53:22,100
most places in the source don't correspond to any field

692
00:53:22,120 --> 00:53:25,950
and what people do for that is they create this artificial other state

693
00:53:25,970 --> 00:53:27,410
that's not the field

694
00:53:27,430 --> 00:53:30,790
but then you have to model the correlations between the various things and you know

695
00:53:30,790 --> 00:53:33,790
this is very messy because is a pile of stuff

696
00:53:33,810 --> 00:53:35,830
in alchemy you actually need to do that

697
00:53:35,850 --> 00:53:39,220
only the only need to do is you actually allow

698
00:53:40,010 --> 00:53:44,120
the notice i put no exclamation mark you

699
00:53:44,140 --> 00:53:46,950
which means the position might not be in any field

700
00:53:47,030 --> 00:53:51,160
position to not be in any field and what i'm doing here is just understanding

701
00:53:51,160 --> 00:53:54,930
of a rule that says well you can be more than one field once

702
00:53:54,950 --> 00:53:57,260
so if you are you not then you

703
00:53:57,390 --> 00:53:58,740
and so forth

704
00:53:59,470 --> 00:54:02,530
so this system does information extraction

705
00:54:02,540 --> 00:54:06,660
no sorry these three forms of the HMM for information extraction and this one was

706
00:54:06,660 --> 00:54:10,560
here i just the form that we saw before to the resolution except that they

707
00:54:10,560 --> 00:54:13,990
now start from this predicates instead of the predicates that had before

708
00:54:14,240 --> 00:54:19,850
so this the complete information extraction system in just you know seven short formulas that

709
00:54:19,850 --> 00:54:21,100
fit on the slide

710
00:54:23,100 --> 00:54:27,040
as i said the introduction part is actually fairly state-of-the-art

711
00:54:27,110 --> 00:54:29,870
the information extraction part is actually not that great

712
00:54:29,890 --> 00:54:32,470
and the reason why it's not that great is is that it's not very good

713
00:54:32,470 --> 00:54:34,580
at detecting field boundaries

714
00:54:34,580 --> 00:54:39,810
it's very propagating fields and identifying correlations between woods and fields but placing the boundaries

715
00:54:39,810 --> 00:54:41,310
exactly is one of the challenge

716
00:54:41,370 --> 00:54:45,830
and people know this information extraction what it is like to define rules explicitly to

717
00:54:45,830 --> 00:54:47,830
predict field boundaries

718
00:54:47,870 --> 00:54:51,930
but combining this with an HMM is not you know very straightforward

719
00:54:51,950 --> 00:54:54,220
alchemy however you can do that very easily

720
00:54:54,310 --> 00:54:57,010
for example in citations

721
00:54:57,030 --> 00:55:00,530
there's a very good predictor of the field band which is the period

722
00:55:00,560 --> 00:55:05,870
most few in citation separated by periods so i can just add this one precondition

723
00:55:05,870 --> 00:55:07,330
to this rule

724
00:55:07,330 --> 00:55:12,270
it says that nearby positions like to be in the same field as long as

725
00:55:12,270 --> 00:55:15,040
one of the of money is not the case that one of them is the

726
00:55:15,850 --> 00:55:21,390
so if i have appeared that stops the propagation of fields this one change very

727
00:55:21,390 --> 00:55:24,600
easy to make it makes a big difference in the accuracy in fact with this

728
00:55:24,600 --> 00:55:29,680
one change you actually get something that is a fairly state-of-the-art into resolution system sorry

729
00:55:30,220 --> 00:55:32,060
citation matching system

730
00:55:32,120 --> 00:55:38,560
like what's very

731
00:55:38,590 --> 00:55:40,310
the good question so

732
00:55:41,830 --> 00:55:44,950
what happens in your citations right is that

733
00:55:44,950 --> 00:55:50,140
periods appears separators between fields but they also appear as abbreviations of

734
00:55:50,970 --> 00:55:55,870
well this is why we need a weighted rule as opposed to the tremendous decline

735
00:55:55,870 --> 00:55:58,950
because i'm going to learn the wait for the rule that a function of how

736
00:55:58,950 --> 00:56:01,450
often you get each case

737
00:56:01,470 --> 00:56:04,040
so what's going to happen is that it's going to

738
00:56:04,040 --> 00:56:08,140
ten down propagation but not to zero because it could be and often

739
00:56:08,180 --> 00:56:10,620
but what you what you really want to do is you want to put in

740
00:56:10,620 --> 00:56:15,260
that knowledge right that this thing that appears in are you know letters within the

741
00:56:15,370 --> 00:56:19,240
with full stops are probably initials you can model that says that

742
00:56:19,260 --> 00:56:20,450
but in that case

743
00:56:20,470 --> 00:56:22,540
it is actually an exception to this rule

744
00:56:22,580 --> 00:56:24,840
in fact this is one of the things that we do in this paper that

745
00:56:24,840 --> 00:56:28,220
just came out in tripoli two thousand seven you know we actually wrote a bunch

746
00:56:28,220 --> 00:56:31,930
of stuff like this that we know about you know citations then again there's a

747
00:56:31,930 --> 00:56:35,080
lot of the fun of working with something like companies that you can just right

748
00:56:35,640 --> 00:56:38,120
the things you know about the domain and that you know sort of like of

749
00:56:38,120 --> 00:56:40,060
which translates into better models

750
00:56:40,700 --> 00:56:47,470
and this is the state-of-the-art a model

751
00:56:47,490 --> 00:56:51,370
the full one that we have in this paper citation matching and like the standard

752
00:56:51,370 --> 00:56:56,120
datasets and it's still pretty simple MLN we've only about you know a couple dozen

753
00:56:56,120 --> 00:56:58,620
formulas for

754
00:57:00,200 --> 00:57:03,330
so see how the information extraction

755
00:57:03,350 --> 00:57:07,930
not really because you don't have to wait until the fields and so on and

756
00:57:08,510 --> 00:57:09,600
in order to me

757
00:57:09,620 --> 00:57:14,390
well right now but let me clarify

758
00:57:14,390 --> 00:57:18,950
this because this is the complete information extraction system but like an information extraction system

759
00:57:18,950 --> 00:57:23,220
it needs the data to learn the ways some sort

760
00:57:23,220 --> 00:57:29,510
raise so we need for to to actually made that clearer right so

761
00:57:29,530 --> 00:57:32,330
in order to train this right any the database

762
00:57:32,490 --> 00:57:33,850
on the database

763
00:57:33,870 --> 00:57:37,100
is going to be groundings of these predicates that this is basically going to be

764
00:57:39,310 --> 00:57:41,220
like these datasets are

765
00:57:41,240 --> 00:57:44,930
you have at the base of like you know citations and then you know this

766
00:57:44,930 --> 00:57:48,760
was after this was you know then you these two authors with the same in

767
00:57:48,760 --> 00:57:52,620
these to fields with the same from that you learn the weights for the samoan

768
00:57:52,680 --> 00:57:56,140
and then this similarly come up with a new database and like the standard machine

769
00:57:56,140 --> 00:57:58,890
learning so

770
00:57:58,910 --> 00:58:02,620
so in love this information extraction

771
00:58:04,450 --> 00:58:09,350
so you try to go the weights on these particular one right

772
00:58:10,890 --> 00:58:12,910
there are some new

773
00:58:15,240 --> 00:58:19,290
we entities that

774
00:58:20,760 --> 00:58:22,290
the CIA

775
00:58:22,290 --> 00:58:27,430
the biggest i'm doing it myself one of the biggest another because i've seen the

776
00:58:27,430 --> 00:58:29,510
biggest as

777
00:58:29,540 --> 00:58:34,030
so this is any that is that sort of a different schools here as well

778
00:58:34,030 --> 00:58:39,950
as the learning machine learning now specifically the thing is that there is

779
00:58:39,970 --> 00:58:43,290
good question and the answer is it's up to you what you wanted to go

780
00:58:43,290 --> 00:58:46,790
on and not the way you make it go on is that you include your

781
00:58:46,790 --> 00:58:51,060
original things like you know the thing this is not in your new inference

782
00:58:51,060 --> 00:58:54,100
and that's a known fact and you can infer from that

783
00:58:54,330 --> 00:58:56,490
for example certain records of the set

784
00:58:56,490 --> 00:58:58,430
and you know in general you want to use them

785
00:58:58,680 --> 00:59:02,010
there is also this tricky issues that when you have you know non IID data

786
00:59:02,640 --> 00:59:05,510
your training in your tests may not be independent

787
00:59:05,530 --> 00:59:09,140
so for england although actually have to be careful but i do that but for

788
00:59:09,140 --> 00:59:12,830
practical purposes yes you one include information and you know you probably get a lot

789
00:59:12,830 --> 00:59:14,040
of mileage out of it

790
00:59:15,700 --> 00:59:16,720
OK so

791
00:59:16,740 --> 00:59:18,540
let's get even more ambitious

792
00:59:19,200 --> 00:59:25,060
you know why i just do segmentation right let's actually do passing of the input

793
00:59:25,080 --> 00:59:27,040
because to really doing in real

794
00:59:27,040 --> 00:59:32,850
two to quickly would find at least a fixed percentage of negative

795
00:59:32,860 --> 00:59:34,110
throw them away

796
00:59:34,130 --> 00:59:37,480
and then everything else is just passes on to the next next states to look

797
00:59:38,280 --> 00:59:42,450
so all the time if you go down the change rejecting some things which are

798
00:59:42,550 --> 00:59:44,660
initially relatively easy

799
00:59:44,680 --> 00:59:48,720
things and and further down the classifiers tend to be more complex and you have

800
00:59:48,720 --> 00:59:50,430
to do more things

801
00:59:50,450 --> 00:59:56,610
the features here again is how wavelets in fact these ones are rectangular so there's

802
00:59:56,610 --> 00:59:59,330
this fact many different rectangular

803
00:59:59,330 --> 01:00:04,820
aspirations positions that can have so there's a very large set of features things trained

804
01:00:05,050 --> 01:00:08,520
in each of those features is treated as an individual weak classifiers

805
01:00:08,530 --> 01:00:12,860
for the for the think tank based weak classifier in each stage adaboost

806
01:00:13,770 --> 01:00:14,520
so a

807
01:00:14,540 --> 01:00:18,730
you can see the detections they can see the first two features the pulls this

808
01:00:18,730 --> 01:00:23,590
is very characteristic faced section kind of dark region around the eyes

809
01:00:23,930 --> 01:00:25,790
and the fact that the bright

810
01:00:25,840 --> 01:00:28,080
but are in the middle you know this is

811
01:00:29,050 --> 01:00:31,160
the most characteristic signal

812
01:00:31,190 --> 01:00:32,470
the faces

813
01:00:32,480 --> 01:00:35,530
and faces are actually relatively easy cluster take

814
01:00:35,540 --> 01:00:38,190
because of that frontal faces

815
01:00:38,500 --> 01:00:43,680
so all detectors whatever the features use basically have those could those two things the

816
01:00:44,550 --> 01:00:48,620
but as said yes i did was that it was good here

817
01:00:48,680 --> 01:00:53,640
well it's able to select the best of the large weekly which features

818
01:00:54,050 --> 01:00:57,130
and basically

819
01:00:57,160 --> 01:01:00,950
although the algorithm seems somewhat

820
01:01:00,970 --> 01:01:03,190
ad hoc or

821
01:01:03,320 --> 01:01:07,100
if you're not sure that the features are selected in the in the world to

822
01:01:07,190 --> 01:01:08,180
the classifier

823
01:01:08,200 --> 01:01:12,840
just select also features nevertheless does link to run small set of features which were

824
01:01:12,840 --> 01:01:16,930
relatively well so you can think of it more as feature selection method

825
01:01:17,070 --> 01:01:21,360
and is a classifier trained were equally is a feature selection method across the training

826
01:01:25,820 --> 01:01:28,870
and then you can do the same thing for pedestrian detection

827
01:01:28,950 --> 01:01:32,280
mister tate also involves no motion derivative

828
01:01:32,320 --> 01:01:34,710
i wanted the video that i can find the videos

829
01:01:34,780 --> 01:01:36,510
you can

830
01:01:36,510 --> 01:01:39,050
OK onto another type detector

831
01:01:39,200 --> 01:01:42,370
so this is a new orleans inspired detector

832
01:01:42,420 --> 01:01:43,450
the dates

833
01:01:43,470 --> 01:01:45,390
from the early nineties

834
01:01:45,630 --> 01:01:50,330
with standard eighteen t with support vector machines came out because they were doing it

835
01:01:50,330 --> 01:01:52,610
were well aware

836
01:01:52,620 --> 01:01:56,970
we're doing support vector machines well aware of this and these guys well aware of

837
01:01:57,010 --> 01:02:02,880
what machines but they kept the neural approach and the reason is that it works

838
01:02:03,250 --> 01:02:06,120
quite hard to train because the complex

839
01:02:06,130 --> 01:02:09,190
mister back propagation and things need to know what doing

840
01:02:09,210 --> 01:02:12,260
this approach is still giving

841
01:02:12,270 --> 01:02:15,090
competitive detectors with anything else

842
01:02:15,100 --> 01:02:16,180
we know about

843
01:02:16,200 --> 01:02:21,100
so the way that works says it's a neural network the new network the spatial

844
01:02:21,970 --> 01:02:26,910
which is convolutional so in fact what happens you take your image u

845
01:02:26,940 --> 01:02:30,040
run a bank filters of a given size it

846
01:02:30,050 --> 01:02:31,560
what you're going to learn

847
01:02:31,830 --> 01:02:37,350
and then you rectify those filters you run the second bank filters on the output

848
01:02:37,370 --> 01:02:38,860
again which is

849
01:02:38,900 --> 01:02:41,120
so on third fourth bank etcetera

850
01:02:41,350 --> 01:02:48,130
so this mimics the simple cell complex cell structure list of the v one

851
01:02:48,190 --> 01:02:51,120
part of the visual cortex

852
01:02:51,520 --> 01:02:56,590
is that the inspiration for it turns out that this actually works very well the

853
01:02:56,590 --> 01:03:00,330
conductivity changes as you go up so first of all it's rather local

854
01:03:00,330 --> 01:03:04,020
it tends to spread out so the final few stages of the global

855
01:03:04,040 --> 01:03:07,090
and we'll give you a class the class classification

856
01:03:07,110 --> 01:03:12,090
p and so here it's digital sensors ten different classes will output

857
01:03:12,110 --> 01:03:16,600
he trained by gradient descent one thing this thing needs very big training sets

858
01:03:16,930 --> 01:03:21,350
so this was trained on i think fifty thousand or something digits

859
01:03:21,650 --> 01:03:26,610
but in terms of an actual applications machine learning it's one of the earliest and

860
01:03:26,610 --> 01:03:30,780
still one of the most successful the system actually reads about ten percent of objects

861
01:03:30,780 --> 01:03:32,930
the persians united states

862
01:03:33,260 --> 01:03:36,320
it doesn't make too many mistakes so you can see here

863
01:03:36,330 --> 01:03:39,680
the kind of resistance to perturbations of noise

864
01:03:39,700 --> 01:03:41,940
changes in position and scale

865
01:03:41,950 --> 01:03:44,660
the system has you probably can't read the figures here

866
01:03:44,680 --> 01:03:46,310
which is the output of the system

867
01:03:46,320 --> 01:03:51,170
but it's getting things mostly right despite very very severe perturbations

868
01:03:58,330 --> 01:03:59,120
OK so

869
01:03:59,130 --> 01:04:01,150
another neuron detector

870
01:04:01,530 --> 01:04:03,850
kind of inspired by the previous one

871
01:04:03,930 --> 01:04:07,840
and this one trying to build an some rotation invariance to face detection

872
01:04:07,850 --> 01:04:09,340
and the way they did

873
01:04:09,340 --> 01:04:12,370
so this equals minus ng

874
01:04:12,380 --> 01:04:14,420
h two

875
01:04:14,430 --> 01:04:16,770
this is zero

876
01:04:16,790 --> 01:04:19,390
and so you see what you see here

877
01:04:19,460 --> 01:04:21,590
is exactly what you see here

878
01:04:21,640 --> 01:04:24,580
the two are identical

879
01:04:24,630 --> 01:04:27,060
so you could use work energy theorem

880
01:04:27,130 --> 01:04:31,510
or you can use the conservation of mechanical energy that makes no difference

881
01:04:31,640 --> 01:04:34,230
and so you know can calculate the maximum

882
01:04:34,250 --> 01:04:38,730
and for those of you who want some numbers i found that the maximum

883
01:04:38,740 --> 01:04:41,220
was lots minus seven

884
01:04:41,300 --> 01:04:43,230
o point four degrees

885
01:04:43,270 --> 01:04:45,410
you always get two angles

886
01:04:48,070 --> 01:04:52,730
and in radiance that because the mind is o point one three ratings

887
01:04:52,860 --> 01:04:57,230
you know the cosine of the angle is so always get away

888
01:04:57,240 --> 01:04:59,160
nothing you can do about it

889
01:04:59,290 --> 01:05:01,560
so now you can ask yourself the question

890
01:05:01,650 --> 01:05:02,840
what is phi

891
01:05:02,860 --> 01:05:05,090
if i is always a bit of a pain in the neck and is really

892
01:05:05,090 --> 01:05:06,940
not all that much physics five

893
01:05:07,040 --> 01:05:08,520
but i was sort of curious

894
01:05:08,530 --> 01:05:09,280
with these

895
01:05:09,290 --> 01:05:12,190
initial conditions what if i would be

896
01:05:12,190 --> 01:05:13,230
so that

897
01:05:13,240 --> 01:05:15,190
just take a quick look at that

898
01:05:15,230 --> 01:05:17,310
so if we want to know what

899
01:05:17,330 --> 01:05:19,670
we have to look at the initial condition that

900
01:05:19,670 --> 01:05:21,650
t equals zero

901
01:05:23,170 --> 01:05:24,680
velocity at point p is

902
01:05:24,700 --> 01:05:26,430
o point three

903
01:05:26,490 --> 01:05:28,390
in this direction

904
01:05:28,430 --> 01:05:31,550
and we know to fatah equals

905
01:05:31,640 --> 01:05:37,130
data zero and we know what data series that was the five degrees at point

906
01:05:37,180 --> 01:05:38,280
o nine

907
01:05:38,300 --> 01:05:40,700
radiance and so i'm going to substitute that

908
01:05:40,700 --> 01:05:42,340
in my solution

909
01:05:42,360 --> 01:05:44,640
so i don't equals zero

910
01:05:44,650 --> 01:05:47,010
i noticed they're equal status zero

911
01:05:47,030 --> 01:05:50,580
fatah zero i know the data zero is

912
01:05:50,610 --> 01:05:53,310
we just calculated with data maxis

913
01:05:53,370 --> 01:05:54,660
times the cosine

914
01:05:55,390 --> 01:05:57,220
t equals zero

915
01:05:57,220 --> 01:05:58,580
so our pop

916
01:05:58,640 --> 01:06:00,270
two angles of phi

917
01:06:00,330 --> 01:06:03,370
plus and minus five one

918
01:06:03,400 --> 01:06:06,630
always find the plus and minus sign because the cosine of the angle is the

919
01:06:06,630 --> 01:06:09,730
same as the cosine minus

920
01:06:09,810 --> 01:06:13,130
so now we have to find out which of the two it is

921
01:06:13,170 --> 01:06:14,590
by the way

922
01:06:14,610 --> 01:06:15,810
when you find

923
01:06:15,830 --> 01:06:17,230
data maximum

924
01:06:17,260 --> 01:06:20,440
because plaza mine o point one three iranians

925
01:06:20,500 --> 01:06:22,730
you could have picked a plus or minus

926
01:06:22,780 --> 01:06:24,690
i pick the plus

927
01:06:24,730 --> 01:06:28,000
if you want to pick the minus you would have found different facing

928
01:06:28,050 --> 01:06:29,840
but you can pick minus

929
01:06:29,890 --> 01:06:34,730
i just want to remind you that i picked plus whatever follows

930
01:06:34,750 --> 01:06:38,270
so now i have to take into account the

931
01:06:38,280 --> 01:06:40,400
the fact that at equals zero

932
01:06:40,420 --> 01:06:41,790
that i know the

933
01:06:44,270 --> 01:06:46,770
out of that committee but i take the

934
01:06:46,840 --> 01:06:49,070
relative of that equation

935
01:06:49,120 --> 01:06:50,750
there are so i get that

936
01:06:50,810 --> 01:06:53,230
the fate of the two

937
01:06:53,230 --> 01:06:57,770
which is the angular velocity in radians per second at any moment in time that

938
01:06:57,770 --> 01:07:00,510
we're going to evaluate it equal zero

939
01:07:00,560 --> 01:07:03,120
because miners omega

940
01:07:04,250 --> 01:07:07,230
the sign

941
01:07:07,400 --> 01:07:08,930
omega t

942
01:07:08,930 --> 01:07:09,960
let's fly

943
01:07:10,080 --> 01:07:13,950
we will evaluate it equal zero

944
01:07:13,990 --> 01:07:16,020
one of the fate of the t

945
01:07:16,070 --> 01:07:20,720
well the theory t is v divided by l

946
01:07:20,750 --> 01:07:22,620
this is to divided by l

947
01:07:22,630 --> 01:07:23,750
and is therefore

948
01:07:23,780 --> 01:07:25,220
plus o point three

949
01:07:25,220 --> 01:07:29,220
this plus because a zero angle is increasing

950
01:07:29,290 --> 01:07:31,260
so it is plus

951
01:07:31,270 --> 01:07:33,560
how do we know to be overwhelmed

952
01:07:33,610 --> 01:07:36,630
well remember we discussed before

953
01:07:37,710 --> 01:07:39,160
your changes

954
01:07:39,170 --> 01:07:43,240
angle by an amount p theta and if these are here

955
01:07:43,330 --> 01:07:45,040
i call that the

956
01:07:45,050 --> 01:07:46,730
and if the length is l

957
01:07:46,730 --> 01:07:49,770
and the definition of the data

958
01:07:49,910 --> 01:07:53,250
and in radiance is as divided by l

959
01:07:53,340 --> 01:07:59,510
if we divide both sides by dt which mathematicians cannot do physicists can

960
01:07:59,560 --> 01:08:02,080
then you get the theta DT

961
01:08:02,130 --> 01:08:03,820
equals the

962
01:08:03,840 --> 01:08:08,000
and that is the velocity divided by l so you see the theta DT

963
01:08:08,010 --> 01:08:09,940
is he divided by l

964
01:08:09,980 --> 01:08:12,470
so we now have the second equation

965
01:08:12,520 --> 01:08:13,360
we now

966
01:08:13,370 --> 01:08:16,060
console for sin phi

967
01:08:16,260 --> 01:08:18,060
give you again to angles

968
01:08:18,110 --> 01:08:21,150
the viewing angle phi two

969
01:08:21,990 --> 01:08:25,140
and gives you hundred eighty degrees minus fights

970
01:08:25,180 --> 01:08:28,270
they have the same value for sin phi

971
01:08:28,360 --> 01:08:30,310
but only one of these

972
01:08:30,380 --> 01:08:31,960
will be the same

973
01:08:32,040 --> 01:08:33,290
as one of these

974
01:08:33,370 --> 01:08:35,070
and that's the one that you pick

975
01:08:35,120 --> 01:08:36,440
and in my case

976
01:08:36,450 --> 01:08:39,260
before my value of o point one three

977
01:08:39,280 --> 01:08:40,410
i find then

978
01:08:40,420 --> 01:08:41,520
that's fine

979
01:08:41,540 --> 01:08:44,070
equals minus o point eight

980
01:08:44,120 --> 01:08:45,570
two radios

981
01:08:45,630 --> 01:08:48,990
it is about minus forty seven degrees

982
01:08:49,110 --> 01:08:51,310
there's not much physics in the facing

983
01:08:51,330 --> 01:08:55,440
what is interesting perhaps is to mention that if we had chosen

984
01:08:55,480 --> 01:09:00,360
the speed at time t equals zero if we had given speech in this direction

985
01:09:00,400 --> 01:09:02,160
o point three

986
01:09:02,250 --> 01:09:03,520
meters per second

987
01:09:03,530 --> 01:09:06,570
they maximum wouldn't have changed of course not

988
01:09:06,620 --> 01:09:08,410
but the phi would have changed

989
01:09:08,410 --> 01:09:10,340
so maybe we can start

990
01:09:14,140 --> 01:09:19,320
it is a small example before going to the next slide that should clear up

991
01:09:19,320 --> 01:09:22,110
some of the concept that we are talking about

992
01:09:22,410 --> 01:09:25,270
so this is showing the litter box

993
01:09:25,640 --> 01:09:30,960
that has this navigation task and this is kind of the standard environment in

994
01:09:31,100 --> 01:09:35,060
reinforcement learning the point my mind that people you like

995
01:09:35,170 --> 01:09:38,410
you seem you imagine that the robot is into the space

996
01:09:38,410 --> 01:09:40,990
and it has actions that can go

997
01:09:41,090 --> 01:09:46,160
two as the composite actions like you the the agent can say that i want

998
01:09:46,160 --> 01:09:47,260
to go on mars

999
01:09:47,270 --> 01:09:51,590
but what happens is that agent saying i want to go to mars

1000
01:09:51,630 --> 01:09:56,880
sometime it goes to the other direction so zero point

1001
01:09:58,520 --> 01:10:03,460
percent of the time it goes really but in the rest of the time just

1002
01:10:03,460 --> 01:10:08,210
randomly goes in the direction of the other compress

1003
01:10:08,260 --> 01:10:11,350
and so the task of the agent is to get to

1004
01:10:11,370 --> 01:10:13,850
two somebody were state and so maybe

1005
01:10:13,870 --> 01:10:15,700
four or transitions

1006
01:10:15,710 --> 01:10:19,410
the reward is going to to be zero

1007
01:10:19,430 --> 01:10:23,820
except when they finally some whole gets to the their state

1008
01:10:23,870 --> 01:10:26,060
and then somehow it it tries to

1009
01:10:26,070 --> 01:10:28,840
to stay there let let's say and

1010
01:10:28,910 --> 01:10:31,930
what's happening leaves that forever

1011
01:10:32,350 --> 01:10:35,760
so the disk that all of these counting here by the way

1012
01:10:35,880 --> 01:10:37,790
is that when this happens

1013
01:10:37,850 --> 01:10:42,200
if you didn't have discounting that the sun would be infinite right so if you

1014
01:10:42,200 --> 01:10:44,240
do this discounting saying

1015
01:10:44,240 --> 01:10:48,270
the sun is always finite because konami smaller than one

1016
01:10:49,150 --> 01:10:53,730
so you know that this is the geometric theory

1017
01:10:53,770 --> 01:10:56,240
if you just saw all these numbers

1018
01:10:56,260 --> 01:10:57,510
what you get

1019
01:10:57,560 --> 01:10:59,930
you get one of one minus come

1020
01:10:59,950 --> 01:11:03,190
so we receive our minds come a lot of

1021
01:11:04,460 --> 01:11:05,930
in the talk

1022
01:11:07,560 --> 01:11:10,680
so this defines the transition probability

1023
01:11:12,060 --> 01:11:15,240
i was criticized for saying cut by

1024
01:11:15,240 --> 01:11:18,930
the kernel is just you know what your argument function and

1025
01:11:18,970 --> 01:11:22,770
and that's what you want you want to sink when you hear the word co

1026
01:11:23,770 --> 01:11:25,940
so the transition probability

1027
01:11:25,960 --> 01:11:29,860
could be a matrix if you have a finite state space but if you have

1028
01:11:29,860 --> 01:11:35,620
an infinite state space is just the function for this defines that the thing

1029
01:11:35,640 --> 01:11:38,250
and and this defines the rewards for

1030
01:11:38,270 --> 01:11:42,560
so then everything is pretty much defined here and

1031
01:11:42,560 --> 01:11:43,620
how do you

1032
01:11:43,640 --> 01:11:46,030
design a controller in this case

1033
01:11:46,050 --> 01:11:50,140
well what the content should do is is that it should try to use some

1034
01:11:50,140 --> 01:11:54,620
actions that go to the action that brings the agent closer to the goal

1035
01:11:54,650 --> 01:11:56,180
some of

1036
01:11:56,180 --> 01:12:00,670
and what makes this difficult is the reward is

1037
01:12:00,680 --> 01:12:03,400
so no no one this is

1038
01:12:03,470 --> 01:12:07,800
the control problem specification this is very simple

1039
01:12:07,810 --> 01:12:10,140
that you want to take this action is right

1040
01:12:10,190 --> 01:12:13,000
because this is defined in terms of the rewards

1041
01:12:13,060 --> 01:12:17,530
and the immediate reward at every time step i just zero

1042
01:12:18,340 --> 01:12:19,580
so this is

1043
01:12:19,620 --> 01:12:21,470
this makes the problem

1044
01:12:21,490 --> 01:12:22,830
the figure

1045
01:12:22,840 --> 01:12:25,500
but this makes the problem i suspect

1046
01:12:25,560 --> 01:12:30,720
so i hope that that i know these concepts are

1047
01:12:30,770 --> 01:12:32,520
easier to understand

1048
01:12:36,150 --> 01:12:41,860
so again policies of the behaving so the robot decides to

1049
01:12:41,900 --> 01:12:45,150
that it looks at the state and then

1050
01:12:45,190 --> 01:12:48,780
it seems that well into the forests and on into the

1051
01:12:48,960 --> 01:12:51,240
was that there is the best

1052
01:12:51,250 --> 01:12:55,920
so maybe i should take the action that brings me to to use

1053
01:12:55,930 --> 01:13:01,240
so that's the policy so places and they have of defining the behavior

1054
01:13:01,300 --> 01:13:03,610
it could depend on the full blast

1055
01:13:03,620 --> 01:13:07,180
but it doesn't necessarily have to depend on

1056
01:13:08,080 --> 01:13:10,070
and given your policy

1057
01:13:10,620 --> 01:13:13,970
what is the value of the policy it could be good policies are about but

1058
01:13:13,970 --> 01:13:16,950
this is you start region from some states

1059
01:13:17,040 --> 01:13:21,310
and then you start to execute the policy so that really stuck in some random

1060
01:13:23,220 --> 01:13:24,930
going somebody

1061
01:13:24,980 --> 01:13:26,700
and then use on

1062
01:13:26,720 --> 01:13:31,180
the rewards that i received along this pass

1063
01:13:31,240 --> 01:13:36,370
OK you do the discarding as well you take the expectations and

1064
01:13:36,420 --> 01:13:40,980
but you're taking the expectation what happens is that you are basically summing over all

1065
01:13:41,030 --> 01:13:45,990
this possible future trajectories right so some of the actors are going to hit the

1066
01:13:45,990 --> 01:13:49,410
goal some of the trajectory is to missing in

1067
01:13:49,450 --> 01:13:53,680
and you take the expectation we suspect all this trajectory

1068
01:13:54,850 --> 01:13:55,850
it's good

1069
01:13:55,880 --> 01:13:57,250
so that the

1070
01:13:57,260 --> 01:14:02,200
the value for state tax and the policy pi

1071
01:14:02,250 --> 01:14:06,740
and have a function again it's just we're taking the maximum of this was just

1072
01:14:06,990 --> 01:14:09,140
all possible policies

1073
01:14:09,160 --> 01:14:10,980
an optimal policy

1074
01:14:11,010 --> 01:14:14,680
would get this value in every possible state and you can buy that if such

1075
01:14:14,680 --> 01:14:18,370
an optimal policy would exist at all

1076
01:14:18,380 --> 01:14:20,420
so what's missing

1077
01:14:20,430 --> 01:14:23,470
so given that you know about the problem so far

1078
01:14:23,480 --> 01:14:29,410
let's assume that everything is fine and the states finite actions are finite

1079
01:14:30,930 --> 01:14:37,890
does an optimal policy as the still not

1080
01:14:38,250 --> 01:14:42,680
of many optimal policies

1081
01:14:42,750 --> 01:14:55,290
OK why

1082
01:14:55,330 --> 01:15:03,970
so talking about this specific problem but i'm really asking more generally

1083
01:15:03,980 --> 01:15:08,300
that the church is given a finite MDP and and the question is if there

1084
01:15:08,300 --> 01:15:13,080
exists an optimal policy

1085
01:15:13,080 --> 01:15:14,110
if i write

1086
01:15:14,110 --> 01:15:17,900
the actual words which make up the joke of the information bearing thing for the

1087
01:15:18,690 --> 01:15:24,300
so telling and then we have a whole range of strokes about is it's about

1088
01:15:25,230 --> 01:15:29,100
six about christmas those

1089
01:15:29,180 --> 01:15:32,070
this things so about

1090
01:15:32,110 --> 01:15:33,990
all sorts of

1091
01:15:34,020 --> 01:15:37,770
all sorts of things are never mind but not to about slovenians were talks about

1092
01:15:37,770 --> 01:15:48,370
potatoes or jokes about civilians potatoes but that will be created solely

1093
01:16:05,080 --> 01:16:05,720
i'm trying to get

1094
01:16:06,030 --> 01:16:07,970
twenty million

1095
01:16:11,150 --> 01:16:21,870
i can never going to talk

1096
01:16:36,610 --> 01:16:39,060
want to

1097
01:16:39,270 --> 01:16:46,230
so find mutual funds china

1098
01:17:10,690 --> 01:17:11,450
all right

1099
01:17:11,470 --> 01:17:16,000
the second suspect that the product and this one one of the argument restrictions on

1100
01:17:16,000 --> 01:17:17,020
the front

1101
01:17:17,270 --> 01:17:22,700
o think right you matrix about anything according to size so right so that these

1102
01:17:22,700 --> 01:17:23,940
jokes but the

1103
01:17:23,940 --> 01:17:29,180
ones which are listed where things someone made a decision at some stage about jokes

1104
01:17:29,180 --> 01:17:34,980
about those things so that title john has been reified so it so the concept

1105
01:17:34,980 --> 01:17:38,830
of jokes about

1106
01:17:42,070 --> 01:17:47,730
austrians was the homeless here because it just about austrian is in the knowledge base

1107
01:17:48,020 --> 01:17:53,400
so every time someone made some assertion about possibly the the offensive

1108
01:17:53,860 --> 01:17:59,930
no i'm not so we have to the full KB defined can you see world

1109
01:18:00,190 --> 01:18:03,400
with the decision on to the austrians

1110
01:18:03,410 --> 01:18:05,580
or to money

1111
01:18:05,600 --> 01:18:06,930
any other

1112
01:18:11,180 --> 01:18:15,350
so coverage

1113
01:18:28,530 --> 01:18:36,190
it was it's only deep brain wouldn't it has a number of predict is countable

1114
01:18:36,190 --> 01:18:41,570
on the fingers and the figures are now on your toes as well

1115
01:18:41,820 --> 01:18:48,560
so we've got thousands and thousands of so it's in the sun

1116
01:18:48,620 --> 01:18:52,480
no it's

1117
01:18:52,540 --> 01:18:55,980
the difference is mostly that's more suited for inference

1118
01:18:55,990 --> 01:18:57,180
right but

1119
01:18:57,390 --> 01:18:59,480
wouldn't it loses

1120
01:18:59,490 --> 01:19:02,140
has more

1121
01:19:02,190 --> 01:19:04,160
has more uniform coverage

1122
01:19:05,350 --> 01:19:09,970
and it in some cases more fine grained

1123
01:19:09,980 --> 01:19:13,470
perhaps i global even in reality

1124
01:19:14,910 --> 01:19:19,680
that that they have very

1125
01:19:19,720 --> 01:19:23,690
different purposes and you can use them together because we have these links to win

1126
01:19:23,690 --> 01:19:29,240
if you can actually find some german wouldn't have go up wouldn't some two we're

1127
01:19:29,240 --> 01:19:32,190
gonna correspondence and then you can start reasoning about

1128
01:19:48,120 --> 01:19:53,290
four drawn random to from the sort of list of good ingrams and see whether

1129
01:19:53,290 --> 01:19:55,400
they those are perfectly

1130
01:19:55,410 --> 01:20:02,190
the different games and they give you some information about coverage which might give you

1131
01:20:02,190 --> 01:20:05,570
some information about utility i think it's

1132
01:20:05,650 --> 01:20:09,820
important to realize what sort of game that you're playing the idea of playing a

1133
01:20:09,820 --> 01:20:15,770
game of sampling in a knowledge inferentially productive knowledge base so don't

1134
01:20:15,780 --> 01:20:19,070
compare to what the coverage again wouldn't it

1135
01:20:19,120 --> 01:20:24,830
is was would be what you do the things you should compare it to serve

1136
01:20:24,860 --> 01:20:31,370
as a feature compared to something in a in

1137
01:20:31,410 --> 01:20:35,570
knowledge bases which it should have been used for inference

1138
01:20:36,820 --> 01:20:39,370
so here's the key

1139
01:20:40,260 --> 01:20:45,770
rather than because he was

1140
01:20:46,560 --> 01:20:49,640
is says you

1141
01:20:49,690 --> 01:20:50,850
yes and no

1142
01:20:51,140 --> 01:20:56,150
and i very much want to i sort of produced infrastructure which is all the

1143
01:20:56,150 --> 01:21:00,860
wikipedia articles sorted by the council including the list and i want to go through

1144
01:21:01,760 --> 01:21:07,330
one by one and in the end to cyc i want cite from them one

1145
01:21:07,330 --> 01:21:11,150
by one element to itself and i want you guys to do it to show

1146
01:21:11,150 --> 01:21:16,280
you how we're going to make you do that at the end of the talk

1147
01:21:16,280 --> 01:21:18,850
of three hopefully will likely

1148
01:21:44,990 --> 01:21:48,560
so there's a lot of things the

1149
01:21:48,580 --> 01:21:54,740
a lot of data about the

1150
01:21:55,770 --> 01:21:57,700
that they all

1151
01:21:59,200 --> 01:22:03,180
on the basis of that

1152
01:22:04,200 --> 01:22:07,150
the things he

1153
01:22:07,150 --> 01:22:09,830
because he it was that

1154
01:22:12,980 --> 01:22:13,610
don't know

1155
01:22:13,610 --> 01:22:17,220
what does that mean if you look at the relationship like that where i was

1156
01:22:17,220 --> 01:22:20,850
showing you the container completely and so on we have

1157
01:22:20,900 --> 01:22:26,040
large numbers of meanings for war i mentioned then wouldn't it

1158
01:22:26,690 --> 01:22:29,060
wouldn't it is

1159
01:22:30,190 --> 01:22:31,720
meanings for

1160
01:22:31,730 --> 01:22:32,860
this is

1161
01:22:33,800 --> 01:22:40,970
contextual variants on the meanings of reasonably narrowly applied words we tend to have large

1162
01:22:40,970 --> 01:22:41,900
numbers of

1163
01:22:41,950 --> 01:22:45,940
variants on common words we

1164
01:22:45,940 --> 01:22:48,550
g one

1165
01:23:14,690 --> 01:23:20,850
i give you one

1166
01:24:01,150 --> 01:24:06,050
you know

1167
01:24:06,070 --> 01:24:12,600
you know all

1168
01:24:32,670 --> 01:24:36,740
so what

1169
01:24:48,520 --> 01:24:50,980
all this

1170
01:24:56,080 --> 01:25:01,340
the average

1171
01:25:01,360 --> 01:25:04,740
you know

1172
01:25:15,810 --> 01:25:29,140
so you can

1173
01:25:58,430 --> 01:26:01,150
the second

1174
01:26:41,590 --> 01:26:44,990
it's not

1175
01:27:02,190 --> 01:27:06,800
what is the

1176
01:27:08,880 --> 01:27:13,370
it here is that

1177
01:27:17,010 --> 01:27:21,680
we can read them

1178
01:27:21,690 --> 01:27:24,250
it the

1179
01:27:25,110 --> 01:27:26,740
we use

1180
01:27:32,430 --> 01:27:35,370
its mission

1181
01:27:39,740 --> 01:27:44,950
it seems to the

1182
01:27:45,160 --> 01:27:51,050
so it was really is

1183
01:27:55,920 --> 01:28:02,750
it is

1184
01:28:08,340 --> 01:28:16,490
is it

1185
01:28:16,500 --> 01:28:20,810
so this

1186
01:28:22,870 --> 01:28:30,550
so you

1187
01:28:46,630 --> 01:28:51,700
the new

1188
01:29:02,890 --> 01:29:07,730
what we really need

1189
01:29:10,840 --> 01:29:14,030
with my

1190
01:29:21,120 --> 01:29:25,510
the discrete

1191
01:29:36,200 --> 01:29:41,990
this is not

1192
01:29:53,920 --> 01:29:58,390
it is

1193
01:29:58,410 --> 01:30:06,760
so the story

1194
01:30:06,760 --> 01:30:13,130
at the same time hilbert was openly disparaging and skeptical of philosophy and the belief

1195
01:30:13,240 --> 01:30:18,060
the ability of philosophy to to solve problems on its own terms so

1196
01:30:18,120 --> 01:30:19,250
for help

1197
01:30:19,260 --> 01:30:24,830
the only way to make philosophical prior progress was to translate philosophical questions into properly

1198
01:30:24,830 --> 01:30:26,470
mathematical questions

1199
01:30:26,510 --> 01:30:31,170
and then you do mathematics is the mathematical method ties the philosophical questions and then

1200
01:30:31,170 --> 01:30:32,990
and then you can make

1201
01:30:33,250 --> 01:30:34,770
you can make progress

1202
01:30:34,820 --> 01:30:38,580
no good of course did that ended that to great effect

1203
01:30:38,620 --> 01:30:44,540
so he was remarkably good at using formal methods to address epistemological problems but at

1204
01:30:44,540 --> 01:30:47,040
the same time is very sensitive to

1205
01:30:47,090 --> 01:30:49,680
to the limitations of the former methods and largely

1206
01:30:49,720 --> 01:30:53,950
as a consequence of his incompleteness theorems and so

1207
01:30:53,980 --> 01:30:58,780
while recognizing and feeling very strongly these limitations he looked too

1208
01:30:58,800 --> 01:31:03,140
philosophy of these falls out of a certain type of philosophical method to fill the

1209
01:31:03,140 --> 01:31:09,530
gap and so here's another quote from from from conversations with how long so kernel

1210
01:31:10,280 --> 01:31:14,800
is says that the analysis of concepts is central to philosophy

1211
01:31:14,820 --> 01:31:20,230
science only combines concepts is and does not analyse concepts it contributes the analysis of

1212
01:31:20,230 --> 01:31:25,110
concepts by being stimulating from real analysis analysis is to arrive at what thinking is

1213
01:31:25,110 --> 01:31:29,930
based on the inborn intuitions and so the idea is to science we basically work

1214
01:31:29,930 --> 01:31:32,640
with the concepts were given me we can take them apart and put them together

1215
01:31:32,640 --> 01:31:36,020
in different ways and apply new concepts from the old ones but it doesn't give

1216
01:31:36,020 --> 01:31:40,840
us the initial concept to start with for that i mean that's what that's we

1217
01:31:40,840 --> 01:31:43,310
you need this kind of

1218
01:31:43,350 --> 01:31:50,670
big philosophical method that no one discussed this morning that you that's where you have

1219
01:31:50,670 --> 01:31:52,770
to rely on one

1220
01:31:52,870 --> 01:31:58,110
this mysterious method of analysis to give you the concepts to work with

1221
01:31:58,180 --> 01:32:03,970
and this i take it is explained his disdain for many mathematicians met mathematicians and

1222
01:32:03,970 --> 01:32:06,550
philosophers who expect to get

1223
01:32:06,600 --> 01:32:08,780
too much from syntactic methods

1224
01:32:08,790 --> 01:32:13,060
so they're the ones who expect to derive something from nothing you know in

1225
01:32:13,680 --> 01:32:16,900
from that quote while avoiding the appearance of philosophy

1226
01:32:19,570 --> 01:32:25,360
i take that to be some drama here or there this this this this tension

1227
01:32:25,360 --> 01:32:31,220
between a girl and hope it to be a poignant one i mean girl had

1228
01:32:31,220 --> 01:32:32,940
inherited the powerful

1229
01:32:33,900 --> 01:32:35,380
from from help at

1230
01:32:35,390 --> 01:32:40,740
any shared gilbert strong desire to see mathematics from describe the destructive skeptical

1231
01:32:40,760 --> 01:32:46,810
attitudes but in the end he concluded that an overly narrow reading of the metamathematical

1232
01:32:46,810 --> 01:32:49,650
tradition left skepticism with the upper hand

1233
01:32:52,000 --> 01:32:55,680
and there's you know some historical irony here as well so this

1234
01:32:55,750 --> 01:32:59,790
as far as i know there is no evidence that hilbert and kernel ever meant

1235
01:32:59,810 --> 01:33:02,020
but they once came close

1236
01:33:02,030 --> 01:33:06,060
so in in nineteen

1237
01:33:06,140 --> 01:33:08,060
thirty one

1238
01:33:08,070 --> 01:33:16,870
hilbert gave a lecture in can expert called not to can logic so the knowledge

1239
01:33:16,890 --> 01:33:18,400
ninety three

1240
01:33:18,450 --> 01:33:19,110
thank you

1241
01:33:19,140 --> 01:33:27,880
where the use cases of logic and and and and the rational sciences and a

1242
01:33:29,070 --> 01:33:32,860
and you natural sciences with great optimism

1243
01:33:34,320 --> 01:33:39,320
so for minute excerpt of that speech was excerpted

1244
01:33:39,330 --> 01:33:41,460
and so her girl

1245
01:33:41,460 --> 01:33:46,330
albert read on the radio and i'm pretty sure you can still find it online

1246
01:33:46,330 --> 01:33:49,750
today so if you google or if not sending email send it if you can

1247
01:33:49,750 --> 01:33:55,960
actually you know you get an MP MP three files with with you know talbot's

1248
01:33:55,960 --> 01:33:57,110
voice just reading the

1249
01:33:57,540 --> 01:34:04,570
a snippet of this lecture lecture that ends with the words famous in this in

1250
01:34:04,570 --> 01:34:07,360
very and so we must know

1251
01:34:07,440 --> 01:34:08,850
we will

1252
01:34:08,970 --> 01:34:14,580
and the historical irony is that that at the same time kernel was the conference

1253
01:34:14,580 --> 01:34:18,950
on epistemology and exact sciences in that very same city

1254
01:34:19,060 --> 01:34:20,370
and that was the

1255
01:34:20,540 --> 01:34:26,450
the conference where google announced the incomplete the first incompleteness theorem just the day before

1256
01:34:26,450 --> 01:34:27,830
public lecture

1257
01:34:27,840 --> 01:34:34,720
and of course that the inputs a is true it shows that there are limitations

1258
01:34:34,720 --> 01:34:39,860
to the knowledge and former methods

1259
01:34:40,640 --> 01:34:45,790
OK so let me sort of now jump to the present and

1260
01:34:45,800 --> 01:34:48,760
how to extract some what i mean so what good is history unless you to

1261
01:34:48,760 --> 01:34:51,760
learn something from it so they i take

1262
01:34:51,760 --> 01:34:53,500
from these considerations

1263
01:34:53,520 --> 01:34:54,970
so first of all

1264
01:34:55,120 --> 01:35:01,950
i think it's undeniable that the metamathematical approach which involves syntactic formal methods modelling mathematical

1265
01:35:01,950 --> 01:35:06,340
methods provide a powerful means of understanding mathematics i mean i think it's undeniable that

1266
01:35:06,560 --> 01:35:10,670
work in the hope at school as well as girls work tells us something about

1267
01:35:10,670 --> 01:35:15,860
the nature mathematical we understand mathematics better than we did a hundred years ago

1268
01:35:15,880 --> 01:35:17,140
as a result

1269
01:35:17,150 --> 01:35:22,270
but at the same time the mathematical modeling should be complemented by a properly philosophical

1270
01:35:23,310 --> 01:35:26,540
on the subject matter so we should always be

1271
01:35:26,550 --> 01:35:28,030
mindful of

1272
01:35:28,030 --> 01:35:32,260
what it is we're trying to understand you know formal systems these days are a

1273
01:35:32,260 --> 01:35:35,140
dime a dozen you really have to think long and hard about what it is

1274
01:35:35,140 --> 01:35:40,040
you're trying to capture and whether or not your formal modelling is is actually doing

1275
01:35:40,080 --> 01:35:41,550
what you think it is

1276
01:35:45,540 --> 01:35:49,190
at least for me in my view mathematical logic is often most compelling

1277
01:35:49,210 --> 01:35:52,720
and satisfying these two strands come together so that is when you get

1278
01:35:52,880 --> 01:35:57,790
mathematical results that contribute to a deeper philosophical understanding

1279
01:35:57,800 --> 01:36:05,460
so another from the mathematics is informed by and informs our philosophical or philosophical understanding

1280
01:36:05,990 --> 01:36:06,850
and so

1281
01:36:06,870 --> 01:36:12,440
so the landmine like to tell you give you a quick overview of some things

1282
01:36:12,440 --> 01:36:14,760
are going on and metamathematics today

1283
01:36:14,780 --> 01:36:19,340
and i mean happily i don't have to spend too much time on any of

1284
01:36:19,340 --> 01:36:23,970
them because you been hearing them all along in the conference and i don't have

1285
01:36:23,970 --> 01:36:26,270
what would be how much longer life

1286
01:36:28,860 --> 01:36:30,230
sounds good

1287
01:36:30,700 --> 01:36:36,110
so yes i'm going to talk about quickly proof mining automated reasoning and formal verification

1288
01:36:36,120 --> 01:36:41,770
combinatorial independences dependences in history and philosophy of mathematics in fifteen minutes

1289
01:36:41,770 --> 01:36:42,670
and if it doesn't

1290
01:36:43,790 --> 01:36:44,690
only logarithmic

1291
01:36:45,260 --> 01:36:47,750
so that's quite dramatically dozens and dozens grow

1292
01:36:48,570 --> 01:36:48,960
and we

1293
01:36:49,570 --> 01:36:53,170
grows logarithmically so much much weaker

1294
01:36:54,790 --> 01:36:55,210
and then

1295
01:36:55,740 --> 01:36:56,190
this fine

1296
01:36:57,620 --> 01:37:00,770
precision takes place is an important consequence is a mention

1297
01:37:02,710 --> 01:37:03,160
tells you

1298
01:37:03,810 --> 01:37:06,480
that you have an issue with this and dimension

1299
01:37:07,550 --> 01:37:08,810
yes it's a motivations

1300
01:37:09,970 --> 01:37:10,490
that are

1301
01:37:12,420 --> 01:37:13,660
no more than the dimension

1302
01:37:14,330 --> 01:37:19,850
and this is the machine looks maximally complexity can realize all possible separations on such

1303
01:37:20,330 --> 01:37:22,010
training sets of size

1304
01:37:22,820 --> 01:37:24,250
characterized by the dimension

1305
01:37:25,100 --> 01:37:28,000
and once we got past that we see image what you want

1306
01:37:28,040 --> 01:37:29,850
training examples and mention the

1307
01:37:30,080 --> 01:37:31,520
machine yourself in the regime

1308
01:37:32,000 --> 01:37:32,770
with the machine

1309
01:37:33,210 --> 01:37:36,610
can i realize everything anymore so are some things that you can do

1310
01:37:37,720 --> 01:37:38,790
which means that suddenly

1311
01:37:39,330 --> 01:37:41,300
an inductive bias suddenly

1312
01:37:42,190 --> 01:37:45,510
prior knowledge or whatever we want you have to see function class will

1313
01:37:46,370 --> 01:37:48,090
after that point sandy

1314
01:37:48,740 --> 01:37:49,300
you can hope to

1315
01:37:49,550 --> 01:37:50,270
to generalize

1316
01:37:52,250 --> 01:37:53,110
and nothing in between

1317
01:37:53,980 --> 01:37:55,410
no because it's possible

1318
01:37:57,500 --> 01:38:00,070
there is an example of that is the dimension

1319
01:38:02,670 --> 01:38:04,290
we take half spaces in our two

1320
01:38:06,890 --> 01:38:07,460
so they are

1321
01:38:08,260 --> 01:38:09,110
can be written like this

1322
01:38:11,330 --> 01:38:13,330
functions taking values plus or minus one

1323
01:38:13,920 --> 01:38:14,800
two different space

1324
01:38:17,590 --> 01:38:20,120
you know this is how anyone can reach

1325
01:38:22,360 --> 01:38:22,910
and if we

1326
01:38:23,830 --> 01:38:24,670
three points

1327
01:38:26,380 --> 01:38:27,030
which can

1328
01:38:28,150 --> 01:38:30,010
can be to to the poll three

1329
01:38:30,850 --> 01:38:31,510
three points

1330
01:38:32,220 --> 01:38:34,210
so we can have it possible separation

1331
01:38:37,270 --> 01:38:42,920
place the points in general position it turns out we can actually realize all these eight possible separations

1332
01:38:43,850 --> 01:38:44,740
so we can show all

1333
01:38:45,420 --> 01:38:47,180
three points in general position

1334
01:38:48,270 --> 01:38:49,070
and how it

1335
01:38:49,480 --> 01:38:50,820
it turns out that true

1336
01:38:51,620 --> 01:38:55,830
that we should never shuffle four points so if you take four ones no matter place them

1337
01:38:56,600 --> 01:38:58,890
you will not be able to separate in

1338
01:38:59,330 --> 01:39:01,570
sixteen possible ways to do put the

1339
01:39:03,140 --> 01:39:05,780
using functions from the class of functions

1340
01:39:07,430 --> 01:39:09,860
or in this case you mention is three

1341
01:39:11,570 --> 01:39:15,360
and it turns out this case the of equal number

1342
01:39:17,350 --> 01:39:20,320
and the number rounds of both of these users

1343
01:39:21,370 --> 01:39:24,010
some kind of complexity concept in statistics

1344
01:39:27,440 --> 01:39:28,080
from the point of view

1345
01:39:29,080 --> 01:39:30,390
statistical learning theory is

1346
01:39:30,840 --> 01:39:31,850
sometimes makes sense

1347
01:39:32,270 --> 01:39:35,800
but not always because it turns out there are cases where

1348
01:39:37,020 --> 01:39:38,370
can be very different cases

1349
01:39:39,020 --> 01:39:42,100
learning machines which is one parameter with dimension is infinite

1350
01:39:43,080 --> 01:39:43,980
and the cases

1351
01:39:44,410 --> 01:39:44,980
when you have

1352
01:39:45,540 --> 01:39:49,360
infinitely many parameters implicitly in the present to find out

1353
01:39:51,100 --> 01:39:56,500
anyway somehow things it's so clear to everybody that just counting the number of parameters

1354
01:39:57,240 --> 01:40:02,310
doesn't make sense as long as you don't have some sense of scale also people in because

1355
01:40:03,370 --> 01:40:06,000
with one parameter which is a real number you end

1356
01:40:06,140 --> 01:40:09,150
as much as you want you can including many parameters

1357
01:40:10,670 --> 01:40:15,570
our accuracy in one real numbers so discounting real numbers that make sense that's clear

1358
01:40:18,310 --> 01:40:19,290
a lot of this has been done

1359
01:40:20,970 --> 01:40:21,690
many approaches

1360
01:40:25,140 --> 01:40:25,430
this is

1361
01:40:26,260 --> 01:40:27,650
one example of this examining

1362
01:40:29,100 --> 01:40:29,490
and the

1363
01:40:33,730 --> 01:40:37,470
like this into a typical bones that when i showed you before

1364
01:40:38,830 --> 01:40:42,160
basically the same kind of thing stream arguments before

1365
01:40:43,550 --> 01:40:43,990
we get

1366
01:40:44,540 --> 01:40:45,110
well i

1367
01:40:45,990 --> 01:40:48,860
well now we have the test error training error

1368
01:40:49,570 --> 01:40:50,800
here we have a quantity that

1369
01:40:51,440 --> 01:40:53,220
depends on the species are mentioned age

1370
01:40:55,400 --> 01:40:58,830
today depends on the ratio between these dimension

1371
01:40:59,680 --> 01:41:01,440
and the number training stations

1372
01:41:02,400 --> 01:41:02,890
and then

1373
01:41:03,630 --> 01:41:04,740
we can also look at this

1374
01:41:05,880 --> 01:41:07,820
respond and discuss it bit

1375
01:41:10,400 --> 01:41:12,590
when i first saw this kind of was quite

1376
01:41:14,290 --> 01:41:15,620
something like this is possible

1377
01:41:16,930 --> 01:41:18,070
we know about the induction

1378
01:41:18,070 --> 01:41:21,730
a which are and going work

1379
01:41:22,110 --> 01:41:24,620
at a canadian university

1380
01:41:24,660 --> 01:41:29,400
and the university of massachusetts of the the UK systems is

1381
01:41:30,700 --> 01:41:37,490
designed for being able to define some complex queries about evolution

1382
01:41:37,540 --> 01:41:42,790
a stock information stock price

1383
01:41:49,450 --> 01:41:51,950
we had a look

1384
01:41:51,980 --> 01:41:55,230
what's the data stream

1385
01:41:55,230 --> 01:41:58,400
main applications some models

1386
01:41:58,410 --> 01:42:01,570
what data stream management systems are

1387
01:42:01,610 --> 01:42:04,440
process spend too much time on this

1388
01:42:04,550 --> 01:42:10,070
subject but i think that the management of data is very important

1389
01:42:10,070 --> 01:42:16,650
and i think that these systems we represent the future of data management

1390
01:42:16,660 --> 01:42:20,380
in real applications in the next lecture

1391
01:42:21,040 --> 01:42:23,080
now let's turn to

1392
01:42:23,130 --> 01:42:25,290
data stream mining

1393
01:42:25,330 --> 01:42:32,290
so the outline in the following so first i'm going to give the definition

1394
01:42:32,330 --> 01:42:34,870
and context of the data stream mining

1395
01:42:34,880 --> 01:42:37,450
and then i'm going to focus on

1396
01:42:37,450 --> 01:42:39,870
three different methods

1397
01:42:39,920 --> 01:42:41,450
decision tree

1398
01:42:42,690 --> 01:42:46,940
and clustering

1399
01:42:46,960 --> 01:42:47,980
the goal

1400
01:42:47,980 --> 01:42:48,990
it's important

1401
01:42:49,010 --> 01:42:51,830
apply data mining algorithms to

1402
01:42:51,840 --> 01:42:55,740
once we more to several weeks

1403
01:42:55,740 --> 01:42:57,070
the constraints

1404
01:42:57,080 --> 01:43:00,580
are the same as before limited memory

1405
01:43:00,620 --> 01:43:02,050
limited CPU

1406
01:43:02,070 --> 01:43:03,110
one possible

1407
01:43:03,120 --> 01:43:05,620
o PM

1408
01:43:05,620 --> 01:43:07,070
as well

1409
01:43:07,080 --> 01:43:08,860
we want to introduce

1410
01:43:10,770 --> 01:43:15,330
what's windowing in the data mining process

1411
01:43:15,420 --> 01:43:19,490
windowing is that if we consider a stream

1412
01:43:19,490 --> 01:43:22,860
so we have here at the beginning of the stream

1413
01:43:22,910 --> 01:43:24,040
at each

1414
01:43:24,940 --> 01:43:26,490
we have

1415
01:43:26,540 --> 01:43:29,240
some elements arriving in the stream

1416
01:43:29,300 --> 01:43:32,410
here is the current day

1417
01:43:32,410 --> 01:43:34,820
and windowing

1418
01:43:34,870 --> 01:43:40,120
it is to define to which portion of the stream we want to apply

1419
01:43:40,160 --> 01:43:41,990
data mining algorithm

1420
01:43:42,000 --> 01:43:46,120
i've we want to apply it to the whole stream

1421
01:43:46,160 --> 01:43:50,370
so i mean from the beginning to the current day date

1422
01:43:50,370 --> 01:43:53,570
or two is sliding window

1423
01:43:53,580 --> 01:43:55,870
i want to build the model

1424
01:43:55,870 --> 01:44:01,830
for the last three hours and maintain the model for the last three hours

1425
01:44:01,880 --> 01:44:02,830
all too

1426
01:44:02,840 --> 01:44:04,040
any portion of the

1427
01:44:05,210 --> 01:44:09,490
any portion of the past of schools but not defined

1428
01:44:09,540 --> 01:44:12,790
in order to

1429
01:44:17,170 --> 01:44:21,160
let's have a look at these different requirements

1430
01:44:21,170 --> 01:44:23,380
if we want

1431
01:44:23,450 --> 01:44:26,830
to apply the algorithm to the whole stream

1432
01:44:26,950 --> 01:44:27,910
we need

1433
01:44:27,910 --> 01:44:31,570
the algorithm to be incremental

1434
01:44:31,620 --> 01:44:34,990
why because we don't want we want to be

1435
01:44:35,050 --> 01:44:39,370
one possible origin we want to have only one pass for each element and we

1436
01:44:39,370 --> 01:44:41,450
don't want to memorize

1437
01:44:41,450 --> 01:44:42,730
all in

1438
01:44:44,150 --> 01:44:48,570
incremental algorithms are sufficient to do

1439
01:44:48,580 --> 01:44:50,480
if we want to

1440
01:44:50,490 --> 01:44:52,910
apply it on sliding window

1441
01:44:52,920 --> 01:44:54,040
last day

1442
01:44:54,050 --> 01:44:56,360
last three hours for instance

1443
01:44:56,360 --> 01:44:59,400
we need an incremental algorithm

1444
01:45:00,540 --> 01:45:03,110
the ability to forget the past

1445
01:45:03,170 --> 01:45:05,120
when some elements

1446
01:45:05,120 --> 01:45:07,440
died from window

1447
01:45:07,450 --> 01:45:09,830
get out of the window

1448
01:45:09,840 --> 01:45:16,360
we have we need to remove them from the model

1449
01:45:16,380 --> 01:45:23,240
if we want to apply on any past portion not defined in advance

1450
01:45:23,360 --> 01:45:25,740
we need incremental algorithms

1451
01:45:26,740 --> 01:45:29,780
we need to to keep from summaries

1452
01:45:31,380 --> 01:45:33,540
history of the host tree

1453
01:45:33,540 --> 01:45:35,090
not the whole stream

1454
01:45:35,110 --> 01:45:39,460
but a summary of

1455
01:45:40,980 --> 01:45:42,690
what are we going to

1456
01:45:42,710 --> 01:45:44,740
i see no

1457
01:45:44,790 --> 01:45:46,960
but the whole stream

1458
01:45:46,990 --> 01:45:51,530
well one meant for which is already

1459
01:45:51,580 --> 01:45:54,070
applicable to stream

1460
01:45:54,120 --> 01:45:57,050
if is no own network

1461
01:45:57,110 --> 01:45:58,710
we can

1462
01:45:58,770 --> 01:46:00,860
at the beginning of the stream

1463
01:46:01,950 --> 01:46:04,420
with the neural network

1464
01:46:05,870 --> 01:46:07,690
and then we wait

1465
01:46:07,700 --> 01:46:09,740
it's not that easy

1466
01:46:09,740 --> 01:46:13,900
the question is actually on this slide during the break

1467
01:46:13,910 --> 01:46:16,030
the first one is

1468
01:46:16,040 --> 01:46:18,000
yes there's a mistake here

1469
01:46:18,210 --> 01:46:24,080
for example some examples of images and that our semi definite positive include diagonal matrix

1470
01:46:24,390 --> 01:46:27,190
only if the diagonal elements are

1471
01:46:27,200 --> 01:46:29,380
positive nonnegative

1472
01:46:29,400 --> 01:46:36,580
so you're mean you're missing here and a diagonal matrix with nonnegative elements inherent in

1473
01:46:37,010 --> 01:46:39,970
the diagonal matrix with nonnegative elements

1474
01:46:39,970 --> 01:46:45,690
and the results zeros on the diagonal then is semi definite positive

1475
01:46:47,820 --> 01:46:48,830
so why

1476
01:46:48,890 --> 01:46:54,370
is the transpose b always the semi definite positive matrix

1477
01:46:54,400 --> 01:46:57,890
the reason is that you want to know if

1478
01:46:57,940 --> 01:47:04,260
this dot product is is always nonnegative and it turns out that the end is

1479
01:47:04,260 --> 01:47:09,010
the domain of the matrix which is the transpose of the matrix has this property

1480
01:47:09,010 --> 01:47:10,900
then you can

1481
01:47:11,180 --> 01:47:14,460
transfer it to the left of the dot product

1482
01:47:14,490 --> 01:47:19,460
by by just transposing a matrix

1483
01:47:20,160 --> 01:47:26,020
this means that the product is exactly this one and obviously it's the norm of

1484
01:47:26,020 --> 01:47:27,910
the x squared so it's got to be

1485
01:47:28,300 --> 01:47:32,460
and then get it right that's the reason why be transposed b

1486
01:47:32,460 --> 01:47:40,880
all the transpose is always symmetric semi definite positive matrix

1487
01:47:40,930 --> 01:47:46,760
so again i would be switching rather quickly enough from linear algebra to probability so

1488
01:47:46,760 --> 01:47:48,210
if you have

1489
01:47:48,270 --> 01:47:50,680
a few questions then

1490
01:47:50,710 --> 01:47:52,740
now is the time

1491
01:48:01,600 --> 01:48:02,570
all right

1492
01:48:03,430 --> 01:48:07,190
this issue probabilities

1493
01:48:07,210 --> 01:48:15,300
so again i'm not planning to go into these areas into the very

1494
01:48:15,320 --> 01:48:22,580
very complicated concepts in probability so we start to with was really the basics let's

1495
01:48:22,580 --> 01:48:24,900
say you have

1496
01:48:24,920 --> 01:48:29,710
according to new to sit and you look at is if the the outcome is

1497
01:48:29,710 --> 01:48:31,640
to use our heads

1498
01:48:31,650 --> 01:48:33,930
and you do that several times

1499
01:48:33,950 --> 01:48:39,530
and you wonder if you've done that and sometimes what is the probability to have

1500
01:48:39,550 --> 01:48:43,450
and two s exactly

1501
01:48:43,460 --> 01:48:45,670
that would be a fair coin right

1502
01:48:50,240 --> 01:48:51,610
if you want

1503
01:48:51,620 --> 01:48:55,090
to study the problem the

1504
01:48:55,150 --> 01:48:58,420
the outcome of random events

1505
01:48:58,450 --> 01:49:04,780
then you have to formalize that in mathematics with a random space

1506
01:49:04,800 --> 01:49:12,770
we're all media is actually the space of random events the set of random events

1507
01:49:12,800 --> 01:49:16,150
a year is the

1508
01:49:16,170 --> 01:49:19,530
the set of measurable collections of events

1509
01:49:19,550 --> 01:49:23,650
and these are probability we should go from

1510
01:49:23,700 --> 01:49:29,050
eighty two you one so if in my

1511
01:49:29,110 --> 01:49:32,870
in my car in in my car experiments

1512
01:49:32,930 --> 01:49:37,360
the set of random even for it if if

1513
01:49:38,620 --> 01:49:41,060
sorry is that even the

1514
01:49:41,080 --> 01:49:46,650
even so i want to study is just does one calling and i look at

1515
01:49:46,650 --> 01:49:48,580
the outcome of of of

1516
01:49:48,680 --> 01:49:51,140
disney these

1517
01:49:51,180 --> 01:49:53,770
this thing and then the

1518
01:49:53,770 --> 01:49:59,050
he said on omega is the set containing only add and k is the set

1519
01:49:59,050 --> 01:50:02,300
of measurable collections of even is

1520
01:50:02,330 --> 01:50:06,460
is made of four minutes that is that are

1521
01:50:07,180 --> 01:50:13,930
was all omega and the empty set and the

1522
01:50:13,950 --> 01:50:18,860
the set that contains only adds or sitcom that contains only three years

1523
01:50:18,890 --> 01:50:25,530
and so you will be able to measure the probability of any elements in e

1524
01:50:25,550 --> 01:50:29,340
so the probability of the empty set is you know the probability of the whole

1525
01:50:29,340 --> 01:50:32,120
set omega is exactly one

1526
01:50:32,130 --> 01:50:36,920
and if you have a occurred which is maybe not for but

1527
01:50:36,930 --> 01:50:41,890
which is a little bit biased then the probability of heads and may be p

1528
01:50:42,060 --> 01:50:45,480
and the one of these maybe one p

1529
01:50:46,620 --> 01:50:49,040
so there

1530
01:50:49,050 --> 01:50:56,490
let's properties of or of the probability are that the probabilities between zero and one

1531
01:50:56,500 --> 01:51:02,280
the empty set as the probability the full set as one of probability one if

1532
01:51:02,280 --> 01:51:07,200
you have if you consider to is to measure random events

1533
01:51:07,540 --> 01:51:12,360
that there are

1534
01:51:12,430 --> 01:51:17,610
OK but there's a there's a mistake there if you consider two random even for

1535
01:51:17,610 --> 01:51:21,370
which means that there section is empty and their union

1536
01:51:21,430 --> 01:51:26,970
the other is the intersection is empty then the probability of the union of

1537
01:51:26,980 --> 01:51:30,120
the evans is the sum of the two probabilities

1538
01:51:30,190 --> 01:51:33,800
so you can easily imagine that he is you have and

1539
01:51:33,800 --> 01:51:36,340
we'll see what the rules are women

1540
01:51:36,360 --> 01:51:39,970
that's quite different from what must of this might try to to do

1541
01:51:39,970 --> 01:51:42,200
today was certainly pretty

1542
01:51:42,220 --> 01:51:44,860
revolutionary i think in nineteen thirty

1543
01:51:44,910 --> 01:51:46,340
which was

1544
01:51:46,360 --> 01:51:51,300
an idea of having a little abstract or ideal idealise machine which is going to

1545
01:51:51,300 --> 01:51:54,340
carry out computations for you

1546
01:51:54,360 --> 01:51:56,640
and there are a couple of different approaches to that

1547
01:51:56,640 --> 01:51:59,160
the first one is called turing machine

1548
01:51:59,240 --> 01:52:00,860
in all around during

1549
01:52:04,200 --> 01:52:05,550
i guess not

1550
01:52:05,550 --> 01:52:09,010
and coincidentally actually was responsible for

1551
01:52:09,200 --> 01:52:12,220
taking for the concept of digital computer

1552
01:52:12,860 --> 01:52:13,890
at least in

1553
01:52:13,930 --> 01:52:16,260
during the war in england

1554
01:52:16,300 --> 01:52:17,570
so the the second world war

1555
01:52:17,610 --> 01:52:18,700
and in

1556
01:52:18,740 --> 01:52:22,370
and the true machine is what i call the state machine

1557
01:52:22,430 --> 01:52:25,140
it's like a little engine remembers what it up to

1558
01:52:25,180 --> 01:52:28,590
and remember that by saying i mean state forty four

1559
01:52:28,610 --> 01:52:31,860
and it looks up the title of what's best to do it in state forty

1560
01:52:31,860 --> 01:52:33,240
four something else

1561
01:52:33,280 --> 01:52:35,660
maybe that changes the state of ideas

1562
01:52:35,680 --> 01:52:39,930
changes some storage being written from

1563
01:52:39,970 --> 01:52:43,320
there's the third approach called abacus machines

1564
01:52:43,340 --> 01:52:48,930
and that's machines are can't just intermediary device really make it easier to prove some

1565
01:52:49,930 --> 01:52:54,280
because machines are really more like what we think of computer

1566
01:52:54,640 --> 01:52:56,870
you imagine that there is a bunch of

1567
01:52:56,930 --> 01:53:00,030
containers and each contain has a numbering

1568
01:53:00,050 --> 01:53:02,890
and so we call the registers

1569
01:53:03,800 --> 01:53:05,700
as time goes by

1570
01:53:05,700 --> 01:53:08,740
there's some operations which can affect the

1571
01:53:08,760 --> 01:53:12,630
values of numbers in registers and the operations are controlled

1572
01:53:12,680 --> 01:53:15,720
by little thing it remarkable program i guess

1573
01:53:15,740 --> 01:53:17,910
so that actually have a machine is

1574
01:53:17,990 --> 01:53:21,220
really closer to conception of computer

1575
01:53:21,300 --> 01:53:23,180
o by the

1576
01:53:23,200 --> 01:53:25,510
computer like things

1577
01:53:25,530 --> 01:53:29,070
so it's kind of interesting as three different approaches to computability

1578
01:53:29,090 --> 01:53:32,970
and what will mainly be trying to do is just push forward to showing both

1579
01:53:32,970 --> 01:53:34,490
particular ones

1580
01:53:34,760 --> 01:53:37,340
or equivalent

1581
01:53:38,410 --> 01:53:40,760
there was a

1582
01:53:40,820 --> 01:53:42,590
this problem that

1583
01:53:42,640 --> 01:53:49,030
there might be ways of computing that we somehow or having captured yet

1584
01:53:49,200 --> 01:53:51,800
but we can see it every time we come up with a new way of

1585
01:53:51,820 --> 01:53:54,550
figuring out whether something far artistically

1586
01:53:54,550 --> 01:53:58,070
computable victory so far we have tried to do this

1587
01:53:58,140 --> 01:53:59,890
it always turns out to be

1588
01:53:59,930 --> 01:54:06,450
we can prove mathematics and science some some something else someone else already thought of

1589
01:54:08,200 --> 01:54:13,530
the mathematician working at the time when the church symbolic logician

1590
01:54:13,610 --> 01:54:15,610
propose the thesis

1591
01:54:15,630 --> 01:54:18,570
as as a formal statement to control

1592
01:54:18,590 --> 01:54:20,200
discussion in this area

1593
01:54:20,200 --> 01:54:22,410
culture to status

1594
01:54:22,430 --> 01:54:27,450
OK and just read that because i think it's can isolate just the they self

1595
01:54:27,510 --> 01:54:32,760
this is there's no end to the possible variations in detailed characterizations of the notions

1596
01:54:32,760 --> 01:54:34,450
of computability

1597
01:54:34,450 --> 01:54:36,340
and effectiveness

1598
01:54:36,390 --> 01:54:39,720
being able to tell whether really done the job not

1599
01:54:39,760 --> 01:54:43,820
you have to finally accept or reject the thesis

1600
01:54:45,050 --> 01:54:49,320
that the set of functions computable in any one senses someone comes up with

1601
01:54:49,360 --> 01:54:53,640
is the same as another way to do it

1602
01:54:53,700 --> 01:54:56,360
to us when we're thinking about this

1603
01:54:56,410 --> 01:54:57,450
so think

1604
01:54:57,510 --> 01:54:58,740
OK it's but

1605
01:54:58,740 --> 01:55:02,990
in the light of the problem space that we're dealing with it's really important

1606
01:55:03,030 --> 01:55:04,870
we're really trying to capture

1607
01:55:04,890 --> 01:55:07,010
whether or not they could be

1608
01:55:07,030 --> 01:55:11,260
one of gilbert's little as could really be a call

1609
01:55:11,280 --> 01:55:13,200
a little lower others got

1610
01:55:13,260 --> 01:55:16,370
effective computability that's the why of

1611
01:55:16,430 --> 01:55:20,740
ensuring that we haven't gone wrong don't always idealised stack

1612
01:55:20,780 --> 01:55:25,430
the importance of is around that maybe we left something out maybe there is a

1613
01:55:25,430 --> 01:55:28,360
way that humans think about calculations

1614
01:55:28,390 --> 01:55:29,640
so we haven't yet

1615
01:55:29,700 --> 01:55:31,930
teased out of

1616
01:55:31,970 --> 01:55:34,590
apparently attempts to do this

1617
01:55:34,640 --> 01:55:39,280
just to be completely crazily skeptical speculative

1618
01:55:39,300 --> 01:55:40,550
just as

1619
01:55:40,590 --> 01:55:44,410
in a sense the greeks didn't want to see real numbers

1620
01:55:44,450 --> 01:55:46,760
i run up against them all the time

1621
01:55:46,800 --> 01:55:50,910
but they kept on the will way we have been dealing with numbers all other

1622
01:55:50,910 --> 01:55:52,590
integers or rationals

1623
01:55:52,610 --> 01:55:56,910
you can see this this problem here the edge looking at diagnosis of

1624
01:55:56,930 --> 01:55:59,110
five squares and so on

1625
01:55:59,180 --> 01:56:01,550
but will figure that one out

1626
01:56:01,610 --> 01:56:05,820
really it was that they had teased at the following locations and come up with

1627
01:56:05,910 --> 01:56:07,390
strong theories

1628
01:56:07,410 --> 01:56:11,220
the church's this is about that you might be the problem here is some figured

1629
01:56:11,220 --> 01:56:14,360
out enough about what it means to compute

1630
01:56:14,410 --> 01:56:16,410
i don't know if it's possible

1631
01:56:16,450 --> 01:56:18,430
but the faces we have

1632
01:56:18,450 --> 01:56:25,090
they're all it's always all sign

1633
01:56:25,820 --> 01:56:27,220
so we can define the

1634
01:56:27,350 --> 01:56:29,320
because functions

1635
01:56:29,630 --> 01:56:34,430
you start with the thing actually called primitive recursive functions by

1636
01:56:34,470 --> 01:56:37,300
got two sets of introduction so i don't know

1637
01:56:38,930 --> 01:56:43,050
the simplest sort of calculable functions are the ones that either

1638
01:56:44,300 --> 01:56:47,990
if for every argument these are functions on non so

1639
01:56:48,470 --> 01:56:50,640
not not stuff just not

1640
01:56:50,660 --> 01:56:54,070
can indeed side to

1641
01:56:55,090 --> 01:56:57,430
so the function that for every

1642
01:56:57,450 --> 01:56:59,200
input document number

1643
01:56:59,200 --> 01:57:00,470
it is zero

1644
01:57:00,490 --> 01:57:04,340
easy to compute one step can be the number to give you the answer you

1645
01:57:04,340 --> 01:57:06,430
know the number here

1646
01:57:06,550 --> 01:57:07,660
this the

1647
01:57:07,720 --> 01:57:08,890
it's clearly

1648
01:57:10,840 --> 01:57:15,510
so is the successor function in a number of one two

1649
01:57:15,550 --> 01:57:19,160
and so is the function that says taking projections

1650
01:57:19,160 --> 01:57:23,130
if we've got a whole bunch of arguments will take the attack

1651
01:57:23,160 --> 01:57:24,950
this is a list of accolades

1652
01:57:25,010 --> 01:57:29,010
we can find the odd because now given to us is always to stop this

1653
01:57:29,010 --> 01:57:31,140
through the list

1654
01:57:31,200 --> 01:57:34,610
the things are called recursive functions because of this the next

1655
01:57:34,660 --> 01:57:39,970
axioms around composition recursion k so the composition function

1656
01:57:39,990 --> 01:57:43,840
and says we can make up more complicated functions from

1657
01:57:43,890 --> 01:57:47,470
from others self we have a bunch of functions

1658
01:57:47,470 --> 01:57:49,340
h one is there

1659
01:57:49,370 --> 01:57:50,610
h one

1660
01:57:50,660 --> 01:57:52,280
through a chance

1661
01:57:52,320 --> 01:57:55,470
we can somehow the take the result loss functions

1662
01:57:55,780 --> 01:57:57,820
apply new function g

1663
01:57:57,840 --> 01:58:00,130
and we call that a new function

1664
01:58:00,180 --> 01:58:03,890
that's a lie creating new functions from old

1665
01:58:03,930 --> 01:58:06,340
is to compose

1666
01:58:08,110 --> 01:58:10,300
we want to have a way of creating

1667
01:58:10,320 --> 01:58:12,950
functions by starting from

1668
01:58:12,990 --> 01:58:15,890
what the function does when it's even

1669
01:58:15,910 --> 01:58:17,910
zero an argument

1670
01:58:17,950 --> 01:58:20,090
and then what we should do

1671
01:58:20,110 --> 01:58:23,130
if we are given the number of nonzero

1672
01:58:23,160 --> 01:58:24,630
and the answer is

1673
01:58:24,720 --> 01:58:26,990
i will do it like this

1674
01:58:27,030 --> 01:58:30,700
it's to be some particular function for zero

1675
01:58:30,740 --> 01:58:35,050
and for the successor case the case we are dealing with anything other than zero

1676
01:58:35,110 --> 01:58:37,860
it's going to work out some composition

1677
01:58:37,870 --> 01:58:40,840
of simple things

1678
01:58:40,840 --> 01:58:42,430
so we know how to

1679
01:58:42,490 --> 01:58:47,070
we didn't know how to calculate the value of f when we have expressed one

1680
01:58:47,280 --> 01:58:51,050
so that's three express one's car three

1681
01:58:52,030 --> 01:58:54,550
we don't know how to do it for zero

1682
01:58:55,610 --> 01:58:58,430
we worked our way after knowing how to do it for two

1683
01:59:01,530 --> 01:59:03,610
given that we know how to do it for two

1684
01:59:03,610 --> 01:59:04,610
in no

1685
01:59:04,610 --> 01:59:06,180
this expression here

1686
01:59:06,240 --> 01:59:09,470
as you look like that

1687
01:59:09,510 --> 01:59:12,190
taking logs and matching terms

1688
01:59:13,190 --> 01:59:16,240
initially depends on all the random variables at once

1689
01:59:16,390 --> 01:59:19,310
and these are functions just in the last couple weeks

1690
01:59:19,360 --> 01:59:22,050
this has to hold for all distributions

1691
01:59:22,070 --> 01:59:25,150
and that's the constant was as easy

1692
01:59:25,180 --> 01:59:28,150
so we just decompose

1693
01:59:28,200 --> 01:59:33,810
state in terms of orthonormal basis

1694
01:59:33,810 --> 01:59:36,930
and we just take care of those synergy

1695
01:59:36,990 --> 01:59:41,080
well then this expression here

1696
01:59:41,100 --> 01:59:43,240
can be written as such

1697
01:59:43,300 --> 01:59:44,980
because of this

1698
01:59:45,000 --> 01:59:49,150
the times the corresponding coefficients theta i has to match the right hand side

1699
01:59:49,290 --> 01:59:55,310
and this only works if f individual terms which depend on the maximal cliques

1700
01:59:55,320 --> 01:59:59,480
this has sold for all size and data

1701
01:59:59,570 --> 02:00:00,590
then you just

1702
02:00:00,630 --> 02:00:03,680
collect all those terms depending on the maximal cliques together

1703
02:00:03,700 --> 02:00:08,900
it is defined as as just feature maps on the maximal cliques themselves

1704
02:00:08,930 --> 02:00:13,370
then we can get this inner product

1705
02:00:13,390 --> 02:00:14,620
so it's really just

1706
02:00:14,700 --> 02:00:16,830
straightforward linear algebra

1707
02:00:16,830 --> 02:00:17,990
it is but

1708
02:00:18,010 --> 02:00:20,520
not deep

1709
02:00:20,570 --> 02:00:22,500
now let's take an example

1710
02:00:22,560 --> 02:00:24,380
normal distribution

1711
02:00:24,390 --> 02:00:27,340
so this is actually something that

1712
02:00:27,380 --> 02:00:29,770
martin already had on slides we didn't

1713
02:00:29,910 --> 02:00:34,950
discuss that we will show the same example but will just see it was probably

1714
02:00:34,950 --> 02:00:37,980
slightly different numbers but other than that same

1715
02:00:38,120 --> 02:00:43,150
so mean that for normal distribution of topics was just six and a six transpose

1716
02:00:43,150 --> 02:00:45,590
the only thing that kind of stuff passes now

1717
02:00:46,020 --> 02:00:49,170
all the sudden those excess of vector valued

1718
02:00:49,180 --> 02:00:52,710
everybody knows how to write it to write normal distribution

1719
02:00:53,540 --> 02:00:58,420
we would also see that will have to express first inverse covariance matrix it's time

1720
02:00:58,420 --> 02:00:59,910
for a normal distribution

1721
02:00:59,960 --> 02:01:02,770
now we know

1722
02:01:02,820 --> 02:01:09,070
that's how far must decompose into the subsets involving on undergraduates from each maximal clique

1723
02:01:09,080 --> 02:01:14,660
so i know that have normal distribution with certain conditional independence properties

1724
02:01:14,690 --> 02:01:18,300
sometimes this is called a gauss markov random field

1725
02:01:18,310 --> 02:01:20,230
so if you see somebody writing this

1726
02:01:20,250 --> 02:01:26,250
you know this is code for saying something very simple namely have a normal distribution

1727
02:01:26,260 --> 02:01:30,550
and have conditional independence properties

1728
02:01:30,620 --> 02:01:32,680
now for the linear term well that's just fine

1729
02:01:33,490 --> 02:01:38,560
it decomposes very nicely so the only really happen in terms of the excited state

1730
02:01:40,770 --> 02:01:44,430
and they correspond to an nation this graph

1731
02:01:45,150 --> 02:01:49,720
now we know that for a normal distribution we have x transpose inverse covariance matrix

1732
02:01:51,610 --> 02:01:57,410
we must not have any coupling terms between vertices that don't have any age

1733
02:01:57,430 --> 02:02:02,970
what this means is that the inverse covariance matrix has to be sparse

1734
02:02:03,770 --> 02:02:08,460
seven look

1735
02:02:09,910 --> 02:02:12,350
this is my normal distribution

1736
02:02:12,370 --> 02:02:15,270
at some coefficients theta here

1737
02:02:15,490 --> 02:02:17,190
and these must be zero

1738
02:02:17,220 --> 02:02:19,650
whenever this knowledge

1739
02:02:20,580 --> 02:02:25,620
they can just write eta two is the inverse covariance matrix

1740
02:02:25,710 --> 02:02:26,480
and then

1741
02:02:26,490 --> 02:02:28,360
well it's just leave off

1742
02:02:28,360 --> 02:02:30,240
so it's between one and two

1743
02:02:31,080 --> 02:02:32,640
so i can have those terms

1744
02:02:32,880 --> 02:02:38,060
and actually i made a mistake here

1745
02:02:38,880 --> 02:02:44,740
this should be too and this should be answers what does the numbers you

1746
02:02:46,620 --> 02:02:50,950
and there is an edge between the two and three

1747
02:02:51,000 --> 02:02:57,560
and then three four and five fully connected

1748
02:02:57,570 --> 02:03:00,470
remember sometimes you would actually right across

1749
02:03:00,490 --> 02:03:02,220
through it's adjacency matrix

1750
02:03:02,240 --> 02:03:05,220
and i've told you in addition to all that that

1751
02:03:05,230 --> 02:03:08,910
this actually makes some of the scenes this this really corresponds to gauss markov random

1752
02:03:11,200 --> 02:03:15,160
i don't it means that they have some dependence

1753
02:03:15,170 --> 02:03:21,510
so we solve large sparse linear systems before

1754
02:03:21,650 --> 02:03:24,760
they quite well

1755
02:03:24,790 --> 02:03:26,210
at least three four people

1756
02:03:28,150 --> 02:03:30,220
the use this if you do that

1757
02:03:30,260 --> 02:03:33,880
from a really good idea if you don't use just the standard matlab routine for

1758
02:03:33,880 --> 02:03:37,080
solving a linear system but use

1759
02:03:37,090 --> 02:03:40,230
eight specific sparse linear solver

1760
02:03:40,290 --> 02:03:42,960
is the sparseness cells actually much faster

1761
02:03:42,990 --> 02:03:46,930
was exploiting the fact that the linear system has lots of zero

1762
02:03:49,250 --> 02:03:53,790
system proceed this by eliminating one variable after the

1763
02:03:54,610 --> 02:03:57,160
as it so happens is exactly the same procedure

1764
02:03:57,180 --> 02:04:00,240
as the message passing algorithm

1765
02:04:00,250 --> 02:04:02,970
and we'll will get to that a little bit

1766
02:04:03,970 --> 02:04:04,790
the point

1767
02:04:04,800 --> 02:04:05,800
here is

1768
02:04:07,070 --> 02:04:10,660
the inference procedures that we've talked about in graphical models last week

1769
02:04:10,690 --> 02:04:11,440
we just

1770
02:04:11,450 --> 02:04:15,140
in the next one after the other we wanted to ensure doesn't cover was too

1771
02:04:15,140 --> 02:04:16,580
much else

1772
02:04:16,620 --> 02:04:20,650
that is the same problem that you will get if you solve linear system

1773
02:04:20,670 --> 02:04:24,380
because if you remove the wrong variable all the other variables that depends on a

1774
02:04:25,560 --> 02:04:27,760
and then you will get to really dance to

1775
02:04:27,800 --> 02:04:31,410
and it takes a long time to solve

1776
02:04:31,430 --> 02:04:33,910
and you can use the very same techniques

1777
02:04:33,920 --> 02:04:36,200
for finding a good action order

1778
02:04:36,210 --> 02:04:38,390
on the graphical model

1779
02:04:38,400 --> 02:04:42,640
and on the sparse linear system

1780
02:04:43,010 --> 02:04:43,920
so here

1781
02:04:44,140 --> 02:04:50,120
OK well

1782
02:04:51,660 --> 02:04:54,420
so let's see how we do is actually

1783
02:04:54,990 --> 02:04:56,410
really simple

1784
02:04:56,420 --> 02:04:59,100
markov chain

1785
02:04:59,100 --> 02:05:02,320
so the data and they had to law

1786
02:05:02,330 --> 02:05:04,940
of the some of my entire domain

1787
02:05:04,960 --> 02:05:10,290
now here in the markov chain have expressions which depend only on adjacent land

1788
02:05:10,290 --> 02:05:13,990
five pxtxt the first one is something

1789
02:05:14,110 --> 02:05:17,850
so this is some in of x plus one

1790
02:05:17,890 --> 02:05:20,430
have to some or all this one sixty

1791
02:05:20,450 --> 02:05:25,390
of the product over all those intuitionistic one


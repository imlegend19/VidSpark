1
00:00:00,000 --> 00:00:09,790
you guys probably sit here talk about how to kind of noxious title from my

2
00:00:09,790 --> 00:00:13,410
original research i talk where i was going to talk about

3
00:00:13,430 --> 00:00:18,140
several problems and how inference in these models can solve all your problems but

4
00:00:19,880 --> 00:00:21,470
actually don't really need this

5
00:00:22,320 --> 00:00:27,620
OK but i decided that i decided that

6
00:00:27,640 --> 00:00:32,490
first of all we still don't have enough also decided let's just talk about something

7
00:00:32,490 --> 00:00:36,330
very very simple because the end of the day and i know john i really

8
00:00:36,330 --> 00:00:41,370
tired because he really really so i about something so simple

9
00:00:41,390 --> 00:00:43,180
it's incredibly simple

10
00:00:43,190 --> 00:00:47,550
once you get the basic idea it's like very easy to understand really this talk

11
00:00:47,550 --> 00:00:52,450
should take ten minutes and it will probably take actually twenty minutes but hopefully will

12
00:00:52,450 --> 00:00:55,450
you sure happen

13
00:00:55,490 --> 00:00:56,400
here it is

14
00:00:58,440 --> 00:01:01,280
scan of paper i wrote a whole

15
00:01:01,290 --> 00:01:03,070
which is about

16
00:01:03,190 --> 00:01:04,920
almost fifteen years ago

17
00:01:06,760 --> 00:01:07,400
from this

18
00:01:07,410 --> 00:01:13,600
just an observation that very very simple classifiers perform annoyingly well on the problems so

19
00:01:13,660 --> 00:01:15,140
basically just a little

20
00:01:15,160 --> 00:01:20,760
medium scale experimental study where he majored a whole bunch

21
00:01:20,780 --> 00:01:25,730
classification algorithms on all the different problems and he concluded that

22
00:01:25,790 --> 00:01:30,090
if you don't know what the problem is before hand and ask you to bet

23
00:01:30,090 --> 00:01:31,490
on the classifier

24
00:01:31,510 --> 00:01:35,720
you're probably better off spending on a really simple classifier

25
00:01:35,730 --> 00:01:40,150
and for any in any given problem these classifiers are never at the top of

26
00:01:40,180 --> 00:01:41,990
the list but

27
00:01:42,040 --> 00:01:44,520
they consistently performs surprisingly

28
00:01:46,040 --> 00:01:51,370
i want focus today on the simplest possible classifiers which is k nearest neighbour so

29
00:01:51,370 --> 00:01:57,140
k nearest neighbour kind has a bad reputation across the country classifiers are usually uses

30
00:01:57,140 --> 00:01:59,870
k nearest neighbour is like you know the

31
00:02:00,020 --> 00:02:04,100
think that i'm going to show you my algorithm is now going to beat but

32
00:02:04,180 --> 00:02:08,760
actually k nearest neighbour has many kind of healing properties right so it's very simple

33
00:02:08,760 --> 00:02:13,170
but surprisingly effective classification procedure the decision surfaces

34
00:02:13,190 --> 00:02:19,880
automatically nonlinear it's nonparametric so it has very high capacity but you don't need to

35
00:02:19,880 --> 00:02:21,510
do anything to training

36
00:02:21,530 --> 00:02:25,310
i the quality of predictions improves

37
00:02:25,320 --> 00:02:31,090
automatically as you some very strong theoretical result this and on the face only a

38
00:02:31,090 --> 00:02:33,340
single parameter k which

39
00:02:33,440 --> 00:02:36,390
you can easily achieve by cross validation so

40
00:02:36,410 --> 00:02:40,200
he was actually an pretty pretty exciting part

41
00:02:40,340 --> 00:02:46,160
idea and so what's the problem here

42
00:02:46,170 --> 00:02:47,950
there's at least

43
00:02:47,970 --> 00:02:50,350
at least three problems

44
00:02:50,360 --> 00:02:52,220
one is

45
00:02:52,240 --> 00:02:54,540
what is the nearest mean

46
00:02:54,590 --> 00:02:57,170
so i told you k nearest neighbour

47
00:02:57,190 --> 00:02:57,930
the videos

48
00:02:57,940 --> 00:02:59,490
the nearest neighbour

49
00:02:59,500 --> 00:03:01,780
classifier they take the point

50
00:03:01,800 --> 00:03:07,150
you find the k nearest training examples to the test and in the majority vote

51
00:03:07,150 --> 00:03:09,570
of their labels

52
00:03:10,150 --> 00:03:15,380
we need to define what you're saying that requires a scientist very important for

53
00:03:15,430 --> 00:03:19,320
so this is where things get a little bit and we will usually be just

54
00:03:19,320 --> 00:03:24,950
say well you know normalized features some kind of way that my cousin told me

55
00:03:24,950 --> 00:03:28,810
it's good idea and then i'm going to the euclidean distance in that space and

56
00:03:28,810 --> 00:03:33,050
time to pretend that everything will be OK but seems a little bit unsatisfying summary

57
00:03:33,060 --> 00:03:37,850
principles just arbitrary defines distance anyway even if you have

58
00:03:37,860 --> 00:03:41,030
it could just be another problem which is

59
00:03:41,040 --> 00:03:43,730
i do actually find the k nearest neighbors

60
00:03:43,780 --> 00:03:48,250
the difficulty is that you know that people are using our huge hundreds of thousands

61
00:03:48,250 --> 00:03:52,720
of the training examples and so you really need search through all of these examples

62
00:03:53,070 --> 00:03:54,330
test site

63
00:03:54,340 --> 00:03:57,740
and furthermore is really going to carry them around in your suitcase with you when

64
00:03:57,740 --> 00:03:59,900
you deploy your classifier is OK

65
00:04:00,280 --> 00:04:03,040
he said my classifier but you

66
00:04:03,360 --> 00:04:07,260
x your hard drive has the training because of problem class

67
00:04:07,310 --> 00:04:12,490
well there's also a very good idea so i would like to improve on these

68
00:04:12,490 --> 00:04:14,360
things you like to somehow

69
00:04:14,360 --> 00:04:15,930
dance in the middle

70
00:04:15,970 --> 00:04:17,300
the first years

71
00:04:17,320 --> 00:04:20,700
and it's very sparse on the outside and that's in that region

72
00:04:20,720 --> 00:04:21,570
of the

73
00:04:21,590 --> 00:04:23,970
visual cortex v one

74
00:04:23,980 --> 00:04:26,940
like that in a way that makes this

75
00:04:26,950 --> 00:04:33,130
sprints the central region that comprises the outside regions also noted is half circle here

76
00:04:33,130 --> 00:04:37,860
affect the left right halves of two eyes are mapped to the left to right

77
00:04:37,860 --> 00:04:41,100
and left halves your brain so they separated

78
00:04:41,130 --> 00:04:44,900
so you actually first-half field in each of the brain

79
00:04:44,910 --> 00:04:48,740
so the effect that if you look at this this image here which just to

80
00:04:48,740 --> 00:04:52,130
zoom and has an idea there is that you see

81
00:04:52,170 --> 00:04:54,100
this kind of mapping

82
00:04:54,110 --> 00:04:56,550
so very very high central reservation

83
00:04:56,560 --> 00:04:59,550
that's a much lower resolution outside

84
00:04:59,600 --> 00:05:04,410
the effect that if you focus on the dot here

85
00:05:04,440 --> 00:05:09,110
you should be able to have approximately the same ability to read and they all

86
00:05:09,110 --> 00:05:10,320
of the letters

87
00:05:10,320 --> 00:05:13,380
OK so that same year resolution near the centre

88
00:05:13,400 --> 00:05:17,960
is much higher than your resolution outside is probably depends a little bit on distance

89
00:05:18,050 --> 00:05:23,440
much of work for here the other thing is so that's the sound spatial sampling

90
00:05:23,440 --> 00:05:27,210
density and the other thing is that there's multiscale in terms of precision in terms

91
00:05:27,210 --> 00:05:28,480
of frequency

92
00:05:28,510 --> 00:05:33,830
in the brain so you frequency response to spatial frequency is depends on something you

93
00:05:33,830 --> 00:05:35,800
should see the kind of harm here

94
00:05:36,210 --> 00:05:38,940
possibly it's amazing stuff that you could ignore

95
00:05:38,990 --> 00:05:41,640
your i has a peak

96
00:05:41,660 --> 00:05:43,020
spatial frequency

97
00:05:44,270 --> 00:05:49,410
around here with the spirit of about three octaves so just don't see spatial frequencies

98
00:05:49,410 --> 00:05:50,870
the outside that too low

99
00:05:51,270 --> 00:05:55,560
they get removed by the system to to i don't know the resolution see

100
00:05:59,090 --> 00:06:00,400
and then finally

101
00:06:00,430 --> 00:06:02,590
some stuff about how

102
00:06:02,590 --> 00:06:05,940
we kind of construct picture of visual world

103
00:06:05,960 --> 00:06:08,690
OK so

104
00:06:08,740 --> 00:06:12,290
you might think OK which take an image and then interpret the image does not

105
00:06:12,290 --> 00:06:16,510
really like that human vision is very much driven by cycad so your eyes are

106
00:06:16,510 --> 00:06:21,330
continually flipping from one part of the same to another analyzing it for a few

107
00:06:21,330 --> 00:06:25,660
milliseconds and and the thing to another part of the same so

108
00:06:25,710 --> 00:06:31,110
and that's used to together with very nonuniform spatial resolution of the i to get

109
00:06:31,110 --> 00:06:35,130
a kind of zoom in on particular points of the scene with some kind of

110
00:06:35,130 --> 00:06:36,520
context around it

111
00:06:36,810 --> 00:06:41,430
so what you do is you construct your mental picture out of the series of

112
00:06:41,460 --> 00:06:45,580
which you very piecewise kind of representation we don't have that impression when you're walking

113
00:06:45,580 --> 00:06:49,650
around the world you don't have to stop and think oh gosh need to look

114
00:06:49,650 --> 00:06:53,940
somewhere else you just have the impression of surrounding seen this this kind of uniform

115
00:06:53,940 --> 00:06:57,150
and well-defined but you're your eyes not like that

116
00:06:57,540 --> 00:07:02,670
OK have ha

117
00:07:02,680 --> 00:07:06,650
right but first we have here this account course driven by ten to mechanisms they

118
00:07:06,650 --> 00:07:09,210
tend to focus on things that are important in the scene

119
00:07:09,260 --> 00:07:14,570
another thing that's actually took a the people want to understand is that even when

120
00:07:14,570 --> 00:07:16,590
your eye is fixed on

121
00:07:16,640 --> 00:07:17,690
o point

122
00:07:17,710 --> 00:07:21,240
it's never stationary this ways doing a little bit of juggling

123
00:07:21,250 --> 00:07:22,790
article microsd cards

124
00:07:22,800 --> 00:07:24,460
that allows

125
00:07:24,480 --> 00:07:28,130
the right to do better spatial resolution

126
00:07:28,190 --> 00:07:32,370
typically if she in terms of images you can resolve out of pixel

127
00:07:32,410 --> 00:07:37,110
but if you stop moving your camera a little that you can resolve maybe ten

128
00:07:37,160 --> 00:07:39,950
pixel if you move it off by averaging

129
00:07:40,020 --> 00:07:44,650
signals of the spatial positions so this gives you the factor of maybe five or

130
00:07:44,650 --> 00:07:47,150
spatial acuity the otherwise would have

131
00:07:47,170 --> 00:07:53,040
and it happens all the time is something something around actually does

132
00:07:53,050 --> 00:07:57,010
so all of that requires some kind of temporal persistence and model what's going on

133
00:07:57,010 --> 00:08:02,170
you can of integrate the of space to make into this model secondly i love

134
00:08:02,170 --> 00:08:03,820
you that what you see is

135
00:08:03,840 --> 00:08:10,030
basically driven by subconscious processes so stuff that you don't see like grouping together and

136
00:08:10,030 --> 00:08:16,310
relevant elements completing contours removing shadows all this kind of thing gets done by your

137
00:08:16,980 --> 00:08:20,730
and you just you just don't see that happens nevertheless

138
00:08:20,780 --> 00:08:23,060
so you don't notice all these things

139
00:08:23,110 --> 00:08:28,990
this just some examples cont conclusion conclusion is classic things so you'll see a nice

140
00:08:28,990 --> 00:08:30,530
white triangle here

141
00:08:30,860 --> 00:08:34,740
even though in fact there is no context given the triangle is just that they've

142
00:08:34,750 --> 00:08:39,740
got some pieces of content here your brain completes to make these things here you'll

143
00:08:39,740 --> 00:08:41,890
see there's actually two illusions here one

144
00:08:41,930 --> 00:08:46,100
is that you will see that the cube can be very very easily was not

145
00:08:46,100 --> 00:08:51,440
completed here the second cube so if you look at it for a few seconds

146
00:08:51,700 --> 00:08:53,810
to find it tends to that

147
00:08:57,010 --> 00:09:00,020
either this one will be at the front and this one will be back with

148
00:09:01,350 --> 00:09:04,730
so your your brain simply accommodating to that signal

149
00:09:04,730 --> 00:09:07,510
and when it gets used to it and decides going to flip because it needs

150
00:09:07,510 --> 00:09:12,880
to find a different interpretation of something similar figure ground segmentations very dependent on the

151
00:09:12,880 --> 00:09:17,330
exact context it's just the white and black transitions and changes your interpretation of what's

152
00:09:17,330 --> 00:09:20,130
figure and ground here

153
00:09:21,400 --> 00:09:24,150
again the level context is

154
00:09:24,150 --> 00:09:27,100
but is about one point four one

155
00:09:27,260 --> 00:09:29,950
so only

156
00:09:30,030 --> 00:09:31,680
and i got only four

157
00:09:31,730 --> 00:09:35,400
so i get sixty degrees

158
00:09:37,020 --> 00:09:40,740
can only be approximated again by about one point seven

159
00:09:40,830 --> 00:09:43,260
omega zero

160
00:09:43,320 --> 00:09:47,030
and then i have only got five which is the last

161
00:09:47,040 --> 00:09:48,450
so i get signed

162
00:09:48,490 --> 00:09:50,980
seventy five degrees

163
00:09:50,980 --> 00:09:52,530
that becomes

164
00:09:52,590 --> 00:09:54,420
three point seven three

165
00:09:56,490 --> 00:10:00,960
one point nine three

166
00:10:01,000 --> 00:10:02,450
one point nine three

167
00:10:08,410 --> 00:10:12,850
what i want to concentrate on because that's part of the demonstration

168
00:10:12,910 --> 00:10:16,010
it's not so much on the meaning of omega zero

169
00:10:16,100 --> 00:10:18,740
to some arbitrary

170
00:10:18,740 --> 00:10:20,040
they i called

171
00:10:20,060 --> 00:10:21,160
omega zero

172
00:10:21,160 --> 00:10:23,190
but i want to concentrate his u

173
00:10:23,200 --> 00:10:29,020
on the ratios of the higher frequencies below lower one

174
00:10:29,140 --> 00:10:31,540
so i called the lowest one

175
00:10:31,600 --> 00:10:33,350
omega one

176
00:10:33,410 --> 00:10:36,970
simply called is omega what

177
00:10:37,020 --> 00:10:39,380
if that one is only one

178
00:10:39,410 --> 00:10:43,280
then the next one is one point nine three o one

179
00:10:43,340 --> 00:10:45,250
not exactly

180
00:10:46,560 --> 00:10:49,110
it is this one divided by four five one

181
00:10:49,220 --> 00:10:50,680
the ratio now

182
00:10:50,780 --> 00:10:54,330
the of the tree

183
00:10:54,390 --> 00:10:57,410
and if i think this one divided by the one that i get to point

184
00:10:57,410 --> 00:10:59,700
seven three

185
00:10:59,860 --> 00:11:04,580
we've got one that i think the next one

186
00:11:04,600 --> 00:11:07,460
i get three point three five

187
00:11:07,610 --> 00:11:11,760
and the last one then

188
00:11:11,770 --> 00:11:14,220
if three point seven three

189
00:11:14,290 --> 00:11:20,060
so the bottom line is

190
00:11:20,110 --> 00:11:22,450
that the ratio of these frequencies

191
00:11:22,530 --> 00:11:26,210
not all very nice numbers as you may have expected

192
00:11:26,250 --> 00:11:28,940
but the ratios are quite bizarre

193
00:11:29,020 --> 00:11:32,860
o point nine three times higher than the lowest one two point seven three times

194
00:11:32,860 --> 00:11:38,750
higher three point three five times higher than three point seven three

195
00:11:38,800 --> 00:11:40,300
so the general

196
00:11:42,230 --> 00:11:44,150
two that system

197
00:11:44,190 --> 00:11:48,390
is the linear superposition of all these normal modes

198
00:11:48,400 --> 00:11:50,560
the general solution

199
00:11:50,650 --> 00:11:53,090
you give them very modest amplitudes

200
00:11:53,140 --> 00:11:54,800
and you can choose

201
00:11:54,890 --> 00:11:58,150
the amplitude of each one of them

202
00:11:58,150 --> 00:12:02,240
that's effective let's say you're using c one c two c three c four c

203
00:12:05,860 --> 00:12:11,000
and you also can give the initial velocities if you want to sort equals zero

204
00:12:11,020 --> 00:12:13,280
they do not have to stand still

205
00:12:13,330 --> 00:12:15,070
you have the choice to of course

206
00:12:15,080 --> 00:12:17,330
so we can change the relative face

207
00:12:17,340 --> 00:12:18,650
three to five

208
00:12:18,650 --> 00:12:21,910
different modes

209
00:12:21,950 --> 00:12:23,260
what i will do

210
00:12:23,280 --> 00:12:25,830
it is i will to make life simple

211
00:12:25,920 --> 00:12:29,340
i will generate all five normal modes for you

212
00:12:29,360 --> 00:12:32,970
and i will start them off all at zero speed when i

213
00:12:33,010 --> 00:12:35,820
so you the simulation

214
00:12:35,830 --> 00:12:40,130
the the first one that i'm going to show you that is number one

215
00:12:40,130 --> 00:12:42,970
now i'm going to show you number two

216
00:12:42,980 --> 00:12:46,890
i want you to appreciate that if i showed you the superposition of one and

217
00:12:47,820 --> 00:12:49,680
so i

218
00:12:49,920 --> 00:12:52,500
also made in this mode in this mode

219
00:12:52,520 --> 00:12:56,180
i started off at a certain position of these particles

220
00:12:56,200 --> 00:12:59,080
and they start to oscillate in this mode and that money

221
00:12:59,310 --> 00:13:02,480
the shape that i have never

222
00:13:03,720 --> 00:13:05,330
become the same as it was

223
00:13:05,350 --> 00:13:06,420
time zero

224
00:13:06,440 --> 00:13:08,040
why is that

225
00:13:08,160 --> 00:13:11,980
this letter also maybe you can write a hundred billion years you will never see

226
00:13:11,980 --> 00:13:14,210
the station

227
00:13:14,220 --> 00:13:17,150
i start with a certain shape

228
00:13:17,210 --> 00:13:19,930
and will never ever

229
00:13:19,990 --> 00:13:22,990
ever come back to that you why that

230
00:13:25,260 --> 00:13:28,340
right at the site of fifty degrees is the killer

231
00:13:28,360 --> 00:13:29,820
that's not the ratio

232
00:13:29,840 --> 00:13:32,990
of two integers and therefore you will never get it back to the same position

233
00:13:32,990 --> 00:13:34,520
made of approximately

234
00:13:34,530 --> 00:13:39,990
but you never get it back

235
00:13:39,990 --> 00:13:41,970
this demonstration is going to be

236
00:13:41,980 --> 00:13:43,860
cocktail between

237
00:13:43,860 --> 00:13:47,740
what do you see red because there's only one coming from this part

238
00:13:47,800 --> 00:13:49,550
you bring red

239
00:13:49,590 --> 00:13:52,740
well you see green here the only green because your brain

240
00:13:52,820 --> 00:13:57,200
the green because there's no article caller coming

241
00:13:57,220 --> 00:14:00,840
if i rotate it that this very fact

242
00:14:00,880 --> 00:14:05,220
your brain will get so confused because they will see the caller coming from one

243
00:14:05,220 --> 00:14:07,990
location all colors simultaneously

244
00:14:08,070 --> 00:14:10,260
you see white light again

245
00:14:10,260 --> 00:14:11,510
so that's what i

246
00:14:11,590 --> 00:14:13,450
i will do next

247
00:14:13,510 --> 00:14:17,800
and the first we get some light on that

248
00:14:17,800 --> 00:14:20,260
this no make dark

249
00:14:20,280 --> 00:14:26,110
the rooms not completely dark with almost dark

250
00:14:26,150 --> 00:14:28,650
nelson then that very fast

251
00:14:28,700 --> 00:14:32,110
and you will see that you have a new idea of colors going to fade

252
00:14:32,800 --> 00:14:35,130
i'm going to call us anymore

253
00:14:35,180 --> 00:14:40,050
which proves my point if you see colours from the same direction of the color

254
00:14:40,110 --> 00:14:40,990
your brain

255
00:14:42,240 --> 00:14:43,240
the brain state

256
00:14:43,780 --> 00:14:47,840
white light

257
00:14:47,920 --> 00:14:48,930
see that

258
00:14:49,110 --> 00:15:00,820
this is not part of polarisation

259
00:15:00,820 --> 00:15:03,280
this has nothing to do with polarisation

260
00:15:03,280 --> 00:15:05,420
but i want you to understand

261
00:15:05,430 --> 00:15:07,780
a lot of trouble

262
00:15:07,900 --> 00:15:09,420
is a little bit

263
00:15:11,430 --> 00:15:12,740
president except

264
00:15:12,740 --> 00:15:15,220
that it doesn't have this shape

265
00:15:15,260 --> 00:15:16,010
it is

266
00:15:16,030 --> 00:15:18,530
he has this shape

267
00:15:20,880 --> 00:15:22,180
different shapes

268
00:15:22,200 --> 00:15:23,740
you can make the colors

269
00:15:23,760 --> 00:15:27,700
separate articles can be composed columns and that's what's happening

270
00:15:27,740 --> 00:15:29,010
with rain

271
00:15:29,010 --> 00:15:30,150
so now

272
00:15:30,150 --> 00:15:31,680
what i will do for you

273
00:15:31,740 --> 00:15:34,090
i will make for use something like

274
00:15:35,570 --> 00:15:38,110
it's not exactly right

275
00:15:38,400 --> 00:15:41,380
like ring

276
00:15:41,430 --> 00:15:44,430
and i will do it was one one

277
00:15:44,490 --> 00:15:48,260
because if i made of reindeer twenty six one

278
00:15:48,320 --> 00:15:49,740
you will never come back

279
00:15:49,740 --> 00:15:51,470
we can do

280
00:15:51,490 --> 00:15:55,220
so we have one one there are these

281
00:15:55,220 --> 00:15:59,650
the glass sphere

282
00:15:59,720 --> 00:16:02,630
and we're going to shine an enormous amount of light

283
00:16:02,680 --> 00:16:05,360
right in your face

284
00:16:05,360 --> 00:16:08,220
it's this one of

285
00:16:08,240 --> 00:16:12,530
i will some of it will reflect on the back and we'll come back

286
00:16:12,570 --> 00:16:14,950
you will see here

287
00:16:16,380 --> 00:16:18,380
we ran on the outside

288
00:16:18,450 --> 00:16:22,010
inside you will thank you see

289
00:16:22,070 --> 00:16:25,280
it is indeed very similar

290
00:16:25,340 --> 00:16:26,380
i can't

291
00:16:26,430 --> 00:16:28,380
chinese light into your face

292
00:16:28,400 --> 00:16:29,740
so i have to

293
00:16:29,820 --> 00:16:32,400
the cover over it otherwise

294
00:16:32,450 --> 00:16:35,030
will not come back either

295
00:16:35,160 --> 00:16:39,240
and the the hospital

296
00:16:44,470 --> 00:16:46,280
the light on this

297
00:16:46,340 --> 00:16:49,680
screen will be extremely faint

298
00:16:49,680 --> 00:16:54,340
what do you expect to use on one one

299
00:16:54,380 --> 00:16:57,680
and that's face how much did you pay for this line

300
00:16:57,680 --> 00:17:00,050
right can you can which forever

301
00:17:00,150 --> 00:17:03,880
so it's going to be extremely faint

302
00:17:03,930 --> 00:17:05,360
but it will be poor

303
00:17:05,380 --> 00:17:07,220
and i will show you the four

304
00:17:07,300 --> 00:17:09,090
along the arc

305
00:17:09,150 --> 00:17:11,340
you can use your own arises

306
00:17:11,360 --> 00:17:13,200
because once the light here

307
00:17:13,240 --> 00:17:15,970
it comes back to you it loses the election

308
00:17:15,970 --> 00:17:21,530
vision maybe not for one the percent all more

309
00:17:21,590 --> 00:17:25,280
i'll give you thirty seconds for your eyes to get used to be

310
00:17:26,470 --> 00:17:30,380
i don't do that you won't see anything because it's very thing

311
00:17:30,400 --> 00:17:32,180
and then

312
00:17:32,260 --> 00:17:33,280
i will

313
00:17:33,300 --> 00:17:35,800
show you with my parameters

314
00:17:35,800 --> 00:17:39,650
you are cured i can rotate around

315
00:17:39,650 --> 00:17:40,630
and i can

316
00:17:40,680 --> 00:17:43,340
just in the right direction killed light

317
00:17:43,380 --> 00:17:44,490
of the art

318
00:17:44,530 --> 00:17:47,240
related through

319
00:17:47,280 --> 00:17:48,550
right so the first thing

320
00:17:48,570 --> 00:17:52,240
your eyes have to get used to the dark

321
00:17:52,280 --> 00:17:53,990
one is like there

322
00:17:54,110 --> 00:17:59,650
two and off

323
00:17:59,720 --> 00:18:04,470
give it a little bit of time

324
00:18:04,490 --> 00:18:05,240
i for the video

325
00:18:24,470 --> 00:18:28,800
it is

326
00:18:29,760 --> 00:18:32,510
there is you're park

327
00:18:32,510 --> 00:18:35,450
you see it

328
00:18:35,570 --> 00:18:38,300
just so you can see here

329
00:18:38,300 --> 00:18:41,000
so the x's are locations where i measure

330
00:18:41,100 --> 00:18:42,470
namely the members of the

331
00:18:42,480 --> 00:18:47,560
OK would be the covariance matrix and what you would assume is that you have

332
00:18:48,660 --> 00:18:50,930
nonzero terms in the covariance

333
00:18:51,930 --> 00:18:54,390
parts that actually share an edge

334
00:18:54,410 --> 00:18:59,040
so let me just put another hot in here to make things will be easier

335
00:18:59,080 --> 00:19:01,040
what you will get is that

336
00:19:01,930 --> 00:19:03,930
in the covariance matrix and k

337
00:19:03,930 --> 00:19:07,880
i would have nonzero term for the internet say that two and three

338
00:19:07,890 --> 00:19:09,930
one two three four

339
00:19:09,930 --> 00:19:11,440
five six

340
00:19:15,380 --> 00:19:20,120
and so my covariance matrix so will have a nonzero terms between one and three

341
00:19:20,170 --> 00:19:23,660
one between two and three one between three and four and so on

342
00:19:23,720 --> 00:19:27,600
they can translate this directly into the matrix and do inference

343
00:19:27,790 --> 00:19:39,510
people doing this often talk about cars gauss markov random fields

344
00:19:39,560 --> 00:19:41,980
they write entire books about it

345
00:19:42,030 --> 00:19:45,990
as if it were something very special and very different from everything else

346
00:19:46,050 --> 00:19:47,240
which is that

347
00:19:47,300 --> 00:19:49,740
so don't be scared somebody talks about it

348
00:19:49,800 --> 00:19:54,670
all this does is it just means for many cases you can actually

349
00:19:54,680 --> 00:19:59,950
get away with matrix inversion where otherwise you would have to the something expensive

350
00:20:01,130 --> 00:20:03,490
so this is where my covariance matrix come from

351
00:20:03,600 --> 00:20:07,410
so these these would be the voltage is that majoring here

352
00:20:07,470 --> 00:20:10,720
but since my voltmeter is unreliable

353
00:20:10,730 --> 00:20:15,320
so i go with my multimeter here

354
00:20:15,420 --> 00:20:17,420
played in there and then i see

355
00:20:17,470 --> 00:20:18,490
maybe this

356
00:20:18,490 --> 00:20:19,680
two hundred and

357
00:20:19,720 --> 00:20:21,490
fifteen volts

358
00:20:22,430 --> 00:20:24,200
what i'm really observing

359
00:20:24,230 --> 00:20:27,390
maybe next played in here i will get the difference

360
00:20:28,610 --> 00:20:30,500
so why is this

361
00:20:30,550 --> 00:20:32,220
he will be that

362
00:20:32,230 --> 00:20:35,970
these locations will be there exists

363
00:20:42,240 --> 00:20:45,870
the mean of y would be t

364
00:20:45,930 --> 00:20:48,120
sorry sir sorry

365
00:20:50,700 --> 00:20:51,810
of course

366
00:20:53,550 --> 00:20:54,750
stewart was

367
00:20:54,760 --> 00:20:59,100
paying attention to the told me that before the break

368
00:20:59,120 --> 00:21:01,660
OK so

369
00:21:01,680 --> 00:21:05,670
what is basic and

370
00:21:05,680 --> 00:21:07,680
he actually would have a pretty good

371
00:21:07,680 --> 00:21:09,420
the reason to assume some u

372
00:21:09,430 --> 00:21:12,560
i could for instance assume that this is uniform at least if i have a

373
00:21:12,560 --> 00:21:13,620
good network

374
00:21:13,680 --> 00:21:16,480
and i would assume that this is just before the voltage

375
00:21:16,620 --> 00:21:19,870
you can find in australia which i think at the moment is like two hundred

376
00:21:19,870 --> 00:21:22,000
thirty watts

377
00:21:24,140 --> 00:21:25,980
basically the victim you

378
00:21:25,990 --> 00:21:29,390
what be just two hundred thirteen

379
00:21:29,410 --> 00:21:30,450
two thirty

380
00:21:30,470 --> 00:21:32,600
and so on and so on

381
00:21:32,610 --> 00:21:38,660
maybe a slightly better assumption would be if this is where i think connect two

382
00:21:39,720 --> 00:21:42,580
actually my

383
00:21:42,630 --> 00:21:44,810
a power supply

384
00:21:45,780 --> 00:21:48,890
well i could assume that maybe the will to a little bit lower they wouldn't

385
00:21:48,890 --> 00:21:55,560
pick exactly to thirty but maybe over there have pick something like two twenty five

386
00:21:55,580 --> 00:21:59,380
but again the surprise so you can always learn

387
00:22:15,210 --> 00:22:18,380
but this is why you will get the covariance matrix

388
00:22:18,460 --> 00:22:22,270
which has a nonzero terms all the way along the edges

389
00:22:22,300 --> 00:22:24,550
so if you don't observe those variables

390
00:22:24,560 --> 00:22:30,630
you look at the remaining covariance matrix this will actually make things correlate

391
00:22:30,640 --> 00:22:32,550
because what happens is

392
00:22:33,510 --> 00:22:36,970
we have basically

393
00:22:37,030 --> 00:22:39,230
x well sorry

394
00:22:39,250 --> 00:22:41,080
t minus mu

395
00:22:42,190 --> 00:22:43,860
OK inverse

396
00:22:43,950 --> 00:22:45,800
he wants me

397
00:22:45,810 --> 00:22:49,450
so if you take a sparse matrix in inverted you will get things

398
00:22:50,440 --> 00:22:52,630
so you get things feelings

399
00:22:52,700 --> 00:22:54,340
which actually tells you

400
00:22:54,350 --> 00:22:59,260
that you will get correlation between longer range ranges

401
00:22:59,270 --> 00:23:02,930
now the nice thing of this piece here is

402
00:23:02,930 --> 00:23:05,520
those of you who have fundamental analysis

403
00:23:05,530 --> 00:23:06,460
you will know

404
00:23:06,570 --> 00:23:10,610
the matrix with that sparse structure is very easy to solve

405
00:23:10,690 --> 00:23:14,890
because you can basically to variable elimination by going for this is that these two

406
00:23:14,890 --> 00:23:18,560
variables and you can eliminate for this it just pile of things that the aliens

407
00:23:18,560 --> 00:23:20,400
as you go along

408
00:23:20,450 --> 00:23:22,850
you can use exactly the same procedure two

409
00:23:22,910 --> 00:23:25,680
deal with the inverse of this matrix

410
00:23:25,730 --> 00:23:27,020
never even

411
00:23:27,060 --> 00:23:30,190
in that case if you have such beautiful representation

412
00:23:30,200 --> 00:23:33,010
right OK inverse explicitly

413
00:23:33,060 --> 00:23:35,190
always deal with k inverse

414
00:23:35,210 --> 00:23:39,530
through the implementation of an algorithm

415
00:23:39,590 --> 00:23:42,080
because in this case actually solving

416
00:23:42,140 --> 00:23:44,730
OK inverse times t minus mu

417
00:23:44,790 --> 00:23:48,690
is an order of in of operation because the tree

418
00:23:48,700 --> 00:23:54,500
whereas writing out that matrix explicitly will be in order for in square operations

419
00:23:54,510 --> 00:24:00,230
so you're completely screwed if you actually in right that matrix out

420
00:24:00,260 --> 00:24:04,810
never do that people will run out of memory for reasonable problems

421
00:24:04,860 --> 00:24:07,940
there is a corollary to that in graphical models

422
00:24:07,950 --> 00:24:11,660
and then you would have message passing so you will see exactly the same structure

423
00:24:11,660 --> 00:24:14,750
game messages going all the way around

424
00:24:19,140 --> 00:24:21,400
but the very same ideas

425
00:24:21,440 --> 00:24:23,110
that you would get four

426
00:24:23,170 --> 00:24:27,580
gauss in markov random fields he would have in general

427
00:24:27,590 --> 00:24:29,680
except that the theme

428
00:24:29,720 --> 00:24:34,380
variable elimination isn't quite that easy anymore because it's not all quadratic

429
00:24:34,390 --> 00:24:36,130
that's really the only difference

430
00:24:36,180 --> 00:24:39,540
the for instance win and was talking about message passing today

431
00:24:39,550 --> 00:24:41,950
and particle filtering

432
00:24:41,950 --> 00:24:42,580
i'll push on

433
00:24:44,260 --> 00:24:46,770
with the case and notation reminder

434
00:24:47,260 --> 00:24:48,650
we're gonna be using all

435
00:24:49,440 --> 00:24:50,810
some of these guys now so

436
00:24:51,750 --> 00:24:53,200
as well as what we used last time

437
00:24:54,490 --> 00:24:54,910
we've got

438
00:24:56,000 --> 00:24:56,850
the similarity

439
00:24:57,400 --> 00:24:58,270
now came for me

440
00:24:58,670 --> 00:25:04,050
it is three things it's a similarity matrix is a covariance matrix and its the kernel matrix

441
00:25:05,690 --> 00:25:07,790
ages the what i

442
00:25:08,400 --> 00:25:10,720
felt have the slides on this time last time i

443
00:25:11,190 --> 00:25:12,200
i found them in this deck

444
00:25:12,650 --> 00:25:14,300
they were in the wrong place so all

445
00:25:14,710 --> 00:25:16,790
go through the centering matrix idea a little bit

446
00:25:17,820 --> 00:25:20,330
and then the key thing is the sentence similarity

447
00:25:21,410 --> 00:25:27,120
or kernel or covariance be used beef about follows a model you can baby's notation

448
00:25:27,900 --> 00:25:29,620
and then we get at some point need the

449
00:25:30,110 --> 00:25:33,280
the graph laplacian so will use alpha that's

450
00:25:33,570 --> 00:25:35,290
so today is more about them

451
00:25:35,760 --> 00:25:39,070
spectral approaches to dimensionality reduction we gonna pick up

452
00:25:39,810 --> 00:25:41,430
where we left off last time

453
00:25:42,500 --> 00:25:43,180
so just the

454
00:25:44,000 --> 00:25:45,700
the slides i was missing where

455
00:25:46,460 --> 00:25:49,300
these ones considered the matrix form the squared distance

456
00:25:49,810 --> 00:25:53,080
so if you've got a few computing distances in data space

457
00:25:53,530 --> 00:25:55,640
this is how you might write them in a matrix form

458
00:25:56,230 --> 00:25:58,360
the diagonal the inner product matrix

459
00:25:59,270 --> 00:26:02,660
as a vector that's what operation is a poster indicate

460
00:26:04,010 --> 00:26:04,640
times the

461
00:26:05,810 --> 00:26:06,880
the vector ones

462
00:26:07,410 --> 00:26:12,650
minus two times in a product plus one times the diagonal any other way so this is

463
00:26:13,090 --> 00:26:17,570
they from this part you get the centre while i transpose why i hear you

464
00:26:17,570 --> 00:26:20,040
get the minus two why i transpose why jay

465
00:26:20,500 --> 00:26:23,270
and here you get plus why jay transpose why jay

466
00:26:24,170 --> 00:26:25,000
in your matrix

467
00:26:26,730 --> 00:26:30,040
i don't know i know i think i've spoken to about not about this before

468
00:26:30,040 --> 00:26:34,760
and then he feels like matrix things the less clear and i feel able clear

469
00:26:35,690 --> 00:26:36,020
there you go

470
00:26:37,160 --> 00:26:39,520
it's certainly much easier to do derivations on

471
00:26:40,070 --> 00:26:43,140
and one other derivations which is the one i showed you last time

472
00:26:44,630 --> 00:26:47,210
what happens when you send the distance matrix

473
00:26:47,950 --> 00:26:52,610
so this centering operation the centering matrix has this form which we talked about last time

474
00:26:53,330 --> 00:26:55,770
what this if you multiply this by on

475
00:26:56,800 --> 00:26:57,510
the matrix why

476
00:27:00,030 --> 00:27:03,560
you get why minus one overran times

477
00:27:03,970 --> 00:27:07,640
why times one why times one just sums otherwise together

478
00:27:08,850 --> 00:27:13,760
and then this one transposed maps back out again so just means you've got eight

479
00:27:13,760 --> 00:27:19,430
why minus vector see this in matlab right you do this regret matter operation this

480
00:27:19,470 --> 00:27:24,340
evil operation in matlab to send your data copy the mean down a hundred times

481
00:27:24,340 --> 00:27:28,010
to avoid using a loop is matlab disgusting language on

482
00:27:28,730 --> 00:27:34,270
hands this is the main affect the matrix where writing down this isn't how you should compute these things

483
00:27:35,170 --> 00:27:39,030
obviously but it's a nice convenient way of writing nothing you're doing in matlab if

484
00:27:39,030 --> 00:27:41,430
you subtracting the mean from the data and its

485
00:27:42,040 --> 00:27:46,830
denoted in statistics age is called the centering matrix and when you multiply age

486
00:27:47,240 --> 00:27:50,900
he decided these guys eliminates these two terms and just gives u

487
00:27:51,350 --> 00:27:53,170
this why have why had transpose

488
00:27:54,550 --> 00:28:00,330
so the centre square distance matrix is is closely related to the sentence similarity or kernel

489
00:28:02,280 --> 00:28:03,490
so i want to use an example

490
00:28:04,480 --> 00:28:09,330
so might think what all this distance is going about his a classic statistical example

491
00:28:09,770 --> 00:28:12,960
when you're given distances and how you project them so

492
00:28:13,520 --> 00:28:16,820
we redraw a road map a map from road distances

493
00:28:17,250 --> 00:28:21,690
so what we're gonna have is using distances across europe and all we know is

494
00:28:21,700 --> 00:28:23,830
city names and what the distance between

495
00:28:24,450 --> 00:28:26,090
those different cities is yeah

496
00:28:26,550 --> 00:28:28,610
so that we can guess squared distance matrix

497
00:28:29,290 --> 00:28:31,430
we've got the distance between london and edinburgh

498
00:28:32,250 --> 00:28:33,430
a number in paris

499
00:28:34,260 --> 00:28:36,550
and in terms of road distance traveled

500
00:28:37,410 --> 00:28:37,830
and you can

501
00:28:38,640 --> 00:28:39,420
i've got some data

502
00:28:42,040 --> 00:28:45,000
and then you could also know the actual location of these things so what you

503
00:28:45,000 --> 00:28:50,000
can try and do it well you can visualize these distances and ideally they should

504
00:28:50,000 --> 00:28:52,250
look something similar to the map of europe

505
00:28:53,890 --> 00:28:59,540
what we do is we enter all road distances in the distance matrix we square directly using squared distances

506
00:29:00,210 --> 00:29:04,830
and we convert to this similarity matrix a can told you about the convergence interpretation

507
00:29:04,830 --> 00:29:09,600
but the outcome of the moment we converted the similarity matrix using this operation on

508
00:29:09,600 --> 00:29:10,350
the distances

509
00:29:11,260 --> 00:29:13,000
and then you have two times by minus two

510
00:29:13,640 --> 00:29:18,770
and then you do the i can decomposition because we know that minimizes this entrywise

511
00:29:18,770 --> 00:29:20,920
one number b

512
00:29:20,960 --> 00:29:23,000
three for each

513
00:29:24,240 --> 00:29:30,710
nine these seventy were seldom like much

514
00:29:30,720 --> 00:29:33,030
and i can

515
00:29:33,080 --> 00:29:38,590
work with those numbers and never made another function

516
00:29:38,610 --> 00:29:42,210
but so that's really the

517
00:29:43,470 --> 00:29:46,200
the idea is that the

518
00:29:47,360 --> 00:29:52,020
everything now is seen in terms of those coefficients

519
00:29:52,040 --> 00:29:53,790
and actually

520
00:29:53,890 --> 00:29:56,830
it's that c

521
00:29:56,930 --> 00:29:59,010
how would i

522
00:29:59,020 --> 00:30:02,970
what is the relation between

523
00:30:05,130 --> 00:30:07,030
what i produce

524
00:30:07,630 --> 00:30:12,790
function one out of this function to give you an example so you where you

525
00:30:12,790 --> 00:30:15,030
have some numbers

526
00:30:15,080 --> 00:30:18,780
i suppose my function in one

527
00:30:20,230 --> 00:30:21,720
a specific function

528
00:30:22,490 --> 00:30:24,650
on tried

529
00:30:25,570 --> 00:30:31,070
so suppose i want to come to take off just one interval

530
00:30:33,530 --> 00:30:35,690
so all the time

531
00:30:36,900 --> 00:30:39,440
also to one

532
00:30:39,530 --> 00:30:41,390
one of the box

533
00:30:42,170 --> 00:30:45,510
square wave here

534
00:30:45,610 --> 00:30:47,290
like to produce

535
00:30:47,380 --> 00:30:49,770
so would

536
00:30:49,780 --> 00:30:53,470
one zero one suppose i would like to produce

537
00:31:00,590 --> 00:31:02,350
there are one

538
00:31:02,360 --> 00:31:03,670
how much

539
00:31:03,670 --> 00:31:05,630
of the box

540
00:31:05,750 --> 00:31:07,080
how much

541
00:31:07,200 --> 00:31:10,040
this where we should put it

542
00:31:10,060 --> 00:31:13,400
to produce five

543
00:31:13,450 --> 00:31:16,290
four of his

544
00:31:19,640 --> 00:31:21,310
four is

545
00:31:23,780 --> 00:31:25,100
one of the

546
00:31:26,480 --> 00:31:30,490
right so you have no trouble to do that my point is

547
00:31:30,500 --> 00:31:33,740
these numbers for what you could have

548
00:31:33,750 --> 00:31:36,480
what you should could and should have done

549
00:31:36,490 --> 00:31:39,030
to take the five three

550
00:31:40,300 --> 00:31:41,850
send it through

551
00:31:41,880 --> 00:31:43,980
you're from last time

552
00:31:44,040 --> 00:31:47,780
so through this lowpass filter

553
00:31:47,790 --> 00:31:49,480
it's not filter

554
00:31:49,570 --> 00:31:50,940
so this one

555
00:31:51,020 --> 00:31:52,510
one filter

556
00:31:52,570 --> 00:31:55,820
and when have come out a member of those filters

557
00:31:55,840 --> 00:32:02,050
well it's a very short signal we really really all zeros until

558
00:32:02,060 --> 00:32:03,780
all zeros after

559
00:32:03,790 --> 00:32:06,950
well four

560
00:32:07,000 --> 00:32:10,940
so do you remember what

561
00:32:11,030 --> 00:32:12,200
this is a very good

562
00:32:12,220 --> 00:32:13,740
o thing to do

563
00:32:13,850 --> 00:32:20,020
remember what comes out you know what's filter again for four

564
00:32:21,550 --> 00:32:24,830
OK so i send signals through

565
00:32:24,840 --> 00:32:26,210
and what what's in the

566
00:32:26,220 --> 00:32:27,780
get out

567
00:32:27,790 --> 00:32:33,940
the averaging filter takes so this filter takes half of the current

568
00:32:33,990 --> 00:32:37,430
plus half of the previous

569
00:32:37,490 --> 00:32:39,760
OK so outcome

570
00:32:39,780 --> 00:32:42,750
i can mean always zero

571
00:32:42,760 --> 00:32:45,820
and it'll keep everything was wrong

572
00:32:45,840 --> 00:32:52,360
the first time it sees five averaging with this guy before so i guess what

573
00:32:52,370 --> 00:32:55,790
we want to know more about this

574
00:32:55,790 --> 00:32:56,830
that's it

575
00:32:58,230 --> 00:33:01,370
the average three with five

576
00:33:01,390 --> 00:33:03,500
for the we really want

577
00:33:03,500 --> 00:33:07,740
however it is zero with three because one

578
00:33:07,760 --> 00:33:10,750
so and then it's series of that so it's all

579
00:33:13,240 --> 00:33:19,730
eighty five four that we really like three we really don't want to know this

580
00:33:19,730 --> 00:33:20,960
is zero

581
00:33:21,840 --> 00:33:25,980
but then you remember what the filter i did

582
00:33:27,220 --> 00:33:29,980
downsample it to every other one

583
00:33:29,990 --> 00:33:32,140
so it takes

584
00:33:32,310 --> 00:33:33,860
pick the right one

585
00:33:33,880 --> 00:33:35,700
throwaway way he

586
00:33:35,700 --> 00:33:40,310
now down here of course is the difference in filter

587
00:33:40,340 --> 00:33:44,380
take five minus over two

588
00:33:45,060 --> 00:33:48,530
minus award two

589
00:33:49,950 --> 00:33:51,690
you see

590
00:33:54,280 --> 00:33:56,610
probably one minus one

591
00:33:56,630 --> 00:33:58,920
three minus five or

592
00:33:58,950 --> 00:34:00,110
so o

593
00:34:00,140 --> 00:34:02,530
why am i getting

594
00:34:02,530 --> 00:34:04,620
now let's assume the other case

595
00:34:04,630 --> 00:34:08,590
with the constraint here is satisfied with the street

596
00:34:09,860 --> 00:34:11,420
so this means

597
00:34:11,430 --> 00:34:12,830
you back here

598
00:34:12,860 --> 00:34:18,130
this means we have a point which is somewhere inside the correct area

599
00:34:18,170 --> 00:34:20,530
and not even on the boundary

600
00:34:20,550 --> 00:34:25,540
so it could be like this point here so its corresponding constraint is satisfied as

601
00:34:25,540 --> 00:34:32,590
a strict inequality

602
00:34:32,640 --> 00:34:36,200
and what i'm going to say now is that in this case the corresponding like

603
00:34:36,420 --> 00:34:38,780
multiply it has to be zero

604
00:34:39,550 --> 00:34:42,370
because otherwise the same arguments before

605
00:34:42,600 --> 00:34:46,170
so this thing is positive and and

606
00:34:46,170 --> 00:34:51,030
here we have minus but at the same time for i want to maximize

607
00:34:51,120 --> 00:34:58,940
then the value that maximizes l is actually phi zero everything else would be suboptimal

608
00:34:59,400 --> 00:35:01,360
so these points that lie

609
00:35:01,380 --> 00:35:03,730
inside the allowed regions

610
00:35:03,740 --> 00:35:06,930
they have to have a value of five which is zero

611
00:35:07,240 --> 00:35:08,760
so this is

612
00:35:08,770 --> 00:35:12,490
stuff like intuitive proof or intuitive argument

613
00:35:12,500 --> 00:35:20,390
what's known as the KKT conditions kowalczyk and tucker conditions so that certain conditions about

614
00:35:20,390 --> 00:35:25,060
these logos multipliers that hold true at the optimal solution

615
00:35:28,120 --> 00:35:30,140
so the next step and

616
00:35:30,150 --> 00:35:34,010
i hope you have you believe me that doing this thing here is a good

617
00:35:34,010 --> 00:35:40,240
idea to maximize the respective wnb minimizing sorry minimizing with respect to WP maximizing with

618
00:35:40,240 --> 00:35:42,090
respect to the other five

619
00:35:42,310 --> 00:35:44,590
the next thing that people usually

620
00:35:44,610 --> 00:35:47,640
two is a derived what's called the dual problem

621
00:35:49,090 --> 00:35:52,280
eliminating the primal variables

622
00:35:52,290 --> 00:35:57,420
in the way you can do this is that at the extremum

623
00:35:57,430 --> 00:36:02,620
the derivative with respect to the primal variables vanish

624
00:36:03,320 --> 00:36:05,700
this gives us two conditions

625
00:36:05,700 --> 00:36:09,610
and we can use these conditions to eliminate the problem variables

626
00:36:09,840 --> 00:36:14,330
so let's compute the derivative of l with respect to be

627
00:36:14,350 --> 00:36:20,320
so this will give us some time depending on how to find and y i

628
00:36:20,320 --> 00:36:22,600
y i multiplies be also

629
00:36:23,790 --> 00:36:26,670
she gives us this equation here

630
00:36:26,710 --> 00:36:33,290
likewise will take the derivative with respect to w gradient user vector

631
00:36:33,310 --> 00:36:36,990
if we do this we get something here linear term in w and here we

632
00:36:36,990 --> 00:36:43,550
get something with phi y i x i this is the product

633
00:36:43,740 --> 00:36:50,050
so when you go through this he find this expression

634
00:36:50,070 --> 00:36:53,040
so we substitute both of these things into the

635
00:36:53,050 --> 00:36:55,200
like loss function

636
00:36:55,240 --> 00:37:03,010
before i show you the result of this substitution let's take a little closer look

637
00:37:03,010 --> 00:37:05,730
at the second equation from the last slide

638
00:37:05,790 --> 00:37:07,830
is this equation actually tells us

639
00:37:07,850 --> 00:37:11,000
not only how to eliminate w

640
00:37:11,010 --> 00:37:11,900
from the

641
00:37:11,930 --> 00:37:13,540
primal objective function

642
00:37:13,560 --> 00:37:18,240
it also tells us all the solution of look like

643
00:37:18,500 --> 00:37:24,680
so terms of the solution will be an expansion in terms of training points

644
00:37:24,700 --> 00:37:31,510
multiplying with these not what multipliers and the training labels so this was plus one

645
00:37:31,510 --> 00:37:35,400
minus one depending on the two classes this is a nonnegative numbers so

646
00:37:35,800 --> 00:37:39,720
so we know already know the solution of the problem we we find one

647
00:37:39,850 --> 00:37:43,650
is such that it's a linear combination of the training points

648
00:37:43,670 --> 00:37:48,790
where the points of the positive class of nonnegative weights in the training points of

649
00:37:48,790 --> 00:37:51,180
the negative class have on positive weight

650
00:37:51,190 --> 00:37:55,810
because the weights could be zero and we also know when the weights are zero

651
00:37:56,230 --> 00:38:02,980
remember from this argument here was saying if there a constraint which is trivially satisfied

652
00:38:03,100 --> 00:38:08,570
strict inequalities of point which is easy which is inside the respective class then the

653
00:38:08,570 --> 00:38:13,540
corresponding phi has to be zero so this means all the points that

654
00:38:13,560 --> 00:38:17,800
my inside here at this point is this point of these points here

655
00:38:18,420 --> 00:38:21,470
we'll have to wait zero in the solution

656
00:38:21,940 --> 00:38:24,240
which makes sense if you think about it because

657
00:38:24,250 --> 00:38:28,580
geometrically so we said we want to find a hyperplane that leads to the largest

658
00:38:28,580 --> 00:38:32,810
margin of separation and i guess you can imagine that this point back here does

659
00:38:32,810 --> 00:38:36,720
not carry any information about the position of this hyperplane so if we remove this

660
00:38:36,720 --> 00:38:43,170
point from the training set solution wouldn't change so it doesn't contain information about the

661
00:38:43,170 --> 00:38:47,210
solution therefore it also doesn't appear in the expansion of the solution

662
00:38:48,470 --> 00:38:53,620
it's reassuring that this intuition is recovered by the

663
00:38:53,620 --> 00:38:59,960
started in november and developing in nineteen ninety six and

664
00:38:59,990 --> 00:39:05,850
it is a programme for analysis and visualisation of large networks

665
00:39:07,480 --> 00:39:09,730
this is really important thing

666
00:39:09,770 --> 00:39:16,530
that large networks can be analyzed with it because it does not support the algorithms

667
00:39:16,910 --> 00:39:22,830
that are really time consuming because that what they would run too long

668
00:39:23,140 --> 00:39:26,620
and the latest version of course it can be accessed

669
00:39:26,640 --> 00:39:28,200
freely at this

670
00:39:33,500 --> 00:39:40,320
this is just the set of real numbers

671
00:39:40,330 --> 00:39:41,740
and they the same

672
00:39:43,860 --> 00:39:44,970
OK so

673
00:39:44,980 --> 00:39:50,580
large networks this means several thousands to several million years of vertices

674
00:39:51,800 --> 00:39:58,510
what kind of networks that are usually analyzed pike are the

675
00:39:58,520 --> 00:40:02,750
these are usually sparse networks that been that the

676
00:40:02,760 --> 00:40:06,570
number of all lines is a lot less than

677
00:40:06,580 --> 00:40:07,920
number of

678
00:40:07,940 --> 00:40:09,190
what is the square

679
00:40:09,580 --> 00:40:14,010
and what they are typically of that order are

680
00:40:14,070 --> 00:40:15,880
of order and

681
00:40:15,890 --> 00:40:17,830
times longer of

682
00:40:17,840 --> 00:40:23,490
and these are just some of the networks that can be also accessed from

683
00:40:23,500 --> 00:40:31,290
into from internet page of buying so there already in format and if i just

684
00:40:31,310 --> 00:40:38,000
briefly go through so you know what these networks are about whether the smallest one

685
00:40:38,000 --> 00:40:41,730
has almost three thousand vertices so we start this small

686
00:40:41,740 --> 00:40:47,290
it's this one is the dictionary of

687
00:40:47,310 --> 00:40:53,490
on what it is an online dictionary of library and information science

688
00:40:55,090 --> 00:40:57,810
here the vertices are presented by

689
00:40:57,830 --> 00:41:04,060
war and the lines between two words means that one word can use

690
00:41:04,080 --> 00:41:10,330
is explained by the other by also by the other work

691
00:41:10,340 --> 00:41:14,580
so we're in the explaination of the first word there is

692
00:41:14,590 --> 00:41:17,550
this second work including

693
00:41:17,560 --> 00:41:22,790
then there are some citation networks for example this one is the situation of

694
00:41:23,210 --> 00:41:29,750
self organizing maps of the people who are who are working on self organizing maps

695
00:41:29,750 --> 00:41:36,470
than the other citation would be from computational geometry and this one from US patents

696
00:41:36,470 --> 00:41:41,080
well i can i can explain this one a bit more what does this mean

697
00:41:41,090 --> 00:41:49,050
this means that we have four vertex vertices we have patterns and art between two

698
00:41:49,050 --> 00:41:56,680
patterns well are between two patterns mean that the first what excites the other one

699
00:41:56,690 --> 00:41:59,730
then we have class

700
00:41:59,750 --> 00:42:06,890
so the vertices would be atoms then english words for example

701
00:42:06,900 --> 00:42:12,710
we can can different words and links between them would be if they are synonyms

702
00:42:12,710 --> 00:42:15,090
of each other or something like that

703
00:42:15,130 --> 00:42:22,060
then internet of course here the vertices would be removed routers

704
00:42:22,070 --> 00:42:26,450
and for world wide web the more distant vertices would be

705
00:42:28,850 --> 00:42:29,580
would be

706
00:42:29,780 --> 00:42:33,500
websites and of course the

707
00:42:33,530 --> 00:42:34,540
links would be

708
00:42:34,560 --> 00:42:36,340
here are links

709
00:42:36,360 --> 00:42:42,540
and then this one is almost the same but this is the largest one slovenian

710
00:42:42,540 --> 00:42:45,200
internet and this was used by

711
00:42:45,660 --> 00:42:51,630
gregor petritsch also in his work in his doctoral dissertation

712
00:42:51,640 --> 00:42:53,230
so it's

713
00:42:53,240 --> 00:42:56,930
he also collected the whole network

714
00:42:56,940 --> 00:43:02,530
OK so what kind of data types the despite support are despite

715
00:43:02,550 --> 00:43:05,700
one has well

716
00:43:05,720 --> 00:43:07,040
by then

717
00:43:07,060 --> 00:43:13,110
like operations are performed are the first one with the network of course if there

718
00:43:13,110 --> 00:43:19,770
if there's we're we're talking about network analysis and the second one the partition the

719
00:43:19,770 --> 00:43:23,300
partition east what we mean by that is

720
00:43:23,310 --> 00:43:25,330
we can divide the

721
00:43:25,340 --> 00:43:30,980
but this is of the network on subsets that excludes

722
00:43:32,120 --> 00:43:35,080
on on different subset

723
00:43:35,940 --> 00:43:37,500
none of

724
00:43:38,470 --> 00:43:39,610
each vertex

725
00:43:40,360 --> 00:43:44,160
only in just in one of the subset

726
00:43:44,170 --> 00:43:46,710
then we have vectors

727
00:43:46,730 --> 00:43:48,700
this would be the

728
00:43:48,890 --> 00:43:50,860
vertex properties

729
00:43:50,880 --> 00:43:52,210
so each

730
00:43:53,680 --> 00:43:56,210
can has can have

731
00:43:56,300 --> 00:43:58,030
number attached to it

732
00:43:58,040 --> 00:44:00,750
then cluster will be just

733
00:44:00,760 --> 00:44:03,620
a part of the partition so

734
00:44:04,400 --> 00:44:06,810
or maybe one or maybe made

735
00:44:06,860 --> 00:44:10,810
more of these subnetworks the permutation

736
00:44:10,820 --> 00:44:13,410
it will be just

737
00:44:13,430 --> 00:44:16,550
that every vertex has of of course again

738
00:44:16,600 --> 00:44:22,860
number attached to it but there are these numbers are all different so the permutation

739
00:44:22,860 --> 00:44:28,130
is normally used when we want some kind of sorting out of vertices

740
00:44:28,180 --> 00:44:29,990
so each one has its

741
00:44:31,220 --> 00:44:40,170
and how hierarchy is rarely used but is used for example when we do hierarchy

742
00:44:42,220 --> 00:44:45,960
sorry hierarchical clustering

743
00:44:45,980 --> 00:44:49,840
and the something more about five

744
00:44:49,850 --> 00:44:55,160
well i'm going to also show how this help i looks like

745
00:44:55,170 --> 00:44:56,750
this is

746
00:44:57,630 --> 00:44:58,650
it looks

747
00:44:58,670 --> 00:44:59,880
so here

748
00:44:59,890 --> 00:45:06,340
we have the network and this is the list accumulator where all the networks with

749
00:45:06,350 --> 00:45:11,350
that we have here we don't have any network selected of course but if we

750
00:45:11,350 --> 00:45:16,710
had the some that was selected they would appear here in this list

751
00:45:16,720 --> 00:45:22,700
and here the partition permutation cluster hierarchy and vector so

752
00:45:22,710 --> 00:45:26,100
it's of the data set that i described before

753
00:45:26,120 --> 00:45:29,760
and of course IT operations are also

754
00:45:31,090 --> 00:45:38,010
are also here will depression can be used on different types of this

755
00:45:38,040 --> 00:45:42,560
data types and of course there are there are

756
00:45:42,560 --> 00:45:45,560
which is a conducting

757
00:45:46,750 --> 00:45:48,390
it closed

758
00:45:48,520 --> 00:45:49,400
the cut

759
00:45:49,430 --> 00:45:50,940
you see open it just

760
00:45:50,960 --> 00:45:52,980
allow you to look inside but it is

761
00:45:52,980 --> 00:45:54,340
close all

762
00:45:55,670 --> 00:45:58,690
and there are some negative charges here

763
00:45:58,810 --> 00:46:03,270
and positive charges in the foreground which you don't see the red field lines

764
00:46:03,280 --> 00:46:06,130
come from positive charges and up on the box

765
00:46:06,190 --> 00:46:09,090
and the negative field lines go from the box

766
00:46:09,090 --> 00:46:11,010
two the negative charge

767
00:46:11,040 --> 00:46:12,820
there is clear polarisation

768
00:46:12,870 --> 00:46:16,110
the box itself is neutral i started his neutral box

769
00:46:16,270 --> 00:46:20,730
because of this electric field they get polarization i end up with negative charge on

770
00:46:20,730 --> 00:46:21,860
the box here

771
00:46:21,870 --> 00:46:23,670
only on the outside

772
00:46:23,670 --> 00:46:28,230
the positive charge on the box here only on the outside

773
00:46:29,630 --> 00:46:31,500
electric field is zero

774
00:46:31,560 --> 00:46:33,130
no charge

775
00:46:36,250 --> 00:46:38,980
due to this crazy electric fields

776
00:46:39,020 --> 00:46:42,380
the free moving charges in the conductor

777
00:46:42,400 --> 00:46:44,500
i will rearrange themselves

778
00:46:44,520 --> 00:46:48,670
in such a way that the electric field is zero everywhere in the conductor

779
00:46:48,710 --> 00:46:50,360
it is zero inside

780
00:46:50,360 --> 00:46:51,500
the cavity

781
00:46:51,520 --> 00:46:52,920
and that the close

782
00:46:52,980 --> 00:46:56,560
the integral of of e dot tl is zero everywhere

783
00:46:56,630 --> 00:46:57,920
if these are

784
00:46:57,940 --> 00:47:00,110
static fields

785
00:47:00,170 --> 00:47:01,020
and this

786
00:47:01,040 --> 00:47:03,330
clearly impossible for us

787
00:47:03,330 --> 00:47:04,940
however calculate

788
00:47:04,960 --> 00:47:09,330
how to charge configuration at the surface will have to be in order to meet

789
00:47:09,330 --> 00:47:11,400
all those conditions

790
00:47:12,770 --> 00:47:13,630
can do this

791
00:47:15,080 --> 00:47:20,080
and it can do it extremely fast will being all the laws of physics

792
00:47:20,130 --> 00:47:25,980
it could very quickly passed starts here and minus charge there

793
00:47:26,020 --> 00:47:29,110
make sure there is no charge on the inside of the surface

794
00:47:29,150 --> 00:47:33,580
make sure that the electric field is everywhere zero inside and in the box

795
00:47:33,630 --> 00:47:37,210
and also make sure that the integral you don't you have a zero everywhere in

796
00:47:38,520 --> 00:47:43,810
and therefore the box and everything inside becomes an equipotential so it also arranges matters

797
00:47:43,810 --> 00:47:48,610
sort of the field lines never intersect with the box always perpendicular to

798
00:47:48,710 --> 00:47:50,730
all of that is down

799
00:47:50,730 --> 00:47:53,020
in almost no time at all

800
00:47:53,130 --> 00:47:54,150
by nature

801
00:47:54,190 --> 00:47:55,880
it's an amazing thing

802
00:47:56,040 --> 00:48:00,420
this happens and something that as i said it would be impossible for us

803
00:48:00,460 --> 00:48:03,060
calculate because the field configurations

804
00:48:03,110 --> 00:48:08,480
are extraordinarily difficult

805
00:48:08,540 --> 00:48:11,440
so if you're inside his metal box

806
00:48:11,500 --> 00:48:14,400
no matter what happens on the outside

807
00:48:14,500 --> 00:48:16,920
you would be electrically isolated

808
00:48:16,940 --> 00:48:21,400
from the outside world you wouldn't notice that there is a strong electric field outside

809
00:48:21,540 --> 00:48:24,360
know what you notice that people are trying to

810
00:48:24,400 --> 00:48:26,560
charge up your house

811
00:48:26,580 --> 00:48:28,710
recall that

812
00:48:28,710 --> 00:48:30,670
electrostatic shielding

813
00:48:30,710 --> 00:48:32,170
and we give them the name

814
00:48:32,170 --> 00:48:34,670
that house use would be called a

815
00:48:34,690 --> 00:48:37,670
faraday cage called after the great

816
00:48:37,750 --> 00:48:44,380
physicist fire they will learn a lot more about him during this course

817
00:48:44,400 --> 00:48:47,440
before i demonstrate this

818
00:48:47,500 --> 00:48:49,270
i want to address the issue

819
00:48:49,290 --> 00:48:51,900
which is related to the problem two one

820
00:48:51,960 --> 00:48:54,520
which is your next assign

821
00:48:54,580 --> 00:48:57,210
and i want to urge you

822
00:48:57,350 --> 00:49:00,670
make myself no solution but i want to urge you to start working on that

823
00:49:00,670 --> 00:49:05,590
assignment this weekend not next week this assignment and not

824
00:49:05,650 --> 00:49:10,190
just baby sign these MIT assignments are you going to put in a lot of

825
00:49:10,920 --> 00:49:15,090
to do them so please start this weekend not to do me a favor but

826
00:49:15,190 --> 00:49:17,290
do yourself a favor

827
00:49:17,420 --> 00:49:21,330
let's talk about problem to one know i will help you with that problem

828
00:49:21,380 --> 00:49:24,900
to one

829
00:49:25,040 --> 00:49:27,060
i said several times

830
00:49:27,080 --> 00:49:32,020
that is not possible to get the electric field inside the hollow conductor

831
00:49:33,400 --> 00:49:36,590
i suppose i go inside the conductor

832
00:49:36,610 --> 00:49:39,420
i go inside there

833
00:49:39,460 --> 00:49:42,960
and i put sneakily chart in my pocket

834
00:49:43,000 --> 00:49:46,060
and i sit inside the new clothes

835
00:49:46,110 --> 00:49:49,150
there's the charge inside nothing you can do

836
00:49:49,170 --> 00:49:50,920
and it is the charge inside

837
00:49:50,960 --> 00:49:53,980
is electric field

838
00:49:54,020 --> 00:49:56,920
so now we have a situation

839
00:49:56,960 --> 00:49:59,150
since it is post

840
00:49:59,170 --> 00:50:03,750
valentine's day my heart has evolved into a sphere again

841
00:50:03,810 --> 00:50:06,020
now we take a spherical

842
00:50:08,440 --> 00:50:10,250
this is solid material

843
00:50:10,250 --> 00:50:13,170
and somehow i'm sitting inside here

844
00:50:13,170 --> 00:50:14,610
with a charge

845
00:50:14,610 --> 00:50:15,420
plus q

846
00:50:15,500 --> 00:50:18,130
make it mine is if you want to that's exactly the problem to one is

847
00:50:20,980 --> 00:50:22,830
now clearly

848
00:50:22,880 --> 00:50:24,900
there is positive charge inside

849
00:50:24,940 --> 00:50:27,940
so clearly there has to be an election

850
00:50:30,770 --> 00:50:33,750
but the electric field inside the conductor

851
00:50:33,860 --> 00:50:36,540
these electric field anywhere year

852
00:50:36,540 --> 00:50:37,810
must be zero

853
00:50:37,860 --> 00:50:42,110
it is not zero electrons will keep moving until it is

854
00:50:42,150 --> 00:50:49,670
sort of conducting material itself has no electric fields

855
00:50:49,710 --> 00:50:52,210
what does that mean now

856
00:50:52,270 --> 00:50:55,980
with respect to any charts on the inside surface

857
00:50:56,020 --> 00:50:59,400
now they must be charged only insights

858
00:50:59,560 --> 00:51:00,770
because now

859
00:51:00,790 --> 00:51:03,940
if i made this my gaussian surface

860
00:51:04,000 --> 00:51:07,650
which is now a spherical surface closed surface

861
00:51:07,670 --> 00:51:09,210
miss the girl says

862
00:51:09,280 --> 00:51:13,880
that the closed surface integral of e dot the age of this surface must be

863
00:51:13,880 --> 00:51:16,750
zero because the electric field is zero anywhere

864
00:51:16,750 --> 00:51:21,080
that's the same as all of the charge inside divided by actually non-zero

865
00:51:21,090 --> 00:51:24,520
so does charge inside must be zero

866
00:51:24,610 --> 00:51:27,400
and it can be no charges in the conductor itself

867
00:51:27,460 --> 00:51:29,520
the negative charge must know

868
00:51:31,170 --> 00:51:33,670
on the inside of that

869
00:51:33,710 --> 00:51:37,230
so that the net charge inside

870
00:51:37,230 --> 00:51:38,650
this surface is zero

871
00:51:38,690 --> 00:51:40,790
now we do get

872
00:51:40,810 --> 00:51:45,850
charge on the inside and how much charge you get on the inside exactly minus

873
00:51:45,850 --> 00:51:50,440
q sort of the sum of the two is zero

874
00:51:50,440 --> 00:51:52,460
now this conductor

875
00:51:52,480 --> 00:51:54,380
originally was neutral

876
00:51:54,400 --> 00:51:56,080
it had no net charge

877
00:51:57,900 --> 00:51:59,980
on the surface of the conductor

878
00:52:00,000 --> 00:52:03,480
we must now seek charged prosecuted

879
00:52:03,480 --> 00:52:06,810
because the minus charge on the inside

880
00:52:06,860 --> 00:52:09,560
came from the inductor itself

881
00:52:09,630 --> 00:52:11,540
so the sum must be zero

882
00:52:11,630 --> 00:52:16,230
so now you get a curious situation that the prosecution charged insights

883
00:52:16,230 --> 00:52:18,400
which creates in field inside

884
00:52:18,440 --> 00:52:21,270
creates negative charge on the inside the same

885
00:52:21,290 --> 00:52:23,730
the magnitude and opposite in sign

886
00:52:23,750 --> 00:52:25,670
and plus q charge

887
00:52:25,670 --> 00:52:27,610
on the outside

888
00:52:27,650 --> 00:52:31,520
and the electric fields they're very complicated

889
00:52:31,580 --> 00:52:33,060
electric fields

890
00:52:33,770 --> 00:52:35,830
i to put him in

891
00:52:36,110 --> 00:52:40,650
i would imagine that this charge q is closer to this world and this will

892
00:52:40,690 --> 00:52:42,790
that the negative charge here

893
00:52:42,790 --> 00:52:45,460
will be larger in density than there

894
00:52:45,480 --> 00:52:47,770
really an induction effect

895
00:52:47,770 --> 00:52:51,860
the negative charge wants to go to this place that's really what's happening

896
00:52:51,920 --> 00:52:54,670
and so since this charge is close to this wall

897
00:52:54,690 --> 00:52:58,500
that will it will be able to attract more electrons

898
00:52:58,500 --> 00:53:02,720
one question to ask ourselves

899
00:53:02,760 --> 00:53:05,000
it is what is engineering

900
00:53:05,080 --> 00:53:07,640
how do define now what is engineering

901
00:53:09,160 --> 00:53:15,430
the definition of to use is one put forward by steve centre you are one

902
00:53:15,430 --> 00:53:18,910
of our professors who now what attire

903
00:53:18,950 --> 00:53:24,070
he defined engineering to be purposeful use of science

904
00:53:24,230 --> 00:53:33,580
right so then

905
00:53:33,620 --> 00:53:36,840
what is external to about

906
00:53:36,840 --> 00:53:37,300
so six

907
00:53:38,020 --> 00:53:39,550
this course in engineering

908
00:53:39,600 --> 00:53:41,920
and i like to use it level two

909
00:53:42,880 --> 00:53:46,220
the gainful employment of maxwell's equations

910
00:53:46,230 --> 00:53:50,200
many of you have seen maxwell's equations before most of you should have

911
00:53:50,230 --> 00:53:53,030
and their hearts

912
00:53:53,050 --> 00:53:57,730
six two is all about teaching you how to simplify our lives make things simple

913
00:53:57,740 --> 00:54:03,830
so we can gainfully employed maxwell's equations gainfully employed

914
00:54:03,840 --> 00:54:07,800
the facts of nature to build very interesting systems

915
00:54:07,860 --> 00:54:11,300
so let me show you how the transition is made

916
00:54:11,340 --> 00:54:17,140
so while the world around us

917
00:54:21,950 --> 00:54:27,190
so we make some observations in nature we make measurements and we can write down

918
00:54:27,200 --> 00:54:29,020
a large tables of measurements

919
00:54:29,080 --> 00:54:30,330
so for example

920
00:54:30,330 --> 00:54:32,560
we can take objects and

921
00:54:32,640 --> 00:54:34,560
measure the voltage across the

922
00:54:34,610 --> 00:54:39,090
and look at the resulting current through the element so we may end up getting

923
00:54:39,090 --> 00:54:42,220
a bunch of values such as

924
00:54:49,220 --> 00:54:52,380
so start of life making measurements on what exists

925
00:54:52,390 --> 00:54:53,940
i mean but the tables

926
00:54:54,860 --> 00:54:56,780
we could directly these tables

927
00:54:56,800 --> 00:55:01,720
and based on the observation these tables you could go ahead and very interesting

928
00:55:01,730 --> 00:55:06,270
engineer interesting systems that help us out in day-to-day life but i think it will

929
00:55:06,270 --> 00:55:08,160
be hard to imagine having to

930
00:55:08,160 --> 00:55:10,490
resort a set of tables to

931
00:55:10,500 --> 00:55:12,350
do any kind of useful work

932
00:55:12,370 --> 00:55:14,470
so what we do is engineers

933
00:55:14,530 --> 00:55:16,720
is the first there

934
00:55:16,740 --> 00:55:18,560
eleven of abstract

935
00:55:19,220 --> 00:55:21,820
we look at all the data and so how

936
00:55:22,790 --> 00:55:24,180
an abstraction

937
00:55:24,190 --> 00:55:29,590
such that we can simplify or much more succinctly put

938
00:55:29,650 --> 00:55:33,820
in a simple equation a simple statement what these numbers are telling us

939
00:55:33,840 --> 00:55:37,370
OK so for example a physics laws

940
00:55:39,590 --> 00:55:41,560
so laws of physics for example

941
00:55:41,570 --> 00:55:44,120
or simply abstractions abstractions

942
00:55:44,130 --> 00:55:49,250
so these sets of numbers can be quantified by law for example

943
00:55:49,340 --> 00:55:51,740
these equal to i what this current

944
00:55:51,840 --> 00:55:54,260
relates to the resistance of the object

945
00:55:54,280 --> 00:55:57,190
so the musical i is a law

946
00:55:58,260 --> 00:56:00,780
succinctly described the sort of experiments

947
00:56:00,780 --> 00:56:04,620
OK a and places a large number of tables with a very simple

948
00:56:05,600 --> 00:56:07,000
you could call this lot

949
00:56:07,000 --> 00:56:08,930
you could call it an abstraction

950
00:56:08,970 --> 00:56:10,760
because i see a lot of physics

951
00:56:10,840 --> 00:56:13,970
call the mass fractions of physics if you like

952
00:56:15,460 --> 00:56:18,010
there are maxwell's equations

953
00:56:18,030 --> 00:56:22,000
and so on and so forth

954
00:56:22,130 --> 00:56:24,280
so this is what it is

955
00:56:24,320 --> 00:56:25,760
OK this is out there

956
00:56:25,810 --> 00:56:28,590
OK and along an abstraction describe

957
00:56:28,590 --> 00:56:32,900
well the properties of nature the see it in some succinct form

958
00:56:33,650 --> 00:56:36,150
if you want to go and build a useful things

959
00:56:36,190 --> 00:56:41,000
we could take the abstractions of text my maxwell's equations and going about things

960
00:56:41,100 --> 00:56:43,940
but it's hard it's really really hard

961
00:56:44,000 --> 00:56:45,870
and what you learned in

962
00:56:47,100 --> 00:56:55,380
this place is all about simplifying things a complicated things believe that fraction simplified things

963
00:56:55,380 --> 00:56:57,760
so that we can build useful system

964
00:56:57,780 --> 00:57:00,650
OK even in six table two restart life by

965
00:57:00,660 --> 00:57:03,430
making a huge leap from maxwell's equations

966
00:57:03,630 --> 00:57:07,100
very popular very very simple laws

967
00:57:07,160 --> 00:57:10,090
again we show that lead to make today

968
00:57:10,120 --> 00:57:11,310
so the full set of

969
00:57:11,320 --> 00:57:17,190
the first fraction we layer is called the lumped circuit abstraction

970
00:57:17,810 --> 00:57:20,360
and once again abstraction

971
00:57:20,400 --> 00:57:22,730
what we do is

972
00:57:22,850 --> 00:57:27,350
because of simplifications that allows us to view a set of objects

973
00:57:28,500 --> 00:57:32,880
the discrete or lumped elements so we may have to define now

974
00:57:32,980 --> 00:57:34,200
water sources

975
00:57:34,250 --> 00:57:37,120
well defined resistors defined

976
00:57:37,230 --> 00:57:39,050
capacitors and so on

977
00:57:39,060 --> 00:57:42,180
and i'm going make the jump and show you how to make the jump in

978
00:57:42,180 --> 00:57:44,000
a few minutes

979
00:57:44,000 --> 00:57:45,240
so no

980
00:57:45,270 --> 00:57:50,930
on that sort of abstractions within the layer another abstract layer and we call that

981
00:57:54,070 --> 00:57:56,150
the amplifier abstraction

982
00:57:56,180 --> 00:57:57,560
OK to remember

983
00:57:57,610 --> 00:58:03,560
if you actually down and dirty the sitting probe measuring objects and billiards stables

984
00:58:03,680 --> 00:58:07,630
the abstract things in the simple laws and life for the better

985
00:58:07,680 --> 00:58:11,860
then we show you can abstract things further out and the discrete objects

986
00:58:11,880 --> 00:58:16,890
and and then you can build an even more interesting components all amplifiers

987
00:58:16,900 --> 00:58:19,000
and the playing on the amplifiers fires

988
00:58:19,000 --> 00:58:25,030
so these little red rose

989
00:58:25,640 --> 00:58:29,230
they choose

990
00:58:31,490 --> 00:58:38,390
all that we have some

991
00:58:38,420 --> 00:58:41,720
when corresponds

992
00:58:57,570 --> 00:58:58,940
this strategy

993
00:59:03,110 --> 00:59:06,130
like squared

994
00:59:12,220 --> 00:59:15,620
there that's were

995
00:59:16,970 --> 00:59:20,200
it's not for

996
00:59:31,530 --> 00:59:33,330
so is

997
00:59:36,990 --> 00:59:46,490
so you can

998
00:59:55,620 --> 00:59:57,890
seems like

999
01:00:00,820 --> 01:00:02,540
so w

1000
01:00:02,940 --> 01:00:12,500
this means

1001
01:00:26,250 --> 01:00:27,290
also we

1002
01:00:27,290 --> 01:00:31,340
you can see the difference between

1003
01:00:31,550 --> 01:00:33,610
they're all

1004
01:00:37,570 --> 01:00:41,750
a lot of them

1005
01:00:41,800 --> 01:00:44,940
the reason for

1006
01:00:44,960 --> 01:00:47,360
we have

1007
01:00:47,380 --> 01:00:49,090
so what

1008
01:00:49,320 --> 01:00:55,460
the need

1009
01:00:59,170 --> 01:01:01,630
o ratio

1010
01:01:08,050 --> 01:01:15,670
well so much the ricci flow

1011
01:01:18,440 --> 01:01:22,050
you some

1012
01:01:23,670 --> 01:01:27,050
he he

1013
01:01:27,590 --> 01:01:31,050
one of

1014
01:01:36,650 --> 01:01:39,150
all of us

1015
01:01:39,170 --> 01:01:41,710
this is the

1016
01:01:46,320 --> 01:01:47,730
you want

1017
01:01:51,690 --> 01:01:55,690
let me

1018
01:01:55,710 --> 01:02:04,570
all of the walls

1019
01:02:10,670 --> 01:02:15,570
you think of it as well

1020
01:02:17,270 --> 01:02:18,300
all the

1021
01:02:19,190 --> 01:02:21,800
thirty keep

1022
01:02:31,840 --> 01:02:35,360
i think she is

1023
01:02:35,460 --> 01:02:38,710
so what

1024
01:02:46,400 --> 01:02:50,070
but in this distribution was

1025
01:02:50,190 --> 01:02:54,860
it is the or

1026
01:02:54,880 --> 01:02:57,610
is it the place

1027
01:03:05,050 --> 01:03:08,690
you want see the

1028
01:03:13,790 --> 01:03:17,770
is easy to

1029
01:03:17,790 --> 01:03:21,320
it is

1030
01:03:25,520 --> 01:03:28,630
so the initial

1031
01:03:34,150 --> 01:03:37,960
and for

1032
01:03:37,980 --> 01:03:44,770
so you are in this range and the

1033
01:03:46,000 --> 01:03:47,940
i don't know

1034
01:04:06,000 --> 01:04:16,250
what is the expectation of the vision

1035
01:04:16,250 --> 01:04:17,360
the first one

1036
01:04:19,730 --> 01:04:21,480
he was the

1037
01:04:26,230 --> 01:04:28,090
this is the

1038
01:04:42,380 --> 01:04:43,840
i see

1039
01:04:43,860 --> 01:04:49,880
that's what lost

1040
01:05:00,190 --> 01:05:02,420
what you get

1041
01:05:02,420 --> 01:05:05,570
as non proper nouns

1042
01:05:05,710 --> 01:05:08,580
i mean cocaine

1043
01:05:09,370 --> 01:05:12,860
so i started some cook

1044
01:05:16,460 --> 01:05:18,520
how to

1045
01:05:19,290 --> 01:05:23,280
you can also use cope with a lower case e

1046
01:05:23,370 --> 01:05:24,670
to mean

1047
01:05:25,170 --> 01:05:31,080
like something called

1048
01:05:31,670 --> 01:05:35,450
four serving of such drink

1049
01:05:35,500 --> 01:05:37,700
as the sun

1050
01:05:37,960 --> 01:05:40,860
that's OK

1051
01:05:40,870 --> 01:05:44,930
so that's how the notation works

1052
01:05:45,510 --> 01:05:48,530
OK so

1053
01:05:48,640 --> 01:05:51,870
the notation works for single words

1054
01:05:51,890 --> 01:05:53,940
but what about phrases

1055
01:05:53,940 --> 01:05:56,750
like clinton joke or joke about clinton

1056
01:05:58,210 --> 01:06:02,910
when you have something like that you use either multiwordstring are compound

1057
01:06:02,960 --> 01:06:06,170
string depending on whether the head of the phrase

1058
01:06:06,190 --> 01:06:08,100
his initial or final

1059
01:06:08,100 --> 01:06:09,270
so if the

1060
01:06:09,310 --> 01:06:10,890
head of the phrase is

1061
01:06:10,890 --> 01:06:11,940
at the end

1062
01:06:11,960 --> 01:06:14,250
which normally is an english

1063
01:06:16,480 --> 01:06:18,250
you use multiwordstring

1064
01:06:18,270 --> 01:06:20,120
and if had this at the beginning

1065
01:06:20,190 --> 01:06:22,080
then use compoundstring

1066
01:06:22,500 --> 01:06:25,830
clinton joke

1067
01:06:25,830 --> 01:06:26,770
the head

1068
01:06:27,710 --> 01:06:28,940
he is joe

1069
01:06:28,960 --> 01:06:30,390
rather than clinton

1070
01:06:30,410 --> 01:06:31,870
and you can tell that

1071
01:06:32,000 --> 01:06:33,960
by thinking about

1072
01:06:34,060 --> 01:06:36,120
how how to make the plural

1073
01:06:36,170 --> 01:06:37,270
of this

1074
01:06:39,250 --> 01:06:43,170
plural clinton joke is clinton jokes clintons

1075
01:06:44,810 --> 01:06:47,160
so that

1076
01:06:47,170 --> 01:06:48,960
head of the

1077
01:06:49,250 --> 01:06:54,290
well i joke about clinton you would add the as to choke

1078
01:06:54,370 --> 01:06:57,890
so that means the joke is the head of the phrase

1079
01:07:04,560 --> 01:07:06,290
takes a list of

1080
01:07:06,520 --> 01:07:10,310
here but it's just a list of strings and

1081
01:07:10,310 --> 01:07:12,290
a lexical words

1082
01:07:12,330 --> 01:07:14,310
which is going to be the head

1083
01:07:14,350 --> 01:07:16,810
and part of speech for the word

1084
01:07:18,350 --> 01:07:19,330
the meaning

1085
01:07:19,330 --> 01:07:24,250
clinton joke is represented with multiwordstring

1086
01:07:24,350 --> 01:07:27,500
first arguement is the list

1087
01:07:28,830 --> 01:07:30,540
the string

1088
01:07:30,580 --> 01:07:33,560
followed by jokes the were

1089
01:07:33,600 --> 01:07:36,250
this is the head of the phrase

1090
01:07:37,790 --> 01:07:40,790
we want the company

1091
01:07:40,850 --> 01:07:42,770
version of just the word

1092
01:07:42,810 --> 01:07:48,600
and denotes joke about find bill clinton

1093
01:07:48,620 --> 01:07:49,370
you could

1094
01:07:49,430 --> 01:07:51,980
potentially infer this lexical entries

1095
01:07:52,020 --> 01:07:56,960
it happens to be stated

1096
01:07:57,730 --> 01:08:00,790
so right because

1097
01:08:00,910 --> 01:08:03,600
the plural is clinton jokes we know that

1098
01:08:03,690 --> 01:08:05,790
joke is the head of the phrase

1099
01:08:05,830 --> 01:08:08,410
compoundstring is

1100
01:08:08,410 --> 01:08:11,710
very similar to multiwordstring but for convenience

1101
01:08:11,730 --> 01:08:14,480
the word which is the head comes first

1102
01:08:14,500 --> 01:08:15,730
and then

1103
01:08:15,730 --> 01:08:19,060
the second argument is the list of string

1104
01:08:19,060 --> 01:08:20,410
again but now

1105
01:08:20,410 --> 01:08:25,140
because i'm on that side the thing i need to plug in the other forms

1106
01:08:25,160 --> 01:08:26,750
nine six two

1107
01:08:26,780 --> 01:08:31,570
and that's going to give us two

1108
01:08:34,640 --> 01:08:38,970
that the left and right limits and this is one little tiny subtlety and almost

1109
01:08:38,970 --> 01:08:42,110
the only thing that i needed to really pay attention to a little bit right

1110
01:08:42,770 --> 01:08:44,600
is is that this

1111
01:08:44,610 --> 01:08:46,550
we did not need

1112
01:08:47,270 --> 01:08:51,800
you need x equals zero

1113
01:08:54,290 --> 01:08:58,280
in fact i never even told you what f of zero was

1114
01:08:59,940 --> 01:09:01,750
if we stick it in

1115
01:09:01,840 --> 01:09:04,840
we could stick in OK let's say we stick it in

1116
01:09:05,320 --> 01:09:07,350
on one

1117
01:09:07,370 --> 01:09:09,750
on this side let's let's make it b

1118
01:09:09,750 --> 01:09:14,980
that it's on this site so that means that this point is in

1119
01:09:16,550 --> 01:09:18,050
this point

1120
01:09:18,110 --> 01:09:20,970
his out

1121
01:09:21,000 --> 01:09:23,980
so that's a typical notation

1122
01:09:23,990 --> 01:09:24,800
this little

1123
01:09:24,830 --> 01:09:27,640
open circle this close dot

1124
01:09:27,640 --> 01:09:28,750
for when you

1125
01:09:28,760 --> 01:09:31,270
include the so so in that case

1126
01:09:31,280 --> 01:09:35,250
the value of f of x happens to be the same as its right hand

1127
01:09:36,440 --> 01:09:38,650
namely the value is one

1128
01:09:39,540 --> 01:09:44,640
and not too

1129
01:09:45,360 --> 01:09:47,680
so that's the the

1130
01:09:47,720 --> 01:09:54,750
the first kind of example questions

1131
01:09:55,410 --> 01:09:57,340
so now

1132
01:09:57,360 --> 01:09:59,370
our next job

1133
01:10:01,010 --> 01:10:05,270
introduce the definition of continuity

1134
01:10:05,290 --> 01:10:08,160
so that was the other topic here

1135
01:10:08,200 --> 01:10:10,740
so we're going to find

1136
01:10:15,310 --> 01:10:22,470
at x is zero mean

1137
01:10:22,550 --> 01:10:25,580
that the limit

1138
01:10:25,610 --> 01:10:27,250
of f of x

1139
01:10:27,290 --> 01:10:28,500
as x tends to

1140
01:10:29,260 --> 01:10:32,540
is equal to that

1141
01:10:37,120 --> 01:10:39,680
so the reason why i spend all this time

1142
01:10:39,680 --> 01:10:43,170
paying attention to the left and the right and so on and so forth focusing

1143
01:10:43,170 --> 01:10:46,180
is that i i want you to pay attention from one moment to what the

1144
01:10:46,180 --> 01:10:48,020
content of this

1145
01:10:48,050 --> 01:10:49,850
of this definition is

1146
01:10:49,860 --> 01:10:51,300
what it's saying

1147
01:10:51,310 --> 01:10:53,720
is the following so

1148
01:11:00,770 --> 01:11:06,390
it has has at various ingredients here so the first one is the limit

1149
01:11:08,520 --> 01:11:10,530
it the

1150
01:11:10,660 --> 01:11:14,750
and what that means is

1151
01:11:14,800 --> 01:11:19,190
that there's an honest limiting value both from the left and right

1152
01:11:19,200 --> 01:11:25,410
and they also have to be the same

1153
01:11:25,490 --> 01:11:28,730
right so that's

1154
01:11:28,740 --> 01:11:31,620
that's what's going on here in the second

1155
01:11:31,650 --> 01:11:35,920
property is that after that zero

1156
01:11:36,830 --> 01:11:41,160
well defined so i can be in one of these situations where i but i

1157
01:11:41,160 --> 01:11:44,410
haven't even specified what the big zero is

1158
01:11:44,410 --> 01:11:46,070
and there are equal

1159
01:11:55,010 --> 01:11:57,250
so that's the situation

1160
01:11:58,280 --> 01:12:00,260
again let me emphasise

1161
01:12:00,280 --> 01:12:03,020
a tricky part of the definition of the limit

1162
01:12:03,110 --> 01:12:06,030
this side the left hand side

1163
01:12:06,050 --> 01:12:12,920
is completely independent is evaluated by a procedure which does not involve the right hand

1164
01:12:12,920 --> 01:12:14,950
side these are separate things

1165
01:12:15,050 --> 01:12:17,670
this one is to evaluate it

1166
01:12:17,690 --> 01:12:19,560
you always

1167
01:12:20,840 --> 01:12:22,510
the limit point

1168
01:12:22,510 --> 01:12:27,250
so that if you like a paradox because it's exactly the question is is it

1169
01:12:28,190 --> 01:12:30,990
that if you plug in a zero you get the same answer as if you

1170
01:12:30,990 --> 01:12:32,410
move in the limit

1171
01:12:32,450 --> 01:12:36,490
that's the issue that we're we're considering we have to make that distinction in order

1172
01:12:36,490 --> 01:12:38,160
to say that these are two

1173
01:12:38,280 --> 01:12:44,790
other otherwise this is just tautological makes it's very little it doesn't have any meaning

1174
01:12:44,790 --> 01:12:48,780
but in fact it does happening because one thing is evaluated separately with reference to

1175
01:12:48,790 --> 01:12:50,510
all the other points

1176
01:12:50,520 --> 01:12:53,370
and the other is evaluated right

1177
01:12:53,450 --> 01:12:56,660
but the the point in question and indeed

1178
01:12:56,710 --> 01:12:59,160
what these things are

1179
01:12:59,210 --> 01:13:02,250
are exactly the easy linear

1180
01:13:02,300 --> 01:13:09,280
that's exactly what we're talking about here they are the ones

1181
01:13:09,300 --> 01:13:12,320
you can evaluate this way

1182
01:13:12,360 --> 01:13:15,290
so we have to make a distinction in the these other ones are going to

1183
01:13:15,290 --> 01:13:17,750
be the ones which we can't

1184
01:13:17,750 --> 01:13:18,900
these are the

1185
01:13:18,920 --> 01:13:21,220
the nice ones and that's why we care about and why we have a whole

1186
01:13:21,220 --> 01:13:24,600
definition associated with

1187
01:13:24,620 --> 01:13:26,720
all right

1188
01:13:26,750 --> 01:13:29,250
so now so now what's next twelve

1189
01:13:29,300 --> 01:13:30,340
i need to

1190
01:13:30,350 --> 01:13:33,850
give you a

1191
01:13:33,860 --> 01:13:38,510
a little too or very brief tour of the zoo of

1192
01:13:38,570 --> 01:13:42,220
what are known as discontinuous functions

1193
01:13:42,230 --> 01:13:45,430
so sort of everything else that's not continue

1194
01:13:46,560 --> 01:13:49,850
the first example here

1195
01:13:49,940 --> 01:13:54,160
but let me just write down here is is jump

1196
01:13:55,530 --> 01:14:06,840
so what jump discontinuity b well we actually already seen

1197
01:14:06,860 --> 01:14:08,760
the jump discontinuity

1198
01:14:08,770 --> 01:14:13,420
is the example that we had right there this is when the limit

1199
01:14:13,440 --> 01:14:16,550
from the left

1200
01:14:16,650 --> 01:14:19,680
left and right

1201
01:14:30,370 --> 01:14:31,580
OK so that's

1202
01:14:31,590 --> 01:14:33,140
that's the

1203
01:14:33,520 --> 01:14:35,750
as in the example

1204
01:14:39,360 --> 01:14:40,770
right in this example

1205
01:14:40,810 --> 01:14:42,830
the two limits one of them was one

1206
01:14:42,930 --> 01:14:46,040
one of them was too

1207
01:14:46,060 --> 01:14:47,980
so that the jump discontinuity

1208
01:14:54,800 --> 01:14:56,150
this kind of issue

1209
01:14:56,940 --> 01:15:01,270
whether something is continuous or not is

1210
01:15:01,290 --> 01:15:03,780
may seem a little bit technical but

1211
01:15:03,790 --> 01:15:05,410
but it is true

1212
01:15:08,540 --> 01:15:14,200
that that people have worried about a lot the

1213
01:15:14,240 --> 01:15:17,480
palmer who was a professor at MIT when he

1214
01:15:17,540 --> 01:15:21,460
did his work for the nobel prize in economics

1215
01:15:21,470 --> 01:15:24,220
i was interested in this very issue

1216
01:15:24,230 --> 01:15:29,570
of whether stock prices of various kinds are continuous from the left right in a

1217
01:15:29,570 --> 01:15:30,670
certain model

1218
01:15:30,680 --> 01:15:32,660
and that was a very serious issue

1219
01:15:32,670 --> 01:15:34,540
in developing the model that

1220
01:15:36,140 --> 01:15:39,790
priced things that are hedge funds use all the time now

1221
01:15:41,290 --> 01:15:43,270
left and right really

1222
01:15:43,310 --> 01:15:45,750
can mean something very different

1223
01:15:45,760 --> 01:15:48,140
i in this case left is the past

1224
01:15:48,140 --> 01:15:49,800
and right is the future

1225
01:15:49,820 --> 01:15:53,220
and it makes a big difference whether things are continuous from the left and continues

1226
01:15:53,220 --> 01:15:54,940
from the right

1227
01:15:54,970 --> 01:15:58,650
right is the true that the point is here here somewhere in the middle somewhere

1228
01:15:59,870 --> 01:16:01,490
that's a serious issue

1229
01:16:03,540 --> 01:16:05,030
the next example

1230
01:16:05,040 --> 01:16:08,760
that i want to give you is a little bit more subtle

1231
01:16:08,960 --> 01:16:13,180
it's what's known as the removable

1232
01:16:13,180 --> 01:16:15,420
and i want to update that number

1233
01:16:15,430 --> 01:16:17,080
in the light of

1234
01:16:17,120 --> 01:16:21,880
the data of collected so i will the data and then c

1235
01:16:21,910 --> 01:16:28,560
what does that tell me about theta it update what i believe that the college

1236
01:16:28,570 --> 01:16:33,350
this is the posterior distribution center given the data

1237
01:16:33,420 --> 01:16:37,000
it turns out

1238
01:16:39,410 --> 01:16:44,280
this idea is very closely related to the likelihood of idea

1239
01:16:44,280 --> 01:16:49,110
so it's that we wait the likelihood by this but subjective

1240
01:16:49,140 --> 01:16:51,380
probability distribution

1241
01:16:51,550 --> 01:16:55,820
so that's the way we actually do that way we get from the

1242
01:16:55,870 --> 01:16:57,130
initial belief

1243
01:16:57,910 --> 01:17:03,430
the belief after the the data is multiplied by the likelihood and then rescale to

1244
01:17:03,430 --> 01:17:04,460
make sure that

1245
01:17:04,840 --> 01:17:07,160
the probability that one

1246
01:17:07,170 --> 01:17:10,770
the proportions add up to one side and the way that you do that is

1247
01:17:10,770 --> 01:17:12,150
you just integrate

1248
01:17:12,170 --> 01:17:14,950
the constant

1249
01:17:16,270 --> 01:17:21,150
and the reason i wanted to mention this is as well as being

1250
01:17:21,160 --> 01:17:26,550
because the rest of the talk about i will come back to this but people

1251
01:17:26,550 --> 01:17:28,700
will come back to it later in the course

1252
01:17:28,780 --> 01:17:36,640
but but this this is important because this gives you away

1253
01:17:36,650 --> 01:17:39,320
to think about automated data collection

1254
01:17:39,320 --> 01:17:43,020
many of these systems are out there

1255
01:17:43,020 --> 01:17:46,780
to for a statistical model to the data take

1256
01:17:48,530 --> 01:17:50,540
i haven't got time to

1257
01:17:50,550 --> 01:17:53,090
i use method that requires you to

1258
01:17:53,100 --> 01:17:56,930
he refitting the model over and over again

1259
01:17:57,000 --> 01:17:59,150
this however

1260
01:17:59,170 --> 01:18:02,140
gives a mechanism for saying

1261
01:18:02,540 --> 01:18:06,470
this is what i think is going on about the in the model of the

1262
01:18:06,470 --> 01:18:10,430
world and then i got some data

1263
01:18:10,990 --> 01:18:12,690
and that updates

1264
01:18:12,710 --> 01:18:16,850
my belief that the world would come to an automated data collection

1265
01:18:16,980 --> 01:18:22,210
then if i've got a model that the next there something to data comes in

1266
01:18:22,250 --> 01:18:25,570
i can apply this procedure i don't have to do this just once i can

1267
01:18:27,430 --> 01:18:30,690
i guess data update my original belief to this

1268
01:18:30,700 --> 01:18:34,730
well i got that if i get some of something about that

1269
01:18:34,740 --> 01:18:36,880
i can you have some more data

1270
01:18:37,290 --> 01:18:40,710
i can apply this procedure so this is what i think now

1271
01:18:41,850 --> 01:18:44,080
the database we now think this

1272
01:18:44,100 --> 01:18:45,690
so then

1273
01:18:45,750 --> 01:18:49,940
this page goes back into their and it's more data do this trick again and

1274
01:18:49,940 --> 01:18:51,600
again and again and again

1275
01:18:51,600 --> 01:18:55,070
whereas if you say something like

1276
01:18:55,090 --> 01:19:00,280
a classification trees oates

1277
01:19:00,290 --> 01:19:04,210
what was called induction trees i think in the book

1278
01:19:04,230 --> 01:19:10,130
in that situation and it's very difficult if somebody if you in models thing that's

1279
01:19:10,130 --> 01:19:12,390
so if you some more data

1280
01:19:12,410 --> 01:19:14,570
it's not that easy so they can model

1281
01:19:14,580 --> 01:19:18,920
what you have to what tend to have to do is to incorporate the data

1282
01:19:18,920 --> 01:19:23,900
in back into the main dataset and rebuild the model from scratch was saying here

1283
01:19:23,920 --> 01:19:26,640
as we have no way of

1284
01:19:26,660 --> 01:19:30,370
holding on to model and then i'd least basically we have an automated

1285
01:19:30,370 --> 01:19:32,280
update method

1286
01:19:32,300 --> 01:19:38,410
or so not a dating is built into the whole idea here that's that's what

1287
01:19:38,410 --> 01:19:40,200
we're doing is saying

1288
01:19:40,220 --> 01:19:44,130
that's what i think i remember all that that belief based on some more like

1289
01:19:44,380 --> 01:19:45,560
i get some data

1290
01:19:45,660 --> 01:19:51,040
so that's appealing if we've got an automated data collection so that's what the reason

1291
01:19:51,040 --> 01:19:55,160
why things should be in here because i think in the long run this is

1292
01:19:55,160 --> 01:19:59,540
where a lot of data mining might end up if it's using any statistical is

1293
01:19:59,540 --> 01:20:00,390
the model

1294
01:20:01,040 --> 01:20:04,690
because this is going to make it feasible

1295
01:20:05,290 --> 01:20:09,370
OK and the last little bit don't to

1296
01:20:09,380 --> 01:20:12,660
so shown here is

1297
01:20:12,710 --> 01:20:14,880
the primary use that we're going be

1298
01:20:14,900 --> 01:20:19,120
making a living out of thought that mining is

1299
01:20:19,280 --> 01:20:24,150
the statistics is we build model we try to make predictions from it

1300
01:20:24,350 --> 01:20:26,360
OK so

1301
01:20:26,370 --> 01:20:31,800
and let's say that is build models to describe some function that we don't know

1302
01:20:31,880 --> 01:20:36,110
that's what estimate this function f and we have

1303
01:20:36,120 --> 01:20:37,920
well first of all the

1304
01:20:37,940 --> 01:20:40,830
i had so we build the model

1305
01:20:40,830 --> 01:20:44,860
and these are predictions as heart to the prediction of fx

1306
01:20:47,980 --> 01:20:50,900
if we want to know how good the model is

1307
01:20:50,920 --> 01:20:55,670
that we would look at what's the difference between

1308
01:20:55,690 --> 01:20:56,870
the truth

1309
01:20:56,870 --> 01:21:00,340
and the model's prediction of what happened

1310
01:21:00,350 --> 01:21:04,850
however we don't really know the truth best known for exercise all i want to

1311
01:21:04,850 --> 01:21:06,240
know is

1312
01:21:06,300 --> 01:21:10,840
we can look at what's the difference square to make it always positive and then

1313
01:21:10,840 --> 01:21:15,140
look at what is the average of that that will become the mean squared error

1314
01:21:15,310 --> 01:21:19,020
and we might want to use the mean squared error to try

1315
01:21:19,080 --> 01:21:22,310
work out what's going on with the models

1316
01:21:22,400 --> 01:21:26,900
if this is one of the things that the early days of say no networks

1317
01:21:27,310 --> 01:21:29,980
where problem because

1318
01:21:29,980 --> 01:21:32,750
what you find is very bright star

1319
01:21:32,770 --> 01:21:39,830
it makes sense to two bits one is called by us and that's the difference

1320
01:21:43,640 --> 01:21:45,940
how far you ask

1321
01:21:45,960 --> 01:21:48,710
systematically with this

1322
01:21:48,750 --> 01:21:51,710
and the variance is supposed

1323
01:21:52,850 --> 01:21:56,520
the natural variability

1324
01:21:56,540 --> 01:22:02,170
well into the model is that the variance is

1325
01:22:02,190 --> 01:22:03,620
the bias is

1326
01:22:03,650 --> 01:22:08,290
government the bias is how wrong he model

1327
01:22:08,310 --> 01:22:10,310
that's not what put it

1328
01:22:10,330 --> 01:22:15,980
so if if the behaviour between two variables should be quadratic curve and if a

1329
01:22:15,980 --> 01:22:20,100
straight line so it then you have a bias in your model because the model

1330
01:22:20,100 --> 01:22:21,000
is wrong

1331
01:22:21,060 --> 01:22:28,540
but they also have variance because even when you get to say that the quadratic

1332
01:22:28,540 --> 01:22:31,960
curve is what you put in there you find the data doesn't say that onto

1333
01:22:31,960 --> 01:22:35,730
the quadratic actually very very lucky

1334
01:22:35,750 --> 01:22:39,400
so the variance to be taking account of the

1335
01:22:39,440 --> 01:22:41,620
basic variability in the data

1336
01:22:41,640 --> 01:22:45,190
and the bias is that you've got the model wrong and both measures of how

1337
01:22:45,190 --> 01:22:46,440
far fewer

1338
01:22:46,460 --> 01:22:50,620
so so this was the city's main square is based on

1339
01:22:51,480 --> 01:22:53,290
the message here

1340
01:22:54,770 --> 01:22:57,350
what's the matter

1341
01:23:02,330 --> 01:23:04,580
if you think about the bias

1342
01:23:04,670 --> 01:23:06,730
but if the bias is

1343
01:23:06,730 --> 01:23:13,480
how do you model if you you're potential lots of models very flexible

1344
01:23:14,730 --> 01:23:17,750
you're going to manage to reduce the bias

1345
01:23:17,750 --> 01:23:19,330
because if

1346
01:23:19,330 --> 01:23:23,960
even if you say you have a quadratic is the chance relationship if you it's

1347
01:23:23,960 --> 01:23:26,580
a a tenth degree polynomial

1348
01:23:26,580 --> 01:23:30,680
and the answer is no so in fact i wasn't assuming normalisation of this

1349
01:23:30,680 --> 01:23:36,140
i was only assuming that that fight times q not i was normalizable i never

1350
01:23:36,140 --> 01:23:38,510
had to assume that if i was normalizable

1351
01:23:38,530 --> 01:23:41,390
nor that i have to send after lives was normalizable

1352
01:23:43,240 --> 01:23:45,720
that's right

1353
01:23:46,450 --> 01:23:51,410
so if you look at all my equations i never have to and never compute

1354
01:23:51,410 --> 01:23:54,810
the moments of just firefighter by itself

1355
01:23:54,830 --> 01:23:59,430
i always compute products of things

1356
01:23:59,450 --> 01:24:05,490
which by construction will be will be normalized

1357
01:24:07,780 --> 01:24:10,310
so of course initially from reviewers right

1358
01:24:10,370 --> 01:24:15,220
here's here's more detailed comparison

1359
01:24:15,240 --> 01:24:17,080
well i'm showing the

1360
01:24:17,080 --> 01:24:19,310
computation time versus the air

1361
01:24:19,330 --> 01:24:23,680
of different approximation for the clutter problem here one then is a picture of john

1362
01:24:23,680 --> 01:24:25,100
twenty points from the model

1363
01:24:25,100 --> 01:24:26,080
and here i drew

1364
01:24:26,080 --> 01:24:28,950
on the right-hand side to two hundred points from

1365
01:24:29,240 --> 01:24:33,350
and the the the real mean was two

1366
01:24:35,080 --> 01:24:36,760
the way you read these curves is

1367
01:24:36,780 --> 01:24:40,280
each iteration of the p gives you an estimate so i can always stop BP

1368
01:24:40,280 --> 01:24:45,050
after say one iteration two iteration to get an estimate and so the blue EP

1369
01:24:45,050 --> 01:24:49,850
curve there is showing what you get after every after every iteration

1370
01:24:49,870 --> 01:24:53,120
and similarly we get a curve out of the past method variational bayes because again

1371
01:24:53,120 --> 01:24:55,640
you could stop them early and get a good answer

1372
01:24:55,700 --> 01:24:59,350
i'm also showing the result from importance sampling gibbs sampling

1373
01:24:59,370 --> 01:25:03,560
again were after every sample you look at what is the quality of the answer

1374
01:25:03,760 --> 01:25:08,780
and so on the left curve showing how well you estimate posterior mean as you

1375
01:25:08,780 --> 01:25:12,510
saw before he has a much better result interestingly enough also get a very fast

1376
01:25:12,510 --> 01:25:18,370
circuit the compare amount time as competing plants that are very short bounds

1377
01:25:21,580 --> 01:25:25,220
on the third iteration gets it gets closer to the posterior mean but in practice

1378
01:25:25,220 --> 01:25:28,240
often moves back away from the posterior

1379
01:25:28,290 --> 01:25:34,290
that can certainly happen right is just an iterative fixpoint algorithm similarly gives sometimes gets

1380
01:25:34,290 --> 01:25:38,390
closer to the posterior mean moves is away taking samples and averaging

1381
01:25:40,370 --> 01:25:43,950
i have and i have an average the results over many problems which is so

1382
01:25:43,950 --> 01:25:47,390
usually you see averages over many many problems you see these nice smooth curves here

1383
01:25:47,390 --> 01:25:52,080
i'm showing it for one particular instances all the noise inherent in it

1384
01:25:52,100 --> 01:26:01,450
OK so right that that's just the the dynamics of the of the procedure if

1385
01:26:01,490 --> 01:26:05,700
it goes towards the towards the correct answer and then maybe overshoots considered to get

1386
01:26:12,140 --> 01:26:13,660
OK so

1387
01:26:13,830 --> 01:26:16,030
so what i'm comparing two years the exact

1388
01:26:16,050 --> 01:26:20,330
posterior mean not not the target value the album is trying to get out which

1389
01:26:20,330 --> 01:26:24,060
is which will be different each of the able cases

1390
01:26:24,080 --> 01:26:28,470
right so interesting thing to notice on this plot is that as they go from

1391
01:26:28,470 --> 01:26:30,720
twenty point two hundred points

1392
01:26:30,740 --> 01:26:36,970
the deterministic methods possibly being EP suddenly get very good i mean that the accuracy

1393
01:26:36,970 --> 01:26:38,350
is very high

1394
01:26:38,370 --> 01:26:40,680
i the right to the people

1395
01:26:40,700 --> 01:26:44,790
vertical scales the things of the these these methods have suddenly become practically p is

1396
01:26:44,790 --> 01:26:48,970
not the time minor sixth whereas the sampling methods are essentially the same air

1397
01:26:49,080 --> 01:26:51,160
as it did in twenty one case

1398
01:26:51,160 --> 01:26:53,010
and the reason for that

1399
01:26:53,030 --> 01:26:56,260
is that when you have more data the posterior becomes more and more gas sincere

1400
01:26:56,260 --> 01:27:01,300
assumption makes more and more sense so all of the these deterministic methods get better

1401
01:27:01,300 --> 01:27:04,990
that sort of a nice property all deterministic inference methods which is something that is

1402
01:27:04,990 --> 01:27:08,620
don't have so if you think about it the something that is generally don't benefit

1403
01:27:08,620 --> 01:27:10,240
from the fact that you're posteriors

1404
01:27:10,260 --> 01:27:12,060
is especially calcium

1405
01:27:12,120 --> 01:27:15,050
i mean the benefit from there being one more than two

1406
01:27:15,140 --> 01:27:18,530
but if you have one mil which is becoming more and more gas your something

1407
01:27:18,530 --> 01:27:22,470
that isn't going to suddenly become that the

1408
01:27:26,220 --> 01:27:30,200
it very very well that's right here

1409
01:27:32,580 --> 01:27:35,060
these were

1410
01:27:35,080 --> 01:27:38,140
well that gas property would be the same

1411
01:27:38,160 --> 01:27:40,780
even in our dimensions

1412
01:27:40,780 --> 01:27:43,160
here we like

1413
01:27:43,180 --> 01:27:44,780
that to

1414
01:27:44,810 --> 01:27:47,260
this is goal

1415
01:27:49,200 --> 01:27:50,560
so four

1416
01:27:50,580 --> 01:27:53,050
what we get

1417
01:27:53,050 --> 01:27:55,160
the results the

1418
01:27:55,220 --> 01:27:58,320
all will be so first of all these results are not really based on the

1419
01:27:58,320 --> 01:28:03,060
dimension of the problem so you you get results like this even if you make

1420
01:28:03,060 --> 01:28:06,330
even if you make the clutter from high dimensional so i have a version of

1421
01:28:06,330 --> 01:28:08,060
the core problem which is we have

1422
01:28:08,080 --> 01:28:12,050
OK dimensional gaussians which is observed with noise and so on and you can run

1423
01:28:12,390 --> 01:28:16,450
all these organs on new music exact same curves out when you're on the k

1424
01:28:16,450 --> 01:28:21,530
dimensional very it really the the difference in performance comes down to

1425
01:28:21,550 --> 01:28:23,390
the shape of the posterior

1426
01:28:23,410 --> 01:28:27,200
really what it comes down to so if you have a multivariate gaussian posterior

1427
01:28:27,220 --> 01:28:29,620
then deterministic i'm going to work very well

1428
01:28:29,640 --> 01:28:31,370
compared to sample one

1429
01:28:31,390 --> 01:28:34,720
that's that's really what it comes down to

1430
01:28:40,700 --> 01:28:44,200
this is

1431
01:28:44,310 --> 01:28:47,490
you know you user

1432
01:28:47,510 --> 01:28:51,740
in the evening when he

1433
01:28:53,200 --> 01:28:57,780
yes in fact variational bounds even more flavor

1434
01:28:57,810 --> 01:29:00,140
yes that appears that clear

1435
01:29:00,160 --> 01:29:06,700
why did i mean expectation propagation

1436
01:29:06,950 --> 01:29:11,640
why because there because it extends belief propagation

1437
01:29:11,640 --> 01:29:14,990
minus one so the question is how do you find these weights so you've got

1438
01:29:14,990 --> 01:29:18,640
this setup and you've got a linear algorithm where you're multiplying two in the inner

1439
01:29:18,640 --> 01:29:24,250
product to find the answer and then you thresholding it too

1440
01:29:24,270 --> 01:29:29,520
give an answer as to what the class the data point is so his algorithm

1441
01:29:29,520 --> 01:29:33,450
i'm not sure about initialisation perceptrons how people do that but i just came up

1442
01:29:33,450 --> 01:29:36,250
with the initialisation of my

1443
01:29:37,200 --> 01:29:39,790
there is an algorithm for finding the weights

1444
01:29:39,820 --> 01:29:44,180
so select random data points you've got some data set of points you just choose

1445
01:29:44,180 --> 01:29:46,670
one data point around

1446
01:29:46,670 --> 01:29:53,060
and they use you ensure that point is correctly classified by setting these weights

1447
01:29:53,120 --> 01:29:54,950
two whatever the label is

1448
01:29:54,960 --> 01:29:56,190
times x

1449
01:29:56,200 --> 01:29:57,660
whatever the input was

1450
01:29:57,680 --> 01:30:04,430
OK so why does that insurance classified because that ensures correctly classified because basically

1451
01:30:05,980 --> 01:30:11,870
thing is the sign of w transpose x which if we substitute values for w

1452
01:30:11,870 --> 01:30:16,970
in why then that this gives us the sign why i find x transpose x

1453
01:30:16,970 --> 01:30:20,730
i now that is always going to be positive x transpose x i

1454
01:30:20,730 --> 01:30:25,330
so basically this is just the sign why i so it's the late so that's

1455
01:30:25,330 --> 01:30:30,120
the way of ensuring some kind an algorithm and the way i'm inventing algorithms i'm

1456
01:30:30,950 --> 01:30:33,610
well i that this

1457
01:30:33,630 --> 01:30:37,550
i'm trying to go through a process of inventing is if i'm inventing it and

1458
01:30:37,570 --> 01:30:44,750
initialisation ensuring the initialisation sets a random data point classifiers that the point correctly

1459
01:30:44,770 --> 01:30:48,890
now i'm going to iterate because other points on classified correctly and what i'm going

1460
01:30:48,940 --> 01:30:51,220
to reiterate its

1461
01:30:52,120 --> 01:30:56,230
a misclassified point for getting growing k i remove that they to move that section

1462
01:30:56,230 --> 01:30:59,470
so taken new misclassified point right

1463
01:30:59,500 --> 01:31:04,800
so now we've got some other misclassified points and what we do is we had

1464
01:31:04,840 --> 01:31:09,320
so this thing we set to here we add some portion of this to our

1465
01:31:09,320 --> 01:31:11,540
existing weight

1466
01:31:11,550 --> 01:31:15,370
so we basically train existing weight and then this is the portion we call this

1467
01:31:15,370 --> 01:31:16,660
the learning rate

1468
01:31:16,660 --> 01:31:21,210
and then some proportion of this y i x we add it now

1469
01:31:21,260 --> 01:31:26,890
the point in doing this is if they this argument here still holds this number

1470
01:31:26,920 --> 01:31:27,940
is large enough

1471
01:31:28,470 --> 01:31:32,120
what will happen is will be back to this situation this term will dominate if

1472
01:31:32,120 --> 01:31:35,450
this learning rate is large enough yet so there's obviously if we make a really

1473
01:31:35,450 --> 01:31:39,170
large learning rate will classify the new data point correctly

1474
01:31:39,180 --> 01:31:40,170
now we we

1475
01:31:40,190 --> 01:31:41,380
we don't want to go

1476
01:31:41,400 --> 01:31:45,400
just classify the new data point correctly and ignore the old one so we find

1477
01:31:45,400 --> 01:31:50,210
some balance where we reduce this learning rate is level so we got some combination

1478
01:31:50,210 --> 01:31:52,440
of the data points

1479
01:31:52,460 --> 01:31:56,170
and by doing that this be this new data point might be correctly classified all

1480
01:31:56,170 --> 01:31:59,960
the decision boundary will move towards that and then we'll repeat this until there's no

1481
01:31:59,960 --> 01:32:03,880
misspecified points are going to little demo of that

1482
01:32:04,820 --> 01:32:06,490
if i can see it correctly

1483
01:32:10,170 --> 01:32:12,670
iteration one with a simple dataset

1484
01:32:12,670 --> 01:32:18,850
and what we're going do is we select a data point for initialisation and then

1485
01:32:18,850 --> 01:32:21,590
what we do is

1486
01:32:21,610 --> 01:32:26,590
we for the first iteration assume that these are initialised first iterations we say the

1487
01:32:26,590 --> 01:32:30,960
way they we set the weight vector to that data point

1488
01:32:30,990 --> 01:32:34,800
multiply by one and this is the positive this is the positive class this is

1489
01:32:34,800 --> 01:32:39,960
the negative class so what that means is that actually we say that weight vector

1490
01:32:39,960 --> 01:32:43,300
to exactly the data point and this is a common way of showing decision boundaries

1491
01:32:43,530 --> 01:32:47,760
you show the line of decision and then the weight vector is always a normal

1492
01:32:47,760 --> 01:32:52,320
direction to that line in this case pointing at the data point we selected so

1493
01:32:52,320 --> 01:32:57,880
that they point will now be correctly classified by guaranteed by the initialisation of the

1494
01:32:57,880 --> 01:33:01,820
other thing is of course it is also correctly classified bunch other points because in

1495
01:33:01,820 --> 01:33:06,260
the simulation but there's things incorrectly despite all these are now being said to be

1496
01:33:06,260 --> 01:33:09,710
positive and all these are being sent to be negative in fact only these data

1497
01:33:09,710 --> 01:33:13,380
points positive so we now find

1498
01:33:14,320 --> 01:33:16,570
incorrectly classified data points

1499
01:33:16,590 --> 01:33:21,260
we've got a current weights

1500
01:33:21,280 --> 01:33:26,280
but incorrect classification we adjust the weight vector with the new data points we add

1501
01:33:26,340 --> 01:33:28,090
that proportional

1502
01:33:28,150 --> 01:33:31,890
of the new data point now because if you look at where the vector is

1503
01:33:31,890 --> 01:33:35,670
from the origin so i purposely chose the decision boundary to go through the origin

1504
01:33:35,670 --> 01:33:40,010
so this works you can see the vector this data point here basically is a

1505
01:33:40,010 --> 01:33:45,150
vector pointing in this direction from the origin so when we had that that new

1506
01:33:45,150 --> 01:33:48,840
data point we can add some components of that that

1507
01:33:48,860 --> 01:33:50,490
to this point here

1508
01:33:50,550 --> 01:33:55,070
and so we'll see a new decision boundary points in this direction

1509
01:33:55,090 --> 01:33:57,360
so actually flips around and now

1510
01:33:57,380 --> 01:33:58,240
there was

1511
01:33:58,300 --> 01:34:00,090
partial components that

1512
01:34:00,110 --> 01:34:05,510
original that being added here we're now pointing in this direction OK so the you

1513
01:34:05,510 --> 01:34:08,860
incorrectly classified data points i think there is green one it should be i can't

1514
01:34:08,860 --> 01:34:10,240
see from this angle

1515
01:34:12,920 --> 01:34:17,630
so one of the negative data points is is now

1516
01:34:17,650 --> 01:34:22,650
the incorrectly classified data points on the positive side of the decision boundary to be

1517
01:34:22,650 --> 01:34:26,150
the same thing again but this time we're gonna be subtracting because the sign of

1518
01:34:26,150 --> 01:34:30,210
the data point is negative

1519
01:34:30,230 --> 01:34:34,300
so this sign of this fifty eight data point is negative sort subtracting that vector

1520
01:34:34,300 --> 01:34:38,650
component of only a little bit of it and now all the data is correctly

1521
01:34:38,650 --> 01:34:41,150
classified so we don't

1522
01:34:41,190 --> 01:34:46,510
that's actually a remarkably fast classification algorithm for data sets of this type

1523
01:34:47,190 --> 01:34:51,190
it is true that the perceptron algorithm does tend to converge very quickly if the

1524
01:34:51,190 --> 01:34:54,880
data is fully separated and not going to talk about what happens if the data

1525
01:34:54,880 --> 01:34:58,240
is separated but basically this proves about

1526
01:34:58,260 --> 01:35:01,900
if you set up your learning rate if you reduce your learning rate

1527
01:35:01,990 --> 01:35:06,050
at a certain what value you will converge towards something in the limit of large

1528
01:35:06,050 --> 01:35:07,740
data which is the optimal

1529
01:35:07,740 --> 01:35:13,550
decision boundary so i think the really nice thing about this algorithm is the

1530
01:35:13,550 --> 01:35:16,860
i mean i think rosenblatt book in nineteen sixty three but he was using in

1531
01:35:16,860 --> 01:35:21,140
the fifties and he was head of course on how the brain works where he

1532
01:35:21,140 --> 01:35:23,260
used to sit on

1533
01:35:31,900 --> 01:35:34,800
good question

1534
01:35:34,900 --> 01:35:40,400
not what want not really equipped to ask answer that i had this diagram in

1535
01:35:41,420 --> 01:35:43,440
so it's the threshold like that

1536
01:35:44,340 --> 01:35:48,840
one of the things in machine learning that one of the things in

1537
01:35:48,860 --> 01:35:50,820
and it's community that we knew

1538
01:35:50,880 --> 01:35:54,650
is that if you could draw your algorithm with the circle

1539
01:35:54,650 --> 01:35:56,960
and a bunch of interconnecting lines

1540
01:35:57,110 --> 01:36:01,990
that meant it was like the brain

1541
01:36:06,380 --> 01:36:08,380
the idea was that you had

1542
01:36:08,470 --> 01:36:09,990
you're in

1543
01:36:10,010 --> 01:36:12,190
x one x two x three

1544
01:36:12,210 --> 01:36:15,490
w one w two

1545
01:36:15,510 --> 01:36:16,740
w three

1546
01:36:16,740 --> 01:36:19,900
and then you have this was input from another neuron

1547
01:36:19,920 --> 01:36:24,420
or cents so in this case it's obviously this is

1548
01:36:24,470 --> 01:36:28,130
i mean we did multi-layered perceptrons as well and they were quite effective algorithms but

1549
01:36:28,130 --> 01:36:30,590
this in this case you have to think of it some sort of a same

1550
01:36:30,590 --> 01:36:37,030
if i have a a set of entries that has been corrected

1551
01:36:37,030 --> 01:36:42,380
at random locations of positive fraction of entries have been corrupted

1552
01:36:42,380 --> 01:36:47,700
random locations and i solve this problem with lambda equals one of the square root

1553
01:36:47,700 --> 01:36:52,700
of the dimension so is no cross validation or anything of this nature i just

1554
01:36:52,700 --> 01:36:56,840
take long that equals one of the code of the dimension

1555
01:36:56,860 --> 01:36:58,510
then the theorem says

1556
01:36:58,530 --> 01:37:01,700
that with very high probability and the probability is over the distribution

1557
01:37:01,700 --> 01:37:07,890
of the locations of the errors then this solution is exact that is i recover

1558
01:37:07,950 --> 01:37:13,090
the lower income one exactly and recovers sparse company exactly this is something that when

1559
01:37:13,090 --> 01:37:16,970
i look at it i almost find impossible

1560
01:37:17,070 --> 01:37:20,950
i prepare low rank matrix i give it to you you look at a lot

1561
01:37:20,950 --> 01:37:21,930
of entries

1562
01:37:21,990 --> 01:37:23,860
you corrupt them

1563
01:37:23,880 --> 01:37:25,650
you give it back to me

1564
01:37:25,660 --> 01:37:31,300
well not to meet somebody else because we already know what prepared

1565
01:37:31,340 --> 01:37:35,360
use of this optimisation problem depends on nothing so use so nuclear norm plus one

1566
01:37:35,360 --> 01:37:38,160
of his code of dimension times one of the

1567
01:37:38,180 --> 01:37:40,110
and you will find exactly what you did

1568
01:37:40,150 --> 01:37:44,260
all the entries you've touch how you touch them and so so you recover the

1569
01:37:44,280 --> 01:37:48,610
low rank structure and it's an exact recovery that has nothing to do

1570
01:37:48,630 --> 01:37:52,760
the exact amount of what the magnitude of the loan companies and no matter what

1571
01:37:52,760 --> 01:37:58,260
the magnitude of the sparse there is no tuning parameter is in this thing just

1572
01:37:58,300 --> 01:37:59,840
just the way it is

1573
01:38:01,760 --> 01:38:03,220
so we seem to

1574
01:38:04,260 --> 01:38:09,180
one way have missing data the other one is more complicated because now we have

1575
01:38:09,180 --> 01:38:12,860
corruption so in the missing data world is good because

1576
01:38:12,880 --> 01:38:15,530
what you've got is you've got an entry and then you have to predict missing

1577
01:38:15,530 --> 01:38:18,650
entries but you know these entries including the corrupted world you never know when you

1578
01:38:18,650 --> 01:38:21,820
look at the data point to good data point about data point you have to

1579
01:38:31,930 --> 01:38:35,820
it for those of you know about cutting theories like you have erasures here and

1580
01:38:35,840 --> 01:38:39,950
errors here and it's much harder to correct errors than to deal with the rangers

1581
01:38:41,220 --> 01:38:42,110
OK so

1582
01:38:42,130 --> 01:38:46,740
it's information theoretically harder so if you look at this so what we've done is

1583
01:38:46,740 --> 01:38:51,780
we've run the algorithms what you see on the right hand side is uses the

1584
01:38:51,780 --> 01:38:55,490
rank of the low rank component divided by the dimension

1585
01:38:55,490 --> 01:39:00,110
and on the white ox y axis uses the sparsity

1586
01:39:00,110 --> 01:39:04,490
that is the number of the fraction of entries have been corrected

1587
01:39:04,490 --> 01:39:11,090
then each pixel on these images lot of experiment a great example is the experiment

1588
01:39:11,150 --> 01:39:13,360
which method works half the time

1589
01:39:13,410 --> 01:39:17,010
a white pixels one hundred percent of the time a black pixel it works zero

1590
01:39:17,010 --> 01:39:20,950
percent of the time what you see here is used in a very sharp phase

1591
01:39:20,950 --> 01:39:25,090
transition between the regime was the algorithm is perfect and the regime in which it

1592
01:39:25,090 --> 01:39:26,590
fails miserably

1593
01:39:26,630 --> 01:39:31,860
OK but the regime in which person is very interesting so let's be in his

1594
01:39:31,860 --> 01:39:36,650
white region for example is the rank is the total dimension divided by

1595
01:39:36,700 --> 01:39:41,530
ten so and over ten what this plot indicates that can corrupt thirty percent of

1596
01:39:41,530 --> 01:39:42,970
the entries

1597
01:39:42,970 --> 01:39:45,360
and it's harmless

1598
01:39:45,380 --> 01:39:48,200
k is the rank decreases two

1599
01:39:48,220 --> 01:39:50,450
five percent and over twenty

1600
01:39:50,470 --> 01:39:54,490
i can corrupt almost half of the entries in is to harmless

1601
01:39:54,530 --> 01:40:00,090
OK in the matrix completion world the region where things go better is much larger

1602
01:40:00,090 --> 01:40:05,650
because it's here now this is the fraction of missing entries so the right region

1603
01:40:05,650 --> 01:40:09,930
is much larger because it's much easier to deal with missing entries and was corrupted

1604
01:40:13,570 --> 01:40:18,070
so i'm writing a bit of time because i want to show you some numerical

1605
01:40:19,800 --> 01:40:24,010
i want to mention this very important paper by alan willsky and his colleagues introducing

1606
01:40:24,010 --> 01:40:29,150
deterministic results of very beautiful piece of work and just like as matrix completion is

1607
01:40:29,930 --> 01:40:34,200
this robust PCA generates a lot of interest and since then a lot of people

1608
01:40:34,200 --> 01:40:40,260
in machine learning and statistics have been able to even improve on these results

1609
01:40:40,260 --> 01:40:45,470
that's a lot of activity at the moment by several teams around the world getting

1610
01:40:45,680 --> 01:40:48,180
better and better results

1611
01:40:48,200 --> 01:40:52,860
OK in fact the last result i want mentioned but i don't want to take

1612
01:40:52,860 --> 01:40:56,220
too much of your time says well you could tie them together you could have

1613
01:40:56,220 --> 01:41:01,590
both missing and corrupted entries and you run the optimisation algorithm and you

1614
01:41:01,610 --> 01:41:02,880
back out the

1615
01:41:02,880 --> 01:41:07,470
this is one source of variance the p three is different in each

1616
01:41:07,490 --> 01:41:12,590
and another strong source of variance is a vision for

1617
01:41:12,610 --> 01:41:15,320
from the visual areas

1618
01:41:18,740 --> 01:41:21,340
and so this is not

1619
01:41:21,360 --> 01:41:22,860
and important

1620
01:41:22,880 --> 01:41:24,360
on the then

1621
01:41:24,610 --> 01:41:28,530
what what is noise does and how it has to be

1622
01:41:28,550 --> 01:41:30,470
the accounted for the classifier

1623
01:41:30,610 --> 01:41:31,360
so i

1624
01:41:31,770 --> 01:41:35,160
this is artificially generated from

1625
01:41:35,180 --> 01:41:37,240
not so much the better

1626
01:41:37,260 --> 01:41:38,240
so we have

1627
01:41:39,920 --> 01:41:45,860
two electrodes have CP set in the two conditions target and nontarget

1628
01:41:45,880 --> 01:41:48,880
so the very nicely separated because there

1629
01:41:48,970 --> 01:41:50,380
quite clean

1630
01:41:50,400 --> 01:41:55,400
but we have seen that one source of noise for example comes from the

1631
01:41:55,430 --> 01:41:57,680
i've written from from all that

1632
01:41:57,680 --> 01:41:59,720
no i added some

1633
01:41:59,740 --> 01:42:00,660
to this

1634
01:42:00,700 --> 01:42:02,420
q data some

1635
01:42:02,470 --> 01:42:05,700
the result from all that this two different factors

1636
01:42:05,720 --> 01:42:10,400
so this is neurons effect of fuzzy set the

1637
01:42:10,450 --> 01:42:11,780
if c two

1638
01:42:11,800 --> 01:42:14,950
and then we get this plot

1639
01:42:14,970 --> 01:42:21,090
while the classification linear classification and fifteen percent of their on the the second case

1640
01:42:22,420 --> 01:42:26,180
thirty seven percent of our own

1641
01:42:27,490 --> 01:42:30,300
in this case you know the source of

1642
01:42:30,300 --> 01:42:31,340
the noise

1643
01:42:31,360 --> 01:42:34,010
so if we had this disturbing channel

1644
01:42:34,010 --> 01:42:34,920
o that

1645
01:42:34,920 --> 01:42:37,950
that's introduces noise and weak classifier

1646
01:42:38,030 --> 01:42:41,990
in this region then again we have zero

1647
01:42:42,010 --> 01:42:44,400
sixteen percent

1648
01:42:44,420 --> 01:42:49,090
and so it is important message here is that we need is always that channel

1649
01:42:48,950 --> 01:42:51,430
centre-forward classification also

1650
01:42:51,450 --> 01:42:53,260
in itself has no

1651
01:42:53,260 --> 01:42:55,090
discriminative information

1652
01:42:55,090 --> 01:42:58,740
so the the mean for the two conditions and all that is the same for

1653
01:42:58,740 --> 01:43:00,530
both classes

1654
01:43:01,150 --> 01:43:05,490
nevertheless we needed for classification so therefore you see that

1655
01:43:05,760 --> 01:43:10,400
in this case got my first one where we only use the difference between the

1656
01:43:10,400 --> 01:43:12,300
two means that the classifiers

1657
01:43:12,320 --> 01:43:16,340
this does not account for for this this noise

1658
01:43:16,360 --> 01:43:17,490
so this

1659
01:43:18,180 --> 01:43:22,590
the difference of the mean whatever the weight zero for the channel of that and

1660
01:43:22,590 --> 01:43:25,430
would not make use of only if e

1661
01:43:25,720 --> 01:43:28,280
i have to log gamma

1662
01:43:28,300 --> 01:43:31,180
we account for the noise and therefore

1663
01:43:31,970 --> 01:43:36,240
from the topography maybe you would like more this small theatres

1664
01:43:36,760 --> 01:43:41,400
but i hope i convinced you that is more complicated

1665
01:43:41,530 --> 01:43:44,070
important to account for the noise

1666
01:43:44,150 --> 01:43:46,590
only this page you can cancel out

1667
01:43:46,650 --> 01:43:49,700
noise from other anecdotes

1668
01:43:49,760 --> 01:43:52,070
here see the error rates and you see

1669
01:43:52,110 --> 01:43:55,590
in this case the law come about non-zero gamma

1670
01:43:55,610 --> 01:43:56,650
what is it

1671
01:43:56,700 --> 01:43:58,030
the best

1672
01:44:00,720 --> 01:44:03,180
now i hope hopefully

1673
01:44:03,180 --> 01:44:04,450
convinced that it

1674
01:44:04,470 --> 01:44:05,680
the shrinkage is the

1675
01:44:05,760 --> 01:44:07,220
the nice thing about

1676
01:44:07,240 --> 01:44:14,240
so far is problem that this the selection is time consuming this first validation but

1677
01:44:14,240 --> 01:44:21,150
recently there was an analytical way to calculate optimum government was published and we pointed

1678
01:44:21,150 --> 01:44:22,720
to this technique

1679
01:44:22,740 --> 01:44:25,220
because i am a part of

1680
01:44:25,240 --> 01:44:27,450
you don't

1681
01:44:27,470 --> 01:44:30,800
so this is the setting is again we

1682
01:44:30,820 --> 01:44:33,590
feature vectors estimate of the mean

1683
01:44:33,630 --> 01:44:35,760
and this

1684
01:44:35,760 --> 01:44:38,070
covariance matrix and we want to

1685
01:44:38,090 --> 01:44:40,930
five best shrinkage

1686
01:44:40,950 --> 01:44:43,930
to get improved covariance matrix

1687
01:44:43,950 --> 01:44:45,320
and so

1688
01:44:45,320 --> 01:44:47,510
use something that is

1689
01:44:47,530 --> 01:44:50,470
quite using the which is the hinge loss

1690
01:44:57,760 --> 01:44:59,990
so now

1691
01:45:00,130 --> 01:45:03,010
so we should relax our goal

1692
01:45:03,050 --> 01:45:04,160
and we

1693
01:45:04,430 --> 01:45:06,360
is that of

1694
01:45:06,430 --> 01:45:10,760
OK so let's look at this

1695
01:45:10,780 --> 01:45:13,610
graph here we have a marginal

1696
01:45:13,650 --> 01:45:14,780
or some

1697
01:45:14,800 --> 01:45:16,240
classified u

1698
01:45:16,260 --> 01:45:18,920
on some example YX

1699
01:45:18,950 --> 01:45:20,130
so what we know

1700
01:45:20,150 --> 01:45:21,920
is that

1701
01:45:21,950 --> 01:45:26,760
there's a mistake one imagine walking scholars

1702
01:45:26,780 --> 01:45:32,240
there's a mistake when the when the function is when imagining negative by definition

1703
01:45:32,280 --> 01:45:39,900
a mistake here

1704
01:45:39,920 --> 01:45:42,090
my mistake here

1705
01:45:42,110 --> 01:45:45,470
this is a lot of being a

1706
01:45:45,490 --> 01:45:49,470
the mistake indicator function on the margin

1707
01:45:49,820 --> 01:45:55,900
and now we want to use something which is a convex linear piecewise linear approximation

1708
01:45:55,900 --> 01:45:56,970
of it

1709
01:45:56,970 --> 01:46:00,280
which is the hinge loss

1710
01:46:00,300 --> 01:46:02,320
which is a bit

1711
01:46:03,990 --> 01:46:13,070
so this is i call it

1712
01:46:13,090 --> 01:46:16,360
this is the graph of

1713
01:46:16,380 --> 01:46:18,590
the graph of the function

1714
01:46:19,780 --> 01:46:24,800
between zero and one minus y

1715
01:46:25,590 --> 01:46:27,320
keep in the same year

1716
01:46:27,340 --> 01:46:30,780
new acts

1717
01:46:31,320 --> 01:46:33,660
we take also did not we

1718
01:46:34,010 --> 01:46:36,930
one minus one u

1719
01:46:36,990 --> 01:46:44,880
he plus the math which i also did not there

1720
01:46:47,550 --> 01:46:51,070
difficult if i love

1721
01:46:56,800 --> 01:47:02,280
three keys to score the guy against which comparing

1722
01:47:02,300 --> 01:47:04,220
using this hinge loss is that of the

1723
01:47:04,300 --> 01:47:06,610
of the mistake indicator function

1724
01:47:06,630 --> 01:47:09,200
and being these conflicts

1725
01:47:09,220 --> 01:47:12,530
you have you seen this is an upper bound

1726
01:47:12,570 --> 01:47:16,450
this is a convex upper bound on the step function this is going to be

1727
01:47:16,450 --> 01:47:20,030
if score my you with this means a lot

1728
01:47:20,050 --> 01:47:21,030
and grateful

1729
01:47:21,030 --> 01:47:22,490
penalized more

1730
01:47:22,510 --> 01:47:25,950
the guy on the right side my competitor

1731
01:47:26,090 --> 01:47:31,780
that's why you that is not the way to be able to prove things

1732
01:47:31,820 --> 01:47:34,930
indeed this is pretty much in

1733
01:47:34,930 --> 01:47:40,030
and nothing important to not if you score

1734
01:47:40,720 --> 01:47:44,570
was of classifier with the hinge loss then the length of your matter

1735
01:47:44,610 --> 01:47:49,880
the length of humans so let's look at a little bit more to the first

1736
01:47:49,880 --> 01:47:53,680
of all you know they're not just that being gay when the margin

1737
01:47:53,740 --> 01:47:56,880
is smaller than one and opinion

1738
01:47:57,220 --> 01:48:00,260
and now so

1739
01:48:00,260 --> 01:48:05,260
you could be have zero into laws should never mind in at least one of

1740
01:48:05,280 --> 01:48:07,400
each example

1741
01:48:07,400 --> 01:48:09,970
so for is that now

1742
01:48:09,970 --> 01:48:12,030
suppose that

1743
01:48:12,130 --> 01:48:16,430
assume that this is a sphere is

1744
01:48:16,450 --> 01:48:22,320
and that so you have unit norm x seven hundred

1745
01:48:22,320 --> 01:48:24,360
if you want

1746
01:48:24,400 --> 01:48:29,220
and you have some unique or x

1747
01:48:29,240 --> 01:48:32,990
which part of the data

1748
01:48:32,990 --> 01:48:35,300
so you don't

1749
01:48:35,340 --> 01:48:37,780
with positive label

1750
01:48:37,920 --> 01:48:42,610
it is classified correctly but it's not enough for the about to be zero

1751
01:48:42,660 --> 01:48:48,360
you you have to be long enough so they

1752
01:48:48,380 --> 01:48:50,820
this is enough

1753
01:48:50,860 --> 01:48:57,900
so that the projection of u onto way it's little like this one

1754
01:48:58,030 --> 01:49:01,090
fine but if you take x like these

1755
01:49:03,660 --> 01:49:04,990
and then the

1756
01:49:05,010 --> 01:49:09,320
tangent here you see the who was who was trying to learn more

1757
01:49:09,340 --> 01:49:14,570
a lot more so that the projection onto the effect will have my mac imagine

1758
01:49:15,970 --> 01:49:19,610
so that the projection of x this one

1759
01:49:19,630 --> 01:49:23,720
so now we need to continue you

1760
01:49:23,720 --> 01:49:24,720
so too

1761
01:49:25,400 --> 01:49:29,150
so to make it achieve margin of the


1
00:00:00,000 --> 00:00:02,520
and the most obvious one is security performance

2
00:00:02,600 --> 00:00:07,860
select a small measure of performance

3
00:00:07,870 --> 00:00:09,180
most people in the moment

4
00:00:09,200 --> 00:00:10,280
by that

5
00:00:10,340 --> 00:00:14,650
there are some applications things the computation service

6
00:00:14,670 --> 00:00:17,540
where people have reduced internal security

7
00:00:17,650 --> 00:00:20,150
because it makes the week-long job finish

8
00:00:20,160 --> 00:00:27,150
eight hours earlier which is quite nice

9
00:00:27,160 --> 00:00:29,710
so if look kind the details as the

10
00:00:29,740 --> 00:00:35,260
the unique smallest that is you the configuration file eureka polk kind

11
00:00:35,280 --> 00:00:44,380
this advanced over time as the point because the expensive we don't want to read

12
00:00:44,390 --> 00:00:48,800
because we don't want to give you all the a single large binary you can't

13
00:00:51,200 --> 00:00:54,950
so they got the idea for device configuration at the time your machine boots up

14
00:00:54,950 --> 00:00:57,070
this is where learning

15
00:00:57,090 --> 00:00:58,320
and it's

16
00:00:58,350 --> 00:01:00,490
yes you this problem

17
00:01:00,520 --> 00:01:03,570
that would cause i know your machine looks like i'm not going to look any

18
00:01:07,760 --> 00:01:09,040
everything is done

19
00:01:09,050 --> 00:01:12,720
then with the actual model we use

20
00:01:12,730 --> 00:01:17,990
it is such that all the drivers using it sparingly it happens dynamically

21
00:01:18,010 --> 00:01:20,250
at the time

22
00:01:20,260 --> 00:01:24,760
each driver which is loaded time effectively get said well look like of a given

23
00:01:26,000 --> 00:01:28,630
this device appeared this device appeared

24
00:01:28,690 --> 00:01:31,600
listing all hard which present

25
00:01:31,610 --> 00:01:35,900
so device driver authors don't have to do something different that the hardware

26
00:01:36,060 --> 00:01:37,850
all right light

27
00:01:37,880 --> 00:01:40,590
the idea that you have to do two things they want to do one or

28
00:01:40,590 --> 00:01:44,210
the other never do so they never get it right

29
00:01:44,270 --> 00:01:49,060
so we were making people life easier

30
00:01:49,110 --> 00:01:53,240
so there is we've got a couple model where things appear

31
00:01:53,710 --> 00:01:59,040
we have a question because if things that dynamically

32
00:01:59,060 --> 00:02:00,780
the traditional unix model

33
00:02:00,790 --> 00:02:02,850
was he have device file system

34
00:02:02,850 --> 00:02:04,340
plug in this case

35
00:02:04,360 --> 00:02:09,370
you create a device node lh a of the HDP

36
00:02:09,390 --> 00:02:13,660
the distribution of ships with kind of standard

37
00:02:13,680 --> 00:02:18,750
but nowadays device to appear and disappear as you have removed

38
00:02:18,770 --> 00:02:23,940
so the first thing we tried think of death that the kind but file system

39
00:02:23,950 --> 00:02:29,050
so the kind of you'll see it presented you with your device files

40
00:02:29,130 --> 00:02:32,420
the problem with that you can't really really figure

41
00:02:32,440 --> 00:02:34,130
so does this

42
00:02:34,150 --> 00:02:35,900
its mission

43
00:02:38,570 --> 00:02:42,490
if you want for example you want this to be swapped around fifty nine

44
00:02:42,510 --> 00:02:44,340
you could do

45
00:02:44,400 --> 00:02:45,880
so i didn't really work

46
00:02:46,470 --> 00:02:49,720
the modelling use now is think called you

47
00:02:49,740 --> 00:02:51,570
the kernel sends a message to

48
00:02:51,590 --> 00:02:53,070
hough green

49
00:02:53,090 --> 00:02:56,260
using hate this new hardware

50
00:02:56,280 --> 00:03:01,130
and a set scripts called you defend normally do the work so well

51
00:03:01,150 --> 00:03:03,490
it's hard disk it's this

52
00:03:03,820 --> 00:03:06,820
because the device should create

53
00:03:06,840 --> 00:03:09,400
see what they see two

54
00:03:09,400 --> 00:03:11,470
create nodes

55
00:03:11,490 --> 00:03:14,900
and it does not using rule files which are used space

56
00:03:14,920 --> 00:03:17,130
and scripts are also added

57
00:03:17,150 --> 00:03:21,590
so as an end user system and you could change the way this works figure

58
00:03:21,780 --> 00:03:24,460
make it do what you want

59
00:03:24,530 --> 00:03:29,990
that avoids the problem we have data for us

60
00:03:30,010 --> 00:03:31,070
so we

61
00:03:31,070 --> 00:03:34,780
the album that no then model we to an that

62
00:03:34,800 --> 00:03:36,050
gonna like this

63
00:03:36,070 --> 00:03:37,840
you asking things

64
00:03:37,860 --> 00:03:42,240
into doing things the way we want

65
00:03:42,260 --> 00:03:43,900
so now nowadays

66
00:03:43,900 --> 00:03:45,150
o device are

67
00:03:45,150 --> 00:03:48,420
we respond to events greater than you space

68
00:03:48,440 --> 00:03:53,360
hopefully user space is interesting things

69
00:03:53,380 --> 00:03:56,360
the namespaces dynamic is committed

70
00:03:56,630 --> 00:03:58,340
i don't know

71
00:03:58,360 --> 00:04:00,030
we were doing events

72
00:04:00,050 --> 00:04:04,030
image object lifetimes again

73
00:04:04,050 --> 00:04:05,880
internally in the car

74
00:04:05,900 --> 00:04:07,510
we now

75
00:04:07,570 --> 00:04:10,170
basic optical tail

76
00:04:10,170 --> 00:04:15,970
which is basically a name is reference can hang everything else all

77
00:04:16,300 --> 00:04:20,740
the kernel does do garbage collection there are lots and lots of problems with doing

78
00:04:20,760 --> 00:04:23,280
garbage collection in the county

79
00:04:23,340 --> 00:04:27,490
things like knowing the worst case memory use

80
00:04:27,530 --> 00:04:28,440
the fact that

81
00:04:28,460 --> 00:04:32,510
a real-time garbage collection algorithms are

82
00:04:32,530 --> 00:04:34,240
very very hard

83
00:04:34,340 --> 00:04:35,130
sort of

84
00:04:35,170 --> 00:04:38,720
kind of research materials like cases

85
00:04:38,800 --> 00:04:44,530
the basic reference counting it and we don't get circular references become very of often

86
00:04:44,550 --> 00:04:48,960
there's only one normal things that happen in the pacific garbage collector

87
00:04:49,150 --> 00:04:52,900
what the user made sockets file description c

88
00:04:52,920 --> 00:04:56,860
the result special case or not

89
00:04:56,920 --> 00:05:00,920
a total of all the people who designed it works

90
00:05:00,940 --> 00:05:05,780
but we don't really need to go over work

91
00:05:05,880 --> 00:05:07,960
these object properly referenced

92
00:05:08,010 --> 00:05:09,360
means that

93
00:05:09,380 --> 00:05:14,550
you can say well i'm using it not using its free when the last person

94
00:05:14,590 --> 00:05:16,840
finished using it

95
00:05:16,840 --> 00:05:19,010
so this does all this hopefully to do

96
00:05:19,030 --> 00:05:23,490
things went free memory before you finished using it

97
00:05:23,590 --> 00:05:27,220
and we use this to build generic device subject to build

98
00:05:27,260 --> 00:05:30,610
PCI device or PCI thing

99
00:05:31,030 --> 00:05:35,220
platform devices things that fit in the else

100
00:05:35,570 --> 00:05:42,940
i suppose devices devices use devices will be all the classes and everywhere

101
00:05:42,940 --> 00:05:45,990
and we have a single system versus system file system

102
00:05:46,030 --> 00:05:50,630
which allows you to actually see all these values of configuration files all these devices

103
00:05:50,630 --> 00:05:53,380
hope for the

104
00:05:53,400 --> 00:05:58,690
the model of the dynamics no good just saying something is happening is

105
00:05:58,780 --> 00:06:02,990
you have to make it is when you place so let's call change that was

106
00:06:02,990 --> 00:06:04,720
just this

107
00:06:04,740 --> 00:06:09,460
because all these things you're just to your size this use all ceased big files

108
00:06:09,740 --> 00:06:15,840
in my service performing a double-sided disc you define can the violence

109
00:06:15,860 --> 00:06:21,360
doesn't work i kind of want

110
00:06:21,470 --> 00:06:25,940
so that's self is a hierarchical file system

111
00:06:26,440 --> 00:06:30,440
uses the name space the k objects things or configuration

112
00:06:30,510 --> 00:06:35,650
so it's really fast and things have real names and all qn numbers magic magic

113
00:06:35,650 --> 00:06:38,610
constant they were assessed

114
00:06:39,090 --> 00:06:44,260
we trying to replace the process other old things with

115
00:06:44,260 --> 00:06:48,150
it's also dynamically extensible so every time you add a new try to create a

116
00:06:48,150 --> 00:06:50,530
new node is the director

117
00:06:50,550 --> 00:06:53,220
and so this thing can just browse it needs to

118
00:06:53,240 --> 00:06:55,840
when you been used this

119
00:06:55,860 --> 00:06:59,260
i mean these user space can not only to figure things that you can actually

120
00:06:59,260 --> 00:07:01,740
walk says fast

121
00:07:01,740 --> 00:07:03,140
sharp transition

122
00:07:03,160 --> 00:07:05,350
and in terms of approximation

123
00:07:05,410 --> 00:07:09,990
whenever smooth transition i can be much more sloppy with my approximation and won't hurt

124
00:07:09,990 --> 00:07:14,550
me as much as the situation where i have very sharp transition in the conditional

125
00:07:14,550 --> 00:07:18,010
probability function and that's a little easier to see if we just look at a

126
00:07:18,010 --> 00:07:21,370
one d example so this is the one d example what plotting here is the

127
00:07:21,370 --> 00:07:23,780
conditional probability of y one

128
00:07:23,850 --> 00:07:28,050
in two different cases in this case where we have a smooth transition

129
00:07:28,080 --> 00:07:32,100
around the level set one half and so you can imagine if an approximate the

130
00:07:32,100 --> 00:07:35,680
bayes decision says you should have the threshold right here

131
00:07:35,720 --> 00:07:40,810
and if i'm a little bit off my approximation one her much because the probability

132
00:07:40,810 --> 00:07:44,850
of error very gradually around that one half level sets

133
00:07:44,870 --> 00:07:48,830
the situation is different over in this fits very sharp transition or jump in the

134
00:07:48,830 --> 00:07:51,300
conditional probability function the base

135
00:07:51,330 --> 00:07:54,600
decision threshold is right here in a fun little bit off to the right or

136
00:07:54,600 --> 00:08:00,030
left i'm going to incur a much larger area than i do whenever smooth transition

137
00:08:01,080 --> 00:08:07,050
the idea here gets that the smooth transition the easier it is to approximate

138
00:08:08,200 --> 00:08:13,490
with those two kinds of ideas of smoothness smoothness of the boundary of the decision

139
00:08:13,490 --> 00:08:16,080
region and smoothness of the transition

140
00:08:16,100 --> 00:08:20,580
in the vicinity of the one one-half levels of the conditional probability functions

141
00:08:20,620 --> 00:08:22,660
that gives a way of

142
00:08:22,740 --> 00:08:28,410
sir define defining class of problems of varying complexities in terms of approximation

143
00:08:28,430 --> 00:08:32,180
so gamma is the smoothness of the boundary which you can measure in terms of

144
00:08:32,180 --> 00:08:36,080
say derivatives and so that's often called holders this

145
00:08:36,120 --> 00:08:40,990
kappa is the transition smoothness which could also think of in terms of derivatives around

146
00:08:40,990 --> 00:08:44,450
that one half level set of conditional probability functions

147
00:08:44,490 --> 00:08:49,280
and d is the dimension of the problem which also going to govern the difficulty

148
00:08:49,280 --> 00:08:50,970
of learning

149
00:08:51,010 --> 00:08:57,010
so there's an interesting theoretical result which is due to mammon and tsybakov which basically

150
00:08:57,010 --> 00:09:02,050
says that for class of distributions governed by these parameters the smoothness of the boundary

151
00:09:02,050 --> 00:09:06,240
the smoothness of the transition and the dimension of the feature space

152
00:09:06,850 --> 00:09:11,140
expected probability of of all learning rule

153
00:09:11,180 --> 00:09:13,240
relative to the base here

154
00:09:13,260 --> 00:09:14,660
can never

155
00:09:14,680 --> 00:09:20,120
decay faster than this function of that it's kind of complicated but basically what it's

156
00:09:20,120 --> 00:09:25,680
saying is that for different values of the kappa gamma dimension you're going to get

157
00:09:25,700 --> 00:09:27,640
a different levels of achievable

158
00:09:27,700 --> 00:09:32,970
performance relative to the bayes performance as you have

159
00:09:33,120 --> 00:09:37,140
increasing sample size is the main point here is that is an gets larger sample

160
00:09:37,140 --> 00:09:42,160
size of training set size the air will go down in the parameters covering how

161
00:09:42,160 --> 00:09:44,950
quickly decays to zero

162
00:09:47,140 --> 00:09:49,600
this is i should also say that

163
00:09:49,620 --> 00:09:52,910
over here what i'm looking at you you look at

164
00:09:52,950 --> 00:09:55,720
we consider all possible

165
00:09:55,720 --> 00:09:57,760
underlying distributions p which

166
00:09:57,780 --> 00:10:00,490
are governed by these parameters gamma kappa d

167
00:10:00,490 --> 00:10:01,490
and then you

168
00:10:01,490 --> 00:10:06,720
consider the best possible learning algorithm you could ever imagine sensors are fictitious

169
00:10:06,740 --> 00:10:10,680
it's strawman that we don't necessarily know how to compute but in principle we can

170
00:10:10,680 --> 00:10:12,070
get access to these

171
00:10:12,120 --> 00:10:17,280
minimax lower bounds in theory and tells us basically how good we could expect to

172
00:10:17,280 --> 00:10:21,220
deal with any possible learning algorithm i'm not going to go into the details of

173
00:10:21,220 --> 00:10:25,350
how to derive these minimax lower bounds but in some of the papers

174
00:10:25,410 --> 00:10:27,740
that you can find on my website you'll see

175
00:10:27,760 --> 00:10:33,470
derivations of things like this and and really quickly say that the idea is sort

176
00:10:33,470 --> 00:10:35,580
of like you discretize the problem

177
00:10:35,580 --> 00:10:38,680
the space of of classifiers into

178
00:10:38,700 --> 00:10:40,330
a set of points

179
00:10:40,350 --> 00:10:45,010
and hypercube and then you can basically boils down to a simple decision problem of

180
00:10:45,010 --> 00:10:51,300
deciding which point on hypercube iran and that activity this lower bound

181
00:10:51,300 --> 00:10:53,950
OK so

182
00:10:53,970 --> 00:10:59,200
the word that sort of aimed towards this direction saying well can can we derive

183
00:10:59,260 --> 00:11:02,850
learning rule that does as well as its lower bound suggest we ought to be

184
00:11:02,850 --> 00:11:03,910
able to do

185
00:11:04,010 --> 00:11:07,080
there is essentially two ways you might pursue this one is

186
00:11:07,100 --> 00:11:14,740
by placing constraints on the underlying probability densities governing the classes and the labels

187
00:11:14,890 --> 00:11:17,660
and that kind of approach is

188
00:11:17,680 --> 00:11:23,050
basically shown that you can just estimate densities plug them into a classification rule and

189
00:11:23,050 --> 00:11:27,240
you get the optimal rate of convergence and marries working in this work are good

190
00:11:27,240 --> 00:11:29,510
examples of this kind of philosophy

191
00:11:29,510 --> 00:11:32,050
the problem with this approach is that

192
00:11:32,100 --> 00:11:38,010
making assumptions on the global smoothness of the density functions as a little bit heavy-handed

193
00:11:38,010 --> 00:11:42,120
we don't really care about the density functions all we care about is finding the

194
00:11:42,140 --> 00:11:45,160
sets for the decision boundaries and so

195
00:11:46,280 --> 00:11:52,300
this of promoted by number of research is primarily starting with mammon tsybakov said well

196
00:11:52,300 --> 00:11:56,830
let's make assumptions only and the smoothness of the decision boundary and in

197
00:11:56,910 --> 00:12:01,350
the vicinity of the decision boundary like i was just describing above and then the

198
00:12:01,350 --> 00:12:04,300
number of people have looked at translating

199
00:12:04,310 --> 00:12:06,160
those ideas into

200
00:12:06,160 --> 00:12:10,490
rates of convergence for different classification rules the problem with

201
00:12:10,700 --> 00:12:15,680
this work that i'm listing here is that is primarily only of theoretical interest they

202
00:12:15,680 --> 00:12:18,600
don't really drive prior estimation models

203
00:12:18,720 --> 00:12:22,640
our classification rules rather well after was that simple tree

204
00:12:22,640 --> 00:12:26,950
methods achieve the optimal rate in many cases and so

205
00:12:27,010 --> 00:12:30,780
i know that a lot of learning theory is concerned so much with optimal rates

206
00:12:30,780 --> 00:12:34,550
but when you look at rates of convergence it often can give you a lot

207
00:12:34,550 --> 00:12:38,740
of insight as to why one method is working better than another and in particular

208
00:12:38,740 --> 00:12:42,910
also one various found classification the weaker one

209
00:12:42,930 --> 00:12:48,030
does not perform as well as the stronger one and we wouldn't really know that

210
00:12:48,080 --> 00:12:52,450
in a nice mathematical way unless we look at these kinds of rates of convergence

211
00:12:54,720 --> 00:12:58,530
so i'm going to focus on

212
00:12:58,550 --> 00:13:01,680
the class of distributions of describe here

213
00:13:02,430 --> 00:13:08,490
what do is the main assumption that all have been well described is that the

214
00:13:08,490 --> 00:13:11,780
bayes decision boundary serenity dimensional feature space

215
00:13:11,830 --> 00:13:17,620
and the boundary of the based decisions is a d minus one dimensional curve OK

216
00:13:17,620 --> 00:13:22,330
so if you imagine it to be it's like a line or curve in

217
00:13:22,350 --> 00:13:26,390
three d would be some sort of a two dimensional surface in three-dimensional space and

218
00:13:26,390 --> 00:13:31,780
so on and so forth and one way to serve express that idea that the

219
00:13:31,780 --> 00:13:36,050
bar three is most one-dimensional curve is to look at something called the box counting

220
00:13:37,050 --> 00:13:41,280
and the that's going to mention is just simply say we divide the feature space

221
00:13:41,280 --> 00:13:45,850
into lots of tiny boxes of the same size one over

222
00:13:45,850 --> 00:13:47,120
m to the

223
00:13:47,140 --> 00:13:49,780
and then you look at how many of those boxes

224
00:13:49,780 --> 00:13:51,550
subject to constraints

225
00:13:51,570 --> 00:13:54,080
what i discovery something almost

226
00:13:54,100 --> 00:14:00,460
well magical which says that the recovery is actually completely exact

227
00:14:00,480 --> 00:14:02,240
which is a bit surprising

228
00:14:02,260 --> 00:14:06,470
and in fact it so exact that numerically exact because when i look at the

229
00:14:06,470 --> 00:14:09,340
relative error that is the norm the the error between

230
00:14:09,830 --> 00:14:14,110
the l two error between the original vector and the reconstruction is like something like

231
00:14:14,110 --> 00:14:15,660
ten minus ten

232
00:14:15,680 --> 00:14:17,700
tensor minus nine

233
00:14:17,710 --> 00:14:20,330
six times ten to minus so it's

234
00:14:20,330 --> 00:14:21,210
it seems to be

235
00:14:21,230 --> 00:14:24,200
rather remarkable

236
00:14:25,300 --> 00:14:29,970
this little experiment shows you that you can actually recovered

237
00:14:30,870 --> 00:14:37,480
sparse solutions some underdetermined equations exactly if you don't have to

238
00:14:37,510 --> 00:14:40,970
now of course we discussed another method at the beginning of this lecture which would

239
00:14:40,970 --> 00:14:42,480
be to solve

240
00:14:42,500 --> 00:14:44,390
xiao two problem

241
00:14:44,400 --> 00:14:46,840
so i'm going to run exactly the same

242
00:14:46,840 --> 00:14:50,510
code except there will be a crucial difference we're now going to minimize the l

243
00:14:50,540 --> 00:14:52,750
two norm and now the l one norm

244
00:14:52,780 --> 00:14:54,030
in this discrete so

245
00:14:54,040 --> 00:14:56,090
the only difference was what you've seen

246
00:14:56,100 --> 00:14:59,590
is that now instead of minimizing the l one norm of the unknown to minimize

247
00:14:59,590 --> 00:15:05,250
the two norm and i'm going to run the same scripts

248
00:15:05,280 --> 00:15:11,530
OK so let's do that

249
00:15:11,780 --> 00:15:14,900
and now we get something has nothing to do is the true second just say

250
00:15:14,920 --> 00:15:18,880
x equals zero just do as good as the other job

251
00:15:18,880 --> 00:15:22,570
so what i see now is that while the original vector is in blue the

252
00:15:22,570 --> 00:15:27,530
red factories in in red and they have very little income

253
00:15:27,580 --> 00:15:29,990
OK so many many things in one norm works

254
00:15:30,050 --> 00:15:34,820
minimizes the l two norm doesn't change

255
00:15:38,160 --> 00:15:39,180
now i can

256
00:15:39,200 --> 00:15:43,130
change the matrices are for example you going instead of having a matrix which i

257
00:15:43,130 --> 00:15:49,490
did using gauss entries random problem i can make a matrix with plus and minus

258
00:15:49,490 --> 00:15:53,110
one entries for example selected at random and that's what this piece of code does

259
00:15:53,340 --> 00:15:56,600
someone to generate another problems with

260
00:15:56,600 --> 00:15:58,140
we use

261
00:15:59,130 --> 00:16:02,420
plus and minus one entries in the matrix i'm still going to have a sparse

262
00:16:02,420 --> 00:16:03,820
right hand side

263
00:16:03,830 --> 00:16:09,170
and i'm going to solve and one

264
00:16:09,190 --> 00:16:16,150
OK thanks again it's exact so i can take out matrices i can take binary

265
00:16:16,150 --> 00:16:18,630
matrices and when i saw this

266
00:16:18,630 --> 00:16:22,960
minimisation problem it seems that in one gives me the right answer

267
00:16:22,990 --> 00:16:25,530
that kind of stuff that is even more fancy

268
00:16:25,540 --> 00:16:29,590
i can actually and this is extremely connected to what we'll see

269
00:16:29,600 --> 00:16:31,440
in a minute

270
00:16:31,470 --> 00:16:37,430
i can have very few measurements so sixty four measurements about effective dimension five twelve

271
00:16:37,440 --> 00:16:38,360
and now

272
00:16:38,360 --> 00:16:41,400
maybe i'm not going to explain the code but basically what i'm going to show

273
00:16:41,400 --> 00:16:45,230
you i suggest very few fourier coefficients of

274
00:16:46,230 --> 00:16:48,820
and how many for each coefficient i'm going to show you

275
00:16:48,860 --> 00:16:52,710
about sixty four thirty two complex coefficients

276
00:16:52,740 --> 00:16:54,800
and we're going to have

277
00:16:54,800 --> 00:17:01,040
a vector which has thirty two nonzero components and now instead of making random matrices

278
00:17:01,160 --> 00:17:02,640
showing you for you

279
00:17:02,660 --> 00:17:05,410
coefficients of the vector x

280
00:17:05,460 --> 00:17:10,220
OK now i'm gonna again have to solve this underdetermined system of equations which i

281
00:17:10,220 --> 00:17:17,900
do by minimizing the l one norm subject to x equals b of course

282
00:17:18,640 --> 00:17:21,900
so this is running

283
00:17:22,560 --> 00:17:23,510
and again

284
00:17:23,530 --> 00:17:28,440
it's always exact so we've seen a lot of different types of matrices we have

285
00:17:28,460 --> 00:17:33,230
underdetermined system of equations the right hand side is sparse and want to minimize the

286
00:17:33,230 --> 00:17:37,140
one norm there's this kind of a miracle that occurs which i always seem to

287
00:17:37,140 --> 00:17:40,390
get the exact solution with no water whatsoever

288
00:17:40,400 --> 00:17:42,400
the question

289
00:17:46,200 --> 00:17:53,820
there's no was the beautiful thing about this saying is that i don't need to

290
00:17:53,820 --> 00:17:54,980
know is it

291
00:17:55,000 --> 00:17:57,740
as the number of nonzero coefficients

292
00:17:57,760 --> 00:18:00,690
i just to minimize in one norm subjective data

293
00:18:00,700 --> 00:18:01,680
there's no

294
00:18:01,690 --> 00:18:06,390
our call information i need access to to be able to solve this problem

295
00:18:09,060 --> 00:18:13,500
the method does not need any kind of side information that i do not have

296
00:18:13,530 --> 00:18:17,130
i just minimize one norm subject equals b

297
00:18:17,140 --> 00:18:20,680
now you pointing out in very interesting direction at some point this will have to

298
00:18:22,970 --> 00:18:26,300
and that's the topic of this lecture

299
00:18:26,310 --> 00:18:32,100
any other questions

300
00:18:32,100 --> 00:18:33,250
he two

301
00:18:33,280 --> 00:18:36,200
all right so

302
00:18:36,650 --> 00:18:41,130
OK so the agenda for this kind of tutorial it is quite simple

303
00:18:41,470 --> 00:18:44,450
i want to show you first because i think it's the tutorial so i think

304
00:18:44,450 --> 00:18:47,330
it's important to give credits to people

305
00:18:47,340 --> 00:18:51,940
and so i would like to start the first half hour forty five minutes discussing

306
00:18:51,940 --> 00:18:55,730
a little bit the history of l one minimisation and discuss some of the early

307
00:18:57,030 --> 00:19:02,190
in the second part of the tutorial will discuss compressed sensing that it relies enormously

308
00:19:02,230 --> 00:19:06,560
on our ability to solve anyone's problems and the third party it would be much

309
00:19:06,560 --> 00:19:13,830
more statistical in nature since we'll talk about sparse signal recovery from noisy data

310
00:19:13,840 --> 00:19:16,690
OK but in the first part of the talk i want to show you some

311
00:19:16,690 --> 00:19:18,730
i want explain some of the history

312
00:19:18,750 --> 00:19:21,190
and explain some of the early use

313
00:19:21,230 --> 00:19:23,040
of the one norm

314
00:19:23,050 --> 00:19:28,420
OK so to to my knowledge is the first time in one minimisation has been

315
00:19:28,420 --> 00:19:30,350
used systematically

316
00:19:30,350 --> 00:19:32,310
besides the plus

317
00:19:32,320 --> 00:19:35,490
i was in reflection seismology

318
00:19:35,540 --> 00:19:36,650
and so

319
00:19:36,670 --> 00:19:40,780
i'm going to give you a little sketch of what people do in reflection seismology

320
00:19:40,830 --> 00:19:42,800
and show you how the

321
00:19:42,800 --> 00:19:44,340
the l one norm comes up

322
00:19:44,360 --> 00:19:51,590
so as you know many people on earth are interested in knowing what it is

323
00:19:51,590 --> 00:19:53,190
on the ground

324
00:19:53,220 --> 00:19:57,410
especially if your accent you would like to know whether wonders

325
00:19:57,980 --> 00:20:02,910
gulf of mexico the underwater there's oil or not

326
00:20:02,930 --> 00:20:07,460
and the way we do this to kind of in fear what is the composition

327
00:20:07,460 --> 00:20:13,680
of the upper crust we come people conduct what they call it

328
00:20:13,690 --> 00:20:15,370
seismic experiment

329
00:20:15,380 --> 00:20:17,760
we're basically the idea is very simple

330
00:20:17,790 --> 00:20:20,260
you have both floating on the sea

331
00:20:20,290 --> 00:20:23,560
you can do this earth by the way and so of course it on this

332
00:20:23,560 --> 00:20:24,460
is so

333
00:20:24,490 --> 00:20:28,870
you have water underneath the bows maybe hassan maybe have fallen and so on and

334
00:20:28,870 --> 00:20:29,660
so forth

335
00:20:30,400 --> 00:20:34,380
all right and you are floating on the sea and you'd like to know

336
00:20:34,400 --> 00:20:37,070
let's be nice book

337
00:20:37,070 --> 00:20:38,920
and the way you do this

338
00:20:38,980 --> 00:20:43,950
is basically going to create you're going to propagate a sound wave

339
00:20:43,970 --> 00:20:45,360
through the years

340
00:20:45,400 --> 00:20:51,500
right so you can make an explosion which here is pictorially represented by big hammer

341
00:20:51,530 --> 00:20:54,070
so you hit hits the surface of the sea

342
00:20:54,120 --> 00:20:56,680
typically what you do is you have explosions

343
00:20:57,140 --> 00:20:58,810
the surface of the sea

344
00:20:58,820 --> 00:21:04,600
and then use anderson waiver pressure waves propagating down the years

345
00:21:04,620 --> 00:21:05,310
now the areas

346
00:21:05,890 --> 00:21:07,780
is made of different stuff

347
00:21:07,790 --> 00:21:13,030
so you have water that has a certain speed of propagation

348
00:21:13,080 --> 00:21:16,900
which is indicated by this profile that you see on the right

349
00:21:16,930 --> 00:21:21,480
then you have sand which has the difference is speed of propagation then maybe you

350
00:21:21,480 --> 00:21:26,000
have oil which has a different speed of propagation and so on and so forth

351
00:21:26,000 --> 00:21:27,080
some really

352
00:21:27,090 --> 00:21:33,370
schematically representing what happens but essentially you're sending your son your pressure wave and it's

353
00:21:33,370 --> 00:21:35,310
it again

354
00:21:35,350 --> 00:21:39,530
and even the alignment we can compute a score

355
00:21:39,550 --> 00:21:44,950
so this is actually this is what i meant for which we cannot use them

356
00:21:44,960 --> 00:21:47,860
but there was

357
00:21:47,910 --> 00:21:50,330
ban showed or

358
00:21:50,510 --> 00:21:51,680
you can actually

359
00:21:51,690 --> 00:21:53,680
exponentiated score

360
00:21:53,690 --> 00:21:56,480
the sum of all possible alignments

361
00:21:56,560 --> 00:21:59,930
and this is actually going to be

362
00:22:00,240 --> 00:22:06,470
OK so i

363
00:22:06,510 --> 00:22:11,610
i think i'm going to give one part is on remote homology and you find

364
00:22:11,610 --> 00:22:12,710
it just like

365
00:22:12,790 --> 00:22:16,140
this is an application of the school

366
00:22:16,270 --> 00:22:20,490
and i would that

367
00:22:20,540 --> 00:22:24,340
OK so let's summarize

368
00:22:25,180 --> 00:22:31,480
can we extend to non linear decision boundary while keeping keeping the simplicity of the

369
00:22:32,640 --> 00:22:35,360
classification one linear separation

370
00:22:35,540 --> 00:22:39,930
so good kernel design is important for every single data analysis time when you get

371
00:22:39,930 --> 00:22:43,370
some new dataset you really have to think through what i'm going to get going

372
00:22:43,390 --> 00:22:46,450
to use they maybe on knowledge which

373
00:22:47,770 --> 00:22:55,590
the string kernels perform computations in very high dimensional feature space is usually like

374
00:22:55,590 --> 00:22:59,800
the size of to the power of ten y i mean depending on how many

375
00:23:00,460 --> 00:23:07,690
along the motor armature considering and this can be based on substrings like

376
00:23:07,710 --> 00:23:11,510
we can all they can be based on probabilistic models

377
00:23:11,520 --> 00:23:15,450
or can be derived from some similarity measure

378
00:23:15,490 --> 00:23:20,710
so i didn't mention kernel on top down which

379
00:23:20,720 --> 00:23:26,740
on images and i'm which sure can have a look at shop lived there

380
00:23:26,750 --> 00:23:33,600
machine learning summer school oil on bioinformatics and he talk more about

381
00:23:33,600 --> 00:23:38,900
application of course if you know course probably on come about

382
00:23:41,950 --> 00:23:44,000
OK i think this is for

383
00:23:44,860 --> 00:23:45,990
i think

384
00:23:46,020 --> 00:23:48,390
so what i would continue

385
00:23:48,390 --> 00:23:49,420
talking about

386
00:23:50,290 --> 00:23:54,970
large scale

387
00:23:54,980 --> 00:23:56,990
OK that's thing

388
00:24:01,060 --> 00:24:06,870
i don't really understand why a kernel based on graphical model cannot be

389
00:24:07,650 --> 00:24:09,280
in the graphical model

390
00:24:09,340 --> 00:24:17,660
why cannot be

391
00:24:17,670 --> 00:24:22,140
this would mean that features which extracting doesn't

392
00:24:22,150 --> 00:24:26,050
contains the information necessary for discrimination

393
00:24:26,110 --> 00:24:31,380
so and you can show that this actually that

394
00:24:31,390 --> 00:24:35,860
whenever you have the label of the latent variable in your perfect world for the

395
00:24:35,860 --> 00:24:40,260
model and extracting features from this is actually

396
00:24:40,280 --> 00:24:42,090
going to give you even

397
00:24:43,400 --> 00:24:48,890
asymptotically without i mean OK so it has some results from google to that

398
00:24:48,900 --> 00:24:50,900
and they have shown that

399
00:24:50,930 --> 00:24:54,030
many extract features in that way

400
00:24:56,170 --> 00:25:02,260
sixty one extension of the project and about one extension of whatever is very similar

401
00:25:02,700 --> 00:25:08,760
many expected then the rate of convergence for the best classifier which you generate based

402
00:25:08,760 --> 00:25:09,860
on the features

403
00:25:09,860 --> 00:25:13,550
it's actually better than b

404
00:25:13,610 --> 00:25:17,830
the maximum likelihood estimate the tube and they do on you know when you read

405
00:25:17,840 --> 00:25:20,630
the model the country the paper

406
00:25:26,930 --> 00:25:28,650
can you say a few words about

407
00:25:28,710 --> 00:25:38,080
i mean so i thought maybe but talked a little bit about maybe it

408
00:25:38,120 --> 00:25:44,660
so this is one kind of what very

409
00:25:44,670 --> 00:25:47,720
so i mean you some hard to work on the

410
00:25:47,740 --> 00:25:51,490
OK i guess you don't have to wait so usually kind of work on the

411
00:25:52,530 --> 00:25:55,790
so at least but because are not

412
00:25:55,800 --> 00:26:00,250
too many then and what you so but there are other approaches

413
00:26:00,300 --> 00:26:06,240
you might to extract features like certain point of interest then you might combine these

414
00:26:06,240 --> 00:26:08,440
points in it

415
00:26:10,030 --> 00:26:12,380
the actually on

416
00:26:21,600 --> 00:26:26,810
it's start about to talk about large scale data structures

417
00:26:26,900 --> 00:26:31,110
so we had a spectral colours are not quite a bit so the problem is

418
00:26:31,910 --> 00:26:35,260
how can be efficiently computed the spectrum kernel in general

419
00:26:35,290 --> 00:26:40,620
so the problem is that the dimensionality of the feature space is exponential

420
00:26:40,860 --> 00:26:43,120
we talked about some ideas and

421
00:26:43,170 --> 00:26:46,220
trying to

422
00:26:47,040 --> 00:26:54,050
so what i talked about already what thing were all to compute the new kernel

423
00:26:54,060 --> 00:26:56,710
i mean a single element

424
00:26:56,730 --> 00:27:02,840
so we just need to look maybe all came in which sequences he which appear

425
00:27:02,840 --> 00:27:04,190
in both

426
00:27:06,670 --> 00:27:12,770
so this has some general formulation which is called sort list approach language

427
00:27:12,830 --> 00:27:14,670
so first of all

428
00:27:14,680 --> 00:27:18,420
so we have to compute a the single kind commentations as fast as possible

429
00:27:18,440 --> 00:27:22,490
but often we are only interested in computing a single kernel but we have to

430
00:27:22,490 --> 00:27:24,340
compute a whole bunch of

431
00:27:24,420 --> 00:27:29,480
i mean went the falconer metric and other ways of computing the more efficiently than

432
00:27:29,480 --> 00:27:32,610
just competing every single element

433
00:27:33,930 --> 00:27:37,690
and what you are the open to do it using a linear combination

434
00:27:37,740 --> 00:27:43,610
so went the decision boundary actually looking like this is a linear combination of different

435
00:27:44,450 --> 00:27:47,590
and if you would like to apply the SVM classifier

436
00:27:48,740 --> 00:27:50,180
new test data set

437
00:27:50,230 --> 00:27:54,620
then you compute quite a few of the elements

438
00:27:54,620 --> 00:27:57,330
the first you are going to

439
00:27:57,350 --> 00:27:59,850
start disagreeing but match

440
00:27:59,850 --> 00:28:02,250
two the millimetre and

441
00:28:02,250 --> 00:28:03,640
mismatching disagree

442
00:28:05,230 --> 00:28:09,280
how long will how lonely to these be i'm gonna shout out i'm going to

443
00:28:09,280 --> 00:28:11,450
say a change

444
00:28:11,500 --> 00:28:13,490
these are be change

445
00:28:13,540 --> 00:28:17,830
a state is OK so let's see how this goes remember to the millimeter when

446
00:28:17,830 --> 00:28:20,990
you matching also doesn't work OK start

447
00:28:21,060 --> 00:28:23,490
matching and green

448
00:28:23,500 --> 00:28:24,080
so many

449
00:28:34,430 --> 00:28:37,060
i have

450
00:28:37,080 --> 00:28:40,290
you can UK should go

451
00:28:45,000 --> 00:28:50,700
now i mean your your from west live in your experience in slovenia has been

452
00:28:50,700 --> 00:28:52,850
very positive

453
00:28:52,910 --> 00:28:53,730
five first

454
00:28:53,750 --> 00:28:57,250
and i think we can we can learn a lot from

455
00:28:57,330 --> 00:29:04,020
from the slovenian you think it's people so for the other countries as well i

456
00:29:04,020 --> 00:29:09,390
think i

457
00:29:09,430 --> 00:29:12,790
sounds crazy

458
00:29:12,830 --> 00:29:16,730
i don't understand which

459
00:29:20,600 --> 00:29:22,500
i have exact

460
00:29:24,600 --> 00:29:26,270
exactly when i came

461
00:29:26,270 --> 00:29:27,890
two play

462
00:29:27,910 --> 00:29:30,040
i have actually

463
00:29:30,060 --> 00:29:31,250
you know it's crazy

464
00:29:31,370 --> 00:29:41,770
dogs must be there must be a lot mostly along

465
00:29:41,790 --> 00:29:44,000
OK maybe

466
00:29:44,000 --> 00:29:46,390
carry on agreeing mismatch

467
00:29:53,680 --> 00:29:57,520
you they travel along

468
00:29:57,700 --> 00:30:02,220
they they agree agree agree they agree that

469
00:30:02,250 --> 00:30:04,830
the euro begin

470
00:30:04,850 --> 00:30:10,990
politicians agreed to another

471
00:30:16,810 --> 00:30:22,180
it's crazy i don't know why would don't think we should agree should change

472
00:30:38,870 --> 00:30:40,950
the pressures

473
00:30:40,950 --> 00:30:47,310
we should change the show which changes as the question no question UK should junior

474
00:30:52,680 --> 00:30:58,660
start disagreeing but match a to the millimetre

475
00:30:58,770 --> 00:31:04,580
i'm not sure that must

476
00:31:04,660 --> 00:31:08,290
i'm not sure the UK should join

477
00:31:22,020 --> 00:31:23,120
but in the end

478
00:31:23,160 --> 00:31:27,270
current it's an economic crisis is this a good time

479
00:31:27,310 --> 00:31:30,500
to be changed shortly stability

480
00:31:30,520 --> 00:31:32,100
it is important

481
00:31:39,770 --> 00:31:45,870
but maybe in the future but let's get past the next two years

482
00:31:45,910 --> 00:31:47,560
you need to do anything

483
00:31:53,450 --> 00:32:02,930
but they changed

484
00:32:03,660 --> 00:32:06,640
the crisis

485
00:32:10,390 --> 00:32:26,750
i i understand what you say i hate i'm just concerned

486
00:32:26,790 --> 00:32:29,200
let's wait for one or two years

487
00:32:29,200 --> 00:32:30,950
come out of the

488
00:32:30,950 --> 00:32:34,500
the current crisis and then sure you i agree i think you know in the

489
00:32:35,390 --> 00:32:37,890
let's look at this

490
00:32:41,430 --> 00:32:44,680
politicians are generally

491
00:32:44,680 --> 00:32:45,490
i agree

492
00:32:45,500 --> 00:32:47,140
some of them agree with

493
00:32:47,160 --> 00:32:49,770
well i think most of them agree with me

494
00:32:49,830 --> 00:32:51,660
not the right time

495
00:32:51,680 --> 00:32:53,830
not the right time

496
00:32:53,850 --> 00:32:59,410
yes they are always

497
00:32:59,410 --> 00:33:03,330
always always pressures from

498
00:33:05,060 --> 00:33:06,330
i disagree

499
00:33:08,250 --> 00:33:16,520
the pressures from europe but who cares

500
00:33:16,540 --> 00:33:21,560
there are always there always pressures always pressure

501
00:33:21,580 --> 00:33:23,680
you know and

502
00:33:23,700 --> 00:33:25,080
it doesn't mean we should do it

503
00:33:25,100 --> 00:33:26,580
and just because

504
00:33:26,600 --> 00:33:33,180
you in slovenia just because it with you doesn't mean it's going to work

505
00:33:41,080 --> 00:33:46,660
we should join

506
00:33:46,750 --> 00:33:49,540
it's not it's not is not a reason

507
00:33:49,540 --> 00:33:55,890
to join the u

508
00:33:55,910 --> 00:33:59,950
i don't know how to priority

509
00:34:00,040 --> 00:34:01,970
why why would we

510
00:34:02,040 --> 00:34:03,770
we're not the same

511
00:34:03,790 --> 00:34:04,540
what different

512
00:34:05,870 --> 00:34:13,000
do we want more tourists

513
00:34:13,200 --> 00:34:15,230
i'm not sure

514
00:34:15,930 --> 00:34:17,100
i'm not sure

515
00:34:19,290 --> 00:34:20,620
i'm not sure

516
00:34:20,620 --> 00:34:22,120
OK thank you

517
00:34:22,230 --> 00:34:23,890
OK let's stop there

518
00:34:23,890 --> 00:34:24,950
this stuff

519
00:34:24,970 --> 00:34:28,310
always take to thank you very much

520
00:34:30,390 --> 00:34:32,520
i want to get some feedback

521
00:34:38,200 --> 00:34:40,080
let's go through these fall

522
00:34:40,100 --> 00:34:42,180
faces what i'm interested in

523
00:34:42,250 --> 00:34:44,040
is how it felt to you

524
00:34:44,040 --> 00:34:49,060
so let's start with face number one you are both agreeing you're both matching each

525
00:34:49,810 --> 00:34:51,160
how did that feel

526
00:34:54,120 --> 00:35:04,000
so want to say is that it's it's like it's comfortable but is on the

527
00:35:04,000 --> 00:35:06,200
verge of boron

528
00:35:06,220 --> 00:35:09,310
two sweet

529
00:35:10,000 --> 00:35:12,250
sweet it's everywhere

530
00:35:12,270 --> 00:35:17,450
always is the number one

531
00:35:19,230 --> 00:35:22,790
disagreed mismatch in four

532
00:35:22,790 --> 00:35:26,720
is there any point in continuing the conversation

533
00:35:26,770 --> 00:35:27,830
there's no point

534
00:35:29,410 --> 00:35:32,450
you're not going to change i'm going to change with it's obvious

535
00:35:32,470 --> 00:35:33,750
let's just stop

536
00:35:33,770 --> 00:35:38,220
the conversation what i'm interested in is number two and number three

537
00:35:38,230 --> 00:35:39,870
so number two

538
00:35:39,870 --> 00:35:41,620
you were agreeing

539
00:35:41,640 --> 00:35:45,850
but you were mismatching how did that feel

540
00:35:45,890 --> 00:35:48,180
not comfortable

541
00:35:48,220 --> 00:35:52,680
didn't feel honest

542
00:35:52,700 --> 00:35:57,350
and even if this funny even though

543
00:35:57,350 --> 00:35:59,310
the person is agreeing

544
00:35:59,310 --> 00:36:03,950
the very much for inviting me to to be here BBCI

545
00:36:04,010 --> 00:36:11,040
excited to finally see their magical bmvc and thank you for waking up early so

546
00:36:11,100 --> 00:36:15,580
planned right ahead because yes i have lots of lots of stuff to talk about

547
00:36:15,580 --> 00:36:18,610
some of some some new

548
00:36:18,670 --> 00:36:20,740
so what i'm interested in

549
00:36:20,790 --> 00:36:24,430
four today is to look at a single image

550
00:36:24,490 --> 00:36:25,990
two indices see

551
00:36:25,990 --> 00:36:31,200
if you if we restrict ourselves to a single sample in space and time what

552
00:36:31,200 --> 00:36:36,040
is all the information that we are able to squeeze out from that one image

553
00:36:36,720 --> 00:36:41,180
and of course we humans are able to do a lot from a single image

554
00:36:41,180 --> 00:36:46,540
given a seen something like this we can say that meeting amount we can give

555
00:36:46,540 --> 00:36:51,040
an amazing amount of information about the see for example we can not only say

556
00:36:51,710 --> 00:36:56,260
detector you know the cars in the pedestrians like every you know all the algorithms

557
00:36:56,260 --> 00:37:00,900
can do a different objects within the scene but it can also reason about the

558
00:37:00,900 --> 00:37:06,340
major services on the scene where the ground plane where are the other major surfaces

559
00:37:06,340 --> 00:37:10,980
we can talk about what things are walkable and what are not walkable where you

560
00:37:10,980 --> 00:37:14,640
can go to and where you're going to like it to hit the wall we

561
00:37:14,640 --> 00:37:17,280
can talk about that

562
00:37:17,290 --> 00:37:21,590
the composition of the camera maybe the height of the camera that's taking this picture

563
00:37:21,590 --> 00:37:26,000
we can even say something about maybe the weather and lighting candles illumination conditions within

564
00:37:26,000 --> 00:37:31,420
the scene and we can even perhaps a which which country this this picture was

565
00:37:31,420 --> 00:37:34,010
taken in and maybe even which city

566
00:37:34,030 --> 00:37:39,430
OK so we were able to provide a whole story just given a single image

567
00:37:39,430 --> 00:37:40,370
like this

568
00:37:40,390 --> 00:37:45,920
of course now imagine if you are a typical object detector know your life is

569
00:37:45,980 --> 00:37:51,590
pretty miserable you're looking at the world through this little peopole sliding people

570
00:37:51,650 --> 00:37:55,870
and what you're seeing is not as beautiful panorama using something like this

571
00:37:55,920 --> 00:38:02,000
this is what a sliding detect a sliding window detector sees in his little miserable

572
00:38:02,000 --> 00:38:07,120
life and of course no no no no there's is no reason why

573
00:38:07,710 --> 00:38:12,810
it should produce good results because given this

574
00:38:12,870 --> 00:38:16,430
it's really trying the best it can and it is for it can find a

575
00:38:16,430 --> 00:38:20,840
few of the pedestrians for example here's a pedestrian detector and but of course is

576
00:38:20,840 --> 00:38:27,780
going to miss a few and more so embarrassingly it's gonna have rather rather strange

577
00:38:27,780 --> 00:38:32,230
false positives here right for example here on the top of the lamppost but you

578
00:38:32,230 --> 00:38:36,440
before you go and blame the object detector

579
00:38:36,470 --> 00:38:41,000
i have to say that it's really not the detectors for

580
00:38:41,030 --> 00:38:45,680
it's really the fact that it's too local it's looking at this too small of

581
00:38:46,030 --> 00:38:49,910
over patch and not really seeing the big picture and to demonstrate this here is

582
00:38:50,280 --> 00:38:56,430
some example for your visual system so is here is a very nice early impressionist

583
00:38:56,430 --> 00:39:01,120
painting money paying in mostly that's a

584
00:39:01,120 --> 00:39:02,960
this this this really

585
00:39:02,970 --> 00:39:06,440
wonderful way to represent the

586
00:39:06,460 --> 00:39:11,060
trains the train station turn-of-the-century train station you can feel the hustle and bustle and

587
00:39:11,060 --> 00:39:14,960
you know the noise and everything and then you have you have the the cloud

588
00:39:14,960 --> 00:39:19,040
of steam in the centre and then money which this had the steam engine right

589
00:39:19,040 --> 00:39:22,940
in the center it's coming right at you it's just coming up advancing get to

590
00:39:22,970 --> 00:39:25,470
really very powerful

591
00:39:25,520 --> 00:39:29,360
the painting but let's look at the steam engine more closely look at this thing

592
00:39:29,360 --> 00:39:34,260
this this the splash paint that that really looks more like a penguin or or

593
00:39:34,260 --> 00:39:37,660
or of phase where the steam engine go

594
00:39:37,720 --> 00:39:41,190
because it's not here the pixels it somewhere else

595
00:39:41,250 --> 00:39:46,650
and the the somewhere else is well partially it's is in the whole scene

596
00:39:46,680 --> 00:39:51,250
in in the connection between the different elements of the scene and partly it's really

597
00:39:51,370 --> 00:39:56,370
inside your head and and i'm sure that h one of you might have a

598
00:39:56,370 --> 00:40:01,090
slightly different so be it seems like a different version of the steam engine perhaps

599
00:40:01,090 --> 00:40:01,900
connected to

600
00:40:03,120 --> 00:40:07,630
particular steam engine museum you went to a child OK so

601
00:40:08,430 --> 00:40:10,500
the point is that that

602
00:40:10,520 --> 00:40:15,600
the pixels inside don't really tell you the whole story there is that extra world

603
00:40:15,600 --> 00:40:21,170
outside of it that the influences your your perception of course at this point somebody

604
00:40:21,170 --> 00:40:24,030
should stop me and say that this is this is not fair this is a

605
00:40:24,030 --> 00:40:28,740
cheating example because after all this is i think this is impressionism this is exactly

606
00:40:28,740 --> 00:40:32,620
designed to evoke an impression in viewers

607
00:40:32,870 --> 00:40:38,410
but unfortunately the same thing happens in normal image and video data here's is an

608
00:40:38,410 --> 00:40:39,830
example of

609
00:40:39,930 --> 00:40:44,300
world cup football world cup of few years back to this is germany versus the

610
00:40:44,300 --> 00:40:49,310
united states can to tell me something about this guy in the red box what's

611
00:40:49,310 --> 00:40:52,020
his posts anyone can tell me the pose of the

612
00:40:52,050 --> 00:40:53,050
of that

613
00:40:58,000 --> 00:41:01,190
how we see standing

614
00:41:01,880 --> 00:41:02,730
all right

615
00:41:02,770 --> 00:41:04,920
right before left yes

616
00:41:04,930 --> 00:41:06,190
he's looking

617
00:41:06,190 --> 00:41:08,580
how his looking

618
00:41:08,620 --> 00:41:13,100
it's kind of taking you know he's looking backwards cubic perhaps taking this american fellow

619
00:41:13,100 --> 00:41:20,420
there are his the german body there is yes small big broad-shouldered man

620
00:41:21,520 --> 00:41:27,120
well it some people say oh yeah he's a big guy he's tired i gave

621
00:41:27,120 --> 00:41:30,370
this talk in germany and some some guys yeah i know this is placed so

622
00:41:30,370 --> 00:41:32,630
and so the this the that has no head

623
00:41:32,740 --> 00:41:34,640
he has no arms either

624
00:41:34,660 --> 00:41:37,010
and his legs are massive pixels

625
00:41:37,120 --> 00:41:41,740
so clearly something is going on that is not explained by the

626
00:41:41,750 --> 00:41:43,930
the pixels of that little box

627
00:41:45,170 --> 00:41:50,020
extra to this this box is is happening and and we are not really quite

628
00:41:50,020 --> 00:41:51,070
sure what

629
00:41:51,080 --> 00:41:54,570
but what it seems like is that it's the

630
00:41:54,620 --> 00:41:56,930
considering the ceiling as a whole

631
00:41:56,980 --> 00:42:03,950
is what's needed if we really to understand understand this this this image so

632
00:42:03,960 --> 00:42:09,010
excuse me my plan but really what we need to do is think outside of

633
00:42:09,010 --> 00:42:10,500
the bounding box

634
00:42:11,300 --> 00:42:12,750
to be able to really

635
00:42:12,750 --> 00:42:14,080
i do see and understand

636
00:42:14,100 --> 00:42:16,580
OK and

637
00:42:18,630 --> 00:42:22,750
worse than that not only do we need to reason globally about the image but

638
00:42:22,750 --> 00:42:27,710
actually we need to reason globally about the underlying three d scene because of course

639
00:42:27,800 --> 00:42:32,100
relationships within the image are not the same as relationship within the scene for example

640
00:42:32,410 --> 00:42:35,620
these two red dots here they are very close in pixel space and they are

641
00:42:35,620 --> 00:42:40,560
also very close and in three d space but these blue dots they're equally close

642
00:42:40,560 --> 00:42:45,860
in pixel space but there are very very far away in seems OK so we

643
00:42:45,910 --> 00:42:50,070
you can just talk about the two d image plane would have to deal with

644
00:42:50,600 --> 00:42:54,600
with the three d work right because the problem is that

645
00:42:54,640 --> 00:42:58,270
this is but a shadow of what is really happening right so we have the

646
00:42:58,660 --> 00:43:03,960
imaging process you know your camera any painting your retina they always basically the same

647
00:43:03,960 --> 00:43:08,410
thing i do have a beautiful three world on the left and then you you

648
00:43:08,410 --> 00:43:13,940
projected onto a two d plane on the right and just obliterating whole entire dimension

649
00:43:13,990 --> 00:43:18,740
it's gone it's it's it's it's lost forever right and then you just have to

650
00:43:18,740 --> 00:43:23,290
go do that just after you have that that to as the computer to basically

651
00:43:23,290 --> 00:43:27,930
the today biology has become a science over the last fifty years

652
00:43:30,720 --> 00:43:34,430
and as a consequence we can talk about some basic principles we can talk about

653
00:43:34,430 --> 00:43:39,620
some laws and then begin to apply them to very interesting biological problems and so

654
00:43:39,620 --> 00:43:41,380
are general strategy

655
00:43:41,450 --> 00:43:44,250
this semester as it has been in the past

656
00:43:44,270 --> 00:43:48,670
is to spend roughly the first half the semester talking about the basic laws and

657
00:43:48,670 --> 00:43:53,180
rules that govern all forms of bile biological life

658
00:43:53,200 --> 00:43:54,660
on on this planet

659
00:43:54,680 --> 00:43:58,770
and then the second half of the semester to begin to apply what we learned

660
00:43:58,770 --> 00:44:02,050
in the first half to specific kinds of problems

661
00:44:02,060 --> 00:44:07,580
and you can see some of the the specific kinds of problems including

662
00:44:07,830 --> 00:44:11,630
the problem of cancer how cancer cells begin to grow abnormally

663
00:44:11,650 --> 00:44:18,890
other viruses proliferate how the immune system functions of the nervous system functions are stem

664
00:44:18,890 --> 00:44:22,420
cells and how they work and their impact on modern biology

665
00:44:22,430 --> 00:44:24,230
molecular medicine

666
00:44:24,240 --> 00:44:30,610
and finally perhaps the future of biology and even certain aspects of evolution

667
00:44:30,630 --> 00:44:33,950
the fact of the matter is that we now understand lots of these things in

668
00:44:33,950 --> 00:44:37,430
ways that were inconceivable fifty years ago

669
00:44:37,480 --> 00:44:42,120
and now we can begin to talk about things the fifty years ago

670
00:44:42,170 --> 00:44:46,940
people could not have dreamt of when i took this course and i did take

671
00:44:46,940 --> 00:44:47,690
it in

672
00:44:47,700 --> 00:44:49,310
in nineteen sixty one

673
00:44:49,330 --> 00:44:52,660
we didn't know about eighty percent of what we now know

674
00:44:52,670 --> 00:44:58,990
you can say that about mechanics about in physics you can say that about a

675
00:44:59,060 --> 00:45:04,440
circuit theory in electronics and you can see that obviously about chemistry and i'm mentioning

676
00:45:04,440 --> 00:45:06,390
that to you

677
00:45:06,410 --> 00:45:09,080
simply because

678
00:45:09,130 --> 00:45:16,910
in this field has changed enormously over the ensuing four decades i will tell you

679
00:45:16,920 --> 00:45:20,800
what a great i got seven one because if i were you might try it

680
00:45:20,800 --> 00:45:25,620
out to me later in the semester you probably would never show up again lecture

681
00:45:25,620 --> 00:45:28,120
but in any case

682
00:45:28,250 --> 00:45:29,320
please no

683
00:45:29,350 --> 00:45:34,810
that this has been an area of enormous ferment and the reason it's been in

684
00:45:34,810 --> 00:45:37,360
such enormous ferment is

685
00:45:37,370 --> 00:45:41,460
of the discovery in nineteen fifty three by watson and crick of the structure of

686
00:45:41,470 --> 00:45:46,640
the DNA double helix last year i said that we're so close to this discovery

687
00:45:46,640 --> 00:45:51,470
for both watson and crick are alive and with us in metabolic lee active

688
00:45:51,520 --> 00:45:57,050
and more than fifty years well exactly fifty years after the discovery

689
00:45:57,060 --> 00:45:58,930
sadly several months ago

690
00:45:58,950 --> 00:46:03,380
one of the two characters francis crick died well into his eighties and so he's

691
00:46:03,380 --> 00:46:04,670
no longer with us

692
00:46:04,890 --> 00:46:08,820
but i want to impress on you the notion that two hundred years from now

693
00:46:08,860 --> 00:46:11,210
we will talk about watson and crick

694
00:46:11,230 --> 00:46:14,990
the same way that people talk about isaac newton in terms of physics

695
00:46:16,840 --> 00:46:21,260
that will be so because we are only beginning to to perceive the ramifications

696
00:46:21,280 --> 00:46:25,920
all this enormous revolution that was triggered by their discovery that is the field of

697
00:46:25,920 --> 00:46:31,430
molecular biology and genetics and biochemistry which is totally changed our perceptions of all life

698
00:46:31,430 --> 00:46:33,960
on earth is actually organised

699
00:46:34,010 --> 00:46:37,790
much of the boundary to which you may have been exposed until now

700
00:46:38,320 --> 00:46:41,100
has been highly descriptive science that is

701
00:46:41,110 --> 00:46:45,150
you may have had courses in high school where you had to memorize the names

702
00:46:45,150 --> 00:46:51,840
of different organisms we had to understand how evolutionary phylogenies organised you had to name

703
00:46:51,850 --> 00:46:54,100
learn the names of different organelles

704
00:46:54,120 --> 00:46:58,220
and the biology falls for you in a field of memorization

705
00:46:58,260 --> 00:47:03,310
in one point we would like hopefully successfully to drive home this semester is the

706
00:47:03,310 --> 00:47:05,360
notion that biology has now

707
00:47:05,770 --> 00:47:10,810
it achieved a logical and and rational coherence that allows us to articulate the whole

708
00:47:10,810 --> 00:47:12,050
set of rules

709
00:47:12,070 --> 00:47:16,990
then explain how all life forms on this planet are organised it's no longer just

710
00:47:16,990 --> 00:47:20,320
a collection of jumbled facts

711
00:47:20,340 --> 00:47:26,770
indeed if one masters these molecular and genetic principles one can understand in principle

712
00:47:26,790 --> 00:47:28,930
a large number of

713
00:47:28,990 --> 00:47:31,790
processes that exist in the biosphere

714
00:47:31,800 --> 00:47:36,350
and begin to apply one's molecular biology to solve new problems

715
00:47:38,020 --> 00:47:40,580
in this in this arena

716
00:47:40,600 --> 00:47:45,630
one of the important ideas that will refer to repeatedly this semester is the fact

717
00:47:45,630 --> 00:47:49,830
that many of the biological attributes that we possess now

718
00:47:49,850 --> 00:47:54,430
we're already developed a very long time ago early in the inception of life on

719
00:47:54,430 --> 00:47:59,160
this planet so if we look at the history of of earth here history versus

720
00:47:59,160 --> 00:48:02,010
is given as five billion years

721
00:48:02,030 --> 00:48:05,500
this is a thousand obviously

722
00:48:05,600 --> 00:48:09,640
the earth is probably not that old is probably four four four four three billion

723
00:48:09,640 --> 00:48:10,860
years but anyhow

724
00:48:10,960 --> 00:48:15,500
that's when the planet first aggregated as far as we know

725
00:48:15,510 --> 00:48:21,030
one believes that no other life existed for perhaps the first half billion years but

726
00:48:21,030 --> 00:48:25,560
after half a billion years which is a lot of time to be sure there

727
00:48:25,560 --> 00:48:30,350
are really begins to be traces of life forms on the surface of this planet

728
00:48:30,360 --> 00:48:36,770
and that itself is an extraordinary testimonial we don't know testimonial to how evolutionary processes

729
00:48:37,340 --> 00:48:41,340
occurring we don't know how many planets there are in the universe were similar things

730
00:48:42,300 --> 00:48:47,500
and we don't know whether the solutions that were arrived at by other life systems

731
00:48:47,500 --> 00:48:51,700
and other places in the universe which we may or may not ever discovered with

732
00:48:51,700 --> 00:48:56,200
the similar solutions to the ones that have been arrived at here

733
00:48:56,210 --> 00:49:01,270
it's clear for example that to the extent that darwinian evolution governance

734
00:49:01,350 --> 00:49:05,660
the development of life forms on this planet that is not an artifact of the

735
00:49:05,660 --> 00:49:10,620
or darwinian evolution is the logic which is applicable to all life forms in all

736
00:49:10,990 --> 00:49:14,720
systems that may exist in the universe even the ones with not discovered

737
00:49:14,740 --> 00:49:18,160
however there are specific solutions that were arrived at

738
00:49:18,180 --> 00:49:20,500
during the development of life on earth

739
00:49:20,520 --> 00:49:22,070
which may be killer

740
00:49:22,090 --> 00:49:26,900
the structure of the DNA double helix the use of rivals and deoxy rivalries robots

741
00:49:26,900 --> 00:49:30,700
you can calculate the frequency of one you know what the speed of sound is

742
00:49:30,750 --> 00:49:32,660
three hundred forty

743
00:49:32,700 --> 00:49:34,310
we take an equal one

744
00:49:34,380 --> 00:49:37,000
so if frequency that we get

745
00:49:37,150 --> 00:49:39,350
o three hundred forty

746
00:49:39,430 --> 00:49:42,370
divided by two l which is o point five

747
00:49:42,380 --> 00:49:43,480
i mean

748
00:49:43,500 --> 00:49:46,580
and so to give six hundred eighty

749
00:49:46,580 --> 00:49:51,600
so to speak give you six hundred eighty hertz

750
00:49:51,610 --> 00:49:52,800
but the second

751
00:49:52,850 --> 00:49:55,550
monarch have two

752
00:49:55,570 --> 00:49:57,040
double that

753
00:49:57,110 --> 00:50:02,820
so we'll be thirteen hundred and sixty years and so on

754
00:50:02,870 --> 00:50:03,680
now this

755
00:50:03,710 --> 00:50:07,580
system which is close on both sides wouldn't be very good musical instruments because you

756
00:50:07,580 --> 00:50:10,560
sound wouldn't come out

757
00:50:10,590 --> 00:50:12,800
so what people do they make them all

758
00:50:12,850 --> 00:50:14,560
sound cavity

759
00:50:14,570 --> 00:50:16,840
it open on both sides

760
00:50:16,850 --> 00:50:18,250
like this for instance

761
00:50:18,350 --> 00:50:22,450
is open on both sides

762
00:50:22,460 --> 00:50:24,560
and even though it may surprise you

763
00:50:24,590 --> 00:50:26,590
if we put a little

764
00:50:26,600 --> 00:50:28,180
speaker here

765
00:50:28,200 --> 00:50:32,060
we can excite the columns even in his own consistent in a complete similar way

766
00:50:32,060 --> 00:50:34,320
than we do it here it is closest

767
00:50:34,320 --> 00:50:36,170
and we get exactly the same

768
00:50:36,240 --> 00:50:39,910
series of frequencies that i put you on the record

769
00:50:39,980 --> 00:50:42,120
there also musical instruments

770
00:50:42,160 --> 00:50:45,900
which open on one side and close on the other

771
00:50:45,900 --> 00:50:49,660
so this is called an open open systems

772
00:50:49,750 --> 00:50:56,050
and this would be called closed open clarinet close

773
00:50:56,060 --> 00:51:00,570
i can also get a series of resonance frequencies even though here

774
00:51:00,620 --> 00:51:03,850
the series wouldn't be exactly like this it's a little different it doesn't matter now

775
00:51:03,900 --> 00:51:08,250
different but it it a little different but you get again the whole series

776
00:51:08,310 --> 00:51:11,660
all resonance frequencies

777
00:51:11,750 --> 00:51:15,120
so again you see that if i make the system longer

778
00:51:16,180 --> 00:51:18,560
i get lower frequencies

779
00:51:18,560 --> 00:51:20,240
if i make the length

780
00:51:20,300 --> 00:51:22,050
one meter

781
00:51:23,550 --> 00:51:25,580
then i will get the frequency

782
00:51:27,060 --> 00:51:29,890
which is about four times lower than the one that i have there

783
00:51:29,910 --> 00:51:32,240
which is hundred seventy words

784
00:51:32,380 --> 00:51:38,610
and the second harmonic within three hundred

785
00:51:38,640 --> 00:51:40,090
forty years and so on

786
00:51:40,140 --> 00:51:42,540
so when you see an organ

787
00:51:42,650 --> 00:51:44,980
in the church you see all these organ pipes

788
00:51:45,070 --> 00:51:48,900
different lengths the one ones very low tones and the short ones at the very

789
00:51:49,990 --> 00:51:51,480
and that's the way that these

790
00:51:51,490 --> 00:51:54,860
in summons work

791
00:51:54,950 --> 00:51:57,100
i have here

792
00:51:58,040 --> 00:52:02,580
wind organ which i have demonstrated you before it is open on both sides

793
00:52:02,630 --> 00:52:04,660
and because is corrugated

794
00:52:04,810 --> 00:52:06,220
a very special way

795
00:52:06,270 --> 00:52:08,300
when i blow winds past this

796
00:52:08,370 --> 00:52:09,150
it will

797
00:52:09,160 --> 00:52:10,250
going to

798
00:52:10,300 --> 00:52:11,810
residents that's to say

799
00:52:11,820 --> 00:52:15,950
went here is like a spectrum of all possible frequencies

800
00:52:16,010 --> 00:52:18,470
it's like the bow on the violin

801
00:52:18,490 --> 00:52:21,700
and then it picks out the frequencies that like

802
00:52:21,750 --> 00:52:24,260
however if i increase the speed of the wind

803
00:52:24,270 --> 00:52:25,920
i can try to

804
00:52:25,930 --> 00:52:28,820
forces into higher frequency

805
00:52:28,820 --> 00:52:32,720
so at low wind speed i'm more likely to hit

806
00:52:32,810 --> 00:52:36,480
the lower harmonics at high wind speeds i'm more likely to hit the

807
00:52:36,510 --> 00:52:39,550
i harmonic this one is seventy five centimetres long

808
00:52:39,590 --> 00:52:41,150
it's open open

809
00:52:41,160 --> 00:52:42,850
if i were able

810
00:52:42,870 --> 00:52:43,940
two hits the

811
00:52:43,980 --> 00:52:45,130
first harmonic

812
00:52:45,130 --> 00:52:48,000
that would be a frequency of about two hundred and

813
00:52:48,060 --> 00:52:49,810
forty hertz

814
00:52:49,860 --> 00:52:53,160
i may not be able to excite the lowest harmonics

815
00:52:53,240 --> 00:52:57,850
the first harmonic but i'll try certainly the higher harmonics are very easy to excite

816
00:52:57,850 --> 00:53:01,070
and i can make you even this and simultaneously

817
00:53:01,120 --> 00:53:02,900
two more than one frequency

818
00:53:02,920 --> 00:53:04,680
just like the violin string

819
00:53:04,730 --> 00:53:06,250
when you strike it

820
00:53:06,260 --> 00:53:08,230
and simultaneously oscillate

821
00:53:08,240 --> 00:53:10,890
in a combination of these modes

822
00:53:10,970 --> 00:53:12,590
but this world is around

823
00:53:12,600 --> 00:53:16,020
first start low

824
00:53:16,050 --> 00:53:20,890
this maybe two forty

825
00:53:20,910 --> 00:53:34,170
dance definitely weihai hana i i

826
00:53:34,300 --> 00:53:36,900
this is what is the lowest this is

827
00:53:36,910 --> 00:53:39,050
first harmonic

828
00:53:39,080 --> 00:53:40,840
we're not trying to do here that you

829
00:53:40,850 --> 00:53:51,110
two simultaneously tool

830
00:53:51,130 --> 00:53:53,170
if you play flute

831
00:53:54,010 --> 00:53:58,940
you do the following make holes in here

832
00:53:58,960 --> 00:54:01,340
you take your fingers of both holes

833
00:54:01,340 --> 00:54:03,430
and the effective length of the fruit

834
00:54:03,450 --> 00:54:06,290
this is not going hide

835
00:54:06,360 --> 00:54:08,830
you put your finger on this one

836
00:54:08,910 --> 00:54:13,320
and the effective length of the flu this longer load

837
00:54:13,350 --> 00:54:14,960
you put your finger on both

838
00:54:14,980 --> 00:54:17,820
the effective length of the flu this long

839
00:54:17,820 --> 00:54:19,870
you get an even lower

840
00:54:19,880 --> 00:54:21,800
i have you very special fruit

841
00:54:21,850 --> 00:54:23,490
open on both sides

842
00:54:23,620 --> 00:54:25,390
you see the two holes

843
00:54:25,390 --> 00:54:27,210
well first close to two

844
00:54:27,410 --> 00:54:29,920
this is the lowest frequency

845
00:54:37,430 --> 00:54:46,850
he played flute

846
00:54:46,850 --> 00:54:49,600
which implemented making in some and longer

847
00:54:49,610 --> 00:54:51,360
well short

848
00:54:51,410 --> 00:54:53,860
i have another example here of an instrument

849
00:54:53,900 --> 00:54:55,320
it is

850
00:54:55,400 --> 00:54:56,850
open here

851
00:54:56,870 --> 00:54:59,110
here is clear

852
00:54:59,160 --> 00:55:01,340
this is my version of the trombone

853
00:55:01,410 --> 00:55:03,720
this thing here

854
00:55:03,750 --> 00:55:06,490
so this is the system that is like this

855
00:55:06,500 --> 00:55:08,370
but i can move this in

856
00:55:08,400 --> 00:55:11,950
and so when i heard before

857
00:55:11,980 --> 00:55:14,890
frequency would be high

858
00:55:19,300 --> 00:55:32,730
this is directly related to the legs

859
00:55:32,740 --> 00:55:34,090
of this trombone

860
00:55:34,090 --> 00:55:36,950
and if you learn how to play you can try to play

861
00:55:48,650 --> 00:56:06,850
thank you

862
00:56:08,200 --> 00:56:10,470
i all around us

863
00:56:10,520 --> 00:56:12,860
when you drive your car

864
00:56:12,860 --> 00:56:15,990
you may have noticed that all of a sudden you some crazy rattle somewhere could

865
00:56:15,990 --> 00:56:23,450
distance that this defines the angular diameter distance other cosmological observables include the volume how

866
00:56:23,450 --> 00:56:29,210
the volume of the universe changes the age of the universe and any distances

867
00:56:29,210 --> 00:56:35,870
depend upon H of Z now in terms of the evidence for dark energy the first

868
00:56:35,870 --> 00:56:42,110
evidence for dark energy came from the luminosity distance redshift or Hubble diagram and I

869
00:56:42,110 --> 00:56:51,190
show this graph in the first lecture this is a graph showing some random notation

870
00:56:51,190 --> 00:56:57,190
related to supernova brightness as a function of the supernova redshift and these low redshift

871
00:56:57,190 --> 00:57:04,870
supernova faint objects are there bright objects are down there and this graph is normalized to

872
00:57:04,940 --> 00:57:10,050
the best fit lambda CDM model so you can do the statistics

873
00:57:10,050 --> 00:57:15,910
and convince yourself that the lambda CDM model is a reasonable fit to the observations and

874
00:57:15,910 --> 00:57:19,490
you can also just look at look at it you don't have to do a fancy

875
00:57:19,490 --> 00:57:26,410
statistical analysis to realize that the Einstein-de Sitter model the flat spatially flat

876
00:57:26,410 --> 00:57:35,290
as suggested by the CMB matter dominated universe does not fit the data so this

877
00:57:35,300 --> 00:57:41,130
can be expressed and is often expressed in terms of confidence contours sixty-seven percent

878
00:57:41,130 --> 00:57:47,890
ninety percent ninety-five percent in the omega lambda omega matter plane so it's

879
00:57:47,890 --> 00:57:53,750
important to remember how this is constructed one finds a standard candle in this case

880
00:57:53,750 --> 00:58:00,950
type one A supernovae you observe the magnitude in redshift of this standard candle then

881
00:58:00,950 --> 00:58:08,990
so that's the observations the magnitude and the redshift then you assume a cosmological

882
00:58:08,990 --> 00:58:14,560
model and on the basis of this cosmologi cosmological model compare the observations and the model

883
00:58:14,560 --> 00:58:21,810
this in this graph this the particular cosmological model assumes that W is equal

884
00:58:21,810 --> 00:58:28,950
to minus one so it is not allowed for W to be changing with redshift and it

885
00:58:28,950 --> 00:58:37,070
also assumes priors on other cosmological parameters H nod omega things like that omega

886
00:58:37,070 --> 00:58:41,750
baryon what have you and on the basis of that you can see that

887
00:58:41,750 --> 00:58:48,390
the fit  requires a cosmological constant that this is the best fit contour and if

888
00:58:48,390 --> 00:58:53,810
you take the flat value as suggested by the CMB is suggests omega lambda

889
00:58:53,810 --> 00:59:01,470
of point six point seven and omega matter of about point three so the fit

890
00:59:01,470 --> 00:59:08,350
within the framework of this model requires a cosmoillogical constant and the value of the

891
00:59:08,350 --> 00:59:13,890
energy density of the cosmoillogical constant is ten to the minus thirty  grams per cubic

892
00:59:13,890 --> 00:59:22,530
centimeter a remarkably small number that the fact that it should be that small in

893
00:59:22,540 --> 00:59:30,690
non zero is remarkable and you can imagine that's it's ill it's illogical if you

894
00:59:30,690 --> 00:59:36,430
compare it to a mass scale or a length scale you can write ten to the minus thirty

895
00:59:36,430 --> 00:59:43,730
grams per cubic centimeter as ten to the minus four electron volts to the fourth power or

896
00:59:43,730 --> 00:59:49,470
ten to the minus three centimeters to the minus four power  so if this is a

897
00:59:49,470 --> 00:59:57,170
fundamental constant in nature then it suggests that there is a fundamental energy scale of

898
00:59:57,170 --> 01:00:02,170
ten to the minus four electron volts or its  fundamental length  scale of ten to

899
01:00:02,170 --> 01:00:10,830
the minus three centimeters it's hard to imagine those being fundamental scales in nature you

900
01:00:10,830 --> 01:00:17,370
can also express the cosmoillogical constant in terms of the way Einstein wrote it lambda which

901
01:00:17,370 --> 01:00:22,690
is eight pi G times the energy density and in this case the mass scale is ten

902
01:00:22,710 --> 01:00:31,210
to the minus thirty-three electron volts  that doesn't sound like high-energy physics to me  corresponding to

903
01:00:31,210 --> 01:00:36,730
a length  scale of ten to the twenty-nine centimeters so this is why I call it

904
01:00:36,730 --> 01:00:43,710
of the current text mining techniques and the real natural language understanding what people in

905
01:00:43,730 --> 01:00:45,490
already for quite some

906
01:00:49,510 --> 01:00:51,110
so what

907
01:00:51,120 --> 01:00:52,350
look at the

908
01:00:52,360 --> 01:00:53,870
what kind

909
01:00:55,010 --> 01:00:57,750
discussed so far

910
01:00:57,760 --> 01:01:01,460
the sequences

911
01:01:01,490 --> 01:01:09,300
these sequences classical technique this using markov models

912
01:01:09,310 --> 01:01:13,290
we can all see themselves

913
01:01:14,270 --> 01:01:16,360
and i think is in fact

914
01:01:16,370 --> 01:01:18,000
graphical models

915
01:01:18,020 --> 01:01:20,200
so then speak about the

916
01:01:21,760 --> 01:01:23,790
but conditions in

917
01:01:24,630 --> 01:01:30,130
two of graph structure just she sequence

918
01:01:30,180 --> 01:01:32,200
of information

919
01:01:32,230 --> 01:01:33,660
and in this

920
01:01:33,670 --> 01:01:35,070
so are

921
01:01:35,100 --> 01:01:38,870
i was thinking about directed graphical models

922
01:01:39,820 --> 01:01:46,260
bayesian networks for instance but i speak about techniques of topics

923
01:01:47,450 --> 01:01:49,120
i think topic

924
01:01:49,140 --> 01:01:52,180
which become

925
01:01:53,500 --> 01:01:55,050
also text mining

926
01:01:55,080 --> 01:01:57,240
this information

927
01:01:57,250 --> 01:01:58,370
and this

928
01:01:58,450 --> 01:02:02,270
the techniques of probabilistic latent semantic

929
01:02:02,290 --> 01:02:03,690
and it

930
01:02:07,360 --> 01:02:11,020
i want to go to the future

931
01:02:11,040 --> 01:02:26,420
research directions

932
01:02:26,490 --> 01:02:28,570
so it's it's

933
01:02:29,240 --> 01:02:31,750
i don't know the

934
01:02:31,760 --> 01:02:34,020
classification techniques to

935
01:02:34,050 --> 01:02:35,050
go first

936
01:02:35,060 --> 01:02:36,250
they didn't not

937
01:02:36,250 --> 01:02:38,260
consider the context

938
01:02:38,270 --> 01:02:41,410
so the context independent

939
01:02:41,420 --> 01:02:43,120
but there is

940
01:02:43,170 --> 01:02:45,690
the techniques are

941
01:02:45,710 --> 01:02:47,440
talking about like that

942
01:02:47,500 --> 01:02:51,120
of course well all the ones that

943
01:02:52,420 --> 01:02:55,640
there should be

944
01:02:56,380 --> 01:02:58,960
context c

945
01:02:59,010 --> 01:03:00,460
which means that we

946
01:03:00,490 --> 01:03:02,510
before classification

947
01:03:06,410 --> 01:03:08,730
that's the only

948
01:03:08,750 --> 01:03:11,730
feature vector to object

949
01:03:11,750 --> 01:03:13,910
that you want to classify

950
01:03:13,920 --> 01:03:14,600
but it

951
01:03:14,610 --> 01:03:21,560
in this classification also depends on the values of the feature vectors

952
01:03:23,510 --> 01:03:25,790
we have a knowledge

953
01:03:25,810 --> 01:03:30,050
about the relationship between classes which

954
01:03:30,060 --> 01:03:34,750
model for instance sequences are graphical models

955
01:03:34,760 --> 01:03:38,450
and so we get these examples hidden markov model

956
01:03:38,520 --> 01:03:41,570
conditional fees

957
01:03:41,600 --> 01:03:44,420
so what

958
01:03:44,620 --> 01:03:54,640
well it's actually probabilistic finite state automaton with maybe i

959
01:03:54,650 --> 01:03:56,220
we can look

960
01:03:56,270 --> 01:03:58,070
some examples

961
01:04:01,040 --> 01:04:04,830
sequential structure in the

962
01:04:04,850 --> 01:04:06,810
which i want to discard

963
01:04:06,830 --> 01:04:11,760
and an example could be a text

964
01:04:14,610 --> 01:04:18,830
in the sequence legal case like example of it

965
01:04:21,810 --> 01:04:28,900
you've served as in the case my description of the core of the names of

966
01:04:28,900 --> 01:04:30,180
the victims

967
01:04:31,010 --> 01:04:33,820
use of france

968
01:04:33,880 --> 01:04:41,100
some sort of being useful sections of the church fine examples include

969
01:04:41,130 --> 01:04:42,810
so what

970
01:04:42,830 --> 01:04:44,130
not all of

971
01:04:44,140 --> 01:04:48,340
when you can follow a different path c

972
01:04:50,270 --> 01:04:52,110
course data

973
01:04:52,170 --> 01:04:53,290
the let

974
01:04:54,580 --> 01:04:56,230
i mentioned

975
01:04:56,390 --> 01:05:02,360
why the we could be mentioned in the first instance so you could follow

976
01:05:02,410 --> 01:05:04,510
well defined

977
01:05:04,530 --> 01:05:06,310
this is

978
01:05:08,140 --> 01:05:11,880
to write this document

979
01:05:12,470 --> 01:05:14,780
the transitions from

980
01:05:14,800 --> 01:05:17,190
state party

981
01:05:17,210 --> 01:05:19,230
document to another

982
01:05:19,260 --> 01:05:23,310
has some probability of transitioning from

983
01:05:23,320 --> 01:05:28,240
so this is a probabilistic statement was to

984
01:05:28,270 --> 01:05:29,360
problem is

985
01:05:29,420 --> 01:05:31,530
you could just

986
01:05:32,040 --> 01:05:34,290
final state of italy

987
01:05:34,330 --> 01:05:35,450
and if

988
01:05:35,490 --> 01:05:42,220
document complies with all these elements of the states it would be

989
01:05:42,230 --> 01:05:43,980
case of you

990
01:05:44,010 --> 01:05:46,940
because graph of the document

991
01:05:46,940 --> 01:05:50,560
but since we have a transition probability

992
01:05:50,570 --> 01:05:53,070
is a probabilistic model

993
01:05:53,090 --> 01:05:55,560
we also interested

994
01:05:55,680 --> 01:06:01,040
so the image is emissions of symbols alphabet

995
01:06:01,060 --> 01:06:03,380
in this case my

996
01:06:03,390 --> 01:06:13,580
strings character strings that so that the system complement of documents which belong to that

997
01:06:13,610 --> 01:06:16,940
for instance to see the

998
01:06:20,190 --> 01:06:22,270
and also these images

999
01:06:22,290 --> 01:06:26,020
after probabilities which are not

1000
01:06:26,770 --> 01:06:28,360
a few missions

1001
01:06:28,390 --> 01:06:45,990
often but also here you've so if the problem is often

1002
01:06:46,010 --> 01:06:47,140
so i think

1003
01:06:47,140 --> 01:06:51,760
i think the joint distribution between the six random variables

1004
01:06:51,790 --> 01:06:53,830
is factorised

1005
01:06:53,850 --> 01:06:55,540
in this way

1006
01:06:55,560 --> 01:06:57,200
this is joint injury problems

1007
01:06:57,200 --> 01:07:01,470
the next year so that is the probability of x one

1008
01:07:01,490 --> 01:07:04,080
given up because the has parents

1009
01:07:04,080 --> 01:07:08,660
time the probability of x two given all of his parents but just XY

1010
01:07:08,680 --> 01:07:12,620
so from the next given all of his parents

1011
01:07:12,680 --> 01:07:16,220
so this is a picture that drawn this is the assumption

1012
01:07:16,220 --> 01:07:20,220
that i'm making and this is the structure of a computer program

1013
01:07:20,220 --> 01:07:23,700
the computer program has each of these

1014
01:07:23,720 --> 01:07:30,040
undefined constants which control the conditional distributions and our job is to fill in these

1015
01:07:30,040 --> 01:07:31,720
probability distribution so

1016
01:07:31,740 --> 01:07:36,760
all that's left to left right down model is the values the table everything else

1017
01:07:36,780 --> 01:07:42,660
has already been specified misspecified structure of office costs by running track which is we

1018
01:07:42,660 --> 01:07:47,490
select depends the values for these conditional probability tables which is equivalent to specifying these

1019
01:07:47,490 --> 01:07:51,700
assumptions so the graph tells factorizations

1020
01:07:51,720 --> 01:07:53,890
the parameters in the nodes

1021
01:07:53,950 --> 01:07:55,950
graph the details

1022
01:07:55,970 --> 01:07:57,740
which is a specific

1023
01:07:57,760 --> 01:08:02,740
memory is so this picture does not specify at all

1024
01:08:02,760 --> 01:08:06,700
a specific model specifies the hypothesis class set of all

1025
01:08:06,700 --> 01:08:08,990
we want to go through

1026
01:08:08,990 --> 01:08:12,370
fighters would instantiate that you get to this position

1027
01:08:12,490 --> 01:08:15,930
probabilistic model

1028
01:08:15,950 --> 01:08:24,410
so this is the hypothesis class and within we select anything want by setting is

1029
01:08:24,450 --> 01:08:30,510
so the key point about directed graphical models is missing edges imply conditional independence

1030
01:08:30,520 --> 01:08:35,100
so surrounded by the chain rule we can always write the full joint distribution has

1031
01:08:36,540 --> 01:08:40,710
i could always take any joint distribution without making any assumption about it and start

1032
01:08:40,710 --> 01:08:41,930
writing in this way

1033
01:08:41,990 --> 01:08:46,410
it is the probability that one times the probability of x two given x excellent

1034
01:08:46,430 --> 01:08:49,660
times extreme given everything that came before

1035
01:08:49,720 --> 01:08:52,240
export given everything can form

1036
01:08:52,260 --> 01:08:56,020
and what does that have to adapt those in any crosses all these things is

1037
01:08:56,020 --> 01:09:00,810
that makes collector picture

1038
01:09:00,810 --> 01:09:03,680
thanks for here

1039
01:09:03,700 --> 01:09:06,850
doesn't have anyone except x two is

1040
01:09:06,950 --> 01:09:11,580
so our assumption going on sale crossed x one x three and x six those

1041
01:09:11,580 --> 01:09:13,870
no longer parents before

1042
01:09:13,890 --> 01:09:16,640
so could missing edges

1043
01:09:16,680 --> 01:09:19,760
correspond to conditional independence assumptions are

1044
01:09:19,760 --> 01:09:24,700
the conditional independence assumption saying that the probability of something given

1045
01:09:24,700 --> 01:09:29,890
many things is the same as the probability that a given subset conditional independence and

1046
01:09:29,890 --> 01:09:31,290
that's exactly what we do

1047
01:09:31,410 --> 01:09:34,850
that we crossed the conditioning

1048
01:09:34,870 --> 01:09:39,560
so the DAG is telling us that each variable is conditionally independent of its non

1049
01:09:39,560 --> 01:09:45,060
descendants given its parents once you your parents then the conditional on the conditional distributions

1050
01:09:45,060 --> 01:09:47,060
completely specified

1051
01:09:47,080 --> 01:09:52,930
and removing an edge into i eliminates an argument from the right hand side

1052
01:09:57,470 --> 01:10:00,760
this is a very important factor directed graphical models

1053
01:10:00,760 --> 01:10:03,910
right to to before we we get start

1054
01:10:03,930 --> 01:10:06,560
this is called explaining away

1055
01:10:06,580 --> 01:10:10,970
and it addresses the confusion of what people have when they start thinking for the

1056
01:10:10,970 --> 01:10:11,580
first time

1057
01:10:12,330 --> 01:10:13,370
if you look at this

1058
01:10:13,390 --> 01:10:14,990
graph here

1059
01:10:15,010 --> 01:10:17,850
you might think to to yourself well

1060
01:10:17,870 --> 01:10:21,430
x and z are unrelated

1061
01:10:21,430 --> 01:10:23,970
because there's no in between

1062
01:10:24,660 --> 01:10:26,910
many parents so

1063
01:10:26,930 --> 01:10:30,060
this is no only thing but

1064
01:10:30,080 --> 01:10:35,620
because they share a common child when we condition on this child when user value

1065
01:10:36,760 --> 01:10:38,990
x and z become coupled

1066
01:10:39,040 --> 01:10:42,640
so x and z are marginally that's true

1067
01:10:42,660 --> 01:10:48,430
if you just generate samples from the family of distributions is a graph of marginal

1068
01:10:48,430 --> 01:10:52,110
links and they can themselves be type of the network so it sort of worth

1069
01:10:52,140 --> 01:10:58,140
realizing that there's a kind of hierarchical relationship that one the link layer

1070
01:10:58,410 --> 01:11:03,720
may actually itself be network can consisting of multiple links but from the point of

1071
01:11:03,720 --> 01:11:08,200
view of the level here is just a single link modem connection to some point

1072
01:11:08,250 --> 01:11:11,190
we can send a message of

1073
01:11:13,800 --> 01:11:19,760
what i want to do now is take you through we're going to switch gears

1074
01:11:19,760 --> 01:11:22,090
a little bit and talk about

1075
01:11:22,110 --> 01:11:25,250
so the next piece that i said that we needed to address which is this

1076
01:11:25,250 --> 01:11:27,350
issue router

1077
01:11:27,370 --> 01:11:29,690
so i said we're going to talk about forwarding

1078
01:11:29,690 --> 01:11:33,060
there were to talk about something else called routing so

1079
01:11:38,100 --> 01:11:40,440
is the process by which we build up

1080
01:11:40,450 --> 01:11:41,630
our boring

1081
01:11:42,850 --> 01:11:45,510
what i should here was i just sort of told you what the values that

1082
01:11:45,510 --> 01:11:46,870
you go in the forty tables should be

1083
01:11:47,260 --> 01:11:50,110
i didn't tell you how they are derived where they came from

1084
01:11:50,200 --> 01:11:53,510
so in this case the simple network is relatively easy for us to

1085
01:11:53,520 --> 01:11:56,960
by hand sort of come up with a set of possible

1086
01:11:57,020 --> 01:12:01,780
four it has that seems reasonable but you can imagine that this thing if this

1087
01:12:01,780 --> 01:12:05,030
network it scaled up to a million nodes that's not something that we want any

1088
01:12:05,030 --> 01:12:06,490
individual they have to do

1089
01:12:06,500 --> 01:12:09,450
no person should have to configure all these routing tables

1090
01:12:09,470 --> 01:12:12,830
so instead of all these forty table so instead what going do

1091
01:12:12,850 --> 01:12:16,660
it is we're going use this process called routing in order to build these forwarding

1092
01:12:16,660 --> 01:12:18,810
tables automatically

1093
01:12:18,940 --> 01:12:23,310
and what we want we really want our routing protocol to be three things

1094
01:12:23,390 --> 01:12:26,110
first try to be scalable

1095
01:12:26,120 --> 01:12:29,310
and the obvious way in which you want to scale the way that just said

1096
01:12:29,350 --> 01:12:32,320
we don't want to have to have people

1097
01:12:32,340 --> 01:12:35,130
we want to this thing to scale up to say a million nodes are several

1098
01:12:35,130 --> 01:12:38,380
million nodes and be able to continue to work we shouldn't have to people sort

1099
01:12:38,380 --> 01:12:43,720
of involved with configuring building up these forwarding tables at every step of the way

1100
01:12:43,840 --> 01:12:47,750
we also wanted to be robust so by that i mean

1101
01:12:47,910 --> 01:12:51,530
it should be tolerant of false if a node fails in the network

1102
01:12:52,360 --> 01:12:56,800
network should eventually discovered that node has failed and be able to forward packets around

1103
01:12:56,800 --> 01:13:01,030
the failure to be able to compensate for the failure of it all possible

1104
01:13:01,050 --> 01:13:08,710
finally we want this routing protocol hopefully to be distributed

1105
01:13:08,860 --> 01:13:13,040
so we don't want to have to have one machine is responsible for setting up

1106
01:13:13,430 --> 01:13:18,270
to forty people and all the other machines don't have one machine that needs to

1107
01:13:18,270 --> 01:13:21,690
contact all of the other nodes and collect information about what all of the links

1108
01:13:21,690 --> 01:13:25,600
are an example of those links together into one global for scheme

1109
01:13:25,660 --> 01:13:29,970
and this really gets at the scalability again

1110
01:13:30,910 --> 01:13:33,570
what we're going to do what i do is to take you through the process

1111
01:13:33,570 --> 01:13:36,570
of routing before i do that i just want to do is take a quick

1112
01:13:36,570 --> 01:13:40,840
digression we're going to start off with a very tiny networks and this and just

1113
01:13:40,840 --> 01:13:44,260
talking about a very simple BBC network which is so you guys don't feel like

1114
01:13:44,280 --> 01:13:48,100
this is completely unrealistic i want to show you that in fact the internet somewhere

1115
01:13:48,100 --> 01:13:50,140
at some level started out like this too

1116
01:13:50,160 --> 01:13:53,170
we're going to do in the course this class sort of build up from these

1117
01:13:53,180 --> 01:13:58,050
very simple networks maybe look the way the internet the first two schemes that are

1118
01:13:58,050 --> 01:14:01,140
more like what is actually used in today's production

1119
01:14:05,510 --> 01:14:09,270
one back on you guys

1120
01:14:09,330 --> 01:14:12,300
OK so this is a picture of what the internet looked like in nineteen sixty

1121
01:14:12,300 --> 01:14:13,320
nine so

1122
01:14:13,330 --> 01:14:16,580
you may not be able to read the labels on these things but there are

1123
01:14:16,580 --> 01:14:21,700
these there are with looking at three notes here this is UC santa barbara

1124
01:14:21,700 --> 01:14:24,310
on the coast of california

1125
01:14:24,490 --> 01:14:30,210
a sort of central california are southern and central california this is stanford research institute

1126
01:14:30,210 --> 01:14:31,060
as our i

1127
01:14:31,070 --> 01:14:32,740
which is the variable

1128
01:14:32,740 --> 01:14:34,310
this is utah

1129
01:14:34,330 --> 01:14:38,720
and this is UCLA so this was this was this are which was the precursor

1130
01:14:38,720 --> 01:14:42,280
to the internet the sort of the very one of the very first of these

1131
01:14:42,280 --> 01:14:44,910
and that can be high school

1132
01:14:44,910 --> 01:14:48,580
and then we take the rest of the thing going to look at some point

1133
01:14:50,070 --> 01:14:51,690
and so on

1134
01:14:51,890 --> 01:14:55,730
so this produce was born i

1135
01:14:55,740 --> 01:14:58,540
because we think that one

1136
01:14:58,590 --> 01:15:00,580
we know that this sequence of high

1137
01:15:02,290 --> 01:15:07,580
has some one because the focal length of the biggest one

1138
01:15:07,700 --> 01:15:11,640
that is called the stick breaking construction

1139
01:15:11,640 --> 01:15:13,310
and basically

1140
01:15:13,330 --> 01:15:17,220
it's a very direct construction of this

1141
01:15:18,180 --> 01:15:20,110
probability measure g

1142
01:15:20,860 --> 01:15:22,710
i would say that

1143
01:15:22,750 --> 01:15:26,910
the corresponding to each

1144
01:15:26,920 --> 01:15:32,460
i a we draw the corresponding to sparky from a base distribution

1145
01:15:38,700 --> 01:15:47,460
sample of

1146
01:15:47,470 --> 01:15:50,130
some examples of the

1147
01:15:50,130 --> 01:15:52,010
draws of high

1148
01:15:52,030 --> 01:15:57,000
so the height corresponds to i one i two i three

1149
01:15:57,010 --> 01:15:59,500
and this is the value of y

1150
01:15:59,660 --> 01:16:00,780
so this is

1151
01:16:00,890 --> 01:16:03,750
as free independent samples from

1152
01:16:03,820 --> 01:16:06,440
from the stick breaking construction

1153
01:16:06,480 --> 01:16:07,710
i i notice that

1154
01:16:07,780 --> 01:16:09,270
they need may not be

1155
01:16:09,330 --> 01:16:10,990
strictly decreasing

1156
01:16:10,990 --> 01:16:12,930
but generally

1157
01:16:13,000 --> 01:16:16,250
beyond the value of pi very small

1158
01:16:16,270 --> 01:16:20,900
most of the non-fatal values of i think

1159
01:16:31,240 --> 01:16:34,490
the first thing the

1160
01:16:34,500 --> 01:16:35,740
o thing with

1161
01:16:35,740 --> 01:16:39,920
i guess i didn't show that you could actually about what nations of the dirichlet

1162
01:16:39,920 --> 01:16:43,750
process and get from that the stick breaking construction

1163
01:16:43,800 --> 01:16:47,920
and what the romans show in nineteen ninety four is that bad

1164
01:16:47,960 --> 01:16:51,390
bankers but from the stick breaking construction

1165
01:16:51,400 --> 01:16:56,330
and you can prove that the random probability measure which is constructed satisfies all the

1166
01:16:56,330 --> 01:17:00,690
properties of the dirichlet process which means that that is the

1167
01:17:00,710 --> 01:17:02,980
this very constructive

1168
01:17:04,280 --> 01:17:09,530
of the existence of this process

1169
01:17:09,580 --> 01:17:11,660
so we have

1170
01:17:12,820 --> 01:17:17,540
three different representations of dirichlet processes as well as the iteration process

1171
01:17:17,600 --> 01:17:18,700
so there

1172
01:17:20,040 --> 01:17:23,320
the chinese restaurant process and then the construction

1173
01:17:23,460 --> 01:17:25,850
so all this actually

1174
01:17:26,240 --> 01:17:33,260
if you have a different understanding of what is this object of dirichlet process

1175
01:17:33,320 --> 01:17:37,950
and in fact they only two different rhythms as well

1176
01:17:37,980 --> 01:17:40,060
any questions

1177
01:17:40,420 --> 01:17:42,330
i guess so and with the

1178
01:17:42,340 --> 01:17:45,780
the ways in which you could model data with dirichlet process

1179
01:17:45,820 --> 01:17:47,060
the first question

1180
01:17:47,150 --> 01:17:49,360
could deal with it

1181
01:17:49,400 --> 01:17:54,300
the question that the estimation recall that in the case of that the estimation what

1182
01:17:54,310 --> 01:17:58,080
we did was what i think we do is the following

1183
01:17:59,430 --> 01:18:00,920
distribution g

1184
01:18:00,940 --> 01:18:03,610
random distribution g from the prior

1185
01:18:03,740 --> 01:18:06,000
which is given by dirichlet process

1186
01:18:06,020 --> 01:18:08,740
and we see that are actors drawn from g

1187
01:18:11,540 --> 01:18:12,950
the idea

1188
01:18:13,020 --> 01:18:14,250
that doesn't work

1189
01:18:15,940 --> 01:18:18,240
do people know why

1190
01:18:18,730 --> 01:18:22,700
only on

1191
01:18:24,220 --> 01:18:29,490
anyway actually can probably be

1192
01:18:30,040 --> 01:18:32,880
the problem is that since we saw that

1193
01:18:32,880 --> 01:18:36,140
draws from a dirichlet process a discrete distribution

1194
01:18:36,150 --> 01:18:41,250
and this despite distributions both actually happened and so we can only do depth estimation

1195
01:18:41,250 --> 01:18:43,580
if we use the model that

1196
01:18:43,850 --> 01:18:47,300
so the solution is simply to take our

1197
01:18:48,610 --> 01:18:50,590
and convolved with a small

1198
01:18:51,900 --> 01:18:53,950
in this case

1199
01:18:55,190 --> 01:18:58,230
the coverage is simply with a GMM we

1200
01:18:58,240 --> 01:19:00,900
integrate the act of

1201
01:19:00,910 --> 01:19:03,940
they is the distribution on axis

1202
01:19:03,950 --> 01:19:07,270
which is a small distribution parameterized by theta

1203
01:19:07,410 --> 01:19:10,940
we simply integrate with respect to g

1204
01:19:11,100 --> 01:19:13,950
and they

1205
01:19:13,950 --> 01:19:15,550
and that

1206
01:19:15,610 --> 01:19:18,970
you have more than of x would be more than one

1207
01:19:19,010 --> 01:19:21,830
and we use that our

1208
01:19:23,000 --> 01:19:25,540
i thought

1209
01:19:26,040 --> 01:19:33,920
as the construction of the density of our dispute

1210
01:19:35,290 --> 01:19:38,800
that underlies the act and this thing has

1211
01:19:38,960 --> 01:19:42,140
and so that the

1212
01:19:42,290 --> 01:19:44,190
she has this

1213
01:19:44,240 --> 01:19:47,060
representation at the bottom of the ocean

1214
01:19:47,080 --> 01:19:51,230
we know that acts it's all basically it's the mixture

1215
01:19:51,270 --> 01:19:53,450
as of the date first

1216
01:19:54,730 --> 01:20:00,760
where the mixing proportions i given by higher

1217
01:20:00,940 --> 01:20:05,190
coming back to this

1218
01:20:05,310 --> 01:20:10,960
this is the bigger the actual you know where this other random draws from

1219
01:20:11,010 --> 01:20:11,750
i was

1220
01:20:11,760 --> 01:20:13,500
prior over the density

1221
01:20:13,530 --> 01:20:16,690
in this case we use a

1222
01:20:16,690 --> 01:20:19,420
so the with the mean

1223
01:20:19,470 --> 01:20:22,340
basically with given mean and covariance

1224
01:20:22,360 --> 01:20:26,090
well base distribution is out in the which

1225
01:20:26,140 --> 01:20:27,500
and you get prior

1226
01:20:28,510 --> 01:20:30,270
u and sigma

1227
01:20:30,630 --> 01:20:31,960
not so on

1228
01:20:31,970 --> 01:20:33,930
from basically

1229
01:20:33,930 --> 01:20:35,040
and we

1230
01:20:35,080 --> 01:20:40,400
pick a random height uniformly filled with sampling points underneath the screen somewhere

1231
01:20:40,430 --> 01:20:43,470
now what we're doing is with some points uniformly and the green curve if we

1232
01:20:43,470 --> 01:20:46,640
toss out full ones that aren't underneath the blue curve then will just be left

1233
01:20:46,640 --> 01:20:52,310
with samples drawn uniformly from the because the algorithm is a sample of the public

1234
01:20:52,350 --> 01:20:57,690
rejected draw sample is underneath the we keep it and we have a sample

1235
01:21:05,280 --> 01:21:10,630
this is this is pretty general the only technical requirement is that

1236
01:21:10,640 --> 01:21:13,060
you need to be able to bound

1237
01:21:13,100 --> 01:21:17,830
this function because you need to build construct this thing will be above it everywhere

1238
01:21:19,720 --> 01:21:23,140
the problem with really is it seems a bit wasteful because you do all this

1239
01:21:23,140 --> 01:21:26,480
computation and then if you have a rejection you just sort of straight away you

1240
01:21:26,480 --> 01:21:32,180
get nothing from it and potentially you can spend most of your computer time just

1241
01:21:32,180 --> 01:21:32,900
sort of

1242
01:21:32,910 --> 01:21:37,770
computing these functions and then doing nothing with the computation answering

1243
01:21:37,780 --> 01:21:42,990
so this the trick that means that you never have to reject samples if you

1244
01:21:43,290 --> 01:21:46,660
if you're in regime where you can't draw samples from the distribution you want to

1245
01:21:46,680 --> 01:21:48,970
but you can draw from some of the distribution

1246
01:21:48,980 --> 01:21:52,610
important something is the trick that allows you to just sample from the distribution you

1247
01:21:52,610 --> 01:21:54,520
actually want to instead

1248
01:21:56,120 --> 01:22:00,710
you have an integral to solve this is what we want to estimate and we

1249
01:22:00,710 --> 01:22:04,520
multiply by q which is the distribution we can sample from and we divide like

1250
01:22:04,520 --> 01:22:07,980
you say this is just multiplying by one as long as we never divide by

1251
01:22:08,970 --> 01:22:11,710
and so this is an identity

1252
01:22:11,720 --> 01:22:15,440
and now this is just an integral which is an expectation on the key and

1253
01:22:15,450 --> 01:22:18,360
the function of the whole object here

1254
01:22:18,380 --> 01:22:22,530
so now we just apply simple monte carlo we sample from here and we evaluate

1255
01:22:22,530 --> 01:22:25,890
the rest of the underground

1256
01:22:25,950 --> 01:22:30,140
and what's nice about this trick is actually

1257
01:22:30,210 --> 01:22:33,340
you're integral to need to be an expectation in the first place you'll notice here

1258
01:22:33,340 --> 01:22:36,110
that nothing about this relied on

1259
01:22:36,120 --> 01:22:42,290
p hitting distribution i think FP together being integral into ground that just sticks together

1260
01:22:42,290 --> 01:22:45,560
you can do that with any underground wouldn't have to be an expectation

1261
01:22:55,120 --> 01:23:00,850
so that's the that's a great question how do you choose q say i've said

1262
01:23:00,880 --> 01:23:04,500
you can choose any q like one that you can draw a sample from the

1263
01:23:04,610 --> 01:23:09,930
song as we don't divide by zero so the technical requirement but

1264
01:23:09,970 --> 01:23:14,790
it's probably clear that some cues are gonna work much better than others and so

1265
01:23:14,850 --> 01:23:18,850
the sort of the question of why and how we might say

1266
01:23:18,900 --> 01:23:21,170
i mean

1267
01:23:21,190 --> 01:23:24,780
if we had an input space and

1268
01:23:24,840 --> 01:23:26,760
this was that true distribution

1269
01:23:26,770 --> 01:23:30,550
and you know we're interested in the average of some function which run

1270
01:23:30,570 --> 01:23:33,200
run through the space is well then clearly

1271
01:23:33,220 --> 01:23:37,270
if we pick the distribution had most of its mass over here then sample theta

1272
01:23:37,280 --> 01:23:40,380
here i'm going to tell us much about the expectation of this function under the

1273
01:23:41,870 --> 01:23:47,450
say were going to want to distribution that has mass in much the same place

1274
01:23:49,560 --> 01:23:51,960
something else you want to really avoid is

1275
01:23:52,020 --> 01:23:57,780
making q small when p is big say for example imagine what a variational if

1276
01:23:57,780 --> 01:24:01,120
you know about variational approximations what they would do is

1277
01:24:01,130 --> 01:24:04,560
find mode seeking to that defended against an approximation to this

1278
01:24:04,590 --> 01:24:09,750
under some cost function i would physicality and around the tightest made

1279
01:24:09,770 --> 01:24:13,160
now that means and very rarely gonna get samples over here

1280
01:24:13,170 --> 01:24:15,410
so now if i do

1281
01:24:15,460 --> 01:24:17,780
very occasionally you'll get sample here

1282
01:24:17,840 --> 01:24:21,140
and now evaluate the importance of the sample

1283
01:24:21,140 --> 01:24:24,220
an important if p and q

1284
01:24:24,230 --> 01:24:27,200
OK so now in the tail of the gas in q is

1285
01:24:27,210 --> 01:24:28,380
really small

1286
01:24:28,400 --> 01:24:32,820
and p is quite big and the importance of the sample ends up being

1287
01:24:32,870 --> 01:24:38,450
absolutely enormous and so that means that in this empirical from my sample

1288
01:24:38,460 --> 01:24:42,870
maybe one of the terms will be hugely bigger than any the others infected drawn

1289
01:24:42,870 --> 01:24:44,190
one sample

1290
01:24:44,400 --> 01:24:48,510
say what you want to do is constructed distribution

1291
01:24:48,530 --> 01:24:53,760
roughly covers the distribution and make sure that it never really small where there is

1292
01:24:53,760 --> 01:24:56,620
appreciable amounts of mass it's fine to have

1293
01:24:56,620 --> 01:25:00,850
UK distribution have to tell whether a name as because you're just occasionally get sample

1294
01:25:00,850 --> 01:25:02,740
out there and give it no weight and

1295
01:25:02,770 --> 01:25:05,670
the wasted do that but nothing blows up

1296
01:25:16,500 --> 01:25:22,090
so the question is in rejection sampling we sample from the song distribution and sometimes

1297
01:25:22,090 --> 01:25:22,710
you say

1298
01:25:22,750 --> 01:25:26,690
o we sample here too often because our q is a key compared to piece

1299
01:25:26,690 --> 01:25:31,540
all thrown out and here we just after rejecting because we downweighting the bit but

1300
01:25:31,540 --> 01:25:33,830
it looks much the same and

1301
01:25:33,880 --> 01:25:37,850
it's just slightly more efficient in that it soft so if we are not interested

1302
01:25:37,850 --> 01:25:42,000
in the samples themselves were interested enough expectation then

1303
01:25:42,020 --> 01:25:44,140
its lower variance too

1304
01:25:44,140 --> 01:25:47,950
attach real numbers every single sample you've got to make a hard decision if i'm

1305
01:25:47,950 --> 01:25:51,570
going to wait the sample by zero one so if you compute the variance of

1306
01:25:51,570 --> 01:25:54,010
the estimator this turns out to be more efficient

1307
01:25:54,040 --> 01:25:58,180
the new these

1308
01:26:00,910 --> 01:26:02,870
there's a huge huge huge

1309
01:26:02,880 --> 01:26:06,280
which is what we call

1310
01:26:07,980 --> 01:26:13,450
so if we can bound the function so the biggest thing and we know

1311
01:26:13,460 --> 01:26:17,440
the extent of it we could just have a top hat like that if

1312
01:26:17,480 --> 01:26:21,240
if p with something like calcium as infinite

1313
01:26:21,240 --> 01:26:24,790
the uniform distribution would have to go out and then it would be improper we

1314
01:26:24,790 --> 01:26:28,920
can touch actually sample from that the right if the distribution has compact support then

1315
01:26:28,920 --> 01:26:33,240
you know maybe from distribution would find it depends on the problem sometimes you have

1316
01:26:33,270 --> 01:26:37,310
clever tricks way you know really tight bounds of the function in some places and

1317
01:26:37,330 --> 01:26:41,050
they're also adaptive rejection sampling algorithms that sort of conforms

1318
01:26:41,100 --> 01:26:44,300
a really good approximation for you on the fly

1319
01:26:56,990 --> 01:27:01,420
on the previous slide i assume that we could evaluate both p and q

1320
01:27:01,460 --> 01:27:05,520
and that's not actually always true say

1321
01:27:05,520 --> 01:27:09,050
I could see what was the best way

1322
01:27:09,090 --> 01:27:13,250
so the question is how to find these images and I cannot puzzled about that

1323
01:27:13,250 --> 01:27:14,480
for quite a while

1324
01:27:14,860 --> 01:27:22,740
and then as a colander holiday do it I I solve Lord of the pattern

1325
01:27:22,810 --> 01:27:27,360
and I saw the connection between these

1326
01:27:27,640 --> 01:27:33,620
equation these equations with matrices carotene

1327
01:27:33,860 --> 01:27:40,840
and these equations with these differential equations that we looked at in a later lecture

1328
01:27:40,860 --> 01:27:46,330
so the differential equations the differential equation that we looked at was

1329
01:27:49,280 --> 01:27:54,390
what's the connection of minus so was the connection between the differential equation the left

1330
01:27:54,390 --> 01:27:56,010
side and these matrices

1331
01:27:58,000 --> 01:28:02,740
but see these matrices are in words what what kind of matrices are we seeing

1332
01:28:02,740 --> 01:28:07,800
what we're seeing a typical role of these matrices minus 1 to n minus 1

1333
01:28:07,800 --> 01:28:12,140
and yeah and what that those 3 numbers for jumps to mind when I see

1334
01:28:12,140 --> 01:28:13,660
those 3 numbers

1335
01:28:13,680 --> 01:28:16,010
it's a 2nd difference

1336
01:28:16,130 --> 01:28:18,980
where here we have a 2nd derivatives

1337
01:28:19,050 --> 01:28:23,220
and we have a minus sign actually

1338
01:28:23,240 --> 01:28:28,070
a minus sign here to the the true 2nd difference would be 1 minus 2

1339
01:28:28,090 --> 01:28:33,480
1 and we've strikes which those OK now

1340
01:28:37,360 --> 01:28:43,360
what that I had several of wasted to approach the inverse solutions because the question

1341
01:28:43,360 --> 01:28:44,430
of the universe

1342
01:28:44,780 --> 01:28:48,930
and so let me that really take easier 1 1st

1343
01:28:49,680 --> 01:28:54,260
it to say how did we get to the inverse of that

1344
01:28:54,280 --> 01:28:56,070
and and the way

1345
01:28:56,780 --> 01:29:00,490
a good way to get to the inverse of that is starting with the of

1346
01:29:00,490 --> 01:29:04,100
course we gotta get there course every we can check it that works but that

1347
01:29:04,100 --> 01:29:07,050
doesn't seem quite fair so

1348
01:29:07,890 --> 01:29:08,690
let me

1349
01:29:08,740 --> 01:29:11,920
I take that matrix

1350
01:29:12,010 --> 01:29:14,300
and factory

1351
01:29:14,360 --> 01:29:20,240
remember how it factors so so of the concentrate T for just a minute to

1352
01:29:20,240 --> 01:29:25,720
give a direct way to deal with the effect to be slightly repetitions that that

1353
01:29:25,720 --> 01:29:26,440
matrix T

1354
01:29:27,660 --> 01:29:29,930
factored into

1355
01:29:29,990 --> 01:29:34,130
like all all good matrices factored into

1356
01:29:34,190 --> 01:29:37,130
upper trying here we did elimination

1357
01:29:37,190 --> 01:29:43,480
we ended up with some upper triangular you and the lowered it turned out to

1358
01:29:43,480 --> 01:29:46,740
be you transpose you it turned out to be

1359
01:29:46,780 --> 01:29:51,430
I don't know if it's best to look at them again

1360
01:29:51,490 --> 01:29:56,810
you transpose you will you ones on the diagonal pivotal all turned out to be

1361
01:29:56,820 --> 01:30:00,250
ones and minus ones just above

1362
01:30:00,300 --> 01:30:06,250
and then it's transposes ones on the diagonal and minus 1 is just below

1363
01:30:07,890 --> 01:30:10,810
if I multiply those matrices

1364
01:30:10,860 --> 01:30:11,810
I guess

1365
01:30:12,510 --> 01:30:13,550
the alright

1366
01:30:14,140 --> 01:30:20,080
so that the idea was OK maybe we can invert those pieces

1367
01:30:20,130 --> 01:30:22,010
and we can

1368
01:30:22,050 --> 01:30:28,450
so let's now we're now so that was T then the inverse was

1369
01:30:28,480 --> 01:30:29,430
the inverse of you

1370
01:30:30,200 --> 01:30:34,080
times the inverse of you transport

1371
01:30:34,100 --> 01:30:37,980
and so if I now want to invert this guy and put it here

1372
01:30:38,040 --> 01:30:41,570
0 my god

1373
01:30:43,990 --> 01:30:46,130
what's the

1374
01:30:47,190 --> 01:30:49,390
what's the inverse of this 1

1375
01:30:49,430 --> 01:30:52,430
let me make it be fill out it's

1376
01:30:52,450 --> 01:30:54,110
I want there's you

1377
01:30:54,180 --> 01:30:56,740
so I wanna put its inverse comes 1st

1378
01:30:56,890 --> 01:31:01,220
so what we've done this before but do you remember what the inverse look like

1379
01:31:01,220 --> 01:31:04,980
0 I have here a trying upper triangular matrix

1380
01:31:04,990 --> 01:31:08,340
so what can you tell me about its inverse

1381
01:31:09,370 --> 01:31:11,280
upper triangular

1382
01:31:13,110 --> 01:31:18,310
this is the difference matrix and its inverse will just be some matrix

1383
01:31:19,340 --> 01:31:23,110
this is what turned out to be the inverse

1384
01:31:23,220 --> 01:31:31,910
and then there's inverse of that was there transpose so it's now

1385
01:31:31,940 --> 01:31:34,340
some now

1386
01:31:40,200 --> 01:31:42,740
so that that's all quite

1387
01:31:42,980 --> 01:31:44,860
quick to check

1388
01:31:45,110 --> 01:31:46,000
I mean

1389
01:31:47,100 --> 01:31:51,840
even more quickly here but it would be quick to check and that gives us

1390
01:31:51,840 --> 01:31:56,840
our answer right what I take it if I do the multiplication of find the

1391
01:31:58,270 --> 01:32:04,320
I just gotta multiply those guys OK I get from that is that a good

1392
01:32:06,440 --> 01:32:12,120
and that times the next 1 gives me 3 1 produces the 3 then the

1393
01:32:12,580 --> 01:32:18,010
than the 1 that road times that column will be the 3 here I get

1394
01:32:18,010 --> 01:32:19,100
this formula

1395
01:32:19,170 --> 01:32:21,700
no problem with the

1396
01:32:23,220 --> 01:32:24,130
so that's right

1397
01:32:25,380 --> 01:32:28,620
so I I guess I fill it with the we

1398
01:32:28,880 --> 01:32:33,990
could legitimately say yes we know only got the discovered the universe we

1399
01:32:34,760 --> 01:32:37,130
found system that produces

1400
01:32:37,170 --> 01:32:40,030
now I change over to

1401
01:32:40,060 --> 01:32:41,840
it was not so easy

1402
01:32:42,840 --> 01:32:43,820
this method

1403
01:32:46,630 --> 01:32:51,320
triangular factors but their inverses will take a little patience

1404
01:32:51,340 --> 01:32:56,720
not led to but they're quite quite attractive still but then multiplying the 2 factors

1405
01:32:56,720 --> 01:32:58,990
together takes even more pictures

1406
01:32:59,010 --> 01:33:02,960
so I would like to think of another way

1407
01:33:02,990 --> 01:33:08,720
to deal with inverse so this is really my principal job how to deal with

1408
01:33:09,880 --> 01:33:13,700
1 way would be the triangular factors invert them multiplied by

1409
01:33:14,320 --> 01:33:15,170
but to

1410
01:33:15,250 --> 01:33:22,390
somehow we're not wouldn't really see what was happening here OK so now

1411
01:33:22,600 --> 01:33:27,020
now so now I can decay

1412
01:33:27,090 --> 01:33:28,440
right now I have to

1413
01:33:28,480 --> 01:33:31,650
2 approaches decay

1414
01:33:32,060 --> 01:33:34,440
today was easy

1415
01:33:38,660 --> 01:33:40,600
so 1 approach

1416
01:33:44,630 --> 01:33:46,770
OK and they tell you 1 approach that

1417
01:33:47,320 --> 01:33:51,170
well that I'm that I'll describe a little bit but then it will be an

1418
01:33:51,370 --> 01:33:57,630
important step in the Kalman filtering updating least squares so it sort of links to

1419
01:33:58,270 --> 01:34:00,410
last topic on my

1420
01:34:02,710 --> 01:34:07,110
that this is this occurred to me on the airplane actually

1421
01:34:07,320 --> 01:34:13,880
what's the difference between well 1st of all let me that just look at the

1422
01:34:13,960 --> 01:34:19,320
figure out what the difference I to compare the inverses of T k

1423
01:34:21,370 --> 01:34:23,990
that if I compare

1424
01:34:23,990 --> 01:34:26,660
you don't have to let's suppose we do for simplicity

1425
01:34:26,710 --> 01:34:28,260
let's assume

1426
01:34:28,270 --> 01:34:30,790
that for each class separately

1427
01:34:32,120 --> 01:34:38,020
the distribution of images and blood factorizes so the independent so what that it says

1428
01:34:38,030 --> 01:34:41,820
it is practical the people who have cancer

1429
01:34:41,890 --> 01:34:46,310
then the variation in images amongst the cancer people in the variation in there

1430
01:34:46,330 --> 01:34:50,460
blood results are independent of each other and have a look at all the people

1431
01:34:50,460 --> 01:34:52,070
who are normal

1432
01:34:52,090 --> 01:34:56,700
they also have the same property the variation images the variation in blood tests are

1433
01:34:56,700 --> 01:34:58,110
independent of each other

1434
01:34:58,150 --> 01:35:02,690
obviously if i combine them together they're not going to be independent because

1435
01:35:02,700 --> 01:35:06,630
you know the the people have cancer will have certain kind of images kind of

1436
01:35:06,630 --> 01:35:11,700
blood test people at normal have different kind so the population in general they won't

1437
01:35:11,700 --> 01:35:15,540
be independent which is going to see the independent for each class separately so that's

1438
01:35:15,540 --> 01:35:18,110
our assumption

1439
01:35:18,130 --> 01:35:21,540
and that correspond to the slammer graphs says that

1440
01:35:21,580 --> 01:35:24,920
as we think of as in the generative model we say there is some probability

1441
01:35:24,920 --> 01:35:26,370
that you have cancer

1442
01:35:26,390 --> 01:35:29,110
described by this note if you have cancer

1443
01:35:29,120 --> 01:35:34,340
then there's some distribution of possible images that that's associated with you and the some

1444
01:35:34,340 --> 01:35:39,190
distribution of possible blood tests and equal if you don't have cancer this some different

1445
01:35:39,190 --> 01:35:44,820
distribution of images and of blood tests but each of those classes separately these are

1446
01:35:44,820 --> 01:35:46,000
independent so

1447
01:35:46,040 --> 01:35:51,210
as mentioned the separation yesterday if we look at the if you look at the

1448
01:35:51,210 --> 01:35:55,210
polls in this in this very simple graph those apart from this node up here

1449
01:35:55,670 --> 01:35:59,970
to this node on the path it goes through this node in this node is

1450
01:36:00,200 --> 01:36:03,630
what we call it tells tale note because the arrows pointing away from the node

1451
01:36:03,830 --> 01:36:07,410
and that node is observed so if that the d separation

1452
01:36:07,470 --> 01:36:13,330
grew slides even had yesterday this is no blocks that path causes these to be

1453
01:36:13,450 --> 01:36:18,420
independent if we don't observe this if this node is not shaded then the path

1454
01:36:18,420 --> 01:36:21,260
is not blocked and they're not independent

1455
01:36:21,320 --> 01:36:23,420
so this seems like a reasonable assumption

1456
01:36:23,480 --> 01:36:24,830
to make

1457
01:36:24,890 --> 01:36:26,860
and so

1458
01:36:26,880 --> 01:36:32,000
what we interested in then is the probability of cancer once you've observed the image

1459
01:36:32,000 --> 01:36:34,300
data and the blood data

1460
01:36:34,300 --> 01:36:38,420
and from bayes theorem we can write that is the prior probability times the likelihood

1461
01:36:39,250 --> 01:36:43,540
now we can use our assumption factorizations factorize this

1462
01:36:43,590 --> 01:36:48,380
and now if we multiply and divide by p of ck and then use bayes

1463
01:36:48,380 --> 01:36:49,840
theorem again the other way

1464
01:36:49,860 --> 01:36:54,040
what we have is is this so this is the proper posterior probability of cancer

1465
01:36:54,040 --> 01:36:58,000
given the image data that was one of the engines we built two years ago

1466
01:36:58,020 --> 01:37:02,540
now along came these new blood tests so we built a new engine

1467
01:37:02,590 --> 01:37:06,110
inference engine gives probability of cancer given the blood tests

1468
01:37:06,130 --> 01:37:08,960
and we can combine it with the

1469
01:37:09,110 --> 01:37:14,860
image data simply by multiplying the posterior probabilities and dividing by the priors

1470
01:37:14,880 --> 01:37:20,070
and of course that's a rather simple example of combining two modules together using probabilities

1471
01:37:20,070 --> 01:37:24,610
are sort of common currency of courses in the framework of graphical models we can

1472
01:37:24,610 --> 01:37:29,770
build much more complex models and build lots of different modules and combining together i

1473
01:37:29,770 --> 01:37:30,650
showed you

1474
01:37:30,690 --> 01:37:33,480
it's actually very complex example in the asthma

1475
01:37:33,500 --> 01:37:38,520
the study which was my first few graph today in fact

1476
01:37:38,540 --> 01:37:40,570
OK so lots of advantages too

1477
01:37:40,570 --> 01:37:42,320
to using probabilities

1478
01:37:42,320 --> 01:37:46,070
i think i move on to slightly different topic that any questions

1479
01:37:46,110 --> 01:37:50,520
band think we've covered so far but

1480
01:37:53,540 --> 01:37:55,690
it is

1481
01:37:55,790 --> 01:37:58,880
probably not

1482
01:37:58,880 --> 01:38:00,150
right OK so

1483
01:38:00,170 --> 01:38:04,960
dmitri there's two separate question the question what is your machine bridge causes real probabilities

1484
01:38:04,960 --> 01:38:09,270
in some sense what would you what would you do with the peaceful one thing

1485
01:38:09,270 --> 01:38:12,630
to say is that if you are going to associate

1486
01:38:12,630 --> 01:38:16,960
subscribe to feeds out of wiki like give me

1487
01:38:16,960 --> 01:38:21,230
all the papers written by a certain person certain topic areas and in the system

1488
01:38:21,230 --> 01:38:27,150
just i want my RSS reader to pick it up and really be informed and

1489
01:38:27,320 --> 01:38:31,360
the other stuff so we are right now britain and the active project on having

1490
01:38:31,360 --> 01:38:35,820
more export formats so i call was one of the new ones are created hours

1491
01:38:35,820 --> 01:38:41,440
as we also create weak another expert from this kind of data came out data

1492
01:38:41,440 --> 01:38:48,060
for geographical data so those are very specific export formats just showing that

1493
01:38:48,110 --> 01:38:52,040
we have to semantics in the background to understand what the pages are about you

1494
01:38:52,040 --> 01:38:55,920
can exported in the form today used by industry so that she was spread the

1495
01:38:55,920 --> 01:38:56,940
outset tools

1496
01:38:57,060 --> 01:38:59,730
so one of the nice things i hope i can show you that later on

1497
01:38:59,730 --> 01:39:02,230
semantic that there are are few

1498
01:39:02,290 --> 01:39:08,210
let's try this out right now

1499
01:39:08,230 --> 01:39:11,460
so this is an article about the park and i hope i will have access

1500
01:39:11,460 --> 01:39:14,070
one now this is the

1501
01:39:14,090 --> 01:39:19,590
events listed decide the upcoming events that next on the list of quasars in manchester

1502
01:39:19,630 --> 01:39:25,590
first during ESWC starting today with several supplements like this is the same as surgeons

1503
01:39:25,610 --> 01:39:31,610
on LDP's brain it's been two weeks than experts and so on so this is

1504
01:39:31,610 --> 01:39:33,650
directly big information

1505
01:39:33,670 --> 01:39:35,000
if you click here

1506
01:39:35,000 --> 01:39:38,790
you can subscribe to that i kind of feel

1507
01:39:38,800 --> 01:39:40,130
two years

1508
01:39:40,150 --> 01:39:42,420
outlook for example

1509
01:39:42,460 --> 01:39:43,960
another way to

1510
01:39:43,960 --> 01:39:49,090
half that

1511
01:39:49,090 --> 01:39:50,980
let's hope it loads

1512
01:39:51,020 --> 01:39:55,920
so what's happening here is actually that i have created google calendar it's taking the

1513
01:39:55,940 --> 01:39:59,320
i calendar information out of to be keep

1514
01:39:59,340 --> 01:40:06,290
and displaying the who can get which again i can integrate it in HTML page

1515
01:40:07,170 --> 01:40:11,690
well i have been so this is not the same information that we have to

1516
01:40:11,790 --> 01:40:16,150
just taking the i can export in this plane and the nice can

1517
01:40:16,170 --> 01:40:19,840
so we see the ESWC starting today is going to find

1518
01:40:19,840 --> 01:40:21,900
i get probably you knew that already

1519
01:40:21,920 --> 01:40:24,880
first a sorry

1520
01:40:24,900 --> 01:40:30,250
here we have yet invents direct thing the deadline several conferences so we have on

1521
01:40:30,250 --> 01:40:31,730
the content the

1522
01:40:31,790 --> 01:40:34,400
rules conference coming up

1523
01:40:35,880 --> 01:40:39,940
so this this one of those nice hx school calendar which is we just go

1524
01:40:39,940 --> 01:40:43,130
to the next month this information there and so on and so on

1525
01:40:53,460 --> 01:40:55,900
it was about

1526
01:40:55,920 --> 01:40:59,900
yes the semantic media wiki is pretty bad product right now

1527
01:40:59,920 --> 01:41:01,980
so one of their

1528
01:41:02,000 --> 01:41:07,170
goals we have set ourselves for active project but we don't promise anything this area

1529
01:41:07,400 --> 01:41:09,610
is that we are also able

1530
01:41:09,610 --> 01:41:15,480
to change information and to add information from an external source so week is much

1531
01:41:15,480 --> 01:41:17,610
much better about that we are

1532
01:41:19,630 --> 01:41:21,960
so OK

1533
01:41:25,920 --> 01:41:30,190
so we don't promise that but we hope to achieve that there are several problems

1534
01:41:30,190 --> 01:41:33,900
of them in the media wiki system

1535
01:41:33,940 --> 01:41:39,230
but we hope to somehow solve the problem is actually

1536
01:41:39,320 --> 01:41:42,730
this is a

1537
01:41:43,360 --> 01:41:45,570
well known

1538
01:41:45,940 --> 01:41:48,880
go one

1539
01:42:00,630 --> 01:42:03,980
if you have great ideas about it so everyone discuss much as because this is

1540
01:42:03,980 --> 01:42:06,980
one of the things we really have problems of solving it's the

1541
01:42:07,630 --> 01:42:12,670
the major problem is just to illustrate why we're not having this right now is

1542
01:42:12,670 --> 01:42:14,730
that in semantic media mediawiki

1543
01:42:14,790 --> 01:42:16,690
every annotation

1544
01:42:16,690 --> 01:42:19,040
it is based on the wiki text

1545
01:42:19,110 --> 01:42:24,130
and this human readable and you edit the wiki text and now have about this

1546
01:42:24,130 --> 01:42:30,120
and then you will uncover so that's good falls new it's very simple it can

1547
01:42:30,140 --> 01:42:34,800
extremely fast because you have the part of the fuzzy is no problem

1548
01:42:34,880 --> 01:42:40,460
the point is that the real problem with this with this same type of BBC

1549
01:42:40,520 --> 01:42:46,750
is the poets it's what's inside channel can cannot can make it out of the

1550
01:42:46,750 --> 01:42:48,120
reach detector

1551
01:42:48,160 --> 01:42:50,600
there's a number of children with this kind

1552
01:42:52,330 --> 01:42:56,750
flash flash ADC where in fact you put two

1553
01:42:56,880 --> 01:43:03,040
flash one for the which we take the most significant bit and the other one

1554
01:43:03,040 --> 01:43:07,560
which became the only thing you can then you have to make the grid so

1555
01:43:07,760 --> 01:43:12,530
have the typical performances four to ten bits can go up to one million out

1556
01:43:12,540 --> 01:43:19,280
you are using less because you have left left the number of combined actually less

1557
01:43:19,280 --> 01:43:23,030
than the previous and so you see for instance for fourth place for which would

1558
01:43:23,030 --> 01:43:24,650
be in a bit

1559
01:43:24,650 --> 01:43:28,540
you will have thirty comparators instead of two and five

1560
01:43:28,600 --> 01:43:31,010
but then were

1561
01:43:31,040 --> 01:43:34,260
you have to to treat you as you have some

1562
01:43:34,270 --> 01:43:38,420
some of the literature which are tricky to be done but that's not something which

1563
01:43:38,420 --> 01:43:40,490
is quite

1564
01:43:40,560 --> 01:43:45,710
often use them very often uses the pipeline ADC upipeline ADC is there's something which

1565
01:43:46,770 --> 01:43:51,900
collect and which is calculating when beta tells the story starts with this saying is

1566
01:43:51,900 --> 01:43:56,650
the signal in the first half of and also one half and then to use

1567
01:43:56,650 --> 01:43:59,790
the most significant bit and then use the talk

1568
01:43:59,990 --> 01:44:05,050
the services that you and you continued like that until the so so the point

1569
01:44:05,290 --> 01:44:09,490
is that you you have some time between the input and the availability of the

1570
01:44:09,490 --> 01:44:11,650
output which is

1571
01:44:11,660 --> 01:44:15,470
and time is a number of stage

1572
01:44:15,490 --> 01:44:19,650
you save a lot of people also settled in our local and you can still

1573
01:44:19,650 --> 01:44:24,050
be quite fast for instance you can get twenty to fourteen years for something like

1574
01:44:24,090 --> 01:44:25,780
two hundred one

1575
01:44:25,800 --> 01:44:27,450
it's quite

1576
01:44:28,530 --> 01:44:33,160
successive approximation and that's also something quite simple it's just that you

1577
01:44:33,160 --> 01:44:42,320
you you have you make delta converter on the new you just sweep this and

1578
01:44:42,530 --> 01:44:47,600
you just make some did that input to your that can you compare the output

1579
01:44:47,600 --> 01:44:49,940
of the input

1580
01:44:49,950 --> 01:44:54,170
and when it's equally says that's it you can get

1581
01:44:54,260 --> 01:44:57,890
resolution of the order of ten to twenty feet in in out conduction sometimes is

1582
01:44:57,890 --> 01:45:00,900
quite long for a very long

1583
01:45:00,920 --> 01:45:02,280
which is

1584
01:45:02,300 --> 01:45:03,590
which is

1585
01:45:03,600 --> 01:45:06,830
already later concerns come back to that

1586
01:45:06,970 --> 01:45:11,660
and francis is of something

1587
01:45:11,660 --> 01:45:14,120
well something that

1588
01:45:14,140 --> 01:45:19,080
the thing is that you we have seen that we have this quantization their

1589
01:45:19,290 --> 01:45:23,040
when when we make an agency

1590
01:45:23,040 --> 01:45:27,810
and then if if you are indices is

1591
01:45:27,830 --> 01:45:34,270
it is somewhat similar to frequency of switches sampling we not

1592
01:45:34,350 --> 01:45:38,930
then the is useful frequency of the signal

1593
01:45:38,970 --> 01:45:44,450
then what you can do is is to destroy the american villages that so and

1594
01:45:44,450 --> 01:45:48,330
then there is no quantization noise will just use

1595
01:45:48,330 --> 01:45:49,560
quite a lot

1596
01:45:49,580 --> 01:45:54,500
because you will just take the partition the which is the fraction of you if

1597
01:45:54,640 --> 01:45:57,330
want to that over sampling ADC

1598
01:45:57,330 --> 01:46:05,910
which which would using the noise ratio again for and indeed the four and indeed

1599
01:46:06,020 --> 01:46:11,700
the if you sample you can increase the the signal to noise ratio

1600
01:46:11,730 --> 01:46:17,140
and that's the phi function of the sampling frequency with respect to you

1601
01:46:17,160 --> 01:46:19,790
because if continue interested in

1602
01:46:19,790 --> 01:46:23,350
and you see that for instance you could go from an eight bit ADC two

1603
01:46:23,350 --> 01:46:27,560
it would be reasonable sampling of two hundred and fifty so if you want to

1604
01:46:27,560 --> 01:46:31,140
know if you have an eight bit ADC which is able to learn at twenty

1605
01:46:31,220 --> 01:46:35,640
and you will get it will be that when you get it back to shifts

1606
01:46:35,700 --> 01:46:37,490
so that

1607
01:46:37,490 --> 01:46:41,680
that's a good thing in fact then based on that you've got to see that

1608
01:46:41,680 --> 01:46:45,710
the ABC so i'm not going to detail about what is important to know is

1609
01:46:45,710 --> 01:46:47,640
that with this kind of

1610
01:46:47,660 --> 01:46:52,470
then you can you very very good resolutions up to twenty four bits which is

1611
01:46:53,160 --> 01:46:55,930
immediately good but

1612
01:46:56,020 --> 01:46:57,430
the question

1613
01:46:57,430 --> 01:47:00,310
the of something which is quite high

1614
01:47:00,370 --> 01:47:04,350
so there are a number of formulas fuzzy dice

1615
01:47:04,660 --> 01:47:09,390
important thing for the ADC when you have something you else known is is the

1616
01:47:09,390 --> 01:47:13,950
shannon doing that you probably you know which is which says that

1617
01:47:13,970 --> 01:47:16,640
when you when you samples

1618
01:47:16,660 --> 01:47:18,680
this signal

1619
01:47:18,680 --> 01:47:21,230
you can see that can be removed

1620
01:47:21,240 --> 01:47:25,310
in an inner product

1621
01:47:25,330 --> 01:47:28,850
in the first of its input space in two dimensions

1622
01:47:28,870 --> 01:47:29,890
input space

1623
01:47:29,900 --> 01:47:31,070
with the

1624
01:47:31,080 --> 01:47:33,510
the scalar product of x

1625
01:47:33,520 --> 01:47:34,910
and ex-prime

1626
01:47:34,920 --> 01:47:36,560
and you just have to square

1627
01:47:36,570 --> 01:47:39,370
with the square of this quantity you get

1628
01:47:40,620 --> 01:47:41,970
scalar product

1629
01:47:41,980 --> 01:47:43,980
in the feature space

1630
01:47:44,690 --> 01:47:46,320
this is very nice

1631
01:47:46,330 --> 01:47:48,060
it means that

1632
01:47:48,070 --> 01:47:49,390
if i need

1633
01:47:49,410 --> 01:47:51,190
some projects

1634
01:47:51,190 --> 01:47:53,170
in the in the

1635
01:47:54,770 --> 01:48:02,140
i can use the competition not in this three-dimensional space but again the competition is

1636
01:48:02,940 --> 01:48:04,790
two two-dimensional

1637
01:48:04,800 --> 01:48:06,930
it could input space

1638
01:48:08,340 --> 01:48:14,120
just to give you some notation my powerpoint slides are

1639
01:48:14,140 --> 01:48:20,230
all slides that i've previously is changed so that only people point sources for air

1640
01:48:20,290 --> 01:48:27,800
so so it's not really nice but can get used see we

1641
01:48:27,810 --> 01:48:30,680
so that we have a continuum and that was

1642
01:48:30,690 --> 01:48:32,170
for the cat in

1643
01:48:36,230 --> 01:48:38,400
OK so now what you can say

1644
01:48:38,440 --> 01:48:44,480
it is only can we generalize this idea here and you can imagine that you

1645
01:48:44,480 --> 01:48:47,080
have some number

1646
01:48:47,870 --> 01:48:52,920
you can consider all the polynomial of the from the scalar product of x and

1647
01:48:52,920 --> 01:48:53,990
x y

1648
01:48:54,050 --> 01:48:56,690
the power of n

1649
01:48:56,720 --> 01:49:01,520
the game you will you will be able to compute

1650
01:49:01,540 --> 01:49:06,310
so by definition you will be able to compute the

1651
01:49:06,360 --> 01:49:10,350
it's kind of product not but move

1652
01:49:10,410 --> 01:49:12,310
in this case again

1653
01:49:12,360 --> 01:49:16,730
this competition will correspond to some function phi

1654
01:49:16,780 --> 01:49:22,180
the function phi fact maps into the space not sitting down to the space spanned

1655
01:49:22,180 --> 01:49:27,560
by the by all the products of the input direction so you are going to

1656
01:49:27,560 --> 01:49:32,520
use this idea and made yes but of all the

1657
01:49:33,550 --> 01:49:38,550
so this is a nice example of the transformation

1658
01:49:38,590 --> 01:49:43,140
but if you look at at

1659
01:49:43,180 --> 01:49:44,840
dimension of the space

1660
01:49:44,850 --> 01:49:50,320
in fact it's very large and if you consider that was input space you have

1661
01:49:51,080 --> 01:49:52,440
same dimension d

1662
01:49:52,670 --> 01:49:54,190
and end

1663
01:49:54,200 --> 01:49:55,570
is four

1664
01:49:55,580 --> 01:49:57,170
off you

1665
01:49:57,240 --> 01:49:59,260
if you come across

1666
01:49:59,300 --> 01:50:03,850
then you have to do the dimension of s goals as the

1667
01:50:03,940 --> 01:50:07,560
the core of and so it's is a we week

1668
01:50:07,570 --> 01:50:10,440
huge space we are using here

1669
01:50:11,470 --> 01:50:14,170
at the low cost because we're using

1670
01:50:14,270 --> 01:50:17,440
as this scalar product in fact it

1671
01:50:17,480 --> 01:50:21,820
the input space so this is a nice example

1672
01:50:21,860 --> 01:50:23,860
when you get it can

1673
01:50:24,650 --> 01:50:28,370
has a very complex there we

1674
01:50:28,420 --> 01:50:34,670
it also action which gives you a very nice representation of x that you have

1675
01:50:34,670 --> 01:50:37,470
not the complexity of computations

1676
01:50:41,220 --> 01:50:46,040
so we define space of higher dimension was the classification problem is easier so of

1677
01:50:46,040 --> 01:50:51,190
course what we want to know is what does the functions of value for x

1678
01:50:51,240 --> 01:50:52,540
x y that

1679
01:50:52,550 --> 01:50:54,670
verify the nice property

1680
01:50:54,680 --> 01:50:59,490
to be returned as inner products in some newer presentation space

1681
01:50:59,690 --> 01:51:03,360
because if we are able to deal with such function

1682
01:51:03,420 --> 01:51:08,430
then we will be able to compute inner product this

1683
01:51:08,440 --> 01:51:09,840
eventually huge

1684
01:51:09,850 --> 01:51:14,320
this is a huge feature space

1685
01:51:14,460 --> 01:51:16,720
we use some function

1686
01:51:16,730 --> 01:51:19,110
OK so here's the function

1687
01:51:19,120 --> 01:51:23,530
it was the function

1688
01:51:23,560 --> 01:51:28,050
was this character products causes the function in fact you can get

1689
01:51:28,070 --> 01:51:33,290
it is this kind of approach no looking going to look it was

1690
01:51:33,330 --> 01:51:38,900
the class of functions that low to have this kind of presentation

1691
01:51:38,910 --> 01:51:41,040
it's kind cool

1692
01:51:42,730 --> 01:51:47,320
so these functions are called positive this defeated candidates

1693
01:51:47,370 --> 01:51:54,460
and in fact semi definite positive comments but as i have

1694
01:51:54,520 --> 01:51:59,890
i noticed here usually people just forget this

1695
01:51:59,910 --> 01:52:02,650
so imagine you have a function k

1696
01:52:04,120 --> 01:52:06,800
cartesian product of x phi x

1697
01:52:06,830 --> 01:52:09,260
that go to air

1698
01:52:09,310 --> 01:52:12,980
this function is called the positive definite came in

1699
01:52:12,990 --> 01:52:16,440
there are there is the following property

1700
01:52:16,690 --> 01:52:20,790
four for any n stereo two zero

1701
01:52:20,840 --> 01:52:25,680
for any choice of objects x one to x n

1702
01:52:25,770 --> 01:52:28,700
in in

1703
01:52:28,810 --> 01:52:30,060
set x

1704
01:52:30,070 --> 01:52:32,720
and for any choice of real numbers

1705
01:52:32,720 --> 01:52:40,150
about the student using my university la sapienza OK this is the data about a

1706
01:52:40,150 --> 01:52:44,850
about the engineering courses in particular in

1707
01:52:44,980 --> 01:52:50,130
actually we have only fragments of the database and the

1708
01:52:51,170 --> 01:52:57,390
the database contains essentially the data of the students from a ninety to ninety eight

1709
01:52:57,390 --> 01:53:04,640
OK so you will not colonized student because we have anonymized

1710
01:53:04,640 --> 01:53:06,420
this unit u

1711
01:53:06,440 --> 01:53:09,070
you may recognise the name of some professor

1712
01:53:09,070 --> 01:53:13,120
but please forget them when you walk out of the k

1713
01:53:16,470 --> 01:53:21,150
OK so here you see there are a lot of relations OK

1714
01:53:21,310 --> 01:53:25,440
a lot of relation and let's look at the map is OK so first i

1715
01:53:25,440 --> 01:53:26,840
want to show

1716
01:53:26,880 --> 01:53:31,480
some easy mapping OK so let's look at the mapping for students

1717
01:53:31,500 --> 01:53:34,290
for students

1718
01:53:34,300 --> 01:53:37,250
OK so this is the mapping for student you see

1719
01:53:39,220 --> 01:53:41,560
you see here

1720
01:53:42,580 --> 01:53:46,230
what i'm doing

1721
01:53:47,340 --> 01:53:48,610
you see here

1722
01:53:48,620 --> 01:53:50,130
i have

1723
01:53:50,210 --> 01:53:57,220
a in this case we give people OK is simply says take the identifier from

1724
01:53:57,230 --> 01:53:59,060
these relation over here

1725
01:53:59,060 --> 01:54:01,700
OK and this state

1726
01:54:01,780 --> 01:54:07,910
is the concepts you ontology OK the consisted ontology and the

1727
01:54:11,150 --> 01:54:13,580
you see that we use this should be

1728
01:54:13,590 --> 01:54:16,910
OK so this is really divide OK after existing

1729
01:54:16,940 --> 01:54:19,800
it we get out of the people carry

1730
01:54:19,800 --> 01:54:21,160
and we use it

1731
01:54:21,190 --> 01:54:25,050
to generate a new object OK this call

1732
01:54:25,050 --> 01:54:28,150
students all over that article about

1733
01:54:28,890 --> 01:54:34,560
that particular what this is about the way then a this term is completely out

1734
01:54:34,560 --> 01:54:36,140
OK we don't kill

1735
01:54:36,150 --> 01:54:37,880
OK so this is just

1736
01:54:38,790 --> 01:54:40,740
object identifier

1737
01:54:40,760 --> 01:54:46,690
of the particular student in the relational database of cases they objectify using the ontology

1738
01:54:46,690 --> 01:54:48,110
for that particular

1739
01:54:48,150 --> 01:54:52,910
for for the student in this in this in this table

1740
01:54:52,930 --> 01:54:55,200
OK so

1741
01:54:55,220 --> 01:54:59,660
this is a very nice marking OK so one relation with just one people to

1742
01:54:59,680 --> 01:55:05,540
we put it in a way we use it to generate object in the in

1743
01:55:05,550 --> 01:55:06,840
the student

1744
01:55:06,860 --> 01:55:12,370
concept of class about all these things are not so nice so we always so

1745
01:55:12,370 --> 01:55:14,650
let me look at the

1746
01:55:14,710 --> 01:55:16,710
let me look at the

1747
01:55:18,920 --> 01:55:21,000
OK so

1748
01:55:21,790 --> 01:55:25,150
this is the same shape OK located is really

1749
01:55:25,170 --> 01:55:32,360
over the database OK it's clear the database we extracted one of the activity particularly

1750
01:55:32,390 --> 01:55:33,340
the code

1751
01:55:33,350 --> 01:55:34,850
OK we use

1752
01:55:34,870 --> 01:55:37,130
the code to generate

1753
01:55:37,150 --> 01:55:43,030
the upset of for professional OK this is the output of the corresponding to be

1754
01:55:43,060 --> 01:55:45,180
OK by the way at the same time

1755
01:55:45,200 --> 01:55:46,630
i'm also

1756
01:55:46,630 --> 01:55:47,540
and also

1757
01:55:47,560 --> 01:55:50,700
put in some instances in the end of

1758
01:55:50,750 --> 01:55:52,150
a property

1759
01:55:52,170 --> 01:55:55,330
OK that i can capture from this

1760
01:55:55,340 --> 01:55:59,590
from this quickly now i want you to look at this is quickly

1761
01:55:59,600 --> 01:56:02,050
OK so this is a very nasty

1762
01:56:02,070 --> 01:56:03,290
it's quite quickly

1763
01:56:03,310 --> 01:56:05,170
OK if he and

1764
01:56:06,650 --> 01:56:11,860
in this database this is an operational database we recognise a professional has the been

1765
01:56:12,510 --> 01:56:15,280
because it is this field

1766
01:56:15,320 --> 01:56:16,640
put that now

1767
01:56:16,660 --> 01:56:18,870
OK so that it is now

1768
01:56:18,880 --> 01:56:21,080
they used to be

1769
01:56:21,840 --> 01:56:25,320
so you can make sense out of this thing you have to talk with people

1770
01:56:25,320 --> 01:56:28,580
that database to understand how you

1771
01:56:28,600 --> 01:56:32,540
you might be OK this is always like that

1772
01:56:32,550 --> 01:56:36,630
that databases that in operation OK so these are not you know in are not

1773
01:56:36,640 --> 01:56:44,060
nine databases for doing ontologies area databases and activities that ability since the seventies OK

1774
01:56:44,060 --> 01:56:48,780
in in the years stratification of the open and this is really about

1775
01:56:49,470 --> 01:56:54,120
by the way notice also that they need a regular expression over a stream

1776
01:56:54,710 --> 01:56:56,180
i understand

1777
01:56:56,220 --> 01:56:57,680
these guys in the

1778
01:56:57,690 --> 01:57:02,640
a is the dean of loss of yeah OK i have to look at this

1779
01:57:02,870 --> 01:57:06,960
OK inside this thing to notice so this is very nasty

1780
01:57:07,840 --> 01:57:12,370
OK so now let's look at the face of

1781
01:57:14,590 --> 01:57:17,590
so we get profits

1782
01:57:17,630 --> 01:57:20,130
we get professor at the same time we get also

1783
01:57:20,140 --> 01:57:23,930
from what you want to actually we are interested only in those profits colours are

1784
01:57:23,940 --> 01:57:31,860
being so we essentially take this perfection out of a these people are professional here

1785
01:57:32,860 --> 01:57:38,230
so let me let me see also assistant a assistant professor

1786
01:57:38,260 --> 01:57:41,130
he is the assistant associate professor

1787
01:57:41,840 --> 01:57:46,610
as a professional actor in another table OK after this is a different database OK

1788
01:57:46,610 --> 01:57:48,570
these are only professor

1789
01:57:48,740 --> 01:57:52,480
a professor by the way

1790
01:57:52,510 --> 01:57:55,750
we don't have all information in particular we don't even know

1791
01:57:55,760 --> 01:58:00,990
o what a what university OK although most of them will be of so is

1792
01:58:02,290 --> 01:58:03,620
so you see now

1793
01:58:03,640 --> 01:58:05,740
that i'm using

1794
01:58:05,750 --> 01:58:11,410
OK by the way i know that this professor not decided so i can use

1795
01:58:11,430 --> 01:58:13,840
i can generate object in an easy way

1796
01:58:13,850 --> 01:58:17,670
OK for both of them so for this guy i think the cold

1797
01:58:17,700 --> 01:58:22,470
out of the stable for this guy technical about of these other people OK

1798
01:58:22,480 --> 01:58:26,780
offaly this should work and now let me see state

1799
01:58:27,420 --> 01:58:29,400
i mean

1800
01:58:29,430 --> 01:58:32,140
i think it's by some provinces

1801
01:58:32,180 --> 01:58:34,250
yeah this one

1802
01:58:35,880 --> 01:58:37,440
so this is

1803
01:58:37,500 --> 01:58:40,870
this this property over here

1804
01:58:40,870 --> 01:58:42,540
so the students

1805
01:58:42,550 --> 01:58:50,830
it's been advised for the graduation essentially got students what is being advised for by

1806
01:58:51,250 --> 01:58:53,090
the professional game

1807
01:58:53,100 --> 01:58:57,150
and actually i do we get this pervasive is professor called when i actually get

1808
01:58:57,150 --> 01:59:00,760
the professor got from the face OK and i have to

1809
01:59:00,790 --> 01:59:05,340
you see this we again is nasty because in the table advice so i don't

1810
01:59:05,340 --> 01:59:09,470
have to call it but i was so i have a it with degree in

1811
01:59:09,470 --> 01:59:12,420
which i don't have to call the face of the they just the first name

1812
01:59:12,460 --> 01:59:15,600
last name so i made up the code on the fly

1813
01:59:15,620 --> 01:59:19,870
OK and by the way i can think this professor out of

1814
01:59:19,880 --> 01:59:25,120
their professional debut all the perfect so that they so these are the assistant professors

1815
01:59:26,160 --> 01:59:31,740
so i see i have a union of two conjunctive queries over here

1816
01:59:31,750 --> 01:59:35,830
OK so let me show these are the ones and this is the last one

1817
01:59:35,840 --> 01:59:38,130
they are good enough OK


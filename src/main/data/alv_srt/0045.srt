1
00:00:00,000 --> 00:00:02,110
we should stop

2
00:00:02,130 --> 00:00:06,830
so before you make an announcement before

3
00:00:06,840 --> 00:00:09,060
the very top today

4
00:00:09,120 --> 00:00:13,010
so the instrument is the

5
00:00:13,030 --> 00:00:16,800
however a feedback for online

6
00:00:17,930 --> 00:00:22,790
the rest of the feedback form is you just go to the home page

7
00:00:22,800 --> 00:00:26,890
of the summer school new that slash feedback

8
00:00:26,930 --> 00:00:29,770
so the price is right there you just go to

9
00:00:29,790 --> 00:00:31,880
o pages slash feedback

10
00:00:31,890 --> 00:00:34,280
well it's very much appreciated

11
00:00:35,480 --> 00:00:37,940
for the support

12
00:00:46,120 --> 00:00:49,270
the plenary talks today begin by man

13
00:00:49,620 --> 00:00:51,170
and this from

14
00:00:51,190 --> 00:00:52,730
call to action

15
00:00:53,590 --> 00:00:55,340
subject of the

16
00:00:56,660 --> 00:00:58,380
matrix completion

17
00:00:58,470 --> 00:00:59,880
there are convex

18
00:01:02,730 --> 00:01:06,940
OK so thank you very much

19
00:01:06,950 --> 00:01:10,140
so had already three hours and a half

20
00:01:10,260 --> 00:01:14,690
a course of lectures of the convex optimisation guy and you have

21
00:01:14,700 --> 00:01:16,450
one more power now

22
00:01:16,980 --> 00:01:20,660
so don't blame me blame the organizers

23
00:01:22,140 --> 00:01:25,060
all rights are going to talk about something new today we're going to talk about

24
00:01:25,060 --> 00:01:26,810
exact matrix completion

25
00:01:26,830 --> 00:01:31,520
i will try to present some theory in some algorithms

26
00:01:31,530 --> 00:01:36,620
OK alright so before i get started i just want to

27
00:01:36,670 --> 00:01:41,200
to say a few words about why is it that we're setting this problem

28
00:01:41,220 --> 00:01:43,000
so i drive

29
00:01:43,000 --> 00:01:45,810
i live very far away from my workplace and so when i go to work

30
00:01:45,810 --> 00:01:47,780
and the center's radio

31
00:01:47,810 --> 00:01:52,280
and one day i was listening to NPR and they talked about the netflix prize

32
00:01:52,280 --> 00:01:54,200
which i got interested in

33
00:01:54,500 --> 00:01:59,090
so i ssume that everybody is familiar with netflix although we have some international students

34
00:01:59,090 --> 00:02:04,220
who are the people who don't know what netflix

35
00:02:04,230 --> 00:02:08,410
if you a few people so netflix is a company that is renting out movies

36
00:02:08,410 --> 00:02:12,930
so you you go online and you are you order movies and then they come

37
00:02:12,930 --> 00:02:14,000
through the mail

38
00:02:14,010 --> 00:02:17,070
and then once you're done watching them you just returned

39
00:02:17,750 --> 00:02:21,150
and so netflix is a very large company that has

40
00:02:21,500 --> 00:02:26,120
about a million users at the moment and they're running out something like about twenty

41
00:02:26,120 --> 00:02:27,910
five thousand movies

42
00:02:27,930 --> 00:02:30,160
and typically once you

43
00:02:30,160 --> 00:02:35,310
you you rent movies you receive emails from netflix so when you go on the

44
00:02:35,310 --> 00:02:37,570
website asking you to write movies

45
00:02:37,760 --> 00:02:42,440
and so we have a large database and netflix is assembling a very large database

46
00:02:42,440 --> 00:02:47,290
that contains about a million users and has about twenty five thousand movies and people

47
00:02:47,290 --> 00:02:49,410
rate is movies

48
00:02:49,430 --> 00:02:52,720
and so the netflix has the database that looks like this is looks very much

49
00:02:52,720 --> 00:02:58,160
like what rafi was discussing yesterday or you have columns are movies

50
00:02:58,160 --> 00:03:01,780
rules are users and users rate movies

51
00:03:02,940 --> 00:03:08,710
and so a typical feature of this matrix it's set extremely sparsely sampled beacon on

52
00:03:08,710 --> 00:03:11,530
on average users with great i don't know

53
00:03:11,540 --> 00:03:16,530
out of the twenty five thousand movie they will rate fifty to one hundred movies

54
00:03:16,530 --> 00:03:19,410
and so you have very few entries available

55
00:03:19,430 --> 00:03:21,780
about this matrix

56
00:03:21,810 --> 00:03:25,500
and yet what netflix would like to do is we would like to complete this

57
00:03:25,500 --> 00:03:28,340
matrix that they would like to be able to

58
00:03:29,690 --> 00:03:33,070
complete the matrix that is predict the

59
00:03:33,090 --> 00:03:38,370
movies that user has not rated or movie that the user has not seen and

60
00:03:38,380 --> 00:03:41,470
they would like to do this for very obvious reason that is if i could

61
00:03:41,470 --> 00:03:44,690
predict the preferences of

62
00:03:44,710 --> 00:03:48,160
of a manual for movies that he has not seen then i would be able

63
00:03:48,160 --> 00:03:50,490
to do very efficient advertising

64
00:03:50,500 --> 00:03:52,690
and so of course in the modern economy

65
00:03:52,750 --> 00:03:57,750
it's extremely important as we purchase more and more things online is very important for

66
00:03:57,750 --> 00:04:04,280
companies which operate on line to be able to make targeted recommendations because in the

67
00:04:04,280 --> 00:04:08,010
old days you would go to a bookstore and then you'd find books on the

68
00:04:08,010 --> 00:04:11,650
shelves and you will browse through them in you bible stories but now nobody goes

69
00:04:11,650 --> 00:04:13,320
to bookstores anymore

70
00:04:13,340 --> 00:04:16,740
it is very important for amazonian for barnes and noble

71
00:04:16,750 --> 00:04:20,830
and so on to be able to recommend books that you might like

72
00:04:20,850 --> 00:04:23,730
so there are many problems of this kind were

73
00:04:23,810 --> 00:04:27,390
users rate their preferences for a few items

74
00:04:27,400 --> 00:04:30,050
and yet the vendor would like to know

75
00:04:30,060 --> 00:04:34,860
their preferences for unrated item so that they can do fish and recommendation

76
00:04:34,880 --> 00:04:38,310
right so you can imagine that amazon has the same problem

77
00:04:38,310 --> 00:04:42,670
paul was selling selling music has the same problem

78
00:04:42,680 --> 00:04:47,260
facebook have similar problems and so on and so forth now all these problems have

79
00:04:47,260 --> 00:04:52,640
the same flavor in machine learning then known under the name of collaborative filtering and

80
00:04:52,640 --> 00:04:56,060
the idea is that perhaps i can borrow information

81
00:04:56,070 --> 00:05:01,320
across users to actually predict my own preferences

82
00:05:01,330 --> 00:05:06,240
OK in statistics is a familiar problem because you can think about this as a

83
00:05:06,240 --> 00:05:09,000
survey of asking questions to people

84
00:05:09,060 --> 00:05:12,760
and people decide not to answer some questions and you'd like to guess

85
00:05:12,820 --> 00:05:16,750
what they would have answered had chosen to answer this question

86
00:05:16,800 --> 00:05:25,070
OK is famous netflix problem and there many of problems where i have partial information

87
00:05:25,070 --> 00:05:29,000
about a large matrix of interest and i want to immediately

88
00:05:29,190 --> 00:05:32,750
i suggest another problem which is global positioning

89
00:05:32,750 --> 00:05:36,420
so here we are in the area of sensor networks for example and there are

90
00:05:36,420 --> 00:05:40,670
points in d dimensional space that we would like to locate

91
00:05:40,690 --> 00:05:42,980
so think about them as sensors

92
00:05:42,990 --> 00:05:47,150
and the sensors what they can do is they can construct a distance estimate

93
00:05:47,190 --> 00:05:50,240
two other senses so there is a matrix m i j

94
00:05:50,240 --> 00:05:51,910
i think that the

95
00:05:51,960 --> 00:05:54,130
so this is the only one in bar

96
00:05:54,140 --> 00:05:56,370
it in vertical position

97
00:05:56,430 --> 00:05:58,650
a hundred and forty nine

98
00:05:58,690 --> 00:05:59,810
o point nine

99
00:05:59,860 --> 00:06:04,420
but i would think that the uncertainty of my measurement is probably one millimeter

100
00:06:04,430 --> 00:06:08,310
i can really guarantee you that i did actually that

101
00:06:08,350 --> 00:06:10,320
so that's the vertical

102
00:06:10,340 --> 00:06:13,150
now we're going to measure the bar

103
00:06:14,280 --> 00:06:16,310
which we have set up here will

104
00:06:16,320 --> 00:06:18,210
OK this news site

105
00:06:18,260 --> 00:06:21,820
know i measure the length of this are

106
00:06:21,870 --> 00:06:24,060
hundred fifty point zero

107
00:06:28,660 --> 00:06:33,580
one hundred fifty one zero again so minus o point one centimeter

108
00:06:33,660 --> 00:06:36,580
so you would agree with me that i am capable

109
00:06:36,630 --> 00:06:42,450
of measuring some minus one millimeter that uncertainty of mine

110
00:06:42,460 --> 00:06:45,130
now if

111
00:06:45,140 --> 00:06:46,990
the difference in length between

112
00:06:47,000 --> 00:06:50,790
lying down and standing up there were one foot

113
00:06:50,800 --> 00:06:53,660
we would all know it wouldn't get out of bed in the morning you lie

114
00:06:53,670 --> 00:06:55,380
down and clunk

115
00:06:55,430 --> 00:06:59,150
u one foot short and we know that's not the case

116
00:06:59,200 --> 00:07:02,080
if the difference only one millimetres

117
00:07:02,090 --> 00:07:04,110
we would never know

118
00:07:04,120 --> 00:07:05,800
therefore i suspect

119
00:07:05,850 --> 00:07:07,960
if my grandmother was right

120
00:07:08,010 --> 00:07:11,440
it is probably only a few centimeters maybe an inch

121
00:07:11,490 --> 00:07:13,890
and so i would argue that if i can measure

122
00:07:13,940 --> 00:07:15,520
the length of the building two

123
00:07:15,530 --> 00:07:17,260
one millimeter accuracy

124
00:07:17,310 --> 00:07:19,780
that's said several issues

125
00:07:19,790 --> 00:07:23,470
so i need to volunteer

126
00:07:23,510 --> 00:07:24,780
you want to volunteer

127
00:07:24,950 --> 00:07:27,280
like very polite hope

128
00:07:27,320 --> 00:07:31,200
i hope we can hope that we don't run out of

129
00:07:31,250 --> 00:07:34,500
not all in one seventy eight so

130
00:07:34,550 --> 00:07:35,760
what's your name

131
00:07:35,770 --> 00:07:37,910
rick rick writer

132
00:07:37,960 --> 00:07:40,440
you know you're right

133
00:07:47,800 --> 00:07:49,930
i can old guys you come up

134
00:07:49,970 --> 00:07:51,040
we need someone

135
00:07:51,060 --> 00:07:53,660
more modest in size

136
00:07:53,740 --> 00:07:56,880
don't take it personal right

137
00:07:58,700 --> 00:08:00,000
what is unique

138
00:08:02,470 --> 00:08:04,070
the exact

139
00:08:04,320 --> 00:08:06,350
if you're right

140
00:08:06,420 --> 00:08:08,090
the first lecture at MIT

141
00:08:08,170 --> 00:08:11,340
i don't know

142
00:08:11,350 --> 00:08:12,920
OK man

143
00:08:12,970 --> 00:08:16,610
and there

144
00:08:16,900 --> 00:08:18,510
eighty three

145
00:08:21,070 --> 00:08:23,720
to they they don't move

146
00:08:25,560 --> 00:08:30,050
and this is the article

147
00:08:30,080 --> 00:08:33,310
what did i say hundred eighty

148
00:08:33,330 --> 00:08:35,690
only one person

149
00:08:38,850 --> 00:08:41,490
come on

150
00:08:41,540 --> 00:08:43,790
o point two OK

151
00:08:43,800 --> 00:08:46,580
on the eighty three points

152
00:08:46,630 --> 00:08:48,710
and the circuitry

153
00:08:48,800 --> 00:08:51,680
are about

154
00:08:51,720 --> 00:08:55,420
one of these centimetres of point one centimeter

155
00:08:55,470 --> 00:08:58,770
now we're going to make him

156
00:08:58,780 --> 00:09:01,700
or is

157
00:09:01,710 --> 00:09:08,030
they're going don't want you to break your bones so we have labels that you

158
00:09:08,040 --> 00:09:11,400
what you see there will be removed part

159
00:09:11,460 --> 00:09:13,130
watch out for this

160
00:09:13,140 --> 00:09:15,250
right that it's all over

161
00:09:15,400 --> 00:09:19,640
OK i'll come on your site i have to do that

162
00:09:23,240 --> 00:09:27,250
think of this as a small sacrifice for the sake of size right

163
00:09:28,330 --> 00:09:30,550
OK you good

164
00:09:30,560 --> 00:09:33,350
you can you comfortable

165
00:09:33,420 --> 00:09:35,590
really conflict right

166
00:09:45,920 --> 00:09:51,190
five point seven you are on eighty five point seven

167
00:09:51,240 --> 00:09:56,530
i'm sure one of the first make traction right on eighty five point seven

168
00:09:56,630 --> 00:10:01,200
is o point one standing

169
00:10:01,290 --> 00:10:06,850
of the five that is point five one minus o point is

170
00:10:06,900 --> 00:10:11,570
about one installer when you sleep and when you stand up my grandmother was right

171
00:10:11,580 --> 00:10:12,790
you always right

172
00:10:12,840 --> 00:10:13,850
get off

173
00:10:13,860 --> 00:10:19,040
i want you to appreciate that the accuracy thank you very much

174
00:10:19,230 --> 00:10:22,200
the accuracy of one millimeter was more than sufficient

175
00:10:22,250 --> 00:10:23,620
to make the case

176
00:10:23,630 --> 00:10:26,950
if the accuracy by measurement would have been much less

177
00:10:27,000 --> 00:10:28,030
this measurement

178
00:10:28,040 --> 00:10:29,910
i wouldn't have been convincing

179
00:10:29,920 --> 00:10:31,190
at all

180
00:10:31,290 --> 00:10:35,110
so whenever you make measurements you must know the uncertainty otherwise

181
00:10:35,160 --> 00:10:37,660
it is meaning less

182
00:10:37,680 --> 00:10:40,090
galileo galilei

183
00:10:40,110 --> 00:10:42,150
as himself the question

184
00:10:43,550 --> 00:10:46,250
mammals as large as they are not

185
00:10:46,360 --> 00:10:49,710
what's large

186
00:10:49,730 --> 00:10:53,000
we had a very clever reasoning which i have never seen in print

187
00:10:53,050 --> 00:10:57,590
what it comes down to the fact that he argued that if the mental becomes

188
00:10:59,540 --> 00:11:01,290
the bones of great

189
00:11:01,340 --> 00:11:04,680
and he thought the that was on limiting factor

190
00:11:04,690 --> 00:11:07,450
even though i've never seen his reasoning in print

191
00:11:07,460 --> 00:11:11,230
i will try to reconstruct what could have gone through his head

192
00:11:12,900 --> 00:11:16,170
is a mammal

193
00:11:16,220 --> 00:11:17,690
and this is the

194
00:11:17,770 --> 00:11:21,070
one of the collective memory

195
00:11:21,120 --> 00:11:22,240
and these memo

196
00:11:22,470 --> 00:11:24,330
as the size

197
00:11:27,400 --> 00:11:29,880
and what i mean by that is

198
00:11:29,930 --> 00:11:31,850
there must be a big

199
00:11:31,870 --> 00:11:33,640
and cat is a

200
00:11:33,650 --> 00:11:35,550
that's what i mean by size

201
00:11:36,280 --> 00:11:38,620
crudely defined

202
00:11:38,650 --> 00:11:39,740
the mass of the

203
00:11:39,750 --> 00:11:41,880
mcmanus and

204
00:11:41,890 --> 00:11:43,880
and this mammals

205
00:11:44,810 --> 00:11:45,730
five o

206
00:11:45,740 --> 00:11:47,020
which we call the female

207
00:11:50,200 --> 00:11:51,350
and a few more

208
00:11:51,360 --> 00:11:54,230
would carries the one large extent

209
00:11:54,280 --> 00:11:57,410
and that's the full assume that the female has a length l

210
00:11:57,460 --> 00:11:59,850
and as the thickness b

211
00:11:59,900 --> 00:12:07,140
there's a few more

212
00:12:07,190 --> 00:12:10,230
this is what if you were approximately like

213
00:12:10,280 --> 00:12:17,650
so this would be the length of the femur

214
00:12:17,670 --> 00:12:19,280
and this would be

215
00:12:21,770 --> 00:12:29,260
and this would be the cross sectional area a

216
00:12:29,310 --> 00:12:31,340
i'm not going to

217
00:12:31,420 --> 00:12:37,190
take you through what we call in physics is failing or

218
00:12:37,200 --> 00:12:39,820
i would argue that the length of the femur

219
00:12:39,850 --> 00:12:41,290
must be proportional

220
00:12:41,300 --> 00:12:44,070
the size of the animal that's completely plausible

221
00:12:44,120 --> 00:12:47,480
if an animal is four times larger than another you would be four times longer

222
00:12:48,260 --> 00:12:50,230
that's all this is a

223
00:12:50,240 --> 00:12:53,500
very recent

224
00:12:53,620 --> 00:12:56,900
it is also very reasonable that the mass of an animal

225
00:12:56,910 --> 00:12:58,600
is proportional

226
00:12:58,610 --> 00:13:00,120
is the power

227
00:13:00,320 --> 00:13:02,020
the size because the

228
00:13:02,070 --> 00:13:03,940
related with volume

229
00:13:04,140 --> 00:13:09,180
so if it's related to the group of the size must also be proportional

230
00:13:09,190 --> 00:13:10,450
the third power

231
00:13:10,470 --> 00:13:12,860
the length of the femur because of this

232
00:13:15,040 --> 00:13:17,580
OK that's why

233
00:13:17,590 --> 00:13:20,880
now comes the argument

234
00:13:23,070 --> 00:13:24,940
on the femur

235
00:13:25,010 --> 00:13:26,800
is proportional

236
00:13:27,010 --> 00:13:29,680
the weight of the animal

237
00:13:29,770 --> 00:13:31,870
divided by the cross section eight

238
00:13:31,880 --> 00:13:33,590
one of the femur

239
00:13:33,600 --> 00:13:35,820
what pressures

240
00:13:35,830 --> 00:13:38,330
and that is the mass of the animal there is proportional to to the the

241
00:13:38,330 --> 00:13:39,770
mass of the animals

242
00:13:39,820 --> 00:13:42,040
divided by the square

243
00:13:42,090 --> 00:13:43,660
because you want every year

244
00:13:43,670 --> 00:13:46,660
fortunately with

245
00:13:46,670 --> 00:13:50,500
now follow me close

246
00:13:50,510 --> 00:13:52,670
if the pressure

247
00:13:52,670 --> 00:13:56,800
things like that so there's about open field which is due to the interoperability which

248
00:13:56,800 --> 00:13:58,530
gives you an ontology

249
00:13:58,550 --> 00:14:03,990
OK so now had the first introduction what is semantic web ontology

250
00:14:04,030 --> 00:14:07,010
will i'll give you a brief glimpse

251
00:14:07,050 --> 00:14:09,170
of what is ontology engineering

252
00:14:09,210 --> 00:14:11,480
how can you support by learning

253
00:14:11,480 --> 00:14:14,460
and what is mine the semantic web

254
00:14:15,440 --> 00:14:20,070
and the energy is and i will only grow very briefly over that because this

255
00:14:20,090 --> 00:14:24,800
manual approach this was the outcome of the so-called knowledge project

256
00:14:24,900 --> 00:14:30,170
and the task was to build some ontology based knowledge management applications for example to

257
00:14:30,170 --> 00:14:36,320
support skills management a large insurance company typical problems if you have a manual approach

258
00:14:36,320 --> 00:14:40,780
there you rely on the knowledge from your domain experts so how can you support

259
00:14:40,780 --> 00:14:46,990
the collaboration between domain experts and knowledge engineers that's ontology engineers and on the other

260
00:14:46,990 --> 00:14:51,860
hand how can you evaluate ontology so these are the the two main problems i

261
00:14:51,860 --> 00:14:52,830
would say

262
00:14:52,900 --> 00:14:56,010
and then we define the methodology

263
00:14:56,050 --> 00:15:01,460
which is a bit too complex for tutorial so in the not so there's process

264
00:15:01,460 --> 00:15:08,920
oriented and cyclic methodology to manually create ontology and you have pre-defined decisions at each

265
00:15:08,920 --> 00:15:10,380
and others that

266
00:15:10,440 --> 00:15:15,300
and you have pre-defined outcomes of the end of that so you know really what

267
00:15:15,300 --> 00:15:19,280
to do was also to make it understandable for industrial people so there we have

268
00:15:19,300 --> 00:15:23,440
to deal with people who had no clue about ontology modelling or modelling at all

269
00:15:23,670 --> 00:15:27,860
and we have to teach them how to build the ontology for their domain

270
00:15:27,900 --> 00:15:33,460
so that was the purpose so this manual approach is now quite well established

271
00:15:33,820 --> 00:15:39,990
we link to further existing methodologies for certain subsets all for example two

272
00:15:40,010 --> 00:15:43,650
well where to draw the line between instances and the schema for example this is

273
00:15:43,650 --> 00:15:48,590
one very common problem also not from the databases there exist some methodologies so there

274
00:15:48,610 --> 00:15:51,340
we for example pointers that

275
00:15:51,340 --> 00:15:57,530
there's a big but the manual approach is very cross it's a very time-consuming task

276
00:15:57,550 --> 00:15:58,610
and especially in industry

277
00:15:59,220 --> 00:16:03,460
you don't have the time and you don't have the money also to maintain always

278
00:16:03,460 --> 00:16:05,510
your resource manually

279
00:16:05,710 --> 00:16:07,630
so what is the idea

280
00:16:07,650 --> 00:16:09,980
well actually use this

281
00:16:10,990 --> 00:16:14,130
is this technology which already exists and expand

282
00:16:14,240 --> 00:16:16,860
armed with semi-automatic support

283
00:16:16,880 --> 00:16:19,610
for example by ontology and instance learning

284
00:16:19,760 --> 00:16:22,840
this will be presented now by my college london

285
00:16:35,840 --> 00:16:44,240
so introduced i tried to in the overview about how can be semi-automatic these

286
00:16:44,260 --> 00:16:50,530
or bring up the the semantic web as well as interviews and

287
00:16:50,550 --> 00:16:52,090
if i start to

288
00:16:52,130 --> 00:16:56,510
all of you you know about them applications might yes

289
00:16:56,610 --> 00:17:03,130
she can support this automatically step by the shortly say something about why only seniority

290
00:17:03,130 --> 00:17:06,480
might not automatically and

291
00:17:06,480 --> 00:17:10,460
the idea of this semi-automatic

292
00:17:10,480 --> 00:17:12,710
is that the problem is that

293
00:17:12,740 --> 00:17:18,840
a lot of technical technical background knowledge experience is in the mind of the people

294
00:17:18,840 --> 00:17:21,210
that's the problem and

295
00:17:21,240 --> 00:17:26,550
that if data to derive all the things that matter to them

296
00:17:26,570 --> 00:17:30,610
we do not need to semantic that you can all recorded in one program and

297
00:17:30,630 --> 00:17:36,460
can automatically derive like this is a step commit to guide the semantic web contact

298
00:17:36,860 --> 00:17:42,340
to to use the the good things the semantic web so the problem is if

299
00:17:42,460 --> 00:17:46,400
we are not able to do all the things that matter and this is important

300
00:17:46,510 --> 00:17:49,110
we want to which is to support

301
00:17:49,150 --> 00:17:52,570
do you as much as possible of meetings

302
00:17:52,840 --> 00:17:57,190
solutions but the decision lies on the people which are modelling of which

303
00:17:57,690 --> 00:18:04,780
the ontology and which food ontology information and that's very important thing which i want

304
00:18:04,780 --> 00:18:12,280
mentioned as i start to say something about automatically derive the government he

305
00:18:12,340 --> 00:18:18,630
derive some information for ontology so very want to stop so you to discovered

306
00:18:18,650 --> 00:18:24,670
that and it's usually start with this is what we have and the idea is

307
00:18:24,710 --> 00:18:32,760
the use of data mining and text mining knowledge discovery techniques on the and

308
00:18:32,760 --> 00:18:36,510
we distinguished three different i

309
00:18:36,530 --> 00:18:45,630
is subsumed under the topic that that mining and one is so-called that content mining

310
00:18:45,670 --> 00:18:54,780
which focus on the content of to content after pages a nominee also mean by

311
00:18:54,780 --> 00:18:58,980
taking text mining on the second step second

312
00:18:58,990 --> 00:19:05,170
idea is to use the structure which had no meanings between ages but exist dealings

313
00:19:05,170 --> 00:19:12,300
between this the picture to use and to derive some knowledge out of this information

314
00:19:12,300 --> 00:19:16,860
and to find out what is an important website not important which are the content

315
00:19:16,900 --> 00:19:18,980
of this information and

316
00:19:19,380 --> 00:19:24,400
drive this information and put them into the ontology

317
00:19:24,440 --> 00:19:26,130
last that is

318
00:19:26,150 --> 00:19:31,240
to have a look and on business application how use US

319
00:19:31,400 --> 00:19:39,090
users go to the vessel day called that use its mining and basis based on

320
00:19:39,130 --> 00:19:41,650
the prices usually

321
00:19:41,670 --> 00:19:47,150
captured by the that and the idea is that we try to follow because it

322
00:19:47,150 --> 00:19:51,280
seems to me on the page and to find out what he is interested in

323
00:19:51,300 --> 00:19:53,280
and maybe to improve some

324
00:19:53,340 --> 00:19:57,980
that site design want to try to give you some advice maybe what i'm interested

325
00:19:57,980 --> 00:20:04,010
in all make some marketing stuff and if we use ontology to you can try

326
00:20:04,010 --> 00:20:06,740
to make it and the analysis that and

327
00:20:06,960 --> 00:20:11,690
and we can put this information on

328
00:20:11,960 --> 00:20:15,110
into the ontology

329
00:20:16,940 --> 00:20:20,960
the idea is all what i want to show now is we have two parts

330
00:20:21,550 --> 00:20:26,050
which we tried to from that we want to go because is that we need

331
00:20:26,070 --> 00:20:34,630
to talk this ontology layer and for this we tried to apply some data-mining techniques

332
00:20:34,760 --> 00:20:39,720
known this ontology so we learned from the semantic web users those that in a

333
00:20:39,720 --> 00:20:44,460
second one is that we need some instances to fill up this knowledge base that

334
00:20:44,460 --> 00:20:47,190
he can after that are some

335
00:20:47,210 --> 00:20:51,820
ah it makes an inference is not so much knowledge so now i come to

336
00:20:51,820 --> 00:20:56,280
london it's going to give you an overview so as i mentioned ontology learning is

337
00:20:56,300 --> 00:21:02,130
in the middle between knowledge discovery data mining and ontology engineering so we have this

338
00:21:02,150 --> 00:21:07,780
manual approach to to bring up the ontology and we have the techniques to derive

339
00:21:07,780 --> 00:21:12,840
some information from data to capture some information from data we have and you think

340
00:21:13,510 --> 00:21:18,380
those ideas together and try to support this manual approach it's much

341
00:21:18,380 --> 00:21:24,910
and one idea which was done by a colleague of mine alexander mitchell in his

342
00:21:24,910 --> 00:21:30,150
well so so there's a term balanced corpus so corpus is a collection of tax

343
00:21:30,170 --> 00:21:34,960
that you can use to do things like estimate probability of balanced corpus one remix

344
00:21:34,960 --> 00:21:38,590
different kinds of text i want to be fair and balanced so i used equal

345
00:21:38,590 --> 00:21:44,630
parts of genesis and the communist manifesto so we get this lovely hundred words like

346
00:21:44,630 --> 00:21:48,100
reactionary so this is the ground

347
00:21:48,220 --> 00:21:53,160
five airline like model so every letter is being generated depending on the previous four

348
00:21:53,710 --> 00:21:54,830
and you see that

349
00:21:54,950 --> 00:21:58,360
we've got to make sure these two kinds of test we can also do this

350
00:21:58,360 --> 00:22:03,460
instead of doing it instead of doing n grams of letters

351
00:22:03,480 --> 00:22:06,950
four and five we could do n grams of words so this is

352
00:22:07,260 --> 00:22:12,150
word try grounds every word is being generated given the previous two

353
00:22:12,200 --> 00:22:15,190
so we have a

354
00:22:15,200 --> 00:22:22,290
let's see

355
00:22:22,450 --> 00:22:26,200
OK right we have here the bourgeoisie keeps more more splitting up into two great

356
00:22:26,200 --> 00:22:30,590
lights the greater light to rule the day

357
00:22:31,920 --> 00:22:36,600
the interests of the conditions of oppression new forms of struggle in place of segment

358
00:22:36,600 --> 00:22:40,330
to the plaintiff or so

359
00:22:40,350 --> 00:22:44,120
yes because of the ground of the same character into one nation

360
00:22:44,170 --> 00:22:47,590
with one government so what happened here we seem to have switched from one kind

361
00:22:47,600 --> 00:22:52,940
of text into another kind of text and the reason is that we have big

362
00:22:52,950 --> 00:22:58,540
great plagues because that's probably from one tax because of could be from either of

363
00:22:58,540 --> 00:22:59,980
the grounds

364
00:22:59,990 --> 00:23:04,990
so so when you get something like that that kind of risk between two tracks

365
00:23:05,010 --> 00:23:09,120
could be generated once once you've got that can't

366
00:23:09,150 --> 00:23:12,110
you might want to generate next work

367
00:23:12,840 --> 00:23:16,680
so we tend to go for a while from one for from one from genesis

368
00:23:16,680 --> 00:23:18,650
and then switch to the companies

369
00:23:18,660 --> 00:23:20,320
or vice versa

370
00:23:20,330 --> 00:23:24,700
OK so why am i doing this this kind of an in fact on my

371
00:23:24,700 --> 00:23:28,720
i first saw this when my freshman roommate in college wrote a program to do

372
00:23:28,720 --> 00:23:30,540
this just for fun

373
00:23:31,830 --> 00:23:36,050
so why this actually be useful so let me show you a little text that

374
00:23:36,050 --> 00:23:37,700
was generated

375
00:23:37,710 --> 00:23:39,680
using a tri gram model

376
00:23:39,700 --> 00:23:43,700
from the core as you might guess that this is a different corpus

377
00:23:43,710 --> 00:23:47,150
what can you tell me about the corpus

378
00:23:51,930 --> 00:23:57,170
well it's not english OK it's not japanese either many and maybe somebody can guess

379
00:23:57,180 --> 00:23:59,570
actually what language

380
00:23:59,610 --> 00:24:02,210
many closer

381
00:24:02,220 --> 00:24:06,630
o very it's actually cause which is closely related to

382
00:24:06,660 --> 00:24:12,030
right to its eventual language of southern africa nelson mandela's native language for example and

383
00:24:12,030 --> 00:24:15,100
you can immediately tell that it's not english because

384
00:24:15,210 --> 00:24:18,090
you know if you look at the number of cues and disease are much too

385
00:24:18,090 --> 00:24:21,830
high for example the number of spaces is too low that's another way of saying

386
00:24:21,830 --> 00:24:24,250
that the words long

387
00:24:24,310 --> 00:24:27,950
after q

388
00:24:27,960 --> 00:24:32,780
well there's no factor q we have a lot of examples

389
00:24:32,800 --> 00:24:35,170
things like you a

390
00:24:35,200 --> 00:24:40,830
right doesn't show very often in english the kudos in english is almost always

391
00:24:41,820 --> 00:24:46,200
it's going to be very very heavily weighted towards the cost that's not true now

392
00:24:46,200 --> 00:24:48,580
this tax over here is a

393
00:24:48,590 --> 00:24:49,740
OK so

394
00:24:49,760 --> 00:24:54,650
even though this is terrible model right this is only a trying model of

395
00:24:54,670 --> 00:24:58,580
this doesn't look very much like english this doesn't look very much like because you

396
00:24:58,580 --> 00:25:03,740
can see there are still good enough you can tell the difference from randomly generated

397
00:25:05,080 --> 00:25:08,180
it might be that there is enough statistics syntax

398
00:25:08,200 --> 00:25:12,710
just looking at these these programs to be able to tell what kind of text

399
00:25:12,710 --> 00:25:13,800
is coming from

400
00:25:13,820 --> 00:25:18,830
here's an example with four nodes

401
00:25:18,960 --> 00:25:22,180
and again you might be able to start to see what the what the text

402
00:25:22,180 --> 00:25:25,030
is if you look at the english

403
00:25:25,050 --> 00:25:29,870
so i don't know what this is where the colours are being

404
00:25:29,900 --> 00:25:33,800
but this comes from the universal declaration of human rights which has been translated into

405
00:25:33,830 --> 00:25:37,460
i think now over four hundred languages it's inspiring

406
00:25:37,480 --> 00:25:38,760
document which

407
00:25:38,790 --> 00:25:40,810
it and to tell everybody in the world

408
00:25:41,240 --> 00:25:43,720
what the basic human rights are even if

409
00:25:43,730 --> 00:25:44,950
there's only

410
00:25:44,960 --> 00:25:49,070
twenty speakers of the language itself

411
00:25:49,170 --> 00:25:50,810
OK so

412
00:25:50,880 --> 00:25:54,100
that's a little motivation for using probability

413
00:25:54,120 --> 00:25:59,630
as we'll will see you can and i have people do this at the beginning

414
00:25:59,630 --> 00:26:00,490
my course

415
00:26:00,510 --> 00:26:06,080
if you're given syntax is not very hard to tell from the statistics of the

416
00:26:06,080 --> 00:26:09,920
tax which letters followed which ones what language it's written and you can do this

417
00:26:10,440 --> 00:26:15,050
given you know very short substring language say ten to twenty years

418
00:26:15,070 --> 00:26:18,980
with the accuracy if you're only trying to distinguish among the few languages if you're

419
00:26:18,980 --> 00:26:22,960
trying to distinguish between say two bantu languages then you might need a little more

420
00:26:22,960 --> 00:26:24,070
tax because

421
00:26:24,080 --> 00:26:27,470
there's little more like and you might need to go until you find a war

422
00:26:28,210 --> 00:26:31,340
some pattern of letters which is common in one of those languages

423
00:26:33,060 --> 00:26:37,950
but as you get more and more text you're just aggregating so one example of

424
00:26:37,950 --> 00:26:42,550
QA maybe you could tolerate in english because maybe you're talking about the country color

425
00:26:45,410 --> 00:26:50,160
if you see a lot of this then you pretty quickly the probability pretty quickly

426
00:26:50,160 --> 00:26:52,170
tip in favor of some

427
00:26:52,200 --> 00:26:56,850
OK so let's switch to talking about

428
00:26:56,870 --> 00:27:00,790
i am i bring a few transparency is back love this afternoon but switched to

429
00:27:00,790 --> 00:27:04,790
talking about about probabilities

430
00:27:04,820 --> 00:27:08,010
so the goals of this lecture the first of all i want you know

431
00:27:08,030 --> 00:27:14,920
really understand what this probability notation means how many people are totally comfortable with this

432
00:27:14,930 --> 00:27:19,500
a majority but only that you so

433
00:27:19,530 --> 00:27:23,750
so what is this expression means how can you sling these things around to be

434
00:27:23,750 --> 00:27:28,440
very comfortable and words its value from

435
00:27:29,740 --> 00:27:34,880
that's the notation and talk about probability models which defines this function so what we

436
00:27:34,880 --> 00:27:39,520
mean by probability model with talking about language identification

437
00:27:39,650 --> 00:27:43,410
so how do we actually do that then how would we evaluate to find out

438
00:27:43,410 --> 00:27:44,780
of the models

439
00:27:44,800 --> 00:27:52,790
i want start with the word about statistics i think the term statistics is misunderstood

440
00:27:53,110 --> 00:27:58,380
because most people are taking statistics courses in college are taking a course that tells

441
00:27:58,380 --> 00:28:00,540
them how to compute means and medians

442
00:28:00,550 --> 00:28:05,510
or if they are in the social sciences they try to find out whether

443
00:28:05,530 --> 00:28:07,890
there's is enough data

444
00:28:08,020 --> 00:28:13,380
in the with enough subjects in the experiments to find out the answer was statistically

445
00:28:13,380 --> 00:28:19,670
significant i'm going to try here too

446
00:28:19,670 --> 00:28:23,540
one slide stops the contrast a little better is that they

447
00:28:25,130 --> 00:28:27,430
there's a problem that the

448
00:28:27,450 --> 00:28:30,970
computers are on the same circuit

449
00:28:31,190 --> 00:28:37,920
as the overhead lights overturn the lights off the the machine that never fixed

450
00:28:37,920 --> 00:28:39,920
it was recognised as negative of course

451
00:28:40,580 --> 00:28:41,950
and there's another one

452
00:28:43,590 --> 00:28:44,490
u markets

453
00:28:45,790 --> 00:28:51,470
there's distrust in your markets despite some rumors involving his be which is supposed to be

454
00:28:53,220 --> 00:28:56,320
and district of course was also recognised as negative

455
00:28:58,530 --> 00:28:59,240
because some more

456
00:29:01,380 --> 00:29:03,270
this district is referring to

457
00:29:03,930 --> 00:29:07,260
post which talks about that spain contributing to

458
00:29:07,830 --> 00:29:09,020
over the top few dept

459
00:29:09,830 --> 00:29:11,650
of course this also negative news so

460
00:29:12,150 --> 00:29:14,220
this it was also recognised as negative

461
00:29:16,150 --> 00:29:18,460
four some positive tweets so that

462
00:29:18,900 --> 00:29:20,360
it only got a new prime minister

463
00:29:21,950 --> 00:29:23,770
this was recognized as a positive thing

464
00:29:24,900 --> 00:29:26,680
apparently the old one wasn't they're good

465
00:29:31,360 --> 00:29:36,810
and another one wear wear william dudley said that she absolutely things that euro will

466
00:29:36,810 --> 00:29:39,220
survive right so the streets of course work

467
00:29:39,600 --> 00:29:40,670
categorized as opposed to

468
00:29:41,660 --> 00:29:43,540
and can you oppose it now so

469
00:29:43,980 --> 00:29:48,450
and i like this one when one of the user says this this sounds to

470
00:29:48,450 --> 00:29:50,670
me like a pump-and-dump scenario right so

471
00:29:51,740 --> 00:29:56,180
get rid of europe because currently it sponsored by these the dudley got

472
00:29:57,430 --> 00:29:59,160
okay so this is the first part of the video

473
00:30:00,130 --> 00:30:02,070
the of the demo and the rest i'll show you

474
00:30:02,610 --> 00:30:03,400
on the slides

475
00:30:07,640 --> 00:30:08,220
great thanks

476
00:30:11,170 --> 00:30:16,110
what you have seen in this video is that we can kind of categorized it into positive and negative right

477
00:30:17,830 --> 00:30:19,810
what we did here in this graph

478
00:30:20,390 --> 00:30:24,140
we collect the tweets about netflix which is the ust company

479
00:30:24,600 --> 00:30:28,650
maybe some of you already heard about it it's a company that streams

480
00:30:29,750 --> 00:30:32,330
thirty programs and shows over the internet

481
00:30:33,230 --> 00:30:35,670
right hand we collected tweets from

482
00:30:38,580 --> 00:30:39,180
to december

483
00:30:40,030 --> 00:30:41,240
about netflix

484
00:30:41,870 --> 00:30:46,420
and we categorize them as positive and negative sentiment and we display the results

485
00:30:47,230 --> 00:30:48,480
like this a long time timeline

486
00:30:49,590 --> 00:30:50,240
right in in

487
00:30:50,540 --> 00:30:51,100
these blue

488
00:30:51,770 --> 00:30:54,670
these blue line shows you the number of positive tweets

489
00:30:55,440 --> 00:30:57,770
the number of tweets that were detected as positive

490
00:30:58,360 --> 00:31:00,150
these red line shows u

491
00:31:00,580 --> 00:31:03,470
the number of tweets that were detected as negative right

492
00:31:04,130 --> 00:31:04,950
and the yellow one

493
00:31:05,480 --> 00:31:09,370
i will tell you the difference between the positive and the negative to its so

494
00:31:09,370 --> 00:31:11,890
if they is above the zero line

495
00:31:12,780 --> 00:31:15,620
which this means that there are more positive than negative

496
00:31:16,000 --> 00:31:18,340
and if it's below it's the other way around

497
00:31:19,930 --> 00:31:23,610
okay so green dots are some events concerning netflix

498
00:31:24,080 --> 00:31:26,430
that we entered into the system manually

499
00:31:27,310 --> 00:31:28,210
and the great

500
00:31:28,360 --> 00:31:31,120
one is the closing daily crawl closing price

501
00:31:31,510 --> 00:31:33,010
so far the netflix stock

502
00:31:34,480 --> 00:31:34,900
okay so

503
00:31:35,630 --> 00:31:37,860
what does this graph tell us

504
00:31:39,700 --> 00:31:40,260
first of all

505
00:31:40,760 --> 00:31:41,360
this kind of

506
00:31:43,050 --> 00:31:44,250
these are the volume peaks

507
00:31:45,440 --> 00:31:46,100
with tell us

508
00:31:46,990 --> 00:31:50,640
that something important happened at this time so people

509
00:31:51,860 --> 00:31:53,180
more than usual talking

510
00:31:53,620 --> 00:31:57,070
about some event concerning netflix or something happened

511
00:31:57,620 --> 00:32:01,220
which is actually true so we can check out some events so this peak here

512
00:32:01,470 --> 00:32:02,660
that we're looking at right now

513
00:32:03,440 --> 00:32:05,330
is the first-quarter earnings release

514
00:32:06,040 --> 00:32:09,560
right so this one here a smaller one but still

515
00:32:10,450 --> 00:32:15,240
netflix was planning to launch its serve it service in in latin america and the

516
00:32:15,240 --> 00:32:17,000
caribbean so this was the big news

517
00:32:18,440 --> 00:32:20,910
this one here for example is when netflix

518
00:32:21,950 --> 00:32:24,180
c last a couple of years

519
00:32:24,680 --> 00:32:26,200
forty shows and movies

520
00:32:26,800 --> 00:32:29,250
and also something called studies deal

521
00:32:29,830 --> 00:32:34,620
i think if i if i remember correctly stars is also one of the networks which

522
00:32:35,590 --> 00:32:41,670
they tried to make a deal so that the netflix would stream there's there are programs over the internet

523
00:32:42,740 --> 00:32:47,640
so you see this is already something useful we are alerted when something big happens

524
00:32:49,930 --> 00:32:52,940
but you can also see that the sentiment right

525
00:32:53,430 --> 00:32:54,470
was pretty positive

526
00:32:54,470 --> 00:32:58,240
of the log probability of data with no information on the log probability of the

527
00:32:58,240 --> 00:33:04,540
data set given parameters and in effect this log p theatre serves as a regularisation

528
00:33:04,540 --> 00:33:06,770
term just as the generalisation error

529
00:33:06,820 --> 00:33:10,030
it was a regularisation term in in discriminative methods

530
00:33:10,040 --> 00:33:14,220
so it serves in effect is an upper bound on the difference that we believe

531
00:33:14,220 --> 00:33:17,250
to be possible between the training and test this

532
00:33:17,290 --> 00:33:22,050
maximum entropy winds up having the same form can be written the same form except

533
00:33:22,050 --> 00:33:25,800
that we we assume we don't know anything at all about p of data we

534
00:33:25,800 --> 00:33:30,800
don't know anything at all about the prior except that the probability density and since

535
00:33:30,800 --> 00:33:35,890
in the space of probability densities those with large entropy on arms are much more

536
00:33:35,890 --> 00:33:37,970
numerous than those with small entropy

537
00:33:37,970 --> 00:33:42,920
we estimate a lot of prior stated to be by the by the entropy of

538
00:33:42,920 --> 00:33:45,260
the probability density implied by

539
00:33:47,340 --> 00:33:51,210
that is the measure of the probability density is with with high entropy is larger

540
00:33:51,210 --> 00:33:56,140
than measure those with low entropy

541
00:33:56,150 --> 00:33:57,070
all right

542
00:33:57,180 --> 00:34:02,720
and then in testing once we learned these parameters we can compute the

543
00:34:02,800 --> 00:34:06,450
i said that given the given the likelihood function you know everything there is to

544
00:34:06,460 --> 00:34:10,260
know you know how to compute the minimum probability of error classifier also know how

545
00:34:10,260 --> 00:34:15,280
to compute the minimum mean square error estimate of y that can be written that

546
00:34:15,280 --> 00:34:19,930
can be computed from all of these intrinsic variables by just marginalizing by summing over

547
00:34:19,930 --> 00:34:23,150
all possible values of the intrinsic variables

548
00:34:24,100 --> 00:34:28,140
in training we use maximum likelihood and testing we use a minimum probability of error

549
00:34:29,960 --> 00:34:36,670
rather than give you use speech recognition examples of hidden markov model i thought i'd

550
00:34:36,670 --> 00:34:38,860
show you something that you may not have seen before

551
00:34:38,880 --> 00:34:42,200
hidden markov models can be used for regression

552
00:34:42,260 --> 00:34:45,320
just as much as they can be used for recognition

553
00:34:45,340 --> 00:34:46,800
here's how

554
00:34:46,810 --> 00:34:52,860
if we if we have the gaussians states each state has if each state says

555
00:34:52,860 --> 00:34:55,550
that the acoustic spectrum is gaussian distributed

556
00:34:55,790 --> 00:35:01,050
then that is as shown here that is the probability of x given the state

557
00:35:01,050 --> 00:35:05,970
variable is the is e to the minus one half

558
00:35:06,010 --> 00:35:11,010
x minus x bar y minus wiper we're now why is real valued vector that

559
00:35:11,010 --> 00:35:13,650
we're trying to estimate

560
00:35:13,720 --> 00:35:17,390
then we compute we can compute the minimum mean square estimate of this real valued

561
00:35:17,390 --> 00:35:22,040
vector by just summing over the posterior probability the states

562
00:35:22,060 --> 00:35:26,990
the linear regression formula this is the linear regression formula that one gets from jointly

563
00:35:26,990 --> 00:35:31,770
gaussian random variables you take the mean value they are pre or mean of y

564
00:35:31,790 --> 00:35:34,250
otherwise vector plus

565
00:35:34,300 --> 00:35:39,420
x minus its pierre mean multiplied by the core the correlation between

566
00:35:39,490 --> 00:35:42,490
between x and y so here's the here's the

567
00:35:42,500 --> 00:35:47,150
linear regression formula for jointly gaussian random variables and we some that over all the

568
00:35:47,150 --> 00:35:52,130
different possible gaussians that might apply to the data weighted by the posterior probability that

569
00:35:52,130 --> 00:35:55,540
that's the correct gaussians this gives us the nonlinear regression

570
00:35:55,550 --> 00:35:59,200
for y given x

571
00:35:59,200 --> 00:36:03,600
that can be extended to a hidden markov model by by including state

572
00:36:03,850 --> 00:36:08,350
so for example we can assume that that x and y are not just jointly

573
00:36:08,350 --> 00:36:11,570
gassing with each other but there are also jointly gaussians with the

574
00:36:11,950 --> 00:36:16,980
the hidden state variable y at the previous time and the result is exactly like

575
00:36:16,980 --> 00:36:22,160
the regression that i showed the previous formula except now the correlation between the correlation

576
00:36:22,160 --> 00:36:27,790
between between x and y depends on is is a function of time depends on

577
00:36:27,790 --> 00:36:32,090
what our current estimate of the of the y variable might be an essentially work

578
00:36:32,100 --> 00:36:38,450
rather than computing rather than computing a weighted sum of linear regression formulas now computing

579
00:36:38,450 --> 00:36:40,750
a weighted sum of common filters

580
00:36:40,800 --> 00:36:46,690
with common soldiers linear regression with parameters updated over time

581
00:36:46,700 --> 00:36:52,410
here's an example of an experiment we did using comparing hmm regression and and

582
00:36:52,830 --> 00:36:55,820
a switching kalman smoother

583
00:36:55,830 --> 00:37:00,010
the results were unfortunately not too compelling so the the the the task was to

584
00:37:00,010 --> 00:37:02,190
try to estimate the position of the tongue

585
00:37:02,340 --> 00:37:04,480
given the acoustic spectrum

586
00:37:04,490 --> 00:37:10,830
so we have a database of we have a database of of tract pellets on

587
00:37:10,830 --> 00:37:16,270
the surface of the tongue and the set of a set of matched acoustic spectra

588
00:37:16,630 --> 00:37:21,080
and we use we use hmm regression that is we assume that there is no

589
00:37:21,110 --> 00:37:26,220
dependence of the current position the articulators on their previous position except as specified by

590
00:37:26,740 --> 00:37:28,590
the state in hidden markov model

591
00:37:28,670 --> 00:37:32,690
and we also use the switching kalman smoother that is we use the bayesian networks

592
00:37:32,690 --> 00:37:35,030
shown in previous page where the

593
00:37:35,050 --> 00:37:40,070
articulators which otherwise depend not only on the current discrete state which is the as

594
00:37:40,070 --> 00:37:41,950
they also depend on the previous

595
00:37:42,000 --> 00:37:47,880
positions of the articulators with the previous the previous why vector and we find a

596
00:37:47,880 --> 00:37:53,300
consistent but extremely small on europe point one millimeter reduction of the the tracking air

597
00:37:53,650 --> 00:37:59,240
using the switching kalman smoother as opposed to using a hidden markov model regression and

598
00:37:59,240 --> 00:38:01,270
that industry would benefit a lot more

599
00:38:01,440 --> 00:38:04,480
even theory will will be more relevant

600
00:38:04,980 --> 00:38:09,080
huge believer that you know that the most fundamental theories

601
00:38:09,390 --> 00:38:10,760
lies in the most

602
00:38:12,590 --> 00:38:16,420
like little details of applications and building systems and things like that

603
00:38:17,530 --> 00:38:21,440
you know great discoveries in science you know probably test that

604
00:38:21,770 --> 00:38:22,670
but you know

605
00:38:23,580 --> 00:38:25,570
you do yourself a favor

606
00:38:25,900 --> 00:38:29,980
and to be much better investment of your very valuable time that are talked about

607
00:38:30,310 --> 00:38:34,400
if you do that phd just later don't we're too long because then you lose your brains

608
00:38:34,580 --> 00:38:41,890
but yeah wrong ok yeah i just wanted to strongly disagree that finally we have

609
00:38:41,910 --> 00:38:47,950
a lot you get object from move from from the floor but

610
00:38:48,550 --> 00:38:55,920
the problems some cetera is that people don't come back to this statistical factor after five years

611
00:38:55,940 --> 00:38:56,550
even after

612
00:38:56,750 --> 00:39:01,560
three years people people just don't come back so you should take might start to

613
00:39:01,580 --> 00:39:03,990
say that you don't learning huge amount like said

614
00:39:04,200 --> 00:39:07,730
but if you leave the program you don't come back again i just said you need to

615
00:39:07,750 --> 00:39:11,820
think through why you want to do it but don't leave was i can always come back

616
00:39:11,910 --> 00:39:16,300
those yeah my master's award for two years and came back

617
00:39:16,470 --> 00:39:25,820
to years to yours yeah i yeah i actually think that making doing a phd

618
00:39:25,840 --> 00:39:29,980
area of data mining it's very helpful for for being a good data scientist

619
00:39:30,410 --> 00:39:36,600
for a for one reason so like when you're doing your phd are pretty much on your old

620
00:39:36,980 --> 00:39:42,590
and that you need to do good research and you need to have your research published

621
00:39:42,890 --> 00:39:45,940
so you're reaching a level of excellence

622
00:39:46,260 --> 00:39:51,570
dad if you have your papers published kdd and that are good venues right

623
00:39:51,740 --> 00:39:55,460
so you have much more confidence in yourself

624
00:39:55,740 --> 00:39:57,340
that you have done this

625
00:39:57,560 --> 00:40:03,080
and it's a small step a each papers small startup yourself right yeah after all it's

626
00:40:03,250 --> 00:40:05,620
yes like an off year of your life

627
00:40:05,800 --> 00:40:09,500
you do you are all experimentation and sell it so you're doing

628
00:40:09,730 --> 00:40:13,930
all from the prototype to marketing after all

629
00:40:14,170 --> 00:40:17,970
once you have done this like to know five to ten times

630
00:40:18,190 --> 00:40:23,560
and your papers got except that and you have allowed a lot of confidence to come to the

631
00:40:23,580 --> 00:40:26,740
industry and say you know what guys i can do it

632
00:40:28,620 --> 00:40:36,720
ok i spent six years getting a phd make sure don't it all

633
00:40:38,300 --> 00:40:43,010
i probably would have been happy doing something else my life but enough time i had and

634
00:40:45,510 --> 00:40:47,720
from that perspective that runcorn app

635
00:40:48,530 --> 00:40:50,670
good data scientists take seasoning

636
00:40:52,350 --> 00:40:55,760
you have to go for the potholes you have to make all mistake

637
00:40:55,990 --> 00:40:59,710
i can even teach you all that mistakes complete

638
00:41:01,070 --> 00:41:05,790
if a stream of masten have taken to data science courses maybe five

639
00:41:06,490 --> 00:41:12,160
you're still going to have to learn off a lot of lessons so from hiring perspective

640
00:41:12,650 --> 00:41:16,190
i like people with a phd exactly for the fact the

641
00:41:16,600 --> 00:41:18,210
staff five years

642
00:41:18,810 --> 00:41:23,720
and they have a certain amount of things of course somebody who wasn't in this five years i guess i even

643
00:41:23,740 --> 00:41:24,200
back up

644
00:41:24,420 --> 00:41:27,850
back you have to start somewhere cell if you have

645
00:41:28,130 --> 00:41:31,300
if you don't have experience for me phd is a

646
00:41:31,610 --> 00:41:32,900
value proposition

647
00:41:33,470 --> 00:41:34,750
as high as a look at them

648
00:41:37,210 --> 00:41:38,330
actually let me let me

649
00:41:39,550 --> 00:41:41,250
jump in as well because i think

650
00:41:41,380 --> 00:41:41,790
there's a

651
00:41:42,110 --> 00:41:46,060
distinction that's generally not made we talk about data scientists these days

652
00:41:46,240 --> 00:41:50,440
right and if you look in companies there are two very different sources where this far

653
00:41:50,450 --> 00:41:51,650
more to it is leased to

654
00:41:51,800 --> 00:41:53,830
very different sorts of data scientists right

655
00:41:53,980 --> 00:41:56,520
people who are essentially what i would call data science engineers

656
00:41:56,920 --> 00:41:58,720
their primary job building things

657
00:41:59,030 --> 00:42:03,270
and there are people who might say are the data science kind of

658
00:42:03,650 --> 00:42:08,630
scientists research but you know their job is pretty much coming up with new ideas

659
00:42:08,840 --> 00:42:11,180
evaluating and so all right

660
00:42:11,360 --> 00:42:12,510
for the former

661
00:42:12,950 --> 00:42:14,830
ph d is a nice to have

662
00:42:16,170 --> 00:42:20,910
for the latter her you know i mean as quality points out i mean they decide doing data

663
00:42:20,930 --> 00:42:22,250
science researchers craft

664
00:42:22,380 --> 00:42:24,290
and just like most of the mature

665
00:42:25,380 --> 00:42:27,840
right the best way to learn it is the apprenticeship

666
00:42:28,180 --> 00:42:30,220
right you can get that apprenticeship by

667
00:42:30,420 --> 00:42:33,490
by pressing with a really good professor

668
00:42:33,790 --> 00:42:37,020
right so just getting a phd where somebody tells you what to do you go to

669
00:42:37,030 --> 00:42:40,190
do is get help got very much having a really good professor

670
00:42:40,350 --> 00:42:41,910
that gives you a good apprenticeship

671
00:42:42,150 --> 00:42:46,400
then leads you to go on to be journeymen data data you know that data

672
00:42:46,420 --> 00:42:47,660
data scientist right

673
00:42:47,880 --> 00:42:53,190
and so i think it's not really just getting a phd right it's do you

674
00:42:53,200 --> 00:42:58,030
get a good apprenticeship you could also get a good apprenticeship not through a phd but

675
00:42:58,040 --> 00:43:03,780
by saying go in your company as a fantastic chief scientist who really mentors her people

676
00:43:03,880 --> 00:43:09,890
yeah so that would be ok so right there are there are other ways to do and i don't

677
00:43:09,910 --> 00:43:13,910
think we should think about it as the label phd whether that's i think the question is

678
00:43:13,930 --> 00:43:15,270
you get a good apprenticeship

679
00:43:15,420 --> 00:43:16,740
such that you can

680
00:43:16,920 --> 00:43:22,300
come up with good ideas design the right ces sums maybe not build them if

681
00:43:22,320 --> 00:43:26,300
you're not put together the right evaluations and so on

682
00:43:27,910 --> 00:43:32,550
ok i'm going to this song of a lot of questions running out

683
00:43:32,560 --> 00:43:36,560
of time i'm going to two sides tom going to ask the age to address this

684
00:43:36,570 --> 00:43:39,090
in point forms just stalled

685
00:43:39,480 --> 00:43:41,150
out points so

686
00:43:43,760 --> 00:43:48,410
what yeah yeah could you work fresh discreetly because

687
00:43:48,710 --> 00:43:52,590
they're clear i can see them but i can see them in mind that they can see them on this

688
00:43:53,570 --> 00:43:59,720
yeah yeah i can allow of ok come on yeah

689
00:44:03,600 --> 00:44:06,460
yeah just specifically or

690
00:44:06,750 --> 00:44:12,330
disallowing this allowed but lodging objections through technology to which you put your objection ended

691
00:44:12,350 --> 00:44:16,370
everybody votes it up i put they yeah

692
00:44:23,230 --> 00:44:26,070
yeah yeah ok

693
00:44:27,200 --> 00:44:32,200
so i'm ok yeah i was fortunate to have been given the first kdd innovation award

694
00:44:32,590 --> 00:44:38,900
like guys as we speak something ok

695
00:44:39,470 --> 00:44:43,100
so i just professed by saying that i have no look you straight

696
00:44:43,590 --> 00:44:45,100
what i'm going to argue why

697
00:44:45,240 --> 00:44:46,910
if you can you should look phd

698
00:44:47,940 --> 00:44:49,120
i know put it

699
00:44:49,250 --> 00:44:50,150
in a start-up

700
00:44:50,570 --> 00:44:51,010
but i would

701
00:44:51,250 --> 00:44:52,040
argue that

702
00:44:52,440 --> 00:44:55,260
if you're trying to what right reason for doing the start

703
00:44:55,660 --> 00:44:57,800
because i have enough friends in the silicon valley

704
00:44:58,190 --> 00:45:00,030
whipping but it's startups

705
00:45:00,490 --> 00:45:02,330
because i just want to cook point

706
00:45:02,780 --> 00:45:06,780
who really to an important point for us to understand why phd

707
00:45:09,600 --> 00:45:11,100
much since the falling that

708
00:45:12,650 --> 00:45:14,480
actually let me start with the start-up thing

709
00:45:14,900 --> 00:45:16,640
if you are going to start a company

710
00:45:16,990 --> 00:45:18,200
to make a million dollars

711
00:45:18,990 --> 00:45:19,940
and testable

712
00:45:20,410 --> 00:45:21,910
then you should know start a company

713
00:45:24,260 --> 00:45:25,440
what you are doing is

714
00:45:25,710 --> 00:45:27,040
you're putting at risk

715
00:45:27,220 --> 00:45:28,440
like full-throttle people

716
00:45:28,820 --> 00:45:31,040
what the company spent five just like that you

717
00:45:31,830 --> 00:45:33,660
and if your goal is to make only money

718
00:45:34,060 --> 00:45:35,260
you know when to use so

719
00:45:36,560 --> 00:45:38,860
you should passionate really doing something

720
00:45:39,030 --> 00:45:40,560
and that you use to construct

721
00:45:42,340 --> 00:45:43,340
it doesn't make sense

722
00:45:43,870 --> 00:45:50,380
thanks talk bush ok yeah ok yeah so i don't simple phd i'll quickly

723
00:45:50,750 --> 00:45:54,190
yeah yeah i think the point to a phd is

724
00:45:55,050 --> 00:45:56,160
to be able to do

725
00:45:57,480 --> 00:45:58,990
that you was capable of doing

726
00:45:59,460 --> 00:46:00,440
in some sense

727
00:46:00,680 --> 00:46:02,530
your to recoup think at the level

728
00:46:03,050 --> 00:46:04,430
that god has given you are

729
00:46:04,880 --> 00:46:05,720
able to do

730
00:46:05,720 --> 00:46:12,170
our feature mapping and we write down our eigen value problem in the feature space

731
00:46:12,570 --> 00:46:17,290
we note that the solutions live in the span of the training data

732
00:46:17,300 --> 00:46:22,390
we can then come up with the dual eigen value problem which is an eigen

733
00:46:22,450 --> 00:46:29,060
value problem for this coefficients which we used to expand the eigenvectors and that eigenvalue

734
00:46:29,060 --> 00:46:32,830
problem will turn out to look like it will be a kernel eigenvalue

735
00:46:32,840 --> 00:46:39,480
problem we just to compute the kernel matrix again it's eigenvalue it's essentially and we have to

736
00:46:39,480 --> 00:46:44,210
normalize them in a certain way but I think I don't have to go through

737
00:46:44,210 --> 00:46:49,190
all details here so once we have found these eigenvectors that dual eigen vectors

738
00:46:49,190 --> 00:46:55,550
this alphas we pluck them into our expression for the eigenvectors now we have

739
00:46:55,550 --> 00:47:00,710
the eigenvectors as kernel expansions in the feature space and we can apply them to

740
00:47:00,720 --> 00:47:04,950
some test point of which we want to extract features or which we want to

741
00:47:04,950 --> 00:47:10,670
project to another dimension subspace to get these values and these values are of course it's

742
00:47:10,670 --> 00:47:14,910
not surprising in view of the representive theorem expansions in terms of the training

743
00:47:14,910 --> 00:47:22,930
points or kernels centered on the training points okay so I think I'm going to skip

744
00:47:22,970 --> 00:47:30,730
this one long well no maybe just briefly so remember at the beginning of today's lecture

745
00:47:30,730 --> 00:47:37,460
I told you if I map a training point or any point to its set of its

746
00:47:37,460 --> 00:47:45,030
similarities to the training set and I perform this pre widening step it's like a

747
00:47:45,030 --> 00:47:52,330
widening step then I get an alternative representation which

748
00:47:52,330 --> 00:47:57,050
if I'm only dealing with the training set is equivalent to the full feautre map

749
00:47:57,050 --> 00:48:00,270
turns out I can also do this with kernel PCA it will give basically

750
00:48:00,270 --> 00:48:06,830
the same so if I project a point on to all the kernel PCA principal

751
00:48:06,830 --> 00:48:16,570
components I get I get something like this which is almost the same

752
00:48:16,570 --> 00:48:22,630
as this quantity where is D is now the diagonalization of K the only difference between this

753
00:48:22,700 --> 00:48:26,950
mapping that I've told you about this morning so I can rewrite it like that so the

754
00:48:26,950 --> 00:48:30,840
difference between this mapping and the projection of the kernel PCA components will be that

755
00:48:30,850 --> 00:48:36,450
this leading unitary matrix U will be dopped but that doesn't make a difference because

756
00:48:36,450 --> 00:48:41,010
if I'm interested in computing dot products unitary matrices don't count of dot products are

757
00:48:41,020 --> 00:48:49,150
invariant under unitary transformations so that's a side remark so here's an example

758
00:48:49,150 --> 00:48:55,290
of what happens if you apply kernel PCA so here we have a data set

759
00:48:55,290 --> 00:48:59,410
I'm not sure you can see is the same data set everywhere it has three clusters

760
00:48:59,420 --> 00:49:05,340
of data points now you can imagine if I did linear principcomponent analysis on

761
00:49:05,410 --> 00:49:10,510
such a data set it wouldn't make much sense maybe and the direction maximum

762
00:49:10,510 --> 00:49:14,470
variance would be something like this and then the second direction would have to be

763
00:49:14,470 --> 00:49:19,710
orthogonal to it because we're working in two-dimensional space in of components are orthogonal

764
00:49:19,720 --> 00:49:25,030
and then that's it so in particular I wouldn't find anything of the cluster structure

765
00:49:25,030 --> 00:49:31,350
now if I do the same thing in the kernel space using a gaussian kernel turns out to

766
00:49:31,360 --> 00:49:36,990
be quite interesting so it turns out that the first feature extraction function so

767
00:49:36,990 --> 00:49:45,090
what I'm showing now here in gray value is the value of the projection of these corresponding

768
00:49:45,090 --> 00:49:51,330
locations in this space on the first second third and so on principal component in

769
00:49:51,330 --> 00:49:56,090
the feature space so I compute the projection in the feature space this corresponds to a non-linear

770
00:49:56,090 --> 00:50:03,050
function input space this nonlinear function is is color-coded here so the first principle component

771
00:50:03,050 --> 00:50:07,250
looks for whether we are in this cluster or this one and ignores this cluster

772
00:50:07,290 --> 00:50:13,150
the second component now more or less ignores the distinction between these two clusters and just

773
00:50:13,150 --> 00:50:19,570
identifies this cluster now the high order components have to look for additional

774
00:50:19,570 --> 00:50:25,030
structure because they are orhogonal to the previous ones orthogonal in the feature space so

775
00:50:25,030 --> 00:50:30,020
this component now looks for structure within this cluster this looks at this cluster and

776
00:50:30,020 --> 00:50:33,290
this looks at the top cluster this looks at the top cluster again but roughly

777
00:50:33,290 --> 00:50:37,080
a little better than most people know less about the so I would like to

778
00:50:37,080 --> 00:50:37,930
talk a little bit more

779
00:50:38,400 --> 00:50:41,160
about their genetic rule over

780
00:50:41,190 --> 00:50:44,990
transmission of information and what better genetics

781
00:50:49,240 --> 00:50:56,620
what we see here are different cell types of in the body of a ship

782
00:50:56,680 --> 00:51:04,800
television the relative and when all of the different cells in our borders on the

783
00:51:04,800 --> 00:51:10,120
whole with some exceptions have the same amount of DNA from sending their Indiana that

784
00:51:10,140 --> 00:51:16,000
very different and the differences between the cells have happened at some point during development

785
00:51:16,100 --> 00:51:18,940
and that once that happened that fixed

786
00:51:20,240 --> 00:51:26,170
I'm pretty Congress when they were when they added divide they bring the British troops

787
00:51:26,170 --> 00:51:33,260
from all punk skin cells when they provided they produce lost themselves so there is

788
00:51:33,260 --> 00:51:39,470
some kind of memory of the functional and structural their state of the service and

789
00:51:39,470 --> 00:51:43,330
we want to understand what this memory is after all the all the stuff that

790
00:51:43,330 --> 00:51:47,950
Indian I wholeheartedly come to be different and how all of this is very important

791
00:51:47,950 --> 00:51:56,170
for us when we're thinking about that worried about inheritance Howell is obvious difference maintained

792
00:51:59,880 --> 00:52:05,160
we understand that this questions were also some something many years ago but there were

793
00:52:05,160 --> 00:52:10,640
no good answers for that and they became a focus of a lot of studying

794
00:52:10,650 --> 00:52:17,670
when the mechanisms that underlies this kind of 7 memory became clear to us and

795
00:52:17,670 --> 00:52:21,780
what we should see is that it is not just the memory within the balding

796
00:52:21,780 --> 00:52:27,740
but that this kind of differences this kind of variations can be transmitted also between

797
00:52:27,740 --> 00:52:30,620
generations soul

798
00:52:30,690 --> 00:52:35,640
we're when we're thinking about 7 memory and about the systems that underlies the memorial

799
00:52:35,640 --> 00:52:43,590
and the inheritance of particular states and the state's morphological physiological state of cells

800
00:52:43,690 --> 00:52:48,740
we can think about several types of picnic in mechanisms

801
00:52:49,090 --> 00:52:53,920
and when we're thinking about that genetics in general with think also about

802
00:52:53,950 --> 00:53:01,540
it other ways of transmitting information which I'm not to send but our also transmitted

803
00:53:01,540 --> 00:53:09,930
through the development of reconstruction behavior and the culture not before mechanism similar mechanisms of

804
00:53:09,930 --> 00:53:16,640
some hereditary of self-sustaining group structural inheritance chromatin marking an army mediated inheritance and I

805
00:53:16,640 --> 00:53:22,360
would say a few words about picture the ourselves sustaining groups what we see here

806
00:53:22,590 --> 00:53:29,270
not to say let things that bacterial cells from their will invariably bit group off

807
00:53:29,270 --> 00:53:36,210
the dark property the regulatory general overdue and they like part is the structural region

808
00:53:36,210 --> 00:53:42,050
which produces approach and here we are in this gene is not up it silent

809
00:53:42,050 --> 00:53:48,290
and this silence there is inherited from 1 generation to the next the rest problem

810
00:53:48,520 --> 00:53:52,740
the gym has no problem and the other for the daughters of also have no

811
00:53:52,740 --> 00:53:58,450
problems and songs so you have the sense of what happened here is that the

812
00:53:58,450 --> 00:54:03,380
led to the creation of the students and that as a result of this kind

813
00:54:03,380 --> 00:54:09,690
of protein product cost for this broadened probe has told functions while function is to

814
00:54:09,690 --> 00:54:15,120
always have some effect on the morphology of itself and the other function is tool

815
00:54:15,130 --> 00:54:20,640
by to the regulatory region here and make the gene are so it produces more

816
00:54:20,640 --> 00:54:26,050
of this problem so this is a positive feedback loop now what happens when there

817
00:54:26,050 --> 00:54:29,540
is a cell divides the products

818
00:54:29,570 --> 00:54:35,550
the proteins are also distributed to the daughters of as a result of this problem

819
00:54:35,840 --> 00:54:41,310
are operated them in the daughter cells and then by the regulatory region as a

820
00:54:41,310 --> 00:54:45,120
result of the person more of the product and sold so we can come to

821
00:54:45,120 --> 00:54:50,340
this time at this point in time and we see blood types of cells cells

822
00:54:50,360 --> 00:54:54,880
which are inactive in cells which are active in the same environment they have exactly

823
00:54:54,880 --> 00:55:01,640
the staging of a British troops help come because something happened in the history of

824
00:55:01,640 --> 00:55:08,120
the cells which made this which in this case created this figure positive feed group

825
00:55:08,300 --> 00:55:14,660
and creative differences which note which consists of generations now this kind of thing is

826
00:55:14,660 --> 00:55:20,380
not true that many examples of this kind of thing if few groups in microorganisms

827
00:55:20,700 --> 00:55:25,260
and without going into detail from here is just 1 example promised not to live

828
00:55:25,260 --> 00:55:31,260
apart from John Candy that becomes a single-celled from John and we know the different

829
00:55:31,260 --> 00:55:37,380
states from all this funnels morphological physiological state of the fund was arming tech can

830
00:55:37,390 --> 00:55:42,220
be maintained for a very long time tool alternative feedback loops

831
00:55:42,280 --> 00:55:48,280
so there was quite a lot of this kind of thing in microorganisms and we

832
00:55:48,280 --> 00:55:52,840
have here and this is what type of every genetic inheritance system 1 type of

833
00:55:52,840 --> 00:55:56,100
every genetic inheritance mechanism

834
00:55:56,120 --> 00:56:06,500
now you probably all had about problems problems of very unpleasant it sometimes is proteins

835
00:56:08,070 --> 00:56:14,380
Our sells completed from and the lead to diseases such as the mad cow disease

836
00:56:14,640 --> 00:56:19,880
not what do we mean by self-proclaimed and how related to sell heredity you know

837
00:56:19,880 --> 00:56:28,540
we have to surface is normal probe normal brought creates this this type of by

838
00:56:28,540 --> 00:56:34,880
putting problems and as a result the of her particular phenotype a particular morphology would

839
00:56:35,040 --> 00:56:42,770
support now the same prompting on that because of all kinds of reasons can form

840
00:56:42,770 --> 00:56:51,520
an alternative three-dimensional structure we don't change anything in the amino acid sequence in which

841
00:56:51,520 --> 00:56:56,380
a it's exactly the same but the way that it is organized a three-dimensional organization

842
00:56:56,380 --> 00:57:02,330
is different from now once this happens in this particular weight at trial is formed

843
00:57:02,330 --> 00:57:10,280
and this program interacts with the norm of confirmation where interrupted when the confirmation he

844
00:57:10,280 --> 00:57:16,160
makes it assumed its own structures so here we have an interruptions and as a

845
00:57:16,160 --> 00:57:16,950
result of that

846
00:57:17,380 --> 00:57:23,830
all of the white becomes becomes a Bronwen a grave and sold so what happens

847
00:57:23,830 --> 00:57:29,120
is that and this is of course inherited from almost division and what we have

848
00:57:29,130 --> 00:57:34,740
in that are cells are all set ourselves which have a probe which have sprung

849
00:57:34,750 --> 00:57:39,920
type of proteins that Protestant would to create fibrosis and as a result of that

850
00:57:39,920 --> 00:57:43,670
they have a different feel and the game we can look at them by it

851
00:57:43,770 --> 00:57:48,830
at cells but say save studies cells in a particular environment that would see the

852
00:57:48,830 --> 00:57:54,420
output of Sulzer 1 Taipei 1 within the time being they have exactly the same

853
00:57:54,420 --> 00:57:59,140
DNA moving in exactly the same environment and yet there are different and the British

854
00:57:59,140 --> 00:58:05,930
troops and this is due to this type of mechanism that to the simple symmetrical

855
00:58:05,930 --> 00:58:08,670
division of the service

856
00:58:08,740 --> 00:58:15,790
and again we have many examples of the same things in front here is 1

857
00:58:15,790 --> 00:58:17,140
example Iast

858
00:58:17,290 --> 00:58:22,090
and what is not about this example is that the experiment that were done by

859
00:58:22,590 --> 00:58:26,740
Susan Lindquist and her group was that they tried to see

860
00:58:26,780 --> 00:58:31,190
whether the different types of cells which are only different in the sense that 1

861
00:58:31,200 --> 00:58:35,330
has the crime and 1 doesn't have the prime whether they will respond to selection

862
00:58:35,760 --> 00:58:40,590
and they do all in 1 environment they did proprietor of those that bulk of

863
00:58:40,590 --> 00:58:43,230
Iteration 3 I think that the 1st 3

864
00:58:43,430 --> 00:58:46,530
and I have to know I have fliers

865
00:58:46,610 --> 00:58:49,220
8 times like 68

866
00:58:50,170 --> 00:58:55,110
again doubling the same things going on with the 2nd quarter and this distance here

867
00:58:55,110 --> 00:59:02,130
you can see by the time you're getting exponentials the minus sign he I think

868
00:59:02,130 --> 00:59:05,750
this is the this is the

869
00:59:06,210 --> 00:59:12,470
in itself but also the associated to a

870
00:59:13,970 --> 00:59:20,530
maybe it was a continuous Fernando donors in the form of

871
00:59:21,310 --> 00:59:24,320
that would explain OK

872
00:59:24,510 --> 00:59:27,990
here here thank you

873
00:59:28,160 --> 00:59:37,740
OK so the convergence rate of the method is quadratic pursuant to these examples of

874
00:59:37,740 --> 00:59:41,910
very nice but let's just the little credit also was 1 drawback

875
00:59:42,570 --> 00:59:47,210
the see and that's what I thought you

876
00:59:47,790 --> 00:59:52,070
yeah an initial point has to satisfy all those conditions that

877
00:59:53,950 --> 01:00:05,090
let's look at those in addition to that I don't think that's all the all

878
01:00:05,090 --> 01:00:09,970
the all all

879
01:00:10,870 --> 01:00:15,430
so these conditions in a sense I would just rather than the labor the point

880
01:00:15,430 --> 01:00:22,450
these conditions existential right we never know age because if we knew area we typically

881
01:00:22,450 --> 01:00:27,910
don't know don't know like stock and that means we don't know data we don't

882
01:00:27,910 --> 01:00:33,280
know dealt with L but we don't know we don't know gamma using these areas

883
01:00:33,280 --> 01:00:38,770
essential conditions that say if life is very well well-behaved near the optimum and I'm

884
01:00:38,770 --> 01:00:46,380
already nearly optimal I'll really get this of thing that way and the other thing

885
01:00:46,550 --> 01:00:51,230
you should know is that there is an important class of functions for which this

886
01:00:51,230 --> 01:00:53,370
theorem can be made a lot more constructive

887
01:00:54,270 --> 01:00:57,510
OK and I will

888
01:00:58,610 --> 01:01:03,970
I will give you 3 functions for which we can know all these constants and

889
01:01:03,970 --> 01:01:05,910
other things before him

890
01:01:06,050 --> 01:01:11,660
and we will we will visit this when we study interior point methods and those

891
01:01:11,660 --> 01:01:18,390
functions minus the log of that don't write this down unless you just you know

892
01:01:18,390 --> 01:01:24,660
you know responsible for the rest the edges of the rhetoric 1 minus the log

893
01:01:24,890 --> 01:01:31,730
minus the log of the squared minus the middle of the day

894
01:01:32,250 --> 01:01:36,230
might look to squared minus x

895
01:01:36,240 --> 01:01:38,490
authority positive

896
01:01:40,700 --> 01:01:45,890
n minus the log determinant of a matrix X

897
01:01:46,730 --> 01:01:50,410
it turns out these 3 functions

898
01:01:50,610 --> 01:01:56,230
we can see a lot more constructively about Newton's that

899
01:01:57,910 --> 01:02:07,190
and not only that we can say constructively about these but that we in functions

900
01:02:07,190 --> 01:02:08,230
to 1 another

901
01:02:08,750 --> 01:02:13,410
OK we can say with the functions and all of the combination

902
01:02:13,930 --> 01:02:18,510
and believe that it is these 3 functions that are there at the heart of

903
01:02:18,510 --> 01:02:20,210
modernity here that the

904
01:02:21,110 --> 01:02:22,990
so just that

905
01:02:23,430 --> 01:02:25,050
this is little factor

906
01:02:25,910 --> 01:02:33,910
OK so I'm at page 6 cover these bullet points so we typically have another

907
01:02:33,920 --> 01:02:38,350
constant speed H a L there's some amazing exceptions

908
01:02:38,630 --> 01:02:42,750
these 3 years among those exceptions

909
01:02:43,610 --> 01:02:48,270
is a curious fact which is lost a lot of people which is

910
01:02:52,070 --> 01:02:58,250
the rate of convergence in a sense is independent of the choice of norms

911
01:02:58,770 --> 01:03:00,830
but the constants are not

912
01:03:01,390 --> 01:03:04,510
and there is a mismatch

913
01:03:05,250 --> 01:03:10,550
that is not the case for these 3 functions with the same energy so that

914
01:03:10,550 --> 01:03:11,950
it very deep state

915
01:03:12,210 --> 01:03:16,370
OK badges will lead that so

916
01:03:17,690 --> 01:03:19,000
to form

917
01:03:19,050 --> 01:03:27,380
Soviet Union mathematicians in Yuri Nesterov numerosity were 500 page book resolving the question and

918
01:03:27,380 --> 01:03:31,090
it's a fantastic book and and other

919
01:03:31,140 --> 01:03:33,430
very brilliant optimisation

920
01:03:33,630 --> 01:03:39,030
a professor at Cornell wrote 120 page book just trying to make sense out of

921
01:03:39,030 --> 01:03:46,870
the 5 pages and that's really of the 128 is so easy to read and

922
01:03:47,070 --> 01:03:51,290
I spent a semester and have just trying to figure it out there and we

923
01:03:51,290 --> 01:03:57,250
did actually some of early seed of

924
01:03:59,490 --> 01:04:03,180
here also Newton's method we did not assume any convexity

925
01:04:03,200 --> 01:04:05,220
only that the Hessian matrix

926
01:04:05,280 --> 01:04:07,990
but is invertible

927
01:04:09,490 --> 01:04:15,730
and well story have here before we get the prove

928
01:04:17,390 --> 01:04:23,760
note from the statement of the convergence theorem that iterative Newton's method a equally attracted

929
01:04:23,760 --> 01:04:27,910
to local minima and local maxima that is the statement of the theorem just as

930
01:04:27,910 --> 01:04:31,570
much getting attracted to a point where the gradient is 0

931
01:04:31,590 --> 01:04:37,950
linux . says that when we apply the method in practice sometimes we get points

932
01:04:37,950 --> 01:04:41,620
where the Hessian of becomes singular

933
01:04:41,640 --> 01:04:44,640
and when that's the case usually set of

934
01:04:44,660 --> 01:04:50,950
In software is written so that you know if the Hessian is sufficiently singular then

935
01:04:50,950 --> 01:04:54,530
we had some epsilon times the identity matrix to

936
01:04:55,590 --> 01:04:57,390
and that's just

937
01:04:57,660 --> 01:05:00,090
that's called like acquires the Newton method

938
01:05:00,350 --> 01:05:06,130
and there used to be an entire field called causing Newton methods how many of

939
01:05:06,130 --> 01:05:09,310
you know anything about causing

940
01:05:09,320 --> 01:05:14,820
OK your name is Steve and what you know about aquifer

941
01:05:15,510 --> 01:05:18,710
you heard it in what costs

942
01:05:19,740 --> 01:05:25,220
and who taught that was here at MIT OK OK so if and when a

943
01:05:25,220 --> 01:05:30,450
professor boisei requires Newton method

944
01:05:30,450 --> 01:05:37,800
really OK I have to talk to Steve about that and so cuisine Newton methods

945
01:05:37,800 --> 01:05:41,840
used to be all the rage because so what they are is a thinking

946
01:05:41,990 --> 01:05:46,680
so go back 15 years in computing power

947
01:05:46,700 --> 01:05:54,050
because you don't want solve large systems of equations from scratch at each iteration cited

948
01:05:54,050 --> 01:05:58,660
and here I solve a large system of equations I get my Newton direction that

949
01:05:58,660 --> 01:05:59,950
I go over here

950
01:05:59,950 --> 01:06:02,990
right now instead of here

951
01:06:03,030 --> 01:06:05,340
building my Hessian inverting it

952
01:06:05,360 --> 01:06:09,820
I instead use information about this session

953
01:06:09,990 --> 01:06:13,010
combine it with information about

954
01:06:13,090 --> 01:06:15,450
at the gradient here

955
01:06:15,640 --> 01:06:20,780
and some other thing to save a lot of work and unfortunately that's all I

956
01:06:20,780 --> 01:06:26,660
know about causing Newton methods OK except just that they're designed they don't do full

957
01:06:26,660 --> 01:06:29,860
Newton steps they don't do complete Newton steps

958
01:06:29,950 --> 01:06:32,340
but they save on work

959
01:06:32,780 --> 01:06:35,050
pages and

960
01:06:35,430 --> 01:06:43,590
by various forces acting on the body of the there's a whole lot of in

961
01:06:43,590 --> 01:06:50,220
my senses that is literally dozens of classical methods can actually have lecture notes somewhere

962
01:06:50,590 --> 01:06:52,430
question methods

963
01:06:52,490 --> 01:06:57,860
I should try and take them up 1 of these but I don't see users

964
01:06:57,930 --> 01:07:03,470
much anymore again because computational power such that they're not as relevant at the moment

965
01:07:03,470 --> 01:07:05,390
as they used to be

966
01:07:05,470 --> 01:07:09,620
by the way are Katie Nemirovski is going to be giving a talk at MIT

967
01:07:09,620 --> 01:07:13,110
on ice to talks 17th and 18th

968
01:07:16,490 --> 01:07:20,120
but so this should be a big event this is this guy is

969
01:07:20,260 --> 01:07:24,700
a giant really in in this in the field of optimisation yes

970
01:07:25,340 --> 01:07:27,970
the with

971
01:07:28,910 --> 01:07:31,620
I want you to know about

972
01:07:31,620 --> 01:07:36,140
bright patches in the image those are all compressed to within range the neural systems

973
01:07:36,140 --> 01:07:42,530
can handle and typically against differential coding thing comes in this lecture in division so

974
01:07:44,430 --> 01:07:48,390
from regions next to one another will mutually inhibit one another in order to kind

975
01:07:48,390 --> 01:07:52,190
of focus on the stuff is most important and suppress the rest

976
01:07:52,200 --> 01:07:57,500
so typically this logarithmic or power law response is more sigmoid responses

977
01:07:57,940 --> 01:08:03,490
some kind of contrast invariance is this b is built using this these is

978
01:08:04,410 --> 01:08:09,430
and you suppress non maxima stuff stuff it's not the most salient thing in the

979
01:08:09,430 --> 01:08:10,830
image gets supressed

980
01:08:11,170 --> 01:08:15,170
together those two things imply that your code is going to be sparse so

981
01:08:15,360 --> 01:08:16,680
you have

982
01:08:16,700 --> 01:08:20,350
lots of ways of representing different types of features in the image

983
01:08:21,780 --> 01:08:22,990
in your brain

984
01:08:23,440 --> 01:08:27,570
but each of those things each of those filters or whether it is the firing

985
01:08:27,570 --> 01:08:31,240
of some kind of feature is going to find a new relatively really on a

986
01:08:31,240 --> 01:08:33,330
particular piece of image

987
01:08:33,340 --> 01:08:38,110
OK so typically is very high dimensional representation lots of different filters that fire some

988
01:08:38,110 --> 01:08:41,240
basic is the image but only few of them will be found in any one

989
01:08:41,240 --> 01:08:45,220
time not only particularly salient points the image

990
01:08:45,230 --> 01:08:51,580
so this process is important biologically because it meets means neural firings actually quite expensive

991
01:08:51,590 --> 01:08:54,840
i mean you can fire listen if we save a lot of energy

992
01:08:55,170 --> 01:08:58,640
a large part of the food you eat goes to just running brain

993
01:08:58,680 --> 01:09:01,080
a large part of your brain is devoted to vision

994
01:09:01,100 --> 01:09:06,270
and it's also useful for kind of salient so focusing in on things that are

995
01:09:06,270 --> 01:09:10,550
important in the image and pulling them out so that the brain can concentrate on

996
01:09:10,550 --> 01:09:11,980
the most relevant pieces

997
01:09:12,070 --> 01:09:15,110
because there's just some examples of these principles

998
01:09:16,350 --> 01:09:18,870
this is contrast colour opponent coding

999
01:09:18,890 --> 01:09:20,070
so in each

1000
01:09:20,070 --> 01:09:22,360
images there are two hours

1001
01:09:22,410 --> 01:09:26,750
pointing to two regions some of which are coloured some which are not

1002
01:09:27,590 --> 01:09:30,350
and all of those regions are each for each

1003
01:09:30,400 --> 01:09:33,490
image to pair regions has exactly the same

1004
01:09:33,500 --> 01:09:36,370
pixel greater intensity of colour

1005
01:09:36,430 --> 01:09:38,940
so perhaps the most striking one is this

1006
01:09:38,950 --> 01:09:41,080
this nice brown

1007
01:09:41,100 --> 01:09:42,680
could keep here

1008
01:09:42,770 --> 01:09:48,440
rather orange one here there's are interviewed look on screen anyway another brown one here

1009
01:09:48,580 --> 01:09:52,860
but the human vision system and so that's completely different colours

1010
01:09:53,870 --> 01:09:58,400
and it's right they are in the real world different colours because the shadowing means

1011
01:09:58,400 --> 01:10:01,250
that the fate of the colours been modified

1012
01:10:01,270 --> 01:10:06,590
so what's happening is you can differentially you're looking on in the surrounding

1013
01:10:06,700 --> 01:10:09,190
distribution of colours and using that

1014
01:10:09,200 --> 01:10:11,290
two code what the colours

1015
01:10:11,300 --> 01:10:17,000
similarly with intensities know this back queries what scare the same intensity don't see that

1016
01:10:17,000 --> 01:10:22,500
because once in the shadows so you interpret the scene properly to get rid of

1017
01:10:22,550 --> 01:10:26,860
OK a couple more effects on the same line so bands classical fit

1018
01:10:26,940 --> 01:10:28,160
you should see

1019
01:10:28,180 --> 01:10:32,550
that these things are other non uniform intensity with some h and in the kind

1020
01:10:32,550 --> 01:10:34,730
of decay in an agent kind of decay

1021
01:10:34,820 --> 01:10:39,280
in fact the uniform intensity so what's happening is differentially cutting edge

1022
01:10:39,300 --> 01:10:41,210
and then the stuff that that's

1023
01:10:41,230 --> 01:10:46,030
next was being suppressed some extent this is an example not sure if you seen

1024
01:10:46,030 --> 01:10:50,360
this one from back if you look at the blue spot in the middle of

1025
01:10:50,360 --> 01:10:52,540
all seem to shrink

1026
01:10:52,570 --> 01:10:54,840
OK so what's happening is that you know

1027
01:10:54,970 --> 01:10:57,480
he is temporarily accommodated

1028
01:10:57,490 --> 01:11:01,590
so that it's kind of trying to suppress the signal because it's no longer interesting

1029
01:11:03,550 --> 01:11:06,820
this there's lots of other examples of these things but i'm just taking a few

1030
01:11:08,570 --> 01:11:11,700
OK so more principles of human vision

1031
01:11:11,700 --> 01:11:17,050
the architecture is pretty orderly multi layer

1032
01:11:18,090 --> 01:11:22,720
there are a number of vision regions we've got listen the next slide the signal

1033
01:11:22,720 --> 01:11:26,030
goes through these regions to go through the one that goes to be two of

1034
01:11:26,030 --> 01:11:26,910
the three

1035
01:11:26,920 --> 01:11:31,230
he goes into the forest try to get a set of these vision regions the

1036
01:11:31,230 --> 01:11:35,540
lower-level ones are kind of understood the highly ones much less well understood but at

1037
01:11:35,540 --> 01:11:40,820
least the signals progressing through an orderly chain of processing the processing chain is actually

1038
01:11:40,820 --> 01:11:46,180
relatively shallow compared to what you might think machine learning vision algorithms

1039
01:11:46,190 --> 01:11:49,190
so typically around eight layers maximum

1040
01:11:49,200 --> 01:11:52,790
the response within a few layers very often

1041
01:11:53,690 --> 01:11:57,970
and that's typically twenty to thirty neurons the say your responses can actually start coming

1042
01:11:57,970 --> 01:12:02,140
within about fifty milliseconds which is very very fast by your standards

1043
01:12:06,330 --> 01:12:09,700
we'd like to be able to do that with vision systems but typically vision systems

1044
01:12:09,700 --> 01:12:11,360
are much deeper than that

1045
01:12:11,440 --> 01:12:15,360
there's lots of chains of processing after doctor processes in order to get things to

1046
01:12:16,500 --> 01:12:19,860
so we have really attain the rapidity

1047
01:12:19,890 --> 01:12:24,970
this is the basic processing to the human brain has also

1048
01:12:25,030 --> 01:12:29,250
in the arctic should tends to separate things that you might find rather surprising that

1049
01:12:29,360 --> 01:12:35,180
separates localisation in recognition so the channel that recognizes things in another channel this is

1050
01:12:35,180 --> 01:12:36,270
where they are

1051
01:12:36,290 --> 01:12:42,730
and to a large extent those actually operates several separately you separate colour intensity processing

1052
01:12:42,740 --> 01:12:44,170
things like this

1053
01:12:44,690 --> 01:12:50,390
also top-down feedback attention context all very important so you you know scene you start

1054
01:12:50,390 --> 01:12:54,700
interpreting it in your attention goes to one point and you start interpreting that in

1055
01:12:54,700 --> 01:12:56,910
terms of the context surrounding it

1056
01:12:58,800 --> 01:13:01,930
so all of those things and then

1057
01:13:02,650 --> 01:13:06,640
mapping the representation is very very non uniform

1058
01:13:06,660 --> 01:13:11,050
so what's called topographic mapping written topic mapping

1059
01:13:11,070 --> 01:13:16,150
we'll see an example of that second year i is is very non uniformly sampled

1060
01:13:16,150 --> 01:13:20,160
and that sampling is repeated on the brain in the areas where we with the

1061
01:13:20,160 --> 01:13:21,200
brain treats

1062
01:13:21,230 --> 01:13:24,120
information in the spatial way

1063
01:13:24,180 --> 01:13:27,450
in such a way that the signal from the eyes basically mapped onto the signal

1064
01:13:27,450 --> 01:13:31,340
from the brain but is distorted this perceptions with other senses as well including hearing

1065
01:13:31,340 --> 01:13:36,320
things are come to that in a second

1066
01:13:36,360 --> 01:13:40,960
sir you the other thing is that a lot of the filtering and this was

1067
01:13:40,960 --> 01:13:44,910
going on is arranged in regular columns what are called the columns which typically contain

1068
01:13:45,090 --> 01:13:51,490
all little sensor processing different scales different orientations and it's kind of integrated within a

1069
01:13:51,490 --> 01:13:52,530
small region

1070
01:13:52,540 --> 01:13:55,240
and then passed on to the next the next level

1071
01:13:55,710 --> 01:13:58,360
and much of the processing is multiscale

1072
01:13:58,830 --> 01:14:02,340
let me just skip over these regions but you can see this a list of

1073
01:14:02,340 --> 01:14:03,970
basic regions

1074
01:14:04,350 --> 01:14:07,550
well will only mention a few of them later

1075
01:14:07,560 --> 01:14:11,750
they have some functionality but when you get about the to the functionality is particularly

1076
01:14:11,750 --> 01:14:15,650
v three v four gets a little bit vague exactly what's going on these are

1077
01:14:15,710 --> 01:14:19,200
rather different places of the brain the ones in the back of the brain

1078
01:14:19,420 --> 01:14:24,700
algerians in the centre of the brain theorize go through this interview brain in map

1079
01:14:24,700 --> 01:14:28,820
onto the back of your brain the first stage of processing

1080
01:14:28,830 --> 01:14:31,560
OK so written the topic mapping

1081
01:14:31,570 --> 01:14:34,700
this is roughly the sampling density of the retina

1082
01:14:34,770 --> 01:14:36,370
so the other

1083
01:14:37,230 --> 01:14:38,930
it's very very

1084
01:14:38,930 --> 01:14:41,970
so hello sorry for the time to

1085
01:14:41,980 --> 01:14:47,200
but all of that stuff from me and my computer and when there

1086
01:14:47,280 --> 01:14:51,230
a few things i need to tell you before i start talking the first one

1087
01:14:51,230 --> 01:14:54,050
is i am not enrico motta

1088
01:14:54,070 --> 01:14:59,670
in case somebody one you may see on your USB stick but was she was

1089
01:14:59,680 --> 01:15:01,020
to be talk

1090
01:15:01,040 --> 01:15:06,450
called semantic web applications by enrico motta and supported through the media

1091
01:15:06,470 --> 01:15:08,500
so my name is much like icon

1092
01:15:08,520 --> 01:15:10,970
from the nineteen institute the open university

1093
01:15:10,980 --> 01:15:12,600
the second thing

1094
01:15:12,620 --> 01:15:13,830
i want to tell you that

1095
01:15:13,850 --> 01:15:20,300
the good thing is that my talk with it quite well with what jim just

1096
01:15:20,630 --> 01:15:24,810
shown in this kind of a continuation making it just a bit more concrete we

1097
01:15:24,810 --> 01:15:27,290
see that in a minute the last thing

1098
01:15:27,330 --> 01:15:28,170
is that

1099
01:15:28,190 --> 01:15:31,320
i intended to put a lot of

1100
01:15:31,340 --> 01:15:37,430
live demos live demos of online things when are talking about web here fortunately as

1101
01:15:37,430 --> 01:15:38,700
you may know

1102
01:15:38,710 --> 01:15:43,260
that would be really possible so i will tell another story about what life demo

1103
01:15:43,270 --> 01:15:47,950
we look like if you were able to connect to the internet so

1104
01:15:48,040 --> 01:15:51,350
first using the semantic web

1105
01:15:51,360 --> 01:15:52,420
i mean

1106
01:15:52,460 --> 01:15:53,710
the title is not

1107
01:15:53,720 --> 01:15:58,010
say much about what the plantation is supposed to be so what

1108
01:15:58,070 --> 01:15:59,770
could there be two

1109
01:15:59,830 --> 01:16:03,690
i'm missing something

1110
01:16:03,710 --> 01:16:05,830
can we do is on this part

1111
01:16:09,520 --> 01:16:12,020
we continue like this is ten

1112
01:16:12,020 --> 01:16:15,960
in addition to not having is alive demos you will not be part of the

1113
01:16:15,960 --> 01:16:20,210
screen so whenever there would be something in this part we describe it as well

1114
01:16:20,260 --> 01:16:23,050
so we will have lots of very nice story today

1115
01:16:23,600 --> 01:16:25,690
so what is there

1116
01:16:25,710 --> 01:16:27,380
to use on the

1117
01:16:27,390 --> 01:16:29,150
antique web

1118
01:16:29,160 --> 01:16:35,470
well i mean you can think of the obvious technologies or RDF RDF a great

1119
01:16:36,110 --> 01:16:40,320
sparql all these things have been talking about

1120
01:16:41,140 --> 01:16:41,960
they are

1121
01:16:41,980 --> 01:16:46,540
this ten services infrastructure all these things about there

1122
01:16:47,450 --> 01:16:52,210
what i want to talk about is not all this thing is the knowledge information

1123
01:16:52,210 --> 01:16:56,590
and data which is why the semantic web is about is what is semantic web

1124
01:16:57,620 --> 01:16:58,720
and actually

1125
01:16:58,760 --> 01:17:00,220
if you look at a few

1126
01:17:00,240 --> 01:17:02,400
i believe what you just said

1127
01:17:02,420 --> 01:17:06,290
there is a lot of

1128
01:17:07,890 --> 01:17:10,350
now the question is

1129
01:17:10,370 --> 01:17:11,710
how other use

1130
01:17:11,750 --> 01:17:16,490
the semantic web are use this data on the semantic information that is out there

1131
01:17:18,100 --> 01:17:19,550
my answer is

1132
01:17:19,560 --> 01:17:24,450
by building yet

1133
01:17:24,460 --> 01:17:30,040
i will try to sort it because indeed it seems to be a bit

1134
01:17:30,050 --> 01:17:33,960
ninety two two

1135
01:17:33,980 --> 01:17:36,640
with a screen

1136
01:17:51,920 --> 01:17:53,610
doesn't seem a lot better

1137
01:17:59,000 --> 01:18:02,450
but what which is supposed to be the resolution differences

1138
01:18:02,490 --> 01:18:08,590
one thousand

1139
01:18:08,610 --> 01:18:11,290
yes that's better

1140
01:18:11,340 --> 01:18:18,170
thank you

1141
01:18:18,170 --> 01:18:22,670
and you and

1142
01:18:22,690 --> 01:18:29,680
and there

1143
01:18:29,790 --> 01:18:33,850
OK this is the lecture on

1144
01:18:33,920 --> 01:18:37,390
the singular value decomposition

1145
01:18:37,440 --> 01:18:40,190
but everybody calls it

1146
01:18:40,240 --> 01:18:42,690
the SVD

1147
01:18:42,710 --> 01:18:48,930
so this is the final and best factorization of the matrix

1148
01:18:48,970 --> 01:18:52,610
and let me tell you what's coming

1149
01:18:52,650 --> 01:19:00,340
the factors will be an orthogonal matrix diagonal matrix orthogonal matrix

1150
01:19:00,990 --> 01:19:04,150
so it's things that we've seen before

1151
01:19:04,160 --> 01:19:08,880
the special good matrices orthogonal diagonal

1152
01:19:08,940 --> 01:19:11,250
that the new point is

1153
01:19:11,290 --> 01:19:17,870
that we need to orthogonal matrices that a couldn't be any matrix whatsoever

1154
01:19:17,980 --> 01:19:25,550
any matrix whatsoever has singular value decomposition so a diagonal line in the middle but

1155
01:19:25,550 --> 01:19:32,640
I need to different probably different orthogonal matrices that to be able to do this

1156
01:19:32,700 --> 01:19:38,200
OK and this factorisation has jumped into important

1157
01:19:38,220 --> 01:19:39,690
and is

1158
01:19:39,780 --> 01:19:44,620
properly I think maybe the bringing together of everything in this course

1159
01:19:45,150 --> 01:19:48,250
1 thing will bring together is

1160
01:19:49,340 --> 01:19:56,220
like this the good very good family of matrices that we just added symmetric positive

1161
01:19:56,220 --> 01:19:58,950
definite remember the story with those guys

1162
01:19:59,220 --> 01:20:04,360
because they were symmetric their eigenvectors

1163
01:20:04,400 --> 01:20:06,330
work orthogonal

1164
01:20:06,340 --> 01:20:11,690
so I could produce an orthogonal matrix and it this is my usual 1

1165
01:20:11,750 --> 01:20:16,480
my usual 1 is the eigenvectors and eigen value

1166
01:20:16,530 --> 01:20:23,640
In this symmetric case the eigenvectors are orthogonal so I've got the good might might

1167
01:20:23,640 --> 01:20:27,620
ordinary has become an especially good q

1168
01:20:27,880 --> 01:20:33,820
and positive definite by ordinary land has become a positive

1169
01:20:33,870 --> 01:20:35,090
so this is

1170
01:20:35,120 --> 01:20:41,970
that's the that's the singular value decomposition in case of a matrix is symmetric positive

1171
01:20:44,000 --> 01:20:49,750
in that case I don't need to be 1 of the 1 matrix 1 orthogonal

1172
01:20:49,750 --> 01:20:52,090
matrix will do for both of us

1173
01:20:52,220 --> 01:20:57,910
but is it so this would be no good and in general because usually the

1174
01:20:57,910 --> 01:21:00,870
eigenvector matrix is an orthogonal

1175
01:21:00,880 --> 01:21:05,540
so this is not what I'm that's not what I'm after

1176
01:21:05,590 --> 01:21:07,380
I'm I'm looking for

1177
01:21:08,660 --> 01:21:14,970
times diagonal times orthography and let me show you what that means and where it

1178
01:21:14,970 --> 01:21:17,090
comes from OK

1179
01:21:17,340 --> 01:21:19,280
what is meaning

1180
01:21:19,440 --> 01:21:23,720
you remember that

1181
01:21:23,750 --> 01:21:28,490
the picture of any linear transformation this was like the most important

1182
01:21:29,770 --> 01:21:32,320
in 1806

1183
01:21:32,370 --> 01:21:35,000
and 1 my looking for now

1184
01:21:35,040 --> 01:21:37,650
it a typical bacteria

1185
01:21:41,650 --> 01:21:44,430
that go vector let me the ones

1186
01:21:44,650 --> 01:21:51,750
gets taken over to sun vector in the column space say you want so you

1187
01:21:52,780 --> 01:21:54,880
it is a 1

1188
01:22:00,370 --> 01:22:02,690
another factor

1189
01:22:02,710 --> 01:22:08,590
gets taken over here somewhere what am I looking for in this SVD this singular

1190
01:22:08,590 --> 01:22:10,370
value decomposition

1191
01:22:10,470 --> 01:22:12,120
what I'm looking for

1192
01:22:12,190 --> 01:22:15,770
it an orthogonal basis here

1193
01:22:15,810 --> 01:22:21,500
that gets knocked over into 1 orthogonal basis over there

1194
01:22:21,530 --> 01:22:27,720
that's the that's pretty special going to have to have an orthogonal basis

1195
01:22:27,770 --> 01:22:30,660
and there are also based

1196
01:22:30,870 --> 01:22:35,630
that goes over into an orthogonal basis so this is like a right angle and

1197
01:22:35,630 --> 01:22:37,100
this is the right angle

1198
01:22:37,220 --> 01:22:41,360
into an orthogonal basis in the columns

1199
01:22:41,390 --> 01:22:45,830
so that's that's our goal is defined

1200
01:22:46,200 --> 01:22:49,840
it because do see how things are coming together

1201
01:22:49,900 --> 01:22:55,570
1st of all can I find an orthogonal basis for this row space

1202
01:22:55,590 --> 01:23:01,570
Of course no did no big deal define an orthogonal basis Gram Schmidt tells me

1203
01:23:01,570 --> 01:23:06,510
how to do it start with radial basis and greater use grind through Gram Schmidt

1204
01:23:06,510 --> 01:23:09,680
outcomes an orthogonal basis

1205
01:23:09,710 --> 01:23:15,840
but then if I just take any old orthogonal basis than when I multiply by

1206
01:23:15,850 --> 01:23:18,480
there's no reason why it should be orthogonal over here

1207
01:23:20,390 --> 01:23:27,890
so I'm looking for this special set of where a takes these bases vectors into

1208
01:23:28,400 --> 01:23:34,630
orthogonal vectors over there now you might have noticed that the null space I didn't

1209
01:23:34,630 --> 01:23:39,780
include why don't I think that it it's you memory usual figure had a little

1210
01:23:39,780 --> 01:23:41,830
null space

1211
01:23:41,850 --> 01:23:43,890
and a little multiple

1212
01:23:43,970 --> 01:23:49,780
and of those there no problems there's no spaces they're going to show up at

1213
01:23:50,890 --> 01:23:53,330
on the diagonal of signal

1214
01:23:53,390 --> 01:23:56,860
so that that's not what we're

1215
01:23:56,920 --> 01:24:03,390
that doesn't presented the difficult are difficulty justifying the so see what this will mean

1216
01:24:03,900 --> 01:24:08,180
this will mean that a of times this

1217
01:24:09,680 --> 01:24:13,630
these regions the wire and the 2 up to

1218
01:24:13,660 --> 01:24:15,710
what's the dimension of this

1219
01:24:15,720 --> 01:24:18,630
rose space of the

1220
01:24:18,790 --> 01:24:24,100
so it can be a little smaller up to the ah

1221
01:24:24,800 --> 01:24:28,180
so bad

1222
01:24:28,210 --> 01:24:31,010
a B 1

1223
01:24:31,030 --> 01:24:35,770
is gonna be the 1st column facility here as well and here's what I'm achieved

1224
01:24:36,720 --> 01:24:40,840
I would like to have not only have to make these orthogonal but why not

1225
01:24:40,840 --> 01:24:42,710
make them orthonormal

1226
01:24:42,720 --> 01:24:44,510
make them unit vectors

1227
01:24:44,570 --> 01:24:46,150
so this

1228
01:24:46,180 --> 01:24:50,300
maybe the unit vector is here is the you want

1229
01:24:50,330 --> 01:24:52,070
and this might be

1230
01:24:52,130 --> 01:24:54,180
a multiple of

1231
01:24:54,220 --> 01:24:59,780
so we really what's happening is a V 1 is some multiple

1232
01:24:59,960 --> 01:25:05,830
of you 1 right under and these guys would be unit vectors and they'll go

1233
01:25:05,830 --> 01:25:12,340
over into multiples of unit vectors and the multiple univocal lambda anymore

1234
01:25:12,400 --> 01:25:17,090
I'm calling and sigma so that's the number that the stretching of

1235
01:25:17,180 --> 01:25:22,530
and similarly they need to do is to you too

1236
01:25:22,540 --> 01:25:24,680
this is what this is my goal

1237
01:25:24,710 --> 01:25:29,340
and now I want to express their goal in matrix language

1238
01:25:29,360 --> 01:25:34,420
that's the usual step think of what you want and then express it as a

1239
01:25:34,420 --> 01:25:36,240
matrix mobile occasion so

1240
01:25:36,800 --> 01:25:38,800
a V ones

1241
01:25:39,840 --> 01:25:43,540
signal 1 new actually here here we go

1242
01:25:43,600 --> 01:25:49,070
let me pull out these you want you to to you are

1243
01:25:49,160 --> 01:25:53,570
and then a matrix with this

1244
01:25:53,600 --> 01:25:56,090
but it's

1245
01:25:56,130 --> 01:25:58,510
everything now is going to be in this

1246
01:25:58,530 --> 01:26:01,090
in that in that

1247
01:26:01,100 --> 01:26:03,240
little part of the blackboard

1248
01:26:03,280 --> 01:26:05,470
you see that this

1249
01:26:07,270 --> 01:26:14,180
sense what I'm trying to do with my Figure 8 times the 1st basis vectors

1250
01:26:14,230 --> 01:26:20,090
should be saying 1 times times the other bases of the 1st places like vectors

1251
01:26:20,220 --> 01:26:26,980
is basis vectors on the row space the the basis vectors in the columns space

1252
01:26:27,150 --> 01:26:30,340
and the use the multiplying factor

1253
01:26:30,400 --> 01:26:32,530
so as a to

1254
01:26:32,590 --> 01:26:35,110
it is sigma 2 times you to

1255
01:26:35,160 --> 01:26:40,860
a v r is signal r times you are and then we got a whole

1256
01:26:40,860 --> 01:26:45,510
lot of zeros and maybe some zeros at the end but this is that's the

1257
01:26:45,510 --> 01:26:51,230
everybody can fairly accurately predicted position in this room or from outside moving to estimate

1258
01:26:51,230 --> 01:26:55,370
fairly accurately predict position so there are cases that really are fully observable that i

1259
01:26:55,370 --> 01:26:56,410
can sort hack

1260
01:26:56,560 --> 01:26:58,210
potential for observable

1261
01:26:58,210 --> 01:27:00,240
on the very close to put ball

1262
01:27:00,290 --> 01:27:01,970
and this is OK

1263
01:27:05,710 --> 01:27:09,950
so the hardest case i think is the part of the rule case so driving

1264
01:27:09,950 --> 01:27:10,800
a car

1265
01:27:11,730 --> 01:27:16,980
truly anything in in the real world where every officially is noisy the something state

1266
01:27:17,220 --> 01:27:18,320
but not complete

1267
01:27:18,330 --> 01:27:24,060
OK so far things are partially observable reinforcement learning planning is very difficult task it

1268
01:27:24,060 --> 01:27:25,910
would take it in six hours

1269
01:27:25,970 --> 01:27:29,070
OK so this example in several case today

1270
01:27:29,130 --> 01:27:33,140
and again if really have to be allocated into really interested i wanted to course

1271
01:27:33,620 --> 01:27:38,460
of the next year and we can go more in detail fourteen weeks

1272
01:27:38,510 --> 01:27:42,470
in some of these problems

1273
01:27:43,420 --> 01:27:46,010
so again active state observations

1274
01:27:46,070 --> 01:27:47,460
these are problem

1275
01:27:47,470 --> 01:27:49,630
you how map between

1276
01:27:49,640 --> 01:27:52,750
i know what

1277
01:27:52,780 --> 01:27:56,390
missing my transition slide

1278
01:27:56,420 --> 01:27:59,120
here OK so i got water

1279
01:27:59,140 --> 01:28:03,090
OK we have the activation function tells us how information that the states we also

1280
01:28:03,110 --> 01:28:07,240
know how actions how actions taken between states

1281
01:28:07,260 --> 01:28:08,930
OK so there there's

1282
01:28:08,930 --> 01:28:10,820
two of these two crucial part three

1283
01:28:10,860 --> 01:28:14,500
two crucial properties of it every ten function

1284
01:28:14,510 --> 01:28:18,790
OK so stationarity does not change over time

1285
01:28:18,810 --> 01:28:20,830
so let's see

1286
01:28:20,880 --> 01:28:27,130
i have

1287
01:28:27,180 --> 01:28:28,450
the year

1288
01:28:39,950 --> 01:28:42,530
australia's ooo

1289
01:28:42,580 --> 01:28:45,830
ladies and templates

1290
01:28:46,470 --> 01:28:48,880
so stationary function if i tried to predict

1291
01:28:48,900 --> 01:28:52,240
the average temperature as a function of

1292
01:28:52,280 --> 01:28:53,880
the day of the year

1293
01:28:53,880 --> 01:28:56,880
this is stationary function it's noisy

1294
01:28:57,460 --> 01:29:01,360
but the day of the year the pretty good average picture of temperature

1295
01:29:01,470 --> 01:29:04,390
what i tried to take the average temperature as a function of the day of

1296
01:29:04,390 --> 01:29:06,130
the week

1297
01:29:08,940 --> 01:29:12,590
clearly this differs about what time of the year year in OK so if you

1298
01:29:12,590 --> 01:29:16,650
just saw the day of the week and nothing else has transition function will be

1299
01:29:16,650 --> 01:29:21,800
nonstationary active role in the winter than when someone you know how to to determine

1300
01:29:21,880 --> 01:29:23,760
change from tuesday

1301
01:29:23,800 --> 01:29:27,530
OK that that depends on whether you're you're in the winter and summer resident function

1302
01:29:27,570 --> 01:29:30,260
today the year one three sixty five

1303
01:29:30,320 --> 01:29:33,650
OK that stationary has a site signal behavior

1304
01:29:33,780 --> 01:29:35,630
doesn't change over time

1305
01:29:35,650 --> 01:29:38,470
well global warming side

1306
01:29:40,070 --> 01:29:47,170
OK another crucial property his heart of a markovian decision processes or MDP

1307
01:29:47,170 --> 01:29:50,740
his her a markov chain markov model

1308
01:29:50,760 --> 01:29:53,340
more people right from start

1309
01:29:53,380 --> 01:29:54,570
OK right

1310
01:29:54,860 --> 01:29:58,610
to be accurate right

1311
01:29:58,670 --> 01:30:00,110
OK so

1312
01:30:00,130 --> 01:30:05,050
when the markov property in any single to problem is is probably european releases because

1313
01:30:05,050 --> 01:30:07,190
it simplifies

1314
01:30:07,240 --> 01:30:10,070
the problem substantially

1315
01:30:10,090 --> 01:30:12,280
OK make something the markov assumption

1316
01:30:12,300 --> 01:30:16,300
the next is only depend upon the previous state and the action

1317
01:30:16,400 --> 01:30:17,950
so where i go

1318
01:30:17,990 --> 01:30:19,400
from the states

1319
01:30:19,400 --> 01:30:23,590
to next state only tens or not aware was yesterday

1320
01:30:24,470 --> 01:30:26,130
now you say well

1321
01:30:26,130 --> 01:30:30,780
this the hacking you can always make the claim that problems marketing well actually you

1322
01:30:31,610 --> 01:30:35,940
OK you can always put enough information in just a description

1323
01:30:35,960 --> 01:30:40,840
to have a a marketing problem so imagine an elevator

1324
01:30:42,300 --> 01:30:43,400
which i think

1325
01:30:43,440 --> 01:30:46,590
the rest of the day people come in the morning they're all going up to

1326
01:30:46,630 --> 01:30:52,010
four work OK five PM there's mass exodus everyone's going down

1327
01:30:52,010 --> 01:30:55,360
OK so the arrival rate is changing throughout the day

1328
01:30:55,440 --> 01:30:58,800
and they say this is not markovian i don't have time in the state

1329
01:30:58,860 --> 01:31:00,960
the ten depends on time

1330
01:31:01,670 --> 01:31:03,840
the surface but time state

1331
01:31:03,860 --> 01:31:07,840
but everything upon which the transverse you could depend on the state and you make

1332
01:31:07,840 --> 01:31:09,590
it a marketing problem

1333
01:31:10,420 --> 01:31:14,600
and in extreme if you see marketers talk i think at the end of the

1334
01:31:14,600 --> 01:31:15,780
summer school

1335
01:31:15,820 --> 01:31:17,190
so assume

1336
01:31:17,320 --> 01:31:20,590
that the state is everything you see in the past

1337
01:31:20,590 --> 01:31:22,880
OK and that's surely markovian

1338
01:31:23,110 --> 01:31:27,130
you know you if it stays there is everything you've seen that you can know

1339
01:31:27,300 --> 01:31:30,130
you possibly no no no more

1340
01:31:32,110 --> 01:31:35,630
but key here the problem is the markovian you can always put more

1341
01:31:35,630 --> 01:31:39,590
efficient state making markovian so seemed like a big assumption was not

1342
01:31:39,610 --> 01:31:42,550
but the markovian assumption will grow simplify

1343
01:31:42,550 --> 01:31:47,380
how we solve these problems

1344
01:31:47,460 --> 01:31:50,090
OK now it's funny so far we talked about

1345
01:31:50,210 --> 01:31:53,800
modeling agent observations action state how it

1346
01:31:53,860 --> 01:31:58,690
how how this would be observe how it gets different places based on the action

1347
01:31:58,690 --> 01:32:00,320
to take

1348
01:32:00,360 --> 01:32:04,780
but we're talking about learning here more and more learning to do something right

1349
01:32:04,820 --> 01:32:08,420
OK so it's crucial have some notion of goal reward what is it that you

1350
01:32:08,420 --> 01:32:10,400
want to optimize

1351
01:32:12,110 --> 01:32:17,240
so OK obvious case of of of of reward simple goal you need to get

1352
01:32:17,240 --> 01:32:18,530
to that door

1353
01:32:18,530 --> 01:32:22,630
OK so you just make sure that the reward that you get the door greater

1354
01:32:22,630 --> 01:32:25,170
than they were not getting to the door

1355
01:32:25,740 --> 01:32:28,390
now you might want to get the shortest path to the door that is i

1356
01:32:28,390 --> 01:32:30,380
don't want to go all the way around

1357
01:32:30,400 --> 01:32:33,070
this way it's the door if i'm here

1358
01:32:33,070 --> 01:32:34,780
i want to go straight to the door

1359
01:32:34,840 --> 01:32:37,710
how do you get an agent to optimize

1360
01:32:37,710 --> 01:32:40,740
the shortest path or we put cost on actions

1361
01:32:41,300 --> 01:32:45,110
so you get minus one for every step you take and then you get hundred

1362
01:32:45,130 --> 01:32:46,740
going to the door OK

1363
01:32:46,760 --> 01:32:49,420
if you you can optimize that

1364
01:32:49,780 --> 01:32:53,150
then you can get shorter section

1365
01:32:53,270 --> 01:32:57,530
so if you want to infer behaviour you have make sure to reward function

1366
01:32:57,940 --> 01:33:01,300
rewards that behavior

1367
01:33:01,360 --> 01:33:05,170
OK but not all problems have explicit goals

1368
01:33:05,170 --> 01:33:08,690
OK so imagine that you've got mail delivery robots

1369
01:33:08,730 --> 01:33:13,150
there's no robot has become a lot has to go live at the mail offices

1370
01:33:13,170 --> 01:33:15,610
the males always coming in from today

1371
01:33:15,630 --> 01:33:21,070
so really is there's never any points during the day with this this this is

1372
01:33:21,070 --> 01:33:24,610
where i can say goal achieved undone because males

1373
01:33:24,670 --> 01:33:29,590
more malcolm and it's more of a dead melted two people as fast as possible

1374
01:33:29,590 --> 01:33:33,860
what sigma kappa nu metal may arrive OK let's see if the horizon problem because

1375
01:33:33,860 --> 01:33:36,960
on today tomorrow next year ten years from now

1376
01:33:36,990 --> 01:33:40,340
OK after about last that long OK but there are problems that don't have a

1377
01:33:42,260 --> 01:33:45,630
you have clearly reward you get plus one for say

1378
01:33:45,650 --> 01:33:49,820
getting every piece of mail to it's it's a it's adresse

1379
01:33:49,920 --> 01:33:54,530
but you don't have a single we can just get too and stop you optimize

1380
01:33:54,530 --> 01:33:56,490
over infinite horizon

1381
01:33:56,490 --> 01:33:59,860
or continuing horizon

1382
01:33:59,920 --> 01:34:04,110
so here we just assign utility you're reading more into decision theory using his own

1383
01:34:04,110 --> 01:34:07,400
you can also like optimise information

1384
01:34:07,490 --> 01:34:09,510
where zero mean

1385
01:34:09,530 --> 01:34:11,050
not present

1386
01:34:11,110 --> 01:34:14,670
and one would mean present

1387
01:34:14,710 --> 01:34:16,440
for instance you could see here

1388
01:34:16,440 --> 01:34:17,420
he would read

1389
01:34:17,440 --> 01:34:19,210
case one

1390
01:34:19,860 --> 01:34:21,990
not on the right

1391
01:34:23,400 --> 01:34:25,460
it is not below

1392
01:34:25,530 --> 01:34:28,990
and is not inside

1393
01:34:29,090 --> 01:34:32,360
and it has be present outcome of zero

1394
01:34:32,360 --> 01:34:34,670
absence of the outcome

1395
01:34:34,760 --> 01:34:38,420
by contrast to be taken logically opposite case

1396
01:34:38,460 --> 01:34:39,440
k seven

1397
01:34:40,090 --> 01:34:42,030
it stands on the right

1398
01:34:42,090 --> 01:34:43,440
stands below

1399
01:34:43,440 --> 01:34:45,300
stands inside

1400
01:34:45,300 --> 01:34:48,070
and displays the presence of the outcome

1401
01:34:51,650 --> 01:34:54,610
it's driving this data you are

1402
01:34:56,010 --> 01:34:58,900
both set of properties school of public space

1403
01:34:58,920 --> 01:35:00,740
and you are able to map

1404
01:35:00,800 --> 01:35:06,590
the cases in the level of the devil away in this public space

1405
01:35:06,590 --> 01:35:08,170
very simple things

1406
01:35:08,190 --> 01:35:08,860
this is

1407
01:35:08,990 --> 01:35:12,420
tableau way to present the time you see

1408
01:35:12,420 --> 01:35:13,510
and of course

1409
01:35:13,510 --> 01:35:16,610
these variables could be social science variables right

1410
01:35:16,650 --> 01:35:18,670
it is of course textbook example

1411
01:35:18,690 --> 01:35:22,780
this is also in a textbook

1412
01:35:22,840 --> 01:35:24,590
the same information

1413
01:35:24,610 --> 01:35:27,900
exactly the same can be summarized in the venn diagram

1414
01:35:27,990 --> 01:35:30,940
then diagram is produced by the just minor

1415
01:35:33,050 --> 01:35:36,460
this is just taken i just

1416
01:35:36,510 --> 01:35:37,820
coded this

1417
01:35:37,840 --> 01:35:42,920
table i got it read by the tasman software what you get

1418
01:35:42,920 --> 01:35:45,740
you get the visual representation of the same data

1419
01:35:45,740 --> 01:35:49,050
OK so hard to read this is not very real from the distance i hope

1420
01:35:49,050 --> 01:35:50,030
you can

1421
01:35:50,050 --> 01:35:54,150
graphically the basic idea

1422
01:35:55,740 --> 01:35:58,210
we have three properties rights

1423
01:35:58,210 --> 01:35:59,800
i have to go back

1424
01:35:59,800 --> 01:36:02,010
to go back is here

1425
01:36:02,150 --> 01:36:08,900
right below inside so the first properties right second is below thirty inside

1426
01:36:08,940 --> 01:36:11,460
so what the band diagram does

1427
01:36:11,510 --> 01:36:12,780
it's said that

1428
01:36:12,780 --> 01:36:18,380
the many different forms of here's a simple one there is much more complex ones

1429
01:36:18,420 --> 01:36:20,840
the first property is right

1430
01:36:22,190 --> 01:36:23,630
each property will

1431
01:36:23,650 --> 01:36:27,380
we learn cut the properties space into equal

1432
01:36:30,590 --> 01:36:33,280
or yes spaces so

1433
01:36:33,340 --> 01:36:36,050
the vertical line here

1434
01:36:36,090 --> 01:36:37,340
he is

1435
01:36:37,380 --> 01:36:39,420
this is the problem space into

1436
01:36:39,530 --> 01:36:42,380
what stands on the right-hand side over here

1437
01:36:43,550 --> 01:36:47,190
everything on the right of the vertical line has one value on the right has

1438
01:36:48,090 --> 01:36:49,610
everything on the left

1439
01:36:49,670 --> 01:36:51,490
has zero value

1440
01:36:52,940 --> 01:36:54,780
this first condition right

1441
01:36:54,820 --> 01:36:56,880
so on the right-hand side you have right

1442
01:36:56,920 --> 01:36:59,280
on the that you have no right

1443
01:36:59,280 --> 01:37:01,340
OK this left

1444
01:37:04,170 --> 01:37:05,550
it's called

1445
01:37:09,070 --> 01:37:12,340
this horizontal lines it's also private two

1446
01:37:12,400 --> 01:37:17,420
everything underneath is has one value on below this whole space here below

1447
01:37:17,460 --> 01:37:19,960
everything about has a

1448
01:37:20,010 --> 01:37:21,570
zero value on

1449
01:37:21,590 --> 01:37:22,710
this variable

1450
01:37:22,760 --> 01:37:23,720
this condition

1451
01:37:23,740 --> 01:37:25,550
it is not below

1452
01:37:25,590 --> 01:37:27,070
about right

1453
01:37:27,130 --> 01:37:29,150
below not below

1454
01:37:29,150 --> 01:37:31,300
finally you have this square here

1455
01:37:31,300 --> 01:37:34,110
across that the third property

1456
01:37:35,960 --> 01:37:37,780
everything inside the square

1457
01:37:39,090 --> 01:37:42,240
as one value on the inside variable

1458
01:37:42,300 --> 01:37:48,460
everything outside as zero value it's not inside

1459
01:37:48,590 --> 01:37:50,480
OK that's the property space

1460
01:37:50,490 --> 01:37:55,170
so you have splits the space into eight basic zones

1461
01:37:55,960 --> 01:37:58,240
three dimensions

1462
01:37:58,320 --> 01:38:00,400
and you're able to qualify

1463
01:38:00,510 --> 01:38:02,340
each one of these basic sounds

1464
01:38:02,360 --> 01:38:04,280
by combining the three

1465
01:38:04,320 --> 01:38:06,570
values so for instance let us take

1466
01:38:06,570 --> 01:38:09,990
going back to the van diagram sorry oops

1467
01:38:12,490 --> 01:38:14,210
so case one

1468
01:38:14,280 --> 01:38:18,900
it's not on the right not below not inside

1469
01:38:18,940 --> 01:38:25,480
let's just look at the conditions for time being

1470
01:38:25,490 --> 01:38:29,070
so case one indeed it is not below it is about

1471
01:38:29,110 --> 01:38:30,820
it is not on the right

1472
01:38:30,820 --> 01:38:32,300
it is on the left

1473
01:38:32,340 --> 01:38:34,280
and it's not inside

1474
01:38:34,340 --> 01:38:37,090
outside of the square so this is this

1475
01:38:37,800 --> 01:38:40,510
this is where case one is located

1476
01:38:40,530 --> 01:38:43,990
and so on and so forth

1477
01:38:44,050 --> 01:38:47,650
the second of information which is then in diagram

1478
01:38:47,670 --> 01:38:49,150
it conveys or

1479
01:38:50,530 --> 01:38:52,460
it contains

1480
01:38:52,530 --> 01:38:55,280
is the value of the outcome

1481
01:38:55,300 --> 01:38:57,920
so the dark shaded areas

1482
01:38:59,480 --> 01:39:02,300
this whole area with dark shaded area

1483
01:39:02,900 --> 01:39:06,130
and the zero value for the outcome

1484
01:39:06,130 --> 01:39:08,570
in this area here

1485
01:39:08,610 --> 01:39:10,440
the light shaded area

1486
01:39:10,480 --> 01:39:11,380
if the area

1487
01:39:11,400 --> 01:39:17,820
where you have a one outcome value

1488
01:39:17,940 --> 01:39:20,030
could someone please tell me

1489
01:39:20,090 --> 01:39:23,090
or express in another way

1490
01:39:23,090 --> 01:39:24,340
the area

1491
01:39:24,340 --> 01:39:28,940
where they one outcome is observed

1492
01:39:29,010 --> 01:39:35,090
one outcome so that the lighted area here

1493
01:39:35,090 --> 01:39:39,590
once in the content

1494
01:39:46,460 --> 01:39:49,670
that's part of it right

1495
01:39:49,710 --> 01:39:51,030
it is on the right

1496
01:39:52,210 --> 01:40:00,490
yes it is below and inside so is this one as k seven right

1497
01:40:04,590 --> 01:40:05,590
that's great

1498
01:40:05,610 --> 01:40:08,840
when you have performed the first ascent by yourself

1499
01:40:10,030 --> 01:40:12,840
because indeed there are two ways to express this area

1500
01:40:12,980 --> 01:40:14,880
there's a long way

1501
01:40:14,900 --> 01:40:16,480
they're always saying

1502
01:40:16,490 --> 01:40:17,960
well it is

1503
01:40:17,980 --> 01:40:19,300
this area

1504
01:40:19,360 --> 01:40:20,840
plus this area

1505
01:40:20,860 --> 01:40:24,320
right so we do everything that is on the right

1506
01:40:24,550 --> 01:40:27,670
below and inside this one k seven

1507
01:40:27,840 --> 01:40:29,010
it's also

1508
01:40:29,030 --> 01:40:30,900
what is on the right

1509
01:40:30,920 --> 01:40:33,940
and below and outside so case number eight

1510
01:40:33,990 --> 01:40:35,630
that's a long way

1511
01:40:35,630 --> 01:40:36,690
that's the complex

1512
01:40:36,690 --> 01:40:39,780
a way to express this area

1513
01:40:39,860 --> 01:40:41,510
that's what stands in the truth table

1514
01:40:43,150 --> 01:40:45,130
what you see does actually

1515
01:40:45,150 --> 01:40:48,090
is to try to express this area

1516
01:40:48,110 --> 01:40:49,800
in the shorthand man

1517
01:40:49,840 --> 01:40:50,960
it's called

1518
01:40:52,990 --> 01:40:54,840
it's a synthesis of information

1519
01:40:54,900 --> 01:40:56,670
doesn't change anything data

1520
01:40:56,720 --> 01:40:59,940
you simply learn how to express this in the shorter

1521
01:41:01,550 --> 01:41:04,550
and indeed the shortest way to express this area

1522
01:41:04,550 --> 01:41:07,560
and this has to have the density with respect to some

1523
01:41:07,620 --> 01:41:09,760
measure which need not be a probability measure

1524
01:41:09,800 --> 01:41:12,300
could be that measure which is not a probability measure

1525
01:41:12,380 --> 01:41:16,540
it has to be the same for all values of

1526
01:41:28,620 --> 01:41:30,850
good and

1527
01:41:30,870 --> 01:41:34,530
this is something that a kind of mentioned last time introduction but i would like

1528
01:41:35,170 --> 01:41:36,780
just restate that

1529
01:41:37,030 --> 01:41:39,480
so when i'm talking about

1530
01:41:39,500 --> 01:41:41,730
a nonparametric bayesian model here

1531
01:41:41,770 --> 01:41:45,210
and i'm talking about bayesian model just as on the last slide which might may

1532
01:41:45,210 --> 01:41:47,050
or may not be equation

1533
01:41:48,930 --> 01:41:53,530
what i assume is that both the parameter space and the observation space have

1534
01:41:53,580 --> 01:41:55,980
i have infinite dimension

1535
01:42:00,680 --> 01:42:04,040
this might for example be in the case of of the dirichlet process

1536
01:42:04,070 --> 01:42:06,690
where the process starts the prior

1537
01:42:06,690 --> 01:42:11,650
this you would be this parameter space would be the set of probability measures

1538
01:42:11,900 --> 01:42:15,500
actually subset of discrete probability

1539
01:42:16,430 --> 01:42:20,010
the the the random value that grow from the dirichlet process is what we call

1540
01:42:20,010 --> 01:42:25,230
the parameters not the parameters of the dirichlet process suppose would be the hyperparameters basis

1541
01:42:29,980 --> 01:42:33,300
the the second the second assumption that we have to make is if we if

1542
01:42:33,320 --> 01:42:36,480
we define nonparametric models in this way that we say OK

1543
01:42:36,530 --> 01:42:38,800
we want to accommodate in

1544
01:42:38,810 --> 01:42:42,940
a finite but arbitrary large number of parameters and so we use an infinite an

1545
01:42:42,940 --> 01:42:44,630
infinite dimensional space

1546
01:42:44,630 --> 01:42:46,710
then we need to have some way of

1547
01:42:46,760 --> 01:42:51,580
of actually evaluating the small do what we usually do with models either put probability

1548
01:42:51,580 --> 01:42:55,550
on something or condition something if we only have a partial observations we have only

1549
01:42:55,550 --> 01:42:59,040
seen a finite subset of this infinite

1550
01:42:59,130 --> 01:43:02,200
infinitely many degrees of freedom so for example

1551
01:43:03,370 --> 01:43:07,480
if you think of the gaussian process prior parameters something like like function or draw

1552
01:43:07,510 --> 01:43:09,740
function for the girls process priors

1553
01:43:09,740 --> 01:43:13,450
what we actually observe is not this function the whole function at each individual point

1554
01:43:13,450 --> 01:43:17,870
of the on the real line but it's something like a few points and we

1555
01:43:17,870 --> 01:43:21,100
assume that these values generated by this function

1556
01:43:21,150 --> 01:43:24,620
and so we have to be need to have some rule how we have we

1557
01:43:24,720 --> 01:43:31,020
we can substitute this subsample this discretisation fine discretisation of our function into the probability

1558
01:43:31,060 --> 01:43:34,660
model that we have and usually this involves

1559
01:43:34,880 --> 01:43:37,820
in some way or another integrating out

1560
01:43:37,840 --> 01:43:39,480
the remaining degrees of freedom

1561
01:43:41,870 --> 01:43:44,830
so that's what i call the partial observations of the random quantity we have has

1562
01:43:44,870 --> 01:43:46,890
the dimensions

1563
01:43:46,900 --> 01:43:48,520
he might be infinite

1564
01:43:48,540 --> 01:43:53,970
and only m of these are which some smaller number of pieces of

1565
01:43:54,000 --> 01:43:59,010
but conceivably this might also be like the is is something large but finite ten

1566
01:43:59,010 --> 01:44:00,430
thousand or something

1567
01:44:00,430 --> 01:44:04,240
and we observe only a few of those who i have never seen a nonparametric

1568
01:44:15,190 --> 01:44:26,000
we use the word is used

1569
01:44:56,740 --> 01:44:59,510
so this year

1570
01:44:59,530 --> 01:45:03,530
is you mean that we once we have a condition on on the sampling model

1571
01:45:03,530 --> 01:45:06,910
and we say something about the part of the posterior prior is that is that

1572
01:45:06,910 --> 01:45:07,880
the question

1573
01:45:07,880 --> 01:45:12,380
OK so

1574
01:45:12,400 --> 01:45:14,570
for this to exist at all

1575
01:45:14,740 --> 01:45:17,620
for me to make sense by the of here

1576
01:45:17,630 --> 01:45:19,780
the existence of densities

1577
01:45:19,810 --> 01:45:24,530
you need to have that the posterior is absolutely continuous with respect to the prior

1578
01:45:25,270 --> 01:45:26,870
so you you need this year

1579
01:45:26,870 --> 01:45:31,710
and this year is is a stronger condition which implies

1580
01:45:32,780 --> 01:45:34,200
so that means we have to

1581
01:45:34,200 --> 01:45:37,180
it's very convenient because this is all we have to cheque you don't have to

1582
01:45:37,180 --> 01:45:38,850
explicitly check

1583
01:45:38,910 --> 01:45:40,540
the posterior prime

1584
01:45:42,150 --> 01:45:46,890
we could have an expression like this conceivably we could have an expression like this

1585
01:45:46,890 --> 01:45:52,040
even if this this expression of this restriction is not satisfied

1586
01:45:53,240 --> 01:45:56,410
but but this is really a where where this breaks down

1587
01:45:57,560 --> 01:46:07,170
OK and any questions on that before we move on to

1588
01:46:07,190 --> 01:46:11,100
stochastic process construction

1589
01:46:16,680 --> 01:46:18,130
when we when want to

1590
01:46:18,630 --> 01:46:21,430
when we want to do the bayesian nonparametrics in the sense that we put a

1591
01:46:21,430 --> 01:46:24,230
probability distributions on infinite dimensional spaces

1592
01:46:24,240 --> 01:46:29,550
then we need some way to define the probability distribution and this is why why

1593
01:46:29,550 --> 01:46:32,680
so these mk had almost

1594
01:46:33,970 --> 01:46:37,030
so there and appended the the

1595
01:46:37,120 --> 01:46:42,600
you look at the k nearest neighbors right there certainly highly dependent

1596
01:46:42,720 --> 01:46:45,050
but they n over k

1597
01:46:45,100 --> 01:46:48,070
things left each of those things are very is one of k

1598
01:46:48,070 --> 01:46:50,840
and if they were independent you get is one right

1599
01:46:50,890 --> 01:46:55,260
and in fact you can show

1600
01:46:59,370 --> 01:47:03,570
let's see i what fifteen more minutes ten minutes

1601
01:47:05,280 --> 01:47:09,760
seven OK alright well i guess i will get to some of the stuff but

1602
01:47:10,970 --> 01:47:13,740
i think this is appointed really has to be made

1603
01:47:13,740 --> 01:47:18,450
it's appointed we saw empirically but but but which actually

1604
01:47:18,470 --> 01:47:20,870
after we sort empirically we

1605
01:47:20,890 --> 01:47:23,490
we realized what was happening

1606
01:47:23,530 --> 01:47:27,100
we thought oh gee you've got a real as the dimension it works very well

1607
01:47:27,100 --> 01:47:29,780
as you see for dimensions up to

1608
01:47:30,410 --> 01:47:31,720
fifteen or so

1609
01:47:32,470 --> 01:47:35,010
five thousand observations

1610
01:47:35,050 --> 01:47:40,990
and we said well you know this let's push up let's make the dimension higher

1611
01:47:41,050 --> 01:47:43,490
the dimension

1612
01:47:43,580 --> 01:47:46,300
basically it went unanswered

1613
01:47:46,300 --> 01:47:50,450
so under you grossly underestimated

1614
01:47:50,510 --> 01:47:52,140
and the reason for that

1615
01:47:52,160 --> 01:47:56,390
to see why that's happening it's not solely reflects the theory so far

1616
01:47:56,410 --> 01:48:00,430
to see what happening i think is that the person dimensionality still have something

1617
01:48:00,470 --> 01:48:03,180
if you do asymptotic variance something you should

1618
01:48:03,200 --> 01:48:06,800
as you know both the dimension go to infinity and the sample size for me

1619
01:48:06,840 --> 01:48:10,550
that tells you how big is the sample size b

1620
01:48:10,570 --> 01:48:13,140
i have to be in order for you to

1621
01:48:13,180 --> 01:48:15,350
to get a reasonable estimate of dimension

1622
01:48:15,390 --> 01:48:18,760
well it turns out unfortunately well this is looks horrible but let me just tell

1623
01:48:19,910 --> 01:48:23,850
that the sample size has to be of the order of

1624
01:48:23,910 --> 01:48:28,140
dimension divided by two factorial

1625
01:48:28,180 --> 01:48:33,910
this is very bad at super exponential convergence

1626
01:48:33,950 --> 01:48:35,820
so basically

1627
01:48:35,870 --> 01:48:39,300
essentially what that says is that unless you have sample sizes which

1628
01:48:39,340 --> 01:48:42,470
and are absurd even in these days

1629
01:48:44,140 --> 01:48:46,010
we should really trust dimensions over

1630
01:48:46,010 --> 01:48:47,890
o twenty

1631
01:48:47,910 --> 01:48:51,840
yes some of the trigger

1632
01:48:51,850 --> 01:48:53,760
and i believe this is not simply

1633
01:48:53,820 --> 01:48:55,760
a floor of our method

1634
01:48:55,800 --> 01:48:57,010
it's the floor

1635
01:48:57,100 --> 01:49:00,680
it's actually a problem with any method of estimating dimension

1636
01:49:00,680 --> 01:49:01,870
not linearly

1637
01:49:01,870 --> 01:49:03,870
because what happens is

1638
01:49:04,800 --> 01:49:06,890
all of these calculations rely

1639
01:49:08,450 --> 01:49:10,620
the nearest neighbour to appointing

1640
01:49:13,720 --> 01:49:16,890
in high dimension the nearest neighbour actually very far

1641
01:49:17,740 --> 01:49:18,910
you never less

1642
01:49:18,910 --> 01:49:20,890
the sample size

1643
01:49:20,970 --> 01:49:31,140
is of an order larger than the over two factorial the nearest neighbour distance doesn't

1644
01:49:31,140 --> 01:49:34,180
it was

1645
01:49:34,200 --> 01:49:39,560
some of this idea as

1646
01:49:48,720 --> 01:49:53,180
one will have

1647
01:49:56,760 --> 01:49:58,350
you know

1648
01:49:58,350 --> 01:50:00,430
it's a

1649
01:50:06,330 --> 01:50:11,660
it was

1650
01:50:16,760 --> 01:50:23,950
one of the

1651
01:50:27,810 --> 01:50:31,470
it's is going to be

1652
01:50:42,260 --> 01:50:45,370
i it

1653
01:51:25,470 --> 01:51:29,810
so we can

1654
01:51:31,850 --> 01:51:34,350
i thing

1655
01:51:41,160 --> 01:51:43,240
it's not

1656
01:51:43,370 --> 01:51:45,510
the of

1657
01:51:56,200 --> 01:52:00,040
one the

1658
01:52:16,220 --> 01:52:16,890
if you

1659
01:52:22,290 --> 01:52:26,810
it to be

1660
01:52:34,220 --> 01:52:38,600
i would like to say

1661
01:52:42,990 --> 01:52:45,850
for us

1662
01:52:57,560 --> 01:53:03,560
o four

1663
01:53:37,470 --> 01:53:46,220
what i want

1664
01:54:08,560 --> 01:54:29,490
if you wish to first

1665
01:54:36,470 --> 01:54:37,410
it was

1666
01:55:24,720 --> 01:55:32,430
that's what

1667
01:55:32,430 --> 01:55:34,310
i mean

1668
01:57:08,390 --> 01:57:13,790
he e

1669
01:57:13,790 --> 01:57:22,570
this is a list of

1670
01:57:28,920 --> 01:57:34,770
she just

1671
01:57:49,890 --> 01:57:55,210
yes she

1672
01:58:08,780 --> 01:58:11,500
she yes

1673
01:58:11,510 --> 01:58:15,460
she was here

1674
01:58:28,490 --> 01:58:36,560
she she

1675
01:58:36,590 --> 01:58:43,300
she she

1676
01:58:43,340 --> 01:58:49,600
it is

1677
01:58:49,900 --> 01:58:59,040
and the

1678
01:59:03,490 --> 01:59:09,030
it was

1679
01:59:18,720 --> 01:59:21,050
what do due

1680
01:59:24,000 --> 01:59:29,750
i also made by the

1681
02:00:03,930 --> 02:00:14,740
she was

1682
02:00:17,480 --> 02:00:23,280
this is all this year

1683
02:00:31,700 --> 02:00:35,180
these are

1684
02:01:17,760 --> 02:01:26,010
o five

1685
02:02:21,130 --> 02:02:24,800
as you

1686
02:02:27,540 --> 02:02:30,060
all in all

1687
02:02:30,060 --> 02:02:31,790
so before the break

1688
02:02:33,500 --> 02:02:35,400
well somebody as well

1689
02:02:35,420 --> 02:02:36,950
now what happens

1690
02:02:36,960 --> 02:02:38,950
why is this quantity

1691
02:02:38,960 --> 02:02:40,710
but we're getting here

1692
02:02:40,730 --> 02:02:44,790
whether that's always nonnegative

1693
02:02:45,650 --> 02:02:49,180
this is obviously not the case

1694
02:02:49,190 --> 02:02:51,450
and actually we don't want it to be the case

1695
02:02:52,400 --> 02:02:54,970
see what we want to set p equals q

1696
02:02:55,150 --> 02:02:59,220
this is a random variable with expected value zero

1697
02:02:59,260 --> 02:03:02,310
because of people q we want to have a statistic that

1698
02:03:02,360 --> 02:03:05,260
well i will tell us the distance sierra

1699
02:03:05,270 --> 02:03:08,780
we want to really is to make the distance between p and q

1700
02:03:08,800 --> 02:03:10,510
therefore obviously

1701
02:03:10,520 --> 02:03:13,560
if you had a random variable which was always nonnegative

1702
02:03:13,660 --> 02:03:15,320
you would be

1703
02:03:15,360 --> 02:03:19,490
rather missus situation trying to estimate whether people skills

1704
02:03:19,540 --> 02:03:22,210
based on that

1705
02:03:23,270 --> 02:03:27,770
so that's what we've done is we've found a way

1706
02:03:28,620 --> 02:03:29,960
getting the mean

1707
02:03:29,990 --> 02:03:34,640
of that statistic right

1708
02:03:34,650 --> 02:03:36,300
so that means

1709
02:03:36,330 --> 02:03:38,180
if we have some data

1710
02:03:38,190 --> 02:03:39,500
x and y

1711
02:03:43,180 --> 02:03:44,670
that's was serious

1712
02:03:44,740 --> 02:03:47,030
and we might observe some values here

1713
02:03:47,180 --> 02:03:51,230
and then

1714
02:03:51,240 --> 02:03:53,620
all we need to do is

1715
02:03:53,660 --> 02:03:55,910
just put the threshold somewhere

1716
02:03:55,920 --> 02:03:58,790
and we say everything up here

1717
02:03:58,850 --> 02:04:00,790
means p is not equal to q

1718
02:04:00,800 --> 02:04:02,560
everything down there

1719
02:04:02,580 --> 02:04:04,150
it's all right

1720
02:04:04,160 --> 02:04:08,750
and then for the distribution with zero mean

1721
02:04:08,800 --> 02:04:12,000
and it turns out that this is actually asymptotically normal

1722
02:04:12,010 --> 02:04:13,550
that quantity here

1723
02:04:13,560 --> 02:04:18,900
so the probability mass of this these events is going to tell you exactly what

1724
02:04:18,900 --> 02:04:22,390
the error of taste

1725
02:04:22,450 --> 02:04:26,100
so we want this probability mass here to be in the order five percent or

1726
02:04:27,280 --> 02:04:31,560
depending on how conservative for want my case

1727
02:04:32,870 --> 02:04:34,660
what we have to do it

1728
02:04:34,670 --> 02:04:36,420
will have to find out

1729
02:04:36,470 --> 02:04:39,130
we we want to set a threshold

1730
02:04:39,180 --> 02:04:42,600
we want to get this point here

1731
02:04:42,660 --> 02:04:45,900
the next two slides are all concerned about getting this

1732
02:04:45,910 --> 02:04:47,910
right threshold

1733
02:04:47,930 --> 02:04:51,210
after me

1734
02:04:51,220 --> 02:04:55,700
now we want to get to scale

1735
02:04:56,100 --> 02:05:00,640
before we do so let me just give you a simple example

1736
02:05:00,700 --> 02:05:01,610
what the

1737
02:05:01,630 --> 02:05:04,530
and he actually does

1738
02:05:04,540 --> 02:05:06,010
so let's say b

1739
02:05:06,020 --> 02:05:08,520
this line is the normal distribution

1740
02:05:08,650 --> 02:05:10,070
and the dotted line

1741
02:05:10,080 --> 02:05:12,810
so the class distribution

1742
02:05:13,790 --> 02:05:16,470
that's gonna computed

1743
02:05:16,480 --> 02:05:17,960
well the function

1744
02:05:17,970 --> 02:05:21,140
that maximizes the discrepancy in the means

1745
02:05:21,190 --> 02:05:24,600
and that's the function here

1746
02:05:24,660 --> 02:05:26,320
so you can see

1747
02:05:26,340 --> 02:05:30,110
with the class distributions larger than the normal distribution

1748
02:05:30,120 --> 02:05:32,730
the that is very large

1749
02:05:32,880 --> 02:05:34,920
very easy be around

1750
02:05:34,940 --> 02:05:37,400
three negative

1751
02:05:37,450 --> 02:05:41,920
but obviously we want this function to be reasonably smart

1752
02:05:41,970 --> 02:05:42,990
and that's why

1753
02:05:43,000 --> 02:05:47,650
it doesn't just jump

1754
02:05:48,350 --> 02:05:50,390
so this is

1755
02:05:50,430 --> 02:05:51,720
what the

1756
02:05:51,760 --> 02:05:54,950
maximum mean discrepancy will give you

1757
02:05:58,650 --> 02:06:00,650
now the really cool thing is

1758
02:06:00,700 --> 02:06:03,900
in order to get all those bounds we don't have to do any work because

1759
02:06:03,900 --> 02:06:05,690
shifting has done all the work for us

1760
02:06:05,800 --> 02:06:09,140
so in particular what he showed is that

1761
02:06:09,190 --> 02:06:12,630
for the kernel of a u statistic so not to be confused with the past

1762
02:06:12,660 --> 02:06:13,830
windows kernel

1763
02:06:13,880 --> 02:06:15,180
well the massacre

1764
02:06:15,380 --> 02:06:18,740
this thing is also called the crown

1765
02:06:18,750 --> 02:06:21,690
the fact that is bounded by are

1766
02:06:21,780 --> 02:06:23,150
then the probability

1767
02:06:23,180 --> 02:06:26,660
that its expectation which will give us the

1768
02:06:27,540 --> 02:06:30,180
true the distance between distributions

1769
02:06:30,400 --> 02:06:32,570
minus the empirical estimate

1770
02:06:32,620 --> 02:06:35,210
the probability that this exceeds epsilon

1771
02:06:35,260 --> 02:06:36,800
it is less equal than

1772
02:06:36,820 --> 02:06:42,720
two times e to the minus in its own square or square

1773
02:06:42,740 --> 02:06:45,620
so that means that they get more data


1
00:00:00,000 --> 00:00:04,910
remember in the course

2
00:00:04,920 --> 00:00:06,200
we measured

3
00:00:06,210 --> 00:00:08,270
the average speed of the bullet which we

4
00:00:08,280 --> 00:00:10,390
fired from a rifle

5
00:00:10,450 --> 00:00:12,370
that was because we had

6
00:00:12,380 --> 00:00:15,050
the ability of very fast time

7
00:00:15,060 --> 00:00:17,250
in the old days

8
00:00:17,250 --> 00:00:19,050
fast timing was not possible

9
00:00:19,070 --> 00:00:23,390
and people measure the speed of bought in very delicate way

10
00:00:23,390 --> 00:00:26,020
and all the tools that we have learned

11
00:00:26,070 --> 00:00:27,480
we can apply now

12
00:00:27,480 --> 00:00:29,110
to this

13
00:00:29,160 --> 00:00:30,880
device which we call

14
00:00:30,930 --> 00:00:32,840
the ballistic pendulum

15
00:00:32,920 --> 00:00:41,120
where the pendulum

16
00:00:41,160 --> 00:00:42,590
this is very

17
00:00:42,630 --> 00:00:46,200
heavy object hanging you at the end i call it the block

18
00:00:46,260 --> 00:00:48,660
you see here

19
00:00:48,700 --> 00:00:50,730
and this page and has length l

20
00:00:50,730 --> 00:00:52,660
ours is about one meter

21
00:00:52,690 --> 00:00:55,240
i will give you the exact numbers later

22
00:00:55,260 --> 00:00:57,800
and we have aborted

23
00:00:57,810 --> 00:00:59,700
one of my little

24
00:00:59,730 --> 00:01:00,660
and aborted

25
00:01:00,670 --> 00:01:02,770
comes in with velocity v

26
00:01:03,700 --> 00:01:05,410
that's completely absorbed

27
00:01:05,420 --> 00:01:06,750
sticks in there

28
00:01:06,770 --> 00:01:09,060
it's a completely inelastic collision

29
00:01:09,090 --> 00:01:11,190
and the

30
00:01:12,430 --> 00:01:13,800
real then pick up

31
00:01:13,910 --> 00:01:17,110
velocity v prime was the inside

32
00:01:17,110 --> 00:01:18,420
but it is somewhere here

33
00:01:18,530 --> 00:01:22,830
momentum is conserved

34
00:01:22,880 --> 00:01:25,020
so we clearly have

35
00:01:27,730 --> 00:01:32,780
equals and plus and times

36
00:01:32,860 --> 00:01:35,720
the prime

37
00:01:35,730 --> 00:01:38,310
so if you could measure the prime

38
00:01:38,330 --> 00:01:40,250
then you could measure the

39
00:01:40,330 --> 00:01:41,610
speed of the bullet

40
00:01:41,620 --> 00:01:43,610
which is the

41
00:01:43,610 --> 00:01:45,880
how do we measure b prime

42
00:01:47,020 --> 00:01:49,360
we wait for the kind

43
00:01:49,380 --> 00:01:50,340
to come

44
00:01:50,360 --> 00:01:51,840
to hold

45
00:01:51,890 --> 00:01:53,560
let's see here

46
00:01:55,170 --> 00:01:57,110
the speed is zero

47
00:01:57,160 --> 00:01:59,590
when it was here

48
00:01:59,610 --> 00:02:00,860
you had a speed

49
00:02:00,910 --> 00:02:02,950
the prime

50
00:02:03,810 --> 00:02:05,620
we know that there was

51
00:02:05,670 --> 00:02:08,530
kinetic energy here

52
00:02:10,750 --> 00:02:13,510
gravitational potential energy i can call this level

53
00:02:13,530 --> 00:02:15,160
you equals zero

54
00:02:15,250 --> 00:02:17,690
right here

55
00:02:17,780 --> 00:02:19,280
this difference

56
00:02:19,340 --> 00:02:23,960
in height is h and all the kinetic energy has been converted to

57
00:02:24,030 --> 00:02:28,780
gravitational potential energy so we apply the

58
00:02:28,840 --> 00:02:29,840
theorem the

59
00:02:29,840 --> 00:02:33,180
work energy theorem or you could say it's equally

60
00:02:34,500 --> 00:02:37,820
you could say we apply to conservation of mechanical energy

61
00:02:37,880 --> 00:02:39,840
and so this

62
00:02:39,850 --> 00:02:42,720
kinetic energy which is one half

63
00:02:44,250 --> 00:02:46,290
plus and

64
00:02:46,340 --> 00:02:48,100
and the prime squared

65
00:02:48,190 --> 00:02:52,430
is now converted exclusively to gravitational potential energy

66
00:02:52,440 --> 00:02:54,720
which equals and and

67
00:02:54,740 --> 00:02:58,910
times g times age

68
00:02:58,910 --> 00:03:01,590
and we lose our employees and

69
00:03:01,650 --> 00:03:02,940
so the prime

70
00:03:02,970 --> 00:03:04,190
will be described route

71
00:03:04,220 --> 00:03:05,690
of two g h

72
00:03:06,220 --> 00:03:08,910
so all you would have to measure h and then you know the prime and

73
00:03:08,940 --> 00:03:10,160
if you know the prime

74
00:03:10,260 --> 00:03:12,190
you know the speed of the bullet

75
00:03:12,190 --> 00:03:13,000
but life

76
00:03:13,010 --> 00:03:15,620
it's not that simple

77
00:03:15,660 --> 00:03:19,040
it's very difficult to measure h and i can make you see that

78
00:03:19,070 --> 00:03:20,900
suppose this angle

79
00:03:20,940 --> 00:03:22,880
angle theta

80
00:03:22,900 --> 00:03:25,030
when it comes to a halt

81
00:03:25,070 --> 00:03:26,590
is only two degrees

82
00:03:26,690 --> 00:03:31,030
then h

83
00:03:31,040 --> 00:03:35,060
which is l times one minus cosine fade

84
00:03:35,120 --> 00:03:37,060
is only

85
00:03:37,070 --> 00:03:38,900
o point six

86
00:03:40,370 --> 00:03:43,470
forty dimensions that i have chosen

87
00:03:43,510 --> 00:03:45,440
falling one

88
00:03:45,680 --> 00:03:48,340
that's it you can even see it it's invisible

89
00:03:48,340 --> 00:03:52,410
that alone that you can measure to any degree of accuracy

90
00:03:52,470 --> 00:03:54,720
so what are we going to do now

91
00:03:56,070 --> 00:03:57,720
we are going to

92
00:03:57,760 --> 00:03:59,340
not measure

93
00:04:00,400 --> 00:04:02,290
but we are going to measure

94
00:04:03,910 --> 00:04:06,470
i call this actually falls zero

95
00:04:06,760 --> 00:04:08,940
and here the

96
00:04:08,940 --> 00:04:10,740
and then comes to a halt

97
00:04:10,810 --> 00:04:11,970
i call that

98
00:04:13,620 --> 00:04:14,870
four two degrees

99
00:04:17,940 --> 00:04:19,500
it is approximately

100
00:04:19,560 --> 00:04:21,330
three and a half centimetres

101
00:04:21,350 --> 00:04:23,870
can easily be checked by you've course

102
00:04:23,880 --> 00:04:27,000
you get a huge displacement in this direction compared

103
00:04:27,080 --> 00:04:29,830
two h

104
00:04:29,880 --> 00:04:34,900
if you use small angle approximation you better believe it two degrees is very small

105
00:04:34,930 --> 00:04:39,170
then you can prove which is purely geometrical

106
00:04:39,190 --> 00:04:42,230
mathematics and i view is that proof

107
00:04:42,390 --> 00:04:44,210
this is approximately

108
00:04:44,750 --> 00:04:45,940
x squared

109
00:04:45,950 --> 00:04:48,670
divided by two l

110
00:04:48,710 --> 00:04:50,560
i want you to prove that

111
00:04:50,560 --> 00:04:53,400
you take the expansion of cosine

112
00:04:53,430 --> 00:04:55,230
a series of the taylor series

113
00:04:55,270 --> 00:05:00,210
and you cut off somewhere and this is not too difficult to prove

114
00:05:00,300 --> 00:05:02,430
in other words

115
00:05:02,480 --> 00:05:05,100
the prime square and

116
00:05:06,300 --> 00:05:07,900
o two g h

117
00:05:07,990 --> 00:05:11,370
can now be replaced by approximately

118
00:05:11,400 --> 00:05:12,290
two g

119
00:05:12,300 --> 00:05:14,750
times x great divided by two l

120
00:05:14,800 --> 00:05:15,670
which is g

121
00:05:15,740 --> 00:05:17,690
times x

122
00:05:17,750 --> 00:05:20,440
divided by l

123
00:05:20,490 --> 00:05:23,230
and so the velocity of the

124
00:05:27,740 --> 00:05:29,040
which is

125
00:05:29,120 --> 00:05:32,110
and plays and

126
00:05:32,120 --> 00:05:33,870
divided by

127
00:05:33,930 --> 00:05:35,000
i bring the

128
00:05:35,060 --> 00:05:36,140
down there

129
00:05:36,210 --> 00:05:37,770
times b prime

130
00:05:37,820 --> 00:05:39,060
b prime

131
00:05:39,170 --> 00:05:40,000
is no

132
00:05:40,010 --> 00:05:41,490
the square root of this

133
00:05:41,500 --> 00:05:43,010
so i got next here

134
00:05:43,010 --> 00:05:43,880
we map into this

135
00:05:44,300 --> 00:05:45,910
as i mentioned space

136
00:05:46,380 --> 00:05:47,680
we which is a pretty common

137
00:05:48,340 --> 00:05:49,200
entered the party

138
00:05:50,130 --> 00:05:55,260
so for instance from these pages sixty six these images sixteen sixteen if we want

139
00:05:55,280 --> 00:05:58,410
to look at product of all five which turns out to be a reasonable

140
00:05:59,010 --> 00:06:02,280
number that will working in attendance space

141
00:06:03,340 --> 00:06:03,660
so now

142
00:06:04,140 --> 00:06:04,660
we know

143
00:06:05,200 --> 00:06:08,680
that we can work such a space is we control the capacity but we still have

144
00:06:09,260 --> 00:06:12,430
computational problems are doing this in practice and that's is

145
00:06:13,200 --> 00:06:14,130
the trick comes in

146
00:06:14,910 --> 00:06:19,180
and the trick is very easy one is are used all machine learning

147
00:06:19,880 --> 00:06:21,380
the first of all the simple case

148
00:06:21,840 --> 00:06:22,700
dimensionality to

149
00:06:23,630 --> 00:06:25,240
the products of two

150
00:06:26,320 --> 00:06:26,720
so that's

151
00:06:27,090 --> 00:06:28,380
he actually due to slides ago

152
00:06:29,090 --> 00:06:31,400
so it take two points x and x prime

153
00:06:31,880 --> 00:06:33,380
each point gets mapped to this

154
00:06:33,860 --> 00:06:35,530
that's all about what to

155
00:06:37,910 --> 00:06:39,220
the first point seven point

156
00:06:40,160 --> 00:06:43,090
we compute the standard dot product between these three dimensional vectors

157
00:06:43,720 --> 00:06:44,140
and the

158
00:06:44,360 --> 00:06:45,740
in terms of this work

159
00:06:46,050 --> 00:06:47,990
square root of two comes from turns out to be

160
00:06:48,430 --> 00:06:48,990
well we know that

161
00:06:49,720 --> 00:06:53,570
comes out this it's just the square of the original product

162
00:06:54,430 --> 00:06:57,360
so we can compute this dot product in high dimensions

163
00:06:57,430 --> 00:06:58,780
space by simply taking the

164
00:06:59,410 --> 00:07:00,110
in the input space

165
00:07:00,800 --> 00:07:01,910
recipient of two

166
00:07:02,400 --> 00:07:03,820
so in this case we don't see much

167
00:07:04,700 --> 00:07:05,610
but of course in the

168
00:07:09,660 --> 00:07:10,860
products we can save a lot

169
00:07:12,490 --> 00:07:13,630
we can see this as follows

170
00:07:14,340 --> 00:07:16,490
let's just take the product the product

171
00:07:17,910 --> 00:07:19,280
between two images vehicles

172
00:07:20,010 --> 00:07:21,110
and raise the whole thing

173
00:07:22,030 --> 00:07:23,360
so this gives us this

174
00:07:23,970 --> 00:07:29,180
expression we multiply also we get these sums over here with sixty one

175
00:07:30,760 --> 00:07:35,320
but here we just saw terms everything in axis here within prime here

176
00:07:36,320 --> 00:07:38,590
and what you can see that this is just the product

177
00:07:39,430 --> 00:07:41,840
in this representation so this is like

178
00:07:43,340 --> 00:07:48,280
these are all possible products already have copied x this is simply prime

179
00:07:49,090 --> 00:07:51,800
and this is just some in high dimensional space

180
00:07:52,970 --> 00:07:54,010
so this is just

181
00:07:54,410 --> 00:07:57,820
some or all of them so this is basically nothing but the product

182
00:07:59,930 --> 00:08:01,700
after the mapping phi where phi

183
00:08:03,490 --> 00:08:05,220
this is an input vector x

184
00:08:05,630 --> 00:08:07,320
produces operator overloading

185
00:08:07,990 --> 00:08:09,260
o course makes

186
00:08:10,760 --> 00:08:14,820
in almost all products some products will appear multiple times

187
00:08:15,740 --> 00:08:18,720
that's why we have this we ought to in the previous case

188
00:08:21,050 --> 00:08:22,160
okay so we can compute

189
00:08:23,160 --> 00:08:27,320
the product in the space spanned by all ordered products of tonality

190
00:08:27,970 --> 00:08:28,570
simply by

191
00:08:28,990 --> 00:08:31,990
the product in the input space and raise into the party

192
00:08:33,550 --> 00:08:33,880
and there

193
00:08:36,220 --> 00:08:40,380
so typically this is not generalize one can generalize this

194
00:08:40,800 --> 00:08:42,450
this is the finite dimensional space

195
00:08:43,380 --> 00:08:45,800
we enter the policy dimensions you want

196
00:08:47,050 --> 00:08:49,220
this infinite dimensional space as well end

197
00:08:50,180 --> 00:08:54,410
this was typically motivated using something called the theorem the

198
00:08:55,160 --> 00:08:55,680
so far

199
00:08:56,090 --> 00:08:57,590
here in functional analysis

200
00:08:59,070 --> 00:09:01,200
which briefly show you because i think

201
00:09:02,470 --> 00:09:04,740
it's nice to do it in terms of something

202
00:09:05,220 --> 00:09:06,880
called positive definite kernels

203
00:09:09,030 --> 00:09:11,910
this is this is a theorem which tells you something about

204
00:09:13,720 --> 00:09:16,760
because of individual operators which has certain

205
00:09:17,340 --> 00:09:18,930
positive definiteness property

206
00:09:19,570 --> 00:09:20,780
if this property holds true

207
00:09:21,380 --> 00:09:24,490
we can expand this kind of the posteriors are

208
00:09:25,280 --> 00:09:26,990
the whole series is a series

209
00:09:27,610 --> 00:09:29,530
in terms i functions and i mean

210
00:09:30,010 --> 00:09:30,840
functions is

211
00:09:31,360 --> 00:09:33,240
we i can values that are negative

212
00:09:33,720 --> 00:09:34,220
due to this

213
00:09:35,470 --> 00:09:36,740
the positivity condition

214
00:09:37,510 --> 00:09:39,930
and then from this series we can construct

215
00:09:40,360 --> 00:09:41,300
they mapping

216
00:09:42,110 --> 00:09:47,220
into a feature space that looks like this remember these things and you can make a square root

217
00:09:47,990 --> 00:09:48,760
uh and then

218
00:09:49,200 --> 00:09:51,630
we can construct this mapping the mapping such that if we

219
00:09:52,110 --> 00:09:54,470
take the dot product between two match points

220
00:09:55,030 --> 00:09:56,180
we recover all this

221
00:09:56,760 --> 00:09:59,490
i mean function here is thus the kernel

222
00:10:00,110 --> 00:10:01,030
so that's one way

223
00:10:02,320 --> 00:10:06,380
attitudes but i want to tell you more details about another way of doing it

224
00:10:07,640 --> 00:10:08,300
because we can

225
00:10:09,050 --> 00:10:12,260
for example way we can actually explicity construct

226
00:10:12,880 --> 00:10:14,200
the mapping into the feature space

227
00:10:14,720 --> 00:10:16,260
so that's the second main

228
00:10:16,880 --> 00:10:18,110
ingredient of what

229
00:10:18,640 --> 00:10:20,800
i'm trying to teach a course for the first one was

230
00:10:21,910 --> 00:10:24,430
uh not be scalability dimensions

231
00:10:25,050 --> 00:10:27,820
the second one is be scared of feature spaces

232
00:10:30,160 --> 00:10:33,380
basically what will do tomorrow and start today is

233
00:10:36,930 --> 00:10:39,260
a positive definite kernel which is called

234
00:10:39,260 --> 00:10:42,860
attention but they they should both be mentioned the idea is that if you look

235
00:10:42,860 --> 00:10:44,920
at the gap between

236
00:10:44,940 --> 00:10:46,910
your inner product with the true label

237
00:10:46,920 --> 00:10:50,090
and any alternative label y

238
00:10:50,100 --> 00:10:54,450
then that gap should be proportional to the loss minus the slack

239
00:10:54,470 --> 00:10:58,910
that's the margin rescaling version or proportional to one minus the flag divided by the

240
00:11:01,400 --> 00:11:05,090
if we impose no constraints at all are basically say this gap should should always

241
00:11:05,090 --> 00:11:09,180
be greater than or equal to zero we basically get rid of the variable and

242
00:11:09,330 --> 00:11:13,430
essentially found back to the perceptron with some kind of regularisation term and just pointing

243
00:11:13,430 --> 00:11:18,250
that out because sometimes it's nice to see that there's a connection the problem here

244
00:11:18,270 --> 00:11:20,780
is that there are a lot of different wise

245
00:11:20,790 --> 00:11:23,870
we have one constraint for every different

246
00:11:25,780 --> 00:11:29,110
labeling of the sequence or partial tree and we know that there could be exponentially

247
00:11:29,110 --> 00:11:30,250
many of those

248
00:11:32,320 --> 00:11:33,900
so what is required here

249
00:11:33,920 --> 00:11:38,100
is some way of taking care taking advantage of local factory

250
00:11:38,170 --> 00:11:42,440
both the features as we've been doing all along we use that when we when

251
00:11:42,440 --> 00:11:45,120
we decode but also the loss function l

252
00:11:45,160 --> 00:11:50,220
so m three ends are one one formalism that use margin rescaling and try to

253
00:11:50,220 --> 00:11:52,450
exploit both the factor g

254
00:11:52,500 --> 00:11:56,050
vector space function and l loss function

255
00:11:56,070 --> 00:11:58,910
so from the hyperplane view i think this kind of sums up the idea of

256
00:11:59,120 --> 00:12:03,380
the worst an example is the more it's going to push on the hyperplane

257
00:12:03,440 --> 00:12:07,500
you want the bad the bad labelings of a sequence of the bad structures to

258
00:12:07,500 --> 00:12:08,730
be farther away

259
00:12:08,730 --> 00:12:10,980
not slightly less bad

260
00:12:10,990 --> 00:12:13,650
everybody is pushing against the

261
00:12:13,670 --> 00:12:18,930
the hyperplane but the bad ones push hard

262
00:12:18,940 --> 00:12:24,410
this is sort of another way of looking at the objective this is the margin

263
00:12:24,410 --> 00:12:26,100
rescaling version

264
00:12:26,110 --> 00:12:29,690
and what this i sort of collapse out the taxi

265
00:12:30,140 --> 00:12:31,740
and what you end up with

266
00:12:31,780 --> 00:12:37,340
it is inside your minimisation problem we've got this maximisation problem so this this problem

267
00:12:37,340 --> 00:12:38,840
is still convex

268
00:12:38,860 --> 00:12:39,940
like crfs

269
00:12:39,950 --> 00:12:43,140
but the bad news is that

270
00:12:44,400 --> 00:12:47,270
it's always differentiable

271
00:12:47,280 --> 00:12:48,140
it's sort of

272
00:12:48,160 --> 00:12:50,410
i got this piece wise

273
00:12:50,470 --> 00:12:52,410
component two it because of the max

274
00:12:54,660 --> 00:12:58,610
one thing that one thing that it's kind of different here is that

275
00:12:58,660 --> 00:13:02,050
inside the max you've got a loss function

276
00:13:02,050 --> 00:13:06,620
so it's got this it's got this sort of weird problem where you're trying to

277
00:13:06,620 --> 00:13:08,360
find the best y

278
00:13:08,410 --> 00:13:13,740
we're scoring y based on their actual scores like you would use in decoding here

279
00:13:13,760 --> 00:13:18,080
but also with this loss terms this is called loss augmented decoding is often pointed

280
00:13:18,080 --> 00:13:21,890
out standard decoding want you to find the y

281
00:13:21,910 --> 00:13:25,640
that maximizes the inner products the weight vector

282
00:13:25,740 --> 00:13:30,890
loss augmented decoding then again there are two versions one for each type rescaling requires

283
00:13:30,890 --> 00:13:36,780
you to maximise the sum of what you would normally maximise this lost her

284
00:13:36,800 --> 00:13:40,700
OK so you're trying to it's like trying to find the competitor to the correct

285
00:13:40,700 --> 00:13:44,950
answer that's that's both competitive and also really bad

286
00:13:44,970 --> 00:13:47,990
you know both both its loss has is lost has to be and also it's

287
00:13:47,990 --> 00:13:52,640
chorus we sort of the the biggest threat so if as as i said before

288
00:13:52,640 --> 00:13:55,820
in m three n is the whole point is that you can do this if

289
00:13:55,820 --> 00:13:58,030
things factor locally in the same way

290
00:13:58,070 --> 00:14:04,640
and you can use dynamic programming or or some other local reasoning sorry sorry combinatorial

291
00:14:04,640 --> 00:14:11,070
optimization problem they uses local local independence assumptions to to manage this the other version

292
00:14:11,070 --> 00:14:14,760
the slack rescaling version you actually end up may taking the product of these two

293
00:14:16,570 --> 00:14:19,680
this is just generally almost always intractable

294
00:14:19,700 --> 00:14:22,180
i don't actually know the case where it's not tractable

295
00:14:22,200 --> 00:14:28,850
for combinatorial problems so you have to approximate some

296
00:14:29,570 --> 00:14:32,200
again i told you at the beginning i'm not going to go into details about

297
00:14:32,200 --> 00:14:35,570
implementation i think it's fair to say that

298
00:14:35,570 --> 00:14:43,030
structural SVM models and methods for optimizing the weights according to these kinds of objectives

299
00:14:43,240 --> 00:14:47,470
are very hot topic and there's a lot of work going into them there are

300
00:14:47,470 --> 00:14:50,240
a whole lot of things on the table many of them require this loss augmented

301
00:14:50,240 --> 00:14:55,930
decoding probably what had the most impact lately in natural language processing of these passive

302
00:14:55,930 --> 00:15:00,800
aggressive online algorithms because the very easy to implement and they essentially accomplish the same

303
00:15:00,800 --> 00:15:05,490
thing although the connection to the objectives is not always clear and they may not

304
00:15:05,490 --> 00:15:09,200
be capturing the regularisation quite the way that we usually think about it right on

305
00:15:09,200 --> 00:15:12,720
the objective functions i think there's still more work to be done on figuring out

306
00:15:12,720 --> 00:15:17,490
this this connection people on the remaining more about it than i do

307
00:15:17,530 --> 00:15:21,490
all right i want to keep moving here

308
00:15:21,530 --> 00:15:26,840
OK so this is something of large margin classifiers what's nice about them is that

309
00:15:26,840 --> 00:15:31,450
and it also minimizes sensitivity to coastal

310
00:15:31,470 --> 00:15:38,700
here in some problem so in fact when compute saying what is important to is

311
00:15:38,700 --> 00:15:41,290
that you have got to with this if there

312
00:15:41,310 --> 00:15:47,050
which is which is this one so that is is the blue one so you

313
00:15:47,050 --> 00:15:47,960
will get

314
00:15:47,980 --> 00:15:51,780
following once you've got a capacitance

315
00:15:51,790 --> 00:15:54,430
input impedance

316
00:15:54,450 --> 00:15:57,870
after a while it is just a list the and the

317
00:15:57,940 --> 00:16:01,870
the frequency welding is in this sense of what it's like

318
00:16:02,050 --> 00:16:04,200
we would like to register

319
00:16:04,210 --> 00:16:09,360
and the type of you don't want to get is a few modelling or something

320
00:16:09,520 --> 00:16:11,410
very quite quite small

321
00:16:11,490 --> 00:16:13,950
that we simply don't

322
00:16:13,960 --> 00:16:16,200
and by the with is

323
00:16:16,230 --> 00:16:18,430
deposit detector capacitance which

324
00:16:18,430 --> 00:16:20,360
which we defined

325
00:16:20,370 --> 00:16:24,350
so one something for the is extremely stable so

326
00:16:24,360 --> 00:16:25,270
just to

327
00:16:25,350 --> 00:16:31,710
shortly twenty the capacity to otherwise if you if you have a succession of the

328
00:16:31,910 --> 00:16:35,270
input you just show the capacitance until

329
00:16:35,290 --> 00:16:36,590
you a first

330
00:16:36,590 --> 00:16:41,630
so this is the situation of the fail also you have to to discharge the

331
00:16:41,630 --> 00:16:44,510
capacitance in general and we do that just

332
00:16:44,540 --> 00:16:45,920
the only

333
00:16:48,090 --> 00:16:52,860
and that's what's so here you've got this inputs counties input

334
00:16:54,750 --> 00:16:55,960
yeah have

335
00:16:55,970 --> 00:16:59,550
the voltage output is just going to play just like that

336
00:16:59,570 --> 00:17:02,010
we have this capacitance

337
00:17:02,030 --> 00:17:03,790
if we go down

338
00:17:04,500 --> 00:17:09,820
two zero again and then what happens to be the value it shouldn't be too

339
00:17:09,940 --> 00:17:13,710
two small that it shouldn't be too large to the people of course this is

340
00:17:14,960 --> 00:17:19,760
if something happened during this discussion would have some biological and

341
00:17:20,790 --> 00:17:22,170
and you know it

342
00:17:22,180 --> 00:17:23,690
so the same reasons

343
00:17:23,710 --> 00:17:24,550
i find that

344
00:17:26,910 --> 00:17:30,870
so the question is what is called stoke in that they have that as i

345
00:17:30,870 --> 00:17:34,150
said of channels general from one to two

346
00:17:34,260 --> 00:17:38,020
the other you do not have so much distance issues if you take

347
00:17:38,380 --> 00:17:41,840
silicon strip detectors get

348
00:17:41,850 --> 00:17:46,810
eighty two on nikon between two channels which means that if you look at one

349
00:17:46,810 --> 00:17:49,710
hundred the other so you will get

350
00:17:49,720 --> 00:17:54,400
in between because they are close time capacitance in this course

351
00:17:54,420 --> 00:17:55,440
see it

352
00:17:57,380 --> 00:18:01,450
if i take this if i think this is generally of the

353
00:18:03,680 --> 00:18:10,850
generated by particle causing the gender with which would be shared between the amplifier

354
00:18:10,860 --> 00:18:12,970
this sparse here

355
00:18:13,000 --> 00:18:15,730
so which means that you will inject

356
00:18:15,750 --> 00:18:19,540
some other to go on and on and on the name

357
00:18:19,600 --> 00:18:23,010
so of course as it is the capacitance you will

358
00:18:23,020 --> 00:18:26,090
between basis

359
00:18:26,110 --> 00:18:28,180
the signal

360
00:18:28,190 --> 00:18:30,850
and then he said that it's a

361
00:18:30,870 --> 00:18:34,770
it seems to have a low input input

362
00:18:34,880 --> 00:18:37,630
you don't even if you don't know

363
00:18:37,630 --> 00:18:41,850
the current most of the if it is you most all the current flows is

364
00:18:42,570 --> 00:18:48,020
if it is most of the and flows with very little flow this way and

365
00:18:48,020 --> 00:18:53,450
that's why it's better to low input impedance amplifier in terms of course if you

366
00:18:54,440 --> 00:18:56,280
large domes

367
00:18:56,380 --> 00:19:00,600
most of the killing to this way and then you are

368
00:19:00,620 --> 00:19:03,780
north pole

369
00:19:03,810 --> 00:19:09,800
so have try to find you could say well what about if just

370
00:19:09,820 --> 00:19:13,900
i can simplify which is that in this case the feedback

371
00:19:13,920 --> 00:19:15,620
just put all this stuff

372
00:19:15,630 --> 00:19:16,770
and that's the kind of thing

373
00:19:16,790 --> 00:19:19,690
which are useful in back to this

374
00:19:19,690 --> 00:19:23,250
and they are which is useful const meeting

375
00:19:25,790 --> 00:19:28,290
and optical fibre

376
00:19:28,300 --> 00:19:30,690
so the

377
00:19:30,700 --> 00:19:33,530
the relationship between the input

378
00:19:34,790 --> 00:19:37,500
in the output voltage

379
00:19:37,530 --> 00:19:38,800
it's just

380
00:19:38,840 --> 00:19:44,240
even by this formula are hundreds of in your face if the game is really

381
00:19:46,280 --> 00:19:48,510
i think it is the cost

382
00:19:48,520 --> 00:19:53,680
this is again the just the value of the is also a public you get

383
00:19:53,680 --> 00:19:56,850
that you know things that you want to the

384
00:19:56,900 --> 00:20:03,570
so that the fact that if you compute in the same computed the input impedance

385
00:20:03,590 --> 00:20:05,030
of charge amplifier operation

386
00:20:05,040 --> 00:20:08,680
compute the input impedance this configurations

387
00:20:08,700 --> 00:20:11,390
you will see i have a

388
00:20:11,410 --> 00:20:17,090
and if you do this input impedance match on the

389
00:20:17,170 --> 00:20:18,130
you could

390
00:20:18,420 --> 00:20:21,510
because this deposit during growth

391
00:20:21,540 --> 00:20:25,010
on the detector you have something which is very easy

392
00:20:27,230 --> 00:20:28,550
and then

393
00:20:28,630 --> 00:20:34,070
two two to get to done this thing is to put a resistor somewhere to

394
00:20:34,100 --> 00:20:36,710
them to dump and

395
00:20:37,060 --> 00:20:40,470
so in fact instead of putting the

396
00:20:40,490 --> 00:20:43,000
the input of the amplifier

397
00:20:43,020 --> 00:20:46,690
we just due the fact that if if we put the capacitance embodied to this

398
00:20:46,690 --> 00:20:51,590
the cascade can barely see it relation to everything else so the cascade and get

399
00:20:51,590 --> 00:20:53,000
some forms

400
00:20:53,000 --> 00:20:53,880
and so

401
00:20:53,900 --> 00:20:55,270
this is the big

402
00:20:55,370 --> 00:21:01,850
the cascade made a big difference in terms of GNU object detection because you have

403
00:21:01,850 --> 00:21:06,820
to do exhaustive search but rather do it in an efficient manner

404
00:21:07,100 --> 00:21:14,500
and what should be the next four

405
00:21:14,910 --> 00:21:22,340
yes so that's really well we go that more detail there is a dramatically reduced

406
00:21:22,370 --> 00:21:26,450
basically you have the full support vector machine to start off with

407
00:21:26,510 --> 00:21:30,170
and this is then there's method that you can do this kind of

408
00:21:30,200 --> 00:21:33,290
i want to analogous to whatever

409
00:21:33,290 --> 00:21:38,200
essentially what you have to do is a saying you're able to represent the decision

410
00:21:38,200 --> 00:21:43,090
boundary with all with endless support vectors and it is basically an iterative approach that

411
00:21:43,770 --> 00:21:47,890
you can employ we can talk of one about the details things but it's in

412
00:21:47,890 --> 00:21:52,210
the paper if interested but essentially what i want to convey here about is essentially

413
00:21:52,210 --> 00:21:59,340
that cascade is effective in that improves things in the speeds things up but this

414
00:21:59,340 --> 00:22:00,140
is not

415
00:22:01,250 --> 00:22:07,140
unfortunately for these guys this came out random at the same time as a volunteer

416
00:22:07,150 --> 00:22:08,900
and so

417
00:22:08,960 --> 00:22:10,740
the kind of work it was into

418
00:22:17,790 --> 00:22:21,120
it was rejected

419
00:22:21,140 --> 00:22:29,430
and they realize it was a good idea

420
00:22:29,450 --> 00:22:32,950
so listen for everyone

421
00:22:33,370 --> 00:22:38,380
so i mean and so essentially as as alex was talking about unfortunately in those

422
00:22:38,390 --> 00:22:42,980
really neat idea in the theory behind it's really becoming marginalized again because of the

423
00:22:43,600 --> 00:22:48,630
this this other approach which perhaps was an elegant but again the

424
00:22:49,260 --> 00:22:55,300
practical practical speedup that gave was again much greater and so that kind of it

425
00:22:55,300 --> 00:23:01,120
just became ubiquitous and so on explains the large method can combine this idea of

426
00:23:01,120 --> 00:23:05,370
cascaded classifiers with this idea of using box filters

427
00:23:06,430 --> 00:23:08,360
i'm going to explain what a box filter is

428
00:23:08,360 --> 00:23:12,590
so a box filter is essentially let's say

429
00:23:12,600 --> 00:23:17,300
i've got a sub image soft sub here

430
00:23:17,310 --> 00:23:18,560
this area here

431
00:23:18,610 --> 00:23:21,870
and the two adjacent regions region one

432
00:23:21,880 --> 00:23:22,880
in region two

433
00:23:22,890 --> 00:23:29,250
you can see that essentially what i my feature value is essentially

434
00:23:29,460 --> 00:23:33,780
some nations of the pixels in region one

435
00:23:33,780 --> 00:23:36,640
one is the summation of the pixels in britain to

436
00:23:36,700 --> 00:23:42,020
so set to box so instead of me actually so with an SVM on actually

437
00:23:42,020 --> 00:23:43,340
feeding in

438
00:23:43,350 --> 00:23:47,810
so that's a twenty one twenty image four hundred pixels so with an SVM beating

439
00:23:48,470 --> 00:23:52,140
all those pixels for me to for me to actually

440
00:23:52,150 --> 00:23:57,420
to the classification with the box filter what i'm doing is that i'm actually instead

441
00:23:57,960 --> 00:23:59,950
actually getting to measurements

442
00:24:00,710 --> 00:24:04,800
this twenty by twenty image one region two one region one

443
00:24:04,800 --> 00:24:06,890
and i just got a single number

444
00:24:06,950 --> 00:24:09,490
region two monastery one

445
00:24:09,540 --> 00:24:10,720
and i can

446
00:24:10,770 --> 00:24:16,200
there are three types about is one where you actually so talked about region one

447
00:24:16,200 --> 00:24:18,100
is written two

448
00:24:18,120 --> 00:24:20,810
there's one where actually

449
00:24:20,810 --> 00:24:21,740
at the two ears

450
00:24:21,750 --> 00:24:22,770
take away

451
00:24:22,790 --> 00:24:24,540
the other diagonal

452
00:24:24,550 --> 00:24:28,940
this vertical and then there's the triple so we kind of got a good good

453
00:24:28,940 --> 00:24:30,130
nature here

454
00:24:30,150 --> 00:24:35,440
and you can essentially very size aspect ratio location orientation

455
00:24:37,210 --> 00:24:40,560
in their work funded every twenty four but twenty four windows

456
00:24:40,600 --> 00:24:43,300
it's got one hundred sixty thousand distinct features

457
00:24:43,660 --> 00:24:48,910
it could possibly go through and it's classifier you basically do classification on every single

458
00:24:49,680 --> 00:24:51,740
thanks so much as well war

459
00:24:51,900 --> 00:24:56,250
why i want to come across through that the the advantage to this is twofold

460
00:24:56,250 --> 00:25:00,070
the first thing is that the individual pixels for themselves

461
00:25:00,090 --> 00:25:04,300
don't contain much information all the time it's when you look at the mess hall

462
00:25:04,330 --> 00:25:05,510
the really useful

463
00:25:05,520 --> 00:25:08,800
so essentially you can kind of think of what we're doing here

464
00:25:08,860 --> 00:25:12,340
is that we can't getting different

465
00:25:12,360 --> 00:25:16,470
so we can realize it so it's not good look at individual pixel so cannot

466
00:25:16,470 --> 00:25:22,430
perhaps get different combinations of pixels and explore if i if i basically is almost

467
00:25:22,440 --> 00:25:27,220
a greedy search can get different combinations of pixels and explore how useful that is

468
00:25:27,280 --> 00:25:31,720
me recognise objects so i just look at that one individual features and obviously this

469
00:25:31,720 --> 00:25:36,220
is like to quite useful for boosting so i essentially of maybe one hundred sixty

470
00:25:36,220 --> 00:25:40,780
thousand different ways of representing representing the object and i can if i not enough

471
00:25:40,780 --> 00:25:44,440
training data of time i can go offline and essentially

472
00:25:44,450 --> 00:25:49,490
apply boosting so say OK how well does this individual individual feature works how well

473
00:25:49,490 --> 00:25:53,010
does this subsequent individual feature work and then keep on adding the waiting into the

474
00:25:53,010 --> 00:25:56,820
sequential learning and it is useful fold you can process a lot of data this

475
00:25:56,820 --> 00:26:00,370
one thing so boosting sort myself to this and also

476
00:26:00,490 --> 00:26:05,860
you can and will talk to the next part of that you can actually two

477
00:26:05,860 --> 00:26:09,090
get substantial speedup by using this box filters

478
00:26:09,100 --> 00:26:14,430
so so these is like SVM actually got away with SVM as you add more

479
00:26:14,430 --> 00:26:15,670
and more

480
00:26:15,690 --> 00:26:20,700
you define a non-linear decision boundary things using so as the sequential learning

481
00:26:20,720 --> 00:26:26,800
so why why we do this so work arrived and why why would you do

482
00:26:27,580 --> 00:26:31,600
the big advantage is actually how you can buy the box filters so it turns

483
00:26:31,600 --> 00:26:33,810
out that when i need to

484
00:26:33,870 --> 00:26:38,080
and compute approximate the value many many times and i want to do it fast

485
00:26:38,080 --> 00:26:41,860
i can take advantage of an inherent redundancy in images or not an image just

486
00:26:41,860 --> 00:26:44,090
in in the in the two dimensional structure

487
00:26:44,140 --> 00:26:47,520
and it was always an integral image

488
00:26:47,530 --> 00:26:49,810
and what i can do is essentially

489
00:26:51,070 --> 00:26:54,870
but want to compute the sum of pixels in a rectangular area here

490
00:26:54,890 --> 00:27:02,110
i can take what interval image so i'll go back inside the initial image between

491
00:27:02,160 --> 00:27:08,520
so i've got two regions extraction x y one and what are basically

492
00:27:08,520 --> 00:27:09,320
i want to do

493
00:27:09,360 --> 00:27:13,310
is i want to get the summation of all values

494
00:27:13,360 --> 00:27:14,400
from the origin

495
00:27:14,420 --> 00:27:17,440
to expression white ash

496
00:27:17,450 --> 00:27:22,810
so the summing up all those values

497
00:27:22,880 --> 00:27:23,920
and then so

498
00:27:24,280 --> 00:27:27,240
if only is in the context of box filters a candidate

499
00:27:27,900 --> 00:27:30,160
i can get into the image of

500
00:27:31,050 --> 00:27:32,820
it's essentially summations

501
00:27:32,830 --> 00:27:34,390
of all the values here

502
00:27:34,450 --> 00:27:37,150
to this point

503
00:27:37,190 --> 00:27:39,500
with black with the black line here

504
00:27:39,520 --> 00:27:44,350
is what i want my box the value to be

505
00:27:44,360 --> 00:27:48,000
what i can do also is getting image b

506
00:27:48,030 --> 00:27:49,750
which is this area

507
00:27:49,800 --> 00:27:54,620
again with reference to the origin

508
00:27:54,640 --> 00:27:57,110
then limits to see

509
00:27:57,180 --> 00:28:00,260
but cool thing is is that if i actually

510
00:28:00,260 --> 00:28:02,470
it goes through

511
00:28:08,450 --> 00:28:13,690
one of them was

512
00:28:20,900 --> 00:28:24,120
so the brain

513
00:28:29,100 --> 00:28:37,670
all these is you know

514
00:28:45,410 --> 00:28:51,460
you know what to do with

515
00:28:56,940 --> 00:28:58,950
world war

516
00:28:58,990 --> 00:29:02,030
that is

517
00:29:02,130 --> 00:29:07,960
know that

518
00:29:29,700 --> 00:29:32,040
when you

519
00:29:35,720 --> 00:29:37,820
after all

520
00:30:21,740 --> 00:30:28,300
the problem of deciding whether to

521
00:30:55,370 --> 00:30:56,620
all o

522
00:31:11,580 --> 00:31:15,050
well i

523
00:31:44,400 --> 00:31:48,340
she she

524
00:31:53,480 --> 00:32:02,640
all of the

525
00:32:11,500 --> 00:32:12,470
all these

526
00:32:25,470 --> 00:32:27,910
we have

527
00:32:28,080 --> 00:32:36,700
so all

528
00:32:36,700 --> 00:32:44,120
is less than  H if the constraint is not active then you decrease

529
00:32:44,120 --> 00:32:50,660
the price unless  but you never make it negative that's the plus size so you never made the

530
00:32:50,670 --> 00:32:58,840
prices negative so that's one application of the dual methods you get methods that actually are

531
00:32:58,840 --> 00:33:13,520
easy to that can exploit a separable structure in optimization problems is this clear so

532
00:33:13,520 --> 00:33:19,040
next question is  maybe briefly so we saw these were all applications of the sub

533
00:33:19,040 --> 00:33:24,520
gradient method or a gradient method applied to the dual we've seen in the

534
00:33:24,520 --> 00:33:30,520
previous section that the proximal gradient method is much faster than the subgradient method and can

535
00:33:30,520 --> 00:33:36,420
handle some non-differentiable objectives so an interesting question is when can we apply

536
00:33:36,420 --> 00:33:42,640
the proximal gradient method to a dual problem so when is it true that in the

537
00:33:42,650 --> 00:33:48,160
dual problem that's repeated here we get this structure that's you need

538
00:33:48,160 --> 00:33:53,740
in the proximal gradient method where you have a composite objective function with a differentiable term

539
00:33:53,740 --> 00:34:00,600
and a simple non-differentiable term with  an inexpensive prox operator and that's very useful because

540
00:34:00,600 --> 00:34:05,580
if that can have a much faster dual method than using the subgradient

541
00:34:05,580 --> 00:34:12,600
method because again we've seen that a subgradient method is a very general method but it's also very slow in

542
00:34:12,600 --> 00:34:19,020
practice and it's difficult to  select a step size so if you can use a

543
00:34:19,020 --> 00:34:24,440
gradient method or a proximal gradient method you have a much faster way of solving a dual

544
00:34:24,440 --> 00:34:29,560
and you can also extend it  to these fast proximal gradient methods and then it's even

545
00:34:29,660 --> 00:34:44,230
faster yes because it's yeah it's difficult the

546
00:34:44,250 --> 00:34:53,220
so the step size selection is difficult in general because we've seen that these convergence

547
00:34:53,250 --> 00:34:58,980
rules proves actually the convergence the step sizes for which you have convergence results are

548
00:34:58,980 --> 00:35:05,440
for example if you use a fixed step size then we didn't show convergence we

549
00:35:05,440 --> 00:35:09,780
just showed that if the step size is sufficiently small you get close to the optimum

550
00:35:09,780 --> 00:35:15,540
and to actually show convergence you have to use a decreasing or a diminishing step size which

551
00:35:15,760 --> 00:35:25,980
also makes it slow yeah it's I'm not sure how that would

552
00:35:26,160 --> 00:35:38,500
work but certainly the convergence would still be quite slow in  practice so now the

553
00:35:38,500 --> 00:35:42,200
next question is just simply let's look at some  what it means for the

554
00:35:42,200 --> 00:35:47,200
dual problem to have this structure we need in the primal  we see it's actually very useful

555
00:35:47,200 --> 00:35:52,020
to have this proximal gradient  method so suppose we have a problem with

556
00:35:52,020 --> 00:35:59,240
a separable objective a primal problem and then that's the dual function again with conjugates F star

557
00:35:59,240 --> 00:36:05,540
a conjugate for H and a linear term so when is it true that we have

558
00:36:05,600 --> 00:36:10,600
we can split this is in these two terms well for example if the first term

559
00:36:10,600 --> 00:36:19,080
is differentiable with the Lipschitz continuous gradient then that fits the framework  for the proximal gradient method

560
00:36:19,080 --> 00:36:24,520
in terms of the primal problem that means that F is strongly convex for example for

561
00:36:24,520 --> 00:36:28,960
the second term  we don't need any assumptions to use a proximal gradient method if you call

562
00:36:28,960 --> 00:36:34,860
that non-differentiable term in the for the proximal gradient method the only thing

563
00:36:34,860 --> 00:36:40,180
we need is that we can evaluate the prox operator of H star efficiently

564
00:36:40,180 --> 00:36:48,480
either by a closed form or efficient and simple method so let's look at an example suppose

565
00:36:48,480 --> 00:36:52,980
this thing here cannot be written as a single but obviously it so we we

566
00:36:52,980 --> 00:36:53,960
have to

567
00:36:53,970 --> 00:36:58,150
complete the space under the linear combinations

568
00:36:58,180 --> 00:37:01,470
and we'll just do this formally we just say OK

569
00:37:01,890 --> 00:37:03,960
o space contains

570
00:37:03,980 --> 00:37:05,600
elements of this form

571
00:37:05,650 --> 00:37:08,380
the elements of this form where

572
00:37:08,690 --> 00:37:12,730
the point x i x i x j prime here are some points from our

573
00:37:12,730 --> 00:37:17,970
input domain and five beta i j some real numbers and also the

574
00:37:18,000 --> 00:37:22,640
we keep we keep it open how many terms aren't just some so more prime

575
00:37:23,240 --> 00:37:29,060
which could be any natural numbers so say this points also all space

576
00:37:29,120 --> 00:37:34,290
next we have to say what's the dot product in all space

577
00:37:37,170 --> 00:37:41,190
of course we want the dot product to satisfy this

578
00:37:41,200 --> 00:37:42,640
question here

579
00:37:42,650 --> 00:37:47,120
but of course we have to extend this to product also to other points

580
00:37:47,200 --> 00:37:50,750
which are not of this format which are linear combinations in such

581
00:37:50,770 --> 00:37:51,750
o point

582
00:37:51,770 --> 00:37:54,860
so there is actually only one way of doing it

583
00:37:54,860 --> 00:37:59,810
it is as follows this say that if we have functions f and g as

584
00:37:59,810 --> 00:38:02,520
defined on the last slide

585
00:38:02,550 --> 00:38:06,450
so these two functions with this representation

586
00:38:06,540 --> 00:38:12,710
so the dot product is this double some here

587
00:38:14,630 --> 00:38:18,750
if you plug in the special case where both f and g only single kernel

588
00:38:18,770 --> 00:38:21,890
will see that this is consistent with with what i had before

589
00:38:22,270 --> 00:38:26,290
not linearly extended to other points and

590
00:38:26,320 --> 00:38:30,250
if we do something like this we have to worry about whether it's well defined

591
00:38:30,380 --> 00:38:32,030
term that mathematicians like

592
00:38:32,130 --> 00:38:35,820
it is well defined in other words this is

593
00:38:35,880 --> 00:38:40,320
depends on how we write a function in terms of kernels

594
00:38:40,350 --> 00:38:41,850
because of these problems

595
00:38:42,050 --> 00:38:44,610
because it may be the case that for some kernel

596
00:38:44,620 --> 00:38:47,660
some functions this representation is not unique

597
00:38:49,470 --> 00:38:53,400
and then maybe the definition of the dot product will depend on how the functions

598
00:38:53,400 --> 00:38:58,350
are expressed as the product to be just the property of the functions than that

599
00:38:58,350 --> 00:39:02,560
off whole they are expanded in terms of the

600
00:39:02,570 --> 00:39:06,290
so we need to show that this does not depend on the expansion and it's

601
00:39:06,290 --> 00:39:08,090
actually simple to do this

602
00:39:08,090 --> 00:39:11,870
if you briefly remember what other definitions of f and g

603
00:39:13,510 --> 00:39:18,520
f was the sum of the of five and six IND was over the bhattacharyya

604
00:39:18,520 --> 00:39:20,450
next a prime

605
00:39:20,790 --> 00:39:25,210
you what you can see here this is actually the same as the

606
00:39:25,230 --> 00:39:27,180
so half

607
00:39:27,190 --> 00:39:31,500
the time the ex-prime was actually the expansion of g

608
00:39:31,520 --> 00:39:35,480
so this is the same as a linear combination of expand of evaluations of g

609
00:39:35,480 --> 00:39:37,850
at x i

610
00:39:37,860 --> 00:39:41,040
and if you go the other way round you can also eliminate the

611
00:39:41,060 --> 00:39:44,150
i fast by substituting the expression for f

612
00:39:45,470 --> 00:39:48,460
so these are just two simple identities

613
00:39:48,460 --> 00:39:53,570
and what they tell us is the following his first identity tells us

614
00:39:53,590 --> 00:39:56,250
that the

615
00:39:57,060 --> 00:39:59,880
the solution does not depend on the better days

616
00:39:59,890 --> 00:40:03,470
because you as you can see it it does not explicitly depend on the better

617
00:40:03,470 --> 00:40:08,170
days it just depends on what function d you really have say the function g

618
00:40:08,170 --> 00:40:11,760
that has different expansions in different be different but i j edges

619
00:40:11,910 --> 00:40:16,500
it doesn't matter because this this equality here shows that it doesn't depend on which

620
00:40:16,500 --> 00:40:20,350
of the expansion to use it just depends on what the function g

621
00:40:20,360 --> 00:40:25,940
likewise this equation here shows it does not depend on which was used to express

622
00:40:25,940 --> 00:40:30,200
the function f it only depends on the function f itself

623
00:40:30,220 --> 00:40:35,120
so was shown is only depends on g and if not enough as another better

624
00:40:35,120 --> 00:40:36,990
so this is well defined

625
00:40:38,790 --> 00:40:43,500
it it's symmetric by definition

626
00:40:43,550 --> 00:40:48,960
if you have too expensive two functions f very few exchange f and g

627
00:40:48,980 --> 00:40:51,460
you will get the same result here

628
00:40:51,900 --> 00:40:54,110
and also it's by linear

629
00:40:54,130 --> 00:40:55,630
so it will

630
00:40:56,030 --> 00:40:57,790
you can take

631
00:40:57,820 --> 00:41:00,510
o five times have put into the product

632
00:41:00,520 --> 00:41:02,960
you can take f one plus f two

633
00:41:02,960 --> 00:41:06,090
and use linearity so

634
00:41:06,130 --> 00:41:10,010
i mean so the trivially built in you don't have to worry about this by

635
00:41:10,010 --> 00:41:15,190
construction by linear do people know what it means by linear

636
00:41:18,800 --> 00:41:21,380
so it just means that

637
00:41:21,410 --> 00:41:24,990
if you have something like this

638
00:41:33,300 --> 00:41:45,340
so this is a is true and the same would be true

639
00:41:45,350 --> 00:41:47,340
in the second arguement if i have some

640
00:41:47,590 --> 00:41:51,460
but i one one plus bit i two d two

641
00:41:51,480 --> 00:41:52,660
it could also be

642
00:41:52,670 --> 00:41:56,460
extracted from the product so it's by

643
00:41:56,550 --> 00:42:01,790
that's nice but we still need a little bit more for it to be the

644
00:42:01,790 --> 00:42:03,590
product of the products are

645
00:42:04,060 --> 00:42:08,420
have to be well defined symmetric by linear and positive definite and i'm going to

646
00:42:08,420 --> 00:42:13,860
show that is positive definite but that's a little bit more tricky

647
00:42:13,910 --> 00:42:15,720
before we do this

648
00:42:15,740 --> 00:42:19,170
let's just consider two special cases

649
00:42:19,180 --> 00:42:21,980
so again i'm still here sorry

650
00:42:22,000 --> 00:42:24,620
still here this definition of the dot product

651
00:42:24,620 --> 00:42:30,930
and i will substitute some special cases so that's substitute a special case

652
00:42:31,120 --> 00:42:35,990
where the first function is just a single kernel

653
00:42:36,020 --> 00:42:39,720
and if you then take the dot product between

654
00:42:39,740 --> 00:42:42,700
that single kernel the second function

655
00:42:42,730 --> 00:42:47,510
you simply get function second function evaluated at x

656
00:42:53,270 --> 00:42:57,520
i guess if you want you can verify this but it's just a trivial consequence

657
00:42:57,520 --> 00:43:01,920
of the definition of this dot product so we have this decided here

658
00:43:01,960 --> 00:43:06,240
and moreover if we choose both functions to be single clones so f is the

659
00:43:06,260 --> 00:43:10,220
single sitting on x which is integral to the next prime

660
00:43:10,460 --> 00:43:15,910
then all definition of the product reduces to this quote this equation here which you

661
00:43:15,910 --> 00:43:19,630
might remember from before this is what we want

662
00:43:19,640 --> 00:43:21,090
because this

663
00:43:21,100 --> 00:43:25,320
the monster saying that the kernel is the same as the between files x i

664
00:43:25,320 --> 00:43:26,490
phi xj

665
00:43:26,710 --> 00:43:29,820
this suffix i five xt and this is the same as the kernel

666
00:43:30,040 --> 00:43:34,510
and this equation here which is contained in a special case and the notion of

667
00:43:34,510 --> 00:43:39,050
to get a deeper understanding of the formation of the rainbow behind

668
00:43:39,100 --> 00:43:40,450
this of course

669
00:43:40,460 --> 00:43:42,000
so you notice that the

670
00:43:42,050 --> 00:43:43,260
blue light

671
00:43:43,290 --> 00:43:45,930
is one percent slower in water

672
00:43:45,930 --> 00:43:47,540
then the red light

673
00:43:47,600 --> 00:43:49,860
and this phenomenon that you see there

674
00:43:49,870 --> 00:43:55,680
that the speed of electromagnetic radiation depends on the wavelength depends on the frequency we

675
00:43:55,680 --> 00:43:58,120
call that dispersion

676
00:43:58,170 --> 00:43:59,850
it is a good thing that

677
00:43:59,870 --> 00:44:05,840
sound in air is not this person because just imagine that high frequencies will travel

678
00:44:05,840 --> 00:44:09,790
faster than low frequency is just as an example

679
00:44:09,850 --> 00:44:11,930
or or so for that matter

680
00:44:11,960 --> 00:44:14,940
it would mean then that if you go to a concert

681
00:44:15,010 --> 00:44:18,460
you would listen to the violins on the basis that the violence would reach you

682
00:44:18,460 --> 00:44:22,340
first and then the sound of the bass would which later in the forty you

683
00:44:22,350 --> 00:44:26,040
away from august the worst that would be

684
00:44:26,090 --> 00:44:28,010
if the effect very strong

685
00:44:28,030 --> 00:44:32,590
in twenty six one hundred someone sitting in the back row could not even understand

686
00:44:32,590 --> 00:44:37,680
my words because the high frequencies would reach that person at different times and the

687
00:44:37,680 --> 00:44:38,910
low frequencies

688
00:44:38,910 --> 00:44:40,590
so sound in air

689
00:44:40,600 --> 00:44:42,620
is non dispersive

690
00:44:42,630 --> 00:44:45,230
but glass and water i dispersive

691
00:44:45,280 --> 00:44:46,670
four lights

692
00:44:46,710 --> 00:44:48,670
and it's very noticeable

693
00:44:48,670 --> 00:44:49,960
if i take

694
00:44:50,060 --> 00:44:52,020
a piece of glass

695
00:44:52,030 --> 00:44:53,750
and i give you this shape

696
00:44:53,800 --> 00:44:56,000
the shape of the prison

697
00:44:56,050 --> 00:44:59,600
and i shine some light on here

698
00:44:59,600 --> 00:45:02,200
light from

699
00:45:02,250 --> 00:45:05,950
these light bulbs or light from the sun for that matter

700
00:45:05,960 --> 00:45:08,930
that i can apply snails were here

701
00:45:09,000 --> 00:45:11,030
and angle of incidence

702
00:45:11,050 --> 00:45:12,000
they one

703
00:45:12,020 --> 00:45:15,230
i know the index of refraction this is for what would you can look them

704
00:45:15,230 --> 00:45:16,930
up for class of course

705
00:45:17,020 --> 00:45:20,720
and then you will see there is the difference of the index of refraction

706
00:45:20,740 --> 00:45:22,210
four red light

707
00:45:22,240 --> 00:45:24,430
that there is for

708
00:45:24,510 --> 00:45:26,660
through light

709
00:45:26,700 --> 00:45:28,870
and so

710
00:45:28,880 --> 00:45:30,450
when you read this site

711
00:45:30,470 --> 00:45:31,710
of the present

712
00:45:31,710 --> 00:45:34,250
again you have to apply snails law

713
00:45:34,310 --> 00:45:36,910
and when you do that you will see that the red light

714
00:45:36,940 --> 00:45:39,000
it doesn't come out at the same angle

715
00:45:39,020 --> 00:45:40,500
that the blue light come out

716
00:45:40,510 --> 00:45:44,210
but the two diverge

717
00:45:44,240 --> 00:45:48,410
that is the result of the fact that the indices of refraction i different but

718
00:45:48,410 --> 00:45:50,810
also the result of the fact that we have

719
00:45:50,930 --> 00:45:56,170
this particular shape body shape namely that this side of the glass is not parallel

720
00:45:56,170 --> 00:45:57,460
to decide

721
00:45:57,510 --> 00:45:59,950
so he put his screen here

722
00:45:59,970 --> 00:46:03,820
you will see colors you can make a spectrum you can convince yourself that the

723
00:46:03,820 --> 00:46:07,260
light from the light bulbs is just not white light

724
00:46:07,280 --> 00:46:10,200
but that it contains many many callers

725
00:46:10,200 --> 00:46:12,480
well it has to contain many callers

726
00:46:12,500 --> 00:46:15,890
because of a look at the gentleman there he's wearing a red shirt

727
00:46:15,900 --> 00:46:18,070
the only thing that you have colors coming from

728
00:46:18,090 --> 00:46:21,500
must come from the light bulb filaments be red light in their the woman sitting

729
00:46:21,500 --> 00:46:25,060
next to him is wearing a green shirt so there must also be green light

730
00:46:25,060 --> 00:46:26,350
in this

731
00:46:26,490 --> 00:46:28,820
lights and the same is true for sunlight

732
00:46:28,850 --> 00:46:32,240
but the beauty is that making use of the dispersion

733
00:46:32,290 --> 00:46:33,890
you can decompose

734
00:46:33,920 --> 00:46:36,470
the white light into the individual

735
00:46:39,240 --> 00:46:40,440
and the spectrum

736
00:46:40,590 --> 00:46:45,200
if you take a piece of plane parallel glass

737
00:46:45,250 --> 00:46:46,430
which is

738
00:46:46,470 --> 00:46:48,050
window glass

739
00:46:49,100 --> 00:46:50,970
you're not going to see colors

740
00:46:50,990 --> 00:46:53,070
because if now i shine

741
00:46:53,120 --> 00:46:54,370
light on here

742
00:46:54,380 --> 00:46:55,670
white light

743
00:46:55,720 --> 00:47:00,420
from the light bulbs of from the sun it is true that it will obviously

744
00:47:00,470 --> 00:47:03,100
refracted here

745
00:47:03,140 --> 00:47:05,900
but when you apply snails will again here

746
00:47:05,920 --> 00:47:07,380
then it will come out

747
00:47:07,430 --> 00:47:10,770
all the colors will come out in the same direction

748
00:47:11,660 --> 00:47:13,370
the red light

749
00:47:13,420 --> 00:47:17,610
comes out here and the blue light comes out in the same direction

750
00:47:17,620 --> 00:47:20,360
and your brains are very special

751
00:47:20,370 --> 00:47:24,020
if your brain see all colors coming from one direction

752
00:47:24,050 --> 00:47:28,010
they say i see white light look at the light bulb

753
00:47:28,020 --> 00:47:31,650
you say that's why i'd like to look at this gentleman using a red must

754
00:47:31,650 --> 00:47:33,240
come from the light bulb

755
00:47:33,290 --> 00:47:35,730
so your brains are special in the sense

756
00:47:35,740 --> 00:47:37,420
the the thing

757
00:47:37,420 --> 00:47:40,530
that the combination of many colours

758
00:47:43,050 --> 00:47:47,160
i can show it to you in a you know rather convincing way

759
00:47:47,200 --> 00:47:49,270
you see here this case

760
00:47:49,290 --> 00:47:52,730
and i would assume that you see colours on the disk

761
00:47:52,740 --> 00:47:57,150
if not you have a problem

762
00:47:57,150 --> 00:47:59,280
and i can for your brains

763
00:47:59,350 --> 00:48:00,890
what i can do

764
00:48:00,940 --> 00:48:03,110
i can rotate the disk

765
00:48:03,120 --> 00:48:04,930
so fast

766
00:48:04,960 --> 00:48:07,090
that your brain gets so mixed up

767
00:48:07,100 --> 00:48:08,650
that they're going to say to you

768
00:48:08,660 --> 00:48:11,170
that's white light

769
00:48:11,220 --> 00:48:13,070
so let me first give you

770
00:48:13,120 --> 00:48:14,400
so my view

771
00:48:14,460 --> 00:48:17,900
light on that this is going to spend couple of

772
00:48:17,900 --> 00:48:21,010
so you agree with me right you still see colours

773
00:48:21,030 --> 00:48:22,880
chelsea college right

774
00:48:24,250 --> 00:48:26,180
still see colours right

775
00:48:29,820 --> 00:48:35,120
this is why is it can be for me

776
00:48:35,160 --> 00:48:38,690
not too surprising right if a situation when you look at the light bulb

777
00:48:38,690 --> 00:48:40,100
the second goal

778
00:48:40,150 --> 00:48:45,230
several minutes ago to be honest i'm always honest with you

779
00:48:45,250 --> 00:48:48,090
the primary structure of the amino acid sequence

780
00:48:48,120 --> 00:48:54,170
the secondary structure represents configurations like here's an alpha helix

781
00:48:55,160 --> 00:48:56,660
here's a data

782
00:48:56,680 --> 00:48:58,470
please she

783
00:48:58,520 --> 00:49:02,420
so what we see in this alpha helix is we have the local structure

784
00:49:02,420 --> 00:49:07,290
where the in the groove down here the NHK hydrogen bond with the residue which

785
00:49:07,290 --> 00:49:10,890
is i think three three-and-a-half residues upstream one

786
00:49:12,260 --> 00:49:16,660
doesn't mean that there is a with the carbon three residues

787
00:49:18,010 --> 00:49:22,060
this one once again reached three residents

788
00:49:22,100 --> 00:49:23,950
not all the hydrogen bonds are shown

789
00:49:24,010 --> 00:49:25,170
in the background

790
00:49:25,210 --> 00:49:28,650
only the ones are on our side of the lake show the front side of

791
00:49:28,660 --> 00:49:29,480
the lake

792
00:49:29,560 --> 00:49:30,750
you can imagine

793
00:49:30,880 --> 00:49:34,270
this to perpetuate itself and each of these carbonell

794
00:49:34,320 --> 00:49:36,750
they associate with the proton

795
00:49:36,770 --> 00:49:39,930
many schools that either above or below

796
00:49:39,940 --> 00:49:41,400
that particular residues

797
00:49:41,400 --> 00:49:44,560
and this in turn can create new local structure

798
00:49:44,600 --> 00:49:46,420
by the way probably

799
00:49:46,480 --> 00:49:52,120
doesn't fit well in this case it's probably here proline is known in the trade

800
00:49:52,120 --> 00:49:54,230
as helix breakers

801
00:49:54,280 --> 00:49:58,960
why because you cannot twist itself around to form an alpha helix

802
00:49:59,000 --> 00:50:02,150
so if the primary amino acid would indicate

803
00:50:02,150 --> 00:50:05,230
the probably would be inserted right here for example

804
00:50:05,290 --> 00:50:08,460
then the sea looks like this down below

805
00:50:08,530 --> 00:50:13,790
but but but it wouldn't be continuous because the presence of protein is highly disruptive

806
00:50:13,810 --> 00:50:15,140
of the formation

807
00:50:16,860 --> 00:50:18,490
now alpha helix

808
00:50:18,510 --> 00:50:24,260
this means that in principle you can make some predictions about the localized structural polypeptide

809
00:50:24,260 --> 00:50:28,130
by knowing whether or not role the spread president for example but that still doesn't

810
00:50:28,130 --> 00:50:34,600
give you the power to predict the entire three-dimensional structure of the protein itself

811
00:50:35,270 --> 00:50:40,460
let's agree that this is the secondary structure of protein i e the various domains

812
00:50:40,460 --> 00:50:41,910
which often form

813
00:50:41,920 --> 00:50:45,010
alpha helix is within a certain segment of the protein

814
00:50:45,110 --> 00:50:49,960
or a certain segment of the protein form beta pleated sheets and several are several

815
00:50:49,960 --> 00:50:53,910
other less common kinds of of secondary structure

816
00:50:53,950 --> 00:50:54,990
and here

817
00:50:55,000 --> 00:50:56,490
we deal with

818
00:50:56,500 --> 00:51:01,430
tertiary structure now we're getting really interesting or maybe you don't like it but

819
00:51:01,450 --> 00:51:06,710
some people say it's really interesting because here are the tertiary structures of some arbitrarily

820
00:51:06,710 --> 00:51:08,940
chosen from

821
00:51:10,030 --> 00:51:13,450
the tertiary structure of this particular protein

822
00:51:13,490 --> 00:51:18,490
and there are and the identities and are these are given textbook

823
00:51:18,500 --> 00:51:21,400
i'm sure he spent two or three weeks to find out what they were but

824
00:51:22,440 --> 00:51:26,420
here is a protein three dimensional structure of proteins

825
00:51:26,470 --> 00:51:28,810
we're which is composed of four

826
00:51:28,810 --> 00:51:30,660
all three losses which go

827
00:51:30,780 --> 00:51:36,240
another alpha helix alpha helix alpha helix alpha helix

828
00:51:36,260 --> 00:51:39,730
there different here forty four different colors

829
00:51:39,820 --> 00:51:44,330
so we see that when we talk about tertiary structure we're talking about how the

830
00:51:44,370 --> 00:51:48,200
how to use these are disposed with respect to one another

831
00:51:48,220 --> 00:51:51,470
the primary structure as sequence is not shown here

832
00:51:51,540 --> 00:51:54,420
secondary structure represents the individual

833
00:51:54,430 --> 00:51:55,710
well see

834
00:51:55,720 --> 00:52:00,770
and the tertiary structure represents cell alpha uses are arranged these one another

835
00:52:00,790 --> 00:52:06,230
here is a protein which is structured much differently

836
00:52:06,410 --> 00:52:09,420
here this is it is

837
00:52:09,420 --> 00:52:13,140
one of many beta pleated sheets we saw them in in the last figure in

838
00:52:13,140 --> 00:52:18,870
the last over here you quite different overall three-dimensional structure

839
00:52:18,920 --> 00:52:23,710
this could be the beginning of an alpha helix down here although that's quite critical

840
00:52:23,720 --> 00:52:27,250
and here we see yet another point and that is has been said before the

841
00:52:27,250 --> 00:52:30,620
tertiary structure independent of these alpha and beta

842
00:52:30,650 --> 00:52:34,680
all fields in the face may be stabilised by

843
00:52:34,700 --> 00:52:36,520
covalent inter

844
00:52:36,620 --> 00:52:40,680
grand cross formed by the city

845
00:52:40,720 --> 00:52:43,060
in the end if we put all that together

846
00:52:43,150 --> 00:52:46,970
then we come to the realization that the three dimensional structure of proteins

847
00:52:47,000 --> 00:52:48,440
the determined by

848
00:52:48,490 --> 00:52:54,350
the art of extreme

849
00:52:54,390 --> 00:52:56,250
very good

850
00:52:56,270 --> 00:52:58,970
i'm not actually dyslexic

851
00:52:59,020 --> 00:53:00,590
i actually have cousins

852
00:53:00,600 --> 00:53:04,170
i won't mention son was so dyslexic when it came to stairways you know where

853
00:53:04,170 --> 00:53:08,650
the put foot up or down now that's difficult this is

854
00:53:08,660 --> 00:53:09,720
it's not so bad

855
00:53:09,750 --> 00:53:11,220
OK anyhow

856
00:53:11,260 --> 00:53:15,930
i all within less than two minutes i really think this is what the three-dimensional

857
00:53:15,930 --> 00:53:17,760
structure protein looks like

858
00:53:17,780 --> 00:53:21,370
this is called the space filling models because you're one brought in

859
00:53:21,410 --> 00:53:26,730
determined by x-ray crystallography what the if we could see what protein looks like maximize

860
00:53:26,730 --> 00:53:27,680
look like

861
00:53:27,740 --> 00:53:33,290
where each of the scene including side chains is actually affected

862
00:53:33,330 --> 00:53:36,660
before we use these far more schematic

863
00:53:36,660 --> 00:53:38,750
descriptions like you

864
00:53:38,770 --> 00:53:41,980
we were just talking about the overall structure that formerly were really

865
00:53:42,190 --> 00:53:45,060
in the case where the side chains were

866
00:53:45,100 --> 00:53:46,940
and what they say would fill up

867
00:53:46,940 --> 00:53:51,440
and if we give them a chance to put in all the other side chains

868
00:53:51,460 --> 00:53:54,500
and we created space filling molecule model

869
00:53:54,540 --> 00:53:55,600
where the

870
00:53:55,690 --> 00:53:59,390
the actual animals so this is what the protein would look like

871
00:53:59,460 --> 00:54:04,830
and the fact of the matter is that virtually all proteins have very specific structures

872
00:54:04,830 --> 00:54:07,730
is that they can shift from one structure to another

873
00:54:07,810 --> 00:54:11,480
once they leave their normal native structure they will lose

874
00:54:12,790 --> 00:54:16,980
two to do what the normal jobs are

875
00:54:17,040 --> 00:54:22,480
and this particular already happens to bring in yet another thing going to focus on

876
00:54:23,620 --> 00:54:26,790
which is what proteins do in cells

877
00:54:26,850 --> 00:54:28,250
and i a question

878
00:54:28,250 --> 00:54:30,690
one of the things they do in there

879
00:54:30,960 --> 00:54:34,370
hello i e as enzymes

880
00:54:34,410 --> 00:54:37,520
the fact is we will discuss later

881
00:54:37,540 --> 00:54:42,270
virtually all biochemical reactions require an enzyme

882
00:54:42,270 --> 00:54:44,560
list in order to propel them forward

883
00:54:44,600 --> 00:54:49,040
that is to say if the biochemical reaction to occur almost always

884
00:54:49,080 --> 00:54:53,660
i will not occur spontaneously in the same way that the hydroxyl ion hydrogen will

885
00:54:53,680 --> 00:54:55,920
going together spontaneously water

886
00:54:55,940 --> 00:55:02,730
almost all biochemical reactions we require the mediation of an enzyme

887
00:55:02,730 --> 00:55:05,230
which is the biological

888
00:55:05,290 --> 00:55:07,600
in order to encourage this

889
00:55:07,620 --> 00:55:10,410
and this while almost all

890
00:55:10,420 --> 00:55:11,910
catalyst in

891
00:55:12,390 --> 00:55:14,910
in our cells are protein

892
00:55:14,980 --> 00:55:16,140
so if you have

893
00:55:16,140 --> 00:55:18,290
four thousand three hundred twenty six

894
00:55:18,330 --> 00:55:19,730
distinct biochemical

895
00:55:19,750 --> 00:55:21,940
reactions occurring in the cell

896
00:55:22,040 --> 00:55:26,020
that means that there's probably almost as many distinct enzymes each one of which is

897
00:55:26,910 --> 00:55:30,100
the median one or another of those things

898
00:55:30,100 --> 00:55:31,870
the biochemical reactions

899
00:55:31,870 --> 00:55:36,590
very difficult to photograph i have not been able to get good slides

900
00:55:36,630 --> 00:55:38,080
but today however

901
00:55:38,080 --> 00:55:40,670
i did see some pictures on the web

902
00:55:40,720 --> 00:55:41,950
and when you

903
00:55:41,960 --> 00:55:44,680
log on to the web when you visit the web eight two

904
00:55:44,690 --> 00:55:45,620
but you should

905
00:55:45,630 --> 00:55:47,870
and i give you directions how to access

906
00:55:47,940 --> 00:55:49,810
slides pictures of the

907
00:55:49,850 --> 00:55:52,510
red sprites and of the blue jets

908
00:55:52,560 --> 00:55:57,100
the physics of that is not very well understood being researched very heavily

909
00:55:57,190 --> 00:56:00,980
it is way above the clouds

910
00:56:01,090 --> 00:56:03,180
there are also other forms

911
00:56:03,230 --> 00:56:05,770
of electrical breakdown

912
00:56:05,820 --> 00:56:07,590
of this charge

913
00:56:07,690 --> 00:56:11,610
they are different in the sense that is not an individual sport

914
00:56:11,610 --> 00:56:14,000
but there is a continuous flow

915
00:56:15,680 --> 00:56:16,900
of charge

916
00:56:16,910 --> 00:56:19,670
it occurs always very sharp points

917
00:56:19,770 --> 00:56:23,390
so there is a continuous current actually going on

918
00:56:24,690 --> 00:56:27,530
some of that you may have seen that you may not remember

919
00:56:27,530 --> 00:56:28,380
when we

920
00:56:28,440 --> 00:56:30,370
use the carbon arc here

921
00:56:30,390 --> 00:56:32,120
we had two carbon arcs

922
00:56:32,130 --> 00:56:33,340
two carbon

923
00:56:34,200 --> 00:56:36,440
and we had the potential difference between them

924
00:56:37,500 --> 00:56:40,900
we've got this charge between them would cause the tremendous amount of light which we

925
00:56:40,900 --> 00:56:43,320
use for projection purposes

926
00:56:43,370 --> 00:56:44,340
so carbon

927
00:56:44,360 --> 00:56:46,390
are discharged is such a form

928
00:56:46,410 --> 00:56:51,370
of this charge by have continuous current is not just parts

929
00:56:51,410 --> 00:56:54,290
if you take grass or trees

930
00:56:55,190 --> 00:56:56,810
brushes for that matter

931
00:56:56,840 --> 00:56:58,980
what is thunderstorm activity

932
00:56:59,000 --> 00:57:03,280
they can go into his discharge at the sharp tips

933
00:57:03,320 --> 00:57:07,110
and we call this brush discharge we call it an almost fires all the same

934
00:57:07,900 --> 00:57:10,630
also called corona discharge i normally

935
00:57:10,640 --> 00:57:12,870
call it corona discharge

936
00:57:12,920 --> 00:57:17,270
it produces light because the ions when they neutralize produce light

937
00:57:17,280 --> 00:57:19,880
it make sound pressure

938
00:57:20,080 --> 00:57:22,750
so you can hear the cracking noise of the

939
00:57:22,750 --> 00:57:25,020
corona discharge

940
00:57:25,060 --> 00:57:29,520
an airplane that flies or car drives there is friction with the air and any

941
00:57:29,520 --> 00:57:32,230
form of friction can charge things up

942
00:57:32,250 --> 00:57:35,720
and so it's not uncommon at night that you can see

943
00:57:35,770 --> 00:57:39,110
this corona discharge from the tip of the wings of an airplane

944
00:57:39,160 --> 00:57:41,390
i've also seen it from cars

945
00:57:41,400 --> 00:57:46,000
corona discharge from cars which charge themselves up simply by

946
00:57:46,000 --> 00:57:50,270
driving through the area air flow charts them up

947
00:57:50,280 --> 00:57:51,550
you can hear

948
00:57:52,750 --> 00:57:56,540
and you can see it sometimes it dark enough you see some light general generally

949
00:57:56,540 --> 00:58:00,750
blue is light

950
00:58:00,790 --> 00:58:04,810
something completely on the side going back to the lightning bolts

951
00:58:04,870 --> 00:58:06,170
lightning bolts

952
00:58:06,190 --> 00:58:09,500
the discharge moving electrons can cause

953
00:58:09,560 --> 00:58:10,810
radio waves

954
00:58:10,810 --> 00:58:14,270
these are a new ways you can receive on your car radio

955
00:58:14,270 --> 00:58:17,580
and all of you have experienced is driving around

956
00:58:17,630 --> 00:58:21,040
lightning very far away you can hear on the radio

957
00:58:21,080 --> 00:58:23,710
but that's telling you that there is likely

958
00:58:23,730 --> 00:58:26,290
going on somewhere

959
00:58:26,350 --> 00:58:28,690
after a thunderstorm something that

960
00:58:28,710 --> 00:58:30,920
many of you may not have experience

961
00:58:30,980 --> 00:58:32,980
was in the city's there's always

962
00:58:33,020 --> 00:58:37,870
always examples from cars that's spoils everything but when you're out in the country

963
00:58:37,880 --> 00:58:44,000
after a thunderstorm is a very special smell air i love and and that's also

964
00:58:44,040 --> 00:58:45,400
oxygen two

965
00:58:45,400 --> 00:58:47,020
oxygen two

966
00:58:47,020 --> 00:58:51,520
in lightning comes up to three and oxygen three has wonderful smell

967
00:58:51,540 --> 00:58:53,810
you can really smell that it's very typical

968
00:58:53,830 --> 00:58:55,400
i hope that most of you

969
00:58:55,420 --> 00:58:58,920
so late in life will have that experience to go to the country after the

970
00:59:00,100 --> 00:59:01,690
and you can really smell

971
00:59:01,710 --> 00:59:06,400
these ozone

972
00:59:06,440 --> 00:59:09,520
let's now look at some slides

973
00:59:09,520 --> 00:59:10,690
the first slide

974
00:59:10,730 --> 00:59:12,110
but you will see

975
00:59:12,210 --> 00:59:16,540
is one very classics like made by gary led

976
00:59:16,560 --> 00:59:19,690
OK peak observatory in arizona

977
00:59:20,060 --> 00:59:23,670
what i like about this is that these are the

978
00:59:23,670 --> 00:59:26,710
observatory telescopes don't

979
00:59:26,770 --> 00:59:29,370
and of course when you're an astronomer

980
00:59:29,420 --> 00:59:31,940
this is the kind of whether you can do without

981
00:59:31,980 --> 00:59:34,170
but nevertheless it happens

982
00:59:34,210 --> 00:59:35,830
you see here

983
00:59:35,850 --> 00:59:37,170
return stroke

984
00:59:37,190 --> 00:59:40,940
the light is definitely due to the return strokes it's very bright

985
00:59:40,980 --> 00:59:42,580
these are step

986
00:59:42,940 --> 00:59:44,880
that never made it to the earth

987
00:59:44,940 --> 00:59:48,310
and it is that it doesn't make studio you don't get the return stroke

988
00:59:48,400 --> 00:59:49,380
so the light

989
00:59:49,400 --> 00:59:50,750
as you can see here

990
00:59:50,790 --> 00:59:52,600
is much less

991
00:59:52,650 --> 00:59:55,060
and what you think here is only one ball

992
00:59:55,110 --> 00:59:56,730
it's probably at least ten

993
00:59:56,730 --> 00:59:58,920
five ten maybe fifteen

994
01:00:00,040 --> 01:00:02,600
we construct

995
01:00:02,650 --> 01:00:06,170
all right next slide please

996
01:00:06,310 --> 01:00:10,350
you see the result of a boy camera exposure

997
01:00:10,400 --> 01:00:13,600
for those of you who are sitting in front you can recognise maybe the empire

998
01:00:13,600 --> 01:00:15,440
state building here

999
01:00:15,460 --> 01:00:19,580
and the empire state building is hit by lightning very cheap at the sharp edge

1000
01:00:19,600 --> 01:00:22,250
that's where you expect it to be here

1001
01:00:22,380 --> 01:00:23,750
this is not

1002
01:00:23,770 --> 01:00:25,810
can when the camera was rotating

1003
01:00:25,960 --> 01:00:26,870
is just

1004
01:00:26,870 --> 01:00:30,560
the exposure to where you and i would see it

1005
01:00:30,580 --> 01:00:33,670
not moving camera and here you see the results

1006
01:00:33,710 --> 01:00:35,880
of the rotating boys camera

1007
01:00:35,920 --> 01:00:38,710
this is the same place you see

1008
01:00:38,810 --> 01:00:42,900
he returned from the light from the step leads to faint

1009
01:00:42,920 --> 01:00:44,290
you can see that

1010
01:00:44,420 --> 01:00:45,900
here's the return stroke

1011
01:00:45,920 --> 01:00:47,130
and then this

1012
01:00:47,150 --> 01:00:49,980
time separation maybe thirty or forty millisecond

1013
01:00:50,000 --> 01:00:51,310
you know stroke

1014
01:00:51,330 --> 01:00:56,080
you know one another one to six here like if you don't want here

1015
01:00:56,130 --> 01:00:59,250
so you have six or seven of these return strokes

1016
01:00:59,290 --> 01:01:01,520
and this is the way that you can study

1017
01:01:03,110 --> 01:01:05,730
and how much charge actually

1018
01:01:05,900 --> 01:01:09,020
exchange between these three clubs

1019
01:01:09,060 --> 01:01:12,130
and in this case the empire state building

1020
01:01:12,210 --> 01:01:15,210
the next slide shows you a corona discharge

1021
01:01:15,230 --> 01:01:18,210
in the laboratory is a high-voltage supply

1022
01:01:18,210 --> 01:01:21,270
it's a very short period and the sharp point

1023
01:01:21,290 --> 01:01:24,900
and you see not individuals spark you don't call this lightning

1024
01:01:24,920 --> 01:01:27,560
but this is what you would call the saint elmo's fire

1025
01:01:27,560 --> 01:01:32,900
okay goes pretty close the points ok ok and we can do an order

1026
01:01:32,910 --> 01:01:40,670
three effect ok or in order for fit for northern five ok six and

1027
01:01:40,680 --> 01:01:52,820
so on ok which of these is the best fit yeah to the data ok is

1028
01:01:53,140 --> 01:01:58,190
this ok is this so this ok

1029
01:02:00,250 --> 01:02:03,640
so that's that's part of the problem depends what we mean by fit

1030
01:02:03,640 --> 01:02:08,540
to the data ok so what can we mean well one thing we could mean

1031
01:02:08,550 --> 01:02:11,600
is what's the error on the training set that we're using

1032
01:02:11,830 --> 01:02:16,230
ok and we can do something really good on the training set we

1033
01:02:16,240 --> 01:02:22,850
can do this ok we can actually find high enough degree polynomial

1034
01:02:22,850 --> 01:02:24,810
that are exactly fit the training set

1035
01:02:24,810 --> 01:02:27,080
ok and the error on the training set is zero

1036
01:02:27,080 --> 01:02:29,460
okay is this a good fit to the data

1037
01:02:30,870 --> 01:02:34,510
well sort of our intuition says no ok why

1038
01:02:34,740 --> 01:02:38,440
because it's very wild ok goes to points but it seems to have no

1039
01:02:38,440 --> 01:02:41,250
rhyme or reason another words we're not confident that this kind

1040
01:02:41,250 --> 01:02:45,670
of fit actually generalizes from the training data that we have

1041
01:02:45,980 --> 01:02:48,400
to new data that we might see in the future

1042
01:02:48,560 --> 01:02:53,470
okay probably some other things you know maybe order to order three

1043
01:02:53,480 --> 01:02:58,690
might actually be be better ok so this points to a problem

1044
01:02:58,990 --> 01:03:03,570
of mismatch between what we would like to measure in the objective

1045
01:03:03,580 --> 01:03:06,900
of the optimization and what we can actually measure

1046
01:03:07,270 --> 01:03:14,250
ok what we would like to do is to measure the true rule error on

1047
01:03:14,250 --> 01:03:16,890
the whole distribution of the data but we don't have access to

1048
01:03:16,890 --> 01:03:19,160
that we only have access to find example

1049
01:03:19,420 --> 01:03:23,750
as a result we can only measure things on that finite sample of data

1050
01:03:24,170 --> 01:03:30,730
ok now if all we do is train and test on the same sample of data

1051
01:03:31,170 --> 01:03:35,010
then we're going to run into trouble okay we essentially get

1052
01:03:35,150 --> 01:03:38,210
solutions that look like this where we have

1053
01:03:38,210 --> 01:03:41,860
to know the training data fit perfectly but not really good hypothesis

1054
01:03:41,860 --> 01:03:43,670
not hypothesis that generalize well

1055
01:03:43,670 --> 01:03:46,720
ok so this is a really really important problem in all machine

1056
01:03:46,720 --> 01:03:52,830
learning called overfitting and it basically means that we find a

1057
01:03:52,840 --> 01:03:56,100
hypothesis that fits the training data very well but does

1058
01:03:56,110 --> 01:03:59,530
not generalize well once examples and

1059
01:04:00,730 --> 01:04:04,770
essentially the nature of this comes from have been to many parameters

1060
01:04:04,770 --> 01:04:07,740
for how much data we have ok we're going to make this a little

1061
01:04:07,740 --> 01:04:11,430
bit more formal now a lot of this that that you're going to hear

1062
01:04:11,430 --> 01:04:14,630
during the week is methods to get around this problem when you

1063
01:04:14,630 --> 01:04:17,710
do have a lot of parameters not very much training data

1064
01:04:18,240 --> 01:04:23,490
ok so this is another examples that picture are taken from

1065
01:04:24,080 --> 01:04:28,690
bishops book of different hypotheses fit through these blue

1066
01:04:28,700 --> 01:04:35,030
circles okay and here we have one specific function that's the

1067
01:04:35,040 --> 01:04:37,570
green function that's sort of the true function

1068
01:04:37,570 --> 01:04:40,560
the point were generated by applying a little bit of noise to

1069
01:04:40,560 --> 01:04:44,660
that function and then we do fits of various degrees

1070
01:04:45,420 --> 01:04:51,340
of polynomials and as you can see as if you're degrees to small

1071
01:04:51,350 --> 01:04:55,090
ok basically can't fit the data that's called underfitting ok it

1072
01:04:55,100 --> 01:04:57,820
means that your hypothesis spaces to simple

1073
01:04:57,990 --> 01:05:00,640
and you cannot represent the true function

1074
01:05:00,870 --> 01:05:03,310
ok doesn't allow you to represent the function

1075
01:05:04,110 --> 01:05:07,880
if of hypothesis space as to complicated like the degree nine

1076
01:05:07,890 --> 01:05:11,720
polynomials over here you have the overfitting problem that we've

1077
01:05:11,720 --> 01:05:14,920
just seen in other words you can represent perfectly the training

1078
01:05:14,920 --> 01:05:18,050
data can in fact memorize it because you have enough parameters

1079
01:05:18,050 --> 01:05:21,270
to to to memorize it but there's no generalization

1080
01:05:21,550 --> 01:05:26,590
ok and so what we would like to have is a learning method that goes

1081
01:05:26,600 --> 01:05:29,310
in between and finds the right complexity

1082
01:05:29,310 --> 01:05:32,530
of the hypothesis and so now we're going to have to talk about

1083
01:05:32,530 --> 01:05:34,540
how how to do that ok

1084
01:05:36,440 --> 01:05:39,770
so this is just to to give to the different tion of overfitting

1085
01:05:39,770 --> 01:05:43,360
a little bit more formally okay so in general we have

1086
01:05:43,590 --> 01:05:47,570
for any hypothesis a true error ok which we denote by j star

1087
01:05:48,480 --> 01:05:51,820
j star is the expected error when the data comes

1088
01:05:52,070 --> 01:05:58,380
from the true distribution ok but we don't have all the data ok

1089
01:05:58,380 --> 01:06:01,290
so what do we do we get a sample of data b d that's our data

1090
01:06:01,290 --> 01:06:03,990
set and so we estimate the true error

1091
01:06:04,530 --> 01:06:10,620
by a finite sample ok now the problem is that if we use this finite

1092
01:06:10,630 --> 01:06:16,740
sample both to find a hypothesis and to estimate the error

1093
01:06:16,750 --> 01:06:20,430
we might be fooling ourselves so we can be a situation where we

1094
01:06:20,440 --> 01:06:26,380
find a hypothesis that best error on the data set that we have

1095
01:06:26,630 --> 01:06:30,340
that but which is actually worse when we look at the entire

1096
01:06:30,340 --> 01:06:33,900
to have a different kind of of output formats

1097
01:06:33,920 --> 01:06:40,560
so this is a good environment for us to do this kind of such experiments

1098
01:06:43,930 --> 01:06:46,730
now we have the tools we have

1099
01:06:47,310 --> 01:06:52,380
did some experiments with the IMF staff reports the idea

1100
01:06:52,600 --> 01:06:57,100
is that if we wanted to follow up with

1101
01:06:57,370 --> 01:07:02,250
country development or even want to do country analysis and this kind of tool could

1102
01:07:02,250 --> 01:07:03,490
be useful

1103
01:07:03,500 --> 01:07:10,440
another reason is the IMF staff reports is a very well written every almost everyone

1104
01:07:10,440 --> 01:07:17,320
has the executive summary one page executive summary we could use it as a benchmark

1105
01:07:17,320 --> 01:07:21,780
for evaluation proposed

1106
01:07:21,790 --> 01:07:25,740
and so these are

1107
01:07:25,890 --> 01:07:29,490
two examples of how the

1108
01:07:29,500 --> 01:07:30,400
how do

1109
01:07:30,410 --> 01:07:34,970
staff report is written a it's very standard format always

1110
01:07:35,740 --> 01:07:43,300
always had three or four sections basically there is the introduction about economic background of

1111
01:07:43,360 --> 01:07:49,710
the country and then policies setting and a lot of local of the economic situation

1112
01:07:49,710 --> 01:07:54,640
of of this country and then in the main

1113
01:07:54,650 --> 01:07:59,620
the main concepts and you can see this report and

1114
01:07:59,630 --> 01:08:01,380
policy discussions

1115
01:08:03,230 --> 01:08:09,460
that that the second that date the meet an IMF staff scientist who were with

1116
01:08:09,460 --> 01:08:16,040
the country's authorities so they were wearing a little bit but not not so very

1117
01:08:16,040 --> 01:08:19,060
much in different reports

1118
01:08:22,460 --> 01:08:24,360
and then

1119
01:08:24,410 --> 01:08:29,670
before we evaluate the effects of different methods and we also

1120
01:08:30,180 --> 01:08:35,760
need to choose evaluation methods there are basically two different types

1121
01:08:35,900 --> 01:08:39,030
one one is the this

1122
01:08:39,080 --> 01:08:40,530
this package

1123
01:08:40,550 --> 01:08:42,670
provided in a

1124
01:08:42,940 --> 01:08:44,750
it's basically calculate

1125
01:08:44,970 --> 01:08:47,630
lexical overlapping beaten

1126
01:08:47,640 --> 01:08:50,200
we tend

1127
01:08:50,220 --> 01:08:57,150
we tend to documents so in this case we calculate the lexical overlapping the to

1128
01:08:57,290 --> 01:09:02,830
the executive summary and our some system generated summaries

1129
01:09:02,850 --> 01:09:08,190
and then we were thinking this is perhaps not the

1130
01:09:08,590 --> 01:09:14,980
it is definitely not perfect evaluation methods but the problem is that

1131
01:09:15,080 --> 01:09:23,270
it seems very difficult to find the perfect one but complimentary methods without seems latent

1132
01:09:23,270 --> 01:09:29,820
semantic analysis is supposed to be able to capture semantic similarities so

1133
01:09:29,960 --> 01:09:33,510
we also tried to use this method

1134
01:09:33,620 --> 01:09:36,500
and so we have and that it

1135
01:09:36,510 --> 01:09:40,490
several experiments in the first experiment

1136
01:09:41,020 --> 01:09:43,610
the proposal to test

1137
01:09:43,740 --> 01:09:47,540
the effect of the IDF dictionary

1138
01:09:50,620 --> 01:09:57,410
the regulator of the all the documents are modelled based on the vector space model

1139
01:09:57,410 --> 01:10:00,660
and then use the TF IDF weight

1140
01:10:00,700 --> 01:10:06,850
so and so obviously or or at least i would think that IDF dictionary has

1141
01:10:07,050 --> 01:10:14,240
will will have a big effect on the out the results

1142
01:10:14,450 --> 01:10:22,210
so meet system has has an IDF dictionary itself and the group said that a

1143
01:10:22,240 --> 01:10:29,970
should work reasonably while as a general dictionary but we thought maybe if we create

1144
01:10:29,970 --> 01:10:33,160
like text the specific

1145
01:10:33,210 --> 01:10:36,470
IDF dictionary it might help to improve the

1146
01:10:38,630 --> 01:10:45,840
so we have in addition to these ones from me since we have created three

1147
01:10:45,840 --> 01:10:49,860
three IDF dictionaries one is where small ones

1148
01:10:49,880 --> 01:10:53,270
sorry that was a mistake it was the old idea it was

1149
01:10:53,800 --> 01:10:58,940
created from only thirteen the IMF country reports

1150
01:10:58,940 --> 01:11:04,850
only i am kind of country reports and then there is the next one IMF

1151
01:11:04,850 --> 01:11:07,160
idea it is

1152
01:11:07,170 --> 01:11:11,660
in larger scale sixty nine the country of course

1153
01:11:11,740 --> 01:11:14,790
and then the larger RDF is created from

1154
01:11:14,880 --> 01:11:16,400
many economic

1155
01:11:16,430 --> 01:11:20,830
reports and papers not only that not only the

1156
01:11:20,850 --> 01:11:22,320
staff reports

1157
01:11:25,180 --> 01:11:28,660
so this is i think i'm going to

1158
01:11:28,710 --> 01:11:30,700
to do so

1159
01:11:30,750 --> 01:11:33,480
it is substantively

1160
01:11:33,580 --> 01:11:40,580
so it was actually very disappointing this large idea spend a lot of a lot

1161
01:11:40,580 --> 01:11:42,220
of time actually in

1162
01:11:42,220 --> 01:11:47,650
it takes a lot of efforts to create these IDF dictionaries from much document and

1163
01:11:47,650 --> 01:11:53,470
the performances is actually

1164
01:11:55,200 --> 01:11:57,410
this large RDF

1165
01:11:57,570 --> 01:12:00,720
performance really quite

1166
01:12:00,970 --> 01:12:09,390
inferior compared to other the IDF dictionaries but as you can see because this compression

1167
01:12:09,390 --> 01:12:16,060
rate has such influence on the summary output that ten percent of compression rate the

1168
01:12:16,350 --> 01:12:19,510
then the differences is quite quite small

1169
01:12:19,750 --> 01:12:24,910
but five percent of compression eight percent of sentences you can see

1170
01:12:25,360 --> 01:12:29,470
some differences in performance however the main idea of

1171
01:12:29,470 --> 01:12:33,970
best performing quite good compare with the others

1172
01:12:33,980 --> 01:12:40,720
this is based on the evaluation using latent semantic analysis

1173
01:12:40,730 --> 01:12:47,720
and then there's also another experiment we tested the random method because its centroid method

1174
01:12:47,720 --> 01:12:54,030
seems has alot of rationality is behind it but how the state functions that it

1175
01:12:54,080 --> 01:13:00,090
perform comparing to the random method and the result is a little bit

1176
01:13:00,160 --> 01:13:02,190
disappointed actually

1177
01:13:02,200 --> 01:13:04,330
the random method is

1178
01:13:04,350 --> 01:13:06,140
a little bit

1179
01:13:06,250 --> 01:13:09,890
they a little bit

1180
01:13:10,000 --> 01:13:18,410
lies and performed in terms of these overlapping metric measurements however with the latent semantic

1181
01:13:18,410 --> 01:13:22,820
analysis the random method should sometimes can or will perform

1182
01:13:23,160 --> 01:13:26,390
so brendan can do quite well

1183
01:13:26,970 --> 01:13:36,310
so the and then we also tested the reranking facility there are three ranking facilities

1184
01:13:36,310 --> 01:13:39,690
in need and

1185
01:13:40,290 --> 01:13:43,750
the difference is not very big

1186
01:13:44,710 --> 01:13:51,810
in a if we are using this evaluation metrics for lexical similarity merriment but

1187
01:13:51,810 --> 01:13:57,210
using here slightly different citation here vikram they have done that in a slightly different

1188
01:13:57,210 --> 01:14:00,460
way but they all try to extract the knowledge people

1189
01:14:00,470 --> 01:14:01,810
encoding in the web

1190
01:14:01,810 --> 01:14:06,080
so here for example in textrunner the system began new world in our and it's

1191
01:14:06,080 --> 01:14:07,400
only and use that

1192
01:14:07,440 --> 01:14:10,090
we can ask now very slight

1193
01:14:10,910 --> 01:14:17,250
wildcard topic asking you in which relation to paper topic standing right so you get

1194
01:14:17,250 --> 01:14:20,470
that things like paper discusses

1195
01:14:20,490 --> 01:14:21,550
o addresses

1196
01:14:21,660 --> 01:14:24,780
and so on and so on so what do we learn from these kinds of

1197
01:14:25,000 --> 01:14:29,180
systems and what do we have to achieve but managed to do if we want

1198
01:14:29,180 --> 01:14:32,560
to make use of this right for right now this is just a

1199
01:14:32,590 --> 01:14:36,380
particularly closer what we what you see when we talk about here are kind of

1200
01:14:36,380 --> 01:14:42,450
objects like paper in topic with some relations between different topics and maybe some form

1201
01:14:42,450 --> 01:14:47,230
of uncertainty the numbers here is something like the number of times you have extracted

1202
01:14:47,240 --> 01:14:48,460
this kind of thing

1203
01:14:48,550 --> 01:14:51,920
let's not have a debate about whether really uncertainty or not you can do that

1204
01:14:51,920 --> 01:14:56,720
in different ways for this tutorial here the best viewed as an uncertainty ninety if

1205
01:14:56,720 --> 01:15:00,900
you see it quite often this relation with a high number of pounds and we

1206
01:15:00,900 --> 01:15:03,610
are sure about it all more about it

1207
01:15:03,630 --> 01:15:06,610
if you just want to come

1208
01:15:13,440 --> 01:15:18,840
it tells us that task we are facing now we will face in the future

1209
01:15:18,900 --> 01:15:24,010
some are characterized by objects and these objects and and in contrast to traditional using

1210
01:15:24,010 --> 01:15:29,770
machine learning and AI are not just feature vectors right they are more than they

1211
01:15:29,770 --> 01:15:31,420
have maybe even part

1212
01:15:31,450 --> 01:15:36,740
they certainly have relations to other objects they might be trees graphs whatever it's an

1213
01:15:36,740 --> 01:15:40,330
object is not just one line in a table but much more than the more

1214
01:15:42,090 --> 01:15:46,400
given that there are relations we should definitely say objects not really

1215
01:15:46,410 --> 01:15:53,240
independent identically distributed but they're like neighborhoods right they are interconnected with other objects and

1216
01:15:53,240 --> 01:15:57,690
information about the neighbours are related objects of a lot about the object we are

1217
01:15:57,690 --> 01:15:59,090
currently facing

1218
01:15:59,130 --> 01:16:02,530
it might be class hierarchies and the semantic web community

1219
01:16:02,570 --> 01:16:06,460
i mean this is all about all the triple stores they talk about our data

1220
01:16:06,460 --> 01:16:08,990
are still coming from the ontology

1221
01:16:09,480 --> 01:16:15,590
and definitely properties of one object depends on the properties of the other ones like

1222
01:16:15,610 --> 01:16:18,830
if i look into the audience here i don't know anything about most of you

1223
01:16:19,610 --> 01:16:22,150
but i definitely know that you're attending UAI

1224
01:16:22,150 --> 01:16:26,360
because of that i also know that you somehow interest in computer science

1225
01:16:26,380 --> 01:16:31,900
announcer somehow interest in mathematics they just using my world knowledge and using the relations

1226
01:16:31,900 --> 01:16:36,630
between you and other entities like i i can draw much more conclusions than just

1227
01:16:36,630 --> 01:16:42,530
looking at you like a single person each of your independent that's all about

1228
01:16:43,950 --> 01:16:45,440
if we agree on that

1229
01:16:45,450 --> 01:16:48,440
definitely the question is how can we deal with this kind of knowledge how can

1230
01:16:48,440 --> 01:16:53,600
we make sense of the knowledge base of the data OK we do inference

1231
01:16:53,650 --> 01:16:57,570
so let's have a look at how people have commented a way

1232
01:16:57,590 --> 01:17:01,820
over the last ten twenty thirty years so one classical way

1233
01:17:01,840 --> 01:17:04,030
of dealing with the complexity and

1234
01:17:04,130 --> 01:17:06,840
things like we have objects and relations among them

1235
01:17:07,100 --> 01:17:08,670
first order logic

1236
01:17:08,700 --> 01:17:14,230
right so traditionally we may have an explicit enumeration we have comic representation of first

1237
01:17:14,230 --> 01:17:15,840
order or relational

1238
01:17:15,850 --> 01:17:22,150
logical representation the benefit of using logic is essentially that you get a compressed representation

1239
01:17:22,150 --> 01:17:25,740
of what you have included otherwise in in the long run this story narration of

1240
01:17:25,740 --> 01:17:30,580
all the facts so here for example where you list all the daughter of relations

1241
01:17:30,610 --> 01:17:35,050
for all pairs of individuals separately you just define

1242
01:17:35,080 --> 01:17:39,240
right so we're now when we have any information about father of female we can

1243
01:17:39,240 --> 01:17:44,260
conclude that someone is the daughter of someone so you get this compression

1244
01:17:44,270 --> 01:17:45,380
and then you can

1245
01:17:45,400 --> 01:17:47,860
you get a general rule

1246
01:17:47,890 --> 01:17:52,880
i and within then this kind of more traditional knowledge representation there was a lot

1247
01:17:52,880 --> 01:17:57,440
interesting going on like you can ask how to read and all the different knowledge

1248
01:17:57,440 --> 01:18:01,650
we talking about like trees graphs hierarchies and so on but they also

1249
01:18:01,650 --> 01:18:05,530
very interesting inference algorithms typically in the early days of leave

1250
01:18:05,530 --> 01:18:11,900
here i have not seen much UAI like satisfiability SAT solvers resolution theorem proving and

1251
01:18:11,910 --> 01:18:13,610
so on

1252
01:18:13,630 --> 01:18:14,860
right so

1253
01:18:14,880 --> 01:18:19,890
two even further illustrate that that's an example you're as like to give

1254
01:18:19,940 --> 01:18:23,900
also in his book if you want to and coach has an atomic representation where

1255
01:18:23,900 --> 01:18:28,380
you just list everything this would maybe take the same millions of pages

1256
01:18:28,400 --> 01:18:30,380
maybe an accelerating healing

1257
01:18:30,390 --> 01:18:32,130
if you use

1258
01:18:32,140 --> 01:18:36,980
propositional logic which is something like a factorized representation you can get already much more

1259
01:18:36,980 --> 01:18:41,780
compact but only if you use if you abstract of certain places on the board

1260
01:18:41,850 --> 01:18:46,550
you can get a one or two-page kind of compression representation of the theory of

1261
01:18:46,580 --> 01:18:49,350
the rules of chess

1262
01:18:49,990 --> 01:18:55,180
but of course task not just structure they are not just complex but

1263
01:18:55,200 --> 01:18:59,360
there's also a lot of uncertainty involved in that's why we're all here i and

1264
01:18:59,370 --> 01:19:00,910
we want to deal with

1265
01:19:02,240 --> 01:19:05,360
probability because information might be

1266
01:19:06,380 --> 01:19:08,090
might be incomplete

1267
01:19:08,100 --> 01:19:13,870
we may just be uncertain about certain things that might be typos in there if

1268
01:19:13,870 --> 01:19:16,720
you think of database and if you think of the task of cleaning and they

1269
01:19:16,720 --> 01:19:21,840
don't care big company and you have people creating and all the information about customers

1270
01:19:21,950 --> 01:19:26,020
very likely that there here and then a few typos in there so for example

1271
01:19:26,020 --> 01:19:31,650
i recently troubles financial department because they retracting my last name wrongly but only with

1272
01:19:31,650 --> 01:19:32,740
too little

1273
01:19:32,760 --> 01:19:36,850
little typos took them quite long and what faces people say oh it's in the

1274
01:19:36,880 --> 01:19:38,940
system so it's true

1275
01:19:38,960 --> 01:19:41,940
and i always try to tell them well it's in the system so it's more

1276
01:19:41,940 --> 01:19:45,180
likely to be true but they still don't get it to let let's try to

1277
01:19:45,180 --> 01:19:46,590
work on that

1278
01:19:46,600 --> 01:19:47,590
to then

1279
01:19:47,590 --> 01:19:51,230
again we can ask how do computer systems nowadays

1280
01:19:51,240 --> 01:19:55,200
deal with uncertainty and well that's all what you know about in the sand mixture

1281
01:19:55,200 --> 01:19:57,710
models hidden markov models bayesian networks

1282
01:19:57,710 --> 01:20:00,870
markov random fields and maximum entropy models whatever

1283
01:20:00,880 --> 01:20:04,800
take your favourite on the right so we have these two kind of taxis in

1284
01:20:06,040 --> 01:20:08,510
if you look at what classically in

1285
01:20:08,560 --> 01:20:12,350
AI people would have done to tackle these problems

1286
01:20:12,370 --> 01:20:13,750
and so

1287
01:20:13,760 --> 01:20:20,230
given these two axes you can ask with traditional AI or UAI scale

1288
01:20:20,240 --> 01:20:23,210
so given this simplified view on

1289
01:20:23,230 --> 01:20:24,670
i hope you agree

1290
01:20:24,690 --> 01:20:26,120
this will not work

1291
01:20:27,550 --> 01:20:31,180
let's see how you traditionally do it like with based on that

1292
01:20:31,190 --> 01:20:32,490
what does it mean

1293
01:20:32,540 --> 01:20:35,610
the traditional view we have something like table

1294
01:20:35,620 --> 01:20:38,070
right so you features head of labels

1295
01:20:38,100 --> 01:20:42,970
OK and then you do whatever you like you can do prediction you may do

1296
01:20:45,340 --> 01:20:47,340
variable model one

1297
01:20:47,350 --> 01:20:50,080
so what do is essentially to try to

1298
01:20:50,090 --> 01:20:55,200
have a lot of independence within you are random variables

1299
01:20:55,210 --> 01:20:59,000
and then try to get a compact representation of these independencies

1300
01:20:59,010 --> 01:21:03,130
let's say in terms of bayesian network in order to do

1301
01:21:03,190 --> 01:21:04,700
that's what we all know

1302
01:21:06,090 --> 01:21:10,600
in many cases like i was showing you already with world-wide mind project from the

1303
01:21:11,470 --> 01:21:14,950
we know that we are not having just a single cable or

1304
01:21:14,970 --> 01:21:18,860
indeed if you go for universal cable then this would be a very large table

1305
01:21:18,880 --> 01:21:19,830
with a lot of knowledge

1306
01:21:20,420 --> 01:21:24,370
it's not a good idea that already what whatever theory tells you so if you

1307
01:21:24,370 --> 01:21:26,370
go for any kind of normal form

1308
01:21:26,380 --> 01:21:30,690
then you would have not a single table but several tables with relations between

1309
01:21:30,710 --> 01:21:32,520
how do we deal

1310
01:21:34,470 --> 01:21:38,870
yet another example what was taken from daphne and here

1311
01:21:39,140 --> 01:21:42,410
something at least i had to learn

1312
01:21:42,760 --> 01:21:44,880
when i was a phd student

1313
01:21:45,250 --> 01:21:49,190
as everybody we're going to submit a paper to a conference and then you know

1314
01:21:49,190 --> 01:21:55,090
your supervisor if he has no time to tell you that have a certificate getting

1315
01:21:56,100 --> 01:22:00,000
but he's not talking a lot about you do about every rule like you may

1316
01:22:00,000 --> 01:22:04,260
say that it is sometimes get a b and so on so he's giving you

1317
01:22:04,260 --> 01:22:05,700
just these rules

1318
01:22:05,710 --> 01:22:09,970
so from that you build up your little structure in bayesian networks

1319
01:22:09,990 --> 01:22:15,930
like the quality of the paper difficult to certain conferences and you try to predict

1320
01:22:15,950 --> 01:22:21,870
the grade of your paper to see whether it's worth submitting it clearly getting

1321
01:22:21,870 --> 01:22:23,530
you could probably apply

1322
01:22:23,550 --> 01:22:30,410
the expectation propagation algorithm for this problem you can apply the variational bayesian framework this

1323
01:22:30,410 --> 01:22:33,780
problem this is something that we've done played around with

1324
01:22:33,830 --> 01:22:38,600
so all those approximate inference tools can now be used to try to solve this

1325
01:22:40,700 --> 01:22:45,510
and i'm not selling one versus the other they have advantages and disadvantages

1326
01:22:47,490 --> 01:22:50,080
so to summarize parameter learning

1327
01:22:51,700 --> 01:22:55,510
we had the case with complete data

1328
01:22:55,560 --> 01:22:59,450
in the case of incomplete or missing data are hidden variables

1329
01:22:59,470 --> 01:23:03,060
and then we consider maximum likelihood versus bayesian

1330
01:23:03,100 --> 01:23:06,050
and these two are really easy

1331
01:23:06,100 --> 01:23:12,760
they just involve counting frequencies are updating dirichlet distributions which are just frequencies plus some

1332
01:23:12,760 --> 01:23:14,870
hyperparameters added to them

1333
01:23:14,890 --> 01:23:19,220
those alpha is that to them both these cases were a bit harder we had

1334
01:23:19,220 --> 01:23:25,700
ian algorithm here MCMC the terribly or this variational bayesian sometimes called variational bayes in

1335
01:23:25,700 --> 01:23:30,490
yemen algorithm because this is a simple generalization of the algorithm here

1336
01:23:30,560 --> 01:23:35,220
these are always trying to iteratively fill in the missing data and then do

1337
01:23:35,220 --> 01:23:37,830
parameter estimation and inference

1338
01:23:39,120 --> 01:23:44,430
so any any questions about this

1339
01:23:49,220 --> 01:23:55,240
i was

1340
01:23:55,260 --> 01:23:59,100
so the question was in the case where you need to do variational bayes or

1341
01:23:59,100 --> 01:24:00,510
maybe one of these other

1342
01:24:00,560 --> 01:24:05,330
inference methods you might as well choose the non conjugate prior well

1343
01:24:06,680 --> 01:24:11,220
yes and no i mean because you're already doing approximate inference

1344
01:24:11,240 --> 01:24:17,930
you may have the flexibility of choosing larger families of priors then original analytic

1345
01:24:17,970 --> 01:24:20,160
answers you with the complete data

1346
01:24:21,140 --> 01:24:27,460
the updates for variational bayes you're going to hear about variational methods in common because

1347
01:24:27,460 --> 01:24:31,450
talk in more detail by the way for everybody else but the update variational bayes

1348
01:24:31,450 --> 01:24:35,970
are incredibly simple if the priors are conjugate

1349
01:24:36,160 --> 01:24:41,450
so everything becomes very computationally fast and that's the sort of situation where

1350
01:24:41,470 --> 01:24:47,200
the time complexity is almost the same whether you're bayesian or to a maximum likelihood

1351
01:24:47,200 --> 01:24:48,720
between these two

1352
01:24:48,720 --> 01:24:55,160
whereas if you choose arbitrarily complicated priors you're updates become very very hard

1353
01:24:55,180 --> 01:24:56,740
and keep in mind that

1354
01:24:56,760 --> 01:25:01,140
you know even if you choose the sort of complicated prior have a huge datasets

1355
01:25:01,160 --> 01:25:05,240
you're likely functions going to swamp out the prior anyway

1356
01:25:06,390 --> 01:25:07,930
you know it

1357
01:25:07,950 --> 01:25:10,720
you can worry about your choice of prior but if you have a a lot

1358
01:25:10,720 --> 01:25:14,680
of data you just need to make sure your prior puts reasonable amounts of mass

1359
01:25:16,060 --> 01:25:20,290
reasonable set of hypotheses basically

1360
01:25:20,310 --> 01:25:23,580
additionally distributions to put reasonable mass on

1361
01:25:23,600 --> 01:25:25,050
lots of different things

1362
01:25:25,060 --> 01:25:29,100
OK the questions

1363
01:25:33,470 --> 01:25:41,350
for non discrete data so you know there are many kinds of non discrete data

1364
01:25:41,950 --> 01:25:44,330
you know but but let's think of like simple

1365
01:25:44,370 --> 01:25:46,100
simple cases are

1366
01:25:46,100 --> 01:25:50,830
calcium variables a linear relationship between the parameters then

1367
01:25:50,850 --> 01:25:54,740
you can do this whole conjugacy trick again

1368
01:25:54,740 --> 01:25:57,680
and basically becomes a complicated way of doing

1369
01:25:57,700 --> 01:25:59,240
you know

1370
01:25:59,260 --> 01:26:05,720
regression of children on their parents in a big graphs but

1371
01:26:05,740 --> 01:26:09,160
i i would assume that i mean that's quite limiting

1372
01:26:09,160 --> 01:26:16,740
o thing depends really on the application for very general for very general

1373
01:26:17,950 --> 01:26:19,330
value data

1374
01:26:19,350 --> 01:26:23,030
and complicated relationships between the parents and children

1375
01:26:24,120 --> 01:26:28,560
one of the approximate inference methods would have to be used either something like EP

1376
01:26:28,680 --> 01:26:34,910
or very safe thing to try is markov chain monte carlo methods et cetera

1377
01:26:35,030 --> 01:26:39,180
particle filters et cetera all the things that you'll hear about

1378
01:26:41,580 --> 01:26:45,950
so this is a summary of parameter learning let me arms it through a

1379
01:26:45,970 --> 01:26:47,680
structure learning

1380
01:26:47,700 --> 01:26:49,950
and then i want to give you a flavor for

1381
01:26:49,970 --> 01:26:54,010
this sort of a really more like a research topic that actually hides a whole

1382
01:26:54,010 --> 01:26:55,470
bunch of things together

1383
01:26:58,180 --> 01:27:03,490
structure learning well structure learning is the following given a data set of observations of

1384
01:27:03,490 --> 01:27:09,240
a bunch of variables can we learn the structure of the graphical model from data

1385
01:27:09,260 --> 01:27:13,560
so what do i mean by structure well we know what the variables are is

1386
01:27:13,560 --> 01:27:15,780
a b c d e here

1387
01:27:15,830 --> 01:27:19,430
five variables the structure corresponds to

1388
01:27:19,450 --> 01:27:25,160
different choices of the set of edges connecting up these graphs

1389
01:27:25,180 --> 01:27:30,240
OK so these are four different structures for this and for these five variables and

1390
01:27:30,240 --> 01:27:33,780
the number of possible structures is absolutely huge it grows

1391
01:27:33,850 --> 01:27:35,780
you know like

1392
01:27:35,780 --> 01:27:39,180
two the power and squared

1393
01:27:39,220 --> 01:27:41,870
roughly four and variables

1394
01:27:43,140 --> 01:27:46,410
but let's try to learn a good structure from data and i'm not going to

1395
01:27:46,410 --> 01:27:51,330
assume that structure corresponds any sort of causal relationships or anything like that

1396
01:27:51,430 --> 01:27:52,780
we're now

1397
01:27:52,810 --> 01:27:54,140
thank you

1398
01:27:54,140 --> 01:27:55,700
so how do we do this

1399
01:27:55,720 --> 01:28:01,970
well broadly speaking for directed graphs there are two kind of camps for the structure

1400
01:28:04,370 --> 01:28:06,010
one of them is

1401
01:28:06,060 --> 01:28:08,580
constraint based learning

1402
01:28:08,600 --> 01:28:15,430
where what's done is to come up with statistical tests of marginal and conditional independence

1403
01:28:15,470 --> 01:28:19,760
so it's sort of as yourself alright i got the measurements of these five variables

1404
01:28:19,780 --> 01:28:24,240
let's do a classical test of independence between a and b

1405
01:28:24,260 --> 01:28:29,580
OK that has comes out saying a b are independent OK

1406
01:28:29,640 --> 01:28:31,910
with some confidence or something

1407
01:28:31,930 --> 01:28:33,530
for significance

1408
01:28:33,580 --> 01:28:36,120
all right well now let's do a given

1409
01:28:36,140 --> 01:28:38,160
a and b given c

1410
01:28:38,180 --> 01:28:40,220
is that conditional independence

1411
01:28:40,240 --> 01:28:44,850
true or not let's let's get an answer yes or no with some

1412
01:28:44,870 --> 01:28:49,160
you know p value or confidence of some kind

1413
01:28:49,160 --> 01:28:50,180
and now

1414
01:28:50,180 --> 01:28:55,020
he proposed some modifications to the boar model he like the boar model you wanna

1415
01:28:55,020 --> 01:28:59,640
throw out he liked the concept of a planetary model but then he want to

1416
01:29:00,030 --> 01:29:04,860
maybe look to the heavens no capitalist laws of planetary motion what's the orbits of

1417
01:29:04,860 --> 01:29:06,340
the planets described

1418
01:29:06,860 --> 01:29:08,960
it's already website

1419
01:29:09,400 --> 01:29:15,820
so Sommerfeld said how about this suppose just supposing this is not to scale exaggerated

1420
01:29:16,100 --> 01:29:24,620
sentiment suppose in addition to a spherical orbital suppose the electron might describe an elliptical

1421
01:29:28,280 --> 01:29:34,140
now over all this is roughly the same it's not super elliptical it's just mildly

1422
01:29:34,140 --> 01:29:41,160
elliptical but just enough that it's not exactly spherical so this could give users have

1423
01:29:41,170 --> 01:29:45,320
your cake and eat it too you could say this but this is the principle

1424
01:29:45,320 --> 01:29:48,380
quantum number of war it's

1425
01:29:48,400 --> 01:29:55,670
but within and there's a little bit of fine structure fine structure that is to

1426
01:29:55,670 --> 01:30:00,360
say they're details there that the 1st didn't quite catch a

1427
01:30:01,380 --> 01:30:05,720
so suppose we have a lot more than 1 level we have a plurality of

1428
01:30:05,720 --> 01:30:06,760
elliptical orbits

1429
01:30:10,760 --> 01:30:16,560
so we have elliptical orbits but they're roughly of the same dimension as the original

1430
01:30:16,560 --> 01:30:27,180
circular orbit this we have sort of a urbanity calls this a shell containing multiple

1431
01:30:31,140 --> 01:30:36,660
which he termed baubles to distinguish them from the circular orbits

1432
01:30:37,450 --> 01:30:43,340
white-collar shell model he said think about the eggs shall be eggs shall we can

1433
01:30:43,340 --> 01:30:51,380
describe it but the NHL itself has something so this is a sense of what

1434
01:30:51,380 --> 01:30:52,600
what Sommerfeld was given

1435
01:30:53,590 --> 01:30:58,140
so he says how am I going to capture these ideas quantitatively while the shell

1436
01:30:58,140 --> 01:31:02,860
could be captured by the quantity and but these orbitals some of them circular some

1437
01:31:02,860 --> 01:31:09,080
of elliptical under new quantum numbers you quantum numbers

1438
01:31:09,170 --> 01:31:15,250
In order to capture these new ideas

1439
01:31:15,800 --> 01:31:21,020
and so let's take a look at the quantum numbers that are Sommerfeld gave us

1440
01:31:21,640 --> 01:31:24,880
so the first one is on and it is as it was in the case

1441
01:31:24,880 --> 01:31:29,520
of the boar model so this is called the principal shall quality the principle of

1442
01:31:29,530 --> 01:31:36,680
quantum number or the shell quantum number principle shall quantum number and it talks about

1443
01:31:36,680 --> 01:31:41,440
size it talks about size the size of that is to say the distance from

1444
01:31:41,450 --> 01:31:44,020
the nucleus to the

1445
01:31:45,700 --> 01:31:51,160
it takes values 1 2 3 and so on up to infinity infinity we're talking

1446
01:31:51,160 --> 01:31:52,780
about a free electron

1447
01:31:52,820 --> 01:31:58,340
and in parallel there's another notation that used the spectroscopy

1448
01:31:58,510 --> 01:32:03,860
came up with their own notation they like numbers the spectroscopy stews letters but you

1449
01:32:04,050 --> 01:32:09,070
spectroscopy is the funny bunch don't the very suspicious so here's what happens if you

1450
01:32:09,070 --> 01:32:13,970
look on this chart here for a while we thought Baltimore was the bottom of

1451
01:32:13,970 --> 01:32:15,470
the barrel

1452
01:32:15,490 --> 01:32:19,950
that's equals 2 and then when the detectors got better we saw that n equals

1453
01:32:19,950 --> 01:32:25,300
1 so the spectroscopy said what if somebody comes along with an even better detector

1454
01:32:25,800 --> 01:32:29,900
and finds transitions to energy levels below

1455
01:32:29,910 --> 01:32:32,990
that which we're calling 1

1456
01:32:33,010 --> 01:32:36,430
so we're going to get ready we're going to give letters to these and they

1457
01:32:36,430 --> 01:32:40,200
started with the letter cake is a somewhere in the middle of the alphabet

1458
01:32:40,280 --> 01:32:44,990
so if we are discovered energy level lower than equals 1 we can use the

1459
01:32:44,990 --> 01:32:46,630
latter will be the j

1460
01:32:46,820 --> 01:32:50,720
so this K L M and this notation is used to this day when we

1461
01:32:50,720 --> 01:32:57,300
talk about X rays x-rays generated by electrons falling down to ground state called came

1462
01:32:57,340 --> 01:32:58,590
x rays

1463
01:32:58,610 --> 01:33:04,240
so this is the other notation for the values that can contain now let's get

1464
01:33:04,240 --> 01:33:06,720
into the contributions of

1465
01:33:06,720 --> 01:33:13,240
Sommerfeld he called the next quantum number lowercase L and this is the orbital quantum

1466
01:33:13,240 --> 01:33:15,900
number the orbital quantum number

1467
01:33:16,470 --> 01:33:21,430
and it describes the shape of the orbital memorize we needed some way to distinguish

1468
01:33:21,780 --> 01:33:25,880
purely circular from elliptical or other shape orbitals

1469
01:33:26,150 --> 01:33:32,070
and the orbital quantum number takes values 0 1 2 up to the value of

1470
01:33:32,070 --> 01:33:32,990
n minus 1

1471
01:33:33,610 --> 01:33:36,220
up to the value and minus 1

1472
01:33:36,240 --> 01:33:43,590
and the spectroscopists newsletters they they refused to use numbers they're very numeral folder so

1473
01:33:43,590 --> 01:33:49,110
that use lowercase letters to distinguish the orbital quantum number from the principle quantum number

1474
01:33:49,400 --> 01:33:50,680
and so when the

1475
01:33:50,840 --> 01:33:57,300
l equals 0 it's case s for shop these would be very sharp lines then

1476
01:33:57,590 --> 01:34:03,970
P 4 an l equals 1 which is the principal d over l equals to

1477
01:34:04,080 --> 01:34:06,470
which stands for diffuse

1478
01:34:06,530 --> 01:34:11,200
and f which stands for fundamental because by the time you get to f level

1479
01:34:11,490 --> 01:34:16,680
you got such compression all of the spectral lines starting look very similar to those

1480
01:34:16,680 --> 01:34:20,970
file over the lousy mode and flips ten percent bits we have to make a

1481
01:34:20,970 --> 01:34:24,740
phone call the last three times as long or we have to buy three telephone

1482
01:34:24,740 --> 01:34:26,370
lines that allows a

1483
01:34:27,180 --> 01:34:30,930
and the way we quantify this is really thing called the rate of communication the

1484
01:34:30,930 --> 01:34:37,620
rate was won by definition when we started with the channel with no

1485
01:34:37,640 --> 01:34:38,680
error correction

1486
01:34:38,700 --> 01:34:42,820
and we had to probability of death and what we've done is we've improved their

1487
01:34:42,820 --> 01:34:47,450
probably but the rate has got low we define the rate to be the ratio

1488
01:34:47,450 --> 01:34:50,820
of the number of source bits that are actually being sent to the number of

1489
01:34:50,820 --> 01:34:52,660
times we use the channel

1490
01:34:52,680 --> 01:34:56,950
and so for three which are rubbed off three

1491
01:34:56,970 --> 01:34:58,820
has the property

1492
01:35:00,180 --> 01:35:04,640
the number of cells called k one and two

1493
01:35:04,660 --> 01:35:10,780
the number of different bits which we call and which was three and the range

1494
01:35:12,140 --> 01:35:16,390
the rate is one

1495
01:35:16,410 --> 01:35:18,870
so that's the bad news

1496
01:35:18,890 --> 01:35:22,280
but it is promising isn't it

1497
01:35:22,300 --> 01:35:26,970
i'll leave homework exercise to discuss whether r two is a good idea

1498
01:35:26,970 --> 01:35:31,640
or not this was all one which means code

1499
01:35:31,660 --> 01:35:35,660
and here's another homework exercise for you

1500
01:35:35,700 --> 01:35:42,160
what happens when we switch to an where n is an odd number like five

1501
01:35:42,160 --> 01:35:45,870
o seven o thirteen o fifty one

1502
01:35:46,910 --> 01:35:48,430
and in particular

1503
01:35:48,490 --> 01:35:50,870
how big does and need to be

1504
01:35:50,870 --> 01:35:57,180
o thing about are and how big this and need to be

1505
01:35:57,200 --> 01:36:02,570
to deliver

1506
01:36:04,740 --> 01:36:09,050
which is my name for the probability of being error

1507
01:36:09,070 --> 01:36:12,330
the probability of

1508
01:36:12,350 --> 01:36:13,850
the error

1509
01:36:13,870 --> 01:36:19,320
to deliver the TV that i said we want to register my fifteen

1510
01:36:19,330 --> 01:36:21,140
for today's lecture

1511
01:36:21,140 --> 01:36:24,490
because they need to be you understand the question

1512
01:36:24,550 --> 01:36:28,100
OK so that's the problem and when you've done your homework problems

1513
01:36:28,100 --> 01:36:32,740
you will find that the answer for at this point what

1514
01:36:32,780 --> 01:36:35,070
is sixty one

1515
01:36:35,120 --> 01:36:37,450
here's the answer that book

1516
01:36:37,470 --> 01:36:41,330
so assuming at this point one

1517
01:36:41,350 --> 01:36:44,200
and is

1518
01:36:44,220 --> 01:36:47,180
sixty one

1519
01:36:53,800 --> 01:36:58,370
and this is a graph showing exactly the numbers we've just been talking about one

1520
01:36:58,910 --> 01:37:04,180
three but the end are sixty one and this is saying yes we can make

1521
01:37:04,250 --> 01:37:07,830
encoding and decoding systems have the property

1522
01:37:07,890 --> 01:37:11,390
that we can get the error probability down to the required level

1523
01:37:11,390 --> 01:37:13,390
so this is possible

1524
01:37:13,410 --> 01:37:17,950
we just need to put sixty one this tries to box with his your this

1525
01:37:20,350 --> 01:37:25,870
OK one describing there and it costs us sixty one times as much to make

1526
01:37:25,910 --> 01:37:28,740
as we'd really like

1527
01:37:31,200 --> 01:37:35,370
can we do better here is the astonishing amazing things

1528
01:37:35,390 --> 01:37:39,660
the amazing thing is we can do much better than repetition codes

1529
01:37:39,680 --> 01:37:42,010
and so anyone want to

1530
01:37:42,030 --> 01:37:45,300
it's just always abiding redundancy

1531
01:37:45,490 --> 01:37:49,950
apart from repetition

1532
01:37:53,910 --> 01:37:56,370
what is sphere packing me

1533
01:38:10,120 --> 01:38:16,950
OK so many lattice

1534
01:38:16,950 --> 01:38:18,410
o points

1535
01:38:21,260 --> 01:38:22,570
a high dimensional space

1536
01:38:22,590 --> 01:38:24,050
the idea

1537
01:38:24,070 --> 01:38:27,090
nicholas points in a high dimensional space

1538
01:38:31,640 --> 01:38:35,010
you want that lattice of points is going to be transmission so it's going to

1539
01:38:35,010 --> 01:38:40,120
be a great long list transmissions like zero zero zero zero zero zero zero could

1540
01:38:40,760 --> 01:38:43,910
possible transmission and

1541
01:38:43,930 --> 01:38:48,370
and then you could also have long

1542
01:38:48,390 --> 01:38:52,720
and maybe not long from OK

1543
01:38:52,850 --> 01:38:56,280
and you can have some systematic way of making these points such that the a

1544
01:38:56,280 --> 01:38:58,570
big gap between all of them right

1545
01:38:58,700 --> 01:39:01,510
and then you take source files

1546
01:39:01,530 --> 01:39:04,890
let's say for simplicity we just had

1547
01:39:06,490 --> 01:39:11,200
this is your set of lattice point it's a possible source of i'm going to

1548
01:39:11,200 --> 01:39:14,030
work with i'm going to be zero zero zero one

1549
01:39:14,050 --> 01:39:20,050
one zero one one this is an example of a lot to the idea is

1550
01:39:20,050 --> 01:39:25,530
going to block of source because at the time like one of the time and

1551
01:39:25,530 --> 01:39:29,680
repeating them we taken two at a time and then every pair is going to

1552
01:39:31,510 --> 01:39:34,430
in a more complicated way than simple repetition

1553
01:39:34,490 --> 01:39:35,800
like that

1554
01:39:35,820 --> 01:39:39,950
OK this is an example of the lattice of points in a dimensional space the

1555
01:39:39,950 --> 01:39:44,050
four of them and we can associate them with source strength that's school the block

1556
01:39:46,550 --> 01:39:49,320
four it to work well we want these to be a long way from each

1557
01:39:49,320 --> 01:39:52,740
other because we don't want flips to confuse them with each other

1558
01:39:52,740 --> 01:39:54,500
m and c are constants

1559
01:39:55,600 --> 01:39:58,450
the q is proportional to develop

1560
01:39:58,470 --> 01:40:01,260
if we divide both the time elapsed

1561
01:40:01,450 --> 01:40:05,600
the invented with the temperature rises when the data with heat flows into the system

1562
01:40:05,640 --> 01:40:11,580
if he playing at a steady rate pressure should rise and indeed it does

1563
01:40:11,580 --> 01:40:12,970
part of the ice

1564
01:40:12,970 --> 01:40:14,600
go from minus thirty

1565
01:40:14,660 --> 01:40:17,790
minus twenty to minus ten and so on

1566
01:40:17,830 --> 01:40:19,520
but once it hits zero

1567
01:40:19,540 --> 01:40:22,140
it gets stuck

1568
01:40:22,160 --> 01:40:25,700
i know he is coming in but it's not getting harder

1569
01:40:25,720 --> 01:40:26,930
but i notice

1570
01:40:27,040 --> 01:40:30,290
the ice is beginning to map

1571
01:40:30,330 --> 01:40:31,770
that would be a period

1572
01:40:31,790 --> 01:40:33,680
between here and here

1573
01:40:33,680 --> 01:40:36,850
when i pop in calories i don't get any increase in temperature but i get

1574
01:40:36,850 --> 01:40:40,790
conversion of ice into water

1575
01:40:40,830 --> 01:40:43,350
and that would a period when the guys

1576
01:40:43,390 --> 01:40:49,220
looks like some water would sometimes of ice floating on

1577
01:40:49,240 --> 01:40:51,430
and until all the ice

1578
01:40:51,470 --> 01:40:53,620
was converted to water

1579
01:40:53,720 --> 01:40:57,950
the whole system is stuck at that time

1580
01:40:58,000 --> 01:41:01,870
that's very interesting properties and a few really took a real part

1581
01:41:01,910 --> 01:41:04,430
and you put a chunk of ice on it you know what will happen right

1582
01:41:04,450 --> 01:41:07,930
the bottom of the ice will melt it may even evaporate

1583
01:41:07,970 --> 01:41:11,020
that's not what i'm talking about because that's not a system where there's a globally

1584
01:41:11,020 --> 01:41:14,470
defined but i want you to heat the i so slowly

1585
01:41:14,470 --> 01:41:16,520
i mean to put a little bit of calories

1586
01:41:16,520 --> 01:41:20,830
give it enough time for all these guys to share the heat the whole system

1587
01:41:20,870 --> 01:41:23,700
has one single common temperature

1588
01:41:23,810 --> 01:41:27,350
that's what the temperature rise and saying it gets stuck in zero

1589
01:41:27,370 --> 01:41:31,970
but your calories are getting something converting ice into what

1590
01:41:32,020 --> 01:41:34,890
and you can ask OK what penalty do have to pay

1591
01:41:34,910 --> 01:41:37,100
that's called the latent heat of melting

1592
01:41:37,120 --> 01:41:38,490
and again i know only

1593
01:41:38,540 --> 01:41:40,350
in calories per gram

1594
01:41:40,410 --> 01:41:45,310
is it calories for example one

1595
01:41:45,350 --> 01:41:47,180
some of you don't thank you

1596
01:41:47,240 --> 01:41:49,760
now goes not to raise the temperature

1597
01:41:49,770 --> 01:41:52,620
but to melt some more stuff

1598
01:41:52,620 --> 01:41:57,540
the latent heat of melting

1599
01:41:57,580 --> 01:41:59,580
that so much q you need to melt

1600
01:41:59,580 --> 01:42:01,200
that more the stuff

1601
01:42:01,220 --> 01:42:07,330
and the elevators from substance to substance but walkers eighty calories per gram

1602
01:42:07,390 --> 01:42:12,540
one melt mercury from solid making the liquid crystal have different

1603
01:42:12,540 --> 01:42:13,680
then once

1604
01:42:13,700 --> 01:42:15,790
everybody has become

1605
01:42:17,270 --> 01:42:22,790
then that uniform system of water start growing

1606
01:42:22,870 --> 01:42:25,870
and this is called a phase change this changes when

1607
01:42:27,270 --> 01:42:33,040
atomic arrangement from the regular race for example the form solid into a liquid

1608
01:42:33,060 --> 01:42:36,290
in the solid everybody has its place you can check in on where you are

1609
01:42:36,370 --> 01:42:39,700
liquid you can run around

1610
01:42:39,810 --> 01:42:41,850
the specific heat of eyes

1611
01:42:41,910 --> 01:42:44,260
it's not the the same as the specific you know what

1612
01:42:44,310 --> 01:42:46,500
because the careful even though

1613
01:42:46,660 --> 01:42:48,720
two made up of water molecules

1614
01:42:48,740 --> 01:42:51,740
the calories needed to hit one gram of ice is roughly half what it takes

1615
01:42:51,740 --> 01:42:53,470
to heat one grammy of water

1616
01:42:53,580 --> 01:42:56,470
in these problems don't make the mistake

1617
01:42:56,520 --> 01:42:59,490
OK then you go along and i guess you know what the next stopping point

1618
01:42:59,490 --> 01:43:01,600
is when it comes to one hundred degrees

1619
01:43:01,640 --> 01:43:03,140
again it gets stuck

1620
01:43:03,140 --> 01:43:04,540
well everybody

1621
01:43:04,560 --> 01:43:06,970
their prices and then you get the

1622
01:43:06,990 --> 01:43:09,990
and you can have superheated steam which is even higher than

1623
01:43:10,040 --> 01:43:11,640
hundred degrees

1624
01:43:11,680 --> 01:43:14,410
so that's the latent heat of vaporization

1625
01:43:14,430 --> 01:43:18,200
i don't know what you want to write something i think is five hundred something

1626
01:43:19,930 --> 01:43:21,390
this information i don't

1627
01:43:21,450 --> 01:43:26,080
katie in my head

1628
01:43:26,100 --> 01:43:27,450
so you can

1629
01:43:27,490 --> 01:43:31,180
if i tell you i took some ice minus thirty dumped in

1630
01:43:31,200 --> 01:43:33,120
five thousand calories

1631
01:43:33,140 --> 01:43:36,490
where will it end up you got first spend a few calories going from here

1632
01:43:36,490 --> 01:43:37,680
to here

1633
01:43:37,700 --> 01:43:40,350
you've got some more money left you can start melting this

1634
01:43:40,410 --> 01:43:43,450
if you run out of stuff there and that's what you will have

1635
01:43:43,450 --> 01:43:46,520
some amount of water and some ice

1636
01:43:46,540 --> 01:43:49,040
you don't even more calories at your disposal

1637
01:43:49,040 --> 01:43:51,330
you can melt the all and start eating it

1638
01:43:51,370 --> 01:43:54,020
you may come this way and you may be running out of calories if not

1639
01:43:54,020 --> 01:43:56,180
keep going here and there and then

1640
01:43:56,200 --> 01:43:59,270
you may end up being provided of calories

1641
01:43:59,310 --> 01:44:02,870
or one can ask question how many calories does it take

1642
01:44:02,890 --> 01:44:06,290
to convert ice minus thirty to say what a hundred

1643
01:44:06,290 --> 01:44:07,270
well that he

1644
01:44:07,310 --> 01:44:09,600
he left see delta t for that

1645
01:44:09,640 --> 01:44:11,700
in times the latent heat for this

1646
01:44:11,720 --> 01:44:19,390
mc delta the for that and claims latent heat of vaporization from

1647
01:44:19,410 --> 01:44:22,470
so the kind of problems you can get a fairly simple

1648
01:44:22,490 --> 01:44:24,910
what's the time

1649
01:44:24,990 --> 01:44:29,020
only kind of problem where you can really get in trouble is the following

1650
01:44:29,020 --> 01:44:30,510
good morning everybody

1651
01:44:32,220 --> 01:44:34,640
welcome to the tutorial

1652
01:44:34,650 --> 01:44:36,620
about reasoning for

1653
01:44:36,630 --> 01:44:41,240
ontology engineering and usage this tutorial

1654
01:44:41,240 --> 01:44:43,440
consists of four parts

1655
01:44:43,460 --> 01:44:52,030
the first part the introduction and related information about standard reasoning techniques and query answering

1656
01:44:52,030 --> 01:44:56,170
techniques will be presented by me after the break there will be

1657
01:44:56,600 --> 01:44:58,140
an introduction to

1658
01:44:58,140 --> 01:45:05,380
new ontology design technique we call this the bottom-up approach for the for ontology design

1659
01:45:05,800 --> 01:45:11,360
this part will be presented by any admin to learn from dresden university

1660
01:45:11,550 --> 01:45:17,800
modularisation issues and explanation issues will be handled in the third part

1661
01:45:18,110 --> 01:45:24,630
which is presented by matthew horridge from manchester university and the last topic will be

1662
01:45:24,650 --> 01:45:31,880
data integration through ontologies and this tutorial and them demo will be given by few

1663
01:45:31,900 --> 01:45:36,500
companies from both tunnel giuseppe verdi giacomo from

1664
01:45:36,590 --> 01:45:39,610
wrong university last cancer and

1665
01:45:39,620 --> 01:45:42,750
a demo will be given by mariano rodriguez from

1666
01:45:43,810 --> 01:45:47,330
so my name is roughness from hamburg univ

1667
01:45:47,340 --> 01:45:48,840
of technology

1668
01:45:48,940 --> 01:45:51,700
and i will introduce the

1669
01:45:51,720 --> 01:45:58,720
standard ideas behind ontology based modeling and we will try to develop

1670
01:45:58,720 --> 01:46:05,900
and methodological way for developing ontologies this is by what we call an topology engineering

1671
01:46:06,580 --> 01:46:13,870
and i will show several examples in which ontologies are actually used

1672
01:46:14,060 --> 01:46:18,610
i mean if you have any questions don't hesitate to ask

1673
01:46:18,620 --> 01:46:23,400
it a very technical question then we might put this offline but it could be

1674
01:46:23,420 --> 01:46:27,250
an interactive tutorial so if you have a question just race

1675
01:46:27,260 --> 01:46:28,810
raise your hand

1676
01:46:30,030 --> 01:46:38,530
speaking about terminological knowledge means representing an application domain in terms of classes

1677
01:46:38,540 --> 01:46:41,130
properties and

1678
01:46:41,180 --> 01:46:46,310
objects instances of classes and as you might know there is

1679
01:46:46,350 --> 01:46:51,060
multiple ways to name things so talking about classes

1680
01:46:52,440 --> 01:46:59,740
fields of is complemented with other notions so in more mathematical

1681
01:47:01,160 --> 01:47:08,540
mathematically oriented fields one talks about concepts or concept descriptions properties are well known and

1682
01:47:08,540 --> 01:47:14,560
also called relations or role descriptions as you want you can these

1683
01:47:14,570 --> 01:47:21,270
you can use these names interchangeably objects also known as instances or individuals play a

1684
01:47:21,270 --> 01:47:24,870
major role in applications and

1685
01:47:24,900 --> 01:47:26,940
with objects we capture

1686
01:47:27,000 --> 01:47:29,630
information on knowledge about

1687
01:47:29,660 --> 01:47:31,990
individual objects of our world

1688
01:47:32,130 --> 01:47:35,740
the first step in our view

1689
01:47:35,780 --> 01:47:43,410
for ontology engineering is to select names or to define a signature for the

1690
01:47:43,460 --> 01:47:49,720
knowledge base for the ontology to be developed so the first step consists of selecting

1691
01:47:49,720 --> 01:47:54,250
atomic concept descriptions in our tutorial and

1692
01:47:54,320 --> 01:47:59,840
demonstration we will use the university ontology because we assume that most of you will

1693
01:47:59,840 --> 01:48:06,340
be familiar with the notions used there so we have concept names such as student

1694
01:48:06,340 --> 01:48:12,870
professor chair department and so on and so forth these have to be selected as

1695
01:48:12,900 --> 01:48:17,840
modelling primitives if you one and the same also for the atomic

1696
01:48:17,850 --> 01:48:22,320
role description so we will be talking about head off

1697
01:48:22,340 --> 01:48:27,470
professor maybe had offered department and so on students take courses

1698
01:48:27,470 --> 01:48:35,090
and professors are members of department and so on also we will use individuals and

1699
01:48:35,120 --> 01:48:41,070
it is a common tradition to use numbers for denoting individuals here as you will

1700
01:48:41,070 --> 01:48:43,910
see later it's not really

1701
01:48:43,940 --> 01:48:45,980
the issue about selecting

1702
01:48:46,010 --> 01:48:51,420
ten or twenty individuals we will be talking about ten thousands of individuals so

1703
01:48:51,950 --> 01:48:56,840
probably one doesn't really select every name by hand so the names are generated automatically

1704
01:48:56,840 --> 01:49:02,330
but the basic view is that one defines the signature first and then we use

1705
01:49:02,340 --> 01:49:10,260
so called axioms to impose constraints or restrictions on the possible interpretation of these names

1706
01:49:10,260 --> 01:49:15,420
so the next example would be that a chair must be a person or professor

1707
01:49:15,420 --> 01:49:17,900
depending on what you want to model

1708
01:49:17,910 --> 01:49:23,380
persons are no departments those two things are disjoint

1709
01:49:24,050 --> 01:49:27,510
next we build up the model by

1710
01:49:27,550 --> 01:49:31,530
defining these axioms and

1711
01:49:31,530 --> 01:49:32,720
i will

1712
01:49:32,730 --> 01:49:33,730
continue the

1713
01:49:33,740 --> 01:49:40,090
tutorial by introducing different types of axioms different languages such that at the end you

1714
01:49:40,090 --> 01:49:42,230
will be familiar with this kind of modelling

1715
01:49:42,910 --> 01:49:49,840
maybe you've already made some experiences using these modelling languages so

1716
01:49:49,900 --> 01:49:51,320
if you already have

1717
01:49:51,490 --> 01:49:56,730
some knowledge about this what i present might be complementary

1718
01:49:56,760 --> 01:50:00,140
so basically

1719
01:50:00,150 --> 01:50:02,010
the hope was that

1720
01:50:02,050 --> 01:50:09,300
this picture doesn't work critical of

1721
01:50:14,020 --> 01:50:15,410
so basically

1722
01:50:15,420 --> 01:50:20,510
ontologies consist of a class level and an instance level

1723
01:50:20,530 --> 01:50:26,030
for historical reasons the axioms put the view is that the axioms are put into

1724
01:50:26,030 --> 01:50:27,920
a box so we call the

1725
01:50:27,930 --> 01:50:34,080
class level t box and you can easily imagine that one can define classes here

1726
01:50:35,520 --> 01:50:40,400
he said the classes into relation to each other

1727
01:50:40,410 --> 01:50:46,900
the instance is also very important so we model the relations between instances and the

1728
01:50:46,900 --> 01:50:50,950
relations are usually directed or we might

1729
01:50:50,990 --> 01:50:56,890
use both directions and so on we have to explicitly model this and this

1730
01:50:56,900 --> 01:50:58,580
knowledge about individuals

1731
01:50:58,590 --> 01:51:04,160
these surgeons about individuals are put into a so called a box a search box

1732
01:51:04,420 --> 01:51:04,980
this then

1733
01:51:04,980 --> 01:51:13,480
for two

1734
01:51:13,580 --> 01:51:18,180
the same

1735
01:51:18,200 --> 01:51:25,770
try trying to get the ball

1736
01:51:32,670 --> 01:51:34,110
so people

1737
01:51:34,160 --> 01:51:38,190
why not

1738
01:51:38,230 --> 01:51:48,830
we also wish to you good at something not

1739
01:51:51,800 --> 01:51:57,190
but i

1740
01:51:57,210 --> 01:52:00,250
you know we know

1741
01:52:02,130 --> 01:52:03,590
you need to talk

1742
01:52:03,600 --> 01:52:05,270
i mean

1743
01:52:05,290 --> 01:52:12,020
are you know they will

1744
01:52:12,050 --> 01:52:17,320
so for the one i want to try it

1745
01:52:23,840 --> 01:52:25,590
well that make

1746
01:52:25,680 --> 01:52:28,140
don't use

1747
01:52:29,290 --> 01:52:32,970
you might

1748
01:52:32,990 --> 01:52:36,210
so should and hopefully

1749
01:52:39,580 --> 01:52:43,120
and i think that

1750
01:52:43,210 --> 01:52:47,390
francis bach

1751
01:52:53,850 --> 01:53:00,330
so this is the use of the

1752
01:53:04,480 --> 01:53:07,200
this is

1753
01:53:09,930 --> 01:53:13,040
the addition as he

1754
01:53:15,720 --> 01:53:17,850
on features you

1755
01:53:23,960 --> 01:53:27,340
so this was going to happen

1756
01:53:29,440 --> 01:53:35,190
so the in the past and

1757
01:53:42,120 --> 01:53:44,330
the laws of the

1758
01:53:44,340 --> 01:53:46,290
these were

1759
01:53:48,250 --> 01:53:52,330
actually that's a

1760
01:53:52,340 --> 01:53:56,870
last much less work

1761
01:54:09,140 --> 01:54:11,800
we were able to solve this problem

1762
01:54:11,850 --> 01:54:13,840
at the bottom

1763
01:54:14,350 --> 01:54:15,680
so what

1764
01:54:16,800 --> 01:54:19,600
the whole

1765
01:54:22,340 --> 01:54:27,460
and should all

1766
01:54:27,630 --> 01:54:31,200
i think the problems

1767
01:54:31,220 --> 01:54:32,840
he tried

1768
01:54:37,870 --> 01:54:41,150
also the problem of moral hazard

1769
01:54:44,130 --> 01:54:46,320
is no a solution

1770
01:54:47,560 --> 01:54:50,830
o point

1771
01:54:50,850 --> 01:54:53,740
and also is

1772
01:55:05,340 --> 01:55:07,520
the which

1773
01:55:17,090 --> 01:55:19,900
i mean you

1774
01:55:28,690 --> 01:55:30,280
and then one

1775
01:55:37,090 --> 01:55:42,170
and although the russians actually seems like

1776
01:55:48,320 --> 01:55:59,630
so i can't see some kind of

1777
01:56:07,080 --> 01:56:12,290
observations it's possible to actually see section one

1778
01:56:12,470 --> 01:56:17,790
there's a reason why they want to

1779
01:56:17,810 --> 01:56:20,580
i just want to see the russian

1780
01:56:21,660 --> 01:56:29,340
so the first approach to the

1781
01:56:35,340 --> 01:56:37,790
in new space by projecting

1782
01:56:37,810 --> 01:56:39,990
into a high dimensional

1783
01:56:40,010 --> 01:56:42,950
to the feature space

1784
01:56:44,290 --> 01:56:48,860
and is this much higher dimension is

1785
01:56:48,880 --> 01:56:50,600
for example

1786
01:56:51,700 --> 01:56:53,040
in two dimensions

1787
01:56:53,730 --> 01:56:55,760
projected into this

1788
01:56:55,780 --> 01:56:56,720
o dimensional

1789
01:56:56,740 --> 01:56:59,500
which is actually

1790
01:56:59,580 --> 01:57:03,000
thank you for

1791
01:57:04,290 --> 01:57:08,410
then we can actually write a

1792
01:57:08,430 --> 01:57:12,600
live in the place for a time

1793
01:57:13,630 --> 01:57:16,610
we can't rely on

1794
01:57:16,620 --> 01:57:18,970
and i agree with that you

1795
01:57:18,980 --> 01:57:22,540
this is know

1796
01:57:22,580 --> 01:57:25,520
but by the she

1797
01:57:25,530 --> 01:57:30,910
she is a

1798
01:57:30,930 --> 01:57:35,030
the nice demonstration of

1799
01:57:39,110 --> 01:57:42,590
three locations

1800
01:57:51,330 --> 01:57:55,980
so you see one

1801
01:57:57,010 --> 01:57:59,180
one hundred times

1802
01:58:06,560 --> 01:58:09,380
and there is

1803
01:58:10,520 --> 01:58:13,480
we can change for the

1804
01:58:15,240 --> 01:58:19,170
i also right

1805
01:58:19,290 --> 01:58:23,730
in nineteen ninety

1806
01:58:23,740 --> 01:58:26,360
and you

1807
01:58:29,780 --> 01:58:37,160
that is a linear function of three dimensional space

1808
01:58:37,210 --> 01:58:38,700
the graph

1809
01:58:38,720 --> 01:58:40,120
the image

1810
01:58:40,800 --> 01:58:42,670
he was

1811
01:58:42,690 --> 01:58:44,700
the plane

1812
01:58:48,830 --> 01:58:50,650
and ends we with

1813
01:58:50,660 --> 01:58:56,160
the when i get back the original space using that

1814
01:58:56,180 --> 01:58:59,130
the linear separation

1815
01:58:59,150 --> 01:59:01,600
in fact

1816
01:59:01,610 --> 01:59:08,440
the fact that she i don't

1817
01:59:18,010 --> 01:59:26,660
OK so

1818
01:59:26,670 --> 01:59:28,720
now we can use

1819
01:59:28,730 --> 01:59:30,300
the same

1820
01:59:30,360 --> 01:59:31,500
just show

1821
01:59:31,520 --> 01:59:36,610
actually there is a direct relationship between the dimensions of space

1822
01:59:36,620 --> 01:59:39,880
feature space and as is basically

1823
01:59:39,900 --> 01:59:42,130
dimensional space

1824
01:59:42,150 --> 01:59:43,620
you live brain

1825
01:59:43,640 --> 01:59:47,670
as you mentioned in the song

1826
01:59:47,690 --> 01:59:50,090
so even more

1827
01:59:51,630 --> 01:59:54,130
and so on

1828
01:59:57,980 --> 02:00:02,750
i would like to see

1829
02:00:05,640 --> 02:00:08,130
the years


1
00:00:00,000 --> 00:00:00,960
so the deed

2
00:00:02,620 --> 00:00:06,090
is one point five metres

3
00:00:06,180 --> 00:00:10,340
and the frequency three thousand

4
00:00:10,350 --> 00:00:17,250
so we do this experiment of

5
00:00:17,270 --> 00:00:19,030
so let them

6
00:00:19,160 --> 00:00:24,780
it is about eleven point three centimetres if you take forty the second one

7
00:00:28,180 --> 00:00:31,860
so we have way monochromatic light monochromatic

8
00:00:31,860 --> 00:00:32,890
more or less

9
00:00:32,900 --> 00:00:38,300
one wavelength and so you can calculate lambda divided by d is

10
00:00:38,520 --> 00:00:43,160
o point o seven five

11
00:00:43,250 --> 00:00:46,680
so you can calculate where now those surfaces are

12
00:00:46,690 --> 00:00:49,660
they i really surfaces

13
00:00:49,670 --> 00:00:53,650
they're coming out from the center you and they inventing the new directions where all

14
00:00:53,650 --> 00:00:57,230
those hyperbolic services are there is no sound

15
00:00:57,250 --> 00:01:00,670
and then you can calculate all those hyperbolic surfaces are

16
00:01:02,950 --> 00:01:08,110
first calculate how many probable surfaces they are

17
00:01:08,150 --> 00:01:10,960
so in order to do that we simply have to

18
00:01:11,020 --> 00:01:12,630
stake in our crazy

19
00:01:12,640 --> 00:01:16,550
the sign theta equals and one that we just put in data is the maximum

20
00:01:16,550 --> 00:01:17,750
value possible

21
00:01:17,770 --> 00:01:18,600
and that is

22
00:01:18,600 --> 00:01:20,190
ninety degrees

23
00:01:20,280 --> 00:01:24,380
so you put theta max

24
00:01:24,420 --> 00:01:26,510
and that is ninety degrees

25
00:01:26,900 --> 00:01:28,930
over two

26
00:01:28,990 --> 00:01:32,750
so when you do that you'll find that and max

27
00:01:32,770 --> 00:01:34,880
that the highest number of n

28
00:01:34,920 --> 00:01:38,300
in that series zero one two three four five

29
00:01:38,340 --> 00:01:39,440
and max

30
00:01:39,460 --> 00:01:42,560
it is then divided by lambda

31
00:01:42,600 --> 00:01:44,300
in our case

32
00:01:44,410 --> 00:01:47,120
is about thirty

33
00:01:47,130 --> 00:01:50,920
it is one of these not

34
00:01:50,930 --> 00:01:55,080
but it means there are thirty of those services going in this direction

35
00:01:55,080 --> 00:01:59,330
but also thirteen going in this direction and we have lots mine so you really

36
00:01:59,330 --> 00:02:01,100
have to multiply this by two

37
00:02:01,110 --> 00:02:04,240
and so to twenty six services no more

38
00:02:04,300 --> 00:02:05,870
and probably no less

39
00:02:05,880 --> 00:02:07,430
in this audience of

40
00:02:07,450 --> 00:02:11,910
contructive interference and then they probably also around twenty six

41
00:02:11,920 --> 00:02:14,430
that's struck interference

42
00:02:14,530 --> 00:02:16,110
now i want to be

43
00:02:16,150 --> 00:02:19,060
as qualitative as i can

44
00:02:19,070 --> 00:02:20,430
and i would like to know

45
00:02:20,450 --> 00:02:22,200
students who are sitting

46
00:02:22,260 --> 00:02:24,500
about five metres away

47
00:02:24,590 --> 00:02:29,640
what the distances between one maximum zero to maximum right at the center and the

48
00:02:30,980 --> 00:02:33,920
to get an idea of where to search for those

49
00:02:34,710 --> 00:02:36,510
for those minima

50
00:02:36,520 --> 00:02:38,730
so i'll go now four

51
00:02:38,850 --> 00:02:40,340
the maximum

52
00:02:40,350 --> 00:02:43,340
so i know that they zero

53
00:02:43,350 --> 00:02:44,410
right here

54
00:02:44,430 --> 00:02:48,840
all of you use it you must maximum display

55
00:02:48,840 --> 00:02:52,070
the question is what the next

56
00:02:53,180 --> 00:02:57,630
the next maxima depends of course on the distance how far you're sending away from

57
00:02:57,630 --> 00:03:06,090
so i think this is what i'm about five meters away

58
00:03:06,110 --> 00:03:08,320
the site of you what

59
00:03:08,360 --> 00:03:14,130
this one makes reference to any one of the first surface away from the

60
00:03:15,630 --> 00:03:19,930
design of data one is then o point o seven five

61
00:03:21,780 --> 00:03:23,280
that translates

62
00:03:23,300 --> 00:03:26,970
in two value of data

63
00:03:27,030 --> 00:03:31,030
i think it's about four point three

64
00:03:32,970 --> 00:03:34,660
so now you can calculate

65
00:03:34,680 --> 00:03:36,900
what the separation is

66
00:03:36,950 --> 00:03:41,760
between one maximum and the next maximum that separation x one

67
00:03:41,820 --> 00:03:43,610
i call it x y

68
00:03:43,700 --> 00:03:45,650
is roughly l

69
00:03:45,650 --> 00:03:49,110
by that point o seventy five

70
00:03:49,130 --> 00:03:50,490
that is about

71
00:03:50,510 --> 00:03:53,680
thirty eight percent

72
00:03:53,700 --> 00:03:56,320
so right there those guys and i'm looking at now

73
00:03:56,320 --> 00:04:00,360
you will have the maximum sound you when you will find it's image you'll have

74
00:04:00,360 --> 00:04:02,970
another maximum and the minimum in between

75
00:04:02,990 --> 00:04:05,610
so the minima and maximum right there

76
00:04:05,660 --> 00:04:10,550
religiosity is about nineteen seventy four you lay in the back it large

77
00:04:10,650 --> 00:04:13,510
and for you here in front it is small

78
00:04:13,510 --> 00:04:18,490
because remember those services like this and so separation is small i just give you

79
00:04:18,490 --> 00:04:23,430
this as an example that you know roughly in order of magnitude of what you

80
00:04:24,220 --> 00:04:27,400
looking for

81
00:04:27,450 --> 00:04:29,780
i'm going to turn on the sound

82
00:04:29,800 --> 00:04:31,030
and then i want you to

83
00:04:31,070 --> 00:04:32,650
we go back and forth

84
00:04:32,700 --> 00:04:34,780
you did when you were nursery school

85
00:04:34,840 --> 00:04:36,070
and i want you to

86
00:04:36,070 --> 00:04:39,320
find the locations of maxima and minima

87
00:04:39,380 --> 00:04:42,490
and i can assure you that the ones with minimum

88
00:04:42,490 --> 00:04:45,150
the ones with some science it's you a

89
00:04:45,180 --> 00:04:48,990
well defined because of course we have done this several times ourselves don't move too

90
00:04:48,990 --> 00:04:51,380
fast move very slowly

91
00:04:51,400 --> 00:04:52,800
there will be points

92
00:04:52,860 --> 00:04:54,280
where you here

93
00:04:54,300 --> 00:05:07,070
no sound there will be when you look for

94
00:05:09,380 --> 00:05:17,700
also you will find

95
00:05:17,780 --> 00:05:19,550
i was able to clearly

96
00:05:19,550 --> 00:05:22,990
this thing with the maximum from the minimum

97
00:05:22,990 --> 00:05:25,010
not too many

98
00:05:25,050 --> 00:05:30,930
the reason is that all you allows scientists

99
00:05:30,990 --> 00:05:32,510
if the difference

100
00:05:32,660 --> 00:05:36,610
is based maximize is nineteen seventy

101
00:05:36,680 --> 00:05:38,280
there is this much

102
00:05:38,300 --> 00:05:41,400
what is the separation between you two years

103
00:05:41,420 --> 00:05:43,010
about twenty centimetres

104
00:05:43,070 --> 00:05:45,900
well actually the actual

105
00:05:45,970 --> 00:05:49,150
so if you have the maximum you would have a minimum there so what have

106
00:05:49,150 --> 00:05:50,510
we have to do

107
00:05:50,510 --> 00:05:51,930
you have to close

108
00:05:51,970 --> 00:05:55,720
then you will be real scientists so i'm going to turn it back on again

109
00:05:55,760 --> 00:05:57,450
i wanted to close one year

110
00:05:57,470 --> 00:05:59,050
and then you will be able

111
00:05:59,050 --> 00:06:02,220
to find those minima in those

112
00:06:02,320 --> 00:06:09,630
again back and forth maybe some reflections from the wall

113
00:06:09,630 --> 00:06:12,200
may interfere with this experiment no

114
00:06:12,220 --> 00:06:20,050
one was an

115
00:06:20,800 --> 00:06:36,090
well that was all the more the other is not

116
00:06:36,380 --> 00:06:40,180
the model

117
00:06:40,180 --> 00:06:42,050
so are now

118
00:06:42,210 --> 00:06:43,740
there you go

119
00:06:43,800 --> 00:06:46,660
all right this is the great moment for the years

120
00:06:46,720 --> 00:06:47,920
many break

121
00:06:47,930 --> 00:06:49,740
many chris

122
00:06:49,800 --> 00:06:57,180
so if someone could help me

123
00:06:57,280 --> 00:06:58,970
o u

124
00:07:00,320 --> 00:07:03,340
regarding them to use the histogram

125
00:07:03,360 --> 00:07:04,680
of example two

126
00:07:04,720 --> 00:07:06,180
what is interesting

127
00:07:06,340 --> 00:07:08,450
anyway helpful to me

128
00:07:08,470 --> 00:07:11,780
it's almost by bimodal

129
00:07:11,800 --> 00:07:14,720
now we have forty seven percent to go in the court

130
00:07:14,760 --> 00:07:18,360
of which forty percent is for the final

131
00:07:18,420 --> 00:07:25,470
so clearly i can't say much about dividing line ABCD is in and

132
00:07:25,530 --> 00:07:29,720
i want to make only global state

133
00:07:29,760 --> 00:07:33,650
and only one those of you who i put in the danger zone

134
00:07:33,660 --> 00:07:35,840
danger zone for me

135
00:07:35,880 --> 00:07:40,550
students whose cumulative assuming that they've taken all the examples

136
00:07:40,550 --> 00:07:43,240
red and black

137
00:07:43,260 --> 00:07:46,420
nature is the red black tree

138
00:07:46,470 --> 00:07:53,990
not every tree can be labelled as the red black tree right

139
00:07:54,010 --> 00:07:55,640
it it is good practice because

140
00:07:55,650 --> 00:07:59,540
sort of thing shows up increases

141
00:07:59,640 --> 00:08:02,300
make a thread

142
00:08:03,650 --> 00:08:06,420
and then everything else black

143
00:08:06,430 --> 00:08:09,910
that's that's certainly solution

144
00:08:10,580 --> 00:08:14,290
because then that basically brings the level of the sky up here

145
00:08:14,310 --> 00:08:18,400
actually i had a more complicated one because it seemed like more fun

146
00:08:19,500 --> 00:08:22,820
so what i did was i mean this guy black

147
00:08:22,870 --> 00:08:25,850
OK and these two guys read

148
00:08:30,510 --> 00:08:33,730
black and

149
00:08:34,490 --> 00:08:39,040
your solutions perfectly good as well

150
00:08:39,870 --> 00:08:43,620
so we don't have any to read zero on any path

151
00:08:43,670 --> 00:08:45,300
and all

152
00:08:46,030 --> 00:08:51,160
the black height from any particular point going down we get the same number of

153
00:08:52,420 --> 00:08:53,520
whichever way we go

154
00:08:55,510 --> 00:08:58,060
so good

155
00:08:58,110 --> 00:09:02,600
so the idea here now is that we're going to keep the subtree sizes

156
00:09:02,620 --> 00:09:04,720
these are the keys there are stored in our

157
00:09:04,730 --> 00:09:09,950
in our dynamics that we keep the subtree sizes in the red black tree

158
00:09:09,960 --> 00:09:13,150
so for example this guy has size one

159
00:09:13,210 --> 00:09:15,820
these guys have size one because the leaves

160
00:09:15,830 --> 00:09:17,480
and we just work

161
00:09:17,530 --> 00:09:20,250
OK so this is size three

162
00:09:20,270 --> 00:09:23,260
this guy is size five

163
00:09:23,280 --> 00:09:25,950
this guy has size three

164
00:09:26,000 --> 00:09:30,700
this guy has five plus three plus one is nine

165
00:09:31,310 --> 00:09:33,220
so in general have

166
00:09:33,430 --> 00:09:40,850
size of x

167
00:09:40,900 --> 00:09:42,230
is equal to

168
00:09:45,640 --> 00:09:49,650
left index

169
00:09:49,660 --> 00:09:52,820
class sizes

170
00:09:57,160 --> 00:10:01,810
plus one

171
00:10:01,860 --> 00:10:05,320
that's how i computed recursively

172
00:10:05,530 --> 00:10:07,480
so very simple

173
00:10:07,510 --> 00:10:09,700
formula for the sizes

174
00:10:09,750 --> 00:10:13,020
it turns out that for the code that we're going to want to write to

175
00:10:14,120 --> 00:10:16,270
these operations

176
00:10:16,280 --> 00:10:18,520
we're going to

177
00:10:18,890 --> 00:10:24,640
it's going to be convenient to be talking about the size of no

178
00:10:24,650 --> 00:10:26,650
so what's the size of no

179
00:10:30,490 --> 00:10:33,290
OK size of no

180
00:10:33,300 --> 00:10:34,850
there's no elements there

181
00:10:34,860 --> 00:10:36,100
however if i

182
00:10:36,120 --> 00:10:38,920
in most programming i i take size now

183
00:10:38,930 --> 00:10:41,800
well happen

184
00:10:44,610 --> 00:10:48,300
that's kind convenient so what i have to do in my code is everywhere that

185
00:10:48,300 --> 00:10:50,280
size of nil

186
00:10:50,330 --> 00:10:52,900
that i might want to take sides if now like to say

187
00:10:52,910 --> 00:10:56,980
or take the size of anything i to say well if it's now

188
00:10:57,040 --> 00:10:59,220
then return

189
00:10:59,280 --> 00:11:01,410
zero otherwise

190
00:11:01,430 --> 00:11:03,810
return to the size field et cetera

191
00:11:04,660 --> 00:11:07,840
there's an implementation tricks that were used

192
00:11:07,990 --> 00:11:12,250
to simplify that scored using a sentinel

193
00:11:17,660 --> 00:11:20,910
seven knows nothing more than a dummy record

194
00:11:22,870 --> 00:11:27,780
so instead of using an ill will actually use and nielsen

195
00:11:27,790 --> 00:11:30,270
we use the dummy record

196
00:11:30,290 --> 00:11:31,880
four nil

197
00:11:31,980 --> 00:11:35,270
such that size

198
00:11:37,150 --> 00:11:39,380
is equal to zero

199
00:11:39,430 --> 00:11:42,440
instead of any place i would have use no in the tree

200
00:11:42,450 --> 00:11:45,250
instead all have special records

201
00:11:45,260 --> 00:11:47,730
but i call now

202
00:11:47,780 --> 00:11:51,540
but it would be a whole record and that way i can set its sights

203
00:11:51,540 --> 00:11:53,450
field to be zero

204
00:11:53,460 --> 00:11:56,660
and then i don't have to check that is a special case

205
00:11:56,740 --> 00:12:02,710
and that's a very common type of programming trick to use two sentinels to simplify

206
00:12:02,720 --> 00:12:05,630
to simplify code so you have all these

207
00:12:05,640 --> 00:12:08,580
boundary cases are don't have to right next to function

208
00:12:10,110 --> 00:12:13,790
when all i want to do is just index the size of some everybody with

209
00:12:13,790 --> 00:12:15,510
me on that

210
00:12:15,520 --> 00:12:20,050
OK so let's write the code for OS select

211
00:12:20,100 --> 00:12:21,470
given this

212
00:12:26,550 --> 00:12:35,230
and this is going to basically give us the

213
00:12:35,280 --> 00:12:37,830
i smallest

214
00:12:37,880 --> 00:12:42,450
in the subtree

215
00:12:51,250 --> 00:12:53,180
so it's actually going to be

216
00:12:53,190 --> 00:12:54,940
a little more general

217
00:12:54,990 --> 00:12:58,520
so if i want to find implement the OS select i have up there i

218
00:12:58,520 --> 00:13:00,210
basically given the route

219
00:13:00,260 --> 00:13:01,320
and i

220
00:13:02,380 --> 00:13:05,980
but we're going to build this recursively so it can be helpful to

221
00:13:07,760 --> 00:13:09,020
r two

222
00:13:10,760 --> 00:13:14,780
i have the node in which we're trying to find the subtree

223
00:13:14,780 --> 00:13:22,250
then the approaches in the literature can be classified look and mobile according to whom

224
00:13:22,860 --> 00:13:28,500
if they look a solution for one pixel without looking there is that the solution

225
00:13:28,550 --> 00:13:29,920
on the rest of the image

226
00:13:30,310 --> 00:13:37,020
or global approach of course the global approach are not good in our framework because

227
00:13:37,030 --> 00:13:43,620
there is very time consuming even if they are better in case of uniform

228
00:13:43,630 --> 00:13:48,990
but that's incident is the problem of local approaches

229
00:13:49,010 --> 00:13:51,480
in the summer of

230
00:13:51,850 --> 00:13:54,620
out of the selected algorithms

231
00:13:54,630 --> 00:14:01,030
as is said the p a g g c and d f that is that

232
00:14:01,350 --> 00:14:06,900
all these algorithms need stronger constraints on the e

233
00:14:06,970 --> 00:14:15,180
two major sometimes they are not good for real applications because they have not alone

234
00:14:15,220 --> 00:14:16,530
sufficient time

235
00:14:16,540 --> 00:14:22,000
as is city the is called for these a goal but is not to go

236
00:14:22,000 --> 00:14:30,350
going the uniform uniform part and in case of local perturbations between the left and

237
00:14:30,380 --> 00:14:33,420
right to

238
00:14:34,610 --> 00:14:36,100
for example

239
00:14:36,120 --> 00:14:38,030
if we have

240
00:14:38,080 --> 00:14:40,960
if we have

241
00:14:40,970 --> 00:14:49,710
a uniform but it's not very easy for to matching find the correspondence on a

242
00:14:49,710 --> 00:14:57,020
few of the pixel inside the effect the dynamic programming give this kind of results

243
00:14:57,020 --> 00:15:01,550
that is not good because the object is in front of the world

244
00:15:01,560 --> 00:15:03,380
and it's the

245
00:15:03,540 --> 00:15:08,720
it's not good this representation in another problem

246
00:15:09,370 --> 00:15:18,590
can be in real applications for robots can produce produces mechanical vibration and the algorithm

247
00:15:18,590 --> 00:15:20,400
for example in this case is the

248
00:15:20,420 --> 00:15:26,180
SS city algorit can have problem in the results

249
00:15:26,200 --> 00:15:29,980
time consuming and that's the end we can have

250
00:15:29,990 --> 00:15:38,230
some problem if the two images this therapy is acquired with different conditions like life

251
00:15:38,310 --> 00:15:41,050
focus on the third edition was

252
00:15:41,100 --> 00:15:43,500
for these reasons

253
00:15:43,560 --> 00:15:48,480
our approach wants to all represents the history major as

254
00:15:48,490 --> 00:15:56,010
a as a graph and we provide a graph matching between

255
00:15:56,060 --> 00:16:04,180
regions and not some not yet between points in the stereo image in this case

256
00:16:04,220 --> 00:16:07,880
we we we want to do

257
00:16:07,920 --> 00:16:15,960
use this integral approaches and in order to resolve some problems in uniform idea

258
00:16:17,150 --> 00:16:23,400
in case of lot colour or global perturbation between their steps

259
00:16:23,420 --> 00:16:27,270
so we start from the projection of the region and not

260
00:16:27,320 --> 00:16:33,360
on and on the projection of the points in the scene and we we define

261
00:16:33,360 --> 00:16:37,260
an approximation of this but the properties that these days

262
00:16:37,270 --> 00:16:43,360
this early or is the displacement of a wall regions and not yet of point

263
00:16:43,480 --> 00:16:50,580
fact the disparity map is defined as the autism the displacement of each point of

264
00:16:50,580 --> 00:16:57,980
each corresponding the corresponding point in the left and right image in our definition despite

265
00:16:58,150 --> 00:17:04,280
is defined on marriage and not yet on a point

266
00:17:07,080 --> 00:17:08,260
i want to

267
00:17:08,270 --> 00:17:11,680
represents the stale be as

268
00:17:12,570 --> 00:17:18,560
so we have left graph and the right to have and we provide a stable

269
00:17:20,140 --> 00:17:24,110
the graph matching between these image

270
00:17:24,130 --> 00:17:28,220
yeah it

271
00:17:28,230 --> 00:17:32,090
the fine segmentation process is the it is composed

272
00:17:32,090 --> 00:17:38,230
i'll show you immediately nothing to do with my talk it's not likely to play

273
00:17:38,250 --> 00:17:42,990
and probably we cannot distribute but you can find future

274
00:17:43,360 --> 00:17:51,660
so i'd really like this clip show you this

275
00:17:51,700 --> 00:17:56,570
the song coming up

276
00:17:56,640 --> 00:18:03,130
probably it

277
00:18:03,140 --> 00:18:05,810
can you

278
00:18:05,820 --> 00:18:07,040
you can hear i

279
00:18:17,990 --> 00:18:43,700
can you see it

280
00:23:34,580 --> 00:23:37,590
i just always

281
00:23:37,660 --> 00:23:42,140
the science students telling them what algorithms that you know he's a machine how do

282
00:23:42,140 --> 00:23:44,470
you react two numbers

283
00:23:44,480 --> 00:23:50,360
use that because it is

284
00:23:51,160 --> 00:23:58,660
so you're experts

285
00:23:58,780 --> 00:24:28,960
is what you know a lot of work is taking place

286
00:24:30,530 --> 00:24:32,610
theoretical point statistics

287
00:24:32,630 --> 00:24:41,110
i of course machine learning the dealing with lots of data sets coming from domains

288
00:24:41,130 --> 00:24:45,590
so today i'm going to look at a particular aspect of data mining is called

289
00:24:46,010 --> 00:24:47,630
contrast data mining

290
00:24:47,640 --> 00:24:49,860
and that's what we're going to look at

291
00:24:49,910 --> 00:24:54,170
i have you know when you work for so many years will have lots of

292
00:24:55,350 --> 00:25:00,800
and colleagues who we work with and my main collaborator was james bailey who is

293
00:25:01,450 --> 00:25:02,710
senior lecturer

294
00:25:02,780 --> 00:25:04,470
he was one of my

295
00:25:04,590 --> 00:25:06,130
phd students

296
00:25:06,170 --> 00:25:10,140
and then i was doing he used to be called

297
00:25:10,150 --> 00:25:16,040
melbourne but now he's at wright state university in the US

298
00:25:16,050 --> 00:25:22,350
so what is the contrast contrast is to compare or appraise in respect to differences

299
00:25:22,450 --> 00:25:24,450
so this is the definition of

300
00:25:24,460 --> 00:25:26,350
it within in the dictionary

301
00:25:26,400 --> 00:25:30,530
in contrast data mining is the mining of patterns all models

302
00:25:30,540 --> 00:25:33,630
contrasting two or more classes of conditions

303
00:25:33,650 --> 00:25:38,340
so will will look at more details as we go through

304
00:25:38,600 --> 00:25:41,530
i think in the fuzzy two thousand one

305
00:25:41,580 --> 00:25:45,530
derby s is sometimes it's good to contrast

306
00:25:45,590 --> 00:25:49,900
what you like with something else it makes you appreciate it even more

307
00:25:49,950 --> 00:25:52,450
now is interesting thing is that you know we all

308
00:25:52,460 --> 00:25:56,090
you know very well that you know when you

309
00:25:56,150 --> 00:25:57,890
go to an environment

310
00:25:57,940 --> 00:26:02,090
from different environment first time you noticed lots of differences

311
00:26:02,100 --> 00:26:05,060
but very soon you get it just torso so for example

312
00:26:05,120 --> 00:26:08,510
she came from a very cold country and in one place

313
00:26:08,590 --> 00:26:12,570
the first two days with miserable and afterward it's very not

314
00:26:12,590 --> 00:26:15,340
just to give you an example you know what i my like

315
00:26:15,340 --> 00:26:17,670
colleagues who came from denmark

316
00:26:17,680 --> 00:26:19,090
the first winter

317
00:26:19,110 --> 00:26:21,840
in australia was it's like somebody in

318
00:26:21,880 --> 00:26:23,720
so he started wearing no

319
00:26:23,730 --> 00:26:26,520
now almost like t-shirts sensing lights

320
00:26:26,540 --> 00:26:28,970
was signed for the first three

321
00:26:28,980 --> 00:26:34,830
next winter he was put really radiator causing room in the same danish guy

322
00:26:35,040 --> 00:26:40,340
so we already lost his contract because the transition already took place

323
00:26:40,980 --> 00:26:44,610
the contrast is the the changes that we see that that's the one that makes

324
00:26:45,210 --> 00:26:46,290
you know the

325
00:26:46,300 --> 00:26:47,490
some kind of

326
00:26:47,680 --> 00:26:53,060
a difference that makes us to notice these things and similarly you know we you

327
00:26:53,060 --> 00:26:56,670
know if you look at entropy in know anything highly probable

328
00:26:56,680 --> 00:26:58,770
i tend to have low entropy then

329
00:26:58,790 --> 00:27:01,830
an improbable ones

330
00:27:01,840 --> 00:27:04,890
so so that's where the contrast come into play

331
00:27:04,960 --> 00:27:10,550
so what can we contrast so for example we could contrast objects at different times

332
00:27:10,550 --> 00:27:12,130
for for example it's a

333
00:27:12,140 --> 00:27:16,380
you know one of the conferences i go to these international conference on data mining

334
00:27:16,470 --> 00:27:18,970
so let's say you wanted to see

335
00:27:18,980 --> 00:27:24,090
what are the differences between the paper was later published

336
00:27:24,090 --> 00:27:28,630
during the conference you know the year two thousand six to two thousand eight

337
00:27:28,690 --> 00:27:32,500
versus those

338
00:27:32,510 --> 00:27:35,810
the speed of two thousand three to

339
00:27:35,820 --> 00:27:37,120
two thousand five

340
00:27:37,130 --> 00:27:40,330
so you may be interested in knowing for example they may be

341
00:27:40,340 --> 00:27:43,760
you know when you're looking at this conference the contrast could be in terms of

342
00:27:43,770 --> 00:27:45,770
the authorship for example

343
00:27:45,790 --> 00:27:48,840
maybe in a new place came into into this

344
00:27:48,960 --> 00:27:55,180
this area or

345
00:27:55,980 --> 00:27:59,860
it is not publishing any more you might want to know why this is happening

346
00:27:59,960 --> 00:28:04,960
could that be that ATA is no more interest or could that be something more

347
00:28:04,970 --> 00:28:09,240
so interesting thing is that in the international conference on data mining

348
00:28:09,300 --> 00:28:12,500
around i think two thousand six they introduced the

349
00:28:12,510 --> 00:28:15,210
blind referee until then

350
00:28:15,250 --> 00:28:20,090
when you submit a paper you actually put your name your applications and so forth

351
00:28:20,090 --> 00:28:25,390
from two thousand six onwards double-blind that means you don't put your affiliations i'm you

352
00:28:25,390 --> 00:28:30,420
also should not leave any traces in the paper the paper belongs to you sometimes

353
00:28:30,420 --> 00:28:33,220
it's very hard to make a hundred percent

354
00:28:33,220 --> 00:28:38,680
so i think a lot for the intro guys so i'm coats and as i mentioned i'm

355
00:28:38,780 --> 00:28:41,850
currently post-doc at stanford and also a visiting scholar at

356
00:28:42,100 --> 00:28:43,600
indiana university bloomington

357
00:28:44,650 --> 00:28:46,930
i'm going to talk about here is actually

358
00:28:47,280 --> 00:28:47,650
try to

359
00:28:47,770 --> 00:28:51,050
get good be a little different from the abstract in fact i want to change things try

360
00:28:51,060 --> 00:28:53,480
to get enough inherent amount of time we get

361
00:28:53,700 --> 00:28:58,040
one of the things i'm going to try to go through real slowly as those very basics of

362
00:28:58,380 --> 00:29:01,300
what we want machine learning to do wise deep learning important

363
00:29:01,500 --> 00:29:05,560
try to give you some of the basic tools for actually doing some deep learning yourselves

364
00:29:05,800 --> 00:29:10,890
and there's sort of a story many of you may have heard about about unsupervised learning and feature learning

365
00:29:11,130 --> 00:29:12,880
and i'll try to get to the end

366
00:29:13,080 --> 00:29:16,230
but i want to make sure to go through some of the low level stuff to

367
00:29:16,240 --> 00:29:18,880
give you an idea for how actually use these things so that

368
00:29:19,050 --> 00:29:19,910
when you go home

369
00:29:20,040 --> 00:29:22,440
and look at some of the resources that are going to have a link to the

370
00:29:22,460 --> 00:29:23,250
end of the talk

371
00:29:23,540 --> 00:29:29,430
you'll be able to go do online tutorial and actually play with some of these things even have enough

372
00:29:29,550 --> 00:29:31,600
knowledge behind you reduce real applications

373
00:29:32,310 --> 00:29:35,130
so i want to start to motivate all this stuff

374
00:29:35,370 --> 00:29:36,970
by sort of

375
00:29:37,260 --> 00:29:41,430
time about what is it that we want machine learning to do especially with computer vision

376
00:29:41,790 --> 00:29:45,580
are the basic idea is that we have these applications were some input like

377
00:29:46,170 --> 00:29:50,420
in image and we want to do something like object recognition we want to be able to

378
00:29:50,620 --> 00:29:53,330
look at this low level pattern to make predictions about

379
00:29:53,520 --> 00:29:57,190
what's what's going on so for example an object recognition we want to predict

380
00:29:57,440 --> 00:29:59,380
whether there's a cat in the image are not

381
00:30:01,550 --> 00:30:02,820
for something like detection

382
00:30:03,060 --> 00:30:05,350
the output as a little different we want to be able to

383
00:30:05,470 --> 00:30:09,020
look at this image and figure out that this is the location of bicyclist

384
00:30:09,320 --> 00:30:12,720
and for more sophisticated applications for instance segmentation

385
00:30:12,950 --> 00:30:17,280
maybe went on to look at this image and figure out the outline of the birds

386
00:30:17,300 --> 00:30:18,760
outline of the objects in the scene

387
00:30:19,000 --> 00:30:20,640
it's called f

388
00:30:20,780 --> 00:30:21,860
n one of the

389
00:30:23,390 --> 00:30:25,720
one of the sort of common approaches to machine learning

390
00:30:25,930 --> 00:30:29,610
and other a whole bunch of different ways of solving these problems but a pretty large

391
00:30:29,630 --> 00:30:31,280
number of these approaches

392
00:30:31,640 --> 00:30:35,070
are sort of covered by common pipeline we take this

393
00:30:35,190 --> 00:30:37,570
input example image of a cat let's say

394
00:30:37,760 --> 00:30:38,930
and then we have

395
00:30:39,040 --> 00:30:40,920
some sort of black box system

396
00:30:41,040 --> 00:30:45,110
that extracts features tries to extract some sort of higher-level patterns

397
00:30:47,240 --> 00:30:52,830
and then we usually have some final off the shelf machine learning algorithm that we just drop all this information

398
00:30:52,850 --> 00:30:55,670
into and tries to learn to make decisions

399
00:30:55,840 --> 00:31:00,270
starting from the sort of higher level representation so we might want to machine learning algorithm tell us

400
00:31:00,510 --> 00:31:02,590
is this cat picture in this image

401
00:31:03,150 --> 00:31:07,270
and the the thing that ends up taking all of our time causes a lot of grief

402
00:31:07,500 --> 00:31:09,460
or is this feature extraction piece

403
00:31:10,070 --> 00:31:13,820
because you know we can try to get pretty sophisticated here sometimes

404
00:31:13,990 --> 00:31:15,130
you'll see this box

405
00:31:15,280 --> 00:31:18,740
taking on some pretty complex engineering we're trying to build

406
00:31:18,930 --> 00:31:20,620
several layers in fact

407
00:31:20,870 --> 00:31:23,440
of increasingly high level abstractions

408
00:31:23,850 --> 00:31:27,350
and the way that we do that as we try to take all our prior knowledge

409
00:31:27,360 --> 00:31:30,890
about the world how images work what we might see images

410
00:31:31,030 --> 00:31:33,860
and so forth and somehow wire them into this box

411
00:31:34,820 --> 00:31:38,590
and it turns out that if you do a really good job then you can get great results

412
00:31:38,730 --> 00:31:41,900
but if you're not computer vision expert you have done this before

413
00:31:42,100 --> 00:31:44,270
the you can end up with a really terrible results

414
00:31:45,180 --> 00:31:46,520
so this sort of

415
00:31:46,810 --> 00:31:52,040
starting point for talking about deep learning what deep learning is and why we hope this can work because

416
00:31:52,300 --> 00:31:55,090
we like to do is keep the same kind of pipeline

417
00:31:55,260 --> 00:31:56,770
this basic idea

418
00:31:56,980 --> 00:31:58,730
that we want to take our input image

419
00:31:58,990 --> 00:32:03,360
and then feed it through several modules where we're going to extract higher and higher

420
00:32:03,380 --> 00:32:04,320
level features

421
00:32:04,440 --> 00:32:08,230
so we might start with some low level features like detecting edges in an image

422
00:32:08,530 --> 00:32:09,810
and then we want to move to

423
00:32:09,950 --> 00:32:12,810
sort of middle level features like recognizing parts

424
00:32:13,020 --> 00:32:18,600
and so forth to maybe some higher level structures like recognizing objects and then at the very end

425
00:32:18,790 --> 00:32:21,130
only very and we're going to have some classifier

426
00:32:21,290 --> 00:32:23,810
that make some application-specific decision

427
00:32:24,050 --> 00:32:25,220
like is this cat

428
00:32:25,410 --> 00:32:27,360
where the outlines of object and so on

429
00:32:27,930 --> 00:32:30,900
and the basic idea is that whenever we build these pipelines we're

430
00:32:31,120 --> 00:32:36,060
going from sort of low-level ideas getting more and more abstract representation as we go up

431
00:32:36,320 --> 00:32:38,310
and where we normally build that by hand

432
00:32:38,670 --> 00:32:41,750
we want to somehow train these multiple layers from data

433
00:32:42,030 --> 00:32:47,380
and try to discover representation so that by the time we get to the high-level features out here

434
00:32:47,510 --> 00:32:49,530
if we just train a classifier on the and

435
00:32:49,750 --> 00:32:51,190
we can make really good decisions

436
00:32:51,390 --> 00:32:54,000
so the idea behind deep learning is to figure out a way

437
00:32:54,140 --> 00:32:58,790
to train this whole pipeline systems and i have to engineer them so much by hand

438
00:33:01,880 --> 00:33:04,560
it's worth asking why is it

439
00:33:04,770 --> 00:33:05,800
just upfront

440
00:33:06,010 --> 00:33:08,650
why do we want to even do this deep learning thing

441
00:33:08,920 --> 00:33:10,370
there's a handful of sort of

442
00:33:10,650 --> 00:33:12,230
a simple justifications

443
00:33:12,750 --> 00:33:15,250
one is that we just know sort of

444
00:33:15,490 --> 00:33:17,870
inherently from working on this for so many years that

445
00:33:18,080 --> 00:33:20,970
some decisions just require a lot of stages of processing

446
00:33:21,130 --> 00:33:26,790
it's very unlikely that i can see an image and decide whether there's catenin imager dog the image just

447
00:33:26,810 --> 00:33:30,470
with linear function somehow to simple we know that can be that simple

448
00:33:30,890 --> 00:33:34,230
and all the systems we currently have no matter how we built

449
00:33:34,420 --> 00:33:36,600
involved many different stages of processing

450
00:33:36,870 --> 00:33:40,940
so we sort of know that we want this long pipeline of decision making

451
00:33:41,090 --> 00:33:42,790
but unfortunately

452
00:33:43,320 --> 00:33:45,650
trying to engineer that by hand is quite difficult

453
00:33:46,730 --> 00:33:53,180
we already have been intuitively engineering these sorts of things in computer vision for quite a while so if

454
00:33:53,210 --> 00:33:56,630
we're already building these kinds of architectures a very natural thing to try to do is

455
00:33:56,630 --> 00:33:59,880
them and you even for playing l of last

456
00:33:59,900 --> 00:34:06,020
in the fifties conjugate gradient came around this gave a run time of

457
00:34:06,030 --> 00:34:08,020
and square

458
00:34:10,780 --> 00:34:15,280
the analysis i guess we didn't finish that but because the convergence rate

459
00:34:15,340 --> 00:34:20,300
and then lipton rozen tarjan proved that any planar graph can be done and at

460
00:34:20,320 --> 00:34:21,800
one point five

461
00:34:21,820 --> 00:34:23,440
as we've talked about

462
00:34:23,960 --> 00:34:30,320
vida then gave algorithm using preconditioned iterative methods which is and at one point two

463
00:34:30,340 --> 00:34:36,130
then using low stretch spanning trees bill mnteng show how to get this down to

464
00:34:36,130 --> 00:34:38,000
and log square and

465
00:34:39,570 --> 00:34:41,380
more recently we've shown

466
00:34:41,400 --> 00:34:45,550
that you can actually get the standard linear time so it's known that any plane

467
00:34:45,650 --> 00:34:48,480
linear system that can be solved in linear time

468
00:34:48,520 --> 00:34:52,400
so that's the punchline is that says that if you want to do a forward

469
00:34:52,400 --> 00:34:54,940
multiply an inverse power

470
00:34:54,960 --> 00:34:57,500
up to constants those are all the same so

471
00:34:57,520 --> 00:34:59,380
you should then

472
00:34:59,400 --> 00:35:03,150
and let me show you some examples actually quantify the exact cost of doing an

473
00:35:03,150 --> 00:35:07,780
inverse power forward power but this is in these cases that

474
00:35:07,800 --> 00:35:10,150
and there a cost about the same

475
00:35:11,460 --> 00:35:15,320
so but i should point out that this is a very famous result in this

476
00:35:15,320 --> 00:35:18,610
area and this is this film tag and what they were able to show

477
00:35:18,630 --> 00:35:20,210
is that

478
00:35:20,260 --> 00:35:22,520
if you take any love lost in

479
00:35:22,520 --> 00:35:26,630
you can solve this in time and place and n plus an remember and the

480
00:35:26,630 --> 00:35:30,710
number of variables and the number of non zeros in the matrix and the twiddle

481
00:35:30,710 --> 00:35:34,860
here means that we're ignoring warnings and i think it's film and pointed out

482
00:35:34,880 --> 00:35:36,570
in this talk yesterday

483
00:35:36,590 --> 00:35:39,650
and the number of locks somewhere

484
00:35:39,690 --> 00:35:41,960
bigger than twenty nine right

485
00:35:42,940 --> 00:35:47,670
so this is not exactly practically the some huge number of logs but at least

486
00:35:47,670 --> 00:35:52,050
theoretically this is very interesting because it it says that with more work

487
00:35:52,070 --> 00:35:55,780
chances are the right answer is that it and log in with some very few

488
00:35:55,780 --> 00:35:59,230
laws try and i'll show you some experiments on

489
00:35:59,260 --> 00:36:02,960
we've done with others other solvers OK

490
00:36:04,030 --> 00:36:06,860
so let's let's go back and actually look at

491
00:36:06,860 --> 00:36:08,480
this solver

492
00:36:08,500 --> 00:36:12,030
good is actually developed to solve at CMU

493
00:36:12,050 --> 00:36:16,300
using what we call coming from multigrid and

494
00:36:16,300 --> 00:36:21,380
we compare this to the matlab solver and what's interesting here is that the math

495
00:36:21,520 --> 00:36:23,420
and this is for two d

496
00:36:24,630 --> 00:36:26,230
which will talk about more

497
00:36:26,250 --> 00:36:29,650
you can see that this is slightly better method than the other

498
00:36:29,730 --> 00:36:33,190
what's interesting here is that what happens in the matlab solve at least for the

499
00:36:33,190 --> 00:36:34,550
machines we have

500
00:36:34,630 --> 00:36:39,690
is some is very quickly we end up running out of

501
00:36:39,690 --> 00:36:44,630
two you can see the numbers here and so i think this is about somewhere

502
00:36:46,300 --> 00:36:48,380
o point seven million variables

503
00:36:48,440 --> 00:36:53,320
this thing starts to break down right we can no longer solve these things OK

504
00:36:53,340 --> 00:36:56,150
because we run out of memory that

505
00:36:56,170 --> 00:37:00,440
great seems like the direct methods of anything that's the one downside they quickly run

506
00:37:00,460 --> 00:37:01,650
out of memory

507
00:37:01,650 --> 00:37:04,340
so in three d

508
00:37:04,340 --> 00:37:09,690
again and millions of variables here so what happens is that we can get this

509
00:37:09,690 --> 00:37:11,250
nice linear

510
00:37:12,710 --> 00:37:14,460
so this is in seconds

511
00:37:14,480 --> 00:37:17,880
to solve one of these systems and you can see the matlab quickly just runs

512
00:37:17,880 --> 00:37:21,480
out of memory because again we said if you're doing direct methods

513
00:37:21,530 --> 00:37:26,530
that the film is going to what's going to cost that and three have so

514
00:37:26,530 --> 00:37:30,460
these things run out of memory and crashed right so

515
00:37:30,480 --> 00:37:33,110
these are

516
00:37:33,190 --> 00:37:35,440
see OK

517
00:37:36,280 --> 00:37:39,840
so i guess what i'd like to do and it anyway so that's our solar

518
00:37:39,840 --> 00:37:44,690
stuff and so the hope was eventually try to get solvers out because like and

519
00:37:44,690 --> 00:37:48,760
this an natural community there we should have access to good solvers

520
00:37:48,860 --> 00:37:51,690
but i'd like to do that we spend a few minutes on

521
00:37:51,710 --> 00:37:53,050
how some

522
00:37:53,050 --> 00:37:57,460
one generalization that we have the full posterior

523
00:37:57,460 --> 00:38:01,090
and unfortunately i don't know any interesting applications in one of the reason i want

524
00:38:01,090 --> 00:38:05,190
to do this year's hopefully in showing you this reduction

525
00:38:05,210 --> 00:38:06,530
one of you

526
00:38:06,550 --> 00:38:10,750
are many of you will see how to apply this to machine learning so

527
00:38:10,760 --> 00:38:12,550
let's assume that i

528
00:38:12,590 --> 00:38:17,020
then instead of being a gravel pos in this is simply a symmetric diagonally dominant

529
00:38:17,020 --> 00:38:22,900
system right this simply means that the diagonal then is greater than or equal to

530
00:38:22,900 --> 00:38:27,880
the sum of the soft the absolute value of the soft corals OK

531
00:38:27,900 --> 00:38:30,960
so the goal of the rest of this talk tends to show that these systems

532
00:38:30,960 --> 00:38:33,480
calculate very easily being

533
00:38:33,490 --> 00:38:35,290
with regards to this matter

534
00:38:35,310 --> 00:38:38,300
reaches the neutron star

535
00:38:38,310 --> 00:38:41,340
the kinetic energy one of these grids

536
00:38:41,350 --> 00:38:43,260
must be equal to

537
00:38:43,290 --> 00:38:45,610
and ng over are

538
00:38:45,630 --> 00:38:50,700
we have this equation on the blackboard last lecture when we discussed cosmology with the

539
00:38:50,700 --> 00:38:52,730
same equation

540
00:38:52,810 --> 00:38:54,200
this is the speed

541
00:38:54,250 --> 00:38:56,810
which which the matter will fall onto the neutron star

542
00:38:56,910 --> 00:39:00,320
this is the mass of the neutron star and this is the radius of

543
00:39:00,610 --> 00:39:06,360
you lose the masses you always do so you can calculate

544
00:39:06,370 --> 00:39:09,460
this despite this being is around this

545
00:39:09,460 --> 00:39:11,540
because the ratings of neutron star

546
00:39:11,560 --> 00:39:16,280
so ridiculously small mass of a neutron star is very comparable to the mass of

547
00:39:16,280 --> 00:39:17,550
the sun and the larger

548
00:39:17,650 --> 00:39:22,360
not much larger but the radius is hundred thousand times smaller than that of the

549
00:39:23,370 --> 00:39:24,770
o to ten kilometres

550
00:39:24,770 --> 00:39:26,300
and as a result of that

551
00:39:27,150 --> 00:39:32,050
speed which which the matter it's the neutron star is about one-third of the speed

552
00:39:32,050 --> 00:39:34,130
of light

553
00:39:34,140 --> 00:39:36,760
but it's the neutron stars

554
00:39:36,800 --> 00:39:38,800
this kinetic energy

555
00:39:38,830 --> 00:39:40,290
is converted to heat

556
00:39:40,340 --> 00:39:43,400
it will heat up the surface layers of the neutron star

557
00:39:43,450 --> 00:39:46,570
and increases the temperature to about

558
00:39:46,590 --> 00:39:48,740
ten million nine hundred million degrees

559
00:39:48,770 --> 00:39:50,980
and at such high temperatures

560
00:39:51,000 --> 00:39:54,120
the starwood image almost all its radiation

561
00:39:54,140 --> 00:39:57,730
in x-rays and other optical sun is relatively cold

562
00:39:57,770 --> 00:40:00,100
only six hundred six thousand degrees

563
00:40:00,120 --> 00:40:00,970
and so

564
00:40:00,970 --> 00:40:02,080
the sun

565
00:40:02,140 --> 00:40:06,410
as most of its radiation in the optical but when the temperature becomes ten million

566
00:40:06,410 --> 00:40:07,790
hundred million degrees

567
00:40:07,790 --> 00:40:11,950
a function only of the data but in the but Bayesians can use the parameters as

568
00:40:11,950 --> 00:40:19,610
well because we are we quantifying the variability over that parameter so you you select that measure well we'll

569
00:40:19,610 --> 00:40:26,710
we'll call it D and find it's predictive distributions under the model so what is and that's a

570
00:40:26,720 --> 00:40:34,230
Bayesian numerical computation and then we we actually have some data so

571
00:40:34,250 --> 00:40:39,230
we replace X by X obs the observed data on which we find out where does

572
00:40:39,230 --> 00:40:47,510
that observed value that discrepancy measure lie in that distribution and so we can conduct a

573
00:40:47,510 --> 00:40:55,690
formal test of significance and of course reject if the discrepancy measures is up in the upper tail and

574
00:40:55,810 --> 00:41:01,350
this is this is very are flexible because you can choose a discrepancy measure focused on the

575
00:41:01,350 --> 00:41:05,910
the the act avt the facet of the model predictions that you most you must

576
00:41:05,910 --> 00:41:12,100
worry about that's the thing that's the most relevant to you in the future

577
00:41:12,150 --> 00:41:18,130
you serve a rather you have another choice and that is under what under

578
00:41:18,130 --> 00:41:26,630
what distribution do you evaluate this predictive because there's an issue of potentially doubly

579
00:41:26,640 --> 00:41:33,890
using data and is quite a rich literature taken back thirty years now of different choices

580
00:41:33,890 --> 00:41:42,250
some are which example are rather conservative thate there they are rather tolerant rather insensitive at at

581
00:41:42,530 --> 00:41:48,570
detecting a detecting problems because effectively they are doubly using data so there's you know quite a rich layer

582
00:41:48,570 --> 00:41:52,730
area there and I'm not gonna say anything more about it but this

583
00:41:52,730 --> 00:41:57,490
has you know this has been done but these all these things of course obey

584
00:41:57,490 --> 00:42:04,250
and aim the prediction that that's that's what it's for so they tell you something about the

585
00:42:04,250 --> 00:42:12,330
quality or goodness of fit of the model globally but they don't tell you where there

586
00:42:12,330 --> 00:42:19,570
might be problems and they don't help you do anything about it so much

587
00:42:19,570 --> 00:42:23,710
more recently there've been a rise in interest in methods that are node-based they they they

588
00:42:23,710 --> 00:42:28,590
they they look at a particularly variable in in the model I'd I say no because I don't think in ever

589
00:42:28,590 --> 00:42:33,750
represented on a graph and they try and say what's the what's the problem

590
00:42:33,750 --> 00:42:41,230
around here there are various approaches being considered again sort of getting

591
00:42:41,230 --> 00:42:49,610
back towards P value type calculations which are are local to that specific node

592
00:42:49,610 --> 00:42:52,910
but we we felt that all of these methods were kind of a little

593
00:42:52,910 --> 00:42:59,530
bit uninformative there that there they thay they formally give P value

594
00:42:59,540 --> 00:43:04,670
type assessments but they don't realy tell you qualitatively what the problem is so we wanted to

595
00:43:04,670 --> 00:43:08,630
go back to basics and think about prior likelihood conflict and try to think about

596
00:43:08,630 --> 00:43:18,270
how you could examine that perhaps graphically in in a complex model so the

597
00:43:18,270 --> 00:43:21,270
the simplest situation is this one this is one where you don't need any new

598
00:43:21,270 --> 00:43:28,970
technology okay so you have which way around is it the a complete trivial model

599
00:43:28,970 --> 00:43:35,430
we have ten observations from a normal distribution with known variants and the blue curve

600
00:43:35,430 --> 00:43:40,130
there is the plot of the likelihood function the the the the likelihood of the

601
00:43:40,130 --> 00:43:46,010
data as a function of the parameter theta which is the unknown mean the data meaning was

602
00:43:46,010 --> 00:43:52,450
twelve so of course that blue curve is set to noumber twelve now that the prior I

603
00:43:52,450 --> 00:43:59,030
used in in this particular case was a normal distribution also but we mean eight and that's yellow yellow curve

604
00:43:59,350 --> 00:44:05,990
so the a bayes theorem does it's work and you multiply

605
00:44:05,990 --> 00:44:12,710
these two together and renormalize and that gives the uncoloured curve in the middle

606
00:44:12,710 --> 00:44:17,250
okay so bayesian is really going good you you can throw anything into

607
00:44:17,250 --> 00:44:23,330
it and it will produce some inference for you but how comfortable should you be about that

608
00:44:23,340 --> 00:44:29,170
inference in this kind of situation where really the two sources of information your

609
00:44:29,170 --> 00:44:34,190
your scientific judgments about sorry this one your scientific judgments about the parameter before you

610
00:44:34,190 --> 00:44:39,870
had data are completely in conflict with those after you had the data okay is it are are you

611
00:44:39,870 --> 00:44:46,050
comfortable with letting bayes theorem make that choice when really what it's doing is taking

612
00:44:46,050 --> 00:44:52,430
two functions and multiplying them together and thyy they're almost always something very very tiny

613
00:44:52,430 --> 00:44:57,130
but it's renormalized and you and you get the curve out of it the overlap between the two is

614
00:44:57,130 --> 00:45:01,570
very small and the I've drawn in a very symmetric way but of course you get

615
00:45:01,570 --> 00:45:04,750
the same sort of thing when you vary the variances and the overlap can easily

616
00:45:04,750 --> 00:45:10,390
be even smaller so as a bayes theorem is a bit too good at his job

617
00:45:10,390 --> 00:45:16,900
okay it it it part it yields you an inference without telling you that perhaps something there's something else in

618
00:45:16,900 --> 00:45:23,870
there maybe you should reexamine your assumptions now I'm not saying throughout this section and I'm

619
00:45:23,870 --> 00:45:29,490
not saying you're assumptions were wrong I am just saying saying you shouldn't make that assumptions and not have

620
00:45:29,490 --> 00:45:33,230
it drawn to your attention that there's in conflict so that you have a

621
00:45:33,230 --> 00:45:39,570
chance to reconsider so we want to do that sort of thing everywhere in a complex model

622
00:45:39,590 --> 00:45:44,340
and the language we need to to talk about such things is again

623
00:45:44,410 --> 00:45:53,460
the language of graphical models so graphical models in this context here are graphs

624
00:45:53,470 --> 00:45:57,750
in which the the nodes of the graph the vertices of the graph represent variables and

625
00:45:57,750 --> 00:46:02,370
some of those some of those variables are connected by edges that may

626
00:46:02,370 --> 00:46:08,610
be directed or undirected and then we observe some of the some some

627
00:46:08,610 --> 00:46:10,940
what without and manfred positive

628
00:46:11,430 --> 00:46:12,610
because what you

629
00:46:13,130 --> 00:46:15,570
notice there is one zero one zero

630
00:46:16,110 --> 00:46:16,780
one zero

631
00:46:17,220 --> 00:46:18,980
is forty two in binary

632
00:46:24,350 --> 00:46:24,710
and although

633
00:46:25,340 --> 00:46:27,810
any comments questions everyone with me

634
00:46:31,200 --> 00:46:31,750
so i

635
00:46:32,070 --> 00:46:34,220
but i selection to the game sixty three

636
00:46:36,390 --> 00:46:38,890
and observation we can make is about

637
00:46:40,040 --> 00:46:44,460
if you want to be sure identifying an outcome in this alphabet

638
00:46:45,990 --> 00:46:49,030
then it will take you six binary questions to

639
00:46:49,480 --> 00:46:51,000
be sure about identifying it

640
00:46:52,430 --> 00:46:58,750
we could have a think about these claims at the shannon information content let's call the uncertainty to

641
00:46:59,340 --> 00:47:01,380
the first question he wrong

642
00:47:01,830 --> 00:47:03,950
it is three three four and so on

643
00:47:04,440 --> 00:47:05,670
the answers to these

644
00:47:06,180 --> 00:47:07,070
question is

645
00:47:15,930 --> 00:47:17,820
shannon information content all

646
00:47:18,270 --> 00:47:19,510
each of these answers

647
00:47:21,430 --> 00:47:24,680
each time you ask the question i question

648
00:47:26,030 --> 00:47:28,340
you know what i was thinking of those fifty fifty

649
00:47:29,180 --> 00:47:30,000
well the answer be

650
00:47:32,260 --> 00:47:35,600
be shannon information content about outcome walls

651
00:47:36,200 --> 00:47:38,670
log ways to one over the probability the outcome

652
00:47:39,320 --> 00:47:40,970
which was one of whatever happened

653
00:47:42,080 --> 00:47:42,790
that's lot to

654
00:47:44,750 --> 00:47:45,370
this one bit

655
00:47:49,280 --> 00:47:52,480
the total information content according to shannon you've got

656
00:48:01,170 --> 00:48:01,920
but you're going to

657
00:48:03,210 --> 00:48:03,790
throughout the whole

658
00:48:04,840 --> 00:48:05,460
thrilling game

659
00:48:06,270 --> 00:48:06,880
mistakes that

660
00:48:10,840 --> 00:48:11,410
i mean

661
00:48:12,260 --> 00:48:13,930
the string announces that you got

662
00:48:17,430 --> 00:48:18,570
eighty six

663
00:48:20,360 --> 00:48:22,240
is an encoding objects

664
00:48:32,790 --> 00:48:34,010
call see annex

665
00:48:34,140 --> 00:48:37,900
what that's the string six socio forty two

666
00:48:40,200 --> 00:48:43,170
last one zero one zero one zero so

667
00:48:44,860 --> 00:48:46,480
when making a connection to

668
00:48:47,410 --> 00:48:51,700
the question is if you get outcome you can compress it intersects the

669
00:48:52,330 --> 00:48:57,480
and six expenses and information content and making sense there's nothing very surprising happening here

670
00:48:58,910 --> 00:49:01,380
this is very weak evidence for the idea

671
00:49:02,280 --> 00:49:04,720
john information content is looking promising

672
00:49:07,930 --> 00:49:09,970
why is it a good strategy to split

673
00:49:10,690 --> 00:49:12,760
it into space everything into

674
00:49:13,250 --> 00:49:13,710
some people

675
00:49:14,420 --> 00:49:16,950
sale why don't you ask first is a prime number

676
00:49:17,670 --> 00:49:19,980
why is it a good idea to split exactly into

677
00:49:24,800 --> 00:49:30,920
it's got maximum information content maximum explore the information content if you have any other questions the probabilities

678
00:49:31,760 --> 00:49:32,410
it wouldn't be

679
00:49:32,880 --> 00:49:33,420
of all

680
00:49:34,480 --> 00:49:38,810
in general say you're not getting as much as expected information as you could the

681
00:49:38,830 --> 00:49:43,270
chance the answer might be in the big set out to your in fact is

682
00:49:43,560 --> 00:49:48,010
better than fifty fifty chance it will be and that's and then you need more

683
00:49:48,010 --> 00:49:51,190
than the remaining whatever it would have been five questions

684
00:49:55,140 --> 00:49:59,870
let's ask you one question based on this game and then do another game

685
00:50:01,070 --> 00:50:01,620
and right

686
00:50:02,130 --> 00:50:03,440
such is the question

687
00:50:04,500 --> 00:50:07,310
if i've got a set with the best possible outcomes in it

688
00:50:07,920 --> 00:50:10,510
how many bits long beach name be

689
00:50:11,030 --> 00:50:15,280
if every outcome is gonna have a unique name okay so the question is

690
00:50:15,800 --> 00:50:16,980
i'm gonna draw

691
00:50:18,960 --> 00:50:19,950
on the way home

692
00:50:27,370 --> 00:50:31,140
and i want to be thorough and systematic and give everyone these unique name so

693
00:50:31,140 --> 00:50:34,270
i can record on facebook which clothing and wearing today

694
00:50:35,270 --> 00:50:37,130
i'm gonna write little names on them

695
00:50:37,880 --> 00:50:38,730
and the question is

696
00:50:39,870 --> 00:50:42,130
if i'm going to post on facebook be

697
00:50:46,270 --> 00:50:47,890
namely to these items

698
00:50:48,310 --> 00:50:48,970
and there are

699
00:50:54,470 --> 00:50:55,270
capital assets

700
00:50:55,790 --> 00:50:56,680
different pieces of underwear

701
00:50:57,420 --> 00:51:01,410
how long does it should be these binary names have to be assuming i give

702
00:51:01,410 --> 00:51:03,260
them all binary names are the same

703
00:51:05,540 --> 00:51:06,360
habitat geneva

704
00:51:11,380 --> 00:51:13,470
how long the mine labels need to be

705
00:51:14,050 --> 00:51:15,500
to label my underwear

706
00:51:16,540 --> 00:51:21,160
and outcome from the set can be encoded can be communicated in how many bits

707
00:51:27,080 --> 00:51:27,790
one way to

708
00:51:28,710 --> 00:51:31,560
all this ended up some not any alternative answer

709
00:51:35,290 --> 00:51:39,820
that's what they rounded up a in case this is an integer number sixty four

710
00:51:40,720 --> 00:51:42,360
six which is not can be

711
00:51:42,960 --> 00:51:45,700
in general so sixty seven or something

712
00:51:46,500 --> 00:51:50,740
well rounded up bit so maybe we need to go up by almost one

713
00:51:51,150 --> 00:51:51,820
and we collapse

714
00:51:52,190 --> 00:51:54,400
feeling this symbol means

715
00:51:57,410 --> 00:51:57,990
which means

716
00:51:58,590 --> 00:52:01,040
the number rounded up to the nearest integer

717
00:52:02,640 --> 00:52:03,970
so let's definitely

718
00:52:04,540 --> 00:52:09,220
so the answer after for being obsessive we see longer just to make sure all

719
00:52:11,840 --> 00:52:12,920
we've got the right engine

720
00:52:12,920 --> 00:52:16,980
like saying you need to hurry up to not miss your bus or there's no

721
00:52:16,980 --> 00:52:25,210
parking in this parking lot you should rewrite and self evolving by by changing services

722
00:52:25,280 --> 00:52:31,690
benefits are emergency management traffic management and and mobile commerce

723
00:52:31,730 --> 00:52:36,230
but a location-based advertisment for example so this is all

724
00:52:36,290 --> 00:52:40,980
an ecosystem which thrives on this real time data which is not that today but

725
00:52:40,980 --> 00:52:46,130
we have several cities trying to to invest in that

726
00:52:47,250 --> 00:52:54,970
IBM's smarter planet initiative you might have have heard about so big advertising buzzwords is

727
00:52:55,030 --> 00:52:59,890
going in this direction smart electronic health

728
00:53:00,300 --> 00:53:06,650
many diseases require personalized treatment on real time data so you could have a small

729
00:53:06,650 --> 00:53:08,210
sensors which you wear

730
00:53:08,570 --> 00:53:11,180
which help you by by

731
00:53:12,280 --> 00:53:18,030
processing on on on the a wearable computer to deal with this and and to

732
00:53:20,400 --> 00:53:25,880
like increase of your illness and help you visit the doctor at the right time

733
00:53:26,330 --> 00:53:28,200
there's people developing

734
00:53:28,250 --> 00:53:34,230
a what they called a tense and medical check-up for india

735
00:53:34,250 --> 00:53:38,160
which is supposed to be a little sticker that you stick next to your heart

736
00:53:38,160 --> 00:53:41,810
and it will tell you if you have certain heart diseases and it will save

737
00:53:41,810 --> 00:53:46,400
you the trip to the doctor or recommend you to even

738
00:53:46,420 --> 00:53:50,310
go far distance to the doctor if you really need to

739
00:53:50,340 --> 00:53:51,730
so this is all o

740
00:53:51,770 --> 00:53:58,540
working with sensor data in real time processing fashion to to help really different problems

741
00:53:58,560 --> 00:54:00,720
and the smart grid

742
00:54:00,720 --> 00:54:07,720
which is the the power of electricity revolution is obviously dealing with real time data

743
00:54:08,580 --> 00:54:16,830
electricity coming from renewable sources is not as reliable as from non-renewable resources and you

744
00:54:16,830 --> 00:54:22,540
need to you need to leverage a supply and demand in this network with real-time

745
00:54:23,440 --> 00:54:26,420
so you need a very dynamic system which again

746
00:54:26,430 --> 00:54:28,500
thrives on these events

747
00:54:28,520 --> 00:54:33,140
so the potential of this real-time push information is crucial for many of these

748
00:54:33,330 --> 00:54:39,210
verticals here and this can be very data intensive so i was talking about the

749
00:54:39,220 --> 00:54:42,410
about on-the-fly processing all the time

750
00:54:42,720 --> 00:54:48,260
and this overload will become worse or more challenging if you wish for example the

751
00:54:48,260 --> 00:54:52,320
real time web growing number of resources even on the web move away from this

752
00:54:52,330 --> 00:54:57,360
traditional request response system where website will just sit there and wait until you call

753
00:54:57,360 --> 00:55:02,880
it but websites are updating each other blogs have these being backs twitter has a

754
00:55:02,880 --> 00:55:06,780
an API which pushes data and so on and so on

755
00:55:06,800 --> 00:55:13,220
facebook graph API supports real-time updates and jason so you will get pushed a data

756
00:55:13,220 --> 00:55:19,160
item google supports these modifications to what they call it pops up how about

757
00:55:19,160 --> 00:55:23,160
where you can subscribe for let's say

758
00:55:23,170 --> 00:55:29,550
in rss items and they will push them to you so are as traditionally is

759
00:55:29,550 --> 00:55:35,570
again a request response paradigm that these people changed it into a real push system

760
00:55:35,580 --> 00:55:40,120
html five websockets will even allow it to push data to the browser so the

761
00:55:40,120 --> 00:55:45,660
client can sit there viewing a static web page and and he can get updates

762
00:55:45,670 --> 00:55:46,800
from the server

763
00:55:46,830 --> 00:55:49,310
while he's looking at this page

764
00:55:49,330 --> 00:55:53,970
you can see this with facebook part of this can be simulated today with javascript

765
00:55:54,660 --> 00:56:00,770
with longstanding connections but anyway the standard will formalise this push communication so you get

766
00:56:00,770 --> 00:56:04,770
an even the last mile to the web client

767
00:56:04,920 --> 00:56:07,920
will enable pushchair

768
00:56:09,120 --> 00:56:13,160
there is supposed to be a great outlook for complex event processing if anyone wants

769
00:56:13,160 --> 00:56:18,650
to form a company the vendor market is very turbulent and but application potential is

770
00:56:19,620 --> 00:56:24,910
and mainly improving the real time awareness so there's many systems out there which are

771
00:56:24,910 --> 00:56:29,190
that is you take each of your parameters you're going to add for

772
00:56:29,200 --> 00:56:32,690
each individual parameter some positive constant epsilon

773
00:56:33,050 --> 00:56:35,430
compute what is the loss in this case this

774
00:56:35,580 --> 00:56:39,140
f of x function would be the the complete loss

775
00:56:39,520 --> 00:56:43,810
and also to do the same thing again but subtracting epsilon stem

776
00:56:43,810 --> 00:56:46,140
from your current you know some value of the

777
00:56:46,340 --> 00:56:50,050
issue of the parameters taking the difference and divided by to

778
00:56:50,060 --> 00:56:53,550
absalom so if that's on goes to zero this is

779
00:56:53,550 --> 00:56:55,620
essentially a definition of the gradient

780
00:56:55,620 --> 00:56:58,370
views a very small absalon you should get a value is going to be

781
00:56:58,370 --> 00:57:01,560
pretty close to a correct implementation

782
00:57:01,840 --> 00:57:06,530
of the computation of the gradient so if using things like

783
00:57:06,530 --> 00:57:09,830
you know the know which adagrad and full that's probably not really

784
00:57:09,830 --> 00:57:13,530
necessary but if you've changed some of the components yourself you

785
00:57:13,530 --> 00:57:16,290
plemented some of the gradients you definitely want to that was the

786
00:57:16,290 --> 00:57:18,800
first thing you should do yeah a are

787
00:57:19,570 --> 00:57:23,420
always by default or yeah you can ask yes then usually are actually

788
00:57:23,430 --> 00:57:27,550
procedures built tend to just do that test very easily yes yes

789
00:57:32,130 --> 00:57:36,000
yeah presumably for more yet the question is you should have epsilon

790
00:57:36,010 --> 00:57:39,030
depend on x there are certainly cases where

791
00:57:39,530 --> 00:57:42,280
batch is that give you a very bad approximations

792
00:57:42,910 --> 00:57:47,240
there's no whole obviously way that i know of of choosing epsilon

793
00:57:47,540 --> 00:57:50,610
depending on the value of x unfortunately not that i

794
00:57:52,940 --> 00:57:57,230
yes so so the question was whether you know our other i seem

795
00:57:57,230 --> 00:57:59,190
to have hinted that realize i did but

796
00:57:59,250 --> 00:58:02,580
i had said that there's other ways of computing estimating this

797
00:58:02,860 --> 00:58:07,520
there if you could it could just be plus epsilon and f of x and

798
00:58:07,530 --> 00:58:10,600
divided by just epsilon and that will still

799
00:58:10,670 --> 00:58:13,160
you know most cases give you also good estimate

800
00:58:22,850 --> 00:58:27,840
so and ok and then assuming gradients are fine

801
00:58:27,990 --> 00:58:32,170
and you pass your that check first thing to do

802
00:58:33,070 --> 00:58:35,600
that will debug other potential problems in your

803
00:58:35,800 --> 00:58:39,680
experiment code is to just take whatever there's a replanning on

804
00:58:39,690 --> 00:58:43,400
training on shrink it by whole lot like maybe fifty examples

805
00:58:43,640 --> 00:58:46,990
and just make sure that you can overfit that training set

806
00:58:46,990 --> 00:58:50,000
that you can reach perfect performance if you during classification

807
00:58:50,000 --> 00:58:53,600
for instance on that training set this will allow you to see whether

808
00:58:53,610 --> 00:58:57,450
some units are saturating you're not even optimising properly

809
00:58:57,610 --> 00:59:00,010
whether this will give you some idea of

810
00:59:00,230 --> 00:59:02,390
new popper ranges for the learning rates

811
00:59:02,530 --> 00:59:05,750
it's really good for hours debugging experiment to do that i

812
00:59:05,750 --> 00:59:08,330
personally always do what i could it up something new

813
00:59:08,330 --> 00:59:11,970
will allow you to check whether you're initialization which you know

814
00:59:11,980 --> 00:59:16,440
bad regime and so it allows you to the bug about these different

815
00:59:16,450 --> 00:59:19,980
things this is not a replacement for rach go so

816
00:59:22,410 --> 00:59:26,670
essentially backprop or gradient descent is a very bug resistant

817
00:59:26,800 --> 00:59:30,390
so if you have bad computer laser gradients point stunt some

818
00:59:30,390 --> 00:59:32,930
your brain it's just always zero for some reason

819
00:59:33,400 --> 00:59:36,840
you will see some training you will see training error reduce you

820
00:59:36,840 --> 00:59:40,620
might some overfitting from the engineering standpoint if you're

821
00:59:40,620 --> 00:59:44,080
going to have the bug having to be somewhat resistant to bad situations

822
00:59:44,080 --> 00:59:46,500
as a good thing but scientifically speaking or doing

823
00:59:46,500 --> 00:59:49,690
research that is not a good thing so you deftly want to do both

824
00:59:49,690 --> 00:59:53,440
the gretsch eq if you've you know design or the new

825
00:59:53,710 --> 00:59:56,900
great to estimate or a new module for which you're computing

826
00:59:56,910 --> 00:59:58,740
gradients and do this also

827
01:00:01,020 --> 01:00:04,750
ok other questions quick

828
01:00:07,310 --> 01:00:11,530
yes yes so why yeah so the question is why is

829
01:00:12,110 --> 01:00:16,730
doing expanse of small dataset interesting here it's compute nationally

830
01:00:16,820 --> 01:00:19,450
only it's small dataset you going to be able to

831
01:00:19,610 --> 01:00:22,940
try a bunch of things very quickly whereas like

832
01:00:22,940 --> 01:00:26,360
if you always training full dataset you still trying to fix problems

833
01:00:26,360 --> 01:00:28,580
in your initialization of things like that

834
01:00:28,580 --> 01:00:31,810
just take much more time because you know if you dataset as

835
01:00:31,820 --> 01:00:36,580
long as it's pretty big then gaining performance at each generations

836
01:00:36,590 --> 01:00:39,030
might take a lot of time that's why i'm saying

837
01:00:39,240 --> 01:00:41,570
you know if you have a very large dataset to

838
01:00:41,630 --> 01:00:43,750
that actually want to run the experiment

839
01:00:43,750 --> 01:00:47,790
on first doing like this very quickly small experiment on small

840
01:00:47,800 --> 01:00:51,520
dataset will know the fast to do so that's why

841
01:00:51,800 --> 01:00:57,830
yeah yeah yeah in this case other like you don't care about the

842
01:00:57,840 --> 01:01:00,480
performance seeing beyond like on the training set

843
01:01:00,730 --> 01:01:03,900
because essentially your learning algorithm if it's not able

844
01:01:03,900 --> 01:01:06,630
to overfit on a very small dataset you're probably not going

845
01:01:06,630 --> 01:01:10,660
to do well or anything good on a large dataset because you have

846
01:01:10,800 --> 01:01:14,340
you have more data to fit in that situation to you should at least

847
01:01:14,350 --> 01:01:18,270
pass this unit test so right moving on

848
01:01:18,490 --> 01:01:21,810
in the last twenty five minutes yeah on the

849
01:01:22,180 --> 01:01:24,380
i guess deep learning so trying to

850
01:01:24,720 --> 01:01:27,190
remember in the first part i describe

851
01:01:28,030 --> 01:01:32,310
theoretically anyways we to approximate the function we don't

852
01:01:32,310 --> 01:01:35,600
knesset need multiple layers result only mention using a single

853
01:01:35,600 --> 01:01:39,930
layer have enough hidden units should be fine approximating any

854
01:01:39,940 --> 01:01:43,680
function so why do we actually want multiple hidden layers

855
01:01:45,140 --> 01:01:49,650
so maybe just a quick few words about

856
01:01:50,130 --> 01:01:53,560
deep learning what one might mean about deep learning and what

857
01:01:53,970 --> 01:01:56,290
one might consider as deep learning research

858
01:01:56,290 --> 01:01:59,530
there is kind of a person ole interpret patient but i would say

859
01:01:59,530 --> 01:02:02,150
that generally speaking for me deploying is

860
01:02:02,320 --> 01:02:06,760
broad enough to include really any and s agation of models that

861
01:02:06,970 --> 01:02:10,310
at the core extract multi levels of representations

862
01:02:10,310 --> 01:02:13,580
and specifically multi levels of distributed representations that

863
01:02:13,580 --> 01:02:15,820
is representations where you have units

864
01:02:15,880 --> 01:02:19,480
which are not really mutually exclusive they can represent different

865
01:02:19,480 --> 01:02:23,220
factors variations that are separate that are not necessarily

866
01:02:23,690 --> 01:02:28,780
mutually exclusive so for instance article clustering approach

867
01:02:28,920 --> 01:02:32,310
you might argue as multiple levels but because all the different

868
01:02:32,310 --> 01:02:35,800
clusters are mutually inclusive i personally would nicely think of

869
01:02:36,830 --> 01:02:40,970
the learning thing at the core least sort ically of research behind

870
01:02:40,970 --> 01:02:42,520
that has been label as deep learning

871
01:02:42,520 --> 01:02:45,350
there was this notion of distributed representations which

872
01:02:45,350 --> 01:02:48,680
i think is quite important at multiple situations for

873
01:02:48,840 --> 01:02:54,400
multiple types of data one motivation of course is a newt thinking

874
01:02:54,400 --> 01:02:56,950
broadly about the brain influences the visual cortex where

875
01:02:56,950 --> 01:03:01,380
we know that the stimuli we get from the retina eventually goes through

876
01:03:01,390 --> 01:03:05,520
several regions of of the brain v y on and then be doing that different

877
01:03:05,520 --> 01:03:08,020
levels there's been measurements that suggest that

878
01:03:08,020 --> 01:03:12,170
savy want will detect simple visual forms like edges and corners

879
01:03:12,250 --> 01:03:16,280
and eventually get intermediate more complex visual forms or features

880
01:03:16,290 --> 01:03:20,290
are being detected by these units and eventually these neurons

881
01:03:20,300 --> 01:03:22,860
and eventually i t wy-ghet high-level objects

882
01:03:23,010 --> 01:03:27,870
and faces and so on and so in a cartoon way you

883
01:03:28,220 --> 01:03:31,550
would kind of expect say face recognizer differs initially have

884
01:03:31,550 --> 01:03:36,080
a layer of detection of very simple things like edges and and

885
01:03:36,080 --> 01:03:39,060
points and then eventually maybe edges that combine together

886
01:03:39,060 --> 01:03:43,760
to form a nose or mouth or eyes and actually get a full phase that's

887
01:03:43,770 --> 01:03:48,650
combination of these concepts there are some theoretical justifications

888
01:03:48,660 --> 01:03:52,210
the early ones were relating to some theory from

889
01:03:52,520 --> 01:03:55,380
the study of boolean functions and willing search cuts

890
01:03:55,380 --> 01:03:59,630
so this is the thought of reasoning that happens in put into the plans of

891
01:03:59,960 --> 01:04:01,310
this plan space

892
01:04:01,360 --> 01:04:05,110
OK the reason i brought this up really is to say that well planning is

893
01:04:05,110 --> 01:04:10,310
not just state space search planning can be any type of search which ultimately leads

894
01:04:10,310 --> 01:04:11,230
to apply

895
01:04:11,250 --> 01:04:16,380
again i told you history there are many other ways of yes

896
01:04:16,380 --> 01:04:27,060
OK so that the names again i'm not going into the details but that's it

897
01:04:27,080 --> 01:04:31,190
since you ask me l and you an open condition is so for example q

898
01:04:31,190 --> 01:04:37,040
one is currently in open conditions you have not said anybody is supporting q one

899
01:04:37,090 --> 01:04:40,970
OK so when you said somebody is going to give you q one that sort

900
01:04:40,970 --> 01:04:46,290
of commitments causal commitments o five s zero will q one then output because the

901
01:04:46,290 --> 01:04:51,060
link from q one that's the way the search numbers that whatever happens i want

902
01:04:51,060 --> 01:04:54,670
to make sure that nobody comes in tunisia and it's one of the most q

903
01:04:54,730 --> 01:04:59,250
that's basically or you know if you have an open condition due establish a causal

904
01:04:59,860 --> 01:05:03,790
having put a causal link in this case for example s one is giving to

905
01:05:03,790 --> 01:05:08,000
s three that causal link now we became an unsafe causal link because this tool

906
01:05:08,000 --> 01:05:10,960
can possibly come between these two and killed

907
01:05:11,920 --> 01:05:15,770
and in that case you can actually separate

908
01:05:15,790 --> 01:05:19,460
OK so those are the names that in fact part planning

909
01:05:19,460 --> 01:05:24,290
it has much more colorful set of names in all sorts of fun stuff like

910
01:05:24,290 --> 01:05:26,110
and say things and

911
01:05:26,110 --> 01:05:29,900
confrontation which is if somebody is trying to

912
01:05:29,920 --> 01:05:32,250
say no for example is to say

913
01:05:32,270 --> 01:05:36,520
well if i have a few through before me i will delete b

914
01:05:36,540 --> 01:05:40,590
so here's your enemy and he is happening that they would really be fully they

915
01:05:40,590 --> 01:05:45,060
have queudrue and so you confront the enemy by saying i didn't make not queudrue

916
01:05:45,060 --> 01:05:46,540
before you

917
01:05:46,590 --> 01:05:49,590
and then that becomes an extra goat you what kind of

918
01:05:49,610 --> 01:05:52,690
OK so they're all sorts of this terminology but you know i won't go into

919
01:05:52,860 --> 01:05:56,210
now the important things to note is for the city

920
01:05:56,250 --> 01:05:59,580
planets is there are there are doing search

921
01:05:59,580 --> 01:06:03,770
different kinds of search for the exact became the cancer progression it's easy enough to

922
01:06:03,770 --> 01:06:07,540
understand the search you start from these estate and then you upload possible actions and

923
01:06:07,540 --> 01:06:11,590
then for each of these steps you about possible actions looks easy enough question is

924
01:06:11,590 --> 01:06:14,840
which of the branches that i should go forward and so that i have some

925
01:06:14,840 --> 01:06:17,170
hope of being done fast

926
01:06:17,230 --> 01:06:21,940
OK so i need to figure out the choice point here which branches are closer

927
01:06:22,210 --> 01:06:24,230
to the goal that i'm trying to get

928
01:06:24,310 --> 01:06:29,520
the same thing is true for integration with the tries points which of these branches

929
01:06:29,520 --> 01:06:33,170
will get me to the initial state fast and i'm starting the wall street so

930
01:06:33,170 --> 01:06:37,630
for searches goal state would be the problems issues

931
01:06:37,650 --> 01:06:43,900
and the choice points but this algorithm are different they have actually selecting which opened

932
01:06:43,900 --> 01:06:48,170
condition i'm going to support and deciding which uncivil income going to

933
01:06:48,170 --> 01:06:53,840
you know confront and and and and and then although open conditions and all the

934
01:06:53,980 --> 01:06:57,880
siblings have been that it now it turns out that actually those you have to

935
01:06:57,880 --> 01:06:59,480
deal with every plan

936
01:06:59,500 --> 01:07:03,880
which is finally complete should not have any open conditions and in you have

937
01:07:03,900 --> 01:07:07,360
but the question is one i decided that i'm supporting q one there may be

938
01:07:07,360 --> 01:07:11,340
multiple ways of supporting two or maybe initial state can supported maybe some other actions

939
01:07:11,460 --> 01:07:14,980
supported maybe i can brand i can bring about a new action which was support

940
01:07:15,000 --> 01:07:15,790
q one

941
01:07:15,840 --> 01:07:18,590
and these are all the possible choices and you don't know which one will actually

942
01:07:20,150 --> 01:07:23,710
i mean the end of the that's so those the that choices that you need

943
01:07:23,730 --> 01:07:25,520
to learn about here

944
01:07:28,860 --> 01:07:31,900
the thing that i was trying to make the point of is i love this

945
01:07:31,900 --> 01:07:36,540
search there maybe into search in different places but all search and i'm not actually

946
01:07:36,540 --> 01:07:40,960
going to spend more time talking about the simplest search which is progression and i'll

947
01:07:40,960 --> 01:07:43,750
tell you how they were able to to prove that and you know by definition

948
01:07:43,790 --> 01:07:48,170
sort of more of the other things were done by default so the basic idea

949
01:07:48,170 --> 01:07:51,340
is in field in progress you have this humungous tree and you know which branch

950
01:07:51,360 --> 01:07:54,720
to go on and if you extend and at the and and then try to

951
01:07:54,720 --> 01:08:00,270
figure out variable you get in the regression you know i this with background you're

952
01:08:00,270 --> 01:08:04,540
going in the direction i'm not very good animations and stuff so it and the

953
01:08:04,540 --> 01:08:09,730
animations in this thing that because my students and my best kind of ideas that

954
01:08:09,730 --> 01:08:14,420
is for all i know so you how you know when we have to figure

955
01:08:14,420 --> 01:08:16,150
out which band is going to

956
01:08:16,900 --> 01:08:18,380
take it to the belfast

957
01:08:18,420 --> 01:08:23,320
and remember that so this much all of this stuff is like into one you

958
01:08:23,320 --> 01:08:27,650
know enjoy i into planning you know everybody knew this stuff longest time and people

959
01:08:27,650 --> 01:08:30,810
who are having their various different ideas as to which of these ties is to

960
01:08:30,810 --> 01:08:34,880
take and from the point of view of learning you might say that the learning

961
01:08:34,880 --> 01:08:36,060
algorithm might say

962
01:08:36,080 --> 01:08:39,540
that if your goal is this and you are in this state

963
01:08:39,560 --> 01:08:42,060
hinted you should be taking this action

964
01:08:42,090 --> 01:08:45,380
that that is the way of learning search control from will talk about some of

965
01:08:45,380 --> 01:08:47,130
the first of march

966
01:08:47,150 --> 01:08:53,000
the other possibility is you can just do basically the heuristics based on problem relaxations

967
01:08:53,000 --> 01:08:58,540
and you just the way you learn your is that the discussion in and it

968
01:08:58,540 --> 01:09:02,790
turns out that the biggest break for of came then people figured out that there

969
01:09:02,810 --> 01:09:08,270
is class of relaxations cars approximate reachability analysis that seemed to do wonders

970
01:09:08,290 --> 01:09:11,770
now why did it take so long i have no idea what we figured it

971
01:09:11,770 --> 01:09:15,540
out so that's a good story

972
01:09:16,820 --> 01:09:21,090
here is a way of figuring out which of these branches pick one is i

973
01:09:21,090 --> 01:09:22,520
would say so

974
01:09:22,560 --> 01:09:26,590
suppose there is in state you know there are many many possible states in the

975
01:09:26,590 --> 01:09:31,270
third grade because the number to see whether or not it's worth taking it

976
01:09:31,290 --> 01:09:35,090
whether or not it's worth expanding it one way of answering the question is how

977
01:09:35,110 --> 01:09:36,920
close it with the goal state

978
01:09:36,940 --> 01:09:40,940
OK well here is a number idea which actually works very well in text if

979
01:09:40,940 --> 01:09:46,270
you can ignore the cost of computing which is good and bad progression-free from this

980
01:09:46,270 --> 01:09:48,130
date onwards

981
01:09:48,150 --> 01:09:53,770
OK and then see v if you know until you find the ball state in

982
01:09:53,880 --> 01:09:55,080
one of the fringes

983
01:09:55,090 --> 01:09:56,040
and then you know

984
01:09:56,040 --> 01:09:59,940
what is the length of the path from the state goals

985
01:09:59,960 --> 01:10:03,110
so what you can then do and this is done by and i think you

986
01:10:03,110 --> 01:10:07,320
should always understand the idea before you can appreciate the that you so

987
01:10:07,340 --> 01:10:11,270
all these guys for each of them i do a big progression from each of

988
01:10:11,270 --> 01:10:14,960
these states figured out how far the familiar with straight and which are the same

989
01:10:15,020 --> 01:10:17,110
family closest the ones that expand

990
01:10:17,150 --> 01:10:22,340
you know that's the perfect heuristic for this case and this implies what you want

991
01:10:22,340 --> 01:10:26,560
to do that essentially computing the reachability between states and the goal states how far

992
01:10:26,560 --> 01:10:28,190
is it to work with

993
01:10:28,230 --> 01:10:32,610
and one idea that actually works quite well and in fact you know

994
01:10:32,610 --> 01:10:37,860
in private account that account for most of the interesting planning performance performances this is

995
01:10:37,860 --> 01:10:39,210
really to say about

996
01:10:39,230 --> 01:10:41,820
instead of doing that and that progression

997
01:10:41,840 --> 01:10:46,750
let's do approximated watching of provision there for example this pattern

998
01:10:46,790 --> 01:10:48,500
level is just

999
01:10:48,540 --> 01:10:55,310
you start removing the membrane between the states and you saying well on this PSI

1000
01:10:55,320 --> 01:11:00,020
has of which is all the possible values p q and r and s can

1001
01:11:00,020 --> 01:11:04,640
roughly again for same that matter plus the cost which is to compare exit the

1002
01:11:04,640 --> 01:11:08,340
middle elements is actually one comparison

1003
01:11:08,390 --> 01:11:14,190
this has solution

1004
01:11:14,270 --> 01:11:17,870
log and you all know the running time but

1005
01:11:18,550 --> 01:11:19,790
binary search

1006
01:11:19,800 --> 01:11:20,840
here it is

1007
01:11:20,850 --> 01:11:25,130
solving the recurrence and i mean there are couple differences here we don't have the

1008
01:11:25,170 --> 01:11:28,660
added water and term if we did it would be

1009
01:11:29,670 --> 01:11:32,010
the running time better than i can

1010
01:11:32,030 --> 01:11:35,760
so we're getting rid of the to bring it down to one taking the and

1011
01:11:35,760 --> 01:11:37,100
bring it down to one

1012
01:11:37,120 --> 01:11:42,310
that's making around a lot faster both and kind of a surprise there

1013
01:11:42,410 --> 01:11:47,680
let's do some more interesting algorithms

1014
01:11:47,690 --> 01:11:58,490
the powering a number problem

1015
01:11:58,510 --> 01:12:00,940
it is i give you

1016
01:12:03,470 --> 01:12:07,360
that is like a real number

1017
01:12:07,370 --> 01:12:09,650
one point number whatever

1018
01:12:09,660 --> 01:12:11,650
and i give you

1019
01:12:11,800 --> 01:12:13,950
integer and

1020
01:12:13,960 --> 01:12:17,510
we cerro

1021
01:12:17,530 --> 01:12:20,670
i want to compute x the power

1022
01:12:25,550 --> 01:12:29,650
a very simple problem is in some sense even easier than all of these

1023
01:12:29,720 --> 01:12:33,700
so here it is and divide and conquer is the right thing to do so

1024
01:12:33,700 --> 01:12:36,600
the naive algorithm

1025
01:12:36,620 --> 01:12:38,140
it's very simple

1026
01:12:38,150 --> 01:12:42,410
how do you compute x power and well the definition of x the power i

1027
01:12:42,410 --> 01:12:44,410
take x y multiply by

1028
01:12:44,420 --> 01:12:46,250
by x n times

1029
01:12:46,260 --> 01:12:47,520
so i take x

1030
01:12:47,530 --> 01:12:53,800
times x times accessed x were there and copies of next

1031
01:12:53,810 --> 01:12:55,390
and that's six to be

1032
01:12:56,970 --> 01:12:58,230
big surprise that's

1033
01:12:58,240 --> 01:13:01,740
and multiplications are n minus one multiplications

1034
01:13:01,760 --> 01:13:02,920
they data and time

1035
01:13:02,940 --> 01:13:12,880
that's not the best you can do

1036
01:13:12,960 --> 01:13:14,400
for this problem

1037
01:13:14,420 --> 01:13:16,560
any suggestions on what we might do

1038
01:13:16,740 --> 01:13:18,260
using divide and conquer

1039
01:13:18,270 --> 01:13:25,070
for someone has anyone seen this before

1040
01:13:25,710 --> 01:13:29,120
so for the rest

1041
01:13:33,060 --> 01:13:38,130
on the spot creativity which is very difficult

1042
01:13:38,150 --> 01:13:40,310
i was like the challenge

1043
01:13:40,330 --> 01:13:43,620
so what i mean random ideas what can we possibly do

1044
01:13:43,640 --> 01:13:47,780
to make this problem solved this problem in less than linear time houses sort of

1045
01:13:47,780 --> 01:13:50,120
divide and problem

1046
01:13:50,200 --> 01:13:55,040
we have two inputs x and and

1047
01:13:55,060 --> 01:13:59,010
so we can try to divide on x

1048
01:13:59,030 --> 01:14:01,070
he was bit hard to some

1049
01:14:02,010 --> 01:14:07,010
we can try to divide and

1050
01:14:07,030 --> 01:14:09,470
any guesses doesn't

1051
01:14:09,520 --> 01:14:11,810
look actually innovative very good that's

1052
01:14:11,830 --> 01:14:13,040
exactly the idea

1053
01:14:13,050 --> 01:14:15,720
the divine cockeyed

1054
01:14:24,990 --> 01:14:27,900
we'd like to look at x the innovative this is going to be a little

1055
01:14:27,900 --> 01:14:31,080
bit tricky now we are going to have to pay attention floors and ceilings

1056
01:14:31,160 --> 01:14:34,140
what i would like to say is well next to the

1057
01:14:34,150 --> 01:14:35,010
he is

1058
01:14:35,030 --> 01:14:37,200
x to the and over two

1059
01:14:37,280 --> 01:14:40,950
times xtn innovative two

1060
01:14:40,970 --> 01:14:43,630
and this is true if and easy

1061
01:14:43,680 --> 01:14:49,530
if it's ok then i need to be will be more careful but let's just

1062
01:14:49,530 --> 01:14:53,300
think about the intuition why this is a good divide-and-conquer we have a problem of

1063
01:14:53,300 --> 01:14:55,370
size and let's say

1064
01:14:55,390 --> 01:14:57,000
we converted into

1065
01:14:57,020 --> 01:15:00,900
it looks like to some problems of size and number two but in fact they

1066
01:15:00,900 --> 01:15:05,050
are the same subproblems have to solve one of them by computer actually over two

1067
01:15:05,050 --> 01:15:07,160
hey i know next the innovative

1068
01:15:07,250 --> 01:15:12,150
so there's one recursive call problem size and over to that square that number and

1069
01:15:12,150 --> 01:15:16,540
that's one computations exactly the same recurrence as binary search

1070
01:15:16,590 --> 01:15:18,970
log time much better than that

1071
01:15:20,470 --> 01:15:22,750
they also have to solve the case

1072
01:15:24,980 --> 01:15:27,720
and as i

1073
01:15:27,740 --> 01:15:30,260
a look at and minus one over two

1074
01:15:30,270 --> 01:15:33,680
that's and minus one that be even

1075
01:15:35,800 --> 01:15:38,870
and then missing another factor six

1076
01:15:41,140 --> 01:15:43,020
so that is i'm going to have to do

1077
01:15:43,040 --> 01:15:46,160
one recursive call n two multiplications

1078
01:15:46,180 --> 01:15:47,760
same recurrence

1079
01:15:47,760 --> 01:15:49,490
a judicious mix of

1080
01:15:49,510 --> 01:15:53,170
exploitation and exploration so explanation is

1081
01:15:53,200 --> 01:15:57,920
use the existence of the best possible act and so the best possible that

1082
01:15:57,950 --> 01:15:59,400
an exploration is

1083
01:15:59,420 --> 01:16:03,610
that we realize that the system is not so good outcome for this is not

1084
01:16:03,610 --> 01:16:07,720
the best but the more and so we pick out some things that just increase

1085
01:16:07,720 --> 01:16:11,130
the knowledge of the space of the space effects

1086
01:16:11,150 --> 01:16:13,700
we don't expect to make lots of money right now

1087
01:16:13,700 --> 01:16:15,090
but in the long run

1088
01:16:15,110 --> 01:16:17,420
we should we hope to get back to model

1089
01:16:17,430 --> 01:16:19,690
which can increase the number of clicks

1090
01:16:19,740 --> 01:16:21,820
so this is more for long

1091
01:16:23,040 --> 01:16:28,150
there's been a lot of literature on this sort of problem combining explotation and exploration

1092
01:16:28,150 --> 01:16:32,470
and this falls under the realm of something called multi armed bandits

1093
01:16:33,840 --> 01:16:37,320
i look at some of it provided background of

1094
01:16:37,320 --> 01:16:40,300
of the literature on this particular

1095
01:16:41,030 --> 01:16:46,860
and i focused more on some aspects that would limit the online advertising sector so

1096
01:16:46,860 --> 01:16:51,700
in discuss the background and provide some applications to online advertising and then look at

1097
01:16:51,720 --> 01:16:57,610
what works what doesn't what are the challenges with open problems in this set

1098
01:16:57,670 --> 01:16:59,740
so let's start with the band

1099
01:17:00,490 --> 01:17:01,970
you go to las vegas

1100
01:17:01,990 --> 01:17:03,320
you see no

1101
01:17:03,340 --> 01:17:05,720
there are two slot machines and ahead of you

1102
01:17:06,510 --> 01:17:11,190
in the terminology of the literature each of the slot machines is called a bandit

1103
01:17:11,190 --> 01:17:15,380
and this constitutes three on bent

1104
01:17:15,400 --> 01:17:17,510
associated with each man

1105
01:17:17,590 --> 01:17:19,130
is something unknown

1106
01:17:19,150 --> 01:17:21,050
they are probably so

1107
01:17:21,050 --> 01:17:24,340
if i is played on what i forty five

1108
01:17:24,340 --> 01:17:25,990
then with probability p one

1109
01:17:26,010 --> 01:17:29,490
i have a success and they get a unit award

1110
01:17:29,510 --> 01:17:33,880
otherwise failure and they get no rewards

1111
01:17:33,900 --> 01:17:34,950
and now

1112
01:17:34,970 --> 01:17:41,380
my goal is to pull arms sequentially one after another so that over time

1113
01:17:41,400 --> 01:17:44,320
the total expected reward is maximized

1114
01:17:44,450 --> 01:17:45,550
so what they do

1115
01:17:45,550 --> 01:17:49,780
initially i don't know the payoff probabilities of any of these arms so go in

1116
01:17:49,780 --> 01:17:51,110
and play arms

1117
01:17:51,130 --> 01:17:53,610
waterless randomly just to figure out

1118
01:17:53,610 --> 01:17:56,260
what the p of property is approximately

1119
01:17:56,280 --> 01:17:59,280
and then i tried and i over time

1120
01:17:59,380 --> 01:18:02,590
you start to see that because some of these arms and much better than some

1121
01:18:02,590 --> 01:18:06,340
of the other and then you start focusing on the back arms and you keep

1122
01:18:06,340 --> 01:18:10,400
doing this until at the end you start to focus on what you believe to

1123
01:18:10,400 --> 01:18:11,630
be the best

1124
01:18:11,650 --> 01:18:13,610
and then you keep playing the best

1125
01:18:13,610 --> 01:18:17,030
the hope is that if you figure out the best in very quickly

1126
01:18:17,030 --> 01:18:19,820
then you'll get a lot of rewards in the long run

1127
01:18:20,430 --> 01:18:23,570
essentially what bandit algorithms try to do is

1128
01:18:23,570 --> 01:18:25,280
try to to estimate the

1129
01:18:25,300 --> 01:18:27,470
probabilities px

1130
01:18:27,490 --> 01:18:31,570
but then you want to bias this estimation process towards the fact that with the

1131
01:18:32,700 --> 01:18:36,550
if i know that someone is not so good a low price of probability i

1132
01:18:36,550 --> 01:18:39,200
don't really need to estimate is very

1133
01:18:39,490 --> 01:18:40,470
great big

1134
01:18:40,490 --> 01:18:43,340
i just need to focus on the best need to figure out which one is

1135
01:18:43,340 --> 01:18:44,430
the best

1136
01:18:44,450 --> 01:18:50,280
and an algorithm actually sequentially pose content placed converge on the best is what's called

1137
01:18:50,280 --> 01:18:52,220
a bandit policy

1138
01:18:52,240 --> 01:18:55,280
now obviously can have many different bandit policies

1139
01:18:55,340 --> 01:18:56,740
it's funny how they

1140
01:18:56,780 --> 01:18:58,510
choose to pay on sequential

1141
01:18:58,530 --> 01:19:03,110
the way to compare different policies is via something called the degree of policy

1142
01:19:03,130 --> 01:19:07,570
so the regret is essentially how much extra payoff would i have to see if

1143
01:19:07,570 --> 01:19:10,470
i knew the payoff probabilities from the very beginning

1144
01:19:10,470 --> 01:19:15,200
so in some sense the degree is the price and playing for having to explore

1145
01:19:15,220 --> 01:19:19,610
the payoffs instead of if i had known the payoffs for the best of all

1146
01:19:19,630 --> 01:19:21,130
the time

1147
01:19:21,190 --> 01:19:22,320
and learning

1148
01:19:22,340 --> 01:19:26,860
implies that the policy was caught it was converging on the best and very quickly

1149
01:19:26,880 --> 01:19:29,320
and this is the sort of policy we need

1150
01:19:29,400 --> 01:19:30,400
so now

1151
01:19:30,420 --> 01:19:35,220
the obvious next question is what is the optimal policy

1152
01:19:35,240 --> 01:19:36,780
the optimal policy

1153
01:19:36,800 --> 01:19:38,380
we can see something small

1154
01:19:38,400 --> 01:19:43,030
obviously it cannot just for whatever one things is the best and right now

1155
01:19:43,030 --> 01:19:45,820
because the best and right now might have

1156
01:19:45,820 --> 01:19:51,490
given success just you know some statistical fluctuations in keep playing it forever

1157
01:19:51,490 --> 01:19:53,920
it might actually does a fairly poor

1158
01:19:53,930 --> 01:19:55,690
so it would seem that

1159
01:19:55,700 --> 01:20:00,110
in fact even like this time it becomes a dynamic programming things on the full

1160
01:20:00,110 --> 01:20:05,510
on ferry huge markov chain where the state of the that each state in the

1161
01:20:05,510 --> 01:20:11,170
markov process essentially encodes all the success and all the failures of all the arms

1162
01:20:11,170 --> 01:20:16,150
it becomes this huge markov chain which is obviously almost impossible

1163
01:20:17,420 --> 01:20:19,430
very nice thing is that

1164
01:20:19,450 --> 01:20:22,090
in a seminal paper people in

1165
01:20:22,110 --> 01:20:27,070
the late nineteen seventies gibbons showed that you don't really need to solve this entire

1166
01:20:27,070 --> 01:20:28,380
huge markov chain

1167
01:20:28,400 --> 01:20:29,950
what you can do with that

1168
01:20:29,970 --> 01:20:31,420
the optimal policy

1169
01:20:31,450 --> 01:20:34,950
for any given band can actually be decoupled into

1170
01:20:34,990 --> 01:20:40,090
certain policies for each of those arms independent so what is said is that i

1171
01:20:40,090 --> 01:20:41,510
can build up a markov chain

1172
01:20:41,650 --> 01:20:43,070
for each part

1173
01:20:43,090 --> 01:20:48,780
independently of all the other ips so looking at one compete i compute something called

1174
01:20:48,780 --> 01:20:51,740
the priority function for this particular

1175
01:20:51,760 --> 01:20:56,180
looking at just this time in isolation and then a computer program for all the

1176
01:20:56,900 --> 01:21:00,360
i began which is the highest priority and please

1177
01:21:00,380 --> 01:21:02,300
and that's all i need to do this

1178
01:21:02,320 --> 01:21:04,590
becomes the optimal policy

1179
01:21:04,610 --> 01:21:08,700
and what this is doing is it significantly reducing the state space that i have

1180
01:21:08,700 --> 01:21:11,170
is convex

1181
01:21:11,220 --> 01:21:15,420
and while this the main caplthy theta is convex

1182
01:21:15,600 --> 01:21:17,360
so i can just go

1183
01:21:17,400 --> 01:21:19,190
and compute the

1184
01:21:19,220 --> 01:21:20,840
painkillers on the dual

1185
01:21:20,850 --> 01:21:22,340
of this convex function

1186
01:21:22,350 --> 01:21:25,430
this algebraic manipulation i can do that

1187
01:21:25,480 --> 01:21:30,230
basically what it does is

1188
01:21:31,020 --> 01:21:34,950
that's what it turns out to be the case that this is the negative entropy

1189
01:21:35,000 --> 01:21:37,030
it's quite nice connection

1190
01:21:37,080 --> 01:21:40,730
so i will show this in a moment

1191
01:21:40,730 --> 01:21:42,610
but for the moment this is just

1192
01:21:42,620 --> 01:21:44,000
the soup

1193
01:21:44,010 --> 01:21:46,290
overall theta such that

1194
01:21:46,360 --> 01:21:50,310
this expression is maximized what you will end up doing is well let's just take

1195
01:21:50,310 --> 01:21:54,180
the derivative with respect to say to so we get a new one is the

1196
01:21:54,180 --> 01:21:57,230
seat of geophysical zero so what we get

1197
01:21:57,290 --> 01:22:02,240
is mu r equals the theta chi of data so we're just mapping from

1198
01:22:02,250 --> 01:22:05,330
data which is the natural parameter to the corresponding

1199
01:22:05,350 --> 01:22:08,970
i mean parameter

1200
01:22:19,280 --> 01:22:24,580
there's a lot more that you can do with this machinery then just this small

1201
01:22:41,400 --> 01:22:44,230
in fact g star

1202
01:22:44,240 --> 01:22:46,030
of mu

1203
01:22:46,040 --> 01:22:46,940
to be

1204
01:22:46,940 --> 01:22:51,270
soup other

1205
01:22:51,320 --> 01:22:53,060
they tend this

1206
01:22:53,080 --> 01:22:54,530
happens theta

1207
01:22:54,650 --> 01:23:02,130
the don't theta minus gl and this is optimized for

1208
01:23:02,150 --> 01:23:04,540
well mu r equals

1209
01:23:04,550 --> 01:23:05,750
d theta

1210
01:23:05,930 --> 01:23:10,500
g of data which we know is the expected value

1211
01:23:10,520 --> 01:23:13,020
up y x

1212
01:23:15,330 --> 01:23:17,980
so therefore

1213
01:23:18,030 --> 01:23:19,850
i will get

1214
01:23:22,720 --> 01:23:24,040
well later

1215
01:23:26,900 --> 01:23:30,640
the state tree

1216
01:23:30,690 --> 01:23:33,470
of data

1217
01:23:33,480 --> 01:23:35,400
function set

1218
01:23:35,420 --> 01:23:37,650
functional inverse

1219
01:23:37,800 --> 01:23:47,170
so then what i get is that this expression here

1220
01:23:47,180 --> 01:23:50,070
is inappropriate to a new

1221
01:23:51,790 --> 01:23:53,930
as state of new

1222
01:23:56,460 --> 01:23:57,630
of data

1223
01:23:58,510 --> 01:24:05,520
now it turns out

1224
01:24:05,540 --> 01:24:06,780
but this is

1225
01:24:06,790 --> 01:24:11,000
this leads us to the following

1226
01:24:11,010 --> 01:24:14,290
well the negative log

1227
01:24:14,320 --> 01:24:15,730
probability of fix

1228
01:24:15,730 --> 01:24:17,340
prentice by theta

1229
01:24:17,650 --> 01:24:18,940
tom speer

1230
01:24:18,980 --> 01:24:22,690
given theta d theta so that seem to be quite very definition

1231
01:24:25,520 --> 01:24:28,730
right out

1232
01:24:28,750 --> 01:24:31,760
it's the integral

1233
01:24:33,200 --> 01:24:35,760
express by theta all

1234
01:24:35,820 --> 01:24:39,740
now the inner product between fall thinks data

1235
01:24:39,740 --> 01:24:42,990
one you

1236
01:24:47,080 --> 01:24:50,380
now this will give us

1237
01:24:51,630 --> 01:24:53,820
mu of slater

1238
01:24:53,840 --> 01:24:57,060
has its expected value of topics

1239
01:24:57,070 --> 01:25:00,980
this remains the same remains the same so it gives us

1240
01:25:00,980 --> 01:25:02,310
in the process of

1241
01:25:02,380 --> 01:25:04,150
mu of data

1242
01:25:05,490 --> 01:25:06,580
one is

1243
01:25:06,610 --> 01:25:08,950
g state

1244
01:25:08,960 --> 01:25:13,770
i could also write this as the inner product between

1245
01:25:13,790 --> 01:25:17,170
mu theta of new

1246
01:25:17,340 --> 01:25:19,190
one is g

1247
01:25:19,200 --> 01:25:20,280
of data

1248
01:25:23,710 --> 01:25:24,920
and that's

1249
01:25:24,960 --> 01:25:26,560
exactly what we have appear

1250
01:25:26,690 --> 01:25:31,490
so what i'm getting is that

1251
01:25:31,500 --> 01:25:33,550
the entropy

1252
01:25:34,330 --> 01:25:39,200
the negative of the convex dual of the log partition function

1253
01:25:39,260 --> 01:25:46,310
so far that's just curious observation but actually want to make use of that now

1254
01:25:46,790 --> 01:25:49,800
the way that exploit this is

1255
01:25:51,590 --> 01:25:54,040
well first of all you can notice that

1256
01:25:54,090 --> 01:25:58,190
if idealise back again them by strong duality

1257
01:25:58,230 --> 01:26:01,210
i get back my log partition function so this is the function it may be

1258
01:26:01,210 --> 01:26:02,800
hard to compute

1259
01:26:02,830 --> 01:26:05,210
by taking the convex dual

1260
01:26:05,480 --> 01:26:07,620
overall marginals in the

1261
01:26:07,650 --> 01:26:09,650
corresponding marginal polytope

1262
01:26:09,680 --> 01:26:17,690
well into inappropriate between theta mu plus the entropy corresponding to the marginals

1263
01:26:17,740 --> 01:26:21,940
so basically this is like g double star of data

1264
01:26:21,950 --> 01:26:24,690
if g stop is of data

1265
01:26:24,710 --> 01:26:28,620
all i've done is i've taken the log partition function which is

1266
01:26:28,640 --> 01:26:31,460
which may be a pain to compute

1267
01:26:31,460 --> 01:26:33,180
i have gone to the dual

1268
01:26:33,190 --> 01:26:35,040
which i know is the entropy

1269
01:26:35,170 --> 01:26:38,020
and actualized back again

1270
01:26:38,800 --> 01:26:41,830
so far it doesn't look like going anything

1271
01:26:41,840 --> 01:26:45,670
but actually gained a lot of insight on how i can now approximate things

1272
01:26:45,930 --> 01:26:53,330
and the two approximations that wainwright and jordan made all the following

1273
01:26:53,380 --> 01:26:54,880
first of all

1274
01:26:54,890 --> 01:26:56,560
i might have an upper bound

1275
01:26:56,570 --> 01:27:00,240
on the on the entropy

1276
01:27:00,240 --> 01:27:03,610
so for instance if i have a random variables with a given covariance

1277
01:27:03,630 --> 01:27:06,010
i know that the normal distribution

1278
01:27:06,020 --> 01:27:06,940
it is

1279
01:27:07,110 --> 01:27:11,900
the distribution with the largest entropy for a given covariance structure

1280
01:27:12,830 --> 01:27:14,370
if i plug in

1281
01:27:15,110 --> 01:27:18,980
entropy that i get from a normal distribution with the given covariance this will be

1282
01:27:18,980 --> 01:27:20,250
box here

1283
01:27:20,250 --> 01:27:23,740
so the colour mismatch apologies for that and we divided by the total number of

1284
01:27:23,740 --> 01:27:27,810
crosses and taking the limit as n goes to infinity that's actually frequentist definition of

1285
01:27:27,810 --> 01:27:30,770
probability so that's a very

1286
01:27:30,820 --> 01:27:33,050
probably the most people have seen before

1287
01:27:34,360 --> 01:27:38,210
it's an interesting one because of course never really does go to infinity but

1288
01:27:38,230 --> 01:27:43,190
i will be happy with that definition for the marginal will be

1289
01:27:44,270 --> 01:27:49,680
the model for axes this box here a really bad got colours mismatching sorry so

1290
01:27:50,130 --> 01:27:55,670
blue boxes the limit as we sample the ones in that both as goes to

1291
01:27:56,850 --> 01:27:58,230
and the conditional

1292
01:27:58,250 --> 01:28:01,250
will be looking at one of these boxes here

1293
01:28:01,260 --> 01:28:03,900
s equals x three and y equals for

1294
01:28:03,930 --> 01:28:07,120
and then dividing by the one in another box

1295
01:28:07,890 --> 01:28:13,810
four y equals forces divided divided by all the totally dividing the ones that give

1296
01:28:13,940 --> 01:28:17,570
so the nice thing about the little definitions and i think this is something that

1297
01:28:17,570 --> 01:28:20,440
i first saw or when

1298
01:28:20,460 --> 01:28:24,600
i was asked in nineteen ninety six and chris bishop use this way of introducing

1299
01:28:24,600 --> 01:28:28,580
probability wasn't it's possible but i think it's second actually to do it this way

1300
01:28:28,580 --> 01:28:32,930
i haven't read the second but i think i saw in everything

1301
01:28:32,940 --> 01:28:38,000
so it might have introducing all these different things because you can introduce the rules

1302
01:28:38,000 --> 01:28:40,450
of probability from it so as i said before

1303
01:28:40,460 --> 01:28:42,630
typically we should write out the full

1304
01:28:42,680 --> 01:28:46,400
definition of the probability right we should be clear we should be saying

1305
01:28:46,450 --> 01:28:50,110
x is equal into little x and y is equally little one but in practice

1306
01:28:50,110 --> 01:28:56,110
we often use this little shortcut and the implication is somehow dismissing complex equals but

1307
01:28:56,110 --> 01:28:59,430
that has this effect so this looks very much like we might write a multivariate

1308
01:28:59,430 --> 01:29:04,370
function f of x from y is equal to one the cause x ex-con wife

1309
01:29:04,370 --> 01:29:10,790
of x white noise y come in probability is that it's true because of that

1310
01:29:11,000 --> 01:29:12,320
the saddle point

1311
01:29:13,190 --> 01:29:19,210
it caused to be argument wants the post-doc so to current

1312
01:29:19,250 --> 01:29:20,450
i think he did

1313
01:29:20,480 --> 01:29:24,270
i realize that because he was a mathematician so i was thinking of that he

1314
01:29:24,270 --> 01:29:25,500
didn't believe in that

1315
01:29:25,510 --> 01:29:27,110
i had to explain it

1316
01:29:28,140 --> 01:29:29,770
OK so

1317
01:29:29,790 --> 01:29:33,830
all distributions are normalized and that can be easily seen from the definition seen before

1318
01:29:33,830 --> 01:29:37,510
by summing over one of these models is just the sum of all the things

1319
01:29:37,510 --> 01:29:41,250
in that marginal divided by the total which is equal to one

1320
01:29:41,250 --> 01:29:46,750
and modernization is really important property of probabilities because it has effects has effects maximum

1321
01:29:46,750 --> 01:29:48,860
likelihood when you when you push on

1322
01:29:48,880 --> 01:29:54,060
the likelihood one region because the distributions normalized it must be suppressed in other regions

1323
01:29:54,060 --> 01:29:57,810
it goes down elsewhere so it's like a it's like a sort of tents you

1324
01:29:57,810 --> 01:30:01,270
know when you if you want your probability go up here

1325
01:30:01,300 --> 01:30:05,520
your edits attention is paid down then it will go down somewhere else if you

1326
01:30:05,520 --> 01:30:09,580
live tip over ten other possibly go down and so that's sort of important property

1327
01:30:09,580 --> 01:30:13,880
the tent has a certain fixed volume and the probability case as you move it

1328
01:30:13,890 --> 01:30:16,650
up and down in moscow down elsewhere

1329
01:30:16,670 --> 01:30:18,880
that's very important

1330
01:30:18,940 --> 01:30:22,420
the marginal probabilities the summing across

1331
01:30:22,430 --> 01:30:26,190
all the axes you should know that the sum rule of probability

1332
01:30:26,200 --> 01:30:30,250
and this is probably one of the biggest painter experience it looks so innocent

1333
01:30:30,260 --> 01:30:34,150
but in practice when we're looking at very large state spaces

1334
01:30:34,170 --> 01:30:37,510
doing these sums can be very very hard exploring

1335
01:30:37,540 --> 01:30:39,390
a large state space

1336
01:30:39,730 --> 01:30:43,120
this is the one of the hardest things to deal with in probability says the

1337
01:30:43,120 --> 01:30:47,110
some probability and then the product rule of probability

1338
01:30:47,120 --> 01:30:53,010
it is relating the joint distribution to the conditional distributions probability vector y times probability

1339
01:30:53,010 --> 01:30:55,170
y is equal to the probability of

1340
01:30:55,240 --> 01:31:00,300
x and y and that can all be seen just by going through those definitions

1341
01:31:00,330 --> 01:31:02,520
now the nice thing

1342
01:31:03,430 --> 01:31:08,640
the simple definitions also leads to something that some people think it's controversial

1343
01:31:08,690 --> 01:31:11,330
and one of the point of introducing in that way you can see this is

1344
01:31:11,330 --> 01:31:13,610
completely non-controversial

1345
01:31:13,620 --> 01:31:16,270
bayes rule is not controversial

1346
01:31:16,300 --> 01:31:19,520
it is true

1347
01:31:19,620 --> 01:31:23,980
if you want to write probability this is the way to do it

1348
01:31:24,820 --> 01:31:29,330
you can equate the joint probabilities in this way politifact com y is equal to

1349
01:31:29,360 --> 01:31:31,090
probability of white-collar x

1350
01:31:31,130 --> 01:31:36,450
probability why correct time is equal to appear like given x compared accent

1351
01:31:36,460 --> 01:31:40,460
so we can write this basically and then you just dividing time that side and

1352
01:31:40,460 --> 01:31:41,850
you get this ability

1353
01:31:41,870 --> 01:31:43,950
to inv

1354
01:31:43,960 --> 01:31:46,360
the probability go from this probably why

1355
01:31:46,380 --> 01:31:49,150
given x the probability of x given y and that's important

1356
01:31:49,170 --> 01:31:51,900
now basically right about it and

1357
01:31:51,910 --> 01:31:55,140
i tried to read the paper the introduction is really clear it's written by someone

1358
01:31:55,140 --> 01:31:56,770
else called enterprise

1359
01:31:56,820 --> 01:31:58,500
and it looks really clear

1360
01:31:58,520 --> 01:32:02,700
and most of what you get from the papers from and then reading actual paper

1361
01:32:02,700 --> 01:32:05,130
is not very clear

1362
01:32:05,140 --> 01:32:06,590
read the plastic

1363
01:32:07,300 --> 01:32:11,150
his i can't remember the name of the actual paper where he affection he doesn't

1364
01:32:11,820 --> 01:32:14,950
bayes rule but he does a lot more interesting stuff with it and i think

1365
01:32:15,040 --> 01:32:20,380
a as a british pains me to say but plastics far more interesting than bayes

1366
01:32:20,390 --> 01:32:21,450
and he

1367
01:32:21,460 --> 01:32:24,800
there's an enormous amount of work on on using this rule

1368
01:32:24,860 --> 01:32:30,480
well i have not explicitly saying what the rule is many post states

1369
01:32:30,490 --> 01:32:33,880
the poster is based thing which is why people credit based but i think if

1370
01:32:33,880 --> 01:32:36,390
your friends you can be might be proud of the class

1371
01:32:36,400 --> 01:32:40,790
it seems to me is a little bit depressing the red class because i realized

1372
01:32:40,790 --> 01:32:42,380
that my entire

1373
01:32:42,400 --> 01:32:46,960
research career was already envisaged by the last two hundred years ago

1374
01:32:47,090 --> 01:32:49,920
and it was only through lack of having a computer

1375
01:32:49,950 --> 01:32:51,990
that he didn't do

1376
01:32:52,010 --> 01:32:55,950
the sort of things that we do but basically he worked out approximations for doing

1377
01:32:55,950 --> 01:33:01,170
bayesian inference he worked out to error functions fitting models to data

1378
01:33:01,350 --> 01:33:04,500
astronomical models to data

1379
01:33:04,510 --> 01:33:05,550
and he also

1380
01:33:05,580 --> 01:33:09,260
it was first interested in the example he looks and this is biased coins he

1381
01:33:09,260 --> 01:33:13,690
so all these numbers represented by a square white

1382
01:33:13,710 --> 01:33:16,690
white squares i mean it they all add up to one

1383
01:33:16,690 --> 01:33:19,520
so are what you're feeling this too

1384
01:33:19,530 --> 01:33:24,050
independent who says they are

1385
01:33:24,140 --> 01:33:30,670
could you write this SP of xm still y

1386
01:33:32,410 --> 01:33:34,780
the question is if

1387
01:33:34,830 --> 01:33:37,260
if x and y are

1388
01:33:37,300 --> 01:33:40,150
what they are meaning a pick x

1389
01:33:40,150 --> 01:33:44,210
x is any letter in my links manual text and y is the latter that

1390
01:33:44,210 --> 01:33:46,280
goes right after that

1391
01:33:46,300 --> 01:33:49,460
and i now believe the joint probability

1392
01:33:49,470 --> 01:33:55,180
distribution for these two things right so i say followed by a has some some

1393
01:33:55,180 --> 01:33:57,450
probability now now

1394
01:33:58,450 --> 01:34:00,200
followed by c

1395
01:34:00,210 --> 01:34:01,940
not so much

1396
01:34:10,760 --> 01:34:11,800
fair enough

1397
01:34:11,940 --> 01:34:13,720
so do you think there's any language

1398
01:34:13,800 --> 01:34:15,370
in which

1399
01:34:15,410 --> 01:34:17,170
in which

1400
01:34:17,220 --> 01:34:21,180
i could sort of factorizes thing in which i could write p of that in

1401
01:34:21,180 --> 01:34:24,150
which i could write the joint p of x come y as p of x

1402
01:34:24,150 --> 01:34:26,270
times p of y so

1403
01:34:30,770 --> 01:34:36,300
the thing is this constraints because although there are some languages

1404
01:34:36,340 --> 01:34:38,230
i i think i saw

1405
01:34:38,280 --> 01:34:45,010
people from slovenia here somewhere who is from slovenia

1406
01:34:45,120 --> 01:34:48,850
how you have more

1407
01:34:48,860 --> 01:34:52,560
consonants one after another than we have in spanish for example

1408
01:34:52,620 --> 01:34:54,410
so in spanish

1409
01:34:54,460 --> 01:34:57,550
if you have two consonants one after another that's already a lot

1410
01:34:57,600 --> 01:34:59,580
you never have three as far as i know

1411
01:34:59,590 --> 01:35:04,200
maybe someone correct me three maybe but anyway so so so you know that after

1412
01:35:05,750 --> 01:35:08,800
you know if you already have seen the consonant then it's more likely that you're

1413
01:35:08,800 --> 01:35:12,520
going to see vowel than other consonant it's in spanish

1414
01:35:12,540 --> 01:35:14,900
all right in english as well

1415
01:35:14,930 --> 01:35:18,450
so they are not independent because it's the latter that follows

1416
01:35:18,470 --> 01:35:22,270
so why is really the letter that comes after all right now if you if

1417
01:35:22,270 --> 01:35:25,210
you had some text i didn't make any sense some sort of random bag of

1418
01:35:25,210 --> 01:35:27,300
of of letters any organised in anyway

1419
01:35:27,310 --> 01:35:29,550
then yes then you could actually factor

1420
01:35:29,560 --> 01:35:33,190
so if they were independent how would this matrix look like

1421
01:35:33,190 --> 01:35:36,150
well i put it to you that he would be symmetric

1422
01:35:36,360 --> 01:35:40,670
so why why would it be symmetric

1423
01:35:40,680 --> 01:35:43,300
how would you believe what i just told you they would be p of x

1424
01:35:43,300 --> 01:35:44,350
times of y

1425
01:35:44,450 --> 01:35:47,720
and so it would be it would really be like the multiplication of a column

1426
01:35:49,450 --> 01:35:50,700
by a row vector

1427
01:35:52,970 --> 01:35:56,720
and this thing is symmetric OK

1428
01:35:56,770 --> 01:35:58,930
but here it is not symmetric

1429
01:35:58,940 --> 01:36:01,210
however what i can do

1430
01:36:01,280 --> 01:36:04,920
is i can actually recover the marginal that i had earlier so

1431
01:36:05,090 --> 01:36:06,410
here we only had

1432
01:36:06,450 --> 01:36:07,370
a single

1433
01:36:07,380 --> 01:36:09,980
column here OK we were only looking at letters

1434
01:36:10,000 --> 01:36:13,860
i could recover that in two different ways from here i could either

1435
01:36:13,870 --> 01:36:15,340
i up

1436
01:36:15,360 --> 01:36:18,700
in the rows or i could add up in the columns and i recover OK

1437
01:36:18,910 --> 01:36:20,790
and that's the marginalisation

1438
01:36:23,790 --> 01:36:31,550
all right so now we're going to do a practical exercise

1439
01:36:31,620 --> 01:36:33,050
it's always

1440
01:36:33,100 --> 01:36:37,980
i've been having meaning to figure different exercise four four one because it's it's always

1441
01:36:38,180 --> 01:36:42,360
an unpleasant one to to give exercises about cancer but since isabelle has mentioned the

1442
01:36:42,360 --> 01:36:47,100
word counts for five times in her lecture now i feel is bad about

1443
01:36:47,160 --> 01:36:53,420
OK so there's little little little exercise i i give you this this actually the

1444
01:36:53,420 --> 01:36:58,510
interesting thing about this exercise it's based on the real world study about how doctors

1445
01:36:58,530 --> 01:37:00,450
i understand probabilities

1446
01:37:01,050 --> 01:37:04,810
so let's see what you think and that tell you what the doctors that

1447
01:37:04,850 --> 01:37:08,210
so the first thing is a you some facts i give you this following three

1448
01:37:08,210 --> 01:37:11,900
facts the first factor is

1449
01:37:11,920 --> 01:37:12,960
one percent

1450
01:37:12,980 --> 01:37:15,950
of of of women that gets scanned

1451
01:37:15,990 --> 01:37:19,830
actually do have breast cancer OK

1452
01:37:19,870 --> 01:37:20,950
second fact

1453
01:37:22,850 --> 01:37:27,020
that person has breast cancer

1454
01:37:28,390 --> 01:37:33,520
then the mammography will turn out positive with eighty percent chance

1455
01:37:33,540 --> 01:37:36,270
OK now the third factor give you is

1456
01:37:36,280 --> 01:37:39,320
that nine point six percent of

1457
01:37:39,360 --> 01:37:41,770
completely healthy patients that do not have

1458
01:37:41,790 --> 01:37:42,950
breast cancer

1459
01:37:42,990 --> 01:37:45,940
actually also get a positive mammography right

1460
01:37:45,980 --> 01:37:46,990
so this would be

1461
01:37:47,000 --> 01:37:50,630
the probability of detection and this would be the probability of false alarm or you

1462
01:37:50,640 --> 01:37:54,170
for those of you who are used to that kind of stuff

1463
01:37:54,200 --> 01:37:59,370
another question i ask you is

1464
01:37:59,380 --> 01:38:00,240
a woman

1465
01:38:00,260 --> 01:38:04,500
actually has a positive mammography positive in this in this context

1466
01:38:04,530 --> 01:38:07,110
is not very positive or very means

1467
01:38:07,150 --> 01:38:09,450
the red light goes on

1468
01:38:09,520 --> 01:38:14,800
so what is the probability that she has breast cancer

1469
01:38:14,810 --> 01:38:17,050
and understand the question

1470
01:38:17,140 --> 01:38:19,870
go to the doctor you get the bad news OK

1471
01:38:21,220 --> 01:38:23,470
bad exactly are those news

1472
01:38:23,520 --> 01:38:27,600
in the light of the of the data

1473
01:38:27,640 --> 01:38:32,930
so now i know i have sort of

1474
01:38:32,930 --> 01:38:37,750
let so doctor wouldn't sit down and write probabilities OK

1475
01:38:37,780 --> 01:38:43,080
so i doctor we just use his or her gut feeling so let's see

1476
01:38:43,080 --> 01:38:45,550
who of you thinks that is going to turn out to be less than one

1477
01:38:48,450 --> 01:38:50,150
OK we have three people

1478
01:38:50,180 --> 01:38:53,560
performers who of you things that is going to be somewhere between one percent and

1479
01:38:53,560 --> 01:38:55,930
seventy percent

1480
01:38:56,010 --> 01:38:58,150
about five or six people

1481
01:38:58,150 --> 01:39:04,410
we have this skewed degree distributions like that then the expression that is used is

1482
01:39:04,410 --> 01:39:08,950
called scale free networks than any other

1483
01:39:08,960 --> 01:39:11,570
o experiment

1484
01:39:11,580 --> 01:39:14,300
OK so this is just just

1485
01:39:14,320 --> 01:39:19,280
of land and then also some temporal patterns so what i want to say here

1486
01:39:19,280 --> 01:39:20,460
is that was this

1487
01:39:20,460 --> 01:39:25,590
which is actually quite fascinating that was this experiment but by nineteen sixties where he

1488
01:39:25,630 --> 01:39:30,110
asked people in nebraska to the to the following right so he he asked people

1489
01:39:30,400 --> 01:39:34,350
to send letters to some stock brokers in boston right and all these people knew

1490
01:39:34,350 --> 01:39:39,270
was the name of the person and they were a stockbroker and they were asked

1491
01:39:39,280 --> 01:39:44,230
to send to send letters to the like immediate friends and the what he was

1492
01:39:44,230 --> 01:39:48,100
measured is how how long how many hops does it take for the letter to

1493
01:39:48,100 --> 01:39:50,210
arrive to particular broker

1494
01:39:50,260 --> 01:39:54,780
right and it did not like twenty five percent of the letters that were initially

1495
01:39:54,780 --> 01:39:57,040
sent reach the goal but they

1496
01:39:57,070 --> 01:40:01,490
but the important part is that the each in about six steps right

1497
01:40:01,540 --> 01:40:03,420
so it means that

1498
01:40:03,440 --> 01:40:07,920
a random person nebraska can send the letter and the person in boston in about

1499
01:40:07,920 --> 01:40:09,350
six hops

1500
01:40:09,400 --> 01:40:13,220
which has implications for the businesses in the networks of small and the other one

1501
01:40:13,220 --> 01:40:17,450
is that the humans are able to find OK and hot what do we mean

1502
01:40:17,450 --> 01:40:22,240
by distances in the networks so this is usually captured by the diameter

1503
01:40:24,190 --> 01:40:28,910
so diameter is defined as like maximum so if the idea is the shortest path

1504
01:40:29,140 --> 01:40:33,460
the length of the shortest path between iron nodes i and j then just the

1505
01:40:33,460 --> 01:40:39,280
maximum order then sees this is like very noisy measure right you what usually do

1506
01:40:39,280 --> 01:40:43,540
is they call about the talk about effective diameter which is like just the nineteen

1507
01:40:43,550 --> 01:40:49,880
percentile of the diameter or you can i get great like average shortest path distance

1508
01:40:49,880 --> 01:40:52,670
right so i just go here over all pairs of path

1509
01:40:52,720 --> 01:40:57,100
and i i normalize appropriate for the other one

1510
01:40:57,130 --> 01:40:58,740
OK won't go into detail

1511
01:40:59,200 --> 01:41:03,570
and for example here here is what you get right so here we have

1512
01:41:03,580 --> 01:41:08,080
microsoft messenger network right so we have a hundred and eighty million people talking to

1513
01:41:08,080 --> 01:41:11,460
each other over a period of four months and we have one one point three

1514
01:41:11,460 --> 01:41:14,660
billion edges right so we have pretty much the whole world and there is an

1515
01:41:14,660 --> 01:41:19,670
edge if two people exchanged if people were engaged in conversations at least once in

1516
01:41:19,670 --> 01:41:24,540
this one month period right and if i can plot the distance and the number

1517
01:41:24,540 --> 01:41:30,150
of number of pairs of nodes at that distance you can see that the motive

1518
01:41:30,160 --> 01:41:32,910
distribution is at seven by this means

1519
01:41:32,940 --> 01:41:38,890
most of the network is reachable within seven hot and this is log scale

1520
01:41:39,490 --> 01:41:42,000
if this would be like one hundred million

1521
01:41:42,050 --> 01:41:45,130
o thirty then no here ten million

1522
01:41:45,220 --> 01:41:46,680
right so this is like now

1523
01:41:46,700 --> 01:41:50,290
almost hundred million people have the right to more than half of the network can

1524
01:41:50,290 --> 01:41:52,100
be reached in

1525
01:41:52,120 --> 01:41:57,480
in semi at least seven hops and this says the diameter is small

1526
01:41:57,490 --> 01:42:02,740
so the other properties degree distributions that people talk a lot about and this is

1527
01:42:02,740 --> 01:42:07,500
basically so this is what we mean that so we take to denote like the

1528
01:42:07,500 --> 01:42:10,070
fraction of nodes that have degree k

1529
01:42:10,110 --> 01:42:12,740
right and then you can just block the histogram of

1530
01:42:12,750 --> 01:42:15,990
probability of observing could nobody with degree k

1531
01:42:16,000 --> 01:42:17,790
right and

1532
01:42:17,840 --> 01:42:23,630
what what would like what one would maybe we expect to see something like this

1533
01:42:23,630 --> 01:42:27,230
right if we would expect that there is some need to this distribution in the

1534
01:42:27,290 --> 01:42:30,980
we would sail on average person has their friends and then somehow the class and

1535
01:42:30,980 --> 01:42:34,580
some have a bit more about that is when feel like there is an average

1536
01:42:34,580 --> 01:42:38,130
of that is the most to the distribution what happens is that it's

1537
01:42:38,160 --> 01:42:43,840
more like that so it's cute it's skewed towards towards towards the right

1538
01:42:43,860 --> 01:42:45,100
OK and

1539
01:42:45,110 --> 01:42:49,960
they called this types of distributions like heavy along the institutions and there are many

1540
01:42:50,500 --> 01:42:56,160
quantities in the real world that follow these types of distributions for example the amazon

1541
01:42:56,160 --> 01:43:01,390
sales for the world land distribution follows OK and to be even more precise

1542
01:43:01,420 --> 01:43:06,140
so we said it's it's cute but

1543
01:43:06,190 --> 01:43:10,880
what is even more importantly the is that the data does not decay exponentially but

1544
01:43:11,020 --> 01:43:14,390
with it because of the power so what i mean is that

1545
01:43:14,880 --> 01:43:20,290
the probability of observing a degree of node degree k schemes like the minors house

1546
01:43:20,290 --> 01:43:22,260
where i face some

1547
01:43:22,260 --> 01:43:24,160
IQ matters

1548
01:43:24,160 --> 01:43:29,460
more particularly IQ matters for social achievement for prestigious positions and for on the job

1549
01:43:29,460 --> 01:43:34,230
performance and other work related variables of i know your IQ score

1550
01:43:34,280 --> 01:43:36,830
i know something about you that matters

1551
01:43:36,840 --> 01:43:38,330
it's not irrelevant

1552
01:43:38,350 --> 01:43:43,320
just as if i know your score on a personality test big five i would

1553
01:43:43,320 --> 01:43:47,710
know something about you that would tell me something interesting about you in the real

1554
01:43:48,910 --> 01:43:56,300
on the other hand there's a lot of controversy about why this connection exists on

1555
01:43:56,330 --> 01:44:01,340
so to some extent people have worried that the effectiveness of IQ

1556
01:44:01,400 --> 01:44:03,890
is a self-fulfilling prophecy

1557
01:44:03,930 --> 01:44:07,020
and here's why

1558
01:44:07,080 --> 01:44:13,640
if society takes IQ tests important seriously they become important

1559
01:44:13,640 --> 01:44:16,200
so it's true they are IQ

1560
01:44:16,220 --> 01:44:21,900
is very related to your success in getting into a good school like yale

1561
01:44:21,920 --> 01:44:26,010
but the reason for this in large extent is because they get to yale to

1562
01:44:26,020 --> 01:44:29,280
give you an IQ test this stating

1563
01:44:30,210 --> 01:44:35,240
the same for graduate school gehry which is yet another IQ test

1564
01:44:35,250 --> 01:44:38,280
so to some extent is a self-fulfilling prophecy

1565
01:44:38,730 --> 01:44:39,900
i could make

1566
01:44:39,920 --> 01:44:45,300
society could choose to make how tall you are extremely important for educational success they

1567
01:44:45,300 --> 01:44:48,840
could say nobody under six feet tall gets into

1568
01:44:48,900 --> 01:44:53,080
and in some psychopaths would stand up and say of course height is profoundly related

1569
01:44:53,080 --> 01:44:57,670
to educational accomplishment and it would be because people made itself

1570
01:44:57,690 --> 01:45:03,060
so to some extent society that draws highly on IQ tests

1571
01:45:03,550 --> 01:45:10,190
regarding promotion educational educational achievement and military status and so on

1572
01:45:10,480 --> 01:45:15,210
it's just going of follow that IQ then becomes important

1573
01:45:15,210 --> 01:45:17,340
at the same time however

1574
01:45:17,370 --> 01:45:22,250
the role of IQ is pretty clearly not entirely a social construction

1575
01:45:22,270 --> 01:45:25,850
there is some evidence to your IQ score

1576
01:45:25,900 --> 01:45:32,240
you're related to intelligence and an interesting sense including domains like mental speed

1577
01:45:32,790 --> 01:45:35,670
o and memory span

1578
01:45:35,710 --> 01:45:39,790
so your your score an IQ test for instance is to some extent related to

1579
01:45:39,790 --> 01:45:42,470
how fast you to think and

1580
01:45:42,480 --> 01:45:46,610
your memory abilities

1581
01:45:46,640 --> 01:45:49,360
now i want to shift in the second half of the class

1582
01:45:49,390 --> 01:45:51,330
and talk about why

1583
01:45:51,350 --> 01:45:57,220
so we talked about two differences one person at one personality one intelligence

1584
01:45:57,220 --> 01:46:00,770
i want to talk about why people differ but before i do i do people

1585
01:46:00,770 --> 01:46:03,370
have any questions

1586
01:46:05,010 --> 01:46:09,870
this one

1587
01:46:25,210 --> 01:46:31,440
is also

1588
01:46:38,820 --> 01:46:40,750
so the question the question is

1589
01:46:40,790 --> 01:46:42,640
this young man took

1590
01:46:42,650 --> 01:46:47,250
took i just took a personality test he was he was accepted slithering

1591
01:46:47,280 --> 01:46:52,010
is a hogwarts reference i'm i'm hip to that

1592
01:46:52,860 --> 01:46:56,830
and that in the but the question is a good one

1593
01:46:56,840 --> 01:46:58,780
you're you're you're clever man

1594
01:47:00,420 --> 01:47:04,050
and if you wanted to be an slithering how do we know even worse the

1595
01:47:05,050 --> 01:47:08,850
i mean you know you got to get his personality tests all the time and

1596
01:47:08,860 --> 01:47:12,990
you an as you if you apply for business and one test is i like

1597
01:47:12,990 --> 01:47:15,390
to steal from my bosses

1598
01:47:15,390 --> 01:47:18,710
o thing so no that's the like you test right there

1599
01:47:19,470 --> 01:47:24,080
so the question is how do you avoid that problem on the test constructors have

1600
01:47:24,080 --> 01:47:26,950
done so in certain clever ways

1601
01:47:27,000 --> 01:47:30,450
instance are often catch questions

1602
01:47:30,460 --> 01:47:32,370
designed to capture life

1603
01:47:32,390 --> 01:47:36,330
some of these questions posed very unrealistic

1604
01:47:36,360 --> 01:47:40,710
phenomena so you might have a question in their saying

1605
01:47:41,940 --> 01:47:44,910
i have never done anything i'm ashamed of

1606
01:47:44,930 --> 01:47:47,750
now some people say yes that's true me

1607
01:47:47,770 --> 01:47:49,410
but they can be liars

1608
01:47:50,240 --> 01:47:56,510
unrealistic questions tend to catch liars also you get the same question as in different

1609
01:47:56,510 --> 01:48:00,760
ways across the hundred items and they could use the correlations to figure these things

1610
01:48:01,600 --> 01:48:04,430
i mean again the proof is sort of inputting

1611
01:48:04,440 --> 01:48:08,270
but the reliability and validity of the test

1612
01:48:09,490 --> 01:48:14,260
is determined in part by just how well it does at predicting your future performance

1613
01:48:14,260 --> 01:48:19,450
on the test in the real world performance on the test that is easily fooled

1614
01:48:19,450 --> 01:48:23,150
easily tricked by smart people

1615
01:48:23,160 --> 01:48:25,470
wouldn't survive long personality test

1616
01:48:25,480 --> 01:48:28,790
so we know that we know the test you've got is a pretty good test

1617
01:48:28,790 --> 01:48:32,750
because it seems to work for most people

1618
01:48:34,800 --> 01:48:43,650
it's a good question questions about emotional IQ which is something i matching to touch

1619
01:48:43,650 --> 01:48:47,820
upon little bit later in the course that people talk about different forms of intelligence

1620
01:48:47,850 --> 01:48:49,200
and emotional

1621
01:48:49,200 --> 01:48:58,590
intelligence social intelligence is is it can arguably a candidate for success across different domains

1622
01:48:58,650 --> 01:49:01,390
the evidence for predictive power

1623
01:49:01,410 --> 01:49:05,060
it is not as strong as for regular IQ tests

1624
01:49:05,080 --> 01:49:09,020
so you might be right it might turn out to be much better predictive but

1625
01:49:09,930 --> 01:49:13,540
it's not clear that we know that you peter saleh is actually done some very

1626
01:49:13,540 --> 01:49:18,410
interesting research on this is continuing work along those lines the second thing is emotional

1627
01:49:18,410 --> 01:49:21,870
intelligence actually related to good old old-fashioned intelligence

1628
01:49:21,930 --> 01:49:25,420
they kind of pull together a lot so it's not entirely separate

1629
01:49:25,430 --> 01:49:27,760
but that's a good point and i like to return to a little bit later

1630
01:49:28,340 --> 01:49:29,260
in the course

1631
01:49:41,780 --> 01:49:46,370
good question how do you determine wondered what good test

1632
01:49:46,390 --> 01:49:47,640
and again

1633
01:49:47,660 --> 01:49:51,180
it's a real are going through the details of how to do that but the

1634
01:49:51,180 --> 01:49:54,370
branches involved reliability and validity

1635
01:49:54,430 --> 01:49:56,720
it's good testify test you today

1636
01:49:56,720 --> 01:49:59,200
and it test you tomorrow i get the same score

1637
01:49:59,220 --> 01:50:02,870
it's a really good test if your score on that task

1638
01:50:02,890 --> 01:50:05,540
predicts your grades

1639
01:50:05,600 --> 01:50:12,490
are the personality test predicts how many girlfriends you are predicts whether people think you're

1640
01:50:12,490 --> 01:50:13,790
a nice guy

1641
01:50:13,790 --> 01:50:18,700
so you have to see both the replicability to test over time but also its

1642
01:50:18,700 --> 01:50:20,910
relationship to real world phenomena

1643
01:50:20,930 --> 01:50:25,270
and that's important again why we know the batman and wonder woman hope

1644
01:50:26,080 --> 01:50:29,310
it is about one one answer is

1645
01:50:30,450 --> 01:50:35,560
what what i what i how i scorn et test is about anything about me

1646
01:50:35,560 --> 01:50:38,790
is not going to relate to migrate is not going to write how long liked

1647
01:50:38,810 --> 01:50:47,160
how do we notice it is useful well actually corresponds with other things like great

1648
01:50:47,160 --> 01:50:49,440
at around the TV energy scale

1649
01:50:49,450 --> 01:50:51,530
that is just to see

1650
01:50:51,540 --> 01:50:52,640
he works

1651
01:50:52,660 --> 01:50:57,300
so that's the temperature and symmetry in the universe

1652
01:50:57,300 --> 01:51:00,500
and i will give you the idea is now being

1653
01:51:00,530 --> 01:51:02,710
government health warnings with this

1654
01:51:02,800 --> 01:51:05,410
maybe it's not explained higgs mechanism

1655
01:51:05,590 --> 01:51:08,450
i'm going to give you an example

1656
01:51:08,470 --> 01:51:13,330
the show this is not something that is certainly knew you need to particle physics

1657
01:51:13,330 --> 01:51:17,830
it is the phenomenon that is very well known throughout nature and science

1658
01:51:17,840 --> 01:51:20,910
and this is just had this manifestation of

1659
01:51:20,940 --> 01:51:26,130
so we can the pictures i had to motivate this first let's show again

1660
01:51:26,130 --> 01:51:28,140
then to explain it

1661
01:51:28,310 --> 01:51:33,150
the idea patterns and structures existing in the cold low energy

1662
01:51:34,410 --> 01:51:39,640
this is very revealing different symmetry in the war

1663
01:51:39,680 --> 01:51:40,640
if you want

1664
01:51:40,640 --> 01:51:43,060
as a glass of water

1665
01:51:44,230 --> 01:51:45,810
engineered so

1666
01:51:45,860 --> 01:51:48,540
according to the possible for the better

1667
01:51:48,600 --> 01:51:53,160
he that it doesn't matter which and rotated through it will be exactly the same

1668
01:51:53,160 --> 01:51:56,910
it's invariant under complete rotation symmetry

1669
01:51:56,990 --> 01:51:59,430
but if i froze

1670
01:51:59,450 --> 01:52:01,930
and one snowflake that's the

1671
01:52:02,130 --> 01:52:05,250
only invariant under rotations sixty

1672
01:52:05,270 --> 01:52:08,540
one hundred ninety two

1673
01:52:09,460 --> 01:52:13,150
the symmetry has changed many froze when it was

1674
01:52:14,860 --> 01:52:19,240
we have seen examples of this already in the negative forces missing electromagnetic and weak

1675
01:52:20,370 --> 01:52:23,650
which inference the like snowflakes in the cold

1676
01:52:23,690 --> 01:52:28,860
coming together at high energies with the z mass can be neglected we suspect that

1677
01:52:28,860 --> 01:52:31,080
is true some all forces

1678
01:52:31,250 --> 01:52:34,610
we have the standard model of the plant that forces which is the pattern based

1679
01:52:34,610 --> 01:52:39,130
on mass cold we suspect that the above this temperature

1680
01:52:39,140 --> 01:52:44,580
this mass will become irrelevant you see the real symmetry behind

1681
01:52:45,420 --> 01:52:47,170
this is the reason to the real

1682
01:52:47,190 --> 01:52:49,200
general the last twenty minutes

1683
01:52:49,900 --> 01:52:54,310
what is symmetry is what we liked and wanted to change in

1684
01:52:54,320 --> 01:52:55,470
so what

1685
01:52:56,230 --> 01:52:57,700
this is really about how symmetries

1686
01:52:57,710 --> 01:52:59,470
this appeal change

1687
01:52:59,480 --> 01:53:04,660
and i like to think about this picture from it realized the increasing profundity would

1688
01:53:07,060 --> 01:53:09,740
the right

1689
01:53:09,850 --> 01:53:14,630
the first psychologically we like symmetry

1690
01:53:14,640 --> 01:53:17,180
and when we don't see one why

1691
01:53:17,370 --> 01:53:18,960
so here's a picture of

1692
01:53:18,970 --> 01:53:21,890
because the joined peterborough in my home town in england

1693
01:53:22,190 --> 01:53:23,500
and you see

1694
01:53:23,630 --> 01:53:27,380
for example you can use in their quest for the things

1695
01:53:27,410 --> 01:53:30,250
art on one side that the other but then you look

1696
01:53:30,300 --> 01:53:33,020
the top and you see there is the town on one side

1697
01:53:33,040 --> 01:53:35,200
and there's nothing on the other

1698
01:53:35,610 --> 01:53:37,110
your media reactions

1699
01:53:38,410 --> 01:53:40,980
but there's no reason why they should be

1700
01:53:40,990 --> 01:53:44,360
but these are the fields but also one of the one on the north side

1701
01:53:44,410 --> 01:53:45,740
of the south side

1702
01:53:45,880 --> 01:53:47,430
the answer because the money

1703
01:53:47,550 --> 01:53:52,540
but there's a reason you see you will be asked you OK

1704
01:53:52,810 --> 01:53:53,700
rather more

1705
01:53:55,490 --> 01:54:03,160
i think the third the fourteenth century philosopher baroness

1706
01:54:03,190 --> 01:54:10,430
home the following month he imagine a perfectly symmetric don't last

1707
01:54:10,450 --> 01:54:16,360
that is positioned exactly midway between two identical bunches of carrots

1708
01:54:16,370 --> 01:54:21,800
and the philosopher than that because of the symmetry

1709
01:54:21,820 --> 01:54:23,750
there is no need

1710
01:54:23,780 --> 01:54:26,140
don't need to choose a character left

1711
01:54:26,170 --> 01:54:28,150
OK county right

1712
01:54:28,170 --> 01:54:34,430
therefore we can say that i do not think this that

1713
01:54:34,530 --> 01:54:39,300
if you have also that is what it's all about

1714
01:54:39,390 --> 01:54:42,720
but know what happens in practice

1715
01:54:42,890 --> 01:54:47,770
the challenge is one i will not happen in practice and you can make it

1716
01:54:47,920 --> 01:54:52,470
you can say well of course there is no such thing as absolutely symmetry don't

1717
01:54:52,490 --> 01:54:53,340
you can imagine

1718
01:54:55,630 --> 01:55:02,370
some of the random event will have small symmetry maybe

1719
01:55:02,380 --> 01:55:03,680
four days today

1720
01:55:03,970 --> 01:55:07,070
but it's a bit hotter almost no

1721
01:55:07,110 --> 01:55:09,480
don't need to go to the shady side

1722
01:55:09,570 --> 01:55:12,970
some trivial thing will spoil the symmetry

1723
01:55:13,000 --> 01:55:14,860
in the very small way

1724
01:55:14,860 --> 01:55:16,370
and have a huge

1725
01:55:16,380 --> 01:55:17,810
consequence namely

1726
01:55:17,810 --> 01:55:20,100
in two thousand this sign will survive

1727
01:55:20,600 --> 01:55:22,150
so that brings us

1728
01:55:22,180 --> 01:55:26,430
philosophical example which is now

1729
01:55:26,450 --> 01:55:31,470
and now which is getting near to real physical situation that's the problem

1730
01:55:31,520 --> 01:55:33,300
the symmetries in the party

1731
01:55:33,310 --> 01:55:39,810
but if you someday go really flash in party where they set the tables

1732
01:55:39,820 --> 01:55:41,700
so the table

1733
01:55:41,900 --> 01:55:43,640
a to use it in a table

1734
01:55:43,690 --> 01:55:44,970
each place

1735
01:55:44,980 --> 01:55:47,930
and we can set up to use symmetry

1736
01:55:47,940 --> 01:55:52,270
midway between you and your neighbors the table

1737
01:55:52,460 --> 01:55:58,380
and imagine yourself in these two table napkins you on the and all roads as

1738
01:55:58,820 --> 01:56:02,580
that which of these table napkins is yours

1739
01:56:02,590 --> 01:56:07,470
and until somebody breaks symmetry the dinner party cannot begin

1740
01:56:07,570 --> 01:56:15,880
and of course some rest the graph that is on the right because there's more

1741
01:56:16,230 --> 01:56:18,220
to the left interesting asymmetry anyway

1742
01:56:18,340 --> 01:56:21,220
OK they red table right

1743
01:56:21,240 --> 01:56:22,680
which breaks symmetry

1744
01:56:24,050 --> 01:56:26,370
now what to do with it

1745
01:56:26,500 --> 01:56:31,330
well this is analogous to what happens in magnets

1746
01:56:31,340 --> 01:56:33,090
as i explained

1747
01:56:33,100 --> 01:56:35,120
well first of all imagine we had to it

1748
01:56:35,140 --> 01:56:37,600
party when two hundred people

1749
01:56:37,600 --> 01:56:39,140
around this

1750
01:56:39,160 --> 01:56:39,750
so what

1751
01:56:39,770 --> 01:56:41,070
imagine the people there

1752
01:56:41,120 --> 01:56:43,590
ruby symmetrically placed on the state

1753
01:56:43,610 --> 01:56:48,640
and now we have the following all can happen following the over there

1754
01:56:48,770 --> 01:56:51,850
general background on his left

1755
01:56:51,860 --> 01:56:56,380
which forces all of you have been brought coming around here

1756
01:56:56,410 --> 01:57:01,010
now they're laying pig so that you know how right which forces all these people

1757
01:57:01,010 --> 01:57:03,280
the right to grab coming around here

1758
01:57:03,320 --> 01:57:06,180
so suddenly i have that


1
00:00:00,000 --> 00:00:03,000
by fours or whether it just

2
00:00:03,050 --> 00:00:06,410
go with you say OK i can do sixty four

3
00:00:06,440 --> 00:00:09,150
i can deal with sixty four nonzeros

4
00:00:09,160 --> 00:00:13,400
we're going to go down well under sixty four

5
00:00:15,660 --> 00:00:17,480
and of course

6
00:00:17,490 --> 00:00:19,050
four higher and

7
00:00:19,060 --> 00:00:20,380
pays off

8
00:00:21,520 --> 00:00:24,550
OK so what are these factors

9
00:00:24,580 --> 00:00:29,940
well these are the identity is this is the identity

10
00:00:29,960 --> 00:00:32,040
of size and is sitting here

11
00:00:32,060 --> 00:00:32,920
and here

12
00:00:33,020 --> 00:00:38,940
and here is the diagonal matrix of size m and here is its conjugate i

13
00:00:40,230 --> 00:00:43,600
so so i have to say what is diagonal matrix

14
00:00:44,730 --> 00:00:46,580
the matrix

15
00:00:47,270 --> 00:00:49,710
w square

16
00:00:49,730 --> 00:00:54,600
w to the n minus one is diagonal

17
00:00:58,940 --> 00:01:03,210
or maybe it's just that this is conjugate is just minus

18
00:01:03,540 --> 00:01:05,500
think it's just

19
00:01:05,640 --> 00:01:15,920
OK i'll come back to that matrix this matrix is the

20
00:01:15,940 --> 00:01:20,290
it is the permutation that puts all of

21
00:01:20,290 --> 00:01:23,270
even coefficients zero two

22
00:01:23,290 --> 00:01:26,540
the this permutation p here

23
00:01:26,580 --> 00:01:31,410
p is p takes the numbers zero the

24
00:01:31,440 --> 00:01:33,980
this is in order that they come

25
00:01:34,020 --> 00:01:38,960
and and produced puts them in the order even the first to o two four

26
00:01:40,320 --> 00:01:43,620
one three five seven

27
00:01:43,710 --> 00:01:45,480
so it

28
00:01:45,500 --> 00:01:52,020
evans before so in other words this FM acts on that evening

29
00:01:52,270 --> 00:01:53,210
this is

30
00:01:53,230 --> 00:01:54,790
and this

31
00:01:54,790 --> 00:01:59,640
this half size transform acts on the odd in this is

32
00:01:59,670 --> 00:02:02,960
did i really should have

33
00:02:03,120 --> 00:02:04,520
i mean

34
00:02:04,540 --> 00:02:06,410
you know what i mean

35
00:02:06,410 --> 00:02:11,190
so this is p so so the matrix has one in that position one and

36
00:02:11,190 --> 00:02:18,060
that one and that one that was that's the zero second fourth and sixth then

37
00:02:18,080 --> 00:02:23,420
one in the first third fifth and seventh

38
00:02:23,440 --> 00:02:25,650
that would be the eight by eight

39
00:02:27,000 --> 00:02:30,580
well sorry i jumped ahead to a by a here

40
00:02:30,600 --> 00:02:33,650
and but that's it

41
00:02:33,670 --> 00:02:37,250
and there's the

42
00:02:37,270 --> 00:02:38,770
why don't we

43
00:02:39,960 --> 00:02:43,080
just to be sure this is the key

44
00:02:43,100 --> 00:02:46,230
can you tell me what it will look like

45
00:02:46,230 --> 00:02:47,370
breaking up

46
00:02:47,370 --> 00:02:49,080
so while it's

47
00:02:49,210 --> 00:02:53,170
there's one more key idea here and what is it

48
00:02:53,270 --> 00:02:54,730
if i have

49
00:02:55,000 --> 00:02:59,170
so if i have if n is one thousand twenty four let's say let's let's

50
00:02:59,170 --> 00:03:02,120
take that as an example to to the ten

51
00:03:02,230 --> 00:03:08,270
i'm i'm using i'm doing the FFT radix two it's actually the only one i

52
00:03:10,920 --> 00:03:14,620
shmuel winograd created by

53
00:03:14,620 --> 00:03:18,420
number theoretic tricks

54
00:03:18,480 --> 00:03:20,600
efficient FFT is of

55
00:03:20,620 --> 00:03:22,060
prime powers

56
00:03:22,770 --> 00:03:28,100
porter minor they are these are the very opposite of prime these are probably the

57
00:03:28,100 --> 00:03:31,790
most used so suppose that is to the ten

58
00:03:31,810 --> 00:03:34,560
how many

59
00:03:34,580 --> 00:03:37,410
how many modifications so so

60
00:03:37,410 --> 00:03:44,500
how many modifications will it take to multiply just flat out by the matrix f

61
00:03:44,500 --> 00:03:46,250
of this order

62
00:03:46,270 --> 00:03:48,170
so the operation count

63
00:03:48,190 --> 00:03:50,140
it would be what

64
00:03:50,150 --> 00:03:53,270
what's the number that we're trying to

65
00:03:53,270 --> 00:03:57,100
trying to improve on

66
00:03:57,100 --> 00:04:01,810
so if i just multiply then by n matrix by a vector phi just did

67
00:04:01,810 --> 00:04:04,040
this or that this

68
00:04:04,060 --> 00:04:09,520
and i am i am in terms of i got to in square right

69
00:04:09,540 --> 00:04:14,440
because i got an terms in each sample and of the the ants squared entries

70
00:04:14,440 --> 00:04:16,060
in the matrix

71
00:04:16,080 --> 00:04:17,230
OK so

72
00:04:17,230 --> 00:04:20,920
so i'm trying to be dense square

73
00:04:22,980 --> 00:04:28,120
now i know and what does the FFT lead me to

74
00:04:28,150 --> 00:04:29,710
i try to

75
00:04:30,390 --> 00:04:34,710
so this single step

76
00:04:34,730 --> 00:04:37,310
let me that happens square

77
00:04:37,330 --> 00:04:38,870
cut it in half

78
00:04:38,920 --> 00:04:45,170
and i won't count that because of the just adds and here is just one

79
00:04:45,170 --> 00:04:46,730
and over two

80
00:04:46,770 --> 00:04:50,640
this is at

81
00:04:50,860 --> 00:04:56,290
multiplying by those both multiply the same

82
00:04:56,290 --> 00:05:00,030
of zero convex to the right of zero so you know very well behaved function

83
00:05:00,040 --> 00:05:02,620
but with this

84
00:05:02,630 --> 00:05:06,450
with this function you can take you know a combination of just three of these

85
00:05:06,460 --> 00:05:07,890
these tends to

86
00:05:07,910 --> 00:05:13,410
two nonlinearities and and get into the VC dimension and the the trick is you're

87
00:05:13,410 --> 00:05:15,660
hiding the sinusoidal

88
00:05:15,670 --> 00:05:17,840
in inside this still

89
00:05:18,730 --> 00:05:24,730
this can only and so so then you can subtract two pieces out there that

90
00:05:24,730 --> 00:05:26,860
have these nice smooth properties and

91
00:05:26,910 --> 00:05:30,470
the other picture here right you know he is the difference between

92
00:05:30,520 --> 00:05:31,760
between the

93
00:05:31,770 --> 00:05:35,880
the standard sigmoid in the dotted line is this one that's hiding a sinusoid in

94
00:05:35,880 --> 00:05:39,000
that when you take the difference between two of these things you can extract the

95
00:05:39,000 --> 00:05:44,000
same k it's it's very very sparse and very small level but with thresholding so

96
00:05:44,000 --> 00:05:48,940
the magnitude of this thing doesn't matter so we know again we have through the

97
00:05:48,940 --> 00:05:51,180
size of having infinite VC dimension

98
00:05:51,190 --> 00:05:53,490
OK sorry i mean i guess i should

99
00:05:53,510 --> 00:05:58,250
step back this might be some cause for concern right that about the

100
00:05:58,260 --> 00:06:02,480
here is that the here we're talking about the VC dimension it's the right notion

101
00:06:02,490 --> 00:06:06,280
of complexity if working minimax setting and yet

102
00:06:06,300 --> 00:06:07,890
you know when you look at this picture

103
00:06:07,900 --> 00:06:12,800
if we were to do some sort of a gradient descent optimisation over

104
00:06:12,810 --> 00:06:17,750
the quadratic criterion using a class of functions defined in terms of this thing right

105
00:06:17,750 --> 00:06:20,710
we're never going to be able to see those small wiggles

106
00:06:20,860 --> 00:06:24,890
seems quite unreasonable and so the distribution that gives us

107
00:06:24,900 --> 00:06:29,970
it exhibits the difficulties with the the infinite VC dimension is one that is exploiting

108
00:06:29,970 --> 00:06:31,910
those small wheels

109
00:06:32,670 --> 00:06:34,260
in the threshold the class

110
00:06:34,270 --> 00:06:37,900
o point is the optimisation problem

111
00:06:37,910 --> 00:06:44,340
that that we want to solve that is to find the function from from

112
00:06:44,350 --> 00:06:46,470
this class

113
00:06:46,490 --> 00:06:51,040
right that that minimizes the empirical error of the threshold function

114
00:06:51,090 --> 00:06:53,780
that's a very difficult optimisation problem

115
00:06:53,880 --> 00:06:55,030
and so

116
00:06:55,040 --> 00:06:59,080
you know this is not this is not a practical course concern for this class

117
00:06:59,080 --> 00:07:01,130
of functions

118
00:07:01,150 --> 00:07:02,790
right because because

119
00:07:02,820 --> 00:07:07,200
we we can solve the computational problem for this class to minimize in particular so

120
00:07:07,200 --> 00:07:10,900
we'll see later when we look at a large margin setting we optimize different criteria

121
00:07:10,920 --> 00:07:12,400
were not optimizing

122
00:07:12,980 --> 00:07:17,230
we're not minimizing empirical risk we're not trying to minimize the number of mistakes we

123
00:07:17,860 --> 00:07:21,530
when the threshold functions are optimizing some smooth

124
00:07:21,540 --> 00:07:25,210
criterion involving the real valued function

125
00:07:25,570 --> 00:07:27,930
the left here itself

126
00:07:27,950 --> 00:07:30,210
OK so in that setting

127
00:07:30,270 --> 00:07:31,960
our optimisation

128
00:07:31,980 --> 00:07:35,980
is not able to exploit all the that exploit the full power

129
00:07:35,990 --> 00:07:38,460
of this threshold the class

130
00:07:38,480 --> 00:07:40,780
OK we're working with a slightly different

131
00:07:42,490 --> 00:07:45,940
and these kinds of negative results point out

132
00:07:45,960 --> 00:07:49,240
you know that if we were to to work with the right criterion would be

133
00:07:49,240 --> 00:07:50,090
in trouble

134
00:07:50,100 --> 00:07:54,820
we'll see later that when we work with something not quite the right criterion you

135
00:07:54,820 --> 00:07:57,120
know we get around this kind of difficulty

136
00:07:57,160 --> 00:08:00,870
OK will see also that the general results about to tell you

137
00:08:00,920 --> 00:08:03,110
about to show you these

138
00:08:03,440 --> 00:08:08,840
results about parameterise real valued functions are useful in in that setting also we can

139
00:08:08,840 --> 00:08:13,720
build up estimates of the rademacher averages for instance the complex classes in terms of

140
00:08:13,760 --> 00:08:15,640
VC dimension estimates for simple

141
00:08:15,680 --> 00:08:17,040
simple class

142
00:08:18,520 --> 00:08:23,530
these results are important even in the the large margin

143
00:08:24,350 --> 00:08:27,000
OK so let me tell you i need one

144
00:08:27,010 --> 00:08:32,110
technical definition two to explain the result that we're going to

145
00:08:32,120 --> 00:08:33,560
so we're to look at

146
00:08:34,200 --> 00:08:37,270
for for these thresholded real valued

147
00:08:39,130 --> 00:08:43,060
and you and i'm just broadening things a little bit

148
00:08:43,500 --> 00:08:48,420
to include not just a single real valued function parameters now

149
00:08:48,430 --> 00:08:52,520
i've i've called i instead of instead of theta not just a single real valued

150
00:08:52,520 --> 00:08:55,880
function but we've got k of them and when combining them in some fixed y

151
00:08:55,880 --> 00:08:57,280
with the boolean function

152
00:08:57,300 --> 00:08:58,480
OK so there's no

153
00:08:58,490 --> 00:09:00,500
i just want to make

154
00:09:00,560 --> 00:09:04,440
make my classifier actions a little richer

155
00:09:04,450 --> 00:09:07,500
in particular so that we can include a certain

156
00:09:07,510 --> 00:09:09,800
model of real valued computation

157
00:09:09,810 --> 00:09:14,460
and relate the VC dimension to the computational complexity of calculating the value of the

158
00:09:15,590 --> 00:09:19,160
OK so i need this extension to do so so let's look at the definition

159
00:09:19,160 --> 00:09:22,200
we've got some class g of real valued functions

160
00:09:22,210 --> 00:09:26,770
right and and all these functions that we're going to consider a continuous in their

161
00:09:26,790 --> 00:09:28,370
in the parameters

162
00:09:28,740 --> 00:09:32,140
these are all a and we've got some

163
00:09:33,510 --> 00:09:36,020
class of boolean function

164
00:09:36,070 --> 00:09:39,350
so we've got some boolean function g

165
00:09:39,430 --> 00:09:42,130
right so this thing and that's from plus minus one

166
00:09:43,440 --> 00:09:47,460
OK OK of these these signs two plus one one

167
00:09:47,510 --> 00:09:52,170
and then we compute the function in a class by first computing these k

168
00:09:52,260 --> 00:09:58,660
distinct functions parameterized functions and then take some fixed boolean function of

169
00:09:58,710 --> 00:09:59,670
right so

170
00:09:59,680 --> 00:10:03,020
you know why am i going to this generally let's look at

171
00:10:03,040 --> 00:10:04,610
because the

172
00:10:04,630 --> 00:10:10,240
it's very typical example we will see one more later but here i want to

173
00:10:10,240 --> 00:10:12,530
look at functions that can be computed

174
00:10:14,200 --> 00:10:17,220
founded time under certain model of computation

175
00:10:17,230 --> 00:10:21,400
OK and that fits into this model of i i guess i

176
00:10:21,420 --> 00:10:25,840
user nomenclature so this class boolean functions that we define down here is called the

177
00:10:25,850 --> 00:10:29,700
k combination of threshold functions from

178
00:10:29,710 --> 00:10:32,440
from g this present class

179
00:10:32,490 --> 00:10:35,670
OK so

180
00:10:35,690 --> 00:10:37,100
the the class

181
00:10:37,980 --> 00:10:40,540
the class i wanted to find

182
00:10:40,560 --> 00:10:42,590
is it a combination

183
00:10:42,600 --> 00:10:44,840
official functions from the

184
00:10:44,850 --> 00:10:46,420
the class of polynomials

185
00:10:46,470 --> 00:10:48,550
right polynomially parameterized

186
00:10:48,560 --> 00:10:52,690
functions for some value of k so let me explain the model of computation he

187
00:10:52,690 --> 00:10:57,720
was talking about how much time it takes to compute the value of the function

188
00:10:57,740 --> 00:11:03,010
so we have a parameterized class d these are the material parameters and let's say

189
00:11:03,010 --> 00:11:07,610
x is is represented as a vector in rn

190
00:11:07,620 --> 00:11:10,750
and we supposing that this

191
00:11:13,260 --> 00:11:15,740
this is now a plus and minus one

192
00:11:15,750 --> 00:11:20,800
valued function was saying that this thing can be computed

193
00:11:20,810 --> 00:11:22,730
in no more than t steps

194
00:11:22,740 --> 00:11:24,490
one of the following types

195
00:11:24,510 --> 00:11:26,240
right so we take as input

196
00:11:26,240 --> 00:11:27,560
then b

197
00:11:31,490 --> 00:11:34,490
assigned this value g

198
00:11:35,770 --> 00:11:37,210
output b

199
00:11:37,210 --> 00:11:38,980
the action

200
00:11:39,030 --> 00:11:41,060
and then

201
00:11:41,070 --> 00:11:43,370
repeat this until

202
00:11:43,380 --> 00:11:45,010
the reason

203
00:11:49,120 --> 00:11:52,570
OK three which is also implemented by the the same enjoy

204
00:11:52,700 --> 00:11:57,050
protection of sexual person

205
00:11:57,110 --> 00:11:59,620
it it should

206
00:11:59,740 --> 00:12:02,030
that's it so

207
00:12:02,240 --> 00:12:05,290
not in that way

208
00:12:05,300 --> 00:12:08,990
treatment of patients from as as far as

209
00:12:10,080 --> 00:12:12,500
so far away

210
00:12:12,550 --> 00:12:15,250
and at least one goal

211
00:12:15,250 --> 00:12:20,670
allows us to record at least one in this

212
00:12:20,850 --> 00:12:22,760
one goals

213
00:12:22,820 --> 00:12:25,570
this will be

214
00:12:25,580 --> 00:12:28,470
as i explained essentially the formula

215
00:12:28,470 --> 00:12:29,510
is the same

216
00:12:29,530 --> 00:12:33,260
it was simply

217
00:12:33,370 --> 00:12:35,180
is not the can be

218
00:12:36,840 --> 00:12:38,340
is probably the

219
00:12:39,240 --> 00:12:43,020
existence of structure prediction

220
00:12:43,040 --> 00:12:50,610
and join intersection process and he played form rather than simply asked whether there so

221
00:12:50,620 --> 00:12:53,160
well that this is basically

222
00:12:53,190 --> 00:12:58,320
the core well satisfies

223
00:13:06,730 --> 00:13:08,630
seven days

224
00:13:08,690 --> 00:13:13,740
we have an increase in sequence of these four class every conjoined g

225
00:13:13,750 --> 00:13:15,740
the satisfiability

226
00:13:15,790 --> 00:13:17,870
you seem like reasonable competition case

227
00:13:18,920 --> 00:13:20,930
gerard of these

228
00:13:21,280 --> 00:13:23,430
that eliminating everything else

229
00:13:23,480 --> 00:13:25,670
but it was for the

230
00:13:26,100 --> 00:13:27,970
last time

231
00:13:27,980 --> 00:13:29,560
and then there the intersection

232
00:13:29,590 --> 00:13:32,010
go to the goal states and

233
00:13:32,020 --> 00:13:33,940
six of them

234
00:13:35,190 --> 00:13:35,910
but OK

235
00:13:35,920 --> 00:13:39,810
these form the simple case said

236
00:13:39,960 --> 00:13:42,840
you can see

237
00:13:46,560 --> 00:13:50,340
how good is the second that this

238
00:13:50,380 --> 00:13:52,790
useful much much worse

239
00:13:52,800 --> 00:13:53,850
and the

240
00:13:53,860 --> 00:13:56,410
the reason is simply

241
00:14:00,370 --> 00:14:02,770
on line these problems

242
00:14:02,780 --> 00:14:06,490
sets of states that are reasonable by even more

243
00:14:06,500 --> 00:14:09,130
actually there is much more information

244
00:14:09,200 --> 00:14:11,990
needs to be much more than one needs

245
00:14:12,010 --> 00:14:14,300
but so that so

246
00:14:14,360 --> 00:14:18,120
what we are doing not what work

247
00:14:18,130 --> 00:14:22,620
you will need to find one black

248
00:14:22,630 --> 00:14:24,440
i don't know where you

249
00:14:25,550 --> 00:14:27,440
the benefit of this

250
00:14:29,530 --> 00:14:33,530
because we can this be fixed point condition what he's doing

251
00:14:33,580 --> 00:14:35,320
we know

252
00:14:35,370 --> 00:14:38,810
when you have with which

253
00:14:39,700 --> 00:14:41,470
this approach is not as

254
00:14:41,480 --> 00:14:44,500
scalable set approach

255
00:14:44,520 --> 00:14:46,410
problem is that the former

256
00:14:46,420 --> 00:14:49,100
class three is set here

257
00:14:49,120 --> 00:14:50,650
they go to to be

258
00:14:50,650 --> 00:14:54,660
the main reason is what i already explained

259
00:14:54,830 --> 00:14:56,420
that the

260
00:14:56,560 --> 00:15:01,110
it was like operation the worst case

261
00:15:01,900 --> 00:15:02,980
can grow

262
00:15:04,340 --> 00:15:05,250
number of

263
00:15:05,260 --> 00:15:07,490
variables i

264
00:15:07,540 --> 00:15:13,330
and this is no general way starting that doesn't happen also practise some kind of

265
00:15:14,190 --> 00:15:17,860
growth is slow but some other kind of problems because three

266
00:15:22,360 --> 00:15:23,740
the very

267
00:15:23,850 --> 00:15:26,760
simply by

268
00:15:26,810 --> 00:15:28,040
using this

269
00:15:28,050 --> 00:15:30,990
it's not methods

270
00:15:31,140 --> 00:15:35,160
OK one can run out of main memory supported by

271
00:15:35,510 --> 00:15:38,950
memory like in sectors

272
00:15:38,990 --> 00:15:41,100
one thousand eight

273
00:15:42,340 --> 00:15:43,920
you you know what

274
00:15:47,620 --> 00:15:52,900
only days in which he scored much better and is that approach is

275
00:15:56,320 --> 00:16:00,160
number reasonable space is actually quite small

276
00:16:00,170 --> 00:16:06,340
one is really high number of accidents two weeks so let's say this only

277
00:16:07,130 --> 00:16:10,610
a couple of thousand of fans states

278
00:16:10,650 --> 00:16:14,540
that are reachable by one needs hundred factors which

279
00:16:14,660 --> 00:16:20,260
because of the very high planning is that the prose might fail completely but the

280
00:16:20,260 --> 00:16:24,900
formulas in this approach states what's more than one

281
00:16:24,930 --> 00:16:27,010
one of the problem

282
00:16:27,020 --> 00:16:27,790
but the

283
00:16:27,820 --> 00:16:31,640
usually there is that in those cases it is only a small number of states

284
00:16:32,800 --> 00:16:34,520
one would be using logic

285
00:16:35,840 --> 00:16:36,880
in one

286
00:16:36,920 --> 00:16:39,080
what would be using the

287
00:16:40,410 --> 00:16:42,430
it's certain

288
00:16:43,340 --> 00:16:47,500
and not just what all

289
00:16:47,510 --> 00:16:56,000
OK and that really actually brings us to the last topic

290
00:16:56,000 --> 00:17:00,660
i'll go through this world weekly i'm not going to be playing with this and

291
00:17:00,660 --> 00:17:04,160
the main ideas what is there

292
00:17:05,190 --> 00:17:10,180
i started elected by sorting the transition graph using the many problem in the simplest

293
00:17:10,180 --> 00:17:14,830
so given a bunch of data x one to xn sitting in the high dimensional space

294
00:17:14,850 --> 00:17:19,230
you want to project you want to say project in the one dimensional space are

295
00:17:19,230 --> 00:17:22,970
and find numbers y one through y n

296
00:17:22,980 --> 00:17:26,820
each y is just the projection of x i

297
00:17:28,490 --> 00:17:30,260
so you want to find

298
00:17:30,270 --> 00:17:36,210
y one to y and to represent york high dimensional data x one to xn

299
00:17:36,230 --> 00:17:38,830
and you want to find the projection

300
00:17:38,850 --> 00:17:41,430
that maximises the variance of the data

301
00:17:41,440 --> 00:17:45,750
here i assumed that all the exercise i have mean zero and so automatically the

302
00:17:45,750 --> 00:17:49,600
wise have mean zero so that the variance is this particular formula which is the

303
00:17:49,600 --> 00:17:51,660
sum of the squares

304
00:17:51,780 --> 00:17:53,760
i mean you actually have to the mean subtract

305
00:17:54,030 --> 00:17:56,630
to do that for the correct

306
00:17:56,660 --> 00:18:00,590
definition of variance but i just as in the mean zero here

307
00:18:00,600 --> 00:18:02,360
so you want to find

308
00:18:02,370 --> 00:18:05,510
that w that maximises the variance

309
00:18:05,510 --> 00:18:07,890
and it's fairly easy to see that

310
00:18:07,950 --> 00:18:10,350
the sum of the squares of the wise

311
00:18:10,370 --> 00:18:13,120
ends up being this particular quadratic forms

312
00:18:13,130 --> 00:18:14,300
in w

313
00:18:14,310 --> 00:18:18,600
so you want to find w that maximizes this particular

314
00:18:18,610 --> 00:18:19,980
quadratic form

315
00:18:19,980 --> 00:18:23,510
and that gives rise to earlier it's like question

316
00:18:23,520 --> 00:18:25,690
and then leads to

317
00:18:25,700 --> 00:18:29,810
finding the leading i can vector

318
00:18:31,000 --> 00:18:34,000
the data covariance matrix

319
00:18:34,010 --> 00:18:36,010
so i'm sure all of you have seen this

320
00:18:36,020 --> 00:18:42,050
there is also something else which is the way to interpret principal components analysis

321
00:18:43,520 --> 00:18:47,030
what principal components analysis is doing also

322
00:18:47,050 --> 00:18:48,170
in some sense

323
00:18:48,180 --> 00:18:49,320
he is

324
00:18:50,950 --> 00:18:52,800
the best

325
00:18:52,840 --> 00:18:55,780
linear subspace to the data

326
00:18:55,820 --> 00:18:58,500
office certain rank over certain desired

327
00:19:00,620 --> 00:19:16,070
let me just write that

328
00:19:20,670 --> 00:19:23,660
so you have all this data x one through

329
00:19:25,530 --> 00:19:29,020
consider some subspace h

330
00:19:29,250 --> 00:19:33,420
consider the projection

331
00:19:33,440 --> 00:19:38,880
on two a talking projection onto h of x i

332
00:19:38,910 --> 00:19:40,330
and consider this

333
00:19:40,360 --> 00:19:43,330
least squares

334
00:19:45,520 --> 00:19:47,830
and i want to minimize this

335
00:19:47,890 --> 00:19:51,330
overall h

336
00:19:51,350 --> 00:19:55,700
this is also essentially the same problem as principal components

337
00:19:56,570 --> 00:19:58,810
so what principal components is doing

338
00:19:58,850 --> 00:20:03,870
is trying to essentially fit in this least squares sense

339
00:20:03,920 --> 00:20:05,890
a linear manifold

340
00:20:05,910 --> 00:20:08,540
to the data

341
00:20:08,890 --> 00:20:17,970
so this is a very classical

342
00:20:17,990 --> 00:20:19,520
widely used

343
00:20:22,390 --> 00:20:26,190
you could think of it also just like the mixture of gaussians is very classical

344
00:20:26,190 --> 00:20:31,620
and widely used and is the simplest instantiation of

345
00:20:33,300 --> 00:20:36,450
structure probability distribution

346
00:20:36,500 --> 00:20:41,310
PCA which is another classical example and widely used can be part of

347
00:20:41,330 --> 00:20:45,670
as the simplest instantiation of fitting in manifold to data

348
00:20:45,670 --> 00:20:47,160
but this manifold

349
00:20:47,190 --> 00:20:48,370
is just

350
00:20:48,390 --> 00:20:53,330
a linear space

351
00:20:53,350 --> 00:20:58,530
so what was what is the more general manifold model say

352
00:20:58,540 --> 00:21:02,960
suppose data does not lie on or near some linear space at all

353
00:21:02,970 --> 00:21:08,120
suppose actually the distribution of the data looks like this

354
00:21:09,090 --> 00:21:13,730
well you can clearly see the debate seems to rely on some

355
00:21:13,760 --> 00:21:18,660
set which seems to have only one degree of freedom

356
00:21:18,680 --> 00:21:22,160
and yet it's not obvious that lies in some linear space

357
00:21:22,180 --> 00:21:26,510
so the line some dimensional space

358
00:21:26,620 --> 00:21:28,140
so what happens

359
00:21:28,160 --> 00:21:32,060
if the data looks like this

360
00:21:32,080 --> 00:21:33,890
can you actually

361
00:21:34,110 --> 00:21:39,710
to develop some scheme where you could unravel the structure of the data i realized

362
00:21:39,710 --> 00:21:44,780
that there is one degree of freedom in the data represent the data appropriately

363
00:21:44,880 --> 00:21:49,140
without trying to either fit some linear subspace to something that looks like this bit

364
00:21:49,140 --> 00:21:51,850
aligned with the score

365
00:21:54,170 --> 00:21:59,480
anything else you might think of

366
00:21:59,620 --> 00:22:02,820
so let me give you an acoustic example which is a mark of three

367
00:22:02,840 --> 00:22:07,280
ends up with the distribution of data that looks more or less like what i

368
00:22:07,290 --> 00:22:11,760
just told you OK because the picture they put up might seem artificial it might

369
00:22:11,760 --> 00:22:15,530
seem that i just made it up to make some abstract point so let me

370
00:22:15,530 --> 00:22:20,090
give you an actual example of data is generated by very simple physical system

371
00:22:20,260 --> 00:22:21,950
then yes the physical system

372
00:22:22,000 --> 00:22:26,100
it's an acoustic tube of length l

373
00:22:26,160 --> 00:22:29,560
and i blow puffs of air at one end of the two u of t

374
00:22:29,560 --> 00:22:33,210
is the exciting asian of the steel so puffs of air at one end of

375
00:22:33,210 --> 00:22:34,560
symmetry of

376
00:22:34,560 --> 00:22:38,620
certain problems are yourself and really a very quite is quite far reaching we're going

377
00:22:38,630 --> 00:22:39,440
to do it

378
00:22:39,490 --> 00:22:42,600
well actually have a few occasions due to go to to go into this but

379
00:22:42,820 --> 00:22:47,100
but the light-touch are underselling just give you some indication where the subject goes

380
00:22:47,160 --> 00:22:49,590
right now

381
00:22:51,220 --> 00:22:54,240
one of the mathematical description jas

382
00:23:00,860 --> 00:23:10,020
now that i've said so far i'm sure is new to you at all

383
00:23:10,030 --> 00:23:12,790
you just have to trust me that at some point before you know it some

384
00:23:12,790 --> 00:23:15,020
things i say to you will be new

385
00:23:15,070 --> 00:23:15,810
i hope

386
00:23:15,820 --> 00:23:21,560
but what of the mathematical descriptions periodicity again the in the two different categories say

387
00:23:21,600 --> 00:23:25,250
the numbers one is the associate

388
00:23:25,260 --> 00:23:36,620
with either either phenomenon is periodic in time or function or for phenomenon periodic in

389
00:23:36,620 --> 00:23:43,390
space for periodic in time for periodicity in time

390
00:23:43,390 --> 00:23:45,100
you can use the frequency

391
00:23:45,120 --> 00:23:48,100
all right frequency is the word

392
00:23:48,950 --> 00:23:53,260
but you hear most often associated with the phenomenon that is periodic in time use

393
00:23:55,590 --> 00:24:03,200
the number of repetitions the number of cycles in a second say

394
00:24:03,220 --> 00:24:09,140
if the pattern is repeating one of the partners

395
00:24:09,180 --> 00:24:13,590
and finally that term sort of undefined sort of a is the number of repetitions

396
00:24:13,590 --> 00:24:15,320
of the pattern

397
00:24:15,410 --> 00:24:20,260
in one second or over time

398
00:24:20,260 --> 00:24:27,090
all right

399
00:24:27,160 --> 00:24:32,370
that's the most common this descriptor mathematical description of a phenomenon is periodic that's periodic

400
00:24:32,370 --> 00:24:36,200
in time for function for my periodic in space

401
00:24:38,010 --> 00:24:41,950
you actually use the period

402
00:24:41,970 --> 00:24:46,550
that's the only word really in use in general for the particular well one thing

403
00:24:46,550 --> 00:24:52,820
that i

404
00:24:52,820 --> 00:24:55,510
for periodicity in space

405
00:24:55,510 --> 00:25:04,660
use the period

406
00:25:04,820 --> 00:25:10,760
that is sort of physical measurement of how long the long longer pattern is before

407
00:25:11,760 --> 00:25:13,820
how write the measurement of how

408
00:25:13,840 --> 00:25:18,370
whether it's length or some other quantity measurement of how

409
00:25:18,430 --> 00:25:24,260
we just say how big the pattern is repeated

410
00:25:24,600 --> 00:25:31,140
they're not the same article

411
00:25:31,160 --> 00:25:33,010
every different fields

412
00:25:33,050 --> 00:25:35,370
they arise from different sorts of

413
00:25:36,570 --> 00:25:41,720
is probably too strong statement but i think i think it's fair to say that

414
00:25:41,800 --> 00:25:44,890
mathematicians tend to think in terms of mostly periodic they tend to think in terms

415
00:25:44,890 --> 00:25:48,390
of the period of function of the period is the description of periodic behavior

416
00:25:48,390 --> 00:25:52,260
whereas engineers and scientists tend to think of systems evolving in time so they tend

417
00:25:52,260 --> 00:25:54,590
to think in terms of frequency they tend to think of how often

418
00:25:54,590 --> 00:25:59,450
a pattern is over a certain period of time that's

419
00:25:59,450 --> 00:26:02,570
but everything else is that same has to be qualified to get tired of qualify

420
00:26:02,590 --> 00:26:05,200
every statement so i'll just leave it at that

421
00:26:06,450 --> 00:26:07,510
of course

422
00:26:07,510 --> 00:26:12,280
the two phenomena are not completely separate not always completely separate they come together periodicity

423
00:26:12,280 --> 00:26:16,090
in time and periodicity space come together in for example wave motion

424
00:26:16,090 --> 00:26:18,370
all right that traveling

425
00:26:18,370 --> 00:26:20,950
disturbance traveling periodic disturbance

426
00:26:20,950 --> 00:26:24,620
so the two notions aperiodicity come together

427
00:26:24,660 --> 00:26:29,260
two notions here periodicity concrete bridges in space come together

428
00:26:29,410 --> 00:26:33,140
in g

429
00:26:33,180 --> 00:26:34,640
wave motion

430
00:26:34,860 --> 00:26:44,140
understood very generally here as a periodic as a regularly repeating pattern changes in time

431
00:26:44,200 --> 00:26:46,550
and movies

432
00:26:46,570 --> 00:26:52,620
more jumps up a little bit i think are

433
00:26:56,050 --> 00:27:05,510
so a regular

434
00:27:05,530 --> 00:27:09,620
a moving results regularly

435
00:27:09,800 --> 00:27:12,140
moving disturbance

436
00:27:12,140 --> 00:27:19,490
like group professions for the quad

437
00:27:20,720 --> 00:27:24,590
they're everywhere

438
00:27:25,760 --> 00:27:27,990
mostly moving right now

439
00:27:28,140 --> 00:27:33,300
there again that the two descriptors come in the frequency and wavelength so again you

440
00:27:33,300 --> 00:27:38,430
have frequency and wavelength

441
00:27:42,050 --> 00:27:45,280
and wavelength usually associated usually denoted by

442
00:27:45,300 --> 00:27:50,280
this is for periodicity in space for periodicity in time frequency

443
00:27:51,010 --> 00:27:53,530
four periodicity in time

444
00:27:56,120 --> 00:28:03,590
as the number of times

445
00:28:03,590 --> 00:28:07,000
so last lecture was arguably the most important

446
00:28:07,010 --> 00:28:09,300
all my lectures

447
00:28:09,350 --> 00:28:12,690
we saw how it changing magnetic fields

448
00:28:12,770 --> 00:28:15,110
can produce current

449
00:28:15,140 --> 00:28:17,320
an induced electric

450
00:28:18,380 --> 00:28:20,340
the induced EMF

451
00:28:20,440 --> 00:28:22,820
and finally express that

452
00:28:22,840 --> 00:28:24,930
in his famous

453
00:28:24,950 --> 00:28:28,320
law famous equation which you see there

454
00:28:28,360 --> 00:28:31,040
on the blackboard

455
00:28:31,090 --> 00:28:34,490
you select the closed loop in your circuit

456
00:28:35,290 --> 00:28:37,330
link is OK

457
00:28:37,400 --> 00:28:41,180
your attention open surface that closed loop

458
00:28:41,190 --> 00:28:42,790
any open source

459
00:28:42,820 --> 00:28:44,360
is OK

460
00:28:44,400 --> 00:28:47,210
and you don't get an EMF in the loop

461
00:28:47,210 --> 00:28:49,510
that's the time derivative

462
00:28:49,600 --> 00:28:53,180
of the magnetic flux through that surface

463
00:28:53,320 --> 00:28:55,560
the minus sign indicates

464
00:28:55,610 --> 00:28:58,890
that the induced current itself

465
00:28:58,890 --> 00:29:01,570
it uses a magnetic flux that opposes

466
00:29:01,580 --> 00:29:03,170
the flux change

467
00:29:03,180 --> 00:29:03,860
and that

468
00:29:03,870 --> 00:29:07,230
we refer to as men's law

469
00:29:08,840 --> 00:29:11,200
i will expand on this

470
00:29:11,230 --> 00:29:13,280
a lot further

471
00:29:13,320 --> 00:29:15,320
let's start with a

472
00:29:15,340 --> 00:29:17,510
conducting look

473
00:29:19,400 --> 00:29:22,530
a magnetic field

474
00:29:22,610 --> 00:29:25,420
this is the conducting loop

475
00:29:25,430 --> 00:29:28,180
but the dimensions the y

476
00:29:30,500 --> 00:29:33,980
and that i have a uniform magnetic field

477
00:29:34,180 --> 00:29:37,030
medical field b

478
00:29:37,030 --> 00:29:38,620
it's like so

479
00:29:39,700 --> 00:29:41,560
i choose

480
00:29:41,610 --> 00:29:43,980
as perpendicular vector

481
00:29:43,980 --> 00:29:48,420
two my surface this surface by text that closed loop

482
00:29:48,470 --> 00:29:49,430
i choose it

483
00:29:49,480 --> 00:29:51,510
pointing up

484
00:29:51,560 --> 00:29:54,140
so the angle between the a and b

485
00:29:54,170 --> 00:29:56,920
you say that the the

486
00:29:56,970 --> 00:29:59,750
is uniform

487
00:29:59,820 --> 00:30:01,640
so the flux

488
00:30:01,680 --> 00:30:02,530
five b

489
00:30:02,650 --> 00:30:07,590
it is defined as the integral

490
00:30:07,640 --> 00:30:11,090
of the built the a

491
00:30:11,090 --> 00:30:18,650
over these open surface

492
00:30:22,370 --> 00:30:25,240
plus or minus with zero

493
00:30:25,250 --> 00:30:28,580
phlox has no direction

494
00:30:28,620 --> 00:30:29,590
so to flux

495
00:30:29,600 --> 00:30:31,930
in this case

496
00:30:31,970 --> 00:30:37,250
would be x y which is the area of the loop since the magnetic field

497
00:30:37,250 --> 00:30:39,870
is uniform

498
00:30:39,880 --> 00:30:42,160
it's very easy to grow

499
00:30:42,220 --> 00:30:45,340
then i get

500
00:30:45,350 --> 00:30:47,750
the magnetic field b

501
00:30:47,750 --> 00:30:55,720
and then i get the cosine of the angle

502
00:30:55,780 --> 00:30:58,620
so now according to faraday

503
00:30:58,690 --> 00:31:03,840
it is the time derivative of this quantity that determines the EMF

504
00:31:03,900 --> 00:31:06,560
you can do that in several ways

505
00:31:06,580 --> 00:31:08,210
you can never be

506
00:31:08,220 --> 00:31:11,240
change in the magnetic field

507
00:31:11,280 --> 00:31:13,090
this is the area eight

508
00:31:13,090 --> 00:31:14,370
of the loop

509
00:31:14,410 --> 00:31:16,960
you can change the area

510
00:31:16,970 --> 00:31:19,060
you can have the eighty

511
00:31:19,100 --> 00:31:21,120
but you can also change data

512
00:31:21,190 --> 00:31:24,430
you can have it is say that dt

513
00:31:24,490 --> 00:31:29,330
and i will look at those today

514
00:31:29,370 --> 00:31:32,800
this number here the way i've chosen ninety eight

515
00:31:32,850 --> 00:31:36,750
is the positive number

516
00:31:36,830 --> 00:31:39,000
if somehow

517
00:31:39,060 --> 00:31:42,620
this number increases in positive value

518
00:31:42,680 --> 00:31:45,620
the induced current that is going to run

519
00:31:45,660 --> 00:31:49,780
i will try to create a magnetic field to oppose the change

520
00:31:49,830 --> 00:31:51,960
so in that case

521
00:31:53,020 --> 00:31:57,600
the flux which is now positive is getting larger positive

522
00:31:57,620 --> 00:31:59,520
the current that's going to run

523
00:31:59,590 --> 00:32:01,590
will be in this direction

524
00:32:01,600 --> 00:32:03,430
that's lands for you

525
00:32:03,440 --> 00:32:05,810
so it creates by itself

526
00:32:05,830 --> 00:32:09,910
this current creates a magnetic field in this direction

527
00:32:09,930 --> 00:32:11,470
and if the

528
00:32:11,470 --> 00:32:15,160
magnetic flux which is now positive way have defined it

529
00:32:15,210 --> 00:32:16,720
with decreasing

530
00:32:16,730 --> 00:32:18,170
then the current

531
00:32:18,190 --> 00:32:23,820
we got a lot of a around

532
00:32:23,860 --> 00:32:25,360
last time

533
00:32:25,410 --> 00:32:29,210
i did several demonstrations by we changed

534
00:32:29,270 --> 00:32:31,770
we had the

535
00:32:31,780 --> 00:32:34,260
and there was one particular demonstration

536
00:32:34,300 --> 00:32:36,200
the blue your mind

537
00:32:36,210 --> 00:32:37,670
and that you will tell

538
00:32:37,690 --> 00:32:40,820
your grandchildren about and that you always remember

539
00:32:40,830 --> 00:32:42,840
i hope

540
00:32:44,400 --> 00:32:45,710
i'm going to change

541
00:32:46,900 --> 00:32:48,600
and i'm going to change

542
00:32:48,650 --> 00:32:50,360
the area

543
00:32:50,380 --> 00:32:52,630
also give me then

544
00:32:52,640 --> 00:32:54,510
induced him as

545
00:32:54,520 --> 00:32:55,480
and therefore

546
00:32:55,520 --> 00:32:57,280
induced currents in two

547
00:32:57,290 --> 00:33:02,800
a closed conducting look

548
00:33:02,850 --> 00:33:05,780
so let me

549
00:33:05,790 --> 00:33:09,080
make another drawing of the

550
00:33:09,090 --> 00:33:12,260
close conducting look

551
00:33:12,270 --> 00:33:14,150
it has

552
00:33:14,220 --> 00:33:16,260
lang's y

553
00:33:16,290 --> 00:33:19,340
in which x

554
00:33:19,390 --> 00:33:22,270
and i'm going to rotate this

555
00:33:22,350 --> 00:33:25,440
my idea is considered three-dimensional

556
00:33:25,450 --> 00:33:28,400
i'm going to rotate is about its axis

557
00:33:28,440 --> 00:33:30,160
with angular

558
00:33:30,170 --> 00:33:33,650
frequency omega

559
00:33:33,650 --> 00:33:37,090
omega is two pi

560
00:33:37,140 --> 00:33:41,050
divided by the period period time one rotation

561
00:33:41,070 --> 00:33:43,400
normally we choose for that capital t

562
00:33:43,400 --> 00:33:49,400
i don't want to do that today because you can compute you was that's why

563
00:33:49,540 --> 00:33:51,860
so i'm going to rotate is around

564
00:33:51,950 --> 00:33:55,260
so the angle theta that you have there

565
00:33:55,270 --> 00:33:56,600
say that

566
00:33:56,610 --> 00:33:59,420
then becomes theta zero

567
00:33:59,440 --> 00:34:01,030
was omega t

568
00:34:01,080 --> 00:34:03,580
going back to a to one

569
00:34:03,610 --> 00:34:06,400
and i choose this state zero such

570
00:34:06,450 --> 00:34:08,460
t zero

571
00:34:08,510 --> 00:34:11,670
i choose my fate to be zero

572
00:34:11,690 --> 00:34:16,590
and so i have nothing to do with data zero

573
00:34:16,590 --> 00:34:18,030
so what now

574
00:34:18,070 --> 00:34:21,610
is the magnetic flux

575
00:34:21,640 --> 00:34:23,090
this is my look

576
00:34:23,150 --> 00:34:25,970
i have to commit myself to surface

577
00:34:26,050 --> 00:34:29,530
well i'll just use this flat surface

578
00:34:29,580 --> 00:34:33,100
just like i did they i chose the flat surface

579
00:34:33,200 --> 00:34:38,280
i'm free to choose any surface by not taking the flat one

580
00:34:38,280 --> 00:34:41,440
and so the flux through that flat surface

581
00:34:41,570 --> 00:34:44,740
is there the area which is x times a

582
00:34:44,790 --> 00:34:46,090
x times y

583
00:34:46,090 --> 00:34:47,790
that's the area

584
00:34:47,840 --> 00:34:50,040
of these look

585
00:34:50,100 --> 00:34:51,900
and that i have

586
00:34:51,900 --> 00:34:57,960
in in the in the juggling usually learning machine learning general john fourteen classifier ignored

587
00:34:57,960 --> 00:35:01,300
know this is called the model

588
00:35:01,400 --> 00:35:05,590
this is called the model and

589
00:35:05,610 --> 00:35:08,480
if x is uniform

590
00:35:08,500 --> 00:35:12,540
which is often useful if you want to go

591
00:35:12,550 --> 00:35:16,550
this the margin is just the

592
00:35:16,610 --> 00:35:22,270
if x is unique nor the margin is just the distance

593
00:35:22,320 --> 00:35:26,960
you can see from this inner product is just the distance between

594
00:35:26,960 --> 00:35:32,650
x and the hyperplane defined by w

595
00:35:40,150 --> 00:35:44,860
either way you want to see i i i mean i can think of executing

596
00:35:45,980 --> 00:35:48,460
and then that is because the market

597
00:35:48,630 --> 00:35:55,440
OK you know you can the

598
00:35:55,460 --> 00:35:59,380
you can think of none of them scale this is another definition of margin

599
00:36:06,860 --> 00:36:13,900
good so now let's see so if the margin is negative nine make mistakes so

600
00:36:13,940 --> 00:36:16,440
if you make a mistake then you would like

601
00:36:16,480 --> 00:36:20,750
to make the matters more positive on that same example that cause you to make

602
00:36:20,750 --> 00:36:25,880
a mistake with the current classifier so got it how the model changes after we

603
00:36:25,880 --> 00:36:27,110
made enough

604
00:36:27,130 --> 00:36:28,590
on the same example

605
00:36:28,590 --> 00:36:30,500
now let's look at the margin why

606
00:36:35,440 --> 00:36:38,250
x p

607
00:36:38,360 --> 00:36:41,980
so this is what you see is the margin of the same pair

608
00:36:42,040 --> 00:36:46,960
but WP is that WP minus one with WP has been computed according to this

609
00:36:46,960 --> 00:36:50,590
rule but this is pretty creek CA

610
00:36:51,360 --> 00:36:55,090
why the w three minus one

611
00:36:55,110 --> 00:36:57,040
plus y p

612
00:36:57,050 --> 00:36:58,960
next you

613
00:37:04,690 --> 00:37:07,070
and this part of town

614
00:37:09,710 --> 00:37:16,250
why do you all think NYT that minus one for all x the

615
00:37:16,270 --> 00:37:21,440
last YTY squared is one

616
00:37:21,440 --> 00:37:23,320
so is

617
00:37:23,320 --> 00:37:24,670
just x the

618
00:37:24,710 --> 00:37:28,110
just suppose xt which is the norm squared

619
00:37:28,170 --> 00:37:34,150
so now you see that the update

620
00:37:35,110 --> 00:37:37,230
pensions increases the margin

621
00:37:37,230 --> 00:37:42,110
by an amount which is exactly the description of xt

622
00:37:42,130 --> 00:37:43,820
the weight

623
00:37:43,920 --> 00:37:49,840
so it this is not guaranteed to be stopped it doesn't is not fully correct

624
00:37:49,840 --> 00:37:52,000
doesn't guarantee that

625
00:37:52,000 --> 00:37:56,730
if you see the same example again you're going to be correct going to classify

626
00:37:59,130 --> 00:38:00,940
it goes in the right direction

627
00:38:01,000 --> 00:38:06,340
because it had the negative the negative margin driven by post or

628
00:38:07,300 --> 00:38:08,570
so now

629
00:38:11,090 --> 00:38:13,690
you may

630
00:38:13,710 --> 00:38:17,540
you may wonder how we are interested in seeing something more

631
00:38:17,550 --> 00:38:19,400
useful about the properties of the guy

632
00:38:19,610 --> 00:38:21,860
the the

633
00:38:21,920 --> 00:38:25,900
so let's look at so suppose

634
00:38:27,090 --> 00:38:31,750
so now i suppose that we

635
00:38:31,780 --> 00:38:37,550
the first the first question to ask is is the following OK suppose that we

636
00:38:37,550 --> 00:38:38,360
have now

637
00:38:39,820 --> 00:38:42,340
which is really not separable

638
00:38:43,320 --> 00:38:45,230
suppose now that we have

639
00:38:45,270 --> 00:38:48,520
find extreme

640
00:38:48,550 --> 00:38:58,070
and this is linear linearly separable

641
00:38:58,110 --> 00:39:00,090
it means that

642
00:39:00,130 --> 00:39:02,440
which means that there exists some u

643
00:39:02,500 --> 00:39:07,610
such that

644
00:39:07,650 --> 00:39:10,150
why he

645
00:39:11,190 --> 00:39:13,130
thanks the

646
00:39:13,150 --> 00:39:16,130
always begins zero

647
00:39:16,170 --> 00:39:19,480
for all

648
00:39:19,750 --> 00:39:23,800
means that some of the plane such that

649
00:39:23,820 --> 00:39:28,380
all the positive examples in the stream dataset lying on one side and on the

650
00:39:28,400 --> 00:39:33,230
negative examples lying on the other side note now

651
00:39:33,250 --> 00:39:38,250
you may assume that you would want to ask what happens if i

652
00:39:38,250 --> 00:39:40,770
cycle disagree on this

653
00:39:41,840 --> 00:39:43,420
all right if i run

654
00:39:43,440 --> 00:39:45,440
this protocol over and over

655
00:39:45,480 --> 00:39:50,730
it will be hard to find a linear separator

656
00:39:50,750 --> 00:39:55,480
and if it doesn't find policy so i mean how many times i have

657
00:39:55,500 --> 00:40:01,270
make an update to find out the minister

658
00:40:02,770 --> 00:40:06,610
none this this is the linear programming problem

659
00:40:08,770 --> 00:40:11,420
so you want to find actually

660
00:40:11,460 --> 00:40:15,800
you only have a set of constraints you want to find a point

661
00:40:15,800 --> 00:40:16,730
in b the

662
00:40:16,730 --> 00:40:22,610
in the feasible region

663
00:40:22,610 --> 00:40:26,780
the objective function will come back to this little later so you might think you

664
00:40:26,780 --> 00:40:30,960
can solve this by using a linear programming package but this is a simple and

665
00:40:30,960 --> 00:40:33,270
incremental way of farming

666
00:40:33,280 --> 00:40:38,550
so it is not the biggest problem but it deal really is having a very

667
00:40:38,550 --> 00:40:39,980
simple way

668
00:40:39,980 --> 00:40:44,960
of the weight and being able to analyse it in in

669
00:40:44,980 --> 00:40:48,300
in a simple way is what it's all

670
00:40:48,300 --> 00:40:50,360
so that's find any such u

671
00:40:50,360 --> 00:40:59,720
in this talk i will introduce the problem the problem is and what is the

672
00:40:59,720 --> 00:41:01,950
importance of this problem

673
00:41:01,970 --> 00:41:04,020
and then i'll talk about the

674
00:41:04,050 --> 00:41:08,040
model which we have proposed the challenges she faced by this morning

675
00:41:08,090 --> 00:41:13,450
and the experiments how evil the experiment was the setting for the experiments and results

676
00:41:13,450 --> 00:41:14,360
which you can

677
00:41:14,380 --> 00:41:17,790
and some future work

678
00:41:17,910 --> 00:41:22,800
but fifteen years computers and that have revolutionized the communication people can connect with each

679
00:41:23,380 --> 00:41:26,730
across different time zones with the geographical barriers

680
00:41:26,810 --> 00:41:32,200
and this has created a human this measure of social interactions which is call the

681
00:41:32,230 --> 00:41:34,020
social network

682
00:41:34,050 --> 00:41:35,450
as you can see in the

683
00:41:36,800 --> 00:41:38,330
there are different services

684
00:41:38,370 --> 00:41:41,850
which revolves around the world a better name

685
00:41:41,870 --> 00:41:43,630
which has been catalyzed

686
00:41:43,630 --> 00:41:45,270
this communication

687
00:41:45,350 --> 00:41:51,140
and by the use of user interface and the stuff like experience these services like

688
00:41:51,140 --> 00:41:53,760
friendship networks blogs wikis

689
00:41:53,770 --> 00:41:57,280
collaborative tagging and media sharing

690
00:41:57,300 --> 00:42:01,000
in our research focus blogsphere

691
00:42:01,020 --> 00:42:04,060
block says could be individual or community

692
00:42:04,110 --> 00:42:09,500
four individual blog sites these at all and maintained by individual users as compared to

693
00:42:09,500 --> 00:42:14,890
committee blocks shown in writing by a group of like minded users

694
00:42:14,890 --> 00:42:19,650
and the community blog sites more like discussion forums and discussion boards you can see

695
00:42:19,650 --> 00:42:22,780
a high degree of group discussion and collaboration

696
00:42:22,800 --> 00:42:27,310
there is an individual blog sites there are more like personal account you know that

697
00:42:27,410 --> 00:42:30,910
is an almost negligible group interaction

698
00:42:30,940 --> 00:42:33,970
we focus on community blog sites

699
00:42:34,000 --> 00:42:37,550
to find these influential bloggers

700
00:42:37,560 --> 00:42:43,750
it's considered of physical set scenario where you are trying to buy a digital camera

701
00:42:43,750 --> 00:42:47,280
if you want to supercool gamma with all these great features

702
00:42:47,330 --> 00:42:51,340
so in the physical world what you do is you go to an expert on

703
00:42:51,380 --> 00:42:53,830
your talk to your friends who

704
00:42:53,840 --> 00:42:57,140
get the reviews and feedback about this problem

705
00:42:57,920 --> 00:42:59,830
in virtual world you

706
00:42:59,850 --> 00:43:05,150
world online community and try to find out the feedbacks of this problem

707
00:43:06,650 --> 00:43:10,950
now there's so many communities online in so many users they're giving the feedback about

708
00:43:10,980 --> 00:43:13,010
this product so

709
00:43:13,050 --> 00:43:20,860
which one you should go was feedback should follow that is the main problems

710
00:43:20,920 --> 00:43:24,350
so here we introduce this problem

711
00:43:24,400 --> 00:43:29,800
inspired by the analogy between this real world and blog communities we tried to answer

712
00:43:31,400 --> 00:43:33,170
influential bloggers

713
00:43:33,230 --> 00:43:36,300
and who are these can we find them

714
00:43:37,120 --> 00:43:42,860
just active bloggers and influential bloggers for the difference between them and

715
00:43:42,900 --> 00:43:45,930
can active bloggers influential influential bloggers b

716
00:43:45,950 --> 00:43:49,330
active all these sort of questions

717
00:43:49,480 --> 00:43:54,010
other applications for influential bloggers could be

718
00:43:54,020 --> 00:43:59,010
that they could be more cynical easy spread the word about the product

719
00:43:59,020 --> 00:44:03,740
and they could sway opinions in government policy and campaigns

720
00:44:04,740 --> 00:44:09,110
the customers they could be really helpful in customer support and troubleshooting

721
00:44:09,900 --> 00:44:14,890
i have really valuable feedback the products which can be used different companies for market

722
00:44:14,890 --> 00:44:16,140
research surveys

723
00:44:16,300 --> 00:44:20,600
and technorati published a report which said that there are eighteen point six new blog

724
00:44:20,600 --> 00:44:26,360
posts which appear every second so you need to find a representative always so that

725
00:44:26,360 --> 00:44:29,050
you can look at the end it's just not possible to look at all the

726
00:44:29,920 --> 00:44:35,550
so these influential blog posts could be the representative articles

727
00:44:36,710 --> 00:44:38,850
searching the influentials

728
00:44:38,990 --> 00:44:45,110
as i mentioned we have

729
00:44:45,110 --> 00:44:50,150
active bloggers and we have infringed bloggers an active blogger is easy to define the

730
00:44:50,150 --> 00:44:54,360
based just on the volume of postings he has

731
00:44:54,400 --> 00:44:57,430
and these are often listed on the blog sites

732
00:44:58,510 --> 00:45:03,270
i don't necessarily influential that's what we want to find out and according find influential

733
00:45:04,580 --> 00:45:06,330
by the

734
00:45:06,760 --> 00:45:08,470
posts he has submitted

735
00:45:08,480 --> 00:45:11,440
obviously it's a very subjective concept

736
00:45:11,460 --> 00:45:15,940
what kind of statistics can be collected and how we can use these statistics to

737
00:45:15,940 --> 00:45:18,550
give the influence of this blogger

738
00:45:18,570 --> 00:45:21,990
and actually we use

739
00:45:22,050 --> 00:45:25,620
four different statistic which we call social gestures

740
00:45:25,650 --> 00:45:31,740
first is the recognition which is given by the incoming links on the citations

741
00:45:31,760 --> 00:45:36,840
the more influential the referring posts are the more influential the referred forwards becomes

742
00:45:36,850 --> 00:45:42,660
an influential bloggers replaced by a lot of other bloggers answers again is activity generation

743
00:45:42,660 --> 00:45:45,310
which is basically the volume of discussion e

744
00:45:45,350 --> 00:45:48,860
it generates which is given by the number of comments he opens on this blog

745
00:45:50,230 --> 00:45:53,860
the third is minority which is basically the

746
00:45:54,900 --> 00:46:00,240
number of outlinks he's using the point in order it is

747
00:46:00,250 --> 00:46:06,550
we have done study is all ideas exert more influence so if the idea is

748
00:46:06,550 --> 00:46:07,860
not really

749
00:46:09,420 --> 00:46:11,070
it might not be very influential

750
00:46:11,090 --> 00:46:13,610
so we give this by the number of for

751
00:46:13,620 --> 00:46:17,550
o thing sees using some of the large number of outlinks suggests that the blog

752
00:46:17,550 --> 00:46:21,620
post refers to several other blog posts hence less knowledge

753
00:46:21,670 --> 00:46:25,550
in words which is basically hollywood blockbusters

754
00:46:25,600 --> 00:46:29,350
right now using the length of the block was but there can be several other

755
00:46:29,350 --> 00:46:31,610
measures like linguistic analysis

756
00:46:31,620 --> 00:46:33,210
you can use to gauge the

757
00:46:33,220 --> 00:46:35,940
how good this blog post is

758
00:46:35,960 --> 00:46:40,720
when you combine these different social justice and then come up with the influence score

759
00:46:40,740 --> 00:46:43,570
four about post

760
00:46:43,680 --> 00:46:49,500
OK can have the wiki

761
00:46:49,510 --> 00:46:51,430
or or

762
00:46:51,460 --> 00:46:55,760
measure goodness to play for me i thought i would prefer the smaller blog entries

763
00:46:56,050 --> 00:46:59,920
concerning the abolition of the blog posts so you don't have an incentive to write

764
00:46:59,920 --> 00:47:04,310
longer blog posts so if you're writing a lot of content that means you have

765
00:47:04,310 --> 00:47:09,740
some insight is undertaken got lot some text and that could harm the more and

766
00:47:11,860 --> 00:47:15,530
as you can see in the for for the slaves we have various parameters one

767
00:47:15,530 --> 00:47:21,160
of its these parameters are can use these routes to adjust these parameters the contribution

768
00:47:21,160 --> 00:47:21,660
any better

769
00:47:22,200 --> 00:47:25,280
when we see all colors proposal later brain

770
00:47:25,860 --> 00:47:26,180
that's why

771
00:47:28,260 --> 00:47:29,470
it is not true

772
00:47:30,650 --> 00:47:32,680
it's the surface of the outcome

773
00:47:33,050 --> 00:47:33,590
only read

774
00:47:34,450 --> 00:47:34,880
and here

775
00:47:37,300 --> 00:47:37,740
that's what

776
00:47:38,340 --> 00:47:39,630
we say nothing of course

777
00:47:40,490 --> 00:47:44,030
should be second with that so think that you can see

778
00:47:45,800 --> 00:47:48,990
and so in here the light is polarized in this election

779
00:47:49,450 --> 00:47:51,400
you be polarized this reaction

780
00:47:51,840 --> 00:47:53,240
and i can show that this power

781
00:47:54,550 --> 00:47:58,050
i have here polarizing sheet just the way you have said you can use your now

782
00:47:58,840 --> 00:47:59,680
and you see here

783
00:48:00,930 --> 00:48:02,820
i let the light through a polarizer

784
00:48:06,300 --> 00:48:09,400
killed almost all the light i think it's close to ninety eight percent are

785
00:48:10,380 --> 00:48:11,090
the same year

786
00:48:12,010 --> 00:48:13,030
and let the light through

787
00:48:15,180 --> 00:48:15,820
and i rotate

788
00:48:16,990 --> 00:48:21,760
you see i killed the line so that means that right in this direction the direction of polarization of tissue

789
00:48:22,610 --> 00:48:23,050
it's like so

790
00:48:24,180 --> 00:48:24,550
and here

791
00:48:25,860 --> 00:48:27,090
polarized this addiction

792
00:48:28,820 --> 00:48:29,400
cannot like this

793
00:48:31,930 --> 00:48:33,300
so you're not looking at the rainbow

794
00:48:34,300 --> 00:48:35,360
that you're looking at something

795
00:48:36,130 --> 00:48:37,900
it has all the ingredients in it

796
00:48:38,860 --> 00:48:39,420
that explain

797
00:48:50,740 --> 00:48:52,110
the next time you see a rainbow

798
00:48:54,130 --> 00:48:54,660
it will look

799
00:48:55,220 --> 00:48:56,260
very differently to you

800
00:48:58,130 --> 00:48:59,360
i predict that you will check

801
00:49:00,450 --> 00:49:02,110
whether the red indeed is only outside

802
00:49:03,420 --> 00:49:04,050
it's a disease

803
00:49:07,240 --> 00:49:09,150
and i can no longer cure the disease

804
00:49:11,920 --> 00:49:12,800
and note of the can

805
00:49:13,920 --> 00:49:15,420
you also try to find the second

806
00:49:16,740 --> 00:49:20,610
are you will check the call sequence of the second very different from the primary

807
00:49:22,990 --> 00:49:26,880
and what you will probably do if you have a linear polarizer on which you should

808
00:49:27,550 --> 00:49:30,030
you will probably want to check the polarisation is kind

809
00:49:31,220 --> 00:49:32,280
which is quite remarkable

810
00:49:33,950 --> 00:49:35,420
and all the joy and fun

811
00:49:36,150 --> 00:49:39,050
you'll get over and above the everlasting beauty of the bauhaus

812
00:49:39,680 --> 00:49:40,630
you will see much more

813
00:49:41,680 --> 00:49:45,760
then people will not have this knowledge and experience is therefore necessarily

814
00:49:46,610 --> 00:49:47,300
rather shallow

815
00:49:48,780 --> 00:49:50,650
new knowledge heads it never

816
00:49:51,220 --> 00:49:52,320
every set facts

817
00:49:56,630 --> 00:49:57,320
i want to change

818
00:49:58,320 --> 00:50:00,340
direction and finish this lecture with

819
00:50:01,660 --> 00:50:02,920
talking about sunsets

820
00:50:04,740 --> 00:50:06,360
ask the question why the sky blue

821
00:50:07,340 --> 00:50:08,800
and why sunsets red

822
00:50:13,900 --> 00:50:14,650
the sky is blue

823
00:50:15,610 --> 00:50:16,820
four very simple reason

824
00:50:18,070 --> 00:50:18,860
that in our sky

825
00:50:20,970 --> 00:50:22,610
are very small dust particles

826
00:50:25,510 --> 00:50:26,050
and even

827
00:50:30,070 --> 00:50:32,950
density fluctuations of the air molecules themselves

828
00:50:33,990 --> 00:50:34,650
and the lights

829
00:50:35,200 --> 00:50:36,300
can scan all those

830
00:50:39,610 --> 00:50:43,200
has nothing to do with the geometric optics scattering phenomenon

831
00:50:44,300 --> 00:50:45,930
and if these particles are very small

832
00:50:46,450 --> 00:50:47,800
talking about micron

833
00:50:48,320 --> 00:50:49,430
few microns at most

834
00:50:50,550 --> 00:50:51,740
then the probability

835
00:50:52,450 --> 00:50:52,920
that light

836
00:50:53,950 --> 00:50:54,470
this get

837
00:50:55,550 --> 00:50:58,610
is inversely proportional to the wavelength of the light

838
00:50:59,180 --> 00:51:00,380
the power forward

839
00:51:01,110 --> 00:51:02,400
and in physics books

840
00:51:03,240 --> 00:51:03,740
we call this

841
00:51:04,150 --> 00:51:04,780
ratings can

842
00:51:07,360 --> 00:51:10,610
now blue light has a much shorter wavelength than red light

843
00:51:13,260 --> 00:51:17,970
and so if you take the ratio of the wavelength of red and blue raised to the power forward

844
00:51:18,450 --> 00:51:20,320
depending on what you choose for the wavelength

845
00:51:20,920 --> 00:51:21,680
you get about seven

846
00:51:22,150 --> 00:51:22,860
so the blue light

847
00:51:23,400 --> 00:51:27,110
sportscenter about seven times more likely to scatter then the red

848
00:51:28,130 --> 00:51:28,930
anywhere from five

849
00:51:29,590 --> 00:51:29,920
to ten

850
00:51:32,340 --> 00:51:33,050
so imagine now

851
00:51:34,860 --> 00:51:35,630
here on the ground

852
00:51:36,990 --> 00:51:37,800
here's the atmosphere

853
00:51:39,260 --> 00:51:40,840
and let's say the sun is in this direction

854
00:51:41,570 --> 00:51:42,380
so light comes in

855
00:51:43,380 --> 00:51:44,260
it's the atmosphere here

856
00:51:47,340 --> 00:51:48,050
you're standing you

857
00:51:51,400 --> 00:51:51,920
this light

858
00:51:53,720 --> 00:51:54,610
enters the atmosphere

859
00:51:55,380 --> 00:51:56,760
the only way it can continue

860
00:51:57,680 --> 00:51:59,320
if only scattering process

861
00:52:00,950 --> 00:52:02,920
and so there is some light comes to which

862
00:52:05,840 --> 00:52:07,110
very likely that that's true

863
00:52:08,400 --> 00:52:10,470
because it has seven times higher probability

864
00:52:11,300 --> 00:52:11,630
be blue

865
00:52:12,070 --> 00:52:12,430
and read

866
00:52:13,530 --> 00:52:14,570
but not only would it be

867
00:52:15,470 --> 00:52:17,280
blue in this election but this slide here

868
00:52:17,930 --> 00:52:18,720
also sceptics

869
00:52:19,010 --> 00:52:19,470
also comes

870
00:52:20,650 --> 00:52:24,090
and so the blue is highly favored over the on colors in the spectrum

871
00:52:25,110 --> 00:52:26,220
and that's in a nutshell

872
00:52:26,920 --> 00:52:27,380
the reason

873
00:52:28,570 --> 00:52:28,860
this guy

874
00:52:29,400 --> 00:52:29,950
is broken

875
00:52:30,930 --> 00:52:31,800
it is essential though

876
00:52:32,840 --> 00:52:35,720
that's particles which scattering takes place

877
00:52:36,180 --> 00:52:36,650
is small

878
00:52:37,150 --> 00:52:38,070
preferably one

879
00:52:38,570 --> 00:52:39,360
what to microns

880
00:52:40,530 --> 00:52:43,630
if the particles become larger they tend microns like

881
00:52:44,030 --> 00:52:45,860
small water drops in clouds

882
00:52:46,450 --> 00:52:48,720
and there is no preferred wavelength anymore

883
00:52:49,150 --> 00:52:51,660
what becomes independent of the wavelength lambda

884
00:52:52,320 --> 00:52:54,180
that's the reason why clouds are white

885
00:52:56,970 --> 00:52:57,840
because all the cars

886
00:52:58,340 --> 00:53:00,720
have a similar same roughly the same probability

887
00:53:01,400 --> 00:53:01,990
to be scattered

888
00:53:05,530 --> 00:53:09,010
i'm going to tell you before i do a demonstration to show you the blue color

889
00:53:10,360 --> 00:53:11,930
i wanna tell you something that i will not

890
00:53:13,720 --> 00:53:14,510
some of you may know

891
00:53:15,990 --> 00:53:16,570
but i want you to

892
00:53:16,970 --> 00:53:17,630
no the fact

893
00:53:19,530 --> 00:53:20,400
if the lights

894
00:53:20,680 --> 00:53:22,990
scanners over an angle of ninety degrees

895
00:53:24,240 --> 00:53:25,680
this approximately the case here

896
00:53:27,090 --> 00:53:30,050
then the that this scattered is also a hundred percent polarized

897
00:53:30,970 --> 00:53:33,050
nothing to do with bruce like totally different from

898
00:53:34,720 --> 00:53:37,860
and the reason why i mentioned that because now you can actually start testing your

899
00:53:37,920 --> 00:53:40,470
polarizes experiment i going to do

900
00:53:41,590 --> 00:53:44,970
if it is not carried over ninety degrees it is partially polarized

901
00:53:45,990 --> 00:53:46,430
a little bit

902
00:53:47,320 --> 00:53:48,780
until the end of the ninety degrees

903
00:53:49,550 --> 00:53:53,360
strongly polarized so that means when you walk outside after my lectures

904
00:53:54,160 --> 00:53:56,260
you look at the blue sky let's assume it is blue

905
00:53:57,280 --> 00:54:00,680
and you look ninety degrees away from the sun which is a great circle in the sky

906
00:54:01,180 --> 00:54:02,110
you can pick any point

907
00:54:02,780 --> 00:54:05,470
you look very see by rotating a little polarimeter

908
00:54:06,130 --> 00:54:07,760
that light is almost hundred per cent

909
00:54:09,800 --> 00:54:11,990
but it's an extra bonus i want you to have

910
00:54:12,800 --> 00:54:14,800
to appreciate the demonstration that is coming up

911
00:54:17,820 --> 00:54:18,550
in astronomy

912
00:54:19,530 --> 00:54:19,840
we see

913
00:54:20,630 --> 00:54:21,320
this blue light

914
00:54:22,720 --> 00:54:24,450
often from stars we don't

915
00:54:26,030 --> 00:54:26,400
have any

916
00:54:26,990 --> 00:54:28,070
dominance in blue lines

917
00:54:28,780 --> 00:54:29,950
very bright stars

918
00:54:29,950 --> 00:54:33,680
has the water that there are not given that

919
00:54:33,690 --> 00:54:37,390
i so that the loan was what

920
00:54:39,590 --> 00:54:41,870
you can compute that using

921
00:54:42,020 --> 00:54:47,160
these probabilities will obtain zero point forty tree

922
00:54:47,210 --> 00:54:49,370
however if i now no

923
00:54:50,140 --> 00:54:52,170
it has rain or not

924
00:54:52,180 --> 00:54:56,210
let's say that i know that it has range then the probability

925
00:54:56,240 --> 00:54:59,090
the sprinkler is on given that

926
00:54:59,110 --> 00:55:00,790
the grass is wet and

927
00:55:00,810 --> 00:55:02,200
it has range

928
00:55:02,210 --> 00:55:07,010
it's it which also can be computed using these properties

929
00:55:07,060 --> 00:55:10,010
it's much more

930
00:55:10,030 --> 00:55:12,610
which goes with our intuition that

931
00:55:12,610 --> 00:55:14,250
if i know that has range

932
00:55:15,060 --> 00:55:20,940
now the property that's my neighbours have watered down on it's much lower

933
00:55:20,970 --> 00:55:26,060
so that's the phenomenon called explaining away so if i see ISO

934
00:55:26,090 --> 00:55:26,880
i see

935
00:55:26,880 --> 00:55:32,320
one the child then this is to become dependent and sewing

936
00:55:32,380 --> 00:55:34,770
seeing that one of the two

937
00:55:34,980 --> 00:55:38,510
will influence the computation of

938
00:55:38,530 --> 00:55:41,970
of the probability of the other

939
00:55:44,830 --> 00:55:51,420
this now and have shown this conditional independence seen on move

940
00:55:51,620 --> 00:55:53,420
this small tree

941
00:55:56,730 --> 00:55:58,610
this can be generalised to

942
00:55:59,710 --> 00:56:03,460
any sets of not so this time we have like

943
00:56:03,510 --> 00:56:07,180
conditional independence between sets of nodes is given

944
00:56:07,190 --> 00:56:09,880
as set of nodes

945
00:56:13,800 --> 00:56:15,620
so let's have

946
00:56:15,640 --> 00:56:20,260
the poetry set of nodes a b and c

947
00:56:20,440 --> 00:56:24,280
so for example here i think a as being a

948
00:56:24,290 --> 00:56:25,620
b is being b

949
00:56:25,690 --> 00:56:27,260
and see as being

950
00:56:27,280 --> 00:56:30,990
the rest of the of the graph

951
00:56:33,930 --> 00:56:35,920
the property of this

952
00:56:35,950 --> 00:56:37,840
separation so i is

953
00:56:37,880 --> 00:56:39,180
is said to be

954
00:56:39,190 --> 00:56:40,790
the separated from b

955
00:56:40,820 --> 00:56:42,260
by c

956
00:56:42,280 --> 00:56:46,050
if each bus from a to b is blocked

957
00:56:46,060 --> 00:56:47,170
that is

958
00:56:47,200 --> 00:56:48,310
but there is

959
00:56:48,370 --> 00:56:50,540
at least one and in the past

960
00:56:51,170 --> 00:56:52,440
such that

961
00:56:52,460 --> 00:56:53,720
now that is

962
00:56:53,810 --> 00:56:56,630
head to tail or to tail

963
00:56:56,630 --> 00:56:58,190
in the bus

964
00:56:58,210 --> 00:57:01,410
and the another is in c for example

965
00:57:02,170 --> 00:57:03,790
this one

966
00:57:05,870 --> 00:57:07,940
is the

967
00:57:09,610 --> 00:57:12,440
data tail

968
00:57:14,300 --> 00:57:16,730
he's not observed

969
00:57:17,880 --> 00:57:19,190
that's makes

970
00:57:19,200 --> 00:57:21,430
that makes these two

971
00:57:24,770 --> 00:57:27,690
not independent

972
00:57:27,700 --> 00:57:33,150
or the other the other possibility that we say that

973
00:57:33,820 --> 00:57:38,960
any passes block from the from a to b is block is to say that

974
00:57:38,970 --> 00:57:42,530
there is another in the past so that he can e

975
00:57:42,580 --> 00:57:44,960
who is head to head node

976
00:57:46,890 --> 00:57:52,360
nader not nor any of his descendants so and you know we're not is in

977
00:57:55,090 --> 00:57:58,170
here we have again this example e

978
00:57:58,180 --> 00:58:00,980
blocks also the bus

979
00:58:01,000 --> 00:58:03,260
does it look

980
00:58:03,980 --> 00:58:06,630
no because we have an observation

981
00:58:06,630 --> 00:58:12,870
so one of the descendants is observed so as we've seen before we have explaining

982
00:58:15,880 --> 00:58:20,940
in which seeing these make that a and b are dependent

983
00:58:20,960 --> 00:58:25,610
well in this second graph

984
00:58:25,660 --> 00:58:29,830
f is observed which makes that he's

985
00:58:31,430 --> 00:58:32,580
his blocking

986
00:58:33,560 --> 00:58:38,890
the past between a and b and this in this graph is a observe

987
00:58:41,560 --> 00:58:44,710
then a is conditional independence

988
00:58:44,730 --> 00:58:49,650
of the given the rest of the variables

989
00:58:51,440 --> 00:58:53,430
this usually because

990
00:58:53,430 --> 00:58:56,680
this is useful i mean because you can write

991
00:58:56,730 --> 00:58:57,940
you can see

992
00:58:57,970 --> 00:59:00,430
the set take a set of variables

993
00:59:03,700 --> 00:59:04,800
the rest of

994
00:59:04,860 --> 00:59:09,930
the variables conditioned on this one which helps in in

995
00:59:09,970 --> 00:59:11,680
and computation

996
00:59:11,720 --> 00:59:14,930
most among mosses is that it

997
00:59:18,630 --> 00:59:20,050
OK so

998
00:59:20,070 --> 00:59:22,310
examples which you know

999
00:59:22,320 --> 00:59:25,620
and which used this this this separation

1000
00:59:26,140 --> 00:59:31,680
this conditional independence property as are for example a face

1001
00:59:32,550 --> 00:59:33,260
in which

1002
00:59:33,270 --> 00:59:36,040
you say that you have example in

1003
00:59:38,360 --> 00:59:40,270
real examples of of

1004
00:59:40,290 --> 00:59:42,130
d component

1005
00:59:42,130 --> 00:59:44,010
and the lord said that

1006
00:59:44,040 --> 00:59:48,430
we have two class classification naive bayes

1007
00:59:48,470 --> 00:59:52,770
and let z be the random variable representing the classes

1008
00:59:54,340 --> 00:59:56,240
we want to take the decision

1009
00:59:56,250 --> 00:59:59,820
what is naive bayes taking the decision that

1010
01:00:00,020 --> 01:00:03,690
four for a new example the class

1011
01:00:03,690 --> 01:00:05,680
is the

1012
01:00:05,760 --> 01:00:09,430
is the one that gives me the maximum

1013
01:00:09,470 --> 01:00:11,550
of the

1014
01:00:11,620 --> 01:00:15,610
the joint probability of the examples time

1015
01:00:15,620 --> 01:00:16,940
the class

1016
01:00:18,480 --> 01:00:20,370
this can be decomposed

1017
01:00:20,480 --> 01:00:25,390
no money as it just using for the word for the

1018
01:00:25,430 --> 01:00:29,790
as the probability of the input given the class time the property of the class

1019
01:00:30,060 --> 01:00:31,390
and what's

1020
01:00:31,460 --> 01:00:35,340
what's the the naive bayes assumption is

1021
01:00:35,440 --> 01:00:37,500
as it can be seen here in the graph

1022
01:00:37,500 --> 01:00:39,370
do better than x one

1023
01:00:39,460 --> 01:00:43,370
so one particular type of structure you might want to have this band limited is

1024
01:00:44,400 --> 01:00:46,810
but you could also be sparse in some domain

1025
01:00:47,040 --> 01:00:53,310
now nyquist version number two would then be to say oh the band limited sparse

1026
01:00:53,310 --> 01:00:56,060
but otherwise let us be completely random

1027
01:00:56,070 --> 01:00:57,340
so only sparse

1028
01:00:57,350 --> 01:01:01,450
no other the structure and then again you really cannot do better than x two

1029
01:01:01,460 --> 01:01:08,050
this is smaller than x one and this is a really nice and important result

1030
01:01:08,090 --> 01:01:12,200
but i would argue that i guess we're not quite there yet because natural images

1031
01:01:12,210 --> 01:01:17,120
and probably also all sorts of other real-world signals i mean they're probably bandlimited i

1032
01:01:17,120 --> 01:01:22,030
mean at least you're going to you information that this young band

1033
01:01:22,040 --> 01:01:25,500
there are also approximately sparse that's why many

1034
01:01:25,520 --> 01:01:28,750
you know coding algorithms work

1035
01:01:28,840 --> 01:01:33,400
but beyond that they really have much more exploitable structure and that's what you can

1036
01:01:33,400 --> 01:01:37,520
probably also use to then even do better than x two for example in natural

1037
01:01:39,670 --> 01:01:40,820
and if you want to so

1038
01:01:40,840 --> 01:01:44,150
how this works and you just cannot prove it at the moment and you can

1039
01:01:44,150 --> 01:01:48,110
also do is sound empirical evaluation and then you know if you don't favor your

1040
01:01:48,110 --> 01:01:52,050
method in the in the in the way that i probably you can convince people

1041
01:01:52,050 --> 01:01:54,610
that this works

1042
01:01:54,620 --> 01:01:57,500
i guess that's what we did in our study

1043
01:01:57,520 --> 01:02:00,790
let me conclude

1044
01:02:00,800 --> 01:02:02,100
if we measure

1045
01:02:02,120 --> 01:02:06,220
real world things like natural images we have we should really be sure that you

1046
01:02:06,220 --> 01:02:08,960
know if we draw our design brand

1047
01:02:09,000 --> 01:02:10,270
using some

1048
01:02:10,280 --> 01:02:13,020
distribution like uniform that we actually

1049
01:02:13,030 --> 01:02:14,130
why these

1050
01:02:14,140 --> 01:02:20,030
the current axis and then we do convex simple convex reconstruction i mean we took

1051
01:02:20,030 --> 01:02:24,780
the lasso but you can also take basis pursuit of six select maybe a couple

1052
01:02:24,780 --> 01:02:28,790
of other methods on his way to the optimal in the sense that it meets

1053
01:02:28,800 --> 01:02:30,810
minimax lower bounds

1054
01:02:30,840 --> 01:02:33,100
which have been proven for sparse signals

1055
01:02:33,110 --> 01:02:36,520
all other things completely random

1056
01:02:38,220 --> 01:02:41,540
but then if you really working with natural images then you

1057
01:02:41,550 --> 01:02:45,520
i mean you can go to that of natural image statistics and they basically figure

1058
01:02:45,540 --> 01:02:50,510
out is that they are sparse approximately but actually that's much beyond sparsity which is

1059
01:02:50,510 --> 01:02:55,430
not random and which is actually pretty robust and that allows you to

1060
01:02:55,440 --> 01:03:00,920
so to do something which is basically impossible namely to robustly choose if it doesn't

1061
01:03:01,030 --> 01:03:05,690
much better than the next two for example

1062
01:03:05,700 --> 01:03:08,990
so here is one very important thing i don't know whether that really came across

1063
01:03:08,990 --> 01:03:09,940
so far

1064
01:03:09,960 --> 01:03:13,940
o method it's not that i'm just giving it all these prior information that people

1065
01:03:13,940 --> 01:03:17,970
know about images all method starts from exactly the same prior

1066
01:03:17,990 --> 01:03:20,740
estimation information there

1067
01:03:20,750 --> 01:03:22,490
the lasso reconstruction

1068
01:03:23,100 --> 01:03:28,200
it's exactly the same prior than what these guys take the lot prior for reconstruction

1069
01:03:28,420 --> 01:03:32,520
but the important difference is that it just takes that prior together with the likelihood

1070
01:03:32,520 --> 01:03:36,920
and it does more with it it's it's not only maximizing the posterior just a

1071
01:03:36,920 --> 01:03:37,940
little bit more

1072
01:03:37,960 --> 01:03:44,700
it's using the posterior to actually choose good measurement architecture

1073
01:03:44,710 --> 01:03:47,970
and i would say i mean i would conclude from from this study that

1074
01:03:48,010 --> 01:03:52,090
it can really help a lot if you optimize the measurement architecture for your domain

1075
01:03:52,090 --> 01:03:56,440
of interest i guess whether i can really only say that from natural images that's

1076
01:03:56,440 --> 01:03:58,200
my domain of interest but i would

1077
01:03:58,240 --> 01:04:00,910
conjectured that holds true for other domains

1078
01:04:00,920 --> 01:04:02,880
you can do that

1079
01:04:03,210 --> 01:04:07,150
with very little from prior knowledge

1080
01:04:07,690 --> 01:04:11,140
but but that really needs a little bit more than uniform random sampling you need

1081
01:04:11,150 --> 01:04:14,480
to do something which is experimental design i mean you just need to spend a

1082
01:04:14,480 --> 01:04:15,700
little bit more work

1083
01:04:15,750 --> 01:04:19,330
thinking about how you optimize to things

1084
01:04:21,850 --> 01:04:24,180
the last line

1085
01:04:24,190 --> 01:04:27,930
is that OK we did this in sixty four by sixty four images you can

1086
01:04:27,930 --> 01:04:31,480
scale this up some recent algorithms that work say images

1087
01:04:31,480 --> 01:04:33,420
including this kind of

1088
01:04:33,430 --> 01:04:36,570
sentence into some

1089
01:04:36,580 --> 01:04:39,160
and as we can

1090
01:04:39,190 --> 01:04:41,680
all unbounded others

1091
01:04:41,730 --> 01:04:44,330
has universally quantified so we can skip these

1092
01:04:44,740 --> 01:04:45,730
four also

1093
01:04:45,740 --> 01:04:47,970
have in this case

1094
01:04:47,990 --> 01:04:52,240
to say we just said if there's something is about do something

1095
01:04:52,760 --> 01:04:56,270
four or

1096
01:04:56,360 --> 01:04:59,530
and the type quantifiers is an existential

1097
01:04:59,690 --> 01:05:02,610
so there exists

1098
01:05:04,050 --> 01:05:06,390
he left his keys summaries

1099
01:05:07,350 --> 01:05:10,810
where the police are looking

1100
01:05:10,820 --> 01:05:12,910
example of this

1101
01:05:12,920 --> 01:05:14,430
how we write this cycle

1102
01:05:14,450 --> 01:05:15,750
so we use

1103
01:05:16,650 --> 01:05:18,420
there exist

1104
01:05:19,770 --> 01:05:21,430
same as before

1105
01:05:21,500 --> 01:05:24,160
that all this holds so

1106
01:05:24,170 --> 01:05:28,590
person this person is a person this person

1107
01:05:30,360 --> 01:05:32,810
it is located on this chart

1108
01:05:32,850 --> 01:05:36,110
so this is the same as this sentence here

1109
01:05:36,160 --> 01:05:38,120
is it in a rule

1110
01:05:38,180 --> 01:05:40,070
here it would be for example

1111
01:05:40,070 --> 01:05:42,600
the for all persons

1112
01:05:42,730 --> 01:05:45,880
that person is actually

1113
01:05:46,970 --> 01:05:49,340
there exist the lower so

1114
01:05:49,350 --> 01:05:50,870
lower level the first

1115
01:05:50,940 --> 01:05:53,500
so this

1116
01:05:53,550 --> 01:05:55,500
this would be a really

1117
01:05:55,600 --> 01:05:58,920
using an extension of twenty four

1118
01:05:58,920 --> 01:06:00,250
and they can be taken

1119
01:06:00,270 --> 01:06:07,140
it more for example consider exist exactly so must be exactly five instances

1120
01:06:07,150 --> 01:06:09,510
this decreased it and so on so

1121
01:06:09,530 --> 01:06:12,660
it's possible to elaborate on this

1122
01:06:12,660 --> 01:06:16,860
that's true because

1123
01:06:17,080 --> 01:06:26,970
if you can't cite walk

1124
01:06:27,010 --> 01:06:30,860
you've been following along the first

1125
01:06:31,880 --> 01:06:33,960
you all know

1126
01:06:33,980 --> 01:06:37,330
one of

1127
01:06:37,330 --> 01:06:55,270
a free for find between one finds that by the end of the soil

1128
01:06:55,280 --> 01:07:03,340
that this introduction to the cycle in which you may wonder why we're talking to

1129
01:07:03,380 --> 01:07:08,220
about the psychology language when you're going to be producing semantic

1130
01:07:08,240 --> 01:07:12,390
f of the stuff in you have using RDF and so forth well the main

1131
01:07:12,390 --> 01:07:14,340
reason is that it

1132
01:07:14,380 --> 01:07:20,370
o although this has some school this syntax it's a lot easier to understand

1133
01:07:20,450 --> 01:07:25,900
the so just in terms of dealing with the dealing with decisions

1134
01:07:26,010 --> 01:07:30,600
four to express in words and it's also useful to know

1135
01:07:30,660 --> 01:07:34,140
a little bit about attracting

1136
01:07:34,140 --> 01:07:37,140
inference productive content out of these

1137
01:07:37,220 --> 01:07:40,520
and so i come to terms

1138
01:07:41,280 --> 01:07:47,640
now i'm going to give you an overview of all things that are contained in

1139
01:07:47,640 --> 01:07:53,770
in inside and i think it was a little bit of time just connecting to

1140
01:07:53,770 --> 01:07:56,120
the site looking up some terms

1141
01:07:56,130 --> 01:08:01,260
see what's in there and see whether it's called the sort of content that you're

1142
01:08:01,280 --> 01:08:05,150
interested in the projects they before

1143
01:08:06,900 --> 01:08:09,570
all of it

1144
01:08:09,950 --> 01:08:15,720
has about ten thousand fifteen minutes

1145
01:08:15,740 --> 01:08:22,490
so things relating things to each other like this for example which can be used

1146
01:08:22,490 --> 01:08:28,650
to make statements like lights is friends with carbon carbonic or force

1147
01:08:29,070 --> 01:08:32,260
or false statements like like his friend

1148
01:08:34,610 --> 01:08:41,240
george w bush gore or universal statements about mccain like everybody is his friend for

1149
01:08:41,240 --> 01:08:42,490
these claims

1150
01:08:46,710 --> 01:08:53,240
and also three hundred thousand concepts which is listed cover of the terms that's generally

1151
01:08:53,240 --> 01:08:54,110
come up in

1152
01:08:54,510 --> 01:08:57,880
news articles and being

1153
01:08:57,880 --> 01:09:00,870
taking news articles with these terms recently

1154
01:09:00,880 --> 01:09:06,880
and about the musicians now most renowned musicians and in

1155
01:09:06,890 --> 01:09:07,830
the site

1156
01:09:07,900 --> 01:09:15,420
so what you get is the decisions which required to specify the text momentarily turns

1157
01:09:15,420 --> 01:09:18,960
and to give you the information about the sun had

1158
01:09:18,980 --> 01:09:25,350
why is the first and then amounts to i think about a million assertions not

1159
01:09:25,360 --> 01:09:30,440
many are in the full KB and in particular there are very few

1160
01:09:32,670 --> 01:09:36,280
the such called which make generalizations in

1161
01:09:36,330 --> 01:09:37,850
openside but

1162
01:09:39,770 --> 01:09:46,030
compatible with side so if you decide that you want reasoning then you can do

1163
01:09:46,030 --> 01:09:50,820
a inside the new can move up from the two research

1164
01:09:50,900 --> 01:09:54,670
do more complex complex reasoning

1165
01:09:56,240 --> 01:10:01,600
this is an overview of the types of knowledge in the knowledge base

1166
01:10:01,650 --> 01:10:08,630
about physical objects broken down say to living things and the living thing is about

1167
01:10:08,640 --> 01:10:13,840
the relationship between the pace of life forms and their relationships going down to

1168
01:10:13,860 --> 01:10:19,590
relationships in ecology the relationship between these organizations

1169
01:10:20,410 --> 01:10:21,980
and with their environment

1170
01:10:22,400 --> 01:10:27,900
and the environment as opposed to geography with

1171
01:10:27,980 --> 01:10:32,460
you know the content of the earth and the solar system and types of core

1172
01:10:32,460 --> 01:10:35,670
the kind of wave that you get is really not very much of a plane

1173
01:10:35,670 --> 01:10:37,790
wave we vision

1174
01:10:37,880 --> 01:10:39,610
the only case this

1175
01:10:39,610 --> 01:10:41,750
both goes to the moon

1176
01:10:41,790 --> 01:10:43,880
and then some of it comes back

1177
01:10:43,920 --> 01:10:46,230
reflected of these trader

1178
01:10:46,290 --> 01:10:49,500
corner reflectors and operators light

1179
01:10:49,540 --> 01:10:51,270
laser light

1180
01:10:51,330 --> 01:10:54,670
two times ten to the seventeenth photons roughly

1181
01:10:54,730 --> 01:10:57,840
in one of these policies only one

1182
01:10:57,900 --> 01:11:00,020
comes back to ten pulses

1183
01:11:00,110 --> 01:11:01,790
not much comes back

1184
01:11:01,790 --> 01:11:03,750
but it's enough if you integrate it

1185
01:11:03,770 --> 01:11:05,540
to get an accurate

1186
01:11:05,590 --> 01:11:08,560
this is the combination between us and the

1187
01:11:08,610 --> 01:11:10,460
corner reflectors in the

1188
01:11:10,540 --> 01:11:14,290
accuracy is about ten centimeters and the goal is really

1189
01:11:16,330 --> 01:11:21,610
handle on the precise orbit of the moon

1190
01:11:21,650 --> 01:11:25,360
i can show you this corner reflectors

1191
01:11:25,380 --> 01:11:26,810
the way they were

1192
01:11:26,810 --> 01:11:28,230
built on earth

1193
01:11:28,400 --> 01:11:33,210
and then i will also show you an optical observatory

1194
01:11:33,270 --> 01:11:35,020
as it is

1195
01:11:35,040 --> 01:11:36,560
sending out these

1196
01:11:36,570 --> 01:11:38,480
quarter nano-second pulses

1197
01:11:39,380 --> 01:11:40,840
laser light to

1198
01:11:40,860 --> 01:11:43,540
the money

1199
01:11:43,750 --> 01:11:48,960
so this is one of those

1200
01:11:49,000 --> 01:11:52,150
corner reflectors

1201
01:11:52,190 --> 01:11:54,250
they are designed in such a way that

1202
01:11:54,270 --> 01:11:56,790
if light strikes it

1203
01:11:56,810 --> 01:11:58,340
in a certain direction

1204
01:11:58,340 --> 01:12:03,020
that reflects the light in exactly the same direction back one hundred eighty degrees

1205
01:12:03,040 --> 01:12:05,710
very clever design

1206
01:12:05,730 --> 01:12:09,440
so the next slide will show you

1207
01:12:09,480 --> 01:12:11,070
in texas

1208
01:12:11,170 --> 01:12:13,560
mcdonald observatory

1209
01:12:13,570 --> 01:12:15,230
standing here

1210
01:12:16,540 --> 01:12:19,340
short brief pulses of laser light

1211
01:12:19,360 --> 01:12:21,440
to the moon

1212
01:12:21,500 --> 01:12:23,330
and what you see here is simply

1213
01:12:24,090 --> 01:12:28,130
kind of like of the dust in the atmosphere

1214
01:12:28,130 --> 01:12:31,340
and then only eighteen a little bit of that comes back with that is enough

1215
01:12:31,340 --> 01:12:32,840
to get the

1216
01:12:32,880 --> 01:12:35,560
distance to the moon

1217
01:12:35,670 --> 01:12:37,110
there are

1218
01:12:37,150 --> 01:12:38,440
on the moon

1219
01:12:38,500 --> 01:12:41,090
there's enough for this slide to

1220
01:12:42,520 --> 01:12:43,840
i on the moon

1221
01:12:43,860 --> 01:12:45,730
several cameras

1222
01:12:45,770 --> 01:12:48,830
they were left there by surveyor there's small cameras

1223
01:12:48,860 --> 01:12:52,070
the lens i think is only two inches across

1224
01:12:52,150 --> 01:12:56,270
and they keep an eye on the order of all the time

1225
01:12:56,310 --> 01:12:59,040
something that you may never have thought of

1226
01:12:59,090 --> 01:13:01,250
if you were on the moon

1227
01:13:01,420 --> 01:13:04,730
you look at the earth the the earth is there say

1228
01:13:04,730 --> 01:13:06,090
that an hour from now

1229
01:13:06,110 --> 01:13:07,750
it would still be there

1230
01:13:07,750 --> 01:13:11,730
and ten hours from now will still be there and ten years from now

1231
01:13:11,790 --> 01:13:15,570
it was will still be there as seen from the moon

1232
01:13:15,630 --> 01:13:18,880
never moved of course it rotates about its axis

1233
01:13:18,880 --> 01:13:20,190
you'll see that

1234
01:13:20,210 --> 01:13:24,690
we also see that certain parts of the earth at night and others are

1235
01:13:25,340 --> 01:13:29,500
that's different but it's always in the same direction so it's very easy for these

1236
01:13:29,500 --> 01:13:32,920
cameras to keep an eye on it so to speak or you have to do

1237
01:13:32,920 --> 01:13:34,630
is to aim them

1238
01:13:34,670 --> 01:13:39,690
in one direction you never have to change that direction

1239
01:13:39,860 --> 01:13:42,360
imagine that you and i will now on the moon

1240
01:13:42,400 --> 01:13:43,730
and we were looking

1241
01:13:44,650 --> 01:13:46,380
the earth

1242
01:13:46,560 --> 01:13:51,560
you for instance would seem curious as you see here

1243
01:13:51,640 --> 01:13:54,040
is north america

1244
01:13:54,110 --> 01:13:57,190
and this part of earth happens to be

1245
01:13:57,270 --> 01:13:58,250
very light

1246
01:13:58,420 --> 01:14:02,610
and here is the night

1247
01:14:02,770 --> 01:14:04,980
and this is the moment

1248
01:14:05,020 --> 01:14:06,790
that these cameras

1249
01:14:06,810 --> 01:14:08,520
are going to take a picture

1250
01:14:08,540 --> 01:14:12,330
of the earth so you expect to see a lot of light here

1251
01:14:12,340 --> 01:14:14,750
you expect this to be night

1252
01:14:14,840 --> 01:14:16,690
was no we are

1253
01:14:16,710 --> 01:14:17,880
you may think

1254
01:14:17,900 --> 01:14:20,630
there's so much light coming from new york

1255
01:14:20,670 --> 01:14:23,060
you may actually see new york that

1256
01:14:23,060 --> 01:14:27,560
so four types of distances in fact related to the to the first few

1257
01:14:27,660 --> 01:14:31,890
which is to you find this time an infinite

1258
01:14:31,910 --> 01:14:34,280
a set of measurable features

1259
01:14:34,310 --> 01:14:37,530
what's the point of looking for an infinite where we see a bit later but

1260
01:14:37,530 --> 01:14:40,200
for example if i look at all the possible

1261
01:14:40,280 --> 01:14:41,950
of subsequences

1262
01:14:41,950 --> 01:14:46,600
OK with the number of possible subsequences is infinite because it's a must or itself

1263
01:14:46,620 --> 01:14:51,280
so anyway for trying to count it on this feature space without having infinite feature

1264
01:14:51,280 --> 01:14:52,760
space even if for each

1265
01:14:52,830 --> 01:14:55,050
individual string

1266
01:14:55,060 --> 01:14:57,280
the number of

1267
01:14:57,330 --> 01:15:00,870
values different from zero is going to be finite

1268
01:15:00,890 --> 01:15:05,220
but still you don't have an infinity of possible infinity but at the same time

1269
01:15:05,220 --> 01:15:07,810
you can describe things as an infinite space

1270
01:15:07,850 --> 01:15:12,240
and you just do distances and if it's just you can define the distance of

1271
01:15:12,240 --> 01:15:15,080
the feature space and that's what you meant

1272
01:15:19,510 --> 01:15:20,450
and i just

1273
01:15:20,470 --> 01:15:24,680
give the edit distance and then they pass on to which we can

1274
01:15:24,700 --> 01:15:32,100
edit distance defined by of levenstein in nineteen sixty six and algorithms or typical algorithms

1275
01:15:32,100 --> 01:15:35,870
or from pregnant fisher nineteen seventy four there's been a a lot of things that

1276
01:15:36,100 --> 01:15:42,010
since it is very important and the to describe this mister levenstein sorry

1277
01:15:42,080 --> 01:15:45,790
there's always the mystery of what is it

1278
01:15:45,810 --> 01:15:51,280
so that the so this is really important this is what we're talking about strings

1279
01:15:51,290 --> 01:15:56,870
this is these are the top distance the distance it is mostly used because of

1280
01:15:56,870 --> 01:16:03,120
many reasons one of which is that it does take into account things like the

1281
01:16:04,140 --> 01:16:08,050
OK when you type the text and you know very very careful you don't forget

1282
01:16:08,050 --> 01:16:13,620
to let eventtype twice the same letter type one letter instead of another so all

1283
01:16:13,620 --> 01:16:18,100
that sort of noise you want to be able to

1284
01:16:18,170 --> 01:16:21,290
it to talk about it and typically you want to talk about it through the

1285
01:16:21,290 --> 01:16:26,740
edit operations the edit sort of mistakes you made between the road texture whatever you

1286
01:16:26,740 --> 01:16:31,390
typed in biology is the same you may have the real gene and whatever happens

1287
01:16:31,390 --> 01:16:37,220
transformations things have appeared in certain positions there's been some transformations were all this is

1288
01:16:37,220 --> 01:16:40,600
also described by by the statistics

1289
01:16:41,030 --> 01:16:45,990
so the basic operations of three insertion deletion substitution

1290
01:16:46,030 --> 01:16:51,160
and then sometimes people invented and things like taking two consecutive characters and saying well

1291
01:16:51,160 --> 01:16:54,810
you know i've talked one before the other side of the other way around that

1292
01:16:54,810 --> 01:16:57,950
happens when i want to talk about it here

1293
01:16:57,950 --> 01:17:04,240
so it can be described in terms of rewriting rules just for the mathematics we're

1294
01:17:04,240 --> 01:17:06,830
not use it here

1295
01:17:06,870 --> 01:17:10,720
and the idea is to say that we can't see much because

1296
01:17:10,740 --> 01:17:16,700
strange so that the idea of the matter is just to say that we're taking

1297
01:17:16,700 --> 01:17:17,680
a strange

1298
01:17:17,720 --> 01:17:22,100
right now the only thing that happens is the letter disappears in fact today seems

1299
01:17:22,120 --> 01:17:27,470
to have disappeared already shouldn't have here there's an insertion of a letter a

1300
01:17:27,470 --> 01:17:32,910
and here letter a has become a letter bee if you can't really see

1301
01:17:32,930 --> 01:17:35,560
exchange with the colours

1302
01:17:35,620 --> 01:17:42,240
so examples where the three operations can be described as follows right CC

1303
01:17:42,260 --> 01:17:45,850
and typically the idea is to say OK we're not going to have just one

1304
01:17:45,850 --> 01:17:53,140
operation because in text may have been various operations that have

1305
01:17:53,200 --> 01:17:57,180
he made to transform first x into the second text

1306
01:17:57,180 --> 01:18:02,060
so we will consider what is called the reflexive and transitive closure of this derivation

1307
01:18:02,060 --> 01:18:06,620
saying how many operations have we had to to do to go from text one

1308
01:18:08,490 --> 01:18:17,530
now then if i take two texts there may be various ways of modifying text

1309
01:18:17,530 --> 01:18:19,080
one to get to text two

1310
01:18:19,100 --> 01:18:23,600
prior to compressed stored by an insertion then delete and they're not all equivalent

1311
01:18:23,640 --> 01:18:28,350
so what the levenstein distance tells this is average time

1312
01:18:28,350 --> 01:18:32,100
distance is the smallest of the past

1313
01:18:32,100 --> 01:18:35,720
that allow us to get from text one two text

1314
01:18:36,120 --> 01:18:39,720
behind that there is the idea that the smallest is the most probable is that

1315
01:18:39,720 --> 01:18:45,280
all come idea although is not entirely justified is just the weight is defined we

1316
01:18:45,280 --> 01:18:50,140
will suppose that there are various explanations of how text what became text to the

1317
01:18:50,140 --> 01:18:53,830
shortest path is the one that truly came through this

1318
01:18:56,910 --> 01:19:00,870
in this case for example from a b a two a b where we can

1319
01:19:00,870 --> 01:19:06,530
see that we can do it into operations one operation consisting for example raising the

1320
01:19:06,530 --> 01:19:11,810
b and the second one that we've got a a a and then the a

1321
01:19:11,810 --> 01:19:13,660
the last a becomes b

1322
01:19:13,680 --> 01:19:17,720
that's one of the possibilities but there but there are others

1323
01:19:17,720 --> 01:19:22,180
now then this is the easiest cases in the case where every operation has got

1324
01:19:22,180 --> 01:19:25,200
the same cost and the cost is one

1325
01:19:25,200 --> 01:19:29,490
it is the co operation while is what normally people use the police when doing

1326
01:19:29,490 --> 01:19:32,450
mathematics or atleast when they describe the

1327
01:19:32,470 --> 01:19:37,060
so it it is represented by confusion matrix saying that to go from a to

1328
01:19:37,060 --> 01:19:42,660
a cost zero so basically the operation then teams operation coast zero doing nothing or

1329
01:19:42,660 --> 01:19:45,600
zero going from a to b

1330
01:19:45,680 --> 01:19:50,330
meaning substituting the a by b will cost one

1331
01:19:50,370 --> 01:19:53,530
and then a two lambda the last column

1332
01:19:53,530 --> 01:19:58,780
lambda means the empty string so h lambda means raising the deleting the a lot

1333
01:19:58,780 --> 01:20:00,780
of course one the cost

1334
01:20:00,830 --> 01:20:05,410
and you can also see that inserting in a the

1335
01:20:05,410 --> 01:20:07,990
here inserting a here

1336
01:20:08,010 --> 01:20:11,140
and i will also cost one

1337
01:20:11,140 --> 01:20:15,950
but it's not the only confusion matrix we can have a confusion much problem this

1338
01:20:15,950 --> 01:20:17,780
is not a mathematical one

1339
01:20:17,790 --> 01:20:22,830
and this one here is the typical sort of confusion metrics used by the biologist

1340
01:20:22,970 --> 01:20:27,830
you find the different proteins and you will find this school this is what they

1341
01:20:27,830 --> 01:20:30,450
call the blows from sixty two metrics

1342
01:20:30,510 --> 01:20:35,660
which in fact if you're looking at it is giving us some negative and some

1343
01:20:35,660 --> 01:20:41,390
positive weights and it's even giving us the weights on the diagonal saying that is

1344
01:20:41,390 --> 01:20:43,210
present the whole thing again

1345
01:20:43,220 --> 01:20:44,740
i would like to

1346
01:20:45,510 --> 01:20:50,130
go over a paper by sings lab NEC

1347
01:20:50,200 --> 01:20:55,360
and how do how and how to extract communities using factorizations

1348
01:20:55,420 --> 01:20:57,850
this attempt application in particular

1349
01:20:58,050 --> 01:20:59,820
so here's the full citation

1350
01:20:59,950 --> 01:21:04,850
structural and temporal analysis of the blogosphere through community factorisation and the main idea is

1351
01:21:04,850 --> 01:21:09,420
to use tensor factorisation to identify graphs over time

1352
01:21:09,440 --> 01:21:13,310
so it so we can also think of community is the temporal aspect so

1353
01:21:13,690 --> 01:21:17,970
we want to describe the intensity of a certain community at any given time

1354
01:21:18,010 --> 01:21:19,830
and to do it too

1355
01:21:19,860 --> 01:21:23,510
and the temporal aspect would requires intensive methods

1356
01:21:23,550 --> 01:21:25,780
so the results of this which

1357
01:21:26,970 --> 01:21:32,370
well able to identify several communities one of them being the hurricane katrina community and

1358
01:21:32,370 --> 01:21:37,330
here's the intensity of this community over time luckily hurricane katrina be

1359
01:21:39,230 --> 01:21:43,290
probably this was right after new orleans got flooded because we

1360
01:21:43,320 --> 01:21:47,760
new hurricane katrina was coming over here and then after that there was news related

1361
01:21:47,760 --> 01:21:48,410
to that

1362
01:21:48,450 --> 01:21:49,840
they also

1363
01:21:51,220 --> 01:21:53,280
upon status community

1364
01:21:53,310 --> 01:21:57,960
and this has all this is a much smaller size compared to hurricane katrina community

1365
01:21:57,960 --> 01:22:01,680
because there are fewer people that are interested in

1366
01:22:01,680 --> 01:22:06,290
in this blog sets and this was started with the post by by david sifry

1367
01:22:06,290 --> 01:22:10,260
on august seventeen to o five after spike was

1368
01:22:10,280 --> 01:22:16,820
and there's a lot of us to generated by that

1369
01:22:16,930 --> 01:22:21,700
so next what sort of anomaly detection can we perform and so fraud detection is

1370
01:22:21,700 --> 01:22:24,230
another emerging area for graph mining

1371
01:22:24,280 --> 01:22:25,280
and so

1372
01:22:25,340 --> 01:22:28,730
i'll introduce and fraud detection on e bay and a little bit of work related

1373
01:22:28,730 --> 01:22:32,510
to spam detection

1374
01:22:32,510 --> 01:22:37,530
so even a fraud detection there's no pro project and the full citation is here

1375
01:22:37,550 --> 01:22:41,460
and so is it the goal is to detect non delivery fraud that is the

1376
01:22:41,460 --> 01:22:45,700
seller takes takes your money and then disappears and you never get your digital camera

1377
01:22:46,620 --> 01:22:47,500
and so

1378
01:22:47,520 --> 01:22:50,790
if you if you knew the graph of all of

1379
01:22:50,890 --> 01:22:54,920
feedback that people are given who you choose to

1380
01:22:54,960 --> 01:23:00,620
to buy from

1381
01:23:00,640 --> 01:23:02,530
so we can actually

1382
01:23:02,550 --> 01:23:06,270
use user the tripartite graph and

1383
01:23:08,370 --> 01:23:11,580
but they they were able to identify three types of nodes that is on his

1384
01:23:11,590 --> 01:23:16,420
nose the fraud nodes and any accomplices

1385
01:23:16,430 --> 01:23:21,040
so we have so we have the from fraudsters up here and they don't actually

1386
01:23:21,070 --> 01:23:24,000
interact with honest people very often the most of their

1387
01:23:24,010 --> 01:23:29,290
feedback it comes from all these accomplices

1388
01:23:29,310 --> 01:23:32,790
any accomplices himself never perform any fraud because then

1389
01:23:32,810 --> 01:23:34,770
the whole project would

1390
01:23:34,780 --> 01:23:38,430
would just be be revealed that they do they they do

1391
01:23:38,480 --> 01:23:42,890
give high ratings to process to some prostitutes to be for instance they might sell

1392
01:23:42,890 --> 01:23:43,990
a lot of light

1393
01:23:44,000 --> 01:23:47,360
items that are sold for dollars something like that

1394
01:23:47,390 --> 01:23:48,790
and so

1395
01:23:49,440 --> 01:23:50,250
so the

1396
01:23:50,260 --> 01:23:53,290
the way they are able to identify some of these people is that they use

1397
01:23:53,290 --> 01:23:57,850
belief propagation and the intuition is that if i'm honest in my neighbours are either

1398
01:23:57,850 --> 01:24:03,500
honest or their accomplices and if i'm an accomplice my neighbours are either honest fraud

1399
01:24:03,520 --> 01:24:07,470
but different frost and then my neighbours will not be honest

1400
01:24:07,470 --> 01:24:13,300
so they use belief propagation using message passing and find the converges to some probabilities

1401
01:24:13,300 --> 01:24:20,000
of of on each node whether it's honest and accomplice or fraudster to

1402
01:24:27,920 --> 01:24:33,060
yes i i i i i just love this project they sent me a plus

1403
01:24:33,060 --> 01:24:34,990
plus plus plus

1404
01:24:38,870 --> 01:24:44,050
it could be either because i'm it's always the binary they give some men they

1405
01:24:44,050 --> 01:24:48,090
may or may not give some into some content to the actual review but there's

1406
01:24:48,090 --> 01:24:49,420
there's a binary

1407
01:24:49,420 --> 01:24:50,610
good or bad

1408
01:24:50,670 --> 01:24:53,430
on each one

1409
01:24:55,180 --> 01:24:58,770
they crawl the bay

1410
01:25:03,640 --> 01:25:08,420
they just do they just use the standard crawler and there were some

1411
01:25:08,430 --> 01:25:13,810
the it was somehow legit even made in evading complain about it the matters like

1412
01:25:13,820 --> 01:25:15,160
but i think that

1413
01:25:15,180 --> 01:25:16,750
there's there's some API

1414
01:25:16,770 --> 01:25:18,470
the EPA has

1415
01:25:24,970 --> 01:25:30,190
yeah i don't think the

1416
01:25:30,260 --> 01:25:34,220
so i think that they didn't really have this labelled data

1417
01:25:35,630 --> 01:25:39,740
i think the baby was pretty thrilled with what they did find

1418
01:25:39,870 --> 01:25:52,780
o means that you reviewed them

1419
01:25:52,830 --> 01:26:00,750
but you buy something from them and then reviewed repeated the transaction

1420
01:26:02,080 --> 01:26:05,180
so now quick application the patterns we

1421
01:26:05,180 --> 01:26:07,880
we've discussed to spam detection

1422
01:26:07,910 --> 01:26:11,660
so this was claridge are java

1423
01:26:11,680 --> 01:26:14,540
in two thousand six so they

1424
01:26:14,540 --> 01:26:16,800
there is no no semantics

1425
01:26:16,800 --> 01:26:19,570
and cookie came along in about fifty

1426
01:26:19,590 --> 01:26:24,530
o five o thing fifty four i've got the details at the end of lectures

1427
01:26:24,530 --> 01:26:27,010
if you want to look and he said well

1428
01:26:27,130 --> 01:26:31,990
this is really the modal logic of graphs named after so cricket

1429
01:26:32,010 --> 01:26:33,240
what are we trying to do

1430
01:26:33,250 --> 01:26:36,940
we're trying to the and these notions like truth and model

1431
01:26:37,030 --> 01:26:41,050
model with the d not model within a

1432
01:26:43,530 --> 01:26:48,250
what we want to do is trying to find the notion of when pfizer logical

1433
01:26:48,250 --> 01:26:52,400
consequence of gamma and prove some properties about logical consequence

1434
01:26:52,430 --> 01:26:55,530
OK and i'll try and wrap up by about ten o'clock today if i can

1435
01:26:57,180 --> 01:27:00,340
again this is not the lecture which we should be taking

1436
01:27:00,370 --> 01:27:04,120
shortcuts right so if i go i will just delay the break little bit of

1437
01:27:04,120 --> 01:27:05,520
something i had

1438
01:27:05,560 --> 01:27:07,340
you're amenable to that

1439
01:27:09,260 --> 01:27:12,580
what secret key frames

1440
01:27:12,600 --> 01:27:17,030
it's going to read somewhere that first

1441
01:27:17,040 --> 01:27:21,410
so you've got the indian already

1442
01:27:22,250 --> 01:27:26,260
could keyframe is that the graph WI i

1443
01:27:26,270 --> 01:27:27,990
so instead of using VE

1444
01:27:28,050 --> 01:27:30,870
the vertices i'm just going to use w

1445
01:27:30,890 --> 01:27:36,140
and these these are is subset of w crossed over right so w can have

1446
01:27:36,150 --> 01:27:37,820
a set of points

1447
01:27:37,870 --> 01:27:42,180
w crossed w is the complete graph where you put all the edges it

1448
01:27:42,180 --> 01:27:45,530
and in our is just you go back and delete some of them

1449
01:27:45,710 --> 01:27:47,760
so hours just to

1450
01:27:47,760 --> 01:27:51,490
could keyframe is just to directed graphs

1451
01:27:51,540 --> 01:27:54,040
what's the valuation on a kripke frame

1452
01:27:54,050 --> 01:28:01,930
well it's the map it looks complicated but it's not all of these is

1453
01:28:01,930 --> 01:28:06,560
so now i'm just going to rename these guys just using these

1454
01:28:06,580 --> 01:28:10,540
now is in w so i'm just going to go back and rewrite these W's

1455
01:28:11,490 --> 01:28:16,050
we are using the same notation

1456
01:28:17,710 --> 01:28:19,980
and now what's evaluation

1457
01:28:21,680 --> 01:28:26,650
is a map from every atomic formula to true or false

1458
01:28:26,680 --> 01:28:27,800
i the truth

1459
01:28:27,820 --> 01:28:29,650
or else falls

1460
01:28:29,700 --> 01:28:31,640
at every point

1461
01:28:32,290 --> 01:28:36,450
simple way of thinking about it is this image where this point you just write

1462
01:28:36,450 --> 01:28:41,620
out the atomic formula that he not p one and p two dot dot

1463
01:28:41,690 --> 01:28:44,090
and then you go through and and

1464
01:28:44,110 --> 01:28:45,750
you just decide

1465
01:28:45,760 --> 01:28:47,820
is it true or false

1466
01:28:47,880 --> 01:28:52,630
maybe it's true maybe it's false whatever

1467
01:28:52,650 --> 01:28:55,250
OK when you do the same thing over here

1468
01:28:55,250 --> 01:28:59,970
for every dollar valuation says if you give me a world and i'll give you

1469
01:29:01,280 --> 01:29:04,790
formulae that at the of atomic formulae true there

1470
01:29:05,780 --> 01:29:11,020
here we are again p not p one p to the top and you evaluation

1471
01:29:11,020 --> 01:29:16,880
might be different so i suppose it's which is exactly the opposite that's perfectly legal

1472
01:29:17,310 --> 01:29:21,190
you more world you have the more variation you can make

1473
01:29:21,240 --> 01:29:22,700
is that makes sense

1474
01:29:22,730 --> 01:29:28,120
doesn't make sense k

1475
01:29:28,180 --> 01:29:31,430
OK w is the set of worlds

1476
01:29:31,480 --> 01:29:34,300
OK so it's the vertices is

1477
01:29:34,310 --> 01:29:37,970
right so this is called the point is called w no

1478
01:29:37,970 --> 01:29:41,120
the point is called w one the point is called w two

1479
01:29:41,150 --> 01:29:42,800
and pain or

1480
01:29:43,580 --> 01:29:45,900
our language of formulae

1481
01:29:45,950 --> 01:29:49,360
OK i remember up here

1482
01:29:49,410 --> 01:29:51,040
at the top

1483
01:29:51,050 --> 01:29:52,370
they with the atomic

1484
01:29:54,430 --> 01:29:58,240
so what i'm saying is that we build formulae

1485
01:29:58,250 --> 01:30:01,570
out of these atomic formulae p not p one p two

1486
01:30:01,590 --> 01:30:04,130
they can't be broken down into further

1487
01:30:04,140 --> 01:30:06,840
OK and we build formulae

1488
01:30:06,880 --> 01:30:09,030
using these connectives

1489
01:30:09,030 --> 01:30:13,300
OK so we have more and more complicated formation treated like this

1490
01:30:15,810 --> 01:30:20,830
and we go so in classical logic which you've seen before what do we do

1491
01:30:20,850 --> 01:30:23,300
what we do is we take evaluation

1492
01:30:23,370 --> 01:30:24,400
the same

1493
01:30:24,410 --> 01:30:28,130
just ignore this for the moment we just take evaluation and say

1494
01:30:28,150 --> 01:30:29,500
they know what is true

1495
01:30:29,530 --> 01:30:33,850
o p one p one is false or whatever write in classical logic we only

1496
01:30:33,850 --> 01:30:35,550
have one the evaluation

1497
01:30:35,610 --> 01:30:38,320
in modal logic what we do is we just

1498
01:30:38,340 --> 01:30:41,440
bill that over graph what we say saying is

1499
01:30:41,440 --> 01:30:45,550
imagine you have valuation of the atoms to true and false

1500
01:30:45,610 --> 01:30:49,910
right now you have a kripke frame which is the graph

1501
01:30:49,960 --> 01:30:51,660
two separate things

1502
01:30:51,730 --> 01:30:52,990
OK so

1503
01:30:53,130 --> 01:30:54,860
syntax was formulated

1504
01:30:54,870 --> 01:30:56,720
chris keyframe is sitting here

1505
01:30:56,720 --> 01:31:00,620
so the word frame should be see inherent semantic

1506
01:31:00,650 --> 01:31:03,150
it's just the graph

1507
01:31:03,160 --> 01:31:05,190
and now we're tying them together

1508
01:31:05,190 --> 01:31:07,130
so w r

1509
01:31:07,200 --> 01:31:11,630
is the graph that

1510
01:31:12,240 --> 01:31:15,250
w is is the graph

1511
01:31:15,260 --> 01:31:17,260
OK that's sitting here

1512
01:31:17,280 --> 01:31:19,060
as the frame

1513
01:31:19,090 --> 01:31:21,110
and the evaluation

1514
01:31:22,110 --> 01:31:24,050
there's a valuation here

1515
01:31:24,060 --> 01:31:27,790
whenever you give me a w

1516
01:31:27,810 --> 01:31:32,900
and one of the atoms so this is your european or p one p two

1517
01:31:32,900 --> 01:31:36,130
so so that's the trick here

1518
01:31:36,150 --> 01:31:40,070
but we do so so we have a practical question here

1519
01:31:40,070 --> 01:31:46,540
two question about specific values for these unknown parameters these are numbered

1520
01:31:46,560 --> 01:31:48,560
and the way you will get this

1521
01:31:48,960 --> 01:31:50,480
it is

1522
01:31:50,520 --> 01:31:53,130
what's called analysis

1523
01:31:58,520 --> 01:32:00,750
hopefully this is

1524
01:32:00,930 --> 01:32:02,810
this is the tree

1525
01:32:09,640 --> 01:32:13,160
so this is sort of an aside this is why it works so there is

1526
01:32:13,350 --> 01:32:15,270
general model

1527
01:32:15,280 --> 01:32:17,790
so that's the general linear model

1528
01:32:20,080 --> 01:32:23,290
there are algorithms out there so could take this into r

1529
01:32:23,310 --> 01:32:24,390
so it's

1530
01:32:24,450 --> 01:32:29,710
please give me the estimate of the basis of called the these so hot

1531
01:32:29,730 --> 01:32:33,030
and then what you have is

1532
01:32:33,070 --> 01:32:35,770
what the model predicts the output should be

1533
01:32:35,790 --> 01:32:39,060
for each y michael fifty values so that is

1534
01:32:39,080 --> 01:32:43,280
i would say yes to beta zero place so that it is the place sacked

1535
01:32:43,280 --> 01:32:49,620
the only with plugins of all these users and then take original data feed through

1536
01:32:49,620 --> 01:32:52,420
the system to what we get to the end

1537
01:32:52,450 --> 01:32:55,030
and that we call fitted value from model

1538
01:32:55,130 --> 01:32:57,710
we can compare

1539
01:32:57,740 --> 01:32:59,770
the city value for money

1540
01:32:59,790 --> 01:33:04,780
one with what we observe one of the different

1541
01:33:04,830 --> 01:33:07,270
let's call the residual

1542
01:33:10,480 --> 01:33:12,960
the size of services

1543
01:33:12,980 --> 01:33:14,120
related to

1544
01:33:14,160 --> 01:33:18,340
you can explain variations related to these that solutions that got flow right to those

1545
01:33:19,430 --> 01:33:24,510
what we would like to estimate is the variance of those things i would like

1546
01:33:24,530 --> 01:33:26,940
to estimate sigma square which

1547
01:33:26,960 --> 01:33:30,790
it was written down in the previous slide

1548
01:33:30,910 --> 01:33:33,170
including the

1549
01:33:33,180 --> 01:33:34,760
but any linear model

1550
01:33:34,800 --> 01:33:40,710
do is you take use residuals square

1551
01:33:40,730 --> 01:33:43,020
and divided by

1552
01:33:43,030 --> 01:33:47,360
but the number of data points x and

1553
01:33:48,670 --> 01:33:51,790
the number of pages you go out there so here we go

1554
01:33:51,800 --> 01:33:55,100
one b so that and and b in here

1555
01:33:55,360 --> 01:33:57,150
so that was an plus one

1556
01:33:57,170 --> 01:34:03,340
so be zero beta one beta and so that's what that was so one peters

1557
01:34:03,340 --> 01:34:06,770
and take away from the number of data points you got

1558
01:34:06,780 --> 01:34:11,850
that's about formula gives me three

1559
01:34:11,880 --> 01:34:15,640
i will give a decent estimate of sigma square

1560
01:34:15,740 --> 01:34:18,840
now the service

1561
01:34:21,210 --> 01:34:25,090
it will given decent single square in

1562
01:34:25,100 --> 01:34:26,600
this model one model

1563
01:34:26,680 --> 01:34:30,690
if this model fits the data correctly that that will be a good estimate of

1564
01:34:30,690 --> 01:34:31,880
sigma squared

1565
01:34:35,840 --> 01:34:43,420
if you don't want to talk about something distributions this is sort of information that

1566
01:34:43,430 --> 01:34:46,040
you can get about something obvious i want to know

1567
01:34:46,040 --> 01:34:48,730
well the properties of this thing that square

1568
01:34:48,750 --> 01:34:50,840
which i can work out

1569
01:34:52,130 --> 01:34:54,520
this case is calculated from the data

1570
01:34:54,520 --> 01:34:59,400
calculate because i want to know about six square but also about the behaviour of

1571
01:34:59,400 --> 01:35:01,120
this quantity

1572
01:35:01,150 --> 01:35:06,460
under different scenarios so that's what they something distribution stuff is about how

1573
01:35:06,700 --> 01:35:12,590
what's going to happen to this quantity that can tell from the data in general

1574
01:35:13,680 --> 01:35:16,480
what i know from statistical theory is this

1575
01:35:17,500 --> 01:35:19,660
if got the right models

1576
01:35:19,730 --> 01:35:24,290
so it's correct is a good predictor of what's coming out there is a square

1577
01:35:24,420 --> 01:35:27,070
will be a good estimate of sigma square

1578
01:35:27,080 --> 01:35:33,280
a single word constant that's the building to hold on to a fixed value

1579
01:35:33,290 --> 01:35:38,630
if got redundancies that is inputs they don't actually affects the output

1580
01:35:38,660 --> 01:35:41,670
the related to the output then

1581
01:35:41,690 --> 01:35:46,600
i would still have good estimates that was quite so if i use the same

1582
01:35:46,600 --> 01:35:48,170
sort of formula

1583
01:35:48,200 --> 01:35:51,560
to get the best if i knew the my model

1584
01:35:54,600 --> 01:35:59,900
things are important missing from it so this is where we're going

1585
01:35:59,920 --> 01:36:04,360
does not include one or more inputs that it ought to things that do affect

1586
01:36:04,360 --> 01:36:06,430
the output some of those things out there

1587
01:36:06,900 --> 01:36:09,030
now what happens

1588
01:36:09,660 --> 01:36:10,930
as square

1589
01:36:10,950 --> 01:36:15,300
i will not be a good estimate of square in fact it will be big

1590
01:36:15,420 --> 01:36:16,840
bigger than it should be

1591
01:36:16,860 --> 01:36:17,990
at the beginning

1592
01:36:18,000 --> 01:36:22,070
we need to be bigger than single square is that's the point so that we

1593
01:36:22,070 --> 01:36:26,120
could estimate so is trade

1594
01:36:26,150 --> 01:36:27,330
i can compare

1595
01:36:27,330 --> 01:36:34,990
two models can take complex in other and input particular inputs to the model

1596
01:36:35,950 --> 01:36:37,560
adding the

1597
01:36:38,880 --> 01:36:42,010
the estimate of sigma squared change

1598
01:36:42,010 --> 01:36:44,260
but you know that

1599
01:36:44,270 --> 01:36:48,840
that was basically happened is that the input needs to be included in the model

1600
01:36:49,560 --> 01:36:54,030
when i first went to the estimate things square to high that i didn't call

1601
01:36:54,040 --> 01:36:57,010
variable and maybe come down to the right level

1602
01:36:57,030 --> 01:36:59,600
so that's that's what we're trying to do so

1603
01:36:59,610 --> 01:37:05,540
we decide which actually should be in by looking at what happens to this quantity

1604
01:37:05,540 --> 01:37:09,070
ask where does it go down or what are well

1605
01:37:09,070 --> 01:37:12,540
how much does it go down when you add to the sum of all when

1606
01:37:12,540 --> 01:37:14,040
you drop

1607
01:37:14,060 --> 01:37:15,820
inputs from the model

1608
01:37:15,840 --> 01:37:17,930
OK so that's the general

1609
01:37:19,300 --> 01:37:25,790
let's see how it works in the case so we had to model

1610
01:37:27,370 --> 01:37:29,360
which was

1611
01:37:30,140 --> 01:37:34,340
which is the same as this but i had a little bit about

1612
01:37:36,080 --> 01:37:38,420
it's like this model

1613
01:37:38,440 --> 01:37:40,710
but it was

1614
01:37:42,560 --> 01:37:46,130
is that have all these bits about treatments

1615
01:37:46,150 --> 01:37:50,540
so the difference between the model that we're about to look on this model is

1616
01:37:50,540 --> 01:37:53,900
that of course that we're looking at is politics

1617
01:37:53,940 --> 01:37:56,560
blue these from the model

1618
01:37:56,560 --> 01:38:02,610
fort to get to their effect if forced beta b beta c beta beta are

1619
01:38:03,060 --> 01:38:07,020
from a those all zero that's the same as excluding the inputs

1620
01:38:07,040 --> 01:38:12,360
from the model because they don't have any effect if i got them so

1621
01:38:12,380 --> 01:38:14,900
so first of all the thing is if

1622
01:38:14,920 --> 01:38:19,670
lastly this model

1623
01:38:20,830 --> 01:38:24,110
or you can say is like saying

1624
01:38:24,130 --> 01:38:27,630
but compared to model i just had with this model

1625
01:38:27,650 --> 01:38:29,560
where they just they

1626
01:38:29,580 --> 01:38:33,650
terms to do the treatments just don't exist about to do the different blocks

1627
01:38:33,670 --> 01:38:36,750
so hard to compare two models i can

1628
01:38:36,810 --> 01:38:42,170
bring in the impulse to do the treatment and see what effect it has upon

1629
01:38:42,190 --> 01:38:44,670
my estimate of

1630
01:38:46,690 --> 01:38:50,580
so do that this is the sort of output you get from one you get

1631
01:38:50,710 --> 01:38:54,610
from our which something like this so

1632
01:38:54,650 --> 01:38:56,650
in this output

1633
01:38:56,670 --> 01:38:59,670
the quantity that was going to ask where is this thing

1634
01:38:59,690 --> 01:39:01,380
it's the residual

1635
01:39:01,400 --> 01:39:03,920
i mean square in this table

1636
01:39:03,920 --> 01:39:08,750
so when i look at that was the change so this is just a single

1637
01:39:10,170 --> 01:39:12,670
so look at that

1638
01:39:12,670 --> 01:39:17,900
influences on ordering and actually what favors

1639
01:39:17,910 --> 01:39:20,530
what favors crystallisation

1640
01:39:20,540 --> 01:39:29,680
factors favouring crystallisation remember we're not talking about perfect crystals here we're talking about local

1641
01:39:29,680 --> 01:39:35,130
warming over certain lengths of chain which give rise to some

1642
01:39:35,170 --> 01:39:39,120
strengthening of the material and so i'm just going to go back and revisit one

1643
01:39:39,120 --> 01:39:40,670
two and three above

1644
01:39:40,680 --> 01:39:46,540
i'm going to ask how composition hottest actors city and how does confirmation and hands

1645
01:39:46,610 --> 01:39:51,590
crystallisation so first thing was leaked composition

1646
01:39:51,600 --> 01:39:57,590
the way to favor crystallisation is to make

1647
01:39:57,600 --> 01:40:02,800
materials more nearly uniform the higher the degree of uniformity in the poll were the

1648
01:40:02,800 --> 01:40:07,790
greater the chances are that it can zigzag back and forth and in a predictable

1649
01:40:07,790 --> 01:40:11,040
manner set up these zones of

1650
01:40:11,060 --> 01:40:16,410
crystallinity so self this is a city straight chain of a linear chain polr if

1651
01:40:16,410 --> 01:40:18,350
it's made homogeneous

1652
01:40:18,350 --> 01:40:24,960
of the same composition than the chances of its folding back and forth on itself

1653
01:40:24,980 --> 01:40:27,470
and setting up this local

1654
01:40:27,500 --> 01:40:30,850
sort of semi crystalline

1655
01:40:30,900 --> 01:40:39,340
semi crystalline regions are greater than if the polymer has some random variation in composition

1656
01:40:39,340 --> 01:40:43,360
so the factor that favors crystallisation is

1657
01:40:43,370 --> 01:40:49,530
having a single composition so homer polymers are

1658
01:40:49,560 --> 01:40:58,190
much more easy easily crystallized so as an example polyethylene oxide can form crystalline polymers

1659
01:40:58,190 --> 01:41:03,510
were as if you take the polyethylene oxide block copolymer was a poly

1660
01:41:03,600 --> 01:41:08,690
propylene oxide the second case is more likely to be amorphous

1661
01:41:08,700 --> 01:41:11,580
the second factor one look at his tactics city

1662
01:41:11,600 --> 01:41:16,800
texas city you know you've got three forms of texas city ISO tactic send tactic

1663
01:41:16,800 --> 01:41:22,230
in a tactic and one that's more readily willing to pack is going to be

1664
01:41:22,230 --> 01:41:24,510
ISO tax

1665
01:41:24,530 --> 01:41:28,200
so i so tactic version well

1666
01:41:28,240 --> 01:41:30,610
be favoured

1667
01:41:30,630 --> 01:41:37,100
standpoint crystallisation we have evidence that i ISO tactic

1668
01:41:37,140 --> 01:41:39,010
i tactic

1669
01:41:39,020 --> 01:41:47,600
polystyrene is a highly crystalline so you see some of these hard polystyrene containers

1670
01:41:47,650 --> 01:41:52,520
they are predominantly ISO tactic whereas a tactic

1671
01:41:52,530 --> 01:41:56,480
a tactic polystyrene is dominantly

1672
01:41:57,960 --> 01:42:02,980
so there's the influence of texas city and the third one is confirmation

1673
01:42:03,000 --> 01:42:08,260
this confirmation that we've got the linear chains you've got branch chains and we've got

1674
01:42:08,270 --> 01:42:13,610
crosslinked chains and clearly following this paradigm the linear chains

1675
01:42:13,620 --> 01:42:14,810
our favourite

1676
01:42:15,530 --> 01:42:16,730
when it comes to

1677
01:42:16,740 --> 01:42:19,320
the formation of

1678
01:42:19,330 --> 01:42:23,480
ordered structures so if you look at something like

1679
01:42:23,490 --> 01:42:26,340
high-density polyethylene

1680
01:42:26,350 --> 01:42:27,890
that's shown here this the

1681
01:42:27,950 --> 01:42:36,100
the opaque milk jug this has a high degree of linearity in the chains whereas

1682
01:42:36,100 --> 01:42:43,830
branching or crosslinking are going to make things very difficult from the perspective of forming

1683
01:42:43,840 --> 01:42:46,940
crystalline structures

1684
01:42:47,070 --> 01:42:52,450
and in fact here's something that's volume versus temperature should remind you of the unit

1685
01:42:52,450 --> 01:42:56,780
that we've discovered in silicate glasses we see

1686
01:42:56,800 --> 01:42:57,710
but the

1687
01:42:58,520 --> 01:43:03,450
cooling curves here at two different rates and fast cooling has the in the curvature

1688
01:43:03,480 --> 01:43:10,900
higher glass transition temperature than slow cooling and similarly the with fast cooling there's a

1689
01:43:10,900 --> 01:43:13,320
higher degree of quenched in

1690
01:43:13,650 --> 01:43:17,770
three volumes so all those ideas apply

1691
01:43:17,800 --> 01:43:21,340
the other thing i want to look at now is on the basis of what

1692
01:43:21,340 --> 01:43:25,960
we've seen so far what are the properties of polymers and we can tailor things

1693
01:43:25,960 --> 01:43:30,020
to a great extent but there are certain properties that that they are that they

1694
01:43:30,020 --> 01:43:31,440
all share

1695
01:43:31,450 --> 01:43:32,770
so let's

1696
01:43:32,780 --> 01:43:40,510
the document goes

1697
01:43:40,520 --> 01:43:41,750
the first one

1698
01:43:41,770 --> 01:43:44,350
electrical insulators

1699
01:43:44,490 --> 01:43:47,840
electrical insulators

1700
01:43:50,330 --> 01:43:54,960
whatever as why we have to look at electronic structure here we have strong covalent

1701
01:43:54,960 --> 01:43:58,720
bonds up and down the backbone and we have

1702
01:43:58,730 --> 01:44:05,360
o relatively weak van der waals bonds with some hydrogen bonding in between

1703
01:44:05,380 --> 01:44:08,480
no case are we looking at free electrons so

1704
01:44:09,700 --> 01:44:13,530
covalent bonds

1705
01:44:15,380 --> 01:44:16,860
these are interesting

1706
01:44:16,870 --> 01:44:18,770
molecular bonds

1707
01:44:23,700 --> 01:44:30,300
with covalent bonds we have electron sharing we have octet stability and the electrical

1708
01:44:30,300 --> 01:44:32,300
former group because

1709
01:44:32,310 --> 01:44:33,620
the group g

1710
01:44:33,640 --> 01:44:35,790
of natural isabelle in

1711
01:44:35,790 --> 01:44:38,870
so it doesn't matter whether you multiply things

1712
01:44:39,580 --> 01:44:42,390
this subgroup is always normal

1713
01:44:42,410 --> 01:44:44,410
so that's why

1714
01:44:44,580 --> 01:44:48,820
the union of the set of cosets

1715
01:44:48,870 --> 01:44:51,000
former group but

1716
01:44:51,000 --> 01:44:54,460
they form a group under different location

1717
01:44:54,510 --> 01:44:58,190
which is this one here

1718
01:44:58,220 --> 01:45:00,940
so you can see this example

1719
01:45:00,960 --> 01:45:03,300
you can construct this by

1720
01:45:03,350 --> 01:45:05,330
o to blind

1721
01:45:06,680 --> 01:45:09,150
all the multiplication table for this

1722
01:45:09,160 --> 01:45:11,710
for this group of this set

1723
01:45:12,870 --> 01:45:15,590
here is to show that the whole group

1724
01:45:15,590 --> 01:45:17,400
the group's itself

1725
01:45:18,250 --> 01:45:19,840
they are

1726
01:45:19,840 --> 01:45:21,860
the abstract things

1727
01:45:21,900 --> 01:45:23,170
this is one

1728
01:45:23,170 --> 01:45:26,230
one way that the group may appear

1729
01:45:26,270 --> 01:45:29,190
it's true you know

1730
01:45:29,820 --> 01:45:33,170
in takers

1731
01:45:34,090 --> 01:45:37,690
a number model and

1732
01:45:37,690 --> 01:45:42,540
you know its motherland because when you multiply one this last element here you get

1733
01:45:42,690 --> 01:45:45,980
this one

1734
01:45:46,110 --> 01:45:48,270
this cycle

1735
01:45:48,290 --> 01:45:50,520
this is the same group

1736
01:45:50,540 --> 01:45:52,250
represented differently

1737
01:45:52,250 --> 01:45:55,310
here you have the roots of the unity the

1738
01:45:56,340 --> 01:45:58,270
roots of the unity

1739
01:45:58,290 --> 01:46:02,320
and the multiplication is complex multiplication

1740
01:46:02,340 --> 01:46:04,520
so the core sets here

1741
01:46:04,560 --> 01:46:06,960
if you take this

1742
01:46:06,980 --> 01:46:10,060
white said here as

1743
01:46:10,080 --> 01:46:12,770
the subgroup h

1744
01:46:12,820 --> 01:46:14,060
the core sets

1745
01:46:14,060 --> 01:46:16,130
you get is

1746
01:46:16,150 --> 01:46:17,730
multiplied this

1747
01:46:17,820 --> 01:46:23,060
so group by one gen generate generic element of the

1748
01:46:24,040 --> 01:46:27,420
and you get for example the green one

1749
01:46:27,460 --> 01:46:30,560
you multiply again get the red

1750
01:46:30,610 --> 01:46:34,080
if you multiply again you go back to each

1751
01:46:34,080 --> 01:46:36,040
so you have done

1752
01:46:36,060 --> 01:46:38,320
in this case you have the three cassette as well

1753
01:46:38,340 --> 01:46:43,380
and it's the same thing abstractly the same thing about how you you implement the

1754
01:46:43,380 --> 01:46:49,150
multiplication of the action of the group was different

1755
01:46:49,190 --> 01:46:56,460
what defines the a group abstractly it it's stable occasionally fly to be get c

1756
01:46:56,480 --> 01:46:57,880
that's more that's

1757
01:46:57,900 --> 01:47:02,750
it doesn't matter if a certain number of symmetric polynomials

1758
01:47:02,770 --> 01:47:06,920
and it doesn't matter how you do the multiplication can represent the action of the

1759
01:47:06,920 --> 01:47:08,460
group elements

1760
01:47:08,520 --> 01:47:12,520
as much tricks multiplication as the differential operator

1761
01:47:12,590 --> 01:47:14,710
there are you know many ways to

1762
01:47:14,730 --> 01:47:15,750
do these things

1763
01:47:15,770 --> 01:47:17,250
it is open

1764
01:47:17,270 --> 01:47:23,090
only the group itself the abstract thing that's important in terms of

1765
01:47:23,110 --> 01:47:29,880
of the the more fundamental properties of the graph

1766
01:47:32,500 --> 01:47:36,210
OK so this division the result of this division here

1767
01:47:36,210 --> 01:47:37,650
i wrote

1768
01:47:37,670 --> 01:47:40,500
this single gene of

1769
01:47:40,520 --> 01:47:41,960
eight zero

1770
01:47:41,980 --> 01:47:44,590
the result of this is

1771
01:47:44,650 --> 01:47:46,540
number of course sets

1772
01:47:46,590 --> 01:47:49,630
so this is the generalisation of the

1773
01:47:49,650 --> 01:47:54,360
so you get three courses

1774
01:47:54,360 --> 01:47:58,360
but this case is when the subgroup is normal

1775
01:48:01,810 --> 01:48:05,290
this article is not normal

1776
01:48:05,310 --> 01:48:06,250
you get

1777
01:48:06,250 --> 01:48:08,630
the division you get

1778
01:48:08,710 --> 01:48:12,420
you get and i'm watching this page

1779
01:48:12,420 --> 01:48:16,960
and i went into space is just avoiding space which every point looks like

1780
01:48:16,980 --> 01:48:20,840
you know the sphere and pointed shoes has the same in the same vicinity you

1781
01:48:22,060 --> 01:48:25,360
differentiate among them

1782
01:48:29,960 --> 01:48:34,290
it's boring because nothing happens that not the whole there there's you know it's just

1783
01:48:34,290 --> 01:48:40,710
small just like the whole space the euclidean space not any point it's if

1784
01:48:40,730 --> 01:48:41,670
you know

1785
01:48:41,670 --> 01:48:45,750
everywhere if you were there you if you don't have any references you cannot know

1786
01:48:45,750 --> 01:48:47,590
where you are

1787
01:48:49,310 --> 01:48:52,110
so these are

1788
01:48:52,130 --> 01:48:57,460
our example from would that's why it's called the more genius

1789
01:48:57,520 --> 01:48:59,770
the the collection of all cosets which

1790
01:49:02,150 --> 01:49:07,080
another another way to see them

1791
01:49:07,130 --> 01:49:11,400
they can be used to as it as an active equivalence classes can be because

1792
01:49:11,400 --> 01:49:14,840
it is the same thing but you can you can relate to them for many

1793
01:49:16,000 --> 01:49:20,880
and this is one way to see the course is for example given a set

1794
01:49:24,380 --> 01:49:28,770
i'm using this set this line here the set x

1795
01:49:28,790 --> 01:49:31,560
and relations

1796
01:49:31,560 --> 01:49:37,090
of this this is the definition of equivalent class right now given a set x

1797
01:49:37,110 --> 01:49:43,420
and our relation with the single year for relations seem to other

1798
01:49:43,460 --> 01:49:47,730
the equivalent class is a class of an element of x

1799
01:49:47,770 --> 01:49:49,840
is given by the

1800
01:49:49,880 --> 01:49:53,040
equivalent class of x it's all

1801
01:49:54,270 --> 01:49:55,750
belongs to

1802
01:49:58,080 --> 01:50:02,940
x and y have this relation to find is an abstract definition

1803
01:50:02,960 --> 01:50:04,710
and here's an example

1804
01:50:04,710 --> 01:50:06,250
free energy throughout the hierarchy

1805
01:50:07,010 --> 01:50:10,790
but the coupling but the world is absolutely very very important and and that's basically

1806
01:50:10,790 --> 01:50:14,070
what i description here to the oculomotor reflex arc

1807
01:50:14,570 --> 01:50:16,780
but you can profoundly change or imports

1808
01:50:17,440 --> 01:50:21,580
just by moving they are moving what you sample so prediction errors

1809
01:50:22,100 --> 01:50:25,830
in certain privileged parts of of the of the brain

1810
01:50:26,350 --> 01:50:31,190
namely those that actually control the deployment of your sensory something organs

1811
01:50:31,750 --> 01:50:33,910
this sensory receptors sensory epithelia

1812
01:50:34,620 --> 01:50:39,080
they can they can minimize prediction error in one of two ways they can either try to

1813
01:50:40,640 --> 01:50:44,650
these predictions or they can just go and change the sensory data

1814
01:50:46,680 --> 01:50:55,030
so this is absolutely crucial in understanding these actionperception duality here's perception is certainly caused by

1815
01:50:55,570 --> 01:51:01,000
what is sampled to actually sets on the which forms the basis of the prediction

1816
01:51:01,310 --> 01:51:04,100
because you're actually something what you're predicting so there's actually

1817
01:51:05,240 --> 01:51:09,940
a self-fulfilling prophecy about the way these systems behave but show you an example of the term

1818
01:51:10,950 --> 01:51:12,470
they show the hierarchical

1819
01:51:14,160 --> 01:51:17,340
if i don't do that now the the next in the next example

1820
01:51:18,570 --> 01:51:21,490
so the conclusion is that the sort of the first the first

1821
01:51:22,240 --> 01:51:23,670
as theoretical overview

1822
01:51:25,550 --> 01:51:29,900
what we said what i said is biological systems agents resist the second law

1823
01:51:30,810 --> 01:51:34,560
well strictly there's is the fluctuation theorem because we're not talking about equilibrium systems

1824
01:51:36,020 --> 01:51:40,330
they must minimize their average surprise all although surprisingly entropy

1825
01:51:40,870 --> 01:51:45,000
and they can minimize surprise by suppressing prediction error will formally free energy

1826
01:51:45,410 --> 01:51:48,950
well prediction error can be reduced by changing predictions that perception

1827
01:51:49,640 --> 01:51:52,830
or it can be reduced by changing sensations namely action

1828
01:51:53,720 --> 01:52:00,720
perception entails recurrent message passing in the brain to optimise predictions while action makes its predictions come true

1829
01:52:01,470 --> 01:52:03,600
and thereby minimizes surprise

1830
01:52:04,100 --> 01:52:07,330
so in the time that i have left i just try and give u

1831
01:52:07,970 --> 01:52:08,350
the sort of

1832
01:52:09,740 --> 01:52:14,740
an example from from sort action and perception and the perception and action and then

1833
01:52:14,740 --> 01:52:18,910
finally turned to the key question is how and why do we explore what research

1834
01:52:18,910 --> 01:52:21,370
had we build models and optimizes models

1835
01:52:23,600 --> 01:52:26,700
the first example is meant to illustrate this sort of

1836
01:52:27,850 --> 01:52:28,850
just a simple

1837
01:52:30,270 --> 01:52:31,200
use of

1838
01:52:31,850 --> 01:52:35,040
dynamical models as generative models that environment hand

1839
01:52:35,660 --> 01:52:39,330
perception as categorisation recovering the underlying causes

1840
01:52:41,770 --> 01:52:43,640
and what i've done here is just

1841
01:52:44,410 --> 01:52:46,370
consider the problem of categorizing

1842
01:52:46,930 --> 01:52:53,620
the bird might have in categorizing a song emitted upwards which permitted by conspecific about that

1843
01:52:54,060 --> 01:52:57,410
i'm trying to categorize it in the same way that we might try to categorize

1844
01:52:57,410 --> 01:53:00,470
a word or or the meaning of a sentence

1845
01:53:01,470 --> 01:53:04,740
so i have to generate data and then i have to specify

1846
01:53:05,270 --> 01:53:06,700
birds generative model

1847
01:53:07,140 --> 01:53:07,890
and then run the

1848
01:53:08,500 --> 01:53:09,620
predictive coding scheme

1849
01:53:10,020 --> 01:53:13,700
in order to see whether i can recover the underlying causes of

1850
01:53:14,120 --> 01:53:14,970
the sensory input

1851
01:53:15,560 --> 01:53:16,020
do that

1852
01:53:16,990 --> 01:53:20,040
just basically boring to state lorenz attractor here

1853
01:53:20,470 --> 01:53:26,080
to modulate the frequency and the amplitude is some synthetic ship the bird might make

1854
01:53:26,890 --> 01:53:29,870
in terms of the hidden causes i'm gonna change

1855
01:53:30,290 --> 01:53:33,470
we control parameters that the ants attracted to change the flow

1856
01:53:34,310 --> 01:53:40,270
the change the tempo and the amplitude of the actual chips cells so that i can actually

1857
01:53:40,830 --> 01:53:42,970
think of these two control parameters

1858
01:53:44,520 --> 01:53:51,120
that are basically coefficients of these in these equations emotional attractor as defining

1859
01:53:51,970 --> 01:53:52,470
eight nature

1860
01:53:53,700 --> 01:53:56,470
eight song in a two-dimensional perceptual space

1861
01:53:56,950 --> 01:54:01,930
and the job of the burden i was trying not from the sort of continuous time-dependent import

1862
01:54:02,410 --> 01:54:04,220
which is just an opportune frequency

1863
01:54:04,640 --> 01:54:05,260
back to

1864
01:54:06,140 --> 01:54:08,640
you've time-invariant central

1865
01:54:09,760 --> 01:54:16,790
categorizations are going from fast time scale to a slow timescale so gently model goes from some time invariant

1866
01:54:17,290 --> 01:54:23,000
category just some fast dynamics and the main versions taking first dynamics mapping back

1867
01:54:24,180 --> 01:54:26,140
seven slow categorisation


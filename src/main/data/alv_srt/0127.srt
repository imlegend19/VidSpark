1
00:00:00,000 --> 00:00:01,730
your body about columnist storage

2
00:00:02,920 --> 00:00:04,380
you worry about networking

3
00:00:04,980 --> 00:00:08,420
because lots of data moves over and data movement is a huge part of the cost

4
00:00:09,280 --> 00:00:11,130
if you're concerned about machine learning

5
00:00:11,770 --> 00:00:15,750
you might not care as much about forty tolerance you may be okay if i

6
00:00:15,750 --> 00:00:21,050
give you a good handle on fort venice because many loopy algorithms the major algorithms

7
00:00:21,050 --> 00:00:21,630
allows u

8
00:00:22,280 --> 00:00:25,380
to deal with the fact that some piece if your computation just went away

9
00:00:26,050 --> 00:00:28,030
you will have to restart and really do exactly the

10
00:00:29,380 --> 00:00:32,380
you can rely on good convergence properties good sampling properties

11
00:00:33,530 --> 00:00:35,750
local data cache and turns out to be critical

12
00:00:36,320 --> 00:00:39,500
right of local iterations but some global sink

13
00:00:40,190 --> 00:00:43,000
can do just as well as global iterations

14
00:00:44,010 --> 00:00:45,440
low latency networking

15
00:00:46,170 --> 00:00:47,210
becomes important here

16
00:00:47,610 --> 00:00:49,000
it's not high-bandwidth network

17
00:00:50,650 --> 00:00:55,400
the amount of data is not the issue the motive communications how quickly it has to happen

18
00:00:55,770 --> 00:00:56,320
this issue

19
00:00:56,940 --> 00:00:58,170
if you think about it and by

20
00:00:59,820 --> 00:01:01,460
right it's very different from

21
00:01:01,920 --> 00:01:04,070
how do style data-driven bottles

22
00:01:04,570 --> 00:01:06,420
it's communication driven by was

23
00:01:08,300 --> 00:01:08,710
how do

24
00:01:11,440 --> 00:01:17,480
well you can run it ninety eight jobs not on a dedicated in its basic cluster

25
00:01:17,940 --> 00:01:19,280
but on the map reveals cluster

26
00:01:19,780 --> 00:01:20,820
on you know the cluster

27
00:01:21,590 --> 00:01:22,650
there's sort of way we are

28
00:01:23,340 --> 00:01:24,110
trying to take things

29
00:01:27,280 --> 00:01:29,320
today if you look at these various phases

30
00:01:30,250 --> 00:01:30,710
there is

31
00:01:31,690 --> 00:01:34,110
a wide variety of tools that are used in practice

32
00:01:36,380 --> 00:01:37,550
for example formation

33
00:01:38,280 --> 00:01:39,880
the sequel systems mapreduce

34
00:01:41,340 --> 00:01:42,980
four the modeling as i said

35
00:01:43,440 --> 00:01:49,730
precisely because this is inadequate people at the level of specialised systems in memory optimisations like spock

36
00:01:50,280 --> 00:01:52,630
graph-oriented schemes like graphlab

37
00:01:53,150 --> 00:01:53,550
and by

38
00:01:54,070 --> 00:01:54,630
is well known

39
00:01:56,730 --> 00:01:58,110
let someone else as well

40
00:02:02,500 --> 00:02:04,460
young officers the possibility

41
00:02:05,050 --> 00:02:06,730
of unifying how we build these

42
00:02:09,440 --> 00:02:10,630
and the question in front of us

43
00:02:12,090 --> 00:02:13,170
can take this further

44
00:02:13,690 --> 00:02:14,960
like the refactoring

45
00:02:15,480 --> 00:02:16,150
of the order

46
00:02:16,650 --> 00:02:17,750
mapreduce systems

47
00:02:18,670 --> 00:02:19,750
the began that you are

48
00:02:20,210 --> 00:02:22,480
hardly carried forward in the same space

49
00:02:26,690 --> 00:02:27,400
at this point

50
00:02:28,270 --> 00:02:31,380
hopefully you'll understand the machine learning applications

51
00:02:31,860 --> 00:02:32,940
the only under the hood

52
00:02:33,480 --> 00:02:35,210
i haven't done a systems challenges

53
00:02:37,090 --> 00:02:38,860
building these silos

54
00:02:39,750 --> 00:02:40,570
doesn't want any good

55
00:02:43,150 --> 00:02:47,230
the motivation forest which we plan to open source is built by

56
00:02:47,860 --> 00:02:49,670
folks in microsoft's mostly

57
00:02:50,940 --> 00:02:51,840
in my day mostly

58
00:02:53,030 --> 00:02:55,610
we are planning to open source is in the next month or so

59
00:02:56,230 --> 00:02:57,320
it will also be demoted

60
00:02:58,110 --> 00:02:58,710
really mean

61
00:02:59,360 --> 00:03:01,110
and we have built several things already

62
00:03:01,730 --> 00:03:03,250
we have built from scratch

63
00:03:03,730 --> 00:03:06,030
a version of mapreduce that is capable of running

64
00:03:07,110 --> 00:03:12,170
is not intended as a replacement for the standard mapreduce it's a demonstration of how flexible the system can be

65
00:03:13,440 --> 00:03:16,050
we also implemented several machine learning algorithms

66
00:03:16,460 --> 00:03:19,030
today i'll talk about linear models only

67
00:03:20,010 --> 00:03:21,000
but they've been doing many more

68
00:03:23,000 --> 00:03:25,750
for those of you who are interested in research on florida where

69
00:03:27,590 --> 00:03:28,610
you could use grief

70
00:03:29,190 --> 00:03:32,300
as a platform for experimentation four year of research perhaps

71
00:03:32,960 --> 00:03:35,210
okay and in the statistician make the point

72
00:03:35,690 --> 00:03:37,340
this is roughly that's that's right

73
00:03:38,880 --> 00:03:41,690
you're trying to provide horizontally that extends the yarn surface

74
00:03:43,320 --> 00:03:45,510
in the examples and will give you illustrate grief

75
00:03:46,630 --> 00:03:48,710
keep in mind the following colour coding

76
00:03:49,400 --> 00:03:49,860
the yellow

77
00:03:50,570 --> 00:03:52,170
this control control plane

78
00:03:52,650 --> 00:03:54,920
quite a lot what facilitates

79
00:03:56,210 --> 00:04:01,300
the really messy called of keeping track of thousands of your tasks

80
00:04:01,840 --> 00:04:03,460
right which task failed

81
00:04:04,590 --> 00:04:06,150
what state it failed

82
00:04:06,920 --> 00:04:08,250
when started

83
00:04:08,750 --> 00:04:10,610
do i have to restart entire draw

84
00:04:12,880 --> 00:04:14,710
control flow can be a real issue

85
00:04:15,730 --> 00:04:17,590
so we try and facilitate this

86
00:04:19,250 --> 00:04:24,030
the actual user code that supply as part of your job you'll see an orange

87
00:04:24,590 --> 00:04:29,750
at the computer resources the reef gets through you are you'll see colour coded

88
00:04:30,170 --> 00:04:30,510
in blue

89
00:04:33,960 --> 00:04:35,480
so beyond the control flow

90
00:04:36,590 --> 00:04:38,210
that is what we begin by illustrating

91
00:04:38,800 --> 00:04:39,690
these provides

92
00:04:40,320 --> 00:04:42,320
extensible libraries that's

93
00:04:42,800 --> 00:04:47,230
allow you to have a storied services network services state management services

94
00:04:47,670 --> 00:04:51,050
and it has a dependency injection framework called band

95
00:04:51,530 --> 00:04:57,500
that allows you to mix and match just what services you need for a given task for a given application

96
00:04:57,500 --> 00:04:59,920
this is a

97
00:04:59,920 --> 00:05:04,170
they are all of the

98
00:05:10,100 --> 00:05:20,520
so it's very easy to deal with these issues them all the time lol

99
00:05:20,540 --> 00:05:23,710
this is all will

100
00:05:25,210 --> 00:05:30,730
that is really just the face down computation

101
00:05:31,890 --> 00:05:37,170
if we take a small station to some function

102
00:05:38,980 --> 00:05:45,130
we we can say no more than two steps of these operations

103
00:05:45,150 --> 00:05:47,170
we see that he would say

104
00:05:47,440 --> 00:05:50,100
nomination they want to

105
00:05:50,170 --> 00:05:51,170
two d

106
00:05:53,540 --> 00:05:55,650
if we want to see

107
00:05:57,520 --> 00:06:01,810
so a lot of goals

108
00:06:06,560 --> 00:06:11,940
he's going to operations that he mentioned them all the time so the

109
00:06:16,390 --> 00:06:19,480
so so the

110
00:06:20,250 --> 00:06:21,810
the relationship between

111
00:06:21,830 --> 00:06:25,000
the computational complexity of the world

112
00:06:27,440 --> 00:06:33,020
and the statistical lab class

113
00:06:47,960 --> 00:06:55,460
which you still have the problem is that

114
00:06:55,520 --> 00:06:57,100
all right

115
00:06:57,100 --> 00:07:01,040
all right let me you

116
00:07:01,150 --> 00:07:03,810
or how i used

117
00:07:03,830 --> 00:07:09,710
this is this is the result cells

118
00:07:09,810 --> 00:07:13,170
this is a very useful one

119
00:07:13,190 --> 00:07:16,940
to the east and

120
00:07:17,020 --> 00:07:19,080
so you can

121
00:07:19,100 --> 00:07:20,600
even more

122
00:07:25,520 --> 00:07:28,350
and also one

123
00:07:28,370 --> 00:07:33,290
these classes with real or something

124
00:07:33,310 --> 00:07:39,100
you know it's all really very simple to get this

125
00:07:39,120 --> 00:07:42,310
very very

126
00:07:44,210 --> 00:07:45,810
so instance

127
00:07:45,830 --> 00:07:47,520
an example

128
00:07:47,770 --> 00:07:51,100
in recent

129
00:07:51,150 --> 00:07:53,670
this is consistency

130
00:07:53,750 --> 00:07:55,130
that is

131
00:07:55,150 --> 00:07:57,100
was actually really

132
00:07:57,120 --> 00:07:58,940
it's the basis of

133
00:07:59,250 --> 00:08:03,170
this list is it

134
00:08:03,190 --> 00:08:09,250
so when there a service

135
00:08:10,830 --> 00:08:11,810
which is

136
00:08:11,810 --> 00:08:15,270
the result of

137
00:08:17,270 --> 00:08:21,400
for that

138
00:08:21,440 --> 00:08:23,600
the whole system to

139
00:08:23,600 --> 00:08:26,050
the first lecture but i can repeat it so

140
00:08:26,060 --> 00:08:30,230
that's one way to define machine learning machine learning is concerned with developing

141
00:08:30,240 --> 00:08:32,820
the developing algorithms that learn from experience

142
00:08:32,850 --> 00:08:34,910
model of the environment

143
00:08:34,920 --> 00:08:36,360
from the queen knowledge

144
00:08:36,370 --> 00:08:37,440
and i mean

145
00:08:37,500 --> 00:08:39,110
so far so good bugs

146
00:08:39,120 --> 00:08:41,600
what distinguishes

147
00:08:41,630 --> 00:08:44,980
machine learning from some of the fields that you really want to use this model

148
00:08:44,980 --> 00:08:46,090
for something

149
00:08:46,130 --> 00:08:49,090
and something to be means for prediction

150
00:08:54,920 --> 00:09:01,420
OK overview comes first then some philosophical issues than bayesian sequence prediction then i come

151
00:09:01,420 --> 00:09:03,800
to this all element of universal inductive

152
00:09:03,820 --> 00:09:05,800
inference schemes

153
00:09:05,850 --> 00:09:07,510
and then the slide

154
00:09:07,530 --> 00:09:10,740
digression because this is

155
00:09:11,310 --> 00:09:16,610
so applications or alex would say then or in analogy i would say this is

156
00:09:16,610 --> 00:09:19,100
ten months theoretical this work

157
00:09:19,110 --> 00:09:23,970
remember alex always told you that our work is applied if it was theoretically

158
00:09:23,980 --> 00:09:26,280
so this is

159
00:09:26,320 --> 00:09:30,460
this is an theoretical this work then but it really works well in practice

160
00:09:30,470 --> 00:09:31,380
if you can

161
00:09:31,420 --> 00:09:34,990
and then about the universal AI

162
00:09:39,740 --> 00:09:41,560
OK you will see that

163
00:09:41,610 --> 00:09:45,680
so some philosophical questions around induction

164
00:09:45,700 --> 00:09:47,890
i mean induction

165
00:09:47,910 --> 00:09:50,250
i mean inferring model

166
00:09:50,270 --> 00:09:54,440
from data roughly OK so

167
00:09:54,480 --> 00:09:56,780
you can ask i mean does inductive or

168
00:09:56,790 --> 00:09:59,780
inductive inference or doctor prediction

169
00:09:59,790 --> 00:10:03,730
they use this models propagation i often do not distinguish between

170
00:10:03,770 --> 00:10:04,990
these two things

171
00:10:05,000 --> 00:10:09,160
so one question is first i mean does inductive inference work at all

172
00:10:09,190 --> 00:10:10,570
OK it seems so

173
00:10:10,610 --> 00:10:13,120
but then you can ask why

174
00:10:13,140 --> 00:10:14,230
and how

175
00:10:17,020 --> 00:10:19,780
in the bayesian framework

176
00:10:19,790 --> 00:10:21,940
you have to choose the model class

177
00:10:22,180 --> 00:10:25,570
you have to choose the prior so how do we do that in a generic

178
00:10:28,390 --> 00:10:32,810
how then we can do optimal decisions if nothing is known about the environment

179
00:10:32,860 --> 00:10:34,900
and finally for instance

180
00:10:35,130 --> 00:10:36,610
what is intelligence

181
00:10:37,280 --> 00:10:40,740
if you want to work on a i it's good to know what it

182
00:10:41,240 --> 00:10:47,240
OK let me first give an ontology to different field i mean i could

183
00:10:47,270 --> 00:10:51,310
but benefited let's take complexity theory because you probably know that

184
00:10:51,410 --> 00:10:54,980
so what is the goal of complexity theory the goal is to find

185
00:10:55,020 --> 00:10:56,980
class i were them

186
00:10:56,990 --> 00:10:58,580
for solving problems

187
00:10:58,590 --> 00:11:03,200
to show lower bounds on their computation time

188
00:11:03,210 --> 00:11:06,330
so if you i mean read the statement to look at the literature everything is

189
00:11:06,330 --> 00:11:08,890
rigorously defined and what is an algorithm

190
00:11:08,900 --> 00:11:12,480
during machine problem class computation time so

191
00:11:12,500 --> 00:11:14,910
nearly everything is rigorous

192
00:11:14,930 --> 00:11:19,410
OK but most disciplines start in an informal way

193
00:11:19,500 --> 00:11:22,190
and then it's time they get more and more formalized and

194
00:11:22,230 --> 00:11:27,010
absolutely rigorous and then maybe even maximisation and then a few months in a certain

195
00:11:27,940 --> 00:11:30,790
look at probability theory may you measure theory

196
00:11:30,850 --> 00:11:33,740
it's not the kind of axioms and then you can do all kinds of things

197
00:11:35,490 --> 00:11:41,240
OK for example set theory started informal way then you but the russell paradox the

198
00:11:41,240 --> 00:11:43,480
set of all sets which do do not contain each other

199
00:11:44,370 --> 00:11:48,610
and some point to formalise the axiomatized in our our

200
00:11:48,620 --> 00:11:54,990
at least from conceptual point of view logical reasoning proof theory probability theory infinitesimal calculus

201
00:11:55,740 --> 00:11:58,140
physics to conserve energy and temperature

202
00:11:58,150 --> 00:12:03,720
and quantum field theory so all apart from the last if no rigorous mathematical formulation

203
00:12:03,760 --> 00:12:07,830
quantum field theory of all developed in the nineteen thirties and

204
00:12:07,850 --> 00:12:10,740
the most important theory in physics and most successful

205
00:12:10,760 --> 00:12:13,370
still not rigorously mathematically defined

206
00:12:13,430 --> 00:12:18,230
but it doesn't really matter in this case because able to compute numbers

207
00:12:18,240 --> 00:12:19,110
OK so

208
00:12:19,150 --> 00:12:22,500
so now let's look at machine learning

209
00:12:22,560 --> 00:12:26,680
OK so machine learning OK repeat myself tries to build and understand systems that learn

210
00:12:26,680 --> 00:12:28,000
from past data

211
00:12:28,010 --> 00:12:33,450
make good predictions are able to generalize maybe act intelligently

212
00:12:33,460 --> 00:12:38,230
so many of these terms are vaguely defined or there are many alternative definition i

213
00:12:38,230 --> 00:12:41,980
mean what does generalise meanwhile good prediction means

214
00:12:42,000 --> 00:12:45,360
understanding and so on so it would be nice

215
00:12:45,370 --> 00:12:47,650
and probably very useful to have a formal

216
00:12:47,690 --> 00:12:49,810
general definition

217
00:12:50,230 --> 00:12:53,720
well characterisation of machine learning axiomatizations

218
00:12:58,140 --> 00:13:01,020
i present a classical example plus from

219
00:13:01,040 --> 00:13:04,570
seventeen hundred something

220
00:13:05,780 --> 00:13:07,740
so he asked what is the probability

221
00:13:07,740 --> 00:13:09,840
that the sun will rise tomorrow

222
00:13:09,870 --> 00:13:15,540
so what you have so far as you have seen the sun rising every day

223
00:13:15,600 --> 00:13:18,240
i mean it was cloudy sort of i mean you can still see this light

224
00:13:18,890 --> 00:13:19,770
it's not about

225
00:13:19,780 --> 00:13:21,210
clouds or

226
00:13:21,760 --> 00:13:27,410
and so on so we have seen this on raising awareness in the days

227
00:13:27,530 --> 00:13:30,660
and he asked me what is is the chance to the greatest tomorrow

228
00:13:30,720 --> 00:13:32,180
i mean it

229
00:13:32,190 --> 00:13:33,250
good to know

230
00:13:33,310 --> 00:13:37,740
so i mean if it not raise sort of your sources to stay

231
00:13:37,760 --> 00:13:42,470
OK so you i can think of several answers so you can say OK p

232
00:13:42,470 --> 00:13:45,960
is undefined because there has never been an experiment that tested the existence of the

233
00:13:45,960 --> 00:13:47,600
sun tomorrow

234
00:13:48,870 --> 00:13:51,210
thank you

235
00:13:51,220 --> 00:13:53,470
now the answer would be people one

236
00:13:53,470 --> 00:14:01,620
so when whose first invited me to be a one of the speakers

237
00:14:01,730 --> 00:14:04,240
at this conference

238
00:14:04,410 --> 00:14:08,500
my initial reaction was

239
00:14:08,510 --> 00:14:12,470
it's about time because they been coming this conference for seven or eight years and

240
00:14:12,620 --> 00:14:15,720
i don't know why no one ever thought of inviting me to give a keynote

241
00:14:15,720 --> 00:14:17,170
talk before

242
00:14:17,260 --> 00:14:21,240
so this is long overdue as far as i'm concerned but then a little bit

243
00:14:21,860 --> 00:14:23,650
humility crept in

244
00:14:23,770 --> 00:14:26,630
there's a little bit of me

245
00:14:26,630 --> 00:14:29,120
and so i decided in in

246
00:14:29,130 --> 00:14:32,500
in repentance for my initial reaction i should

247
00:14:32,520 --> 00:14:35,730
actually admit to some of the mistakes i made

248
00:14:35,800 --> 00:14:39,420
over the past several years

249
00:14:42,350 --> 00:14:46,130
so i think i'll give you a little bit of my own personal history just

250
00:14:46,130 --> 00:14:47,960
to set the context

251
00:14:49,810 --> 00:14:54,090
and then i'm actually going to go through some honest mistakes that i made when

252
00:14:54,090 --> 00:14:59,350
i was following you everything and was very comfortable to predict

253
00:14:59,440 --> 00:15:02,750
the failure of various technologies

254
00:15:02,800 --> 00:15:08,550
and hopefully learn some lessons from the mistakes i made that we can all benefit

255
00:15:08,550 --> 00:15:12,080
from and then i will attempt to do it again

256
00:15:12,080 --> 00:15:15,880
and we can see at some point whether or not my

257
00:15:15,890 --> 00:15:17,450
predictions are true

258
00:15:17,530 --> 00:15:21,020
so a little bit of personal history i was born in new york

259
00:15:21,030 --> 00:15:26,440
during a period of turmoil and change in the united states my parents are both

260
00:15:26,500 --> 00:15:29,440
civil rights activists

261
00:15:29,450 --> 00:15:34,270
but very early on i was really

262
00:15:34,310 --> 00:15:36,630
i believe myself to know everything

263
00:15:36,670 --> 00:15:39,630
and my mother tells the story of how

264
00:15:39,720 --> 00:15:41,470
i refuse to watch

265
00:15:41,470 --> 00:15:44,630
in the early but rogers TV show

266
00:15:44,700 --> 00:15:47,810
because i insisted there was no air in space

267
00:15:47,850 --> 00:15:52,190
in second grade this true story

268
00:15:52,200 --> 00:15:57,160
our second-grade teacher gave us arithmetic problem to keep us busy for a few hours

269
00:15:57,160 --> 00:16:00,890
you may have heard this story before in the context of the more famous mathematician

270
00:16:00,890 --> 00:16:05,150
and i but honestly i didn't do this

271
00:16:05,160 --> 00:16:06,410
very quickly

272
00:16:06,430 --> 00:16:09,400
surprising the crap out of my teacher

273
00:16:09,440 --> 00:16:12,030
except that i've got the wrong answer

274
00:16:13,910 --> 00:16:17,650
sorry my life so how did i do i want to share this with you

275
00:16:17,660 --> 00:16:20,480
as this is true maybe you believe the story if i show you how it

276
00:16:20,480 --> 00:16:25,130
actually happened so i started writing the numbers down

277
00:16:25,130 --> 00:16:29,530
and as i started adding them it occurred to me that this number was going

278
00:16:29,530 --> 00:16:34,290
to keep getting bigger and bigger and it would probably be easier if i started

279
00:16:34,290 --> 00:16:37,500
with the bigger numbers and work backwards so that

280
00:16:37,510 --> 00:16:41,440
when i got to the and i'd be adding small numbers to be once instead

281
00:16:41,440 --> 00:16:44,040
of being numbers too big numbers

282
00:16:44,060 --> 00:16:47,290
and as i was writing it down on my piece of paper i just so

283
00:16:47,290 --> 00:16:49,000
happen to notice

284
00:16:50,380 --> 00:16:56,260
you know the first five or so numbers writing down backwards lined up perfectly in

285
00:16:56,280 --> 00:16:58,000
some two hundred

286
00:16:58,000 --> 00:16:59,320
with the pair

287
00:16:59,340 --> 00:17:04,250
in the beginning so i literally having come up with any particular formula for this

288
00:17:04,250 --> 00:17:07,100
i just went on my piece of paper and wrote down all the numbers from

289
00:17:07,100 --> 00:17:07,720
one to fifty

290
00:17:08,100 --> 00:17:13,220
and then backwards wrote all the numbers from one hundred down to fifty

291
00:17:13,260 --> 00:17:18,010
noticing that they sum to one hundred and then counted how many times it happened

292
00:17:18,030 --> 00:17:22,930
but unfortunately i counted fifty twice

293
00:17:22,980 --> 00:17:25,730
so this is the kind of thing that i do all the time little little

294
00:17:25,730 --> 00:17:30,010
flashes of insight mixed with the a complete lack of rigour

295
00:17:33,560 --> 00:17:37,850
so anyway my teacher maybe go back to my seat do it right

296
00:17:38,160 --> 00:17:44,190
the first prediction of the future that i made was in nineteen seventy five when

297
00:17:44,190 --> 00:17:47,900
i predicted that i would marry for forces majors

298
00:17:47,910 --> 00:17:54,160
how many people remember far majors

299
00:17:59,190 --> 00:18:00,850
brings back fond memories

300
00:18:01,790 --> 00:18:04,900
now i'm going to launch into this sort of admission of failure part of the

301
00:18:04,900 --> 00:18:07,870
talk and i just want to make sure that everyone understands that i have a

302
00:18:09,060 --> 00:18:12,850
because some of you may feel insulted by some of the things i say and

303
00:18:12,850 --> 00:18:16,990
i want to make sure that you understand that i never insulted group of people

304
00:18:16,990 --> 00:18:19,930
are less i consider myself part of that group

305
00:18:19,950 --> 00:18:25,300
so all of these insults i consider insult to a group that i'm a central

306
00:18:25,300 --> 00:18:28,950
part of consider myself central to

307
00:18:28,990 --> 00:18:32,420
so i'm really talking about myself

308
00:18:32,490 --> 00:18:35,490
so how did that what kinds of predictions that i make

309
00:18:35,540 --> 00:18:41,650
so i started out at RPI in the early eighties as a system administrator i

310
00:18:41,650 --> 00:18:47,520
was the classic kind of system administrator that revels in his own esoteric knowledge and

311
00:18:47,520 --> 00:18:50,030
insults everyone who doesn't

312
00:18:50,030 --> 00:18:53,040
no those things so we had at that time

313
00:18:53,050 --> 00:18:55,160
a unix system that had been

314
00:18:55,170 --> 00:18:57,680
usenet email protocol

315
00:18:57,700 --> 00:19:03,150
which was just having for hackers and system administrators because

316
00:19:03,200 --> 00:19:08,300
you have to have the most esoteric knowledge imaginable in order to be able to

317
00:19:08,300 --> 00:19:12,490
send an email message from one person to another you had to know the modem

318
00:19:12,490 --> 00:19:18,520
connections between these unix machines because the way the mail was routed was basically you

319
00:19:19,900 --> 00:19:24,160
computer called up another computer and how to finite set of computers whose

320
00:19:24,160 --> 00:19:25,890
phone numbers in new

321
00:19:25,900 --> 00:19:31,720
and you literally had to know which computers do about which other computers this was

322
00:19:31,760 --> 00:19:34,220
known as the past

323
00:19:34,230 --> 00:19:35,970
and if you wanted to send me

324
00:19:35,980 --> 00:19:38,160
email from say bell labs

325
00:19:38,170 --> 00:19:39,410
you had to know

326
00:19:39,430 --> 00:19:43,960
that the bell labs computer talk to have a computer some other university which talk

327
00:19:43,970 --> 00:19:46,650
to another university which talk to ours

328
00:19:46,680 --> 00:19:51,640
and then the last thing that was my user account that she

329
00:19:51,680 --> 00:19:56,350
so this is fantastic but i was not so stupid as to think that this

330
00:19:56,350 --> 00:19:58,390
was a usable technology

331
00:19:58,480 --> 00:20:01,970
so i predicted that no one will ever use email

332
00:20:02,080 --> 00:20:09,200
i said over and over again in a that time growing community of

333
00:20:09,610 --> 00:20:11,600
fans of networking

334
00:20:11,600 --> 00:20:16,880
what right

335
00:20:18,350 --> 00:20:22,550
it what

336
00:20:26,210 --> 00:20:30,170
he wanted

337
00:21:25,930 --> 00:21:35,280
these are our

338
00:21:57,680 --> 00:22:06,550
well we it

339
00:22:16,990 --> 00:22:19,790
who we are

340
00:22:26,970 --> 00:22:29,440
i been

341
00:22:41,800 --> 00:22:42,650
the same

342
00:22:46,090 --> 00:22:52,350
we don't know

343
00:22:57,210 --> 00:22:59,210
if you add more

344
00:24:28,120 --> 00:24:33,000
the common prior

345
00:24:51,890 --> 00:24:56,800
you can read more

346
00:24:56,810 --> 00:24:58,050
we use

347
00:25:09,640 --> 00:25:15,720
or one

348
00:25:15,940 --> 00:25:18,350
we you

349
00:25:24,450 --> 00:25:27,490
the people are

350
00:25:27,500 --> 00:25:31,180
he said it

351
00:25:32,190 --> 00:25:38,030
all right

352
00:25:38,080 --> 00:25:40,290
o five

353
00:25:50,660 --> 00:25:57,720
i'm not on

354
00:26:07,880 --> 00:26:10,160
in the real world

355
00:26:19,730 --> 00:26:21,710
the game

356
00:26:21,710 --> 00:26:23,530
as the first step

357
00:26:23,540 --> 00:26:27,650
before we get into the current what the velocity of the electron

358
00:26:27,660 --> 00:26:28,720
it's phenomenal

359
00:26:28,720 --> 00:26:29,910
it's an incredible

360
00:26:30,990 --> 00:26:35,430
so v then becomes i was one hour

361
00:26:35,470 --> 00:26:37,720
so i get the square root

362
00:26:37,740 --> 00:26:40,740
again e squared up here

363
00:26:40,760 --> 00:26:42,580
i am goes downstairs

364
00:26:42,590 --> 00:26:45,680
four by epsilon zero

365
00:26:45,730 --> 00:26:47,530
and i have you and are

366
00:26:47,580 --> 00:26:48,680
and i told

367
00:26:48,700 --> 00:26:51,370
you know what is an old capitol are you know what

368
00:26:51,420 --> 00:26:56,510
four by actually non-zero is one over four pi actually non-zero is famous nine

369
00:26:56,550 --> 00:26:59,030
the power nine times ten to the

370
00:26:59,040 --> 00:27:00,010
o nine

371
00:27:00,020 --> 00:27:02,470
so i can calculate obvious

372
00:27:02,550 --> 00:27:05,530
and if i stick the numbers and if i did not make a mistake

373
00:27:05,540 --> 00:27:08,730
and i find about two point three

374
00:27:08,740 --> 00:27:10,290
i'm ten two to six

375
00:27:11,200 --> 00:27:12,110
a second

376
00:27:13,350 --> 00:27:14,920
the high-speed five

377
00:27:14,960 --> 00:27:17,160
million miles of

378
00:27:17,170 --> 00:27:19,790
if this were straight line you would make it to the moon

379
00:27:19,850 --> 00:27:22,110
in three minutes

380
00:27:22,120 --> 00:27:24,110
five million miles per hour

381
00:27:24,160 --> 00:27:25,780
it one goes around

382
00:27:25,840 --> 00:27:28,260
the problem

383
00:27:28,300 --> 00:27:30,970
now i have to go to the current have to find out what the current

384
00:27:32,160 --> 00:27:35,160
so the question that i'm going to ask now is how long does it take

385
00:27:35,160 --> 00:27:37,800
for the electron to go around

386
00:27:37,820 --> 00:27:39,840
all that time capital p

387
00:27:39,850 --> 00:27:43,160
is of course this conference of my circle

388
00:27:43,210 --> 00:27:46,850
divided by the speed of the electron trivial even the high school students in my

389
00:27:46,850 --> 00:27:50,370
audience will understand that one

390
00:27:50,390 --> 00:27:51,400
and so

391
00:27:51,410 --> 00:27:55,300
i know two pi r is because they know INNOV and so i can calculate

392
00:27:55,320 --> 00:27:57,540
the time just by sticking in the numbers

393
00:27:57,590 --> 00:28:00,280
and i find it is about one point one four

394
00:28:00,280 --> 00:28:05,290
five ten to the minus sixteen seconds just met

395
00:28:05,300 --> 00:28:08,540
how small that time is cannot even

396
00:28:08,590 --> 00:28:09,910
we can't even imagine

397
00:28:09,930 --> 00:28:11,430
what it's like it goes

398
00:28:11,450 --> 00:28:15,790
ten two to sixteen times per second around

399
00:28:15,900 --> 00:28:18,470
there's a huge

400
00:28:18,520 --> 00:28:22,180
one point one four times ten to the minus sixteen

401
00:28:22,200 --> 00:28:25,910
really should have one point four times ten to the minus sixteen

402
00:28:25,960 --> 00:28:28,450
because it doesn't make much difference but

403
00:28:28,460 --> 00:28:31,580
in case you substitute in the numbers

404
00:28:31,670 --> 00:28:33,110
is one point four

405
00:28:33,160 --> 00:28:37,280
ten to the minus sixteen

406
00:28:39,270 --> 00:28:41,090
now we still haven't

407
00:28:41,100 --> 00:28:44,030
i found the current current almost there

408
00:28:44,080 --> 00:28:47,090
because when you look here

409
00:28:47,090 --> 00:28:50,100
this is the electron going by

410
00:28:50,160 --> 00:28:55,510
and every one point one four ten to the minus sixteen seconds leg goes by

411
00:28:55,540 --> 00:29:00,910
so the current i that's the definition of current is the charge per unit time

412
00:29:01,110 --> 00:29:02,520
so every

413
00:29:02,570 --> 00:29:08,240
capital t seconds the charge he goes quiet so this is the definition the current

414
00:29:08,360 --> 00:29:10,150
so this current and

415
00:29:10,200 --> 00:29:14,210
that you have which is simply due to the election going around the proton

416
00:29:14,270 --> 00:29:15,170
is about

417
00:29:15,200 --> 00:29:16,660
one point one

418
00:29:16,710 --> 00:29:20,400
times ten to the minus three

419
00:29:21,710 --> 00:29:23,780
that is mind boggling

420
00:29:23,850 --> 00:29:27,320
many and here one electron going around

421
00:29:29,030 --> 00:29:30,660
represents occurrence of

422
00:29:32,680 --> 00:29:35,480
and of course they have the magnetic moment you

423
00:29:35,490 --> 00:29:37,340
that is i times a

424
00:29:37,350 --> 00:29:39,370
we already calculated a

425
00:29:39,420 --> 00:29:41,840
and that we also have the current i

426
00:29:41,850 --> 00:29:42,690
and so

427
00:29:42,700 --> 00:29:44,490
we now get that new

428
00:29:44,540 --> 00:29:45,820
is approximately

429
00:29:45,830 --> 00:29:49,500
nine point three if you put in all the best and most correctly times ten

430
00:29:49,500 --> 00:29:51,690
to the the minus twenty four

431
00:29:51,700 --> 00:29:54,210
and the united support employees

432
00:29:56,690 --> 00:29:59,980
this is current is a has nothing to do with that a this is an

433
00:29:59,980 --> 00:30:04,220
NP is careful this for me this these are uris

434
00:30:04,260 --> 00:30:06,360
and this has the name

435
00:30:06,370 --> 00:30:08,970
this is called the boar

436
00:30:18,930 --> 00:30:22,300
what we can understand with our knowledge now

437
00:30:22,350 --> 00:30:25,400
but you can if you ever quantum mechanics

438
00:30:26,230 --> 00:30:27,850
the magnetic moment

439
00:30:27,870 --> 00:30:34,350
of all electrons in orbit can only be a multiple this number nothing in between

440
00:30:34,400 --> 00:30:37,450
one mechanics which has its quantisation

441
00:30:37,490 --> 00:30:40,140
it's not in between the two or

442
00:30:40,300 --> 00:30:43,700
it includes even zero which is even harder to understand

443
00:30:43,740 --> 00:30:46,110
could even be zero

444
00:30:46,170 --> 00:30:48,770
in addition to

445
00:30:48,830 --> 00:30:52,950
the dipole moment of the electron going around the proton

446
00:30:52,980 --> 00:30:57,190
the electron itself is the charge which begins about its own axis

447
00:30:57,200 --> 00:31:01,940
and that also means that the charge is going around

448
00:31:01,950 --> 00:31:04,480
on the spending scale of electrons

449
00:31:04,500 --> 00:31:09,620
and that the magnetic dipole moment is always this value

450
00:31:09,630 --> 00:31:10,350
and so

451
00:31:10,350 --> 00:31:15,790
the net magnetic dipole moment of an atom or molecule is now to vectorial some

452
00:31:15,800 --> 00:31:20,710
of all the dipole moments all these electrons going around means orbital

453
00:31:20,710 --> 00:31:23,790
than ten dollars so very small citizen surface

454
00:31:23,940 --> 00:31:28,970
and this kind of a scalability issue as a pretty fundamental issues about the nature

455
00:31:28,980 --> 00:31:34,080
of the algorithms and these kind of scalability issues are very important in particular for

456
00:31:34,080 --> 00:31:35,690
pattern recognition

457
00:31:35,700 --> 00:31:37,890
OK so let me explain

458
00:31:37,900 --> 00:31:42,150
quickly what's the idea of super resolution the is pretty simple that we take the

459
00:31:42,150 --> 00:31:48,750
example which is the first example where that was done in geophysics sparse spike deconvolution

460
00:31:48,770 --> 00:31:53,420
so the idea of sparse spike deconvolution is that you know that the input signal

461
00:31:53,430 --> 00:31:56,220
priority should be a set of spikes

462
00:31:56,220 --> 00:32:00,480
OK so it's the sparse signal which is the sum of the is now you

463
00:32:00,480 --> 00:32:05,850
have the convolution with the filter you and you see here it's called the way

464
00:32:07,060 --> 00:32:09,310
now that's what you see over

465
00:32:09,320 --> 00:32:14,640
and these weights let's kill the low frequency and the kill they have high frequency

466
00:32:14,670 --> 00:32:18,630
so the fourier transform of the dirac is far basically

467
00:32:18,700 --> 00:32:21,100
lot of information here here

468
00:32:21,120 --> 00:32:23,550
and every or it's impossible to recover

469
00:32:23,600 --> 00:32:28,650
not superresolution claims that you can in fact if you look at the problem

470
00:32:28,680 --> 00:32:33,040
what do you have the data are just in fact a linear combination

471
00:32:33,050 --> 00:32:38,640
of the hough vote by you you get you translated that's what you see over

472
00:32:38,720 --> 00:32:42,490
there is very simple if you do that these things

473
00:32:42,510 --> 00:32:47,320
well you know there is zero so that the issue here

474
00:32:47,340 --> 00:32:49,980
first iraq second and third year i

475
00:32:50,040 --> 00:32:54,440
john OK so that's the simple idea of super resolution

476
00:32:56,270 --> 00:32:59,960
how do extend so the idea which is behind is to say you have a

477
00:32:59,960 --> 00:33:04,340
dictionary which is a family of functions and the prior information that you have on

478
00:33:04,340 --> 00:33:07,130
your problem here is the fact that you signal

479
00:33:07,520 --> 00:33:14,310
has a sparse representation within this dictionary so that's the way you incorporate prior information

480
00:33:14,320 --> 00:33:18,690
now if you look at your data now the data which is you have plus

481
00:33:18,690 --> 00:33:21,740
noise can be written as a linear combination

482
00:33:21,790 --> 00:33:25,560
of the dictionary elements which have been transformed

483
00:33:25,580 --> 00:33:27,350
by the operator you

484
00:33:28,190 --> 00:33:31,690
another term which is basically the error terms

485
00:33:31,710 --> 00:33:37,050
now what that shows is that now the data has also sparse representation but not

486
00:33:37,050 --> 00:33:42,900
in the original dictionary in the transformed dictionary which is obtained by

487
00:33:42,920 --> 00:33:44,140
the function transform

488
00:33:45,950 --> 00:33:49,140
the problem that you are now having is that your original dictionary for was for

489
00:33:49,140 --> 00:33:54,060
example an orthogonal basis like the hoc basis but here you are going to have

490
00:33:54,060 --> 00:34:00,210
more than that they all the space of dimension q so now we have redundant

491
00:34:01,220 --> 00:34:06,940
and now we are facing this problem of decomposing a signal in redundant dictionary

492
00:34:06,950 --> 00:34:11,320
so the idea is you are going to take your data

493
00:34:11,350 --> 00:34:12,340
and you're going to

494
00:34:12,360 --> 00:34:17,290
try to find the most sparsely presentation you can out of your

495
00:34:17,300 --> 00:34:19,450
transform diction

496
00:34:19,460 --> 00:34:21,060
and what you hope

497
00:34:21,070 --> 00:34:25,570
is that what we call for a set of coefficients

498
00:34:26,220 --> 00:34:31,020
precisely corresponds to the approximation support of the real function because

499
00:34:31,050 --> 00:34:33,100
what we call the

500
00:34:33,150 --> 00:34:34,420
two inverts

501
00:34:34,430 --> 00:34:36,200
the function

502
00:34:37,110 --> 00:34:40,700
you're just going to say oh i observe u phi p

503
00:34:40,700 --> 00:34:44,940
so in the original signal what i must have had was fighting

504
00:34:45,920 --> 00:34:49,790
here you're using your prior information because you is not invertible so they could have

505
00:34:49,790 --> 00:34:55,000
been many other functions but since you know that f is sparse in this basis

506
00:34:55,010 --> 00:34:57,510
you've decided it was fine

507
00:34:57,590 --> 00:35:01,340
that's all very well indeed out of the

508
00:35:01,370 --> 00:35:03,020
you've selected

509
00:35:03,030 --> 00:35:09,610
the appropriate function for so it's a pattern recognition problem you had to find the

510
00:35:09,610 --> 00:35:12,400
appropriate part of

511
00:35:12,430 --> 00:35:16,870
after degraded observation OK

512
00:35:18,150 --> 00:35:19,550
does that work

513
00:35:19,560 --> 00:35:22,800
OK let's look at sparse spike deconvolution

514
00:35:22,810 --> 00:35:26,540
this is an example an observed that would here here's five

515
00:35:26,650 --> 00:35:28,840
those close to the

516
00:35:29,730 --> 00:35:31,230
this is your data

517
00:35:31,250 --> 00:35:32,620
with the

518
00:35:33,790 --> 00:35:39,310
you do decomposition in your transform dictionary minimize now one norm and what you get

519
00:35:39,310 --> 00:35:41,110
is what you have on the right

520
00:35:41,130 --> 00:35:45,320
what you can see f till estimator is very close to f

521
00:35:45,330 --> 00:35:46,650
at the beginning

522
00:35:46,680 --> 00:35:48,340
in this region

523
00:35:48,340 --> 00:35:50,160
now despite

524
00:35:51,790 --> 00:35:54,240
you completely messed

525
00:35:54,260 --> 00:35:58,180
now why is that the case because if you take what you're working working out

526
00:35:58,180 --> 00:36:00,870
of your way translate

527
00:36:02,340 --> 00:36:06,400
well that's what you cannot recognise anymore

528
00:36:06,510 --> 00:36:10,140
you can detect individual events and your

529
00:36:10,190 --> 00:36:14,630
OK so what is actually that shows that in order to be able to do

530
00:36:14,630 --> 00:36:16,590
these kind of things

531
00:36:16,600 --> 00:36:21,370
so this kind of pattern recognition version you need to constraints on your

532
00:36:21,400 --> 00:36:23,250
dictionary often

533
00:36:23,250 --> 00:36:26,230
and this constraint is notion of you got here

534
00:36:26,240 --> 00:36:31,020
what's the a again the idea is out of the data

535
00:36:31,030 --> 00:36:35,340
you're going to decompose that in the transformed dictionary

536
00:36:35,410 --> 00:36:39,630
and you want to identify the approximation support of

537
00:36:39,640 --> 00:36:44,590
the first thing you need is that if you have a fast decomposition of

538
00:36:44,590 --> 00:36:46,230
the elements of

539
00:36:46,230 --> 00:36:49,810
the question is which of those is the best

540
00:36:49,820 --> 00:36:52,550
well if we look at it in a probabilistic way

541
00:36:52,560 --> 00:36:56,980
we can actually show the decoding three one appeals dismissed intuitively

542
00:36:57,030 --> 00:36:59,940
this one is actually the most probable

543
00:36:59,950 --> 00:37:04,320
so much as well that

544
00:37:04,410 --> 00:37:08,610
so we wanted to it is calculate the probability

545
00:37:08,660 --> 00:37:09,920
any given model

546
00:37:09,930 --> 00:37:12,670
produced the observed sequence

547
00:37:12,720 --> 00:37:16,300
and we do that with reference to all of the possible sequences this is the

548
00:37:16,950 --> 00:37:18,920
all the possible sequences

549
00:37:18,920 --> 00:37:21,680
but that model could also produce

550
00:37:21,730 --> 00:37:23,800
so if we assume

551
00:37:23,860 --> 00:37:27,400
what that the sequence was the results of model

552
00:37:28,340 --> 00:37:30,760
six single bit sequences

553
00:37:30,780 --> 00:37:35,450
and the original knowledge of the system is the bits can be placed anywhere

554
00:37:35,490 --> 00:37:37,840
i can overlap

555
00:37:37,850 --> 00:37:39,670
and we have to consider

556
00:37:39,740 --> 00:37:44,440
it's a perfectly good decoding this sequence how many of the sequences

557
00:37:44,450 --> 00:37:46,970
could this model generated

558
00:37:46,980 --> 00:37:49,120
and the answer is of course

559
00:37:49,170 --> 00:37:50,540
we can place each bit

560
00:37:50,550 --> 00:37:52,040
one of ten positions

561
00:37:52,050 --> 00:37:53,750
allowed to overlap

562
00:37:53,800 --> 00:37:59,460
so there are ten to the six possible sequences this model could have generated

563
00:37:59,470 --> 00:38:02,750
the question is how many of those sequences

564
00:38:03,180 --> 00:38:07,420
look like format exactly sequence we observe

565
00:38:07,420 --> 00:38:09,650
that gives us a measure of the probability

566
00:38:09,790 --> 00:38:11,050
this model

567
00:38:11,090 --> 00:38:14,070
generates or explains the sequence

568
00:38:14,080 --> 00:38:16,750
because we can interchange their

569
00:38:16,810 --> 00:38:18,800
and we can commute

570
00:38:18,880 --> 00:38:21,920
he's been warned that changing our sequence

571
00:38:21,960 --> 00:38:24,980
you can see that there are going to be six factorial

572
00:38:26,390 --> 00:38:29,180
sequences generated from this model that will match

573
00:38:29,230 --> 00:38:31,270
so the probability of this model

574
00:38:31,280 --> 00:38:33,430
the probability of the data given the model

575
00:38:33,530 --> 00:38:38,170
six factorial over ten to six seven twenty seven million

576
00:38:38,270 --> 00:38:44,460
that to probability is point no no no seventy four that's

577
00:38:44,520 --> 00:38:47,370
everyone OK with that

578
00:38:47,520 --> 00:38:50,550
so if we were to actually

579
00:38:50,580 --> 00:38:51,700
run simulation

580
00:38:53,220 --> 00:38:55,550
from that very moment just described the

581
00:38:55,560 --> 00:38:58,070
we should find this is the proportion

582
00:38:58,120 --> 00:39:02,690
it actually look like that of say one example if you know convinced

583
00:39:02,710 --> 00:39:04,850
so just following after that

584
00:39:04,880 --> 00:39:05,680
model two

585
00:39:05,680 --> 00:39:07,870
three two bit sequences

586
00:39:07,880 --> 00:39:10,700
we have to place three symbols

587
00:39:10,760 --> 00:39:14,040
and one of only nine positions as nine q possibilities

588
00:39:14,080 --> 00:39:15,220
we can permute them

589
00:39:15,230 --> 00:39:17,280
in three factorial ways

590
00:39:17,290 --> 00:39:20,420
so we have six o seven twenty nine

591
00:39:20,550 --> 00:39:22,900
to one or type two

592
00:39:22,960 --> 00:39:25,510
on this intuitively appealing sequence

593
00:39:25,550 --> 00:39:27,440
seven ways of placing this

594
00:39:28,720 --> 00:39:31,000
yes some laser placing this

595
00:39:31,050 --> 00:39:33,380
nine ways of placing this

596
00:39:33,390 --> 00:39:36,290
but only one of these generated sequences

597
00:39:36,340 --> 00:39:37,680
is the precise hit

598
00:39:37,690 --> 00:39:38,630
we won

599
00:39:38,710 --> 00:39:41,030
this is less complex model

600
00:39:41,040 --> 00:39:44,300
because only the only one in the set of matches

601
00:39:44,300 --> 00:39:48,000
the set is only sixty nine sorry sixty three large

602
00:39:48,010 --> 00:39:50,570
so the probability is one sixty

603
00:39:50,660 --> 00:39:53,390
o point one five nine

604
00:39:53,430 --> 00:39:55,050
so the simplest model

605
00:39:55,140 --> 00:39:56,680
because we consider

606
00:39:56,710 --> 00:39:58,440
all the other possible sequences

607
00:39:58,450 --> 00:39:59,760
it is more probable

608
00:39:59,780 --> 00:40:03,470
so all three the data equally can't separate them in terms of how well they

609
00:40:03,470 --> 00:40:04,760
fit the data

610
00:40:04,800 --> 00:40:06,060
if we take account

611
00:40:06,120 --> 00:40:08,440
all the other possible models they could match

612
00:40:08,450 --> 00:40:11,010
this one looks more probable

613
00:40:11,250 --> 00:40:13,300
we do data mining course

614
00:40:13,310 --> 00:40:14,600
we don't normally

615
00:40:14,650 --> 00:40:17,550
it's not a case of model either fits the data

616
00:40:17,550 --> 00:40:20,090
the data perfectly or doesn't

617
00:40:20,100 --> 00:40:22,080
use these is the degree of accuracy

618
00:40:22,150 --> 00:40:24,920
squared error misclassification rate something like that

619
00:40:24,970 --> 00:40:27,300
so that's why introduce the full model

620
00:40:27,350 --> 00:40:29,200
which is why we look at

621
00:40:29,250 --> 00:40:31,960
and over simple decoding

622
00:40:32,030 --> 00:40:35,020
which seems some form of our

623
00:40:35,030 --> 00:40:39,190
so this decoding the seventy three possible places i could place simple

624
00:40:39,250 --> 00:40:41,700
generating set is only has three

625
00:40:41,710 --> 00:40:42,980
elements in it

626
00:40:43,040 --> 00:40:45,810
but seems to bits of our

627
00:40:45,820 --> 00:40:48,730
and and i'm going to seem very simple noise

628
00:40:48,790 --> 00:40:52,580
he says i can place those two bits anywhere that any two bits

629
00:40:52,590 --> 00:40:55,680
and i went the same it's white

630
00:40:55,690 --> 00:40:57,270
so the possibility

631
00:40:57,280 --> 00:41:00,300
different areas i could given the could be too

632
00:41:00,350 --> 00:41:03,420
tend to use two or forty five

633
00:41:03,430 --> 00:41:05,830
the probability this model is one

634
00:41:06,000 --> 00:41:09,690
three times forty five hundred thirty five

635
00:41:09,750 --> 00:41:14,210
and that works at this point there will not some form

636
00:41:15,760 --> 00:41:17,890
the over simple model

637
00:41:17,900 --> 00:41:19,320
doesn't quite fit the data

638
00:41:19,410 --> 00:41:22,420
is less probable than the relatively simple model

639
00:41:22,470 --> 00:41:26,120
it does so you can say hamas this probability calculation

640
00:41:26,150 --> 00:41:28,420
automatically imposed trade

641
00:41:28,460 --> 00:41:33,320
but interestingly there was simple model is actually an order magnitude more probable

642
00:41:33,420 --> 00:41:35,800
and the most complex model we have

643
00:41:35,840 --> 00:41:38,060
the escape probability calculation

644
00:41:38,070 --> 00:41:39,730
this automatically

645
00:41:39,790 --> 00:41:40,910
if you like

646
00:41:40,960 --> 00:41:43,340
built in occam's razor trade

647
00:41:43,440 --> 00:41:45,190
occam's razor trade

648
00:41:45,250 --> 00:41:49,160
it's assigned low probability too complex model

649
00:41:49,170 --> 00:41:52,900
because they had to take into account all the other sequences all the other data

650
00:41:52,900 --> 00:41:55,540
model that accurately predicted

651
00:41:55,580 --> 00:41:56,580
and it's also

652
00:41:56,600 --> 00:41:59,650
signed low probability to over simple model

653
00:41:59,660 --> 00:42:00,620
based done that

654
00:42:00,640 --> 00:42:02,920
because it had to introduce noise model

655
00:42:02,970 --> 00:42:05,180
not to appropriately explain the data

656
00:42:05,220 --> 00:42:07,210
and that noise model

657
00:42:07,380 --> 00:42:12,410
then the space of all possible data sets it could still observed again gets expanded

658
00:42:12,420 --> 00:42:15,780
because of the noise assumption

659
00:42:15,810 --> 00:42:18,070
so i just want convincing case

660
00:42:18,080 --> 00:42:21,300
you know maybe you don't believe that maybe that means calculations

661
00:42:21,330 --> 00:42:32,140
i just have a quick simulation i can say

662
00:42:32,410 --> 00:42:35,330
well we just simply empirically proven

663
00:42:35,340 --> 00:42:37,100
those numbers in the last slide

664
00:42:37,300 --> 00:42:40,460
i'm just going to do with a few lines of simple model you can see

665
00:42:40,460 --> 00:42:42,380
yourself you so minded

666
00:42:42,840 --> 00:42:47,530
we just going to sample from those four models more just verify this values

667
00:42:47,540 --> 00:42:51,930
so this is just six placed random almost write the code and you had

668
00:42:51,940 --> 00:42:54,040
good luck to you probably

669
00:42:54,070 --> 00:42:57,300
this is three two space random for t

670
00:42:57,340 --> 00:43:00,300
on the eighth with two randomly for

671
00:43:00,680 --> 00:43:05,880
and every time symbol actually matches the target sequence of flashing white i will consider

672
00:43:05,890 --> 00:43:07,530
i'm just really stimulating

673
00:43:07,540 --> 00:43:14,100
exactly what you might think

674
00:43:14,120 --> 00:43:16,380
if you just wanted to prove that

675
00:43:18,100 --> 00:43:19,280
i think

676
00:43:19,320 --> 00:43:21,640
so we just a ten thousand samples

677
00:43:21,650 --> 00:43:26,260
and what is simply count how many times they generative models that simulate models that

678
00:43:28,830 --> 00:43:30,680
as you can see

679
00:43:30,710 --> 00:43:32,470
if you have the more convinced

680
00:43:32,500 --> 00:43:33,620
model three

681
00:43:33,730 --> 00:43:35,090
much more probable

682
00:43:35,200 --> 00:43:40,320
ten thousand times it hits the target sequence predicts it explains it

683
00:43:40,670 --> 00:43:42,550
so far more than the other models

684
00:43:42,630 --> 00:43:47,090
the red lines are the theoretical values and actually much formal knowledge expected

685
00:43:48,410 --> 00:43:49,380
the model for

686
00:43:49,400 --> 00:43:53,190
the noise the over simple model doesn't match the data with noise

687
00:43:53,260 --> 00:44:07,370
still predicts the target sequence from all the complicated model one

688
00:44:07,390 --> 00:44:12,470
so have the written down much in probability distributions are really done any probabilistic manipulation

689
00:44:12,470 --> 00:44:15,010
done anything by counting sequences

690
00:44:15,030 --> 00:44:18,420
but this example is basically bayesian inference in disguise

691
00:44:18,460 --> 00:44:19,780
and the reason is

692
00:44:19,810 --> 00:44:23,550
it's because we calculated probabilities from models

693
00:44:23,650 --> 00:44:25,560
take into account

694
00:44:25,570 --> 00:44:27,270
all the above

695
00:44:27,310 --> 00:44:31,040
that's the data those models capable of explaining this is the essence

696
00:44:31,050 --> 00:44:34,050
the way bayesian inference implements ockham's razor

697
00:44:34,100 --> 00:44:36,180
penalizes over complex models

698
00:44:36,180 --> 00:44:39,340
i apply the disjunction rules which state is

699
00:44:40,130 --> 00:44:43,130
one go and the right branch from the other

700
00:44:43,180 --> 00:44:45,130
this is the left branch

701
00:44:45,150 --> 00:44:48,070
it is the right branch and copy everything across

702
00:44:48,130 --> 00:44:50,530
that's what the external

703
00:44:50,530 --> 00:44:52,590
OK so this is x

704
00:44:52,630 --> 00:44:54,300
this is the next

705
00:44:54,320 --> 00:45:00,860
and now the contradictions on both sides

706
00:45:07,650 --> 00:45:14,320
kids that they

707
00:45:14,360 --> 00:45:18,510
i i made up you didn't question when we when i told you about necessitation

708
00:45:21,400 --> 00:45:25,110
i mean you you see what's going on basically what it's doing is it's creating

709
00:45:25,110 --> 00:45:27,630
a successor world

710
00:45:27,650 --> 00:45:32,030
read the bottom guys that success that makes the diameter

711
00:45:32,760 --> 00:45:35,470
this is the world that makes the diamond guy true

712
00:45:35,490 --> 00:45:38,590
and this makes the boxes well you have to take all the boxes across the

713
00:45:38,590 --> 00:45:40,490
junction box

714
00:45:44,650 --> 00:45:47,300
we assert that

715
00:45:47,380 --> 00:45:49,700
in a moment of get their money

716
00:45:49,720 --> 00:45:54,590
usually in tablet formulations you don't see multiset that's because they don't do it properly

717
00:45:54,630 --> 00:45:56,510
OK i want to do it properly

718
00:45:57,320 --> 00:45:59,240
there is a k

719
00:45:59,260 --> 00:46:02,050
there is a closed k tableau for this guy

720
00:46:02,070 --> 00:46:05,740
OK so what does that mean well theoretically has all show you know what it

721
00:46:05,740 --> 00:46:07,780
means is that

722
00:46:07,820 --> 00:46:12,280
the negation of this formula is not k satisfiable

723
00:46:12,320 --> 00:46:15,910
why because this formula is valid we know

724
00:46:15,930 --> 00:46:17,320
i'll get onto

725
00:46:17,340 --> 00:46:19,430
OK so more examples

726
00:46:19,450 --> 00:46:20,670
same rules

727
00:46:22,610 --> 00:46:27,050
this is an instance of the t shaped box p know implies b

728
00:46:27,180 --> 00:46:31,220
the previous slide show you define negated i get is

729
00:46:31,240 --> 00:46:35,150
the only thing i can do is apply the and so i apply

730
00:46:35,170 --> 00:46:37,260
now i'm stuck

731
00:46:38,220 --> 00:46:42,220
this thing has to be driven by diamond and there are no diamonds

732
00:46:42,260 --> 00:46:46,800
OK there are disjunctions and conjunctions and there are contradictions

733
00:46:46,820 --> 00:46:48,990
so what do i conclude

734
00:46:49,670 --> 00:46:51,700
this tabloid

735
00:46:52,900 --> 00:46:54,400
not closed

736
00:46:54,430 --> 00:46:56,700
i tried one and it didn't come

737
00:46:56,720 --> 00:46:58,720
over here the same thing

738
00:46:58,760 --> 00:47:01,170
push negation normal form

739
00:47:01,200 --> 00:47:03,650
there is a conjunction applications

740
00:47:03,650 --> 00:47:07,780
i've got it done formula so i can apply the diamond rule strip a strip

741
00:47:07,780 --> 00:47:10,510
off the outermost dominant expose this guy

742
00:47:10,550 --> 00:47:12,840
take away the box

743
00:47:12,910 --> 00:47:16,110
support of the outermost i mean there are no boxes

744
00:47:16,110 --> 00:47:18,700
and now i'm stuck kind of doing things

745
00:47:18,700 --> 00:47:21,050
OK so that tableau

746
00:47:21,070 --> 00:47:22,220
the club

747
00:47:22,220 --> 00:47:24,470
but i claim there is no

748
00:47:24,470 --> 00:47:26,950
because k tableau for these guys

749
00:47:27,010 --> 00:47:29,400
had i go from one

750
00:47:33,570 --> 00:47:36,760
i just tried one

751
00:47:36,800 --> 00:47:40,200
and now i'm saying it doesn't matter what you do you won't find clients one

752
00:47:40,200 --> 00:47:48,200
how to make that leap

753
00:47:48,220 --> 00:47:49,490
that's one way

754
00:47:49,510 --> 00:47:51,700
but not it's much easier

755
00:47:51,740 --> 00:47:55,340
it's completely deterministic i had no choice is

756
00:47:55,360 --> 00:47:59,740
what could i went in negation normal form

757
00:47:59,800 --> 00:48:03,860
and that's all i could do so there is only one template that i could

758
00:48:04,030 --> 00:48:07,630
sit here what can i do i couldn't do anything

759
00:48:07,670 --> 00:48:10,090
right it's completely deterministic

760
00:48:10,240 --> 00:48:12,840
because this doesn't hold in general right so

761
00:48:12,900 --> 00:48:15,630
we'll get to that in minute

762
00:48:18,260 --> 00:48:22,550
they were more examples of tableau now your question about six

763
00:48:22,570 --> 00:48:24,670
and this is the proper way to do

764
00:48:24,680 --> 00:48:26,030
proof theory

765
00:48:26,090 --> 00:48:27,170
but most

766
00:48:27,180 --> 00:48:31,030
tablet systems in in the literature don't do that

767
00:48:31,050 --> 00:48:33,220
do don't want to keep that anymore

768
00:48:36,650 --> 00:48:37,860
let's get

769
00:48:40,180 --> 00:48:43,470
you know very well

770
00:48:46,200 --> 00:48:47,630
is that blood

771
00:48:48,840 --> 00:48:50,260
and now i'm going to do

772
00:48:50,280 --> 00:48:52,840
this proved a couple of lemmas

773
00:48:52,880 --> 00:48:56,650
so if i semicolon x has a closedk tableau

774
00:48:56,670 --> 00:48:59,170
so let's call phi semicolon x

775
00:48:59,510 --> 00:49:02,590
right i remember so what i'm going to do is i'm going to take it

776
00:49:02,800 --> 00:49:06,240
for five semicolon x

777
00:49:06,260 --> 00:49:11,740
so if there is a closedk then so does phi semicolon x column y four

778
00:49:12,570 --> 00:49:21,720
how my going to close this tabloid

779
00:49:21,840 --> 00:49:25,570
just going to do whatever i did hear and ignore the stuff in

780
00:49:25,630 --> 00:49:27,630
OK thank know this stuff and why

781
00:49:27,630 --> 00:49:29,470
it just gets carried out

782
00:49:29,510 --> 00:49:30,380
as this

783
00:49:31,490 --> 00:49:35,340
right the stuff that i don't want to take statistics carried down

784
00:49:35,360 --> 00:49:40,050
and sometimes here some of the boxes will come across but i can keep doing

785
00:49:40,050 --> 00:49:42,530
that just ignore this stuff

786
00:49:43,150 --> 00:49:46,900
it's not quite as easy as that but that's the intuition

787
00:49:46,910 --> 00:49:48,880
OK what does it say

788
00:49:48,900 --> 00:49:51,010
is the intuition here

789
00:49:51,130 --> 00:49:55,110
we have a closed tableau already then adding extra junk at the root

790
00:49:55,110 --> 00:50:00,370
this new ball okay if the ball that we drew is not of a special color

791
00:50:00,610 --> 00:50:05,950
then is of some color drawn from H then we will note its color and then

792
00:50:05,950 --> 00:50:13,810
return two balls of that color back into the urn okay so basically whenever we reach

793
00:50:13,810 --> 00:50:18,670
into the urn and pick our ball with probability alpha over Alpha plus N we're

794
00:50:18,670 --> 00:50:23,570
gonna pick a ball of a special color because we start off with alpha balls

795
00:50:23,570 --> 00:50:28,930
of that color of that special color with probability one over Alpha plus

796
00:50:28,970 --> 00:50:33,250
N so basically this is the probability of picking one of the balls out from

797
00:50:33,250 --> 00:50:41,390
the urn and we'll pick ball I basically okay yeah so this is kind of

798
00:50:41,400 --> 00:50:49,870
the the interpretation the metaphor for this urn scheme okay

799
00:50:49,870 --> 00:50:55,450
so an interesting property of thus earn scheme is that it has this clustering

800
00:50:55,450 --> 00:51:00,190
property right so basically if you look at N of this variables theta

801
00:51:00,190 --> 00:51:04,310
one to theta N then you notice that because each of the thetas can

802
00:51:04,310 --> 00:51:08,750
take on the same value as one of the previous thetas they will

803
00:51:08,750 --> 00:51:15,570
take on they could take on less than N distinct values right so the

804
00:51:15,570 --> 00:51:19,970
total number of distinct values is given by big K and that could be

805
00:51:19,970 --> 00:51:25,650
less than N okay it's at most N when everything has a distinct value but it's

806
00:51:25,650 --> 00:51:31,170
it's a it could be less than N okay so we can think of the distinct values

807
00:51:31,520 --> 00:51:36,490
let's call them theta star one to theta star K then we can think of this

808
00:51:36,490 --> 00:51:41,730
distinct values as basically defining a partition of the index set one to N

809
00:51:41,730 --> 00:51:49,070
alright so that if data item so that data item I is in cluster K

810
00:51:49,070 --> 00:51:55,270
if theta I takes on the Kth distinct value okay so this defines a clustering

811
00:51:55,270 --> 00:52:01,590
of theta one to theta N and if you look at the induced distribution of a

812
00:52:01,590 --> 00:52:05,710
partitions of one to N this is called the Chinese restaurant process and this is

813
00:52:05,710 --> 00:52:10,850
now gonna relate back to the problem of model based clustering so we

814
00:52:10,850 --> 00:52:16,070
can think of each theta I here as basically the parameter of the cluster that

815
00:52:16,070 --> 00:52:23,330
data item I belongs to okay and they're at most K different clusters among a

816
00:52:23,330 --> 00:52:27,970
data item of among a data set of size N okay

817
00:52:28,010 --> 00:52:33,310
and it turns out that in the case of of coarse model based clustering this

818
00:52:33,310 --> 00:52:38,030
notion of the partition of the data set one to N indexed by one to

819
00:52:38,030 --> 00:52:44,070
N is of course gonna play a central role in the problem of clustering because

820
00:52:44,070 --> 00:52:48,490
that should be the output of our clustering algorithm as a partition of our data

821
00:52:48,490 --> 00:52:58,190
set okay so that leads us to the Chinese restaurant process to before I start on the Chinese

822
00:52:58,190 --> 00:53:03,310
restaurant process I'd like to discuss be a bit more precise by what I mean by

823
00:53:03,310 --> 00:53:11,330
a partition okay let's say that we have a set S big S okay so

824
00:53:11,330 --> 00:53:16,480
in this case our big S consists of six individuals alpha Alice Bob Charles David Emma

825
00:53:16,650 --> 00:53:23,770
and Florence so a partition is basically at this joint's family of subsets of S

826
00:53:23,770 --> 00:53:31,030
whose union is S okay so here's a petition okay so it consists of a cluster here

827
00:53:31,050 --> 00:53:36,150
of alpha and David of Alice and David another cluster here of Bob Charles and Emma and another

828
00:53:36,150 --> 00:53:42,130
cluster where Florence is by herself and the set of all partition of S is gonna

829
00:53:42,140 --> 00:53:46,890
be denoted by this script P of S okay so that's a set of all partitions

830
00:53:46,890 --> 00:53:52,050
and basically a random partition is gonna be a random variables that take on values

831
00:53:52,050 --> 00:54:00,470
in that set okay and particularly will we'll working with partitions of of S where

832
00:54:00,470 --> 00:54:04,470
S is the index set of our data sets so it's gonna be one to

833
00:54:04,470 --> 00:54:15,510
N okay so and that the typical notation here is this square brackets N okay right so what's

834
00:54:15,510 --> 00:54:22,830
a Chinese restaurant process it's basically a random partition okay and here's a generative process for the

835
00:54:22,830 --> 00:54:29,270
random partition okay so imagine there's lots of metaphors in Bayesian nonparametrics is

836
00:54:29,270 --> 00:54:34,510
part of the nice fun thing about this area in in this metaphor

837
00:54:34,880 --> 00:54:40,070
imagine that we have restaurants okay of a Chinese restaurant with an infinite number of tables

838
00:54:40,070 --> 00:54:46,010
each table consider infinite number of customers okay customers are gonna come in

839
00:54:46,010 --> 00:54:50,830
one at a time and sit at some table okay so customer one comes in

840
00:54:50,830 --> 00:54:56,990
and will sit at some table and we can just call that table one okay

841
00:54:56,990 --> 00:55:01,950
and then a customer two comes in can now decide whether to sit with customer one or at

842
00:55:01,950 --> 00:55:06,670
new table and customer tree comes in can now decide to sit with custom one customer

843
00:55:06,670 --> 00:55:12,890
two or new table okay and each of customer has a decision to make and basically

844
00:55:12,890 --> 00:55:19,570
the probability that a customer that just comes in will sit at table C

845
00:55:19,570 --> 00:55:24,950
is gonna be equal to the number of customers already sitting at that table divided by

846
00:55:24,950 --> 00:55:30,910
Alpha plus the total number of customers sitting around all the tables at that point

847
00:55:30,910 --> 00:55:35,330
in time and the probability that the customer will sit at the new table is

848
00:55:35,330 --> 00:55:39,430
gonna be equal to alpha divided by the normalization constant

849
00:55:40,550 --> 00:55:48,450
so basically how does this Chinese restaurant process define a a partition basically

850
00:55:48,450 --> 00:55:51,180
there's a term like that so what's the idea so

851
00:55:51,200 --> 00:55:54,050
if you if you are

852
00:55:54,110 --> 00:55:58,550
in this country space on the robot wants to get to this part of the

853
00:55:58,550 --> 00:56:02,300
space and once or that part of the space

854
00:56:02,410 --> 00:56:04,880
you could just discovered that the state space by

855
00:56:04,930 --> 00:56:06,970
as we know that our

856
00:56:07,030 --> 00:56:11,180
so it's enough and and OK so if you discretize than wealth

857
00:56:11,220 --> 00:56:13,740
you get some resolution and

858
00:56:13,780 --> 00:56:16,910
again the longer so

859
00:56:18,070 --> 00:56:21,530
and this doesn't work for the reason i

860
00:56:21,610 --> 00:56:25,110
they cannot work due to his chances like this

861
00:56:25,160 --> 00:56:26,450
so what do you do

862
00:56:26,470 --> 00:56:32,220
so one problem is discretisation is that when you try to uniformly colored space and

863
00:56:32,380 --> 00:56:34,720
as i tried to show you

864
00:56:34,740 --> 00:56:35,860
if you

865
00:56:37,930 --> 00:56:43,160
ridiculous accuracy of one or excellence and you have a high dimensional space in order

866
00:56:43,160 --> 00:56:45,470
to have job someone the cattle

867
00:56:45,490 --> 00:56:49,050
it can be a better option right so that's the idea

868
00:56:49,070 --> 00:56:50,300
so is enough

869
00:56:50,410 --> 00:56:55,070
doing uniform discusses at this position and what you do is that

870
00:56:55,090 --> 00:57:01,970
uniformly distributed uniformly at random select some points so you do at random discretisation

871
00:57:03,400 --> 00:57:07,610
so the question is about was the finite MDP in the case when

872
00:57:07,880 --> 00:57:11,510
you do a uniform grid escaped isation

873
00:57:11,510 --> 00:57:13,530
and we had this

874
00:57:13,580 --> 00:57:17,930
so this is this is the contour plots or so to say i have the

875
00:57:18,410 --> 00:57:20,360
density function of the

876
00:57:20,450 --> 00:57:25,550
the next distribution and if this that then you get something like this so here

877
00:57:25,550 --> 00:57:26,880
the trail of as

878
00:57:26,900 --> 00:57:30,130
correspond to higher probabilities

879
00:57:30,160 --> 00:57:36,200
and so you would get a discrete problem representation and if you do a uniform

880
00:57:37,740 --> 00:57:39,760
so how do you do that

881
00:57:39,760 --> 00:57:41,470
if you have this wrong

882
00:57:41,490 --> 00:57:48,800
so that that's the first problem if you want to have this random discretisation

883
00:57:49,800 --> 00:57:54,360
again what you have to do is just to look at the monte carlo literature

884
00:57:54,800 --> 00:57:58,070
basically if you want to compute

885
00:57:58,760 --> 00:58:04,030
and ultimately value function what you have to do is that well if you find

886
00:58:04,030 --> 00:58:08,260
a problem some over the next state and you do you want to use value

887
00:58:08,280 --> 00:58:11,130
addition you some over the next

888
00:58:11,180 --> 00:58:13,180
if you have it continues

889
00:58:13,200 --> 00:58:18,400
space and then the song has to be replaced by the so the change

890
00:58:19,360 --> 00:58:23,050
this is integrated with respect to the next state y

891
00:58:23,110 --> 00:58:24,090
and so

892
00:58:24,110 --> 00:58:27,610
you want to compute in the rest of this form so hard to compute in

893
00:58:27,640 --> 00:58:29,800
the as of this form

894
00:58:29,820 --> 00:58:32,630
but you can use weighted importance sampling

895
00:58:32,640 --> 00:58:36,820
so imagine that you're at a certain point

896
00:58:36,840 --> 00:58:41,970
and you sound puts some other points may be uniformly at random

897
00:58:42,030 --> 00:58:47,740
then we learned from almost all that you could be waiting for downsampling

898
00:58:47,840 --> 00:58:53,030
so this is what you do exactly so in order to approximate this integral here

899
00:58:53,050 --> 00:58:55,130
which is

900
00:58:55,140 --> 00:58:57,280
if you're primary interest

901
00:58:57,360 --> 00:59:01,720
basically you just you know computer

902
00:59:02,200 --> 00:59:06,260
this is some of the products and divided by the sum

903
00:59:06,300 --> 00:59:09,820
and that's going to converge to this integral

904
00:59:09,840 --> 00:59:12,090
so that was waiting for something

905
00:59:12,130 --> 00:59:13,400
is not clear

906
00:59:13,400 --> 00:59:22,550
does any does everyone see that

907
00:59:26,320 --> 00:59:30,140
so you know this is just the last large numbers so you divide by and

908
00:59:30,140 --> 00:59:31,720
you divide by here

909
00:59:31,800 --> 00:59:34,010
here by and so

910
00:59:34,050 --> 00:59:39,530
this is the probability distribution so this is going to converge to to just one

911
00:59:39,530 --> 00:59:43,300
and this is exactly call that into this in

912
00:59:50,570 --> 00:59:53,910
OK so

913
00:59:53,950 --> 00:59:57,470
so far so good

914
00:59:57,490 --> 01:00:03,090
and so what what do we think that this might avoid the curse of dimensionality

915
01:00:03,110 --> 01:00:08,320
well you know in high dimensional spaces if you want to compute an integral is

916
01:00:08,320 --> 01:00:10,820
also what to learn from numbers four

917
01:00:11,950 --> 01:00:16,800
you could really interested this sampling saying then

918
01:00:18,950 --> 01:00:21,400
this is going to come independently

919
01:00:21,410 --> 01:00:25,740
at the rate that is independent of the dimensionality of the state space

920
01:00:25,760 --> 01:00:27,220
that's fine

921
01:00:27,240 --> 01:00:29,260
so far we have a good track

922
01:00:29,320 --> 01:00:30,880
and so what do we do

923
01:00:31,550 --> 01:00:34,880
the way they are going to discretize the NDP

924
01:00:34,910 --> 01:00:35,800
is that

925
01:00:35,820 --> 01:00:41,550
we just compute this this creates a transition probabilities so you have this base points

926
01:00:41,550 --> 01:00:45,280
x one and x and so that's the there on the grid that was laid

927
01:00:46,340 --> 01:00:47,530
over the

928
01:00:47,550 --> 01:00:48,910
state space

929
01:00:50,070 --> 01:00:53,340
so that we want to come up with the discrete MDP

930
01:00:53,340 --> 01:00:57,360
so what do we do so we can't we have to compute some transition probabilities

931
01:00:57,360 --> 01:00:58,780
and rewards

932
01:00:58,820 --> 01:01:00,840
the transition probabilities

933
01:01:00,840 --> 01:01:02,160
i going to be

934
01:01:02,180 --> 01:01:05,910
just this normalized transition densities so

935
01:01:05,930 --> 01:01:08,630
if i had stayed xmj

936
01:01:08,660 --> 01:01:11,860
i two action a what's my

937
01:01:11,860 --> 01:01:17,410
density at a point x y z is given by p i and

938
01:01:17,470 --> 01:01:22,180
my transition probability and the discrete problem is going to be proportional to the

939
01:01:22,200 --> 01:01:23,720
when i do this

940
01:01:23,720 --> 01:01:25,990
i'm just

941
01:01:26,030 --> 01:01:29,490
pre computing what i'm going to need

942
01:01:29,530 --> 01:01:31,820
if i want to execute

943
01:01:32,090 --> 01:01:35,240
value iteration so he invented tradition

944
01:01:35,260 --> 01:01:38,240
i will need to compute this in right

945
01:01:38,340 --> 01:01:42,200
instead of computing that in that i want to use or santa claus

946
01:01:42,260 --> 01:01:46,930
so right now or something because it will be the same sample set x x

947
01:01:46,930 --> 01:01:48,900
suffice it of y phi

948
01:01:48,910 --> 01:01:53,490
so i is here via five because that corresponds here to the next state

949
01:01:53,530 --> 01:01:58,840
but in the random discretisation method you just had this random great

950
01:01:58,860 --> 01:02:01,470
and you are using that sample

951
01:02:01,470 --> 01:02:07,260
in all steps of a iteration right so that a set of samples is uniformly

952
01:02:08,400 --> 01:02:09,840
or the state space

953
01:02:09,860 --> 01:02:12,720
so it just satisfy this condition

954
01:02:12,780 --> 01:02:14,630
the same condition is here

955
01:02:14,680 --> 01:02:19,360
so just saying that these acts suffice if these are acts of phi

956
01:02:19,410 --> 01:02:22,450
then well what i can do is that there is enough

957
01:02:22,470 --> 01:02:27,220
during this island dividing this by the other i could compute

958
01:02:27,220 --> 01:02:29,660
does this ratio first

959
01:02:29,660 --> 01:02:33,430
we can show that if we are able to maximize that

960
01:02:33,490 --> 01:02:35,290
to find the best

961
01:02:35,740 --> 01:02:39,930
the best thing here the best new set of parameter

962
01:02:42,720 --> 01:02:46,310
then you can show that maximizing this

963
01:02:47,740 --> 01:02:51,140
the likelihood of your data so the goal was in the intellectual to find the

964
01:02:51,140 --> 01:02:58,010
parameters theta that maximizes the likelihood p of x given theta and there's this iterative

965
01:02:58,010 --> 01:02:59,270
way that tells you

966
01:02:59,290 --> 01:03:02,680
but if you're able to maximise its expectation

967
01:03:02,700 --> 01:03:04,540
then you maximize also

968
01:03:04,560 --> 01:03:05,490
the likelihood

969
01:03:05,510 --> 01:03:11,810
and here in fact you see the e and m steps because

970
01:03:12,770 --> 01:03:18,010
computing this is in fact doing the e step it's the your computing the expectation

971
01:03:18,010 --> 01:03:22,540
over the hidden viable and doing that is the same stuff

972
01:03:24,080 --> 01:03:27,080
hi i am not sure if i have time to

973
01:03:27,080 --> 01:03:30,220
two two weeks there is proof

974
01:03:31,560 --> 01:03:35,270
after that and i'm not going to explain it may be it's on your flight

975
01:03:35,270 --> 01:03:39,890
at least some of the slides in some slides in my website but i don't

976
01:03:39,890 --> 01:03:42,830
have time to to go

977
01:03:42,850 --> 01:03:48,140
what i would like instead is to to provide you intuitively of holidays that apply

978
01:03:48,950 --> 01:03:56,970
gaussian mixture models so

979
01:03:56,990 --> 01:03:58,870
what i said

980
01:03:58,890 --> 01:04:00,270
we first need

981
01:04:00,290 --> 01:04:05,620
to decide what is our having viable and as i showed you already graphically in

982
01:04:05,620 --> 01:04:09,030
that case we're going to decide that the hidden viable is

983
01:04:09,080 --> 01:04:13,220
that we're going to assume that each point was generated by only one goshen and

984
01:04:13,220 --> 01:04:15,720
we want to know which washington

985
01:04:16,580 --> 01:04:21,430
which points and this information is is going to be are inviable

986
01:04:22,760 --> 01:04:24,720
so let's go back to the mixture

987
01:04:24,760 --> 01:04:29,790
model so we have a mixture of gaussians which can be expressed here as a

988
01:04:29,790 --> 01:04:32,930
weighted sum this is the weight of each caution

989
01:04:32,970 --> 01:04:36,700
and this is the likelihood of it to goshen so this is the the gushing

990
01:04:36,700 --> 01:04:39,100
pretty and this is the way

991
01:04:39,120 --> 01:04:41,180
so it's the mixture model

992
01:04:41,270 --> 01:04:47,260
i'm going to introduce this is viable so i suppose i know

993
01:04:47,260 --> 01:04:48,510
i know which caution

994
01:04:48,540 --> 01:04:53,890
a generated which point so it because i know that

995
01:04:53,890 --> 01:04:58,450
four four while i can define this variable which is q i g

996
01:04:58,470 --> 01:05:01,890
which is going to be one if russian j

997
01:05:02,790 --> 01:05:03,540
o point

998
01:05:03,560 --> 01:05:08,450
i mean zero otherwise so i can just have these big matrix q

999
01:05:08,470 --> 01:05:13,120
which tells me which gaussian generated which point so of course i don't know that

1000
01:05:13,120 --> 01:05:17,220
but i suppose i know it

1001
01:05:18,850 --> 01:05:21,990
if i know the information then i can compute

1002
01:05:22,760 --> 01:05:25,910
the joint probability of the data

1003
01:05:27,540 --> 01:05:29,850
that information

1004
01:05:29,870 --> 01:05:33,100
the fact that i know which caution generated which

1005
01:05:33,120 --> 01:05:33,950
o point

1006
01:05:33,970 --> 01:05:37,870
by being the product over all the the examples

1007
01:05:37,890 --> 01:05:41,580
and then the the product of all the gaussians of

1008
01:05:42,600 --> 01:05:48,640
the priority of the goshen x two two this value which is one or zero

1009
01:05:48,640 --> 01:05:52,040
and the like you would to the part of this value which is one or

1010
01:05:53,450 --> 01:06:00,180
you have to understand is very very carefully these two value one effect to these

1011
01:06:00,180 --> 01:06:05,490
two powers or zero and one so when they are zero this is equal to

1012
01:06:06,390 --> 01:06:08,490
so when goshen

1013
01:06:10,760 --> 01:06:15,000
goshen j did not generated by i

1014
01:06:15,010 --> 01:06:20,580
all this is equal to one so it has no effect and when goshen

1015
01:06:20,630 --> 01:06:27,010
j generated point i then you have the weight the probability of goshen so in

1016
01:06:27,010 --> 01:06:31,200
the end you do have the real like would if you knew that information so

1017
01:06:31,200 --> 01:06:34,040
this is equivalent to the mixture model

1018
01:06:34,040 --> 01:06:37,660
mixture of gaussians if you know this information

1019
01:06:37,670 --> 01:06:43,920
now it's as as you so this auxiliary function that we thought

1020
01:06:43,930 --> 01:06:48,670
works with the log likelihood so we need to go into the log space so

1021
01:06:48,670 --> 01:06:51,630
we take that we're going to log

1022
01:06:51,630 --> 01:06:55,080
that's very useful in fact because of the products because

1023
01:06:55,130 --> 01:06:57,830
sons and the power

1024
01:06:57,840 --> 01:07:01,840
come here and this form is much easier to

1025
01:07:01,890 --> 01:07:04,540
to work with

1026
01:07:05,670 --> 01:07:08,010
i'm going to have to plug

1027
01:07:08,030 --> 01:07:15,880
my theoretical into that stuff so i defined again this auxiliary function which is the

1028
01:07:15,880 --> 01:07:18,330
expected value of the log blah blah

1029
01:07:18,430 --> 01:07:23,250
i just plug my question into inside this and because expect that

1030
01:07:23,270 --> 01:07:26,240
it already viable q

1031
01:07:26,250 --> 01:07:28,670
in fact the expectation of the sun

1032
01:07:28,680 --> 01:07:33,880
you can always showed is going to be the sum of the expectations where it

1033
01:07:33,880 --> 01:07:39,160
applies so in fact the only way are the only positions where i think you

1034
01:07:39,160 --> 01:07:44,800
are here and there so i'm going to put the expectation over q only so

1035
01:07:44,800 --> 01:07:47,840
i have put all my expectations

1036
01:07:48,700 --> 01:07:51,350
in in one place where it matters

1037
01:07:51,380 --> 01:07:58,450
and in that very useful because now so the goal now is to maximize there

1038
01:07:58,460 --> 01:08:02,220
that's the only thing i can do to maximize in fact two to work out

1039
01:08:02,390 --> 01:08:09,890
what i to expectation terms so i first need to estimate the expectation terms and

1040
01:08:11,450 --> 01:08:16,290
now i'm going to apply in basically and i'm only going to need to estimate

1041
01:08:16,290 --> 01:08:17,920
and this is basically

1042
01:08:17,960 --> 01:08:20,050
to estimate whether

1043
01:08:20,060 --> 01:08:21,750
that goshen

1044
01:08:21,760 --> 01:08:24,750
j a

1045
01:08:24,770 --> 01:08:29,870
whether goshen g generated the point i so

1046
01:08:29,910 --> 01:08:34,920
i'm going to estimate this according to my training data and i have when i

1047
01:08:34,920 --> 01:08:38,080
have used to make them going to modify the value of the parameters according to

1048
01:08:38,080 --> 01:08:43,810
the i don't have time to show you do mechanics

1049
01:08:44,500 --> 01:08:46,600
give you results but

1050
01:08:46,620 --> 01:08:49,420
it's very interesting on the other hand

1051
01:08:49,460 --> 01:08:55,550
i i really don't have enough time for this but in the end it's very

1052
01:08:55,560 --> 01:08:59,590
it is very simple and you can express each of the parameters of the mixture

1053
01:08:59,600 --> 01:09:01,880
of gaussians which include the mean

1054
01:09:01,880 --> 01:09:04,810
my talking about just the usual sort of knowledge right common sense knowledge that we

1055
01:09:04,810 --> 01:09:09,120
have is tweety bird can once the chair of the object in front pick up

1056
01:09:09,120 --> 01:09:12,810
the phone calls number what's the probability that my my wife of pick up and

1057
01:09:12,810 --> 01:09:17,670
so on supports can block a stack probably be so i want to be able

1058
01:09:17,670 --> 01:09:21,310
to represent these kinds of knowledge representations

1059
01:09:21,310 --> 01:09:22,650
but are not

1060
01:09:22,680 --> 01:09:26,480
classical sort of a representation of a major connection to what i've been talking about

1061
01:09:26,730 --> 01:09:30,640
prior to this is not immediate let me make sure that you are grasping why

1062
01:09:30,640 --> 01:09:33,230
i'm going in destruction

1063
01:09:33,240 --> 01:09:37,190
reinforcement learning is about agents interacting with the world is up to represent knowledge about

1064
01:09:37,190 --> 01:09:41,250
the world knowledge of all sorts of things and we want to think about very

1065
01:09:41,250 --> 01:09:44,290
flexible which sort of knowledge like these

1066
01:09:44,300 --> 01:09:48,440
and this should be clear and it is impounded that are really good way

1067
01:09:49,050 --> 01:09:53,750
two together and so we need to think about knowledge representation a fresh and again

1068
01:09:53,750 --> 01:09:54,930
and again so

1069
01:09:54,940 --> 01:09:57,190
the key idea

1070
01:09:57,240 --> 01:10:00,460
is the following is given the key idea behind what i'm doing is actually really

1071
01:10:00,460 --> 01:10:05,250
old idea the the the the novel part here is the these is

1072
01:10:05,260 --> 01:10:09,820
the computational aspects of the intuitive idea is very simple you know how to cut

1073
01:10:09,890 --> 01:10:12,380
my hand and i think up to you and a lot lot lots meaning to

1074
01:10:12,380 --> 01:10:17,290
you and one can build a knowledge base in system as i write symbol cup

1075
01:10:18,110 --> 01:10:18,980
talk about

1076
01:10:18,990 --> 01:10:21,650
you know the fact that you can put water in cups and you can you

1077
01:10:21,650 --> 01:10:26,260
can you can you know what panic up and so on so forth right way

1078
01:10:26,260 --> 01:10:27,500
to do it is just so

1079
01:10:27,520 --> 01:10:31,730
not have any sort of notion of couple directly but instead

1080
01:10:31,750 --> 01:10:36,050
they represent the knowledge about cup in terms of observable outcomes cup so for example

1081
01:10:36,380 --> 01:10:39,290
i might be able to predict the effects of the so object in a certain

1082
01:10:39,290 --> 01:10:43,440
way and here's something if i do this i hear something if i drop it

1083
01:10:43,700 --> 01:10:48,940
something for poor water or licey things that's all right so a cup is that

1084
01:10:48,940 --> 01:10:52,880
is a is union of a set of predictions i can make about the car

1085
01:10:52,900 --> 01:10:56,480
or or another way of saying that we are using is that a cup is

1086
01:10:56,480 --> 01:11:00,990
essentially a set of answers to questions i can ask about this

1087
01:11:01,040 --> 01:11:03,490
and so i think about representations

1088
01:11:03,500 --> 01:11:08,130
there are in fact in effect

1089
01:11:08,190 --> 01:11:13,900
knowledge representations that are answers to questions one can ask about objects in the world

1090
01:11:14,760 --> 01:11:22,940
how big very precisely a good mathematical in just a minute or two of us

1091
01:11:24,000 --> 01:11:25,500
so what

1092
01:11:27,230 --> 01:11:29,570
going to come

1093
01:11:29,600 --> 01:11:36,810
the all of that but yes i'm limited by the language they speak so so

1094
01:11:36,830 --> 01:11:43,020
the point is that i can ask questions entirely improper times get at time

1095
01:11:43,170 --> 01:11:48,990
because the precise in the future but i don't think you can

1096
01:11:49,000 --> 01:11:52,770
so what causes mean estimator

1097
01:11:52,900 --> 01:11:55,190
right is going to be

1098
01:11:55,230 --> 01:11:56,810
when you and

1099
01:11:56,820 --> 01:11:58,110
this time

1100
01:11:59,440 --> 01:12:04,380
image or so what i mean is so i mean

1101
01:12:04,400 --> 01:12:07,040
and this is exactly

1102
01:12:07,060 --> 01:12:09,170
so for example physical world

1103
01:12:09,210 --> 01:12:10,880
you all

1104
01:12:11,380 --> 01:12:13,750
the last where

1105
01:12:13,760 --> 01:12:18,500
right now i focused on the ball and what we see is is is is

1106
01:12:18,500 --> 01:12:21,360
where the square focused on this and

1107
01:12:21,420 --> 01:12:26,500
full or whatever that's where we want to that

1108
01:12:26,510 --> 01:12:33,630
people who live in this direction and keep the direction some probability may operations

1109
01:12:36,130 --> 01:12:38,520
so how long it

1110
01:12:38,540 --> 01:12:41,640
this is in practice would lot

1111
01:12:42,620 --> 01:12:49,180
the classical way modelling it so a physics based model after all of the environment

1112
01:12:49,240 --> 01:12:55,650
policies that i'm actually equations or with this discrete versions of that and so on

1113
01:12:55,670 --> 01:12:59,340
that's one way to model this environment and you can make any answer any question

1114
01:12:59,340 --> 01:13:03,660
about its environment once you've model like that is an alternative way of thinking about

1115
01:13:03,660 --> 01:13:04,990
the model

1116
01:13:05,000 --> 01:13:10,380
a model that instead of having this notion of ball and i is instead captures

1117
01:13:10,380 --> 01:13:15,140
knowledge in the form of answers to certain questions so here kinds of questions so

1118
01:13:15,140 --> 01:13:20,620
music which so this bottom diagram represents questions and answers to questions so these are

1119
01:13:20,620 --> 01:13:23,110
the questions for example you know

1120
01:13:23,120 --> 01:13:26,780
this square being black is an and is is is the answer the following question

1121
01:13:26,780 --> 01:13:30,580
if i move down one step my i

1122
01:13:30,630 --> 01:13:34,470
what's the probability i see the ball and it's a very high probability that you

1123
01:13:34,480 --> 01:13:38,080
see the ball because he don't have the ball in this case is moving down

1124
01:13:38,090 --> 01:13:42,140
if i move down two steps two time steps the ball will be here with

1125
01:13:42,140 --> 01:13:45,100
high probability so i see the ball with high probability

1126
01:13:45,110 --> 01:13:48,990
but on the move right to the ball moving down i wanted the ball

1127
01:13:49,000 --> 01:13:50,790
and so on so these are

1128
01:13:50,800 --> 01:13:56,340
the square here represent questions and the grayscale image in it represents the answers to

1129
01:13:56,340 --> 01:13:57,500
those questions

1130
01:13:57,500 --> 01:14:01,990
so i'm not sure yet this but giving you and anticipating the following thing is

1131
01:14:01,990 --> 01:14:03,540
that having a notion of ball

1132
01:14:03,670 --> 01:14:07,550
and i was going to have representations

1133
01:14:07,570 --> 01:14:08,620
in which the

1134
01:14:08,620 --> 01:14:13,000
representation of knowledge is in the form of answers to these sorts of questions

1135
01:14:13,020 --> 01:14:15,930
there people just a few more slides no free so now

1136
01:14:16,880 --> 01:14:21,290
this let's see the system in action right the ball down as it was moving

1137
01:14:21,290 --> 01:14:23,640
in the i moved right words right now

1138
01:14:24,100 --> 01:14:27,880
it's basically saying look i can't catch up with the ball

1139
01:14:27,920 --> 01:14:30,250
right because it was moving down

1140
01:14:30,250 --> 01:14:33,170
every time will keep moving down i can't catch up with the ball

1141
01:14:33,180 --> 01:14:37,150
in these in this much space and now you can see what it's saying is

1142
01:14:37,150 --> 01:14:39,600
that if i keep moving right twice

1143
01:14:39,620 --> 01:14:44,750
i'll be on the ball with high probability i down after that able to follow

1144
01:14:44,820 --> 01:14:47,480
ball sort of predictions it's making

1145
01:14:48,200 --> 01:14:53,000
let's let's make this let's use mathematics and the mathematics helps the let's go towards

1146
01:14:55,320 --> 01:15:01,550
come back to this so

1147
01:15:01,610 --> 01:15:03,750
i'm going to

1148
01:15:04,580 --> 01:15:06,720
think of an alternative representation

1149
01:15:06,730 --> 01:15:10,380
of the notion of these slides are not in here

1150
01:15:10,640 --> 01:15:14,090
so if you give on slide because of their and here they were not being

1151
01:15:14,750 --> 01:15:17,880
this is this is the slide in the first day so ignore these slides

1152
01:15:17,920 --> 01:15:19,650
i think

1153
01:15:19,670 --> 01:15:20,430
as you

1154
01:15:21,280 --> 01:15:25,250
well maybe it's in there may be some possible

1155
01:15:25,300 --> 01:15:26,110
i don't know

1156
01:15:26,120 --> 01:15:30,800
it's possible it and then yes i see it and they're okay good

1157
01:15:33,480 --> 01:15:40,210
so should stop rushing and go slowly

1158
01:15:40,330 --> 01:15:44,360
what i'm going to try and do today

1159
01:15:44,380 --> 01:15:48,520
in the rest of this talk is try to give you an alternative model an

1160
01:15:48,520 --> 01:15:51,030
alternative to mdps and pomdps

1161
01:15:54,180 --> 01:15:56,620
have notion of underlying

1162
01:15:56,700 --> 01:15:57,930
hidden state

1163
01:15:57,960 --> 01:15:59,380
which you never get to see

1164
01:15:59,400 --> 01:16:01,980
is it is the observation so if you think if you know a tremendous palm

1165
01:16:01,990 --> 01:16:04,180
diffuser HMM actions

1166
01:16:04,240 --> 01:16:07,010
four is just to the left palm deepest you i'm going to show you an

1167
01:16:07,010 --> 01:16:10,340
alternative way of thinking about the model in the world which doesn't use any hidden

1168
01:16:10,340 --> 01:16:13,030
variables and as powerful as part b

1169
01:16:13,040 --> 01:16:14,080
so that's my goal

1170
01:16:14,080 --> 01:16:16,580
in the plane

1171
01:16:16,640 --> 01:16:23,180
will be and i can vector and what will happen when i multiply by p

1172
01:16:23,300 --> 01:16:29,140
what i project vector x i i i called b here because this is our

1173
01:16:29,140 --> 01:16:33,650
familiar picture but now i'm going to say that b was no good for for

1174
01:16:33,660 --> 01:16:35,200
the for our purposes

1175
01:16:35,240 --> 01:16:36,550
i'm interested in

1176
01:16:36,560 --> 01:16:40,590
in the vector x that's actually in the plane

1177
01:16:40,620 --> 01:16:44,500
and i projected and what do i get back

1178
01:16:44,570 --> 01:16:46,020
x of course

1179
01:16:46,070 --> 01:16:47,760
doesn't move

1180
01:16:48,640 --> 01:16:50,570
every x in the plane

1181
01:16:52,440 --> 01:16:54,310
unchanged by p

1182
01:16:54,320 --> 01:16:56,260
and what's telling me

1183
01:16:56,260 --> 01:16:59,770
that's telling me that x is and i can vector and it's also telling me

1184
01:16:59,770 --> 01:17:02,130
what's the igon value

1185
01:17:02,140 --> 01:17:04,620
which is just compare it with

1186
01:17:04,650 --> 01:17:06,980
the idea of multipliers

1187
01:17:11,670 --> 01:17:13,760
so we actually all

1188
01:17:15,420 --> 01:17:17,030
now i or the other

1189
01:17:19,270 --> 01:17:24,150
i expect you should be because i would like to get free time in three

1190
01:17:25,370 --> 01:17:30,150
i would like to call for three hundred ninety two

1191
01:17:30,210 --> 01:17:32,720
playing one

1192
01:17:33,620 --> 01:17:36,410
so can be not

1193
01:17:36,660 --> 01:17:40,190
good what's the right i mean vector

1194
01:17:40,210 --> 01:17:43,590
that's not the way

1195
01:17:43,760 --> 01:17:45,880
good morning everyone

1196
01:17:45,920 --> 01:17:48,010
per second

1197
01:17:48,020 --> 01:17:52,300
yes because one

1198
01:17:52,330 --> 01:17:53,020
so that the

1199
01:17:54,490 --> 01:17:55,690
another here

1200
01:17:55,880 --> 01:17:58,860
right there but here

1201
01:18:14,180 --> 01:18:16,870
one of the project i

1202
01:18:20,720 --> 01:18:23,510
so there is no space

1203
01:18:23,510 --> 01:18:27,040
px not for those

1204
01:18:27,060 --> 01:18:29,050
or zero

1205
01:18:29,080 --> 01:18:31,110
and the zero

1206
01:18:31,240 --> 01:18:33,600
so what

1207
01:18:33,620 --> 01:18:39,780
my question is one of the four main

1208
01:18:42,750 --> 01:18:47,550
i we we know projection matrices

1209
01:18:47,560 --> 01:18:50,090
we can write down

1210
01:18:50,290 --> 01:18:54,380
that a fraction of the universe transport

1211
01:18:55,630 --> 01:18:58,750
well from from the page

1212
01:18:58,760 --> 01:19:01,520
see what are the idea

1213
01:19:02,440 --> 01:19:06,920
are these limiting the second example

1214
01:19:08,150 --> 01:19:12,940
permutation what about all

1215
01:19:12,970 --> 01:19:14,890
zero one

1216
01:19:16,910 --> 01:19:23,870
can you tell me to

1217
01:19:23,880 --> 01:19:27,640
so you will just soon enough so i would like to do

1218
01:19:27,870 --> 01:19:30,340
these couple of examples

1219
01:19:31,610 --> 01:19:34,210
see the picture before we

1220
01:19:34,250 --> 01:19:37,680
before we all

1221
01:19:37,710 --> 01:19:38,740
going to

1222
01:19:40,970 --> 01:19:45,760
system where that need to be expected because

1223
01:19:45,760 --> 01:19:47,490
and why

1224
01:19:47,510 --> 01:19:48,710
so what

1225
01:19:50,560 --> 01:19:54,680
the same direction in his body like this

1226
01:19:55,640 --> 01:19:58,020
i mean

1227
01:19:58,040 --> 01:20:03,870
x one x two rights which is

1228
01:20:03,880 --> 01:20:07,310
for the two components of s

1229
01:20:08,370 --> 01:20:09,850
the vector

1230
01:20:09,860 --> 01:20:12,210
with its

1231
01:20:12,230 --> 01:20:15,260
x two x one with permuted

1232
01:20:15,270 --> 01:20:16,880
turn out to be

1233
01:20:17,000 --> 01:20:21,490
multiple of o x one x two restart

1234
01:20:21,500 --> 01:20:24,680
can you tell me and i are here for

1235
01:20:24,710 --> 01:20:26,650
people one

1236
01:20:27,630 --> 01:20:31,660
only one factor that i want

1237
01:20:31,680 --> 01:20:34,710
so what you would like know why

1238
01:20:34,720 --> 01:20:39,680
so that i can find a permutation

1239
01:20:39,690 --> 01:20:42,010
that would be

1240
01:20:42,030 --> 01:20:43,550
one one

1241
01:20:44,560 --> 01:20:45,750
OK thanks

1242
01:20:45,760 --> 01:20:50,730
that be alive because the right

1243
01:20:50,750 --> 01:20:53,280
i one

1244
01:20:56,680 --> 01:20:59,840
one of brain

1245
01:20:59,860 --> 01:21:03,530
that's what i but there are two by two matrix

1246
01:21:03,550 --> 01:21:07,110
i think i'm going to

1247
01:21:13,640 --> 01:21:16,160
what about what where

1248
01:21:16,180 --> 01:21:18,940
maybe we just like

1249
01:21:22,110 --> 01:21:32,880
there actually this one thing is going to be about

1250
01:21:32,890 --> 01:21:36,780
my my

1251
01:21:36,790 --> 01:21:38,880
it's not like

1252
01:21:38,900 --> 01:21:40,260
i mean

1253
01:21:40,380 --> 01:21:41,640
and i

1254
01:21:41,660 --> 01:21:43,390
it's going to come

1255
01:21:49,060 --> 01:21:51,050
so i want to

1256
01:21:52,390 --> 01:21:56,060
which reversed

1257
01:21:57,580 --> 01:22:01,300
i want my real

1258
01:22:01,310 --> 01:22:04,550
so what

1259
01:22:06,550 --> 01:22:10,730
no one

1260
01:22:10,740 --> 01:22:13,380
that's what i like a

1261
01:22:13,380 --> 01:22:19,860
OK want one

1262
01:22:24,690 --> 01:22:30,420
let me what

1263
01:22:32,640 --> 01:22:38,240
can i

1264
01:22:38,260 --> 01:22:39,160
like john

1265
01:22:49,780 --> 01:22:52,760
well i

1266
01:22:52,760 --> 01:22:53,720
the a

1267
01:22:53,730 --> 01:22:58,110
i repeat you the conditional independence that is not obvious from the graph this in

1268
01:22:58,120 --> 01:23:02,170
the probability can you change the graph so that it will be obvious from prior

1269
01:23:02,170 --> 01:23:06,290
right it's a good question and in general you can't in other words

1270
01:23:06,350 --> 01:23:11,200
the graphs that i'm described not sufficiently general to be able to represent arbitrary sets

1271
01:23:11,200 --> 01:23:14,200
of of conditional independence properties you say the question

1272
01:23:14,210 --> 01:23:18,750
right list the conditional independence property for and try to construct the graph that describes

1273
01:23:18,750 --> 01:23:21,770
those i think that's really your question and in general you can't go in that

1274
01:23:21,770 --> 01:23:25,190
direction i'm going to show you some examples of

1275
01:23:25,200 --> 01:23:29,910
for example directed undirected graphs there an equivalent they can't be mapped into each other

1276
01:23:29,910 --> 01:23:34,440
and there are yet other distributions sets conditional independence properties which can be expressed as

1277
01:23:34,440 --> 01:23:39,200
either directed or undirected they can be expressed as a chain graphs so the answer

1278
01:23:39,200 --> 01:23:41,030
is no in general you can't

1279
01:23:41,060 --> 01:23:44,750
capture although conditional independence properties in in the graph

1280
01:23:45,620 --> 01:23:49,700
any other questions

1281
01:23:49,700 --> 01:23:53,080
OK that was example number one that's good example number two

1282
01:23:53,100 --> 01:23:57,210
so this is the tail to tail case again we got three variables and the

1283
01:23:58,170 --> 01:23:59,530
through node c

1284
01:23:59,560 --> 01:24:03,350
and the half is called tail to tail because the tails of the arrows connect

1285
01:24:03,350 --> 01:24:04,970
to node c

1286
01:24:05,010 --> 01:24:07,010
let's right the joint distribution

1287
01:24:07,030 --> 01:24:08,730
well it's PMC given

1288
01:24:09,730 --> 01:24:13,510
he is a given its parents which is c so that that fact

1289
01:24:13,530 --> 01:24:17,420
and then you be given its parents you see so that that fact so that's

1290
01:24:17,430 --> 01:24:18,880
the joint distribution

1291
01:24:18,890 --> 01:24:21,750
and again is the missing link is no link between a and b

1292
01:24:21,800 --> 01:24:28,230
so this is not a general distribution it's just it's sub family of distributions

1293
01:24:32,510 --> 01:24:35,000
what happens now when we condition on nodes c

1294
01:24:38,040 --> 01:24:39,700
all we have to do

1295
01:24:39,700 --> 01:24:44,150
it to divide the joint distribution by pfc

1296
01:24:44,170 --> 01:24:47,480
so get the thing conditional on c and divided by p c

1297
01:24:47,500 --> 01:24:49,690
another piece is just cancel

1298
01:24:49,700 --> 01:24:52,660
so it's very much max to do you can see that at some point the

1299
01:24:52,660 --> 01:24:57,300
screen you can see that it does indeed factorized into the product of conditionals so

1300
01:24:57,300 --> 01:25:02,000
in other words the this family of distributions y conditional on c

1301
01:25:02,020 --> 01:25:05,620
i get a vacancy times p the given c so a is intended to be

1302
01:25:05,620 --> 01:25:08,510
given c

1303
01:25:10,170 --> 01:25:15,580
so one of the title should be c if c is not observed

1304
01:25:15,590 --> 01:25:20,270
again i have piece of a and b is not equal to

1305
01:25:22,710 --> 01:25:24,050
and again you can see

1306
01:25:27,440 --> 01:25:28,840
if you

1307
01:25:28,940 --> 01:25:32,660
have a common being some of the sea when you some of the sea

1308
01:25:32,670 --> 01:25:39,870
these two factors get muddled up general function of a b not to products

1309
01:25:40,660 --> 01:25:41,860
so again we have

1310
01:25:41,910 --> 01:25:43,550
again we can

1311
01:25:43,580 --> 01:25:45,390
express that graphically

1312
01:25:45,410 --> 01:25:47,510
by saying that

1313
01:25:47,600 --> 01:25:53,430
a and b independent from each other because of half the next eight

1314
01:25:53,450 --> 01:25:58,000
but when we observe the it blocks the path causing these

1315
01:25:58,040 --> 01:26:00,410
nodes to become independent

1316
01:26:00,440 --> 01:26:05,950
so again it's just like the the undirected case simple graph separation

1317
01:26:06,540 --> 01:26:11,340
now the sort of thing this is the case which distinguishes directed graph from undirected

1318
01:26:11,340 --> 01:26:12,960
graphs and is the head to head

1319
01:26:12,980 --> 01:26:14,150
OK case

1320
01:26:15,360 --> 01:26:17,660
again got three notable missing link

1321
01:26:17,670 --> 01:26:21,480
but no c is now head to head with respect to this path is that

1322
01:26:21,480 --> 01:26:24,590
it has to be harassed touch the no

1323
01:26:24,610 --> 01:26:29,610
the joint distribution is p of a given nothing he would be given nothing you

1324
01:26:29,610 --> 01:26:35,120
see given its parents a and b so that's the the joint distribution

1325
01:26:35,140 --> 01:26:38,280
now suppose c is unobserved

1326
01:26:38,310 --> 01:26:42,370
p of a common b

1327
01:26:42,430 --> 01:26:43,330
is just

1328
01:26:43,430 --> 01:26:46,950
some of the city of a b and c

1329
01:26:48,260 --> 01:26:50,390
by some this c

1330
01:26:50,400 --> 01:26:53,280
in the first two factors platypus some

1331
01:26:53,310 --> 01:26:58,850
and the idea some of the factor because that the conditional distribution is normalized sums

1332
01:26:58,850 --> 01:27:01,930
to one

1333
01:27:01,930 --> 01:27:05,310
so it follows that p of a common physical to p of a times he

1334
01:27:06,040 --> 01:27:08,560
it was the other way round

1335
01:27:08,580 --> 01:27:09,810
a and b

1336
01:27:09,830 --> 01:27:13,170
are independent of each other when i'm not observed

1337
01:27:14,480 --> 01:27:18,340
so what happens when we observe c

1338
01:27:18,440 --> 01:27:20,940
well we observe c

1339
01:27:22,240 --> 01:27:26,410
that property is not so when we condition on c

1340
01:27:26,410 --> 01:27:28,250
so if you go back to

1341
01:27:28,660 --> 01:27:31,540
to this case when we condition on the

1342
01:27:31,560 --> 01:27:32,930
we divide by

1343
01:27:32,940 --> 01:27:33,990
here see

1344
01:27:34,010 --> 01:27:38,780
but we still have this factor which is the general function of a and b

1345
01:27:38,800 --> 01:27:46,620
it doesn't factorize into product in the function of a the function of b

1346
01:27:47,760 --> 01:27:49,940
a is not independent the when we observe

1347
01:27:50,730 --> 01:27:56,840
in other words observing see unlocks the path so exactly the opposite behavior observed no

1348
01:27:57,010 --> 01:28:03,550
blocks the path causes a and b to become dependent

1349
01:28:03,560 --> 01:28:07,750
something else which i will improve here mathematically but all motivator in the minutes i

1350
01:28:07,750 --> 01:28:11,040
think it should become intuitively reasonable

1351
01:28:11,190 --> 01:28:14,790
supposing i had a graph which looks like this

1352
01:28:16,560 --> 01:28:18,430
two know here a and b

1353
01:28:18,440 --> 01:28:19,440
and c

1354
01:28:19,450 --> 01:28:21,240
and i have the a descendant

1355
01:28:21,260 --> 01:28:26,350
called so descendants just has the obvious meaning that i can follow

1356
01:28:26,490 --> 01:28:29,840
is apart from c to d going in the direction of the arrows is called

1357
01:28:29,840 --> 01:28:31,220
the descendant

1358
01:28:32,580 --> 01:28:33,560
so again

1359
01:28:33,670 --> 01:28:36,950
a a is independent of b for this graph

1360
01:28:36,980 --> 01:28:39,970
now suppose you observe the descendant

1361
01:28:39,980 --> 01:28:42,560
well the descendants

1362
01:28:42,580 --> 01:28:47,840
is observed effectively what it's doing is propagating some evidence to back up to node c

1363
01:28:47,850 --> 01:28:51,200
and changing its distribution and that's causing

1364
01:28:51,210 --> 01:28:54,440
that's it for this particular observing c

1365
01:28:54,440 --> 01:28:55,790
it causes

1366
01:28:55,860 --> 01:28:58,200
a and b to become dependent

1367
01:28:58,300 --> 01:29:02,750
and i'll try and motivate that with an example rather than

1368
01:29:02,770 --> 01:29:06,090
worrying about mathematics but you could complain about that on a piece of paper if

1369
01:29:06,090 --> 01:29:08,440
you like by

1370
01:29:08,460 --> 01:29:12,480
so here's my example to try and explain what's going on this is sometimes called

1371
01:29:12,480 --> 01:29:16,080
this phenomenon sometimes called explaining away

1372
01:29:16,110 --> 01:29:22,870
so this is all to do with head-to-head nodes in directed graphs

1373
01:29:22,890 --> 01:29:27,940
so let's have a simple example let's imagine that i i take a photograph of

1374
01:29:29,350 --> 01:29:30,380
an object

1375
01:29:30,390 --> 01:29:32,410
i'm gonna particular pixel

1376
01:29:32,430 --> 01:29:34,700
i mean look at the color of that pixel

1377
01:29:34,710 --> 01:29:38,430
let's say that pixel happens to be a blue colour

1378
01:29:38,440 --> 01:29:40,710
well i can model

1379
01:29:40,740 --> 01:29:46,330
the process of observing that blue pixels using a probabilistic model and i can represent

1380
01:29:46,330 --> 01:29:48,210
probabilistic model graphically

1381
01:29:48,230 --> 01:29:52,810
simple example of what we do in these graphical models in machine learning

1382
01:29:52,870 --> 01:29:55,870
we know that the colour of a pixel is determined by two things it was

1383
01:29:55,870 --> 01:29:59,770
determined by the colour of the light which illuminated it and it was determined by

1384
01:29:59,770 --> 01:30:03,890
the reflectance properties of the physical material that the surface was made of

1385
01:30:03,940 --> 01:30:05,200
so for example

1386
01:30:07,210 --> 01:30:11,350
they could look blue because it's made of the material and illuminated with white light

1387
01:30:11,390 --> 01:30:14,730
reflects the blue components absorbs about going

1388
01:30:14,790 --> 01:30:18,890
it could be blue because it's a white piece of white surfaces illuminated with blue

1389
01:30:20,870 --> 01:30:24,330
but it can't be a piece of red surface illuminated with red light because that

1390
01:30:24,330 --> 01:30:25,480
would great

1391
01:30:25,730 --> 01:30:30,580
so when i observe the pixel i get some information about the colour of the

1392
01:30:30,580 --> 01:30:32,810
surface and about the colour of the light

1393
01:30:32,830 --> 01:30:35,580
but neither is determined completely

1394
01:30:35,660 --> 01:30:37,710
so i can represent this

1395
01:30:37,710 --> 01:30:42,430
process by little graphical model in this graphical model reflects the causality

1396
01:30:42,460 --> 01:30:44,430
of the process by which the

1397
01:30:44,430 --> 01:30:46,500
pixel got its color

1398
01:30:46,500 --> 01:30:50,210
so what i'm saying is that i'm going to choose the colour of the lighting

1399
01:30:50,210 --> 01:30:53,960
so there's no represents the color of the light source i choose that from some

1400
01:30:53,960 --> 01:30:56,390
distribution already dies not pick

1401
01:30:56,410 --> 01:30:58,180
a value for the colour

1402
01:30:58,210 --> 01:31:00,270
then completely independently of that

1403
01:31:00,390 --> 01:31:02,770
i would choose the colour of the surface

1404
01:31:02,770 --> 01:31:08,200
of like the real solution to the exploration exploitation problem the various kinds of approaches

1405
01:31:08,200 --> 01:31:09,060
to this

1406
01:31:09,110 --> 01:31:14,670
one of the relatively recent paper where they talk about the beetle algorithm is considered

1407
01:31:14,670 --> 01:31:19,470
the state-of-the-art they they use the latest ideas from solving continuous partially observable markov decision

1408
01:31:19,470 --> 01:31:25,210
processes to to reason about how should i after egionact so that its

1409
01:31:25,260 --> 01:31:28,760
improving its understanding of the environment as it goes

1410
01:31:28,770 --> 01:31:32,590
i can exploit various sort of ideas and parameter tying these two states actually have

1411
01:31:32,590 --> 01:31:37,170
the same kind of distribution so we can learn about that together

1412
01:31:37,190 --> 01:31:42,430
they demonstrated in various kinds of problems it was getting what appears to be near

1413
01:31:42,430 --> 01:31:47,580
optimal exploration of five state leagues this by state domain five here is slightly larger

1414
01:31:47,580 --> 01:31:51,120
domain from the comes from more realistic setting that he didn't do it nearly as

1415
01:31:51,940 --> 01:31:55,560
the biggest so basically it's not really

1416
01:31:55,610 --> 01:32:00,440
the planner the the solution here is actually outputting an entire learning algorithm right fit

1417
01:32:00,440 --> 01:32:04,820
in a bayesian setting there's no learning right there's just you know observed data and

1418
01:32:04,820 --> 01:32:09,420
so the the dispute has to kind of truck long and then spits out an

1419
01:32:09,420 --> 01:32:14,380
entire strategy for dealing with the environment of a certain size so that the learning

1420
01:32:14,380 --> 01:32:18,300
algorithm now encoded inside that that that plan

1421
01:32:18,320 --> 01:32:20,630
so you can imagine that's going to be really hard to do in a very

1422
01:32:20,630 --> 01:32:21,640
general setting

1423
01:32:21,660 --> 01:32:26,180
it doesn't have a lot of the ability to computational and so i don't know

1424
01:32:26,180 --> 01:32:27,550
if it doesn't

1425
01:32:27,630 --> 01:32:29,800
doesn't scale very well

1426
01:32:29,840 --> 01:32:32,120
now you can say we get away from this a little bit and talk about

1427
01:32:32,120 --> 01:32:36,150
instead of bayes optimal really trying to maximize it what about new ways of optimal

1428
01:32:36,190 --> 01:32:39,590
this is kind of like the PAC MDP idea that i talked about before but

1429
01:32:39,590 --> 01:32:42,930
we're going to find mistakes a little bit differently we're going to say an algorithm

1430
01:32:42,930 --> 01:32:45,130
is near bayes optimal

1431
01:32:45,170 --> 01:32:49,320
if the number of missus oh sorry it makes a mistake if an action is

1432
01:32:49,320 --> 01:32:53,640
taken has value that's very far from what the bayes optimal

1433
01:32:53,660 --> 01:32:55,290
solution would be

1434
01:32:55,310 --> 01:32:57,860
right so it doesn't to solve it out and it doesn't have to get right

1435
01:32:57,860 --> 01:33:01,370
on every trial but it has to get it right on nearly all the trials

1436
01:33:01,390 --> 01:33:05,720
and what call during show this year is that of

1437
01:33:05,730 --> 01:33:10,170
at least in the case where all the states are separate little bayesian learners

1438
01:33:10,200 --> 01:33:14,810
all you have to do is keep at this bayesian exploration bonus you one over

1439
01:33:14,810 --> 01:33:18,900
and for each action has been taken in times this of course is going to

1440
01:33:18,900 --> 01:33:22,980
zero is you take an action many many times this this this bonus goes to

1441
01:33:22,980 --> 01:33:27,390
zero the for actions that have been tried this bonuses is substantial and causes the

1442
01:33:27,610 --> 01:33:31,220
the algorithm to choose those actions and learn about them

1443
01:33:31,250 --> 01:33:35,450
so what they showed is that this this bayesian exploration bonus idea it's very simple

1444
01:33:35,450 --> 01:33:37,140
it gets too near bayesian

1445
01:33:37,150 --> 01:33:38,200
but what's

1446
01:33:38,220 --> 01:33:41,860
but as kind of rock my world it probably will rock your world nearly as

1447
01:33:41,860 --> 01:33:44,510
much as my but nonetheless

1448
01:33:44,530 --> 01:33:49,790
this is the shattering make this idea this being near bayes optimal is not the

1449
01:33:49,790 --> 01:33:52,140
same as being PAC MDP

1450
01:33:52,190 --> 01:33:56,030
right so it's apparently but they seem so similar in so many ways

1451
01:33:56,030 --> 01:34:01,610
but there's examples and questioning showed one in the home shared his thesis where

1452
01:34:01,630 --> 01:34:05,700
this is really really little simple MDP with two different reward values and you have

1453
01:34:05,700 --> 01:34:09,880
a prior that says maybe there are roughly equally likely

1454
01:34:09,890 --> 01:34:13,940
when you get but there's two different models here action one gives you a half

1455
01:34:13,940 --> 01:34:15,710
with certainty action two

1456
01:34:15,730 --> 01:34:17,410
in one model gives zero

1457
01:34:17,420 --> 01:34:20,830
any other model gives you just a little bit more than half

1458
01:34:20,830 --> 01:34:24,400
but no more than half the to be epsilon optimal you have to try and

1459
01:34:24,440 --> 01:34:28,790
in fact you have to try infinitely often infinite but bayes these optimal what do

1460
01:34:28,790 --> 01:34:32,810
it these is optimal basically says you know i could do that by the time

1461
01:34:32,810 --> 01:34:34,660
i figure out that it's any good

1462
01:34:34,680 --> 01:34:40,240
you know i'd missed opportunities for reward and so it actually sits there taking

1463
01:34:40,260 --> 01:34:44,590
why worse than epsilon optimal actions forever

1464
01:34:44,600 --> 01:34:47,460
which really bothers me and then i decided well maybe i don't really know what

1465
01:34:47,460 --> 01:34:49,040
reinforcement learning trying to be

1466
01:34:49,060 --> 01:34:51,700
and then i was reading over my daughter shoulder when she was reading a cartoon

1467
01:34:51,700 --> 01:34:55,390
book and i realize this is well known in the literature

1468
01:34:55,420 --> 01:35:00,000
so it's this is the calvin hobbes good cartoon actually just calvinism this one so

1469
01:35:00,240 --> 01:35:04,920
so just to set up three calvin has has just discovered time travel which by

1470
01:35:04,920 --> 01:35:08,360
time travel here has the cardboard box your time machine on the side of it

1471
01:35:08,660 --> 01:35:11,250
instead of doing his homework and what he did to use the time machine to

1472
01:35:11,860 --> 01:35:16,990
from six o'clock necessary six thirty his at six thirty creating a time machine he

1473
01:35:16,990 --> 01:35:19,130
goes to o eight thirty which is bedtime

1474
01:35:19,140 --> 01:35:21,980
by which of course by then he must have finished the homework so you get

1475
01:35:21,980 --> 01:35:26,690
but there is a similar to classification is where the prediction space has structure for

1476
01:35:26,690 --> 01:35:33,860
instance labeling document this document pixel data mining and also with machine learning and or

1477
01:35:33,860 --> 01:35:38,570
charlotte clustering and or some of the EMI and or some of those years and

1478
01:35:38,790 --> 01:35:43,210
there is some connection between them they are not independently

1479
01:35:43,210 --> 01:35:49,380
the difference between countries your decision on what the classification is whether the connections between

1480
01:35:49,380 --> 01:35:51,860
the labels are part of new data

1481
01:35:51,880 --> 01:35:54,320
or part of your task

1482
01:35:54,380 --> 01:35:57,730
which makes it even more

1483
01:35:57,750 --> 01:36:03,230
in ranking you will be on the yes and no i have some linear ordering

1484
01:36:03,300 --> 01:36:07,150
an interest in europe and america page of course if you have an administration you

1485
01:36:07,150 --> 01:36:09,610
can use it to rank

1486
01:36:09,670 --> 01:36:13,590
and if you can draw and you can decide whether not

1487
01:36:13,630 --> 01:36:18,320
number one should we do with results has still not

1488
01:36:18,400 --> 01:36:21,820
what did she say they usually you don't know this

1489
01:36:21,860 --> 01:36:30,030
show you india after non with with a connected i the is there a website

1490
01:36:30,030 --> 01:36:31,270
that you know that

1491
01:36:31,290 --> 01:36:37,130
were many much much information related mining is for post and another thing they do

1492
01:36:37,130 --> 01:36:41,520
is more similar to all sorts of things how much money are not only minor

1493
01:36:42,230 --> 01:36:46,480
one of the questions i posed really only once a year later you is what

1494
01:36:47,440 --> 01:36:48,610
by using

1495
01:36:48,630 --> 01:36:52,690
and if you if you have if you know anything about statistics and data analysis

1496
01:36:52,840 --> 01:36:55,270
statistics you wouldn't be suppression that our

1497
01:36:55,940 --> 01:36:57,230
high up there

1498
01:36:57,250 --> 01:37:01,150
and this one is even more useful tool they would mention

1499
01:37:01,320 --> 01:37:03,710
and know what find had

1500
01:37:10,610 --> 01:37:11,590
do it

1501
01:37:11,750 --> 01:37:17,650
would have data or of course tag dominance whatever the openoffice

1502
01:37:17,670 --> 01:37:18,710
and outlook

1503
01:37:20,590 --> 01:37:26,250
i dont start analyzing data without having seen it yourself

1504
01:37:26,300 --> 01:37:30,880
have a look at it be aware only looking at that time tiny tiny tiny

1505
01:37:30,880 --> 01:37:35,020
portion of it but still have a look at it

1506
01:37:35,070 --> 01:37:36,440
at least not less

1507
01:37:37,630 --> 01:37:39,380
let it go away

1508
01:37:39,380 --> 01:37:44,170
or open it in excel or this have a look at it

1509
01:37:45,770 --> 01:37:47,270
well actually you

1510
01:37:47,270 --> 01:37:49,020
we will see many many things that we

1511
01:37:49,040 --> 01:37:51,020
that is that we try to come up with

1512
01:37:51,070 --> 01:37:54,860
things that are similar to each other

1513
01:37:54,880 --> 01:37:56,540
then you interested in

1514
01:37:56,730 --> 01:38:01,670
another point is

1515
01:38:01,710 --> 01:38:05,070
the we have and one for

1516
01:38:06,210 --> 01:38:07,440
in sense if

1517
01:38:07,560 --> 01:38:10,320
could actually that structure

1518
01:38:10,400 --> 01:38:11,980
so we don't want any

1519
01:38:12,000 --> 01:38:17,060
stefanie observations will stand up and say this information to me because they are too

1520
01:38:17,060 --> 01:38:19,320
many different places all of them

1521
01:38:20,570 --> 01:38:22,320
let's find

1522
01:38:23,710 --> 01:38:26,820
this time

1523
01:38:28,520 --> 01:38:29,750
one of them somehow

1524
01:38:29,770 --> 01:38:35,570
it's in that case the similarity for instance marketing you identify common characteristics of parts

1525
01:38:35,570 --> 01:38:37,000
of the population

1526
01:38:37,020 --> 01:38:41,770
get smart section definitions of what's going on

1527
01:38:41,820 --> 01:38:47,860
produced by moving clusters single point many times boss once this

1528
01:38:48,710 --> 01:38:50,020
and economics

1529
01:38:50,040 --> 01:38:52,130
many times divorce

1530
01:38:52,150 --> 01:38:57,090
once magic that looks like this

1531
01:38:57,110 --> 01:38:58,210
you have give him

1532
01:38:58,250 --> 01:39:02,460
there something like this not magic

1533
01:39:02,460 --> 01:39:04,920
well maybe you can i can

1534
01:39:09,320 --> 01:39:17,090
o devices because something like this about magic to that that it him everything about

1535
01:39:17,090 --> 01:39:19,960
it and it's not that easy

1536
01:39:20,000 --> 01:39:25,750
so what we see here here we have seen became is how we

1537
01:39:25,770 --> 01:39:31,070
i'm not a we will see later on but there are many more here popular

1538
01:39:31,070 --> 01:39:35,540
many spectral clustering was mentioned two

1539
01:39:37,520 --> 01:39:43,000
when there so many other is different ways of doing the same

1540
01:39:43,000 --> 01:39:47,250
no different ways of doing similar things with still

1541
01:39:47,290 --> 01:39:51,270
what is the best

1542
01:39:51,940 --> 01:39:53,790
so actually

1543
01:39:53,800 --> 01:39:55,710
they serve shown before

1544
01:39:56,150 --> 01:39:59,540
such a variety for the time being

1545
01:39:59,540 --> 01:40:03,080
and at what point those interest strong and

1546
01:40:03,800 --> 01:40:07,120
restrict freedom

1547
01:40:07,180 --> 01:40:09,660
then going back to justice harlan

1548
01:40:09,690 --> 01:40:14,880
recall that he said that the intervention had to be safe

1549
01:40:14,910 --> 01:40:18,860
and so i come back to work in another balance

1550
01:40:18,910 --> 01:40:21,520
what disease risk

1551
01:40:21,520 --> 01:40:23,630
threat of half

1552
01:40:23,740 --> 01:40:29,550
balanced by what assurance of vaccine safety and efficacy

1553
01:40:31,080 --> 01:40:34,550
a universal recommendation for vaccines

1554
01:40:34,550 --> 01:40:37,200
or even stronger mandate

1555
01:40:37,240 --> 01:40:38,980
are required

1556
01:40:39,030 --> 01:40:44,760
now this is a good point at which for me to point out that safety

1557
01:40:44,760 --> 01:40:46,060
is relative

1558
01:40:46,070 --> 01:40:48,820
it is not absolute

1559
01:40:48,860 --> 01:40:51,030
and that in medicine we

1560
01:40:51,040 --> 01:40:53,730
can reject but not prove

1561
01:40:53,750 --> 01:40:57,730
the null hypothesis another words

1562
01:40:57,750 --> 01:41:03,250
you begin a study by saying there is

1563
01:41:03,320 --> 01:41:05,940
no association

1564
01:41:07,110 --> 01:41:10,550
a vaccine and an adverse event

1565
01:41:10,620 --> 01:41:15,220
you then do a study and if you find evidence of an association

1566
01:41:15,230 --> 01:41:18,160
you can reject the null hypothesis

1567
01:41:18,180 --> 01:41:20,400
because you found evidence

1568
01:41:20,430 --> 01:41:25,190
what you can do is prove the the null hypothesis is a hypothesis

1569
01:41:25,290 --> 01:41:26,850
you can prove

1570
01:41:26,880 --> 01:41:28,950
there is no association

1571
01:41:29,020 --> 01:41:32,150
between an adverse events and vaccine

1572
01:41:32,180 --> 01:41:33,450
so you can

1573
01:41:33,500 --> 01:41:38,650
prove absolute safety safety is again irrelevant issues

1574
01:41:38,680 --> 01:41:44,430
and i would ask you to think for a second about the old

1575
01:41:44,440 --> 01:41:50,490
rotavirus vaccine is no longer on the market was called roller shield and it was

1576
01:41:50,490 --> 01:41:52,530
withdrawn from the market

1577
01:41:52,540 --> 01:41:54,550
about nine years ago

1578
01:41:54,660 --> 01:42:00,030
and with the vaccine we had a million individuals vaccinated

1579
01:42:00,050 --> 01:42:02,470
about one hundred got sick

1580
01:42:02,510 --> 01:42:04,250
he died from the disease

1581
01:42:04,270 --> 01:42:07,200
or from the side effects of the vaccine

1582
01:42:07,290 --> 01:42:13,810
and one died in the side of this vaccine we're intestinal obstruction called deception

1583
01:42:13,830 --> 01:42:18,220
without the vaccine

1584
01:42:18,300 --> 01:42:21,380
about sixteen thousand will get sick

1585
01:42:21,400 --> 01:42:23,500
and about ten will die

1586
01:42:23,540 --> 01:42:27,060
from the effects of the disease

1587
01:42:27,210 --> 01:42:32,050
and the point and this vaccine was then withdrawn from the market

1588
01:42:32,070 --> 01:42:35,620
as unacceptable in this country

1589
01:42:35,630 --> 01:42:38,520
and the point is that i'm trying to make here is that if you are

1590
01:42:39,730 --> 01:42:45,300
for the deaths related to the vaccine you also culpable for deaths

1591
01:42:45,320 --> 01:42:50,350
that have occurred when you withhold

1592
01:42:50,400 --> 01:42:55,780
so you are on the importance of the land

1593
01:42:55,820 --> 01:42:57,440
so we come back to

1594
01:42:57,440 --> 01:43:02,680
the fundamental question which is what should be the balance between the state's duty

1595
01:43:02,730 --> 01:43:05,090
to protect the public health

1596
01:43:05,110 --> 01:43:06,880
and the individuals right

1597
01:43:06,900 --> 01:43:08,280
for free choice

1598
01:43:08,290 --> 01:43:11,290
now let's look at how that plays out

1599
01:43:11,300 --> 01:43:17,220
the way we have restricted freedom in this country is through school immunisation laws and

1600
01:43:17,220 --> 01:43:22,210
the modern origin of school immunisation laws just up the road in los angeles

1601
01:43:22,280 --> 01:43:24,950
when there was a major league out

1602
01:43:25,000 --> 01:43:27,080
right in the nineteen seventies

1603
01:43:27,110 --> 01:43:34,970
there were deaths associated with the numerous hospitalizations and they're very courageous health officer

1604
01:43:35,860 --> 01:43:38,820
i decided to exclude children from school

1605
01:43:38,840 --> 01:43:42,270
if they do not have a proof of community

1606
01:43:42,340 --> 01:43:46,860
some fifty thousand kids were excluded from school

1607
01:43:46,950 --> 01:43:50,630
but most were back in school within a few days

1608
01:43:50,890 --> 01:43:56,290
that was kind of of the beginning of the school entry immunization loss

1609
01:43:56,300 --> 01:43:59,000
quickly multiple states

1610
01:43:59,010 --> 01:44:04,010
enacted such laws and some of them and forced them but not all

1611
01:44:04,010 --> 01:44:09,470
common traditional architecture of the web to actually do this to to enable this lincoln's

1612
01:44:09,490 --> 01:44:13,830
publishing of structured data and because it is those allows you to to discover thing

1613
01:44:14,080 --> 01:44:17,410
unexpected things in the same way that the web has allowed us to move from

1614
01:44:17,410 --> 01:44:21,660
one one website one document to another on

1615
01:44:22,330 --> 01:44:27,990
so the this is growing at an incredible rate and looks like it the trend

1616
01:44:27,990 --> 01:44:32,490
will continue and there's an increasing number of

1617
01:44:33,180 --> 01:44:34,720
applications that

1618
01:44:35,010 --> 01:44:39,780
that exploit this what to do something useful for the end user or talk about

1619
01:44:39,780 --> 01:44:41,390
more than that

1620
01:44:42,090 --> 01:44:46,590
in two thousand nine what can we expect to see both exists even more data

1621
01:44:46,660 --> 01:44:52,810
sets that cloud is is getting increasingly hard to for richard and his colleagues to

1622
01:44:52,810 --> 01:44:56,920
actually manage the you can see the errors all kind of cut across each other

1623
01:44:57,030 --> 01:45:00,810
and that's just gonna increasingly hard when we won't be able to represent any more

1624
01:45:00,810 --> 01:45:03,860
in in just one

1625
01:45:04,600 --> 01:45:09,250
one image there are a number of tools which you can use if you want

1626
01:45:09,330 --> 01:45:11,830
to publish stuff you can which said you can roll your own or you can

1627
01:45:11,830 --> 01:45:15,550
use one kind of rappers like d two r server triplify

1628
01:45:16,600 --> 01:45:21,580
and there are a number of kind of a growing number of plugins for these

1629
01:45:21,580 --> 01:45:25,390
what deployed services like drupal and wordpress

1630
01:45:25,680 --> 01:45:27,720
so much so

1631
01:45:28,370 --> 01:45:29,830
so it's all good and we

1632
01:45:29,870 --> 01:45:34,720
the work and implementation issues and getting well practiced how to actually publish stuff and

1633
01:45:36,410 --> 01:45:39,220
if i will feel more able to two

1634
01:45:39,330 --> 01:45:42,990
get involved in this kind of thing having been tutorial but this is a research

1635
01:45:42,990 --> 01:45:45,050
perspective is the number of

1636
01:45:45,240 --> 01:45:51,240
thorny issues which we really need to address and which provide nice opportunities for people

1637
01:45:51,240 --> 01:45:55,720
looking for interesting and kind of exciting research directions topics

1638
01:45:58,200 --> 01:45:59,580
like is already on the

1639
01:45:59,640 --> 01:46:04,140
the range of link algorithms which are being used is very limited and the algorithms

1640
01:46:04,140 --> 01:46:09,390
themselves very primitive really needs to do some better work in developing

1641
01:46:10,050 --> 01:46:14,800
the link algorithms which we familiar with them well practised in using and

1642
01:46:15,740 --> 01:46:19,720
the good news is is loads and loads of existing work on on stuff from

1643
01:46:20,140 --> 01:46:23,430
the database community we just need to get better looking at that and see how

1644
01:46:23,430 --> 01:46:27,410
we can use this in in the web context and see how we need to

1645
01:46:27,410 --> 01:46:32,350
adapt to this new article was rather well complex

1646
01:46:35,410 --> 01:46:43,030
hypothesis is that we have validated this experimentally is that users

1647
01:46:43,120 --> 01:46:47,220
i just want to see one RDF argument about protecting their want into it if

1648
01:46:47,220 --> 01:46:51,620
you have any particular topical entity seven counterculture i just don't want to just see

1649
01:46:51,990 --> 01:46:57,260
one person that once you have a broad overview pages i can find out information

1650
01:46:57,260 --> 01:47:02,370
about places to eat all maps of the area blah blah blah and what culture

1651
01:47:02,370 --> 01:47:03,640
is the

1652
01:47:04,510 --> 01:47:09,390
the kind of central entity that the the and the and browsing

1653
01:47:09,600 --> 01:47:17,140
that's the hypothesis and if first theta really validate experimentally but if this

1654
01:47:17,300 --> 01:47:20,830
is why do we need to progress from the user interaction point of view and

1655
01:47:20,850 --> 01:47:22,390
there are lots of these

1656
01:47:22,580 --> 01:47:25,300
thorny issues which the semantic web

1657
01:47:25,370 --> 01:47:27,050
community has been

1658
01:47:28,300 --> 01:47:31,950
working on the two of we to do more work in these areas particularly

1659
01:47:32,220 --> 01:47:36,740
in particular the consistency and trust in quality

1660
01:47:39,030 --> 01:47:44,800
being a kind of fairly relaxed approach until now in terms of how the data

1661
01:47:44,800 --> 01:47:50,390
in the linked data cloud is licensed some of the data is about is is

1662
01:47:50,390 --> 01:47:55,160
a republication of data that has the already published under said license

1663
01:47:57,560 --> 01:48:05,220
that lighting effect is always expressed explicitly or even expressed all and this if people

1664
01:48:05,220 --> 01:48:10,680
are going to feel confident building applications that consume and use integrate this statement to

1665
01:48:11,410 --> 01:48:14,930
conf about the terms under which they can reuse this

1666
01:48:15,100 --> 01:48:17,260
that means we only to get a lot better

1667
01:48:17,600 --> 01:48:23,030
making explicit statements for all the bits of data published about how those lies

1668
01:48:24,640 --> 01:48:28,450
papers from the linked data on the web workshop this year in beijing

1669
01:48:28,760 --> 01:48:32,950
about the open data commons

1670
01:48:33,080 --> 01:48:37,060
framework licensing data and we can also say that provide some

1671
01:48:37,760 --> 01:48:42,280
direction for how approach these issues is also

1672
01:48:42,640 --> 01:48:46,050
commons which is useful for philosophy it works but one

1673
01:48:46,390 --> 01:48:50,120
i think i will mention stages there's been a tendency to license data using for

1674
01:48:50,240 --> 01:48:52,700
the creative commons licenses

1675
01:48:53,050 --> 01:48:56,560
this find a blog post but if it's data

1676
01:48:57,350 --> 01:49:01,510
factual information then you can't use creative commons licensing that stuff you need to look

1677
01:49:01,510 --> 01:49:05,430
at something like the open data commons PDDL

1678
01:49:05,870 --> 01:49:11,830
the legal framework for which it based just doesn't apply to data so

1679
01:49:17,370 --> 01:49:19,960
i think that was the

1680
01:49:19,960 --> 01:49:24,280
this is for you

1681
01:49:25,260 --> 01:49:28,430
explain what is supposed to be

1682
01:49:28,450 --> 01:49:39,060
the model for the same using these boards

1683
01:49:39,080 --> 01:49:43,320
maybe that was the first thing to happen

1684
01:49:43,340 --> 01:49:47,130
the second world war

1685
01:49:47,150 --> 01:49:49,890
the hgplvm prior

1686
01:49:51,470 --> 01:49:54,770
right yes

1687
01:49:54,790 --> 01:49:57,210
so let me show you

1688
01:49:57,230 --> 01:49:59,080
it's simple to use

1689
01:49:59,100 --> 01:50:03,490
we try to

1690
01:50:03,510 --> 01:50:06,990
although this is a very simple works

1691
01:50:07,010 --> 01:50:09,720
and this is the only for

1692
01:50:09,730 --> 01:50:12,190
some joint

1693
01:50:12,240 --> 01:50:16,890
and then we use is the result from the use of the word

1694
01:50:18,110 --> 01:50:21,960
that is one of the

1695
01:50:26,330 --> 01:50:33,210
we minimize the creation of the signal to reach so that you don't have to

1696
01:50:33,210 --> 01:50:34,220
do with

1697
01:50:35,340 --> 01:50:37,430
or as

1698
01:50:40,060 --> 01:50:45,030
there's a lot of this is i don't know

1699
01:50:49,150 --> 01:50:51,440
so this is the

1700
01:50:51,490 --> 01:50:53,860
many of

1701
01:50:54,140 --> 01:50:57,320
o thing is

1702
01:50:57,330 --> 01:51:01,930
so we can see what you want

1703
01:51:01,980 --> 01:51:05,400
one is first so you see the

1704
01:51:05,420 --> 01:51:08,470
first of all you have

1705
01:51:08,590 --> 01:51:14,640
this is the first

1706
01:51:14,660 --> 01:51:15,950
this is the

1707
01:51:15,970 --> 01:51:25,180
so we use this small two five c so this is one not the

1708
01:51:28,580 --> 01:51:31,530
here for two

1709
01:51:33,920 --> 01:51:36,290
because this is what to do

1710
01:51:36,300 --> 01:51:40,760
and because we can

1711
01:51:40,770 --> 01:51:42,310
brennan also

1712
01:51:42,320 --> 01:51:45,270
o point of view

1713
01:51:45,280 --> 01:51:50,540
this when you start

1714
01:51:50,580 --> 01:51:53,410
so you get sounds like that

1715
01:51:53,430 --> 01:51:56,710
this is because

1716
01:51:56,730 --> 01:52:01,500
if you

1717
01:52:01,510 --> 01:52:04,860
so this a list

1718
01:52:04,880 --> 01:52:07,500
the same process here

1719
01:52:10,350 --> 01:52:12,560
from all of this

1720
01:52:12,570 --> 01:52:15,240
so one of the things that this

1721
01:52:15,260 --> 01:52:21,560
when you see some observations and what is

1722
01:52:21,580 --> 01:52:25,760
so this is an example where the whole

1723
01:52:25,830 --> 01:52:28,360
but i think of it

1724
01:52:30,150 --> 01:52:35,980
the reason for that is that

1725
01:52:35,990 --> 01:52:38,980
so you can see

1726
01:52:39,000 --> 01:52:43,280
i agree that

1727
01:52:46,100 --> 01:52:53,640
one of the things that we

1728
01:52:53,710 --> 01:52:56,340
is that most

1729
01:52:58,970 --> 01:53:08,750
this is a sequence of interest most and you know it was have started

1730
01:53:08,760 --> 01:53:11,670
so i was looking at

1731
01:53:18,550 --> 01:53:19,330
and yes

1732
01:53:19,510 --> 01:53:26,390
other side of the world

1733
01:53:26,410 --> 01:53:30,070
so far all of these sequences

1734
01:53:30,390 --> 01:53:34,820
similarly used by the

1735
01:53:37,500 --> 01:53:39,320
we have

1736
01:53:39,340 --> 01:53:43,020
so i

1737
01:53:43,030 --> 01:53:45,130
percent b

1738
01:53:45,420 --> 01:53:48,670
that would be that

1739
01:53:48,690 --> 01:53:54,070
with respect to use of the sequence is so supposed to be

1740
01:53:54,080 --> 01:53:55,850
and also

1741
01:53:59,070 --> 01:54:00,950
so this is the

1742
01:54:01,030 --> 01:54:02,850
o five three

1743
01:54:03,080 --> 01:54:06,700
so it's a

1744
01:54:06,730 --> 01:54:08,850
and the different colors

1745
01:54:10,690 --> 01:54:16,110
here is that it's very

1746
01:54:18,710 --> 01:54:20,770
last year and you get

1747
01:54:20,850 --> 01:54:21,930
one we go

1748
01:54:21,960 --> 01:54:25,660
far from the training because the one that is not

1749
01:54:25,760 --> 01:54:27,630
let's war


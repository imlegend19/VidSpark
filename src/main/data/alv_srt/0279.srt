1
00:00:00,000 --> 00:00:01,760
a strategic thinking

2
00:00:01,770 --> 00:00:04,970
which would help you predict

3
00:00:04,980 --> 00:00:06,210
the move

4
00:00:07,060 --> 00:00:10,810
other countries was a sexy

5
00:00:10,880 --> 00:00:15,650
in glamorous idea whose idea whose time seem to have

6
00:00:16,590 --> 00:00:19,570
now john nash was naturally

7
00:00:19,620 --> 00:00:22,220
irreverent iconoclastic

8
00:00:22,230 --> 00:00:29,060
when he was asked on his princeton graduate school application to state his religion he

9
00:00:29,060 --> 00:00:31,860
wrote down shintaro

10
00:00:31,920 --> 00:00:34,800
soon after he got to princeton he

11
00:00:34,810 --> 00:00:38,660
zeroed in on the problem that he knew

12
00:00:38,710 --> 00:00:41,610
i had eluded the great when i met

13
00:00:41,630 --> 00:00:42,400
you see

14
00:00:42,420 --> 00:00:45,420
john lennon had a good theory

15
00:00:45,430 --> 00:00:49,840
only four all out rivalries in which

16
00:00:49,890 --> 00:00:50,850
you're game

17
00:00:50,910 --> 00:00:52,810
is my loss

18
00:00:52,810 --> 00:00:55,520
and vice versa

19
00:00:55,530 --> 00:00:59,300
but very few real life situations

20
00:00:59,350 --> 00:01:06,150
certainly not in economics and if you think about it not even in nuclear warfare

21
00:01:06,160 --> 00:01:07,600
very few

22
00:01:07,610 --> 00:01:13,280
interesting real-life situations are in fact

23
00:01:13,320 --> 00:01:15,570
zero sum games

24
00:01:15,570 --> 00:01:17,210
so johnny cash

25
00:01:17,210 --> 00:01:19,620
instead of focusing

26
00:01:19,640 --> 00:01:21,650
on that model

27
00:01:21,660 --> 00:01:27,550
focused instead on competitive situations in which mutual gain was possible

28
00:01:27,590 --> 00:01:31,180
scenarios all the scenarios that lay

29
00:01:32,510 --> 00:01:34,570
on the spectrum between

30
00:01:34,590 --> 00:01:36,420
all out conflict

31
00:01:36,430 --> 00:01:38,810
in total cooperation

32
00:01:38,810 --> 00:01:43,770
one i'm in theory applied only to games with two players

33
00:01:43,770 --> 00:01:47,010
again most real-life situations

34
00:01:47,020 --> 00:01:50,350
that we might want to model

35
00:01:50,450 --> 00:01:53,050
whether we're talking about

36
00:01:53,100 --> 00:01:56,040
options for

37
00:01:56,080 --> 00:02:00,030
collective bargaining or the war on terror

38
00:02:00,070 --> 00:02:07,010
most interesting real-life situations involve several or many players

39
00:02:07,060 --> 00:02:10,180
what nash proved in his thesis

40
00:02:10,200 --> 00:02:12,830
was that no matter

41
00:02:12,890 --> 00:02:15,740
how complex the scenario

42
00:02:15,780 --> 00:02:19,130
no matter where it lies on this spectrum

43
00:02:19,220 --> 00:02:21,380
there is always

44
00:02:21,390 --> 00:02:22,530
at least

45
00:02:22,530 --> 00:02:24,610
one situation

46
00:02:24,660 --> 00:02:31,570
one set of circumstances in which each and every player says to him or herself

47
00:02:31,620 --> 00:02:34,990
that they have done the best they can do

48
00:02:36,400 --> 00:02:41,360
the choice is that the other players have made and therefore that they

49
00:02:41,400 --> 00:02:43,590
i have no incentive

50
00:02:43,600 --> 00:02:48,030
to make further move or otherwise change their positions

51
00:02:48,040 --> 00:02:51,430
he called them the equilibrium point

52
00:02:51,490 --> 00:02:53,020
i didn't tell you

53
00:02:53,150 --> 00:02:54,160
show you

54
00:02:54,230 --> 00:02:56,560
how you could get there

55
00:02:56,600 --> 00:03:04,570
but he proved that always exists and he did that in twenty seven pages

56
00:03:04,590 --> 00:03:06,020
in the movie

57
00:03:06,020 --> 00:03:08,070
it's a very interesting scene

58
00:03:08,090 --> 00:03:09,390
in a bar

59
00:03:09,410 --> 00:03:13,850
that dramatize is i think in a very clever way

60
00:03:13,890 --> 00:03:18,100
the dramatized the essence of nash's original idea

61
00:03:18,140 --> 00:03:19,290
and of course

62
00:03:19,320 --> 00:03:21,520
people are always asking me

63
00:03:21,560 --> 00:03:22,760
so did he

64
00:03:22,770 --> 00:03:26,050
really come up with this idea in in bar

65
00:03:27,800 --> 00:03:34,220
now nash did hang out with with graduate students in the borough council street in

66
00:03:37,390 --> 00:03:40,620
we're definitely not picking up girls

67
00:03:41,920 --> 00:03:45,960
there were no co-eds at princeton in the late forties in fact not until the

68
00:03:47,220 --> 00:03:49,580
and anyhow john nash

69
00:03:49,600 --> 00:03:53,310
it i was fairly shy with girls at that point

70
00:03:53,330 --> 00:03:55,400
at his high school prom

71
00:03:55,450 --> 00:03:58,610
which is mother forced him to attend

72
00:03:58,640 --> 00:04:02,800
with a date which she forced his younger sister

73
00:04:04,060 --> 00:04:05,530
make for him

74
00:04:07,300 --> 00:04:10,240
i prefer to spend the evening

75
00:04:10,290 --> 00:04:13,050
dancing with the stack of chairs

76
00:04:13,060 --> 00:04:14,040
and not

77
00:04:14,050 --> 00:04:15,350
not the girl

78
00:04:15,380 --> 00:04:24,280
anyway johnny cash's original idea got princeton doctorate in nineteen fifty that was a few

79
00:04:25,280 --> 00:04:28,350
short of his twenty second birthday

80
00:04:28,380 --> 00:04:31,780
it also got him an invitation to work at

81
00:04:32,840 --> 00:04:34,130
you lead

82
00:04:35,910 --> 00:04:40,300
cold war think tank the rand corporation in santa monica

83
00:04:40,310 --> 00:04:46,920
ironically however it did not impress his fellow mathematicians much

84
00:04:46,970 --> 00:04:51,140
despite the glamour that john von niemann lent

85
00:04:51,160 --> 00:04:53,840
the subject of game theory

86
00:04:53,890 --> 00:04:55,810
game theory was

87
00:04:55,810 --> 00:04:59,030
considered slightly the class a

88
00:04:59,070 --> 00:05:01,530
by princeton's pure mathematicians

89
00:05:01,530 --> 00:05:05,810
because it looked as if it might actually be useful

90
00:05:08,290 --> 00:05:13,590
i should tell you that one of the great pleasures enormous pleasures of working on

91
00:05:13,590 --> 00:05:15,000
this book was the

92
00:05:19,170 --> 00:05:24,280
many of the most eminent mathematicians of johnny cash's

93
00:05:26,490 --> 00:05:28,890
so several who are in this room

94
00:05:28,910 --> 00:05:31,070
and i have decided

95
00:05:31,110 --> 00:05:32,860
in every interview

96
00:05:32,880 --> 00:05:36,110
invariably after about a minute passed

97
00:05:36,130 --> 00:05:38,770
the mathematician would stop and say

98
00:05:38,770 --> 00:05:40,030
so the

99
00:05:40,080 --> 00:05:44,490
before i go on this one thing that you must understand

100
00:05:44,520 --> 00:05:45,800
that tries

101
00:05:45,900 --> 00:05:47,710
those economies

102
00:05:48,890 --> 00:05:49,990
that work

103
00:05:49,990 --> 00:05:53,290
that those economies gave john nash

104
00:05:53,300 --> 00:05:54,680
prize for

105
00:05:54,790 --> 00:05:58,000
the most trivial thing he ever did

106
00:06:01,570 --> 00:06:03,070
even before

107
00:06:03,090 --> 00:06:04,990
john nash

108
00:06:05,000 --> 00:06:07,400
finished his

109
00:06:07,420 --> 00:06:10,310
pieces which would one day when the nobel prize

110
00:06:11,780 --> 00:06:15,780
i started working on some other things that that you have

111
00:06:15,820 --> 00:06:20,500
another problem in his back pocket to pull out just in case

112
00:06:20,500 --> 00:06:23,290
the prince math department turned down

113
00:06:23,360 --> 00:06:25,250
his thesis

114
00:06:25,260 --> 00:06:30,110
so even before he finished he set really set out to prove

115
00:06:31,780 --> 00:06:34,430
power is the pure mathematicians

116
00:06:34,490 --> 00:06:41,530
someone to him to solve a deep problem that has baffled mathematicians since the nineteenth

117
00:06:42,590 --> 00:06:43,740
he did

118
00:06:43,750 --> 00:06:48,400
a few years later he once again a standard in the profession

119
00:06:48,430 --> 00:06:55,290
by solving an equally difficult problems in the field of partial differential equations

120
00:06:55,290 --> 00:06:57,020
in each instance

121
00:06:57,750 --> 00:07:00,650
what he did was to simplify

122
00:07:00,710 --> 00:07:02,580
a complex problems

123
00:07:02,600 --> 00:07:05,760
that appear to defy solution

124
00:07:05,760 --> 00:07:08,380
by pursuing a strategy

125
00:07:08,400 --> 00:07:11,390
but the experts in the field and he

126
00:07:11,410 --> 00:07:17,170
never tried to be an expert in any field because he felt that absorbing the

127
00:07:17,170 --> 00:07:19,050
work of other people

128
00:07:19,100 --> 00:07:21,870
would tell his creativity

129
00:07:21,890 --> 00:07:23,800
pursuing a strategy

130
00:07:23,810 --> 00:07:27,160
then the experts in the field

131
00:07:27,180 --> 00:07:32,760
i said up front was impossible if not downright bizarre

132
00:07:32,770 --> 00:07:34,200
a friend of his

133
00:07:34,210 --> 00:07:39,840
once tried to describe nash is style of thinking to me

134
00:07:39,860 --> 00:07:41,310
by saying

135
00:07:41,320 --> 00:07:44,410
everyone else would climb a peak

136
00:07:44,420 --> 00:07:49,000
by looking for piano somewhere in the mountains

137
00:07:51,420 --> 00:07:52,280
we go

138
00:07:52,290 --> 00:07:58,590
i would go over to completely different mountain climb completely different now and from that

139
00:07:58,590 --> 00:08:01,760
two elements are included

140
00:08:01,780 --> 00:08:03,230
or no x and y

141
00:08:03,240 --> 00:08:07,900
four no x and y we have accessibility problems why

142
00:08:07,940 --> 00:08:09,940
so edges are subsets

143
00:08:09,950 --> 00:08:13,250
and vertices are the elements of this

144
00:08:13,270 --> 00:08:17,170
i found herself is basically a

145
00:08:17,170 --> 00:08:19,700
that's allison mixes up it's about common

146
00:08:20,920 --> 00:08:22,760
OK lets herself

147
00:08:22,790 --> 00:08:28,280
he of the hypergraph is a subset that it's all the edges

148
00:08:28,300 --> 00:08:31,090
i mean i found herself

149
00:08:31,100 --> 00:08:33,280
is it transfers

150
00:08:33,300 --> 00:08:34,210
none of whose

151
00:08:35,290 --> 00:08:37,390
the transfer

152
00:08:37,400 --> 00:08:39,420
given the hypergraph so

153
00:08:39,430 --> 00:08:42,910
the set of elements and a bunch stubs

154
00:08:42,960 --> 00:08:47,590
he said the minimum transfer is a collection of subsets of the original set so

155
00:08:47,590 --> 00:08:50,950
it's also

156
00:08:53,560 --> 00:08:55,260
the claim is

157
00:08:57,020 --> 00:08:58,790
if we take all

158
00:08:58,850 --> 00:09:05,390
frequent sets and use them as high for

159
00:09:05,390 --> 00:09:07,290
or if we take

160
00:09:07,320 --> 00:09:10,500
he said in the positive border and u

161
00:09:10,550 --> 00:09:11,950
its complement

162
00:09:11,950 --> 00:09:15,390
as an edge in a hypergraph

163
00:09:15,400 --> 00:09:17,030
so then why

164
00:09:17,140 --> 00:09:19,930
subset of the set of elements used

165
00:09:22,100 --> 00:09:24,220
h there is an excess

166
00:09:24,240 --> 00:09:28,270
such that x is true

167
00:09:28,280 --> 00:09:32,960
so you know is is why intersect all

168
00:09:32,960 --> 00:09:35,360
the edges in the hypergraph

169
00:09:35,370 --> 00:09:37,190
then it means

170
00:09:37,210 --> 00:09:39,400
that is not included

171
00:09:39,410 --> 00:09:40,630
in any case

172
00:09:40,640 --> 00:09:43,880
on the set in the positive border

173
00:09:43,930 --> 00:09:48,270
so if something is not included in any of the sets in the positive border

174
00:09:49,050 --> 00:09:52,600
so why is not included in any of the maxima

175
00:09:52,600 --> 00:09:54,900
frequent sets

176
00:09:55,980 --> 00:09:57,100
it has be

177
00:09:57,100 --> 00:10:02,650
you can't be frequent because of everything that is frequent would be a subset of

178
00:10:02,660 --> 00:10:03,870
one of these

179
00:10:03,920 --> 00:10:05,570
maximum frequency

180
00:10:05,630 --> 00:10:07,560
so i why

181
00:10:07,970 --> 00:10:10,260
not frequent if and only if

182
00:10:10,320 --> 00:10:11,860
it transfer

183
00:10:12,610 --> 00:10:14,700
the hypergraph containing

184
00:10:14,750 --> 00:10:19,120
the complement of the

185
00:10:19,120 --> 00:10:21,400
of the frequency

186
00:10:21,420 --> 00:10:22,460
so now

187
00:10:22,470 --> 00:10:28,240
the money transfer cells are the smallest things that intersect all edges in the hypergraph

188
00:10:28,290 --> 00:10:32,940
so the minimum frequencies are exactly the minimal transversals

189
00:10:32,980 --> 00:10:34,000
of the

190
00:10:34,010 --> 00:10:39,610
compliments of the positive

191
00:10:39,620 --> 00:10:42,640
of the things in the positive toward

192
00:10:42,650 --> 00:10:48,480
so this shows that this concept of the transfer so many now transversal hypergraph theory

193
00:10:48,540 --> 00:10:50,340
actually has a clear

194
00:10:52,670 --> 00:10:56,550
two of humans in the context of

195
00:10:56,570 --> 00:10:58,800
finding frequent patterns

196
00:10:58,850 --> 00:11:00,880
and the reason why this might be of

197
00:11:00,890 --> 00:11:02,720
interest is that

198
00:11:02,740 --> 00:11:05,200
the problem of computing

199
00:11:05,240 --> 00:11:12,440
transversal hypergraph it's it studies has long been open source credit money nineteen ninety so

200
00:11:12,480 --> 00:11:13,790
that it had

201
00:11:13,870 --> 00:11:17,820
the rest of ten to the power of love

202
00:11:17,850 --> 00:11:19,760
and actually

203
00:11:19,820 --> 00:11:21,720
finding maximum

204
00:11:21,730 --> 00:11:25,200
finding an approximation of the maximal frequent sets

205
00:11:25,210 --> 00:11:26,660
you could do that

206
00:11:26,660 --> 00:11:27,910
with the

207
00:11:29,020 --> 00:11:31,090
the pretty quickly

208
00:11:31,100 --> 00:11:35,070
and the question that was asked before the break about the k to

209
00:11:35,120 --> 00:11:37,380
about the problems with sparsity

210
00:11:37,390 --> 00:11:43,980
so even for dense data one could find representation of all the frequent sets

211
00:11:44,010 --> 00:11:45,000
not all the

212
00:11:45,020 --> 00:11:50,950
not by listing all the frequency but finding the positive border by depth first search

213
00:11:50,990 --> 00:11:52,800
and then verify

214
00:11:52,820 --> 00:11:58,260
the result by computing the transfer of of the hypergraph and checking whether the things

215
00:11:58,350 --> 00:11:59,940
would really be

216
00:11:59,980 --> 00:12:03,380
minimize things would be non-free frequent

217
00:12:03,400 --> 00:12:08,590
so one could do this if we know we know how to compute hypergraph transversals

218
00:12:08,610 --> 00:12:11,700
unfortunately we don't know how to compute screen

219
00:12:17,100 --> 00:12:22,840
on the basis of a little bit confused explanations of what it that not going

220
00:12:22,900 --> 00:12:25,930
be this is just a straightforward outcome

221
00:12:25,930 --> 00:12:34,680
convert it to an semi-definite program using the formulation we showed yesterday for example for the

222
00:12:34,680 --> 00:12:40,740
maximum singular value suppose you in CVX I should have mentioned in CVX here we use

223
00:12:40,740 --> 00:12:46,210
a variable X that's a vector variable but there are many other types of objects

224
00:12:46,330 --> 00:12:50,320
you can  use instead of or other types of variables you can say

225
00:12:50,320 --> 00:12:54,820
X is a symmetric matrix of a certain order or you can say X  is a rectangular

226
00:12:54,820 --> 00:13:04,180
matrix variable of a certain dimension and CVX will handle all these things automatically so you don't have to

227
00:13:04,260 --> 00:13:08,760
combine or collects all the optimization variables in a single vector X you can just

228
00:13:08,760 --> 00:13:18,600
enumerate the variables as they several variables with the as matrices or vectors or et cetera

229
00:13:18,600 --> 00:13:21,720
so if you have a a matrix variable and you have a constraint on the on

230
00:13:21,720 --> 00:13:29,160
the matrix norm the maximum singular value then CVX will convert it into this linear

231
00:13:29,160 --> 00:13:34,800
matrix inequality so then maximum  single singular value of X is less than T if

232
00:13:34,800 --> 00:13:41,240
this matrix is positive semidefinite and so T times an identity matrix on the diagonal and then

233
00:13:41,310 --> 00:13:48,880
X and X transpose on the in the other blocks if you want to impose a

234
00:13:48,880 --> 00:13:52,820
bound on the nuclear norm so the sum of the singular values of a matrix X there is a

235
00:13:52,950 --> 00:14:00,020
similar conversion you have to introduce new variables U and V  a matrix inequality and a scalar inequality

236
00:14:00,020 --> 00:14:08,980
and then these inequalities combined are equivalent to this so it's very powerful and there is a

237
00:14:08,980 --> 00:14:13,540
much longer list but in fact here I can simply refer to the user guide of

238
00:14:13,540 --> 00:14:21,480
CVX everything in the user guide is basically very complete a list of constraints

239
00:14:21,480 --> 00:14:28,430
and functions that can be converted into semi-definite or second order cone problems

240
00:14:28,470 --> 00:14:35,010
this example also shows you some of the actual limitation of this modeling system so you

241
00:14:35,010 --> 00:14:42,400
see that because you convert  the constraint into a semi-definite form that in this case that

242
00:14:42,400 --> 00:14:50,440
requires auxiliary variables U and V of the dimensions determined by the dimensions of

243
00:14:50,440 --> 00:14:54,580
X so if X is a P times Q matrix then you have an matrix U of

244
00:14:54,580 --> 00:14:59,580
order P and a new variable V of order Q so the number of variables

245
00:14:59,580 --> 00:15:04,080
you get in this problem if you do this transformation actually can be very large

246
00:15:04,080 --> 00:15:11,280
so for very large problems this conversion to an semi-definite programming

247
00:15:11,280 --> 00:15:20,080
by these automated modeling systems might become too expensive at some point because it converts

248
00:15:20,080 --> 00:15:26,040
everything into semi-definite constraints and that may require introducing some auxiliary variables and increasing the

249
00:15:26,040 --> 00:15:35,560
dimension of the problem so then these are some applications of these two other

250
00:15:35,560 --> 00:15:42,620
cones the exponential cone and the power cone that are actually not s examples of functions

251
00:15:42,620 --> 00:15:46,860
that cannot be directly written as second-order cone or semi-definite constraint for example if you

252
00:15:46,860 --> 00:15:54,720
have an exponential or a logarithm so convex exponential the logarithm as a concave function or

253
00:15:54,720 --> 00:16:00,760
an entropy then you can easily write these as linear functions with respect to the exponential cone

254
00:16:00,760 --> 00:16:08,060
but if you want to write them using semi-definite cones you have to approximate these

255
00:16:08,060 --> 00:16:15,920
nonlinear functions for example by polynomials or by piece-wise linear functions for the power cone

256
00:16:15,920 --> 00:16:22,140
also is a little more general then  the functions you can handle using semi-definite

257
00:16:22,140 --> 00:16:27,280
or second-order cones for example we've seen that powers of X can be written as

258
00:16:27,280 --> 00:16:33,800
second-order cone constraints if P or Q are rational if it's not rational you either have to approximate it by

259
00:16:33,800 --> 00:16:40,940
a rational number and write it as a second-order cone constraint and that may  require introducing

260
00:16:41,040 --> 00:16:46,640
many new variables or you can directly write it as linear inequalities with respect to this power cone

261
00:16:46,640 --> 00:16:53,500
because there you had  restriction so these are currently not  included in these

262
00:16:53,500 --> 00:17:00,040
modeling systems it's not much of a limitation because these constraints can be easily approximated

263
00:17:00,040 --> 00:17:03,290
which is the target value

264
00:17:03,310 --> 00:17:06,430
OK it sounds unclear on given the model

265
00:17:06,460 --> 00:17:10,140
i'm gonna policy amassed evaluated i just cycle through iteration

266
00:17:10,160 --> 00:17:13,710
and you out in the end when he finishes

267
00:17:13,750 --> 00:17:17,140
you have good estimate of the pie

268
00:17:17,160 --> 00:17:21,180
how good it is a public policy pi

269
00:17:21,230 --> 00:17:22,000
this is the

270
00:17:22,000 --> 00:17:24,620
policy evaluation evaluation

271
00:17:28,750 --> 00:17:30,480
now let's do

272
00:17:30,520 --> 00:17:32,790
and as you do the same thing

273
00:17:32,810 --> 00:17:35,680
you can do the same thing with the state action value what i want to

274
00:17:35,680 --> 00:17:40,620
spend time with this is exactly the same iterations but only for the state action

275
00:17:40,620 --> 00:17:43,930
pair rather than the that the

276
00:17:43,980 --> 00:17:46,020
state values so it's

277
00:17:46,040 --> 00:17:48,200
to say

278
00:17:48,210 --> 00:17:51,250
what is unique

279
00:17:52,180 --> 00:17:53,810
why you

280
00:17:53,830 --> 00:17:59,870
the my question the question is is behind me

281
00:17:59,890 --> 00:18:01,270
give height

282
00:18:01,370 --> 00:18:02,930
is it you

283
00:18:02,960 --> 00:18:09,890
and it is unique because you fix the policy some reward distribution and but for

284
00:18:09,890 --> 00:18:13,640
the first principal definition by the value of a state as the policy pi the

285
00:18:13,640 --> 00:18:16,390
expected discounted sum of rewards you would get

286
00:18:16,440 --> 00:18:19,890
and everything is well formulated so you will get a unique value function

287
00:18:19,890 --> 00:18:21,810
three pies inequality

288
00:18:21,850 --> 00:18:26,410
what's not unique is the optimal policy get but i mean i get to that

289
00:18:26,480 --> 00:18:28,580
talk about that

290
00:18:28,600 --> 00:18:31,290
OK so now let's talk to control

291
00:18:31,310 --> 00:18:36,910
optimal control is planning optimal control is given the model is given the transition probabilities

292
00:18:37,230 --> 00:18:41,660
given the reward function and your task is to find the optimal policy

293
00:18:41,710 --> 00:18:44,210
part that word is exactly the same idea

294
00:18:44,290 --> 00:18:48,710
i'm going to do exactly the same thing called value iteration from dynamic programming i'm

295
00:18:48,710 --> 00:18:51,960
sure recursive bellman optimality equation

296
00:18:51,980 --> 00:18:54,100
that is i'm going to feed my initial guess

297
00:18:54,140 --> 00:18:58,790
on the right-hand side of the left hand side my next guest cycle

298
00:18:58,850 --> 00:19:02,890
so i'm said in my new guess who comedian max all actions of the media

299
00:19:02,890 --> 00:19:09,660
award but the discounted expected current value of the next day

300
00:19:09,660 --> 00:19:13,520
and again i will talk about why this converges in if you know in you

301
00:19:13,520 --> 00:19:18,020
know when i don't like you know these convergence

302
00:19:18,040 --> 00:19:20,270
and the same thing here

303
00:19:20,290 --> 00:19:24,640
for state action values and in particularly for optimal control question state action values become

304
00:19:25,020 --> 00:19:29,430
very meaningful minute so now you are getting every state action pair

305
00:19:29,480 --> 00:19:32,580
and the next guess is the immediate reward plus

306
00:19:32,600 --> 00:19:39,480
the discounted expected best value the next day

307
00:19:39,480 --> 00:19:44,290
he cooks and you and you repeat this in every iteration converges to the queue

308
00:19:45,480 --> 00:19:52,430
it converges in the limit to the optimal optimal value functions and what is stopping

309
00:19:52,430 --> 00:19:57,560
criteria again stopping criterion is the same thing the difference between two iterations the max

310
00:19:57,560 --> 00:19:59,850
norm the maximum difference

311
00:19:59,850 --> 00:20:02,270
absolute difference between

312
00:20:02,290 --> 00:20:06,830
a state action pairs of eyes or two iterations is less than that's what it's

313
00:20:08,680 --> 00:20:12,370
right so this is the solution to the optimal control problem in in in in

314
00:20:12,370 --> 00:20:15,750
the planning case

315
00:20:15,830 --> 00:20:16,980
and talk about

316
00:20:25,370 --> 00:20:26,870
let me prove to you

317
00:20:26,890 --> 00:20:31,180
and just because i want to one of these proofs because they are the foundation

318
00:20:31,180 --> 00:20:36,310
if you like of the proof to reinforcement learning has had has built over time

319
00:20:36,310 --> 00:20:41,350
for forcefully bonds one illustrate the idea is very simple proof of the conclusion convergence

320
00:20:41,350 --> 00:20:47,790
for value iteration using the state action values as the as the instance

321
00:20:47,790 --> 00:20:52,580
so what would prove to you now is that

322
00:20:52,750 --> 00:20:57,060
is what's called the contraction property and dynamic programming towards

323
00:20:57,080 --> 00:20:59,210
we define that means so

324
00:20:59,270 --> 00:21:01,460
let delta k

325
00:21:01,520 --> 00:21:02,700
be the better

326
00:21:02,750 --> 00:21:04,140
they the can iteration

327
00:21:04,230 --> 00:21:07,230
that is it is the maximum

328
00:21:08,520 --> 00:21:09,960
after the q set k

329
00:21:09,980 --> 00:21:12,080
from q stock

330
00:21:12,080 --> 00:21:16,060
so i'm looking at you start looking at which i don't know

331
00:21:16,160 --> 00:21:17,560
you want to get to

332
00:21:17,580 --> 00:21:21,930
but conceptually i'm saying let delta OK k with the at time step k defined

333
00:21:21,930 --> 00:21:25,680
in this fashion that i'm looking all state action pairs and asking what the absolute

334
00:21:25,680 --> 00:21:31,960
difference between of confused i'm going to prove to you is that qz campus one

335
00:21:31,960 --> 00:21:33,350
it is close to

336
00:21:33,350 --> 00:21:35,520
to q started his of k one

337
00:21:35,560 --> 00:21:37,100
by a factor of gamma

338
00:21:37,140 --> 00:21:39,330
i multiplicative factor again

339
00:21:39,350 --> 00:21:40,640
let's do that proof

340
00:21:40,640 --> 00:21:43,140
because it gives one that's come coming here

341
00:21:43,160 --> 00:21:48,890
is the immediate reward plus the discounted expected best value of next day

342
00:21:48,940 --> 00:21:51,060
so let's look at q of k

343
00:21:51,060 --> 00:21:52,830
let's look at the can guess

344
00:21:53,000 --> 00:21:57,140
i know they can guess by this definition

345
00:21:59,040 --> 00:22:00,040
no more

346
00:22:00,060 --> 00:22:04,830
then q star optimal value for the election papers delta k

347
00:22:05,580 --> 00:22:08,370
that's what this definition means well defined as the k

348
00:22:08,370 --> 00:22:11,000
so that this inequality holds

349
00:22:11,160 --> 00:22:13,480
so replacing cues of k

350
00:22:13,500 --> 00:22:14,770
by something

351
00:22:14,770 --> 00:22:17,100
but i know is larger

352
00:22:17,160 --> 00:22:20,770
q stock must have k

353
00:22:20,810 --> 00:22:22,140
and now

354
00:22:22,200 --> 00:22:25,500
the simple trick is the observation that delta k

355
00:22:25,500 --> 00:22:28,310
it is independent of a is independent of s

356
00:22:28,330 --> 00:22:31,160
so is put out

357
00:22:31,230 --> 00:22:32,810
when i put out

358
00:22:32,830 --> 00:22:35,230
i modified by gamma

359
00:22:35,270 --> 00:22:36,890
so gamma delta k

360
00:22:36,910 --> 00:22:40,350
and i'm left with things square brackets

361
00:22:40,390 --> 00:22:43,480
and if you look at this

362
00:22:43,500 --> 00:22:44,930
this is exactly

363
00:22:44,930 --> 00:22:46,770
by the optimality equations

364
00:22:46,790 --> 00:22:52,120
the optimal q value of state action pairs come i

365
00:22:52,160 --> 00:22:53,350
thereby proving

366
00:22:54,890 --> 00:22:57,100
after the configuration

367
00:22:57,100 --> 00:23:00,590
exact solutions much before the tree with depending of course on the on the problem

368
00:23:16,120 --> 00:23:18,910
the length of the what cycle

369
00:23:18,970 --> 00:23:24,470
long cycles in some ways are good

370
00:23:24,490 --> 00:23:26,080
tree with

371
00:23:26,990 --> 00:23:28,830
two it is more related to

372
00:23:28,860 --> 00:23:32,020
it goes up as you have short cycles roughly speaking

373
00:23:32,240 --> 00:23:33,630
so if you have a grid

374
00:23:33,690 --> 00:23:37,400
two by biogrid and in two dimensions you have cycles of length four

375
00:23:37,410 --> 00:23:40,390
the tree with the the grid if you have a side length let's say a

376
00:23:40,390 --> 00:23:43,040
square root and by square root and

377
00:23:43,080 --> 00:23:47,600
the tree with asymptotically is of the same size as the side length

378
00:23:47,610 --> 00:23:50,530
so it's a disaster it's like square root and

379
00:23:50,640 --> 00:23:55,120
so instead of being exponential in n you're exponential square root and butt

380
00:23:55,160 --> 00:23:59,100
you know it doesn't really matter when you talk about reasonable size and

381
00:23:59,110 --> 00:24:02,970
yes so i i'm not doing this but it for those who don't know in

382
00:24:03,040 --> 00:24:08,460
introductory chapter talks about junction tree it's very important framework due to low attendance beagle

383
00:24:08,460 --> 00:24:10,610
halter essentially

384
00:24:10,630 --> 00:24:14,740
any problem can be solved exactly if you're prepared to pay a price exponential in

385
00:24:14,740 --> 00:24:15,880
the treewidth

386
00:24:15,890 --> 00:24:19,450
but what's interesting for practical purposes that many graphs

387
00:24:19,500 --> 00:24:23,680
i don't have low treewidth they have large treewidth so junction tree

388
00:24:23,690 --> 00:24:26,900
it is known to be practical for those problems and that's that's where all these

389
00:24:27,330 --> 00:24:32,690
approximation schemes are motivated by graphs with high treewidth

390
00:24:32,700 --> 00:24:34,410
so it's been

391
00:24:34,460 --> 00:24:38,720
a lot of work on the slides could be updated to be whole

392
00:24:38,730 --> 00:24:44,980
another slides actually mention sort of convergence schemes globerson and jaakkola and in two thousand

393
00:24:44,980 --> 00:24:49,400
seven had to convergence scheme comoros in two thousand five also had a slightly different

394
00:24:49,400 --> 00:24:50,680
convergence scheme

395
00:24:50,730 --> 00:24:54,850
there's been a whole line of work there's more than this more recent papers by

396
00:24:54,850 --> 00:24:57,330
you where your wife and his group about

397
00:24:57,340 --> 00:25:04,180
more generally and convex free energies and generalizations of this tree reweighted belief propagation

398
00:25:04,270 --> 00:25:09,240
there's a whole line of work until dual decomposition as which i said is is

399
00:25:09,240 --> 00:25:14,380
some related and there's various higher order relaxations

400
00:25:26,970 --> 00:25:28,380
where did he go

401
00:25:28,420 --> 00:25:35,640
so let's just go back to this example here

402
00:25:35,690 --> 00:25:38,330
because i just want to sort of describe just i'm not going to go into

403
00:25:38,330 --> 00:25:41,880
details but just as a guide for you and reading literature in addition to a

404
00:25:41,880 --> 00:25:48,080
linear programming relaxation you you may well read about things like conic programming relaxations

405
00:25:48,320 --> 00:25:53,640
and probably even mentions a second order cone programs and semi definite programs

406
00:25:53,640 --> 00:25:57,810
so there are there other relaxations that you can do they are not linear programming

407
00:26:00,120 --> 00:26:03,450
there's been some work on that but i think quite a bit less i actually

408
00:26:03,450 --> 00:26:08,590
think there's there's probably more juice in that area because some of these relaxations have

409
00:26:08,590 --> 00:26:11,850
very different field than the linear programming ones

410
00:26:11,860 --> 00:26:16,640
so to give you a flavor let's go back to this problem here right so

411
00:26:16,640 --> 00:26:18,460
if you remember this problem

412
00:26:18,490 --> 00:26:25,100
this was this weird example i constructed this morning it was an example of the

413
00:26:25,110 --> 00:26:28,170
problem where

414
00:26:28,220 --> 00:26:30,030
everyone is pairwise happy

415
00:26:30,330 --> 00:26:34,920
but globally something bad is going on so we had a pair that were agreeing

416
00:26:34,920 --> 00:26:38,790
eighty percent of the time eighty percent of the time and then

417
00:26:38,810 --> 00:26:43,140
this peer here were a green twenty percent of the time this was OK for

418
00:26:43,140 --> 00:26:48,170
the local relaxation but we sort of reasoned well i told you and you have

419
00:26:48,170 --> 00:26:50,630
to believe me that it's not globally feasible

420
00:26:50,670 --> 00:26:53,900
so let me just show you quickly of give you a quick proof

421
00:26:53,910 --> 00:26:58,930
of why it's not globally feasible and this will actually illustrate how semi definite constraints

422
00:26:58,930 --> 00:27:04,090
can be used

423
00:27:04,880 --> 00:27:08,460
so mean it's right here because i found that i destroy my slides less if

424
00:27:08,460 --> 00:27:12,300
i do this so this does bear with me for one second and then i'll

425
00:27:12,300 --> 00:27:22,810
put it up for us

426
00:27:22,820 --> 00:27:28,240
OK so

427
00:28:02,880 --> 00:28:03,810
all right so

428
00:28:04,330 --> 00:28:09,200
what i'm doing here so what i'd like to do is to show you why

429
00:28:09,210 --> 00:28:14,160
this thing is it's sort of bad i'm going to focus just on

430
00:28:14,200 --> 00:28:15,410
let's focus on

431
00:28:15,450 --> 00:28:18,370
this number here

432
00:28:18,380 --> 00:28:21,350
so we give that name what's called that number

433
00:28:21,860 --> 00:28:28,380
so the little bit of abuse of notation and call that mu one

434
00:28:28,430 --> 00:28:31,410
a focus on that number there will call that mu one three

435
00:28:31,440 --> 00:28:35,780
site abuse of notation but despair with me that number there were column u two

436
00:28:36,490 --> 00:28:39,880
and similarly will call this mu three

437
00:28:39,900 --> 00:28:42,090
this mu two

438
00:28:42,090 --> 00:28:45,080
first thank you for inviting

439
00:28:45,090 --> 00:28:47,420
in particular for

440
00:28:47,750 --> 00:28:51,340
give me a chance of coming back to barcelona last year when i was here

441
00:28:51,340 --> 00:28:55,410
at the time to explore the city i hope more can now

442
00:28:55,470 --> 00:29:00,110
yes of this tutorial jointly with petrol is about combining logic and probability and very

443
00:29:00,110 --> 00:29:03,680
happy to give this talk because i'm quite excited about this research topic

444
00:29:03,700 --> 00:29:05,300
but it's not only me

445
00:29:05,450 --> 00:29:11,140
it's actually quite a lot of people who are excited about that so well patronised

446
00:29:11,140 --> 00:29:13,790
would like to thank all of them because without them

447
00:29:13,820 --> 00:29:16,900
what we are talking about wouldn't be there so

448
00:29:16,920 --> 00:29:19,070
in case

449
00:29:19,080 --> 00:29:20,740
that you want to leave early

450
00:29:20,750 --> 00:29:24,770
here's what you should take home with you right so the idea is that the

451
00:29:24,770 --> 00:29:29,010
graph is not enough we need logic i mean given that we here i guess

452
00:29:29,010 --> 00:29:32,360
you know what we need to graphical models are called

453
00:29:32,420 --> 00:29:34,820
we don't say we need logical models we need

454
00:29:34,820 --> 00:29:39,820
most likely new forms of models we need models which combine probability and logic across

455
00:29:39,850 --> 00:29:40,970
not just

456
00:29:42,540 --> 00:29:44,430
the roadmap to this goal

457
00:29:45,250 --> 00:29:49,090
well so that you have to take away message that you go home and say

458
00:29:49,090 --> 00:29:52,980
you could we can contribute there is little motivation

459
00:29:53,010 --> 00:29:58,780
then very by is a short overview on what statistical relational learning statistical relational AI

460
00:29:59,840 --> 00:30:03,320
and then many of the concepts mentioned here will be illustrated

461
00:30:03,340 --> 00:30:07,530
using markov logic networks and the second or third part

462
00:30:07,530 --> 00:30:10,450
there will be a break somewhere in the third part

463
00:30:10,450 --> 00:30:12,640
but let's see car we can get

464
00:30:12,650 --> 00:30:15,030
so motivation

465
00:30:15,040 --> 00:30:20,780
and this is currently my most favourite motivation for the whole topic for two reasons

466
00:30:20,840 --> 00:30:23,760
if you look at it i can ask you what you see

467
00:30:23,780 --> 00:30:26,790
and i can ask myself what i would do a learn

468
00:30:26,810 --> 00:30:27,700
about you

469
00:30:27,730 --> 00:30:30,730
by looking at

470
00:30:30,750 --> 00:30:34,750
but i also like it to my wife background just for you my wife is

471
00:30:34,870 --> 00:30:39,310
psychologist so i cannot really tell you this doesn't work right we know that now

472
00:30:39,310 --> 00:30:43,900
operators already it really does it doesn't tell me anything about you it doesn't tell

473
00:30:44,150 --> 00:30:48,920
you anything about me by showing you that next to that my wife maybe like

474
00:30:48,980 --> 00:30:51,000
but then this or its union are

475
00:30:51,020 --> 00:30:54,710
he managed to come up with the world's best selling a lot

476
00:30:54,800 --> 00:30:57,370
about computer science

477
00:30:57,380 --> 00:31:00,720
because when i show you this slide and ask you what you see here i

478
00:31:00,720 --> 00:31:03,310
guess you can come up with many and right

479
00:31:03,340 --> 00:31:06,940
so for example you may say this is much more efficient right

480
00:31:06,970 --> 00:31:08,210
or you may say

481
00:31:08,210 --> 00:31:10,330
this is storage capacity

482
00:31:10,340 --> 00:31:13,590
i say this is number of scientific publications

483
00:31:13,630 --> 00:31:16,280
you may say this is the number of facebook users

484
00:31:16,310 --> 00:31:20,150
it makes a number of web pages

485
00:31:20,160 --> 00:31:20,960
all right

486
00:31:20,970 --> 00:31:24,830
any other kind of so for example right now i was just coming back from

487
00:31:24,830 --> 00:31:31,120
meeting on computational sustainability and can fairly say that similar curve get the data together

488
00:31:31,120 --> 00:31:35,240
currently with rather low price and price and they are facing the problem of how

489
00:31:35,240 --> 00:31:40,300
to make any sense of the of the data gathering

490
00:31:40,400 --> 00:31:47,270
a similar project actually many people not only in the AI community or UAI community

491
00:31:47,270 --> 00:31:51,880
of machine learning community but also in the database community are looking at this idea

492
00:31:51,880 --> 00:31:55,930
of the world-wide mind right so we have these kinds of web pages we have

493
00:31:55,990 --> 00:31:59,400
users who are willing to spend the time to put all the knowledge on the

494
00:31:59,400 --> 00:32:03,400
web and imagine that we can extract all the knowledge they put them in

495
00:32:03,520 --> 00:32:05,800
and every second

496
00:32:05,990 --> 00:32:10,030
their lives are like if we can extract that hopefully we can make the machine

497
00:32:10,030 --> 00:32:15,740
turned smarter so that's the idea here and there is another project you don't hear

498
00:32:15,740 --> 00:32:18,530
sending someone to a clinic or not

499
00:32:19,610 --> 00:32:21,050
data from

500
00:32:21,050 --> 00:32:23,240
security personnel

501
00:32:23,260 --> 00:32:28,930
taking shelter contain danger this is like a government

502
00:32:29,180 --> 00:32:31,490
safety procedures

503
00:32:33,110 --> 00:32:37,280
if i want to do this web scale

504
00:32:38,120 --> 00:32:42,130
there's again this growing number of

505
00:32:42,260 --> 00:32:47,200
of technology so if you look at this in in a bottom-up fashion there's more

506
00:32:47,200 --> 00:32:51,300
real time data that today which can not be processed efficiently

507
00:32:51,320 --> 00:32:52,720
so i

508
00:32:52,740 --> 00:32:55,360
i have some goes to process this data on the fly

509
00:32:55,380 --> 00:32:58,950
with the high throughput and distributed event processing

510
00:32:58,950 --> 00:33:04,180
and i want to do this in an elastic way that it's not expensive for

511
00:33:04,180 --> 00:33:08,380
me so that you if i want to use cloud resources to do this i'm

512
00:33:08,400 --> 00:33:11,340
available i'm i'm able to

513
00:33:11,360 --> 00:33:18,530
to use these computing resources into freedom again after i i did my processing

514
00:33:18,530 --> 00:33:24,130
multi tenancy so having many different customers in isolation permissions and privacy

515
00:33:24,140 --> 00:33:26,110
the parts of the goals

516
00:33:27,700 --> 00:33:30,030
if you want to do this for the web

517
00:33:30,050 --> 00:33:35,010
i need an event format how to describe my data which should be standardised and

518
00:33:35,010 --> 00:33:39,110
extensible so that many people can take part in actually extend the system so i

519
00:33:39,110 --> 00:33:43,400
don't expect to know all the use cases and to formalise all events so i

520
00:33:43,400 --> 00:33:45,970
need this event format to be open to everyone

521
00:33:45,990 --> 00:33:48,840
and then in this event pattern language

522
00:33:48,910 --> 00:33:55,740
which matches the event formats only the matching query language to filter events and

523
00:33:55,760 --> 00:34:01,010
i will probably need some thoughts sort of event marketplace because the fabric big and

524
00:34:01,010 --> 00:34:04,450
i need to be able to find interesting sources

525
00:34:07,780 --> 00:34:13,180
OK again an event is something that happened or is being contemplated is happening

526
00:34:13,200 --> 00:34:15,590
and one want these as

527
00:34:15,610 --> 00:34:20,240
first class citizens in our in our system so that there an event is of

528
00:34:21,430 --> 00:34:26,900
information unit which can be stored queried merged with other events processed

529
00:34:26,910 --> 00:34:30,590
so an event is really an object which i can hand from one function to

530
00:34:30,590 --> 00:34:34,450
the next and from one system to the next and event is not inferred from

531
00:34:34,450 --> 00:34:35,760
changes in value

532
00:34:35,780 --> 00:34:40,380
or in class membership of something and it's not the function call per say

533
00:34:40,400 --> 00:34:44,520
but it really the data object which i can handle around and also store for

534
00:34:44,520 --> 00:34:47,090
a history events have

535
00:34:47,110 --> 00:34:51,510
time properties as i said already an event is at least a data item and

536
00:34:51,510 --> 00:34:57,640
timestamp but often times you will have type hierarchy is like saying this is something

537
00:34:57,640 --> 00:34:59,050
from social media

538
00:34:59,070 --> 00:35:04,390
more specifically this is from facebook more specifically this is a feat update of a

539
00:35:04,390 --> 00:35:07,050
friend and

540
00:35:07,110 --> 00:35:11,450
we'll probably have into event relationships where linking will come in again

541
00:35:15,110 --> 00:35:21,180
many real life systems this domain of occurrences that can possibly happen is so large

542
00:35:21,180 --> 00:35:25,450
and cannot be modelled at design time so we

543
00:35:25,470 --> 00:35:27,050
model explicitly

544
00:35:27,070 --> 00:35:33,220
the known relationships so if you think of a state machine where you have i

545
00:35:33,220 --> 00:35:36,990
don't know facebook user in the state of sending something

546
00:35:36,990 --> 00:35:41,490
and then coming into another state of having sent something you don't model all these

547
00:35:41,490 --> 00:35:46,240
states because you don't know what facebook will allow today allow tomorrow but you model

548
00:35:46,240 --> 00:35:47,610
the state transitions

549
00:35:47,660 --> 00:35:51,220
by creating new event types

550
00:35:51,220 --> 00:35:53,450
and the RDF the

551
00:35:53,470 --> 00:35:59,680
w three c standard comes in because it allows open world assumption modelling so that

552
00:35:59,680 --> 00:36:04,450
everybody can add new types and new subtypes to this large system

553
00:36:04,470 --> 00:36:09,900
we want to be open extensible so everybody can produce or consume events and create

554
00:36:09,910 --> 00:36:14,970
a new types to to work together with the web community

555
00:36:14,990 --> 00:36:20,590
now more requirements if you want to build this for the web

556
00:36:21,090 --> 00:36:26,220
his ontology reuse so we want to create an RDF model

557
00:36:27,450 --> 00:36:33,070
i want to find ontologies which enabled me to do this we've heard in john

558
00:36:33,070 --> 00:36:39,990
paul's talk about the adult top level ontology which defines endurant current were endurant is

559
00:36:39,990 --> 00:36:42,880
something that is always true is static fact

560
00:36:42,930 --> 00:36:45,140
and the current which is an event

561
00:36:45,160 --> 00:36:49,660
so we can inherit from this data type and use this in our model defined

562
00:36:49,680 --> 00:36:54,220
starttime and endtime for example like

563
00:36:54,240 --> 00:36:54,820
in in

564
00:36:54,990 --> 00:36:58,910
tweet i'll just have one timestamp but i can define them over an interval if

565
00:36:58,910 --> 00:37:03,720
i want there's also a lot of ways of modelling location so i'll just inherited

566
00:37:03,740 --> 00:37:12,530
from ontology for example the neo geo ontology which is based on the very simple

567
00:37:12,530 --> 00:37:14,930
ECG o point

568
00:37:14,930 --> 00:37:16,490
which is why you get to

569
00:37:16,510 --> 00:37:22,510
points lines strings polygons to model that something happened on the city area of city

570
00:37:23,590 --> 00:37:28,470
the goal is again to be open and extensible

571
00:37:28,490 --> 00:37:29,930
and use RDF

572
00:37:32,510 --> 00:37:37,550
precisely to use linked data you've heard a lot about that so i'll skip the

573
00:37:42,030 --> 00:37:48,160
happy to use linked data for several purposes one is to get static context for

574
00:37:48,160 --> 00:37:54,280
events so that additional information is being able to be retrieved so if i have

575
00:37:56,720 --> 00:38:01,880
moving piece of data someone saying on facebook that he liked the movie x

576
00:38:01,910 --> 00:38:04,200
i can always if it's linked

577
00:38:04,220 --> 00:38:05,680
i can go to

578
00:38:05,760 --> 00:38:11,380
wikipedia and query all the parameters of this movie like i can get to direct

579
00:38:11,400 --> 00:38:12,840
i can get the year

580
00:38:12,860 --> 00:38:17,720
and so there's a lot of additional information like which we call event context which

581
00:38:17,720 --> 00:38:22,590
i can get from this linked data cloud there was shown yesterday also

582
00:38:22,590 --> 00:38:28,140
structured information is very important that it's machine readable

583
00:38:28,160 --> 00:38:31,660
not only the modelling of the data but also the publishing of the data is

584
00:38:31,660 --> 00:38:34,010
interesting in terms of linked data

585
00:38:34,010 --> 00:38:36,780
that you should use http

586
00:38:36,820 --> 00:38:40,880
your eyes for events so that you can retrieve them by IDE and link to

587
00:38:40,880 --> 00:38:42,900
all the events which happened before

588
00:38:42,910 --> 00:38:49,110
and you should also be able to link two real-time updates so you're

589
00:38:49,160 --> 00:38:54,820
able to connect events but also to have actually if your eyes to get the

590
00:38:54,820 --> 00:38:59,280
latest updates so if you want to create a mashup with only the newest events

591
00:38:59,680 --> 00:39:01,990
there will be a link for that everything is

592
00:39:01,990 --> 00:39:05,280
pure http and restful communication

593
00:39:06,430 --> 00:39:08,550
i was working

594
00:39:08,570 --> 00:39:10,220
and working with a colleague

595
00:39:10,240 --> 00:39:16,610
from i've been from our institute to create a paper on that and how to

596
00:39:16,610 --> 00:39:22,050
publish event streams as linked data where we try to on all these linked data

597
00:39:22,050 --> 00:39:24,380
principles that you heard about yesterday

598
00:39:24,400 --> 00:39:26,700
and the

599
00:39:26,720 --> 00:39:32,570
the hard part is to get this working for streaming so once you open once

600
00:39:32,570 --> 00:39:37,160
you do reference such a URI in your browser you will not get a fixed

601
00:39:37,160 --> 00:39:41,380
set of triples back but you will get an endless stream so

602
00:39:41,410 --> 00:39:44,050
application integration is

603
00:39:45,180 --> 00:39:47,720
for this sort of application and

604
00:39:47,740 --> 00:39:49,240
some research

605
00:39:49,260 --> 00:39:51,050
still needs or some

606
00:39:51,050 --> 00:39:54,180
structure macro consequences but it

607
00:39:54,240 --> 00:39:55,050
so how

608
00:39:55,060 --> 00:39:57,480
local things when they interact

609
00:39:57,480 --> 00:39:59,670
in apply some

610
00:40:00,620 --> 00:40:05,180
overall behavior in other words when you have many small pieces

611
00:40:05,240 --> 00:40:08,010
yet somehow interact together

612
00:40:08,050 --> 00:40:09,880
you would be interested in

613
00:40:09,900 --> 00:40:12,250
figuring out how the whole

614
00:40:12,260 --> 00:40:16,170
right that's the typical case of happens in physics

615
00:40:16,180 --> 00:40:17,610
when they

616
00:40:18,870 --> 00:40:20,990
after something like

617
00:40:21,120 --> 00:40:23,840
cuba eyes will t

618
00:40:24,550 --> 00:40:26,740
so how can you actually

619
00:40:26,780 --> 00:40:31,610
even though both things out theoretically how can you actually show

620
00:40:32,610 --> 00:40:33,480
all these

621
00:40:33,480 --> 00:40:37,300
things that happen in democracy structure arise from

622
00:40:37,350 --> 00:40:38,220
the local

623
00:40:39,620 --> 00:40:42,790
behaviour of atoms in this case

624
00:40:42,860 --> 00:40:47,050
for example in physics and people have tried to to figure out how

625
00:40:47,110 --> 00:40:47,790
i mean

626
00:40:47,800 --> 00:40:50,850
i have a system of particles you want to understand

627
00:40:50,970 --> 00:40:55,440
basically what's the overall state minimum energy because it's not

628
00:40:56,690 --> 00:40:58,870
real systems like two

629
00:40:59,650 --> 00:41:02,430
person who states of small energy

630
00:41:02,480 --> 00:41:03,650
and basically

631
00:41:04,860 --> 00:41:10,850
it's a very important question many problems in physics people out which configuration

632
00:41:10,900 --> 00:41:12,470
system give you

633
00:41:12,480 --> 00:41:13,690
most energy

634
00:41:13,710 --> 00:41:15,220
for example

635
00:41:15,310 --> 00:41:20,610
other systems may also have interacting parts and you are interested in not in the

636
00:41:20,610 --> 00:41:27,120
interacting parts themselves but you are interested in some query about the consequence of the

637
00:41:27,120 --> 00:41:31,600
entire system given interacting parts town

638
00:41:31,650 --> 00:41:34,170
think about the college you have a set of

639
00:41:34,170 --> 00:41:37,360
organisms animals or whatever

640
00:41:37,470 --> 00:41:40,900
they can each assume certain types of behavior

641
00:41:40,920 --> 00:41:44,240
in a given ecosystem for example

642
00:41:44,320 --> 00:41:49,740
and then you have given interactions between these organisms you may assume for example that

643
00:41:49,740 --> 00:41:51,550
some parts of the animal

644
00:41:51,550 --> 00:41:56,820
they like other types of animals and is like the factors

645
00:41:57,880 --> 00:41:59,420
and they also have some

646
00:41:59,420 --> 00:42:02,460
preference towards certain behaviours maybe they

647
00:42:02,540 --> 00:42:05,740
usually well-behaved or you bet

648
00:42:05,800 --> 00:42:10,110
given that to put a bunch of these animals together

649
00:42:10,110 --> 00:42:12,050
what's going to happen i mean

650
00:42:12,100 --> 00:42:14,120
is that

651
00:42:14,150 --> 00:42:18,990
ecosystems going to be clear every time i'm going to basically

652
00:42:19,010 --> 00:42:23,240
drive towards extinction of some species mean what's going to happen

653
00:42:23,340 --> 00:42:24,790
what's the actually bring

654
00:42:25,870 --> 00:42:28,740
of such system and have very complex

655
00:42:28,800 --> 00:42:31,100
small interacting

656
00:42:31,110 --> 00:42:33,050
parts that are

657
00:42:33,110 --> 00:42:36,170
somehow dynamically coupled

658
00:42:36,180 --> 00:42:38,220
what's the overall leaving the

659
00:42:38,260 --> 00:42:39,940
things like

660
00:42:39,990 --> 00:42:44,410
i mean i'm starting with these examples outside computer science just to show

661
00:42:44,470 --> 00:42:46,470
the generality of is

662
00:42:46,480 --> 00:42:49,010
approach for let's talk a little bit more about

663
00:42:51,040 --> 00:42:53,020
in computer science

664
00:42:53,030 --> 00:42:57,210
image processing computer for example image processing in who

665
00:42:57,220 --> 00:43:01,970
has work with or work from image processing related one

666
00:43:01,980 --> 00:43:06,420
a few people so i mean image processing is is one example of a few

667
00:43:07,610 --> 00:43:11,680
graphical models have had a strong impact as a matter of fact as far as

668
00:43:11,680 --> 00:43:12,630
i mean

669
00:43:12,700 --> 00:43:14,860
it's probably one of the

670
00:43:15,270 --> 00:43:18,200
areas market from fields were applied

671
00:43:19,540 --> 00:43:20,820
early eighties

672
00:43:20,840 --> 00:43:26,270
image processing basically you have digital images you know and you want to

673
00:43:26,280 --> 00:43:27,340
i mean

674
00:43:27,380 --> 00:43:29,320
performance some

675
00:43:29,360 --> 00:43:34,210
restoration of the image or some processing or something like you're doing denoising

676
00:43:35,150 --> 00:43:38,220
you want to keep learning the job well

677
00:43:39,310 --> 00:43:43,740
so again you can consider pixels of an image as

678
00:43:45,020 --> 00:43:47,010
entities in the system

679
00:43:47,020 --> 00:43:49,950
you can consider that neighboring pixels

680
00:43:49,960 --> 00:43:51,910
are interacting

681
00:43:51,980 --> 00:43:53,880
agents in the system

682
00:43:55,000 --> 00:43:58,900
the goal is to figure out what could be the overall

683
00:43:59,040 --> 00:44:00,850
the best solution

684
00:44:00,890 --> 00:44:04,130
like for example a denoised image given noisy

685
00:44:04,440 --> 00:44:06,930
we need to figure out

686
00:44:06,940 --> 00:44:11,370
the analysis of an energy function for that system for example and minimize the energy

687
00:44:12,200 --> 00:44:14,410
something in this line

688
00:44:17,330 --> 00:44:18,740
you have here so

689
00:44:18,780 --> 00:44:22,230
analogy and is called energy because

690
00:44:22,260 --> 00:44:24,160
everything started in physics

691
00:44:24,190 --> 00:44:27,400
the real ones that you really wanted to minimize was energy

692
00:44:28,320 --> 00:44:29,640
which is the physical

693
00:44:32,360 --> 00:44:37,440
should be understood that when we talk about energy minimisation image processing computer vision that's

694
00:44:38,280 --> 00:44:42,060
the energy that's just across from from the one line

695
00:44:42,070 --> 00:44:43,950
so many terms were

696
00:44:44,820 --> 00:44:46,090
brought from

697
00:44:46,100 --> 00:44:48,130
from physics because that's where

698
00:44:48,820 --> 00:44:50,520
i started work

699
00:44:50,590 --> 00:44:55,530
well there the case for example in computer vision i mean so

700
00:44:55,560 --> 00:45:01,480
how many people that work on computer vision related problems and some people

701
00:45:01,520 --> 00:45:02,660
so basically

702
00:45:02,680 --> 00:45:07,880
also like an image processing are working with him on this

703
00:45:07,890 --> 00:45:10,500
but in computer vision usually one

704
00:45:10,560 --> 00:45:11,470
the sum

705
00:45:11,480 --> 00:45:13,240
more type of high level

706
00:45:13,250 --> 00:45:15,680
image analysis like for example interpreting

707
00:45:15,690 --> 00:45:19,280
the content of visual scene or something

708
00:45:20,480 --> 00:45:24,980
so for example if you want to match objects you may want to

709
00:45:24,980 --> 00:45:28,690
match fingerprints for example we have to fingerprint

710
00:45:28,780 --> 00:45:31,720
one fingerprint and one that basis

711
00:45:31,780 --> 00:45:36,980
we want to match up the fingerprints to figure out whether this fingerprint is the

712
00:45:36,980 --> 00:45:38,530
same as these

713
00:45:39,610 --> 00:45:43,520
and you can extract features of the fingerprint but you need to ask some questions

714
00:45:43,520 --> 00:45:44,500
like well

715
00:45:44,600 --> 00:45:46,960
the fingerprint is

716
00:45:46,970 --> 00:45:48,720
made up of several parts

717
00:45:48,730 --> 00:45:50,740
right there are technical terms

718
00:45:50,820 --> 00:45:52,290
social order that

719
00:45:52,390 --> 00:45:54,940
and you know that some parts are close to each other

720
00:45:55,030 --> 00:45:58,560
well if i have some parts of the close to each other in one fingerprint

721
00:45:58,560 --> 00:46:01,510
they need to be close to each other and the other fingerprint as well

722
00:46:01,570 --> 00:46:05,030
so that when a match up i need to keep this consistency

723
00:46:07,610 --> 00:46:12,610
this can also be modeled as a graphical model because you also have this part

724
00:46:12,610 --> 00:46:17,390
there's little parts social whatever you have this constraints that

725
00:46:17,450 --> 00:46:18,640
things needs to

726
00:46:18,660 --> 00:46:20,820
match under some

727
00:46:20,830 --> 00:46:22,930
conditions to be created

728
00:46:23,150 --> 00:46:27,460
find things in our final goal is to find what's the overall

729
00:46:27,490 --> 00:46:29,450
matching the

730
00:46:29,460 --> 00:46:33,790
better according to some criterion or in form

731
00:46:34,990 --> 00:46:35,860
just some

732
00:46:35,860 --> 00:46:36,980
types of

733
00:46:37,230 --> 00:46:39,580
high-level example of

734
00:46:39,790 --> 00:46:43,530
so basically what graphical models

735
00:46:43,530 --> 00:46:49,410
corresponding to this value here correspond to feature which really does not separate well at

736
00:46:49,410 --> 00:46:51,240
all the two classes however

737
00:46:51,570 --> 00:46:52,730
taken together

738
00:46:52,740 --> 00:46:54,940
the two features have much better

739
00:46:54,950 --> 00:46:58,470
four separation that x one

740
00:46:58,470 --> 00:47:03,370
the figure the deeper about what could be the meaning of these two features

741
00:47:03,400 --> 00:47:07,950
we decided that only x one was really informative features

742
00:47:09,320 --> 00:47:11,730
this corresponds to the abundance

743
00:47:11,760 --> 00:47:14,110
of proteins area

744
00:47:14,120 --> 00:47:15,060
and so

745
00:47:15,070 --> 00:47:16,020
there are some

746
00:47:16,070 --> 00:47:18,560
people who have no more abundant

747
00:47:18,610 --> 00:47:21,010
protein and some other people

748
00:47:21,030 --> 00:47:23,360
whereas this position here

749
00:47:23,390 --> 00:47:26,530
doesn't really represents the abundance of

750
00:47:26,540 --> 00:47:31,120
ten is just valid just protein that's equally

751
00:47:31,140 --> 00:47:36,860
not present in all the patients of the population

752
00:47:36,910 --> 00:47:42,570
the only difference is that we observe here are just noise

753
00:47:42,580 --> 00:47:47,860
and it just so happens that there must be a systematic source of noise that

754
00:47:47,860 --> 00:47:49,270
makes it that

755
00:47:49,270 --> 00:47:52,060
on spectral simultaneously reason or

756
00:47:53,440 --> 00:47:59,370
in this neighborhood here even though we had performed some based on removal there was

757
00:47:59,370 --> 00:48:02,570
some residual error there was significant in

758
00:48:02,600 --> 00:48:04,520
that it was useful

759
00:48:04,530 --> 00:48:06,660
to add this feature x two

760
00:48:06,680 --> 00:48:08,650
that is in local estimation

761
00:48:08,660 --> 00:48:10,230
of the baseline here

762
00:48:10,230 --> 00:48:13,400
so i'm showing you actually it is a very very small piece of a very

763
00:48:16,600 --> 00:48:21,220
and so this is actually a close in the close neighborhood of this of the

764
00:48:24,270 --> 00:48:27,510
so from my point of view having understood that

765
00:48:27,520 --> 00:48:28,780
tracks two

766
00:48:28,800 --> 00:48:30,910
in not really irrelevant feature

767
00:48:30,940 --> 00:48:35,910
it is an indirect measure of some systematic error that should have been removing by

768
00:48:38,850 --> 00:48:42,020
so i'm showing you this is real that actually this was an example but this

769
00:48:42,020 --> 00:48:44,890
is the real data that we had

770
00:48:44,940 --> 00:48:48,860
OK so so this is still a problem can shows up in in the case

771
00:48:48,860 --> 00:48:50,180
of the ex or

772
00:48:50,190 --> 00:48:54,360
and we also have real data example in which we have situations like this

773
00:48:54,370 --> 00:48:59,730
in which in fact the the fact that we have separate clusters in this abrupt

774
00:48:59,730 --> 00:49:04,490
change you know where when she was still a separating other one

775
00:49:04,660 --> 00:49:08,890
and then all of a sudden for a a given value of another should change

776
00:49:08,890 --> 00:49:13,440
is the other way around very often this is just a symptom of something that

777
00:49:13,650 --> 00:49:17,860
that when the wrong for example there has been

778
00:49:17,950 --> 00:49:19,820
shifting operator or

779
00:49:19,820 --> 00:49:25,400
or something that happened to to the process there was a randomisation of the samples

780
00:49:25,600 --> 00:49:30,190
in we're seeing some artifact here

781
00:49:31,300 --> 00:49:35,470
interpreted in terms of the causal graph this is what happens

782
00:49:35,480 --> 00:49:40,520
why is the target in that case this would be or disease

783
00:49:40,570 --> 00:49:43,220
and x y is the abundance

784
00:49:43,870 --> 00:49:45,530
some you know

785
00:49:45,570 --> 00:49:47,640
components in

786
00:49:47,720 --> 00:49:53,560
blood for example ban supporting this disease causes some changes

787
00:49:53,560 --> 00:49:55,950
in the violence of protein

788
00:49:55,970 --> 00:49:57,440
but simultaneously

789
00:49:57,450 --> 00:49:59,280
they some

790
00:49:59,300 --> 00:50:00,740
some noise

791
00:50:00,760 --> 00:50:03,180
that also feeds into x y

792
00:50:03,200 --> 00:50:06,060
some bad but variable

793
00:50:06,070 --> 00:50:09,320
and so x one is the results of mixing

794
00:50:09,370 --> 00:50:12,100
these two elements here

795
00:50:12,110 --> 00:50:15,320
so knowing x two is actually useful

796
00:50:15,330 --> 00:50:17,310
two making better prediction y

797
00:50:17,370 --> 00:50:19,470
then not knowing it

798
00:50:19,480 --> 00:50:22,370
but this doesn't mean that x two

799
00:50:22,440 --> 00:50:24,930
tells us something about you know

800
00:50:24,940 --> 00:50:28,600
how the how wide is related to x one

801
00:50:28,620 --> 00:50:32,770
so for example in the case of you know of measuring instrument if i change

802
00:50:32,770 --> 00:50:37,400
instrument if i would have now this which is calibrated in a different way

803
00:50:37,400 --> 00:50:38,480
x one

804
00:50:38,570 --> 00:50:44,200
x two will become completely useless variable whereas in the x y if it has

805
00:50:44,200 --> 00:50:47,100
the reality in the system that we're interested in

806
00:50:47,140 --> 00:50:50,930
it is the one that is relevant or important

807
00:50:50,980 --> 00:50:58,330
what happens is that the reason why it's too becomes a relevant is that

808
00:50:58,350 --> 00:51:03,490
for a particular value of x y then there's is the dependency which is induced

809
00:51:03,490 --> 00:51:04,850
by x one

810
00:51:04,860 --> 00:51:06,820
between x two and y

811
00:51:07,700 --> 00:51:09,730
x two is independent of y

812
00:51:09,730 --> 00:51:15,990
but given values of x y it becomes apparent reason being that x two

813
00:51:16,020 --> 00:51:18,830
because information into two x one

814
00:51:18,850 --> 00:51:23,280
it's the same thing happens here in the case of the chessboard problem for any

815
00:51:23,280 --> 00:51:27,120
particular value of x y and we see that there is a separation

816
00:51:27,220 --> 00:51:28,870
on the x two axis

817
00:51:28,900 --> 00:51:30,900
between the two categories

818
00:51:30,930 --> 00:51:34,070
so there's induced dependency

819
00:51:34,080 --> 00:51:41,150
in reality is not really x two that causes x y it's probably more complicated

820
00:51:41,150 --> 00:51:44,200
than that there may be a common cause

821
00:51:44,660 --> 00:51:51,440
which is your systematic noise there is no that causes changing the baseline and resulting

822
00:51:51,440 --> 00:51:54,520
in some observed value of the spectrum

823
00:51:54,570 --> 00:51:59,200
that we call x y some of the values that we call x two

824
00:51:59,770 --> 00:52:04,070
practically we can't differentiate between these two graphs just look at the data

825
00:52:04,110 --> 00:52:07,980
but it's important to keep that in mind in order to interpret but we are

826
00:52:07,980 --> 00:52:11,030
looking at

827
00:52:11,080 --> 00:52:16,140
it's important to understand that as soon as we have measurements

828
00:52:16,150 --> 00:52:20,140
measurements always consequences

829
00:52:20,160 --> 00:52:24,080
of the phenomenon that we want to observe

830
00:52:24,100 --> 00:52:27,650
and we are not immune to measurement errors

831
00:52:27,680 --> 00:52:30,190
and we need to take into account

832
00:52:30,220 --> 00:52:35,120
when we do feature selection

833
00:52:35,140 --> 00:52:38,030
so i justify somehow

834
00:52:38,060 --> 00:52:45,970
the discovery of causal relationships between x y x i and y

835
00:52:46,020 --> 00:52:49,800
so in a sense if you ignore them you might make some bad decisions about

836
00:52:49,800 --> 00:52:51,680
good morning

837
00:52:51,730 --> 00:52:55,090
my name shown back off from the university of manchester

838
00:52:55,090 --> 00:53:00,010
so like to thank him for that very interesting introduction made me think about a

839
00:53:00,010 --> 00:53:02,710
few things i think it's always interesting to

840
00:53:02,760 --> 00:53:07,530
so have a background in the context of the work they we're doing is introduced

841
00:53:08,250 --> 00:53:13,890
i'd like to give you a kind overview and introduction to the language now known

842
00:53:13,890 --> 00:53:17,640
like jim this is probably a lot more material in my slides that i'll be

843
00:53:17,640 --> 00:53:22,790
able to present at the time i have available but the information is there that

844
00:53:22,920 --> 00:53:26,530
if you want to look at the slides later on this there some resources for

845
00:53:26,530 --> 00:53:29,150
you to look at

846
00:53:29,750 --> 00:53:33,060
so i'm going to talk about some of the details of the

847
00:53:33,110 --> 00:53:34,100
if a

848
00:53:34,100 --> 00:53:38,400
and some of the motivation kind of why is the way it is and how

849
00:53:38,420 --> 00:53:40,250
how the language is described

850
00:53:42,030 --> 00:53:46,830
as a a brief this kind of overview introduction of an ontology language is a

851
00:53:46,830 --> 00:53:52,290
language for describing all models describing the way that we think the world fit together

852
00:53:52,310 --> 00:53:58,240
and it provides us with a very rich collection of operators for describing concept descriptions

853
00:53:58,250 --> 00:54:02,750
and i'll say a little more about what i mean by concept descriptions later on

854
00:54:02,940 --> 00:54:07,690
it's also w three c standards and i think this is very important so standardisation

855
00:54:07,690 --> 00:54:12,860
is crucial for this kind of work if we're going to build applications and tools

856
00:54:13,050 --> 00:54:17,800
interoperation they can share information so i can build an application that i can present

857
00:54:17,800 --> 00:54:23,530
you with some data the application produces you can read that and understand using standard

858
00:54:23,570 --> 00:54:28,520
is very important so i think that again with the kind of standardisation stack organisations

859
00:54:28,520 --> 00:54:32,110
like the w three c provide is crucial

860
00:54:32,520 --> 00:54:37,300
and i was also been designed to be compatible with existing web standards languages like

861
00:54:37,300 --> 00:54:43,470
RDF and XML we're using to describe things in the web context

862
00:54:43,470 --> 00:54:49,050
so genes already talked about the semantic web vision so i want say much here

863
00:54:49,050 --> 00:54:54,910
but the key thing here is that we're aiming towards resources that are described

864
00:54:56,190 --> 00:55:01,490
annotations that machine readable and machine understandable to a certain extent

865
00:55:01,490 --> 00:55:07,020
OK so i'm going to achieve this by the using semantic markup system annotations metadata

866
00:55:07,020 --> 00:55:13,170
annotations that describe content function of web resources so what what's in our web resources

867
00:55:13,200 --> 00:55:18,330
what they do in the case of services for example

868
00:55:18,390 --> 00:55:22,610
so what's what's the problem well i'm sure we all understand what this problem is

869
00:55:22,610 --> 00:55:26,490
i mean this is this is kind of this is nothing new now that a

870
00:55:26,490 --> 00:55:33,010
typical web page has some markup information OK have some HTML perhaps some stylesheet information

871
00:55:33,010 --> 00:55:37,390
and this tells us how to render the page essentially so what we're doing is

872
00:55:37,390 --> 00:55:41,730
we're making use of machines about rises to help to present information in a nice

873
00:55:41,730 --> 00:55:47,740
way i have a web page here and all the presentational information the fonts colors

874
00:55:47,740 --> 00:55:52,420
position of the things on the page is all contained within that markup

875
00:55:52,590 --> 00:55:56,990
the semantic content of this page is accessible to me as a human being i

876
00:55:56,990 --> 00:56:00,020
can read this page and i know that this is the page of the w

877
00:56:00,020 --> 00:56:03,390
three c has some information about the workshop

878
00:56:03,920 --> 00:56:09,020
tells me some useful something about mobile web initiative but the content of this page

879
00:56:09,020 --> 00:56:11,960
is not particularly accessible to machines

880
00:56:11,960 --> 00:56:16,060
the it has natural language OK so if i really wanted to understand what this

881
00:56:16,060 --> 00:56:20,920
page is about i may have to use and sophisticated natural language techniques we some

882
00:56:20,920 --> 00:56:23,010
more about that later on today

883
00:56:23,050 --> 00:56:25,800
but if i really want to kind of get into the information here it's very

884
00:56:25,800 --> 00:56:30,240
hard for me to describe this and way the machine on the stand

885
00:56:30,260 --> 00:56:34,590
so the the idea now is to make a web resources more accessible to automated

886
00:56:34,590 --> 00:56:38,390
processes extend existing market that we have

887
00:56:38,430 --> 00:56:44,730
with the semantic markup so metadata annotations describing the content of the function of our

888
00:56:46,040 --> 00:56:47,590
and in order to do this

889
00:56:47,610 --> 00:56:52,540
we feel we need we need to use ontologies to provide vocabulary for annotations

890
00:56:52,550 --> 00:56:57,490
so the vocab the ontologies provide us with a collection of terms we can use

891
00:56:57,490 --> 00:57:00,180
to populate this metadata

892
00:57:00,200 --> 00:57:01,360
and in particular

893
00:57:01,400 --> 00:57:05,680
we want a rule system we want systems that kind of open to that in

894
00:57:05,680 --> 00:57:09,910
the way that we can combine existing terms we can form new terms and we

895
00:57:09,910 --> 00:57:15,510
have some formal notions underpinning the way in which these vocabularies are used and the

896
00:57:15,510 --> 00:57:18,740
way in which we combined terms and i will go on to say more about

897
00:57:18,740 --> 00:57:22,950
what i mean about this kind of formal notion of the combination terms

898
00:57:22,980 --> 00:57:28,660
so a prerequisite here some kind of standardisation some standard language so we need to

899
00:57:28,660 --> 00:57:34,110
agree some common syntax before we can share semantics some common representations that we can

900
00:57:34,110 --> 00:57:35,610
use and share

901
00:57:35,620 --> 00:57:36,930
and this

902
00:57:36,940 --> 00:57:42,940
it will be then based on some some underlying language is like a city units

903
00:57:42,970 --> 00:57:46,940
so the the technologies that we we need for the semantic web

904
00:57:47,180 --> 00:57:49,100
things like metadata

905
00:57:49,110 --> 00:57:50,660
OK so metadata

906
00:57:50,670 --> 00:57:55,450
allows us to describe resources with descriptions of their content

907
00:57:56,420 --> 00:58:01,170
it it's no good as providing this metadata OK unless everyone is speaking the same

908
00:58:01,170 --> 00:58:05,490
language we need we need to have some common ground meat as some common language

909
00:58:05,510 --> 00:58:09,670
that we used to represent this metadata and these annotations on our resources

910
00:58:09,680 --> 00:58:13,320
and we can achieve this through the use of terminologies

911
00:58:13,370 --> 00:58:17,920
so the terminology provides some shared common vocabulary the domain

912
00:58:17,930 --> 00:58:21,500
OK so so we know that the terms that we are all using the same

913
00:58:21,790 --> 00:58:24,470
the same collection of terms in this kind of restricts their

914
00:58:24,930 --> 00:58:27,430
the problems with

915
00:58:27,440 --> 00:58:30,950
with people using terms that we don't necessarily understand or know

916
00:58:30,970 --> 00:58:35,480
but using a shared terminology still doesn't take it all the way that because there

917
00:58:35,480 --> 00:58:37,010
are still problems with

918
00:58:37,090 --> 00:58:41,370
with terms that have multiple meanings so we may have synonyms we may have word

919
00:58:41,400 --> 00:58:46,730
has possibly different meanings in different contexts so it's important that we have

920
00:58:46,740 --> 00:58:51,840
everybody meaning the same thing for sharing context terminologies and we can achieve this through

921
00:58:51,840 --> 00:58:56,070
the use of ontology ontologies which give us some kind of notion of the meaning

922
00:58:56,070 --> 00:59:00,740
of terms because described some of the underlying semantics and help us in doing this

923
00:59:01,090 --> 00:59:05,360
they share a common understanding about domain

924
00:59:05,410 --> 00:59:09,820
so to build the semantic web we need to go through three processes

925
00:59:09,840 --> 00:59:15,180
essentially we need to to annotate things we need to annotate metadata resources cesar marking

926
00:59:15,180 --> 00:59:18,260
up describing what resources are

927
00:59:18,260 --> 00:59:19,340
the next speaker had

928
00:59:20,000 --> 00:59:21,040
by him to the podium

929
00:59:22,650 --> 00:59:26,360
so i used to be before in the state department psychology department

930
00:59:28,150 --> 00:59:30,940
hand there is always a joke which is that a few

931
00:59:32,140 --> 00:59:36,860
look to people interested in perception they were very perceptive people people study memory that every good memories

932
00:59:38,690 --> 00:59:40,170
end people who are

933
00:59:40,840 --> 00:59:44,670
studied rational thinking didn't actually very rational and so on so people tend to say

934
00:59:44,670 --> 00:59:47,910
things they were good at and think that holds in statistics and here's a counter

935
00:59:47,910 --> 00:59:51,020
example so here's one hour world experts in dynamical systems

936
00:59:51,660 --> 00:59:54,380
hand i think you'll agree that might pretty dynamical individual

937
00:59:56,200 --> 00:59:58,700
weather is stationary i don't know probably not

938
00:59:59,420 --> 01:00:00,240
certainly nonlinear

939
01:00:01,430 --> 01:00:04,330
what is predictable i let others make that call

940
01:00:06,170 --> 01:00:10,450
anyway were delighted have might give the second is a lecture on basic foundations

941
01:00:11,310 --> 01:00:14,260
again this will be an hour and a half hours fifteen minutes slot

942
01:00:14,910 --> 01:00:17,490
questions afterwards and then we'll have a break for coffee

943
01:00:19,230 --> 01:00:19,880
okay well

944
01:00:20,400 --> 01:00:22,050
thank you michael for the introduction

945
01:00:23,100 --> 01:00:25,060
hand thank you to the organizing

946
01:00:25,690 --> 01:00:27,220
committee for the invitation

947
01:00:28,030 --> 01:00:33,290
and hello kyoto hello is the twenty twelve but be been looking forward to this meeting for a few years

948
01:00:34,550 --> 01:00:35,750
i is everybody comfortable

949
01:00:38,640 --> 01:00:39,700
is everybody warming of

950
01:00:43,170 --> 01:00:48,290
so i was invited to give one foundation lectures and despite the invitation and was

951
01:00:48,290 --> 01:00:53,060
asked to give a sort of valencia old style tutorial overview which is what i

952
01:00:53,940 --> 01:00:54,640
put together today

953
01:00:55,930 --> 01:00:59,920
and a tutorial overview should start with these some allusion to where things began

954
01:01:00,520 --> 01:01:02,560
i'm talking about state-space modeling

955
01:01:04,510 --> 01:01:08,230
basically this is the fiftieth anniversary of two key papers

956
01:01:08,670 --> 01:01:09,080
i'm sorry

957
01:01:10,110 --> 01:01:11,530
a trigger-happy here

958
01:01:12,500 --> 01:01:13,450
two key papers

959
01:01:15,550 --> 01:01:19,310
the beginning thee nineteen sixties by geoff harrison really common

960
01:01:19,930 --> 01:01:21,680
coming from very different perspectives

961
01:01:23,410 --> 01:01:29,630
in the one case very subjective bayesian modeling in commercial environments time series problems with time

962
01:01:30,180 --> 01:01:33,100
adapting to change in time is this is the essential

963
01:01:33,650 --> 01:01:34,840
forecasting accuracy

964
01:01:35,420 --> 01:01:36,160
and in the other case

965
01:01:36,650 --> 01:01:38,110
very non bayesian

966
01:01:39,320 --> 01:01:43,480
engineering perspective in control theory and control systems but utilizing machinery

967
01:01:44,090 --> 01:01:45,480
bayesian state space modeling

968
01:01:46,470 --> 01:01:49,590
there are a lot of other people other things that were happening around the same

969
01:01:49,590 --> 01:01:51,750
time the all ingredient and all hardware

970
01:01:52,250 --> 01:01:55,200
these are the world of dynamic modelling in

971
01:01:55,790 --> 01:02:00,830
time series spatial systems and other kinds of contexts is as evolved from

972
01:02:01,840 --> 01:02:04,980
but these were really what i identifies the essential and

973
01:02:05,510 --> 01:02:06,910
people who kicked it off

974
01:02:07,530 --> 01:02:08,860
so don't state space models

975
01:02:09,610 --> 01:02:13,480
and what will be looking at some pictures from examples from business and finance

976
01:02:14,910 --> 01:02:17,040
it's it's i think dennis lillian

977
01:02:17,550 --> 01:02:18,960
late nineteen eighties

978
01:02:19,850 --> 01:02:23,770
remarked that the state space modeling it has become about point really

979
01:02:25,380 --> 01:02:26,920
most important practical

980
01:02:27,580 --> 01:02:30,680
success for bayesian thinking this was pre-empts him see of course

981
01:02:31,600 --> 01:02:32,300
where around

982
01:02:33,400 --> 01:02:35,070
you know we were still doing calculations

983
01:02:35,840 --> 01:02:36,930
on the backs of envelopes

984
01:02:38,900 --> 01:02:39,840
business and finance

985
01:02:40,320 --> 01:02:44,400
i will be talking about the physical sciences will be talking about biological sciences

986
01:02:45,300 --> 01:02:46,200
will be talking about

987
01:02:48,270 --> 01:02:48,800
a little bit

988
01:02:49,210 --> 01:02:53,550
at least allusions to more recent and current kinds applications

989
01:02:54,040 --> 01:02:56,950
in dynamic network modeling and computer modeling

990
01:02:58,430 --> 01:03:00,540
these good ol fifty year old ideas

991
01:03:00,940 --> 01:03:02,680
and methods that are based on those ideas

992
01:03:03,280 --> 01:03:05,960
really driving creative challenging applications

993
01:03:08,490 --> 01:03:13,140
ah some of my slides will have at the top of the time foundation is

994
01:03:13,140 --> 01:03:15,550
a foundation lecture really talking about concepts

995
01:03:16,120 --> 01:03:17,780
that i regard as foundational

996
01:03:18,230 --> 01:03:21,170
and that of foundational to to to this particular field

997
01:03:21,930 --> 01:03:22,270
the keep

998
01:03:22,700 --> 01:03:24,450
concept is times the covariance

999
01:03:25,270 --> 01:03:27,080
that stuff changes in time

1000
01:03:27,730 --> 01:03:30,020
anne due to ignore them at your peril

1001
01:03:30,660 --> 01:03:31,920
so here's a stylized model

1002
01:03:32,970 --> 01:03:34,820
i do apologize for this is just like

1003
01:03:36,030 --> 01:03:38,850
here's a stylized model where we have some data in time

1004
01:03:40,300 --> 01:03:43,920
possibly with some regression where theta here represents a regression parameter

1005
01:03:46,440 --> 01:03:50,230
andy parameter is changing in time in some way this is a mnemonic for more

1006
01:03:50,230 --> 01:03:52,980
elaborate models that you might use and people to use

1007
01:03:54,430 --> 01:03:58,020
and if you have such a circumstance and ignore the the time variation in the

1008
01:03:58,020 --> 01:04:02,030
parameters then all the variation you see about the regression gets lumped into the air

1009
01:04:02,450 --> 01:04:04,210
so you inflate your errors if

1010
01:04:04,840 --> 01:04:06,360
unpredictable pieces the model

1011
01:04:07,350 --> 01:04:08,750
you degrade forecasts

1012
01:04:10,330 --> 01:04:14,320
realize forecast uncertainties that just bigger and bigger than they should be

1013
01:04:15,500 --> 01:04:19,580
allowing for change in very simple ways of partitioning variation

1014
01:04:20,050 --> 01:04:25,430
by recognizing times the covariance is really the fundamental concept the foundation a state space model

1015
01:04:27,090 --> 01:04:30,500
so as an example and this is a textbook example that goes back a number of years to

1016
01:04:31,220 --> 01:04:32,270
only a textbook that's

1017
01:04:32,910 --> 01:04:36,100
it to time-series sales and the predicted market

1018
01:04:37,090 --> 01:04:39,990
that share similar patterns over time and if you simply looking

1019
01:04:40,630 --> 01:04:41,720
why against export

1020
01:04:42,230 --> 01:04:44,020
you be tempted to fit a regression

1021
01:04:44,980 --> 01:04:49,420
andy because a few then bring in the time covariate you see a slightly different picture repeatedly

1022
01:04:51,870 --> 01:04:54,390
are these sales data and you see an increasing

1023
01:04:55,520 --> 01:04:57,940
parameter vector regression relationship

1024
01:04:58,450 --> 01:04:59,310
if you ignore it

1025
01:05:00,040 --> 01:05:03,720
then you're tracking one step forecasts along here you're doing a very poor job in

1026
01:05:03,720 --> 01:05:07,220
forecasting your residual variances lead to inflated forecasts variances

1027
01:05:07,730 --> 01:05:11,410
whereas by comparison if you recognise it and even the very simple things

1028
01:05:12,310 --> 01:05:15,830
then the model will adapt and track the time-varying coefficient

1029
01:05:16,440 --> 01:05:21,560
improve forecasts reduced forecasts uncertainties and d and so you went out on both counts

1030
01:05:22,730 --> 01:05:24,000
so times the covariance

1031
01:05:25,140 --> 01:05:30,050
always worth considering times the covariate shift times it all in the context the problem

1032
01:05:30,760 --> 01:05:31,860
for these kinds reasons

1033
01:05:33,930 --> 01:05:37,940
the second foundation and an example leads into this is

1034
01:05:38,550 --> 01:05:41,740
very naturally in time series one is involved in sequential analysis

1035
01:05:42,350 --> 01:05:46,080
u model sequentially in time you look forward in time to think about how the

1036
01:05:46,080 --> 01:05:48,650
process that you are trying to understand is evolving

1037
01:05:49,410 --> 01:05:50,570
state space models

1038
01:05:52,360 --> 01:05:54,360
this is a linear guassian so the framework

1039
01:05:54,920 --> 01:05:55,720
to begin of course

1040
01:05:56,530 --> 01:05:57,360
a very natural

1041
01:05:58,630 --> 01:06:02,290
very naturally looked at in in a sequential format so here we have a signal and noise

1042
01:06:03,240 --> 01:06:08,780
the signal is a dynamic regression where the regression vector all state vector it's a state space model

1043
01:06:09,270 --> 01:06:11,500
undergoes a markovian evolution through time

1044
01:06:11,500 --> 01:06:13,240
the message

1045
01:06:13,250 --> 01:06:14,940
even though

1046
01:06:14,950 --> 01:06:16,580
which is

1047
01:06:16,590 --> 01:06:17,870
i don't think

1048
01:06:17,920 --> 01:06:21,510
do something but i don't think you know

1049
01:06:21,570 --> 01:06:23,170
i would tend to these

1050
01:06:23,180 --> 01:06:26,600
i mean when i was

1051
01:06:26,610 --> 01:06:27,420
it was

1052
01:06:27,440 --> 01:06:31,370
that's just saying the sentence i love

1053
01:06:31,380 --> 01:06:33,120
it connects everything

1054
01:06:35,170 --> 01:06:37,880
you know i

1055
01:06:41,100 --> 01:06:42,550
the good

1056
01:06:42,890 --> 01:06:44,450
q and

1057
01:06:44,500 --> 01:06:47,280
we can not

1058
01:06:47,300 --> 01:06:49,530
all the

1059
01:06:49,550 --> 01:06:50,950
what that

1060
01:06:52,890 --> 01:06:56,200
i don't think the message is

1061
01:06:56,230 --> 01:07:00,070
forget it be useful for the than

1062
01:07:00,120 --> 01:07:01,760
forget the old

1063
01:07:01,780 --> 01:07:05,490
because it was the only people

1064
01:07:05,510 --> 01:07:08,790
i don't think so

1065
01:07:08,930 --> 01:07:11,030
it's not

1066
01:07:11,050 --> 01:07:12,170
i think

1067
01:07:12,190 --> 01:07:14,200
more we should

1068
01:07:18,150 --> 01:07:20,710
we believe in that fine

1069
01:07:20,730 --> 01:07:24,770
i would like to thank you this is your

1070
01:07:24,780 --> 01:07:27,310
don't becomes part of

1071
01:07:27,320 --> 01:07:33,310
and it's the following approach by which i mean this is you know in the

1072
01:07:33,360 --> 01:07:36,010
you know the old yugoslavia

1073
01:07:36,020 --> 01:07:40,420
we get some are probably unfortunately not really

1074
01:07:40,520 --> 01:07:42,270
we will

1075
01:07:42,340 --> 01:07:43,320
but the community

1076
01:07:44,410 --> 01:07:49,190
well there fact that the best thing would be useful

1077
01:07:49,320 --> 01:07:52,040
streamline education and the

1078
01:07:52,070 --> 01:07:55,360
post something called

1079
01:07:57,360 --> 01:08:03,970
you get the point i was listening to a few people all education can

1080
01:08:04,030 --> 01:08:11,410
so going to be of some use to someone not interest to to learn how

1081
01:08:11,410 --> 01:08:12,680
maybe it was a

1082
01:08:12,700 --> 01:08:14,200
as you

1083
01:08:14,250 --> 01:08:17,160
both of which is going cause

1084
01:08:17,160 --> 01:08:19,710
it is important to note that the

1085
01:08:19,720 --> 01:08:23,680
now is this kind of you

1086
01:08:25,050 --> 01:08:27,770
the social usefulness

1087
01:08:27,790 --> 01:08:30,430
everything but we

1088
01:08:30,440 --> 01:08:34,070
the first element is that there

1089
01:08:34,090 --> 01:08:36,470
so i remember

1090
01:08:36,550 --> 01:08:39,390
they all get discovered by

1091
01:08:40,870 --> 01:08:46,530
or or they may just need to put it in the trunk

1092
01:08:46,550 --> 01:08:48,430
he and the other one

1093
01:08:50,430 --> 01:08:52,430
it comes from

1094
01:08:52,480 --> 01:08:55,820
OK we can construct the launch

1095
01:09:00,110 --> 01:09:02,830
one of those to me like tree

1096
01:09:03,180 --> 01:09:07,400
language which was just a a few months

1097
01:09:07,420 --> 01:09:08,710
wasn't there

1098
01:09:11,370 --> 01:09:16,970
four is these but by

1099
01:09:17,020 --> 01:09:17,980
you know

1100
01:09:20,270 --> 01:09:26,220
eight or nine to the environment in the problem

1101
01:09:26,250 --> 01:09:30,480
the space over which was

1102
01:09:31,460 --> 01:09:36,360
let's say for language which was the second and so on and so on so

1103
01:09:36,450 --> 01:09:38,630
more than we should

1104
01:09:44,610 --> 01:09:46,120
i think

1105
01:09:46,140 --> 01:09:50,000
to be nice to be in the of you use

1106
01:09:51,520 --> 01:09:55,520
the function of the brain it's let's stop speculating

1107
01:09:55,540 --> 01:09:59,800
let's focus on the economic problems these into

1108
01:10:00,590 --> 01:10:03,240
this is effectively from

1109
01:10:03,300 --> 01:10:04,510
o thing

1110
01:10:04,530 --> 01:10:07,410
don't blame me for his emergency

1111
01:10:07,450 --> 01:10:10,180
state route six you know

1112
01:10:11,340 --> 01:10:14,940
the corresponding stopped it was i think about and

1113
01:10:16,160 --> 01:10:19,770
but do we even know where you

1114
01:10:22,060 --> 01:10:24,420
what's going on the menu

1115
01:10:26,830 --> 01:10:29,120
on the one hand we have

1116
01:10:29,130 --> 01:10:33,830
people keep things think that goes on

1117
01:10:33,900 --> 01:10:42,590
we need to learn a stochastic changes he said you are all much they they

1118
01:10:42,730 --> 01:10:45,020
say that the solution goes

1119
01:10:45,050 --> 01:10:46,820
then we have

1120
01:10:46,840 --> 01:10:49,230
people who see brain

1121
01:10:49,280 --> 01:10:51,010
it time

1122
01:10:51,410 --> 01:10:58,620
a name for new if let's say you say the information was that has to

1123
01:10:59,520 --> 01:11:00,590
i do not going to

1124
01:11:00,620 --> 01:11:04,680
now why these but i think it

1125
01:11:04,760 --> 01:11:07,840
pros cons is actually to

1126
01:11:10,220 --> 01:11:16,030
most of our going all i think we

1127
01:11:18,730 --> 01:11:19,310
i think

1128
01:11:19,810 --> 01:11:23,450
going to make you know some kind of

1129
01:11:23,500 --> 01:11:25,480
basic orientation

1130
01:11:25,490 --> 01:11:29,840
cognitive coordinates which is why i think

1131
01:11:29,860 --> 01:11:30,570
two o

1132
01:11:30,590 --> 01:11:31,960
things are

1133
01:11:31,970 --> 01:11:34,200
getting what

1134
01:11:34,220 --> 01:11:35,510
we see

1135
01:11:35,530 --> 01:11:37,290
local the making

1136
01:11:37,920 --> 01:11:42,070
conspiracy theories are in the bottom and you can

1137
01:11:42,330 --> 01:11:43,900
what's going on

1138
01:11:44,640 --> 01:11:45,680
you see

1139
01:11:48,490 --> 01:11:51,840
well of what i will be

1140
01:11:51,860 --> 01:11:54,300
i don't recall which will be

1141
01:11:57,380 --> 01:12:02,330
the which is flow

1142
01:12:02,340 --> 01:12:04,570
is the dominant view

1143
01:12:06,310 --> 01:12:10,200
even if they are not christians

1144
01:12:10,210 --> 01:12:15,000
could be flavor a newspaper which is not forget

1145
01:12:15,090 --> 01:12:17,240
you know it's

1146
01:12:17,260 --> 01:12:25,830
it's actually ontology for which is that you just like to let you know that

1147
01:12:26,720 --> 01:12:29,700
they don't go don't

1148
01:12:29,710 --> 01:12:36,420
i think that's all you have to remove the intellectual so

1149
01:12:36,430 --> 01:12:39,200
this think

1150
01:12:39,520 --> 01:12:41,110
the game

1151
01:12:41,150 --> 01:12:43,950
the for

1152
01:12:44,000 --> 01:12:51,970
we should be aware of the opposition and he was between being made having

1153
01:12:53,610 --> 01:12:54,880
so far

1154
01:12:54,930 --> 01:12:57,180
i think there is any

1155
01:12:57,230 --> 01:12:58,230
so we have

1156
01:12:58,240 --> 01:13:00,470
and the lack of

1157
01:13:00,480 --> 01:13:01,440
i mean

1158
01:13:01,440 --> 01:13:08,520
it's very difficult to help people out you thought his

1159
01:13:08,620 --> 01:13:13,410
no gold nineteen ninety nine percent of us he wants

1160
01:13:13,720 --> 01:13:15,870
fukui fukui

1161
01:13:16,040 --> 01:13:19,410
basically he is

1162
01:13:19,430 --> 01:13:20,500
of course

1163
01:13:20,880 --> 01:13:22,690
be on the

1164
01:13:23,230 --> 01:13:25,660
there is a

1165
01:13:28,300 --> 01:13:30,270
if you feel that

1166
01:13:30,280 --> 01:13:33,060
we found the end

1167
01:13:33,060 --> 01:13:34,760
what frequency

1168
01:13:34,780 --> 01:13:37,610
in the in the document and waited

1169
01:13:37,620 --> 01:13:42,280
in the way by the the frequency of different words in the in the whole

1170
01:13:42,310 --> 01:13:47,210
database you don't want to work that is in every every document to be

1171
01:13:47,230 --> 01:13:49,220
the important it would be

1172
01:13:49,240 --> 01:13:52,520
so it's weighted this week

1173
01:13:52,540 --> 01:13:54,740
OK so in this representation

1174
01:13:55,740 --> 01:13:58,560
this sentence the boat in the sea

1175
01:13:58,570 --> 01:14:00,380
this ship in the ocean

1176
01:14:01,310 --> 01:14:03,080
would be considered as different

1177
01:14:03,090 --> 01:14:04,510
because they don't share

1178
01:14:04,520 --> 01:14:07,800
the important words

1179
01:14:07,810 --> 01:14:10,340
why and

1180
01:14:10,360 --> 01:14:15,570
representation should serve has two sentence such as surfing a wave of

1181
01:14:15,590 --> 01:14:19,250
and also to sort things internet which we human no

1182
01:14:19,300 --> 01:14:23,700
are not really related in this presentation we will have

1183
01:14:23,850 --> 01:14:30,270
kind of similarity since they share the this towards this the world surfing is is

1184
01:14:30,270 --> 01:14:33,750
is shared between the two sentences

1185
01:14:34,490 --> 01:14:38,520
this is one of the drawbacks of each of these

1186
01:14:40,860 --> 01:14:47,150
so the problem of text representation is that we looking for a representation of of

1187
01:14:47,180 --> 01:14:48,920
documents p of d

1188
01:14:50,070 --> 01:14:53,720
the money in the mapping phi takes into account the knowledge

1189
01:14:53,730 --> 01:14:55,860
about the links between words

1190
01:14:55,870 --> 01:14:58,540
so for example we human we know

1191
01:14:58,570 --> 01:15:00,580
that's both and sheep in fact

1192
01:15:00,590 --> 01:15:05,260
and the same thing so how how to

1193
01:15:06,870 --> 01:15:16,160
take this knowledge and and put it into into our representation of documents and the

1194
01:15:16,160 --> 01:15:21,820
idea is to gain this knowledge from the huge amount of very valuable documents in

1195
01:15:21,820 --> 01:15:23,210
digital format

1196
01:15:23,230 --> 01:15:24,730
which we have one

1197
01:15:24,740 --> 01:15:28,510
really which is for example into internet

1198
01:15:31,720 --> 01:15:38,720
there have been several probabilistic approaches for for this problem of text representation

1199
01:15:39,260 --> 01:15:44,660
they are trying to to model

1200
01:15:44,680 --> 01:15:48,730
the links between words and documents

1201
01:15:48,840 --> 01:15:51,810
among this one i'm going here to two

1202
01:15:51,820 --> 01:15:53,810
talk about tree

1203
01:15:54,050 --> 01:15:57,000
the probability is probabilistic

1204
01:15:57,050 --> 01:15:59,260
latent semantic analysis

1205
01:15:59,280 --> 01:16:01,620
latent dirichlet allocation

1206
01:16:02,840 --> 01:16:06,980
one that i propose which was the theme topic mixture model

1207
01:16:06,980 --> 01:16:13,110
this achievement of having in common their main assumption

1208
01:16:13,150 --> 01:16:16,460
which is that the distribution of words

1209
01:16:16,480 --> 01:16:18,140
in the document

1210
01:16:18,620 --> 01:16:24,030
is independent of this particular document if i have latent variable

1211
01:16:24,220 --> 01:16:28,790
so which is called usually topic

1212
01:16:28,890 --> 01:16:31,510
which partition the space

1213
01:16:31,530 --> 01:16:32,980
of the words into

1214
01:16:33,700 --> 01:16:35,270
to get objects have

1215
01:16:35,290 --> 01:16:38,060
OK topics and in fact i think that the

1216
01:16:38,070 --> 01:16:43,140
i will assume that the words in a document are generated but they this

1217
01:16:43,150 --> 01:16:47,940
by this topics belong to one of this topic

1218
01:16:48,520 --> 01:16:50,670
so that that's the main assumption of

1219
01:16:50,670 --> 01:16:51,950
this stream mothers

1220
01:16:51,960 --> 01:16:54,270
which can be

1221
01:16:54,300 --> 01:16:58,670
really we write and as as an equation so as i said

1222
01:16:58,680 --> 01:17:02,070
the main assumption is that the probability of words

1223
01:17:03,340 --> 01:17:06,190
the document

1224
01:17:06,230 --> 01:17:08,540
can be

1225
01:17:08,560 --> 01:17:13,990
can be seen as a as a mixture over the topics

1226
01:17:14,010 --> 01:17:15,970
of the probability of the word

1227
01:17:15,970 --> 01:17:17,510
given the topic

1228
01:17:17,530 --> 01:17:21,570
so here you see that we have

1229
01:17:21,580 --> 01:17:27,280
w w m which is a random variable representing the presence or the absence of

1230
01:17:27,280 --> 01:17:28,710
the word

1231
01:17:28,720 --> 01:17:30,760
in the document

1232
01:17:32,290 --> 01:17:34,840
we have the

1233
01:17:34,860 --> 01:17:38,310
variable case which is the topic

1234
01:17:38,890 --> 01:17:40,980
which has k values

1235
01:17:40,980 --> 01:17:44,740
and this is is is

1236
01:17:44,790 --> 01:17:47,840
in this x is how this of going to

1237
01:17:47,880 --> 01:17:52,960
to to be different but for so i think it as a generic

1238
01:17:53,180 --> 01:17:56,910
random but it is in the in the in the

1239
01:17:56,910 --> 01:17:58,020
document space

1240
01:17:58,180 --> 01:18:06,930
and of course since this fear more i can also represent it as

1241
01:18:06,980 --> 01:18:12,480
x is so you can see it in the in the graph

1242
01:18:12,490 --> 01:18:17,630
it's in fact i have this tree in the stream of x is it's how

1243
01:18:17,630 --> 01:18:21,710
do they they have all the tree

1244
01:18:21,730 --> 01:18:23,800
a different implementation of x

1245
01:18:23,810 --> 01:18:28,650
so i have a that's like generic more than just i'm not saying what is

1246
01:18:29,360 --> 01:18:31,470
for the moment

1247
01:18:31,480 --> 01:18:34,710
so something i didn't talk

1248
01:18:34,750 --> 01:18:38,590
to about it this representation with the plates

1249
01:18:39,570 --> 01:18:41,110
what does that mean

1250
01:18:41,110 --> 01:18:44,360
decomposition we get will be adapted to the kinds of questions we need to add

1251
01:18:44,490 --> 01:18:47,360
to discrimination between two classes

1252
01:18:49,780 --> 01:18:56,220
this is called extremely randomized clustering forests randomized and they're extremely randomized because we don't

1253
01:18:57,450 --> 01:19:00,280
essentially any information about the classes

1254
01:19:00,300 --> 01:19:02,030
to generate

1255
01:19:02,110 --> 01:19:04,450
we do use discriminative information

1256
01:19:04,470 --> 01:19:07,200
when we come to decide which trees will take

1257
01:19:08,950 --> 01:19:11,550
and although we do is that

1258
01:19:11,570 --> 01:19:12,720
three each tree

1259
01:19:12,720 --> 01:19:14,070
for each

1260
01:19:14,090 --> 01:19:15,450
feature we get

1261
01:19:15,470 --> 01:19:18,090
we put it down through the tree and gets to release

1262
01:19:18,110 --> 01:19:22,510
it's been the binary trees are coast live to ride gets down to leave

1263
01:19:22,530 --> 01:19:26,930
OK and it will go through several of the trees have several separate these those

1264
01:19:27,800 --> 01:19:30,220
now classically if you have

1265
01:19:30,220 --> 01:19:31,530
the decision tree

1266
01:19:31,550 --> 01:19:32,670
the leaves

1267
01:19:32,680 --> 01:19:37,010
coated with the class the tree decided i was going to give to the to

1268
01:19:37,010 --> 01:19:42,780
the leaf nodes could be because this is not council something so certainly these will

1269
01:19:42,780 --> 01:19:47,430
belong to cars those features as cars novelists who belong to non cars

1270
01:19:47,450 --> 01:19:51,900
OK and we get that information we train the trees we throw it away

1271
01:19:51,950 --> 01:19:57,360
we just use the spatial decomposition and then we train a separate SVM on these

1272
01:19:57,410 --> 01:19:59,450
on the sixteenth histogram

1273
01:19:59,450 --> 01:20:03,530
it turns out that that's a very good thing to do because the information from

1274
01:20:03,530 --> 01:20:05,760
the discrimination is not very reliable

1275
01:20:06,110 --> 01:20:10,470
but the spacial decompositions nevertheless adapted to the kinds of places we need to be

1276
01:20:10,470 --> 01:20:11,860
looking in space

1277
01:20:12,130 --> 01:20:15,970
and then we train an SVM on so we get good results

1278
01:20:15,990 --> 01:20:18,180
so this is pretty quick quick to do this

1279
01:20:18,200 --> 01:20:19,760
city quick to train

1280
01:20:19,780 --> 01:20:21,050
it works very well

1281
01:20:22,070 --> 01:20:23,490
the spatial decomposition

1282
01:20:23,550 --> 01:20:29,200
is very messy but it's it's relevant to problem and that's the thing that matters

1283
01:20:33,010 --> 01:20:35,150
in one point with all these models

1284
01:20:37,590 --> 01:20:40,570
in particular local features tend to characterize the

1285
01:20:40,590 --> 01:20:42,880
the current in particular object

1286
01:20:44,360 --> 01:20:45,680
what we can do

1287
01:20:45,700 --> 01:20:49,740
is that if we look for example and the nearest the find out which features

1288
01:20:49,740 --> 01:20:50,950
are important

1289
01:20:50,970 --> 01:20:55,050
for the particular discrimination of the object class we can look back and see where

1290
01:20:55,070 --> 01:20:57,950
those features were in the the image and it will give an idea

1291
01:20:58,630 --> 01:21:02,840
with the feature with the object is in the image so here's bicycles

1292
01:21:03,180 --> 01:21:06,650
it may be difficult to see that was meant massive bicycle where

1293
01:21:06,700 --> 01:21:10,740
this is the method is pick pick that the features that correspond to it and

1294
01:21:10,740 --> 01:21:14,450
you can do this in a kind of iterative loop that focuses on on the

1295
01:21:14,680 --> 01:21:21,130
region contains the bicycles suppressing the wrist so that when it calculates the histogram the

1296
01:21:21,130 --> 01:21:25,590
thing is going to use this on using those regions that strengthens the signal from

1297
01:21:25,590 --> 01:21:30,050
the high schools and you get an idea a nice relatively clean segmentation despite the

1298
01:21:30,050 --> 01:21:34,240
fact that there is no structural model tall for bicycle looks like

1299
01:21:34,260 --> 01:21:36,760
four cow whatever this thing is

1300
01:21:36,820 --> 01:21:39,550
OK so you can do that with basically and if these local feature methods and

1301
01:21:39,550 --> 01:21:41,990
it works pretty well to get first idea

1302
01:21:42,050 --> 01:21:45,090
if we the objects

1303
01:21:45,220 --> 01:21:48,150
OK latent aspect models so

1304
01:21:48,180 --> 01:21:49,590
all of these things

1305
01:21:49,610 --> 01:21:54,860
we've talked about we doing vector quantization whatever that is so high dimensional representation

1306
01:21:54,880 --> 01:21:56,110
from the features

1307
01:21:56,130 --> 01:21:59,800
and there high dimensional representations could be

1308
01:21:59,820 --> 01:22:01,820
subject to overfitting

1309
01:22:01,880 --> 01:22:04,150
so we'd like to regularize somehow

1310
01:22:04,170 --> 01:22:06,970
and one way to do this

1311
01:22:06,970 --> 01:22:09,450
is by some kind of dimensionality reduction

1312
01:22:09,580 --> 01:22:14,220
and what this corresponds to is that we're going to try to take out

1313
01:22:14,260 --> 01:22:17,900
particular thing signals that occur in the image

1314
01:22:17,950 --> 01:22:19,880
signals maybe not the right word

1315
01:22:19,930 --> 01:22:21,130
in particular

1316
01:22:21,150 --> 01:22:26,300
structures that occur in the image which which correspond to real world objects so for

1317
01:22:26,300 --> 01:22:29,820
example i've got an image here which is an building isn't trees and sky some

1318
01:22:32,110 --> 01:22:35,110
if i look at all the interest points that i get on buildings

1319
01:22:35,110 --> 01:22:40,490
we quite varied the buildings have different aspects of windows they is things like that

1320
01:22:40,510 --> 01:22:43,200
but they all tend to co occur in the images

1321
01:22:43,240 --> 01:22:48,280
because when i see building see see several of those aspects seagrass lc other kinds

1322
01:22:48,280 --> 01:22:49,150
of signals

1323
01:22:49,240 --> 01:22:52,630
OK so what these things do kind of pulls out

1324
01:22:52,650 --> 01:22:56,030
the cluster of things that co occur together

1325
01:22:56,050 --> 01:22:58,670
treats that is a single individual signals

1326
01:22:58,700 --> 01:23:02,090
and another cluster of things that can occur for graphs and treated as an individual

1327
01:23:05,400 --> 01:23:07,360
their models

1328
01:23:07,360 --> 01:23:11,910
this morning when i see you

1329
01:23:11,980 --> 01:23:14,690
a great weekend

1330
01:23:14,700 --> 01:23:17,540
if you didn't it wasn't because of the weather

1331
01:23:17,600 --> 01:23:20,180
so here i am once again member

1332
01:23:20,230 --> 01:23:24,460
walking wounded and we're talking about carbohydrates today's

1333
01:23:24,500 --> 01:23:29,500
they recall lists we were at the end of our discussion last time

1334
01:23:29,500 --> 01:23:32,300
so we made the point that

1335
01:23:32,340 --> 01:23:37,870
these multiple hydroxyl groups on the carbohydrates on the one hand determine the identity

1336
01:23:37,870 --> 01:23:41,090
of the various kinds of

1337
01:23:42,560 --> 01:23:46,230
the orientation three-dimensional orientation and

1338
01:23:46,230 --> 01:23:48,060
for one thing

1339
01:23:48,080 --> 01:23:52,150
and and for another that these multiple hydroxyl groups

1340
01:23:52,160 --> 01:23:57,880
represented the opportunity for forming covalent bonds with other models that right as indicated here

1341
01:23:57,880 --> 01:24:00,340
in the states rights or

1342
01:24:00,620 --> 01:24:04,990
covalent bonds and then to create large molecules

1343
01:24:05,050 --> 01:24:08,410
which will increase the speed of our discussion

1344
01:24:08,420 --> 01:24:13,010
i want i talk talk about are molecules which is used the phrase generically

1345
01:24:15,850 --> 01:24:17,410
so in principle

1346
01:24:17,430 --> 01:24:20,490
these and then joining of molecules

1347
01:24:20,510 --> 01:24:27,850
which involves the the dehydration and the formation of covalent bonds right here

1348
01:24:27,900 --> 01:24:33,350
can create molecules that are hundreds and even thousands of subunits along

1349
01:24:33,400 --> 01:24:35,240
so here we're talking about former

1350
01:24:35,260 --> 01:24:37,210
we refer to each one of these

1351
01:24:37,260 --> 01:24:40,870
some units of the former as being monomer

1352
01:24:40,940 --> 01:24:44,480
and the aggregate is the whole the singapore

1353
01:24:44,490 --> 01:24:49,130
so here we are we touched on the back towards the end of last lecture

1354
01:24:49,290 --> 01:24:51,260
at the very end

1355
01:24:51,340 --> 01:24:57,290
that one can write twenty crosslink these long linear chains of carbohydrates

1356
01:24:57,300 --> 01:24:59,100
here we see the fact that like engine

1357
01:24:59,100 --> 01:25:00,870
which is the form

1358
01:25:00,880 --> 01:25:03,070
glucose is stored in our liver

1359
01:25:03,090 --> 01:25:05,550
largely in small extent the model

1360
01:25:05,570 --> 01:25:07,850
actually it is

1361
01:25:07,880 --> 01:25:11,710
across different brands so if one looks at that if one draws on a much

1362
01:25:11,710 --> 01:25:16,970
smaller scale like molecule one might drop it looks like this

1363
01:25:16,980 --> 01:25:20,660
looks almost like a christmas tree with multiple branches

1364
01:25:20,700 --> 01:25:24,530
and the purpose of this is actually to sequester the glucose

1365
01:25:24,570 --> 01:25:28,140
to store the glucose metabolic rate inactive forms

1366
01:25:28,230 --> 01:25:33,130
until the time comes the organism leads once again the energy that is stored in

1367
01:25:33,130 --> 01:25:37,380
the calls upon which occasionally sponsor rapidly broken down

1368
01:25:37,410 --> 01:25:40,600
and the glucose is mobilized put into the circulation

1369
01:25:40,640 --> 01:25:45,450
four eventual disposition and use in certain specific tissues

1370
01:25:45,500 --> 01:25:49,570
while it's incumbent in these high molecular weight polymers

1371
01:25:49,610 --> 01:25:51,320
glucose is essentially

1372
01:25:51,320 --> 01:25:55,130
metabolic clinging to the by realise there

1373
01:25:55,130 --> 01:25:56,830
and we can have consequence

1374
01:25:56,850 --> 01:26:00,410
store large amounts of energy in supply chain molecules

1375
01:26:00,450 --> 01:26:03,630
and it can be stored indefinitely

1376
01:26:03,670 --> 01:26:05,970
now the fact is that

1377
01:26:05,980 --> 01:26:09,720
this this idea of end-to-end delivery station

1378
01:26:09,810 --> 01:26:13,880
that i just mentioned can be extended to other macromolecules

1379
01:26:13,920 --> 01:26:16,610
which also become linked and and

1380
01:26:16,630 --> 01:26:20,420
in a specific kinds of polymers

1381
01:26:20,480 --> 01:26:24,220
and here we are moving on to the naked into the notion of talking about

1382
01:26:24,260 --> 01:26:25,440
amino acid

1383
01:26:25,450 --> 01:26:26,510
we're talking

1384
01:26:26,570 --> 01:26:27,850
about proteins

1385
01:26:27,910 --> 01:26:29,780
if we look at amino acid

1386
01:26:29,790 --> 01:26:32,790
so what we see is an important

1387
01:26:32,810 --> 01:26:34,260
structure like this

1388
01:26:34,280 --> 01:26:36,040
the central carbon

1389
01:26:36,080 --> 01:26:38,830
and for the principle

1390
01:26:38,880 --> 01:26:40,720
the state society

1391
01:26:40,780 --> 01:26:45,390
where are represents some side chains that can be anyone as we will see shortly

1392
01:26:46,500 --> 01:26:49,190
twenty distinct identities

1393
01:26:49,230 --> 01:26:54,980
but we all know and share common property that they had the overall structure

1394
01:26:55,000 --> 01:26:57,860
and as you may recall from our discussions

1395
01:26:57,910 --> 01:26:59,890
of the discussions of last week

1396
01:26:59,910 --> 01:27:05,160
neutral ph it wouldn't a amino acid this or whatever are is would look like

1397
01:27:05,160 --> 01:27:06,580
this all

1398
01:27:06,600 --> 01:27:12,030
because the main group will attract extra proton causing it to become positively charged and

1399
01:27:12,040 --> 01:27:14,310
the carboxyl group which really

1400
01:27:15,500 --> 01:27:17,980
according to become negatively charged

1401
01:27:18,030 --> 01:27:20,630
and as you might be use from this

1402
01:27:20,650 --> 01:27:26,660
at very low ph d greatly increased concentration of protons free protons in the solution

1403
01:27:26,760 --> 01:27:31,590
equilibrium will be will be driven more in favor of reattach a proton to the

1404
01:27:31,590 --> 01:27:33,040
carboxyl group

1405
01:27:33,090 --> 01:27:36,250
because there are so many of these protons around

1406
01:27:36,270 --> 01:27:38,860
conversely is very high p

1407
01:27:38,880 --> 01:27:41,820
where the hydroxyl ions are in in

1408
01:27:41,830 --> 01:27:42,840
the government

1409
01:27:42,880 --> 01:27:45,630
they obviously tend to scavenge protons

1410
01:27:45,640 --> 01:27:50,190
reducing the level of protons to very low level in in the water and under

1411
01:27:50,190 --> 01:27:52,140
very high ph conditions

1412
01:27:52,150 --> 01:27:57,030
this proton will be released and pulled away by the hydroxyl ions causing this i

1413
01:27:57,030 --> 01:28:02,600
mean once again returned to its negative charge state

1414
01:28:02,610 --> 01:28:04,520
now the fact of the matter is

1415
01:28:05,670 --> 01:28:08,000
these amino acids are

1416
01:28:08,080 --> 01:28:11,960
there exists in a very specific three-dimensional configuration

1417
01:28:12,010 --> 01:28:15,370
and he was very much more nicely here than i could possibly

1418
01:28:15,450 --> 01:28:16,710
across the board

1419
01:28:16,760 --> 01:28:20,210
which in any case would be hopeless which is

1420
01:28:20,260 --> 01:28:23,820
there you can see in principle that once you have more distinct

1421
01:28:23,870 --> 01:28:26,230
so coming of carbon

1422
01:28:26,280 --> 01:28:28,720
there's principle two different ways

1423
01:28:30,180 --> 01:28:31,170
create them

1424
01:28:31,220 --> 01:28:33,920
this is sometimes called chirality

1425
01:28:33,940 --> 01:28:36,250
chiral form right here

1426
01:28:36,260 --> 01:28:37,800
hands are chiral

1427
01:28:37,820 --> 01:28:40,000
if i try my will to

1428
01:28:40,050 --> 01:28:41,240
so propose one hand

1429
01:28:41,240 --> 01:28:45,780
the big

1430
01:30:09,080 --> 01:30:19,310
the number of

1431
01:30:19,310 --> 01:30:28,560
just for you

1432
01:30:28,620 --> 01:30:31,000
it is

1433
01:31:02,460 --> 01:31:08,850
the root of

1434
01:33:01,000 --> 01:33:07,040
or right

1435
01:34:36,750 --> 01:34:46,040
all the goal

1436
01:36:06,790 --> 01:36:14,290
i mean it

1437
01:36:14,290 --> 01:36:16,870
it was this side there's factor

1438
01:36:16,900 --> 01:36:19,050
which is a function of x y

1439
01:36:19,140 --> 01:36:21,700
but there's also these factor here

1440
01:36:21,710 --> 01:36:25,300
just or thing by summing up six

1441
01:36:25,350 --> 01:36:28,570
this effect is also a function of x y

1442
01:36:28,620 --> 01:36:30,160
when multiply

1443
01:36:30,170 --> 01:36:33,280
these m six function with is c functions

1444
01:36:33,290 --> 01:36:35,830
and the thing in new function two

1445
01:36:35,850 --> 01:36:38,550
three five

1446
01:36:38,620 --> 01:36:40,880
and then a sum over x y

1447
01:36:40,890 --> 01:36:45,600
o thing function of x two and x three

1448
01:36:45,650 --> 01:36:49,200
now this is the function of x two and x three so it's a constant

1449
01:36:49,200 --> 01:36:52,530
with regard to the summation over or

1450
01:36:55,650 --> 01:36:58,010
this is the functional registration three

1451
01:36:58,020 --> 01:36:59,190
so this is

1452
01:36:59,200 --> 01:37:01,390
constantly that these

1453
01:37:01,400 --> 01:37:05,750
the measurements four so what can i do

1454
01:37:05,790 --> 01:37:08,900
you can use

1455
01:37:08,960 --> 01:37:11,740
once again the distributive law

1456
01:37:11,820 --> 01:37:13,830
correct can all these

1457
01:37:13,900 --> 01:37:18,630
outside of this information is it's also

1458
01:37:18,680 --> 01:37:19,660
two he

1459
01:37:19,870 --> 01:37:21,260
pushes the

1460
01:37:21,270 --> 01:37:22,950
because there's xt

1461
01:37:22,960 --> 01:37:25,140
is extreme

1462
01:37:25,180 --> 01:37:28,480
conclusion is that

1463
01:37:28,550 --> 01:37:30,890
now i just evaluate

1464
01:37:30,930 --> 01:37:32,200
these cells

1465
01:37:32,280 --> 01:37:35,750
over the next four

1466
01:37:35,790 --> 01:37:38,870
remember push and these in five

1467
01:37:38,940 --> 01:37:42,160
evaluate these works for function

1468
01:37:46,040 --> 01:37:50,520
which itself is a function of x two here in this image the axis of

1469
01:37:50,640 --> 01:37:55,400
constant vector this omission i push it outside

1470
01:37:57,480 --> 01:38:01,000
and then you just have to politics

1471
01:38:01,070 --> 01:38:03,740
and finally the so called

1472
01:38:03,780 --> 01:38:06,010
there's bug

1473
01:38:06,020 --> 01:38:12,610
are just the summation x two

1474
01:38:13,690 --> 01:38:17,330
yes but it's hard to find for graph

1475
01:38:17,430 --> 01:38:22,030
so basically if you want to find an optimal illumination

1476
01:38:22,030 --> 01:38:27,770
when i take graph that's from

1477
01:38:27,780 --> 01:38:35,790
will be as

1478
01:38:38,280 --> 01:38:42,070
but not by much of the original graph

1479
01:38:42,120 --> 01:38:45,250
well seriously by the maximum

1480
01:38:46,170 --> 01:38:52,270
of the allies were for the original graph with more information

1481
01:38:52,370 --> 01:38:58,660
in case of vision that in this case you just accumulation of graph

1482
01:38:58,670 --> 01:39:02,350
the key message here is that once we did things in this way

1483
01:39:02,400 --> 01:39:04,120
the instead of b

1484
01:39:05,930 --> 01:39:08,390
of the six because there are six old

1485
01:39:08,400 --> 01:39:10,900
it's just complexity of the three because

1486
01:39:10,900 --> 01:39:14,490
three is the size of the maximal clique

1487
01:39:14,570 --> 01:39:18,430
this is the general here whenever you have

1488
01:39:18,540 --> 01:39:21,900
uses elimination of with is

1489
01:39:21,930 --> 01:39:24,300
distributive law

1490
01:39:24,310 --> 01:39:28,390
essentially what you can do is to compute things

1491
01:39:28,520 --> 01:39:30,530
time exponential

1492
01:39:30,580 --> 01:39:33,150
on the size of the maximal clique

1493
01:39:33,160 --> 01:39:37,300
so the size of the maximum if the maximal cliques are small groups of two

1494
01:39:37,300 --> 01:39:38,180
or three

1495
01:39:38,300 --> 01:39:42,200
so the explanation which was used to that

1496
01:39:42,260 --> 01:39:46,620
so in the near the number of

1497
01:39:50,550 --> 01:39:54,600
so this is we're going to use this elimination ours whenever we have a very

1498
01:39:54,620 --> 01:39:56,920
specific type of query

1499
01:39:56,920 --> 01:39:57,980
so today

1500
01:39:58,000 --> 01:40:01,620
i will start with a general discussion on the waves

1501
01:40:01,640 --> 01:40:03,600
as in the introduction

1502
01:40:03,610 --> 01:40:06,620
two electromagnetic waves which we will discuss

1503
01:40:06,630 --> 01:40:08,550
next week

1504
01:40:08,600 --> 01:40:09,960
i will start with a very

1505
01:40:09,970 --> 01:40:12,150
down to earth equation

1506
01:40:12,200 --> 01:40:14,170
y equals one

1507
01:40:14,240 --> 01:40:16,740
thirty axis

1508
01:40:16,760 --> 01:40:22,540
i'm going to plot that for you

1509
01:40:22,540 --> 01:40:24,830
here's why

1510
01:40:24,850 --> 01:40:26,940
these acts

1511
01:40:26,990 --> 01:40:30,600
and that's a straight line through the origin

1512
01:40:30,640 --> 01:40:34,520
y equals one third x

1513
01:40:34,530 --> 01:40:37,700
suppose now i want this line to move

1514
01:40:37,780 --> 01:40:41,710
one this line to move with the speed of six meters per second in the

1515
01:40:41,710 --> 01:40:44,230
planes x ex-director

1516
01:40:44,280 --> 01:40:46,500
all i will have to do now

1517
01:40:46,550 --> 01:40:48,300
is to replace x

1518
01:40:48,310 --> 01:40:49,570
in that equation

1519
01:40:49,680 --> 01:40:51,490
by x minus

1520
01:40:52,740 --> 01:40:57,660
notice the minus sign i will go down in the plus x

1521
01:40:59,120 --> 01:41:01,430
creation then becomes y

1522
01:41:01,450 --> 01:41:03,780
equals one

1523
01:41:03,820 --> 01:41:05,370
time axis

1524
01:41:08,010 --> 01:41:11,460
so we going to achieve equals one

1525
01:41:11,510 --> 01:41:12,810
t equals zero

1526
01:41:12,820 --> 01:41:14,460
we already have the line

1527
01:41:14,510 --> 01:41:16,100
t equals one

1528
01:41:16,120 --> 01:41:17,900
you know i have y

1529
01:41:17,920 --> 01:41:19,930
equals one third x

1530
01:41:22,820 --> 01:41:24,590
that means

1531
01:41:25,540 --> 01:41:28,090
it will intersect minus two

1532
01:41:28,130 --> 01:41:29,900
and you it will intersect

1533
01:41:29,900 --> 01:41:31,680
class six

1534
01:41:31,730 --> 01:41:32,960
in the line

1535
01:41:34,240 --> 01:41:36,450
the first one

1536
01:41:36,460 --> 01:41:38,230
this line is now t

1537
01:41:38,230 --> 01:41:39,840
equals one

1538
01:41:39,920 --> 01:41:41,060
this is the

1539
01:41:41,070 --> 01:41:43,240
well zero and it has moved

1540
01:41:43,260 --> 01:41:46,850
in this direction was the speed of six meters

1541
01:41:46,900 --> 01:41:48,980
a second

1542
01:41:49,040 --> 01:41:50,950
so what this is telling us

1543
01:41:51,020 --> 01:41:53,620
if we ever want something to move

1544
01:41:53,670 --> 01:41:54,980
with speed

1545
01:41:55,930 --> 01:41:57,760
in the process acts direction

1546
01:41:57,790 --> 01:42:01,240
all we have to do in our equations to replace x

1547
01:42:01,260 --> 01:42:02,260
by x

1548
01:42:02,290 --> 01:42:03,930
minus the team

1549
01:42:03,930 --> 01:42:07,340
and if we wanted to move into minus x directions

1550
01:42:07,400 --> 01:42:09,900
then we replace x by x

1551
01:42:10,510 --> 01:42:15,310
all we have to do

1552
01:42:16,490 --> 01:42:17,870
i'm going to change

1553
01:42:17,960 --> 01:42:21,400
something that is the real way

1554
01:42:21,440 --> 01:42:23,680
i don't know why

1555
01:42:23,740 --> 01:42:27,280
he calls two

1556
01:42:27,330 --> 01:42:29,560
times size

1557
01:42:29,630 --> 01:42:31,400
of three acts

1558
01:42:31,470 --> 01:42:32,440
it's way

1559
01:42:32,460 --> 01:42:35,060
not moving not yet

1560
01:42:35,110 --> 01:42:37,400
i can make it plot

1561
01:42:38,840 --> 01:42:42,280
as a function of x

1562
01:42:45,240 --> 01:42:50,770
that plot will be like this

1563
01:42:50,840 --> 01:42:52,780
this is zero

1564
01:42:52,800 --> 01:42:55,060
the sign is zero

1565
01:42:55,150 --> 01:42:58,120
this is why divided by three

1566
01:42:58,180 --> 01:43:00,740
this is hundred eighty degrees and it's again zero

1567
01:43:00,740 --> 01:43:03,890
this is two pi divided by three

1568
01:43:03,900 --> 01:43:06,840
again zero

1569
01:43:09,930 --> 01:43:12,590
which we call the wavelength

1570
01:43:12,640 --> 01:43:14,180
let down

1571
01:43:14,190 --> 01:43:16,590
in this case from here to here

1572
01:43:16,640 --> 01:43:17,990
is goodbye

1573
01:43:18,050 --> 01:43:19,620
divided by three

1574
01:43:19,660 --> 01:43:21,000
was also from here

1575
01:43:23,620 --> 01:43:29,390
i will introduce symbol kdq often see we call the wave number

1576
01:43:29,400 --> 01:43:32,020
and k is simply defined

1577
01:43:32,020 --> 01:43:33,460
two pi

1578
01:43:33,500 --> 01:43:36,660
provided by land so in our specific case

1579
01:43:36,710 --> 01:43:38,560
OK sorry

1580
01:43:38,620 --> 01:43:40,000
this year

1581
01:43:42,500 --> 01:43:44,150
you know there is no more

1582
01:43:44,150 --> 01:43:49,430
you can immediately tell what the wavelength is

1583
01:43:50,120 --> 01:43:53,150
i want to have these wave moves

1584
01:43:53,160 --> 01:43:55,360
i will have traveling wave

1585
01:43:55,440 --> 01:43:58,800
and i want to have it moved with six meters per second into plus x

1586
01:44:00,000 --> 01:44:02,180
the recipe is now very simple

1587
01:44:02,190 --> 01:44:05,110
all i have to do is replace this ex

1588
01:44:05,150 --> 01:44:06,430
i x minus

1589
01:44:06,440 --> 01:44:08,160
six t

1590
01:44:08,210 --> 01:44:10,310
so now i get why

1591
01:44:10,360 --> 01:44:12,190
equals two

1592
01:44:15,420 --> 01:44:17,040
times x

1593
01:44:21,320 --> 01:44:23,640
and if you look at this curve

1594
01:44:23,690 --> 01:44:25,160
this equation

1595
01:44:25,250 --> 01:44:29,020
you plotted a little bit later in time than t zero this is already two

1596
01:44:29,880 --> 01:44:31,320
a little later in time

1597
01:44:31,330 --> 01:44:32,970
you will see that indeed

1598
01:44:32,980 --> 01:44:34,190
he has moved

1599
01:44:34,210 --> 01:44:37,230
plus direction

1600
01:44:37,280 --> 01:44:42,150
it is moving with a speed of six meters per second

1601
01:44:42,160 --> 01:44:44,340
so this equation when you look at it

1602
01:44:44,360 --> 01:44:48,290
holds all the characteristics of the oscillation

1603
01:44:48,340 --> 01:44:50,480
it's hold the amplitude

1604
01:44:50,530 --> 01:44:51,420
this too

1605
01:44:51,570 --> 01:44:53,720
the amplitude minus two

1606
01:44:53,770 --> 01:44:55,450
that's the amplitude

1607
01:44:55,500 --> 01:44:57,470
this information came

1608
01:44:57,480 --> 01:44:59,910
all the information on the wavelength

1609
01:44:59,940 --> 01:45:01,750
and this information

1610
01:45:01,790 --> 01:45:02,860
tells you what the

1611
01:45:02,880 --> 01:45:05,150
speed is

1612
01:45:05,190 --> 01:45:07,760
and the minus sign which is important

1613
01:45:07,820 --> 01:45:13,340
tell you is going into politics direction and not in the minors ecstatic

1614
01:45:13,390 --> 01:45:14,160
can we

1615
01:45:15,170 --> 01:45:16,800
such a traveling wave

1616
01:45:17,020 --> 01:45:19,910
we can do that actually quite easily

1617
01:45:19,920 --> 01:45:21,850
suppose i have here

1618
01:45:21,900 --> 01:45:23,600
a rotating wheel

1619
01:45:23,650 --> 01:45:26,460
rotate at angular frequency of omega

1620
01:45:26,470 --> 01:45:28,750
and that this has radius are

1621
01:45:28,820 --> 01:45:33,020
i give it two units so they get the same amplitude that i have here

1622
01:45:33,080 --> 01:45:36,340
and i attached to this history

1623
01:45:36,390 --> 01:45:39,610
put some tension on the string

1624
01:45:39,660 --> 01:45:41,860
so i creates

1625
01:45:42,000 --> 01:45:44,210
wave is rotated

1626
01:45:44,260 --> 01:45:46,110
the strings attached here

1627
01:45:46,130 --> 01:45:49,000
and as it rotates

1628
01:45:49,010 --> 01:45:51,600
we're going to propagate

1629
01:45:51,610 --> 01:45:52,590
in two

1630
01:45:52,650 --> 01:45:53,460
the string

1631
01:45:53,520 --> 01:45:55,380
with the velocity

1632
01:45:55,420 --> 01:45:58,380
that's a feat so i can generate

1633
01:45:58,410 --> 01:46:02,190
a traveling wave

1634
01:46:02,230 --> 01:46:04,150
the periods

1635
01:46:04,230 --> 01:46:06,040
of one oscillation

1636
01:46:06,090 --> 01:46:08,100
if you have on the string

1637
01:46:08,150 --> 01:46:12,250
you're going up going down going up you're going down so you're doing way passes

1638
01:46:13,330 --> 01:46:15,700
the period of one whole summation

1639
01:46:15,710 --> 01:46:21,360
it's obviously two pi divided by this omega

1640
01:46:21,410 --> 01:46:23,270
the wavelength lambda

1641
01:46:23,320 --> 01:46:25,230
that you're creating

1642
01:46:30,020 --> 01:46:33,030
well if you notice which which is this travelling

1643
01:46:33,040 --> 01:46:38,710
and you know it has been travelling capital three seconds one oscillations that distant land

1644
01:46:38,710 --> 01:46:39,730
is nothing more

1645
01:46:39,750 --> 01:46:42,750
the electromagnetic force but in disguise

1646
01:46:43,700 --> 01:46:48,230
history so i suppose the history of unification goes back as far as eighteen sixty

1647
01:46:48,850 --> 01:46:51,030
when maxwell first

1648
01:46:51,050 --> 01:46:55,940
united electricity and magnetism into what we call electromagnetism

1649
01:46:55,950 --> 01:46:57,550
a hundred years later

1650
01:46:57,570 --> 01:47:03,430
it was shown one of the proposed that the electromagnetic and weak forces could be

1651
01:47:04,210 --> 01:47:08,850
and what we call the electroweak force this uniting being based upon the idea that

1652
01:47:08,860 --> 01:47:14,530
there are w bosons the analogs photons with this one little problem w bosons have

1653
01:47:14,530 --> 01:47:16,440
to have mass

1654
01:47:16,460 --> 01:47:18,530
five percent

1655
01:47:18,550 --> 01:47:22,060
but the trick involved the higgs mechanism which is away

1656
01:47:22,070 --> 01:47:25,930
of starting off as if the w boson had no matter tool

1657
01:47:25,930 --> 01:47:27,790
playing this trick and they

1658
01:47:27,810 --> 01:47:32,370
again the mass without spawning the nice features the story the technical details of that

1659
01:47:32,370 --> 01:47:36,280
you only later but let me just for a moment take on board the fact

1660
01:47:36,360 --> 01:47:38,290
w and z

1661
01:47:38,300 --> 01:47:41,820
expected to have a mass will tell you very shortly

1662
01:47:41,840 --> 01:47:45,890
how big the mass is why work out beautifully

1663
01:47:45,900 --> 01:47:51,130
speedy for the w and z particles were found in experiments here it's by colliding

1664
01:47:51,130 --> 01:47:52,790
protons and antiprotons

1665
01:47:52,790 --> 01:47:59,730
a single class proton antiquark antiproton if they just by chance had the right energy

1666
01:47:59,750 --> 01:48:04,890
and the right formation flavours they could once the blue moon w or z rather

1667
01:48:04,890 --> 01:48:09,770
than shouting pions they normally produce so it is like looking for a needle in

1668
01:48:09,780 --> 01:48:13,470
a haystack but eventually was done during the linear

1669
01:48:13,480 --> 01:48:17,610
the prize for the discovery which actually was quite interesting given the

1670
01:48:17,640 --> 01:48:20,590
nobel prize for the theory had already been given even though these things have been

1671
01:48:20,590 --> 01:48:23,870
found so if it turned out to be wrong with the nobel committee but have

1672
01:48:23,880 --> 01:48:25,890
lost their first prize back again

1673
01:48:25,900 --> 01:48:29,310
speculation to having discovered the w and z

1674
01:48:29,360 --> 01:48:32,890
and this is a rather clumsy experiments with protons that we say well i mean

1675
01:48:32,890 --> 01:48:37,340
by that because it's quite relevant to the present station history with the OEC starting

1676
01:48:37,940 --> 01:48:45,180
protons antiprotons that complicated things they contain quarks i suggest the three quarks but the

1677
01:48:45,180 --> 01:48:47,050
simplest way of making them

1678
01:48:47,060 --> 01:48:50,710
the war resolution you look at these things with a course you don't see a

1679
01:48:50,710 --> 01:48:56,530
single class see that surrounded by a cloud of quark antiquark gluon so protein is

1680
01:48:56,530 --> 01:49:01,170
actually three quarks the cloud of quantum the quantum one real

1681
01:49:01,210 --> 01:49:02,900
missy bad stuff

1682
01:49:03,120 --> 01:49:05,030
the antiproton likewise

1683
01:49:05,070 --> 01:49:09,670
but the first experiment because it's the easiest way to get high energy is the

1684
01:49:09,670 --> 01:49:13,510
fact that these things are two thousand times more massive than an electron or positron

1685
01:49:13,790 --> 01:49:18,230
means part of punch so you can access new regions you never been to before

1686
01:49:18,850 --> 01:49:21,230
this is rather clumsy way

1687
01:49:21,230 --> 01:49:25,170
i mean discovered things in the case of

1688
01:49:25,180 --> 01:49:27,110
the nineteen eighties the w and z

1689
01:49:27,170 --> 01:49:31,520
you can then go to very clean probpsf like electrons and positrons

1690
01:49:31,540 --> 01:49:36,760
an electron positron are nothing more than electron positron you can control the energy precisely

1691
01:49:36,760 --> 01:49:40,060
and choose the energy of the collision to exactly what you want

1692
01:49:40,080 --> 01:49:45,240
and that was what was done in the nineteen nineties here met the large electoral

1693
01:49:45,240 --> 01:49:46,470
positron collider

1694
01:49:46,540 --> 01:49:53,030
and it was changed specifically to apply ninety gv because that energy z bozos

1695
01:49:54,020 --> 01:49:55,020
and they

1696
01:49:55,040 --> 01:49:59,550
united about ten million examples of producing z bosons and seeing how decay

1697
01:50:00,020 --> 01:50:02,730
looking it very precisely

1698
01:50:02,740 --> 01:50:08,220
and in the course of ten years because about six years experimentation

1699
01:50:08,640 --> 01:50:10,570
they found that you the same

1700
01:50:10,600 --> 01:50:12,200
is unstable

1701
01:50:12,210 --> 01:50:13,570
it decays

1702
01:50:13,600 --> 01:50:17,320
a democratically indicated to all possible things that could do

1703
01:50:17,330 --> 01:50:19,750
in particular it can be k

1704
01:50:19,760 --> 01:50:20,620
in two

1705
01:50:22,240 --> 01:50:25,030
neutrinos electron time

1706
01:50:25,130 --> 01:50:29,640
and and depression and to another neuron type and version the notion of the town

1707
01:50:29,640 --> 01:50:30,940
type incentive version

1708
01:50:31,020 --> 01:50:35,870
and the nature of any other types we have previously seen their devotion

1709
01:50:35,890 --> 01:50:38,420
so long as the light

1710
01:50:38,420 --> 01:50:43,110
now you can begin to see qualitatively here the more varieties of neutrino that there

1711
01:50:43,110 --> 01:50:44,290
might be in nature

1712
01:50:44,820 --> 01:50:48,800
the more opportunities there are for the z decay is like a bucket full of

1713
01:50:48,800 --> 01:50:52,560
water the water holes there are in it the quicker the water drains out the

1714
01:50:52,730 --> 01:50:55,450
channels for k is that there are

1715
01:50:55,460 --> 01:50:57,090
the children will live

1716
01:50:57,110 --> 01:51:02,850
and what was found remarkably is that z indeed is unstable it has

1717
01:51:02,870 --> 01:51:03,760
a width

1718
01:51:03,770 --> 01:51:05,600
and this manifests itself

1719
01:51:05,630 --> 01:51:11,020
in the following way that you collide electron positron not exactly ninety gv but sometimes

1720
01:51:11,020 --> 01:51:17,040
energies below through ninety over and you see the cross section the probability for something

1721
01:51:17,040 --> 01:51:19,670
to happen rises and falls

1722
01:51:19,680 --> 01:51:23,860
the rise and fall is what we call the z boson on residents

1723
01:51:23,880 --> 01:51:26,090
nine quantum mechanics

1724
01:51:27,600 --> 01:51:32,680
this thing is like the uncertainty in energy over which this thing is produced

1725
01:51:32,680 --> 01:51:39,350
and quantum mechanics the highs and the uncertainty principle tells you that uncertainty in energy

1726
01:51:39,360 --> 01:51:42,170
multiplied by uncertainty in time

1727
01:51:42,200 --> 01:51:44,460
is the order of plants

1728
01:51:44,480 --> 01:51:47,920
which he six times ten to the minus twenty five

1729
01:51:47,940 --> 01:51:50,500
gv time seconds

1730
01:51:50,520 --> 01:51:52,630
so by measuring the rate

1731
01:51:52,700 --> 01:51:53,620
of this

1732
01:51:53,640 --> 01:51:56,850
but you can work out how long

1733
01:51:56,870 --> 01:51:58,440
the particle that

1734
01:51:58,450 --> 01:52:02,050
maybe this a from that you find that the

1735
01:52:02,100 --> 01:52:06,280
said personal it's about ten to twenty five seconds in traditional time

1736
01:52:06,460 --> 01:52:08,100
but what is more beautiful

1737
01:52:08,210 --> 01:52:09,220
is that

1738
01:52:09,230 --> 01:52:10,610
you could span

1739
01:52:10,630 --> 01:52:15,000
very precisely over the the peak and the data points are the black dots on

1740
01:52:15,000 --> 01:52:19,740
the three lines are what theory would expect for the with the z if there

1741
01:52:19,740 --> 01:52:24,510
were only two varieties tree of course we mean know it's nonsense free

1742
01:52:24,520 --> 01:52:25,850
o four

1743
01:52:26,120 --> 01:52:29,940
and the line the three neutrinos goes beautifully through the data

1744
01:52:30,030 --> 01:52:34,170
so it is the precise measurements of the properties of the z in the nineteen

1745
01:52:35,530 --> 01:52:40,930
which shows that there are at most three varieties of like neutrinos

1746
01:52:41,070 --> 01:52:44,500
mean if there right neutrino weighs more than half the mass of the z like

1747
01:52:44,500 --> 01:52:45,200
fifty gv

1748
01:52:45,670 --> 01:52:49,710
then of course you would know that but if there is that something totally different

1749
01:52:49,720 --> 01:52:54,460
but we know there are three varieties of light neutrino

1750
01:52:54,480 --> 01:52:57,420
each country seems to be married to

1751
01:52:57,430 --> 01:53:01,300
the negatively charged lepton like an electron muon tau we infer

1752
01:53:01,320 --> 01:53:05,740
most three varieties of charged leptons seeing that each pair

1753
01:53:05,740 --> 01:53:09,100
these seem to be married to the pair of quarks up and down john strange

1754
01:53:09,100 --> 01:53:14,030
top and bottom we infer that if the system is right there are almost three

1755
01:53:14,060 --> 01:53:16,360
generations of these quarks

1756
01:53:16,380 --> 01:53:19,790
that one alternatively wrong but that's how it appears to be a white is we

1757
01:53:19,790 --> 01:53:23,290
don't know but this is to show that this is an experimental deduce facts that

1758
01:53:23,290 --> 01:53:24,070
we had

1759
01:53:24,090 --> 01:53:28,460
from left by studying is it precisely

1760
01:53:28,500 --> 01:53:33,820
and in nineteen sixty two thousand they did electron positron annihilation higher energies in the

1761
01:53:33,820 --> 01:53:38,790
hope what fact in the success of producing pairs of w bosons charged w plus

1762
01:53:38,790 --> 01:53:44,480
and minus to serve electric charge electron positron coming in w possibly minus have to

1763
01:53:44,480 --> 01:53:48,210
balance going out and you need much more energy to produce those so they started

1764
01:53:48,420 --> 01:53:52,840
quite a lot of detail the properties of z and w for many years

1765
01:53:52,890 --> 01:53:58,230
so think that the whole precision of the electroweak was confirmed

1766
01:53:58,230 --> 01:53:59,170
so now

1767
01:53:59,180 --> 01:54:01,520
what is going to do with unity

1768
01:54:01,800 --> 01:54:04,350
this is what i want to show you the idea of the weak force being

1769
01:54:04,350 --> 01:54:07,430
electromagnetism in disguise

1770
01:54:07,450 --> 01:54:10,550
although those back to this point that

1771
01:54:10,580 --> 01:54:12,680
when for came into the game

1772
01:54:12,710 --> 01:54:13,750
the for me

1773
01:54:15,270 --> 01:54:19,600
it's not a number is a dimensionless quantity ten to the minus five

1774
01:54:19,620 --> 01:54:23,320
divided by dimensions gv squared

1775
01:54:23,460 --> 01:54:25,650
and we now know

1776
01:54:25,710 --> 01:54:27,290
it's not a black box

1777
01:54:27,310 --> 01:54:27,950
it is

1778
01:54:27,950 --> 01:54:30,980
w boson being exchanged

1779
01:54:30,980 --> 01:54:33,960
so that you have something to think about

1780
01:54:34,000 --> 01:54:36,020
believe me is healthy

1781
01:54:36,070 --> 01:54:37,670
MIT student

1782
01:54:37,730 --> 01:54:39,190
to sleep

1783
01:54:39,190 --> 01:54:41,920
but also healthy sometimes not

1784
01:54:42,000 --> 01:54:43,880
sleepless nights

1785
01:54:43,900 --> 01:54:45,130
and worry

1786
01:54:45,130 --> 01:54:46,050
that's the way

1787
01:54:46,090 --> 01:54:49,420
but i had sleepless nights in high school

1788
01:54:49,460 --> 01:54:50,940
about or something

1789
01:54:50,940 --> 01:54:52,610
it's healthy

1790
01:54:52,610 --> 01:54:56,460
the reason why that's healthy because once you see seen solution

1791
01:54:56,480 --> 01:54:57,090
you say

1792
01:54:57,110 --> 01:55:00,400
i of course and you never forget it

1793
01:55:00,440 --> 01:55:01,880
whereas if someone tells you

1794
01:55:01,940 --> 01:55:03,480
from the start say

1795
01:55:04,500 --> 01:55:06,300
you forgot it in the next day

1796
01:55:06,300 --> 01:55:07,730
you don't remember

1797
01:55:07,770 --> 01:55:09,210
so i wanted to

1798
01:55:09,230 --> 01:55:11,340
c is remarkable

1799
01:55:13,020 --> 01:55:15,040
often also nations

1800
01:55:15,090 --> 01:55:19,480
that can be produced not by regions as we have seen

1801
01:55:19,500 --> 01:55:21,210
but by heat

1802
01:55:21,280 --> 01:55:23,750
and by calling

1803
01:55:23,840 --> 01:55:25,630
i have here

1804
01:55:25,690 --> 01:55:27,650
nice pipe

1805
01:55:27,770 --> 01:55:30,500
and there is a great here

1806
01:55:30,500 --> 01:55:32,420
i can touch it

1807
01:55:32,500 --> 01:55:33,500
touching it now

1808
01:55:33,550 --> 01:55:36,690
or is it opened by the great

1809
01:55:36,750 --> 01:55:38,270
what i need that grid

1810
01:55:38,280 --> 01:55:40,840
and call it

1811
01:55:42,750 --> 01:55:44,270
it generates

1812
01:55:44,280 --> 01:55:45,800
one hundred ten hurdles

1813
01:55:45,800 --> 01:55:48,270
should probably pressure wave

1814
01:55:48,270 --> 01:55:50,590
which you will be able to do

1815
01:55:50,610 --> 01:55:53,300
and i'll give you until

1816
01:55:53,320 --> 01:55:54,650
the end of december

1817
01:55:54,650 --> 01:55:57,730
maybe mid-december to come up with a

1818
01:55:57,800 --> 01:56:09,770
solution whites doing that

1819
01:56:09,770 --> 01:56:16,920
i mean the great now

1820
01:56:17,000 --> 01:56:32,940
model that was roughly

1821
01:56:32,940 --> 01:56:34,860
you want to play with this don't break it

1822
01:56:34,880 --> 01:56:36,020
try to

1823
01:56:36,050 --> 01:56:38,710
transfer liquid for seventeen seconds

1824
01:56:38,730 --> 01:56:41,150
i was part of the reason lecture

1825
01:56:41,170 --> 01:56:45,110
exactly five minutes from now

1826
01:56:45,130 --> 01:56:51,860
if you turn it into a tornado

1827
01:56:51,880 --> 01:56:53,980
rotate it

1828
01:56:54,960 --> 01:56:57,480
you open up a full of air

1829
01:56:57,520 --> 01:57:00,440
so it is never the problem that the

1830
01:57:00,460 --> 01:57:02,670
liquid cannot go through

1831
01:57:02,710 --> 01:57:04,840
there's always pressure equilibrium

1832
01:57:04,860 --> 01:57:08,340
and i don't remember how long it takes but i thought i was seventeen seconds

1833
01:57:08,340 --> 01:57:14,320
but if you want to we can time may even be less

1834
01:57:14,340 --> 01:57:15,920
i now want to

1835
01:57:16,040 --> 01:57:17,710
address the issue of

1836
01:57:17,730 --> 01:57:20,920
simple harmonic oscillation of a

1837
01:57:23,750 --> 01:57:26,880
as you will remember from a one

1838
01:57:27,170 --> 01:57:29,420
the pendulum

1839
01:57:29,440 --> 01:57:31,190
thanks al

1840
01:57:31,190 --> 01:57:33,550
mass and

1841
01:57:33,550 --> 01:57:36,110
and if the mass of the strange

1842
01:57:36,130 --> 01:57:38,130
is negligibly small

1843
01:57:38,150 --> 01:57:40,750
compared to the mass is hanging here

1844
01:57:40,780 --> 01:57:42,980
then the period of oscillation

1845
01:57:43,090 --> 01:57:44,460
two pi

1846
01:57:44,520 --> 01:57:47,670
i've described over g

1847
01:57:47,670 --> 01:57:50,750
g in the boston area

1848
01:57:50,800 --> 01:57:53,670
in two high degree of accuracy

1849
01:57:53,690 --> 01:57:55,090
nine point

1850
01:57:55,130 --> 01:58:00,110
eight zero meters per second squared

1851
01:58:00,170 --> 01:58:02,400
if you simply take l

1852
01:58:02,420 --> 01:58:04,230
approximately one meter

1853
01:58:04,250 --> 01:58:08,940
then you can see that you get the period of about two seconds

1854
01:58:08,940 --> 01:58:10,750
and if you make the legs

1855
01:58:10,800 --> 01:58:14,880
about twenty five centimeters that is four times shorter

1856
01:58:14,900 --> 01:58:17,130
then you would expect the spirit

1857
01:58:17,190 --> 01:58:18,880
which is two times

1858
01:58:18,940 --> 01:58:22,210
joint which is about one second

1859
01:58:22,270 --> 01:58:24,550
and without any pretense

1860
01:58:27,570 --> 01:58:29,000
just eyeballing

1861
01:58:29,690 --> 01:58:31,230
really testing

1862
01:58:31,340 --> 01:58:34,190
i just i will this to be about a meter

1863
01:58:34,190 --> 01:58:36,550
levi also back and forth

1864
01:58:36,550 --> 01:58:39,210
it's about two seconds for one oscillation

1865
01:58:45,380 --> 01:58:48,210
if however make twenty five centimetres

1866
01:58:48,250 --> 01:58:49,610
four times shorter

1867
01:58:49,610 --> 01:58:50,550
then it is

1868
01:58:50,570 --> 01:58:53,320
very close to one second

1869
01:58:53,500 --> 01:58:58,050
no interference here

1870
01:59:07,480 --> 01:59:10,270
when you look at the this equation is

1871
01:59:10,320 --> 01:59:13,800
that just like in the case of the spring

1872
01:59:13,820 --> 01:59:19,630
it is independent of the amplitude in other words when i have a large amplitude

1873
01:59:19,690 --> 01:59:24,420
four small amplitude will take the same amount of time to go back and forth

1874
01:59:28,590 --> 01:59:29,840
what pendulum

1875
01:59:29,900 --> 01:59:31,570
when we make

1876
01:59:31,610 --> 01:59:36,210
we derive this period you remember that you have to assume what we call small

1877
01:59:36,210 --> 01:59:38,610
angle approximation

1878
01:59:38,630 --> 01:59:40,860
you'll see that again and again was

1879
01:59:40,900 --> 01:59:42,250
you know it

1880
01:59:42,270 --> 01:59:44,980
called small angle

1881
01:59:47,230 --> 01:59:49,770
the small angle approximations

1882
01:59:49,780 --> 01:59:56,110
the final thing that is always the same as data in radiance

1883
01:59:56,110 --> 01:59:58,840
now if you ask me how small is small

1884
01:59:58,880 --> 02:00:04,380
it's a matter of taste

1885
02:00:04,400 --> 02:00:06,750
in twenty six one hundred we have

1886
02:00:06,750 --> 02:00:09,070
the mother of all kinds


1
00:00:00,000 --> 00:00:04,490
i which should which i cannot decision between unfunded

2
00:00:04,850 --> 00:00:09,580
with different size of training set a and b here we have the

3
00:00:09,590 --> 00:00:13,960
objective function evaluated on the test set which was used for training

4
00:00:14,440 --> 00:00:21,100
and we have to function and the function of the time of training

5
00:00:21,110 --> 00:00:26,580
on the second city is ten thousand how can we

6
00:00:26,710 --> 00:00:29,070
so yes which

7
00:00:29,080 --> 00:00:32,290
i think the is really because we don't have

8
00:00:33,110 --> 00:00:36,750
then becomes evident when you have that becomes whole

9
00:00:37,820 --> 00:00:40,080
excuse for me to

10
00:00:40,090 --> 00:00:43,450
the council of bit

11
00:00:44,200 --> 00:00:45,790
here is some of the

12
00:00:45,810 --> 00:00:49,090
sixteen we see here so

13
00:00:49,100 --> 00:00:50,860
in the

14
00:00:51,750 --> 00:00:58,830
and we had a better case and there were to this experiment in the egyptian

15
00:00:58,850 --> 00:01:04,910
sitting in the let's see how we follow that is beta

16
00:01:04,930 --> 00:01:09,900
then can here is even more difference between the that city in the thing that

17
00:01:09,900 --> 00:01:12,970
if you go even further using

18
00:01:12,980 --> 00:01:19,650
even more conditions then that becomes almost people when you have a laugh

19
00:01:21,450 --> 00:01:22,300
so now

20
00:01:22,320 --> 00:01:26,700
we can ask why is that it is and

21
00:01:26,830 --> 00:01:31,060
you can it's also a

22
00:01:31,340 --> 00:01:34,170
virtually longer

23
00:01:34,190 --> 00:01:38,190
that we have to assume it and so on the first

24
00:01:38,420 --> 00:01:42,320
we have to make the weight of the world in this

25
00:01:42,360 --> 00:01:44,930
and by the time

26
00:01:44,950 --> 00:01:47,840
and here's what you said and this set you have

27
00:01:47,850 --> 00:01:50,080
so you have a mate

28
00:01:50,090 --> 00:01:51,000
for the

29
00:01:51,030 --> 00:01:52,870
the other is

30
00:01:52,900 --> 00:01:54,750
we have a small

31
00:01:54,770 --> 00:01:58,220
the same thing the here

32
00:01:58,330 --> 00:02:02,120
on the left that which is even more difficult even more

33
00:02:02,140 --> 00:02:03,190
there is

34
00:02:03,210 --> 00:02:06,790
the difference is even

35
00:02:06,830 --> 00:02:09,430
so now i want do that solve

36
00:02:09,440 --> 00:02:12,890
so the last fall because

37
00:02:12,900 --> 00:02:15,650
with this method have been walking

38
00:02:16,990 --> 00:02:19,320
you know maybe all these small

39
00:02:19,320 --> 00:02:25,360
the image was images which are getting excited by twenty times for you want to

40
00:02:25,540 --> 00:02:28,910
get the image and have dictionary

41
00:02:28,930 --> 00:02:32,320
but it seems to be

42
00:02:32,420 --> 00:02:35,330
this is what you can get in

43
00:02:38,710 --> 00:02:42,540
so he was some text from the image

44
00:02:42,560 --> 00:02:46,710
and the result in a that is how many

45
00:02:46,730 --> 00:02:49,650
you can be a small effect

46
00:02:51,150 --> 00:02:51,910
so now

47
00:02:51,930 --> 00:02:58,320
i told you also that extension of the method which are here be

48
00:02:58,330 --> 00:03:01,230
and it would be nice

49
00:03:02,500 --> 00:03:04,410
we can define

50
00:03:04,590 --> 00:03:06,410
and then they get this

51
00:03:06,420 --> 00:03:10,460
and then when they get the exact solution is the very easy to to cooperate

52
00:03:10,530 --> 00:03:13,340
with the consequent on but it's also easy

53
00:03:13,790 --> 00:03:15,100
two at this

54
00:03:15,560 --> 00:03:19,150
we have also seen points on the walls

55
00:03:19,160 --> 00:03:21,780
well dictionary to have stuff

56
00:03:21,800 --> 00:03:24,370
which can be useful applications

57
00:03:25,190 --> 00:03:30,920
when you can use to replace the constraints but we had the

58
00:03:30,930 --> 00:03:34,190
by the consequent which induces sparsity

59
00:03:34,200 --> 00:03:36,960
so it was here use the media

60
00:03:36,970 --> 00:03:40,440
in the end to end one don't

61
00:03:40,450 --> 00:03:41,840
c five

62
00:03:41,860 --> 00:03:45,500
and as you can see that the constraint

63
00:03:45,520 --> 00:03:48,980
so here is the largest images show you

64
00:03:49,820 --> 00:03:51,310
what you can get

65
00:03:51,320 --> 00:03:55,980
so we have played with the and

66
00:03:55,990 --> 00:04:00,080
so the estimate shows get PCA

67
00:04:00,090 --> 00:04:01,400
so the

68
00:04:01,410 --> 00:04:05,020
the positive values

69
00:04:05,070 --> 00:04:08,330
and it is a low so here we have a dictionary

70
00:04:08,870 --> 00:04:11,820
which something is the

71
00:04:12,000 --> 00:04:14,550
forty nine months

72
00:04:14,560 --> 00:04:21,470
and when you use and if not they should have to make sure that

73
00:04:21,480 --> 00:04:22,570
there more

74
00:04:22,570 --> 00:04:26,460
located in the future we can look on the faces

75
00:04:26,470 --> 00:04:31,700
when using traditional methods used to make the right

76
00:04:31,740 --> 00:04:35,310
and what is interesting that using

77
00:04:35,320 --> 00:04:38,340
one you strategy by p

78
00:04:38,350 --> 00:04:42,070
we can update the same images were

79
00:04:42,070 --> 00:04:44,140
all this stuff

80
00:04:44,280 --> 00:04:50,640
so on the left we have seventy percent of the surface which is the one

81
00:04:50,640 --> 00:04:53,450
on the right hand

82
00:04:53,460 --> 00:04:54,560
so what

83
00:04:54,590 --> 00:04:55,990
so we have the

84
00:04:56,320 --> 00:04:59,090
i don't think about

85
00:04:59,100 --> 00:05:00,400
is this

86
00:05:00,980 --> 00:05:05,060
the age and let see

87
00:05:05,100 --> 00:05:09,810
the image on the medium is the decision

88
00:05:09,820 --> 00:05:12,050
so maybe is this

89
00:05:12,070 --> 00:05:13,330
it going

90
00:05:13,340 --> 00:05:16,780
you know that you can see i can see

91
00:05:16,840 --> 00:05:19,050
that is not

92
00:05:19,940 --> 00:05:20,930
they don't always

93
00:05:20,940 --> 00:05:22,220
the structure is

94
00:05:22,230 --> 00:05:24,440
well the first component of

95
00:05:24,450 --> 00:05:25,850
this is

96
00:05:26,210 --> 00:05:30,740
the dictionary show some structure which

97
00:05:30,800 --> 00:05:38,450
if you like like we did for this on the shape of the show

98
00:05:38,540 --> 00:05:45,570
there is a city which on the one

99
00:05:45,570 --> 00:05:48,180
the beginning of the second half of the story

100
00:05:48,210 --> 00:05:51,940
what to do now will actually so this thing here on the left is

101
00:05:52,030 --> 00:05:53,410
side the

102
00:05:53,420 --> 00:05:56,740
i think you get if you go to the site website and download the local

103
00:05:57,660 --> 00:05:59,490
so it's the ontology

104
00:05:59,500 --> 00:06:01,830
together with the reasoning engines

105
00:06:01,840 --> 00:06:05,670
and it but in this one allows also to edit to add new section in

106
00:06:05,880 --> 00:06:06,860
them and so on

107
00:06:06,880 --> 00:06:09,240
not individual at couple of

108
00:06:09,240 --> 00:06:11,970
new constants so if your social

109
00:06:12,020 --> 00:06:14,360
and also make it all the

110
00:06:14,380 --> 00:06:17,070
use these assertions to do something new knowledge

111
00:06:17,310 --> 00:06:19,940
and not that they would have

112
00:06:20,060 --> 00:06:24,560
we love the concept of oversight authority which is a collection of or

113
00:06:24,630 --> 00:06:27,810
all the time in order to support the site

114
00:06:28,050 --> 00:06:30,050
well the concept of michael witbrock

115
00:06:30,130 --> 00:06:31,440
and about

116
00:06:32,300 --> 00:06:35,520
presentation at the station here so

117
00:06:35,530 --> 00:06:36,700
the first three

118
00:06:36,810 --> 00:06:38,450
you have to create

119
00:06:39,280 --> 00:06:41,310
it's a great here

120
00:06:41,440 --> 00:06:47,240
we select the the constants through the web interface

121
00:06:48,210 --> 00:06:52,150
now we know that open sector because was sector has

122
00:06:52,210 --> 00:06:55,430
this is one of or

123
00:06:55,590 --> 00:07:00,070
now i will eat some assertions about this new constants

124
00:07:00,120 --> 00:07:03,620
that open sector tortoise is

125
00:07:03,630 --> 00:07:05,880
so collection of all the tutorials

126
00:07:05,930 --> 00:07:07,260
that means

127
00:07:07,270 --> 00:07:08,960
it is a journalist

128
00:07:09,540 --> 00:07:13,180
the total generalizes this oversight hours

129
00:07:14,980 --> 00:07:16,290
what you see here that

130
00:07:16,290 --> 00:07:20,310
these constraints kicked in telling us that

131
00:07:20,400 --> 00:07:22,900
so as not to be

132
00:07:22,990 --> 00:07:27,710
so a collection of the collection is to be collection itself first

133
00:07:28,900 --> 00:07:32,820
it is one sec is telling us and suggested that you can repair it can

134
00:07:32,950 --> 00:07:34,680
found this by adding this

135
00:07:34,810 --> 00:07:39,240
so the whole concept of forest is a collection

136
00:07:39,260 --> 00:07:41,570
thinking this

137
00:07:41,590 --> 00:07:44,460
i want this to this assertion in

138
00:07:44,460 --> 00:07:47,340
and if you click what what do we know about

139
00:07:47,370 --> 00:07:48,230
o percent

140
00:07:49,870 --> 00:07:53,980
so a collection of all the photos in its collection

141
00:07:54,070 --> 00:07:55,300
these are these

142
00:07:55,350 --> 00:07:58,830
constraints to talking before

143
00:07:58,850 --> 00:08:01,510
then we also have the assertion that

144
00:08:02,300 --> 00:08:06,080
an instance open borders

145
00:08:06,130 --> 00:08:09,070
and that

146
00:08:09,080 --> 00:08:10,660
four percent

147
00:08:12,070 --> 00:08:14,640
artificial intelligence

148
00:08:14,720 --> 00:08:16,000
is this

149
00:08:17,030 --> 00:08:20,880
we have the knowledge about of it just about michael witbrock

150
00:08:20,920 --> 00:08:21,860
it's not

151
00:08:21,880 --> 00:08:23,410
you know it was

152
00:08:26,540 --> 00:08:27,660
not yet

153
00:08:27,700 --> 00:08:29,110
now you

154
00:08:29,350 --> 00:08:32,880
and that he's the person so

155
00:08:34,350 --> 00:08:37,750
i could be got is the first

156
00:08:37,900 --> 00:08:40,670
and if you check whether that tell us so

157
00:08:40,750 --> 00:08:45,630
not much at the moment

158
00:08:47,540 --> 00:08:57,790
so we can ask is

159
00:08:57,800 --> 00:09:06,040
but for all the things that mikey east

160
00:09:06,100 --> 00:09:08,910
and he said that he person social being

161
00:09:09,000 --> 00:09:11,110
partiallytangible agent

162
00:09:11,260 --> 00:09:13,580
but tangible

163
00:09:15,600 --> 00:09:18,630
he's come posits you

164
00:09:27,610 --> 00:09:38,380
so we're just doing this

165
00:09:38,510 --> 00:09:43,140
semi automatic candidate for these things

166
00:09:44,410 --> 00:09:47,750
the constant

167
00:09:47,760 --> 00:09:51,300
which responds to this presentation this

168
00:09:55,630 --> 00:09:58,940
but it is an instance of presentations so this is this

169
00:10:02,290 --> 00:10:03,730
and he also

170
00:10:04,670 --> 00:10:11,730
well just to write it in the

171
00:10:12,040 --> 00:10:16,000
this instance of presentation

172
00:10:16,050 --> 00:10:20,020
so the ISWC site presentation

173
00:10:20,040 --> 00:10:24,890
o percent talk this was given this presentation

174
00:10:24,930 --> 00:10:26,460
what is this

175
00:10:26,690 --> 00:10:30,480
now we already not just below the

176
00:10:30,480 --> 00:10:33,850
at least in the propositional level

177
00:10:33,860 --> 00:10:37,770
as we move out of that is that there are other things about such as

178
00:10:37,770 --> 00:10:38,660
its ability

179
00:10:38,720 --> 00:10:40,390
to give us the basis

180
00:10:40,400 --> 00:10:42,140
for mathematics

181
00:10:42,160 --> 00:10:43,880
that's an extremely important

182
00:10:45,110 --> 00:10:47,700
classical mathematics is extremely important

183
00:10:48,050 --> 00:10:49,950
feature had

184
00:10:50,030 --> 00:10:52,460
not something to be a little

185
00:10:54,620 --> 00:10:57,650
will talk about non-classical mathematics a little bit

186
00:10:57,890 --> 00:11:02,050
in our last lecture

187
00:11:03,070 --> 00:11:06,980
although we don't talk about the intuitionist mathematics actually a couple minutes

188
00:11:09,390 --> 00:11:13,810
will get to the natural deduction proofs here in a few minutes

189
00:11:13,880 --> 00:11:14,710
the first

190
00:11:14,730 --> 00:11:20,380
non-classical logic we're going to talk about is intuitionist logic actually it's going to be

191
00:11:20,380 --> 00:11:25,660
something called well intuitions logic there something called minimal logic which isn't which should have

192
00:11:25,660 --> 00:11:29,730
been in your hands and the role of the stuff that actually gone through minimalist

193
00:11:29,730 --> 00:11:33,580
to because the first lecture i just put in

194
00:11:33,590 --> 00:11:37,120
the all stuff the huge amount of stuff on on

195
00:11:37,130 --> 00:11:40,350
just as a background two

196
00:11:40,560 --> 00:11:44,220
fitch style natural deduction was to get everybody up to speed

197
00:11:44,600 --> 00:11:50,140
i teach that in my courses to get everybody up to speed because we tend

198
00:11:50,140 --> 00:11:54,830
to use lower levels tableau based approaches and

199
00:11:54,860 --> 00:11:58,530
i think for the the largest we're talking about the tableau based approaches are very

200
00:12:01,390 --> 00:12:02,350
it's just

201
00:12:04,080 --> 00:12:06,070
then i'll get

202
00:12:06,080 --> 00:12:06,930
i mean there

203
00:12:07,230 --> 00:12:09,950
the ingenious people thought of them

204
00:12:10,000 --> 00:12:12,650
but they're not

205
00:12:12,730 --> 00:12:14,070
but anyway

206
00:12:14,470 --> 00:12:16,890
OK now

207
00:12:16,890 --> 00:12:19,870
despite what i just said about it

208
00:12:19,880 --> 00:12:27,060
classical mathematics being so important intuitionist logic group grew out of something called intuitionist mathematics

209
00:12:27,110 --> 00:12:30,070
very mature thought the very much what he's is thinking

210
00:12:31,790 --> 00:12:36,470
he could talks about the sort of mystical understanding of oneness and then

211
00:12:36,490 --> 00:12:39,060
two minutes which goes to it e

212
00:12:39,340 --> 00:12:43,310
which is also another unfortunate name but anyway he uses the sort of very mystical

213
00:12:43,310 --> 00:12:46,990
language to science that's the sort of

214
00:12:47,000 --> 00:12:49,410
directory of human intuition

215
00:12:51,030 --> 00:12:52,610
and structures

216
00:12:52,630 --> 00:12:56,990
and it's very interesting view what i think is actually very interesting read it it's

217
00:12:56,990 --> 00:12:59,890
not solely all assessed very

218
00:12:59,890 --> 00:13:06,410
strange different for people aren't used to thinking in mathematics and mystical terms

219
00:13:07,490 --> 00:13:10,030
likely it doesn't have to be thought of that way

220
00:13:11,240 --> 00:13:12,960
isn't just for the mistake

221
00:13:12,970 --> 00:13:18,310
back in the late fifties and early sixties other people

222
00:13:29,810 --> 00:13:34,410
cleaning doesn't get enough stephen cleaning doesn't get enough credit for this

223
00:13:34,470 --> 00:13:37,950
but he developed was called the realizability interpretation

224
00:13:37,960 --> 00:13:39,690
intuition is

225
00:13:39,710 --> 00:13:42,730
and michael dominant

226
00:13:42,740 --> 00:13:47,780
well he did help develop the sort of

227
00:13:47,830 --> 00:13:50,610
non mystical version as well

228
00:13:50,630 --> 00:13:54,450
he talks about a lot unfortunately he often

229
00:13:54,480 --> 00:13:56,200
lapses into

230
00:13:56,210 --> 00:13:58,420
now mystical version that's kind of

231
00:13:58,430 --> 00:14:01,210
he contradicts himself

232
00:14:01,230 --> 00:14:03,420
it's very annoying phosphor in that way

233
00:14:06,000 --> 00:14:07,900
the idea is quite simple

234
00:14:08,940 --> 00:14:10,990
the problem the problem is this

235
00:14:11,040 --> 00:14:12,810
well brower was

236
00:14:12,820 --> 00:14:14,700
fighting against

237
00:14:16,680 --> 00:14:19,180
classical set theory

238
00:14:19,200 --> 00:14:22,400
and all of you know a little bit about and one of the things about

239
00:14:22,430 --> 00:14:24,410
classical set theory

240
00:14:24,450 --> 00:14:27,360
is its treatment of infinity

241
00:14:28,540 --> 00:14:29,650
what about

242
00:14:29,710 --> 00:14:37,390
intended insert their what is it that you found strange when i first learned about

243
00:14:40,210 --> 00:14:42,920
let me a lot of sense to the first time you heard that

244
00:14:43,120 --> 00:14:47,110
the very first time i think not now right you know you understand now

245
00:14:47,180 --> 00:14:50,380
right because you you've been grilled

246
00:14:50,390 --> 00:14:52,590
the very first time i heard that

247
00:14:52,630 --> 00:14:54,960
seem pretty strange right

248
00:14:55,020 --> 00:14:57,540
different sizes of infinity

249
00:14:57,540 --> 00:14:58,340
in the results

250
00:14:58,900 --> 00:15:00,540
you need best

251
00:15:05,240 --> 00:15:06,450
i was talking about

252
00:15:07,400 --> 00:15:07,870
three or four

253
00:15:10,840 --> 00:15:12,240
he he the

254
00:15:13,460 --> 00:15:14,310
and animation of it

255
00:15:14,800 --> 00:15:15,860
it you want

256
00:15:16,000 --> 00:15:18,140
one three cluster start with three

257
00:15:19,020 --> 00:15:20,850
cluster centers the seed points

258
00:15:21,450 --> 00:15:23,810
assign points to the closest cluster centre

259
00:15:24,250 --> 00:15:24,980
we don't do that

260
00:15:25,400 --> 00:15:26,490
the to

261
00:15:27,720 --> 00:15:28,040
that's all

262
00:15:29,620 --> 00:15:30,960
and typically

263
00:15:31,270 --> 00:15:31,650
what is

264
00:15:32,350 --> 00:15:35,380
regimes extremely fast as the fastest growing

265
00:15:36,650 --> 00:15:39,820
you run many times with different initializations

266
00:15:47,580 --> 00:15:48,830
this is the first one

267
00:15:48,940 --> 00:15:50,370
that's an isolated clusters

268
00:15:51,330 --> 00:15:52,040
the measure

269
00:15:52,230 --> 00:15:54,290
similarities between the

270
00:15:55,450 --> 00:15:56,230
it is based on the

271
00:15:58,780 --> 00:16:02,150
those are your points that they constantly distances

272
00:16:03,330 --> 00:16:03,610
a sphere

273
00:16:04,240 --> 00:16:06,290
so basically refers to find

274
00:16:07,300 --> 00:16:08,310
just chat

275
00:16:08,780 --> 00:16:11,210
of similar size of nicely

276
00:16:12,520 --> 00:16:13,080
the data

277
00:16:13,880 --> 00:16:14,320
has in

278
00:16:15,170 --> 00:16:17,900
twenty years from and they find two clusters

279
00:16:18,320 --> 00:16:19,780
it was little bit like this

280
00:16:20,990 --> 00:16:21,640
the ones the

281
00:16:24,330 --> 00:16:24,540
but in

282
00:16:26,230 --> 00:16:28,820
so basically can be used to refer to find

283
00:16:30,150 --> 00:16:31,330
linearly separated

284
00:16:33,500 --> 00:16:34,020
and not

285
00:16:38,170 --> 00:16:39,820
nonlinear separation

286
00:16:40,250 --> 00:16:41,080
that's why are

287
00:16:45,220 --> 00:16:46,620
classification you

288
00:16:49,590 --> 00:16:50,340
the image

289
00:16:50,980 --> 00:16:55,640
it's actually trying to decide not just that he needs any clustering together

290
00:16:56,620 --> 00:16:57,360
see the

291
00:16:57,990 --> 00:16:58,570
my attention

292
00:17:00,120 --> 00:17:00,520
is there

293
00:17:01,080 --> 00:17:03,300
you find it in a randomly generated

294
00:17:03,840 --> 00:17:05,760
in this case you want to mention

295
00:17:06,740 --> 00:17:08,830
and i think it needs to it

296
00:17:09,390 --> 00:17:10,630
and you need to find

297
00:17:12,090 --> 00:17:13,770
clusters it

298
00:17:14,830 --> 00:17:16,420
so that's why we should have some

299
00:17:18,090 --> 00:17:18,560
you know the

300
00:17:22,340 --> 00:17:24,470
say anything about the number clusters in

301
00:17:24,990 --> 00:17:25,520
the same data

302
00:17:26,110 --> 00:17:28,150
it is it to be able to

303
00:17:28,940 --> 00:17:30,650
you before it was five

304
00:17:31,520 --> 00:17:33,620
someone who's the user

305
00:17:35,050 --> 00:17:38,650
who that it is trying to form hypothesis about

306
00:17:39,690 --> 00:17:40,950
so all have

307
00:17:41,260 --> 00:17:42,700
quantitative measurement of

308
00:17:44,280 --> 00:17:45,740
was the last round

309
00:17:46,850 --> 00:17:47,820
in high dimensions

310
00:17:51,370 --> 00:17:51,670
use the

311
00:17:52,850 --> 00:17:55,310
but at the least makes sense

312
00:17:57,670 --> 00:17:58,330
so he

313
00:17:58,860 --> 00:18:01,170
think about you which model to the data

314
00:18:02,340 --> 00:18:04,780
this is a very powerful message if you know the

315
00:18:05,850 --> 00:18:08,510
in this case goes here is appropriate

316
00:18:09,440 --> 00:18:10,490
information about the

317
00:18:12,300 --> 00:18:13,330
it is found three

318
00:18:16,170 --> 00:18:17,350
with the world

319
00:18:18,950 --> 00:18:20,310
in fact this at the time

320
00:18:20,850 --> 00:18:21,960
designed by my father

321
00:18:23,060 --> 00:18:23,700
and about

322
00:18:24,960 --> 00:18:26,370
automatically finds the

323
00:18:28,680 --> 00:18:30,560
but if the model is not correct

324
00:18:31,320 --> 00:18:32,330
then it will not work

325
00:18:34,380 --> 00:18:34,700
so now

326
00:18:35,120 --> 00:18:35,760
let me go through

327
00:18:39,090 --> 00:18:40,280
that is the nature of

328
00:18:40,990 --> 00:18:41,690
it means that the

329
00:18:44,620 --> 00:18:45,470
kernel approach

330
00:18:45,980 --> 00:18:47,850
the idea is to project the data

331
00:18:48,780 --> 00:18:51,440
from the given dimensions to higher education

332
00:18:52,040 --> 00:18:53,230
in the case

333
00:18:54,790 --> 00:18:57,370
so we have two dimensional data consists

334
00:18:59,130 --> 00:18:59,750
which is

335
00:19:00,300 --> 00:19:00,920
cannot find

336
00:19:01,730 --> 00:19:02,650
so how you

337
00:19:02,830 --> 00:19:03,870
the mapping function

338
00:19:05,120 --> 00:19:05,820
which can be

339
00:19:06,300 --> 00:19:07,420
x one point

340
00:19:07,900 --> 00:19:08,270
you do

341
00:19:09,010 --> 00:19:12,700
three dimensional space x words were to explain why

342
00:19:14,520 --> 00:19:17,170
at this two-dimensional three-dimensional

343
00:19:18,260 --> 00:19:19,360
the two clusters

344
00:19:22,510 --> 00:19:23,270
and now and

345
00:19:27,130 --> 00:19:28,940
why is he is he possible

346
00:19:30,870 --> 00:19:32,050
so this is this is a

347
00:19:32,570 --> 00:19:34,670
instance as well as long as are

348
00:19:35,840 --> 00:19:37,030
well what on

349
00:19:37,750 --> 00:19:38,270
on the

350
00:19:39,350 --> 00:19:40,070
this function

351
00:19:42,560 --> 00:19:46,090
which currently the most appropriate that's designed parameter

352
00:19:46,570 --> 00:19:47,240
and how to

353
00:19:48,560 --> 00:19:51,520
there also sigma squared

354
00:19:54,670 --> 00:19:55,270
so this is

355
00:19:56,140 --> 00:19:56,970
the answer

356
00:19:57,060 --> 00:19:57,880
cross validation

357
00:20:01,770 --> 00:20:06,620
what are the spectral clustering the same thing as the we don't you

358
00:20:07,500 --> 00:20:10,280
so there are no matrix is the number of clusters

359
00:20:10,450 --> 00:20:10,990
and this is

360
00:20:12,310 --> 00:20:13,790
the kernel matrix of the data

361
00:20:14,370 --> 00:20:15,350
you got you are

362
00:20:15,460 --> 00:20:16,360
we find that

363
00:20:17,820 --> 00:20:21,220
the most this this is what i is that in nineteen

364
00:20:21,610 --> 00:20:22,460
and data

365
00:20:23,040 --> 00:20:24,290
can be easily clustering

366
00:20:26,080 --> 00:20:28,290
so the representation e

367
00:20:31,260 --> 00:20:33,190
semantic representation to make

368
00:20:37,120 --> 00:20:38,420
so some companies

369
00:20:39,000 --> 00:20:39,640
he was

370
00:20:40,670 --> 00:20:43,800
please let me show you some examples you

371
00:20:45,290 --> 00:20:46,030
so here's

372
00:20:46,350 --> 00:20:49,060
datasets were he doesn't work

373
00:20:50,680 --> 00:20:52,760
but that's the point without any

374
00:20:54,340 --> 00:20:56,060
this is completely unlabeled data

375
00:20:57,390 --> 00:20:58,140
like he's

376
00:20:59,580 --> 00:21:00,840
it is found in

377
00:21:01,260 --> 00:21:04,690
the ones one cluster one cluster

378
00:21:05,380 --> 00:21:06,370
same thing this one

379
00:21:07,340 --> 00:21:08,300
not finding it

380
00:21:13,750 --> 00:21:15,040
but it doesn't

381
00:21:20,850 --> 00:21:22,630
we have to understand the kernel

382
00:21:22,630 --> 00:21:26,690
now have seen that we have we to live in the same

383
00:21:26,700 --> 00:21:28,560
as early as possible

384
00:21:28,570 --> 00:21:30,960
they don't they don't

385
00:21:30,980 --> 00:21:34,040
chain and this would require some four

386
00:21:34,060 --> 00:21:39,490
so far and some just taking the decision was example the fundamental security industry industry-funded

387
00:21:39,540 --> 00:21:42,350
c which is called the fido of mary

388
00:21:42,370 --> 00:21:48,370
and which is just the follow the ADC divided by the two teams

389
00:21:48,440 --> 00:21:51,830
to support effective number of bits that

390
00:21:51,830 --> 00:21:54,820
times has a sampling frequency so you get

391
00:21:55,750 --> 00:22:01,430
p called rule of thumb to improve conditions in bone twenty five micrometer we form

392
00:22:02,410 --> 00:22:06,320
this region one because this if we go to

393
00:22:06,330 --> 00:22:14,880
sixty five millimetre we can expect because that's representation caulfield ADC with this kind of

394
00:22:14,930 --> 00:22:16,260
if you're

395
00:22:16,260 --> 00:22:21,600
so then lets example i guarantee which is we have two key challenges for the

396
00:22:21,600 --> 00:22:24,190
atlas calorimeter we want to i fifteen

397
00:22:24,220 --> 00:22:28,980
the effective number of bits forty million this would require two hundred and sixty kilowatt

398
00:22:29,000 --> 00:22:32,780
with this technology so i think you know what is this one

399
00:22:32,800 --> 00:22:33,850
so we have

400
00:22:33,870 --> 00:22:36,560
we lose about in terms of using the

401
00:22:37,250 --> 00:22:42,130
this technology was not alone in jail in engineering because now if i look at

402
00:22:42,160 --> 00:22:46,250
what is the growth of the power supplies which are needed to put that we

403
00:22:47,010 --> 00:22:52,540
quite a lot because we are not using cheap oil supplies y that because we

404
00:22:52,540 --> 00:22:56,080
need to have avoid auditioned on supply so it's not something that you just by

405
00:22:57,380 --> 00:23:01,700
it's it's special because lots so you could say that million two million trees five

406
00:23:01,720 --> 00:23:02,990
and on the

407
00:23:03,030 --> 00:23:08,500
when the ball supply and so that they can only material they don't speak of

408
00:23:08,500 --> 00:23:13,940
fifteen million channels could imagine what it means you have made it would it would

409
00:23:13,940 --> 00:23:18,760
you know you what's in fact apply all the tricks him but

410
00:23:18,780 --> 00:23:19,930
but you see there

411
00:23:19,980 --> 00:23:22,090
it's it's really important

412
00:23:25,410 --> 00:23:30,130
the government that is does that yes it got something to to use

413
00:23:30,800 --> 00:23:35,630
modem technology because in terms of money cost in terms of human investment because you

414
00:23:35,630 --> 00:23:37,330
have to spend some time in the

415
00:23:37,680 --> 00:23:38,890
what can do

416
00:23:40,390 --> 00:23:43,180
what we need is at the end payoff

417
00:23:44,130 --> 00:23:47,490
what would be a for the

418
00:23:47,570 --> 00:23:50,810
electronics and in fact to to tell you what

419
00:23:50,830 --> 00:23:56,840
if g is and how do we hold on this kind of very

420
00:23:56,870 --> 00:24:01,800
so that's the typical block detector clinic so you receive

421
00:24:01,810 --> 00:24:06,510
from the impending fault and intuitive that

422
00:24:06,530 --> 00:24:11,320
and then you want this is where where you have to check for that the

423
00:24:11,330 --> 00:24:16,690
choices are quite you have to make some data processing could be done for doing

424
00:24:17,150 --> 00:24:24,100
it could be just see also questioned it could be a portion of that anything

425
00:24:24,160 --> 00:24:28,000
and then you have to prepare for each event you have to prepare

426
00:24:28,010 --> 00:24:29,730
and even to

427
00:24:29,740 --> 00:24:33,230
thank you for your follow-up and then you have to show that

428
00:24:33,240 --> 00:24:35,330
to that acquisition system

429
00:24:35,340 --> 00:24:39,660
in addition to get it said that there that you will have some interface to

430
00:24:40,450 --> 00:24:42,090
to the training in ten years

431
00:24:42,090 --> 00:24:45,630
because you have to know when you go to three you you have to know

432
00:24:45,630 --> 00:24:47,520
when there's

433
00:24:47,530 --> 00:24:51,600
you also point here some

434
00:24:51,630 --> 00:24:55,530
twenty clinics and some many times so you are you have to be able hear

435
00:24:55,590 --> 00:25:00,580
to sample the number of runs for making look at least six

436
00:25:00,590 --> 00:25:04,480
so don't think that we have

437
00:25:04,490 --> 00:25:07,410
and none of the film medium i just couldn't

438
00:25:07,430 --> 00:25:12,010
some of the things we see a lot of them are are using the mean

439
00:25:12,010 --> 00:25:13,630
different from factor

440
00:25:13,680 --> 00:25:19,090
i don't want to discard all of that but i want to talk about it

441
00:25:22,610 --> 00:25:26,500
and the point where you live to be expanded called ten one but i want

442
00:25:26,500 --> 00:25:29,500
to talk about all these big things here

443
00:25:29,520 --> 00:25:32,800
but you see which FPGA

444
00:25:35,040 --> 00:25:36,610
so what have you

445
00:25:36,630 --> 00:25:40,800
and is the is the secretary which he you about six of

446
00:25:40,940 --> 00:25:45,330
first of all i will block green

447
00:25:45,330 --> 00:25:48,270
which are interconnected

448
00:25:49,590 --> 00:25:51,880
with their a and also

449
00:25:51,900 --> 00:25:56,730
with switches so you have to choose all of the place so that you can

450
00:25:58,140 --> 00:26:04,720
any connection that you region between one of block in the

451
00:26:04,720 --> 00:26:09,840
this is which means that when you get that you have nothing inside business and

452
00:26:09,840 --> 00:26:13,830
then you will put you know and i don't know knowing that that would be

453
00:26:13,830 --> 00:26:16,770
fine we define what you will

454
00:26:17,240 --> 00:26:21,720
in the user's block and what we were doing definition

455
00:26:21,730 --> 00:26:26,620
in addition to that you've got some input output so we could do you want

456
00:26:26,630 --> 00:26:28,040
to do this

457
00:26:28,060 --> 00:26:31,340
she that is in some sense

458
00:26:31,370 --> 00:26:38,670
and you've got the number of possible number of input and output with the capability

459
00:26:38,670 --> 00:26:44,020
of state in which a particular value one to use the syntax so that something

460
00:26:44,020 --> 00:26:46,820
which looks very extreme

461
00:26:46,850 --> 00:26:48,600
in addition to that the

462
00:26:49,080 --> 00:26:55,260
you have inside some some generic blocks like class distribution system so when you have

463
00:26:55,500 --> 00:27:00,350
when you have a second system you have to distribute the close to different elements

464
00:27:00,360 --> 00:27:03,990
and you have to be careful with the flat face of the clock really separate

465
00:27:03,990 --> 00:27:08,990
inside which is built in which allows you to control the face of the clock

466
00:27:08,990 --> 00:27:10,880
to different places

467
00:27:10,920 --> 00:27:17,330
you have some memory blocks embedded with which you can make five full-time you just

468
00:27:17,360 --> 00:27:18,650
made by you harm

469
00:27:18,670 --> 00:27:21,720
what you want and you have special blocks line

470
00:27:21,800 --> 00:27:24,570
DSP so does posses or block

471
00:27:24,590 --> 00:27:30,080
even on but michael posner selma michael berthold also you have an unbelievable influence in

472
00:27:30,080 --> 00:27:34,320
this in can and you can download you can you can ask you to outline

473
00:27:34,320 --> 00:27:41,530
some software that you have very useful forces you've got also i been so you

474
00:27:44,740 --> 00:27:46,830
so the beginning of the

475
00:27:46,860 --> 00:27:48,910
the PGA

476
00:27:49,030 --> 00:27:52,390
you look at the bottom

477
00:27:54,810 --> 00:27:58,720
so in the get the lookup table the number of inputs data to the but

478
00:27:58,720 --> 00:28:02,300
it's it's like it's like any more

479
00:28:03,020 --> 00:28:08,490
in which you are you will use millions of these would these a b c

480
00:28:08,510 --> 00:28:16,170
d so before before you making the cheap working you will you will load the

481
00:28:16,200 --> 00:28:19,490
the content of the mainly with the values that you want to get to the

482
00:28:19,490 --> 00:28:21,120
mine you

483
00:28:21,180 --> 00:28:25,620
now that i'm

484
00:28:25,680 --> 00:28:27,100
i can take

485
00:28:28,560 --> 00:28:32,120
derivative of this equation so i get on the left side

486
00:28:32,140 --> 00:28:33,470
the dp

487
00:28:33,720 --> 00:28:39,240
pt is going to be zero

488
00:28:39,300 --> 00:28:41,160
so we get zero

489
00:28:43,700 --> 00:28:45,530
times DVD

490
00:28:45,600 --> 00:28:47,410
the DVD is the accent

491
00:28:51,390 --> 00:28:53,640
the NDP

492
00:28:53,780 --> 00:28:58,370
and that is the thrust

493
00:28:58,410 --> 00:28:59,660
on the rocket

494
00:28:59,680 --> 00:29:02,080
so what you see here is something

495
00:29:02,100 --> 00:29:04,060
it's very easy to digest

496
00:29:04,160 --> 00:29:06,310
and they which is the

497
00:29:06,330 --> 00:29:09,430
this is the acceleration of the rocket this is the mass of the rocket at

498
00:29:09,430 --> 00:29:10,600
time t

499
00:29:11,810 --> 00:29:14,220
the thrust of the rocket

500
00:29:14,280 --> 00:29:15,700
and that equal

501
00:29:18,660 --> 00:29:19,890
the team

502
00:29:19,930 --> 00:29:21,010
and some people

503
00:29:21,030 --> 00:29:22,620
we call this the

504
00:29:22,660 --> 00:29:25,350
the rocket equation

505
00:29:25,390 --> 00:29:27,260
now this is true

506
00:29:28,890 --> 00:29:32,660
there is no external force on the system

507
00:29:32,720 --> 00:29:35,850
it is interesting to include

508
00:29:35,870 --> 00:29:38,140
a real loans from earth

509
00:29:38,220 --> 00:29:40,970
and if you have a real entrepreneurs

510
00:29:42,620 --> 00:29:45,300
the rocket is going up in this direction

511
00:29:45,350 --> 00:29:46,470
but then gravity

512
00:29:46,490 --> 00:29:48,660
is exactly the opposite direction

513
00:29:48,760 --> 00:29:52,640
in other words only when you launch vertically from our earth

514
00:29:52,660 --> 00:29:54,580
what you have

515
00:29:54,640 --> 00:29:56,240
thrust like this

516
00:29:56,390 --> 00:29:58,370
and you would have

517
00:29:58,410 --> 00:29:59,930
and you like this

518
00:29:59,970 --> 00:30:01,640
in that case

519
00:30:01,640 --> 00:30:03,180
this equation

520
00:30:03,200 --> 00:30:04,600
has to be

521
00:30:04,600 --> 00:30:07,450
just it and then you get a

522
00:30:07,470 --> 00:30:09,990
he equals and throws

523
00:30:11,140 --> 00:30:12,060
and g

524
00:30:12,950 --> 00:30:17,430
if you have a launch from earth vertically up

525
00:30:17,430 --> 00:30:20,660
now you have to do a little bit of massaging and i'll leave you with

526
00:30:20,660 --> 00:30:22,010
that massaging

527
00:30:22,060 --> 00:30:24,220
a couple of integrals are necessary

528
00:30:24,310 --> 00:30:27,390
to convert this into the final

529
00:30:27,430 --> 00:30:29,180
the velocity of the

530
00:30:29,240 --> 00:30:32,310
rocket after the birth

531
00:30:32,310 --> 00:30:35,510
compared to the initial velocity

532
00:30:35,560 --> 00:30:38,310
and that part i believe you wish but you will see that worked out in

533
00:30:38,310 --> 00:30:39,620
all the tail

534
00:30:39,640 --> 00:30:42,720
on the notes that i left on the web

535
00:30:42,720 --> 00:30:46,810
and then you come up with a very famous equation that the final velocity of

536
00:30:46,810 --> 00:30:50,310
the rocket minus the initial velocity of the rocket

537
00:30:50,350 --> 00:30:51,990
equals minus you

538
00:30:51,990 --> 00:30:53,450
times the logarithm

539
00:30:53,490 --> 00:30:55,490
of the final mass of the rocket

540
00:30:55,530 --> 00:30:56,760
divided by

541
00:30:56,760 --> 00:30:58,970
initial mass of the rocket

542
00:30:58,990 --> 00:31:00,560
this is if there were

543
00:31:00,620 --> 00:31:02,680
no gravity at all

544
00:31:02,760 --> 00:31:06,890
just in case and only in case of a vertical launch from earth

545
00:31:06,930 --> 00:31:09,100
there is also year terms

546
00:31:11,540 --> 00:31:13,930
only if you have a vertical launch

547
00:31:17,760 --> 00:31:21,800
when i want my lecture i noted in my enthusiasm i put brackets around the

548
00:31:21,800 --> 00:31:23,680
minus gt

549
00:31:23,870 --> 00:31:27,370
this is quite misleading because it may give you the wrong impression

550
00:31:27,430 --> 00:31:30,560
that the product it's taking which is not so

551
00:31:30,620 --> 00:31:34,180
so the brackets really should not be around to his duty

552
00:31:34,220 --> 00:31:35,640
it is this term

553
00:31:35,640 --> 00:31:37,510
mine you logarithms

554
00:31:37,510 --> 00:31:38,560
of MF

555
00:31:38,580 --> 00:31:40,740
divided by amplify

556
00:31:40,780 --> 00:31:43,620
minus gt

557
00:31:43,700 --> 00:31:46,260
let's now look at this equation in a little bit more detail

558
00:31:46,280 --> 00:31:48,810
so we get a little bit of feeling for it

559
00:31:48,910 --> 00:31:51,530
suppose we had a vertical launch from

560
00:31:51,640 --> 00:31:53,390
but we had no rockets

561
00:31:53,390 --> 00:31:55,410
it's possible

562
00:31:55,430 --> 00:31:58,180
so but this term does not exist

563
00:31:58,180 --> 00:31:59,450
what you see

564
00:31:59,490 --> 00:32:01,580
that the velocity

565
00:32:01,600 --> 00:32:02,530
he calls

566
00:32:02,560 --> 00:32:07,640
the initial we have called that before anyone one p zero initial speed

567
00:32:11,100 --> 00:32:13,390
we had that was ill during our first like

568
00:32:13,450 --> 00:32:17,420
completely consistent with this equation if you have no rocket you get that v equals

569
00:32:17,420 --> 00:32:23,030
three zero minus if you strongly object vertically up and we had a vertical launch

570
00:32:23,080 --> 00:32:25,600
so that looks good

571
00:32:25,620 --> 00:32:28,040
we learned from the earth

572
00:32:28,060 --> 00:32:29,810
and we know

573
00:32:29,830 --> 00:32:31,510
have initial speeds

574
00:32:31,530 --> 00:32:35,430
which is zero rocket is standing there

575
00:32:35,430 --> 00:32:40,560
and we fired rockets the by the way is the burn time of the rock

576
00:32:40,560 --> 00:32:42,260
we write that down t

577
00:32:42,390 --> 00:32:44,850
is the first time

578
00:32:44,890 --> 00:32:50,780
so initial speed is zero

579
00:32:50,810 --> 00:32:53,370
so now

580
00:32:53,370 --> 00:32:56,830
this final velocity if we want find velocity be

581
00:32:56,830 --> 00:33:01,080
anything physically meaningful positive number

582
00:33:01,100 --> 00:33:04,220
this thing has to come out positive USA

583
00:33:04,280 --> 00:33:05,850
how can that be

584
00:33:05,890 --> 00:33:08,910
because we have a minus sign here and we have a minus sign there how

585
00:33:08,910 --> 00:33:11,200
can ever become positive well

586
00:33:11,200 --> 00:33:12,240
don't forget

587
00:33:13,450 --> 00:33:15,620
the final math

588
00:33:15,620 --> 00:33:18,160
space not what is this

589
00:33:18,310 --> 00:33:19,510
what is it

590
00:33:19,780 --> 00:33:23,330
so we want to be famous

591
00:33:24,870 --> 00:33:27,740
he was used

592
00:33:27,760 --> 00:33:30,850
what is it

593
00:33:35,580 --> 00:33:37,310
so are

594
00:33:40,200 --> 00:33:42,640
sixty years

595
00:33:42,660 --> 00:33:44,160
and random

596
00:33:48,180 --> 00:33:51,970
so this nomination is

597
00:33:52,140 --> 00:33:57,740
actually smaller distances that so few month

598
00:33:57,950 --> 00:34:02,240
this is at the end

599
00:34:02,260 --> 00:34:05,350
most of you know that we have

600
00:34:05,430 --> 00:34:07,450
so that it

601
00:34:07,530 --> 00:34:10,560
since is zero

602
00:34:10,560 --> 00:34:11,950
user base

603
00:34:11,970 --> 00:34:16,310
the function space

604
00:34:17,280 --> 00:34:24,490
and also normalize contrast skin so dimensions space

605
00:34:24,560 --> 00:34:33,240
it is almost constant is close to zero it turns out that in seen significant

606
00:34:33,330 --> 00:34:35,660
lots of data

607
00:34:35,740 --> 00:34:39,580
is actually response to the world

608
00:34:40,470 --> 00:34:42,200
use that you've seen

609
00:34:42,200 --> 00:34:44,470
i just before

610
00:34:44,490 --> 00:34:46,450
is well

611
00:34:46,560 --> 00:34:49,930
because we want to say that

612
00:34:50,010 --> 00:34:52,790
prosperity is

613
00:34:52,810 --> 00:34:54,890
and normalized the

614
00:34:54,950 --> 00:34:57,680
fact and so what had was

615
00:34:59,200 --> 00:35:01,080
not on

616
00:35:01,100 --> 00:35:04,790
but as said mister here so

617
00:35:06,580 --> 00:35:09,100
so we don't lose trust

618
00:35:09,120 --> 00:35:12,030
that is we can do cross his

619
00:35:12,410 --> 00:35:14,890
and now we have a sense here

620
00:35:14,910 --> 00:35:17,910
of data as an expression is

621
00:35:17,950 --> 00:35:22,370
instance action is

622
00:35:24,030 --> 00:35:29,450
there no have databases collect four points

623
00:35:29,830 --> 00:35:33,780
statistical distribution

624
00:35:33,830 --> 00:35:40,010
of the city the fall we randomly chosen actually

625
00:35:40,030 --> 00:35:42,830
the statistical distribution of sense

626
00:35:43,990 --> 00:35:46,200
is one fashion

627
00:35:46,260 --> 00:35:48,720
it doesn't come close here

628
00:35:48,740 --> 00:35:50,260
it's not issue

629
00:35:50,290 --> 00:35:53,870
it's not really what you say about

630
00:35:53,890 --> 00:35:59,720
this is what i need to grow and team decided to

631
00:35:59,740 --> 00:36:02,100
play in this talk

632
00:36:04,280 --> 00:36:08,240
the set of

633
00:36:08,260 --> 00:36:10,100
this to is

634
00:36:10,120 --> 00:36:15,680
there an industrial center but it is not

635
00:36:15,680 --> 00:36:17,930
right there is the need

636
00:36:17,950 --> 00:36:21,790
this is kind of action

637
00:36:21,830 --> 00:36:25,660
one thousand eight inches

638
00:36:26,600 --> 00:36:28,870
actually very very high

639
00:36:28,930 --> 00:36:31,260
because you

640
00:36:31,280 --> 00:36:36,470
you made me love you know what we see here

641
00:36:36,490 --> 00:36:39,910
the transition between one constant college

642
00:36:39,930 --> 00:36:42,410
one one

643
00:36:43,100 --> 00:36:46,310
would like to review

644
00:36:50,450 --> 00:36:54,180
and if i o

645
00:36:54,180 --> 00:36:54,970
and this

646
00:36:56,180 --> 00:36:58,120
this is

647
00:37:03,030 --> 00:37:07,890
as soon as it was

648
00:37:07,910 --> 00:37:10,510
one species

649
00:37:10,510 --> 00:37:12,870
and you see that in space is

650
00:37:12,890 --> 00:37:15,810
of these there is

651
00:37:15,830 --> 00:37:17,740
what is

652
00:37:20,310 --> 00:37:23,080
we have

653
00:37:23,180 --> 00:37:27,060
this is not the right

654
00:37:28,810 --> 00:37:31,010
you see

655
00:37:31,080 --> 00:37:35,810
this is actually on these

656
00:37:35,810 --> 00:37:36,870
and this

657
00:37:39,200 --> 00:37:42,560
so that's

658
00:37:45,560 --> 00:37:50,010
he is the a sense in some there's not this

659
00:37:50,010 --> 00:37:55,350
so my mind is that as far as it concerns

660
00:37:55,370 --> 00:38:00,100
to take this into

661
00:38:00,510 --> 00:38:02,200
i the

662
00:38:02,240 --> 00:38:06,010
the hardest part

663
00:38:06,030 --> 00:38:07,850
missus the public

664
00:38:09,050 --> 00:38:12,510
we all conditions in this

665
00:38:14,140 --> 00:38:15,430
and this

666
00:38:15,450 --> 00:38:18,890
it is

667
00:38:20,510 --> 00:38:24,640
in response

668
00:38:24,640 --> 00:38:25,310
we to

669
00:38:25,330 --> 00:38:33,010
since the sentence inside out

670
00:38:33,060 --> 00:38:34,370
it is

671
00:38:34,370 --> 00:38:35,660
my point

672
00:38:35,850 --> 00:38:38,850
have to decide which ones

673
00:38:41,560 --> 00:38:45,850
not be the density estimation

674
00:38:47,830 --> 00:38:50,580
there is only

675
00:38:50,600 --> 00:38:52,470
one of the problems

676
00:38:52,810 --> 00:38:54,660
i see

677
00:38:54,890 --> 00:38:56,700
you decide

678
00:38:57,740 --> 00:39:03,450
it is rational for use of this

679
00:39:03,640 --> 00:39:05,100
initially i

680
00:39:05,140 --> 00:39:05,720
it is

681
00:39:07,890 --> 00:39:12,220
have some density estimation function

682
00:39:12,260 --> 00:39:14,350
but you decide how much

683
00:39:14,490 --> 00:39:20,530
so we can use named entities as well

684
00:39:21,200 --> 00:39:23,680
for point

685
00:39:23,700 --> 00:39:25,680
cincinnati is

686
00:39:25,680 --> 00:39:28,550
one hundred thousand dollars

687
00:39:28,560 --> 00:39:29,930
when you

688
00:39:29,950 --> 00:39:32,280
one hundred years

689
00:39:32,290 --> 00:39:38,240
we on this is the

690
00:39:38,240 --> 00:39:44,150
so the model free solutions we cover

691
00:39:45,540 --> 00:39:50,110
monte carlo

692
00:39:50,750 --> 00:39:53,450
k k one

693
00:39:53,500 --> 00:39:55,520
what is michaela sample from

694
00:39:55,580 --> 00:39:59,430
the next day return full return

695
00:39:59,450 --> 00:40:01,510
before it right

696
00:40:04,090 --> 00:40:09,520
temporal difference

697
00:40:10,390 --> 00:40:19,930
sample obviously from the next returned

698
00:40:24,460 --> 00:40:26,520
next day return

699
00:40:26,540 --> 00:40:33,360
the next day OK let's let's let's cut the next reward

700
00:40:33,400 --> 00:40:42,800
plus the next state value estimate

701
00:40:42,810 --> 00:40:45,220
get good

702
00:40:45,260 --> 00:40:47,880
OK so if you with me with this thing you've got the basic idea is

703
00:40:47,880 --> 00:40:49,710
to what you need

704
00:40:49,720 --> 00:40:54,560
OK you need team know how this problem the probability that slowly so let's how

705
00:40:54,580 --> 00:40:57,590
how do we improve on the original

706
00:40:57,610 --> 00:41:02,610
OK by this is the book is very unified very nice view of all the

707
00:41:02,610 --> 00:41:06,930
methods that discovered so let me discover that one more time so that two dimensions

708
00:41:06,930 --> 00:41:10,460
here that we see on this on the vertical axis

709
00:41:10,500 --> 00:41:13,010
at the top we have full backups

710
00:41:13,040 --> 00:41:16,130
that means you sample or next states

711
00:41:16,170 --> 00:41:21,250
and in the bottom we assemble backup with fifty samples from transitions

712
00:41:22,760 --> 00:41:24,470
and under given policy

713
00:41:24,550 --> 00:41:29,500
on the horizontal axis we have shall backups it is one step back and on

714
00:41:30,370 --> 00:41:34,530
right hand side we have the backup meaning all eighty and

715
00:41:34,540 --> 00:41:37,080
OK so if you look at sample backups

716
00:41:37,120 --> 00:41:41,300
there are deep you get the money method selects the shell different methods

717
00:41:41,380 --> 00:41:43,260
you look for backups

718
00:41:43,270 --> 00:41:45,670
right these require the model

719
00:41:47,450 --> 00:41:51,410
dynamic programming or value iteration some things

720
00:41:51,470 --> 00:41:53,330
and we didn't have an exhaustive search

721
00:41:53,370 --> 00:41:55,510
but from from from a given state

722
00:41:55,620 --> 00:42:02,250
you could just to expecting that so is just expectimax search to all terminal states

723
00:42:02,340 --> 00:42:04,880
and this is exactly

724
00:42:05,150 --> 00:42:09,630
you know so in in games you know that you can do game tree search

725
00:42:09,810 --> 00:42:15,750
this is just expected search where instead of doing minimax you do next expectation maximisation

726
00:42:16,020 --> 00:42:19,800
next actions to expectation over the transition probabilities

727
00:42:19,810 --> 00:42:23,310
so you could do is also search from from from a given state spent that

728
00:42:23,350 --> 00:42:24,380
entire tree

729
00:42:27,850 --> 00:42:29,130
is name for methods

730
00:42:29,140 --> 00:42:30,680
now the key

731
00:42:30,700 --> 00:42:32,770
two getting an efficient method

732
00:42:32,850 --> 00:42:36,980
for RL with sampling is going to be to sort of find some middle ground

733
00:42:36,980 --> 00:42:41,660
between temporal difference methods in medical methods to incorporate some of the properties of the

734
00:42:41,660 --> 00:42:43,520
deeper returns

735
00:42:43,530 --> 00:42:47,050
right now the monte carlo method can learn very early on because it's all a

736
00:42:47,050 --> 00:42:50,370
to the end with the probably temporal difference methods that we saw in the in

737
00:42:50,370 --> 00:42:53,760
the in experiments that they can learn faster

738
00:42:53,770 --> 00:42:58,350
right so you know if you're in the in the graphs t

739
00:42:58,360 --> 00:43:02,640
the team methods did find out policy in some problems faster than the MC methods

740
00:43:02,660 --> 00:43:06,550
so how to get the best of both worlds

741
00:43:06,600 --> 00:43:12,800
OK this we're asking is a hybrid of temporal difference and what happens

742
00:43:15,170 --> 00:43:17,270
of course skip this

743
00:43:17,280 --> 00:43:18,420
OK so

744
00:43:18,450 --> 00:43:19,880
let's think about

745
00:43:20,740 --> 00:43:21,880
template of

746
00:43:21,930 --> 00:43:24,490
prediction that we did we previously covered

747
00:43:24,530 --> 00:43:26,620
the one step prediction here

748
00:43:26,660 --> 00:43:31,080
from the from this table to the next day we that we we we we

749
00:43:31,220 --> 00:43:35,270
used as the values for the stage

750
00:43:35,380 --> 00:43:41,290
we use the reward samples plus state but imagine a two step TD methods

751
00:43:41,350 --> 00:43:43,730
you sample two states of the current state

752
00:43:43,760 --> 00:43:45,650
as prime minister wilfried

753
00:43:45,750 --> 00:43:50,900
now take the we were you here word here and that i estimate at this

754
00:43:51,790 --> 00:43:55,660
right which summarizes the future that currently believe you would get

755
00:43:56,450 --> 00:43:57,780
likewise for three steps

756
00:43:57,800 --> 00:44:02,330
sample the first three wards and then use the estimate values from that point on

757
00:44:02,370 --> 00:44:06,800
OK clearly all the way down to the monte carlo method you sample

758
00:44:06,860 --> 00:44:09,730
all the words in every estimate

759
00:44:09,740 --> 00:44:14,500
OK so there no continuum of back from one step two and step all down

760
00:44:14,500 --> 00:44:16,170
to the in which is the monte carlo

761
00:44:16,230 --> 00:44:17,840
start back

762
00:44:17,880 --> 00:44:24,870
OK now what's interesting is these all give you estimates of the same value

763
00:44:24,880 --> 00:44:28,770
so i think it's more clear from next slide

764
00:44:31,950 --> 00:44:34,400
because remember looking to return

765
00:44:34,410 --> 00:44:37,130
OK this is the two-step return

766
00:44:37,140 --> 00:44:38,160
at time t

767
00:44:38,230 --> 00:44:40,310
several more time t plus one

768
00:44:40,370 --> 00:44:42,950
gamma tend toward time t plus two

769
00:44:42,960 --> 00:44:45,060
gamma squared times value estimate

770
00:44:45,080 --> 00:44:50,260
at time t plus two k where the summarizes all future would be expect

771
00:44:50,270 --> 00:44:54,010
OK so what is a three step for step by step these are all as

772
00:44:54,010 --> 00:44:58,170
being the same value as here's the beautiful in inside you get from the from

773
00:44:58,170 --> 00:44:59,950
from the dual methods that is

774
00:45:00,020 --> 00:45:02,230
if you have

775
00:45:02,270 --> 00:45:05,720
if you have a bunch of different aspects of the same value

776
00:45:05,760 --> 00:45:07,860
we just use one

777
00:45:07,960 --> 00:45:11,360
because one one estimator might have high variance

778
00:45:12,600 --> 00:45:15,750
but if you got but it is the same value to combine and you average

779
00:45:16,930 --> 00:45:19,840
get estimate with lower variance

780
00:45:19,850 --> 00:45:22,770
right now the lower variance estimates get after learning

781
00:45:22,780 --> 00:45:26,760
so this is the idea of the team methods average above two different step returns

782
00:45:26,780 --> 00:45:30,500
so to get lower variance in your estimate any lower variance in new sampling then

783
00:45:30,500 --> 00:45:31,880
you get faster

784
00:45:38,660 --> 00:45:44,560
let's do it just goes back to to the random walk example you've got five

785
00:45:44,560 --> 00:45:46,210
states e

786
00:45:46,270 --> 00:45:50,630
you go right i think probably point eight says if you say go right you're

787
00:45:50,750 --> 00:45:54,510
probably point eight and with point two you actually go left

788
00:45:54,520 --> 00:45:59,170
OK so it's sort of a random walk with scale better control that

789
00:45:59,230 --> 00:46:02,100
you can search direct the walkers

790
00:46:02,170 --> 00:46:04,660
OK so let's look in this example

791
00:46:04,780 --> 00:46:07,130
of using different in step returns

792
00:46:07,180 --> 00:46:10,660
so let's look at the top axis

793
00:46:10,730 --> 00:46:14,010
you've got alpha which is the learning rate on the x axis

794
00:46:14,100 --> 00:46:18,890
and on the y axis you've got the air between the current value estimate

795
00:46:21,030 --> 00:46:22,890
and the

796
00:46:22,960 --> 00:46:24,220
in the optimal

797
00:46:27,290 --> 00:46:31,500
they are messages that just says discovered of the meteor

798
00:46:31,550 --> 00:46:34,150
that means greater sorry

799
00:46:38,030 --> 00:46:41,010
root root mean square

800
00:46:42,150 --> 00:46:44,950
so it's just near measure

801
00:46:44,990 --> 00:46:49,660
clearly the lower their measure the better the algorithm on here that the different line

802
00:46:49,680 --> 00:46:53,690
different different instead of using different step backups

803
00:46:54,360 --> 00:46:57,940
and what we previously covered with TD one right

804
00:46:57,940 --> 00:47:02,790
OK to assess performance over the different learning rates OK clearly see here probably learning

805
00:47:02,790 --> 00:47:04,330
rate of

806
00:47:04,350 --> 00:47:07,030
well three given certain offers

807
00:47:07,040 --> 00:47:09,230
it's going to be actually

808
00:47:09,460 --> 00:47:12,900
give you lowest error estimate for a fixed number of samples

809
00:47:12,900 --> 00:47:17,540
but we can look at a small example that user another intuition why light source

810
00:47:19,480 --> 00:47:23,730
imagine that we have one million documents its fare collection for

811
00:47:25,020 --> 00:47:30,420
during during the evening if you you want to exercise this information is available

812
00:47:30,480 --> 00:47:33,100
and it's a collection of small documents

813
00:47:33,120 --> 00:47:37,140
yeah i think that looks like a collection of HTML documents

814
00:47:37,190 --> 00:47:41,040
so only one thousand words document if you are doing

815
00:47:41,100 --> 00:47:44,500
legal that's legal information retrieval it will be

816
00:47:44,520 --> 00:47:50,330
four thousand to five so and if you are doing retrieval from microblogs

817
00:47:50,330 --> 00:47:51,540
you have

818
00:47:51,540 --> 00:47:55,900
ten was document of fifteen work

819
00:47:57,040 --> 00:47:59,190
in dictionary will have

820
00:48:00,420 --> 00:48:04,600
hundred thousand why so many

821
00:48:04,640 --> 00:48:08,160
it's not so many words by the way because extracting

822
00:48:08,170 --> 00:48:10,020
geographical names

823
00:48:10,040 --> 00:48:12,270
think the people names

824
00:48:12,440 --> 00:48:14,690
and you know that

825
00:48:16,350 --> 00:48:18,920
in english and russian

826
00:48:18,960 --> 00:48:21,400
other languages that

827
00:48:21,420 --> 00:48:23,040
been working with

828
00:48:23,060 --> 00:48:29,560
usually have millions of words from this small collection five hundred thousand

829
00:48:29,670 --> 00:48:33,730
it's really very close to what you get

830
00:48:33,770 --> 00:48:36,120
so if you create this metric

831
00:48:36,140 --> 00:48:39,000
this was semantic have

832
00:48:39,040 --> 00:48:41,100
every rewards are all

833
00:48:41,140 --> 00:48:44,420
and every document is the column

834
00:48:44,460 --> 00:48:45,690
you will have

835
00:48:45,810 --> 00:48:49,560
five hundred billion cells in huge mansion

836
00:48:49,580 --> 00:48:52,120
it says sally b

837
00:48:53,210 --> 00:48:56,350
at the same time how many words we have collection

838
00:48:56,370 --> 00:48:59,960
we have only one billion words in collection

839
00:49:00,020 --> 00:49:01,770
so it means that

840
00:49:01,790 --> 00:49:05,620
only less than one percent

841
00:49:05,660 --> 00:49:12,330
o point two percent of elements in this magic magic but not zero

842
00:49:12,440 --> 00:49:16,890
what does it mean that it a huge matrix and all before

843
00:49:16,940 --> 00:49:22,140
every element of is zero and only a small number of elements that will be

844
00:49:22,140 --> 00:49:23,210
one or

845
00:49:23,230 --> 00:49:27,940
for example if you put in constant fieldscount field

846
00:49:30,390 --> 00:49:35,060
let's see how we can present in memory of this huge metric

847
00:49:36,540 --> 00:49:38,230
the most common idea

848
00:49:38,250 --> 00:49:39,710
the game

849
00:49:42,250 --> 00:49:43,270
i know

850
00:49:43,290 --> 00:49:45,790
i mentioned that i was walking

851
00:49:45,810 --> 00:49:47,790
in the library

852
00:49:47,850 --> 00:49:50,710
somewhere in ancient egypt or

853
00:49:50,710 --> 00:49:52,250
i don't know

854
00:49:52,270 --> 00:49:54,310
many thousands of years ago

855
00:49:54,370 --> 00:49:55,600
is what we can do

856
00:49:55,640 --> 00:50:01,420
because are going from four PM decision session from our going from to document what

857
00:50:01,460 --> 00:50:02,460
we can do

858
00:50:02,480 --> 00:50:03,620
you can take

859
00:50:03,620 --> 00:50:05,190
every word

860
00:50:05,210 --> 00:50:09,810
and for everybody can at least of documents

861
00:50:09,830 --> 00:50:11,290
i have seen this work

862
00:50:11,310 --> 00:50:13,190
during in the

863
00:50:13,980 --> 00:50:17,270
with this story collection that it was semantics

864
00:50:18,500 --> 00:50:19,730
get everywhere

865
00:50:19,730 --> 00:50:22,460
rather and reported least

866
00:50:22,460 --> 00:50:25,140
and it exactly exactly the same

867
00:50:25,140 --> 00:50:27,290
that is on this for you

868
00:50:27,330 --> 00:50:29,850
exactly the same you coming to library

869
00:50:29,870 --> 00:50:32,230
we are looking for

870
00:50:32,310 --> 00:50:36,160
actually it's not a word about librarians are smart enough to be in the

871
00:50:37,330 --> 00:50:40,250
so information all the water in this in this

872
00:50:40,270 --> 00:50:41,660
what an index

873
00:50:41,670 --> 00:50:43,350
so they

874
00:50:43,350 --> 00:50:46,540
you can i open the door

875
00:50:46,560 --> 00:50:49,080
in information retrieval on shield

876
00:50:49,100 --> 00:50:55,850
and you see lists of all books or documents that really contained this this is

877
00:50:55,850 --> 00:50:57,480
inverted file

878
00:50:57,480 --> 00:51:01,060
and again this is one of the most popular

879
00:51:01,750 --> 00:51:04,270
structures for information retrieval

880
00:51:04,350 --> 00:51:09,810
just it was invented as i said by librarians many thousands years ago

881
00:51:09,870 --> 00:51:11,690
then it was

882
00:51:11,730 --> 00:51:13,230
in the winter

883
00:51:15,040 --> 00:51:20,900
in the fifties by people who are developing

884
00:51:20,980 --> 00:51:24,080
just search engine for computers

885
00:51:28,690 --> 00:51:31,560
internet search engines became popular

886
00:51:31,600 --> 00:51:33,560
suddenly people started to talk

887
00:51:33,580 --> 00:51:39,850
in all cases very good structure that they actually again that are talking about started

888
00:51:39,850 --> 00:51:44,920
talking about inverted file is the main structure for change

889
00:51:45,620 --> 00:51:47,000
in one thousand eight

890
00:51:47,040 --> 00:51:48,870
very useful structure

891
00:51:50,120 --> 00:51:51,620
as one one

892
00:51:51,670 --> 00:51:55,440
around one day i'm not trivial programs

893
00:51:55,460 --> 00:51:59,560
if you're not real programmer you can you can say OK

894
00:51:59,580 --> 00:52:02,480
i don't want to do this because

895
00:52:02,500 --> 00:52:05,330
actually it's not very good structure for me

896
00:52:05,390 --> 00:52:07,580
why it's not very good structure

897
00:52:08,600 --> 00:52:12,520
i need to extract work put them introduction OK i can do it it's not

898
00:52:12,520 --> 00:52:13,640
a problem

899
00:52:13,690 --> 00:52:17,890
but the problem is that i'm going to to report to every

900
00:52:18,960 --> 00:52:22,390
all documents that are linked to this work

901
00:52:22,390 --> 00:52:28,290
and if it doesn't fit into memory and i can i can create it using

902
00:52:28,310 --> 00:52:29,440
using my

903
00:52:29,460 --> 00:52:33,310
all the computer from nineteen ninety

904
00:52:33,330 --> 00:52:35,440
in one one evening

905
00:52:35,440 --> 00:52:36,890
it's not good

906
00:52:36,940 --> 00:52:42,080
i i will implement the change in the way is is working exactly the same

907
00:52:42,100 --> 00:52:46,560
but much more simpler because because and smart guy

908
00:52:46,620 --> 00:52:48,620
and his saying OK

909
00:52:48,620 --> 00:52:51,100
what i'm going to do it

910
00:52:51,120 --> 00:52:54,230
and i'm going to create a signature file

911
00:52:54,290 --> 00:52:55,520
maybe he

912
00:52:55,560 --> 00:53:00,330
it doesn't know that signature file but what this might go to say is

913
00:53:00,350 --> 00:53:01,660
OK so

914
00:53:01,690 --> 00:53:07,000
let's imagine that we have a caching point

915
00:53:07,020 --> 00:53:11,250
and this session functions can map

916
00:53:11,270 --> 00:53:12,850
every four

917
00:53:12,870 --> 00:53:14,750
to some long

918
00:53:14,810 --> 00:53:18,400
but in addition to being a one b

919
00:53:18,460 --> 00:53:23,540
why because we cannot have such long

920
00:53:23,580 --> 00:53:30,190
one string as whole collection of the whole dictionary because the whole dictionary is

921
00:53:30,210 --> 00:53:32,640
as i said millions of words

922
00:53:32,690 --> 00:53:35,980
we will use the same position many times

923
00:53:36,020 --> 00:53:37,710
typical examples of passion

924
00:53:37,710 --> 00:53:39,520
that insurance companies

925
00:53:40,460 --> 00:53:42,970
when they have independent probabilities

926
00:53:42,980 --> 00:53:44,410
to estimate

927
00:53:46,990 --> 00:53:52,810
of having a certain number of accidents are concerned with having too many accidents which

928
00:53:53,850 --> 00:53:58,750
i'm exhausted reserves insurance company has reserve

929
00:53:58,760 --> 00:54:03,690
and they they have enough reserves to cover them for a certain number of actions

930
00:54:03,690 --> 00:54:06,380
and they use the binomial distribution

931
00:54:06,690 --> 00:54:09,010
to calculate the probability

932
00:54:09,020 --> 00:54:12,620
of getting any specific pacific number of accidents

933
00:54:13,360 --> 00:54:17,530
that is the most efficient the binomial

934
00:54:20,660 --> 00:54:26,740
i can expand the hand because i can't get into detail this is not of

935
00:54:26,750 --> 00:54:28,520
course in probability theory

936
00:54:28,530 --> 00:54:33,270
but i'm hopeful that you can see the formula and could apply

937
00:54:33,280 --> 00:54:34,550
all right

938
00:54:34,600 --> 00:54:38,810
the question this is clear enough you read my handwriting

939
00:54:40,280 --> 00:54:41,430
OK so

940
00:54:41,590 --> 00:54:46,410
another important concept in probability theory that we will use a lot

941
00:54:46,520 --> 00:54:48,790
is expected value

942
00:54:48,810 --> 00:54:51,040
and so

943
00:54:51,120 --> 00:54:54,820
the mean or average

944
00:54:54,870 --> 00:54:57,900
those are all roughly interchangeable

945
00:54:58,870 --> 00:55:05,460
we have expected value

946
00:55:05,460 --> 00:55:07,020
i mean

947
00:55:07,040 --> 00:55:11,680
are average

948
00:55:14,830 --> 00:55:19,220
but we can define it in a couple of different ways depending on whether we're

949
00:55:19,220 --> 00:55:20,910
talking about sample

950
00:55:20,910 --> 00:55:22,740
i mean all

951
00:55:22,810 --> 00:55:25,960
population in the basic definition

952
00:55:25,980 --> 00:55:30,540
the expected value of some random variable x

953
00:55:31,720 --> 00:55:34,080
deflation have a random variable

954
00:55:34,100 --> 00:55:36,170
is a

955
00:55:36,330 --> 00:55:39,040
quantity that takes time

956
00:55:40,620 --> 00:55:43,370
is in fact if you have an experiment

957
00:55:43,420 --> 00:55:46,190
and the outcome of the experiment is a number

958
00:55:46,190 --> 00:55:49,170
then a random variable is that number

959
00:55:49,190 --> 00:55:53,620
o which comes from the experiment so for example the experiment could be tossing a

960
00:55:54,620 --> 00:55:56,080
and i will call

961
00:55:56,090 --> 00:55:58,300
the outcome heads

962
00:55:58,350 --> 00:55:59,870
the number one

963
00:55:59,880 --> 00:56:04,160
and i called the outcome tales the number zero so i've just define a random

964
00:56:05,500 --> 00:56:09,760
you have discrete random variables like the one i just defined or there are also

965
00:56:09,760 --> 00:56:14,310
can that was taken only a finite number of values and we have continuous random

966
00:56:14,310 --> 00:56:17,350
variables they can take on any

967
00:56:17,550 --> 00:56:21,600
a number of values along a continuum another experiment would be to say

968
00:56:21,680 --> 00:56:23,530
next two chemicals together

969
00:56:23,550 --> 00:56:29,660
and put thermometer and measure the temperature that's another invention of the sixteen hundreds by

970
00:56:29,660 --> 00:56:31,650
the way the thermometer

971
00:56:31,690 --> 00:56:36,980
and they learn that concept fit perfectly natural to us temperature but it was a

972
00:56:36,980 --> 00:56:39,270
new idea in the sixteen hundred

973
00:56:39,290 --> 00:56:43,500
so anyway that's continuous right when you mix two chemicals together

974
00:56:43,630 --> 00:56:48,170
it could be any number is an infinite number of possible numbers that would be

975
00:56:49,560 --> 00:56:51,870
i for discrete random variables

976
00:56:51,920 --> 00:56:54,560
we can define the expected value

977
00:56:54,580 --> 00:56:58,120
or use of that that's the greek letters mu

978
00:56:58,160 --> 00:57:00,490
it is the summation

979
00:57:00,530 --> 00:57:04,740
i equals one two infinity

980
00:57:04,740 --> 00:57:06,500
of the probability

981
00:57:06,520 --> 00:57:08,690
that x

982
00:57:08,740 --> 00:57:11,490
equals x survived

983
00:57:11,500 --> 00:57:13,700
times x by

984
00:57:13,750 --> 00:57:18,380
all right so i haven't done that there might be an infinite number of possible

985
00:57:18,380 --> 00:57:19,810
values for

986
00:57:19,840 --> 00:57:21,760
the random variable x

987
00:57:21,760 --> 00:57:24,660
in the case of the coin toss there are only two

988
00:57:24,670 --> 00:57:25,570
but i'm

989
00:57:25,600 --> 00:57:29,180
it's saying in general there could be an infinite number but there countable

990
00:57:29,180 --> 00:57:32,580
so we can list all possible values when they're discrete

991
00:57:32,600 --> 00:57:38,740
and form a probability weighted average of the outcomes and that's called the expected value

992
00:57:38,740 --> 00:57:42,460
and it's people also call that the mean or the average

993
00:57:44,100 --> 00:57:46,460
but note that this is based on

994
00:57:47,340 --> 00:57:49,450
these are probabilities

995
00:57:50,620 --> 00:57:53,200
in order to compute using this formula

996
00:57:53,210 --> 00:57:54,570
you have to know

997
00:57:54,590 --> 00:57:57,560
the troopers prior probabilities

998
00:57:57,600 --> 00:58:02,080
there's another formula which applies for continuous random variables

999
00:58:02,130 --> 00:58:04,360
and it's the same idea

1000
00:58:04,380 --> 00:58:05,560
except that

1001
00:58:05,580 --> 00:58:08,370
o also called backs

1002
00:58:08,380 --> 00:58:10,810
except that it's an integral

1003
00:58:10,830 --> 00:58:12,320
so we have in

1004
00:58:12,370 --> 00:58:16,010
from minus infinity to plus infinity

1005
00:58:16,020 --> 00:58:18,810
of f of x

1006
00:58:18,850 --> 00:58:20,520
times x

1007
00:58:23,100 --> 00:58:27,930
that's really see is the same thing because an integral is analogous to a some

1008
00:58:27,930 --> 00:58:34,710
or are more

1009
00:58:47,060 --> 00:58:49,460
four or

1010
00:58:49,480 --> 00:58:52,370
one of more general

1011
00:58:52,370 --> 00:59:00,460
not just the structure of the city looking for so

1012
00:59:00,460 --> 00:59:03,690
things to look for the right

1013
00:59:03,710 --> 00:59:08,980
is the is one the bushy what kinds of aspects with the

1014
00:59:13,580 --> 00:59:14,910
the user

1015
00:59:14,960 --> 00:59:17,580
a lot of

1016
00:59:19,040 --> 00:59:24,920
the school was using normal inverse is the first time

1017
00:59:28,340 --> 00:59:30,250
some of these

1018
00:59:31,120 --> 00:59:38,570
that's really all

1019
00:59:38,580 --> 00:59:41,830
well that are three

1020
00:59:44,980 --> 00:59:45,690
so we are

1021
00:59:49,090 --> 00:59:51,310
however are

1022
00:59:52,080 --> 00:59:55,090
so what this is

1023
00:59:55,100 --> 00:59:56,170
you will be

1024
00:59:57,830 --> 01:00:04,460
all of the

1025
01:00:05,560 --> 01:00:09,250
the art of

1026
01:00:09,830 --> 01:00:11,830
so a more

1027
01:00:11,850 --> 01:00:12,670
you will get

1028
01:00:13,620 --> 01:00:17,480
of all

1029
01:00:17,580 --> 01:00:23,270
he also understand that in the last

1030
01:00:26,640 --> 01:00:29,560
what are

1031
01:00:29,560 --> 01:00:32,960
also possible is

1032
01:00:40,270 --> 01:00:42,390
the more

1033
01:00:46,640 --> 01:00:48,480
what you see

1034
01:00:53,120 --> 01:00:55,190
you know

1035
01:00:55,210 --> 01:00:57,580
we were

1036
01:00:57,600 --> 01:01:05,040
it's all three this is the semantic structure people flock

1037
01:01:07,120 --> 01:01:10,060
he is

1038
01:01:10,120 --> 01:01:12,350
there's a lot

1039
01:01:12,540 --> 01:01:16,560
you can see that you can get

1040
01:01:16,750 --> 01:01:23,420
really work

1041
01:01:23,440 --> 01:01:28,670
and then we can

1042
01:01:30,040 --> 01:01:34,040
i i the more fundamental we also need to understand classes because of what of

1043
01:01:34,040 --> 01:01:35,390
the to

1044
01:01:35,420 --> 01:01:36,770
our to describe

1045
01:01:38,420 --> 01:01:41,230
grass roots north

1046
01:01:41,250 --> 01:01:43,870
and relations between

1047
01:01:47,850 --> 01:01:51,350
of the graph

1048
01:01:51,370 --> 01:01:58,750
i think will do with no is

1049
01:01:58,770 --> 01:02:01,420
sometimes it's important in the past

1050
01:02:01,560 --> 01:02:04,670
not always easy

1051
01:02:06,770 --> 01:02:08,750
of course

1052
01:02:08,770 --> 01:02:16,830
a lot of work on developing for this is about themselves are part

1053
01:02:16,870 --> 01:02:19,140
one this work well

1054
01:02:19,410 --> 01:02:21,830
all this stuff

1055
01:02:21,850 --> 01:02:28,790
progress on the

1056
01:02:28,790 --> 01:02:31,670
excellent here we get this the contributions

1057
01:02:31,720 --> 01:02:37,120
then you would like to have a large margin between the true difference is what

1058
01:02:38,710 --> 01:02:45,040
OK let's it so that does it looks more like this three more scores you

1059
01:02:45,130 --> 01:02:48,880
transcription start for all these to school

1060
01:02:50,100 --> 01:02:53,090
computer for every position in the genome and then you would like to fit this

1061
01:02:53,090 --> 01:02:55,160
kind of model

1062
01:02:55,510 --> 01:02:57,360
to use

1063
01:02:57,370 --> 01:02:59,410
the structure of the learning for doing this

1064
01:02:59,460 --> 01:03:03,740
and then you don't need to explain this again just try to learn a function

1065
01:03:03,910 --> 01:03:05,140
of y x

1066
01:03:05,160 --> 01:03:12,940
and labelling is the segmentation into different unique arts and input is this the

1067
01:03:12,960 --> 01:03:18,950
predictions of the SVM for the take

1068
01:03:19,170 --> 01:03:21,380
OK let me show you some results on that

1069
01:03:21,580 --> 01:03:28,190
so first of all actually talk to kind of the first one is one

1070
01:03:28,200 --> 01:03:33,820
predicting splice forms only so say we even started the end of the gene would

1071
01:03:33,820 --> 01:03:36,550
only like to predict the starts

1072
01:03:36,570 --> 01:03:39,680
and so in into one we would like to find all the info

1073
01:03:40,830 --> 01:03:47,770
and then i also have prediction have some results on a protein protein predictions very

1074
01:03:47,770 --> 01:03:50,300
can also identify new

1075
01:03:52,660 --> 01:03:54,100
OK so we

1076
01:03:54,110 --> 01:03:57,590
we had about four searle is four

1077
01:03:57,640 --> 01:03:59,330
these results selected

1078
01:04:00,450 --> 01:04:05,550
we had about four thousand genes which will equal this was like a quarter of

1079
01:04:06,640 --> 01:04:09,960
he took sixty percent for training percent for testing

1080
01:04:10,010 --> 01:04:12,680
and maybe explode i like

1081
01:04:12,720 --> 01:04:16,970
and we tested on one thousand one hundred eighty model

1082
01:04:17,020 --> 01:04:19,280
and we found the lights on

1083
01:04:19,300 --> 01:04:23,340
based on error rate was just five percent so that means five percent of the

1084
01:04:23,340 --> 01:04:26,960
cases the prediction up

1085
01:04:26,970 --> 01:04:27,820
that means

1086
01:04:27,830 --> 01:04:33,480
of the single or this but from what incorrect means one of the intron exon

1087
01:04:35,340 --> 01:04:40,180
OK so there are two different tasks one is involving only coding sequences and the

1088
01:04:40,180 --> 01:04:43,620
other one was what could is not only forty to

1089
01:04:43,670 --> 01:04:47,450
compare this to other approaches recently published

1090
01:04:47,500 --> 01:04:54,000
i can be with i think about you by many with four x and on

1091
01:04:54,000 --> 01:04:56,510
the same datasets

1092
01:04:56,530 --> 01:05:01,660
they got like twice as high error rates than in inspector

1093
01:05:01,780 --> 01:05:09,820
so like i said that ten percent and here second task sort of fifteen percent

1094
01:05:09,830 --> 01:05:12,070
to six percent

1095
01:05:12,160 --> 01:05:19,120
so this is how prediction looks like right so we start in any given that

1096
01:05:19,120 --> 01:05:23,070
it's like what sequence that starts at the end of the

1097
01:05:23,080 --> 01:05:25,470
six of them

1098
01:05:25,520 --> 01:05:27,980
so what is interesting is that we

1099
01:05:28,030 --> 01:05:35,530
we took me to our system and went to the annotation of the genome

1100
01:05:36,060 --> 01:05:41,790
there's already some genes right so said of those genes are completely uncalled

1101
01:05:42,370 --> 01:05:46,090
went to those genes and we predict the the gene structure for those genes

1102
01:05:46,160 --> 01:05:50,670
so there was some other tool which was you ought to be fifteen structures and

1103
01:05:52,030 --> 01:05:57,610
important part was that we found only if all that all critics disagreed with the

1104
01:05:57,610 --> 01:05:59,740
adaptation fifty percent of the cases

1105
01:06:00,320 --> 01:06:04,720
i mean really very high disagreement even though we know if accuracy should be much

1106
01:06:04,720 --> 01:06:07,200
much higher from the property

1107
01:06:07,220 --> 01:06:10,370
the westerners who was right so

1108
01:06:10,380 --> 01:06:16,490
we looked at twenty of those cases experimentally so we went to the benefits of

1109
01:06:16,490 --> 01:06:20,810
sequencing of them on a line those found that

1110
01:06:22,500 --> 01:06:27,300
in order the twenty cases non what's correct from the annotation and fifteen cases correct

1111
01:06:27,490 --> 01:06:29,990
for what four

1112
01:06:30,030 --> 01:06:35,390
OK so this is like one case this was that station and then we predicted

1113
01:06:35,430 --> 01:06:37,510
splice form then we sequenced

1114
01:06:37,840 --> 01:06:43,780
that part and you see that it is exactly matching of

1115
01:06:43,790 --> 01:06:47,310
so the error rate of a patient that has one hundred percent

1116
01:06:47,310 --> 01:06:49,020
this is a useful thing to do

1117
01:06:51,400 --> 01:06:54,070
now the the most interesting one

1118
01:06:54,130 --> 01:06:55,900
four class the

1119
01:06:55,910 --> 01:07:00,640
equation of state that the most interesting is the van der waals equation of state

1120
01:07:00,740 --> 01:07:07,080
developed by mister van der waals in eighteen seventy three

1121
01:07:07,130 --> 01:07:09,990
and the beauty of that equation of state is that it only relies on two

1122
01:07:11,380 --> 01:07:20,950
so let's build up and see where it comes from

1123
01:07:20,950 --> 01:07:24,720
and just frustrated and then divorced

1124
01:07:29,760 --> 01:07:33,120
that's a the bars where

1125
01:07:37,980 --> 01:07:41,210
if you take a equal to zero these are the two parameters a and b

1126
01:07:41,220 --> 01:07:46,400
you take those two equal to zero the musical director field as well

1127
01:07:46,410 --> 01:07:49,830
OK let's build this ability when this comes from when these parameters a and b

1128
01:07:49,830 --> 01:07:51,980
comes from

1129
01:07:52,030 --> 01:07:54,630
the first thing to do is we're going take gas

1130
01:07:54,630 --> 01:07:57,600
in a box

1131
01:07:57,620 --> 01:07:59,660
building blocks for here

1132
01:07:59,670 --> 01:08:02,200
gotta go on a bunch of gas molecules

1133
01:08:02,220 --> 01:08:05,190
four atoms

1134
01:08:05,240 --> 01:08:07,980
the box here

1135
01:08:08,010 --> 01:08:09,720
well these

1136
01:08:09,810 --> 01:08:14,000
gas is gas molecules or atoms to a first approximation

1137
01:08:14,010 --> 01:08:15,640
like hard spheres

1138
01:08:15,670 --> 01:08:19,650
they occupy a certain volume each molecule occupies

1139
01:08:19,670 --> 01:08:21,790
a particular volume

1140
01:08:22,930 --> 01:08:23,980
and so

1141
01:08:24,310 --> 01:08:27,200
we can

1142
01:08:27,290 --> 01:08:28,580
called the

1143
01:08:28,630 --> 01:08:30,730
is the volume

1144
01:08:30,770 --> 01:08:32,770
per mole

1145
01:08:32,780 --> 01:08:40,370
of the hard spheres

1146
01:08:40,390 --> 01:08:41,830
by and promoted

1147
01:08:41,890 --> 01:08:43,120
that is the little

1148
01:08:43,130 --> 01:08:44,210
fear that the

1149
01:08:44,260 --> 01:08:45,580
molecules are

1150
01:08:45,600 --> 01:08:47,440
so that the volume

1151
01:08:47,440 --> 01:08:51,080
that's available to any one of those spheres

1152
01:08:51,100 --> 01:08:53,950
it is actually smaller than b

1153
01:08:53,990 --> 01:08:58,940
because you've got all these other little spheres around so the actual volume seen by

1154
01:08:58,940 --> 01:09:00,700
any one of the sphere is smaller than the

1155
01:09:00,740 --> 01:09:02,540
so when we take our

1156
01:09:02,550 --> 01:09:04,840
the ideal gas law

1157
01:09:04,970 --> 01:09:07,020
particle to rt

1158
01:09:07,060 --> 01:09:11,830
we have to replace the bar by the actual volume available to this hard spheres

1159
01:09:11,880 --> 01:09:14,160
so instead of the berkeley right p

1160
01:09:14,170 --> 01:09:15,710
the bar

1161
01:09:15,720 --> 01:09:18,680
a minus b

1162
01:09:20,010 --> 01:09:21,040
that's the

1163
01:09:21,120 --> 01:09:25,700
parts here volume of the spheres

1164
01:09:25,750 --> 01:09:29,790
now those molecules or atoms are here

1165
01:09:29,830 --> 01:09:31,470
i also feel each other

1166
01:09:31,540 --> 01:09:34,530
of whole bunch of forces a new in five eleven two

1167
01:09:34,580 --> 01:09:38,190
one like van der waals attraction things like this

1168
01:09:38,230 --> 01:09:42,190
so the attractive forces are repulsive forces

1169
01:09:44,710 --> 01:09:46,750
these molecules

1170
01:09:46,830 --> 01:09:50,870
and that's going to change

1171
01:09:50,880 --> 01:09:52,800
the pressure

1172
01:09:52,980 --> 01:09:56,740
the molecules field for instance if i have

1173
01:09:56,790 --> 01:10:00,870
pressure pressure is when you have one of his her sphere colliding against the wall

1174
01:10:00,940 --> 01:10:02,820
the biosphere

1175
01:10:02,840 --> 01:10:06,370
once the colliding the water to create a force on the wall

1176
01:10:06,430 --> 01:10:08,960
and i have a couple of hard spheres nearby

1177
01:10:10,150 --> 01:10:13,980
right in the absence of any interactions at a certain pressure this thing with careen

1178
01:10:13,990 --> 01:10:16,310
into the walk junior

1179
01:10:16,340 --> 01:10:17,740
the force

1180
01:10:17,740 --> 01:10:21,270
but only in the presence of these interactions

1181
01:10:21,350 --> 01:10:27,960
get these other molecules here are watching the other partners

1182
01:10:28,040 --> 01:10:29,330
one two are

1183
01:10:29,380 --> 01:10:31,430
two damage to themselves right

1184
01:10:31,540 --> 01:10:34,490
that one to come back right

1185
01:10:36,310 --> 01:10:39,090
the attractive force there is no other molecules on the outside of the wall so

1186
01:10:40,190 --> 01:10:43,880
is attractive for that that makes the velocity thing not quite as far as the

1187
01:10:43,880 --> 01:10:45,660
force is not quite as strong

1188
01:10:45,710 --> 01:10:49,130
as it was without this attractive force so the real pressure is not quite the

1189
01:10:50,250 --> 01:10:52,910
because of these attractive forces it was

1190
01:10:52,980 --> 01:10:55,070
it would be without forces

1191
01:10:55,090 --> 01:10:58,700
the pressures of the last in this case here

1192
01:10:58,780 --> 01:11:01,400
so instead of

1193
01:11:01,440 --> 01:11:04,100
half of this piece here now

1194
01:11:04,180 --> 01:11:07,460
if i write this equation here he

1195
01:11:07,510 --> 01:11:09,580
is equal to RTE

1196
01:11:09,680 --> 01:11:12,390
divided by the bottom line is the

1197
01:11:12,390 --> 01:11:15,300
just rewriting this equation

1198
01:11:15,340 --> 01:11:17,050
as it is

1199
01:11:17,100 --> 01:11:24,480
so the pressure is going to depend on how strong this attractive forces

1200
01:11:24,530 --> 01:11:26,530
so the pressure is going to be less

1201
01:11:26,550 --> 01:11:29,050
if is a strong attractive forces

1202
01:11:29,060 --> 01:11:32,050
and the one of the squared is the statistical

1203
01:11:32,160 --> 01:11:35,990
this approach basically the probability of having

1204
01:11:36,070 --> 01:11:40,130
and another molecule a second molecule in the volume of space

1205
01:11:40,980 --> 01:11:43,770
if the molar volume is small

1206
01:11:43,820 --> 01:11:45,620
and one of the is large

1207
01:11:45,630 --> 01:11:47,790
is a large probability into

1208
01:11:47,890 --> 01:11:50,540
two spheres together by

1209
01:11:50,580 --> 01:11:53,050
the is large

1210
01:11:53,060 --> 01:11:53,980
it means that

1211
01:11:53,990 --> 01:11:55,400
there's a lot of room

1212
01:11:55,400 --> 01:11:58,400
for the molecules and they're not going to be close to each other so this

1213
01:11:58,400 --> 01:12:00,420
isn't going to be as important

1214
01:12:00,430 --> 01:12:04,470
so a is the strength of the interaction of the bar is how

1215
01:12:04,490 --> 01:12:07,630
likely they are to be close to each other

1216
01:12:07,640 --> 01:12:12,480
that's going to affect the actual pressure seen by the as

1217
01:12:12,690 --> 01:12:14,740
and a

1218
01:12:16,030 --> 01:12:18,500
when you

1219
01:12:21,030 --> 01:12:23,730
that gives you the van der waals

1220
01:12:23,780 --> 01:12:25,740
the question is that

1221
01:12:25,740 --> 01:12:28,180
two parameters the hard sphere volume

1222
01:12:28,190 --> 01:12:30,820
and the attraction

1223
01:12:30,850 --> 01:12:33,760
you don't have to go look up into tables but you don't have to have

1224
01:12:33,780 --> 01:12:37,770
all the values of the second virial coefficient or the fudge factor

1225
01:12:37,810 --> 01:12:38,830
just to

1226
01:12:38,840 --> 01:12:41,340
variables that make physical sense

1227
01:12:41,390 --> 01:12:44,530
and you get an equation of state which is a reasonable equations and that's the

1228
01:12:44,530 --> 01:12:46,120
power animals

1229
01:12:46,130 --> 01:12:49,150
equation of state and that's the one we're going to be using later on in

1230
01:12:49,150 --> 01:12:51,980
this class describe real gases

1231
01:12:51,980 --> 01:12:54,020
you should have seen a little bit

1232
01:12:54,040 --> 01:12:58,060
the one using this class predominantly is the notation

1233
01:13:02,810 --> 01:13:08,650
and then notation is pretty easy notation to master because all you do is you

1234
01:13:09,480 --> 01:13:12,600
from the formula you just drop low order terms

1235
01:13:16,000 --> 01:13:19,790
and ignore

1236
01:13:19,790 --> 01:13:26,350
leading constants and then

1237
01:13:27,620 --> 01:13:30,520
so for example

1238
01:13:30,540 --> 01:13:33,000
i have a formally like three and q

1239
01:13:34,790 --> 01:13:41,460
ninety and squared minus five and class six o four six

1240
01:13:41,480 --> 01:13:45,420
i say well what's the

1241
01:13:46,420 --> 01:13:51,210
one of the what order terms do i drop nq is a bigger term then

1242
01:13:51,210 --> 01:13:52,560
and square

1243
01:13:52,600 --> 01:13:54,790
from drop all these terms

1244
01:13:54,810 --> 01:14:00,790
and ignore the leading constant so i say that's made of and q

1245
01:14:00,810 --> 01:14:03,230
pretty easy

1246
01:14:03,920 --> 01:14:09,440
so that as in that they notation now this is an engineering

1247
01:14:09,460 --> 01:14:12,360
the a way of manipulating data notation

1248
01:14:12,380 --> 01:14:15,330
there's actually a mathematical definition for this

1249
01:14:15,350 --> 01:14:18,000
which one talk about next time

1250
01:14:18,850 --> 01:14:23,670
which is the definition in terms of sets of functions

1251
01:14:23,690 --> 01:14:27,100
and you're going to be responsible in this class this is both a man

1252
01:14:27,120 --> 01:14:30,880
and in engineering computer science engineering class

1253
01:14:30,900 --> 01:14:35,850
so throughout the course of responsible both for mathematical rigour

1254
01:14:35,900 --> 01:14:41,310
as if it were math course and engineering common sense because it's an engineering course

1255
01:14:41,360 --> 01:14:43,230
going to be doing both

1256
01:14:43,290 --> 01:14:47,130
so this is the engineering way of understanding what you do

1257
01:14:47,170 --> 01:14:50,730
so you're responsible for being able to do these manipulations you're also going to be

1258
01:14:50,730 --> 01:14:54,730
responsible for understanding the mathematical definition of data notation

1259
01:14:54,750 --> 01:14:59,860
and of its related o notation and omega notation

1260
01:15:04,060 --> 01:15:05,600
if i take a look

1261
01:15:05,600 --> 01:15:08,850
as n approaches infinity

1262
01:15:08,900 --> 01:15:13,380
the square albert algorithm

1263
01:15:19,100 --> 01:15:23,960
i data nq algorithm

1264
01:15:24,130 --> 01:15:30,310
as n gets bigger it doesn't matter what these other terms were if i were

1265
01:15:30,310 --> 01:15:34,190
describing the absolute precise behaviour

1266
01:15:34,210 --> 01:15:37,000
in terms of the formula

1267
01:15:37,750 --> 01:15:43,540
if i had and squared algorithm it will always be faster for sufficiently large n

1268
01:15:43,580 --> 01:15:46,310
then if haiti and cube algorithm

1269
01:15:46,310 --> 01:15:48,920
it wouldn't matter what those laura terms work

1270
01:15:48,940 --> 01:15:52,960
it wouldn't matter what the leading constant was

1271
01:15:53,980 --> 01:15:56,960
this one will always be faster even

1272
01:15:56,960 --> 01:15:58,940
if you read

1273
01:15:58,940 --> 01:16:03,730
the theta and squared algorithm on a slow computer

1274
01:16:03,750 --> 01:16:08,690
in the data and q algorithm one of fast computers

1275
01:16:08,690 --> 01:16:13,900
so the great thing about asymptotic notation is it satisfies are issue being able to

1276
01:16:13,900 --> 01:16:19,080
compare both relative and absolute speed

1277
01:16:19,100 --> 01:16:22,130
OK because really able to do this

1278
01:16:22,150 --> 01:16:23,920
no matter what

1279
01:16:23,940 --> 01:16:26,540
computer no matter what the platform

1280
01:16:26,560 --> 01:16:30,520
so on different platforms we may get different

1281
01:16:30,560 --> 01:16:34,920
constance here machine dependent constants for the actual running time

1282
01:16:34,960 --> 01:16:37,130
but if i look at the growth

1283
01:16:37,150 --> 01:16:39,310
as the size of the input gets larger

1284
01:16:39,330 --> 01:16:42,500
the asymptotics generally won't change

1285
01:16:42,560 --> 01:16:45,190
so for example

1286
01:16:45,210 --> 01:16:48,750
just draw that is the picture

1287
01:16:48,810 --> 01:16:51,100
so if i have and on this axis

1288
01:16:51,130 --> 01:16:54,250
t then on this axis

1289
01:16:55,880 --> 01:16:57,020
this may be

1290
01:16:59,230 --> 01:17:04,900
this may be for example of data and cube algorithm and this may be data

1291
01:17:04,900 --> 01:17:07,600
in square algorithm

1292
01:17:07,620 --> 01:17:10,520
there's always going to be some points

1293
01:17:10,540 --> 01:17:13,630
and not

1294
01:17:13,630 --> 01:17:15,830
and when you put results

1295
01:17:15,850 --> 01:17:19,420
that's where it's even more important not to make too many assumptions

1296
01:17:19,880 --> 01:17:21,830
so now

1297
01:17:21,900 --> 01:17:23,770
what you can do is

1298
01:17:23,790 --> 01:17:27,750
two things so either someone tells you what is the objective so you want to

1299
01:17:27,750 --> 01:17:30,540
maximize some

1300
01:17:30,560 --> 01:17:36,520
misclassification error sorry minimize the misclassification error or maximize the money you get

1301
01:17:36,540 --> 01:17:41,080
from applying a certain reason to certain problem or anything like this and then you

1302
01:17:41,080 --> 01:17:43,170
can see from this tried to

1303
01:17:45,100 --> 01:17:47,210
the optimal algorithm for

1304
01:17:47,250 --> 01:17:49,830
maximizing or minimizing the this quantity

1305
01:17:51,000 --> 01:17:52,610
you can say well

1306
01:17:52,630 --> 01:17:54,920
let's forget about this and let's try to

1307
01:17:54,940 --> 01:17:56,250
make another reason that

1308
01:17:56,270 --> 01:18:00,520
estimates everything about the the properties of the

1309
01:18:01,150 --> 01:18:03,170
so for example if you're in classification

1310
01:18:03,170 --> 01:18:04,380
you can either try

1311
01:18:04,480 --> 01:18:08,520
to build a classifier or first try to build something that is to make the

1312
01:18:10,040 --> 01:18:15,440
how the data is distributed in space and then from that from these estimates construct

1313
01:18:20,630 --> 01:18:22,870
moreover most often you would get

1314
01:18:22,900 --> 01:18:24,980
the same algorithms

1315
01:18:25,000 --> 01:18:26,830
but the point is if you

1316
01:18:26,830 --> 01:18:29,290
o was the first approach

1317
01:18:29,310 --> 01:18:32,790
and sometimes a bit more risky because you're trying to do things that you don't

1318
01:18:32,790 --> 01:18:35,110
have to do or you don't need to do

1319
01:18:36,730 --> 01:18:37,560
and you may

1320
01:18:37,600 --> 01:18:39,770
by the following that you may

1321
01:18:41,480 --> 01:18:43,870
necessary assumptions

1322
01:18:44,170 --> 01:18:46,610
but the point is

1323
01:18:46,650 --> 01:18:48,810
algorithms are algorithms

1324
01:18:48,830 --> 01:18:51,350
they are completely independent on

1325
01:18:51,380 --> 01:18:55,350
what what you may assume about the distribution of the data and the may work

1326
01:18:55,350 --> 01:18:58,830
on network independently on your assumption just because

1327
01:18:59,270 --> 01:19:03,460
the the problem is nice or not

1328
01:19:05,380 --> 01:19:07,270
OK so now the question is

1329
01:19:07,290 --> 01:19:08,290
how can we

1330
01:19:08,310 --> 01:19:11,710
two the priory very guidance for choosing priors

1331
01:19:11,730 --> 01:19:17,650
prior in the very general sense like what's an algorithm should prefer

1332
01:19:20,250 --> 01:19:23,920
he there's not much seen right away

1333
01:19:24,020 --> 01:19:27,790
i've kept repeating during his lectures that

1334
01:19:27,810 --> 01:19:29,730
all the series

1335
01:19:29,750 --> 01:19:34,690
cannot justify the prior it can only tell you once you have chosen the prior

1336
01:19:34,690 --> 01:19:39,920
whether i mean the kind of behaviour you may expect so once you have restricted

1337
01:19:39,920 --> 01:19:43,940
your special functions to functions of a certain form it will tell you kids with

1338
01:19:43,940 --> 01:19:45,960
these within this class

1339
01:19:45,980 --> 01:19:48,560
you may expect to upset to rate of convergence

1340
01:19:49,960 --> 01:19:53,130
doesn't mean that this class is good for your problem

1341
01:19:55,880 --> 01:20:01,560
forget about series if you wanted to the prior i would say

1342
01:20:01,610 --> 01:20:05,580
but still you can have

1343
01:20:05,580 --> 01:20:09,190
so i mean i can give you some personal feelings about how to choose the

1344
01:20:12,420 --> 01:20:15,250
not generally speaking you want to

1345
01:20:15,270 --> 01:20:16,830
make operational

1346
01:20:16,830 --> 01:20:17,670
all the

1347
01:20:17,690 --> 01:20:20,730
operational in the sense that you can derive an algorithm from it

1348
01:20:20,750 --> 01:20:23,080
all the knowledge of belief that you

1349
01:20:23,100 --> 01:20:25,000
but for that you don't have to

1350
01:20:29,520 --> 01:20:32,960
approach of theory or whatever just

1351
01:20:32,980 --> 01:20:36,380
b as pragmatic as possible i would say

1352
01:20:36,750 --> 01:20:40,650
it's a bit messy slides

1353
01:20:40,670 --> 01:20:45,440
so OK so this is more precise definition of the sentence

1354
01:20:45,500 --> 01:20:48,940
this prior to be what to expect before seeing the data

1355
01:20:48,980 --> 01:20:53,480
or assumptions about the function that are likely to solve the problem

1356
01:20:57,150 --> 01:21:00,630
you know it's just way to choose between two and i put these sort of

1357
01:21:00,630 --> 01:21:03,710
functions that look similar on your data

1358
01:21:06,560 --> 01:21:11,730
two to put it a bit more precisely priorities nothing but something that

1359
01:21:11,750 --> 01:21:12,790
gives you

1360
01:21:12,880 --> 01:21:18,170
number or score for each function so you function in i mean you have the

1361
01:21:18,190 --> 01:21:22,060
set of function and what you want is to assign a preference to each function

1362
01:21:22,170 --> 01:21:23,810
so you get

1363
01:21:24,540 --> 01:21:28,830
so any functional would be a prior that

1364
01:21:28,850 --> 01:21:30,000
so here are some

1365
01:21:30,060 --> 01:21:30,750
if you

1366
01:21:30,770 --> 01:21:33,520
few ways to do that

1367
01:21:33,540 --> 01:21:35,480
the simplest way

1368
01:21:35,500 --> 01:21:37,480
is two

1369
01:21:37,520 --> 01:21:40,110
here again there are some typos here

1370
01:21:40,130 --> 01:21:44,480
the simplest ways to restrict the class of functions so that the

1371
01:21:44,520 --> 01:21:47,060
could just prior you say well

1372
01:21:47,130 --> 01:21:48,460
i hope

1373
01:21:48,540 --> 01:21:52,350
that the target function is in this class and if it's not

1374
01:21:52,540 --> 01:21:53,960
two but

1375
01:21:55,650 --> 01:22:00,270
you can have some kind of nested structure of functions classes

1376
01:22:00,290 --> 01:22:04,170
you say well i hope that my function is in this class but it's not

1377
01:22:04,170 --> 01:22:07,460
maybe it would be in the second one and if it's not maybe within the

1378
01:22:07,460 --> 01:22:09,770
larger one and so on

1379
01:22:11,460 --> 01:22:15,400
and to each of the set to you associate some numbers that tell you

1380
01:22:15,400 --> 01:22:20,440
i mean i did should be something like the complexity of this

1381
01:22:21,080 --> 01:22:24,600
it can be anything that allows you to trade off between

1382
01:22:25,000 --> 01:22:28,980
the error that you made by the using function in set and

1383
01:22:29,000 --> 01:22:30,110
the prior your

1384
01:22:30,130 --> 01:22:33,000
preference that you have on the on this

1385
01:22:33,020 --> 01:22:36,920
and that's i mean here is where c we can give you a little bit

1386
01:22:36,920 --> 01:22:40,790
of guidance it can tell you what is the relevant notion of complexity for the

1387
01:22:40,790 --> 01:22:44,580
set and hence tell you how you should trade-off

1388
01:22:46,250 --> 01:22:49,190
so errors on your data

1389
01:22:49,920 --> 01:22:51,810
complexity in the class so

1390
01:22:51,810 --> 01:22:56,540
is it better to choose a function here which has such an error or function

1391
01:22:56,540 --> 01:23:00,710
here that a much smaller error but we within the class which is much bigger

1392
01:23:00,770 --> 01:23:02,960
than the exact balance

1393
01:23:03,000 --> 01:23:06,170
between those those choices can be

1394
01:23:06,230 --> 01:23:07,400
given by

1395
01:23:07,400 --> 01:23:10,960
the notion of complexity that we discussed before

1396
01:23:10,980 --> 01:23:13,100
here and then you can imagine

1397
01:23:13,130 --> 01:23:17,980
more general functionals like none of your functions or or anything

1398
01:23:17,980 --> 01:23:22,580
and usually you do that by are you consider very large set of function as

1399
01:23:22,580 --> 01:23:27,880
large as you can because you want to approximate potentially any function or at least

1400
01:23:27,880 --> 01:23:29,810
any continuous function for example

1401
01:23:29,870 --> 01:23:33,250
and you want to define a norm on this set the function that

1402
01:23:33,250 --> 01:23:35,830
from a simple alphabet with force

1403
01:23:36,330 --> 01:23:38,160
of size four

1404
01:23:38,220 --> 01:23:42,120
then for every two in you get one out

1405
01:23:42,130 --> 01:23:43,660
if you take a

1406
01:23:43,670 --> 01:23:47,150
if you take three binary digits coming in

1407
01:23:47,210 --> 01:23:50,760
then you need a symbol alphabet size a here

1408
01:23:50,760 --> 01:23:51,430
if you

1409
01:23:51,460 --> 01:23:53,010
if you

1410
01:23:53,030 --> 01:23:55,130
if you move down in rate

1411
01:23:55,550 --> 01:23:58,060
from four binary digits

1412
01:23:58,090 --> 01:24:00,010
to one symbol

1413
01:24:00,100 --> 01:24:03,530
and then of course you need an alphabet of size sixteen

1414
01:24:03,530 --> 01:24:06,050
so the size of the alphabet here

1415
01:24:06,060 --> 01:24:09,790
is going up exponentially as the

1416
01:24:09,810 --> 01:24:11,810
great advantage that you get

1417
01:24:11,820 --> 01:24:13,400
is going down

1418
01:24:13,560 --> 01:24:17,280
we will talk about that more as we move on

1419
01:24:17,330 --> 01:24:22,710
you should sort of keep in mind that estranged relationship

1420
01:24:22,760 --> 01:24:25,680
between the size of alphabet

1421
01:24:25,820 --> 01:24:28,490
and the rate at which you can transmit

1422
01:24:28,510 --> 01:24:29,350
as you

1423
01:24:29,370 --> 01:24:34,560
as you try to transmit higher and higher rates here the decisive year alphabet goes

1424
01:24:34,560 --> 01:24:39,580
up exponentially with the rate can you can

1425
01:24:39,600 --> 01:24:43,310
in fact when you look at shannon's famous formula

1426
01:24:43,540 --> 01:24:46,570
how fast you can communicate on the channel

1427
01:24:46,570 --> 01:24:49,070
you find the logarithm

1428
01:24:49,090 --> 01:24:51,590
the signal to noise ratio

1429
01:24:51,910 --> 01:24:54,600
of one plus the signal to noise ratio

1430
01:24:54,620 --> 01:24:58,840
when you look at that signal to noise ratio and you look at this alphabet

1431
01:24:58,840 --> 01:25:02,790
size and here you could almost see just from that

1432
01:25:02,790 --> 01:25:07,530
why in fact that the logarithm is in this capacity formulas and we'll come back

1433
01:25:07,530 --> 01:25:10,710
to talk about that again more later also

1434
01:25:10,730 --> 01:25:11,830
but anyway

1435
01:25:11,850 --> 01:25:16,840
what we're going to do at this point is to separate this into the problem

1436
01:25:16,840 --> 01:25:18,630
of discrete encoding

1437
01:25:18,640 --> 01:25:26,590
and modulation and modulating you start out with some arbitrary alphabet symbols you turn that

1438
01:25:26,590 --> 01:25:33,380
these symbols in that alphabet into waveforms you transmitter waveforms you then get the symbol

1439
01:25:33,400 --> 01:25:38,210
back and then you put it into a digital encoder which gets the binary digits

1440
01:25:39,570 --> 01:25:42,850
now what order we want to study the set

1441
01:25:42,880 --> 01:25:46,300
well we're going to study the modulation first

1442
01:25:46,740 --> 01:25:50,020
and we're not going to study this at all essentially

1443
01:25:50,050 --> 01:25:53,810
except for a few very very simple minded examples

1444
01:25:53,820 --> 01:25:55,580
six four fifty one

1445
01:25:55,590 --> 01:25:58,310
which is the course it follows after this

1446
01:25:58,310 --> 01:26:00,850
which might or might not be towards

1447
01:26:00,860 --> 01:26:02,320
in the spring term

1448
01:26:02,340 --> 01:26:07,210
and incidentally those of you who wanted to be tortured sent me an email

1449
01:26:07,220 --> 01:26:11,740
saying you really need to take this next term for some reason or other

1450
01:26:11,790 --> 01:26:15,710
and because otherwise it will be given

1451
01:26:15,860 --> 01:26:19,450
in spring of the following year instead of spring of this year

1452
01:26:20,260 --> 01:26:22,480
there's another side to that issue

1453
01:26:22,500 --> 01:26:24,550
which is a wireless course

1454
01:26:24,570 --> 01:26:28,230
it's going to be given in the spring of this year

1455
01:26:28,250 --> 01:26:30,730
and if you want to take away course

1456
01:26:30,750 --> 01:26:34,650
postponed taking the coding course until the following year

1457
01:26:35,030 --> 01:26:39,220
then in fact it might be better to do the postponing job

1458
01:26:39,220 --> 01:26:42,070
i would recommend that those of you who

1459
01:26:42,120 --> 01:26:47,640
are interested in wireless take the course now because if you're looking for research problems

1460
01:26:47,640 --> 01:26:49,770
in the communication area

1461
01:26:49,770 --> 01:26:55,580
wireless is probably the the hottest area around the area where the most interesting problems

1462
01:26:56,380 --> 01:26:59,090
so you have to make the trade off if you want to to take both

1463
01:26:59,280 --> 01:27:01,600
courses grades so many males

1464
01:27:01,670 --> 01:27:05,240
so you want to take the coding course but anyway there will be very little

1465
01:27:05,240 --> 01:27:08,570
coding in this course very little discrete week

1466
01:27:08,600 --> 01:27:12,730
coding and mostly we're going to look at a simple ways of taking simple

1467
01:27:12,750 --> 01:27:14,600
symbol sequences

1468
01:27:14,630 --> 01:27:19,710
turning them into waveforms then transmitting the on channels

1469
01:27:36,000 --> 01:27:37,650
binary symbol

1470
01:27:37,680 --> 01:27:39,310
the way forward

1471
01:27:40,880 --> 01:27:48,790
OK what i go from waveforms directly to waveforms instead of going from waveforms the

1472
01:27:48,790 --> 01:27:53,170
symbols the binary digits and i just have to go back up again

1473
01:27:53,520 --> 01:27:55,370
a bunch of reasons

1474
01:27:55,390 --> 01:28:00,480
one of the reasons is that some of the stuff you transmit is already digital

1475
01:28:00,480 --> 01:28:02,270
to start with

1476
01:28:02,270 --> 01:28:07,470
when you look at what goes over network today for example it is carrying digital

1477
01:28:07,470 --> 01:28:11,410
data is carrying analog data this could carrying images

1478
01:28:11,570 --> 01:28:14,320
carry everything you can imagine

1479
01:28:14,340 --> 01:28:17,360
if you want to design

1480
01:28:17,370 --> 01:28:19,680
a modulation system

1481
01:28:19,720 --> 01:28:24,530
which goes directly from analog data to channel data

1482
01:28:24,540 --> 01:28:28,170
and you have a hundred different kinds of analog

1483
01:28:28,200 --> 01:28:29,710
source data

1484
01:28:29,720 --> 01:28:33,640
and you have a hundred different kinds of channels

1485
01:28:33,660 --> 01:28:38,890
then you're going to have to build one encoder for every one of those hundreds

1486
01:28:38,900 --> 01:28:42,400
for every combination of source channel

1487
01:28:42,410 --> 01:28:45,790
in other words you've got to build ten thousand devices

1488
01:28:45,800 --> 01:28:49,860
if you're interested in keeping engineers employed

1489
01:28:49,880 --> 01:28:53,110
which i think is very good interest

1490
01:28:53,120 --> 01:28:56,880
that's that's a very good philosophy to take

1491
01:28:56,900 --> 01:29:03,810
but but unfortunately most people who build communication equipment say we would really rather have

1492
01:29:03,810 --> 01:29:09,450
just a hundred or two hundred different devices two hundred one hundred devices which turn

1493
01:29:09,450 --> 01:29:15,920
all these different sources into binary digits and another hundred devices which turn the binary

1494
01:29:15,920 --> 01:29:21,310
digits into something that can be transmitted over any channel you want to

1495
01:29:21,310 --> 01:29:24,880
and this is just the general example of what people call layering

1496
01:29:24,910 --> 01:29:27,650
you want to turn systems into

1497
01:29:27,670 --> 01:29:30,150
systems with a bunch of layers and

1498
01:29:30,160 --> 01:29:35,240
where each layer is standardized in some way and only has to take care of

1499
01:29:35,240 --> 01:29:37,610
a few particular functions

1500
01:29:37,810 --> 01:29:41,270
and in fact that's what we're doing here also because we're

1501
01:29:41,280 --> 01:29:46,800
because we're dealing with one layer which is doing discrete encoding

1502
01:29:47,010 --> 01:29:50,000
which in fact this sort of generating

1503
01:29:50,010 --> 01:29:53,910
for the most part binary digits out of the discrete encoder

1504
01:29:54,270 --> 01:29:59,220
where as you go through all this stuff and you come out with binary digits

1505
01:29:59,220 --> 01:30:03,100
some of which are wrong you can do the the decoding and get the correct

1506
01:30:03,100 --> 01:30:04,800
binary digits and

1507
01:30:04,810 --> 01:30:07,550
if you look at the of a lot of coding theory

1508
01:30:07,550 --> 01:30:10,550
you will find that it doesn't pay any attention at all

1509
01:30:10,610 --> 01:30:13,780
the what's going on in the channel

1510
01:30:13,800 --> 01:30:18,660
lots of people have studied coding of their lives and decoding of their lives living

1511
01:30:18,660 --> 01:30:21,810
this mathematical theory of abstract algebra

1512
01:30:21,880 --> 01:30:24,830
and i had no idea of what channels are

1513
01:30:24,850 --> 01:30:28,630
and they survive because of this layering principle

1514
01:30:28,650 --> 01:30:32,220
so if you want to employ engineers it's nice to have layering

1515
01:30:32,230 --> 01:30:36,260
because engineers that after that was much better

1516
01:30:36,300 --> 01:30:39,020
course you people should know what all so

1517
01:30:39,020 --> 01:30:41,370
there are problems with computing the posterior bayesian

1518
01:30:41,870 --> 01:30:42,830
and this is statistics

1519
01:30:43,270 --> 01:30:44,930
but that's because you have to compute

1520
01:30:45,310 --> 01:30:47,760
these this quotient and it contains an integral

1521
01:30:48,180 --> 01:30:49,240
now the evidence term

1522
01:30:50,100 --> 01:30:54,350
in the denominator is an integral and that can be hard to compute that is an entirely different problem

1523
01:30:55,160 --> 01:30:59,620
and this is not about whether it's hard to compute this is whether about this quantity exists or does not

1524
01:31:05,720 --> 01:31:05,990
and with

1525
01:31:08,830 --> 01:31:11,790
so far the dirichlet process for example it happens i don't want to go into

1526
01:31:11,790 --> 01:31:13,390
much detail because it gets a bit technical

1527
01:31:13,950 --> 01:31:14,560
but basically

1528
01:31:18,520 --> 01:31:21,410
the problem is that these these nonparametric models can get

1529
01:31:24,180 --> 01:31:26,810
the posterior is a family is a family of distributions

1530
01:31:27,220 --> 01:31:28,260
right you get one

1531
01:31:29,140 --> 01:31:30,890
different probability for each possible

1532
01:31:31,310 --> 01:31:31,990
observation here

1533
01:31:35,060 --> 01:31:39,660
basically in these nonparametric models be this family can get too large and diverse

1534
01:31:40,810 --> 01:31:41,560
so the two

1535
01:31:43,140 --> 01:31:44,200
what you want to have

1536
01:31:44,640 --> 01:31:49,220
four or what you would need to have fuzzy force this equation to exist is that every single

1537
01:31:49,720 --> 01:31:52,890
element of this family is absolutely continuous with respect to the prior

1538
01:31:53,740 --> 01:31:57,440
and basically these families are too large and diverse for this to be possible for

1539
01:31:57,440 --> 01:31:59,560
all elements your new way that you can

1540
01:31:59,930 --> 01:32:01,930
you could get that is by making this measure here

1541
01:32:03,720 --> 01:32:04,810
down on sigma finance

1542
01:32:06,680 --> 01:32:08,100
and and models for rich so

1543
01:32:08,580 --> 01:32:09,620
basically models for which

1544
01:32:13,220 --> 01:32:15,560
families of distributions for which that's not possible

1545
01:32:16,000 --> 01:32:19,290
to make them all absolutely continuous with respect to one distribution

1546
01:32:19,890 --> 01:32:21,310
i called nondominated models

1547
01:32:23,140 --> 01:32:28,620
and so otherwise if if that's possible then you say that this measure dominates the the family yeah

1548
01:32:31,850 --> 01:32:35,520
one example of that are directly process measures are basically all these

1549
01:32:36,370 --> 01:32:39,520
the the measures based on random discrete measures that we saw yesterday

1550
01:32:40,100 --> 01:32:43,720
yeah so directly processes pitman yor process all these distributions

1551
01:32:46,310 --> 01:32:48,680
intuitively the problem is that that these

1552
01:32:50,270 --> 01:32:51,310
because the discreteness

1553
01:32:52,040 --> 01:32:53,930
they can they can put their masks

1554
01:32:54,470 --> 01:32:55,620
at individual points

1555
01:32:56,270 --> 01:32:59,060
but the space has an uncountable number of points

1556
01:32:59,580 --> 01:33:03,080
so there is an uncountable number of possible patterns where they can place their masks

1557
01:33:04,520 --> 01:33:05,080
if you would like

1558
01:33:05,540 --> 01:33:07,290
if you would like to have a density like this

1559
01:33:07,700 --> 01:33:11,160
and then what you would need is a measure here which puts positive mass every

1560
01:33:11,160 --> 01:33:13,490
single one of these points and that's just too much

1561
01:33:26,270 --> 01:33:27,240
i'm not going to dwell on this

1562
01:33:28,470 --> 01:33:28,990
but the

1563
01:33:32,240 --> 01:33:33,100
if you're interested

1564
01:33:33,930 --> 01:33:34,990
you know you will

1565
01:33:36,060 --> 01:33:39,410
you would just have to look into the literature and read it up and no it's not

1566
01:33:39,830 --> 01:33:43,020
easy i went through it at some point and i can tell you it's a

1567
01:33:43,870 --> 01:33:45,060
yeah it takes its time

1568
01:33:46,180 --> 01:33:47,770
just the message i want to convey is

1569
01:33:50,470 --> 01:33:55,430
in bayes nonparametrics really cannot think of a bayesian model has been defined in terms of basic equations

1570
01:33:56,560 --> 01:33:58,540
three the other way around to define a bayesian model

1571
01:33:59,080 --> 01:34:01,330
if you're lucky it satisfies the bayes equation

1572
01:34:01,990 --> 01:34:04,310
and that tells you how to get from the prior to the posterior

1573
01:34:05,870 --> 01:34:08,240
and bayesian nonparametrics it often doesn't work

1574
01:34:09,240 --> 01:34:12,160
and then we have to find some kind of substitute we have to find some

1575
01:34:12,390 --> 01:34:14,200
way of connecting the prior to the posterior

1576
01:34:15,520 --> 01:34:19,100
and it turned out that the way that it's done in bayesian nonparametrics as conjugacy

1577
01:34:19,350 --> 01:34:20,390
and we will get back to that

1578
01:34:22,240 --> 01:34:23,560
like two three slides on

1579
01:34:29,620 --> 01:34:30,520
i'm i'm going to spend

1580
01:34:32,080 --> 01:34:33,040
three or four slides

1581
01:34:33,700 --> 01:34:36,560
i'm trying to tell you how how these problems can be addressed

1582
01:34:38,290 --> 01:34:40,660
end of

1583
01:34:41,520 --> 01:34:43,350
i also wanted to use this at the

1584
01:34:44,290 --> 01:34:47,330
an opportunity to to try to show you how the girls in process and the

1585
01:34:47,330 --> 01:34:49,040
dirichlet processes are related to each other

1586
01:34:51,470 --> 01:34:52,040
okay so

1587
01:34:53,640 --> 01:34:55,370
this morning you heard john talking about

1588
01:34:56,270 --> 01:34:58,040
about the gaussianprocess and he told u

1589
01:34:59,410 --> 01:35:00,350
if you recall the

1590
01:35:00,520 --> 01:35:01,140
the definition

1591
01:35:03,850 --> 01:35:06,720
the girls in process is a distribution that gives us a function that

1592
01:35:07,180 --> 01:35:08,370
is it is a distribution that

1593
01:35:09,240 --> 01:35:13,390
on random functions right so we have a random function that we sample from the

1594
01:35:13,430 --> 01:35:15,220
gaussianprocess say on the interval maybe

1595
01:35:15,890 --> 01:35:16,580
and which maps to

1596
01:35:19,870 --> 01:35:21,700
that means that if we use this has

1597
01:35:22,120 --> 01:35:23,620
say a nonparametric regression

1598
01:35:24,140 --> 01:35:26,700
then the patterns that we are using are

1599
01:35:27,470 --> 01:35:31,660
continuous functions so the parameter space of our model is a set of continuous functions

1600
01:35:32,390 --> 01:35:32,770
on may be

1601
01:35:34,930 --> 01:35:36,200
and i have a picture here where we see

1602
01:35:37,200 --> 01:35:40,910
there we see a bunch of samples from a gaussianprocess which are these functions and then you

1603
01:35:42,060 --> 01:35:46,100
where they all you know where they are trained using point that's where observations are

1604
01:35:46,620 --> 01:35:49,450
so this conditions as the posterior conditioned on observations

1605
01:35:49,990 --> 01:35:53,790
and that these few points for the observations were we exactly know the value

1606
01:35:54,260 --> 01:35:55,310
and otherwise we answer

1607
01:35:57,020 --> 01:36:00,160
so here this but a specific point we have location est

1608
01:36:00,720 --> 01:36:01,520
between you and me

1609
01:36:02,270 --> 01:36:04,540
and this is the function value of the random function

1610
01:36:07,020 --> 01:36:09,330
so now recall the definition that john view that is

1611
01:36:10,180 --> 01:36:14,700
we call this a gaussianprocess because this function the gaussianprocess if the following holds if

1612
01:36:14,700 --> 01:36:17,850
we can take any finite subset of points down here

1613
01:36:21,040 --> 01:36:21,700
we look at this

1614
01:36:22,080 --> 01:36:26,910
vector here so we plucked we take the vector of function values at this finite subset of points

1615
01:36:27,930 --> 01:36:30,540
now since the function is a random this is a random vector

1616
01:36:31,040 --> 01:36:36,080
it has a probability distribution and we say that the girls and processes that if the distribution is a gas

1617
01:36:37,120 --> 01:36:39,620
whiskey dimensions because it's the vector of laxity

1618
01:36:44,520 --> 01:36:49,620
this is this is the definition and john said already this morning that that this object exists is not

1619
01:36:50,740 --> 01:36:51,660
not a triviality

1620
01:36:52,180 --> 01:36:52,910
and it's not

1621
01:36:53,790 --> 01:36:55,700
by any means clear that this are actually exist but

1622
01:36:56,120 --> 01:37:00,270
the kind of the intuition behind construction of because the results which guarantee that this

1623
01:37:00,490 --> 01:37:02,000
this actually works is the following

1624
01:37:03,540 --> 01:37:05,740
if you imagine we start from a gaussianprocess

1625
01:37:06,770 --> 01:37:07,640
like this right

1626
01:37:08,080 --> 01:37:08,680
and we

1627
01:37:09,060 --> 01:37:13,310
we look at these possible distributions that we get four different sets of points here

1628
01:37:14,640 --> 01:37:17,870
and these distributions are related to each other in some way right they can be

1629
01:37:18,200 --> 01:37:23,410
arbitrary because they are all marginal distributions of one and the same infinite dimensional probability

1630
01:37:25,790 --> 01:37:26,850
so in particular

1631
01:37:27,310 --> 01:37:27,950
if we take

1632
01:37:28,410 --> 01:37:30,220
if we take some set of points here

1633
01:37:31,200 --> 01:37:32,950
and look at the distribution that we get from that

1634
01:37:33,560 --> 01:37:35,470
and then we take a subset of these points

1635
01:37:36,220 --> 01:37:36,700
it again

1636
01:37:37,410 --> 01:37:38,890
look at the distribution that we get from

1637
01:37:39,850 --> 01:37:43,890
then the first is that the second distribution will be a margin of the first one

1638
01:37:45,720 --> 01:37:46,270
that makes sense

1639
01:37:48,180 --> 01:37:48,720
okay so

1640
01:37:49,740 --> 01:37:51,950
these distributions are all marginals of each other

1641
01:37:52,660 --> 01:37:56,020
if we take two sets overlap two sets of points that overlap

1642
01:37:57,430 --> 01:38:00,740
then once again the marginal on the common set of points

1643
01:38:01,490 --> 01:38:04,720
the two marginals on the commons the points that they have in common will coincide

1644
01:38:06,180 --> 01:38:09,830
so we have a kind of coherence condition between these different distributions that we get

1645
01:38:09,830 --> 01:38:13,180
for different sets of points down here that they all have to marginalize

1646
01:38:13,850 --> 01:38:14,390
to produce a

1647
01:38:17,120 --> 01:38:20,330
that's simply because they're all marginals of one and the same goes process

1648
01:38:22,220 --> 01:38:24,240
if we know all these distributions here

1649
01:38:24,910 --> 01:38:26,410
all possible sets of points

1650
01:38:26,950 --> 01:38:28,850
then we can ask conversely

1651
01:38:30,200 --> 01:38:34,390
if we start with these distributions and they have this coherence property that they're all

1652
01:38:34,390 --> 01:38:37,020
marginals of each other doesn't define the gaussianprocess

1653
01:38:37,890 --> 01:38:38,950
and there are results in

1654
01:38:38,950 --> 01:38:44,660
starting from the data selecting the day the target data for analysis then pre processing

1655
01:38:44,660 --> 01:38:52,950
it in an appropriate form trying to eliminate and missing data noisy data irregularities since

1656
01:38:52,950 --> 01:38:57,010
forming it into the programme which is appropriate for the data mining tool which we

1657
01:38:57,010 --> 01:39:01,860
have selected then we get the patterns or the models

1658
01:39:01,880 --> 01:39:07,260
which we have induced from the data and finally we have evaluation hopefully leading to

1659
01:39:07,260 --> 01:39:12,230
some use new piece of knowledge and as you see and interactive process when we

1660
01:39:12,230 --> 01:39:20,780
return back to different steps trying to improve the data itself and also trying to

1661
01:39:20,780 --> 01:39:26,410
improve the data analysis before the final selection and evaluation

1662
01:39:27,720 --> 01:39:30,330
so interesting enough the

1663
01:39:30,340 --> 01:39:32,580
the process of data mining

1664
01:39:32,600 --> 01:39:37,720
although it is the key facing the knowledge discovery process

1665
01:39:38,230 --> 01:39:42,530
it only takes a minor part of the entire process in terms of the data

1666
01:39:42,530 --> 01:39:49,710
cleaning and preparation is extremely laborious compared to data mining itself

1667
01:39:49,730 --> 01:39:51,900
so i'm going out to some

1668
01:39:51,920 --> 01:39:55,450
examples of discovered patterns and their applications

1669
01:39:55,470 --> 01:40:01,400
this example crowned from large project we were coordinating carpools of stefan institute

1670
01:40:01,460 --> 01:40:05,940
this was in the years two thousand to two thousand three the protein was named

1671
01:40:05,940 --> 01:40:12,920
data mining and decision support for business competitiveness european virtual enterprise which has been called

1672
01:40:12,920 --> 01:40:18,360
it mated by ourselves we had twelve partners involved it was the three million euro

1673
01:40:19,730 --> 01:40:24,470
eight academic partners and for business partners from seven different countries in europe

1674
01:40:24,480 --> 01:40:29,530
and the idea was to use data mining and decision support for building useful

1675
01:40:29,550 --> 01:40:36,670
solutions for end users they were developed until the prototype phase a and that was

1676
01:40:36,670 --> 01:40:41,420
covered by the money of the project and we also had the goal of finding

1677
01:40:41,440 --> 01:40:47,800
virtual enterprise for marketing data mining and decision support expertise involving business and academia

1678
01:40:47,940 --> 01:40:54,330
actually such virtual enterprise model was developed how different partners across europe was

1679
01:40:54,340 --> 01:40:59,090
work collaboratively in data mining and decision support tasks

1680
01:41:00,360 --> 01:41:10,530
developed ideas how and mechanisms how how to work collaboratively in data mining projects

1681
01:41:10,540 --> 01:41:12,240
there was the number of

1682
01:41:12,250 --> 01:41:19,330
prototype developments within this project starting from analysis of media research data were our client

1683
01:41:19,340 --> 01:41:23,210
was an indiana company we

1684
01:41:23,240 --> 01:41:25,220
worked for clean air and clean air

1685
01:41:25,440 --> 01:41:31,750
another marketing company trying to improve brand name recognition we worked on the data for

1686
01:41:31,750 --> 01:41:33,870
an australian financial house

1687
01:41:33,890 --> 01:41:38,710
doing quality evaluation of customers and stock market prediction

1688
01:41:38,720 --> 01:41:45,480
four checks check how far we were predicting the use of resources like people going

1689
01:41:45,510 --> 01:41:47,970
to a swimming pool people

1690
01:41:47,980 --> 01:41:53,690
having massage within hours and how resources will be used for

1691
01:41:53,900 --> 01:41:58,550
every week by new people coming to the house farm and then worked for the

1692
01:41:58,550 --> 01:42:02,060
UK county council and i will

1693
01:42:02,070 --> 01:42:07,960
illustrate the the KDD process also through this application it was the analysis of traffic

1694
01:42:07,960 --> 01:42:09,350
accident data of

1695
01:42:10,050 --> 01:42:13,400
UK accidents which occurred in twenty years

1696
01:42:15,270 --> 01:42:16,650
in the last twenty years

1697
01:42:16,930 --> 01:42:22,100
we also did an application for a portuguese statistical bureau about web page

1698
01:42:22,270 --> 01:42:27,460
access analysis and the idea was that based on the understanding of how people

1699
01:42:28,570 --> 01:42:34,300
the web pages of the statistical bureau can we learn how to improve the web

1700
01:42:34,300 --> 01:42:36,270
page organisation

1701
01:42:36,280 --> 01:42:44,740
we developed an application for for the zagreb medical centre coronary heart disease risk group

1702
01:42:44,780 --> 01:42:55,340
prediction and detection we had an interesting application for a small english company who's doing

1703
01:42:55,340 --> 01:42:56,720
online dating

1704
01:42:56,720 --> 01:43:00,220
and that requires defining

1705
01:43:00,240 --> 01:43:03,420
what is the threat to the public health

1706
01:43:03,470 --> 01:43:06,530
if you're mandated tetanus immunization

1707
01:43:06,800 --> 01:43:11,220
this is not a communicable disease you need to be clear as to why you're

1708
01:43:11,220 --> 01:43:12,260
doing it

1709
01:43:12,260 --> 01:43:15,820
is it because of the state's interest to protect children

1710
01:43:15,840 --> 01:43:19,990
or because of the cost to take care of people who have to this

1711
01:43:20,010 --> 01:43:21,280
you need to

1712
01:43:21,300 --> 01:43:25,820
so for some future disease we to explain the rationale

1713
01:43:25,840 --> 01:43:32,240
you don't want to mandate a immunization unless there is broad support within the medical

1714
01:43:32,240 --> 01:43:34,320
community for

1715
01:43:34,360 --> 01:43:36,280
you see that vaccine

1716
01:43:36,300 --> 01:43:42,490
the rationale has to be transparent and clear and the process of amending should engage

1717
01:43:42,490 --> 01:43:44,050
the public

1718
01:43:44,070 --> 01:43:49,510
and the washington state board of health in fact has adopted a series of criteria

1719
01:43:50,240 --> 01:43:54,240
with which it will approach future vaccines

1720
01:43:54,320 --> 01:43:56,150
decision making about

1721
01:43:56,170 --> 01:43:59,860
vaccines needs to be informed

1722
01:43:59,930 --> 01:44:02,590
we need to monitor exemption rates

1723
01:44:02,610 --> 01:44:03,760
when people

1724
01:44:03,920 --> 01:44:09,030
i asked for exemptions we need to understand their reasons

1725
01:44:09,070 --> 01:44:14,690
and the process for exemption should be thoughtful we need to discourage what we call

1726
01:44:14,690 --> 01:44:18,240
convenience exemptions which is check the box

1727
01:44:18,240 --> 01:44:22,840
i object in order to get your child registered for schools

1728
01:44:22,840 --> 01:44:27,860
fond of pointing out that in washington state to people to agencies that work for

1729
01:44:27,900 --> 01:44:28,880
the governor

1730
01:44:28,920 --> 01:44:32,260
work at cross-purposes health department

1731
01:44:32,280 --> 01:44:34,110
get kids immunized

1732
01:44:34,110 --> 01:44:38,090
the office of public instruction wants to get the kids in school

1733
01:44:38,150 --> 01:44:40,860
if you can get in school in most

1734
01:44:40,860 --> 01:44:44,280
immunize the school doesn't get paid for their pupils

1735
01:44:44,300 --> 01:44:50,030
so somehow we need to remove the financial incentive to opt out in order to

1736
01:44:50,030 --> 01:44:52,860
get the child registered for school

1737
01:44:52,860 --> 01:44:57,970
also i think we need to employ imposing with some of my colleagues are in

1738
01:44:57,970 --> 01:45:03,720
favour of which is what i call irrelevant kernels two exemptions such as having the

1739
01:45:03,740 --> 01:45:06,280
parents objections no rights

1740
01:45:06,320 --> 01:45:07,650
which i don't think

1741
01:45:09,200 --> 01:45:13,300
educated about the risks and benefits

1742
01:45:13,380 --> 01:45:17,280
and finally an exemption should be time limited

1743
01:45:17,740 --> 01:45:21,400
unless it's for a reversible medical condition

1744
01:45:21,450 --> 01:45:25,760
so that people will come back and revisit the issue

1745
01:45:25,800 --> 01:45:34,260
and where we have widely held erroneous beliefs perceptions those should be confronted

1746
01:45:34,280 --> 01:45:38,360
and the one i would like to just address very quickly is the concept that

1747
01:45:38,360 --> 01:45:44,860
multiple vaccines administered simultaneously overwhelmed the immune system

1748
01:45:44,880 --> 01:45:47,220
and it's relatively easy to

1749
01:45:47,220 --> 01:45:51,090
are to point out the that's fallacious

1750
01:45:51,110 --> 01:45:57,130
back when we were using smallpox vaccine whole self protesters vaccine

1751
01:45:57,240 --> 01:46:00,570
the number of immunogenic antigens

1752
01:46:00,570 --> 01:46:04,340
that we would inject that greatly exceeds

1753
01:46:04,360 --> 01:46:07,930
all vaccines that we administer today

1754
01:46:07,990 --> 01:46:15,280
we go through that one more time the smallpox virus vaccine has two hundred separate

1755
01:46:15,280 --> 01:46:17,260
immunogenic antigens

1756
01:46:17,340 --> 01:46:20,550
the vaccines were giving the total

1757
01:46:20,590 --> 01:46:23,490
somewhere around one hundred twenty five

1758
01:46:23,590 --> 01:46:27,590
so the actual new world is actually less

1759
01:46:27,720 --> 01:46:34,050
now i couldn't come to southern california without talking about the problem with selective

1760
01:46:34,050 --> 01:46:36,490
an alternative schedule

1761
01:46:36,490 --> 01:46:40,880
some new options other than the recommended schedule

1762
01:46:40,950 --> 01:46:42,780
one of the

1763
01:46:43,780 --> 01:46:46,220
objections to that skip the

1764
01:46:46,260 --> 01:46:49,920
schedules are they really undercuts

1765
01:46:49,920 --> 01:46:52,270
and then

1766
01:47:04,950 --> 01:47:06,720
well that's actually the

1767
01:47:06,780 --> 01:47:10,050
test so as the training error i guess

1768
01:47:10,070 --> 01:47:11,560
you're thinking of

1769
01:47:11,570 --> 01:47:14,870
this is what this is the test error so it's small

1770
01:47:14,900 --> 01:47:17,260
it's i mean that's certainly

1771
01:47:17,300 --> 01:47:20,830
would be the right estimation on the training set

1772
01:47:20,850 --> 01:47:25,190
but what i was looking for was an expression for this in terms of the

1773
01:47:25,190 --> 01:47:27,600
probabilities of these events

1774
01:47:27,900 --> 01:47:30,350
anyone else have

1775
01:47:35,650 --> 01:47:43,650
could be expressed in a way officially i actually was thinking of well let me

1776
01:47:43,650 --> 01:47:49,330
let me show you what i was thinking and hopefully will be clear so

1777
01:47:49,340 --> 01:47:52,060
if we take that

1778
01:47:52,200 --> 01:47:53,760
have to do this

1779
01:47:57,210 --> 01:47:58,970
we take that

1780
01:48:01,410 --> 01:48:03,910
x y

1781
01:48:06,380 --> 01:48:09,320
functions just write a s

1782
01:48:18,110 --> 01:48:22,070
essentially we can write that as the

1783
01:48:23,950 --> 01:48:24,600
thank you

1784
01:48:26,810 --> 01:48:29,930
we can write that as the probability

1785
01:48:30,750 --> 01:48:33,840
a s

1786
01:48:33,860 --> 01:48:36,380
so the probability that a

1787
01:48:36,390 --> 01:48:38,840
as of today

1788
01:48:38,840 --> 01:48:40,420
is equal

1789
01:48:40,440 --> 01:48:41,930
two y

1790
01:48:43,070 --> 01:48:46,900
zero because the loss is zero in that case

1791
01:48:48,280 --> 01:48:51,030
the probability that a

1792
01:48:51,060 --> 01:48:52,620
of x

1793
01:48:52,680 --> 01:48:54,810
is not equal to y

1794
01:48:54,820 --> 01:49:00,580
times one because the loss in that case this is just working out their expectations

1795
01:49:00,600 --> 01:49:02,020
in terms of the

1796
01:49:02,020 --> 01:49:04,600
different events that can occur

1797
01:49:05,340 --> 01:49:06,910
remember the discrete loss

1798
01:49:08,290 --> 01:49:10,580
it isn't perfectly

1799
01:49:15,850 --> 01:49:17,540
can you back and said OK

1800
01:49:17,860 --> 01:49:20,100
OK so

1801
01:49:20,130 --> 01:49:23,420
that means that of course this

1802
01:49:23,820 --> 01:49:28,110
his doesn't occur and it actually just equals

1803
01:49:30,450 --> 01:49:32,340
that the function

1804
01:49:32,350 --> 01:49:34,360
applied to the

1805
01:49:34,390 --> 01:49:36,090
new test point

1806
01:49:36,720 --> 01:49:38,800
not equal to the correct

1807
01:49:38,800 --> 01:49:40,330
so in other words this

1808
01:49:40,340 --> 01:49:43,600
in this case this generalization for the discrete loss

1809
01:49:43,630 --> 01:49:46,380
it's just the probability of misclassification

1810
01:49:46,400 --> 01:49:47,890
that's all i was trying to

1811
01:49:47,900 --> 01:49:50,020
to try that maybe i didn't express

1812
01:49:50,030 --> 01:49:54,470
very clearly this just in that case very becomes very simple expression

1813
01:49:54,490 --> 01:49:55,720
this is a everyone happy

1814
01:49:55,740 --> 01:49:56,770
with the idea

1815
01:49:57,620 --> 01:50:00,540
any questions

1816
01:50:02,800 --> 01:50:06,550
so i just wanted to get faced by all these i mean one

1817
01:50:06,600 --> 01:50:08,340
big problems with theory

1818
01:50:08,350 --> 01:50:09,420
is that

1819
01:50:09,440 --> 01:50:11,860
because you have to write things down

1820
01:50:12,960 --> 01:50:16,520
you get all of this sort of garbage of

1821
01:50:17,740 --> 01:50:20,790
and that's just i mean once you get used to it is just to sort

1822
01:50:20,790 --> 01:50:23,260
of symbols and the idea is not actually

1823
01:50:23,270 --> 01:50:27,700
difficult or complicated really it's is just you get face by simple so part of

1824
01:50:27,700 --> 01:50:30,590
it is to just work with a little bit and get

1825
01:50:30,600 --> 01:50:32,860
familiar with the symbols in the way that they

1826
01:50:32,900 --> 01:50:36,900
so you know this looks horrible horrid but in this case it just it

1827
01:50:36,950 --> 01:50:39,750
reduced something very simple

1828
01:50:45,240 --> 01:50:47,140
this this is really a very

1829
01:50:47,160 --> 01:50:52,450
i think important i need with respect

1830
01:50:53,590 --> 01:50:57,070
so this quantity

1831
01:50:58,420 --> 01:51:00,830
s a

1832
01:51:00,830 --> 01:51:06,970
this is the expected value of the loss on randomly generated test point in the

1833
01:51:06,970 --> 01:51:09,390
case of classification is just the probability

1834
01:51:09,500 --> 01:51:13,120
the randomly generated point is misclassified

1835
01:51:13,150 --> 01:51:18,070
if you think of running your algorithm with the training and test sets your test

1836
01:51:18,070 --> 01:51:19,600
set error

1837
01:51:19,970 --> 01:51:26,150
which perhaps is also what you're referring to maybe is is an estimate of this

1838
01:51:26,180 --> 01:51:28,950
it's the sample estimate based on actually

1839
01:51:28,970 --> 01:51:33,310
looking at the track the test examples which you assume again and generated according to

1840
01:51:33,310 --> 01:51:35,630
the same distribution so it's a good

1841
01:51:35,650 --> 01:51:39,920
estimate of the quantity but from a theoretical point of view we prefer to think

1842
01:51:39,920 --> 01:51:45,910
of this as the quantity really interested in is the pure probability of misclassification of

1843
01:51:45,910 --> 01:51:47,240
randomly generated

1844
01:51:49,020 --> 01:51:50,100
so i want to

1845
01:51:50,330 --> 01:51:52,100
try and

1846
01:51:52,120 --> 01:51:55,070
give an example of of what this

1847
01:51:55,080 --> 01:52:00,390
random variable is how it looks in particular concrete case because i think it if

1848
01:52:00,390 --> 01:52:04,360
you can build up a picture in your mind of what this random variable distribution

1849
01:52:04,360 --> 01:52:08,360
looks like a lot of learning theory starts to make sense you can see what

1850
01:52:08,360 --> 01:52:12,120
what learning theories attempting to achieve so i'm not going to give you an example

1851
01:52:12,120 --> 01:52:14,040
which is

1852
01:52:14,050 --> 01:52:15,170
real world data

1853
01:52:15,190 --> 01:52:21,160
breast cancer dataset from the UCI repository i'm going to do a very simple parzen

1854
01:52:21,160 --> 01:52:25,440
window classifier as described by bernard shaw carpet the beginning of his

1855
01:52:26,880 --> 01:52:34,550
so the weight vector is actually just this it's a linear function classifier thresholded linear

1856
01:52:34,550 --> 01:52:40,900
function the weight vector is just the average of the positive training examples

1857
01:52:41,220 --> 01:52:45,160
minus the average of the negative so if you can imagine the you know the

1858
01:52:45,450 --> 01:52:48,100
is cloud of positive put

1859
01:52:48,110 --> 01:52:52,370
point in the central that a cloud of negative point in the center that join

1860
01:52:52,380 --> 01:52:53,320
the two

1861
01:52:53,320 --> 01:52:56,280
and bisects the line between

1862
01:52:56,300 --> 01:52:59,360
that's the hyperplane that we're can use to classify

1863
01:52:59,380 --> 01:53:01,050
OK it's very very simple

1864
01:53:04,630 --> 01:53:09,390
and what i'm going to look at is i'm gonna repeatedly draw random

1865
01:53:09,400 --> 01:53:11,340
training sets as

1866
01:53:11,380 --> 01:53:15,190
and i'm going to get an estimate of this distribution i'm actually going to create

1867
01:53:15,190 --> 01:53:19,270
a histogram of the distribution of the errors

1868
01:53:19,270 --> 01:53:23,200
so each time i draw a random training set i going

1869
01:53:23,220 --> 01:53:26,040
compute the sky of causing i'm going to compute in the way

1870
01:53:26,040 --> 01:53:27,530
that we always do

1871
01:53:27,540 --> 01:53:30,040
estimating on on the test set

1872
01:53:30,060 --> 01:53:34,100
OK i can't help but because it's so you know if you have some

1873
01:53:34,120 --> 01:53:37,360
abstract problem where you can define the true error but in our case we got

1874
01:53:37,360 --> 01:53:38,860
a concrete

1875
01:53:38,860 --> 01:53:42,430
datasets on this can use the test error as a proxy for this

1876
01:53:42,450 --> 01:53:44,810
so i'm going

1877
01:53:44,830 --> 01:53:47,390
repeatedly generate random training sets

1878
01:53:47,420 --> 01:53:52,070
use the remainder of the data as the test set an estimate this quantity after

1879
01:53:52,070 --> 01:53:54,850
applying this very simple algorithm

1880
01:53:55,890 --> 01:54:00,140
possibly no estimator and i'm going to plot the histogram and the average of the

1881
01:54:00,140 --> 01:54:05,190
distribution of this quantity for various sizes of training set

1882
01:54:06,170 --> 01:54:07,830
now if i take the whole

1883
01:54:07,840 --> 01:54:12,250
dataset then that will give a single value because essentially there's just one function is

1884
01:54:12,250 --> 01:54:16,540
the average of the positive and negative and then apply it to the same set

1885
01:54:16,550 --> 01:54:19,110
and just just like a sort of if you like

1886
01:54:19,320 --> 01:54:22,400
o thing we might aim for the person the best you could possibly do with


1
00:00:00,000 --> 00:00:03,950
large amount explains a very large amount of data that's a good theory

2
00:00:03,970 --> 00:00:05,620
it means you understand

3
00:00:05,670 --> 00:00:09,980
and it turns out if you if you with this model is easy to show

4
00:00:10,870 --> 00:00:15,590
most finite strings of bits about our data have no theory

5
00:00:15,600 --> 00:00:18,420
smaller than than their own size

6
00:00:18,490 --> 00:00:21,690
so this would be the most of was most strings of bits

7
00:00:21,760 --> 00:00:25,850
the vast majority are lawless according to this criterion there is no theory

8
00:00:25,900 --> 00:00:28,340
no real theory because the

9
00:00:28,400 --> 00:00:31,960
sure is the smallest program that calculates exactly

10
00:00:31,980 --> 00:00:36,720
that string is the same size really does not calculation just as just produces an

11
00:00:36,760 --> 00:00:41,630
output you know something directly without doing any calculations

12
00:00:41,680 --> 00:00:43,420
OK so so

13
00:00:46,030 --> 00:00:47,060
so this

14
00:00:47,730 --> 00:00:54,210
so so in this model that one extreme is random or lawless data for which

15
00:00:54,250 --> 00:00:57,070
the program has to be the same size and therefore is not considered to be

16
00:00:57,070 --> 00:00:59,990
understanding real theory the other extreme

17
00:01:00,040 --> 00:01:04,580
is that what the best theory before data which really does file well it would

18
00:01:04,580 --> 00:01:07,330
be the smallest program that produces that

19
00:01:07,340 --> 00:01:09,500
that data that explains the data

20
00:01:09,520 --> 00:01:11,290
that would be the simplest theory

21
00:01:21,000 --> 00:01:25,260
like this you can distinguish this is your experimental data from a physical system

22
00:01:25,310 --> 00:01:29,150
if you use physical system is a finite string of zeroes and ones is behaviour

23
00:01:29,150 --> 00:01:31,720
is a function of time see then

24
00:01:31,740 --> 00:01:35,450
you would say that this is lawless or randomly

25
00:01:35,760 --> 00:01:42,610
if the smallest program to calculate it is no better than is no smaller than

26
00:01:42,610 --> 00:01:44,040
has the same number of bits

27
00:01:44,050 --> 00:01:51,740
well the complexity is measured in the size in bits of the fear so a

28
00:01:51,740 --> 00:01:55,840
small number of bits here means this is actually very simple and if this is

29
00:01:55,840 --> 00:01:59,810
as large as this then this is irreducible complexity there's no real theory

30
00:01:59,830 --> 00:02:02,010
and that's the majority of cases yes

31
00:02:02,060 --> 00:02:06,730
yes it to ensure

32
00:02:06,740 --> 00:02:11,790
well it's a serious problem

33
00:02:11,800 --> 00:02:16,520
that's a very good question it means it means what you pointing out is i

34
00:02:16,520 --> 00:02:20,790
have no way to find the best theory i have no way to decide if

35
00:02:20,790 --> 00:02:24,550
if a theory if data has a theory or not and and i have no

36
00:02:24,550 --> 00:02:29,640
way to know if i have the best theory in fact that is the main

37
00:02:29,650 --> 00:02:31,080
application of this

38
00:02:31,080 --> 00:02:32,070
OK so

39
00:02:32,100 --> 00:02:34,340
it's it's sort of a different viewpoint on

40
00:02:34,370 --> 00:02:37,540
the halting problem so let me tell you

41
00:02:37,550 --> 00:02:41,510
that's so the first thing in this theory is can you find out what this

42
00:02:41,590 --> 00:02:44,760
is what the best areas that would be the smallest program that gives you the

43
00:02:44,760 --> 00:02:49,590
data what can you determine if a string of bits has theory

44
00:02:49,610 --> 00:02:53,560
you know program that smaller the answer in general is you can't

45
00:02:54,850 --> 00:02:58,330
there's no algorithm and there's no way to

46
00:02:58,340 --> 00:02:59,870
to prove it so

47
00:02:59,890 --> 00:03:03,550
so that gives you an incompleteness results based on this notion in other words let

48
00:03:03,550 --> 00:03:04,630
me put it this way

49
00:03:04,710 --> 00:03:08,080
one way to put it is called the program elegant let me talk about elegant

50
00:03:08,080 --> 00:03:10,840
programs so i'm not going to talk about theories

51
00:03:10,840 --> 00:03:11,920
any more

52
00:03:11,940 --> 00:03:13,340
a theory

53
00:03:13,360 --> 00:03:15,560
another program

54
00:03:15,570 --> 00:03:18,850
well defined to be a program that is the smallest

55
00:03:18,900 --> 00:03:22,750
that there is no smaller programs like if no smaller OK i remember i'm not

56
00:03:22,750 --> 00:03:24,540
concerned with runtime

57
00:03:24,580 --> 00:03:27,100
i'm only concerned with the size of the program

58
00:03:27,120 --> 00:03:32,860
the the complete compact conceptual complexity not concerned with practical complexity issues like time or

59
00:03:32,860 --> 00:03:35,840
have just with conceptual concerns

60
00:03:36,010 --> 00:03:39,060
think it so called the program elegant

61
00:03:39,100 --> 00:03:43,440
if it is no program that is smaller than it produces the same output so

62
00:03:43,440 --> 00:03:47,390
this would be the best theory for its output if you if you use programs

63
00:03:47,390 --> 00:03:51,290
as theories rather than equations and elegant program would be the best theory for its

64
00:03:51,290 --> 00:03:55,350
output OK so what if we want to prove that we have the best theory

65
00:03:55,360 --> 00:03:59,570
you know that we this was not a particular program that we're interested in is

66
00:03:59,570 --> 00:04:03,340
in fact the best theory for its output that there is no program more concise

67
00:04:03,340 --> 00:04:07,240
that produces the same output yes you are

68
00:04:07,250 --> 00:04:12,870
there may be several there may be several i could maybe several elegant programs to

69
00:04:12,880 --> 00:04:17,480
produce the same output could be attacked it's true so let's say we have one

70
00:04:17,480 --> 00:04:20,960
of these programs we convinced it's not from we would like to give a mathematical

71
00:04:21,890 --> 00:04:24,500
and the answer is it's very very hard

72
00:04:24,510 --> 00:04:29,430
this is an incomplete result which has a core library the unsolvability of turning folding

73
00:04:29,430 --> 00:04:33,550
problem so the way you prove this incomplete result the proof is actually rather simple

74
00:04:33,550 --> 00:04:37,900
and in some ways even simpler than the original proof of the completeness theorem or

75
00:04:37,920 --> 00:04:42,480
strings halting problem which involves self reference and i don't need a self reference i'll

76
00:04:42,480 --> 00:04:44,840
show you what i need the proof of the

77
00:04:44,850 --> 00:04:48,090
you cannot prove that the program is elegant in general so let me give proof

78
00:04:48,090 --> 00:04:52,500
that you can prove that an individual programmes elegant there are infinitely many elegant programs

79
00:04:52,500 --> 00:04:56,460
of course for any computational task there has to be at least one elegant program

80
00:04:56,480 --> 00:05:00,250
there may be many so so infinity about from what if i have a particular

81
00:05:00,250 --> 00:05:03,550
problem and i want to prove its elegant that you can do that in general

82
00:05:03,550 --> 00:05:08,430
you can see from the following paradoxical programme p

83
00:05:08,440 --> 00:05:20,370
its output is

84
00:05:20,490 --> 00:05:32,960
i i have to explain this but

85
00:05:32,990 --> 00:05:41,000
so let me explain this

86
00:05:41,010 --> 00:05:42,490
this paradoxical

87
00:05:42,500 --> 00:05:45,890
programme p

88
00:05:45,920 --> 00:05:49,140
so here how it works

89
00:05:49,950 --> 00:05:53,370
the output of this program is the same as the output of the first probably

90
00:05:53,370 --> 00:05:57,170
elegant program q that is larger than p has been explained

91
00:05:57,180 --> 00:06:00,390
first of all we are talking about what you can prove

92
00:06:00,400 --> 00:06:04,870
i need to assume that you have what's called the formal axiomatic systems

93
00:06:04,920 --> 00:06:09,820
an idea that i think is mostly due to

94
00:06:09,820 --> 00:06:11,660
u in x one x two

95
00:06:11,680 --> 00:06:14,910
you propose new company y one y two on the way you do it as

96
00:06:15,850 --> 00:06:20,530
new sampled the new component y one the updated by sampling it

97
00:06:20,530 --> 00:06:24,320
according to its conditional distribution given the current value of x two

98
00:06:24,340 --> 00:06:25,930
on basically

99
00:06:25,950 --> 00:06:30,220
you don't modify the component x to this is what i was doing because felt

100
00:06:30,280 --> 00:06:34,260
so this thing to do simply don't modify the company x two then the second

101
00:06:34,260 --> 00:06:39,970
killer considering the considering the following kernel which basically what it does

102
00:06:39,990 --> 00:06:45,340
he does modify the current value of x y on the day the components the

103
00:06:45,340 --> 00:06:46,700
current value

104
00:06:46,740 --> 00:06:53,050
all of this is the story on it and they basically the second component by

105
00:06:53,050 --> 00:06:56,550
sampling according to its conditional distribution

106
00:06:56,570 --> 00:06:58,640
it's very easy to check

107
00:06:58,640 --> 00:07:00,660
that both p one

108
00:07:00,660 --> 00:07:05,970
on p two alpine OK so i can do it for p one and this

109
00:07:05,970 --> 00:07:10,760
value to determine is really really simple to show that both p one

110
00:07:11,110 --> 00:07:16,220
basically pi in the distribution p two as priors in the distribution so the composition

111
00:07:16,220 --> 00:07:20,530
of of those killed as basically priors in the distribution

112
00:07:21,050 --> 00:07:22,280
so i know

113
00:07:22,300 --> 00:07:26,590
that you are you going to propose to leave pine valley and which is actually

114
00:07:26,620 --> 00:07:31,680
something which is actually necessary requirement for intensive

115
00:07:31,700 --> 00:07:35,840
that doesn't mean that basically you convert going on the solution as i said you

116
00:07:35,840 --> 00:07:39,390
need additional condition you need to ensure that basically

117
00:07:40,490 --> 00:07:45,180
said to each other and that any positive mass on the target problem

118
00:07:45,220 --> 00:07:49,510
so you need to ensure that whatever being

119
00:07:49,510 --> 00:07:54,140
the initial point you can which any set of positive point mass the target

120
00:07:54,140 --> 00:08:01,110
on you need essentially tall are also be so OK going OK

121
00:08:02,620 --> 00:08:08,530
this is basically what unit soldiers became a conjurer this algorithm also

122
00:08:08,550 --> 00:08:13,450
to the chase where instead of into components UIP components so let's say that x

123
00:08:13,450 --> 00:08:17,280
can be separated can be divided in like p

124
00:08:17,300 --> 00:08:20,700
corpus of number of valuable x one x two x p

125
00:08:20,720 --> 00:08:25,530
well basically the categories the way the gibbs sampler we work in this case so

126
00:08:25,530 --> 00:08:29,160
as to simulate approximately from the target distribution

127
00:08:29,180 --> 00:08:30,320
is following

128
00:08:30,340 --> 00:08:31,550
at each iteration

129
00:08:31,570 --> 00:08:35,610
i basically you're going to cite call for the company and one to the component

130
00:08:36,660 --> 00:08:41,970
on basically you date because the company xk

131
00:08:41,990 --> 00:08:46,200
i call them by sampling according to its conditional distribution under pi

132
00:08:46,210 --> 00:08:47,930
given the chance

133
00:08:49,080 --> 00:08:50,380
of the

134
00:08:50,380 --> 00:08:53,710
all the components that is in this scenario

135
00:08:55,080 --> 00:08:59,930
OK minus one feels confident have already been updated at iteration i on the remaining

136
00:09:01,080 --> 00:09:06,070
components which are at iteration minus one because they haven't been sampled OK so these

137
00:09:06,200 --> 00:09:11,780
categories by using this try generalisation of what i've been discussing before he's and it's

138
00:09:11,780 --> 00:09:20,000
basically by as in the distribution on you can also instead of cycling deterministically and

139
00:09:20,830 --> 00:09:26,000
from one computer components you can basically so paul them

140
00:09:26,010 --> 00:09:29,250
so called this company components that one the only

141
00:09:30,210 --> 00:09:35,040
according to the distribution a uniform distribution over the set one to p

142
00:09:35,050 --> 00:09:39,580
OK so instead of citing for use on paul ron the basically

143
00:09:39,580 --> 00:09:41,760
the company want to update OK

144
00:09:41,790 --> 00:09:42,750
six j

145
00:09:42,760 --> 00:09:46,870
that's going to give you a return value which is uniformly distributed according to intercept

146
00:09:46,870 --> 00:09:51,250
want to be on your data is distributed so company according to the full conditional

147
00:09:51,250 --> 00:09:56,990
distribution this guy corresponds to a mixture of kernels also using the same argument he

148
00:09:57,000 --> 00:09:59,990
admits basically the wife involved distribution

149
00:10:00,990 --> 00:10:06,490
so i've can back to basically on nuclear pump again i've told you we've shown

150
00:10:06,500 --> 00:10:13,370
that basically these algorithm i was proposing is just a simple example of the gibbs

151
00:10:13,370 --> 00:10:14,880
sampler OK

152
00:10:14,890 --> 00:10:18,890
so i know it that means the light in distribution OK

153
00:10:18,910 --> 00:10:25,080
what about this condition we basically with the additional condition that briefly sketch which are

154
00:10:25,080 --> 00:10:26,460
that basically

155
00:10:26,460 --> 00:10:30,930
i need to be awarded to reach any basically said

156
00:10:30,960 --> 00:10:35,920
o point met opposite point and the target whatever being the starting point where is

157
00:10:35,930 --> 00:10:36,760
going to be

158
00:10:36,800 --> 00:10:43,040
automatically unsure because all the conditional distribution of strictly positive until plus infinity

159
00:10:43,050 --> 00:10:44,410
on similarly

160
00:10:44,410 --> 00:10:50,510
basically my markov chain doesn't exhibit any periodic behavior because similarly all the conditional are

161
00:10:50,510 --> 00:10:56,250
strictly positive so i know this algorithm is going basically generates so important that essentially

162
00:10:56,250 --> 00:11:01,410
as i can go to plus infinity converge toward the target distribution whatever the rate

163
00:11:01,410 --> 00:11:03,620
of convergence well

164
00:11:03,630 --> 00:11:08,110
that is going to be much more complicated on this simple example actually some people

165
00:11:08,110 --> 00:11:13,570
have and establish some results on actually on this policies example is simple enough that

166
00:11:13,570 --> 00:11:17,850
you can get rid of convergence german-speaking is going to be much more complicated

167
00:11:17,880 --> 00:11:22,170
so that's basically keep sampling

168
00:11:22,170 --> 00:11:24,260
so the

169
00:11:24,290 --> 00:11:28,080
you should be a bit careful when you discover

170
00:11:28,090 --> 00:11:31,460
well the point is that it's very nice to come up with this kind of

171
00:11:31,460 --> 00:11:33,250
separating essentially

172
00:11:33,250 --> 00:11:35,070
he said the company short

173
00:11:35,130 --> 00:11:40,040
state vector instead p company innovating one conditional upon the other

174
00:11:40,040 --> 00:11:43,780
but conditioning is going to come out the sales price OK

175
00:11:44,460 --> 00:11:47,320
let's look at the another really toy example

176
00:11:47,350 --> 00:11:50,740
which is essentially unified ocean distribution

177
00:11:51,960 --> 00:11:57,370
so a bivariate gaussian distribution of zero mean on compliance basically

178
00:11:57,380 --> 00:12:03,010
violence gumbel metric given by this guy has always the correlation coefficient here i can

179
00:12:03,030 --> 00:12:06,380
i just assumed that basically this unit unit

180
00:12:07,420 --> 00:12:08,990
OK so in this case

181
00:12:09,000 --> 00:12:11,620
OK i wouldn't use the example

182
00:12:11,630 --> 00:12:16,040
but if you have to use the gibbs sampler on practice sample

183
00:12:16,050 --> 00:12:23,050
from these joy target distribution by the theory iteratively sampling from the conditional distribution of

184
00:12:23,050 --> 00:12:25,280
a given y and then y given x

185
00:12:25,280 --> 00:12:28,930
then this is the form of the conditional distribution

186
00:12:28,960 --> 00:12:30,870
well what you see

187
00:12:30,880 --> 00:12:33,000
he's obviously so this is the question

188
00:12:33,010 --> 00:12:36,970
OK so if you can rewrite it basically you can think that the gibbs sampler

189
00:12:36,970 --> 00:12:41,070
which also just follow essentially so this is the first component you would at time

190
00:12:41,210 --> 00:12:43,620
at iteration and was one of the categories

191
00:12:43,620 --> 00:12:47,470
i will get back later on this

192
00:12:47,470 --> 00:12:51,350
i'm going to explain more in the following if you don't have the answer you

193
00:12:51,350 --> 00:12:53,300
ask again OK

194
00:12:58,390 --> 00:13:00,130
all this kind of query

195
00:13:00,170 --> 00:13:01,640
it's more difficult

196
00:13:01,690 --> 00:13:06,990
so if you want to find the one hundred most frequent IP addresses

197
00:13:07,040 --> 00:13:08,420
the standard solution

198
00:13:08,450 --> 00:13:12,110
is to build an array of all IP addresses

199
00:13:12,140 --> 00:13:15,300
appearing in root

200
00:13:16,320 --> 00:13:20,080
when a new packet musician right

201
00:13:20,090 --> 00:13:24,040
you have a look at your table if it's not there

202
00:13:24,050 --> 00:13:25,380
you add it and

203
00:13:25,410 --> 00:13:26,710
if it is

204
00:13:26,710 --> 00:13:28,640
you increment the counter

205
00:13:28,660 --> 00:13:30,520
if it's not then you have

206
00:13:32,530 --> 00:13:39,060
in this kind of applications you may have several thousands or hundreds of thousands of

207
00:13:39,060 --> 00:13:41,560
different IP addresses

208
00:13:41,590 --> 00:13:42,800
and this

209
00:13:42,810 --> 00:13:47,620
table is going to be very very large and accessing it and finding

210
00:13:48,070 --> 00:13:49,440
the right

211
00:13:49,480 --> 00:13:53,080
place to increment is going to be very expensive

212
00:13:54,170 --> 00:13:56,050
this solution

213
00:13:56,060 --> 00:14:01,590
of maintaining a table of IP addresses with frequencies is not a good solution

214
00:14:01,630 --> 00:14:02,980
for this example

215
00:14:03,000 --> 00:14:07,970
so they may be either of solutions one solution would be to some for the

216
00:14:10,320 --> 00:14:12,150
this is a good solution

217
00:14:12,170 --> 00:14:14,230
if you sample the stream

218
00:14:14,290 --> 00:14:18,110
since you want information the list of

219
00:14:18,440 --> 00:14:23,860
one hundred most frequent IP addresses you have a good chance that they may be

220
00:14:23,860 --> 00:14:24,980
the sample

221
00:14:25,020 --> 00:14:26,670
so this is a good solution

222
00:14:26,690 --> 00:14:30,130
we will go we will i will present you

223
00:14:30,150 --> 00:14:30,940
and not

224
00:14:32,040 --> 00:14:33,540
and the idea here

225
00:14:33,570 --> 00:14:39,710
is that we will not provide the exact solution that an approximation of the

226
00:14:53,310 --> 00:14:55,980
you have a question any question about the

227
00:14:56,040 --> 00:14:58,790
applications the motivation

228
00:15:01,360 --> 00:15:04,210
data stream processing

229
00:15:05,570 --> 00:15:07,270
so now we

230
00:15:07,320 --> 00:15:09,270
we're going to define

231
00:15:09,310 --> 00:15:10,710
more precisely

232
00:15:10,730 --> 00:15:12,040
what is

233
00:15:12,070 --> 00:15:16,960
the structure of the data stream and model

234
00:15:16,960 --> 00:15:20,980
so as we have seen the structure of the data stream is that you have

235
00:15:20,980 --> 00:15:24,960
an infinite sequence of items or elements

236
00:15:24,980 --> 00:15:28,860
one night is structured information

237
00:15:28,880 --> 00:15:30,840
just records

238
00:15:30,860 --> 00:15:32,920
and it's the same structure for

239
00:15:32,940 --> 00:15:34,650
items industry

240
00:15:34,670 --> 00:15:37,210
what you've seen

241
00:15:37,210 --> 00:15:38,570
is that

242
00:15:38,590 --> 00:15:40,070
when you have a stream

243
00:15:40,090 --> 00:15:41,540
all we could

244
00:15:41,590 --> 00:15:44,150
we have the timestamps

245
00:15:44,150 --> 00:15:45,880
the time stamps

246
00:15:45,940 --> 00:15:48,170
will be i've

247
00:15:49,900 --> 00:15:51,150
that is

248
00:15:51,150 --> 00:15:53,320
there is a field in the recurrence

249
00:15:54,920 --> 00:15:56,230
the times

250
00:15:56,250 --> 00:15:57,750
so the break

251
00:15:57,750 --> 00:16:00,250
arrived with the times

252
00:16:00,250 --> 00:16:02,520
or implicit

253
00:16:02,570 --> 00:16:07,420
the record does not having time stamps and when it enters the the system thanks

254
00:16:07,460 --> 00:16:10,320
and is given by the system

255
00:16:10,380 --> 00:16:14,810
or we could have time time

256
00:16:14,820 --> 00:16:17,500
the time stamps can be of two types

257
00:16:17,500 --> 00:16:19,650
they may be either physical

258
00:16:19,670 --> 00:16:20,960
so it's today

259
00:16:20,980 --> 00:16:22,750
all are not equal

260
00:16:22,770 --> 00:16:27,400
so it's number and in tag let's have a look at two examples

261
00:16:28,900 --> 00:16:32,110
in this first example the timestamp

262
00:16:32,110 --> 00:16:34,920
here is implicit

263
00:16:34,940 --> 00:16:36,730
it has been it's

264
00:16:36,770 --> 00:16:39,840
implicit energy called so it's the numbers

265
00:16:39,860 --> 00:16:41,860
given by the systems

266
00:16:41,880 --> 00:16:44,460
when information enters the system

267
00:16:44,570 --> 00:16:45,690
in this

268
00:16:46,790 --> 00:16:48,980
the timestamp is physical

269
00:16:49,040 --> 00:16:51,170
it's the

270
00:16:54,110 --> 00:16:55,860
it was present

271
00:16:55,880 --> 00:16:58,860
in recruit before arriving

272
00:16:58,880 --> 00:17:04,210
in the facist

273
00:17:04,230 --> 00:17:07,440
so this was for the structure the

274
00:17:07,520 --> 00:17:09,460
the elements of the stream

275
00:17:09,460 --> 00:17:13,480
so of course the timestamp is very important

276
00:17:14,090 --> 00:17:19,940
as for not adding the stream

277
00:17:20,710 --> 00:17:22,270
an important

278
00:17:24,820 --> 00:17:26,540
the fact is that

279
00:17:26,590 --> 00:17:28,460
we must distinguish

280
00:17:28,480 --> 00:17:30,730
the contents of the stream

281
00:17:32,020 --> 00:17:35,810
that's the so values information

282
00:17:35,820 --> 00:17:37,810
contained the tree could

283
00:17:37,820 --> 00:17:40,500
two we must distinguish this two

284
00:17:40,540 --> 00:17:41,520
from the

285
00:17:41,540 --> 00:17:43,570
underlying signal

286
00:17:43,610 --> 00:17:45,610
we want to study

287
00:17:45,670 --> 00:17:46,860
and the model

288
00:17:46,880 --> 00:17:48,320
of the stream

289
00:17:48,340 --> 00:17:50,190
it's a relationship

290
00:17:50,210 --> 00:17:52,210
between observed values

291
00:17:52,230 --> 00:17:55,130
and this signal

292
00:17:55,340 --> 00:17:59,190
so as for the contents of the stream

293
00:17:59,230 --> 00:18:01,320
so as i told you before

294
00:18:01,320 --> 00:18:03,400
we have structured recur

295
00:18:04,270 --> 00:18:10,480
we have we received an infinite sequence of items x

296
00:18:10,500 --> 00:18:12,840
with two information

297
00:18:12,900 --> 00:18:15,340
the time the observation time

298
00:18:15,360 --> 00:18:20,310
which if it's logical time just one two three four five

299
00:18:20,360 --> 00:18:21,710
and so

300
00:18:21,940 --> 00:18:27,750
descriptive values which may be numerical symbolic or ID's

301
00:18:27,770 --> 00:18:30,150
of some other object

302
00:18:30,210 --> 00:18:32,840
so for instance if we consider the

303
00:18:32,900 --> 00:18:34,960
this dream

304
00:18:34,980 --> 00:18:37,040
and these

305
00:18:37,050 --> 00:18:40,520
elements it's a short version at the time

306
00:18:40,520 --> 00:18:42,820
one two three four

307
00:18:43,790 --> 00:18:46,400
and the observed values are

308
00:18:46,400 --> 00:18:48,610
the two IP addresses

309
00:18:48,630 --> 00:18:52,190
the duration the volume and protocol

310
00:18:52,230 --> 00:18:54,540
so this is the information

311
00:18:54,570 --> 00:18:57,460
contained in the street

312
00:18:57,460 --> 00:19:00,110
when you model the stream

313
00:19:00,130 --> 00:19:02,440
from the same stream

314
00:19:02,500 --> 00:19:05,770
you may want to extract different information

315
00:19:05,790 --> 00:19:07,250
and depending

316
00:19:07,270 --> 00:19:09,290
on the model of the stream

317
00:19:09,320 --> 00:19:10,790
the algorithms

318
00:19:10,810 --> 00:19:14,650
to process them will be different

319
00:19:14,650 --> 00:19:16,110
people are able to learn

320
00:19:16,130 --> 00:19:18,380
structural forms on relations

321
00:19:18,440 --> 00:19:22,690
or just make one last point because it's just relevant for the general conclusion i

322
00:19:22,690 --> 00:19:25,960
wanna make which is what happens if we look at how

323
00:19:25,970 --> 00:19:29,800
the structural forms developed as we observe more and more data

324
00:19:29,820 --> 00:19:33,800
so here we are back to the animals domain and we're going to see what

325
00:19:33,800 --> 00:19:37,690
have we learned when we just take five features twenty features or the full data

326
00:19:37,690 --> 00:19:42,090
set of one hundreds features and what you can see something kind of interesting here

327
00:19:42,110 --> 00:19:44,570
that with with just

328
00:19:44,610 --> 00:19:48,920
five features we don't we learn a more simple structural form we just learn a

329
00:19:48,920 --> 00:19:53,920
set of flat clusters there reasonable clusters this sort of large-scale supernote categories like birds

330
00:19:53,920 --> 00:19:59,860
and insects and carnivorous mammals an herbivore mammals and aquatic creatures and so on but

331
00:19:59,860 --> 00:20:01,860
we don't have the full hierarchical structure

332
00:20:01,920 --> 00:20:05,720
now when you add a few more features now the model realizes that the extra

333
00:20:05,720 --> 00:20:07,740
complexity of the tree structured

334
00:20:07,760 --> 00:20:11,780
taxonomy is licence and it doesn't for the best structural forms the tree but it

335
00:20:11,780 --> 00:20:14,990
doesn't have the right tree so you can see over here has the tree has

336
00:20:14,990 --> 00:20:17,960
a node with dolphins seals whales and penguins

337
00:20:17,970 --> 00:20:22,240
and we know as adults the penguins up along with dolphins seals and whales

338
00:20:22,280 --> 00:20:25,760
rather they belong something like over here so this is this is what the tree

339
00:20:25,760 --> 00:20:31,030
learning you have the full dataset where now there's there's a distinct subtree for the

340
00:20:31,030 --> 00:20:35,110
aquatic mammals and penguins are over here with the other birds although there sort of

341
00:20:35,110 --> 00:20:38,380
closer to the fish and aquatic mammals

342
00:20:38,400 --> 00:20:41,670
and what's what you see going on here is the phenomenon that that we call

343
00:20:41,670 --> 00:20:43,960
the blessing of abstraction it's kind of

344
00:20:43,990 --> 00:20:46,860
kind of overly dramatic name for

345
00:20:46,880 --> 00:20:50,070
what i think is the basic but really important phenomenon which is the

346
00:20:50,070 --> 00:20:56,150
often learning abstract knowledge is easier than learning concrete knowledge that the concrete knowledge here

347
00:20:56,150 --> 00:21:00,470
is the specific structure in the abstract not knowledge is the structural form and it

348
00:21:00,590 --> 00:21:03,900
you will often find when you work with hierarchical bayesian models

349
00:21:05,010 --> 00:21:07,590
that because because that you

350
00:21:07,610 --> 00:21:09,840
less data is required to

351
00:21:09,900 --> 00:21:11,610
converge on the right

352
00:21:11,630 --> 00:21:15,490
learned knowledge at a higher level than at the lower levels in this case that

353
00:21:15,490 --> 00:21:18,900
means the structural form than the other than the

354
00:21:18,920 --> 00:21:23,780
the particular structure and i think that's an important feature of cognitive development as well

355
00:21:23,780 --> 00:21:26,990
as science where when the first learning about the domain we kind of get the

356
00:21:26,990 --> 00:21:31,530
big picture and sort of the general way of organizing things and that might take

357
00:21:31,530 --> 00:21:35,420
much more observations to fill in the details indeed the that's exactly what happened in

358
00:21:35,420 --> 00:21:40,050
scientific biology and that's exactly what happens in children's cognitive development where he was relatively

359
00:21:40,050 --> 00:21:43,880
early scene seventeen hundred so we figured out some kind of tree structure is the

360
00:21:44,470 --> 00:21:47,820
tree structure is the right form but it took a long time a lot more

361
00:21:47,820 --> 00:21:49,240
data to two

362
00:21:49,240 --> 00:21:51,670
converge on what we thought was the right rate

363
00:21:51,690 --> 00:21:55,280
and this is this is really a sort of a different perspective on

364
00:21:55,380 --> 00:22:00,970
what is maybe the most classic debate in cognitive science about the nature of learning

365
00:22:01,130 --> 00:22:04,570
what's what's called the need disperse the empiricists and you see the same kind of

366
00:22:04,570 --> 00:22:05,960
debate in

367
00:22:05,970 --> 00:22:07,260
a i just

368
00:22:07,300 --> 00:22:09,320
conclude by talking about the

369
00:22:09,320 --> 00:22:15,820
the bayesian in cognitive science it's long recognised that that some kind of abstraction is

370
00:22:15,820 --> 00:22:20,970
important but you have these two camps the natives who say that there is explicit

371
00:22:20,970 --> 00:22:25,940
knowledge of say structural former we we have explicit abstract knowledge but that is not

372
00:22:27,110 --> 00:22:32,130
chomsky being the most famous example and then you have the so-called empiricist camp which

373
00:22:32,130 --> 00:22:36,550
says well we can learn abstract knowledge but it's not really explicit we just sort

374
00:22:36,550 --> 00:22:41,570
of it it's just comes out kind of implicitly from overlaying a lot of concrete

375
00:22:41,570 --> 00:22:46,200
experiences sort of the classic connectionist approach as well as traditional i would say traditional

376
00:22:46,200 --> 00:22:51,690
structure learning probabilistic graphical models we're learning some graphical representation of the structure of the

377
00:22:51,700 --> 00:22:55,610
set of variables but you but you're not learning the some kind of higher level

378
00:22:55,610 --> 00:22:59,760
inductive bias abstract constraint on the kind of structure that's there and what i tried

379
00:22:59,760 --> 00:23:03,940
to argue here is that that both of these things are necessary we really do

380
00:23:03,940 --> 00:23:08,070
need explicit structural forms because you can see from modelling people's ability to generalize from

381
00:23:08,070 --> 00:23:12,400
very few examples you need that the stronger inductive bias but you also need the

382
00:23:12,400 --> 00:23:16,720
flexibility that comes from being able to learn and it's what we what we're trying

383
00:23:16,720 --> 00:23:20,300
to work towards here is really a third way or a new approach to thinking

384
00:23:20,300 --> 00:23:24,670
about how the development as well as how you might say engineer the development of

385
00:23:24,670 --> 00:23:26,090
an artificial system

386
00:23:26,090 --> 00:23:28,670
so let's get my little thing and causal learning

387
00:23:28,690 --> 00:23:33,990
in the summer of two i've given you two case studies on

388
00:23:34,090 --> 00:23:39,510
how we can model human inductive learning used by combining a few basic ideas the

389
00:23:39,510 --> 00:23:48,380
idea of bayesian inference over hierarchies of flexibly structured representations and what in each of

390
00:23:48,380 --> 00:23:51,990
these cases we looked at multiple levels of knowledge and tried as some of the

391
00:23:51,990 --> 00:23:56,150
big questions about cognitive science what's the form and content of knowledge at these different

392
00:23:56,150 --> 00:24:01,190
levels of abstraction how does that knowledge guide learning and how much knowledge itself acquired

393
00:24:01,190 --> 00:24:05,150
in a way that combines both strong inductive biases but also flexibility

394
00:24:05,170 --> 00:24:08,380
and the and there's sort of these bigger picture lessons which i hope

395
00:24:08,400 --> 00:24:11,610
you know i certainly in cognitive science these are important but i hope they will

396
00:24:11,610 --> 00:24:14,650
also payoff for people interested in machine learning and AI

397
00:24:14,670 --> 00:24:18,320
this third way of thinking about development the idea that

398
00:24:18,460 --> 00:24:24,030
in some sense inductive biases abstract powerful abstractions can be learned very quickly sometimes in

399
00:24:24,050 --> 00:24:27,330
a kind of a top-down way rather than having to be wired in or learned

400
00:24:27,330 --> 00:24:29,090
very gradually and implicitly

401
00:24:29,150 --> 00:24:33,320
and maybe the most general lesson which i think many people in machine learning are

402
00:24:33,340 --> 00:24:37,690
already have already learned and taught others including me that we need to go beyond

403
00:24:37,690 --> 00:24:42,380
some of the classic dichotomy is a thinking about intelligence dichotomies of say you know

404
00:24:42,380 --> 00:24:44,510
domain specific hardwired

405
00:24:44,550 --> 00:24:50,900
approaches versus domain general learning based approaches are statistics versus structured representations and as really

406
00:24:50,900 --> 00:24:52,590
the existing one

407
00:24:52,610 --> 00:24:54,360
so this is the motivation

408
00:24:54,380 --> 00:25:01,030
for some estimation of local optima we can achieve based on the current configuration

409
00:25:01,060 --> 00:25:05,600
so here is a graph figure showing how we can we can do this

410
00:25:06,460 --> 00:25:10,110
on the x axis this is number of iterations

411
00:25:10,160 --> 00:25:12,850
of the current procedure of reason

412
00:25:12,900 --> 00:25:18,390
and the blue line is the log likelihood after after some iterations

413
00:25:18,460 --> 00:25:22,610
and the blue one is best solution we have seen so far based on the

414
00:25:22,610 --> 00:25:25,020
previous rounds of the

415
00:25:25,030 --> 00:25:29,270
and if we can derive some upper bound on the log likelihood of the local

416
00:25:29,270 --> 00:25:31,570
optimum here

417
00:25:31,830 --> 00:25:33,560
after every iteration

418
00:25:33,600 --> 00:25:37,200
and if some after some iterations we found

419
00:25:37,210 --> 00:25:41,710
so look the upper bound of the local optima is already small that the current

420
00:25:41,710 --> 00:25:42,880
best solution

421
00:25:42,900 --> 00:25:45,810
we can stop this procedure at this moment

422
00:25:46,570 --> 00:25:50,340
we can save the time for the rest of the iterations

423
00:25:50,360 --> 00:25:56,540
and we know that in current practice many in sincere i is stopped based on

424
00:25:56,540 --> 00:26:02,690
the difference between two iterations however this is not a good good solution y

425
00:26:02,730 --> 00:26:03,900
for example here

426
00:26:03,910 --> 00:26:07,650
you can see that the difference between two iterations is very small

427
00:26:07,670 --> 00:26:09,420
however we can now start here

428
00:26:09,440 --> 00:26:12,950
because we are not sure if we can leave to so much better solution

429
00:26:13,760 --> 00:26:19,450
o upper bound based termination as it is much better than the current solution for

430
00:26:19,450 --> 00:26:23,020
you from what he re

431
00:26:23,030 --> 00:26:24,650
so far

432
00:26:24,670 --> 00:26:26,690
now we have seen the motivation

433
00:26:26,700 --> 00:26:28,040
for the

434
00:26:28,090 --> 00:26:30,410
as the estimation of the local optima

435
00:26:30,460 --> 00:26:34,460
let's see some interesting properties we proving your paper

436
00:26:35,310 --> 00:26:38,010
first let let me define the solution space

437
00:26:38,030 --> 00:26:43,750
the solution space we a point in this space the configuration of the gaussian mixture

438
00:26:45,090 --> 00:26:49,710
and it is easy to do this we just need to concatenate all the parameters

439
00:26:49,710 --> 00:26:54,420
of the of the costumes so we can generate a very high sequence and this

440
00:26:54,420 --> 00:26:58,460
is the sequence can be mapped into a high dimensional space

441
00:26:59,450 --> 00:27:01,890
every every year iteration

442
00:27:01,900 --> 00:27:05,410
when moved the confederation from one position to another

443
00:27:05,460 --> 00:27:06,590
so for example here

444
00:27:06,590 --> 00:27:11,440
the original iteration is it at d and after william iterations to move to to

445
00:27:11,440 --> 00:27:14,260
see that he plus one

446
00:27:14,690 --> 00:27:20,580
here we use a degree level to indicate the log likelihood the configuration can achieve

447
00:27:20,590 --> 00:27:22,460
so the doctors about

448
00:27:22,470 --> 00:27:25,540
so we know that the that t plus one must be a better solution to

449
00:27:25,570 --> 00:27:26,460
see that

450
00:27:26,470 --> 00:27:31,110
so the colour here must be darker and see that

451
00:27:32,840 --> 00:27:36,950
the local trapping is some is some very interesting properties

452
00:27:36,960 --> 00:27:39,660
we can find past fall for every

453
00:27:39,670 --> 00:27:43,960
for every p of configurations across a yemi iterations

454
00:27:44,020 --> 00:27:46,750
we can find past in the solution space

455
00:27:46,770 --> 00:27:49,840
connecting c that you and see that the plus one

456
00:27:49,860 --> 00:27:51,210
and we can prove that

457
00:27:51,210 --> 00:27:53,720
on this past every configuration

458
00:27:53,730 --> 00:27:57,090
can lead to some better solution see that

459
00:27:57,230 --> 00:28:03,310
we prove this by by first finding a new configuration c sharp between that you

460
00:28:03,310 --> 00:28:04,520
can see that first one

461
00:28:04,540 --> 00:28:06,140
present at every

462
00:28:06,170 --> 00:28:10,110
every configuration between that you see that show is that that e

463
00:28:10,140 --> 00:28:15,480
and also configuration between swedish opportunity plus one is better than c russia

464
00:28:16,110 --> 00:28:17,700
you can check chicks

465
00:28:17,710 --> 00:28:22,970
the paper for the data of this proof this part is very interesting

466
00:28:23,660 --> 00:28:27,260
based on this local local trapping property

467
00:28:27,270 --> 00:28:31,020
we can derive some some maximal region on the local optimums

468
00:28:31,070 --> 00:28:32,270
how can we do this

469
00:28:32,280 --> 00:28:34,710
we need to find some some regions

470
00:28:34,760 --> 00:28:35,580
for example

471
00:28:35,590 --> 00:28:41,660
for this one comprises this this country if if every configuration in this country

472
00:28:41,710 --> 00:28:44,250
yes it's no better than thirty

473
00:28:44,260 --> 00:28:48,590
we know that the first iterations can not jump out of this region

474
00:28:48,610 --> 00:28:51,580
so in this way we can somehow down local

475
00:28:51,590 --> 00:28:55,720
local optima in this region we can try to derive some upper bound of the

476
00:28:55,720 --> 00:29:00,100
local optimum achieved by by further iterations

477
00:29:00,160 --> 00:29:01,860
so this is the basic idea

478
00:29:01,890 --> 00:29:05,310
of the estimation

479
00:29:05,360 --> 00:29:06,970
so r

480
00:29:07,010 --> 00:29:09,100
now let me show you some

481
00:29:09,120 --> 00:29:11,040
definition of the maximal region

482
00:29:11,060 --> 00:29:15,980
so i maximal region is some region in the solution space which can cover

483
00:29:15,980 --> 00:29:19,610
so she would fall

484
00:29:19,790 --> 00:29:21,210
is exciting

485
00:29:21,210 --> 00:29:23,810
many different

486
00:29:23,880 --> 00:29:28,570
now i present first and my guests

487
00:29:30,310 --> 00:29:37,190
and then we what you not you want to to know what

488
00:29:37,360 --> 00:29:38,940
complaints anything

489
00:29:38,940 --> 00:29:43,520
you have to

490
00:29:43,550 --> 00:29:46,130
i think about the first lesson for

491
00:29:46,170 --> 00:29:49,150
you try to four forty

492
00:29:49,150 --> 00:29:52,380
o come close

493
00:29:54,860 --> 00:29:55,820
now go ahead

494
00:30:04,480 --> 00:30:11,020
the nice factor which the sort of violence doesn't have many terrible violence

495
00:30:11,040 --> 00:30:12,590
you have play something

496
00:30:12,590 --> 00:30:14,340
the exact

497
00:30:15,650 --> 00:30:23,420
well have no where

498
00:30:23,420 --> 00:30:25,630
i just play whatever you want

499
00:30:25,690 --> 00:30:31,340
o i

500
00:30:31,400 --> 00:30:43,570
hurricane hugo

501
00:30:45,150 --> 00:30:52,690
one more time

502
00:31:06,020 --> 00:31:07,440
joseph guilt

503
00:31:07,500 --> 00:31:11,840
the violence resulted by lack of holy

504
00:31:11,920 --> 00:31:15,400
now we get the violin is a little smaller maybe we can can hold one

505
00:31:15,420 --> 00:31:16,920
next to the other

506
00:31:16,980 --> 00:31:20,420
so that you can actually see that they lies the larger

507
00:31:23,270 --> 00:31:25,400
oh my goodness

508
00:31:25,400 --> 00:31:27,590
why did i invite you in the first place

509
00:31:27,610 --> 00:31:32,090
OK so it since ones are not full five

510
00:31:32,090 --> 00:31:35,610
there may not be able to compare the

511
00:31:35,690 --> 00:31:38,860
three of the file if you have violin right

512
00:31:38,880 --> 00:31:40,270
they showed to us

513
00:31:40,440 --> 00:31:53,190
joseph buildings

514
00:31:53,250 --> 00:31:56,790
ah this war is

515
00:31:56,790 --> 00:31:58,590
i only show you some again

516
00:31:58,730 --> 00:32:01,420
hold hold it up to make them

517
00:32:01,520 --> 00:32:03,610
are there

518
00:32:03,670 --> 00:32:08,790
but it's not the full-size instrument so the total debt instrument will be lower on

519
00:32:08,790 --> 00:32:13,500
average than what this was because the strings are shorter but of course the invention

520
00:32:13,500 --> 00:32:15,860
and to within

521
00:32:17,040 --> 00:32:20,650
makes it much harder to make predictions about

522
00:32:20,690 --> 00:32:23,000
the frequencies

523
00:32:23,020 --> 00:32:25,570
get the four forty

524
00:32:25,650 --> 00:32:29,480
i'll have to change the location again i think

525
00:32:29,500 --> 00:32:32,480
now go ahead

526
00:32:32,540 --> 00:32:40,960
see that same which is the result of the violence

527
00:32:41,190 --> 00:32:42,880
you can play something

528
00:32:44,040 --> 00:32:45,610
are you need the music

529
00:32:45,650 --> 00:32:47,980
go ahead

530
00:32:48,110 --> 00:32:51,730
you can you can use to music there's nothing wrong with that

531
00:32:51,730 --> 00:32:59,480
by which your margin is bigger than sorry fails to be one so if

532
00:32:59,480 --> 00:33:04,820
this is if this is bigger than one then  the xi is zero there's no penalty that

533
00:33:04,820 --> 00:33:09,740
corresponds to this section here at the line but as the margin drops below one

534
00:33:09,740 --> 00:33:14,360
you start to pay a penalty which is linear in the amount by which it fails to

535
00:33:14,360 --> 00:33:21,140
meet that target margin of one  so the ideal is here is this margin is

536
00:33:21,140 --> 00:33:25,960
not a margin in the input space but it's a functional margin and so by

537
00:33:26,280 --> 00:33:30,320
increasing the norm of W you can increase this margin but you pay a penalty here so

538
00:33:30,320 --> 00:33:36,120
this is sort of translating the margin into a penalty on the weight vector effectively

539
00:33:36,380 --> 00:33:40,660
so it looks very similar to the to the ridge regression except the rather than

540
00:33:40,660 --> 00:33:47,960
the xis being the squares of the residuals it's this slack variable which is sort

541
00:33:47,960 --> 00:33:52,620
of measuring a loss which is zero if the margin is bigger than one but

542
00:33:52,620 --> 00:33:57,460
then linear in the by which is which is that margin of one so this

543
00:33:57,460 --> 00:34:02,680
is the thing you optimize and I as I say I claim that's a proxy

544
00:34:02,680 --> 00:34:08,460
for optimizing this bound there are other bounds as well as at least three or

545
00:34:08,460 --> 00:34:14,080
four different ways of proving bounds in terms of the margin of of a support

546
00:34:14,080 --> 00:34:19,560
vector machine or combinations of margin and slack variables of a support vector machine but they

547
00:34:19,560 --> 00:34:23,220
all  tell the same story I just mentioned this one cause I'm gonna

548
00:34:23,220 --> 00:34:30,240
bring it up this afternoon and it's the tightest as far as I'm aware so basically this

549
00:34:30,240 --> 00:34:35,320
is a very sort of ruthless in a sense approach it's it's just saying Look

550
00:34:35,320 --> 00:34:39,160
here's here's here's what I want to optimize I want to  get my test set performance

551
00:34:39,160 --> 00:34:45,720
to be good here's the way of measuring it I'll optimize that quantity with the provisor that

552
00:34:45,720 --> 00:34:52,520
I've slightly adapted it so that the optimization remains convex that's why following this line

553
00:34:52,520 --> 00:34:56,240
that you can't see would have not been such a good choice because it would

554
00:34:56,240 --> 00:35:03,220
have resulted in a  non-convex optimization whereas this because it's a convex function convex loss function

555
00:35:03,220 --> 00:35:12,180
does end up with the convex optimization so this is a a quadratic convex quadratic optimization problem

556
00:35:12,180 --> 00:35:16,640
which  one can  solve now I don't want to you know the aim of

557
00:35:16,640 --> 00:35:21,460
this tutorial was to talk about kernel methods and not optimization methods so I'm not gonna

558
00:35:21,460 --> 00:35:26,020
go into sort of say details of how one translates that into

559
00:35:26,020 --> 00:35:33,480
a dual  or  any of the detailed algorithmics around support vector machines it's a whole

560
00:35:33,490 --> 00:35:37,660
tutorial in itself if if if you you wanted to look into that but the

561
00:35:37,660 --> 00:35:41,780
the the long and short of it is that if you take the dual optimization

562
00:35:41,780 --> 00:35:49,940
of this optimization problem you end up with this optimization and suggestively over the variables

563
00:35:49,940 --> 00:35:54,660
alpha rhi which are very very close to our dual variables that we've been looking

564
00:35:54,660 --> 00:36:00,300
at all along there's a very slight difference that they are actually all

565
00:36:00,320 --> 00:36:04,760
positive and they have to be multiplied by the label in order to get what

566
00:36:04,760 --> 00:36:08,940
we were using as dual variables before so there's a slight mismatch between this alpha rhi and the

567
00:36:08,940 --> 00:36:15,480
previous alpha rhis which were just there was no Y I here so just think of

568
00:36:15,480 --> 00:36:19,060
the previous alpha rhi is just alpha rhi times the the label so this is just the

569
00:36:19,060 --> 00:36:24,840
size of it and the label gives the sign so you optimize this again quadratic

570
00:36:25,120 --> 00:36:32,680
convex quadratic optimization and you end up with a solution vector alpha rhi and you

571
00:36:32,680 --> 00:36:39,260
classification is given by this plus possibility  a threshold which you can compute relatively

572
00:36:39,260 --> 00:36:44,300
straightforwardly again you know all of this I don't know if you ever have to do yourself

573
00:36:44,300 --> 00:36:48,480
because there are so many packages that you can download that do this for you

574
00:36:48,480 --> 00:36:56,260
but it's more to understand what's behind those packages so notice that there's a regularization

575
00:36:56,260 --> 00:37:01,320
parameter or actually one  over the regularization parameter in the ridge regression we had the lambda

576
00:37:01,320 --> 00:37:07,260
here with now  gotta C  here but it's a trade-off between these two competing facts

577
00:37:07,260 --> 00:37:16,930
necessarily monotonic so you can get things like this but eventually it so it

578
00:37:16,930 --> 00:37:24,740
still satisfies this bounce so that's all I wanted to say about gradient methods

579
00:37:24,740 --> 00:37:35,800
are there questions about this so than in the last part of the tutorial I'd like

580
00:37:35,800 --> 00:37:47,000
to say a few things on dual methods so so I'll first start with defining duality something

581
00:37:47,090 --> 00:37:53,600
we skipped yesterday and then we look at some cases where actually it's interesting to

582
00:37:53,600 --> 00:38:00,280
solve the dual problem using a first order method for example to apply the proximal

583
00:38:00,280 --> 00:38:05,140
gradient method to the dual and so on so let's start with the definition of the

584
00:38:05,140 --> 00:38:14,460
dual so suppose I have an convex problem and I'll assume that the equalities

585
00:38:14,460 --> 00:38:21,180
and all the constraints are linear for simplicity so you have just linear inequalities and linear equalities

586
00:38:21,180 --> 00:38:25,980
then the dual is  something you can just derive very mechanically the starting point

587
00:38:25,980 --> 00:38:32,000
is to find the Lagrangian of the problem and the Lagrangian is the objective function plus a

588
00:38:32,000 --> 00:38:36,300
weighted sum of all the constraints you make a weighted sum of G X minus H times

589
00:38:36,300 --> 00:38:42,600
the multiplier lambda  a weighted sum of A X minus B times a multiplier nu and if

590
00:38:42,600 --> 00:38:46,860
you collect terms you can write it like this it's F of X plus a linear term

591
00:38:46,860 --> 00:38:51,490
in X and then something that only depends on lambda and nu so that's

592
00:38:51,490 --> 00:38:56,220
the Lagrangian of the problem and then the dual function is defined as the

593
00:38:56,220 --> 00:39:03,680
minimum of this over X so we minimize this over X and then you can recognize

594
00:39:03,680 --> 00:39:09,920
an that conjugate so if you minimize this term over X you can express

595
00:39:09,920 --> 00:39:14,940
that minimum in as a conjugate but unfortunately because we use people use different

596
00:39:14,940 --> 00:39:20,400
conventions in the definition of a conjugate and in the Lagrange dual you get many minus signs

597
00:39:20,440 --> 00:39:28,400
everywhere so the conjugate was defined as a maximum of  a linear function of X minus

598
00:39:28,400 --> 00:39:32,520
F of X here what we mean need is  the minimum of F

599
00:39:32,520 --> 00:39:37,620
of X plus a linear function of X so you have to switch signs to

600
00:39:37,620 --> 00:39:44,940
change minimization to maximization and that introduces all these signs  right so that would be the dual

601
00:39:44,940 --> 00:39:48,900
function it's not a function because you minimize over X it's a function of lambda and nu

602
00:39:49,480 --> 00:39:54,580
and it's also it's concave right it's concave because we know that a conjugate is

603
00:39:54,580 --> 00:40:00,580
convex where we change the sign it also follows directly from this because the

604
00:40:00,580 --> 00:40:06,880
minimum of this over  X will be a concave function of lambda and nu so that follows

605
00:40:06,880 --> 00:40:14,120
from some of the rules we saw yesterday and then the dual problem is simply

606
00:40:14,120 --> 00:40:19,980
to maximize the dual function over lambda and nu with constraints on lambda

607
00:40:20,400 --> 00:40:26,860
dual multipliers associated with the inequalities in the primal problem are must be positive in

608
00:40:26,930 --> 00:40:33,450
a dual problem so then we have the same types of duality results as we had

609
00:40:33,450 --> 00:40:42,840
for conic LP we also always have weak duality without exception the

610
00:40:42,840 --> 00:40:47,740
primal optimal value is greater than or equal to the dual optimal value we usually

611
00:40:47,740 --> 00:40:53,980
have equality if the problem the primal problem   is  convex but you need a technical condition

612
00:40:53,980 --> 00:41:00,360
it's called a constraint qualification and one example is that if the primal

613
00:41:00,360 --> 00:41:07,400
problem is feasible and for example F of X is dome  defined everywhere the domain

614
00:41:07,400 --> 00:41:13,300
is all of then you have strong duality so constraint qualifications are  sufficient

615
00:41:13,320 --> 00:41:22,780
conditions that guarantee strong duality and that are easier to check than just assuming strong duality

616
00:41:22,780 --> 00:41:26,320
so let's look at some examples suppose I want to minimize a norm subject to

617
00:41:26,320 --> 00:41:31,720
A X is B then the dual problem if you just apply the formula would be

618
00:41:31,720 --> 00:41:36,240
the dual function would be minus B transpose nu where nu is the multiplier for

619
00:41:36,250 --> 00:41:42,860
the constraints and then the dual the conjugates of the norm apply to many

620
00:41:42,880 --> 00:41:46,600
minus A transpose nu and now we can look up what a conjugate is of a

621
00:41:46,600 --> 00:41:52,240
norm and it turns out that a conjugate of a norm is the indicating function

622
00:41:52,240 --> 00:41:58,160
of the dual norm ball so it means that this conjugate is zero if minus

623
00:41:58,160 --> 00:42:03,540
A transpose nu has dual norm less than one an otherwise it's plus infinity so

624
00:42:03,540 --> 00:42:08,700
this is actually the conjugate function you get minus B transpose nu if A transpose nu

625
00:42:08,700 --> 00:42:13,760
has dual norm less than one otherwise it's minus infinity and then normally you would

626
00:42:13,760 --> 00:42:19,620
rewrite this problem in a nicer form  you would say that's equivalent to minimizing actually max

627
00:42:19,810 --> 00:42:34,960
maximizing B transpose Z subject to this  norm constraint right so the dual this problem is

628
00:42:34,960 --> 00:42:49,260
maximizing B transpose Z subject  to the an inequality on the dual norm yeah yeah that's just

629
00:42:49,260 --> 00:42:54,660
the convention and there  exist over conventions but if you maximize than you can say

630
00:42:54,860 --> 00:43:02,720
the interpretation of the dual or the main property is that every for positive value

631
00:43:02,720 --> 00:43:07,420
of lambda this gives the lower bound on the primal problem so that's why it

632
00:43:07,420 --> 00:43:12,600
makes sense to maximize its because that way you compute the best possible lower bound you

633
00:43:12,600 --> 00:43:19,960
can construct this way but there are other conventions that are both as a minimum minimization problem

634
00:43:19,960 --> 00:43:29,700
and then that also works but this should be a maximization and this too so

635
00:43:29,820 --> 00:43:34,080
in norm approximation if you minimize the norm of A X minus B then you

636
00:43:34,080 --> 00:43:40,240
see that actually the dual of this would be quite trivial because yes

637
00:43:40,240 --> 00:43:49,980
maximization yeah but I think you still  want the maximization because what I try

638
00:43:49,980 --> 00:43:55,580
to do here is it's actually to maximize this subject to this constraint but

639
00:43:55,580 --> 00:44:03,410
that's a symmetric set so if I change I call Z minus nu I get

640
00:44:03,410 --> 00:44:13,020
this problem with the maximization so this Z is actually minus nu in this problem and

641
00:44:13,030 --> 00:44:16,180
I make use of the fact that this is symmetric so if I change a sign of

642
00:44:16,180 --> 00:44:26,040
nu it's still feasible but I correct it in the version that's online so

643
00:44:26,540 --> 00:44:30,480
often it's necessary if you want to find an interesting dual to reformulate a problem

644
00:44:30,860 --> 00:44:33,500
so if you took the dual of this it would be quite trivial  because there are no

645
00:44:33,500 --> 00:44:38,000
it should be

646
00:44:38,020 --> 00:44:40,860
they can cause

647
00:44:46,020 --> 00:44:48,820
the the

648
00:44:55,860 --> 00:44:57,230
this one

649
00:44:57,250 --> 00:44:59,790
so much

650
00:45:01,420 --> 00:45:06,750
the which

651
00:45:09,170 --> 00:45:11,150
but the to

652
00:45:37,880 --> 00:45:42,150
you know

653
00:45:57,400 --> 00:46:00,840
and i don't

654
00:46:00,840 --> 00:46:03,130
let's come to

655
00:46:08,610 --> 00:46:12,710
because when they

656
00:46:16,060 --> 00:46:19,380
a little

657
00:46:22,440 --> 00:46:24,300
so way

658
00:46:55,630 --> 00:46:57,480
she know

659
00:47:01,590 --> 00:47:04,790
and what about the play

660
00:47:10,980 --> 00:47:13,960
one thing that can come into play

661
00:47:14,110 --> 00:47:15,820
if one

662
00:47:15,820 --> 00:47:17,290
she began

663
00:47:27,480 --> 00:47:29,610
from it

664
00:47:31,230 --> 00:47:34,750
so it's the small world

665
00:47:34,770 --> 00:47:38,750
hard call

666
00:47:54,520 --> 00:47:58,060
like i the

667
00:47:58,110 --> 00:48:00,190
but what about

668
00:48:00,250 --> 00:48:06,420
the like

669
00:48:11,940 --> 00:48:14,860
that the

670
00:48:14,880 --> 00:48:17,040
home again

671
00:48:19,710 --> 00:48:23,210
the you know

672
00:48:23,210 --> 00:48:26,440
for machine learning

673
00:48:28,350 --> 00:48:29,620
OK so

674
00:48:29,690 --> 00:48:33,100
what i'm going to do

675
00:48:33,100 --> 00:48:37,920
just in the interests of time i'm not going to sort of follow the derivation

676
00:48:37,940 --> 00:48:42,670
for the sort of next part of things right so high level

677
00:48:42,730 --> 00:48:44,020
if you remember

678
00:48:44,040 --> 00:48:46,750
if i can get my slides to appear

679
00:48:46,870 --> 00:48:51,540
what sort of backup and remember where we came from in

680
00:48:51,540 --> 00:48:56,000
trying to figure out where we're going

681
00:48:57,670 --> 00:49:02,420
that's where we came from this we had graphical models we said all these problems

682
00:49:02,420 --> 00:49:03,830
are important in practice

683
00:49:04,890 --> 00:49:11,190
spanish a of time understanding this problem linear programming relaxations message passing algorithms and i

684
00:49:11,190 --> 00:49:16,580
just mentioned generalizations like semi definite programming relaxations there's a whole hierarchy of methods there

685
00:49:16,690 --> 00:49:19,250
if you want to learn more i would encourage you to go to you either

686
00:49:19,250 --> 00:49:21,910
one or both of those NIPS tutorials that i mentioned

687
00:49:21,940 --> 00:49:25,140
let's talk a little about these problems

688
00:49:25,190 --> 00:49:29,750
so these are some asian or integration problems

689
00:49:31,830 --> 00:49:34,650
what i'm going to do this algorithm that i just arrived this

690
00:49:34,670 --> 00:49:40,270
reweighted max product this algorithm makes perfect sense if you replace

691
00:49:40,290 --> 00:49:41,940
max with some

692
00:49:41,960 --> 00:49:46,790
and that's what's known as re weighted sum product obviously and there's many convexified forms

693
00:49:46,790 --> 00:49:50,440
of it the people of studied what i'd like to do is to show you

694
00:49:50,440 --> 00:49:54,640
have very similar ideas to what i just did with tree splitting will be allow

695
00:49:54,650 --> 00:49:57,560
me to derive re weighted sum product

696
00:49:57,580 --> 00:50:01,460
one derive three weighted sum product i can sort of go backwards and show you

697
00:50:01,460 --> 00:50:06,850
how you would have gotten ordinary belief propagation ordinary sum product so i'm not really

698
00:50:06,850 --> 00:50:10,420
respecting the history or the history is that you did it freeman wise sort of

699
00:50:11,390 --> 00:50:15,730
this connection for belief propagation first but i'm just in the interests of

700
00:50:15,730 --> 00:50:20,830
making the derivation clear just allow me to flip the history a little bit

701
00:50:21,020 --> 00:50:24,190
jonathan is a good friend of mine so i don't think you'll

702
00:50:29,620 --> 00:50:30,790
OK so

703
00:50:30,790 --> 00:50:35,330
i sort of remember right so what we did when we were doing upper bounds

704
00:50:36,140 --> 00:50:41,080
the ground state or the the MAP problem we're splitting the graph let's say into

705
00:50:41,940 --> 00:50:47,060
and what was key is that this function was a convex function

706
00:50:47,920 --> 00:50:51,580
so this approach will work for any convex function

707
00:50:51,600 --> 00:50:55,910
and what turns out to be useful for this is that the graphical models the

708
00:50:55,910 --> 00:50:59,210
log likelihood is a convex function of the parameters

709
00:50:59,230 --> 00:51:04,420
so we can do the exact same splitting technique on the log likelihood and if

710
00:51:04,420 --> 00:51:10,020
we do that we're going to derive what's known as the reweighted beta problem data

711
00:51:10,130 --> 00:51:15,080
variational problems

712
00:51:22,100 --> 00:51:23,270
so again

713
00:51:23,330 --> 00:51:27,750
let me work through special case some work the special case but

714
00:51:27,750 --> 00:51:32,210
the slide certainly contain much more generality and also the

715
00:51:32,230 --> 00:51:36,230
the lecture notes are posters well side just let's work this special case if you

716
00:51:36,230 --> 00:51:39,750
understand that if you're interested i think you can go off and read about the

717
00:51:39,910 --> 00:51:42,730
more general ones

718
00:51:44,120 --> 00:51:45,080
well look at

719
00:51:45,100 --> 00:51:52,000
our graphical model with binary variables and just pairwise interactions very simple

720
00:51:52,000 --> 00:51:56,560
right and i before when i was maximizing i called this j or l of

721
00:51:56,560 --> 00:51:57,460
text data

722
00:51:57,480 --> 00:52:01,730
well use that shorthand again that sort of the physicists would call that the energy

723
00:52:01,730 --> 00:52:03,890
function of the graphical model

724
00:52:03,940 --> 00:52:07,520
what i now want to focus on i want to focus on this quantity

725
00:52:07,540 --> 00:52:11,810
before i was writing always the one over c and we haven't said much about

726
00:52:11,810 --> 00:52:16,120
these so far i just said that the thing that makes the distribution normalize

727
00:52:16,140 --> 00:52:20,250
what i'm going do is instead of one overs and moving upstairs and take

728
00:52:20,270 --> 00:52:23,100
i put law here minus log of c

729
00:52:23,120 --> 00:52:26,020
but i was going to call it something else i'm going to call the function

730
00:52:26,020 --> 00:52:27,810
field data

731
00:52:27,850 --> 00:52:31,890
so the function of these parameters if you change these parameters you than the number

732
00:52:31,890 --> 00:52:35,910
that you need to normalize the distribution would change

733
00:52:35,910 --> 00:52:39,000
right so explicitly it's it's this function it's

734
00:52:39,060 --> 00:52:42,370
delete even talk about log exp functions

735
00:52:42,370 --> 00:52:49,410
after lunch session

736
00:52:49,420 --> 00:52:53,330
i would be the session chair i'm rich and i can come from the investors

737
00:52:53,330 --> 00:52:55,910
ltd and and the

738
00:52:55,920 --> 00:52:59,920
first order decision will be given by professors when shimmery

739
00:52:59,920 --> 00:53:04,750
and the title of the talk is information geometry and its applications

740
00:53:32,810 --> 00:53:33,430
thank you

741
00:53:35,070 --> 00:53:39,490
and the title of my talk page rather than here

742
00:53:39,570 --> 00:53:43,000
so you promised to do with the topic

743
00:53:43,070 --> 00:53:46,320
but i would object like to forecast of something

744
00:53:46,360 --> 00:53:48,340
the other

745
00:53:49,370 --> 00:53:54,920
what is the information geometry

746
00:53:54,980 --> 00:53:57,600
eighteen thousand

747
00:53:57,790 --> 00:54:01,680
the remaining form of probability distributions

748
00:54:01,700 --> 00:54:04,370
i told about it

749
00:54:04,390 --> 00:54:08,040
what not are you make

750
00:54:08,060 --> 00:54:12,540
in the name the situation

751
00:54:12,560 --> 00:54:13,990
and this the

752
00:54:14,010 --> 00:54:17,430
i don't find it to remain

753
00:54:18,490 --> 00:54:22,100
some think the time

754
00:54:22,150 --> 00:54:25,070
i've got a little bit

755
00:54:25,090 --> 00:54:28,760
and also it can be a lot of applications

756
00:54:28,780 --> 00:54:29,670
i not

757
00:54:29,680 --> 00:54:31,700
not much yet

758
00:54:31,700 --> 00:54:35,090
nothing much put a few

759
00:54:35,100 --> 00:54:37,400
i want to know

760
00:54:37,510 --> 00:54:40,700
about that but i in the

761
00:54:40,920 --> 00:54:44,780
so i guess i'm not that much

762
00:54:44,810 --> 00:54:49,560
but then you know the i'm really looking to

763
00:54:49,590 --> 00:54:52,250
you have to deal with any and all four

764
00:54:52,270 --> 00:54:54,050
the application to the

765
00:54:54,110 --> 00:55:00,650
the system is the CID off that discounting around on around the like

766
00:55:00,650 --> 00:55:04,310
and the reason to something you they have to you

767
00:55:04,370 --> 00:55:06,380
well my nation

768
00:55:06,560 --> 00:55:09,240
the the upper right

769
00:55:09,250 --> 00:55:12,190
so in the model

770
00:55:12,210 --> 00:55:13,460
very simple

771
00:55:13,460 --> 00:55:16,180
for example you can think of

772
00:55:18,270 --> 00:55:22,360
having name mu

773
00:55:22,370 --> 00:55:25,630
so that's what happens to

774
00:55:25,650 --> 00:55:28,440
the two into

775
00:55:28,490 --> 00:55:30,530
one hour and

776
00:55:31,150 --> 00:55:33,740
and i like this

777
00:55:33,750 --> 00:55:35,360
so the thing

778
00:55:39,370 --> 00:55:42,460
the problem is

779
00:55:44,030 --> 00:55:46,370
four come

780
00:55:46,380 --> 00:55:53,660
both in the

781
00:55:53,680 --> 00:55:57,620
how to find out what they done not

782
00:55:57,970 --> 00:56:00,520
we have that in the future

783
00:56:00,530 --> 00:56:03,060
maybe you have a

784
00:56:03,080 --> 00:56:05,750
between two guys and

785
00:56:05,810 --> 00:56:06,680
and so

786
00:56:06,770 --> 00:56:11,800
and of course if not at time to go

787
00:56:11,810 --> 00:56:14,590
parameterized me

788
00:56:14,650 --> 00:56:16,960
probability distribution

789
00:56:17,020 --> 00:56:21,460
you can see the

790
00:56:21,470 --> 00:56:22,650
so mean

791
00:56:22,770 --> 00:56:25,490
the major criterion

792
00:56:25,630 --> 00:56:28,090
this five years

793
00:56:28,120 --> 00:56:30,000
of course the

794
00:56:30,120 --> 00:56:33,000
what i think

795
00:56:33,020 --> 00:56:34,300
think about

796
00:56:34,340 --> 00:56:40,240
the set of probability distributions where the

797
00:56:40,250 --> 00:56:41,960
so please

798
00:56:41,960 --> 00:56:44,380
the rule of law and of course

799
00:56:48,060 --> 00:56:51,150
she is

800
00:56:51,160 --> 00:56:53,030
and according to a

801
00:56:53,050 --> 00:56:58,990
so we didn't really have on this record

802
00:56:58,990 --> 00:57:03,370
the second thing to say i explain the real

803
00:57:03,380 --> 00:57:06,430
we can change the scale of

804
00:57:06,540 --> 00:57:09,160
so i found

805
00:57:09,170 --> 00:57:11,930
two and it was only

806
00:57:11,950 --> 00:57:14,750
the distribution of y

807
00:57:14,760 --> 00:57:18,250
change in the distribution of y

808
00:57:18,250 --> 00:57:21,750
that's the parliament i just in case

809
00:57:23,610 --> 00:57:25,830
be or the

810
00:57:27,020 --> 00:57:30,050
to be equal equal to the speed

811
00:57:32,810 --> 00:57:34,600
so the next

812
00:57:34,640 --> 00:57:37,430
there should not be in

813
00:57:37,480 --> 00:57:38,950
on page p

814
00:57:40,860 --> 00:57:44,560
and i'm sure

815
00:57:44,560 --> 00:57:45,450
it does seem

816
00:57:45,470 --> 00:57:48,870
now that we can have unique

817
00:57:48,880 --> 00:57:50,320
the deal

818
00:57:50,330 --> 00:57:52,070
to be introduced

819
00:57:53,080 --> 00:57:54,550
one made four

820
00:57:54,700 --> 00:57:59,110
parameter estimation

821
00:57:59,180 --> 00:58:04,930
what we really mean it

822
00:58:05,000 --> 00:58:06,600
OK so the

823
00:58:06,930 --> 00:58:09,450
think about that space

824
00:58:09,500 --> 00:58:11,770
probability distributions

825
00:58:16,490 --> 00:58:19,730
and you know what i mean you all

826
00:58:19,770 --> 00:58:21,500
up to point to see

827
00:58:21,510 --> 00:58:24,880
so in essence name

828
00:58:24,890 --> 00:58:28,690
we have a been

829
00:58:28,750 --> 00:58:31,330
the content

830
00:58:32,940 --> 00:58:36,910
this between two probability distributions

831
00:58:36,950 --> 00:58:38,010
i mean why

832
00:58:38,040 --> 00:58:43,630
parameterized by theta and the space that but i have seen

833
00:58:45,360 --> 00:58:46,350
it can be

834
00:58:47,580 --> 00:58:49,270
it is

835
00:58:49,320 --> 00:58:53,260
can be made at the bicluster out

836
00:58:53,410 --> 00:58:56,500
we need to be

837
00:58:56,560 --> 00:59:00,290
this can be transformed into and i am not all

838
00:59:00,300 --> 00:59:01,320
and have

839
00:59:01,380 --> 00:59:03,910
you can extract

840
00:59:05,300 --> 00:59:06,270
there's also

841
00:59:06,940 --> 00:59:08,540
according to queen

842
00:59:08,570 --> 00:59:10,330
to the naked

843
00:59:10,430 --> 00:59:13,300
it depends on conditional fee

844
00:59:14,930 --> 00:59:19,100
we have the called

845
00:59:19,140 --> 00:59:25,250
by hope g i becomes the idea can make it

846
00:59:25,300 --> 00:59:28,100
that the euclidean

847
00:59:28,140 --> 00:59:31,490
however i i think about this

848
00:59:31,500 --> 00:59:32,790
they don't have that

849
00:59:32,800 --> 00:59:35,050
now what

850
00:59:35,060 --> 00:59:38,040
what they call the house

851
00:59:38,060 --> 00:59:41,170
one going you

852
00:59:41,180 --> 00:59:42,720
i mean

853
00:59:44,260 --> 00:59:46,250
that i to think

854
00:59:51,510 --> 00:59:54,190
the think we go by

855
00:59:54,240 --> 00:59:57,310
they find context

856
00:59:57,360 --> 00:59:59,690
what find connection

857
00:59:59,700 --> 01:00:00,690
i mean

858
01:00:00,750 --> 01:00:03,350
OK so we have right

859
01:00:04,060 --> 01:00:06,330
nine called

860
01:00:08,580 --> 01:00:11,110
we have the look and

861
01:00:11,160 --> 01:00:13,630
by quadratic forms

862
01:00:13,660 --> 01:00:17,300
and two hundred yard

863
01:00:17,310 --> 01:00:22,310
however i'm not point we also the

864
01:00:22,430 --> 01:00:23,490
in august

865
01:00:23,540 --> 01:00:27,560
however i mean for the car

866
01:00:33,380 --> 01:00:38,370
so you have to about the after that we see

867
01:00:38,380 --> 01:00:40,570
about so-called

868
01:00:44,580 --> 01:00:46,700
you can see from the data

869
01:00:47,510 --> 01:00:49,360
let me

870
01:00:49,370 --> 01:00:52,490
OK you can fun with all

871
01:00:55,310 --> 01:00:56,660
that they the

872
01:00:56,670 --> 01:00:58,720
i find connection

873
01:00:58,760 --> 01:01:00,230
and typically

874
01:01:00,310 --> 01:01:02,690
it did you have to buy provided and

875
01:01:02,700 --> 01:01:07,180
evaluation and so about for get the second had

876
01:01:07,220 --> 01:01:09,000
and now

877
01:01:09,080 --> 01:01:11,320
we think about jewish

878
01:01:11,540 --> 01:01:15,980
one of the

879
01:01:16,010 --> 01:01:18,100
they so that they need to

880
01:01:18,100 --> 01:01:20,930
directly into the program

881
01:01:20,930 --> 01:01:23,480
so that when you programming

882
01:01:23,500 --> 01:01:28,300
you actually program with police cynicism talking about here and desires intentions

883
01:01:28,310 --> 01:01:31,720
see anybody well i guess is still running control and things like that but the

884
01:01:31,720 --> 01:01:36,510
programming languages so explicitly has these concepts

885
01:01:36,510 --> 01:01:38,640
and you build your agent programs

886
01:01:38,650 --> 01:01:41,170
in terms of these concepts

887
01:01:41,210 --> 01:01:44,170
is in the sense moving to a higher level of abstraction

888
01:01:44,180 --> 01:01:45,210
this machine

889
01:01:45,220 --> 01:01:46,720
come down here

890
01:01:47,820 --> 01:01:51,960
mid-level level programming languages like haskell whatever else and this may be

891
01:01:51,990 --> 01:01:54,760
this job problem whatever also things

892
01:01:54,860 --> 01:01:57,510
and above that maybe object orientated

893
01:01:57,510 --> 01:01:59,900
and above that nineteen

894
01:02:00,580 --> 01:02:01,350
the the

895
01:02:01,370 --> 01:02:05,230
concept the belief is explicitly part of the programme custom syntax and you can apply

896
01:02:05,240 --> 01:02:08,970
to one

897
01:02:09,050 --> 01:02:12,150
other there are

898
01:02:12,230 --> 01:02:14,530
so experiment language

899
01:02:14,580 --> 01:02:15,800
but the the

900
01:02:15,800 --> 01:02:19,520
the i guess the problem is

901
01:02:19,520 --> 01:02:23,550
the the the the this and experimental languages which of course not widely

902
01:02:23,570 --> 01:02:26,070
quite a lot of years

903
01:02:26,090 --> 01:02:27,530
languages that

904
01:02:27,540 --> 01:02:30,040
use this concept fairly widely used

905
01:02:30,050 --> 01:02:30,810
i mean

906
01:02:30,830 --> 01:02:33,640
into this in very weak sense

907
01:02:33,690 --> 01:02:35,120
so that's almost

908
01:02:35,400 --> 01:02:38,050
inspired by the i

909
01:02:38,120 --> 01:02:40,510
actually i actually rather low level

910
01:02:40,550 --> 01:02:43,040
so the take on some of the ideas

911
01:02:43,120 --> 01:02:45,950
and push the bit in that direction but not with

912
01:02:45,950 --> 01:02:47,580
the size you want

913
01:02:48,570 --> 01:02:52,200
in terms of having a widely used language which is really working at this level

914
01:02:52,200 --> 01:02:53,730
the answer is no

915
01:02:53,770 --> 01:02:55,530
are some experimental languages

916
01:02:56,830 --> 01:02:58,310
i'm not going to

917
01:02:58,350 --> 01:03:01,030
find the mind

918
01:03:03,090 --> 01:03:05,980
so there's another phd

919
01:03:07,290 --> 01:03:09,960
some the likely OK alright so

920
01:03:09,980 --> 01:03:11,420
so here's the world

921
01:03:11,480 --> 01:03:14,900
there's not very personal very helpful but at the top level the

922
01:03:14,960 --> 01:03:18,370
one of the BIA

923
01:03:18,400 --> 01:03:19,940
OK so

924
01:03:20,030 --> 01:03:21,320
the solution

925
01:03:21,420 --> 01:03:24,490
which involves getting a percept

926
01:03:24,490 --> 01:03:25,750
from the per cent

927
01:03:25,760 --> 01:03:27,790
presumably ability should change because

928
01:03:27,800 --> 01:03:29,720
something things changed environment

929
01:03:29,730 --> 01:03:33,420
so there is that when you update your beliefs

930
01:03:33,440 --> 01:03:34,850
as a result of that

931
01:03:35,420 --> 01:03:37,580
you may want to update your desires

932
01:03:37,620 --> 01:03:38,800
for example

933
01:03:38,810 --> 01:03:42,100
you may now be aware some that's true which means that i had just waste

934
01:03:42,110 --> 01:03:42,850
of time

935
01:03:42,860 --> 01:03:46,460
you can do you can two reasons they might decide to do that we might

936
01:03:46,460 --> 01:03:48,440
modify something

937
01:03:48,450 --> 01:03:49,330
and then

938
01:03:49,360 --> 01:03:53,740
this more small thinking that goes on amongst the designers you might keep intention had

939
01:03:53,740 --> 01:03:56,300
before changed when you want

940
01:03:56,340 --> 01:03:59,220
and then having decided that intention you want to achieve

941
01:03:59,220 --> 01:04:02,270
it's like an action plan action government again

942
01:04:02,320 --> 01:04:06,840
so explicitly the high-level this mentalistic concepts which are used to guide

943
01:04:06,850 --> 01:04:09,780
the construction of the program

944
01:04:09,820 --> 01:04:11,370
so it's a beautiful idea

945
01:04:11,440 --> 01:04:14,550
but my experience is it doesn't work

946
01:04:14,600 --> 01:04:16,040
right and

947
01:04:16,040 --> 01:04:19,020
the place that doesn't work is is that

948
01:04:19,040 --> 01:04:21,550
is the goal directed this you want

949
01:04:22,470 --> 01:04:24,560
my experience is that

950
01:04:24,580 --> 01:04:29,900
instead of desires intentions to utilize the idea

951
01:04:29,920 --> 01:04:33,670
maybe this would be true forever knight distance to make it work

952
01:04:33,690 --> 01:04:37,710
it seems that based idea rewards so on

953
01:04:37,750 --> 01:04:40,310
has been more successful getting access to work

954
01:04:40,420 --> 01:04:44,170
on the other hand the beliefs ideas really crucial i places not least to the

955
01:04:44,170 --> 01:04:45,870
knowledge base

956
01:04:45,880 --> 01:04:47,790
there's no way you get do that

957
01:04:47,790 --> 01:04:48,590
the others

958
01:04:48,610 --> 01:04:50,400
desires intentions

959
01:04:50,540 --> 01:04:54,540
given the goal directed the what what's trying to achieve

960
01:04:54,550 --> 01:04:56,540
and it's nice

961
01:04:56,550 --> 01:04:59,260
in a sort of philosophical and psychological way

962
01:04:59,270 --> 01:05:01,710
because there's no doubt that we operating like that

963
01:05:01,720 --> 01:05:03,740
somehow when you come down to it

964
01:05:03,750 --> 01:05:05,750
it doesn't seem to work

965
01:05:05,760 --> 01:05:07,260
so that some

966
01:05:08,520 --> 01:05:10,800
politically incorrect anyway

967
01:05:10,850 --> 01:05:13,810
that was my experience

968
01:05:13,860 --> 01:05:16,840
right more things you should be aware of actually some of you down

969
01:05:16,850 --> 01:05:19,200
reinforcement learning course right

970
01:05:19,200 --> 01:05:22,070
yes yes are you got able to slide away

971
01:05:22,130 --> 01:05:25,760
for those who haven't i just mentioned two ideas

972
01:05:25,810 --> 01:05:29,620
so this is just a listing some concepts that you need to be aware of

973
01:05:29,670 --> 01:05:32,820
and the people widely used and IR are

974
01:05:32,870 --> 01:05:35,650
so markov decision processes

975
01:05:35,700 --> 01:05:38,770
i've got a number of components

976
01:05:38,820 --> 01:05:40,190
the state

977
01:05:40,200 --> 01:05:42,200
typically finance estate

978
01:05:42,200 --> 01:05:45,160
X divided by some other polynomial

979
01:05:54,230 --> 01:06:01,630
well this is plus transform of the end so this is all plus transform of

980
01:06:01,630 --> 01:06:05,670
the solution we are looking for so the final step is to go backwards

981
01:06:06,710 --> 01:06:12,400
by taking the universal plus transform of this guy and what will you get what

982
01:06:12,420 --> 01:06:17,590
you get y equals y of t that we're looking for

983
01:06:18,900 --> 01:06:28,900
it's really a wildly improbable procedure in other words instead going from here to here

984
01:06:29,030 --> 01:06:33,180
you have to imagine there's of mountain here and the only way get around this

985
01:06:33,280 --> 01:06:38,100
to go 1st year across the street here and then go back

986
01:06:38,490 --> 01:06:39,830
and go back

987
01:06:39,890 --> 01:06:44,710
it looks like a senseless procedure you know where they are going around Robin Hoods

988
01:06:44,710 --> 01:06:49,710
born with when I was 1 of my school that but that's what we used

989
01:06:49,710 --> 01:06:53,800
to call not that will plus transform that was adjusted to thing we you have

990
01:06:53,890 --> 01:06:58,050
do something like this or that but

991
01:06:59,050 --> 01:07:04,330
but the answer that it's hard to go from here to here but trivial to

992
01:07:04,330 --> 01:07:05,290
go from here to here

993
01:07:06,290 --> 01:07:09,490
this solutions that is the easiest step of

994
01:07:10,390 --> 01:07:13,530
this is not very hard

995
01:07:13,550 --> 01:07:18,360
it's easy in fact this is easy and straightforward businesses

996
01:07:18,380 --> 01:07:20,790
true essentially

997
01:07:20,790 --> 01:07:22,360
yeah trivial

998
01:07:22,670 --> 01:07:27,690
but that is on

999
01:07:27,700 --> 01:07:30,510
this is where you have use partial fractions

1000
01:07:30,510 --> 01:07:35,140
look up things in the table and to get back there so most of the

1001
01:07:35,140 --> 01:07:40,170
work of the procedure isn't going from here to here going from here there's a

1002
01:07:42,290 --> 01:07:48,140
OK now in order to implement this 1 that we have to do well the

1003
01:07:48,140 --> 01:07:50,700
basic thing is I have to explain to you

1004
01:07:51,030 --> 01:07:55,070
you already know this a little bit of a reasonable amount of take the stating

1005
01:07:55,070 --> 01:08:00,490
that you want to recitation yesterday in practice a little bit this part I assure

1006
01:08:00,490 --> 01:08:05,860
you was nothing so all I have to do now is explained it is explained

1007
01:08:05,900 --> 01:08:12,460
to you take will plus transform differential equation and that really means anti-takeover plus transform

1008
01:08:12,600 --> 01:08:13,860
of the derivatives

1009
01:08:13,960 --> 01:08:16,140
so that's problem

1010
01:08:16,340 --> 01:08:32,140
what voices in other words a formula for plus transform of f prime now in

1011
01:08:32,140 --> 01:08:33,990
terms of what was

1012
01:08:34,290 --> 01:08:39,380
since there isn't an arbitrary function and the only thing I can hope for is

1013
01:08:39,460 --> 01:08:45,460
somehow to express the will plus transform of the derivative in terms of all plus

1014
01:08:45,460 --> 01:08:49,180
transform of the original function

1015
01:08:49,250 --> 01:08:50,640
so that's what I'm aiming for

1016
01:08:51,490 --> 01:08:57,980
OK where we start well starting is easier because we know nothing if you don't

1017
01:08:57,990 --> 01:09:02,750
know anything there is no place to start with the definition since I know nothing

1018
01:09:02,750 --> 01:09:04,990
whatever about the function of the

1019
01:09:06,600 --> 01:09:11,490
and want calculate the plot strands of transformed through it on the start with definitions

1020
01:09:11,490 --> 01:09:19,290
so whatever that it it's the integral from 0 to infinity of either the minus

1021
01:09:19,290 --> 01:09:23,120
2 times prior to the

1022
01:09:23,340 --> 01:09:25,120
now my looking for

1023
01:09:25,990 --> 01:09:32,860
I'm looking for somehow transformed so that what appears here is not trying to

1024
01:09:32,880 --> 01:09:36,120
which I'm clueless about but at to

1025
01:09:36,140 --> 01:09:38,290
because of this war effort

1026
01:09:38,290 --> 01:09:43,510
this expression plus transform of f of tea and I'm assuming I know that

1027
01:09:44,010 --> 01:09:51,530
so the question is how do I take this somehow do something clever to it

1028
01:09:51,800 --> 01:09:55,430
that turns this into FFT instead of trying to

1029
01:09:55,430 --> 01:10:02,860
frequency time phase difference immediately reflects also the time difference between those two channels

1030
01:10:02,910 --> 01:10:04,560
and actually

1031
01:10:04,580 --> 01:10:08,660
basically this low here

1032
01:10:08,670 --> 01:10:12,220
represents the time delay

1033
01:10:15,830 --> 01:10:18,900
it's not defined for frequency as i mean how do

1034
01:10:18,910 --> 01:10:20,890
define a face

1035
01:10:20,910 --> 01:10:24,180
face of four four still frequency

1036
01:10:24,200 --> 01:10:31,010
actually in this case it was

1037
01:10:31,030 --> 01:10:32,870
either zero or one

1038
01:10:32,890 --> 01:10:35,070
one hundred eighty degrees

1039
01:10:37,200 --> 01:10:43,260
but here is the face displayed i did not display the time

1040
01:10:43,280 --> 01:10:46,720
so that's not the band below that's just the face

1041
01:10:46,730 --> 01:10:51,290
so and for this reason i think it did not include the picture on the

1042
01:10:51,290 --> 01:10:53,550
time difference

1043
01:10:53,570 --> 01:10:55,400
probably because of that reason

1044
01:10:55,450 --> 01:11:00,760
i mentioned already that there is the problem with what and conduction and that's what

1045
01:11:00,800 --> 01:11:07,030
i want is known to be a big issue in in classical coherence analysis

1046
01:11:07,140 --> 01:11:14,110
and for this reason koreans was criticized very much and in the in the nineties

1047
01:11:14,110 --> 01:11:19,990
colleagues of mine it and eleven class were criticizing coherence and i guess also others

1048
01:11:19,990 --> 01:11:20,630
in the world

1049
01:11:20,920 --> 01:11:24,530
criticizing her kerkorian's exactly for that reason

1050
01:11:24,550 --> 01:11:31,070
and one possible solution that was already proposed at that time is to use partial

1051
01:11:32,130 --> 01:11:36,580
but coherence has includes basically the concept that

1052
01:11:36,600 --> 01:11:40,410
if you look at the the coupling of clearance between a pair of channels here

1053
01:11:40,470 --> 01:11:46,220
one to two and then we look at the behaviour of all the other channels

1054
01:11:46,380 --> 01:11:49,180
we can partial out the activity

1055
01:11:49,300 --> 01:11:53,190
of all the other channels on that specific area

1056
01:11:53,200 --> 01:11:59,640
so what remains is just the coupling peter that's unique to that p of channels

1057
01:12:00,180 --> 01:12:04,120
what you see here is that really coherence

1058
01:12:04,180 --> 01:12:07,350
was large and almost everywhere here

1059
01:12:07,360 --> 01:12:12,020
much of the clearances can not only in specific areas

1060
01:12:12,090 --> 01:12:12,910
we see

1061
01:12:13,000 --> 01:12:18,160
still have partial coherence but that's not here

1062
01:12:18,750 --> 01:12:22,910
but what about something i want to point out here two is that queens is

1063
01:12:22,910 --> 01:12:24,580
also symmetric measures

1064
01:12:24,590 --> 01:12:30,690
that's budget clients from two to one is the famous has from one to two

1065
01:12:30,880 --> 01:12:40,950
in analyzing the coupling between different areas we are not only interested but the two

1066
01:12:40,950 --> 01:12:44,370
areas are interconnected but we wanted to know

1067
01:12:44,410 --> 01:12:49,820
which channel which area is time which other and whether there's a backlog connection to

1068
01:12:49,820 --> 01:12:55,810
one not so the question is whether area one is driving area two

1069
01:12:55,860 --> 01:13:03,970
or two is driving one or is it a little with connections in both directions

1070
01:13:03,980 --> 01:13:06,450
this could not be

1071
01:13:06,470 --> 01:13:13,150
analysed by by the semantic measures but we need some kind of and symmetric measure

1072
01:13:13,190 --> 01:13:16,990
and one of the first proposing such kind of

1073
01:13:17,000 --> 01:13:19,360
not actually the first about earlier works

1074
01:13:19,370 --> 01:13:24,850
going back to to granger and then later in the eighties kbk but something that

1075
01:13:24,850 --> 01:13:28,060
was proposed also by article in from russia

1076
01:13:28,100 --> 01:13:30,500
kaminski north scott

1077
01:13:30,550 --> 01:13:33,860
proposing the directed transfer function

1078
01:13:33,880 --> 01:13:37,130
to analyse this coupling

1079
01:13:37,140 --> 01:13:39,820
what you see here is that

1080
01:13:39,830 --> 01:13:41,630
the DTF

1081
01:13:41,650 --> 01:13:48,950
it's it's not symmetric so you can have here coupling that is large in one

1082
01:13:49,050 --> 01:13:51,950
actions here in the other direction

1083
01:13:53,210 --> 01:13:57,360
this was not the only one proposing something like this

1084
01:13:57,420 --> 01:14:05,260
there was a mesh another measure was proposed that the so-called partial directed coherence

1085
01:14:05,360 --> 01:14:09,610
it's motivated by using the partial coherence as introduced earlier

1086
01:14:09,720 --> 01:14:16,560
but including also some kind of protection information so that we get in or something

1087
01:14:16,610 --> 01:14:21,080
and symmetric measure what we see here is

1088
01:14:22,150 --> 01:14:25,940
here we have a connection between one and two but no connection between two in

1089
01:14:25,940 --> 01:14:30,360
ponce so that's that's clearly not symmetric at all

1090
01:14:31,020 --> 01:14:34,740
this is from the coat of parklands machine

1091
01:14:34,750 --> 01:14:41,510
proposing this in two thousand one and then the first paper there active actually put

1092
01:14:41,520 --> 01:14:45,560
describing also the second kind of the BBC the BBC have

1093
01:14:45,610 --> 01:14:47,490
which is defined here

1094
01:14:47,530 --> 01:14:49,320
which reflects all the

1095
01:14:49,330 --> 01:14:52,650
make sure of the instantaneous causality

1096
01:14:52,670 --> 01:14:59,970
whatever that means instantaneous causality is

1097
01:15:00,550 --> 01:15:06,010
causality is usually mean something that there is a relationship in time

1098
01:15:06,020 --> 01:15:10,200
and if something is reflects that is an instantaneous correlations so

1099
01:15:10,230 --> 01:15:11,540
that's the somehow

1100
01:15:11,550 --> 01:15:12,900
doesn't fit well well

1101
01:15:12,910 --> 01:15:18,900
basically what i will continue to talk about this the PDC in itself

1102
01:15:20,900 --> 01:15:24,200
so if you go back to this is to the original model

1103
01:15:24,220 --> 01:15:26,470
and look at the various capping measures

1104
01:15:26,480 --> 01:15:27,610
the question is

1105
01:15:27,620 --> 01:15:29,090
which of the

1106
01:15:30,360 --> 01:15:36,200
measures of the coupling measure the suitability to identify the underlying structure of the model

1107
01:15:36,430 --> 01:15:38,160
and so

1108
01:15:38,170 --> 01:15:42,980
or we can phrase the question is in the way in which the coupling measures

1109
01:15:42,980 --> 01:15:46,880
to distinguish between direct and indirect activity

1110
01:15:46,900 --> 01:15:48,380
and which

1111
01:15:50,590 --> 01:15:55,900
distinguishing between is able to distinguish between being forward and backward connections

1112
01:15:55,920 --> 01:16:03,480
and if you if you make and looking at the slightest earlier then you should

1113
01:16:03,480 --> 01:16:07,840
be able to answer that question and if if you're looking at this set a

1114
01:16:07,840 --> 01:16:09,150
set of

1115
01:16:09,200 --> 01:16:12,450
coupling measures ten

1116
01:16:12,460 --> 01:16:15,940
only the BBC for free all of these requirements

1117
01:16:15,950 --> 01:16:22,650
so so far for the for the for the

1118
01:16:22,660 --> 01:16:27,120
background for the theoretically part

1119
01:16:27,170 --> 01:16:28,540
we've also

1120
01:16:30,950 --> 01:16:36,840
is that so you have an autoregressive process to try to

1121
01:16:38,400 --> 01:16:40,930
when the the most

1122
01:16:41,100 --> 01:16:44,070
and you could try to estimate this

1123
01:16:44,070 --> 01:16:47,290
in the mouth they put it on the head the saturday banged on it and

1124
01:16:47,460 --> 01:16:50,130
they tend to pull the levers independently

1125
01:16:50,190 --> 01:16:54,520
so what it looks like and they made the claim in their paper that really

1126
01:16:54,520 --> 01:16:58,440
doing experiment designed to understand how all the levels in the world works is an

1127
01:16:58,460 --> 01:17:01,980
intractable problems like that bayes optimal exploration problem

1128
01:17:02,000 --> 01:17:06,400
but maybe can running something like a quick like heuristic write something that says i

1129
01:17:06,400 --> 01:17:08,790
don't know what the right thing to do is but

1130
01:17:08,810 --> 01:17:11,540
well it would be what kind of make me happy to see what would happen

1131
01:17:11,540 --> 01:17:13,350
if i pull this level by itself

1132
01:17:13,360 --> 01:17:17,650
but that just i something about this box intrigues me still writing drawn to it

1133
01:17:17,650 --> 01:17:19,900
may be that i have a real detail plan about what they're going to do

1134
01:17:19,900 --> 01:17:23,690
when they get there but it's still kinda curious about it in the condition with

1135
01:17:23,690 --> 01:17:25,690
a solvable the liver spots separately

1136
01:17:25,710 --> 01:17:29,940
somehow it just lost its charm the box is no longer find that and so

1137
01:17:30,020 --> 01:17:32,380
you could try to explain this with that they know what they seen to know

1138
01:17:32,380 --> 01:17:35,770
what they have seen this want to see more than used

1139
01:17:35,790 --> 01:17:39,130
so these guys could these are psychology they continue to do all kinds of really

1140
01:17:39,130 --> 01:17:40,770
need studies with

1141
01:17:40,830 --> 01:17:42,960
kids and learning

1142
01:17:42,980 --> 01:17:44,960
kapali going to learn any more

1143
01:17:44,980 --> 01:17:47,500
i don't know maybe just can't get funding for growing

1144
01:17:47,810 --> 01:17:51,520
and then back to the you know it's already in the literature the cartoon literature

1145
01:17:51,730 --> 01:17:55,380
this is this is also deals with the problem of two people explore this is

1146
01:17:55,380 --> 01:17:59,770
an xkcd cartoon which have not really show because it's the nerdy is find the

1147
01:17:59,770 --> 01:18:05,170
funniest narrator by it's it's ninety and find the same time so the main character

1148
01:18:05,190 --> 01:18:08,980
you could tell is the main character because doesn't had the main character walks up

1149
01:18:09,000 --> 01:18:13,400
to a podium that has lebron pulls it and instantly hit by lightning

1150
01:18:13,420 --> 01:18:18,810
and now he's since standing in front of the podium and now the choice point

1151
01:18:18,860 --> 01:18:22,790
i make this terminology normal person versus i this is what's in the cartoon he

1152
01:18:22,790 --> 01:18:26,250
said personnel says well i guess i should do that

1153
01:18:26,480 --> 01:18:29,830
what a scientist says i wonder if that happens every time which is for the

1154
01:18:29,830 --> 01:18:31,000
less so

1155
01:18:31,350 --> 01:18:35,290
we're building our algorithms may be a little bit more like this because it seems

1156
01:18:35,290 --> 01:18:36,120
like that

1157
01:18:36,130 --> 01:18:40,150
the people i know but you know maybe there's something to be said for this

1158
01:18:40,150 --> 01:18:41,830
perspective as well

1159
01:18:41,850 --> 01:18:45,710
so so just to wrap up i told you about model based reinforcement learning i

1160
01:18:45,710 --> 01:18:49,350
summarise reinforcement learning for you and talk about the model based approach i spent a

1161
01:18:49,350 --> 01:18:54,210
lot of time talking about quick learning efficient exploration and i hope that that some

1162
01:18:54,310 --> 01:18:57,750
interesting because i spent a lot of your time on a little bit about bayesian

1163
01:18:57,750 --> 01:19:02,190
reinforcement learning how the difference between near bayesian PAC MDP may actually be really interesting

1164
01:19:02,190 --> 01:19:04,330
to think about what's the right

1165
01:19:04,360 --> 01:19:05,770
problem to be attacking

1166
01:19:05,790 --> 01:19:09,250
and a little bit about planning and how we actually can take the models that

1167
01:19:09,250 --> 01:19:12,520
the learner and model based RL setting and use them to make decisions in the

1168
01:19:12,520 --> 01:19:16,130
world when things are some inefficient and how this may or may not connected with

1169
01:19:16,130 --> 01:19:19,360
people and that was the story that i have to tell you some things like

1170
01:19:19,360 --> 01:19:27,500
three times

1171
01:19:27,520 --> 01:19:34,880
now it is are lights that can come on to anybody know

1172
01:19:34,900 --> 01:19:38,980
co i can be introduced to really bright lights at the back in the shining

1173
01:19:38,980 --> 01:19:39,960
right at

1174
01:19:39,960 --> 01:19:43,440
episode of star trek i see five lights

1175
01:19:43,460 --> 01:19:48,190
i can i can vaguely see websites see the hand standing just just call out

1176
01:19:48,190 --> 01:19:49,440
i can hear you

1177
01:19:57,000 --> 01:20:00,190
yes no

1178
01:20:00,210 --> 01:20:03,560
well yes

1179
01:20:14,670 --> 01:20:22,400
so i'm i say yes absolutely yes i don't know that a lot of existing

1180
01:20:22,400 --> 01:20:27,130
what does that because they were really keeping track of uncertainty bayesian or in the

1181
01:20:27,190 --> 01:20:31,150
black and white quick sense so they just use it as the best guess with

1182
01:20:31,150 --> 01:20:34,770
it and have gone off and to try to get better data and make sure

1183
01:20:34,770 --> 01:20:37,330
the exploration solved better though sometimes have people

1184
01:20:37,330 --> 01:20:40,060
demonstrate the task for them so they get the right kind of data in the

1185
01:20:40,060 --> 01:20:44,190
right part of the state space but the algorithms that really nicely with those cases

1186
01:20:44,210 --> 01:20:48,850
so in particular like like a UCT learner it can give those exploration bonuses if

1187
01:20:48,920 --> 01:20:52,620
get transition state transition that doesn't know well they can a little bit to that

1188
01:20:52,620 --> 01:20:55,540
in the plan so that when it comes back and actually tries to act that

1189
01:20:55,540 --> 01:20:58,170
derivative of something

1190
01:20:58,240 --> 01:21:02,960
with respect to x see the motivation for that if this turns out to be

1191
01:21:02,960 --> 01:21:08,110
the derivative of something because i've chosen you so cleverly then I'll be able to

1192
01:21:08,110 --> 01:21:13,060
solve the equation immediately just by integrating this with respect to x and integrating that

1193
01:21:13,080 --> 01:21:18,610
with respect to X you just integrate both sides with respect to x and equation

1194
01:21:18,610 --> 01:21:25,560
is solved now the only question is what should I choose for you well what

1195
01:21:25,560 --> 01:21:29,110
I'm this if you would think of the product formula

1196
01:21:29,240 --> 01:21:32,930
there might be many things to try here there's only 1 reasonable thing to try

1197
01:21:33,860 --> 01:21:39,100
try to pick you so that is the derivative of times Y. see reasonable that

1198
01:21:39,110 --> 01:21:43,610
is values the product rule on this in the 1st term is you

1199
01:21:43,610 --> 01:21:49,890
times y prime the 2nd term would be you prime times while I well I

1200
01:21:49,890 --> 01:21:54,260
got the why there so this will work

1201
01:21:54,350 --> 01:22:01,350
works if what is what the condition that you must satisfy in order for that

1202
01:22:01,350 --> 01:22:07,270
to be true well it must be that after I do the differentiation you prime

1203
01:22:07,350 --> 01:22:15,850
turns out to be P times you

1204
01:22:16,790 --> 01:22:22,280
so a clear we want this is something we want to be equal to

1205
01:22:22,370 --> 01:22:28,090
and mind the thing I'll try to do it is by choosing you in such

1206
01:22:28,090 --> 01:22:32,470
a way that this equality will take place and then I'll be able to solve

1207
01:22:32,520 --> 01:22:37,930
equation now so here's what might you prime must satisfy we can solve that but

1208
01:22:37,930 --> 01:22:42,890
please don't forget that p is p of X it's a function of X so

1209
01:22:42,890 --> 01:22:46,390
if you separated variables here I'm going to do this

1210
01:22:46,670 --> 01:22:53,040
so what is it the over u equals P of X times dx

1211
01:22:53,060 --> 01:22:59,910
if I integrate that so separated variables integrate

1212
01:22:59,970 --> 01:23:04,010
and you're going to get the EU over you integrates to be the lot of

1213
01:23:04,010 --> 01:23:09,550
you and the other side integrates to be the integral of p of X T

1214
01:23:09,550 --> 01:23:15,260
X and you can put arbitrary constant they're all you can think of it as

1215
01:23:15,260 --> 01:23:20,530
you already employed by the indefinite integral well that doesn't tell us that with you

1216
01:23:20,540 --> 01:23:25,390
is what should you be noticed I don't have to find every possible you which

1217
01:23:25,390 --> 01:23:30,130
works all I'm looking for is 1 all I want is a single you which

1218
01:23:30,130 --> 01:23:37,690
satisfies that equation well u equals the integral each to the integral PBX that's not

1219
01:23:37,700 --> 01:23:43,610
too beautiful looking but by differential equations can things can get so complicated that by

1220
01:23:43,610 --> 01:23:47,310
the you know and a weaker to you will think of this as an extremely

1221
01:23:47,310 --> 01:23:54,950
simple formula so there is a formula for integrating fact there we found

1222
01:23:54,960 --> 01:24:05,390
we were always be able to write integrating factor don't worry about the arbitrary constant

1223
01:24:05,390 --> 01:24:13,720
because you only need 1 such you so no arbitrary constant since only 1 since

1224
01:24:13,800 --> 01:24:25,980
only 1 you needed and that's a solution the way we solve the linear equations

1225
01:24:26,760 --> 01:24:28,040
OK let's see

1226
01:24:28,130 --> 01:24:30,460
take over and

1227
01:24:30,480 --> 01:24:37,260
actually do it I think I would be better to summarize is a clear-cut methods

1228
01:24:37,740 --> 01:24:42,910
are so let's do that

1229
01:24:43,370 --> 01:24:58,170
yeah so on on the system method for solving why pointless p y equals cute

1230
01:24:58,790 --> 01:25:04,450
well in the 1st place make sure it's in standard standard linear form if it

1231
01:25:04,450 --> 01:25:10,190
isn't you must put in that form notice the formula for the integrating factor

1232
01:25:10,220 --> 01:25:16,130
the formula for the integrating factor involves the integral of PDX so you better get

1233
01:25:16,130 --> 01:25:21,870
the right he otherwise you some OK so put it in the standard linear form

1234
01:25:21,910 --> 01:25:27,170
that way you have the right piece notice that if you in that

1235
01:25:27,170 --> 01:25:29,370
and all you remembered was integral

1236
01:25:30,070 --> 01:25:35,570
the yearly integral PBX the P. would have the wrong sign that is good right

1237
01:25:35,890 --> 01:25:41,230
that the shouldn't have to have a negative sign there

1238
01:25:41,240 --> 01:25:46,090
do it this way and no other way otherwise you get confused and get wrong

1239
01:25:46,090 --> 01:25:50,760
signs and as I say that will produce wrong answers and not just slightly wrong

1240
01:25:50,760 --> 01:25:55,170
answers with disastrously wrong answers from the point of view of the modeling

1241
01:25:55,170 --> 01:25:59,910
if you really want answers to physical problems so here's a standard linear Leopold then

1242
01:26:00,170 --> 01:26:13,910
finally integrating factor so calculated each of the integral PBX the integrating factor and the

1243
01:26:14,060 --> 01:26:23,590
then multiply evolved and I'm putting this system goes to underline that as many times

1244
01:26:23,590 --> 01:26:29,610
as you a room in your notes on multiply both sides by

1245
01:26:29,990 --> 01:26:37,790
this integrating factor by the EU the integral Pt

1246
01:26:38,090 --> 01:26:49,170
and then integrate OK let's take a simple example suppose we sort of the equation

1247
01:26:49,250 --> 01:26:54,530
x y prime minus y equals 0

1248
01:26:54,590 --> 01:27:01,410
I had excluded execute someone that executed think yet excuse

1249
01:27:02,710 --> 01:27:12,280
OK what's the 1st thing to do output in standard form so said 0 will

1250
01:27:12,280 --> 01:27:16,110
be to write it as y prime minus

1251
01:27:16,830 --> 01:27:26,070
1 over X times Y equals X. squared here to standard error let's do the

1252
01:27:26,070 --> 01:27:31,470
work 1st and then I'll talk about sex our well we now calculate the integrating

1253
01:27:31,470 --> 01:27:32,490
factor so that

1254
01:27:33,590 --> 01:27:37,090
I do it do instead you can integrate

1255
01:27:37,110 --> 01:27:42,700
was 1 of negative 1 over X right that integrates to minus log X so

1256
01:27:42,740 --> 01:27:52,740
the integrating factor is he to integral of the dx so at each of the

1257
01:27:52,750 --> 01:28:02,200
negative log X now in real life that's not the way to leave that was

1258
01:28:02,200 --> 01:28:05,850
the year the negative log X will think of it as you need to log

1259
01:28:05,850 --> 01:28:12,220
X to the minus 1 or in other words it is you log X is

1260
01:28:12,220 --> 01:28:18,330
X so it's x amount so it's 1 over X so the integrating factor is

1261
01:28:18,330 --> 01:28:19,220
1 over X

1262
01:28:23,760 --> 01:28:27,670
multiply both sides by the integrating factor

1263
01:28:27,670 --> 01:28:33,440
o group is the value of the last significant terms and good sentences that just

1264
01:28:33,900 --> 01:28:38,510
to send to deceive non correlated start the people and so then if you make

1265
01:28:38,510 --> 01:28:42,720
an histogram what you get it is not going to should get the flattest because

1266
01:28:42,720 --> 01:28:45,640
you have no no

1267
01:28:46,220 --> 01:28:49,150
no timing which is better than the other

1268
01:28:49,250 --> 01:28:54,060
so it should be completely flat like that after after after once you have to

1269
01:28:54,060 --> 01:28:57,860
get rid of the statistically and then you have something which is going on in

1270
01:28:57,880 --> 01:28:59,190
the in the two

1271
01:28:59,210 --> 01:29:00,900
you will see the

1272
01:29:00,920 --> 01:29:03,880
that's what shall i do not understand which means

1273
01:29:03,900 --> 01:29:09,680
this difference and idea not good

1274
01:29:09,680 --> 01:29:14,140
so that that's one for the for two d and now i want to move

1275
01:29:14,140 --> 01:29:15,990
to the to the ADC

1276
01:29:16,020 --> 01:29:21,980
goes work introduction and then what the difference is that you get it questions what

1277
01:29:21,980 --> 01:29:26,240
are the different types of another candidate converters

1278
01:29:26,290 --> 01:29:30,620
what are the trends in our applications

1279
01:29:30,630 --> 01:29:31,860
so is

1280
01:29:31,880 --> 01:29:34,580
what he's is doing is that he's just

1281
01:29:34,610 --> 01:29:37,630
looking at the

1282
01:29:37,760 --> 01:29:43,290
it that you know i don't seem to use it will just text

1283
01:29:43,310 --> 01:29:45,920
it will give you a given time

1284
01:29:45,960 --> 01:29:50,080
did you seem so we should take thing and seeing what you would get if

1285
01:29:50,080 --> 01:29:52,500
the condition is

1286
01:29:52,530 --> 01:29:56,020
a world know axis

1287
01:29:58,060 --> 01:30:01,190
you can imagine that

1288
01:30:01,200 --> 01:30:04,030
what will be important to understand how

1289
01:30:04,050 --> 01:30:05,970
besides your sampling

1290
01:30:05,980 --> 01:30:10,420
if you sample sale although you get the same results

1291
01:30:10,430 --> 01:30:15,070
and then one is also the older jamaican on the measurement so now if you

1292
01:30:16,080 --> 01:30:19,190
same signals also we have some political i don't know

1293
01:30:19,220 --> 01:30:20,540
you want to make

1294
01:30:20,560 --> 01:30:26,610
delta convention so that it means that you want to go detail value in the

1295
01:30:27,040 --> 01:30:28,300
to convert to

1296
01:30:28,790 --> 01:30:31,130
what you would get out

1297
01:30:31,140 --> 01:30:36,360
so it's been actually what this is doing to be seen from this

1298
01:30:36,380 --> 01:30:40,300
continuous stuff in between

1299
01:30:40,410 --> 01:30:46,950
if you use this that and the quantisation

1300
01:30:46,990 --> 01:30:52,350
the addition of an ADC is relationship between the islands and the number of bits

1301
01:30:52,350 --> 01:30:54,190
so you've got a

1302
01:30:54,200 --> 01:30:57,160
you've got an n bit ADC

1303
01:30:57,170 --> 01:31:01,620
and if you if the maximum amplitude that you can get code with and it

1304
01:31:01,660 --> 01:31:09,230
is is a then the last significant bit the have this value in terms of

1305
01:31:09,260 --> 01:31:14,480
the the maximum divided by two to support and so for instance if you use

1306
01:31:14,480 --> 01:31:16,160
it and a bit ADC

1307
01:31:16,170 --> 01:31:17,810
you have one world

1308
01:31:17,830 --> 01:31:19,310
full scale

1309
01:31:19,520 --> 01:31:23,730
you know solution to this one point nine million people the minimum values that you

1310
01:31:23,730 --> 01:31:25,130
can measure also

1311
01:31:25,130 --> 01:31:28,960
o point about the fulfilment

1312
01:31:29,020 --> 01:31:35,930
the maximum quantisation normally should be hyphenated and be divided by two which we use

1313
01:31:35,940 --> 01:31:38,490
this kind of noise

1314
01:31:38,520 --> 01:31:40,730
so something which

1315
01:31:40,780 --> 01:31:44,600
we should not confuse is what is the solution and what is a dynamic range

1316
01:31:44,600 --> 01:31:49,470
the dynamics and interaction between the minimum and the maximum amplitude to be measured so

1317
01:31:49,950 --> 01:31:55,610
so it can be can be a very large for instance fall

1318
01:31:55,610 --> 01:32:01,520
can i met with generally maintain hcs has to be able to measure signals from

1319
01:32:01,830 --> 01:32:04,220
ten in the

1320
01:32:04,230 --> 01:32:08,030
to two t so that's a lot of sometimes you want to measure also don't

1321
01:32:09,040 --> 01:32:12,460
high precision with large

1322
01:32:12,480 --> 01:32:14,270
in any kind

1323
01:32:14,320 --> 01:32:19,220
in the system so you have completely in system than the

1324
01:32:20,250 --> 01:32:24,980
as dynamic and is related to the number of bits for instance if you have

1325
01:32:24,980 --> 01:32:28,800
a bit ADC u have two hundred fifty six in any change because you have

1326
01:32:28,800 --> 01:32:30,270
two hundred fifty six

1327
01:32:30,280 --> 01:32:32,130
possible values

1328
01:32:32,170 --> 01:32:37,600
now we can see what you you need to to have a large dynamic range

1329
01:32:37,620 --> 01:32:42,960
linear systems cannot be used because

1330
01:32:42,980 --> 01:32:48,030
for instance for for this kind of of dynamic and you would need a twenty

1331
01:32:48,030 --> 01:32:52,300
one bit linear ADC so something that you can get but not in quantity and

1332
01:32:52,310 --> 01:32:56,500
the reason i speed so we cannot use that so what you

1333
01:32:56,520 --> 01:33:00,650
what you do that you introduce some nineteen eighty which is that you will you

1334
01:33:00,650 --> 01:33:03,060
will not just a linear

1335
01:33:03,080 --> 01:33:04,530
compassion but you will

1336
01:33:04,550 --> 01:33:11,670
you do some trick is always an amplifier before the CEO the things

1337
01:33:11,680 --> 01:33:17,460
so what we have is that you should be confusing so for instance when i

1338
01:33:17,460 --> 01:33:19,220
went to a set because

1339
01:33:19,320 --> 01:33:26,000
if i didn't detect a sequence depicting going in hcl and in a lot of

1340
01:33:26,000 --> 01:33:28,450
that year because of unusual

1341
01:33:29,450 --> 01:33:33,730
and and out of of that circuit also and you want to be able to

1342
01:33:34,600 --> 01:33:38,310
good morning i'm going to talk about you when the temperature is low but you

1343
01:33:38,310 --> 01:33:41,960
want to be able to know that the temperature is twenty five degrees c for

1344
01:33:41,960 --> 01:33:45,680
instance we should just take your resolution things that i want to go from twenty

1345
01:33:45,680 --> 01:33:51,040
five degrees c to minus thirty with the same is what you wish for

1346
01:33:51,070 --> 01:33:56,770
when it's called then you will get very large dynamic range and that's difficult expensive

1347
01:33:56,770 --> 01:33:58,580
extent so it's

1348
01:33:58,600 --> 01:34:04,220
when any obligation whether it's twenty five of twenty four games you don't get so

1349
01:34:06,280 --> 01:34:11,720
so that's important not to fire so in terms of the solutions the there is

1350
01:34:11,740 --> 01:34:13,830
kind of between the sampling rate

1351
01:34:13,850 --> 01:34:16,650
and the number of bits that you can so

1352
01:34:16,670 --> 01:34:21,350
so we have the ability this on this absolute go from six to twenty two

1353
01:34:23,020 --> 01:34:24,650
o twenty four

1354
01:34:24,660 --> 01:34:29,530
and this is this which saw how you can get the job done so you

1355
01:34:29,600 --> 01:34:31,440
want to know

1356
01:34:31,450 --> 01:34:37,980
and you see that the higher the frequency the lower the number of bits and

1357
01:34:38,020 --> 01:34:41,680
and and then you be found technology

1358
01:34:41,690 --> 01:34:47,170
i also want to know that in terms of where the ball is going

1359
01:34:47,220 --> 01:34:51,920
is increasing this way so you you can start shooting what

1360
01:34:51,960 --> 01:34:58,000
but i when when force law one but if you wanted to get very fast

1361
01:34:58,000 --> 01:35:00,630
it's it's of what's which is not always

1362
01:35:00,720 --> 01:35:04,560
easy to two hundred that the choice of an ADC we learn is that even

1363
01:35:04,560 --> 01:35:07,760
of course by the application that you have you have to know whether you want

1364
01:35:07,760 --> 01:35:09,060
to be fast

1365
01:35:09,120 --> 01:35:13,330
all extremely precise something in the between

1366
01:35:13,350 --> 01:35:15,020
so it's

1367
01:35:15,060 --> 01:35:16,890
construct the

1368
01:35:16,900 --> 01:35:21,300
ideal things is like that so you have your signal which is just not only

1369
01:35:23,000 --> 01:35:27,120
i mean max and then the ADC we just use

1370
01:35:27,190 --> 01:35:31,320
the is and in fact we have and that some else

1371
01:35:31,400 --> 01:35:35,690
like of sets which can be offset by that you can have integral nonlinearity in

1372
01:35:35,810 --> 01:35:37,470
films and on

1373
01:35:37,490 --> 01:35:43,600
so the idea that the maximum difference between the best linear fit

1374
01:35:43,600 --> 01:35:47,980
that you can do and the and the with the output of the system and

1375
01:35:47,980 --> 01:35:49,480
the idea of

1376
01:35:49,510 --> 01:35:50,860
in particular so

1377
01:35:50,860 --> 01:35:52,960
then there's disease little fluctuations

1378
01:35:53,510 --> 01:35:56,900
like that's so if it albeit with a single length scale

1379
01:35:57,920 --> 01:36:01,820
and it's trying to do that's actually is you observe more data in in in

1380
01:36:01,820 --> 01:36:04,300
the bayesian case peter sollich study this

1381
01:36:05,240 --> 01:36:09,480
you're learning curve will be slower but eventually when you see in the data it

1382
01:36:09,480 --> 01:36:13,150
will come out with not balance scale but the small in scale and it will

1383
01:36:13,880 --> 01:36:17,090
interpolate exactly through the function at the limit of infinite data

1384
01:36:17,800 --> 01:36:21,300
but i rarely get given infinite data size and wanna know what happens

1385
01:36:22,280 --> 01:36:26,010
in the case where i've got less data and i think i'm gonna give you

1386
01:36:26,010 --> 01:36:28,300
any prose but i think the danger is what happens

1387
01:36:28,820 --> 01:36:30,170
is you get effects like this

1388
01:36:30,780 --> 01:36:32,210
these small fluctuations hear

1389
01:36:33,710 --> 01:36:35,300
but you get a global effect like this

1390
01:36:36,360 --> 01:36:40,440
so this problem okay you have to account for the noise if you don't have

1391
01:36:40,440 --> 01:36:42,920
the right to noise than uh it's

1392
01:36:43,490 --> 01:36:45,260
is indicative that your smoothness term

1393
01:36:46,380 --> 01:36:50,940
is wrong you're obviously is only smooth verses to what's going on in the function

1394
01:36:51,630 --> 01:36:52,840
you only see that's law

1395
01:36:53,320 --> 01:36:57,150
it's the it's again this is why i think that the saving grace is normally

1396
01:36:57,150 --> 01:37:00,880
you don't see enough data to expose the flaws in your model you only find

1397
01:37:00,880 --> 01:37:05,240
out that you decided the system is much smoother is in one day where you've

1398
01:37:05,240 --> 01:37:09,260
got a lot of data if you've got sparsely distributed data you don't even discovered

1399
01:37:09,260 --> 01:37:12,080
this flaw in the model and it gives you a nice error bars but as

1400
01:37:12,080 --> 01:37:13,710
you get data very close together

1401
01:37:14,340 --> 01:37:19,820
you get numerical problems the data that you become overly confident about your error bars

1402
01:37:20,050 --> 01:37:22,800
because the real smoothness is larger than that's

1403
01:37:23,320 --> 01:37:27,190
is real smoothness is rougher the map but you think things are infinitely small you

1404
01:37:27,190 --> 01:37:29,110
get at collapsing effect i showed u

1405
01:37:32,480 --> 01:37:33,630
an example i showed

1406
01:37:34,550 --> 01:37:35,400
any other lecture

1407
01:37:36,320 --> 01:37:37,380
that's the end result

1408
01:37:37,940 --> 01:37:40,300
after only observing data hear hear

1409
01:37:41,420 --> 01:37:42,070
and here there

1410
01:37:43,210 --> 01:37:47,440
so the error function that's smoothness was actually correct in this case

1411
01:37:49,090 --> 01:37:52,820
you get this collapsing effect even if the smoothness is in fact correct and your

1412
01:37:52,820 --> 01:37:55,400
error bars are much tighter than they should be so

1413
01:37:56,050 --> 01:37:59,510
gaston processes are a big help but actually one of the problems when you work

1414
01:37:59,510 --> 01:38:02,360
with a bit you just push the problem to another level

1415
01:38:03,170 --> 01:38:07,150
and the worst things the smoothness you can deal with matern covariance is an rational

1416
01:38:07,150 --> 01:38:09,670
quadratic the worst thing is is jumps

1417
01:38:13,980 --> 01:38:16,530
if you need to start putting those in as well so then you need a

1418
01:38:16,530 --> 01:38:18,860
markov jump process on top guassian process

1419
01:38:19,400 --> 01:38:21,340
and they're difficult to deal with so

1420
01:38:22,050 --> 01:38:26,420
as you start adding all the components you need someone what you really think is going on

1421
01:38:27,030 --> 01:38:28,740
the model becomes much more complex

1422
01:38:29,190 --> 01:38:32,240
on and that's a headache for people who do bayesian inference

1423
01:38:44,610 --> 01:38:45,010
on the

1424
01:38:50,480 --> 01:38:51,880
and i think that's okay

1425
01:38:52,670 --> 01:38:57,010
so that's perhaps an area i haven't thought about so much in bayesian learning there's a lot over the

1426
01:38:57,960 --> 01:38:59,380
subjective decision so

1427
01:39:01,670 --> 01:39:02,980
the statistics community

1428
01:39:04,050 --> 01:39:08,720
the bayesians and the frequencies fallen out so much that they don't even go to the same conferences

1429
01:39:10,630 --> 01:39:15,170
so because you have to fall out over something and so the bayesians fallen out

1430
01:39:15,170 --> 01:39:21,610
over something and what they fall and now it is subjective bayesianism an objective bayesianism

1431
01:39:22,400 --> 01:39:23,710
and objective bayesianism

1432
01:39:25,130 --> 01:39:26,860
as opposed to objectionable bayesianism

1433
01:39:28,490 --> 01:39:32,990
objective bayesianism is when you think that there is a universally correct prior for an

1434
01:39:32,990 --> 01:39:38,860
inference problem and that everyone the priors shared subjective bayesianism says well

1435
01:39:40,030 --> 01:39:44,510
these things just about believe so where does the prior come from that's a big problem for bayesian inference

1436
01:39:44,920 --> 01:39:47,340
and subjective bayesian you've this personal

1437
01:39:48,050 --> 01:39:49,110
idea if your prior

1438
01:39:49,880 --> 01:39:52,630
which you put down and that's specific to u

1439
01:39:53,340 --> 01:39:54,130
so it's still

1440
01:39:54,570 --> 01:39:55,670
i would say um

1441
01:39:57,190 --> 01:39:57,880
that's interesting

1442
01:39:58,570 --> 01:40:02,510
i don't know the answer one possible answer is subjective bayesianism is

1443
01:40:04,300 --> 01:40:09,440
pushing everything to be a systemic about all uncertainty ends objective bayesianism is trying to

1444
01:40:09,440 --> 01:40:11,710
be aleatoric about all uncertainty i don't know

1445
01:40:13,170 --> 01:40:14,460
fundamentally uh

1446
01:40:15,650 --> 01:40:18,110
i don't identify worry that much about it

1447
01:40:19,360 --> 01:40:20,460
because in machine learning

1448
01:40:22,490 --> 01:40:25,490
i think we worry often about empirical performance so

1449
01:40:26,630 --> 01:40:29,760
i think the answer to all these problems you know you can spend a lot

1450
01:40:29,780 --> 01:40:33,630
time arguing about it the right answer is they have a community where everyone

1451
01:40:34,130 --> 01:40:39,090
is looking at similar things talking about and showing their empirical performance on data

1452
01:40:39,630 --> 01:40:42,990
so it's an addict and i think it's it's an interesting question to which i

1453
01:40:42,990 --> 01:40:46,940
don't know the answer but perhaps the answer for machine learning is um

1454
01:40:48,690 --> 01:40:51,800
who cares let's see who wins on them this data

1455
01:40:53,340 --> 01:40:55,800
or whatever all in reinforcement learning you know

1456
01:40:56,260 --> 01:40:58,720
i think there's lots about from questions there let's see if you can get a

1457
01:40:58,720 --> 01:40:59,820
robot to make a cup of tea

1458
01:41:02,260 --> 01:41:03,190
and on

1459
01:41:03,360 --> 01:41:03,780
on the

1460
01:41:05,570 --> 01:41:06,550
right i mean

1461
01:41:08,960 --> 01:41:09,940
and the

1462
01:41:11,110 --> 01:41:12,340
corresponding of more

1463
01:41:12,670 --> 01:41:13,780
all the people

1464
01:41:15,300 --> 01:41:16,090
what is the

1465
01:41:17,440 --> 01:41:18,920
so you're not these

1466
01:41:21,030 --> 01:41:22,800
you ones

1467
01:41:24,240 --> 01:41:26,960
are you know just like right

1468
01:41:28,860 --> 01:41:31,840
well it's interesting to they actually make an i i d e

1469
01:41:32,480 --> 01:41:34,510
empirical risk and was an interesting point

1470
01:41:36,610 --> 01:41:38,760
where the idea because what i was claiming

1471
01:41:39,360 --> 01:41:42,380
and the you know maybe this reveals a hole in what i was claiming is

1472
01:41:42,380 --> 01:41:45,800
that cisco learning theory people don't make an assumption about the noise

1473
01:41:46,860 --> 01:41:50,550
um so in our case it's funny to then say that making an idea assumption

1474
01:41:50,570 --> 01:41:54,860
but they must be making some assumption in order write the expected loss down must

1475
01:41:54,860 --> 01:41:57,070
be where the idea assumptions coming in the

1476
01:41:57,670 --> 01:41:58,880
potentially the loss is called

1477
01:42:03,400 --> 01:42:03,860
you know

1478
01:42:04,960 --> 01:42:05,710
and on

1479
01:42:07,550 --> 01:42:08,780
and on

1480
01:42:15,150 --> 01:42:17,630
yes in fact that's a good point yes i think one thing that is very

1481
01:42:17,630 --> 01:42:23,070
powerful it sometimes it's so we just wrote aom recent review papers for foundations and

1482
01:42:24,630 --> 01:42:30,630
which was looking at multiple output covariance functions which some people call multitask learning structured

1483
01:42:30,630 --> 01:42:34,860
and it's got million wonderful night but it's using kernel methods and it's used in

1484
01:42:36,400 --> 01:42:41,570
i'm guessing processes and myself and my student mauricio alvarez and lorenzo and i should

1485
01:42:41,570 --> 01:42:43,400
say mercy and lawrence that most of the work

1486
01:42:43,900 --> 01:42:45,150
work hard to pull together

1487
01:42:45,530 --> 01:42:51,590
what the statistical learning theory viewer these multiple output covariance functions is and the bayesian

1488
01:42:51,590 --> 01:42:56,490
view and what was introduced that's because what philips driving at is that often clear

1489
01:42:56,510 --> 01:43:01,610
for bayesian how you expand your model to say the right probabilistic things so

1490
01:43:02,300 --> 01:43:06,460
i don't like the term multi-task learning because from probabilistic point of view it's just

1491
01:43:06,880 --> 01:43:11,190
a more complex model and in general if i wanna learn across different tasks i

1492
01:43:11,190 --> 01:43:12,960
it's an minus one

1493
01:43:13,070 --> 01:43:15,070
which is that term there

1494
01:43:15,070 --> 01:43:20,690
times q of w one which is this term here times the gas intensity

1495
01:43:20,710 --> 01:43:24,090
that's the gas in density for w one

1496
01:43:24,090 --> 01:43:30,020
which is one over square root of two pi is the normalized invariant but has

1497
01:43:30,020 --> 01:43:32,020
a means of alpha sort

1498
01:43:32,270 --> 01:43:33,810
so what's this

1499
01:43:33,820 --> 01:43:36,130
OK well the next thing we have to do

1500
01:43:36,150 --> 01:43:39,190
it's either fiddle around like mad

1501
01:43:39,210 --> 01:43:41,730
or look at this

1502
01:43:41,750 --> 01:43:45,710
if you remember one of the things that you did i think in the previous

1503
01:43:45,710 --> 01:43:47,750
homework you passed in

1504
01:43:48,150 --> 01:43:51,520
you found the band on q

1505
01:43:54,400 --> 01:43:55,820
looks like this

1506
01:44:05,670 --> 01:44:10,290
that's just the tail of the gaussians distribution tail of the gas distribution

1507
01:44:10,340 --> 01:44:12,270
is upper bounded by this

1508
01:44:12,290 --> 01:44:13,880
for w one

1509
01:44:13,880 --> 01:44:18,230
greater than or equal to zero is upper bounded by a bunch of other things

1510
01:44:18,940 --> 01:44:21,070
you find this problem

1511
01:44:21,320 --> 01:44:23,520
the other bounds are tighter

1512
01:44:23,540 --> 01:44:27,840
this is the most useful bound to the gas in distribution areas

1513
01:44:27,860 --> 01:44:33,270
because it works for all w w greater than or equal to zero

1514
01:44:33,320 --> 01:44:37,570
and it's exactly w one is equal to zero because you're disintegrating over half of

1515
01:44:37,590 --> 01:44:40,110
the gaussians density

1516
01:44:40,110 --> 01:44:43,360
it is convenient and easy to work with

1517
01:44:43,600 --> 01:44:46,050
but but what that says

1518
01:44:46,070 --> 01:44:50,380
is the QR w one one w one is

1519
01:44:50,400 --> 01:44:56,690
anything greater than or equal to zero looks very much like the gas density

1520
01:44:56,710 --> 01:45:00,360
so the thing that you are doing here is taking one guassian density

1521
01:45:00,380 --> 01:45:04,000
and you're multiplying it by another calcium density

1522
01:45:04,000 --> 01:45:08,020
and the one guassian density

1523
01:45:08,150 --> 01:45:11,420
sitting here looking like this

1524
01:45:11,420 --> 01:45:14,670
some scale factor on it it's zero

1525
01:45:14,690 --> 01:45:16,610
the other jealousy and density

1526
01:45:16,630 --> 01:45:19,210
is here that alpha

1527
01:45:19,210 --> 01:45:21,520
it was awful wasn't there was a camera

1528
01:45:21,540 --> 01:45:22,750
thank keep my

1529
01:45:22,750 --> 01:45:25,500
gamma alpha straight

1530
01:45:25,520 --> 01:45:31,230
OK and it looks like this

1531
01:45:31,230 --> 01:45:34,650
if you take the product of two gas intensities

1532
01:45:34,650 --> 01:45:35,690
the same

1533
01:45:35,690 --> 01:45:38,320
amplitude and everything in the same variance

1534
01:45:38,340 --> 01:45:40,710
what do you wind up with

1535
01:45:40,770 --> 01:45:44,360
what you can go through complete the square you can sort of see from looking

1536
01:45:44,360 --> 01:45:46,500
at this from the symmetry of it

1537
01:45:46,550 --> 01:45:49,400
the what you're going to get is the gaussians

1538
01:45:49,520 --> 01:45:51,880
from there

1539
01:45:51,880 --> 01:45:53,250
over two

1540
01:45:53,290 --> 01:45:57,360
OK so so these two things when you multiply them

1541
01:45:57,380 --> 01:46:02,440
look like this

1542
01:46:02,440 --> 01:46:05,500
this has the same variances these two things to

1543
01:46:05,520 --> 01:46:10,050
it is centered on alpha over

1544
01:46:10,070 --> 01:46:14,540
if you want to take the fourier transform and multiply the fourier transform we take

1545
01:46:14,540 --> 01:46:17,650
the fourier transform of the gas you get the gaussians

1546
01:46:17,650 --> 01:46:22,340
and then so here we're here we're multiplying

1547
01:46:22,400 --> 01:46:27,020
up there in fourier transform space you're convolving and we combine the gas in with

1548
01:46:27,020 --> 01:46:31,650
the gas and you get gaussians so when you multiply calcium by carcinogenic get as

1549
01:46:31,650 --> 01:46:35,310
we do anything to account for you get to gaussians OK

1550
01:46:37,550 --> 01:46:39,460
so this thing

1551
01:46:39,480 --> 01:46:41,090
and if you don't believe me just

1552
01:46:41,110 --> 01:46:44,710
just actually take these two exponent simply square

1553
01:46:44,730 --> 01:46:48,980
and see what you get so the mean is going to be alpha over two

1554
01:46:49,000 --> 01:46:52,150
so here you have the term

1555
01:46:52,190 --> 01:46:55,690
which is one tale of the gas distribution

1556
01:46:55,710 --> 01:46:59,270
senator alpha minus gamma

1557
01:46:59,320 --> 01:47:00,880
here you have another one

1558
01:47:00,920 --> 01:47:04,610
centered at alpha over two

1559
01:47:04,630 --> 01:47:06,920
when you see these two terms

1560
01:47:06,940 --> 01:47:11,230
something clicks in your mind and says that sometimes this term is going to be

1561
01:47:11,230 --> 01:47:17,110
the significantterms sometimes this term is going to be significant terms and it depends on

1562
01:47:17,110 --> 01:47:18,460
whether gamma

1563
01:47:18,500 --> 01:47:20,050
alpha minus gamma

1564
01:47:20,090 --> 01:47:23,190
is greater than or less than alpha over to

1565
01:47:23,210 --> 01:47:29,540
so you can sort of see what's going to happen right white

1566
01:47:31,170 --> 01:47:34,020
i hope you can see what's going to happen right away because i'm not going

1567
01:47:34,020 --> 01:47:36,900
to talk to you anymore of this and you can you can look at the

1568
01:47:36,900 --> 01:47:38,270
notes to find

1569
01:47:38,380 --> 01:47:43,440
to find the details but you know sort of see what's happening because because you

1570
01:47:44,250 --> 01:47:46,130
the sum of two terms

1571
01:47:46,150 --> 01:47:50,270
we're trying to upper bound this we don't we don't much care about factors of

1572
01:47:50,290 --> 01:47:52,860
two or fact is the square root of two pi

1573
01:47:52,900 --> 01:47:54,250
or anything

1574
01:47:54,270 --> 01:47:57,420
we're trying to look at when this goes to zero

1575
01:47:57,440 --> 01:48:01,940
when you make and bigger and bigger and when it doesn't go to zero

1576
01:48:01,940 --> 01:48:05,150
so when we do this the probability of error is going to be less than

1577
01:48:05,150 --> 01:48:08,840
or equal to either of these two terms here these two

1578
01:48:08,860 --> 01:48:11,130
alternative so we spoke about

1579
01:48:11,130 --> 01:48:15,670
namely when alpha over two is less than or equal to gamma we get this

1580
01:48:15,710 --> 01:48:19,210
one of over two is greater than gamma we get this

1581
01:48:19,270 --> 01:48:22,810
and this involves using gamma in the right way

1582
01:48:22,880 --> 01:48:25,000
so the union bound

1583
01:48:25,020 --> 01:48:27,210
is about equal to one

1584
01:48:27,980 --> 01:48:30,150
that gamma

1585
01:48:30,210 --> 01:48:33,590
OK well that doesn't tell us anything so we said okay

1586
01:48:33,590 --> 01:48:36,000
what we're really interested in here

1587
01:48:36,020 --> 01:48:39,270
it is as an is getting bigger and bigger

1588
01:48:39,270 --> 01:48:41,400
we're spending a certain amount of energy

1589
01:48:41,420 --> 01:48:43,380
per input bit

1590
01:48:43,400 --> 01:48:47,860
and that's what we're interested in is for shannon's theorem is concerned how much energy

1591
01:48:47,860 --> 01:48:51,230
you spend to send the bits through this channel

1592
01:48:51,270 --> 01:48:55,000
and this gives you the answer that question

1593
01:48:55,020 --> 01:48:57,460
he led log will be

1594
01:48:57,480 --> 01:49:01,790
m is the size of the signal alphabet so b is the number of features

1595
01:49:04,820 --> 01:49:10,840
namely the energy per bit is just the total energy in these orthogonal waveforms divided

1596
01:49:10,840 --> 01:49:11,940
by the way

1597
01:49:11,960 --> 01:49:17,710
so that that's the energy per bit OK substitute these two things into that equation

1598
01:49:17,710 --> 01:49:19,460
and what you get

1599
01:49:19,480 --> 01:49:21,730
as these two different terms

1600
01:49:21,750 --> 01:49:24,380
you to the minus p times this

1601
01:49:25,500 --> 01:49:27,130
and a to the a minus b

1602
01:49:27,130 --> 01:49:29,150
times this chuck

1603
01:49:29,190 --> 01:49:31,320
what happens when n gets the

1604
01:49:31,340 --> 01:49:34,540
when n gets big holding a be fixed

1605
01:49:34,540 --> 01:49:35,920
so the game is

1606
01:49:35,940 --> 01:49:37,130
we're going to keep

1607
01:49:37,130 --> 01:49:38,500
doubling our

1608
01:49:38,520 --> 01:49:40,270
orthogonal set

1609
01:49:40,270 --> 01:49:42,730
being able to transmit one more bit

1610
01:49:42,730 --> 01:49:46,750
and every time we transmit one more bit we get a little more energy

1611
01:49:46,770 --> 01:49:51,380
but we can use to transmit that one extra bit so we use an orthogonal

1612
01:49:51,380 --> 01:49:55,710
set but using a little more energy and that are orthogonal set

1613
01:49:56,340 --> 01:49:58,290
what this says

1614
01:49:58,290 --> 01:50:01,540
is that the probability of error

1615
01:50:01,570 --> 01:50:04,320
goes down exponentially with the

1616
01:50:05,340 --> 01:50:07,380
either one of these terms

1617
01:50:07,400 --> 01:50:08,670
are possible

1618
01:50:08,670 --> 01:50:09,500
and this

1619
01:50:09,750 --> 01:50:12,460
and looking at the biggest of these terms tells you

1620
01:50:12,520 --> 01:50:14,440
which one you want to look at

1621
01:50:14,460 --> 01:50:19,360
so any time that be over four zero is less than or equal to log

1622
01:50:19,360 --> 01:50:20,920
so you put

1623
01:50:20,930 --> 01:50:27,550
to discriminate one with the highest threshold which is the value above which you want

1624
01:50:27,550 --> 01:50:31,390
to fire and another one with a very low threshold so so that it will

1625
01:50:31,420 --> 01:50:33,740
it will give the as

1626
01:50:33,820 --> 01:50:38,420
formation very close to the to the yourself so you see here

1627
01:50:38,430 --> 01:50:43,470
what will happen on the signal is that if if it

1628
01:50:44,300 --> 01:50:49,040
it's faster or slower you are you are making the timing threshold other less was

1629
01:50:49,040 --> 01:50:52,800
he was about this time he found between these two signal is is as low

1630
01:50:52,800 --> 01:50:56,050
as possible so the point that that you cannot go

1631
01:50:56,070 --> 01:50:59,760
two groups to deal with the we the rule spatial

1632
01:50:59,790 --> 01:51:01,240
i have no problem

1633
01:51:02,850 --> 01:51:08,080
these are the benefits signals which are of the form so the amplitude times of

1634
01:51:09,810 --> 01:51:14,490
if you if you apply a formula like that which is that you take a

1635
01:51:14,490 --> 01:51:18,460
fraction of the signal and you compare it with this

1636
01:51:18,470 --> 01:51:20,350
the same signal dealer

1637
01:51:20,360 --> 01:51:24,240
and you will find that this formula for this expression is

1638
01:51:24,250 --> 01:51:26,170
it is

1639
01:51:26,200 --> 01:51:29,080
it is it is going is new

1640
01:51:29,120 --> 01:51:34,080
it is your for a time which is independent of it because of course have

1641
01:51:34,200 --> 01:51:36,740
a huge impact on both sides

1642
01:51:36,740 --> 01:51:38,490
so we apply

1643
01:51:38,500 --> 01:51:41,400
to make the following so we we take the

1644
01:51:41,480 --> 01:51:47,510
we take we have the input signals and we just take a fraction of the

1645
01:51:47,510 --> 01:51:50,880
input signal and then we apply this thing which is that we take a fraction

1646
01:51:50,880 --> 01:51:55,790
of the signal added always attracted to

1647
01:51:55,860 --> 01:51:59,580
the signal delayed and then you can this for any shape you when you have

1648
01:51:59,580 --> 01:52:03,970
an negative signals and because the only goes up and the answers your causing is

1649
01:52:03,970 --> 01:52:07,190
independent of time so you can

1650
01:52:07,210 --> 01:52:11,350
get very good results with with that

1651
01:52:11,360 --> 01:52:12,730
and the way

1652
01:52:12,850 --> 01:52:15,560
don't is again you have to

1653
01:52:15,980 --> 01:52:18,120
to combat

1654
01:52:18,120 --> 01:52:22,140
one which is for the i spatial that you want to signal to exceed and

1655
01:52:22,140 --> 01:52:24,290
that's all the time in the u

1656
01:52:24,320 --> 01:52:26,620
on the one side input delayed

1657
01:52:26,630 --> 01:52:28,820
and the other input the

1658
01:52:28,860 --> 01:52:31,860
the fraction of those who were signals

1659
01:52:31,940 --> 01:52:33,970
equal you will get

1660
01:52:34,020 --> 01:52:37,080
a change in the output

1661
01:52:37,100 --> 01:52:41,510
and this was used by signal will be phase

1662
01:52:41,520 --> 01:52:44,750
with that but it should be independent

1663
01:52:46,350 --> 01:52:52,870
the opportunity inputting and you can get quite good performance without which is basically no

1664
01:52:52,890 --> 01:52:57,100
time will come when you are you when you have seen going from fifty one

1665
01:52:57,100 --> 01:53:02,370
to one hundred again the limitations are coming from a limitation in the second part

1666
01:53:02,370 --> 01:53:07,370
the diocese of that you have to compose it follows that but the main thing

1667
01:53:07,370 --> 01:53:12,240
is to know that you cannot get real zero crossing where you have to be

1668
01:53:12,240 --> 01:53:16,420
just to know always this thing is always oscillating

1669
01:53:16,450 --> 01:53:21,000
and of course the simulated probability to that so this effective

1670
01:53:21,010 --> 01:53:22,870
mister albert but

1671
01:53:22,990 --> 01:53:25,170
so it's a

1672
01:53:27,350 --> 01:53:29,990
having if a is independent of the amplitude

1673
01:53:29,990 --> 01:53:38,360
then how do we make time so one first met method is to make it

1674
01:53:38,360 --> 01:53:41,750
time to amplitude converter so far that you just

1675
01:53:41,770 --> 01:53:44,260
but you flop so when was

1676
01:53:44,280 --> 01:53:48,200
you would make that you want to measure the time between start and stuff

1677
01:53:50,600 --> 01:53:52,990
fire on this floor

1678
01:53:53,000 --> 01:53:56,540
and from the stock felicity and

1679
01:53:56,600 --> 01:54:01,640
as the number of this flow fire which is between the prime start and stop

1680
01:54:01,640 --> 01:54:06,720
you could switch on the rich deposits account with constant around

1681
01:54:06,850 --> 01:54:10,070
so if will get voltage

1682
01:54:10,130 --> 01:54:11,880
on the capacitor which is

1683
01:54:11,890 --> 01:54:17,390
just proportional to the time he found between start and stop

1684
01:54:17,400 --> 01:54:19,140
just then

1685
01:54:20,120 --> 01:54:24,230
and opened fire with some again if you wish anything and we

1686
01:54:24,240 --> 01:54:27,380
you have to have i don't see because you don't want to have the capacity

1687
01:54:27,470 --> 01:54:28,770
to be discharged

1688
01:54:28,810 --> 01:54:31,480
and you will to energy

1689
01:54:31,750 --> 01:54:36,950
kind you can you can get a very good resolution because

1690
01:54:36,970 --> 01:54:40,370
there was originally just dictated by the

1691
01:54:40,390 --> 01:54:42,220
as a

1692
01:54:42,230 --> 01:54:46,740
according to the capacity of the values according to the council six thousand so you

1693
01:54:46,740 --> 01:54:50,600
can can be a few people so one solution

1694
01:54:50,610 --> 01:54:56,580
a way of making them to digital conversion which was heavily used in the past

1695
01:54:56,580 --> 01:55:00,590
is the we send it could argued also what you do is again

1696
01:55:00,600 --> 01:55:03,860
you you have the time to

1697
01:55:03,880 --> 01:55:06,740
to digital converter that we've seen so here

1698
01:55:06,760 --> 01:55:09,650
in addition to the two of them

1699
01:55:09,660 --> 01:55:13,340
councils which is the low values and one

1700
01:55:13,350 --> 01:55:18,620
which is able to discharge the capacitance and you will discharge the capacitance when you

1701
01:55:18,620 --> 01:55:20,670
start conversion

1702
01:55:20,700 --> 01:55:26,910
so what you get the output is you this is the time between the spartans

1703
01:55:26,910 --> 01:55:32,390
document devoted to the capacitance which is going down and up to

1704
01:55:32,530 --> 01:55:36,080
and and then when you start the actually we stopped

1705
01:55:36,100 --> 01:55:38,250
MTV's capacitance with

1706
01:55:38,260 --> 01:55:43,620
this course council you will get all going down but slower

1707
01:55:43,630 --> 01:55:45,920
and then what you do

1708
01:55:45,970 --> 01:55:47,090
is that you

1709
01:55:47,100 --> 01:55:50,480
you look at all on how much time it takes to go

1710
01:55:51,660 --> 01:55:53,900
the value to the also was

1711
01:55:53,920 --> 01:55:54,960
which in

1712
01:55:55,340 --> 01:56:02,900
combined here and then when you to see all you just start stop shouting the

1713
01:56:06,220 --> 01:56:07,970
and and

1714
01:56:07,980 --> 01:56:11,020
this scenario is the duration of the

1715
01:56:11,030 --> 01:56:14,950
child and you just call to number of clubs during this time since then you've


1
00:00:00,000 --> 00:00:04,240
of that have best benefit cost ratio

2
00:00:05,560 --> 00:00:06,760
so this is the idea

3
00:00:08,470 --> 00:00:13,250
this also won't work so optimizing this can also fail arbitrarily badly and here i

4
00:00:13,250 --> 00:00:13,920
have an example

5
00:00:14,550 --> 00:00:18,240
we can try to go through right so if we are given some budget and

6
00:00:18,240 --> 00:00:22,530
we consider just locations right on one location has cost epsilon the other one has

7
00:00:22,530 --> 00:00:23,580
the patient b

8
00:00:23,630 --> 00:00:28,850
and we only have one cascade one of breaking news network right four one four

9
00:00:29,430 --> 00:00:33,810
four placing a sensor that this one will get two epsilon award and first place

10
00:00:33,810 --> 00:00:39,130
in the second location to get the reward we now if we compute the cost-benefit

11
00:00:39,130 --> 00:00:44,460
ratios we get so the first one the concepts we have we have reworked two

12
00:00:44,460 --> 00:00:45,880
and the second one

13
00:00:45,890 --> 00:00:51,360
we have this cost benefit cost ratio of one so we select sensor one

14
00:00:51,370 --> 00:00:54,110
and then we won't be able to afford sensitive to

15
00:00:54,130 --> 00:00:57,890
and now we so we get reward to have some instead of instead of being

16
00:00:57,890 --> 00:01:02,010
now we send exception to zero and we get arbitrarily bad or we got an

17
00:01:02,010 --> 00:01:06,970
an arbitrary away from this optimal what we could get the fit in our model

18
00:01:07,620 --> 00:01:10,900
this is again so it seems like a bad news but the question is now

19
00:01:11,160 --> 00:01:13,340
what if we take best of both solutions

20
00:01:13,380 --> 00:01:15,960
and so this is what we do

21
00:01:15,990 --> 00:01:20,390
the idea is that we have resort music we had like two pairs greedy algorithm

22
00:01:20,450 --> 00:01:25,760
solve two separate problems in the first we obtain one solution that just use the

23
00:01:25,760 --> 00:01:31,260
benefit cost greedy the one i just introduced and then the second instance separately around

24
00:01:31,260 --> 00:01:35,010
the unit cost greedy so we just we optimize as there is no cost to

25
00:01:35,010 --> 00:01:41,690
the census but at end we the solution whatever we exhausted our much OK so

26
00:01:41,690 --> 00:01:45,510
define solution just the best of both and what is good

27
00:01:46,110 --> 00:01:50,640
or what they can ask now is how far is this from unknown or optimal

28
00:01:50,640 --> 00:01:52,730
solution that we cannot compute right

29
00:01:54,300 --> 00:01:59,080
what they show is that if one uses this type of algorithm we are we

30
00:01:59,080 --> 00:02:04,000
are we lose one-half right so we have one half whatever had before away

31
00:02:04,010 --> 00:02:07,780
from from documents so this is this is this is very good news so right

32
00:02:07,780 --> 00:02:11,050
now we cannot guarantee that we can't fail to badly

33
00:02:11,060 --> 00:02:15,070
OK so this is the first part of the good news and the second part

34
00:02:15,070 --> 00:02:18,050
of the good news about that you know is how to scale up this how

35
00:02:18,050 --> 00:02:19,480
to make it go faster

36
00:02:20,970 --> 00:02:25,320
before i do that i just want to do something i want to believe the

37
00:02:25,320 --> 00:02:29,730
talk about something else that i won't go into much so this traditional mound there's

38
00:02:29,730 --> 00:02:34,020
us how far from optimal is we would going to be before even we see

39
00:02:34,020 --> 00:02:38,920
the data around got right so you before and we know that there is at

40
00:02:38,920 --> 00:02:42,780
most thirty three sixty thirty six percent away

41
00:02:42,810 --> 00:02:48,240
from from this optimal solutions we don't know any questions can we do better and

42
00:02:48,240 --> 00:02:50,840
in the paper we have this to we show that we can get a much

43
00:02:50,840 --> 00:02:54,540
better estimate how far is our solution from the optimal solution

44
00:02:54,560 --> 00:02:59,680
and the idea that the reason for the intuition that we exploit is that this

45
00:02:59,690 --> 00:03:04,190
marginal gains are getting smaller and smaller with the placement size so given this you

46
00:03:04,190 --> 00:03:08,690
can sort the first you can estimate how how good could the best possible solution

47
00:03:08,690 --> 00:03:12,510
to this gives you in practice much much tighter bounds

48
00:03:12,520 --> 00:03:18,030
what i mean by this is decreasing marginal gains is the following because this will

49
00:03:18,030 --> 00:03:24,770
also help us in scaling up the god so this someone says submodularity property guarantees

50
00:03:24,770 --> 00:03:29,150
as that this marginal benefits will decrease with the solution size and this means that

51
00:03:29,150 --> 00:03:33,780
if we have a particular if we are considering placing particular stands me and this

52
00:03:33,780 --> 00:03:38,170
is the reward people get sorted now

53
00:03:38,180 --> 00:03:42,170
if we decide to place some other sensor and then again going to consider

54
00:03:42,460 --> 00:03:46,240
says again what will happen is that this one can only get smaller

55
00:03:46,250 --> 00:03:50,620
and this is this is known as a lazy evaluations and this is what we

56
00:03:50,660 --> 00:03:55,660
explore exploit OK so here is here is what we do right so again we

57
00:03:55,660 --> 00:03:59,040
have the same the the same network in the same year considering placing some set

58
00:03:59,040 --> 00:04:03,510
of sensors and what we do is again the first going to evaluate rewards for

59
00:04:03,510 --> 00:04:06,910
all the sense that we would get and we still degree right so we pick

60
00:04:06,920 --> 00:04:11,210
the best one in place what we do now is

61
00:04:11,210 --> 00:04:12,960
this this the rewards are now

62
00:04:12,970 --> 00:04:17,820
invalid but what we do is we sort of our senses by by this rewards

63
00:04:17,860 --> 00:04:22,550
or gained from previous timestep and we will go and evaluated evaluate them in this

64
00:04:22,550 --> 00:04:23,370
order so

65
00:04:23,400 --> 00:04:27,920
we go and evaluated the and again sort

66
00:04:27,920 --> 00:04:28,750
we go

67
00:04:28,780 --> 00:04:30,030
we evaluate the

68
00:04:30,050 --> 00:04:32,620
now our new values reward

69
00:04:33,250 --> 00:04:36,970
this is this new melody what is larger than the reward of the from the

70
00:04:36,970 --> 00:04:40,510
previous step and we know that if you would go to evaluate it

71
00:04:40,570 --> 00:04:44,440
the this area could only showing this means that we already have the best got

72
00:04:44,450 --> 00:04:48,290
so we can go and place b again and this will now be right so

73
00:04:48,290 --> 00:04:51,920
this may be saved a lot we have to go and i know you evaluate

74
00:04:51,920 --> 00:04:56,740
all the marginal gains but at every step we only keeping evaluating them until we

75
00:04:56,740 --> 00:05:01,010
should someone who who is invalid and instead has what is the what you already

76
00:05:01,650 --> 00:05:05,750
OK in this way we can we can do this much much faster and show

77
00:05:05,780 --> 00:05:07,200
some timings late

78
00:05:07,220 --> 00:05:10,820
so OK this was the idea and now

79
00:05:11,150 --> 00:05:14,050
i could go and show some experimental results so

80
00:05:14,060 --> 00:05:16,140
it must be

81
00:05:16,150 --> 00:05:19,220
i would say

82
00:05:19,240 --> 00:05:19,780
we have

83
00:05:19,800 --> 00:05:27,960
estimate how couples can become a hub can be estimated that was to come

84
00:05:27,960 --> 00:05:31,420
that's that's a different so that's a different question so one question is how to

85
00:05:31,420 --> 00:05:35,040
do this faster and the other questions how to how so i go around this

86
00:05:35,040 --> 00:05:38,580
algorithm i know i don't get optimal can i get some kind of idea how

87
00:05:38,580 --> 00:05:40,780
far am i from this

88
00:05:40,810 --> 00:05:43,330
something that i can't even compute

89
00:05:43,350 --> 00:05:48,050
and then we also have a way to do that gives much better estimate how

90
00:05:48,050 --> 00:05:54,300
far away are you from from optimal than what was previously previously not because i

91
00:05:54,300 --> 00:05:58,650
did not know i i don't want to go too much into

92
00:06:00,120 --> 00:06:04,690
the i mean the the deal old deal the result basically even without looking at

93
00:06:04,690 --> 00:06:08,110
the data they get the guarantee what we do is we look at the data

94
00:06:08,110 --> 00:06:11,560
and this gives much better estimate in practice OK

95
00:06:11,580 --> 00:06:17,890
OK so now i briefly about the experiments so we have two case studies one

96
00:06:17,890 --> 00:06:21,950
is on basically it's all have for both of you have been need to find

97
00:06:21,950 --> 00:06:25,650
the data set where we have real propagation data right so you don't need to

98
00:06:25,650 --> 00:06:29,710
assume any monetary can just go and measure how the news propagate through the network

99
00:06:29,710 --> 00:06:33,320
and here we have a blog network where we have we were growing books blocks

100
00:06:33,320 --> 00:06:37,250
for one year and then we were identify how does information spread through the blogosphere

101
00:06:37,250 --> 00:06:41,150
right some blogger says something and on other refer to it and this spreads and

102
00:06:41,150 --> 00:06:42,200
we are asking

103
00:06:42,240 --> 00:06:45,420
which which blogs should be in the second

104
00:06:45,470 --> 00:06:47,690
cases this water distribution network

105
00:06:47,710 --> 00:06:53,070
well we have again a real city water distribution network and some some way to

106
00:06:53,070 --> 00:06:55,140
to compute how would the

107
00:06:55,180 --> 00:06:58,080
however the disease spread through the network

108
00:06:58,150 --> 00:07:02,390
and again the question is as i said where to place sensors to detect disease

109
00:07:02,390 --> 00:07:03,740
outbreaks quicker

110
00:07:03,740 --> 00:07:06,200
so first of all setting the context clearly

111
00:07:06,220 --> 00:07:12,200
statistical learning theory is something i need to put in context with other attempts to

112
00:07:12,200 --> 00:07:18,270
understand the system is so i spend most of this lecture looking at that

113
00:07:20,280 --> 00:07:24,730
then move into the basic

114
00:07:24,750 --> 00:07:31,930
pac ideas probably approximately correct i think what the acronym stands for

115
00:07:32,290 --> 00:07:34,120
and the proof

116
00:07:34,200 --> 00:07:38,290
and again here i will be looking at some of the detailed proof because i

117
00:07:38,290 --> 00:07:39,130
don't want to

118
00:07:39,180 --> 00:07:42,530
just to give you a series of results i want to try and show you

119
00:07:42,530 --> 00:07:44,020
how those results

120
00:07:44,040 --> 00:07:49,310
i arrived at where the proofs are instructive in themselves so it is my intention

121
00:07:49,310 --> 00:07:54,150
to try and look approves and see how they work this the key ideas how

122
00:07:54,150 --> 00:07:55,020
they work

123
00:07:55,030 --> 00:07:56,600
so i'll be looking

124
00:07:56,610 --> 00:07:59,550
at those little bit more detail

125
00:08:00,710 --> 00:08:02,000
that will lead us to

126
00:08:02,020 --> 00:08:05,130
the sort of the point at which

127
00:08:05,160 --> 00:08:10,340
if you like learning theory was that when suddenly support vector machines broke on the

128
00:08:10,340 --> 00:08:16,370
scene and were performing extremely well and the theory that was at that point developed

129
00:08:16,370 --> 00:08:17,480
was completely

130
00:08:17,940 --> 00:08:20,780
unable to explain their performance

131
00:08:20,790 --> 00:08:24,250
and i think that was a critical moment where if you like theory and practice

132
00:08:24,250 --> 00:08:25,260
were completely

133
00:08:26,980 --> 00:08:30,500
with each other and i think that was very

134
00:08:30,750 --> 00:08:33,770
challenged the theory community to try and

135
00:08:33,790 --> 00:08:38,240
if you like agree that theory to match practice and that's what i'll talk about

136
00:08:38,270 --> 00:08:43,360
next which is this idea of real valued function classes and the margin

137
00:08:44,590 --> 00:08:45,560
that will

138
00:08:45,570 --> 00:08:49,500
hopefully be the point i reach the end of today so that the for lectures

139
00:08:49,500 --> 00:08:50,360
and then

140
00:08:50,370 --> 00:08:53,550
starting tomorrow will look at more modern

141
00:08:56,860 --> 00:09:00,860
two in statistical learning theory concentration and stability

142
00:09:00,880 --> 00:09:03,450
and then rademacher complexity

143
00:09:03,850 --> 00:09:05,270
and its main theorem

144
00:09:05,290 --> 00:09:08,720
and on the some applications again i would hope to cover

145
00:09:08,930 --> 00:09:11,740
the next slide guitar

146
00:09:11,750 --> 00:09:14,160
sort of eighteen of

147
00:09:14,170 --> 00:09:18,510
what i would hope consensus is just giving a re capitulation some extent of what

148
00:09:18,510 --> 00:09:21,080
i said at the beginning that some thoughts on why

149
00:09:21,100 --> 00:09:22,810
fearing what it can do for you

150
00:09:24,510 --> 00:09:28,160
the basic techniques with some deference to history but not a strict

151
00:09:28,180 --> 00:09:29,830
historical sequence

152
00:09:29,850 --> 00:09:34,860
insights into the proof techniques and statistical learning approaches

153
00:09:35,870 --> 00:09:38,880
tomorrow complete proof of the SVM

154
00:09:38,910 --> 00:09:43,590
found using rather rademacher approach i think somehow taking you through the whole thing you

155
00:09:43,590 --> 00:09:49,670
know it's like climbing everest something outside but it can give you an idea of

156
00:09:49,670 --> 00:09:50,540
what the

157
00:09:50,590 --> 00:09:53,920
different components that are needed in the proof

158
00:09:54,070 --> 00:09:58,310
OK so that is what i'm hoping to do what i want to include it

159
00:09:58,320 --> 00:10:01,030
is the most general results by any stretch

160
00:10:01,080 --> 00:10:06,380
i certainly don't i certainly won't include a complete history

161
00:10:08,060 --> 00:10:11,460
i will be looking at an analysis of bayesian inference

162
00:10:12,180 --> 00:10:16,110
typically that is

163
00:10:16,150 --> 00:10:20,190
you outside statistical learning theory until recently when

164
00:10:20,210 --> 00:10:23,180
the development of the PAC bayes

165
00:10:24,330 --> 00:10:26,820
which sort of links the two

166
00:10:26,860 --> 00:10:28,950
but i came will be covering that

167
00:10:29,140 --> 00:10:33,610
and i live in this case is giving the advanced section of this course

168
00:10:33,630 --> 00:10:36,450
i will be looking at the PAC bayes results

169
00:10:36,500 --> 00:10:42,780
and also had this idea of local rademacher complexity so developing on from the

170
00:10:42,790 --> 00:10:46,390
rademacher stuff all be talking about tomorrow

171
00:10:46,400 --> 00:10:50,850
OK so hopefully seen i would welcome you to

172
00:10:51,330 --> 00:10:55,870
ask questions and gain give feedback about speed

173
00:10:56,540 --> 00:10:59,290
and appropriateness of what i'm saying

174
00:10:59,310 --> 00:11:01,900
so please just try your hand

175
00:11:01,920 --> 00:11:05,630
you are trying to stop him

176
00:11:07,310 --> 00:11:10,530
so i'm going to start with an attempt to

177
00:11:11,740 --> 00:11:14,720
by the way is point that i can usefully

178
00:11:14,880 --> 00:11:16,700
just that see

179
00:11:16,700 --> 00:11:18,590
closer to some

180
00:11:18,600 --> 00:11:22,340
mediterranean area they have problems with force for a lot of force have

181
00:11:22,800 --> 00:11:24,270
this appears because of that

182
00:11:24,300 --> 00:11:26,790
in one way to do this is to use the

183
00:11:26,810 --> 00:11:28,620
sensor networks

184
00:11:28,630 --> 00:11:32,320
to deploy them throughout the forest or some critical area

185
00:11:32,330 --> 00:11:33,850
and detect

186
00:11:33,940 --> 00:11:35,660
five when it's really starts

187
00:11:35,700 --> 00:11:37,470
so that you can react quickly

188
00:11:37,490 --> 00:11:43,830
you will you will lose probably a small portion of forest but not everything

189
00:11:43,870 --> 00:11:48,180
and this is something that because there was a nice them what one or three

190
00:11:48,190 --> 00:11:49,630
previous workshops with the

191
00:11:49,640 --> 00:11:53,950
all the trees and grass and all the sensors and we had even by almost

192
00:11:53,950 --> 00:11:55,340
started the

193
00:11:55,350 --> 00:11:59,610
so that's the so there's of proof of concept is to show that OK yes

194
00:11:59,610 --> 00:12:04,610
you can use of this technology is not a commercial product but if somebody

195
00:12:04,630 --> 00:12:07,360
is really keen and see business case can

196
00:12:07,410 --> 00:12:10,460
take that improve it and make it

197
00:12:10,470 --> 00:12:13,050
commercial stuff

198
00:12:13,130 --> 00:12:16,270
smart road monitoring that's a big area

199
00:12:16,290 --> 00:12:19,790
so if you enable all the cars to interact with each other and talk to

200
00:12:19,790 --> 00:12:23,050
each other so you can get information from the car in front of you what's

201
00:12:23,050 --> 00:12:26,190
happening so you can stop before

202
00:12:26,200 --> 00:12:31,220
you would stop otherwise or like just coming this morning there with myself and

203
00:12:31,230 --> 00:12:33,760
one woman scratch my mica

204
00:12:33,790 --> 00:12:38,190
because she was trying to squeeze between me and the end of the road and

205
00:12:38,190 --> 00:12:39,370
it was not possible

206
00:12:39,390 --> 00:12:44,370
so if you had some of these sensors maybe she would have stopped before going

207
00:12:44,380 --> 00:12:47,540
luckily enough the scratches on this small so it's to be problem

208
00:12:49,820 --> 00:12:51,350
then some of the

209
00:12:51,360 --> 00:12:57,130
health care scenarios of fitness areas where people can where some of the ECG or

210
00:12:57,130 --> 00:12:59,590
blood pressure or even

211
00:12:59,610 --> 00:13:03,470
some sensors that can analyse your so at hand based on that they can do

212
00:13:03,470 --> 00:13:08,210
certain things and conclude what's wrong with you are what you should do

213
00:13:08,450 --> 00:13:13,710
and then you can use it while running doctor can monitor ECG and if you

214
00:13:13,710 --> 00:13:15,570
are preparing to run the marathon

215
00:13:15,580 --> 00:13:18,710
and actually to five kilometres your heart rate goes

216
00:13:18,720 --> 00:13:24,220
twenty two hundred fifty or something and you get some heart disorder then they will

217
00:13:24,220 --> 00:13:25,080
say OK

218
00:13:25,090 --> 00:13:28,640
forget about what monotone go play chess or something

219
00:13:29,660 --> 00:13:33,210
if you ever find there say OK just continue this way or this way and

220
00:13:33,210 --> 00:13:38,330
then you will eventually you will be able to run

221
00:13:38,590 --> 00:13:45,050
one of the colleges of always interesting thing and waste management is another application that's

222
00:13:45,050 --> 00:13:45,970
of interest

223
00:13:46,080 --> 00:13:49,340
but you can monitor all these waste dumps

224
00:13:49,720 --> 00:13:51,390
and to monitor the

225
00:13:51,420 --> 00:13:56,070
temperature inside them and to some of the chemicals that or some chemical processes happening

226
00:13:56,590 --> 00:13:59,540
and then you can react and maybe

227
00:13:59,630 --> 00:14:04,470
and do something about that if you notice that some chemical reactions will happen that

228
00:14:04,470 --> 00:14:08,930
can cause some environmental pollution

229
00:14:09,940 --> 00:14:13,970
more and more applications these are just a few examples and

230
00:14:14,000 --> 00:14:18,460
we can i can probably stand here and talk about these are application for whole

231
00:14:19,040 --> 00:14:21,660
you want examples complete list

232
00:14:21,680 --> 00:14:26,090
so that's wireless sensor networks and some of the applications

233
00:14:26,100 --> 00:14:30,140
and then when talking about what it says metrics you talk about

234
00:14:30,200 --> 00:14:35,470
isolated system so you have to waste management application i put my says there

235
00:14:35,490 --> 00:14:39,710
and in the summer in my house i monitor from IPC what's happening there

236
00:14:39,820 --> 00:14:44,470
or i put some usages as on me and my doctor sees what's happening with

237
00:14:45,390 --> 00:14:46,230
so that's

238
00:14:46,260 --> 00:14:47,020
kind of

239
00:14:47,050 --> 00:14:48,560
isolated systems

240
00:14:48,570 --> 00:14:50,080
with the internet of things

241
00:14:50,090 --> 00:14:55,440
the idea is to blend all these publications are all the systems so yes i

242
00:14:55,440 --> 00:14:57,160
put those sensors in the waste

243
00:14:57,210 --> 00:15:02,880
for the military ways but i want everybody to be able to discover those sensors

244
00:15:02,990 --> 00:15:07,390
and to use that information or maybe some other purpose completely

245
00:15:07,420 --> 00:15:11,120
maybe they have to pay me for using those sensors maybe they will have to

246
00:15:11,120 --> 00:15:14,460
ask me first for some credentials yes

247
00:15:15,920 --> 00:15:22,260
the idea is that you connect all these different devices smart devices that are called

248
00:15:22,290 --> 00:15:28,330
and make them accessible by anybody who has a proper authorization to use them

249
00:15:28,340 --> 00:15:34,080
and then to start building application services on top of that

250
00:15:34,090 --> 00:15:39,960
so x has this fifty billion connections by twenty twenty vision saying that it's OK

251
00:15:39,960 --> 00:15:42,690
not just sensors and actuators but there will be

252
00:15:42,700 --> 00:15:44,660
fifty billion

253
00:15:44,680 --> 00:15:50,630
connections to all sorts of different machines including coffee machines and refrigerators

254
00:15:51,320 --> 00:15:53,860
temperature sensors and everything else

255
00:15:53,920 --> 00:15:56,980
and the number of machines

256
00:15:56,990 --> 00:15:58,710
is much higher than the

257
00:15:58,720 --> 00:16:03,190
number of people living so obviously from the

258
00:16:03,190 --> 00:16:07,550
and you need to check every path from here to here to see whether that

259
00:16:07,550 --> 00:16:14,560
he's blocked

260
00:16:14,580 --> 00:16:28,850
is separated out

261
00:16:54,740 --> 00:16:57,160
yes true

262
00:17:00,150 --> 00:17:03,400
it's head had so these will have a problem with

263
00:17:04,310 --> 00:17:07,820
if we observed these and these and you need to ask whether these

264
00:17:07,840 --> 00:17:09,280
two and the separation

265
00:17:10,270 --> 00:17:13,360
we need to study every path from here to here

266
00:17:14,560 --> 00:17:16,630
so this is one thing

267
00:17:16,660 --> 00:17:18,650
this page is blocked

268
00:17:18,670 --> 00:17:20,340
by x five

269
00:17:20,390 --> 00:17:23,990
because it's head to tail node which is absurd

270
00:17:23,990 --> 00:17:26,950
and the first condition is met

271
00:17:27,000 --> 00:17:29,370
now this pattern here

272
00:17:29,430 --> 00:17:33,420
it's another possible path from x three two x six

273
00:17:34,300 --> 00:17:37,040
but this fact is also blocked

274
00:17:37,050 --> 00:17:39,580
because x one is so

275
00:17:39,640 --> 00:17:42,340
and this is the tail to tail nodes so is also

276
00:17:42,340 --> 00:17:45,490
the first condition

277
00:17:45,510 --> 00:17:49,820
now the remaining pair is this here

278
00:17:49,870 --> 00:17:52,810
is this bad block

279
00:17:52,810 --> 00:17:54,520
this but not working

280
00:17:54,530 --> 00:17:57,360
because x y is in the conditioning set

281
00:17:57,410 --> 00:17:59,540
but its head to head

282
00:17:59,570 --> 00:18:02,080
so when i observed x five

283
00:18:02,090 --> 00:18:06,430
i created connection between x two and x three remember the example i gave you

284
00:18:06,540 --> 00:18:10,320
if i see a child with brown eyes i know that both parents can not

285
00:18:10,320 --> 00:18:11,540
be able one

286
00:18:11,560 --> 00:18:15,780
right so if i hope so this child immediately create some

287
00:18:15,830 --> 00:18:18,520
dependency between these viable

288
00:18:18,750 --> 00:18:21,280
this that becomes law

289
00:18:21,370 --> 00:18:26,940
so x three and x six are not the separate when x one and x

290
00:18:26,940 --> 00:18:30,040
five ir are sort

291
00:18:38,900 --> 00:18:43,830
he is

292
00:18:43,840 --> 00:18:45,270
so again

293
00:18:45,440 --> 00:18:50,260
the previous example OK up

294
00:19:00,830 --> 00:19:04,400
a block at that

295
00:19:04,430 --> 00:19:06,910
note that the point is that

296
00:19:06,950 --> 00:19:10,000
this pattern is is not one

297
00:19:10,080 --> 00:19:12,800
this smart also

298
00:19:13,130 --> 00:19:14,650
it's correct because

299
00:19:14,740 --> 00:19:17,580
these head-to-head nodes

300
00:19:17,670 --> 00:19:19,590
is not so

301
00:19:19,600 --> 00:19:23,980
if there is one was not observed respect would be block

302
00:19:24,020 --> 00:19:26,170
but he is absurd

303
00:19:26,230 --> 00:19:30,080
defining a blog that

304
00:19:32,190 --> 00:19:37,950
containing none of these two affirmations one of them

305
00:19:38,040 --> 00:19:40,160
one of them is to be true

306
00:19:41,090 --> 00:19:43,540
containing all

307
00:19:43,590 --> 00:19:52,980
so basically in this case

308
00:19:52,990 --> 00:19:56,810
only the first holes in this case is only the first hold

309
00:19:56,830 --> 00:20:00,300
in this case non hold

310
00:20:02,800 --> 00:20:08,610
it's not the separate i mean this concept a bit tricky but it's essential y

311
00:20:08,630 --> 00:20:11,550
because the concept of the separation

312
00:20:11,640 --> 00:20:13,880
turns out to be exactly

313
00:20:13,900 --> 00:20:15,640
the concept of

314
00:20:16,720 --> 00:20:18,920
independent in

315
00:20:18,940 --> 00:20:21,570
directed graph

316
00:20:21,570 --> 00:20:22,970
we will see

317
00:20:22,980 --> 00:20:26,040
so basically

318
00:20:26,100 --> 00:20:27,810
we will see some

319
00:20:30,610 --> 00:20:33,800
it's interesting results which is basically

320
00:20:34,470 --> 00:20:36,550
the problem we have is written

321
00:20:36,560 --> 00:20:40,130
that's all i will need to read write it here

322
00:20:42,610 --> 00:20:46,160
i have the following result

323
00:20:46,200 --> 00:20:48,440
this is really important

324
00:20:48,490 --> 00:20:52,840
this is the first of the two most important slides

325
00:20:52,890 --> 00:20:54,560
of the course

326
00:20:58,370 --> 00:21:02,280
the first is that there is that you can prove which is the following

327
00:21:02,320 --> 00:21:05,100
factorisation implies conditional independence

328
00:21:05,120 --> 00:21:06,290
so basically

329
00:21:06,300 --> 00:21:07,950
the attention to detail

330
00:21:08,000 --> 00:21:11,390
you have a probability distribution that factorises

331
00:21:11,490 --> 00:21:16,580
according to a directed acyclic graph so it's not bayesian network probability distribution

332
00:21:16,590 --> 00:21:18,580
factorizes according to

333
00:21:19,540 --> 00:21:21,120
children given parents

334
00:21:24,780 --> 00:21:25,840
and if you have

335
00:21:25,890 --> 00:21:31,740
a b and c which are disjoint subsets of nodes such that a is d

336
00:21:31,740 --> 00:21:35,650
separated from b by c

337
00:21:35,660 --> 00:21:40,250
then that distribution satisfies the conditional independence a

338
00:21:40,290 --> 00:21:43,000
independent given c

339
00:21:43,100 --> 00:21:45,190
look at what this is saying

340
00:21:45,250 --> 00:21:47,800
this is connecting a concert from

341
00:21:47,850 --> 00:21:50,380
pure graph theoretical concept

342
00:21:50,430 --> 00:21:53,350
with the concept of conditional independence

343
00:21:53,430 --> 00:21:57,480
offer probability distribution OK

344
00:21:57,480 --> 00:22:00,590
but this will get counted twice

345
00:22:00,620 --> 00:22:02,620
in the feature vector

346
00:22:02,630 --> 00:22:03,590
so we went

347
00:22:03,610 --> 00:22:12,610
good good fun at the moment we're not talking and talking

348
00:22:12,890 --> 00:22:16,400
and this method is designed for translational invariance

349
00:22:16,440 --> 00:22:19,590
i'll come in in the second to deal with the fact that the car might

350
00:22:19,590 --> 00:22:24,660
be rotated so the the moment there is this problem you mentioning because when the

351
00:22:24,660 --> 00:22:29,600
model is learned one is recognised there is only one orientation

352
00:22:30,690 --> 00:22:32,520
it will find this over here you say

353
00:22:32,530 --> 00:22:36,690
they were only vote on these two positions for the moment because both tracking and

354
00:22:38,060 --> 00:22:41,570
assume no rotation

355
00:22:43,120 --> 00:22:50,650
yes what this is the last week of

356
00:22:53,670 --> 00:22:57,270
this is not much publicity using its is awaiting on

357
00:22:57,270 --> 00:22:58,490
this point

358
00:22:58,500 --> 00:23:03,350
that's the whole point in the next

359
00:23:03,410 --> 00:23:09,860
but i don't think it's so much geometric smearing though i think about this myself

360
00:23:09,860 --> 00:23:13,180
but i think that these these links from

361
00:23:13,570 --> 00:23:15,370
models are

362
00:23:15,380 --> 00:23:21,880
a fictional very that in your voting

363
00:23:21,930 --> 00:23:26,400
three to four

364
00:23:26,550 --> 00:23:30,520
it's just that i mean there's is some gathering

365
00:23:30,530 --> 00:23:32,960
here you can see that

366
00:23:35,650 --> 00:23:40,270
this region here which lies inside as well as like adaptive half so there is

367
00:23:40,270 --> 00:23:44,290
some smearing that's allowed because you you're saying all of these contribute some maximum and

368
00:23:44,290 --> 00:23:48,010
that decide that the smearing depends on the size of the

369
00:23:48,540 --> 00:23:51,270
square that you you you cluster

370
00:23:51,310 --> 00:23:52,290
astro very

371
00:23:52,520 --> 00:23:54,240
you you count votes over

372
00:23:55,530 --> 00:24:04,140
the system parameters and that goes in the opposite model or not

373
00:24:04,160 --> 00:24:07,160
OK so i'm going move on to one of model which is in one of

374
00:24:07,160 --> 00:24:09,370
the method which is in this class

375
00:24:09,390 --> 00:24:13,090
which is a policy norman method in two thousand two

376
00:24:13,090 --> 00:24:14,640
now this is actually

377
00:24:14,650 --> 00:24:18,760
it was designed for segmentation but more given as a recognition

378
00:24:19,950 --> 00:24:24,770
apologies for six like this differs slightly in the way the parts i got some

379
00:24:24,770 --> 00:24:29,790
of the details but for small they start off with segmented images in fact they

380
00:24:29,790 --> 00:24:34,100
have an alpha mask for each image they know what's the foreground background

381
00:24:34,170 --> 00:24:36,480
and they learn

382
00:24:36,480 --> 00:24:41,550
these what they call fragments which are variable size rectangles from both the the

383
00:24:41,570 --> 00:24:44,500
training positive examples and from the negative examples

384
00:24:44,550 --> 00:24:48,360
and they decide which fragments are important using mutual information

385
00:24:50,360 --> 00:24:53,050
this is slightly different and it is still the same idea is in the end

386
00:24:53,050 --> 00:24:58,340
you and you have a set of segments which should capture the shape of the

387
00:24:58,350 --> 00:25:00,360
the object of interest

388
00:25:01,780 --> 00:25:07,390
the parts which occur in two interesting and their goal is to cover the objects

389
00:25:07,390 --> 00:25:08,350
that's that's there

390
00:25:11,490 --> 00:25:14,780
he will be some fragments they might learn from this particular training image

391
00:25:14,830 --> 00:25:19,670
and then when they come to want to recognise horses and the test image

392
00:25:19,730 --> 00:25:22,340
what these fragments try to cover

393
00:25:23,030 --> 00:25:25,830
image with these fragments OK so when they come

394
00:25:25,840 --> 00:25:29,640
the new image they don't know the segmentation but have alpha mask

395
00:25:29,700 --> 00:25:34,480
so what i want to to assemble horse at all these fragments as they go

396
00:25:34,490 --> 00:25:36,960
so you get something like this

397
00:25:36,980 --> 00:25:37,860
OK so small

398
00:25:38,750 --> 00:25:40,140
assembling a jigsaw

399
00:25:40,160 --> 00:25:42,500
that's an ocean structure

400
00:25:42,510 --> 00:25:47,590
so if you have a horse you stick on these various parts and when you

401
00:25:47,620 --> 00:25:49,060
sticking on part

402
00:25:49,060 --> 00:25:54,750
it has to be against and sticking on done by cross correlation must cross correlation

403
00:25:54,790 --> 00:25:58,230
so you have to some agreement with the texture some agreement with the

404
00:25:58,270 --> 00:25:59,590
foreground background

405
00:25:59,600 --> 00:26:01,190
so it the part just sticking on

406
00:26:01,210 --> 00:26:04,350
you know the segmentation of the image you don't

407
00:26:06,960 --> 00:26:09,880
you end up all these parts being stuck on then

408
00:26:10,320 --> 00:26:15,370
you have a constraint for whether or not the overlap of parts consistent so basically

409
00:26:15,430 --> 00:26:19,240
if you used if you sticking on two parts the overlap

410
00:26:20,080 --> 00:26:22,050
in terms of background and foreground must be

411
00:26:22,060 --> 00:26:27,490
consistent and that's the only structure constraints going on here the two parts on both

412
00:26:27,490 --> 00:26:29,310
of them have to agree on

413
00:26:29,900 --> 00:26:34,120
background and foreground segmentation and that's all very very loose constraint and then you end

414
00:26:34,120 --> 00:26:36,240
up with a covering like this

415
00:26:36,240 --> 00:26:40,590
now in our implementations of this what we found is that this this constraint is

416
00:26:40,590 --> 00:26:42,030
just too loose

417
00:26:42,050 --> 00:26:45,250
is no explicit geometry justice

418
00:26:45,310 --> 00:26:51,490
overlap constraint and in terms of the allies than the policy norman described a greedy

419
00:26:51,490 --> 00:26:56,070
algorithm the weight if this is the first of all i find the best fit

420
00:26:56,070 --> 00:26:57,880
in part to the image

421
00:26:58,240 --> 00:27:01,290
the best we can just means normalized cross correlation so it can be the best

422
00:27:01,290 --> 00:27:05,650
fitting part is the background and in the first part is on the background there's

423
00:27:05,650 --> 00:27:08,600
no way of recovering there's no backtracking in the algorithm

424
00:27:08,610 --> 00:27:12,090
so we found this was the weakest of the three methods

425
00:27:12,210 --> 00:27:17,230
OK so long as about this method pieces is a very different way of doing

426
00:27:17,230 --> 00:27:19,280
the geometry

427
00:27:19,290 --> 00:27:23,060
any questions on this method

428
00:27:23,110 --> 00:27:30,320
so this is a comparison for this part talk where parts are found first

429
00:27:30,830 --> 00:27:37,160
these two methods she'll graph cluster from positive examples but one is a has a

430
00:27:37,160 --> 00:27:39,180
slightly more sophisticated

431
00:27:39,200 --> 00:27:43,670
he's mutual information to decide what the fragments use interest points

432
00:27:44,710 --> 00:27:46,300
in terms of the structure

433
00:27:46,540 --> 00:27:49,000
we've seen maybe she'll have simple voting on

434
00:27:50,290 --> 00:27:58,550
and a lot more traditional classifier on very sparse vectors and then both norman this

435
00:27:58,550 --> 00:28:00,110
jigsaw like overlap

436
00:28:03,070 --> 00:28:05,790
so what we've seen so far

437
00:28:07,210 --> 00:28:11,610
dealing with recognizing class insist on the image translation only

438
00:28:11,630 --> 00:28:14,750
all the examples we seem to have had an implicit structure model to be made

439
00:28:16,330 --> 00:28:18,450
we have no articulation so far

440
00:28:18,480 --> 00:28:20,790
and the only dealt with one aspect

441
00:28:20,800 --> 00:28:23,330
of the object side or rear of cars for example

442
00:28:23,340 --> 00:28:26,380
now coming to the question about orientation

443
00:28:26,460 --> 00:28:31,590
if we want to recognise cars rotated or even scaled we have to an exhaustive

444
00:28:32,590 --> 00:28:34,620
and this is very familiar to people who do

445
00:28:34,650 --> 00:28:36,640
face detection

446
00:28:36,660 --> 00:28:41,790
so the idea is going over sliding windows into the active roster sliding window

447
00:28:41,800 --> 00:28:45,430
each of these positions you want to decide if there's a face inside

448
00:28:45,450 --> 00:28:46,580
this window

449
00:28:46,910 --> 00:28:49,930
it's a convex faces a certain scale

450
00:28:49,990 --> 00:28:56,180
so here smaller scale and then to deal with scale changes explicitly the images resizing

451
00:28:56,180 --> 00:28:58,870
the pyramid and the same the same size window

452
00:28:58,890 --> 00:29:01,620
moved over that's how scales we have

453
00:29:01,680 --> 00:29:06,840
likewise the orientation have to rotate the image and then run the same

454
00:29:06,840 --> 00:29:11,050
so in the training is one orientation in the testing you can rotate the image

455
00:29:11,660 --> 00:29:15,000
a set amount of each time we run out with them because that's how

456
00:29:16,490 --> 00:29:18,200
and scaling

457
00:29:18,260 --> 00:29:22,620
is dealt with in this class about them

458
00:29:24,670 --> 00:29:25,930
any more questions on this

459
00:29:25,940 --> 00:29:30,490
so then i'm going to go on to

460
00:29:31,710 --> 00:29:32,950
the which

461
00:29:33,420 --> 00:29:37,910
instead of the parts being the most important this structure term is the most important

462
00:29:37,910 --> 00:29:41,030
that's really what counts

463
00:29:41,110 --> 00:29:45,480
and what you see here the two new ideas one is that the structure what

464
00:29:45,480 --> 00:29:49,230
i'm Xifing Yan from IBM t j watson research center and the today

465
00:29:49,230 --> 00:29:54,770
Karsten from university of cambridge and i are going to talk about a graph mining

466
00:29:54,770 --> 00:29:59,020
we will talk about graph mining from two perspectives graph

467
00:29:59,020 --> 00:30:02,760
pattern mining from data mining perspective and graph

468
00:30:05,700 --> 00:30:07,790
a machine learning perspective

469
00:30:07,830 --> 00:30:11,510
and i will talk about the first part of graph pattern mining and Karsten

470
00:30:11,510 --> 00:30:14,330
will talk about the second part of graph kernels

471
00:30:14,630 --> 00:30:18,500
between these two parts we will have fifteen minutes to break

472
00:30:18,590 --> 00:30:24,110
between three fifteen to three thirty

473
00:30:24,150 --> 00:30:27,160
so as we know that graphs and graphs applications

474
00:30:27,210 --> 00:30:32,410
become more and more important and popular in both scientific and commercial domains actually every

475
00:30:32,410 --> 00:30:35,440
day we experienced a lot of graph applications

476
00:30:35,510 --> 00:30:38,800
here i show you some examples - graph examples

477
00:30:38,820 --> 00:30:45,090
so the first figure is very commonly used in bioinformatics gene coexpression networks

478
00:30:45,160 --> 00:30:47,760
derived from microarray datasets

479
00:30:47,820 --> 00:30:50,700
the second is chemical compound dataset

480
00:30:50,700 --> 00:30:52,530
protein structure

481
00:30:52,530 --> 00:30:58,920
programme for all graphs extracted from program traces and a very popular one

482
00:30:58,970 --> 00:31:01,000
social networks

483
00:31:01,010 --> 00:31:06,140
so given this kind of graphs, there are many interesting research problems we can

484
00:31:07,140 --> 00:31:12,030
for example suppose we are given a set of chemical compounds can we find some

485
00:31:12,060 --> 00:31:14,450
interesting hiddden inside

486
00:31:14,670 --> 00:31:16,530
protein chemicals

487
00:31:16,540 --> 00:31:21,170
chemical components super-structures that are active to some virus

488
00:31:21,420 --> 00:31:25,090
if we are given two sets of graphs we might ask the following question can

489
00:31:25,090 --> 00:31:30,370
we view the graph classification model which can tells us the difference between these two

490
00:31:30,370 --> 00:31:33,040
sets of graphs

491
00:31:33,060 --> 00:31:38,670
so i will examine these questions from pattern discovery perspective

492
00:31:38,890 --> 00:31:44,280
mainly focus on graph pattern mining so i will talk about frequent graph pattern mining

493
00:31:44,340 --> 00:31:47,650
pattern summarization optimal pattern mining

494
00:31:47,700 --> 00:31:51,140
and graph patten with constraints and approximate graph pattern

495
00:31:51,170 --> 00:31:55,340
and the later i will show you the application of these graph patterns in a specific

496
00:31:56,480 --> 00:32:02,620
scenario - graph classification i will show you how to use these patterns to build high quality graph classifiers

497
00:32:04,350 --> 00:32:05,650
and then later i will

498
00:32:05,660 --> 00:32:08,560
discuss a a little bit about the graph compression

499
00:32:08,650 --> 00:32:12,990
however i have to mention this by no means this tutorial is comprehensive about graph

500
00:32:12,990 --> 00:32:15,740
mining because there are so many interesting topics

501
00:32:15,750 --> 00:32:17,090
and the some of

502
00:32:17,090 --> 00:32:21,340
these topics are very hot recently for example how to model graphs

503
00:32:21,410 --> 00:32:24,380
how to analyse graphs dynamics

504
00:32:24,400 --> 00:32:27,500
how to do the social network analysis how to graph

505
00:32:27,550 --> 00:32:30,310
visualisation summarisation and et cetera

506
00:32:30,350 --> 00:32:34,090
so if you are interested in you are very welcome to join session tomorrow on

507
00:32:34,090 --> 00:32:41,090
monday afternoon we will have a session titled graph mining

508
00:32:41,100 --> 00:32:45,840
so the solutions to the previous question i mentioned the for example graph pattern mining,  graph

509
00:32:45,840 --> 00:32:50,370
classification actually can find many many applications for example of

510
00:32:50,370 --> 00:32:55,460
mine  about chemical structures to find those active chemical fragments

511
00:32:56,070 --> 00:33:01,990
mine those protein interaction networks to find those biologically conserved networks across

512
00:33:01,990 --> 00:33:03,750
different species

513
00:33:03,820 --> 00:33:07,340
find the functional modules in gene coexpression networks

514
00:33:07,350 --> 00:33:11,430
do the program flow analysis to find software bugs

515
00:33:11,500 --> 00:33:17,280
and and the using graph analysis to find the intrusion network fingerprints i will

516
00:33:17,300 --> 00:33:22,440
use show you two examples in the end of the talk

517
00:33:22,500 --> 00:33:27,220
so when we talk about graph pattern mining there are actually two typical settings

518
00:33:27,240 --> 00:33:30,060
in graph pattern mining in the first setting

519
00:33:30,280 --> 00:33:33,870
one is given one set of graphs without any label

520
00:33:34,930 --> 00:33:36,990
each circle represents class

521
00:33:37,120 --> 00:33:40,410
in this setting we only given one set of graphs without any level of this

522
00:33:40,410 --> 00:33:42,840
is very typical application scenario

523
00:33:42,940 --> 00:33:44,550
in the second setting

524
00:33:44,750 --> 00:33:51,310
one is given two sets of graphs always supportive label and the negative labels

525
00:33:51,310 --> 00:33:55,720
for example we can do a set of four experiments to test the activity of

526
00:33:55,720 --> 00:34:02,140
chemical compounds with respect to the activity to HIV virus for example and we

527
00:34:02,140 --> 00:34:03,990
can put those those active

528
00:34:04,000 --> 00:34:07,300
chemical compounds into the supportive set

529
00:34:07,310 --> 00:34:11,500
and as those inactive chemical compounds to the negative set

530
00:34:11,540 --> 00:34:15,290
so immediately it becomes very challenging and interesting problems

531
00:34:15,480 --> 00:34:19,950
can we find some unique chemical substructures

532
00:34:20,000 --> 00:34:24,510
which can tell us the difference between these two sets of graphs

533
00:34:24,540 --> 00:34:29,850
actually we can combine these two settings into one setting for example if we are

534
00:34:29,850 --> 00:34:38,700
according to Parliament jobs actually couldn't because faulty acquitted you we have a lot of

535
00:34:38,700 --> 00:34:44,970
sources of some of all that done jumped to the judiciary but for the birth

536
00:34:44,970 --> 00:34:49,120
of the acquittals you also we should very feisty situation

537
00:34:49,890 --> 00:34:52,970
if we get a simplified because

538
00:34:53,050 --> 00:35:00,100
the predicted all we use it for much of not to projects he said

539
00:35:00,160 --> 00:35:07,410
To defined an extended to the high don't feel to call that of various central

540
00:35:07,470 --> 00:35:12,660
also find expression in his race and and you can't Wyoming matchup in 5 couldn't

541
00:35:13,390 --> 00:35:20,180
on the conveyor less than 10 iterations so are so you

542
00:35:20,200 --> 00:35:27,530
you initiate your process we are happy to reopened judiciary Petraeus is only applies iterations

543
00:35:27,550 --> 00:35:33,300
of the contest advice on also on mattresses which are given by you want to

544
00:35:33,320 --> 00:35:38,280
be here and so you could of sales that falls advice on bills this exclusion

545
00:35:38,280 --> 00:35:44,550
was equipped with you also fund equipped you want be used action

546
00:35:47,820 --> 00:35:53,490
he's asked said the agency will also sell a lot of time John will not

547
00:35:53,550 --> 00:36:00,680
be equipped with a wall push mattress to position of the marathon aren't what these

548
00:36:00,680 --> 00:36:07,510
areas venture that is due to the new Getty section Camacho space very stable so

549
00:36:07,510 --> 00:36:14,970
you can initiate your of film back and you with the addition of a mattress

550
00:36:14,970 --> 00:36:18,800
on the between congestion due to the barracks and

551
00:36:19,030 --> 00:36:25,350
but we have not complexity of the program so we have objected to don't walk

552
00:36:25,350 --> 00:36:31,760
songs on the program because we have no but we have noted took steps to

553
00:36:31,760 --> 00:36:38,930
also mattresses sold means fool between the contest between going to do with the defeat

554
00:36:38,990 --> 00:36:45,970
meant proceeds by our ambition beautifully but was a vital don't really know how to

555
00:36:45,970 --> 00:36:52,740
to the truth is we have only exist for both the Web easier wanted to

556
00:36:52,760 --> 00:36:59,800
know if he is also we would like to fool to Congress to adopt a

557
00:36:59,800 --> 00:37:09,260
pizza Kamyshin attitude shipment removed can make some inquiries the classical fully equation so this

558
00:37:09,260 --> 00:37:14,530
is just a good for ya questioning include appeared in space just too is defined

559
00:37:14,530 --> 00:37:21,910
by the abductions versions of some of the going regret faltered in space mission retired

560
00:37:22,070 --> 00:37:23,910
so that actions

561
00:37:23,930 --> 00:37:31,920
UK Yukon factors rights as a 48 equation basis situation contracted that he did all

562
00:37:31,920 --> 00:37:42,050
of you use which is in fact adequately community which is increase 1 on the

563
00:37:42,660 --> 00:37:48,780
the end use 1 of the great debate was his are being fall 48 integration

564
00:37:48,780 --> 00:37:51,090
of the Allied victory

565
00:37:51,090 --> 00:37:55,280
and the Indonesian further 21 hours the PGA in space

566
00:37:55,300 --> 00:38:03,470
on the inside of the fuels the guidance for the fleeting decommissioning is flat fee

567
00:38:03,470 --> 00:38:06,240
free medical burdened with Phil

568
00:38:06,280 --> 00:38:13,300
the fact that you could define a gang of 4 unique equation falters face-off with

569
00:38:13,410 --> 00:38:21,740
big red of where you could upset association has been replaced by biting factories pollution

570
00:38:21,740 --> 00:38:29,700
are already exists this equation this feelings exactly as an extension of the slope of

571
00:38:29,700 --> 00:38:39,080
the fleet equipped that we have great players adequately Camino afforded by the community but

572
00:38:39,080 --> 00:38:45,180
his expression is exactly the same 6 which only ups to lose the geometric mean

573
00:38:45,180 --> 00:38:49,680
of the cheapest to neighbor would mattress

574
00:38:49,950 --> 00:38:56,030
and it could be extended for years Rifkind neutral when the suspects it is no

575
00:38:56,030 --> 00:38:59,390
longer changes that did

576
00:38:59,410 --> 00:39:06,680
Was there is some somewhat done by caliber of also on and he needs to

577
00:39:06,680 --> 00:39:13,280
win to explain his approach on so we have extended flop but don't receive than

578
00:39:13,280 --> 00:39:23,910
a complex of Toronto's models so seasons of complexity model is very simple and when

579
00:39:23,910 --> 00:39:28,300
you have a time series in fact you get is to make each point by

580
00:39:28,720 --> 00:39:34,640
the pass with a longer or with novel which is defined by the although also

581
00:39:34,640 --> 00:39:41,760
the old competitors modems facilities everywhere in signal was seen diesel elated to eventual possibilities

582
00:39:41,760 --> 00:39:48,030
of social bomb the pond it is it being pushed by the oddity seasons the

583
00:39:48,050 --> 00:39:50,200
mode maximum for peace

584
00:39:50,200 --> 00:39:54,760
its effects would be next and the social construction would be next and you guys

585
00:39:54,760 --> 00:39:57,880
alluded to all these and in your answers to my questions

586
00:39:57,910 --> 00:40:03,190
so first you might say well food is something that's found in nature

587
00:40:03,200 --> 00:40:08,110
that humans have evolved to eat foods that are found in nature they're out there

588
00:40:08,110 --> 00:40:11,790
you can gather them you can hunt them you can fish them or you can

589
00:40:11,790 --> 00:40:15,270
grow them you can do something but it's out there in nature well that's one

590
00:40:15,270 --> 00:40:17,450
possible definition of food

591
00:40:17,470 --> 00:40:19,780
another is how much is processed

592
00:40:19,790 --> 00:40:25,290
and how if you take things that started out as food like wheat or corn

593
00:40:25,530 --> 00:40:30,910
and their process many different ways and things are added to them or done to

594
00:40:30,930 --> 00:40:35,650
that change their chemical properties that affect whether we consider

595
00:40:35,680 --> 00:40:43,090
its effect is recognised by the body can the body ingest this particular item

596
00:40:43,150 --> 00:40:48,060
and deal with it in a reasonable way and not have internal have occurred

597
00:40:48,070 --> 00:40:52,070
a when people are eating foods that are too high in fat and sugar

598
00:40:52,080 --> 00:40:57,150
and they eat these foods consistently in hand have other bad nutrients like trans fats

599
00:40:57,290 --> 00:41:01,050
like the bad things happen to them on the body cannot adapt

600
00:41:01,090 --> 00:41:03,590
two of diet that has certain properties

601
00:41:03,610 --> 00:41:06,640
so if food belongs to class

602
00:41:06,840 --> 00:41:12,560
foods that control class of items that contributes to the internal metabolic capt

603
00:41:12,660 --> 00:41:16,720
with that the reason to consider a non food

604
00:41:16,730 --> 00:41:19,050
and the social construction of course

605
00:41:19,070 --> 00:41:20,540
it is very important

606
00:41:20,540 --> 00:41:24,220
do we think something with taste good and we define it as the food as

607
00:41:24,220 --> 00:41:25,650
part of the culture

608
00:41:25,710 --> 00:41:29,540
so if we go back to the cheetos in the cockroach

609
00:41:29,560 --> 00:41:32,780
and we look at our different criteria

610
00:41:32,780 --> 00:41:35,660
and we ask ourselves is it found in nature

611
00:41:35,690 --> 00:41:38,640
well we get checked for the cockroach on that the only

612
00:41:38,700 --> 00:41:42,230
his flaming hot cheetos are not found in nature

613
00:41:42,250 --> 00:41:43,910
is it concocted well

614
00:41:43,930 --> 00:41:47,130
the cockroaches pretty much its natural state

615
00:41:47,240 --> 00:41:51,750
and you have all the ingredients and the other for recognised by the body

616
00:41:52,060 --> 00:41:57,140
my guess is that eating cockroaches probably won't do internal damage eating too much food

617
00:41:57,140 --> 00:41:59,640
like this certainly will

618
00:41:59,700 --> 00:42:01,580
is it harmful well

619
00:42:01,610 --> 00:42:06,060
i mean cockroach might be seen as being harmful because we consider the dirty disgusting

620
00:42:06,060 --> 00:42:12,140
revolting insects and we don't define insects something we released our culture

621
00:42:12,200 --> 00:42:15,340
and then finally do we find it is food well then we get checked for

622
00:42:15,340 --> 00:42:19,050
the cheetos does it taste good we get it checked for the cheetos as well

623
00:42:19,080 --> 00:42:22,280
but only because we're trained to believe that one taste good and the other one

624
00:42:22,280 --> 00:42:26,400
doesn't because in different cultures it would be the reverse

625
00:42:26,410 --> 00:42:30,520
so you see how these different properties of food affect whether we would even consider

626
00:42:31,650 --> 00:42:32,610
so far

627
00:42:32,820 --> 00:42:34,910
are interesting part of this

628
00:42:34,930 --> 00:42:40,030
there was a time when people were very close to their food they were physically

629
00:42:40,030 --> 00:42:43,080
close to it psychologically close to

630
00:42:43,140 --> 00:42:45,750
the food was raised locally

631
00:42:45,900 --> 00:42:51,720
usually think back to new haven in the nineteen fifties are forty or thirty

632
00:42:51,730 --> 00:42:56,050
a lot of the food much more than is the case today was grown locally

633
00:42:56,130 --> 00:42:59,700
and was sold in markets and so there might have been one person or one

634
00:43:00,870 --> 00:43:05,380
that resided between you and your food and you might even see the farmers sometimes

635
00:43:05,380 --> 00:43:07,710
who brought the food into market

636
00:43:07,760 --> 00:43:10,210
that was certainly true in earlier days

637
00:43:10,230 --> 00:43:11,040
and so

638
00:43:11,060 --> 00:43:14,570
but but the distance to food has changed a lot

639
00:43:14,590 --> 00:43:16,730
because food has come has to come in

640
00:43:16,730 --> 00:43:20,910
from far greater distances than used to be the case and that's changed our relationship

641
00:43:20,910 --> 00:43:25,060
with a lot into a distance rather than close relationship

642
00:43:25,210 --> 00:43:28,440
here's an example that you highlighted

643
00:43:28,600 --> 00:43:30,370
in the block there

644
00:43:31,290 --> 00:43:34,550
the is a farm called fairview gardens

645
00:43:34,620 --> 00:43:38,190
that's outside of los angeles in suburban los angeles

646
00:43:38,220 --> 00:43:42,710
and so that's the bracketed part is the farm in nineteen fifty four

647
00:43:42,730 --> 00:43:45,070
the next slide shows the

648
00:43:45,090 --> 00:43:47,970
so far same farm and its surroundings

649
00:43:47,980 --> 00:43:50,830
in nineteen ninety eight

650
00:43:50,860 --> 00:43:54,840
so you can see that a lot has happened here

651
00:43:54,890 --> 00:43:59,900
and so this means that all the areas surrounding at fairview gardens

652
00:43:59,950 --> 00:44:04,640
it was mainly farmland back in the nineteen fifties all growing food

653
00:44:04,660 --> 00:44:08,730
probably a fair amount of it being equal locally by people

654
00:44:08,730 --> 00:44:12,590
but since it's all been pushed out of the way by development

655
00:44:12,650 --> 00:44:16,960
that means the food has to get shipped in from larger and larger distances and

656
00:44:16,960 --> 00:44:20,360
it means that people in los angeles who are eating their food a lot of

657
00:44:20,360 --> 00:44:22,240
it shipped in from far away

658
00:44:22,240 --> 00:44:25,190
have a distant relationship with her

659
00:44:25,210 --> 00:44:30,790
there's also distance psychological relationship with because we just aren't is concerned this people used

660
00:44:30,790 --> 00:44:32,550
to be about where it came from

661
00:44:32,610 --> 00:44:36,310
but that's changing and more and more people do want to know the story of

662
00:44:38,790 --> 00:44:41,780
and that story is something we'll talk about in the class

663
00:44:41,780 --> 00:44:42,870
very similar

664
00:44:42,880 --> 00:44:46,140
but it just gets a little bit more messy i wanted to try and give

665
00:44:46,150 --> 00:44:49,020
you a flavour of what's going on here so i'm not going to go into

666
00:44:49,020 --> 00:44:50,220
this at all with nonzero

667
00:44:50,230 --> 00:44:54,620
training error but you can get similar type of result which says that the bound

668
00:44:54,620 --> 00:44:57,990
on the generalisation is b

669
00:44:58,000 --> 00:45:02,530
number of so you should be k and so some mistake k is the number

670
00:45:02,530 --> 00:45:05,690
of training OK around so that's the empirical

671
00:45:05,700 --> 00:45:07,270
training error

672
00:45:07,320 --> 00:45:11,350
plus it looks very much like what we had before

673
00:45:11,370 --> 00:45:13,540
except that now the square root

674
00:45:15,440 --> 00:45:17,540
which makes it larger

675
00:45:17,550 --> 00:45:19,020
and lucerne

676
00:45:19,020 --> 00:45:23,710
and that comes from using a different bands only

677
00:45:23,730 --> 00:45:31,370
probabilities but you need in the non zero training case in fact

678
00:45:31,390 --> 00:45:37,370
the bayes bounds that are now being developed has sort of interpolate between these two

679
00:45:37,390 --> 00:45:41,990
so you know you could expect that as you go towards low training area you

680
00:45:41,990 --> 00:45:45,040
might actually get something better than the square root

681
00:45:45,150 --> 00:45:49,610
the square root is needed definitely when you have training areas that have large

682
00:45:51,310 --> 00:45:52,780
there's something that

683
00:45:52,810 --> 00:45:54,980
goes between those two

684
00:45:56,730 --> 00:46:01,520
we're going to see the square root come back in the rademacher complexity tomorrow when

685
00:46:01,520 --> 00:46:05,010
we look at the pounds come out of the market complexity

686
00:46:05,010 --> 00:46:07,050
so i wanted to just show you

687
00:46:09,100 --> 00:46:12,850
white squares that because these things should be very much less than one if you

688
00:46:12,850 --> 00:46:15,530
take the square root is something less than one it gets bigger

689
00:46:16,050 --> 00:46:21,750
quite significantly so so it's not a good thing but but it's it's still

690
00:46:21,870 --> 00:46:23,950
an interesting band

691
00:46:23,960 --> 00:46:26,530
so that's the non-zero training error case

692
00:46:27,000 --> 00:46:31,250
so now i want to sort of step back

693
00:46:31,260 --> 00:46:34,500
and sort of review where we've got two and

694
00:46:34,520 --> 00:46:35,810
in this sense

695
00:46:37,900 --> 00:46:39,930
you know the good news is that

696
00:46:40,010 --> 00:46:42,870
this looks like a really nice theory

697
00:46:43,050 --> 00:46:47,340
it all ties together you've got lower and upper bounds is beautiful sort of proof

698
00:46:47,340 --> 00:46:51,570
and so on the bad news is

699
00:46:51,610 --> 00:46:57,830
doesn't seem to actually apply in practice so

700
00:46:57,850 --> 00:46:59,490
it's an interesting case

701
00:46:59,490 --> 00:47:02,160
the problem is that the

702
00:47:02,180 --> 00:47:05,860
you can't criticize it as it stands is clearly correct you know we've got up

703
00:47:05,860 --> 00:47:07,260
and lower bounds

704
00:47:07,270 --> 00:47:13,130
but in it doesn't apply and this is a clear mismatch between the theory and

705
00:47:13,130 --> 00:47:19,060
the practice and probably the best example of that is the support vector machine

706
00:47:20,360 --> 00:47:22,300
so this is sort of

707
00:47:22,340 --> 00:47:27,040
if you like the catastrophic failure of systemic failure of a

708
00:47:27,060 --> 00:47:28,200
the PAC theory

709
00:47:28,200 --> 00:47:32,300
so what is SVM as well

710
00:47:32,310 --> 00:47:36,260
from sort of learning theory point of view all they are is applying linear functions

711
00:47:36,260 --> 00:47:37,750
in very high dimensional

712
00:47:37,750 --> 00:47:39,330
feature spaces

713
00:47:40,260 --> 00:47:44,150
OK this is the kernel trick that you've learned about from from the song which

714
00:47:44,150 --> 00:47:46,500
allows you to do this efficiently

715
00:47:46,510 --> 00:47:51,590
but from the point of view of the learning theorist how you actually implement function

716
00:47:51,600 --> 00:47:56,190
is irrelevant you're actually using a linear function of very high dimensional space

717
00:47:56,210 --> 00:48:00,980
now we know that the VC dimension of an linear function space is

718
00:48:01,300 --> 00:48:03,360
the dimension that space

719
00:48:03,390 --> 00:48:05,550
so the VC dimension of these

720
00:48:06,540 --> 00:48:10,070
svm spaces is is very high and there is no way

721
00:48:10,090 --> 00:48:13,790
the theory will give anything like an indication of good bound i mean for instance

722
00:48:14,230 --> 00:48:16,030
if you use the gas in kernel

723
00:48:16,090 --> 00:48:19,300
the feature space is actually infinite dimension

724
00:48:19,310 --> 00:48:22,510
so you you know you you actually into that town and clearly that's not going

725
00:48:22,510 --> 00:48:23,980
to give you

726
00:48:23,990 --> 00:48:26,530
anything non-trivial

727
00:48:26,570 --> 00:48:32,120
so the PAC theories is completely failing to give any indication of why these

728
00:48:32,140 --> 00:48:35,150
the function should work at all and if you just using the PAC theory to

729
00:48:35,150 --> 00:48:36,770
guide you in your

730
00:48:37,830 --> 00:48:40,070
you know investigation of learning

731
00:48:40,080 --> 00:48:42,990
algorithms you would throw out SVM

732
00:48:43,400 --> 00:48:48,040
and yet we all know that they actually very impressive performance

733
00:48:50,300 --> 00:48:51,940
how they work and

734
00:48:51,960 --> 00:48:54,000
what's happening you know and we need to

735
00:48:54,030 --> 00:48:56,860
you know learning theory needs to sort of

736
00:48:56,940 --> 00:48:58,590
wake up

737
00:49:00,360 --> 00:49:03,980
i understand what's going on trying to analyse this so this is the state of

738
00:49:03,980 --> 00:49:07,020
the game if you like in about ninety three four one

739
00:49:08,750 --> 00:49:11,900
st anne's have been invented in learning theory was still

740
00:49:11,930 --> 00:49:14,790
start with the PAC VC dimension

741
00:49:18,830 --> 00:49:25,050
OK seems work in the following way they effectively the one norm SVM seeks to

742
00:49:25,150 --> 00:49:26,490
minimize this

743
00:49:26,590 --> 00:49:31,140
two norm of the weight vectors plus the one norm of the slack variables where

744
00:49:31,150 --> 00:49:34,880
the slack variables measure how much the

745
00:49:35,120 --> 00:49:38,320
the particular training example fails to be

746
00:49:38,340 --> 00:49:44,060
margin one so it effectively is enforcing the margin one the actual geometrical margin is

747
00:49:44,060 --> 00:49:49,390
is effectively maximized by minimizing the weight vector here and the slack variables allow allowed

748
00:49:49,440 --> 00:49:53,500
individual points to fail to meet margin but it

749
00:49:53,510 --> 00:49:55,700
it penalizes those

750
00:49:55,710 --> 00:49:57,740
failures by adding in

751
00:49:57,760 --> 00:50:02,480
this one norm of the slack variables to the to the minimisation

752
00:50:02,530 --> 00:50:04,400
OK so that's how it it works

753
00:50:04,490 --> 00:50:09,410
and the intuition behind svms so i mean they weren't invented just

754
00:50:09,430 --> 00:50:14,520
arbitrary i mean there was very clear intuition of maximising the margin would make it

755
00:50:14,520 --> 00:50:19,800
possible to change good generalisation despite heist these dimensions

756
00:50:19,820 --> 00:50:25,200
and the phrase effective VC dimension was thrown around but was an imprecise

757
00:50:25,200 --> 00:50:28,390
there was no precise definition of what that meant at the time

758
00:50:29,970 --> 00:50:31,410
that need the

759
00:50:31,430 --> 00:50:34,660
OK so how we getting around this lower bound i mean you know we've got

760
00:50:34,700 --> 00:50:36,060
a lower and

761
00:50:36,080 --> 00:50:37,100
you can't do that

762
00:50:37,120 --> 00:50:42,260
the VC dimension what's happening but there is a critical difference between the upper bound

763
00:50:42,260 --> 00:50:42,930
on the log

764
00:50:42,950 --> 00:50:46,620
you have advances for every distribution

765
00:50:46,620 --> 00:50:48,450
you can have better performance

766
00:50:49,390 --> 00:50:53,910
the second the lower bound says there exist distributions

767
00:50:53,910 --> 00:50:56,300
four which were forced to make this error

768
00:50:56,530 --> 00:50:58,260
so one with

769
00:50:58,280 --> 00:51:04,280
effectively using here is the fact that there are the distributions image in practice may

770
00:51:04,280 --> 00:51:05,220
not be

771
00:51:05,240 --> 00:51:06,240
as nasty

772
00:51:06,260 --> 00:51:09,100
as the worst case distributions

773
00:51:11,310 --> 00:51:17,280
looking for something if you like about nine distribution something about the distribution which is

774
00:51:17,280 --> 00:51:23,310
serendipitous it's it's helping us nature is actually not against us it's it's helping us

775
00:51:25,220 --> 00:51:28,200
learning the actual task that we're trying to learn

776
00:51:28,220 --> 00:51:30,600
and in fact what we

777
00:51:30,620 --> 00:51:33,080
find is the margin is in this sense

778
00:51:33,100 --> 00:51:35,800
a measure of how lucky we are

779
00:51:35,810 --> 00:51:38,490
in in

780
00:51:39,620 --> 00:51:42,470
particular distribution we're looking at

781
00:51:42,490 --> 00:51:46,080
the distribution is somehow luckily aligned with the

782
00:51:46,100 --> 00:51:52,080
hyperplane that we need to separate the data and actually is if you like showing

783
00:51:52,100 --> 00:51:55,810
us the solution and that is what is actually

784
00:51:56,100 --> 00:51:58,280
occurring in order to

785
00:51:58,390 --> 00:52:00,720
avoid the

786
00:52:00,760 --> 00:52:02,560
difficulties of love

787
00:52:02,600 --> 00:52:05,560
so we know a lot about what i yes if you use these high dimensional

788
00:52:05,560 --> 00:52:07,890
space is there are distributions will

789
00:52:08,700 --> 00:52:09,620
that's for sure

790
00:52:09,620 --> 00:52:14,200
what we're saying is that the margin is telling us actually that we can measure

791
00:52:14,200 --> 00:52:18,450
the the ninth the distribution as we do our training and we can

792
00:52:19,640 --> 00:52:22,910
see that we're unlucky situation

793
00:52:23,450 --> 00:52:26,560
so what i'm not going to do is is is sort of take the first

794
00:52:26,560 --> 00:52:29,760
approach to proving the band's

795
00:52:29,780 --> 00:52:32,310
for ESPN's which are based

796
00:52:32,330 --> 00:52:34,080
on the margin

797
00:52:34,120 --> 00:52:40,120
i will give a complete proof of these birds' out

798
00:52:40,160 --> 00:52:44,870
given a fairly it follows very similar pattern to the proof for the that we've

799
00:52:44,870 --> 00:52:46,740
seen so far for the VC dimension

800
00:52:46,910 --> 00:52:50,870
but i want to give you a flavour of these ideas are translated across

801
00:52:50,870 --> 00:52:54,020
i'm now leaving out of this notation because

802
00:52:54,020 --> 00:53:00,150
this argmax here that i'm interested in its for specific x five minutes for a

803
00:53:00,150 --> 00:53:02,570
specific data facts

804
00:53:03,860 --> 00:53:08,680
much so i can leave it out of the notation

805
00:53:09,940 --> 00:53:12,860
OK i guess that was the

806
00:53:12,860 --> 00:53:16,120
and there

807
00:53:36,460 --> 00:53:37,430
so this

808
00:53:37,440 --> 00:53:39,670
this GI function if you

809
00:53:41,720 --> 00:53:43,180
if you look back up here

810
00:53:43,930 --> 00:53:46,000
the thing that we want to maximize

811
00:53:46,000 --> 00:53:49,810
it is the sum of all feature functions or high level feature functions the need

812
00:53:49,810 --> 00:53:53,930
high level feature function is the sum of the positions in the sequence so now

813
00:53:53,930 --> 00:53:57,440
always said as we have some of the positions in the sequence

814
00:53:57,590 --> 00:54:02,850
and then this g function is really the total contribution

815
00:54:03,860 --> 00:54:06,910
a single position i in the sequence

816
00:54:07,850 --> 00:54:11,420
so much so and noticed that

817
00:54:11,480 --> 00:54:14,600
you know why i minus one

818
00:54:14,640 --> 00:54:16,610
and why i

819
00:54:16,650 --> 00:54:18,200
they belong to

820
00:54:18,460 --> 00:54:24,040
look OK the set of tags

821
00:54:26,030 --> 00:54:28,710
so if i have a hyphenation problem

822
00:54:28,750 --> 00:54:32,250
then there are just two possible tax zero and one

823
00:54:32,260 --> 00:54:34,210
and if i have a part of speech

824
00:54:34,260 --> 00:54:38,070
problem then maybe there are twenty possible tax twenty possible

825
00:54:38,080 --> 00:54:40,360
parts of speech

826
00:54:43,450 --> 00:54:46,680
x but

827
00:54:46,690 --> 00:54:47,880
and w but

828
00:54:47,910 --> 00:54:49,780
i fixed

829
00:54:51,530 --> 00:54:59,250
this function g i said member trying to derive an algorithm so algorithms depend on

830
00:54:59,250 --> 00:55:01,050
data structures so

831
00:55:01,090 --> 00:55:03,270
what data structure

832
00:55:03,290 --> 00:55:06,880
can i use what's the simple data structure that can use to represent the function

833
00:55:06,880 --> 00:55:11,690
g i

834
00:55:11,760 --> 00:55:16,050
data structure

835
00:55:16,160 --> 00:55:20,680
g i

836
00:55:21,790 --> 00:55:25,190
so set of tags we call this set t

837
00:55:25,210 --> 00:55:27,570
with cardinality

838
00:55:36,540 --> 00:55:41,350
so m is the number of different tags to five-nation twenty four part of speech

839
00:55:42,340 --> 00:55:45,550
have the function g i and i'm going to need to evaluate it for every

840
00:55:46,510 --> 00:55:50,050
combination of values while i minus one y i

841
00:55:50,770 --> 00:55:55,050
and then i'm going to need to store this function so what data structure can

842
00:55:55,050 --> 00:56:01,500
be used to store this function in

843
00:56:02,880 --> 00:56:06,370
hash all actually i can use something even simpler

844
00:56:06,390 --> 00:56:09,210
i can just use a two dimensional matrix

845
00:56:09,220 --> 00:56:14,440
because there are just two different arguments and their and values which are used the

846
00:56:14,440 --> 00:56:15,730
m squared

847
00:56:15,750 --> 00:56:17,100
possible values

848
00:56:22,830 --> 00:56:25,300
g i

849
00:56:25,310 --> 00:56:31,840
is an m by n matrix

850
00:56:31,850 --> 00:56:36,050
and so actually the first thing i algorithm

851
00:56:36,070 --> 00:56:38,800
precompute these by functions

852
00:56:41,310 --> 00:56:42,640
and is it

853
00:56:46,570 --> 00:56:49,540
x bars fixed

854
00:56:49,550 --> 00:56:52,380
and then for four equals one

855
00:56:52,400 --> 00:56:56,390
i just computer some some of the jwj

856
00:56:56,430 --> 00:56:57,670
the left j

857
00:56:57,690 --> 00:57:03,050
of why i minus one y i for every possible pair of values y i

858
00:57:03,050 --> 00:57:12,610
so it's GI is an m by n matrix

859
00:57:18,880 --> 00:57:22,020
so so g to g one

860
00:57:22,020 --> 00:57:25,480
it is an m by n matrix g two is an m by n matrix

861
00:57:25,500 --> 00:57:27,680
g three is an m by n matrix

862
00:57:27,750 --> 00:57:37,180
so then precompute all of these

863
00:57:37,280 --> 00:57:38,510
so that's

864
00:57:39,630 --> 00:57:43,250
it's and square squirt

865
00:57:51,320 --> 00:57:57,200
and square and time

866
00:57:57,220 --> 00:57:59,690
so there and these matrices

867
00:57:59,730 --> 00:58:02,070
each one has got m squared entries

868
00:58:03,810 --> 00:58:06,780
entry in the matrix is the sum of the room

869
00:58:07,530 --> 00:58:09,510
little feature functions

870
00:58:09,560 --> 00:58:14,080
so it's it's quadratic in and

871
00:58:14,080 --> 00:58:18,590
but linear otherwise

872
00:58:20,640 --> 00:58:26,890
and unfortunately don't have much room on the board

873
00:58:29,510 --> 00:58:30,940
and now

874
00:58:36,480 --> 00:58:38,850
this goal

875
00:58:38,850 --> 00:58:41,140
almost all the protons are going to be zero

876
00:58:41,140 --> 00:58:44,910
because the use the gammas of you are independent

877
00:58:44,930 --> 00:58:50,070
so you only get contribution at the turn at the point where you're multiplying the

878
00:58:50,070 --> 00:58:53,320
same termites are just turns out to be the interval

879
00:58:53,340 --> 00:58:58,410
all the all the time as series except for these sort of diagonal terms

880
00:58:58,740 --> 00:59:01,570
where you takes on the same value

881
00:59:02,390 --> 00:59:05,010
that gives you an expression that look like this

882
00:59:05,010 --> 00:59:07,160
and you can rearrange this expression

883
00:59:07,280 --> 00:59:08,300
to get

884
00:59:08,780 --> 00:59:13,490
well it's a it's actually gauss integral manually evaluate that goes into google you get

885
00:59:14,320 --> 00:59:16,240
term that look like this

886
00:59:16,280 --> 00:59:21,510
which is just a financial x minus ex-prime squared over two

887
00:59:22,340 --> 00:59:23,720
this now

888
00:59:23,780 --> 00:59:26,140
is the covariance function

889
00:59:26,160 --> 00:59:28,620
we have been working on on the previous example

890
00:59:28,680 --> 00:59:29,550
this is this

891
00:59:29,570 --> 00:59:33,450
calcium or squared exponential growth

892
00:59:33,450 --> 00:59:34,620
that means

893
00:59:34,760 --> 00:59:36,260
doing inference

894
00:59:36,280 --> 00:59:38,070
in the gas process

895
00:59:38,140 --> 00:59:39,620
is equivalent

896
00:59:39,640 --> 00:59:41,110
to doing inference

897
00:59:41,950 --> 00:59:43,390
the set of functions

898
00:59:43,410 --> 00:59:47,030
i have little galson pumps everywhere

899
00:59:47,030 --> 00:59:51,050
notice that have gas improv everywhere not just on the training points

900
00:59:51,070 --> 00:59:52,870
this turns out to be quite important

901
00:59:54,990 --> 00:59:57,200
of course if you wanted to do

902
00:59:57,740 --> 01:00:00,660
regression in your fashion way

903
01:00:00,700 --> 01:00:04,070
then you get into trouble if you have infinite number one because that means that

904
01:00:04,070 --> 01:00:08,280
you're just input vector you feature that will be the value

905
01:00:08,300 --> 01:00:11,140
of of

906
01:00:11,140 --> 01:00:14,180
of each of those bonds right but if there are infinitely many of those

907
01:00:14,260 --> 01:00:15,700
and then of course

908
01:00:15,740 --> 01:00:17,890
you wouldn't really be able to write down

909
01:00:17,930 --> 01:00:21,160
what you can do the inference if you think of it as gospel

910
01:00:21,700 --> 01:00:23,280
because in that case

911
01:00:23,280 --> 01:00:30,840
the inference only involves the covariance matrix which is dimension and by i

912
01:00:32,200 --> 01:00:34,850
here's the figure that tries to illustrate

913
01:00:34,910 --> 01:00:38,510
why it's important that you have infinitely many got involved

914
01:00:38,550 --> 01:00:41,010
so you could sort of say well

915
01:00:41,470 --> 01:00:46,990
this other stuff is just using some fancy mathematics and use sort of infinity all

916
01:00:46,990 --> 01:00:50,700
looks very neat but actually when it comes down to doing something practical practical

917
01:00:50,720 --> 01:00:52,800
i don't care about us to

918
01:00:52,890 --> 01:00:56,280
is the figure which had to why you want to care about that

919
01:00:56,300 --> 01:00:57,590
here's an example

920
01:00:57,680 --> 01:00:58,850
where we have

921
01:00:58,870 --> 01:01:05,280
we have a model which has three months got right the centre

922
01:01:05,320 --> 01:01:08,760
exactly at the location where he also training data three

923
01:01:08,820 --> 01:01:10,350
the training data points

924
01:01:10,370 --> 01:01:12,070
you have three girls in bonds

925
01:01:12,070 --> 01:01:13,870
in other model

926
01:01:14,120 --> 01:01:17,720
to do inference model you have to inference over the weights corresponding to the three

927
01:01:17,720 --> 01:01:20,120
girls in

928
01:01:20,850 --> 01:01:23,970
now when you do the bayes analysis you have to think about doing it into

929
01:01:24,570 --> 01:01:26,610
over all the possible settings

930
01:01:26,640 --> 01:01:30,990
of those different parameters you can sort of think of the little girls bumps

931
01:01:31,070 --> 01:01:34,200
as jiggling around but they have to dig around such way

932
01:01:34,280 --> 01:01:36,320
we all know that they always

933
01:01:36,350 --> 01:01:40,680
almost exactly explains the data to the red curve here is some

934
01:01:40,680 --> 01:01:41,840
other the values

935
01:01:42,260 --> 01:01:46,890
for this setting about can sort of imagine under the posterior distribution

936
01:01:46,990 --> 01:01:51,390
these are wiggle around and you can get you some distribution of this of the

937
01:01:51,390 --> 01:01:52,700
underlying rate function

938
01:01:52,760 --> 01:01:55,120
we could use this associated areas

939
01:01:55,120 --> 01:01:56,890
to illustrate what that

940
01:01:56,910 --> 01:01:59,530
what that inference what those

941
01:01:59,610 --> 01:02:02,070
confidence intervals would be

942
01:02:02,760 --> 01:02:05,470
now comes out just point test runs over here

943
01:02:06,120 --> 01:02:07,570
so how do we do

944
01:02:07,570 --> 01:02:11,840
what happens when we doing inference here in the model how the prediction here when

945
01:02:11,840 --> 01:02:12,870
we look at

946
01:02:12,930 --> 01:02:15,050
what is the model predicting

947
01:02:15,050 --> 01:02:18,870
and then integrate over the posterior we look at what happened somewhere here

948
01:02:18,910 --> 01:02:22,890
then we regard around the little bumps here under the posterior distribution

949
01:02:22,910 --> 01:02:24,320
and what happens out here

950
01:02:25,430 --> 01:02:28,180
OK the function is always zero

951
01:02:28,240 --> 01:02:33,160
that means the predictive distribution is going to be gaussians centered around zero

952
01:02:33,180 --> 01:02:37,220
with zero variance

953
01:02:37,260 --> 01:02:40,840
OK the fact that the centre and zero is maybe not so bad because because

954
01:02:41,570 --> 01:02:44,590
the truth is we don't know what's going on here so zero is as good

955
01:02:44,590 --> 01:02:46,820
as guest as anyone has anything

956
01:02:46,820 --> 01:02:48,620
but it has zero variance

957
01:02:48,740 --> 01:02:50,200
this is a catastrophe

958
01:02:50,340 --> 01:02:55,120
it's saying that it's absolutely sure that the values zero

959
01:02:55,240 --> 01:02:58,160
that's the wrong answer

960
01:02:58,180 --> 01:03:00,800
why why do we get the right answer here

961
01:03:00,840 --> 01:03:02,530
we've got the wrong answer

962
01:03:02,530 --> 01:03:05,030
because the prior was sort of city

963
01:03:05,060 --> 01:03:08,300
the prior already said well we only entertain

964
01:03:08,340 --> 01:03:13,870
hypothesis about what's going on that only allow functions that vary over here

965
01:03:13,870 --> 01:03:17,510
of course seeing any amount of data you still only get functions that very over

966
01:03:20,260 --> 01:03:23,280
so what was wrong about the prior

967
01:03:23,340 --> 01:03:26,660
but thing that was wrong about the prior is that it that it excluded that

968
01:03:26,660 --> 01:03:30,820
anything could happen over here even before we started

969
01:03:30,870 --> 01:03:33,950
which is which is an unreasonable assumption usually

970
01:03:33,970 --> 01:03:36,910
you wouldn't want to assume that kind of thing in some applications it might be

971
01:03:36,910 --> 01:03:40,260
an appropriate assumptions right but in general it doesn't seem like such and such good

972
01:03:41,340 --> 01:03:46,780
so you can get away from that kind of prior by having down syndrome everywhere

973
01:03:46,820 --> 01:03:48,850
OK so in this example

974
01:03:48,870 --> 01:03:51,820
well let's say we also have a gas and pop over here

975
01:03:52,590 --> 01:03:54,220
now we do the inference

976
01:03:54,240 --> 01:03:58,200
these things are jiggling around ever-so-slightly right because i have to agree with the data

977
01:03:58,260 --> 01:03:59,280
in this thing

978
01:03:59,300 --> 01:04:00,820
it's just going around

979
01:04:00,840 --> 01:04:04,950
its posterior distribution equal to its prior distribution because the data doesn't have any opinion

980
01:04:04,950 --> 01:04:06,430
about what's going on here

981
01:04:06,490 --> 01:04:08,840
that means this is jiggling around wildly

982
01:04:08,890 --> 01:04:11,820
which means that the error bar is going to be large and that's the right

983
01:04:20,620 --> 01:04:21,450
OK so

984
01:04:26,990 --> 01:04:39,990
so this a particular gaussianprocess which you can think of it that way

985
01:04:40,090 --> 01:04:43,510
but that's just for a particular choice of the covariance function

986
01:04:43,530 --> 01:04:46,820
what i wanna spend the last ten minutes on is going to talk about

987
01:04:46,910 --> 01:04:48,930
different types of covariance functions

988
01:04:52,140 --> 01:04:57,280
so the so i so the gas processes are somehow much which class depends on

989
01:04:57,300 --> 01:04:59,490
what the covariance functions are

990
01:04:59,530 --> 01:05:04,030
the other is in the information about what you can do here so before we

991
01:05:04,030 --> 01:05:05,970
look at the squared exponential

992
01:05:06,010 --> 01:05:08,570
covariance function discussed in great functions

993
01:05:09,410 --> 01:05:12,180
in one dimension which had a single length scales

994
01:05:12,200 --> 01:05:15,580
but if you have more if you have multiple dimensions then you might have a

995
01:05:15,580 --> 01:05:18,760
length scale parameter for each of the dimensions the new covariance function would look like

996
01:05:20,470 --> 01:05:21,610
and drawn

997
01:05:21,620 --> 01:05:25,840
random functions for different settings of the length scale parameter

998
01:05:25,840 --> 01:05:28,720
three and four four point inside this

999
01:05:31,030 --> 01:05:32,690
the radius here

1000
01:05:33,400 --> 01:05:35,270
they define outliers

1001
01:05:35,320 --> 01:05:37,880
as data records

1002
01:05:37,940 --> 01:05:39,770
therefore every are they

1003
01:05:39,780 --> 01:05:42,550
you have to define this is the parameter

1004
01:05:42,570 --> 01:05:47,740
so basically this a the number and the idea of are significantly deviates from the

1005
01:05:47,740 --> 01:05:52,200
distribution of values pj of our so that means the from the neighbors here

1006
01:05:52,250 --> 01:05:57,070
a source the simple pj from from from the neighborhood so for example

1007
01:05:57,090 --> 01:05:59,580
if this is true

1008
01:05:59,640 --> 01:06:02,590
that means point BI i is the outer

1009
01:06:03,630 --> 01:06:05,870
so let's let's assume you so that

1010
01:06:05,880 --> 01:06:08,550
and b i are that means

1011
01:06:08,560 --> 01:06:12,020
all the points that are from point p i

1012
01:06:12,030 --> 01:06:13,050
this post

1013
01:06:13,060 --> 01:06:14,210
at least our

1014
01:06:14,220 --> 01:06:16,320
there are four points this one

1015
01:06:17,390 --> 01:06:19,440
four so and are four

1016
01:06:19,450 --> 01:06:20,180
it's here

1017
01:06:20,200 --> 01:06:22,940
so if you if you introduce new parameter alpha

1018
01:06:23,000 --> 01:06:25,690
so basically having small circle here

1019
01:06:25,740 --> 01:06:29,070
so in this case and p of our is one

1020
01:06:29,120 --> 01:06:32,440
so can construct similarly this value for

1021
01:06:32,440 --> 01:06:34,830
support points p one p two and p three

1022
01:06:34,900 --> 01:06:35,950
p one

1023
01:06:36,490 --> 01:06:40,320
circles the are three point in this that's three

1024
01:06:40,380 --> 01:06:41,510
p two

1025
01:06:41,510 --> 01:06:43,920
there are five points on the circle here

1026
01:06:44,840 --> 01:06:47,380
so and the two of five

1027
01:06:47,470 --> 01:06:48,440
will be three

1028
01:06:48,450 --> 01:06:51,740
there are two points in the circle so that's two

1029
01:06:51,760 --> 01:06:55,500
and i know you can put in this average value so basically

1030
01:06:55,510 --> 01:06:59,560
the i are of this is the average value of all the points

1031
01:06:59,590 --> 01:07:03,240
including this point this point this this and this

1032
01:07:03,270 --> 01:07:06,050
so these all the numbers to the computed so far

1033
01:07:06,130 --> 01:07:11,620
this is the average so basically computer use this average in this competition here

1034
01:07:11,630 --> 01:07:13,770
of course you compute the standard

1035
01:07:13,820 --> 01:07:15,240
the nation here

1036
01:07:15,300 --> 01:07:17,620
and then depending on parameter k

1037
01:07:17,650 --> 01:07:20,290
you can define is a certain value

1038
01:07:20,300 --> 01:07:25,850
seven data record is anomaly some this is simple they how to compute

1039
01:07:25,870 --> 01:07:30,150
of these the director

1040
01:07:30,200 --> 01:07:33,820
OK of they want to make a break five minutes or ten minutes or you

1041
01:07:33,820 --> 01:07:37,580
want me to continue

1042
01:07:39,800 --> 01:07:40,940
OK then

1043
01:07:40,950 --> 01:07:44,950
it's very

1044
01:07:46,240 --> 01:07:52,430
can we continue

1045
01:07:52,590 --> 01:08:15,080
OK so far recovered classification based on nearest neighbour based anomaly detection techniques to cover

1046
01:08:15,080 --> 01:08:16,670
some of the remaining ones

1047
01:08:16,680 --> 01:08:21,090
we'll talk briefly about this online distributed anomaly detection as well

1048
01:08:22,400 --> 01:08:23,810
let's go to

1049
01:08:23,820 --> 01:08:29,890
clustering based techniques so same clustering based anomaly detection techniques key assumption is that

1050
01:08:29,930 --> 01:08:32,570
normal data points belong to to

1051
01:08:32,590 --> 01:08:35,450
large and dense clusters while anomalies

1052
01:08:35,490 --> 01:08:37,110
they belong to

1053
01:08:37,120 --> 01:08:41,690
actually cannot belong to any cluster may belong to some very small clusters

1054
01:08:41,730 --> 01:08:44,550
so the general approaches to cluster data

1055
01:08:44,570 --> 01:08:49,320
in two thousand clusters and analyse data instances with respect to what is the closest

1056
01:08:49,320 --> 01:08:53,600
cluster and if the points belong to any cluster

1057
01:08:53,680 --> 01:08:58,790
so the points that correspond to analysis that can be

1058
01:08:58,830 --> 01:09:01,360
they do not belong to any of the clusters

1059
01:09:01,420 --> 01:09:03,750
the sell small clusters

1060
01:09:03,810 --> 01:09:06,240
some this clusters as well

1061
01:09:06,300 --> 01:09:07,520
and also

1062
01:09:07,530 --> 01:09:11,550
things that are far from other points within the same cluster so depends on the

1063
01:09:11,550 --> 01:09:14,420
class three able write code behind

1064
01:09:14,430 --> 01:09:21,720
so obvious advantages included this is again unsupervised approach does not require any labels

1065
01:09:21,740 --> 01:09:25,670
and existing clustering approaches can be plugged in an applied here

1066
01:09:25,680 --> 01:09:27,610
for the problem of anomaly detection

1067
01:09:30,070 --> 01:09:31,740
there are many drawbacks

1068
01:09:31,770 --> 01:09:34,460
if the data does not have the natural

1069
01:09:34,520 --> 01:09:37,230
clustering of

1070
01:09:37,290 --> 01:09:38,890
natural kind of grouping

1071
01:09:38,930 --> 01:09:43,170
this approach not able to find this clusters and then you know the the goal

1072
01:09:43,170 --> 01:09:44,810
of an action

1073
01:09:44,840 --> 01:09:49,200
they're also computationally expensive like the nearest neighbour reported because they are based on the

1074
01:09:49,200 --> 01:09:52,120
similar idea computing the distances

1075
01:09:52,140 --> 01:09:54,910
and a national time people are using

1076
01:09:54,920 --> 01:09:56,770
different index structures

1077
01:09:56,780 --> 01:09:59,440
to alleviate this problem

1078
01:09:59,480 --> 01:10:01,940
and again in high dimensional

1079
01:10:01,950 --> 01:10:03,700
spaces data is sparse

1080
01:10:03,900 --> 01:10:09,790
distances may not be meaningful the same problem with the nearest neighbour technique

1081
01:10:10,070 --> 01:10:16,000
i will present a few of this approach is what is actually what people what

1082
01:10:16,000 --> 01:10:18,280
kind of the things people

1083
01:10:18,340 --> 01:10:21,650
using to detect anomalies

1084
01:10:22,750 --> 01:10:25,080
this approach is called find out

1085
01:10:25,100 --> 01:10:27,970
it's by these people

1086
01:10:28,020 --> 01:10:31,030
and this is basically a by-product of

1087
01:10:31,100 --> 01:10:35,640
they cluster of making this growing interest in buffalo

1088
01:10:35,650 --> 01:10:40,890
so only buffalo and the main idea is to transform all data records into multidimensional

1089
01:10:40,890 --> 01:10:43,240
signals using the wavelet transformation

1090
01:10:43,290 --> 01:10:45,520
and then high frequency of the signals

1091
01:10:45,570 --> 01:10:51,320
correspond to data regions where is the rapid change of distribution

1092
01:10:51,420 --> 01:10:56,780
these are usually about this is because of the boundaries of the clusters we here

1093
01:10:56,820 --> 01:11:01,160
and low frequency parts correspond to regions where the data is

1094
01:11:01,340 --> 01:11:05,930
concentrated so basically this is here and here so basically when you remove all these

1095
01:11:05,930 --> 01:11:11,520
points what this approach does basically takes all remaining points out of this

1096
01:11:11,520 --> 01:11:15,870
you all are

1097
01:11:23,050 --> 01:11:24,970
no i

1098
01:11:55,820 --> 01:11:59,600
you want to go

1099
01:12:05,610 --> 01:12:10,470
o or one one

1100
01:12:10,730 --> 01:12:16,290
you are

1101
01:12:17,370 --> 01:12:21,540
we are all

1102
01:12:52,290 --> 01:13:01,050
all right

1103
01:13:56,180 --> 01:14:01,830
you can be your

1104
01:14:33,680 --> 01:14:40,480
also a

1105
01:15:25,610 --> 01:15:29,380
here you

1106
01:15:29,380 --> 01:15:34,220
this a

1107
01:16:01,930 --> 01:16:05,840
the case

1108
01:16:09,190 --> 01:16:11,830
of these

1109
01:16:34,130 --> 01:16:36,850
on the other

1110
01:16:38,960 --> 01:16:43,170
twenty four

1111
01:16:51,890 --> 01:17:02,380
the you know

1112
01:17:25,410 --> 01:17:29,540
o are more

1113
01:17:33,250 --> 01:17:36,620
he you are

1114
01:17:36,620 --> 01:17:41,500
what i do it is a simple example i agree but notice what i just

1115
01:17:41,500 --> 01:17:45,410
did it allow me to highlight is the code doing the right thing

1116
01:17:45,410 --> 01:17:49,240
spotted an i could have spotted it by running on different test sets and using

1117
01:17:49,240 --> 01:17:53,280
prince things another way doing about this idea of at least simulating and simple examples

1118
01:17:53,310 --> 01:17:54,640
lets you checked

1119
01:17:54,660 --> 01:17:56,450
a couple of important questions

1120
01:17:56,540 --> 01:18:00,020
in fact now let me ask those two questions about this piece of code

1121
01:18:00,030 --> 01:18:01,900
the first question is

1122
01:18:01,940 --> 01:18:04,150
for what values of integers

1123
01:18:04,260 --> 01:18:09,330
images overall values of x does this code terminate

1124
01:18:09,340 --> 01:18:11,190
the second question is

1125
01:18:11,230 --> 01:18:15,670
for what values of x doesn't give me back the right answer

1126
01:18:15,950 --> 01:18:18,180
first question

1127
01:18:18,220 --> 01:18:22,150
of eyes have access to terminate

1128
01:18:22,170 --> 01:18:26,070
it's in x is an integer

1129
01:18:26,720 --> 01:18:29,550
break it down into pieces suppose x is positive

1130
01:18:29,570 --> 01:18:32,160
does it terminates

1131
01:18:33,430 --> 01:18:35,990
because answer start so to zero

1132
01:18:36,030 --> 01:18:41,360
so answer squared is zero and each time through the loop answer is increasing

1133
01:18:41,370 --> 01:18:45,270
that means at some point in some finite number of steps answers squared is going

1134
01:18:45,280 --> 01:18:47,700
to get bigger than x is possible

1135
01:18:47,740 --> 01:18:50,210
so for positive integers it terminates

1136
01:18:50,250 --> 01:18:54,350
probably i think we can deduce to return to the right answer here

1137
01:18:55,610 --> 01:18:57,350
x is negative

1138
01:18:57,370 --> 01:18:59,390
x minus sixteen

1139
01:18:59,440 --> 01:19:04,590
does this code terminate

1140
01:19:06,860 --> 01:19:10,810
i feel like arnold schwarzenegger does this too many

1141
01:19:13,060 --> 01:19:17,090
thank you so does germany right

1142
01:19:17,110 --> 01:19:19,560
there's too far back to try

1143
01:19:19,970 --> 01:19:24,170
so far sorry come to one later if you can find it it starts at

1144
01:19:24,170 --> 01:19:26,570
the first step right let's look at it

1145
01:19:26,580 --> 01:19:31,810
it says if answer i imagine axes minus sixteen answer is zero is zero less

1146
01:19:33,190 --> 01:19:34,810
minus sixteen

1147
01:19:35,760 --> 01:19:37,300
so what does it do

1148
01:19:37,390 --> 01:19:39,710
prince of zero

1149
01:19:39,740 --> 01:19:42,570
that now answers my second question

1150
01:19:42,600 --> 01:19:46,490
it does terminate but does it give me the right answer

1151
01:19:47,260 --> 01:19:51,310
it gives me an answer imagine i'm using this somewhere else you know it's is

1152
01:19:51,320 --> 01:19:54,690
going to go off and say g these square root of minus sixteen is zero

1153
01:19:54,990 --> 01:19:58,000
really should be you know an imaginary number but this is not a valuable thing

1154
01:19:58,000 --> 01:19:59,240
to have come back

1155
01:19:59,290 --> 01:20:03,500
so that's the second thing i just highlighted here i now have the ability

1156
01:20:03,620 --> 01:20:04,910
to cheque

1157
01:20:04,950 --> 01:20:06,910
what does the right thing

1158
01:20:06,960 --> 01:20:10,400
those are two things that you'd like to do with every looping construct right you'd

1159
01:20:10,400 --> 01:20:14,490
like to be able to assure yourself that they will always terminate

1160
01:20:14,600 --> 01:20:17,310
in the second thing you'd like to do is to assure yourself that it does

1161
01:20:17,330 --> 01:20:19,670
give back to reasonable answer

1162
01:20:19,720 --> 01:20:22,500
we started to talk about ways to do the former is looking at the end

1163
01:20:22,500 --> 01:20:25,230
test is looking at the kinds of conditions you can put in

1164
01:20:25,240 --> 01:20:26,700
for the latter

1165
01:20:26,710 --> 01:20:29,340
this is the place for running test cases would do a good job of helping

1166
01:20:29,350 --> 01:20:31,000
with that

1167
01:20:31,050 --> 01:20:33,740
nonetheless having done that let's look at

1168
01:20:33,830 --> 01:20:35,690
better way to write this

1169
01:20:35,750 --> 01:20:38,000
which is

1170
01:20:38,930 --> 01:20:42,500
it is also i think on your she uncommon that

1171
01:20:42,520 --> 01:20:47,260
comment this one out

1172
01:20:47,680 --> 01:20:53,210
so let's look at this code for second

1173
01:20:53,210 --> 01:20:56,920
is what this does certainly the heart of right in here

1174
01:20:56,930 --> 01:20:58,170
it is still

1175
01:20:58,220 --> 01:20:59,530
the same thing

1176
01:20:59,640 --> 01:21:02,430
but notice what this does the first thing it does is it says let's check

1177
01:21:02,430 --> 01:21:05,250
and make sure x is greater than or equal to zero

1178
01:21:05,280 --> 01:21:06,750
if it isn't

1179
01:21:06,810 --> 01:21:10,620
this was going to happen under that block is going to get executed that's going

1180
01:21:10,660 --> 01:21:14,340
come down here print out a useful piece of information was assayed in a negative

1181
01:21:15,390 --> 01:21:17,540
i don't know how to do this

1182
01:21:17,570 --> 01:21:20,510
if it is in fact positive then we're going to go in here but now

1183
01:21:20,510 --> 01:21:24,200
notice what we're doing here there's the basic thing we did before i were checking

1184
01:21:24,200 --> 01:21:25,900
the intestine incrementing

1185
01:21:25,900 --> 01:21:28,810
actually was going i commented that for a reason you see in the second but

1186
01:21:28,890 --> 01:21:32,310
normally would keep the sum which would let me at each step see what it's

1187
01:21:33,370 --> 01:21:36,640
if i ran this it would print out each step helping me make sure that

1188
01:21:36,750 --> 01:21:38,070
increment in the right way

1189
01:21:38,080 --> 01:21:41,290
they want to get to the end of that what's going to do is going

1190
01:21:41,290 --> 01:21:44,110
to come down here and now

1191
01:21:44,160 --> 01:21:46,500
was that during

1192
01:21:46,520 --> 01:21:49,710
well i cheated when i started some some is given a perfect square looking for

1193
01:21:49,710 --> 01:21:51,020
the square root of

1194
01:21:51,070 --> 01:21:53,590
but suppose i gave this thing fifteen

1195
01:21:53,640 --> 01:21:55,440
and as to to run

1196
01:21:55,500 --> 01:21:59,370
it's to give me an answer it just wouldn't be the answer i'm looking for

1197
01:21:59,430 --> 01:22:03,020
so now in this case this code is going to what we get here check

1198
01:22:03,040 --> 01:22:07,690
if you haven't seen that strange thing explanation point in computer is called the bang

1199
01:22:07,830 --> 01:22:11,150
this is the answer star answer is not equal

1200
01:22:13,870 --> 01:22:16,180
what sets a says i've already got to the end of the loop on all

1201
01:22:16,180 --> 01:22:18,850
past where i wanted to be and i want to check to make sure that

1202
01:22:18,850 --> 01:22:21,540
in fact this really is a perfect square if it isn't

1203
01:22:21,560 --> 01:22:25,070
print out something says you gave me something that wasn't perfect square

1204
01:22:25,270 --> 01:22:26,950
and only

1205
01:22:26,960 --> 01:22:27,810
if that

1206
01:22:27,830 --> 01:22:28,910
is true

1207
01:22:28,920 --> 01:22:32,070
print out the answer

1208
01:22:32,100 --> 01:22:34,650
it's the same computation

1209
01:22:34,690 --> 01:22:39,950
but this is a nice way of writing it often called defensive program

1210
01:22:40,000 --> 01:22:49,880
and i think we have lots of variations on down on the drum what your

1211
01:22:49,880 --> 01:22:53,750
favourites for the definition of defensive programming for me it says

1212
01:22:53,760 --> 01:22:57,370
make sure that i'm going through all possible paths through the code

1213
01:22:57,430 --> 01:23:01,910
make sure and printing ordered or returning if you like useful information for each style

1214
01:23:02,190 --> 01:23:04,150
sorry for each pass through the code

1215
01:23:04,200 --> 01:23:07,820
make sure that for all possible inputs there is a path through the code or

1216
01:23:07,820 --> 01:23:11,690
way to get through the code does not cause an error an infinite loop

1217
01:23:11,710 --> 01:23:14,400
well for jadran john

1218
01:23:14,420 --> 01:23:19,200
i i will come back to this later in the term and talk it in

1219
01:23:19,200 --> 01:23:23,430
less work to solve perturbed version of the problem so that's what happens with the

1220
01:23:23,430 --> 01:23:27,890
segmentation problem where you you've got here

1221
01:23:28,990 --> 01:23:33,970
you want to get back gov heads

1222
01:23:34,220 --> 01:23:36,720
but you got a little bit more than the head i resisted the temptation to

1223
01:23:36,720 --> 01:23:38,600
make the cut through the area

1224
01:23:38,620 --> 01:23:40,660
letting with easier but

1225
01:23:40,700 --> 01:23:42,590
we didn't want to share so

1226
01:23:42,620 --> 01:23:46,720
market in for the show to the problem you have to solve is almost the

1227
01:23:46,720 --> 01:23:52,990
same as the original problem except with this extra annotation which comes into the which

1228
01:23:52,990 --> 01:23:57,760
is sort of brought into the the problem the boundary conditions so you actually take

1229
01:23:57,760 --> 01:24:03,200
some of the the XII values the hidden variables just tie them

1230
01:24:03,260 --> 01:24:05,160
two foreground background or maybe

1231
01:24:05,180 --> 01:24:09,870
encourage them to be in the foreground background by applying extra costs on the graph

1232
01:24:10,010 --> 01:24:13,070
and now you'd like to solve the new graph cut problem here it is the

1233
01:24:13,090 --> 01:24:16,800
offending bit has been removed but it should be much less work

1234
01:24:16,820 --> 01:24:19,740
so the question is can you reuse

1235
01:24:19,760 --> 01:24:22,200
the work that you did before well

1236
01:24:22,220 --> 01:24:23,800
what happens with the

1237
01:24:23,870 --> 01:24:26,430
the first version of the problem is you solve it and then you end up

1238
01:24:26,430 --> 01:24:27,590
with the flood

1239
01:24:27,640 --> 01:24:30,720
you know you because you saw the maximum flow and if you just keep that

1240
01:24:31,700 --> 01:24:36,450
alive is not the same as the as the graphical model but the actual network

1241
01:24:36,450 --> 01:24:38,760
graph you keep that graph don't right away

1242
01:24:38,800 --> 01:24:42,680
the the allocate all those variables whatever you might have done this key that graph

1243
01:24:43,320 --> 01:24:44,930
and when you revisit it

1244
01:24:44,930 --> 01:24:48,510
all you need to do is to just touch few the edges in the graph

1245
01:24:48,640 --> 01:24:50,180
and change the

1246
01:24:50,200 --> 01:24:53,070
the costs on those few edges

1247
01:24:56,120 --> 01:24:56,970
so now

1248
01:24:56,970 --> 01:25:01,220
if you change the course on on a few the edges most of the edges

1249
01:25:01,220 --> 01:25:05,720
have the same cost as before can we somehow use the flow well the worst

1250
01:25:05,720 --> 01:25:10,410
thing that could happen is that you have when you're doing this maximum flow

1251
01:25:10,430 --> 01:25:15,200
the one kind of grammar school the augmenting flow algorithm which is the more as

1252
01:25:15,220 --> 01:25:20,780
the kind described to you know in hand-waving terms one of the rules of augmenting

1253
01:25:20,780 --> 01:25:25,220
flow algorithms is they maintain valid flow at all times never allowed to have an

1254
01:25:25,220 --> 01:25:31,220
intermediate stage where the flow exceeds capacity there are other algorithms like push relabel

1255
01:25:31,930 --> 01:25:36,620
you are actually temporarily allowed to have invented flows with their own temporary eventually they'll

1256
01:25:36,620 --> 01:25:39,820
go away and the reason why you shouldn't do that but in the augmenting flow

1257
01:25:39,820 --> 01:25:45,410
algorithm you'd like the question is can we change the augmenting flow algorithm to work

1258
01:25:45,410 --> 01:25:50,620
with this modified perturbed problem and reusing the old flow or the west could happen

1259
01:25:50,620 --> 01:25:53,950
to you is that you

1260
01:25:53,950 --> 01:25:59,700
change the FIA and FIM zero here five one here and which are the capacities

1261
01:25:59,720 --> 01:26:03,070
and you've now got the capacity which is less

1262
01:26:03,090 --> 01:26:06,300
and the flow you inherited from the previous version of the problem so they are

1263
01:26:06,300 --> 01:26:07,820
in trouble you don't want to do

1264
01:26:07,840 --> 01:26:11,240
i mean the flow is you know what we like is to work on the

1265
01:26:11,240 --> 01:26:15,620
residual graph where the spare capacity and then push extra flow through this through the

1266
01:26:15,620 --> 01:26:19,660
spec capacity so if in fact i had the model the preservation i made was

1267
01:26:19,660 --> 01:26:23,840
increasing the values of costs and all of these ideas you'd be happy be able

1268
01:26:23,840 --> 01:26:28,870
to reuse the old flow the be you opened up some residual capacity by perturbing

1269
01:26:28,870 --> 01:26:33,550
the problem and you just do some more pushing to mop up residual capacity but

1270
01:26:33,550 --> 01:26:34,470
if you

1271
01:26:34,470 --> 01:26:39,120
if instead the modification the problem to reduce some of these costs now you may

1272
01:26:39,120 --> 01:26:44,240
be breaking the constraints and have some flowsin some pipes that exceed capacity this is

1273
01:26:44,240 --> 01:26:46,950
very upsetting i can see you're all very upset

1274
01:26:46,970 --> 01:26:51,640
what can you do that is well it's very easy with vertical

1275
01:26:52,550 --> 01:26:56,720
log likelihood arcs because all you have to do is that same re parameterisation trick

1276
01:26:56,970 --> 01:27:01,950
that we did before i add some constant to this are here enough to make

1277
01:27:01,950 --> 01:27:07,260
the capacity exceeds the flow again providing and the same capacity this arc than the

1278
01:27:07,260 --> 01:27:09,140
original problem is not changed

1279
01:27:09,200 --> 01:27:12,760
and so you can see easily that's going to work and i want to show

1280
01:27:12,760 --> 01:27:14,930
you what to do with the horizontal

1281
01:27:14,950 --> 01:27:16,990
links because that's a little bit more

1282
01:27:17,090 --> 01:27:21,240
complicated but take it from me the same kind of re parameterisation tricks that we

1283
01:27:21,240 --> 01:27:26,300
saw before work there as well and you can switch the

1284
01:27:26,320 --> 01:27:29,490
you can see you can reprogram tries the horizontal

1285
01:27:29,490 --> 01:27:34,800
capacity is to make sure they exceed this flow that you have to start with

1286
01:27:34,820 --> 01:27:35,910
so this was

1287
01:27:35,930 --> 01:27:38,160
he invented by code in talk

1288
01:27:38,180 --> 01:27:40,910
and they did so demonstrated rather nice

1289
01:27:40,930 --> 01:27:42,840
capabilities with it

1290
01:27:42,840 --> 01:27:46,970
so for example suppose you wanted a segment of video like we just work

1291
01:27:47,050 --> 01:27:50,590
and supposing it is the case the things in the video or not

1292
01:27:50,600 --> 01:27:53,740
changing radically fast this is a slow-moving cow

1293
01:27:53,740 --> 01:27:55,320
and so

1294
01:27:55,340 --> 01:27:58,410
one should be able to capitalize on

1295
01:27:58,410 --> 01:28:00,890
the state of the time t

1296
01:28:01,200 --> 01:28:05,570
you know in the same time the character t when trying to solve the problem

1297
01:28:05,570 --> 01:28:06,890
at time t plus one

1298
01:28:06,910 --> 01:28:07,930
so now

1299
01:28:07,930 --> 01:28:10,990
run the video and you see either the real time

1300
01:28:12,410 --> 01:28:13,840
and what you see here

1301
01:28:13,870 --> 01:28:16,220
is the residual flow

1302
01:28:16,240 --> 01:28:20,780
i teach at each time step that needed to be

1303
01:28:22,430 --> 01:28:26,140
what does and you see that you know nothing at all is happening over most

1304
01:28:26,140 --> 01:28:29,430
of the image none of the background is any work being done they will flow

1305
01:28:29,430 --> 01:28:33,100
is being pushed and in the interior and then we'll fly is being pushed the

1306
01:28:33,100 --> 01:28:38,070
only place the flow needs to be pushed is as you'd expect in around the

1307
01:28:38,070 --> 01:28:42,450
silhouette moving to the rest of the of the really is very neat trick and

1308
01:28:42,450 --> 01:28:47,340
that can you save may be a factor of twenty or something about aldrin in

1309
01:28:47,340 --> 01:28:55,600
practical settings with this kind of problem so that's actually a very nice discovery

1310
01:28:56,320 --> 01:29:01,320
don't be sorry

1311
01:29:05,160 --> 01:29:05,840
it's a

1312
01:29:05,860 --> 01:29:09,570
i mean it works with horses as well

1313
01:29:09,620 --> 01:29:13,830
well you know

1314
01:29:13,830 --> 01:29:16,500
green losses which are in short supply of the

1315
01:29:17,390 --> 01:29:21,620
that's the kind of camouflage problem isn't and so

1316
01:29:21,630 --> 01:29:22,420
you know we

1317
01:29:22,470 --> 01:29:25,820
we talked about that yes we agree the camouflage problem is hard of course is

1318
01:29:25,830 --> 01:29:26,570
hard than this one

1319
01:29:26,960 --> 01:29:32,250
and about then the the potts model and the ising model i mean the modified

1320
01:29:32,250 --> 01:29:36,540
ising model country or a because they you know bringing in prior or a data

1321
01:29:36,540 --> 01:29:37,870
modified prior

1322
01:29:37,960 --> 01:29:40,450
that you know

1323
01:29:40,490 --> 01:29:43,960
makes up for some of the ambiguity in the foreground background

1324
01:29:43,960 --> 01:29:47,560
there's no contributions here there is no contribution here

1325
01:29:47,620 --> 01:29:52,520
the electric field is only exist in that's my assumption

1326
01:29:52,530 --> 01:29:55,870
and so the whole thing here

1327
01:29:55,930 --> 01:29:59,660
is now the five

1328
01:29:59,670 --> 01:30:01,480
let's look at our results

1329
01:30:01,510 --> 01:30:03,400
and also by

1330
01:30:03,440 --> 01:30:05,280
and was i are square and

1331
01:30:05,380 --> 01:30:07,550
my cap actually non-zero

1332
01:30:07,590 --> 01:30:10,980
well i get i get new zero times i

1333
01:30:11,010 --> 01:30:12,660
that is truly amazing

1334
01:30:12,690 --> 01:30:14,750
so if i know that we

1335
01:30:14,800 --> 01:30:17,500
equals new zero times i

1336
01:30:17,550 --> 01:30:19,550
divided by two quite

1337
01:30:19,570 --> 01:30:22,100
which is exactly what we had before

1338
01:30:22,160 --> 01:30:24,140
hooray for mister maxwell

1339
01:30:24,180 --> 01:30:28,090
because now it doesn't matter anymore when you take the flat surface

1340
01:30:28,120 --> 01:30:30,500
what do you think the bags of

1341
01:30:30,550 --> 01:30:32,430
you know get the same answer

1342
01:30:32,480 --> 01:30:35,160
in one case there is no contribution

1343
01:30:35,170 --> 01:30:37,050
from the displacement

1344
01:30:37,050 --> 01:30:38,020
current term

1345
01:30:38,030 --> 01:30:41,630
and in that case there is no contribution from the first

1346
01:30:41,640 --> 01:30:46,600
the real current

1347
01:30:46,670 --> 01:30:49,800
make sure what i'm happy with my results

1348
01:30:51,170 --> 01:30:53,930
i think that's fine

1349
01:30:53,980 --> 01:30:57,090
we can also go one step further

1350
01:30:57,100 --> 01:30:59,260
and we can calculate

1351
01:30:59,270 --> 01:31:00,980
anywhere in between

1352
01:31:01,000 --> 01:31:02,340
the capacitor

1353
01:31:02,470 --> 01:31:04,580
what the

1354
01:31:04,620 --> 01:31:07,700
magnetic field is

1355
01:31:07,760 --> 01:31:10,450
make another drawing of the capacitor

1356
01:31:10,550 --> 01:31:12,030
right here

1357
01:31:12,040 --> 01:31:15,260
i have this feel that will not repeat that every time

1358
01:31:15,300 --> 01:31:17,420
you have my point p two now

1359
01:31:17,430 --> 01:31:19,280
which is inside

1360
01:31:19,300 --> 01:31:20,530
the capacitor

1361
01:31:20,540 --> 01:31:22,430
and radius there are

1362
01:31:22,470 --> 01:31:24,300
from the centre

1363
01:31:24,320 --> 01:31:25,910
and this is capital are

1364
01:31:25,990 --> 01:31:29,970
circular plates

1365
01:31:29,980 --> 01:31:33,090
i have here my close

1366
01:31:33,100 --> 01:31:34,330
the circle

1367
01:31:34,370 --> 01:31:36,420
radius there are

1368
01:31:36,430 --> 01:31:37,930
i apply now

1369
01:31:37,940 --> 01:31:39,570
the new law

1370
01:31:41,380 --> 01:31:42,720
i to buy are

1371
01:31:42,730 --> 01:31:47,410
there we go we have museo we have an absolute non-zero we have a cap

1372
01:31:48,670 --> 01:31:52,470
there is no current going through year so it's non-negotiable i plan is zero right

1373
01:31:52,480 --> 01:31:54,690
it's not even an issue

1374
01:31:54,700 --> 01:31:57,060
so we get new zero

1375
01:31:57,190 --> 01:31:59,180
actually non-zero

1376
01:31:59,290 --> 01:32:02,370
i get kappa

1377
01:32:02,480 --> 01:32:05,320
now the surface area

1378
01:32:05,410 --> 01:32:06,820
right here

1379
01:32:06,930 --> 01:32:09,530
it's not pi capital are square

1380
01:32:09,560 --> 01:32:10,780
where is an

1381
01:32:10,820 --> 01:32:14,810
changing electric fields but it is only by large square

1382
01:32:14,900 --> 01:32:17,750
take a flat surface now

1383
01:32:17,760 --> 01:32:19,780
so now we multiply this

1384
01:32:19,820 --> 01:32:22,310
but by the large screen

1385
01:32:22,370 --> 01:32:25,450
and then of course the genes in the same

1386
01:32:25,460 --> 01:32:26,920
so we get our

1387
01:32:26,930 --> 01:32:28,380
current i

1388
01:32:29,980 --> 01:32:30,890
divided by

1389
01:32:30,910 --> 01:32:33,130
by capital are created

1390
01:32:33,170 --> 01:32:37,040
divided by kappa actually non-zero

1391
01:32:37,220 --> 01:32:41,580
and now you again losing lots

1392
01:32:41,630 --> 01:32:43,670
you lose your actually non-zero

1393
01:32:43,700 --> 01:32:46,430
which are kept

1394
01:32:46,460 --> 01:32:51,550
the idea is that by

1395
01:32:51,580 --> 01:32:53,800
and i kind of little or you have

1396
01:32:53,800 --> 01:32:56,590
they are square there

1397
01:32:56,630 --> 01:32:59,200
now we're going to get the results

1398
01:32:59,260 --> 01:33:02,430
something that you may actually have anticipated

1399
01:33:02,430 --> 01:33:04,810
namely together

1400
01:33:04,870 --> 01:33:08,040
field inside the capacity is growing

1401
01:33:08,050 --> 01:33:10,550
we are

1402
01:33:10,560 --> 01:33:12,780
because i make up my balance

1403
01:33:12,820 --> 01:33:17,290
i get upstairs museo times i

1404
01:33:17,290 --> 01:33:23,060
but i get one little stations you are square you you are here

1405
01:33:25,050 --> 01:33:27,040
i get to my

1406
01:33:27,040 --> 01:33:29,710
and i get a

1407
01:33:29,780 --> 01:33:33,500
capitol are squared i believe that correct

1408
01:33:33,560 --> 01:33:35,790
the check my notes

1409
01:33:35,910 --> 01:33:38,840
yes i'm happy with that

1410
01:33:38,850 --> 01:33:44,900
and this is proportional was little are

1411
01:33:46,860 --> 01:33:50,280
falling off one of or

1412
01:33:50,340 --> 01:33:52,890
and so i can make a plot

1413
01:33:52,900 --> 01:33:55,810
of the magnetic field as a function of the heart

1414
01:33:55,870 --> 01:34:01,040
when i'm inside the capacitor plates

1415
01:34:02,590 --> 01:34:05,780
because the magnetic field

1416
01:34:05,860 --> 01:34:12,180
this is the radius of the capacitor plates

1417
01:34:12,270 --> 01:34:14,100
the straight line

1418
01:34:14,190 --> 01:34:16,150
to that point

1419
01:34:16,190 --> 01:34:20,490
and then it will fall as one of the are

1420
01:34:20,510 --> 01:34:23,590
you can do your own work and that that is very trivial

1421
01:34:23,660 --> 01:34:27,070
to calculate to demonstrate that value

1422
01:34:27,140 --> 01:34:30,360
go beyond the edge of the capacitor

1423
01:34:30,410 --> 01:34:32,580
then it falls off as one of our

1424
01:34:32,590 --> 01:34:34,170
in the same way that

1425
01:34:34,190 --> 01:34:37,250
o point one is doing

1426
01:34:37,260 --> 01:34:41,720
so now we have the tools to calculate the magnetic field even inside capacitors

1427
01:34:41,790 --> 01:34:47,410
well we were charging which we didn't have before

1428
01:34:47,410 --> 01:34:50,840
the strength here the maximum magnetic field here

1429
01:34:50,890 --> 01:34:53,480
you find by substituting in there

1430
01:34:53,500 --> 01:34:56,170
four that are capital are

1431
01:34:56,220 --> 01:34:59,200
and when you do that it becomes capital are

1432
01:34:59,260 --> 01:35:02,930
this becomes one of capitol are

1433
01:35:02,930 --> 01:35:06,510
if you substituted in year for the lower capital or you will find the same

1434
01:35:12,690 --> 01:35:15,030
this part

1435
01:35:15,040 --> 01:35:18,210
it's not kosher cannot be correct

1436
01:35:18,230 --> 01:35:20,990
and i cannot make it right for you

1437
01:35:21,000 --> 01:35:23,670
and the reason why that part cannot be kosher

1438
01:35:23,700 --> 01:35:26,690
it's because we have made this assumption which is wrong

1439
01:35:26,710 --> 01:35:28,780
there is no friends

1440
01:35:28,790 --> 01:35:31,200
so we have something of calculations

1441
01:35:31,260 --> 01:35:33,650
that the electric field is only here

1442
01:35:33,660 --> 01:35:40,170
and there but it's zero user there's nothing known each year no changing magnetic electric

1443
01:35:40,170 --> 01:35:42,370
flux and that's not true

1444
01:35:42,430 --> 01:35:43,450
so clearly

1445
01:35:43,460 --> 01:35:45,820
when you get close to the edge

1446
01:35:45,860 --> 01:35:47,830
this is not correct

1447
01:35:47,900 --> 01:35:50,920
there's no way i can correct for that because the french fields will be different

1448
01:35:50,920 --> 01:35:52,940
from capacity capacity

1449
01:35:53,000 --> 01:35:55,310
and those calculations support

1450
01:35:55,310 --> 01:36:02,680
very easy to make

1451
01:36:02,780 --> 01:36:07,430
maxwell had to introduced his displacement current term

1452
01:36:07,480 --> 01:36:11,820
a very smart man he predicted that as a consequence of that term

1453
01:36:11,860 --> 01:36:15,120
the radio waves should exists

1454
01:36:15,130 --> 01:36:18,730
it was the time that we denote radio waves exist

1455
01:36:18,780 --> 01:36:20,930
he predicted the existence

1456
01:36:20,940 --> 01:36:23,690
but not only did he predict the existence

1457
01:36:23,830 --> 01:36:25,390
he was able

1458
01:36:25,390 --> 01:36:27,560
to calculate what this means

1459
01:36:27,610 --> 01:36:29,570
it's going to be

1460
01:36:29,620 --> 01:36:31,420
recall that the speed of light

1461
01:36:31,420 --> 01:36:33,480
let's which you and now we

1462
01:36:33,490 --> 01:36:36,340
consider what happens if we take the view of

1463
01:36:36,380 --> 01:36:39,140
knowledge representation of ontologies

1464
01:36:39,380 --> 01:36:44,890
and we know what ontologies impose constraints on the data and the actual data that

1465
01:36:44,910 --> 01:36:49,330
we have may be incomplete or inconsistent with respect to these constraints

1466
01:36:49,340 --> 01:36:53,570
and the point is that you want to take into account constraints while answering queries

1467
01:36:53,570 --> 01:36:56,530
so we cannot forget about them as is done in databases

1468
01:36:56,540 --> 01:36:58,580
and so p answering is not anymore

1469
01:36:58,600 --> 01:37:04,480
the evaluation criterion corresponds to performing logical inference which is a much more computationally costly

1470
01:37:05,430 --> 01:37:08,250
and notice that this is possible by

1471
01:37:08,370 --> 01:37:12,440
this is headed by current system because people the size of data is not so

1472
01:37:12,440 --> 01:37:15,810
critical we don't have huge amounts of data

1473
01:37:15,860 --> 01:37:22,190
and also generally which is considered to be seen so simple class expressions not complex

1474
01:37:22,190 --> 01:37:26,940
queries that's why current systems able to deal with although i mean the technologies is

1475
01:37:26,950 --> 01:37:33,010
is advancing let's look again victoria this situation are now have left he mo an

1476
01:37:33,010 --> 01:37:37,040
ontology there been used to together with reason to design the largest schema

1477
01:37:37,060 --> 01:37:42,510
but now the opposed over the ontology and we want to answer these queries and

1478
01:37:42,510 --> 01:37:45,530
the point is that in order to answer queries we have to reason over the

1479
01:37:45,530 --> 01:37:49,620
whole amount of information that we have to reason with the scheme and the ontology

1480
01:37:49,940 --> 01:37:53,770
to reason also over the data the data comes into play when reasoning and that's

1481
01:37:53,820 --> 01:37:57,160
the that's the problematic issue in general

1482
01:37:57,160 --> 01:38:00,330
let's look at

1483
01:38:00,350 --> 01:38:05,920
take up again our over variational for simple example where we now have the

1484
01:38:05,930 --> 01:38:07,460
the ontology of view

1485
01:38:07,480 --> 01:38:12,080
again the faculties professors in colleges and faculties work for colleges but now

1486
01:38:12,100 --> 01:38:16,770
we assume that at query answering time we want to take into account the ontology

1487
01:38:16,820 --> 01:38:20,500
you have again information notice that now the data in

1488
01:38:20,530 --> 01:38:25,630
read in the in the relational table database may not be completely may be incompletely

1489
01:38:25,630 --> 01:38:27,330
specified and for some

1490
01:38:27,390 --> 01:38:32,070
class properties we may not even have a table for example is not a faculty

1491
01:38:32,070 --> 01:38:35,690
home can we just have you know the john except professors there may be additional

1492
01:38:35,690 --> 01:38:39,250
professors we don't know who but we know these two plot professors we know that

1493
01:38:39,250 --> 01:38:41,820
college encouraged apologies and we know that

1494
01:38:41,970 --> 01:38:46,110
john for college a methodist college b but there may be additional information that is

1495
01:38:46,110 --> 01:38:48,260
not explicitly represented

1496
01:38:48,760 --> 01:38:51,690
and now we are very simple query asking give me

1497
01:38:51,710 --> 01:38:55,240
the members of those that are faculty members

1498
01:38:55,280 --> 01:38:56,470
i notice there is no

1499
01:38:56,470 --> 01:39:01,030
data about faculty members now let's see what happens in this case in our system

1500
01:39:01,080 --> 01:39:02,360
so now

1501
01:39:02,930 --> 01:39:07,920
by enabling reasoning so we exploiting now the information that we haven't seen before

1502
01:39:07,920 --> 01:39:11,390
in the ontology to answer this query and i see

1503
01:39:11,410 --> 01:39:12,280
we get

1504
01:39:12,300 --> 01:39:15,300
some sort of page on marinade

1505
01:39:15,350 --> 01:39:19,870
now let's look at why we get john many here here we don't we were

1506
01:39:19,870 --> 01:39:24,130
asking for faculty members john many can not listed as faculty members why do we

1507
01:39:25,820 --> 01:39:30,160
any any any clue why we get these answers why do we get john

1508
01:39:30,170 --> 01:39:33,460
once once it

1509
01:39:33,470 --> 01:39:36,330
what do we get john

1510
01:39:36,360 --> 01:39:39,140
i was surprised and not surprised

1511
01:39:39,280 --> 01:39:43,390
no one is surprised look for these was easy you surprised

1512
01:39:43,450 --> 01:39:45,200
no OK we

1513
01:39:49,720 --> 01:39:53,520
so you have to ask

1514
01:39:53,530 --> 01:39:57,200
OK this is the usual thing so

1515
01:39:57,520 --> 01:40:01,040
and no exactly

1516
01:40:02,700 --> 01:40:06,990
let's see what we get john it's also difficult john is is listed the professor

1517
01:40:07,020 --> 01:40:11,810
the ontology these professors faculty member so if you ask faculty members we expect to

1518
01:40:11,810 --> 01:40:14,940
get john and the same funny

1519
01:40:14,950 --> 01:40:17,690
get john because of these reasons now

1520
01:40:17,790 --> 01:40:21,340
question is married is professor why do we get married

1521
01:40:21,420 --> 01:40:27,410
this is also seen but maybe not so immediate what we get now

1522
01:40:27,420 --> 01:40:28,430
once once

1523
01:40:28,450 --> 01:40:36,390
exactly works for is a relation is a property whose domains faculty so we know

1524
01:40:36,390 --> 01:40:40,770
that whoever is in the domain of the works for property should all be a

1525
01:40:40,770 --> 01:40:45,030
faculty member and mary by the way here so we should expect to get married

1526
01:40:45,030 --> 01:40:49,130
as a member of faculty and that's what our system actually that's so we see

1527
01:40:49,850 --> 01:40:51,540
we have works for

1528
01:40:51,560 --> 01:40:56,630
property whose domain is a faculty and that's why we get married announced

1529
01:40:56,640 --> 01:41:01,330
now let's look at a bit more interesting example a bit more complex

1530
01:41:01,350 --> 01:41:07,560
this is again omitted toys schema just illustrate the

1531
01:41:08,720 --> 01:41:13,950
the basic notions so we have an ontology that just talked about persons and each

1532
01:41:13,950 --> 01:41:18,360
person has a father who is again the person who gets what ontology expresses this

1533
01:41:18,390 --> 01:41:21,270
one he expresses that each person has a father

1534
01:41:21,280 --> 01:41:25,860
and then we know some persons and we know some father of

1535
01:41:25,880 --> 01:41:28,000
person father relation john

1536
01:41:28,000 --> 01:41:32,020
five is an economics finance tony and johnny cantoni persons now

1537
01:41:32,030 --> 01:41:33,780
we are asking for the bears

1538
01:41:33,820 --> 01:41:35,960
x and y such that x is father

1539
01:41:35,990 --> 01:41:39,050
such access father y

1540
01:41:39,070 --> 01:41:41,250
what do you expect to get here

1541
01:41:41,250 --> 01:41:43,440
let's see what the system here

1542
01:41:43,450 --> 01:41:48,430
so we get to top

1543
01:41:48,450 --> 01:41:52,680
you get john in economic and tony surprise surprise you get exactly what we had

1544
01:41:52,690 --> 01:41:54,210
asserted as

1545
01:41:54,240 --> 01:41:56,490
explicit information in our

1546
01:41:56,500 --> 01:42:00,080
in our database let's say OK now a box

1547
01:42:00,110 --> 01:42:04,500
the system in this case is not able to infer information to get this expresses

1548
01:42:04,510 --> 01:42:10,080
adopted but it cannot infer new information knowledge cl slightly different query query looks very

1549
01:42:10,080 --> 01:42:14,130
much similar but now we are not asking for the pairs x y just asking

1550
01:42:14,130 --> 01:42:18,940
for those persons x that have some father but not interested in the father of

1551
01:42:18,950 --> 01:42:21,500
now let's see what we get is an answer here

1552
01:42:24,340 --> 01:42:28,760
now we get three doctors care and you see now get also tony

1553
01:42:28,760 --> 01:42:34,140
as the first component of answer we didn't have to only before someone returned in

1554
01:42:34,160 --> 01:42:37,050
the pair why do we get only here

1555
01:42:37,080 --> 01:42:41,100
i mean it's similar to the argument that we had before we get only because

1556
01:42:41,120 --> 01:42:42,860
we know that every person

1557
01:42:42,870 --> 01:42:47,570
should have fathered by ontology has father although we don't know the father

1558
01:42:47,680 --> 01:42:51,050
of tony we know that since he is the person he will have someone who

1559
01:42:51,050 --> 01:42:55,300
is his father here and that's why he's returned as an answer to the query

1560
01:42:55,320 --> 01:42:57,410
now let

1561
01:42:57,410 --> 01:43:00,730
go on let's look at a bit more complex queries

1562
01:43:00,780 --> 01:43:05,920
we are now asking for persons for which we have a chain of ancestors

1563
01:43:05,950 --> 01:43:09,740
so x which show some wide it is that is the father of x

1564
01:43:09,750 --> 01:43:13,120
for some y one this part of x and y two years followed by one

1565
01:43:13,120 --> 01:43:13,860
well look

1566
01:43:19,670 --> 01:43:20,460
adds up to six

1567
01:43:21,120 --> 01:43:24,940
we found the submarine without which number sixty three

1568
01:43:26,450 --> 01:43:27,680
the computer was thinking of

1569
01:43:28,180 --> 01:43:30,590
and why come to such a beautiful random numbers

1570
01:43:31,570 --> 01:43:32,920
some special coincidence

1571
01:43:33,340 --> 01:43:35,540
what is it always happens well let's just

1572
01:43:36,570 --> 01:43:38,800
check reporter cancel this semester

1573
01:43:38,880 --> 01:43:39,230
this and the

1574
01:43:42,700 --> 01:43:45,890
this and this and this and this and this is the

1575
01:43:47,950 --> 01:43:48,300
and this

1576
01:43:48,790 --> 01:43:53,370
and this so the answer is always gonna come out once you've found

1577
01:43:54,530 --> 01:43:55,100
the submarine

1578
01:43:55,820 --> 01:43:56,600
a lot landscape

1579
01:43:57,480 --> 01:43:57,750
thank you

1580
01:43:58,750 --> 01:43:59,710
you know it makes

1581
01:44:03,430 --> 01:44:04,280
have no proof

1582
01:44:04,710 --> 01:44:08,960
but it's a nice little bit evidence that maybe this logo one over pete thing

1583
01:44:08,960 --> 01:44:10,570
which looked a bit strange at beginning

1584
01:44:10,970 --> 01:44:12,070
maybe that's the right way

1585
01:44:12,490 --> 01:44:14,440
to measure how much information you get

1586
01:44:14,880 --> 01:44:15,740
when something happens

1587
01:44:16,970 --> 01:44:17,740
do you want to play again

1588
01:44:18,730 --> 01:44:21,180
maybe not i think we got arrested any questions

1589
01:44:25,630 --> 01:44:26,360
so that's what

1590
01:44:27,330 --> 01:44:28,710
now let's do then collaborate

1591
01:44:30,660 --> 01:44:33,050
the question is the mafia boss tells you you

1592
01:44:34,070 --> 01:44:35,250
two but i tickets

1593
01:44:37,040 --> 01:44:38,930
the outcome is going be the stream

1594
01:44:39,510 --> 01:44:41,730
is obtained when the coin is tossed

1595
01:44:42,240 --> 01:44:44,320
one thousand times as the bent coin

1596
01:44:46,300 --> 01:44:50,150
raag heads and common tales was are very few ones

1597
01:44:51,800 --> 01:44:54,690
you can buy any that it is you want from the box office

1598
01:44:55,690 --> 01:44:56,120
if you

1599
01:44:56,900 --> 01:44:59,650
do we need it then you get exactly in pounds

1600
01:45:00,570 --> 01:45:02,180
and the mafia was forces you to buy

1601
01:45:03,440 --> 01:45:06,010
lotto the tickets and that have a ninety nine percent chance

1602
01:45:06,420 --> 01:45:10,830
and questions i'm going to ask you first if instead the rules you just being

1603
01:45:10,830 --> 01:45:13,750
forced by one ticket so got pound forced

1604
01:45:14,160 --> 01:45:16,960
to go and spend it which take it would you buy

1605
01:45:17,830 --> 01:45:19,200
have the best chance of winning

1606
01:45:20,710 --> 01:45:24,440
question two is gonna be having ninety nine percent and winning which tickets with you by

1607
01:45:24,850 --> 01:45:26,250
and how many tickets is back

1608
01:45:27,040 --> 01:45:31,480
and please express your form in your answer in the form to the power something okay

1609
01:45:31,870 --> 01:45:33,520
so that's the really questions for you

1610
01:45:34,080 --> 01:45:35,470
please contact with your neighbour

1611
01:45:35,960 --> 01:45:37,940
and so all of these questions

1612
01:45:38,880 --> 01:45:39,550
our what the world

1613
01:45:42,980 --> 01:45:45,470
okay let's start with a simple question

1614
01:45:45,910 --> 01:45:48,390
you're forced to buy one ticket from the shop

1615
01:45:51,200 --> 01:45:52,100
would you buy

1616
01:45:53,390 --> 01:45:53,920
they on

1617
01:45:58,120 --> 01:45:58,760
the only

1618
01:46:09,970 --> 01:46:11,430
and on wanted different ticket

1619
01:46:22,710 --> 01:46:24,100
one nine hundred zero

1620
01:46:25,250 --> 01:46:26,540
i one hundred one

1621
01:46:31,740 --> 01:46:32,350
i feel the

1622
01:46:34,750 --> 01:46:36,780
anne which one would you

1623
01:46:37,220 --> 01:46:37,540
would you buy

1624
01:46:38,750 --> 01:46:39,450
which these

1625
01:46:43,740 --> 01:46:44,320
you don't mind

1626
01:46:44,930 --> 01:46:46,050
that's all people employed

1627
01:47:01,030 --> 01:47:03,650
are you happy with this choice would you like a different one

1628
01:47:06,030 --> 01:47:06,350
so do you

1629
01:47:11,160 --> 01:47:12,650
you like most spread out again

1630
01:47:12,650 --> 01:47:16,760
will feel free space I call this the milk carton problem how many different shapes

1631
01:47:16,760 --> 01:47:21,120
of milk cartons could you make the dimethyl truck perfectly and he came up with

1632
01:47:21,120 --> 01:47:22,220
7 of

1633
01:47:22,380 --> 01:47:26,980
7 and a lot of getting ahead of myself there the 7 of them were

1634
01:47:26,990 --> 01:47:31,290
shown here this is in your in your notes and these are the labels for

1635
01:47:31,290 --> 01:47:35,980
the visit here is the basic unit so you have 3 lengths ABC and have

1636
01:47:35,980 --> 01:47:40,690
3 angles alpha beta and gamma and depending on which makes you choose for example

1637
01:47:40,690 --> 01:47:46,500
the Cuba's here a equals B equals 3 in edges all normal to 1 another

1638
01:47:46,500 --> 01:47:50,130
and then here's the author Robert they're not equal to each other and so

1639
01:47:50,820 --> 01:47:52,380
so 7 basic shapes

1640
01:47:53,720 --> 01:47:56,960
and here they are drawn for you and this is taken of the lecture notes

1641
01:47:57,600 --> 01:47:59,310
the archive lecture notes

1642
01:48:00,480 --> 01:48:05,220
this is analogous to the the tiling problem to drive home the point that you

1643
01:48:05,220 --> 01:48:08,810
wanted to the tiling problem how many distinct shapes of tiles

1644
01:48:09,060 --> 01:48:11,400
farther into space

1645
01:48:11,580 --> 01:48:16,590
so I think we can agree we can go with square tiles or we can

1646
01:48:16,610 --> 01:48:19,120
go with the entanglement tiles What other tiles we have

1647
01:48:20,180 --> 01:48:27,480
triangle triangle is actually it's not a basic unit because I can't it doesn't observe

1648
01:48:27,500 --> 01:48:32,780
translational symmetry but if I close the triangle like there's never 60 degrees and this

1649
01:48:32,780 --> 01:48:39,080
will become the basis repeat unit OK then there's a regular the parallel pipe where

1650
01:48:39,080 --> 01:48:43,680
this unit in angle rather is not equal to 60 degrees and this effect is

1651
01:48:43,680 --> 01:48:47,420
the basic unit the frank gary users in building is if you go over to

1652
01:48:47,430 --> 01:48:52,280
the the status that you will see that the basic unit that's used to make

1653
01:48:52,280 --> 01:48:54,840
those irregular shapes is this

1654
01:48:54,960 --> 01:48:58,140
was a space-filling and that all of these are labeled and so on this is

1655
01:48:58,140 --> 01:49:01,920
the clothing problem will how do you cut a two-dimensional piece of cloth to fit

1656
01:49:01,920 --> 01:49:08,570
over 3 dimensional shape nontrivial problem has worked was closed off that this is a

1657
01:49:08,570 --> 01:49:13,040
very simple fashion designers don't understand the simple geometry

1658
01:49:13,220 --> 01:49:17,900
and we have a we describe size and for for men at least take a

1659
01:49:17,900 --> 01:49:24,780
chastising size for women go she's 8 1 8 1 number and this is why

1660
01:49:24,780 --> 01:49:28,680
things don't forget you have to get down to the unit cell

1661
01:49:29,410 --> 01:49:34,840
here's 1 that will work at the Pentagon won't work and I'm not trying to

1662
01:49:34,840 --> 01:49:38,010
make a political statement simply saying

1663
01:49:38,030 --> 01:49:40,930
so here's what you can do is is if you here's what happens if you

1664
01:49:40,930 --> 01:49:45,680
try to filter space with the Pentagon you see disabled but up there's these white

1665
01:49:45,680 --> 01:49:50,500
gaps the reds touch the Reds but it will fail so this is how always

1666
01:49:50,500 --> 01:49:55,240
work in free space and determined that certain units will not bought up against 1

1667
01:49:55,240 --> 01:49:57,710
another and feel free space perfect

1668
01:49:58,160 --> 01:50:02,440
OK so we're click and things are going well but we still haven't got atomic

1669
01:50:02,440 --> 01:50:06,520
erasures all we got his milk cartons so far so now let's think about the

1670
01:50:06,520 --> 01:50:09,840
next the next step step came

1671
01:50:10,250 --> 01:50:12,060
about 50 years later

1672
01:50:12,060 --> 01:50:17,650
but 1848 which was an auspicious here and in Europe there was another frenchman was

1673
01:50:18,840 --> 01:50:24,450
and that he proved mathematically that there are 14 distinct ways to arrange points in

1674
01:50:24,450 --> 01:50:28,580
space and what do I mean by that there's a cartoon that shows a

1675
01:50:28,650 --> 01:50:29,620
the cube

1676
01:50:29,620 --> 01:50:33,690
we've agreed that the cubism cookie-cutter that will fill 3 space

1677
01:50:33,750 --> 01:50:39,280
but when I start putting atoms in the cube I have 3 distinguishable arrangements so

1678
01:50:39,280 --> 01:50:43,710
here on the left I have something where I put Adams only on the corners

1679
01:50:43,960 --> 01:50:47,440
and the 2nd 1 I . atoms on the corners and 1 in the center

1680
01:50:47,440 --> 01:50:51,280
nothing look at the 1 in the center that 1 of the centers sees 8

1681
01:50:51,290 --> 01:50:53,580
nearest neighbors each 1 of these sea

1682
01:50:53,580 --> 01:50:58,670
only 6 nearest neighbors so these atoms have a different

1683
01:50:58,690 --> 01:51:04,710
Adam arrangements a different Adam environment from the atoms and this arrangement so the last

1684
01:51:04,710 --> 01:51:09,190
1 is called simple cubic the center 1 is called body centered cubic because there's

1685
01:51:09,190 --> 01:51:12,340
an atom in the center and it doesn't matter I can arbitrarily shift the center

1686
01:51:12,340 --> 01:51:17,470
of discourse in this corner Random sees the same nearest neighbors in the same arrangement

1687
01:51:17,610 --> 01:51:18,690
relative to the center

1688
01:51:19,830 --> 01:51:22,180
there's a body centered cubic

1689
01:51:22,340 --> 01:51:25,970
choose any 1 of those if I sit here in the center of the 1

1690
01:51:25,970 --> 01:51:29,910
2 3 4 5 6 7 8 or I can go to this 1 over

1691
01:51:29,910 --> 01:51:34,910
here vertices 1 2 3 4 and you just keep going the same arrangement and

1692
01:51:34,910 --> 01:51:39,950
yet that's the cookie cutter that fill spaces the acute there's 1 other possibility and

1693
01:51:39,950 --> 01:51:45,380
that's face centered cubic face centered cubic is here where you have this this

1694
01:51:45,380 --> 01:51:48,930
the square face that atom in the center of each face

1695
01:51:49,020 --> 01:51:53,430
and that's distinguishable that's so

1696
01:51:53,470 --> 01:51:59,970
brother again frenchman steeped in math goes into the mathematics and ask how many different

1697
01:51:59,970 --> 01:52:08,250
ways can I put Adams into these 7 crystal systems that only has specified and

1698
01:52:08,250 --> 01:52:16,630
get distinguishable . environment and the answer is 14 the 14 14 ways to arrange

1699
01:52:16,820 --> 01:52:18,280
points in space

1700
01:52:19,080 --> 01:52:23,500
so now we're getting somewhere now we're getting somewhere by the way if you look

1701
01:52:23,500 --> 01:52:29,120
at this object here the 14 different brevity lattice as

1702
01:52:29,130 --> 01:52:33,560
and the shown this is also from the lecture notes and all putting here is

1703
01:52:33,560 --> 01:52:37,970
1 . and each lattice point but it doesn't have to be a adopted because

1704
01:52:38,130 --> 01:52:42,090
was showing a 2nd is I can put sets of atoms groups of atoms in

1705
01:52:42,130 --> 01:52:46,430
other words if I wanted to describe what the positions of every apple in orchard

1706
01:52:46,710 --> 01:52:51,950
what I could do is say that the bond that the brevity lattice is telling

1707
01:52:51,960 --> 01:52:54,280
me the planting of the trees

1708
01:52:54,560 --> 01:53:00,100
and then I can hang different for different types of Apple arrangements at each point

1709
01:53:00,300 --> 01:53:02,880
so that's what we're going to we're trying to break this down otherwise you're going

1710
01:53:02,900 --> 01:53:08,050
have a gazillion different atomic arrangements were able to do is confined everything to a

1711
01:53:08,050 --> 01:53:09,450
simple set of 14

1712
01:53:10,200 --> 01:53:14,560
so what I wanna do now is show that we can look at different sets

1713
01:53:14,560 --> 01:53:19,360
of elements that these at these points so it's good to see what happens if

1714
01:53:19,360 --> 01:53:25,960
we look at face centered cubic input different atomic groupings air at each point so

1715
01:53:25,960 --> 01:53:32,200
ultimately what I'm in search of is the crystal structure the crystal structure and the

1716
01:53:32,200 --> 01:53:42,200
crystal structure is the atomic arrangement in 3 space atomic arrangement and the crystal structure

1717
01:53:42,360 --> 01:53:50,820
is the sum of 2 components 1st is the brevity lattice gravity lattice what the

1718
01:53:50,820 --> 01:53:58,970
brevity lattices it's really just a point environment it's a point environment but not including

1719
01:53:59,170 --> 01:54:04,420
want the point including nothing American make this sequel John Cage penalties in just the

1720
01:54:04,430 --> 01:54:09,320
point arrests of different time signatures from time

1721
01:54:09,320 --> 01:54:16,430
you compare this with this it's not based upon sonnet 57 because 1 of only

1722
01:54:16,470 --> 01:54:22,820
57 this is really really good and I mean I would just give it because

1723
01:54:22,820 --> 01:54:27,060
he wrote assigned but there were some of the key points here you see in

1724
01:54:27,060 --> 01:54:33,370
mentioned smelting amazon extracted metallurgists that took the case make sense melting ice and you

1725
01:54:33,380 --> 01:54:35,580
guys so

1726
01:54:36,040 --> 01:54:38,000
I think this is something to

1727
01:54:38,580 --> 01:54:45,320
to think about the way before we go to the place OK so the contest

1728
01:54:45,620 --> 01:54:50,520
there is the prices are necktie's and as

1729
01:54:50,660 --> 01:54:58,810
starts with the they're they're very hot the black with a colored elements of the

1730
01:54:58,810 --> 01:55:05,840
periodic table so very nice level bring samples next day they're really look sharp very

1731
01:55:05,840 --> 01:55:10,220
sharp you know there's all kinds of gift-giving coming down the road you never know

1732
01:55:10,220 --> 01:55:17,420
when 1 of these could just do the trick but so don't fail to enter

1733
01:55:17,920 --> 01:55:24,250
and I will have office hours today uh starting both 330 to 431 tomorrow if

1734
01:55:24,250 --> 01:55:28,490
you want to see me by all means go during a recitation structure that as

1735
01:55:28,490 --> 01:55:34,540
well so last day we were looking at similarly but taxonomy and then on to

1736
01:55:34,540 --> 01:55:39,300
a little bit more about the interior of the atom we looked at the representation

1737
01:55:39,300 --> 01:55:43,110
of elements in the periodic table where we have the proton number z which is

1738
01:55:43,110 --> 01:55:47,660
equal to the number of electrons in the neutral atom and the atomic mass which

1739
01:55:47,660 --> 01:55:54,720
is the sum of the proton number and the neutron number we talked about isotopes

1740
01:55:54,720 --> 01:56:01,750
and and what today I want to continue so far we've been looking at static

1741
01:56:01,750 --> 01:56:08,480
elements but most people think of chemistry as involving reactions so let's look at the

1742
01:56:08,480 --> 01:56:15,310
dynamics reactions between chemicals and we describe chemical reaction what are the rules about the

1743
01:56:15,320 --> 01:56:18,810
1st thing you do is you write an equation the equation is subject to these

1744
01:56:18,810 --> 01:56:28,870
constraints 1st of all we involve Dalton's law we invoke Dalton's law of molar proportions

1745
01:56:28,870 --> 01:56:32,450
Dalton's law of small proportion

1746
01:56:32,480 --> 01:56:44,110
and secondly we write subject to conservation of mass conservation of matter I mean literally

1747
01:56:44,550 --> 01:56:52,360
mass not mall number analysts look this is probably best seen by example so it's

1748
01:56:52,360 --> 01:56:55,090
look at a simple 1 this is the calcination of

1749
01:56:55,860 --> 01:57:02,930
limestone limestone is calcium carbonate and about 900 degrees centigrade

1750
01:57:03,440 --> 01:57:11,960
calcium carbonate decomposes to give line for calcium oxide plus of carbon dioxide and this

1751
01:57:11,960 --> 01:57:17,000
is used as the 1st step for making a cement concrete and so on and

1752
01:57:17,000 --> 01:57:22,700
so when you think about how much cement concrete are consumed annually on the planet

1753
01:57:23,050 --> 01:57:30,280
this becomes a considerable source point source of greenhouse gas emissions is you know carbon

1754
01:57:30,280 --> 01:57:35,470
dioxide is implicated as greenhouse gas and there's a huge amount of

1755
01:57:35,740 --> 01:57:41,720
of C O 2 that comes from this process that is also used in steelmaking

1756
01:57:41,720 --> 01:57:47,110
and so so anything on the left side of the equation is called the reactant

1757
01:57:47,450 --> 01:57:51,780
anything on the right side of the equation is called the products of the products

1758
01:57:52,070 --> 01:57:58,280
react to give us reactants in distance shows some of the hitting a balance here

1759
01:57:58,280 --> 01:58:01,220
here we have 1 mole I don't put a 1 in front we just take

1760
01:58:01,220 --> 01:58:05,740
1 for granted so there's 1 mole of calcium carbonate that gives us 1 mole

1761
01:58:05,800 --> 01:58:13,250
of calcium oxide and 1 mole of carbon dioxide and so

1762
01:58:13,950 --> 01:58:17,870
here we have 2 moles and here we have 1 mole so what's the conservation

1763
01:58:17,870 --> 01:58:23,360
of mass if we divide by the atomic masses here we will get a 100

1764
01:58:23,360 --> 01:58:29,370
. 1 grams of calcium carbonate and then discovered that we have 56 . 1

1765
01:58:29,370 --> 01:58:38,340
grams of calcium oxide and 44 grams of carbon dioxide so clearly masses conserve not

1766
01:58:38,530 --> 01:58:43,610
numbers and if you have trouble balancing equations you can look in Section 2 .

1767
01:58:43,610 --> 01:58:45,980
1 1 in the text and they go through some

1768
01:58:46,440 --> 01:58:53,320
the mechanics but when without look at what happens when things are not in proper

1769
01:58:53,320 --> 01:58:57,560
proportion so in other words what happens if we put a bunch of other elements

1770
01:58:57,810 --> 01:59:04,220
compounds and reactor but they're not in the balanced amounts and so for that I

1771
01:59:04,220 --> 01:59:09,540
will look at the production of titanium by the crawl process and this involves the

1772
01:59:09,540 --> 01:59:19,400
reaction of titanium kept chloride with magnesium to form of magnesium chloride cluster containing this

1773
01:59:19,400 --> 01:59:28,700
was invented 19 37 by wj crawl while he was still in Luxembourg can just

1774
01:59:28,700 --> 01:59:36,220
before and just before World War Two broker-dealers United States and finished his career in

1775
01:59:36,220 --> 01:59:41,720
the Pacific Northwest where he held on make huge quantities of of titanium and this

1776
01:59:41,720 --> 01:59:48,340
is performed this reaction is performed giant batch type reactor in which you feed titanium

1777
01:59:48,340 --> 01:59:57,320
tougher chloride and magnesium and he to about 900 degrees as the reaction goes will

1778
01:59:57,320 --> 02:00:04,240
have some magnesium liquid sitting on top of magnesium chloride liquids and then chunks of

1779
02:00:04,240 --> 02:00:12,220
titanium solid forming at the bottom titanium chloride gas above and really clever reaction because

1780
02:00:12,560 --> 02:00:17,280
the change of records against so it's obviously buoyant magnesium liquid but it's less dense

1781
02:00:17,280 --> 02:00:20,620
than magnesium chloride so as these products for

1782
02:00:20,740 --> 02:00:25,270
they continue to fall out of the way they keep this interface opens the reaction

1783
02:00:25,280 --> 02:00:29,580
can keep going and the end of the reaction you have the right reactive power

1784
02:00:29,620 --> 02:00:34,490
consumed of 2 teams chloride magnesium you have salt on top and you have to

1785
02:00:34,490 --> 02:00:38,650
take him on the bottom and this is what the stuff looks like this is

1786
02:00:38,650 --> 02:00:45,100
earlier this summer I was on smelter in Japan the largest titanium smoke from the

1787
02:00:45,100 --> 02:00:48,670
planet and this is coming out of 1 of these reactors is about 3 meters

1788
02:00:48,670 --> 02:00:54,130
across 6 meters tall is titanium sponge comes on the bottom of this reactor that

1789
02:00:54,150 --> 02:00:59,770
subsequently remounted in a vacuum arc furnaces and these were generated ability of solid titania

1790
02:00:59,940 --> 02:01:05,340
winning tens of talking OK so let's say some young engineers on the job the

1791
02:01:05,340 --> 02:01:11,320
1st day and says OK let's put into 100 kilograms of tackle and let's put

1792
02:01:11,360 --> 02:01:19,600
about 25 kilograms of maggie using the typical terms only sister tania typical right it's

1793
02:01:19,600 --> 02:01:26,370
tackle this is mag undergraduate student answers of brilliant PhD student of mine and she

1794
02:01:26,370 --> 02:01:32,600
had 2 dogs is parenthetical and she and she loved metallurgic has idea and she


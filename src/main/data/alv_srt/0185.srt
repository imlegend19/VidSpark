1
00:00:00,000 --> 00:00:04,570
templates so the table is one is likely to find the target

2
00:00:04,580 --> 00:00:07,270
the same thing in this world

3
00:00:07,280 --> 00:00:11,450
it provides areas and typology and they were not just in

4
00:00:11,450 --> 00:00:17,000
this kind of features and not just as they are but just simple that filters

5
00:00:17,440 --> 00:00:21,400
and again trying to localize them a little bit more love respective to the central

6
00:00:21,400 --> 00:00:26,860
location of the object and then there is also the world by jimmy and collaborators

7
00:00:26,860 --> 00:00:31,040
in which they try to have fragments of edges that they will tied to detect

8
00:00:31,040 --> 00:00:34,460
and image and each fragment will vote for what they think is the centre of

9
00:00:34,460 --> 00:00:35,450
an object

10
00:00:35,460 --> 00:00:41,000
and the same work was also done by opel's instances

11
00:00:41,090 --> 00:00:43,470
then there is another family of features

12
00:00:43,490 --> 00:00:46,980
and that are also based on edges but they try to have a representation of

13
00:00:46,980 --> 00:00:49,600
edges is more flexible so instead of having

14
00:00:49,660 --> 00:00:54,580
and edge has been the basic representation where they have the histograms of orientations for

15
00:00:54,580 --> 00:00:58,650
instance one of the most famous ones SIFT in which to take a bunch of

16
00:00:58,650 --> 00:01:05,000
an image distract management in that patch and then four different bins divided into the

17
00:01:05,000 --> 00:01:06,040
state by two

18
00:01:06,050 --> 00:01:11,220
especially windows and at each window you can't count how many edges have a particular

19
00:01:12,470 --> 00:01:16,840
so to build this histograms and that's going to be just presentation for that pixel

20
00:01:16,900 --> 00:01:22,190
and the same thing can be done with shape contexts in which they on the

21
00:01:22,190 --> 00:01:27,610
basic difference is that the been is donna bullock instead of being donnerstag great but

22
00:01:27,610 --> 00:01:31,850
it's basically the same representation so at each point is going to have notion of

23
00:01:31,850 --> 00:01:37,190
what's the structure of edges around that point but being very flexible just like histogram

24
00:01:37,200 --> 00:01:41,700
so it's not an exact edge as the press as the previous representations

25
00:01:42,730 --> 00:01:47,520
that simple representation can be have to be very useful for object recognition although it

26
00:01:47,520 --> 00:01:52,090
was developed first on the much much in the main for object recognition has been

27
00:01:52,090 --> 00:01:55,720
shown to be able to very powerful so there is this work by the intrigues

28
00:01:55,730 --> 00:01:58,930
in which what they do is they take an image

29
00:01:58,940 --> 00:02:02,570
and the representation is going to be for this track edges

30
00:02:02,630 --> 00:02:06,990
and then they take a small patches and again they do this histogram in of

31
00:02:06,990 --> 00:02:11,660
different orientations in the part that's going to be the basic presentation

32
00:02:11,680 --> 00:02:15,910
and they are going to apply some normalisation so that everything seems to one of

33
00:02:15,910 --> 00:02:20,220
his like that and those normalisation to become more important in order to get this

34
00:02:20,220 --> 00:02:25,380
things to work to perform the maximum performance but then the idea is that once

35
00:02:25,400 --> 00:02:29,830
you have transformed the imagine to be representation in which each pixel now contains this

36
00:02:29,830 --> 00:02:35,670
vector instead of RGB values contains these vectors encodes the structure of the big so

37
00:02:35,730 --> 00:02:39,800
now you can apply something like template matching and not to the object detection

38
00:02:39,820 --> 00:02:42,700
so what they do is to train a linear SVM

39
00:02:42,700 --> 00:02:45,100
so in that case will just be template matching

40
00:02:45,110 --> 00:02:49,310
i mean setting which they have examples of pedestrians

41
00:02:49,320 --> 00:02:53,830
but just the content pages that do not contain pedestrians and then the idea is

42
00:02:53,830 --> 00:02:54,830
that you take

43
00:02:54,870 --> 00:02:56,220
target image

44
00:02:56,240 --> 00:02:59,630
for which you are looking for testers you will start all possible pages from this

45
00:03:00,460 --> 00:03:02,170
let's say you think this but here

46
00:03:02,180 --> 00:03:04,990
you extract this orientation my

47
00:03:05,070 --> 00:03:08,540
and then to apply to have them play that you have learned from the SVM

48
00:03:08,550 --> 00:03:12,220
so this will be the template will have some negative and positive weights and if

49
00:03:12,270 --> 00:03:16,540
the value of the first of these properties more than a particular threshold with the

50
00:03:16,540 --> 00:03:19,680
site of the person is not present and

51
00:03:19,700 --> 00:03:21,020
i don't know if these

52
00:03:21,030 --> 00:03:26,060
in the product of the template for by the features that define this part out

53
00:03:26,060 --> 00:03:29,910
of a certain threshold and you will see the persons present so this is basically

54
00:03:29,920 --> 00:03:33,250
the template matching just like what i was arguing before that even really make any

55
00:03:33,250 --> 00:03:34,210
sense to apply

56
00:03:34,220 --> 00:03:37,480
here they apply it it and they are getting really good results

57
00:03:39,250 --> 00:03:44,100
so of course if johnconstable presentation and you have more flexibility for instance your parts

58
00:03:44,100 --> 00:03:48,800
instead of having just read template matching the things work a lot better and so

59
00:03:48,800 --> 00:03:52,670
in this case there is the world wide fund so that and collaborators in which

60
00:03:52,670 --> 00:03:53,550
what they do

61
00:03:53,560 --> 00:03:59,810
is they apply exactly the same idea that this template matching with orientation maps

62
00:03:59,870 --> 00:04:04,250
but they are going to introduce also parts each part is going to be detected

63
00:04:04,250 --> 00:04:07,520
also as if it was a single object so it's also going to be defined

64
00:04:07,520 --> 00:04:09,940
by the same template matching operation

65
00:04:09,950 --> 00:04:13,350
but all the different parts are going to vote for the presence of a particular

66
00:04:13,350 --> 00:04:17,860
object so will have a global template and also templates that will look for parts

67
00:04:17,870 --> 00:04:19,970
and they will put all these things together

68
00:04:19,980 --> 00:04:23,670
and then will define an object so for instance the template for the last three

69
00:04:23,670 --> 00:04:28,330
and this will be the template that will correspond to the global pattern of

70
00:04:28,520 --> 00:04:31,730
orientation maps that will define the best

71
00:04:31,780 --> 00:04:35,860
and these will define the different parts of the find pedestrian

72
00:04:35,880 --> 00:04:38,020
so you can see that here there there are more details you can see the

73
00:04:38,020 --> 00:04:41,160
face appeared in some of the shoulders and so on

74
00:04:41,170 --> 00:04:42,240
and despite its

75
00:04:42,250 --> 00:04:45,950
have a particular location so that you don't want them to move to match

76
00:04:45,970 --> 00:04:49,450
and they have some weight that will tell you know who you are going to

77
00:04:49,450 --> 00:04:54,790
penalize when this plots against the far from their original locations

78
00:04:54,790 --> 00:04:57,050
so here are some of the kind of

79
00:04:57,090 --> 00:05:00,530
four bottles guys so fast bicycles

80
00:05:00,530 --> 00:05:05,670
exactly what secretary fairly well for genetic of this is not a solved problem but

81
00:05:05,670 --> 00:05:07,540
not conducive for many things

82
00:05:07,560 --> 00:05:11,890
so here are are some examples of detections from the skull of the set and

83
00:05:11,900 --> 00:05:15,070
so here are the actions of this there's no reason to think that the visions

84
00:05:15,070 --> 00:05:19,130
of shape note people people people and this is a false alarm so it's nice

85
00:05:19,130 --> 00:05:23,580
when her false alarm the kind of funny and so here is the victim bottles

86
00:05:23,610 --> 00:05:26,770
this but also for his personal is like motel

87
00:05:26,770 --> 00:05:29,000
here is protecting cars

88
00:05:29,020 --> 00:05:30,850
here's the thing cultures

89
00:05:30,880 --> 00:05:32,540
if you have a have false alarm

90
00:05:32,550 --> 00:05:36,010
but they relatively was relatively well in general

91
00:05:36,030 --> 00:05:39,130
so so that they were not you can use in order to build something more

92
00:05:39,130 --> 00:05:43,530
forest service

93
00:05:43,600 --> 00:05:45,210
to express

94
00:05:45,210 --> 00:05:48,580
lens law that it is always opposing

95
00:05:48,600 --> 00:05:50,200
the change of the

96
00:05:52,110 --> 00:05:53,980
we have a minus sign here

97
00:05:54,060 --> 00:05:58,260
minus sign will never bother you believe me because you always know in which direction

98
00:05:58,260 --> 00:05:59,920
the EMF is

99
00:05:59,950 --> 00:06:01,960
it's clear that the EMF

100
00:06:01,970 --> 00:06:03,030
it's going to be

101
00:06:03,040 --> 00:06:05,770
in this direction that's the direction in which it

102
00:06:05,890 --> 00:06:07,760
will make the current flow

103
00:06:07,930 --> 00:06:10,500
but we have to put it there

104
00:06:10,560 --> 00:06:18,300
be mathematically correct that's really lens law you're looking at lens law

105
00:06:18,350 --> 00:06:21,130
so you can also write down for this

106
00:06:23,410 --> 00:06:27,970
the surface integral of the don't be a

107
00:06:29,650 --> 00:06:33,060
that open who appeared in cities

108
00:06:33,060 --> 00:06:37,160
one is open surface

109
00:06:37,170 --> 00:06:41,820
that's the third

110
00:06:42,550 --> 00:06:46,900
look what i did i forgot to DDT in front of integral sign sorry for

111
00:06:52,000 --> 00:06:55,850
if you put yourself inside the conductor

112
00:06:55,870 --> 00:06:58,970
and you march around in the direction of the current

113
00:06:59,010 --> 00:07:03,490
you will see everywhere in the wire in the electric field of course otherwise

114
00:07:03,500 --> 00:07:06,060
there would be no current flowing

115
00:07:06,150 --> 00:07:09,770
so if you go once around this whole circus

116
00:07:10,910 --> 00:07:12,150
that you may have

117
00:07:12,160 --> 00:07:14,510
we must of course also be

118
00:07:14,510 --> 00:07:17,340
delta l

119
00:07:18,320 --> 00:07:21,050
the closed loop

120
00:07:21,090 --> 00:07:23,390
so you're watching inside the wire

121
00:07:23,400 --> 00:07:24,830
you find everywhere

122
00:07:24,840 --> 00:07:26,230
the electric field

123
00:07:26,230 --> 00:07:28,510
and these little sections

124
00:07:28,560 --> 00:07:30,820
i dl

125
00:07:30,920 --> 00:07:34,960
ian dl always in the same direction if you stay in the wire

126
00:07:35,000 --> 00:07:36,050
and so

127
00:07:36,060 --> 00:07:37,030
this should be

128
00:07:37,030 --> 00:07:37,960
the same

129
00:07:37,970 --> 00:07:40,270
and it is a closed loop

130
00:07:40,290 --> 00:07:42,120
so this is all if you want

131
00:07:42,140 --> 00:07:43,730
what we call

132
00:07:43,730 --> 00:07:45,990
fire this role

133
00:07:46,060 --> 00:07:48,760
we never see it in so much detail

134
00:07:48,800 --> 00:07:50,660
i will abbreviated a little bit

135
00:07:50,680 --> 00:07:52,160
on the board there

136
00:07:52,180 --> 00:07:56,840
but i wanted to appreciate that there is no battery in this area

137
00:07:56,850 --> 00:08:00,130
there is only a change in the magnetic flux

138
00:08:00,180 --> 00:08:02,570
through surface that i have attached

139
00:08:02,580 --> 00:08:05,000
two the conducting wire

140
00:08:05,000 --> 00:08:07,780
and then i get an induced EMF

141
00:08:07,830 --> 00:08:09,950
an induced EMF

142
00:08:09,980 --> 00:08:17,540
well put those occurrence given by ohms law

143
00:08:17,620 --> 00:08:21,730
so i want to write down on that blackboard there

144
00:08:21,770 --> 00:08:25,200
so far there is law in a somewhat abbreviated way because

145
00:08:25,210 --> 00:08:26,020
we have all

146
00:08:26,030 --> 00:08:28,850
maxwell's equations here

147
00:08:28,910 --> 00:08:32,740
and so we now have that the

148
00:08:32,790 --> 00:08:36,180
closed loop integral

149
00:08:36,320 --> 00:08:39,020
a closed loop

150
00:08:39,020 --> 00:08:41,050
if you don't pl

151
00:08:41,060 --> 00:08:46,450
that's that induced EMF

152
00:08:46,460 --> 00:08:48,790
you can take minus the phi

153
00:08:48,810 --> 00:08:54,820
all the time derivative of the integral bwt a that's the one i will take

154
00:08:57,540 --> 00:09:00,720
of the don't be a

155
00:09:00,730 --> 00:09:05,210
and and this is over an an open service

156
00:09:05,260 --> 00:09:08,180
and that open surface has to be attached

157
00:09:08,200 --> 00:09:09,700
to this little

158
00:09:09,750 --> 00:09:14,980
and that is violated a

159
00:09:15,000 --> 00:09:16,960
we've got law

160
00:09:16,970 --> 00:09:19,700
we and law

161
00:09:19,770 --> 00:09:25,010
we have this one which tells you the magnetic monopole don't exist

162
00:09:25,060 --> 00:09:27,450
this would only not be zero

163
00:09:27,500 --> 00:09:30,820
if you had a magnetic monopole and put it in close to

164
00:09:32,830 --> 00:09:35,850
come and see me if you find one

165
00:09:35,860 --> 00:09:38,710
and this now is by this law

166
00:09:38,710 --> 00:09:42,780
so you think that all four maxwell's equations are now complete

167
00:09:42,830 --> 00:09:45,040
not quite

168
00:09:45,040 --> 00:09:46,830
going to change this one

169
00:09:46,830 --> 00:09:51,460
course even here we still have to return to another issue that we considered before

170
00:09:53,640 --> 00:09:56,550
it is life itself

171
00:09:56,580 --> 00:10:02,820
we're having is the very fact that you're alive itself a good thing

172
00:10:02,840 --> 00:10:08,800
these are the valuable container theories which i previously contracted with the neutral container theories

173
00:10:08,800 --> 00:10:14,090
you recall that according to the neutral container theories and thinking about the quality of

174
00:10:14,090 --> 00:10:17,570
someone's like you just look at the contents

175
00:10:17,580 --> 00:10:22,270
life itself is only a container good or bad you know what is filled up

176
00:10:23,450 --> 00:10:27,870
but opposed to the neutral container theories we had a valuable container theories would say

177
00:10:28,190 --> 00:10:31,780
that the very fact that you're alive

178
00:10:31,790 --> 00:10:38,760
and some positive value above and beyond what was going on in your life

179
00:10:40,140 --> 00:10:45,010
even the valuable container theories came in different versions there were more modest versions were

180
00:10:45,010 --> 00:10:46,770
in principle

181
00:10:46,800 --> 00:10:52,190
the positive value of being alive could be outweighed if the content got bad enough

182
00:10:52,200 --> 00:10:58,200
and we contrast that with fantastic container theories according to which being alive is so

183
00:10:58,200 --> 00:11:04,870
valuable that doesn't matter how bad the contents get the grand total is always positive

184
00:11:04,870 --> 00:11:10,540
wanna look if you accept a fantastic container theory

185
00:11:10,560 --> 00:11:14,400
then pretty clearly it's never true

186
00:11:14,450 --> 00:11:17,450
that somebody could be better off dead

187
00:11:17,470 --> 00:11:22,440
because no matter how bad the contents get

188
00:11:22,450 --> 00:11:28,590
the fact that they're alive per say is so valuable it always that the sum

189
00:11:29,370 --> 00:11:33,310
giving us positive grand total

190
00:11:34,060 --> 00:11:41,380
pretty clearly from the perspective of fantastic container theories suicide will never be

191
00:11:41,390 --> 00:11:46,680
rational because it's never true that you're better off dead because it's never true that

192
00:11:46,680 --> 00:11:54,030
your life overall taking everything relevant into consideration gives us the negative

193
00:12:04,510 --> 00:12:05,740
the question was

194
00:12:05,750 --> 00:12:11,680
and the fantastic container theories what so incredible about life itself always tainted intrinsically valuable

195
00:12:11,940 --> 00:12:17,480
and yes the answer is precisely the fans of the valuable container theories are saying

196
00:12:17,740 --> 00:12:21,110
being alive itself is valuable

197
00:12:21,130 --> 00:12:24,610
you may recall that i previously said other people talk the way they probably don't

198
00:12:24,610 --> 00:12:25,690
actually mean

199
00:12:25,700 --> 00:12:29,730
right it's not OK to be alive is the blade of grass they wouldn't say

200
00:12:29,730 --> 00:12:34,510
oh wouldn't be wonderful that would have been most fans of the claim to be

201
00:12:34,530 --> 00:12:39,480
alive per say is valuable don't really mean like for say they mean something more

202
00:12:39,480 --> 00:12:40,870
like light

203
00:12:40,930 --> 00:12:43,900
and as a person

204
00:12:43,960 --> 00:12:48,620
because you have been kind of entity who can think and plan even if that

205
00:12:48,760 --> 00:12:55,170
what your plans go wrong at least you were a person able to experience things

206
00:12:55,170 --> 00:12:58,420
no things and so forth

207
00:13:00,130 --> 00:13:04,530
if that's the reason for accepting the fantastic container theory

208
00:13:04,530 --> 00:13:08,010
that we might wonder what should we say about those cases where

209
00:13:08,500 --> 00:13:09,190
that the

210
00:13:09,200 --> 00:13:15,180
p functioning has decayed and the person is no longer able to continue as a

211
00:13:15,180 --> 00:13:19,300
person but perhaps can still feel pain

212
00:13:19,320 --> 00:13:22,980
in that case perhaps life could cease to be worth living though

213
00:13:22,990 --> 00:13:26,120
you know whether or not we should describe it that way also depends on these

214
00:13:26,130 --> 00:13:30,750
complicated issues that we've discussed previously about with that still be you would you still

215
00:13:30,750 --> 00:13:35,790
exist would you still be alive under those circumstances so the basic idea

216
00:13:35,810 --> 00:13:40,730
behind valuable container theories is that life for the life of a person or something

217
00:13:40,730 --> 00:13:45,940
like that has intrinsic value above and beyond the question of what's going on with

218
00:13:45,940 --> 00:13:48,340
in your life

219
00:13:48,470 --> 00:13:52,850
if we accept the fantastic container theory

220
00:13:52,900 --> 00:13:58,110
maybe nobody's life is ever so bad grand total

221
00:13:59,100 --> 00:14:03,820
this led to set of the rational thing to do because the value of life

222
00:14:03,820 --> 00:14:07,880
per say so incredible that always the content it has to with the content that

223
00:14:07,880 --> 00:14:11,950
that's that the philosophical view at the opposite end of the pessimists

224
00:14:11,970 --> 00:14:16,680
the person said as a matter of philosophical reflection we can see that everybody's life

225
00:14:16,680 --> 00:14:18,870
is worse than nothing

226
00:14:18,900 --> 00:14:21,300
the fantastic container fans

227
00:14:21,320 --> 00:14:26,300
the a matter of philosophical reflection we can see that everybody's life is better than

228
00:14:27,060 --> 00:14:33,550
most of us i imagine find ourselves somewhere in between either we believe in the

229
00:14:33,550 --> 00:14:38,370
neutral container theory i think it's a contentious matter whether the contents are sufficiently good

230
00:14:38,370 --> 00:14:39,350
or bad

231
00:14:39,360 --> 00:14:45,190
or we may accept the modest version of the valuable container theory

232
00:14:45,200 --> 00:14:48,150
on that theory of course life

233
00:14:48,170 --> 00:14:54,030
has some intrinsic value but it's kind of finite intrinsic value and in principle even

234
00:14:54,030 --> 00:14:57,530
that could be outweighed if the contents get bad enough

235
00:14:57,570 --> 00:15:01,240
so again it will be an empirical question we have to take a look and

236
00:15:02,220 --> 00:15:07,380
in which case is do the contents get bad enough

237
00:15:09,000 --> 00:15:11,870
i guess on one of these people in the middle

238
00:15:11,920 --> 00:15:16,690
i'm inclined to think it's not true that everybody's life is worse than nothing nor

239
00:15:16,690 --> 00:15:21,720
is it true that everybody's life is better than nothing it varies from person to

240
00:15:21,720 --> 00:15:25,990
person and indeed not just since we think about what i want talk about their

241
00:15:25,990 --> 00:15:31,510
life as a whole really what does life promise from here on out

242
00:15:31,530 --> 00:15:34,670
sadly to to sad to say

243
00:15:34,670 --> 00:15:38,150
it seems to me there are cases and probably most of us are familiar with

244
00:15:38,150 --> 00:15:44,650
cases where the correct description given that your favourite theory of well-being is going to

245
00:15:44,650 --> 00:15:46,680
be that

246
00:15:46,700 --> 00:15:47,940
for this person

247
00:15:47,960 --> 00:15:54,400
here on out what life has to offer is sufficiently bad so the contents are

248
00:15:54,400 --> 00:16:01,650
sufficiently negative as to outweigh whatever value like itself might have

249
00:16:01,680 --> 00:16:04,430
you can imagine somebody in the

250
00:16:04,440 --> 00:16:08,010
terminal stages of some illness

251
00:16:08,990 --> 00:16:13,990
the cancer perhaps is causing them a great deal of pain

252
00:16:14,030 --> 00:16:18,550
and the pain so bad that they can't really do much of anything else it's

253
00:16:18,550 --> 00:16:24,280
not as though they can continue working on their their novel or continue talking with

254
00:16:24,280 --> 00:16:29,100
the members of their family because they just distracted by the pain and wishing it

255
00:16:29,100 --> 00:16:35,530
would come to an end horribly enough many degenerative diseases leave the person less and

256
00:16:35,530 --> 00:16:37,210
less capable

257
00:16:37,220 --> 00:16:41,320
of doing the things that like value

258
00:16:41,350 --> 00:16:46,580
and the very realization that you're in that situation no longer able to

259
00:16:46,610 --> 00:16:51,190
spend time doing things are hanging out with your family or or talking to whatever

260
00:16:51,190 --> 00:16:57,340
it is it may itself be a source of more frustration and pain

261
00:16:57,360 --> 00:16:58,310
there are

262
00:16:58,320 --> 00:17:03,440
medical conditions where horribly enough infants get born

263
00:17:03,470 --> 00:17:09,420
where they're just in in continual pain and they never developed cognitively the brain doesn't

264
00:17:09,490 --> 00:17:10,710
open and they died

265
00:17:10,720 --> 00:17:13,830
and you look at these lives and you say these are lies i want to

266
00:17:13,830 --> 00:17:19,320
say these are lives that were not worth having

267
00:17:19,370 --> 00:17:24,460
these children would have been better off never having been born at all certainly not

268
00:17:24,490 --> 00:17:29,140
any kind of favour for them to continue their lives

269
00:17:29,150 --> 00:17:32,050
well let's focus on some cases like

270
00:17:32,100 --> 00:17:34,580
the the terminal patient

271
00:17:34,600 --> 00:17:39,090
persons got disease was that would be nice easy example not easy to live through

272
00:17:39,090 --> 00:17:44,930
body easy philosophically easy example think about some terminally ill patients whose disease is getting

273
00:17:44,930 --> 00:17:49,130
worse and worse and so there are fewer and fewer of the good things in

274
00:17:50,360 --> 00:17:54,540
the the future holds for them instead what the future holds is more and more

275
00:17:54,540 --> 00:17:59,180
pain suffering incapacity and frustration

276
00:17:59,220 --> 00:18:02,610
when it gets bad enough it seems to me in some of those cases the

277
00:18:02,610 --> 00:18:08,030
the lower the probability of y given x

278
00:18:35,610 --> 00:18:38,430
it is

279
00:18:38,450 --> 00:19:01,090
it is it is possible for the weight wj to be negative

280
00:19:01,130 --> 00:19:04,420
and if the weight wj is negative

281
00:19:04,430 --> 00:19:07,200
then a big via the feature function

282
00:19:07,220 --> 00:19:09,720
it's going to reduce the problem to y

283
00:19:09,740 --> 00:19:16,580
OK so much

284
00:19:16,590 --> 00:19:20,950
i'm feeling a bit of a chicken and egg problem and talking about log linear

285
00:19:20,950 --> 00:19:24,350
models because because everything is connected by

286
00:19:25,660 --> 00:19:26,970
these weights

287
00:19:26,980 --> 00:19:31,300
which are the equivalent of the vedas i had before that the parameters are going

288
00:19:31,310 --> 00:19:33,500
to have a learning algorithm for that

289
00:19:33,500 --> 00:19:34,590
and so

290
00:19:34,620 --> 00:19:38,360
what we actually do is we define feature functions

291
00:19:38,400 --> 00:19:39,590
and then

292
00:19:39,600 --> 00:19:44,140
the and in the feature functions we define the feature function that measures some property

293
00:19:44,140 --> 00:19:45,540
of x and y

294
00:19:45,550 --> 00:19:50,500
and then the learning i was going to learn whether or not that probability has

295
00:19:50,500 --> 00:19:52,220
an affinity with

296
00:19:52,260 --> 00:19:57,330
why being more likely has an affinity with y being less likely

297
00:20:03,630 --> 00:20:05,970
once the value of the function is

298
00:20:07,510 --> 00:20:11,900
and it's pre-defined then the way that actually tells us

299
00:20:11,920 --> 00:20:17,610
but when we define when when when when the human defines the function in the

300
00:20:17,610 --> 00:20:19,890
human is going to define functions

301
00:20:25,910 --> 00:20:32,400
that he thinks so she thinks is going like it have affinity maybe

302
00:20:35,030 --> 00:20:37,710
the easiest if i were

303
00:20:37,720 --> 00:20:39,970
move on to my

304
00:20:39,990 --> 00:20:40,730
trying to

305
00:20:40,740 --> 00:20:43,090
something examples

306
00:20:48,840 --> 00:20:50,850
my car so

307
00:20:52,500 --> 00:20:56,050
x equals sentence

308
00:20:56,070 --> 00:20:57,780
y equals

309
00:20:57,820 --> 00:21:01,510
tag sequence

310
00:21:01,520 --> 00:21:08,830
so this is the same part of speech example then i have my

311
00:21:08,870 --> 00:21:12,010
fj of x and y

312
00:21:12,060 --> 00:21:13,110
it would be

313
00:21:13,120 --> 00:21:16,410
you know axis

314
00:21:16,450 --> 00:21:18,530
it starts with

315
00:21:18,550 --> 00:21:23,010
a capitalized word

316
00:21:24,970 --> 00:21:30,330
like you also to start with capitalized words that's not

317
00:21:35,200 --> 00:21:35,870
so just

318
00:21:35,890 --> 00:21:43,330
the second word is capitalized

319
00:21:46,140 --> 00:21:48,710
second tag

320
00:21:49,750 --> 00:21:56,340
proper noun

321
00:21:59,750 --> 00:22:05,160
after a x y is second was capitalizing second tag is proper noun

322
00:22:07,660 --> 00:22:13,000
feature functions are real valued but are very common special case of the feature function

323
00:22:13,010 --> 00:22:15,750
is that the zero one valued

324
00:22:15,800 --> 00:22:19,470
and so here's the feature function has zero one value

325
00:22:19,560 --> 00:22:23,430
the second sentence starts with a capital letter

326
00:22:23,430 --> 00:22:27,190
and the second tag is proper nouns

327
00:22:30,230 --> 00:22:34,160
chances are that when we train this model

328
00:22:34,240 --> 00:22:36,490
we're going to find that

329
00:22:37,080 --> 00:22:39,750
the weight w j

330
00:22:39,750 --> 00:22:43,000
is large and positive

331
00:22:43,780 --> 00:22:45,250
what that means

332
00:22:45,260 --> 00:22:48,860
what what that's what that's going to do is going to say that everything else

333
00:22:48,860 --> 00:22:50,170
being equal

334
00:22:51,020 --> 00:22:53,730
this feature function is switched on

335
00:22:56,370 --> 00:22:57,920
tag sequence y

336
00:22:57,930 --> 00:23:00,400
it is more likely

337
00:23:03,720 --> 00:23:08,520
so here's another feature functions have

338
00:23:11,320 --> 00:23:12,740
x and y

339
00:23:13,840 --> 00:23:22,220
first word is capitalized

340
00:23:22,230 --> 00:23:27,020
and first tag

341
00:23:27,040 --> 00:23:31,590
is probably now

342
00:23:34,420 --> 00:23:41,240
first tag is proper noun

343
00:23:41,290 --> 00:23:43,020
must so

344
00:23:43,030 --> 00:23:47,210
you know that this is also zero one feature that we can measure

345
00:23:47,220 --> 00:23:53,870
that any sentence and any tag sequence first word is capitalized and first

346
00:23:53,890 --> 00:23:55,440
tag is proper noun

347
00:23:56,420 --> 00:23:59,620
there are going to be lots of sentences

348
00:23:59,670 --> 00:24:03,500
well there are going to be lots of x y pairs well y

349
00:24:03,510 --> 00:24:06,110
this the correct answer for x

350
00:24:06,120 --> 00:24:08,060
but this feature function

351
00:24:10,610 --> 00:24:14,420
those are going to be sentences which have the first word capitalized but at first

352
00:24:14,420 --> 00:24:16,350
one is not a proper noun

353
00:24:16,360 --> 00:24:17,860
and so

354
00:24:17,870 --> 00:24:18,990
the weight

355
00:24:18,990 --> 00:24:22,740
w fourteen that we learn for this feature

356
00:24:22,810 --> 00:24:24,150
is going to be

357
00:24:24,180 --> 00:24:26,160
pretty small

358
00:24:26,290 --> 00:24:27,920
but the weights

359
00:24:27,920 --> 00:24:29,440
it is this feature

360
00:24:31,650 --> 00:24:35,780
the weight w fifteen we love this feature is going to be pretty big

361
00:24:39,660 --> 00:24:41,520
if this feature is true

362
00:24:41,550 --> 00:24:43,040
then y

363
00:24:43,110 --> 00:24:44,680
tends to be

364
00:24:44,680 --> 00:24:48,990
the correct answer for x

365
00:24:49,090 --> 00:24:52,820
OK so these examples of william functions

366
00:24:52,860 --> 00:24:58,890
and billion functions are special case of real valued functions and in general feature functions

367
00:24:58,890 --> 00:25:00,640
are allowed to be real valued

368
00:25:00,750 --> 00:25:01,940
but there are often

369
00:25:08,260 --> 00:25:10,330
and they are allowed to be

370
00:25:10,350 --> 00:25:15,290
positive or negative there are allowed to take any take on any real value

371
00:25:15,420 --> 00:25:16,700
one of the most

372
00:25:19,020 --> 00:25:22,560
among the

373
00:25:22,560 --> 00:25:25,970
so how does that relate to what we had before

374
00:25:25,970 --> 00:25:29,470
so this is the distribution in r two

375
00:25:29,480 --> 00:25:35,240
and i just happened to give specific names for those coordinates namely height and weight

376
00:25:35,250 --> 00:25:38,250
in general and might have maybe fifty images

377
00:25:38,300 --> 00:25:41,290
of maybe apples and i might want to find out you know how much acid

378
00:25:41,290 --> 00:25:42,790
they contain

379
00:25:45,500 --> 00:25:50,050
i might have been also assume that somehow by from those images those readings of

380
00:25:50,050 --> 00:25:56,230
acidity are correlated

381
00:25:56,240 --> 00:25:58,150
so overall

382
00:25:58,210 --> 00:26:01,270
we assume that we have some covariance matrix k

383
00:26:01,290 --> 00:26:04,610
and all the while alive

384
00:26:04,630 --> 00:26:09,090
so i might have some general correlation time which is parameterized by some function k

385
00:26:09,090 --> 00:26:11,140
of x i and x j

386
00:26:11,190 --> 00:26:14,790
what happened to be the same thing as a kernel that we did before

387
00:26:14,900 --> 00:26:17,410
and i might have some an additive noise term

388
00:26:17,520 --> 00:26:20,760
they can actually be derived is in a bit more detail what you say well

389
00:26:21,040 --> 00:26:22,940
i've got some

390
00:26:22,990 --> 00:26:24,330
parameter here

391
00:26:24,380 --> 00:26:26,900
and drawing some variables from that some

392
00:26:26,950 --> 00:26:29,230
latent variables t

393
00:26:29,270 --> 00:26:30,070
and then

394
00:26:30,160 --> 00:26:34,550
from that i'm getting some additive noise and actually get the observations y

395
00:26:34,570 --> 00:26:35,640
just very much

396
00:26:35,660 --> 00:26:37,350
short-circuited that

397
00:26:37,360 --> 00:26:40,330
to save some time here

398
00:26:41,540 --> 00:26:44,110
if i have

399
00:26:44,150 --> 00:26:45,880
what i get is that

400
00:26:45,930 --> 00:26:48,220
my overall covariance matrix

401
00:26:48,300 --> 00:26:50,290
it's going to be

402
00:26:50,300 --> 00:26:52,520
just as kernel matrix k

403
00:26:54,710 --> 00:26:57,660
something added to the main diagonal

404
00:26:58,440 --> 00:27:00,780
so this is a reasonable model of assuming

405
00:27:00,790 --> 00:27:03,820
how a bunch of scalars are correlated

406
00:27:04,610 --> 00:27:07,570
well depending on what my prize and how those very

407
00:27:07,580 --> 00:27:09,390
is remembered for light

408
00:27:09,400 --> 00:27:11,610
well i get a different distribution

409
00:27:12,740 --> 00:27:17,790
i could just go and as well what's the probability of what crime given y

410
00:27:19,180 --> 00:27:20,160
now of course

411
00:27:20,180 --> 00:27:23,150
i know that this is normally distributed

412
00:27:23,180 --> 00:27:26,580
because conditioned on some variables in normal given normal back

413
00:27:26,600 --> 00:27:29,010
and after a lot of linear algebra

414
00:27:29,050 --> 00:27:32,970
well actually don't really do it yourself you just look at the book like paul

415
00:27:32,980 --> 00:27:38,060
which has everything in there about matrices that you never want to derive yourself

416
00:27:38,090 --> 00:27:39,730
so wonderful book

417
00:27:39,730 --> 00:27:44,020
this guy probably spent a couple of years just compiling matrix identities

418
00:27:44,060 --> 00:27:56,560
so if you haven't got that book is required

419
00:27:56,610 --> 00:28:00,620
this guy apparently for several years did nothing else but whenever he thought of

420
00:28:00,690 --> 00:28:04,710
something useful for matrix he wrote it up in the end he compiled

421
00:28:05,530 --> 00:28:08,520
i think it's like thirty dollars because

422
00:28:08,570 --> 00:28:09,690
the great thing

423
00:28:12,100 --> 00:28:15,370
what you can basically do is you look at the big

424
00:28:17,240 --> 00:28:19,620
we look at this because variance matrix

425
00:28:19,640 --> 00:28:24,310
with that the variables into those people served in those that happened observed

426
00:28:24,350 --> 00:28:26,810
then collect the linear and quadratic

427
00:28:26,830 --> 00:28:30,850
and then you just rewrite that back into normal it

428
00:28:30,910 --> 00:28:33,950
into normal so this really not much else in there

429
00:28:33,970 --> 00:28:36,120
but what you get is you get this

430
00:28:36,140 --> 00:28:40,160
as the resulting covariance matrix for y prime given y

431
00:28:40,260 --> 00:28:42,850
and this is the mean

432
00:28:45,910 --> 00:28:48,910
yes of course

433
00:28:48,950 --> 00:28:55,830
know that this action of formality so let's discuss the various terms

434
00:28:55,890 --> 00:29:01,600
this species is symmetric that's the covariance matrix between the y fronts

435
00:29:03,030 --> 00:29:07,310
so this thing so for instance i might have a thousand training observations and might

436
00:29:07,310 --> 00:29:09,180
have fifty test observations

437
00:29:09,220 --> 00:29:12,660
so this is actually associated tall and skinny matrix

438
00:29:12,700 --> 00:29:14,080
p fifty by

439
00:29:14,100 --> 00:29:15,310
one thousand so

440
00:29:15,450 --> 00:29:17,870
couldn't even be semantically anyway

441
00:29:18,330 --> 00:29:23,010
so this is like the the carbon center covariance matrix of a gate

442
00:29:23,010 --> 00:29:25,850
just by observing the y fronts and

443
00:29:26,430 --> 00:29:30,660
having observed the wise will reduce the variance in the y fronts

444
00:29:30,720 --> 00:29:32,970
subtracted something from it

445
00:29:33,010 --> 00:29:35,390
and the variance reduction will be large

446
00:29:35,410 --> 00:29:39,120
if one y prime strongly correlated

447
00:29:39,160 --> 00:29:40,240
and and also

448
00:29:40,240 --> 00:29:41,350
if the y

449
00:29:41,370 --> 00:29:43,780
i'm not very noise

450
00:29:43,780 --> 00:29:45,680
if there was very noisy

451
00:29:45,680 --> 00:29:49,280
in this covariance matrix will be large so one of the covariance matrix for very

452
00:29:49,280 --> 00:29:51,950
small so the overall time

453
00:29:53,140 --> 00:29:57,140
what you're doing is you're taking into account how noisy the y are

454
00:29:57,160 --> 00:29:58,510
not wise are

455
00:29:58,510 --> 00:30:02,010
and how strongly the wise and the y fronts are correlated

456
00:30:02,850 --> 00:30:06,280
that's what gives you the very

457
00:30:09,700 --> 00:30:13,220
for the mean i just get the original meaning that they would have had to

458
00:30:13,240 --> 00:30:14,330
anything else

459
00:30:14,330 --> 00:30:16,200
the need to correct

460
00:30:16,290 --> 00:30:21,720
and correcting upon the surprise of seeing why rather than you

461
00:30:21,760 --> 00:30:23,870
this is of course why why

462
00:30:23,870 --> 00:30:26,390
what they assume how noisy the why store

463
00:30:26,410 --> 00:30:29,600
if they're very noisy then i'm not going to get much about it

464
00:30:29,660 --> 00:30:33,450
and by how strong otherwise electrons are correlated

465
00:30:33,510 --> 00:30:39,680
so for instance if the what what crimes are uncorrelated and this will not natural

466
00:30:40,510 --> 00:30:43,390
the other interesting thing is that of course this matrix here

467
00:30:43,410 --> 00:30:45,890
it has to be positive semidefinite

468
00:30:45,910 --> 00:30:51,600
because the main of the residual covariance has to be nonnegative

469
00:30:51,620 --> 00:30:56,430
sometimes you can use such into theta take with the matrix is positive semidefinite for

470
00:30:56,430 --> 00:30:58,700
instance take that this whole

471
00:30:58,720 --> 00:31:00,260
and that furthermore

472
00:31:00,290 --> 00:31:03,120
this matrix itself is positive semidefinite

473
00:31:03,240 --> 00:31:06,410
sometimes that's also referred to as the sure complement

474
00:31:06,450 --> 00:31:08,890
if somebody writes about that don't be scared

475
00:31:08,950 --> 00:31:12,430
is it just fancy name

476
00:31:15,780 --> 00:31:18,160
is a a couple of functions

477
00:31:18,180 --> 00:31:25,780
and not very surprisingly all of our friends of kernels will just for fun

478
00:31:25,930 --> 00:31:29,740
seeing all of those

479
00:31:35,660 --> 00:31:39,910
you would think is completely trivial obvious inside

480
00:31:41,120 --> 00:31:43,410
it's not true that it's trivial

481
00:31:43,450 --> 00:31:47,760
so as i already mentioned kriging does exactly that

482
00:31:48,910 --> 00:31:51,050
garson processes the same thing

483
00:31:51,050 --> 00:31:53,050
svm so the same thing

484
00:31:53,180 --> 00:31:55,490
so there are still books which say

485
00:31:55,490 --> 00:31:58,370
well we work on least squares support vector machines

486
00:31:58,390 --> 00:32:03,100
which are essentially gaussianprocess regression with a slightly different interpretation

487
00:32:03,140 --> 00:32:08,100
and those three streams and people are still publishing in different areas and then always

488
00:32:08,100 --> 00:32:09,220
really mixing

489
00:32:09,280 --> 00:32:10,510
the results which is

490
00:32:10,530 --> 00:32:13,330
a bit sad because it just means that sometimes we have to prove the same

491
00:32:13,330 --> 00:32:16,620
results three times

492
00:32:17,030 --> 00:32:20,350
but basically

493
00:32:20,370 --> 00:32:21,640
you can show

494
00:32:22,410 --> 00:32:24,970
support vector regression with a squared loss

495
00:32:24,970 --> 00:32:28,680
and process regression are the same thing

496
00:32:28,740 --> 00:32:33,780
the key difference being that if you use casting process regression you actually get an

497
00:32:33,780 --> 00:32:35,780
estimate of the variance

498
00:32:35,830 --> 00:32:37,010
so what you get

499
00:32:37,030 --> 00:32:39,030
which is really useful

500
00:32:39,100 --> 00:32:43,660
is an idea of how reliable or unreliable you this

501
00:32:43,660 --> 00:32:45,760
this we will get that

502
00:32:45,780 --> 00:32:47,200
yes to have

503
00:32:55,620 --> 00:33:00,390
the short answer is just use whatever you using synchronous SVM

504
00:33:00,430 --> 00:33:02,990
but that's not a very satisfactory and so i guess

505
00:33:03,030 --> 00:33:06,350
long and so is you could for instance put the prior

506
00:33:06,370 --> 00:33:08,470
on the covariance function

507
00:33:08,470 --> 00:33:10,220
and then integrate that out

508
00:33:10,260 --> 00:33:13,120
and then maybe i could try on your prior

509
00:33:13,200 --> 00:33:15,580
and keep on doing this

510
00:33:15,990 --> 00:33:19,060
as soon as you go beyond the standard cost model

511
00:33:19,510 --> 00:33:22,510
a lot of those things and also he's anymore and then you need to use

512
00:33:22,510 --> 00:33:25,990
sampling or variational methods to get anywhere

513
00:33:27,260 --> 00:33:31,530
basically you need to talk to nando

514
00:33:35,350 --> 00:33:37,760
we show you how it works

515
00:33:37,780 --> 00:33:41,370
some training data

516
00:33:41,370 --> 00:33:43,090
that is if you this

517
00:33:43,090 --> 00:33:44,240
question from

518
00:33:44,370 --> 00:33:46,880
the first time

519
00:33:46,900 --> 00:33:48,720
implications of vision

520
00:33:48,740 --> 00:33:53,760
and so in one of the biggest image

521
00:33:55,330 --> 00:33:57,570
uses computation

522
00:33:57,590 --> 00:34:00,210
applications that

523
00:34:00,230 --> 00:34:03,630
so is the same as

524
00:34:03,630 --> 00:34:05,110
and the

525
00:34:06,240 --> 00:34:08,390
doing inference

526
00:34:10,380 --> 00:34:13,860
this as far possible so far

527
00:34:13,990 --> 00:34:23,790
you cannot expect to understand express we pushed solution seems to expressed some sense

528
00:34:23,830 --> 00:34:25,580
keep like that

529
00:34:25,590 --> 00:34:28,230
it could be

530
00:34:28,360 --> 00:34:32,030
in fact the g three x three computer science

531
00:34:32,130 --> 00:34:37,460
this is just an interesting because this competition

532
00:34:37,480 --> 00:34:41,200
competitions because because we have to inside

533
00:34:43,070 --> 00:34:44,170
because it

534
00:34:46,180 --> 00:34:50,460
this is going to push sum missions inside

535
00:34:50,480 --> 00:34:51,680
so just

536
00:34:51,730 --> 00:34:55,370
this is something like that

537
00:34:55,550 --> 00:34:57,190
so so so that

538
00:34:57,290 --> 00:34:59,400
so i mean that's

539
00:34:59,420 --> 00:35:05,180
it's just as well keeping a bunch of them unchanged

540
00:35:09,650 --> 00:35:14,370
so that's the same imagine extract

541
00:35:17,980 --> 00:35:21,800
it's just factor just in different ways

542
00:35:21,800 --> 00:35:24,660
what about

543
00:35:24,720 --> 00:35:27,040
first thing is true

544
00:35:28,870 --> 00:35:33,130
the next three years percent ago

545
00:35:33,140 --> 00:35:35,820
next to it

546
00:35:36,800 --> 00:35:40,370
right so this is a few minutes

547
00:35:41,780 --> 00:35:47,180
history is just passing messages from leaves

548
00:35:47,540 --> 00:35:51,140
six months which is operations

549
00:35:57,710 --> 00:35:59,530
but it's

550
00:35:59,600 --> 00:36:01,120
exactly this

551
00:36:01,160 --> 00:36:04,680
it's exactly this is another way of doing this

552
00:36:07,380 --> 00:36:11,120
three this kind of got

553
00:36:11,130 --> 00:36:12,880
you know it's

554
00:36:12,900 --> 00:36:18,210
not so we have the specifications to messages

555
00:36:18,290 --> 00:36:21,860
what happens to the the messages factor

556
00:36:21,870 --> 00:36:26,060
simple thing that's gone

557
00:36:27,540 --> 00:36:28,380
that's it

558
00:36:33,370 --> 00:36:35,800
thing that's gonna change

559
00:36:40,040 --> 00:36:43,450
so you think about it

560
00:36:44,990 --> 00:36:47,510
and this that

561
00:36:48,600 --> 00:36:53,630
and so this separation is straightforward

562
00:36:53,650 --> 00:36:58,830
so you can see that the operations of extreme this is only sixty

563
00:36:58,870 --> 00:37:00,760
and so that's it

564
00:37:00,800 --> 00:37:03,930
that's the that's applications

565
00:37:05,160 --> 00:37:07,650
so it's here

566
00:37:07,660 --> 00:37:11,670
you you have because that's from the structure of business

567
00:37:13,870 --> 00:37:15,640
the fact

568
00:37:15,740 --> 00:37:20,310
that's coming back to the fact that with the same

569
00:37:20,410 --> 00:37:25,100
actually sourced production from here it you is

570
00:37:26,370 --> 00:37:29,430
it's exactly this

571
00:37:29,450 --> 00:37:30,630
right so

572
00:37:30,670 --> 00:37:33,770
this is a list of that

573
00:37:33,810 --> 00:37:39,600
exact expression which which is marginalized out

574
00:37:39,700 --> 00:37:40,990
the next one

575
00:37:41,010 --> 00:37:45,610
you can see this is because we have

576
00:37:48,790 --> 00:37:49,830
in after

577
00:37:49,840 --> 00:37:56,680
after the visit him as opposed to

578
00:37:56,710 --> 00:37:58,170
you before

579
00:37:58,290 --> 00:38:00,830
examples street

580
00:38:00,830 --> 00:38:04,050
using a factor in the computation tree

581
00:38:04,060 --> 00:38:09,910
messages like this this is so because it's on the structure of the population is

582
00:38:09,910 --> 00:38:10,770
the same

583
00:38:10,820 --> 00:38:14,370
and you know you get exactly this

584
00:38:14,390 --> 00:38:18,330
so this is a

585
00:38:18,480 --> 00:38:23,660
the structure is actually quite efficiently

586
00:38:23,840 --> 00:38:25,430
which was

587
00:38:25,450 --> 00:38:30,310
ninety percent of people efficient this is

588
00:38:30,470 --> 00:38:33,320
the story is set of models

589
00:38:33,330 --> 00:38:35,460
right so

590
00:38:35,480 --> 00:38:37,520
so successful was is

591
00:38:38,480 --> 00:38:39,480
right so

592
00:38:39,520 --> 00:38:40,590
it it is

593
00:38:40,600 --> 00:38:43,730
this is known as

594
00:38:43,820 --> 00:38:48,330
according to them and things like that it's exactly this

595
00:38:48,340 --> 00:38:49,530
so this is

596
00:38:50,100 --> 00:38:53,210
these things

597
00:38:53,270 --> 00:38:54,850
so it's

598
00:38:57,080 --> 00:38:58,310
into the details

599
00:39:02,040 --> 00:39:04,530
this is not useful

600
00:39:04,540 --> 00:39:10,490
graphical models since the seventies which have been used in many different applications that

601
00:39:10,540 --> 00:39:19,550
speech recognition that has been applied to many applications ever since so this mentioned

602
00:39:19,560 --> 00:39:22,840
the sequence of this is

603
00:39:22,920 --> 00:39:25,850
so this means it is it one and so

604
00:39:27,120 --> 00:39:30,200
sixty minus one xtxt plus one these observed

605
00:39:31,260 --> 00:39:37,040
the first step so this is first one factor graph and in

606
00:39:37,440 --> 00:39:40,630
the problem is that you have

607
00:39:41,370 --> 00:39:42,770
what is it that you

608
00:39:42,770 --> 00:39:44,970
it can be solved

609
00:39:45,030 --> 00:39:50,990
OK example relates to the example which is used in speech recognition

610
00:39:51,100 --> 00:39:52,420
he was

611
00:39:54,900 --> 00:39:56,680
it's not about

612
00:40:02,190 --> 00:40:07,630
the sixty this is the case with three outside

613
00:40:10,360 --> 00:40:12,470
this guy lebanon

614
00:40:13,130 --> 00:40:18,550
so you will see that this person is going to allow the you to

615
00:40:18,590 --> 00:40:21,270
mining and chance of rain

616
00:40:21,350 --> 00:40:22,850
it just

617
00:40:22,850 --> 00:40:30,230
about these two p atomic wavefunctions that are centered on the carbon right we're not

618
00:40:30,290 --> 00:40:32,800
done yet

619
00:40:32,850 --> 00:40:34,810
right so what's going to happen

620
00:40:34,820 --> 00:40:37,190
so that will there no overlap

621
00:40:37,190 --> 00:40:41,190
constructively and destructively interfere

622
00:40:41,210 --> 00:40:42,630
and i

623
00:40:42,650 --> 00:40:43,780
to see the

624
00:40:43,800 --> 00:40:48,690
let's take this benzene molecule and rotated ninety degrees so that we're going to look

625
00:40:48,690 --> 00:40:49,950
at it

626
00:40:49,960 --> 00:40:54,150
from the side and view that you

627
00:40:54,160 --> 00:40:59,500
so there it is right here are my carbon carbon sigma bond

628
00:40:59,560 --> 00:41:02,760
two sp two two two sp two bonds

629
00:41:02,770 --> 00:41:05,740
here's my arm

630
00:41:05,780 --> 00:41:12,280
sigma bond between the hydrogen on the carbon two sp two wave function

631
00:41:12,290 --> 00:41:14,520
and now i'm going to let the

632
00:41:14,530 --> 00:41:15,660
two p

633
00:41:15,750 --> 00:41:21,590
atomic wavefunctions not ivory functions the atomic wavefunctions and the carbon i'm going to let

634
00:41:22,700 --> 00:41:26,620
constructively and destructively interfere

635
00:41:26,630 --> 00:41:30,320
OK and here goes well they're going to overlap

636
00:41:31,810 --> 00:41:32,660
i got

637
00:41:32,670 --> 00:41:34,470
something that looks like

638
00:41:34,480 --> 00:41:36,330
a pi bond here

639
00:41:37,020 --> 00:41:38,180
i've got

640
00:41:38,180 --> 00:41:43,950
weight function above the plane of these and i got weight function below

641
00:41:43,960 --> 00:41:46,550
the plane of these atoms

642
00:41:46,580 --> 00:41:49,070
it is a pi bond

643
00:41:49,080 --> 00:41:53,070
that is formed by the overlap of the two p

644
00:41:53,180 --> 00:41:57,560
wavefunctions the atomic wavefunctions are

645
00:41:57,580 --> 00:41:59,470
right it's part

646
00:41:59,500 --> 00:42:04,320
because it's not symmetric around the

647
00:42:04,340 --> 00:42:06,820
now all of the body axis

648
00:42:07,210 --> 00:42:11,220
there's density up here density up here

649
00:42:11,230 --> 00:42:13,820
but not in the plane

650
00:42:15,870 --> 00:42:21,980
let's look at it again from the top you

651
00:42:21,980 --> 00:42:24,490
right so what i do well i lack

652
00:42:24,510 --> 00:42:27,480
these two p wave functions here

653
00:42:29,520 --> 00:42:34,210
so let's look at a little more carefully what exactly do they do here

654
00:42:34,250 --> 00:42:35,930
so what i did

655
00:42:36,010 --> 00:42:37,710
is for example

656
00:42:37,720 --> 00:42:42,790
i let the two p wave functions and these two carbons overlap to form a

657
00:42:42,790 --> 00:42:45,800
pi bond

658
00:42:45,820 --> 00:42:51,040
i love the two p wave functions and these two carbons overlap

659
00:42:51,050 --> 00:42:53,750
to form a pi bond

660
00:42:53,760 --> 00:42:55,570
and i like these two

661
00:42:55,580 --> 00:43:00,280
two p wave functions overlap to form a pipe that

662
00:43:00,330 --> 00:43:02,040
well that's very nice

663
00:43:03,630 --> 00:43:05,530
i could also

664
00:43:05,550 --> 00:43:06,510
the last

665
00:43:06,660 --> 00:43:11,830
two p wave functions and these two carbons overlap for these two problems

666
00:43:12,590 --> 00:43:17,590
in other words i could have made a pi bond between these two carbons

667
00:43:17,630 --> 00:43:19,830
are these two carbons schools

668
00:43:19,850 --> 00:43:21,740
these two parent

669
00:43:22,930 --> 00:43:25,240
so which one do i chose

670
00:43:27,220 --> 00:43:30,130
in recitation the other day

671
00:43:30,150 --> 00:43:33,300
you should have a look at the

672
00:43:33,320 --> 00:43:34,810
lewis structure

673
00:43:34,820 --> 00:43:38,700
of molecular benzene and benzene

674
00:43:38,750 --> 00:43:42,020
and what you should have seen

675
00:43:42,120 --> 00:43:47,560
is that you would be able to write several different lewis structures all which have

676
00:43:47,560 --> 00:43:49,290
the the same set

677
00:43:49,310 --> 00:43:51,480
of the formal charges

678
00:43:51,490 --> 00:43:56,980
and you wouldn't be able to decide which structure you should here

679
00:43:56,980 --> 00:43:59,910
based on the formal charges

680
00:44:00,070 --> 00:44:03,800
rather what you had is the resonant structure

681
00:44:03,830 --> 00:44:07,140
and that is exactly what you hear

682
00:44:07,150 --> 00:44:09,800
instead of

683
00:44:09,820 --> 00:44:12,620
the six x for electrons

684
00:44:12,630 --> 00:44:17,590
which are centered on the carbon those two pi electrons right one year one there

685
00:44:17,590 --> 00:44:21,030
one one their one there one there

686
00:44:21,070 --> 00:44:22,890
instead of those

687
00:44:23,670 --> 00:44:30,010
each one of those electrons being shared between just one of the adjacent carbons

688
00:44:30,060 --> 00:44:35,820
o six extra electrons are actually d localized

689
00:44:35,830 --> 00:44:39,000
around all the carbons

690
00:44:39,040 --> 00:44:43,460
and so what you're going to form a year is not

691
00:44:43,530 --> 00:44:44,790
a clear

692
00:44:44,800 --> 00:44:50,210
o double bond between the carbon and this one and this one

693
00:44:50,210 --> 00:44:53,800
instead what you're going to form

694
00:44:54,890 --> 00:44:56,560
a kind of the whole

695
00:44:56,620 --> 00:44:58,730
of pi bonds

696
00:44:59,630 --> 00:45:04,680
that is you're going to let those six electrons

697
00:45:04,700 --> 00:45:08,240
be equally distributed so to speak

698
00:45:08,300 --> 00:45:11,200
around all all the six carbons

699
00:45:11,240 --> 00:45:13,720
and so this pi bond here

700
00:45:13,720 --> 00:45:17,510
isn't quite a full pi bond it's kind of a

701
00:45:19,440 --> 00:45:20,890
right because

702
00:45:20,910 --> 00:45:27,460
this current sharing its two p electron with carbon and with this current

703
00:45:27,480 --> 00:45:29,240
and vice versa

704
00:45:29,260 --> 00:45:31,740
thank all the way around

705
00:45:31,740 --> 00:45:37,570
so we have this resonance structure i drew this is kind of of fuzzy

706
00:45:37,590 --> 00:45:42,910
green line here we have the six pi electrons that are localize

707
00:45:43,000 --> 00:45:47,970
amongst these six atoms of this part the brain

708
00:45:48,800 --> 00:45:50,980
so these are the ones

709
00:45:51,830 --> 00:45:53,210
i really

710
00:45:53,220 --> 00:45:54,990
abandoning him

711
00:45:56,020 --> 00:45:58,460
they are these bonds this band

712
00:45:58,480 --> 00:46:01,410
is of more than a single bond

713
00:46:01,420 --> 00:46:05,190
in terms of its bands train

714
00:46:05,200 --> 00:46:09,820
and in terms of its distance it's closer than single bonds

715
00:46:09,850 --> 00:46:13,990
but it isn't as strong as a double bond

716
00:46:13,990 --> 00:46:16,670
it follows this thing here

717
00:46:16,690 --> 00:46:19,860
and then you can then take the covariance

718
00:46:19,870 --> 00:46:24,260
book but the expectation here in the in the middle so what you get here

719
00:46:24,280 --> 00:46:29,340
in the middle is the lagged covariance matrix of this is the source signals and

720
00:46:29,340 --> 00:46:31,990
you will have a and eighty

721
00:46:32,750 --> 00:46:38,290
multiplying it on both sides that the point is that the way it lack covariance

722
00:46:39,250 --> 00:46:43,050
of the rest of the source signals will be diagonal

723
00:46:43,070 --> 00:46:44,260
by definition

724
00:46:44,360 --> 00:46:51,190
well it it it really that it be diagonal simply because the sourcing site independent

725
00:46:51,230 --> 00:46:55,620
and well also we we have to make the assumption that we actually we really

726
00:46:55,620 --> 00:47:00,360
do have some kind of time dependence is some of the correlations which means that

727
00:47:00,760 --> 00:47:06,140
which then implies that this this is really a non-zero by matrix

728
00:47:07,790 --> 00:47:10,660
what this means is that basically

729
00:47:10,670 --> 00:47:17,230
uh this is what i my i guess what this means is that basically

730
00:47:17,520 --> 00:47:22,220
what we need to do is and i can value decomposition we have here matrix

731
00:47:22,220 --> 00:47:26,980
that's well not exactly symmetric but you can take the semantic relation of that by

732
00:47:27,020 --> 00:47:32,520
adding it with its transpose and this is a symmetric matrix is expressed as the

733
00:47:32,530 --> 00:47:37,680
product of an orthogonal matrix by a diagonal matrix times the transpose of the of

734
00:47:37,680 --> 00:47:41,780
the so this is nothing but i can barely legal

735
00:47:44,400 --> 00:47:46,440
we can estimate a

736
00:47:47,480 --> 00:47:49,120
and only if

737
00:47:49,140 --> 00:47:56,180
the eigen value decomposition of that's like covariance matrix of the data

738
00:47:59,290 --> 00:48:00,700
is diagonal

739
00:48:00,710 --> 00:48:03,500
actually i think there was a small area here

740
00:48:06,890 --> 00:48:11,590
so basically i mean here we should be talking about the lack covariance matrix of

741
00:48:11,600 --> 00:48:17,440
z that is that the white and data

742
00:48:17,450 --> 00:48:23,480
well the basic idea is to change so now if and only if document decomposition

743
00:48:23,500 --> 00:48:28,660
is unique we can actually actually get a direct from the eigen value decomposition

744
00:48:28,680 --> 00:48:33,070
now the question is that when you say i can value decomposition unit for symmetric

745
00:48:33,080 --> 00:48:36,240
real valued matrix well it is unique

746
00:48:36,330 --> 00:48:40,040
if if all those i can values are distinct

747
00:48:40,050 --> 00:48:43,700
if not so i can values to one like and values which are equal to

748
00:48:43,700 --> 00:48:49,790
each other than the eigen vectors are no longer uniquely defined because you can make

749
00:48:49,790 --> 00:48:55,720
any kind of arbitrary rotation inside that subspace defined by those two i can to

750
00:48:55,720 --> 00:48:56,100
one y

751
00:48:59,630 --> 00:49:03,330
after this would is that we all that's going that is computationally very simple we

752
00:49:03,330 --> 00:49:06,730
only need to do the eigen value decomposition we see that the bad news is

753
00:49:06,730 --> 00:49:13,100
that is that it doesn't work always basically if all these all sources signals have

754
00:49:13,110 --> 00:49:18,640
the same statistical properties meaning for example that they have the same order correlations then

755
00:49:18,640 --> 00:49:20,290
this method doesn't really work at all

756
00:49:20,700 --> 00:49:22,990
because the eigen value decomposition will be

757
00:49:23,010 --> 00:49:26,190
completely undetermined

758
00:49:26,270 --> 00:49:30,160
but still it in some cases it gives you a very simple and very simple

759
00:49:30,160 --> 00:49:31,780
solution the problem

760
00:49:32,750 --> 00:49:35,330
some improvements to these

761
00:49:35,340 --> 00:49:37,490
the situation can be obtained by

762
00:49:37,510 --> 00:49:43,550
looking at several time lag is not only one has been these basic case well

763
00:49:43,550 --> 00:49:49,430
then what happens is that the computations are more complicated you can just solve it

764
00:49:49,430 --> 00:49:53,300
by eigen value decomposition but then

765
00:49:53,640 --> 00:49:57,890
but then you have more chance of actually separating sources

766
00:49:57,930 --> 00:50:02,540
but still we have we even even if they use

767
00:50:02,550 --> 00:50:08,710
arbitrary number of different time next we still have this fundamental limitation that if you

768
00:50:08,710 --> 00:50:14,000
if there is the features of if the source signals have identical fourier spectrum which

769
00:50:14,000 --> 00:50:18,020
means which is true for example if that if you

770
00:50:18,250 --> 00:50:22,960
if the source signals have the same statistical properties

771
00:50:22,980 --> 00:50:23,690
and then

772
00:50:23,710 --> 00:50:26,020
this method just just doesn't work

773
00:50:26,040 --> 00:50:30,090
the point is the point here is that

774
00:50:30,140 --> 00:50:33,180
if you have two random signals

775
00:50:33,230 --> 00:50:35,010
which have the same

776
00:50:36,600 --> 00:50:38,980
that is the same according to spectra

777
00:50:39,090 --> 00:50:41,030
then any some

778
00:50:41,050 --> 00:50:47,410
in some of these signals which has the same variance the original signals we'll have

779
00:50:47,580 --> 00:50:51,170
again the same the same for respect

780
00:50:51,180 --> 00:50:56,490
and this very but the situation is very different from the case of ICA that's

781
00:50:56,490 --> 00:51:00,330
so that if we have two variables so random variables

782
00:51:00,410 --> 00:51:04,150
non gaussian random variables and we take some

783
00:51:04,150 --> 00:51:08,840
what is this component perpendicular you can just

784
00:51:08,850 --> 00:51:12,940
feel new stuff like that that is the one that is responsible

785
00:51:13,030 --> 00:51:17,560
that is the electric field in the travelling wave that moves outwards because this whole

786
00:51:17,560 --> 00:51:21,270
shell moves out was speed c

787
00:51:21,290 --> 00:51:25,960
and load is this one is perpendicular to the the direction that i have chosen

788
00:51:25,990 --> 00:51:27,250
of propagation

789
00:51:27,260 --> 00:51:28,910
you're watching here

790
00:51:28,970 --> 00:51:30,920
and they shall comes over you

791
00:51:30,930 --> 00:51:34,910
and so do you feel that is perpendicular to line of sight that is the

792
00:51:34,910 --> 00:51:36,610
field in the traveling wave

793
00:51:36,650 --> 00:51:38,330
so our task is now

794
00:51:38,330 --> 00:51:39,500
to calculate

795
00:51:39,520 --> 00:51:40,900
e vector

796
00:51:44,020 --> 00:51:47,010
well if you look at the fact that this triangle

797
00:51:47,030 --> 00:51:49,470
is congruent with this one

798
00:51:49,490 --> 00:51:52,880
then you see that the perpendicular

799
00:51:52,910 --> 00:51:55,050
divided by parallel

800
00:51:56,100 --> 00:52:02,610
he perpendicular divided by parallel must be you perpendicular to

801
00:52:03,720 --> 00:52:05,260
divided by c delta t

802
00:52:05,260 --> 00:52:10,830
but you perpendicular

803
00:52:13,510 --> 00:52:14,840
we noted you

804
00:52:14,850 --> 00:52:15,840
is a

805
00:52:15,850 --> 00:52:19,820
so you perpendicular

806
00:52:19,830 --> 00:52:22,180
is a perpendicular party

807
00:52:22,320 --> 00:52:27,170
a perpendicular is now the component of the acceleration perpendicular to are i don't want

808
00:52:27,170 --> 00:52:29,790
to pull value because it becomes too cluttered with you

809
00:52:29,810 --> 00:52:34,410
i will make new drawing shortly put you in their accelerations in this direction and

810
00:52:34,410 --> 00:52:37,390
so a perpendicular is like this

811
00:52:37,450 --> 00:52:39,620
so i can replace

812
00:52:39,630 --> 00:52:41,620
you perpendicularity

813
00:52:41,630 --> 00:52:45,660
i can replace it by a perpendicular

814
00:52:45,930 --> 00:52:50,090
sorry this is a perpendicular delta t you guys should have

815
00:52:50,120 --> 00:52:52,320
shy guy should screen because

816
00:52:52,320 --> 00:52:57,190
the acceleration only last for about thirty seconds

817
00:52:57,350 --> 00:53:02,920
only delta t sec

818
00:53:02,970 --> 00:53:07,660
so now i get a perpendicular time delta t times t

819
00:53:07,670 --> 00:53:09,750
divided by c delta t

820
00:53:09,810 --> 00:53:12,800
so there is a perpendicular

821
00:53:12,930 --> 00:53:14,160
times t

822
00:53:14,170 --> 00:53:20,670
divided by c

823
00:53:20,720 --> 00:53:22,150
if no

824
00:53:22,200 --> 00:53:25,070
i can calculate what you parallelise

825
00:53:25,110 --> 00:53:28,060
i'm done because i know the perpendicular is

826
00:53:28,060 --> 00:53:29,850
i put the parallel here

827
00:53:29,900 --> 00:53:30,910
and i am

828
00:53:30,920 --> 00:53:32,250
in business

829
00:53:32,250 --> 00:53:35,770
before i do that i want to eliminate t

830
00:53:35,820 --> 00:53:38,040
and i'm going to write for the st

831
00:53:38,100 --> 00:53:40,670
are divided by c

832
00:53:40,690 --> 00:53:44,080
so it is also a perpendicular

833
00:53:44,080 --> 00:53:46,010
times are

834
00:53:46,060 --> 00:53:48,850
divided by c squared

835
00:53:48,940 --> 00:53:56,360
and so i can write down perpendicular is this times parallel

836
00:53:56,370 --> 00:54:00,510
how do we find the parallel

837
00:54:00,550 --> 00:54:02,020
o eight o two

838
00:54:02,030 --> 00:54:04,430
gauss law

839
00:54:04,450 --> 00:54:07,100
i make a pillbox

840
00:54:07,110 --> 00:54:11,370
and the pillbox is going to be like this i'll make a drawing of it

841
00:54:11,390 --> 00:54:15,830
and this surface is here in the world doesn't know yet what happens

842
00:54:15,870 --> 00:54:19,890
and this surface here is in the world which is in turn more

843
00:54:19,940 --> 00:54:24,180
which is in the transition

844
00:54:24,190 --> 00:54:28,450
so i'm going to make that pillbox for you

845
00:54:28,500 --> 00:54:34,600
so i draw here again this

846
00:54:34,610 --> 00:54:38,220
this is aligned to go somewhere to this point here is not this one the

847
00:54:40,400 --> 00:54:46,310
and here is my pillbox

848
00:54:46,350 --> 00:54:52,520
that's my pillbox

849
00:54:52,530 --> 00:54:53,650
and so on

850
00:54:53,670 --> 00:54:55,520
in that little box

851
00:54:55,550 --> 00:54:58,060
i have in the outside world

852
00:54:58,070 --> 00:55:01,240
the outside world here i have that if you want

853
00:55:01,280 --> 00:55:04,780
so i'll put it in and e it's in the world that doesn't know yet

854
00:55:04,780 --> 00:55:08,030
what happened

855
00:55:08,040 --> 00:55:11,610
that's really going to point o

856
00:55:11,650 --> 00:55:19,270
inside the box i have this property portfolio coming in like this

857
00:55:19,310 --> 00:55:24,540
and then going straight through the sides of the box is this one in particular

858
00:55:24,560 --> 00:55:26,170
but this comes in

859
00:55:26,310 --> 00:55:27,610
and perpendicular

860
00:55:27,630 --> 00:55:29,640
and that the perpendicular

861
00:55:29,710 --> 00:55:31,750
goes out

862
00:55:31,810 --> 00:55:34,260
now since this is in vacuum

863
00:55:34,300 --> 00:55:37,100
there is no charge density inside this box

864
00:55:37,110 --> 00:55:40,350
so the divergence of e must be zero

865
00:55:40,370 --> 00:55:41,990
and that means that

866
00:55:42,030 --> 00:55:43,840
the vector here

867
00:55:43,890 --> 00:55:47,350
must be exactly the same as the vector here

868
00:55:47,390 --> 00:55:51,090
because the contribution to these two is zero so this must also be here there

869
00:55:51,090 --> 00:55:54,280
is no charge inside the box

870
00:55:54,320 --> 00:55:57,120
but i do know what this is field this

871
00:55:57,140 --> 00:55:58,970
that is a don't do

872
00:55:58,990 --> 00:56:01,570
if someone tells you that i have the charge here

873
00:56:01,620 --> 00:56:02,850
sitting there

874
00:56:02,850 --> 00:56:06,890
what is the electric field edit distance are that school of law

875
00:56:06,910 --> 00:56:09,820
this is simple is not causal or it's the gauss law

876
00:56:09,860 --> 00:56:14,410
but in any case you will find very easy that this is a vector

877
00:56:14,430 --> 00:56:15,610
is q

878
00:56:15,610 --> 00:56:16,770
divided by

879
00:56:16,780 --> 00:56:17,670
four pi

880
00:56:17,690 --> 00:56:21,840
absolutely absolute zero hours credit falls off as one of our square

881
00:56:21,850 --> 00:56:25,050
you people should remember that from eight o two

882
00:56:25,160 --> 00:56:26,820
so now

883
00:56:26,890 --> 00:56:28,780
we have accomplished

884
00:56:28,780 --> 00:56:31,010
thirteen minutes are almost up

885
00:56:31,030 --> 00:56:33,220
he perpendicular now

886
00:56:33,240 --> 00:56:36,470
it is therefore a perpendicular times are

887
00:56:36,490 --> 00:56:38,410
divided by c squared

888
00:56:38,440 --> 00:56:40,000
times q

889
00:56:41,540 --> 00:56:42,950
divided by four pi

890
00:56:43,040 --> 00:56:45,820
absolutely zero

891
00:56:45,860 --> 00:56:47,700
times are square

892
00:56:47,710 --> 00:56:51,020
you lose one are

893
00:56:51,090 --> 00:56:52,510
and so this

894
00:56:52,540 --> 00:56:54,260
is the classic derivation

895
00:56:54,270 --> 00:56:55,700
also known in the

896
00:56:55,720 --> 00:56:59,410
already were known in the nineteen late nineteenth century

897
00:56:59,420 --> 00:57:01,370
which is now the

898
00:57:01,390 --> 00:57:03,340
electric vector

899
00:57:03,400 --> 00:57:08,620
the strength of the factor which clearly is responsible for the electromagnetic travelling wave because

900
00:57:08,620 --> 00:57:13,600
is perpendicular to my direction or that i have chosen

901
00:57:13,640 --> 00:57:17,210
it is inversely proportional to are

902
00:57:17,220 --> 00:57:18,660
i will come back to that

903
00:57:18,750 --> 00:57:21,550
that is a natural consequence of the conservation

904
00:57:21,550 --> 00:57:22,610
of energy

905
00:57:22,620 --> 00:57:28,340
and this field is very different from static electric fields which fall off is one

906
00:57:28,340 --> 00:57:30,210
of the great

907
00:57:30,290 --> 00:57:34,160
this is the traveling wave which is in the field that falls off

908
00:57:34,180 --> 00:57:35,630
as one of our

909
00:57:35,640 --> 00:57:40,940
not as one of our squared

910
00:57:40,990 --> 00:57:43,530
before i write down the final four

911
00:57:43,540 --> 00:57:49,400
we also have to take into account the fact that there is a time delay

912
00:57:50,050 --> 00:57:54,100
if i observe so i am an observer

913
00:57:54,100 --> 00:57:55,800
the fourier basis

914
00:57:55,830 --> 00:57:59,950
and i may actually be able to acquire single by sending in time which is

915
00:57:59,950 --> 00:58:02,480
what analog to digital converters do

916
00:58:02,490 --> 00:58:03,850
and so the

917
00:58:03,870 --> 00:58:09,490
measures are functions are just the sense it is the function that

918
00:58:09,490 --> 00:58:15,180
given information are simply rocks and then i can calculate the coherence between the canonical

919
00:58:15,180 --> 00:58:20,810
basis of the spike basis in the fourier basis and which was this calculation we

920
00:58:20,810 --> 00:58:25,070
see that all the coefficients are all the same equal to one of his code

921
00:58:25,120 --> 00:58:27,780
and so on and square them and multiply by ten

922
00:58:27,800 --> 00:58:31,860
all this coffee quantity is equal to one and therefore the coherence between time and

923
00:58:31,860 --> 00:58:33,520
frequency is one

924
00:58:33,810 --> 00:58:38,080
and because we've seen that the coherence cannot be less than one what it says

925
00:58:38,080 --> 00:58:43,280
is that spikes in sinusoids are maximally incoherent that is time and frequency our

926
00:58:44,800 --> 00:58:46,470
four five

927
00:58:46,490 --> 00:58:49,750
as it can be in this view of the world

928
00:58:49,770 --> 00:58:52,050
does this make sense

929
00:58:52,070 --> 00:58:54,820
OK and in english it means that despite

930
00:58:54,870 --> 00:58:58,530
looks nothing like the sun that i need a lot of sinusoids to make up

931
00:58:58,530 --> 00:58:59,560
with spike

932
00:58:59,580 --> 00:59:02,570
or that i need a lot of spikes to make up the signs say are

933
00:59:02,570 --> 00:59:09,040
very very different objects one is completely localized the completely global

934
00:59:10,290 --> 00:59:15,930
OK so this is good because we we want no coherence and then we'll see

935
00:59:15,930 --> 00:59:21,190
what you would want to have in in in in pair five size that it

936
00:59:21,190 --> 00:59:23,800
achieves local humans

937
00:59:23,820 --> 00:59:27,500
so for example you may ask what's since i want to use wavelets to do

938
00:59:27,500 --> 00:59:32,380
my image reconstruction what is a going korean was wavelets well lots of things one

939
00:59:32,380 --> 00:59:36,970
thing that i like are those let's introduced by roughly kauffman even a year and

940
00:59:36,970 --> 00:59:39,620
it's kind was an interesting paper because it published

941
00:59:39,970 --> 00:59:44,140
a paper in the early nineties saying this is the system that serves absolutely no

942
00:59:44,140 --> 00:59:47,490
purpose is because it sparsifies nothing

943
00:59:47,530 --> 00:59:52,660
in in particular it does not sparsify wavelets at all and so knows that kind

944
00:59:52,660 --> 00:59:54,470
of random checkerboard

945
00:59:54,490 --> 00:59:58,200
waveforms that looks like this in two d

946
00:59:58,210 --> 01:00:03,890
and the ideal for this compressed sensing applications because incoherent with wavelets and they come

947
01:00:03,890 --> 01:00:09,160
with a very fast algorithm which is useful in applications and when you calculate numerically

948
01:00:09,160 --> 01:00:14,140
is the coherence between let's and wavelet get something which is almost minimal between one

949
01:00:14,140 --> 01:00:16,550
and three

950
01:00:16,570 --> 01:00:20,990
OK and again it's because we know is that it's very localized in in space

951
01:00:20,990 --> 01:00:24,180
were wavelets are extremely low

952
01:00:25,300 --> 01:00:28,780
this is one way to make measurements which

953
01:00:28,830 --> 01:00:30,990
are incoherent in this just to

954
01:00:30,990 --> 01:00:34,090
drawing upon randomness and so

955
01:00:34,120 --> 01:00:40,380
if you just tried to design sensors that essentially correlate with girls in white night

956
01:00:40,460 --> 01:00:42,620
so i i d plus minus one

957
01:00:42,640 --> 01:00:44,250
saying that look like this

958
01:00:44,250 --> 01:00:45,390
then of course

959
01:00:45,410 --> 01:00:50,250
that will be incoherent with everything that is my main by by just design so

960
01:00:50,250 --> 01:00:54,960
you actually have random sensors that are acquiring information about it

961
01:00:55,390 --> 01:01:00,920
the signal of interest by essentially correlated the signal with random waveforms was IID idea

962
01:01:00,920 --> 01:01:06,350
entries is are calcium all binary entries that will be incoherent with anything that is

963
01:01:09,910 --> 01:01:10,690
and so

964
01:01:10,690 --> 01:01:14,830
if you believe that no coherence is a good thing then this is a very

965
01:01:14,830 --> 01:01:16,860
serious proposal because

966
01:01:16,880 --> 01:01:22,360
what i would ask is to design sensors that essentially correlate an object with junk

967
01:01:22,360 --> 01:01:27,810
and that's a bit of a scary proposition and i remember like soon after i

968
01:01:27,810 --> 01:01:33,300
discovered early results in compressed sensing and visited the university and i visited a friend

969
01:01:33,300 --> 01:01:36,040
of mine and i thought i was

970
01:01:36,060 --> 01:01:40,520
i was giving an overview of the talk will be the next day was that

971
01:01:40,700 --> 01:01:45,690
wisconsin actually and this friend of mine told me is a change in talk

972
01:01:45,730 --> 01:01:48,560
o you go away and you go back to california

973
01:01:49,090 --> 01:01:53,550
because you know suggesting that we should design sensors things was like now is whether

974
01:01:53,560 --> 01:01:55,900
we are in two thousand four

975
01:01:56,000 --> 01:02:01,200
OK but the picture is this which is that there's something very sparse that we

976
01:02:01,200 --> 01:02:03,210
wish to sense

977
01:02:03,240 --> 01:02:07,590
something that looks like this something is extremely concentrated except we don't know where

978
01:02:07,620 --> 01:02:11,390
and so we have on the one side sparsity which we have is this kind

979
01:02:11,390 --> 01:02:16,630
of concentrated factor and on the other side has is incoherent measurement which looks like

980
01:02:16,650 --> 01:02:20,550
completely localised wave forms and so

981
01:02:20,570 --> 01:02:23,770
the signal is calls but the measurements are global

982
01:02:23,770 --> 01:02:27,880
and the point of this global measurements is that each measurement picks up a little

983
01:02:27,880 --> 01:02:30,100
information about each component

984
01:02:30,130 --> 01:02:33,120
for example if i have six opposes time

985
01:02:33,140 --> 01:02:36,630
and suppose i have sparse signal in time for example let's say it has only

986
01:02:36,630 --> 01:02:38,040
one spike

987
01:02:38,050 --> 01:02:40,530
so everything is zero but this guy

988
01:02:40,530 --> 01:02:41,690
and then it's zero

989
01:02:41,700 --> 01:02:46,510
and i want to subsamples the signal in time well that is not possible

990
01:02:46,640 --> 01:02:48,980
because if i if i measures this

991
01:02:48,980 --> 01:02:51,100
here here here here here

992
01:02:51,130 --> 01:02:55,810
in i skip this point and of course i missed everything second out samples the

993
01:02:55,810 --> 01:02:57,890
signal that's not possible

994
01:02:57,900 --> 01:03:03,130
but what will see is that we can subsampling very efficiently in an incoherent domain

995
01:03:03,270 --> 01:03:07,370
by making measurements that look like this

996
01:03:07,950 --> 01:03:10,390
OK so now let's look at compressed sensing

997
01:03:10,410 --> 01:03:13,570
and incoherent sampling

998
01:03:13,580 --> 01:03:15,060
OK so now

999
01:03:15,080 --> 01:03:17,890
we have this sensing waveforms phi k

1000
01:03:17,940 --> 01:03:21,210
we have our image of interest which we call we

1001
01:03:21,230 --> 01:03:26,150
correlating we sensing way from phi k and so we're gonna collect data of the

1002
01:03:26,150 --> 01:03:29,960
form y k which is simply using the product between and phi k and the

1003
01:03:29,960 --> 01:03:34,160
problem is as usual that we have measurements were as we would like to see

1004
01:03:34,180 --> 01:03:37,600
and so we have too few data

1005
01:03:38,740 --> 01:03:44,430
right now it shouldn't come as a surprise that well if f has some sparsity

1006
01:03:44,430 --> 01:03:50,070
in some basic side then perhaps we should go about this was construction by finding

1007
01:03:50,090 --> 01:03:55,700
that image whose coefficient sequence in the business side has minimum one norm

1008
01:03:55,790 --> 01:03:57,200
and so out of this

1009
01:03:57,210 --> 01:04:01,730
all the solutions feeding the data we're going to take a specific one

1010
01:04:01,740 --> 01:04:05,220
and we're going to do is we're going pick the solution the minimizes the l

1011
01:04:05,220 --> 01:04:08,360
one norm subject to data constraints

1012
01:04:08,390 --> 01:04:13,030
OK so that's a convex optimisation programme as we've discussed in fact that's a linear

1013
01:04:13,030 --> 01:04:18,040
program i can recast this as a linear programme trivially and so this is something

1014
01:04:18,040 --> 01:04:21,770
that is in principle like and so on the computer

1015
01:04:21,770 --> 01:04:23,690
all right so here's the proposal

1016
01:04:23,710 --> 01:04:25,610
you make very few

1017
01:04:25,630 --> 01:04:29,500
measurements about an object of interest to recover using

1018
01:04:29,510 --> 01:04:30,380
and one

1019
01:04:31,140 --> 01:04:32,580
OK so

1020
01:04:32,600 --> 01:04:36,930
the result is as follows that resulted to myself and justin wonder

1021
01:04:36,940 --> 01:04:42,340
it says suppose that the signals and is indeed sparse that is it has less

1022
01:04:42,380 --> 01:04:46,500
at most s nonzero coefficients right so the right hand

1023
01:04:46,500 --> 01:04:48,010
i put on the computer screen

1024
01:04:48,510 --> 01:04:49,980
it's called the variational free energy

1025
01:04:50,740 --> 01:04:52,480
it depends on the adjustable parameters

1026
01:04:53,870 --> 01:04:55,780
q and by definition is

1027
01:04:56,310 --> 01:04:56,870
the average

1028
01:04:59,610 --> 01:05:00,920
interesting energy function

1029
01:05:01,560 --> 01:05:01,980
and the q

1030
01:05:05,360 --> 01:05:06,280
so q log q

1031
01:05:13,070 --> 01:05:16,070
of q and the theta dependence in here is

1032
01:05:20,500 --> 01:05:24,190
depends on theta theta is a description of how you just

1033
01:05:26,530 --> 01:05:29,560
and this thing has a name is called the variational free energy

1034
01:05:37,650 --> 01:05:39,310
anne because where this came from

1035
01:05:40,150 --> 01:05:41,880
and because of the fact that this thing here

1036
01:05:47,480 --> 01:05:49,180
it is a true statement but

1037
01:05:50,200 --> 01:05:50,980
after the theta

1038
01:05:53,590 --> 01:05:54,890
is lower bounded by

1039
01:05:56,350 --> 01:05:57,740
minus log z

1040
01:06:01,440 --> 01:06:04,310
so if we succeed in minimizing the variational free energy

1041
01:06:04,710 --> 01:06:06,490
we will have also minimized

1042
01:06:07,030 --> 01:06:08,650
the cale between q and p e

1043
01:06:08,740 --> 01:06:12,940
and the objective function that pops out about minimization if we can evaluate the variational

1044
01:06:12,940 --> 01:06:17,290
free energy at the optimum is a bound on log z so well for free

1045
01:06:17,730 --> 01:06:19,030
be getting something interesting

1046
01:06:23,800 --> 01:06:26,610
the variational methods i'll talk to you about today

1047
01:06:27,470 --> 01:06:31,540
are entirely based on this objective function there are other variational methods as well

1048
01:06:32,020 --> 01:06:33,050
but that's all i'm going to

1049
01:06:33,730 --> 01:06:34,180
do today

1050
01:06:38,040 --> 01:06:41,340
so let's look at some examples now so you can see how this works

1051
01:06:42,230 --> 01:06:44,340
can we evaluate this variational free energy

1052
01:06:44,780 --> 01:06:49,050
well for some problems for some red energy is e

1053
01:06:49,590 --> 01:06:54,920
the answer is yes you can as long as you constrain cuter have appropriately simple form

1054
01:06:55,660 --> 01:06:57,420
so let's go through two examples

1055
01:07:01,590 --> 01:07:05,060
these first example i'll do is the good old guassian

1056
01:07:07,050 --> 01:07:08,340
inference thereof

1057
01:07:14,760 --> 01:07:16,370
so hopefully remember this distribution

1058
01:07:18,980 --> 01:07:20,820
discussions all the inference problem

1059
01:07:33,930 --> 01:07:36,040
the assumption is that there is a normal distribution

1060
01:07:36,530 --> 01:07:38,090
the parameters mu sigma squared

1061
01:07:38,500 --> 01:07:39,910
it's giving rise to the data

1062
01:07:49,650 --> 01:07:50,470
we now want to infer

1063
01:07:50,930 --> 01:07:51,810
mu and sigma

1064
01:07:54,020 --> 01:07:55,480
so they read distribution

1065
01:07:59,710 --> 01:08:00,940
is the inference of

1066
01:08:03,120 --> 01:08:03,630
the variance

1067
01:08:05,010 --> 01:08:06,070
and we've looked about before

1068
01:08:09,890 --> 01:08:12,290
andy this is the new axis and this is the thing

1069
01:08:13,440 --> 01:08:14,250
square axis

1070
01:08:14,960 --> 01:08:17,060
what the nasty red distribution looks like

1071
01:08:20,250 --> 01:08:20,920
something like

1072
01:08:22,310 --> 01:08:26,400
the distribution that has the property that any slice through it in this direction

1073
01:08:28,290 --> 01:08:29,590
is a normal distribution

1074
01:08:36,040 --> 01:08:37,220
i didn't realize there are

1075
01:08:38,940 --> 01:08:42,210
and all those are centered on the same place in spite of looks like

1076
01:08:42,640 --> 01:08:43,980
role centered on x but are

1077
01:08:45,650 --> 01:08:46,270
the sample mean

1078
01:08:50,430 --> 01:08:51,170
that's redirect

1079
01:09:03,250 --> 01:09:06,640
okay so all three slices through our normal distributions

1080
01:09:08,180 --> 01:09:09,800
and slices in this direction

1081
01:09:11,980 --> 01:09:13,200
gamma distributions

1082
01:09:20,580 --> 01:09:22,000
maximum the posterior

1083
01:09:24,860 --> 01:09:27,270
under the assumptions that we had earlier in the course

1084
01:09:27,920 --> 01:09:29,240
is at a place called

1085
01:09:32,030 --> 01:09:32,960
sigma is

1086
01:09:33,860 --> 01:09:36,720
sector sigma and sigma red button on a calculator

1087
01:09:37,510 --> 01:09:41,440
however if we marginalize over all these gamma distributions

1088
01:09:42,070 --> 01:09:44,130
the projection all over all those on to

1089
01:09:44,960 --> 01:09:45,490
this axis

1090
01:09:47,500 --> 01:09:48,780
is a gamma distribution

1091
01:09:49,530 --> 01:09:50,090
it has a peak

1092
01:09:52,140 --> 01:09:53,760
a larger values of sigma

1093
01:09:56,310 --> 01:09:56,940
one minus one

1094
01:09:58,740 --> 01:10:00,240
okay so this is a very simple

1095
01:10:03,520 --> 01:10:04,530
we're going to pretend were

1096
01:10:05,860 --> 01:10:08,240
challenge enough by that we want a variational methods

1097
01:10:09,030 --> 01:10:10,260
so what we will not do

1098
01:10:10,680 --> 01:10:12,860
is introduce a variational approximation

1099
01:10:14,580 --> 01:10:19,770
be inference which is the posterior distribution on the and sigma squared given the data

1100
01:10:21,490 --> 01:10:22,940
this can be approximated by

1101
01:10:23,380 --> 01:10:24,500
a similar distribution q

1102
01:10:26,290 --> 01:10:29,440
how much we want constrain what form so we constrain it have

1103
01:10:30,810 --> 01:10:33,200
i'm gonna constrain very little indeed

1104
01:10:33,590 --> 01:10:35,190
i'm just going to constrain it could be

1105
01:10:36,330 --> 01:10:38,470
a separable distribution function and

1106
01:10:40,840 --> 01:10:41,340
they function

1107
01:10:42,270 --> 01:10:42,960
of sigma squared

1108
01:10:43,680 --> 01:10:45,070
so that's the constraint al apply

1109
01:10:46,330 --> 01:10:48,940
and then we can ask the question now if we write down a little

1110
01:10:50,620 --> 01:10:52,390
and minimize it what happens

1111
01:10:59,270 --> 01:11:00,610
so here's what happens

1112
01:11:11,140 --> 01:11:15,290
o m

1113
01:11:16,470 --> 01:11:16,750
thank you

1114
01:11:17,190 --> 01:11:18,870
we have temporarily lost

1115
01:11:23,800 --> 01:11:25,030
so there's the red distribution

1116
01:11:25,760 --> 01:11:27,570
and that's an accurate control part of it

1117
01:11:29,260 --> 01:11:29,750
if you do now

1118
01:11:30,450 --> 01:11:33,810
kickoff with any distribution qx obvious separable form

1119
01:11:35,740 --> 01:11:38,760
and then you say let's alternately update

1120
01:11:39,450 --> 01:11:40,390
the new dependent

1121
01:11:42,010 --> 01:11:43,490
and then the sigma dependent function

1122
01:11:44,030 --> 01:11:46,590
and alternately update them and see what happens

1123
01:11:47,250 --> 01:11:51,570
the answer is straight away when you optimize the new dependent one the new dependent

1124
01:11:51,570 --> 01:11:53,670
thing says i want to be guassian please

1125
01:11:56,780 --> 01:12:00,140
so you can do that's and then if you update these sigma dependent one

1126
01:12:00,700 --> 01:12:03,110
it say i want to be a gamma distribution please

1127
01:12:04,310 --> 01:12:07,770
and then you can ask the new depending on what you want to do now and it says of-course

1128
01:12:08,500 --> 01:12:11,230
i want to be a guassian but he will change as parameters

1129
01:12:11,850 --> 01:12:14,790
and then you ask the sigma depend one what you want to do so we can do this sort of

1130
01:12:16,450 --> 01:12:20,550
i alternating update approach to the optimization about funding is

1131
01:12:22,670 --> 01:12:26,530
after it'll all the variational free energy with respect to the distribution q mew

1132
01:12:26,950 --> 01:12:30,290
and then with respect to q sigma and then we can alternate this range

1133
01:12:30,760 --> 01:12:32,290
and when you run the convergence

1134
01:12:32,980 --> 01:12:33,890
you end up with

1135
01:12:34,530 --> 01:12:36,530
and optimise q distribution that is a normal

1136
01:12:37,810 --> 01:12:39,840
and optimizing the distribution that is a gamma

1137
01:12:43,030 --> 01:12:44,620
the optimized distribution

1138
01:12:45,110 --> 01:12:45,560
over mu

1139
01:12:46,180 --> 01:12:50,360
is a normal distribution centered on x by of course what what else could possibly be

1140
01:12:51,320 --> 01:12:52,040
but it's weird

1141
01:12:52,610 --> 01:12:54,800
isn't the same as this slice through

1142
01:12:54,800 --> 01:12:58,140
i think you can you can the one with the canadian on in a model

1143
01:12:58,140 --> 01:13:00,510
with an EKF you can kind

1144
01:13:00,890 --> 01:13:05,860
so i you basically readability risation each at each time step the appropriate because because

1145
01:13:05,860 --> 01:13:09,910
t to the question relates to just flip back to this nonlinear model i mean

1146
01:13:09,910 --> 01:13:12,840
i hadn't done any careful actually on that model but i think it can be

1147
01:13:15,970 --> 01:13:23,030
a this one yes so basically all eralisation hitting nonlinear function for the state update

1148
01:13:23,030 --> 01:13:27,260
and it's got an awkward term involving time i don't think that presents a problem

1149
01:13:27,260 --> 01:13:32,490
because you just get a slightly different linearisation for each time step

1150
01:13:32,490 --> 01:13:33,970
i think it still works

1151
01:13:38,070 --> 01:13:45,030
it it just becomes less effective it just becomes a constant offset at each time

1152
01:13:45,030 --> 01:13:48,300
in the organization you don't right

1153
01:13:48,360 --> 01:13:52,530
so that that's a red herring it doesn't doesn't bother us for that doesn't bother

1154
01:13:52,530 --> 01:13:54,950
the care

1155
01:13:54,990 --> 01:14:01,320
but this model will about the care because importantly it's got multimodality in the observation

1156
01:14:01,320 --> 01:14:05,650
function because you've got this x squared term here which means there is always an

1157
01:14:05,650 --> 01:14:09,220
ambiguity between x plus or minus values

1158
01:14:09,860 --> 01:14:16,140
the EKF extended kalman filter won't routinely be able to track both both positive and

1159
01:14:16,140 --> 01:14:18,890
negative going parts of the posterior density

1160
01:14:18,950 --> 01:14:22,950
which is one reason why you would want to use it for the model

1161
01:14:22,970 --> 01:14:27,320
right if i can find when were

1162
01:14:27,340 --> 01:14:34,390
they have the things but

1163
01:14:34,450 --> 01:14:36,890
i think we'll be here yes

1164
01:14:36,910 --> 01:14:40,870
right so monte carlo filtering them so

1165
01:14:40,930 --> 01:14:45,340
if we just concerned with calculating expectation is with respect to the filtering density that

1166
01:14:45,340 --> 01:14:48,370
is the question we're interested in

1167
01:14:48,390 --> 01:14:52,820
the integral is intractable and we're going to resort to some kind of monte carlo

1168
01:14:52,820 --> 01:14:54,630
integration so ideally

1169
01:14:54,680 --> 01:14:58,070
we like to be able to draw i i d samples from the filtering

1170
01:14:58,090 --> 01:15:00,220
density somehow

1171
01:15:00,260 --> 01:15:02,640
plug them in to get estimates

1172
01:15:02,660 --> 01:15:05,530
eight half of h have the h-bomb

1173
01:15:05,590 --> 01:15:06,990
of the

1174
01:15:06,990 --> 01:15:13,450
me which will simply be the arithmetic mean of those sampled values h x i

1175
01:15:13,720 --> 01:15:17,820
five to use the i th sample from a large monte carlo collection of n

1176
01:15:17,860 --> 01:15:20,720
capital and samples

1177
01:15:20,820 --> 01:15:25,430
because we can't do that in general we have access to direct samples from p

1178
01:15:25,780 --> 01:15:30,030
to p from the filtering density if we did we pretty much solves the problem

1179
01:15:30,030 --> 01:15:36,610
from monte carlo perspective anyway the monte carlo is really all about is usually about

1180
01:15:36,910 --> 01:15:37,950
how to use

1181
01:15:37,970 --> 01:15:38,990
actually draw

1182
01:15:39,010 --> 01:15:44,360
samples from indirectly from some very hard target density

1183
01:15:44,370 --> 01:15:49,200
so in this case we could do this using importance sampling

1184
01:15:49,300 --> 01:15:52,780
in principle we can anyway so it would take some

1185
01:15:52,800 --> 01:15:58,990
alternative distribution for x t say q vector t called it the importance function

1186
01:15:59,010 --> 01:16:03,470
and there are some minor technical requirements on that principally that it has the same

1187
01:16:04,640 --> 01:16:11,030
as the least is much larger support as the as the filtering density p x

1188
01:16:11,050 --> 01:16:13,390
to give north through t

1189
01:16:13,450 --> 01:16:18,820
now we make in random draws from this proposal function q instead of p

1190
01:16:18,870 --> 01:16:23,220
so you now have a different set of monte carlo samples drawn i i d

1191
01:16:23,220 --> 01:16:26,720
from q t

1192
01:16:26,740 --> 01:16:28,950
problem almost solved but not quite

1193
01:16:30,300 --> 01:16:33,930
to do important something you don't have to make a correction to ensure that the

1194
01:16:34,090 --> 01:16:38,450
expectation estimates good and the required correction would be the same as we had for

1195
01:16:38,450 --> 01:16:44,550
the static importance sampling start the talk called the importance weight w and it would

1196
01:16:45,160 --> 01:16:50,470
the ratio of the filtering density evaluated at the i th sample xt line

1197
01:16:50,470 --> 01:16:51,680
divided by

1198
01:16:51,720 --> 01:16:55,360
importance function the density that is sampled from q

1199
01:16:55,390 --> 01:16:58,260
again evaluated at the sample points

1200
01:16:58,280 --> 01:16:59,860
x i t

1201
01:17:00,490 --> 01:17:07,970
and then if we normalized importance weights if we then go ahead and take these

1202
01:17:07,970 --> 01:17:10,700
W's are normalised to sum to one

1203
01:17:10,760 --> 01:17:14,240
we've got our approximation of the dirac function approximation

1204
01:17:15,430 --> 01:17:19,280
filtering density so would approximately be this weighted sum now

1205
01:17:19,320 --> 01:17:24,070
of direct functions the weights proportional to the ratio of the target filtering building this

1206
01:17:24,280 --> 01:17:26,070
density divided by

1207
01:17:26,110 --> 01:17:27,740
the importance function

1208
01:17:28,610 --> 01:17:35,590
normalized such that they sum to one but still proportional to the rotation

1209
01:17:35,610 --> 01:17:39,950
which again gives the weighted sample estimates for

1210
01:17:42,200 --> 01:17:47,870
and this is just restating what we had before

1211
01:17:48,640 --> 01:17:53,140
we don't need to work through that's just working through the same steps taking our

1212
01:17:53,140 --> 01:17:54,570
approximation for

1213
01:17:54,590 --> 01:17:58,640
the filtering density is now a weighted sum of direct functions

1214
01:17:58,660 --> 01:18:00,970
and showing that the expectation drops out

1215
01:18:01,010 --> 01:18:06,660
the weighted sum of h is evaluated at sample points

1216
01:18:06,720 --> 01:18:10,430
that's what that's all around the globe actually because we're not going to be able

1217
01:18:10,430 --> 01:18:13,010
to do this because we won't be able to calculate the weight so there's gonna

1218
01:18:13,030 --> 01:18:16,010
be another step coming for the time being

1219
01:18:16,050 --> 01:18:21,570
let's just talk about resampling briefly stayed in the sequential setting and they're going to

1220
01:18:22,090 --> 01:18:26,910
progressing this importance sampling from one timepoint to the next the next the next

1221
01:18:26,930 --> 01:18:33,510
the whole importance sampling paradigm will fall down because will find that the weights in

1222
01:18:33,510 --> 01:18:36,280
this weighted importance sampling

1223
01:18:36,320 --> 01:18:42,260
well become very degenerate over time because of the way we construct the sample will

1224
01:18:42,260 --> 01:18:47,320
see see more of that in a moment in by degenerate i mean that's one

1225
01:18:47,320 --> 01:18:51,280
way to carry all the probability mass so one we would have to be one

1226
01:18:51,280 --> 01:18:54,370
and the others would all be very close to zero one will be almost more

1227
01:18:54,370 --> 01:18:57,700
than the others will be very close to zero which means that it's a very

1228
01:18:57,700 --> 01:19:00,250
in the form of engineering models

1229
01:19:00,270 --> 01:19:06,240
so this is a simple information processing model of the overall structure and mechanisms that

1230
01:19:06,240 --> 01:19:07,350
are involved in

1231
01:19:07,370 --> 01:19:11,890
human mind to provide quantitative descriptions of of

1232
01:19:11,930 --> 01:19:18,690
important thing is what this thing is based not just to the next picture a

1233
01:19:18,690 --> 01:19:25,520
set of interconnected processors things shown in grey circles here and memory stores

1234
01:19:25,530 --> 01:19:27,580
which is shown in the square

1235
01:19:27,830 --> 01:19:30,960
and i don't want to go through the gruesome details of this sort of a

1236
01:19:30,960 --> 01:19:34,390
quick example to show you how it works but

1237
01:19:34,430 --> 01:19:38,120
basically what this does is put together a whole bunch of phenomena that have been

1238
01:19:38,120 --> 01:19:42,180
observed into relatively simple form that is easy to see why

1239
01:19:42,400 --> 01:19:45,370
what's involved in getting a particular task done

1240
01:19:46,390 --> 01:19:48,500
so here's a quick example

1241
01:19:48,520 --> 01:19:53,520
before the quick example have to tell you the key box works which is this

1242
01:19:53,520 --> 01:19:56,100
thing called the cognitive processes

1243
01:19:56,370 --> 01:20:02,600
takes information from the production memory and long-term memory and working memory

1244
01:20:03,060 --> 01:20:08,000
and here's the idea this is a strange idea that to make sure of what

1245
01:20:08,000 --> 01:20:14,050
we are often called cognitive science the original idea developed in psychology and artificial intelligence

1246
01:20:14,510 --> 01:20:19,710
it turns out to be a very good way to represent human procedural knowledge if

1247
01:20:19,710 --> 01:20:22,620
you know how to do something what you have there's is a whole bunch of

1248
01:20:22,620 --> 01:20:24,580
this pattern action pairs

1249
01:20:24,590 --> 01:20:25,770
in memory

1250
01:20:25,780 --> 01:20:30,760
in production memory the patterns all tests in parallel but in the actions are performed

1251
01:20:30,760 --> 01:20:36,660
serially each one these takes about seventeen was second if you have a procedure that

1252
01:20:36,660 --> 01:20:40,690
you know are you have a skill what you have a set of rules that

1253
01:20:40,690 --> 01:20:43,220
once they get started firing they will

1254
01:20:43,270 --> 01:20:48,540
fire in the proper order to carry out the task properly to don't want to

1255
01:20:48,540 --> 01:20:52,980
spend some time on the details but this actually works out very well

1256
01:20:52,990 --> 01:20:55,940
in terms of accounting for human problem solving

1257
01:20:55,960 --> 01:21:01,000
execution skill and it's nice because it can be represented in the form of a

1258
01:21:01,000 --> 01:21:07,520
computational simulation so this is the only way to build a simulated humans that knows

1259
01:21:07,520 --> 01:21:12,050
how to do tasks and and that will represent how we think the test should

1260
01:21:12,050 --> 01:21:13,130
be done

1261
01:21:14,200 --> 01:21:19,850
the kind processors and this framework thanks by manipulating the contents of working memory according

1262
01:21:19,860 --> 01:21:26,190
to production rules okay each we can modify what's in working memory and that can

1263
01:21:26,190 --> 01:21:28,090
trigger which rules

1264
01:21:28,120 --> 01:21:35,480
will execute next so here's my cricket example but the simplest as psychologists ever study

1265
01:21:35,480 --> 01:21:40,860
is called simple reaction light comes on press the button as fast as you can

1266
01:21:40,880 --> 01:21:44,880
and you can write journal articles based on the results of this can maybe even

1267
01:21:44,890 --> 01:21:46,460
get ten years OK

1268
01:21:46,720 --> 01:21:51,160
but if it has been represented in this in this system

1269
01:21:52,580 --> 01:21:59,330
what we see is that after hearing instructions what the person has appropriate sets up

1270
01:21:59,330 --> 01:22:04,520
some production rules and in production memory in this case is this one that says

1271
01:22:04,830 --> 01:22:10,590
if the term stimulus is in working memory then put push button working memory and

1272
01:22:10,590 --> 01:22:15,440
we assume that the motor processor has a little bit of knowledge that's says if

1273
01:22:15,440 --> 01:22:19,700
push button is the command in working memory then

1274
01:22:19,890 --> 01:22:24,030
trigger the various muscles which will cause the button to be pushed the down

1275
01:22:24,050 --> 01:22:29,960
so in that first test starts off time because zero stimulus appears

1276
01:22:29,980 --> 01:22:32,160
then after the

1277
01:22:32,220 --> 01:22:38,780
video processors down thing after one hundred most seconds power combination of

1278
01:22:38,790 --> 01:22:45,250
processing the visual stimulus and recognising it takes a hundred no second son the average

1279
01:22:45,250 --> 01:22:51,100
for simple stimulus and we get the term stimulus being deposited in working memory

1280
01:22:51,160 --> 01:22:56,230
said that the time one hundred seconds

1281
01:22:56,240 --> 01:23:00,830
at this point the cognitive processor production rule gets triggered

1282
01:23:00,930 --> 01:23:03,190
over here

1283
01:23:03,250 --> 01:23:05,820
and we see

1284
01:23:05,840 --> 01:23:10,070
it fires and that deposits push-button in working memory

1285
01:23:10,080 --> 01:23:13,190
that takes another seventeen no seconds

1286
01:23:13,240 --> 01:23:19,010
and then the motor processor gets triggered by a push button commands sitting in working

1287
01:23:19,010 --> 01:23:22,100
memory that causes muscles to twitch

1288
01:23:22,120 --> 01:23:27,500
after two hundred forty milliseconds the but actually expressed that's a good thing

1289
01:23:27,520 --> 01:23:32,970
it's alright approximate estimate but it's pretty pretty typical for what a simple reaction will

1290
01:23:32,970 --> 01:23:36,970
take necessary clarification question

1291
01:23:45,500 --> 01:23:47,800
the trees were

1292
01:23:47,800 --> 01:23:48,980
a lot of things

1293
01:23:50,680 --> 01:23:55,720
all these values vary in various ways but the key idea here is that if

1294
01:23:55,720 --> 01:23:58,550
you're trying to get a system designed

1295
01:23:58,580 --> 01:24:02,620
oftentimes these approximations are good enough

1296
01:24:02,630 --> 01:24:09,150
why intelligent design from bad design if you're in a situation that requires more detailed

1297
01:24:09,200 --> 01:24:15,430
more precision then you can collect data as necessary to get more refined estimates of

1298
01:24:16,320 --> 01:24:22,330
OK so should be this is the first simple approximation works well enough for design

1299
01:24:22,330 --> 01:24:27,810
purposes and i'll provide more more extensive example of how this sort of thing actually

1300
01:24:27,810 --> 01:24:29,030
works in practice

1301
01:24:29,990 --> 01:24:37,700
OK so but this is sort of basic sketch of were psychology is in terms

1302
01:24:37,700 --> 01:24:40,210
of understanding a lot about

1303
01:24:40,230 --> 01:24:43,110
the structure of the human mind and how it works

1304
01:24:43,120 --> 01:24:47,080
the point of view of the engineering purposes if you're trying to get a system

1305
01:24:47,080 --> 01:24:50,250
designed this is not a bad idea

1306
01:24:50,310 --> 01:24:52,460
about how to view what goes on with

1307
01:24:52,470 --> 01:24:53,510
with humans

1308
01:24:53,530 --> 01:24:59,810
OK so that provides overall framework terms the big picture and the small picture

1309
01:24:59,820 --> 01:25:03,430
there's a lot more work going on in terms of

1310
01:25:03,430 --> 01:25:07,010
i have refining this model human processor idea

1311
01:25:08,390 --> 01:25:11,090
he said had more about this later on

1312
01:25:11,320 --> 01:25:16,760
but the next thing i want to get to was important phenomenon ideas about perceptual

1313
01:25:16,760 --> 01:25:18,810
motor and cognitive systems

1314
01:25:18,840 --> 01:25:23,620
so start with input basics these are this is input to the computer

1315
01:25:23,630 --> 01:25:25,410
which is output from the human

1316
01:25:27,640 --> 01:25:29,320
twenty miles as

1317
01:25:29,360 --> 01:25:35,210
an example of an ancient movement and the movement were studied extensively long before anybody

1318
01:25:35,210 --> 01:25:37,340
thought of a computer mouse

1319
01:25:37,360 --> 01:25:41,970
OK and profits who case mentioned

1320
01:25:42,000 --> 01:25:45,970
came up with this empirical relationships called fitts law

1321
01:25:45,970 --> 01:25:50,090
and here's what's interesting if you're making and aimed movements you're trying to point to

1322
01:25:50,090 --> 01:25:55,620
something using visual feedback interesting quantities the fact

1323
01:25:55,630 --> 01:25:59,460
if you plan how long it takes to make the movement because the function of

1324
01:26:00,340 --> 01:26:02,340
distance to the target

1325
01:26:02,360 --> 01:26:05,420
the cookouts

1326
01:26:05,420 --> 01:26:06,290
and so on

1327
01:26:06,410 --> 01:26:12,090
and the semantics as per DL in practice actually what we've seen really is the

1328
01:26:12,090 --> 01:26:15,290
OWL lite is not really used i think i think the

1329
01:26:15,290 --> 01:26:20,130
the realization has been the the fragment was selected there is perhaps kind of too

1330
01:26:20,130 --> 01:26:25,290
expensive for some purposes not expressive rather so it's a light something that i think

1331
01:26:25,290 --> 01:26:27,340
we're kind of not really seen

1332
01:26:27,720 --> 01:26:30,500
use particularly so perhaps that could have been

1333
01:26:30,500 --> 01:26:35,180
a slightly smaller language to be more useful

1334
01:26:35,200 --> 01:26:40,840
number of different ways of presenting these things OK so different syntaxes we've got what

1335
01:26:40,840 --> 01:26:45,290
what what's called the abstract syntax is you can define

1336
01:26:45,960 --> 01:26:48,780
the construction the language

1337
01:26:48,790 --> 01:26:53,580
and this was used to define the semantics and the number of concrete syntaxes serializations

1338
01:26:53,580 --> 01:26:56,400
so we have OWL in RDF XML

1339
01:26:56,430 --> 01:27:00,020
which is seen as the kind of normative serializations

1340
01:27:00,020 --> 01:27:04,620
there also an XML presentation syntax and people have worked over the last few years

1341
01:27:04,620 --> 01:27:08,930
on various kind of what might call human readable syntaxes which kind of tend to

1342
01:27:08,930 --> 01:27:13,060
be sort text based on the idea being that they're easier for people to work

1343
01:27:13,060 --> 01:27:17,770
on small examples the RDF XML kind of presentation is not really a human readable

1344
01:27:18,310 --> 01:27:23,760
syntax is quite difficult to understand just evolves into

1345
01:27:29,800 --> 01:27:33,090
a quick survey of the kind of constructors that we get and how

1346
01:27:34,320 --> 01:27:37,890
so i has a number of operators that allows to construct class expressions

1347
01:27:37,960 --> 01:27:42,300
OK and these have some associated semantics i talked about before

1348
01:27:42,320 --> 01:27:46,130
so if so we consider really the semantics has this domain

1349
01:27:46,390 --> 01:27:50,930
delta things and then interpretation functions map

1350
01:27:50,980 --> 01:27:55,110
the concept classes of a to set of things in the domain

1351
01:27:55,140 --> 01:28:00,280
properties to sets of pairs and individuals to individuals and i can then

1352
01:28:00,290 --> 01:28:04,250
so this is essentially tells me how to interpret my atomic things if you remember

1353
01:28:04,250 --> 01:28:08,150
when i talked back about the ontology had some kind of basic vocabulary that likely

1354
01:28:08,150 --> 01:28:11,560
me to talk about my domain and then some additional assumptions that i put on

1355
01:28:11,560 --> 01:28:15,750
top of this tells me how to interpret the basic atomic terms

1356
01:28:15,770 --> 01:28:20,730
and i can then extend this interpretation function to concept expressions

1357
01:28:20,740 --> 01:28:25,510
so for example i have things like i can talk about primitive classes based interpretation

1358
01:28:25,560 --> 01:28:28,330
this is just one interpretation function gives me

1359
01:28:28,360 --> 01:28:32,790
i can talk about intersection union so i have some and operators to allow me

1360
01:28:33,370 --> 01:28:35,540
california new class descriptions

1361
01:28:35,580 --> 01:28:38,530
i have a conference having negation

1362
01:28:39,150 --> 01:28:42,980
and over here on the on the left-hand side of got things like so it's

1363
01:28:42,980 --> 01:28:45,410
telling me that my intersectionofhuman male

1364
01:28:45,420 --> 01:28:50,290
to find out i find the collection of things which are in interpretation human pose

1365
01:28:50,340 --> 01:28:54,970
interpretation of male i find those those things which are in the intersection that set

1366
01:28:55,180 --> 01:28:56,300
this gives me the

1367
01:28:56,340 --> 01:29:00,830
semantics of my intersection so i've got some kind of very clear unambiguous way in

1368
01:29:00,830 --> 01:29:07,080
which i can interpret this notion of the intersection or union complement constructed likely to

1369
01:29:07,080 --> 01:29:09,170
explicitly name

1370
01:29:09,380 --> 01:29:10,640
as a class

1371
01:29:10,930 --> 01:29:15,560
through the individuals that are members of that class this this is likely to build

1372
01:29:15,570 --> 01:29:16,490
a class which

1373
01:29:16,670 --> 01:29:21,270
only consists of these two individuals john mary

1374
01:29:21,280 --> 01:29:26,510
i have explicit quantifications this is a very important thing in this this helps me

1375
01:29:26,510 --> 01:29:28,800
to avoid the kind of black telephone issues

1376
01:29:28,860 --> 01:29:33,470
OK so i can talk about universal and existential quantification so i can i can

1377
01:29:33,470 --> 01:29:39,310
talk about the first example somevaluesfrom OK so this is telling me this class description

1378
01:29:40,080 --> 01:29:45,030
the restriction of all the things that has the child somevaluesfrom lawyer saying OK this

1379
01:29:45,030 --> 01:29:48,820
is the collection of all those things which which are related to something by has

1380
01:29:48,820 --> 01:29:52,120
child relationship and the thing that they are related to

1381
01:29:52,130 --> 01:29:53,620
is the law

1382
01:29:53,630 --> 01:29:57,210
OK so here is that all those sorts some wine

1383
01:29:57,210 --> 01:30:01,620
x y related by has childminder lawyer case this is kind of allowing me to

1384
01:30:01,620 --> 01:30:07,110
explicitly kind of quantified relationship a consumer that to universal quantification which is saying that

1385
01:30:07,260 --> 01:30:12,070
everything is related via this relationship must be in this particular class

1386
01:30:12,120 --> 01:30:17,180
i can also specify cardinalities things that must have at least two children or no

1387
01:30:17,180 --> 01:30:20,040
more than two children and so on

1388
01:30:21,300 --> 01:30:24,670
that gives me a mechanism for kind of describing classes

1389
01:30:24,700 --> 01:30:30,020
one of n doing my ontology design includes some axioms and the axioms are really

1390
01:30:30,020 --> 01:30:32,550
the things that provides the

1391
01:30:33,090 --> 01:30:37,560
the background knowledge because these are things think actually the assumptions i made about the

1392
01:30:37,560 --> 01:30:40,700
domain so for example i can see a subclass of

1393
01:30:40,710 --> 01:30:44,680
i can see that is a subclass of animals so what i'm saying here is

1394
01:30:44,680 --> 01:30:49,230
something that in order for my interpretation is to be kind of valid models i

1395
01:30:49,230 --> 01:30:51,040
really expect the

1396
01:30:51,050 --> 01:30:54,750
interpretation of the of humans to the set of things which humans to be a

1397
01:30:54,750 --> 01:30:58,370
subset of the set of things which are animals so this is kind of removing

1398
01:30:59,040 --> 01:31:04,020
ambiguity OK so now you know all i'm expecting all humans to be animals

1399
01:31:04,180 --> 01:31:07,890
so you have to talk about equivalences so i can say i expect interpretation of

1400
01:31:07,890 --> 01:31:13,470
these particular class descriptions to correspond the okay so again i kind of restricting the

1401
01:31:13,470 --> 01:31:18,020
interpretations that your life thomas trying to force them to be close to how i'm

1402
01:31:18,020 --> 01:31:21,830
outline and one talk very briefly the basics

1403
01:31:21,850 --> 01:31:25,030
you know when you first look at it looks like it's too good to be

1404
01:31:25,840 --> 01:31:31,280
you know but so we figure out why it makes sense and there are some

1405
01:31:31,280 --> 01:31:35,580
interesting mathematical principles that underlie this fields

1406
01:31:35,660 --> 01:31:40,340
and also the an issue of recovery you know of you recover the thing that

1407
01:31:40,340 --> 01:31:46,420
you need from compressed measurements and i'll give you three examples all from from my

1408
01:31:46,420 --> 01:31:53,090
group one will be the construction of gradient fields using l one optimisation and

1409
01:31:53,150 --> 01:31:59,020
how these ideas can be used for iris recognition and also provide cancelability the third

1410
01:31:59,020 --> 01:32:02,460
one is that i'm not very familiar with the matter of my stories are working

1411
01:32:02,460 --> 01:32:08,100
on the whole compressive sensing is useful in graphics and briefly mention other applications of

1412
01:32:08,100 --> 01:32:12,130
course and can give me a signal for the last five ten minutes i really

1413
01:32:12,130 --> 01:32:17,140
want to spend time on concluding remarks i think that's what's spam

1414
01:32:17,190 --> 01:32:21,390
and the feeling is that from what i little i know that the breakthroughs here

1415
01:32:21,390 --> 01:32:26,420
we come not just from the processing site but by integrating sensing and processing site

1416
01:32:27,210 --> 01:32:32,520
for many years darpa has programs in the different sciences itself is known as integrated

1417
01:32:32,520 --> 01:32:34,400
sensing and processing

1418
01:32:34,420 --> 01:32:37,840
in the compressive sensing idea

1419
01:32:37,860 --> 01:32:43,560
OK alright relation is an offshoot of that so

1420
01:32:44,640 --> 01:32:48,530
computer vision researchers we've been expensive sensing what's

1421
01:32:48,560 --> 01:32:52,360
you know put thousand cameras and collect data and so on so suddenly if you

1422
01:32:52,360 --> 01:32:55,650
tell them no know you don't have to get all of them just get what

1423
01:32:55,650 --> 01:33:00,040
you need it's it's a big ship

1424
01:33:00,060 --> 01:33:02,060
my microphone

1425
01:33:04,460 --> 01:33:09,260
so that's the page i make because were eighty five percent ninety percent of computer

1426
01:33:09,260 --> 01:33:13,910
vision researchers we accept that that's collected by others or even by us and we

1427
01:33:13,910 --> 01:33:15,270
just processes

1428
01:33:15,280 --> 01:33:18,470
but now to make an impact in this field you have to work with the

1429
01:33:18,470 --> 01:33:23,510
folks who designed this new cameras and single pixel camera is an example right so

1430
01:33:23,510 --> 01:33:28,190
there are many other sensors like gradient cameras built in march and so on

1431
01:33:28,210 --> 01:33:32,360
so it's kind of a change in our way of thinking so if you want

1432
01:33:32,360 --> 01:33:35,530
to make an impact you go to work with the front end and which is

1433
01:33:35,530 --> 01:33:39,280
kind of good for signal processing types and then

1434
01:33:39,330 --> 01:33:42,600
from the early eighties onwards computer vision research

1435
01:33:42,610 --> 01:33:47,260
as seen in tons of work on the so called regularisation methods and the nom

1436
01:33:47,260 --> 01:33:52,150
that was very comparable to work is a altoona now we see that l one

1437
01:33:52,150 --> 01:33:56,290
arm not nom and so on and sparsity and so forth is very tempting to

1438
01:33:56,290 --> 01:33:59,560
redo all of them using l one norm and so on now

1439
01:33:59,590 --> 01:34:03,650
should we do that i would really make that much of a difference so those

1440
01:34:03,650 --> 01:34:05,360
would be my

1441
01:34:05,380 --> 01:34:10,650
you know can perform most of my concluding remarks sparsity is everywhere as you can

1442
01:34:10,650 --> 01:34:15,580
see you know have a periodic signal in the fourier basis the sparsity and if

1443
01:34:15,580 --> 01:34:21,730
you have background subtracted images background is huge for small the sparsity in spatial extent

1444
01:34:22,180 --> 01:34:26,660
and of course the compression folks so really rely on the fact that you don't

1445
01:34:26,660 --> 01:34:30,190
need to keep the signal in its glory and use it

1446
01:34:30,210 --> 01:34:35,460
a small set of numbers and so on in wavelet theory and many other no

1447
01:34:35,460 --> 01:34:40,040
basis that have been used in the past so again trip signal is another example

1448
01:34:40,040 --> 01:34:45,360
right well traditionally what we do we collect data we sample it and then we

1449
01:34:46,410 --> 01:34:51,410
we have too much better and maybe we can reduce it so that the traditional

1450
01:34:51,420 --> 01:34:57,460
the more you learn in signal processing and image processing process here the idea is

1451
01:34:57,460 --> 01:35:02,700
you have x the original signal and then just don't get all of it just

1452
01:35:03,500 --> 01:35:08,170
bits and pieces of it that's what the compressive measurements are and then transmit them

1453
01:35:08,170 --> 01:35:10,000
and how the method

1454
01:35:10,010 --> 01:35:16,800
recovering the original x so that's the name for compressive sensing what's somebody saying how

1455
01:35:16,800 --> 01:35:17,980
can you get

1456
01:35:18,040 --> 01:35:19,820
more from less

1457
01:35:19,860 --> 01:35:24,890
people ask me and said that in computer vision is asking for more from less

1458
01:35:26,210 --> 01:35:30,860
we're asking for shape from a single and the intensity image stereo is a little

1459
01:35:30,860 --> 01:35:36,080
bit better structure from motion right so we are used to asking more

1460
01:35:36,090 --> 01:35:41,290
from less so compressive sensing and the philosophical is more tuned to

1461
01:35:41,310 --> 01:35:42,440
no computer vision

1462
01:35:42,460 --> 01:35:45,410
researchers at the same time than you do

1463
01:35:45,420 --> 01:35:49,660
ask for more from less there are issues you have to tell people that this

1464
01:35:49,660 --> 01:35:51,790
is actually the

1465
01:35:51,810 --> 01:35:54,940
you know it's time you invest ten dollars and somebody said to give you a

1466
01:35:54,940 --> 01:35:58,590
hundred dollars you really think about right so

1467
01:35:58,600 --> 01:36:03,140
more from from less is always thing that needs to be justified and that is

1468
01:36:03,140 --> 01:36:07,960
the basic thing that we need to worry about

1469
01:36:07,970 --> 01:36:09,000
all right so

1470
01:36:09,010 --> 01:36:15,300
y here the compressive measurements fees some transformation x there that

1471
01:36:15,310 --> 01:36:17,410
that's the really interested in

1472
01:36:17,430 --> 01:36:19,030
so given y

1473
01:36:19,040 --> 01:36:20,960
how do you get x

1474
01:36:21,680 --> 01:36:27,310
in general you can because if you look at the feed the matrix it's what

1475
01:36:27,310 --> 01:36:28,720
people call it the fact

1476
01:36:28,780 --> 01:36:30,610
matrix right because

1477
01:36:30,620 --> 01:36:33,730
more columns in rows and so on so

1478
01:36:33,750 --> 01:36:35,660
t his is really possible

1479
01:36:35,670 --> 01:36:38,510
well suppose the signal

1480
01:36:38,530 --> 01:36:45,130
has only k core elements that are non-zero so that's the name for k sparse

1481
01:36:45,130 --> 01:36:51,640
signals it can be in any representation doesn't have to be in spatial representation would

1482
01:36:51,640 --> 01:36:58,070
be any basis maybe the case the coefficients are non-zero and then put everything dies

1483
01:36:58,080 --> 01:37:02,990
k fourier coefficients are non-zero k plus one on which is erected across it can

1484
01:37:03,530 --> 01:37:09,790
and suppose if the signal is such sort scholar k sparse signals then

1485
01:37:09,800 --> 01:37:13,720
mathematicians you know can be as tall

1486
01:37:13,740 --> 01:37:18,610
and professor donna and so on what on this for the last five years or

1487
01:37:19,880 --> 01:37:23,980
and say this possible but if you look at fee as i said before it's

1488
01:37:23,980 --> 01:37:29,590
not full rank and therefore you lose information and infinitely many x map on to

1489
01:37:30,280 --> 01:37:34,070
so if you are interested in sparse then maybe you can design the matrix p

1490
01:37:34,070 --> 01:37:35,340
such that

1491
01:37:35,350 --> 01:37:38,850
it is the color now the property that allows you

1492
01:37:38,870 --> 01:37:44,910
do that is what is known as the restricted isometry property of the idea is

1493
01:37:44,910 --> 01:37:50,710
to design fees so that each of its k submatrices are full rank if you

1494
01:37:50,710 --> 01:37:56,760
do that then you have the option of either doing zero optimization and since it's

1495
01:37:56,760 --> 01:38:00,640
pretty hard being an NP complete problem you can come up with an l one

1496
01:38:00,640 --> 01:38:04,880
the extracted sample in which we have no nodes change

1497
01:38:05,660 --> 01:38:10,370
so we were so this is an example of inference problem where you want to

1498
01:38:10,400 --> 01:38:14,260
of all the relevant information of this set is the pitch of the notes the

1499
01:38:14,260 --> 01:38:18,220
amplitude and so on

1500
01:38:18,230 --> 01:38:19,330
OK so

1501
01:38:19,500 --> 01:38:24,330
this is the fourier transform of a single flute playing

1502
01:38:26,260 --> 01:38:29,360
here's is the frequency axis and here is the amplitude

1503
01:38:29,370 --> 01:38:35,560
and as you can see there is a very nice fundamental frequency here first harmonic

1504
01:38:35,560 --> 01:38:41,190
sequence x so it is very easy to model this time series as a son

1505
01:38:42,100 --> 01:38:43,870
call signs

1506
01:38:43,900 --> 01:38:48,990
which frequencies are multiple of the fundamental frequency so if any course three then we

1507
01:38:48,990 --> 01:38:50,490
have this one

1508
01:38:50,550 --> 01:38:54,570
and sign is if initial phases coded

1509
01:38:54,580 --> 01:38:55,820
into the

1510
01:38:56,100 --> 01:38:58,320
images of the amplitude

1511
01:39:00,290 --> 01:39:05,610
and we have say two one two three four five six seven eight nine ten

1512
01:39:06,870 --> 01:39:11,130
well this one is very low so let's say we have eleven harmonics so this

1513
01:39:11,130 --> 01:39:12,580
is the parameter him

1514
01:39:12,620 --> 01:39:14,580
so we can model this time series

1515
01:39:14,600 --> 01:39:18,600
we something which looks like that

1516
01:39:18,660 --> 01:39:20,700
any question that is the

1517
01:39:25,280 --> 01:39:28,710
the problem is that this model is not realistic at all it will not feature

1518
01:39:28,710 --> 01:39:30,400
will have

1519
01:39:30,410 --> 01:39:32,660
so we need to improve it

1520
01:39:32,670 --> 01:39:35,250
if we come back to this spectrogram

1521
01:39:35,260 --> 01:39:37,590
then we hold we still have

1522
01:39:37,650 --> 01:39:39,620
the frequency components

1523
01:39:39,680 --> 01:39:44,790
but what we see is first the amplitude is not constant it decreases with time

1524
01:39:44,810 --> 01:39:47,050
and that the frequencies

1525
01:39:47,070 --> 01:39:50,130
i'm not exactly related as multiples

1526
01:39:50,150 --> 01:39:52,840
that is the first harmonic is not twice

1527
01:39:52,850 --> 01:39:55,400
the frequency of the fundamental it's

1528
01:39:55,410 --> 01:39:58,190
close to twice but it's not exactly twice

1529
01:39:58,210 --> 01:40:02,330
so you need to put this into the model as well

1530
01:40:02,350 --> 01:40:03,540
so first

1531
01:40:03,550 --> 01:40:06,690
how to model time varying amplitude

1532
01:40:06,720 --> 01:40:11,450
so imagine this is in blue the amplitude of the partial

1533
01:40:12,580 --> 01:40:16,540
so a good solution could be to decompose it into a set of windows like

1534
01:40:17,580 --> 01:40:20,460
and have an amplitude for each of the windows

1535
01:40:20,480 --> 01:40:24,310
and by summing up all these windows you might be able to reconstruct the overall

1536
01:40:25,100 --> 01:40:29,980
that's the first lady for the modernization

1537
01:40:31,170 --> 01:40:32,610
so we come back

1538
01:40:32,620 --> 01:40:33,970
two how model

1539
01:40:33,990 --> 01:40:37,880
so we are still some all the partial

1540
01:40:37,910 --> 01:40:41,200
here we have the cosine and sine which are

1541
01:40:41,210 --> 01:40:42,880
the partial

1542
01:40:42,940 --> 01:40:45,250
and this time we have

1543
01:40:45,280 --> 01:40:49,000
and amplitude which is decomposed on the basis of functions phi

1544
01:40:49,080 --> 01:40:53,170
we sum up on all the functions the basis functions

1545
01:40:53,180 --> 01:40:55,950
if i come back to the previous slide

1546
01:40:55,960 --> 01:40:57,490
the phi functions are

1547
01:40:58,440 --> 01:40:59,340
in red

1548
01:40:59,360 --> 01:41:03,800
OK each one is localized in time

1549
01:41:04,830 --> 01:41:07,090
it corresponds to this

1550
01:41:07,100 --> 01:41:10,620
and another improvement through for

1551
01:41:10,630 --> 01:41:15,450
compared to the previous model is that matters of frequency is not exactly equal

1552
01:41:15,490 --> 01:41:19,660
and i multiple of the fundamental frequency

1553
01:41:19,670 --> 01:41:22,430
right so in this example uses that

1554
01:41:22,440 --> 01:41:23,290
from the

1555
01:41:23,300 --> 01:41:25,290
from a set of that we can build

1556
01:41:26,490 --> 01:41:28,900
for example

1557
01:41:30,090 --> 01:41:31,470
for instance we have

1558
01:41:32,650 --> 01:41:36,980
it's a mathematical model it is not the probabilistic model right so we need to

1559
01:41:37,870 --> 01:41:42,920
probabilistic assumptions around

1560
01:41:42,930 --> 01:41:43,760
OK so

1561
01:41:43,780 --> 01:41:45,830
this is just a remark

1562
01:41:47,670 --> 01:41:50,960
if i consider for one i times the cosine

1563
01:41:50,980 --> 01:41:55,940
then it's time frequency atoms that we just discussed in in the previous lecture

1564
01:41:55,950 --> 01:42:00,440
and is the like that so overall what we're going to do is to project

1565
01:42:00,600 --> 01:42:04,780
time series and to a set of time for concept

1566
01:42:04,840 --> 01:42:07,820
just to make the link with respect

1567
01:42:09,070 --> 01:42:13,090
this model for example we have only

1568
01:42:13,110 --> 01:42:17,990
previously when only one node that is one fundamental frequency and the partials but in

1569
01:42:17,990 --> 01:42:22,090
true in real music you so all notes played at the same time so you

1570
01:42:22,090 --> 01:42:23,210
need to sum up

1571
01:42:23,920 --> 01:42:26,690
all the nodes in the time series

1572
01:42:26,700 --> 01:42:29,300
so now we have

1573
01:42:29,340 --> 01:42:30,730
a realistic

1574
01:42:31,420 --> 01:42:32,450
the music

1575
01:42:33,160 --> 01:42:34,100
many music

1576
01:42:34,310 --> 01:42:39,130
OK so

1577
01:42:39,230 --> 01:42:42,150
this can be very easily written in vector form

1578
01:42:42,160 --> 01:42:46,440
OK so i'll do it now into two simplifies the patients

1579
01:42:46,470 --> 01:42:52,430
so this is the time series in vector form beta victories vector of all the

1580
01:42:53,400 --> 01:42:56,100
the vector of noise and g

1581
01:42:56,110 --> 01:42:58,310
it is the matrix of

1582
01:42:58,360 --> 01:42:59,800
gaussian for

1583
01:42:59,810 --> 01:43:01,070
gabor atoms

1584
01:43:01,080 --> 01:43:03,510
it is the metrics made of these guys

1585
01:43:03,570 --> 01:43:07,740
OK stacked in columns and we want to predlrt number of partial for each node

1586
01:43:07,950 --> 01:43:12,580
and on the number of nodes so we have an inference problem in which the

1587
01:43:12,580 --> 01:43:18,750
dimension of the state space is varying

1588
01:43:18,780 --> 01:43:20,210
OK and

1589
01:43:20,250 --> 01:43:23,440
the parameter we want to estimate is made of

1590
01:43:23,480 --> 01:43:30,550
the amplitude the variance of the additive noise and the frequencies

1591
01:43:34,080 --> 01:43:36,090
if we assume aggression nice

1592
01:43:36,100 --> 01:43:38,850
it is very easy to write the likelihood

1593
01:43:38,870 --> 01:43:41,010
OK this is a gaussian likelihood

1594
01:43:41,030 --> 01:43:42,710
where we have here is model

1595
01:43:42,710 --> 01:43:44,550
the true that

1596
01:43:44,570 --> 01:43:46,630
the squared distance and

1597
01:43:46,860 --> 01:43:51,060
was in the gaussian distribution

1598
01:43:51,100 --> 01:43:55,400
nothing very complicated here

1599
01:43:57,250 --> 01:43:58,690
so the

1600
01:43:58,700 --> 01:44:03,380
in this example assume we want to learn everything we can do about music so

1601
01:44:03,380 --> 01:44:07,200
for example we would like to learn how many notes have played

1602
01:44:07,210 --> 01:44:10,400
for each note how many possible that have

1603
01:44:10,420 --> 01:44:12,800
and for each of these nodes

1604
01:44:12,810 --> 01:44:16,790
what are the frequencies of the fundamental and the partials

1605
01:44:16,830 --> 01:44:20,000
so this is a big set of parameters

1606
01:44:20,010 --> 01:44:22,590
i assume you have forsaken the music

1607
01:44:22,680 --> 01:44:25,340
we have three nodes each with its partial

1608
01:44:25,340 --> 01:44:28,710
i don't think there's much difference here really between the

1609
01:44:28,750 --> 01:44:33,080
sociologist economist for social physicists encounters this i think

1610
01:44:33,160 --> 01:44:38,920
this issue of computational versus dynamic definition is

1611
01:44:39,830 --> 01:44:41,700
across the disciplines

1612
01:44:41,810 --> 01:44:48,120
now some of you may have read john hawkins the end of science came out

1613
01:44:48,140 --> 01:44:50,870
a a little over a decade ago the best-selling book

1614
01:44:50,910 --> 01:44:52,690
another scientific american

1615
01:44:52,700 --> 01:44:55,700
and he has a chapter in there

1616
01:44:55,710 --> 01:44:57,760
two chapters which is very critical

1617
01:44:57,780 --> 01:44:59,770
of complexity approaches

1618
01:44:59,860 --> 01:45:02,950
santa fe institute things that were done there

1619
01:45:03,180 --> 01:45:06,560
he came up with this term KL complexity

1620
01:45:06,580 --> 01:45:12,000
he he cites floyd MIT compiled forty five

1621
01:45:12,010 --> 01:45:14,950
distinct definitions of complexity

1622
01:45:14,960 --> 01:45:17,980
and so on

1623
01:45:27,890 --> 01:45:31,900
the boundary here

1624
01:45:34,290 --> 01:45:44,700
so actually at the bottom of the page we have something

1625
01:45:44,750 --> 01:45:49,430
one of the things that hawkins came up with this difficult four

1626
01:45:49,440 --> 01:45:51,350
and cybernetics

1627
01:45:51,360 --> 01:45:53,700
catastrophe theory chaos theory

1628
01:45:53,750 --> 01:45:56,380
and complexity theory

1629
01:45:56,400 --> 01:46:00,300
now in the paper in nineteen ninety nine i want all these together to

1630
01:46:00,320 --> 01:46:04,750
in the pay paper in the journal of economic perspectives to call these big ten

1631
01:46:06,630 --> 01:46:10,990
and small time complexity was sort of what most people here would think of it

1632
01:46:11,100 --> 01:46:12,850
sort of

1633
01:46:12,870 --> 01:46:16,220
but what i call your heterogeneous agents type complexity

1634
01:46:16,270 --> 01:46:21,200
agent based complexity sort of thing one has seen out of santa fe institute

1635
01:46:21,250 --> 01:46:24,330
some other places in more recent years i think the sort of thing many people

1636
01:46:24,330 --> 01:46:25,210
in this room

1637
01:46:25,230 --> 01:46:27,460
are fact involved this sort work

1638
01:46:28,410 --> 01:46:31,700
and according of use these forces to dismiss

1639
01:46:31,720 --> 01:46:35,460
all said well we had this string of intellectual bubbles

1640
01:46:35,480 --> 01:46:38,440
first order cybernetics by decades

1641
01:46:38,460 --> 01:46:44,010
in the sixties was contested during in the seventies and newscaster eighties there we got

1642
01:46:44,100 --> 01:46:46,370
small time complexity in the nineties

1643
01:46:46,390 --> 01:46:49,460
they're all bubbles and you know

1644
01:46:49,510 --> 01:46:54,170
garbage therefore you know since guitar string theory with garbage all of the garbage

1645
01:46:54,210 --> 01:46:59,320
paper last year in the journal of economic dynamics and control writers attempted to revive

1646
01:46:59,330 --> 01:47:04,550
to test theory that the baby got thrown out with the bathwater other problems overwrite

1647
01:47:04,550 --> 01:47:06,200
all these over-hyped

1648
01:47:06,220 --> 01:47:10,560
but just because you haven't over-valuation doesn't mean you overshoot the other way round evaluation

1649
01:47:10,560 --> 01:47:11,660
defined kind of

1650
01:47:12,980 --> 01:47:16,610
valuation will measure what these things are

1651
01:47:16,630 --> 01:47:20,610
and i argued that in fact organ before it had a very active or inactive

1652
01:47:20,610 --> 01:47:23,670
point that there is a faint of continuity

1653
01:47:23,680 --> 01:47:26,620
and accumulated development through these ideas

1654
01:47:26,640 --> 01:47:29,760
fundamental link is nonlinear dynamics

1655
01:47:29,770 --> 01:47:33,390
and the idea of the dodgers

1656
01:47:33,410 --> 01:47:37,860
cool uris if you will and dynamics arising from these

1657
01:47:37,880 --> 01:47:39,600
nonlinear dynamics

1658
01:47:39,620 --> 01:47:42,170
i actually see

1659
01:47:42,200 --> 01:47:44,360
the cybernetics is mostly disappear

1660
01:47:44,370 --> 01:47:47,090
i see it sort of the best part of it is as a sort of

1661
01:47:47,090 --> 01:47:54,270
reappearing in a small town heterogeneous agents complexity agent based modeling will and both of

1662
01:47:54,270 --> 01:47:58,930
these other elements that that are useful in the analysis i see this as a

1663
01:47:58,930 --> 01:48:02,470
cumulative process not a not a sequence

1664
01:48:02,500 --> 01:48:03,870
dead worthless

1665
01:48:03,890 --> 01:48:05,690
bubbles it should be thrown out the window

1666
01:48:05,700 --> 01:48:10,460
but cumulative process of intellectual development and there are quite a few individuals around who

1667
01:48:10,460 --> 01:48:16,010
in fact some time i think who have been involved with a three if not

1668
01:48:16,010 --> 01:48:17,170
all four of these

1669
01:48:17,280 --> 01:48:22,800
kind of building on top of each other to kind of view of the economy

1670
01:48:22,810 --> 01:48:29,290
so i said i compare this to sort a how we think about certain terms

1671
01:48:29,290 --> 01:48:33,230
sometimes sometimes the terms we use for things are created by critics

1672
01:48:33,240 --> 01:48:36,930
i think the best way to think about this is in our our history

1673
01:48:36,940 --> 01:48:39,120
OK i think of the term impressionism

1674
01:48:39,970 --> 01:48:45,000
today an impressionist painting a real impressionist painting is worth many many millions of dollars

1675
01:48:45,010 --> 01:48:49,020
euros and swiss francs and if you if you had a roman a you know

1676
01:48:49,080 --> 01:48:51,590
you would be very wealthy he had very

1677
01:48:51,610 --> 01:48:55,920
go bankrupt to get your hands on it and you know the first came up

1678
01:48:55,920 --> 01:49:00,480
with the term impressionism as critic he was putting down overhears here is this painting

1679
01:49:00,480 --> 01:49:02,450
by this guy money

1680
01:49:02,490 --> 01:49:07,880
sunrise in london by just is not realistic it it's just impressions of you know

1681
01:49:07,910 --> 01:49:11,650
get a lot of people have sent away from the camp so you know now

1682
01:49:11,650 --> 01:49:14,910
is actually all and so so

1683
01:49:14,920 --> 01:49:18,740
i sort of take organs criticism just for that

1684
01:49:18,760 --> 01:49:22,490
morgan's right the forces but in fact this is the positive about this is not

1685
01:49:22,490 --> 01:49:26,100
something to sneer just have to keep keep the balanced view here

1686
01:49:26,110 --> 01:49:28,290
and not get all impressed that there are bubbles

1687
01:49:28,310 --> 01:49:30,760
over-hyping but certainly did have

1688
01:49:30,770 --> 01:49:36,460
now this view very much tied the dynamic complexity view from there i i drew

1689
01:49:36,460 --> 01:49:42,850
from richard de my predecessors energy about who that gave a nice

1690
01:49:42,930 --> 01:49:47,580
definition that i have used a number of occasions saying that dynamic complexity

1691
01:49:47,640 --> 01:49:52,820
it involves having a system in which you have died since we have

1692
01:49:53,640 --> 01:49:55,390
some erratic dynamics

1693
01:49:55,400 --> 01:50:00,340
more specifically not convergence to point not a simple expansion and contraction

1694
01:50:00,350 --> 01:50:06,580
and not just the limit cycle this fuzzy was about what kind of cyclical fluctuations

1695
01:50:06,580 --> 01:50:07,340
are in

1696
01:50:07,360 --> 01:50:14,050
any case you know you can get great discontinuity is you can get erratic fluctuations

1697
01:50:14,060 --> 01:50:16,790
the variety of things can happen

1698
01:50:16,810 --> 01:50:21,980
and i really for say most economists i'm not quite sure about sociologists this is

1699
01:50:22,180 --> 01:50:24,750
this is really what most practical

1700
01:50:24,790 --> 01:50:28,250
complexity economics they think in terms of what they look at

1701
01:50:28,270 --> 01:50:29,830
three years

1702
01:50:29,920 --> 01:50:34,530
and i'm not going to get off along the discussion here about certain details of

1703
01:50:34,530 --> 01:50:39,290
this are what these terms mean take

1704
01:50:39,330 --> 01:50:42,690
we've got that we have some of the fish to fry so hopefully you know

1705
01:50:42,700 --> 01:50:46,480
you have an idea and opportunity is in some of these other things

1706
01:50:46,580 --> 01:50:53,220
so in you know most of these systems are not there are a few cases

1707
01:50:53,230 --> 01:50:56,690
richard goodwin actually had a model in nineteen forty seven

1708
01:50:56,700 --> 01:51:01,000
alan turing who was able to to generate the dodgers erratic

1709
01:51:01,050 --> 01:51:05,270
dynamics that was a couple of linear systems flags

1710
01:51:05,280 --> 01:51:10,350
however if you reduced the system to normal form it becomes nonlinear

1711
01:51:10,360 --> 01:51:15,990
fuzzy definition many people study this particular equation just take this used by robert greatest

1712
01:51:15,990 --> 01:51:17,700
q two

1713
01:51:17,740 --> 01:51:23,910
then i use the superposition principle which we've used many times in a to one

1714
01:51:23,930 --> 01:51:27,570
and we say OK the net force on number two

1715
01:51:27,580 --> 01:51:29,740
it is the fourth studio number one

1716
01:51:29,740 --> 01:51:32,850
plus the force from number three

1717
01:51:32,910 --> 01:51:34,070
if number three

1718
01:51:34,080 --> 01:51:37,300
this is positive and this is positive and these were negative

1719
01:51:37,340 --> 01:51:38,780
then this force

1720
01:51:38,780 --> 01:51:40,700
would be in this direction

1721
01:51:41,870 --> 01:51:44,180
one x three

1722
01:51:45,890 --> 01:51:49,490
and then the net force

1723
01:51:49,510 --> 01:51:50,800
on number two

1724
01:51:50,800 --> 01:51:54,050
it would be the vectorial some of these

1725
01:51:54,050 --> 01:51:59,240
is it obvious that the superposition principle works

1726
01:51:59,260 --> 01:52:01,010
not at all

1727
01:52:01,070 --> 01:52:02,970
it's not at all obvious

1728
01:52:02,990 --> 01:52:05,920
i do we believe in its yes we do why do we believe in it

1729
01:52:05,920 --> 01:52:09,720
because it's consistent was all experiments that we've done

1730
01:52:09,720 --> 01:52:13,350
but the superposition principle which is very powerful

1731
01:52:13,350 --> 01:52:14,890
it's really not

1732
01:52:14,910 --> 01:52:17,070
and that of course

1733
01:52:17,160 --> 01:52:23,300
but it works we can always use it then we will

1734
01:52:23,350 --> 01:52:25,390
if you compare

1735
01:52:25,530 --> 01:52:27,850
o to one with a node two

1736
01:52:27,910 --> 01:52:30,370
by comparing electricity

1737
01:52:36,600 --> 01:52:39,300
you will see the electric forces

1738
01:52:39,350 --> 01:52:41,970
and we are powerful

1739
01:52:41,970 --> 01:52:44,390
then gravitational force

1740
01:52:44,430 --> 01:52:46,530
and the way i can best show you that

1741
01:52:46,570 --> 01:52:48,370
is by taking

1742
01:52:48,390 --> 01:52:50,390
two protons

1743
01:52:50,410 --> 01:52:52,030
which are distance

1744
01:52:52,070 --> 01:52:54,030
d apart

1745
01:52:54,120 --> 01:52:57,140
he was proton

1746
01:52:57,200 --> 01:52:59,100
he was about from song

1747
01:52:59,160 --> 01:53:06,320
and they are separated by a distance d

1748
01:53:06,350 --> 01:53:08,910
they repel each other

1749
01:53:08,930 --> 01:53:11,410
and the fourth by which they repel each other

1750
01:53:11,430 --> 01:53:14,200
is of course extremely easy to calculate

1751
01:53:14,220 --> 01:53:18,080
we know cools law that law is called afterglow

1752
01:53:18,180 --> 01:53:19,640
and so the force

1753
01:53:19,740 --> 01:53:23,200
electric force which which they repel each other

1754
01:53:23,200 --> 01:53:25,720
this is just the magnitude now of course

1755
01:53:25,800 --> 01:53:27,640
is the charge of the

1756
01:53:29,030 --> 01:53:32,120
one point six times ten to the minus nineteen that i have two

1757
01:53:32,140 --> 01:53:33,700
it's clear that

1758
01:53:33,720 --> 01:53:43,220
i have multiplied by cools constant which is nine times ten to nine

1759
01:53:43,280 --> 01:53:45,320
and i divided by the square

1760
01:53:45,370 --> 01:53:50,180
that's electric force

1761
01:53:50,240 --> 01:53:52,640
if i want to know the gravitational force

1762
01:53:52,700 --> 01:53:56,370
which is the force with which they attract each other

1763
01:53:56,410 --> 01:54:00,220
these are repelling forces but i just want magnitude here

1764
01:54:00,240 --> 01:54:03,470
then i have to take the mass of the proton

1765
01:54:03,470 --> 01:54:04,930
which is one point seven

1766
01:54:04,930 --> 01:54:06,970
times ten to the minus twenty seven

1767
01:54:06,990 --> 01:54:11,410
you have to square that

1768
01:54:11,510 --> 01:54:15,450
remember and one times and to kind of gravitational constant

1769
01:54:15,450 --> 01:54:18,180
the gravitational constant as i unit

1770
01:54:18,180 --> 01:54:21,300
six point seven times ten to the minus eleven

1771
01:54:21,320 --> 01:54:23,260
and i divide that

1772
01:54:23,280 --> 01:54:27,660
by the squid

1773
01:54:27,680 --> 01:54:31,600
if no i compare the electric force was the gravitational force

1774
01:54:31,600 --> 01:54:32,910
i divide one

1775
01:54:32,930 --> 01:54:35,410
by the other

1776
01:54:35,550 --> 01:54:37,660
i notice that the councils

1777
01:54:37,720 --> 01:54:40,680
they both have the square downstairs

1778
01:54:40,700 --> 01:54:42,490
and so you easy

1779
01:54:42,570 --> 01:54:44,450
to be able to show

1780
01:54:44,530 --> 01:54:46,030
this ratio

1781
01:54:46,070 --> 01:54:47,410
is roughly ten to

1782
01:54:47,930 --> 01:54:49,600
thirty six

1783
01:54:49,790 --> 01:54:56,850
so the electric forces thirty six orders of magnitude more potent

1784
01:54:56,870 --> 01:54:59,850
then the gravitational attraction

1785
01:54:59,910 --> 01:55:02,680
this teaches you some respect perhaps

1786
01:55:02,680 --> 01:55:07,870
four eight o two

1787
01:55:08,050 --> 01:55:12,390
these were the only forces that acted on the program

1788
01:55:12,530 --> 01:55:15,300
you bring them in the nucleus

1789
01:55:15,450 --> 01:55:18,530
which has the size of only ten to the minus twelve

1790
01:55:18,550 --> 01:55:21,550
suddenly those

1791
01:55:21,600 --> 01:55:23,850
the acceleration that the

1792
01:55:23,890 --> 01:55:26,260
proton will experience

1793
01:55:26,350 --> 01:55:27,350
is the

1794
01:55:27,450 --> 01:55:29,430
electric force

1795
01:55:29,490 --> 01:55:31,550
divided by the mass of the proton

1796
01:55:31,570 --> 01:55:33,160
because i a

1797
01:55:33,260 --> 01:55:34,570
the basis of a to one

1798
01:55:36,140 --> 01:55:38,240
and if you take electric forces

1799
01:55:38,320 --> 01:55:41,890
but you may the

1800
01:55:41,890 --> 01:55:46,490
ten to the minus twelve centimeters which is ten to the minus forty meters

1801
01:55:46,510 --> 01:55:51,990
you calculate this ratio you will find that this twenty six orders of magnitude higher

1802
01:55:52,030 --> 01:55:55,640
then the gravitational acceleration

1803
01:55:55,660 --> 01:56:00,550
twenty six orders of magnitude higher so you wonder what the hell hold the nucleus

1804
01:56:02,800 --> 01:56:06,410
if there is such a tremendous force on these programs well

1805
01:56:06,450 --> 01:56:08,430
so what is holding them together

1806
01:56:08,430 --> 01:56:11,760
and the nuclear forces which we do not fully understand

1807
01:56:11,850 --> 01:56:13,070
but thank goodness

1808
01:56:13,080 --> 01:56:14,350
the nuclear forces

1809
01:56:14,390 --> 01:56:17,870
not part of a two two so i'll leave it alone for now

1810
01:56:17,890 --> 01:56:20,740
so what holds them together

1811
01:56:20,740 --> 01:56:22,680
well the nuclear scale

1812
01:56:22,780 --> 01:56:25,350
ten to the minus twelve centimetres

1813
01:56:25,350 --> 01:56:28,760
very important that the nuclear forces

1814
01:56:28,760 --> 01:56:32,140
or atomic scale up to thousands of kilometres

1815
01:56:32,200 --> 01:56:34,050
it's really an electric forces

1816
01:56:34,050 --> 01:56:36,390
that hold our world together

1817
01:56:36,430 --> 01:56:39,300
but on a much larger scale

1818
01:56:39,370 --> 01:56:42,300
planets and stars in the galaxy

1819
01:56:42,350 --> 01:56:44,160
it is credited hold

1820
01:56:44,160 --> 01:56:46,450
world together

1821
01:56:46,510 --> 01:56:47,870
now you may say

1822
01:56:47,930 --> 01:56:51,280
that's very inconsistent with what you just told us

1823
01:56:51,340 --> 01:56:53,700
because it you tell us that the councils

1824
01:56:53,720 --> 01:56:55,180
if you compare gravity

1825
01:56:55,200 --> 01:56:57,550
which electricity

1826
01:57:00,140 --> 01:57:02,070
most objects

1827
01:57:02,120 --> 01:57:03,390
i'm neutral

1828
01:57:03,430 --> 01:57:05,800
or very close to neutral

1829
01:57:05,890 --> 01:57:08,010
and so if you take the earth

1830
01:57:08,050 --> 01:57:12,160
it is very unlikely even that the earth as a whole

1831
01:57:12,200 --> 01:57:13,780
whatever charge

1832
01:57:13,840 --> 01:57:17,970
more than ten cool the problem is already an exaggeration

1833
01:57:17,990 --> 01:57:21,220
so if i take the earth

1834
01:57:21,280 --> 01:57:24,320
and i take them all

1835
01:57:24,320 --> 01:57:25,910
and i put on both

1836
01:57:25,930 --> 01:57:30,010
the charge of ten cool

1837
01:57:30,010 --> 01:57:31,780
he is the earth

1838
01:57:32,260 --> 01:57:34,700
he is the moon

1839
01:57:34,760 --> 01:57:38,320
and i would say just arbitrarily ten cool year

1840
01:57:38,370 --> 01:57:40,100
and that put on here

1841
01:57:40,120 --> 01:57:41,510
you know minus

1842
01:57:41,510 --> 01:57:43,070
minus cool or

1843
01:57:43,110 --> 01:57:47,570
so they will attract each other but given that this is

1844
01:57:47,620 --> 01:57:50,600
it's almost nothing forces negligibly small

1845
01:57:50,600 --> 01:57:53,410
i think it is

1846
01:57:54,390 --> 01:57:56,790
which which is that

1847
01:57:56,790 --> 01:57:58,120
is the first time

1848
01:57:58,180 --> 01:58:04,390
it's like you

1849
01:58:05,620 --> 01:58:11,600
this the the when you because

1850
01:58:11,620 --> 01:58:13,250
and then

1851
01:58:18,040 --> 01:58:19,700
right next

1852
01:58:21,870 --> 01:58:24,910
they have been

1853
01:58:34,040 --> 01:58:36,770
grand prix fixe

1854
01:58:36,830 --> 01:58:44,830
so i made my presentation where is that

1855
01:58:44,850 --> 01:58:51,770
shares uses images but i think

1856
01:58:51,850 --> 01:58:55,270
actually because it is known to be

1857
01:58:55,290 --> 01:58:56,640
what is

1858
01:58:56,640 --> 01:58:58,980
the presentation

1859
01:58:59,000 --> 01:59:02,770
it was possible to search by

1860
01:59:02,790 --> 01:59:04,700
independently might

1861
01:59:07,250 --> 01:59:08,600
so like

1862
01:59:08,660 --> 01:59:16,080
electrons the color to some call it provides images where you have cited column

1863
01:59:17,830 --> 01:59:22,040
this system to the query was yet

1864
01:59:23,520 --> 01:59:28,410
i want to show that our

1865
01:59:28,430 --> 01:59:31,310
the way

1866
01:59:32,430 --> 01:59:37,850
it's not because easy

1867
01:59:42,720 --> 01:59:45,120
and remember

1868
01:59:49,430 --> 01:59:52,470
so i can come by

1869
01:59:53,390 --> 01:59:56,450
there was

1870
01:59:56,500 --> 02:00:01,720
just before independence the light calibration

1871
02:00:01,770 --> 02:00:04,450
i don't know

1872
02:00:09,930 --> 02:00:13,180
i was stimulated to

1873
02:00:13,220 --> 02:00:16,020
drop it was possible to

1874
02:00:16,740 --> 02:00:17,410
by the

1875
02:00:19,520 --> 02:00:21,160
so search by

1876
02:00:21,370 --> 02:00:24,770
and one

1877
02:00:24,790 --> 02:00:26,890
also we're all one

1878
02:00:26,930 --> 02:00:32,200
one of the possible

1879
02:00:32,250 --> 02:00:34,560
what we

1880
02:00:34,580 --> 02:00:39,580
they have to deal with these

1881
02:00:39,580 --> 02:00:41,140
the some

1882
02:00:41,180 --> 02:00:43,410
problem is possible

1883
02:00:43,430 --> 02:00:46,040
by the way to do

1884
02:00:52,000 --> 02:00:54,680
all the first

1885
02:00:54,700 --> 02:01:01,290
the the color texture color and texture like

1886
02:01:02,350 --> 02:01:05,910
among the positive could be coupled

1887
02:01:05,930 --> 02:01:08,060
some combination of features

1888
02:01:08,160 --> 02:01:14,120
they late so it's clear that they use linear combination combine

1889
02:01:21,020 --> 02:01:22,720
it was possible

1890
02:01:22,720 --> 02:01:24,520
it is located in italy

1891
02:01:24,520 --> 02:01:26,470
so i

1892
02:01:26,580 --> 02:01:27,750
and by the way

1893
02:01:27,770 --> 02:01:30,850
from the

1894
02:01:30,890 --> 02:01:33,060
and of course this case

1895
02:01:43,810 --> 02:01:46,080
deal with it

1896
02:01:46,140 --> 02:01:47,910
so there was

1897
02:01:47,930 --> 02:01:51,040
and that the combination of all

1898
02:01:51,740 --> 02:01:56,850
one more

1899
02:02:00,830 --> 02:02:02,470
which just mentioned

1900
02:02:02,500 --> 02:02:04,160
nearly all

1901
02:02:04,180 --> 02:02:05,680
and to

1902
02:02:08,870 --> 02:02:11,060
all the way anymore

1903
02:02:11,910 --> 02:02:14,200
but in this case

1904
02:02:14,250 --> 02:02:16,950
i met some people who tell them

1905
02:02:16,950 --> 02:02:25,790
and the idea is to have right to the

1906
02:02:25,790 --> 02:02:27,850
this is what it is

1907
02:02:27,850 --> 02:02:29,060
in end

1908
02:02:32,560 --> 02:02:40,100
because we can come out

1909
02:02:40,120 --> 02:02:42,500
so just about by

1910
02:02:47,580 --> 02:02:49,850
the main difference

1911
02:02:51,180 --> 02:02:57,580
comparing to the configuration is considered fixed onto so

1912
02:02:57,640 --> 02:02:59,290
last column

1913
02:02:59,310 --> 02:03:02,910
but some relations between different

1914
02:03:08,640 --> 02:03:11,720
this is the global picture

1915
02:03:11,770 --> 02:03:16,040
i can call you can do a lot

1916
02:03:16,060 --> 02:03:17,870
false positive

1917
02:03:21,120 --> 02:03:24,680
but when combined this global picture

1918
02:03:26,180 --> 02:03:29,870
some of the your

1919
02:03:31,390 --> 02:03:33,370
so here we

1920
02:03:35,720 --> 02:03:36,580
this debate

1921
02:03:39,000 --> 02:03:40,750
written by

1922
02:03:40,810 --> 02:03:41,700
the main

1923
02:03:41,890 --> 02:03:46,950
so you can see here because will the two other systems which are able to

1924
02:03:46,950 --> 02:03:49,850
write about the person

1925
02:03:51,270 --> 02:03:52,620
for the

1926
02:03:53,770 --> 02:04:00,950
which is is the real but all these systems are quite old

1927
02:04:01,000 --> 02:04:04,500
is that because eighties visualseek

1928
02:04:04,520 --> 02:04:11,160
i think it's also the least bit of i nineteen ninety seven nineteen ninety nine

1929
02:04:11,220 --> 02:04:13,470
like this but

1930
02:04:13,480 --> 02:04:14,750
all right

1931
02:04:16,580 --> 02:04:18,160
and they use

1932
02:04:18,160 --> 02:04:21,850
so we can finish university and it's OK so

1933
02:04:21,850 --> 02:04:25,870
you know that the face paper using sparsity now the reason i suspect that i'm

1934
02:04:25,870 --> 02:04:30,060
sure we can figure fingerprint paper things sparsity that we cannot go around

1935
02:04:30,160 --> 02:04:35,540
that road and we had a visitor from IBM his name is not known rather

1936
02:04:35,700 --> 02:04:38,410
than he gave a talk about cancelability

1937
02:04:38,430 --> 02:04:43,350
and biometrics what happens if somebody steals your face signatures and so on right so

1938
02:04:43,350 --> 02:04:47,740
they have been working on it for music it's not nearly as you can see

1939
02:04:47,740 --> 02:04:52,950
here in two thousand one he was looking at biometrics insecurity that basically cancel abilities

1940
02:04:52,950 --> 02:05:00,780
that help can you produce secure biometrics and then he showed this this method

1941
02:05:00,850 --> 02:05:04,160
OK i'll go back to this later again he said well this is how he

1942
02:05:04,160 --> 02:05:06,390
produces cancelability

1943
02:05:06,390 --> 02:05:13,540
where they have random projections nodes if the g is the give our features that

1944
02:05:13,560 --> 02:05:18,950
are used in iris recognition and they use a random projection

1945
02:05:19,010 --> 02:05:23,760
and then so they have no signature and why this is now is the one

1946
02:05:23,760 --> 02:05:26,950
that we used and in case it is stored on

1947
02:05:26,950 --> 02:05:30,390
you know you can again generate another and the production and so on and the

1948
02:05:30,390 --> 02:05:34,680
guy who steals your signature will not be able to recover your wife

1949
02:05:34,700 --> 02:05:38,990
because of this particular transformation random projection

1950
02:05:39,010 --> 02:05:42,010
then i told him you know what this is this is the kind of problem

1951
02:05:42,010 --> 02:05:44,240
that is in compressive sensing two

1952
02:05:44,280 --> 02:05:51,930
so what is the link between cancelability random projections OK well there is johnson

1953
02:05:51,950 --> 02:05:56,140
then tries to lemma that says when you do a random projection like that the

1954
02:05:56,140 --> 02:06:01,180
distance is almost research was you take the original image

1955
02:06:01,220 --> 02:06:04,870
OK you have a major a an image b let's say you calculate the distance

1956
02:06:04,870 --> 02:06:09,060
between these two images and then you do random projection on in under the command

1957
02:06:09,060 --> 02:06:13,510
we calculate the distance the distance would be very close so by doing this random

1958
02:06:13,510 --> 02:06:15,580
projection can kind of

1959
02:06:15,620 --> 02:06:17,870
change signal you're working with

1960
02:06:17,890 --> 02:06:23,060
all right but you will still be able to to recognise me because any method

1961
02:06:23,060 --> 02:06:25,870
that works on the original image

1962
02:06:25,890 --> 02:06:30,950
OK you can now brewed on the random projections so if originally made in your

1963
02:06:31,140 --> 02:06:35,220
feature extraction so that the transformation and then you can do that and the predictions

1964
02:06:35,220 --> 02:06:40,350
on the feature extraction right so that should be fine so this there is a

1965
02:06:40,350 --> 02:06:42,620
nice paper that kind of things the

1966
02:06:42,640 --> 02:06:47,030
i'd probably to jail in mumbai rich baraniuk and so on and so we were

1967
02:06:47,030 --> 02:06:52,530
kind of been surprised by this link but of course process online users so there's

1968
02:06:52,530 --> 02:06:54,280
nothing new under the sun

1969
02:06:54,300 --> 02:06:57,950
so i thought well we have found no link and then we go and look

1970
02:06:57,950 --> 02:07:03,560
into the golden couple of people have already figured this one out this paper and

1971
02:07:03,560 --> 02:07:06,760
family and i think this is a paper from

1972
02:07:06,810 --> 02:07:12,430
professor documents crawled because people have been working environment is along how also worried about

1973
02:07:12,430 --> 02:07:17,390
the security of the biometrics so here you have in for the what i'm discussing

1974
02:07:17,450 --> 02:07:22,310
application compressive sensing sorts of things come in many different ways first but i its

1975
02:07:22,310 --> 02:07:25,100
recognition sparsity based recognition

1976
02:07:25,220 --> 02:07:29,810
it's useful and then if you want to go cancelability you bring in random projections

1977
02:07:29,850 --> 02:07:34,720
and we talked about random projections the matrix p here again bernoulli goes in and

1978
02:07:34,720 --> 02:07:39,260
so on and that's how you also produces compressive measurements so that all kind of

1979
02:07:39,260 --> 02:07:42,280
sitting together so this is somewhat interesting

1980
02:07:42,300 --> 02:07:46,370
to me at least now i have one last one

1981
02:07:47,140 --> 02:07:50,640
and of course you can know show that the performance test and you know go

1982
02:07:50,640 --> 02:07:54,300
on and so forth again in the world down because you and production

1983
02:07:54,310 --> 02:08:00,380
well the graphics folks have been no worrying about getting reflectance functions because then they

1984
02:08:00,380 --> 02:08:06,700
can use them for relighting and so forth were making no cool magistrate so in

1985
02:08:06,700 --> 02:08:11,030
general it's an eighty problem for the first enough

1986
02:08:11,060 --> 02:08:17,850
for viewing and for the for the acquisition thing but if you make assumptions fixed

1987
02:08:17,850 --> 02:08:22,430
viewpoint and fix acquisition and things like that you can bring it down before

1988
02:08:22,450 --> 02:08:25,120
function OK now

1989
02:08:25,160 --> 02:08:31,620
right so the reflectance thing has all components to try haslam machine component shadows of

1990
02:08:31,620 --> 02:08:37,950
this peculiar in a given scene so called the sparsity come into play here i

1991
02:08:37,950 --> 02:08:41,370
think in the best example

1992
02:08:41,370 --> 02:08:42,660
of sparsity

1993
02:08:42,680 --> 02:08:47,530
compressive sensing and recovery is this paper so if you want to really get into

1994
02:08:47,530 --> 02:08:48,680
this field

1995
02:08:48,740 --> 02:08:51,890
before reading all the mathematics history this paper

1996
02:08:52,010 --> 02:08:55,720
you know i really like it it gives a nice overview

1997
02:08:55,760 --> 02:08:59,600
of reflectance function estimation problem why

1998
02:08:59,660 --> 02:09:03,080
it requires so much of the data to be collected

1999
02:09:03,100 --> 02:09:08,140
and then it says way compressive sensing may make sense here because britain reflectance functions

2000
02:09:08,140 --> 02:09:13,280
by themselves maybe part so so beautiful match on top of it

2001
02:09:13,300 --> 02:09:18,800
graphics works no-hoper set back you know are and experimental setup to collect actually these

2002
02:09:18,800 --> 02:09:23,560
kinds of compressive measurements so to me this is the other two examples i i


1
00:00:00,000 --> 00:00:02,120
play femal

2
00:00:02,130 --> 00:00:04,650
i think it was the piano doing

3
00:00:04,700 --> 00:00:06,730
it's the same courtyard

4
00:00:14,960 --> 00:00:30,250
actually i'm seeing the melody they're playing a chordal accompaniment against

5
00:00:30,350 --> 00:00:36,040
all right let's listen to the next iteration of this theme we've identified this is

6
00:00:36,040 --> 00:00:40,650
being who's got the females exactly the same and one of the strings up to

7
00:00:40,650 --> 00:00:45,510
in terms of string technique here

8
00:01:12,870 --> 00:01:16,080
so who had the theme

9
00:01:16,100 --> 00:01:19,660
can but was in exactly the same

10
00:01:19,670 --> 00:01:23,610
not really is kind of noodling around the varying a little bit when the strings

11
00:01:23,610 --> 00:01:28,410
doing they were playing the accompaniment and what string technique where they use it

12
00:01:28,460 --> 00:01:31,310
mentioned the first chapter of the book there

13
00:01:31,490 --> 00:01:33,430
you've got a nice laplace

14
00:01:33,440 --> 00:01:38,120
pizzicato good OK pizzicato we can write that we write the termites OK we've got

15
00:01:38,120 --> 00:01:40,050
it up pizzicato that's help

16
00:01:41,550 --> 00:01:45,750
with the in that particular case we switch the roles around

17
00:01:45,770 --> 00:01:51,490
let's let's go ahead two ten we can move this along just a little bit

18
00:01:51,490 --> 00:01:57,480
here as we come back into this i think we've got a situation where the

19
00:01:57,530 --> 00:02:00,130
the piano keep playing for

20
00:02:00,630 --> 00:02:05,260
key building enough attention and a cascade and the team comes back let's see what

21
00:02:08,510 --> 00:02:09,820
it's not

22
00:02:09,830 --> 00:02:14,690
one two three

23
00:02:14,800 --> 00:02:44,820
all right so that's an introduction to a three movement piano concerto happens to be

24
00:02:45,160 --> 00:02:50,330
the first of these three movements it's pretty spectacular music i hope you like music

25
00:02:50,330 --> 00:02:54,000
it's one of the one of the great melodies of all time it's bit of

26
00:02:54,110 --> 00:02:57,680
a wonderful example of a of a scene

27
00:02:57,780 --> 00:03:02,670
having talk just a little bit about genres we can conclude by saying there are

28
00:03:02,670 --> 00:03:07,870
other kinds of genres in music of course we're we've been introduced this idea of

29
00:03:08,090 --> 00:03:13,450
the tone poem the strauss zarathustra is a tone poem that's the kind of one

30
00:03:13,450 --> 00:03:19,870
movement work in which the composer tries to tell the story or play at historic

31
00:03:19,870 --> 00:03:24,170
events or in the case of the strauss i guess to give us the beginning

32
00:03:24,170 --> 00:03:28,800
of the contents of the philosophical novel through music so tom on a one room

33
00:03:29,010 --> 00:03:34,510
we've got other kinds of dramas music we've got opera we've got cantatas sonatas and

34
00:03:34,510 --> 00:03:38,910
ballets things such as this will get to each of those in turn

35
00:03:38,920 --> 00:03:42,160
so that's the end of the discussion of strong let's go going now to talk

36
00:03:42,160 --> 00:03:48,450
about instruments and how instruments produce sound a heater come on this is my friend

37
00:03:48,450 --> 00:03:55,440
longtime colleague music library an extraordinary and professional french horn player peter who will demonstrate

38
00:03:55,440 --> 00:03:59,200
here come on over here right in the centre gene campbell was in the basement

39
00:03:59,200 --> 00:04:01,610
somewhere recording all of the

40
00:04:01,660 --> 00:04:08,340
so it's very exciting time to be alive so he was going to just demonstrate

41
00:04:08,340 --> 00:04:09,690
the physical

42
00:04:09,700 --> 00:04:12,860
processor playing the french horn

43
00:04:14,520 --> 00:04:19,230
this is a very common

44
00:04:19,360 --> 00:04:23,880
in this case they come close

45
00:04:23,930 --> 00:04:26,110
there's a whole

46
00:04:33,090 --> 00:04:35,670
that what

47
00:04:39,730 --> 00:04:48,490
we go

48
00:04:50,680 --> 00:04:56,910
i have

49
00:04:58,970 --> 00:05:00,690
was just note

50
00:05:06,230 --> 00:05:08,310
that's hard

51
00:05:08,430 --> 00:05:11,540
what about

52
00:05:11,550 --> 00:05:14,230
is a short line

53
00:05:14,280 --> 00:05:15,620
like car

54
00:05:25,690 --> 00:05:27,680
so what

55
00:05:27,890 --> 00:05:31,280
i think which was

56
00:05:31,400 --> 00:05:37,280
OK that's fine that's great that's that's the principle which is actually overblown what that

57
00:05:37,280 --> 00:05:44,060
means is more keep emphasizing is pointed out that new partial that once sounds made

58
00:05:44,060 --> 00:05:47,910
you have not just one sound but that to tube is dividing it up into

59
00:05:47,910 --> 00:05:53,180
sections and all kinds of little sections of that one two are certainly not just

60
00:05:53,180 --> 00:05:59,530
the biggest sound but the partial of the overtone behind-the-scenes intervals in the harmonic series

61
00:05:59,540 --> 00:06:03,140
so it's a whole series when we listen to a single tone is a whole

62
00:06:03,140 --> 00:06:07,600
series of what he was doing there is playing out the nodes in that series

63
00:06:07,600 --> 00:06:12,820
successively will keep banging on that now if you would ever play just the beginning

64
00:06:13,080 --> 00:06:19,420
of the our through struggle with the trumpet part can you do that

65
00:06:21,820 --> 00:06:24,670
well whenever here in what do you

66
00:06:24,920 --> 00:06:28,980
what you would do do well to do what can we do see an

67
00:07:02,770 --> 00:07:14,880
that's not that that's another thank you very much thank you

68
00:07:14,890 --> 00:07:19,620
OK have another gig out in guildford to this morning so she's going to have

69
00:07:19,620 --> 00:07:23,390
to run off and i'm going to show you maybe if we get our slides

70
00:07:23,390 --> 00:07:28,170
up overtone series OK it's not

71
00:07:28,290 --> 00:07:32,880
i hope i got it on the slide gentlemen can you i'm going to hit

72
00:07:32,880 --> 00:07:34,110
but i was told to do

73
00:07:34,120 --> 00:07:35,280
the function

74
00:07:35,300 --> 00:07:39,120
f eight is that right

75
00:07:39,170 --> 00:07:42,530
alright something came up and then disappear

76
00:07:42,570 --> 00:07:46,400
right so can we have the technical person please bring

77
00:07:46,420 --> 00:07:48,670
press it one more time

78
00:07:52,900 --> 00:07:55,940
OK so we don't have read

79
00:07:55,950 --> 00:07:58,790
all right so let's i tell you what we're going to just leave this up

80
00:07:58,790 --> 00:08:03,140
and i will bag the other slot i have slides with all this information on

81
00:08:03,140 --> 00:08:05,340
it but we can't seem to bring these

82
00:08:05,340 --> 00:08:10,790
what we've got here is the following this idea of partials even was talking about

83
00:08:10,960 --> 00:08:12,680
with ratios

84
00:08:12,700 --> 00:08:17,640
two to one three two four forty three five four sixty five and so on

85
00:08:17,640 --> 00:08:20,530
you can prove to yourself or higher order

86
00:08:20,530 --> 00:08:24,180
how the half-life various concentration so i said we look at the other which is

87
00:08:24,220 --> 00:08:25,470
second order

88
00:08:25,510 --> 00:08:28,240
second order reactions and

89
00:08:28,280 --> 00:08:31,140
here's an example it's dimerisation of

90
00:08:31,160 --> 00:08:35,930
try chloride try chloride can form the dimer failed to

91
00:08:35,930 --> 00:08:42,070
cl six gas phase and right off the bat and let c be the concentration

92
00:08:42,360 --> 00:08:43,450
of illumina

93
00:08:43,470 --> 00:08:48,780
try chloride and its second order because the rate of disappearance of aluminum try chloride

94
00:08:48,820 --> 00:08:53,200
goes as the square now this is one of those instances where it's really tempting

95
00:08:54,050 --> 00:08:58,030
this reaction has the two in front of it and it turns out that the

96
00:08:58,030 --> 00:09:05,260
rate of disappearance of aluminum try chloride goes as casey square but do not do

97
00:09:05,260 --> 00:09:10,320
not want to say three times do not assume that this is the rule that

98
00:09:10,360 --> 00:09:15,570
because you sort once that this is always the case that the stoichiometry gives you

99
00:09:16,300 --> 00:09:20,260
the order of reaction this is not the general case it happens in this reaction

100
00:09:20,260 --> 00:09:25,470
for reasons that will go into later but generally you have to measure

101
00:09:25,510 --> 00:09:27,070
the order of reaction

102
00:09:27,090 --> 00:09:29,990
so if we go through the same analysis one minus

103
00:09:30,030 --> 00:09:33,470
the c overseas squared equals

104
00:09:33,510 --> 00:09:36,490
kt t will do the integration blah blah blah

105
00:09:36,510 --> 00:09:41,220
and eventually we end up with this relationship the reciprocal of concentration

106
00:09:41,240 --> 00:09:42,220
it is

107
00:09:42,220 --> 00:09:44,610
a linear function of

108
00:09:45,550 --> 00:09:50,970
so that means that the functional that we need is given here so the way

109
00:09:50,970 --> 00:09:52,720
to determine if something is

110
00:09:52,800 --> 00:09:55,720
this first order in the second order and

111
00:09:55,800 --> 00:09:57,910
is to take this

112
00:10:02,360 --> 00:10:04,910
concentration versus time

113
00:10:04,970 --> 00:10:08,550
which is always look like this to the naked eye because i don't know if

114
00:10:08,550 --> 00:10:13,260
that's first or second order but i can detect the straight lines of instead i

115
00:10:13,260 --> 00:10:16,530
map this into one over c

116
00:10:16,550 --> 00:10:21,030
first this time i should end up with a straight line starting at one overseen

117
00:10:21,860 --> 00:10:24,160
and the slope of that line should be

118
00:10:25,220 --> 00:10:27,550
so when i see that this is a straight line

119
00:10:27,550 --> 00:10:28,280
i go

120
00:10:28,300 --> 00:10:29,800
and equals two

121
00:10:29,800 --> 00:10:34,550
and the slope is the rate constant if this were not a second order i

122
00:10:34,550 --> 00:10:37,140
wouldn't get a straight line so

123
00:10:37,160 --> 00:10:39,300
this this allows me to

124
00:10:39,320 --> 00:10:43,700
to proceed and get the order of reaction in fact what i'm showing you is

125
00:10:43,700 --> 00:10:45,510
one of the ways people

126
00:10:45,530 --> 00:10:51,320
determine order of reaction they use the integrated form of the rate equation

127
00:10:51,380 --> 00:10:55,640
so this is called the integral method to determine order of reaction

128
00:10:58,760 --> 00:11:02,740
the order of reaction

129
00:11:02,800 --> 00:11:07,610
the order of reaction the first way is

130
00:11:07,630 --> 00:11:10,360
integral method

131
00:11:10,360 --> 00:11:12,400
integral method

132
00:11:12,450 --> 00:11:15,360
and it's essentially a comparison

133
00:11:15,400 --> 00:11:19,220
so comparison with the integrated form of the rate law

134
00:11:19,240 --> 00:11:21,410
comparison with

135
00:11:21,910 --> 00:11:24,510
integrated form of the rate law

136
00:11:24,530 --> 00:11:31,990
integrated rate law equation this really inspection this is trial and error

137
00:11:31,990 --> 00:11:34,240
we also try to america

138
00:11:34,380 --> 00:11:38,450
from MIT so we use faster reducing by inspection

139
00:11:38,510 --> 00:11:43,590
that's a televised what you're doing just really have to do this by inspection

140
00:11:45,110 --> 00:11:49,070
so what i do is i try and equals one if i get an arbitrary

141
00:11:49,070 --> 00:11:51,800
data set i try and equals one

142
00:11:51,840 --> 00:11:54,430
i try and equals two after that i said forget it i'm going go to

143
00:11:54,430 --> 00:11:56,470
the other methods so let me show you

144
00:11:56,490 --> 00:11:58,860
a couple of slides that indicate this

145
00:11:58,910 --> 00:12:02,550
so here's the data set up i pulled set some somewhat this is the reaction

146
00:12:02,550 --> 00:12:08,140
so this this time this is the concentration some species and don't worry about that

147
00:12:08,140 --> 00:12:10,990
will get to that in second so here's your data set designer you have if

148
00:12:10,990 --> 00:12:14,760
you plot these here's what they look like this is concentration

149
00:12:14,820 --> 00:12:17,220
in animals per

150
00:12:17,240 --> 00:12:21,240
unit volume as a function of time and there is a c

151
00:12:22,430 --> 00:12:27,220
normalized to one unit and its attenuates over five hundred seconds were down to about

152
00:12:27,220 --> 00:12:32,050
twenty percent of the initial value so i say what's the order of reaction i

153
00:12:32,050 --> 00:12:33,030
can't tell

154
00:12:33,070 --> 00:12:34,110
so i want to do

155
00:12:34,130 --> 00:12:38,090
yes i'm going to say OK now let's take the natural log of c

156
00:12:38,110 --> 00:12:41,590
versus time then go straight line

157
00:12:41,640 --> 00:12:45,590
so that for on this basis i conclude that it's a straight line and the

158
00:12:45,590 --> 00:12:47,530
slope of this line is the

159
00:12:47,550 --> 00:12:49,840
rate constants

160
00:12:49,880 --> 00:12:52,630
but just to show you that doesn't always work i said just for grins and

161
00:12:52,630 --> 00:12:57,510
chuckles plot that same data set as one overseas and look what happens when i

162
00:12:57,510 --> 00:13:00,820
plotted as one over c i don't get a straight line

163
00:13:00,840 --> 00:13:04,050
so it really does discriminate doesn't give me

164
00:13:04,110 --> 00:13:09,550
what i was going to expect in terms of the straight line except when i

165
00:13:09,550 --> 00:13:11,760
have the proper order of reaction

166
00:13:11,760 --> 00:13:14,880
so now let's see another way that we can get at this and this is

167
00:13:14,880 --> 00:13:16,880
called the differential method

168
00:13:16,930 --> 00:13:20,970
and i'm going to use the integrated form of the rate equation

169
00:13:21,050 --> 00:13:22,550
will use the

170
00:13:22,610 --> 00:13:24,570
the differential form

171
00:13:24,630 --> 00:13:29,930
and i'm going to to compress the notation on the left lower case are

172
00:13:29,930 --> 00:13:34,240
the the rate the rate is lower case are which i'm going to

173
00:13:34,630 --> 00:13:38,930
let stand for miners d by DTC how i give my thoughts more and more

174
00:13:38,930 --> 00:13:42,590
compressed i start with the big with the square brackets and i get to this

175
00:13:42,590 --> 00:13:44,360
and i get to this is getting

176
00:13:44,410 --> 00:13:46,280
tighter and tighter

177
00:13:46,340 --> 00:13:50,260
OK so now i can write the rate equation as the re

178
00:13:50,260 --> 00:13:51,490
goes as

179
00:13:52,340 --> 00:13:55,630
c to the and so there's the arbitrary radius equation

180
00:13:55,640 --> 00:13:59,130
and i want do something to take the logarithm of the equation

181
00:13:59,180 --> 00:14:03,880
so i i can map that into the logarithm of the rate

182
00:14:05,030 --> 00:14:08,090
the log of the product is the sum of the log so that'll be the

183
00:14:09,260 --> 00:14:17,280
of the rate constant plus and times the logarithm of concentration

184
00:14:17,300 --> 00:14:18,740
now i can do

185
00:14:18,740 --> 00:14:21,640
that does exactly

186
00:14:21,700 --> 00:14:25,640
what generates black

187
00:14:25,640 --> 00:14:27,200
so if

188
00:14:27,220 --> 00:14:30,850
anybody ever tells you to the density estimation

189
00:14:30,870 --> 00:14:38,220
this is really the first thing you want to do

190
00:14:38,240 --> 00:14:52,620
it's called parzen windows

191
00:14:52,640 --> 00:14:53,970
and obviously

192
00:14:54,010 --> 00:14:57,200
you can also use that to build the classifier

193
00:14:57,240 --> 00:14:59,240
princess binary classification

194
00:14:59,260 --> 00:15:01,240
two this statement one class

195
00:15:01,240 --> 00:15:03,290
the density estimate for the class

196
00:15:03,350 --> 00:15:05,080
computer asia

197
00:15:05,260 --> 00:15:07,740
if the ratio is larger than one

198
00:15:07,790 --> 00:15:09,470
class one

199
00:15:09,470 --> 00:15:11,040
iteration less than one

200
00:15:11,060 --> 00:15:12,910
plus minus one

201
00:15:12,930 --> 00:15:17,140
this is exactly

202
00:15:17,160 --> 00:15:19,220
that equation here

203
00:15:23,640 --> 00:15:25,720
and then we can just go

204
00:15:25,760 --> 00:15:28,180
several let's compute the squared distance

205
00:15:28,200 --> 00:15:30,180
between p hard

206
00:15:30,180 --> 00:15:33,640
into that

207
00:15:36,220 --> 00:15:37,470
if i do that

208
00:15:37,540 --> 00:15:43,830
to a little bit of algebra that's what i'm getting

209
00:15:43,850 --> 00:15:47,790
now those functions k

210
00:15:47,930 --> 00:15:49,970
i just the integral

211
00:15:49,990 --> 00:15:52,160
of k f x minus t

212
00:15:52,200 --> 00:16:00,700
and kale ex-prime honesty dt

213
00:16:00,720 --> 00:16:03,890
these actually happened to be proper kernels

214
00:16:03,910 --> 00:16:05,430
this function k

215
00:16:05,470 --> 00:16:08,200
not the campus

216
00:16:08,810 --> 00:16:10,430
and i obtain those

217
00:16:10,450 --> 00:16:11,810
by just doing

218
00:16:11,990 --> 00:16:18,240
the past windows density estimate and then computing the squared distance

219
00:16:18,290 --> 00:16:22,540
the questions at this point

220
00:16:22,580 --> 00:16:28,390
so obviously if i have this i could say well if this quantity is small

221
00:16:28,390 --> 00:16:30,260
then i can

222
00:16:30,260 --> 00:16:33,160
argue that people's q

223
00:16:33,180 --> 00:16:35,030
and if this distance is large

224
00:16:35,040 --> 00:16:36,640
and i would say p is not you

225
00:16:36,680 --> 00:16:40,640
would have probabilities

226
00:16:40,700 --> 00:16:42,830
the catch to it

227
00:16:42,990 --> 00:16:45,140
so let's assume p is really q

228
00:16:47,310 --> 00:16:50,260
and i said why

229
00:16:50,290 --> 00:16:52,600
so who thinks

230
00:16:52,740 --> 00:16:54,810
this quantity you will be zero

231
00:16:54,870 --> 00:16:59,430
if i use the same distribution to generate x and y

232
00:16:59,450 --> 00:17:01,160
he thinks it's going to be here

233
00:17:04,790 --> 00:17:06,060
who thinks

234
00:17:06,100 --> 00:17:10,330
it's going to be large

235
00:17:11,640 --> 00:17:15,330
who thinks it's going to be small

236
00:17:15,390 --> 00:17:17,240
OK quite a few people

237
00:17:18,970 --> 00:17:20,600
that's exactly what's going to happen

238
00:17:20,640 --> 00:17:23,850
this term is not going to vanish

239
00:17:23,890 --> 00:17:26,010
even if people q

240
00:17:26,030 --> 00:17:29,720
it's going to get smaller and smaller as we get more data sure

241
00:17:29,760 --> 00:17:34,260
but this term has the bias

242
00:17:34,270 --> 00:17:37,810
and this applies mainly comes from one thing

243
00:17:37,810 --> 00:17:41,180
if you look at these expressions here

244
00:17:41,180 --> 00:17:43,890
they well they're all those terms here

245
00:17:44,620 --> 00:17:46,950
i was j

246
00:17:46,970 --> 00:17:50,660
now how likely is it that the name drawing from a distribution that i'm seeing

247
00:17:50,660 --> 00:17:52,680
the same data twice

248
00:17:52,760 --> 00:17:54,080
extremely unlikely

249
00:17:54,100 --> 00:17:56,080
and if ever discrete distribution

250
00:17:56,140 --> 00:18:01,350
so the self-interest in trends describe everything

251
00:18:01,430 --> 00:18:06,350
and later on we'll see very similar quantity to this red line

252
00:18:06,350 --> 00:18:08,390
which is an unbiased estimator

253
00:18:08,450 --> 00:18:11,100
that is exactly the same policies

254
00:18:11,100 --> 00:18:14,370
it will be deriving it in a very different way

255
00:18:14,390 --> 00:18:20,260
slightly will be slightly different normalizations up here but that's really just in the details

256
00:18:20,290 --> 00:18:21,680
and that time then

257
00:18:21,700 --> 00:18:26,140
will take care of all the self interactions

258
00:18:26,700 --> 00:18:33,540
so this is the really simple way it actually works reasonably well

259
00:18:33,560 --> 00:18:35,490
well there are a couple of for

260
00:18:42,040 --> 00:18:44,850
that's true that's hard

261
00:18:44,910 --> 00:18:47,040
and i didn't bother doing it

262
00:18:48,160 --> 00:18:50,430
will see a much simpler way of

263
00:18:50,430 --> 00:18:53,220
getting this to get things similar case

264
00:18:53,220 --> 00:18:56,240
but the very accurate confidence level

265
00:18:56,850 --> 00:18:58,470
based on the results

266
00:18:58,470 --> 00:19:02,390
it should they not be too difficult to get the confidence level

267
00:19:02,470 --> 00:19:06,060
on this text

268
00:19:06,080 --> 00:19:07,560
OK but

269
00:19:07,600 --> 00:19:11,080
think that the question that the fast so much harder than the problem i'm going

270
00:19:11,080 --> 00:19:13,060
to show you how to sort

271
00:19:13,080 --> 00:19:17,290
OK so we're going to be lazy to solve simple problems

272
00:19:21,220 --> 00:19:27,410
the problem here is what we're accustomed dimensionality when we estimate those things it is

273
00:19:27,430 --> 00:19:31,450
well we have problem with the statistical analysis because well you know

274
00:19:31,560 --> 00:19:32,870
we need to

275
00:19:32,910 --> 00:19:37,850
basic is a multi-stage procedure first we need to estimate the density and then we

276
00:19:37,850 --> 00:19:40,540
compute the distance and then we want to get the confidence

277
00:19:40,560 --> 00:19:42,560
that's really hard

278
00:19:42,580 --> 00:19:46,660
and besides said what do we do on strings images and structured data

279
00:19:46,720 --> 00:19:49,310
all graphs

280
00:19:49,370 --> 00:19:53,390
so i mean how did the parzen window density estimate on graphs

281
00:19:53,410 --> 00:19:56,040
i don't know

282
00:19:56,060 --> 00:19:59,700
and obviously this quantity is biased

283
00:19:59,760 --> 00:20:00,990
OK so

284
00:20:01,040 --> 00:20:02,760
but the problems

285
00:20:02,850 --> 00:20:04,910
this is the thing that we're not going to do

286
00:20:04,910 --> 00:20:05,990
now let's

287
00:20:06,010 --> 00:20:08,030
look at the simplicity

288
00:20:08,040 --> 00:20:10,970
so the key ideas

289
00:20:10,990 --> 00:20:15,100
to avoid the thing that there was a lot of problems namely the density estimate

290
00:20:15,120 --> 00:20:18,950
use the means directly

291
00:20:18,970 --> 00:20:21,660
and now he is the key criterion and world

292
00:20:21,680 --> 00:20:26,140
we reinvented the wheel and then realise that people in nineteen fifty three already had

293
00:20:26,140 --> 00:20:27,890
done something like that

294
00:20:28,040 --> 00:20:30,410
his friends also the profit of metric

295
00:20:30,410 --> 00:20:35,930
on distributions which uses something similar in someone's kontorovich problem and all that which are

296
00:20:35,970 --> 00:20:37,600
very close related to

297
00:20:37,620 --> 00:20:38,760
the setting

298
00:20:41,970 --> 00:20:44,240
what they usually do when i have the density

299
00:20:44,310 --> 00:20:45,850
estimation well

300
00:20:45,970 --> 00:20:51,160
i will use it at some stage eventually to compute expectations

301
00:20:51,160 --> 00:20:53,490
of some sort

302
00:20:53,530 --> 00:20:56,600
for instance i would compute the expectation of

303
00:20:58,080 --> 00:21:02,240
say the loss being larger than hundred

304
00:21:03,670 --> 00:21:06,760
i want to compute

305
00:21:06,810 --> 00:21:11,640
so the average amateur compute the average gain that i'm making audience but at the

306
00:21:11,640 --> 00:21:13,770
end of the day quite often will

307
00:21:13,810 --> 00:21:16,620
compute expectations

308
00:21:16,640 --> 00:21:17,990
and in fact

309
00:21:20,620 --> 00:21:26,530
in some way uniquely defined distributions they they define uniquely in the weak sense

310
00:21:26,540 --> 00:21:32,760
basically except for some pathological cases that i'm not going to get into

311
00:21:33,640 --> 00:21:36,060
this is why fourteen said well

312
00:21:36,680 --> 00:21:39,040
if i have to distributions p and q

313
00:21:39,060 --> 00:21:42,290
for the moment i'm going to assume that we know them and will get into

314
00:21:42,290 --> 00:21:44,580
how to get those estimators afterwards

315
00:21:44,620 --> 00:21:47,600
i can define the distance between p and q

316
00:21:47,600 --> 00:21:50,680
with respect to some function classes

317
00:21:50,770 --> 00:21:51,950
to be

318
00:21:51,990 --> 00:21:57,010
the so so basically the search of the worst possible function from the function class

319
00:21:57,040 --> 00:21:59,660
over the expectation of f of x

320
00:21:59,660 --> 00:22:04,230
sp three hybridized carbon along this axis here

321
00:22:04,250 --> 00:22:07,370
that's why i turned around here comes the other

322
00:22:07,370 --> 00:22:11,620
sp three hybridized carbon and i'm going to let these two

323
00:22:11,630 --> 00:22:15,570
sp three hybrid wave functions overlap

324
00:22:15,590 --> 00:22:20,250
so that now one of my ISP three states two electrons in it

325
00:22:20,280 --> 00:22:21,540
so here

326
00:22:21,560 --> 00:22:27,660
one of my doing right here i'm letting those two sp three wave functions overlap

327
00:22:27,660 --> 00:22:30,790
constructive interference hey i'm going to make

328
00:22:32,500 --> 00:22:34,710
a sigma bond because

329
00:22:34,720 --> 00:22:40,240
this weight function is cylindrically symmetric around that axis sigma bond

330
00:22:40,260 --> 00:22:44,100
it is a sigma bond composed of the carbon

331
00:22:44,100 --> 00:22:47,220
two sp three hybrid wave functions

332
00:22:47,240 --> 00:22:51,840
and another carbon two sp three hybrid function

333
00:22:53,780 --> 00:22:58,270
i just for carbon carbon bonds

334
00:22:58,320 --> 00:23:01,050
OK i just brought in some hydrogens

335
00:23:02,390 --> 00:23:03,910
in each one

336
00:23:03,920 --> 00:23:05,800
in each case

337
00:23:05,820 --> 00:23:08,040
i now have overlapping

338
00:23:08,050 --> 00:23:10,620
between the line as weight function

339
00:23:10,620 --> 00:23:15,360
and the sp three wave function of the carbon in the molecule that here is

340
00:23:17,160 --> 00:23:23,020
let's look at and this angle here is one hundred ninety degrees right

341
00:23:23,180 --> 00:23:25,630
one hundred nine degrees

342
00:23:25,630 --> 00:23:28,630
because you had the hat-trick

343
00:23:28,640 --> 00:23:31,840
tetrahedral configuration around the carbon

344
00:23:31,860 --> 00:23:33,480
because that's how

345
00:23:34,500 --> 00:23:39,920
as the two as wave functions and the three two p wave functions around the

346
00:23:41,770 --> 00:23:45,120
constructively and destructively interfere

347
00:23:45,130 --> 00:23:46,650
to give you

348
00:23:47,380 --> 00:23:49,220
he drove for a

349
00:23:49,240 --> 00:23:52,660
for the SP three wave functions

350
00:23:52,660 --> 00:23:55,200
let's take a look like at but we can do this

351
00:23:55,450 --> 00:24:03,930
let's start right so we may be VCH bond here they're all sigma bonds also

352
00:24:03,950 --> 00:24:05,950
OK so that carbon

353
00:24:05,990 --> 00:24:10,010
this sp three hybridization for carbon

354
00:24:10,030 --> 00:24:11,940
but other atoms

355
00:24:11,950 --> 00:24:13,520
and also wonder

356
00:24:13,570 --> 00:24:16,810
this sp three hybridization

357
00:24:16,820 --> 00:24:21,090
and one of those atoms here is nitrogen

358
00:24:21,100 --> 00:24:24,340
here's the electron configuration for

359
00:24:26,780 --> 00:24:29,980
in this case we got

360
00:24:31,660 --> 00:24:38,000
two electrons and two st then one in each one of the two p states

361
00:24:38,020 --> 00:24:40,520
what we're going to do here

362
00:24:40,540 --> 00:24:43,710
is going to allow now

363
00:24:43,710 --> 00:24:50,620
these three function for which functions to constructively and destructively interfere what we call

364
00:24:52,820 --> 00:24:57,500
and the result will be

365
00:24:58,450 --> 00:25:01,380
four sp three weight function

366
00:25:01,610 --> 00:25:07,940
except the difference is that because we have one more electron nitrogen

367
00:25:07,980 --> 00:25:12,950
one of these sp three state is already got two electrons in it

368
00:25:12,950 --> 00:25:16,800
right so it's not going to be available for bonding

369
00:25:21,350 --> 00:25:23,270
in nitrogen

370
00:25:23,300 --> 00:25:24,740
the electron

371
00:25:24,750 --> 00:25:29,450
arrangement of the function arrangement is also tetrahedral right

372
00:25:29,450 --> 00:25:32,490
st three to the score sp three

373
00:25:32,550 --> 00:25:35,890
sp three sp three

374
00:25:35,900 --> 00:25:41,460
except that one of these wavefunctions is this three functions

375
00:25:41,500 --> 00:25:43,280
really is kind of two

376
00:25:43,290 --> 00:25:48,000
st three wavefunctions are so electrons here in this

377
00:25:48,020 --> 00:25:50,920
this is the lone pair

378
00:25:50,920 --> 00:25:56,150
on the nitrogen and sp three hybridized nitrogen atom

379
00:25:56,160 --> 00:26:00,920
this is the long pair pointed at one of these vertices

380
00:26:01,120 --> 00:26:03,930
then each one of these loans has just

381
00:26:03,930 --> 00:26:07,660
the following content is provided under creative commons license

382
00:26:07,700 --> 00:26:14,440
your support will help MIT opencourseware continue to offer high quality educational resources for free

383
00:26:14,450 --> 00:26:19,250
to make a donation or view additional materials from hundreds of MIT courses

384
00:26:19,280 --> 00:26:21,090
this MIT opencourseware

385
00:26:21,090 --> 00:26:24,910
at OCW MIT that EDU

386
00:26:24,970 --> 00:26:27,310
good morning

387
00:26:27,360 --> 00:26:29,730
try tried again good morning

388
00:26:29,750 --> 00:26:31,410
thank you

389
00:26:31,410 --> 00:26:34,110
this is six hundred also known as

390
00:26:34,160 --> 00:26:36,770
introduction to computer science and programming

391
00:26:36,810 --> 00:26:40,460
my name is eric grimson together professor john good tag over here

392
00:26:40,480 --> 00:26:42,580
we're going to be lecturing the course this term

393
00:26:42,590 --> 00:26:47,380
i want to give you a heads up getting some serious firepower this term

394
00:26:47,440 --> 00:26:50,240
john was department head for

395
00:26:50,280 --> 00:26:54,240
ten years felt like a century in a course six on the current department head

396
00:26:54,240 --> 00:26:56,810
in caustics john's been lecturing for

397
00:26:56,830 --> 00:26:57,940
thirty years

398
00:26:59,490 --> 00:27:03,550
all right i'm the young guy only been lecturing for twenty five years

399
00:27:03,740 --> 00:27:06,440
you can tell i have less gray hair than he does

400
00:27:06,510 --> 00:27:10,910
what i'm trying to say to you is we take this course really seriously

401
00:27:10,960 --> 00:27:12,370
we hope you do as well

402
00:27:12,430 --> 00:27:15,540
but we think it's really important for the department to help

403
00:27:16,510 --> 00:27:19,900
learn about computation and that's what this course is about

404
00:27:19,930 --> 00:27:21,410
what i want to do today

405
00:27:21,430 --> 00:27:23,490
these three things

406
00:27:23,510 --> 00:27:24,740
i'm going to start

407
00:27:24,760 --> 00:27:28,340
should starting in a little bit of administrative you the kinds of things you need

408
00:27:28,340 --> 00:27:30,600
to know about how we're going to run the course

409
00:27:30,620 --> 00:27:33,430
i want to talk about the goals of the course

410
00:27:33,520 --> 00:27:35,380
what it is you will be able to do

411
00:27:35,400 --> 00:27:37,960
at the end of this course when you get through it

412
00:27:38,010 --> 00:27:41,930
and then i want to begin talking about the concepts and tools

413
00:27:41,930 --> 00:27:43,540
of computational thinking

414
00:27:43,540 --> 00:27:46,210
which is what we're primarily going to focus on here we're going to try and

415
00:27:46,210 --> 00:27:48,960
help you learn how to think like a computer scientist and we're going to begin

416
00:27:48,960 --> 00:27:52,150
talking about that towards the end of this lecture on the course throughout the rest

417
00:27:52,150 --> 00:27:54,650
of the lectures to carry on

418
00:27:54,660 --> 00:27:56,680
by the start with the goals

419
00:27:56,730 --> 00:27:59,180
to give it goes into levels

420
00:27:59,240 --> 00:28:01,910
the strategic goals of the following

421
00:28:01,960 --> 00:28:04,180
we want to help prepare

422
00:28:04,180 --> 00:28:07,650
freshmen and sophomores who are interested in majoring in caustics

423
00:28:07,700 --> 00:28:11,160
to get an easy entry into the department especially for those students who don't have

424
00:28:11,160 --> 00:28:13,520
a lot of prior programming experience

425
00:28:13,590 --> 00:28:16,620
if you're in that category don't panic run get

426
00:28:16,640 --> 00:28:19,440
we're going to help you ramp in and you'll certainly be able to start the

427
00:28:19,440 --> 00:28:20,890
course six curriculum

428
00:28:20,900 --> 00:28:24,050
and do just fine and still finish on target

429
00:28:24,110 --> 00:28:26,520
we don't expect everybody to be a course six major

430
00:28:26,580 --> 00:28:28,580
contrary to popular opinion

431
00:28:28,590 --> 00:28:31,310
so for those who you not in that category the second thing we want to

432
00:28:31,310 --> 00:28:35,240
do is one help students who don't plan to major in caustics to feel

433
00:28:35,280 --> 00:28:39,180
justifiably confident in their ability to write and read

434
00:28:39,210 --> 00:28:41,740
small pieces of code

435
00:28:41,740 --> 00:28:44,810
for all students we want to do is you want to give you an understanding

436
00:28:44,810 --> 00:28:48,400
of the role computation can and can not play

437
00:28:48,460 --> 00:28:49,930
in tackling

438
00:28:49,940 --> 00:28:51,280
technical problems

439
00:28:51,300 --> 00:28:53,710
so if you will come away with the sense of what you can do what

440
00:28:53,710 --> 00:28:56,780
you can do and what kinds of things you should use to tackle

441
00:28:56,840 --> 00:28:58,490
complex problems

442
00:28:58,550 --> 00:29:02,580
and finally we want to position all students so that you can easily if you

443
00:29:03,400 --> 00:29:06,300
compete for things like europe in summer jobs

444
00:29:06,340 --> 00:29:10,340
because you have an appropriate level of confidence and confidence in your ability to do

445
00:29:10,340 --> 00:29:12,460
computational problems

446
00:29:12,520 --> 00:29:14,560
so the strategic goals

447
00:29:15,680 --> 00:29:20,520
this course is primarily aimed at students who have little or no

448
00:29:20,530 --> 00:29:22,870
prior programming experience

449
00:29:22,890 --> 00:29:27,120
as a consequence we believe that no student here is underqualified

450
00:29:27,140 --> 00:29:30,640
for this course you're all MIT students are all qualified to be here

451
00:29:30,770 --> 00:29:34,460
but we also hope that there aren't any students here who are overqualified

452
00:29:34,470 --> 00:29:35,780
for this course

453
00:29:35,900 --> 00:29:40,180
what i mean by that if you've done a lot of prior program

454
00:29:40,250 --> 00:29:43,710
this is probably not the best course for you and if you are in that

455
00:29:43,710 --> 00:29:47,830
category i would you please encourage you to talk to john right after class about

456
00:29:47,830 --> 00:29:51,500
what your goals are what kind of experience you have and how we might find

457
00:29:51,500 --> 00:29:53,330
you of course that better meets

458
00:29:53,340 --> 00:29:55,140
your goals

459
00:29:55,150 --> 00:29:59,220
a second reason we don't want overqualified students in the class sounds a little nasty

460
00:29:59,220 --> 00:30:01,180
but the second reason is

461
00:30:01,240 --> 00:30:05,310
and overqualified students somebody who's i don't know program for google for the last five

462
00:30:06,360 --> 00:30:09,460
is going to have an easy time in this course but we don't want such

463
00:30:09,460 --> 00:30:12,580
as student accidentally intimidating the rest of

464
00:30:12,670 --> 00:30:15,220
we don't want you to feel inadequate

465
00:30:15,240 --> 00:30:17,370
when you're simply inexperienced

466
00:30:17,490 --> 00:30:21,000
so it really is a course aimed at students with little or no

467
00:30:21,080 --> 00:30:24,690
prior programming experience and again if you're not in that category talk to john after

468
00:30:25,430 --> 00:30:28,500
and we'll help you figure out where you might want to go

469
00:30:28,510 --> 00:30:31,760
OK those are the top level goals of the course let's talk

470
00:30:31,850 --> 00:30:35,010
sort of other more tactical level of what do we want you to know this

471
00:30:35,180 --> 00:30:37,810
is what we want you to be able to do by the time you leave

472
00:30:37,810 --> 00:30:40,320
this course so here are the skills

473
00:30:40,380 --> 00:30:41,810
we would like you

474
00:30:41,820 --> 00:30:43,330
to acquire

475
00:30:45,350 --> 00:30:47,670
the first scale we want you to acquire

476
00:30:47,670 --> 00:30:51,320
the of the in his name down

477
00:30:52,780 --> 00:30:53,780
they do

478
00:30:53,780 --> 00:31:01,130
he got to mixtures of spherical clusters spread equally in the space of higher dimension

479
00:31:01,150 --> 00:31:05,090
and a very large number of points the number of clusters the number of dimensions

480
00:31:05,090 --> 00:31:06,900
and how far the clusters

481
00:31:06,920 --> 00:31:09,050
this should be over sigma here so

482
00:31:09,110 --> 00:31:11,670
so the difference between the news defined

483
00:31:11,690 --> 00:31:13,840
the separation

484
00:31:13,980 --> 00:31:18,610
so there's a specific term

485
00:31:20,630 --> 00:31:26,170
they use the best c and one of the problem which was the

486
00:31:26,170 --> 00:31:29,510
with a projection of the visible

487
00:31:29,950 --> 00:31:34,070
remember this is not the in general this is best for or what they found

488
00:31:34,070 --> 00:31:40,050
to be that was for clustering or cluster were sort of semantically space

489
00:31:40,090 --> 00:31:41,900
so there are some similar to the

490
00:31:41,920 --> 00:31:45,760
two things that the

491
00:31:45,780 --> 00:31:48,590
and with the initialisation something like

492
00:31:48,610 --> 00:31:49,670
and they want

493
00:31:49,800 --> 00:31:52,070
the cheetah which is

494
00:31:52,090 --> 00:31:53,800
yeah mean

495
00:31:53,820 --> 00:31:54,820
seven years

496
00:31:54,840 --> 00:31:56,920
so you know where to start

497
00:31:56,920 --> 00:32:02,780
and smart enough to sustain their return to send something very close and give the

498
00:32:02,780 --> 00:32:06,230
correct clustering so we get a lot of help

499
00:32:06,460 --> 00:32:08,940
and then they looked to see

500
00:32:10,260 --> 00:32:16,340
you find clustering anybody could maximize like

501
00:32:16,400 --> 00:32:19,320
now we can never know what the likelihood is maximum

502
00:32:19,550 --> 00:32:22,050
you can only say

503
00:32:22,070 --> 00:32:23,510
things like

504
00:32:24,360 --> 00:32:26,010
she'd followed

505
00:32:26,030 --> 00:32:28,440
you the solutions for the

506
00:32:28,480 --> 00:32:32,710
what assumptions are different from us close what hired like

507
00:32:35,710 --> 00:32:37,400
things like

508
00:32:37,420 --> 00:32:38,630
of the rest

509
00:32:40,090 --> 00:32:43,840
we never could increase the likelihood of of what the simple you

510
00:32:43,920 --> 00:32:47,550
you can see the default

511
00:32:47,610 --> 00:32:51,170
and what they found is that

512
00:32:51,710 --> 00:32:54,030
an interesting fact

513
00:32:54,070 --> 00:32:58,590
to some it is not surprising but it's not i see mentioned is basically that

514
00:32:58,590 --> 00:33:00,900
if you have enough data points

515
00:33:00,920 --> 00:33:03,900
and two years in the house

516
00:33:03,920 --> 00:33:05,690
what depends on the degree

517
00:33:05,690 --> 00:33:07,860
the number of dimensions and so on

518
00:33:08,030 --> 00:33:10,750
but if you if the number of points

519
00:33:12,420 --> 00:33:13,460
the regime

520
00:33:13,510 --> 00:33:17,010
he also always the solution

521
00:33:18,960 --> 00:33:21,110
and you should also

522
00:33:21,130 --> 00:33:22,800
so having lots of data

523
00:33:22,820 --> 00:33:25,920
order parameter problem that

524
00:33:26,690 --> 00:33:31,610
there is no to understand the initial find

525
00:33:33,650 --> 00:33:34,280
there is you

526
00:33:34,690 --> 00:33:37,820
so solution to is the global optimum

527
00:33:37,840 --> 00:33:46,670
the true parameters are like so here you can almost guarantee that you have maximize

528
00:33:46,690 --> 00:33:49,880
this is an important result

529
00:33:49,900 --> 00:33:53,760
and maybe not surprising but it's good for

530
00:33:53,800 --> 00:33:54,980
and then

531
00:33:54,980 --> 00:33:58,030
the regime of poor to little

532
00:33:58,050 --> 00:34:01,840
when they want to know how

533
00:34:01,840 --> 00:34:06,190
that's too bad you don't even though they don't have to know anything with with

534
00:34:06,190 --> 00:34:08,280
the original

535
00:34:08,300 --> 00:34:11,840
because just two days

536
00:34:11,900 --> 00:34:15,030
or at least you have enough to be discovered by the model

537
00:34:15,190 --> 00:34:17,440
thirty years

538
00:34:18,360 --> 00:34:24,460
and then night you didn't find anything and cheating to find and basically the correlation

539
00:34:24,460 --> 00:34:25,440
between the two

540
00:34:26,460 --> 00:34:28,250
and the true clustering with

541
00:34:28,250 --> 00:34:30,690
no the incarnation

542
00:34:32,750 --> 00:34:33,690
and then

543
00:34:36,050 --> 00:34:38,210
he doesn't find

544
00:34:38,230 --> 00:34:40,300
the anything relevant

545
00:34:40,340 --> 00:34:43,840
however she that

546
00:34:43,860 --> 00:34:44,780
i think

547
00:34:45,710 --> 00:34:47,170
find the most

548
00:34:47,190 --> 00:34:48,630
you don't you think

549
00:34:50,150 --> 00:34:57,750
well away from the person but is significantly better than the cheap

550
00:34:57,760 --> 00:35:00,940
but the likelihood the class

551
00:35:00,960 --> 00:35:08,380
which means that in fact there is information then you can multiply

552
00:35:08,380 --> 00:35:10,330
OK surprisingly

553
00:35:11,070 --> 00:35:14,640
the things that are nearly sorted but often it's just you know it's sort somebody

554
00:35:14,640 --> 00:35:16,300
wants to make sure it sort it

555
00:35:16,340 --> 00:35:20,170
just sort it again rather than checking see if sort

556
00:35:21,280 --> 00:35:23,970
in those cases one side of partition

557
00:35:23,990 --> 00:35:27,660
each partition

558
00:35:34,030 --> 00:35:35,700
has no

559
00:35:37,340 --> 00:35:42,780
so that we can write out what the recursion is for that

560
00:35:42,790 --> 00:35:46,920
so it's here and if one side has no elements

561
00:35:46,970 --> 00:35:49,870
we're going to have to zero on that side

562
00:35:49,890 --> 00:35:52,920
and on the other side have to give n minus one

563
00:35:52,940 --> 00:35:57,850
for that which is running out the recursion for this

564
00:35:58,610 --> 00:36:03,230
so one side has no elements the other side has n minus one elements

565
00:36:03,230 --> 00:36:09,500
and the partitioning of the bookkeeping and so forth is water and

566
00:36:10,410 --> 00:36:14,840
so what is to zero

567
00:36:14,860 --> 00:36:20,920
what's two zero

568
00:36:20,940 --> 00:36:24,830
but what does that asymptotically

569
00:36:24,860 --> 00:36:27,280
yes constant or one

570
00:36:27,280 --> 00:36:29,530
OK so that's just

571
00:36:29,540 --> 00:36:30,980
o or one

572
00:36:30,990 --> 00:36:33,340
plus here than minus one

573
00:36:33,390 --> 00:36:36,310
first order and well

574
00:36:36,360 --> 00:36:40,830
the order one can be absorbed into your and so this is really just saying

575
00:36:40,850 --> 00:36:42,790
t then minus one

576
00:36:45,000 --> 00:36:46,510
four and

577
00:36:46,520 --> 00:36:50,830
and what's that equal to

578
00:36:51,060 --> 00:36:53,970
that's order in square

579
00:36:53,980 --> 00:36:55,910
k or m squared

580
00:36:55,970 --> 00:37:00,560
why is that and squared

581
00:37:00,570 --> 00:37:03,760
yes an arithmetic series

582
00:37:04,800 --> 00:37:11,210
OK actually just like

583
00:37:11,230 --> 00:37:12,390
we got more

584
00:37:12,420 --> 00:37:15,220
insertion sort

585
00:37:15,290 --> 00:37:19,610
just like for insertion sort

586
00:37:19,630 --> 00:37:25,880
because an arithmetic series went all that work

587
00:37:25,900 --> 00:37:28,350
we have an algorithm called the quicksort

588
00:37:32,490 --> 00:37:34,870
it's no faster

589
00:37:34,900 --> 00:37:36,640
then insertion sort

590
00:37:39,160 --> 00:37:41,880
well as i said good algorithm

591
00:37:42,640 --> 00:37:45,660
the reason is a good algorithm is because it's

592
00:37:45,720 --> 00:37:49,220
average case time when see is very good

593
00:37:51,540 --> 00:37:55,370
but let's try to understand this little bit more just so that we understand the

594
00:37:55,370 --> 00:37:58,620
difference between what's going to happen in the average case what's going to happen in

595
00:38:01,160 --> 00:38:02,950
in the worst case

596
00:38:03,070 --> 00:38:05,790
so let's draw recursion tree for this

597
00:38:11,390 --> 00:38:14,850
here's an equal to zero

598
00:38:14,870 --> 00:38:17,480
and minus one

599
00:38:17,480 --> 00:38:21,540
plus and i'll make the cost explicit per se

600
00:38:21,590 --> 00:38:26,620
OK so we get an intuition what's going on so some constant times and

601
00:38:26,690 --> 00:38:27,580
and then

602
00:38:27,610 --> 00:38:31,950
we have to and is equal to and we write it with the

603
00:38:32,250 --> 00:38:34,030
in part here c

604
00:38:34,080 --> 00:38:35,940
in nineteen zero here

605
00:38:35,940 --> 00:38:39,610
t of n minus one here

606
00:38:39,640 --> 00:38:42,970
i know there are you folks are really fast and want to jump immediately to

607
00:38:42,970 --> 00:38:44,750
the full tree

608
00:38:44,790 --> 00:38:48,670
but let me tell you my advice is that you spend just a couple minutes

609
00:38:48,670 --> 00:38:49,970
writing out

610
00:38:50,020 --> 00:38:55,860
only costs to since the tree grows exponentially only cost you constant overhead

611
00:38:55,880 --> 00:39:00,050
to write out the small cases OK and make sure you got the pattern that

612
00:39:00,050 --> 00:39:02,640
you're developing someone go one more step

613
00:39:02,690 --> 00:39:04,720
here we he zero

614
00:39:04,870 --> 00:39:08,560
and now this becomes to see this become c

615
00:39:08,610 --> 00:39:10,560
times and minus one

616
00:39:10,560 --> 00:39:13,140
and now we have another over here

617
00:39:13,160 --> 00:39:14,840
t of

618
00:39:14,850 --> 00:39:17,040
one minus two

619
00:39:17,080 --> 00:39:19,310
and we continue that

620
00:39:19,380 --> 00:39:20,850
the dot

621
00:39:20,870 --> 00:39:23,890
until we get to

622
00:39:23,910 --> 00:39:26,250
so that's all equal to

623
00:39:26,280 --> 00:39:28,890
c and with two zero here

624
00:39:29,080 --> 00:39:33,050
sometimes and minus one

625
00:39:33,060 --> 00:39:35,060
the key is zero here

626
00:39:35,060 --> 00:39:36,630
single interest groups

627
00:39:37,190 --> 00:39:38,250
as we've come to call them

628
00:39:39,500 --> 00:39:45,630
whereby and religions one of those right to have the some reason why you will belong together

629
00:39:46,080 --> 00:39:47,960
and if they create a sense can ship

630
00:39:48,420 --> 00:39:52,460
and if you think the language used in a lot of religious brothers sisters fathers mothers

631
00:39:53,040 --> 00:39:56,250
will kind terminology it's the language family and kinship

632
00:39:57,790 --> 00:39:58,310
and so

633
00:39:59,320 --> 00:40:00,040
the reason route

634
00:40:00,500 --> 00:40:05,960
down that's beautiful creating a sensor belonging i think what it's all about is creating

635
00:40:06,170 --> 00:40:10,340
some grand project this is clearly one religions what is a grand project that we're

636
00:40:10,360 --> 00:40:11,460
all trying to achieve

637
00:40:12,230 --> 00:40:15,380
so you have to have the sense of the big project which everybody signs up

638
00:40:15,380 --> 00:40:17,730
to as bright i belong to the club

639
00:40:18,250 --> 00:40:20,860
and we see that all the time so you know

640
00:40:21,690 --> 00:40:22,340
they were are

641
00:40:22,770 --> 00:40:26,190
you know so the band you say you've you you go to the bar and

642
00:40:26,190 --> 00:40:28,730
i'd be so in the guy sitting next you turns out to be

643
00:40:29,360 --> 00:40:33,860
a profound founded the same football club u you know and then your mind each other drinks or not

644
00:40:34,520 --> 00:40:36,110
just on the you never met the guy before

645
00:40:36,900 --> 00:40:39,130
you know we do something that gets kicked in

646
00:40:39,610 --> 00:40:40,980
when you have the sensitive

647
00:40:41,610 --> 00:40:45,630
belong to a club some kind of doesn't appear to be unique to human so

648
00:40:45,630 --> 00:40:46,730
there is a route down there

649
00:40:47,270 --> 00:40:51,080
question is what kinda grand project can we have that is religion

650
00:40:52,730 --> 00:40:54,340
that would create sensitive

651
00:41:02,540 --> 00:41:04,810
okay thank you for the talk i really enjoyed it

652
00:41:05,340 --> 00:41:06,000
my question was

653
00:41:06,940 --> 00:41:10,480
very related so i'm gonna have to change it i guess my original question was

654
00:41:10,940 --> 00:41:11,560
you know that the

655
00:41:12,460 --> 00:41:15,520
framework that you posted the beginning about why isn't facebook

656
00:41:15,960 --> 00:41:19,710
opening up these new vistas for u i i feel a little bit like that

657
00:41:20,880 --> 00:41:23,040
straw person argument given that's

658
00:41:23,790 --> 00:41:25,520
we know that that's just

659
00:41:25,750 --> 00:41:27,400
sites like facebook are typically

660
00:41:27,900 --> 00:41:28,540
used to

661
00:41:29,310 --> 00:41:32,590
articulated previously existing relationships so so

662
00:41:33,060 --> 00:41:33,710
i don't know that

663
00:41:34,730 --> 00:41:38,090
i haven't seen in scholarship a popular press this idea about

664
00:41:39,060 --> 00:41:40,080
that work kind making

665
00:41:41,000 --> 00:41:42,770
entirely new sets friends

666
00:41:44,610 --> 00:41:46,520
sites like facebook but rather using them to

667
00:41:46,980 --> 00:41:49,340
kind connect more deeply in our

668
00:41:49,810 --> 00:41:51,630
and easily with people that we already know

669
00:41:52,020 --> 00:41:54,380
so i guess i wanted to kind of push you a little bit on this

670
00:41:55,360 --> 00:41:55,670
kind of

671
00:41:56,150 --> 00:42:00,610
idea that's that's what they're supposed to do and that's a feeling you know i

672
00:42:01,320 --> 00:42:05,810
i mean i think the argument really hinges around the fact that facebook or another

673
00:42:05,880 --> 00:42:09,590
social networking sites in principle when the set had vision in my

674
00:42:10,360 --> 00:42:11,940
it implicitly if not explicitly

675
00:42:12,520 --> 00:42:15,710
like that could allow you to connect up lots of people and so

676
00:42:16,150 --> 00:42:16,880
that's my

677
00:42:17,610 --> 00:42:22,520
interpretation why facebook started to give you in particular started to give you these linkages

678
00:42:22,960 --> 00:42:27,980
you itself senses a friend friend friend you may be interested in signing up them as well

679
00:42:28,940 --> 00:42:35,150
most people i think we have resisted at temptations so hasn't really worked in the way they probably originally intended

680
00:42:35,770 --> 00:42:38,170
but not everybody and some people clearly do

681
00:42:38,690 --> 00:42:41,270
and i think there into this with a competitive game problem

682
00:42:42,020 --> 00:42:42,630
if anything

683
00:42:44,790 --> 00:42:48,150
but it's clear that what i mean by facebook and the like

684
00:42:49,190 --> 00:42:54,290
ah have really filled an important niche and that's the next that come about as

685
00:42:54,290 --> 00:42:56,480
a result probably only in the last half century

686
00:42:57,480 --> 00:42:59,840
whereby as we become more mobile

687
00:43:01,480 --> 00:43:03,810
three all life you end up having little

688
00:43:04,310 --> 00:43:05,670
blocks are friends

689
00:43:06,210 --> 00:43:11,090
scattered around in the world where you've worked or been to university or whatever it is

690
00:43:13,060 --> 00:43:15,630
what it does is allow you to keep keep those

691
00:43:16,860 --> 00:43:20,440
going in when they were clearly drop the great question is

692
00:43:21,110 --> 00:43:22,270
well they drop out anyway

693
00:43:23,400 --> 00:43:28,590
doesn't know facebook level contact there's all it do is slow down the rate of decay

694
00:43:29,590 --> 00:43:30,540
what is it hold it up

695
00:43:31,190 --> 00:43:34,130
we guess that we have no evidence at the moment

696
00:43:34,630 --> 00:43:38,950
that's it just slows down the rate of decay because what's important ultimately keep a

697
00:43:38,950 --> 00:43:43,420
relationship going is actually doing stuff that together face-to-face now face

698
00:43:44,060 --> 00:43:46,690
social networking sites start to be able to introduce

699
00:43:47,090 --> 00:43:49,020
you know videoconferencing talk formats as

700
00:43:49,730 --> 00:43:50,500
google groups and

701
00:43:51,130 --> 00:43:55,270
people have been doing that's may solve the problem but it still hasn't done the

702
00:43:55,270 --> 00:43:59,590
virtual touch things because we actually release close friends we engage in a lot of

703
00:43:59,590 --> 00:44:00,270
physical touch

704
00:44:00,730 --> 00:44:02,210
so the question then is

705
00:44:02,730 --> 00:44:03,360
well actually

706
00:44:03,360 --> 00:44:04,560
in astronomy

707
00:44:04,570 --> 00:44:07,900
if you have a binary system and the stars exactly do this

708
00:44:07,930 --> 00:44:10,090
to determine all these quantities that you

709
00:44:10,120 --> 00:44:11,010
would like

710
00:44:12,330 --> 00:44:15,320
i first would like to show you know

711
00:44:15,320 --> 00:44:20,020
some slides

712
00:44:20,050 --> 00:44:28,410
the first slide

713
00:44:28,440 --> 00:44:34,110
o i have lower described by the way that would help wouldn't it

714
00:44:34,120 --> 00:44:35,130
the first slide

715
00:44:35,170 --> 00:44:36,740
it's a spectrum

716
00:44:36,750 --> 00:44:39,390
made in the laboratory

717
00:44:41,420 --> 00:44:43,930
helium and calcium and sodium

718
00:44:43,980 --> 00:44:45,350
it shows you

719
00:44:45,410 --> 00:44:48,070
emission lines no absorption lines

720
00:44:49,500 --> 00:44:51,670
o lines are produced by lamps

721
00:44:51,760 --> 00:44:54,130
and the frequencies are very well known

722
00:44:54,160 --> 00:44:57,090
you see the famous sodium yellow lines

723
00:44:57,100 --> 00:44:59,500
so here's the red part of the spectrum and is the blue part of the

724
00:45:02,420 --> 00:45:03,930
so we know these

725
00:45:03,940 --> 00:45:06,970
frequencies node wavelengths very well

726
00:45:06,980 --> 00:45:08,230
and here you see

727
00:45:09,380 --> 00:45:13,140
of the sun was all these absorption lines that i mentioned to you

728
00:45:13,190 --> 00:45:15,080
last was absorption lines

729
00:45:15,090 --> 00:45:17,220
each of them can be identified

730
00:45:17,260 --> 00:45:18,720
these are due to calcium

731
00:45:18,730 --> 00:45:20,920
i hydrogen and so on

732
00:45:20,940 --> 00:45:22,830
here is the real part of the spectrum

733
00:45:22,840 --> 00:45:25,880
is the green party the green party and and here is the red part of

734
00:45:25,880 --> 00:45:29,890
the space

735
00:45:29,900 --> 00:45:31,320
and here

736
00:45:31,370 --> 00:45:32,230
you see

737
00:45:32,230 --> 00:45:33,650
the basic idea

738
00:45:34,740 --> 00:45:36,960
a binary system

739
00:45:36,970 --> 00:45:40,320
suppose you have a binary system that only one stars visible and the other one

740
00:45:40,320 --> 00:45:41,630
is invisible

741
00:45:41,650 --> 00:45:45,390
and the one star show you three clear absorption lines

742
00:45:45,430 --> 00:45:46,750
then as the star

743
00:45:46,760 --> 00:45:48,890
moves around the centre of mass

744
00:45:48,920 --> 00:45:51,350
you see them all these lines drifting unit

745
00:45:51,360 --> 00:45:52,880
and out of this information

746
00:45:52,890 --> 00:45:57,680
you get the radius the velocity and the period assuming that you are on earth

747
00:45:57,680 --> 00:46:00,490
in the plane of the orbit of the stars

748
00:46:00,530 --> 00:46:04,000
if you have a binary system whereby

749
00:46:04,010 --> 00:46:05,820
both stars are visible

750
00:46:05,830 --> 00:46:08,480
so you get the spectrum of both stars

751
00:46:08,600 --> 00:46:12,010
there you see the doppler shift of both stars in the spectrum

752
00:46:12,010 --> 00:46:15,960
here we have the simple case that we only have two absorption lines not to

753
00:46:15,960 --> 00:46:17,260
confuse the issue

754
00:46:17,300 --> 00:46:19,990
so in one in the case of one start

755
00:46:20,040 --> 00:46:22,660
the shift will be towards the left of the two lines

756
00:46:22,730 --> 00:46:25,600
but the order of start to shift will be to the right

757
00:46:25,650 --> 00:46:28,890
because if you have a binary system and one star comes to you

758
00:46:28,930 --> 00:46:31,920
the other start goes away from you and vice versa

759
00:46:31,970 --> 00:46:33,570
so now you're very lucky

760
00:46:33,580 --> 00:46:35,650
now you have an ideal situation

761
00:46:35,670 --> 00:46:38,180
that you can find football stars

762
00:46:38,230 --> 00:46:42,040
the radius of the orbit the velocity in orbit and the period

763
00:46:42,090 --> 00:46:44,680
for each star which of course is the same

764
00:46:44,690 --> 00:46:48,280
for both

765
00:46:48,320 --> 00:46:50,410
and here you see real data

766
00:46:50,430 --> 00:46:52,480
you see here first of all

767
00:46:52,510 --> 00:46:55,560
the emission lines which are measured in the laboratory

768
00:46:55,680 --> 00:46:58,600
i just showed you always done simultaneously

769
00:46:58,650 --> 00:46:59,890
with the measurements

770
00:46:59,900 --> 00:47:04,150
you always must be sure that you have good calibration of your wavelength

771
00:47:04,160 --> 00:47:09,840
and this spectrum eight pop spectrum is store binary system that has a period of

772
00:47:09,840 --> 00:47:11,750
twenty point five days

773
00:47:11,790 --> 00:47:16,470
you see here a single lines if you have good eyes that means at this

774
00:47:16,470 --> 00:47:21,210
very moment both stars move relative to you at angles of ninety degrees so you

775
00:47:21,210 --> 00:47:25,350
don't see any doppler shift but now look here later in time

776
00:47:25,370 --> 00:47:26,730
you see this line

777
00:47:26,750 --> 00:47:30,990
split into lines and this one is also split into lines

778
00:47:31,040 --> 00:47:33,440
clearly one component is coming to you

779
00:47:33,460 --> 00:47:35,780
and the other component is moving

780
00:47:35,820 --> 00:47:36,930
away from you

781
00:47:36,960 --> 00:47:40,480
and so you get all this useful information

782
00:47:40,490 --> 00:47:41,740
in astronomy

783
00:47:43,410 --> 00:47:45,580
the doppler shift measurements

784
00:47:45,580 --> 00:47:52,040
of binary systems

785
00:47:54,660 --> 00:47:55,540
i want to

786
00:47:55,540 --> 00:47:57,160
so the idea of

787
00:47:57,220 --> 00:48:00,240
binary stars

788
00:48:00,320 --> 00:48:01,380
they give us

789
00:48:01,390 --> 00:48:03,280
not only the information

790
00:48:03,310 --> 00:48:05,020
that we want regarding

791
00:48:05,030 --> 00:48:06,410
the orbit

792
00:48:06,440 --> 00:48:07,710
but there is even

793
00:48:08,410 --> 00:48:11,050
that we can get out of it which is even more

794
00:48:12,780 --> 00:48:21,300
so i will remind you want a binary system looks like

795
00:48:21,310 --> 00:48:23,850
remember exams

796
00:48:23,940 --> 00:48:27,010
the second exam sure you'll never

797
00:48:27,100 --> 00:48:30,790
forget that second examine maybe never forgive me for that

798
00:48:30,800 --> 00:48:35,440
binary system

799
00:48:35,470 --> 00:48:37,220
star one

800
00:48:37,270 --> 00:48:40,040
radius are one

801
00:48:40,060 --> 00:48:42,540
mass and one

802
00:48:44,270 --> 00:48:46,060
v one

803
00:48:46,120 --> 00:48:50,630
and start to

804
00:48:50,650 --> 00:48:55,510
going about their common centre of mass

805
00:48:55,550 --> 00:48:56,630
mass two

806
00:48:56,760 --> 00:49:00,280
radius r two

807
00:49:00,380 --> 00:49:06,030
and the velocity v two

808
00:49:06,080 --> 00:49:07,570
and one or one

809
00:49:07,580 --> 00:49:12,370
he calls and two are that's the way the centre of of mass

810
00:49:12,430 --> 00:49:14,040
is defined

811
00:49:14,040 --> 00:49:16,390
imagine that you as an observer

812
00:49:16,410 --> 00:49:18,590
somewhere in the plane of its orbit

813
00:49:18,610 --> 00:49:21,010
and you are you

814
00:49:21,030 --> 00:49:22,820
you observing system

815
00:49:22,870 --> 00:49:26,280
going around

816
00:49:26,320 --> 00:49:27,600
capra's third law

817
00:49:27,620 --> 00:49:29,070
which derived

818
00:49:29,170 --> 00:49:32,970
on the exam as well as on i

819
00:49:34,830 --> 00:49:38,770
the period squared equals four pi squared

820
00:49:38,780 --> 00:49:40,610
times are one

821
00:49:40,640 --> 00:49:42,090
plus are two

822
00:49:42,110 --> 00:49:43,960
the power three

823
00:49:44,000 --> 00:49:45,140
divided by

824
00:49:46,220 --> 00:49:47,780
times and one

825
00:49:47,790 --> 00:49:49,890
plus and two

826
00:49:49,910 --> 00:49:52,350
we checked that to make sure you have the right yes

827
00:49:52,480 --> 00:49:54,050
that is correct

828
00:49:54,100 --> 00:49:58,760
imagine how you can make the doppler shift measurements of both stars

829
00:49:58,840 --> 00:50:01,800
you make the doppler shift measurements of star number one

830
00:50:01,860 --> 00:50:05,600
so you measure lambda one prime as a function of time

831
00:50:05,600 --> 00:50:09,150
this is actually applicable to any kind of discrete rituals

832
00:50:09,690 --> 00:50:12,850
for example we could do stemming if we if we like

833
00:50:12,890 --> 00:50:13,840
so you could

834
00:50:13,860 --> 00:50:19,720
apply that the stem once you've lectures use capitalization features and things like that this

835
00:50:19,720 --> 00:50:22,120
kind of features you can

836
00:50:22,130 --> 00:50:23,270
you know use

837
00:50:23,300 --> 00:50:24,090
it is

838
00:50:24,930 --> 00:50:28,480
actually this idea is quite all as well all over world

839
00:50:28,510 --> 00:50:32,720
it's more reasons and that works in the field it has been published in two

840
00:50:32,720 --> 00:50:33,640
thousand one

841
00:50:34,540 --> 00:50:36,050
by yoshua bengio

842
00:50:36,070 --> 00:50:42,210
four like actually training error which model and what you one

843
00:50:42,240 --> 00:50:47,120
so once you know how to force from once interact

844
00:50:47,130 --> 00:50:49,590
well you are you are already on was done

845
00:50:49,600 --> 00:50:52,380
you just

846
00:50:52,390 --> 00:50:53,430
you can actually

847
00:50:53,450 --> 00:50:56,190
you know you consider a sentence like you know like the cat sat on the

848
00:50:56,190 --> 00:50:58,890
mat on suppose you want to tag

849
00:50:58,890 --> 00:51:00,490
the one on

850
00:51:00,520 --> 00:51:02,710
so i'm going to take a window of

851
00:51:03,540 --> 00:51:05,630
one one of interest

852
00:51:05,630 --> 00:51:07,270
so it's a fixed size window

853
00:51:07,300 --> 00:51:10,090
of it's a window of size five

854
00:51:10,100 --> 00:51:14,930
and for each one in the window you consider all your features of interest

855
00:51:14,960 --> 00:51:18,830
and for each features on each one you apply

856
00:51:18,830 --> 00:51:21,450
you're lookuptable or idea

857
00:51:21,470 --> 00:51:27,190
so you're paying for each one like the corresponding feature vector

858
00:51:27,190 --> 00:51:32,800
once you've done that you can just like concatenate concatenate everything and find that classical

859
00:51:32,800 --> 00:51:33,850
or you know

860
00:51:33,860 --> 00:51:36,210
nine network layouts and you train

861
00:51:36,440 --> 00:51:37,520
it's in

862
00:51:37,540 --> 00:51:40,140
by the competition

863
00:51:40,140 --> 00:51:47,040
and surprisingly it works well for many tasks like you know part of speech tracking

864
00:51:47,390 --> 00:51:49,950
to children is it's it's OK

865
00:51:52,410 --> 00:51:55,050
the only thing is that

866
00:51:55,110 --> 00:52:01,540
four best which led to require long range dependencies like for example simmons' column

867
00:52:01,620 --> 00:52:06,530
you cannot expect this to because final before semantic quality your thinking one with respect

868
00:52:06,530 --> 00:52:11,430
to have a neutral beforehand and then might be even that outside the window

869
00:52:11,440 --> 00:52:14,730
so instead of that you know you cannot consider

870
00:52:14,750 --> 00:52:19,180
just a window of text you have to consider the complete sentence

871
00:52:19,220 --> 00:52:23,630
so instead well just like consider the complete sentence

872
00:52:23,640 --> 00:52:25,920
the point then is that

873
00:52:25,940 --> 00:52:31,650
the sentence might be of fibre lengths right and z is a is actually like

874
00:52:31,690 --> 00:52:34,790
a quite common

875
00:52:34,800 --> 00:52:39,990
no network architecture to deal with this kind of things it's cooler conditions

876
00:52:42,080 --> 00:52:46,100
one this time it's a bit like a generalisation of the window approach

877
00:52:46,100 --> 00:52:48,020
basically because you don't

878
00:52:48,050 --> 00:52:51,180
again a window of

879
00:52:51,190 --> 00:52:53,190
size with the right answer

880
00:52:53,200 --> 00:52:56,370
you can look at the net all of this three vectors together and you play

881
00:52:56,420 --> 00:52:58,080
metrics are some indication

882
00:52:58,110 --> 00:53:01,580
which points you like a kind of local features you shift you do the same

883
00:53:01,580 --> 00:53:06,690
for the next three it gives you again like local features and so on

884
00:53:06,700 --> 00:53:11,130
come on this is done in nineteen eighty nine when presented this energy towards two

885
00:53:11,130 --> 00:53:14,580
thousand nine because you forgot about it

886
00:53:14,800 --> 00:53:18,360
actually works very well for fixed so

887
00:53:18,400 --> 00:53:19,930
so that

888
00:53:20,000 --> 00:53:24,670
they basically are going to train again disbarment metrics

889
00:53:24,680 --> 00:53:28,920
as a result you know knowledge work

890
00:53:31,010 --> 00:53:35,190
once you you you you produce like this you know local features

891
00:53:35,230 --> 00:53:37,490
you still have like a number of vectors

892
00:53:37,510 --> 00:53:40,010
which is which is like

893
00:53:40,050 --> 00:53:45,020
dependent on of of the number of walls in the sentence so you still have

894
00:53:45,020 --> 00:53:47,970
to get rid of this you know the time dimension

895
00:53:47,990 --> 00:53:52,820
so for doing this here we apply max over time so we try to capture

896
00:53:52,820 --> 00:53:54,500
the most interesting

897
00:53:54,530 --> 00:53:57,440
features over time just playing a max of

898
00:53:57,460 --> 00:53:59,890
each feature of time

899
00:54:01,350 --> 00:54:05,880
and that's it once we got that we have no fixed size feature vector which

900
00:54:05,880 --> 00:54:14,640
like represent opted sentence and we can fit fit that two classic or no at

901
00:54:14,700 --> 00:54:17,680
so we're going to do that actually fall

902
00:54:17,690 --> 00:54:20,840
each one in this sentence so we need to

903
00:54:20,840 --> 00:54:23,150
and some extra features

904
00:54:24,190 --> 00:54:26,940
to the network which what we are interested in

905
00:54:26,960 --> 00:54:30,620
and with respect to which we want to thank you

906
00:54:30,650 --> 00:54:39,100
so the network in that case looks like that it's again and this time you

907
00:54:39,100 --> 00:54:40,920
posted on the complete sentence

908
00:54:41,640 --> 00:54:43,690
all one in this sentence you

909
00:54:43,720 --> 00:54:46,710
consider on the features you are interested in

910
00:54:46,730 --> 00:54:48,530
you apply the lookup table four

911
00:54:48,540 --> 00:54:51,100
all of all the words in the sentence

912
00:54:51,110 --> 00:54:55,270
play operations if you like but look charlie

913
00:54:55,300 --> 00:54:56,930
you apply the maximum time

914
00:54:56,940 --> 00:54:59,190
to get rid of the

915
00:54:59,200 --> 00:55:00,600
the time dimension

916
00:55:00,600 --> 00:55:05,300
and then you find that the classical millions and that's it

917
00:55:09,180 --> 00:55:10,970
we have to train this beast

918
00:55:11,030 --> 00:55:16,870
we actually like to use like i mean we are we are much also we

919
00:55:16,870 --> 00:55:20,880
consider our training set right and we are going to

920
00:55:21,080 --> 00:55:22,800
temperate some of

921
00:55:22,830 --> 00:55:25,880
on on the talk outputs as priorities

922
00:55:25,900 --> 00:55:30,850
so after all so i will show you two ways to interpret this

923
00:55:30,870 --> 00:55:33,160
network puts us point

924
00:55:33,170 --> 00:55:34,240
but once

925
00:55:34,650 --> 00:55:39,190
you've probably is you can just like maximum maximize the log likelihood

926
00:55:39,930 --> 00:55:44,760
apply stochastic gradient descent you know parliament also the network

927
00:55:44,850 --> 00:55:47,080
that they represent him

928
00:55:47,090 --> 00:55:48,860
and you

929
00:55:50,370 --> 00:55:51,600
train like

930
00:55:51,690 --> 00:55:55,930
i mean people sink usually is on that there is a lot of tricks you

931
00:55:55,930 --> 00:56:03,960
know but actually we consider only two classical tricks we divide the learning rates by

932
00:56:04,040 --> 00:56:08,970
what is called the finding actually the nonlinearities fixed

933
00:56:09,000 --> 00:56:13,320
and we initialize also according to the opening the singers

934
00:56:17,450 --> 00:56:20,220
what this

935
00:56:20,240 --> 00:56:26,950
good christians if it's a sentence internal make sure it's

936
00:56:27,380 --> 00:56:29,800
like number of

937
00:56:29,860 --> 00:56:32,340
inputs you have initially basically

938
00:56:32,360 --> 00:56:35,450
OK so somehow you normalized by the number of

939
00:56:35,530 --> 00:56:38,420
parliament also in the late

940
00:56:38,460 --> 00:56:40,910
input parliament

941
00:56:40,930 --> 00:56:42,800
so what

942
00:56:42,830 --> 00:56:44,620
your knowledge workers are kind of

943
00:56:44,640 --> 00:56:49,430
if you look at it like you know exists

944
00:56:49,510 --> 00:56:51,540
it's really like module

945
00:56:51,590 --> 00:56:53,430
and actually we

946
00:56:53,460 --> 00:56:56,990
it's what you're

947
00:56:57,020 --> 00:57:01,670
computes is its derivative was

948
00:57:01,670 --> 00:57:05,710
i mean it's model as to compute is density with respect to the parameters right

949
00:57:05,740 --> 00:57:10,000
and this can be done efficiently by what is called a competition which is just

950
00:57:10,000 --> 00:57:11,730
an application of the general

951
00:57:11,740 --> 00:57:17,800
so it's more you're basically computes its derivative with respect to its own parliament

952
00:57:17,820 --> 00:57:20,760
it started with respect

953
00:57:20,760 --> 00:57:22,910
so you might be interested in actually looking at that

954
00:57:22,930 --> 00:57:27,920
the posterior distribution itself forming some kind of expectations with respect to it

955
00:57:27,930 --> 00:57:29,380
for example

956
00:57:29,390 --> 00:57:34,900
if we set is a function just to be xity itself there will be calculating

957
00:57:34,900 --> 00:57:40,190
the posterior mean estimates which is the minimum mean square error estimator for the states

958
00:57:41,040 --> 00:57:45,960
you may also wish to allow ourselves the lack to make it more reliable estimates

959
00:57:46,110 --> 00:57:47,630
made moving

960
00:57:47,670 --> 00:57:50,690
for example estimating the state of the lack of

961
00:57:52,280 --> 00:57:55,940
or we may wish to fixed interval smoothing trying get the distribution of the entire

962
00:57:55,940 --> 00:58:00,980
state sequence over some time axis not

963
00:58:01,010 --> 00:58:06,510
so that it illustrates that filtering is concerned with the media estimation is you get

964
00:58:06,510 --> 00:58:08,550
a new data point smoothing

965
00:58:08,580 --> 00:58:11,950
give you some look ahead of future data points and hence you should get a

966
00:58:11,950 --> 00:58:16,210
tighter distribution on the on on the states

967
00:58:16,230 --> 00:58:22,280
right so filtering there is the main focus of this this work so let's consider

968
00:58:22,280 --> 00:58:23,860
filtering at time t

969
00:58:23,900 --> 00:58:28,030
suppose we solve the filtering problem up to that time so these things are divided

970
00:58:28,550 --> 00:58:31,190
to right in a recursive fashion usually

971
00:58:31,220 --> 00:58:35,300
we've got the filtering distribution we want to update it one time step with the

972
00:58:35,300 --> 00:58:37,140
input of new data point y

973
00:58:37,150 --> 00:58:38,340
t plus one

974
00:58:38,440 --> 00:58:42,910
in principle we could do that with the filtering recursions in the first of all

975
00:58:42,910 --> 00:58:44,470
the prediction step

976
00:58:44,490 --> 00:58:46,700
so first of all take

977
00:58:46,740 --> 00:58:50,500
the filtering distribution and update it one time in the future

978
00:58:50,510 --> 00:58:54,620
here is the distribution of x t plus one given all the old data

979
00:58:54,630 --> 00:58:57,490
we can do that by taking the joint distribution

980
00:58:57,920 --> 00:59:02,080
the old state and the new state given all the old data and marginalizing with

981
00:59:02,080 --> 00:59:03,910
respect to it

982
00:59:03,920 --> 00:59:09,590
thanks old state we can factorize that in terms of thing that we have

983
00:59:09,630 --> 00:59:15,400
so factorized in terms of the filtering density that we've already solved at time t

984
00:59:15,900 --> 00:59:17,310
multiplied by

985
00:59:17,310 --> 00:59:21,560
the conditional distribution conditional density of the state at time t plus one

986
00:59:21,580 --> 00:59:24,700
given the all states and all the old data

987
00:59:24,720 --> 00:59:27,160
but because of the assumptions of the model

988
00:59:27,180 --> 00:59:33,070
that's not the state transition density at right comes this marginalization in terms of the

989
00:59:33,070 --> 00:59:35,180
previous filtering density

990
00:59:35,220 --> 00:59:40,470
time the state transition density taking the time t plus one

991
00:59:40,480 --> 00:59:44,650
and then base their kicks in because we now want to incorporate effective a new

992
00:59:44,650 --> 00:59:47,470
data point y t plus one

993
00:59:47,490 --> 00:59:51,660
well that's got directly them from that from the remaining terms in the model

994
00:59:51,680 --> 00:59:56,710
we've already got the predictive distribution of xt plus one given the old data

995
00:59:56,730 --> 00:59:59,630
we multiply that by the observation density

996
00:59:59,640 --> 01:00:03,210
the GFY t plus one given x t plus one

997
01:00:03,420 --> 01:00:09,290
divide through by the normalizing constant PY t plus one given y north routine that

998
01:00:09,290 --> 01:00:16,100
bayes theorem is given us directly then the corrected formula for the new filtering distribution

999
01:00:16,110 --> 01:00:20,890
so that's all very straightforward except that you

1000
01:00:20,900 --> 01:00:25,500
probably can't do this integral in closed form it could be high dimensional

1001
01:00:25,550 --> 01:00:32,010
you've got all the usual problems of dealing with nasty forms nicely unknown forms for

1002
01:00:32,030 --> 01:00:35,720
the for the pdf there

1003
01:00:35,760 --> 01:00:36,950
and so

1004
01:00:36,960 --> 01:00:41,630
but in principle it operates simply you just progress through time adding more data points

1005
01:00:41,630 --> 01:00:45,720
as you go y t plus one y t y t plus one

1006
01:00:45,740 --> 01:00:50,400
you do the filtering getting timesteps sold it to t minus one

1007
01:00:50,420 --> 01:00:53,640
you do the prediction step two to two

1008
01:00:53,790 --> 01:00:56,070
predict one state in the future

1009
01:00:56,090 --> 01:01:03,230
then you correctly using bayes theorem predicts correct status as leapfrog type approach through time

1010
01:01:03,730 --> 01:01:09,120
but as i say this can be done in in general approximations must be used

1011
01:01:09,120 --> 01:01:11,430
especially when x is high dimensional

1012
01:01:11,450 --> 01:01:16,160
and f and g are nongaussian on linear

1013
01:01:17,410 --> 01:01:23,220
so i'm going to go through now the basics of the the kalman filter

1014
01:01:23,240 --> 01:01:27,010
because the say that this is fundamental to some of the particle filters and there's

1015
01:01:27,050 --> 01:01:33,630
a very fundamental idea underlying sequential updating bayesian sequential updating

1016
01:01:35,880 --> 01:01:37,800
OK so it applies for

1017
01:01:37,800 --> 01:01:47,370
where they did actually use study and compared the learned system with google MSN search

1018
01:01:47,420 --> 01:01:51,880
and another search engine top ranked in a blind testing and the way they could

1019
01:01:51,880 --> 01:01:56,830
show yes you know this combined system performs better than all of the individual search

1020
01:01:56,830 --> 01:02:02,220
engines and here's a here the weights that were put on the different features so

1021
01:02:02,220 --> 01:02:07,860
you can see query abstract cosine has the highest weight so this is kind of

1022
01:02:07,860 --> 01:02:12,160
you know the vector space model type of thing being among the top ten in

1023
01:02:13,120 --> 01:02:18,640
it was you know rather to get relatively high weight the key cosine between the

1024
01:02:18,640 --> 01:02:23,100
query and the euro the euro words if we segmented and so on and so

1025
01:02:23,100 --> 01:02:26,180
forth and down here you can see some of the

1026
01:02:26,230 --> 01:02:29,130
the ones that have negative impact like the URL length

1027
01:02:29,150 --> 01:02:31,580
for instance is usually that's fine

1028
01:02:31,590 --> 01:02:35,070
OK so

1029
01:02:35,080 --> 01:02:38,420
so this is you know another example where

1030
01:02:39,110 --> 01:02:43,790
you use relatively weak data but you have large volumes of these data and use

1031
01:02:43,790 --> 01:02:48,480
it to optimize an information retrieval system

1032
01:02:48,520 --> 01:02:52,810
OK so

1033
01:02:52,830 --> 01:02:55,970
and any questions about this yes

1034
01:03:00,990 --> 01:03:06,900
in this experiment ran instance we talking about several thousands of users who have used

1035
01:03:06,910 --> 01:03:10,130
the system for

1036
01:03:12,850 --> 01:03:19,520
and again it depends on on what level of granularity want to choose

1037
01:03:20,260 --> 01:03:25,080
but i think you know this is a very interesting and promising paradigm in general

1038
01:03:25,090 --> 01:03:27,520
also while this is not to say

1039
01:03:27,540 --> 01:03:29,740
you have a system

1040
01:03:29,760 --> 01:03:31,620
it has some key

1041
01:03:31,640 --> 01:03:35,210
component that is parametrized in some way by

1042
01:03:35,230 --> 01:03:37,360
has has been impact on the

1043
01:03:40,070 --> 01:03:44,770
and as users actually all use the system and work with the system interacts with

1044
01:03:44,770 --> 01:03:47,980
the system the system is highly able to use

1045
01:03:48,010 --> 01:03:48,560
you know just

1046
01:03:48,570 --> 01:03:51,270
the information collected during the user

1047
01:03:52,380 --> 01:03:54,110
optimized performance

1048
01:03:54,130 --> 01:03:56,730
that is a very attractive here because you know

1049
01:03:56,830 --> 01:04:01,290
the user doesn't even know that anything is happening there is that proxy is used

1050
01:04:01,450 --> 01:04:07,190
kind of reports you what need to click also to the user it's completely transparent

1051
01:04:07,200 --> 01:04:12,350
and in the long range it produces this is

1052
01:04:12,370 --> 01:04:15,020
OK so that may come to the final

1053
01:04:15,040 --> 01:04:18,230
party on structured classification

1054
01:04:18,250 --> 01:04:21,150
which i also think is is

1055
01:04:21,150 --> 01:04:26,880
you know you can not exist or not to mention that the

1056
01:04:26,890 --> 01:04:28,910
we'll see

1057
01:04:28,930 --> 01:04:31,740
so what i'd like to talk about here than in the last

1058
01:04:31,760 --> 01:04:38,110
it's kind of

1059
01:04:41,920 --> 01:04:42,960
does that mean

1060
01:04:42,970 --> 01:04:43,720
i mean

1061
01:04:43,740 --> 01:04:49,060
he does not like the pressure

1062
01:04:49,080 --> 01:04:50,700
the problem

1063
01:04:50,710 --> 01:04:59,750
i'm talking about but i think it might help to get a second opinion on

1064
01:04:59,770 --> 01:05:01,580
the same subject

1065
01:05:01,630 --> 01:05:04,180
see it might help too

1066
01:05:06,210 --> 01:05:10,680
so i thought i'd like to talk about you know what i call structured classification

1067
01:05:10,680 --> 01:05:16,910
with some people call structured classification is actually the following setting and particularly interesting thing

1068
01:05:16,910 --> 01:05:21,960
of all the information retrieval is that you know traditionally we've been looking at problems

1069
01:05:21,960 --> 01:05:26,860
classification problems in regression problems for these two types of problem we used to working

1070
01:05:26,860 --> 01:05:32,620
at and classification really typically we're looking at binary classification and we're very courageous we'll

1071
01:05:32,890 --> 01:05:38,140
also maybe multiclass classification right but there already it's not so clear sometimes how we

1072
01:05:38,140 --> 01:05:44,670
would do multiclass classification whether we should combine binary classifiers or two proper multiclass approach

1073
01:05:44,850 --> 01:05:49,100
so what i'd like to look at here is the situation where the outputs that

1074
01:05:49,100 --> 01:05:51,130
and port

1075
01:05:51,140 --> 01:05:55,270
we can call them ready results into the index

1076
01:05:55,280 --> 01:05:57,140
for example we can

1077
01:05:57,200 --> 01:05:58,180
no that

1078
01:05:58,200 --> 01:06:01,560
force this force zero and four five

1079
01:06:02,740 --> 01:06:04,450
they was long

1080
01:06:04,500 --> 01:06:08,380
but they have a small number of intersection

1081
01:06:08,400 --> 01:06:09,660
in this case

1082
01:06:09,670 --> 01:06:11,290
we can create

1083
01:06:11,380 --> 01:06:13,100
c of the war

1084
01:06:13,140 --> 01:06:17,650
that is combination of zero and five and create in advance this

1085
01:06:20,150 --> 01:06:23,040
and during search we can use this

1086
01:06:23,080 --> 01:06:25,470
special auxiliary police

1087
01:06:25,470 --> 01:06:30,650
and it can increase the speed of search for such phrases in

1088
01:06:30,670 --> 01:06:34,150
thousands or even more than some the time

1089
01:06:34,250 --> 01:06:39,060
it's a lot of so there is some research in this area

1090
01:06:39,070 --> 01:06:40,760
the problem is how to

1091
01:06:40,950 --> 01:06:46,290
we nol that how do we know that we need to create this special auxiliary

1092
01:06:46,330 --> 01:06:48,060
force these

1093
01:06:50,160 --> 01:06:55,290
the simplest idea we can take the the longest

1094
01:06:55,290 --> 01:06:56,760
post lists

1095
01:06:57,360 --> 01:06:59,150
the most frequent

1096
01:06:59,160 --> 01:07:01,390
and create all axillary

1097
01:07:01,400 --> 01:07:05,330
intersection for them in advance

1098
01:07:05,350 --> 01:07:07,340
this is a good idea

1099
01:07:07,350 --> 01:07:09,510
the problem is

1100
01:07:09,550 --> 01:07:13,510
we can create a lot of these axillary texas

1101
01:07:13,520 --> 01:07:18,490
some of them can be not so short as we want

1102
01:07:18,540 --> 01:07:24,080
and it can increase size to follow in the again significant

1103
01:07:24,160 --> 01:07:25,810
another way

1104
01:07:26,680 --> 01:07:28,980
tried to fix

1105
01:07:29,020 --> 01:07:30,490
to predict

1106
01:07:30,500 --> 01:07:33,060
what can be frequent phrases

1107
01:07:33,080 --> 01:07:35,960
so what are phrases that

1108
01:07:35,970 --> 01:07:39,860
can cause very slow execution of all

1109
01:07:40,810 --> 01:07:42,430
follows search

1110
01:07:42,450 --> 01:07:47,450
what we can do so the idea is now looking to all documents and thinking

1111
01:07:47,460 --> 01:07:50,990
so this document contains these two version

1112
01:07:51,830 --> 01:07:57,230
produces this situation when research very very small we have a lot of documents we

1113
01:07:57,330 --> 01:07:58,870
zero and five

1114
01:07:58,880 --> 01:07:59,760
OK so

1115
01:07:59,770 --> 01:08:01,090
let's create this

1116
01:08:01,120 --> 01:08:04,230
axillary forcing police for them

1117
01:08:04,230 --> 01:08:07,560
we can get this information from our collection

1118
01:08:07,570 --> 01:08:12,340
we can take for example some subset of the whole collection and do this

1119
01:08:12,350 --> 01:08:14,870
collect this information

1120
01:08:14,890 --> 01:08:18,630
in advance and then created this still the war

1121
01:08:18,640 --> 01:08:22,270
and what's this for them during our index spewed phrase

1122
01:08:23,210 --> 01:08:30,640
or another approach we can build our index and then post process this index

1123
01:08:30,660 --> 01:08:35,780
it's again good idea pretty simple we you can implement it

1124
01:08:35,820 --> 01:08:39,380
you can be most more can things that OK

1125
01:08:39,500 --> 01:08:41,820
of course i can do this but for

1126
01:08:43,090 --> 01:08:44,850
is doing this query

1127
01:08:44,900 --> 01:08:48,790
maybe our auxiliary index is is not useful

1128
01:08:48,800 --> 01:08:53,380
maybe users are submitting another phrases and we need

1129
01:08:53,400 --> 01:08:57,470
to create in this for this special phrases

1130
01:08:57,510 --> 01:08:59,810
so we can take a very long

1131
01:08:59,820 --> 01:09:05,060
if you are looking for some search engine only you have access to query logs

1132
01:09:05,060 --> 01:09:06,610
you can

1133
01:09:07,550 --> 01:09:11,340
this hard queries from this query

1134
01:09:11,370 --> 01:09:17,400
and create this index in advance this forcing the postings in advance for this

1135
01:09:17,410 --> 01:09:19,220
part careers

1136
01:09:19,260 --> 01:09:21,230
and the jumping ahead

1137
01:09:21,240 --> 01:09:26,560
we can look into this approach has a look at this approach has static caching

1138
01:09:26,580 --> 01:09:27,580
so we

1139
01:09:27,600 --> 01:09:32,300
in advance process information

1140
01:09:32,300 --> 01:09:34,250
OK but

1141
01:09:34,290 --> 01:09:35,860
the problem is to here

1142
01:09:37,370 --> 01:09:40,750
even his all artillery units

1143
01:09:40,750 --> 01:09:43,980
time of our search

1144
01:09:44,000 --> 01:09:45,990
is always

1145
01:09:46,010 --> 01:09:50,210
linear from the type from the size of foul collection

1146
01:09:50,230 --> 01:09:52,760
and this is this is the main problem

1147
01:09:52,810 --> 01:09:57,540
if it getting more documents for example internet sites on the internet

1148
01:09:57,560 --> 01:10:00,430
it increases risks

1149
01:10:00,450 --> 01:10:05,660
exponential growth getting more and more documents every day

1150
01:10:05,720 --> 01:10:12,200
if they have a linear speed of our search

1151
01:10:12,250 --> 01:10:17,230
we are we cannot all be dubious this law is slower and slower

1152
01:10:17,280 --> 01:10:19,820
in in using all our

1153
01:10:19,880 --> 01:10:26,210
advantages and using all complex structure so we need some stories

1154
01:10:26,260 --> 01:10:28,000
that can reduce

1155
01:10:28,010 --> 01:10:29,710
speed of CRH

1156
01:10:29,720 --> 01:10:33,520
to some constant

1157
01:10:35,220 --> 01:10:40,600
or on the other hand what we can see that nobody actually needs this

1158
01:10:40,630 --> 01:10:43,290
thousands of millions of documents

1159
01:10:43,290 --> 01:10:47,810
the user will never read all these lists that we are produce

1160
01:10:47,860 --> 01:10:52,850
maybe the right idea is not to create full result

1161
01:10:52,860 --> 01:10:59,830
maybe we need to only one thousand most relevant documents and that's

1162
01:10:59,880 --> 01:11:03,550
so stop processing after we have enough

1163
01:11:03,560 --> 01:11:05,950
relevant results

1164
01:11:06,290 --> 01:11:12,520
you can check all popular search engines right now that are available on the internet

1165
01:11:12,520 --> 01:11:15,870
on the internet can see that they always

1166
01:11:15,890 --> 01:11:19,880
you can come to the last page you can see all

1167
01:11:19,960 --> 01:11:25,650
five hundred million documents in the result i can see only for thousand or even

1168
01:11:26,620 --> 01:11:29,760
so everybody's doing this one because we need

1169
01:11:32,160 --> 01:11:38,730
we need to do all search during constant time even if internet grows exponentially

1170
01:11:38,740 --> 01:11:39,810
OK so

1171
01:11:39,820 --> 01:11:42,990
we need some assumptions again

1172
01:11:43,000 --> 01:11:50,910
it's another question on the last lecture you your intuition how to calculate number of

1173
01:11:50,910 --> 01:11:53,600
results how many documents we have

1174
01:11:53,610 --> 01:11:56,200
even if we don't have

1175
01:11:56,240 --> 01:12:01,420
and if you're playing any search engine you very easily can see that this number

1176
01:12:01,420 --> 01:12:03,720
is very far from the real world

1177
01:12:05,250 --> 01:12:07,990
we need to do some assumptions

1178
01:12:09,130 --> 01:12:13,140
we need to things that we have some ranking function it's

1179
01:12:13,160 --> 01:12:16,490
it's good assumption we different have ranking function

1180
01:12:16,500 --> 01:12:19,990
the second assumption is not so good because it

1181
01:12:20,040 --> 01:12:21,970
it doesn't always work

1182
01:12:21,980 --> 01:12:24,010
but the idea is that

1183
01:12:24,060 --> 01:12:26,850
if you have to wait for four

1184
01:12:26,850 --> 01:12:30,360
we need to know is that it

1185
01:12:30,380 --> 01:12:36,590
it turns out the very powerful theory called stochastic approximation theory for applied mathematics is

1186
01:12:36,590 --> 01:12:39,780
actually talks about the convergence of algorithms

1187
01:12:39,790 --> 01:12:41,230
which have the following

1188
01:12:41,990 --> 01:12:45,900
even a deterministic algorithm converges to something

1189
01:12:45,910 --> 01:12:49,930
and have an equivalent circuit if you have a stochastic version of the algorithm that

1190
01:12:49,930 --> 01:12:54,590
essentially have mean zero noise and every step the deterministic algorithm

1191
01:12:55,670 --> 01:12:58,540
under certain conditions that i could find

1192
01:12:58,710 --> 01:13:03,370
the stochastic out converges to the same thing is deterministic algorithm with probability one and

1193
01:13:03,370 --> 01:13:06,730
q learning fits exactly in that

1194
01:13:06,790 --> 01:13:07,840
in that

1195
01:13:07,900 --> 01:13:13,290
in that stochastic approximation framework or the conditions the conditions of this

1196
01:13:13,340 --> 01:13:14,560
the step size

1197
01:13:14,570 --> 01:13:17,580
after some to infinity

1198
01:13:17,590 --> 01:13:20,420
and the solve square the step size has to be finite

1199
01:13:20,720 --> 01:13:23,470
i'm thinking how can that be

1200
01:13:23,520 --> 01:13:27,260
one instance of something like this is outside one over time step for example

1201
01:13:27,300 --> 01:13:28,960
so one of t

1202
01:13:28,970 --> 01:13:34,480
sums to infinity one rt squares some still find quite

1203
01:13:34,500 --> 01:13:40,210
what's the intuition behind these something out infinity simply means you never stop learning

1204
01:13:40,260 --> 01:13:41,870
the the step size

1205
01:13:41,910 --> 01:13:44,770
doesn't shrink to zero so fast

1206
01:13:44,810 --> 01:13:47,980
but you cannot recover

1207
01:13:48,070 --> 01:13:50,520
you can do that you can then you cannot recover

1208
01:13:50,540 --> 01:13:54,720
right so it it it converges to zero slowly enough

1209
01:13:54,770 --> 01:13:57,470
but you always have infinite time to learn

1210
01:13:57,520 --> 01:13:59,770
that's what this condition ensures

1211
01:13:59,780 --> 01:14:04,770
what this condition ensures is that the noise is being shrunk to the variance

1212
01:14:04,900 --> 01:14:07,110
is being shrunk

1213
01:14:07,170 --> 01:14:09,650
advances in keep going down and keep adding

1214
01:14:09,840 --> 01:14:12,330
so these two conditions together

1215
01:14:12,350 --> 01:14:15,280
and the very important conditions

1216
01:14:15,300 --> 01:14:17,450
that you have to ensure

1217
01:14:17,460 --> 01:14:20,010
as you choose actions

1218
01:14:20,140 --> 01:14:23,360
i can tell you how to choose actions i just told you given trajectory this

1219
01:14:23,370 --> 01:14:24,620
i update

1220
01:14:24,630 --> 01:14:26,270
we choose actions somehow

1221
01:14:26,320 --> 01:14:31,380
provided you choose actions in a way that every action gets taken in every state

1222
01:14:31,380 --> 01:14:33,170
infinitely often in the limit

1223
01:14:33,950 --> 01:14:38,230
you get convergence to the optimal value

1224
01:14:38,250 --> 01:14:39,350
number of people

1225
01:14:39,370 --> 01:14:45,940
made this connection i did some work with the mike jordan proving this charted simultaneously

1226
01:14:45,940 --> 01:14:47,470
john stickers

1227
01:14:47,480 --> 01:14:52,120
bringing in the notion of stochastic approximation theory to reinforcement learning and since then it's

1228
01:14:52,120 --> 01:14:54,600
been the how where we have used

1229
01:14:54,620 --> 01:14:58,810
to prove convergence for a lot of reinforcement learning algorithms

1230
01:14:58,820 --> 01:15:04,930
once he made this sort of connection between q learning stochastic approximation

1231
01:15:04,970 --> 01:15:06,940
OK yes

1232
01:15:13,580 --> 01:15:15,770
what you

1233
01:15:15,780 --> 01:15:19,050
so he goes well

1234
01:15:22,750 --> 01:15:30,550
the land

1235
01:15:31,260 --> 01:15:32,230
it is also

1236
01:15:32,240 --> 01:15:33,880
the very

1237
01:15:33,900 --> 01:15:36,730
it was

1238
01:15:37,690 --> 01:15:41,530
this this and this is what we need to ensure that the the way

1239
01:15:41,550 --> 01:15:42,910
exactly one

1240
01:15:42,990 --> 01:15:46,170
we have to see what happens with require

1241
01:15:46,190 --> 01:15:47,200
this what

1242
01:15:50,900 --> 01:15:52,970
or give some intuition is two

1243
01:15:52,990 --> 01:15:54,010
so so

1244
01:15:54,020 --> 01:15:57,270
this album was the first

1245
01:15:57,280 --> 01:16:00,860
direct adaptive optimal control algorithm

1246
01:16:01,890 --> 01:16:05,870
the first algorithm that solves optimal control problems

1247
01:16:05,920 --> 01:16:08,230
without building along

1248
01:16:08,360 --> 01:16:13,660
one of the key contribution of reinforcement learning even dropping the control and operation research

1249
01:16:13,670 --> 01:16:17,230
prior to this there was no such out available at all

1250
01:16:17,240 --> 01:16:18,970
so this is really

1251
01:16:19,020 --> 01:16:22,350
important and key in key contribution now

1252
01:16:22,400 --> 01:16:25,200
let make a couple of observations about the

1253
01:16:25,250 --> 01:16:31,150
the shift from learning state values state action values there was key in making this

1254
01:16:31,150 --> 01:16:35,930
possible and to do that let me unfortunately go back should put that slide here

1255
01:16:35,940 --> 01:16:38,970
is well i forgot

1256
01:16:39,050 --> 01:16:42,110
go to the bellman optimality equation way back he

1257
01:16:44,880 --> 01:16:47,050
this one

1258
01:16:48,510 --> 01:16:50,420
why do we move from

1259
01:16:50,430 --> 01:16:52,990
state by state action values

1260
01:16:53,000 --> 01:16:56,110
now i can make that point six

1261
01:16:56,450 --> 01:17:02,200
moving from state value state action values move the max

1262
01:17:02,210 --> 01:17:04,060
inside the summation

1263
01:17:04,100 --> 01:17:05,000
well the max

1264
01:17:05,010 --> 01:17:07,930
inside the expectation

1265
01:17:07,930 --> 01:17:10,000
which was key

1266
01:17:10,050 --> 01:17:11,510
what is property

1267
01:17:11,530 --> 01:17:13,950
that a random sample

1268
01:17:14,000 --> 01:17:15,330
it was unbiased

1269
01:17:15,350 --> 01:17:19,400
that is if we sample the next state look at a sample quality

1270
01:17:19,400 --> 01:17:22,890
its expectation is exactly the right hand side

1271
01:17:22,900 --> 01:17:27,670
while so if play different for those of you just meaningful

1272
01:17:27,680 --> 01:17:31,120
max is a non linear quantity summation easily acquired

1273
01:17:31,800 --> 01:17:36,400
so into changing the supporting the max inside the summation

1274
01:17:36,400 --> 01:17:42,060
allowed for a direct algorithm whether the max without side information you lose this quantity

1275
01:17:42,060 --> 01:17:43,890
that is if you just look at the

1276
01:17:43,910 --> 01:17:49,770
sample value of the square brackets because the max outside the expectation is not unbiased

1277
01:17:49,770 --> 01:17:52,700
well in this setting it is unbiased

1278
01:17:52,760 --> 01:17:54,890
so into changing

1279
01:17:54,890 --> 01:17:57,090
the max and the expectation

1280
01:17:57,110 --> 01:17:59,040
let to this critical

1281
01:17:59,100 --> 01:18:03,710
o thing that allowed us to develop large chris watkins

1282
01:18:03,730 --> 01:18:08,250
to develop a direct method for reinforcement learning where he stayed with the state value

1283
01:18:08,250 --> 01:18:10,240
that's method for

1284
01:18:10,260 --> 01:18:15,640
metal super position

1285
01:18:15,640 --> 01:18:21,140
and this method says that the output of the circuit

1286
01:18:27,140 --> 01:18:30,300
again focusing on linear circuits

1287
01:18:30,360 --> 01:18:34,270
so i had this remember had the ground where l applies

1288
01:18:34,290 --> 01:18:38,900
and within that playground and playing in the salt goal area

1289
01:18:38,900 --> 01:18:41,770
in the south pole area

1290
01:18:41,840 --> 01:18:45,110
in that subset of the playground circuits are linear

1291
01:18:45,160 --> 01:18:47,230
OK so in that part of the playground

1292
01:18:47,550 --> 01:18:50,920
so the position applies because there circuits are linear

1293
01:18:50,960 --> 01:18:55,330
so the output of a circuit is determined by

1294
01:19:01,570 --> 01:19:04,020
something of the responses to

1295
01:19:04,340 --> 01:19:06,960
it's source

1296
01:19:06,980 --> 01:19:09,390
acting alone

1297
01:19:20,180 --> 01:19:21,720
in the statement here

1298
01:19:21,730 --> 01:19:25,180
the source stands for independent source

1299
01:19:25,360 --> 01:19:28,950
haven't talked about independent sources dependent sources

1300
01:19:29,000 --> 01:19:31,910
talk about dependent sources a few weeks from today

1301
01:19:33,590 --> 01:19:36,430
just so you don't get confused four

1302
01:19:36,520 --> 01:19:41,610
dependent sources you will be looking at section three point three point three

1303
01:19:41,610 --> 01:19:43,260
of course notes

1304
01:19:43,290 --> 01:19:46,940
to see how supervision works with dependent sources

1305
01:19:47,050 --> 01:19:50,650
remember we haven't covered dependent sources yet it will be covering them of about two

1306
01:19:50,650 --> 01:19:54,130
weeks from two weeks from now

1307
01:19:59,050 --> 01:20:01,580
so let's go back to an example

1308
01:20:01,590 --> 01:20:03,460
and apply the method of

1309
01:20:03,530 --> 01:20:06,490
super position two examples

1310
01:20:06,500 --> 01:20:11,110
so the method says

1311
01:20:11,130 --> 01:20:12,000
some of

1312
01:20:12,070 --> 01:20:13,450
the outputs

1313
01:20:17,140 --> 01:20:19,840
applying one source acting alone

1314
01:20:19,850 --> 01:20:21,780
so let me do this here

1315
01:20:21,850 --> 01:20:23,360
let me start with the circuit

1316
01:20:23,370 --> 01:20:27,440
and let me start with shining by all

1317
01:20:27,490 --> 01:20:37,660
so i wanted to be

1318
01:20:37,820 --> 01:20:42,430
are two and i'm showing i

1319
01:20:42,480 --> 01:20:44,840
because of the places with an open circuit

1320
01:20:45,630 --> 01:20:46,970
so i is

1321
01:20:48,180 --> 01:20:49,780
so let me

1322
01:20:49,840 --> 01:20:51,690
we call the notable page

1323
01:20:52,870 --> 01:20:54,290
to reflect

1324
01:20:54,300 --> 01:20:56,520
that component of the node will change

1325
01:20:56,570 --> 01:20:59,730
that arises due to be acting alone

1326
01:21:02,220 --> 01:21:05,340
we should look at this pattern here and very quickly be able to write the

1327
01:21:05,340 --> 01:21:10,450
answer for patterns like the cell voltage the two resistors that's called a resistive divider

1328
01:21:10,450 --> 01:21:13,450
it will appear again and again and again

1329
01:21:14,640 --> 01:21:15,650
is simply

1330
01:21:15,660 --> 01:21:17,050
the times

1331
01:21:17,070 --> 01:21:21,220
two by one close to

1332
01:21:21,270 --> 01:21:23,300
that's that's the micron or

1333
01:21:23,350 --> 01:21:25,170
OK so

1334
01:21:25,240 --> 01:21:28,600
but what is here is simply the voltage

1335
01:21:28,640 --> 01:21:31,440
divided by the total resistance is given the current

1336
01:21:31,540 --> 01:21:33,390
multiplied by r two

1337
01:21:33,420 --> 01:21:35,670
given the words across the sahara

1338
01:21:35,860 --> 01:21:39,440
remember this pattern became applied voltage divider patterns

1339
01:21:39,440 --> 01:21:43,180
three more times than any other pattern that you might imagine

1340
01:21:43,850 --> 01:21:46,750
so that's the acting alone

1341
01:21:46,770 --> 01:21:50,950
now that we do

1342
01:21:50,970 --> 01:21:53,440
i acting alone

1343
01:21:53,480 --> 01:21:56,170
so far i acting alone

1344
01:21:56,250 --> 01:22:07,480
pointing out

1345
01:22:07,500 --> 01:22:10,180
and what to do this time around

1346
01:22:10,220 --> 01:22:13,650
the places for the sharks

1347
01:22:13,840 --> 01:22:16,070
replace the word sort the short

1348
01:22:16,080 --> 01:22:18,710
and we call this voltage

1349
01:22:18,730 --> 01:22:24,570
e i for the voltage that is the component of the world that due to

1350
01:22:24,570 --> 01:22:26,900
the current i

1351
01:22:26,930 --> 01:22:32,700
and we are in this case is simply given by yet another pattern here

1352
01:22:32,760 --> 01:22:37,100
the current across the pair of resistors is simply the effective resistance multiplied by the

1353
01:22:37,820 --> 01:22:39,070
so line

1354
01:22:39,140 --> 01:22:41,890
and effective resistances are one two

1355
01:22:41,900 --> 01:22:46,320
there are one less active

1356
01:22:46,400 --> 01:22:47,500
that's your life

1357
01:22:47,600 --> 01:22:51,500
that's the component at node to the current i

1358
01:22:52,210 --> 01:23:00,730
so that it says that's in the biggest components some them up and there you

1359
01:23:00,730 --> 01:23:02,490
have the answer

1360
01:23:02,590 --> 01:23:05,300
e is simply EV

1361
01:23:05,340 --> 01:23:06,400
because EI

1362
01:23:06,420 --> 01:23:09,240
the components of i acting alone

1363
01:23:09,370 --> 01:23:11,350
just simply the time

1364
01:23:11,430 --> 01:23:14,690
doctor quite close to

1365
01:23:14,710 --> 01:23:18,660
class one or two

1366
01:23:18,690 --> 01:23:25,420
never go

1367
01:23:25,680 --> 01:23:29,070
unfortunately the fates have been kind to us and answers the same as the answer

1368
01:23:29,070 --> 01:23:30,910
to the node

1369
01:23:30,910 --> 01:23:32,130
the surprise here

1370
01:23:32,180 --> 01:23:35,120
so this is actually incredibly simple method

1371
01:23:35,240 --> 01:23:38,360
so you can take a very complex

1372
01:23:38,360 --> 01:23:39,950
OK what is usually done here

1373
01:23:40,010 --> 01:23:42,290
you can think of a complex circuits

1374
01:23:42,300 --> 01:23:47,930
and you can solve it very complex circuits by breaking it down into many simple

1375
01:23:47,930 --> 01:23:49,820
individual subproblems

1376
01:23:50,050 --> 01:23:53,970
we do this in you years time and time and time again

1377
01:23:54,070 --> 01:23:57,940
OK but it in software systems hardware systems are what have

1378
01:23:58,110 --> 01:24:02,680
often times building complicated systems remember human decide

1379
01:24:02,770 --> 01:24:05,990
and the way you put assistance together that's a large software system is not right

1380
01:24:06,010 --> 01:24:10,340
the whole piece of software starting main and you going down

1381
01:24:10,350 --> 01:24:13,510
you belong to components and then by the components together

1382
01:24:13,570 --> 01:24:15,120
in the same manner here

1383
01:24:15,180 --> 01:24:16,710
take a big circuit

1384
01:24:16,730 --> 01:24:18,450
and if you find

1385
01:24:18,600 --> 01:24:23,080
its behaviour for each source acting alone

1386
01:24:23,080 --> 01:24:25,840
lots of little including simple circuit

1387
01:24:25,850 --> 01:24:29,950
in your use examples in your homework where you are given a big circuit

1388
01:24:29,970 --> 01:24:34,090
but because the set of the ice to zero and the other of eastern europe

1389
01:24:34,100 --> 01:24:38,170
the whole circuit almost vanishes and all that you have to do a little research

1390
01:24:38,220 --> 01:24:41,720
OK so this is very very powerful method

1391
01:24:41,740 --> 01:24:45,180
OK i like to do the latter

1392
01:24:45,220 --> 01:24:47,100
demonstration for you

1393
01:24:47,850 --> 01:24:53,610
and what i'm going to show you in the demo

1394
01:24:53,720 --> 01:24:56,840
is a that of water

1395
01:24:58,230 --> 01:25:04,300
i'll tell you what it is second but assume human saltwater for now

1396
01:25:04,410 --> 01:25:06,720
can apply

1397
01:25:12,250 --> 01:25:13,210
two homepages

1398
01:25:13,220 --> 01:25:15,190
in this case reply

1399
01:25:15,240 --> 01:25:17,980
it's a

1400
01:25:18,030 --> 01:25:20,720
very good

1401
01:25:20,790 --> 01:25:23,110
the sinusoidal

1402
01:25:23,150 --> 01:25:26,050
and the triangular roof

1403
01:25:26,120 --> 01:25:27,170
what we do

1404
01:25:27,260 --> 01:25:30,280
his measure

1405
01:25:30,340 --> 01:25:32,580
the response at the site

1406
01:25:32,580 --> 01:25:34,810
maximize we suspect

1407
01:25:35,240 --> 01:25:39,390
it is more possible that by doing so then

1408
01:25:39,450 --> 01:25:43,770
the right hand side the maximum can reach the minimum of the prime

1409
01:25:43,790 --> 01:25:49,490
so this is still to the peaceful nation that i just gave is called we

1410
01:25:50,260 --> 01:25:56,410
so we can do it says this is medium primary school historical amount of these

1411
01:25:56,660 --> 01:25:58,700
going we do a

1412
01:25:58,760 --> 01:26:05,060
so this probably an explanation but this has nothing to do we support vectors

1413
01:26:05,080 --> 01:26:10,840
because we're doing this problem deal with for optimisation people and this is this is

1414
01:26:10,840 --> 01:26:17,160
nothing to do support vector machines is just pure quadratic optimisation problem

1415
01:26:17,180 --> 01:26:18,580
and so

1416
01:26:18,600 --> 01:26:20,310
a o

1417
01:26:20,330 --> 01:26:24,580
and this from the point that point of view we don't worry about why we

1418
01:26:27,410 --> 01:26:31,540
with more about the meaning of support vectors but maybe you can see more from

1419
01:26:31,540 --> 01:26:35,180
the point of view i don't know

1420
01:26:35,200 --> 01:26:37,220
maybe you can come up with new

1421
01:26:37,220 --> 01:26:40,060
explanation of primal and dual using

1422
01:26:40,080 --> 01:26:44,930
from the support vector point machine point of view that would be very good

1423
01:26:44,950 --> 01:26:50,040
but i don't have a good is about that right now

1424
01:26:50,080 --> 01:26:52,830
OK so now this

1425
01:26:52,850 --> 01:26:56,890
to say OK this is the lagrangian do

1426
01:26:57,400 --> 01:27:03,770
so the next thing we will have to do is to simplify the problem

1427
01:27:04,810 --> 01:27:07,510
so how to simplify it is

1428
01:27:07,640 --> 01:27:15,370
but this is looks like the complicated optimisation problem maximize user minimize so that we

1429
01:27:15,370 --> 01:27:17,890
can do is to assume that point to

1430
01:27:17,930 --> 01:27:24,200
think about the situation where you fixed so to check if is fixed then

1431
01:27:25,180 --> 01:27:29,410
how to solve the minimisation problem inside these big processes

1432
01:27:29,490 --> 01:27:33,990
so this is sort of is fixed

1433
01:27:34,040 --> 01:27:35,060
is fixed

1434
01:27:35,060 --> 01:27:37,270
the immediate what we can see is

1435
01:27:37,290 --> 01:27:42,600
even some additional by y is not equal to zero and we can be we

1436
01:27:42,600 --> 01:27:46,010
can make this minimisation to go to minus infinity

1437
01:27:46,160 --> 01:27:49,740
well how to see that

1438
01:27:49,830 --> 01:27:52,410
so you can see you

1439
01:27:52,410 --> 01:27:53,930
i alpha i y

1440
01:27:53,950 --> 01:27:56,100
time to be well so you can

1441
01:27:56,120 --> 01:28:02,470
you can for the out so the becomes beethoven's some measure of my y i

1442
01:28:02,700 --> 01:28:05,720
so yes i mentioned by why y is nonzero

1443
01:28:05,740 --> 01:28:10,540
and are minimizing with respect to w and b so you just want be too

1444
01:28:10,540 --> 01:28:16,340
you look process or minus infinity depending on whether this is positive or negative well

1445
01:28:16,340 --> 01:28:21,560
if it is positive they just move b to plus infinity then

1446
01:28:21,560 --> 01:28:25,580
this minus the you you get minus in here

1447
01:28:27,240 --> 01:28:34,770
so listen this minimisation problem with respect to w b can be rewritten as is

1448
01:28:35,290 --> 01:28:40,850
so in situations so the first one is evil is why transports off

1449
01:28:40,870 --> 01:28:45,990
this image is actually wages whatsoever is not is not zero length

1450
01:28:46,040 --> 01:28:52,720
this minimum has a minus infinity but on the other hand if want impose optimisation

1451
01:28:53,810 --> 01:28:56,970
then we don't need to write this terms we

1452
01:28:56,990 --> 01:28:58,620
related to be

1453
01:28:58,620 --> 01:29:02,490
if you you have these some asian to be zero then you can remove this

1454
01:29:02,490 --> 01:29:04,370
term so we don't have

1455
01:29:04,450 --> 01:29:09,200
we don't have to be here we only have to minimize with respect to w

1456
01:29:09,330 --> 01:29:14,330
so we simplify do a little bit

1457
01:29:14,350 --> 01:29:21,790
i really think it was more complicated in you so not so this is the

1458
01:29:21,790 --> 01:29:25,140
problem we have so far

1459
01:29:25,470 --> 01:29:32,240
then that we took the second the situation where the white transfer is zero

1460
01:29:32,530 --> 01:29:38,560
there's no we are going to minimize with respect to w this function so that

1461
01:29:38,580 --> 01:29:40,260
so this policy right now

1462
01:29:40,260 --> 01:29:42,140
OK so now by fixed

1463
01:29:42,160 --> 01:29:44,370
so that is the only variable

1464
01:29:44,390 --> 01:29:49,700
it is situated the convex function that

1465
01:29:49,720 --> 01:29:54,810
so you know what the convex function is or street convex function is

1466
01:29:55,640 --> 01:30:02,010
when you this one is strictly convex because of this country to that transport stop

1467
01:30:02,010 --> 01:30:11,970
so from optimisation and we know that the optimum happens when the partial derivative with

1468
01:30:11,970 --> 01:30:14,540
respect to w easier

1469
01:30:14,540 --> 01:30:16,260
so we do this

1470
01:30:16,260 --> 01:30:17,180
so there

1471
01:30:17,180 --> 01:30:18,890
so we do

1472
01:30:18,890 --> 01:30:19,540
so for the

1473
01:30:20,120 --> 01:30:26,450
that has to stop that's actually that and then if only we should remove them

1474
01:30:27,600 --> 01:30:29,810
we have w

1475
01:30:29,850 --> 01:30:32,970
is equal to the linear combination of

1476
01:30:33,430 --> 01:30:34,950
training instances

1477
01:30:34,970 --> 01:30:40,450
so now we have these so that means give up his face

1478
01:30:40,450 --> 01:30:43,160
and what is most about is it

1479
01:30:43,760 --> 01:30:46,240
these optimized that must be

1480
01:30:46,270 --> 01:30:51,240
the linear combination of training data using these up

1481
01:30:51,260 --> 01:30:57,350
so we can further simplify our dual problem

1482
01:30:57,370 --> 01:31:08,060
so now we have a formal that in terms of the

1483
01:31:08,330 --> 01:31:14,850
so so we can we not represent that community in combination so you have

1484
01:31:14,890 --> 01:31:17,930
we want to remove remove that

1485
01:31:17,950 --> 01:31:22,580
the reason is we to simplify these so we know we hope that we don't

1486
01:31:22,580 --> 01:31:30,220
have this minimisation so we want to remove variables that could be in this formulation

1487
01:31:30,240 --> 01:31:33,080
so we put stop there too

1488
01:31:33,080 --> 01:31:34,790
this objective function

1489
01:31:34,930 --> 01:31:38,350
so we have to do something creation

1490
01:31:38,370 --> 01:31:41,180
so this checked that transports the first

1491
01:31:41,180 --> 01:31:49,200
so now is about these linear combinations transposed for these linear combinations will say this

1492
01:31:49,200 --> 01:31:51,600
is something you should i fail

1493
01:31:51,700 --> 01:31:57,830
x i transpose exchange with this is this is already very close to the project

1494
01:31:57,850 --> 01:31:59,950
in terms of our due problem

1495
01:31:59,950 --> 01:32:04,840
exactly k clusters if my stopping criteria is stop when the distance when all the

1496
01:32:04,840 --> 01:32:07,710
distance is now bigger than

1497
01:32:07,730 --> 01:32:09,140
the get rich miss

1498
01:32:09,150 --> 01:32:11,370
i mean i can rearrange the points to get any

1499
01:32:11,380 --> 01:32:16,070
clustering by just saying i stop when the distance the minimum distance left it up

1500
01:32:16,070 --> 01:32:17,110
and i get

1501
01:32:17,210 --> 01:32:22,520
consistency but is not scale invariant because this are is fixed so we find blow

1502
01:32:22,520 --> 01:32:25,850
up my that it will fracture into more clusters

1503
01:32:26,820 --> 01:32:27,890
if my

1504
01:32:27,920 --> 01:32:30,860
stopping criterion is some scaling things

1505
01:32:30,860 --> 01:32:34,600
stop when i get to the distance alpha times the distance

1506
01:32:34,610 --> 01:32:40,340
then it will be scale invariant because if i multiply by scale this will take

1507
01:32:40,340 --> 01:32:41,300
care of it

1508
01:32:43,110 --> 01:32:49,360
i'm going to lose their consistency so any pair of them is mutually satisfied all

1509
01:32:49,380 --> 01:32:51,640
reasonable but they can be

1510
01:32:52,520 --> 01:32:55,670
three satisfied simultaneously

1511
01:33:04,570 --> 01:33:10,930
talking about the clustering algorithm is supposed to look at examiner that and decide which

1512
01:33:10,930 --> 01:33:13,980
is the correct number of clusters and then cluster

1513
01:33:14,010 --> 01:33:15,860
into this number of clusters

1514
01:33:23,360 --> 01:33:29,600
right it may say well i it returns everything in a single class or every

1515
01:33:29,600 --> 01:33:35,920
point in singapore on that answers my question about this cluster structure

1516
01:33:37,620 --> 01:33:40,800
those requirements are pretty harsh as we saw

1517
01:33:40,810 --> 01:33:44,460
OK so where do we go from here so i think one of the big

1518
01:33:44,470 --> 01:33:48,060
mistakes in the community i don't know how many people were looking but people and

1519
01:33:48,060 --> 01:33:56,890
it is that people had this talk of climate NIPS was very widely

1520
01:33:56,910 --> 01:34:01,610
cited and people don't remember what exactly did as well but they

1521
01:34:01,620 --> 01:34:05,540
conclusion is there's no way to do it yourself clustering because there is this impossibility

1522
01:34:06,380 --> 01:34:07,780
and so on

1523
01:34:07,780 --> 01:34:09,880
let's forget about it there's no way to do here

1524
01:34:09,890 --> 01:34:14,060
well i'm trying to claim that is that is very it's very nice results but

1525
01:34:14,060 --> 01:34:19,540
it has limited application which says that this choice of three axioms was misfortunate of

1526
01:34:19,540 --> 01:34:22,170
fortunate in the sense that it led to a contradiction

1527
01:34:22,180 --> 01:34:27,580
but it doesn't mean that you cannot do any theory so

1528
01:34:27,580 --> 01:34:31,580
what would be the next step what can we do

1529
01:34:31,600 --> 01:34:34,460
so what

1530
01:34:34,480 --> 01:34:37,270
i would like in an ideal theory is to have

1531
01:34:37,310 --> 01:34:44,010
two types of requirements one type of axioms and axiom should be a requirement that

1532
01:34:44,050 --> 01:34:48,290
any clustering method satisfies the so

1533
01:34:48,300 --> 01:34:51,240
in particular the clan

1534
01:34:51,300 --> 01:34:57,770
axioms are not because each of them we know is falsified by many good clustering

1535
01:34:57,780 --> 01:35:00,400
we went whenever he saw an example

1536
01:35:00,420 --> 01:35:01,590
that's too

1537
01:35:01,600 --> 01:35:04,580
properties are satisfied by some clustering algorithms

1538
01:35:05,790 --> 01:35:09,610
inconsistency we know that this clustering algorithm fail

1539
01:35:09,620 --> 01:35:12,060
the third requirement

1540
01:35:12,060 --> 01:35:18,580
so each of those requirements is found by some natural clustering algorithm so if i

1541
01:35:18,580 --> 01:35:20,600
gave you the axioms of geometry

1542
01:35:20,700 --> 01:35:26,400
and then i will tell you all these axioms of geometry but some lines and

1543
01:35:26,400 --> 01:35:32,460
points satisfies axioms but some other lines and points don't satisfy the accent so you

1544
01:35:32,460 --> 01:35:33,780
want to call them axioms

1545
01:35:33,870 --> 01:35:39,080
y actions you want to do that by nature he wanted to be something that

1546
01:35:39,080 --> 01:35:43,240
says but by all the objects trying to describe i can give you axioms of

1547
01:35:43,240 --> 01:35:47,210
group theory and tell you OK these are the absence of group theory but some

1548
01:35:47,210 --> 01:35:50,020
groups satisfy them and some groups don't

1549
01:35:50,040 --> 01:35:54,020
that is contradictory to the nature accent so

1550
01:35:54,030 --> 01:35:58,180
when i want access one something that any clustering method was satisfies and we know

1551
01:35:58,180 --> 01:36:02,340
that i'm inclined to themselves us that his actions are not

1552
01:36:02,360 --> 01:36:05,440
like that because each of them is failed by

1553
01:36:05,470 --> 01:36:08,530
the same clustering as sets for the other two

1554
01:36:08,600 --> 01:36:13,880
and the other requirement is even more difficult to follow

1555
01:36:13,890 --> 01:36:17,940
well i want to any function that is clearly not a clustering will fail to

1556
01:36:17,940 --> 01:36:22,160
satisfy this one of the axioms because i could be relaxed i can tell you

1557
01:36:22,160 --> 01:36:25,620
maxims is that there what you should satisfy

1558
01:36:25,620 --> 01:36:28,560
is there a requirement that one plus one equals two

1559
01:36:28,610 --> 01:36:32,860
so now any function you give me which satisfy the axioms and we all have

1560
01:36:32,880 --> 01:36:37,340
but it doesn't distinguish good functions from that functions

1561
01:36:37,350 --> 01:36:38,840
so we want to

1562
01:36:38,860 --> 01:36:45,290
mutually satisfied the requirements set of axioms and it may be difficult to two two-way

1563
01:36:45,300 --> 01:36:49,860
formerly because what do i mean by clustering that is obviously not

1564
01:36:49,880 --> 01:36:53,490
a clustering function so it's not going to be an easy task

1565
01:36:54,590 --> 01:36:55,880
on top of it

1566
01:36:55,890 --> 01:37:01,110
i would call the kind of axioms that climate is called properties rather than access

1567
01:37:01,120 --> 01:37:03,070
so i have properties

1568
01:37:03,070 --> 01:37:09,230
which hopefully will distinguish between different clustering paradigms so i can say here is the

1569
01:37:09,240 --> 01:37:13,940
clustering paradigms that is scale invariant he was clustering paradigm

1570
01:37:13,970 --> 01:37:19,020
that is rich in the clustering paradigm that satisfy the property so now we have

1571
01:37:19,020 --> 01:37:21,460
a user that wants to apply

1572
01:37:21,470 --> 01:37:27,150
clustering trees that could look at the list of properties and choose which properties i

1573
01:37:27,150 --> 01:37:34,820
you want me you

1574
01:37:42,640 --> 01:37:47,450
one of the

1575
01:38:27,540 --> 01:38:30,390
so you get the picture in the

1576
01:38:31,920 --> 01:38:33,110
is this

1577
01:38:33,130 --> 01:38:34,300
very low

1578
01:40:19,120 --> 01:40:25,090
i think

1579
01:40:38,710 --> 01:40:49,280
you know

1580
01:41:01,070 --> 01:41:05,660
one one

1581
01:41:26,040 --> 01:41:29,470
while the

1582
01:41:29,480 --> 01:41:35,730
you not

1583
01:42:15,450 --> 01:42:22,260
in nineteen ninety eight

1584
01:42:22,260 --> 01:42:24,720
and then you can give them to some other technique

1585
01:42:24,720 --> 01:42:26,510
which may be slower but better

1586
01:42:26,530 --> 01:42:29,600
and i can tell you which was you really want

1587
01:42:29,700 --> 01:42:33,200
but at least you can get it down from a billion documents two hundred thousand

1588
01:42:34,120 --> 01:42:37,300
in a few machine instructions

1589
01:42:37,340 --> 01:42:40,640
but i should emphasise only if you're using documents indices

1590
01:42:40,640 --> 01:42:45,340
two indexing on the document that makes much more sense if using images

1591
01:42:46,590 --> 01:42:50,550
so people at MIT have tried this images and it works pretty well

1592
01:42:50,570 --> 01:42:54,260
these a nice work much better than things like locality sensitive hashing which was the

1593
01:42:54,280 --> 01:42:57,870
first thing before this

1594
01:42:57,930 --> 01:43:03,340
unfortunately the people at MIT very smart and they found another method that uses this

1595
01:43:03,340 --> 01:43:07,470
idea of going to address space but works even better than using the networks and

1596
01:43:07,490 --> 01:43:12,300
we in our work better to compete with that

1597
01:43:12,340 --> 01:43:16,890
so the people of a wise from fergusson antonio torralba

1598
01:43:16,910 --> 01:43:20,620
and they got a paper i think in the last minutes about this other method

1599
01:43:20,620 --> 01:43:24,640
some spectral method for getting these codes and spectral methods used work even better than

1600
01:43:24,640 --> 01:43:29,050
our method

1601
01:43:29,050 --> 01:43:32,530
we're gonna make it we can figure out how to do better

1602
01:43:32,570 --> 01:43:36,870
the shortlist found this way we've only tried it for twenty bit codes one million

1603
01:43:36,870 --> 01:43:39,820
documents and for many documents

1604
01:43:39,910 --> 01:43:41,620
and it works very well

1605
01:43:44,890 --> 01:43:48,410
OK now i'm going to something else

1606
01:43:48,470 --> 01:43:53,160
what i want to know is about what kind of generative models we really want

1607
01:43:53,160 --> 01:43:53,820
so you know

1608
01:43:53,840 --> 01:43:55,860
talked about learning generative models

1609
01:43:55,870 --> 01:44:00,950
and we have assumed that the generative model is the sigmoid belief nett

1610
01:44:00,970 --> 01:44:03,220
after we learn many layers

1611
01:44:03,280 --> 01:44:06,320
and the way to the top is an infinite sigmoid belief nett otherwise known as

1612
01:44:06,320 --> 01:44:10,200
restricted boltzmann machine

1613
01:44:10,260 --> 01:44:14,140
but you know do we really want that kind of model may i mean obviously

1614
01:44:14,160 --> 01:44:16,590
want to be able to other types of variables

1615
01:44:16,600 --> 01:44:19,970
but maybe there's something else we want to try and convince you the something else

1616
01:44:19,970 --> 01:44:22,050
we really do want generative model

1617
01:44:22,090 --> 01:44:25,550
the makes the gentleman more complicated but it's very useful

1618
01:44:25,600 --> 01:44:29,870
so let's suppose that you want to generative model i a square and i tell

1619
01:44:29,870 --> 01:44:33,320
you as part this and you can reduce the square in that

1620
01:44:33,370 --> 01:44:37,590
and the generative model has several layers and is one layer consists of things like

1621
01:44:37,590 --> 01:44:39,030
edges and corners

1622
01:44:39,070 --> 01:44:43,170
so i need to get from the level of description this this the square and

1623
01:44:43,170 --> 01:44:45,160
how big and what orientation one

1624
01:44:45,160 --> 01:44:49,090
to level of description tells me were all the pieces

1625
01:44:49,100 --> 01:44:51,970
well one thing i could do it is

1626
01:44:52,010 --> 01:44:55,600
i have very accurate

1627
01:44:55,620 --> 01:44:57,700
top down information

1628
01:44:57,700 --> 01:45:01,820
the given this computes exactly where all the different pieces should be

1629
01:45:01,890 --> 01:45:03,840
but it needs to be really accurate

1630
01:45:03,840 --> 01:45:07,410
otherwise i'll get square with the corners quite join up

1631
01:45:09,030 --> 01:45:12,570
i could generate some redundant stuff like this where this is meant to be a

1632
01:45:12,570 --> 01:45:17,940
distribution over whether samples from a distribution that web about whether editors this is samples

1633
01:45:17,940 --> 01:45:20,030
from distribution backwards

1634
01:45:20,050 --> 01:45:21,700
but i could also known

1635
01:45:21,740 --> 01:45:24,890
these things have to join up

1636
01:45:24,910 --> 01:45:27,860
you know the edge has to end article

1637
01:45:27,870 --> 01:45:30,410
so now given these distributions

1638
01:45:30,430 --> 01:45:31,950
i can do some cleanup

1639
01:45:31,970 --> 01:45:35,300
and get i tracker square like this

1640
01:45:35,360 --> 01:45:38,450
and i'm going to argue this is a much better way to do business

1641
01:45:38,450 --> 01:45:41,490
most the rest of the show is going to be about trying to show is

1642
01:45:41,490 --> 01:45:43,240
the best way to do business

1643
01:45:43,260 --> 01:45:48,680
my analogy is if i'm an office and i want to hold bunches soldiers to

1644
01:45:48,680 --> 01:45:50,680
stand in an ice rectangle

1645
01:45:50,700 --> 01:45:54,360
i could get my GPS i could tell each soldier what GPS coordinates able to

1646
01:45:54,360 --> 01:45:56,870
stand up up and the stand

1647
01:45:56,870 --> 01:45:58,930
unless i'm really really accurate

1648
01:45:58,990 --> 01:46:01,660
it's going to be a pretty ragged rectangle

1649
01:46:01,720 --> 01:46:05,780
it will be erected rectangle just in the right place exactly the right place brother

1650
01:46:06,550 --> 01:46:11,050
alternatively if i'm more worried about it being nice rectangle and being exactly the right

1651
01:46:11,050 --> 01:46:14,470
place i can tell the soldiers sort of stand roughly here

1652
01:46:14,510 --> 01:46:16,780
and i can tell them all to do this kind of business and that far

1653
01:46:16,780 --> 01:46:18,070
away from the neighbour

1654
01:46:18,120 --> 01:46:21,450
so i set up a markov random field between soldiers

1655
01:46:21,660 --> 01:46:23,700
and i get a nice rectangle

1656
01:46:23,760 --> 01:46:30,320
i don't think the soldiers know their markov random field but that's what they're

1657
01:46:30,320 --> 01:46:33,410
so we can try and do the same with a generative models

1658
01:46:34,780 --> 01:46:37,530
the first thing to try and do is get the

1659
01:46:37,530 --> 01:46:39,280
the hidden units

1660
01:46:39,320 --> 01:46:44,320
two just affect the is visible units with the talk on connections but also have

1661
01:46:44,320 --> 01:46:45,820
lateral interactions

1662
01:46:45,870 --> 01:46:48,350
and then the next thing you do which is more exciting is to get the

1663
01:46:48,350 --> 01:46:51,390
hidden units to directly affect the latter interactions

1664
01:46:51,410 --> 01:46:54,910
so we need to specify the markov random field as opposed to just and is

1665
01:46:54,910 --> 01:46:57,200
unbiased is a markov random field

1666
01:46:58,820 --> 01:47:03,360
it's still pretty easy to train this thing not quite as easy as the standard

1667
01:47:03,360 --> 01:47:04,570
restricted boltzmann machines

1668
01:47:04,590 --> 01:47:06,860
what we're going to do is we're going to

1669
01:47:06,870 --> 01:47:08,840
take the visible units

1670
01:47:08,840 --> 01:47:12,820
this was all logistic units activity in unit

1671
01:47:12,860 --> 01:47:15,620
we can get some binary state here

1672
01:47:15,660 --> 01:47:19,340
it's important to have noise you see contrast real values

1673
01:47:19,360 --> 01:47:22,430
and then holding the binary state fixed

1674
01:47:22,470 --> 01:47:24,470
it's going to right top down input

1675
01:47:24,490 --> 01:47:29,530
to these visible units as this MRF settlers who settled

1676
01:47:29,550 --> 01:47:30,510
a bit

1677
01:47:33,320 --> 01:47:36,840
i will use mean field down here is there are

1678
01:47:36,840 --> 01:47:38,550
and we get a reconstruction

1679
01:47:38,570 --> 01:47:43,140
and then migrated news again

1680
01:47:43,160 --> 01:47:44,720
this is non trivial

1681
01:47:44,720 --> 01:47:49,340
if you want to use stochastic units because you don't get the nice

1682
01:47:50,470 --> 01:47:54,200
division and you can be all these and update all of those it's everybody's talking

1683
01:47:54,200 --> 01:47:58,090
to everybody here you have to really up to one using the next generation song

1684
01:47:58,090 --> 01:48:01,120
on or you can use mean field which is after all a little bit in

1685
01:48:02,660 --> 01:48:04,320
so that's what we do

1686
01:48:04,340 --> 01:48:07,700
then the learning signal for these bottom-up connections is just the same as it was

1687
01:48:07,700 --> 01:48:12,660
before the learning signal for these connections is just the difference in the correlation here

1688
01:48:12,680 --> 01:48:13,990
and here

1689
01:48:14,840 --> 01:48:20,740
and that will tell us how to update these lateral interactions

1690
01:48:24,030 --> 01:48:27,030
that's what you ought to do if you do the something properly this is what

1691
01:48:27,030 --> 01:48:29,840
we actually do because it's quicker and you have to download it it to prevent

1692
01:48:31,240 --> 01:48:32,120
so you say

1693
01:48:32,140 --> 01:48:36,240
as your settling down the new value the new real value between zero and one

1694
01:48:36,320 --> 01:48:39,780
is lands until value plus one minus lambda times what the new value ought to

1695
01:48:39,780 --> 01:48:43,120
be given the input comes from the neighbours and from above

1696
01:48:43,120 --> 01:48:51,890
so simon osindero tried this on patches of natural images

1697
01:48:51,950 --> 01:48:54,430
he was using twenty by twenty patches

1698
01:48:54,430 --> 01:48:58,860
he was using garrison units to model the pixel intensities

1699
01:48:58,910 --> 01:49:01,990
except that this data is already being wind

1700
01:49:02,050 --> 01:49:07,050
so because the data already been morning and we didn't need pairwise interactions here

1701
01:49:07,100 --> 01:49:09,390
it's already whitened data

1702
01:49:09,410 --> 01:49:12,660
so there's no sort of power structure

1703
01:49:12,680 --> 01:49:16,640
so the way you learn it is you learn it with no lateral interactions among

1704
01:49:16,640 --> 01:49:18,360
the hiddens

1705
01:49:18,410 --> 01:49:21,220
because the semi restricted boltzmann machines

1706
01:49:21,220 --> 01:49:24,220
particular for maximal scheme

1707
01:49:24,980 --> 01:49:28,720
i don't know if you've ever worked together

1708
01:49:30,930 --> 01:49:36,580
a lot of people coming two six of schema was converted to make it already

1709
01:49:36,580 --> 01:49:38,180
are all wonderful

1710
01:49:38,230 --> 01:49:39,750
except semantics

1711
01:49:39,770 --> 01:49:42,000
really what you want

1712
01:49:42,020 --> 01:49:44,300
a little semantics

1713
01:49:44,950 --> 01:49:46,610
one of the

1714
01:49:48,110 --> 01:49:48,630
all o

1715
01:49:48,680 --> 01:49:52,330
we are step we can expect to get from this

1716
01:49:54,520 --> 01:49:55,910
what happens in the region

1717
01:49:56,720 --> 01:50:00,700
some better than others to help do this already in XML schema and try to

1718
01:50:00,700 --> 01:50:03,700
generate some sort of our from

1719
01:50:03,710 --> 01:50:11,580
so one example that were was that all of the whole world

1720
01:50:13,600 --> 01:50:17,570
there's this field of semantic web services and a lot of these things look what

1721
01:50:17,570 --> 01:50:24,250
love is happening is people looking at the XML formats that people industry generate this

1722
01:50:24,250 --> 01:50:27,620
people in history who actually build schools

1723
01:50:27,640 --> 01:50:28,870
and this

1724
01:50:28,890 --> 01:50:30,670
we get some of his

1725
01:50:30,690 --> 01:50:34,900
we can predict some sort of versions and try to convince people that this is

1726
01:50:35,890 --> 01:50:39,580
so the biggest of which is great because it's really simple

1727
01:50:39,680 --> 01:50:42,710
the reason

1728
01:50:43,610 --> 01:50:45,710
which this

1729
01:50:49,190 --> 01:50:53,480
these are security a certain

1730
01:50:57,340 --> 01:51:01,700
on one

1731
01:51:02,720 --> 01:51:05,170
as of june

1732
01:51:05,180 --> 01:51:09,670
one to the destruction so it's pretty obvious one specified

1733
01:51:09,680 --> 01:51:11,150
there you go

1734
01:51:11,170 --> 01:51:15,440
reliable messaging and some form of security or something else

1735
01:51:18,250 --> 01:51:22,370
there's a lot of stuff

1736
01:51:22,390 --> 01:51:26,800
and semantic formal semantics of

1737
01:51:26,810 --> 01:51:27,860
for example

1738
01:51:30,890 --> 01:51:36,550
i suspect around the distribution mechanism it really is best to find a little tiny

1739
01:51:36,550 --> 01:51:38,830
bit of a logical

1740
01:51:41,120 --> 01:51:43,520
here is a very simple example

1741
01:51:43,540 --> 01:51:48,010
this is one of the

1742
01:51:52,300 --> 01:51:54,170
a series of

1743
01:51:54,190 --> 01:51:58,710
this is the all one one

1744
01:51:58,720 --> 01:52:06,830
they were

1745
01:52:06,840 --> 01:52:13,310
and this is what you want to

1746
01:52:13,340 --> 01:52:15,000
sounds good

1747
01:52:19,660 --> 01:52:24,870
presentation of policy of

1748
01:52:27,500 --> 01:52:29,250
twenty eight

1749
01:52:29,260 --> 01:52:34,940
here is where you have to get some joy it's not just

1750
01:52:37,850 --> 01:52:41,550
he is

1751
01:52:41,650 --> 01:52:44,300
the disjunction of these

1752
01:52:44,320 --> 01:52:47,620
we can do actually seems like a sensible way to go

1753
01:52:48,320 --> 01:52:53,380
there is in fact contrary to my understanding to a hundred times two we can

1754
01:52:54,420 --> 01:52:57,520
the first

1755
01:53:01,880 --> 01:53:03,510
has names for things

1756
01:53:04,360 --> 01:53:10,860
significant gains in the area of peru you know you

1757
01:53:10,880 --> 01:53:13,900
thing here

1758
01:53:13,920 --> 01:53:16,240
we're going to

1759
01:53:16,460 --> 01:53:19,600
all right

1760
01:53:20,410 --> 01:53:26,710
something instantiation relations between policy these processes

1761
01:53:26,730 --> 01:53:29,040
and if fact managed to

1762
01:53:29,050 --> 01:53:31,090
get him to dig up

1763
01:53:31,510 --> 01:53:34,570
his initial sketch before

1764
01:53:34,590 --> 01:53:38,670
o seventy four

1765
01:53:38,720 --> 01:53:42,950
can see

1766
01:53:43,280 --> 01:53:47,210
this is not the only that it's reasonable for what he was trying to do

1767
01:53:47,210 --> 01:53:51,170
i guess so we have the notion of an operator for search we have these

1768
01:53:51,170 --> 01:53:54,050
three contracts with all

1769
01:53:56,130 --> 01:54:01,630
operators and then within the operator for

1770
01:54:02,540 --> 01:54:05,610
all in exactly one

1771
01:54:05,660 --> 01:54:09,710
one of the

1772
01:54:11,760 --> 01:54:15,090
really really do

1773
01:54:15,100 --> 01:54:16,870
it doesn't

1774
01:54:17,080 --> 01:54:23,090
he manages to get any sort of syntax checking or or or guidance anything

1775
01:54:23,720 --> 01:54:30,190
so far

1776
01:54:30,200 --> 01:54:33,860
i have constraints we managed to the children

1777
01:54:33,880 --> 01:54:38,600
it's not actually constrained instances of that shape that

1778
01:54:38,620 --> 01:54:40,510
very hard

1779
01:54:40,540 --> 01:54:42,220
this is very

1780
01:54:44,500 --> 01:54:46,190
converting x models

1781
01:54:50,400 --> 01:54:52,320
there's a better way

1782
01:55:00,680 --> 01:55:04,150
one of these

1783
01:55:04,700 --> 01:55:08,940
so these are the same things that use this template

1784
01:55:09,000 --> 01:55:10,710
reliable the

1785
01:55:13,370 --> 01:55:15,770
all these

1786
01:55:15,870 --> 01:55:21,840
this is one of any security and uses some form

1787
01:55:21,890 --> 01:55:24,620
correction or other times

1788
01:55:24,970 --> 01:55:31,510
the structure we can take this and instead including the syntax of the schema we

1789
01:55:31,510 --> 01:55:34,330
can map the language over


1
00:00:00,000 --> 00:00:05,180
always cheat when they think that when they play with dice

2
00:00:05,200 --> 00:00:08,140
promise it in zero to be team

3
00:00:08,140 --> 00:00:12,430
so basically like the point when he would usually at some point get frustrated and

4
00:00:12,430 --> 00:00:16,610
say well you cheating

5
00:00:16,660 --> 00:00:17,810
said but

6
00:00:17,820 --> 00:00:22,350
yes getting the right getting the prior right is not quite so easy

7
00:00:22,360 --> 00:00:23,990
but out of

8
00:00:26,710 --> 00:00:28,960
they were

9
00:00:29,000 --> 00:00:32,370
in exactly

10
00:00:33,390 --> 00:00:37,350
and while there is only really one way to address this

11
00:00:37,360 --> 00:00:40,430
you just measure more

12
00:00:42,420 --> 00:00:46,300
that's the end of the day what you have to do what you can do

13
00:00:46,300 --> 00:00:47,520
so is

14
00:00:47,540 --> 00:00:51,650
you can get uniform convergence statement saying well

15
00:00:51,710 --> 00:00:56,840
actually with high probability the likelihood that getting cannot be too too far off from

16
00:00:56,850 --> 00:00:59,180
what it should be

17
00:00:59,200 --> 00:01:03,160
you can get back up statements reasonably easily

18
00:01:03,180 --> 00:01:06,060
and this might influence the choice of prior

19
00:01:06,160 --> 00:01:10,820
i think that when you might want to really really small that you say

20
00:01:10,990 --> 00:01:13,570
in this case

21
00:01:13,580 --> 00:01:16,620
was the expression can change the law

22
00:01:16,680 --> 00:01:20,840
if i get the general of it wrong

23
00:01:24,290 --> 00:01:25,100
i mean

24
00:01:25,110 --> 00:01:28,240
this is essentially problem that he will not be able to

25
00:01:28,300 --> 00:01:29,870
so exactly

26
00:01:29,890 --> 00:01:32,830
so for instance if you measuring wind speed

27
00:01:32,870 --> 00:01:37,120
and you know that in a certain area usually have wind speed of ten kilometres

28
00:01:37,120 --> 00:01:38,780
per hour

29
00:01:38,800 --> 00:01:42,710
then you should of course that the prime people serve many times before you would

30
00:01:42,710 --> 00:01:44,320
probably because rather

31
00:01:44,340 --> 00:01:49,030
strong prior

32
00:01:49,040 --> 00:01:51,940
one way of addressing to some extent is

33
00:01:51,960 --> 00:01:55,620
by doing something like cross validation but that

34
00:01:55,620 --> 00:01:58,060
kind of defeats the purpose of prime

35
00:01:58,110 --> 00:02:00,170
people have done

36
00:02:05,350 --> 00:02:06,330
and and then

37
00:02:06,350 --> 00:02:09,890
you have to question how do you say hyperprior

38
00:02:09,920 --> 00:02:13,920
you can then have a heart-to-heart prior make it more and more and more

39
00:02:16,490 --> 00:02:18,080
OK so

40
00:02:18,110 --> 00:02:19,440
this was

41
00:02:19,470 --> 00:02:20,590
the first unit

42
00:02:20,590 --> 00:02:23,190
and i know what looks like a run out of time

43
00:02:23,210 --> 00:02:24,140
i think l

44
00:02:24,140 --> 00:02:26,580
just briefly mention what can do

45
00:02:26,620 --> 00:02:28,180
in the afternoon

46
00:02:28,200 --> 00:02:30,820
so that that's

47
00:02:30,860 --> 00:02:32,810
the partition

48
00:02:37,200 --> 00:02:39,420
we shall prove the maximum entropy

49
00:02:39,440 --> 00:02:42,580
you what to stay on rather than half of the after

50
00:02:42,590 --> 00:02:46,280
so that was

51
00:02:46,280 --> 00:02:48,450
that is

52
00:02:48,470 --> 00:02:55,600
can estimate of this so all i done to the morning now was really classical

53
00:02:55,600 --> 00:02:58,500
statistical estimation theory

54
00:02:58,520 --> 00:03:03,340
there wasn't much nonparametric to it except for the fact that we have this fix

55
00:03:03,350 --> 00:03:05,340
lurking around which

56
00:03:05,360 --> 00:03:09,300
i didn't we say whether it's finite dimensional not in fact if you want to

57
00:03:09,300 --> 00:03:14,530
do nice things you have to pick for fixed to be really complicated sophisticated and

58
00:03:14,530 --> 00:03:16,040
quite often

59
00:03:16,060 --> 00:03:17,680
infinite dimensional

60
00:03:17,740 --> 00:03:19,980
but other than that

61
00:03:20,020 --> 00:03:24,730
i mean this is really basic statistics it's quite powerful and quite often you might

62
00:03:24,730 --> 00:03:26,100
want to use that

63
00:03:26,110 --> 00:03:27,330
the first k

64
00:03:29,240 --> 00:03:30,380
we want to again

65
00:03:30,380 --> 00:03:36,340
and i'll be just explaining a little bit i get the maximum entropy estimate

66
00:03:36,550 --> 00:03:40,930
subject to

67
00:03:40,940 --> 00:03:43,380
the integral

68
00:03:43,480 --> 00:03:44,640
of course

69
00:03:44,690 --> 00:03:47,150
p of x

70
00:03:47,180 --> 00:03:49,960
we have maximize with distribution

71
00:03:51,350 --> 00:03:52,580
he calls

72
00:03:53,560 --> 00:03:58,740
going to pick an equality constraint is that the math turns out to be slightly

73
00:03:59,820 --> 00:04:04,940
otherwise we'll have to take which constraints are active or not and all that

74
00:04:08,380 --> 00:04:10,630
now how can we solve this

75
00:04:10,720 --> 00:04:14,800
one way is first is to set up lagrange function

76
00:04:14,840 --> 00:04:16,610
so l

77
00:04:16,650 --> 00:04:17,980
of p

78
00:04:18,000 --> 00:04:21,370
and lambda

79
00:04:21,380 --> 00:04:24,450
this is the constrained optimization problem

80
00:04:24,500 --> 00:04:26,050
so i get

81
00:04:26,050 --> 00:04:27,480
while the integral

82
00:04:27,500 --> 00:04:28,800
of minus

83
00:04:28,850 --> 00:04:32,160
log of p of x

84
00:04:32,250 --> 00:04:35,880
and your x

85
00:04:45,500 --> 00:04:46,890
and here we have

86
00:04:48,060 --> 00:04:50,690
of forth ics

87
00:04:51,770 --> 00:04:53,290
p x

88
00:04:56,340 --> 00:05:00,770
OK that one is me

89
00:05:00,790 --> 00:05:04,000
but we have a whole bunch of other constraints

90
00:05:04,710 --> 00:05:06,460
we also know

91
00:05:06,470 --> 00:05:07,860
that the integral

92
00:05:07,900 --> 00:05:09,680
of p of x

93
00:05:10,630 --> 00:05:13,790
equals one

94
00:05:13,800 --> 00:05:15,130
so we get

95
00:05:17,810 --> 00:05:21,340
it's called astronomer energy for reason

96
00:05:21,350 --> 00:05:23,220
g times

97
00:05:23,350 --> 00:05:25,490
g here

98
00:05:26,790 --> 00:05:29,140
of p of x

99
00:05:29,150 --> 00:05:32,610
x minus one

100
00:05:32,650 --> 00:05:36,070
and furthermore we know that the density is nonnegative

101
00:05:37,140 --> 00:05:38,310
here x

102
00:05:38,330 --> 00:05:43,590
is critical in sierra rawlings

103
00:05:43,600 --> 00:05:45,790
and now this

104
00:05:45,840 --> 00:05:49,050
actually will lead to a lagrange multiplier which is

105
00:05:49,090 --> 00:05:50,350
the function

106
00:05:50,360 --> 00:05:52,200
so we get

107
00:05:52,230 --> 00:05:54,320
plus the integral

108
00:05:54,320 --> 00:05:58,810
and for r the sum of the squared the match

109
00:05:58,820 --> 00:06:01,400
you have something

110
00:06:01,410 --> 00:06:06,750
it be different so you have the camera case to ground metric symmetrical again in

111
00:06:06,750 --> 00:06:08,170
metric which is

112
00:06:14,040 --> 00:06:22,320
so we take the function side will be replaced

113
00:06:22,370 --> 00:06:23,970
o also known

114
00:06:24,030 --> 00:06:26,260
and also function phi f

115
00:06:27,980 --> 00:06:31,500
corresponds terms of this problem

116
00:06:31,520 --> 00:06:35,080
and maybe you know the kind of problems

117
00:06:35,090 --> 00:06:37,570
it's like that people

118
00:06:37,590 --> 00:06:41,340
the problem of a picture

119
00:06:41,350 --> 00:06:43,290
so you have

120
00:06:43,350 --> 00:06:44,830
this is called a factor the

121
00:06:45,070 --> 00:06:50,190
highly coefficient and if you want to find a solution of this

122
00:06:50,210 --> 00:06:58,190
you will have you will have

123
00:06:58,280 --> 00:07:02,990
two sons aching vector problem

124
00:07:03,080 --> 00:07:04,860
so if you don't trust me

125
00:07:04,890 --> 00:07:09,470
just think about the following thing texas formula

126
00:07:09,490 --> 00:07:11,480
it took six days gradient

127
00:07:11,490 --> 00:07:14,540
and make it a new

128
00:07:14,560 --> 00:07:17,320
and you will find that the solution

129
00:07:17,340 --> 00:07:21,900
that are able the solution for the table two and you have to make new

130
00:07:21,900 --> 00:07:24,810
to gradient satisfying

131
00:07:24,820 --> 00:07:28,040
this kind of equation

132
00:07:28,070 --> 00:07:32,120
so the eighth it again vectors of the matrix k

133
00:07:32,140 --> 00:07:34,350
OK so we are happy because we

134
00:07:34,400 --> 00:07:35,460
it's another way

135
00:07:35,490 --> 00:07:40,320
to come back to what we know about principal component analysis

136
00:07:40,490 --> 00:07:43,070
and of course was that

137
00:07:43,110 --> 00:07:44,870
as you as you see

138
00:07:44,890 --> 00:07:45,920
if i take

139
00:07:45,940 --> 00:07:49,040
and you can then also came in

140
00:07:49,130 --> 00:07:51,740
all work

141
00:07:51,770 --> 00:07:53,910
what they describe these

142
00:07:53,950 --> 00:07:56,830
it is always OK can i can use it

143
00:07:57,580 --> 00:07:59,840
so this method is called cannot PCA

144
00:07:59,990 --> 00:08:01,640
and you will use it

145
00:08:03,280 --> 00:08:09,230
i said he was data which i just described by by proximity based similarity so

146
00:08:09,230 --> 00:08:13,970
you will try to check that your proximity assuming is really you can and then

147
00:08:13,990 --> 00:08:16,360
you have you cannot PCA

148
00:08:16,360 --> 00:08:18,750
all eyes are if you think that

149
00:08:18,770 --> 00:08:20,270
you have some doubt

150
00:08:20,290 --> 00:08:25,110
about the fact that the about the fact that your cloud is really a

151
00:08:26,730 --> 00:08:35,620
risation of caution viable and you will know that principal component classic the company

152
00:08:35,620 --> 00:08:36,610
well one

153
00:08:36,630 --> 00:08:40,680
these two cases to try to go forward canard PC

154
00:08:41,390 --> 00:08:46,450
notice also that so when you were structured object when you have a graph or

155
00:08:46,450 --> 00:08:50,660
when you have if an object in the sense of

156
00:08:52,170 --> 00:08:55,910
object oriented language you will be able to

157
00:08:55,960 --> 00:08:59,740
two began then and then you will be able to

158
00:08:59,760 --> 00:09:07,070
to visualize in fact two projects into this is the first principal directions

159
00:09:07,070 --> 00:09:12,910
the object and it would be a nice way to visualize complex objects

160
00:09:15,360 --> 00:09:18,750
he then you equations

161
00:09:18,780 --> 00:09:20,310
to two battle

162
00:09:20,320 --> 00:09:24,320
of the course

163
00:09:24,330 --> 00:09:28,170
is to keep

164
00:09:28,390 --> 00:09:31,150
you seem

165
00:09:31,280 --> 00:09:37,230
OK so we have

166
00:09:37,340 --> 00:09:39,060
question that

167
00:09:39,070 --> 00:09:40,880
OK so

168
00:09:40,920 --> 00:09:44,690
in these short course as you see

169
00:09:44,710 --> 00:09:47,700
there are a lot of things i didn't talk about

170
00:09:47,710 --> 00:09:48,990
so first

171
00:09:49,030 --> 00:09:52,780
i talked about the way how to formulate problem of

172
00:09:52,920 --> 00:09:57,390
machine learning algorithm and i i d i the

173
00:09:57,430 --> 00:09:59,110
optimisation formulation

174
00:09:59,130 --> 00:10:03,600
but they didn't gave its accredited program for instance

175
00:10:03,620 --> 00:10:09,690
in the two cases support vector regression and support the commission show you an implementation

176
00:10:09,730 --> 00:10:15,700
of the programs we use in this case so in fact you can you can

177
00:10:16,360 --> 00:10:21,210
that was pretty much quite programming tools

178
00:10:21,240 --> 00:10:22,820
to get the tools because there

179
00:10:22,820 --> 00:10:25,980
a variety of tools are so i didn't

180
00:10:26,180 --> 00:10:28,430
talk about the fact that you need

181
00:10:28,450 --> 00:10:30,180
to define you can

182
00:10:31,120 --> 00:10:35,000
even if you have defined can and usually you have some parameter

183
00:10:35,020 --> 00:10:36,570
two to tune

184
00:10:36,570 --> 00:10:39,630
and you have several ways to to do that

185
00:10:39,700 --> 00:10:42,100
the first way ways to use

186
00:10:43,890 --> 00:10:49,580
things like cross validation of obstruct in order to select parameters so this is more

187
00:10:50,830 --> 00:10:53,650
model selection

188
00:10:53,660 --> 00:10:57,920
or in some cases not seen in support vector machine

189
00:10:57,940 --> 00:11:02,030
you have some some researchers who have proposed away

190
00:11:02,070 --> 00:11:03,640
of learning both

191
00:11:03,660 --> 00:11:11,000
the parameters of q is the whole USPS but also with us in the parameters

192
00:11:11,000 --> 00:11:11,980
you can

193
00:11:12,090 --> 00:11:19,420
usually they did gradient in g instead of using a classical quadratic programs they use

194
00:11:19,420 --> 00:11:22,000
gradient all the combined

195
00:11:22,000 --> 00:11:26,900
three examples for M is two where we have two v variables X one and X two

196
00:11:26,920 --> 00:11:31,920
and the vector Y on the ri on the vertical axis if alpha is one

197
00:11:31,920 --> 00:11:35,940
one one-half  one-half then this is just a geometric mean of these two

198
00:11:36,620 --> 00:11:42,890
inequalities and you see that this is actually the same as the second-order cone but

199
00:11:42,900 --> 00:11:47,440
rotated to be in the horizontal plane so you can show that if you take

200
00:11:47,440 --> 00:11:52,440
this power cone with alpha is one half alpha all the alphas are one half then you

201
00:11:52,440 --> 00:11:59,260
get the second order cone but just rotate it   we can also consider other types of alpha

202
00:11:59,260 --> 00:12:03,660
and then you get some cones that are not equivalent to the semi-definite cone or

203
00:12:03,660 --> 00:12:11,460
the second order cone this is for alpha is two-thirds one third for example three quarters

204
00:12:11,460 --> 00:12:20,120
one quarter and so on so those are some examples of convex cones that are useful

205
00:12:20,120 --> 00:12:31,360
in applications are there questions about this so then let's say a few things about modeling

206
00:12:31,360 --> 00:12:37,480
tools so software for modeling I think many of you are familiar

207
00:12:37,480 --> 00:12:43,440
with packages like CVX or YALMIP and MATLAB and there are also some  similar packages

208
00:12:43,440 --> 00:12:49,760
in Python they are less well developed but they're also developed for Python

209
00:12:50,460 --> 00:12:59,920
so modeling system is a software that will translate a convex problem in the natural format in which

210
00:12:59,920 --> 00:13:06,860
you would normally specify an optimization problem and then would translate it into a canonical

211
00:13:06,860 --> 00:13:13,840
form required by a solver and then it solves it and returns the solution back or translates it

212
00:13:13,840 --> 00:13:20,200
back to your notation in your problem so to give an example suppose you want to

213
00:13:20,200 --> 00:13:25,940
solve this simple problem in MATLAB you know from yesterday how to write this

214
00:13:25,940 --> 00:13:33,620
as an LP but  you could also just use CVX this is a modeling system

215
00:13:33,620 --> 00:13:39,380
for MATLAB and then solve this problem by this MATLAB code so everything

216
00:13:39,380 --> 00:13:46,740
between these two key words cvx begin and cvx end is CVX code so you first declare a variable you say X

217
00:13:46,740 --> 00:13:51,900
is a variable of length three for example then you say what the objective is

218
00:13:51,910 --> 00:13:56,380
in the normal notation you would use a MATLAB you say minimize I want to minimize the one

219
00:13:56,380 --> 00:14:01,780
norm of A X minus B you give the constraints you say subject to X greater or equal

220
00:14:01,780 --> 00:14:06,380
to zero less than or equal to one so these will be componentwise interpreted as componentwise

221
00:14:06,380 --> 00:14:13,600
inequalities and then when you finish CVX will pass this it'll recognize that this

222
00:14:13,600 --> 00:14:18,420
objective can be written or trans transformed into a linear programming objective so it'll do

223
00:14:18,420 --> 00:14:27,290
this transformation call an an interior point solver to solve that LP and then return the

224
00:14:27,300 --> 00:14:33,270
answer so after finishing X will be a standard MATLAB variable with the result

225
00:14:33,560 --> 00:14:38,790
of the optimal X right so in this cope X is a CVX optimizational

226
00:14:38,790 --> 00:14:45,060
variable so it's not determined after finishing  it's the optimal value so that's

227
00:14:45,340 --> 00:14:50,120
modeling software so this is a very basic problem but CVX will recognize actually most

228
00:14:50,120 --> 00:14:56,250
of the constraints that we saw yesterday because it knows all these  tricks and

229
00:14:56,260 --> 00:15:02,000
equivalences that allow you to translate convex problems into LPs but also second-order cone

230
00:15:02,000 --> 00:15:13,020
problems or semi-definite programming problems  so it's very convenient because otherwise the translation of

231
00:15:13,020 --> 00:15:17,760
a problem even fairly simple problem in a canonical form required by a solver

232
00:15:17,760 --> 00:15:25,680
can be very tedious and so this does it automatically and so there's others so

233
00:15:25,680 --> 00:15:33,620
that's CVX YALMIP is a similar package for also MATLAB does more or less similar things

234
00:15:33,620 --> 00:15:40,400
and then there is also some older general-purpose modeling packages in optimization and the best

235
00:15:40,420 --> 00:15:52,040
known ones are AMPL and GAMS so these packages use conic optimization solvers so

236
00:15:52,070 --> 00:15:57,820
in this case CVX will translate it into a linear programming problem but depending on the

237
00:15:57,820 --> 00:16:03,700
problem it might also convert it into a second-order cone problem or a semi-definite optimization problem

238
00:16:03,860 --> 00:16:10,020
so it translates everything into conic linear programming problems with these three types of cones so

239
00:16:10,020 --> 00:16:16,820
nonactive orthant the second-order cone and the positive semidefinite cone so that's a little

240
00:16:16,820 --> 00:16:21,230
bit of a limitation so for example the exponential cone included the power cone

241
00:16:21,320 --> 00:16:28,820
is also not included so there's some a few constraints that cannot be directly written as

242
00:16:28,820 --> 00:16:35,500
conic inequalities with these three cones and that need to be approximated but  one of the

243
00:16:35,500 --> 00:16:40,580
reasons why the restriction of the restriction to these cones is that the solvers interior point

244
00:16:40,580 --> 00:16:46,280
solvers for conic optimization are actually also limited to these three cones and you see later

245
00:16:46,280 --> 00:16:53,420
why has to do with the algorithms the classes of interior point methods that people use in these solvers

246
00:16:53,520 --> 00:16:59,640
are restricted to these three cones in practice that's not much of a restriction because actually

247
00:16:59,640 --> 00:17:06,800
surprisingly these three cones the nonactive orthant second-order cone semi-definite cone cover actually most of

248
00:17:06,800 --> 00:17:14,190
the convex constraints you encounter in practice so this is a list of some

249
00:17:14,200 --> 00:17:19,590
constraints that can be written as second-order cone constraints and we saw them already

250
00:17:19,590 --> 00:17:24,380
yesterday so for example if you have a function in the objective like this or

251
00:17:24,380 --> 00:17:27,700
an upper bound on a f this quadratic-over linear function then you can write

252
00:17:27,700 --> 00:17:33,580
it as a second-order cone constraint yesterday also we mentioned the powers of X

253
00:17:33,580 --> 00:17:39,460
so if you have X to positive power greater than one or a negative

254
00:17:39,600 --> 00:17:45,920
power beta for positive X then you can write it as a second-order cone constraint

255
00:17:45,920 --> 00:17:51,420
if alpha and beta are rational and of course if it's not rational you can

256
00:17:51,420 --> 00:18:00,220
easily approximate it by a rational function it also allows you to by using this

257
00:18:00,220 --> 00:18:06,980
trick to minimize P norms  for general P as long as P is rational you

258
00:18:06,980 --> 00:18:13,500
can also write this as a second-order cone program although it's not obvious at first sight

259
00:18:13,500 --> 00:18:24,360
these are some  functions or constraints that can be converted into semi-definite inequalities

260
00:18:24,360 --> 00:18:28,420
and we saw them some of them yesterday for example the maximum eigenvalue of

261
00:18:28,420 --> 00:18:34,220
a symmetric matrix  is something you can directly enter in CVX or YALMIP

262
00:18:34,230 --> 00:18:38,880
you can say I want to minimize the maximum eigenvalue of this matrix variable and it'll

263
00:18:38,880 --> 00:18:42,040
the answer to that is that it did

264
00:18:42,050 --> 00:18:43,670
i just didn't mention it

265
00:18:43,730 --> 00:18:49,850
that's what we all explain so suppose i'd stuck in the minus sign here

266
00:18:49,850 --> 00:18:51,510
OK i would have gotten

267
00:18:52,210 --> 00:18:54,940
with the difference so with an extra minus sign

268
00:18:54,950 --> 00:18:58,040
but then when i compared to what was over there i would have had to

269
00:18:58,040 --> 00:19:00,540
have another different minus sign over here

270
00:19:00,540 --> 00:19:04,320
so actually both places we get an extra minus sign

271
00:19:04,330 --> 00:19:08,170
and they would still coincide so actually the implicit method is little better doesn't even

272
00:19:08,170 --> 00:19:12,200
notice the difference between the branches it does the job both on both

273
00:19:12,270 --> 00:19:13,750
the top and bottom

274
00:19:13,870 --> 00:19:18,720
another way of saying that is that you're calculating the slopes here so let's look

275
00:19:18,720 --> 00:19:20,200
at this picture

276
00:19:20,290 --> 00:19:21,760
here's the slopes

277
00:19:21,770 --> 00:19:26,080
let's just take a look at the positive value of x and just check sites

278
00:19:26,080 --> 00:19:27,640
to see what's happening

279
00:19:27,700 --> 00:19:31,110
if you take a positive value of x over here

280
00:19:31,180 --> 00:19:34,560
x is positive the denominator is positive the slope is negative you can see that

281
00:19:34,560 --> 00:19:36,430
it's tilting down

282
00:19:37,530 --> 00:19:39,540
so it's OK now

283
00:19:39,560 --> 00:19:42,330
on the bottom side

284
00:19:42,370 --> 00:19:44,420
it's going to be tilting up

285
00:19:44,450 --> 00:19:48,830
and similarly what's happening here is that both x and y are positive

286
00:19:48,870 --> 00:19:52,800
and this sexiness this wire positive and the slope is negative on the other hand

287
00:19:52,800 --> 00:19:57,620
on the bottom side exit still positive but y is negative and it's tilting up

288
00:19:57,620 --> 00:19:58,880
because the

289
00:19:58,900 --> 00:20:04,000
the denominator is negative positive in mind positive slope

290
00:20:04,030 --> 00:20:06,760
so it it matches perfectly in every

291
00:20:07,910 --> 00:20:09,940
this the this is

292
00:20:09,950 --> 00:20:15,030
complicated however and it's easier just to keep track of one branch of the time

293
00:20:15,030 --> 00:20:17,020
even in advanced

294
00:20:18,640 --> 00:20:22,300
so we only do have one branch of time

295
00:20:22,350 --> 00:20:25,080
other questions

296
00:20:28,920 --> 00:20:34,470
OK so now i want to give you a slightly more complicated example here and

297
00:20:34,470 --> 00:20:36,650
indeed some of the

298
00:20:36,660 --> 00:20:37,510
so here's

299
00:20:37,540 --> 00:20:41,850
here's a little more complicated example it's not going to be the most complicated example

300
00:20:41,850 --> 00:20:43,550
but you know

301
00:20:43,610 --> 00:20:45,370
would be a little bit

302
00:20:58,390 --> 00:21:05,060
so this example

303
00:21:05,060 --> 00:21:09,530
ah i'm going to give you a fourth order equations so why did the four

304
00:21:09,540 --> 00:21:12,040
what's x y square

305
00:21:12,050 --> 00:21:14,250
minus two is equal to zero

306
00:21:17,630 --> 00:21:19,870
it just so happens

307
00:21:19,870 --> 00:21:21,520
that there's the trick

308
00:21:21,560 --> 00:21:23,610
to solving this equation

309
00:21:23,630 --> 00:21:28,520
so actually you can all you can do both the explicit method and the not

310
00:21:30,960 --> 00:21:32,690
OK so the explicit

311
00:21:34,230 --> 00:21:37,380
i would say OK well i want to solve for this so i'm going to

312
00:21:37,380 --> 00:21:42,880
use the quadratic formula but on on y square this is quadratic in y square

313
00:21:42,930 --> 00:21:46,430
because there's a fourth power in the second pair in the first and those in

314
00:21:46,430 --> 00:21:48,280
the third powers are missing

315
00:21:48,320 --> 00:21:51,460
so this is why square is equal to

316
00:21:51,520 --> 00:21:54,840
minor axis plus or minus the square root

317
00:21:54,890 --> 00:21:56,370
x squared

318
00:21:57,960 --> 00:22:01,910
nine four times minus two

319
00:22:01,940 --> 00:22:04,290
divided by two

320
00:22:05,270 --> 00:22:07,750
so this axis the b

321
00:22:07,770 --> 00:22:10,070
this minus two is the sea

322
00:22:10,080 --> 00:22:12,110
and is equal to one

323
00:22:12,120 --> 00:22:14,770
in the quadratic form

324
00:22:14,780 --> 00:22:16,940
and so the formula for y

325
00:22:17,000 --> 00:22:18,110
it is

326
00:22:18,260 --> 00:22:20,900
plus or minus the square root

327
00:22:20,950 --> 00:22:26,430
of minor axis was minus the square root x squared plus eight

328
00:22:26,440 --> 00:22:29,120
divided by two

329
00:22:29,940 --> 00:22:34,730
so now you can see this problem of branches this happens actually a lot of

330
00:22:34,730 --> 00:22:36,630
cases coming up

331
00:22:37,070 --> 00:22:40,020
in an elaborate where you have two choices for the sign you you have two

332
00:22:40,020 --> 00:22:44,660
choices for the sign here conceivably there's many is four routes to this equation because

333
00:22:44,660 --> 00:22:45,620
it's the fourth

334
00:22:45,680 --> 00:22:47,190
degree equation

335
00:22:47,270 --> 00:22:51,030
it's quite a mess you should have to check each branch separately

336
00:22:51,070 --> 00:22:56,660
and this is really is that level of complexity and in general it's very difficult

337
00:22:56,660 --> 00:22:59,220
to figure out

338
00:22:59,860 --> 00:23:02,810
the formulas for quartic equations

339
00:23:02,890 --> 00:23:06,620
but fortunately we're never going to use them

340
00:23:06,640 --> 00:23:09,780
that is we're never going to need those formulas

341
00:23:09,820 --> 00:23:13,350
so the act the implicit method

342
00:23:13,360 --> 00:23:15,130
it's far easier

343
00:23:15,160 --> 00:23:18,530
so the implicit method

344
00:23:18,530 --> 00:23:20,100
just says OK

345
00:23:20,110 --> 00:23:24,020
i'll leave the equation in its simplest form

346
00:23:24,060 --> 00:23:25,640
and now differentiate

347
00:23:25,660 --> 00:23:28,310
so i differentiate i get four

348
00:23:28,350 --> 00:23:31,350
why cubed why prime

349
00:23:32,420 --> 00:23:35,680
here i have to apply the product rule

350
00:23:35,790 --> 00:23:38,370
so i differentiate the x and

351
00:23:38,390 --> 00:23:39,910
the y squared

352
00:23:39,910 --> 00:23:42,710
alright so what we're going to do today

353
00:23:42,790 --> 00:23:48,050
and that i'm going to start talking about the development of atomic theory

354
00:23:48,970 --> 00:23:54,510
in the next few minutes i'm going to win is through the observations that led

355
00:23:54,580 --> 00:23:55,740
to the

356
00:23:55,760 --> 00:23:58,690
belief that adams

357
00:23:58,740 --> 00:24:03,340
what are the most basic constituent

358
00:24:03,390 --> 00:24:05,400
and then what we're going to be

359
00:24:05,420 --> 00:24:06,210
is there

360
00:24:06,240 --> 00:24:08,250
i can actually be

361
00:24:09,360 --> 00:24:13,130
the animal is not the most basic constituents of matter

362
00:24:13,240 --> 00:24:17,020
there's it lists an electron and the nucleus

363
00:24:17,040 --> 00:24:19,770
we're going to start talking about

364
00:24:19,790 --> 00:24:22,530
what are the fundamental principles

365
00:24:22,630 --> 00:24:28,880
there are to obtain in order for the electron to the nucleus came together to

366
00:24:28,880 --> 00:24:31,040
remain an entity

367
00:24:31,060 --> 00:24:34,770
and what we're going to see is that we're going to have to

368
00:24:34,790 --> 00:24:43,110
understand the new kind of mechanics to understand how the electron and nucleus hang together

369
00:24:43,130 --> 00:24:46,400
and then further on in the course we're going to see be we're going to

370
00:24:46,450 --> 00:24:51,900
need a new kind of mechanics wall also understood how to adults came together how

371
00:24:51,910 --> 00:24:56,010
to atoms bind to form molecules

372
00:24:56,030 --> 00:25:01,200
all right but today i'll lecture for the first two-thirds or three three quarters of

373
00:25:01,240 --> 00:25:06,740
course and announced that now why introduced the rest of our teaching team and we'll

374
00:25:06,740 --> 00:25:12,790
talk about the mechanics of course we'll talk about the expectations of course and some

375
00:25:12,790 --> 00:25:14,340
details like

376
00:25:15,470 --> 00:25:17,270
OK so

377
00:25:17,300 --> 00:25:19,410
let's get going here

378
00:25:19,430 --> 00:25:24,020
and now we turn the lights down because and going to use the

379
00:25:24,630 --> 00:25:26,680
here in the right

380
00:25:29,600 --> 00:25:32,410
the ancient greek philosophers

381
00:25:32,420 --> 00:25:36,990
they certainly were known to have pondered whether matter

382
00:25:37,030 --> 00:25:42,220
can be divided endlessly into smaller and smaller pieces

383
00:25:42,230 --> 00:25:47,390
or whether there was appointed which you couldn't divide matter any further

384
00:25:47,440 --> 00:25:52,710
and in that year he was one of those philosophers who

385
00:25:52,730 --> 00:25:54,830
i argue that matter

386
00:25:54,850 --> 00:26:01,060
could be divided into smaller and smaller particles chopped up into smaller and smaller pieces

387
00:26:01,060 --> 00:26:04,770
and in nineteen and was visible

388
00:26:04,820 --> 00:26:09,040
this is called the continuum theory of matter continue

389
00:26:09,090 --> 00:26:14,770
because you don't have nice discrete point of the continuum no boundaries

390
00:26:14,830 --> 00:26:23,500
but there was a contrary philosophy contrary philosophy heralded by democritus who actually was about

391
00:26:23,500 --> 00:26:26,960
one hundred years older than aristotle

392
00:26:26,970 --> 00:26:28,410
and he held

393
00:26:28,450 --> 00:26:34,730
that matter indeed was composed of individual discrete particles

394
00:26:34,740 --> 00:26:38,890
these discrete particles he called animals

395
00:26:39,620 --> 00:26:40,840
for now

396
00:26:40,890 --> 00:26:42,910
almost four divisible

397
00:26:43,150 --> 00:26:46,770
the origin of our world of course is that

398
00:26:46,810 --> 00:26:51,920
now in the fourth century BC there wasn't much evidence one way or the other

399
00:26:51,920 --> 00:26:57,210
for these kinds of either one of these philosophies i call the plot

400
00:26:57,230 --> 00:27:04,120
because it was the search for understanding reality by speculative as opposed to a

401
00:27:04,130 --> 00:27:08,080
investigation or observation mean

402
00:27:08,100 --> 00:27:10,250
but for whatever reason

403
00:27:10,300 --> 00:27:16,050
it was the aristotle here his continuum theory of matter prevailed all the way to

404
00:27:16,090 --> 00:27:18,230
the seventeenth century

405
00:27:18,240 --> 00:27:22,850
and here he is depicted by rap eleanor fresco

406
00:27:22,920 --> 00:27:27,010
and now on the walls of the vatican holding court

407
00:27:27,020 --> 00:27:29,800
continuum theory man

408
00:27:29,940 --> 00:27:37,110
but just about at the same time in which rafael painted this picture

409
00:27:37,220 --> 00:27:41,770
there were observations set of observations being made

410
00:27:41,860 --> 00:27:47,680
that began to point out that there wasn't really behaving

411
00:27:49,480 --> 00:27:51,830
like eight continue

412
00:27:51,840 --> 00:27:53,790
there was a

413
00:27:53,810 --> 00:27:59,490
behaving more like that i have some discrete nature to it

414
00:27:59,510 --> 00:28:02,110
so what are the observation well

415
00:28:02,130 --> 00:28:05,760
one of them was by this gentleman here robert boyle

416
00:28:05,870 --> 00:28:12,860
and that yes what is moral occupation was

417
00:28:12,910 --> 00:28:20,170
constraint that the good by his former occupation was the theologian both scientists were at

418
00:28:20,210 --> 00:28:21,250
the time

419
00:28:21,270 --> 00:28:23,300
and you of course know him

420
00:28:24,960 --> 00:28:31,410
the empirical observation that the pressure times volume is of constant along the temperature is

421
00:28:32,630 --> 00:28:35,140
but he actually advanced the

422
00:28:35,150 --> 00:28:38,930
one of the first ideas of an element

423
00:28:38,940 --> 00:28:40,300
and that is

424
00:28:40,310 --> 00:28:41,330
he called

425
00:28:42,460 --> 00:28:44,580
a certain primitive

426
00:28:44,620 --> 00:28:46,430
i mangled body

427
00:28:46,440 --> 00:28:53,170
and that somehow you can take these primitive on mangled bodies and put them together

428
00:28:53,190 --> 00:28:56,520
to form a perfectly mixed body

429
00:28:56,520 --> 00:29:01,540
again if everything if all of these probabilities are gaussian

430
00:29:01,620 --> 00:29:04,120
everything is going to be alright

431
00:29:04,140 --> 00:29:10,600
annual and up with nice convex functions and convex functions to minimize

432
00:29:10,600 --> 00:29:11,750
in any case

433
00:29:12,040 --> 00:29:17,910
there are

434
00:29:17,920 --> 00:29:21,020
there are ways of choosing the prize

435
00:29:22,620 --> 00:29:24,750
which i did not described here

436
00:29:24,830 --> 00:29:32,600
prior to that might be might either be obvious from the setting that you have

437
00:29:32,650 --> 00:29:38,390
in in your problem but if not then there are ways of treating noninformative prior

438
00:29:38,390 --> 00:29:40,310
or jeffreys priors

439
00:29:40,390 --> 00:29:51,310
that i won't go into now but you may want to look into that

440
00:29:54,350 --> 00:29:58,910
now i have to all sides about

441
00:29:58,960 --> 00:30:01,960
a few months size about probabilities which are

442
00:30:03,640 --> 00:30:06,600
the first one here is about concepts

443
00:30:06,640 --> 00:30:13,480
that stem from the information series that information theory is a theory that in that

444
00:30:13,480 --> 00:30:19,480
aims at measuring the amount of information you have in your random variables in your

445
00:30:23,080 --> 00:30:28,170
the basic thing in information theory is the entropy the entropy of

446
00:30:28,190 --> 00:30:30,500
a random viable is

447
00:30:30,520 --> 00:30:34,620
nine the integral of x log px of x

448
00:30:34,640 --> 00:30:44,370
you can show that it's actually negative

449
00:30:44,390 --> 00:30:46,120
actually no

450
00:30:55,640 --> 00:31:00,810
so i think it may be may be due to the entropy is positive when

451
00:31:01,170 --> 00:31:05,390
you have the discrete survival but if if you have a continuous horrible that it's

452
00:31:05,390 --> 00:31:11,120
it's not necessarily positive anyways i don't remember and if we if someone knows that

453
00:31:11,120 --> 00:31:12,520
better than it now

454
00:31:12,540 --> 00:31:15,980
what is true is that the kullback leibler divergence

455
00:31:16,020 --> 00:31:20,980
is always positive OK

456
00:31:21,000 --> 00:31:25,230
the biggest

457
00:31:32,870 --> 00:31:35,330
and it

458
00:31:40,000 --> 00:31:42,520
contract thank you

459
00:31:44,960 --> 00:31:50,890
so for a discrete distribution on the

460
00:31:50,920 --> 00:31:56,190
on the set exercise that takes values x one to x and

461
00:31:56,290 --> 00:32:03,350
then the distribution that minimizes the entropy is different the function is in in one

462
00:32:03,350 --> 00:32:07,750
of the the excited so basically if you're

463
00:32:07,890 --> 00:32:12,730
random viable takes values in x one to x and x one x two to

464
00:32:14,190 --> 00:32:17,790
then the probability as the minimum entropy if it's

465
00:32:17,790 --> 00:32:21,460
the problem if it's the poverty

466
00:32:21,580 --> 00:32:25,040
the random bible it takes only one value

467
00:32:25,040 --> 00:32:26,560
with probability one

468
00:32:26,580 --> 00:32:29,330
and values was probably his u

469
00:32:29,390 --> 00:32:31,410
that's what the function is

470
00:32:32,650 --> 00:32:35,830
and the entropy is maximal

471
00:32:35,830 --> 00:32:36,830
if all

472
00:32:36,850 --> 00:32:41,690
of the exercise of exactly the same probability which is one of

473
00:32:41,690 --> 00:32:42,560
so if

474
00:32:43,250 --> 00:32:48,310
the discrete probability the uniform discrete probability the the one having the most

475
00:32:48,330 --> 00:32:51,390
the largest entropy

476
00:32:51,670 --> 00:32:57,810
on the set of probabilities of exercise

477
00:32:57,850 --> 00:32:59,020
all right

478
00:32:59,040 --> 00:33:05,670
the kullback leibler divergence is the way of comparing comparing the

479
00:33:05,690 --> 00:33:10,190
mountains of information in in the two variables x and y

480
00:33:10,250 --> 00:33:13,920
it's in particular its way

481
00:33:18,790 --> 00:33:20,640
it's a way of comparing them

482
00:33:20,640 --> 00:33:27,100
two probability team there to probabilities px and py y it's always but even it's

483
00:33:27,100 --> 00:33:29,850
it equal to zero if and only if

484
00:33:29,960 --> 00:33:32,640
the probabilities are equal

485
00:33:32,650 --> 00:33:37,420
and the mutual information i of x and y

486
00:33:37,460 --> 00:33:42,520
it is the only one type of information that is shared between the two of

487
00:33:42,520 --> 00:33:49,170
the two random variables x and y it's actually the kullback divergence the kullback leibler

488
00:33:50,580 --> 00:33:52,000
between the two

489
00:33:52,080 --> 00:33:53,520
so in probability

490
00:33:53,640 --> 00:33:56,670
and the product of the probabilities

491
00:33:56,750 --> 00:34:02,650
the two marginal probability so it's the distance between the joint probability and what would

492
00:34:04,330 --> 00:34:06,410
and x x and y

493
00:34:06,420 --> 00:34:08,890
it would be independent

494
00:34:08,940 --> 00:34:16,410
so there is no information shared between x and y if and only if x

495
00:34:16,410 --> 00:34:18,230
and y are independent

496
00:34:18,250 --> 00:34:20,350
he two s three

497
00:34:21,020 --> 00:34:26,520
now there's an ocean called city which is a measure of the complexity of the

498
00:34:26,520 --> 00:34:28,870
complexity of the distribution

499
00:34:30,230 --> 00:34:34,370
unfortunately finish and is due to the entropy of x

500
00:34:34,420 --> 00:34:39,120
and it's used in evaluating language is a language model

501
00:34:39,120 --> 00:34:43,310
so i don't know much about this but i think you see it in the

502
00:34:57,750 --> 00:35:01,890
maybe a few more musically

503
00:35:01,910 --> 00:35:06,560
you can you should think about en tropy as matter that can tell you

504
00:35:06,560 --> 00:35:13,450
is stationary or of

505
00:35:16,680 --> 00:35:19,650
one that's right

506
00:35:19,670 --> 00:35:22,440
stationarity so

507
00:35:22,450 --> 00:35:27,150
we want to view the world as we want to view the

508
00:35:27,160 --> 00:35:33,060
there are the objects of study is static now i'm not as concerned about stationary

509
00:35:33,120 --> 00:35:37,160
since the world is a stationary dynamical system because it's

510
00:35:37,310 --> 00:35:39,240
because that's still dynamic

511
00:35:39,250 --> 00:35:43,630
it's just if they don't have source streams of inputs and outputs at all

512
00:35:43,990 --> 00:35:48,510
OK so the let's let's move on to second idea in the second idea is

513
00:35:48,510 --> 00:35:50,300
perhaps most obvious of all

514
00:35:50,380 --> 00:35:53,450
is one of the kind more carefully reward

515
00:35:54,400 --> 00:35:58,370
rewards values verification

516
00:35:59,310 --> 00:36:01,330
the awards are very simple

517
00:36:01,340 --> 00:36:06,470
and general formulation che both both short and long term goals and

518
00:36:06,490 --> 00:36:08,580
that's a key point in

519
00:36:08,580 --> 00:36:13,590
because of that enables the agent to tell for itself whether it's right or wrong

520
00:36:13,590 --> 00:36:19,090
so we can verify its own thoughts its own understanding

521
00:36:19,100 --> 00:36:22,770
or you know i'm just talking about the elementary things like you know the backgammon

522
00:36:22,770 --> 00:36:24,580
player can know if it's one the game

523
00:36:24,630 --> 00:36:30,500
OK so bill rewards and values short and long term goals i think this is

524
00:36:31,200 --> 00:36:33,560
people are talking about

525
00:36:33,650 --> 00:36:36,890
obviously this is this has to do with with the reward system in the brain

526
00:36:37,130 --> 00:36:41,920
and the relationship between short-term things the reward signal and a long-term things the value

527
00:36:41,920 --> 00:36:45,650
thing so i theory of long term goal is just to the prediction of some

528
00:36:45,650 --> 00:36:46,860
of the structure goals

529
00:36:47,110 --> 00:36:50,840
OK that's that's the theory that the computational theory

530
00:36:51,250 --> 00:36:55,170
that's reinforcement learning computational theory of what it means to have a goal

531
00:36:55,170 --> 00:36:57,750
and for the purpose of the mind

532
00:36:57,770 --> 00:37:01,750
very very simple

533
00:37:01,760 --> 00:37:06,130
and that i think is where the power comes from so it's it's simple but

534
00:37:06,130 --> 00:37:09,250
it's also very

535
00:37:10,530 --> 00:37:12,590
and it actually is more

536
00:37:12,600 --> 00:37:16,770
it's not more complex but it's more powerful than what is often considered like he

537
00:37:16,770 --> 00:37:19,860
might consider goal states or

538
00:37:19,900 --> 00:37:22,480
desired trajectories and so

539
00:37:22,500 --> 00:37:28,080
a reward measure instantaneous measure over time is more sophisticated than that

540
00:37:28,080 --> 00:37:32,410
even though it's OK so it's been stated ball is we can so i wrote

541
00:37:32,410 --> 00:37:38,030
up this this this attempt to do that and a strong way in which i

542
00:37:38,030 --> 00:37:42,130
call this hypothesis because because i'm not brave enough to stand up and say it's

543
00:37:43,090 --> 00:37:47,320
but i think this is in a major the stent which is chosen major reason

544
00:37:47,320 --> 00:37:52,760
for power reinforcement so you say all all of what we mean by goals and

545
00:37:52,760 --> 00:37:58,160
purposes can be well thought of as maximizing the expected value

546
00:37:58,240 --> 00:38:00,710
the cumulative sum

547
00:38:00,890 --> 00:38:04,620
the scalar signal that comes from outside recall reward

548
00:38:08,670 --> 00:38:10,500
so ruling out lot

549
00:38:10,520 --> 00:38:14,060
this this this is sort of a really general but it's not

550
00:38:14,060 --> 00:38:17,740
it's not true in general its ruling like and that's

551
00:38:17,760 --> 00:38:21,420
that can be good to tap the simplicity we're just going to have a single

552
00:38:21,420 --> 00:38:26,950
criterion that che that should be sufficient for the expectation this ruling out issues of

553
00:38:26,950 --> 00:38:29,670
sensitivity to risk

554
00:38:29,690 --> 00:38:33,350
we're going to deal with additive sums

555
00:38:33,370 --> 00:38:37,720
not interactions between things and finally

556
00:38:37,740 --> 00:38:43,720
the goal is received its external to the system is not internally generated goal so

557
00:38:43,730 --> 00:38:49,860
all these are make this a substantial to hypothesis could be wrong you could disagree

558
00:38:49,860 --> 00:38:55,700
with it but i really think these are just making simple and not real limitations

559
00:38:55,960 --> 00:38:59,600
for example you idea of risking can easily encode the risk as a different kind

560
00:38:59,600 --> 00:39:00,930
of reward

561
00:39:00,950 --> 00:39:05,660
doesn't really change it if you don't want to deal with things being additive just

562
00:39:07,210 --> 00:39:11,860
this is me the fuel additive you can and you can see the goal

563
00:39:11,900 --> 00:39:15,270
the final reward including everything to come at the end

564
00:39:15,300 --> 00:39:16,800
and the goal

565
00:39:16,820 --> 00:39:21,500
you could something is a huge difference is if you want it

566
00:39:21,530 --> 00:39:23,510
go to the

567
00:39:27,830 --> 00:39:31,700
makes it is that it is these

568
00:39:33,680 --> 00:39:35,470
right so big

569
00:39:35,550 --> 00:39:42,190
it's a big deal i think i'm trying to present positively that that that the

570
00:39:42,190 --> 00:39:45,700
reason we can cross across fields have very simple

571
00:39:45,760 --> 00:39:51,580
theory there can be no that we can analyse mathematicians and psychologist can make sense

572
00:39:51,580 --> 00:39:57,070
of it it's just like a theory of sums signal going on in the brains

573
00:39:57,080 --> 00:39:58,570
of communicating

574
00:39:58,580 --> 00:40:00,200
you what

575
00:40:00,220 --> 00:40:05,210
well of course obviously on excommunicate people and i realized that when i say these

576
00:40:05,210 --> 00:40:10,360
so he had this connection between the property of the base learner and the margin

577
00:40:10,360 --> 00:40:15,710
of the combined forces OK if the base learner has this property that always returns

578
00:40:15,710 --> 00:40:16,960
to certain

579
00:40:17,150 --> 00:40:23,960
weighted error why i mean they are which is more than half minus half coming

580
00:40:24,000 --> 00:40:25,520
then we have this property

581
00:40:25,560 --> 00:40:28,610
and therefore the margin of the combined forces

582
00:40:28,650 --> 00:40:36,460
is the least common when we find the optimal of k

583
00:40:36,480 --> 00:40:40,400
OK so what the model which is actually see but it was to sort of

584
00:40:40,400 --> 00:40:44,940
what i was talking about was the optimal case here so we maximize all of

585
00:40:45,560 --> 00:40:48,840
so the question is what is article was actually cheating

586
00:40:48,860 --> 00:40:53,690
so it can be shown that it is actually finding a solution which has a

587
00:40:53,690 --> 00:40:58,020
large margin but not the maximum margin it can be shown that the

588
00:40:58,080 --> 00:41:03,270
margin which is achieved by the most is at least half of the maximum margin

589
00:41:03,320 --> 00:41:08,080
OK so that's why i mean it's it's some it's fine hypothesis which has a

590
00:41:08,080 --> 00:41:11,170
large margin is good so it's good for these margin bounds

591
00:41:11,190 --> 00:41:14,690
for the more modern but it doesn't really matter too much about the margins half

592
00:41:14,690 --> 00:41:16,980
what just what the maximum

593
00:41:18,650 --> 00:41:23,130
it can be shown that i was might not be

594
00:41:23,150 --> 00:41:27,810
converging what they can or cannot examples of articles is definitely not maximising the margin

595
00:41:27,810 --> 00:41:31,860
was open problem for a long time but it was actually maximizing the margin and

596
00:41:32,060 --> 00:41:35,880
so it has been shown like two years ago i think that but it was

597
00:41:35,880 --> 00:41:40,380
not maximizing the margin for i mean they're called example

598
00:41:40,400 --> 00:41:45,600
OK proves it was only known it finds combined forces with which has least to

599
00:41:45,600 --> 00:41:47,590
half of the maximum margin

600
00:41:47,670 --> 00:41:53,040
OK so then we came up with ideas of changing articles such that actually maximize

601
00:41:53,060 --> 00:41:57,650
the margin so the first one was actually little prime and i think he to

602
00:41:57,650 --> 00:42:00,110
design the new algorithm which is called opportunity

603
00:42:02,020 --> 00:42:07,540
asymptotically maximizes the margin so he changed something such that really maximize the margin but

604
00:42:07,540 --> 00:42:09,580
only in the very limit

605
00:42:09,630 --> 00:42:14,270
so he didn't have any convergence rate

606
00:42:14,290 --> 00:42:20,630
then month and and i worked on adaboost star so that's

607
00:42:20,630 --> 00:42:23,590
what application and total was very recently

608
00:42:23,610 --> 00:42:27,400
and then we were able to show that it requires

609
00:42:27,400 --> 00:42:32,460
we can be changed the algorithm and the algorithm needs only to look and over

610
00:42:32,460 --> 00:42:39,460
x squared iterations in order to achieve margin which is at least roast minus epsom

611
00:42:39,480 --> 00:42:44,630
OK so roast as the maximum margin and epsilon this the accuracy would like to

612
00:42:44,630 --> 00:42:49,690
achieve me need this many iterations

613
00:42:49,770 --> 00:42:53,630
and i'm going to show you how we did that

614
00:42:53,840 --> 00:42:59,560
the last technique is based on linear programming that was some by christian bennett

615
00:42:59,710 --> 00:43:05,560
and that's related to kind of generations and that is usually very fast however there

616
00:43:05,560 --> 00:43:08,060
are no convergence rate so the only on

617
00:43:08,080 --> 00:43:17,060
with convergence rates are these adaboost stein told post

618
00:43:17,080 --> 00:43:19,420
the case is it clear

619
00:43:20,270 --> 00:43:30,290
how the model relates to the edge and any questions for that

620
00:43:31,340 --> 00:43:34,230
please ask now getting more complicated

621
00:43:42,580 --> 00:43:46,590
essentially on the training at a service on training data so that means here that

622
00:43:46,590 --> 00:43:51,130
on the training data we would like to achieve margin so rule starlets a max

623
00:43:51,190 --> 00:43:53,360
margin and then

624
00:43:53,380 --> 00:43:56,880
we would like to achieve margin on the training set which is at least roast

625
00:44:00,360 --> 00:44:09,650
so all which comes now is is empirically that means is on the training set

626
00:44:13,420 --> 00:44:15,380
so this may be

627
00:44:15,440 --> 00:44:18,360
i mean you know it's all yours

628
00:44:25,480 --> 00:44:27,630
i mean

629
00:44:27,840 --> 00:44:31,400
firstly of course i would like to find something which i mean to say i

630
00:44:31,400 --> 00:44:35,200
would like to compute something that we have to run the algorithm and then i

631
00:44:35,200 --> 00:44:39,400
would like to maximize the margin small number of iterations is just cost something to

632
00:44:39,400 --> 00:44:46,060
run and if the number of iterations is ten billion second which kind run some

633
00:44:46,060 --> 00:44:51,560
some tree ten billion times something so it's more like a computational issues

634
00:44:51,610 --> 00:44:57,840
OK it does it says satisfied

635
00:45:00,590 --> 00:45:10,310
OK well is the right so

636
00:45:10,340 --> 00:45:15,920
of course when you have in your functions are very simple for instance of anyone

637
00:45:15,920 --> 00:45:18,730
conscious just one dimension of your of your data

638
00:45:18,750 --> 00:45:22,790
OK so then you might want to have a very small number of features because

639
00:45:22,790 --> 00:45:24,230
then you can actually interpreted

640
00:45:24,250 --> 00:45:28,440
so if you achieve small i mean large margin which is with a small number

641
00:45:28,440 --> 00:45:33,380
of iterations but small number of features then this is good for you practice for

642
00:45:33,540 --> 00:45:37,270
the solution of practical problem because then you can actually look at what these features

643
00:45:37,270 --> 00:45:44,290
on can try to understand what's going on there

644
00:45:46,980 --> 00:45:51,130
so what i want to say so the minmax theorem that's really the the most

645
00:45:51,130 --> 00:45:52,040
important thing

646
00:45:52,040 --> 00:45:52,920
i mean

647
00:45:52,940 --> 00:46:00,670
so make make note in your notes and this this really relates the it's

648
00:46:00,670 --> 00:46:03,840
with the margin

649
00:46:03,900 --> 00:46:05,900
OK so

650
00:46:05,960 --> 00:46:11,110
that is so let me try to drive a little bit how this new algorithms

651
00:46:11,130 --> 00:46:15,080
this article star and also called forced work so

652
00:46:15,210 --> 00:46:18,190
i start with a small modification of post

653
00:46:18,290 --> 00:46:25,880
so it's called adaboost role it's made by first proposed by prime in ninety seven

654
00:46:25,940 --> 00:46:31,230
it is essentially just about which articles are so we have everything which was another

655
00:46:31,230 --> 00:46:35,320
post if just one wanting thing so and that's something which we call the target

656
00:46:35,320 --> 00:46:37,190
marginal role

657
00:46:38,560 --> 00:46:40,440
so and only goes in

658
00:46:40,480 --> 00:46:42,630
to the

659
00:46:42,820 --> 00:46:50,730
computation of poverty so this role simply constant which is subtracted from the

660
00:46:50,730 --> 00:46:55,150
it's only modifications

661
00:46:55,170 --> 00:46:59,480
everything else is just the same

662
00:46:59,500 --> 00:47:00,690
OK so

663
00:47:00,710 --> 00:47:01,980
what does it mean

664
00:47:02,040 --> 00:47:04,840
so you might ask

665
00:47:04,860 --> 00:47:06,940
and there is some

666
00:47:07,130 --> 00:47:11,900
there's some theory so maybe maybe let me first explained you so the idea of

667
00:47:11,900 --> 00:47:17,210
this target margin is that OK adaboost madaboost this rule is here

668
00:47:17,230 --> 00:47:19,840
OK so then this term is just here

669
00:47:19,840 --> 00:47:21,680
and to give the sequence

670
00:47:22,890 --> 00:47:27,400
i think i think it's important to see that there is a difference between

671
00:47:29,060 --> 00:47:33,890
these kind of fixed continuation i would say like when you look at the numbers

672
00:47:33,940 --> 00:47:36,030
as they are given in the this

673
00:47:38,370 --> 00:47:42,900
and you try to find out how you can add them up

674
00:47:42,920 --> 00:47:46,320
to get that in the next sequence

675
00:47:46,330 --> 00:47:52,730
and here you try to look for other type of properties not additive properties but

676
00:47:52,940 --> 00:47:56,280
i don't know how to go about but i don't know

677
00:47:56,330 --> 00:48:00,030
but and properties like you look for patterns in the binary expansion

678
00:48:00,240 --> 00:48:06,230
well OK there are some other funny things that you can think of actually this

679
00:48:06,230 --> 00:48:07,390
one is not in the

680
00:48:07,410 --> 00:48:11,890
encyclopedia but because it's not exactly correct there should be as free

681
00:48:11,890 --> 00:48:15,820
to make its correct because i i just

682
00:48:15,840 --> 00:48:17,690
so it's OK if you look at

683
00:48:17,720 --> 00:48:20,910
the by the expansion of pi and

684
00:48:22,420 --> 00:48:25,590
and you can interleave them so i would be three

685
00:48:25,630 --> 00:48:28,080
one four one five nine

686
00:48:28,090 --> 00:48:31,350
and e two seven one eight

687
00:48:32,320 --> 00:48:33,110
what they were

688
00:48:34,680 --> 00:48:36,000
so when not i mean

689
00:48:36,020 --> 00:48:40,560
it's also corrects it starts with one two four seven so why not

690
00:48:40,580 --> 00:48:44,090
and can you can invent all sorts of things

691
00:48:44,680 --> 00:48:49,280
in general in these IQ tests there is one

692
00:48:49,280 --> 00:48:50,200
kind of

693
00:48:50,230 --> 00:48:51,480
natural answer

694
00:48:51,490 --> 00:48:52,880
one is that looks

695
00:48:52,890 --> 00:48:57,560
simpler than the other ones although all the other ones are correct

696
00:48:57,610 --> 00:49:00,390
there is one that seems more reasonable

697
00:49:00,580 --> 00:49:03,580
and and and again usually is to just two

698
00:49:03,580 --> 00:49:04,400
try to

699
00:49:04,430 --> 00:49:05,450
i guess

700
00:49:05,470 --> 00:49:07,170
what's the

701
00:49:07,190 --> 00:49:09,130
this exam minor

702
00:49:09,150 --> 00:49:15,270
the sinking actually but but there is no there is no reason why i i

703
00:49:15,280 --> 00:49:18,420
would prefer this version to this version because

704
00:49:18,440 --> 00:49:23,810
so maybe my brain is naturally inclined to looking at numbers in binary form rather

705
00:49:23,810 --> 00:49:28,630
than looking at numbers in this form is just a convention like we have been

706
00:49:28,630 --> 00:49:30,620
trained to look at numbers

707
00:49:30,630 --> 00:49:33,350
like this and make additions

708
00:49:34,560 --> 00:49:35,830
i mean if you show

709
00:49:35,850 --> 00:49:42,120
these two two two-year-old baby you probably would see the patterns but you will not

710
00:49:42,120 --> 00:49:44,130
see the additive structure

711
00:49:44,180 --> 00:49:46,410
so it's just a matter of

712
00:49:46,430 --> 00:49:47,330
what you

713
00:49:47,330 --> 00:49:51,550
how are you know what you think about

714
00:49:51,560 --> 00:49:58,200
another one which is also funny i think this example from marcus later again if

715
00:49:58,200 --> 00:50:00,620
you start with this the

716
00:50:00,630 --> 00:50:05,850
OK this is the prime numbers so you write the prime numbers until fifty nine

717
00:50:05,860 --> 00:50:07,690
you enter the sequence

718
00:50:07,720 --> 00:50:08,650
in the

719
00:50:09,800 --> 00:50:13,480
on the web and you you would seen that

720
00:50:13,500 --> 00:50:16,560
there is only one way to continue this sequences to put

721
00:50:16,560 --> 00:50:21,630
prime numbers but actually it's not the case there is another sequence that's exactly the

722
00:50:21,630 --> 00:50:22,650
same way

723
00:50:22,710 --> 00:50:25,390
and which has sixty instead of sixty one

724
00:50:25,400 --> 00:50:26,720
which is

725
00:50:26,730 --> 00:50:29,230
the the least of the order of the

726
00:50:29,240 --> 00:50:30,480
simple group

727
00:50:30,500 --> 00:50:33,700
OK i i will not tell you what simple groups are

728
00:50:34,370 --> 00:50:40,280
just to show you that i mean if you are a mathematician working on group

729
00:50:40,290 --> 00:50:45,100
theory maybe you would mean that you immediately notice looking at the sequence that this

730
00:50:45,100 --> 00:50:49,680
is the sequence of orders of simple groups you say sixty whereas if you are

731
00:50:49,680 --> 00:50:50,930
number theorist

732
00:50:50,960 --> 00:50:52,630
he was a sixty one

733
00:50:52,680 --> 00:50:57,080
OK so it's it's also depends on your culture you know way

734
00:50:57,180 --> 00:51:05,750
OK yet another example

735
00:51:05,770 --> 00:51:07,140
in the same flavour

736
00:51:07,170 --> 00:51:10,850
you have a sequence of numbers again

737
00:51:10,850 --> 00:51:13,950
and the goal is to extend the sequence of numbers

738
00:51:14,950 --> 00:51:16,550
if you have ever

739
00:51:16,570 --> 00:51:17,580
looked at the

740
00:51:17,600 --> 00:51:22,390
this is this email expansion of by you will notice that it's actually the first

741
00:51:22,540 --> 00:51:25,530
numbers in the decimal expansion of pi

742
00:51:25,540 --> 00:51:28,210
but if you have not seen that

743
00:51:28,230 --> 00:51:30,130
like if if i have put u

744
00:51:30,150 --> 00:51:32,100
if i put here some

745
00:51:32,120 --> 00:51:36,710
other people maybe he or square root of two you would probably have not noticed

746
00:51:38,970 --> 00:51:40,890
so the question is

747
00:51:40,890 --> 00:51:44,060
when do you not is the structure and when do you not not just the

748
00:51:46,290 --> 00:51:48,200
you could say

749
00:51:49,000 --> 00:51:53,330
let's just count how many times i have one i mean sometimes i have two

750
00:51:53,330 --> 00:51:55,690
and so on and you will notice

751
00:51:55,710 --> 00:51:57,900
at least if you continue the sequence

752
00:51:58,550 --> 00:52:06,280
long enough that actually all this the frequencies converge to one over one pence

753
00:52:07,190 --> 00:52:08,200
this is the

754
00:52:08,220 --> 00:52:09,990
funny properties of

755
00:52:10,000 --> 00:52:15,360
pi and e and some numbers like this that

756
00:52:15,390 --> 00:52:17,390
actually every

757
00:52:17,410 --> 00:52:19,100
in figure appears

758
00:52:19,100 --> 00:52:22,650
take some ten years ago

759
00:52:22,660 --> 00:52:29,810
usually the data recording was quite expensive so people really care about what they measured

760
00:52:29,810 --> 00:52:30,580
so they

761
00:52:30,610 --> 00:52:34,260
really measured only relevant things and what

762
00:52:34,300 --> 00:52:40,730
the out come was the outcome of this was that the datasets for the

763
00:52:40,740 --> 00:52:43,060
really well defined

764
00:52:43,080 --> 00:52:47,830
very good for the state of minas because we were quite sure not really should

765
00:52:47,830 --> 00:52:49,700
but but

766
00:52:49,710 --> 00:52:56,510
consider a sure that all variables all attributes of the data points are really relevant

767
00:52:56,530 --> 00:52:58,700
to the talks about talks

768
00:52:58,710 --> 00:53:03,270
so that is usually was quite low dimensional analysis or

769
00:53:03,300 --> 00:53:09,550
even if we have a higher dimensional data usually all attributes are relevant

770
00:53:10,290 --> 00:53:14,580
if all attributes irrelevant even you can have thousands of of attributes you don't have

771
00:53:14,610 --> 00:53:16,700
crisp dimensionality because

772
00:53:16,740 --> 00:53:17,650
if all

773
00:53:17,660 --> 00:53:20,410
actually are relevant then

774
00:53:21,450 --> 00:53:23,000
there's nothing

775
00:53:23,050 --> 00:53:29,960
to be cursed by much OK but nowadays the situation is different

776
00:53:29,970 --> 00:53:35,980
data causing it's very easy very cheap so everyone measures everything

777
00:53:36,030 --> 00:53:39,120
maybe you know it's myself so

778
00:53:39,150 --> 00:53:45,240
attributes are no longer have evaluated before measurement measurement if they are relevant or not

779
00:53:45,240 --> 00:53:46,290
just measure

780
00:53:46,300 --> 00:53:48,130
because it's so cheap so easy

781
00:53:48,150 --> 00:53:52,950
and we end up in datasets that usually contain a large number of features

782
00:53:53,240 --> 00:53:56,680
and a large number of these features are irrelevant

783
00:53:56,700 --> 00:53:58,230
for the task of data mining

784
00:53:58,280 --> 00:54:00,220
we have it in and we don't know

785
00:54:00,230 --> 00:54:03,530
which other elements once and which are not

786
00:54:03,550 --> 00:54:05,050
so for example here's some

787
00:54:07,040 --> 00:54:12,560
very few examples in molecular biology mir gene expression data with more than a thousand

788
00:54:12,580 --> 00:54:14,610
dimensions for object

789
00:54:14,620 --> 00:54:17,740
quite a lot of them are irrelevant

790
00:54:19,270 --> 00:54:21,100
how to do that

791
00:54:21,120 --> 00:54:25,480
customer recommendations but we have ratings for products again tends to

792
00:54:25,510 --> 00:54:27,920
thousands of sorry to hundreds of

793
00:54:27,960 --> 00:54:29,440
dimensions for

794
00:54:29,460 --> 00:54:32,260
corruption and there are many more

795
00:54:34,150 --> 00:54:36,010
whatever text

796
00:54:36,020 --> 00:54:39,440
highdimensional data is is really

797
00:54:39,450 --> 00:54:42,030
a big challenge nowadays

798
00:54:42,060 --> 00:54:43,900
so what is the challenge

799
00:54:44,420 --> 00:54:49,000
again the curse of dimensionality so if you have a lot of irrelevant attributes

800
00:54:50,000 --> 00:54:52,190
usually data is really because by

801
00:54:52,400 --> 00:54:55,600
this is the fact that the relative contrast between

802
00:54:56,870 --> 00:54:59,100
simply increase with

803
00:54:59,200 --> 00:55:02,680
increasing dimensionality we had this in the

804
00:55:02,740 --> 00:55:06,310
which is great

805
00:55:06,340 --> 00:55:07,720
picture we

806
00:55:07,720 --> 00:55:10,050
the cheese credit distribution of

807
00:55:13,270 --> 00:55:16,270
to the to the to the mean

808
00:55:16,270 --> 00:55:23,670
when we increase the degrees of freedom and the distances converged to economy

809
00:55:23,670 --> 00:55:25,420
so the distances get

810
00:55:26,730 --> 00:55:28,400
the higher the dimensions are

811
00:55:28,410 --> 00:55:30,990
so the relative contrast between the distances

812
00:55:33,010 --> 00:55:38,750
consequences they don't very sparse almost all points and noise or outliers what kind of

813
00:55:39,460 --> 00:55:42,010
i mean all points of

814
00:55:42,020 --> 00:55:44,700
at least in the full dimensional space

815
00:55:44,720 --> 00:55:46,980
and many

816
00:55:47,480 --> 00:55:50,300
models that we heard

817
00:55:50,320 --> 00:55:55,000
here rely on the concept of neighborhoods to to define outliers in the concept of

818
00:55:56,000 --> 00:56:00,270
does not apply it becomes meaningless in high dimensional spaces cannot say

819
00:56:00,360 --> 00:56:03,670
what is the one of the k nearest neighbours of the absentee

820
00:56:03,670 --> 00:56:07,770
if we if the concept of distances is no longer

821
00:56:07,810 --> 00:56:12,600
meaningful in high dimensional space so is the concept of

822
00:56:12,610 --> 00:56:18,670
so solutions for this is to use more robust distance functions and find for the

823
00:56:18,670 --> 00:56:21,540
full dimensional outliers cosine

824
00:56:21,550 --> 00:56:23,160
measurements or whatever

825
00:56:23,160 --> 00:56:25,520
or to find outliers in projections

826
00:56:25,550 --> 00:56:27,800
of the original feature space

827
00:56:27,850 --> 00:56:33,770
that means only a subset of the features are relevant and we try not only

828
00:56:33,770 --> 00:56:37,290
to find the outliers but also the features

829
00:56:37,340 --> 00:56:41,330
that specify the lines that are relevant to this line

830
00:56:42,190 --> 00:56:46,670
the guys did intensional knowledge with the distance based on

831
00:56:46,680 --> 00:56:51,230
so i think these are the most important challenge is here

832
00:56:51,820 --> 00:56:53,110
so here's one

833
00:56:53,130 --> 00:56:56,190
the idea for the first

834
00:56:56,200 --> 00:57:01,010
the idea of solution using more robust distance function or distance measure and find full

835
00:57:01,010 --> 00:57:05,720
dimensional outliers which is called a but angle based outlier degree

836
00:57:05,730 --> 00:57:07,340
so the idea here is

837
00:57:08,250 --> 00:57:11,660
and angle based distance measure is

838
00:57:11,680 --> 00:57:16,900
potentially more stable in high dimensional spaces for example you may be you know that

839
00:57:17,420 --> 00:57:21,690
text data which is really high dimensional this term frequency

840
00:57:22,770 --> 00:57:27,060
it's very popular to use cosine

841
00:57:27,070 --> 00:57:28,580
similarity measure

842
00:57:28,590 --> 00:57:33,100
because and that's a more stable than distances dimensions space

843
00:57:33,150 --> 00:57:37,580
so this is that you use angle sensor instead of of distances

844
00:57:37,600 --> 00:57:41,990
and the idea is that

845
00:57:42,030 --> 00:57:47,170
an object could be an outlier if most other objects are located in similar directions

846
00:57:47,170 --> 00:57:49,170
or take this

847
00:57:49,170 --> 00:57:51,400
object here

848
00:57:51,400 --> 00:57:53,730
you see that most of the objects are

849
00:57:53,750 --> 00:57:55,320
in a similar direction

850
00:57:56,250 --> 00:57:58,480
tation from from o

851
00:57:58,530 --> 00:58:00,380
they are all in this direction

852
00:58:00,440 --> 00:58:02,130
on the other hand if you take

853
00:58:02,150 --> 00:58:03,670
o point in here

854
00:58:03,690 --> 00:58:07,690
all other points are most of the points are in various this similar

855
00:58:09,900 --> 00:58:11,070
so this is the

856
00:58:11,070 --> 00:58:12,820
the idea

857
00:58:12,820 --> 00:58:14,730
how is this formalized

858
00:58:14,750 --> 00:58:20,150
so well first of all the basic assumptions again here outliers are at the border

859
00:58:20,150 --> 00:58:24,130
of the of the data distribution because all other points are interested in a similar

860
00:58:24,130 --> 00:58:29,000
direction and normal points are in the centre of the data fusion because

861
00:58:29,050 --> 00:58:31,480
most of the points are similar

862
00:58:32,960 --> 00:58:38,190
and the idea is now implemented in the following models so you just consider

863
00:58:38,210 --> 00:58:40,150
for a given point p

864
00:58:40,170 --> 00:58:41,050
the angle

865
00:58:43,280 --> 00:58:48,940
yeah sorry for a given point p you take two other points x and y

866
00:58:48,940 --> 00:58:50,690
from the database

867
00:58:50,770 --> 00:58:52,900
and consider the angle between

868
00:58:54,440 --> 00:58:56,230
the line

869
00:58:56,250 --> 00:59:00,440
p x p y so take this one you

870
00:59:00,460 --> 00:59:04,230
x and y and you just consider the angles between

871
00:59:04,280 --> 00:59:06,630
this line OK

872
00:59:06,630 --> 00:59:14,120
perhaps change system accordingly so that adapts system that interfaces all that sort of thing

873
00:59:14,420 --> 00:59:15,080
to do

874
00:59:15,090 --> 00:59:16,590
it's a step further

875
00:59:16,610 --> 00:59:23,690
i organised a workshop in the modelling two years ago and had been fight with

876
00:59:24,450 --> 00:59:28,110
they actually convinced me i was wrong because we're saying you know we do machine

877
00:59:28,110 --> 00:59:34,220
learning and clearly machine learning and so we got these wonderful system can actually help

878
00:59:34,220 --> 00:59:39,210
you to do this we all doing these systems they finish off by

879
00:59:39,230 --> 00:59:43,310
then predicting what the user is going to do

880
00:59:43,330 --> 00:59:46,960
so we are very happy to come up with system model

881
00:59:46,970 --> 00:59:51,310
which will predict the next clue to use these two to

882
00:59:51,370 --> 00:59:53,470
so i think that is no way

883
00:59:53,470 --> 00:59:58,900
the next operation person is going to do is to actually that direction all of

884
00:59:59,050 --> 01:00:01,490
this is what he likes because this is what see

885
01:00:01,500 --> 01:00:05,830
and they said no we do not want that all because we know that you

886
01:00:05,830 --> 01:00:09,310
should use the money is used in context

887
01:00:09,380 --> 01:00:14,660
being used in context means that as soon as you install user modeling system are

888
01:00:14,670 --> 01:00:15,970
also using

889
01:00:15,980 --> 01:00:17,310
the adaptation

890
01:00:17,320 --> 01:00:23,880
of the system to model which then means that the user himself going change what

891
01:00:24,030 --> 01:00:28,940
does not correspond to this model to predict so coming out in machine learning just

892
01:00:28,940 --> 01:00:32,100
as capable of coming out the system with its

893
01:00:32,110 --> 01:00:36,330
that's not good for us because it's a bit like when are talking about the

894
01:00:36,330 --> 01:00:43,460
the distribution of probabilities relaxing the distribution is not change between the training and testing

895
01:00:43,460 --> 01:00:47,620
whether it's clearly something they don't want distribution is going to change because the machine

896
01:00:47,620 --> 01:00:50,290
learning is going to actually do so

897
01:00:50,340 --> 01:00:56,650
and getting this example just to show that all truths in machine learning which are

898
01:00:56,720 --> 01:01:01,190
then people go further thanks to this sort of discussion available in machine learning that

899
01:01:01,190 --> 01:01:07,600
then into account how to measure the annotation system although there will be nice theories

900
01:01:07,710 --> 01:01:08,880
but if we do want to

901
01:01:10,210 --> 01:01:11,330
of interest

902
01:01:12,050 --> 01:01:16,310
groups want to hire is very capable of saying you know i don't arrive with

903
01:01:16,310 --> 01:01:21,720
my true this is what what has always existed they all work in different ways

904
01:01:21,720 --> 01:01:28,680
to get the data we think sampling is pressing to about naming them sampling might

905
01:01:28,680 --> 01:01:35,040
take four years to see how the child may develop and language so you can't

906
01:01:35,040 --> 01:01:41,020
always just say right and i disagree i saying we need to know twenty thousand

907
01:01:41,020 --> 01:01:42,800
examples to

908
01:01:42,900 --> 01:01:48,820
so i was my last message which is machine learning there's lots of perspective in

909
01:01:48,820 --> 01:01:53,210
pure machine learning i'm not sure also means is a machine learning and something else

910
01:01:53,620 --> 01:01:59,550
and a huge keep open-minded towards towards the sun

911
01:01:59,560 --> 01:02:02,080
this is

912
01:02:03,540 --> 01:02:06,140
yet so

913
01:02:06,260 --> 01:02:10,360
a follow-on from but

914
01:02:10,400 --> 01:02:13,840
you think that OK so first of all

915
01:02:13,850 --> 01:02:17,760
my own careers is i'm coming academic

916
01:02:17,760 --> 01:02:20,880
professor university but actually started out

917
01:02:20,900 --> 01:02:27,160
as an engineer with IBM and stay the same for ten years solving problems designing

918
01:02:27,160 --> 01:02:33,320
systems and so forth and then i went into to accademia and so although my

919
01:02:35,120 --> 01:02:41,390
probably would be called applied statistics rather than machine learning problem solved because

920
01:02:41,980 --> 01:02:44,710
a lot of people would argue that machine learning is

921
01:02:44,730 --> 01:02:51,000
applied statistics and in many ways some people will disagree with me i actually agree

922
01:02:51,000 --> 01:02:56,460
with fully but it certainly are a viewpoint that an awful lot of very senior

923
01:02:56,460 --> 01:03:00,170
people within the machine learning community take

924
01:03:00,250 --> 01:03:01,340
push forward

925
01:03:04,550 --> 01:03:08,790
machine learning i would say is is very much an applied

926
01:03:08,810 --> 01:03:17,230
subject and takes all of his motivation from the problems that are being considered

927
01:03:17,240 --> 01:03:20,580
for example one of the really hot is at the moment

928
01:03:20,670 --> 01:03:27,960
is computational biology and we were talking about earlier on so very area because it

929
01:03:27,960 --> 01:03:30,050
is largely a data driven

930
01:03:30,060 --> 01:03:40,250
subject biologists and experimentalists they have these hypotheses there is no

931
01:03:40,260 --> 01:03:42,220
underlying c

932
01:03:42,240 --> 01:03:45,340
o which describes the systems that we are studying

933
01:03:45,360 --> 01:03:50,080
the one to understand that they want to develop the in the only way they

934
01:03:50,080 --> 01:03:55,230
can do that is by observing the systems usually have a in that minor

935
01:03:55,240 --> 01:04:02,310
generating observations generating data and then going by contesting for these hypotheses

936
01:04:02,470 --> 01:04:07,970
and consequently there is a huge amount of data there is a huge amount of

937
01:04:07,980 --> 01:04:13,240
uncertainty in the data is well and so that there is

938
01:04:13,250 --> 01:04:20,240
a lot of opportunity for people machine learning background applied statistics by background to engage

939
01:04:20,240 --> 01:04:25,050
with biologists in trying to understand some of the most complex

940
01:04:26,340 --> 01:04:32,870
around mean user modeling is extremely complex because of the interaction and the other activity

941
01:04:32,870 --> 01:04:35,130
it is converted to heat

942
01:04:35,140 --> 01:04:36,630
and to give you

943
01:04:36,640 --> 01:04:40,580
some feeling for the incredible power of neutron star

944
01:04:40,660 --> 01:04:41,790
if you make

945
01:04:41,790 --> 01:04:43,080
this little

946
01:04:43,090 --> 01:04:45,650
as little as ten grams

947
01:04:45,730 --> 01:04:47,850
think of it as a

948
01:04:47,850 --> 01:04:49,950
thirteen full-size marshmallow

949
01:04:50,060 --> 01:04:54,910
and you throw marshmallow from a large distance on two neutron star the energy that's

950
01:04:54,910 --> 01:04:59,730
released is comparable to the atomic bomb that was used the russian

951
01:04:59,740 --> 01:05:06,100
ten gram objects thrown onto a neutron star the reason being that this velocity becomes

952
01:05:06,100 --> 01:05:07,730
enormously high

953
01:05:07,780 --> 01:05:09,150
if you put in

954
01:05:09,180 --> 01:05:10,910
for the neutron star

955
01:05:10,960 --> 01:05:12,360
a mass of about

956
01:05:12,370 --> 01:05:15,590
ten two to three times ten to the thirty kilograms

957
01:05:15,590 --> 01:05:18,600
and you take for the radius of the neutron stars

958
01:05:18,620 --> 01:05:20,280
about ten kilometres

959
01:05:20,380 --> 01:05:24,090
you'll find that that velocity becomes about

960
01:05:25,020 --> 01:05:30,360
times ten to eight meters per second which is about seventy percent

961
01:05:30,410 --> 01:05:31,430
of the

962
01:05:31,480 --> 01:05:33,230
speed of light

963
01:05:33,450 --> 01:05:39,550
because of this enormous speed one half the square is horrendously high is the conversion

964
01:05:39,630 --> 01:05:44,460
of gravitational potential energy to kinetic energy and then ultimately

965
01:05:44,510 --> 01:05:46,600
two weeks

966
01:05:46,690 --> 01:05:48,090
no nature

967
01:05:51,520 --> 01:05:53,040
transferring mass

968
01:05:53,050 --> 01:05:56,920
at extraordinarily high rate

969
01:05:57,850 --> 01:06:01,050
many of these binary systems there are at least

970
01:06:02,080 --> 01:06:03,920
hundred and so did we know

971
01:06:03,940 --> 01:06:06,700
in our own galaxy

972
01:06:06,750 --> 01:06:08,710
the mass transfer rates

973
01:06:08,760 --> 01:06:11,190
which i call the MDT

974
01:06:11,250 --> 01:06:15,500
so is transfected from the donor onto the neutron star

975
01:06:15,510 --> 01:06:17,170
that transfer rate

976
01:06:17,200 --> 01:06:18,950
it is roughly

977
01:06:19,000 --> 01:06:21,350
ten two to fourteen

978
01:06:23,050 --> 01:06:24,750
a second

979
01:06:24,800 --> 01:06:27,620
there's no ran this mass transfer rates

980
01:06:27,640 --> 01:06:29,060
you can calculate

981
01:06:29,060 --> 01:06:30,760
by multiplying it with

982
01:06:30,810 --> 01:06:32,520
one half the square

983
01:06:32,530 --> 01:06:36,590
how many joules per second are released in the form of kinetic energy that means

984
01:06:36,590 --> 01:06:39,770
in the form of the form of heat and i call that the power of

985
01:06:39,770 --> 01:06:43,400
the neutron star and that then for this mass

986
01:06:43,430 --> 01:06:46,880
transfer rate that's about two times ten to the thirty

987
01:06:46,930 --> 01:06:48,270
joules per second

988
01:06:49,170 --> 01:06:51,610
which is what

989
01:06:51,670 --> 01:06:57,300
and that is about five thousand times larger than the power of our own sun

990
01:06:57,340 --> 01:07:02,100
but the temperature of these neutron star because of this enormous amount of energy released

991
01:07:02,140 --> 01:07:07,140
the temperature will reach values of about ten million degrees kelvin and at that high

992
01:07:08,230 --> 01:07:12,510
the neutron star would emit almost exclusively x-rays

993
01:07:12,530 --> 01:07:17,200
you and i am very cold bodies only three hundred degrees kelvin we radiate electromagnetic

994
01:07:17,200 --> 01:07:21,630
radiation in the infrared part of the spectrum we have warm bodies we also someone

995
01:07:21,630 --> 01:07:23,100
in your arms you can feel that

996
01:07:23,180 --> 01:07:24,240
if i

997
01:07:24,280 --> 01:07:25,760
what need to update

998
01:07:25,770 --> 01:07:29,880
two three thousand degrees kelvin you become red hot

999
01:07:29,990 --> 01:07:33,400
you actually we could turn the light off and i would see you you just

1000
01:07:33,480 --> 01:07:35,090
remaining red light

1001
01:07:35,100 --> 01:07:39,530
if i would need to up to three million degrees you would start to begin

1002
01:07:39,570 --> 01:07:43,200
two radiates in x-rays you may not like it but that's the detail of course

1003
01:07:43,200 --> 01:07:47,320
so i wanted to appreciate the fact that the

1004
01:07:47,330 --> 01:07:49,350
the kind of radiation that you get

1005
01:07:49,400 --> 01:07:51,370
depends strongly on the temperature

1006
01:07:51,380 --> 01:07:54,690
and that ten million degrees you're dealing almost exclusively

1007
01:07:56,350 --> 01:08:04,440
so these binary system very potent sources of x-rays

1008
01:08:04,440 --> 01:08:07,850
the neutron stars rotate around we discover that we discussed earlier

1009
01:08:07,850 --> 01:08:09,690
conservation of angular momentum

1010
01:08:09,710 --> 01:08:12,420
and they have strong magnetic fields

1011
01:08:13,480 --> 01:08:19,060
matter that falls onto the neutron star already heats up doing in full

1012
01:08:19,110 --> 01:08:23,270
because the gravitational potential energy released and so the matter is so hot that in

1013
01:08:23,270 --> 01:08:25,250
general it's highly ionized

1014
01:08:25,310 --> 01:08:28,400
and highly ionized material can cannot reach

1015
01:08:28,460 --> 01:08:29,810
the magnetic

1016
01:08:29,810 --> 01:08:31,500
neutron star and all

1017
01:08:31,500 --> 01:08:35,480
locations that it prefers to do so a o two you will learn why that's

1018
01:08:35,480 --> 01:08:36,440
the case

1019
01:08:36,480 --> 01:08:38,440
however the matter can reach

1020
01:08:38,460 --> 01:08:41,250
the neutron star at the magnetic poles

1021
01:08:41,270 --> 01:08:44,500
so what you're going to see now is you're going have a neutron star

1022
01:08:44,580 --> 01:08:46,040
with magnetic poles

1023
01:08:46,060 --> 01:08:49,440
so the matter streams in on to the magnetic pole to give you two hot

1024
01:08:50,670 --> 01:08:53,860
and if the axis of rotation doesn't coincide

1025
01:08:53,900 --> 01:08:57,520
was the mind forty two hotspots if the neutron star rotates

1026
01:08:57,520 --> 01:09:00,230
you're going to see x-ray politicians

1027
01:09:00,330 --> 01:09:02,560
when the hotspot is here

1028
01:09:02,560 --> 01:09:03,850
or not

1029
01:09:03,890 --> 01:09:07,310
and the way it's going to do that is is in a random way

1030
01:09:08,200 --> 01:09:11,970
it's random but it's depends on its neighbors this node is going to decide whether

1031
01:09:11,970 --> 01:09:15,660
to flip is going to look at its four nearest neighbours

1032
01:09:15,720 --> 01:09:18,580
and what is going to do is

1033
01:09:19,200 --> 01:09:22,310
you've got value zeros and ones that these neighbours

1034
01:09:22,330 --> 01:09:26,250
and you can compute a certain kind of logistic function

1035
01:09:26,290 --> 01:09:30,430
is a very specific reason this function arises but i won't go into details if

1036
01:09:30,430 --> 01:09:33,660
it comes is the conditional probability from this

1037
01:09:33,720 --> 01:09:36,790
but what you want to take aways that all this node does a very simple

1038
01:09:36,790 --> 01:09:38,330
local update

1039
01:09:38,350 --> 01:09:41,680
just like message passing its local in diameter says

1040
01:09:41,830 --> 01:09:47,200
depending on this number on this sample uniform random variable

1041
01:09:47,220 --> 01:09:50,850
and based on that all decide whether flip or not

1042
01:09:50,870 --> 01:09:56,000
just going around the graph and you're just doing single site updates just flipping variables

1043
01:09:56,000 --> 01:10:00,160
and what's interesting is you can show that if you do this and you wait

1044
01:10:00,160 --> 01:10:01,430
long enough

1045
01:10:01,950 --> 01:10:04,640
the second part is key if you wait long enough

1046
01:10:04,660 --> 01:10:09,470
eventually you get a sample that's that's essentially a random sample that looks like an

1047
01:10:09,470 --> 01:10:12,450
image that's been drawn from this model

1048
01:10:12,580 --> 01:10:16,890
but in general you might have to wait a very long time

1049
01:10:16,890 --> 01:10:22,560
so these methods are always practical but but they're interesting methods

1050
01:10:22,580 --> 01:10:26,230
so the reason i mention this is because it it sort of gives nice parallel

1051
01:10:26,230 --> 01:10:29,250
to the class of methods that i'd like to talk about which

1052
01:10:29,660 --> 01:10:31,910
i called variational methods

1053
01:10:31,950 --> 01:10:34,390
we're going to see the

1054
01:10:34,410 --> 01:10:38,540
the message passing algorithms that we've already seen the ones that are exact

1055
01:10:38,540 --> 01:10:43,320
we're going to see those can be understood as variational methods that were also to

1056
01:10:43,320 --> 01:10:48,640
see that there are other algorithms actually ones that were understood before that look very

1057
01:10:48,640 --> 01:10:52,250
much like sampling there are also variational methods

1058
01:10:52,290 --> 01:10:59,040
and the motivation here's these algorithms for instance of discussing here the mean field algorithm

1059
01:10:59,230 --> 01:11:02,250
these algorithms are not exact anymore

1060
01:11:02,410 --> 01:11:05,950
that is going to give you approximations to the exact quantities

1061
01:11:06,000 --> 01:11:09,660
but i will see is that in certain cases they can give you very good

1062
01:11:09,660 --> 01:11:11,930
approximations to the exact quantities

1063
01:11:11,950 --> 01:11:17,310
and what's key is very cheap they're not exponential you're not doing things with the

1064
01:11:17,310 --> 01:11:21,520
tree with the graph you're doing dumb and local things

1065
01:11:21,540 --> 01:11:25,950
so this algorithm this mean field algorithm a special case of it it looks very

1066
01:11:25,950 --> 01:11:28,230
much like the gibbs sampler

1067
01:11:28,250 --> 01:11:29,990
except that there's is

1068
01:11:30,040 --> 01:11:33,810
everything that's been passed all the messages that are being passed just numbers there is

1069
01:11:33,810 --> 01:11:39,790
no sort of deciding to i flip or not there's just numbers going along edges

1070
01:11:39,810 --> 01:11:42,930
and this is very easy to implement

1071
01:11:42,950 --> 01:11:45,730
it's even simpler than belief propagation

1072
01:11:45,750 --> 01:11:47,060
the way it works is

1073
01:11:47,080 --> 01:11:49,390
you pick another random

1074
01:11:49,490 --> 01:11:52,330
that node looks its neighbors

1075
01:11:52,390 --> 01:11:56,230
each of its neighbors has some real numbers this is a real number between zero

1076
01:11:56,230 --> 01:11:57,640
and one

1077
01:11:57,700 --> 01:12:02,270
it just take these numbers inputs into this logistic function and updates itself in this

1078
01:12:03,870 --> 01:12:08,520
so what you sort of want to see here's there's a strong parallel between this

1079
01:12:08,520 --> 01:12:13,200
algorithm in gibbs sampling this this function here is basically the same function in the

1080
01:12:13,200 --> 01:12:14,620
structure of

1081
01:12:14,700 --> 01:12:19,950
picking a node and then looking at neighbours that's the same structure it's again purely

1082
01:12:19,950 --> 01:12:23,310
local it's just obeying the local graph structure

1083
01:12:23,370 --> 01:12:27,700
so it's something that can be done in parallel can be done very cheaply

1084
01:12:27,720 --> 01:12:30,620
but the question here is now

1085
01:12:30,620 --> 01:12:33,770
where did this come from it looks like i just took it out of the

1086
01:12:34,810 --> 01:12:38,680
what is this over them do doesn't converge

1087
01:12:38,680 --> 01:12:40,700
does it give reasonable answers

1088
01:12:40,720 --> 01:12:43,830
i mean it's nice because it's very cheap you could just implement this and maybe

1089
01:12:43,830 --> 01:12:46,350
three or four lines of matlab

1090
01:12:47,560 --> 01:12:51,580
cheap algorithms are interesting unless they do something reasonable

1091
01:12:51,600 --> 01:12:57,660
so c in certain cases this this kind of algorithm slide extensions of perhaps do

1092
01:12:57,660 --> 01:13:01,140
things that are reasonable

1093
01:13:01,180 --> 01:13:05,200
the second sort of motivation here is is coming back to what i spoke about

1094
01:13:05,200 --> 01:13:07,230
in the beginning part

1095
01:13:07,600 --> 01:13:11,600
we spoke about these message passing algorithms on trees

1096
01:13:12,870 --> 01:13:17,750
there we derive them from the elimination perspective we saw that they were exact algorithms

1097
01:13:18,410 --> 01:13:23,640
guys are just again doing dumb local computations but everything converges

1098
01:13:23,660 --> 01:13:27,970
and at the end of the day everybody is happy

1099
01:13:27,970 --> 01:13:32,750
so again just like the HMM these algorithms are real work courses in practice people

1100
01:13:32,750 --> 01:13:36,910
use these terms all the time for chains and for trees

1101
01:13:37,020 --> 01:13:42,390
but what i'd like to move on to to here is the interesting question well

1102
01:13:42,390 --> 01:13:46,310
you know not everything is the tree like we've discussed someone may well have graph

1103
01:13:46,310 --> 01:13:48,290
that has cycles

1104
01:13:50,350 --> 01:13:54,720
what's actually been done this seems like an incredibly stupid thing to do

1105
01:13:54,730 --> 01:13:57,100
well not stupid but naive

1106
01:13:57,100 --> 01:14:00,330
that's something that has turned out to work much better than i think anybody would

1107
01:14:00,330 --> 01:14:05,540
have expected people will have to take the same the exact same algorithm

1108
01:14:05,600 --> 01:14:08,990
the exact same message passing updates

1109
01:14:09,040 --> 01:14:12,810
and i just run the monograph that has cycles

1110
01:14:12,910 --> 01:14:17,500
right here i was running on the tree and here everything we discussed everything's nice

1111
01:14:17,500 --> 01:14:20,470
converges everything makes sense

1112
01:14:20,540 --> 01:14:25,020
there's nothing to stop me from just doing it when i have cycles

1113
01:14:25,060 --> 01:14:26,880
right the algorithm doesn't know

1114
01:14:26,890 --> 01:14:32,430
this node is just computing is taking messages is just some meaning sending things along

1115
01:14:32,470 --> 01:14:35,640
what he doesn't even know there a cycle cycle in this graph that he has

1116
01:14:35,640 --> 01:14:37,450
no idea that it's there

1117
01:14:37,470 --> 01:14:43,130
there's nothing to stop you from from implementing the algorithm for a general graph

1118
01:14:43,140 --> 01:14:46,910
but you might have some concerns about this

1119
01:14:46,930 --> 01:14:52,770
you know it's again no longer an exact algorithm

1120
01:14:52,830 --> 01:14:55,350
what does this mean to do this

1121
01:14:55,390 --> 01:14:57,540
it doesn't mean anything

1122
01:14:57,560 --> 01:15:01,760
before we did it you know the messages meant something they were

1123
01:15:01,810 --> 01:15:07,420
we're eliminating things in the messages were things we're sending to give partial information here

1124
01:15:07,450 --> 01:15:10,640
it's really not at all clear what's going on

1125
01:15:10,680 --> 01:15:14,410
so lots of questions i mean this to begin what does this mean what is

1126
01:15:14,410 --> 01:15:18,370
it doing questions doesn't converge

1127
01:15:18,390 --> 01:15:20,310
does it good good answers

1128
01:15:20,310 --> 01:15:26,560
if so when if not one behave badly there are all sorts of questions and

1129
01:15:26,560 --> 01:15:30,100
the only reason these questions are interesting is because people are using this all the

1130
01:15:30,100 --> 01:15:35,290
time in both communication theory and in computer vision

1131
01:15:35,300 --> 01:15:38,170
as two particular examples

1132
01:15:38,940 --> 01:15:43,770
sort of one way to understand why the algorithms approximate is

1133
01:15:43,790 --> 01:15:48,190
well there are many ways to understand it

1134
01:15:48,200 --> 01:15:52,250
maybe the simplest intuition is is the following

1135
01:15:52,300 --> 01:15:55,590
i i think this is a reasonable example

1136
01:15:55,640 --> 01:15:57,790
so i'd like to say this because

1137
01:15:58,160 --> 01:16:03,200
none of my colleagues from berklee are here in the audience began sort of think

1138
01:16:04,730 --> 01:16:07,910
graphical models

1139
01:16:07,930 --> 01:16:13,470
actually some people use graphical models whole area they use them to model social networks

1140
01:16:13,540 --> 01:16:17,800
right you think about sort of the nodes being people and edges are for instance

1141
01:16:17,800 --> 01:16:20,560
which people are friends which people are enemies

1142
01:16:20,600 --> 01:16:22,160
who talks to whom

1143
01:16:23,270 --> 01:16:25,730
people model things like gossip behaviour

1144
01:16:25,750 --> 01:16:27,410
gossip protocols

1145
01:16:27,410 --> 01:16:31,000
would be to actually have no activation function so i've linear

1146
01:16:31,010 --> 01:16:34,820
neuron just means that the activation function on my pre-activation

1147
01:16:34,830 --> 01:16:38,440
is just pre-activation itself that's not very interesting

1148
01:16:40,150 --> 01:16:43,250
we often have sigmoid units have you seen that in

1149
01:16:43,520 --> 01:16:48,580
on stock this morning so this sigmoid function has the property

1150
01:16:48,580 --> 01:16:51,960
that is essentially squashes pre-activation between zero and one

1151
01:16:51,960 --> 01:16:55,920
as you can see here so this is this axes pre-activation that's the

1152
01:16:55,920 --> 01:16:58,600
activation of the neuron you can see the squash between zero and

1153
01:16:58,600 --> 01:17:03,290
one it's always positive it is bounded and it's strictly increasing

1154
01:17:03,300 --> 01:17:06,610
so the hired pre-activation higher the activation

1155
01:17:07,030 --> 01:17:10,680
and the actual mathematical formula for the sigmoid is this here

1156
01:17:10,690 --> 01:17:13,100
it's one over one plus the exponential

1157
01:17:13,280 --> 01:17:18,050
of the negative pre-activation another popular choice is the tange

1158
01:17:18,060 --> 01:17:21,110
or hyperbolic tangent function in this case

1159
01:17:21,300 --> 01:17:25,000
mainly what changes it's it's it's quite similar to a sigmoid function

1160
01:17:25,000 --> 01:17:29,080
but instead it it's activation ranges between minus one and one

1161
01:17:29,300 --> 01:17:33,060
and so you have this somewhat more complicated formula which is

1162
01:17:33,070 --> 01:17:35,490
the exponential of pre-activation minus

1163
01:17:35,710 --> 01:17:38,180
exponential of minus pre-activation

1164
01:17:38,480 --> 01:17:41,760
divided by exponential the pre-activation plus the exponential

1165
01:17:41,760 --> 01:17:45,700
of the negative pre-activation this is one way of computing it

1166
01:17:45,980 --> 01:17:50,830
you could multiply the numerator and denominator by the

1167
01:17:50,840 --> 01:17:54,390
exponential of the activation exponential ok and then you get this

1168
01:17:54,400 --> 01:17:57,430
formula which is slightly more interesting just because

1169
01:17:57,580 --> 01:18:01,580
here we only have to compute one exponential exponential twice

1170
01:18:01,590 --> 01:18:05,580
pre-activation and exponential is more are

1171
01:18:05,740 --> 01:18:08,260
actually expensive to compute that can be a

1172
01:18:08,430 --> 01:18:11,300
more convenient more form compassionately

1173
01:18:12,570 --> 01:18:16,610
and filey probably right now the most popular activation function

1174
01:18:16,860 --> 01:18:20,780
is the rectifier a linear activation you are function

1175
01:18:20,980 --> 01:18:25,380
we often refer to those as a rare this is painful re l

1176
01:18:25,580 --> 01:18:30,520
move ok for rectified linear unit

1177
01:18:31,670 --> 01:18:35,530
as if you see this in papers is refer to the usage of this activation

1178
01:18:35,530 --> 01:18:37,910
function rectified linear activation function

1179
01:18:38,040 --> 01:18:41,780
it is bounded below by zero but it is not upper bounded

1180
01:18:42,510 --> 01:18:46,180
it's also increasing not strictly though because here it's

1181
01:18:46,190 --> 01:18:49,830
not it's actually flat it's a stake and then

1182
01:18:50,670 --> 01:18:55,410
it in practice it will tend to give when you train neural net with

1183
01:18:55,420 --> 01:18:58,860
a rather units will tend to give you a sparse activities which

1184
01:18:58,870 --> 01:19:03,220
is property we observe empirically and the function itself

1185
01:19:03,230 --> 01:19:08,330
is simply the maximum between zero and pre-activation so the pre-activation

1186
01:19:08,340 --> 01:19:11,410
is larger zero you get a linear function

1187
01:19:11,760 --> 01:19:15,710
but if it's below zero you get a flat zero output zero activation

1188
01:19:16,820 --> 01:19:24,070
right question on that ok so what is the cap as capacity of single

1189
01:19:24,070 --> 01:19:26,240
neuron what kind of things can we achieve

1190
01:19:26,400 --> 01:19:29,400
and represent using a single neuron so we've seen this

1191
01:19:30,050 --> 01:19:33,640
picture already and you can just looking at this already see

1192
01:19:33,650 --> 01:19:37,880
that at it seems we are able to represent a linear decision boundaries

1193
01:19:37,890 --> 01:19:42,150
so perform linear classification so indeed

1194
01:19:42,830 --> 01:19:47,260
if we think of single neuron and we use the sigmoid activation

1195
01:19:47,270 --> 01:19:50,780
function one thing we could do for want to take the probabilistic

1196
01:19:50,780 --> 01:19:53,750
approach of classifiers that are going to describe this to think

1197
01:19:53,750 --> 01:19:57,430
of the activation of that neuron as representing what is the

1198
01:19:57,440 --> 01:20:00,600
probability that for some given input x

1199
01:20:01,470 --> 01:20:04,370
the label associated with my input is one

1200
01:20:04,550 --> 01:20:08,780
so think of in mind tation a assume sometimes a binary classification

1201
01:20:08,780 --> 01:20:11,110
problem which case the positive class is one

1202
01:20:11,140 --> 01:20:13,210
and the negative class going to be zero

1203
01:20:13,450 --> 01:20:17,040
so this actually corresponds to the model behind logistic regression

1204
01:20:17,120 --> 01:20:21,620
that are going represented and so if you want to make a prediction

1205
01:20:21,760 --> 01:20:24,370
that is assigned the label to some given input

1206
01:20:24,590 --> 01:20:29,240
we would just compute are activation of the neuron linear transformation

1207
01:20:29,250 --> 01:20:33,170
followed by a sigmoid and with threshold zero point five weibull

1208
01:20:33,180 --> 01:20:37,730
if that represents the models predictive distribution over the

1209
01:20:37,740 --> 01:20:42,440
label y if it's if it's values are the zero point five it means

1210
01:20:42,440 --> 01:20:45,540
it thinks it's more likely that belong to the class one in class

1211
01:20:45,540 --> 01:20:49,300
zero and that's how you would get a classifier performing a classification

1212
01:20:49,300 --> 01:20:53,590
using sing neuron is one can easily see that you would essentially

1213
01:20:53,820 --> 01:20:58,000
be drawing a line in your input space between the positives and negatives

1214
01:20:59,820 --> 01:21:03,900
so what's kind of function you represent i'm going to use a very

1215
01:21:03,910 --> 01:21:07,690
simple example of boolean functions which is a classic example

1216
01:21:07,700 --> 01:21:12,020
for explaining why we want more than just a single artificial neuron

1217
01:21:12,020 --> 01:21:15,540
so it's also those even though it's simple it's kind of interesting

1218
01:21:15,540 --> 01:21:18,250
in a sense that you know if we would like to use neural nets to

1219
01:21:18,250 --> 01:21:20,870
perform some kind of logical reasoning

1220
01:21:21,160 --> 01:21:24,720
we would probably want such functions of neural nets to be able

1221
01:21:24,730 --> 01:21:28,700
to represent sort and simply simple move and operations

1222
01:21:29,370 --> 01:21:33,170
to representing three different boolean operations so here are true

1223
01:21:33,180 --> 01:21:37,610
represented by one and falls by zero so we have the or function

1224
01:21:37,800 --> 01:21:39,970
the or function would output true one

1225
01:21:40,350 --> 01:21:43,040
if any of its input x one and x to

1226
01:21:43,240 --> 01:21:47,570
z at is equal to one so in this case so the triangles would be the

1227
01:21:47,580 --> 01:21:50,440
positive class so we can see if at either

1228
01:21:50,670 --> 01:21:54,530
this dimension that dimension is equal to one we are in the positive

1229
01:21:54,540 --> 01:21:58,090
class and output of one f and otherwise both zero we get a zero

1230
01:21:58,170 --> 01:22:02,860
so we can see that in this case it is easy to draw a line that separates

1231
01:22:02,860 --> 01:22:06,090
all the positives from the negatives so we can represent that

1232
01:22:06,100 --> 01:22:09,720
with a single neuron and other function is the and function i'm

1233
01:22:09,730 --> 01:22:13,190
here i'm showing the and function on the negative of the first

1234
01:22:13,200 --> 01:22:17,190
argument and the second argument so in this case

1235
01:22:17,360 --> 01:22:21,640
and will be equal one or true only if both arguments are one so

1236
01:22:21,640 --> 01:22:24,850
that means that x one x one since i'm taking it's negative needs

1237
01:22:24,850 --> 01:22:28,590
to be zero and then x to needs to be one that's why i have a

1238
01:22:28,900 --> 01:22:32,230
positive example here and all the others either one is going to

1239
01:22:32,230 --> 01:22:37,190
be zero so i get the negative class and again in this situation

1240
01:22:37,200 --> 01:22:41,450
i can easily chop the space using a line into the positive and

1241
01:22:41,460 --> 01:22:44,380
negative and same thing for and where applied

1242
01:22:44,520 --> 01:22:48,170
negative on another argument so all these function that can represent

1243
01:22:48,170 --> 01:22:54,390
with a single neuron however right take a slightly more complicated

1244
01:22:54,400 --> 01:22:58,050
really not that complicated function the x or function which

1245
01:22:58,060 --> 01:23:02,480
is equal to one output true if either one

1246
01:23:02,670 --> 01:23:05,990
is equal to true the other false or vice versa

1247
01:23:06,350 --> 01:23:10,720
so this case in this case this would be positive examples zero one

1248
01:23:10,860 --> 01:23:14,230
and one zero the other with an output of one

1249
01:23:14,410 --> 01:23:18,390
and any other combinations to ones or to zeros would be

1250
01:23:18,390 --> 01:23:20,800
the one on the right to the one on the left

1251
01:23:20,830 --> 01:23:21,880
in fact

1252
01:23:23,570 --> 01:23:27,440
they're not superimpose we're looking at here is essentially

1253
01:23:27,450 --> 01:23:28,860
a pair of gloves

1254
01:23:28,910 --> 01:23:32,800
this is considered the left hand and this is the right hand and you can

1255
01:23:32,800 --> 01:23:36,300
close the gloves you can make them fit one against the other

1256
01:23:36,300 --> 01:23:37,680
they will here

1257
01:23:37,690 --> 01:23:39,280
one another

1258
01:23:39,290 --> 01:23:40,850
across mirror planes

1259
01:23:40,860 --> 01:23:43,780
but they are not superimposed upon

1260
01:23:43,790 --> 01:23:47,650
you know as opposed to something like say propane if i take propane which is

1261
01:23:47,650 --> 01:23:51,090
also carbon sp three hybridized

1262
01:23:51,110 --> 01:23:53,160
propane in contrast has

1263
01:23:53,180 --> 01:23:54,940
math all above

1264
01:23:54,960 --> 01:23:56,690
and below

1265
01:23:57,340 --> 01:23:58,690
and that clearly

1266
01:23:59,800 --> 01:24:01,550
perfectly symmetric and

1267
01:24:01,560 --> 01:24:04,260
doesn't have such a glove like

1268
01:24:04,320 --> 01:24:10,680
feature such molecules that have we say a handedness

1269
01:24:10,690 --> 01:24:12,590
are called chiral

1270
01:24:12,690 --> 01:24:15,190
chiral from the greek word for here

1271
01:24:15,200 --> 01:24:17,930
so chirality is the property of

1272
01:24:17,930 --> 01:24:19,830
having handedness

1273
01:24:19,840 --> 01:24:22,350
nine super impose upon

1274
01:24:22,360 --> 01:24:27,130
we call these another term for these is stereo isomers

1275
01:24:27,170 --> 01:24:28,630
we can consider

1276
01:24:28,640 --> 01:24:34,030
chiral molecules stereo isomers

1277
01:24:34,050 --> 01:24:37,900
stereo listeners

1278
01:24:37,910 --> 01:24:43,160
and the different che hands if you will the different hands are called in and

1279
01:24:44,930 --> 01:24:47,030
and and tumours

1280
01:24:47,090 --> 01:24:51,930
we don't refer to one stereo lies somewhere in the other story my so we

1281
01:24:51,970 --> 01:24:56,340
refer to the and and humor coming from the greek word for mirror and uses

1282
01:24:56,340 --> 01:24:58,690
the greek word from here so these are

1283
01:24:59,810 --> 01:25:01,090
mirror images

1284
01:25:01,100 --> 01:25:04,440
the other thing about this is that they are optically active

1285
01:25:04,450 --> 01:25:08,960
and what they will do is they will take polarized light

1286
01:25:10,020 --> 01:25:11,800
rotated through

1287
01:25:12,300 --> 01:25:15,300
a degree

1288
01:25:15,340 --> 01:25:19,970
of polarisation here just to give you another example of the difference between something that's

1289
01:25:19,970 --> 01:25:24,020
chiral and i see the box at the top with no distinguishing features they can

1290
01:25:24,020 --> 01:25:25,800
be twisted and turned and made

1291
01:25:26,480 --> 01:25:31,300
superimposed over one another by putting these little features in the bottom corner we render

1292
01:25:31,310 --> 01:25:32,930
these boxes chiral

1293
01:25:32,980 --> 01:25:36,340
no matter how you twist and turn this box you will be able to superimpose

1294
01:25:36,880 --> 01:25:39,830
on top the other box

1295
01:25:39,930 --> 01:25:44,250
here's more complicated molecule that can come chemically identical

1296
01:25:44,960 --> 01:25:45,830
he has

1297
01:25:45,840 --> 01:25:49,580
a right-handed version are left-handed version

1298
01:25:49,590 --> 01:25:52,260
so let's talk about optical activity

1299
01:25:52,270 --> 01:25:56,680
the only reason i refer to this is that it gives the labels

1300
01:25:56,690 --> 01:25:59,330
that are used in referring to one

1301
01:25:59,340 --> 01:26:03,150
versus the other so if you have a light source that just gives

1302
01:26:03,160 --> 01:26:07,410
like that randomly polarized that is to say it's not polarized and then you put

1303
01:26:07,410 --> 01:26:12,750
it through a polarizing prism so that the light is polarized in a certain direction

1304
01:26:12,750 --> 01:26:15,540
others electric vector is only in one direction

1305
01:26:15,580 --> 01:26:18,960
now now the polarized light here it's indicating that

1306
01:26:18,970 --> 01:26:21,050
there is polarized vertically

1307
01:26:21,060 --> 01:26:28,140
this is the optically active substance which could include an aqueous solution of alani

1308
01:26:28,150 --> 01:26:33,220
and if the aqueous solution of alamein consists of only one and here are only

1309
01:26:33,220 --> 01:26:34,570
one and tumour

1310
01:26:34,630 --> 01:26:38,160
then when the polarized light passes through that solution

1311
01:26:38,170 --> 01:26:41,400
the plane of polarization will be rotated

1312
01:26:41,460 --> 01:26:47,860
a certain amount by interaction of the light with the electrons in the orbitals in

1313
01:26:47,880 --> 01:26:51,070
this particular molecule and

1314
01:26:51,380 --> 01:26:53,030
what you see here is

1315
01:26:53,060 --> 01:26:55,780
angle of rotation alpha

1316
01:26:55,790 --> 01:27:00,610
where alpha is proportional to the concentration of the chiral species and also the path

1317
01:27:00,610 --> 01:27:01,720
length through the

1318
01:27:01,920 --> 01:27:03,140
the solution

1319
01:27:03,150 --> 01:27:04,600
so if we put in both

1320
01:27:04,650 --> 01:27:08,430
and and tumors we expect no change if we put in one and actually

1321
01:27:08,440 --> 01:27:09,550
we will have

1322
01:27:09,560 --> 01:27:11,190
one direction

1323
01:27:11,200 --> 01:27:12,250
and so

1324
01:27:12,260 --> 01:27:14,040
it turns out that

1325
01:27:16,250 --> 01:27:21,100
the different and humorous will cause different directions of rotation and this is how they

1326
01:27:21,100 --> 01:27:24,580
are labeled so the one that i've shown here on the right

1327
01:27:24,610 --> 01:27:26,160
it will cause

1328
01:27:26,250 --> 01:27:30,260
a clockwise rotation of the light

1329
01:27:30,350 --> 01:27:32,090
and so it is termed

1330
01:27:33,000 --> 01:27:36,680
as indexed wrote tree from the latin word for word

1331
01:27:37,500 --> 01:27:38,670
dex wrote

1332
01:27:38,710 --> 01:27:40,890
the to tory

1333
01:27:40,970 --> 01:27:43,380
this the dexter for rotary form

1334
01:27:43,410 --> 01:27:45,750
and one here on the left will cause

1335
01:27:45,820 --> 01:27:49,940
the light the right age new here it's the it's the it's the plane of

1336
01:27:49,940 --> 01:27:54,610
polarization of the light it's a right so the plane of polarization

1337
01:27:54,620 --> 01:27:59,110
if it went through a solution that consist of only the and and humor

1338
01:27:59,190 --> 01:28:03,070
depicted on the left it would move in the left direction and even though the

1339
01:28:03,070 --> 01:28:08,990
latin word for left sinister they didn't call it sinister auditory the college level

1340
01:28:09,000 --> 01:28:10,870
wrote to tree

1341
01:28:10,920 --> 01:28:13,770
because they had slavic languages together

1342
01:28:13,840 --> 01:28:19,500
a report so level rotary is this one dexter rotary some will cause

1343
01:28:19,540 --> 01:28:21,200
we call this the positive

1344
01:28:21,210 --> 01:28:22,510
and and more

1345
01:28:22,520 --> 01:28:24,450
on the left when the negative

1346
01:28:24,460 --> 01:28:28,720
and and humor but in most of the reading the you'll encounter it will be

1347
01:28:28,770 --> 01:28:30,000
the the d

1348
01:28:30,010 --> 01:28:31,660
and the l

1349
01:28:31,720 --> 01:28:34,160
it turns out that only

1350
01:28:34,220 --> 01:28:36,540
the l four

1351
01:28:37,470 --> 01:28:42,050
only the l form of amino acids are found in proteins

1352
01:28:45,090 --> 01:28:48,940
in and humor

1353
01:28:48,980 --> 01:28:51,300
of amino acids

1354
01:28:51,300 --> 01:28:52,220
good afternoon everybody

1355
01:28:53,210 --> 01:28:57,530
it's my pleasure to introduce the fifth called the lecture series speakers today

1356
01:28:58,270 --> 01:29:02,660
and we are introducing professor neil james is university distinguished professor

1357
01:29:03,400 --> 01:29:05,730
your science and engineering at michigan state

1358
01:29:06,240 --> 01:29:09,060
it is also a member of the electrical faculty

1359
01:29:09,920 --> 01:29:14,620
doctor changes in species diversity in nineteen seventy three

1360
01:29:16,230 --> 01:29:16,890
something like this

1361
01:29:17,780 --> 01:29:21,570
distinguished researchers here the pattern recognition computer vision

1362
01:29:22,150 --> 01:29:22,890
and biometrics

1363
01:29:23,940 --> 01:29:25,030
if you look at his

1364
01:29:25,590 --> 01:29:26,870
can online you

1365
01:29:27,640 --> 01:29:31,560
quickly come across some rather impressive numbers five hundred ninety seven papers

1366
01:29:32,200 --> 01:29:33,810
eighty thousand citations

1367
01:29:34,680 --> 01:29:38,110
h-index and one hundred thirty three which in computer science second

1368
01:29:39,660 --> 01:29:45,410
thirty six species students advised in his career eighteen those since the year two thousand

1369
01:29:45,870 --> 01:29:46,310
i happen

1370
01:29:46,480 --> 01:29:46,950
one of them

1371
01:29:49,940 --> 01:29:51,060
better for the experience

1372
01:29:51,480 --> 01:29:51,710
you see

1373
01:29:52,190 --> 01:29:52,830
thirty books

1374
01:29:53,450 --> 01:29:54,360
six patterns

1375
01:29:55,930 --> 01:29:58,220
fell i hear are actually

1376
01:29:58,670 --> 01:29:59,190
it in

1377
01:29:59,840 --> 01:30:00,620
the recipe he

1378
01:30:03,200 --> 01:30:05,420
that's for sciences so without further ado

1379
01:30:06,770 --> 01:30:09,880
history professor jane to speak about large scale data clustering

1380
01:30:18,150 --> 01:30:18,540
i'd like

1381
01:30:19,690 --> 01:30:20,780
to a little bit about

1382
01:30:22,610 --> 01:30:25,830
there are some problems in science is known it

1383
01:30:26,230 --> 01:30:27,240
become more interesting

1384
01:30:27,920 --> 01:30:29,020
at the time

1385
01:30:29,270 --> 01:30:29,750
so far

1386
01:30:30,300 --> 01:30:32,270
data clustering is one such problem

1387
01:30:32,810 --> 01:30:35,570
i was first introduced the last thing i'd like

1388
01:30:37,860 --> 01:30:38,850
in nineteen seventy

1389
01:30:39,690 --> 01:30:40,900
at the time was

1390
01:30:41,580 --> 01:30:43,190
to not published

1391
01:30:43,850 --> 01:30:44,670
right now

1392
01:30:45,800 --> 01:30:47,050
draft a copy of the book

1393
01:30:47,810 --> 01:30:48,290
and the

1394
01:30:50,690 --> 01:30:52,950
it's very easy to describe the problem

1395
01:30:53,540 --> 01:30:55,880
the problem is very simple for people

1396
01:30:56,310 --> 01:30:56,910
in this room

1397
01:30:57,520 --> 01:30:58,890
can be partitioned into

1398
01:30:59,840 --> 01:31:01,950
so the number of rules based on some

1399
01:31:03,580 --> 01:31:03,950
that's all

1400
01:31:04,630 --> 01:31:06,640
that's what that's what clustering is

1401
01:31:08,310 --> 01:31:10,820
and that's why has fascinated scientists

1402
01:31:11,420 --> 01:31:14,080
every discipline information from biology to

1403
01:31:14,880 --> 01:31:17,470
computer science to marketing psychology

1404
01:31:18,930 --> 01:31:20,300
anyway these data

1405
01:31:21,350 --> 01:31:22,140
has to deal with

1406
01:31:24,500 --> 01:31:25,430
two ways about it

1407
01:31:26,030 --> 01:31:28,190
and the reason why it's getting more interest now

1408
01:31:28,850 --> 01:31:31,140
because all the data we see the web

1409
01:31:31,620 --> 01:31:33,190
the text images

1410
01:31:33,820 --> 01:31:34,820
all of the new

1411
01:31:35,640 --> 01:31:36,520
you know you've

1412
01:31:37,400 --> 01:31:38,750
hundreds of millions of

1413
01:31:42,730 --> 01:31:43,170
on you

1414
01:31:44,040 --> 01:31:45,850
you have to somehow organised state

1415
01:31:46,840 --> 01:31:48,610
data clustering is a convenient way

1416
01:31:49,310 --> 01:31:50,730
so in this organization

1417
01:31:52,800 --> 01:31:54,600
it had over fifty years of history

1418
01:31:55,630 --> 01:31:56,800
and let me also w

1419
01:31:58,130 --> 01:31:59,800
simplest clustering algorithm

1420
01:32:00,200 --> 01:32:01,190
it's called kings

1421
01:32:01,590 --> 01:32:01,900
some of

1422
01:32:03,470 --> 01:32:05,260
you can write the keys at time

1423
01:32:06,030 --> 01:32:07,170
one in ten lines of

1424
01:32:09,190 --> 01:32:11,780
and it is still the most widely used

1425
01:32:13,340 --> 01:32:13,810
even though

1426
01:32:14,920 --> 01:32:15,350
all the

1427
01:32:16,220 --> 01:32:18,910
the problem is that it was published

1428
01:32:20,630 --> 01:32:21,290
no good

1429
01:32:26,990 --> 01:32:27,340
can you

1430
01:32:31,030 --> 01:32:32,400
so so this problem

1431
01:32:33,070 --> 01:32:34,140
it's really exciting

1432
01:32:34,770 --> 01:32:35,300
and now that

1433
01:32:35,770 --> 01:32:40,060
i did the title of my talk for large data data with document

1434
01:32:40,680 --> 01:32:41,390
it doesn't

1435
01:32:43,200 --> 01:32:46,200
so i know it doesn't give you some labelled data

1436
01:32:47,450 --> 01:32:48,310
and then the

1437
01:32:49,090 --> 01:32:50,290
introduction to clustering

1438
01:32:50,880 --> 01:32:51,320
and then

1439
01:32:51,910 --> 01:32:52,350
some of the

1440
01:32:54,200 --> 01:32:55,170
my keys to the

1441
01:32:57,960 --> 01:32:58,920
likely contd

1442
01:33:01,110 --> 01:33:03,070
large scale clustering and all that

1443
01:33:03,410 --> 01:33:05,080
cluster one billion points

1444
01:33:06,700 --> 01:33:08,200
thousands of features into

1445
01:33:08,750 --> 01:33:10,280
tens of thousands of clusters

1446
01:33:14,000 --> 01:33:15,830
so this is a city of london

1447
01:33:18,480 --> 01:33:20,380
the reason we are doing is basically

1448
01:33:20,890 --> 01:33:22,630
an approximation in

1449
01:33:25,290 --> 01:33:27,060
so some statistics about the

1450
01:33:28,620 --> 01:33:29,450
the following

1451
01:33:32,480 --> 01:33:33,220
forty years ago

1452
01:33:33,630 --> 01:33:35,540
started doing clustering the points where

1453
01:33:36,110 --> 01:33:39,480
large one of the was

1454
01:33:40,970 --> 01:33:41,650
last time

1455
01:33:41,730 --> 01:33:43,480
link is not on the

1456
01:33:45,570 --> 01:33:47,940
but now not going to be killed by the way

1457
01:33:48,330 --> 01:33:49,320
it's not to

1458
01:33:51,110 --> 01:33:51,270
you know

1459
01:33:51,720 --> 01:33:52,390
the power

1460
01:33:52,520 --> 01:33:52,880
only one

1461
01:33:53,310 --> 01:33:55,180
so now know the new

1462
01:33:55,560 --> 01:33:56,790
when we see the lights

1463
01:33:57,300 --> 01:33:58,490
the data was created

1464
01:33:59,260 --> 01:34:01,500
and the estimated by thousand fifteen

1465
01:34:02,050 --> 01:34:02,320
will be

1466
01:34:04,850 --> 01:34:06,160
for some reason idea

1467
01:34:06,920 --> 01:34:07,990
introduced nature

1468
01:34:08,650 --> 01:34:09,540
that's not just me

1469
01:34:10,020 --> 01:34:11,120
one data

1470
01:34:11,790 --> 01:34:13,490
it's also velocities is

1471
01:34:14,390 --> 01:34:15,010
the world

1472
01:34:15,650 --> 01:34:16,420
aspect to it

1473
01:34:17,090 --> 01:34:21,050
the nineteen eighties heterogeneous data is not all numbers

1474
01:34:22,790 --> 01:34:23,930
edition of the

1475
01:34:24,560 --> 01:34:25,540
so heterogeneous

1476
01:34:26,000 --> 01:34:26,380
it's also

1477
01:34:28,320 --> 01:34:30,190
structured data and unstructured

1478
01:34:32,780 --> 01:34:33,170
so you

1479
01:34:33,690 --> 01:34:35,300
some statistics on on

1480
01:34:36,300 --> 01:34:37,900
information is on the on

1481
01:34:39,210 --> 01:34:39,820
so these

1482
01:34:40,710 --> 01:34:42,170
i'm sure numbers exceeded

1483
01:34:43,400 --> 01:34:45,320
nine hundred million million o

1484
01:34:45,740 --> 01:34:46,920
two one five billion

1485
01:34:48,360 --> 01:34:50,240
five hundred divided by data

1486
01:34:50,510 --> 01:34:51,930
have to

1487
01:34:53,270 --> 01:34:54,460
one million years old

1488
01:34:56,180 --> 01:34:57,110
have to do with you

1489
01:34:58,490 --> 01:34:59,680
well i was smart

1490
01:35:01,520 --> 01:35:03,160
the interesting statistics

1491
01:35:03,850 --> 01:35:04,900
but in the house

1492
01:35:06,400 --> 01:35:08,650
be many more like was both

1493
01:35:10,820 --> 01:35:11,720
it is also in the

1494
01:35:15,800 --> 01:35:18,930
one hundred twenty five million users rating it

1495
01:35:19,370 --> 01:35:19,770
tweets per

1496
01:35:22,370 --> 01:35:24,200
this is mind-boggling amount

1497
01:35:25,220 --> 01:35:27,110
that is being generated somewhat

1498
01:35:27,910 --> 01:35:28,880
statistics from

1499
01:35:31,060 --> 01:35:32,150
one five million

1500
01:35:33,700 --> 01:35:33,960
every day

1501
01:35:35,010 --> 01:35:36,430
to forty thousand

1502
01:35:38,380 --> 01:35:39,860
more than one trillion euros

1503
01:35:40,980 --> 01:35:45,350
so the idea that all the data you need to extract information from it so that

1504
01:35:45,840 --> 01:35:47,080
you can make it lies

1505
01:35:49,870 --> 01:35:51,960
so that's what this is what to do with it

1506
01:35:52,070 --> 01:35:54,060
next generation to make decisions

1507
01:35:55,690 --> 01:35:57,790
even companies like walmart

1508
01:35:57,790 --> 01:36:00,620
and similar result for another example

1509
01:36:00,640 --> 01:36:03,620
OK pretty much finished actually just wanted to draw

1510
01:36:03,620 --> 01:36:04,690
attention to

1511
01:36:05,250 --> 01:36:11,520
an important area that i haven't covered in detail yet that's the combination of MCMC

1512
01:36:11,960 --> 01:36:20,250
with particle filters and there are two principal schemes that that i'm aware of there

1513
01:36:20,250 --> 01:36:26,520
are other of other things with different flavours particle the so-called particle MCMC which is

1514
01:36:26,520 --> 01:36:33,690
an iterative algorithm for batch parameter estimation but here i'm talking about sequential schemes that

1515
01:36:33,690 --> 01:36:34,650
use MCMC

1516
01:36:37,850 --> 01:36:43,120
so back it should be there about that so the idea

1517
01:36:43,140 --> 01:36:45,960
in the first game is very simple

1518
01:36:46,000 --> 01:36:52,770
it says that after resampling importance sampling filter you've got some particle trajectories that are

1519
01:36:52,770 --> 01:36:57,500
drawn at least approximately from the smoothing density up to time t

1520
01:36:59,370 --> 01:37:01,100
since those already

1521
01:37:01,100 --> 01:37:04,000
nominally at least drawn from the correct entity

1522
01:37:04,120 --> 01:37:10,460
if i simply applied an MCMC kernel with this thing as its target density

1523
01:37:10,520 --> 01:37:15,520
for example you common thing to do would be to apply fixed like gives

1524
01:37:15,540 --> 01:37:18,390
gives within a metropolis hastings

1525
01:37:18,410 --> 01:37:20,420
sample on the

1526
01:37:20,440 --> 01:37:24,770
on on a lack of data points going some way into the past

1527
01:37:24,830 --> 01:37:26,750
conditional upon everything else

1528
01:37:26,770 --> 01:37:31,600
then the intuition is that as the MCMC converges the particle representation is going to

1529
01:37:31,600 --> 01:37:36,440
get closer to the true target density so we can actually just improve performance by

1530
01:37:36,440 --> 01:37:39,480
applying a few iterations of our chosen favor

1531
01:37:39,640 --> 01:37:42,770
mcmc scheme or particles

1532
01:37:42,830 --> 01:37:48,600
because we are nominally already converged we don't have to diagnose really the convergence of

1533
01:37:48,620 --> 01:37:49,520
the chains

1534
01:37:50,150 --> 01:37:53,900
we just know will likely to improve things a little bit by running these a

1535
01:37:53,900 --> 01:37:59,250
few steps of these MCMC is and this is the the well-known resample move scheme

1536
01:37:59,350 --> 01:38:04,770
berzuini in-jokes from nineteen ninety eight some related work on similar scheme down a little

1537
01:38:04,770 --> 01:38:09,040
bit about quetion clyde and you very effective schemes

1538
01:38:09,060 --> 01:38:13,980
because it doesn't remove the importance sampling element you still waiting in then resampling before

1539
01:38:13,980 --> 01:38:17,620
you go into your MCMC so i think this is an add-on it's just basically

1540
01:38:17,620 --> 01:38:23,210
the particle filter then run some MCMC on a limited part of the state space

1541
01:38:23,250 --> 01:38:24,940
and improve the situation

1542
01:38:26,620 --> 01:38:27,910
but slightly more

1543
01:38:27,910 --> 01:38:33,830
it was not really a more recent idea but a perhaps more fundamental idea

1544
01:38:33,890 --> 01:38:37,640
it's simply get rid of the importance sampling altogether but still stay

1545
01:38:37,670 --> 01:38:39,350
within the sequential

1546
01:38:40,980 --> 01:38:42,120
and you'll recall

1547
01:38:42,150 --> 01:38:44,120
that the SMC scheme

1548
01:38:44,140 --> 01:38:49,500
can be thought of this is the first thing i revised started this talk SMC

1549
01:38:49,500 --> 01:38:54,060
scheme is simply approximating the updated filtering density

1550
01:38:54,100 --> 01:38:59,520
in terms of the previous particle representation from not t time some other terms the

1551
01:38:59,520 --> 01:39:03,410
state transition density the observation density of constant

1552
01:39:04,890 --> 01:39:10,350
or equivalently so that's represented on the joint space of the path we can integrate

1553
01:39:10,350 --> 01:39:15,140
out x not through t and just look at the marginal t plus one then

1554
01:39:15,140 --> 01:39:22,750
you have the formation of a state transition kernels overall centered on all the particles

1555
01:39:22,790 --> 01:39:24,410
nothing to say

1556
01:39:24,420 --> 01:39:28,640
what see seeing what monte carlo algorithm you have to use here so the

1557
01:39:28,810 --> 01:39:34,330
the point is why not simply run MCMC on this or this or combinations of

1558
01:39:34,350 --> 01:39:35,330
the two

1559
01:39:35,350 --> 01:39:44,080
so this one has some benefits of being marginalized spaces reduced dimensional space but very

1560
01:39:44,080 --> 01:39:51,000
heavy computational at evaluating this likelihood function in the MCMC because you've got salvation over

1561
01:39:51,000 --> 01:39:53,150
and is this

1562
01:39:53,170 --> 01:39:57,080
joint space that doesn't apply because this these is direct functions so you don't end

1563
01:39:57,080 --> 01:40:01,350
up having to evaluate all and these reach likelihood

1564
01:40:01,370 --> 01:40:08,250
evaluation in the MCMC so that this one might be statistically better but very expensive

1565
01:40:08,270 --> 01:40:11,290
to to compute in practice we would prefer this one

1566
01:40:11,330 --> 01:40:15,500
and you can run MCMC directly on this target

1567
01:40:15,980 --> 01:40:21,710
using whatever your favourite scheme is there gibbs sampler you can apply to regenerate the

1568
01:40:22,020 --> 01:40:28,350
the initial state sequence from its point mass representation run metropolis hastings on elements of

1569
01:40:28,370 --> 01:40:31,920
the state vector and that's the important point actually is you can spread the state

1570
01:40:31,920 --> 01:40:36,500
vector ron gibbs sampling type steps on bits of it conditional on the other you

1571
01:40:36,500 --> 01:40:41,000
not start with the importance sampling paradigm that says you have to generate the whole

1572
01:40:41,000 --> 01:40:44,920
that in one go and if it has a long way to go about fit

1573
01:40:44,920 --> 01:40:46,440
to the density tough

1574
01:40:46,460 --> 01:40:54,270
you've lost the game so you've got the possibility of converging refining your sampling representation

1575
01:40:54,310 --> 01:40:58,710
so i don't really goes back right back to some some work in nineteen ninety

1576
01:40:58,710 --> 01:41:05,670
seven by one jokes and can they operated sample from the joint space a recently

1577
01:41:05,670 --> 01:41:09,290
more easily the computer vision people have done things on this

1578
01:41:09,310 --> 01:41:14,250
the marginal space with reversible jump samples but they are very effective schemes and quite

1579
01:41:14,250 --> 01:41:21,100
promising we've some papers in in just about to go to print at the moment

1580
01:41:21,120 --> 01:41:26,460
developed these schemes further show how how effective they can be also very difficult structured

1581
01:41:26,460 --> 01:41:33,000
state space models violating learning hierarchical model sequentially over time effectively

1582
01:41:33,960 --> 01:41:37,920
but i really have run out of time more than run out of time i

1583
01:41:37,920 --> 01:41:38,790
hope i've

1584
01:41:38,960 --> 01:41:45,920
it the particle filters are very interesting thing to pursue for hard problems powerful computationally

1585
01:41:47,500 --> 01:41:52,520
colour most of the basics i couldn't get through everything by any means in in

1586
01:41:52,520 --> 01:41:57,140
in the three hours in particular are not covered very much about parameter estimation so

1587
01:41:57,190 --> 01:42:02,210
brief example of that with our estimation of alpha and they are stable noise i

1588
01:42:02,210 --> 01:42:06,850
didn't get a chance to to talk about SMC samplers and population monte carlo which

1589
01:42:06,850 --> 01:42:11,000
is quite a hot topic at the moment in the area

1590
01:42:11,000 --> 01:42:15,390
seventy exist in all different levels

1591
01:42:15,410 --> 01:42:21,230
so for for example when we use sensors to detect the presence of animals

1592
01:42:21,360 --> 01:42:26,630
but when reports is a movement of animals you might not be correct

1593
01:42:26,690 --> 01:42:31,210
he made mistake other phenomenon as a movement of the animals

1594
01:42:31,230 --> 01:42:37,070
so in this level and uncertainty because it's seeing whether this event happens or not

1595
01:42:37,070 --> 01:42:40,050
so it's because the existence uncertainty

1596
01:42:40,070 --> 01:42:42,910
so this is the up

1597
01:42:42,910 --> 01:42:46,410
up to

1598
01:42:46,470 --> 01:42:53,010
go figure something so this is because the term couple level of certainty

1599
01:42:53,150 --> 01:42:57,740
so in this example and opted to take a probability to appear

1600
01:42:57,800 --> 01:42:59,470
in the table

1601
01:42:59,520 --> 01:43:02,880
but the examples for example the the the the example

1602
01:43:02,910 --> 01:43:06,050
we know that there is one record of posthumous

1603
01:43:06,130 --> 01:43:10,450
the thing that we were not sure about is the social security number of miss

1604
01:43:10,490 --> 01:43:13,300
you might be one eighty five or seven eighty five

1605
01:43:13,350 --> 01:43:17,280
so in this example the uncertainty only lies in one attribute

1606
01:43:17,330 --> 01:43:20,080
we just don't know is correct

1607
01:43:20,080 --> 01:43:21,940
and that of this attribute

1608
01:43:22,020 --> 01:43:24,660
it's called the output level of uncertainty

1609
01:43:24,690 --> 01:43:29,360
so in this actually level uncertainty and that to build an object takes a few

1610
01:43:29,360 --> 01:43:30,720
possible values

1611
01:43:30,750 --> 01:43:35,170
and then we may have a probability density function over the possible values

1612
01:43:35,220 --> 01:43:40,880
i will introduce the two different uncertainty one by one

1613
01:43:40,940 --> 01:43:45,030
so first of all the publicity that this model is always

1614
01:43:45,080 --> 01:43:48,920
after used to fly up to the top level of uncertainty

1615
01:43:48,940 --> 01:43:54,980
in this example this is are table all the speed of car detected by radar

1616
01:43:55,030 --> 01:43:58,620
because the radio radar and they may be interfered by

1617
01:43:58,640 --> 01:44:04,420
high voltage lines or the close by car interference so the problem may not be

1618
01:44:04,420 --> 01:44:06,420
one hundred percent correct

1619
01:44:07,500 --> 01:44:13,470
for example for t one contains the time relocation car make plate number and speed

1620
01:44:13,470 --> 01:44:14,620
of the a car

1621
01:44:14,640 --> 01:44:20,690
but due to the uncertainty we we may associate with a confidence value with this

1622
01:44:21,470 --> 01:44:26,030
it means that this temple only takes the probability of zero point four

1623
01:44:26,030 --> 01:44:29,070
to be existing in that table

1624
01:44:29,120 --> 01:44:35,970
and in addition to that the plate number of cars are identified by human operators

1625
01:44:36,060 --> 01:44:38,960
this may also introduce uncertainty

1626
01:44:38,970 --> 01:44:39,900
for example

1627
01:44:40,060 --> 01:44:43,120
t two and t three there the

1628
01:44:43,220 --> 01:44:46,680
o records about the same card the plate number fame

1629
01:44:46,690 --> 01:44:50,120
but the passion time quite close

1630
01:44:50,150 --> 01:44:56,690
with the addition can quite close by the relocation are far away

1631
01:44:56,690 --> 01:44:59,900
and also the reading of speed are quite different

1632
01:44:59,910 --> 01:45:04,350
so between these two titles we know that only one could be true

1633
01:45:04,380 --> 01:45:06,260
we use a generation rule

1634
01:45:06,280 --> 01:45:10,680
to specify this explosiveness between the two temples

1635
01:45:10,690 --> 01:45:15,570
the same situation of also happens to t four and t five

1636
01:45:15,620 --> 01:45:21,490
so in summary in probabilistic database you can test a lot a set of probabilistic

1637
01:45:22,340 --> 01:45:26,040
and each table the values of each table are sorted

1638
01:45:26,090 --> 01:45:30,510
but each table carries existing or membership probability

1639
01:45:30,560 --> 01:45:38,430
in addition we may have generation rules to specify the constraints among those couples

1640
01:45:38,440 --> 01:45:44,350
then we can make another example in the survey data we have records about smith

1641
01:45:44,350 --> 01:45:50,280
and the wrong when we create an uncertain table to describe in this case

1642
01:45:50,280 --> 01:45:52,490
in this uncertain table we have

1643
01:45:52,500 --> 01:45:53,870
four records

1644
01:45:53,870 --> 01:46:00,150
OK so for this last bit going to talk about the sierra called belief

1645
01:46:00,200 --> 01:46:03,260
change article believe change what people call belief revision

1646
01:46:03,780 --> 01:46:08,910
and as i say the basic idea again this is another application of logic in

1647
01:46:08,910 --> 01:46:10,910
this case we're just going to look at the

1648
01:46:10,940 --> 01:46:14,510
propositional case there's a lot of work on the first order case and so on

1649
01:46:16,190 --> 01:46:20,250
again people to tackle this problem using different logics modal logics and so on in

1650
01:46:21,370 --> 01:46:23,920
but as we can look at a fairly simple

1651
01:46:23,940 --> 01:46:26,860
propositional model get an application of logic

1652
01:46:26,880 --> 01:46:30,530
as an application to the following problems

1653
01:46:30,570 --> 01:46:32,640
you want to sort of figure out how

1654
01:46:32,650 --> 01:46:37,640
some reason who is maintaining beliefs about their environment

1655
01:46:37,680 --> 01:46:41,460
firstly how they maintain their police and secondly how those beliefs

1656
01:46:41,650 --> 01:46:43,140
should change

1657
01:46:44,710 --> 01:46:49,320
the reason to obtain new information about the

1658
01:46:49,520 --> 01:46:54,390
so that's state that sort of simple statement of the problem

1659
01:46:54,460 --> 01:47:05,570
anyway the beginning never wants to go forward

1660
01:47:08,210 --> 01:47:09,210
OK now

1661
01:47:09,250 --> 01:47:16,590
as i say now what we're going to look at a particular price are quite

1662
01:47:16,590 --> 01:47:20,310
of few approach to this problem but just to try and introduce the area going

1663
01:47:20,310 --> 01:47:21,120
to take

1664
01:47:21,140 --> 01:47:25,280
perhaps the approach that's the most commonly encountered one in literature

1665
01:47:25,340 --> 01:47:28,400
now what will see is that at the end of the day this approach that

1666
01:47:28,420 --> 01:47:33,060
sits at one end of the spectrum which is probably the more idealized in the

1667
01:47:33,070 --> 01:47:35,280
spectrum in terms of belief change approaches

1668
01:47:35,390 --> 01:47:40,210
but when you leave reading literature billy change this is invariably approach the people mentioned

1669
01:47:40,250 --> 01:47:41,590
and measure the

1670
01:47:41,620 --> 01:47:46,250
they're approaching its

1671
01:47:46,260 --> 01:47:49,670
OK so let's take an example suppose you have the following believes these ones are

1672
01:47:50,960 --> 01:47:55,390
and if they say that the word caught in this trap is this one

1673
01:47:55,400 --> 01:47:58,170
secondly the but according to track comes from sweden

1674
01:47:58,180 --> 01:48:03,250
sweden is part of europe and all europeans wonder so these are ablaze

1675
01:48:03,340 --> 01:48:05,900
now from the six possibilities in

1676
01:48:05,910 --> 01:48:11,490
consequences so one of the consequences that the bird caught in the trap is white

1677
01:48:11,560 --> 01:48:17,890
why is that the case well we know that all europeans once alliance sweden this

1678
01:48:17,890 --> 01:48:21,310
part of your according to track conditions within

1679
01:48:22,930 --> 01:48:25,360
should be sufficient to prevent calls

1680
01:48:25,440 --> 01:48:30,130
OK now suppose we're told that the boy caught in the trap is black

1681
01:48:30,150 --> 01:48:31,190
now that

1682
01:48:31,210 --> 01:48:35,940
contradicts the belief that we currently have so obviously there's something wrong

1683
01:48:35,960 --> 01:48:39,360
in our in this set of beliefs that we hold

1684
01:48:39,370 --> 01:48:42,030
so the question to you is which

1685
01:48:42,050 --> 01:48:44,460
a sentence or sentences

1686
01:48:44,540 --> 01:48:47,240
of the initial belief said

1687
01:48:47,250 --> 01:48:49,030
would you give up

1688
01:48:49,120 --> 01:48:55,970
OK great why

1689
01:48:55,990 --> 01:49:03,590
so you think it's like the last one you take before you make consequence

1690
01:49:03,610 --> 01:49:04,970
right OK

1691
01:49:04,990 --> 01:49:08,250
again the exile that's great

1692
01:49:08,300 --> 01:49:09,530
so one great

1693
01:49:16,940 --> 01:49:22,300
one for the has any other guesses as to what you might throw away

1694
01:49:22,590 --> 01:49:30,580
good beginning there while the second one

1695
01:49:30,590 --> 01:49:31,370
right good

1696
01:49:31,370 --> 01:49:34,220
good so it sort of sounds a bit dodgy right you might be able to

1697
01:49:34,220 --> 01:49:36,780
figure that out just by looking at this

1698
01:49:36,830 --> 01:49:40,160
but you know what got apologies to go out there and actually take the DNA

1699
01:49:40,160 --> 01:49:46,310
and it just happened that swedish d

1700
01:49:46,340 --> 01:49:47,720
could be

1701
01:49:47,810 --> 01:49:52,490
i didn't know that the birds were in this way

1702
01:49:52,550 --> 01:49:57,810
anyone else want to hazard

1703
01:49:57,830 --> 01:50:02,990
when only one or maybe something else

1704
01:50:03,220 --> 01:50:07,310
all europeans wonder why why is that

1705
01:50:07,610 --> 01:50:10,060
because you probably need a lot of to

1706
01:50:10,070 --> 01:50:13,190
figure that out right in a lot of europe efficiently was once you need to

1707
01:50:13,190 --> 01:50:16,420
figure out where the european and then way

1708
01:50:16,820 --> 01:50:22,060
what about the third one

1709
01:50:22,060 --> 01:50:32,230
you're all pretty happy with the way

1710
01:50:35,600 --> 01:50:39,570
so it's not part of the european union i decided to call to the

1711
01:50:41,250 --> 01:50:44,750
OK now my claim is that if you take it these are expressed in logical

1712
01:50:44,750 --> 01:50:48,500
logic which is what we want to do it then there's no reason was released

1713
01:50:48,500 --> 01:50:50,200
at this point

1714
01:50:50,220 --> 01:50:53,490
claiming that any of these forms is better than any other

1715
01:50:53,560 --> 01:50:57,980
so as far as i'm concerned any of these funds could be removed

1716
01:50:58,050 --> 01:50:59,970
any of them is a good choice

1717
01:50:59,980 --> 01:51:01,700
the only reason

1718
01:51:01,720 --> 01:51:03,750
we sort of triumph a

1719
01:51:03,760 --> 01:51:04,940
so performers

1720
01:51:04,950 --> 01:51:08,540
so the pre leaf for emotional factors or perhaps maybe we know a little bit

1721
01:51:08,540 --> 01:51:11,720
more than i explicitly written down on the

1722
01:51:11,730 --> 01:51:15,580
on the slide here maybe some you might claim that was not just a matter

1723
01:51:15,610 --> 01:51:18,700
whether believe something i don't believe something is allowed to shades of gray here and

1724
01:51:19,510 --> 01:51:25,100
really strongly believe that you know europe a source which this part of europe

1725
01:51:25,110 --> 01:51:28,130
but i less strongly believe that you know one

1726
01:51:28,750 --> 01:51:31,800
that all europeans wonder why something like

1727
01:51:32,720 --> 01:51:35,950
in this slide here are just illustrated one example is the same as far as

1728
01:51:35,950 --> 01:51:38,640
i'm concerned you can remove any of those sentences

1729
01:51:38,680 --> 01:51:42,260
what i've done is i've done another sort of trivial thing and that is taken

1730
01:51:42,260 --> 01:51:43,620
one of the sentences

1731
01:51:43,670 --> 01:51:47,320
that all your spain's wonder why have we can slightly

1732
01:51:47,430 --> 01:51:51,300
and a sense what i've done is i've taken it sensorimotor but i've replaced its

1733
01:51:51,300 --> 01:51:55,310
energy from moving and throwing it away which is sort of what i was originally

1734
01:51:55,310 --> 01:51:58,860
it is a taking the sentence i removed it i've replaced by

1735
01:51:58,870 --> 01:52:00,680
one of its consequences

1736
01:52:00,680 --> 01:52:02,790
and this consequences that

1737
01:52:02,800 --> 01:52:06,510
all europeans ones except for some of the swedish ones away

1738
01:52:06,540 --> 01:52:10,740
but as i say this point if we will have to transcend the problem into

1739
01:52:11,680 --> 01:52:15,060
logic propositional formulas then there's no

1740
01:52:15,390 --> 01:52:18,620
the reason to favour one over the

1741
01:52:18,630 --> 01:52:23,870
OK so the lesson at this point is the logical considerations alone not sufficient to

1742
01:52:23,870 --> 01:52:26,740
answer this question is going to need to have something more

1743
01:52:26,750 --> 01:52:28,620
large enough to assign

1744
01:52:28,620 --> 01:52:33,120
degrees of belief maybe probabilities and to do something to these formulas to help me

1745
01:52:33,120 --> 01:52:36,440
answer this question to make this choice

1746
01:52:36,550 --> 01:52:39,690
i think this is going to have a look at the general idea belief change

1747
01:52:39,690 --> 01:52:43,370
and then i'm going to focus on this AGM account of belief change which is

1748
01:52:43,370 --> 01:52:47,130
the most common one literature

1749
01:52:47,180 --> 01:52:52,810
h images the initials of the people that came up with the initial idea

1750
01:52:52,850 --> 01:52:53,970
OK so

1751
01:52:55,470 --> 01:52:58,580
so the diagrammatic form this is what

1752
01:52:58,600 --> 01:53:00,180
the problem looks like

1753
01:53:00,190 --> 01:53:03,680
you've got your reason in there are some in some belief state

1754
01:53:03,690 --> 01:53:08,790
o epistemic state in computing tend to like abuse all the words in the english

1755
01:53:10,220 --> 01:53:13,630
the stomach is more about knowledge belief but anyway just take it to be some

1756
01:53:13,630 --> 01:53:17,050
be the number of common friends to people have and this is the probability that

1757
01:53:17,050 --> 01:53:21,730
they will send email to each other and again the whole reason for this pot

1758
01:53:21,730 --> 01:53:28,070
here is that again we see the diminishing returns type of curve where first few having

1759
01:53:28,070 --> 01:53:31,790
a few friends adds a lot to the curve and then less and less

1760
01:53:31,790 --> 01:53:35,930
this is exactly if you remember from before we had this submodularity property right

1761
01:53:35,940 --> 01:53:41,470
and it seems that properties is good right because we observe this diminishing returns

1762
01:53:41,490 --> 01:53:47,190
so this is now let's take a step back and see what we are really doing

1763
01:53:47,210 --> 01:53:51,810
right for example for viral marketing for the study I will go into more

1764
01:53:51,810 --> 01:53:58,090
detail about it later all we see is that some node received the i-th recommendation

1765
01:53:58,090 --> 01:54:02,590
and then purchases a product or doesn't do anything for communities again what we see

1766
01:54:02,590 --> 01:54:04,610
is that that some time T

1767
01:54:04,610 --> 01:54:09,550
they they decided we see behavior of their friends and then we see that the particularly

1768
01:54:09,550 --> 01:54:14,610
node decided to join the community so there are there are there are questions like when

1769
01:54:14,610 --> 01:54:20,350
did this node become aware of the recommendations of of a friend right so when when when

1770
01:54:20,500 --> 01:54:25,510
when did they became aware of I know that their friends adopted how did this translate

1771
01:54:25,510 --> 01:54:31,290
into their decision to act right I mean we only have like one

1772
01:54:31,290 --> 01:54:35,190
trace of of of what was going on right we don't know whether they

1773
01:54:35,190 --> 01:54:40,430
were watching television or not what what newspapers they read and so on and also we don't know

1774
01:54:40,450 --> 01:54:48,640
what was the lag between the the decision to buy and the act right so these are all questions

1775
01:54:48,660 --> 01:54:55,550
one can ask here and go exploi explore them here's there are also more subtleties to

1776
01:54:55,550 --> 01:54:59,710
everything so for example here here's one one thing that you can you can ask right so

1777
01:54:59,710 --> 01:55:04,090
if this is if this is some predefined some community of people and now we have

1778
01:55:04,090 --> 01:55:09,250
two candidates to to join right they all have like three friends in the

1779
01:55:09,250 --> 01:55:16,170
group but the friends of Y are all connected among themselves while X has like

1780
01:55:16,170 --> 01:55:19,110
friends that don't know each other and the question is who is more likely to

1781
01:55:19,110 --> 01:55:26,550
join right and there are two competing theories or two possible explanations for this so first

1782
01:55:26,550 --> 01:55:31,730
first one is called the information argument and the information argument says that unconnected friends

1783
01:55:31,730 --> 01:55:37,290
give you the independent support so this would mean that having independent friends is better because they sort of

1784
01:55:37,290 --> 01:55:43,350
each one gives you a independent opinion and having more independent opinions is better so

1785
01:55:43,390 --> 01:55:49,390
this theory would say that X is more likely to join the social capital arguments on the

1786
01:55:49,390 --> 01:55:55,080
other hand says that trust in having friends who know each other is what we really

1787
01:55:55,080 --> 01:55:58,890
value right so we want to have we don't we want to have people that

1788
01:55:58,890 --> 01:56:02,230
we want to have a set of friends who are all friends among themselves so

1789
01:56:02,230 --> 01:56:07,590
that we can hang hang out with them once we join the group right so this would mean that you

1790
01:56:07,590 --> 01:56:13,030
get independent support while here you have you have a highly connected set of friends in

1791
01:56:13,030 --> 01:56:17,190
there and that gives you a lot of social capital because you can hang out with them

1792
01:56:17,270 --> 01:56:27,390
so  for the livejournal data set we can go and measure this so we can ask how

1793
01:56:27,390 --> 01:56:34,030
does the community joining probability increase with the number of connections between the friends and

1794
01:56:34,030 --> 01:56:39,090
what turns out that is actually that the and the connectedness of these friends

1795
01:56:39,090 --> 01:56:43,980
if you want to if if you if you define these as a

1796
01:56:43,980 --> 01:56:48,480
as a prediction task where you want to be able to predict whether a node

1797
01:56:48,520 --> 01:56:52,510
will join the network join the group or not and I don't know train a decision tree

1798
01:56:52,510 --> 01:56:57,470
then number and connectedness of these friends is the most important feature so this is the

1799
01:56:57,470 --> 01:57:04,130
first split in the decision so now so basically what this is means is

1800
01:57:04,130 --> 01:57:08,550
that the more so the more the friends are connected the better so what

1801
01:57:08,670 --> 01:57:12,130
what the experiment says is that this is if if this is the case you

1802
01:57:12,130 --> 01:57:17,410
are more likely to join the group then this but then one can go

1803
01:57:17,410 --> 01:57:23,250
on and ask a different question so if connectedness among friends promotes joining

1804
01:57:23,250 --> 01:57:28,730
then do highly connected groups right groups that have high clustering coefficient so groups where a lot of

1805
01:57:28,750 --> 01:57:34,750
friends are friends among themselves are they growing more quickly right because if if people join to

1806
01:57:34,830 --> 01:57:39,970
them with higher probability because they are highly connected are they are they also growing quicker right

1807
01:57:39,970 --> 01:57:43,670
so we define clustering as the number of triangles in the network over the number

1808
01:57:43,670 --> 01:57:49,230
of open triads or land to paths and now we ask we

1809
01:57:49,370 --> 01:57:54,390
look at the growth as a function of clustering and here's here's the plot right

1810
01:57:54,390 --> 01:58:00,550
this clearly shows that as as the clustering increases the growth sort

1811
01:58:00,560 --> 01:58:06,570
of sort of decreases right so groups that have large clustering grow slower

1812
01:58:06,570 --> 01:58:10,690
and this is not just because the groups would have fewer fewer nodes so this

1813
01:58:10,690 --> 01:58:16,180
could maybe be explained by saying that all older groups sort of saturated and they

1814
01:58:16,180 --> 01:58:21,910
and they don't grow for that reason there are more subtleties when thinking about

1815
01:58:23,170 --> 01:58:30,310
this is an example from viral marketing so one easy question to

1816
01:58:30,310 --> 01:58:36,070
ask is does sending more recommendations influence more purchases right so here would be the

1817
01:58:36,070 --> 01:58:40,950
total number of recommendations somebody sent and this is the number of people that

1818
01:58:40,950 --> 01:58:47,630
would buy that product okay and the reason we can we can get get this curve because

1819
01:58:47,640 --> 01:58:52,640
we have this total record of what was going on because the recommendations were sent

1820
01:58:52,750 --> 01:58:58,050
through email people would get discounts so they were incentivized to really go and buy something

1821
01:58:58,050 --> 01:59:02,100
okay and what you can see here is that again we have a increase

1822
01:59:02,110 --> 01:59:10,550
up to I know around thirty forty recommendations right it's a superlinear growth and then it sort of stabilizes sort of slows down

1823
01:59:10,550 --> 01:59:13,990
and this is this is also something that one would want to want this is even more

1824
01:59:13,990 --> 01:59:19,310
surprising here so if you say what is the effectiveness of subsequent recommendations between two


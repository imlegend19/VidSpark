1
00:00:00,000 --> 00:00:02,260
little bit of fraud

2
00:00:02,270 --> 00:00:05,320
in fact i can give you a number of examples of this are just singled

3
00:00:05,320 --> 00:00:07,270
out one which is the lesser

4
00:00:07,280 --> 00:00:12,100
which was written to the times in london just a month or so ago this

5
00:00:12,100 --> 00:00:16,710
said sir i was recently the victim of an internet fraud the sum involved was

6
00:00:16,770 --> 00:00:21,190
several hundred pounds my local police refused to investigate stating that their policy was to

7
00:00:22,270 --> 00:00:26,710
only for sums of over five thousand pounds about ten thousand dollars it's less than

8
00:00:26,710 --> 00:00:28,470
that they don't bother

9
00:00:28,530 --> 00:00:31,610
this has all sorts of implications i think it has an implication

10
00:00:31,700 --> 00:00:34,850
suggesting that society is changing it means that small

11
00:00:34,860 --> 00:00:41,150
and less than ten thousand dollars fraud are regarded as in some sense except to

12
00:00:41,190 --> 00:00:42,760
certain about places

13
00:00:42,770 --> 00:00:48,340
i don't feel it's worth investigating they're sort of of interesting sociological consequences of that

14
00:00:48,380 --> 00:00:52,340
secondly there's something there's sort of version of the preta principle

15
00:00:52,360 --> 00:00:56,700
in general in fraud detection first fifty percent these numbers don't really mean anything you

16
00:00:56,700 --> 00:01:00,450
know just of indicate is the first fifty percent of fraud

17
00:01:00,500 --> 00:01:02,400
it is easy to stop

18
00:01:02,420 --> 00:01:04,090
relatively easy

19
00:01:04,130 --> 00:01:06,890
you know many forces are pretty stupid

20
00:01:06,900 --> 00:01:10,840
but some clever the first fifty percent is easy to stop the next twenty five

21
00:01:10,840 --> 00:01:14,450
takes the same amount of effort next twelve office percent takes the same amount of

22
00:01:14,450 --> 00:01:15,840
effort again

23
00:01:15,840 --> 00:01:17,090
and then you can see that

24
00:01:17,100 --> 00:01:18,630
you'll never stop it all

25
00:01:18,700 --> 00:01:25,230
at the top and presumably there are some very successful fraud as process not detected

26
00:01:25,270 --> 00:01:27,210
and the search point

27
00:01:27,220 --> 00:01:32,840
the resources available for fraud detection always limited was to come from the british bankers'

28
00:01:32,840 --> 00:01:36,090
association conference a few weeks ago

29
00:01:36,140 --> 00:01:37,420
and the figure of

30
00:01:37,770 --> 00:01:43,150
around three percent of police resources are spent on detecting and preventing fraud

31
00:01:44,650 --> 00:01:48,550
just three percent police have lots of other things to spend money on

32
00:01:48,570 --> 00:01:50,690
and what's clear what is very clear

33
00:01:50,700 --> 00:01:53,850
it was that that's three percent isn't going to be increased

34
00:01:53,860 --> 00:01:58,130
they're not going to switch money out of stopping burglars or muggings on the street

35
00:01:58,130 --> 00:01:58,820
or whatever

36
00:01:58,900 --> 00:02:00,900
to put it into fraud detection

37
00:02:01,000 --> 00:02:02,380
consequences of these

38
00:02:02,400 --> 00:02:07,050
these things are the if we come out in the process we go out think

39
00:02:07,050 --> 00:02:10,900
that means we've got to bring sophisticated advanced technologies to better stop them which is

40
00:02:10,900 --> 00:02:16,590
the sort of thing we've been talking about this meeting

41
00:02:16,590 --> 00:02:19,770
there are a number of general problems in fraud detection and i'm going to look

42
00:02:19,770 --> 00:02:23,090
at some of these in detail as we as we go on

43
00:02:23,130 --> 00:02:27,250
four datasets may be huge in both both in terms of numbers of if you

44
00:02:27,250 --> 00:02:30,630
think flat file both in terms of number of variables and in terms of the

45
00:02:30,630 --> 00:02:33,980
number of cases but also in terms of complexity

46
00:02:34,000 --> 00:02:38,200
the relationships between these things i'm talking about flat file here but as we will

47
00:02:38,200 --> 00:02:41,130
see things can be much more complicated

48
00:02:41,250 --> 00:02:45,850
most of these the variables

49
00:02:45,860 --> 00:02:47,580
the only way

50
00:02:50,310 --> 00:02:53,040
most of these the variables to be relevant

51
00:02:53,050 --> 00:02:54,490
and also

52
00:02:54,500 --> 00:02:56,570
and this is really a problem here

53
00:02:56,600 --> 00:03:00,780
most cases will be fraud is the classic data mining

54
00:03:00,830 --> 00:03:03,380
anomaly detection type problem if you like

55
00:03:03,400 --> 00:03:06,070
we really are looking for a needle in a haystack and i'll give you some

56
00:03:06,070 --> 00:03:08,110
figures on those in a moment

57
00:03:08,150 --> 00:03:11,630
there is an evolutionary arms race

58
00:03:11,670 --> 00:03:14,440
i'm going to talk in detail about this

59
00:03:14,470 --> 00:03:18,110
basically what i mean by that is the forces on standing still i don't just

60
00:03:18,110 --> 00:03:22,540
have one method they used when that stopped it stop as we have seen

61
00:03:22,630 --> 00:03:26,820
there's a leapfrog of prevention and detection the banks

62
00:03:26,830 --> 00:03:28,860
telecoms agencies or whatever

63
00:03:28,870 --> 00:03:33,980
put in place a a method for stopping a certain kind of fraud

64
00:03:34,020 --> 00:03:36,680
that they build a nest for detecting a certain kind of fraud and put in

65
00:03:36,680 --> 00:03:39,310
place a method for detecting

66
00:03:39,370 --> 00:03:44,690
and then cycles round and i'll illustrate that the examples there's also a leapfrog of

67
00:03:44,690 --> 00:03:47,320
operations and exploration

68
00:03:47,380 --> 00:03:51,640
you have accumulated database from the past two years

69
00:03:51,880 --> 00:03:54,800
to enable you to construct advanced detection

70
00:03:54,810 --> 00:03:56,570
algorithms you put them into

71
00:03:57,980 --> 00:03:58,650
and then

72
00:03:58,670 --> 00:04:02,040
that collects you collect more data through that cycle around again

73
00:04:02,050 --> 00:04:06,000
and i've already referred to the fact that fraud may involve complex data types most

74
00:04:06,000 --> 00:04:09,120
of the data but i'm going to be talking about a simple numerical data are

75
00:04:09,120 --> 00:04:12,550
mostly i'm going to be talking about flat files but

76
00:04:12,610 --> 00:04:16,970
if if i get to the scientific fraud part will see images and other kinds

77
00:04:16,970 --> 00:04:21,500
of data as well being used in fraud

78
00:04:21,580 --> 00:04:25,820
a little comment about the role of data fusion data fusion integrating data from multiple

79
00:04:27,700 --> 00:04:30,810
there are all sorts of issues associated with this which are not really going to

80
00:04:30,810 --> 00:04:35,730
talk about just a little bit on this slide which they fusion complicates disclosure risk

81
00:04:35,730 --> 00:04:36,550
we had

82
00:04:36,550 --> 00:04:38,610
doesn't matter interactions here

83
00:04:38,750 --> 00:04:42,530
these are conditionally independent given the data which is very important

84
00:04:42,550 --> 00:04:45,240
it's very important for these to be conditionally independent given the data so you can

85
00:04:45,240 --> 00:04:49,070
get the right distribution is much less important together i distribution here

86
00:04:49,130 --> 00:04:54,570
we get the content ourselves with settling towards equilibrium distribution here the free state here

87
00:04:54,570 --> 00:04:55,890
would like the true

88
00:04:55,910 --> 00:04:58,910
conditional distribution here

89
00:05:03,410 --> 00:05:05,160
he learns these

90
00:05:05,180 --> 00:05:06,910
four hundred times

91
00:05:06,930 --> 00:05:09,050
about a million connections here

92
00:05:09,110 --> 00:05:11,950
and then he learns these amazing connections here

93
00:05:11,970 --> 00:05:15,130
and then learns these half half-million connections here

94
00:05:15,140 --> 00:05:17,720
when he learns the second

95
00:05:17,740 --> 00:05:21,260
level connections he puts in latin int

96
00:05:21,260 --> 00:05:23,970
the interconnections among the units that are not visible

97
00:05:24,030 --> 00:05:28,490
OK he didn't do any fine-tuning just degree learning like this

98
00:05:28,510 --> 00:05:30,740
once he's learned

99
00:05:30,740 --> 00:05:35,360
he can i generate it very very slowly

100
00:05:35,370 --> 00:05:39,450
but we just want to see a few samples by generating correctly

101
00:05:39,490 --> 00:05:43,110
so generate correctly this guy needs to go up and down a lot of times

102
00:05:43,110 --> 00:05:46,280
between these two sets of units and each time it comes down

103
00:05:46,840 --> 00:05:49,870
in this study these units one at the time

104
00:05:49,890 --> 00:05:53,090
that's the correct question really needs going to generate stochastically

105
00:05:53,140 --> 00:05:56,800
you know these units one at the time

106
00:05:56,820 --> 00:05:58,110
get all of them

107
00:05:58,160 --> 00:05:59,910
and then you can go back up again

108
00:05:59,930 --> 00:06:03,320
and then you get again and again you lot of times

109
00:06:03,340 --> 00:06:05,360
then the final step

110
00:06:05,410 --> 00:06:07,800
you only have to go down once

111
00:06:07,840 --> 00:06:10,680
that is with the top down input coming from here

112
00:06:10,760 --> 00:06:15,180
you go through all these many times to reach an equilibrium sample given this and

113
00:06:15,180 --> 00:06:17,890
then with an equilibrium sample you got here

114
00:06:17,910 --> 00:06:20,510
if this were connected to go through these many times but they're not so you

115
00:06:20,510 --> 00:06:21,990
just get on it

116
00:06:22,050 --> 00:06:24,370
so it's really the top on third pick because you have to go and down

117
00:06:24,370 --> 00:06:28,510
many times time come down you have to go through units sequentially

118
00:06:29,360 --> 00:06:31,990
that's why we don't use it for learning

119
00:06:32,030 --> 00:06:36,860
but now you can look at how well it doesn't generating natural image patches

120
00:06:37,780 --> 00:06:42,050
these are real natural image patches from manhattan's database

121
00:06:42,070 --> 00:06:44,760
and if you're trying to model just like the one i showed you but without

122
00:06:44,780 --> 00:06:46,320
the lateral interactions

123
00:06:46,340 --> 00:06:48,450
so generating talk to

124
00:06:48,450 --> 00:06:49,970
but you train like in normal

125
00:06:49,970 --> 00:06:52,030
deep belief nett with no

126
00:06:52,090 --> 00:06:53,720
lateral interactions within

127
00:06:53,780 --> 00:06:59,130
you get get clouds basically these have the same second order statistics is the data

128
00:06:59,130 --> 00:07:00,300
but they

129
00:07:00,360 --> 00:07:01,450
a lot

130
00:07:01,470 --> 00:07:03,760
a lot of the structure images which is

131
00:07:03,780 --> 00:07:08,990
forty speaking images nothing happens and then suddenly stuff happens

132
00:07:09,050 --> 00:07:12,930
and then nothing times something most of this stuff like edges

133
00:07:12,970 --> 00:07:17,300
so you sort of see here there's not much of an analog

134
00:07:17,320 --> 00:07:21,610
you see in this one percent nothing then something something interesting thing

135
00:07:21,640 --> 00:07:24,680
these don't really look like that

136
00:07:25,180 --> 00:07:29,050
OK so what happens if we just train the same model with these latter interactions

137
00:07:29,050 --> 00:07:33,530
it takes longer to train is called more parameters because the actual interactions gives you

138
00:07:33,550 --> 00:07:35,780
qualitatively different models

139
00:07:35,800 --> 00:07:38,360
right now it has the property

140
00:07:38,390 --> 00:07:41,820
not is not as well as natural images but much much better than the previous

141
00:07:41,820 --> 00:07:44,240
think of

142
00:07:44,320 --> 00:07:47,680
you know there's not much of making this stuff happening here and here

143
00:07:47,700 --> 00:07:51,200
and you know this looks much more like get in natural images than what you

144
00:07:51,200 --> 00:07:53,550
get if you don't use lateral interactions

145
00:07:55,890 --> 00:08:01,260
now i want to emphasise this is very funny way of using markov random fields

146
00:08:01,340 --> 00:08:03,200
remember says that the vision people

147
00:08:03,220 --> 00:08:05,240
because all vision people

148
00:08:05,300 --> 00:08:06,660
i believe the following

149
00:08:06,680 --> 00:08:09,530
so dangerous statement

150
00:08:09,550 --> 00:08:13,280
they believe that if you use the markov random field and you can do inference

151
00:08:13,280 --> 00:08:14,890
the way it's going to work is this

152
00:08:14,910 --> 00:08:18,640
you can have a markov random field between your hidden variables line show you some

153
00:08:18,640 --> 00:08:22,130
data and you are going have to do inference to figure out

154
00:08:22,140 --> 00:08:26,760
what the what a correct sample from your hidden variables is given you got this

155
00:08:26,760 --> 00:08:28,700
markov random field

156
00:08:30,200 --> 00:08:35,390
that's not what we're going do

157
00:08:35,470 --> 00:08:37,320
well we're going to do is

158
00:08:37,340 --> 00:08:39,180
if i give you some data

159
00:08:39,200 --> 00:08:42,860
even though you learn this model with all these lateral interactions

160
00:08:42,870 --> 00:08:45,260
when you do inference

161
00:08:45,300 --> 00:08:49,390
you're just going to go through these the transpose this way matrix and you can

162
00:08:49,430 --> 00:08:53,860
ignore these latter interactions to for the states of the units

163
00:08:54,990 --> 00:08:58,090
the lateral interactions just don't come into it in doing inference

164
00:08:58,110 --> 00:09:02,700
what happens in your brain is yours in your visual cortex they get initial activity

165
00:09:03,180 --> 00:09:06,800
and then we'll actually interacts and they settled that

166
00:09:06,840 --> 00:09:09,430
and they change what they do

167
00:09:09,450 --> 00:09:13,200
and everybody interprets that as they get a better model of the world

168
00:09:13,200 --> 00:09:15,700
i think they're getting worse model of the world i think what they get in

169
00:09:15,700 --> 00:09:20,320
an initial state is the best model of the world

170
00:09:20,340 --> 00:09:25,240
and then there corrupting it with what they believe so they can do learning so

171
00:09:25,240 --> 00:09:27,660
they get a better signal from learning

172
00:09:28,610 --> 00:09:34,280
well that's what i believe sometimes when i'm doing diebold's machines ability of the story

173
00:09:38,890 --> 00:09:42,950
if you think about

174
00:09:42,950 --> 00:09:46,680
so that some enforcing constraints when you do generations

175
00:09:46,700 --> 00:09:51,050
but how they helping the inference and learning

176
00:09:53,220 --> 00:09:55,530
if you ask why do people want date

177
00:09:55,590 --> 00:10:00,910
people wanting data to get rid of the pairwise correlations so they can concentrate on

178
00:10:00,910 --> 00:10:05,950
higher order correlations because the pairwise correlations to have nearly all the power

179
00:10:07,180 --> 00:10:13,050
any system this modelling the powers correlations if it sort of try to change parameters

180
00:10:13,050 --> 00:10:15,510
to model the higher correlation slightly better

181
00:10:15,530 --> 00:10:19,630
but in doing that it's slightly messes up his model the pairwise correlations it among

182
00:10:19,630 --> 00:10:22,860
want to make that change because so much more power in the power was correlations

183
00:10:23,140 --> 00:10:25,640
those are the most important things to right so if you want to sort of

184
00:10:25,640 --> 00:10:27,530
see those

185
00:10:27,550 --> 00:10:31,430
low-power higher order correlations which of the interesting things

186
00:10:31,450 --> 00:10:35,780
through this sort of a lot of these strong pair wise correlations you better get

187
00:10:35,780 --> 00:10:37,370
rid of the pairwise correlations

188
00:10:37,390 --> 00:10:40,240
and that's what you want in data

189
00:10:40,300 --> 00:10:42,220
so we try to remove the statistics

190
00:10:42,240 --> 00:10:45,910
so the natural way to think about learning multilevel models is to say

191
00:10:45,910 --> 00:10:48,010
OK let's learn hidden

192
00:10:48,070 --> 00:10:50,950
once we have learned that the the pairwise correlations

193
00:10:50,990 --> 00:10:54,340
so let's remove those before find higher order correlations

194
00:10:54,360 --> 00:10:57,910
and in a sense that's what we're doing

195
00:10:57,930 --> 00:11:01,720
but we're doing it in a way this much faster than actually removing

196
00:11:01,820 --> 00:11:05,260
because we cannot allow inference to go much faster than you could if you actually

197
00:11:05,260 --> 00:11:11,180
have to remove the pairwise correlations before you go to the next step

198
00:11:11,220 --> 00:11:13,550
so we're going to do

199
00:11:13,550 --> 00:11:14,610
it is

200
00:11:14,630 --> 00:11:18,590
we can wind the learning signal that is we're going to get the same learning

201
00:11:18,590 --> 00:11:19,780
so we will explain

202
00:11:21,050 --> 00:11:22,450
again as i said earlier u

203
00:11:22,860 --> 00:11:25,660
the don't physics because that's clearly outside are

204
00:11:27,550 --> 00:11:28,330
i think satisfy

205
00:11:28,740 --> 00:11:32,120
neurophysiological explanations is not available today although

206
00:11:32,650 --> 00:11:33,930
it's quite a bit published

207
00:11:34,440 --> 00:11:35,630
on this the literature

208
00:11:36,150 --> 00:11:37,280
i've tried to read up on it

209
00:11:38,070 --> 00:11:39,110
and it comes down to it

210
00:11:39,610 --> 00:11:40,830
stimulation of these

211
00:11:41,330 --> 00:11:42,460
brains in a special way

212
00:11:44,620 --> 00:11:45,560
flickering the lights

213
00:11:46,230 --> 00:11:47,550
on the cells of the retina

214
00:11:49,030 --> 00:11:51,000
and then the brains just tell you that you see color

215
00:11:52,400 --> 00:11:54,100
what can we do about this is is not

216
00:11:58,560 --> 00:12:01,810
i don't speak too fast they wanted cause

217
00:12:02,380 --> 00:12:06,390
and if you go too slowly then you don't seem very rarely the optimum around seven hrs

218
00:12:06,860 --> 00:12:08,630
five ten hertz you one is fine

219
00:12:09,270 --> 00:12:11,160
so in the morning we always play a little bit with that

220
00:12:11,670 --> 00:12:13,610
get it right the twenty words it fades away

221
00:12:17,360 --> 00:12:19,530
the electorate try to challenge my audience

222
00:12:20,110 --> 00:12:20,650
and i am

223
00:12:21,770 --> 00:12:24,040
always make them longer perhaps these in a little bit

224
00:12:25,130 --> 00:12:27,650
and at the same time trying to teach them from physics

225
00:12:28,230 --> 00:12:29,000
students like that

226
00:12:30,020 --> 00:12:32,300
and i see no reason why should make an exception for u

227
00:12:34,930 --> 00:12:36,680
and last two six questions

228
00:12:37,110 --> 00:12:39,220
six questions about three miles

229
00:12:39,770 --> 00:12:42,010
and i know that all you've looked at rainbows

230
00:12:43,180 --> 00:12:46,200
but looking at something is very different from seeing it

231
00:12:47,500 --> 00:12:48,930
and i'm not going to test to

232
00:12:50,330 --> 00:12:53,320
she whether you've never seen rainbows

233
00:12:57,080 --> 00:12:58,340
now that i like u

234
00:12:59,440 --> 00:13:00,390
because when i teach

235
00:13:00,980 --> 00:13:04,430
my freshman about this i ask them fifteen questions about

236
00:13:07,760 --> 00:13:08,570
only six liu

237
00:13:10,500 --> 00:13:11,770
what is the radius of the rainbow

238
00:13:12,940 --> 00:13:16,820
and some of you in the audience may say rabies was how can you talk about the radius

239
00:13:17,950 --> 00:13:19,100
well when you see a rainbow

240
00:13:20,440 --> 00:13:22,440
then it looks like an arc in the sky

241
00:13:23,790 --> 00:13:24,100
like so

242
00:13:25,530 --> 00:13:26,470
you may be horizon

243
00:13:27,320 --> 00:13:30,490
and since it is argued that is a circle somewhere in the mid point

244
00:13:31,230 --> 00:13:33,790
the midpoint could be below right and of course stay here

245
00:13:34,770 --> 00:13:36,300
and so you have a distance here

246
00:13:37,240 --> 00:13:38,870
that you can express in terms of an angle

247
00:13:41,040 --> 00:13:43,790
and that angle can be expressed in terms of so many degrees

248
00:13:44,870 --> 00:13:46,970
now i don't expect you to know the exact answer

249
00:13:47,680 --> 00:13:48,510
is it and degrees

250
00:13:49,000 --> 00:13:51,050
so ninety degrees is a twenty degrees

251
00:13:51,980 --> 00:13:54,550
what is approximately so that's what i mean by angle

252
00:13:56,330 --> 00:13:57,070
in terms of angle

253
00:13:58,590 --> 00:13:59,320
because sequence

254
00:14:00,590 --> 00:14:01,590
is the readout sites

255
00:14:01,980 --> 00:14:05,050
what is already inside or that depend maybe on the time of the day

256
00:14:05,770 --> 00:14:06,820
maybe the time of the year

257
00:14:09,860 --> 00:14:13,610
have you ever noticed that there is a huge difference in brightness

258
00:14:14,200 --> 00:14:14,750
of this guy

259
00:14:15,600 --> 00:14:16,450
when you see a rainbow

260
00:14:18,920 --> 00:14:19,250
this guy

261
00:14:20,350 --> 00:14:25,170
is much brighter in certain areas than it is in other areas and i can ask new

262
00:14:25,720 --> 00:14:28,170
whereas it very bright and whereas it very dark

263
00:14:28,720 --> 00:14:30,020
all relative to the rainbow

264
00:14:31,570 --> 00:14:34,800
and then comes the question is there more than one well maybe there is a

265
00:14:34,800 --> 00:14:36,480
second well maybe there is a third one

266
00:14:36,900 --> 00:14:40,890
and if there is a second one was its colour sequence is a red outside

267
00:14:41,800 --> 00:14:42,500
the real outside

268
00:14:44,510 --> 00:14:49,170
now comes the question number six either both polarized already gave it away didn't i

269
00:14:49,200 --> 00:14:51,210
in my introduction i said we all know

270
00:14:52,490 --> 00:14:52,940
should know

271
00:14:53,720 --> 00:14:54,940
that the both polarized

272
00:14:55,700 --> 00:14:56,950
so you think you're going to get away

273
00:14:57,740 --> 00:15:00,960
which question number six but there is no such thing as a free lunch here

274
00:15:01,250 --> 00:15:03,190
so i'm going to change this question into

275
00:15:03,800 --> 00:15:04,440
why i the

276
00:15:06,140 --> 00:15:07,090
that's a hard question

277
00:15:08,200 --> 00:15:09,680
one of the answer to all six

278
00:15:11,240 --> 00:15:11,840
only models

279
00:15:13,510 --> 00:15:14,270
raise your hands

280
00:15:15,150 --> 00:15:16,470
physics professor and my two

281
00:15:19,940 --> 00:15:21,680
my page my personal physician

282
00:15:22,980 --> 00:15:24,230
michael zero

283
00:15:25,980 --> 00:15:26,710
on this man

284
00:15:28,250 --> 00:15:29,410
one of the few and the mighty

285
00:15:33,930 --> 00:15:36,430
well as this expressions only data five

286
00:15:37,030 --> 00:15:38,870
on more workers just expired

287
00:15:38,870 --> 00:15:43,330
visual sensor so this is some input from the retina and then you whatever the

288
00:15:43,330 --> 00:15:47,790
size of its input the model of the neuron is that your summing up these

289
00:15:47,790 --> 00:15:50,500
imports and then your firing

290
00:15:50,500 --> 00:15:53,770
when that some reaches a certain threshold and you i think you would write this

291
00:15:53,770 --> 00:15:56,230
threshold here b that was

292
00:15:56,250 --> 00:16:01,140
not rose let's model of a neuron it with mcculloch and pitts but it's mcculloch

293
00:16:01,140 --> 00:16:03,350
and pitts in nineteen forty three

294
00:16:03,370 --> 00:16:05,750
so it's quite an old model

295
00:16:05,770 --> 00:16:08,830
you know

296
00:16:08,890 --> 00:16:15,620
i actually was quite excited by this type of model and the major innovation for

297
00:16:15,620 --> 00:16:20,310
the multilayer perceptron was instead of this being a threshold we turn this into a

298
00:16:20,310 --> 00:16:22,040
smooth function

299
00:16:22,160 --> 00:16:26,280
which meant you could do differentiation and you can make multiple they versions of this

300
00:16:26,280 --> 00:16:28,680
so you would have another important here

301
00:16:30,660 --> 00:16:33,950
and basically put the whole thing together so you've got some important you would feed

302
00:16:33,950 --> 00:16:39,870
forward through make your classification and very much i was inspired to come into

303
00:16:40,540 --> 00:16:45,810
machine learning because of these models i think a big disappointment for me

304
00:16:45,830 --> 00:16:47,080
was some

305
00:16:47,160 --> 00:16:50,520
i actually worked out so there was a problem with this

306
00:16:51,180 --> 00:16:52,970
multilayer perceptron idea

307
00:16:52,990 --> 00:16:58,020
because if you go multi-layered versions turned on

308
00:16:58,040 --> 00:16:59,350
this one move away

309
00:16:59,350 --> 00:17:04,250
so if the multi-layered versions of or maybe should

310
00:17:04,310 --> 00:17:09,040
you can hear me OK good if you do multi-layered versions of this if you've

311
00:17:09,040 --> 00:17:13,660
got threshold units there was this problem of how you work out what the

312
00:17:13,680 --> 00:17:19,180
responsibility for the error here is because you your objective function was discontinuous you can

313
00:17:19,180 --> 00:17:24,290
compute gradients and i think it's it's published in a i that in nineteen ninety

314
00:17:25,020 --> 00:17:29,160
i want to an algorithm for doing that i was very excited because it was

315
00:17:29,160 --> 00:17:36,310
written as a big open problems in machine learning how you do the multilayer networks

316
00:17:36,310 --> 00:17:39,620
of these linear threshold units

317
00:17:39,640 --> 00:17:44,750
and when i published it no one cared because it wasn't an interesting problem because

318
00:17:44,750 --> 00:17:46,560
we've moved beyond that

319
00:17:46,580 --> 00:17:50,450
that model in two ways one no one thought of as a realistic model of

320
00:17:50,450 --> 00:17:52,040
the brain and to

321
00:17:52,040 --> 00:17:58,680
no of course it is practically useful way of doing classification so in some sense

322
00:17:58,720 --> 00:18:00,230
we can see that now

323
00:18:00,290 --> 00:18:03,390
but i think we go back to say the early fifties and we look at

324
00:18:03,390 --> 00:18:08,790
rosales work with early computers what you see is he's got

325
00:18:08,810 --> 00:18:10,140
an extremely

326
00:18:10,160 --> 00:18:12,720
fast way of doing classification

327
00:18:14,350 --> 00:18:19,430
that was published this based on the model of a neuron that was published in

328
00:18:19,430 --> 00:18:20,990
less than a decade ago

329
00:18:21,040 --> 00:18:23,970
as the way the brain works i think that would be

330
00:18:23,990 --> 00:18:28,620
at the time would be considered very exciting things so

331
00:18:28,660 --> 00:18:30,700
now we can look back and say

332
00:18:30,720 --> 00:18:34,680
not really how the brain works but it's not some interesting aspects and the reason

333
00:18:34,680 --> 00:18:39,230
i wanted to talk about it here is because it's this interesting aspects of learning

334
00:18:39,230 --> 00:18:43,830
of the you've got something that you need to adapt so in that case

335
00:18:43,830 --> 00:18:45,450
these weights here

336
00:18:45,450 --> 00:18:50,000
and what you adapting those weights according to is what you observe to be the

337
00:18:50,000 --> 00:18:54,750
class we'll talk what your supervision signal is and what your input signal is right

338
00:18:54,810 --> 00:18:58,330
so in the world i think examples of

339
00:18:58,350 --> 00:19:03,520
similar models that were based on very simple learning rules hebbian learning time rules which

340
00:19:03,520 --> 00:19:07,950
you know again i don't know much about but i understand one point it was

341
00:19:08,100 --> 00:19:14,930
taken very seriously in cognitive science see reinforce connections where you see things on together

342
00:19:14,930 --> 00:19:19,180
in same time and those sort of models include things like the hopfield network and

343
00:19:19,180 --> 00:19:23,350
bolss machines which are making a big comeback at the moment

344
00:19:26,020 --> 00:19:29,200
OK so

345
00:19:29,220 --> 00:19:32,620
i don't want to talk much more about that learning rule or what the objective

346
00:19:32,620 --> 00:19:36,870
function is but what i want to do is to talk about something i spend

347
00:19:36,870 --> 00:19:40,160
more time working on which is regression

348
00:19:40,180 --> 00:19:43,750
so that's less connected to the brain but i'm going to follow a similar path

349
00:19:43,750 --> 00:19:48,520
of trying to show you regression we know how to do regression

350
00:19:48,540 --> 00:19:50,790
regression was invented

351
00:19:50,810 --> 00:19:58,770
by sort of physicists around the turn of the nineteenth century for fitting a physical

352
00:19:58,770 --> 00:20:00,770
models the universe two

353
00:20:00,790 --> 00:20:07,640
observations of whether planets were it was reinvented by golden he called regression statistician inside

354
00:20:07,640 --> 00:20:10,580
of the turn of the twentieth century

355
00:20:11,490 --> 00:20:15,290
and it's basically the same a different type of supervised learning but the

356
00:20:15,310 --> 00:20:19,450
the target now has a real value given some set of inputs

357
00:20:20,250 --> 00:20:25,290
one of my favorite data sets on this is predicting the quality of meat given

358
00:20:25,310 --> 00:20:30,450
spectral measurements is take it or data so you've got some sort of set spectral

359
00:20:30,680 --> 00:20:34,790
measurements and you want to predict they measure to meet you want to predict what

360
00:20:34,790 --> 00:20:36,730
the quality of that meat was

361
00:20:36,730 --> 00:20:40,810
that means we have similar structures

362
00:20:40,830 --> 00:20:46,940
but the interesting thing is the whole concept in that has where

363
00:20:46,960 --> 00:20:47,980
you need to be

364
00:20:48,270 --> 00:20:52,790
the structure and global media finds for for

365
00:20:54,040 --> 00:20:58,250
in one of four pass what is

366
00:20:58,350 --> 00:21:00,930
this is the shortest distance

367
00:21:02,180 --> 00:21:03,770
from this no

368
00:21:03,790 --> 00:21:05,620
well spread

369
00:21:05,680 --> 00:21:08,930
you want to find the supposed

370
00:21:09,500 --> 00:21:10,660
for about this

371
00:21:10,680 --> 00:21:12,410
we are

372
00:21:12,430 --> 00:21:17,200
the structure of

373
00:21:18,930 --> 00:21:20,180
i find it

374
00:21:20,200 --> 00:21:23,580
hard to get very efficient index

375
00:21:25,040 --> 00:21:27,640
which is why simple is

376
00:21:28,600 --> 00:21:29,930
and why

377
00:21:29,940 --> 00:21:33,410
and of course many many pass

378
00:21:33,430 --> 00:21:35,390
so all these formation

379
00:21:35,410 --> 00:21:39,600
but the shortest path is very

380
00:21:39,730 --> 00:21:43,290
it is the last one short novels

381
00:21:44,600 --> 00:21:46,370
those reasons why

382
00:21:46,500 --> 00:21:48,180
there's one small

383
00:21:49,160 --> 00:21:51,750
five percent that's only one

384
00:21:51,770 --> 00:21:53,160
well that's all

385
00:21:53,180 --> 00:22:00,460
so you already know that this is really five v five stories and this one

386
00:22:00,560 --> 00:22:02,350
one year

387
00:22:02,370 --> 00:22:04,480
so thank you get this one is

388
00:22:05,770 --> 00:22:07,310
want to give you

389
00:22:07,930 --> 00:22:09,700
the shortest path

390
00:22:09,830 --> 00:22:14,980
he or also showed vast majority that can

391
00:22:15,080 --> 00:22:17,830
well i think about this

392
00:22:17,980 --> 00:22:20,980
that's it because of

393
00:22:21,000 --> 00:22:24,600
but i feel more interesting similarity

394
00:22:24,600 --> 00:22:27,830
sir is a structure

395
00:22:27,870 --> 00:22:29,580
so for example

396
00:22:29,640 --> 00:22:36,770
five crystals follows is going to or or speech innovation or speech

397
00:22:36,790 --> 00:22:38,350
it was most

398
00:22:38,370 --> 00:22:39,430
this is

399
00:22:40,020 --> 00:22:42,000
this is a hard question

400
00:22:42,290 --> 00:22:46,640
just because

401
00:22:48,180 --> 00:22:49,930
just because

402
00:22:52,680 --> 00:22:54,700
actually and all

403
00:22:56,410 --> 00:22:58,060
full what this

404
00:22:58,080 --> 00:22:59,930
for example the

405
00:22:59,930 --> 00:23:01,160
the christmas

406
00:23:01,180 --> 00:23:04,410
he said you're looking for authors

407
00:23:04,430 --> 00:23:06,140
using this

408
00:23:06,190 --> 00:23:11,870
there like his phd students long-term collaborator where we also

409
00:23:11,910 --> 00:23:13,480
the black last

410
00:23:13,500 --> 00:23:17,120
but what about the conferences wall

411
00:23:18,640 --> 00:23:22,350
nine people see set of conferences

412
00:23:22,370 --> 00:23:24,230
like this

413
00:23:24,230 --> 00:23:26,810
five different set of land use

414
00:23:26,830 --> 00:23:28,290
different parts

415
00:23:28,310 --> 00:23:30,680
their research which

416
00:23:31,680 --> 00:23:32,270
you got

417
00:23:33,270 --> 00:23:37,810
you can see also different as good

418
00:23:37,930 --> 00:23:39,730
do sense

419
00:23:39,750 --> 00:23:41,520
so we

420
00:23:41,580 --> 00:23:45,790
the what is the author or a

421
00:23:45,810 --> 00:23:46,870
is of

422
00:23:47,790 --> 00:23:49,160
this the key

423
00:23:49,180 --> 00:23:51,480
or a

424
00:23:51,500 --> 00:23:52,910
the other

425
00:23:54,250 --> 00:23:58,370
one final reasons because he

426
00:23:58,390 --> 00:24:01,080
the only goal

427
00:24:01,100 --> 00:24:03,790
you get a couple answers

428
00:24:05,640 --> 00:24:08,100
is called the similarity

429
00:24:08,390 --> 00:24:09,870
she was

430
00:24:09,890 --> 00:24:14,230
almost majority were his phd students

431
00:24:15,120 --> 00:24:18,830
he said no no no don't know

432
00:24:18,850 --> 00:24:21,660
i think they are do you see

433
00:24:21,680 --> 00:24:24,750
but the interesting thing is

434
00:24:24,810 --> 00:24:27,350
it follows is most cell

435
00:24:29,020 --> 00:24:32,600
in order to try out

436
00:24:32,620 --> 00:24:35,520
the reason is even the authors papers

437
00:24:35,520 --> 00:24:43,620
an image basically yeah typically is used only as a particularly convenient

438
00:24:43,620 --> 00:24:54,920
representation for inference in this H DPN and hierarchical Pitman Yor process type of models okay  so for both

439
00:24:54,920 --> 00:25:01,220
the nested CRP and the Chinese restaurant franchise we see that we get trees which

440
00:25:01,220 --> 00:25:06,520
are not not necessarily binary trees right so we could for example

441
00:25:06,520 --> 00:25:12,500
have it that this three tables get merged into one table up here so they could

442
00:25:12,500 --> 00:25:19,920
be like more than one no that could be coagulations involving more than two clusters

443
00:25:19,920 --> 00:25:28,260
at the same time okay we could also construct hierarchy random trees where

444
00:25:28,260 --> 00:25:37,940
each node of the tree will split into exactly two children okay and you could do that

445
00:25:37,940 --> 00:25:45,360
by actually taking kind of a continuum limit of this partition valued Markov chain sorry

446
00:25:45,360 --> 00:25:53,740
recall that for both this process and this process we get this rand this random

447
00:25:53,740 --> 00:25:59,200
this sequence of either random fragmentations or random coagulations and they are

448
00:25:59,200 --> 00:26:03,460
both Markov chains of partitions and we can take this Markov chain and take

449
00:26:03,610 --> 00:26:10,560
a continuum time limit where we get kind of like a continuous time Markov jump process over over a

450
00:26:10,560 --> 00:26:16,440
random partitions and that it turns out that in that case you could actually derive that the

451
00:26:16,440 --> 00:26:21,720
trees that you get are will all be binary I guess I'm kind

452
00:26:21,720 --> 00:26:26,340
of running out of time so I won't really describe it but you could do that in

453
00:26:26,340 --> 00:26:34,860
the case of the nested CRP the continuum  time limit model called

454
00:26:34,860 --> 00:26:40,480
the Dirichlet diffusion tree and this is a model that was proposed by

455
00:26:40,480 --> 00:26:47,700
Neal  actually even before the nested CRP by Redford Neal who used it

456
00:26:47,720 --> 00:26:55,280
for doing  density estimation and is basically the continuum time time limit of the

457
00:26:55,280 --> 00:27:00,970
of the nested CRP and more recently there has been generalization of

458
00:27:00,970 --> 00:27:09,640
the the Dirichlet diffusion tree to Pitman Yor diffusion trees where Knowles and Ghahramani took the

459
00:27:09,640 --> 00:27:16,280
basically the continuum time limit of a nested chinese restaurant process

460
00:27:16,280 --> 00:27:22,920
where the Chinese restaurant process is what two parameter Chinese restaurant processes  similarly you

461
00:27:22,920 --> 00:27:27,260
can take the continuum time limit of the Chinese restaurant franchise and you can show

462
00:27:27,270 --> 00:27:33,340
that that corresponds to a model that came from genetics long time ago called

463
00:27:33,340 --> 00:27:43,920
Kingman's coalescent which is a basically a standard model for modelling genealogies in population genetics

464
00:27:43,920 --> 00:27:49,780
there're also generalizations called the called the lambda coalescent  I guess I'll skip this

465
00:27:49,780 --> 00:28:01,800
bit okay and and both the Dirichlet diffusion tree and the and the kingman's

466
00:28:01,800 --> 00:28:07,760
coalescence produce random trees which are binary trees so every internal node of the

467
00:28:07,760 --> 00:28:13,940
tree  will always produce two children there are ultrametric trees in the sense that

468
00:28:13,940 --> 00:28:21,720
the leaves are all the same distance away from from the root and

469
00:28:21,720 --> 00:28:33,180
they're random right okay so this are what's called ultrametric trees there are  in fact more

470
00:28:33,220 --> 00:28:40,410
other constructions for random trees and which have been people in probability theory have explored

471
00:28:40,410 --> 00:28:48,700
and these are things like Gibbs fragmentation trees continuum random trees and standard additive coalescent

472
00:28:48,710 --> 00:28:54,580
and so forth so I guess these are kind of things which people who do

473
00:28:54,580 --> 00:29:02,040
modelling of data hasn't really explored that much okay any questions about trees

474
00:29:02,050 --> 00:29:18,040
yes I don't think

475
00:29:18,040 --> 00:29:25,480
there is actually a particular reason for choosing fragmentation over coagulation or vice-versa it seems

476
00:29:25,480 --> 00:29:31,360
that they're all just different trees and if you you can actually generate from these trees

477
00:29:31,360 --> 00:29:37,280
and they'd look quite different okay but in general I don't think there's a particular

478
00:29:37,280 --> 00:29:44,300
reason to choose one over the other you know it's up to your fancy really okay yes

479
00:29:44,300 --> 00:29:53,640
how do you evaluate the trees arm in quantitatively

480
00:29:53,640 --> 00:30:02,780
okay so in the topic models I think it really depends on your application right

481
00:30:02,780 --> 00:30:07,540
so they have used it for things like topic modelling and they have evaluated topic

482
00:30:07,540 --> 00:30:16,460
models quantitatively using perplexity scores like how perplexity is  this score which basically

483
00:30:16,460 --> 00:30:24,260
measures how well it is predicting words that is not seen before and I guess I

484
00:30:24,260 --> 00:30:32,900
think they did find that it  works  somewhat better than than LDA I think more

485
00:30:32,900 --> 00:30:40,960
recently people in the topic modelling literature have been also more interested in how the

486
00:30:40,960 --> 00:30:45,680
issue with perplexity is that it's a quantitative measure but it's not neccessarily

487
00:30:45,680 --> 00:30:52,780
a measure that actually corresponds to what people do with with topic models the way people use

488
00:30:52,790 --> 00:30:58,740
topic models is as a way of summarizing a document corpus so they've been looking

489
00:30:58,740 --> 00:31:03,100
at kind of different ways in which you could evaluate topic models in terms of how

490
00:31:03,100 --> 00:31:13,420
well are they summarizing a document corpus and also how well how well they actually

491
00:31:13,420 --> 00:31:25,960
describe topics which are perceptually coherent okay you have question or

492
00:31:37,840 --> 00:31:45,860
yes yes so we have actually used Kingman's coalescent

493
00:31:45,870 --> 00:31:53,380
this sort of a random trees as a model for doing hierarchical clustering and you can

494
00:31:53,380 --> 00:32:03,160
actually evaluate it we actually evaluated it in a few way one way

495
00:32:03,160 --> 00:32:08,540
is to kind of look at what's called purity scores basically scores which relate the

496
00:32:08,540 --> 00:32:14,040
true underlying clustering to the tree that you have and they do seem to work

497
00:32:14,040 --> 00:32:20,000
a lot better than all of the all of the linkage algorithms you can use

498
00:32:20,000 --> 00:32:26,560
it for things like filling in basically if the data at each leaf

499
00:32:26,560 --> 00:32:30,340
of your tree is partially observed so there might be a few entries that

500
00:32:30,340 --> 00:32:35,160
you do observe few entries which you didn't observe right then you can build this tree and

501
00:32:35,160 --> 00:32:39,640
then you can use the other data items to help you fill in the entries in

502
00:32:39,640 --> 00:32:43,180
your in in your data vectors which you did not observe and then you can

503
00:32:43,180 --> 00:32:46,670
look at how well they did it do that fill that filling in it's basically a

504
00:32:46,670 --> 00:32:51,420
predictive type of process and again you can see that that actually works much better than

505
00:32:51,420 --> 00:32:52,930
but first

506
00:32:52,950 --> 00:32:55,250
remember so this is just a recap from

507
00:32:55,260 --> 00:32:59,290
yes it comes from the commission's in fact she said that there exist for the

508
00:32:59,290 --> 00:33:00,750
system itself

509
00:33:00,760 --> 00:33:03,690
OK there is such kind of it that he

510
00:33:04,380 --> 00:33:07,850
they don't suppose we want to do is human beings also there in the data

511
00:33:07,860 --> 00:33:12,320
for a between vector of body cavities prime you can show that it is positive

512
00:33:12,320 --> 00:33:17,630
semidefinite cases it is symmetric of course and if you compute like the

513
00:33:17,680 --> 00:33:20,620
the metrics of inner product spaces

514
00:33:21,060 --> 00:33:24,880
we also saw some the kind of this that we can all the question

515
00:33:24,890 --> 00:33:31,870
the RBF kernel is also all symmetric positive definite kernels

516
00:33:31,880 --> 00:33:33,990
so there exists

517
00:33:34,240 --> 00:33:37,170
one of the curvature that is that in fact

518
00:33:37,190 --> 00:33:39,810
giving a positive definite kernel

519
00:33:39,830 --> 00:33:41,550
in a sense is equivalent to

520
00:33:41,570 --> 00:33:47,930
giving the structure to you by the structure of a hilbert space about space

521
00:33:47,940 --> 00:33:53,530
that's what that's like hilbert space with an inner product

522
00:33:53,650 --> 00:33:55,010
let's forget about the

523
00:33:55,050 --> 00:34:00,790
other properties so that he was start from space where there is no stranger to

524
00:34:00,900 --> 00:34:04,110
a set of points five point five b

525
00:34:04,150 --> 00:34:07,960
the reason for that is that the set

526
00:34:08,010 --> 00:34:11,420
but positive and you can also function k

527
00:34:11,440 --> 00:34:16,120
two those similarities for me then we will think about that

528
00:34:16,130 --> 00:34:17,170
two defining

529
00:34:17,200 --> 00:34:21,150
prior to finding a space on the right which is a vector space is what

530
00:34:21,230 --> 00:34:26,550
are also some because the space is that can do mitigation but can i can

531
00:34:28,450 --> 00:34:29,660
in fact the it

532
00:34:29,680 --> 00:34:34,700
following form of the most prominent in the nineteen fifties is that

533
00:34:35,430 --> 00:34:39,290
a function k is on this space basis is positive definite

534
00:34:39,330 --> 00:34:42,380
if and only if so there is an equivalence

535
00:34:42,390 --> 00:34:47,010
if you think about space age so this space

536
00:34:47,060 --> 00:34:49,110
with some you know for that

537
00:34:49,120 --> 00:34:50,460
and mapping phi

538
00:34:50,490 --> 00:34:53,350
that goes from the initial state to the hilbert space

539
00:34:53,360 --> 00:34:58,070
so that the value of the can also k of six prime

540
00:34:58,090 --> 00:34:59,240
is equal

541
00:34:59,660 --> 00:35:02,220
so the inner product in the space

542
00:35:02,230 --> 00:35:03,850
between the images

543
00:35:03,860 --> 00:35:05,730
your point by

544
00:35:05,750 --> 00:35:09,150
because we find these things for every spring

545
00:35:09,170 --> 00:35:13,470
so the picture on the beach here really shows that is that you have

546
00:35:13,770 --> 00:35:18,470
initial space without any structure as long as you give me a function k that

547
00:35:18,470 --> 00:35:22,150
is positive it as is

548
00:35:22,160 --> 00:35:26,980
you gave me but the right you can function from its points here to the

549
00:35:27,700 --> 00:35:31,230
and then we can also the synapse between two points here is exactly the inner

550
00:35:31,230 --> 00:35:35,410
products of the product

551
00:35:35,420 --> 00:35:36,720
so the

552
00:35:36,730 --> 00:35:40,530
between the images of the points

553
00:35:40,570 --> 00:35:44,120
OK so that's a very strong so this is one of the reasons why we

554
00:35:44,120 --> 00:35:48,230
focus on that that as long as give me such a search function you give

555
00:35:48,230 --> 00:35:52,160
me a lot of things in fact is beginning and ending of your space into

556
00:35:52,160 --> 00:35:54,380
a vector space

557
00:35:54,390 --> 00:35:58,100
so we just spend few minutes to try to give some ideas on how to

558
00:35:58,100 --> 00:36:04,310
prove that because this will make some interesting things first so here o you want

559
00:36:04,310 --> 00:36:08,350
to prove their existence a there is an argument between two things there is one

560
00:36:08,350 --> 00:36:10,210
direction to prove which is easy

561
00:36:10,230 --> 00:36:12,370
the notion that if

562
00:36:12,380 --> 00:36:16,180
if you define a function k as the inner product space

563
00:36:16,190 --> 00:36:20,340
it is easy to prove that this thing is positive semidefinite why is it the

564
00:36:20,340 --> 00:36:26,040
case just for this line symmetry because inability symmetry and this was different because they

565
00:36:26,040 --> 00:36:28,250
never that is being

566
00:36:28,270 --> 00:36:30,390
this is the easy part

567
00:36:30,410 --> 00:36:32,900
now the other mission is

568
00:36:32,920 --> 00:36:35,910
i suppose you give me a positive definite kernel

569
00:36:35,920 --> 00:36:37,570
how can we prove that

570
00:36:37,580 --> 00:36:41,490
it can be written in a product space

571
00:36:41,500 --> 00:36:47,960
so in fact he took what he is not so easy and find was actually

572
00:36:48,100 --> 00:36:51,360
you could you could prove it is in the US you going to find basis

573
00:36:51,360 --> 00:36:56,690
for a finite set of points that can just be metrics which is positive semidefinite

574
00:36:56,920 --> 00:37:01,260
and the problem there are simply means that you can asymmetric actually so this is

575
00:37:01,290 --> 00:37:03,010
very very traditional

576
00:37:03,020 --> 00:37:07,080
now if you want to use any of the organisation you need you can do

577
00:37:07,080 --> 00:37:11,120
it only on this is set of can and but they can also called mass

578
00:37:11,140 --> 00:37:16,460
of kernels which are defined as continuous functions on compact spaces so it seems a

579
00:37:16,460 --> 00:37:21,720
bit technical just for those of you interested in but so is if you if

580
00:37:21,720 --> 00:37:25,350
you function k is continues in your space is compact then you can extend to

581
00:37:25,350 --> 00:37:29,460
provide the information because you have come back to writers and so on and this

582
00:37:29,460 --> 00:37:33,360
was done in nineteen five by third example accounts

583
00:37:33,370 --> 00:37:36,680
but this is still a bit restricted because for instance if you take the question

584
00:37:37,930 --> 00:37:39,830
on on our

585
00:37:39,850 --> 00:37:41,630
it's not the massacre

586
00:37:41,650 --> 00:37:45,240
so it's continues with the space are not compact OK so you cannot apply

587
00:37:45,260 --> 00:37:48,600
this proves that he doesn't the mission consisted in

588
00:37:48,620 --> 00:37:55,210
in fact the way present before nineteen fifty announced and chance paper that was formed

589
00:37:55,410 --> 00:37:57,840
in the general case that whatever the space k

590
00:37:58,340 --> 00:38:01,740
so whatever the space ace combat or not

591
00:38:01,760 --> 00:38:06,450
what the function k continuous and that's the term is true in the sense that

592
00:38:06,460 --> 00:38:07,660
for any

593
00:38:07,670 --> 00:38:11,690
but if you can no longer any space that is the human space so that

594
00:38:11,690 --> 00:38:15,620
k of crime is equal to the inner product between the images

595
00:38:15,640 --> 00:38:18,020
and the way to prove that was

596
00:38:18,040 --> 00:38:21,260
was introduced space which i want to describe how quickly

597
00:38:21,270 --> 00:38:25,140
because we're gonna use it later on we can thought this space is called the

598
00:38:25,140 --> 00:38:28,350
reproducing kernel hilbert space

599
00:38:28,370 --> 00:38:29,400
so it's a bit

600
00:38:29,420 --> 00:38:30,740
i'm in my name

601
00:38:30,760 --> 00:38:40,190
current name usually so this is simply called rkhs RKHS you think of the RKHS

602
00:38:40,220 --> 00:38:42,120
a space of functions

603
00:38:42,130 --> 00:38:47,170
OK so functions of functions that go from your space

604
00:38:47,180 --> 00:38:48,130
it is

605
00:38:48,140 --> 00:38:50,240
to the real numbers

606
00:38:50,260 --> 00:38:55,080
and in fact as soon as you so not describe everything about architecture rules but

607
00:38:55,080 --> 00:38:57,760
the idea is that as soon as you have account all

608
00:38:57,810 --> 00:39:00,770
then together we can overcome one

609
00:39:00,770 --> 00:39:01,900
OK yes

610
00:39:02,900 --> 00:39:03,930
well start no

611
00:39:03,940 --> 00:39:05,680
with the second part of this

612
00:39:05,700 --> 00:39:09,700
the tar so i'm going to build on what proper talked about

613
00:39:10,900 --> 00:39:13,030
i mean particularly going to

614
00:39:13,040 --> 00:39:16,250
in this part of the talk we're going to try to understand what can active

615
00:39:16,250 --> 00:39:18,230
learning do for us

616
00:39:18,270 --> 00:39:20,630
when need help much does it help

617
00:39:20,660 --> 00:39:24,400
what are its draws and so on so we already saw the main idea is

618
00:39:24,400 --> 00:39:30,540
closing the loop between the data collection process the observations and sampling

619
00:39:30,550 --> 00:39:32,430
and we saw that

620
00:39:32,850 --> 00:39:33,790
you can

621
00:39:33,820 --> 00:39:38,390
possibly by lot but also curiosity can kill the cat if you are focusing too

622
00:39:38,390 --> 00:39:40,900
much on something

623
00:39:40,930 --> 00:39:44,330
you might miss the world so if you look trying to learn about the forest

624
00:39:44,330 --> 00:39:48,110
and if you're looking only at one tree you'll miss forest

625
00:39:49,550 --> 00:39:53,360
so these are going to focus on the very simple problems are very simple

626
00:39:53,370 --> 00:39:55,600
problems maybe

627
00:39:55,610 --> 00:39:59,680
some would say contrived settings but this is what is going to give us a

628
00:39:59,680 --> 00:40:00,570
good idea

629
00:40:01,860 --> 00:40:04,020
what can be done

630
00:40:04,040 --> 00:40:07,690
in particular i'm going to be very interesting

631
00:40:07,710 --> 00:40:11,330
answering this second question how much can be gained

632
00:40:11,470 --> 00:40:15,800
and of course in answering this question rule

633
00:40:15,800 --> 00:40:17,140
also learning

634
00:40:17,210 --> 00:40:20,520
ways of taking advantage of the sampling feedback

635
00:40:20,520 --> 00:40:24,220
and hopefully get some insight about

636
00:40:24,430 --> 00:40:27,550
ways of constructing algorithms that

637
00:40:27,570 --> 00:40:31,900
that do this and will actually part three will talk a little bit about some

638
00:40:31,900 --> 00:40:33,660
of those are reasons

639
00:40:35,050 --> 00:40:37,410
for that session

640
00:40:38,210 --> 00:40:41,600
a little outline here we're going to talk about this

641
00:40:41,630 --> 00:40:47,210
very simple binary classification problems it's going to be one dimensional threshold estimation problems

642
00:40:47,240 --> 00:40:48,660
i'm going to review

643
00:40:48,660 --> 00:40:51,320
the probabilistic classification framework rather

644
00:40:53,080 --> 00:40:56,600
and under this framework was going to quantify

645
00:40:56,610 --> 00:40:58,820
the active learning gains for this

646
00:40:58,850 --> 00:41:01,300
simple setting and also

647
00:41:01,330 --> 00:41:03,540
show what active learning can do

648
00:41:03,550 --> 00:41:06,670
what are the lower bound for the fundamental limitations

649
00:41:06,680 --> 00:41:09,680
generalizes this to multiple and mentions in the

650
00:41:09,760 --> 00:41:12,420
so what happens next

651
00:41:13,550 --> 00:41:16,680
let's consider a very simple problem so you're trying to

652
00:41:16,710 --> 00:41:21,960
learned threshold say the transition between dark and light is

653
00:41:21,990 --> 00:41:26,430
forested areas shaded areas like then you're trying to learn

654
00:41:26,480 --> 00:41:30,840
we're just like the tree canopy and the prairie starts

655
00:41:30,900 --> 00:41:37,030
and more abstractly say function like this it's zero two point in n one and

656
00:41:37,030 --> 00:41:39,110
you're just trying to learn that function

657
00:41:39,140 --> 00:41:42,080
figure out what data studies

658
00:41:42,090 --> 00:41:46,730
and let's say you do this from noisy observations this so you say

659
00:41:46,860 --> 00:41:50,390
so what's the value of the function at this point zero point eight and use

660
00:41:50,390 --> 00:41:53,830
cases that one but it could be something noise it could be

661
00:41:53,860 --> 00:41:57,960
could be zero with some probability could be something different than one like one point

662
00:41:57,960 --> 00:42:01,280
five one three that's like that so

663
00:42:01,300 --> 00:42:06,020
but to make a point samples of observations of this function

664
00:42:06,030 --> 00:42:12,960
so the goal here is to learn this threshold status as accurately as possible

665
00:42:12,960 --> 00:42:15,730
OK so if you're doing passive learning

666
00:42:15,740 --> 00:42:18,650
you cannot use this feedback between

667
00:42:18,670 --> 00:42:22,120
observations on the sampling so if you have to ask

668
00:42:22,140 --> 00:42:24,520
and questions about this function

669
00:42:24,550 --> 00:42:27,930
o point samples to learn about a just are

670
00:42:27,980 --> 00:42:30,400
what where when you ask the questions

671
00:42:30,460 --> 00:42:31,520
if you don't know

672
00:42:31,520 --> 00:42:33,230
it already is

673
00:42:33,240 --> 00:42:35,080
the only reasonable thing to do

674
00:42:36,800 --> 00:42:42,520
especially as this and question somewhat uniformly distributed over the entire domain between zero and

675
00:42:43,180 --> 00:42:46,770
so just put your and samples over there

676
00:42:46,780 --> 00:42:48,610
and let's say there was nice

677
00:42:48,620 --> 00:42:50,610
it collects observations

678
00:42:50,620 --> 00:42:53,270
and you see this and immediately get

679
00:42:53,300 --> 00:42:57,140
they just are must be between this application this application

680
00:42:57,830 --> 00:43:01,410
your error is going to be on the order of one over so it's going

681
00:43:01,410 --> 00:43:06,640
one you and sample space using samples is on europe one of around so your

682
00:43:06,640 --> 00:43:08,710
error in estimating the research

683
00:43:08,740 --> 00:43:10,080
it's going to be

684
00:43:10,140 --> 00:43:13,880
rather like one around but if you look at this to see that you are

685
00:43:13,880 --> 00:43:19,170
wasting too many samples once you've so observations of all the samples are collected here

686
00:43:19,170 --> 00:43:20,650
are completely useless

687
00:43:20,660 --> 00:43:23,310
all these two really matter so you're

688
00:43:23,320 --> 00:43:24,600
we think a lot of

689
00:43:24,630 --> 00:43:27,090
information here

690
00:43:27,120 --> 00:43:31,110
so if you're doing passive active learning what you do well you do binary binarisation

691
00:43:31,110 --> 00:43:33,080
everyone knows about this

692
00:43:34,040 --> 00:43:37,900
now take a sample right in the middle point one half see also wants status

693
00:43:38,030 --> 00:43:39,820
must be to the left

694
00:43:39,830 --> 00:43:41,970
data to support the last

695
00:43:43,650 --> 00:43:46,730
that must be to the right of that point

696
00:43:46,730 --> 00:43:51,230
OK now which it which corner does win

697
00:43:51,340 --> 00:43:56,350
the grad student right because the 3 corners are I could figure out the cost

698
00:43:56,350 --> 00:44:00,750
is here the PhD is doing all the work solving all 4 problems working for

699
00:44:00,750 --> 00:44:03,140
hours for 20 got

700
00:44:03,620 --> 00:44:09,540
here a grad student is doing all the work working for hours 3 dollars an

701
00:44:09,540 --> 00:44:11,470
hour for 12

702
00:44:11,540 --> 00:44:14,640
yeah the computer's doing all the work

703
00:44:14,720 --> 00:44:19,700
only has to work 2 hours but it's clusters 8 dollars an hour so this

704
00:44:19,700 --> 00:44:24,120
is 16 dollars pulse so 68

705
00:44:24,140 --> 00:44:25,220
is that right

706
00:44:25,290 --> 00:44:28,660
yeah 16 28

707
00:44:28,660 --> 00:44:30,750
or 12 so the winner is

708
00:44:30,770 --> 00:44:33,370
the optimum is there gratitude

709
00:44:37,020 --> 00:44:42,120
but that was this was a small problem where we could check all corners and

710
00:44:42,140 --> 00:44:49,040
my point was can't do that usually so now I speak about the simplex method

711
00:44:52,560 --> 00:44:55,380
started some corner

712
00:44:55,390 --> 00:45:00,350
but I need some preliminary method to find the corners suppose I start at corner

713
00:45:00,350 --> 00:45:08,180
cornerpiece so start and the idea of the simplex method will be

714
00:45:09,640 --> 00:45:17,180
to move to another corner and neighbouring corner

715
00:45:17,200 --> 00:45:24,120
what's and neighbouring corner on on on a 1 of these high-dimensional deals

716
00:45:24,140 --> 00:45:27,020
and neighbouring corner means

717
00:45:27,240 --> 00:45:31,180
1 of the axes

718
00:45:32,720 --> 00:45:37,180
1 of the axes that 1 0 well look at the area it the x

719
00:45:37,180 --> 00:45:38,560
at this point

720
00:45:38,580 --> 00:45:41,950
what happens if I moved to the court

721
00:45:44,080 --> 00:45:46,200
1 some drops to 0

722
00:45:46,440 --> 00:45:51,220
and some other X you could say

723
00:45:51,230 --> 00:45:55,250
X 1 leaves the basis is when I travel appear

724
00:45:57,730 --> 00:45:59,540
and x 2

725
00:45:59,700 --> 00:46:02,520
3 rather enters base

726
00:46:02,560 --> 00:46:06,810
I'm using word basis for the free X 1 and 2 it leaves the leaves

727
00:46:06,810 --> 00:46:12,930
the solution becomes 0 and a different 1 x 3 enters a solution

728
00:46:13,160 --> 00:46:14,870
becomes non-zero

729
00:46:15,040 --> 00:46:17,410
and the cost is reduced

730
00:46:17,430 --> 00:46:19,370
went from 20 dollars down to 60

731
00:46:20,800 --> 00:46:24,980
OK then I look around from this course

732
00:46:26,930 --> 00:46:29,250
which way shall I go

733
00:46:29,270 --> 00:46:32,770
I go along an edge to the next 1

734
00:46:32,790 --> 00:46:35,370
so I could go along this edge

735
00:46:35,390 --> 00:46:37,410
or along this edge

736
00:46:37,450 --> 00:46:39,080
so I compute

737
00:46:39,080 --> 00:46:41,660
which way is the best way to go

738
00:46:42,430 --> 00:46:47,850
when I go this way my computations to show on worst costs more

739
00:46:47,870 --> 00:46:53,350
when I go this way it costs less and reducing the cost so course go

740
00:46:53,350 --> 00:46:58,810
that way until I can't go any further because I'm reducing reducing the more work

741
00:46:58,830 --> 00:47:03,120
the grad student does at the more work that's taken away from the computer and

742
00:47:03,120 --> 00:47:05,720
given the the grad student much cheaper

743
00:47:05,850 --> 00:47:09,870
more as I travel down here I'm giving more and more work the grad student

744
00:47:09,870 --> 00:47:12,410
until I reached that point

745
00:47:13,280 --> 00:47:16,980
when I can't take away any more work from the computer and the computer is

746
00:47:17,350 --> 00:47:19,600
is no longer doing anything dropped 0

747
00:47:22,270 --> 00:47:27,890
but in this case the entering variable was the grad student number 2

748
00:47:28,120 --> 00:47:34,100
and the leaving variable was a computer 3 and it left the point of dropping

749
00:47:34,100 --> 00:47:38,720
a 0 the grad student moved up from 0 to something whatever it for whatever

750
00:47:38,720 --> 00:47:40,830
something it took just

751
00:47:40,850 --> 00:47:45,560
to satisfy the constraint and I have added new corn

752
00:47:45,560 --> 00:47:48,100
now I look around from that corners and

753
00:47:48,880 --> 00:47:53,240
the simplex method of courses and know it's got to x so it would look

754
00:47:53,240 --> 00:47:57,800
around it would say there are 2 ways I can move from here

755
00:47:57,810 --> 00:48:00,680
but they both

756
00:48:00,750 --> 00:48:04,180
mean cost increase so I must be at the winner

757
00:48:04,560 --> 00:48:06,480
so that's

758
00:48:06,520 --> 00:48:12,600
that's the idea of the simplex method start somewhere started some corner

759
00:48:12,660 --> 00:48:15,450
move travel along edges

760
00:48:16,470 --> 00:48:20,520
reducing the cost every time

761
00:48:20,520 --> 00:48:23,890
and until you get to edge where you can

762
00:48:23,910 --> 00:48:29,640
because cannot be reduced and that's that's the text the winners

763
00:48:30,220 --> 00:48:33,750
so that's the simplex method now I have to tell you

764
00:48:35,730 --> 00:48:40,850
how the simplex method chooses the age to travel

765
00:48:40,850 --> 00:48:44,890
well not quite

766
00:48:50,300 --> 00:48:55,600
how many

767
00:48:58,890 --> 00:49:02,660
now could

768
00:49:12,410 --> 00:49:16,720
the two

769
00:49:16,840 --> 00:49:18,120
in fact

770
00:49:23,800 --> 00:49:26,930
i i i

771
00:49:27,260 --> 00:49:33,430
i that

772
00:49:47,720 --> 00:49:54,220
and i am i

773
00:49:58,490 --> 00:50:01,620
in that period time

774
00:50:01,820 --> 00:50:06,600
now it

775
00:50:08,320 --> 00:50:16,490
i mean that

776
00:50:16,510 --> 00:50:21,320
so how can

777
00:50:28,990 --> 00:50:32,430
so i can

778
00:50:32,660 --> 00:50:36,050
you have

779
00:50:41,640 --> 00:50:44,720
my life

780
00:51:09,100 --> 00:51:12,740
that that

781
00:51:21,510 --> 00:51:24,530
i field

782
00:51:39,890 --> 00:51:42,450
you can

783
00:51:47,470 --> 00:51:53,510
we are not

784
00:52:00,870 --> 00:52:04,490
for change

785
00:52:29,450 --> 00:52:36,070
there at all the functions

786
00:52:36,100 --> 00:52:44,990
and he signed by

787
00:52:50,030 --> 00:52:54,510
thank you

788
00:52:57,490 --> 00:53:08,890
but i find

789
00:53:35,290 --> 00:53:43,510
and that true

790
00:53:54,890 --> 00:53:59,220
and i

791
00:53:59,240 --> 00:54:04,160
i trying

792
00:54:32,550 --> 00:54:36,340
three years

793
00:54:43,530 --> 00:54:49,220
i mean

794
00:54:59,660 --> 00:55:01,370
so much

795
00:55:10,680 --> 00:55:12,820
if you think that

796
00:55:35,870 --> 00:55:44,550
having at least

797
00:55:44,570 --> 00:55:48,760
a question

798
00:55:53,340 --> 00:55:55,200
i present

799
00:55:57,450 --> 00:56:00,950
thank you

800
00:56:00,950 --> 00:56:02,820
this is my true

801
00:56:02,880 --> 00:56:09,030
o soviet strictly OK in this kind of games you don't need to have been

802
00:56:09,030 --> 00:56:11,880
done so far

803
00:56:13,800 --> 00:56:14,970
to find

804
00:56:15,990 --> 00:56:19,240
this strategy can be so-called memoryless

805
00:56:19,280 --> 00:56:20,610
in the study

806
00:56:22,130 --> 00:56:25,300
he said in which position what you're going to play

807
00:56:26,360 --> 00:56:28,680
it doesn't depend on the history

808
00:56:28,720 --> 00:56:32,470
two and so why is it important

809
00:56:33,720 --> 00:56:36,780
there's also very important if you want to compute

810
00:56:37,570 --> 00:56:43,280
so this is part of your question on the reserve and it's just

811
00:56:44,240 --> 00:56:46,180
if i give you mission

812
00:56:47,010 --> 00:56:49,510
not so if i gave you pretty game

813
00:56:49,570 --> 00:56:55,150
with the starting

814
00:56:57,900 --> 00:57:03,240
now we're not with the start position on the political i give you an arena

815
00:57:04,740 --> 00:57:06,530
with colours

816
00:57:07,610 --> 00:57:11,780
it's a copy with well defined game how to play

817
00:57:12,840 --> 00:57:14,670
so parity games

818
00:57:14,720 --> 00:57:17,990
i want to compute positions

819
00:57:18,880 --> 00:57:23,880
so that players you'll have extracted from this position

820
00:57:29,950 --> 00:57:31,220
can become

821
00:57:31,450 --> 00:57:33,950
to thank you see said

822
00:57:34,720 --> 00:57:38,550
and if you are familiar with the you can compute it

823
00:57:39,970 --> 00:57:41,240
can you can compute

824
00:57:41,510 --> 00:57:43,670
copy of winning position

825
00:57:44,240 --> 00:57:46,150
and this will cost you

826
00:57:48,570 --> 00:57:50,740
like you know and people

827
00:57:50,800 --> 00:57:57,340
yes it's NP into clint PY because as it is that mines issued warnings

828
00:57:59,280 --> 00:58:01,490
so it's as easy to

829
00:58:01,630 --> 00:58:03,360
so i with the other one

830
00:58:05,320 --> 00:58:09,840
its dual system it is hard to see that you losers of the two

831
00:58:10,780 --> 00:58:16,050
well because one win so you just exchange the wall of the players

832
00:58:17,820 --> 00:58:20,910
and the argument very quickly

833
00:58:20,930 --> 00:58:22,720
and then the damage but

834
00:58:23,340 --> 00:58:25,570
you get strategy it's easy

835
00:58:25,590 --> 00:58:29,990
it's so small object because you're so you guessed which outgoing transition you choose from

836
00:58:29,990 --> 00:58:31,300
your position

837
00:58:33,130 --> 00:58:35,220
basically here

838
00:58:35,240 --> 00:58:36,360
popular zero

839
00:58:36,430 --> 00:58:38,220
these rules

840
00:58:39,260 --> 00:58:41,050
and here can guess one

841
00:58:44,380 --> 00:58:46,760
so we start from we start from here

842
00:58:46,880 --> 00:58:48,900
have to get this

843
00:58:49,880 --> 00:58:52,130
both rules so it's wonderful

844
00:58:53,910 --> 00:58:56,470
for this one because we're not go there

845
00:58:58,820 --> 00:59:00,570
you choose not going out

846
00:59:00,650 --> 00:59:04,510
that is your strategy which is with one

847
00:59:05,630 --> 00:59:07,860
and now that know that

848
00:59:08,930 --> 00:59:09,880
you can have

849
00:59:13,200 --> 00:59:16,430
the take

850
00:59:18,650 --> 00:59:21,680
and you check that in the remaining graph

851
00:59:25,880 --> 00:59:28,570
and this is infinitely often

852
00:59:29,570 --> 00:59:31,570
black position

853
00:59:33,740 --> 00:59:35,070
and say

854
00:59:35,130 --> 00:59:38,760
you do it for the first position and the it's things like this position you

855
00:59:38,760 --> 00:59:43,130
guess arrows rules for this position gives you for its position you guess if there

856
00:59:43,130 --> 00:59:45,360
are the guests

857
00:59:49,070 --> 00:59:54,860
if they do you put it in the winning region and to check whether

858
00:59:55,760 --> 01:00:00,510
in a given graph hidden things from something this is pulling them

859
01:00:01,430 --> 01:00:04,360
and you it

860
01:00:08,680 --> 01:00:13,280
this is just so you guess the road to real time that they are really

861
01:00:15,280 --> 01:00:16,860
so this gives you an MP

862
01:00:17,110 --> 01:00:21,320
and then p algorithm

863
01:00:29,900 --> 01:00:31,950
what to do next time

864
01:00:32,240 --> 01:00:33,700
the time

865
01:00:34,450 --> 01:00:36,030
one the two things

866
01:00:36,050 --> 01:00:39,170
i would say that in that very

867
01:00:40,150 --> 01:00:42,340
very simple

868
01:00:44,680 --> 01:00:46,200
they can be

869
01:00:53,930 --> 01:00:55,610
i think

870
01:00:55,630 --> 01:00:59,950
my priority is non deterministic parity tree automata

871
01:01:00,800 --> 01:01:04,280
this is this QA on top and everything

872
01:01:05,280 --> 01:01:06,740
take one

873
01:01:10,450 --> 01:01:14,490
i do right from it

874
01:01:15,570 --> 01:01:18,280
so what they came in way

875
01:01:19,070 --> 01:01:21,150
i will

876
01:01:21,200 --> 01:01:24,990
enable me to

877
01:01:27,780 --> 01:01:29,470
from the initial state

878
01:01:30,820 --> 01:01:32,760
will be in charge of

879
01:01:33,450 --> 01:01:35,530
choosing the transition

880
01:01:35,550 --> 01:01:40,840
you have to guess the computation which is accepting

881
01:01:42,450 --> 01:01:46,070
so sitting in fourth

882
01:01:46,990 --> 01:01:52,550
i want to answer whether my automaton accepts so

883
01:01:54,760 --> 01:01:56,380
so players e

884
01:01:57,050 --> 01:02:00,130
will play in the arena where players zero

885
01:02:04,150 --> 01:02:06,650
the current label will be

886
01:02:07,280 --> 01:02:12,630
this is not too big because finding many inputs on my note

887
01:02:13,240 --> 01:02:15,380
good guesses

888
01:02:16,050 --> 01:02:17,700
the label

889
01:02:17,800 --> 01:02:21,010
it should be put on the model if

890
01:02:21,740 --> 01:02:24,170
and it's also guesses

891
01:02:27,070 --> 01:02:28,530
will be chosen

892
01:02:29,970 --> 01:02:34,340
would be in this current states and there would be this label given to

893
01:02:34,800 --> 01:02:36,970
my automaton nondeterministic

894
01:02:38,220 --> 01:02:39,720
given some

895
01:02:40,220 --> 01:02:41,950
state and

896
01:02:41,970 --> 01:02:43,990
label of the input tree

897
01:02:45,900 --> 01:02:48,070
so i have to choose the there

898
01:02:48,150 --> 01:02:49,380
of states

899
01:02:49,430 --> 01:02:50,670
going to

900
01:02:51,950 --> 01:02:53,010
my run

901
01:02:53,030 --> 01:02:55,590
in the full binary tree

902
01:02:56,150 --> 01:02:59,070
so low here

903
01:02:59,110 --> 01:03:05,450
i have to choose

904
01:03:06,550 --> 01:03:09,050
see that

905
01:03:09,630 --> 01:03:12,880
this one

906
01:03:12,900 --> 01:03:15,410
you're over

907
01:03:15,950 --> 01:03:20,490
what i mean is set q a a

908
01:03:20,930 --> 01:03:24,380
i have to guess whether my computation goal

909
01:03:24,800 --> 01:03:27,050
keep going using

910
01:03:27,070 --> 01:03:30,110
this is like it will make you a right by

911
01:03:30,700 --> 01:03:32,800
by topic or vice versa

912
01:03:33,070 --> 01:03:36,880
so i guess i have to choose

913
01:03:38,680 --> 01:03:42,130
the two brains automaton will be look

914
01:03:42,360 --> 01:03:43,260
would be

915
01:03:45,720 --> 01:03:48,090
i mean state q

916
01:03:48,630 --> 01:03:50,900
form mean some positions

917
01:03:50,930 --> 01:03:56,680
this might have information about the current state of the automaton i have to choose

918
01:03:57,700 --> 01:03:59,610
what i put here

919
01:03:59,630 --> 01:04:02,760
and knowing what they could hear what the truth

920
01:04:03,280 --> 01:04:05,410
you have to guess

921
01:04:05,410 --> 01:04:10,670
nor can i talk about existence constraints so i want to say that all instances

922
01:04:10,670 --> 01:04:13,160
of paper must have an awful

923
01:04:13,170 --> 01:04:15,820
OK so must have an awful which is the person

924
01:04:16,650 --> 01:04:19,520
all papers must have at least three reviewers

925
01:04:19,540 --> 01:04:24,850
i can represent any that using RDF schema disappears and language learning to do that

926
01:04:24,900 --> 01:04:29,240
nor can i say things about properties of the relationship can be characterized the relationship

927
01:04:29,290 --> 01:04:34,100
to say that there transitive perhaps they have inverses

928
01:04:34,120 --> 01:04:38,540
it's also although this is kind of rather weak on this is also a rather

929
01:04:38,540 --> 01:04:45,400
strong as well kind of in almost paradoxically that because there are many things i

930
01:04:45,400 --> 01:04:49,950
can say with RDF i can do some quite sophisticated metamodelling OK so i can

931
01:04:49,950 --> 01:04:54,460
say things about classes are treated as individuals and so on so we can actually

932
01:04:54,470 --> 01:04:56,300
quite hard for me to provide

933
01:04:56,320 --> 01:05:01,010
reasoning support for the kind of RDF inference

934
01:05:01,350 --> 01:05:05,130
so i have this problem the RDF is kind of in some ways week in

935
01:05:05,130 --> 01:05:09,320
a language that allows me to express kind of isn't rich enough to capture some

936
01:05:09,320 --> 01:05:13,280
of the relationships among capture my domain but also it's actually quite strong in other

937
01:05:15,850 --> 01:05:20,310
so the proposed solution was to extend RDF schema with a language which has a

938
01:05:20,310 --> 01:05:25,410
number of desirable characteristics should extend existing web standards to ensure that we can sit

939
01:05:25,410 --> 01:05:29,210
within this space we can interoperating can make tools

940
01:05:29,250 --> 01:05:33,810
it should be easy to understand and use this is of course a kind of

941
01:05:33,830 --> 01:05:36,150
subjective terms

942
01:05:36,410 --> 01:05:40,330
it should have adequate expressive power OK so again this is subjective based on the

943
01:05:40,330 --> 01:05:42,690
context of application that you have

944
01:05:42,910 --> 01:05:46,750
it should be formally specified so that we can provide some reasoning support and this

945
01:05:46,750 --> 01:05:52,890
is the proposed that language that was out there with me he's these requirements

946
01:05:52,900 --> 01:05:57,900
there some insights on the history of volcanic already covered some of this so all

947
01:05:57,940 --> 01:06:01,310
i'll skip over these again these are in the slide so you can you can

948
01:06:01,310 --> 01:06:02,850
read them

949
01:06:02,880 --> 01:06:05,870
so essentially what we have

950
01:06:05,890 --> 01:06:07,310
this we have

951
01:06:07,330 --> 01:06:09,440
a number of different languages

952
01:06:10,760 --> 01:06:14,810
and i say something more about the details of what's actually in the language later

953
01:06:14,810 --> 01:06:20,540
on but i always was constructed to have what was called layer and this allowed

954
01:06:20,550 --> 01:06:25,230
us to basically provides languages which had a very limited expressivity

955
01:06:25,270 --> 01:06:29,970
OK so depending on the application that we had the requirements that you had you

956
01:06:29,970 --> 01:06:32,910
could choose a language with different layer of

957
01:06:34,060 --> 01:06:36,340
so for example we have all fall

958
01:06:36,350 --> 01:06:39,070
which is the union of

959
01:06:39,080 --> 01:06:45,340
the OWL syntax is all the operator's dl language and vocabulary with RDF with little

960
01:06:45,340 --> 01:06:46,480
restrictions on them

961
01:06:46,530 --> 01:06:50,010
there's a language called OWL DL talk talk about more about later

962
01:06:50,060 --> 01:06:55,470
which was the restrict the restriction of the use of all two language which corresponds

963
01:06:55,480 --> 01:06:59,850
to a fragment of first-order logic and reason why this was chosen because this that

964
01:06:59,850 --> 01:07:03,700
allows us to do some reasoning OK so this allows us to have an inference

965
01:07:03,760 --> 01:07:08,380
based on existing algorithms which we know has kind of nice characteristics

966
01:07:08,440 --> 01:07:11,430
there is also a language called OWL lite which is simply a subset of OWL

967
01:07:13,210 --> 01:07:17,840
and these languages are layered so we have what we call syntactic layering so essentially

968
01:07:18,490 --> 01:07:23,080
a light ontology that i can write down is also an DL ontology and any

969
01:07:23,080 --> 01:07:29,370
OWL DL ontologies also now full ontology and certainly as semantic layering whereby any inferences

970
01:07:29,370 --> 01:07:33,530
that we can draw using these languages will correspond case any inference we can do

971
01:07:33,530 --> 01:07:38,590
in OWL lite should correspond to inference which is done in algeria

972
01:07:38,600 --> 01:07:39,770
so powerful

973
01:07:39,880 --> 01:07:44,150
with an awful there is no restriction on the use of the OWL vocabulary OK

974
01:07:44,150 --> 01:07:48,740
so i can i can essentially produce our RDF graphs make use of OWL vocabulary

975
01:07:49,120 --> 01:07:52,920
and there's no restriction on what i can do i can say anything

976
01:07:52,970 --> 01:07:55,310
and this is

977
01:07:55,400 --> 01:07:58,950
the semantic here given in terms of the RDF style model theory i'm not going

978
01:07:58,950 --> 01:08:02,840
to talk about the details of this kind of if you interested in looking up

979
01:08:03,960 --> 01:08:07,240
looking at some of the details of this that i continue around

980
01:08:08,930 --> 01:08:12,880
so the URL is kind of the presentation so you can go and look at

981
01:08:12,880 --> 01:08:16,660
the information here it is on the w three c site in the documentation

982
01:08:16,830 --> 01:08:19,780
associated RDF

983
01:08:19,810 --> 01:08:21,310
so i bl

984
01:08:22,600 --> 01:08:26,320
here we have the use of vocabulary is being restricted in some way

985
01:08:26,330 --> 01:08:29,170
so that we can do some of the things we can do now

986
01:08:29,170 --> 01:08:33,790
and now falls so for example we can modify the vocabulary itself so we're not

987
01:08:33,790 --> 01:08:38,760
allowed to say things about language itself we have some restrictions on the math modelling

988
01:08:38,760 --> 01:08:40,920
that we can perform here

989
01:08:40,940 --> 01:08:44,650
and we have what we call that we have a model theory which is based

990
01:08:44,650 --> 01:08:50,180
on some first order logic description logic model theory so there's some direct correspondence here

991
01:08:50,190 --> 01:08:54,260
between the subset and subset of first-order logic which will will see more about a

992
01:08:55,260 --> 01:08:57,460
and one of the benefits here was the

993
01:08:58,180 --> 01:09:02,430
we were able to kind of leverage off so a number of years of research

994
01:09:02,430 --> 01:09:08,300
into the representation languages so we had some well defined semantics we have known properties

995
01:09:08,300 --> 01:09:12,480
of how we could reason with these languages have known properties but the behaviour of

996
01:09:12,480 --> 01:09:18,560
reasoning with these languages in terms of the complexity the decidability and so on

997
01:09:18,580 --> 01:09:24,290
OWL lite was enough for the subset here with with a few constructs now in

998
01:09:24,600 --> 01:09:27,480
practice i think with hindsight the

999
01:09:27,480 --> 01:09:31,080
the experience seems to be the OWL lite not really the kind of particularly picked

1000
01:09:31,080 --> 01:09:35,680
up there the fragments which kind of sit somewhere around like the people are actually

1001
01:09:35,680 --> 01:09:38,540
really using in practice

1002
01:09:40,870 --> 01:09:46,000
OK so all goal

1003
01:09:46,020 --> 01:09:48,960
OK so this is this is probably quite important here

1004
01:09:49,070 --> 01:09:56,350
the semantics of the OWL DL fragment given using a model theoretic approach

1005
01:09:56,370 --> 01:09:57,590
OK so i have

1006
01:09:57,650 --> 01:09:59,240
i have an interpretation

1007
01:09:59,260 --> 01:10:00,910
OK which describes

1008
01:10:00,910 --> 01:10:05,600
the semantics in terms of a collection of objects and some functions that map my

1009
01:10:05,620 --> 01:10:10,460
classes to sets of objects i'm really kind of thinking of the classes in my

1010
01:10:10,460 --> 01:10:15,030
ontology as collections of objects in my domain can

1011
01:10:15,060 --> 01:10:19,740
and also my properties to pairs of objects properties are relating pairs of objects together

1012
01:10:20,030 --> 01:10:23,390
the classes of describing sets of objects in the domain

1013
01:10:24,000 --> 01:10:27,070
in this in this approach

1014
01:10:27,080 --> 01:10:33,240
class descriptions and characterisation of the individuals that are members of that class

1015
01:10:33,240 --> 01:10:35,440
so what we have now is we have

1016
01:10:35,620 --> 01:10:39,870
vocabulary that allows us to describe

1017
01:10:39,880 --> 01:10:46,640
classes of individuals OK and we have operators to allow kind of form together combine

1018
01:10:46,650 --> 01:10:48,280
those those those

1019
01:10:48,370 --> 01:10:51,490
classes into composite descriptions

1020
01:10:51,510 --> 01:10:56,790
so i have a number of operators for constructing class expressions

1021
01:10:57,220 --> 01:11:00,700
so basically we can we can talk about

1022
01:11:00,750 --> 01:11:03,210
underlying classes

1023
01:11:03,210 --> 01:11:06,270
so here i have an example which is a basic class which is the class

1024
01:11:06,270 --> 01:11:08,430
of humans case so these are

1025
01:11:08,450 --> 01:11:12,450
this this the interpretation here would be a collection of individuals in my domain which

1026
01:11:12,450 --> 01:11:15,580
at time t

1027
01:11:15,630 --> 01:11:18,780
the acceleration took place at an earlier time

1028
01:11:18,800 --> 01:11:21,640
because the radiation has to reach me

1029
01:11:21,650 --> 01:11:23,180
so t prime

1030
01:11:23,190 --> 01:11:24,690
it is then t

1031
01:11:24,690 --> 01:11:29,440
minors are divided by c is always the time delay

1032
01:11:29,450 --> 01:11:31,180
that's the reason

1033
01:11:31,240 --> 01:11:33,610
why we write down these equations

1034
01:11:36,290 --> 01:11:39,140
so i right now than in all weights

1035
01:11:39,210 --> 01:11:42,800
its glory weighted you would find it in most books

1036
01:11:42,840 --> 01:11:46,420
so this is not a e vector

1037
01:11:46,430 --> 01:11:49,020
due to an accelerated charged

1038
01:11:49,080 --> 01:11:51,500
you may choose the direction are

1039
01:11:51,560 --> 01:11:53,920
and is a function of time

1040
01:11:53,920 --> 01:11:55,650
and that now becomes

1041
01:11:55,740 --> 01:11:58,790
minus i'll get back to the minus sign

1042
01:11:58,840 --> 01:12:02,450
then i get a perpendicular at time t prime

1043
01:12:02,470 --> 01:12:05,120
whereas this is at time t

1044
01:12:05,180 --> 01:12:07,830
that is the connection between the two

1045
01:12:07,840 --> 01:12:09,990
proportion the charge

1046
01:12:10,040 --> 01:12:11,920
divided by c squared

1047
01:12:11,920 --> 01:12:13,260
four pi

1048
01:12:13,280 --> 01:12:19,150
epsilon zero and just one hour

1049
01:12:19,200 --> 01:12:21,000
you have the privilege

1050
01:12:21,020 --> 01:12:23,260
to convert not conferred

1051
01:12:23,270 --> 01:12:25,690
right down for me or for yourself

1052
01:12:25,700 --> 01:12:27,910
what is associated be feel this

1053
01:12:27,910 --> 01:12:31,980
it's very easy of course the strength of the b field is see times smaller

1054
01:12:32,000 --> 01:12:35,990
you must make sure that the crosby is in the direction of propagation

1055
01:12:36,040 --> 01:12:37,700
so i'll leave you with that

1056
01:12:37,740 --> 01:12:39,050
and then we get

1057
01:12:39,090 --> 01:12:41,130
that the poynting vector

1058
01:12:41,140 --> 01:12:42,430
as a function

1059
01:12:42,500 --> 01:12:43,650
of rt

1060
01:12:43,690 --> 01:12:48,150
is then e crosby

1061
01:12:48,270 --> 01:12:51,010
divided by new zero

1062
01:12:51,020 --> 01:12:53,920
and there you have the entire set

1063
01:12:55,230 --> 01:12:56,890
tells me

1064
01:12:56,890 --> 01:12:58,530
what electric field is

1065
01:12:58,550 --> 01:13:03,350
due to the acceleration but the magnetic field is to tune acceleration and now

1066
01:13:03,350 --> 01:13:04,680
what the

1067
01:13:04,730 --> 01:13:06,160
the poynting vector is

1068
01:13:06,160 --> 01:13:07,950
how many joules per second for

1069
01:13:07,970 --> 01:13:11,340
square meter flow out

1070
01:13:11,350 --> 01:13:16,190
a perpendicular

1071
01:13:16,200 --> 01:13:23,160
is different for different directions

1072
01:13:23,250 --> 01:13:25,650
if i call this angle theta

1073
01:13:27,580 --> 01:13:30,230
a perpendicular is zero

1074
01:13:30,250 --> 01:13:34,500
if i am looking down here because then A's taught me there is no perpendicular

1075
01:13:35,460 --> 01:13:36,620
if i am

1076
01:13:36,680 --> 01:13:41,540
in this direction than a perpendicular is the same as a

1077
01:13:41,560 --> 01:13:42,640
so you see

1078
01:13:42,640 --> 01:13:45,560
that the strength of the electric field

1079
01:13:45,680 --> 01:13:49,910
is a strong function of that angle theta

1080
01:13:49,980 --> 01:13:53,770
so what you're going to see is that a spherical we're going out from this

1081
01:13:53,770 --> 01:13:55,810
accelerated charge

1082
01:13:55,870 --> 01:14:00,290
but the electric field strength in that spherical wave going on all directions is the

1083
01:14:00,290 --> 01:14:05,100
strongest in this plane here perpendicular to a and is zero

1084
01:14:05,120 --> 01:14:09,870
in that direction

1085
01:14:09,870 --> 01:14:15,020
and so i would like to make is somewhat different

1086
01:14:15,080 --> 01:14:16,730
somewhat simplified

1087
01:14:16,790 --> 01:14:18,140
picture for you

1088
01:14:18,190 --> 01:14:20,100
to stress the connection

1089
01:14:20,140 --> 01:14:23,730
and to also address the minus sign

1090
01:14:23,750 --> 01:14:26,560
so if this is the direction

1091
01:14:26,600 --> 01:14:29,080
of the acceleration in a

1092
01:14:29,080 --> 01:14:33,980
so i put a vector in here

1093
01:14:34,080 --> 01:14:37,830
then this is a perpendicular let's first choose the direction of or

1094
01:14:37,850 --> 01:14:40,480
these are

1095
01:14:40,500 --> 01:14:43,390
you can show that any way you want to sort and this would be a

1096
01:14:46,850 --> 01:14:50,060
and if the charge is positive

1097
01:14:50,160 --> 01:14:53,680
which i have chosen here because look the field lines go away

1098
01:14:53,770 --> 01:14:57,850
then the vector perpendicular is in this direction

1099
01:14:57,890 --> 01:15:00,830
it's like so

1100
01:15:00,890 --> 01:15:05,000
and that is the reason for the minus sign

1101
01:15:05,890 --> 01:15:07,770
if q is positive

1102
01:15:08,560 --> 01:15:13,140
he is in the opposite direction of a perpendicular if q is negative then it

1103
01:15:13,140 --> 01:15:17,120
is in the same direction

1104
01:15:17,120 --> 01:15:18,350
and then

1105
01:15:18,410 --> 01:15:23,660
you get that is angle theta is very important

1106
01:15:23,660 --> 01:15:24,960
the vector

1107
01:15:24,960 --> 01:15:27,790
is proportional to sign of failure

1108
01:15:27,810 --> 01:15:29,660
because a perpendicular

1109
01:15:29,730 --> 01:15:33,310
is of course eight times the sign of theta

1110
01:15:33,370 --> 01:15:37,060
and so the vector in the the vector have signs of theta in the

1111
01:15:37,080 --> 01:15:40,910
and the poynting vector cosine square data in the

1112
01:15:40,960 --> 01:15:44,430
because this as a sign of data and this as a sign of data

1113
01:15:44,480 --> 01:15:46,640
so the poynting vector s

1114
01:15:46,680 --> 01:15:48,460
is proportional

1115
01:15:48,520 --> 01:15:52,750
two designs scroll fader

1116
01:15:52,770 --> 01:15:57,020
and so sort spherical waves going in all their actions

1117
01:15:57,080 --> 01:16:00,330
the poynting vector is very different for the different directions

1118
01:16:00,390 --> 01:16:03,810
the amount of energy per second that flows out

1119
01:16:03,850 --> 01:16:08,270
per square metre in the plane perpendicular to the arbitration is very high

1120
01:16:08,290 --> 01:16:13,290
and it is zero in this direction if you look here you would see nothing

1121
01:16:13,330 --> 01:16:14,770
if you look here

1122
01:16:14,790 --> 01:16:17,690
what's the maximum and anything in between

1123
01:16:17,750 --> 01:16:18,870
you would see

1124
01:16:18,890 --> 01:16:22,810
less than the maximum at more than zero

1125
01:16:22,870 --> 01:16:24,770
so this is really

1126
01:16:26,830 --> 01:16:28,850
a plane wave

1127
01:16:28,910 --> 01:16:31,910
infinitely in all its if anything is more spherical

1128
01:16:31,930 --> 01:16:34,270
and that is the plane wave

1129
01:16:34,270 --> 01:16:37,290
however if you very far away from the origin

1130
01:16:37,350 --> 01:16:40,160
you can probably locally approximated by

1131
01:16:40,160 --> 01:16:44,040
a plane wave solution

1132
01:16:44,100 --> 01:16:46,460
so now i want to summarize for you

1133
01:16:46,500 --> 01:16:51,080
basically what i want you to remember and which is all that i remember

1134
01:16:51,100 --> 01:16:53,600
and that is how do you find the vector

1135
01:16:53,660 --> 01:16:55,830
if you know the acceleration

1136
01:16:55,870 --> 01:16:58,450
and you know where you are in space

1137
01:16:59,140 --> 01:17:02,160
we accelerate q

1138
01:17:02,180 --> 01:17:04,640
and we do not in the direction a

1139
01:17:07,520 --> 01:17:08,770
and you are

1140
01:17:12,020 --> 01:17:15,620
some position in space are

1141
01:17:15,690 --> 01:17:18,810
they you observe an electromagnetic wave

1142
01:17:18,810 --> 01:17:21,310
but you observe time delay

1143
01:17:21,310 --> 01:17:23,950
which i'm not further

1144
01:17:23,960 --> 01:17:25,250
expand on

1145
01:17:25,310 --> 01:17:28,830
now comes the key thing that the field

1146
01:17:28,870 --> 01:17:32,690
this the approach

1147
01:17:37,660 --> 01:17:39,160
and a

1148
01:17:39,180 --> 01:17:42,060
you can confirm that was

1149
01:17:42,120 --> 01:17:43,710
this picture there

1150
01:17:43,710 --> 01:17:47,830
so what are you choose you may choose any are you want to also outside

1151
01:17:47,830 --> 01:17:50,770
the blackboard of course this is just for simplicity

1152
01:17:50,810 --> 01:17:52,000
e vector

1153
01:17:52,060 --> 01:17:53,980
must be in that plane

1154
01:17:54,020 --> 01:17:55,850
but the factory

1155
01:17:56,290 --> 01:17:59,390
must be perpendicular to or

1156
01:17:59,430 --> 01:18:04,250
maxwell's equations the man that e vectors perpendicular to the direction of propagation for a

1157
01:18:04,250 --> 01:18:07,770
traveling wave

1158
01:18:07,810 --> 01:18:10,180
the magnitude of the vector

1159
01:18:10,230 --> 01:18:11,600
is proportional

1160
01:18:11,620 --> 01:18:12,960
two the magnitude

1161
01:18:12,980 --> 01:18:15,730
of the a perpendicular

1162
01:18:15,750 --> 01:18:18,850
and the magnitude of e

1163
01:18:18,850 --> 01:18:21,750
is proportional to one of our

1164
01:18:21,750 --> 01:18:24,270
and if q is positive

1165
01:18:24,330 --> 01:18:27,120
then e is in that direction

1166
01:18:27,160 --> 01:18:31,850
mine is a perpendicular if q is negative then it is in the direction

1167
01:18:31,870 --> 01:18:35,680
of a perpendicular

1168
01:18:35,680 --> 01:18:36,970
there's another paper we

1169
01:18:37,410 --> 01:18:38,690
employed a similar strategy

1170
01:18:40,120 --> 01:18:45,410
but where we still have this markov chain idea although it's not necessary for marketing make during training

1171
01:18:46,120 --> 01:18:49,980
so now the black box is a bit more complicated sequence like boxes

1172
01:18:50,440 --> 01:18:52,570
is the same box we use all right all again

1173
01:18:53,100 --> 01:18:54,250
and the box has

1174
01:18:54,900 --> 01:18:55,540
in addition to

1175
01:18:56,090 --> 01:18:58,190
the random numbers going in the parameters coming in

1176
01:18:58,930 --> 01:19:01,670
it has a previous state coming in and out of the next state

1177
01:19:02,700 --> 01:19:03,530
so so now

1178
01:19:04,150 --> 01:19:05,910
you take the previous state from the

1179
01:19:06,380 --> 01:19:10,430
preview the output the the next day the previous application of this red box

1180
01:19:10,850 --> 01:19:13,950
this is the next paper was previously for the next one

1181
01:19:14,470 --> 01:19:17,050
and basically what doing here is is a markov chain

1182
01:19:17,610 --> 01:19:20,460
it turns out that it's possible to train the markov chain

1183
01:19:21,250 --> 01:19:23,190
using as a training criterion

1184
01:19:24,090 --> 01:19:27,960
the reconstruction error criterion we find autoencoders

1185
01:19:28,580 --> 01:19:29,650
come back to that later

1186
01:19:30,560 --> 01:19:32,900
something very very simple you can find by backdrop

1187
01:19:33,600 --> 01:19:37,350
so what are the things that has happened recently is that we realize that we can

1188
01:19:38,550 --> 01:19:40,240
we can avoid this these

1189
01:19:42,450 --> 01:19:45,640
these markov chains are an essentially use backprop

1190
01:19:46,280 --> 01:19:47,690
train these generative models

1191
01:19:49,140 --> 01:19:50,330
it is also how we try be

1192
01:19:50,870 --> 01:19:52,300
be deep and very deep

1193
01:19:53,060 --> 01:19:54,280
generative industrial needs

1194
01:19:56,200 --> 01:19:56,560
there is

1195
01:19:59,700 --> 01:20:01,860
a set of related approaches

1196
01:20:02,800 --> 01:20:04,460
which avoid again these these

1197
01:20:05,030 --> 01:20:05,990
these markov chains

1198
01:20:06,700 --> 01:20:08,020
at unit during training

1199
01:20:11,920 --> 01:20:14,580
i have come up in the last nine months roughly

1200
01:20:15,370 --> 01:20:17,350
well so there's much more the

1201
01:20:18,050 --> 01:20:20,070
called helmholtz machines from the mid nineties

1202
01:20:21,290 --> 01:20:22,810
game geoff hinton was part of the gang

1203
01:20:26,150 --> 01:20:28,100
in the since starting about

1204
01:20:29,030 --> 01:20:31,310
last december review papers are starting to come out

1205
01:20:32,730 --> 01:20:33,570
more coming out

1206
01:20:36,020 --> 01:20:39,740
ways to build what's called a directed graphical models

1207
01:20:40,230 --> 01:20:41,840
but avoids some of these

1208
01:20:42,280 --> 01:20:45,450
intractability that have been associated with these kinds of models in the past

1209
01:20:46,580 --> 01:20:47,840
in the first these

1210
01:20:48,780 --> 01:20:50,490
which i think is gonna have a lot of impact

1211
01:20:50,980 --> 01:20:54,990
is a paper was presented i cleared doesn't fourteen but

1212
01:20:55,450 --> 01:20:57,890
tech report came out in december two thousand thirteen

1213
01:20:59,020 --> 01:20:59,940
kingman dwelling

1214
01:21:01,060 --> 01:21:09,250
which is about what i call variational autoencoders the title their paper something about bayesian variational something autoencoders but it's

1215
01:21:09,710 --> 01:21:11,680
the world is different but it's the same idea

1216
01:21:12,300 --> 01:21:13,220
and the idea is

1217
01:21:14,620 --> 01:21:17,760
he realized was already in house machine paper from ninety five

1218
01:21:18,850 --> 01:21:20,690
you can have you are

1219
01:21:21,950 --> 01:21:24,160
generative network which is just a sequenceof

1220
01:21:25,580 --> 01:21:27,220
you are stochastic or deterministic

1221
01:21:28,160 --> 01:21:32,610
at the top level you inject something that looks like noise and output generators samples

1222
01:21:32,690 --> 01:21:35,830
so that's the thing picture i showed before but now has multiple layers

1223
01:21:36,560 --> 01:21:37,060
that's the key

1224
01:21:38,220 --> 01:21:38,760
so that's

1225
01:21:39,100 --> 01:21:39,690
your model

1226
01:21:40,400 --> 01:21:41,990
at the joint distribution between

1227
01:21:43,350 --> 01:21:43,840
the visible

1228
01:21:44,280 --> 01:21:45,330
some latent variables

1229
01:21:46,850 --> 01:21:48,640
visible and latent period age

1230
01:21:49,490 --> 01:21:52,160
but you're gonna learn another perhaps cuba

1231
01:21:53,090 --> 01:21:54,990
which has associated joint distribution

1232
01:21:55,800 --> 01:21:59,160
which is driven by the training data so that when it comes from the bottom

1233
01:21:59,670 --> 01:22:04,500
in predicts what the latent variables should be through multiple layers which could be stochastic or not

1234
01:22:06,790 --> 01:22:07,790
this kind of setup

1235
01:22:08,380 --> 01:22:10,110
there has been a lot of work recently

1236
01:22:13,910 --> 01:22:15,700
and the target propagation thing i mentioned

1237
01:22:17,150 --> 01:22:19,020
earlier as part of the thing as well

1238
01:22:21,220 --> 01:22:22,630
so you notice that

1239
01:22:25,540 --> 01:22:28,040
there's a kind of falling water here if you've faulty

1240
01:22:30,040 --> 01:22:32,310
you start from the one which is

1241
01:22:32,970 --> 01:22:35,010
example from the dataset you will

1242
01:22:35,770 --> 01:22:36,600
you get a representation

1243
01:22:37,210 --> 01:22:37,790
and that's what

1244
01:22:38,220 --> 01:22:39,750
the output of an encoder basically

1245
01:22:40,400 --> 01:22:41,430
but stochastic one

1246
01:22:41,870 --> 01:22:45,290
then you go back down from the people at the decoder

1247
01:22:46,110 --> 01:22:46,940
and you're trying to make

1248
01:22:50,060 --> 01:22:52,150
examples are generated very close to

1249
01:22:53,000 --> 01:22:53,910
your original input

1250
01:22:54,450 --> 01:22:58,720
that's reconstruction air so the way these are trying actually is very similar to

1251
01:22:59,240 --> 01:23:00,440
we're trying to autoencoders

1252
01:23:00,970 --> 01:23:03,460
but there are a few bells and whistles are different which

1253
01:23:04,710 --> 01:23:05,950
seem to be important actually

1254
01:23:08,640 --> 01:23:10,290
what is an autoencoder is just

1255
01:23:12,050 --> 01:23:13,900
a particular kind of neural net

1256
01:23:14,490 --> 01:23:17,740
in which is decomposed into functions then called an equal

1257
01:23:19,340 --> 01:23:22,130
and there's something in between which is a representation in computing

1258
01:23:27,250 --> 01:23:31,280
the encoder and the decoder trying to be inverses eachother but

1259
01:23:32,190 --> 01:23:35,570
are not just arbitrary inverse otherwise you could just identity function

1260
01:23:36,820 --> 01:23:37,550
you're trying to

1261
01:23:40,130 --> 01:23:44,110
encoder decoder to work well the ones to have low reconstruction error

1262
01:23:45,030 --> 01:23:46,630
only for the training examples

1263
01:23:47,450 --> 01:23:48,320
but potentially give

1264
01:23:49,180 --> 01:23:52,300
hi reconstruction error elsewhere far from examples

1265
01:23:54,560 --> 01:23:57,400
well the all way of doing this is to make me

1266
01:23:58,220 --> 01:23:59,390
he later small

1267
01:23:59,720 --> 01:24:00,800
smaller than the input

1268
01:24:02,180 --> 01:24:07,860
one special case of this of course is principal components analysis if the encoder is linear inequalities in here

1269
01:24:08,970 --> 01:24:11,970
and the reconstruction error squared here like like in this line

1270
01:24:13,400 --> 01:24:15,320
and then you get peace you essentially

1271
01:24:16,190 --> 01:24:18,470
but if you introduce nonlinearities now you can learn

1272
01:24:18,920 --> 01:24:20,160
much more interesting things

1273
01:24:20,560 --> 01:24:24,120
one thing you might know is that you see is is equivalent to modeling

1274
01:24:24,640 --> 01:24:26,560
he input with eh

1275
01:24:26,920 --> 01:24:28,570
guassian in multivariate calcium

1276
01:24:29,190 --> 01:24:34,350
one autoencoders nonlinearities allow you to do is the model more complicated distributions than the gas in

1277
01:24:37,410 --> 01:24:40,520
indeed reconstruction doesn't have to be square area could be

1278
01:24:41,260 --> 01:24:45,120
any kind of like actually so you can use the usual cross entropy

1279
01:24:46,400 --> 01:24:48,740
which is just the log conditional like you

1280
01:24:50,430 --> 01:24:53,760
you can think of the reconstruction error is just minus log

1281
01:24:54,370 --> 01:24:58,210
he of x given age in other words you have representation age

1282
01:24:58,860 --> 01:25:00,560
from fact that the output of the encoder

1283
01:25:01,190 --> 01:25:02,780
and from its you're trying to predict

1284
01:25:03,230 --> 01:25:03,960
the probability

1285
01:25:05,890 --> 01:25:09,430
be original input and you want the probability to be as large as possible

1286
01:25:13,040 --> 01:25:13,410
all right

1287
01:25:14,550 --> 01:25:15,590
now there is he

1288
01:25:16,350 --> 01:25:17,600
there's been a number of different

1289
01:25:18,260 --> 01:25:21,560
types of what call have been proposed in the literature in the last saw

1290
01:25:24,740 --> 01:25:25,360
eight years

1291
01:25:28,050 --> 01:25:28,590
there's one

1292
01:25:29,100 --> 01:25:30,400
on which there has been a lot more

1293
01:25:31,190 --> 01:25:34,380
mathematical work and anything be understanding of what they do

1294
01:25:35,010 --> 01:25:37,140
has reached a point where r on

1295
01:25:38,840 --> 01:25:41,090
it helps to draw a much clearer picture

1296
01:25:41,690 --> 01:25:42,910
what would and quarters are doing

1297
01:25:42,910 --> 01:25:47,660
they allow for repetitions of nodes could be of infinite length

1298
01:25:47,660 --> 01:25:52,410
so you similarity score would be infinity which is not what you want

1299
01:25:52,460 --> 01:25:56,520
two here this problem you don't wait longer walks

1300
01:25:56,570 --> 01:25:57,570
by using

1301
01:25:57,580 --> 01:25:59,090
a lambda

1302
01:25:59,110 --> 01:26:03,650
smaller than one

1303
01:26:03,650 --> 01:26:05,410
then you compute

1304
01:26:05,450 --> 01:26:07,430
this geometric series here

1305
01:26:07,440 --> 01:26:10,660
for values of k from zero to infinity

1306
01:26:10,680 --> 01:26:12,470
you obtain

1307
01:26:13,760 --> 01:26:15,590
as limit of this series

1308
01:26:15,610 --> 01:26:18,010
and then you add up over all entries

1309
01:26:18,020 --> 01:26:19,600
of the matrix

1310
01:26:19,620 --> 01:26:20,580
which is

1311
01:26:20,590 --> 01:26:23,900
one scalar and that's your similarity score

1312
01:26:23,930 --> 01:26:33,260
your kernel value for the two given graphs g and g-prime

1313
01:26:33,280 --> 01:26:36,370
but then we look at that

1314
01:26:36,380 --> 01:26:38,210
on the following slides

1315
01:26:38,240 --> 01:26:41,510
these random walk comments have their own

1316
01:26:43,930 --> 01:26:46,750
the runtime problem as we will see

1317
01:26:46,800 --> 01:26:52,880
these random walk kernels as they were defined in two thousand and two thousand three

1318
01:26:52,930 --> 01:26:55,810
required runtime of O of n to the six

1319
01:26:55,870 --> 01:26:57,080
and that's

1320
01:26:57,090 --> 01:27:01,170
are you trying time effort if you're working with large graphs

1321
01:27:01,170 --> 01:27:02,840
the second problem

1322
01:27:02,920 --> 01:27:07,400
cause tottering we also have a look at this problem

1323
01:27:07,440 --> 01:27:09,150
later on

1324
01:27:09,190 --> 01:27:11,560
it means

1325
01:27:12,970 --> 01:27:17,690
because you allow for repetitions of nodes in your walks

1326
01:27:17,770 --> 01:27:18,760
your walks

1327
01:27:18,760 --> 01:27:20,310
may visit

1328
01:27:20,330 --> 01:27:21,260
the same

1329
01:27:21,320 --> 01:27:24,210
set of nodes all over again

1330
01:27:24,240 --> 01:27:28,550
they may visit the same cycle over again or even in an undirected graph they

1331
01:27:28,550 --> 01:27:30,400
may go back and forth

1332
01:27:30,450 --> 01:27:33,350
between the same two nodes a and b all the time

1333
01:27:33,400 --> 01:27:35,160
thereby creating

1334
01:27:35,210 --> 01:27:36,820
a long common walk

1335
01:27:36,840 --> 01:27:41,720
in your two input graphs and thereby creating a huge similarity score just

1336
01:27:41,760 --> 01:27:43,520
because of one common edge

1337
01:27:43,520 --> 01:27:45,240
between the two input graphs

1338
01:27:45,270 --> 01:27:46,570
that's too

1339
01:27:46,590 --> 01:27:48,790
the phenomenon of tottering

1340
01:27:48,800 --> 01:27:52,200
there's another phenomenon that i observe which is

1341
01:27:52,240 --> 01:27:55,090
the problem of halting

1342
01:27:57,070 --> 01:28:00,030
let me go back to slides to show this

1343
01:28:00,970 --> 01:28:02,350
you have to choose

1344
01:28:02,380 --> 01:28:04,710
you're decaying factor lambda

1345
01:28:04,710 --> 01:28:07,070
so small

1346
01:28:07,090 --> 01:28:08,590
in order to make this

1347
01:28:08,600 --> 01:28:15,530
geometric series converge that you completely downweight any walk is longer than

1348
01:28:15,580 --> 01:28:17,190
ten of them

1349
01:28:17,230 --> 01:28:18,510
so basically

1350
01:28:18,520 --> 01:28:19,970
often you have to

1351
01:28:19,970 --> 01:28:23,400
choose your lambda so small that in the end of the day

1352
01:28:23,450 --> 01:28:26,230
you just comparing walks of length one

1353
01:28:26,250 --> 01:28:28,200
you two graphs and that

1354
01:28:28,240 --> 01:28:33,250
just a simple similarity measure between two graphs that compares all at all pairs of

1355
01:28:34,180 --> 01:28:38,240
of two input graphs G and G prime

1356
01:28:38,290 --> 01:28:40,260
so for example

1357
01:28:40,310 --> 01:28:44,100
if lambda is one over ten thousand then walks

1358
01:28:44,150 --> 01:28:45,400
of length one

1359
01:28:45,410 --> 01:28:50,210
get ten thousand times more weight in the kernel similarity score then walks of length

1360
01:28:52,070 --> 01:28:56,340
these again ten thousand times more than walks of length three and you can

1361
01:28:56,340 --> 01:28:58,050
imagine at the end of the day

1362
01:28:58,100 --> 01:29:01,680
the only thing that you're comparing all walks of length one

1363
01:29:01,750 --> 01:29:04,260
which means edges

1364
01:29:04,320 --> 01:29:07,810
that's the problem of quality

1365
01:29:07,850 --> 01:29:12,170
and these problems have inspired a lot of work in the machine learning community

1366
01:29:12,240 --> 01:29:14,850
especially in the community of common machines

1367
01:29:19,230 --> 01:29:21,850
and this research try to heal these

1368
01:29:21,880 --> 01:29:26,690
three problems the runtime problems the problem of tottering and the problem of halting. we will

1369
01:29:26,690 --> 01:29:28,220
have a closer look

1370
01:29:29,900 --> 01:29:32,270
of these approaches

1371
01:29:32,290 --> 01:29:33,680
we have look at

1372
01:29:33,720 --> 01:29:34,770
the method

1373
01:29:37,520 --> 01:29:39,050
achieved to

1374
01:29:39,060 --> 01:29:43,960
compute these random walk kernels much faster than was possible before

1375
01:29:43,970 --> 01:29:45,680
we'll have

1376
01:29:45,800 --> 01:29:47,020
closer look

1377
01:29:47,250 --> 01:29:51,780
the technique by my head out from ICML two thousand four

1378
01:29:51,800 --> 01:29:53,260
where they

1379
01:29:53,260 --> 01:29:54,660
propose to ways

1380
01:29:54,660 --> 01:29:56,670
of preventing tottering

1381
01:29:56,710 --> 01:29:58,160
and speeding up

1382
01:29:58,180 --> 01:30:01,150
graph kernel computation

1383
01:30:01,160 --> 01:30:03,450
and then this work

1384
01:30:03,500 --> 01:30:04,760
based on the idea here

1385
01:30:05,430 --> 01:30:08,670
rather compare shortest path into graphs

1386
01:30:08,680 --> 01:30:11,400
then walks thereby getting rid

1387
01:30:11,410 --> 01:30:15,570
after problem of torturing and halting

1388
01:30:15,590 --> 01:30:16,690
we start

1389
01:30:16,690 --> 01:30:18,310
by this approach by

1390
01:30:18,400 --> 01:30:21,540
vishwanathan et al from nips two thousand six

1391
01:30:21,610 --> 01:30:23,320
why is the

1392
01:30:23,410 --> 01:30:25,330
direct computation

1393
01:30:25,340 --> 01:30:26,950
after random

1394
01:30:26,990 --> 01:30:28,480
walk kernel

1395
01:30:28,530 --> 01:30:31,740
you know of n to the six

1396
01:30:31,740 --> 01:30:35,590
so they they they were using as a vertical control

1397
01:30:35,600 --> 01:30:37,100
just the

1398
01:30:40,060 --> 01:30:43,580
the addition of the activities of these two electrodes

1399
01:30:43,650 --> 01:30:47,190
and the horizontal control the subject it

1400
01:30:47,200 --> 01:30:50,940
so they have it's it's just two linear equations

1401
01:30:52,660 --> 01:30:53,730
then they

1402
01:30:53,740 --> 01:30:57,870
there some some gain parameter that they have to

1403
01:30:58,490 --> 01:31:01,020
control and that's it

1404
01:31:02,150 --> 01:31:03,810
let me

1405
01:31:03,820 --> 01:31:05,120
let me show

1406
01:31:05,140 --> 01:31:06,910
so so these are some

1407
01:31:06,930 --> 01:31:09,710
some pictures of of some

1408
01:31:09,730 --> 01:31:15,770
different users for different users and you see that first of all you see the

1409
01:31:15,770 --> 01:31:17,540
speed like

1410
01:31:17,550 --> 01:31:21,940
the paradigms such you have the ball in the centre

1411
01:31:22,070 --> 01:31:23,960
and then

1412
01:31:23,970 --> 01:31:25,720
in the periphery

1413
01:31:26,330 --> 01:31:31,250
there's some classes some boxes lighting up and you you're supposed to move to the

1414
01:31:31,270 --> 01:31:33,730
fall into these boxes

1415
01:31:33,750 --> 01:31:35,490
although the break

1416
01:31:36,890 --> 01:31:37,790
it says

1417
01:31:37,800 --> 01:31:42,320
they can this trajectory to point seven seconds

1418
01:31:43,180 --> 01:31:44,830
this one

1419
01:31:44,850 --> 01:31:50,380
this whole task i mean for example is going to longer twenty seven seconds so

1420
01:31:50,750 --> 01:31:54,390
you see from these these plots already that

1421
01:31:54,400 --> 01:31:59,700
the speed with which certain subjects can perform this task is very quite

1422
01:32:01,860 --> 01:32:09,580
but you can see also that there are some very good subjects and of course

1423
01:32:09,580 --> 01:32:13,260
i'm showing a video from the very good subject

1424
01:32:17,530 --> 01:32:25,310
i have some

1425
01:32:43,300 --> 01:32:47,850
i'm just watching it so peaceful

1426
01:33:33,960 --> 01:33:36,820
so in fact

1427
01:33:36,870 --> 01:33:38,600
if this

1428
01:33:38,620 --> 01:33:44,150
o point you the the block actually hits the target first

1429
01:33:44,170 --> 01:33:49,210
if you were there

1430
01:34:01,210 --> 01:34:02,360
i mean

1431
01:34:02,370 --> 01:34:08,140
it i think is a very impressive results because it's the first time that noninvasively

1432
01:34:08,140 --> 01:34:11,860
somebody did some some two d control

1433
01:34:11,870 --> 01:34:20,650
and it's very hard task and and you actually need to do some learning this

1434
01:34:20,660 --> 01:34:25,550
we have started to do some t two d work

1435
01:34:25,610 --> 01:34:27,960
a couple

1436
01:34:27,980 --> 01:34:30,990
in between years ago but it didn't work so well

1437
01:34:31,040 --> 01:34:34,150
but recently we've we've found

1438
01:34:34,170 --> 01:34:36,800
also some very good well working

1439
01:34:36,850 --> 01:34:43,830
strategy but you see that they can

1440
01:34:44,150 --> 01:34:57,100
even without training

1441
01:34:57,110 --> 01:35:05,980
OK so i i think

1442
01:35:07,720 --> 01:35:10,890
go to the plantation again

1443
01:35:10,940 --> 01:35:13,370
OK so

1444
01:35:16,770 --> 01:35:21,170
so with the new neural them training

1445
01:35:21,190 --> 01:35:23,690
you use

1446
01:35:23,710 --> 01:35:31,660
the sum and difference for controlled horizontal and vertical movements and you can see you

1447
01:35:31,660 --> 01:35:36,180
can see in the video how controlled is

1448
01:35:37,810 --> 01:35:42,250
let's talk about the invasive and and non-invasive side

1449
01:35:42,270 --> 01:35:45,440
in contrast so

1450
01:35:45,460 --> 01:35:46,630
i think

1451
01:35:46,650 --> 01:35:54,230
in in noninvasive world like from the application point of view that some

1452
01:35:54,250 --> 01:35:59,830
some patients like the eleven a-list patients from the obama

1453
01:35:59,840 --> 01:36:02,850
and they using this system

1454
01:36:03,030 --> 01:36:10,610
and i think there's lots of potential applications around which are not medical but which

1455
01:36:10,610 --> 01:36:11,820
are in the

1456
01:36:11,840 --> 01:36:17,510
human machine interface think side and will come to that later

1457
01:36:17,510 --> 01:36:25,410
if you think about visions in this in this invasive world there's very nice

1458
01:36:26,680 --> 01:36:31,990
nature inside article by nicholas where he's

1459
01:36:32,000 --> 01:36:35,620
so to say dreaming about the future of the series

1460
01:36:38,270 --> 01:36:44,470
and i think it's it's it's really a very interesting and worthwhile trying direction that

1461
01:36:44,480 --> 01:36:46,080
you just

1462
01:36:46,090 --> 01:36:47,680
so for example

1463
01:36:47,700 --> 01:36:49,060
the idea would be

1464
01:36:49,060 --> 01:36:51,440
in epilepsy

1465
01:36:51,900 --> 01:36:55,000
you could

1466
01:36:55,030 --> 01:36:58,910
when you have been planted areas you could actually

1467
01:36:58,910 --> 01:37:02,670
provide with some micro problems medication

1468
01:37:02,690 --> 01:37:03,410
if you

1469
01:37:03,460 --> 01:37:06,340
three u ary

1470
01:37:06,350 --> 01:37:09,830
i realize that there some seizure that is coming up

1471
01:37:09,870 --> 01:37:12,640
this is so this is a very very

1472
01:37:12,660 --> 01:37:18,180
interesting applications and of course the question is whether you can do this reliably with

1473
01:37:18,180 --> 01:37:23,240
pricey products also have help maybe this is also the reason because we had these incentives

1474
01:37:23,240 --> 01:37:28,860
for people to buy and recommend and rating so rating that is on the website

1475
01:37:28,860 --> 01:37:32,600
and comments it seems it doesn't play much role

1476
01:37:32,700 --> 01:37:38,100
so what do we want to say for for the future it seems like decision is

1477
01:37:38,100 --> 01:37:44,100
like more complex than just threshold or or simple diminishing returns curve right so I

1478
01:37:44,100 --> 01:37:50,080
hope like that after I showed you those those measurements now you saw that there are many other different factors that are

1479
01:37:50,080 --> 01:37:54,820
going on I don't know viral marketing or diffusion that you would like or that one has to

1480
01:37:54,820 --> 01:38:00,690
think about or at least would like to model and what also turns out that this for

1481
01:38:00,750 --> 01:38:08,400
viral marketing is that this context like so how how how expensive is the

1482
01:38:08,400 --> 01:38:13,560
item and what what area the item comes from right whether it's like some profess

1483
01:38:13,580 --> 01:38:20,660
professional organizational type of thing or it's more like leisure type of product so

1484
01:38:20,660 --> 01:38:25,270
what we can do now is ask how do cascades look like what I mean

1485
01:38:25,270 --> 01:38:30,700
by that is we would like to see what are the information propagation graphs right or something

1486
01:38:30,700 --> 01:38:37,600
so for example this is a cascade of medical guidebooks and again so the red edges

1487
01:38:37,600 --> 01:38:41,780
that I think you should be able to see are the ones that were successful

1488
01:38:41,790 --> 01:38:46,700
recommendations right you can see that most recommendations are not successful but this would mean that this person

1489
01:38:46,820 --> 01:38:52,040
made the recommendation here and they they followed the recommendation so again and

1490
01:38:52,050 --> 01:38:57,760
we have some something where where the thing propagated and the rest is just disconnected and similarly for

1491
01:38:57,760 --> 01:39:05,580
some DVD that is these giant piece where there was some propagation and the rest is just

1492
01:39:05,580 --> 01:39:11,460
a purchase and a recommendation to a single node and nothing happens so now the question is how

1493
01:39:11,460 --> 01:39:15,830
how do these structures look like if you go and count them alright so we basically want to

1494
01:39:15,830 --> 01:39:23,000
do count graphs and what I want to say is this right so how how do I

1495
01:39:23,170 --> 01:39:27,640
define it so let's let's have some social network and now we have some process that spreads

1496
01:39:27,640 --> 01:39:31,860
over the network and as it spreads it creates a graph right so we

1497
01:39:31,860 --> 01:39:38,760
start and then this thing spreads and it creates a cascade right so a cascade is just this

1498
01:39:38,800 --> 01:39:43,460
graph that is induced on the social network as the as the information or some

1499
01:39:43,460 --> 01:39:47,300
some adoption of something spreads over it and now we we'd like to go

1500
01:39:47,750 --> 01:39:55,440
and count these guys and see see what they are so for so this is for viral marketing right

1501
01:39:55,740 --> 01:40:02,340
this is the most common cascade where just somebody purchases a product and makes a recommendation nothing

1502
01:40:02,340 --> 01:40:09,440
happens and this is like in terms of the counts or the frequency in the counts

1503
01:40:09,460 --> 01:40:15,620
for seventy-five percent for books and CD's and so on while only twelve

1504
01:40:15,690 --> 01:40:19,920
percent for DVD's and then for example also what is going on is for

1505
01:40:19,920 --> 01:40:24,760
is that the split of recommendations or a purchase and and a recommendation is six

1506
01:40:24,760 --> 01:40:30,460
times or one point two times for DVD's more frequent than collision  of two recommendations but for

1507
01:40:30,460 --> 01:40:36,100
example for DVD's a collision collision of three is more frequent than a split on three

1508
01:40:36,100 --> 01:40:41,540
and then like chains are more frequent than collisions and this types of graphs are again

1509
01:40:41,550 --> 01:40:47,170
more frequent than collisions even though like collision is has less edges right has two edges versus

1510
01:40:47,180 --> 01:40:54,280
versus three edges or for example here a late split which means propagation and a split is more frequent than

1511
01:40:54,320 --> 01:41:00,100
a split and a propagation so just to show more examples right so here

1512
01:41:00,100 --> 01:41:05,000
this  this ones are have very like nice social interpretation right this would mean

1513
01:41:05,000 --> 01:41:10,570
somebody buys makes recommendations and nothing happens right then we have this sort of bipartite

1514
01:41:10,660 --> 01:41:14,840
cores were there are two friends who or two people who don't know each other or

1515
01:41:15,020 --> 01:41:18,940
known don't recommend to each other but they recommend to the same set of people

1516
01:41:18,940 --> 01:41:23,340
they have a same set of friends or if now one one of the

1517
01:41:23,340 --> 01:41:28,040
people here buys and recommends on then we get structures like this right this is the first

1518
01:41:28,040 --> 01:41:33,440
purchaser and he recommends to all these people now one of them decides to buy and makes recommendations

1519
01:41:33,610 --> 01:41:38,930
to everyone below them right and most of the times this is how cascades look like but there are

1520
01:41:38,930 --> 01:41:44,760
also examples of more complicated cascades where where the purchasing behavior propagates farther

1521
01:41:45,880 --> 01:41:50,100
so this were cascades for viral marketing now if you go back to the

1522
01:41:50,480 --> 01:41:55,520
to the cascades in blogs where we have these blog posts and  information propagating and here

1523
01:41:55,560 --> 01:42:00,240
the influence propagates in the reverse direction of the edges this is like a direction of

1524
01:42:00,250 --> 01:42:05,230
the hyperlink so the influence goes from top to down and these are these are just

1525
01:42:05,230 --> 01:42:08,180
that's what i want to say about morality but i want you to keep in

1526
01:42:08,180 --> 01:42:09,560
mind when we discuss

1527
01:42:09,600 --> 01:42:11,910
different claims about what's involved in what

1528
01:42:11,920 --> 01:42:17,500
hasn't what about inevitability here i want to turn to richard dawkins

1529
01:42:17,520 --> 01:42:19,120
richard dawkins writes

1530
01:42:19,170 --> 01:42:24,820
the trial had bad teaching mathematics it is accepted the resulting efficiency can be remedied

1531
01:42:25,090 --> 01:42:27,820
by extra good teaching the following year

1532
01:42:27,900 --> 01:42:32,230
but any suggestion that the child's efficiency might have genetic origins is likely to be

1533
01:42:32,230 --> 01:42:36,790
greeted with something approaching despair if it's in the genes is determined

1534
01:42:36,800 --> 01:42:39,800
and nothing can be done about it

1535
01:42:39,840 --> 01:42:43,520
this is pernicious nonsense on almost astrological scale

1536
01:42:43,560 --> 01:42:48,390
genetic causes environmental causes are in principle no different from each other some may be

1537
01:42:48,390 --> 01:42:50,890
hard to to reverse others may be using

1538
01:42:50,940 --> 01:42:55,950
why genes what it means to to deserve their sinister drug not like reputation

1539
01:42:55,970 --> 01:42:59,900
why you thought to be so much more fix an inescapable and their effects on

1540
01:42:59,900 --> 01:43:02,370
television nuns books

1541
01:43:02,380 --> 01:43:03,500
i like the nuns

1542
01:43:06,970 --> 01:43:10,080
the point here is

1543
01:43:10,090 --> 01:43:12,260
what causes something

1544
01:43:12,270 --> 01:43:14,120
is logically separate

1545
01:43:14,130 --> 01:43:16,910
from what can reverse it

1546
01:43:17,990 --> 01:43:22,120
you think of clear cases where something is plainly genetic

1547
01:43:22,130 --> 01:43:26,810
but it's fairly easily reversed and where something is cultural and it's very difficult to

1548
01:43:26,810 --> 01:43:28,780
reverse there's an example

1549
01:43:28,790 --> 01:43:31,290
my eyesight is quite poor

1550
01:43:31,310 --> 01:43:34,440
the reason why my site is quite four is not too

1551
01:43:34,460 --> 01:43:36,470
two to patriarchy

1552
01:43:36,520 --> 01:43:39,180
television culture of the map

1553
01:43:40,210 --> 01:43:44,240
my eyesight is quite poor due to the crappy teams mum and dad gave me

1554
01:43:44,450 --> 01:43:51,310
genetically determined if anything is it also fairly easy to fix thirties machines which put

1555
01:43:51,310 --> 01:43:54,180
panes of glass in front of your eyes

1556
01:43:54,230 --> 01:43:55,890
and help you to see better

1557
01:43:55,940 --> 01:44:00,740
more advanced machines known as contact lenses actually stick the thing into your eyes and

1558
01:44:00,740 --> 01:44:05,480
at the cost of occasional infections euro two you come to see that it is

1559
01:44:05,480 --> 01:44:07,920
biologically cars

1560
01:44:07,940 --> 01:44:10,340
but fairly easy defects

1561
01:44:10,500 --> 01:44:15,610
on the other hand take an example of society's treatment of the bees

1562
01:44:15,630 --> 01:44:18,760
it turns out when we and we will get this little bit we talk about

1563
01:44:18,760 --> 01:44:20,780
sexual attractiveness

1564
01:44:20,800 --> 01:44:22,690
how thin somebody is

1565
01:44:22,700 --> 01:44:27,690
or how that they are what you think of that is actually not critically hardwired

1566
01:44:27,700 --> 01:44:30,150
there is often called the culture

1567
01:44:30,160 --> 01:44:34,170
the ones in our culture it is almost impossible to shake

1568
01:44:34,180 --> 01:44:38,910
so the point here is just that genetic does not mean inevitable

1569
01:44:39,670 --> 01:44:43,820
cultural doesn't mean easy to fix

1570
01:44:44,530 --> 01:44:48,840
that's general background let's start with the basics xn

1571
01:44:48,860 --> 01:44:51,400
what's the difference between males and females

1572
01:44:53,320 --> 01:44:54,840
i don't even think

1573
01:44:54,860 --> 01:44:56,880
penis and vagina

1574
01:44:56,900 --> 01:44:59,980
there's a lot of animals that have neither one

1575
01:45:00,000 --> 01:45:02,230
and the actually runs deeper

1576
01:45:02,250 --> 01:45:03,600
by definition

1577
01:45:03,640 --> 01:45:05,500
when biologists talk about this

1578
01:45:05,810 --> 01:45:10,650
animals that are males have a little sex cells

1579
01:45:10,660 --> 01:45:12,660
which carries genes and nothing else

1580
01:45:12,670 --> 01:45:14,420
sperm cells

1581
01:45:14,460 --> 01:45:17,340
animals that are females have sex

1582
01:45:17,650 --> 01:45:19,330
which has genes

1583
01:45:19,340 --> 01:45:23,680
but also food into protective cover and all sorts of other stuff

1584
01:45:24,610 --> 01:45:27,990
the little sex cell is much lower than the big six so this is the

1585
01:45:27,990 --> 01:45:31,820
only erotic picture i'm going to show you today

1586
01:45:31,980 --> 01:45:38,470
it's a bunch little sperm circling around the egg

1587
01:45:38,480 --> 01:45:41,710
it's strawman

1588
01:45:41,730 --> 01:45:43,520
but this raises the puzzle

1589
01:45:43,540 --> 01:45:47,840
i just described male and female roughly in terms of the size difference

1590
01:45:47,860 --> 01:45:49,940
males are smaller

1591
01:45:50,060 --> 01:45:55,520
sex cells females are bigger why is it then that for so many animals

1592
01:45:56,700 --> 01:45:58,040
are bigger ones

1593
01:45:58,050 --> 01:46:01,220
physically and more aggressive ones

1594
01:46:01,240 --> 01:46:06,010
this is a puzzle lands occupied scientists for a long time

1595
01:46:06,340 --> 01:46:08,910
we predict that is no

1596
01:46:08,980 --> 01:46:11,170
a pretty clear answer to it

1597
01:46:11,180 --> 01:46:14,000
and answer goes like this

1598
01:46:14,090 --> 01:46:16,050
it is based on idea

1599
01:46:16,160 --> 01:46:18,390
by robert rivers

1600
01:46:18,400 --> 01:46:20,320
call parental investment

1601
01:46:20,340 --> 01:46:22,500
and what parental investment is

1602
01:46:22,510 --> 01:46:24,180
is defined here as

1603
01:46:24,200 --> 01:46:25,820
any investment

1604
01:46:25,870 --> 01:46:29,710
that's going to increase the offspring's chance of survival

1605
01:46:29,720 --> 01:46:32,020
at the cost of the parents

1606
01:46:32,040 --> 01:46:35,950
the ability to invest in other offspring

1607
01:46:35,960 --> 01:46:37,490
so for example

1608
01:46:37,500 --> 01:46:41,580
suppose an animal can cream offspring by blinking an eye

1609
01:46:41,630 --> 01:46:43,660
and then after the run-off

1610
01:46:43,680 --> 01:46:46,400
that would be extremely little investment

1611
01:46:46,460 --> 01:46:49,840
suppose another animal had to work for ten years

1612
01:46:49,900 --> 01:46:54,470
and during those ten years could not create another offspring

1613
01:46:54,520 --> 01:46:59,800
that is be a huge investment

1614
01:46:59,850 --> 01:47:01,350
troopers points l

1615
01:47:01,360 --> 01:47:07,950
that was in this species females typically have much higher parental investment than males

1616
01:47:08,820 --> 01:47:14,910
because females have these big sex cells they typically incubate them internally

1617
01:47:14,930 --> 01:47:16,340
they carry the

1618
01:47:16,350 --> 01:47:19,340
if there is might have to sit on the

1619
01:47:19,350 --> 01:47:22,300
and hence each potential trials

1620
01:47:22,320 --> 01:47:24,450
is a huge cost

1621
01:47:24,460 --> 01:47:27,980
for males which have the smallest xl

1622
01:47:27,990 --> 01:47:32,710
you don't have the same thing for males it might just be a few moments

1623
01:47:32,710 --> 01:47:34,690
of of copulation

1624
01:47:34,700 --> 01:47:36,050
and that's it

1625
01:47:36,060 --> 01:47:40,370
if you could ask yourself for humans each one of you in the room what

1626
01:47:40,370 --> 01:47:43,130
is the minimum effort you could do

1627
01:47:43,180 --> 01:47:44,690
to create a child

1628
01:47:44,700 --> 01:47:46,650
those happier genes

1629
01:47:46,700 --> 01:47:51,500
and it's apparent that the male investment on average is lower

1630
01:47:51,580 --> 01:47:54,710
then the female investment males can choose

1631
01:47:54,760 --> 01:47:58,720
or might do better off in some circumstances by putting a lot of investment in

1632
01:47:58,720 --> 01:47:59,780
their offspring

1633
01:47:59,790 --> 01:48:02,370
but females don't have a choice

1634
01:48:02,390 --> 01:48:05,490
females barring technological advance

1635
01:48:05,490 --> 01:48:07,230
so now i want to

1636
01:48:07,300 --> 01:48:11,340
first so you to magnetic field configuration

1637
01:48:11,400 --> 01:48:14,320
one of the very loosely one loop

1638
01:48:14,380 --> 01:48:16,720
seven windings

1639
01:48:16,720 --> 01:48:18,350
and i will do that by

1640
01:48:18,370 --> 01:48:21,350
sprinkling magnetite cis ion file

1641
01:48:21,370 --> 01:48:23,320
in the vicinity

1642
01:48:23,320 --> 01:48:25,560
we've done this before

1643
01:48:25,570 --> 01:48:28,800
for the current configuration now i do it

1644
01:48:28,810 --> 01:48:30,420
for this

1645
01:48:30,440 --> 01:48:33,530
so it was seven windings

1646
01:48:33,570 --> 01:48:36,450
and i'm going to run a few hundred MP's

1647
01:48:38,550 --> 01:48:39,760
first get this

1648
01:48:39,790 --> 01:48:42,170
car battery

1649
01:48:43,580 --> 01:48:47,110
so we put some iron filings here

1650
01:48:47,190 --> 01:48:50,700
what i want you to see now is that the magnetic field inside even though

1651
01:48:50,700 --> 01:48:53,250
it's very loosely one

1652
01:48:53,290 --> 01:48:55,490
nicely uniform

1653
01:48:55,600 --> 01:48:57,370
and there is almost no

1654
01:48:57,380 --> 01:49:00,170
like and magnetic field outside look at it

1655
01:49:01,920 --> 01:49:03,290
that incredible

1656
01:49:03,390 --> 01:49:09,120
you see how the five line themselves up very nicely horizontally inside the loop

1657
01:49:09,130 --> 01:49:11,050
and when you look outside the loop

1658
01:49:12,150 --> 01:49:15,230
well there where we assume the magnetic field was above zero

1659
01:49:15,240 --> 01:49:18,890
you don't see the island file being more we and many preferred direction

1660
01:49:18,920 --> 01:49:20,940
which indicates that the magnetic field

1661
01:49:21,010 --> 01:49:23,890
is very low

1662
01:49:29,160 --> 01:49:31,680
i want to show you

1663
01:49:31,690 --> 01:49:33,790
what magnetic field we can get

1664
01:49:33,790 --> 01:49:35,240
with his baby

1665
01:49:35,250 --> 01:49:37,810
which is exactly what you on the record

1666
01:49:37,930 --> 01:49:40,310
has twenty eight on the windings

1667
01:49:40,310 --> 01:49:44,830
and we're going to run the current which is something like four point five mps

1668
01:49:44,890 --> 01:49:48,300
but i'm going to tell you what that could this

1669
01:49:48,340 --> 01:49:49,470
because i haven't

1670
01:49:49,470 --> 01:49:51,880
currently there for you

1671
01:49:51,900 --> 01:49:55,160
and i also have a

1672
01:49:55,170 --> 01:49:56,780
i mean which indicates the

1673
01:50:01,350 --> 01:50:03,270
is the current leader

1674
01:50:03,270 --> 01:50:05,100
and the maximum

1675
01:50:05,190 --> 01:50:10,040
current that you see there are three will be six and

1676
01:50:10,080 --> 01:50:11,240
and the upper one

1677
01:50:11,250 --> 01:50:15,660
calibrated in such a way that if is full scale

1678
01:50:15,720 --> 01:50:20,300
we have three on the gulf three three on the go

1679
01:50:20,310 --> 01:50:22,090
and i can i have approach

1680
01:50:23,150 --> 01:50:27,310
probe we never discussed how that works called the whole problem

1681
01:50:27,350 --> 01:50:29,110
and this whole probe

1682
01:50:29,190 --> 01:50:33,010
allows me to measure the magnetic field in the vicinity of the solenoid

1683
01:50:33,010 --> 01:50:38,000
it's even signed sensitive if the magnetic field is like this

1684
01:50:38,050 --> 01:50:43,560
we go the right the magnetic field is like this go to the left

1685
01:50:43,630 --> 01:50:47,130
so this allows us then to be actually quite quantitative

1686
01:50:47,140 --> 01:50:48,720
and evaluates the

1687
01:50:48,720 --> 01:50:50,030
magnetic field

1688
01:50:50,080 --> 01:50:52,310
near the opening of the solenoid

1689
01:50:52,330 --> 01:50:54,980
then we can go in there and we can also probe

1690
01:50:56,330 --> 01:50:57,870
so i'm running now

1691
01:50:57,890 --> 01:51:01,180
the current let's look at the bottom meter

1692
01:51:01,230 --> 01:51:03,940
so there's about four point eight and

1693
01:51:04,000 --> 01:51:07,110
i saw was four or five it's higher

1694
01:51:07,130 --> 01:51:09,790
and here comes this probe

1695
01:51:09,830 --> 01:51:12,940
and i now about food away from the entrance

1696
01:51:12,990 --> 01:51:14,530
you see nothing

1697
01:51:14,600 --> 01:51:16,740
and i come close to the entrance

1698
01:51:16,780 --> 01:51:20,140
and the magnetic field begins to show

1699
01:51:20,160 --> 01:51:25,430
no and nearly constant yet i'm now entering

1700
01:51:25,440 --> 01:51:26,830
on the gauss

1701
01:51:26,870 --> 01:51:28,720
i'm going to work

1702
01:51:28,760 --> 01:51:30,250
one out

1703
01:51:30,330 --> 01:51:33,090
even deeper

1704
01:51:33,150 --> 01:51:34,090
and the four

1705
01:51:34,100 --> 01:51:36,360
now we have about two hundred forty gauss

1706
01:51:36,380 --> 01:51:38,900
and notice as i go going further

1707
01:51:38,950 --> 01:51:41,590
it doesn't increases more or less constant

1708
01:51:43,090 --> 01:51:45,610
is more or less constant

1709
01:51:45,630 --> 01:51:49,580
when i come out here i moved back and forth about twenty centimetres

1710
01:51:49,610 --> 01:51:51,550
if i came in from the other side

1711
01:51:51,590 --> 01:51:55,120
it would simply see reversal in the sign which is not so interesting

1712
01:51:55,270 --> 01:51:59,540
he two hundred forty dollars in the other direction because this proper science sensitive

1713
01:51:59,540 --> 01:52:02,620
i can also show you if i come on the outside

1714
01:52:02,750 --> 01:52:03,910
the solenoid

1715
01:52:03,920 --> 01:52:05,400
you see nothing

1716
01:52:05,480 --> 01:52:10,750
so indeed our assumption that the magnetic field is very low outside tightly one solenoid

1717
01:52:10,750 --> 01:52:19,000
was a very good assumption

1718
01:52:20,350 --> 01:52:21,620
very well

1719
01:52:21,860 --> 01:52:29,740
you've been asked

1720
01:52:29,830 --> 01:52:33,220
the deadline is friday four PM

1721
01:52:33,260 --> 01:52:34,430
to explain

1722
01:52:34,490 --> 01:52:35,830
the behaviour

1723
01:52:36,820 --> 01:52:39,480
the kelvin water dropper

1724
01:52:39,590 --> 01:52:42,320
and i decided to give you a little bit of help that most of you

1725
01:52:42,320 --> 01:52:44,090
may already have figured it out

1726
01:52:44,140 --> 01:52:45,530
those who haven't

1727
01:52:45,530 --> 01:52:49,140
probably one figure without between now and friday any

1728
01:52:49,160 --> 01:52:52,080
so i might as well tell you

1729
01:52:53,480 --> 01:52:58,650
one of proper called the kelvin water dropper is an amazing battery

1730
01:52:58,670 --> 01:53:00,280
we've seen it before we know

1731
01:53:00,280 --> 01:53:02,440
what it's doing but i will

1732
01:53:02,440 --> 01:53:06,340
i'm going to find this itself to be a matrix

1733
01:53:16,180 --> 01:53:32,950
so the derivative of f with respect to a

1734
01:53:32,970 --> 01:53:36,780
is itself a matrix and matrix contains

1735
01:53:36,860 --> 01:53:39,400
all the partial derivatives of f

1736
01:53:39,400 --> 01:53:46,700
respect to the elements of a

1737
01:53:48,400 --> 01:53:54,780
one more definition is on

1738
01:53:54,840 --> 01:53:59,820
there is a square matrix a

1739
01:54:01,090 --> 01:54:06,170
n by n matrix number equals number of columns then we define the trace of

1740
01:54:06,280 --> 01:54:11,680
a to be equal to the sum of its diagonal elements

1741
01:54:11,700 --> 01:54:13,220
so this is just some

1742
01:54:15,070 --> 01:54:19,380
of AI i

1743
01:54:19,470 --> 01:54:23,700
o for those who don't have seen this sort operator notation before you can think

1744
01:54:23,700 --> 01:54:29,380
of trees a no trace operator applied to the square matrix a but is more

1745
01:54:29,380 --> 01:54:35,010
commonly written without the parentheses are usually right trace is this just means someone that

1746
01:54:42,530 --> 01:54:46,360
here are some facts about the trace operator in about derivatives and i was right

1747
01:54:46,360 --> 01:54:49,720
is proof you can also here is to prove some of them at the discussion

1748
01:54:49,740 --> 01:54:55,670
section on the or you can actually go home and sober by the prince of

1749
01:54:55,670 --> 01:54:56,670
all these

1750
01:54:56,680 --> 01:54:59,130
it turns out that on

1751
01:54:59,150 --> 01:55:01,740
given two mattresses

1752
01:55:01,760 --> 01:55:03,240
a and b

1753
01:55:03,240 --> 01:55:07,880
the trace of the matrix a times b is equal to

1754
01:55:07,900 --> 01:55:11,970
the trace of p a k another proved this but you should be able to

1755
01:55:11,970 --> 01:55:14,240
go home improved this yourself on

1756
01:55:14,300 --> 01:55:15,990
without too much difficulty

1757
01:55:16,050 --> 01:55:18,570
on and similarly

1758
01:55:18,720 --> 01:55:23,970
the trace of the product of three matrices is that we can take the matrix

1759
01:55:23,970 --> 01:55:30,590
at the end you cyclically permuted to the front street it becomes the case that

1760
01:55:32,110 --> 01:55:34,630
to take the matrix you back in the front

1761
01:55:34,670 --> 01:55:38,470
and this is also equal to the chase

1762
01:55:38,680 --> 01:55:42,070
BC take the matrix being the to the

1763
01:55:52,150 --> 01:55:53,900
suppose you have a function

1764
01:55:53,920 --> 01:55:59,760
f of a which is defined as the trace of a b

1765
01:55:59,800 --> 01:56:03,840
so this is right the traces of real numbers so the trace of a b

1766
01:56:03,840 --> 01:56:09,360
is a function that takes as input matrix a and outputs a real number

1767
01:56:09,420 --> 01:56:13,530
so then the derivative with respect to the matrix a

1768
01:56:13,550 --> 01:56:16,940
this function is the

1769
01:56:22,490 --> 01:56:25,970
going to be transposed is just another fact that you can

1770
01:56:25,990 --> 01:56:31,340
prepare yourself by going back referring to definitions of cases images there so i'm not

1771
01:56:31,340 --> 01:56:32,180
going to do

1772
01:56:32,240 --> 01:56:34,090
you left

1773
01:56:34,110 --> 01:56:37,170
i lost the cup was on

1774
01:56:37,220 --> 01:56:43,380
difficult to the case because the pace is just the sum of diagonal elements and

1775
01:56:43,380 --> 01:56:46,610
so suppose matrix the documents change

1776
01:56:46,650 --> 01:56:48,780
and so on

1777
01:56:48,870 --> 01:56:56,260
it located a real numbers you know the space overall numbers just itself so i

1778
01:56:56,260 --> 01:57:00,240
think the real numbers one by one matrix so the trace the one by one

1779
01:57:00,240 --> 01:57:01,880
matrix is just whatever

1780
01:57:02,220 --> 01:57:05,740
whatever the real numbers

1781
01:57:09,010 --> 01:57:11,010
and lastly

1782
01:57:11,170 --> 01:57:15,320
this is somewhat tricky one on

1783
01:57:15,340 --> 01:57:27,700
the derivative respect to the matrix a matrix the ABA transfer c

1784
01:57:27,880 --> 01:57:32,950
this is a plus the transport

1785
01:57:33,220 --> 01:57:41,880
the transport and i want prove value either the soldiers out your work yourself

1786
01:57:41,920 --> 01:57:43,510
and so

1787
01:57:47,470 --> 01:57:51,990
i guess key equations

1788
01:57:52,050 --> 01:57:56,970
the key facts i'm going to use the game

1789
01:57:56,970 --> 01:58:05,030
about racism matrix derivatives are all these five

1790
01:58:07,300 --> 01:58:08,380
ten minutes

1791
01:58:11,420 --> 01:58:14,450
on these things i'm going to go on

1792
01:58:14,490 --> 01:58:15,320
figure out

1793
01:58:15,340 --> 01:58:16,570
let's list

1794
01:58:16,590 --> 01:58:21,170
the outcome of a quick derivation for how to minimize gf theater in as a

1795
01:58:21,170 --> 01:58:25,940
function of theta in closed form without needing to use an iterative alpha

1796
01:58:29,200 --> 01:58:35,240
to work this out then we define the matrix x is called the design matrix

1797
01:58:35,300 --> 01:58:39,740
on to be matrix containing all the input from a training set

1798
01:58:39,760 --> 01:58:45,260
so the one was was was the vector of inputs is the vector of features

1799
01:58:45,260 --> 01:58:49,010
for first training example so i'm going to

1800
01:58:49,990 --> 01:58:52,740
set x one to be the first row of

1801
01:58:52,780 --> 01:58:54,380
this matrix x

1802
01:58:58,340 --> 01:59:03,200
set my second training examples was to be the second row and so we can

1803
01:59:03,220 --> 01:59:05,700
have training example and so on

1804
01:59:05,840 --> 01:59:10,240
that's going to be my on

1805
01:59:10,240 --> 01:59:15,130
the design matrix and this is defined as matrix kappa x as follows

1806
01:59:15,150 --> 01:59:16,420
and so on

1807
01:59:17,880 --> 01:59:23,800
now we take the matrix x multiplied by my parameter vector data starvation just two

1808
01:59:23,800 --> 01:59:26,610
of these steps so x data

1809
01:59:26,820 --> 01:59:33,470
on remand the whole matrix vector multiplications skills right you take this factory multiplied by

1810
01:59:33,490 --> 01:59:35,440
the rows of the matrix

1811
01:59:35,440 --> 01:59:41,800
so x times theater is going to be just x one both data

1812
01:59:41,880 --> 01:59:45,260
that don't


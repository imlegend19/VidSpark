1
00:00:00,000 --> 00:00:05,540
adapt nicely to data effectively using gradient descent heuristic will kind of obsessive lots of

2
00:00:05,540 --> 00:00:11,860
stuff around you could also just sort of to bridge back to this morning's tutorial

3
00:00:11,960 --> 00:00:17,500
no networks then fuzzy approaches use fuzzy rules to sort of visualizing all network has

4
00:00:17,590 --> 00:00:22,740
structure that resembles that holds the parameters of the the fuzzy rule system in the

5
00:00:22,740 --> 00:00:25,520
news network training algorithms thank you

6
00:00:25,580 --> 00:00:29,820
the the the the rules and then data you can sometimes even extract the rules

7
00:00:29,820 --> 00:00:33,210
again and try to understand them so there's a lot of work also been done

8
00:00:33,220 --> 00:00:35,120
in this

9
00:00:35,180 --> 00:00:38,080
this crossover between the two disciplines

10
00:00:38,140 --> 00:00:43,900
this is the term for that soft computing sort of encompasses neural networks fuzzy logic

11
00:00:43,900 --> 00:00:46,240
and evolutionary methods together

12
00:00:49,500 --> 00:00:57,820
now arrests last section i would jump into fuzzy arithmetic fuzzy numbers just to give

13
00:00:57,820 --> 00:01:00,940
you an idea what would you do if you actually going back to this example

14
00:01:00,940 --> 00:01:05,620
of the insurance predictor if you wanted to use the fuzzy set not just fuzzy

15
00:01:05,640 --> 00:01:10,040
he fuzzy hired and then we a crisp number describing risk but actually use that

16
00:01:10,050 --> 00:01:16,460
to go into your fuzzy calculator and use degree this this membership function for risk

17
00:01:16,540 --> 00:01:20,900
and then calculate what kind of premium the person is supposed to pay just having

18
00:01:20,900 --> 00:01:26,200
some the rules in some some equations fuzzy patients is allow to solve all multiply

19
00:01:26,210 --> 00:01:30,700
it by risk by about one hundred euro and then we have to build age

20
00:01:30,700 --> 00:01:36,180
and sex factor and that results and that's what is going to pay per month

21
00:01:36,200 --> 00:01:38,900
so fuzzy arithmetic may be useful

22
00:01:40,740 --> 00:01:46,160
often nice also rule systems if you don't even have to precision to measure or

23
00:01:46,160 --> 00:01:50,300
if you you get very imprecise inputs people just briefly look at someone to figure

24
00:01:50,300 --> 00:01:53,720
out you know is a little bit overweight you don't want maybe if you have

25
00:01:53,750 --> 00:01:59,280
life insurance company give people first quote you rough quote that even an idea it's

26
00:01:59,280 --> 00:02:02,620
interesting to producer for for that person you're not going to ask him to step

27
00:02:02,630 --> 00:02:05,720
on the scale and get the exact weight so the agent is just going to

28
00:02:05,720 --> 00:02:11,700
say all little yes heavily overweight so you get fuzzy inputs into a rule system

29
00:02:11,740 --> 00:02:15,180
so you want to be able to process these imprecise inputs without having the agent

30
00:02:15,180 --> 00:02:19,860
actually sit down our he's and and twenty seven kilo right

31
00:02:19,880 --> 00:02:23,360
you get all these bizarre numbers that are far from being true

32
00:02:23,400 --> 00:02:25,840
so in order to do that you would need to be able to add or

33
00:02:25,840 --> 00:02:31,540
multiply these imprecise concepts of numbers fuzzy numbers and even apply some functions normalisation or

34
00:02:31,540 --> 00:02:33,200
others to fuzzy numbers

35
00:02:33,340 --> 00:02:37,720
OK so that's what i'm trying to explain you in the next sort of twenty

36
00:02:38,980 --> 00:02:39,710
but you

37
00:02:39,740 --> 00:02:44,680
classical crisp will do the same game again you can describe the crisp numbers is

38
00:02:44,680 --> 00:02:51,000
single simply say characteristic function for my number a small

39
00:02:51,020 --> 00:02:56,320
should actually be down here is simply a characteristic function that you're one hundred only

40
00:02:56,320 --> 00:03:01,200
one ball those effects that are precisely equal to a right so this is the

41
00:03:03,120 --> 00:03:06,920
a fuzzy number is very similar to a fuzzy set the idea of about eight

42
00:03:07,180 --> 00:03:10,700
understood about five minutes can also be a

43
00:03:10,930 --> 00:03:17,540
and about is the same idea membership function that describes ball but numbers around eighty

44
00:03:17,550 --> 00:03:21,660
still belong little bit to this has embraced again have a here let's say well

45
00:03:21,660 --> 00:03:26,940
everything down to london minus two in a plus one also the nominal to our

46
00:03:26,940 --> 00:03:32,700
concept of about about eight so we could now say well today's and what's outside

47
00:03:32,700 --> 00:03:37,080
now before was maybe twenty five degrees i wouldn't claim that it was outside it

48
00:03:37,080 --> 00:03:41,840
was twenty five degrees sharp service and is about twenty five degrees and you would

49
00:03:41,840 --> 00:03:43,500
implicitly know

50
00:03:43,520 --> 00:03:47,700
this zero degrees he doesn't that dumb but it was could be twenty three could

51
00:03:47,700 --> 00:03:52,580
be twenty two could also be twenty six degrees so you you inherently have building

52
00:03:52,580 --> 00:03:56,140
this idea of when i say it was about twenty five degrees outside you have

53
00:03:56,140 --> 00:03:59,700
an idea what kind of fuzzy sets one be able to paint the exact membership

54
00:03:59,700 --> 00:04:05,710
function but you know which numbers belong to my about twenty five degrees which don't

55
00:04:05,820 --> 00:04:13,520
OK they difference that's why also this triangular membership function before usually fuzzy numbers are

56
00:04:13,560 --> 00:04:19,360
normalised so you have these one point with the degree of membership of one

57
00:04:19,500 --> 00:04:26,700
they're monotone so usually the membership function will just increase monotonix here decreased one to

58
00:04:26,810 --> 00:04:30,580
right if you're caught and this in usually only have one point that has a

59
00:04:30,580 --> 00:04:35,400
degree of membership once for this about otherwise more be a fuzzy interval right if

60
00:04:35,400 --> 00:04:38,730
you had a plateau up here say well this is really more describing the concept

61
00:04:38,830 --> 00:04:43,320
a fuzzy interval which you could also case so that's a fuzzy numbers

62
00:04:43,440 --> 00:04:44,580
and then of course

63
00:04:44,600 --> 00:04:48,130
the question is how do you eat to fuzzy numbers adding crisp numbers is simple

64
00:04:48,130 --> 00:04:52,100
we go back to the original you have these two singletons for a and b

65
00:04:52,100 --> 00:04:57,360
well that's the characteristic function for the addition of these two numbers the characteristic function

66
00:04:57,360 --> 00:04:59,660
for a plus b

67
00:04:59,680 --> 00:05:02,460
for any value but it's one

68
00:05:02,500 --> 00:05:05,000
when z equals a plus b

69
00:05:05,020 --> 00:05:11,780
only at this point is my characteristic function one and for every everything else it's

70
00:05:11,780 --> 00:05:15,300
it's a very complicated way of writing it down but it makes it easier to

71
00:05:15,300 --> 00:05:17,400
understand how fuzzy numbers can be added

72
00:05:17,540 --> 00:05:21,480
well we could also write it differently and make it even more complicated all but

73
00:05:21,640 --> 00:05:23,000
really doing is

74
00:05:23,040 --> 00:05:26,400
if you want the characteristic function for a plus b

75
00:05:26,440 --> 00:05:30,900
for arbitrary value of set for doing is we're going to look for all combinations

76
00:05:30,900 --> 00:05:36,000
of x and y that you can plug into this being be look for the

77
00:05:36,020 --> 00:05:41,480
but the degree of membership for a for this value x times the degree of

78
00:05:41,480 --> 00:05:46,460
membership for b for this value wines under the constraint that x plus y equals

79
00:05:46,460 --> 00:05:51,320
z so looking for all combinations of x and y that results were the some

80
00:05:51,320 --> 00:05:52,660
results in that

81
00:05:52,680 --> 00:05:55,160
so we have this principle of islam comes from

82
00:05:55,240 --> 00:05:58,080
and then there looking for the degree of membership for this value

83
00:05:58,100 --> 00:06:02,520
for for a whole whole this x to a part of this life to be

84
00:06:02,560 --> 00:06:07,680
in multiply those and we'll deriving the next so the only time that this actually

85
00:06:07,680 --> 00:06:13,600
works is when x equals a exactly a and y equals b then this

86
00:06:13,650 --> 00:06:14,980
is fulfilled

87
00:06:15,300 --> 00:06:20,020
and these actually non-zero otherwise products we get a one here we get a one

88
00:06:20,020 --> 00:06:24,400
here eighty the here and set and then we get this one so this is

89
00:06:24,400 --> 00:06:25,820
OK so

90
00:06:25,920 --> 00:06:32,970
business like amazon netflix wal mart it's virtually this phenomenon with that pain this still

91
00:06:33,030 --> 00:06:35,990
it's the short head and the long tail

92
00:06:36,050 --> 00:06:40,680
and you have you of course he had about his apprentice lori eighty percent eighty

93
00:06:40,680 --> 00:06:42,340
twenty rule

94
00:06:42,700 --> 00:06:45,240
so not because of this web

95
00:06:45,240 --> 00:06:49,320
and then people with the long tail is extended

96
00:06:49,360 --> 00:06:50,880
so people is

97
00:06:50,880 --> 00:06:53,360
based on this book chris anderson spoke

98
00:06:53,360 --> 00:06:57,260
now it's possible for it to reach the long tail to get

99
00:06:57,280 --> 00:06:59,550
more things so

100
00:07:00,420 --> 00:07:02,700
for example how big

101
00:07:02,720 --> 00:07:05,660
i don't know which bookstores do you visit usually

102
00:07:05,680 --> 00:07:07,220
but as

103
00:07:07,240 --> 00:07:11,430
definitely has the largest number of books you can find OK

104
00:07:11,450 --> 00:07:13,920
i usually visit the borders

105
00:07:13,920 --> 00:07:17,820
i would like to buy some over there as well

106
00:07:19,030 --> 00:07:21,700
no comparison so

107
00:07:21,700 --> 00:07:26,380
amazon i i can find a lot of books many books i have ever never

108
00:07:26,380 --> 00:07:27,380
thought about

109
00:07:27,380 --> 00:07:30,610
but because of collaborative filtering

110
00:07:30,660 --> 00:07:31,550
you see

111
00:07:31,590 --> 00:07:34,610
i don't know if we have this conspiracy i have to explain

112
00:07:34,660 --> 00:07:37,860
i bought this book and i was recommended to some of the books than about

113
00:07:37,860 --> 00:07:39,280
other books as well

114
00:07:41,760 --> 00:07:44,050
this is about to like in the new

115
00:07:44,840 --> 00:07:47,970
how can we make take advantage of this long tail

116
00:07:49,030 --> 00:07:54,070
and the so wal-mart sells more long tail items in short head and it's it's

117
00:07:54,070 --> 00:07:56,720
from that book not from us

118
00:07:56,740 --> 00:08:02,740
and then the question is who are familiar strangers

119
00:08:04,800 --> 00:08:10,360
we already talked about in the real world and but in the blogosphere

120
00:08:10,360 --> 00:08:12,320
what we write

121
00:08:12,340 --> 00:08:15,130
what you write is or what you are

122
00:08:15,130 --> 00:08:17,320
OK so

123
00:08:17,360 --> 00:08:20,430
have similar blogging behavior interests

124
00:08:20,450 --> 00:08:25,820
the community games technology and politics et cetera but

125
00:08:25,820 --> 00:08:29,090
but you never cited each other

126
00:08:29,130 --> 00:08:32,420
we have some examples here

127
00:08:32,430 --> 00:08:34,840
later also

128
00:08:35,700 --> 00:08:37,720
this is not

129
00:08:37,720 --> 00:08:42,570
returned as pop hits if we have many many these

130
00:08:42,840 --> 00:08:50,450
bloggers familiar strangers but basically similar brothers there there but they are not connected

131
00:08:50,570 --> 00:08:52,930
but the number is so small

132
00:08:53,820 --> 00:08:56,300
people just don't want to study them

133
00:08:57,400 --> 00:09:00,720
then what's the disadvantage disadvantages

134
00:09:00,740 --> 00:09:04,160
you can not designed ads

135
00:09:04,200 --> 00:09:07,430
probably relevant ads to so these people right

136
00:09:07,570 --> 00:09:10,740
again at the end it's the number of clicks on one of the

137
00:09:10,760 --> 00:09:14,490
popular models used steal the number of clicks

138
00:09:14,490 --> 00:09:16,090
so the assumption is that

139
00:09:16,160 --> 00:09:21,240
more relevant it is the more clicks are going to get

140
00:09:23,280 --> 00:09:25,320
then we need to aggregate

141
00:09:26,260 --> 00:09:28,880
these malicious in the long tail

142
00:09:33,510 --> 00:09:34,590
i hope

143
00:09:34,590 --> 00:09:38,880
i just want to mention this aggregating will help

144
00:09:39,030 --> 00:09:41,160
a lot to these other

145
00:09:42,660 --> 00:09:46,530
i want to work on this this is the exact example

146
00:09:46,550 --> 00:09:48,070
we show you

147
00:09:48,110 --> 00:09:51,700
like the blog is single block and these are the

148
00:09:51,740 --> 00:09:53,590
it's irrelevant at

149
00:09:53,700 --> 00:09:59,240
what's the disadvantage disadvantages if i'm bombarded with too many

150
00:10:01,650 --> 00:10:05,920
i will be trained as a human being i will be trying to ignore all

151
00:10:06,920 --> 00:10:08,800
so it's not a good idea to have

152
00:10:08,860 --> 00:10:10,320
two frequently

153
00:10:10,430 --> 00:10:15,740
many irrelevant that sometimes you have some irrelevant ones that's

154
00:10:15,800 --> 00:10:17,680
that held

155
00:10:17,720 --> 00:10:21,780
will help you to expand your interests right you buy this you also by something

156
00:10:21,780 --> 00:10:23,280
else but not to

157
00:10:24,450 --> 00:10:29,840
many irrelevant ones these now we have the definition these other examples like how do

158
00:10:29,840 --> 00:10:32,950
we define familiar strangers

159
00:10:32,970 --> 00:10:35,340
and for this problem

160
00:10:35,360 --> 00:10:40,360
i just want to shoot the challenge we we we want to study OK and

161
00:10:40,360 --> 00:10:44,320
then we have like partial strangers total strangers

162
00:10:44,340 --> 00:10:51,700
and the but i we usually we want to study this total strangers

163
00:10:51,760 --> 00:10:53,630
types of familiar strangers

164
00:10:53,650 --> 00:10:55,510
these the examples

165
00:10:55,570 --> 00:10:57,990
OK these other examples

166
00:10:57,990 --> 00:11:01,320
you sense i'm rushing right i'm rushing because i want to move on to the

167
00:11:02,300 --> 00:11:04,780
case study our the

168
00:11:05,380 --> 00:11:07,400
convinced you that

169
00:11:07,420 --> 00:11:09,900
there are familiar strangers

170
00:11:09,930 --> 00:11:11,950
the blogsphere and

171
00:11:11,950 --> 00:11:14,320
good idea to aggregate them

172
00:11:14,340 --> 00:11:16,530
but there are challenges

173
00:11:16,530 --> 00:11:17,650
to find them

174
00:11:18,920 --> 00:11:20,660
it's not easy

175
00:11:20,680 --> 00:11:25,920
these are the different types of familiar strangers

176
00:11:25,930 --> 00:11:30,110
so challenges link analysis doesn't work OK

177
00:11:30,160 --> 00:11:32,930
because some of them they're not they're not connected

178
00:11:35,240 --> 00:11:39,320
so you know this is like a you search of the blog posts

179
00:11:39,340 --> 00:11:41,320
do that that's one way

180
00:11:41,470 --> 00:11:44,780
another way is is search via context

181
00:11:44,780 --> 00:11:48,800
it is that you try to find one blog then you come back here the

182
00:11:49,010 --> 00:11:52,490
head you've tried to make use of the short head short hair

183
00:11:52,530 --> 00:11:57,200
people in the short of bloggers in the short head that well connected so you

184
00:11:57,200 --> 00:12:01,050
hope that you could go back to them you can find

185
00:12:01,150 --> 00:12:03,240
the relevant ones

186
00:12:03,260 --> 00:12:05,160
so this is our approach

187
00:12:05,900 --> 00:12:08,360
i suggest i come to work on

188
00:12:08,380 --> 00:12:12,630
to work on this problem that idea is to use the collective wisdom

189
00:12:12,630 --> 00:12:15,160
OK based on one person's

190
00:12:15,220 --> 00:12:19,630
category clusters one person scalar clusters on the left-hand side

191
00:12:19,650 --> 00:12:23,430
we try to use this collective wisdom

192
00:12:23,470 --> 00:12:26,950
use the collective wisdom what's the collective wisdom

193
00:12:27,110 --> 00:12:31,530
collective wisdom is user-generated content

194
00:12:32,280 --> 00:12:34,010
and then we will

195
00:12:34,030 --> 00:12:37,800
try to find relevant categories and we search

196
00:12:39,150 --> 00:12:45,660
so this actually is the nexus the next to kansas case studies called employing collective

197
00:12:46,430 --> 00:12:49,150
however as i said

198
00:12:49,200 --> 00:12:50,470
i find

199
00:12:50,490 --> 00:12:55,860
proper is more interesting and so we go will visit i find the first

200
00:12:55,880 --> 00:12:58,050
and then we come back to

201
00:12:58,110 --> 00:13:00,780
employing collective wisdom if we have time

202
00:13:25,300 --> 00:13:26,590
so i find

203
00:13:26,610 --> 00:13:30,780
basically identifying influential bloggers IN a community

204
00:13:30,800 --> 00:13:35,400
so this is the part of the book presented at conference this year and the

205
00:13:35,400 --> 00:13:37,180
video is also available online

206
00:13:37,510 --> 00:13:39,880
by the same darkness

207
00:13:39,900 --> 00:13:43,740
so you can actually go to the site and you can find

208
00:13:44,280 --> 00:13:48,510
full of presentation there also

209
00:13:49,590 --> 00:13:53,630
because this in any way you have to buy a of camera

210
00:13:53,630 --> 00:13:54,750
the following year

211
00:13:54,760 --> 00:13:58,630
the term for the story in red cross

212
00:13:58,670 --> 00:14:05,000
the theory in the fall for a moment before both states in eastern european country

213
00:14:05,220 --> 00:14:08,250
something of interest to intelligence analysts

214
00:14:08,680 --> 00:14:11,420
trivia country

215
00:14:11,530 --> 00:14:15,210
so some things about a lot about but some things

216
00:14:21,890 --> 00:14:23,920
dummy reversal

217
00:14:23,960 --> 00:14:25,760
i don't even know what that is

218
00:14:25,780 --> 00:14:31,860
not done the reverse dummy

219
00:14:31,870 --> 00:14:33,010
dummy hoy

220
00:14:33,030 --> 00:14:37,740
there's not very nice to name from william hoyt w

221
00:14:37,790 --> 00:14:43,070
w w it's another card game so now we know that someone was working on

222
00:14:43,070 --> 00:14:51,680
cards in dummy companies but not only was one of the universe

223
00:14:51,700 --> 00:15:02,990
so not comprehensive of respect kagame's ridiculous ridiculously heavy coverage nevertheless someone else

224
00:15:10,760 --> 00:15:14,830
o side of things like this is some sort recessive

225
00:15:14,830 --> 00:15:17,570
and so on and so convolution

226
00:15:17,580 --> 00:15:18,990
just inside

227
00:15:19,040 --> 00:15:20,120
in the project

228
00:15:20,140 --> 00:15:27,250
they type of interactive program is kind of vision programme which isn't actually true anymore

229
00:15:27,420 --> 00:15:32,210
i was great that

230
00:15:36,390 --> 00:15:42,570
it's it's interesting that is inadequately represented as well as and i found out

231
00:15:47,660 --> 00:15:51,330
tutorial listen conceptual work that's the one we are after

232
00:15:51,340 --> 00:15:53,000
the trio

233
00:15:53,010 --> 00:15:57,490
tutorial distance so better represented the only because we were foolish enough not to use

234
00:15:57,490 --> 00:15:59,210
this interface search for it

235
00:16:00,240 --> 00:16:05,160
this to to this tutorial here is a information during things was not be of

236
00:16:05,160 --> 00:16:10,500
into the tutorial is the actual tutorial the contents of the tutorial the time producing

237
00:16:11,710 --> 00:16:20,040
it's sort of tory was document some l i think the other one

238
00:16:20,130 --> 00:16:24,970
is there

239
00:16:25,040 --> 00:16:27,080
toy on this

240
00:16:27,130 --> 00:16:28,930
know that

241
00:16:28,950 --> 00:16:32,870
so that's a different types of this tutorial what i'm doing now

242
00:16:32,880 --> 00:16:38,130
is that type of it to listen

243
00:16:56,300 --> 00:16:58,710
o thirty tissues

244
00:16:58,710 --> 00:17:04,710
i've organised as constituent type of inference spatial stuff like thing so again

245
00:17:04,780 --> 00:17:07,740
these things sound ridiculous but there really

246
00:17:07,750 --> 00:17:10,990
useful you can do inference as you can tell

247
00:17:11,030 --> 00:17:14,450
because of this for example that you can count on

248
00:17:14,510 --> 00:17:18,880
in two pieces of minutes till the bone marrow

249
00:17:19,280 --> 00:17:22,790
tell all that stuff about

250
00:17:23,210 --> 00:17:30,420
as an instance of men are some bone marrow side is about

251
00:17:31,250 --> 00:17:35,140
is that

252
00:17:35,200 --> 00:17:41,460
yes so when you hover over anything in here

253
00:17:41,540 --> 00:17:47,700
do you think of a more challenging medical term

254
00:17:54,820 --> 00:18:07,920
how do you spell out

255
00:18:07,960 --> 00:18:10,790
well we have some reasons but we don't have that one

256
00:18:13,700 --> 00:18:19,120
the call the oncology department is not your home board

257
00:18:19,160 --> 00:18:24,640
during going somebody for cardiothoracic surgery

258
00:18:24,680 --> 00:18:25,930
always a year

259
00:18:25,960 --> 00:18:31,030
there are no i wouldn't be surprised if every reason school

260
00:18:38,870 --> 00:18:41,530
so joke the conceptual work

261
00:18:41,580 --> 00:18:46,100
so that's the joke itself the idea of the talk this particular joke here three

262
00:18:46,100 --> 00:18:48,540
civilians into a day after shop

263
00:18:50,130 --> 00:18:54,250
you know whenever i tell that there is the information bearing thing so if i

264
00:18:54,250 --> 00:18:56,040
write down a

265
00:18:56,040 --> 00:18:57,720
a basis for

266
00:18:57,740 --> 00:19:03,740
the atom-pair and this is diamond cubic so diamond cubic is the crystal structure but

267
00:19:03,740 --> 00:19:09,870
it's derived from an FCC lattice so again the the overarching theme here is the

268
00:19:09,870 --> 00:19:14,740
integral of the brevity lattice this is a set of points right this is the

269
00:19:14,740 --> 00:19:20,130
point set points set in 3 space the brevity lattice and then what you put

270
00:19:20,130 --> 00:19:23,740
at each point gives you the crystal structure and you can go on and on

271
00:19:23,740 --> 00:19:26,260
and on because of distance

272
00:19:27,020 --> 00:19:33,300
all here this is show you into space is an integer print is the dogs

273
00:19:33,680 --> 00:19:36,000
so what's the crystal structure here

274
00:19:36,640 --> 00:19:41,040
so let's start looking might go 1 2 3 4 5 you might say well

275
00:19:41,040 --> 00:19:45,520
this looks like a simple the face centered cubic actually face centered by centered the

276
00:19:45,520 --> 00:19:47,000
same into space right

277
00:19:47,300 --> 00:19:49,480
the body is

278
00:19:49,520 --> 00:19:52,260
the how describe a sponge into space

279
00:19:52,420 --> 00:19:57,440
think about it OK the trouble is this facing in the other direction so that

280
00:19:57,460 --> 00:19:58,560
will work

281
00:19:59,440 --> 00:20:04,200
instead all these dogs facing the same way enough you look carefully taken as the

282
00:20:04,200 --> 00:20:09,170
basis see those those could be lattice points the brevity lattice is the red dots

283
00:20:09,170 --> 00:20:13,720
are the basis is the set of for dogs the 2 facing the right and

284
00:20:13,720 --> 00:20:17,830
these 2 facing the now to right to left to right to left so it's

285
00:20:17,830 --> 00:20:20,110
the 4 dogs set

286
00:20:20,800 --> 00:20:26,300
both for dogs are the basis of bingo so now we have we have simple

287
00:20:26,300 --> 00:20:32,410
cubic is STP simple cubic puppy that's into space and I go to this 1

288
00:20:34,670 --> 00:20:41,810
I put the dot here on the abdomen of this

289
00:20:41,850 --> 00:20:50,050
creature of OK so we we know that this is a problem for some of

290
00:20:50,050 --> 00:20:52,800
you might initially have called this the triangle

291
00:20:52,800 --> 00:20:57,850
but you see that when you put the 2 together this has translational symmetry and

292
00:20:57,850 --> 00:21:03,460
in fact look at how many of these entities belong to that lattice point all

293
00:21:03,460 --> 00:21:07,850
of this all of this all this because the tail to this is up here

294
00:21:07,900 --> 00:21:10,780
so the repeat doesn't start until down here you could cut it this way I

295
00:21:10,780 --> 00:21:15,190
don't care but the point is that this is the concept of the basis the

296
00:21:15,190 --> 00:21:21,090
basis is many many units that are repeatable and can be positioned at each lattice

297
00:21:22,120 --> 00:21:26,360
so now what I wanna do is talk a little bit more about that cubic

298
00:21:26,360 --> 00:21:31,820
system because we're focused on cubic system in 309 1 largely because it has a

299
00:21:31,820 --> 00:21:37,540
simple geometry most of the periodic table you find is in fact cubic system FCC

300
00:21:37,550 --> 00:21:44,240
your BCC and the math simple because you can in accordance Cartesian coordinates so let's

301
00:21:44,240 --> 00:21:48,400
take a look at that what we've got all force here

302
00:21:48,410 --> 00:21:53,260
at the properties of cubic crystals so here we are this is a table your

303
00:21:53,260 --> 00:21:57,630
lecture notes and a lot of work through this table I urge you to get

304
00:21:57,630 --> 00:22:02,610
our friendly comparable with this table so that you understand the properties of white and

305
00:22:02,610 --> 00:22:07,440
making you learn this stuff because I think it stands to reason that if you

306
00:22:07,440 --> 00:22:14,090
look in this crystal you see that atoms touch certain directions and Adams the far

307
00:22:14,090 --> 00:22:18,720
apart along other directions while we've already seen in 309 1 that there is a

308
00:22:18,720 --> 00:22:24,150
correlation between atomic contact and bonding

309
00:22:24,220 --> 00:22:30,200
and bonding is related to a whole host of other properties for example mechanical strength

310
00:22:30,500 --> 00:22:35,460
the people in this room think about the mechanical engineers aero astro engineers nuclear engineers

311
00:22:35,910 --> 00:22:40,390
you need to understand the relationship between the crystal structure and the strength of the

312
00:22:40,390 --> 00:22:46,050
material obviously if I look down and Adam direction for look down on direction rather

313
00:22:46,080 --> 00:22:51,200
high density of atoms that's going to be a directions of straight if I look

314
00:22:51,200 --> 00:22:55,850
down direction has a low population of atoms that's going to be a directional weakness

315
00:22:56,060 --> 00:23:00,650
subsequently if I wanna cleaver crystal then where my going clean

316
00:23:00,670 --> 00:23:06,440
I have to understand crystallography the electrical properties the optical properties

317
00:23:06,440 --> 00:23:10,830
what's the index of refraction is the bending of light in response to the field

318
00:23:10,840 --> 00:23:13,650
set up by the bonds

319
00:23:13,720 --> 00:23:17,960
so in order not to electronics you better know this stuff everybody has to know

320
00:23:17,960 --> 00:23:23,000
this stuff because chemistry is central and it's all chemistry

321
00:23:23,200 --> 00:23:30,870
this conversation is brought to you by secondary bonding in the fall it so let's

322
00:23:30,870 --> 00:23:35,280
look at this 1 in some detail and wanted to 1st of all is the

323
00:23:35,280 --> 00:23:37,850
unit cell let's look at the unit cell

324
00:23:37,910 --> 00:23:45,910
so here's FCC face centered cubic so there's lattice and uses a hard sphere model

325
00:23:46,040 --> 00:23:51,740
so I wanna make this the atoms so big that they actually touch belong there

326
00:23:53,720 --> 00:24:00,220
axis of contacts or face centered cubic the atoms touch along that face diagonal and

327
00:24:00,220 --> 00:24:04,720
the unit cell this is called the unit cell this is the repeat unit

328
00:24:04,760 --> 00:24:08,720
this is the unit cell is that which repeats in free space and fills 3

329
00:24:08,720 --> 00:24:14,980
space it's it's that it's the basic unit of the crystal system and the edge

330
00:24:14,980 --> 00:24:18,810
of the unit cell is given by the dimension of a

331
00:24:18,830 --> 00:24:22,390
so the edge of the unit cell this is the cube so it's all the

332
00:24:22,390 --> 00:24:27,130
same so the volume of the unit cell is equal to a cube that's trivial

333
00:24:27,130 --> 00:24:31,810
so we get that all last points 4 unit cell last points unit cell let's

334
00:24:31,810 --> 00:24:32,610
look at them

335
00:24:32,960 --> 00:24:34,150
let's look at this

336
00:24:34,220 --> 00:24:39,040
this red 1 comedy lattice points while we can count lattice was becoming Adams if

337
00:24:39,040 --> 00:24:42,670
you see there's a corner atoms and how much of each of those corner atoms

338
00:24:42,670 --> 00:24:45,700
lies within the bounds of this unit cell

339
00:24:45,740 --> 00:24:47,040
this 108

340
00:24:47,050 --> 00:24:51,040
In case so lattice lattice points

341
00:24:51,050 --> 00:24:53,220
per unit cells

342
00:24:53,220 --> 00:24:59,610
per unit cell is going to equal 8 times 1 8 this is the corners

343
00:24:59,780 --> 00:25:04,710
this is the corners and then we got the space at the time Sunday is

344
00:25:04,710 --> 00:25:09,220
1 and you see these blue ones these blue ones are half inside this unit

345
00:25:09,220 --> 00:25:14,170
cell and half inside the adjacent units only about 1 2 3 4 5 6

346
00:25:14,170 --> 00:25:15,090
of them

347
00:25:15,110 --> 00:25:21,110
2 in this direction 3 principal directions and 2 times so that's 6 times 1

348
00:25:21,110 --> 00:25:28,520
half which is this is the face atoms and incurring 6 times ahead of is

349
00:25:28,550 --> 00:25:32,280
3 3 . 1 is 4 so I have effectively for

350
00:25:32,810 --> 00:25:38,240
lattice points for yourself financing atoms because I could replace each of these single atoms

351
00:25:38,240 --> 00:25:42,810
with methane molecules of 5 atoms 4 points that's on being a little bit festivities

352
00:25:42,810 --> 00:25:46,500
here lattice points per unit cell

353
00:25:46,610 --> 00:25:50,760
what else are we looking at whole number article nearest neighbor distance one nearest neighbor

354
00:25:50,760 --> 00:25:56,000
distance that's that's kind obvious this here there's a there's a drawing this is a

355
00:25:56,000 --> 00:26:01,350
this is and that distances the root 2 times a and this is half of

356
00:26:01,360 --> 00:26:03,220
route to so

357
00:26:03,220 --> 00:26:07,720
that's given here a over route to nearest neighbors well you can see that nearest

358
00:26:07,720 --> 00:26:12,050
neighbors let's count from this 1 is that for at the corners right and it's

359
00:26:12,050 --> 00:26:16,170
. 3 in this plane 3 in other points so that's going to add up

360
00:26:16,520 --> 00:26:16,760
to 4

361
00:26:17,260 --> 00:26:21,870
+ 4 plus 4 is nearest neighbors is equal to 12 some people call this

362
00:26:21,870 --> 00:26:28,780
the coordination number coordination number and this has got the highest this got the highest

363
00:26:28,780 --> 00:26:34,200
number of nearest neighbors when you have hard spheres of equal dimensions of any of

364
00:26:34,250 --> 00:26:38,020
crystal system you can see here body centered cubic and has 8 nearest neighbors were

365
00:26:38,040 --> 00:26:41,050
simple cubic only has 6 nearest neighbors

366
00:26:41,330 --> 00:26:43,140
of silicon anymore

367
00:26:43,170 --> 00:26:48,460
and then the packing density of history the packing density that's an interesting calculation but

368
00:26:48,460 --> 00:26:54,900
the packing density indicates is how much going back to democracy if we model

369
00:26:54,900 --> 00:27:00,060
this and was the first is

370
00:27:02,520 --> 00:27:07,190
his wife and son little reasoning on the

371
00:27:07,200 --> 00:27:08,210
so you can see

372
00:27:08,260 --> 00:27:10,880
it was also

373
00:27:11,050 --> 00:27:18,380
the conjunction

374
00:27:23,760 --> 00:27:25,380
you want to

375
00:27:25,390 --> 00:27:29,890
i'm relationship is that this for the thing to find in this view

376
00:27:29,990 --> 00:27:32,090
is the class of top

377
00:27:32,100 --> 00:27:37,700
so each of these alternatives to find an axiomatic relationship between the function class expressions

378
00:27:37,700 --> 00:27:40,930
as with these are here because expression can be assembled

379
00:27:50,870 --> 00:27:56,650
if you want to see how this works in other formats which you can easily

380
00:27:57,700 --> 00:28:00,020
so most of these are the formats have some

381
00:28:00,040 --> 00:28:01,460
not all

382
00:28:01,480 --> 00:28:03,510
and so on

383
00:28:08,070 --> 00:28:09,470
o also

384
00:28:09,480 --> 00:28:12,790
so we're trying to figure out how to relate

385
00:28:12,800 --> 00:28:14,610
throughout the particular

386
00:28:19,160 --> 00:28:23,060
o on the season one

387
00:28:23,070 --> 00:28:23,770
this is very

388
00:28:23,780 --> 00:28:25,620
and also see the RDF

389
00:28:31,830 --> 00:28:40,970
sure in the functional syntax two pieces of

390
00:28:43,770 --> 00:28:45,850
so far

391
00:28:46,240 --> 00:28:48,530
are some

392
00:28:48,540 --> 00:28:51,540
so we think that this is

393
00:28:51,560 --> 00:28:55,910
all necessary sufficient conditions in

394
00:28:59,030 --> 00:29:04,480
and all you know they want one is

395
00:29:04,500 --> 00:29:07,410
more than a year

396
00:29:08,040 --> 00:29:12,850
so this is the only one this

397
00:29:16,740 --> 00:29:19,830
complete here is exactly the same

398
00:29:19,940 --> 00:29:26,940
you notice that hyperlinks in all these views are long so you can navigate in

399
00:29:26,940 --> 00:29:29,810
any of the views involved

400
00:29:29,830 --> 00:29:32,160
so the architects inside

401
00:29:32,230 --> 00:29:39,310
the ontology of the work they do

402
00:29:49,330 --> 00:29:54,310
i think

403
00:29:58,250 --> 00:29:59,880
for short

404
00:30:03,260 --> 00:30:05,550
so my

405
00:30:08,390 --> 00:30:14,970
materials in one nice thing that we're not very non neutral view is that because

406
00:30:14,970 --> 00:30:19,090
the contracts themselves are represented by regularisation

407
00:30:19,100 --> 00:30:20,510
i think this is well

408
00:30:20,520 --> 00:30:22,840
and you can click on them so

409
00:30:22,860 --> 00:30:26,250
it's a good way to start with and that will take you to some help

410
00:30:26,250 --> 00:30:28,900
text from taken from the album

411
00:30:28,950 --> 00:30:31,120
which is again i was struck

412
00:30:31,480 --> 00:30:33,310
understand that some of

413
00:30:39,470 --> 00:30:42,350
so that's what i'm going to stick concise

414
00:30:43,640 --> 00:30:47,140
the other thing to do

415
00:30:47,300 --> 00:30:49,910
so in the morning at the top level

416
00:30:49,930 --> 00:30:51,050
you can pop up

417
00:30:51,130 --> 00:30:52,040
so so

418
00:30:52,060 --> 00:30:56,960
we know which classes have properties of functional reason can hyperlink from this is two

419
00:30:56,960 --> 00:31:01,230
kinds of links here one is the direct link which takes you to the definition

420
00:31:01,230 --> 00:31:02,730
of the term

421
00:31:02,740 --> 00:31:04,250
the other one

422
00:31:04,300 --> 00:31:08,710
sixty eventually takes it is sufficient to nest into which doesn't have very much you

423
00:31:08,710 --> 00:31:10,530
know the one is cultural references

424
00:31:10,580 --> 00:31:12,890
this also shows if you

425
00:31:12,920 --> 00:31:14,410
options right click

426
00:31:15,600 --> 00:31:17,620
but actually paying you can see

427
00:31:17,670 --> 00:31:20,120
the references in the references at every

428
00:31:20,140 --> 00:31:24,320
four property that has the maximum makes use of this

429
00:31:24,330 --> 00:31:26,330
so in this case

430
00:31:26,350 --> 00:31:29,730
the thing that i was looking for the references four was has gender

431
00:31:29,830 --> 00:31:32,100
there are four

432
00:31:32,120 --> 00:31:36,730
he asked and this is really useful for

433
00:31:36,740 --> 00:31:41,530
actually there is no but also for just taking

434
00:31:41,580 --> 00:31:45,250
has to take

435
00:31:45,270 --> 00:31:49,110
prince was able to debug difficult

436
00:31:50,340 --> 00:31:53,690
come on the absence of

437
00:31:53,750 --> 00:31:56,240
we have to discover that

438
00:31:56,450 --> 00:31:58,710
one of the whole

439
00:32:01,870 --> 00:32:06,930
these are exactly what they are doing it right so here

440
00:32:08,420 --> 00:32:11,790
pop up the show a public assurance i can go i can see

441
00:32:12,950 --> 00:32:16,500
has gender is used to define

442
00:32:18,160 --> 00:32:26,320
since so LC three dollars is defined gender male students fifteen authorities to define

443
00:32:26,330 --> 00:32:28,110
his children

444
00:32:28,160 --> 00:32:29,810
so is no

445
00:32:30,160 --> 00:32:32,760
you know

446
00:32:33,700 --> 00:32:36,360
obviously also to define male in general

447
00:32:36,370 --> 00:32:40,100
it's also define animal which is a little bit we're right

448
00:32:40,110 --> 00:32:43,840
but i guess there were going to go

449
00:32:43,860 --> 00:32:45,210
is that

450
00:32:50,330 --> 00:32:55,560
are already on the

451
00:32:56,710 --> 00:33:00,970
i just want

452
00:33:01,380 --> 00:33:04,880
in these two

453
00:33:04,930 --> 00:33:11,670
a big you compare between them you'll notice that here we have

454
00:33:11,690 --> 00:33:16,470
who knows one

455
00:33:16,490 --> 00:33:21,820
you only have one and you look at the particular instantiations male and female you'll

456
00:33:21,820 --> 00:33:26,260
see that he just using its essentially you know the better

457
00:33:26,370 --> 00:33:27,950
you want

458
00:33:28,000 --> 00:33:30,140
you can see on the right

459
00:33:30,160 --> 00:33:31,900
five try five to

460
00:33:31,930 --> 00:33:32,910
give him

461
00:33:32,930 --> 00:33:34,710
another gender

462
00:33:36,010 --> 00:33:39,130
some public from

463
00:33:39,230 --> 00:33:49,290
you don't need to follow this yet

464
00:33:49,290 --> 00:33:54,540
time the product of the transition

465
00:33:54,600 --> 00:33:58,670
f of x given xk minus one is the markov

466
00:33:58,690 --> 00:34:01,150
so i'm basically the likelihood

467
00:34:01,170 --> 00:34:03,520
one of the of salvation

468
00:34:03,520 --> 00:34:07,060
which is part of g of white jaguar x XK OK

469
00:34:09,170 --> 00:34:10,420
these guys

470
00:34:10,440 --> 00:34:17,600
is simply the normalise target distribution in this context which have called before

471
00:34:17,600 --> 00:34:23,000
in the more general context as gamma and x one x two x so let's

472
00:34:23,000 --> 00:34:30,020
apply this essentially agrees amidst see very specific context so in a very specific context

473
00:34:30,250 --> 00:34:31,060
at so

474
00:34:31,080 --> 00:34:35,650
so as to approximate the sequence of facilities solutions for the latent state given the

475
00:34:36,020 --> 00:34:38,790
acceleration at time warner so-called

476
00:34:38,790 --> 00:34:44,460
capital and particle according to q one of two want to be made dependent on

477
00:34:44,460 --> 00:34:48,040
the first of salvation you collected you can do that not part of your reweighted

478
00:34:48,040 --> 00:34:49,710
particle OK

479
00:34:49,730 --> 00:34:54,580
o ninety six but in this scenario the normalized target

480
00:34:54,600 --> 00:34:58,630
distribution time one is simply the joint distribution of x one y one so this

481
00:34:58,630 --> 00:35:03,580
is initial point of x what time the conditional distribution of y given x y

482
00:35:03,650 --> 00:35:04,750
w divided by the

483
00:35:04,770 --> 00:35:05,790
importance weights

484
00:35:06,830 --> 00:35:08,960
your so called turbulent times

485
00:35:08,980 --> 00:35:13,750
from the associated weighted empirical measure of the approximation was still distribution of x one

486
00:35:13,810 --> 00:35:15,270
y one

487
00:35:15,980 --> 00:35:17,880
that the following time index

488
00:35:17,900 --> 00:35:20,170
when you have time and basically

489
00:35:20,190 --> 00:35:25,460
new song paul x the components and according to conditional distributions

490
00:35:25,480 --> 00:35:30,430
which can you may depend on y or x and minus one typically we tried

491
00:35:30,430 --> 00:35:31,770
to basically

492
00:35:31,790 --> 00:35:35,100
use for this conditional distribution

493
00:35:35,120 --> 00:35:40,520
the posterior distribution of xn given y and x minus one and the target distribution

494
00:35:40,520 --> 00:35:43,290
it's possible to be better

495
00:35:43,350 --> 00:35:45,850
you compute the associated

496
00:35:45,880 --> 00:35:48,170
basically importance weights

497
00:35:48,190 --> 00:35:53,270
of the city and the importance weight in this case this is the ratio of

498
00:35:53,270 --> 00:36:01,210
the successive normalise target distribution divided by the importance distribution but because of the specific

499
00:36:01,210 --> 00:36:06,000
structure of the target distribution support OK when you do gamma x one x two

500
00:36:06,000 --> 00:36:08,020
xn divided by gamma

501
00:36:08,020 --> 00:36:11,210
n minus one x one x two x minus one the only time the remains

502
00:36:11,210 --> 00:36:13,520
of the essentially the point here

503
00:36:13,580 --> 00:36:17,360
the transition point from x amount of one to extend and the conditional distribution of

504
00:36:17,360 --> 00:36:20,420
y given x and you write

505
00:36:21,380 --> 00:36:25,120
you are basically an approximation of the conquest

506
00:36:25,130 --> 00:36:30,230
as the weight of correctly measure if you want your sample basically capital in times

507
00:36:30,230 --> 00:36:34,750
to obtain new particles approximately distributed according to the time

508
00:36:35,500 --> 00:36:40,020
so let's see on twenty on to kind of get an idea was that it

509
00:36:40,020 --> 00:36:44,900
works well i'm going to call could simple algorithm a simple case where i know

510
00:36:44,900 --> 00:36:47,210
what forces OK

511
00:36:47,210 --> 00:36:50,810
so i'm considering a simple in the sense that they

512
00:36:52,130 --> 00:36:58,670
so it's really important for autoregressive gaussian process europe's xn in some notion of

513
00:36:59,350 --> 00:37:01,100
so in this case

514
00:37:01,210 --> 00:37:06,830
you know to join the facilities solution of the first lady during because of salvation

515
00:37:06,830 --> 00:37:07,980
is gaussian

516
00:37:08,020 --> 00:37:13,120
on these parameters can be computed using kalman type techniques OK so in particular

517
00:37:13,130 --> 00:37:17,980
the marginal distribution of x and y one y two y is basically the kalman

518
00:37:21,560 --> 00:37:24,810
basically i know what's the global truce in this case

519
00:37:27,080 --> 00:37:30,690
i'm gonna compare one proves to essentially

520
00:37:31,480 --> 00:37:37,540
particle algorithm the SMC sequential monte carlo methods so what do i need to define

521
00:37:37,580 --> 00:37:43,770
basically to my multicolour well the only degree of freedom i have now is the

522
00:37:43,770 --> 00:37:50,540
distribution i use so as to sample the state and extend time

523
00:37:50,560 --> 00:37:55,630
i believe the so basically what i'm gonna do i'm just going to solve paul

524
00:37:55,650 --> 00:38:00,750
xn and according to its publisher while OK very simple important is to generate per

525
00:38:00,750 --> 00:38:02,420
CPU can always

526
00:38:02,650 --> 00:38:04,880
so i use my glory

527
00:38:04,880 --> 00:38:08,380
OK i'm not going to have a look at what's going on so

528
00:38:08,400 --> 00:38:11,690
the figures they have been provided by only the capital feel so they are using

529
00:38:11,690 --> 00:38:15,080
his book you are not of model that was published by springer in two thousand

530
00:38:15,080 --> 00:38:17,600
five so

531
00:38:17,620 --> 00:38:19,580
what i'm going to present here

532
00:38:19,600 --> 00:38:26,040
he's basically what's going on a few times that when you're running those particles categories

533
00:38:28,480 --> 00:38:34,460
first let's start let's go bowling together at the top to stop just look at

534
00:38:34,460 --> 00:38:38,360
what's happening here at the bottom so i time basically

535
00:38:38,380 --> 00:38:43,500
at the initial time index is important particle x one

536
00:38:43,520 --> 00:38:45,350
on your way down

537
00:38:45,360 --> 00:38:46,810
your resource pool

538
00:38:47,830 --> 00:38:53,940
basically the particle that survived or some things that are propagated basically using

539
00:38:54,210 --> 00:38:58,620
the condition part my scenario because i use that is in part of the solution

540
00:38:58,630 --> 00:39:02,290
so what happens is basically

541
00:39:02,310 --> 00:39:05,150
among all the particles that have been sampled at time warner

542
00:39:05,790 --> 00:39:09,040
because some of them have been survived there are some things that were some of

543
00:39:09,060 --> 00:39:12,020
the some of us have admitted offspring

544
00:39:12,020 --> 00:39:13,880
then basically

545
00:39:13,900 --> 00:39:17,880
you have quite a few that died on the essentially what you have is that

546
00:39:17,880 --> 00:39:20,330
you have a particle approximation

547
00:39:20,380 --> 00:39:24,520
of the joint distribution of x one and x two given y one y two

548
00:39:24,520 --> 00:39:30,600
OK on each particles some on the real correspond to this by disguising you've line

549
00:39:30,620 --> 00:39:34,690
basically indicating this is the passed x one x two OK

550
00:39:34,710 --> 00:39:37,100
so you have capital and of them

551
00:39:37,830 --> 00:39:39,690
those past here

552
00:39:42,940 --> 00:39:45,330
basically you have in your acceleration coming

553
00:39:45,540 --> 00:39:50,900
we weighted by the importance weight your for capital n times form the weighted empirical

554
00:39:51,790 --> 00:39:56,290
so obviously some of them are going to die some of some of those are

555
00:39:56,290 --> 00:40:01,560
gonna basically in every multiple copies on they can be propagated for

556
00:40:01,580 --> 00:40:04,400
that basically positive sort

557
00:40:09,900 --> 00:40:12,440
so let's say this is what's happening

558
00:40:12,460 --> 00:40:18,560
when i'm at time so in this case twenty four OK so what you have

559
00:40:19,440 --> 00:40:24,580
these guys corresponds essentially this

560
00:40:26,290 --> 00:40:30,170
they correspond to

561
00:40:30,190 --> 00:40:35,170
there description

562
00:40:35,190 --> 00:40:38,120
of all the particles

563
00:40:38,130 --> 00:40:42,520
that have been sampled in the joint space x one x two x twenty four

564
00:40:43,560 --> 00:40:45,770
so what you see

565
00:40:46,880 --> 00:40:47,880
is that

566
00:40:47,880 --> 00:40:55,040
essentially what happened because of the successive resampling step where their first initiative first components

567
00:40:55,040 --> 00:40:56,170
from time

568
00:40:56,190 --> 00:40:59,920
i want to in this case then they all similar

569
00:40:59,940 --> 00:41:03,480
OK so some are because of that they should all or some things that you've

570
00:41:03,480 --> 00:41:05,600
introduced basically

571
00:41:05,630 --> 00:41:09,920
their own sister that have coalesced this was quite sense like in that basically genetics

572
00:41:10,170 --> 00:41:15,170
on essentially they all have the same on sisters this is due to essentially success

573
00:41:15,170 --> 00:41:18,480
equal to infinity

574
00:41:18,500 --> 00:41:19,550
for all

575
00:41:19,570 --> 00:41:23,400
other vertices for all vertices not equal to us

576
00:41:23,420 --> 00:41:24,610
but less

577
00:41:25,360 --> 00:41:30,570
now we have to cheque that this inequality holds well we have delta as common

578
00:41:30,570 --> 00:41:33,050
as we've already argued that that's zero

579
00:41:33,070 --> 00:41:35,780
because you can get negative when are only

580
00:41:35,800 --> 00:41:40,570
nonnegative edge weights so that's the best so certainly zero is greater than equal to

581
00:41:41,690 --> 00:41:44,860
and we have everything else well

582
00:41:44,880 --> 00:41:47,150
delta of

583
00:41:48,000 --> 00:41:54,150
comm is certainly less than or equal to infinity so this holds everything is less

584
00:41:54,150 --> 00:41:55,650
wrinkle to infinity

585
00:41:56,730 --> 00:42:01,050
this case is that so now we do induction

586
00:42:01,070 --> 00:42:04,550
and i'm going to write it is a proof by contradiction

587
00:42:04,590 --> 00:42:06,920
so let's say i suppose

588
00:42:06,940 --> 00:42:10,130
the this fails to hold at some point

589
00:42:11,020 --> 00:42:27,230
so suppose for a contradiction that the invariance is violated

590
00:42:27,230 --> 00:42:35,130
so we'd like to sue the violator and find a contradiction so it's going to

591
00:42:35,130 --> 00:42:40,170
be violated so let's look at the first violation the first violin

592
00:42:40,800 --> 00:42:43,130
so this is essentially going proof by induction

593
00:42:46,090 --> 00:42:47,190
so let's say

594
00:42:47,210 --> 00:42:49,300
we have some violation

595
00:42:49,300 --> 00:42:54,800
is less than delta company that would be bad for somehow can estimate smaller than

596
00:42:54,800 --> 00:42:56,880
the shortest path

597
00:42:59,020 --> 00:43:04,420
and i think about looking first violations we know sorted by induction that all previous

598
00:43:04,880 --> 00:43:06,940
all other values are correct

599
00:43:07,190 --> 00:43:09,840
of is the first one where rick schroder

600
00:43:09,860 --> 00:43:11,980
so the very holds everywhere else

601
00:43:11,980 --> 00:43:18,550
well what cause this to fail this with this invariance is violated is some relaxation

602
00:43:18,570 --> 00:43:25,840
OK on DVD so we have indeed we we replace it with some

603
00:43:25,860 --> 00:43:27,070
the idea of you

604
00:43:28,070 --> 00:43:32,050
the weight of the edge from u to v

605
00:43:32,110 --> 00:43:33,610
so how this made it

606
00:43:35,960 --> 00:43:40,130
OK so

607
00:43:40,130 --> 00:43:41,320
so dv

608
00:43:41,360 --> 00:43:44,840
is now somehow less than this we just said the to this

609
00:43:44,860 --> 00:43:46,090
so this thing

610
00:43:46,110 --> 00:43:48,340
this must be less than

611
00:43:48,360 --> 00:43:50,380
delta best comedy

612
00:43:50,380 --> 00:43:54,650
claim is that that's not possible

613
00:43:56,610 --> 00:44:00,540
that's that's me write a little bit

614
00:44:00,550 --> 00:44:02,090
we have dw

615
00:44:02,320 --> 00:44:06,920
plus w b

616
00:44:08,340 --> 00:44:14,880
we have our induction hypothesis which holds on you use some other vertex we know

617
00:44:14,900 --> 00:44:17,960
the diffuse at least delta that's coming you

618
00:44:19,130 --> 00:44:21,040
this has to be at least

619
00:44:21,050 --> 00:44:27,920
delta s come you

620
00:44:27,920 --> 00:44:31,840
plus w w

621
00:44:34,170 --> 00:44:37,800
now what about this w comedy well that some path

622
00:44:37,820 --> 00:44:40,020
from unity

623
00:44:40,040 --> 00:44:40,960
OK so

624
00:44:40,980 --> 00:44:41,780
it's got to be

625
00:44:41,800 --> 00:44:44,360
bigger than the shortest path or equal

626
00:44:44,380 --> 00:44:47,210
certainly this is critical to delta

627
00:44:47,230 --> 00:44:49,130
view comedy

628
00:44:49,150 --> 00:44:58,780
they can be larger there's some multi edge path that has smaller totally

629
00:44:58,800 --> 00:45:00,570
but is certainly

630
00:45:00,590 --> 00:45:02,340
no smaller

631
00:45:02,360 --> 00:45:04,250
then delta if you come to the

632
00:45:04,270 --> 00:45:06,170
and this looks like a good

633
00:45:06,190 --> 00:45:09,840
summation delta s t u and u two v

634
00:45:13,150 --> 00:45:15,360
trying to inequality

635
00:45:15,380 --> 00:45:20,610
so this is upside down here but the trial s t u to be

636
00:45:20,630 --> 00:45:25,770
so this is only longer than rest to be

637
00:45:28,440 --> 00:45:32,460
OK so so we have this thing which is simultaneously greater than or equal to

638
00:45:32,460 --> 00:45:36,070
the shortest path way from us to be and also strictly less than the shortest

639
00:45:36,070 --> 00:45:40,210
path weight from s to v so that's a contradiction

640
00:45:40,230 --> 00:45:44,280
maybe contradiction isn't the most intuitive way to proceed the intuition here

641
00:45:46,020 --> 00:45:51,300
you know whenever is assigned that dv you have path in mind you are inductively

642
00:45:51,300 --> 00:45:54,300
had path from s to u when you this and so that was the real

643
00:45:54,300 --> 00:45:55,960
perhaps it should be no

644
00:45:55,960 --> 00:45:59,900
we always know that every path has weight greater equal to the shortest path so

645
00:45:59,900 --> 00:46:02,770
it should be true and here's the

646
00:46:02,780 --> 00:46:05,610
inductive proof

647
00:46:05,630 --> 00:46:09,630
moving right along this is easy warm-up

648
00:46:09,630 --> 00:46:13,500
great article to now we have to prove less than or equal to at the

649
00:46:13,500 --> 00:46:16,880
end of the album and this is true all the time less recall two will

650
00:46:16,880 --> 00:46:19,070
only be true

651
00:46:30,670 --> 00:46:38,400
we can improve

652
00:46:38,420 --> 00:46:42,480
a single two quite yet proven another lemma

653
00:46:43,800 --> 00:46:44,710
which again

654
00:46:44,710 --> 00:46:49,020
so both of these lemmas are useful for other algorithms to so we're sort of

655
00:46:49,020 --> 00:46:50,190
building some

656
00:46:50,210 --> 00:46:54,340
shortest path theory that we can apply later

657
00:46:54,400 --> 00:46:57,690
this one will give you some intuition about why relaxation

658
00:46:57,710 --> 00:47:01,550
no it's not only is it not bad there actually good

659
00:47:01,570 --> 00:47:05,650
not only does it not screw up anything but also makes good progress

660
00:47:05,650 --> 00:47:07,400
in the following sense

661
00:47:11,150 --> 00:47:14,270
you know the shortest path from s to some vertex

662
00:47:14,270 --> 00:47:20,730
OK so you know forrester summarises in your view then you gotta be suppose that

663
00:47:20,730 --> 00:47:22,590
is a shortest

664
00:47:22,840 --> 00:47:28,730
from s to v

665
00:47:30,360 --> 00:47:32,520
and also suppose

666
00:47:32,540 --> 00:47:34,480
that we already know

667
00:47:34,500 --> 00:47:41,230
india view the shortest path weights from s to u suppose we have this equality

668
00:47:41,230 --> 00:47:44,300
we now know that we always have a great article two suppose to equal for

669
00:47:46,000 --> 00:47:48,920
OK the vertex just before b

670
00:47:48,940 --> 00:47:50,400
in the shortest path

671
00:47:51,020 --> 00:47:52,500
OK i suppose

672
00:47:52,520 --> 00:47:54,980
we relax the edge u v

673
00:47:58,250 --> 00:48:02,820
which is exactly

674
00:48:02,940 --> 00:48:04,570
this stuff

675
00:48:04,570 --> 00:48:09,230
this is relaxing the edge u v died in discoloured relaxation here

676
00:48:09,230 --> 00:48:14,650
then after the relaxation

677
00:48:14,670 --> 00:48:17,650
d of e equals

678
00:48:17,670 --> 00:48:22,000
delta s so we had the correct answer for you we relax u b

679
00:48:22,000 --> 00:48:23,090
suppose i just

680
00:48:24,270 --> 00:48:26,900
i have employees and because of hundred

681
00:48:27,860 --> 00:48:29,100
but i got that would just

682
00:48:30,150 --> 00:48:31,230
two variables

683
00:48:32,210 --> 00:48:33,940
ninety eight constraints

684
00:48:34,860 --> 00:48:38,580
and generating these things randomly so now i can do this i can plot

685
00:48:39,720 --> 00:48:40,350
i get a right

686
00:48:41,840 --> 00:48:43,640
ninety eight have these things that are

687
00:48:48,220 --> 00:48:50,810
ninety eight them that's the intersection always

688
00:48:51,300 --> 00:48:55,140
now i chose those few lines of code that they didn't explain to in such

689
00:48:55,140 --> 00:48:59,270
a way that i know that there is a feasible solution so the intersection of

690
00:48:59,270 --> 00:49:03,000
all these things is not the empty set it's something here let's say this

691
00:49:05,250 --> 00:49:08,000
well you can see even though i've drawn ninety eight

692
00:49:11,010 --> 00:49:11,910
half planes

693
00:49:12,980 --> 00:49:16,360
my polygon the just here only has four vertices

694
00:49:16,820 --> 00:49:21,460
so it's probably very easy to solve so i think when you when you are

695
00:49:21,460 --> 00:49:26,290
more than a small and the other one is large it's probably fundamentally much easier

696
00:49:26,560 --> 00:49:28,440
than when they are both about the same size

697
00:49:28,830 --> 00:49:30,850
and so my little experiment was was

698
00:49:31,310 --> 00:49:33,120
the interesting to me i never realized

699
00:49:33,670 --> 00:49:36,180
that makes a big difference and so then it differently

700
00:49:36,770 --> 00:49:37,520
i plotted

701
00:49:38,860 --> 00:49:39,700
against the minimum

702
00:49:41,010 --> 00:49:41,280
the sea

703
00:49:41,750 --> 00:49:45,890
since there seem to be the more relevant measure of if the minimum is small

704
00:49:46,230 --> 00:49:50,410
it's an easy problem and so let's just say it's a small problem with the

705
00:49:51,040 --> 00:49:56,760
anyway so plotting with them men now it looks like a really captured what's going

706
00:49:56,760 --> 00:49:57,210
on here

707
00:49:57,740 --> 00:50:05,560
and so i plotted these points under regression here and i get that approximately the number of iterations approximately two-thirds

708
00:50:06,080 --> 00:50:11,020
times the minimum and raise the four-thirds power now what these two-thirds of authors are

709
00:50:11,080 --> 00:50:13,190
actually fundamentally the truth i don't know

710
00:50:13,980 --> 00:50:15,000
it seems kind of

711
00:50:15,680 --> 00:50:18,580
compelling because point six eight or six nine

712
00:50:20,050 --> 00:50:23,920
pretty close to two-thirds one point three three four so i don't know maybe is

713
00:50:23,920 --> 00:50:27,490
that just like i only this experiment wants but i do with a couple thousand

714
00:50:28,670 --> 00:50:29,110
i don't know

715
00:50:30,300 --> 00:50:31,140
open question

716
00:50:31,980 --> 00:50:35,190
if that's true theorem that's very interesting but i don't know

717
00:50:39,070 --> 00:50:43,710
here i just plotted on i a logarithmic plot plot of linearly

718
00:50:44,140 --> 00:50:48,730
it is so you can see that it doesn't it doesn't look like it's not power one does

719
00:50:49,170 --> 00:50:50,710
look like it's growing

720
00:50:51,130 --> 00:50:54,670
with some power higher than one such as four-thirds here

721
00:50:56,690 --> 00:50:57,150
so you can

722
00:50:58,380 --> 00:51:02,820
and this was important to me because i actually thought that this power was gonna be one

723
00:51:03,590 --> 00:51:05,380
and so the fact that it's a little bit more than one

724
00:51:06,120 --> 00:51:06,950
surprises me

725
00:51:07,660 --> 00:51:08,390
but it looks like it

726
00:51:09,080 --> 00:51:11,300
least in the way of generating these random problems

727
00:51:11,830 --> 00:51:12,990
it looks like it's real

728
00:51:13,630 --> 00:51:17,210
and i think the way generate a random problems is fairly the german

729
00:51:18,890 --> 00:51:24,090
okay well i also made ample model which may be in the interest of time i'll skip this is

730
00:51:24,860 --> 00:51:26,490
coding is other language i like

731
00:51:27,280 --> 00:51:30,450
that does the same thing also fits into pages so it's not

732
00:51:32,910 --> 00:51:35,000
and you can download the sample code if you like

733
00:51:36,830 --> 00:51:37,560
all right now

734
00:51:37,980 --> 00:51:42,580
and now worst-case and average-case analysis so the simplex methods for the time being

735
00:51:43,770 --> 00:51:44,350
talk about

736
00:51:44,920 --> 00:51:46,990
another topic that's really a fundamental

737
00:51:51,920 --> 00:51:53,480
duality theory end

738
00:51:54,200 --> 00:51:56,090
this is really why

739
00:51:56,870 --> 00:51:57,780
linear programming

740
00:51:58,660 --> 00:52:00,070
is a fundamentally important

741
00:52:00,830 --> 00:52:04,520
well okay there's two reasons why the approach things from an important one

742
00:52:04,940 --> 00:52:06,680
there's lot a real world examples

743
00:52:07,860 --> 00:52:09,150
describe some to you

744
00:52:10,010 --> 00:52:11,470
o and later

745
00:52:14,460 --> 00:52:15,680
from a practical point of view

746
00:52:16,180 --> 00:52:18,350
lots of examples but mathematicians

747
00:52:19,300 --> 00:52:23,960
theorists are also interested in linear programming because there's some very fundamental

748
00:52:24,530 --> 00:52:26,760
ideas here and it's called duality

749
00:52:29,200 --> 00:52:29,460
and so

750
00:52:29,930 --> 00:52:33,830
and this tells us this gonna tell us a lot it's going and former are are newer

751
00:52:34,310 --> 00:52:38,370
versions of the simplex method it's going to inform us and how to derive other

752
00:52:38,500 --> 00:52:41,430
variants and gets in the three point five algorithm

753
00:52:43,660 --> 00:52:45,580
so every problem has a dual

754
00:52:46,690 --> 00:52:48,670
this is our primal problem in standard form

755
00:52:49,240 --> 00:52:49,690
the dual

756
00:52:50,250 --> 00:52:52,460
this is that is a minimization problem

757
00:52:54,900 --> 00:52:57,830
right hand side becomes the objective coefficients

758
00:52:58,710 --> 00:53:01,620
the objective coefficients in the primal become the right hand side

759
00:53:02,160 --> 00:53:07,890
the constraint matrix and its transpose so are here i had em constraints and and

760
00:53:08,220 --> 00:53:11,710
variables here i and constraints and and variables

761
00:53:12,190 --> 00:53:15,930
we just introduce another dummy later why for the dual variables

762
00:53:17,540 --> 00:53:20,740
so here it is it looks very much like this except for t greater than

763
00:53:20,740 --> 00:53:24,790
or equal to constraints and it's a minimization but other than than it looks very

764
00:53:24,790 --> 00:53:27,040
much like the primal problem in fact if

765
00:53:27,560 --> 00:53:30,040
the fact that these two look very much alike is really why

766
00:53:30,490 --> 00:53:32,880
i preferred to uh to

767
00:53:33,360 --> 00:53:35,320
to start with problems in this form

768
00:53:36,350 --> 00:53:36,870
which is at

769
00:53:37,340 --> 00:53:42,560
we edit just as in this in this decision i diverge from many other r

770
00:53:42,640 --> 00:53:47,360
standard textbooks but i think the reason is that is that there is a beautiful

771
00:53:47,360 --> 00:53:48,740
symmetry when you do it this way

772
00:53:51,530 --> 00:53:52,510
the original problem

773
00:53:52,940 --> 00:53:54,330
it's called the primal problem

774
00:53:58,630 --> 00:54:00,480
the problem is defined by its data

775
00:54:01,190 --> 00:54:04,650
and so we have an maybe and see that really define the problem

776
00:54:05,040 --> 00:54:07,780
and the dual problem has the same data

777
00:54:09,660 --> 00:54:10,870
but using a different way

778
00:54:11,450 --> 00:54:13,530
and actually if we write the dual problem

779
00:54:14,030 --> 00:54:18,920
it's standard form so i convert the max the minimize to maximize how do i do there

780
00:54:19,660 --> 00:54:24,390
minimizer function what take its negative and then maximise it and then you're you're done

781
00:54:24,640 --> 00:54:28,390
negate that again so i maximize minus be transposed why

782
00:54:28,870 --> 00:54:30,520
and i said that you gave my answer

783
00:54:32,560 --> 00:54:36,000
i want less than or equal to constraints to be in standard form how do

784
00:54:36,000 --> 00:54:40,780
i do now is multiply both sides this article quality minus one i like this

785
00:54:41,180 --> 00:54:42,480
so now we see that

786
00:54:42,890 --> 00:54:44,010
the the the the

787
00:54:45,420 --> 00:54:46,370
o typo

788
00:54:47,150 --> 00:54:48,380
i never noticed this type

789
00:54:49,300 --> 00:54:51,650
response to be a transpose and they matrix right there

790
00:54:55,670 --> 00:54:57,400
the dual problem is

791
00:54:57,840 --> 00:55:00,880
simply the negative transposable the primal problem

792
00:55:05,190 --> 00:55:05,700
in fact a few

793
00:55:06,130 --> 00:55:07,520
look in the dictionary right the

794
00:55:07,970 --> 00:55:12,450
really looks like the negative transpose because the sea is here and the these here in the eighties

795
00:55:13,360 --> 00:55:16,090
those are the original and the bees here this is here and it is here

796
00:55:16,260 --> 00:55:20,150
think about is just one big matrix and take its transpose the being the sea

797
00:55:20,180 --> 00:55:20,910
get switched

798
00:55:20,910 --> 00:55:21,260
but do

799
00:55:21,700 --> 00:55:22,940
you'd have some over

800
00:55:23,460 --> 00:55:26,620
to that end which is to the one thousand

801
00:55:28,620 --> 00:55:30,620
and to the one thousand

802
00:55:35,760 --> 00:55:40,780
let's put it this way imagine that you had access to all the electrons in the universe

803
00:55:42,160 --> 00:55:43,430
this tend be eighty

804
00:55:45,240 --> 00:55:46,330
electrons in the universe

805
00:55:46,870 --> 00:55:50,440
imagine that you managed to turn everyone those electrons in a powerful computer

806
00:55:52,320 --> 00:55:53,680
and they can do operations

807
00:55:54,890 --> 00:55:57,630
that you have in the universe to do it in

808
00:56:03,040 --> 00:56:05,700
is actually due to ninety eight sentence

809
00:56:08,180 --> 00:56:08,880
so this is

810
00:56:09,670 --> 00:56:11,510
two thousand two hundred sixty six

811
00:56:14,230 --> 00:56:17,430
so if you have every single electron in the universe seems to be still you're

812
00:56:17,460 --> 00:56:21,160
doing operation and repeats the whole eight universe do

813
00:56:22,850 --> 00:56:24,960
multiply those to invite travel and see how many

814
00:56:25,480 --> 00:56:27,670
operations you can do the job

815
00:56:28,290 --> 00:56:31,320
the biggest international efforts to two hundred sixty four

816
00:56:31,750 --> 00:56:33,010
so you can't some

817
00:56:33,740 --> 00:56:38,860
o all states of the enlightenment and an exhaustive enumeration even with

818
00:56:40,590 --> 00:56:42,630
universe of supercomputers

819
00:56:44,160 --> 00:56:46,240
so you can't do this even though

820
00:56:46,860 --> 00:56:48,430
energy is a very simple thing

821
00:56:48,980 --> 00:56:51,930
right at the same time you can do it by exhaustive enumeration

822
00:56:54,040 --> 00:56:57,140
so that's one thing you might want to know anything you might want to know

823
00:56:57,140 --> 00:57:01,660
what you know this is what's the fluctuations in its energy so you might want

824
00:57:01,670 --> 00:57:07,810
to the variance reality work really well know the average energy per square that nobody

825
00:57:08,240 --> 00:57:09,160
what the variance

826
00:57:09,580 --> 00:57:11,440
fluctuations are interesting thing know

827
00:57:12,190 --> 00:57:12,960
so you might want to know

828
00:57:13,740 --> 00:57:15,170
you might want to know what the mean

829
00:57:20,350 --> 00:57:20,930
the magnetic

830
00:57:21,820 --> 00:57:27,310
or you might want to know what the variance it's like citations so define the magnetisation in some way

831
00:57:27,990 --> 00:57:29,200
function to invent it

832
00:57:31,360 --> 00:57:33,670
i'm interested in knowing its meaning or its variants

833
00:57:34,430 --> 00:57:35,460
you might want to know

834
00:57:35,930 --> 00:57:38,930
the entropy of yours that's the average

835
00:57:40,940 --> 00:57:41,430
one over

836
00:57:43,170 --> 00:57:44,220
you might also want to know

837
00:57:46,700 --> 00:57:47,620
the normalizing constant

838
00:57:48,500 --> 00:57:52,030
he said that this is very exciting you don't have the

839
00:57:52,430 --> 00:57:53,900
bayesian inference about that

840
00:57:54,960 --> 00:57:55,980
this is z

841
00:57:57,170 --> 00:57:57,570
the log

842
00:57:59,130 --> 00:58:00,420
is essentially free energy

843
00:58:01,900 --> 00:58:06,040
the free energy fantastic things that you want to know in order to understand

844
00:58:06,490 --> 00:58:07,430
all sorts properties

845
00:58:09,140 --> 00:58:10,940
things like cities as well

846
00:58:11,450 --> 00:58:12,930
i can all be expressed

847
00:58:13,860 --> 00:58:20,030
in terms of x expectations and you anything on this list that can be expressed is log z

848
00:58:21,140 --> 00:58:23,810
which is an expectation is normalizing constant

849
00:58:24,510 --> 00:58:25,830
and that's got a lot

850
00:58:26,930 --> 00:58:29,730
well this is roughly the average energy that

851
00:58:35,590 --> 00:58:36,580
that's the second example

852
00:58:38,280 --> 00:58:41,080
the problem is that all the we have

853
00:58:41,600 --> 00:58:42,610
probability distribution

854
00:58:43,100 --> 00:58:44,910
it can be written in lines and energy

855
00:58:45,560 --> 00:58:51,510
energy can be evaluated and at any x quite easily it's easy that the entire

856
00:58:51,510 --> 00:58:54,740
distribution itself difference thing work because you

857
00:58:55,260 --> 00:58:56,130
give you and so

858
00:58:57,950 --> 00:58:59,490
what article states

859
00:58:59,980 --> 00:59:03,070
promising samples show me ten random samples this

860
00:59:04,540 --> 00:59:06,990
what you can say well i don't know how to draw

861
00:59:07,470 --> 00:59:09,180
ten random samples from this distribution

862
00:59:11,430 --> 00:59:14,480
one thing to note is we want to solve the problem of

863
00:59:15,730 --> 00:59:16,380
so problems

864
00:59:17,670 --> 00:59:18,700
the interest

865
00:59:19,540 --> 00:59:20,790
solve problem to

866
00:59:21,410 --> 00:59:26,280
which is you know these expected values of things you don't actually have to solve problem

867
00:59:26,960 --> 00:59:31,830
but if you have solved problem and then you can use them as a way of solving problems

868
00:59:32,620 --> 00:59:36,090
if you want problem to have

869
00:59:36,160 --> 00:59:36,850
be solved

870
00:59:39,420 --> 00:59:40,490
problem is solved

871
00:59:47,760 --> 00:59:48,230
gives you

872
00:59:49,560 --> 00:59:50,210
some points

873
00:59:50,990 --> 00:59:53,120
usually with that of a random sample

874
00:59:53,890 --> 00:59:54,720
they give you a set

875
01:00:00,200 --> 01:00:00,630
which do

876
01:00:01,000 --> 01:00:04,870
really come from the distribution because you have small problem one

877
01:00:07,630 --> 01:00:08,180
you can

878
01:00:11,070 --> 01:00:14,940
expectations are functions for example if someone says what is the average value of

879
01:00:16,730 --> 01:00:17,110
on the

880
01:00:19,000 --> 01:00:20,290
so want to know this

881
01:00:20,960 --> 01:00:21,840
the expected value

882
01:00:24,990 --> 01:00:27,160
can be estimated by saying

883
01:00:27,600 --> 01:00:28,860
well i'm gonna write down

884
01:00:30,670 --> 01:00:31,310
just talked

885
01:00:32,220 --> 01:00:34,860
several points that you've just given in the training set

886
01:00:35,480 --> 01:00:37,500
i'm see what the main event is

887
01:00:38,460 --> 01:00:38,790
on the

888
01:00:40,840 --> 01:00:42,060
empirical distribution

889
01:00:46,590 --> 01:00:48,520
that means that any functions

890
01:00:49,410 --> 01:00:52,270
i can just take you are random points that you make

891
01:00:52,670 --> 01:00:55,380
and i can be estimated their expectations

892
01:00:57,180 --> 01:00:58,680
using those are points

893
01:00:59,620 --> 01:01:00,720
the figure are is

894
01:01:01,720 --> 01:01:03,460
the better the estimate will be

895
01:01:04,030 --> 01:01:06,460
the closer they will be the true value

896
01:01:07,020 --> 01:01:07,900
the expectation

897
01:01:07,900 --> 01:01:13,760
solutions so therefore it's all one face now let's contrast that something that's to face

898
01:01:13,770 --> 01:01:18,390
to get a sense of what the differences so instead of pure water just liquid

899
01:01:18,390 --> 01:01:21,330
suppose i have i skewed

900
01:01:21,350 --> 01:01:23,740
iswc cubes in water

901
01:01:23,750 --> 01:01:28,340
iswc tubes in water it's still pure i didn't change the composition but i've got

902
01:01:28,340 --> 01:01:30,130
two different states

903
01:01:30,130 --> 01:01:33,930
i've got two different states i've got a solid state in liquid state and this

904
01:01:33,930 --> 01:01:35,260
fits the

905
01:01:35,310 --> 01:01:41,360
fits the definition in other words the ice floating in the water is uniform

906
01:01:41,370 --> 01:01:45,870
in chemical composition and it's physically distinct or i can say i can put boundary

907
01:01:45,870 --> 01:01:49,710
around it and i can isolate all the ice cubes and in fact these are

908
01:01:49,710 --> 01:01:53,650
mechanically separable i could pull out all the ice cubes and be left with only

909
01:01:55,600 --> 01:01:59,870
k solid and liquid two different faces because they're are two different states of the

910
01:01:59,870 --> 01:02:03,660
same material i think we also looked at milk

911
01:02:03,710 --> 01:02:05,420
we looked at mill

912
01:02:05,430 --> 01:02:08,380
and milk as fat globules

913
01:02:10,110 --> 01:02:11,720
aqueous phase

914
01:02:11,740 --> 01:02:15,660
in aqueous solution right so

915
01:02:15,670 --> 01:02:20,240
i've got fat globules they're very tiny they scatter light but if we got down

916
01:02:20,240 --> 01:02:28,510
to the micro level we could find these globules as something that's mechanically separable physically

917
01:02:28,560 --> 01:02:32,810
the state and of uniform composition in different from this so this is two different

918
01:02:32,810 --> 01:02:36,720
phases because we have two different compositions

919
01:02:36,730 --> 01:02:39,340
we have two different compositions

920
01:02:39,360 --> 01:02:40,860
and lastly

921
01:02:40,880 --> 01:02:42,670
there was vision

922
01:02:42,720 --> 01:02:48,650
the visions where the piracy around the piracy around that was the glass ceramic

923
01:02:48,670 --> 01:02:55,340
the glass ceramic it's ninety five percent crystal and five percent glassy so what you

924
01:02:55,340 --> 01:02:59,020
have here is you have a glassy phase

925
01:03:01,780 --> 01:03:04,280
and crystallin

926
01:03:04,330 --> 01:03:08,460
crystalline precipitates

927
01:03:08,500 --> 01:03:12,300
OK so again we don't ever change in composition but we have the change in

928
01:03:12,300 --> 01:03:18,470
order in atomic order so the glassy phase and the david five days so we

929
01:03:18,470 --> 01:03:23,590
can actually draw boundaries around all the crystalline precipitate so i hope this gives you

930
01:03:23,590 --> 01:03:27,880
a sense of what what's going on here the second thing is that this phase

931
01:03:27,880 --> 01:03:31,260
diagrams are drawn under conditions called equilibrium

932
01:03:31,280 --> 01:03:34,150
that's why we talk about stability so let's define

933
01:03:36,240 --> 01:03:41,590
equilibrium is the condition

934
01:03:41,600 --> 01:03:45,080
which represents the lowest energy state of the system

935
01:03:45,100 --> 01:03:46,970
the lowest energy state

936
01:03:46,990 --> 01:03:52,980
richard you take all of the constituents and give them infinite time and the energy

937
01:03:52,980 --> 01:03:57,210
they need to achieve the lowest energy state this is where they will get two

938
01:03:57,210 --> 01:04:03,120
and we'll know that it's the equilibrium state because the properties are invariant properties are

939
01:04:03,120 --> 01:04:07,030
invariant with time this sort of like a steady state but steady state is something

940
01:04:07,030 --> 01:04:11,530
that could be sort of locked in on the road to stability so this is

941
01:04:11,630 --> 01:04:16,650
the ultimate stability as contrasted with metastability

942
01:04:16,730 --> 01:04:19,160
metastability is

943
01:04:19,270 --> 01:04:23,310
something that steady state but could get

944
01:04:23,340 --> 01:04:27,950
stabler you have an example of metastability is diamond

945
01:04:28,000 --> 01:04:33,460
which is not the stable form of carbon with temperature but diamond was formed under

946
01:04:33,460 --> 01:04:39,240
different conditions and then brought under ambient pressure and temperature but the activation energy to

947
01:04:39,240 --> 01:04:42,800
convert is so high that it stays apparently

948
01:04:42,830 --> 01:04:47,880
stable but in point of fact its metastable another one is metallic glass

949
01:04:47,920 --> 01:04:51,630
the italic we know the metallic glass was formed under

950
01:04:51,670 --> 01:04:55,630
hi quench rates if you take the tower glass and heated

951
01:04:56,730 --> 01:05:00,220
you're given sufficient activation energy to then jumps

952
01:05:00,230 --> 01:05:06,480
from this glassy states of the crystal in state and ultimately achieve its its equilibrium

953
01:05:09,210 --> 01:05:13,970
so those are examples of this

954
01:05:13,980 --> 01:05:20,800
equilibrium metastability and the last thing i notice i talked about pure materials and then

955
01:05:20,830 --> 01:05:23,780
multicomponent materials they have different

956
01:05:23,800 --> 01:05:29,580
elements that are mixed and so we need to counter a metric that details what

957
01:05:29,580 --> 01:05:34,790
the level of chemical complexity is and for that we call in to play

958
01:05:34,790 --> 01:05:35,850
the local

959
01:05:35,860 --> 01:05:39,360
maximum correspond to any of the locations of the chairs here

960
01:05:39,380 --> 01:05:44,030
just all over the place but it can even get close to

961
01:05:45,180 --> 01:05:48,110
one of the things that people have stopped doing at the beginning was OK this

962
01:05:48,110 --> 01:05:52,220
promise to hire let's simplify so instead of trying to the genetic images with genetic

963
01:05:52,220 --> 01:05:57,360
of just less work with simple world let's the block walls in which we have

964
01:05:57,360 --> 01:06:01,650
found a mathematical models that explain absolutely everything that goes on in the image and

965
01:06:01,650 --> 01:06:04,990
try to organize the objective that here simple blocks

966
01:06:05,710 --> 01:06:07,100
of course this

967
01:06:07,150 --> 01:06:10,120
it has the problem that doesn't really get to five cannot do other things with

968
01:06:12,420 --> 01:06:16,940
a big family of different models for object recognition appeared in the literature and here

969
01:06:16,940 --> 01:06:17,980
i'm just

970
01:06:17,990 --> 01:06:23,160
clustering them into five families by the war models in which just a distance of

971
01:06:23,160 --> 01:06:27,810
an object and the representation just like above words like what is typically done in

972
01:06:28,150 --> 01:06:31,980
a language modeling in some models for language

973
01:06:32,530 --> 01:06:37,420
you forget all the special locations that to become family of object models or the

974
01:06:37,420 --> 01:06:41,790
models are based on both in the that many many different small pieces of objects

975
01:06:42,050 --> 01:06:44,410
and each one is going to vote for one of the centre for an object

976
01:06:45,130 --> 01:06:48,130
then you have shape matching in which

977
01:06:48,160 --> 01:06:51,230
you have a germ of an object is shape and you are trying to find

978
01:06:51,230 --> 01:06:55,390
instances of the shape on image and just apply smaller formations to the shape until

979
01:06:55,390 --> 01:06:58,220
if it's what you can see on the image

980
01:06:58,230 --> 01:07:02,390
the constellation models in which you have a few parts is similar to the voting

981
01:07:02,390 --> 01:07:06,610
models in some cases but generally have very few but not many many just a

982
01:07:06,610 --> 01:07:07,620
few of them

983
01:07:07,670 --> 01:07:11,170
and you have a very costly model how these parts relate to each other and

984
01:07:11,170 --> 01:07:15,510
to try to protect them on images and then attempt models that is a little

985
01:07:15,510 --> 01:07:18,790
bit like the game of the chair in which you just have a fixed played

986
01:07:19,050 --> 01:07:24,850
juvenile for the formations and you just apply scanning just kind of normalized correlation

987
01:07:24,960 --> 01:07:28,650
and if you do it on the right feature space it may have to work

988
01:07:28,650 --> 01:07:29,570
quite well

989
01:07:29,620 --> 01:07:34,920
do it directly on the pixel intensities it doesn't work very well for genetic up

990
01:07:34,920 --> 01:07:38,320
just four faces can mahler's work a little bit

991
01:07:40,150 --> 01:07:46,030
so all these models got really a big push when people manage to solve basically

992
01:07:46,030 --> 01:07:47,990
the face detection problems

993
01:07:48,010 --> 01:07:49,590
and so

994
01:07:49,620 --> 01:07:53,030
people have been working on for the vision for a long time and this classifier

995
01:07:53,040 --> 01:08:01,020
based models have been extremely successful detecting faces so here just one typical database of

996
01:08:01,560 --> 01:08:06,380
examples of faces generally frontal faces and these are some examples of of is the

997
01:08:07,300 --> 01:08:11,290
and people have been working for this for a very long time and it's been

998
01:08:11,290 --> 01:08:15,290
just and only thousand in which people actually managed to build systems that will work

999
01:08:15,290 --> 01:08:19,970
in real time and they are quite successful at this task but this kind confession

1000
01:08:20,020 --> 01:08:23,190
because when you look at this image is all these faces the only one to

1001
01:08:23,190 --> 01:08:27,670
be detected that's the only one the only thing they want their competitive looking at

1002
01:08:27,670 --> 01:08:32,510
the picture they should be easy easy to detect and he has taken so long

1003
01:08:32,550 --> 01:08:34,770
to detect them but not now

1004
01:08:34,790 --> 01:08:38,410
there are commercial products that combine the use face detection

1005
01:08:38,420 --> 01:08:41,750
and they were pretty well so you have a camera with a face detection

1006
01:08:41,780 --> 01:08:47,050
unit cite them is going to use it in order to do a focus

1007
01:08:47,060 --> 01:08:50,170
and automatic focus selection and so on and light

1008
01:08:50,180 --> 01:08:53,600
and they work pretty well there are very few false alarms so most of the

1009
01:08:53,600 --> 01:08:57,010
time they were the the faces in work pretty well

1010
01:08:57,990 --> 01:09:01,640
so one of the few set for systems that bannister to solve this problem very

1011
01:09:01,640 --> 01:09:04,420
efficiently was the one interview by viola jones

1012
01:09:04,430 --> 01:09:09,580
in which the trick was the one two important contributions one must adjust very simple

1013
01:09:09,580 --> 01:09:14,780
features those were rectangles of based rectangles which can be computed very efficiently with only

1014
01:09:14,780 --> 01:09:19,640
four operations independently of the size of the rectangle and also the use of the

1015
01:09:19,640 --> 01:09:24,780
cascade which is you were going to play a set of different classifiers it's one

1016
01:09:24,780 --> 01:09:26,270
more and more selective

1017
01:09:26,310 --> 01:09:30,170
so that at the beginning to have a classifier that is very cheap but to

1018
01:09:30,180 --> 01:09:33,340
get rid of model most of the background and then play another five it's more

1019
01:09:33,340 --> 01:09:37,590
expensive but only apply to the locations good that still good candidates to contain the

1020
01:09:37,590 --> 01:09:42,250
face and the idea was also interviewed by florida and argument

1021
01:09:42,260 --> 01:09:43,590
at the same time

1022
01:09:43,650 --> 01:09:46,720
in which they also had this cascade of decisions

1023
01:09:46,820 --> 01:09:50,840
so that made the system to be extremely efficient so you could detect faces in

1024
01:09:51,030 --> 01:09:51,990
the right

1025
01:09:53,150 --> 01:09:57,150
which make it available which make it possible to develop the is this and commercial

1026
01:10:00,400 --> 01:10:05,300
then for generic objects of course this simple rectangles with just based on intensities they

1027
01:10:05,300 --> 01:10:07,460
don't work very well for generic objects

1028
01:10:07,490 --> 01:10:10,840
then all of the features that are very powerful like edges

1029
01:10:10,850 --> 01:10:14,050
and again there are a lot of different families of

1030
01:10:14,050 --> 01:10:16,460
classifiers based on edges

1031
01:10:16,470 --> 01:10:19,490
for instance that is this war by capillary

1032
01:10:19,500 --> 01:10:24,790
in nineteen nine in which they will use global silhouettes of objects and they will

1033
01:10:24,790 --> 01:10:30,910
do again template matching by doing by correlating the template with

1034
01:10:30,920 --> 01:10:33,740
with an edge extracted from the image

1035
01:10:33,750 --> 01:10:35,690
and that's my extracted from the image

1036
01:10:36,450 --> 01:10:39,220
and instead of just using just a single template they will have a family of

1037
01:10:39,220 --> 01:10:43,750
this block here is the set of virtual addresses the set of physical addresses the

1038
01:10:43,760 --> 01:10:47,680
correspond to the virtual addresses in a space that day

1039
01:10:47,690 --> 01:10:52,080
these are the only physical addresses they can talk about so if we for example

1040
01:10:52,080 --> 01:10:53,770
have different blocks

1041
01:10:53,790 --> 01:10:59,800
memory addresses the correspond to virtual addresses the beacon reference we can see that there

1042
01:10:59,810 --> 01:11:04,330
is no way for a proper model a to be able to reference some of

1043
01:11:04,330 --> 01:11:08,290
the members for any of the memory the users were able to totally separate physical

1044
01:11:08,290 --> 01:11:13,390
memory pieces of physical memory to a and b and talked about by into posing

1045
01:11:13,390 --> 01:11:17,440
this by by using this page map mechanism the virtual memory gives us

1046
01:11:19,330 --> 01:11:22,940
what we want so basically what we've done is we've sort of added this extra

1047
01:11:22,940 --> 01:11:28,990
layer of interaction with virtual memory system that is it look they gets too

1048
01:11:29,210 --> 01:11:33,000
gets to map virtual addresses into physical addresses

1049
01:11:34,970 --> 01:11:37,830
so the rest this lecture is really going to be details about how we actually

1050
01:11:37,830 --> 01:11:41,510
make this work but how we do things like how we actually

1051
01:11:41,640 --> 01:11:46,080
decide when to change the how how we decide to change this how we assign

1052
01:11:46,080 --> 01:11:51,270
the speed this email register based on which one of the modules is currently executing

1053
01:11:51,330 --> 01:11:55,580
about things like what the format of this page that people can look like so

1054
01:11:55,590 --> 01:11:59,380
this is this is really the key concept

1055
01:12:01,440 --> 01:12:03,910
if you think

1056
01:12:03,920 --> 01:12:07,060
so what i want to do now is returned to the first question is the

1057
01:12:07,060 --> 01:12:10,820
second question i asked which is what it how does this page thing actually work

1058
01:12:10,820 --> 01:12:16,020
what does it actually look how how is actually representing so one very simple representation

1059
01:12:16,020 --> 01:12:21,310
of the page map might be that it's simply is a pointer to the page

1060
01:12:21,310 --> 01:12:25,180
map just says where his memory begins on the processor

1061
01:12:25,200 --> 01:12:29,280
right so it's just one value it is memory begins at this location in the

1062
01:12:29,290 --> 01:12:31,300
physical memory and all

1063
01:12:31,500 --> 01:12:36,560
the virtual addresses should be resolved relative to to this beginning location memory

1064
01:12:37,770 --> 01:12:43,240
the problem with the problem with that representation is that it is not very flexible

1065
01:12:43,240 --> 01:12:48,530
so for example it means that supposed has both a and b

1066
01:12:48,570 --> 01:12:52,030
are suppose there's a third process that third model c

1067
01:12:52,070 --> 01:12:56,260
which is laid out in memory very right right next to it so it's storage

1068
01:12:56,260 --> 01:13:00,090
is is placed right next to a memory and now suppose that a wants to

1069
01:13:00,090 --> 01:13:04,850
allocate some additional memory can use now in order to do that work it with

1070
01:13:04,850 --> 01:13:09,080
its if if these virtual drive if the graph is simply a single point at

1071
01:13:09,080 --> 01:13:12,500
the beginning of these address space are kind of trouble we can just add memory

1072
01:13:12,500 --> 01:13:14,750
on the bottom because then we would overlap sees

1073
01:13:14,750 --> 01:13:18,260
we had overlaps c so we're going after to to remove all of these memory

1074
01:13:18,260 --> 01:13:21,230
around in order to be able to make space for this is that the same

1075
01:13:21,270 --> 01:13:25,030
like a little bit problematic to simply have a pointer thing we could do is

1076
01:13:25,030 --> 01:13:29,200
that we get suppose we could instead have different option where we could say

1077
01:13:29,240 --> 01:13:35,530
for example for every virtual address in in eighties address space so for each

1078
01:13:35,560 --> 01:13:39,970
thirty two bit for each thirty two to be value that it wants to resolve

1079
01:13:40,250 --> 01:13:43,440
there might be an entry in this page map table right so we can for

1080
01:13:43,440 --> 01:13:48,700
every thirty two bit virtual address to the corresponding thirty two bit physical address and

1081
01:13:48,700 --> 01:13:52,190
they're just be a one-to-one mapping between all these things have a good reference a

1082
01:13:52,190 --> 01:13:56,540
million box in memory there would be in a million entries in this page table

1083
01:13:56,560 --> 01:13:57,830
and so

1084
01:13:57,850 --> 01:14:00,860
if you think about this for that sounds like kind of a bad idea too

1085
01:14:00,870 --> 01:14:05,890
because now these tables are totally huge right in fact there is almost as big

1086
01:14:05,890 --> 01:14:09,510
as are there is because the memory itself right because have a million entries in

1087
01:14:09,510 --> 01:14:13,370
the table if it can reference million blocks that i many million entries in the

1088
01:14:13,370 --> 01:14:17,510
table so the table becomes just as big as the memory itself so we need

1089
01:14:17,510 --> 01:14:22,350
some in between sort of alternative hybrid between these two extremes

1090
01:14:22,550 --> 01:14:28,050
and the idea is again a very simple and you are of six were four

1091
01:14:28,050 --> 01:14:30,460
so the idea is to

1092
01:14:30,460 --> 01:14:34,100
take this thirty two bit virtual address

1093
01:14:34,130 --> 01:14:40,870
so i suppose this is a thirty two bit virtual address now we're going to

1094
01:14:40,870 --> 01:14:43,500
do is we're going to split up into two pieces

1095
01:14:43,570 --> 01:14:47,360
a page number

1096
01:14:47,390 --> 01:14:50,200
and offset

1097
01:14:51,720 --> 01:14:58,260
according to some size for these two things for now i'll just arbitrarily twenty to

1098
01:14:58,450 --> 01:15:02,610
twenty billion page number and a twelve bit offset

1099
01:15:03,250 --> 01:15:04,510
OK so

1100
01:15:04,520 --> 01:15:08,600
what this page so what this is going to do with so now we're going

1101
01:15:08,610 --> 01:15:12,270
to do is instead of storing a single

1102
01:15:12,610 --> 01:15:17,110
a single word of memory at each entry in this table restora page of memory

1103
01:15:17,110 --> 01:15:19,260
that each entry in this table so

1104
01:15:32,020 --> 01:15:35,530
so this table is going to look like a mapping between page

1105
01:15:35,540 --> 01:15:36,950
and the physical address

1106
01:15:36,950 --> 01:15:43,260
OK so what pages so if so if the page number is twenty bits long

1107
01:15:43,570 --> 01:15:46,300
then that means that the each page is going to be

1108
01:15:47,740 --> 01:15:49,730
two to twelve bits b

1109
01:15:49,740 --> 01:15:52,450
which is all to say four thousand ninety six

1110
01:15:57,840 --> 01:16:02,540
so the idea is that we're going to have

1111
01:16:02,550 --> 01:16:07,780
two twenty pages within each address space and

1112
01:16:07,830 --> 01:16:11,580
each page is going to map to one of these four thousand ninety six bytes

1113
01:16:21,840 --> 01:16:23,230
we have our memory here

1114
01:16:23,230 --> 01:16:28,410
this is this page the page one is gonna map into some physical address

1115
01:16:28,420 --> 01:16:29,990
page two

1116
01:16:30,000 --> 01:16:32,340
is gonna map into some other

1117
01:16:32,390 --> 01:16:35,960
physical block so each one of these things is now

1118
01:16:36,000 --> 01:16:38,960
four thousand ninety six bytes

1119
01:16:39,910 --> 01:16:41,300
each block here

1120
01:16:47,170 --> 01:16:50,530
just expanded so this is now page

1121
01:16:50,950 --> 01:16:54,600
and this offset this twelve offset is going to be used in order to look

1122
01:16:54,600 --> 01:16:57,340
up the word we want actually look up this page

1123
01:16:57,390 --> 01:16:59,230
so if

1124
01:16:59,300 --> 01:17:05,940
the if the if the virtual address is say for example page one

1125
01:17:05,950 --> 01:17:10,660
offset zero what that's going to do is we're going to look in pay when

1126
01:17:10,660 --> 01:17:14,020
you look up on the page map we're going to find the page number that

1127
01:17:14,020 --> 01:17:15,170
corresponds to

1128
01:17:16,330 --> 01:17:20,500
we're find page number one we find physical address that corresponds to it or come

1129
01:17:20,500 --> 01:17:24,680
down here and look in the physical address and look at this block of memory

1130
01:17:24,730 --> 01:17:29,080
and then within this four thousand ninety six block memory we're going to take the

1131
01:17:29,120 --> 01:17:32,630
addresses are all the time the first world within that thing

1132
01:17:32,630 --> 01:17:34,520
i can give it any random

1133
01:17:34,530 --> 01:17:37,170
the phase angle delta

1134
01:17:37,190 --> 01:17:38,720
and that would then be

1135
01:17:38,740 --> 01:17:40,100
y direction

1136
01:17:40,180 --> 01:17:41,540
so clearly

1137
01:17:41,540 --> 01:17:43,700
this satisfies

1138
01:17:43,750 --> 01:17:45,000
the wave equation

1139
01:17:45,050 --> 01:17:46,340
because it's

1140
01:17:46,350 --> 01:17:50,600
separately it satisfies the wave equation

1141
01:17:50,750 --> 01:17:54,460
it's not only evaluate delta equals zero

1142
01:17:54,500 --> 01:17:59,010
you still have linearly polarized radiation

1143
01:17:59,070 --> 01:18:03,460
look at the x y plane

1144
01:18:03,520 --> 01:18:05,030
this is x

1145
01:18:05,040 --> 01:18:11,950
and this is why the radiation is coming straight to you

1146
01:18:12,010 --> 01:18:14,070
at a certain moment in time

1147
01:18:14,110 --> 01:18:18,100
he factor in this direction reaches a maximum

1148
01:18:18,100 --> 01:18:21,910
he zero x

1149
01:18:21,930 --> 01:18:24,080
and that is

1150
01:18:24,120 --> 01:18:28,190
if delta is zero that's the moment in time that effective in the y direction

1151
01:18:28,190 --> 01:18:31,710
also reaches a maximum because delta is zero

1152
01:18:33,050 --> 01:18:34,590
this one is zero why

1153
01:18:34,710 --> 01:18:38,460
course at the same moment is that one

1154
01:18:38,550 --> 01:18:43,600
so what is the net effect that is the vectorial some of the two

1155
01:18:43,660 --> 01:18:45,940
so in effect or

1156
01:18:46,000 --> 01:18:49,950
is this

1157
01:18:50,080 --> 01:18:53,460
this is the total

1158
01:18:53,490 --> 01:18:55,580
which is the square root

1159
01:18:55,680 --> 01:18:58,510
one of zero x squared

1160
01:18:58,520 --> 01:19:01,860
plus are widespread

1161
01:19:01,890 --> 01:19:03,910
and if you

1162
01:19:04,020 --> 01:19:06,450
c is coming to you

1163
01:19:06,500 --> 01:19:13,040
using an electric field going like this shift linearly polarized

1164
01:19:13,090 --> 01:19:18,260
no longer linearly polarized in the x direction no longer in the y direction but

1165
01:19:18,310 --> 01:19:23,070
in this direction

1166
01:19:23,080 --> 01:19:25,080
i can also

1167
01:19:25,130 --> 01:19:27,860
make the phase angle between the two

1168
01:19:27,890 --> 01:19:30,320
ninety degrees

1169
01:19:30,340 --> 01:19:34,340
so i could make delta

1170
01:19:34,360 --> 01:19:35,600
by over two

1171
01:19:37,950 --> 01:19:43,430
now you get something very interesting

1172
01:19:43,450 --> 01:19:45,160
so this is no x

1173
01:19:45,180 --> 01:19:49,030
and this is no wise for the the radiation comes to x crosswise in new

1174
01:19:53,450 --> 01:19:56,180
and i think a moment in time

1175
01:19:57,260 --> 01:20:00,530
the zero x is maximum here

1176
01:20:00,550 --> 01:20:02,320
this is the factor

1177
01:20:02,320 --> 01:20:04,600
zero x but now is zero why

1178
01:20:04,660 --> 01:20:07,740
effective in the y direction is now zero

1179
01:20:07,800 --> 01:20:10,820
because they are ninety degrees out of phase

1180
01:20:10,840 --> 01:20:12,050
so therefore

1181
01:20:12,260 --> 01:20:15,650
this one which is the maximum this one is zero

1182
01:20:15,720 --> 01:20:17,950
a quarter period later

1183
01:20:18,010 --> 01:20:19,860
this one becomes zero

1184
01:20:21,010 --> 01:20:23,800
you have you y

1185
01:20:23,820 --> 01:20:27,220
according to period later this one is back to zero

1186
01:20:27,220 --> 01:20:28,590
and now this one

1187
01:20:29,660 --> 01:20:32,910
and the quarter period later this one is again zero

1188
01:20:32,930 --> 01:20:34,010
and this one

1189
01:20:36,010 --> 01:20:37,640
so now what you're going to see

1190
01:20:37,660 --> 01:20:39,660
there's never a moment

1191
01:20:39,740 --> 01:20:41,390
the vector

1192
01:20:43,360 --> 01:20:47,180
e vector rotates around in an ellipse

1193
01:20:47,220 --> 01:20:48,970
it goes like so

1194
01:20:49,030 --> 01:20:50,430
like so

1195
01:20:50,490 --> 01:20:51,570
like so

1196
01:20:51,600 --> 01:20:54,050
and so on

1197
01:20:54,050 --> 01:20:57,360
so it rotates around like this

1198
01:20:57,370 --> 01:20:58,550
and we call that

1199
01:20:58,620 --> 01:21:02,070
electrically polarized radiation

1200
01:21:02,120 --> 01:21:07,050
there's nothing very special about it is the perfect solution to maxwell's equations

1201
01:21:07,090 --> 01:21:07,720
you have

1202
01:21:07,740 --> 01:21:11,740
one component in the x direction and not in the y direction offset by ninety

1203
01:21:11,740 --> 01:21:19,620
degrees you can choose this angle any value you want

1204
01:21:20,220 --> 01:21:24,010
he zero x is the same as easier y

1205
01:21:24,050 --> 01:21:26,070
that's the circle

1206
01:21:26,120 --> 01:21:30,340
and then we call it circularly polarized radiation

1207
01:21:30,360 --> 01:21:31,910
in this case

1208
01:21:31,950 --> 01:21:34,320
going clockwise but of course

1209
01:21:34,370 --> 01:21:41,220
if you make delta minus by over two it will go counter-clockwise

1210
01:21:41,240 --> 01:21:43,640
i thought there was question

1211
01:21:43,700 --> 01:21:48,510
now suppose you were asked to calculate the associated field

1212
01:21:48,570 --> 01:21:50,680
that's a piece of cake

1213
01:21:50,700 --> 01:21:52,340
because you just follow

1214
01:21:52,370 --> 01:21:54,680
these simple rules

1215
01:21:54,700 --> 01:21:59,910
you take the component in the x direction you calculate the associated travelling wave in

1216
01:21:59,930 --> 01:22:00,890
in b

1217
01:22:00,990 --> 01:22:02,870
and then you do for the y direction

1218
01:22:02,890 --> 01:22:05,220
you calculate associated

1219
01:22:05,220 --> 01:22:07,700
travelling by the way if you add them up

1220
01:22:07,720 --> 01:22:08,990
that gives you then

1221
01:22:12,590 --> 01:22:15,740
in b

1222
01:22:15,760 --> 01:22:20,390
so this situation is

1223
01:22:21,930 --> 01:22:23,930
and simple

1224
01:22:23,950 --> 01:22:26,300
in two d

1225
01:22:26,320 --> 01:22:27,910
but i think i o u

1226
01:22:27,930 --> 01:22:29,800
a more general description

1227
01:22:29,800 --> 01:22:32,590
to white in your

1228
01:22:34,370 --> 01:22:37,180
and i want to go at least in terms of the

1229
01:22:37,240 --> 01:22:39,240
math going three d

1230
01:22:39,280 --> 01:22:42,720
so we now have XYZ coordinate system

1231
01:22:44,010 --> 01:22:45,030
we want

1232
01:22:45,090 --> 01:22:48,840
the option of having effect or not just in the x y plane or not

1233
01:22:48,840 --> 01:22:50,200
in the xy plane

1234
01:22:50,280 --> 01:22:51,890
but in a random

1235
01:22:54,180 --> 01:22:57,360
and so when we do that

1236
01:22:57,370 --> 01:23:01,220
we now get the vector

1237
01:23:01,240 --> 01:23:03,970
as a function of r and t

1238
01:23:04,010 --> 01:23:06,760
and r is the vector in space

1239
01:23:06,800 --> 01:23:07,970
which is x

1240
01:23:07,990 --> 01:23:09,570
x roof

1241
01:23:09,590 --> 01:23:10,550
that's why

1242
01:23:10,550 --> 01:23:11,820
why rules

1243
01:23:13,050 --> 01:23:19,240
this zero for any position vector in space you prefer

1244
01:23:19,240 --> 01:23:21,160
now i get this is the zero

1245
01:23:21,180 --> 01:23:25,660
it is now vector it's not the actual y or and see it is in

1246
01:23:25,660 --> 01:23:29,350
by at least approximately three meters per second

1247
01:23:29,400 --> 01:23:31,060
three meters per second

1248
01:23:31,110 --> 01:23:34,130
that means seven miles per hour

1249
01:23:34,180 --> 01:23:36,050
and so to a billion people

1250
01:23:36,110 --> 01:23:38,430
will go around like crazy

1251
01:23:38,440 --> 01:23:39,190
in that

1252
01:23:40,390 --> 01:23:41,650
and that's exactly

1253
01:23:41,680 --> 01:23:42,790
what happens

1254
01:23:42,790 --> 01:23:44,680
in the dream

1255
01:23:44,750 --> 01:23:48,570
and i'll show you here

1256
01:23:48,710 --> 01:23:52,770
picture from the book

1257
01:23:52,800 --> 01:23:56,640
mister punc is always in pyjamas just to remind you that is dream

1258
01:23:56,720 --> 01:24:00,550
need to say to professors are very old man has a very nice b

1259
01:24:00,570 --> 01:24:02,570
as the prestige

1260
01:24:02,690 --> 01:24:04,870
another each year from this book

1261
01:24:04,880 --> 01:24:07,220
i read you very short

1262
01:24:07,260 --> 01:24:09,410
paragraph that deals with this

1263
01:24:09,540 --> 01:24:11,480
professor says

1264
01:24:11,490 --> 01:24:12,380
look here

1265
01:24:12,410 --> 01:24:14,380
i'm going to port

1266
01:24:14,390 --> 01:24:17,880
definitely meets on the position of this ball by putting it inside

1267
01:24:17,890 --> 01:24:20,010
a wooden triangle

1268
01:24:20,090 --> 01:24:21,990
as soon as the ball was placed

1269
01:24:21,990 --> 01:24:23,280
in the enclosure

1270
01:24:23,290 --> 01:24:29,290
of the whole inside of the triangle became filled up with glaring of ivory

1271
01:24:29,330 --> 01:24:31,340
she said professor

1272
01:24:31,390 --> 01:24:33,490
i define the position of the ball

1273
01:24:33,490 --> 01:24:36,690
to the extent of the dimensions of the triangle

1274
01:24:36,790 --> 01:24:38,190
this results

1275
01:24:38,190 --> 01:24:41,520
in considerable uncertainty in the velocity

1276
01:24:41,570 --> 01:24:45,850
and the ball is moving rapidly inside the boundary

1277
01:24:45,870 --> 01:24:47,540
can to stop it

1278
01:24:47,570 --> 01:24:49,370
as mister tompkins

1279
01:24:50,790 --> 01:24:51,910
it is physically

1280
01:24:54,290 --> 01:24:58,940
anybody in an enclosed space possesses certain motion

1281
01:24:58,940 --> 01:25:01,890
we physicists call it's zero point motion

1282
01:25:01,950 --> 01:25:03,510
such as for example

1283
01:25:03,520 --> 01:25:04,500
the motion

1284
01:25:04,510 --> 01:25:06,210
the of electrons

1285
01:25:06,230 --> 01:25:09,270
in any at all

1286
01:25:09,310 --> 01:25:10,530
so here you see

1287
01:25:10,530 --> 01:25:12,490
quantum mechanics at work

1288
01:25:12,510 --> 01:25:14,550
when h four

1289
01:25:14,560 --> 01:25:16,560
this one

1290
01:25:16,570 --> 01:25:18,400
this is a very

1291
01:25:18,410 --> 01:25:20,800
non classical idea because

1292
01:25:20,850 --> 01:25:22,540
you and i would think

1293
01:25:22,580 --> 01:25:24,890
we've always dealt with that in the one

1294
01:25:24,970 --> 01:25:28,830
that you can take an object and place it at location a

1295
01:25:28,890 --> 01:25:33,400
and we say at time t zero is a and it has no speed and

1296
01:25:33,400 --> 01:25:34,900
we know them mass so we know

1297
01:25:34,910 --> 01:25:37,130
both the momentum and position

1298
01:25:37,180 --> 01:25:39,290
two infinite accuracy

1299
01:25:39,290 --> 01:25:42,460
but according to quantum mechanics that's not possible

1300
01:25:42,460 --> 01:25:45,000
let's not return to the real world

1301
01:25:45,050 --> 01:25:48,970
where h bar is not among the rage burst to the minus thirty four

1302
01:25:48,970 --> 01:25:53,410
and that's not good a billion people inside this triangle

1303
01:25:55,110 --> 01:25:56,980
delta x is the same

1304
01:25:57,020 --> 01:25:59,980
but since it's bars ten to the minus thirty four

1305
01:26:00,030 --> 01:26:01,490
delta p

1306
01:26:01,550 --> 01:26:02,470
is of course

1307
01:26:02,480 --> 01:26:03,820
ten two thirty four

1308
01:26:03,840 --> 01:26:05,410
times smaller

1309
01:26:05,460 --> 01:26:09,790
and so the velocity is ten to thirty four times smaller

1310
01:26:10,900 --> 01:26:15,430
undetermined degree to which the velocity is now undetermined is so

1311
01:26:15,500 --> 01:26:17,220
ridiculously small

1312
01:26:17,330 --> 01:26:21,260
is three times ten to the minus thirty four meters per second

1313
01:26:21,270 --> 01:26:22,250
but if you

1314
01:26:22,310 --> 01:26:24,880
allowed the ball to move was that speed

1315
01:26:24,930 --> 01:26:27,380
in one hundred billion years

1316
01:26:27,440 --> 01:26:31,830
it we would move only one hundreds of the diameter of an electron source meaningless

1317
01:26:32,830 --> 01:26:34,370
so again you see

1318
01:26:34,390 --> 01:26:39,790
that quantum mechanics plays no role in our daily microscopic world of baseball

1319
01:26:41,000 --> 01:26:42,120
and billiards

1320
01:26:42,180 --> 01:26:45,570
and pots and pans

1321
01:26:45,620 --> 01:26:47,650
and therefore it is completely OK

1322
01:26:47,660 --> 01:26:48,760
for us to say

1323
01:26:48,760 --> 01:26:50,280
i have a billion people

1324
01:26:50,290 --> 01:26:51,990
which is at point a

1325
01:26:52,130 --> 01:26:53,890
and it passes one kilogram

1326
01:26:53,900 --> 01:26:55,180
and it has no speed

1327
01:26:55,180 --> 01:26:56,480
it's completely

1328
01:26:56,490 --> 01:26:58,880
kosher completely acceptable

1329
01:26:58,900 --> 01:27:02,470
quantum mechanics has no problems with that

1330
01:27:02,540 --> 01:27:05,360
let's not turn to

1331
01:27:05,380 --> 01:27:08,250
and adam

1332
01:27:08,290 --> 01:27:10,020
take a hydrogen atom

1333
01:27:10,050 --> 01:27:11,980
the diameter of the hydrogen atom

1334
01:27:11,990 --> 01:27:14,510
it's about ten to the minus ten meters

1335
01:27:14,520 --> 01:27:18,940
sorry electron is confined

1336
01:27:18,950 --> 01:27:20,380
delta x

1337
01:27:20,430 --> 01:27:24,160
of about ten to the minus ten meters

1338
01:27:24,240 --> 01:27:27,240
that means the momentum of that electron

1339
01:27:27,250 --> 01:27:30,080
becomes on the term according to heighten works

1340
01:27:30,130 --> 01:27:32,230
the uncertainty principle

1341
01:27:32,280 --> 01:27:34,380
about ten to the minus thirty four

1342
01:27:34,480 --> 01:27:38,050
divided by ten to the minus ten

1343
01:27:38,060 --> 01:27:41,120
about ten to the minus twenty four

1344
01:27:44,010 --> 01:27:47,090
a second

1345
01:27:47,140 --> 01:27:49,150
what is the mass of an electron

1346
01:27:49,160 --> 01:27:51,230
it's about ten to the minus

1347
01:27:51,230 --> 01:27:53,040
thirty kilograms

1348
01:27:53,200 --> 01:27:55,760
so this

1349
01:27:55,760 --> 01:27:57,090
delta p

1350
01:27:57,160 --> 01:27:59,100
is also and delta v

1351
01:27:59,270 --> 01:28:05,240
so it means that delta means the velocity of the electrons

1352
01:28:05,280 --> 01:28:08,380
is undetermined according to heisenberg's principle

1353
01:28:08,400 --> 01:28:11,280
by an amount which is at least

1354
01:28:11,310 --> 01:28:13,530
ten to the minus twenty four

1355
01:28:14,850 --> 01:28:17,050
this process is delta p

1356
01:28:17,110 --> 01:28:19,210
divided by the mass of the electron

1357
01:28:19,250 --> 01:28:21,270
his ten to the minus two

1358
01:28:21,290 --> 01:28:23,220
that is about ten to six

1359
01:28:24,520 --> 01:28:26,050
the second that is

1360
01:28:27,130 --> 01:28:30,640
thirty percent of the speed of light

1361
01:28:30,650 --> 01:28:32,120
sorry electrons

1362
01:28:32,130 --> 01:28:33,550
is moving

1363
01:28:33,560 --> 01:28:35,290
only because of the fact

1364
01:28:35,290 --> 01:28:36,930
that it is confined

1365
01:28:36,940 --> 01:28:39,310
that's what quantum mechanics is all about

1366
01:28:39,370 --> 01:28:40,940
electrons motion

1367
01:28:40,940 --> 01:28:43,040
is dictated exclusively

1368
01:28:44,080 --> 01:28:50,640
quantum mechanics

1369
01:28:50,700 --> 01:28:54,330
i'm going to show you an experiment

1370
01:28:54,350 --> 01:28:56,860
in which i want to

1371
01:28:56,930 --> 01:28:57,970
very true

1372
01:28:57,980 --> 01:28:59,040
how non

1373
01:29:00,240 --> 01:29:04,050
i works uncertainty principle is

1374
01:29:04,110 --> 01:29:05,290
i have here

1375
01:29:05,290 --> 01:29:07,200
a laser beam

1376
01:29:07,200 --> 01:29:10,250
and this laser beam

1377
01:29:10,260 --> 01:29:12,630
going to be aimed through a

1378
01:29:12,650 --> 01:29:15,160
narrow slits make drawings

1379
01:29:15,210 --> 01:29:17,220
so in this light

1380
01:29:19,130 --> 01:29:20,150
that's it

1381
01:29:20,160 --> 01:29:21,730
which is a vertical slits

1382
01:29:21,760 --> 01:29:22,770
can be made

1383
01:29:22,820 --> 01:29:25,190
narrow and can be made

1384
01:29:28,040 --> 01:29:31,400
here is the sliding

1385
01:29:31,470 --> 01:29:33,640
and here

1386
01:29:33,660 --> 01:29:36,360
is is opening is split

1387
01:29:36,370 --> 01:29:40,150
it's only going to be confined in this direction on in this area

1388
01:29:40,200 --> 01:29:43,040
so the lights

1389
01:29:45,320 --> 01:29:47,970
come out here

1390
01:29:48,100 --> 01:29:51,100
and then on the screen which is going to be that screen

1391
01:29:51,110 --> 01:29:53,520
large distance capital l

1392
01:29:54,950 --> 01:29:55,780
we're going to

1393
01:29:55,790 --> 01:29:57,230
see that light spot

1394
01:29:57,240 --> 01:29:58,460
o two

1395
01:29:58,510 --> 01:30:00,800
the light beam going forward

1396
01:30:00,830 --> 01:30:03,570
this separation

1397
01:30:03,580 --> 01:30:07,080
happy file

1398
01:30:07,100 --> 01:30:08,610
i started off

1399
01:30:08,620 --> 01:30:10,940
with this little the

1400
01:30:11,000 --> 01:30:13,220
so you're going to see the light sport

1401
01:30:13,270 --> 01:30:15,350
like this

1402
01:30:15,480 --> 01:30:19,040
and then i'm going to make this let's never never

1403
01:30:19,050 --> 01:30:22,230
unless i'm going to cut into the lightly

1404
01:30:22,230 --> 01:30:25,390
we're going to see is exactly what you expect

1405
01:30:25,450 --> 01:30:28,210
you expect this line disappears

1406
01:30:28,290 --> 01:30:30,760
and when i can't even further

1407
01:30:30,810 --> 01:30:32,760
this is exactly what you expect

1408
01:30:32,760 --> 01:30:37,490
i've observed these two points x here on this point here

1409
01:30:38,450 --> 01:30:42,660
what are drawn as these lines are just samples of

1410
01:30:42,700 --> 01:30:46,520
lines that are consistent with the data so my posterior

1411
01:30:46,530 --> 01:30:48,770
probability over lines

1412
01:30:54,470 --> 01:30:55,620
it is

1413
01:30:55,630 --> 01:30:58,900
good look something like this

1414
01:30:58,970 --> 01:31:00,330
OK so

1415
01:31:00,410 --> 01:31:04,550
essentially what the data is done is eliminated all lines that are not consistent with

1416
01:31:04,550 --> 01:31:05,240
the the

1417
01:31:05,250 --> 01:31:06,590
observed data

1418
01:31:06,600 --> 01:31:07,750
and then

1419
01:31:08,550 --> 01:31:11,010
what you could do is you could compute just the

1420
01:31:11,290 --> 01:31:18,500
the mean of the mean line in this posterior distribution is called the bayes point

1421
01:31:19,190 --> 01:31:20,460
and that gives you

1422
01:31:20,480 --> 01:31:23,200
a reasonable estimate for your class boundary

1423
01:31:23,280 --> 01:31:26,650
but you have a lot more information here as well you have a kind of

1424
01:31:26,650 --> 01:31:31,130
uncertainty about your classes right the fans out like this

1425
01:31:31,180 --> 01:31:34,220
as you know this point here maybe it does belong to this class i don't

1426
01:31:34,220 --> 01:31:35,070
know maybe

1427
01:31:35,090 --> 01:31:38,470
if the class boundary look like that in this point will belong to the blue

1428
01:31:40,730 --> 01:31:46,350
and essentially if we have different kinds of data sets then are

1429
01:31:46,370 --> 01:31:50,300
distribution over lines which would look quite different

1430
01:31:51,150 --> 01:31:52,120
the main

1431
01:31:52,160 --> 01:31:54,660
the key idea is we have

1432
01:31:54,710 --> 01:31:57,800
in this approach to classification we have

1433
01:31:58,080 --> 01:32:01,650
we define a prior probability on our class boundaries

1434
01:32:01,730 --> 01:32:05,500
then we observe some data and we come up with the posterior probability of class

1435
01:32:08,270 --> 01:32:11,240
so that's very

1436
01:32:12,970 --> 01:32:15,190
easy to do that

1437
01:32:15,200 --> 01:32:17,340
and you can do this stuff

1438
01:32:17,380 --> 01:32:20,550
with kernel methods as well so this is just linear

1439
01:32:20,600 --> 01:32:24,340
linear classifiers you can have a prior

1440
01:32:24,350 --> 01:32:27,640
probability distribution of linear classifiers we can also have

1441
01:32:27,980 --> 01:32:32,440
the same thing in some high dimensional feature space

1442
01:32:32,460 --> 01:32:35,580
and that relates to calcium processes

1443
01:32:35,590 --> 01:32:37,840
which i can explain people interested

1444
01:32:38,130 --> 01:32:42,100
and if anyone here about gas prices

1445
01:32:47,290 --> 01:32:47,950
all right

1446
01:32:50,440 --> 01:32:54,010
let me give you some of the motivation behind as it crosses the gas in

1447
01:32:58,730 --> 01:33:05,320
categorized into the non there for nonparametric models so again here's some terminology we can

1448
01:33:05,320 --> 01:33:09,060
distinguish between parametric models and nonparametric models

1449
01:33:09,110 --> 01:33:14,810
in parametric models we have some finite fixed number of parameters theta

1450
01:33:14,820 --> 01:33:19,430
regardless of the size of the dataset the dimensionality of our parameter space is assumed

1451
01:33:19,430 --> 01:33:21,040
to be fixed

1452
01:33:21,700 --> 01:33:25,380
so that given theta the predictions are independent of the data that you got the

1453
01:33:25,380 --> 01:33:26,540
data from

1454
01:33:27,220 --> 01:33:29,590
so the probability of

1455
01:33:30,360 --> 01:33:34,200
data predictions x and theta

1456
01:33:35,860 --> 01:33:40,140
independent of the data that you actually got it from

1457
01:33:40,160 --> 01:33:44,320
so in a sense what this is the parameters are a finite summary of the

1458
01:33:45,580 --> 01:33:49,590
OK so we can also call this model based learning for example we have a

1459
01:33:49,590 --> 01:33:51,550
mixture of k gaussians

1460
01:33:51,600 --> 01:33:55,900
then when if k is fixed this is a model based you know once we

1461
01:33:55,900 --> 01:33:58,780
know this mixture of gaussians we don't care

1462
01:33:59,190 --> 01:34:03,340
if we know the parameters that make we don't care where this premise came from

1463
01:34:03,360 --> 01:34:05,340
if we send is it true

1464
01:34:05,390 --> 01:34:09,870
in nonparametric models

1465
01:34:10,050 --> 01:34:14,030
essentially what we're doing is we're allowing the number of parameters to grow with the

1466
01:34:14,030 --> 01:34:15,770
data set size

1467
01:34:15,820 --> 01:34:21,040
OK alternatively we can think of the predictions as depending on the dataset itself in

1468
01:34:21,040 --> 01:34:24,340
other words now we want to make predictions

1469
01:34:24,350 --> 01:34:26,580
we tend just throw away the data

1470
01:34:26,590 --> 01:34:29,900
we have to use that data to make those predictions

1471
01:34:31,690 --> 01:34:36,370
that is if we want to predict some input x the probability of where x

1472
01:34:36,370 --> 01:34:40,380
depends on the data explicitly and maybe a few

1473
01:34:40,410 --> 01:34:42,600
so-called hyperparameters

1474
01:34:42,650 --> 01:34:44,210
alpha as well

1475
01:34:44,220 --> 01:34:49,620
but the parameters alpha don't summarize everything about the data sort of additional things that

1476
01:34:49,620 --> 01:34:50,800
you're using

1477
01:34:50,830 --> 01:34:54,490
so we can also call this memory based learning so for example

1478
01:34:54,500 --> 01:34:59,630
kernel density estimation is a memory based learning that you know you put to death

1479
01:34:59,630 --> 01:35:02,180
scene kernel on each data point let's say in

1480
01:35:02,230 --> 01:35:05,970
that investment of your density

1481
01:35:10,350 --> 01:35:13,670
nonparametric bayesian methods

1482
01:35:13,720 --> 01:35:15,580
basically it as

1483
01:35:15,590 --> 01:35:18,580
you basically follows following line of thought

1484
01:35:18,590 --> 01:35:24,340
which is that the real world is complicated OK if we really want priors on

1485
01:35:24,340 --> 01:35:25,790
he was which we that

1486
01:35:25,790 --> 01:35:27,280
each image point

1487
01:35:27,410 --> 01:35:30,940
and then you use labelled you cycle through the labels was not ten labels and

1488
01:35:30,940 --> 01:35:33,470
say OK want to switch to one

1489
01:35:33,490 --> 01:35:37,380
so something which to what you say you want to switch to something

1490
01:35:37,380 --> 01:35:41,080
and three and four five and set train you keep going

1491
01:35:41,130 --> 01:35:45,430
one passed through the key passing through and if you go through a complete pass

1492
01:35:45,480 --> 01:35:48,950
no pixel wants to switch to any other label

1493
01:35:49,830 --> 01:35:51,150
you're not going to get any further

1494
01:35:51,160 --> 01:35:53,070
so that's you

1495
01:35:53,120 --> 01:35:56,930
that's the final solution

1496
01:35:59,160 --> 01:36:02,780
no it doesn't converge because

1497
01:36:02,870 --> 01:36:05,120
at each moment

1498
01:36:05,160 --> 01:36:09,780
only switch if it results in a decrease in the energy function

1499
01:36:11,580 --> 01:36:15,690
so you decrease the function of time

1500
01:36:15,890 --> 01:36:20,910
the general

1501
01:36:20,930 --> 01:36:23,350
you can definitely have local minima yes

1502
01:36:23,380 --> 01:36:24,550
if local

1503
01:36:24,560 --> 01:36:27,030
so going through so many times

1504
01:36:28,280 --> 01:36:30,840
the solution

1505
01:36:30,930 --> 01:36:33,030
there is initial solution

1506
01:36:33,060 --> 01:36:38,430
it doesn't apparently appeared to what might imagine our initial solution is not important

1507
01:36:38,510 --> 01:36:39,890
for each label

1508
01:36:39,890 --> 01:36:41,030
in random order

1509
01:36:41,060 --> 01:36:45,680
you compute the the optimal alpha expansion in other words you

1510
01:36:45,730 --> 01:36:47,140
you switch

1511
01:36:51,670 --> 01:36:54,280
which has the lowest energy subject to

1512
01:36:55,620 --> 01:36:57,050
only switch

1513
01:36:57,060 --> 01:36:58,120
two alpha

1514
01:36:58,160 --> 01:37:07,520
or remain the same right

1515
01:37:10,420 --> 01:37:13,150
maybe not

1516
01:37:17,300 --> 01:37:18,120
could be

1517
01:37:19,300 --> 01:37:21,020
if you look at that way

1518
01:37:21,070 --> 01:37:27,030
now the important thing is when will this

1519
01:37:27,080 --> 01:37:30,850
there are two questions here really

1520
01:37:31,530 --> 01:37:32,640
two questions

1521
01:37:34,440 --> 01:37:37,140
do you get a good solution out of this

1522
01:37:37,180 --> 01:37:39,070
and secondly

1523
01:37:39,110 --> 01:37:43,480
when can you efficiently solve each of these binary problems it is the step the

1524
01:37:43,490 --> 01:37:45,170
binary problem

1525
01:37:45,200 --> 01:37:48,390
binary problem is each pixel has the choice to switch

1526
01:37:48,430 --> 01:37:50,670
well for what i say the same

1527
01:37:51,350 --> 01:37:54,030
binary choice and so that's where it becomes

1528
01:37:54,050 --> 01:37:57,650
just the binary problem and you solve using usual

1529
01:37:57,670 --> 01:37:59,910
graph cuts techniques

1530
01:38:01,200 --> 01:38:05,570
to answer the first question does work

1531
01:38:05,670 --> 01:38:07,030
the answer is

1532
01:38:07,120 --> 01:38:09,510
yes it works pretty well

1533
01:38:09,570 --> 01:38:12,000
right empirically

1534
01:38:12,070 --> 01:38:15,280
the second answers mathematical answer

1535
01:38:15,320 --> 01:38:16,360
and that is

1536
01:38:16,370 --> 01:38:18,810
that is guaranteed

1537
01:38:19,380 --> 01:38:23,270
get within some fixed bound on the absolute

1538
01:38:23,330 --> 01:38:28,080
that's the cost and here's the potts model versus it gives you

1539
01:38:30,450 --> 01:38:34,300
today different parts model then you always get

1540
01:38:39,740 --> 01:38:40,820
maximum engine

1541
01:38:40,820 --> 01:38:42,610
the problem with that

1542
01:38:42,620 --> 01:38:44,130
rather better

1543
01:38:44,320 --> 01:38:48,160
so there's a mathematical bound is currently it seems to work well

1544
01:38:48,170 --> 01:38:51,900
so the other question is

1545
01:38:52,670 --> 01:38:54,880
to look

1546
01:38:54,890 --> 01:38:56,820
this is the this is the

1547
01:38:58,150 --> 01:38:59,660
and the which

1548
01:38:59,710 --> 01:39:00,760
it will work

1549
01:39:02,170 --> 01:39:05,400
article about that in a moment

1550
01:39:05,440 --> 01:39:08,400
the a this is the

1551
01:39:08,400 --> 01:39:11,330
function for the individual cliques of size two

1552
01:39:11,430 --> 01:39:13,820
the functions of two variables right

1553
01:39:13,860 --> 01:39:16,300
and functions are two labels

1554
01:39:16,310 --> 01:39:22,020
and the if the two labels the same you can always arrange zero

1555
01:39:22,160 --> 01:39:26,710
so the a b grade and recalls i don't actually think that

1556
01:39:26,730 --> 01:39:28,530
necessary condition

1557
01:39:28,550 --> 01:39:31,250
he said cities and second for

1558
01:39:31,270 --> 01:39:32,320
we have this

1559
01:39:32,320 --> 01:39:37,230
the IB is necessary to be a sleeper PCB

1560
01:39:37,260 --> 01:39:40,590
right which looks like the triangle inequality

1561
01:39:40,630 --> 01:39:43,880
triangle inequality which means you know the distance

1562
01:39:43,920 --> 01:39:47,080
triangle inequality

1563
01:39:47,150 --> 01:39:49,150
the distance

1564
01:39:49,170 --> 01:39:51,240
from a to b

1565
01:39:51,340 --> 01:39:54,130
list distance you take the two vice

1566
01:39:56,940 --> 01:39:59,830
if that conditional examined condition just a bit

1567
01:40:00,850 --> 01:40:05,080
the conditions hold then you can solve each of these problems

1568
01:40:06,370 --> 01:40:07,930
this examples

1569
01:40:07,960 --> 01:40:11,480
you can solve each of these problems

1570
01:40:13,100 --> 01:40:14,110
the model

1571
01:40:14,120 --> 01:40:17,130
you rather good segmentation

1572
01:40:17,140 --> 01:40:19,360
in this case truncated

1573
01:40:33,330 --> 01:40:37,830
well the noise is the fact that it's the edge weights which had always zero

1574
01:40:37,830 --> 01:40:42,110
and we're not trying to situations which analyse the edge weights are

1575
01:40:42,170 --> 01:40:46,760
for the so called regularisation to this sort of trying to mitigate

1576
01:40:46,780 --> 01:40:47,700
the effect

1577
01:40:47,710 --> 01:40:48,850
the noise

1578
01:40:48,850 --> 01:40:50,090
by saying

1579
01:40:51,050 --> 01:40:52,740
there is some expectations

1580
01:40:52,760 --> 01:40:54,930
of the relationship of

1581
01:40:54,980 --> 01:40:57,590
all pixels which next to each other whole

1582
01:40:57,600 --> 01:41:01,570
do about you don't have to be a weights then get very noisy with the

1583
01:41:01,570 --> 01:41:03,000
edge weights

1584
01:41:03,150 --> 01:41:06,240
don't you don't expect to get

1585
01:41:06,870 --> 01:41:09,310
zero cost

1586
01:41:09,380 --> 01:41:13,690
this would be a non-zero cost of

1587
01:41:14,720 --> 01:41:17,170
and in fact

1588
01:41:18,430 --> 01:41:21,100
that's that's all i can say about this really

1589
01:41:21,130 --> 01:41:22,750
the seven look at

1590
01:41:22,840 --> 01:41:28,490
this again

1591
01:41:28,580 --> 01:41:34,230
there's another article see simulated annealing which is being suggested that that's what the game

1592
01:41:34,230 --> 01:41:36,070
is game in paper which i

1593
01:41:37,020 --> 01:41:38,720
is about

1594
01:41:38,720 --> 01:41:43,270
so thanks very much for inviting me to come here and talk about what might

1595
01:41:43,270 --> 01:41:46,830
not seem to sound too much related to memory

1596
01:41:46,860 --> 01:41:49,830
can you understand me

1597
01:41:51,910 --> 01:41:54,620
i can't tell you so

1598
01:41:54,690 --> 01:41:56,300
i'll start off

1599
01:41:56,310 --> 01:41:58,280
by showing you a little

1600
01:41:59,210 --> 01:42:01,010
and the movie i'm going to show you

1601
01:42:01,030 --> 01:42:04,550
i don't normally show it when i give scientific presentations

1602
01:42:04,580 --> 01:42:09,410
but i think because this is the last talk i thought everybody could enjoy something

1603
01:42:09,410 --> 01:42:14,260
a little bit relaxing so i thought we'd starts by this beautiful scenes

1604
01:42:14,320 --> 01:42:16,400
from the movie future world

1605
01:42:16,410 --> 01:42:21,200
i don't know if anyone have you seen this movie but it basically it's it's

1606
01:42:21,300 --> 01:42:25,800
very nice film

1607
01:42:27,730 --> 01:42:30,080
fort reading device

1608
01:42:30,110 --> 01:42:33,840
and there's basically there is the need to know too much about the story there

1609
01:42:33,840 --> 01:42:35,050
is the bad guy

1610
01:42:35,070 --> 01:42:39,870
and the the two good guys the two reporters and she's going to go into

1611
01:42:39,870 --> 01:42:46,100
this fantastic mind-reading device that this guy here is built and he's gonna look at

1612
01:42:46,100 --> 01:42:49,370
her dreams and she is a little bit skeptical about what you might be dreaming

1613
01:42:49,370 --> 01:42:53,210
in this guy of course is quite eager to find out what she's thinking what

1614
01:42:53,210 --> 01:42:54,210
you can see

1615
01:42:54,260 --> 01:42:58,850
it's quite nice because what you're going to see is a mind-reading machine which looks

1616
01:42:58,850 --> 01:43:03,120
like the current state of the art images system but this film is for thirty

1617
01:43:03,120 --> 01:43:05,940
years old

1618
01:43:06,010 --> 01:43:08,460
the second thing is you're going to see

1619
01:43:08,490 --> 01:43:11,580
nice statement that the thoughts

1620
01:43:11,600 --> 01:43:17,540
are generated by superposition of a large number of independent brainwaves and you'll see a

1621
01:43:17,540 --> 01:43:20,630
nice rendition on on the screen

1622
01:43:20,660 --> 01:43:26,430
and then you also see the introduction of emotional states because one of the workers

1623
01:43:26,430 --> 01:43:30,470
is going to ramp up the pain pleasure gradient and then you can see what

1624
01:43:30,470 --> 01:43:32,020
happens if people do that

1625
01:43:32,040 --> 01:43:38,410
so i'll start this very short sequences just two-and-a-half minutes

1626
01:43:50,110 --> 01:44:22,100
she never trust journalists you know

1627
01:45:27,280 --> 01:45:37,640
i i i i i i

1628
01:46:01,420 --> 01:46:03,780
i guess you get the picture

1629
01:46:03,830 --> 01:46:09,540
so this is i just showed this at the beginning because the research talk about

1630
01:46:10,360 --> 01:46:16,900
it is related to the decoding of mental states from

1631
01:46:23,850 --> 01:46:26,600
actually it's quite interesting because in that movie

1632
01:46:26,610 --> 01:46:30,980
this machine doesn't play any role really they just go there is the new about

1633
01:46:30,980 --> 01:46:34,350
something completely different and i guess they thought it it would be cool to have

1634
01:46:34,350 --> 01:46:40,200
such a machine and then they build as the three-minute sequence in that city at

1635
01:46:40,230 --> 01:46:45,610
the and but she actually has a very nice dream afterwards where she dreams about

1636
01:46:45,610 --> 01:46:49,770
your bring their fantasy lover in great detail and i did i didn't want to

1637
01:46:49,770 --> 01:46:52,050
put that up here because i'm not sure

1638
01:46:52,080 --> 01:46:55,330
if somewhat and all this kind of stuff you appear not to show this kind

1639
01:46:55,330 --> 01:47:00,330
of rousing seen so i decided against that

1640
01:47:00,340 --> 01:47:04,210
so obviously what i'm going to be talking about

1641
01:47:04,220 --> 01:47:10,120
is so our research uses multivariate decoding and pattern recognition techniques

1642
01:47:10,140 --> 01:47:15,970
and applies them to brain imaging data specifically FMRI data but also EEG data

1643
01:47:18,640 --> 01:47:22,790
one thing you can do that is you can trying to decode mental states for

1644
01:47:22,810 --> 01:47:27,620
for example technical applications you can try and build lie detectors find out if someone

1645
01:47:27,620 --> 01:47:29,220
has been at the crime scene

1646
01:47:29,230 --> 01:47:32,100
and so on but a different thing you can do with it and that's actually

1647
01:47:32,100 --> 01:47:39,290
more interesting is you can try and ask specific cognitive neuroscience questions related to the

1648
01:47:39,290 --> 01:47:43,900
encoding of specific representations in the brain because conventionally

1649
01:47:43,910 --> 01:47:45,490
from my research

1650
01:47:45,500 --> 01:47:49,580
is and i think that's why i was quite nice to have this point reyes

1651
01:47:49,580 --> 01:47:50,970
also yesterday

1652
01:47:50,980 --> 01:47:55,290
from my research is often you talk about the whole brain areas active or not

1653
01:47:56,230 --> 01:48:02,410
and this is not very revealing about the mechanisms of processing that's happening in brain

1654
01:48:02,410 --> 01:48:06,740
areas and instead what these techniques allow you to do is to really look at

1655
01:48:06,740 --> 01:48:12,150
the information stored in the brain area and how this information changes under different task

1656
01:48:12,150 --> 01:48:14,550
conditions and also

1657
01:48:14,580 --> 01:48:19,580
we can help you to find out where representations for specific contents are stored in

1658
01:48:19,580 --> 01:48:22,990
the brain for example in cases where not really known for example as what i'm

1659
01:48:22,990 --> 01:48:25,700
going to talk about today is how

1660
01:48:25,710 --> 01:48:29,970
our intentions are coded in the brain which is something that people

1661
01:48:29,980 --> 01:48:33,960
i do know about especially when kind motor intentions but if you kind of look

1662
01:48:33,960 --> 01:48:38,270
there are some models around in the bayesian nonparametric literature which are actually not in

1663
01:48:38,270 --> 01:48:39,860
this class is so for example there's

1664
01:48:42,000 --> 01:48:46,840
in the nineteen seventies after the process was first introduced people try to come up with generalizations

1665
01:48:47,530 --> 01:48:49,790
along several lines and one of them is something called

1666
01:48:50,270 --> 01:48:52,260
neutral to the right process which is some

1667
01:48:52,650 --> 01:48:54,070
form of levy process essentially

1668
01:48:55,820 --> 01:48:56,600
i'm not going to

1669
01:48:58,010 --> 01:49:00,230
to tell you exactly what that is but it's basically

1670
01:49:00,750 --> 01:49:05,420
it's a class of models which contains the process special cases has some nice properties

1671
01:49:05,890 --> 01:49:09,000
and one thing you can show about it is that its conjugate in the sense that

1672
01:49:09,410 --> 01:49:14,030
if you take the posterior of neutral to the right process again a neutral to the right process

1673
01:49:15,220 --> 01:49:15,800
but it is not

1674
01:49:16,320 --> 01:49:17,760
conjugate in the sense so

1675
01:49:18,400 --> 01:49:21,260
we do it so you should write process but you don't know which one

1676
01:49:22,710 --> 01:49:25,710
and you need to find some other way to to to figure that out

1677
01:49:26,660 --> 01:49:27,680
so that's not very useful

1678
01:49:29,520 --> 01:49:33,610
okay so what we need is this we need basically we need to construct models

1679
01:49:33,610 --> 01:49:37,310
that have this kind of this kind of conjugacy and then we don't need a

1680
01:49:37,310 --> 01:49:37,820
basic wage

1681
01:49:39,400 --> 01:49:43,060
that's not say that this is the only way that we can possibly substitute for

1682
01:49:43,080 --> 01:49:44,700
basic creation that many many others

1683
01:49:45,310 --> 01:49:47,840
but this is the only one pretty much the only one

1684
01:49:49,030 --> 01:49:50,910
the analytically is that i know about

1685
01:49:51,350 --> 01:49:54,030
and that's in any way used in the nonparametric bayesian literature

1686
01:49:55,810 --> 01:49:56,240
okay so

1687
01:49:56,860 --> 01:49:57,800
when we construct

1688
01:49:58,550 --> 01:50:01,230
on nonparametric bayesian models can we basically have to

1689
01:50:01,630 --> 01:50:04,440
try and make sure that they are conjugate how can we do that well if we

1690
01:50:04,950 --> 01:50:05,660
one thing is we

1691
01:50:06,070 --> 01:50:09,990
we are we using components right we use here a bit i reckon models for example

1692
01:50:10,510 --> 01:50:11,520
and in that case if we

1693
01:50:12,380 --> 01:50:12,990
if we use

1694
01:50:14,070 --> 01:50:15,820
if we use models that already are cont

1695
01:50:16,790 --> 01:50:20,420
then we can handle the individual layers of the hierarchy and then we do keep sampling

1696
01:50:22,410 --> 01:50:22,980
so basically

1697
01:50:23,560 --> 01:50:24,000
the way to

1698
01:50:24,500 --> 01:50:25,800
to get this to get

1699
01:50:27,420 --> 01:50:29,390
utilizes and hierarchical models is

1700
01:50:30,310 --> 01:50:32,350
use components which have this property

1701
01:50:35,290 --> 01:50:39,410
it's also possible to show that that if you use these constructions that i showed

1702
01:50:39,410 --> 01:50:43,650
you before this project linear constructions that are used for the girls process process over

1703
01:50:43,650 --> 01:50:44,870
the last half hour and

1704
01:50:45,580 --> 01:50:46,240
that if you use

1705
01:50:46,630 --> 01:50:48,100
marginals which are conjugate

1706
01:50:49,080 --> 01:50:49,980
which have this property

1707
01:50:50,790 --> 01:50:52,630
then under under suitable conditions

1708
01:50:53,130 --> 01:50:54,980
the model that you get out is again conjugate

1709
01:50:55,650 --> 01:50:59,600
so in that sense the dirichlet process conjugate because the dirichlet distribution

1710
01:51:00,980 --> 01:51:01,580
its conjugate

1711
01:51:02,110 --> 01:51:05,620
now and the girls and processes contribute because the girls in distribution is conjugate

1712
01:51:06,510 --> 01:51:07,410
and since conjugacy

1713
01:51:08,040 --> 01:51:11,070
in parametric models like the directly in the gas in distribution

1714
01:51:11,740 --> 01:51:15,880
is something that occurs up to some borderline cases only an exponential families

1715
01:51:16,480 --> 01:51:17,550
you have a rough rule of thumb

1716
01:51:19,550 --> 01:51:21,000
models which has this property

1717
01:51:23,840 --> 01:51:26,560
one is that you can get this projective limits

1718
01:51:27,180 --> 01:51:29,020
of exponential family models

1719
01:51:31,590 --> 01:51:32,510
like the girl selected

1720
01:51:37,840 --> 01:51:38,270
so much

1721
01:51:38,860 --> 01:51:40,300
before the representation problem

1722
01:51:40,950 --> 01:51:41,570
and time

1723
01:51:42,350 --> 01:51:43,340
now the young

1724
01:51:43,940 --> 01:51:46,810
the final thing that i would like to talk about in the context of how

1725
01:51:46,820 --> 01:51:49,940
we can construct models as exchangeability once again

1726
01:51:51,930 --> 01:51:55,270
i'm just going to quickly review the two slides on exchangeability de

1727
01:51:55,820 --> 01:51:56,540
showed yesterday

1728
01:51:57,450 --> 01:51:59,620
but the real question here is if we

1729
01:52:00,730 --> 01:52:01,940
if you want to build a model on

1730
01:52:02,570 --> 01:52:05,170
four four data that doesn't come as a sequence

1731
01:52:05,880 --> 01:52:06,550
then what can we do

1732
01:52:07,110 --> 01:52:07,620
and what

1733
01:52:08,430 --> 01:52:11,060
what can be used as a substitute for exchangeable sequences

1734
01:52:15,750 --> 01:52:16,430
quick reminder

1735
01:52:18,820 --> 01:52:25,330
exchangeability room from recall that exchangeability was what we the kind of property that we used to characterize

1736
01:52:25,980 --> 01:52:29,200
the case where we can make this assumption here that the data that we see

1737
01:52:29,790 --> 01:52:33,700
is decomposed into a pattern ant ant independent noise

1738
01:52:35,630 --> 01:52:37,470
so the pattern was our parameter

1739
01:52:37,960 --> 01:52:39,270
and independent noise is

1740
01:52:41,100 --> 01:52:44,580
basically given by the likelihood given the parameter value how does the data in this

1741
01:52:44,580 --> 01:52:47,800
case scatter around the parameter which is the red line

1742
01:52:50,550 --> 01:52:54,380
i told you that if we if we have this exchangeability property so if the

1743
01:52:54,380 --> 01:52:56,090
order in which the data comes in

1744
01:52:57,150 --> 01:52:58,620
doesn't change its distribution

1745
01:52:59,160 --> 01:53:00,410
doesn't change its probability

1746
01:53:01,140 --> 01:53:02,480
he orders relevant then

1747
01:53:03,410 --> 01:53:04,950
we have this property and it it

1748
01:53:05,330 --> 01:53:05,850
i am

1749
01:53:06,440 --> 01:53:07,050
i should do this

1750
01:53:08,480 --> 01:53:13,510
this integral representation you definitive theorem which expresses exactly this conditional independence right

1751
01:53:13,910 --> 01:53:14,260
this is

1752
01:53:15,030 --> 01:53:21,210
in the context of mixture models we also saw yesterday that mixtures are stage sampling procedures right

1753
01:53:21,890 --> 01:53:23,640
first sample from the mixing measure

1754
01:53:24,270 --> 01:53:27,570
and then sample from the component this is exactly what you see in on in

1755
01:53:27,570 --> 01:53:29,080
this case the mixing matrix a prior

1756
01:53:29,900 --> 01:53:31,830
and and then the component is

1757
01:53:32,340 --> 01:53:34,890
this distribution of an infinite i i d equals

1758
01:53:39,040 --> 01:53:40,130
so you can you can

1759
01:53:40,770 --> 01:53:41,640
in the sense you can

1760
01:53:42,200 --> 01:53:42,870
interpret all

1761
01:53:43,670 --> 01:53:48,120
bayesian models at some form some form of mixture you can also see your can

1762
01:53:48,120 --> 01:53:52,570
also regards hierarchies that i showed you earlier this is repeated mixing few well yeah

1763
01:53:53,670 --> 01:53:54,680
from a technical perspective

1764
01:53:56,540 --> 01:53:58,220
but really the important bit is

1765
01:53:58,730 --> 01:53:59,090
we have

1766
01:53:59,510 --> 01:54:00,750
invariance property

1767
01:54:02,200 --> 01:54:03,130
which is this this

1768
01:54:04,280 --> 01:54:07,240
invariance of the probability of the data under permutations

1769
01:54:07,760 --> 01:54:11,240
and that gives us the conditional independence property

1770
01:54:16,620 --> 01:54:20,150
i'm not going to show you two examples of where we get this kind of

1771
01:54:20,280 --> 01:54:22,140
where we have this kind of principle we also have

1772
01:54:23,070 --> 01:54:26,190
invariance property on kind of permutation invariant property

1773
01:54:26,810 --> 01:54:31,000
and you get quite a form of some form of conditional independence property that we

1774
01:54:31,000 --> 01:54:33,450
can use the bayes models but the data is

1775
01:54:33,960 --> 01:54:34,730
is now more

1776
01:54:35,970 --> 01:54:38,110
more sophisticated random object and

1777
01:54:38,750 --> 01:54:39,850
and the first one is

1778
01:54:40,540 --> 01:54:41,930
the case where we really have

1779
01:54:42,900 --> 01:54:46,820
random partitions so that's something only already mentioned briefly yesterday

1780
01:54:47,380 --> 01:54:48,730
if we have a random partition

1781
01:54:49,320 --> 01:54:52,810
in which case can we assume that the random partition comes from a discrete random

1782
01:54:52,810 --> 01:54:57,540
error right the whole set up we looked at yesterday clustering was we generate discrete

1783
01:54:57,540 --> 01:54:58,050
random measure

1784
01:54:58,530 --> 01:55:01,860
using as mixing distribution and a mixture and then sample or data from the

1785
01:55:02,290 --> 01:55:04,510
and that's how we explain how the clustered data

1786
01:55:05,150 --> 01:55:05,870
is generated

1787
01:55:06,370 --> 01:55:08,460
in what cases can we assume that that's really true

1788
01:55:14,580 --> 01:55:20,190
the result which addresses this is something called commenced theorems looking theorem is the random partition version of

1789
01:55:22,400 --> 01:55:24,890
and you objects that are involved here are the following

1790
01:55:25,400 --> 01:55:25,810
we need to

1791
01:55:27,280 --> 01:55:29,820
remember in indefinitely theorem i told you that this

1792
01:55:30,390 --> 01:55:32,110
this random object that we draw here

1793
01:55:33,320 --> 01:55:36,270
that's a probability measure right we have a random probability measure

1794
01:55:36,760 --> 01:55:37,540
we fix that measure

1795
01:55:38,260 --> 01:55:40,140
and then we sample i i d e from that measure

1796
01:55:42,250 --> 01:55:42,830
and now here

1797
01:55:43,600 --> 01:55:44,680
the random object is

1798
01:55:46,650 --> 01:55:47,800
of the unit in terms

1799
01:55:49,000 --> 01:55:52,010
and what is is if you think of the discrete random measure this

1800
01:55:53,130 --> 01:55:57,360
these late the length of these intervals here these are exactly the weights

1801
01:55:57,360 --> 01:56:00,030
OK that gives it way too

1802
01:56:00,050 --> 01:56:05,160
do policy improvement given the current values how you had improve

1803
01:56:05,240 --> 01:56:07,270
the policy

1804
01:56:07,290 --> 01:56:08,500
get policy

1805
01:56:09,150 --> 01:56:12,030
so now we get to what's called monte carlo control

1806
01:56:12,050 --> 01:56:13,310
there lower than

1807
01:56:13,320 --> 01:56:17,860
it with and policy pi you're evaluating q pi

1808
01:56:18,000 --> 01:56:19,330
thank you

1809
01:56:19,390 --> 01:56:21,270
from q you can determine

1810
01:56:21,410 --> 01:56:23,570
for improved policy

1811
01:56:23,580 --> 01:56:25,950
five q

1812
01:56:25,950 --> 01:56:27,450
or a and he

1813
01:56:27,500 --> 01:56:29,460
here they called the greedy policy

1814
01:56:29,470 --> 01:56:33,890
so do the really was respect with with you q

1815
01:56:33,980 --> 01:56:35,230
the new

1816
01:56:35,350 --> 01:56:41,100
and iterate this process is just like policy iteration except that the policy evaluation from

1817
01:56:41,100 --> 01:56:43,900
sampling not from solving linear systems

1818
01:56:43,910 --> 01:56:45,950
the only difference

1819
01:56:47,000 --> 01:56:50,170
under certain conditions again this will converge

1820
01:56:50,170 --> 01:56:54,240
with enough samples for policy violations at each step this will converge to the optimal

1821
01:56:54,240 --> 01:56:58,700
policy so now you can find policy blackjack it's kind of cool

1822
01:56:58,750 --> 01:57:01,980
just without knowing transition function

1823
01:57:02,000 --> 01:57:04,080
generally find the policy

1824
01:57:04,170 --> 01:57:06,180
in any in p

1825
01:57:06,190 --> 01:57:11,380
without knowing it and the transition or reward for doing this method

1826
01:57:11,430 --> 01:57:14,480
and because taught generalized policy iteration

1827
01:57:14,490 --> 01:57:19,930
so the generalized form of what we saw earlier from obvious solution

1828
01:57:19,980 --> 01:57:23,580
OK it converges at all you need to know

1829
01:57:25,670 --> 01:57:28,280
OK now this is interesting

1830
01:57:28,300 --> 01:57:31,310
you may not want to go to casino

1831
01:57:31,360 --> 01:57:33,790
new samples from your casino

1832
01:57:33,830 --> 01:57:35,470
to learn

1833
01:57:35,470 --> 01:57:36,650
OK because

1834
01:57:36,760 --> 01:57:42,590
here's one issue with with with reinforced learning you need to know USA

1835
01:57:42,690 --> 01:57:48,000
which means you need to know accurate estimates for all actions from all states

1836
01:57:48,020 --> 01:57:51,390
OK if you want to guarantee convergence to the optimal policy

1837
01:57:51,390 --> 01:57:54,760
OK so i because you know you know

1838
01:57:54,820 --> 01:57:57,240
and i'm you know i'm

1839
01:57:57,280 --> 01:57:58,740
i've got the value

1840
01:58:00,390 --> 01:58:05,070
you know playing blackjack and i i've got my card three

1841
01:58:05,090 --> 01:58:07,080
and i say stay

1842
01:58:07,130 --> 01:58:10,140
because i got to sample that actually from that state in order to know what

1843
01:58:10,140 --> 01:58:11,250
value it is

1844
01:58:11,270 --> 01:58:13,690
OK clearly and it was a lot of money

1845
01:58:13,700 --> 01:58:16,310
if i try to learn blackjack because you know

1846
01:58:16,360 --> 01:58:17,990
so the interesting so

1847
01:58:18,440 --> 01:58:21,130
if you can simulate of programs

1848
01:58:21,190 --> 01:58:25,000
on the computer then of course experiences for users

1849
01:58:25,110 --> 01:58:28,990
theory compete which were lost that's fine but if you have to act in the

1850
01:58:29,950 --> 01:58:33,780
then you're exploration has to be

1851
01:58:34,010 --> 01:58:38,810
a bit more

1852
01:58:41,560 --> 01:58:44,650
that is still simple active most days but

1853
01:58:45,500 --> 01:58:47,320
you may want use prior knowledge

1854
01:58:47,440 --> 01:58:52,010
you may lists i'll show you some tricks are going show you know in a

1855
01:58:52,010 --> 01:58:53,660
later lecture

1856
01:58:53,660 --> 01:58:56,180
i think in the next lecture

1857
01:58:56,240 --> 01:59:00,610
which is realized you had two exploration here you have to explore all actors from

1858
01:59:00,610 --> 01:59:06,410
all states if you want to get convergence

1859
01:59:08,720 --> 01:59:10,560
so for example here

1860
01:59:10,670 --> 01:59:13,410
how how they how they guaranteed

1861
01:59:13,500 --> 01:59:19,960
convergence where they started with the random state and action in policy pi

1862
01:59:20,980 --> 01:59:23,750
so a course you can't go into blackjack table and say

1863
01:59:23,770 --> 01:59:26,900
starting was eleven story twenty one

1864
01:59:26,940 --> 01:59:32,450
you know by OK but on in tintin in simulation you can do this

1865
01:59:32,450 --> 01:59:36,460
so now from now i will do things that no economist

1866
01:59:36,470 --> 01:59:37,450
a new

1867
01:59:37,450 --> 01:59:43,820
any degree of self-respect will pay any attention to probably by which history physicist get

1868
01:59:44,700 --> 01:59:46,160
so what do we get off

1869
01:59:46,170 --> 01:59:51,190
we often data by now you know that so the first cloned the first step

1870
01:59:51,200 --> 01:59:53,670
is to get data i was

1871
01:59:53,680 --> 01:59:58,710
and leaving out some early work are much of the work here

1872
01:59:58,750 --> 02:00:00,520
it really took off

1873
02:00:00,530 --> 02:00:05,130
when when we got under cover of night from MIT

1874
02:00:05,190 --> 02:00:07,020
which is the ricci university

1875
02:00:07,030 --> 02:00:13,050
i did a database that was so huge that we had to research our university

1876
02:00:13,070 --> 02:00:18,990
to increase in this space just to hold of these and what it is is

1877
02:00:18,990 --> 02:00:21,900
a database that contains every tree

1878
02:00:21,910 --> 02:00:26,090
again this is something economists were never or even thing to do to analyse the

1879
02:00:26,090 --> 02:00:28,020
material i would you want to do that

1880
02:00:28,110 --> 02:00:33,190
to analyse a given sector may be given company to understand that one company why

1881
02:00:33,190 --> 02:00:37,880
analyse every trait but you know in particle physics we

1882
02:00:37,900 --> 02:00:41,990
keep keeper took the molecules apart to get out of his hands apart to get

1883
02:00:41,990 --> 02:00:44,520
nuclear and thereby walks

1884
02:00:44,540 --> 02:00:46,550
so this is the equivalent

1885
02:00:46,560 --> 02:00:49,570
sort of going as low as you can get

1886
02:00:49,580 --> 02:00:54,100
which is every time street and and then

1887
02:00:54,110 --> 02:00:59,150
there's this concept a so-called universality in quotes

1888
02:00:59,170 --> 02:01:03,860
which means that one market could be like another market one time period could be

1889
02:01:03,860 --> 02:01:05,460
like another time period

1890
02:01:08,130 --> 02:01:11,720
and to do this some other databases had to be analysed

1891
02:01:11,790 --> 02:01:14,870
OK what what comes out of moving right along now

1892
02:01:14,940 --> 02:01:18,300
is a graph which i find exciting

1893
02:01:18,340 --> 02:01:22,060
but what i emphasise has its serious flaws

1894
02:01:22,100 --> 02:01:25,530
what is the first of all it's a log log plot one

1895
02:01:25,690 --> 02:01:31,720
local applied every child learns to laugh because everything is straight on log log

1896
02:01:31,730 --> 02:01:37,200
but so it's very hard to persuade an economist even look at the log log

1897
02:01:38,220 --> 02:01:42,780
one economist and his referee report when we tried to get into the top economic

1898
02:01:42,780 --> 02:01:46,630
journal said that if we took out all the figures

1899
02:01:46,650 --> 02:01:49,230
and replace them by

1900
02:01:49,290 --> 02:01:53,900
maximum likelihood estimates things that came out of statistics books

1901
02:01:53,920 --> 02:01:57,990
and then you might be willing to referee the paper again but not until

1902
02:01:58,020 --> 02:02:01,110
so what is this this is a log log plot

1903
02:02:01,120 --> 02:02:05,590
and on the x axis has exactly what we're looking at a minute ago the

1904
02:02:05,610 --> 02:02:09,870
price returns remember we look to the point twenty ten and

1905
02:02:11,070 --> 02:02:15,870
so three of these dots we are looked at for stock average except now this

1906
02:02:15,870 --> 02:02:18,490
is not to stock averages every tree

1907
02:02:18,550 --> 02:02:21,780
two hundred million trees you treat

1908
02:02:21,800 --> 02:02:27,190
y two hundred million because the data are straight line with the relatively big slow

1909
02:02:27,300 --> 02:02:28,500
of three

1910
02:02:28,580 --> 02:02:31,600
and that means events out here

1911
02:02:31,660 --> 02:02:36,610
since the slope is three and the one hundred standard deviations the events out here

1912
02:02:36,920 --> 02:02:38,770
i ten to the

1913
02:02:38,780 --> 02:02:40,740
times more rare

1914
02:02:40,780 --> 02:02:44,070
ten to the eighth because this is the cumulative distribution if you look at the

1915
02:02:44,070 --> 02:02:50,820
PDF you differentiate one so x minus three for canada becomes x minus four for

1916
02:02:50,820 --> 02:02:51,910
the pedia

1917
02:02:51,980 --> 02:02:56,850
and x minus four with two decades here becomes a decade here so these events

1918
02:02:56,850 --> 02:03:00,990
are eight times more rare and that's why you need so many data you need

1919
02:03:00,990 --> 02:03:04,280
two hundred million data going to see rare events

1920
02:03:04,300 --> 02:03:09,990
and what they show is to my mind the most striking thing i i was

1921
02:03:10,320 --> 02:03:11,830
obviously didn't believe this

1922
02:03:11,880 --> 02:03:16,780
it shows that whatever is going on out here these very rare events

1923
02:03:16,780 --> 02:03:22,140
it is the same thing that's going on everywhere there is one fundamental scale free

1924
02:03:23,350 --> 02:03:27,410
they are not different laws there is that one regime here for everyday events in

1925
02:03:27,410 --> 02:03:32,340
one regime here now today this was done some time ago but today this is

1926
02:03:32,340 --> 02:03:38,770
less less surprising but it still is surprising in sociology for example in stockholm frederik


1
00:00:00,000 --> 00:00:04,190
sorry just over the three and have stopped short this what mean

2
00:00:04,210 --> 00:00:07,920
three point seven five just

3
00:00:07,980 --> 00:00:11,920
now i will cocktail you

4
00:00:11,940 --> 00:00:14,610
two and four

5
00:00:14,630 --> 00:00:17,750
cocktail two in four

6
00:00:17,840 --> 00:00:20,860
this appointment standstill

7
00:00:20,960 --> 00:00:22,300
this of course

8
00:00:22,360 --> 00:00:25,340
going to be starting up this will start up because i give them both the

9
00:00:25,340 --> 00:00:28,190
same amplitude i will not go to close to now

10
00:00:28,280 --> 00:00:31,230
i'll make it was one of the ways to get

11
00:00:31,280 --> 00:00:33,980
two large values and it becomes

12
00:00:33,980 --> 00:00:36,270
a little bit unrealistic

13
00:00:36,270 --> 00:00:40,130
what you see there so i'm going to give number two one

14
00:00:40,150 --> 00:00:43,190
and two and then going to give number

15
00:00:43,230 --> 00:00:44,880
five zero

16
00:00:44,980 --> 00:00:47,440
number four also won

17
00:00:47,500 --> 00:00:50,250
and already going to be to see that

18
00:00:50,300 --> 00:00:52,960
the motion is going to see becomes already sort of

19
00:00:52,980 --> 00:00:54,750
a little bit chaotic little

20
00:00:54,770 --> 00:00:57,360
ready to position now

21
00:00:57,360 --> 00:00:59,340
two normal modes

22
00:00:59,400 --> 00:01:02,230
this one which i start off a one here

23
00:01:02,270 --> 00:01:06,750
and this one which i started one here and it equal zero released both with

24
00:01:06,750 --> 00:01:09,040
zero speed

25
00:01:09,130 --> 00:01:10,340
one the

26
00:01:10,340 --> 00:01:11,320
yes i do

27
00:01:17,170 --> 00:01:21,150
this motion is already not so

28
00:01:21,210 --> 00:01:22,670
it still

29
00:01:22,690 --> 00:01:23,650
sort of

30
00:01:23,670 --> 00:01:28,320
symmetric for all these reasons because this one

31
00:01:28,360 --> 00:01:29,800
now what i want to do

32
00:01:29,840 --> 00:01:32,860
started off line

33
00:01:32,880 --> 00:01:36,000
now we're starting all five

34
00:01:36,050 --> 00:01:40,070
this talk will be very asymmetric because look article number one

35
00:01:41,280 --> 00:01:45,820
i set them all of positive positive positive positive positive positive

36
00:01:46,090 --> 00:01:48,540
will start of very high

37
00:01:48,630 --> 00:01:52,710
look at the number five the negative or positive negative positive

38
00:01:52,710 --> 00:01:57,400
number five will start very low number one will stand very hard very

39
00:01:57,400 --> 00:01:59,460
and then when it starts to oscillate

40
00:01:59,500 --> 00:02:00,840
will take

41
00:02:00,860 --> 00:02:01,710
more than

42
00:02:01,840 --> 00:02:06,630
age of the universe to come back to that same shape but it extremely rare

43
00:02:06,690 --> 00:02:09,630
you and i know one really really any more

44
00:02:09,690 --> 00:02:10,880
what's going on

45
00:02:10,880 --> 00:02:13,860
and it is even impossible to measure

46
00:02:13,880 --> 00:02:17,670
that the motion is always very simple namely the superposition

47
00:02:18,820 --> 00:02:21,250
very well behaving

48
00:02:21,250 --> 00:02:26,270
normal mode solutions which is a linear superposition of very five very simple normal mode

49
00:02:27,230 --> 00:02:29,520
but the net result is total

50
00:02:29,520 --> 00:02:31,190
other scales

51
00:02:31,210 --> 00:02:32,650
please that's the way

52
00:02:32,690 --> 00:02:34,960
it is to us

53
00:02:35,020 --> 00:02:38,070
but it can be

54
00:02:38,130 --> 00:02:53,280
it can be dissected into five very simple

55
00:02:53,300 --> 00:02:55,750
so these were

56
00:02:55,840 --> 00:02:59,920
transverse motions

57
00:02:59,920 --> 00:03:04,050
and the same idea holds for longer truly almost so you can have

58
00:03:04,090 --> 00:03:05,710
five beats

59
00:03:05,770 --> 00:03:07,190
six springs

60
00:03:07,210 --> 00:03:08,130
and then

61
00:03:08,190 --> 00:03:13,070
oscillation in this direction we call that longitudinal oscillation

62
00:03:13,130 --> 00:03:14,420
in this case

63
00:03:14,520 --> 00:03:16,750
this patient displacement is

64
00:03:16,770 --> 00:03:19,170
perpendicular to the

65
00:03:19,250 --> 00:03:23,270
also ladies we call that transfers but the other you can imagine

66
00:03:26,590 --> 00:03:32,610
except that the displacement i then all the best direction for the longitudinal story

67
00:03:32,650 --> 00:03:36,130
we will shortly and the domain of waves

68
00:03:36,170 --> 00:03:37,190
to make you

69
00:03:37,210 --> 00:03:40,900
see the idea to big difference the transverse waves and

70
00:03:40,900 --> 00:03:44,380
longitudinal waves sound pressure waves

71
00:03:44,440 --> 00:03:46,000
my direction to you

72
00:03:46,840 --> 00:03:51,090
pressure wave is is doing this so areas is also lady in the same direction

73
00:03:51,090 --> 00:03:55,300
that is that is one two know way

74
00:03:55,380 --> 00:03:57,130
this is a nice moment

75
00:03:57,170 --> 00:03:59,280
the brake wheel brake five minutes

76
00:03:59,300 --> 00:04:06,590
and we'll start exactly five minutes from now

77
00:04:30,400 --> 00:04:33,340
thank you very much for the performance

78
00:04:33,440 --> 00:04:36,800
it was pre-arranged by the way

79
00:04:36,840 --> 00:04:39,730
so we are now ready

80
00:04:40,400 --> 00:04:42,150
make the step

81
00:04:42,190 --> 00:04:46,110
two continuous medium whereby n goes to infinity well

82
00:04:46,130 --> 00:04:48,710
you can argue that goes through many atoms

83
00:04:48,730 --> 00:04:49,750
as we can

84
00:04:49,770 --> 00:04:54,420
line almost very close to infinity

85
00:04:54,480 --> 00:04:57,190
and it shouldn't come as a surprise of course

86
00:04:57,250 --> 00:04:59,070
that now

87
00:04:59,090 --> 00:05:03,460
you're going to get the entire string which is now continuous mass you no longer

88
00:05:03,460 --> 00:05:05,230
have individual beats

89
00:05:05,270 --> 00:05:06,840
that entire string

90
00:05:06,880 --> 00:05:08,800
it's going to oscillate

91
00:05:08,860 --> 00:05:11,500
sinusoidal was about

92
00:05:11,550 --> 00:05:13,230
it is and one

93
00:05:13,300 --> 00:05:16,750
that's going to oscillate

94
00:05:16,820 --> 00:05:18,900
like this

95
00:05:19,000 --> 00:05:21,840
and also

96
00:05:21,840 --> 00:05:26,660
three hundred thirty three frames and it's like one hundred twenty of those in and

97
00:05:26,660 --> 00:05:27,660
seventeen years

98
00:05:27,680 --> 00:05:32,450
tracks in these are the tracks

99
00:05:32,500 --> 00:05:35,560
which as shown by different colours

100
00:05:41,660 --> 00:05:46,540
you are these new tracks one time

101
00:05:46,550 --> 00:05:49,180
a different locations in the

102
00:05:52,670 --> 00:05:57,520
so these are the competitors in the ground truth and what we have so there

103
00:05:57,520 --> 00:06:00,070
is a finite sequence as shown in the beginning

104
00:06:00,090 --> 00:06:01,140
the talk

105
00:06:03,610 --> 00:06:08,770
these other ships in the size of ship is about forty minutes seventeen and we

106
00:06:08,770 --> 00:06:13,570
had about four hundred fifty three friends and reflected about fifty of those to track

107
00:06:13,770 --> 00:06:19,740
and these are the tracks of each of these but in a different location c

108
00:06:19,770 --> 00:06:25,480
and as you can see the contracting for quite long time which is just good

109
00:06:31,470 --> 00:06:33,880
these are the competitors in the country

110
00:06:33,910 --> 00:06:35,120
the computer

111
00:06:35,130 --> 00:06:37,470
these are all

112
00:06:37,490 --> 00:06:43,490
all the tracks and probably this is the most beautiful slide i talk to lots

113
00:06:43,490 --> 00:06:45,020
of lace colours

114
00:06:45,040 --> 00:06:49,320
and south courses of the failures

115
00:06:49,340 --> 00:06:52,970
the fact that many of the severe occlusions

116
00:06:53,000 --> 00:06:55,200
and illumination changes

117
00:06:56,850 --> 00:07:04,380
we have to some quantitative analysis and was selected about fifty

118
00:07:04,400 --> 00:07:06,110
athletes from sequence one

119
00:07:06,150 --> 00:07:11,170
twenty five seconds to fifteen to three and

120
00:07:11,200 --> 00:07:14,730
this is the combination the the forty track

121
00:07:14,740 --> 00:07:17,950
the ground truth and

122
00:07:17,970 --> 00:07:21,250
the the

123
00:07:21,270 --> 00:07:23,760
our method method shown in the black

124
00:07:23,820 --> 00:07:26,630
and then the ground which shows the

125
00:07:26,650 --> 00:07:31,020
brown as you can see that we can train very close

126
00:07:31,040 --> 00:07:32,330
to the contrary

127
00:07:33,600 --> 00:07:39,990
we have to compare if you want to use the traditional methods like mean shift

128
00:07:40,020 --> 00:07:43,510
the government and so we have the area

129
00:07:43,550 --> 00:07:50,420
for to track our method is shown in the green and the mean shift and

130
00:07:50,420 --> 00:07:55,060
it is shown as you see mean shift get distracted and you get out of

131
00:07:55,340 --> 00:08:00,410
some of these cases on the right side and

132
00:08:00,440 --> 00:08:03,500
we have to look at the what is the role of each of the flow

133
00:08:03,550 --> 00:08:06,800
field so if use only

134
00:08:06,800 --> 00:08:12,520
steady flow field there is great and this is the green line which is the

135
00:08:12,520 --> 00:08:18,400
dynamic field and the blue one is all fields combined as you see the average

136
00:08:18,400 --> 00:08:21,230
error in tracking down to

137
00:08:21,260 --> 00:08:25,700
when you have all combined blue one and gives you a pretty good results as

138
00:08:25,700 --> 00:08:29,040
compared to each individual floor

139
00:08:29,080 --> 00:08:34,970
then deeper what citizens of the area

140
00:08:34,990 --> 00:08:40,820
so one thing we found out the extent of becoming less and then this motion

141
00:08:40,870 --> 00:08:43,400
straight that's like that

142
00:08:43,970 --> 00:08:50,140
motion and fluffy you know is commits more

143
00:08:50,210 --> 00:08:54,290
and at least four take because the different from the local

144
00:08:54,290 --> 00:08:57,160
washington of these people

145
00:08:57,170 --> 00:09:03,000
so now let me talk about a couple of pieces which are the scale between

146
00:09:03,880 --> 00:09:10,540
so i give to you know extreme one is the macroscopic to the microscopic level

147
00:09:11,430 --> 00:09:15,200
mesoscopic and in this case

148
00:09:15,220 --> 00:09:19,240
they're going to use the normal behaviour

149
00:09:20,830 --> 00:09:22,170
of the crowd

150
00:09:22,200 --> 00:09:25,080
and you can use the social force model

151
00:09:25,110 --> 00:09:30,580
OK so the idea here is that the social force model to describe the dynamics

152
00:09:30,640 --> 00:09:35,630
and the crowd behavior comes from the changes in the crowd

153
00:09:35,640 --> 00:09:37,020
and the

154
00:09:37,040 --> 00:09:44,210
another approach to generate force OK so so we started with video again into the

155
00:09:44,340 --> 00:09:49,610
show and then compute this interaction force

156
00:09:49,620 --> 00:09:55,230
then from their computers for flow and can be some features using the become

157
00:09:55,300 --> 00:09:59,750
our approach and then basically that some kind of classifier

158
00:09:59,820 --> 00:10:01,890
i don't know what

159
00:10:03,170 --> 00:10:07,140
this is the kind of article is in the social force model this was by

160
00:10:08,120 --> 00:10:11,120
so there are these people shown in the

161
00:10:13,810 --> 00:10:18,670
then is called goal so there is an

162
00:10:18,690 --> 00:10:23,550
which is shown in the channel and actually lasted just short of the green

163
00:10:23,560 --> 00:10:28,050
and then there's the interaction forward from this is that the people which is shown

164
00:10:28,050 --> 00:10:37,580
in the end so the basic model is that which follows the second neutral would

165
00:10:37,580 --> 00:10:43,910
say is the forces equals mass multiplied by acceleration and the force two parts of

166
00:10:43,910 --> 00:10:47,300
the force f pmf interaction

167
00:10:47,340 --> 00:10:50,710
infinite action is the force the walls

168
00:10:50,730 --> 00:10:53,940
in the history the people in FP

169
00:10:53,950 --> 00:10:57,050
it's basically the difference between science philosophy

170
00:10:57,050 --> 00:10:57,900
and the

171
00:10:57,930 --> 00:10:59,480
actually velocity

172
00:10:59,500 --> 00:11:05,510
so doing that you get this equation for the interaction force and that's what we

173
00:11:05,510 --> 00:11:10,910
the ontology can be different levels of ontologies you've seen before of discussion about is

174
00:11:10,910 --> 00:11:17,070
there one ontology can be different ontologies you can have some background knowledge that is

175
00:11:17,070 --> 00:11:20,640
what your company already have has

176
00:11:20,820 --> 00:11:25,290
like for example lists of dictionaries or whatever

177
00:11:25,300 --> 00:11:30,720
and then you can add documents possibly you must normalized so that it doesn't matter

178
00:11:30,720 --> 00:11:35,220
if you receive word final or PDF document used in three dimensions same way

179
00:11:35,230 --> 00:11:39,910
and then you need medium to strong text images and data

180
00:11:39,920 --> 00:11:46,080
and as output to provide annotations typically you will find RDF triples stored in a

181
00:11:46,080 --> 00:11:47,530
triple store

182
00:11:50,470 --> 00:11:54,510
we the uncertainty associated with see that in a minute

183
00:11:54,520 --> 00:11:57,720
so there are many useful tools that are listed in the in the

184
00:11:57,860 --> 00:12:02,160
lies just show you an example of a to the are really lots of that

185
00:12:02,470 --> 00:12:05,440
this is actually media was developed in my lab

186
00:12:05,870 --> 00:12:12,260
active media has the possibility to upload an OWL ontology and documents and what you

187
00:12:12,920 --> 00:12:13,870
you can

188
00:12:15,180 --> 00:12:19,250
very simply the annotation by dragging and dropping things by saying this

189
00:12:19,260 --> 00:12:22,620
the wellcome foundation is whoever is visited

190
00:12:22,670 --> 00:12:28,970
a specific company for example this was an application about visiting now the interesting thing

191
00:12:28,970 --> 00:12:32,600
is that is that you can see it's not just that it's very easy to

192
00:12:32,600 --> 00:12:37,190
annotate text in this way of the document by the ontology value drag and drop

193
00:12:37,190 --> 00:12:41,630
you can create relations this is something you can download from the webpage one is

194
00:12:41,630 --> 00:12:43,670
available but the

195
00:12:43,720 --> 00:12:44,800
that's not all

196
00:12:44,810 --> 00:12:48,340
but is also the annotation of images because there is an image there

197
00:12:49,620 --> 00:12:52,950
one of the things that they store enables you to do is when you have

198
00:12:54,000 --> 00:12:59,000
but text list you go to the image you select image and then say well

199
00:12:59,000 --> 00:13:02,420
you see you draw score square around the post

200
00:13:02,440 --> 00:13:03,420
and you say

201
00:13:03,440 --> 00:13:05,460
this is the person who is visiting

202
00:13:05,480 --> 00:13:09,670
and in this case so it is visited and in this case

203
00:13:09,690 --> 00:13:12,320
using the context of the that's it and you know

204
00:13:12,330 --> 00:13:16,710
is it mappings the bore or is it same buckinghamshire or is it actually peter

205
00:13:17,630 --> 00:13:22,720
and so uses the context of the text will help you annotate the images and

206
00:13:22,720 --> 00:13:26,340
then you can of course attached image recognition for example if you

207
00:13:26,380 --> 00:13:31,830
and then you can also you also want to annotate across documents

208
00:13:31,840 --> 00:13:36,580
this means that in this case it is a homepage bicycle potential very old one

209
00:13:36,580 --> 00:13:40,840
and one from steffen staab you want to say that the person represented here is

210
00:13:40,840 --> 00:13:42,720
actually the students of

211
00:13:42,730 --> 00:13:43,720
someone else

212
00:13:43,740 --> 00:13:46,890
he said full for example what

213
00:13:48,710 --> 00:13:49,340
three are

214
00:13:49,360 --> 00:13:54,760
other methods like this is an ontology called com that enables you to store

215
00:13:55,960 --> 00:14:00,250
of multimedia documents so that just the data

216
00:14:00,260 --> 00:14:02,420
the document said

217
00:14:02,460 --> 00:14:06,800
you also say that every piece of information the in your ontology actually comes from

218
00:14:07,690 --> 00:14:11,850
and this is something that the media does

219
00:14:11,860 --> 00:14:15,690
manual annotation is quite daunting task

220
00:14:15,700 --> 00:14:17,240
the basic point is that

221
00:14:17,290 --> 00:14:18,930
you can try to do it

222
00:14:19,050 --> 00:14:24,340
you know i love it but users are not very happy users typically don't want

223
00:14:24,340 --> 00:14:25,160
to do it

224
00:14:25,210 --> 00:14:28,760
because it takes a lot of time and every new documented they produce will have

225
00:14:28,790 --> 00:14:34,120
to be annotated so you might want to annotate annotation the automated the process of

226
00:14:34,120 --> 00:14:37,120
annotation and so on

227
00:14:37,140 --> 00:14:40,520
this is because so the legacy data is generated huge

228
00:14:40,540 --> 00:14:44,000
so what do you see want to use

229
00:14:44,100 --> 00:14:48,370
something that is what you can see is basis of course this the main the

230
00:14:48,370 --> 00:14:50,660
main thing in that case you just have to

231
00:14:50,670 --> 00:14:54,940
and i think the schema and we are talking about here about about the annotation

232
00:14:54,940 --> 00:15:00,200
of instances so you want to take text documents and images of whatever you have

233
00:15:00,200 --> 00:15:06,710
to ask you and that like entity extraction where you just some names for example

234
00:15:06,720 --> 00:15:09,700
but you can have relations as one

235
00:15:09,710 --> 00:15:14,160
in texas so you can say this document this did this

236
00:15:14,180 --> 00:15:19,290
you can have a table phase because he also lost some documents especially in companies

237
00:15:19,290 --> 00:15:24,840
tend to be actually forms the tables sortable structure is an area

238
00:15:25,040 --> 00:15:30,390
event structure means actually building everything we will see in a second but on data

239
00:15:30,460 --> 00:15:35,560
has rolled eighty five fil vibration analysis will have lots of other tasks for images

240
00:15:35,560 --> 00:15:39,020
lots of tasks so we are talking of quite daunting

241
00:15:40,750 --> 00:15:45,870
as the set of pass if you just restricted information extraction from text

242
00:15:46,090 --> 00:15:51,800
the task for entity extraction the structural relation extraction event structure start with the simplest

243
00:15:51,800 --> 00:15:55,560
one named entity recognition is classification

244
00:15:56,630 --> 00:16:02,520
and it is like japanese is first in this case and then there is a

245
00:16:02,670 --> 00:16:08,210
complexity scales because up to event recognition where you're actually capture the whole event is

246
00:16:08,210 --> 00:16:13,160
described in this case was that there was a company by hiring a person and

247
00:16:13,160 --> 00:16:14,120
this person

248
00:16:14,140 --> 00:16:16,870
lieutenant company this is very

249
00:16:16,890 --> 00:16:18,980
classic example

250
00:16:19,220 --> 00:16:23,720
now if you look at and named entity recognition

251
00:16:23,740 --> 00:16:27,660
there are many ways of doing it the task is to recognise and classify the

252
00:16:27,660 --> 00:16:31,590
name the named entities so you can say paul jacobs is person

253
00:16:31,590 --> 00:16:32,690
i promise

254
00:16:32,720 --> 00:16:36,730
this is going on on video i promise that we will fix up any type

255
00:16:37,030 --> 00:16:39,090
before we release the

256
00:16:39,100 --> 00:16:41,560
the slides

257
00:16:41,610 --> 00:16:46,390
so use potentially complex structure and then

258
00:16:47,030 --> 00:16:48,210
with row

259
00:16:48,230 --> 00:16:50,140
processes of systematic way

260
00:16:50,160 --> 00:16:52,050
increasing it from zero

261
00:16:52,050 --> 00:16:55,750
and you can come up with

262
00:16:55,980 --> 00:16:59,080
an optimal

263
00:16:59,090 --> 00:17:04,130
not necessarily optimal in the mathematical sense but a good trade off between

264
00:17:04,190 --> 00:17:08,210
accuracy on the training samples sum of squares

265
00:17:09,750 --> 00:17:12,940
the smoothness of the function

266
00:17:14,110 --> 00:17:18,050
in many ways that's what we do

267
00:17:19,230 --> 00:17:20,650
in some cases

268
00:17:20,670 --> 00:17:27,010
so what happens if the data will constrain the shape of the function wherever it

269
00:17:29,360 --> 00:17:31,540
we've got the data a number of points

270
00:17:33,550 --> 00:17:40,560
this this demand for smoothness will constrain the function from doing anything too silly

271
00:17:40,610 --> 00:17:44,630
when it's when you're away from the data in the gaps between

272
00:17:44,770 --> 00:17:52,390
so a whole variety of regularisation approaches again if we just simply take the kinds

273
00:17:52,390 --> 00:17:55,700
of models tony looked at the classification

274
00:17:55,780 --> 00:18:01,810
like logistic regression or something then we don't get these nice closed form solutions but

275
00:18:01,810 --> 00:18:07,140
nonetheless we can still do the same things we can so constrained functional

276
00:18:07,170 --> 00:18:11,070
so restricting flexibility is a typical

277
00:18:11,090 --> 00:18:12,360
way of

278
00:18:12,410 --> 00:18:15,830
dealing with this problem of what takes place

279
00:18:15,870 --> 00:18:17,520
in between the date

280
00:18:17,630 --> 00:18:22,880
OK and crop up in a number of ways during the week

281
00:18:22,900 --> 00:18:25,100
so is my little

282
00:18:25,100 --> 00:18:28,200
multi media animated the proud of this

283
00:18:28,230 --> 00:18:33,270
powerpoint which drives him crazy

284
00:18:33,270 --> 00:18:35,830
what we have here

285
00:18:35,840 --> 00:18:36,810
it is

286
00:18:36,870 --> 00:18:37,970
away now

287
00:18:37,980 --> 00:18:42,660
of finding out what is happening in between the samples

288
00:18:42,710 --> 00:18:43,890
OK because

289
00:18:43,940 --> 00:18:47,500
it's all very well having a way of restricting the flexibility

290
00:18:47,530 --> 00:18:51,460
but we need a basis on which to make that trade trade-off

291
00:18:52,330 --> 00:18:57,340
and so we need to know what is happening in between

292
00:18:57,420 --> 00:18:59,520
we don't have the true function

293
00:18:59,520 --> 00:19:02,480
if we did we wouldn't be bothering with any this will pack up and go

294
00:19:04,970 --> 00:19:07,730
what we do is some form of validation

295
00:19:07,800 --> 00:19:12,640
what you what is illustrated here is the most basic form validation

296
00:19:12,670 --> 00:19:13,690
which is called

297
00:19:13,700 --> 00:19:16,660
usually the hold-out method

298
00:19:16,710 --> 00:19:18,770
the hold-out method

299
00:19:18,810 --> 00:19:21,160
there we go

300
00:19:21,220 --> 00:19:23,000
hold out

301
00:19:23,050 --> 00:19:28,610
green circles the flashing on and off they just indicating

302
00:19:28,650 --> 00:19:31,210
the data that has been used for training

303
00:19:31,270 --> 00:19:32,280
OK so

304
00:19:32,290 --> 00:19:35,320
tony mentions splitting up your data into

305
00:19:35,330 --> 00:19:39,080
a number of components here we've done

306
00:19:39,130 --> 00:19:41,370
very basic thing we've got

307
00:19:41,380 --> 00:19:44,160
one his ten data points

308
00:19:44,210 --> 00:19:45,950
i've taken this

309
00:19:45,960 --> 00:19:47,830
one two three four

310
00:19:47,870 --> 00:19:49,590
five of them

311
00:19:49,620 --> 00:19:51,070
and trained

312
00:19:51,110 --> 00:19:53,190
a flexible structure

313
00:19:53,210 --> 00:19:55,420
with those five the five are

314
00:19:55,440 --> 00:19:56,900
but the the

315
00:19:56,950 --> 00:19:58,920
the green flashing ellipses

316
00:19:58,930 --> 00:20:01,060
we can see because we got very

317
00:20:01,070 --> 00:20:03,060
flexible structure

318
00:20:03,150 --> 00:20:05,610
we get very close to these data points

319
00:20:05,620 --> 00:20:09,110
case we get a very small mean squared errors

320
00:20:09,120 --> 00:20:10,260
in these

321
00:20:10,300 --> 00:20:11,810
areas here

322
00:20:14,200 --> 00:20:15,590
but i've got

323
00:20:15,590 --> 00:20:18,910
another five samples which are held out

324
00:20:18,930 --> 00:20:19,830
of my

325
00:20:19,830 --> 00:20:21,940
the entire training set

326
00:20:21,960 --> 00:20:23,460
OK so now

327
00:20:23,470 --> 00:20:26,470
because my best to guess what the

328
00:20:26,550 --> 00:20:29,280
true function is doing

329
00:20:29,330 --> 00:20:32,040
in between my training samples

330
00:20:32,130 --> 00:20:33,830
i can measure

331
00:20:33,830 --> 00:20:35,670
the distance

332
00:20:36,750 --> 00:20:40,310
my estimated function is the turquoise function here

333
00:20:40,350 --> 00:20:42,920
and these held out data points

334
00:20:43,010 --> 00:20:45,850
and get a measure of my performance

335
00:20:45,860 --> 00:20:47,850
i can for instance

336
00:20:47,900 --> 00:20:49,620
look at the mean squared error

337
00:20:49,620 --> 00:20:52,580
some squared error or i can work out

338
00:20:52,680 --> 00:20:54,570
some of them major performer

339
00:20:55,960 --> 00:21:00,430
the sum of absolute errors something doesn't matter whatever i'm interested in

340
00:21:00,480 --> 00:21:03,640
however it my performance indicator

341
00:21:03,730 --> 00:21:08,520
so i measure my performance on these held out sample

342
00:21:08,630 --> 00:21:12,000
and that tells me something about how well under

343
00:21:13,080 --> 00:21:18,660
so in this particular case i one of the look is the

344
00:21:18,720 --> 00:21:20,860
the root mean squared error

345
00:21:20,860 --> 00:21:22,680
k across

346
00:21:22,680 --> 00:21:26,100
cut and paste good cut paste

347
00:21:31,580 --> 00:21:36,540
the way see i can express as the weight of the edge i removed

348
00:21:36,560 --> 00:21:39,660
plus the way i t one

349
00:21:39,700 --> 00:21:42,370
plus the weight of t two

350
00:21:49,370 --> 00:21:52,140
so that's the total weight

351
00:21:52,160 --> 00:21:56,580
so the answer is pretty simple suppose that there were some

352
00:21:56,640 --> 00:22:03,000
t one prime was better

353
00:22:06,620 --> 00:22:09,750
then t one

354
00:22:09,750 --> 00:22:12,700
for g one

355
00:22:12,720 --> 00:22:14,680
suppose some better way

356
00:22:14,680 --> 00:22:17,000
forming a spanning tree

357
00:22:24,750 --> 00:22:28,290
i would make up eighty prime

358
00:22:28,330 --> 00:22:31,930
which was just consists ten the edges you

359
00:22:34,330 --> 00:22:35,910
and in the end you v

360
00:22:38,500 --> 00:22:40,700
she won prime

361
00:22:40,700 --> 00:22:41,930
union t

362
00:22:44,330 --> 00:22:46,580
so i take if i had a better

363
00:22:46,620 --> 00:22:49,020
spanning tree

364
00:22:50,160 --> 00:22:52,770
venturi of lower waves

365
00:22:52,790 --> 00:22:54,350
for t one

366
00:22:54,520 --> 00:22:56,980
for t one

367
00:22:57,000 --> 00:22:58,770
i call that t one prime

368
00:22:58,790 --> 00:23:00,810
i just substitute that

369
00:23:00,830 --> 00:23:05,270
and make up a spanning tree that consisted of my original my edge u v

370
00:23:05,290 --> 00:23:08,620
whatever worked well forty one prime

371
00:23:08,640 --> 00:23:13,120
and worked whatever work property and that would be

372
00:23:14,060 --> 00:23:16,390
that would be a spanning tree

373
00:23:16,410 --> 00:23:18,250
and it would be better

374
00:23:18,310 --> 00:23:28,020
then t itself was

375
00:23:28,040 --> 00:23:31,200
for g

376
00:23:31,220 --> 00:23:33,480
because the way these

377
00:23:33,500 --> 00:23:37,680
it's just that the weight for this i now just get use the weight of

378
00:23:37,680 --> 00:23:42,020
t one prime and that's less

379
00:23:43,240 --> 00:23:46,290
and so therefore

380
00:23:46,350 --> 00:23:47,770
the assumption that

381
00:23:47,870 --> 00:23:52,500
that t was the minimum spanning tree would be violated if i could find better

382
00:23:52,500 --> 00:23:54,980
one for the sub piece

383
00:23:55,040 --> 00:24:01,310
so we have this nice

384
00:24:03,700 --> 00:24:05,390
optimal substructure

385
00:24:05,390 --> 00:24:09,160
OK i have some problems in that are

386
00:24:09,160 --> 00:24:12,810
they can be there that exhibit optimally five and

387
00:24:12,810 --> 00:24:14,810
globally optimal solution

388
00:24:14,830 --> 00:24:16,350
the whole problem

389
00:24:16,370 --> 00:24:20,870
within that i can find optimal solutions to subproblems

390
00:24:20,970 --> 00:24:23,270
so now the question is

391
00:24:23,290 --> 00:24:29,500
that's one hallmark that's one hallmark of dynamic programming what about overlapping subproblems i have

392
00:24:29,500 --> 00:24:32,160
that property

393
00:24:37,080 --> 00:24:45,020
five overlapping subproblems over here

394
00:24:45,040 --> 00:25:07,890
this paper problems

395
00:25:07,890 --> 00:25:12,620
a way of finding overlapping co occurring patterns of words but that's a good point

396
00:25:13,740 --> 00:25:18,290
you're right i don't really answer the question topical i turn it into co occurring

397
00:25:18,560 --> 00:25:24,810
and then i discuss how we're finding these spas overlapping co occurring sets of words

398
00:25:24,850 --> 00:25:26,640
but it's

399
00:25:26,660 --> 00:25:32,220
something worth more thing about it an excellent question and it's it's kind of a

400
00:25:32,240 --> 00:25:42,270
it's an issue you build generative process and you imagine it working one way and

401
00:25:42,270 --> 00:25:47,180
then it works another way that saying something you about to process or about the

402
00:25:47,180 --> 00:25:50,600
intuitions that you're having about the data not being correct

403
00:25:50,930 --> 00:25:54,000
it's good question

404
00:25:54,020 --> 00:25:57,540
OK so this this this this makes sense so this is just an intuition that

405
00:25:57,890 --> 00:26:02,310
that what LDA is doing is softening the strict definition of co occurrence in a

406
00:26:02,310 --> 00:26:06,680
mixture model to allow for overlapping sets of co occurring words and using the dirichlet

407
00:26:06,680 --> 00:26:10,870
prior as a way of enforcing that a document can be about all the topics

408
00:26:10,870 --> 00:26:12,810
at once

409
00:26:12,830 --> 00:26:17,100
OK and that's that's the punchline here

410
00:26:28,620 --> 00:26:36,140
the other thing

411
00:26:40,080 --> 00:26:44,830
well this model has no notion of hierarchy so right this is just the flat

412
00:26:44,830 --> 00:26:48,120
set of distributions over words

413
00:26:48,120 --> 00:26:52,970
and words that are more general so like in baseball there are words about baseball

414
00:26:52,970 --> 00:26:56,620
in general and there words about specific team if i could name one player i

415
00:26:57,350 --> 00:27:00,770
mention the example and the

416
00:27:00,770 --> 00:27:04,020
like paper so

417
00:27:04,040 --> 00:27:08,350
so in your right here in the based in the baseball topics since they all

418
00:27:08,350 --> 00:27:12,850
co occur together we would find general words about baseball in the same topic as

419
00:27:12,850 --> 00:27:17,350
words like the paper who specific to a team

420
00:27:17,350 --> 00:27:23,450
although the words that are specific will necessarily have lower probability than the general words

421
00:27:38,250 --> 00:27:42,250
i you know it's almost like this is finding one level if there is a

422
00:27:42,250 --> 00:27:44,310
hierarchy and you don't

423
00:27:44,330 --> 00:27:48,040
if if you feel like the hierarchy is an extremely important part of what you're

424
00:27:48,040 --> 00:27:52,140
trying to get out of the corpus then you should put a hierarchical structure somehow

425
00:27:53,040 --> 00:27:56,660
on these topics which is something you can do

426
00:27:58,200 --> 00:28:02,770
OK then will the last common and then we'll move on

427
00:28:15,310 --> 00:28:16,410
so the

428
00:28:16,430 --> 00:28:19,040
the right answer that i have no idea

429
00:28:19,040 --> 00:28:22,600
OK but that's a good point but i don't want to go back to the

430
00:28:22,600 --> 00:28:29,120
site that somehow is you produce alpha you're putting more probability on on distributions that

431
00:28:29,120 --> 00:28:32,000
have smaller entropy

432
00:28:32,040 --> 00:28:35,020
and there's really good paper by

433
00:28:35,620 --> 00:28:37,350
bill bialek and

434
00:28:37,370 --> 00:28:39,910
some of some colleagues about the

435
00:28:39,930 --> 00:28:43,560
o b i a l i k

436
00:28:43,680 --> 00:28:45,310
about he's

437
00:28:46,330 --> 00:28:49,080
a neuroscientist and is

438
00:28:49,080 --> 00:28:55,870
does that and it's about the implicit assumptions about the entropy of a distribution that

439
00:28:56,120 --> 00:28:59,290
putting in their sleep prior on something has

440
00:28:59,790 --> 00:29:04,100
that would be what i would point you to learn more about that OK

441
00:29:04,430 --> 00:29:09,080
OK so

442
00:29:12,250 --> 00:29:15,160
that's what i was hoping to talk a little bit about the intuitions for why

443
00:29:15,160 --> 00:29:19,580
this does anything and again you know thinking about the likelihood term is essential they're

444
00:29:19,580 --> 00:29:23,180
not just thinking about the properties of the priors which are also very important you

445
00:29:23,180 --> 00:29:28,100
can see they both had an important component in our our lose understanding what's going

446
00:29:28,600 --> 00:29:29,770
OK so

447
00:29:29,790 --> 00:29:35,350
LTA this simple topic model can be embedded in more complicated models embodying further intuitions

448
00:29:35,350 --> 00:29:40,600
about structures of texts this is already alluded to with things like hierarchies and there

449
00:29:40,600 --> 00:29:44,180
any proposal is

450
00:29:44,240 --> 00:29:47,300
we used to find some sort of objective functions

451
00:29:47,350 --> 00:29:51,320
and you have a main condition that things that

452
00:29:51,370 --> 00:29:56,700
as i see it is this optimiza it splits urinating clusters and you want short

453
00:29:56,720 --> 00:29:59,590
distances within each of

454
00:29:59,600 --> 00:30:01,530
you cannot accept that the

455
00:30:01,550 --> 00:30:05,600
clusters come up with that despotic kings

456
00:30:05,600 --> 00:30:12,030
but then you went the secondary condition that maybe you don't want unfortunatelly that he

457
00:30:12,030 --> 00:30:13,990
found clusters are

458
00:30:15,220 --> 00:30:19,470
and this is very thickly forested is the two moons dataset or you have some

459
00:30:19,470 --> 00:30:22,160
data that comes up in the clouds

460
00:30:22,180 --> 00:30:23,700
but wait

461
00:30:23,760 --> 00:30:28,320
but in another set of data comes up in a closed that way

462
00:30:28,370 --> 00:30:36,100
and if you very they pass a very very close neighbors union all these

463
00:30:36,100 --> 00:30:37,370
there are bus training

464
00:30:37,450 --> 00:30:41,720
this enables all the way here but nothing in between get the distance between two

465
00:30:41,720 --> 00:30:44,680
close points in different clusters is much closer than

466
00:30:44,700 --> 00:30:46,870
some distance within the clusters

467
00:30:48,800 --> 00:30:51,350
it should

468
00:30:51,560 --> 00:30:56,930
the very well one the second benjamini maybe not just keep it in mind

469
00:30:57,570 --> 00:31:05,550
many people from university of phoenix use it to say that the western church

470
00:31:05,570 --> 00:31:10,200
having to rule on the case of pornography in the US

471
00:31:10,890 --> 00:31:15,320
somehow was forced to decide whether something was or was not pornography

472
00:31:15,370 --> 00:31:19,850
i have two in that it could not define pornography but definitely he could recognise

473
00:31:19,850 --> 00:31:21,950
it when the history

474
00:31:22,030 --> 00:31:24,260
and then if it stays

475
00:31:24,370 --> 00:31:25,990
this is the clustering

476
00:31:25,990 --> 00:31:30,220
you can define testimonial you can recognise that with clustering when you see it

477
00:31:30,320 --> 00:31:35,200
and this is great if you're in a place into the

478
00:31:35,260 --> 00:31:37,220
many three d

479
00:31:37,260 --> 00:31:41,510
but how about seeing the clusters in

480
00:31:41,550 --> 00:31:44,120
one thousand dimensional space

481
00:31:44,140 --> 00:31:45,050
you see

482
00:31:48,430 --> 00:31:54,870
that's what form of proportionalities many interesting

483
00:31:54,870 --> 00:31:59,660
there are fewer so proposed the following three axioms

484
00:31:59,680 --> 00:32:02,370
scale invariance

485
00:32:02,430 --> 00:32:05,370
if your studies like this and you you need

486
00:32:06,350 --> 00:32:09,890
the clustering is still the same

487
00:32:09,890 --> 00:32:14,240
if you look at them differently this points here on this point here just because

488
00:32:14,320 --> 00:32:16,090
the length of the unit

489
00:32:16,140 --> 00:32:18,930
in the middle is

490
00:32:18,990 --> 00:32:24,450
you done for me up really any potential to st

491
00:32:24,470 --> 00:32:26,160
and consistent

492
00:32:26,180 --> 00:32:28,160
if you have clustering

493
00:32:28,200 --> 00:32:30,450
you want some point

494
00:32:30,470 --> 00:32:31,450
in one

495
00:32:31,450 --> 00:32:33,720
in such a way that the distances

496
00:32:33,820 --> 00:32:36,780
the colleagues in the same cluster of

497
00:32:36,800 --> 00:32:42,100
think one article and simultaneously all the distances to all the points you know the

498
00:32:42,100 --> 00:32:45,490
cluster is the statewide or increase

499
00:32:45,510 --> 00:32:47,320
and the clustering does not

500
00:32:49,740 --> 00:32:51,660
he says he will axioms

501
00:32:51,680 --> 00:32:54,700
and the great terror behind

502
00:32:54,740 --> 00:32:58,930
there is no

503
00:32:58,950 --> 00:33:04,600
clustering algorithm that can actually see proposition

504
00:33:04,620 --> 00:33:08,550
so this is why for the case

505
00:33:08,600 --> 00:33:14,470
researchers have been proposed by this of clustering of because no one of them will

506
00:33:14,470 --> 00:33:18,550
ever get nasty properties that somehow wasn't not

507
00:33:18,600 --> 00:33:20,050
may is preceded

508
00:33:20,070 --> 00:33:22,430
but they were being looking after

509
00:33:22,570 --> 00:33:28,370
and when you get one of their and sometimes you need be changed and

510
00:33:28,470 --> 00:33:31,410
the scale invariance was away or

511
00:33:32,260 --> 00:33:38,030
the solution is there is is no solution to the problem is over specified

512
00:33:38,030 --> 00:33:39,320
now of course

513
00:33:39,530 --> 00:33:42,300
when you see these

514
00:33:42,320 --> 00:33:44,030
seventy one of the sea

515
00:33:44,030 --> 00:33:47,910
properties becomes very subspecies

516
00:33:47,930 --> 00:33:51,550
for some of users can invite me for some of his which are made of

517
00:33:51,640 --> 00:33:57,990
business maybe some people with this belief consistency they're all sorts of unsourced police area

518
00:33:57,990 --> 00:34:02,450
on all consistency is the stronger condition bring impose we should

519
00:34:02,470 --> 00:34:07,550
but all of them came afterwards

520
00:34:07,600 --> 00:34:12,140
the then what are the terms we don't know yet these people are working on

521
00:34:13,010 --> 00:34:14,990
shaven headed in toronto is

522
00:34:15,050 --> 00:34:16,180
has number of

523
00:34:16,200 --> 00:34:20,950
contributions to history and i'm sorry i haven't followed up the rest

524
00:34:21,030 --> 00:34:25,620
but something exciting is maybe going on here

525
00:34:26,350 --> 00:34:28,200
in k means

526
00:34:30,120 --> 00:34:31,990
throwing geometry

527
00:34:32,030 --> 00:34:35,220
we throwing geometry means that we accept

528
00:34:35,220 --> 00:34:40,280
that we're going to measure distances between of our situations and that no one is

529
00:34:40,280 --> 00:34:43,600
going to give us the distance we have to to come up with one

530
00:34:43,620 --> 00:34:46,720
and if it doesn't make sense for the data

531
00:34:46,780 --> 00:34:49,990
the outcome will not make any sense

532
00:34:50,010 --> 00:34:53,430
and you don't know how to mister whether during this time is the right one

533
00:34:56,010 --> 00:34:58,430
a sense of scale

534
00:34:58,430 --> 00:35:02,680
use a fully informative so it's news is totally independent from the previous ones

535
00:35:02,700 --> 00:35:07,870
but the correct definition of fully informative news because it's piece of news is totally

536
00:35:08,700 --> 00:35:14,200
compared with the that should be no correlation like now but the definition of randomness

537
00:35:14,200 --> 00:35:19,680
is indeed and sometimes you have subsequent random use of the same sign

538
00:35:19,680 --> 00:35:22,330
if the agents over learn about this

539
00:35:22,350 --> 00:35:24,180
because we use bayesian learning

540
00:35:24,240 --> 00:35:28,240
they may be tempted to actually overweight the social imitation factor

541
00:35:28,260 --> 00:35:34,310
all the way back to the new and then her collectivity increases pressure

542
00:35:35,970 --> 00:35:39,490
let's go on to the next stage would go fast on the real estate bubble

543
00:35:39,490 --> 00:35:44,850
and mortgage and backed security above all to address the question of

544
00:35:44,910 --> 00:35:49,700
the denture before going faster detection this world is water

545
00:35:49,740 --> 00:35:51,220
global phenomena

546
00:35:51,220 --> 00:35:52,290
you see the

547
00:35:52,310 --> 00:35:56,930
returns the percentage over a four-year period in various countries

548
00:35:56,930 --> 00:36:01,010
you see the US actually the phenomenon was even larger in some places absent in

549
00:36:01,010 --> 00:36:03,120
some rare places cases

550
00:36:03,140 --> 00:36:08,480
i want just to show you again that is a super exponential acceleration was present

551
00:36:08,480 --> 00:36:10,410
for example in the UK

552
00:36:10,450 --> 00:36:12,260
this is one of the example

553
00:36:13,260 --> 00:36:16,430
roger we did identify the bubble

554
00:36:16,470 --> 00:36:21,680
in advances actually a year before the we correctly predicted that they would be meet

555
00:36:21,950 --> 00:36:25,610
two thousand four and this was published about a year and a half before the

556
00:36:26,830 --> 00:36:29,200
another example for the US

557
00:36:29,220 --> 00:36:33,560
we're here we identify this super exponential growth on the series of

558
00:36:34,640 --> 00:36:36,950
showing here in color

559
00:36:36,970 --> 00:36:39,640
the hot state where

560
00:36:39,680 --> 00:36:45,870
really the price was skyrocketing in the super exponential growth with different colors showing that

561
00:36:45,910 --> 00:36:47,280
w this region

562
00:36:47,410 --> 00:36:51,740
not only was happening so the phenomenon was really as you all know

563
00:36:51,790 --> 00:36:55,720
localized is called nationalist cause and on the

564
00:36:55,720 --> 00:36:58,830
especially california nevada and so on

565
00:36:58,970 --> 00:37:04,620
two years later you see here map where the darkest color show that they did

566
00:37:04,910 --> 00:37:07,850
the measure of the delinquency rates

567
00:37:07,850 --> 00:37:10,450
it shows a very strong correlation between

568
00:37:10,470 --> 00:37:13,350
this analysis and

569
00:37:13,350 --> 00:37:16,470
delinquency rates very interestingly the

570
00:37:17,890 --> 00:37:22,010
of the federal reserve wrote academic paper of this time

571
00:37:22,060 --> 00:37:23,810
we show that one of the

572
00:37:23,830 --> 00:37:25,830
concept the c

573
00:37:25,830 --> 00:37:27,520
motivation for these level

574
00:37:27,540 --> 00:37:29,040
it was actually the

575
00:37:29,060 --> 00:37:31,640
equity extraction

576
00:37:31,660 --> 00:37:33,990
this is called right is the fact that

577
00:37:34,010 --> 00:37:38,670
the on real estate was you know due to this refinancing so that homeowners were

578
00:37:38,670 --> 00:37:42,950
extract value from the house actually to spend more by

579
00:37:43,010 --> 00:37:48,240
BMW's anything like that again in an accelerated fashion this time scale

580
00:37:48,350 --> 00:37:50,970
this is just to to show you that after this big now

581
00:37:50,990 --> 00:37:54,160
we are in in know drop trophy so

582
00:37:54,160 --> 00:37:56,540
why are they dangerous

583
00:37:56,600 --> 00:38:02,740
well this is the captain way of the subsequent about associated with the the real

584
00:38:03,740 --> 00:38:06,780
which shows the different schematic

585
00:38:06,780 --> 00:38:08,040
blocks of

586
00:38:08,060 --> 00:38:11,080
partners of interaction so we had to bore

587
00:38:11,100 --> 00:38:14,120
getting along from the lander a mortgage broker

588
00:38:14,220 --> 00:38:18,430
have this monthly payment that are given to the investment bank that actually

589
00:38:18,430 --> 00:38:23,890
i had a a long contract but you have also the securitisation

590
00:38:24,010 --> 00:38:29,560
mortgage-backed security character that obligations on that have been released solved over all over the

591
00:38:29,560 --> 00:38:33,780
planet to hedge fund two severin freund and so on so that is the global

592
00:38:34,910 --> 00:38:41,680
and this slide actually lists across different partners it's a game

593
00:38:41,680 --> 00:38:43,390
the different problems

594
00:38:43,450 --> 00:38:46,160
that needs a full investigation

595
00:38:46,180 --> 00:38:48,100
this starting from

596
00:38:48,120 --> 00:38:49,990
predatory lending these

597
00:38:50,020 --> 00:38:51,450
very interesting

598
00:38:52,010 --> 00:38:56,240
phenomenon there many studies have now shown that excess learning was

599
00:38:57,740 --> 00:39:00,100
expanded the progress level

600
00:39:00,120 --> 00:39:02,810
mortgage fraud quite significant

601
00:39:02,890 --> 00:39:04,640
adverse selection

602
00:39:04,640 --> 00:39:07,830
mould has many different levels

603
00:39:07,830 --> 00:39:12,430
and the principal agent age in the agency problem but where we are rampant in

604
00:39:12,430 --> 00:39:18,640
the development of the system subsequent to the secretion securitisation of credit risk

605
00:39:18,660 --> 00:39:20,310
just to be very short

606
00:39:21,010 --> 00:39:23,470
so there's a few are not family

607
00:39:23,510 --> 00:39:24,580
corresponded to

608
00:39:24,580 --> 00:39:28,890
four banks would loan to three back these loans from values

609
00:39:28,910 --> 00:39:30,470
home owners

610
00:39:30,470 --> 00:39:33,290
in two different tranches of the course

611
00:39:33,290 --> 00:39:35,220
with rating

612
00:39:35,280 --> 00:39:39,120
the triple eight me that's very low probability of default

613
00:39:39,160 --> 00:39:43,160
homeowners which had a good well spaces

614
00:39:43,180 --> 00:39:48,410
all the way down to basically extremely dangerous someone very poor or

615
00:39:49,180 --> 00:39:50,020
basically the

616
00:39:50,040 --> 00:39:51,370
holmes has been

617
00:39:51,370 --> 00:39:52,430
and it

618
00:39:52,450 --> 00:39:54,790
basically without any collateral

619
00:39:55,060 --> 00:39:58,060
and very little margin and so by

620
00:39:58,080 --> 00:40:02,910
recap packaging or this instrument into single financial things

621
00:40:02,930 --> 00:40:04,100
this was

622
00:40:04,120 --> 00:40:07,930
actually rated by the rating agencies as a

623
00:40:07,930 --> 00:40:10,790
with the consequence that we have heard and we we know

624
00:40:10,810 --> 00:40:15,290
with the cascade phenomenon i just want to say something about the cascade phenomena according

625
00:40:15,370 --> 00:40:18,240
across these different elements

626
00:40:18,260 --> 00:40:20,450
which can be by sculptor

627
00:40:20,470 --> 00:40:22,470
a lot of that is shown

628
00:40:22,490 --> 00:40:28,700
across different disciplines and i will show you two incarnation about one in earthquakes

629
00:40:28,740 --> 00:40:32,810
and the other one in epileptic seizures to make big strides to

630
00:40:32,850 --> 00:40:34,680
connecting the fields that one

631
00:40:34,720 --> 00:40:38,160
you deal with the connected passed and you ask what kind of

632
00:40:38,180 --> 00:40:40,740
avalanches what kind of events can occur

633
00:40:40,780 --> 00:40:44,600
obviously the distribution of the sizes of the risk can

634
00:40:44,640 --> 00:40:48,870
derived from the because going disconnect part is

635
00:40:48,890 --> 00:40:52,760
controlled by the key by the largest component of the system that it could be

636
00:40:52,760 --> 00:40:57,600
that makes can spread beyond the size of the stick disconnected but when they become

637
00:40:57,600 --> 00:41:02,330
coupled is obvious that you have the possibility and that's what the model support of

638
00:41:02,330 --> 00:41:05,660
james across elements and then you develop

639
00:41:05,660 --> 00:41:09,080
two kinds to possible classes of distribution

640
00:41:09,080 --> 00:41:13,330
either heavy tailed distributions are also called power law distributions

641
00:41:13,370 --> 00:41:18,430
and they even more so that's already serious because you have the load non-zero probability

642
00:41:18,430 --> 00:41:21,990
of having quite large events laughter is really revealed

643
00:41:22,010 --> 00:41:23,540
but that somehow

644
00:41:23,600 --> 00:41:25,410
is not so bad because

645
00:41:25,430 --> 00:41:27,290
you can as good or

646
00:41:27,330 --> 00:41:28,700
risk manager

647
00:41:28,700 --> 00:41:31,540
identified its distribution and somehow

648
00:41:31,540 --> 00:41:35,310
measure your residual risk exposure by extrapolating the distribution

649
00:41:35,330 --> 00:41:37,140
much more research

650
00:41:37,240 --> 00:41:41,200
the possibility actually to develop this kind of distribution where

651
00:41:41,200 --> 00:41:44,430
this extreme kings outliers

652
00:41:44,450 --> 00:41:46,470
which occur rarely

653
00:41:46,510 --> 00:41:50,120
which ones as long as they don't occur you don't have any idea about the

654
00:41:50,120 --> 00:41:52,020
OK so this works

655
00:41:52,050 --> 00:41:57,600
but let's see a case where doesn't work and all i'm going to do is

656
00:41:57,600 --> 00:42:00,230
to add one more unlabelled data points

657
00:42:00,270 --> 00:42:02,510
to the data set

658
00:42:02,570 --> 00:42:04,010
you see them

659
00:42:04,020 --> 00:42:05,690
why are there

660
00:42:06,570 --> 00:42:07,440
just like i

661
00:42:07,450 --> 00:42:10,650
and well so at some point

662
00:42:10,660 --> 00:42:16,750
you started propagated in the wrong fishing and then that guy will invade

663
00:42:16,760 --> 00:42:20,700
this reaching and eventually get something else

664
00:42:20,780 --> 00:42:24,700
all right

665
00:42:24,710 --> 00:42:32,870
so just to keep this in mind semisupervised learning may not always work and that

666
00:42:32,870 --> 00:42:38,090
this is a repeating theme in today's talk

667
00:42:39,010 --> 00:42:41,190
so let's move on to

668
00:42:41,240 --> 00:42:43,360
our first

669
00:42:43,370 --> 00:42:48,990
actually second model mixture model you have already seen that that's the two cows examples

670
00:42:49,010 --> 00:42:51,420
let's make it more formal

671
00:42:51,450 --> 00:42:55,250
again here is an example but this time in two d

672
00:42:55,260 --> 00:42:57,140
so let's say you have

673
00:42:57,160 --> 00:43:03,610
some labelled data points and i actually tell you that each class is accounts distribution

674
00:43:05,910 --> 00:43:09,870
if that's the case what you do right you're given this data point this training

675
00:43:09,870 --> 00:43:15,780
data set then it's easy rate you would estimate the mean and covariance of your

676
00:43:15,780 --> 00:43:18,840
account in distributions

677
00:43:18,850 --> 00:43:24,570
so model is a mixture of gaussians which has the following parameters you have w

678
00:43:24,570 --> 00:43:28,740
one w two those are the weights of the two gaussians three respectively they should

679
00:43:28,740 --> 00:43:29,750
sum to one

680
00:43:29,760 --> 00:43:33,380
and then you have to mean and the covariance covariance matrices

681
00:43:35,710 --> 00:43:39,710
the first the full joint model so the joint model is like first you pick

682
00:43:39,710 --> 00:43:44,570
which comes in you generate data points and then use that gaussians

683
00:43:44,590 --> 00:43:46,490
to generate your point

684
00:43:46,540 --> 00:43:51,900
OK so if you know the parameters of the system then the classification is done

685
00:43:51,900 --> 00:43:53,820
by bayes rule o

686
00:43:53,840 --> 00:43:56,000
that's what you get

687
00:43:56,020 --> 00:43:58,170
and if you do it here

688
00:44:00,280 --> 00:44:05,750
contours are the sample mean and sample covariance of your labelled data set

689
00:44:05,750 --> 00:44:10,040
if you apply bayes rule you can plot the decision boundary in this case the

690
00:44:10,040 --> 00:44:11,230
decision boundary is

691
00:44:11,690 --> 00:44:13,470
the very hard to see

692
00:44:13,490 --> 00:44:19,500
green line limit raise it for you it's kind of like this

693
00:44:22,170 --> 00:44:27,650
that's all fine except that when you see

694
00:44:27,670 --> 00:44:30,350
more unlabelled data points

695
00:44:30,380 --> 00:44:31,490
OK so

696
00:44:31,520 --> 00:44:35,770
the green dots are unlabelled data points from the same distribution

697
00:44:35,790 --> 00:44:42,740
no you realize that the maximum likelihood estimate for the guys in distributions are not

698
00:44:42,740 --> 00:44:44,710
so good

699
00:44:44,720 --> 00:44:49,500
instead what you should should have use something like this

700
00:44:49,530 --> 00:44:53,280
OK the two gaussian distributions have more

701
00:44:53,310 --> 00:44:59,080
nicer covariance more diagno h

702
00:45:00,740 --> 00:45:02,600
and the decision boundary

703
00:45:02,640 --> 00:45:04,260
estimated from this data

704
00:45:04,290 --> 00:45:07,530
it is the green line here almost vertical

705
00:45:08,160 --> 00:45:11,070
and we want to capture this notion

706
00:45:11,090 --> 00:45:14,570
so what's the difference here what the differences

707
00:45:14,580 --> 00:45:19,970
how are you going to estimate the parameters of your accounts in mixture models

708
00:45:19,980 --> 00:45:21,430
in particular

709
00:45:21,470 --> 00:45:26,700
we will be doing maximum likelihood but in one case we will maximize the labelled

710
00:45:26,700 --> 00:45:29,030
data likelihood but when you have

711
00:45:29,050 --> 00:45:33,740
o labelled data what you should do is to maximize the

712
00:45:33,740 --> 00:45:39,690
a different form of likelihood they're taking into consideration the unlabelled data

713
00:45:41,320 --> 00:45:44,170
in this mixture model

714
00:45:45,250 --> 00:45:48,250
we make the assumption that you actually know

715
00:45:48,270 --> 00:45:51,600
the form of the model so that means you know it's a mixture of two

716
00:45:51,600 --> 00:45:53,340
gaussians see

717
00:45:53,360 --> 00:45:57,760
but then what you want to look at is this quantity

718
00:45:57,770 --> 00:45:59,520
the probability of

719
00:45:59,530 --> 00:46:02,430
both the labeled data and unlabeled data

720
00:46:02,440 --> 00:46:05,020
now since we do not have

721
00:46:05,050 --> 00:46:09,310
the labels on the unlabelled data you need to marginalize them out

722
00:46:09,330 --> 00:46:14,340
OK so that means you need to sum over the labels on the unlabelled data

723
00:46:14,430 --> 00:46:19,390
OK so this is a joint probability on the labelled data and marginal probability on

724
00:46:19,400 --> 00:46:21,300
the unlabelled data

725
00:46:21,330 --> 00:46:23,170
OK then

726
00:46:23,180 --> 00:46:25,130
that's the quality you want to optimize

727
00:46:25,150 --> 00:46:28,610
you can do maximum likelihood or you can do MAP estimate or you can be

728
00:46:29,850 --> 00:46:33,150
whatever you like

729
00:46:33,160 --> 00:46:38,280
but you want to optimize that quantity

730
00:46:40,250 --> 00:46:42,080
there are many

731
00:46:42,080 --> 00:46:44,350
so that's the to the talk what

732
00:46:44,360 --> 00:46:46,010
i should say

733
00:46:46,290 --> 00:46:51,490
this work was done to about fifteen years ago and autonomous driving has come along

734
00:46:51,490 --> 00:46:55,680
way so many of you were for the doctor grand challenge where one of my

735
00:46:55,680 --> 00:46:59,780
colleagues have action prove that the winning team the winning team to drive a car

736
00:46:59,780 --> 00:47:01,530
across the desert by itself

737
00:47:01,610 --> 00:47:06,840
the album was i think absolutely amazing work force time but you know states of

738
00:47:07,040 --> 00:47:09,990
autonomous driving has also come a long way since then

739
00:47:10,010 --> 00:47:13,650
the so

740
00:47:13,700 --> 00:47:14,770
what you just saw

741
00:47:14,780 --> 00:47:20,720
was an example on making supervised learning and in particular was example of what they

742
00:47:20,730 --> 00:47:26,250
call the regression problem because the vehicle is trying to predict a continuous values variables

743
00:47:26,250 --> 00:47:31,940
over continuous value steering directions we call these so called called the regression problem

744
00:47:33,330 --> 00:47:38,440
what i want to do today is talk about to offer supervised learning algorithm and

745
00:47:38,440 --> 00:47:42,160
it will also be to regression on

746
00:47:44,600 --> 00:47:46,930
the running example then we use on

747
00:47:46,940 --> 00:47:52,620
throughout today's lecture on she can return to the example trying to predict housing prices

748
00:47:55,460 --> 00:48:00,590
it's actually a data set on

749
00:48:00,630 --> 00:48:04,820
collected by RTA

750
00:48:04,870 --> 00:48:09,590
dan ramage on housing prices in portland oregon

751
00:48:13,730 --> 00:48:30,770
so here's a data set of the number of houses of of different sizes

752
00:48:30,780 --> 00:48:31,880
and so on

753
00:48:31,900 --> 00:48:40,350
here are their asking prices in thousands of

754
00:48:40,520 --> 00:48:44,350
o point of thousands

755
00:48:50,600 --> 00:49:02,500
and so on you can take this data and plotted square feet

756
00:49:02,620 --> 00:49:07,680
and so you may get the data set like that the question is given a

757
00:49:07,680 --> 00:49:11,450
data set like this given trait what call it training set like this how do

758
00:49:11,460 --> 00:49:14,290
learn to predict the relationship between the size of house

759
00:49:14,300 --> 00:49:16,180
and the price of the home

760
00:49:17,140 --> 00:49:23,780
so initially come back and modify this talk will be more later on the introduced

761
00:49:23,790 --> 00:49:28,690
some notation which be using actually throughout the rest of the squad

762
00:49:28,700 --> 00:49:33,530
the first is notation is on going to let

763
00:49:33,620 --> 00:49:39,840
the lower case alphabet n denote the number of training examples images number of roles

764
00:49:39,840 --> 00:49:43,640
of the number of from examples holds and prices have been you know in in

765
00:49:43,640 --> 00:49:46,920
this particular dataset we have

766
00:49:46,930 --> 00:49:52,950
what actually happened forty seven training examples of what i wrote down five

767
00:49:54,960 --> 00:50:06,210
throughout this quarter en route to use the output and

768
00:50:06,290 --> 00:50:12,240
to denote the number of training examples

769
00:50:12,260 --> 00:50:19,430
on i'm going to use the lowercase alphabet x

770
00:50:19,440 --> 00:50:33,850
to denote the input variables which all which are often also called the features and

771
00:50:33,850 --> 00:50:38,940
so in this case x with denote the size of the holes are looking at

772
00:50:38,990 --> 00:50:47,570
on the twenty news y to denote holds

773
00:50:47,640 --> 00:50:55,870
the area all which is sometimes also called the targets

774
00:50:55,890 --> 00:50:59,300
target variable

775
00:50:59,320 --> 00:51:00,160
and so

776
00:51:00,180 --> 00:51:11,320
on one pair a comma why is what comprises one training example in other words

777
00:51:11,320 --> 00:51:15,450
one row on the table i i i draw just now what people work on

778
00:51:15,460 --> 00:51:16,880
one training example

779
00:51:19,890 --> 00:51:26,510
and the i th training example

780
00:51:26,520 --> 00:51:32,490
in other words the i th row in that table i'm going to write as

781
00:51:32,570 --> 00:51:37,330
it's class

782
00:51:37,370 --> 00:51:40,900
why i and so on

783
00:51:40,910 --> 00:51:46,240
for the in this notation i'm going to use the superstring i is not exponentiation

784
00:51:46,260 --> 00:51:51,420
so this is not x power i want to pass i in this notation of

785
00:51:51,490 --> 00:51:56,950
this superstring i parentheses is just seven in that sense the i th row

786
00:51:58,320 --> 00:51:59,850
well the training examples

787
00:52:04,660 --> 00:52:07,210
in supervised learning this is how

788
00:52:07,220 --> 00:52:08,920
so this is this is the

789
00:52:08,930 --> 00:52:11,460
what we're going to do

790
00:52:11,470 --> 00:52:12,640
training set

791
00:52:15,970 --> 00:52:21,660
on and we're going to feed our training set comprising our EM training examples of

792
00:52:21,660 --> 00:52:25,490
forty seven training example into learning

793
00:52:34,320 --> 00:52:36,860
algorithm that has opened

794
00:52:36,910 --> 00:52:43,550
a function that maps the by tradition for historical reasons on is usually denoted

795
00:52:43,590 --> 00:52:50,840
lowercase alphabet h and is called the hypothesis

796
00:52:50,860 --> 00:52:54,560
don't worry too much about whether the term hypothesis is the

797
00:52:54,640 --> 00:52:59,280
more turn this use historical reasons

798
00:52:59,930 --> 00:53:04,920
and the hypothesis is job is to so take as input

799
00:53:04,930 --> 00:53:10,990
you know because the new host was first want estimate on what the hypothesis does

800
00:53:10,990 --> 00:53:18,670
it takes as input on a new living area in square feet saying out

801
00:53:22,050 --> 00:53:24,500
yes made the price of this whole

802
00:53:24,520 --> 00:53:26,910
so the hypothesis h

803
00:53:27,030 --> 00:53:29,160
that's from inputs x

804
00:53:30,150 --> 00:53:32,140
outputs y

805
00:53:32,230 --> 00:53:39,600
so in to design learning algorithms on the first we have to decide is how

806
00:53:39,610 --> 00:53:44,880
we want to represent the hypothesis and just for the purposes of this lecture for

807
00:53:44,900 --> 00:53:49,500
the purpose of first learning algorithm on going to use a linear representation for the

808
00:53:49,500 --> 00:53:55,760
hypothesis so i'm going to represent the hypothesis as it affects people

809
00:53:55,780 --> 00:53:57,510
it is zero

810
00:54:00,270 --> 00:54:02,860
plus the the one x where

811
00:54:03,080 --> 00:54:06,560
x here is is the input feature and so that's the

812
00:54:06,570 --> 00:54:09,120
the size of the holes were considering

813
00:54:09,940 --> 00:54:12,430
more generally

814
00:54:12,450 --> 00:54:15,210
come back to this on

815
00:54:15,220 --> 00:54:17,480
more generally for many

816
00:54:17,500 --> 00:54:22,520
because many regression problems we have more than one input feature so for example

817
00:54:22,530 --> 00:54:26,160
if all is just knowing the size of the holes is

818
00:54:26,210 --> 00:54:29,610
we know also

819
00:54:29,610 --> 00:54:37,770
yes some of them

820
00:54:37,790 --> 00:54:39,080
so this

821
00:54:39,100 --> 00:54:41,410
right now

822
00:54:48,580 --> 00:54:54,760
and you get something

823
00:54:54,950 --> 00:54:58,090
he said he

824
00:55:01,680 --> 00:55:10,260
so the same

825
00:55:17,430 --> 00:55:20,050
i know that

826
00:55:20,060 --> 00:55:22,190
now what

827
00:55:32,060 --> 00:55:37,530
so i think it would be the

828
00:55:55,620 --> 00:56:01,200
and of course in the world

829
00:56:01,230 --> 00:56:03,670
so go and

830
00:56:19,630 --> 00:56:22,070
just to

831
00:56:31,560 --> 00:56:35,070
it is not

832
00:56:35,110 --> 00:56:39,280
so you know

833
00:56:44,490 --> 00:56:46,570
the rest

834
00:56:53,640 --> 00:56:54,700
so o

835
00:56:59,210 --> 00:57:04,380
so i give

836
00:57:04,410 --> 00:57:05,790
is equal

837
00:57:05,800 --> 00:57:09,370
he goes way this

838
00:57:11,020 --> 00:57:14,200
he did

839
00:57:18,980 --> 00:57:20,830
the it will

840
00:57:22,170 --> 00:57:24,550
ten is you

841
00:57:24,550 --> 00:57:26,590
thank you

842
00:57:28,470 --> 00:57:30,660
and know

843
00:57:37,070 --> 00:57:40,910
you are

844
00:57:40,940 --> 00:57:47,190
so there like

845
00:57:47,200 --> 00:57:49,410
so he

846
00:57:51,240 --> 00:57:53,100
yes right

847
00:57:54,870 --> 00:57:58,640
so this the right

848
00:57:58,670 --> 00:58:01,210
the right

849
00:58:01,230 --> 00:58:04,040
using this is what do

850
00:58:10,260 --> 00:58:12,460
you know

851
00:58:18,560 --> 00:58:23,570
well maybe one to

852
00:58:28,910 --> 00:58:29,960
so that

853
00:58:29,980 --> 00:58:33,130
if you think it is

854
00:58:40,390 --> 00:58:47,270
in the same

855
00:58:47,280 --> 00:58:49,100
now this

856
00:58:58,310 --> 00:59:01,930
and this is all huge

857
00:59:02,010 --> 00:59:05,550
the graph g

858
00:59:05,660 --> 00:59:08,150
all right

859
00:59:09,080 --> 00:59:16,920
he was with

860
00:59:17,860 --> 00:59:19,490
and this is

861
00:59:19,510 --> 00:59:23,060
as you see i see is

862
00:59:23,070 --> 00:59:29,270
they want believe what we know

863
00:59:34,890 --> 00:59:39,790
o you can

864
00:59:39,960 --> 00:59:44,330
what you just to the west

865
00:59:44,430 --> 00:59:46,460
right so

866
00:59:48,630 --> 00:59:51,010
you know what

867
00:59:51,010 --> 00:59:53,490
it is

868
01:00:13,440 --> 01:00:16,550
this is the same

869
01:00:18,190 --> 01:00:21,260
you know you know

870
01:00:23,200 --> 01:00:23,780
you know

871
01:00:23,790 --> 01:00:25,660
you to

872
01:00:25,680 --> 01:00:31,060
he says you want

873
01:00:31,090 --> 01:00:39,190
what do you

874
01:00:48,510 --> 01:00:54,220
to this

875
01:00:54,620 --> 01:00:59,010
the rules

876
01:01:07,130 --> 01:01:09,110
i mean these really

877
01:01:09,110 --> 01:01:11,810
well that would be

878
01:01:11,840 --> 01:01:14,100
if q one positive

879
01:01:14,110 --> 01:01:16,430
and this might be

880
01:01:16,490 --> 01:01:18,890
representation forty one

881
01:01:20,200 --> 01:01:22,740
if q two were negative

882
01:01:22,760 --> 01:01:25,450
this might be

883
01:01:25,490 --> 01:01:28,360
representation forty two

884
01:01:29,050 --> 01:01:30,960
pointing towards the negative charge

885
01:01:30,970 --> 01:01:32,100
and if this one

886
01:01:32,100 --> 01:01:33,350
were negative

887
01:01:34,110 --> 01:01:36,760
i would have here

888
01:01:36,770 --> 01:01:38,910
contributions three

889
01:01:38,910 --> 01:01:40,230
and so on

890
01:01:40,280 --> 01:01:44,640
and we use the superposition principle as we did last time was coulombs law

891
01:01:44,700 --> 01:01:45,620
that the

892
01:01:45,640 --> 01:01:48,710
net electric field at a point

893
01:01:52,330 --> 01:01:55,990
this the one

894
01:01:56,040 --> 01:01:58,030
in problems of charge q one

895
01:01:58,040 --> 01:02:02,580
splicing factor u two thousand three

896
01:02:02,620 --> 01:02:06,450
and so on and if you have a high charges

897
01:02:06,490 --> 01:02:08,600
it is the sum of all charges

898
01:02:12,390 --> 01:02:15,410
is it obvious that the superposition principle works

899
01:02:16,520 --> 01:02:17,470
does it work

900
01:02:18,350 --> 01:02:19,710
how do we know it works

901
01:02:19,720 --> 01:02:23,120
because it's consistent with all our experimental

902
01:02:25,390 --> 01:02:28,930
so we take the superposition principle for granted

903
01:02:28,950 --> 01:02:30,260
and that is

904
01:02:31,430 --> 01:02:34,270
but it's not obvious

905
01:02:34,350 --> 01:02:37,770
if you tell me what the electric field at this point is which is the

906
01:02:37,780 --> 01:02:39,970
factorial some of

907
01:02:39,980 --> 01:02:42,390
the individual if field vectors

908
01:02:42,480 --> 01:02:45,800
then i can always tell you what the force will be

909
01:02:45,850 --> 01:02:48,990
if i bring a charge at that location

910
01:02:49,010 --> 01:02:52,420
i think any charges always carry in my pocket i take it out of my

911
01:02:53,350 --> 01:02:55,620
and i put at that location

912
01:02:55,670 --> 01:02:58,510
and the charter in my pocket q

913
01:02:58,520 --> 01:02:59,840
then the force

914
01:02:59,890 --> 01:03:01,270
on that charge

915
01:03:01,280 --> 01:03:04,220
it is always q times e

916
01:03:04,220 --> 01:03:06,600
it doesn't matter whether q is positive

917
01:03:06,610 --> 01:03:08,910
then it will be in the same direction as

918
01:03:08,910 --> 01:03:13,370
if it is negative it will be in the opposite direction

919
01:03:13,390 --> 01:03:16,410
if q is large the force will be large if q is small the force

920
01:03:16,410 --> 01:03:18,260
will be small

921
01:03:18,300 --> 01:03:21,520
so once you know do you feel this could be the result of very complicated

922
01:03:21,520 --> 01:03:23,660
charge configurations

923
01:03:23,670 --> 01:03:25,550
the real secret behind

924
01:03:25,580 --> 01:03:30,330
the concept of an field is that you bring any charge at that location

925
01:03:30,340 --> 01:03:31,740
and you know what force

926
01:03:32,540 --> 01:03:34,550
at that point on that

927
01:03:39,130 --> 01:03:41,160
if we try to be a little bit more

928
01:03:42,900 --> 01:03:45,640
suppose i had here

929
01:03:45,650 --> 01:03:46,800
a charge

930
01:03:46,840 --> 01:03:48,740
class three

931
01:03:48,790 --> 01:03:52,580
and he i had charge

932
01:03:52,590 --> 01:03:56,590
minus one

933
01:03:56,640 --> 01:03:58,750
it was minus one

934
01:03:58,760 --> 01:04:03,590
and and i want to know what the field configurations as result of these charges

935
01:04:03,610 --> 01:04:06,410
so you can go to any particular point

936
01:04:06,410 --> 01:04:08,450
you get an effect which is

937
01:04:08,460 --> 01:04:11,070
going away from the past three

938
01:04:11,090 --> 01:04:14,140
you get one that goes to minus one and u

939
01:04:14,150 --> 01:04:18,640
after vector only after two

940
01:04:18,650 --> 01:04:21,800
if you very close to minus one

941
01:04:21,860 --> 01:04:26,390
it's very clear because of the inverse are square relationship that the minus one is

942
01:04:26,390 --> 01:04:28,200
probably going to win

943
01:04:28,210 --> 01:04:32,400
let's in our minds to take a blood test right now

944
01:04:32,410 --> 01:04:34,060
put plus test charge

945
01:04:34,070 --> 01:04:37,420
very close to mine is one so we put it here

946
01:04:37,440 --> 01:04:40,360
even though three is trying to push it out

947
01:04:40,370 --> 01:04:41,750
clearly minus one

948
01:04:41,760 --> 01:04:43,030
is most likely

949
01:04:43,070 --> 01:04:44,240
two with

950
01:04:44,280 --> 01:04:46,540
and so it will probably be enforced

951
01:04:46,550 --> 01:04:49,680
on my test charge in these directions

952
01:04:49,740 --> 01:04:53,690
the net result of effects of the two

953
01:04:53,760 --> 01:04:58,680
suppose i take the same positive test charge anybody here very far away

954
01:04:58,690 --> 01:05:02,660
much far away then this separation

955
01:05:02,710 --> 01:05:03,910
what do you think now

956
01:05:03,960 --> 01:05:07,530
is the direction of the force all my plus chart

957
01:05:07,530 --> 01:05:13,260
thomas if you come here you can do me

958
01:05:13,370 --> 01:05:17,830
just get another chance you take

959
01:05:21,940 --> 01:05:24,820
so everyone has got a pond

960
01:05:27,000 --> 01:05:28,360
now we need to do

961
01:05:28,360 --> 01:05:30,670
within your your pairs

962
01:05:30,680 --> 01:05:35,510
choose who is a and who b and it doesn't matter who's just decide now

963
01:05:35,520 --> 01:05:36,920
use a is b

964
01:05:42,120 --> 01:05:46,230
let we just

965
01:05:46,240 --> 01:05:48,220
you can be

966
01:05:49,650 --> 01:05:54,390
right now very very simple

967
01:05:55,490 --> 01:05:57,310
you have a very easy

968
01:05:59,020 --> 01:06:02,090
a has these jobs

969
01:06:02,140 --> 01:06:04,310
and your job is this

970
01:06:04,330 --> 01:06:05,800
i which is tall

971
01:06:05,810 --> 01:06:06,510
to be

972
01:06:06,520 --> 01:06:09,210
all i want you to do is talk to be

973
01:06:09,210 --> 01:06:11,520
and i want you to say it

974
01:06:11,540 --> 01:06:13,950
however you want to say

975
01:06:13,960 --> 01:06:16,230
you know if you if you want to like this you can still like this

976
01:06:16,420 --> 01:06:20,270
if you need to move a little bit move don't move too much a doesn't

977
01:06:20,270 --> 01:06:25,460
need to move to much to just sit comfortably all the way through this exercise

978
01:06:25,470 --> 01:06:27,730
that's a role b

979
01:06:27,740 --> 01:06:30,380
your job is slightly more difficult

980
01:06:30,410 --> 01:06:35,710
now a what is a need to talk about because we need something to talk

981
01:06:35,710 --> 01:06:37,380
about to give you

982
01:06:38,730 --> 01:06:40,970
just because you need something

983
01:06:40,980 --> 01:06:46,180
so the subject i would like a to talk about is this you believe

984
01:06:46,260 --> 01:06:47,800
that the UK

985
01:06:47,820 --> 01:06:50,030
should join the euro

986
01:06:50,980 --> 01:06:52,190
that's your belief

987
01:06:52,190 --> 01:06:56,900
you know those view from slovenia you can you can inject well it's done so

988
01:06:56,900 --> 01:07:00,900
much for so whatever you're argument is i don't care if you believe in real

989
01:07:00,900 --> 01:07:06,710
life and not or if you care about real life your arguments rather role-play is

990
01:07:06,710 --> 01:07:12,800
the UK should join the euro and sit comfortably don't move too much publicity committee

991
01:07:12,910 --> 01:07:14,030
but not too much

992
01:07:14,080 --> 01:07:15,980
just nice income to be

993
01:07:15,990 --> 01:07:18,260
you're all is slightly

994
01:07:20,290 --> 01:07:22,800
this is what i want you to do is be

995
01:07:22,820 --> 01:07:25,220
at the start of the conversation

996
01:07:25,310 --> 01:07:28,140
i want you to agree

997
01:07:28,150 --> 01:07:29,630
with a

998
01:07:29,640 --> 01:07:34,800
so you agree make sure to two-way conversation is not a one-way communities listening to

999
01:07:34,800 --> 01:07:39,260
a your your interjecting as well you're giving your opinions but the important thing is

1000
01:07:39,260 --> 01:07:40,740
there is agreement

1001
01:07:40,760 --> 01:07:45,000
the UK should join the euro the other thing i want you to do b

1002
01:07:45,130 --> 01:07:48,840
when you start the role when you start the exercise i want you

1003
01:07:48,860 --> 01:07:50,190
to visually

1004
01:07:50,200 --> 01:07:53,300
and vocally match a

1005
01:07:53,360 --> 01:07:55,710
to the millimetre

1006
01:07:55,720 --> 01:08:01,530
to the millimetre if a as a is talking if he or she scratches that

1007
01:08:01,560 --> 01:08:04,140
b you do exactly the same

1008
01:08:04,590 --> 01:08:06,420
you are mimicking

1009
01:08:07,160 --> 01:08:09,040
one millimeter

1010
01:08:10,230 --> 01:08:11,830
now a

1011
01:08:11,840 --> 01:08:13,760
don't make this too difficult

1012
01:08:13,780 --> 01:08:16,920
don't purposely do funny things in it

1013
01:08:16,970 --> 01:08:19,460
you just be yourself

1014
01:08:19,470 --> 01:08:23,040
talk to be comfortable sit comfortably all the way through

1015
01:08:23,060 --> 01:08:24,810
your your role is easy

1016
01:08:24,820 --> 01:08:26,610
UK should join the euro so be

1017
01:08:26,650 --> 01:08:27,720
at the beginning

1018
01:08:27,740 --> 01:08:28,660
you agree

1019
01:08:28,660 --> 01:08:33,920
and you mimic you match visually and vocally to the millimetre this exercise does not

1020
01:08:33,920 --> 01:08:36,820
work unless is to the millimeter

1021
01:08:36,960 --> 01:08:40,230
then i'm going to say be switch

1022
01:08:40,290 --> 01:08:43,110
b you're going be for different things

1023
01:08:43,960 --> 01:08:45,550
i agree and match

1024
01:08:45,570 --> 01:08:47,440
second b

1025
01:08:47,530 --> 01:08:48,960
and then i ask you

1026
01:08:49,010 --> 01:08:51,490
to carry on agreeing

1027
01:08:51,510 --> 01:08:54,130
but now i want you to mismatch

1028
01:08:55,460 --> 01:09:00,740
totally mismatch a and to give you a demonstration of what i want

1029
01:09:00,760 --> 01:09:02,280
so if i'm talking

1030
01:09:02,280 --> 01:09:05,760
with the tightest at the beginning we're talking on going to be something like this

1031
01:09:05,760 --> 01:09:10,470
obviously whatever whatever he does i'm going to do when i ask you to switch

1032
01:09:10,470 --> 01:09:11,420
when i say

1033
01:09:11,440 --> 01:09:13,970
continue agreeing but mismatch

1034
01:09:13,990 --> 01:09:18,090
thomas days is all be doing something like this

1035
01:09:18,110 --> 01:09:20,030
all this

1036
01:09:20,050 --> 01:09:22,320
do you see how i mismatching

1037
01:09:22,340 --> 01:09:26,900
not not subtly this is obvious if you really want to obviously mismatch you can

1038
01:09:26,900 --> 01:09:29,090
even do this

1039
01:09:32,050 --> 01:09:35,780
i want you to carry on agreeing

1040
01:09:35,800 --> 01:09:40,530
with the arguments continue agreeing that's number two i've got all this ringing that don't

1041
01:09:40,530 --> 01:09:42,860
worry i've got this surrender

1042
01:09:44,170 --> 01:09:47,380
verbally agreeing

1043
01:09:47,490 --> 01:09:49,440
visually and vocally mismatching

1044
01:09:49,440 --> 01:09:50,960
number three

1045
01:09:52,240 --> 01:09:55,280
you carry on your the same all the way through b

1046
01:09:55,300 --> 01:09:57,280
number three i want you

1047
01:09:57,280 --> 01:09:59,840
to start this agreeing

1048
01:09:59,860 --> 01:10:01,230
with the argument

1049
01:10:01,240 --> 01:10:03,800
go back to matching

1050
01:10:03,940 --> 01:10:05,550
to the millimetre

1051
01:10:05,570 --> 01:10:06,710
so now

1052
01:10:06,710 --> 01:10:08,840
number three should look like this

1053
01:10:09,030 --> 01:10:10,240
i come back

1054
01:10:10,240 --> 01:10:11,960
however it however you want

1055
01:10:11,970 --> 01:10:13,570
and i will be saying

1056
01:10:13,570 --> 01:10:14,740
i'm not sure

1057
01:10:14,740 --> 01:10:16,900
i'm not sure

1058
01:10:16,940 --> 01:10:20,900
so it's going to look exactly the same i'm going to sound like a but

1059
01:10:20,900 --> 01:10:22,840
i'm disagreeing with him or her

1060
01:10:22,880 --> 01:10:24,530
and then number four

1061
01:10:24,550 --> 01:10:29,530
the fourth thing being is the when i say switch is start mismatching and start

1062
01:10:31,630 --> 01:10:34,780
right so to give you a summary

1063
01:10:34,860 --> 01:10:37,990
he give you a summary it's it's here

1064
01:10:38,030 --> 01:10:40,260
of the

1065
01:10:41,820 --> 01:10:47,070
person a you maintain stay nice comfortable position all the way through UK should join

1066
01:10:47,070 --> 01:10:48,090
the euro b

1067
01:10:48,170 --> 01:10:52,190
you can start the agreeing and match the millimeter vision vocal

1068
01:10:52,240 --> 01:10:55,780
then start agreeing and mismatching

1069
01:10:55,780 --> 01:10:57,780
in exponentiation is factor of two

1070
01:10:57,800 --> 01:11:00,430
so here is really hard to see with this one plus is doing and our

1071
01:11:00,430 --> 01:11:02,550
analysis if we tried it

1072
01:11:02,600 --> 01:11:05,780
and it's a good idea to try to home see what happens

1073
01:11:05,800 --> 01:11:08,640
if you try to do the what i'm about to do with XML

1074
01:11:08,700 --> 01:11:12,010
the one possible sort of get lost and you won't get about

1075
01:11:12,030 --> 01:11:13,410
can't prove

1076
01:11:13,470 --> 01:11:17,740
with the factor two we're in good shape we know how to deal with that

1077
01:11:17,780 --> 01:11:19,300
so more

1078
01:11:19,300 --> 01:11:24,680
when war when we've actually done the proof

1079
01:11:24,800 --> 01:11:27,530
but why we use wireless access for now

1080
01:11:27,550 --> 01:11:28,820
the reason why

1081
01:11:28,870 --> 01:11:32,680
so this is sort of a recursion acceptance condition on the so that so how

1082
01:11:32,680 --> 01:11:45,890
do i turn this into a statement that holds all the time

1083
01:11:48,570 --> 01:11:52,780
by by the probability of the event more or less

1084
01:11:53,910 --> 01:11:56,280
these events are

1085
01:11:57,660 --> 01:12:03,660
are all equally likely i should say not independent that one terms all the others

1086
01:12:03,660 --> 01:12:12,160
so how would i had generally represent events in algebra

1087
01:12:12,220 --> 01:12:14,910
indicator variables

1088
01:12:14,970 --> 01:12:23,600
remember your friends in the random variables of these analyses

1089
01:12:23,620 --> 01:12:26,470
use indicator random variables

1090
01:12:27,390 --> 01:12:29,870
they will just represent this event

1091
01:12:29,910 --> 01:12:35,510
and we'll cause and k

1092
01:12:35,550 --> 01:12:37,220
it's going to be one

1093
01:12:37,220 --> 01:12:42,240
if the rest of the road has rank k

1094
01:12:44,070 --> 01:12:45,660
and zero otherwise

1095
01:12:45,770 --> 01:12:53,600
so in particular

1096
01:12:53,620 --> 01:12:55,320
the probability

1097
01:12:55,330 --> 01:12:59,450
these things are all equally likely for a particular value and if you trial the

1098
01:12:59,450 --> 01:13:00,680
values of k

1099
01:13:00,700 --> 01:13:03,820
the probability that this equals one

1100
01:13:03,830 --> 01:13:04,970
which is also

1101
01:13:04,970 --> 01:13:06,600
the expectation

1102
01:13:06,720 --> 01:13:10,120
that indicator random variable

1103
01:13:10,120 --> 01:13:11,800
you should now

1104
01:13:11,820 --> 01:13:14,760
it only takes values one or zero zero doesn't matter

1105
01:13:16,260 --> 01:13:19,300
so this is going to be

1106
01:13:19,390 --> 01:13:21,220
only one hour and

1107
01:13:22,850 --> 01:13:25,640
so and possibilities of what the rank of the roof could be

1108
01:13:25,660 --> 01:13:31,280
each of is equally likely because we have a uniform permutation

1109
01:13:31,390 --> 01:13:36,240
so now i can rewrite this conditional statements as the summation

1110
01:13:36,260 --> 01:13:40,970
we're busy and cazorla only choose what case i mean

1111
01:13:41,030 --> 01:13:42,600
we have y and

1112
01:13:42,680 --> 01:13:44,550
there is some

1113
01:13:44,570 --> 01:13:46,620
OK cake want

1114
01:13:51,830 --> 01:13:53,680
the max

1115
01:13:57,390 --> 01:13:59,600
OK minus one

1116
01:14:00,320 --> 01:14:02,950
quite minus k

1117
01:14:06,510 --> 01:14:09,820
so now we have a good friend the recurrence

1118
01:14:09,850 --> 01:14:12,010
of it

1119
01:14:12,010 --> 01:14:15,680
OK we can really solve because this is the random variable is talking about recursive

1120
01:14:15,680 --> 01:14:19,280
random variables so first take expectation of both sides

1121
01:14:19,300 --> 01:14:20,680
that's what we really

1122
01:14:20,760 --> 01:14:24,620
that's the only thing we can really ground y and could be an square

1123
01:14:24,640 --> 01:14:26,370
in an unlucky case

1124
01:14:26,430 --> 01:14:28,640
sorry not in square

1125
01:14:28,640 --> 01:14:32,760
it could be an squared it could be to do the

1126
01:14:33,800 --> 01:14:38,590
be to the end if you're unlucky because xn can be as big as an

1127
01:14:38,600 --> 01:14:39,720
the height of the tree

1128
01:14:39,760 --> 01:14:43,490
and why and it's two that could be through the and what we want to

1129
01:14:44,890 --> 01:14:45,890
is that it's

1130
01:14:45,910 --> 01:14:52,070
polynomial in n it's and to some constant we take logs of be log

1131
01:14:52,090 --> 01:14:55,550
so we'll take expectations hopefully that will guarantee

1132
01:14:55,570 --> 01:14:56,820
this also

1133
01:14:56,870 --> 01:15:02,140
so we have expectation of the summation

1134
01:15:02,160 --> 01:15:04,930
random variables times recursive

1135
01:15:04,970 --> 01:15:08,510
random variables

1136
01:15:09,470 --> 01:15:15,930
so what is the first for track

1137
01:15:15,930 --> 01:15:20,120
what is the first thing that we do

1138
01:15:20,160 --> 01:15:24,600
in this analysis

1139
01:15:26,200 --> 01:15:28,320
linearity of expectation

1140
01:15:28,350 --> 01:15:31,320
that was easy to remember

1141
01:15:31,450 --> 01:15:35,600
we have some estimates put the inside

1142
01:15:52,930 --> 01:15:55,410
now we have an expectation of product

1143
01:15:55,430 --> 01:15:57,070
what should we use

1144
01:15:57,100 --> 01:16:04,470
independence hopefully things are independent then we can write this

1145
01:16:04,470 --> 01:16:10,800
then it would be the expectation of the product

1146
01:16:10,820 --> 01:16:14,410
and think this put the two outside is not

1147
01:16:14,430 --> 01:16:16,950
the sense in keeping in here

1148
01:16:22,930 --> 01:16:26,590
as the to like axis i can't even remember that

1149
01:16:26,600 --> 01:16:31,550
it should all be wise

1150
01:16:36,990 --> 01:16:38,240
very wise

1151
01:16:38,320 --> 01:16:40,180
and the variables

1152
01:16:41,870 --> 01:16:46,100
why are these independent so here we're looking at the choice of what the really

1153
01:16:47,200 --> 01:16:50,950
what rank the route has a problem of size n

1154
01:16:50,950 --> 01:16:51,850
in here

1155
01:16:51,850 --> 01:16:53,740
we're looking at what the roots

1156
01:16:53,740 --> 01:16:56,720
i mean there are various traces of what the search tree looks like in the

1157
01:16:56,720 --> 01:16:59,780
stuff left the room and the stuff right at the right

1158
01:16:59,830 --> 01:17:02,700
those are independent choices because everything is uniform

1159
01:17:03,280 --> 01:17:04,810
so the choice of the sky

1160
01:17:04,850 --> 01:17:06,680
was uniform and then

1161
01:17:06,680 --> 01:17:10,140
of the doors of quite close

1162
01:17:10,190 --> 01:17:11,720
now if you could the

1163
01:17:11,740 --> 01:17:15,920
descriptors with the bag of features of presentations we have used in here on this

1164
01:17:15,920 --> 01:17:20,310
dataset poses this mean average precision as performance measure

1165
01:17:20,310 --> 01:17:24,910
but you can first is that all the baseline this is well known the performance

1166
01:17:24,910 --> 01:17:30,680
increases as dimension grows up to point to in this case she obtained for two

1167
01:17:30,680 --> 01:17:33,200
hundred thousand components

1168
01:17:33,230 --> 01:17:38,010
but you can also see that if you from some dimensionality reduction zen

1169
01:17:38,040 --> 01:17:39,720
the performance drops

1170
01:17:39,760 --> 01:17:44,520
and actually it's not good seem to have a very long vector you few dimensions

1171
01:17:44,520 --> 01:17:46,500
so in this case if you reduce the

1172
01:17:47,240 --> 01:17:54,000
i victoriously victor to only sixty four components performances is only forty one on the

1173
01:17:54,220 --> 01:18:00,640
best is obtained for twenty thousand components could use sixty four four forty fourth

1174
01:18:00,670 --> 01:18:06,310
o point five which is not that bad for sixty four dimensionality vector but

1175
01:18:06,360 --> 01:18:08,740
not good enough in all case

1176
01:18:08,760 --> 01:18:13,200
so now if you look at the presentation we propose we only a very small

1177
01:18:13,390 --> 01:18:15,120
number of countries that is four

1178
01:18:15,200 --> 01:18:21,620
low dimensional his final victory you obtain some very good performance of two fifty seven

1179
01:18:21,620 --> 01:18:25,420
point five which outperforms the best but features of presentation

1180
01:18:25,430 --> 01:18:31,230
and also presentation is more likely to be reduced using principal component analysis

1181
01:18:31,240 --> 01:18:36,620
so if you want only one hundred twenty eight components for use that as we

1182
01:18:36,620 --> 01:18:38,370
can get fifty one

1183
01:18:38,380 --> 01:18:42,140
o point of mass so you can see again is that it is difficult to

1184
01:18:43,170 --> 01:18:48,560
the victories i number of components so there tradeoff depending on the number of compensatory

1185
01:18:48,560 --> 01:18:50,060
you want to know

1186
01:18:50,080 --> 01:18:54,350
you should fix k smallest i

1187
01:18:54,360 --> 01:19:01,610
so now the attendees could use their as we have to consider for this purpose

1188
01:19:01,610 --> 01:19:08,430
we use recent so that users search and indexing problem as the distance approximation problem

1189
01:19:08,430 --> 01:19:12,910
so the idea is to approximate the distance between the query vector x

1190
01:19:12,980 --> 01:19:14,810
and the basic to y

1191
01:19:14,820 --> 01:19:18,660
by the distance between x and the quantized version

1192
01:19:18,720 --> 01:19:22,950
was a bit vector so that the visitor is quantized because there's no need to

1193
01:19:22,950 --> 01:19:29,170
to quantize to query so we estimate this distance by distance

1194
01:19:29,250 --> 01:19:34,910
this is a vector to code distance in contrast to speak time she says that

1195
01:19:34,930 --> 01:19:37,060
brighton is based purely on building

1196
01:19:37,080 --> 01:19:43,330
and we compare the both two codes on the crowe's on could be introduced into

1197
01:19:43,330 --> 01:19:45,350
the approximation which is not you

1198
01:19:45,390 --> 01:19:50,320
the church contains a critical we need many centuries to get for estimation of the

1199
01:19:50,320 --> 01:19:56,790
distance where we cannot use the documents approximate k means because we typically want about

1200
01:19:57,090 --> 01:20:00,030
two sixty four centuries

1201
01:20:00,050 --> 01:20:02,880
to produce sixty four bits codes

1202
01:20:02,900 --> 01:20:08,800
instead we are using product contains the idea is quite simple we have to split

1203
01:20:08,800 --> 01:20:15,610
the into civic toes on each subject is quantized separately using contains there was a

1204
01:20:15,610 --> 01:20:20,090
limited number of centroids to in all cases conveys is still can contain the

1205
01:20:20,100 --> 01:20:26,190
risk only if you number simply is this case this example i take two hundred

1206
01:20:26,190 --> 01:20:30,830
fifty six sanctuary for each person except contains

1207
01:20:30,840 --> 01:20:33,260
so finally when you have vector

1208
01:20:33,280 --> 01:20:40,080
to be included usability contest component about a bit index just on taser although it

1209
01:20:40,080 --> 01:20:43,810
could use a sixty four bit composition index

1210
01:20:43,830 --> 01:20:48,440
now the interesting thing is put the contains there is that you can compute the

1211
01:20:48,440 --> 01:20:54,810
squared distance approximation directly in the compressed domain that is we can decompose the square

1212
01:20:54,830 --> 01:21:02,810
distance between two pixels a summation of discrete distance between feature vectors each quantized civic

1213
01:21:02,810 --> 01:21:04,660
to of the databases

1214
01:21:04,680 --> 01:21:08,660
on which is interesting which one would you want to compute the distance between the

1215
01:21:08,660 --> 01:21:13,070
query vector many codes of the disease is that

1216
01:21:13,130 --> 01:21:18,540
the email in also terms describes the terms in this summation are shared by both

1217
01:21:18,610 --> 01:21:23,770
the basic tools that is you first have to the first stage compute the distance

1218
01:21:23,770 --> 01:21:27,640
between bishop victor on all possible some treat this is the first this is not

1219
01:21:27,650 --> 01:21:32,220
the bottleneck on then you want to compute the distance between the query on the

1220
01:21:32,220 --> 01:21:36,860
database because just need additions projects

1221
01:21:36,890 --> 01:21:41,080
in the previous example means that you can compute the distance between vector on the

1222
01:21:41,080 --> 01:21:45,000
sixty book because using twenty eight edition

1223
01:21:45,010 --> 01:21:49,600
we like to mention that this scheme can combine reason i voted for it to

1224
01:21:49,640 --> 01:21:57,080
vote is this search on this provide comparable results we research better efficiency

1225
01:21:57,090 --> 01:22:02,050
so now you know that the red because of the filter approximation

1226
01:22:02,100 --> 01:22:08,040
to first approximation is due to PCA we have some protection we introduce the mean

1227
01:22:08,040 --> 01:22:09,290
square your

1228
01:22:09,300 --> 01:22:13,560
on the approximation due to quantization based upon the contains

1229
01:22:13,610 --> 01:22:15,520
so we can measure this explicitly

1230
01:22:15,720 --> 01:22:17,550
so now if you fix

1231
01:22:17,720 --> 01:22:19,910
given number of science we get

1232
01:22:19,930 --> 01:22:23,720
number of by very major want to use so we use the constraint on the

1233
01:22:23,730 --> 01:22:29,860
memory zen can automatically selects the number of components to be kept the by of

1234
01:22:29,860 --> 01:22:31,930
the dimensionality of addiction

1235
01:22:31,980 --> 01:22:37,180
in this case for example they have chosen sixteenth century from a constraint is sixteen

1236
01:22:38,070 --> 01:22:42,460
so as the dimensionality grows for the number of selected components

1237
01:22:42,470 --> 01:22:47,500
to partition iraq we use this is not surprising that but the same time we

1238
01:22:47,500 --> 01:22:49,930
are small just contains the

1239
01:22:49,950 --> 01:22:52,220
so the quantisation error increases

1240
01:22:52,230 --> 01:22:56,160
so finally trade of this is my on as the

1241
01:22:56,180 --> 01:23:02,800
the values obtained for sixty four components to be kept by the PCA

1242
01:23:02,810 --> 01:23:07,880
now let's go to the residence and some standard the set so we first first

1243
01:23:07,880 --> 01:23:13,960
use the university of kent in key object recognition benchmark on on this datasets this

1244
01:23:13,960 --> 01:23:19,390
score is usually measured as number of relevant images which are quite one in the

1245
01:23:19,390 --> 01:23:24,010
first four positions with is maximum for

1246
01:23:24,070 --> 01:23:29,180
we have also used in the early days dataset we spoke performance measured by an

1247
01:23:29,180 --> 01:23:30,590
average precision

1248
01:23:30,690 --> 01:23:35,680
the two first lines of for the baseline of the bag of features presentation on

1249
01:23:35,680 --> 01:23:38,570
this on canton key or about three

1250
01:23:38,770 --> 01:23:44,590
the mean average precision go from from forty five for medium medium-sized vocabulary two fifty

1251
01:23:45,480 --> 01:23:48,700
fuzzy longer larger vocabulary

1252
01:23:48,720 --> 01:23:51,860
so now if you look at the most probable work two hours

1253
01:23:52,000 --> 01:23:56,690
but you can see that we can reduce some presentation to only twenty bytes in

1254
01:23:56,770 --> 01:23:58,700
that case performance is not very good

1255
01:23:58,920 --> 01:24:03,470
now if you want to have a better is was approach you must use several

1256
01:24:03,470 --> 01:24:08,250
hundreds of bytes on the legs is you cannot achieve the same performance as bag

1257
01:24:08,250 --> 01:24:09,420
of features

1258
01:24:09,430 --> 01:24:11,450
now is the proposed approach

1259
01:24:11,460 --> 01:24:13,000
using only sixteen

1260
01:24:13,010 --> 01:24:19,630
two forty bytes we actually outperformed for forty bytes that if you just presentation was

1261
01:24:19,650 --> 01:24:25,540
not really unconvincing key on your very competitive with forty ninth of the bone five

1262
01:24:25,540 --> 01:24:27,390
one hundred twenty four thousand animals

1263
01:24:28,160 --> 01:24:28,800
four slaughter

1264
01:24:30,880 --> 01:24:33,540
but i mean think about it really think about it

1265
01:24:33,930 --> 01:24:38,620
how many farmed animals have you seen how many have you seen just this week

1266
01:24:39,560 --> 01:24:42,500
other sixty five billion how many have you seen this month

1267
01:24:43,580 --> 01:24:45,210
how many have you seen this year

1268
01:24:46,730 --> 01:24:48,380
how many have you seen in your lifetime

1269
01:24:50,980 --> 01:24:55,290
i mean just to give you some perspective to put this number into some sort perspective

1270
01:24:55,990 --> 01:25:00,210
think about how many people you see how many humans you see every single day

1271
01:25:00,670 --> 01:25:03,580
in the farmed animal population is

1272
01:25:04,030 --> 01:25:06,820
nearly ten times the human population

1273
01:25:08,810 --> 01:25:14,530
we are are given that these animals body parts are literally everywhere we turn

1274
01:25:15,980 --> 01:25:17,790
don't we ever see them alive

1275
01:25:19,580 --> 01:25:23,380
we don't see the animals bodies become a food because we're not supposed to

1276
01:25:24,340 --> 01:25:30,920
they are not as common as the industry would have us believe living unhappy mom-and-pop happy family farms

1277
01:25:31,740 --> 01:25:33,490
i know this is supposed to be happy

1278
01:25:34,140 --> 01:25:35,720
it doesn't look like a happy count them

1279
01:25:36,590 --> 01:25:37,130
the scary

1280
01:25:37,670 --> 01:25:39,190
but it's supposed to be a happy count

1281
01:25:39,770 --> 01:25:44,770
but most animals today are not living unhappily mom-and-pop farms as we say in

1282
01:25:45,240 --> 01:25:51,900
in english family farms over ninety nine percent of the meat eggs and dairy but make it to a place

1283
01:25:52,410 --> 01:25:57,570
come from animals that were raised in factory farms there are windowless shed in remote

1284
01:25:57,570 --> 01:26:03,490
locations that are virtually impossible for anyone other than industry officials to obtain

1285
01:26:03,900 --> 01:26:04,520
access to

1286
01:26:05,670 --> 01:26:11,970
in you did try to obtain access to one of these compounds euclid wide open prison

1287
01:26:12,550 --> 01:26:13,160
for example

1288
01:26:13,710 --> 01:26:18,860
in the united states we now have what's called the animal enterprise terrorism act

1289
01:26:19,530 --> 01:26:26,580
this is eh piece of legislation that's is similar pieces of legislation being passed in countries around the world today

1290
01:26:27,480 --> 01:26:33,910
dara lovitz attorney end of the book muslim movement explains about the eighty eight that's

1291
01:26:34,220 --> 01:26:39,040
it states that one has committed a federal crime and terrorism they engage in any

1292
01:26:39,040 --> 01:26:42,640
activity that may reduce the profits of an animal enterprise

1293
01:26:44,330 --> 01:26:53,740
and she says eighty eight legislation someone this is fundamentally unconstitutional for violating activists right to free speech

1294
01:26:54,500 --> 01:27:01,890
united states refer to these new sets was ag gag laws agribusiness laws that prevent people

1295
01:27:02,440 --> 01:27:06,340
from exposing any part of the practice animal agriculture

1296
01:27:08,120 --> 01:27:12,990
so who are these individuals background music industry tries so

1297
01:27:13,540 --> 01:27:15,010
heart-to-heart for months

1298
01:27:15,820 --> 01:27:22,470
one sheer a short video clip with here narrated by animal behaviourist jonathan balcombe whose

1299
01:27:22,980 --> 01:27:27,960
in october of over forty scientific papers sand forty four books on

1300
01:27:28,490 --> 01:27:29,680
animal consciousness

1301
01:27:30,110 --> 01:27:34,000
in this gives us a rare glimpse into the air in our lives

1302
01:27:45,250 --> 01:27:45,740
and you

1303
01:28:14,750 --> 01:28:15,690
is the

1304
01:28:16,750 --> 01:28:21,150
the first one

1305
01:28:54,760 --> 01:28:57,020
it is the

1306
01:30:38,330 --> 01:30:39,080
on the

1307
01:30:47,300 --> 01:30:48,350
the lower

1308
01:30:59,660 --> 01:31:01,610
and some of the scenes reliably on

1309
01:31:02,090 --> 01:31:03,810
these animals that use other

1310
01:31:03,940 --> 01:31:05,130
the land animals that were

1311
01:31:05,590 --> 01:31:12,640
depicted here are residents farm sanctuary which is seen leaving farmed animal protection organizations a

1312
01:31:12,640 --> 01:31:16,660
sanctuary for abused and neglected farmed animals in the united states

1313
01:31:17,510 --> 01:31:23,170
unfortunately both course sanctuary is home to only a tiny minority

1314
01:31:23,790 --> 01:31:26,050
farmed animals in the world today so

1315
01:31:26,650 --> 01:31:30,820
in just a moment i'm going to show another ship short video four minutes video

1316
01:31:30,820 --> 01:31:31,810
one is

1317
01:31:31,820 --> 01:31:37,260
in this example is thirty percent chance of rain tomorrow and people are lost

1318
01:31:38,010 --> 01:31:39,720
and that's one would be

1319
01:31:39,740 --> 01:31:41,280
so meteorologist

1320
01:31:41,300 --> 01:31:42,960
what i think it should be

1321
01:31:44,380 --> 01:31:47,670
this means in thirty percent of the days

1322
01:31:47,680 --> 01:31:52,650
where we make this prediction of the range of a minimum range

1323
01:31:53,460 --> 01:31:57,650
let me give you one example from hell

1324
01:31:57,680 --> 01:32:00,570
that illustrates how important

1325
01:32:00,620 --> 01:32:04,620
it is for the general public to understand

1326
01:32:06,280 --> 01:32:10,460
essential and very simple concepts that have to do with risk

1327
01:32:11,420 --> 01:32:12,830
in the UK

1328
01:32:12,860 --> 01:32:15,580
there is every seven years or so

1329
01:32:15,610 --> 01:32:18,570
a contraceptive pill scare

1330
01:32:18,630 --> 01:32:21,960
one way in the following way

1331
01:32:21,970 --> 01:32:23,830
the news reported

1332
01:32:23,840 --> 01:32:29,110
that women who take the pill of the third generation increased risk of first rumble

1333
01:32:29,110 --> 01:32:30,130
and billy by

1334
01:32:30,180 --> 01:32:32,620
one hundred percent

1335
01:32:32,670 --> 01:32:35,090
that certainly isn't

1336
01:32:35,110 --> 01:32:37,470
can be more

1337
01:32:37,520 --> 01:32:39,310
many british women

1338
01:32:39,330 --> 01:32:44,070
reacted with fear and anxiety panic and stop the pills

1339
01:32:44,080 --> 01:32:45,760
which led to unwanted

1340
01:32:45,770 --> 01:32:48,430
pregnancies and abortions

1341
01:32:48,570 --> 01:32:51,690
what did the study actually show

1342
01:32:51,740 --> 01:32:54,080
about which the news reported

1343
01:32:54,130 --> 01:32:58,420
it showed that out of every seven thousand women

1344
01:32:58,450 --> 01:33:02,170
who took the pill of the previous generation the second generation

1345
01:33:03,030 --> 01:33:07,440
let's rumble and polly and out of every seven thousand two

1346
01:33:07,440 --> 01:33:11,200
goal of the new generation that increased from one to two

1347
01:33:11,890 --> 01:33:13,200
one hundred percent

1348
01:33:13,220 --> 01:33:16,500
this is called the relative risk increase

1349
01:33:16,550 --> 01:33:17,620
it is

1350
01:33:17,630 --> 01:33:20,120
not transparent for the general public

1351
01:33:20,210 --> 01:33:23,850
because it doesn't specify a hundred percent of what

1352
01:33:25,540 --> 01:33:32,640
the same effect is one in seven thousand that's called an absolute risk increase

1353
01:33:32,650 --> 01:33:35,200
this is transparent for most of us

1354
01:33:35,240 --> 01:33:40,700
so here is another illustration that risk can become come

1355
01:33:40,830 --> 01:33:47,590
communicating in a transparent easy to understand way or in a way that's also correct

1356
01:33:47,590 --> 01:33:49,070
nobodies life

1357
01:33:49,070 --> 01:33:53,620
but it misleads most people in that particular case

1358
01:33:53,680 --> 01:33:56,820
this one was increased

1359
01:33:57,610 --> 01:34:04,990
number of abortions in england and wales in the following year by thirteen thousand

1360
01:34:05,000 --> 01:34:11,250
and it's not that the british public now understands the difference between relative and absolute

1361
01:34:12,140 --> 01:34:13,640
the fraction runs was

1362
01:34:13,700 --> 01:34:18,570
that british women lost their trust in the

1363
01:34:19,810 --> 01:34:21,400
what we need

1364
01:34:21,420 --> 01:34:23,350
in our society is

1365
01:34:23,360 --> 01:34:25,030
to change

1366
01:34:25,280 --> 01:34:26,820
the next generation

1367
01:34:26,860 --> 01:34:28,960
the basic concepts

1368
01:34:29,020 --> 01:34:34,320
about risk such as the difference between the absolute and relative risk

1369
01:34:34,330 --> 01:34:40,050
and moreover we need to teach them to live with uncertainty to enjoy uncertainty rather

1370
01:34:40,050 --> 01:34:42,370
than to feel it

1371
01:34:42,400 --> 01:34:44,740
and uncertainty is often enjoyed

1372
01:34:44,800 --> 01:34:49,700
when you watch the world championships in soccer games people don't know don't want to

1373
01:34:49,700 --> 01:34:50,990
know in advance

1374
01:34:51,020 --> 01:34:52,900
what the result will be

1375
01:34:52,940 --> 01:34:54,540
and in other areas

1376
01:34:55,500 --> 01:35:00,780
even twelve year-olds say american boys know baseball statistics by heart

1377
01:35:00,790 --> 01:35:04,970
but they don't don't know anything about CP is a

1378
01:35:06,610 --> 01:35:07,690
let me start

1379
01:35:07,730 --> 01:35:09,610
what do we do today is

1380
01:35:09,620 --> 01:35:10,570
i will

1381
01:35:10,580 --> 01:35:12,970
the report about

1382
01:35:12,980 --> 01:35:14,220
my own work

1383
01:35:14,300 --> 01:35:17,170
was doctors was health agencies

1384
01:35:17,210 --> 01:35:20,460
and the patients and this is an area

1385
01:35:20,560 --> 01:35:23,330
when you can see how important it would be

1386
01:35:23,350 --> 01:35:25,820
that we teach the general public

1387
01:35:25,830 --> 01:35:28,070
statistically thank you

1388
01:35:28,110 --> 01:35:31,280
now we teach lots of mathematics in schools

1389
01:35:31,300 --> 01:35:34,350
but we teach mostly mathematics of certainty

1390
01:35:34,360 --> 01:35:36,240
trigonometry geometry

1391
01:35:36,300 --> 01:35:40,550
what we need to teach the mathematics of uncertainty

1392
01:35:40,560 --> 01:35:46,090
statistical thinking is the most useful part of mathematics

1393
01:35:46,100 --> 01:35:48,450
for the world after school

1394
01:35:48,580 --> 01:35:50,330
but it's not talk this way

1395
01:35:50,340 --> 01:35:53,320
and it's often if it stored it taught in the way

1396
01:35:53,330 --> 01:35:54,390
that makes

1397
01:35:54,400 --> 01:35:56,200
the students who are curious

1398
01:35:56,210 --> 01:35:58,040
who want to know statistics

1399
01:35:58,050 --> 01:35:59,460
it makes them boring

1400
01:35:59,530 --> 01:36:01,570
and i think they can do

1401
01:36:01,680 --> 01:36:07,090
and the two largest area is in my opinion or that statistics is stored as

1402
01:36:07,090 --> 01:36:09,410
purely mathematical disciplines

1403
01:36:09,450 --> 01:36:12,210
it needs to be told us to problem solving this

1404
01:36:12,220 --> 01:36:14,970
take a problem from the real world

1405
01:36:15,070 --> 01:36:18,740
just mentioned you and then students can think

1406
01:36:18,800 --> 01:36:23,070
does this apply how can i solve that and also need to think about with

1407
01:36:23,070 --> 01:36:24,930
the assumptions hold

1408
01:36:24,970 --> 01:36:26,650
rather than having

1409
01:36:26,670 --> 01:36:29,070
the law of large numbers and then

1410
01:36:29,090 --> 01:36:34,220
provide only problems for the law of large numbers coins and was very interesting things

1411
01:36:34,230 --> 01:36:36,410
and the second thing is

1412
01:36:36,850 --> 01:36:40,840
often statistical thinking is taught with out regard

1413
01:36:42,030 --> 01:36:43,960
the human mind

1414
01:36:44,090 --> 01:36:46,050
and for some

1415
01:36:46,070 --> 01:36:50,160
for instance four

1416
01:36:50,170 --> 01:36:55,470
for the human mind some representations are easy to understand and as or not

1417
01:36:55,480 --> 01:37:01,680
we need to start with the easy understand representations not least those were mathematically convenient

1418
01:37:01,690 --> 01:37:02,690
in order to

1419
01:37:02,720 --> 01:37:07,900
that students get self-confident i can solve this and then i move on to the

1420
01:37:07,900 --> 01:37:12,030
more complicated what we often do it in the other way around

1421
01:37:12,850 --> 01:37:16,180
so let me introduce you to the world health

1422
01:37:16,450 --> 01:37:22,670
and i will today talk about two representations that mislead most

1423
01:37:23,940 --> 01:37:26,270
i hope also some of you

1424
01:37:26,290 --> 01:37:29,940
and then show you know what the representations

1425
01:37:30,740 --> 01:37:32,640
foster insight

1426
01:37:32,650 --> 01:37:34,360
and the first one

1427
01:37:34,420 --> 01:37:36,100
will be

1428
01:37:36,110 --> 01:37:41,160
five years survival rates

1429
01:37:41,180 --> 01:37:46,190
so and let me start with the summary of what i'm saying

1430
01:37:46,230 --> 01:37:51,820
well it doesn't work

1431
01:37:51,860 --> 01:37:54,720
i'm arguing that few physicians

1432
01:37:54,780 --> 01:37:56,910
politicians patients

1433
01:37:56,940 --> 01:37:58,790
understand health statistics

1434
01:37:58,800 --> 01:38:02,200
about patients no surprise

1435
01:38:02,240 --> 01:38:07,900
but the interesting point is that it also applies to physicians

1436
01:38:07,910 --> 01:38:11,490
and then there's a solution for the second

1437
01:38:11,550 --> 01:38:13,620
two of the major causes of

1438
01:38:13,640 --> 01:38:18,310
but the non transparent framing of information

1439
01:38:18,320 --> 01:38:22,100
so much of health statistic is framed in the way they are misled

1440
01:38:23,620 --> 01:38:26,200
that we face in school to teach

1441
01:38:26,200 --> 01:38:28,040
statistical thinking

1442
01:38:28,100 --> 01:38:31,690
i distinguished the decision thinking from statistical rituals

1443
01:38:31,720 --> 01:38:34,780
that are performed in the social sciences like p value

1444
01:38:34,790 --> 01:38:38,100
computations which are done in a mindless way

1445
01:38:39,110 --> 01:38:45,030
we need to teach our students to think is not to apply some

1446
01:38:46,730 --> 01:38:48,070
this is the problem

1447
01:38:48,070 --> 01:38:50,100
which is the solution

1448
01:38:50,100 --> 01:38:53,120
that to time dependent approaches

1449
01:38:53,170 --> 01:39:00,080
and also because of this new poetic flock computer so these allow us to treat

1450
01:39:00,130 --> 01:39:03,220
this reaction process

1451
01:39:03,230 --> 01:39:04,450
so what

1452
01:39:04,460 --> 01:39:06,640
what is the goal of these descriptions

1453
01:39:06,700 --> 01:39:08,790
so the goal is to have

1454
01:39:08,980 --> 01:39:13,630
a description which is as big as well as possible that cannot be completely have

1455
01:39:13,630 --> 01:39:16,800
been issued new graph is it's never been issue

1456
01:39:16,850 --> 01:39:19,480
because we don't know the nucleon nucleon interaction

1457
01:39:19,490 --> 01:39:21,360
so at what time we have

1458
01:39:21,410 --> 01:39:25,790
a few parameters OK these parameters are fixed but is not a big issue we

1459
01:39:25,790 --> 01:39:29,380
don't start from first principles from city whatever

1460
01:39:29,430 --> 01:39:32,830
but we try to do as i've been as possible

1461
01:39:32,870 --> 01:39:38,650
but also we want to give quantitative results because we want to have apps

1462
01:39:38,660 --> 01:39:45,850
we want to calculate observables that can be directly compared to experimental data we really

1463
01:39:45,850 --> 01:39:49,050
want to predict something that can be checked

1464
01:39:49,090 --> 01:39:53,580
so and what do we want to predict is everything that is related to the

1465
01:39:54,650 --> 01:39:58,470
so we want to describe the properties of the fissioning system so all the structure

1466
01:39:58,470 --> 01:40:01,490
for the that label to be sure that we

1467
01:40:01,500 --> 01:40:05,570
we really know what we are doing with this fissioning system we want to describe

1468
01:40:05,570 --> 01:40:09,230
also the time dependent evolution of the dynamical evolution

1469
01:40:09,240 --> 01:40:11,580
and then the properties of the fragments

1470
01:40:11,600 --> 01:40:13,620
so that the main goal

1471
01:40:13,660 --> 01:40:15,530
two has something going around

1472
01:40:15,570 --> 01:40:16,900
quantum mechanics

1473
01:40:16,920 --> 01:40:19,270
microscopic time dependent

1474
01:40:19,280 --> 01:40:24,570
description of the structure and the dynamics of the process

1475
01:40:24,630 --> 01:40:26,980
so what's missing in this description

1476
01:40:26,980 --> 01:40:29,960
so when i showed you that you had the energy

1477
01:40:29,980 --> 01:40:32,240
you have to go through this barrier

1478
01:40:32,250 --> 01:40:36,320
i think there are two things the first is that we don't have time evolution

1479
01:40:36,340 --> 01:40:39,470
so this is only something study that does a few

1480
01:40:39,650 --> 01:40:42,040
a flavour of what happened

1481
01:40:42,090 --> 01:40:47,200
and also here you just have one by corresponding to one fragmentation

1482
01:40:47,210 --> 01:40:52,060
but you have you see that you have fragment distribution so you can have different

1483
01:40:52,060 --> 01:40:54,970
fragmentation for the same fee simple process

1484
01:40:54,980 --> 01:40:56,810
so you can have

1485
01:40:56,820 --> 01:40:59,960
this is symmetric fission for asymmetric fission

1486
01:40:59,970 --> 01:41:03,980
so having a different probability is OK but you can have all these

1487
01:41:03,990 --> 01:41:08,810
process together so you should be able to describe the time evolution

1488
01:41:08,820 --> 01:41:12,010
all the different fragmentations

1489
01:41:12,020 --> 01:41:14,150
so that's why i presented now there

1490
01:41:14,170 --> 01:41:20,010
one of the last study that has been done concerning the description of the fission

1491
01:41:20,010 --> 01:41:22,570
fragments fission process

1492
01:41:22,580 --> 01:41:25,110
so these are the assumption of the calculation

1493
01:41:25,130 --> 01:41:26,560
so what people

1494
01:41:26,570 --> 01:41:27,590
i assume

1495
01:41:27,610 --> 01:41:33,730
that you can only consider a few degree of freedom in location asymmetry

1496
01:41:33,740 --> 01:41:35,930
and you can neglect higher order

1497
01:41:35,950 --> 01:41:38,990
vibrations so this is an assumption

1498
01:41:39,000 --> 01:41:42,890
but this assumption is we take

1499
01:41:42,950 --> 01:41:44,890
and it seems to be reasonable

1500
01:41:44,910 --> 01:41:52,400
but you can first consider elongation asymmetry and neglect the shapes which are more complicated

1501
01:41:52,400 --> 01:41:56,810
less exotic all our other people are

1502
01:41:56,810 --> 01:42:01,020
another assumption that is made here it's very important to be

1503
01:42:01,030 --> 01:42:04,800
the fact that you have two different timescales you have

1504
01:42:04,820 --> 01:42:08,650
the time scale for the fish and so for the collective motion i told you

1505
01:42:08,650 --> 01:42:13,540
that sufficient time is bigger than ten minutes nineteen seconds it's what we call slow

1506
01:42:13,540 --> 01:42:15,080
motion so

1507
01:42:15,110 --> 01:42:19,850
if we compare this time with the time needed for the nucleons to rearrange in

1508
01:42:19,850 --> 01:42:22,990
into clues it's one of the of my metre

1509
01:42:23,000 --> 01:42:27,640
so then that's why you can really separate and having two times so you consider

1510
01:42:27,640 --> 01:42:29,550
that you have a collective motion

1511
01:42:29,600 --> 01:42:32,000
and that it's time of the collective motion

1512
01:42:32,000 --> 01:42:35,770
you have the internet structure which is i particularly brilliant

1513
01:42:35,810 --> 01:42:41,770
in fact what you have behind you that you have neglecting all the internet citations

1514
01:42:41,820 --> 01:42:44,040
so you have the nucleons that

1515
01:42:44,090 --> 01:42:46,280
are at equilibrium

1516
01:42:46,280 --> 01:42:48,890
so that's why we have such away functions

1517
01:42:48,920 --> 01:42:51,780
so we have the wavefunction depending on time

1518
01:42:51,820 --> 01:42:56,430
that is the basis of a linear combination of basis states are used for studies

1519
01:42:56,430 --> 01:43:00,760
of nuclear properties of the nucleus depending on the different information

1520
01:43:00,780 --> 01:43:04,100
and then you do the time evolution

1521
01:43:04,150 --> 01:43:08,490
so what you do is the time evolution into a collective space i'm going to

1522
01:43:08,490 --> 01:43:10,820
explain that in more detail now

1523
01:43:10,840 --> 01:43:13,300
so to sum that to find that

1524
01:43:13,340 --> 01:43:15,720
so first you have to study

1525
01:43:15,730 --> 01:43:20,220
these cues to the basic state so you have to analyse the properties of the

1526
01:43:20,220 --> 01:43:24,570
nucleus when you impose different information like sufficient barriers but then it will be in

1527
01:43:24,590 --> 01:43:26,410
two dimensions the same

1528
01:43:26,470 --> 01:43:27,100
to c

1529
01:43:27,130 --> 01:43:28,960
what happens what is the energy

1530
01:43:28,970 --> 01:43:33,860
what is the response of the nuclei when you pose given information

1531
01:43:33,880 --> 01:43:36,240
so i presented yesterday the

1532
01:43:36,280 --> 01:43:38,430
the approach is just we managed to you

1533
01:43:38,530 --> 01:43:43,890
of this approach very rapidly so what you do is based on the minimization principle

1534
01:43:43,890 --> 01:43:46,090
where you minimize the energy

1535
01:43:46,140 --> 01:43:48,980
by and you impose at the same time some

1536
01:43:48,980 --> 01:43:52,170
a deformation here

1537
01:43:52,200 --> 01:43:58,100
so then when you have these basic state you have to determine the time evolution

1538
01:43:58,120 --> 01:44:00,540
so what you do here

1539
01:44:02,050 --> 01:44:07,560
he also minimize the energy so what is important here you minimize the actions

1540
01:44:07,590 --> 01:44:11,850
what is important is that you have the thermometer and so that's something you have

1541
01:44:11,860 --> 01:44:14,060
to keep in mind that when you

1542
01:44:14,100 --> 01:44:18,820
different steps in your calculation be sure that what you use in the second step

1543
01:44:18,820 --> 01:44:23,680
is going around what uses the first one so here is the same interaction

1544
01:44:23,700 --> 01:44:24,800
so the same

1545
01:44:24,820 --> 01:44:26,870
i mean that you have

1546
01:44:26,920 --> 01:44:28,930
otherwise you have the country

1547
01:44:28,950 --> 01:44:33,220
are you has various models about con thing that you really have to destroy away

1548
01:44:33,250 --> 01:44:34,840
so it's better to

1549
01:44:34,900 --> 01:44:38,320
to have complete calculation so to use the same

1550
01:44:38,350 --> 01:44:40,770
interaction and some ingredients

1551
01:44:40,810 --> 01:44:45,850
so then the equations are quite long but what is important is that he had

1552
01:44:45,880 --> 01:44:51,050
you have this time dependent equations for the propagation

1553
01:44:51,070 --> 01:44:55,890
so you have a collective hamiltonian containing here kinetic there

1554
01:44:55,920 --> 01:45:00,000
potential terror and you have here what we call zero point energy

1555
01:45:00,010 --> 01:45:03,910
it's because it's coming from quantum mechanics so you have to stations

1556
01:45:03,930 --> 01:45:06,360
these stations have here

1557
01:45:06,380 --> 01:45:10,110
to be introduced in the senate

1558
01:45:11,600 --> 01:45:17,220
this is what what he's done so these are the equation that is done so

1559
01:45:17,970 --> 01:45:21,950
other results that we can obtain with that kind of speculation

1560
01:45:21,970 --> 01:45:23,950
so when we look only at study

1561
01:45:23,970 --> 01:45:29,350
the study results we can have access to all the properties of the fissioning system

1562
01:45:29,380 --> 01:45:33,110
we can have also access to all the properties of the fragments

1563
01:45:33,130 --> 01:45:37,310
so that's what i'm going to talk after that first you will have to define

1564
01:45:37,310 --> 01:45:39,900
you go out you find instances of ravens

1565
01:45:39,930 --> 01:45:42,260
and they have the property of being black

1566
01:45:42,290 --> 01:45:46,000
and if you have also not of them then you say OK i'm strongly believing

1567
01:45:46,000 --> 01:45:48,230
in this hypothesis that all ravens are black

1568
01:45:48,240 --> 01:45:50,420
so what you do is

1569
01:45:50,480 --> 01:45:55,370
now you can abstract from it so if you see are instances this property b

1570
01:45:55,550 --> 01:45:58,380
enough of them and no counterexamples

1571
01:45:58,420 --> 01:45:59,280
when you say

1572
01:45:59,430 --> 01:46:01,230
this confirms

1573
01:46:01,490 --> 01:46:03,750
the implications are implies b

1574
01:46:03,800 --> 01:46:05,620
that's what you do in practice

1575
01:46:09,780 --> 01:46:11,990
in another instance of this rule

1576
01:46:12,000 --> 01:46:13,880
i mean because our nphs

1577
01:46:13,900 --> 01:46:15,860
any predicates

1578
01:46:15,910 --> 01:46:18,710
so let's look at not b implies not are i mean you just you know

1579
01:46:18,710 --> 01:46:21,260
replaced are going to be of formula

1580
01:46:21,290 --> 01:46:26,370
so that means that not be instances probably not our should then confirmed the rule

1581
01:46:26,370 --> 01:46:32,570
not b implies not because we can plug in for being things like

1582
01:46:32,660 --> 01:46:34,580
so next

1583
01:46:34,590 --> 01:46:39,920
we know that our implies b is logically equivalent to node b implies not our

1584
01:46:39,930 --> 01:46:41,220
so that means

1585
01:46:41,370 --> 01:46:44,030
and our

1586
01:46:44,070 --> 01:46:45,240
implies b instances

1587
01:46:46,160 --> 01:46:47,330
confirmed by

1588
01:46:47,330 --> 01:46:49,560
not being for with probably not

1589
01:46:49,570 --> 01:46:51,330
so according to the second rule

1590
01:46:51,720 --> 01:46:53,990
not be instances probably the

1591
01:46:54,000 --> 01:46:57,630
confirmed this rule but this really is logically equivalent to the first rule

1592
01:46:58,660 --> 01:47:01,130
these instances conference also

1593
01:47:01,180 --> 01:47:02,510
number one

1594
01:47:02,520 --> 01:47:04,870
so far so good

1595
01:47:04,890 --> 01:47:09,820
so now considered eclectic example so all ravens are black our hypothesis

1596
01:47:09,820 --> 01:47:12,730
and our brave and use black

1597
01:47:13,620 --> 01:47:16,290
i observing a black raven confirms

1598
01:47:16,300 --> 01:47:18,550
our hypothesis

1599
01:47:18,560 --> 01:47:20,870
most of you would agree

1600
01:47:20,890 --> 01:47:23,180
so now i will rules three

1601
01:47:23,190 --> 01:47:25,440
which is derived from one and two

1602
01:47:25,460 --> 01:47:30,830
that means that also observing white sox will confirm that all ravens are black

1603
01:47:30,840 --> 01:47:34,170
because white sox on non raven

1604
01:47:34,190 --> 01:47:36,260
which are not black

1605
01:47:36,270 --> 01:47:38,960
so they confirm that all ravens are black

1606
01:47:39,010 --> 01:47:41,890
which is very convenient if you live in the city just you know go to

1607
01:47:42,040 --> 01:47:46,340
draw and look at all the socks and then you can confirm you know some

1608
01:47:46,340 --> 01:47:51,300
biological rule

1609
01:47:51,310 --> 01:47:54,380
sounds a little bit of search

1610
01:47:55,370 --> 01:47:57,520
so i leave it homework

1611
01:47:57,550 --> 01:47:59,750
so what's going wrong here

1612
01:47:59,760 --> 01:48:05,300
i mean we care confined to kill also we can do that later

1613
01:48:06,010 --> 01:48:08,330
OK let me

1614
01:48:08,350 --> 01:48:14,980
formalise before and the philosophical part set up considering so first it's already mentioned you

1615
01:48:14,980 --> 01:48:19,770
can follow say that problems can all be expressed sequence prediction tasks

1616
01:48:19,780 --> 01:48:21,170
when to classification

1617
01:48:21,190 --> 01:48:25,150
it is also a special case of sequence prediction in classification you say a feature

1618
01:48:25,960 --> 01:48:27,300
and the class labels

1619
01:48:27,590 --> 01:48:29,000
so this

1620
01:48:29,000 --> 01:48:31,340
observation and another feature of the cluster features

1621
01:48:31,400 --> 01:48:34,330
class label now we a new instance feature vector you want to

1622
01:48:34,340 --> 01:48:38,480
predict the class label for each feature cluster to cluster class feature

1623
01:48:39,660 --> 01:48:42,740
for the first the sequence for problem

1624
01:48:42,880 --> 01:48:46,410
so as i mentioned the focus on maximizing profit

1625
01:48:46,470 --> 01:48:48,460
or minimize loss

1626
01:48:48,500 --> 01:48:52,900
just by the way we did we did not in the summer school so we

1627
01:48:52,900 --> 01:48:58,110
don't make any profits so actually they a new and victor heavily sponsored summer school

1628
01:48:58,140 --> 01:48:59,490
to keep the slow

1629
01:48:59,500 --> 01:49:01,130
four students

1630
01:49:01,220 --> 01:49:09,410
domain experts long-term profit maybe some of you want to come to the phd

1631
01:49:10,140 --> 01:49:12,130
OK so

1632
01:49:12,250 --> 01:49:17,060
i'm not primarily interested in finding a model

1633
01:49:17,150 --> 01:49:20,270
when the true model whatever this is or causal model

1634
01:49:20,290 --> 01:49:25,710
but in doing predictions or maximizing profit

1635
01:49:25,710 --> 01:49:30,480
one other thing you may ask during the lecture that never talk about noise and

1636
01:49:30,480 --> 01:49:34,440
useful data and separating them in this framework you don't need me to do that

1637
01:49:34,670 --> 01:49:40,090
so from this highly abstract point of view and this is purely sort of

1638
01:49:40,790 --> 01:49:43,310
practical problem

1639
01:49:43,360 --> 01:49:45,710
OK so i presented there

1640
01:49:45,980 --> 01:49:47,880
last week already

1641
01:49:47,880 --> 01:49:49,610
well it's good to repeat that

1642
01:49:49,610 --> 01:49:51,200
love to we work in

1643
01:49:51,290 --> 01:49:57,060
the one that has many former properties through logical character decisions and then the

1644
01:49:57,090 --> 01:50:00,540
the more structure in the examples i have tried

1645
01:50:00,550 --> 01:50:03,000
at some point maybe we try to

1646
01:50:03,010 --> 01:50:05,300
commercially the moment we are not

1647
01:50:05,320 --> 01:50:08,080
this is what happens with this sense of data

1648
01:50:10,330 --> 01:50:13,520
you have almost three thousand

1649
01:50:13,540 --> 01:50:16,020
but if you keep all rulers that

1650
01:50:16,040 --> 01:50:19,540
however the and you're left with one thousand only

1651
01:50:19,560 --> 01:50:24,770
and if you kill that are almost redundant you that the very efficient letters

1652
01:50:24,780 --> 01:50:28,750
you're not nearly enough to prior censorship was just

1653
01:50:28,760 --> 01:50:30,400
two hundred s

1654
01:50:30,440 --> 01:50:34,510
and this happened just by requiring that might work

1655
01:50:34,530 --> 01:50:35,930
has at least

1656
01:50:35,930 --> 01:50:42,110
five percent more confidence than the other is that look that similar to say similar

1657
01:50:43,720 --> 01:50:47,720
if you want them personal confidence here and

1658
01:50:47,730 --> 01:50:52,290
there's one that have substantially more

1659
01:50:52,320 --> 01:50:55,490
advanced understand most interesting ones

1660
01:50:55,490 --> 01:50:56,420
we will be

1661
01:50:56,420 --> 01:51:00,970
we're working with stuff that computes according to this mission in the

1662
01:51:03,720 --> 01:51:11,830
let me go on i promise to go back to the bias variance

1663
01:51:11,860 --> 01:51:15,170
the rest of an hour i

1664
01:51:16,690 --> 01:51:18,790
will likely

1665
01:51:19,550 --> 01:51:22,710
so what is this bias and variance things

1666
01:51:22,800 --> 01:51:28,260
and and therefore the other peak of father predictor step a planet mentioned will

1667
01:51:28,270 --> 01:51:29,810
sort of

1668
01:51:29,850 --> 01:51:34,090
very fast and we come back to it come back to me if you are

1669
01:51:38,060 --> 01:51:41,980
there are two sources of prediction error i'm thinking here now we know more about

1670
01:51:42,010 --> 01:51:44,880
traditional like task

1671
01:51:44,910 --> 01:51:58,590
and i know i'm sorry to say this i think you for this ask not

1672
01:51:58,590 --> 01:52:00,580
the method

1673
01:52:00,600 --> 01:52:04,610
ask just means that the predictions are real numbers

1674
01:52:04,660 --> 01:52:06,560
that's it

1675
01:52:06,590 --> 01:52:08,750
then there

1676
01:52:08,760 --> 01:52:13,570
several reasons several notches several biases

1677
01:52:14,170 --> 01:52:18,540
i don't look at any of them in concrete

1678
01:52:18,950 --> 01:52:23,380
looking just at the statement of the desk as simple as possible here is a

1679
01:52:23,380 --> 01:52:27,410
number of of observations each of them has an answer responsibility were

1680
01:52:27,580 --> 01:52:30,080
what value which is a real number

1681
01:52:30,100 --> 01:52:34,090
and the later we can infer that point in which i have to make a

1682
01:52:34,090 --> 01:52:36,560
prediction of the random

1683
01:52:36,580 --> 01:52:38,460
and i don't

1684
01:52:38,500 --> 01:52:40,530
well for the family

1685
01:52:40,580 --> 01:52:42,150
the model

1686
01:52:43,390 --> 01:52:46,540
one of the risk of making a mistake

1687
01:52:46,630 --> 01:52:50,030
is that you may happen to be so lucky

1688
01:52:50,080 --> 01:52:53,250
that you have something that doesn't reflect that

1689
01:52:53,430 --> 01:52:55,740
values of the

1690
01:52:55,750 --> 01:52:59,660
i mean did do make up or of a number of people so finding out

1691
01:52:59,660 --> 01:53:05,590
the hate weights and you happen to make europe more and that they can only

1692
01:53:05,940 --> 01:53:09,910
assume we his family

1693
01:53:09,950 --> 01:53:17,090
then december will not reflect the whole population it is probably too independently higher

1694
01:53:17,110 --> 01:53:19,490
not so with

1695
01:53:19,520 --> 01:53:20,910
that's too much weight

1696
01:53:20,910 --> 01:53:23,440
you cannot go out there is

1697
01:53:23,490 --> 01:53:26,050
of course i think there are people in your work

1698
01:53:27,940 --> 01:53:32,860
it's but you are the BOSS approach is very low but it's possible

1699
01:53:32,880 --> 01:53:34,490
so this surface there

1700
01:53:36,490 --> 01:53:39,630
given that the this ambiguity

1701
01:53:39,680 --> 01:53:42,360
and the parameters you find from december

1702
01:53:42,380 --> 01:53:46,440
not really many closed

1703
01:53:46,460 --> 01:53:47,160
so there

1704
01:53:47,170 --> 01:53:49,050
clark population value

1705
01:53:49,110 --> 01:53:52,840
well this is the variance of the statistic

1706
01:53:52,860 --> 01:53:58,110
but in this analysis of imagine that i only

1707
01:53:58,130 --> 01:54:00,940
i will give

1708
01:54:00,950 --> 01:54:06,660
the weight of up as shown in four kilogrammes

1709
01:54:06,710 --> 01:54:14,040
well then i will be committing an error is somebody who is seventy and has

1710
01:54:14,100 --> 01:54:19,530
or if i wouldn't be giving the hate of people only in matters

1711
01:54:19,580 --> 01:54:25,180
then many people will be one method and many people will be two meters

1712
01:54:25,280 --> 01:54:30,200
then somebody comes in and they predict from one of the things that this a

1713
01:54:30,200 --> 01:54:32,840
woman in his one forty nine

1714
01:54:32,860 --> 01:54:33,990
they they hit

1715
01:54:34,000 --> 01:54:37,130
one hundred years because it was

1716
01:54:37,140 --> 01:54:40,520
the best i could do but not really because it's

1717
01:54:40,580 --> 01:54:43,030
very far away

1718
01:54:43,050 --> 01:54:45,460
so they set this kind of

1719
01:54:46,100 --> 01:54:51,390
that comes from the family of hypothesis is the hypothesis families

1720
01:54:51,440 --> 01:54:54,850
not very wide

1721
01:54:54,910 --> 01:54:58,710
we may be the best one is not very well

1722
01:54:59,490 --> 01:55:02,950
what do you want of course you want to reduce the risk

1723
01:55:04,000 --> 01:55:06,470
want to reduce the risk

1724
01:55:06,480 --> 01:55:08,890
and if any point is that

1725
01:55:08,930 --> 01:55:14,010
they compete against each other

1726
01:55:14,050 --> 01:55:18,900
you want to predict some value y you have some samples s

1727
01:55:18,900 --> 01:55:22,750
which reveals some information about the body hard to predict

1728
01:55:22,800 --> 01:55:24,480
and then if

1729
01:55:24,490 --> 01:55:27,630
your favourite only here it looks at the

1730
01:55:27,710 --> 01:55:30,340
and as you might candidate for what is

1731
01:55:33,490 --> 01:55:37,320
the output of the estimator on understand

1732
01:55:38,260 --> 01:55:40,290
what is the variance

1733
01:55:40,390 --> 01:55:41,750
you will be

1734
01:55:41,770 --> 01:55:43,940
the quadratic coverage

1735
01:55:43,940 --> 01:55:45,420
of the estimator

1736
01:55:45,430 --> 01:55:48,350
using as estimator of its own avinash

1737
01:55:48,460 --> 01:55:50,700
it's held how far you have

1738
01:55:50,780 --> 01:55:52,790
from your avinash

1739
01:55:52,810 --> 01:55:54,860
of the two of the estimators

1740
01:55:54,970 --> 01:56:00,070
because you need to see all they use only the sum

1741
01:56:00,090 --> 01:56:02,140
you compare what you have seen

1742
01:56:02,140 --> 01:56:04,450
and the output it did you get

1743
01:56:04,470 --> 01:56:10,210
and you are what you would get if you have actual or something else

1744
01:56:11,520 --> 01:56:14,000
i expected square

1745
01:56:16,890 --> 01:56:18,380
now what's the bias

1746
01:56:18,390 --> 01:56:24,940
the bias is even if the estimator with

1747
01:56:24,990 --> 01:56:29,530
you know they don't have the expectation of the average surface

1748
01:56:29,590 --> 01:56:33,680
wouldn't that be right

1749
01:56:33,720 --> 01:56:37,880
maybe the estimator is not going to heat anyway even if all the

1750
01:56:37,890 --> 01:56:43,040
seventy one we have shown that washu or something

1751
01:56:43,100 --> 01:56:47,430
and note that this quantity is independent of the sample is just expectations and the

1752
01:56:47,990 --> 01:56:49,590
outcome we want

1753
01:56:49,710 --> 01:56:54,500
also there is a difference of scabies square here is not square here so we


1
00:00:00,000 --> 00:00:04,890
family of algorithms that interpolates between perception and we know are going for

2
00:00:04,900 --> 00:00:09,570
those who know what we know about it

3
00:00:15,550 --> 00:00:17,700
let's go back to our

4
00:00:17,700 --> 00:00:19,990
let's leave optimisation

5
00:00:20,100 --> 00:00:23,190
which is the relation restoring from

6
00:00:23,190 --> 00:00:29,790
and then let's go back to our

7
00:00:31,320 --> 00:00:32,570
all power

8
00:00:32,600 --> 00:00:35,660
perceptron which we find the first class

9
00:00:37,430 --> 00:00:38,500
the you know

10
00:00:38,530 --> 00:00:40,490
know i love

11
00:00:40,500 --> 00:00:42,610
because the simple

12
00:00:42,630 --> 00:00:44,880
and i think of

13
00:00:44,890 --> 00:00:51,280
o always generalized it in a different direction

14
00:00:51,310 --> 00:00:57,490
OK so so we can write so let's try to the weight of the perceptron

15
00:00:57,490 --> 00:01:00,850
after certain number of

16
00:01:00,900 --> 00:01:03,480
observations of the brain

17
00:01:03,500 --> 00:01:07,500
the weight

18
00:01:07,500 --> 00:01:08,780
and the weight

19
00:01:08,820 --> 00:01:11,940
we know that it can be written this

20
00:01:11,950 --> 00:01:14,360
so as

21
00:01:14,390 --> 00:01:17,700
one of it being

22
00:01:19,440 --> 00:01:24,260
x indicator function and right in this way now

23
00:01:25,590 --> 00:01:27,730
two different locations

24
00:01:27,780 --> 00:01:30,260
you don't get bored with the same picture

25
00:01:30,270 --> 00:01:37,180
no but i don't know what

26
00:01:37,190 --> 00:01:38,730
OK this is it

27
00:01:38,740 --> 00:01:41,240
it is an indicator function of the mistake

28
00:01:41,270 --> 00:01:43,850
what would you do not we can be

29
00:01:43,860 --> 00:01:46,570
now they really get action

30
00:01:46,580 --> 00:01:50,570
and then you make a mistake i made a mistake

31
00:01:50,580 --> 00:01:53,000
and imagine i have been in the way

32
00:01:53,040 --> 00:01:56,010
OK we know

33
00:01:57,110 --> 00:01:59,070
for some reason for doing

34
00:01:59,600 --> 00:02:01,140
patient who

35
00:02:01,180 --> 00:02:03,930
i want to go to art

36
00:02:03,950 --> 00:02:05,960
because i want to make it a little bit

37
00:02:06,010 --> 00:02:08,220
i want to

38
00:02:08,480 --> 00:02:14,890
at the semantics of this expression from the perceptron with some interesting

39
00:02:16,350 --> 00:02:19,850
i would like to introduce the functions

40
00:02:25,880 --> 00:02:28,600
are being the are

41
00:02:28,630 --> 00:02:32,780
anyone because this is the function that we conditions

42
00:02:32,810 --> 00:02:35,680
on the fact that i like

43
00:02:35,680 --> 00:02:38,610
later on for now just because

44
00:02:38,660 --> 00:02:40,210
any function of the form

45
00:02:40,220 --> 00:02:44,310
and i call it special function

46
00:02:45,040 --> 00:02:50,250
for reasons that hopefully will become clearer

47
00:02:50,270 --> 00:02:51,760
later on

48
00:02:55,660 --> 00:02:58,740
asking what happened

49
00:02:58,830 --> 00:03:00,860
if i

50
00:03:02,090 --> 00:03:04,450
the weight of my degree

51
00:03:06,240 --> 00:03:08,700
the gradient

52
00:03:08,720 --> 00:03:09,710
the gradient

53
00:03:09,720 --> 00:03:11,960
of the potential functions at

54
00:03:12,060 --> 00:03:13,560
the perceptron way

55
00:03:13,590 --> 00:03:16,900
what is this

56
00:03:16,950 --> 00:03:19,650
this is a

57
00:03:19,670 --> 00:03:21,080
this is

58
00:03:21,170 --> 00:03:24,230
i linear

59
00:03:24,270 --> 00:03:29,300
this is the linear classifiers

60
00:03:30,800 --> 00:03:35,070
i can think that are you can make it OK OK

61
00:03:41,590 --> 00:03:43,270
i think the gradient

62
00:03:43,360 --> 00:03:44,090
and i

63
00:03:44,140 --> 00:03:46,490
i wanted this in the back

64
00:03:46,530 --> 00:03:51,180
so might you can use

65
00:03:54,420 --> 00:03:57,550
and defining it is this

66
00:03:57,580 --> 00:04:01,750
five is any differentiable

67
00:04:03,010 --> 00:04:04,910
but this is this in this case

68
00:04:04,950 --> 00:04:07,930
i make it more making you and know

69
00:04:09,340 --> 00:04:10,510
none of this

70
00:04:10,520 --> 00:04:12,130
what about it

71
00:04:13,910 --> 00:04:16,210
OK i would say that

72
00:04:16,220 --> 00:04:17,880
so now that i

73
00:04:18,400 --> 00:04:21,080
define a linear classifier

74
00:04:21,140 --> 00:04:22,940
where the way

75
00:04:22,990 --> 00:04:24,690
i define it in terms

76
00:04:24,700 --> 00:04:28,040
all the gradient of the potential function

77
00:04:28,100 --> 00:04:31,740
it's just that it let me write another line

78
00:04:32,770 --> 00:04:35,890
you might object is defined as the

79
00:04:35,890 --> 00:04:37,500
four why he

80
00:04:39,020 --> 00:04:41,670
but the picture of what

81
00:04:41,720 --> 00:04:45,490
so if i am using it this way

82
00:04:48,270 --> 00:04:52,230
but the classification of the algorithm uses this way

83
00:04:52,240 --> 00:04:54,240
but still i can compute and

84
00:04:54,240 --> 00:04:57,410
and that is used to retrieval

85
00:04:57,420 --> 00:05:00,470
OK now how does this matrix look like that we get

86
00:05:00,580 --> 00:05:03,830
well i can show you a typical matrix here but i can show you hundreds

87
00:05:03,830 --> 00:05:06,390
of millions of typical matrix here

88
00:05:06,410 --> 00:05:09,880
and that's basically what it looked right so

89
00:05:09,920 --> 00:05:15,010
it's a big ocean of zeros and there's some islands of nonzeros right and it's

90
00:05:16,790 --> 00:05:21,410
so the assumptions i made here are basically we have million document about one hundred

91
00:05:21,410 --> 00:05:23,610
thousand terms in the vocabulary

92
00:05:23,660 --> 00:05:25,860
and the responses of about

93
00:05:25,930 --> 00:05:28,120
ten percent which means

94
00:05:28,170 --> 00:05:32,310
every document uses a hundred of the terms in the vocabulary which

95
00:05:32,320 --> 00:05:36,170
if you look at news and shorter documents is reasonable assumptions

96
00:05:38,120 --> 00:05:39,310
so this is how this

97
00:05:39,320 --> 00:05:41,420
this matrix looks like and

98
00:05:42,730 --> 00:05:46,320
you know we don't want to look at that

99
00:05:46,330 --> 00:05:48,370
beast that you know

100
00:05:48,380 --> 00:05:51,200
very sparse matrix but really we feel

101
00:05:51,220 --> 00:05:54,310
perhaps the you know this maybe should have some interesting struck structure that we can

102
00:05:56,000 --> 00:05:58,080
OK now first of all

103
00:05:58,110 --> 00:06:02,040
what does it mean that this matrix has so many zeros right so so this

104
00:06:02,040 --> 00:06:04,490
is the problem really is not just

105
00:06:04,500 --> 00:06:07,450
it's almost everywhere and in various parts but

106
00:06:07,470 --> 00:06:11,420
going back to the application that i was talking about in search

107
00:06:11,430 --> 00:06:16,170
there's a problem called the vocabulary mismatch problem and that is that if we look

108
00:06:16,170 --> 00:06:20,700
at the particular document and look at the actual content of the document there are

109
00:06:20,700 --> 00:06:22,230
many ways to express

110
00:06:22,280 --> 00:06:26,410
certain concept certain facts right by using different types of words

111
00:06:26,450 --> 00:06:30,700
so but but within a document that you know we will use one particular where

112
00:06:30,700 --> 00:06:33,280
you know that so there will only be a subset of the words that could

113
00:06:33,280 --> 00:06:36,980
be used are actually use and that's the decision they inspire or

114
00:06:37,030 --> 00:06:40,780
personal preferences are just the precision in language you know

115
00:06:40,790 --> 00:06:44,880
and that leads to this vocabulary mismatch problem which means that you know very often

116
00:06:44,880 --> 00:06:48,600
we might use certain terms to query for document but then the document might not

117
00:06:48,600 --> 00:06:53,260
contain these exact terms but might contain other terms because the author has decided not

118
00:06:54,440 --> 00:06:58,330
and of course a matrix that means you know they just so many zeros where

119
00:06:58,330 --> 00:07:02,140
in principle they could be nonzeros if the author would have chosen other works but

120
00:07:02,140 --> 00:07:03,220
usually it

121
00:07:03,250 --> 00:07:06,540
so in here just to give you some idea right we know that

122
00:07:06,550 --> 00:07:10,480
we might have a query for this document here labour immigrants germany and then we

123
00:07:10,480 --> 00:07:13,930
happy because of the three terms occur and you know we can see that that

124
00:07:13,930 --> 00:07:16,390
is relevant but as soon as we start varying

125
00:07:16,430 --> 00:07:17,970
the query

126
00:07:17,980 --> 00:07:22,180
right so to the point where something like german green card then you know none

127
00:07:22,180 --> 00:07:25,550
of the terms that we use are actually in the document although

128
00:07:25,560 --> 00:07:29,650
you know that might actually be good match with what about what this particular CNN

129
00:07:29,650 --> 00:07:31,600
news documents talks

130
00:07:31,680 --> 00:07:32,920
OK so

131
00:07:32,930 --> 00:07:34,930
what we'd like to accomplish

132
00:07:34,970 --> 00:07:39,060
is to get some robustness with respect to these variations in queries

133
00:07:39,070 --> 00:07:42,320
OK so that we're not getting a vastly different answer every time

134
00:07:42,400 --> 00:07:46,930
and in particular also that we we find relevant documents even if we don't use

135
00:07:47,850 --> 00:07:53,930
specific terms

136
00:07:53,950 --> 00:07:56,530
OK so one of the main challenges here

137
00:07:57,970 --> 00:08:01,260
the the compactness so typical

138
00:08:01,350 --> 00:08:06,050
query consists of about two point five terms right we all know that the reason

139
00:08:06,230 --> 00:08:07,810
own statistics

140
00:08:07,830 --> 00:08:11,040
there's there's great variability in language

141
00:08:11,050 --> 00:08:14,190
there's an and semantically related terms and so on and so forth

142
00:08:14,210 --> 00:08:19,750
there's a lot of ambiguity so for instance terms with multiple meanings giving example

143
00:08:19,760 --> 00:08:22,400
if you query for

144
00:08:22,420 --> 00:08:25,780
at the time i did this google you find information about you this is a

145
00:08:25,900 --> 00:08:27,210
space probe

146
00:08:27,270 --> 00:08:30,220
about james joyce's

147
00:08:30,280 --> 00:08:34,430
book and then about this is frowned who you know

148
00:08:34,450 --> 00:08:36,450
as a general in the

149
00:08:36,460 --> 00:08:38,220
american civil war

150
00:08:39,550 --> 00:08:43,410
and then there is also questionable quality and authority which is important in the web

151
00:08:43,410 --> 00:08:45,280
context for something like

152
00:08:45,290 --> 00:08:46,380
OK so now

153
00:08:46,390 --> 00:08:50,150
i talk about the technique that can console help to address

154
00:08:50,160 --> 00:08:52,570
some of these challenges and that

155
00:08:52,760 --> 00:08:57,340
get back as i said to the late eighties and early nineties when people invented

156
00:08:57,340 --> 00:09:01,380
this technique called latent semantic analysis of latent semantic indexing

157
00:09:01,390 --> 00:09:05,450
and the idea is that we take this huge matrix and we perform a low

158
00:09:05,450 --> 00:09:08,040
rank approximation of the matrix

159
00:09:08,080 --> 00:09:12,810
and say reduce it down approximated by matrix perhaps of rank

160
00:09:12,820 --> 00:09:16,600
somewhere between one hundred and three hundred just to give you a kind of rough

161
00:09:18,540 --> 00:09:23,300
and the general idea behind this was that you know we wouldn't documents and terms

162
00:09:23,310 --> 00:09:27,970
bye bye bye by computing the low rank approximation effectively mapped into some low dimensional

163
00:09:27,970 --> 00:09:31,380
space one hundred to three hundred dimensional space

164
00:09:31,400 --> 00:09:32,930
in which hopefully

165
00:09:34,090 --> 00:09:37,810
by for instance computing inner product in that space

166
00:09:37,810 --> 00:09:39,860
what is the we want to know v

167
00:09:39,910 --> 00:09:41,480
eight minus six

168
00:09:41,510 --> 00:09:43,290
s two meters per second

169
00:09:44,040 --> 00:09:45,140
physics work

170
00:09:45,160 --> 00:09:48,300
he is now plus two meters per second

171
00:09:48,340 --> 00:09:51,630
all that information is in there but i want you to be able

172
00:09:51,650 --> 00:09:52,560
two also

173
00:09:52,560 --> 00:09:57,210
digest they don't look at the of just some don't have a parabola some done

174
00:09:57,210 --> 00:10:00,270
curve try to imagine what is happening

175
00:10:00,270 --> 00:10:01,500
and only then

176
00:10:01,570 --> 00:10:02,920
you get some insight

177
00:10:02,960 --> 00:10:04,570
then you really begin to

178
00:10:04,570 --> 00:10:05,500
get it

179
00:10:05,500 --> 00:10:08,420
in your brains

180
00:10:08,480 --> 00:10:10,420
i know i would like to write down

181
00:10:10,480 --> 00:10:13,020
in most general four

182
00:10:13,070 --> 00:10:14,840
the equation

183
00:10:14,900 --> 00:10:17,230
for the position

184
00:10:17,250 --> 00:10:19,860
and the velocity as a function of time

185
00:10:19,920 --> 00:10:23,230
for one-dimensional motion

186
00:10:23,610 --> 00:10:26,400
the acceleration is constant

187
00:10:26,440 --> 00:10:28,770
so it's going to be one-dimensional again

188
00:10:28,790 --> 00:10:32,650
and we have a is going to be called

189
00:10:32,690 --> 00:10:36,210
so the equation that i write down is the most general way that i can

190
00:10:36,210 --> 00:10:37,860
write it down

191
00:10:37,900 --> 00:10:39,500
so we're going to get x

192
00:10:40,790 --> 00:10:43,090
some number c one

193
00:10:43,250 --> 00:10:44,980
plus some c two

194
00:10:45,070 --> 00:10:46,250
times t

195
00:10:46,270 --> 00:10:48,270
what some see three

196
00:10:48,300 --> 00:10:49,820
times square

197
00:10:50,630 --> 00:10:54,690
o i already raise my example my example is gone which you would have seen

198
00:10:54,690 --> 00:10:58,170
this was an eight before and here we had

199
00:10:58,380 --> 00:11:01,880
what did we have minus

200
00:11:01,940 --> 00:11:06,070
we had minus six t and we have plus one t squared

201
00:11:06,110 --> 00:11:08,190
so you recognise these three

202
00:11:08,190 --> 00:11:09,270
i can now

203
00:11:09,320 --> 00:11:11,500
take the derivative

204
00:11:11,570 --> 00:11:14,300
and so i get to se two

205
00:11:16,670 --> 00:11:18,150
c three

206
00:11:18,190 --> 00:11:19,670
times t

207
00:11:19,730 --> 00:11:21,710
and then i get the acceleration

208
00:11:21,730 --> 00:11:22,980
he calls

209
00:11:26,070 --> 00:11:28,070
and now we get some insights

210
00:11:28,070 --> 00:11:29,190
in two

211
00:11:30,440 --> 00:11:32,020
what these quantities

212
00:11:32,980 --> 00:11:34,320
x y

213
00:11:34,340 --> 00:11:35,980
c one

214
00:11:36,020 --> 00:11:36,710
it is

215
00:11:38,190 --> 00:11:42,980
of x at time t equals zero which we often right next zero

216
00:11:44,650 --> 00:11:45,570
is zero

217
00:11:45,590 --> 00:11:47,670
that is where x is

218
00:11:47,710 --> 00:11:49,520
c two

219
00:11:49,610 --> 00:11:51,480
is really the velocity

220
00:11:51,540 --> 00:11:54,360
at time t equal zero because when t zero

221
00:11:54,380 --> 00:11:55,560
that's when

222
00:11:55,610 --> 00:11:56,960
c two

223
00:11:57,040 --> 00:11:58,380
it's the

224
00:11:58,380 --> 00:12:00,840
and the acceleration

225
00:12:00,920 --> 00:12:02,730
is not changing with time

226
00:12:02,770 --> 00:12:03,790
it's too

227
00:12:03,900 --> 00:12:04,900
c three

228
00:12:04,920 --> 00:12:06,920
therefore c three

229
00:12:07,000 --> 00:12:10,290
is half accelerate

230
00:12:10,320 --> 00:12:14,020
it is give you some insight into the meaning of these quantities you can see

231
00:12:14,020 --> 00:12:16,730
you can read now some some physics in there

232
00:12:16,790 --> 00:12:21,150
c one c two and c three can independently be zero

233
00:12:21,170 --> 00:12:23,320
larger than zero or negative

234
00:12:23,400 --> 00:12:27,190
makes no different each one of these combinations is

235
00:12:27,250 --> 00:12:31,860
valid possibility in physics

236
00:12:31,920 --> 00:12:34,670
well we have gravity

237
00:12:34,730 --> 00:12:36,400
an object

238
00:12:37,150 --> 00:12:38,790
influenced by

239
00:12:38,860 --> 00:12:41,630
the gravitational acceleration

240
00:12:41,690 --> 00:12:43,900
and the gravitational acceleration

241
00:12:43,980 --> 00:12:45,880
is a constant

242
00:12:46,000 --> 00:12:47,790
and we write often for that

243
00:12:47,820 --> 00:12:49,630
gravitational acceleration

244
00:12:49,630 --> 00:12:51,540
the letter g

245
00:12:51,570 --> 00:12:53,540
when i drop an object

246
00:12:53,590 --> 00:12:55,630
or throw it vertically up

247
00:12:55,630 --> 00:12:59,540
or throw it vertically downwards all one-dimensional

248
00:12:59,610 --> 00:13:02,190
becomes two-dimensional when i throw it at an angle

249
00:13:02,190 --> 00:13:03,940
i keep it one-dimensional

250
00:13:04,130 --> 00:13:06,920
acceleration is always the same

251
00:13:06,980 --> 00:13:08,820
and that g

252
00:13:08,840 --> 00:13:11,520
gravitational acceleration in boston

253
00:13:11,560 --> 00:13:13,340
nine point eight zero

254
00:13:14,620 --> 00:13:20,040
the second square and it's very little bit for different places on earth

255
00:13:20,060 --> 00:13:23,540
this gravitational acceleration

256
00:13:23,650 --> 00:13:25,150
is independent

257
00:13:25,190 --> 00:13:27,340
of the mass of the object

258
00:13:27,400 --> 00:13:28,460
that i draw

259
00:13:28,480 --> 00:13:30,500
of the speed of the object

260
00:13:30,500 --> 00:13:34,590
of the chemical composition of the object of the size of the object and of

261
00:13:34,610 --> 00:13:37,020
the shape of the object assuming

262
00:13:37,020 --> 00:13:40,250
we have no and direct assuming that these experiments are done

263
00:13:41,210 --> 00:13:42,980
in vacuum

264
00:13:43,000 --> 00:13:47,000
is it obvious that the gravitational acceleration

265
00:13:47,070 --> 00:13:49,570
is independent of all these quantities

266
00:13:49,610 --> 00:13:51,750
by no means

267
00:13:51,770 --> 00:13:53,610
is it true

268
00:13:53,610 --> 00:13:54,920
we think so

269
00:13:55,060 --> 00:13:58,900
i want you to appreciate that it is not obvious and it can not be

270
00:13:58,900 --> 00:14:04,170
proven from first principles

271
00:14:04,210 --> 00:14:06,000
i remember the last time

272
00:14:06,060 --> 00:14:07,690
we dropped an apple

273
00:14:07,710 --> 00:14:11,040
from three meters and we drop another one from

274
00:14:11,090 --> 00:14:12,900
one and a half metres

275
00:14:12,960 --> 00:14:15,230
in your second assignment

276
00:14:15,250 --> 00:14:18,070
which you haven't seen yet i'm asking you to calculate

277
00:14:18,110 --> 00:14:20,340
the gravitational acceleration for me

278
00:14:20,360 --> 00:14:21,750
using these both

279
00:14:22,880 --> 00:14:23,860
and of course

280
00:14:23,860 --> 00:14:26,880
i want you to also tell me what the uncertainty is

281
00:14:26,900 --> 00:14:28,650
in your final answer

282
00:14:28,690 --> 00:14:32,250
and i'd like to help you a little bit

283
00:14:32,320 --> 00:14:33,900
set up

284
00:14:33,920 --> 00:14:34,960
and also

285
00:14:34,980 --> 00:14:36,560
to get these equations

286
00:14:36,570 --> 00:14:38,940
in terms of

287
00:14:40,400 --> 00:14:42,210
whenever we deal with gravity

288
00:14:42,230 --> 00:14:43,440
we get

289
00:14:43,480 --> 00:14:44,770
g in there

290
00:14:44,820 --> 00:14:46,070
so suppose

291
00:14:46,090 --> 00:14:47,520
here the object

292
00:14:47,520 --> 00:14:49,070
at time t equals zero

293
00:14:49,070 --> 00:14:50,840
the apple

294
00:14:50,900 --> 00:14:54,980
and i call that position x zero i call that zero i'm free to chose

295
00:14:54,980 --> 00:14:56,340
my zero position

296
00:14:56,380 --> 00:15:00,230
and i drop it zero speed i just let it go because that's the way

297
00:15:00,270 --> 00:15:01,940
we did it in class

298
00:15:01,940 --> 00:15:04,150
the object goes down

299
00:15:04,190 --> 00:15:07,940
and it hits the floor

300
00:15:09,690 --> 00:15:12,840
the general equations now

301
00:15:12,920 --> 00:15:17,980
which dealing gravity if i call this the increasing value of x

302
00:15:17,980 --> 00:15:19,460
you can choose it differently

303
00:15:19,460 --> 00:15:21,480
this is my choice today

304
00:15:21,520 --> 00:15:23,440
is the following

305
00:15:25,840 --> 00:15:27,340
x zero

306
00:15:27,440 --> 00:15:29,500
let's be zero t

307
00:15:30,360 --> 00:15:31,610
one half

308
00:15:32,770 --> 00:15:33,790
the square

309
00:15:33,800 --> 00:15:34,790
and g now

310
00:15:35,560 --> 00:15:37,770
o point eight

311
00:15:39,520 --> 00:15:42,150
i mean it's the second square

312
00:15:42,210 --> 00:15:43,420
the velocity

313
00:15:43,420 --> 00:15:46,470
and if we do that we get a better model of the

314
00:15:46,490 --> 00:15:48,760
so that's what we're doing this recursively

315
00:15:48,820 --> 00:15:57,130
that's one way of thinking about it

316
00:15:57,150 --> 00:16:00,110
OK so

317
00:16:00,150 --> 00:16:01,550
if you try and do that

318
00:16:01,550 --> 00:16:03,590
in a directed net

319
00:16:03,610 --> 00:16:06,300
you could think about

320
00:16:06,300 --> 00:16:08,630
assuming independence here

321
00:16:08,690 --> 00:16:10,920
and the modelling this

322
00:16:10,970 --> 00:16:14,530
and then

323
00:16:14,550 --> 00:16:17,420
looking at the poster you get when you do inference which is going to be

324
00:16:17,420 --> 00:16:20,460
complicated and then trying to model this

325
00:16:22,110 --> 00:16:25,360
the problem is that if you do it in the directed net

326
00:16:25,380 --> 00:16:29,780
when you learn these weights it tries very hard to make these

327
00:16:31,940 --> 00:16:34,220
because as the assumption of the model

328
00:16:34,300 --> 00:16:39,110
so it'll be willing to get weights they don't actually realise to reconstruct very well

329
00:16:39,150 --> 00:16:42,840
because they're trying to get these to be independent and the posterior

330
00:16:42,880 --> 00:16:45,760
and that's simply because later on you can put in most of his so these

331
00:16:45,760 --> 00:16:47,720
don't actually need to be independent

332
00:16:47,760 --> 00:16:50,010
you're trying to achieve something

333
00:16:50,070 --> 00:16:53,130
but you don't really want to achieve in the end because in the end these

334
00:16:53,130 --> 00:16:55,740
are going to be able to make these people are not independent

335
00:16:55,800 --> 00:16:58,940
so you waste about trying to achieve this independence

336
00:16:59,050 --> 00:17:01,720
as a result of which this doesn't work very well this respected and you've already

337
00:17:01,720 --> 00:17:04,010
made a big loss here

338
00:17:05,170 --> 00:17:08,780
we'll see make these two independent

339
00:17:09,490 --> 00:17:13,270
it doesn't work nearly as well to sort of learn these weights and then assuming

340
00:17:13,270 --> 00:17:18,570
independence here and then learn the model of this stuff

341
00:17:18,610 --> 00:17:20,760
so i want to give you a practical example and then go back to the

342
00:17:20,820 --> 00:17:21,940
modern theory

343
00:17:21,960 --> 00:17:26,380
and we're going to take bigger images of digits the and digits and we get

344
00:17:26,380 --> 00:17:28,420
a all ten different classes

345
00:17:28,470 --> 00:17:33,030
and we can learn more like this five hundred binary features the mccollum like this

346
00:17:33,170 --> 00:17:37,150
by features that we're going to put in the class labels with the ten way

347
00:17:38,360 --> 00:17:40,280
and we can learn the model of

348
00:17:40,300 --> 00:17:44,080
this feature vector with the label and its the joint density models so this is

349
00:17:44,080 --> 00:17:46,260
just another restricted boltzmann machine

350
00:17:46,300 --> 00:17:47,760
the lens the joint density

351
00:17:47,780 --> 00:17:50,420
but this was long greedily

352
00:17:50,460 --> 00:17:53,440
and then we're going be fine-tune you won't talk about much

353
00:17:53,510 --> 00:17:57,150
makes it work quite a bit better but it's too complicated for

354
00:17:57,170 --> 00:17:59,510
so basically think we just did this

355
00:17:59,510 --> 00:18:03,420
and then we can look at what we got

356
00:18:03,420 --> 00:18:06,090
so i might come back to the fine tuning of this time but i'm going

357
00:18:06,090 --> 00:18:07,630
to talk about it

358
00:18:07,650 --> 00:18:27,260
i want shake the model that we get

359
00:18:27,280 --> 00:18:28,800
OK so this is that net

360
00:18:28,820 --> 00:18:32,650
twenty by twenty eight five hundred five hundred two thousand ten

361
00:18:32,650 --> 00:18:39,380
and we can give it an image like this one

362
00:18:39,400 --> 00:18:41,650
and we can

363
00:18:41,690 --> 00:18:46,070
it recognizes so what i'm doing now is running this way

364
00:18:46,070 --> 00:18:49,720
so having trained as generative modelling now run it as a sort of just going

365
00:18:49,720 --> 00:18:51,240
to model

366
00:18:51,260 --> 00:18:55,340
and stochastic so these keep changing but has no doubt that is is very short

367
00:18:55,340 --> 00:18:57,130
so for

368
00:18:57,150 --> 00:19:00,420
run faster you can see the top ones don't change that much

369
00:19:00,440 --> 00:19:04,360
rather the some the fairly stable like that one there

370
00:19:07,780 --> 00:19:09,420
i can show some other digit

371
00:19:14,030 --> 00:19:17,440
it's less sure about that but it's most of the times has made occasional thinks

372
00:19:17,440 --> 00:19:19,170
it's a three

373
00:19:19,170 --> 00:19:22,840
and so unreasonable

374
00:19:24,190 --> 00:19:28,130
so i can recognise OK in fact you does quite a good job recognition

375
00:19:28,150 --> 00:19:31,170
this very short that surviving woman to that

376
00:19:31,170 --> 00:19:34,150
i given a tricky one

377
00:19:35,380 --> 00:19:36,940
and he will express

378
00:19:39,220 --> 00:19:41,280
keeping changes mind

379
00:19:41,340 --> 00:19:45,150
it happens to and on the right answer which is that's just constraints actually the

380
00:19:45,150 --> 00:19:47,760
fact that this isn't in the last column means that

381
00:19:47,780 --> 00:19:50,470
the most frequent answer gives is made

382
00:19:50,470 --> 00:19:53,760
but only just

383
00:19:53,780 --> 00:19:59,150
we can deal with various kinds of noise quite well

384
00:19:59,190 --> 00:20:02,440
so we think this is the one or seven most of the time

385
00:20:03,110 --> 00:20:07,880
but what's most interesting about this is when you want to generate

386
00:20:09,240 --> 00:20:10,940
i'm gonna run the model

387
00:20:10,960 --> 00:20:14,010
as a generator

388
00:20:14,030 --> 00:20:17,820
and what's going to happen is this

389
00:20:17,840 --> 00:20:19,280
i'm going to

390
00:20:23,650 --> 00:20:27,510
and i'm just going to go down between these units here with this fixed

391
00:20:27,510 --> 00:20:33,260
so i'm just doing alternating gibbs sampling in restricted boltzmann machine that's always happening cause

392
00:20:33,300 --> 00:20:35,240
that's where the action is

393
00:20:35,260 --> 00:20:37,030
and what will happen is

394
00:20:37,070 --> 00:20:39,570
eleven to various brain states here

395
00:20:42,840 --> 00:20:47,320
and it's impossible future so what they represent because there's just activities neurons

396
00:20:47,340 --> 00:20:49,900
what you would be interested in his mental state

397
00:20:49,970 --> 00:20:52,800
so i'm show you both the brain state here

398
00:20:52,820 --> 00:20:55,510
and the mental state which i'm sure here

399
00:20:55,530 --> 00:20:58,820
you so the way mental state the language of mental states which is this if

400
00:20:58,820 --> 00:21:00,900
i want to tell you one of my brain states

401
00:21:00,900 --> 00:21:04,200
i could try saying you're in fifty three is on the left in the much

402
00:21:04,200 --> 00:21:05,510
good it it

403
00:21:05,510 --> 00:21:07,360
or i could say

404
00:21:07,380 --> 00:21:09,490
this upon active neurons

405
00:21:09,510 --> 00:21:12,780
which is just like the pattern of active neurons you get if i was looking

406
00:21:12,780 --> 00:21:14,690
at the pink elephant

407
00:21:14,700 --> 00:21:20,220
now that's a rather clumsy way of saying of this problem that was the pattern

408
00:21:20,220 --> 00:21:22,860
of the brain state which is like the brain that i get if i was

409
00:21:22,860 --> 00:21:24,420
looking the elephant

410
00:21:25,490 --> 00:21:29,170
so we have a funny way of saying that we have shorthand for that

411
00:21:29,880 --> 00:21:33,420
which is something i saying i've got the perceptron pink elephant

412
00:21:33,440 --> 00:21:38,030
well there really means is some brain stated think the some brain state was like

413
00:21:38,030 --> 00:21:40,240
the one i would have if i was looking the pink elephant

414
00:21:40,260 --> 00:21:43,070
that's your generative model if i ask you

415
00:21:43,070 --> 00:21:45,170
what brings it is this that

416
00:21:45,190 --> 00:21:49,630
well because i can generate from i say the kinds of things to my reference

417
00:21:49,630 --> 00:21:52,720
works like the kinds of things that would normally cause that

418
00:21:52,720 --> 00:21:56,650
so i'm showing the brain states but i'm showing the mental states

419
00:21:56,670 --> 00:21:58,840
by showing the kinds of things that normally cause

420
00:21:58,900 --> 00:22:01,650
so as it runs that's where all the action is

421
00:22:01,690 --> 00:22:03,940
just so you know what's really happening here

422
00:22:03,990 --> 00:22:07,690
i'm showing you what it has in mind by going to time

423
00:22:15,900 --> 00:22:17,490
because that's where the action is

424
00:22:17,490 --> 00:22:22,900
again trenchant each time do it fast

425
00:22:22,900 --> 00:22:24,550
you'll see that after a while

426
00:22:24,590 --> 00:22:29,900
it settles into generating two was once the second generation to the just generated forever

427
00:22:29,970 --> 00:22:32,280
and and all sorts of different things

428
00:22:32,340 --> 00:22:36,200
once we look for the loops you generate even rather bad to use

429
00:22:36,220 --> 00:22:37,190
thank you

430
00:22:37,190 --> 00:22:39,240
this is really running second

431
00:22:39,260 --> 00:22:45,170
but that's important that they can generate because it means you can recognise the two

432
00:22:45,170 --> 00:22:47,600
label for example one

433
00:22:47,620 --> 00:22:51,800
the expert level set and then it may be it passes over example two because

434
00:22:51,800 --> 00:22:56,140
example two might look exactly like example one in terms of its feature vector it's

435
00:22:56,140 --> 00:23:00,690
x-factor so maybe that doesn't seem to things that should be about the same as

436
00:23:00,690 --> 00:23:05,100
the label for the first example and so on and so forth and so the

437
00:23:05,100 --> 00:23:07,760
machine would selectively as

438
00:23:07,970 --> 00:23:12,410
for labels and you could also think of this is the machine selectively asking or

439
00:23:12,410 --> 00:23:19,430
per for suggesting next experiments that the scientist might might try and so on and

440
00:23:19,440 --> 00:23:20,890
so forth

441
00:23:20,930 --> 00:23:22,050
so this is

442
00:23:22,070 --> 00:23:27,730
seventeen people have tried to do with some success there's a project called robot scientist

443
00:23:27,800 --> 00:23:29,480
in the UK

444
00:23:29,490 --> 00:23:34,730
and this is the little snippet from an article that appeared in wired magazine recently

445
00:23:34,730 --> 00:23:37,470
so that there in this case

446
00:23:37,480 --> 00:23:41,940
the human is almost fully out of the loop and there's a little bit of

447
00:23:43,930 --> 00:23:48,200
by humans involved but for the most part of this machine which they call and

448
00:23:48,380 --> 00:23:54,740
carries out the entire scientific process to formulate hypotheses designs and runs experiments analyzes data

449
00:23:54,750 --> 00:23:58,450
decides which experiments right next and so on and so forth so this is the

450
00:23:58,450 --> 00:24:06,010
machine words fully closed loop system or engine for scientific discovery is actually

451
00:24:06,260 --> 00:24:11,000
for certain things are already known and made some some novel discoveries as well so

452
00:24:11,000 --> 00:24:14,890
this is something people are pretty excited about

453
00:24:14,890 --> 00:24:15,680
so let me

454
00:24:15,700 --> 00:24:19,500
now it's a little bit about the BBC

455
00:24:19,530 --> 00:24:25,500
so mathematical framework which will study these problems are introduced some the terms notation that

456
00:24:25,500 --> 00:24:29,260
will be using throughout the talk so there any questions so far in

457
00:24:29,410 --> 00:24:33,770
have lighter stuff and i'll just go into a little bit of the mathematical

458
00:24:33,800 --> 00:24:37,050
foundation framework that will be working

459
00:24:37,070 --> 00:24:38,790
OK so

460
00:24:38,850 --> 00:24:41,990
the typical setup is you have some space h

461
00:24:42,040 --> 00:24:44,600
of hypotheses or models

462
00:24:44,620 --> 00:24:47,510
and our goal is to try to find the best

463
00:24:48,380 --> 00:24:50,640
the hypothesis that set

464
00:24:50,680 --> 00:24:54,630
we have a set AX which is the set of queries or questions we can

465
00:24:54,630 --> 00:24:58,890
ask we can also think of these unlabelled features that we could request labels for

466
00:24:58,990 --> 00:25:03,150
work experiments that we could run and so on and so forth and then the

467
00:25:03,150 --> 00:25:04,390
h star

468
00:25:04,430 --> 00:25:09,430
would be the true model the model that we're trying to identify and it may

469
00:25:09,430 --> 00:25:14,090
or may not belong to the set h so it may have some mismatch between

470
00:25:14,090 --> 00:25:20,350
our actual collection of models and hypotheses and the true model of what's actually going

471
00:25:21,740 --> 00:25:23,790
and there

472
00:25:23,800 --> 00:25:24,990
maybe two

473
00:25:25,000 --> 00:25:27,670
distinct settings here one would be

474
00:25:27,670 --> 00:25:31,780
noise was learning in noiseless learning you'd have an axe

475
00:25:31,800 --> 00:25:33,310
can you request

476
00:25:33,320 --> 00:25:38,090
a label for it can you get why which would just be h star affects

477
00:25:38,090 --> 00:25:39,540
the true label

478
00:25:41,250 --> 00:25:42,560
noisy learning

479
00:25:42,590 --> 00:25:45,290
you would get that label

480
00:25:45,310 --> 00:25:47,430
four response plus noise

481
00:25:47,430 --> 00:25:53,120
and things get trickier more difficult when there is noise but will talk about how

482
00:25:53,120 --> 00:25:57,450
that can be dealt with some of the challenges it presents

483
00:25:57,460 --> 00:26:02,230
so again active learning is the idea of sequentially selecting the most informative queries are

484
00:26:02,230 --> 00:26:09,390
examples to have labels for based on past queries and labels

485
00:26:10,180 --> 00:26:13,990
major type t TV sense of how you might do this

486
00:26:14,000 --> 00:26:18,580
algorithmically out of prison to simple algorithms that

487
00:26:18,590 --> 00:26:22,990
i have been proposed for noiseless active learning in one which is quite well known

488
00:26:24,230 --> 00:26:27,600
method by colin atlas ladner

489
00:26:27,650 --> 00:26:32,270
and here the setting is binary classification so our hypothesis mass

490
00:26:32,300 --> 00:26:38,190
the feature space to space plus one minus one have binary labelling and h stars

491
00:26:38,190 --> 00:26:41,620
assumed to be a member of our collection of hypotheses

492
00:26:41,630 --> 00:26:46,870
and the idea of the algorithm is you initialise

493
00:26:46,930 --> 00:26:50,030
you're set of models to be the complete set

494
00:26:50,130 --> 00:26:54,780
so h one is said to be the whole set of all hypotheses and then

495
00:26:54,780 --> 00:26:59,730
while there's is more than one hypothesis you iterate through these three steps you

496
00:27:00,150 --> 00:27:01,410
so lacked

497
00:27:01,420 --> 00:27:02,870
o point

498
00:27:02,930 --> 00:27:07,200
and unlabeled feature query

499
00:27:07,220 --> 00:27:08,820
in the set of

500
00:27:11,210 --> 00:27:16,250
four new features are queries where there's some disagreement among the hypothesis that are currently

501
00:27:18,080 --> 00:27:22,870
so this is just there are some that it appeared picking an x where some

502
00:27:22,870 --> 00:27:24,850
of the hypotheses are saying

503
00:27:24,870 --> 00:27:27,190
plus one in summer saying minus one

504
00:27:27,200 --> 00:27:30,880
there's been no value depicting a point where they are all in agreement

505
00:27:30,890 --> 00:27:33,900
you query with that point you get the label

506
00:27:33,910 --> 00:27:35,300
and then you simply

507
00:27:36,160 --> 00:27:40,680
your current set of hypotheses to retain only those the degree

508
00:27:40,690 --> 00:27:43,220
with the label you just acquired

509
00:27:43,240 --> 00:27:48,410
OK so that will reduce the size of its surviving you have a new set

510
00:27:48,410 --> 00:27:53,540
of viable hypotheses h survive plus one and that will be decreasing on each step

511
00:27:53,540 --> 00:27:57,240
of this process because you are insisting that there's always going to be some disagreement

512
00:27:57,240 --> 00:27:59,210
in every query make

513
00:27:59,310 --> 00:28:07,870
so that's the the algorithm a few pieces of notation that will refer to later

514
00:28:07,870 --> 00:28:08,660
this is

515
00:28:08,700 --> 00:28:13,670
usually called the region of disagreement the set of hypotheses are the region of feature

516
00:28:13,670 --> 00:28:20,700
space where there is disagreement among the hypotheses and this set of viable hypotheses is

517
00:28:20,700 --> 00:28:22,980
called the version space

518
00:28:24,690 --> 00:28:31,660
this album was actually propose more about online streaming fashion were just unlabelled examples would

519
00:28:31,660 --> 00:28:34,840
come along and whenever one came along the

520
00:28:34,870 --> 00:28:39,230
there was some disagreement and then you would collectively before so it's a really simple

521
00:28:39,230 --> 00:28:43,500
idea and you can see how this simply pairs down the set of hypotheses intelligence

522
00:28:43,500 --> 00:28:46,380
one remaining in that must be the correct one

523
00:28:46,460 --> 00:28:50,020
so that's the the KL algorithm

524
00:28:50,050 --> 00:28:55,710
another idea that's very similar and a bit older and perhaps even older than me

525
00:28:55,710 --> 00:29:01,040
mean certainly in the late sixties is something that you might call generalized binary search

526
00:29:01,040 --> 00:29:05,180
for the splitting algorithm and i'll actually be talking a little bit more about this

527
00:29:05,180 --> 00:29:06,080
one and two

528
00:29:06,120 --> 00:29:09,060
and some non metallic elements over here

529
00:29:09,060 --> 00:29:12,040
five six and seven and so you can imagine that

530
00:29:12,100 --> 00:29:13,680
if you mix these

531
00:29:13,730 --> 00:29:17,520
if you take a sodium new mexico with chlorine you get sodium chloride

532
00:29:17,520 --> 00:29:22,810
but there's nothing saying you can't take magnesium and mixed with oxygen and magnesium oxide

533
00:29:22,810 --> 00:29:27,290
and you would expect that there would be much stable compound because instead of plus

534
00:29:27,290 --> 00:29:32,000
one attracting plus one naive plus two attracting plus

535
00:29:32,020 --> 00:29:34,750
excuse me attracting minus two

536
00:29:34,790 --> 00:29:40,100
plus two attracting minus two so coulombic forces are much much greater

537
00:29:40,120 --> 00:29:42,000
and that will be reflected in what

538
00:29:42,020 --> 00:29:45,180
higher melting point higher boiling point

539
00:29:46,120 --> 00:29:48,330
resistance to reactivity

540
00:29:48,370 --> 00:29:51,750
so what does it strike you or they may be magnesium oxide one of its

541
00:29:51,750 --> 00:29:57,870
applications would be refractory is that is to say brickwork and high temperature furnaces maybe

542
00:29:57,910 --> 00:29:59,540
tiles on the shuttle

543
00:29:59,560 --> 00:30:02,060
to resist high temperatures because of

544
00:30:02,060 --> 00:30:05,690
the high internal bonding

545
00:30:05,810 --> 00:30:07,040
you see there is the

546
00:30:07,040 --> 00:30:09,480
there's there's this system here

547
00:30:09,500 --> 00:30:14,390
chemistry is in the litany of facts we started with a few simple assumptions

548
00:30:14,410 --> 00:30:20,600
and look at what we're doing we're designing systems building engineering systems materials choices

549
00:30:20,620 --> 00:30:22,140
it's fantastic

550
00:30:22,190 --> 00:30:25,960
OK so we can do this one more time was to one more time

551
00:30:25,980 --> 00:30:27,310
actually something else

552
00:30:27,310 --> 00:30:31,580
sure another way to to get a sense of these energies and for that i

553
00:30:31,580 --> 00:30:35,870
want to look at the energy starting from real material see up until now been

554
00:30:35,870 --> 00:30:40,330
talking about gas facing atoms all this stuff so let's look at this reaction sodium

555
00:30:40,350 --> 00:30:42,460
solid plus

556
00:30:42,500 --> 00:30:45,730
chlorine gas it's its diatomic

557
00:30:45,770 --> 00:30:49,980
molecule and i want that to react to give me sodium chloride

558
00:30:50,000 --> 00:30:52,020
as the solid and crystal

559
00:30:52,060 --> 00:30:53,870
i one ordered solid

560
00:30:54,690 --> 00:30:57,680
for this i need to invoke a couple of

561
00:30:57,730 --> 00:31:00,680
bits of science first one is has this law

562
00:31:00,690 --> 00:31:04,500
passes law

563
00:31:04,690 --> 00:31:08,560
has has lost states that for any chemical reaction

564
00:31:08,600 --> 00:31:10,810
the energy change

565
00:31:10,810 --> 00:31:12,830
the energy change

566
00:31:12,850 --> 00:31:14,750
is path independent

567
00:31:14,790 --> 00:31:16,710
path independent that is to say

568
00:31:16,730 --> 00:31:17,890
but i can now

569
00:31:17,890 --> 00:31:23,310
i rewrote this sodium plus chlorine reaction go different way but i still the same

570
00:31:23,430 --> 00:31:24,960
change in energy

571
00:31:26,160 --> 00:31:31,120
it's because the state function is the same thing as gravitational energy whether you take

572
00:31:31,120 --> 00:31:35,480
the elevator to the top of the hancock tower with you walk up the stairs

573
00:31:35,520 --> 00:31:40,480
the change in gravitational potential is identical you might be winded doing at the second

574
00:31:40,480 --> 00:31:44,430
way but when you get to the top and you're at the sixtieth story you're

575
00:31:44,460 --> 00:31:47,730
gravitational potential is independent of how you got there

576
00:31:47,770 --> 00:31:49,910
that's what this is saying it's an analogy

577
00:31:49,950 --> 00:31:54,180
energy change is path independent so now i'm going to break this into into elementary

578
00:31:54,180 --> 00:31:58,910
steps and look at the relative contributions so what do we do so far we

579
00:31:58,910 --> 00:32:01,390
talked about this reaction here we had

580
00:32:01,520 --> 00:32:05,830
chloride ions in the gas phase plus sodium ions

581
00:32:05,890 --> 00:32:11,060
in the gas phase right we started with geisha sodium to make geisha sodium ion

582
00:32:11,390 --> 00:32:17,500
gauges atomic chlorine to make gaseous chloride ions through electron transfer all the gas phase

583
00:32:17,520 --> 00:32:19,390
very idealistic but

584
00:32:19,410 --> 00:32:20,410
that the with

585
00:32:20,450 --> 00:32:24,460
the world works so i want to get to their starting from real sodium real

586
00:32:24,460 --> 00:32:30,000
chlorine so first thing i want to do is to convert the sodium into vapor

587
00:32:30,060 --> 00:32:32,710
so this is sodium goes to sodium gas

588
00:32:32,730 --> 00:32:34,660
and then take sodium gas

589
00:32:34,690 --> 00:32:35,680
and when

590
00:32:35,730 --> 00:32:38,750
make this into sodium

591
00:32:38,750 --> 00:32:43,160
gas plus electron or by the way this is called sublimation isn't it

592
00:32:43,210 --> 00:32:45,770
this process of sublimation solid to vapor

593
00:32:45,790 --> 00:32:49,350
sublimation this is called ionisation is an

594
00:32:49,390 --> 00:32:55,850
gas phase goes gas phase species loses an electron that's the strict definition of ionisation

595
00:32:55,870 --> 00:32:59,620
summary there with sodium chloride i got to do a little bit more heavy lifting

596
00:32:59,620 --> 00:33:04,080
here because core starts as a diatomic molecule the first thing i got to do

597
00:33:04,080 --> 00:33:05,750
with biases that have

598
00:33:05,750 --> 00:33:08,410
so this is called dissociation

599
00:33:08,460 --> 00:33:10,690
so i need to dissociate

600
00:33:10,710 --> 00:33:11,890
the chloride

601
00:33:11,890 --> 00:33:12,960
chlorine rather

602
00:33:13,020 --> 00:33:18,310
and now i've got to convert atomic chlorine into iron chlorine so i'm going to

603
00:33:18,310 --> 00:33:19,770
do that

604
00:33:20,500 --> 00:33:22,500
adding electron

605
00:33:22,570 --> 00:33:25,950
and this reaction here is the inverse of ionisation isn't it

606
00:33:25,960 --> 00:33:30,410
it's ionisation be i take one of the electrons and carina away here i'm actually

607
00:33:30,410 --> 00:33:36,580
throwing electron to chlorine so this reaction is called electron affinity

608
00:33:36,580 --> 00:33:38,410
electron affinity

609
00:33:38,430 --> 00:33:41,040
so you think of electron affinity is sort of

610
00:33:41,080 --> 00:33:44,180
the ionisation reverse of the iron

611
00:33:44,230 --> 00:33:47,060
it's it's the minus loses

612
00:33:47,140 --> 00:33:51,210
and this one here this reaction is what we call crystallisation

613
00:33:53,270 --> 00:33:55,410
so those are the five steps

614
00:33:56,250 --> 00:33:58,430
let's see if we can find information

615
00:33:58,460 --> 00:34:00,060
i call this one

616
00:34:00,100 --> 00:34:02,600
let's say i think unlabelled this one too

617
00:34:02,600 --> 00:34:09,370
this that the talk i should confess that i mean it's not so

618
00:34:09,680 --> 00:34:15,720
to me to the top of the talk is going on manifolds my by manifest

619
00:34:16,700 --> 00:34:19,300
the first delicious

620
00:34:19,420 --> 00:34:22,300
can actually

621
00:34:24,810 --> 00:34:27,850
the first half of the total

622
00:34:27,990 --> 00:34:32,460
and then you can go either toronto instead

623
00:34:32,600 --> 00:34:36,800
you might be running and you may be

624
00:34:36,870 --> 00:34:40,550
but if you know the kind of the text that i'm talking about i'm going

625
00:34:40,550 --> 00:34:42,400
to discuss about

626
00:34:42,410 --> 00:34:47,340
to the riemannian manifolds and the second part of the talk is more kind of

627
00:34:47,340 --> 00:34:50,080
like entertainment purposes of

628
00:34:50,090 --> 00:34:53,190
they time and then

629
00:34:53,190 --> 00:34:58,050
i'm not i and then

630
00:34:58,260 --> 00:35:02,050
this is some interesting applications of the mythos

631
00:35:02,110 --> 00:35:07,130
the is the topological space in the parameters

632
00:35:07,160 --> 00:35:09,430
neighborhoods such as them amazon

633
00:35:09,440 --> 00:35:10,930
thanks for instance

634
00:35:10,940 --> 00:35:12,710
manifold if

635
00:35:12,720 --> 00:35:16,460
i can look at the angles on the sphere is that it is that by

636
00:35:16,830 --> 00:35:19,150
being no sense but the

637
00:35:19,160 --> 00:35:26,380
because scale remain part of the to see it applies so the structure will be

638
00:35:26,380 --> 00:35:32,380
complicated in this case a three sphere but constructor is medium so this what you

639
00:35:32,470 --> 00:35:36,580
need have to remember actually but the is by

640
00:35:36,600 --> 00:35:44,180
some of the right person is considered them for my interaction with the

641
00:35:44,210 --> 00:35:50,980
many many some other examples of the manifold here you see brownouts and this is

642
00:35:50,980 --> 00:35:54,020
the same thing actually happened or not

643
00:35:54,040 --> 00:36:02,660
two and this is a notable institute and climb by the same thing topologically speaking

644
00:36:02,680 --> 00:36:10,270
all right then part started to grow up to be talking about a group of

645
00:36:10,290 --> 00:36:18,250
the same and also to the binary operation and by these are properties is closely

646
00:36:18,250 --> 00:36:22,480
associated with an identity element and a

647
00:36:22,510 --> 00:36:28,220
there are versus to each member in the set for the set of integers under

648
00:36:28,220 --> 00:36:33,070
addition about the identities the group of

649
00:36:33,100 --> 00:36:39,700
set of integers under multiplication is not why because the antigen is not an integer

650
00:36:39,720 --> 00:36:43,910
so that and

651
00:36:43,920 --> 00:36:47,140
so x is all

652
00:36:47,290 --> 00:36:48,660
this talk

653
00:36:48,690 --> 00:36:54,280
this it's the properties for instance it opens

654
00:36:54,340 --> 00:36:55,610
racial numbers

655
00:36:55,630 --> 00:37:00,850
the multiplication is the subset is closed between south of

656
00:37:01,790 --> 00:37:03,410
identity right

657
00:37:03,600 --> 00:37:09,090
the set of a set of negative relational numbers are not because identity is not

658
00:37:09,090 --> 00:37:12,100
in the subset so it's not just

659
00:37:13,600 --> 00:37:21,390
the the taliban thing about committed to see noncommutative the set of points to buy

660
00:37:21,390 --> 00:37:24,510
and square meters is under my it's

661
00:37:24,670 --> 00:37:30,060
application and this is called the general linear group gln

662
00:37:31,190 --> 00:37:37,950
so the spatial which is the number

663
00:37:39,350 --> 00:37:43,100
constraints so is out subgroup of that

664
00:37:43,190 --> 00:37:45,510
topological spaces

665
00:37:45,510 --> 00:37:49,280
so we are as i am moving concepts

666
00:37:49,320 --> 00:37:58,320
now let's go to topological spaces topological spaces in a city is about a it's

667
00:37:58,480 --> 00:38:05,690
a better inside is that is out of an empty set at an intersection of

668
00:38:05,760 --> 00:38:07,690
in the city

669
00:38:07,700 --> 00:38:09,130
so in

670
00:38:09,130 --> 00:38:14,570
this is hard to define a topology since in this she of course consists

671
00:38:14,760 --> 00:38:17,450
after the topological space

672
00:38:17,470 --> 00:38:18,960
and you can see that

673
00:38:19,860 --> 00:38:27,220
in which contains a point x is called in the neighborhood of the point so

674
00:38:27,300 --> 00:38:36,540
we can define the neighborhood boundaries not disconnect hostile separated space is a topological space

675
00:38:36,640 --> 00:38:39,990
in which this thing points in disjoint neighborhoods

676
00:38:40,000 --> 00:38:48,220
so two points separated which was tend to find a small but still distinct was

677
00:38:48,220 --> 00:38:54,540
there an implied important property which means that the two points on the manifold not

678
00:38:54,550 --> 00:38:59,100
kind of coinciding on the same a point

679
00:38:59,120 --> 00:39:04,220
this kind of a news story that i told you maybe i should be deciding

680
00:39:05,250 --> 00:39:08,100
number forms is the most of

681
00:39:08,100 --> 00:39:12,220
is what you see in the middle here

682
00:39:12,240 --> 00:39:14,040
these are

683
00:39:14,100 --> 00:39:15,540
measurements of

684
00:39:15,540 --> 00:39:17,600
no lines was known

685
00:39:17,660 --> 00:39:22,640
wavelengths in the laboratory this is just the calibration here and this is the calibration

686
00:39:22,640 --> 00:39:25,140
this is the spectrum of the galaxy

687
00:39:25,180 --> 00:39:28,080
and what you see here are two guidelines

688
00:39:28,080 --> 00:39:33,430
those are absorption lines every of the stars in the galaxy

689
00:39:33,430 --> 00:39:36,750
they have shifted relative to the

690
00:39:36,810 --> 00:39:40,470
wavelengths in our laboratory by the way one of those lines is the same line

691
00:39:40,470 --> 00:39:41,930
that are used for

692
00:39:42,310 --> 00:39:44,910
pores which is the calcium k absorption lines

693
00:39:44,970 --> 00:39:48,160
the other one is the calcium h two option one h has nothing to do

694
00:39:48,160 --> 00:39:49,700
with hydrogen

695
00:39:49,750 --> 00:39:56,390
and it's been shifted over the distance usually indicated by the small arrows

696
00:39:56,410 --> 00:39:57,750
and if you

697
00:39:57,850 --> 00:40:02,410
measure now the velocity you find eleven hundred fifty kilometres per second

698
00:40:02,410 --> 00:40:05,200
and if you use today's value of hubble's law

699
00:40:05,220 --> 00:40:08,910
this object is fifty two million light years away from us

700
00:40:09,140 --> 00:40:10,850
you go to this object

701
00:40:10,890 --> 00:40:13,060
which is far away

702
00:40:13,080 --> 00:40:16,910
according to hubble's law it has a higher speed receding speed

703
00:40:16,910 --> 00:40:20,370
and you see the spectrum here this is the spectrum and you see those two

704
00:40:20,370 --> 00:40:23,580
absorption lines have shifted all the way

705
00:40:23,640 --> 00:40:26,080
and out of that then follows the

706
00:40:26,100 --> 00:40:30,350
radial velocity which in this case is seven percent of the speed of light twenty

707
00:40:31,170 --> 00:40:37,770
thousand kilometres per second which this object at one billion light years away from us

708
00:40:37,810 --> 00:40:40,370
and when i go to this one here in the corner it's hard to see

709
00:40:40,370 --> 00:40:42,470
which one it is

710
00:40:42,480 --> 00:40:47,430
the absorption lines have shifted even further you see the absorption lines here

711
00:40:47,430 --> 00:40:51,100
and that object is going was twenty percent of the speed of light

712
00:40:52,200 --> 00:40:55,520
then it would be roughly at the distance of two point eight

713
00:40:55,560 --> 00:41:00,390
a billion light years

714
00:41:00,390 --> 00:41:02,870
the most money

715
00:41:02,930 --> 00:41:05,680
work on hubble's law was done by

716
00:41:05,700 --> 00:41:07,000
the group the the

717
00:41:07,020 --> 00:41:09,890
leadership of wendy freedman

718
00:41:11,680 --> 00:41:15,720
when we use data from the hubble space telescope

719
00:41:15,770 --> 00:41:18,160
and she measured

720
00:41:18,200 --> 00:41:20,080
the doppler shift

721
00:41:20,120 --> 00:41:22,350
and the distance

722
00:41:22,540 --> 00:41:26,560
a few hundred object distance is always the can of worms

723
00:41:26,600 --> 00:41:28,270
and she came up

724
00:41:29,060 --> 00:41:31,430
presently the most reliable value

725
00:41:31,450 --> 00:41:34,540
for the

726
00:41:34,580 --> 00:41:36,540
the hubble's constant

727
00:41:36,620 --> 00:41:38,080
let me get the

728
00:41:38,080 --> 00:41:43,370
next slide if i succeed

729
00:41:43,410 --> 00:41:46,520
this is when the freedman's work

730
00:41:46,560 --> 00:41:51,810
forget what you see here just look at what you see here is this sense

731
00:41:51,850 --> 00:41:56,750
so the foreigners objectivity was able to get a reliable distance four

732
00:41:56,770 --> 00:41:59,250
is four hundred mega part six

733
00:41:59,350 --> 00:42:03,970
that's the stunning distance by the way it's about one three one point three billion

734
00:42:04,000 --> 00:42:05,330
light years

735
00:42:05,330 --> 00:42:09,500
and she was able to measure the radial velocities up to about ten percent of

736
00:42:09,500 --> 00:42:10,850
the speed of light

737
00:42:10,870 --> 00:42:14,390
velocities of thirty thousand kilometres per second

738
00:42:14,500 --> 00:42:17,160
so she can draw this line

739
00:42:17,200 --> 00:42:20,600
which is the linear relationship between velocity and distance

740
00:42:20,720 --> 00:42:22,980
and out of that line comes home law

741
00:42:23,000 --> 00:42:24,330
and she concludes

742
00:42:24,350 --> 00:42:26,680
that is very close to seventy two

743
00:42:26,700 --> 00:42:30,200
kilometres per second mega part six plus and minus if you

744
00:42:30,220 --> 00:42:34,220
i used seventy just to round it off

745
00:42:34,290 --> 00:42:37,930
what is interesting

746
00:42:37,950 --> 00:42:40,080
that's how small

747
00:42:40,100 --> 00:42:42,100
in his entire data

748
00:42:42,100 --> 00:42:43,660
the velocities rule

749
00:42:43,660 --> 00:42:46,390
less than eleven hundred kilometres per second

750
00:42:46,480 --> 00:42:48,240
that in scale here

751
00:42:48,290 --> 00:42:53,680
this already has two thousand kilometres per second so that only data in this team

752
00:42:53,700 --> 00:42:57,770
proportion here when he doesn't even have any day doesn't even use them and the

753
00:42:57,770 --> 00:43:02,450
reason why he doesn't use them he says it's too close it's not really representative

754
00:43:02,450 --> 00:43:04,640
forty what we call the hubble flow

755
00:43:04,660 --> 00:43:07,240
so she stays away from the local stuff

756
00:43:07,310 --> 00:43:10,270
but nevertheless based on that very local stuff

757
00:43:10,310 --> 00:43:12,370
which is not even put in here

758
00:43:14,220 --> 00:43:15,140
with his

759
00:43:15,140 --> 00:43:16,680
the relationship

760
00:43:16,740 --> 00:43:19,450
which was monumental

761
00:43:20,740 --> 00:43:25,180
in the history of mankind because it puts the universe

762
00:43:25,200 --> 00:43:27,830
at the very different

763
00:43:27,830 --> 00:43:29,020
level then

764
00:43:29,120 --> 00:43:31,470
what people thought before

765
00:43:31,470 --> 00:43:32,680
the universe

766
00:43:36,740 --> 00:43:41,140
so let's now ask yourself the question what does this all mean

767
00:43:41,310 --> 00:43:44,790
the first thing that may come to mind

768
00:43:44,810 --> 00:43:49,000
since all objects i'm moving away from us

769
00:43:49,060 --> 00:43:52,700
you may think that you are very special we all like to think that we

770
00:43:52,700 --> 00:43:54,350
have very special

771
00:43:54,370 --> 00:43:56,100
so you may even think

772
00:43:56,120 --> 00:43:58,120
that you are at the center of the universe

773
00:43:58,140 --> 00:44:01,370
because everything moves away from you

774
00:44:03,640 --> 00:44:07,250
persuasive is to think that there was a time in the past when there was

775
00:44:07,250 --> 00:44:08,790
a huge explosion

776
00:44:08,810 --> 00:44:11,290
which we refer to as the big bang

777
00:44:11,370 --> 00:44:13,810
when all of this happened

778
00:44:13,870 --> 00:44:17,020
and there were galaxies with large speeds

779
00:44:17,060 --> 00:44:20,000
in the explosion they are now the ones that forest away from us so to

780
00:44:20,000 --> 00:44:24,060
have the highest speed and some had a low-speed speed so that's the picture that

781
00:44:24,060 --> 00:44:27,370
presents itself so little bit naive though and

782
00:44:27,450 --> 00:44:30,620
partially wrong

783
00:44:30,620 --> 00:44:34,750
however the idea of the big bang theory that there was such an explosion

784
00:44:34,810 --> 00:44:36,620
a long time ago

785
00:44:36,700 --> 00:44:38,310
that still holds

786
00:44:38,310 --> 00:44:40,160
and that is considered the birth

787
00:44:40,180 --> 00:44:42,620
of our universe

788
00:44:42,640 --> 00:44:44,560
so now comes the question

789
00:44:44,620 --> 00:44:48,450
when did this big bang walker

790
00:44:49,500 --> 00:44:52,240
we could make

791
00:44:52,250 --> 00:44:55,450
a simple assumption perhaps not quite accurate

792
00:44:55,500 --> 00:44:58,790
that the velocity which was all these galaxies are moving

793
00:44:58,790 --> 00:45:02,870
are a subset of this one GEO dataset and we're using it to make predictions

794
00:45:02,900 --> 00:45:06,380
so we said okay cool we see these fifty nine samples that the ovarian ones

795
00:45:06,630 --> 00:45:09,060
let's go and take a look at them so the very first thing we did

796
00:45:09,060 --> 00:45:12,100
with these fifty nine samples so we said let's go back to the GEO dataset

797
00:45:12,100 --> 00:45:13,540
and see if we can match them up

798
00:45:13,670 --> 00:45:14,820
and when we did

799
00:45:14,830 --> 00:45:16,400
here's what we found so

800
00:45:16,500 --> 00:45:20,580
what if the names matched up for all the fish for all the fifty nine

801
00:45:20,580 --> 00:45:25,960
samples we should see fifty nine red squares lying on this blue diagonal white squares

802
00:45:26,020 --> 00:45:29,340
you see lying on the diagonal

803
00:45:29,350 --> 00:45:31,830
this is not a hard counting question

804
00:45:33,630 --> 00:45:37,890
forty three of the samples they got the labels wrong for sixteen they didn't get

805
00:45:37,890 --> 00:45:41,320
the labels wrong or at least the problem is for the sixteen we can tell

806
00:45:41,360 --> 00:45:45,380
the reason we can tells for those sixteen they scrambled the gene labels so badly

807
00:45:45,380 --> 00:45:47,990
that we don't know what samples they correspond to

808
00:45:48,010 --> 00:45:53,400
what this means is that for the validation data set every single sample is incorrect

809
00:45:53,410 --> 00:45:57,270
for two drugs they've have been using in clinical trials for two years

810
00:45:57,290 --> 00:45:59,620
we think this is disturbing

811
00:45:59,670 --> 00:46:04,160
so what happened next we pointed this out at the end of january

812
00:46:04,180 --> 00:46:05,520
no response

813
00:46:06,320 --> 00:46:08,600
we then said can we do anything else

814
00:46:08,620 --> 00:46:12,050
and it occurred to us that they said well we will show you in

815
00:46:12,060 --> 00:46:16,090
but the reviewers approved about sending it to the NCI

816
00:46:16,100 --> 00:46:20,400
now the NCI in the US is a federally funded institutions and what that means

817
00:46:20,650 --> 00:46:22,140
is that they are subject to federal law

818
00:46:22,690 --> 00:46:26,080
specifically the freedom of information act so

819
00:46:26,090 --> 00:46:30,820
in april we filed a request with the NCI to get the report under the

820
00:46:30,820 --> 00:46:35,610
freedom of information act and the start of a redacted version of the report was

821
00:46:35,610 --> 00:46:39,900
indeed supply and we looked at we found a few things that are rather interesting

822
00:46:39,900 --> 00:46:44,040
in the report or work in the report the two main things that we found

823
00:46:44,040 --> 00:46:48,770
were the first review committee that went through the stuff people evaluated set by the

824
00:46:48,770 --> 00:46:53,410
way we could figure out from the data been published how to do this

825
00:46:53,430 --> 00:46:56,790
the only way we got because there was extra information supplied to us and we

826
00:46:56,800 --> 00:46:59,330
really recommend the investigators problem

827
00:46:59,420 --> 00:47:02,510
so that's one thing the other thing that we found rather disturbing was what was

828
00:47:02,680 --> 00:47:07,540
there specifically this report makes no mention of those problems with cisplatin pemetrexed that i

829
00:47:07,540 --> 00:47:09,760
just told you it's not there

830
00:47:10,740 --> 00:47:13,660
we pointed this out in may and also in may we as the national cancer

831
00:47:13,660 --> 00:47:16,690
institute what do you think about what's going on and what they said let's look

832
00:47:16,690 --> 00:47:20,330
at the trials we actually don't find those three coincidental tries to find another one

833
00:47:20,380 --> 00:47:24,910
to phase three actually based on that they were investigated the rationale again

834
00:47:25,000 --> 00:47:28,730
that signature from the phase three clinical trial in the middle of the trial that's

835
00:47:28,730 --> 00:47:29,620
been made

836
00:47:29,630 --> 00:47:32,760
so we said okay is there anything further that's going to happen with these three

837
00:47:32,760 --> 00:47:34,080
ongoing trials

838
00:47:34,100 --> 00:47:35,300
nothing happened

839
00:47:35,320 --> 00:47:37,480
nothing happened for two more months

840
00:47:37,510 --> 00:47:41,220
and then in mid-july we found out something new that to be orthogonal from normal

841
00:47:42,810 --> 00:47:48,910
one of the p i used to claim he was a rhodes scholar the rhodes

842
00:47:48,910 --> 00:47:51,400
trust in britain says no no he wasn't

843
00:47:51,400 --> 00:47:53,450
so indeed

844
00:47:53,460 --> 00:47:56,670
it appears there was some CV fudging involved now

845
00:47:56,680 --> 00:48:00,140
what happened was that i knew there are a few statisticians would be talking about

846
00:48:00,140 --> 00:48:03,290
saying maybe you we should write letters and so i emailed a few of them

847
00:48:03,290 --> 00:48:05,770
the this came out and said you know if you want to write a letter

848
00:48:05,770 --> 00:48:08,370
now's about the best time

849
00:48:09,130 --> 00:48:14,990
the following monday three days later there's water from thirty one thirty three by statisticians

850
00:48:15,000 --> 00:48:19,690
find if you that you like and the cancer chancellor comments to do you have

851
00:48:19,690 --> 00:48:25,390
accomplished something monumental be triggered a public expression of outrage from file statisticians who call

852
00:48:25,540 --> 00:48:28,400
but the thing about this letter was that it went to newly appointed head of

853
00:48:28,400 --> 00:48:32,930
the national cancer institute have harold varmus and to do the only and to the

854
00:48:33,720 --> 00:48:35,810
so this one gets some coverage

855
00:48:35,820 --> 00:48:38,050
so what happened

856
00:48:38,070 --> 00:48:39,650
it suspended the trials

857
00:48:39,660 --> 00:48:43,740
this has since been covered just to be in a few other outlets like NPR

858
00:48:43,740 --> 00:48:49,500
science teacher and some other fly-by-night journals and a few other investigations are underway there's

859
00:48:49,500 --> 00:48:53,420
actually a new google were devoted entirely to reproducible research and things like that

860
00:48:54,910 --> 00:48:57,820
as we've been looking at this there's a caveat that i think we should keep

861
00:48:57,820 --> 00:49:02,800
in mind and that caveat is that unfortunately some of these mistakes like the one

862
00:49:02,810 --> 00:49:04,340
we've seen them before

863
00:49:04,350 --> 00:49:07,430
this is not the only time we've seen some of these examples going back to

864
00:49:07,460 --> 00:49:10,600
two thousand two two thousand three two thousand five

865
00:49:10,640 --> 00:49:14,860
these types of errors have been around for a while this is an egregious combination

866
00:49:14,870 --> 00:49:18,240
but the problem there so some observations

867
00:49:19,250 --> 00:49:21,370
the most common mistake

868
00:49:21,380 --> 00:49:27,040
are simple once for example statistics simple one here for genomics is complete confounding in

869
00:49:27,070 --> 00:49:31,830
the experimental design others involve mixing up the sample labels team levels things that are

870
00:49:31,830 --> 00:49:33,290
easy to do in excel

871
00:49:33,310 --> 00:49:35,130
OK those are easy to mistake

872
00:49:35,180 --> 00:49:38,500
now the funding about simple mistakes is that if you see that very easy to

873
00:49:39,380 --> 00:49:41,650
but if the documentation is poor

874
00:49:41,660 --> 00:49:43,160
you won't see them

875
00:49:43,170 --> 00:49:47,740
so they will slip by because our intuition is no good and what that means

876
00:49:47,770 --> 00:49:51,370
is that if you go out to literature we sort of suspects

877
00:49:51,380 --> 00:49:55,700
the most simple mistakes are more common than we would like to know

878
00:49:55,800 --> 00:49:58,190
now what would we like to have happened

879
00:49:58,200 --> 00:50:02,160
well for papers we've got a little thing of saying here's some things we really

880
00:50:02,160 --> 00:50:04,870
would like to see in addition to data like this stuff that you know we

881
00:50:04,870 --> 00:50:09,230
really like some idea of if you're gonna supplies for the table qualifications please label

882
00:50:09,260 --> 00:50:10,360
the columns

883
00:50:10,370 --> 00:50:15,760
her examples are which and provide home so these are some other things and these

884
00:50:15,760 --> 00:50:20,910
are recommendations for papers but we think they should be absolute requirements before start clinical

885
00:50:20,910 --> 00:50:24,160
and use that structure the top-down way to find solutions

886
00:50:24,900 --> 00:50:26,670
this approach

887
00:50:26,690 --> 00:50:29,680
has the drawback because it doesn't have an explicit

888
00:50:30,030 --> 00:50:35,130
inter level structure makes a top-down process is a little bit

889
00:50:36,390 --> 00:50:37,960
four pieces at all

890
00:50:37,980 --> 00:50:40,010
two thousand five hundred

891
00:50:40,050 --> 00:50:43,360
maybe an explicit representation likely

892
00:50:43,370 --> 00:50:47,780
horizontal and vertical edges so that the neighborhood would be a good thing and he

893
00:50:47,780 --> 00:50:50,990
used to quite for them to do that

894
00:50:51,010 --> 00:50:54,550
unfortunately it is known in computer vision at least

895
00:50:55,840 --> 00:50:57,460
i think a paper of

896
00:51:01,020 --> 00:51:03,380
forgotten mention now

897
00:51:03,400 --> 00:51:06,000
there are very and

898
00:51:07,080 --> 00:51:11,760
we thought what about having a minimum spanning tree based approach in which

899
00:51:11,780 --> 00:51:15,830
this this this talk in which we are going to this ship as well this

900
00:51:15,830 --> 00:51:16,960
should be very

901
00:51:16,970 --> 00:51:20,850
i mean is if i move from the city layout

902
00:51:20,860 --> 00:51:24,550
i'm going to have this is what you are going to have to

903
00:51:24,570 --> 00:51:30,240
solution and it has been shown by psychologists that humans are very good and robust

904
00:51:30,240 --> 00:51:31,600
to show

905
00:51:31,680 --> 00:51:32,940
please time

906
00:51:32,950 --> 00:51:37,340
so for a very long motivations for the rest the

907
00:51:37,360 --> 00:51:41,510
so i'm going to show you because minimum spanning tree algorithm which allows me to

908
00:51:41,520 --> 00:51:43,400
to build up

909
00:51:43,420 --> 00:51:45,750
the bottom of wavelet pyramid

910
00:51:45,790 --> 00:51:48,580
i'm going to find an trivial solution then

911
00:51:48,630 --> 00:51:52,100
basically started approximative solution of TSP

912
00:51:52,120 --> 00:51:55,350
in the top down weights shows some signs physical results

913
00:51:58,580 --> 00:52:02,770
so as you already assumed this user graph in which every the citizen vertex and

914
00:52:02,770 --> 00:52:06,290
that there is some connection between the cities

915
00:52:06,340 --> 00:52:08,980
and you can use different ways you can have this graph

916
00:52:09,020 --> 00:52:13,300
i decided to use the complete graph i know it's not a smart way to

917
00:52:13,850 --> 00:52:19,090
as i'm going to run into some computational problems probably but for the small instances

918
00:52:19,090 --> 00:52:20,760
of cities which i

919
00:52:20,780 --> 00:52:25,780
i i already know values like less than fifty six it thousand

920
00:52:25,790 --> 00:52:27,200
it doesn't matter what

921
00:52:28,330 --> 00:52:34,440
smart way would have been to use it for neutralisation four and i not

922
00:52:34,450 --> 00:52:37,920
know that in order to kind oppose the travelling salesman problem i need to have

923
00:52:37,920 --> 00:52:39,670
some attitudes and edges

924
00:52:39,680 --> 00:52:42,230
it's also some of these

925
00:52:42,250 --> 00:52:44,070
i fully connected graph

926
00:52:44,120 --> 00:52:45,650
now attributed

927
00:52:45,710 --> 00:52:47,660
by weight w

928
00:52:47,670 --> 00:52:52,020
i get the traveling salesman problem is simply oppose this finding the

929
00:52:52,040 --> 00:52:58,280
to tell which is which has the smallest overall costs basically trying to minimize this

930
00:52:59,980 --> 00:53:01,510
if the weights

931
00:53:01,530 --> 00:53:05,980
and in my case always always open and distance place in this talk

932
00:53:06,030 --> 00:53:11,500
this problem is sometimes called the euclidean travelling salesman problem more specifically to deal with

933
00:53:13,140 --> 00:53:17,350
this the small motives and here he is p and e TSP

934
00:53:17,360 --> 00:53:21,000
in general hard optimisation problem the four

935
00:53:21,020 --> 00:53:24,920
may be the only way to solve this problem for moment this user some approximation

936
00:53:25,060 --> 00:53:27,010
of this

937
00:53:27,020 --> 00:53:29,420
well this talk is also about

938
00:53:29,430 --> 00:53:31,400
approximation i know

939
00:53:31,440 --> 00:53:33,330
let's try to see how

940
00:53:33,340 --> 00:53:38,390
the minimum spanning tree really another connect natural way to reduce the that

941
00:53:38,400 --> 00:53:42,490
telling says problem satisfied

942
00:53:42,510 --> 00:53:43,940
in related

943
00:53:43,950 --> 00:53:44,870
ten billion

944
00:53:44,890 --> 00:53:46,350
in reality

945
00:53:46,370 --> 00:53:52,600
and it has been shown that spanning trees in natural or born of length of

946
00:53:52,600 --> 00:53:56,170
the optimal two as well as by it is that it is

947
00:53:56,210 --> 00:54:00,580
also possible to sort of upper bound in terms of the minimum spanning tree

948
00:54:00,660 --> 00:54:02,880
so now

949
00:54:02,900 --> 00:54:05,110
just show you

950
00:54:05,120 --> 00:54:09,990
what is the minimum spanning tree already know but

951
00:54:10,000 --> 00:54:16,280
just for completion is trying to find the spanning tree unweighted graphs such that

952
00:54:16,300 --> 00:54:18,080
the sum of the weights

953
00:54:19,490 --> 00:54:23,650
fortunately for this problem is easy to solve and it has been shown that the

954
00:54:23,650 --> 00:54:27,440
probability algorithms can solve this problem may be these

955
00:54:27,460 --> 00:54:31,600
two or more prominent but the one that i'm going to use the both crossovers

956
00:54:31,600 --> 00:54:35,310
somebody check scientists that

957
00:54:35,330 --> 00:54:39,920
he found this algorithm in nineteen twenty six trying to optimize some

958
00:54:39,940 --> 00:54:43,240
electrical networking on the all those

959
00:54:43,250 --> 00:54:46,110
i'm going to say

960
00:54:46,120 --> 00:54:50,840
there is one that is the sole reason discussing of

961
00:54:50,850 --> 00:54:51,980
is that

962
00:54:51,990 --> 00:54:54,480
it's natural to build the graph

963
00:54:54,530 --> 00:54:59,560
just another loss this algorithm really does is basically start with an empty list which

964
00:54:59,560 --> 00:55:01,100
i'm going to populate

965
00:55:01,110 --> 00:55:03,910
and i

966
00:55:03,920 --> 00:55:07,100
initialize such that all the edges as are

967
00:55:07,120 --> 00:55:09,410
well to be treasonable itself

968
00:55:09,430 --> 00:55:13,430
but i do is i go in each of these three this list and find

969
00:55:13,430 --> 00:55:15,450
that the minimum weight

970
00:55:15,450 --> 00:55:16,840
platform that's going to

971
00:55:17,430 --> 00:55:18,450
i'm certain

972
00:55:18,990 --> 00:55:21,130
inspire a lot more copycat and that's it

973
00:55:21,380 --> 00:55:25,530
part answer to this young man's questions well you know making their knowledge

974
00:55:25,690 --> 00:55:30,300
i knowledge available i think what's going on today is really exciting work connected all

975
00:55:30,300 --> 00:55:31,950
the knowledge pools in the world together

976
00:55:32,420 --> 00:55:33,630
that's where the flat world means

977
00:55:34,010 --> 00:55:37,240
and what open universities doing is actually a key connector and all

978
00:55:38,030 --> 00:55:40,630
and so it is actually going trigger huge period of innovation

979
00:55:41,650 --> 00:55:47,760
because suddenly the next breakthrough science could come fifteen what morals working on a troll doll a cell phone

980
00:55:48,400 --> 00:55:52,320
so i twelve dollars internet-enabled cellphone that can download google

981
00:55:52,760 --> 00:55:58,240
and light is open university and well who knows where the next innovations in bioscience

982
00:55:58,240 --> 00:56:00,030
will come from maybe a fifteen in romania

983
00:56:00,630 --> 00:56:02,260
who downloads the human genome you know

984
00:56:02,720 --> 00:56:03,470
so on

985
00:56:04,220 --> 00:56:08,030
i think that's what you're doing you know is really really powerful

986
00:56:08,530 --> 00:56:11,630
i guess you want things the themes are discussions today here

987
00:56:12,220 --> 00:56:12,690
has been

988
00:56:13,090 --> 00:56:17,630
i think countries really had wrong direction at the macro level on this subject on

989
00:56:18,280 --> 00:56:19,260
end of

990
00:56:19,970 --> 00:56:23,760
you know i i be cute but we have people your brain back we've movie

991
00:56:23,760 --> 00:56:28,170
theaters in kansas that won't show movies and evolution you know at a time when

992
00:56:28,170 --> 00:56:31,030
the world is you know going in this direction and we stand to be the

993
00:56:31,030 --> 00:56:36,260
greatest beneficiaries i think we've all the secrets of sources can be great research universities

994
00:56:36,840 --> 00:56:38,030
wonderful still rule of law

995
00:56:38,590 --> 00:56:39,490
efficient markets

996
00:56:40,030 --> 00:56:44,550
on intellectual property protection but we are not tending to the sick resource loss

997
00:56:45,930 --> 00:56:49,650
last year the national science foundation cut its budget by a hundred million dollars

998
00:56:50,220 --> 00:56:54,320
now that's just i mean we had its budget cut by congress five hundred million dollars his

999
00:56:55,150 --> 00:56:58,030
and that's just flat out stupid you know i mean on

1000
00:56:58,490 --> 00:57:01,360
in in this moment in time where the flat world where was

1001
00:57:08,530 --> 00:57:12,690
what i really feel and what argue in the book is that we're not we're not quite crisis right now

1002
00:57:14,300 --> 00:57:17,990
and the quiet crisis is at and this is a term coined by surely in

1003
00:57:17,990 --> 00:57:23,130
jackson is a graduate of mighty she's the president rensselaer polytechnic the first african-american woman

1004
00:57:23,130 --> 00:57:25,630
to win a page to physics from nineteen appears

1005
00:57:28,130 --> 00:57:29,670
she calls it the climate crisis

1006
00:57:30,130 --> 00:57:33,570
and she calls it that because she was part of generation inspired to go in

1007
00:57:33,590 --> 00:57:37,970
science and engineering by sputnik and the and president kennedy's vision and putting

1008
00:57:38,780 --> 00:57:39,200
a man

1009
00:57:40,700 --> 00:57:41,700
end on

1010
00:57:43,360 --> 00:57:44,200
generation is

1011
00:57:44,720 --> 00:57:45,420
is retiring

1012
00:57:46,110 --> 00:57:46,650
and dying

1013
00:57:47,490 --> 00:57:49,470
and we all know we don't replace them we imported

1014
00:57:49,970 --> 00:57:51,740
the replacements from india and china

1015
00:57:52,130 --> 00:57:53,300
among other places

1016
00:57:54,030 --> 00:57:54,900
in the arm

1017
00:57:55,930 --> 00:57:59,300
since nine eleven well to things that have one is the world went flat

1018
00:57:59,920 --> 00:58:02,880
and when the world was flat you can innovate without having to emigrate

1019
00:58:03,950 --> 00:58:07,670
and when you can innovate without any emigre who needs succumbed chilly boston

1020
00:58:08,170 --> 00:58:11,450
you know when you can stay home in your own culture living a very high

1021
00:58:11,450 --> 00:58:14,900
standard of living work for cutting-edge global corporation to cutting-edge science

1022
00:58:15,430 --> 00:58:17,220
and and be home with your family

1023
00:58:18,380 --> 00:58:22,260
and second thing that happened was nine eleven and so telling all the first round

1024
00:58:22,260 --> 00:58:24,340
intellectual draft choices the world this tale

1025
00:58:25,780 --> 00:58:28,630
you want twenty really important we don't want your enemies are

1026
00:58:31,360 --> 00:58:31,670
and so

1027
00:58:32,340 --> 00:58:34,860
well actually with the theme of my conversations today with

1028
00:58:36,190 --> 00:58:37,260
folks i've interacted with

1029
00:58:39,010 --> 00:58:45,880
i'm really worried story i told nausium today just triggers the point is my daughter for national

1030
00:58:46,430 --> 00:58:48,010
history day which is in eighth grade

1031
00:58:48,860 --> 00:58:50,690
represented maryland her project was

1032
00:58:51,420 --> 00:58:53,360
how sputnik led to the internet

1033
00:58:54,190 --> 00:58:59,670
yes sputnik that da polenta darkness but in the end something happened fifty years ago

1034
00:59:00,550 --> 00:59:01,400
in reaction to

1035
00:59:02,190 --> 00:59:04,740
something totally different are reaction the sputnik

1036
00:59:05,820 --> 00:59:07,070
please to the internet today

1037
00:59:08,050 --> 00:59:09,220
well i really worry about

1038
00:59:09,930 --> 00:59:11,700
these are reaction to nine eleven

1039
00:59:12,800 --> 00:59:14,720
thousand little steps

1040
00:59:16,530 --> 00:59:17,760
these are rejection by

1041
00:59:18,240 --> 00:59:19,190
these officer

1042
00:59:19,610 --> 00:59:20,170
in chennai

1043
00:59:21,340 --> 00:59:23,550
on a grant proposal denied

1044
00:59:24,030 --> 00:59:24,860
to a research

1045
00:59:25,240 --> 00:59:31,030
you know paper blocked two funds not spent more funds spent somewhere else

1046
00:59:33,150 --> 00:59:40,130
we could get the total some of these things would be something that really needs at the very beginning openness

1047
00:59:43,260 --> 00:59:45,740
interactiveness with the world that's

1048
00:59:46,240 --> 00:59:47,190
american denied

1049
00:59:48,340 --> 00:59:51,840
and the fifty years will wake up and say we do all of them

1050
00:59:52,510 --> 00:59:53,930
in reaction tonight

1051
00:59:55,300 --> 00:59:55,720
and so

1052
00:59:56,700 --> 01:00:00,630
i really really worry about them so i think we're in a quiet crisis right now

1053
01:00:01,110 --> 01:00:02,550
that's part of the quiet crisis

1054
01:00:02,990 --> 01:00:04,150
the other part is simply

1055
01:00:05,610 --> 01:00:08,650
you know time when i think we need a new new deal to deal with

1056
01:00:08,650 --> 01:00:10,530
an integer this the perfect square

1057
01:00:10,540 --> 01:00:13,290
and i want to write a little piece of code is going to find the

1058
01:00:13,290 --> 01:00:14,550
square root of

1059
01:00:14,580 --> 01:00:17,450
some cheating levi not perfect square somebody is given to me

1060
01:00:17,600 --> 01:00:20,820
come back in a second journalism so what would the steps be that i used

1061
01:00:20,820 --> 01:00:22,230
to walk through

1062
01:00:22,280 --> 01:00:24,300
well if you think about these steps

1063
01:00:24,320 --> 01:00:26,230
here's an easy way to do it

1064
01:00:26,280 --> 01:00:29,320
start one scorex the thing i'm trying to find the square root of the start

1065
01:00:29,320 --> 01:00:30,400
started one

1066
01:00:31,890 --> 01:00:33,890
if it's not

1067
01:00:33,950 --> 01:00:35,460
greater than x

1068
01:00:35,470 --> 01:00:36,320
take two

1069
01:00:37,400 --> 01:00:40,970
it is not greater than x take three square and keep going until

1070
01:00:40,970 --> 01:00:45,410
the square of one of those integers is greater than or equal to

1071
01:00:45,470 --> 01:00:47,230
so it is greater than x

1072
01:00:47,240 --> 01:00:50,920
OK well my doing that when i get greater than x gone past the place

1073
01:00:50,920 --> 01:00:52,420
where i want to be

1074
01:00:52,500 --> 01:00:55,580
and obviously want to get to something whose square is equal to actually got the

1075
01:00:55,580 --> 01:00:56,620
answer one

1076
01:00:56,630 --> 01:00:57,990
kick it out

1077
01:00:58,030 --> 01:01:01,260
so what i don't have identified the thing i want to use to count something

1078
01:01:01,260 --> 01:01:05,600
some variables going to discount the editors of identified the and test

1079
01:01:05,660 --> 01:01:07,050
when that squares

1080
01:01:07,060 --> 01:01:11,560
bigger than the thing i'm looking for of identified basically what i wanna do inside

1081
01:01:11,560 --> 01:01:12,500
the loop

1082
01:01:12,510 --> 01:01:15,450
which is simply keep changing that variable

1083
01:01:15,520 --> 01:01:17,290
and i don't see what i wanna do and i'm done

1084
01:01:17,370 --> 01:01:19,960
actually print out the answer

1085
01:01:19,990 --> 01:01:22,660
OK so how can i call this up well and i think this is jumping

1086
01:01:22,660 --> 01:01:25,210
to write some code i don't quite do that because i want to show you

1087
01:01:25,210 --> 01:01:28,210
another tool it's valuable for thinking about how to

1088
01:01:28,280 --> 01:01:29,790
structure of the code

1089
01:01:29,900 --> 01:01:32,990
and that is something called the flowchart

1090
01:01:37,570 --> 01:01:42,420
people of professor good tags my age unfortunately remember flow charts back on the simpsons

1091
01:01:42,420 --> 01:01:43,820
back in the day

1092
01:01:43,830 --> 01:01:48,050
back in the sixties john reid really good programmers have these wonderful little plastic stencils

1093
01:01:48,050 --> 01:01:49,870
i tried to find that i couldn't find it

1094
01:01:49,910 --> 01:01:55,070
so little stencils little cut-out shapes on they used to draft across second in you

1095
01:01:55,080 --> 01:01:58,940
writing your next year pocket protector with all your hands in the answer your belt

1096
01:01:58,940 --> 01:02:02,150
was also about this time classes with this that you know we have

1097
01:02:02,280 --> 01:02:05,650
and few of those nerves left mostly keep the museum but that was what you

1098
01:02:05,650 --> 01:02:09,750
do with the flow chart despite making a bad joke about it we're going to

1099
01:02:09,750 --> 01:02:12,160
do the same thing here in chart out

1100
01:02:12,180 --> 01:02:15,620
a little bit of what should go into actually making this thing

1101
01:02:16,480 --> 01:02:20,910
so here's a simple flowchart i used to capture what i just described

1102
01:02:20,960 --> 01:02:24,390
again i'm actually going to do it the way they used to do it and

1103
01:02:25,830 --> 01:02:28,280
a rectangle with rounded corners

1104
01:02:28,300 --> 01:02:31,140
my starting point

1105
01:02:31,180 --> 01:02:34,120
and then what i say to do i said i need to identify variable a

1106
01:02:34,120 --> 01:02:36,660
given names this call and as for answer

1107
01:02:36,700 --> 01:02:39,030
and i need to initialize

1108
01:02:39,050 --> 01:02:40,670
so i'm going to come down

1109
01:02:40,760 --> 01:02:45,820
in a square box

1110
01:02:45,850 --> 01:02:47,310
initialize answer

1111
01:02:47,350 --> 01:02:50,050
is there

1112
01:02:50,060 --> 01:02:52,240
now want to run through the loop was the first thing i do know the

1113
01:02:52,400 --> 01:02:55,700
a test and test the flowchart says

1114
01:02:55,920 --> 01:02:58,780
tradition wants to do this in a diamond shape

1115
01:02:58,850 --> 01:03:03,850
i want to check if answer times answer

1116
01:03:03,860 --> 01:03:06,600
which we don't want to do this

1117
01:03:06,690 --> 01:03:08,920
less than or equal to x

1118
01:03:08,970 --> 01:03:14,400
now that's the test the two possibilities

1119
01:03:14,440 --> 01:03:18,830
the answer is yes

1120
01:03:18,920 --> 01:03:21,700
i'm still looking for the answer what i wanna do well i don't have to

1121
01:03:21,700 --> 01:03:24,350
do anything other than change the counter

1122
01:03:24,520 --> 01:03:26,690
one to go to

1123
01:03:28,390 --> 01:03:31,660
his answer plus one

1124
01:03:34,150 --> 01:03:37,000
due to you

1125
01:03:37,040 --> 01:03:40,580
eventually five done this right and that test is no

1126
01:03:40,650 --> 01:03:45,660
wonderfully ran out of room here in which case i'm going to go to print

1127
01:03:45,670 --> 01:03:48,660
statement which is always done in a trapezoid

1128
01:03:48,660 --> 01:03:56,300
print out answer should put a box below the system

1129
01:03:59,140 --> 01:04:03,160
and also i got you actually this is a useful tool for visualizing on trying

1130
01:04:03,160 --> 01:04:04,280
to put it together

1131
01:04:04,310 --> 01:04:05,800
because it lets me see

1132
01:04:05,810 --> 01:04:07,410
where the loop is

1133
01:04:08,530 --> 01:04:11,780
lets me see the and test it lets me make sure that i'm in fact

1134
01:04:11,780 --> 01:04:15,540
initializing the variable and checking the right things as i go along

1135
01:04:15,600 --> 01:04:19,600
the idea of this flowchart is if you start off little ball-bearing here is roll

1136
01:04:19,610 --> 01:04:24,650
down setting up an assignment statement and depending on your like is pair of flippers

1137
01:04:24,650 --> 01:04:28,290
and there does the test sensible this way to change it all and plus one

1138
01:04:28,290 --> 01:04:31,060
you may make make an attempt to

1139
01:04:31,070 --> 01:04:32,580
prove that

1140
01:04:32,630 --> 01:04:34,030
the project

1141
01:04:34,050 --> 01:04:37,090
the vector b on h

1142
01:04:37,150 --> 01:04:40,170
this is the projection

1143
01:04:40,210 --> 01:04:42,470
the length of this vector

1144
01:04:46,420 --> 01:04:48,380
and then the dot product

1145
01:04:48,450 --> 01:04:51,290
is the magnitude of eight

1146
01:04:51,330 --> 01:04:53,460
times the magnitude of b

1147
01:04:53,480 --> 01:04:58,050
times the cosine of the angle theta two i completely identical

1148
01:04:58,080 --> 01:05:00,340
now you may ask you may say g

1149
01:05:00,440 --> 01:05:03,280
how do i know what data is how do i know i should take theta

1150
01:05:03,280 --> 01:05:04,220
this angle

1151
01:05:04,230 --> 01:05:06,680
well maybe i should take theta this angle

1152
01:05:07,320 --> 01:05:11,660
what angle is a making with b makes no difference because the cosine of this

1153
01:05:11,660 --> 01:05:15,850
angle here is the same as the cosine of three hundred sixty degrees minus

1154
01:05:15,860 --> 01:05:18,500
so that makes no difference

1155
01:05:18,520 --> 01:05:23,220
sometimes this is faster depending how the problem is presented to you sometimes

1156
01:05:24,280 --> 01:05:26,120
is fast

1157
01:05:26,130 --> 01:05:29,080
you can immediately see by looking at this

1158
01:05:29,120 --> 01:05:31,110
it's easier to see than looking here

1159
01:05:31,820 --> 01:05:34,610
the dot product can be larger than zero

1160
01:05:34,730 --> 01:05:38,520
can be equal to zero and can be smaller than zero

1161
01:05:39,750 --> 01:05:43,520
by definition always positive there in magnitude

1162
01:05:43,550 --> 01:05:46,980
but so are determined by the cosine of theta the cosine of data is larger

1163
01:05:46,980 --> 01:05:49,480
than zero well then it larger than zero

1164
01:05:49,490 --> 01:05:51,840
the cosine of data can be zero

1165
01:05:51,910 --> 01:05:54,390
if the angle for theta

1166
01:05:54,410 --> 01:05:58,810
by over two not always if the two vectors are perpendicular to each other than

1167
01:05:58,810 --> 01:06:00,830
the dot product is zero

1168
01:06:00,840 --> 01:06:05,150
and if is angle theta between ninety degrees and hundred eighty degrees

1169
01:06:05,960 --> 01:06:07,600
cosine negative

1170
01:06:07,660 --> 01:06:09,850
we will see that at work

1171
01:06:09,900 --> 01:06:12,760
o point implied when we're going to do is work

1172
01:06:12,800 --> 01:06:16,530
in physics you will see that we can do positive work and we can do

1173
01:06:16,530 --> 01:06:18,480
negative work

1174
01:06:18,490 --> 01:06:21,470
and it has to do with his doctoral work and energy

1175
01:06:22,270 --> 01:06:25,030
dot products

1176
01:06:25,080 --> 01:06:27,960
i could do an extremely simple

1177
01:06:28,000 --> 01:06:29,800
example with you

1178
01:06:29,820 --> 01:06:32,610
december that i can think of

1179
01:06:32,660 --> 01:06:34,280
perhaps it's almost

1180
01:06:34,280 --> 01:06:37,830
an insult is not meant that way

1181
01:06:39,130 --> 01:06:41,080
we have a

1182
01:06:42,380 --> 01:06:44,320
and a

1183
01:06:44,400 --> 01:06:47,570
is the one that you really have on the blackboard there

1184
01:06:47,610 --> 01:06:49,570
right here that's it

1185
01:06:49,610 --> 01:06:51,970
would be

1186
01:06:52,010 --> 01:06:53,630
it's just too y

1187
01:06:58,790 --> 01:07:00,540
that's all it is

1188
01:07:00,590 --> 01:07:02,740
well what is a don't we

1189
01:07:02,870 --> 01:07:04,930
don't b

1190
01:07:05,010 --> 01:07:06,580
there is no x component

1191
01:07:06,660 --> 01:07:07,810
of b

1192
01:07:07,880 --> 01:07:11,320
so that becomes zero this becomes zero

1193
01:07:11,340 --> 01:07:15,560
there is only one component of the soldiers minus five

1194
01:07:15,580 --> 01:07:16,960
times plus two

1195
01:07:17,040 --> 01:07:18,140
so i get

1196
01:07:18,160 --> 01:07:21,820
minus ten because there was no component simple as that

1197
01:07:21,820 --> 01:07:25,470
was minus ten

1198
01:07:25,470 --> 01:07:27,440
i can give you another example

1199
01:07:27,470 --> 01:07:30,060
example two

1200
01:07:30,150 --> 01:07:32,660
suppose a itself

1201
01:07:32,730 --> 01:07:35,290
is the unit vector in the y direction

1202
01:07:35,370 --> 01:07:37,110
and b

1203
01:07:37,130 --> 01:07:39,050
is the unit vector

1204
01:07:39,050 --> 01:07:40,460
in the direction

1205
01:07:42,980 --> 01:07:47,430
is what

1206
01:07:47,440 --> 01:07:49,050
i want to hear it loud and clear

1207
01:07:51,810 --> 01:07:56,010
it is zero you don't even have to think about anything denoted these stewart ninety

1208
01:07:56,960 --> 01:07:58,760
if you want to waste your time

1209
01:07:58,770 --> 01:08:00,730
one is substituted in here

1210
01:08:00,740 --> 01:08:02,840
you will see that come down to be zero

1211
01:08:02,860 --> 01:08:05,280
it should work because clearly

1212
01:08:05,320 --> 01:08:08,440
a y means that this

1213
01:08:08,490 --> 01:08:09,900
this this is one

1214
01:08:09,920 --> 01:08:11,280
that's what it means

1215
01:08:11,310 --> 01:08:13,550
and b is the that means that

1216
01:08:13,600 --> 01:08:17,320
b of the this is one and all the others

1217
01:08:17,430 --> 01:08:18,880
do not exist well

1218
01:08:18,890 --> 01:08:20,270
i wish you luck with that

1219
01:08:20,270 --> 01:08:21,740
and we now go to

1220
01:08:21,750 --> 01:08:25,310
way way more difficult part of knot locations

1221
01:08:25,320 --> 01:08:26,630
and that is

1222
01:08:26,640 --> 01:08:28,400
vector multiplication

1223
01:08:28,410 --> 01:08:31,370
which is called the vector product

1224
01:08:33,440 --> 01:08:34,790
also called

1225
01:08:34,800 --> 01:08:37,410
most of the time i refer to it

1226
01:08:37,470 --> 01:08:39,740
as the cross product

1227
01:08:39,750 --> 01:08:41,710
the cross product

1228
01:08:41,720 --> 01:08:44,940
is written like so many crosby

1229
01:08:45,460 --> 01:08:48,710
equal see it's across

1230
01:08:48,730 --> 01:08:51,540
very clear across

1231
01:08:51,640 --> 01:08:55,660
i'll tell you how i remember that method number one going to teach you just

1232
01:08:55,660 --> 01:08:58,000
like with the dot product two methods

1233
01:08:58,000 --> 01:09:01,600
i'll tell you method number one which is the one that always works

1234
01:09:01,620 --> 01:09:05,220
time consuming always works

1235
01:09:05,220 --> 01:09:07,280
you're right the matrix

1236
01:09:07,320 --> 01:09:08,780
with three rows

1237
01:09:08,820 --> 01:09:10,480
the first row

1238
01:09:12,280 --> 01:09:13,460
why rule

1239
01:09:13,470 --> 01:09:17,210
zero the second one is a of x

1240
01:09:17,300 --> 01:09:18,710
a y

1241
01:09:18,720 --> 01:09:19,640
they all zinc

1242
01:09:19,660 --> 01:09:22,460
it's important if age is here first

1243
01:09:22,460 --> 01:09:24,740
that second row must be a

1244
01:09:24,790 --> 01:09:26,610
in the third row is then b

1245
01:09:27,190 --> 01:09:28,810
b of x

1246
01:09:28,840 --> 01:09:30,340
the y

1247
01:09:30,410 --> 01:09:32,830
of see these six and numbers

1248
01:09:32,880 --> 01:09:36,040
these are the unit vectors

1249
01:09:36,080 --> 01:09:37,970
i repeated this year

1250
01:09:40,500 --> 01:09:46,530
you'll see the minute why i need that

1251
01:09:46,610 --> 01:09:50,040
and i will do the same here

1252
01:09:57,820 --> 01:10:01,270
OK and now comes the recipe

1253
01:10:01,320 --> 01:10:03,360
you take

1254
01:10:03,410 --> 01:10:06,330
you go from the upper left-hand corner

1255
01:10:06,350 --> 01:10:08,160
two o to one

1256
01:10:08,210 --> 01:10:10,220
in this direction

1257
01:10:10,260 --> 01:10:12,500
you multiply them all three

1258
01:10:12,510 --> 01:10:14,170
that's a plus sign

1259
01:10:14,230 --> 01:10:15,900
so you get a y

1260
01:10:15,960 --> 01:10:19,420
so c which is the cross across b

1261
01:10:20,840 --> 01:10:23,520
a y

1262
01:10:23,570 --> 01:10:25,320
i'm using

1263
01:10:26,170 --> 01:10:29,930
and vx roof but i'm not going to put extra vignette

1264
01:10:29,980 --> 01:10:32,770
because i have to subtract

1265
01:10:32,880 --> 01:10:33,880
this one

1266
01:10:33,940 --> 01:10:36,670
minus sign

1267
01:10:36,720 --> 01:10:37,730
which has

1268
01:10:37,770 --> 01:10:39,830
eighty y

1269
01:10:39,890 --> 01:10:42,030
one minus

1270
01:10:43,310 --> 01:10:44,910
the y

1271
01:10:44,970 --> 01:10:46,080
and that

1272
01:10:46,100 --> 01:10:47,750
it is in the direction

1273
01:10:48,740 --> 01:10:50,560
the next one

1274
01:10:50,630 --> 01:10:51,990
is this one

1275
01:10:52,000 --> 01:10:54,410
eight cbx

1276
01:11:01,290 --> 01:11:04,990
this one

1277
01:11:05,040 --> 01:11:07,090
x c

1278
01:11:07,150 --> 01:11:12,300
in that direction

1279
01:11:13,880 --> 01:11:16,640
and last but not least

1280
01:11:16,930 --> 01:11:18,570
x p y

1281
01:11:27,760 --> 01:11:30,880
a y bx

1282
01:11:36,000 --> 01:11:37,400
the direction of the unit

1283
01:11:40,760 --> 01:11:44,080
so this part here

1284
01:11:44,170 --> 01:11:47,920
is what we call c of x x component

1285
01:11:47,930 --> 01:11:49,280
all this vector

1286
01:11:49,320 --> 01:11:52,140
and this can call seal y

1287
01:11:52,280 --> 01:11:53,940
and this we can call

1288
01:11:55,370 --> 01:11:57,740
you can also write that vector then that c

1289
01:11:57,740 --> 01:11:59,900
because of x

1290
01:11:59,910 --> 01:12:01,460
x roof

1291
01:12:01,510 --> 01:12:02,910
see why

1292
01:12:03,060 --> 01:12:04,710
why roof

1293
01:12:04,770 --> 01:12:06,770
c of the

1294
01:12:08,290 --> 01:12:11,040
cross product of a

1295
01:12:11,050 --> 01:12:12,990
and b

1296
01:12:12,990 --> 01:12:14,340
when i found

1297
01:12:14,350 --> 01:12:15,380
so what

1298
01:12:15,460 --> 01:12:17,460
so this is

1299
01:12:20,720 --> 01:12:24,260
this is the basis from inside and

1300
01:12:24,270 --> 01:12:27,650
when i do that i should get this class is now

1301
01:12:29,350 --> 01:12:31,270
she was

1302
01:12:31,280 --> 01:12:36,380
so with OK so is this one so

1303
01:12:36,390 --> 01:12:38,710
again this is the constraint

1304
01:12:39,720 --> 01:12:41,820
i don't know

1305
01:12:41,840 --> 01:12:43,910
no another

1306
01:12:49,100 --> 01:12:55,600
are there

1307
01:12:56,660 --> 01:12:58,000
this is again

1308
01:12:58,020 --> 01:13:01,880
one of the things you have to look for the foxes before we look at

1309
01:13:01,880 --> 01:13:04,310
female and now

1310
01:13:04,330 --> 01:13:05,620
we find

1311
01:13:05,640 --> 01:13:08,570
is that they are not defined

1312
01:13:08,580 --> 01:13:11,900
to be different from each other

1313
01:13:12,020 --> 01:13:14,590
they just instances agenda

1314
01:13:15,310 --> 01:13:18,670
also there

1315
01:13:28,850 --> 01:13:31,740
o thing

1316
01:13:31,780 --> 01:13:36,220
this is the this is the name that have actually said that there are different

1317
01:13:36,220 --> 01:13:40,880
so in order to get the contradiction i have two

1318
01:13:40,940 --> 01:13:43,380
make them different

1319
01:13:43,390 --> 01:13:47,360
and now

1320
01:13:47,400 --> 01:13:52,420
not unsatisfied

1321
01:13:53,320 --> 01:13:55,970
this is one reason why

1322
01:13:59,120 --> 01:14:01,620
so that

1323
01:14:04,750 --> 01:14:07,630
it's pretty clear

1324
01:14:11,320 --> 01:14:17,580
more on

1325
01:14:24,800 --> 01:14:28,760
and not just one

1326
01:14:28,770 --> 01:14:30,990
one of

1327
01:14:33,070 --> 01:14:37,010
using the decision

1328
01:14:37,020 --> 01:14:44,440
one of the people in the same year it was

1329
01:14:44,460 --> 01:14:46,450
so it were distinct

1330
01:14:48,680 --> 01:14:55,190
yes well this is why this would be the wrong for her

1331
01:14:58,110 --> 01:15:01,330
it's a wonderful world

1332
01:15:05,080 --> 01:15:09,620
in explorations was first

1333
01:15:09,890 --> 01:15:13,160
one thing you should be able to reason on this

1334
01:15:22,840 --> 01:15:28,390
so i think this is one of the things we know

1335
01:15:30,080 --> 01:15:34,260
so we're looking and we see that we can ask one

1336
01:15:34,280 --> 01:15:37,430
it is and it will give the list of which are sufficient

1337
01:15:40,520 --> 01:15:44,900
well known as

1338
01:15:48,240 --> 01:15:49,210
i o

1339
01:15:49,220 --> 01:15:50,390
we have

1340
01:15:50,410 --> 01:15:54,160
no no no no

1341
01:15:54,350 --> 01:15:57,140
no chance

1342
01:15:57,340 --> 01:16:06,030
this is

1343
01:16:06,070 --> 01:16:19,010
i'm missing something

1344
01:16:23,930 --> 01:16:25,560
yes but i don't have man

1345
01:16:33,950 --> 01:16:35,950
so we try this one

1346
01:16:36,110 --> 01:16:40,850
so these breakages one of the

1347
01:16:42,520 --> 01:16:47,050
think of the

1348
01:16:49,520 --> 01:16:52,160
so that's good

1349
01:16:52,250 --> 01:16:55,990
place that works so i can fix that issue enough get who's

1350
01:16:56,040 --> 01:16:58,970
let's not get rid of them

1351
01:16:58,980 --> 01:17:00,120
the changes

1352
01:17:00,130 --> 01:17:05,900
so as before changes are manageable if you look if you could so i have

1353
01:17:05,900 --> 01:17:09,240
done two things to get to the state i clicked on ball which gives me

1354
01:17:09,240 --> 01:17:10,370
cases where

1355
01:17:10,390 --> 01:17:14,640
the model is linear and calcium what we mean by that

1356
01:17:15,340 --> 01:17:20,340
in fact is a slightly more general version of this but that's stick with this

1357
01:17:20,340 --> 01:17:26,140
for them for present purposes linear gases state space model says that the state transition

1358
01:17:27,510 --> 01:17:33,600
is the gas in distribution where the mean is a linear function of the previous

1359
01:17:33,600 --> 01:17:38,350
states of matrix a times the previous state

1360
01:17:38,370 --> 01:17:40,530
the observation density similarly

1361
01:17:40,570 --> 01:17:42,100
linear and garcia

1362
01:17:42,100 --> 01:17:44,080
it's a gas intensity for y

1363
01:17:44,140 --> 01:17:47,740
with the linear function of the state xk got that

1364
01:17:47,780 --> 01:17:48,910
then you can apply

1365
01:17:48,930 --> 01:17:53,800
the kalman filter the notation is the kind of graph again

1366
01:17:53,800 --> 01:17:57,030
is the normal distribution for x with me

1367
01:17:57,240 --> 01:18:03,050
vector u and covariance matrix here

1368
01:18:03,080 --> 01:18:07,820
we can write that equivalently an additive noise model so we got away generating the

1369
01:18:07,820 --> 01:18:12,010
next data point the next state point in if we wanted to synthesize from data

1370
01:18:12,010 --> 01:18:16,490
from the model we would just right the next state is a times the previous

1371
01:18:16,490 --> 01:18:18,910
state plus the noise term

1372
01:18:18,950 --> 01:18:20,160
similarly why

1373
01:18:20,160 --> 01:18:23,990
is obtained from the from the state xt plus noise again

1374
01:18:24,050 --> 01:18:31,010
well these can these w can be generated independently zero mean gaussians vectors with covariance

1375
01:18:31,010 --> 01:18:34,580
matrices c and d respectively

1376
01:18:34,600 --> 01:18:38,260
i've said that they are independent over time and also independent of one another in

1377
01:18:38,260 --> 01:18:41,100
fact you can make and also dependent on one another

1378
01:18:41,120 --> 01:18:44,410
version of the carbon filter that deals with that as well but we don't need

1379
01:18:44,410 --> 01:18:45,660
to hear

1380
01:18:45,700 --> 01:18:50,570
we also require we everything must be linear gaza to the initial state

1381
01:18:50,570 --> 01:18:54,640
must be gas in distributed i think in the previous slide nineteen eighty that f

1382
01:18:54,640 --> 01:18:58,680
of x not that's the same thing the initial probability density for

1383
01:18:58,870 --> 01:19:01,030
the first stage of time not

1384
01:19:01,970 --> 01:19:04,050
so the first thing we need to do

1385
01:19:04,070 --> 01:19:06,870
is to get the predictions that if you remember

1386
01:19:06,910 --> 01:19:09,800
where we heading is to solve these

1387
01:19:09,850 --> 01:19:14,170
two equations are going to do it analytically in closed form for the little girls

1388
01:19:14,170 --> 01:19:15,430
in case

1389
01:19:15,430 --> 01:19:20,990
so the first one involves marginalizing out the current state from for the old state

1390
01:19:20,990 --> 01:19:25,370
from the joint density

1391
01:19:28,010 --> 01:19:30,600
it is so that's what we needed to do

1392
01:19:30,870 --> 01:19:34,390
carry out this integral

1393
01:19:34,450 --> 01:19:40,240
we suppose as before that we solve the problem at time t is recursively defined

1394
01:19:40,260 --> 01:19:43,140
we say that we've got the filtering distribution at time t

1395
01:19:43,200 --> 01:19:44,910
the normal distribution

1396
01:19:44,910 --> 01:19:48,550
with with me insane new t

1397
01:19:48,570 --> 01:19:52,550
covariance pft

1398
01:19:52,580 --> 01:19:58,370
and we know that to get to the next state from the previous equation we

1399
01:19:58,370 --> 01:20:01,700
don't need to go back to that we can generate the next state on the

1400
01:20:01,700 --> 01:20:07,850
previous day just by multiplying by eight and adding random noise to be

1401
01:20:07,870 --> 01:20:12,410
so it's really just standard transformation of variables we've taken

1402
01:20:12,430 --> 01:20:16,600
the random variable x is multiplied by matrix a

1403
01:20:16,600 --> 01:20:24,340
and noise to it so the convolution of the densities and produced t plus one

1404
01:20:24,370 --> 01:20:26,410
so we can get two

1405
01:20:26,430 --> 01:20:33,510
the density for x t plus one straightforward giving evidence before exiting the calcium

1406
01:20:33,530 --> 01:20:35,640
and we've got passes through that

1407
01:20:35,660 --> 01:20:37,100
update step

1408
01:20:38,370 --> 01:20:41,990
the density of x t plus one conditioned on the same data

1409
01:20:42,010 --> 01:20:47,990
is another normal distribution with mean is modified to mean is eight times the original

1410
01:20:47,990 --> 01:20:51,260
meaning beauty because we multiply by a

1411
01:20:51,320 --> 01:20:56,580
and we've added some noise on so it so so so we need to take

1412
01:20:57,410 --> 01:20:59,740
and converted into a

1413
01:20:59,740 --> 01:21:04,490
p p times a transpose that deals with this multiplication effect

1414
01:21:04,510 --> 01:21:08,700
but we also added on the noise a b had covariance matrix c so that

1415
01:21:08,700 --> 01:21:13,140
get started on so

1416
01:21:13,180 --> 01:21:14,260
the moment

1417
01:21:14,570 --> 01:21:22,320
and on the right side so this was the covariance matrix is bounded on zero

1418
01:21:22,320 --> 01:21:28,470
mean girls noise v so had three of the covariance matrix c onto the AP

1419
01:21:30,050 --> 01:21:33,820
so that gives you the formula for doing the update if we started with the

1420
01:21:33,820 --> 01:21:35,910
gas industry time

1421
01:21:37,120 --> 01:21:39,600
so that's the prediction step

1422
01:21:39,640 --> 01:21:44,680
the corrections step the updating step five days for just involves taking what we just

1423
01:21:44,680 --> 01:21:48,070
calculated that prediction density calcium

1424
01:21:48,120 --> 01:21:51,260
multiplying it by the galaxy observation density

1425
01:21:51,470 --> 01:21:55,010
and correctly normalizing it because for a fixed data set y

1426
01:21:55,010 --> 01:21:56,550
that'll be a constant

1427
01:21:56,570 --> 01:21:59,890
turn on the bottom line that so we just need to calculate the normalizer for

1428
01:21:59,890 --> 01:22:02,850
the for the multivariate density

1429
01:22:02,890 --> 01:22:05,970
and substituting it it well don't worry about it too much about this

1430
01:22:06,160 --> 01:22:11,300
arrangement but we've taken the normal distribution for the predictive density for forex

1431
01:22:11,350 --> 01:22:13,930
multiplied by the observation density

1432
01:22:13,950 --> 01:22:16,200
for y conditional upon that new

1433
01:22:17,890 --> 01:22:19,160
plug everything in

1434
01:22:19,180 --> 01:22:22,510
and re-arranged it found the correct normal

1435
01:22:22,530 --> 01:22:24,010
with the right normalising

1436
01:22:26,180 --> 01:22:27,990
this one

1437
01:22:28,010 --> 01:22:31,320
with this particular mean and covariance of more about the details of that you can

1438
01:22:31,320 --> 01:22:37,760
work through your own time afterwards and we can rearrange that using the matrix inversion

1439
01:22:37,760 --> 01:22:41,430
lemma to give a slightly simpler form we don't need all the details of this

1440
01:22:41,430 --> 01:22:42,240
right now

1441
01:22:42,240 --> 01:22:46,970
i just put them there for reference the whole recursion is summarized in terms of

1442
01:22:46,990 --> 01:22:49,890
prediction step on the means and covariances

1443
01:22:49,910 --> 01:22:54,570
and update state on the means and covariances which progressively from the gas in time

1444
01:22:55,550 --> 01:22:59,720
another galaxy in time t plus one

1445
01:22:59,780 --> 01:23:04,410
they get as i say that we don't need the precise details of that at

1446
01:23:04,410 --> 01:23:09,490
the moment just outlining the principles behind it and more importantly what the things you

1447
01:23:09,490 --> 01:23:10,890
can and can't do

1448
01:23:10,890 --> 01:23:15,320
with the kalman filter that arises from the common filter is a fundamental tool is

1449
01:23:15,350 --> 01:23:17,200
still substantially used in

1450
01:23:17,620 --> 01:23:18,550
in may

1451
01:23:18,570 --> 01:23:20,490
estimation and tracking tasks

1452
01:23:20,510 --> 01:23:26,760
you can use it to estimate the system state sequentially by taking for example the

1453
01:23:26,780 --> 01:23:28,910
i mean estimate for the state

1454
01:23:28,930 --> 01:23:34,970
you can obtain uncertainty estimate about the state using the state covariance

1455
01:23:34,970 --> 01:23:39,510
you can do a recursive least squares and the state doesn't evolve time is like

1456
01:23:39,550 --> 01:23:40,820
fixed parameter

1457
01:23:40,890 --> 01:23:43,280
that's basically a type of the kalman filter

1458
01:23:43,300 --> 01:23:47,530
you can do to fix like smoothing by augmenting the states to include not just

1459
01:23:47,530 --> 01:23:49,620
the current state was some previous state

1460
01:23:49,680 --> 01:23:54,850
will get you a bit more money you have to modify the state space model

1461
01:23:54,850 --> 01:23:57,760
to give you the correct update on the axis but otherwise

1462
01:23:57,780 --> 01:23:59,760
everything follows the same

1463
01:23:59,780 --> 01:24:04,680
and similarly if you want to do is fixed interval smoothing estimating the whole sequence

1464
01:24:04,680 --> 01:24:09,780
of x is given the whole sequence of y then the kalman smoother operates backwards

1465
01:24:09,780 --> 01:24:14,930
in time so one filter forwards through the data and then the equivalent equations backwards

1466
01:24:14,930 --> 01:24:19,740
through time to take you back to the data to estimate the posterior distribution of

1467
01:24:19,740 --> 01:24:23,120
particular time point t

1468
01:24:23,140 --> 01:24:24,100
for example

1469
01:24:24,220 --> 01:24:28,430
recursively backwards in time given all of the data

1470
01:24:28,450 --> 01:24:33,540
and you can do similar things with the particle filters so there's also particle smoother

1471
01:24:33,540 --> 01:24:37,240
so we can say this is very much related to calcium so why is that

1472
01:24:37,250 --> 01:24:38,630
the case

1473
01:24:39,700 --> 01:24:42,220
we believe that we have a set of

1474
01:24:42,230 --> 01:24:44,440
input output pairs

1475
01:24:44,480 --> 01:24:48,080
now the data are made of pairs he had axes implies and we assume that

1476
01:24:48,140 --> 01:24:50,230
the x otherwise i just real

1477
01:24:50,340 --> 01:24:56,090
values that money is on a multi dimensional thing so again the idea would be

1478
01:24:56,220 --> 01:25:06,370
so we're after

1479
01:25:08,090 --> 01:25:13,940
a straight line

1480
01:25:13,980 --> 01:25:17,940
so and now this is the generative model point of view so we get some

1481
01:25:19,660 --> 01:25:21,800
so x is unwise

1482
01:25:21,920 --> 01:25:23,020
the idea of

1483
01:25:23,080 --> 01:25:27,800
is to get a straight line through it so now let's we all know

1484
01:25:27,880 --> 01:25:32,770
one way of doing it is of course the least square method but this is

1485
01:25:32,770 --> 01:25:37,030
a way of justifying this from probabilistic model point of view

1486
01:25:37,080 --> 01:25:41,820
so now we believe that actually there is the true straight line and what we

1487
01:25:41,820 --> 01:25:46,620
see these data is a straight line plus noise so here's the straight lines w

1488
01:25:46,620 --> 01:25:48,570
not plus w one

1489
01:25:49,910 --> 01:25:52,010
on new

1490
01:25:52,040 --> 01:25:56,290
some statistically independent calcium noise to it

1491
01:25:56,330 --> 01:25:59,440
i believe so what you you see is the function in here

1492
01:25:59,880 --> 01:26:03,310
so there is always some noise added

1493
01:26:03,770 --> 01:26:08,220
OK so let's write down again what is the probability

1494
01:26:08,230 --> 01:26:11,180
of getting the data

1495
01:26:11,300 --> 01:26:13,360
given the parameters

1496
01:26:13,410 --> 01:26:17,250
now we have two parameters we got w norton w one

1497
01:26:17,310 --> 01:26:18,690
two values

1498
01:26:19,060 --> 01:26:22,680
so we just form a vector

1499
01:26:22,720 --> 01:26:28,830
w these two values and then right and what's the probability density for having an

1500
01:26:28,830 --> 01:26:31,670
x and y and we assume that everything

1501
01:26:31,810 --> 01:26:34,440
it sort of happens independently for

1502
01:26:34,480 --> 01:26:37,090
for these many data

1503
01:26:37,740 --> 01:26:42,750
that is first of all well there is something that generates dx is that we're

1504
01:26:42,750 --> 01:26:46,940
not interested at the moment in modeling this so it's just some function p of

1505
01:26:46,940 --> 01:26:51,120
x and we don't have to bother with this is when we are interested in

1506
01:26:53,920 --> 01:26:59,560
in estimating the w because it turns out that this part will be irrelevant

1507
01:26:59,660 --> 01:27:01,400
a maximum likelihood

1508
01:27:01,410 --> 01:27:04,490
so we can assume there is some function p of x

1509
01:27:05,730 --> 01:27:09,190
so what i'm doing here is i'm writing something well

1510
01:27:09,420 --> 01:27:15,790
i hope you're familiar with that i'm writing a joint distribution in terms of

1511
01:27:15,810 --> 01:27:18,660
conditionals and marginals so if i have

1512
01:27:18,660 --> 01:27:24,200
a density of two variables x and y i can write this is the p

1513
01:27:24,200 --> 01:27:24,920
of y

1514
01:27:25,400 --> 01:27:27,580
given x

1515
01:27:27,620 --> 01:27:31,670
times of p of x so this is done in this line

1516
01:27:31,730 --> 01:27:37,810
so in that condition conditioned on the value of x i say that y is

1517
01:27:39,290 --> 01:27:42,820
in this way so this is kind of the the way to write down the

1518
01:27:42,820 --> 01:27:45,090
generator if i have x

1519
01:27:45,220 --> 01:27:48,980
then y is computed by the simple linear relation plus

1520
01:27:49,010 --> 01:27:51,170
subgaussian noise is added

1521
01:27:51,980 --> 01:27:53,200
what is this

1522
01:27:53,200 --> 01:27:55,810
what is why conditioned on x

1523
01:27:55,840 --> 01:27:58,670
well why conditional nexus the following i know

1524
01:27:59,400 --> 01:28:01,530
the noise is calcium let's say

1525
01:28:01,550 --> 01:28:03,430
well i have the assumption

1526
01:28:03,430 --> 01:28:05,520
there is

1527
01:28:05,540 --> 01:28:10,660
it has variance sigma again we can include the variance sigma into the parameters and

1528
01:28:10,660 --> 01:28:14,060
so we don't know it's let's estimated from the data

1529
01:28:15,340 --> 01:28:16,450
so we know

1530
01:28:16,450 --> 01:28:18,130
this noise is

1531
01:28:18,180 --> 01:28:19,980
has variance sigma

1532
01:28:20,000 --> 01:28:21,910
and and mean zero

1533
01:28:21,950 --> 01:28:25,810
so the idea is the following what is then y

1534
01:28:25,830 --> 01:28:28,140
given x well we know

1535
01:28:28,140 --> 01:28:31,640
for a given x this is not random at all

1536
01:28:31,940 --> 01:28:34,650
but this is just a fixed number

1537
01:28:34,670 --> 01:28:35,910
if i six x

1538
01:28:35,920 --> 01:28:38,760
the parameters w one and w not

1539
01:28:38,880 --> 01:28:42,920
so this is a fixed number so i know that y

1540
01:28:42,940 --> 01:28:44,480
for fixed x

1541
01:28:44,500 --> 01:28:50,070
it is also calcium because i added calcium with zero mean to some number so

1542
01:28:50,070 --> 01:28:53,120
it's also becoming calcium with the same variance

1543
01:28:54,700 --> 01:28:56,940
now the mean is this

1544
01:28:57,020 --> 01:29:00,560
so means that p y

1545
01:29:00,570 --> 01:29:04,290
given x and all the parameters here

1546
01:29:04,460 --> 01:29:08,580
is then one over two pi sigma squared

1547
01:29:08,610 --> 01:29:10,920
e to the minus

1548
01:29:10,930 --> 01:29:13,980
why in here has to come

1549
01:29:14,070 --> 01:29:19,080
sigma square has to come in the mean time we put up until the what's

1550
01:29:19,080 --> 01:29:23,180
medium util well me tilde is the mean

1551
01:29:23,220 --> 01:29:25,310
for this for y

1552
01:29:25,410 --> 01:29:27,180
and this is

1553
01:29:27,190 --> 01:29:28,050
we know

1554
01:29:30,870 --> 01:29:33,780
why fluctuates around

1555
01:29:33,830 --> 01:29:36,000
w not class

1556
01:29:36,010 --> 01:29:37,620
w one x

1557
01:29:37,740 --> 01:29:41,390
so this is what i have here

1558
01:29:41,460 --> 01:29:43,220
this is a generative model

1559
01:29:43,420 --> 01:29:47,470
of course now this would open up the possibility saying well

1560
01:29:47,570 --> 01:29:51,240
i believe actually there's a lot of outliers or things like that so you could

1561
01:29:51,240 --> 01:29:55,420
come up with models for outliers you could come up with models that say

1562
01:29:55,900 --> 01:30:01,620
well i know you know galaxy in that falls off very fast exponentially e to

1563
01:30:01,620 --> 01:30:07,290
the minus something to the square so well i believe actually there's it's more factor

1564
01:30:07,300 --> 01:30:12,670
distribution outside so i just let's come up with something that looks like this

1565
01:30:13,000 --> 01:30:16,610
this will be plus noise for instance

1566
01:30:16,620 --> 01:30:21,560
so it's not like e to the minus lamp

1567
01:30:21,580 --> 01:30:26,410
absolute value for let's say let's call the noise said

1568
01:30:26,440 --> 01:30:28,970
and then that would be a density

1569
01:30:29,010 --> 01:30:34,220
you could also say well maybe noise is just additive only adds positively

1570
01:30:34,220 --> 01:30:36,970
like you know whatever rainfall totals

1571
01:30:36,980 --> 01:30:42,760
something a number that adds to something not subtract so we could come up with

1572
01:30:42,760 --> 01:30:45,460
noise looks only like this

1573
01:30:45,510 --> 01:30:46,720
so this whole

1574
01:30:46,730 --> 01:30:52,140
type of modelling would sort of allows for the noise process is that we think

1575
01:30:52,270 --> 01:30:54,870
maybe more relevant to the data

1576
01:30:54,870 --> 01:30:56,610
in any case this is now

1577
01:30:56,620 --> 01:30:58,890
the probability of of of

1578
01:30:58,920 --> 01:31:03,820
the data and we can write again a log likelihood

1579
01:31:05,090 --> 01:31:07,530
first of all writing a product

1580
01:31:07,640 --> 01:31:10,090
taking the log of it

1581
01:31:10,150 --> 01:31:14,270
and so here at the moment just written down everything

1582
01:31:14,300 --> 01:31:17,320
it depends only on

1583
01:31:18,470 --> 01:31:23,980
w one w norton w one and i can or all the other bits for

1584
01:31:23,980 --> 01:31:25,490
instance look p

1585
01:31:25,520 --> 01:31:26,300
of x

1586
01:31:26,320 --> 01:31:28,930
because we're not interested in modelling

1587
01:31:28,940 --> 01:31:31,230
the generation of these inputs

1588
01:31:31,320 --> 01:31:36,010
so this is all these bits to do not depend on w norton w one

1589
01:31:36,070 --> 01:31:39,790
i don't want to solve that because in any case we see what's happening we

1590
01:31:40,750 --> 01:31:42,210
the negative

1591
01:31:43,180 --> 01:31:46,220
likelihood is just some

1592
01:31:46,230 --> 01:31:48,750
of squares and this is nothing but

1593
01:31:48,800 --> 01:31:52,510
the least squares fitting of the curve

1594
01:31:52,520 --> 01:31:54,110
four gaussians

1595
01:31:54,140 --> 01:31:56,510
well just

1596
01:31:56,530 --> 01:31:59,010
derived from the calcium model

1597
01:31:59,010 --> 01:32:01,340
the rest are

1598
01:32:03,040 --> 01:32:06,090
so this

1599
01:32:06,980 --> 01:32:11,320
her research

1600
01:32:11,340 --> 01:32:15,090
or is

1601
01:32:18,050 --> 01:32:20,640
there's a

1602
01:32:33,770 --> 01:32:37,050
this is

1603
01:33:03,610 --> 01:33:08,050
nine here

1604
01:33:23,360 --> 01:33:26,500
three which

1605
01:33:35,640 --> 01:33:43,020
that's what you that

1606
01:33:44,190 --> 01:33:45,720
how do you

1607
01:33:45,730 --> 01:33:49,300
so of now

1608
01:33:57,120 --> 01:34:00,720
how to use

1609
01:34:00,740 --> 01:34:05,440
is one of the key

1610
01:34:05,470 --> 01:34:08,130
here are

1611
01:34:13,120 --> 01:34:17,040
there was no more

1612
01:34:27,660 --> 01:34:30,030
you my name

1613
01:34:32,130 --> 01:34:34,630
he's your

1614
01:34:34,660 --> 01:34:37,090
so he

1615
01:34:37,140 --> 01:34:40,160
each year is the current

1616
01:34:42,440 --> 01:34:44,820
right now it's

1617
01:34:46,470 --> 01:34:55,540
so what we do

1618
01:34:55,560 --> 01:34:59,660
three things which are not

1619
01:35:01,530 --> 01:35:06,180
you might be more

1620
01:35:16,220 --> 01:35:22,590
thank you guys this is just a really fun day for me and i'm so

1621
01:35:22,590 --> 01:35:26,310
appreciative to everybody so i don't know when you win an academy award how you

1622
01:35:26,310 --> 01:35:29,590
actually have to give thanks to so many people

1623
01:35:29,600 --> 01:35:33,370
and the first of all i want to thank you are personally for nominated me

1624
01:35:33,410 --> 01:35:34,710
for this award

1625
01:35:34,720 --> 01:35:42,160
and then i want to find the review committee that consisted of of this morning

1626
01:35:42,310 --> 01:35:43,630
about four words

1627
01:35:43,650 --> 01:35:45,320
and grey bill

1628
01:35:45,340 --> 01:35:46,660
joe coyle

1629
01:35:46,690 --> 01:35:48,250
larry squire

1630
01:35:48,310 --> 01:35:50,530
and that's all snyder

1631
01:35:51,070 --> 01:35:54,910
to those of you who don't know these are absolutely giants in the field of

1632
01:35:54,910 --> 01:36:00,560
neuroscience and in absolute giants chris barber what's won the nobel prize in physiology in

1633
01:36:00,560 --> 01:36:02,340
two thousand two

1634
01:36:02,380 --> 01:36:06,820
and to be considered and then voted to

1635
01:36:06,830 --> 01:36:10,370
this award by that group of people is just

1636
01:36:10,450 --> 01:36:15,620
still just amazes me so i am deeply appreciative

1637
01:36:15,670 --> 01:36:21,690
and of course i'm deeply appreciative to the government foundation for having this award and

1638
01:36:21,690 --> 01:36:27,450
finally to merge can course at school for being at school like and having work

1639
01:36:28,010 --> 01:36:33,210
have the foresight to endow this wonderful prize in his name

1640
01:36:33,260 --> 01:36:37,730
and i think it is very difficult for and i am sure he's very happy

1641
01:36:37,730 --> 01:36:41,040
about it so i had a great day i had a wonderful time of the

1642
01:36:41,040 --> 01:36:46,130
board and so i'm going to do is to tell you what case

1643
01:36:46,140 --> 01:36:50,450
a little bit about working our laboratory all of the last forty years

1644
01:36:50,540 --> 01:36:55,730
looking at brain systems involved in fear and anxiety and extinction

1645
01:36:55,740 --> 01:37:01,060
and have to work out hero i know because i can't really see the screen

1646
01:37:01,110 --> 01:37:05,440
so let me try this one and

1647
01:37:05,450 --> 01:37:07,680
can you hear in the back now

1648
01:37:07,730 --> 01:37:09,040
that's fine

1649
01:37:10,520 --> 01:37:15,770
so this course is work that has been done by a large number of students

1650
01:37:15,770 --> 01:37:19,260
i've only listed if you hear that are going to continue to contribute to what

1651
01:37:19,260 --> 01:37:20,140
i'm actually be

1652
01:37:20,210 --> 01:37:21,740
discussing today

1653
01:37:21,750 --> 01:37:28,070
and these are students postdocs colleagues that have worked on all of these projects i'm

1654
01:37:28,080 --> 01:37:29,950
simply presenting their data

1655
01:37:30,000 --> 01:37:34,610
and i also do have to give this disclosure that i have a pattern for

1656
01:37:34,610 --> 01:37:38,870
the use of cognitive enhancers as an adjunct to psychotherapy

1657
01:37:38,880 --> 01:37:43,300
and i am entitled to royalties from this company called take the should this work

1658
01:37:43,320 --> 01:37:48,430
be commercialized you'll understand later when i need to make that disclosure

1659
01:37:48,440 --> 01:37:54,460
so the take-home messages in the first part of the talk are that the amygdala

1660
01:37:54,480 --> 01:37:59,310
is particularly the central nucleus of the amygdala the middle has lots of different groups

1661
01:37:59,310 --> 01:38:04,230
of cells the central nucleus is involved in something like stimulus specific fear

1662
01:38:04,640 --> 01:38:09,460
another part of the so-called extended amygdala is called the bed nucleus of the street

1663
01:38:09,460 --> 01:38:14,710
running hours and that's involved in something i think is more like anxiety

1664
01:38:14,740 --> 01:38:18,760
and what we think anxiety is in more operational sense

1665
01:38:18,770 --> 01:38:23,870
it is is really sustain fear due to relief of release of the particular peptide

1666
01:38:23,870 --> 01:38:29,930
could called corticotropin releasing hormone that actually comes from the amygdala acts on receptors in

1667
01:38:29,930 --> 01:38:35,860
the bed nucleus to protect produced the sustains a and and try to explain what

1668
01:38:35,860 --> 01:38:37,800
i mean by that

1669
01:38:37,850 --> 01:38:39,880
so the

1670
01:38:40,310 --> 01:38:45,730
the paradigm that we use is called the fear potentiated startle paradigms for fear potentiated

1671
01:38:45,730 --> 01:38:50,800
startle test and it stems from anecdotal evidence that if you're scared you tend to

1672
01:38:51,500 --> 01:38:56,930
so if you're walking down a dark alley somewhere in boston tonight you'll apprehensive and

1673
01:38:56,930 --> 01:39:01,000
something startles issues such as a cat marking the top of the medal as can

1674
01:39:01,000 --> 01:39:05,320
you feel yourself jump more than you normally do and this is actually shown many

1675
01:39:05,320 --> 01:39:10,550
years ago by brown kalish and farber and we adopted their paradigm so basically what

1676
01:39:10,550 --> 01:39:13,940
we do is we make an animal afraid of some stimulus in this case the

1677
01:39:14,940 --> 01:39:18,740
and we do that by pairing the light with a shock so it's a very

1678
01:39:18,740 --> 01:39:23,190
short lives about three about three seconds and then we bring the animal back a

1679
01:39:23,190 --> 01:39:27,350
day later month later two months later doesn't matter they remember that as long as

1680
01:39:27,350 --> 01:39:32,130
we test and we put them in this cage the specially designed to measure the

1681
01:39:32,130 --> 01:39:34,440
amplitude of the startle reflex

1682
01:39:34,450 --> 01:39:39,550
and now we elicit startled with the loud sound either in the presence or absence

1683
01:39:39,550 --> 01:39:44,180
of the light and the phenomenon is that when the animals afraid by virtue having

1684
01:39:44,180 --> 01:39:48,790
pair that light with the shock they start more to the loud sound than they

1685
01:39:48,790 --> 01:39:53,210
do in the absence of that and we can measure that automatically

1686
01:39:53,240 --> 01:39:56,370
by a trans ducer here called an accelerometer

1687
01:39:56,440 --> 01:40:00,710
that puts out of voltage that is proportional to how much the cage moves which

1688
01:40:00,710 --> 01:40:05,000
in turn is proportional to how much the animals startles

1689
01:40:05,050 --> 01:40:11,940
and these are the kind of data that we get in this paradigm so this

1690
01:40:11,940 --> 01:40:14,390
is the amplitude of startling darkness

1691
01:40:14,420 --> 01:40:18,900
this is the amplitude of startle to the same auditory stimulus in the presence of

1692
01:40:18,900 --> 01:40:23,480
the light and this is our operational definition of fear and what this says is

1693
01:40:23,480 --> 01:40:27,460
that the animal stalls more to the loud sound in the presence versus the absence

1694
01:40:27,460 --> 01:40:32,340
of the light and it turns out the variety of compounds the reduce anxiety and

1695
01:40:32,340 --> 01:40:37,100
fear and people in this case bellingham have a reasonably selective effect that is they

1696
01:40:37,100 --> 01:40:42,130
don't do much the basic startle reflex but what they do is they selectively decrease

1697
01:40:42,430 --> 01:40:47,920
the fear potentiated component consistent with the idea that they reduce fear and anxiety in

1698
01:40:52,770 --> 01:40:57,580
this was the state of affairs about thirty five years ago we had discovered a

1699
01:40:57,580 --> 01:40:59,680
way to measure this objectively

1700
01:40:59,710 --> 01:41:04,760
and we were very interested in in the neural mechanisms that were involved but you

1701
01:41:04,760 --> 01:41:08,290
know how do you go about doing that you have a rat is very complicated

1702
01:41:08,290 --> 01:41:13,020
and there's also the question of why these square of all the things we could

1703
01:41:14,550 --> 01:41:19,210
how do we come up with this criteria for minimizing the square of the error between

1704
01:41:19,350 --> 01:41:24,340
the predictions of the hypothesis and and the values y predictive so why not minimize

1705
01:41:24,390 --> 01:41:29,340
you the absolute value of the areas arizona or the errors the power for some

1706
01:41:30,070 --> 01:41:35,040
what need to do now is present one set of assumptions that will serve to

1707
01:41:35,110 --> 01:41:36,610
quote justify

1708
01:41:36,630 --> 01:41:39,100
while minimizing the sum of squares error

1709
01:41:39,960 --> 01:41:44,960
on the tenth of the the many assumptions that are sufficient to justify why we

1710
01:41:44,970 --> 01:41:49,060
do these queries and this is just one of them on so so

1711
01:41:49,120 --> 01:41:53,250
you know there's just because they present was assumptions under which the squares regression makes

1712
01:41:53,250 --> 01:41:56,880
sense on but this is not the only sort of assumptions so even if the

1713
01:41:56,880 --> 01:42:01,630
assumptions i i described don't whole these square actually still makes sense in many circumstances

1714
01:42:01,630 --> 01:42:03,470
but this of the help

1715
01:42:03,680 --> 01:42:07,190
if one rationalization one reason for the squares regression

1716
01:42:10,430 --> 01:42:13,110
i don't think we we to do is on

1717
01:42:13,170 --> 01:42:17,690
and and out of the least squares model with probabilistic semantics

1718
01:42:17,700 --> 01:42:23,840
so let's see you in my example or predicting housing prices

1719
01:42:23,940 --> 01:42:25,090
that's the

1720
01:42:25,110 --> 01:42:28,140
so the price the whole system forth

1721
01:42:28,150 --> 01:42:36,560
it's going to be some linear function of the features plus on some term epsilon

1722
01:42:36,560 --> 01:42:41,150
i and epsilon i will be

1723
01:42:41,180 --> 01:42:44,110
no error term

1724
01:42:44,130 --> 01:42:45,300
you think

1725
01:42:45,310 --> 01:42:48,680
the error term has capturing and model effects

1726
01:42:48,720 --> 01:42:53,500
like that maybe there are some other features of the holes like holly fireplaces has

1727
01:42:53,500 --> 01:42:55,470
led us regarding the whatever

1728
01:42:55,520 --> 01:42:59,830
there are additional features and we just have to capture or you can think of

1729
01:42:59,840 --> 01:43:01,530
as long as random noise

1730
01:43:01,680 --> 01:43:06,280
so follows that every term that captures both these on model effects of the things

1731
01:43:06,280 --> 01:43:09,510
we forgot to model may be functions and quite you something

1732
01:43:09,520 --> 01:43:12,500
on as well as on

1733
01:43:12,520 --> 01:43:17,030
as well as random noise like maybe that data so it was really bad and

1734
01:43:17,030 --> 01:43:20,810
so you know he so they just refuse to go through surprise

1735
01:43:22,480 --> 01:43:23,380
and now

1736
01:43:23,870 --> 01:43:27,350
i assume that the errors

1737
01:43:27,480 --> 01:43:29,580
have on

1738
01:43:31,090 --> 01:43:37,090
i have had the power distribution assume that errors epsilon i are distributed just so

1739
01:43:38,710 --> 01:43:40,220
the nodes of sunni

1740
01:43:40,800 --> 01:43:48,570
is distributed according to a probability distribution that's calcium distribution with mean zero

1741
01:43:48,580 --> 01:43:50,290
and variance sigma square

1742
01:43:50,420 --> 01:43:55,360
so they use scripts n here on any sense the normal to denote the normal

1743
01:43:55,360 --> 01:43:58,260
distribution also known as the gauss in distribution

1744
01:43:58,260 --> 01:44:01,510
with mean zero covariance sigma

1745
01:44:03,340 --> 01:44:07,530
i think we can raise your hand if you see any cows in distribution or

1746
01:44:07,590 --> 01:44:09,860
the call must also one

1747
01:44:11,180 --> 01:44:18,090
in other words on the density for gaussians is busy scenes for the density for

1748
01:44:18,250 --> 01:44:23,190
and i will be very similar

1749
01:44:26,240 --> 01:44:29,350
two things

1750
01:44:36,440 --> 01:44:38,050
the density for

1751
01:44:38,070 --> 01:44:40,630
that's all i will be the bell-shaped curve

1752
01:44:42,550 --> 01:44:45,020
you know the

1753
01:44:45,020 --> 01:44:46,940
with one standard deviation

1754
01:44:48,840 --> 01:44:50,210
so cyc

1755
01:44:52,350 --> 01:44:56,290
on this is one of those secret

1756
01:45:00,620 --> 01:45:06,240
recent works

1757
01:45:21,200 --> 01:45:22,820
so this implies that

1758
01:45:26,520 --> 01:45:30,020
the probability distribution of the height of the horse

1759
01:45:30,120 --> 01:45:33,700
given by

1760
01:45:33,710 --> 01:45:35,720
and the parameters theta

1761
01:45:35,720 --> 01:45:38,890
obtrusions and ligatures

1762
01:45:38,930 --> 01:45:45,330
had enlarged the mouth cut away the lips led bare the gums distended the ears cut

1763
01:45:45,360 --> 01:45:51,710
the cartilages displaced the eyelids and the cheeks enlarged the zygomatic muscle

1764
01:45:51,870 --> 01:45:57,700
pressed the scars and cicatrices to a level turned back the skin over the lesions whilst

1765
01:45:57,700 --> 01:46:00,570
the face was thus stretched

1766
01:46:00,610 --> 01:46:07,320
from all which resulted that powerful and profound piece of sculpture

1767
01:46:07,350 --> 01:46:08,470
the mask

1768
01:46:08,510 --> 01:46:16,890
Gwynplaine the search for the interest in of the grotesque also leads us to that

1769
01:46:16,930 --> 01:46:19,200
image to imagine

1770
01:46:19,200 --> 01:46:21,330
the deformity

1771
01:46:21,350 --> 01:46:24,450
that drags to our the tragic destiny

1772
01:46:24,640 --> 01:46:31,240
those who may be mean by nature are condemned by their own bodies

1773
01:46:31,240 --> 01:46:37,220
like the first and happy ugly man of romanticism the monster in frankenstein

1774
01:46:37,550 --> 01:46:42,390
or the heroes of verdi's melodramas like rigoletto

1775
01:46:42,410 --> 01:46:46,200
or cyrano de bergerac

1776
01:46:46,350 --> 01:46:55,370
as well as women condemn to an everlasting unhappiness by their unpleasant countenance

1777
01:46:55,390 --> 01:46:57,470
there is a short story

1778
01:46:57,490 --> 01:46:59,320
by zola

1779
01:46:59,350 --> 01:47:02,260
le repourssoir

1780
01:47:02,260 --> 01:47:06,200
a certain Durandeau realizes them that

1781
01:47:06,240 --> 01:47:07,510
on scene

1782
01:47:07,530 --> 01:47:13,450
two women walking together and when one of them is visibly ugly

1783
01:47:13,620 --> 01:47:18,820
then by contrast everyone finds the other one pretty

1784
01:47:19,080 --> 01:47:23,450
so he decides to make ugliness the business

1785
01:47:23,870 --> 01:47:29,800
and sets up an agency were ladies can hire an ugly female partner

1786
01:47:29,800 --> 01:47:35,620
to stroll along the side and thus highlight their own good looks

1787
01:47:35,680 --> 01:47:42,200
eventhough sometimes the client is even uglier than other companion is offered to her

1788
01:47:42,200 --> 01:47:48,030
and then she discover her own scarce attractiveness all in that moment

1789
01:47:48,140 --> 01:47:53,120
it's awful to read about the recruitment process and the way which ugly women

1790
01:47:53,120 --> 01:47:56,300
are told about the reasons and the purpose

1791
01:47:56,330 --> 01:47:58,310
for them being hired

1792
01:47:58,620 --> 01:48:03,600
but what is even worse is the suffering of the chosen candidates

1793
01:48:03,600 --> 01:48:10,200
who after enjoying a day spent dressed elegantly at the theater or an

1794
01:48:10,200 --> 01:48:18,010
expensive restaurant in the company of a high society lady must return to their lonely

1795
01:48:18,010 --> 01:48:26,200
lodging of an evening faced with the mirror that reminds them of the atrocious

1796
01:48:27,490 --> 01:48:32,510
and it is the same mirror which is quoted by the young sartre

1797
01:48:32,890 --> 01:48:39,660
in which he discovered his own condition of an irremediably unattractive man

1798
01:48:39,660 --> 01:48:46,830
and an ugly duckling beyond redemption terrible pictures

1799
01:48:48,950 --> 01:48:54,820
was especially indulgent even with the most repugnant forms of physical

1800
01:48:54,820 --> 01:49:02,930
decomposition poems by baudelaire and and from the nineteenth century onwards

1801
01:49:02,950 --> 01:49:08,620
the corruption caused by lung disease is a sublimated not

1802
01:49:08,620 --> 01:49:12,160
only by literature but also by painting

1803
01:49:12,660 --> 01:49:14,760
whether the artists make

1804
01:49:14,800 --> 01:49:22,180
idolized portrayals of the exhaused abandoned of beauty on the verge

1805
01:49:22,180 --> 01:49:23,410
of death

1806
01:49:23,430 --> 01:49:29,200
let me quote only short passage from barbey d'aurevilly yes my lea you are

1807
01:49:30,300 --> 01:49:38,550
you are the most beautiful of creatures I wouldn't give up your defeated eyes your pallor your sick body

1808
01:49:38,550 --> 01:49:43,100
I would not give them for the beauty of the angles in the heavens

1809
01:49:43,140 --> 01:49:44,200
in the heavens

1810
01:49:44,430 --> 01:49:49,600
that dying women burnt him like the most ardent of

1811
01:49:51,820 --> 01:49:57,720
in the beginning of the twentieeth century the futurists fought against moonlight

1812
01:49:57,720 --> 01:50:04,780
museum and libraries and set themselves the task of boldly producing

1813
01:50:06,430 --> 01:50:08,490
and the palazzeschi

1814
01:50:08,530 --> 01:50:16,820
in Il controdolore called for the younger generations to receive an education in the disgusting

1815
01:50:16,830 --> 01:50:22,550
we have to teach our children to laugh to laugh the most unrestrained insolent laughter

1816
01:50:22,800 --> 01:50:30,370
we will supply them with educational toys hump humpbacked blind gangrenous crippled

1817
01:50:30,370 --> 01:50:39,430
consumptive syphilitic puppets that mechanical cry shout complain are afflicted with epilepsy plague cholera hemorrhoids

1818
01:50:39,430 --> 01:50:45,180
the clap insanity puppets that faint emit the death rattle and die

1819
01:50:45,450 --> 01:50:51,580
their teacher will suffer from dropsy and elephantiasis or be thin as a rail

1820
01:50:51,580 --> 01:50:59,140
long limbed with the neck like a giraffe one tiny little teacher a stunted hunchback and

1821
01:50:59,140 --> 01:51:04,930
another gigantic teacher with the prepubescent face and extremely feeble voice

1822
01:51:04,930 --> 01:51:09,080
who weeps tars tears like shards of glass

1823
01:51:09,180 --> 01:51:14,820
we futurists want to cure the latin races especially our own of

1824
01:51:14,970 --> 01:51:22,910
of conscious pain conformist syphillis aggrevated by the chronic romanticism and of the monstrous susceptibility

1825
01:51:23,140 --> 01:51:28,720
and piteous sentimentalism that depress every Italian we want to substitute the

1826
01:51:28,720 --> 01:51:34,600
use of perfumes with the use of stench transforming insane asylums into

1827
01:51:34,600 --> 01:51:39,100
finishing school for our new generations

1828
01:51:39,480 --> 01:51:46,030
boccioni called a sculpture also that painting antigrazzioso

1829
01:51:46,050 --> 01:51:54,760
and up right then German Expressionist portrayed with systematic and ruthless insistence haggard and repugnant

1830
01:51:54,760 --> 01:51:55,950
will located

1831
01:51:56,200 --> 01:52:00,890
and some of you want know that two or three on that file sequence

1832
01:52:01,390 --> 01:52:05,030
what i did so it was that i i'm at

1833
01:52:06,490 --> 01:52:09,180
ten five around here

1834
01:52:09,200 --> 01:52:14,890
and i'm that the difference between where where the or should be given that i've

1835
01:52:14,890 --> 01:52:18,910
got the the building blocks of the detector and the actual like words

1836
01:52:18,950 --> 01:52:20,990
you actually see that

1837
01:52:21,010 --> 01:52:22,970
but i actually think that are

1838
01:52:22,990 --> 01:52:28,820
that helps me to the search will was actually making things problematic to sense that

1839
01:52:28,890 --> 01:52:32,950
i there's a lot of noise in the school so if i to have a

1840
01:52:32,950 --> 01:52:37,010
face detector and i want to go use in based recognition or want to go

1841
01:52:37,030 --> 01:52:39,470
use that expression recognition all want to go

1842
01:52:39,550 --> 01:52:40,680
news it's a

1843
01:52:40,680 --> 01:52:43,070
in recognizing motorcycles or or

1844
01:52:43,070 --> 01:52:47,030
OK and things like i've got all this noise

1845
01:52:47,070 --> 01:52:48,720
president my signals

1846
01:52:48,720 --> 01:52:53,370
because i'm not only so i've got a lot want to separate one one person's

1847
01:52:53,370 --> 01:52:56,590
identity from another person's identity coupled in there

1848
01:52:56,600 --> 01:52:58,410
is this what noise because

1849
01:52:58,410 --> 01:53:02,240
the things that align properly so pixels long probably without the pixel

1850
01:53:02,240 --> 01:53:03,140
and so

1851
01:53:03,410 --> 01:53:07,700
i need to improve upon this along and just pure translation scale is not to

1852
01:53:11,280 --> 01:53:13,570
this is a slightly less naive approach

1853
01:53:13,570 --> 01:53:18,120
so instead of simply through all possible positions from the best match

1854
01:53:18,140 --> 01:53:22,250
that's the standard linear regression can we later as you as well the statue of

1855
01:53:22,250 --> 01:53:26,340
volcanology regression between the appearance displacement

1856
01:53:26,360 --> 01:53:28,890
and the what spice

1857
01:53:28,910 --> 01:53:31,470
OK i can expand upon what i mean by that

1858
01:53:31,840 --> 01:53:36,590
so we we no longer have to make assumptions about discrete assumptions about what this

1859
01:53:36,590 --> 01:53:39,990
is one thing i really like this instead of having to

1860
01:53:40,010 --> 01:53:43,010
kind of all we have to give you have all this give the positive and

1861
01:53:43,010 --> 01:53:49,490
negative object classes can actually have an object an object detector where i can precisely

1862
01:53:49,490 --> 01:53:55,140
recognise you object to some sort of hard parametric what sort of finds exactly have

1863
01:53:55,140 --> 01:53:58,840
always annoys nose-to-nose mouth-to-mouth rather kind had some game

1864
01:53:58,860 --> 01:54:04,240
and also away the given that are making the wall much more complex is are

1865
01:54:04,280 --> 01:54:11,510
in continuous now is or whether to make the computation based

1866
01:54:11,570 --> 01:54:13,220
and so

1867
01:54:13,220 --> 01:54:15,200
what we essentially trying to do

1868
01:54:15,220 --> 01:54:18,410
is that if one of the cover regression

1869
01:54:18,410 --> 01:54:20,200
between essentially what we want to do

1870
01:54:20,200 --> 01:54:22,530
is that if i got this image here

1871
01:54:22,550 --> 01:54:24,860
which is the aligned image minus

1872
01:54:24,870 --> 01:54:29,200
this image which is the whole people of misaligned images i want to learn a

1873
01:54:30,090 --> 01:54:35,030
between the the displacement of all these values and don't appear

1874
01:54:35,070 --> 01:54:37,910
which is which is my which is my walk noise

1875
01:54:38,120 --> 01:54:42,740
another and so on got a couple of properties but i need first define the

1876
01:54:42,740 --> 01:54:45,030
distribution what this talk he should be

1877
01:54:45,090 --> 01:54:47,240
so i mean how far

1878
01:54:47,260 --> 01:54:51,050
can i have can i take this assumption and things that how far this regression

1879
01:54:51,050 --> 01:54:56,120
where can i make delta p like how can i go hundred by pixels are

1880
01:54:56,120 --> 01:54:59,360
going to about two pixels have partial my delta patient

1881
01:54:59,870 --> 01:55:05,060
and actually more the question is is there a relationship and what we can being

1882
01:55:05,060 --> 01:55:06,680
naive here i mean the

1883
01:55:06,740 --> 01:55:09,700
can we actually do something that doesn't make any sense

1884
01:55:09,700 --> 01:55:14,320
and then when does the relationship occur by which comes back to answer these two

1885
01:55:17,550 --> 01:55:21,120
if you remembering from what we've shown in the previous slides you should be able

1886
01:55:21,120 --> 01:55:24,740
to guess that well that doesn't really relate relationship doesn't it if we look at

1887
01:55:24,740 --> 01:55:26,410
the pixel coherence assumption

1888
01:55:26,430 --> 01:55:31,090
pixels are correlated with each other least individually over small area so that does seem

1889
01:55:31,090 --> 01:55:34,870
to be some sort of relationship that we can leverage the same as it doesn't

1890
01:55:34,870 --> 01:55:36,220
seem like we can come to go

1891
01:55:36,360 --> 01:55:41,760
so pixel at point zero zero twenty two highly correlated with the pixel let's say

1892
01:55:41,820 --> 01:55:46,570
fifty fifty or sixty sixty image things so that the assumptions one you guys so

1893
01:55:47,530 --> 01:55:51,070
so i can quantify this what can i do

1894
01:55:51,120 --> 01:55:54,550
so undermining of the pixel coherence assumption

1895
01:55:54,550 --> 01:56:01,530
moving around and we get this kind of nice graceful the degradation the correlation

1896
01:56:01,550 --> 01:56:06,340
for natural image

1897
01:56:06,360 --> 01:56:12,320
and then might have target patches i think they just put in that that like

1898
01:56:12,340 --> 01:56:15,450
the fact that this is not

1899
01:56:16,200 --> 01:56:22,620
so pixel coherence so the pixel coherence assumption demonstrates the pixels within natural images are

1900
01:56:22,620 --> 01:56:27,140
heavily correlated with one another and within sight a local area this is again at

1901
01:56:27,200 --> 01:56:32,090
war with itself plus and minus five pixels it depends on the same scale and

1902
01:56:32,090 --> 01:56:36,680
also it's fine enough depends on what the content of the images but generically can

1903
01:56:36,680 --> 01:56:41,550
quite safely say that natural image so we can actually do a pretty good job

1904
01:56:41,550 --> 01:56:45,530
if we know that this is an actual image predicting even if this pixels missing

1905
01:56:45,710 --> 01:56:49,690
of predicting what this pixel is so i can probably take the average order all

1906
01:56:49,690 --> 01:56:51,050
these other values and

1907
01:56:51,340 --> 01:56:53,260
it comes at three princes

1908
01:56:53,260 --> 01:56:54,260
i think so

1909
01:56:54,320 --> 01:56:59,100
and i can very very the support region around the missing pixels things but generally

1910
01:56:59,100 --> 01:57:03,090
a local region there highly correlated likely

1911
01:57:03,140 --> 01:57:05,120
and so

1912
01:57:05,140 --> 01:57:06,470
what i can actually

1913
01:57:06,470 --> 01:57:07,390
i don't

1914
01:57:07,410 --> 01:57:11,450
it is a kind of incorporate the idea the image gradient into my idea of

1915
01:57:12,390 --> 01:57:17,240
and so we touched upon the image gradients already for aliasing kind deal with in

1916
01:57:17,300 --> 01:57:21,340
doing the by linear interpolation and things so

1917
01:57:21,360 --> 01:57:24,570
great it's going to come back and help us actually to do the search so


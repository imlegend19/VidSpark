1
00:00:00,000 --> 00:00:03,640
some kind of features of the interaction of nodes u and right i want to

2
00:00:03,640 --> 00:00:04,620
estimate the

3
00:00:04,630 --> 00:00:10,100
this set of weights w that sort of thing only that combines these features and

4
00:00:10,300 --> 00:00:14,750
and whatever the value of this expression becomes that would be like edge edge weight

5
00:00:14,760 --> 00:00:17,090
at strength here OK so

6
00:00:17,350 --> 00:00:20,310
once they can now this weighted graph

7
00:00:20,330 --> 00:00:26,100
now i will do the random walk with restarts starting from as so this is

8
00:00:26,120 --> 00:00:34,020
personalized pagerank with teleportation back to paula jumps back to us and i will this

9
00:00:34,020 --> 00:00:39,320
and now every node gets away which is the random walk visiting probability and i've

10
00:00:39,320 --> 00:00:44,850
just going to the nodes by this the workers the probability and that my prediction

11
00:00:44,850 --> 00:00:48,150
writes in some sense of what i'm doing is i'm learning how to rank nodes

12
00:00:48,150 --> 00:00:52,920
in a graph where i would start with a simple graph i will learn how

13
00:00:52,920 --> 00:00:56,960
to put weight on it so that might and walker sort of bias towards certain

14
00:00:56,960 --> 00:01:00,550
parts of the graph and not biased towards the other parts of the graph so

15
00:01:00,550 --> 00:01:05,250
the main question would be how this function as right how to estimate the parameters

16
00:01:05,250 --> 00:01:11,650
w so that somehow magically by scientists edge strands well it quickly so that my

17
00:01:11,650 --> 00:01:15,170
random walk ends up in one part of the graph and not part of the

18
00:01:15,170 --> 00:01:19,280
graph OK so now what i will show you the way how to estimate is

19
00:01:19,280 --> 00:01:20,960
about how to estimate this

20
00:01:20,980 --> 00:01:25,140
a function that assigns a strand two and h OK so

21
00:01:25,150 --> 00:01:28,710
here is how it is that right so the idea is first is to to

22
00:01:28,710 --> 00:01:34,730
formalise this stochastic random walk transition matrix i reported you right and what it says

23
00:01:34,780 --> 00:01:40,300
probability that that you reverse engine is proportional to the weight of the edge and

24
00:01:40,500 --> 00:01:42,960
if there is no edge then probability of going

25
00:01:43,270 --> 00:01:48,290
the two you is zero right and then five write down what is the pagerank

26
00:01:48,290 --> 00:01:51,060
equations here is the page incorporation right i say

27
00:01:51,070 --> 00:01:54,300
my my transition probabilities

28
00:01:54,800 --> 00:02:00,660
are are sort of my my state is what when i was before or this

29
00:02:00,670 --> 00:02:04,300
is the random jump right so with probability one minus five make a step in

30
00:02:04,300 --> 00:02:08,450
the graph and with probability alpha i john back to my my and the work

31
00:02:08,460 --> 00:02:13,560
of john back to the starting right and now that i that a computer that

32
00:02:13,560 --> 00:02:17,720
they have this transition matrix q and computer agent b

33
00:02:17,750 --> 00:02:20,470
of these of this matrix q where

34
00:02:20,920 --> 00:02:27,400
and now i think nodes by the pagerank is the probability of of right so

35
00:02:27,400 --> 00:02:31,320
that this is what i will do know my question is what how why how

36
00:02:31,320 --> 00:02:34,590
do i figured out what this weight should be and we figured out a way

37
00:02:34,590 --> 00:02:39,530
to to say what i want to know what the parameters w of my function

38
00:02:39,530 --> 00:02:44,010
after that assigns is due to the edge weights the going to my

39
00:02:44,030 --> 00:02:51,870
and what transition probability from random opposition probably i computes i compute these probabilities

40
00:02:51,890 --> 00:02:56,270
and then i ran by visiting probability is OK so this is the way how

41
00:02:56,270 --> 00:03:01,080
we how we are doing the whole thing so the next day the optimisation problem

42
00:03:01,080 --> 00:03:06,780
we like to solve the following right so for every every node has has pagerank

43
00:03:07,300 --> 00:03:11,100
let's call it visiting probability of score piece of your right and then i have

44
00:03:11,100 --> 00:03:15,890
a set of destination nodes disagree nodes of myself of positive training examples and i

45
00:03:15,890 --> 00:03:21,080
have a set of red nodes that have been called nobody knows this i colored

46
00:03:21,080 --> 00:03:25,430
the was communities are the the which one great things in the future right so

47
00:03:25,430 --> 00:03:28,210
what i would like to do is the follow so here are some of my

48
00:03:28,210 --> 00:03:33,130
my optimisation problem i say i want to find i want to find w right

49
00:03:33,130 --> 00:03:38,330
wrt the parameters of the function of the size and strength i want to find

50
00:03:38,330 --> 00:03:42,940
w that is small and i want this to w to be such that the

51
00:03:42,940 --> 00:03:49,580
visiting probability of nodes of the nodes are higher than the visiting probability of right

52
00:03:49,580 --> 00:03:54,220
so i want i want to find such an w that ITN my positive training

53
00:03:54,220 --> 00:03:58,380
examples are to visit more often than during the work on the negative training examples

54
00:03:58,380 --> 00:04:01,430
right so all the sort of the the

55
00:04:02,350 --> 00:04:05,960
the really what you want to do is i want to satisfy these constraints i

56
00:04:05,960 --> 00:04:09,670
don't care so much about his WR's like i want to find w such that

57
00:04:09,670 --> 00:04:13,210
all these constraints are satisfied right in the way i can do this is to

58
00:04:13,220 --> 00:04:17,170
take these constraints input and put them into the objective function and say OK this

59
00:04:17,170 --> 00:04:19,870
is what we want to do that i want to say hi i want to

60
00:04:19,870 --> 00:04:23,900
find w such that w is small it doesn't matter and then he is might

61
00:04:23,900 --> 00:04:29,130
want say right laws goes over all pairs of positive and negative examples and it

62
00:04:29,130 --> 00:04:34,950
takes the probability of n being the probability of being of being visited and now

63
00:04:34,950 --> 00:04:38,870
i think the difference and here is how i can so for example analyse distance

64
00:04:38,870 --> 00:04:45,620
i say half if renault has using probability less the degree node then the difference

65
00:04:45,620 --> 00:04:48,000
is negative and i could no penalty

66
00:04:48,020 --> 00:04:54,210
if you the constrained in some sense is violated so we might negative note my

67
00:04:54,210 --> 00:04:58,960
note to richard creating in the future is visited more likely than some nodes which

68
00:04:58,960 --> 00:05:04,070
i created in the future then i got some penalty but let's is is proportional

69
00:05:04,070 --> 00:05:04,680
to the east

70
00:05:04,690 --> 00:05:08,340
the difference is probably right so now i think the constraints in the previous slide

71
00:05:08,340 --> 00:05:11,480
i just put them in the objective function right so what i'd really like to

72
00:05:11,480 --> 00:05:16,340
do is figure out w so that the sum is the smallest possible right and

73
00:05:16,340 --> 00:05:22,170
this is like a regularization part of the optimisation problem right so this is this

74
00:05:22,170 --> 00:05:25,220
is what we can and now of course what i want i want to solve

75
00:05:25,220 --> 00:05:30,030
this problem so the way i can solve this is is to is to do

76
00:05:30,030 --> 00:05:32,590
the following things right so what is

77
00:05:32,600 --> 00:05:37,470
thing probabilities depend on the right independent w which is the

78
00:05:37,490 --> 00:05:41,450
parameters of the extract the sine function the weight so the way the whole thing

79
00:05:41,450 --> 00:05:45,170
works is right i have this this w goes into my

80
00:05:45,320 --> 00:05:50,720
my function of the size and strength and standard defines the weighted adjacency matrix of

81
00:05:50,720 --> 00:05:56,670
woodbridge then i what pagerank to obtain this but this rank this visiting probability speed

82
00:05:56,700 --> 00:06:00,500
and then i rank nodes based on these probabilities p right and i want to

83
00:06:00,500 --> 00:06:02,370
find such w the

84
00:06:02,380 --> 00:06:05,700
in some sense for any for every node

85
00:06:05,720 --> 00:06:10,390
you get a higher value than every read then every right sort of the nodes

86
00:06:10,390 --> 00:06:15,080
linking nodes need to have need to be less likely to be visited the nodes

87
00:06:15,080 --> 00:06:18,420
that i think OK so that's that's what we'd like to do so now the

88
00:06:18,420 --> 00:06:23,140
question is how do i get publicity w together down here so there's a few

89
00:06:23,140 --> 00:06:26,230
steps in between how WMP i think

90
00:06:26,250 --> 00:06:29,870
OK so the way i can think about this is basically i can just think

91
00:06:29,870 --> 00:06:34,990
of this as taking the derivative of this of this optimisation problem and try to

92
00:06:34,990 --> 00:06:39,410
do try to some kind of descent gradient descent right and what is interesting is

93
00:06:39,430 --> 00:06:40,670
if i think

94
00:06:40,690 --> 00:06:46,660
now here's my function i think that would be the vector w and and if

95
00:06:46,660 --> 00:06:51,080
i write now the partial derivatives the question the question because i think the idea

96
00:06:51,100 --> 00:06:56,750
of the pagerank score with respect to my parameters w and what is interesting is

97
00:06:56,750 --> 00:07:01,350
the same way as you as you have because way to compute pagerank scores through

98
00:07:01,350 --> 00:07:06,320
power iteration it turns out that you can compute the derivatives in the same kind

99
00:07:07,120 --> 00:07:12,440
recursive power iteration lightweight right so the derivative of of a particular w with the

100
00:07:12,440 --> 00:07:16,660
partition of the making of a particular

101
00:07:16,680 --> 00:07:22,620
element of my w i can produce using this kind of crazy right so the

102
00:07:22,620 --> 00:07:27,010
which is sort of like a power iteration so basically it what this shows is

103
00:07:27,010 --> 00:07:30,140
that i can in principle the way to find this

104
00:07:30,150 --> 00:07:32,620
the parameters of the strand

105
00:07:32,630 --> 00:07:34,520
assigning functions

106
00:07:34,520 --> 00:07:38,230
time t and acceleration on p

107
00:07:38,280 --> 00:07:43,150
if you measure the child's genes

108
00:07:43,160 --> 00:07:47,810
then those should be independent of the grandparents genes given the parent genes

109
00:07:47,860 --> 00:07:52,670
if you have some competition with lots of different teams

110
00:07:53,610 --> 00:07:55,440
then presumably

111
00:07:55,450 --> 00:08:01,000
as long as the teams are taking players from the very large all the ability

112
00:08:01,000 --> 00:08:01,880
of some

113
00:08:01,930 --> 00:08:07,570
he knew picking random is independent of the ability of another team you take random

114
00:08:07,700 --> 00:08:08,980
and that all

115
00:08:10,350 --> 00:08:12,790
so that the marginal independent

116
00:08:12,830 --> 00:08:14,750
think like you know

117
00:08:14,760 --> 00:08:16,780
some sort of big we

118
00:08:16,800 --> 00:08:17,840
but now

119
00:08:18,160 --> 00:08:20,170
it's not the case

120
00:08:20,220 --> 00:08:25,070
that the ability of team a is independent of the ability of team b

121
00:08:25,510 --> 00:08:27,490
if we actually know knows

122
00:08:27,550 --> 00:08:31,320
the outcome of the game between a and b

123
00:08:31,370 --> 00:08:35,050
so i just want to have one example of something where

124
00:08:36,300 --> 00:08:41,380
conditioned on the knowledge which we presume is actually a function

125
00:08:41,390 --> 00:08:49,330
these two two things then those two things that were marginally independent are no longer

126
00:08:49,350 --> 00:08:53,110
independent conditioned on that knowledge

127
00:08:53,160 --> 00:08:55,830
so any questions about that

128
00:08:55,840 --> 00:09:00,700
OK so we're trying to represent conditional independence between variables

129
00:09:00,750 --> 00:09:04,700
and let's start out with factor graphs although these are sort of the most

130
00:09:04,790 --> 00:09:10,660
the most modern one there nice easy to understand

131
00:09:10,680 --> 00:09:14,630
so in fact that we have two types of nodes we have the

132
00:09:15,890 --> 00:09:21,750
represents the random variables like for example a and then we have filled dots represent

133
00:09:21,850 --> 00:09:24,800
factors in the joint distribution

134
00:09:24,850 --> 00:09:31,460
so for example there's still but here connecting a and c and that represents a

135
00:09:31,480 --> 00:09:32,730
back there

136
00:09:32,740 --> 00:09:36,370
in the joint distribution of that by factor i just mean

137
00:09:36,960 --> 00:09:40,290
non negative function of its arguments

138
00:09:40,310 --> 00:09:44,980
and essentially what a factor graph represent is

139
00:09:44,990 --> 00:09:48,980
the factorisation of a joint probability distribution so

140
00:09:48,990 --> 00:09:51,180
factor graph h here

141
00:09:51,230 --> 00:09:56,250
represents the that the probability distribution of a b c d and e

142
00:09:56,260 --> 00:10:01,000
factors into the product of a distribution over a and c

143
00:10:01,020 --> 00:10:02,560
the distribution over

144
00:10:02,570 --> 00:10:05,850
sorry not distribution a non negative function

145
00:10:05,860 --> 00:10:08,390
between a and c

146
00:10:08,400 --> 00:10:12,320
a non negative function of b c and d

147
00:10:12,330 --> 00:10:16,330
and and non negative function of the e

148
00:10:16,350 --> 00:10:21,750
OK and this term here is simply a normalisation constant

149
00:10:21,760 --> 00:10:28,280
so that when you multiply these three nonnegative functions you get something that integrates or

150
00:10:28,280 --> 00:10:30,380
sums to one

151
00:10:32,370 --> 00:10:35,370
that was before

152
00:10:37,400 --> 00:10:43,930
for graph b we are representing five different factorizations which have written down here

153
00:10:43,940 --> 00:10:51,270
and just to drive the point home z is a normalisation constant in other words

154
00:10:51,280 --> 00:10:57,440
in in this probability distribution is represented by the a factor graph a if all

155
00:10:57,440 --> 00:11:00,610
variables are discrete and take values in

156
00:11:01,710 --> 00:11:07,150
a b c d and e corresponding to the names of those variables then normalisation

157
00:11:07,150 --> 00:11:12,300
function is just the sum over all possible values of a b

158
00:11:12,310 --> 00:11:16,220
the PDE of the product of these factors

159
00:11:16,450 --> 00:11:20,440
we're going to define two nodes v neighbors if they share a common factor

160
00:11:20,590 --> 00:11:23,860
so for example a and c are neighbours

161
00:11:27,500 --> 00:11:33,040
at the top i've just rewritten stuff that i had on the previous slide

162
00:11:33,160 --> 00:11:38,400
now let's think about what the factor graph represents in terms of conditional independence relationships

163
00:11:38,400 --> 00:11:40,700
between the variables

164
00:11:40,720 --> 00:11:42,050
so remember

165
00:11:42,420 --> 00:11:46,650
two nodes are neighbors if they share a common factor

166
00:11:46,700 --> 00:11:51,270
and we're going to define the pattern to be a sequence of neighboring nodes for

167
00:11:52,150 --> 00:11:53,620
a b b

168
00:11:53,630 --> 00:11:55,880
in the past

169
00:11:55,890 --> 00:11:57,890
and here's the back

170
00:11:59,980 --> 00:12:01,010
is it

171
00:12:01,050 --> 00:12:02,630
independent of y

172
00:12:03,690 --> 00:12:05,370
this is that the

173
00:12:05,420 --> 00:12:08,480
if every path between x and y

174
00:12:09,720 --> 00:12:13,680
contains some nodes in the set b

175
00:12:15,250 --> 00:12:20,020
just by looking at the factor graph and knowing that the factor graph correspond to

176
00:12:20,030 --> 00:12:25,270
some factorizations of the joint probability distribution we can say all sorts of things about

177
00:12:25,270 --> 00:12:29,690
which variables are independent of which other variables

178
00:12:30,840 --> 00:12:33,230
according to the area of the fact

179
00:12:33,280 --> 00:12:35,610
which is fairly trivial

180
00:12:35,620 --> 00:12:40,670
is that given the neighbors of x the variable x is conditionally independent of all

181
00:12:40,670 --> 00:12:43,200
other variables which we can write out

182
00:12:43,220 --> 00:12:47,450
x is independent of y given the neighbors of x for all y that are

183
00:12:47,500 --> 00:12:50,070
x and the neighbours of

184
00:12:50,180 --> 00:12:57,400
and that's pretty clear because if this is true then every path between something else

185
00:12:57,400 --> 00:12:59,700
has to go to one of its neighbors

186
00:13:02,750 --> 00:13:04,490
so how do we show

187
00:13:04,510 --> 00:13:06,530
a statement like this

188
00:13:07,990 --> 00:13:10,310
remember we started out with

189
00:13:10,320 --> 00:13:15,610
with the fact that this graph represents that the probability distribution factors in a particular

190
00:13:17,390 --> 00:13:22,470
and from that we're making grand claims about conditional independence

191
00:13:26,430 --> 00:13:32,100
but i think you look at the following conditional independence was x is conditionally independent

192
00:13:32,110 --> 00:13:33,670
of y given the

193
00:13:33,680 --> 00:13:39,620
that correspond to this big one way of writing that they

194
00:13:41,340 --> 00:13:43,490
so we have the following

195
00:13:43,500 --> 00:13:45,600
factorizations let's say

196
00:13:45,670 --> 00:13:48,940
the joint distribution of x y

197
00:13:48,950 --> 00:13:50,040
in the

198
00:13:50,050 --> 00:13:54,190
can be written as the product of factor

199
00:13:54,230 --> 00:13:55,840
between x and b

200
00:13:55,860 --> 00:13:58,910
and in fact there are between y and p

201
00:13:58,950 --> 00:14:01,540
and some normalisation constant z

202
00:14:03,320 --> 00:14:05,840
so this is what we're going to start

203
00:14:06,960 --> 00:14:09,780
i think this equation here

204
00:14:10,690 --> 00:14:12,980
some this over x

205
00:14:13,790 --> 00:14:16,730
so we sum both sides of the equation

206
00:14:16,750 --> 00:14:18,210
over x

207
00:14:18,220 --> 00:14:23,880
on the left-hand side we get the joint distribution over y and v

208
00:14:23,880 --> 00:14:28,380
this week summed over x and that some one

209
00:14:30,010 --> 00:14:36,540
on the right-hand side the normalisation constant comes out and we get some

210
00:14:36,540 --> 00:14:38,060
it this one

211
00:14:38,070 --> 00:14:39,020
and so on

212
00:14:39,030 --> 00:14:41,930
if you compute the probability of

213
00:14:41,970 --> 00:14:48,250
being at the same time sick and having a positive test and it the probability

214
00:14:48,250 --> 00:14:49,460
of being in the

215
00:14:49,890 --> 00:14:56,080
the upper left corner there ninety or one thousand one hundred

216
00:14:56,100 --> 00:14:58,780
and in then it affinity different of

217
00:15:00,350 --> 00:15:01,750
different from

218
00:15:01,760 --> 00:15:06,650
the product of the probability of being of having a positive test which is

219
00:15:06,690 --> 00:15:09,730
one nine c

220
00:15:09,750 --> 00:15:14,320
divided by one thousand one hundred

221
00:15:14,330 --> 00:15:21,420
and then the probability of being sick which is one hundred if you divided by

222
00:15:21,430 --> 00:15:23,440
one thousand one hundred

223
00:15:25,950 --> 00:15:29,140
obviously here

224
00:15:29,150 --> 00:15:32,480
as would be expected you have

225
00:15:32,490 --> 00:15:36,310
more chances of being sick

226
00:15:36,790 --> 00:15:38,970
when the test

227
00:15:39,020 --> 00:15:40,450
it was positive

228
00:15:40,460 --> 00:15:43,690
when you have more chances of being

229
00:15:43,750 --> 00:15:50,970
being being fits when the test is negative so you expect that the two variables

230
00:15:50,970 --> 00:15:57,040
are actually not independent their quality corey and that's what is your right

231
00:16:03,150 --> 00:16:05,760
no right

232
00:16:05,780 --> 00:16:10,500
so the independence is defined as follows the independent variables

233
00:16:10,520 --> 00:16:16,220
in the two variables x and y are independent if and only if their joint

234
00:16:16,220 --> 00:16:19,090
probability is is the product the product of the

235
00:16:19,100 --> 00:16:25,310
my marginal probabilities so the marginal if if you consider a vector x y of

236
00:16:25,320 --> 00:16:27,820
two random variables the marginals

237
00:16:27,840 --> 00:16:33,940
in x is the probability of x and the marginalize the probability one

238
00:16:33,970 --> 00:16:43,250
it if it follows and if you have an independent variable

239
00:16:43,270 --> 00:16:50,040
then the other their joint probability is the the product of their probabilities

240
00:16:54,510 --> 00:16:57,440
and so you can see that since

241
00:16:57,470 --> 00:16:59,990
the covariance of x and y

242
00:17:00,010 --> 00:17:04,000
is defined as

243
00:17:04,020 --> 00:17:09,040
if you remember the covariance of x and y

244
00:17:09,090 --> 00:17:26,830
is defined as the expectation x y

245
00:17:26,860 --> 00:17:29,700
nine is the expectation of

246
00:17:37,010 --> 00:17:39,690
don't the asian of y

247
00:17:39,700 --> 00:17:44,020
since as can be seen there when you have to

248
00:17:44,070 --> 00:17:49,740
and when you have two independent variables and you have an expectation of two function

249
00:17:49,750 --> 00:17:56,440
of the survival then you can break up to expectation into two single part of

250
00:17:56,530 --> 00:18:02,340
x y then you see that the covariance

251
00:18:02,350 --> 00:18:05,550
after independent

252
00:18:05,560 --> 00:18:08,000
by one you

253
00:18:11,980 --> 00:18:17,730
so this is all there was the

254
00:18:17,780 --> 00:18:20,700
ways to to

255
00:18:20,700 --> 00:18:27,480
was being independent is the following if you think about it in

256
00:18:27,490 --> 00:18:31,400
if you think about too

257
00:18:33,220 --> 00:18:35,980
volume was x and y

258
00:18:36,000 --> 00:18:39,770
then the expectation of

259
00:18:39,780 --> 00:18:43,600
u of x times age of y

260
00:18:43,650 --> 00:18:46,560
we can write it in our two

261
00:18:46,580 --> 00:18:53,540
with the with the densities i

262
00:18:56,130 --> 00:18:57,780
p of x y

263
00:18:57,840 --> 00:18:59,140
x y

264
00:19:00,640 --> 00:19:01,560
since then

265
00:19:01,580 --> 00:19:02,780
and since the

266
00:19:02,790 --> 00:19:08,360
random variables are independent you can people broken into two parts

267
00:19:08,380 --> 00:19:13,040
which are

268
00:19:21,600 --> 00:19:23,790
the two more probabilities

269
00:19:23,810 --> 00:19:32,170
and i can split up the citizens line or two in our as the product

270
00:19:32,170 --> 00:19:37,130
of two into was two intervals in our right by building on on the left

271
00:19:37,130 --> 00:19:37,970
side order

272
00:19:38,440 --> 00:19:43,260
there an accident on the right sail sailed the terms in white and so that

273
00:19:43,260 --> 00:19:45,840
gives you

274
00:19:45,860 --> 00:19:49,470
the reason why could right

275
00:19:49,480 --> 00:19:52,300
that for any function

276
00:19:56,170 --> 00:20:03,310
i could break up the probability into the expectation into two parts

277
00:20:03,330 --> 00:20:05,670
that would be the expectation of

278
00:20:05,700 --> 00:20:09,190
p of x and that the expectation of it of y

279
00:20:11,390 --> 00:20:18,290
that basically what's what's written there

280
00:20:18,320 --> 00:20:22,290
all right so computing things for

281
00:20:22,640 --> 00:20:27,760
joint vectors x y when x and y are independent is pretty easy

282
00:20:27,780 --> 00:20:35,230
and also means that if x and y are independent then basically knowing that an

283
00:20:35,240 --> 00:20:38,140
you have any information on on line

284
00:20:41,750 --> 00:20:47,420
on the contrary when x and y are not independent then definitely knowing x gives

285
00:20:47,420 --> 00:20:49,810
you some information on one

286
00:20:49,830 --> 00:20:54,330
and so we'll we'll we'll see what the conditional expectation

287
00:20:54,350 --> 00:20:57,560
the conditional probabilities mean then

288
00:20:57,590 --> 00:21:01,760
the conditional probability of x given

289
00:21:03,290 --> 00:21:04,280
given y

290
00:21:04,290 --> 00:21:05,540
there's you

291
00:21:05,570 --> 00:21:09,290
is the new probability on x

292
00:21:09,300 --> 00:21:11,710
that takes into account what you know about why

293
00:21:13,070 --> 00:21:14,550
so if found back to

294
00:21:14,570 --> 00:21:17,720
two this example here with with

295
00:21:17,750 --> 00:21:20,410
first on on the pathology

296
00:21:20,420 --> 00:21:22,280
then we've seen

297
00:21:26,190 --> 00:21:33,710
that the two variables are definitely not independent and you can

298
00:21:33,760 --> 00:21:37,520
so if you look at the each rule it's different

299
00:21:37,530 --> 00:21:39,590
for of stable

300
00:21:39,670 --> 00:21:41,900
then you may infer that

301
00:21:41,920 --> 00:21:43,490
if you know

302
00:21:43,510 --> 00:21:46,910
exactly that is you know in advance for

303
00:21:46,910 --> 00:21:48,660
festivities positive

304
00:21:48,670 --> 00:21:51,080
and induces new

305
00:21:51,110 --> 00:21:55,290
in new ship of the probability for y

306
00:21:57,670 --> 00:22:02,560
if you know in advance that this is what positive the probability of being sick

307
00:22:02,570 --> 00:22:07,700
it is ninety over one nineteen and it's different from from the total probability of

308
00:22:07,700 --> 00:22:10,070
being sick if you don't know

309
00:22:10,090 --> 00:22:13,680
that the test is positive OK

310
00:22:13,680 --> 00:22:15,920
so you can substitute in

311
00:22:16,600 --> 00:22:22,790
delta gene not minus or t natural on a because those are equal to each

312
00:22:24,100 --> 00:22:26,410
and then you can rewrite

313
00:22:26,420 --> 00:22:27,890
that equation

314
00:22:28,220 --> 00:22:31,650
delta g equals or to natural law

315
00:22:34,060 --> 00:22:35,710
so if you're interested

316
00:22:35,810 --> 00:22:38,880
and this is a very useful equations

317
00:22:38,900 --> 00:22:40,960
think about all right

318
00:22:40,990 --> 00:22:44,560
well concentration of the reactants

319
00:22:44,570 --> 00:22:48,850
how does that compare concentrations at equilibrium

320
00:22:48,870 --> 00:22:51,110
so if you know where you are now

321
00:22:51,120 --> 00:22:52,600
we know q now

322
00:22:52,640 --> 00:22:54,280
know what is

323
00:22:54,310 --> 00:22:58,940
you can think about the direction of the reaction think about delta g negative

324
00:23:00,000 --> 00:23:02,830
going forward direction going first

325
00:23:02,900 --> 00:23:04,720
so this is a very

326
00:23:04,720 --> 00:23:06,810
very useful equation

327
00:23:06,860 --> 00:23:09,560
predict the direction of the reaction

328
00:23:09,570 --> 00:23:14,560
depending on the composition at that moment pairs competition

329
00:23:14,570 --> 00:23:19,800
at equilibrium

330
00:23:22,040 --> 00:23:24,560
less than k

331
00:23:24,580 --> 00:23:27,110
that's going to mean you get negative

332
00:23:27,130 --> 00:23:28,770
delta g

333
00:23:28,780 --> 00:23:32,080
and to be spontaneous in the forward direction

334
00:23:32,130 --> 00:23:33,910
so this equation

335
00:23:33,920 --> 00:23:36,030
if he was greater than k

336
00:23:36,030 --> 00:23:38,540
delta g is going to be

337
00:23:38,590 --> 00:23:40,860
you're going to go in the reverse direction

338
00:23:40,910 --> 00:23:45,520
so again this is very useful think about the relationship of human k a and

339
00:23:45,520 --> 00:23:46,830
how that impacts

340
00:23:46,830 --> 00:23:49,070
delta g

341
00:23:49,120 --> 00:23:52,060
so let's look at an example

342
00:23:54,070 --> 00:23:55,840
the same reaction

343
00:23:55,970 --> 00:23:58,860
our given a value for k

344
00:23:59,170 --> 00:24:01,270
four hundred degrees c

345
00:24:01,300 --> 00:24:02,020
they were given

346
00:24:02,100 --> 00:24:05,320
partial pressures of reactants and products

347
00:24:05,330 --> 00:24:08,540
as are really here not

348
00:24:08,550 --> 00:24:10,660
which direction the reaction

349
00:24:10,680 --> 00:24:12,290
going to get

350
00:24:12,380 --> 00:24:13,650
so let's

351
00:24:13,670 --> 00:24:14,970
figure out what

352
00:24:14,970 --> 00:24:16,070
q is

353
00:24:16,090 --> 00:24:19,240
because we want to know the the relationship between q

354
00:24:20,070 --> 00:24:24,620
and that's going tell us where we are are really equilibrium what direction will the

355
00:24:24,620 --> 00:24:32,650
reaction go

356
00:24:32,660 --> 00:24:33,960
all right

357
00:24:33,960 --> 00:24:36,400
so here

358
00:24:36,430 --> 00:24:44,220
what's going to be on the top of the expression for you

359
00:24:44,230 --> 00:24:47,760
so what what goes on the top products we have

360
00:24:48,810 --> 00:24:50,830
so we have one right here

361
00:24:50,860 --> 00:24:55,020
so we're gonna put our partial pressure

362
00:24:55,050 --> 00:24:56,850
other product

363
00:24:56,910 --> 00:24:57,940
and then we have to

364
00:24:58,080 --> 00:25:00,230
the geometry

365
00:25:00,240 --> 00:25:03,070
which would give us

366
00:25:03,090 --> 00:25:04,650
on the right other

367
00:25:04,660 --> 00:25:06,920
we are reactant

368
00:25:06,930 --> 00:25:09,410
consider the partial pressure

369
00:25:09,460 --> 00:25:11,220
and two

370
00:25:11,270 --> 00:25:14,510
the partial pressure of h two

371
00:25:14,530 --> 00:25:19,670
against the geometry of the reaction

372
00:25:19,680 --> 00:25:21,220
that's an equal

373
00:25:21,220 --> 00:25:24,660
one point one

374
00:25:27,960 --> 00:25:29,070
five point

375
00:25:30,000 --> 00:25:32,180
science two point two

376
00:25:32,210 --> 00:25:35,130
you could

377
00:25:35,150 --> 00:25:38,220
and if you work out there

378
00:25:38,880 --> 00:25:41,190
two point one

379
00:25:41,240 --> 00:25:43,910
times ten to the minus two

380
00:25:43,930 --> 00:25:46,600
so that q

381
00:25:47,860 --> 00:25:49,710
it was listed as

382
00:25:49,780 --> 00:25:51,560
one point nine

383
00:25:51,570 --> 00:25:53,850
it tends to minus four

384
00:25:53,870 --> 00:25:56,000
at the same temperature

385
00:25:56,000 --> 00:25:57,160
so here

386
00:25:58,650 --> 00:25:59,930
is greater

387
00:26:01,890 --> 00:26:12,010
and so what direction will the reaction go out

388
00:26:12,050 --> 00:26:13,060
so it will go

389
00:26:13,070 --> 00:26:14,060
people said

390
00:26:14,060 --> 00:26:19,220
toward toward reactants

391
00:26:19,300 --> 00:26:20,570
world react

392
00:26:20,740 --> 00:26:22,560
or you could say

393
00:26:24,070 --> 00:26:28,360
reverse direction

394
00:26:29,910 --> 00:26:33,110
NH three

395
00:26:33,120 --> 00:26:38,660
well this is

396
00:26:47,530 --> 00:26:49,920
just one point about doing this

397
00:26:49,940 --> 00:26:55,720
i've noticed people continue to horsing around them when i say well what i meant

398
00:26:55,720 --> 00:26:57,020
was right

399
00:26:58,310 --> 00:27:00,820
and since i've done that numerous times

400
00:27:00,850 --> 00:27:02,340
i suggest

401
00:27:02,360 --> 00:27:03,440
you say

402
00:27:03,460 --> 00:27:07,720
four reactors or toward products drawn aero

403
00:27:07,770 --> 00:27:11,570
because usually that you actually write down what

404
00:27:12,820 --> 00:27:17,670
my personal to to stay away from left to right on exams just just in

405
00:27:17,670 --> 00:27:22,240
case from last year project we got it that but i've seen people before for

406
00:27:22,320 --> 00:27:24,290
when knew the answer is just

407
00:27:30,660 --> 00:27:35,680
here we have an example were able to predict what direction reaction go by looking

408
00:27:35,680 --> 00:27:36,610
at you

409
00:27:36,620 --> 00:27:37,660
and k

410
00:27:37,670 --> 00:27:40,620
so i think about what else we can do more

411
00:27:40,630 --> 00:27:41,870
from k

412
00:27:41,880 --> 00:27:47,210
the size of the equilibrium constant portion of that value tells you something about the

413
00:27:48,370 --> 00:27:55,000
so what does hey tell us

414
00:27:55,040 --> 00:27:57,260
what does

415
00:28:03,160 --> 00:28:05,630
is equal to

416
00:28:08,430 --> 00:28:14,170
the reactants

417
00:28:16,300 --> 00:28:21,760
so the size of q where size k a whether it's greater or less than

418
00:28:22,600 --> 00:28:24,840
it's going to tell us about the ratio

419
00:28:24,850 --> 00:28:27,290
all products to reactants

420
00:28:27,290 --> 00:28:29,490
at equilibrium

421
00:28:33,610 --> 00:28:35,760
is large

422
00:28:35,760 --> 00:28:36,940
or we can say

423
00:28:36,960 --> 00:28:38,010
really well

424
00:28:38,020 --> 00:28:40,570
we're talking about the candidates greater

425
00:28:40,590 --> 00:28:42,490
then one

426
00:28:42,530 --> 00:28:49,630
you're going to have more products

427
00:28:49,660 --> 00:28:53,220
reactance at equilibrium or high products

428
00:28:53,250 --> 00:28:57,190
the products are going to be greater is the big number it's going to mean

429
00:28:57,190 --> 00:28:59,690
that there are more products and reactants

430
00:28:59,720 --> 00:29:01,010
at equilibrium

431
00:29:01,010 --> 00:29:03,180
then the probability

432
00:29:03,200 --> 00:29:04,490
that the dwarf

433
00:29:05,470 --> 00:29:10,390
belong that the belongs to a OK the beam on the valuable corresponding to the

434
00:29:10,390 --> 00:29:13,990
publication is simply the integral

435
00:29:14,430 --> 00:29:16,300
of of the

436
00:29:16,310 --> 00:29:20,820
the self is our you have a dual b is united by the total area

437
00:29:20,820 --> 00:29:25,430
of squared OK where x and y are the counties in calling corresponding to the

438
00:29:25,430 --> 00:29:26,620
location of the ball

439
00:29:26,630 --> 00:29:31,520
so that's really the most basic thing you obviously you the fact that you the

440
00:29:31,570 --> 00:29:34,460
assumption by mowing for uniform

441
00:29:34,490 --> 00:29:35,750
yes and no

442
00:29:35,760 --> 00:29:40,160
this you don't want to compute these guys exactly OK

443
00:29:40,180 --> 00:29:45,220
because a for example has very very complex shape complex shape is not as simple

444
00:29:45,240 --> 00:29:48,130
so-called then basically

445
00:29:48,140 --> 00:29:54,710
what you're proposing going to discuss the simple numerical methods so as to approximate it

446
00:29:54,710 --> 00:29:57,450
numerically this interval so

447
00:29:57,460 --> 00:29:59,360
the way simple

448
00:29:59,370 --> 00:30:03,460
so assume that europe's and search

449
00:30:03,470 --> 00:30:08,700
what independent drops of rain each of them being distributed uniformly on the square

450
00:30:08,700 --> 00:30:14,710
on the basically by d i essentially the random location of block i OK so

451
00:30:14,710 --> 00:30:17,500
i assume you all to compute

452
00:30:17,550 --> 00:30:21,810
there basis so this is basically what you so this is basically

453
00:30:21,820 --> 00:30:26,320
the initial square you have you want them to see at the top you itself

454
00:30:26,320 --> 00:30:30,710
can be learned of then each of them is uniformly distributed according to on the

455
00:30:30,710 --> 00:30:32,440
u on the unit square

456
00:30:32,470 --> 00:30:38,560
on basically you are interested in computing the our of the so-called where what could

457
00:30:38,560 --> 00:30:43,210
you do with a very simple when the simple thing to point is basically forward

458
00:30:43,210 --> 00:30:44,500
want to belong to the number

459
00:30:44,930 --> 00:30:47,960
two to belong to the so-called that basically

460
00:30:47,990 --> 00:30:53,520
in the uniformly distributed where you don't need to have done any stats to know

461
00:30:53,520 --> 00:30:59,320
that basically good estimated that could be simply the number dropped accept that fell into

462
00:30:59,390 --> 00:31:04,830
the so-called divided by the total number of blocks so that's do is said to

463
00:31:04,830 --> 00:31:09,660
compute the point of view belonging to the so-called just guy come and go for

464
00:31:09,820 --> 00:31:14,760
fallen into this article you about the total number of drops that these k called

465
00:31:14,880 --> 00:31:20,650
capital so let's have a little bit of statistical justification for it really the basic

466
00:31:20,650 --> 00:31:25,470
logic element well to do that we try to formalize a little bit what we've

467
00:31:25,470 --> 00:31:30,430
been doing so introducing basically an indicator function for the set k which is called

468
00:31:30,430 --> 00:31:35,530
to essentially one the the point of calling x y belongs to a and zero

469
00:31:37,520 --> 00:31:43,410
on simply one and we're doing doing simple modification i realized the point it was

470
00:31:43,410 --> 00:31:47,840
interested in but point that to draw belong basically

471
00:31:47,870 --> 00:31:51,200
to this set a scene pretty

472
00:31:51,220 --> 00:31:53,260
the expectation

473
00:31:55,610 --> 00:31:57,610
indicator function

474
00:31:57,630 --> 00:32:04,260
and these guys what these guys simply the uniform distribution over the square

475
00:32:04,270 --> 00:32:06,370
so it is the fact

476
00:32:06,460 --> 00:32:12,920
one four here because remember my my square rules for minus one to one

477
00:32:12,930 --> 00:32:15,270
yes it is it found is that simple

478
00:32:15,290 --> 00:32:17,270
so now basically

479
00:32:17,280 --> 00:32:19,970
what we've been doing essentially

480
00:32:19,980 --> 00:32:23,980
is that the through your introduce new on the valuable

481
00:32:24,000 --> 00:32:25,880
OK which is simply

482
00:32:25,890 --> 00:32:27,440
define as the

483
00:32:27,480 --> 00:32:30,000
indicator function

484
00:32:30,730 --> 00:32:32,340
applied to the former

485
00:32:32,350 --> 00:32:33,690
valuable d

486
00:32:33,710 --> 00:32:36,640
then you have be the which is essentially

487
00:32:36,640 --> 00:32:42,490
one of the more restrictive value zero or one these within a new music video

488
00:32:42,690 --> 00:32:47,160
equal to one basically if these are outside and in view of these equal to

489
00:32:47,970 --> 00:32:54,810
on essentially with ministry right essentially the point distribution of interest as the expectation of

490
00:32:54,810 --> 00:32:59,550
such woman volleyball and the uniform distribution

491
00:32:59,560 --> 00:33:03,310
on the square of interest initial square s

492
00:33:03,330 --> 00:33:04,980
so that's it

493
00:33:04,990 --> 00:33:08,270
so essentially you think of it as an art

494
00:33:08,290 --> 00:33:10,760
what we've been doing lately

495
00:33:10,760 --> 00:33:16,560
the the initial kind of introduced me to the point that it was proposing was

496
00:33:17,890 --> 00:33:23,340
basically counting the number of that fell into a divided by the total number of

497
00:33:23,340 --> 00:33:26,560
draw you can write it simply as the so

498
00:33:26,580 --> 00:33:29,370
of those one the rival

499
00:33:29,380 --> 00:33:34,620
divided by n is just writing essentially of what i've been doing before

500
00:33:34,640 --> 00:33:41,020
this is this really like a simple thing we formalising basically into them properly into

501
00:33:41,020 --> 00:33:44,720
more on the viable what i've just been doing intuitively

502
00:33:44,770 --> 00:33:46,660
again no

503
00:33:46,670 --> 00:33:48,890
basically what do we know

504
00:33:48,900 --> 00:33:50,380
when we know

505
00:33:50,430 --> 00:33:52,630
that we have here is essentially

506
00:33:52,640 --> 00:33:58,480
one of the the and some from i want to end of independent random volleyball

507
00:33:59,940 --> 00:34:05,310
so basically if you take the limit as n goes to plus infinity

508
00:34:05,360 --> 00:34:09,300
you have the strong law of large numbers that tells you that essentially

509
00:34:09,330 --> 00:34:14,670
and so then i estimate come and more surely two on the expectation of the

510
00:34:16,050 --> 00:34:22,230
basically the uniform distribution on the square as which is exactly what i was interested

511
00:34:22,260 --> 00:34:25,930
the a century what we've been doing with what we have been using when we

512
00:34:25,930 --> 00:34:32,650
are using this estimate is implicitly we're using the rule of numbers of that sort

513
00:34:32,880 --> 00:34:37,260
so essentially when n is large enough this kind of justify the use of the

514
00:34:37,280 --> 00:34:42,650
system OK so that's good that's good no one about basically

515
00:34:42,660 --> 00:34:47,640
the properties of this estimate was what we know is quite trivial to show that

516
00:34:48,640 --> 00:34:53,440
sn n is an unbiased estimate of the quantities of interest which in the case

517
00:34:53,440 --> 00:34:57,980
of life particular points belonging to self code is equal to pi of form

518
00:35:00,750 --> 00:35:03,630
my estimate is and i as was basically

519
00:35:03,640 --> 00:35:07,710
the all to characterize the properties of the quality of a way to believe in

520
00:35:07,710 --> 00:35:12,760
the use of violence so i'm going to buy and sell us which is independent

521
00:35:12,760 --> 00:35:13,990
woman volleyball

522
00:35:14,000 --> 00:35:20,760
so obviously essentially it's equal to essentially buy and one from the bible they're all

523
00:35:20,760 --> 00:35:24,660
the same so i can put an index divided by one of the and the

524
00:35:24,660 --> 00:35:26,340
number of samples

525
00:35:26,340 --> 00:35:27,640
positive definite

526
00:35:27,650 --> 00:35:33,640
so this matrix of all similarities between ten and training points

527
00:35:33,650 --> 00:35:36,610
if this matrix is positive definite then

528
00:35:36,660 --> 00:35:40,140
we are in the situation where we can construct features

529
00:35:40,150 --> 00:35:44,990
and i will show you how to construct peterman

530
00:35:45,010 --> 00:35:47,350
so before i can do that i have two

531
00:35:47,370 --> 00:35:52,000
show you a few elementary properties maybe i'll let you

532
00:35:52,010 --> 00:35:56,770
show these properties are trying to model of positive definite kernels which we are going

533
00:35:56,770 --> 00:36:00,710
to use in the proof or in the construction of the feature space

534
00:36:04,450 --> 00:36:09,070
maybe if you want we will take five minutes where you can try things out

535
00:36:09,070 --> 00:36:12,500
and afterwards also the solution on the whiteboard

536
00:36:12,520 --> 00:36:15,130
so what you need is you need to

537
00:36:15,140 --> 00:36:17,730
i memorized this definition or write it down

538
00:36:17,780 --> 00:36:22,310
because then i will move to the next slide where you

539
00:36:22,370 --> 00:36:24,880
i have things that you can try to prove so

540
00:36:24,900 --> 00:36:27,660
OK i'll i'll give you a minute to copy this if you are you have

541
00:36:27,850 --> 00:36:28,840
slides right

542
00:36:28,850 --> 00:36:34,100
OK so how many slides i'm missing actually because i wanted lies something sometime

543
00:36:34,210 --> 00:36:38,510
they complete

544
00:36:38,520 --> 00:36:40,620
complete located

545
00:36:45,280 --> 00:36:46,220
this one

546
00:36:49,670 --> 00:36:56,000
c c three to five these results

547
00:36:56,110 --> 00:36:58,840
if you can give you some hints

548
00:36:58,860 --> 00:36:59,740
well actually

549
00:37:03,670 --> 00:37:08,030
the information was

550
00:37:08,040 --> 00:37:09,930
you can

551
00:37:58,920 --> 00:38:29,840
discovery of the same one as usual for all us

552
00:38:29,890 --> 00:38:31,730
so it's

553
00:39:00,920 --> 00:39:05,090
so i think some of you are really finished

554
00:39:05,190 --> 00:39:09,390
first of of all

555
00:39:14,330 --> 00:39:15,560
i would like to

556
00:39:15,640 --> 00:39:20,280
what about all the way

557
00:39:23,770 --> 00:39:29,080
this the first one

558
00:39:31,300 --> 00:39:36,900
well one of the towns i exactly the class of compounds that correspond to dot

559
00:39:36,900 --> 00:39:42,100
product in the space we have proven that yet but this first

560
00:39:42,110 --> 00:39:48,290
the result of there is one direction of proof right given product in some space

561
00:39:48,330 --> 00:39:51,460
this is actually positive definite kernel and

562
00:39:51,470 --> 00:39:56,170
in the next fifteen minutes i'll show you given a positive definite kernel it corresponds

563
00:39:56,170 --> 00:39:59,670
to a dot product in other space then we have both directions but this is

564
00:39:59,670 --> 00:40:00,830
the one direction

565
00:40:00,890 --> 00:40:05,770
and i want to prove this OK you have to substitute this into the into

566
00:40:05,770 --> 00:40:12,980
this equation that we have to cheque for positive definiteness so

567
00:40:13,000 --> 00:40:15,720
and we need to show that

568
00:40:15,880 --> 00:40:23,160
no matter what the AIA AI and exi i are this quantity is non negative

569
00:40:25,150 --> 00:40:28,930
now we can by assumption

570
00:40:28,950 --> 00:40:30,550
this thing is the

571
00:40:30,560 --> 00:40:34,500
OK i didn't say that but i think it was sort of here this angular

572
00:40:34,500 --> 00:40:38,040
brackets thing on the right that the dot product in that space h

573
00:40:38,090 --> 00:40:39,830
but products are

574
00:40:39,850 --> 00:40:41,050
by linear

575
00:40:41,060 --> 00:40:45,780
so you can take these coefficients in the endosomes inside the dot product

576
00:40:45,790 --> 00:40:47,820
what i will do is i will

577
00:40:47,840 --> 00:40:50,010
take the sum over i into this

578
00:40:50,170 --> 00:40:55,160
the argument of the dot product is the sum of the into to this argument

579
00:40:55,320 --> 00:41:09,680
to get this thing here and i feel again that this is actually both the

580
00:41:09,680 --> 00:41:15,310
same so i cant i can rewrite this

581
00:41:15,490 --> 00:41:24,920
like that and that's the norm of some vector

582
00:41:24,980 --> 00:41:28,100
and this is therefore nonnegative

583
00:41:28,310 --> 00:41:31,910
so we know that this is no matter what the axis in the eighties on

584
00:41:31,910 --> 00:41:38,130
this is nonnegative therefore this thing here is a positive definite kernel

585
00:41:38,180 --> 00:41:44,680
OK so now let's look at the second one

586
00:41:44,700 --> 00:41:48,010
and what would like to the second one

587
00:41:48,030 --> 00:41:51,520
you'll still be chinese beginning of the summer school OK

588
00:41:56,470 --> 00:42:01,720
actually i might buy it just

589
00:42:01,730 --> 00:42:03,450
as well

590
00:42:03,450 --> 00:42:07,080
on a on an m dimensional manifold

591
00:42:07,110 --> 00:42:08,510
and you in order to

592
00:42:08,540 --> 00:42:11,790
to get a bayes rule anything close to bayes have to somehow be in the

593
00:42:11,790 --> 00:42:15,460
business implicitly or explicitly estimating

594
00:42:15,530 --> 00:42:17,550
the conditional expectation

595
00:42:17,560 --> 00:42:22,130
right for the square loss in general of estimating the conditional distribution

596
00:42:22,140 --> 00:42:25,100
of y given x

597
00:42:26,700 --> 00:42:30,530
it's quite easy to see that whatever you know if you look at densities these

598
00:42:31,000 --> 00:42:32,350
which are

599
00:42:32,390 --> 00:42:35,250
i mean of course you make cooperate with respect to the big measure you immediately

600
00:42:35,250 --> 00:42:36,880
see the true density

601
00:42:37,610 --> 00:42:41,930
he knew it in the population that would be bad because this would not be

602
00:42:41,930 --> 00:42:44,810
happy as we continue to speculate

603
00:42:46,250 --> 00:42:49,680
they get at least some measure you have you have you have you have the

604
00:42:49,680 --> 00:42:51,850
conditional density

605
00:42:51,890 --> 00:42:53,360
they have

606
00:42:53,370 --> 00:42:55,660
the conditional density of

607
00:42:57,310 --> 00:42:58,940
what you

608
00:42:59,700 --> 00:43:01,600
you this this thing of which

609
00:43:01,600 --> 00:43:05,340
the x that you do see is the image

610
00:43:05,390 --> 00:43:09,270
and it intuitively clear i think that these two quantities of the same because of

611
00:43:10,100 --> 00:43:14,080
it's easy to verify the information is the same

612
00:43:14,120 --> 00:43:15,460
right to know

613
00:43:15,480 --> 00:43:17,840
two notable exception w

614
00:43:17,890 --> 00:43:20,760
is the same

615
00:43:21,590 --> 00:43:24,530
probability density doesn't know about the fact that you don't know t

616
00:43:24,580 --> 00:43:25,470
doesn't doesn't

617
00:43:25,600 --> 00:43:28,460
it doesn't care all about

618
00:43:30,480 --> 00:43:33,920
for her role

619
00:43:34,640 --> 00:43:40,240
although we're doing pinhead of y given x

620
00:43:40,250 --> 00:43:41,750
we're actually doing you

621
00:43:41,760 --> 00:43:45,770
you had y giving you

622
00:43:46,950 --> 00:43:50,500
in other words instead of doing estimation of functions on

623
00:43:50,590 --> 00:43:55,220
rd plus one you're doing estimation functions on rn plus one

624
00:43:55,230 --> 00:43:58,140
few variables for example were

625
00:43:58,140 --> 00:44:00,940
whatever dimensional space with line on the circle well

626
00:44:03,080 --> 00:44:04,290
in one dimension should go

627
00:44:06,480 --> 00:44:09,490
i actually do not believe that that's

628
00:44:09,930 --> 00:44:14,540
that's true for all methods of estimation but

629
00:44:14,590 --> 00:44:17,920
here is an example which suggests that

630
00:44:17,940 --> 00:44:20,690
if you if you estimation

631
00:44:20,740 --> 00:44:21,930
method is

632
00:44:24,030 --> 00:44:26,350
in a suitable sense then

633
00:44:26,350 --> 00:44:29,000
you should be that should be happening to even though you don't know what the

634
00:44:29,000 --> 00:44:31,430
manifold is

635
00:44:33,400 --> 00:44:35,930
in statistics you know very commonly one things of

636
00:44:35,940 --> 00:44:37,000
of kernel

637
00:44:37,050 --> 00:44:39,580
kernel density estimates so you have two classes

638
00:44:39,620 --> 00:44:44,410
p one p not and q one and q not of the corresponding densities of

639
00:44:44,460 --> 00:44:47,010
the underlying variable u

640
00:44:47,030 --> 00:44:48,000
and of course

641
00:44:48,010 --> 00:44:53,700
again this phenomenon is of course the like iterations of the same

642
00:44:55,560 --> 00:44:57,440
basically i mean in way

643
00:44:57,450 --> 00:44:59,210
the phenomenon is really

644
00:44:59,220 --> 00:45:05,140
jacobians council when you're doing prediction

645
00:45:05,650 --> 00:45:09,800
if everything is on the same value in both cases

646
00:45:09,860 --> 00:45:13,890
so suppose we have a kernel density estimate of p one p northern not kernels

647
00:45:13,890 --> 00:45:15,500
in computer science and

648
00:45:15,900 --> 00:45:17,980
which you've heard of this morning

649
00:45:18,690 --> 00:45:22,200
rkhs and these are just kernels in the statistical sense

650
00:45:22,260 --> 00:45:26,140
which is you basically take your density convoluted

651
00:45:26,180 --> 00:45:27,780
with something

652
00:45:28,900 --> 00:45:30,900
and then you estimate

653
00:45:31,050 --> 00:45:34,540
the density of the convolution which can actually do just from the data itself

654
00:45:35,410 --> 00:45:38,700
there's been fancy really let me go on to the next

655
00:45:38,790 --> 00:45:43,200
transparency all you do is you estimate the ratio while by what

656
00:45:43,250 --> 00:45:46,050
you simply count the number of points which are the age of

657
00:45:46,100 --> 00:45:48,640
from one population

658
00:45:48,640 --> 00:45:52,500
and you take the ratio that to the number of points within h x

659
00:45:52,520 --> 00:45:53,760
the population

660
00:45:55,880 --> 00:45:57,560
well if the manifold is

661
00:45:57,590 --> 00:46:01,420
there's more to right not just flat need some some sort of smoothness and so

662
00:46:01,420 --> 00:46:04,530
on but it's intuitively sort of clear

663
00:46:05,380 --> 00:46:07,190
since the metrics

664
00:46:09,910 --> 00:46:11,730
are the same

665
00:46:11,760 --> 00:46:15,700
it is the distortion cancels out of the box

666
00:46:15,740 --> 00:46:20,450
when you're counting the number of observations which are within h acts

667
00:46:20,460 --> 00:46:23,700
you are more or less just counting the number of observations which which are with

668
00:46:23,700 --> 00:46:27,040
an interview

669
00:46:27,050 --> 00:46:29,250
and therefore this ratio

670
00:46:29,260 --> 00:46:32,040
which is the uniform kernel density estimate

671
00:46:32,060 --> 00:46:33,980
you think in

672
00:46:33,990 --> 00:46:36,770
the plus one dimensions

673
00:46:36,810 --> 00:46:39,180
is actually an estimate in

674
00:46:39,180 --> 00:46:41,590
and plus one dimension levels of

675
00:46:41,670 --> 00:46:46,220
even though don't know what the manifold

676
00:46:46,290 --> 00:46:50,290
this again resulted have been obtained by my billion on this

677
00:46:50,340 --> 00:46:56,350
one question which is i think probably not that difficult but is actually quite important

678
00:46:57,170 --> 00:46:59,310
what happens

679
00:46:59,330 --> 00:47:04,230
if you use a fancier methods like things based on wavelet

680
00:47:04,290 --> 00:47:08,110
four fourier series or things like that

681
00:47:09,170 --> 00:47:13,260
i actually believe that in that case

682
00:47:13,310 --> 00:47:14,720
you're in trouble

683
00:47:14,810 --> 00:47:17,030
that is if you don't know what the dimension is

684
00:47:17,190 --> 00:47:21,440
you use the wavelet so the wrong dimension

685
00:47:21,490 --> 00:47:22,700
i think

686
00:47:22,700 --> 00:47:25,740
i think you become west local methods

687
00:47:25,740 --> 00:47:29,490
handing it out here can start right away

688
00:47:29,580 --> 00:47:30,950
and out here

689
00:47:30,970 --> 00:47:34,350
those of you have no seats come forward to get some seats

690
00:47:34,410 --> 00:47:38,410
the call was still friends right away

691
00:47:38,470 --> 00:47:41,260
and why don't you handed down here

692
00:47:41,300 --> 00:47:43,370
you can also get people here

693
00:47:43,390 --> 00:47:49,930
you can start right away

694
00:47:49,950 --> 00:47:51,240
i'm not going to

695
00:47:54,600 --> 00:47:59,680
do something

696
00:47:59,700 --> 00:48:02,080
perhaps even more ambitious

697
00:48:02,100 --> 00:48:06,390
and i'm going to now couple three oscillators not pendulum

698
00:48:07,240 --> 00:48:08,510
but i'm to all

699
00:48:09,620 --> 00:48:13,350
oscillators which are connected with force right

700
00:48:13,390 --> 00:48:15,950
i'm going to work on this

701
00:48:16,680 --> 00:48:19,430
mass is equal masses for strings

702
00:48:19,450 --> 00:48:23,200
spring constant k and the spring constant the same

703
00:48:23,220 --> 00:48:26,160
and i'm going to drive that's it

704
00:48:33,510 --> 00:48:36,660
this is the end

705
00:48:36,740 --> 00:48:40,410
in other words i have he was springs

706
00:48:40,450 --> 00:48:42,740
here's the first class

707
00:48:42,850 --> 00:48:45,200
second class

708
00:48:46,810 --> 00:48:48,080
and here

709
00:48:48,080 --> 00:48:53,680
is fixed and i'm going to try here

710
00:48:53,680 --> 00:48:56,410
with the displacement at

711
00:48:56,530 --> 00:48:58,720
is at the zero

712
00:48:58,870 --> 00:49:02,200
because of course i only get

713
00:49:03,330 --> 00:49:05,640
around the moment in time

714
00:49:05,720 --> 00:49:08,280
this is where my hand will be

715
00:49:08,330 --> 00:49:10,470
so this is at

716
00:49:10,490 --> 00:49:12,970
this is where the first mass will be

717
00:49:12,970 --> 00:49:19,950
remember always called displacement x y from its equilibrium that is it's the line

718
00:49:20,010 --> 00:49:22,350
here is the spring

719
00:49:22,410 --> 00:49:24,510
this one is here

720
00:49:24,550 --> 00:49:26,200
so i all this

721
00:49:26,240 --> 00:49:27,950
x two

722
00:49:27,990 --> 00:49:29,490
the spring

723
00:49:29,510 --> 00:49:32,370
and this one here

724
00:49:32,490 --> 00:49:35,430
this is x three

725
00:49:35,550 --> 00:49:37,620
here is the spring

726
00:49:37,720 --> 00:49:39,580
here is spring

727
00:49:39,600 --> 00:49:42,350
you may have noticed more than once now

728
00:49:42,390 --> 00:49:44,100
i have

729
00:49:44,160 --> 00:49:46,280
so this

730
00:49:46,330 --> 00:49:47,950
and i always

731
00:49:47,990 --> 00:49:51,670
offset them in the same direction do you have to do that you know

732
00:49:51,740 --> 00:49:53,410
if you don't do it

733
00:49:53,510 --> 00:49:57,930
chance of a mistake on the sign is much larger than if you always set

734
00:49:57,930 --> 00:50:00,780
them off in the same using shortly one

735
00:50:00,780 --> 00:50:03,350
but it's certainly something anonymous

736
00:50:03,370 --> 00:50:06,260
but it is more

737
00:50:06,260 --> 00:50:09,390
i find it as my positive direction that causes

738
00:50:09,520 --> 00:50:11,910
three choices

739
00:50:15,080 --> 00:50:18,280
this situation at this moment in time

740
00:50:19,720 --> 00:50:20,720
the larger

741
00:50:22,330 --> 00:50:24,180
that x two

742
00:50:24,240 --> 00:50:25,410
the large

743
00:50:25,550 --> 00:50:26,970
x one

744
00:50:26,990 --> 00:50:28,200
the x three

745
00:50:28,220 --> 00:50:29,160
the larger

746
00:50:29,180 --> 00:50:31,030
the next

747
00:50:31,080 --> 00:50:32,390
this assumption

748
00:50:32,410 --> 00:50:34,280
have no consequences

749
00:50:34,280 --> 00:50:36,300
for what follows

750
00:50:36,410 --> 00:50:41,300
at least not for the differential equation

751
00:50:41,350 --> 00:50:44,740
if x one is larger than ever

752
00:50:44,740 --> 00:50:45,800
that first

753
00:50:45,830 --> 00:50:47,200
the brain

754
00:50:47,260 --> 00:50:49,760
is longer than it wants to be

755
00:50:49,780 --> 00:50:51,570
because i've assumed that x one

756
00:50:52,700 --> 00:50:53,970
and so that means

757
00:50:53,990 --> 00:50:57,190
there will be a force in this election because this thing is longer than one

758
00:50:59,910 --> 00:51:03,510
if x two is larger than x one spring is also lower than the ones

759
00:51:03,510 --> 00:51:04,180
to be

760
00:51:04,200 --> 00:51:05,830
so if want to contract

761
00:51:05,890 --> 00:51:07,280
so force

762
00:51:07,330 --> 00:51:10,070
in this direction

763
00:51:10,140 --> 00:51:12,390
so i can write down a

764
00:51:12,490 --> 00:51:16,330
differential equation for my first of

765
00:51:16,410 --> 00:51:18,850
that's going to be and

766
00:51:18,910 --> 00:51:23,950
x one double dot

767
00:51:23,970 --> 00:51:26,080
that equals

768
00:51:26,080 --> 00:51:29,050
my netscape

769
00:51:29,100 --> 00:51:33,390
time x one minus and because that's the amount by which is is

770
00:51:33,410 --> 00:51:35,200
longer than it wants to be

771
00:51:35,220 --> 00:51:37,580
so times

772
00:51:37,620 --> 00:51:40,220
x one minus at

773
00:51:40,300 --> 00:51:42,180
that is this force

774
00:51:42,410 --> 00:51:43,800
this force

775
00:51:43,850 --> 00:51:46,050
it is now in the past direction

776
00:51:46,100 --> 00:51:48,550
the first k

777
00:51:51,300 --> 00:51:54,680
brain here is longer than the ones to be by an amount x two minus

778
00:51:54,680 --> 00:51:58,990
x one

779
00:51:59,120 --> 00:52:00,580
not only got one

780
00:52:00,580 --> 00:52:05,350
the next one

781
00:52:05,370 --> 00:52:07,430
that's my differential equation

782
00:52:09,030 --> 00:52:10,990
the first of

783
00:52:11,030 --> 00:52:14,550
and this one is always correct even if x one

784
00:52:14,640 --> 00:52:16,220
is not larger than

785
00:52:16,240 --> 00:52:17,620
because if x one is

786
00:52:17,640 --> 00:52:19,930
much larger than than this

787
00:52:19,970 --> 00:52:22,080
force flips over well

788
00:52:22,100 --> 00:52:23,620
this also

789
00:52:23,640 --> 00:52:26,760
that's why it's always culture and advisable

790
00:52:26,760 --> 00:52:31,790
to make that assumption to start with because again it reduces the probability of making

791
00:52:31,790 --> 00:52:33,050
a mistake

792
00:52:34,200 --> 00:52:38,600
nothing else to it just reduce the chance of slipping

793
00:52:38,660 --> 00:52:41,220
but let's not go through this object

794
00:52:41,310 --> 00:52:44,530
if this spring is larger one of them wants to be

795
00:52:44,550 --> 00:52:45,930
want contract

796
00:52:45,950 --> 00:52:49,350
so this object will forced to

797
00:52:49,470 --> 00:52:52,780
but if this spring is longer than it wants to be because x three is

798
00:52:52,780 --> 00:52:54,070
large x two

799
00:52:54,120 --> 00:52:56,180
but experience force

800
00:52:58,100 --> 00:52:59,850
so i can write down now

801
00:52:59,850 --> 00:53:02,890
differential equation object number two

802
00:53:03,830 --> 00:53:04,830
x two

803
00:53:04,850 --> 00:53:09,310
double up

804
00:53:09,370 --> 00:53:12,420
notice that the one that is here to the left is the same one that

805
00:53:12,420 --> 00:53:14,740
is you right

806
00:53:14,760 --> 00:53:18,930
right actually minors reactions this ball is the same as this

807
00:53:18,990 --> 00:53:24,430
so it is going to be that scrutinize minus sign always coupled oscillators

808
00:53:24,450 --> 00:53:26,160
it was as the place here

809
00:53:26,160 --> 00:53:29,640
going to come out he using sign

810
00:53:29,700 --> 00:53:33,180
see that comes out nicely

811
00:53:34,300 --> 00:53:38,220
the brain is long that it wants to be by maximizing

812
00:53:38,220 --> 00:53:40,120
and the forces in the minors direction

813
00:53:40,240 --> 00:53:41,370
and this one

814
00:53:41,390 --> 00:53:42,910
it's not going to be a plus

815
00:53:44,510 --> 00:53:45,990
x three

816
00:53:46,050 --> 00:53:49,680
mines x two

817
00:53:49,720 --> 00:53:51,970
now i go

818
00:53:51,970 --> 00:53:53,680
the next spring

819
00:53:53,800 --> 00:53:55,660
next object

820
00:53:55,680 --> 00:53:57,600
so this object

821
00:53:57,640 --> 00:54:00,530
the experience of force and to the left

822
00:54:00,720 --> 00:54:03,140
this spring is longer than wants to be

823
00:54:03,200 --> 00:54:05,220
once the contract

824
00:54:05,220 --> 00:54:06,890
but this one

825
00:54:08,370 --> 00:54:13,010
therefore the force two to display now also in this

826
00:54:13,050 --> 00:54:15,950
because the end is fixed

827
00:54:15,990 --> 00:54:18,070
so we get for the third object

828
00:54:19,260 --> 00:54:22,700
act three double not

829
00:54:22,720 --> 00:54:24,950
one minus k

830
00:54:24,990 --> 00:54:27,030
five x three

831
00:54:27,070 --> 00:54:30,700
my next which is this term which assigns

832
00:54:30,700 --> 00:54:33,120
and then in addition i get minus

833
00:54:37,800 --> 00:54:41,260
when you reach this point all an example

834
00:54:41,350 --> 00:54:42,850
new pass

835
00:54:42,930 --> 00:54:44,580
you take a deep breath

836
00:54:44,600 --> 00:54:46,180
you go over every

837
00:54:46,200 --> 00:54:48,390
term and every sign

838
00:54:48,390 --> 00:54:50,490
if you put up on one side

839
00:54:50,550 --> 00:54:53,600
o on casual mistake that you

840
00:54:53,600 --> 00:54:58,160
even though you know it you can actually write u for instance of one free

841
00:54:58,180 --> 00:54:59,990
it's all over

842
00:55:00,010 --> 00:55:01,410
then in the waters

843
00:55:01,430 --> 00:55:06,600
the problem will fall apart and may not even oscillate in simple harmonic right

844
00:55:06,640 --> 00:55:08,510
so therefore

845
00:55:08,550 --> 00:55:09,760
let's look at it

846
00:55:09,780 --> 00:55:11,890
and that's one of the

847
00:55:11,890 --> 00:55:14,080
one is larger than n

848
00:55:14,080 --> 00:55:16,990
therefore forces in this election

849
00:55:17,100 --> 00:55:18,950
along this direction

850
00:55:19,330 --> 00:55:21,160
x two minus six

851
00:55:21,220 --> 00:55:22,660
that same force here

852
00:55:22,720 --> 00:55:26,070
it is going to perform the second one so that this is correct this is

853
00:55:27,330 --> 00:55:29,010
this one is driving it

854
00:55:29,010 --> 00:55:32,910
way from equilibrium x reminds x two got to be right

855
00:55:32,970 --> 00:55:35,450
this term shows up here was a minus sign

856
00:55:35,450 --> 00:55:36,640
i can go on there

857
00:55:36,640 --> 00:55:39,160
and since this spring is always shorter here

858
00:55:39,930 --> 00:55:41,370
both the right

859
00:55:41,370 --> 00:55:44,930
i'm happy with my differential equation

860
00:55:44,930 --> 00:55:47,070
so now

861
00:55:47,080 --> 00:55:49,800
going substitute here

862
00:55:49,800 --> 00:55:51,850
i don't need to compute it

863
00:55:51,970 --> 00:55:55,850
you may want to compute even though you know it's one that i was

864
00:55:57,760 --> 00:56:00,410
so what what is left

865
00:56:00,450 --> 00:56:01,140
i mean

866
00:56:01,160 --> 00:56:05,240
basically a quadratic operation because it's linear on next three but you need to compute

867
00:56:05,240 --> 00:56:07,060
for every x

868
00:56:08,010 --> 00:56:13,470
so at the end of the day you have an algorithm which has quadratic complexity

869
00:56:13,490 --> 00:56:15,680
instead of could be compared

870
00:56:17,030 --> 00:56:18,030
and of course

871
00:56:18,030 --> 00:56:22,450
in terms of memory you are better off because here you have to start

872
00:56:22,560 --> 00:56:24,050
or the cube

873
00:56:25,760 --> 00:56:28,760
you have to support triples

874
00:56:28,760 --> 00:56:32,930
here we have to start only

875
00:56:35,080 --> 00:56:36,680
all possible

876
00:56:37,740 --> 00:56:39,200
processing and

877
00:56:40,410 --> 00:56:44,140
the requirements they they have improved

878
00:56:45,780 --> 00:56:47,120
they have improved

879
00:56:47,120 --> 00:56:48,970
again remember

880
00:56:48,970 --> 00:56:53,660
as the result of what is the result of an assumption as the result that

881
00:56:54,700 --> 00:56:55,990
and also

882
00:56:55,990 --> 00:56:59,200
a given conditional independence

883
00:57:03,200 --> 00:57:07,510
so this is just a simple example of how

884
00:57:07,560 --> 00:57:11,490
conditional independence in an extremely simple model

885
00:57:12,450 --> 00:57:13,700
the result

886
00:57:13,740 --> 00:57:15,550
in the efficiency

887
00:57:15,560 --> 00:57:17,050
in terms of

888
00:57:23,240 --> 00:57:25,410
the question here is

889
00:57:25,410 --> 00:57:26,120
i mean

890
00:57:26,140 --> 00:57:28,120
how can we

891
00:57:28,160 --> 00:57:30,970
we size in

892
00:57:30,990 --> 00:57:34,180
in an accurate way the mathematical

893
00:57:37,330 --> 00:57:42,740
what these examples that you just run to the general case the general case where

894
00:57:42,800 --> 00:57:45,910
you have an arbitrary number of virus

895
00:57:47,390 --> 00:57:52,080
if an arbitrary probability distribution

896
00:57:52,180 --> 00:57:53,720
we saw the

897
00:57:53,800 --> 00:57:55,580
the conditional independence

898
00:57:56,700 --> 00:57:58,890
and p of facts

899
00:57:58,930 --> 00:58:03,550
i structure that allows us to exploit the distributive law

900
00:58:03,600 --> 00:58:05,720
to make things more efficient

901
00:58:05,740 --> 00:58:07,890
the basic concept here is that

902
00:58:07,910 --> 00:58:13,010
the structure that is created in the probability space

903
00:58:13,030 --> 00:58:16,620
as a result of the conditional independencies

904
00:58:16,680 --> 00:58:19,870
is such that can be

905
00:58:19,890 --> 00:58:22,490
exploited by this

906
00:58:22,530 --> 00:58:25,370
in order to make computations more fish

907
00:58:31,450 --> 00:58:33,100
the question is

908
00:58:33,140 --> 00:58:36,280
what about the general case

909
00:58:37,160 --> 00:58:40,100
how these things translate

910
00:58:40,140 --> 00:58:46,720
in particular what's the form that the joint probability distribution will take in general

911
00:58:46,850 --> 00:58:49,890
given the set of conditional independence statements

912
00:58:49,890 --> 00:58:51,280
well we saw

913
00:58:51,280 --> 00:58:54,510
no that particular case we have three viable the given

914
00:58:54,530 --> 00:58:56,550
conditional independence day

915
00:58:56,600 --> 00:59:00,970
but have a simple factorizations over subsets of those one

916
00:59:01,830 --> 00:59:05,910
i was going to happen in general case what the general rule

917
00:59:05,910 --> 00:59:10,080
of which that particular example is just an instance of

918
00:59:10,140 --> 00:59:12,220
right that's the general

919
00:59:12,330 --> 00:59:17,970
i mean can use to exploit the distributive law

920
00:59:17,990 --> 00:59:20,350
in the general case

921
00:59:20,350 --> 00:59:21,910
you know

922
00:59:22,060 --> 00:59:25,350
the trick we use it to make things more efficient ways to use the distributive

923
00:59:25,350 --> 00:59:27,620
law can be used to sing tool

924
00:59:27,640 --> 00:59:30,760
in the general case for now

925
00:59:34,160 --> 00:59:36,910
obviously this is the question we should be looking for

926
00:59:38,120 --> 00:59:40,490
that's not what we are going to be

927
00:59:55,370 --> 01:00:00,160
that's going to this example he re writing the joint distribution

928
01:00:00,160 --> 01:00:03,180
that's the this little exercise

929
01:00:03,220 --> 01:00:06,490
here's my drawing history

930
01:00:06,510 --> 01:00:11,140
alright joint distribution

931
01:00:13,550 --> 01:00:14,950
these facts

932
01:00:18,450 --> 01:00:25,410
the fact that

933
01:00:27,490 --> 01:00:30,620
x a human xp

934
01:00:30,700 --> 01:00:32,600
called p of

935
01:00:32,600 --> 01:00:34,300
x a

936
01:00:36,260 --> 01:00:39,320
why would you think

937
01:00:39,330 --> 01:00:41,120
that's the first of the two

938
01:00:41,140 --> 01:00:44,180
rules that they told you in the beginning you should keep in mind all the

939
01:00:45,180 --> 01:00:46,410
that's the condition

940
01:00:48,930 --> 01:00:53,830
this to the question of what to do you think

941
01:00:53,870 --> 01:00:57,760
now we are going to be exactly the same

942
01:00:57,800 --> 01:01:01,120
just defined

943
01:01:01,180 --> 01:01:03,830
x a

944
01:01:06,100 --> 01:01:07,970
has been the entire set

945
01:01:08,010 --> 01:01:15,330
o files from x one to xn

946
01:01:18,490 --> 01:01:23,220
you're going to partition the set in this particular way

947
01:01:23,280 --> 01:01:26,680
the first condition here will be just x and the rest will be

948
01:01:26,700 --> 01:01:29,350
from x one to xn one one

949
01:01:29,700 --> 01:01:32,870
so x

950
01:01:32,870 --> 01:01:35,430
will be called to xn

951
01:01:37,200 --> 01:01:38,580
it will be equal to

952
01:01:38,600 --> 01:01:39,740
x y

953
01:01:44,740 --> 01:01:49,100
should take these definitions for x eight and x being used to control here you

954
01:01:49,100 --> 01:01:53,640
get exactly the

955
01:01:53,640 --> 01:01:56,800
joint is this particular

956
01:01:56,850 --> 01:01:58,300
joint as well

957
01:01:58,320 --> 01:02:00,780
for a small number of trials

958
01:02:00,830 --> 01:02:02,700
and this condition

959
01:02:02,760 --> 01:02:06,160
and there's no assumption that all the positivity

960
01:02:06,160 --> 01:02:08,620
i'm actually very common and probably some overview

961
01:02:09,240 --> 01:02:12,810
i have done in the past are doing the same thing myself was in the while

962
01:02:13,530 --> 01:02:14,660
but let me call it there is

963
01:02:15,960 --> 01:02:17,050
the modeling process

964
01:02:17,890 --> 01:02:20,630
so we facing the big data somewhere in the cluster

965
01:02:21,620 --> 01:02:23,170
what the some modeling on it

966
01:02:24,740 --> 01:02:25,350
with some

967
01:02:26,150 --> 01:02:28,260
two of choice sitting in our laptop

968
01:02:28,980 --> 01:02:32,950
and obviously we not fit the data on the laptop so what do we do well

969
01:02:33,800 --> 01:02:35,680
relegated downsample and somehow

970
01:02:36,120 --> 01:02:38,480
so whatever we get fits in the laptop

971
01:02:41,100 --> 01:02:44,810
well how do we know that you know this is the right something like we

972
01:02:44,810 --> 01:02:46,730
don't know really i mean if it's the laptop right

973
01:02:47,390 --> 01:02:49,470
so next going to build some kind of a model

974
01:02:50,150 --> 01:02:51,090
tested little bit

975
01:02:52,090 --> 01:02:53,760
and there may be pushed back the cluster

976
01:02:56,990 --> 01:02:58,100
so what's wrong with this picture

977
01:02:58,480 --> 01:03:00,480
well maybe the model that should go out now

978
01:03:01,260 --> 01:03:01,820
maybe not

979
01:03:02,760 --> 01:03:04,660
but the biggest problem is that there is no

980
01:03:07,940 --> 01:03:09,020
this thing actually works

981
01:03:09,520 --> 01:03:13,460
and next person which comes around and tries to like work and update model

982
01:03:14,200 --> 01:03:15,650
i mean doesn't really know what happened

983
01:03:16,090 --> 01:03:18,480
you know what to lecture was used build was they

984
01:03:19,100 --> 01:03:22,460
o legal process what really happened and nobody knows

985
01:03:23,220 --> 01:03:24,680
so it's really unmaintainable

986
01:03:26,770 --> 01:03:29,550
and by saying so i'm only shooting down they

987
01:03:29,970 --> 01:03:31,480
experimentation with small data

988
01:03:32,390 --> 01:03:36,770
i think experimentation small data is very valuable it can provide little insight

989
01:03:38,420 --> 01:03:41,620
when you have a lot of people doing this production pipelines

990
01:03:42,440 --> 01:03:43,490
in really because mess

991
01:03:44,570 --> 01:03:45,390
you can really

992
01:03:47,200 --> 01:03:49,490
as like the de-facto standard will agreed that

993
01:03:53,440 --> 01:03:55,090
so for those of you who probably know

994
01:03:56,100 --> 01:03:59,960
about mapreduce framework and maybe machine learning frameworks operate on it

995
01:04:00,600 --> 01:04:02,090
so that's question would be

996
01:04:03,660 --> 01:04:05,000
okay why don't you just take

997
01:04:05,700 --> 01:04:10,940
one of the existing learning frameworks which already operated by producers for day

998
01:04:11,890 --> 01:04:14,840
i also want such an open source framework is called

999
01:04:17,030 --> 01:04:18,520
so it is also party project

1000
01:04:18,980 --> 01:04:21,200
anton actually thought hard about it

1001
01:04:22,050 --> 01:04:25,050
could we use apache mahout to that for whatever we go

1002
01:04:26,480 --> 01:04:28,040
and the answer was not really

1003
01:04:29,400 --> 01:04:31,790
primarily for one particular reason

1004
01:04:32,470 --> 01:04:34,100
and the reason is the integration

1005
01:04:36,050 --> 01:04:39,890
really wanted to make whatever we do really easy for users to

1006
01:04:41,040 --> 01:04:44,510
actually interface with the end users and they then office

1007
01:04:45,370 --> 01:04:46,800
entation interrogate the

1008
01:04:47,630 --> 01:04:50,070
my house in big brother thing flows

1009
01:04:50,300 --> 01:04:51,820
it's very hard and not natural

1010
01:04:52,390 --> 01:04:54,920
i'm gonna show examples later on how this can be done

1011
01:04:55,540 --> 01:04:59,200
but this is something which would probably prevent a lot of people from

1012
01:04:59,730 --> 01:05:00,710
getting the maximum

1013
01:05:01,140 --> 01:05:03,030
benefit from using in machine learning

1014
01:05:09,160 --> 01:05:11,220
having said about what did we actually do

1015
01:05:12,760 --> 01:05:14,510
so first of all we build

1016
01:05:15,890 --> 01:05:17,590
a library machine learning routines

1017
01:05:18,060 --> 01:05:19,350
as i mentioned before r

1018
01:05:20,210 --> 01:05:23,460
we focus on fairly simple models such as

1019
01:05:24,180 --> 01:05:25,630
but just aggression for example

1020
01:05:26,340 --> 01:05:28,510
which are very easy to implement

1021
01:05:28,940 --> 01:05:33,530
end by implementing things ourselves were able put extra optimisations

1022
01:05:34,110 --> 01:05:36,630
which would otherwise difficult to get from outside

1023
01:05:37,340 --> 01:05:41,130
i will also together a bunch of our libraries and the extent we could so

1024
01:05:41,130 --> 01:05:43,890
with another thing implemented from scratch

1025
01:05:47,090 --> 01:05:50,540
the important thing was to build a bridge between this library

1026
01:05:51,110 --> 01:05:53,870
and the high-level processing languages that people use

1027
01:05:54,810 --> 01:05:55,740
doing things

1028
01:05:55,800 --> 01:05:57,110
jobs so in this case

1029
01:05:58,210 --> 01:06:02,090
ant colony five with some people use problem most the people

1030
01:06:03,590 --> 01:06:06,960
big male is the primary and the result of this effort

1031
01:06:07,450 --> 01:06:09,280
i was going talk about in detail

1032
01:06:12,090 --> 01:06:14,970
so this is how it works so there's this library

1033
01:06:17,070 --> 01:06:22,030
a low-level code which actually performs the learning and execution in machine learning

1034
01:06:23,230 --> 01:06:23,890
there's already

1035
01:06:24,520 --> 01:06:26,680
data pipeline which produces the data

1036
01:06:28,390 --> 01:06:29,670
there's an integration of

1037
01:06:30,320 --> 01:06:32,240
internal and external components

1038
01:06:32,880 --> 01:06:34,010
in the form of the library

1039
01:06:35,010 --> 01:06:36,630
there's execution love jobs

1040
01:06:37,340 --> 01:06:38,790
on hadoop using big

1041
01:06:39,620 --> 01:06:40,970
and there's this marriage of

1042
01:06:41,670 --> 01:06:43,440
machine learning via big e-mail

1043
01:06:44,050 --> 01:06:46,570
abridgement which i'm going to show you in a second

1044
01:06:49,720 --> 01:06:55,320
so let's start with just having gave very very brief overview of how mapreduce works

1045
01:06:56,130 --> 01:06:59,710
so usually we take data in the form of key-value pairs

1046
01:07:00,530 --> 01:07:02,130
produced by some process

1047
01:07:03,290 --> 01:07:04,750
we randomly partition this

1048
01:07:06,520 --> 01:07:07,940
into a number of mappers

1049
01:07:08,350 --> 01:07:13,980
which the some processing of the data so that they can be for example doing some feature extraction nor

1050
01:07:15,240 --> 01:07:19,700
transformations of words and maybe some approximate matching so and so forth

1051
01:07:21,100 --> 01:07:23,550
this produces another layer of key value

1052
01:07:26,690 --> 01:07:27,320
which are

1053
01:07:27,660 --> 01:07:29,260
sorted by the value the key

1054
01:07:30,670 --> 01:07:31,530
so what we start

1055
01:07:31,530 --> 01:07:33,340
and so

1056
01:07:33,360 --> 01:07:36,980
g is valid in the class of frames

1057
01:07:37,020 --> 01:07:39,330
bold face

1058
01:07:39,540 --> 01:07:41,700
founded in every frame

1059
01:07:42,140 --> 01:07:46,440
and the formula is valid

1060
01:07:46,490 --> 01:07:48,020
it is found in

1061
01:07:48,060 --> 01:07:50,870
class of all

1062
01:07:50,920 --> 01:07:52,890
so see weekend

1063
01:07:53,490 --> 01:07:58,780
later we see that we can restrict to the class of frames see reflected

1064
01:07:58,830 --> 01:08:01,950
and we get a certain logic

1065
01:08:02,150 --> 01:08:09,560
other properties like reflexive and transitive

1066
01:08:11,950 --> 01:08:13,470
this an example of

1067
01:08:13,480 --> 01:08:16,330
the team

1068
01:08:16,420 --> 01:08:23,010
let's prove

1069
01:08:29,660 --> 01:08:31,450
but can

1070
01:08:31,580 --> 01:08:35,800
it lies box

1071
01:08:36,960 --> 01:08:43,470
the free

1072
01:08:45,510 --> 01:08:49,680
sure it's found that means that it is true in all the world

1073
01:08:49,760 --> 01:08:51,660
all values

1074
01:08:51,910 --> 01:08:55,800
so i'm going to prove this by contradiction

1075
01:08:56,830 --> 01:08:58,800
this is not valid

1076
01:08:58,850 --> 01:09:03,400
this means that there exists

1077
01:09:07,430 --> 01:09:10,110
and said well

1078
01:09:15,700 --> 01:09:20,100
such that

1079
01:09:20,120 --> 01:09:25,690
four o

1080
01:09:29,370 --> 01:09:32,260
this formula falls

1081
01:09:32,500 --> 01:09:37,290
in order to make this phone calls

1082
01:09:37,340 --> 01:09:39,260
we have to make this falls

1083
01:09:39,310 --> 01:09:41,300
make is true

1084
01:09:41,310 --> 01:09:43,360
make this small

1085
01:09:43,440 --> 01:09:46,680
so we have to prove that

1086
01:09:52,350 --> 01:09:55,450
next book speech

1087
01:09:55,660 --> 01:10:01,420
and we have to prove that

1088
01:10:01,490 --> 01:10:03,170
box p

1089
01:10:03,170 --> 01:10:04,070
not true

1090
01:10:17,520 --> 01:10:30,660
that for

1091
01:10:36,510 --> 01:10:39,210
now because you is unspecified

1092
01:10:39,260 --> 01:10:40,540
could be at any point

1093
01:10:40,670 --> 01:11:01,350
that's just supposed to you is at this point

1094
01:11:01,360 --> 01:11:07,280
so we have to test all the possible points but this is supposed

1095
01:11:07,290 --> 01:11:08,930
this is the u

1096
01:11:08,940 --> 01:11:10,610
which is the frog

1097
01:11:12,640 --> 01:11:14,620
o clock speed for this

1098
01:11:15,680 --> 01:11:18,490
to consider all success

1099
01:11:22,630 --> 01:11:26,540
this means that this is true of

1100
01:11:26,600 --> 01:11:28,630
success as to p

1101
01:11:34,410 --> 01:11:36,490
then we have to

1102
01:11:36,550 --> 01:11:38,760
show that

1103
01:11:39,240 --> 01:11:41,670
this is the case

1104
01:11:43,640 --> 01:11:45,880
what about phrases false

1105
01:11:45,930 --> 01:11:47,800
again and one

1106
01:11:47,860 --> 01:11:51,090
you can see here

1107
01:11:51,130 --> 01:11:53,240
the successor

1108
01:11:55,500 --> 01:11:57,790
that should not be used here

1109
01:12:00,890 --> 01:12:06,700
four and then we see that the successor of this is for which

1110
01:12:07,380 --> 01:12:09,630
this is for

1111
01:12:09,640 --> 01:12:11,930
peters actually

1112
01:12:12,010 --> 01:12:13,720
what piece

1113
01:12:15,380 --> 01:12:18,220
box box is also true

1114
01:12:18,280 --> 01:12:20,150
but then it contradicts

1115
01:12:20,150 --> 01:12:22,500
it is not so

1116
01:12:24,280 --> 01:12:26,110
we show that

1117
01:12:26,170 --> 01:12:28,870
this is not the case that both

1118
01:12:29,250 --> 01:12:31,140
and the

1119
01:12:31,140 --> 01:12:35,200
two at the same time means that this formula is

1120
01:12:35,220 --> 01:12:36,500
actually says

1121
01:12:36,520 --> 01:12:38,160
what you

1122
01:12:38,160 --> 01:12:40,880
because you have to test for

1123
01:12:40,890 --> 01:12:43,690
OK to you is this

1124
01:12:43,920 --> 01:12:45,600
it can be done the same

1125
01:12:45,600 --> 01:13:11,630
now that example

1126
01:13:12,030 --> 01:13:15,640
so in this case we have

1127
01:13:16,690 --> 01:13:19,950
what the world is set of natural numbers

1128
01:13:19,990 --> 01:13:24,040
on the relation r is the last station on set

1129
01:13:24,050 --> 01:13:26,740
you drive traffic

1130
01:13:36,030 --> 01:13:40,260
western nations to its

1131
01:13:43,750 --> 01:13:46,210
so it

1132
01:13:51,210 --> 01:13:56,830
and we want to show that

1133
01:13:59,590 --> 01:14:00,850
china p

1134
01:14:05,940 --> 01:14:09,920
going to show this we just have to

1135
01:14:09,970 --> 01:14:14,360
i'm not with the world validation which is formed

1136
01:14:14,400 --> 01:14:17,650
possible by using the cosine

1137
01:14:17,980 --> 01:14:20,590
the world which is the number of p

1138
01:14:20,740 --> 01:14:22,260
on the

1139
01:14:22,310 --> 01:14:25,590
the numbers you get

1140
01:14:29,430 --> 01:14:30,920
this form is for

1141
01:14:30,930 --> 01:14:32,700
for example just take

1142
01:14:32,760 --> 01:14:36,380
it was zero

1143
01:14:43,160 --> 01:14:50,430
o five

1144
01:14:53,580 --> 01:14:55,340
now in order to prove this

1145
01:14:55,360 --> 01:15:00,670
we need to show that

1146
01:15:00,680 --> 01:15:03,480
this is true

1147
01:15:03,530 --> 01:15:11,020
want to show that

1148
01:15:11,060 --> 01:15:13,830
this is false

1149
01:15:13,830 --> 01:15:17,480
to see why this is true from zero

1150
01:15:18,530 --> 01:15:23,590
the successor of the series was a number greater than here

1151
01:15:26,550 --> 01:15:29,540
for any successor would of

1152
01:15:29,610 --> 01:15:32,440
here are the same

1153
01:15:32,450 --> 01:15:35,270
for this reason we show that

1154
01:15:35,290 --> 01:15:36,600
for any

1155
01:15:42,710 --> 01:15:45,450
and next

1156
01:15:45,450 --> 01:15:47,530
damon p true

1157
01:15:47,550 --> 01:15:52,690
now that means p is true only in the world which is numbers

1158
01:15:52,690 --> 01:15:56,140
and this just means that we have to find an even number which is greater

1159
01:15:56,140 --> 01:15:57,600
may have tens

1160
01:15:57,620 --> 01:16:02,070
so in HMM could be enough if you make a lot of assumptions are it

1161
01:16:02,070 --> 01:16:05,850
could not be enough you may want to have this still more complex

1162
01:16:05,870 --> 01:16:10,480
models and we are going to go a little bit on other models that could

1163
01:16:10,480 --> 01:16:14,290
be used for that are extensions of HMM

1164
01:16:14,290 --> 01:16:22,290
so they are all mostly in the family of what we call a graphical model

1165
01:16:23,000 --> 01:16:24,520
what is a graphical model

1166
01:16:25,600 --> 01:16:29,900
we are still in the generative well so we have we have distributions and we

1167
01:16:29,900 --> 01:16:32,270
want to model them and the

1168
01:16:32,290 --> 01:16:36,440
the basic idea of the generative model in general is to be able to model

1169
01:16:36,440 --> 01:16:40,620
the joint probability of several random variables

1170
01:16:42,460 --> 01:16:47,350
similar to HMM we see the same equations you can factor this giant into the

1171
01:16:47,350 --> 01:16:52,750
product of the purview of each random variable given all the other ones that now

1172
01:16:52,750 --> 01:16:56,920
instead of using all the other ones are going to talk about the parents and

1173
01:16:56,940 --> 01:17:01,940
the parents are those that we your prior knowledge you know influence the given environment

1174
01:17:01,980 --> 01:17:05,100
so you may know for instance that x one

1175
01:17:05,140 --> 01:17:09,620
is only depending on x two and x five it has no no relation with

1176
01:17:09,620 --> 01:17:10,500
x two

1177
01:17:10,520 --> 01:17:13,830
so if you knew x two and x five you could decide on the distribution

1178
01:17:13,830 --> 01:17:15,100
of x one

1179
01:17:15,120 --> 01:17:18,850
you could know so that the x two is independent of all the other ones

1180
01:17:18,870 --> 01:17:22,980
extreme as well that x four depends on x two x three so these are

1181
01:17:22,980 --> 01:17:25,310
prior knowledge that you know

1182
01:17:25,330 --> 01:17:29,880
you're going to build that into your mother saying basically that the joint probability

1183
01:17:29,900 --> 01:17:33,790
it is now on the product of these terms instead of being the product

1184
01:17:34,980 --> 01:17:38,140
of each random variable given to all the other ones

1185
01:17:38,150 --> 01:17:39,190
and this

1186
01:17:39,210 --> 01:17:44,920
conditional so graphically that's what we call the graphical models because now each arrow

1187
01:17:44,940 --> 01:17:50,080
present one of these relations so x one depends on x two and x five

1188
01:17:50,080 --> 01:17:52,790
we see here x one depends on x two

1189
01:17:52,810 --> 01:17:54,150
the next five

1190
01:17:54,170 --> 01:17:58,190
and you can go on and draw your life graph

1191
01:17:58,190 --> 01:18:04,200
and what's useful with these graphical models is that there's a lot of literature in

1192
01:18:06,540 --> 01:18:11,100
you can handle an arbitrary number of such random variables

1193
01:18:11,100 --> 01:18:16,370
and in any case there is negative called the junction tree algorithm that can be

1194
01:18:16,370 --> 01:18:20,900
used to estimate the probability of these joint likelihood

1195
01:18:20,900 --> 01:18:22,600
in an efficient way

1196
01:18:22,620 --> 01:18:27,580
although it depends on the relations you have in your in your graph the more

1197
01:18:27,580 --> 01:18:31,150
arrows you have in the graph the more complex it would be to compute this

1198
01:18:31,150 --> 01:18:35,600
joint likelihood but you will always use something similar to the junction tree algorithm so

1199
01:18:35,600 --> 01:18:39,710
this is kind of generic according to compute any

1200
01:18:39,730 --> 01:18:42,690
likelihood of any

1201
01:18:42,730 --> 01:18:45,850
a set of random variables

1202
01:18:45,850 --> 01:18:51,770
although you have to know that sometimes it's not tractable what i mean by that

1203
01:18:51,770 --> 01:18:56,620
is that the you know the computed you need an exponential number of of time

1204
01:18:57,020 --> 01:19:01,850
with respect to the random variables and so in practice you will not be able

1205
01:19:01,850 --> 01:19:06,500
to compute it unless you make a lot of assumptions and simplifications but

1206
01:19:06,580 --> 01:19:11,710
fortunately there are no details are a lot of those algorithm that computes

1207
01:19:11,730 --> 01:19:18,270
over tractable graph by making lots of assumptions so you have the junction tree algorithm

1208
01:19:18,270 --> 01:19:20,850
to compute the likelihood

1209
01:19:20,870 --> 01:19:25,060
and you have again you expected maximisation EMI grid and that can be used to

1210
01:19:25,060 --> 01:19:31,020
train again this is only true when you're you have tractable graph but if you

1211
01:19:31,020 --> 01:19:38,210
have an intractable graph there exist still lots of approximation algorithms that can be used

1212
01:19:38,230 --> 01:19:39,350
now one of the

1213
01:19:39,350 --> 01:19:40,730
one of the

1214
01:19:40,770 --> 01:19:45,310
possible graphical models that you can find and you may have heard of them is

1215
01:19:45,310 --> 01:19:53,540
called dynamic bayes networks which is basically a trained the model have now and temporal

1216
01:19:53,620 --> 01:19:57,370
value so it's kind of temporal extensions

1217
01:19:57,520 --> 01:20:02,120
you can either see there's an extension are part of graphical models but it is

1218
01:20:02,120 --> 01:20:07,080
a subfamily of graphical models

1219
01:20:07,100 --> 01:20:11,370
i just want to mention that the in the territory you can find the aliens

1220
01:20:11,370 --> 01:20:15,770
of possible graphical models with the associated

1221
01:20:15,790 --> 01:20:18,960
i gradients to capitalise you compute the

1222
01:20:18,980 --> 01:20:20,880
training etcetera

1223
01:20:20,900 --> 01:20:22,190
just to show you

1224
01:20:22,210 --> 01:20:25,310
there is plenty of them

1225
01:20:25,310 --> 01:20:33,100
that have been used for multimodal processing in the past the literature that's on your

1226
01:20:33,100 --> 01:20:33,920
part of the

1227
01:20:33,960 --> 01:20:35,350
and of course

1228
01:20:35,380 --> 01:20:38,230
i will not explain all of them but i have said that a couple of

1229
01:20:38,310 --> 01:20:39,330
of those

1230
01:20:39,350 --> 01:20:41,830
they want to to explain in more detail

1231
01:20:41,850 --> 01:20:46,560
but it's going to to be quite quick because each of them would be

1232
01:20:47,420 --> 01:20:51,060
of interest and take about an hour more

1233
01:20:51,080 --> 01:20:54,730
to explain which i don't have time to

1234
01:20:54,750 --> 01:20:58,960
so i just want to to have a kind of uniform notation to explain to

1235
01:20:58,960 --> 01:21:02,190
express our multimodal task

1236
01:21:02,190 --> 01:21:05,650
with respect to these graphical models

1237
01:21:06,400 --> 01:21:10,170
let's talk about notation first

1238
01:21:10,170 --> 01:21:12,900
so we have

1239
01:21:12,920 --> 01:21:14,540
i suppose you only have one

1240
01:21:15,350 --> 01:21:18,710
sequence of an observation which i'm going to call one stream

1241
01:21:18,820 --> 01:21:24,260
so for one stream we could say that we have a training set of these

1242
01:21:25,620 --> 01:21:32,330
of of the strings capital and of strings in sequence and each sequence now

1243
01:21:32,460 --> 01:21:38,480
could of observation would be noted all one o two o two o t l

1244
01:21:38,500 --> 01:21:42,400
and being index the index of the alpha sequence

1245
01:21:42,400 --> 01:21:47,840
will be just the sum over all states of j marginalisation exactly what the

1246
01:21:49,580 --> 01:21:57,900
coupling between g and i times the problem of all incoming messages to j

1247
01:21:59,960 --> 01:22:03,620
so you want to send a message from j to i take all incoming messages

1248
01:22:04,520 --> 01:22:05,660
to j

1249
01:22:05,720 --> 01:22:09,700
take the product of that problem

1250
01:22:11,360 --> 01:22:13,570
the individual potential

1251
01:22:13,620 --> 01:22:14,780
between g

1252
01:22:14,800 --> 01:22:17,270
in some order

1253
01:22:17,320 --> 01:22:20,610
they have the message from day one

1254
01:22:20,690 --> 01:22:22,720
i want to compute all the message

1255
01:22:22,740 --> 01:22:23,760
it just

1256
01:22:23,770 --> 01:22:26,960
compute the product of all incoming messages

1257
01:22:26,970 --> 01:22:28,170
then you have the march

1258
01:22:28,320 --> 01:22:31,420
you can actually prove

1259
01:22:31,420 --> 01:22:33,740
i mean you can do is an the cosine

1260
01:22:33,760 --> 01:22:37,610
from the user will actually give you the that these are will give you the

1261
01:22:37,610 --> 01:22:40,000
correct market

1262
01:22:40,070 --> 01:22:41,250
i mean prove

1263
01:22:42,360 --> 01:22:48,150
correct correctness as of these

1264
01:22:50,030 --> 01:22:50,920
there's a whole

1265
01:22:50,920 --> 01:22:52,210
o thing that we can

1266
01:22:52,220 --> 01:22:55,590
talk about in terms of factor graphs as well

1267
01:22:55,950 --> 01:22:57,570
what i will do is the following

1268
01:22:57,630 --> 01:22:59,480
i'll just go through

1269
01:22:59,500 --> 01:23:01,500
so the junction tree algorithm

1270
01:23:01,550 --> 01:23:05,210
and then we cover factor graph if we have some time

1271
01:23:06,060 --> 01:23:10,020
at the end of day factor graphs are just the nice way of

1272
01:23:10,200 --> 01:23:12,720
doing belief propagation but they don't add

1273
01:23:12,730 --> 01:23:14,490
much of

1274
01:23:14,570 --> 01:23:15,890
essential called

1275
01:23:15,950 --> 01:23:18,530
the junction tree algorithm is more important

1276
01:23:18,650 --> 01:23:20,180
why don't we

1277
01:23:20,190 --> 01:23:21,440
just go to

1278
01:23:21,500 --> 01:23:25,480
the junction tree

1279
01:23:25,740 --> 01:23:27,860
that's what the junction tree

1280
01:23:27,860 --> 01:23:29,800
then if you have time to to go back

1281
01:23:33,070 --> 01:23:36,990
we need to go for the lecture five is likely

1282
01:23:37,030 --> 01:23:41,250
i have added a few slides all may not match exactly what you will not

1283
01:23:41,250 --> 01:23:43,270
match what have been

1284
01:23:44,270 --> 01:23:46,110
we learn that

1285
01:23:46,170 --> 01:23:49,530
let's the magic

1286
01:23:49,550 --> 01:23:52,030
OK so

1287
01:23:52,050 --> 01:23:56,150
let's assume now that we don't have three is anymore i mean these are very

1288
01:23:56,150 --> 01:23:57,860
simple graphs

1289
01:23:57,900 --> 01:24:03,460
i mean you want to be able to work with that all the countries

1290
01:24:03,510 --> 01:24:06,900
let's assume we have well graph like this similar to

1291
01:24:07,030 --> 01:24:09,360
the graph have already seen

1292
01:24:09,360 --> 01:24:13,570
need to run the elimination i wish to compute marginals OK

1293
01:24:13,630 --> 01:24:16,760
so as you see we cannot use belief propagation here

1294
01:24:16,800 --> 01:24:19,440
in principle we can use but

1295
01:24:19,490 --> 01:24:23,550
don't necessarily produce the right results because it's not the three

1296
01:24:25,300 --> 01:24:29,070
but you can use the elimination of one because what the elimination of the elimination

1297
01:24:29,070 --> 01:24:31,170
of one is always exact

1298
01:24:31,210 --> 01:24:38,630
just sometimes inefficient but is always exact because she just making use of

1299
01:24:38,690 --> 01:24:42,510
of the distributive law

1300
01:24:42,740 --> 01:24:45,050
let's assume we want to compute

1301
01:24:45,070 --> 01:24:47,530
we want to compute p of x one

1302
01:24:47,630 --> 01:24:49,490
given x six

1303
01:24:51,260 --> 01:24:54,090
let's assume you have observed that sick

1304
01:24:54,170 --> 01:24:56,440
whatever may be x sixs

1305
01:24:56,440 --> 01:24:57,990
well the fact that

1306
01:24:58,090 --> 01:25:00,340
yesterday we had

1307
01:25:00,400 --> 01:25:02,710
we don't have training or

1308
01:25:02,820 --> 01:25:07,610
and here is the probability of having rain today and kill for example is other

1309
01:25:09,190 --> 01:25:11,050
temperature pressure level

1310
01:25:11,170 --> 01:25:12,550
and you want to compute

1311
01:25:12,570 --> 01:25:15,510
what's the probability that we have range

1312
01:25:15,530 --> 01:25:19,550
and i've given that we do have bring yesterday

1313
01:25:21,210 --> 01:25:22,880
so how do go on

1314
01:25:22,880 --> 01:25:24,440
actually compute these

1315
01:25:24,440 --> 01:25:26,800
probability new models

1316
01:25:26,900 --> 01:25:28,530
well that's how you do it you know

1317
01:25:28,530 --> 01:25:30,880
you need to run

1318
01:25:30,920 --> 01:25:32,490
nomination of

1319
01:25:32,550 --> 01:25:35,070
you're right at all

1320
01:25:37,190 --> 01:25:40,860
the expression for the joint probability distribution using the

1321
01:25:40,880 --> 01:25:43,420
factorisation hammersley clifford

1322
01:25:44,380 --> 01:25:47,800
delta just indicating that we have observed

1323
01:25:47,820 --> 01:25:50,610
the particular value of x six

1324
01:25:50,650 --> 01:25:56,630
so we don't have a distribution have collapsed the distribution into single

1325
01:25:56,630 --> 01:25:58,570
got single that don't have

1326
01:25:58,590 --> 01:26:03,570
we don't have any uncertainty on the variables of the delta function that's basically telling

1327
01:26:04,740 --> 01:26:09,070
we know the value of x six is equal to some x six model given

1328
01:26:11,030 --> 01:26:13,490
and the work is to i mean you know how to do it we just

1329
01:26:13,490 --> 01:26:14,940
learn how to

1330
01:26:14,990 --> 01:26:17,900
now they compute

1331
01:26:17,900 --> 01:26:20,190
compute my

1332
01:26:20,240 --> 01:26:24,920
my p of x one and x six and then just some of

1333
01:26:24,940 --> 01:26:27,170
x six here

1334
01:26:27,170 --> 01:26:29,090
have the condition

1335
01:26:30,710 --> 01:26:32,920
compute these quantities here

1336
01:26:32,920 --> 01:26:34,260
your sexy

1337
01:26:34,260 --> 01:26:36,590
samuel like one i think is

1338
01:26:36,590 --> 01:26:38,990
just divide

1339
01:26:39,010 --> 01:26:40,570
these by that

1340
01:26:40,590 --> 01:26:43,900
because p of x one given x six is equal to p of

1341
01:26:43,940 --> 01:26:45,740
x one x six

1342
01:26:45,760 --> 01:26:48,240
divided by p of x six

1343
01:26:48,300 --> 01:26:55,490
right from just taking the racial this thing in that

1344
01:27:10,010 --> 01:27:14,510
so now we want to compute something else OK let's compute p of extreme given

1345
01:27:14,510 --> 01:27:17,340
x let x six let's assume that

1346
01:27:17,340 --> 01:27:20,190
this is the probability that whatever it will

1347
01:27:20,240 --> 01:27:23,570
rain tomorrow given that yes they brain

1348
01:27:25,090 --> 01:27:28,440
now it's the same we just do the same thing

1349
01:27:28,440 --> 01:27:33,240
we go on compute things about suddenly we see that

1350
01:27:33,300 --> 01:27:38,690
there are some

1351
01:27:38,690 --> 01:27:43,030
computations here there are some

1352
01:27:47,070 --> 01:27:48,780
we know that

1353
01:27:48,800 --> 01:27:53,550
we know them from the previous computation

1354
01:27:53,590 --> 01:27:55,690
the same case head for trees

1355
01:27:55,740 --> 01:27:58,510
if we have different queries

1356
01:27:58,530 --> 01:28:03,340
and that's what always mentioning basically if you have different queries you don't want to

1357
01:28:03,340 --> 01:28:06,220
database and extract satisfy conditions

1358
01:28:06,630 --> 01:28:11,740
exactly the same thing so we are equating me is about in this case we

1359
01:28:11,740 --> 01:28:23,490
are interesting in interested in this going to eventually constrained by particle constraints and the

1360
01:28:23,500 --> 01:28:25,260
mining equipment and it can be

1361
01:28:27,180 --> 01:28:33,070
i would be willing to to be quite obvious kind of syntax is described the

1362
01:28:33,070 --> 01:28:38,920
form of a quite difficult for non-experts to system so we have the important to

1363
01:28:38,920 --> 01:28:45,040
the local some guy that can have not expertise then is system in the formulating

1364
01:28:45,040 --> 01:28:47,260
the query awareness improved

1365
01:28:47,420 --> 01:28:52,590
two things to do microsoft microsoft access system where it is

1366
01:28:52,740 --> 01:28:58,360
formulation by means of a query by example that is designed for use that are

1367
01:28:58,360 --> 01:29:02,480
not expert of as query languages so you can query the database and we don't

1368
01:29:02,480 --> 01:29:05,580
know the knowledge of the

1369
01:29:05,590 --> 01:29:11,710
the square and to the monitoring and is not an invention of the last three

1370
01:29:11,710 --> 01:29:16,680
years because the onset of the mining according to the first one is quite lot

1371
01:29:16,930 --> 01:29:22,190
that was defined in the form of relational database and so it is not about

1372
01:29:22,200 --> 01:29:26,520
the design two dealing with the degree of complexity that are in the

1373
01:29:26,640 --> 01:29:30,180
a special struck structure of graphical data

1374
01:29:30,200 --> 01:29:36,160
the plan was defined by capacity in nineteen ninety nine it is that doc doc

1375
01:29:36,180 --> 01:29:41,470
language for special time mining my data design tool to work on the data that

1376
01:29:41,470 --> 01:29:47,190
are stored in a single table of a relational database so it does not deal

1377
01:29:47,190 --> 01:29:52,420
with exactly all the degree of complexity that we have defined the for this part

1378
01:29:52,420 --> 01:29:58,080
of the mining task in both cases

1379
01:29:58,300 --> 01:30:02,950
in both cases they are inspired to describe languages so too difficult and as assume

1380
01:30:03,170 --> 01:30:10,380
single stable are some some so they are not suitable for dealing with the object

1381
01:30:10,380 --> 01:30:14,330
relational information that is the story of engines system

1382
01:30:14,340 --> 01:30:18,040
as you know quite language is the language that we defined in this case it

1383
01:30:18,090 --> 01:30:19,920
combine them

1384
01:30:19,930 --> 01:30:29,000
object the nature of the data with the specific especially mining requirement the language has

1385
01:30:29,000 --> 01:30:34,390
been designed and according to a set of data mining of primitives so that no

1386
01:30:36,680 --> 01:30:41,770
to facilitate in a feature intended for flutes this quantity of interest in the knowledge

1387
01:30:41,770 --> 01:30:48,670
of the primitive that we have used it included the first specification specification of the

1388
01:30:48,670 --> 01:30:54,070
parts of the data that i think therefore i want mining ghost the second is

1389
01:30:54,070 --> 01:30:57,690
the kind of knowledge engineering sharing to interesting is going to be going to school

1390
01:30:57,700 --> 01:31:06,740
where association rules classification training images in the classification rule clustering of clusters if we

1391
01:31:06,800 --> 01:31:07,460
expand with

1392
01:31:07,760 --> 01:31:13,720
clusters are addition to something that's the kind of knowledge to be extracted the but

1393
01:31:13,790 --> 01:31:17,570
no it that should be useful for guiding them

1394
01:31:17,590 --> 01:31:24,790
discovery process some some interesting transmission that are important in evolution process and the

1395
01:31:24,820 --> 01:31:28,870
and and then we can specify either

1396
01:31:28,880 --> 01:31:33,900
so in addition to we have we intend to have before discovered some

1397
01:31:33,910 --> 01:31:40,400
these different primitives corresponds are limited marked the missing text from

1398
01:31:40,710 --> 01:31:46,760
the language is the top level description of the business in texas so again while

1399
01:31:46,760 --> 01:31:53,020
query can be a statement or sequence of different statement issued statements can be a

1400
01:31:53,120 --> 01:31:59,880
statement for the mining part also or statement specified background nodes to a statement from

1401
01:31:59,900 --> 01:32:07,130
to specify and and this statement to specify ourselves should be displayed in but in

1402
01:32:07,210 --> 01:32:13,350
the case of the mining statement we have an objective way to select the portion

1403
01:32:13,350 --> 01:32:19,800
of the time we are interested in analyzing mine keyword the mind to introduce the

1404
01:32:19,800 --> 01:32:25,280
kind of bot to be discovered analyzer to introduce to the set of descriptors so

1405
01:32:25,840 --> 01:32:30,540
that we use in analyzing we into

1406
01:32:30,550 --> 01:32:37,710
to analyse these data for example a INEX and shown on the topological relations on

1407
01:32:38,220 --> 01:32:44,100
and when this great site to specify the discrete will appear in the past that

1408
01:32:44,700 --> 01:32:49,190
since these descriptors can be exactly the same this data that we have defined within

1409
01:32:49,190 --> 01:32:51,660
hard to deal with the markov networks

1410
01:32:51,670 --> 01:32:56,490
now one thing that is important to realize that if you look at the graphs

1411
01:32:56,660 --> 01:32:59,110
bayesian networks and markov networks

1412
01:32:59,120 --> 01:33:03,760
if there are some things that you can some independence relations you can represent compactly

1413
01:33:03,760 --> 01:33:07,010
in the markov network but not in the business work and vice versa

1414
01:33:07,030 --> 01:33:09,520
so neither one dominates in that respect

1415
01:33:09,570 --> 01:33:12,640
but the important thing to bear in mind is that the log linear form applies

1416
01:33:12,640 --> 01:33:16,190
to both say something is a compact bayes ill how it will be a compact

1417
01:33:16,190 --> 01:33:19,980
log linear form and something for markov network so as long as using the slogan

1418
01:33:19,980 --> 01:33:23,410
linear form in terms of compactness rho was OK

1419
01:33:23,460 --> 01:33:26,780
how do we do inference in markov networks we can use as we shall see

1420
01:33:26,780 --> 01:33:31,830
shortly algorithms like markov chain monte carlo belief propagation and so on

1421
01:33:31,860 --> 01:33:33,760
in bayesian networks

1422
01:33:33,780 --> 01:33:35,310
what we usually do

1423
01:33:35,410 --> 01:33:38,980
for inference is first converted them to markov networks and then we did inference in

1424
01:33:38,980 --> 01:33:44,500
markov networks so in some sense markov networks are the more fundamental notion

1425
01:33:44,520 --> 01:33:47,540
so how do we do inference in markov networks

1426
01:33:47,590 --> 01:33:51,190
well typically what we so the markov network is the model of the full joint

1427
01:33:51,190 --> 01:33:54,500
distribution of the set of variables and typically the questions that we want to answer

1428
01:33:54,730 --> 01:33:59,690
i things like what is the conditional probability of some variable given some others

1429
01:33:59,690 --> 01:34:02,800
what is the marginal distribution of some subset of the variables

1430
01:34:02,820 --> 01:34:06,280
and here is the expression that we want to do this over

1431
01:34:06,300 --> 01:34:10,960
unfortunately doing doing this inference exactly is a very hard problem it struck the complete

1432
01:34:10,960 --> 01:34:13,430
which means it's even worse than NP hard

1433
01:34:14,970 --> 01:34:17,560
however there's something that's actually very easy

1434
01:34:17,580 --> 01:34:21,020
which is the condition notice called the markov blanket

1435
01:34:21,040 --> 01:34:22,350
of the variable

1436
01:34:22,370 --> 01:34:26,310
the markov blanket of a variable in the markov network is just its neighbors in

1437
01:34:26,310 --> 01:34:27,230
the graph

1438
01:34:27,410 --> 01:34:31,310
it's easy to see that the distribution of the variable given its neighbors in the

1439
01:34:31,310 --> 01:34:35,480
graph is actually can be computed directly it's simple expression of the cliques that don't

1440
01:34:35,480 --> 01:34:39,760
involve that variable disappear things cancel out and so this this can be done quite

1441
01:34:39,760 --> 01:34:43,820
efficiently and so what we're going to see is is an algorithm for the inference

1442
01:34:43,820 --> 01:34:45,270
that exploits the

1443
01:34:45,420 --> 01:34:49,060
the algorithm is called gibbs sampling it's probably one of the most widely used algorithms

1444
01:34:49,060 --> 01:34:50,950
in the universe

1445
01:34:50,950 --> 01:34:55,860
there was a survey like i think by at tripoli computer years ago of what

1446
01:34:55,860 --> 01:34:59,940
the most important you know algorithms were this actually came out on top

1447
01:34:59,960 --> 01:35:05,330
because it used throughout science and technologies to do inference on complicated probabilistic models and

1448
01:35:05,330 --> 01:35:09,810
it's or more generally markov chain monte carlo of which gives sampling is an example

1449
01:35:09,820 --> 01:35:14,570
and it's a joyful simple algorithm for its power so it's well worth nine so

1450
01:35:14,700 --> 01:35:17,200
there's give sampling work it works like this

1451
01:35:17,220 --> 01:35:21,830
i start out by assigning random truth values to all my variables are focusing on

1452
01:35:21,830 --> 01:35:23,950
the building case you

1453
01:35:23,960 --> 01:35:26,290
and then i i do the following

1454
01:35:26,320 --> 01:35:28,420
i repeatedly go to variable

1455
01:35:28,430 --> 01:35:30,450
and resample its value

1456
01:35:31,420 --> 01:35:33,360
its neighbours

1457
01:35:33,390 --> 01:35:37,070
so i have its conditional distribution given state not taking you sample of its value

1458
01:35:37,080 --> 01:35:40,280
have new state and i just do this for a long time

1459
01:35:40,300 --> 01:35:45,430
so maximum cycles oriental some convergence criterion is met and then i just estimate my

1460
01:35:45,430 --> 01:35:48,560
problem is of interest as the fraction of states

1461
01:35:48,580 --> 01:35:51,520
in which the event that i'm asking about help

1462
01:35:51,530 --> 01:35:54,910
like can know what is the problem that this person has no disease x y

1463
01:35:54,980 --> 01:35:59,870
i sample which states and if you if if interstates eighty percent of the person

1464
01:36:00,650 --> 01:36:03,500
diseasex then i should probably point

1465
01:36:03,520 --> 01:36:10,830
this is really give sampling it's a very small simple that's but it's also very

1466
01:36:12,340 --> 01:36:16,710
there are the inference methods that are there are worth knowing about

1467
01:36:16,710 --> 01:36:22,930
new sampling in the truth is actually probably over that's use even when it's not

1468
01:36:22,930 --> 01:36:28,030
the best thing to the to have so there are many many variations of markov

1469
01:36:28,030 --> 01:36:29,450
chain monte carlo

1470
01:36:29,650 --> 01:36:33,080
so give sampling is just the best known represent this class but there are many

1471
01:36:33,080 --> 01:36:37,980
other there's also a new class of which called belief propagation

1472
01:36:38,000 --> 01:36:43,200
that that is becoming quite popular in particular for this

1473
01:36:43,210 --> 01:36:47,160
that's the problem we use what's called the sum product version of belief propagation

1474
01:36:47,200 --> 01:36:52,190
because what we're actually doing is we're doing sums of products to compute probabilities

1475
01:36:52,200 --> 01:36:58,740
there's also variational approximations and there's also a very large literature on exact methods

1476
01:36:58,760 --> 01:37:02,950
give sampling and all these other methods are approximate to give an approximate answer with

1477
01:37:02,950 --> 01:37:06,850
more time to give you a better answer there's also exact methods

1478
01:37:06,860 --> 01:37:10,260
however exact methods do not work on the large problems that were interested in here

1479
01:37:10,260 --> 01:37:12,770
so we're not going to focus on the much but there's certainly a lot of

1480
01:37:13,460 --> 01:37:17,490
you know there's a big later literature and so the other main type of inference

1481
01:37:17,490 --> 01:37:21,930
that we are going to want to do is what's called MEP from maximum security

1482
01:37:21,930 --> 01:37:25,910
so again what you see here is the range of possibility

1483
01:37:25,910 --> 01:37:27,160
that the

1484
01:37:27,200 --> 01:37:30,200
well the symmetric variance gamma process

1485
01:37:31,950 --> 01:37:33,640
can achieve so

1486
01:37:33,640 --> 01:37:36,280
again you see very much dominance by

1487
01:37:36,510 --> 01:37:39,160
by the end of the picture by the

1488
01:37:39,160 --> 01:37:45,160
the biggest jumps for small parameters and for bigger parameters you see another convergence this

1489
01:37:45,160 --> 01:37:47,990
is the convergence to brownian motion

1490
01:37:47,990 --> 01:37:49,990
instead of central limit theorem

1491
01:37:51,120 --> 01:37:55,780
within the class of of variance gamma processes

1492
01:37:55,780 --> 01:37:59,370
and you might say well what you are looking at here is really we zoom

1493
01:38:00,220 --> 01:38:03,320
into a a variance gamma process here

1494
01:38:03,320 --> 01:38:05,010
to see such a picture

1495
01:38:05,010 --> 01:38:06,700
and we zoom out

1496
01:38:06,720 --> 01:38:08,890
this is such a picture so

1497
01:38:08,910 --> 01:38:10,990
that's aggregate normality

1498
01:38:11,450 --> 01:38:17,620
that's quite useful for financial time series because in the very long term the normal

1499
01:38:17,620 --> 01:38:22,840
distribution is not all that bad but when you have a reasonably short horizon it's

1500
01:38:22,840 --> 01:38:23,950
just not

1501
01:38:25,320 --> 01:38:30,390
very useful for other problems if you if you take two shortened horizon and looking

1502
01:38:30,390 --> 01:38:32,260
to intraday behavior then

1503
01:38:32,260 --> 01:38:35,570
any of these models is inadequate anyway

1504
01:38:35,590 --> 01:38:37,930
but i get to that

1505
01:38:37,970 --> 01:38:43,780
if i have time at the end so i was saying really modelling freedom comes

1506
01:38:43,780 --> 01:38:48,360
from specifying the characteristics rather than the increment distribution

1507
01:38:49,680 --> 01:38:55,780
famous early examples have been stable processes that have been studied for their scaling relation

1508
01:38:55,780 --> 01:38:58,510
with the distribution at the time eighty

1509
01:38:58,510 --> 01:39:02,470
can be derived from the distribution at time t just by

1510
01:39:02,700 --> 01:39:07,640
by multiplying the random variable y y is a constant

1511
01:39:07,660 --> 01:39:14,280
so such processes can be obtained by specifying in may be the simplest possible way

1512
01:39:14,800 --> 01:39:16,100
the density

1513
01:39:16,160 --> 01:39:17,390
of the

1514
01:39:17,640 --> 01:39:19,320
measure new

1515
01:39:20,100 --> 01:39:23,570
you just take powers of of x

1516
01:39:23,620 --> 01:39:25,260
as as entities

1517
01:39:25,280 --> 01:39:27,430
so that makes sense for

1518
01:39:27,450 --> 01:39:29,590
alpha between zero and two

1519
01:39:29,600 --> 01:39:32,590
i've separated out the two cases here

1520
01:39:32,600 --> 01:39:35,370
in order to be explicit about what

1521
01:39:35,390 --> 01:39:40,090
kind of compensation use here we don't need to compensate any jumps and here we

1522
01:39:40,090 --> 01:39:43,870
can compensate all sounds other than that the two

1523
01:39:43,930 --> 01:39:49,120
the same is also alpha equals one which looks a little different and alpha equals

1524
01:39:49,720 --> 01:39:54,740
which is in is very different it which is brownian motion

1525
01:39:54,740 --> 01:39:59,070
there may be more interestingly is a class of processes

1526
01:39:59,140 --> 01:40:04,660
which is sort of the next most natural way you've got both a a polynomial

1527
01:40:05,510 --> 01:40:07,780
and an exponential time

1528
01:40:07,800 --> 01:40:12,450
well of course this polynomial time describes the behavior near zero

1529
01:40:12,470 --> 01:40:17,950
and the exponential term describes the behavior near infinity in the one case and you

1530
01:40:17,950 --> 01:40:20,910
minus infinity in the other case

1531
01:40:20,930 --> 01:40:22,450
so you've

1532
01:40:22,450 --> 01:40:28,370
you've then got a certain number of parameters this five parameters in this

1533
01:40:28,370 --> 01:40:29,970
this density

1534
01:40:29,990 --> 01:40:31,720
of our measure new

1535
01:40:31,740 --> 01:40:33,300
and that gives us

1536
01:40:33,300 --> 01:40:35,800
quite a bit of of modelling freedom

1537
01:40:35,800 --> 01:40:41,410
to start off with such simple definitions here you could go on and take linear

1538
01:40:41,410 --> 01:40:45,890
combinations of these are taken in take your favourite function

1539
01:40:45,910 --> 01:40:47,820
on the real line

1540
01:40:47,840 --> 01:40:54,220
as soon as it satisfies this is integrability condition of one minimum x squared and

1541
01:40:54,220 --> 01:40:55,660
you can take it as the

1542
01:40:55,720 --> 01:40:59,930
well if nonnegative as well you can take it as the density of

1543
01:40:59,930 --> 01:41:03,680
the nation news so that's a lot of freedom

1544
01:41:03,680 --> 01:41:10,640
and disadvantage then of course is that if you then asked to to fit

1545
01:41:10,660 --> 01:41:16,890
your model to data then while the probability density function is not available in closed

1546
01:41:16,890 --> 01:41:22,090
form you can have some integral representations or some

1547
01:41:22,120 --> 01:41:28,510
you can invert some characteristic functions are moment generating functions and and you've got a

1548
01:41:28,510 --> 01:41:32,030
way of of of doing the

1549
01:41:32,140 --> 01:41:34,090
in the model fitting

1550
01:41:34,090 --> 01:41:35,370
but it's sort of

1551
01:41:35,390 --> 01:41:40,180
a little less elementary then and by modeling the income distribution

1552
01:41:40,240 --> 01:41:41,570
i've got some

1553
01:41:41,590 --> 01:41:44,990
simulations of stable processes so you see

1554
01:41:45,050 --> 01:41:46,550
again very similar

1555
01:41:46,570 --> 01:41:50,720
behaviour in the symmetric case for small value of alpha

1556
01:41:50,740 --> 01:41:51,620
we get

1557
01:41:51,640 --> 01:41:58,510
very much much pictures dominated by small times for large values of of about five

1558
01:41:58,570 --> 01:42:00,890
one point eight is this one here

1559
01:42:00,910 --> 01:42:06,860
you get something that is moving closer together and if you let alpha tend to

1560
01:42:06,870 --> 01:42:10,780
it is actually some sort of continuity that makes this

1561
01:42:10,800 --> 01:42:14,300
converge to true brownian motion again

1562
01:42:14,300 --> 01:42:15,590
so in the

1563
01:42:15,600 --> 01:42:20,700
there is another interesting class of of stable processes where you've only got

1564
01:42:20,700 --> 01:42:26,930
positive chance or only got negative jumps as the case may be is positive jumps

1565
01:42:28,370 --> 01:42:29,680
we've got

1566
01:42:29,700 --> 01:42:31,840
due to our compensation

1567
01:42:31,860 --> 01:42:36,870
rule for for between zero and one we were not compensating any so we are

1568
01:42:36,870 --> 01:42:41,780
really just adding jumps in this process and it dominated by

1569
01:42:41,800 --> 01:42:45,550
my big jumps as alpha moves across one

1570
01:42:45,570 --> 01:42:50,220
we can compensate and to compensate all jumps

1571
01:42:50,240 --> 01:42:53,510
and then we get to behavior that

1572
01:42:53,530 --> 01:42:54,680
but has

1573
01:42:54,680 --> 01:43:00,410
drifts downwards but in that infinite sense that have been been looking at an example

1574
01:43:00,410 --> 01:43:02,260
and upward jumps

1575
01:43:02,280 --> 01:43:08,430
again big jumps being being quite dominant here

1576
01:43:10,370 --> 01:43:16,510
and while this is this is what the stable processes that look like

1577
01:43:16,530 --> 01:43:17,780
OK so

1578
01:43:18,720 --> 01:43:21,530
modeling processes themselves

1579
01:43:21,550 --> 01:43:25,530
we can go further once you've got live processes

1580
01:43:25,530 --> 01:43:31,800
because they are semimartingales essentially we've got stochastic integration at our disposal we can look

1581
01:43:31,800 --> 01:43:33,010
at stochastic

1582
01:43:33,070 --> 01:43:38,820
integrals either of deterministic functions which means that we take these increments of the jump

1583
01:43:38,820 --> 01:43:43,450
sizes and according to when it happens it scaled

1584
01:43:43,490 --> 01:43:45,550
by that function f

1585
01:43:45,570 --> 01:43:51,280
all we have is stochastic process that sort of interacts with the randomness of of

1586
01:43:51,280 --> 01:43:55,370
our lady processes or has some additional randomness in it

1587
01:43:55,370 --> 01:44:00,080
what about skill and the string kernels in contrast to

1588
01:44:00,410 --> 01:44:07,000
talks to conclude this talk about class consisting comments we consider string kernels which are

1589
01:44:07,000 --> 01:44:08,090
linear in time

1590
01:44:08,150 --> 01:44:13,010
and we trying to look like linear in the length of the string not could

1591
01:44:13,010 --> 01:44:17,620
this as it was in that case are trying to speed up such kind

1592
01:44:22,820 --> 01:44:27,570
OK maybe have seen large scale text classification problems string

1593
01:44:27,590 --> 01:44:34,240
problems that appear like normal text classification spam spam categorisation and basically said is given

1594
01:44:34,320 --> 01:44:39,070
documents the classes plus minus one predict linked to

1595
01:44:39,140 --> 01:44:41,490
next time and

1596
01:44:41,500 --> 01:44:42,340
we have

1597
01:44:42,350 --> 01:44:48,600
then for security could be like like given connects executable predict whether executable is a

1598
01:44:48,600 --> 01:44:54,690
virus or not biology has the same thing actually i'm working on also of times

1599
01:44:54,690 --> 01:45:01,620
of splice sites or the start of the gene and you want to predict whether

1600
01:45:01,700 --> 01:45:05,450
in the centre of the sequence this is this splice site or not

1601
01:45:05,540 --> 01:45:11,400
OK so one possible approach is to use to to encourage and support vector machines

1602
01:45:11,430 --> 01:45:14,200
and it's

1603
01:45:14,200 --> 01:45:19,040
actually at least and pilot for example in this case the diffuser large number of

1604
01:45:19,040 --> 01:45:22,920
examples and you can really get like high accuracy

1605
01:45:22,930 --> 01:45:24,930
OK so from the giving

1606
01:45:25,340 --> 01:45:29,390
given his entry examples here string kernels

1607
01:45:29,510 --> 01:45:36,460
like like vote and the kernel k may be scholars like spectrum or to become

1608
01:45:36,480 --> 01:45:41,090
and you want to train a comin machine on on say ten million examples and

1609
01:45:41,090 --> 01:45:45,340
it was created being examples also being example

1610
01:45:45,390 --> 01:45:52,340
so all these incomes look like spectrum can be a computes columns of

1611
01:45:54,510 --> 01:45:56,680
strings of length k

1612
01:45:56,700 --> 01:46:04,710
and to use these consonants summed up for each sequence multiplied and

1613
01:46:05,400 --> 01:46:10,770
and ended up in the system design in cancer spectrum kernel you becomes quite some

1614
01:46:10,770 --> 01:46:16,590
simple then identifies matching blocks and between two sequences and the longer the match

1615
01:46:16,590 --> 01:46:19,250
the high school

1616
01:46:19,270 --> 01:46:22,800
the higher this weighted and this summed up and all good

1617
01:46:22,810 --> 01:46:30,180
the thing that three hundred seven comments the data there's usually a large discrete feature

1618
01:46:30,180 --> 01:46:32,530
space behind it

1619
01:46:32,560 --> 01:46:34,250
full stop

1620
01:46:34,300 --> 01:46:35,960
so in

1621
01:46:36,490 --> 01:46:40,340
and you can machine in situ

1622
01:46:40,360 --> 01:46:44,560
john all sorts of beta which

1623
01:46:44,590 --> 01:46:47,830
these are valid kernels

1624
01:46:48,190 --> 01:46:52,370
you're quite often have to compute outputs for all

1625
01:46:52,400 --> 01:47:00,310
four test examples so for example have to compute this linear combination of of kernels

1626
01:47:01,280 --> 01:47:03,240
therefore the effort is

1627
01:47:03,250 --> 01:47:06,030
the first thing to compute singer

1628
01:47:06,060 --> 01:47:14,080
the computer system of courts for is like and then this is the to the

1629
01:47:14,080 --> 01:47:17,120
number of states constitute

1630
01:47:17,330 --> 01:47:22,310
after coming in a linear combination and is the time to compute computer to current

1631
01:47:22,830 --> 01:47:25,530
so if you have to do it for all the examples it's an

1632
01:47:26,660 --> 01:47:27,940
twenty two

1633
01:47:28,060 --> 01:47:34,380
and that's all for training training is forbidden and t so it's quite quite closely

1634
01:47:37,780 --> 01:47:41,910
the problem is that this is used in training and testing

1635
01:47:41,930 --> 01:47:44,250
so it is actually worth tuning

1636
01:47:45,310 --> 01:47:51,860
just OK so what can we do it for computing the kernel is already because

1637
01:47:51,860 --> 01:47:54,970
i mean the first approach will be just to get the current tools don't in

1638
01:47:54,970 --> 01:47:58,120
any time and

1639
01:47:58,740 --> 01:47:59,970
and this

1640
01:47:59,990 --> 01:48:04,090
i mean it must psychology is actually

1641
01:48:04,150 --> 01:48:10,900
quite simple idea if you are combinations of components you rewrite

1642
01:48:10,900 --> 01:48:17,060
the lexicon is not productive the feature space and you basically just computers w explicitly

1643
01:48:17,060 --> 01:48:18,750
in computer product

1644
01:48:20,910 --> 01:48:23,810
this not it's not at all clear that this

1645
01:48:23,830 --> 01:48:27,760
should be faster than using the original

1646
01:48:27,790 --> 01:48:29,060
general approach

1647
01:48:32,930 --> 01:48:37,260
it can be in some cases so when is it possible it's possible that you

1648
01:48:37,290 --> 01:48:44,120
w has allowed mention entity like the and the string length which

1649
01:48:44,120 --> 01:48:46,020
they spend you know if you see god

1650
01:48:46,090 --> 01:48:50,060
four questions you get fifteen minutes take o five minutes to read the papers forty

1651
01:48:50,060 --> 01:48:54,660
five minutes has roughly ten eleven minutes for questions on the same question might be

1652
01:48:55,570 --> 01:48:59,410
so i spent ten minutes number one and sold against five minutes

1653
01:48:59,440 --> 01:49:01,980
five minutes fifteen minutes elegant steam

1654
01:49:01,990 --> 01:49:05,320
twenty minutes twenty minutes in exams to work on number one

1655
01:49:05,330 --> 01:49:08,430
and it really is to solve this was the last thing i do

1656
01:49:09,880 --> 01:49:12,810
fifty five comes this last thing to do

1657
01:49:12,870 --> 01:49:17,180
now think about the math let's do the math suppose suppose there's an epiphany

1658
01:49:19,110 --> 01:49:20,620
eleven fifty four

1659
01:49:20,660 --> 01:49:23,140
you get a perfect score in question

1660
01:49:23,200 --> 01:49:26,650
it's worth twenty five percent of the paper you get twenty five o twenty five

1661
01:49:27,990 --> 01:49:30,630
gets zero and rescue write anything

1662
01:49:30,670 --> 01:49:31,580
you see what i'm saying

1663
01:49:31,590 --> 01:49:33,770
trial the questions

1664
01:49:34,520 --> 01:49:35,530
and good luck

1665
01:49:35,530 --> 01:49:37,040
i mean it there's no

1666
01:49:37,090 --> 01:49:39,560
there's no attempt to deceive come prepared

1667
01:49:39,640 --> 01:49:43,090
well defined and our goal is to bring those things get back to you

1668
01:49:43,120 --> 01:49:45,910
the following day repertory

1669
01:49:45,960 --> 01:49:47,940
i will post model solutions

1670
01:49:48,000 --> 01:49:51,060
and will be different exam in the afternoon

1671
01:49:51,130 --> 01:49:54,390
but i think it only makes sense for you not to discuss the paper with

1672
01:49:54,400 --> 01:49:56,390
people that are taking the afternoon

1673
01:49:56,470 --> 01:49:57,820
trying to run

1674
01:49:57,860 --> 01:50:01,190
school here that has some standards if

1675
01:50:01,210 --> 01:50:03,360
professional standards

1676
01:50:04,260 --> 01:50:07,800
and there will be plenty of information the website

1677
01:50:07,810 --> 01:50:10,290
alright let's get out the lesson today

1678
01:50:10,330 --> 01:50:15,000
so just to refresh their memories last day we look at the average valence electron

1679
01:50:15,000 --> 01:50:19,780
energy is a measure of reactivity and en route we discovered that

1680
01:50:19,820 --> 01:50:26,140
we can divide the periodic table into metals and which is about seventy five percent

1681
01:50:26,140 --> 01:50:30,320
of the periodic table these have low average valence electron energies which means that

1682
01:50:30,410 --> 01:50:34,110
they're very good these elements are very good electron donors

1683
01:50:34,130 --> 01:50:36,230
and up on the other extreme

1684
01:50:36,280 --> 01:50:42,140
or elements with very high average valence electron energy these are electron acceptors they they

1685
01:50:42,150 --> 01:50:45,230
they cling to their life electrons quite

1686
01:50:46,960 --> 01:50:53,900
and subsequently look the photoelectron spectroscopy which is a technique that allows us to determine

1687
01:50:53,940 --> 01:50:58,530
binding energies ionisation energies being just one

1688
01:50:58,530 --> 01:51:02,270
example but we'll see later on the PS can give us other

1689
01:51:02,400 --> 01:51:07,530
important information can calculate and then towards the end of the lecture we started looking

1690
01:51:07,540 --> 01:51:13,530
at reactivity and we put up this hypothesis that our observation is that

1691
01:51:13,540 --> 01:51:15,490
octet stability

1692
01:51:15,520 --> 01:51:19,250
seems to be an attractive electron configurations so we saw the

1693
01:51:19,270 --> 01:51:22,660
noble gases and then we said you know you can you can also achieve octet

1694
01:51:23,870 --> 01:51:28,310
and electron transfer if you look at elements that are just a little bit

1695
01:51:29,310 --> 01:51:33,310
the of electrons verses octet stability or a little bit ly

1696
01:51:33,320 --> 01:51:34,620
of electrons

1697
01:51:34,630 --> 01:51:38,340
so we got to ionic bonding and i think we just got to the point

1698
01:51:38,340 --> 01:51:42,690
where able start looking at the energetic so that we are at the time so

1699
01:51:42,690 --> 01:51:45,950
i want to resume that i think i managed to get to this point here

1700
01:51:45,950 --> 01:51:48,330
i show what happens when

1701
01:51:48,410 --> 01:51:52,260
the cat here sodium is

1702
01:51:52,300 --> 01:51:57,650
in contact with the and here chlorine and we reason that these two eventually reach

1703
01:51:57,660 --> 01:52:02,890
some kind of an equilibrium separation which were using lower case are

1704
01:52:02,930 --> 01:52:07,030
to represent this is the separation measured from the centre of the

1705
01:52:07,040 --> 01:52:12,760
sodium nucleus and there's this separation which is the balance of attractive forces because the

1706
01:52:12,760 --> 01:52:17,750
chloride is net negative and the sodium is not positive but both of them

1707
01:52:17,770 --> 01:52:20,280
regardless of net charge have

1708
01:52:22,010 --> 01:52:22,840
and so

1709
01:52:22,890 --> 01:52:24,870
when they become very very close

1710
01:52:24,880 --> 01:52:26,010
we spaced

1711
01:52:26,020 --> 01:52:28,800
there's mutual repulsion of those electrons

1712
01:52:28,840 --> 01:52:31,460
and so there's the repulsive term here

1713
01:52:31,540 --> 01:52:36,110
and so the balance of the attractive term and the repulsive term eventually

1714
01:52:36,170 --> 01:52:38,360
leads to to the situation where

1715
01:52:38,370 --> 01:52:44,510
we have the the equilibrium spacing this equilibrium spacing is denoted are sub-zero or are

1716
01:52:45,630 --> 01:52:48,880
and are not really is nothing more than the sum of

1717
01:52:48,890 --> 01:52:54,280
the radius the ionic radius of sodium and the ionic radius of chloride so that

1718
01:52:54,280 --> 01:52:56,060
we can just say are plus

1719
01:52:56,120 --> 01:52:58,910
plus or minus gives you are not

1720
01:52:58,990 --> 01:53:03,420
and writer right off the bat you notice that i'm making a huge assumption here

1721
01:53:03,420 --> 01:53:06,440
i'm modeling the ions as hard spheres

1722
01:53:06,480 --> 01:53:08,290
modeling was billiard balls

1723
01:53:08,290 --> 01:53:10,990
finite dimension

1724
01:53:11,000 --> 01:53:12,010
and so they

1725
01:53:13,050 --> 01:53:15,140
reached this equilibrium position

1726
01:53:15,150 --> 01:53:18,760
and we saw last thing we have the coulomb force of attraction which we've seen

1727
01:53:19,690 --> 01:53:23,700
carolinas plus one airliners minus one but it doesn't have to be this could be

1728
01:53:24,910 --> 01:53:28,070
magnesium would be two plus so here you put to

1729
01:53:28,120 --> 01:53:32,200
or i could have an oxide here so i would put minus two e in

1730
01:53:32,200 --> 01:53:34,060
this case we just have one one

1731
01:53:34,120 --> 01:53:40,340
and the repulsive term some positive coefficient and are two very high number and lies

1732
01:53:40,340 --> 01:53:43,830
between six and twelve and this is known as the born

1733
01:53:43,830 --> 01:53:44,660
help at all

1734
01:53:44,710 --> 01:53:46,590
if it's one one zero

1735
01:53:46,600 --> 01:53:50,560
then we can complement that said think get zero zero one

1736
01:53:50,570 --> 01:53:51,510
so it says that

1737
01:53:51,530 --> 01:53:53,360
everybody problem

1738
01:53:53,420 --> 01:53:54,830
on three labels

1739
01:53:54,960 --> 01:53:57,580
every code on three labels

1740
01:53:57,590 --> 01:53:58,820
these are being

1741
01:53:58,830 --> 01:54:00,810
should a weighted sum

1742
01:54:03,620 --> 01:54:07,340
choices you

1743
01:54:07,350 --> 01:54:09,950
OK so this is a weighted sum of the three choices

1744
01:54:10,000 --> 01:54:10,820
and then

1745
01:54:11,050 --> 01:54:13,950
if it's the case that

1746
01:54:14,000 --> 01:54:15,930
the probability of two

1747
01:54:15,940 --> 01:54:17,430
given x

1748
01:54:17,440 --> 01:54:18,380
it is

1749
01:54:18,390 --> 01:54:20,130
o point four five

1750
01:54:20,170 --> 01:54:24,660
the probability of three different x is

1751
01:54:24,670 --> 01:54:26,730
o point two five

1752
01:54:26,780 --> 01:54:31,900
and the probability of four given x is point three

1753
01:54:31,950 --> 01:54:34,110
and the correct binding prediction

1754
01:54:34,160 --> 01:54:35,250
each of these

1755
01:54:35,340 --> 01:54:37,210
classifiers is zero

1756
01:54:38,690 --> 01:54:39,910
the probability that

1757
01:54:39,920 --> 01:54:42,240
the labels in the set is zero

1758
01:54:42,250 --> 01:54:46,190
to get zeros everywhere you get this

1759
01:54:46,240 --> 01:54:47,280
and then

1760
01:54:47,330 --> 01:54:50,210
you just random

1761
01:54:50,260 --> 01:54:52,300
or maybe the the weighted sum

1762
01:54:52,310 --> 01:54:54,290
i mean you have to pick out

1763
01:54:54,350 --> 01:54:55,840
you pick out one of these

1764
01:54:55,890 --> 01:54:57,490
but but the point is that

1765
01:54:57,500 --> 01:54:59,630
this snake is arbitrary

1766
01:54:59,680 --> 01:55:02,950
because the choice because arbitrary you can have this distribution

1767
01:55:02,960 --> 01:55:06,050
concept between different possibilities

1768
01:55:06,230 --> 01:55:10,960
in such a way that the classifiers can take it out

1769
01:55:11,190 --> 01:55:19,050
OK so if see there are very motivational

1770
01:55:19,060 --> 01:55:21,270
but they have a small problem

1771
01:55:21,280 --> 01:55:23,580
and now i'll tell you

1772
01:55:23,630 --> 01:55:25,250
how to fix the problem

1773
01:55:25,260 --> 01:55:29,780
there is a way to fix the problem

1774
01:55:29,830 --> 01:55:32,220
the fix is to use

1775
01:55:32,270 --> 01:55:35,470
or just talked about this this probing technique

1776
01:55:35,510 --> 01:55:39,300
so in particular

1777
01:55:39,510 --> 01:55:41,430
make probabilistic predictions

1778
01:55:41,510 --> 01:55:44,080
rather than making money predictions

1779
01:55:44,130 --> 01:55:46,340
and then instead of decoding with

1780
01:55:46,770 --> 01:55:48,600
hamming distance

1781
01:55:48,610 --> 01:55:51,580
just trying to get the right numbers of ones and zeros

1782
01:55:51,590 --> 01:55:54,490
and the because l one distance

1783
01:55:54,540 --> 01:55:58,200
and if you don't know what i want is insistent to another idea

1784
01:55:58,220 --> 01:56:01,290
so if we get these predictions

1785
01:56:05,140 --> 01:56:09,350
these these probabilistic predictions for these binary problems here

1786
01:56:09,400 --> 01:56:10,540
there in

1787
01:56:10,550 --> 01:56:11,980
the distance

1788
01:56:12,800 --> 01:56:18,290
i guess on which would imply that you know people will always point nine one

1789
01:56:18,970 --> 01:56:21,340
zero nine away from that

1790
01:56:22,000 --> 01:56:23,550
o point four five way from

1791
01:56:23,600 --> 01:56:24,890
o point five four way

1792
01:56:24,900 --> 01:56:25,930
you sum it up

1793
01:56:26,080 --> 01:56:28,120
one point zero it

1794
01:56:28,140 --> 01:56:29,700
you this region

1795
01:56:29,780 --> 01:56:31,250
in arms

1796
01:56:31,300 --> 01:56:33,430
and you get different numbers

1797
01:56:33,470 --> 01:56:58,460
and you take the minimum

1798
01:56:58,470 --> 01:57:00,200
the claim is

1799
01:57:00,290 --> 01:57:02,610
this fixes the problem

1800
01:57:02,710 --> 01:57:05,030
the small we can you see

1801
01:57:05,080 --> 01:57:07,910
that's the problem theoretically

1802
01:57:08,150 --> 01:57:14,540
does it turns out to work

1803
01:57:14,560 --> 01:57:17,730
so once again we have the most datasets

1804
01:57:17,740 --> 01:57:19,190
in the

1805
01:57:19,200 --> 01:57:21,220
and we use a hadamard

1806
01:57:21,230 --> 01:57:24,540
matrix recurred of see with that is later

1807
01:57:24,620 --> 01:57:25,790
and you can compare

1808
01:57:25,800 --> 01:57:28,290
ECOC test aerated

1809
01:57:29,590 --> 01:57:32,560
creating output code test error rate

1810
01:57:32,660 --> 01:57:36,850
and cesarean accuracy which means small is good which means that

1811
01:57:36,860 --> 01:57:39,880
things will line implies that this is winning

1812
01:57:39,930 --> 01:57:43,940
and you see that for a support vector machine and decision tree

1813
01:57:43,960 --> 01:57:47,980
in logistic regression

1814
01:57:47,990 --> 01:57:51,300
to problems getting up because winning

1815
01:57:51,380 --> 01:57:53,320
on whole dataset

1816
01:58:04,850 --> 01:58:08,240
OK so let's go back here for a minute

1817
01:58:08,250 --> 01:58:12,130
some of them is clear clearing we're it's just like you see

1818
01:58:12,140 --> 01:58:16,210
we have a bunch of binary problems except now make probabilistic predictions

1819
01:58:16,320 --> 01:58:17,770
and we decode with

1820
01:58:17,780 --> 01:58:20,140
l one loss

1821
01:58:20,270 --> 01:58:30,480
with the code to define the smallest l one distance label

1822
01:58:33,020 --> 01:58:34,930
kind of works

1823
01:58:36,390 --> 01:58:40,060
and now we want to analyse it

1824
01:58:40,110 --> 01:58:42,720
so we're going use this one classifier trick again

1825
01:58:42,760 --> 01:58:44,420
we're going to embed

1826
01:58:44,440 --> 01:58:47,930
the choice of the subsets and the probability

1827
01:58:47,940 --> 01:58:54,950
into the name of classifier

1828
01:58:55,000 --> 01:58:56,440
so it's

1829
01:58:56,490 --> 01:58:58,750
so what i have what i said

1830
01:59:00,090 --> 01:59:01,610
well defined

1831
01:59:01,620 --> 01:59:05,190
the different probabilistic predictions for different subsets

1832
01:59:05,210 --> 01:59:09,940
just like that for that

1833
01:59:10,000 --> 01:59:12,310
and that this

1834
01:59:12,320 --> 01:59:15,310
peacock peacock peacock

1835
01:59:15,720 --> 01:59:16,980
these are men

1836
01:59:16,990 --> 01:59:19,850
b the distribution induced

1837
01:59:19,900 --> 01:59:23,790
on the binary classifier

1838
01:59:23,840 --> 01:59:27,650
and then we have this peacock transformed

1839
01:59:27,710 --> 01:59:28,820
it says that

1840
01:59:28,880 --> 01:59:31,480
for every number multi class labels

1841
01:59:31,490 --> 01:59:33,630
it the kernel that

1842
01:59:33,640 --> 01:59:35,940
for every classifier

1843
01:59:37,320 --> 01:59:42,660
for every multicast distribution for everybody has every multiclass distribution

1844
01:59:44,550 --> 01:59:45,650
the multiclass

1845
01:59:47,140 --> 01:59:50,540
minus the minimum multiclass rate

1846
01:59:50,560 --> 01:59:52,400
o is bounded by

1847
01:59:52,400 --> 01:59:53,820
four times

1848
01:59:53,880 --> 01:59:55,570
the square root of

1849
01:59:55,590 --> 01:59:58,590
the binary error rate minus the minimum

1850
01:59:58,630 --> 02:00:06,040
plain binary here it

1851
02:00:06,050 --> 02:00:08,800
discouraged by the way is not that great

1852
02:00:10,420 --> 02:00:11,720
score makes it worse

1853
02:00:11,720 --> 02:00:19,030
from the gaussians distribution minus one half log of the determinant of this negative hessian

1854
02:00:22,150 --> 02:00:27,160
this term in blue is called the lab class approximation for this

1855
02:00:30,080 --> 02:00:36,900
and it involves finding the MAP estimates of the parameters computing these quantities

1856
02:00:36,950 --> 02:00:41,800
from those MAP estimates than trying to compute the

1857
02:00:41,890 --> 02:00:45,010
second derivative of the log marginal likelihood

1858
02:00:45,020 --> 02:00:48,460
this article log

1859
02:00:48,470 --> 02:00:50,950
posterior with respect to the parameters

1860
02:00:50,970 --> 02:00:53,960
in computing the determinant of the matrix here

1861
02:00:54,010 --> 02:00:55,530
OK that's an equation

1862
02:00:55,590 --> 02:01:01,280
so we can use to evaluate this very complicated high dimensional integrals in general

1863
02:01:02,530 --> 02:01:07,480
and this can be used for model comparison selection is a very classical method

1864
02:01:07,870 --> 02:01:11,620
the people use

1865
02:01:11,650 --> 02:01:15,470
the problem with that method is that if you have a very big parameter space

1866
02:01:15,470 --> 02:01:20,720
of these very large computing the hessian and computing the determinant of the hessian can

1867
02:01:20,720 --> 02:01:28,510
be quite costly so much cheaper approximation is called the bayes information or BIC criterion

1868
02:01:28,520 --> 02:01:31,820
and we start from the class approximation

1869
02:01:31,860 --> 02:01:32,890
and we

1870
02:01:34,160 --> 02:01:37,660
the large sample limit as n goes to infinity

1871
02:01:39,120 --> 02:01:42,300
we draw any term that does not grow

1872
02:01:42,320 --> 02:01:44,790
with and

1873
02:01:44,800 --> 02:01:49,910
and what we get is that this term drops and this term drop because they

1874
02:01:49,910 --> 02:01:52,980
don't grow with and and this term here

1875
02:01:53,010 --> 02:01:55,490
the longer the term and this matrix

1876
02:01:55,510 --> 02:01:57,390
it grows with n

1877
02:01:58,870 --> 02:02:02,350
the over two log n

1878
02:02:02,400 --> 02:02:05,700
OK i want to show you how that happens but this is pretty easy to

1879
02:02:05,700 --> 02:02:07,040
to show that

1880
02:02:07,070 --> 02:02:09,510
so essentially the BIC

1881
02:02:09,520 --> 02:02:12,830
criterion is simply the log likelihood

1882
02:02:14,600 --> 02:02:17,180
number of parameters divided by two

1883
02:02:17,210 --> 02:02:22,210
log of the number of data points so it's incredibly cheap to compute and this

1884
02:02:22,210 --> 02:02:27,120
is the easiest way to penalize a model for the number of parameters that has

1885
02:02:27,180 --> 02:02:30,910
an we've shown that it can be derived by these two steps from the marginal

1886
02:02:39,570 --> 02:02:41,300
nice way to

1887
02:02:41,330 --> 02:02:44,490
lower bound the marginal likelihood is given by

1888
02:02:44,520 --> 02:02:48,590
these variational bayesian methods which we work on lot

1889
02:02:49,290 --> 02:02:54,530
imagine we now have the model with some latent or hidden variables x some observed

1890
02:02:54,530 --> 02:02:55,730
variables y

1891
02:02:55,780 --> 02:02:58,210
and some parameters theta

1892
02:02:58,260 --> 02:03:01,910
we can lower bound the marginal likelihood in the same way as i showed you

1893
02:03:01,910 --> 02:03:08,220
before you and using jensen's inequality so the log of the marginal likelihood

1894
02:03:08,230 --> 02:03:10,330
is the log of the integral

1895
02:03:10,350 --> 02:03:13,150
of this joint probability here

1896
02:03:13,180 --> 02:03:17,200
we take each term in that integral we multiply and divide it by

1897
02:03:17,210 --> 02:03:23,430
some arbitrary distribution over the hidden variables and parameters

1898
02:03:23,450 --> 02:03:25,440
and then we say

1899
02:03:25,710 --> 02:03:29,680
we we notice that the log of the average

1900
02:03:29,690 --> 02:03:36,760
this ratio is greater lies that lower bound with respect to that family of distributions

1901
02:03:38,480 --> 02:03:41,950
so even though we cannot compute this guy

1902
02:03:41,990 --> 02:03:44,520
tractably are analytically

1903
02:03:44,540 --> 02:03:48,650
we can often compute this lower bound tractably analytically

1904
02:03:48,710 --> 02:03:53,380
and in particular kind of approximation we can use is too

1905
02:03:55,380 --> 02:03:59,000
that the distribution over the hidden variables and parameters

1906
02:03:59,010 --> 02:04:02,740
assume that the factors

1907
02:04:02,750 --> 02:04:08,310
as a distribution over hidden variables times the distribution over parameters

1908
02:04:09,870 --> 02:04:14,050
so then we have a lower bound on the log marginal likelihood which is the

1909
02:04:14,070 --> 02:04:18,560
functional of this distribution over the hidden variables the distribution of the parameters and the

1910
02:04:20,700 --> 02:04:28,390
so we can maximize this lower bound

1911
02:04:28,420 --> 02:04:30,760
in in in like manner

1912
02:04:32,850 --> 02:04:36,800
optimizing the distribution over the hidden variables

1913
02:04:36,820 --> 02:04:39,920
holding the distribution of the parameters fixed

1914
02:04:39,930 --> 02:04:43,830
and that generally is this is given by this equation

1915
02:04:43,840 --> 02:04:50,430
that kind of like the e step of the EM here in the m step

1916
02:04:50,450 --> 02:04:55,680
we optimize with respect to the distribution over the parameters holding the distribution over the

1917
02:04:55,680 --> 02:04:57,380
hidden variables fixed

1918
02:04:57,390 --> 02:05:01,210
maximizing this lower bound is equivalent to

1919
02:05:01,220 --> 02:05:04,770
minimizing the kullback leibler divergence

1920
02:05:05,840 --> 02:05:07,260
which measures

1921
02:05:07,270 --> 02:05:11,750
in a sense the distance between the approximate posterior

1922
02:05:12,090 --> 02:05:17,600
given here and the true posterior which we can compute tractably

1923
02:05:17,650 --> 02:05:22,300
and this is the expression for that KL divergence

1924
02:05:22,310 --> 02:05:24,810
which is the difference between the

1925
02:05:26,760 --> 02:05:35,440
log marginal likelihood and this lower bound on the log marginal likelihood

1926
02:05:36,320 --> 02:05:38,770
and here is simply a comparison

1927
02:05:38,800 --> 02:05:41,540
of the classical algorithms

1928
02:05:41,560 --> 02:05:43,500
for parameter estimation

1929
02:05:43,520 --> 02:05:47,450
and this variational bayesian in algorithm

1930
02:05:50,120 --> 02:05:51,550
it it looks

1931
02:05:51,570 --> 02:05:53,110
very similar

1932
02:05:53,130 --> 02:05:57,810
so in the e step we compute the distribution over the hidden variables

1933
02:05:57,890 --> 02:06:00,210
that's the inference that

1934
02:06:00,250 --> 02:06:03,450
for graphical model this would involve some sort of

1935
02:06:03,460 --> 02:06:05,610
belief propagation or

1936
02:06:05,670 --> 02:06:07,010
junction tree

1937
02:06:07,020 --> 02:06:09,210
called in here

1938
02:06:09,590 --> 02:06:12,190
in the variational bayesian e step

1939
02:06:12,210 --> 02:06:18,570
we also compute distribution over the hidden variables except we use the different setting of

1940
02:06:18,580 --> 02:06:24,640
the parameters these are parameters average with respect to the distribution of the parameters the

1941
02:06:24,640 --> 02:06:29,800
main difference between the two methods is that whereas the classical is simply trying to

1942
02:06:29,800 --> 02:06:34,200
find a point estimate a single value of the parameters of the model

1943
02:06:34,250 --> 02:06:37,520
this variational bayesian the is trying to find the whole

1944
02:06:37,550 --> 02:06:41,920
distribution over the parameters of the model because it's trying to

1945
02:06:44,010 --> 02:06:45,990
that distribution


1
00:00:00,000 --> 00:00:03,840
i am that's a picture that is very similar to what i just made on the blackboard

2
00:00:04,750 --> 00:00:06,270
so you can digest that again

3
00:00:07,050 --> 00:00:08,050
you see here the year and

4
00:00:08,920 --> 00:00:13,420
a person standing in this direction from the sun here's shadow would be very long

5
00:00:13,420 --> 00:00:15,340
you shadow all the way up to this point is

6
00:00:16,440 --> 00:00:16,980
i would be

7
00:00:18,090 --> 00:00:19,900
and then you see this raindrop

8
00:00:20,730 --> 00:00:25,400
just at the right direction forty two degrees away from this line this raindrop will be read

9
00:00:26,690 --> 00:00:27,460
this raindrop

10
00:00:28,710 --> 00:00:32,250
begins to be white maybe a little the blue site forty two degrees

11
00:00:33,610 --> 00:00:35,500
i was not the first one to make this a

12
00:00:37,750 --> 00:00:40,020
note himself was the first to understand

13
00:00:41,360 --> 00:00:41,920
the rainbows

14
00:00:42,710 --> 00:00:44,520
this is his own picture in the book of figure

15
00:00:46,000 --> 00:00:46,550
you see here

16
00:00:47,150 --> 00:00:47,730
the primary bow

17
00:00:49,590 --> 00:00:54,770
notice the light comes in from the sun penetrates the water drop reflects in the back and comes out

18
00:00:56,230 --> 00:00:57,300
this will be pure red

19
00:00:58,400 --> 00:01:01,000
and this one could be read but it can also be blue

20
00:01:01,710 --> 00:01:02,880
and we'll call it in here

21
00:01:03,770 --> 00:01:05,610
would be white light and this is secondary

22
00:01:07,050 --> 00:01:10,230
secondary allows for an extra reflection inside the raindrop

23
00:01:11,020 --> 00:01:12,000
next reflections

24
00:01:13,270 --> 00:01:14,710
reflection one reflection to

25
00:01:17,090 --> 00:01:19,050
and they give you the secondary and the colour sequences

26
00:01:21,670 --> 00:01:23,750
so you can make a rainbow didn't circles here

27
00:01:24,750 --> 00:01:25,360
your whole body

28
00:01:25,820 --> 00:01:26,820
fun great fun

29
00:01:27,750 --> 00:01:29,250
i do that often when i s

30
00:01:31,780 --> 00:01:32,750
the sun is high in the sky

31
00:01:33,820 --> 00:01:36,690
you just put one all around you it's a great feeling of power

32
00:01:38,730 --> 00:01:41,520
you all the way around the radio readily outside

33
00:01:43,250 --> 00:01:47,130
you see some white light together here the u of course have to produce white

34
00:01:47,570 --> 00:01:48,250
you have to produce

35
00:01:48,900 --> 00:01:51,570
really everywhere here let's say what about

36
00:01:52,130 --> 00:01:53,070
you don't have a lot of

37
00:01:57,020 --> 00:01:58,020
well this is a painting

38
00:01:58,590 --> 00:02:00,650
from the eighth century thirteen

39
00:02:02,090 --> 00:02:05,050
in the bible it says i do set my bow in the cloud

40
00:02:07,570 --> 00:02:09,340
there's something wrong with this picture

41
00:02:10,500 --> 00:02:12,250
i call a sequence isn't quite right

42
00:02:13,000 --> 00:02:15,190
so as possibilities reaction

43
00:02:15,630 --> 00:02:16,920
you physics of different

44
00:02:17,150 --> 00:02:17,920
eight centuries

45
00:02:20,460 --> 00:02:21,130
what paper

46
00:02:21,650 --> 00:02:22,270
made a mistake

47
00:02:23,090 --> 00:02:24,750
all the pain that is very purpose

48
00:02:25,750 --> 00:02:27,070
but we will always be possible

49
00:02:28,520 --> 00:02:30,040
we will never know a wonderful thing

50
00:02:35,770 --> 00:02:37,150
you can of

51
00:02:38,900 --> 00:02:40,610
and you can apply the ball

52
00:02:41,540 --> 00:02:43,300
he said well at time seven

53
00:02:44,190 --> 00:02:46,630
and this is why we need to act shower

54
00:02:47,250 --> 00:02:51,250
after the color in a rainbow i never see a rainbow and i take a shower with that

55
00:02:57,270 --> 00:02:58,520
but they say it's a random

56
00:02:59,770 --> 00:03:00,360
the robot

57
00:03:01,550 --> 00:03:03,480
but colors and not quite right

58
00:03:04,540 --> 00:03:07,500
read globally outside luzon on the inside it's a fake

59
00:03:09,690 --> 00:03:11,400
well know when you buy something

60
00:03:12,820 --> 00:03:13,610
the not

61
00:03:14,270 --> 00:03:15,070
she cause

62
00:03:16,380 --> 00:03:17,250
that's not slow

63
00:03:20,190 --> 00:03:20,940
this is a reasonable

64
00:03:23,320 --> 00:03:24,110
when which

65
00:03:26,420 --> 00:03:28,730
at my door this spring water

66
00:03:29,460 --> 00:03:30,320
from a garden hose

67
00:03:31,500 --> 00:03:32,210
you here

68
00:03:33,070 --> 00:03:34,380
so this behind me

69
00:03:35,420 --> 00:03:37,840
you see all the features that we have discussed now

70
00:03:38,710 --> 00:03:40,480
readily outside and inside

71
00:03:41,040 --> 00:03:41,780
you see the white light

72
00:03:42,380 --> 00:03:43,320
you may always have missed

73
00:03:44,170 --> 00:03:45,210
and when you here

74
00:03:46,300 --> 00:03:48,090
of course there is also water here

75
00:03:48,880 --> 00:03:50,650
but no light comes back from these drops

76
00:03:54,110 --> 00:03:55,570
this was not without problems

77
00:03:56,250 --> 00:04:00,550
was generally freezing cold i

78
00:04:10,360 --> 00:04:11,040
who am i

79
00:04:12,480 --> 00:04:13,770
let's face you want

80
00:04:15,610 --> 00:04:17,020
you see around the outside the

81
00:04:17,590 --> 00:04:19,480
the only only time that

82
00:04:20,020 --> 00:04:21,380
so from so far

83
00:04:25,800 --> 00:04:27,150
agenda is going to give

84
00:04:27,630 --> 00:04:30,460
back to the nineteen eighty three which is the physics of waves

85
00:04:30,920 --> 00:04:31,670
and i really need

86
00:04:32,500 --> 00:04:33,840
right rainbow is

87
00:04:34,210 --> 00:04:34,420
the do

88
00:04:35,940 --> 00:04:38,750
the second of senior secondary very faint

89
00:04:39,750 --> 00:04:42,630
but i don't want to also make a second secondary home

90
00:04:43,210 --> 00:04:46,110
and i succeeded going over my driveway is very dark

91
00:04:48,730 --> 00:04:50,730
driveways and final is easy to make

92
00:04:50,730 --> 00:04:56,010
it so if we have a feature map of this kernel the basic kernel that

93
00:04:56,010 --> 00:05:03,690
compares elements of X then we can construct a kernel on these sets by summing

94
00:05:03,690 --> 00:05:07,510
over so we can construct the feature map for the sets by summing over all these other

95
00:05:07,510 --> 00:05:11,950
feature maps and and it turns out if you do that you will end up

96
00:05:11,950 --> 00:05:16,110
with this kernel so so please try these two things and I will shut up

97
00:05:16,110 --> 00:05:24,510
for a few minutes  so yeah so so I mean another way is

98
00:05:24,520 --> 00:05:28,810
basically the same would be just to to write down the condition that we

99
00:05:28,810 --> 00:05:41,890
want to check so we want to see whether this thing is non-negative right this

100
00:05:41,890 --> 00:05:47,350
is our definition of our function K we don't know yet if it's positive definite

101
00:05:47,350 --> 00:05:52,210
now we use the fact that this is a dot product dot products are linear

102
00:05:52,310 --> 00:05:58,150
so we can take these scalars these factors inside the dot product we can also take the

103
00:05:58,150 --> 00:06:02,310
sums inside to be more specific we have two sums one over I one

104
00:06:02,320 --> 00:06:07,270
over J so we'll take the sum over I in here and the A I in here and we'll

105
00:06:07,270 --> 00:06:17,330
take the sum over J in here along with the A J so we have the sum over

106
00:06:17,710 --> 00:06:37,330
I here and we have the sum over J here okay and now we can see just like before in the argument

107
00:06:37,510 --> 00:06:41,190
this is a certain vector call it  V and this is actually the same

108
00:06:41,190 --> 00:06:44,770
vector and the only thing that's different is the name of the index doesn't

109
00:06:44,770 --> 00:06:52,190
matter so it's a dot product of V with V and dot products are positive definite

110
00:06:52,190 --> 00:07:02,450
meaning so they cannot give you negative values so this is non-negative okay so that

111
00:07:02,450 --> 00:07:09,070
was the first  problem shall  we take a look at the second problem so any

112
00:07:09,070 --> 00:07:28,390
anyone has an idea how to solve the second problem you can you can earn a point

113
00:07:28,390 --> 00:07:32,450
okay I'll do the second one if you collective me promise me  that the next on

114
00:07:32,450 --> 00:07:39,990
the next slide you will solve the other problems for me okay so

115
00:07:39,990 --> 00:07:48,570
second one let's take look at this so I had this hint written down there  so

116
00:07:48,570 --> 00:08:04,190
my hint was use this feature map  so we start with phi which is a

117
00:08:04,200 --> 00:08:10,470
mapping it takes inputs from X and maps them into a dot product space H from that

118
00:08:10,730 --> 00:08:17,570
we define a mapping phi tilde which takes its inputs subsets of the domain so

119
00:08:17,570 --> 00:08:23,350
let's yeah let's say finite subsets for simplicity and as output again vectors in that

120
00:08:23,390 --> 00:08:27,130
vector space H because some of such vectors is again such a vector so it's

121
00:08:27,130 --> 00:08:33,850
mapping into the same feature space and let's do this for two sets so

122
00:08:33,850 --> 00:08:45,810
let's take phi tilde of A and then a dot product with phi tilde of B

123
00:08:45,810 --> 00:08:54,210
now if you remember from the first problem that we just solved so the first problem was

124
00:08:54,210 --> 00:08:59,710
telling us I deleted it with the laser pointer the first problem was telling

125
00:08:59,710 --> 00:09:08,290
us it's gone  whenever we take some mapping of some input domain into a

126
00:09:08,290 --> 00:09:12,310
dot product space and we compute the  dot product after this mapping  we get a

127
00:09:12,320 --> 00:09:18,020
positive definite kernel so now I'm saying let's take a different kind of mapping this time I take a

128
00:09:18,030 --> 00:09:23,730
a mapping from a set of sets  also mapping from sets into some do prod

129
00:09:23,970 --> 00:09:31,110
prod product dot products space  if I then construct this thing here by construction or by this first

130
00:09:31,110 --> 00:09:35,990
result I get a positive definite kernel okay so  I just have to compute this thing

131
00:09:35,990 --> 00:09:38,850
I get a positive definite kernel actually and it will turn out to be the

132
00:09:38,870 --> 00:10:05,250
kernel that's written up there okay so let me substitute here's where I have

133
00:10:05,250 --> 00:10:11,050
substituted phi tilde of A is defined here and and do the sign same for B only

134
00:10:11,050 --> 00:10:15,650
I use a different name for the index so I don't get confused now

135
00:10:15,650 --> 00:10:19,970
again I can use the fact that this is a dot product so I can use

136
00:10:20,050 --> 00:10:24,350
the fact that it's linear so if you don't remember the produ properties of dot products maybe

137
00:10:24,350 --> 00:10:30,470
it's good to remind yourself maybe check on Wikipedia or mathworld or somewhere I

138
00:10:30,470 --> 00:10:35,290
am kind of assuming you know what is a dot product so if if you use this

139
00:10:35,290 --> 00:10:48,680
you can take these sums you can take the sums inside or outside okay

140
00:10:48,680 --> 00:10:58,730
and then inside what you're left with is this and this okay and I think you all recognize

141
00:10:58,730 --> 00:11:09,830
what is this that's our original kernel so so K is a kernel directly on

142
00:11:09,830 --> 00:11:16,410
the Xs and from this we can construct a kernel so let's call this this

143
00:11:16,410 --> 00:11:27,510
is our kernel on sets of Xs so that's one operation already how to construct more

144
00:11:27,510 --> 00:11:34,370
complicated kernels from simpler kernels if you want by construction it's a positive  definite kernel

145
00:11:34,410 --> 00:11:41,570
so taking a feature map explicitly and making a dot product is one way to construct a

146
00:11:41,580 --> 00:11:45,350
kernel and sometimes if you do it you end up with a kernel that's more

147
00:11:45,350 --> 00:11:50,730
efficiently to compute and explicitly doing the feature map but of course you could also always

148
00:11:50,730 --> 00:11:56,670
explicitly do the feature map if it's not too expensive okay so any questions

149
00:11:56,670 --> 00:12:01,870
so far so if I if I go too slowly you have to tell me like like you

150
00:12:01,870 --> 00:12:05,590
to throw something I told by the way I told Jan before the last lecture to throw something

151
00:12:05,590 --> 00:12:10,390
at me if I'm too slow and I asked him during the break I said you didn't throw anything at me he said well

152
00:12:10,720 --> 00:12:20,470
I fell asleep so if it's okay throw before you fall asleep okay so

153
00:12:20,470 --> 00:12:25,370
here we have some more properties and this will be important because we will use

154
00:12:25,410 --> 00:12:32,270
several of them to construct the feature space of a kernel so to prove the

155
00:12:32,270 --> 00:12:36,590
second part in our even only ifs ifs statement I told you before that if

156
00:12:36,590 --> 00:12:41,150
and only if a kernel is positive definite it has a representation as a dot  product so now on

157
00:12:41,150 --> 00:12:46,510
the last slide we showed that if it has a representation as a dot product it's positive

158
00:12:46,510 --> 00:12:50,950
definite but we now have to show if it's positive definite it has a representation

159
00:12:50,950 --> 00:12:51,910
you don't need to discard

160
00:12:52,480 --> 00:12:56,640
bayesian models altogether and migrate altogether too busy nonparametrics

161
00:12:57,830 --> 00:13:00,310
but basically all it's telling you is

162
00:13:01,260 --> 00:13:05,080
it finds a bimodal distribution because that's all it can do

163
00:13:06,460 --> 00:13:08,540
but there's has a high uncertainty

164
00:13:10,290 --> 00:13:12,750
so it's our guide self guards u

165
00:13:13,760 --> 00:13:18,780
by saying well i'm very uncertain about what's going on here but it still gives you the model

166
00:13:19,830 --> 00:13:21,140
this too much only

167
00:13:22,300 --> 00:13:23,700
okay this is

168
00:13:24,290 --> 00:13:26,010
now the samples from the prior

169
00:13:26,830 --> 00:13:27,980
additional process case

170
00:13:28,410 --> 00:13:33,390
so it is a process with conjugate base distribution which is discussed in distributed

171
00:13:34,700 --> 00:13:37,280
and this is the fit to the data

172
00:13:37,870 --> 00:13:41,380
this generated from two gases is expected to have these

173
00:13:42,270 --> 00:13:42,860
two peaks

174
00:13:44,520 --> 00:13:45,560
and this is

175
00:13:46,160 --> 00:13:48,290
data generated from foegaussian

176
00:13:48,930 --> 00:13:52,790
and now you have three peaks so this shouldn't be surprising because

177
00:13:53,560 --> 00:13:54,180
we know that

178
00:13:54,580 --> 00:13:57,120
the bishop process is going to fit to

179
00:13:57,510 --> 00:13:57,930
the data

180
00:13:58,360 --> 00:13:59,490
and it's going to use

181
00:14:00,920 --> 00:14:03,070
the necessary amount of components

182
00:14:03,500 --> 00:14:06,410
to be able to have a good representation of data

183
00:14:11,020 --> 00:14:14,030
you can see things like this for example there are peaks

184
00:14:14,850 --> 00:14:17,340
if we sample from the posterior there are peaks at

185
00:14:17,860 --> 00:14:20,610
places where there is not any data at all

186
00:14:21,020 --> 00:14:23,740
so that that's counts because

187
00:14:24,410 --> 00:14:26,980
the the process still give some probability

188
00:14:28,610 --> 00:14:33,340
other places than it so that it so you may see this as an advantage

189
00:14:33,340 --> 00:14:38,350
or a disadvantage if you believe that's when your data is only what you saw

190
00:14:38,390 --> 00:14:40,270
and there will be no further

191
00:14:40,730 --> 00:14:44,930
data lying outside of the region that you observe data before then

192
00:14:45,340 --> 00:14:47,660
maybe this is something to worry about then maybe

193
00:14:48,300 --> 00:14:51,720
actually this is a model that you shouldn't use them because you don't want all

194
00:14:51,720 --> 00:14:53,840
the flexibility you want to constrain your model

195
00:14:55,300 --> 00:14:59,310
but a few if you want to be flexible and give some probability

196
00:15:00,180 --> 00:15:02,770
to data coming from other regions then

197
00:15:03,300 --> 00:15:04,850
this may not be such a bad idea

198
00:15:05,250 --> 00:15:05,760
to use this

199
00:15:08,670 --> 00:15:09,100
okay so

200
00:15:11,810 --> 00:15:12,370
mixture model

201
00:15:13,110 --> 00:15:15,510
so using additional processes is defined

202
00:15:15,940 --> 00:15:16,740
by this so

203
00:15:17,270 --> 00:15:23,370
we have uh we have data points are that we have and datapoints indexed by i

204
00:15:25,310 --> 00:15:26,940
conditioned on some parameter

205
00:15:27,710 --> 00:15:30,740
and the parameter defines the distribution of the data

206
00:15:31,980 --> 00:15:38,050
and the parameter is drawn from some distribution gene which is drawn from the fission process this

207
00:15:38,610 --> 00:15:43,420
these parameters of the concentration parameter engine on the base distribution

208
00:15:43,920 --> 00:15:46,090
and this is the graphical model showing this

209
00:15:48,860 --> 00:15:50,090
these equations basically

210
00:15:50,710 --> 00:15:53,710
so this is this is how we define the infinite mixture model

211
00:15:55,270 --> 00:15:58,030
you could leave you can show it like this rare

212
00:15:58,460 --> 00:15:59,610
we have pi send

213
00:16:00,980 --> 00:16:02,160
rather than designed

214
00:16:03,970 --> 00:16:05,420
you read we have

215
00:16:06,330 --> 00:16:07,600
tysnd that letters

216
00:16:09,170 --> 00:16:09,790
we basically

217
00:16:11,020 --> 00:16:13,970
using this infinite sum that comes from the stick breaking

218
00:16:17,810 --> 00:16:18,340
okay so

219
00:16:20,850 --> 00:16:23,160
given this model how do we do inference on it

220
00:16:24,880 --> 00:16:30,820
typically the easiest case to use these models and practices to using conjugate base distribution

221
00:16:31,380 --> 00:16:36,980
so that the parameters can be integrated out and the predictive probabilities can be computed using

222
00:16:38,000 --> 00:16:39,480
sufficient statistics of the data

223
00:16:40,030 --> 00:16:42,130
so peter was talking about to cancel

224
00:16:43,070 --> 00:16:47,170
conjugacy one is the controversy after this process itself so the

225
00:16:47,590 --> 00:16:51,700
posterior process is still in there's process that's one type of conjugacy

226
00:16:52,110 --> 00:16:54,430
and that's always present in the dish

227
00:16:54,560 --> 00:16:55,280
process models

228
00:16:55,690 --> 00:16:56,060
but the

229
00:16:56,550 --> 00:16:57,500
are it is the

230
00:16:58,610 --> 00:17:00,480
when look there's a process models that say

231
00:17:02,660 --> 00:17:09,100
ends the can type of conjugacy is about the conjugacy of the parameters of the model to the

232
00:17:09,530 --> 00:17:11,350
base distribution so if you want to

233
00:17:13,690 --> 00:17:16,840
an infinite mixture model with gusting components

234
00:17:17,870 --> 00:17:23,280
you need to specify a prior on top of those components end that's prior needs to be

235
00:17:23,750 --> 00:17:25,970
conjugate to the gas in distribution

236
00:17:28,040 --> 00:17:30,530
because you assume gassing components porter

237
00:17:31,390 --> 00:17:32,550
data generating process

238
00:17:34,010 --> 00:17:34,700
so what is the

239
00:17:36,740 --> 00:17:41,410
what is the conjugate distribution part a guassian distribution so if if you are using

240
00:17:41,410 --> 00:17:44,570
a if you if you do

241
00:17:44,950 --> 00:17:47,610
assume that was mean and covariance is uncertain

242
00:17:47,610 --> 00:17:51,190
but the edge can not belong to the side

243
00:17:51,210 --> 00:17:55,940
the edge itself for this is cycle this cycle is four edges

244
00:17:58,420 --> 00:18:00,440
is an edge

245
00:18:00,480 --> 00:18:04,300
that connects two nodes in the cycle

246
00:18:04,300 --> 00:18:08,090
but does not belong to to the cycle

247
00:18:08,090 --> 00:18:10,110
or another way to put it

248
00:18:10,130 --> 00:18:14,980
is an edge between two non consecutive nodes inside

249
00:18:15,780 --> 00:18:21,590
but this is why i think it is well it's a shortcut in the cycle

250
00:18:22,860 --> 00:18:25,150
these graph is not chordal

251
00:18:25,190 --> 00:18:26,780
because you have

252
00:18:26,800 --> 00:18:29,210
one cycle

253
00:18:29,280 --> 00:18:31,590
and this cycle has no core

254
00:18:31,610 --> 00:18:35,630
immediately it's not chordal because every cycle

255
00:18:35,630 --> 00:18:37,590
in the graph must have a record

256
00:18:37,590 --> 00:18:45,110
of course apart from cycles of size three which by definition cannot have any court

257
00:18:45,630 --> 00:18:49,800
this is the a quarter because the two cycles that you don't have acquired now

258
00:18:49,800 --> 00:18:52,920
they have caught

259
00:18:53,030 --> 00:18:58,070
why does important well you remember

260
00:18:58,110 --> 00:19:00,780
that when we ran the elimination of algorithm

261
00:19:00,780 --> 00:19:02,460
in that previous

262
00:19:02,480 --> 00:19:06,860
example that we were suppressing successively the nodes

263
00:19:06,920 --> 00:19:10,190
at some point we add

264
00:19:10,250 --> 00:19:13,170
an edge right

265
00:19:13,170 --> 00:19:18,030
what the edge was was precisely one of these edges

266
00:19:18,090 --> 00:19:22,500
so one that it was on that it was necessary in order to make that

267
00:19:22,500 --> 00:19:25,630
graph chordal

268
00:19:25,630 --> 00:19:28,360
so you start to see the connection

269
00:19:28,380 --> 00:19:30,550
with the junction tree algorithm will be

270
00:19:30,590 --> 00:19:36,030
is exactly the generalisation of the elimination algorithm by pre computing

271
00:19:36,070 --> 00:19:38,920
all those necessary

272
00:19:43,650 --> 00:19:47,710
we'll get

273
00:19:47,730 --> 00:19:48,980
so basically

274
00:19:49,030 --> 00:19:52,460
what if a graph is not chordal well then you can use the junction tree

275
00:19:52,460 --> 00:19:53,820
of all

276
00:19:54,690 --> 00:19:56,980
in theory you can

277
00:19:56,980 --> 00:20:02,320
but the point is that you need to add edges until it becomes chordal

278
00:20:02,380 --> 00:20:06,010
these will change the graph

279
00:20:08,900 --> 00:20:11,400
exercise why this is not the problem

280
00:20:11,400 --> 00:20:12,650
i mean

281
00:20:12,710 --> 00:20:14,590
if i have a graph which

282
00:20:14,610 --> 00:20:15,820
it's not for

283
00:20:15,840 --> 00:20:21,500
and they went around the junction tree of all which only works on quarter i

284
00:20:21,500 --> 00:20:27,880
i can add add edges until it becomes chordal basically introduced at least one court

285
00:20:27,940 --> 00:20:31,940
in every cycle and make sure that the resulting graph is chordal

286
00:20:31,980 --> 00:20:33,980
or keep on adding until

287
00:20:34,030 --> 00:20:38,320
i have no chordless cycles

288
00:20:38,340 --> 00:20:41,070
but this will change the graph itself

289
00:20:41,090 --> 00:20:47,860
so what am i changing my problem

290
00:20:47,940 --> 00:20:52,030
this is not a problem but the question is why this is not a problem

291
00:20:52,050 --> 00:20:56,090
well this is not a problem for very simple reason and also the more general

292
00:20:57,690 --> 00:21:05,510
because by introducing edges i'm making less conditional independence assumptions

293
00:21:05,610 --> 00:21:08,230
so in solving a more general class

294
00:21:08,280 --> 00:21:09,820
of problems

295
00:21:10,750 --> 00:21:12,650
so this is not a problem at all

296
00:21:12,670 --> 00:21:15,190
of course they may immediately

297
00:21:15,230 --> 00:21:18,570
you will realize by now you know what p

298
00:21:18,570 --> 00:21:21,630
what a perfect map is

299
00:21:21,710 --> 00:21:25,500
what you will realize that by doing that

300
00:21:25,530 --> 00:21:26,940
i may actually

301
00:21:28,130 --> 00:21:32,210
the ability to have a perfect match for example from my distribution

302
00:21:32,250 --> 00:21:35,980
because if i'm forced to introduce some

303
00:21:37,130 --> 00:21:39,030
i will immediately

304
00:21:39,070 --> 00:21:42,210
be unable to enforce

305
00:21:42,230 --> 00:21:45,860
some conditional independence assumption that previously were there

306
00:21:45,880 --> 00:21:48,250
and now we are

307
00:21:49,670 --> 00:21:51,610
go ahead

308
00:21:51,650 --> 00:21:56,860
that's generally graphs

309
00:21:58,630 --> 00:22:01,590
the first step is just three only graph

310
00:22:01,650 --> 00:22:02,340
i mean

311
00:22:02,420 --> 00:22:07,690
our from so that in practice we usually work with lithographs anyway

312
00:22:07,730 --> 00:22:12,440
like chains or two treestreestrees and things like that for example

313
00:22:12,440 --> 00:22:13,710
of that

314
00:22:13,710 --> 00:22:17,040
and that means of the previous guy

315
00:22:17,080 --> 00:22:18,580
together we are thinking

316
00:22:18,600 --> 00:22:23,260
divided by the norm of x where

317
00:22:23,310 --> 00:22:25,260
this is our up

318
00:22:25,270 --> 00:22:28,490
OK so we wanted to analyse

319
00:22:28,500 --> 00:22:35,680
these through the true identity so we compute the like function

320
00:22:35,720 --> 00:22:40,820
all the topic of this constrained optimisation problem

321
00:22:40,870 --> 00:22:46,520
and we end up with something that looks like

322
00:22:48,780 --> 00:22:51,050
or directly

323
00:22:52,450 --> 00:22:57,710
be the last prior to that i think about it i mean i think of

324
00:22:57,710 --> 00:22:59,430
you got here

325
00:22:59,450 --> 00:23:03,120
the this conference and this like multiply is actually

326
00:23:03,190 --> 00:23:06,140
correspond to the

327
00:23:08,260 --> 00:23:12,340
if people are learning rate

328
00:23:12,360 --> 00:23:13,760
indeed there we

329
00:23:13,930 --> 00:23:14,540
we see

330
00:23:14,550 --> 00:23:15,580
so that this is

331
00:23:15,610 --> 00:23:18,240
was equal to minus the house

332
00:23:18,250 --> 00:23:20,080
of these where the

333
00:23:20,110 --> 00:23:23,320
x is where

334
00:23:24,620 --> 00:23:27,820
alpha and then we had the LP

335
00:23:27,830 --> 00:23:32,220
of w minus one hinge loss

336
00:23:32,290 --> 00:23:37,100
and the and the

337
00:23:37,150 --> 00:23:38,510
and alpha and

338
00:23:38,530 --> 00:23:39,750
it would be

339
00:23:40,520 --> 00:23:41,390
when we

340
00:23:41,440 --> 00:23:46,080
worse when we saw the when we compute the dual the primary we found out

341
00:23:46,080 --> 00:23:47,630
that output

342
00:23:47,650 --> 00:23:48,730
well actually

343
00:23:48,770 --> 00:23:51,780
play the same role in the of learning rate

344
00:23:51,790 --> 00:23:54,850
so the one we solve the

345
00:23:54,860 --> 00:23:57,260
one we find the optimum

346
00:23:57,300 --> 00:24:02,830
like to multiply the one that maximizes the world by taking derivatives

347
00:24:02,850 --> 00:24:07,270
and then there will be one of the for all

348
00:24:07,280 --> 00:24:12,330
we therefore can see from here the river is that they were or are you

349
00:24:12,330 --> 00:24:13,310
get a point

350
00:24:13,540 --> 00:24:15,450
you introduce the

351
00:24:15,500 --> 00:24:19,020
the additional costs but you get

352
00:24:19,040 --> 00:24:20,380
the other thing

353
00:24:20,480 --> 00:24:22,470
is the learning rate it up here

354
00:24:22,490 --> 00:24:23,960
so we've got this one

355
00:24:23,980 --> 00:24:27,440
now we wanted to say

356
00:24:27,450 --> 00:24:28,900
so this is the way

357
00:24:29,620 --> 00:24:34,520
computing platforms so we know that we have to be performed

358
00:24:34,540 --> 00:24:35,810
this corresponds to that

359
00:24:36,060 --> 00:24:39,150
that's right this the output is far

360
00:24:39,170 --> 00:24:41,470
because it that be optimal

361
00:24:41,580 --> 00:24:43,900
i got applied mathematics one

362
00:24:43,910 --> 00:24:45,840
OK now you want to go

363
00:24:45,880 --> 00:24:50,000
it for the purpose of coming up with analysis of exactly what we want to

364
00:24:50,010 --> 00:24:51,350
make the game

365
00:24:51,430 --> 00:24:55,560
a relationship established the relationship between this problem and the

366
00:24:55,690 --> 00:24:57,980
batch has been problems

367
00:24:58,030 --> 00:25:02,050
but the problem is get

368
00:25:02,100 --> 00:25:08,600
i'm always thinking of treatment genetic stream of length capital

369
00:25:08,630 --> 00:25:11,020
text in the background

370
00:25:11,900 --> 00:25:45,400
because of the SVM objective

371
00:25:45,420 --> 00:25:49,860
with the same regularisation parameter vector see here

372
00:25:49,870 --> 00:25:53,650
in the

373
00:25:54,940 --> 00:25:56,230
so now we can we

374
00:25:57,230 --> 00:26:00,990
a road to the world

375
00:26:01,010 --> 00:26:06,240
but there will be an

376
00:26:06,260 --> 00:26:07,870
and then we

377
00:26:07,880 --> 00:26:10,820
we noticed that we could write world

378
00:26:10,830 --> 00:26:16,570
in a telescopic weight so we could write it is

379
00:26:24,470 --> 00:26:26,510
because OK write like

380
00:26:28,150 --> 00:26:32,550
zero which is the wrong

381
00:26:33,500 --> 00:26:36,240
part one thing

382
00:26:36,290 --> 00:26:39,150
and we have a different one

383
00:26:39,650 --> 00:26:43,170
but in

384
00:26:44,060 --> 00:26:45,980
it might be

385
00:26:46,000 --> 00:26:48,580
but there

386
00:26:48,630 --> 00:26:51,900
at the end

387
00:26:54,420 --> 00:26:56,320
the main one

388
00:26:58,600 --> 00:27:00,290
OK so

389
00:27:00,340 --> 00:27:03,420
mine this one can

390
00:27:03,440 --> 00:27:04,830
and then

391
00:27:08,210 --> 00:27:11,220
but this is zero we don't care

392
00:27:11,240 --> 00:27:15,350
i don't write in the world but we had money

393
00:27:15,660 --> 00:27:17,260
o thing

394
00:27:17,270 --> 00:27:20,380
so we know that one zero zero so

395
00:27:20,400 --> 00:27:22,520
we have

396
00:27:22,550 --> 00:27:25,310
we're fine so we can just look at

397
00:27:26,430 --> 00:27:32,220
call it here and we know that by which what we serve the foreign assignment

398
00:27:32,270 --> 00:27:34,880
any legal assignment one out the

399
00:27:36,350 --> 00:27:38,080
beginning of zero

400
00:27:38,550 --> 00:27:41,860
if we call the

401
00:27:41,880 --> 00:27:44,710
this up here end the solution of the

402
00:27:44,770 --> 00:27:48,830
training the SVM problem of

403
00:27:49,450 --> 00:27:50,320
the value

404
00:27:50,350 --> 00:27:53,390
of the objective of human

405
00:27:53,410 --> 00:27:54,320
we know that

406
00:27:54,330 --> 00:27:56,160
the what

407
00:27:56,200 --> 00:28:00,250
four in this league assignment of the is

408
00:28:00,290 --> 00:28:06,280
always smaller than up it

409
00:28:07,310 --> 00:28:08,390
so now

410
00:28:08,400 --> 00:28:09,720
you know this fact

411
00:28:09,770 --> 00:28:14,580
we have a relationship between the two world figure should be in the world and

412
00:28:14,600 --> 00:28:16,150
these differences

413
00:28:16,170 --> 00:28:19,570
and what we need is that we observe that

414
00:28:19,590 --> 00:28:21,700
computing these differences

415
00:28:21,710 --> 00:28:24,110
this was his last observation

416
00:28:24,120 --> 00:28:27,590
computing the differences

417
00:28:28,920 --> 00:28:33,140
one of

418
00:28:33,690 --> 00:28:38,350
you remind me

419
00:28:41,690 --> 00:28:42,970
he made

420
00:28:42,990 --> 00:28:45,280
the red arrow

421
00:28:45,290 --> 00:28:49,530
OK if you do the calculation you find out that this

422
00:28:49,570 --> 00:28:50,810
we did

423
00:28:50,830 --> 00:28:53,460
and we found out that it was one the

424
00:28:53,500 --> 00:28:55,180
in game

425
00:28:55,190 --> 00:28:57,660
but the

426
00:29:01,820 --> 00:29:04,340
so all this means that

427
00:29:04,450 --> 00:29:09,750
basically can plug is zero so you can plug this in here

428
00:29:09,770 --> 00:29:11,870
and now you can say OK

429
00:29:11,890 --> 00:29:13,900
i know that some of the the

430
00:29:13,910 --> 00:29:18,160
of the dual for active aggressive which could before

431
00:29:18,870 --> 00:29:20,850
i by the by

432
00:29:20,870 --> 00:29:23,350
the value of the optimum

433
00:29:23,370 --> 00:29:26,070
of the same objective function so

434
00:29:26,090 --> 00:29:28,770
i i can lower bound

435
00:29:28,770 --> 00:29:33,100
of partials but we also a random number which can be either minus one either

436
00:29:33,100 --> 00:29:37,190
zero plus one and this is done so that you removed

437
00:29:37,200 --> 00:29:41,150
you can end up with a name or number of fossils

438
00:29:41,170 --> 00:29:44,320
so as to make it reversible that is if you start from the situation with

439
00:29:44,320 --> 00:29:45,350
the even

440
00:29:45,370 --> 00:29:50,350
a number of times you might be able to do the reverse

441
00:29:53,240 --> 00:29:58,970
this is fairly standard you sample frequencies for the new did both roles

442
00:29:58,990 --> 00:30:02,910
so there is a candidate set of frequencies

443
00:30:02,920 --> 00:30:08,540
and you compute the metropolis hastings ratio designed for reversible jumps

444
00:30:08,560 --> 00:30:09,830
so this is

445
00:30:11,440 --> 00:30:12,720
this is the

446
00:30:12,740 --> 00:30:14,420
the the

447
00:30:14,430 --> 00:30:20,040
the ratio of the proposal of the posterior distribution for the new candidates divided by

448
00:30:21,770 --> 00:30:27,940
the posterior distribution for the previous example OK so found the metropolis hastings ratio multiplied

449
00:30:29,030 --> 00:30:32,700
so the prior becomes here because it's part of the posterior

450
00:30:32,810 --> 00:30:35,530
and here you have the ratio of

451
00:30:35,540 --> 00:30:37,880
i proposal distributions

452
00:30:37,930 --> 00:30:42,270
as in the fundamental belief systems three shows us to to make sure that it

453
00:30:42,270 --> 00:30:45,760
converges to the true distribution

454
00:30:45,770 --> 00:30:50,780
and we either accept the candidate we i are rejected

455
00:30:54,500 --> 00:30:55,920
in this example

456
00:30:56,430 --> 00:30:59,380
you might have seen that all the candidates are

457
00:30:59,390 --> 00:31:02,830
proposed by distributions q

458
00:31:02,840 --> 00:31:05,390
OK which we call the proposal distribution

459
00:31:05,400 --> 00:31:09,690
and which are actually is the key element in the convergence of the algorithm

460
00:31:09,710 --> 00:31:11,990
this is what you can select OK

461
00:31:12,010 --> 00:31:16,580
the problem the posterior distribution you want to sample from you can not selected but

462
00:31:16,600 --> 00:31:20,300
but the probability distributions you can select

463
00:31:20,310 --> 00:31:25,200
so it is very important to to respective few rules and into practical sessions will

464
00:31:25,200 --> 00:31:29,830
see that if you use for example local proposal distribution which can be for example

465
00:31:29,890 --> 00:31:30,840
random walk

466
00:31:30,940 --> 00:31:35,460
you start situation from situation and you propose the candidate in the nineteen in the

467
00:31:36,720 --> 00:31:38,440
OK so this will not

468
00:31:38,450 --> 00:31:41,080
and sure fast if you're using global

469
00:31:41,160 --> 00:31:48,030
proposal distribution you some situation and then you propose candidates independently from the previous accepted

470
00:31:49,050 --> 00:31:53,710
in this case it will not converge very fast again and it will converge faster

471
00:31:53,710 --> 00:31:57,050
to mix the two kind of moves so we see this in the proper in

472
00:31:57,050 --> 00:31:59,630
the practical fish

473
00:31:59,640 --> 00:32:05,480
so this is just an example of how we can design global proposal distribution which

474
00:32:05,480 --> 00:32:11,400
is efficient when mixed together with the local distribution it to for example derive

475
00:32:11,420 --> 00:32:15,040
the probability density function which is proportional to support spectrum

476
00:32:15,130 --> 00:32:18,150
o of the signal

477
00:32:18,160 --> 00:32:23,540
OK so this is just the remarks it's not very important

478
00:32:23,560 --> 00:32:24,620
OK so

479
00:32:24,630 --> 00:32:28,250
you've seen this is quite

480
00:32:28,300 --> 00:32:30,330
big machine to compute

481
00:32:30,350 --> 00:32:33,240
the music but i'll show you some results

482
00:32:33,250 --> 00:32:34,400
and you see

483
00:32:34,480 --> 00:32:36,440
it can be very powerful

484
00:32:36,450 --> 00:32:44,720
need to plug the speaker

485
00:33:08,650 --> 00:33:10,880
the problem there

486
00:33:10,890 --> 00:33:14,390
uniform and she

487
00:33:22,220 --> 00:33:48,190
just once a concern that that

488
00:33:49,090 --> 00:33:58,140
should be working soon

489
00:34:01,440 --> 00:34:02,190
OK so

490
00:34:02,210 --> 00:34:05,760
this is an example of violin

491
00:34:08,210 --> 00:34:10,960
what's happening now

492
00:34:12,160 --> 00:34:18,180
can this for that

493
00:34:20,390 --> 00:34:22,570
sorry about that

494
00:34:22,620 --> 00:34:26,060
tried to fix this and if it doesn't work

495
00:34:26,080 --> 00:34:27,790
the system

496
00:34:49,980 --> 00:34:53,630
OK so now we need to work it doesn't

497
00:34:54,820 --> 00:35:00,010
OK so that's office again the violin playing just one out

498
00:35:00,060 --> 00:35:02,330
OK so it's a bit loud

499
00:35:02,380 --> 00:35:06,340
right so i did it again

500
00:35:06,360 --> 00:35:10,600
OK so this is the original signal

501
00:35:10,610 --> 00:35:14,600
and with this is our that been using and we

502
00:35:14,610 --> 00:35:19,160
put it into this being verizon and then it gives us a set of samples

503
00:35:19,160 --> 00:35:25,100
of the parameters and from this parameters we can reconstruct the doctor and that's what

504
00:35:25,100 --> 00:35:26,990
we can here we've

505
00:35:27,000 --> 00:35:31,270
and if we do the difference between the original data the reconstructed one

506
00:35:31,290 --> 00:35:33,570
we had to put this

507
00:35:36,870 --> 00:35:38,390
OK so

508
00:35:38,700 --> 00:35:44,400
sure some was the results later so here is a figure which shows the convergence

509
00:35:44,400 --> 00:35:48,370
of the markov chain so this is the typical things that you might find

510
00:35:48,390 --> 00:35:52,440
and is the structural parameters and as you can see

511
00:35:52,460 --> 00:35:53,500
was easy

512
00:35:53,510 --> 00:35:57,460
i move that we designed it converges quite quite fast

513
00:35:57,480 --> 00:36:03,760
and this is from the fundamental frequency of the first of one of the because

514
00:36:03,760 --> 00:36:06,110
there is only one here and as you can see

515
00:36:06,160 --> 00:36:09,840
after the convergence is reached it keeps fluctuating

516
00:36:09,850 --> 00:36:14,310
which is good that's what we want because it is supposed to run them to

517
00:36:14,310 --> 00:36:19,670
the speed of sound

518
00:36:19,740 --> 00:36:24,230
is three hundred

519
00:36:24,260 --> 00:36:26,780
forty meters per second

520
00:36:26,810 --> 00:36:29,740
that's a little bit on the temperature of about seven hundred

521
00:36:29,820 --> 00:36:32,360
seventy miles per hour

522
00:36:32,370 --> 00:36:35,860
when i speak to you might sound reaches use that speed

523
00:36:35,870 --> 00:36:39,590
i produces certain frequency here

524
00:36:39,640 --> 00:36:42,230
so the number of oscillations per second

525
00:36:42,300 --> 00:36:47,340
they reach you UUU run starts to oscillate with the same frequency you hear that

526
00:36:47,340 --> 00:36:49,440
i have here tuning fork

527
00:36:49,480 --> 00:36:52,130
it oscillates four hundred forty times per second

528
00:36:52,270 --> 00:36:55,530
your eardrum

529
00:36:58,590 --> 00:37:01,160
four hundred forty times a second you hear this song

530
00:37:01,200 --> 00:37:03,840
you have two hundred fifty six

531
00:37:03,840 --> 00:37:06,300
oscillations per second

532
00:37:06,350 --> 00:37:13,840
move around is now shaking going back and forth two hundred fifty six times per

533
00:37:13,840 --> 00:37:17,220
second if you stay where you are and you don't move

534
00:37:17,260 --> 00:37:20,310
and i moved this tuning forks you here

535
00:37:20,410 --> 00:37:22,110
a different frequency

536
00:37:22,110 --> 00:37:23,360
and that's what we call

537
00:37:23,410 --> 00:37:24,890
doppler effect

538
00:37:25,750 --> 00:37:27,450
my sound source

539
00:37:27,530 --> 00:37:31,280
approaches you

540
00:37:31,330 --> 00:37:33,370
you will hear frequency as prime

541
00:37:33,390 --> 00:37:36,340
which is larger than the frequency of the tuning fork

542
00:37:36,390 --> 00:37:38,810
if it moves away from you

543
00:37:38,830 --> 00:37:41,030
which i will call receding

544
00:37:41,130 --> 00:37:43,810
then f prime

545
00:37:44,980 --> 00:37:47,140
below lower frequency

546
00:37:47,190 --> 00:37:51,470
for instance i moved to you

547
00:37:51,520 --> 00:37:54,250
some stories i call that transmitter

548
00:37:54,270 --> 00:37:55,780
with a speed

549
00:37:55,780 --> 00:37:57,110
of about

550
00:37:58,090 --> 00:38:01,580
one meters per second

551
00:38:01,640 --> 00:38:04,640
transmitter is the sound transmitter

552
00:38:05,340 --> 00:38:08,060
if it approaches you here

553
00:38:08,080 --> 00:38:09,910
you have prime

554
00:38:09,920 --> 00:38:12,970
which is one point zero zero three

555
00:38:13,000 --> 00:38:14,190
times as

556
00:38:14,280 --> 00:38:16,950
this three here is the one part

557
00:38:16,970 --> 00:38:18,720
out of three hundred forty

558
00:38:18,750 --> 00:38:21,110
together with increasing frequency

559
00:38:21,130 --> 00:38:22,940
if i move it away from you

560
00:38:22,970 --> 00:38:24,460
then f prime

561
00:38:24,530 --> 00:38:27,070
would be o point nine nine

562
00:38:27,900 --> 00:38:33,060
times the frequency of the source itself

563
00:38:33,060 --> 00:38:34,560
you stay where you live

564
00:38:34,660 --> 00:38:36,910
i have here a tuning fork

565
00:38:37,720 --> 00:38:41,250
generates four thousand for very high frequency

566
00:38:41,310 --> 00:38:44,100
if i move it to you is the speed of one meter per second which

567
00:38:44,100 --> 00:38:45,470
i can do

568
00:38:45,510 --> 00:38:49,090
then you can increase in picture of point three percent that makes it four thousand

569
00:38:50,190 --> 00:38:53,250
and when i move it away from you that is the decrease of point three

570
00:38:53,250 --> 00:38:58,280
percent you can clearly hear that difference first make you listen to the four thousand

571
00:38:58,280 --> 00:39:00,840
rupees without my moving

572
00:39:03,690 --> 00:39:06,850
actually causes painful really

573
00:39:06,900 --> 00:39:08,130
high frequency

574
00:39:08,190 --> 00:39:11,790
most of you are young enough you should be able to four thousand hertz OK

575
00:39:11,790 --> 00:39:15,030
now i'm going to move it to you one meter per second and away from

576
00:39:17,040 --> 00:39:23,470
did you hear it once more

577
00:39:27,680 --> 00:39:31,680
when it comes to you it's clear that the frequency

578
00:39:31,690 --> 00:39:33,870
goes up and when it moves away from you

579
00:39:33,880 --> 00:39:34,910
the frequency

580
00:39:34,960 --> 00:39:36,560
is that

581
00:39:36,620 --> 00:39:38,780
now imagine that i'm going to

582
00:39:39,870 --> 00:39:42,870
the sound sources around in a circle

583
00:39:43,560 --> 00:39:46,840
the sound that you receive the frequency that you receive

584
00:39:46,910 --> 00:39:47,880
it will change

585
00:39:47,900 --> 00:39:50,440
in a sinusoidal fashion

586
00:39:50,490 --> 00:39:52,210
this is that circle

587
00:39:52,250 --> 00:39:55,930
and this is the radius of the circle

588
00:39:55,940 --> 00:39:58,650
and if you

589
00:39:58,790 --> 00:40:00,040
are you

590
00:40:00,060 --> 00:40:01,350
in the plane

591
00:40:01,400 --> 00:40:03,440
o of the circle

592
00:40:03,470 --> 00:40:05,870
then when the source

593
00:40:05,880 --> 00:40:07,440
comes straight to you

594
00:40:07,460 --> 00:40:08,810
with the velocity v

595
00:40:08,820 --> 00:40:11,190
let's say to uniform circular motion

596
00:40:11,280 --> 00:40:13,630
as prime will be larger than f

597
00:40:13,650 --> 00:40:15,560
and it will in this case

598
00:40:15,630 --> 00:40:17,470
rita maximal

599
00:40:17,490 --> 00:40:20,900
when it is at ninety degrees relative to you

600
00:40:20,910 --> 00:40:24,630
i don't have to give a vector notation as prime

601
00:40:24,650 --> 00:40:25,900
calls f

602
00:40:25,940 --> 00:40:27,180
when it moves

603
00:40:27,220 --> 00:40:28,930
away from you

604
00:40:28,940 --> 00:40:31,300
prime smaller than that

605
00:40:32,930 --> 00:40:34,640
and when it is here again

606
00:40:34,690 --> 00:40:39,420
when the angle between is the velocity and new direction is again ninety degrees

607
00:40:39,490 --> 00:40:42,700
then f prime equal africa

608
00:40:42,740 --> 00:40:44,130
so this phenomenon

609
00:40:44,140 --> 00:40:46,400
it's called

610
00:40:46,450 --> 00:40:50,500
the doppler effect

611
00:40:50,500 --> 00:40:52,440
so if i turn it around

612
00:40:52,480 --> 00:40:53,500
you know

613
00:40:53,500 --> 00:40:57,380
here a sinusoidal fluctuations in

614
00:40:57,430 --> 00:41:00,050
after i suppose i

615
00:41:00,100 --> 00:41:01,370
a lot

616
00:41:01,370 --> 00:41:03,310
as a function of time

617
00:41:03,310 --> 00:41:05,000
f prime

618
00:41:05,010 --> 00:41:08,460
the way you will receive reduced it still but i'm going to move

619
00:41:08,500 --> 00:41:11,580
sound source around like this

620
00:41:11,600 --> 00:41:15,380
then you will have a curve that looks something like this

621
00:41:15,390 --> 00:41:19,770
some signs sinusoidal cosine sort of fluctuations f prime

622
00:41:19,870 --> 00:41:22,040
this will be

623
00:41:22,250 --> 00:41:27,250
the value f produced by the sound source itself

624
00:41:27,270 --> 00:41:28,620
this will be

625
00:41:28,630 --> 00:41:30,850
as prime

626
00:41:33,380 --> 00:41:35,020
and this will be

627
00:41:35,040 --> 00:41:36,690
as prime

628
00:41:39,700 --> 00:41:43,730
if you could record this there is an amazing number of things that you can

629
00:41:43,790 --> 00:41:44,630
do so

630
00:41:44,630 --> 00:41:46,560
from this curve

631
00:41:46,610 --> 00:41:48,290
first of all

632
00:41:48,330 --> 00:41:51,170
you can take you can measure f primex

633
00:41:51,270 --> 00:41:54,820
divided by s

634
00:41:54,870 --> 00:41:58,070
because you see this curve so you know whatever it is you would have climaxes

635
00:41:58,140 --> 00:42:01,520
and that should allow you to retrieve immediately

636
00:42:01,550 --> 00:42:04,870
the velocity of the transmitter if that number

637
00:42:04,880 --> 00:42:06,390
we're one point

638
00:42:06,400 --> 00:42:07,800
zero zero three

639
00:42:07,810 --> 00:42:09,380
then you know that the speed

640
00:42:09,400 --> 00:42:11,930
in the orbit was one meter per second

641
00:42:12,000 --> 00:42:15,240
so it is ratio immediately gives you the transmitter velocity

642
00:42:15,310 --> 00:42:19,370
this time separation

643
00:42:19,390 --> 00:42:22,990
if you immediately the period of rotation

644
00:42:23,000 --> 00:42:26,080
but since two pi r

645
00:42:26,100 --> 00:42:28,800
if r is the radius

646
00:42:28,810 --> 00:42:30,230
divided by

647
00:42:30,240 --> 00:42:33,600
the velocity of the transmitter since that is

648
00:42:34,250 --> 00:42:38,490
i can reverse it doesn't matter two pi are divided by the time to go

649
00:42:38,490 --> 00:42:41,850
around is the velocity of the transmitter

650
00:42:41,890 --> 00:42:46,560
since you know the velocity of the transmitter from this ratio to noted period

651
00:42:46,570 --> 00:42:47,560
which is this

652
00:42:47,560 --> 00:42:49,300
you know also find

653
00:42:49,370 --> 00:42:50,560
the radius r

654
00:42:50,570 --> 00:42:52,080
so from that curve

655
00:42:52,110 --> 00:42:53,080
keep that

656
00:42:53,100 --> 00:42:57,440
with you because going to be important in what follows we can derive three things

657
00:42:57,490 --> 00:42:59,150
the radius

658
00:42:59,200 --> 00:43:00,810
the period of rotation

659
00:43:00,820 --> 00:43:03,630
and the speed

660
00:43:03,640 --> 00:43:05,370
of the object

661
00:43:05,370 --> 00:43:08,000
as i truly around

662
00:43:08,000 --> 00:43:10,600
i have here what we call a wind organ

663
00:43:10,690 --> 00:43:12,610
when i told is around

664
00:43:12,650 --> 00:43:17,760
it produces a particular tone we'll talk later about eighty to one wire produces a

665
00:43:17,760 --> 00:43:22,140
particular time sometimes you hear two towns of trying to make you only one

666
00:43:22,190 --> 00:43:25,670
and and as i it around

667
00:43:25,680 --> 00:43:30,210
the sound is coming the sound source the transmitters coming to you

668
00:43:30,210 --> 00:43:35,000
you really need to do something like this you can exhaustively enumerate all settings of

669
00:43:35,000 --> 00:43:36,790
all variables

670
00:43:36,850 --> 00:43:40,400
now if you want to actually code this

671
00:43:40,610 --> 00:43:48,920
it's easier to code up in the formalism of factor graphs rather than directed graphs

672
00:43:48,920 --> 00:43:53,360
so i'm just going to very quickly show you factor graph propagation as well

673
00:43:53,380 --> 00:43:56,810
which is similar set of propagation rules

674
00:43:56,810 --> 00:44:03,520
so where nodes are sending messages to other nodes

675
00:44:05,110 --> 00:44:08,150
just to remind everyone the factor graph is

676
00:44:08,230 --> 00:44:12,920
a factor graph is just the way of representing a joint probability distribution

677
00:44:12,940 --> 00:44:14,790
as a product

678
00:44:16,020 --> 00:44:21,110
functions on subsets of variables

679
00:44:21,270 --> 00:44:24,020
so this is a normalisation constant

680
00:44:24,080 --> 00:44:27,630
and this joint distribution is simply the product of over

681
00:44:27,630 --> 00:44:33,480
functions each of these functions fj is a non negative function of its

682
00:44:34,690 --> 00:44:35,790
this x

683
00:44:35,810 --> 00:44:40,810
some s j is just some subset of variables

684
00:44:41,270 --> 00:44:46,710
that this function is a function of so you know here you would have this

685
00:44:46,710 --> 00:44:50,790
dot corresponds to the function of a and c

686
00:44:50,810 --> 00:44:53,020
a non negative function

687
00:44:53,290 --> 00:44:57,420
you can have negatives in their consumer multiplying all these together to get the probability

688
00:44:58,980 --> 00:45:02,540
and then you need the normalizer so it sums to one when you some over

689
00:45:02,540 --> 00:45:04,210
for all the very

690
00:45:04,270 --> 00:45:09,690
so this is just a reminder of what a factor graph is

691
00:45:13,290 --> 00:45:17,360
if you have a factor graph you can talk about the

692
00:45:17,420 --> 00:45:20,580
neighbors of node x

693
00:45:20,590 --> 00:45:23,190
first let n of x be the

694
00:45:23,190 --> 00:45:28,440
factor nodes that are neighbors of x and n of FP the variable nodes that

695
00:45:28,440 --> 00:45:30,710
are neighbors of factor

696
00:45:31,880 --> 00:45:33,380
remember each

697
00:45:34,480 --> 00:45:35,850
it is connected

698
00:45:35,850 --> 00:45:39,980
each valuable node is connected to some of these factor nodes and the factor nodes

699
00:45:39,980 --> 00:45:41,170
are connected to

700
00:45:41,230 --> 00:45:44,560
some valuable nodes

701
00:45:46,900 --> 00:45:51,290
factor graph propagation simply sends messages from

702
00:45:51,310 --> 00:45:54,110
variables the factors

703
00:45:54,190 --> 00:45:56,590
and the messages look like this

704
00:45:56,690 --> 00:46:02,380
message from variable to factor is simply the product of the messages from

705
00:46:02,590 --> 00:46:07,060
all the factors that are neighbors of x

706
00:46:08,270 --> 00:46:12,850
is the product of all the messages x is getting from the other factors

707
00:46:12,850 --> 00:46:14,630
not including

708
00:46:16,690 --> 00:46:18,690
and then the message from

709
00:46:18,690 --> 00:46:20,900
a factor to variable

710
00:46:23,860 --> 00:46:28,230
again a product of the messages from all of the variables

711
00:46:28,310 --> 00:46:31,110
that f is connected to

712
00:46:31,110 --> 00:46:32,960
going to have

713
00:46:33,020 --> 00:46:36,590
the product is taken over all the neighbors of that

714
00:46:36,650 --> 00:46:38,670
not including x

715
00:46:38,710 --> 00:46:41,980
and then you multiply it by the actual factor and then use some about all

716
00:46:41,980 --> 00:46:45,520
the other variables so since these two equations

717
00:46:45,610 --> 00:46:48,810
and you can basically run these two equations

718
00:46:48,830 --> 00:46:51,170
which i have written down here

719
00:46:51,230 --> 00:46:53,920
and once all the variables

720
00:46:53,960 --> 00:46:59,060
what sorry of variables receive all messages from its neighboring factors we can compute the

721
00:47:00,190 --> 00:47:05,170
distribution of that variable by multiplying all the messages and renormalizing

722
00:47:06,500 --> 00:47:11,060
it's just these two equations is simpler than the belief propagation algorithm

723
00:47:11,110 --> 00:47:15,170
that i described previously and is really pretty easy to code up

724
00:47:15,190 --> 00:47:17,170
these things are again

725
00:47:17,190 --> 00:47:19,060
functions of

726
00:47:20,710 --> 00:47:25,460
if this has if this takes on k values then this can be represented as

727
00:47:25,860 --> 00:47:27,380
a vector

728
00:47:27,900 --> 00:47:30,110
of length k

729
00:47:34,480 --> 00:47:37,540
that was factor graph propagation so

730
00:47:37,540 --> 00:47:39,380
how would this actually work

731
00:47:39,380 --> 00:47:42,520
well imagine you had a factor graph that look like this

732
00:47:42,650 --> 00:47:44,250
let's say

733
00:47:44,270 --> 00:47:47,630
was initialize all the messages to be ones

734
00:47:47,630 --> 00:47:49,960
that means there vectors

735
00:47:49,980 --> 00:47:51,900
of all ones

736
00:47:52,790 --> 00:47:59,310
here's an example schedule of messages resulting in the computation of p of x probability

737
00:47:59,310 --> 00:48:03,190
of x four OK we want to compute the probability of x four

738
00:48:03,210 --> 00:48:05,000
i really do this well

739
00:48:05,940 --> 00:48:09,900
x one sends a message to f one

740
00:48:09,920 --> 00:48:12,690
the message is

741
00:48:13,090 --> 00:48:15,750
the all ones message

742
00:48:15,790 --> 00:48:18,460
then x three sensor message f two

743
00:48:18,480 --> 00:48:21,580
we could have done many different order if we'd wanted to

744
00:48:22,480 --> 00:48:24,770
f one sensor measures to f two

745
00:48:24,770 --> 00:48:26,580
according to the rules

746
00:48:26,610 --> 00:48:28,110
we had before

747
00:48:28,130 --> 00:48:29,630
the message that

748
00:48:29,670 --> 00:48:33,580
that as a function centre variable is given by

749
00:48:33,630 --> 00:48:35,230
sorry this equation

750
00:48:36,190 --> 00:48:39,520
f one sends this message two x two

751
00:48:39,520 --> 00:48:42,400
and that's the messages says x two

752
00:48:42,400 --> 00:48:48,590
f two sense this passage two x two

753
00:48:48,650 --> 00:48:51,110
that's this message sent to x two

754
00:48:51,110 --> 00:48:52,400
then x two

755
00:48:52,440 --> 00:48:56,000
has received the messages from f one f two and is ready to send out

756
00:48:56,000 --> 00:48:58,080
a message to three

757
00:48:58,130 --> 00:49:03,060
so x two sends this message left three which is simply the product of the

758
00:49:03,060 --> 00:49:05,270
messages a gottfried

759
00:49:05,880 --> 00:49:08,610
f one and f two

760
00:49:10,460 --> 00:49:14,860
and so if three got that message and now if three is ready to send

761
00:49:14,860 --> 00:49:17,670
a message to x four

762
00:49:17,670 --> 00:49:18,900
that they are not known then

763
00:49:19,270 --> 00:49:22,050
and no normal inverse wishart distribution is the

764
00:49:22,590 --> 00:49:24,170
going to get to the gas in distribution

765
00:49:24,650 --> 00:49:26,600
all if you are fixing the

766
00:49:27,860 --> 00:49:29,900
fixing the meaning ants assuming only

767
00:49:30,350 --> 00:49:31,110
you want to learn the

768
00:49:31,530 --> 00:49:32,690
covariance then you need the

769
00:49:33,120 --> 00:49:35,080
inverse wishart distribution on the covariance

770
00:49:36,010 --> 00:49:37,030
or if you know

771
00:49:37,600 --> 00:49:37,950
what the

772
00:49:38,460 --> 00:49:42,110
what the covariances are you're you're pretty sure you can set it

773
00:49:43,670 --> 00:49:44,910
and you only want to put the

774
00:49:45,370 --> 00:49:48,630
distribution over the mean and standard normal distribution is the

775
00:49:49,180 --> 00:49:50,640
conjugate distribution forward the

776
00:49:53,010 --> 00:49:58,420
and similarly if you have discrete data if you're using a multinomial distribution for example to

777
00:49:58,970 --> 00:50:01,420
model your data then the addition distribution

778
00:50:02,600 --> 00:50:03,160
the conjugate

779
00:50:04,000 --> 00:50:06,740
distribution father multinomial so that you're using it

780
00:50:07,400 --> 00:50:08,520
this multinomial

781
00:50:08,990 --> 00:50:09,650
models it

782
00:50:10,750 --> 00:50:11,170
okay so

783
00:50:12,380 --> 00:50:15,940
of course are not tied to using conjugate base distributions but

784
00:50:16,410 --> 00:50:17,920
things become a little more tricky

785
00:50:18,690 --> 00:50:21,330
thank you may you want to use non conjugate models

786
00:50:22,210 --> 00:50:22,760
and that's why

787
00:50:23,310 --> 00:50:24,260
here i'm going to be

788
00:50:25,320 --> 00:50:28,990
talking only about how to do inference forward and conjugate case

789
00:50:30,320 --> 00:50:31,910
in something

790
00:50:32,460 --> 00:50:36,150
what you're doing at each iteration is for each data datapoint

791
00:50:36,810 --> 00:50:39,740
you're remove the data point from its current component so

792
00:50:40,150 --> 00:50:43,880
you start off with some random initially is initializations

793
00:50:45,170 --> 00:50:47,520
uh some initialization of

794
00:50:48,130 --> 00:50:50,310
a number of components with assignments

795
00:50:50,750 --> 00:50:53,530
two of data points to different components

796
00:50:55,490 --> 00:50:58,300
and this when you start something here

797
00:51:00,200 --> 00:51:02,700
a single data point from its current component

798
00:51:03,780 --> 00:51:08,980
and if that's component has become entities so if they that data point that u

799
00:51:09,660 --> 00:51:12,820
removed from the company was the only one that was assigned to it

800
00:51:13,740 --> 00:51:16,010
utility that component from the representation

801
00:51:16,590 --> 00:51:17,220
because nobody

802
00:51:17,910 --> 00:51:18,670
onstad anymore

803
00:51:19,370 --> 00:51:19,820
and then

804
00:51:20,680 --> 00:51:23,080
if you look at the conditional probabilities of

805
00:51:23,630 --> 00:51:27,660
the data points going to any one of the existing components are

806
00:51:28,200 --> 00:51:29,520
another new components

807
00:51:31,140 --> 00:51:36,070
u assigned the data to one of the components looking at this conditional probability is

808
00:51:36,070 --> 00:51:39,500
basically a sample from a multinomial distribution with those properties

809
00:51:42,760 --> 00:51:44,360
so what are those properties

810
00:51:46,660 --> 00:51:47,400
so that they

811
00:51:48,630 --> 00:51:51,370
companies coming from the prior and the likelihood terms

812
00:51:51,880 --> 00:51:56,170
so the probability of assigning to components for which there are more than

813
00:51:57,620 --> 00:51:59,690
zero number of things that scientists

814
00:52:00,270 --> 00:52:05,590
going to one of the empty components musically is proportional to the number of things

815
00:52:05,690 --> 00:52:08,460
that belong to that component except u

816
00:52:09,020 --> 00:52:11,620
except that they point that's your something far now

817
00:52:12,140 --> 00:52:15,060
so this is what this notation means so you take out

818
00:52:15,650 --> 00:52:16,810
but i think the point

819
00:52:17,770 --> 00:52:21,740
from the complement that it belongs to so it may have belonged to decay are

820
00:52:21,740 --> 00:52:24,410
not we don't know that but if it is beyond indicated

821
00:52:25,670 --> 00:52:26,410
and by one

822
00:52:27,250 --> 00:52:28,170
if not we don't touch

823
00:52:29,400 --> 00:52:32,060
so so this term is coming from the prior

824
00:52:32,510 --> 00:52:33,620
and this is basically

825
00:52:34,690 --> 00:52:35,890
the probability of the data

826
00:52:36,320 --> 00:52:37,900
under that's component

827
00:52:39,130 --> 00:52:41,070
so how likely is it to observe the data

828
00:52:41,920 --> 00:52:43,250
given the complement parameter

829
00:52:44,910 --> 00:52:48,180
the probability of assigning to any component is basically

830
00:52:48,600 --> 00:52:49,750
proportional to alpha

831
00:52:50,150 --> 00:52:50,690
times this

832
00:52:51,230 --> 00:52:52,840
so this is basically the

833
00:52:53,510 --> 00:52:54,420
the probability of

834
00:52:55,350 --> 00:52:57,310
this comment this data point

835
00:52:57,760 --> 00:53:01,090
under this base distribution so you integrate out

836
00:53:01,480 --> 00:53:03,530
all data all parameters

837
00:53:04,080 --> 00:53:05,410
using the base distribution

838
00:53:07,090 --> 00:53:07,650
so this is

839
00:53:08,320 --> 00:53:11,990
can kind of coming from the likelihood term and this is coming from the

840
00:53:15,590 --> 00:53:16,610
we can we can do this

841
00:53:17,360 --> 00:53:22,960
so far the components that have been associated with them because they already have some parameters

842
00:53:24,230 --> 00:53:29,350
that are assigned to them and we need to do this we need to integrate out these parameters

843
00:53:31,480 --> 00:53:33,920
there are infinitely many of them and we cannot physically

844
00:53:34,990 --> 00:53:37,490
physically we cannot consider being assigned to

845
00:53:37,890 --> 00:53:40,560
every one of those in many cases right so

846
00:53:40,960 --> 00:53:42,110
this integral basically

847
00:53:42,590 --> 00:53:44,520
says i'm taking into account

848
00:53:45,070 --> 00:53:47,120
being assigned to any one of the possible

849
00:53:47,520 --> 00:53:48,180
infinitely many

850
00:53:50,340 --> 00:53:53,570
of course is proportional to how much mass the

851
00:53:54,620 --> 00:53:55,950
the base distribution gives

852
00:53:56,360 --> 00:53:56,940
to those

853
00:53:57,650 --> 00:53:58,690
those parameter values

854
00:54:02,100 --> 00:54:02,840
so we can also

855
00:54:03,800 --> 00:54:05,130
so it's a little differently

856
00:54:05,560 --> 00:54:06,470
so rather than

857
00:54:07,960 --> 00:54:15,750
knowing the parameter values end conditioning on the parameter values get the predictive value far the point under that

858
00:54:17,060 --> 00:54:18,100
the parameter value

859
00:54:19,000 --> 00:54:20,660
we can integrate this out

860
00:54:20,660 --> 00:54:21,960
the bayesian world

861
00:54:21,980 --> 00:54:26,350
so some of you have done bayesian stuff already

862
00:54:26,370 --> 00:54:33,670
right OK but you haven't so this a bayesian approach to statistics i told you

863
00:54:33,670 --> 00:54:40,060
before their frequentist and frequentists had this idea for you

864
00:54:40,060 --> 00:54:46,020
are principally in principle you're able to repeat experiments many times you're interested in sort

865
00:54:46,020 --> 00:54:50,370
of what happens on average and you want to be good on average and things

866
00:54:50,370 --> 00:54:51,270
like that

867
00:54:51,290 --> 00:54:56,210
they since have more the idea you see this data point you see it only

868
00:54:57,170 --> 00:54:58,810
and so

869
00:54:59,250 --> 00:55:04,190
and bayesians get this idea that everything you don't know

870
00:55:04,210 --> 00:55:07,160
should be treated with probabilities

871
00:55:07,350 --> 00:55:12,540
there is i can't speak too much about her philosophies i only know half of

872
00:55:13,480 --> 00:55:15,790
so maybe even less

873
00:55:15,850 --> 00:55:21,040
the lots of philosophy behind it why this might be a good approach though bayesians

874
00:55:26,460 --> 00:55:33,730
bayesians claim that there is a unique way of dealing with

875
00:55:34,370 --> 00:55:39,120
uncertainties and the unique way is

876
00:55:39,170 --> 00:55:43,930
giving numbers to uncertain things

877
00:55:43,940 --> 00:55:46,270
which sort of sum up to one

878
00:55:46,270 --> 00:55:50,040
and obey the laws of probability

879
00:55:50,080 --> 00:55:56,540
we're frequentist think well you can actually estimate these probabilities by repeating experiments many many

880
00:55:56,540 --> 00:56:01,560
times and then actually find out what is the true value for these probabilities but

881
00:56:01,560 --> 00:56:05,580
for bayesian it may make sense

882
00:56:05,600 --> 00:56:09,290
just simply to say i don't know but i think this one thing is more

883
00:56:10,750 --> 00:56:15,460
even if you can't actually repeat this experiment and just throw many

884
00:56:16,160 --> 00:56:18,560
dice are many coins

885
00:56:20,140 --> 00:56:24,430
so bayesian simply say there is a need for incorporating

886
00:56:24,440 --> 00:56:26,690
prior belief in the

887
00:56:26,710 --> 00:56:29,540
right way of doing it is asserting

888
00:56:29,830 --> 00:56:32,810
putting in probabilities for things that i don't know

889
00:56:32,830 --> 00:56:34,210
and you should

890
00:56:34,270 --> 00:56:38,020
the the probability for everything that you don't know

891
00:56:38,140 --> 00:56:42,600
but you shouldn't put in probabilities for things you don't you just actually know

892
00:56:42,600 --> 00:56:46,430
so the bayesian things in the following way let's say the bayesian does

893
00:56:46,440 --> 00:56:49,910
the toy in the coin tossing

894
00:56:50,910 --> 00:56:53,560
in a bayesian philosophy you say

895
00:56:53,560 --> 00:56:57,480
well what i don't know if the following thing so a sequence that's what i

896
00:56:57,480 --> 00:56:58,830
know of the data

897
00:56:58,850 --> 00:56:59,850
observe this

898
00:57:01,250 --> 00:57:06,330
but what i don't know is the parameter that generated the sequence so if i

899
00:57:06,330 --> 00:57:08,120
don't favor any

900
00:57:09,670 --> 00:57:11,120
specific data

901
00:57:11,140 --> 00:57:15,930
among others i could come up sort of with well i don't know

902
00:57:15,940 --> 00:57:20,640
and it's not actually write what i'm saying here but let's say it seems it

903
00:57:21,980 --> 00:57:26,160
more or less obvious but that for some reason untrue which maybe i can explain

904
00:57:26,160 --> 00:57:27,830
tomorrow why this

905
00:57:28,270 --> 00:57:32,330
well OK if i don't know maybe everything is equally probable

906
00:57:32,370 --> 00:57:36,120
seems to be a sensible way of of

907
00:57:36,120 --> 00:57:39,560
saying so you introduce the probability density

908
00:57:40,660 --> 00:57:47,940
you're unknown parameters theta which is let's say for simplicity uniform over zero one really

909
00:57:47,940 --> 00:57:50,960
don't know what might cause my

910
00:57:56,250 --> 00:58:01,910
before i have actually seen the data the prior distribution over parameters is all my

911
00:58:01,960 --> 00:58:06,750
prior knowledge that i have before i see any data

912
00:58:06,810 --> 00:58:10,500
and the maximum likelihood approach i only choose the model

913
00:58:10,540 --> 00:58:11,890
but i don't say

914
00:58:11,890 --> 00:58:17,520
which parameters i like more than others whereas in the bayesian world i say well there's some

915
00:58:17,520 --> 00:58:21,850
parameters that seem to be more likely than others

916
00:58:21,900 --> 00:58:25,560
but you could say well i mean i know that certain parameters you know i

917
00:58:25,560 --> 00:58:28,210
don't think ten thousand is really

918
00:58:29,710 --> 00:58:34,060
you know maybe it's is some some something in the physical world you know

919
00:58:34,140 --> 00:58:38,210
things are small things are big so we just before

920
00:58:38,230 --> 00:58:42,000
i know my parameter will be in a certain region

921
00:58:42,060 --> 00:58:45,910
in other regions are less and less probable

922
00:58:45,930 --> 00:58:47,790
so they since then do

923
00:58:47,830 --> 00:58:52,390
they use essentially bayes rule for reverting

924
00:58:54,000 --> 00:58:57,480
kind of like how cell structure

925
00:58:57,500 --> 00:59:04,130
so what you say well i know is the uncertainty about the parameter theta and

926
00:59:04,130 --> 00:59:08,190
i know what the probability of the data are when i know it

927
00:59:09,460 --> 00:59:12,000
the first thing gives me

928
00:59:12,000 --> 00:59:17,440
the the maximize the margin subject to constraints that the error on the training and

929
00:59:19,060 --> 00:59:23,200
maybe not large and something so this is about the number of training

930
00:59:23,910 --> 00:59:27,980
adaboost tries to make the training error zero

931
00:59:27,990 --> 00:59:32,680
OK so the extreme case then we maximize the margin now we say OK this

932
00:59:32,680 --> 00:59:34,540
should not be larger than something

933
00:59:34,570 --> 00:59:38,350
some constant and then we maximize speed

934
00:59:38,370 --> 00:59:43,850
OK so this is a discrete optimization problem might be some approximated

935
00:59:43,920 --> 00:59:47,110
and somehow this trade off by

936
00:59:47,190 --> 00:59:51,060
which is determined by a regularisation parameter

937
00:59:51,060 --> 00:59:57,500
OK christian for the six services

938
00:59:57,530 --> 01:00:02,280
this section is to

939
01:00:07,620 --> 01:00:09,100
so then

940
01:00:09,150 --> 01:00:13,490
let's go on two boosting and large margins

941
01:00:13,500 --> 01:00:18,440
so here have a lot of sources that's again shape you're trying this very important

942
01:00:19,180 --> 01:00:22,730
and also some important results by leo prime in nineteen nine

943
01:00:23,510 --> 01:00:30,390
then by christine bennett i and years and john shawe taylor and month and i

944
01:00:30,540 --> 01:00:35,170
also got some some results on that show you some results

945
01:00:35,240 --> 01:00:39,990
OK so you have seen this this picture so we have the input space and

946
01:00:39,990 --> 01:00:43,510
essentially this feature space is generated by the mapping phi

947
01:00:43,890 --> 01:00:48,540
so in this mapping phi is generated by the hypothesis space so every function in

948
01:00:48,540 --> 01:00:51,880
the hypothesis space is one-dimensional the feature space

949
01:00:51,920 --> 01:00:55,150
OK so and we get the linear i mean we have a linear separation if

950
01:00:55,150 --> 01:00:58,440
you just basing something on your input space

951
01:00:58,460 --> 01:01:00,080
OK so

952
01:01:00,120 --> 01:01:06,480
and you can essentially define the hyperplane which is simply five x times of of

953
01:01:06,740 --> 01:01:07,780
this redirect

954
01:01:07,820 --> 01:01:12,930
and you can simply write this in the finite dimensional we can simplify this industry

955
01:01:12,930 --> 01:01:16,660
so alpha j i h j x

956
01:01:16,680 --> 01:01:19,890
so this is simply are combined forces

957
01:01:19,890 --> 01:01:25,390
so in boosting the always use normalized combined process so we normalize these offices such

958
01:01:25,390 --> 01:01:28,040
that the one norm of the offices

959
01:01:28,330 --> 01:01:30,630
one so they these are the sum to one

960
01:01:30,650 --> 01:01:32,170
so essentially

961
01:01:32,180 --> 01:01:35,320
defined this as the margin

962
01:01:35,320 --> 01:01:38,050
and turns out that this

963
01:01:39,000 --> 01:01:40,150
it is actually

964
01:01:40,150 --> 01:01:42,210
the distance

965
01:01:42,220 --> 01:01:46,240
of these points to the hyperplane is not the

966
01:01:46,260 --> 01:01:51,690
the two distance like and support vector machines but it's the so-called l infinity distances

967
01:01:52,160 --> 01:01:55,150
these points to the hyperplane

968
01:01:57,300 --> 01:02:01,990
so this has been shown by maintaining history in nineteen ninety nine

969
01:02:02,760 --> 01:02:08,810
so the margin is simply the signed distance of the point to the hyperplane

970
01:02:12,670 --> 01:02:15,280
OK so let's come back to the weak learners

971
01:02:15,330 --> 01:02:20,600
so the learner uses this example weighting d one to d and and essentially the

972
01:02:20,600 --> 01:02:26,970
returns hypotheses h out of this hypothesis set which classifies these points into

973
01:02:27,030 --> 01:02:28,470
plus and minus one

974
01:02:28,490 --> 01:02:30,860
and those the

975
01:02:30,870 --> 01:02:37,170
learner returns hypotheses which is consistently better than random guessing essentially the weight training and

976
01:02:37,360 --> 01:02:40,070
that the number of the fraction of the

977
01:02:40,080 --> 01:02:44,310
i mean that's the mass of the DNC which are misclassified they should be smaller

978
01:02:44,310 --> 01:02:46,380
than half mile a half

979
01:02:47,490 --> 01:02:52,720
so this this formula only works when the function are really i mean plus minus

980
01:02:52,720 --> 01:02:57,540
one valued so there's another definition which be used

981
01:02:57,580 --> 01:03:02,750
real valued outputs for the hypothesis so then the output can be between minus one

982
01:03:05,090 --> 01:03:07,830
and then we define this quantity here

983
01:03:07,920 --> 01:03:11,450
and this is equivalent to this one

984
01:03:11,650 --> 01:03:16,100
so this this inequality is equivalent to this one so this quantity is called the

985
01:03:17,460 --> 01:03:19,700
so this is the way training error

986
01:03:19,710 --> 01:03:21,000
this is the edge

987
01:03:21,810 --> 01:03:27,190
we use the same quantities we use DNA one x and and just this product

988
01:03:27,190 --> 01:03:29,870
to the sum should be larger than come

989
01:03:29,920 --> 01:03:33,210
so if the weight training i was half

990
01:03:33,260 --> 01:03:36,860
OK then the action is zero

991
01:03:36,870 --> 01:03:40,250
just a different formulation

992
01:03:40,280 --> 01:03:42,360
so i say this is the edge of

993
01:03:42,390 --> 01:03:44,030
the function h

994
01:03:44,170 --> 01:03:48,340
OK so

995
01:03:48,360 --> 01:03:55,150
so we can also define the edge of the weak learner so for certain probability

996
01:03:55,150 --> 01:03:57,190
vectors of some beating d

997
01:03:57,240 --> 01:03:59,640
that is p

998
01:03:59,680 --> 01:04:04,460
best function which you can generate so the best age so this maximizing

999
01:04:04,570 --> 01:04:08,290
the it's maximizing function so he the x for all eight

1000
01:04:08,330 --> 01:04:12,420
OK and we try to maximize this match for the given rating

1001
01:04:12,470 --> 01:04:16,650
OK so and if the base is minimizing weight training

1002
01:04:16,660 --> 01:04:19,480
then actually maximizing the set

1003
01:04:19,490 --> 01:04:22,750
OK this

1004
01:04:22,800 --> 01:04:27,540
so i've already defined the margin for the combined is just a rule of thumb

1005
01:04:27,830 --> 01:04:30,430
it's just this quantity here

1006
01:04:31,050 --> 01:04:34,780
now you might ask what is the connection between these two with edge and this

1007
01:04:34,780 --> 01:04:40,390
margin and is actually a very old hearing by for nine months in

1008
01:04:40,410 --> 01:04:41,660
o thing nineteen

1009
01:04:41,670 --> 01:04:45,110
nineteen twenty eight he proved the minimax theory

1010
01:04:45,330 --> 01:04:51,010
that is essentially relating these two quantities so the scum of the draw of and

1011
01:04:51,010 --> 01:04:52,000
it says

1012
01:04:52,060 --> 01:04:53,790
that he

1013
01:04:56,460 --> 01:04:59,830
OK of all distributions d

1014
01:05:00,890 --> 01:05:02,870
is equal to the maximum

1015
01:05:02,880 --> 01:05:05,230
margin of all

1016
01:05:05,290 --> 01:05:06,820
OK so

1017
01:05:06,900 --> 01:05:10,950
for somehow determining the margin of the training points to the minimum margin of all

1018
01:05:10,990 --> 01:05:12,480
training points

1019
01:05:12,490 --> 01:05:14,950
OK and this is the best found

1020
01:05:14,970 --> 01:05:16,390
maximizing the margin

1021
01:05:16,450 --> 01:05:19,970
and that is equivalent to finding the distribution

1022
01:05:20,090 --> 01:05:25,260
so finding some of the most difficult distribution such that the base learner cannot return

1023
01:05:26,250 --> 01:05:28,570
with a very large set

1024
01:05:33,760 --> 01:05:38,200
so if you can show that the base learner always returns

1025
01:05:38,240 --> 01:05:43,890
a function which has an edge so come off he is at least some constant

1026
01:05:45,010 --> 01:05:49,200
then we can then we already know from this this theory is that the marginal

1027
01:05:49,200 --> 01:05:51,070
must be at least

1028
01:05:51,090 --> 01:05:55,760
OK this is direct it follows from this theory

1029
01:05:55,760 --> 01:05:58,820
take the expectation with respect to the next state

1030
01:05:58,870 --> 01:06:00,920
so there's like one step lookahead

1031
01:06:01,860 --> 01:06:04,900
so if this one step lookahead

1032
01:06:04,920 --> 01:06:06,290
can return

1033
01:06:06,290 --> 01:06:08,470
as better value

1034
01:06:08,500 --> 01:06:11,290
that we have a particular state

1035
01:06:11,300 --> 01:06:12,820
just one state

1036
01:06:12,870 --> 01:06:14,360
then what we get

1037
01:06:14,380 --> 01:06:17,440
is is the policy that strictly better

1038
01:06:17,460 --> 01:06:22,300
so this procedure should converge on the finite number of steps

1039
01:06:22,310 --> 01:06:27,060
in the finite and the like if you have finite states and actions

1040
01:06:27,110 --> 01:06:33,150
and actually you can show that the number of iterations required by this procedure two

1041
01:06:33,200 --> 01:06:40,250
VHS certain precision is is not greater than the number of iterations required

1042
01:06:41,120 --> 01:06:43,580
value iteration

1043
01:06:44,380 --> 01:06:45,110
this is

1044
01:06:45,110 --> 01:06:49,150
sort of faster process on the other hand

1045
01:06:49,170 --> 01:06:51,840
OK so how does this target merck so

1046
01:06:51,840 --> 01:06:56,100
the if you want to make an article of their own without this

1047
01:06:56,110 --> 01:06:56,870
is that

1048
01:06:56,890 --> 01:06:58,960
what you do is you take the policy

1049
01:06:58,970 --> 01:07:01,330
some policy or guess

1050
01:07:01,330 --> 01:07:03,640
you compute its value functions

1051
01:07:03,700 --> 01:07:07,420
and then you greedy five suspected device functions you compute the

1052
01:07:07,430 --> 01:07:11,160
the greedy policy was respected by function

1053
01:07:11,170 --> 01:07:14,830
and then again you compute the value function of the new policy and then you

1054
01:07:14,830 --> 01:07:19,250
repeat this procedure indefinitely so that's the the policy

1055
01:07:19,290 --> 01:07:22,580
improvement of policy iteration are given

1056
01:07:22,590 --> 01:07:28,590
and so the number of iterations required five five policy iteration is never greater than

1057
01:07:28,590 --> 01:07:31,230
the number of iterations required by

1058
01:07:31,250 --> 01:07:32,380
in addition

1059
01:07:32,440 --> 01:07:35,360
but this is not a surprise

1060
01:07:36,460 --> 01:07:43,390
everything the policy here requires matrix inversion so it's it's a much more expensive process

1061
01:07:43,410 --> 01:07:46,900
then just apply the battle operator to a function

1062
01:07:47,010 --> 01:07:52,460
for some people believe that if you have the state space of size and then

1063
01:07:52,460 --> 01:07:53,450
this is

1064
01:07:54,010 --> 01:07:55,320
and times

1065
01:07:55,330 --> 01:08:01,330
more powerful two exactly n times more powerful

1066
01:08:01,380 --> 01:08:04,770
two to have a the policy and good if i

1067
01:08:04,780 --> 01:08:05,790
so if you come

1068
01:08:05,810 --> 01:08:10,460
if you compare the computational complexity of of this target and this makes sense

1069
01:08:10,690 --> 01:08:15,400
the other hand it turns out that we don't know exactly how many iterations are

1070
01:08:15,400 --> 01:08:17,690
required in policy improvement

1071
01:08:17,750 --> 01:08:21,730
and this is an open question if if you can

1072
01:08:21,750 --> 01:08:25,020
really have

1073
01:08:25,220 --> 01:08:28,290
and our given four and the p

1074
01:08:28,330 --> 01:08:30,970
who is computational complexity

1075
01:08:31,070 --> 01:08:35,390
i was careful and that is the number of bits required to describe b and

1076
01:08:35,390 --> 01:08:38,250
the number of states and actions

1077
01:08:38,270 --> 01:08:44,410
and in particular is the number of bits required to describe the discon factors

1078
01:08:44,470 --> 01:08:45,370
if you

1079
01:08:45,410 --> 01:08:50,310
things the discount factor analysis in this polynomial everything is fine but if the discount

1080
01:08:50,310 --> 01:08:52,930
factor is an input then you get this

1081
01:08:52,960 --> 01:08:56,800
dependence on the this factors so the number of iterations

1082
01:08:57,750 --> 01:08:59,820
as the this called factor

1083
01:08:59,950 --> 01:09:03,280
is is getting closer to one so

1084
01:09:03,330 --> 01:09:09,350
the number of iterations is typically vulnerable minors gamma times maybe log

1085
01:09:09,370 --> 01:09:11,080
of the same quantity

1086
01:09:11,130 --> 01:09:14,950
so there is that because the complexity of the target started to become number of

1087
01:09:16,860 --> 01:09:19,630
so anyway it's an open question and

1088
01:09:19,770 --> 01:09:23,320
and this has been an open question since the sixties so if you want to

1089
01:09:23,320 --> 01:09:25,500
become really famous

1090
01:09:25,510 --> 01:09:31,800
in control and reinforcement learning all spheres and this this question

1091
01:09:31,970 --> 01:09:35,060
should be

1092
01:09:35,110 --> 01:09:38,360
so the policy iteration are given bad out here

1093
01:09:39,030 --> 01:09:42,070
you have some initial policy

1094
01:09:43,790 --> 01:09:47,160
you have only appeared and you start its value function

1095
01:09:47,190 --> 01:09:48,920
in b prime

1096
01:09:48,930 --> 01:09:51,340
and then you'll

1097
01:09:51,370 --> 01:09:55,730
sold forty the greedy policy we suspect to the

1098
01:09:55,770 --> 01:09:58,850
and then finally to value function it can be

1099
01:09:58,860 --> 01:10:03,270
and then your computer if you compare the end the prime so if you've got

1100
01:10:03,270 --> 01:10:05,370
something bigger

1101
01:10:06,820 --> 01:10:12,320
then you still have has iterate otherwise against

1102
01:10:12,330 --> 01:10:14,170
that should be easy

1103
01:10:14,930 --> 01:10:19,610
the reason the are concert this all stop is because the mother target inside all

1104
01:10:19,610 --> 01:10:21,780
around is also

1105
01:10:21,840 --> 01:10:24,580
i will be adding also

1106
01:10:24,620 --> 01:10:30,770
OK so this just bad all the policy iteration resides in finite mdps can

1107
01:10:30,770 --> 01:10:33,770
and the optimal policies after a finite number of steps

1108
01:10:33,780 --> 01:10:35,290
it should be easy

1109
01:10:35,340 --> 01:10:38,310
so dynamic programming i guess

1110
01:10:38,320 --> 01:10:42,310
in the interests of seeing some time i'm going to skip that

1111
01:10:42,320 --> 01:10:44,350
what happens is that

1112
01:10:45,520 --> 01:10:49,170
if you think a little bit you can set up elena programs such that the

1113
01:10:49,170 --> 01:10:52,750
solution of the linear programme which is the optimal value function

1114
01:10:52,800 --> 01:10:56,100
and that these things on slice if you are interested in the does come to

1115
01:10:57,130 --> 01:10:58,460
the brig

1116
01:11:00,040 --> 01:11:01,140
and so

1117
01:11:01,190 --> 01:11:07,400
this is yet another way of finding an optimal value function and

1118
01:11:07,420 --> 01:11:08,900
and this is actually the way

1119
01:11:08,900 --> 01:11:14,480
people proved that these are giddens a polynomial complexity in the size of the state

1120
01:11:14,480 --> 01:11:18,250
and action spaces

1121
01:11:19,110 --> 01:11:22,630
some variations of the team so

1122
01:11:22,630 --> 01:11:25,060
moving to arts learning processes

1123
01:11:25,060 --> 01:11:29,190
so we that we are going to concentrate learning processes

1124
01:11:29,250 --> 01:11:31,920
we cannot hope to be able to have two

1125
01:11:32,000 --> 01:11:36,770
just axe acute the value iteration in exactly right

1126
01:11:36,790 --> 01:11:40,460
so that the the errors introduced in every time so maybe we are going to

1127
01:11:40,460 --> 01:11:45,710
use samples so what the procedure we are going to use function approximation

1128
01:11:47,170 --> 01:11:50,920
represent value function so huge state spaces

1129
01:11:50,960 --> 01:11:56,560
they are doing that introducing errors in our iterations question is if those editors can

1130
01:11:56,560 --> 01:11:58,440
screw up and

1131
01:11:59,290 --> 01:12:01,210
one way of looking at this

1132
01:12:01,210 --> 01:12:02,900
is two

1133
01:12:02,920 --> 01:12:06,190
so that the following iterations to the next iteration

1134
01:12:07,520 --> 01:12:12,270
almost the same thing as seen value addition you have the band operator applied to

1135
01:12:12,290 --> 01:12:13,460
the fk

1136
01:12:13,540 --> 01:12:16,270
plus some additive better

1137
01:12:16,290 --> 01:12:18,580
the way to sink about the same

1138
01:12:18,600 --> 01:12:24,380
is that you have your favourite battled after after some including value iteration OK

1139
01:12:24,400 --> 01:12:26,810
so that they come up with vague

1140
01:12:26,920 --> 01:12:29,060
the off cape last one

1141
01:12:29,940 --> 01:12:32,900
so the difference between the FP plus one

1142
01:12:32,900 --> 01:12:35,550
because we we could always multiply

1143
01:12:35,560 --> 01:12:37,810
one is j by

1144
01:12:37,820 --> 01:12:44,760
so for example and then divide the corresponding coefficients AIJ by two and that wouldn't

1145
01:12:44,760 --> 01:12:47,300
change the observations at all

1146
01:12:47,310 --> 01:12:49,090
but of course that's not very

1147
01:12:49,100 --> 01:12:53,310
mysterious thing it just means that well we don't know actually the scale of these

1148
01:12:53,320 --> 01:12:57,840
latent variables and we don't know the signs they might be multiplied by minus one

1149
01:12:58,180 --> 01:13:00,800
and that doesn't really we don't really know

1150
01:13:00,820 --> 01:13:05,730
which signed we should take that in most applications not very

1151
01:13:07,170 --> 01:13:13,360
and then in inconsistent to techniques like principal component analysis these independent companies don't really

1152
01:13:13,360 --> 01:13:17,390
have any intrinsic order so in principle component of this we say that we have

1153
01:13:17,390 --> 01:13:23,250
the first second third principal components but here we have nothing like that

1154
01:13:23,270 --> 01:13:24,960
so once we

1155
01:13:24,970 --> 01:13:27,540
once we make these assumptions here

1156
01:13:27,550 --> 01:13:32,060
then actually it can be proven that we can recover

1157
01:13:32,080 --> 01:13:33,380
we can recover

1158
01:13:33,390 --> 01:13:38,130
the independent components that is we can estimate the i j

1159
01:13:38,150 --> 01:13:43,110
up to these these and indeterminate is that i just mentioned and we can estimate

1160
01:13:43,110 --> 01:13:48,950
an inventor system and estimate the independent components up to this in in the middle

1161
01:13:48,970 --> 01:13:55,150
and this is something that that you can do with PCA of classical factor analysis

1162
01:13:55,150 --> 01:14:00,950
of well any other well known any other classical methods that this is ICASSP

1163
01:14:01,810 --> 01:14:07,610
well basically this the first way of estimating these kind of linear latent variables model

1164
01:14:09,360 --> 01:14:13,330
people have tried to do it for one hundred years but it was not until

1165
01:14:13,350 --> 01:14:17,810
let let let's say the late eighties that people really understood how it can be

1166
01:14:19,470 --> 01:14:23,420
so people for example try to estimate this kind of model by PCA

1167
01:14:23,440 --> 01:14:26,180
for a a long time and i thought that PCA

1168
01:14:26,200 --> 01:14:27,260
kind of

1169
01:14:27,300 --> 01:14:33,010
estimate this kind of model is that it really doesn't it doesn't do it properly

1170
01:14:33,030 --> 01:14:37,270
actually well i should say that it doesn't work properly actually does it it doesn't

1171
01:14:37,270 --> 01:14:39,630
do it really at all

1172
01:14:42,280 --> 01:14:45,200
the question is that how can we actually have an

1173
01:14:45,210 --> 01:14:48,200
estimates these independent components

1174
01:14:48,210 --> 01:14:51,040
but the mixing matrix

1175
01:14:53,470 --> 01:14:57,370
this is the first thing that you might think about this that well if the

1176
01:14:57,370 --> 01:15:04,010
independent components are independent they are OK they are they are by definition independent then

1177
01:15:04,010 --> 01:15:10,110
we could try to find some kind of a linear transformation that makes these that

1178
01:15:10,110 --> 01:15:14,370
gives us as independent variables as possible so

1179
01:15:24,490 --> 01:15:33,900
so what we know is that

1180
01:15:34,580 --> 01:15:37,500
x is a linear transformation of

1181
01:15:37,520 --> 01:15:39,960
the random vector is

1182
01:15:40,000 --> 01:15:44,160
and now what we could just try to make find some kind of

1183
01:15:44,220 --> 01:15:46,210
matrix w

1184
01:15:48,880 --> 01:15:55,440
because just try to find a matrix w multiply x by and then

1185
01:15:55,790 --> 01:15:58,110
look at the statistical properties and y

1186
01:15:58,190 --> 01:16:02,910
now since we know that there is i independent statistically because think that once we

1187
01:16:02,910 --> 01:16:04,180
find w

1188
01:16:04,230 --> 01:16:09,910
that gives us independent component is that once we find w such that all the

1189
01:16:10,120 --> 01:16:16,020
ln the components in why are all independent then perhaps we have recovered this

1190
01:16:16,030 --> 01:16:19,240
but actually it turns out that is true

1191
01:16:19,590 --> 01:16:24,370
so we this is the well this is one of the basic methods of estimating

1192
01:16:24,370 --> 01:16:29,160
ICA but it's just you know it is only very theoretical methods because the method

1193
01:16:29,160 --> 01:16:33,870
for the measurement of the independence of these components is then another question how you

1194
01:16:33,870 --> 01:16:38,740
measure the independent the independent some of these estimates components well we will see in

1195
01:16:38,740 --> 01:16:43,250
one that you can figure out something like that but the first thing that people

1196
01:16:43,250 --> 01:16:47,060
usually try to do is to find a matrix

1197
01:16:47,080 --> 01:16:52,660
that the problem that is the correlation matrix that is it transforms x so that

1198
01:16:52,660 --> 01:16:54,640
these components y

1199
01:16:54,660 --> 01:16:56,540
are uncorrelated

1200
01:16:56,560 --> 01:17:00,120
well the reason why people usually think about this is that this idea of the

1201
01:17:00,120 --> 01:17:04,870
correlation is very old one and it's it's very easy thing to do

1202
01:17:07,260 --> 01:17:14,440
well i was talking about PCA i mentioned that PCA gives uncorrelated components is the

1203
01:17:14,440 --> 01:17:18,730
principal components are uncorrelated

1204
01:17:18,880 --> 01:17:22,710
so there are many different ways so it is easy to find this kind of

1205
01:17:22,710 --> 01:17:23,650
the w

1206
01:17:23,670 --> 01:17:27,080
but the problem is that while most of them are completely wrong

1207
01:17:27,140 --> 01:17:32,610
well there are many different ways of of there are many different matrices that give

1208
01:17:32,610 --> 01:17:36,450
us that's it x and well

1209
01:17:36,460 --> 01:17:43,070
we really need some more information on how to on on which one of those

1210
01:17:43,070 --> 01:17:44,550
we really want to find

1211
01:17:44,680 --> 01:17:51,640
so typically nice context ICA we talk about whether it was closest

1212
01:17:51,640 --> 01:17:57,910
two days you have to check if you compare the dataset you are going to

1213
01:17:57,910 --> 01:18:00,640
do something like the results of the one

1214
01:18:00,650 --> 01:18:03,840
this is where the other people and then compare so you do

1215
01:18:04,270 --> 01:18:09,250
some nations and abstractions when you define this you have to be sure that this

1216
01:18:09,250 --> 01:18:13,890
image is actions make sense that you are not adding apples with oranges

1217
01:18:14,180 --> 01:18:16,710
comparing it across the sets

1218
01:18:16,740 --> 01:18:20,790
yes that's something to keep in mind before anything else that you want to say

1219
01:18:20,790 --> 01:18:24,460
about the this like properties of the data distribution and so on

1220
01:18:24,480 --> 01:18:33,510
it and its algebraic properties like operations make sense this thing that computer

1221
01:18:33,520 --> 01:18:36,430
and then describe two distances

1222
01:18:36,440 --> 01:18:42,820
i don't know until after the support operations that makes sense

1223
01:18:42,820 --> 01:18:51,300
no this is your compute your between two clusterings shown is that the confusion matrix

1224
01:18:51,520 --> 01:18:53,320
and this is the matrix

1225
01:18:53,340 --> 01:18:55,210
this matrix

1226
01:18:55,300 --> 01:19:03,020
that represent so you have to clusterings one with k clusters and one with k

1227
01:19:04,060 --> 01:19:07,380
you don't have to the the same number of clusters because as you can

1228
01:19:07,550 --> 01:19:09,800
two british

1229
01:19:09,820 --> 01:19:15,940
and cape cape this number is the number of points that in the intersection of

1230
01:19:16,000 --> 01:19:18,240
all cluster k

1231
01:19:18,250 --> 01:19:19,940
in the first clustering with

1232
01:19:19,940 --> 01:19:23,570
another classification right in the second

1233
01:19:23,870 --> 01:19:27,710
and so use of intersection and

1234
01:19:27,790 --> 01:19:33,300
obviously this matrix is diagonal then the clustering is identical but if in general the

1235
01:19:33,680 --> 01:19:39,620
most relevant to be non-zero many elements within

1236
01:19:39,630 --> 01:19:43,110
of course that's sum all the elements in m is equal to the number of

1237
01:19:43,110 --> 01:19:45,740
points and and if i by

1238
01:19:45,770 --> 01:19:48,200
this intersection by the number of points again

1239
01:19:48,290 --> 01:19:53,200
something matrix with entries from one and i denoted by p

1240
01:19:53,210 --> 01:19:55,670
it reminds me it would be interpreted as

1241
01:19:55,690 --> 01:19:59,290
probability matrix explain or the probability distribution

1242
01:19:59,300 --> 01:20:05,510
whose entries are this PKK which are the probability of

1243
01:20:05,650 --> 01:20:07,990
the point being in the intersection of

1244
01:20:08,040 --> 01:20:16,340
OK cluster candcluster seaplane prime is sampled uniformly because among all the

1245
01:20:17,170 --> 01:20:20,670
and of course there are some conditions like that of some sort of the confusion

1246
01:20:20,670 --> 01:20:22,170
matrix are

1247
01:20:22,180 --> 01:20:25,360
the size of the clusters

1248
01:20:25,370 --> 01:20:28,580
and the column sums up the size of the clusters and that clustering

1249
01:20:28,590 --> 01:20:33,500
and so on just the natural functions

1250
01:20:33,560 --> 01:20:37,320
now we are ready to define the first

1251
01:20:37,380 --> 01:20:38,830
this is sort the

1252
01:20:38,930 --> 01:20:42,560
we have to make it a little technical assumption that

1253
01:20:42,560 --> 01:20:43,380
we put

1254
01:20:43,390 --> 01:20:45,140
smaller clustering first

1255
01:20:45,230 --> 01:20:50,190
however this is commutative so it's not it's not a strong this other constraints

1256
01:20:50,190 --> 01:20:52,950
major innovations

1257
01:20:52,980 --> 01:20:57,040
if you insist that you have already seen this distance

1258
01:20:57,050 --> 01:20:59,800
this is followed by the matching so

1259
01:20:59,820 --> 01:21:04,260
i mean i the permutation of the labels

1260
01:21:04,320 --> 01:21:06,580
so i

1261
01:21:06,590 --> 01:21:10,500
i changed the labels of the clustering that much

1262
01:21:10,510 --> 01:21:12,300
i mentioned

1263
01:21:12,360 --> 01:21:13,270
the the label

1264
01:21:13,290 --> 01:21:19,260
clusters in one clustering with the clusters that clustering and then look at the best

1265
01:21:19,260 --> 01:21:24,250
on the diagonal matrix the probability mass on the diagonal that is this pk

1266
01:21:24,300 --> 01:21:25,630
of k

1267
01:21:25,630 --> 01:21:27,190
after permuting the rows

1268
01:21:27,190 --> 01:21:29,390
the thing to do that

1269
01:21:31,700 --> 01:21:35,860
that is the total match between the two clusterings under experimentation

1270
01:21:35,940 --> 01:21:40,200
what is left one minus is quantity the mismatch the permutations

1271
01:21:40,370 --> 01:21:45,770
and the distance i define is the smallest possible mismatch

1272
01:21:45,790 --> 01:21:50,240
and the role of limitations

1273
01:21:50,290 --> 01:21:54,820
and it's very related to what to do for classification except for optimizing over label

1274
01:21:54,820 --> 01:22:01,550
permutations that's why i call it the misclassification distance me

1275
01:22:11,890 --> 01:22:14,510
so what can i computing

1276
01:22:14,520 --> 01:22:19,690
yes it can be computed in polynomial time because finding a matching so you would

1277
01:22:20,420 --> 01:22:27,030
all the permutations that k factorial permutations that's not the naive algorithm will not be

1278
01:22:27,030 --> 01:22:31,530
very efficient in general but there is much more efficient algorithms based on linear programming

1279
01:22:31,560 --> 01:22:34,460
it's called the hungarian or

1280
01:22:34,560 --> 01:22:38,720
bipartite matching algorithm that solves this problem

1281
01:22:38,730 --> 01:22:45,270
also you know notice that it is the permutation then this distance is

1282
01:22:45,320 --> 01:22:49,680
the hamming distance is related the number of all points in which the labels that

1283
01:22:51,930 --> 01:22:53,360
divided by

1284
01:22:53,370 --> 01:22:54,950
to make matters even

1285
01:22:55,150 --> 01:22:59,760
also note fifty is one so it's sort of the probabilities and probability

1286
01:22:59,920 --> 01:23:02,800
the classification error on

1287
01:23:02,890 --> 01:23:04,950
if you think of classification

1288
01:23:05,060 --> 01:23:09,470
the less obvious but still i think is that this is a metric it all

1289
01:23:09,480 --> 01:23:12,200
the time one

1290
01:23:12,700 --> 01:23:18,050
why is triangle inequality important because says that i two clustering so close so

1291
01:23:18,090 --> 01:23:19,820
the two and that three

1292
01:23:19,940 --> 01:23:24,270
both close to the one that they can be too far from each other

1293
01:23:24,440 --> 01:23:27,990
that's all the time the inequality signify

1294
01:23:28,050 --> 01:23:34,210
and it's it's very useful in many applications was the use of it later this

1295
01:23:35,970 --> 01:23:40,110
however there is the problem with this misclassification

1296
01:23:40,120 --> 01:23:44,110
this is is great and very interpretable

1297
01:23:44,120 --> 01:23:48,360
if the clusterings are very senior it's small

1298
01:23:48,370 --> 01:23:51,870
actually in computer science almost everybody reinvents this this

1299
01:23:51,930 --> 01:23:54,450
not so so much statistics because they they have

1300
01:23:54,470 --> 01:23:59,520
prior they have other distances but computers and people just renamed it all the time

1301
01:23:59,530 --> 01:24:02,930
so it comes under many names

1302
01:24:02,960 --> 01:24:07,170
OK so what's the problem with this distance is large

1303
01:24:07,180 --> 01:24:10,740
well if the distance is large is

1304
01:24:11,230 --> 01:24:15,570
if k is large which means that is more likely that the clusterings are different

1305
01:24:15,830 --> 01:24:18,180
than the mismatch will be small

1306
01:24:18,220 --> 01:24:20,440
or the matching this small

1307
01:24:20,580 --> 01:24:23,860
by definition this is lower dimensional small

1308
01:24:23,890 --> 01:24:29,210
and this is only cares about how many points are measured doesn't care what happens

1309
01:24:29,230 --> 01:24:31,270
to them especially

1310
01:24:31,280 --> 01:24:38,230
however we may want to care about it and let me show you an example

1311
01:24:45,100 --> 01:24:47,610
i changed want to do that i can change it to the

1312
01:24:49,150 --> 01:24:56,590
the misclassification error says these two are about the same distance from the

1313
01:24:56,600 --> 01:24:59,950
because the mass the number of match points is the the same

1314
01:25:00,010 --> 01:25:03,190
however you may seen here

1315
01:25:03,240 --> 01:25:06,490
this group of your points is all read

1316
01:25:06,510 --> 01:25:11,990
whereas he this group popular point has to be in two different colors red and

1317
01:25:12,070 --> 01:25:13,700
equally likely

1318
01:25:13,700 --> 01:25:18,580
but there

1319
01:25:43,380 --> 01:25:46,780
so are

1320
01:25:59,140 --> 01:26:01,860
so now

1321
01:26:38,860 --> 01:26:42,360
very important for us

1322
01:26:58,240 --> 01:27:01,390
o down so

1323
01:27:24,700 --> 01:27:27,840
of them

1324
01:27:32,630 --> 01:27:36,880
and you

1325
01:27:37,100 --> 01:27:39,760
right show

1326
01:27:50,620 --> 01:27:57,750
well over one

1327
01:27:57,770 --> 01:28:04,530
o twenty

1328
01:28:23,410 --> 01:28:28,060
got the idea of you might be

1329
01:28:35,120 --> 01:28:36,660
so we now

1330
01:28:53,820 --> 01:28:57,990
in the u

1331
01:29:08,500 --> 01:29:11,200
that same

1332
01:29:28,640 --> 01:29:32,440
people are

1333
01:29:41,760 --> 01:29:47,250
the problem

1334
01:29:47,250 --> 01:29:51,650
it is interesting to hear what they did is they actually live the second year

1335
01:29:51,650 --> 01:29:52,460
on it

1336
01:29:52,470 --> 01:29:54,690
which given an input patch

1337
01:29:54,700 --> 01:29:58,120
besides we how to oriented so that it can run

1338
01:29:58,150 --> 01:29:59,700
the real detector

1339
01:30:00,000 --> 01:30:04,500
now turns out to work quite well they get sixty three sixty degree rotation invariance

1340
01:30:04,580 --> 01:30:11,760
the detector and if it would take to on top of

1341
01:30:13,260 --> 01:30:18,370
yet another convolutional neural net thing here this is the face detector again produced by

1342
01:30:18,370 --> 01:30:20,230
the group made the first network

1343
01:30:20,240 --> 01:30:22,780
and it's interesting

1344
01:30:22,840 --> 01:30:27,240
in that it's in multiview detector so detect your face

1345
01:30:27,500 --> 01:30:29,490
essentially any orientation

1346
01:30:29,510 --> 01:30:32,170
and it's in a single neuron it

1347
01:30:32,190 --> 01:30:34,440
which is quite hard to figure out how to do

1348
01:30:34,460 --> 01:30:39,100
so there's a little bit of complexity and figuring out exactly the way to do

1349
01:30:39,100 --> 01:30:41,540
this in the learning process and the way they did

1350
01:30:41,670 --> 01:30:43,600
was that they

1351
01:30:43,680 --> 01:30:46,260
first of all code orientations of ever

1352
01:30:46,260 --> 01:30:49,130
training set has orientations of faces and

1353
01:30:49,200 --> 01:30:54,820
and they code those orientations as unit vectors in some high dimensional space so typically

1354
01:30:54,880 --> 01:30:59,320
you simply say well is it in the section of the right was looking at

1355
01:30:59,320 --> 01:31:01,750
this particular angles also call

1356
01:31:01,790 --> 01:31:05,960
looking straight forward things like this you this whole series of different things at least

1357
01:31:05,960 --> 01:31:10,760
nine dimensional space here and he simply can make the unit vector out where my

1358
01:31:10,760 --> 01:31:14,350
twenty two in the space that's that's very easy to do and what you've got

1359
01:31:14,350 --> 01:31:20,930
these unit vectors the system actually is trained with the input image and non pose

1360
01:31:21,260 --> 01:31:26,840
and in fact also with face and all the things looking at so so it

1361
01:31:26,850 --> 01:31:30,380
using information you don't normally have when you're running the detector

1362
01:31:30,410 --> 01:31:35,170
to do the training and to find a good way of finding this angular response

1363
01:31:35,180 --> 01:31:37,250
out so i said you know data here

1364
01:31:37,260 --> 01:31:41,030
so you have you know that code faces and then zero for nonfaces sitting in

1365
01:31:41,030 --> 01:31:45,990
the central these unit vectors so typically list space something looks like the more minutes

1366
01:31:46,010 --> 01:31:49,900
there will be more like a face in some unit vector which points in the

1367
01:31:49,900 --> 01:31:51,610
right direction to the orientation

1368
01:31:51,670 --> 01:31:56,040
OK and the way use this thing is that because you initially trained with an

1369
01:31:56,040 --> 01:31:59,860
orientation you actually have to do search of orientations but that's a fairly quick gradients

1370
01:32:00,760 --> 01:32:04,870
so it can be done essentially in real time so this detector works in real

1371
01:32:05,920 --> 01:32:10,170
it is one of the more rotation invariant

1372
01:32:10,180 --> 01:32:11,050
it was

1373
01:32:14,170 --> 01:32:16,160
most of the

1374
01:32:21,840 --> 01:32:25,990
it has very good resistance to inclusion this is running individual image by individual image

1375
01:32:25,990 --> 01:32:29,020
has no temporal smoothing anything here

1376
01:32:29,030 --> 01:32:31,040
it's still quite smooth

1377
01:32:41,450 --> 01:32:44,250
on another approach human state

1378
01:32:44,470 --> 01:32:47,560
so this is based on local features

1379
01:32:47,630 --> 01:32:50,520
and what is going to do is is going to try to

1380
01:32:50,520 --> 01:32:52,500
use local tissues

1381
01:32:53,460 --> 01:32:56,060
some kind of interest points to case

1382
01:32:56,090 --> 01:32:59,660
i found the image so will take the image will calculate interest points

1383
01:32:59,700 --> 01:33:02,490
everywhere some of them will happen to line people

1384
01:33:02,500 --> 01:33:07,050
and will try to use the local appearance are the ones that haven't line people

1385
01:33:07,050 --> 01:33:08,560
is cues to kind of

1386
01:33:08,590 --> 01:33:11,520
bootstrap itself into voting process

1387
01:33:11,620 --> 01:33:17,590
to find the positions of the person so it knows on the training set what

1388
01:33:17,590 --> 01:33:21,630
kinds of interest points who produced and what the silhouette of the person was one

1389
01:33:22,180 --> 01:33:26,180
for the training set from that it has a kind of probabilistic model season interest

1390
01:33:26,180 --> 01:33:31,090
point knows roughly where person might be it's very fuzzy model what's in a couple

1391
01:33:31,090 --> 01:33:35,600
of interest points models start getting more and more precise until it can make kind

1392
01:33:35,600 --> 01:33:39,580
of segmentation of the person that based on this interest points

1393
01:33:40,430 --> 01:33:41,520
it can also

1394
01:33:41,540 --> 01:33:44,780
and occlusions and things like that by by figuring out

1395
01:33:44,800 --> 01:33:48,150
kind of assigning

1396
01:33:48,520 --> 01:33:52,880
interest points to a particular person models attracting that model and looking for other things

1397
01:33:54,350 --> 01:33:59,000
so this is actually fairly good performance and the model is not as good as

1398
01:33:59,660 --> 01:34:03,000
the simplest being modelled i talked about

1399
01:34:03,010 --> 01:34:04,260
a while ago

1400
01:34:04,350 --> 01:34:07,110
but it contains a lot richer information so

1401
01:34:08,520 --> 01:34:11,460
it's able to to tell you a lot more about the scene to deal with

1402
01:34:11,460 --> 01:34:14,200
things like inclusions with one count

1403
01:34:14,280 --> 01:34:19,000
OK so that's what i'm going to talk about object recognition

1404
01:34:19,000 --> 01:34:20,320
o to detection

1405
01:34:20,840 --> 01:34:24,370
but there's a whole series of other things you might want to do with images

1406
01:34:24,370 --> 01:34:25,260
of people

1407
01:34:25,270 --> 01:34:28,900
for example build some model of how they vary

1408
01:34:29,310 --> 01:34:32,960
if the person is walking they have characteristic notion

1409
01:34:32,970 --> 01:34:38,550
this is changing expression of characteristic things so there's the a whole set of the

1410
01:34:38,550 --> 01:34:44,550
learning methods involved in learning some kinds of models for variation articulation or human pose

1411
01:34:44,560 --> 01:34:47,090
and things like that have

1412
01:34:47,120 --> 01:34:49,820
OK so the simplest ones

1413
01:34:49,830 --> 01:34:52,310
everybody knows this linear PCA

1414
01:34:52,320 --> 01:34:54,690
i can faces is called vision

1415
01:34:54,720 --> 01:34:56,000
so you take a set of

1416
01:34:56,020 --> 01:34:58,480
images of faces roughly aligned

1417
01:34:58,480 --> 01:35:01,620
varying people living expression varying lighting

1418
01:35:01,650 --> 01:35:04,560
treat each image is the vector

1419
01:35:04,580 --> 01:35:08,940
you build a principal components analysis of that city vectors

1420
01:35:09,380 --> 01:35:12,660
and that captures the main degrees of variation in the set

1421
01:35:14,590 --> 01:35:20,580
that's fine it's not really very deep in the visual sense not doing alignment is

1422
01:35:20,580 --> 01:35:22,720
not doing a correction for elimination

1423
01:35:22,750 --> 01:35:24,810
doesn't really have a strong model

1424
01:35:25,010 --> 01:35:29,050
but nevertheless these models because the purely appearance based quite powerful for a number of

1425
01:35:29,050 --> 01:35:34,860
things and once you've thought of principal components analysis well as a whole

1426
01:35:34,870 --> 01:35:36,590
a lot of other than you

1427
01:35:36,630 --> 01:35:42,020
analysis techniques you can use the news fisher linear discriminant to project out

1428
01:35:42,030 --> 01:35:44,230
good discrimination directions

1429
01:35:44,240 --> 01:35:46,240
between different people for example

1430
01:35:46,270 --> 01:35:51,360
you can use independent components analysis to try to to figure out what the things

1431
01:35:51,360 --> 01:35:55,480
are the most independent about for example the signals interface

1432
01:35:55,750 --> 01:36:00,880
so will typically collapse things like corners of eyes and things like that has been

1433
01:36:00,900 --> 01:36:06,740
the most characteristic signals faces there's a whole series of other new techniques that you

1434
01:36:06,740 --> 01:36:07,600
can use

1435
01:36:07,630 --> 01:36:12,060
this you might not be able to see very here but this a model varying

1436
01:36:12,060 --> 01:36:15,020
of the different PCA components

1437
01:36:15,020 --> 01:36:20,570
four seasons that wants him OK so that's kind of simple technique

1438
01:36:21,360 --> 01:36:24,600
people look down on these days but it does have its uses

1439
01:36:24,600 --> 01:36:25,920
and and

1440
01:36:25,940 --> 01:36:33,600
standard deviation is forty times larger than the mean of

1441
01:36:33,620 --> 01:36:36,000
in the two two dimensional histogram

1442
01:36:36,010 --> 01:36:39,690
which has the interesting feature

1443
01:36:39,700 --> 01:36:46,020
that there is a slight positive correlation between the two as

1444
01:36:46,070 --> 01:36:48,390
which means that either

1445
01:36:48,430 --> 01:36:50,410
well they

1446
01:36:50,420 --> 01:36:53,970
increase the larger probability the

1447
01:36:53,980 --> 01:36:57,690
increased together or decrease together

1448
01:36:57,700 --> 01:37:04,980
then the probability that coca-cola increases and i e IBM crazy or by the very

1449
01:37:04,980 --> 01:37:09,820
well to the corner of the

1450
01:37:09,940 --> 01:37:12,640
the probabilities of these coordinates are

1451
01:37:13,730 --> 01:37:15,790
then he is said

1452
01:37:15,980 --> 01:37:18,600
almost and the corners

1453
01:37:18,690 --> 01:37:21,530
of the histogram

1454
01:37:21,580 --> 01:37:23,960
and here is a curve

1455
01:37:24,010 --> 01:37:30,410
illustrating the concept of the balance or fall ill

1456
01:37:30,430 --> 01:37:35,550
if you put all your money at the very beginning to coca-cola then there is

1457
01:37:35,550 --> 01:37:39,710
that it is the twenty two years longer than the bar

1458
01:37:39,780 --> 01:37:47,800
then you're return for coca-cola is larger than thirteen

1459
01:37:47,850 --> 01:37:53,800
and in IBM just slightly larger than to that

1460
01:37:53,820 --> 01:37:55,280
if you

1461
01:37:56,450 --> 01:37:57,530
every three

1462
01:37:57,550 --> 01:37:59,730
that the portfolio

1463
01:37:59,780 --> 01:38:02,020
for people who have that

1464
01:38:02,070 --> 01:38:02,920
then the

1465
01:38:02,930 --> 01:38:08,820
results of the first flight was that you can achieve

1466
01:38:10,010 --> 01:38:11,640
the better

1467
01:38:11,680 --> 01:38:14,160
asymptotic average growth

1468
01:38:14,210 --> 01:38:16,710
so having no regard hold two

1469
01:38:16,760 --> 01:38:22,490
the debut your initial at the very beginning

1470
01:38:23,130 --> 01:38:29,750
four all around us he the average growth rate of the better

1471
01:38:29,770 --> 01:38:32,140
if you put

1472
01:38:32,390 --> 01:38:39,990
in each morning if you apply because the balanced portfolio

1473
01:38:40,040 --> 01:38:46,910
then each morning according to to a fixed portfolio you rearrange your money

1474
01:38:46,930 --> 01:38:48,870
and in each morning

1475
01:38:48,880 --> 01:38:53,220
sixty per cent of your money is invested in google scholar

1476
01:38:53,270 --> 01:38:55,980
forty per who IBM

1477
01:38:57,360 --> 01:38:59,570
we may have to read the

1478
01:39:06,040 --> 01:39:10,480
friday afternoon i will show you that the

1479
01:39:10,530 --> 01:39:13,850
that if you use a portfolio

1480
01:39:15,410 --> 01:39:18,680
four which the portfolio each morning

1481
01:39:18,690 --> 01:39:21,010
b band

1482
01:39:21,020 --> 01:39:24,440
on the part of the return vector

1483
01:39:26,760 --> 01:39:29,670
you me and she

1484
01:39:29,680 --> 01:39:33,600
for the benefit we use along the maybe

1485
01:39:33,610 --> 01:39:37,320
it's the of eighteen

1486
01:39:37,330 --> 01:39:38,610
so v

1487
01:39:38,620 --> 01:39:43,600
the dependent portfolio you may gain much more

1488
01:39:46,300 --> 01:39:48,740
every day

1489
01:39:49,760 --> 01:39:51,050
every day

1490
01:39:51,060 --> 01:39:56,080
but the portfolio vector according to which you make thirty but that is changing

1491
01:39:56,120 --> 01:39:59,460
from b to b

1492
01:39:59,470 --> 01:40:01,810
i i i give you an example

1493
01:40:01,820 --> 01:40:02,640
you may

1494
01:40:03,210 --> 01:40:05,370
playing games

1495
01:40:05,380 --> 01:40:11,290
we do is they thought that just taking into account IBM and cash

1496
01:40:11,310 --> 01:40:13,860
and in each morning

1497
01:40:14,360 --> 01:40:23,370
you both some of your money to IBM and either ask for cash

1498
01:40:23,420 --> 01:40:27,320
and the

1499
01:40:27,330 --> 01:40:31,760
maybe the following simple rules

1500
01:40:32,570 --> 01:40:38,550
on that day in the preview they don't IBM increase

1501
01:40:38,570 --> 01:40:42,050
then put all your money to the cash

1502
01:40:42,060 --> 01:40:43,500
and vice versa

1503
01:40:43,510 --> 01:40:45,450
if the preview they

1504
01:40:45,460 --> 01:40:51,330
died and bequeathed them with all your money to live here

1505
01:40:51,380 --> 01:40:54,060
you may gain out around

1506
01:40:55,370 --> 01:41:00,030
if i remember well with these things

1507
01:41:00,080 --> 01:41:06,140
yeah but secondly i again use the same rules

1508
01:41:06,150 --> 01:41:09,330
so you have to flip flop

1509
01:41:09,390 --> 01:41:13,330
obviously you will not make

1510
01:41:16,710 --> 01:41:18,370
correct decisions

1511
01:41:18,380 --> 01:41:21,300
at each day

1512
01:41:21,320 --> 01:41:23,010
so the question was

1513
01:41:23,090 --> 01:41:26,720
that for the not memoryless

1514
01:41:27,890 --> 01:41:32,270
not memoryless processes markov processes

1515
01:41:32,320 --> 01:41:34,690
the whole the

1516
01:41:34,700 --> 01:41:37,790
rebel as being is is is made

1517
01:41:37,840 --> 01:41:41,950
and the answer was that that in this case

1518
01:41:41,990 --> 01:41:45,680
i i make every balancing each morning

1519
01:41:45,700 --> 01:41:49,830
by the way of rebalancing portfolio vector or

1520
01:41:49,850 --> 01:41:51,420
is there

1521
01:41:51,430 --> 01:41:53,700
i strongly depending

1522
01:41:53,710 --> 01:41:55,080
on the

1523
01:41:55,100 --> 01:41:57,670
preview the big star

1524
01:41:57,680 --> 01:42:00,400
people the question

1525
01:42:03,540 --> 01:42:09,320
these are some examples i would like to

1526
01:42:09,330 --> 01:42:13,300
summarize the the consequences of these

1527
01:42:13,320 --> 01:42:17,150
constantly rebalanced portfolios

1528
01:42:17,190 --> 01:42:20,810
and in order to avoid that

1529
01:42:20,820 --> 01:42:26,850
common misunderstanding get

1530
01:42:26,940 --> 01:42:28,400
around this

1531
01:42:28,410 --> 01:42:32,950
and mathematical finance of the like very value because there

1532
01:42:33,670 --> 01:42:41,980
not a single as trading but you because there are many as the best

1533
01:42:41,990 --> 01:42:45,560
the basic math each of

1534
01:42:45,600 --> 01:42:47,750
of these

1535
01:42:47,980 --> 01:42:50,460
log optimum portfolio

1536
01:42:50,540 --> 01:42:52,140
is that the

1537
01:42:53,560 --> 01:42:54,860
the real

1538
01:42:57,360 --> 01:42:59,410
the amount of capital

1539
01:42:59,420 --> 01:43:03,460
because the restart it because at the band portfolio

1540
01:43:03,500 --> 01:43:05,460
is not close to

1541
01:43:05,470 --> 01:43:08,070
it expectation

1542
01:43:08,090 --> 01:43:11,540
i will show you that it is much much less

1543
01:43:11,540 --> 01:43:18,140
and at some point idea was very excited to decide the but i was wrong

1544
01:43:18,180 --> 01:43:21,460
so if you think oriented lines that these hyperplanes

1545
01:43:23,520 --> 01:43:27,900
the VC dimension three that's quite well-known facts get three points

1546
01:43:28,000 --> 01:43:31,310
you can find people to consider it in all possible ways

1547
01:43:31,320 --> 01:43:33,210
because they're not aligned

1548
01:43:33,230 --> 01:43:37,060
you do i love you wouldn't be able to separate

1549
01:43:37,110 --> 01:43:39,500
and you can find set

1550
01:43:39,510 --> 01:43:41,480
if you take any set of four points

1551
01:43:41,490 --> 01:43:42,750
there is the separation

1552
01:43:42,770 --> 01:43:45,010
o xo problem of these four points

1553
01:43:45,060 --> 01:43:48,910
but not going to be able to separate with linear optics

1554
01:43:49,010 --> 01:43:51,210
now if you know the whole thing

1555
01:43:51,260 --> 01:43:53,050
well it doesn't actually do

1556
01:43:53,060 --> 01:43:54,650
in that case because

1557
01:43:54,670 --> 01:43:58,380
it requires that

1558
01:43:58,430 --> 01:44:00,840
you can

1559
01:44:00,960 --> 01:44:04,340
any set of three point or instead of two points

1560
01:44:04,350 --> 01:44:06,100
let let me

1561
01:44:06,150 --> 01:44:12,620
if you take a set of three points

1562
01:44:12,640 --> 01:44:15,730
also set of three points but the three points line

1563
01:44:15,780 --> 01:44:17,890
you cannot separate them

1564
01:44:17,900 --> 01:44:20,380
so you can have you can classify

1565
01:44:20,400 --> 01:44:23,040
therefore the popper dimension is less than three

1566
01:44:24,200 --> 01:44:26,830
but the idea of proof that the

1567
01:44:26,890 --> 01:44:31,240
critical this is so institution condition was based on the VC dimension they were very

1568
01:44:31,240 --> 01:44:35,680
happy to see what goes wrong

1569
01:44:35,740 --> 01:44:38,760
but it's also quite interesting to realise that

1570
01:44:38,810 --> 01:44:40,460
but by using

1571
01:44:40,470 --> 01:44:41,900
this philosophy

1572
01:44:43,470 --> 01:44:48,440
and that means by using mathematics came to very similar conclusions

1573
01:44:48,460 --> 01:44:58,060
one of the important things in practice about that need to theory

1574
01:44:58,150 --> 01:45:01,690
is the structure of musician twenty

1575
01:45:01,740 --> 01:45:05,110
and i've been surprised when i met nick

1576
01:45:05,330 --> 01:45:07,650
i was in ninety one

1577
01:45:07,750 --> 01:45:14,750
i told him i was very excited excited by cicero's musician was very surprised because

1578
01:45:14,800 --> 01:45:16,240
many people read the book

1579
01:45:16,250 --> 01:45:19,050
but they were defeated when you go to that point

1580
01:45:19,100 --> 01:45:21,790
and that point is the important one

1581
01:45:21,800 --> 01:45:23,680
we have this kind of bond

1582
01:45:23,690 --> 01:45:26,430
well basically the error you're going to do

1583
01:45:26,470 --> 01:45:27,470
on from

1584
01:45:27,470 --> 01:45:29,100
in the test set

1585
01:45:29,120 --> 01:45:32,100
is going to be less than a or you in the training set

1586
01:45:32,120 --> 01:45:37,470
president functions of the number of examples capacity in the confidence

1587
01:45:37,470 --> 01:45:39,470
so to minimize the air all you do

1588
01:45:39,480 --> 01:45:42,330
on the best that you could just minimize that one

1589
01:45:42,330 --> 01:45:45,950
but you can do smart if you minimize both terms

1590
01:45:45,960 --> 01:45:50,080
so therefore need to to make edge the capacity control viable and the way to

1591
01:45:50,080 --> 01:45:51,980
do it is to say that they

1592
01:45:52,030 --> 01:45:58,040
set function that are just like a russian puppet

1593
01:45:58,150 --> 01:46:00,330
in each of them you can find it

1594
01:46:00,350 --> 01:46:03,270
i mean most of the empirical risk

1595
01:46:03,420 --> 01:46:05,680
evaluate this them

1596
01:46:05,700 --> 01:46:08,250
and for each of these solutions can

1597
01:46:08,260 --> 01:46:11,840
david the sun and pick the best one

1598
01:46:11,880 --> 01:46:14,320
and there is something that was proved the

1599
01:46:14,320 --> 01:46:16,360
much later in fact by the void

1600
01:46:16,390 --> 01:46:20,560
is that this method is strongly universally consistent

1601
01:46:20,570 --> 01:46:23,690
i'm not going to explain what strongly universally means

1602
01:46:24,870 --> 01:46:27,020
in that case that means

1603
01:46:27,100 --> 01:46:30,280
the general idea is that if you do that

1604
01:46:30,330 --> 01:46:35,130
using lighting about which are quite losing not very good but you refused that is

1605
01:46:35,130 --> 01:46:36,350
one of the

1606
01:46:36,450 --> 01:46:37,760
you guarantee

1607
01:46:39,380 --> 01:46:45,570
you're going to find the optimal decision boundary

1608
01:46:45,570 --> 01:46:48,930
so it's interesting to compare again this all comes results

1609
01:46:48,950 --> 01:46:53,030
with the circuitry was musician quincy

1610
01:46:53,430 --> 01:46:57,740
o comes with all its is entities should not be multiplied beyond necessity

1611
01:46:57,740 --> 01:47:01,710
if the statement about the function you find on this function should have too many

1612
01:47:03,350 --> 01:47:05,510
got extra concept

1613
01:47:05,520 --> 01:47:09,860
the structure was musicians says that we should explain the observed facts

1614
01:47:09,920 --> 01:47:14,570
using the function from the subset with the smallest capacity

1615
01:47:16,380 --> 01:47:20,120
explain the observed facts using the theory which is easy to falsify

1616
01:47:20,130 --> 01:47:23,270
and you see something about the number of concepts and the theory that is it

1617
01:47:24,400 --> 01:47:27,110
nothing really tells you

1618
01:47:27,160 --> 01:47:31,060
nothing let's fuzzification and the number of concert use

1619
01:47:31,060 --> 01:47:34,670
and in fact

1620
01:47:34,690 --> 01:47:38,990
the capacity of the VC dimension this does this problem both entities

1621
01:47:39,000 --> 01:47:40,760
so there are cases where this is true

1622
01:47:40,780 --> 01:47:43,850
but if you have a linear as apparent OR

1623
01:47:43,990 --> 01:47:48,300
the VC dimension is equal to the number of entities plus one of the parameters

1624
01:47:48,360 --> 01:47:52,180
i think the indicator function is the sign of the dot product of x and

1625
01:47:52,180 --> 01:47:54,360
some parameters the bias

1626
01:47:54,460 --> 01:47:58,950
and we know that edge in that case and plus one

1627
01:47:58,960 --> 01:48:03,150
but also came with the VC dimension is that is infinity

1628
01:48:03,160 --> 01:48:05,870
well in fact there is just one parameter

1629
01:48:05,880 --> 01:48:10,620
if you take the indicator which is the sign of the signs of x

1630
01:48:10,630 --> 01:48:12,530
well a department

1631
01:48:12,540 --> 01:48:15,940
in fact you can make the sun also led so fast that can survive anything

1632
01:48:15,940 --> 01:48:17,460
you want

1633
01:48:17,490 --> 01:48:18,840
so in that case

1634
01:48:18,890 --> 01:48:20,570
the capacity is infinite

1635
01:48:20,570 --> 01:48:24,600
but the number of parameters number of entities in the sinus

1636
01:48:24,620 --> 01:48:26,160
it is simple functions

1637
01:48:26,170 --> 01:48:29,830
and in fact is if you report by again according to common opinion the sine

1638
01:48:29,830 --> 01:48:31,690
function is a simple one

1639
01:48:31,710 --> 01:48:33,360
but the thing in

1640
01:48:34,880 --> 01:48:37,210
to get you into trouble

1641
01:48:37,260 --> 01:48:40,400
and there is of course the opposite pole

1642
01:48:40,460 --> 01:48:43,810
well if you think and i plan beginning as apparent

1643
01:48:43,840 --> 01:48:48,400
but with the constraints on the normal the punishers and assuming your conference from normal

1644
01:48:48,600 --> 01:48:51,100
examples well

1645
01:48:51,100 --> 01:48:53,370
and the

1646
01:48:53,380 --> 01:48:57,680
if you require classification with a margin

1647
01:48:57,690 --> 01:49:03,330
then you can find not the VC dimension because of the analogous to simulation theory

1648
01:49:03,330 --> 01:49:05,460
where the capacity is bounded

1649
01:49:05,480 --> 01:49:06,740
by the ratio

1650
01:49:07,490 --> 01:49:09,060
the radius of the points

1651
01:49:09,110 --> 01:49:11,010
by the margin you have

1652
01:49:11,050 --> 01:49:14,380
and that means that in that case

1653
01:49:14,400 --> 01:49:18,660
the capacity is bounded by the number of farming with this about about of than

1654
01:49:18,660 --> 01:49:20,540
that can be much smaller

1655
01:49:20,570 --> 01:49:23,850
so you can make systems in which you have a very large number of parameters

1656
01:49:24,110 --> 01:49:27,240
and yet acceptable capacity

1657
01:49:28,050 --> 01:49:31,570
the goal of the three slide is to show that you know the capacity is

1658
01:49:31,570 --> 01:49:33,590
not the same as the number of parameters

1659
01:49:33,600 --> 01:49:36,290
in general

1660
01:49:36,290 --> 01:49:38,290
and this idea

1661
01:49:38,300 --> 01:49:39,870
this the coupling to

1662
01:49:39,890 --> 01:49:43,850
and that was the beginning of the support vector machines from the efforts to optimize

1663
01:49:43,860 --> 01:49:45,890
planes in the sixties

1664
01:49:46,650 --> 01:49:48,380
increase the number of parameters

1665
01:49:48,400 --> 01:49:51,620
map the input vector in a very high dimensional space

1666
01:49:51,660 --> 01:49:56,980
and control of capacity in this high dimensional space

1667
01:49:57,780 --> 01:50:01,070
the idea is that by increasing the dimensionality of the space

1668
01:50:01,110 --> 01:50:03,590
you can decrease

1669
01:50:03,590 --> 01:50:05,330
meant that this ratio

1670
01:50:05,380 --> 01:50:07,230
into an acceptable range

1671
01:50:07,270 --> 01:50:09,370
i actually should be here

1672
01:50:09,390 --> 01:50:13,860
maintenance ratio into an acceptable range

1673
01:50:15,600 --> 01:50:19,370
basically make it work

1674
01:50:19,430 --> 01:50:21,680
so for instance if you have this

1675
01:50:21,690 --> 01:50:24,050
green points in which one from the line

1676
01:50:24,090 --> 01:50:27,340
you cannot separate them with a simple hyperplane

1677
01:50:27,360 --> 01:50:32,680
but if you mapped them into two-dimensional space switzerland called from the line becomes you

1678
01:50:32,680 --> 01:50:36,650
and new square basically you put all points in the problem

1679
01:50:36,670 --> 01:50:41,840
you can find as apparently going to survive the right from the green

1680
01:50:44,150 --> 01:50:47,750
now we if we work on the margin in this two-dimensional space you can still

1681
01:50:47,780 --> 01:50:51,910
make something that's going to learn

1682
01:50:52,100 --> 01:50:56,680
at this point the like to come back to the orginal project vladimir

1683
01:50:56,700 --> 01:50:57,910
he was saying

1684
01:50:57,920 --> 01:51:00,090
he was thinking this

1685
01:51:00,100 --> 01:51:04,320
analogy of physical science all the smart people said

1686
01:51:04,450 --> 01:51:08,690
if you have too many parameters you cannot make useful reductions

1687
01:51:08,730 --> 01:51:12,960
this is a counterexample this is an example where you can have lots of parameters

1688
01:51:12,980 --> 01:51:17,540
and still make useful deduction

1689
01:51:17,600 --> 01:51:23,100
so there are some technical details that are probably going to say keep because the

1690
01:51:23,190 --> 01:51:27,250
mister the slide too incomplete to mark this be

1691
01:51:27,250 --> 01:51:28,400
meaningful enough

1692
01:51:28,400 --> 01:51:29,480
p nor

1693
01:51:29,500 --> 01:51:32,930
falls and just put using a different notation

1694
01:51:32,990 --> 01:51:34,960
that's right

1695
01:51:34,970 --> 01:51:36,380
if underneath

1696
01:51:36,380 --> 01:51:38,410
that's what we know

1697
01:51:38,460 --> 01:51:39,220
and now

1698
01:51:39,230 --> 01:51:47,920
whereas the contradiction well we have and use this bit what does he say

1699
01:51:47,980 --> 01:51:50,990
our assumption was that pino was true everywhere

1700
01:51:51,720 --> 01:51:53,050
in particular

1701
01:51:53,060 --> 01:51:54,470
it's true here

1702
01:51:58,460 --> 01:52:02,240
OK i mean this process you can't just understand them off the top head you've

1703
01:52:02,240 --> 01:52:04,010
got to work through the case

1704
01:52:04,030 --> 01:52:07,210
that's why i'm trying to draw diagram and hopefully if you sort of copy the

1705
01:52:07,210 --> 01:52:09,850
diagram down you can work for

1706
01:52:12,180 --> 01:52:16,430
i claim a couple of exercises and again because and pushed to the limit for

1707
01:52:16,430 --> 01:52:20,270
time i'm going to let you work through these

1708
01:52:20,300 --> 01:52:25,530
all the instances of phi implies sign players phi i k valid

1709
01:52:25,580 --> 01:52:30,380
and again the proof is by contradiction

1710
01:52:30,410 --> 01:52:37,790
on tree

1711
01:52:37,790 --> 01:52:40,910
i'm sorry i just can't i've spent so much time on

1712
01:52:40,940 --> 01:52:43,990
on the introduction that i'm just going to have to let you work through these

1713
01:52:43,990 --> 01:52:47,880
right so what i'm showing you what i'm trying to say here is that

1714
01:52:47,920 --> 01:52:50,870
the shapes somehow

1715
01:52:51,910 --> 01:52:53,780
because no matter what

1716
01:52:53,790 --> 01:52:59,670
what you substitute into the final size long with the same fine here and here

1717
01:52:59,730 --> 01:53:02,040
and then possibly different sign there

1718
01:53:02,050 --> 01:53:03,280
you'll find that

1719
01:53:03,300 --> 01:53:05,390
no matter what model you choose

1720
01:53:05,410 --> 01:53:08,040
this thing is true

1721
01:53:08,730 --> 01:53:10,320
same with

1722
01:53:10,710 --> 01:53:12,140
this guy

1723
01:53:12,150 --> 01:53:14,320
and same with this guy

1724
01:53:15,440 --> 01:53:19,140
what's going on well they're all theorems of classical propositional logic

1725
01:53:19,140 --> 01:53:21,570
they're all classical tautologies

1726
01:53:21,580 --> 01:53:25,140
so i'm not doing anything model there are no boxes in diamonds here that's why

1727
01:53:25,140 --> 01:53:28,320
i don't want to go through the details here and there is nothing notable going

1728
01:53:28,860 --> 01:53:32,770
OK what about this one

1729
01:53:32,820 --> 01:53:35,440
this is what i claimed

1730
01:53:35,500 --> 01:53:36,600
this shape

1731
01:53:36,600 --> 01:53:38,460
hezbollah it's true

1732
01:53:38,480 --> 01:53:40,140
on all models

1733
01:53:40,150 --> 01:53:43,650
so let's do

1734
01:53:43,670 --> 01:53:47,800
do the same thing again until proof by contradiction

1735
01:53:52,520 --> 01:53:53,470
here we are

1736
01:53:53,490 --> 01:53:55,120
i claim that

1737
01:53:55,120 --> 01:54:01,560
that's for a contradiction assume

1738
01:54:02,660 --> 01:54:04,300
let me just get the right

1739
01:54:04,340 --> 01:54:10,070
o things sfi one and so i want OK phi one implies i one implies

1740
01:54:11,360 --> 01:54:14,240
by one

1741
01:54:14,270 --> 01:54:17,310
box size one

1742
01:54:17,330 --> 01:54:22,390
so for a contradiction assume that it's not valid

1743
01:54:22,440 --> 01:54:24,990
what does it mean it means that there is some model

1744
01:54:25,000 --> 01:54:26,440
and some world

1745
01:54:26,460 --> 01:54:28,140
here it is

1746
01:54:28,150 --> 01:54:29,400
such that

1747
01:54:29,420 --> 01:54:31,170
some instances of these

1748
01:54:31,190 --> 01:54:32,790
which is

1749
01:54:35,560 --> 01:54:37,890
so there some instance of this which is also

1750
01:54:37,910 --> 01:54:41,830
i'm not going to bother instantiating i'm just going to take it is indeed what

1751
01:54:41,830 --> 01:54:45,650
does it mean for an implication to be false it means that this part is

1752
01:54:47,680 --> 01:54:49,630
so this is going to be true

1753
01:54:49,630 --> 01:54:50,870
and this

1754
01:54:50,910 --> 01:54:55,560
it is false

1755
01:54:55,560 --> 01:55:00,090
but the implication is false when this part is true in this part falls

1756
01:55:00,140 --> 01:55:02,140
let's just work through it

1757
01:55:02,150 --> 01:55:07,340
what does it mean for this thing to befall so it's also an implication so

1758
01:55:07,340 --> 01:55:09,630
that means that box by one is true

1759
01:55:09,670 --> 01:55:11,250
and books i one

1760
01:55:11,320 --> 01:55:13,700
is false

1761
01:55:15,210 --> 01:55:17,900
what does it mean for this to be false

1762
01:55:17,910 --> 01:55:18,940
this is

1763
01:55:18,950 --> 01:55:22,720
every step deposit successor makes i want true

1764
01:55:23,400 --> 01:55:26,530
going to do is we want that statement to be false

1765
01:55:26,600 --> 01:55:28,440
right every

1766
01:55:33,470 --> 01:55:36,140
so i want true

1767
01:55:36,160 --> 01:55:38,360
four forces side

1768
01:55:38,400 --> 01:55:42,450
that's right that every success

1769
01:55:44,020 --> 01:55:45,730
so i

1770
01:55:45,790 --> 01:55:49,320
well if that's false then it means some success

1771
01:55:49,370 --> 01:55:52,200
forces the negation of size one

1772
01:55:52,220 --> 01:55:54,800
so here we are we begin

1773
01:55:54,800 --> 01:55:56,400
there some success

1774
01:55:56,420 --> 01:55:59,190
which makes i one false

1775
01:55:59,210 --> 01:56:00,520
that's what it means

1776
01:56:00,530 --> 01:56:03,270
the negation of this is some success

1777
01:56:03,280 --> 01:56:05,670
forces not science

1778
01:56:07,690 --> 01:56:10,030
this guy is true in our world

1779
01:56:10,040 --> 01:56:14,610
so this guy says well every successor has to force if one

1780
01:56:14,660 --> 01:56:17,390
well now we have a successor

1781
01:56:17,410 --> 01:56:21,130
so we know that phi one is true

1782
01:56:21,170 --> 01:56:22,650
in this crisis is

1783
01:56:22,660 --> 01:56:24,070
every success

1784
01:56:24,090 --> 01:56:27,980
has to force fi one implies i one

1785
01:56:28,040 --> 01:56:29,280
we have a success

1786
01:56:29,300 --> 01:56:34,590
so if i one implies so one has to be true

1787
01:56:34,680 --> 01:56:39,270
we have a problem

1788
01:56:39,350 --> 01:56:42,370
just use your truth tables

1789
01:56:42,420 --> 01:56:46,470
this is whenever phi one is true so i want this to be true

1790
01:56:46,480 --> 01:56:48,480
or phi one is true

1791
01:56:48,490 --> 01:56:50,410
so someone has to be true

1792
01:56:50,450 --> 01:56:53,090
that's what this implications but we just

1793
01:56:53,090 --> 01:56:54,700
what does that

1794
01:56:54,730 --> 01:56:56,520
so i one had to be false

1795
01:56:56,520 --> 01:56:58,800
so there is a contradiction

1796
01:56:58,910 --> 01:57:00,610
so what that says is

1797
01:57:00,620 --> 01:57:02,530
no matter what

1798
01:57:02,580 --> 01:57:05,460
model you take no matter what valuation take

1799
01:57:05,480 --> 01:57:07,340
this shape

1800
01:57:07,410 --> 01:57:10,180
is true in all models in our world

1801
01:57:10,230 --> 01:57:12,540
this the first model shape we see

1802
01:57:12,640 --> 01:57:14,020
it's not

1803
01:57:14,030 --> 01:57:17,110
theorem of classical logic is known is

1804
01:57:17,130 --> 01:57:19,940
the KX

1805
01:57:19,970 --> 01:57:21,970
OK here's some more

1806
01:57:24,540 --> 01:57:28,000
i'm trying to tell you properties of logical consequence remember

1807
01:57:28,020 --> 01:57:31,970
so the first one is if i is in gamma then phi is a logical

1808
01:57:31,970 --> 01:57:34,160
consequence of gamma

1809
01:57:35,770 --> 01:57:38,910
why is that

1810
01:57:38,940 --> 01:57:47,380
if i is in there than five logical consequence y

1811
01:57:47,400 --> 01:57:49,340
because logical consequences

1812
01:57:49,340 --> 01:57:50,680
you take

1813
01:57:51,930 --> 01:57:55,620
and all the members of gamma true everywhere

1814
01:57:55,680 --> 01:57:57,570
if advising the

1815
01:57:57,590 --> 01:58:01,340
then of course five straight away

1816
01:58:01,350 --> 01:58:04,220
and then what is the right hand say well i to be true everywhere well

1817
01:58:04,230 --> 01:58:06,590
surprise surprise

1818
01:58:06,640 --> 01:58:08,240
OK so that's trivial

1819
01:58:09,190 --> 01:58:11,950
if i is a logical consequence of gamma

1820
01:58:11,970 --> 01:58:16,770
then talks five logical consequence of gamma so if i is a logical consequence of

1821
01:58:18,640 --> 01:58:22,250
fox five is a logical consequence of gamma

1822
01:58:25,460 --> 01:58:30,750
all the members of gamma true everywhere

1823
01:58:32,000 --> 01:58:34,910
and phi is a logical consequence of gamma

1824
01:58:34,960 --> 01:58:38,780
then phi is true everywhere

1825
01:58:38,870 --> 01:58:41,960
you pick a particular point w

1826
01:58:42,020 --> 01:58:44,360
and you know it flies to everywhere

1827
01:58:44,370 --> 01:58:45,410
you want to know

1828
01:58:45,430 --> 01:58:48,650
where the box five true w

1829
01:58:50,040 --> 01:58:52,020
if it doesn't have any successes

1830
01:58:52,030 --> 01:58:53,310
your home already

1831
01:58:53,360 --> 01:58:57,820
because they did in makes a box formula of any form true

1832
01:58:57,910 --> 01:59:02,940
if it doesn't have successes so it's got five them four of them

1833
01:59:02,960 --> 01:59:06,520
we want to know whether phi is true at these points

1834
01:59:06,580 --> 01:59:10,630
but that's what this is if gamma is true everywhere five straight away so we

1835
01:59:10,630 --> 01:59:14,170
already know that phi is true everywhere including here

1836
01:59:14,190 --> 01:59:17,380
then this guy just said well look i can see those guys and all the

1837
01:59:17,380 --> 01:59:19,940
guys that i can see make fighter

1838
01:59:20,660 --> 01:59:25,880
there's is an exercise therefore you the bottom

1839
01:59:25,880 --> 01:59:27,280
i have

1840
01:59:28,400 --> 01:59:33,070
the papers have words in and a topic

1841
01:59:33,110 --> 01:59:34,240
i have

1842
01:59:34,880 --> 01:59:40,050
sites relationship so the papers cite other papers

1843
01:59:40,050 --> 01:59:43,990
and just to make this clearer and actually copying this

1844
01:59:44,050 --> 01:59:48,010
paper class over here

1845
01:59:48,050 --> 01:59:48,880
it really

1846
01:59:48,900 --> 01:59:54,200
is the same one hears of in ER diagram you one it this way and

1847
01:59:54,200 --> 01:59:55,860
then maybe

1848
01:59:55,900 --> 01:59:59,240
papers have others

1849
01:59:59,260 --> 02:00:01,070
so if we set aside

1850
02:00:01,110 --> 02:00:06,990
as appear with attribute uncertainty initially we might have things like a simple

1851
02:00:07,130 --> 02:00:10,420
the naive bayes flavor

1852
02:00:10,420 --> 02:00:12,970
topic model

1853
02:00:12,990 --> 02:00:16,320
maybe we also have the

1854
02:00:18,280 --> 02:00:22,010
area for the topic

1855
02:00:23,050 --> 02:00:25,420
we can say something about the

1856
02:00:25,470 --> 02:00:26,990
other institution

1857
02:00:27,010 --> 02:00:29,670
anything on their research area

1858
02:00:31,800 --> 02:00:33,110
if we want to

1859
02:00:33,150 --> 02:00:34,240
get into

1860
02:00:34,280 --> 02:00:37,430
the uncertainty that we potentially have

1861
02:00:37,450 --> 02:00:42,420
about this relationship so in terms of what papers

1862
02:00:43,150 --> 02:00:44,300
which papers

1863
02:00:46,610 --> 02:00:50,530
a way of setting this up probabilistically

1864
02:00:50,610 --> 02:00:52,720
that may make sense or may not

1865
02:00:52,780 --> 02:00:54,320
is too

1866
02:00:54,340 --> 02:00:57,420
you can view it like we have

1867
02:01:01,380 --> 02:01:02,470
and somehow

1868
02:01:03,070 --> 02:01:04,450
downloaded all

1869
02:01:05,090 --> 02:01:07,200
the very last part got corrupted

1870
02:01:09,720 --> 02:01:11,590
i have the bibliography

1871
02:01:11,590 --> 02:01:13,860
and i know the number of entries there

1872
02:01:14,990 --> 02:01:21,920
i know that there's three entries but i just don't know

1873
02:01:21,930 --> 02:01:25,880
which papers they refer to

1874
02:01:25,900 --> 02:01:30,110
and there are a number of natural settings where you know the number of things

1875
02:01:30,110 --> 02:01:32,200
that you related to you just don't know who

1876
02:01:32,690 --> 02:01:39,470
you related to so reference uncertainty is a way of dealing with that

1877
02:01:42,170 --> 02:01:47,700
it explicitly going in and adding an

1878
02:01:47,720 --> 02:01:49,260
i dependence model

1879
02:01:49,280 --> 02:01:50,900
if you think about it four

1880
02:01:50,920 --> 02:01:52,260
the foreign keys

1881
02:01:52,260 --> 02:01:55,090
and this relationship

1882
02:01:56,720 --> 02:01:58,130
the trick is

1883
02:01:58,170 --> 02:02:00,740
i don't want to have

1884
02:02:00,800 --> 02:02:05,380
i dependence model that explicitly says well the probability of referring to this

1885
02:02:05,380 --> 02:02:10,050
specific papers this the this other specific papers this and so on i want to

1886
02:02:10,050 --> 02:02:16,430
be able to generalise in some way across the US and so the trick is

1887
02:02:16,450 --> 02:02:17,920
to avoid

1888
02:02:17,920 --> 02:02:20,220
doing the naive approach which would be in

1889
02:02:20,280 --> 02:02:22,950
multinomial over the primary keys

1890
02:02:22,970 --> 02:02:25,360
the related object

1891
02:02:26,490 --> 02:02:29,200
stuff is a little too it's going to be

1892
02:02:29,240 --> 02:02:34,030
nine contact do not going to be able to learn very well but also

1893
02:02:34,030 --> 02:02:38,470
an important thing to keep in mind is it limits your ability to generalize to

1894
02:02:38,470 --> 02:02:39,670
in new

1895
02:02:39,690 --> 02:02:42,510
situation where you have different papers

1896
02:02:44,380 --> 02:02:50,050
and in some domains is an important some domains it's not

1897
02:02:53,950 --> 02:02:55,360
the way

1898
02:02:55,380 --> 02:02:56,920
to think about this

1899
02:03:00,340 --> 02:03:02,090
i'm going to take

1900
02:03:02,990 --> 02:03:06,220
and a set of objects that i can refer to

1901
02:03:06,220 --> 02:03:09,340
and in some way form a partition

1902
02:03:09,380 --> 02:03:10,840
of those objects

1903
02:03:11,800 --> 02:03:13,630
in this example

1904
02:03:13,650 --> 02:03:17,550
making life easy thing well there's only

1905
02:03:18,630 --> 02:03:21,010
topics the papers can be

1906
02:03:21,050 --> 02:03:25,510
they can only be a i papers are theory papers and

1907
02:03:25,550 --> 02:03:28,090
in this world where i only have

1908
02:03:28,090 --> 02:03:29,740
five papers

1909
02:03:29,740 --> 02:03:32,240
two of them are AI

1910
02:03:32,260 --> 02:03:34,110
papers and three of them

1911
02:03:34,150 --> 02:03:35,930
our theory papers

1912
02:03:35,950 --> 02:03:40,070
and then what i can do is i can

1913
02:03:40,130 --> 02:03:44,190
i have a distribution over the set of paper that says

1914
02:03:45,340 --> 02:03:46,590
i'm going to say

1915
02:03:48,200 --> 02:03:49,720
a i paper

1916
02:03:49,740 --> 02:03:52,070
with probability point three

1917
02:03:52,090 --> 02:03:53,630
and so

1918
02:03:53,670 --> 02:03:57,200
theory paper with probability points

1919
02:03:57,220 --> 02:04:01,070
and then the way the model works is it assumes

1920
02:04:01,070 --> 02:04:02,800
uniform distribution

1921
02:04:09,050 --> 02:04:14,280
that would mean with probability point one five i will refer to this one point

1922
02:04:14,280 --> 02:04:16,430
one five refer to this

1923
02:04:16,450 --> 02:04:20,470
OK so this is the way of getting a compact parameterisation

1924
02:04:21,300 --> 02:04:25,240
this distribution of over references to objects

1925
02:04:25,320 --> 02:04:30,110
but it's actually not that exciting

1926
02:04:30,150 --> 02:04:32,920
but the easy thing that you can do is

1927
02:04:32,970 --> 02:04:36,070
you can add in something that says

1928
02:04:37,900 --> 02:04:38,920
please add

1929
02:04:39,070 --> 02:04:40,700
parent to this

1930
02:04:40,700 --> 02:04:41,690
and make this

1931
02:04:43,700 --> 02:04:45,800
a little bit more interesting to say

1932
02:04:48,950 --> 02:04:50,340
of the people are

1933
02:04:50,340 --> 02:04:54,920
influences what papers say so

1934
02:04:54,970 --> 02:04:58,340
if i a theory paper then i

1935
02:04:58,340 --> 02:05:00,510
much more likely to

1936
02:05:00,570 --> 02:05:03,010
so a theory papers from

1937
02:05:03,030 --> 02:05:04,340
OK i paper

1938
02:05:05,610 --> 02:05:08,300
much much much more likely to

1939
02:05:08,340 --> 02:05:10,800
so in a i paper and

1940
02:05:10,880 --> 02:05:15,510
well only say theory paper with a very small ability so

1941
02:05:15,550 --> 02:05:16,510
i can

1942
02:05:16,530 --> 02:05:20,110
in the same way that i have the conditional distribution

1943
02:05:20,170 --> 02:05:23,380
for any other attribute i can have the conditional distribution

1944
02:05:23,510 --> 02:05:26,110
over this attribute that has

1945
02:05:26,110 --> 02:05:28,860
reference uncertainty

1946
02:05:29,380 --> 02:05:35,220
the place where this gets

1947
02:05:35,280 --> 02:05:41,280
a little bit complicated is in making sure that all the sense still being illegal

1948
02:05:44,340 --> 02:05:45,840
one way

1949
02:05:45,860 --> 02:05:48,700
kind of understanding this is

1950
02:05:48,740 --> 02:05:53,360
the bayes net that i'm introducing now has this

1951
02:05:53,380 --> 02:05:56,820
structure where

1952
02:05:56,820 --> 02:05:58,420
i have

1953
02:06:03,470 --> 02:06:05,190
foreign key


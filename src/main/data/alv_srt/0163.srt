1
00:00:00,000 --> 00:00:01,310
finally that is this

2
00:00:01,980 --> 00:00:04,600
the issue what sleeping in the class

3
00:00:04,610 --> 00:00:06,860
now my view is it just by

4
00:00:06,870 --> 00:00:09,760
OK i know you guys need the rest

5
00:00:09,770 --> 00:00:11,670
and interestingly

6
00:00:11,730 --> 00:00:16,110
the best sleeper in the first couple of rules haven't met you guys is person

7
00:00:16,110 --> 00:00:17,350
i have followed

8
00:00:17,360 --> 00:00:20,280
some people really have to come to the first and second row

9
00:00:20,330 --> 00:00:24,450
because they claim that don't hear me they cannot really go to sleep

10
00:00:24,460 --> 00:00:27,890
that was true in slow but i think loose has got very good

11
00:00:27,910 --> 00:00:29,640
acoustic so

12
00:00:29,650 --> 00:00:31,670
structure in the back

13
00:00:31,740 --> 00:00:35,740
but only of only criterion is if you talk in your sleep as a lot

14
00:00:35,740 --> 00:00:37,760
of talk

15
00:00:37,780 --> 00:00:43,260
next if you're going to sleep i ask you to sit between two non sleepers

16
00:00:43,270 --> 00:00:47,280
so that's what happens to whole rule will pop up

17
00:00:47,330 --> 00:00:49,530
we don't want the domino effect now it's going to be

18
00:00:49,680 --> 00:00:52,560
captured on tape and that's going to be really bad for my

19
00:00:53,920 --> 00:00:56,850
spread yourself but yourself around

20
00:00:56,860 --> 00:00:58,730
other people

21
00:00:58,750 --> 00:01:00,110
all right so

22
00:01:00,190 --> 00:01:01,860
that's it in terms of

23
00:01:01,870 --> 00:01:03,990
last in logistics and everything

24
00:01:04,030 --> 00:01:05,340
i'm going to start

25
00:01:05,350 --> 00:01:07,730
going into the physics proper

26
00:01:07,780 --> 00:01:10,450
i will try to finish every lecture on time

27
00:01:10,490 --> 00:01:14,630
but sometimes in the middle of a sentence in the middle of the derivation and

28
00:01:14,630 --> 00:01:18,730
they have to go or be complimented no need to shuffle your feet then most

29
00:01:18,950 --> 00:01:20,690
i i know what time it is

30
00:01:20,700 --> 00:01:22,790
i also want to get out like you guys

31
00:01:22,800 --> 00:01:26,870
let me finish something other based on their finish few minutes before time

32
00:01:26,880 --> 00:01:29,980
that's because the ideas of physics don't fall into

33
00:01:30,110 --> 00:01:36,620
seventy time in seconds and sometimes below also i'm used to teaching this course three

34
00:01:36,620 --> 00:01:37,770
times a week

35
00:01:37,780 --> 00:01:39,910
and i would certainly twice a week

36
00:01:39,960 --> 00:01:43,940
so things that fell into nice fifty minute units are now being

37
00:01:43,990 --> 00:01:48,440
there are different ways it's pretty difficult even for me some of it will be

38
00:01:50,470 --> 00:01:53,400
the timing may not be just right

39
00:01:53,410 --> 00:01:56,270
can anybody have any

40
00:01:56,280 --> 00:01:58,710
i should tell you first of all that in this

41
00:01:58,770 --> 00:02:03,830
class the taping is not enough to because the cameras can be behind your head

42
00:02:03,880 --> 00:02:08,190
i mentioned to you in the website that this is not the big opportunity looking

43
00:02:09,430 --> 00:02:10,620
to be a star

44
00:02:10,670 --> 00:02:13,380
only the back of the scene

45
00:02:13,400 --> 00:02:17,040
in some cases the back of the head could be more expressive than the front

46
00:02:17,090 --> 00:02:21,640
in which case this is your opportunity and i shoe otherwise

47
00:02:21,760 --> 00:02:24,780
just don't worry about it because you'll be only heard

48
00:02:24,790 --> 00:02:26,570
you may not even be heard

49
00:02:26,680 --> 00:02:32,000
so i've been asked that if question is not very clear i should repeat

50
00:02:32,010 --> 00:02:36,220
so that people listening to the later we know what the question was

51
00:02:36,240 --> 00:02:38,230
but i would ask you

52
00:02:40,650 --> 00:02:42,600
make one thing very clear

53
00:02:42,650 --> 00:02:46,630
that is i'm not in favor of you're talking to each other because distracting

54
00:02:46,680 --> 00:02:49,680
you're stopping me any time is just fine

55
00:02:49,750 --> 00:02:53,660
welcome that because i have seen this subject for god knows how many years

56
00:02:53,700 --> 00:02:56,680
the only thing that makes it different from me is the questions that you people

57
00:02:57,850 --> 00:03:00,700
you can stop at any time

58
00:03:00,750 --> 00:03:03,720
and you shouldn't feel somehow you're stopping

59
00:03:03,730 --> 00:03:05,030
the progress of the class

60
00:03:05,040 --> 00:03:08,910
there is no fixed syllabus we can move things around is far more exciting for

61
00:03:09,760 --> 00:03:11,900
to answer your questions that

62
00:03:11,920 --> 00:03:14,310
have while i don't

63
00:03:14,370 --> 00:03:17,970
don't worry about that to stop me any time you don't follow something and don't

64
00:03:17,970 --> 00:03:19,970
assume that

65
00:03:20,020 --> 00:03:22,100
you are falling something because

66
00:03:22,590 --> 00:03:26,510
there's something wrong with your level of comprehension quite often

67
00:03:26,560 --> 00:03:31,310
you guys come up with questions that never crossed my mind very interesting

68
00:03:32,570 --> 00:03:36,030
things we need to be year after year after year because this sound so reasonable

69
00:03:36,030 --> 00:03:40,330
suddenly sound unreasonable and some of you point out some aspect of it

70
00:03:40,350 --> 00:03:44,020
that you didn't follow so it could be very interesting for all of us

71
00:03:44,560 --> 00:03:48,340
i have issues to discuss in class and quite often

72
00:03:48,390 --> 00:03:51,700
some questions are very common in your classmates will be grateful to you that you

73
00:03:51,700 --> 00:03:53,080
brought it up

74
00:03:53,130 --> 00:03:58,600
otherwise you get ten years get ten emails all the same question

75
00:03:58,610 --> 00:04:00,230
OK so

76
00:04:00,300 --> 00:04:02,690
when to start now

77
00:04:02,740 --> 00:04:04,730
anybody have any

78
00:04:04,740 --> 00:04:05,870
questions about

79
00:04:08,240 --> 00:04:12,500
format midterm exams

80
00:04:19,970 --> 00:04:26,900
oh you mean my office hours

81
00:04:26,900 --> 00:04:29,400
no the discussion sections are tuesday

82
00:04:30,670 --> 00:04:31,980
from one to two

83
00:04:32,010 --> 00:04:35,300
and tuesday night from eight to ten

84
00:04:35,310 --> 00:04:36,020
and the

85
00:04:36,020 --> 00:04:38,300
the website has got all the details on

86
00:04:38,320 --> 00:04:42,710
when and where yes

87
00:04:42,710 --> 00:04:46,260
there are many many lap times and you have to to

88
00:04:46,310 --> 00:04:49,800
go to the website for the land and by the way that reminds me i

89
00:04:49,800 --> 00:04:51,720
got lots of suppliers

90
00:04:51,780 --> 00:04:55,360
given to me by the director of the laboratories which will tell you

91
00:04:55,380 --> 00:04:58,070
which lab is the right left for you

92
00:04:58,280 --> 00:05:00,530
offered many times a week yes

93
00:05:00,650 --> 00:05:09,970
i think it's a good idea to take the last because

94
00:05:11,360 --> 00:05:15,190
in this particular class because i don't have any demonstrations

95
00:05:15,570 --> 00:05:17,260
all in the other building

96
00:05:17,310 --> 00:05:21,260
so this will remind you that is because of experimental science you will be able

97
00:05:21,260 --> 00:05:22,030
to see

98
00:05:22,040 --> 00:05:24,680
we're all the laws of physics come from

99
00:05:24,760 --> 00:05:28,230
so if you're going to take you should take it at the same time

100
00:05:33,380 --> 00:05:35,590
thank you

101
00:05:35,600 --> 00:05:38,030
this is the calculus this class

102
00:05:39,540 --> 00:05:44,780
i expect everyone to know at least the rudiments of differential calculus

103
00:05:44,830 --> 00:05:49,790
what function what to do with what the second derivative of take derivatives

104
00:05:49,830 --> 00:05:51,320
elementary functions

105
00:05:51,330 --> 00:05:53,840
how to do elementary integrals

106
00:05:53,880 --> 00:05:55,220
some time later

107
00:05:55,220 --> 00:05:56,340
i will

108
00:05:56,380 --> 00:06:01,540
deal with functions are more than one variable which i will briefly introduce you

109
00:06:01,570 --> 00:06:05,480
because that may not be the is but certainly something you will learn

110
00:06:05,480 --> 00:06:08,120
and you may use on and

111
00:06:08,140 --> 00:06:12,520
but there are different ways of doing physics minus two

112
00:06:12,520 --> 00:06:17,440
demonstrated over and over how little mathematics you need to get the job

113
00:06:17,450 --> 00:06:23,390
others who like to show you how much mathematics you could somehow insinuate the process

114
00:06:23,460 --> 00:06:26,300
OK there are different ways of

115
00:06:26,330 --> 00:06:29,830
playing the game and some of his find great pride in finding the most

116
00:06:29,850 --> 00:06:33,580
a simple way to understand something that's certainly my trademark that's how it all made

117
00:06:33,590 --> 00:06:35,790
sense also

118
00:06:36,400 --> 00:06:40,700
if you feel there's not enough mathews i guarantee you that i certainly not

119
00:06:41,270 --> 00:06:45,300
eventually the snow the whole class but that's not the point i will use it

120
00:06:45,340 --> 00:06:46,790
in moderation

121
00:06:46,850 --> 00:06:49,020
and use it to a user talk

122
00:06:49,040 --> 00:06:54,000
the best effort possible rather than use it because it is there

123
00:06:54,040 --> 00:06:55,960
OK so

124
00:06:55,970 --> 00:07:01,250
i don't know your mathematical background but the textbook has an appendix is reasonable measure

125
00:07:01,250 --> 00:07:03,200
of how much that you should know

126
00:07:03,250 --> 00:07:07,930
you've got to know you are trigonometry got know what's sign and what's the cosine

127
00:07:07,930 --> 00:07:10,730
on pairs of pixels

128
00:07:10,750 --> 00:07:12,490
and that one says

129
00:07:15,560 --> 00:07:17,620
there's a big change in

130
00:07:17,670 --> 00:07:20,420
this is a big change in intensity

131
00:07:20,430 --> 00:07:22,970
between these two images

132
00:07:22,980 --> 00:07:24,310
so this is the

133
00:07:24,410 --> 00:07:25,730
very light

134
00:07:25,810 --> 00:07:27,240
then it's quite

135
00:07:28,580 --> 00:07:31,420
likely fact that they belong to different classes

136
00:07:31,470 --> 00:07:34,180
so i put a small weight

137
00:07:34,230 --> 00:07:35,760
on uncut

138
00:07:35,770 --> 00:07:39,480
if on the other hand these two pixels

139
00:07:39,530 --> 00:07:42,120
look very much the same intensity

140
00:07:43,720 --> 00:07:45,930
the cost cutting

141
00:07:45,960 --> 00:07:49,500
assigned different classes i put is relatively large

142
00:07:49,510 --> 00:07:51,940
so this is the dark matter

143
00:07:52,020 --> 00:07:53,120
in the middle

144
00:07:53,120 --> 00:07:54,560
based on contrast

145
00:07:54,580 --> 00:07:57,260
so you can see OK this about

146
00:07:57,280 --> 00:07:58,810
unitary likelihood

147
00:07:58,810 --> 00:08:00,060
is there

148
00:08:00,110 --> 00:08:05,390
and you can see approximately like belongs to class one

149
00:08:05,410 --> 00:08:07,060
the pairwise terms

150
00:08:07,070 --> 00:08:08,560
as you can see

151
00:08:08,610 --> 00:08:10,380
there is a high costs

152
00:08:10,430 --> 00:08:14,160
a low cost rather along edges make cut

153
00:08:14,170 --> 00:08:16,480
and the the potts models just

154
00:08:17,820 --> 00:08:20,950
across the whole thing if you do that

155
00:08:21,010 --> 00:08:23,510
minimize the whole cost

156
00:08:23,520 --> 00:08:25,030
across the image

157
00:08:25,080 --> 00:08:26,040
you get this

158
00:08:26,100 --> 00:08:27,920
solution and everything

159
00:08:27,930 --> 00:08:30,370
rather nice thing about this

160
00:08:30,420 --> 00:08:34,140
works not only on this direction works rather well

161
00:08:37,520 --> 00:08:38,680
so i mean by

162
00:08:38,690 --> 00:08:39,740
this one step

163
00:08:39,840 --> 00:08:42,310
the optimisation step what i mean

164
00:08:42,350 --> 00:08:45,830
by this what i mean is i have each of these

165
00:08:45,840 --> 00:08:47,490
things belonging

166
00:08:47,540 --> 00:08:50,000
have a unitary cost

167
00:08:50,040 --> 00:08:51,910
they have the binary cost

168
00:08:51,910 --> 00:08:53,490
what i want

169
00:08:53,510 --> 00:08:55,060
is card

170
00:08:55,100 --> 00:08:57,330
and i'm getting curve

171
00:08:57,380 --> 00:08:58,480
the costs

172
00:08:58,540 --> 00:08:59,680
only when

173
00:08:59,780 --> 00:09:04,450
phi phi kappa between the two trying to cool the cutting costs

174
00:09:05,490 --> 00:09:09,460
the cost of putting these in given classes supply is given by the first time

175
00:09:09,460 --> 00:09:12,390
minimises hold energy function

176
00:09:12,570 --> 00:09:14,690
all assignments

177
00:09:14,790 --> 00:09:17,030
and that's the result i get

178
00:09:17,040 --> 00:09:19,870
other examples of it

179
00:09:20,880 --> 00:09:23,970
sigma of course rather nicely

180
00:09:26,020 --> 00:09:27,370
stick it

181
00:09:27,440 --> 00:09:29,600
in a different setting

182
00:09:29,600 --> 00:09:32,660
not sure if you are familiar with alpha mapping

183
00:09:32,770 --> 00:09:35,840
formatting means in fact you don't just

184
00:09:36,920 --> 00:09:39,950
o one was you signed transparency

185
00:09:41,720 --> 00:09:44,100
twelve so particularly

186
00:09:44,100 --> 00:09:45,470
along the

187
00:09:45,500 --> 00:09:47,380
the back to the main

188
00:09:48,900 --> 00:09:52,660
when you put that at the top

189
00:09:52,710 --> 00:09:54,950
o thing if you do if you just say

190
00:09:55,000 --> 00:09:59,410
take the pixels directly from the original input you find in fact

191
00:09:59,580 --> 00:10:02,240
you get it grass along the main

192
00:10:02,340 --> 00:10:06,820
in fact so you have this transparency there are some mixture of pixels

193
00:10:06,830 --> 00:10:10,880
along the lines with the of mappings of

194
00:10:10,890 --> 00:10:16,820
this one is actually one which being look quite a lot rather difficult

195
00:10:16,860 --> 00:10:19,380
segmentation task nevertheless

196
00:10:23,060 --> 00:10:26,020
people like to then put them in a different scene just to show how well

197
00:10:26,020 --> 00:10:28,170
it's worked

198
00:10:28,260 --> 00:10:37,850
OK ECCV is the european conference on computer vision there are three kinds computer vision

199
00:10:39,620 --> 00:10:41,040
the major ones

200
00:10:41,070 --> 00:10:42,410
in ECCV

201
00:10:42,420 --> 00:10:44,620
european conference on computer vision

202
00:10:44,630 --> 00:10:46,200
in ICCV

203
00:10:46,220 --> 00:10:49,000
international conference on computer vision

204
00:10:49,010 --> 00:10:50,410
and CV

205
00:10:50,450 --> 00:10:52,640
p or

206
00:10:52,640 --> 00:10:58,140
computer vision and pattern recognition

207
00:10:58,170 --> 00:11:00,060
so once again

208
00:11:07,770 --> 00:11:12,010
and so on

209
00:11:18,450 --> 00:11:19,960
to get a little bit more

210
00:11:19,970 --> 00:11:21,880
down into

211
00:11:21,880 --> 00:11:24,670
the way this time

212
00:11:24,680 --> 00:11:25,630
i said

213
00:11:25,670 --> 00:11:27,900
for instance that there are

214
00:11:27,910 --> 00:11:32,240
two types firms typically there are unitary terms

215
00:11:32,260 --> 00:11:33,190
which just

216
00:11:33,210 --> 00:11:35,040
terms relating cost

217
00:11:35,110 --> 00:11:39,970
given a single pixel of single known graph and there are binary terms

218
00:11:39,990 --> 00:11:41,370
which relate

219
00:11:42,310 --> 00:11:44,610
so the way you do this typically

220
00:11:44,650 --> 00:11:48,220
as you make a graph like this this comes down to a graph we solve

221
00:11:48,220 --> 00:11:50,150
this using graphs

222
00:11:50,190 --> 00:11:51,600
and the graph

223
00:11:51,700 --> 00:11:54,000
draw is

224
00:11:54,020 --> 00:11:57,710
the yellow dots are in one-to-one correspondence between pixels

225
00:11:57,760 --> 00:12:03,070
the image this applies not only pixels with this thing to pixels

226
00:12:03,150 --> 00:12:04,600
we have two other

227
00:12:05,670 --> 00:12:06,520
which we

228
00:12:06,780 --> 00:12:08,200
denoted in red

229
00:12:09,120 --> 00:12:11,070
one of those

230
00:12:11,230 --> 00:12:16,120
labelled zero and the labelled one or maybe s t

231
00:12:16,170 --> 00:12:18,940
one is the case for some reason which is not apparent to me

232
00:12:22,660 --> 00:12:27,730
OK you label you get take this graph and you you join

233
00:12:29,860 --> 00:12:31,990
zero one or two every

234
00:12:32,010 --> 00:12:33,410
one of the other

235
00:12:33,460 --> 00:12:34,900
nodes in the graph

236
00:12:36,080 --> 00:12:38,380
and then you assign weights

237
00:12:39,230 --> 00:12:41,430
signed weights to each age

238
00:12:41,430 --> 00:12:45,620
and the edge weights you assign the edges between the yellow and

239
00:12:45,630 --> 00:12:50,210
no it's quite clear what the edge weights should be those related in fact equal

240
00:12:51,100 --> 00:12:52,820
the energy firms

241
00:12:52,830 --> 00:12:57,020
it's not quite true lyrical they're related and the way will see to the energy

242
00:12:57,020 --> 00:13:00,600
terms involving pairs

243
00:13:01,390 --> 00:13:04,500
blue edges

244
00:13:04,930 --> 00:13:06,440
related to

245
00:13:06,460 --> 00:13:11,270
the energy term of the individual pixels in fact that really need both

246
00:13:11,310 --> 00:13:14,370
top and bottom edges the label on waiting list

247
00:13:14,390 --> 00:13:15,890
label one

248
00:13:18,250 --> 00:13:20,810
those are

249
00:13:20,870 --> 00:13:26,480
that's the way you make graph this more about that later

250
00:13:26,500 --> 00:13:28,100
and then the question is

251
00:13:28,170 --> 00:13:32,730
how do i separate find cut in the graph which separates the top note from

252
00:13:32,730 --> 00:13:35,480
the bottom right now so there's no power

253
00:13:35,520 --> 00:13:36,540
through the graph

254
00:13:37,370 --> 00:13:39,620
top to bottom from zero to one

255
00:13:39,640 --> 00:13:42,190
and then the cost

256
00:13:42,210 --> 00:13:43,480
all that time

257
00:13:43,520 --> 00:13:44,520
the total

258
00:13:45,330 --> 00:13:46,770
for the edges

259
00:13:46,770 --> 00:13:50,980
then the height of static pressure increases by ten atmosphere

260
00:13:50,990 --> 00:13:52,560
for every ten metre

261
00:13:52,600 --> 00:13:57,920
is one atmosphere

262
00:13:57,940 --> 00:14:03,890
canadians from the table

263
00:14:03,910 --> 00:14:07,750
i know how to pronounce the name because i dutch she was the dutch inventor

264
00:14:07,780 --> 00:14:09,750
is usually credited

265
00:14:09,770 --> 00:14:10,750
was building

266
00:14:10,760 --> 00:14:12,250
the first submarine

267
00:14:12,370 --> 00:14:15,810
very early seventeenth century around sixteen twenty two

268
00:14:15,850 --> 00:14:18,510
and he successfully operated the submarine

269
00:14:18,510 --> 00:14:21,370
the depth of about five metres

270
00:14:21,390 --> 00:14:23,230
imagine five metres

271
00:14:23,230 --> 00:14:24,920
how static pressure there

272
00:14:24,960 --> 00:14:26,630
half an atmosphere

273
00:14:26,720 --> 00:14:29,500
ten meters one atmosphere five metres

274
00:14:29,610 --> 00:14:31,630
of an atmosphere

275
00:14:31,640 --> 00:14:33,470
nowadays submarines

276
00:14:33,470 --> 00:14:36,570
go it's a little secret how far to go but

277
00:14:36,620 --> 00:14:38,780
they've gone up to three thousand feet

278
00:14:38,830 --> 00:14:41,000
which is nine hundred meters

279
00:14:41,040 --> 00:14:42,730
well had of static pressure

280
00:14:42,760 --> 00:14:44,910
is ninety atmospheres

281
00:14:45,000 --> 00:14:46,780
on every square meter

282
00:14:46,860 --> 00:14:49,760
all that submarine if it is it

283
00:14:49,760 --> 00:14:51,360
nine hundred meters

284
00:14:51,450 --> 00:14:55,620
there is a force of nine hundred homes nine hundred thousand

285
00:14:57,620 --> 00:14:59,310
often rable submarine

286
00:14:59,310 --> 00:15:02,830
it was an enormous accomplishment for the seventeenth century

287
00:15:02,840 --> 00:15:04,720
that's how are you going to seal

288
00:15:05,960 --> 00:15:09,000
well by the side of the vessel

289
00:15:09,090 --> 00:15:10,740
is one atmosphere

290
00:15:10,780 --> 00:15:13,480
that's the air that he was briefly

291
00:15:13,490 --> 00:15:14,850
five metres

292
00:15:15,840 --> 00:15:16,900
you know level

293
00:15:16,920 --> 00:15:18,460
so the outside

294
00:15:18,460 --> 00:15:20,700
pressure is one of the atmosphere

295
00:15:20,710 --> 00:15:26,020
namely one atmosphere barometric pressure and have an atmosphere from the static pressure so is

296
00:15:26,020 --> 00:15:28,240
an overpressure on the vessel

297
00:15:28,250 --> 00:15:29,320
of half

298
00:15:29,340 --> 00:15:31,230
an atmosphere

299
00:15:31,270 --> 00:15:32,460
but that means

300
00:15:32,500 --> 00:15:36,030
on every square centimeter that is of course pointing inwards

301
00:15:36,060 --> 00:15:42,160
of half a kilogram equivalent the public kilogram weight

302
00:15:42,190 --> 00:15:45,560
force is always perpendicular to the surface

303
00:15:45,570 --> 00:15:48,440
and if you take two square meters of his submarine

304
00:15:48,470 --> 00:15:51,760
that would be a force of ten thousand kilogram

305
00:15:51,810 --> 00:15:55,270
amazing that he managed to do that and that you could actually operate

306
00:15:55,330 --> 00:15:58,990
this submarine successfully

307
00:15:59,000 --> 00:16:01,600
i can show you here twenty six one hundred

308
00:16:01,630 --> 00:16:04,060
what kinds of forces from the labelled

309
00:16:05,040 --> 00:16:07,300
dealing with

310
00:16:07,390 --> 00:16:09,540
you see there in front of you

311
00:16:09,590 --> 00:16:12,160
paint can

312
00:16:12,230 --> 00:16:15,630
and i'm going to evaporate

313
00:16:16,690 --> 00:16:19,520
not a separate ranking factor webpage

314
00:16:19,640 --> 00:16:24,810
the paint can i'm going to one the air out

315
00:16:24,810 --> 00:16:28,700
so here is the pain can

316
00:16:28,800 --> 00:16:33,810
about twenty five centimeters by fifteen

317
00:16:33,940 --> 00:16:40,140
and so it equilibrium this one atmosphere outside one of the inside thing can happen

318
00:16:40,160 --> 00:16:42,310
i'm going to suck the air out

319
00:16:42,350 --> 00:16:44,310
so i got on the pressure here

320
00:16:44,310 --> 00:16:45,280
in other words

321
00:16:45,280 --> 00:16:48,440
the pressure outside is higher than inside exactly

322
00:16:48,460 --> 00:16:50,640
the problem that from label

323
00:16:50,700 --> 00:16:54,820
pressure outside is high and inside you get impose

324
00:16:54,840 --> 00:16:58,410
he managed to counter that build strong enough

325
00:16:58,460 --> 00:17:01,240
we topicality and here

326
00:17:01,290 --> 00:17:06,330
you can argue well then the overpressure is really one atmosphere the only dealt with

327
00:17:06,400 --> 00:17:09,280
one atmosphere well before we reach

328
00:17:09,290 --> 00:17:13,020
this we've actually believe it already implode

329
00:17:13,070 --> 00:17:16,260
so the force is that we're dealing with a very comparable

330
00:17:16,910 --> 00:17:18,810
what from tribal wars dealing with

331
00:17:18,820 --> 00:17:21,300
when he built his submarine

332
00:17:21,350 --> 00:17:23,310
so this can

333
00:17:23,310 --> 00:17:25,100
will start to crumble

334
00:17:25,170 --> 00:17:26,220
when we

335
00:17:26,220 --> 00:17:28,050
take the air out

336
00:17:28,080 --> 00:17:31,160
that's another way really seeing the atmospheric pressure

337
00:17:31,250 --> 00:17:33,260
i take the pressure of the inside

338
00:17:34,840 --> 00:17:37,590
you can literally squeezed

339
00:17:37,630 --> 00:17:39,150
because of the

340
00:17:40,340 --> 00:17:41,230
of air

341
00:17:41,230 --> 00:17:46,750
it is hanging on this and is pushing down on this

342
00:17:51,340 --> 00:17:54,550
it has to be properly sealed

343
00:17:54,570 --> 00:17:56,750
it's always a bit of a problem

344
00:17:56,840 --> 00:17:59,770
and so i have vacuum pump

345
00:17:59,860 --> 00:18:01,340
the problem

346
00:18:05,290 --> 00:18:07,310
you can already here

347
00:18:08,730 --> 00:18:12,460
the force on the front cover alone is three hundred seventy five

348
00:18:12,480 --> 00:18:14,920
square centimeters

349
00:18:17,770 --> 00:18:19,750
if the pressure inside was zero

350
00:18:19,750 --> 00:18:23,360
that would be a force of three hundred seventy five kilograms

351
00:18:24,460 --> 00:18:29,750
i'm very happy that can

352
00:18:29,750 --> 00:18:33,290
and these are the kind of force is very comparable to what from rable

353
00:18:33,290 --> 00:18:34,590
i was dealing with

354
00:18:34,630 --> 00:18:36,320
in the seventeenth century

355
00:18:36,320 --> 00:18:37,480
and he was able to

356
00:18:37,500 --> 00:18:47,900
even operate submarine under these forces without collapse

357
00:18:47,920 --> 00:18:51,500
OK i think we

358
00:18:51,500 --> 00:18:54,170
well i think this is a souvenir

359
00:18:54,300 --> 00:18:57,230
no i can give that you have to first to take this off

360
00:18:57,340 --> 00:18:58,880
you can pick it up later

361
00:19:00,670 --> 00:19:04,190
that mouthpiece is quite pressures for us because we

362
00:19:04,230 --> 00:19:06,440
you have use it again of course

363
00:19:06,570 --> 00:19:10,230
so see what the tremendous forces at stake when you do is

364
00:19:10,270 --> 00:19:13,500
barometric pressure if you go scuba diving

365
00:19:13,550 --> 00:19:16,340
you go to the depth of ten metres

366
00:19:16,750 --> 00:19:19,690
which is taken to open your mouth

367
00:19:19,730 --> 00:19:21,960
we could go all the way to the surface

368
00:19:22,020 --> 00:19:24,520
and culture brief

369
00:19:24,520 --> 00:19:26,960
but there's no way

370
00:19:29,900 --> 00:19:32,290
the other two

371
00:19:32,310 --> 00:19:34,630
here is the water level

372
00:19:34,650 --> 00:19:36,920
if this is ten meters

373
00:19:36,920 --> 00:19:39,460
in that you can produce the gibbs sampler

374
00:19:39,470 --> 00:19:40,520
any time

375
00:19:40,540 --> 00:19:42,720
you can write down your

376
00:19:43,760 --> 00:19:45,070
like that

377
00:19:45,070 --> 00:19:46,390
and the reason is

378
00:19:46,410 --> 00:19:48,730
you can complete

379
00:19:48,810 --> 00:19:51,400
the product of the FC are

380
00:19:51,410 --> 00:19:53,010
the marginal

381
00:19:53,020 --> 00:19:56,920
of the product of the indicator that so omega i

382
00:19:57,060 --> 00:19:59,900
between zero and if i have seat

383
00:19:59,910 --> 00:20:05,570
so when you look at your distribution as a product of simpler

384
00:20:05,590 --> 00:20:10,670
functions and simple we mean that you can do an inversion

385
00:20:10,730 --> 00:20:13,250
of this inequality

386
00:20:13,490 --> 00:20:14,660
you can write

387
00:20:14,660 --> 00:20:16,700
a gibbs sampler because

388
00:20:16,720 --> 00:20:18,790
of course if you integrate this

389
00:20:18,800 --> 00:20:23,660
in omega on you do get f i

390
00:20:23,720 --> 00:20:28,430
what is the marginal is the is the product of the ifis the same time

391
00:20:28,490 --> 00:20:30,690
the omega eyes are uniform

392
00:20:30,710 --> 00:20:32,570
or this interval

393
00:20:32,580 --> 00:20:34,200
you have one two

394
00:20:34,220 --> 00:20:35,490
here f k

395
00:20:35,510 --> 00:20:36,610
so you think

396
00:20:36,610 --> 00:20:41,640
it's very easy to simulate and once you have assuming make hours

397
00:20:41,650 --> 00:20:43,390
your joint distribution

398
00:20:43,930 --> 00:20:46,000
is a product of indicators

399
00:20:46,020 --> 00:20:47,900
so as the function of theta

400
00:20:47,910 --> 00:20:50,290
it's also a product of indicators

401
00:20:50,300 --> 00:20:53,330
and so on on it to simulate is uniform

402
00:20:53,350 --> 00:20:55,660
all the set of y

403
00:20:55,680 --> 00:20:57,840
so it that i y

404
00:20:57,860 --> 00:21:00,680
is bigger than omega

405
00:21:00,710 --> 00:21:03,130
OK so this makes for very

406
00:21:06,320 --> 00:21:07,470
give some

407
00:21:07,510 --> 00:21:09,580
you just go around

408
00:21:09,590 --> 00:21:11,930
OK so it's it's really

409
00:21:12,000 --> 00:21:14,180
the MCMC version

410
00:21:15,160 --> 00:21:16,160
the the

411
00:21:16,170 --> 00:21:18,740
fundamental of simulation because

412
00:21:18,800 --> 00:21:21,620
if you think it in dimension one

413
00:21:21,630 --> 00:21:25,690
you still disliked from from gas

414
00:21:25,720 --> 00:21:27,440
it spirals f

415
00:21:27,490 --> 00:21:29,210
but if you say it

416
00:21:29,230 --> 00:21:33,710
the photographs often

417
00:21:33,730 --> 00:21:34,730
what you do

418
00:21:34,870 --> 00:21:38,990
create random walk or subgraph and random walk

419
00:21:39,010 --> 00:21:41,330
all the photographs

420
00:21:41,350 --> 00:21:47,110
stationary distribution is the uniform distribution so if you keep moving at random you

421
00:21:47,130 --> 00:21:52,180
formerly of the subgraph you produced

422
00:21:52,200 --> 00:21:57,400
the markov chain whose stationary distribution is uniform and if you look only at x

423
00:21:57,400 --> 00:22:03,210
the first component marginally you get a distribution that is

424
00:22:05,320 --> 00:22:08,900
gives the size and probably just move uniformly

425
00:22:10,160 --> 00:22:14,220
exact point and then you move uniformly over this interval

426
00:22:14,240 --> 00:22:15,630
get there

427
00:22:15,640 --> 00:22:20,250
now you move uniformly over this interval get there for instance you keep going on

428
00:22:20,300 --> 00:22:24,940
that one direction at a time this of course in the case where you don't

429
00:22:24,940 --> 00:22:26,860
use the product the competition

430
00:22:28,320 --> 00:22:31,500
in the more general case when you can do it

431
00:22:31,520 --> 00:22:34,430
in one direction you can just multiply

432
00:22:34,450 --> 00:22:35,920
the uniform moves

433
00:22:35,940 --> 00:22:36,900
four eight

434
00:22:36,920 --> 00:22:38,500
of the if i

435
00:22:38,520 --> 00:22:42,060
and are totally arbitrary up exams

436
00:22:42,070 --> 00:22:45,090
the way you like you just want to pigs and so that

437
00:22:45,110 --> 00:22:47,310
this is easy to invert

438
00:22:47,360 --> 00:22:51,920
the king

439
00:22:51,980 --> 00:22:54,270
so this makes for a general

440
00:22:55,450 --> 00:22:57,660
and in addition

441
00:22:59,300 --> 00:23:01,890
one depending on the shape of the factor graph

442
00:23:01,900 --> 00:23:08,090
you get is a geometric ergodicity or if the subgraph is compact you get uniform

443
00:23:08,140 --> 00:23:12,310
good is it says this converges fast enough

444
00:23:12,330 --> 00:23:16,990
drag and the drugs that getting

445
00:23:18,560 --> 00:23:20,400
may prove impossible

446
00:23:20,420 --> 00:23:22,250
in some cases

447
00:23:22,270 --> 00:23:23,330
this step

448
00:23:23,370 --> 00:23:30,430
they require one uniform generation this step may be much harder

449
00:23:30,450 --> 00:23:32,210
because you have to produce

450
00:23:32,230 --> 00:23:33,590
this set

451
00:23:33,660 --> 00:23:34,990
OK so far

452
00:23:36,130 --> 00:23:38,570
the said that contains that's

453
00:23:38,580 --> 00:23:39,810
this is not always

454
00:23:48,640 --> 00:23:52,190
tourists this stochastic volatility yesterday

455
00:23:52,250 --> 00:23:54,990
stochastic volatility was the problem because

456
00:23:55,010 --> 00:23:57,370
in my distribution of the volatility

457
00:23:57,370 --> 00:23:58,920
that is normal bit

458
00:23:58,940 --> 00:24:01,000
which was nice enough

459
00:24:01,010 --> 00:24:03,320
two nine sigma minus two there

460
00:24:03,320 --> 00:24:04,570
and i

461
00:24:04,580 --> 00:24:09,700
the observational bit which had an exponential of an exponential decay

462
00:24:09,760 --> 00:24:12,580
what you can you can break

463
00:24:12,590 --> 00:24:15,900
so you can just rewrite as experiments x where

464
00:24:15,980 --> 00:24:18,470
press of control minus x

465
00:24:20,660 --> 00:24:23,310
if we just look at the simplest

466
00:24:23,310 --> 00:24:24,820
so somewhere

467
00:24:24,870 --> 00:24:26,190
we say

468
00:24:26,310 --> 00:24:27,970
this is

469
00:24:27,980 --> 00:24:29,070
the marginal

470
00:24:29,070 --> 00:24:30,460
of indicator

471
00:24:30,480 --> 00:24:33,870
then omega is less than this exponential

472
00:24:33,870 --> 00:24:36,900
simulated on omega

473
00:24:36,910 --> 00:24:41,880
that is easy cementing the mean that we want to simulate or

474
00:24:41,880 --> 00:24:45,000
actually this is the highest praise

475
00:24:45,000 --> 00:24:46,860
this is not an insult

476
00:24:46,880 --> 00:24:49,610
OK this is the highest praise

477
00:24:49,630 --> 00:24:51,070
and i think what it means is

478
00:24:51,090 --> 00:24:54,440
that other people know enough about the theory

479
00:24:54,440 --> 00:24:59,500
the algorithms and implementations are so good and so reliable

480
00:24:59,540 --> 00:25:03,250
the rest of us can just type a back slash p

481
00:25:03,270 --> 00:25:06,980
that's most of the time and of course if you're building real time system or

482
00:25:07,270 --> 00:25:11,060
or the sizes get two million or ten million unique going to be using back

483
00:25:12,190 --> 00:25:16,840
obviously but that said that the boundary growing with time i mean that's the wonderful

484
00:25:16,840 --> 00:25:21,500
thing about anything that has to do with computers just take a vacation for years

485
00:25:21,560 --> 00:25:22,440
you know

486
00:25:22,820 --> 00:25:29,270
my from my colleagues the other end of the EU actually do real things

487
00:25:29,840 --> 00:25:33,040
they and all their friends around the world will make stuff like twice as fast

488
00:25:33,060 --> 00:25:36,290
c just you just go away and take a vacation

489
00:25:36,300 --> 00:25:39,690
you series no you go you go to the greek islands for three weeks to

490
00:25:39,690 --> 00:25:40,980
come back

491
00:25:41,130 --> 00:25:49,690
computers are faster so just say it's it's it's great

492
00:25:49,710 --> 00:25:51,540
instead it so

493
00:25:51,540 --> 00:25:55,190
i mean that and i think that's everyone being flooded by moore's law and so

494
00:25:55,190 --> 00:25:56,020
on so

495
00:25:56,020 --> 00:26:00,700
OK so that i mean certainly the case with with all this so when i

496
00:26:00,700 --> 00:26:05,650
come back to technology and also no of course i know i'm not telling people

497
00:26:05,650 --> 00:26:09,610
that this use a backslide mesh like be actually i know everyone is classes has

498
00:26:09,610 --> 00:26:13,320
used a everyone here has done a back slash we probably only if you actually

499
00:26:13,320 --> 00:26:15,070
know actually what did

500
00:26:15,070 --> 00:26:16,750
and you look fine normal

501
00:26:16,820 --> 00:26:20,960
nothing terrible has happened is not true nothing no ones

502
00:26:20,980 --> 00:26:22,210
OK so

503
00:26:22,230 --> 00:26:25,980
anyway when i finally do is when they get real i like to come back

504
00:26:25,980 --> 00:26:27,690
to them and also to them

505
00:26:27,710 --> 00:26:29,520
when they're yelling at me all say

506
00:26:29,540 --> 00:26:34,000
also a whole on the back of your use TCP IP

507
00:26:34,020 --> 00:26:39,150
actually sometimes believe they want to know what i'm asking that's which is even cooler

508
00:26:39,150 --> 00:26:43,610
right is that all say oh don't tell me you're using these are using as

509
00:26:43,610 --> 00:26:48,590
a black box you don't even know what's inside it like so

510
00:26:48,610 --> 00:26:52,250
and finally some of them will say OK i do

511
00:26:52,250 --> 00:26:57,860
you know because like everything is i'm even institute this if your even communications on

512
00:26:57,860 --> 00:27:04,170
this on on stupid you know on your laptop between different components and

513
00:27:04,190 --> 00:27:06,070
so say you know what it does

514
00:27:06,130 --> 00:27:07,320
most final say

515
00:27:07,340 --> 00:27:10,750
no and i look here's what you need to know if you need to know

516
00:27:10,880 --> 00:27:14,960
a OK it but it is not trivial by any means

517
00:27:15,000 --> 00:27:18,300
to deliver to make a reliable bit pipe

518
00:27:18,320 --> 00:27:21,960
to the transfer bids from one place to another with unreliable

519
00:27:21,980 --> 00:27:25,710
medium in size it is not trivial but the first thing it's no more trivial

520
00:27:25,940 --> 00:27:30,420
than it is to solve this problem numerical OK it is not trivial

521
00:27:30,480 --> 00:27:32,570
and here's answer all you need to know is this

522
00:27:32,610 --> 00:27:38,540
very intelligent people have thought about this problem very deeply they thought about what can

523
00:27:38,540 --> 00:27:43,380
go wrong deadlocks all sorts of crazy stuff and they have come up with

524
00:27:44,840 --> 00:27:49,170
about which they know an incredible amount that's part one part two

525
00:27:49,190 --> 00:27:51,040
other people have implemented them

526
00:27:52,320 --> 00:27:57,360
to the i with and as far as you know and these are very reliable

527
00:27:57,360 --> 00:28:01,610
implementations and the result is that for most of us we can just

528
00:28:01,630 --> 00:28:04,250
most of us can just consider certain things to be

529
00:28:04,270 --> 00:28:07,340
file transfer to be reliable bit pipes

530
00:28:07,440 --> 00:28:12,040
we don't have to care about how many packets rory transmitter how the flow control

531
00:28:12,040 --> 00:28:15,340
when all that kind of stuff now

532
00:28:15,360 --> 00:28:16,770
likely squares

533
00:28:16,790 --> 00:28:18,800
if you're doing real time control

534
00:28:18,820 --> 00:28:20,130
or something like that

535
00:28:20,150 --> 00:28:24,500
or or or ultra if you're doing some computing requires extreme reliability

536
00:28:24,520 --> 00:28:29,130
then you know what you can't treat TCP IP as a black box

537
00:28:29,190 --> 00:28:31,020
but to do so

538
00:28:31,130 --> 00:28:34,420
but you might ask this is common down the answer is no this makes them

539
00:28:34,420 --> 00:28:35,340
more angry

540
00:28:35,340 --> 00:28:40,980
so anyway so be i i mean technology here as in praise

541
00:28:42,060 --> 00:28:45,650
it's OK now when you lose will use least squares

542
00:28:45,690 --> 00:28:49,320
if you just come from two sixty three use least squares OK but in fact

543
00:28:49,320 --> 00:28:52,650
that at the beginning i mean we use least squares is it easy to recognise

544
00:28:52,650 --> 00:28:55,940
the least squares problem i mean sometimes it comes to on a platter like somebody

545
00:28:55,940 --> 00:29:00,270
walks and says i took these measurements is a linear measurement model we guess these

546
00:29:00,270 --> 00:29:04,500
parameters i know something like that are you know i received signal into this channel

547
00:29:04,500 --> 00:29:09,270
so what seems to be OK right so we have to treat clusters of points

548
00:29:09,290 --> 00:29:11,230
and you can kind of see

549
00:29:11,230 --> 00:29:12,840
the tree different modes

550
00:29:12,860 --> 00:29:15,440
actually i add more data points in here

551
00:29:15,440 --> 00:29:19,190
he might actually be able to see the true clusters small really

552
00:29:21,310 --> 00:29:25,880
this can add lots of data points OK so we see three clusters so this

553
00:29:25,880 --> 00:29:30,460
is nice and working fine stuff like OK so what happens now if we

554
00:29:30,560 --> 00:29:32,810
another class right

555
00:29:35,840 --> 00:29:39,750
still running going a bit slow

556
00:29:41,380 --> 00:29:43,090
OK so

557
00:29:43,770 --> 00:29:45,880
anybody see any problem with

558
00:29:46,000 --> 00:29:48,060
this right now

559
00:29:51,040 --> 00:29:56,730
that's true so this kind like it

560
00:29:56,750 --> 00:29:58,540
it's not quite able to

561
00:29:59,230 --> 00:30:00,710
all four cluster

562
00:30:00,710 --> 00:30:05,070
how many clusters do thing is in a mixture model

563
00:30:06,150 --> 00:30:11,480
obviously so you can see that we have

564
00:30:11,690 --> 00:30:17,000
this financial models come going to get into trouble not because it's not

565
00:30:17,110 --> 00:30:19,440
flexible enough to capture

566
00:30:19,460 --> 00:30:22,040
this is a very simple devices

567
00:30:22,070 --> 00:30:25,400
is a finite mixture three

568
00:30:26,750 --> 00:30:29,920
and if we try to fit it to four classes we're going to see of

569
00:30:29,920 --> 00:30:32,610
course that you try to

570
00:30:32,650 --> 00:30:36,980
model this fall classes using tree mixture component

571
00:30:37,000 --> 00:30:42,610
so so right now it's colour much does two clusters together and it does manage

572
00:30:43,540 --> 00:30:48,250
have a component for each of the class for each of these two clusters

573
00:30:48,270 --> 00:30:50,560
so this can work

574
00:30:50,570 --> 00:30:52,980
but not quite

575
00:30:53,000 --> 00:30:57,830
so what we do next is basically to take a finite mixture now and take

576
00:30:58,340 --> 00:31:00,960
the number of components in this measure to infinity

577
00:31:00,980 --> 00:31:04,520
so that it can do with any number of clusters that you give

578
00:31:24,440 --> 00:31:25,770
so it's

579
00:31:25,790 --> 00:31:29,690
a finite mixture model gibbs sampling definitional

580
00:31:29,830 --> 00:31:32,590
so now we want to take k to infinity

581
00:31:32,880 --> 00:31:39,630
so before we take eighteen to infinity what we do is imagine simply really large

582
00:31:39,650 --> 00:31:46,900
so what happens when we have a really large number of missing components

583
00:31:47,750 --> 00:31:51,810
we only have an data points and could be big c

584
00:31:51,940 --> 00:31:57,500
thousand by k could be even bigger a million something like so

585
00:31:59,840 --> 00:32:01,840
number of missions

586
00:32:02,000 --> 00:32:04,330
mixture components k

587
00:32:04,340 --> 00:32:07,730
we can imagine it to be much larger than the number of data points that

588
00:32:07,730 --> 00:32:08,650
we have

589
00:32:08,880 --> 00:32:11,960
and because every data

590
00:32:11,980 --> 00:32:16,590
in the worst case every data point can be assigned to its own individual cluster

591
00:32:16,630 --> 00:32:18,590
so that's really only

592
00:32:18,650 --> 00:32:22,090
and the clusters that will be used to explain the data

593
00:32:22,150 --> 00:32:24,860
out of this really large number of

594
00:32:24,900 --> 00:32:26,960
we components

595
00:32:27,690 --> 00:32:32,420
but this is that most of the components in the mixture was simply be empty

596
00:32:32,420 --> 00:32:35,210
so they are not going to be associated with it at all

597
00:32:35,290 --> 00:32:36,730
and what we

598
00:32:36,730 --> 00:32:42,060
well we try to do is actually to lump it all this empty components together

599
00:32:42,190 --> 00:32:45,290
so if we

600
00:32:46,230 --> 00:32:51,060
the the first equation here i'm just going to take say

601
00:32:51,130 --> 00:32:53,940
this thing here and copy it over here

602
00:32:55,230 --> 00:33:00,540
the probability so inactive sample of the probability that

603
00:33:00,540 --> 00:33:03,520
data item i is going to be assigned to cluster k

604
00:33:03,560 --> 00:33:06,400
given the assignments of all the other clusters

605
00:33:06,460 --> 00:33:08,570
it is going to be proportional to

606
00:33:08,630 --> 00:33:10,810
again this conditional prior

607
00:33:12,500 --> 00:33:17,900
but i to my i being assigned to complicate multiplied by a likelihood

608
00:33:19,710 --> 00:33:21,290
of the data item

609
00:33:21,340 --> 00:33:26,060
given all the other data items there's currently assigned to cluster k

610
00:33:28,400 --> 00:33:30,000
and so for the

611
00:33:30,040 --> 00:33:32,310
for the clusters for which

612
00:33:32,860 --> 00:33:37,270
for the occupied clusters foot so for the clusters fall

613
00:33:38,150 --> 00:33:39,060
i have

614
00:33:39,090 --> 00:33:40,340
there are currently

615
00:33:40,340 --> 00:33:43,730
they could say that currently have the title assigned to them

616
00:33:43,790 --> 00:33:46,940
so in other words where this and k term is

617
00:33:47,090 --> 00:33:48,710
not zero sum

618
00:33:48,710 --> 00:33:50,440
all land

619
00:33:50,460 --> 00:33:53,750
all the columns would be pivot columns

620
00:33:53,790 --> 00:33:59,960
because three columns are telling me that there are combination of earlier columns

621
00:34:00,020 --> 00:34:03,250
so this would be the case where the rank is an

622
00:34:03,260 --> 00:34:06,210
this would be the case where the rain is

623
00:34:06,260 --> 00:34:09,740
smaller than n

624
00:34:09,790 --> 00:34:12,060
so in this case the rank is and

625
00:34:12,080 --> 00:34:13,870
and the null space

626
00:34:13,870 --> 00:34:15,220
of a

627
00:34:16,190 --> 00:34:17,990
only the zero back

628
00:34:18,930 --> 00:34:20,910
and no free variables

629
00:34:21,830 --> 00:34:23,410
three very

630
00:34:26,250 --> 00:34:32,210
and this is the case yes free variables

631
00:34:32,220 --> 00:34:36,000
if you allow me to

632
00:34:36,020 --> 00:34:38,850
great thing this language that far

633
00:34:38,860 --> 00:34:41,870
that's the case where we have

634
00:34:45,670 --> 00:34:52,130
combination that gives the zero columns so i'm often interested in the case when my

635
00:34:52,130 --> 00:34:55,670
vectors are popped into a matrix

636
00:34:55,750 --> 00:35:01,440
so the the definition over there of independence then talk about any matrix

637
00:35:01,450 --> 00:35:03,310
the vectors didn't have to be

638
00:35:03,320 --> 00:35:05,990
vectors in n dimensional space

639
00:35:06,220 --> 00:35:08,760
and i want to give you some examples

640
00:35:09,510 --> 00:35:11,130
vectors that are

641
00:35:11,140 --> 00:35:14,090
what you think of immediately as vectors

642
00:35:14,140 --> 00:35:18,860
but most of the time this is the we are the vectors we think of

643
00:35:21,390 --> 00:35:24,630
and we can put them in the matrix

644
00:35:24,650 --> 00:35:29,070
and then independence or dependence comes back to

645
00:35:29,120 --> 00:35:30,680
the null space

646
00:35:32,680 --> 00:35:36,600
so that's the idea of independence

647
00:35:36,610 --> 00:35:37,930
can i just

648
00:35:38,640 --> 00:35:43,900
let me let me go on to spending a space

649
00:35:43,910 --> 00:35:47,010
what does it mean for a bunch of actors

650
00:35:48,640 --> 00:35:50,700
a space

651
00:35:50,720 --> 00:35:53,880
well actually we've seen it already

652
00:35:53,940 --> 00:35:54,930
you remember

653
00:35:54,940 --> 00:35:58,970
if if we had columns in the matrix

654
00:35:59,020 --> 00:36:02,200
we took all their combinations

655
00:36:02,250 --> 00:36:04,260
and that gave us the

656
00:36:04,270 --> 00:36:06,750
column space

657
00:36:06,800 --> 00:36:14,660
those vectors that we started with band that column space so spanning the space means

658
00:36:14,710 --> 00:36:16,490
so let me move that

659
00:36:17,680 --> 00:36:23,280
right up

660
00:36:24,260 --> 00:36:26,260
so vectors

661
00:36:28,710 --> 00:36:29,450
let me

662
00:36:29,470 --> 00:36:30,910
call them to say

663
00:36:30,910 --> 00:36:34,860
the one up to car use some different letters a b

664
00:36:37,760 --> 00:36:44,140
i space subspace

665
00:36:44,180 --> 00:36:48,760
or just the vector space i could span space

666
00:36:48,770 --> 00:36:50,810
it means

667
00:36:54,970 --> 00:36:56,240
the space

668
00:36:56,370 --> 00:37:00,430
it consists of

669
00:37:07,860 --> 00:37:11,570
one of those affected

670
00:37:11,620 --> 00:37:21,210
that's exactly what we did with the column space

671
00:37:21,230 --> 00:37:26,170
so now i could say in shorthand the columns of the matrix span

672
00:37:26,210 --> 00:37:28,420
the column space

673
00:37:28,470 --> 00:37:32,880
remember to bunch of vectors that have this property that they span a space and

674
00:37:33,830 --> 00:37:37,460
if i give you a bunch of actors and say OK

675
00:37:37,480 --> 00:37:39,740
let s be the space

676
00:37:39,780 --> 00:37:41,170
that they span

677
00:37:41,180 --> 00:37:45,210
in other words let us contain all their combinations

678
00:37:45,380 --> 00:37:49,600
that space as will be the smallest space

679
00:37:49,600 --> 00:37:51,970
with those vectors in right

680
00:37:52,030 --> 00:37:54,640
because any space with those vectors in it

681
00:37:54,640 --> 00:37:58,870
you must have all combinations of those vectors in it

682
00:37:58,920 --> 00:38:01,740
and if i stop there

683
00:38:02,830 --> 00:38:04,930
i've got the smaller space

684
00:38:04,950 --> 00:38:07,590
and that's the space that they span

685
00:38:07,600 --> 00:38:08,980
OK so i'm just

686
00:38:09,010 --> 00:38:16,620
rather than needing to say take all linear combinations and put them into space

687
00:38:16,630 --> 00:38:19,470
i'm i'm compressing that

688
00:38:19,500 --> 00:38:23,560
into the word spam

689
00:38:27,670 --> 00:38:33,360
so if i think of of the column space of a matrix

690
00:38:33,410 --> 00:38:37,590
i've got i've got there so i start with the columns

691
00:38:37,600 --> 00:38:43,550
i take all their combinations that gives me the column space they span the column

692
00:38:43,590 --> 00:38:46,360
now are they independent

693
00:38:46,410 --> 00:38:49,830
maybe yes maybe no

694
00:38:49,870 --> 00:38:55,300
it depends on the particular columns that went into that matrix

695
00:38:56,120 --> 00:39:02,070
obviously i'm highly interested in a set of vectors

696
00:39:02,080 --> 00:39:04,220
that spans the space

697
00:39:04,250 --> 00:39:07,050
and is independent

698
00:39:07,080 --> 00:39:11,780
that's that means like i've got the right number of vectors

699
00:39:11,840 --> 00:39:14,030
if i didn't have all of them

700
00:39:14,050 --> 00:39:15,170
i wouldn't have

701
00:39:15,210 --> 00:39:17,720
my whole space

702
00:39:17,740 --> 00:39:21,700
if i had more than that they probably wouldn't they wouldn't be

703
00:39:21,710 --> 00:39:23,940
independent so like

704
00:39:25,050 --> 00:39:26,940
and that's the word that's coming

705
00:39:27,780 --> 00:39:33,550
just right so here let me put what that word means a basis

706
00:39:33,670 --> 00:39:39,900
four of vectors for vector space is

707
00:39:41,000 --> 00:39:45,440
it is a sequence of vectors

708
00:39:50,170 --> 00:39:52,120
like all of the y

709
00:39:52,130 --> 00:39:54,400
b two

710
00:39:54,410 --> 00:39:55,300
up to

711
00:39:55,310 --> 00:39:56,440
save the

712
00:39:56,460 --> 00:39:58,170
d now stopped

713
00:39:58,270 --> 00:40:00,260
with that letters that

714
00:40:00,330 --> 00:40:03,740
it has two properties

715
00:40:03,740 --> 00:40:07,400
i mean think about very simple example you have long sequence and the patron two

716
00:40:07,400 --> 00:40:11,900
three five seven eleven to the prime craft and then you make a special entity

717
00:40:11,900 --> 00:40:17,260
of primes you build secretary the prince primes now because this user often then to

718
00:40:17,260 --> 00:40:18,610
reconstruct data

719
00:40:19,560 --> 00:40:22,840
he developed the concept of prime because it allows you to

720
00:40:22,850 --> 00:40:24,260
compress your data

721
00:40:33,100 --> 00:40:41,450
but they only finally many which are simpler than the data themselves

722
00:40:41,590 --> 00:40:46,170
you have

723
00:40:46,170 --> 00:40:49,560
i haven't told you how to find the simplest theory but i mean what to

724
00:40:49,570 --> 00:40:53,780
formalise just i mean this supposed the gain numerator all theories from simpler to more

725
00:40:53,780 --> 00:40:56,860
complex and look how well they are then you pick the best one of course

726
00:40:56,860 --> 00:40:57,840
i mean this is

727
00:40:58,320 --> 00:41:01,530
it takes a lot of time and if you do it know can a computer

728
00:41:01,530 --> 00:41:04,320
do it but

729
00:41:04,370 --> 00:41:08,140
nor can the universe do it but it is the gold standard which you try

730
00:41:08,170 --> 00:41:12,090
to achieve with some more clever methods by

731
00:41:12,210 --> 00:41:15,670
partial search clever search or whatever

732
00:41:17,810 --> 00:41:19,000
OK so

733
00:41:19,250 --> 00:41:22,470
but before we come to that there is one

734
00:41:22,480 --> 00:41:23,670
the problem

735
00:41:23,680 --> 00:41:24,920
and this is

736
00:41:25,220 --> 00:41:29,650
occam's razor is not a formal mathematical objective principles of

737
00:41:29,660 --> 00:41:32,330
so what is simple for one may be complex for another

738
00:41:32,370 --> 00:41:34,150
so we have to

739
00:41:34,200 --> 00:41:38,490
define quantitative notion of complexity first

740
00:41:38,500 --> 00:41:40,730
before i do that give me another

741
00:41:40,910 --> 00:41:45,210
example the famous go emerald paradox

742
00:41:45,230 --> 00:41:48,840
with about that are not about that

743
00:41:48,870 --> 00:41:51,170
OK not OK so

744
00:41:53,900 --> 00:41:55,500
that's one of the most famous

745
00:41:55,540 --> 00:41:57,490
the paradoxes in philosophy

746
00:41:57,530 --> 00:42:00,170
which is still not completely

747
00:42:01,420 --> 00:42:04,470
so have to policies all emeralds are green

748
00:42:05,790 --> 00:42:08,710
most of you know probably there

749
00:42:08,760 --> 00:42:10,690
emerald green

750
00:42:10,700 --> 00:42:11,400
but you have

751
00:42:11,420 --> 00:42:15,260
second hypothesis all emeralds found till two thousand ten i agree

752
00:42:15,320 --> 00:42:18,640
and after the blue

753
00:42:20,790 --> 00:42:23,360
so which hypothesis is more plausible

754
00:42:23,360 --> 00:42:27,760
i mean both totally consistent with all observations

755
00:42:29,430 --> 00:42:31,780
from this perspective the equally good

756
00:42:31,830 --> 00:42:36,200
but nevertheless i guess most of you what

757
00:42:36,220 --> 00:42:41,820
bet on hypothesis h one but the question is what is the justification of that

758
00:42:41,820 --> 00:42:44,240
and you can invoke occam's razor here too

759
00:42:44,260 --> 00:42:48,470
i mean the first hypothesis looks simpler i mean just count the number of letters

760
00:42:48,470 --> 00:42:49,770
in the sentence

761
00:42:51,740 --> 00:42:53,360
use your intuition

762
00:42:53,570 --> 00:42:55,400
in this case

763
00:42:55,450 --> 00:42:59,150
i mean you could argue are the times which in two thousand ten but i

764
00:42:59,150 --> 00:43:02,450
mean that the processes for which after some time to come up with them and

765
00:43:02,450 --> 00:43:05,270
then you would argue for which

766
00:43:11,830 --> 00:43:20,760
well i've seen on road

767
00:43:20,810 --> 00:43:25,100
what you mean have i mean you want to predict the future so

768
00:43:25,490 --> 00:43:29,500
what you mean things never happen

769
00:43:29,560 --> 00:43:33,530
you also never experience the hypothesis that all emeralds are green in two thousand eleven

770
00:43:33,530 --> 00:43:39,390
year-old inexperienced that

771
00:43:39,400 --> 00:43:42,890
i mean what you're trying to do now is huge to to generalise over i

772
00:43:42,890 --> 00:43:46,400
have a class of hypothesis

773
00:43:51,220 --> 00:43:58,850
yeah the continuity arguement which is not bad but there are processes

774
00:44:00,470 --> 00:44:03,080
jump around and

775
00:44:03,080 --> 00:44:05,170
so for instance

776
00:44:05,230 --> 00:44:07,600
the sun i mean grows every day

777
00:44:07,610 --> 00:44:11,710
but you wouldn't predict it's there in twenty billion years

778
00:44:11,770 --> 00:44:14,840
also it has ever been there in the past five

779
00:44:14,850 --> 00:44:19,770
billion years because i mean you know by physical processes that will explode from

780
00:44:19,830 --> 00:44:23,760
so you would predict a discontinuity of all you have never experienced the discontinuity in

781
00:44:23,760 --> 00:44:33,140
this case

782
00:44:40,680 --> 00:44:43,490
this is another thing that you're maybe no no i mean this happens but this

783
00:44:43,490 --> 00:44:47,850
set the eclipse happened in the past so you have some experience these happen so

784
00:44:48,890 --> 00:44:51,840
so you need an example

785
00:44:51,910 --> 00:44:55,220
it has not happened in the past but will happen in the future according to

786
00:45:00,080 --> 00:45:05,900
i mean the continuity arguement is pretty good in many cases but not universal

787
00:45:08,090 --> 00:45:10,360
OK here's another nice paradox

788
00:45:10,360 --> 00:45:13,970
the black raven paradox

789
00:45:13,990 --> 00:45:16,170
or confirmation paradox

790
00:45:18,900 --> 00:45:24,100
i assume we go out and we observe ravens and this all to be black

791
00:45:24,110 --> 00:45:28,670
so what you typically then infer all biologists who is OK probably already

792
00:45:28,720 --> 00:45:31,170
so you have this hypothesis that

793
00:45:32,270 --> 00:45:34,070
raven this

794
00:45:34,110 --> 00:45:36,180
implies likeness

795
00:45:36,270 --> 00:45:37,410
so what you do it

796
00:45:37,410 --> 00:45:41,840
it's like nearly every other point depends on every every other points and so

797
00:45:41,890 --> 00:45:46,290
what you what you're seeing here something called ptolemy triangulation

798
00:45:46,310 --> 00:45:51,960
so basically it away just triangulating all these points and we can parameterise how these

799
00:45:51,960 --> 00:45:57,020
things move in the classic nineteen this is point distribution model

800
00:45:57,520 --> 00:46:03,120
you generally just do this by removing similarity from the shape so member similarity translation

801
00:46:03,120 --> 00:46:04,420
scale rotation

802
00:46:04,420 --> 00:46:08,980
and everything else and prolific with is the non rigid deformation and sensual there was

803
00:46:08,980 --> 00:46:14,620
applied principal component analysis sought to get that variation in there and then they said

804
00:46:14,670 --> 00:46:18,440
we have a model what you're saying the animation

805
00:46:18,480 --> 00:46:19,730
put this again

806
00:46:19,790 --> 00:46:22,140
it's essentially the principal component

807
00:46:22,170 --> 00:46:24,580
that's the first principal component

808
00:46:24,620 --> 00:46:26,560
that's the second principal component

809
00:46:26,560 --> 00:46:28,020
and we

810
00:46:28,040 --> 00:46:30,410
parameterized in exactly the same way

811
00:46:30,410 --> 00:46:32,350
so you that w x p

812
00:46:32,370 --> 00:46:35,580
and just making sure that the way the express my p

813
00:46:36,070 --> 00:46:41,140
it follows that fundamental role that it follows an identity matrix and that it can

814
00:46:41,140 --> 00:46:46,480
be can computed it can be was any information

815
00:46:49,270 --> 00:46:53,060
now you know what function helped users what function with images

816
00:46:53,080 --> 00:46:55,040
so now

817
00:46:55,060 --> 00:46:58,230
most people know that when we actually storing image we deal with an image it's

818
00:46:58,230 --> 00:47:03,960
discrete this kind of the individual pixels is not a continuous a continuous signal

819
00:47:05,310 --> 00:47:09,370
the what function but the problem the what function is nearly always gives the fractional

820
00:47:10,600 --> 00:47:12,690
so we have an example here

821
00:47:14,170 --> 00:47:17,350
to say i i got of the line

822
00:47:17,370 --> 00:47:19,230
coming for you

823
00:47:20,560 --> 00:47:23,100
and this is the actual image

824
00:47:23,190 --> 00:47:26,560
and i want to subsample this image there and the way i want to subsample

825
00:47:26,560 --> 00:47:31,330
this image is essentially just to have this many pixels

826
00:47:31,350 --> 00:47:35,790
evenly space and things so if i'm going naive saying well

827
00:47:35,810 --> 00:47:39,080
on this going to turn pixels on and off based on what the values for

828
00:47:39,080 --> 00:47:39,710
are here

829
00:47:39,730 --> 00:47:41,890
this is what i'm going to get

830
00:47:41,940 --> 00:47:46,790
and it's not really representative what i have in original images is sort of

831
00:47:46,810 --> 00:47:49,810
for anyone is kind and done i suppose any math course or any kind of

832
00:47:49,810 --> 00:47:54,190
thing and sigma systems and things that this is essentially anything

833
00:47:54,210 --> 00:48:00,670
so you're essentially you're you're not we're we're we're we're not take into account the

834
00:48:02,830 --> 00:48:06,270
you want to take into account the icing effects going on this image

835
00:48:07,040 --> 00:48:11,100
one way to get around that in a kind of

836
00:48:11,170 --> 00:48:14,620
had not the slightest talking about never to be

837
00:48:14,870 --> 00:48:22,080
familiar with using this another example by using those who are familiar

838
00:48:22,140 --> 00:48:25,370
is in the wagon wheels examples what camille nineteen

839
00:48:25,390 --> 00:48:26,650
thirty some sort of

840
00:48:26,670 --> 00:48:29,250
going along and they kind of the

841
00:48:29,250 --> 00:48:30,420
the speed of the wheel

842
00:48:30,440 --> 00:48:33,920
doesn't sink up with frame might it actually looks like it was going backwards

843
00:48:33,940 --> 00:48:37,890
and this is the function of not sampling cracked right and that's very similar to

844
00:48:37,890 --> 00:48:40,000
what was going on there

845
00:48:40,000 --> 00:48:45,360
so what we typically do in computer vision is something called image interpolation and there's

846
00:48:45,360 --> 00:48:49,040
a whole mean can become daunting if you have time to perform but if you've

847
00:48:49,040 --> 00:48:53,010
got any map that it's really simple i think people drumming up too much the

848
00:48:53,010 --> 00:48:58,870
compare with polymer interpolation bicubic things about all we really doing is the kind of

849
00:48:58,870 --> 00:49:03,060
thinking hang on an image is an understanding of samples of an image name is

850
00:49:03,060 --> 00:49:05,420
really isn't a discrete

851
00:49:05,620 --> 00:49:10,080
image on this representing discreetly only do something useful with it only to come and

852
00:49:10,080 --> 00:49:12,640
go back into continuous domain

853
00:49:12,640 --> 00:49:13,480
and so

854
00:49:13,480 --> 00:49:16,330
what i

855
00:49:16,330 --> 00:49:17,370
it's essentially

856
00:49:17,370 --> 00:49:22,560
if i think so i think actually visualize an image in one day phyllis to

857
00:49:22,560 --> 00:49:26,460
say that is that my image being to be a commitment on one day come

858
00:49:26,460 --> 00:49:27,850
what occurred

859
00:49:29,140 --> 00:49:34,560
what i do when images it's really sample is that when i story of essentially

860
00:49:35,850 --> 00:49:37,460
all these all these points here

861
00:49:37,500 --> 00:49:42,890
and if i admin nyquist probably as long as i'm sampling at twice the highest

862
00:49:43,980 --> 00:49:47,920
i this actually got a lot of information learning so find something about the human

863
00:49:47,920 --> 00:49:55,100
visual system one of the things i can generally store that information

864
00:49:56,580 --> 00:50:02,420
if i want to know what the images what the image value of objects is

865
00:50:02,420 --> 00:50:03,920
given just these points

866
00:50:03,980 --> 00:50:06,710
given not excited because i know the value of x

867
00:50:06,750 --> 00:50:10,830
but the x which is the fractional values between these two values

868
00:50:10,870 --> 00:50:16,600
i do something very very common things and it's basically like a power series expansion

869
00:50:16,640 --> 00:50:17,480
and so

870
00:50:17,480 --> 00:50:20,080
essentially just take the gradient

871
00:50:20,140 --> 00:50:24,600
OK but the gradient of light based on its neighbours so you can kind of

872
00:50:24,600 --> 00:50:28,270
very it's the can make it larger if you want

873
00:50:28,290 --> 00:50:30,600
and i also

874
00:50:30,650 --> 00:50:32,580
the time i can and in some noise

875
00:50:32,580 --> 00:50:35,250
and i can get a pretty good

876
00:50:36,290 --> 00:50:37,270
of what

877
00:50:37,620 --> 00:50:42,420
all right the so be it should be because if i have obeyed my sampling

878
00:50:42,420 --> 00:50:46,140
theory and things like that all the information is there i need the cartoon

879
00:50:47,730 --> 00:50:48,870
and we have

880
00:50:48,890 --> 00:50:51,770
essentially refer to this is by linear

881
00:50:52,210 --> 00:50:57,750
interpolation now there are other variants human we actually can of trying

882
00:50:57,750 --> 00:51:03,310
it's essentially equivalent the second order derivative but generally falling is good enough and that's

883
00:51:03,310 --> 00:51:05,370
essentially what we use in all this stuff

884
00:51:06,870 --> 00:51:09,190
that's good

885
00:51:09,210 --> 00:51:12,560
for hopefully not going too slow this kind of starting from the beginning kind of

886
00:51:12,560 --> 00:51:17,040
building it so that's how our like given that i have a wall and i

887
00:51:17,040 --> 00:51:20,600
might have fractional coordinates that's how actually get

888
00:51:20,620 --> 00:51:23,620
my image intensities

889
00:51:24,270 --> 00:51:26,890
you can also that's all well and good

890
00:51:27,210 --> 00:51:29,170
and if if

891
00:51:29,190 --> 00:51:33,230
if all coming straight from machine learning which which con was when i started this

892
00:51:33,250 --> 00:51:36,600
actually came from a very different direction to a lot of people when i started

893
00:51:36,600 --> 00:51:42,290
working computer vision idea quite a reasonable background in pattern recognition and machine learning and

894
00:51:42,290 --> 00:51:46,460
i sort came into this and so well what's the big deal i can essentially

895
00:51:46,480 --> 00:51:49,750
go three this when all around

896
00:51:50,390 --> 00:51:51,910
at every values

897
00:51:51,920 --> 00:51:53,830
i can essentially vectorize

898
00:51:53,850 --> 00:51:57,940
these are the pixel values and here the same

899
00:51:57,960 --> 00:52:01,960
the maximum values between fifty five draws and essentially

900
00:52:02,410 --> 00:52:07,370
how to look at every possible value in in in in a certain area so

901
00:52:07,420 --> 00:52:10,170
can so that we will everything all

902
00:52:10,230 --> 00:52:11,190
and then

903
00:52:11,210 --> 00:52:16,600
if i if i then has from my naive perspective whatever i can't then said

904
00:52:16,600 --> 00:52:19,940
my second lecture

905
00:52:24,470 --> 00:52:28,030
so i want to say that this is not true because what i wanted to

906
00:52:28,030 --> 00:52:30,490
present in this lecture is

907
00:52:30,530 --> 00:52:34,740
overview of data structures and

908
00:52:34,760 --> 00:52:38,990
our current background but how do they have

909
00:52:40,490 --> 00:52:42,690
i believe that it is not doing

910
00:52:42,740 --> 00:52:46,210
it's not possible in one lecture to give

911
00:52:46,240 --> 00:52:50,700
a comprehensive overview of this topic

912
00:52:50,750 --> 00:52:57,230
so this idea and they have to be very very simple expression or phrase

913
00:52:57,250 --> 00:52:59,400
of this problem

914
00:52:59,450 --> 00:53:02,700
the first problem is how to create an effect and also

915
00:53:02,720 --> 00:53:04,760
this lecture is

916
00:53:04,770 --> 00:53:05,900
the last

917
00:53:05,900 --> 00:53:09,400
connected real information structure

918
00:53:09,410 --> 00:53:13,250
lecture in the car because it's all about

919
00:53:13,260 --> 00:53:14,970
company o

920
00:53:15,540 --> 00:53:20,900
structure for innovation it doesn't have anything

921
00:53:20,930 --> 00:53:27,580
connected with information and they will our task construction information

922
00:53:27,600 --> 00:53:31,120
starring information need

923
00:53:31,130 --> 00:53:33,260
four from a user

924
00:53:33,270 --> 00:53:36,870
so the question is how to create an effective

925
00:53:37,990 --> 00:53:40,600
very very common approach

926
00:53:41,490 --> 00:53:44,910
talk briefly about modern hardware

927
00:53:45,770 --> 00:53:50,930
a new in and why characterize different from what we

928
00:53:50,960 --> 00:53:53,600
had ten years ago

929
00:53:53,620 --> 00:53:57,370
then i need to talk a bit about compression

930
00:53:57,540 --> 00:54:01,660
don't talk much more about compression tomorrow

931
00:54:02,180 --> 00:54:06,520
when i describe compression and indexing

932
00:54:06,540 --> 00:54:08,740
but the problem is that

933
00:54:08,760 --> 00:54:12,850
i want to be sure that you have some background

934
00:54:13,020 --> 00:54:15,820
this is in the compression

935
00:54:15,870 --> 00:54:22,480
you can understand what is the difference from this very simple and ordinary compression or

936
00:54:22,510 --> 00:54:23,810
actually i

937
00:54:23,820 --> 00:54:28,320
my concern on your understanding of similarity between this

938
00:54:28,320 --> 00:54:30,750
for this aberration

939
00:54:30,850 --> 00:54:34,850
then i will briefly describe the structure and

940
00:54:36,000 --> 00:54:41,940
what we're going to do you remember during our search engine and we need to

941
00:54:41,940 --> 00:54:45,820
build a dictionary rather than going to put all work

942
00:54:46,440 --> 00:54:49,040
talking about structure

943
00:54:49,380 --> 00:54:52,840
solving this problem about trying to put into memory

944
00:54:52,850 --> 00:54:56,600
on may be on this if you have huge dictionary

945
00:54:56,610 --> 00:54:58,510
i'm going to put all work

946
00:54:58,530 --> 00:55:00,130
from all documents

947
00:55:00,190 --> 00:55:02,350
and here we are looking for

948
00:55:02,360 --> 00:55:06,510
toy application window applications correction because

949
00:55:06,560 --> 00:55:10,540
sometimes it important we need to do correction

950
00:55:10,570 --> 00:55:17,200
imagine that we are getting very good documents from character recognition and want to improve

951
00:55:17,200 --> 00:55:24,100
our indexing by automatic correction and then discuss how to implement analysis

952
00:55:24,160 --> 00:55:28,840
and then i will give you a very brief introduction to to presentation and they

953
00:55:28,840 --> 00:55:30,860
were not introduction simply

954
00:55:30,920 --> 00:55:38,290
mentioning on some more and definitions in prohibition that we need to understand the inventor

955
00:55:38,420 --> 00:55:43,820
talk about innovation of information they will agree

956
00:55:43,840 --> 00:55:47,320
so how can create effective

957
00:55:47,320 --> 00:55:51,410
o structure which searching for other

958
00:55:52,480 --> 00:55:56,130
so what we need to think about to think about

959
00:55:56,140 --> 00:55:57,570
data usage

960
00:55:57,600 --> 00:56:00,660
however going to use these days

961
00:56:00,690 --> 00:56:04,850
if that building dictionary what we're going to do with picture

962
00:56:04,860 --> 00:56:08,820
usually they are going to add and we're going to show

963
00:56:08,880 --> 00:56:10,780
so the picture should be

964
00:56:13,230 --> 00:56:17,310
insertion if you do if if you do it in the first challenge

965
00:56:18,630 --> 00:56:21,640
if going to be already

966
00:56:21,660 --> 00:56:23,760
there have been this index

967
00:56:24,340 --> 00:56:29,450
i don't need to optimise the search for this particular type of in the world

968
00:56:29,450 --> 00:56:32,990
judge structure need to optimize the church

969
00:56:33,020 --> 00:56:35,550
so first of all we need to decide

970
00:56:35,560 --> 00:56:41,600
what going to do with this data structure what what what what is the main

971
00:56:43,230 --> 00:56:45,840
how we will access the date

972
00:56:45,850 --> 00:56:47,710
this is our first task

973
00:56:47,720 --> 00:56:48,730
going to

974
00:56:48,770 --> 00:56:53,280
as i said in our thinking of the structure

975
00:56:53,330 --> 00:56:57,870
then we need to do some selection we need to select chorus

976
00:56:57,890 --> 00:57:00,160
and select structure

977
00:57:01,300 --> 00:57:05,620
actually not not two options to one

978
00:57:06,920 --> 00:57:07,910
you cannot

979
00:57:07,960 --> 00:57:10,750
separate stories from structure

980
00:57:10,770 --> 00:57:12,810
i think that the

981
00:57:12,840 --> 00:57:20,300
remember this famous book from the extra programs are very different class structure

982
00:57:21,040 --> 00:57:22,860
the main point of the ball

983
00:57:22,870 --> 00:57:26,970
that you cannot separate algorithms structures that together this

984
00:57:27,030 --> 00:57:30,120
it's in our programs

985
00:57:30,140 --> 00:57:37,200
very very and structures changing algorithm changes structures usually and the same

986
00:57:39,370 --> 00:57:46,660
and the last it's a bit controversial option and to be getting so it's that

987
00:57:46,680 --> 00:57:49,660
again as i said on the first lecture

988
00:57:49,680 --> 00:57:53,390
if we are trying to implement good compression

989
00:57:53,400 --> 00:57:56,240
maybe you don't need to implement it

990
00:57:56,250 --> 00:58:01,340
because if you don't know how to implement compression maybe you have a library to

991
00:58:01,340 --> 00:58:03,500
read doing the

992
00:58:04,870 --> 00:58:07,530
what i'm going to say is that

993
00:58:09,350 --> 00:58:14,420
the current more situation we already have a lot of libraries

994
00:58:14,430 --> 00:58:19,170
and for professional developer and especially for church

995
00:58:19,200 --> 00:58:22,210
it's much more important to understand how to

996
00:58:22,220 --> 00:58:24,460
the right through

997
00:58:24,470 --> 00:58:26,240
and how to use them

998
00:58:26,290 --> 00:58:31,730
then to create the tools from scratch because it's simply not durable in many cases

999
00:58:32,650 --> 00:58:36,060
what we're talking about effective data presentation

1000
00:58:36,420 --> 00:58:39,160
this strange situation here

1001
00:58:39,160 --> 00:58:42,370
and i will talk about it when i talk about

1002
00:58:42,400 --> 00:58:47,560
more than hardware and about all other stuff is that

1003
00:58:49,140 --> 00:58:52,310
data representation is representation that

1004
00:58:53,660 --> 00:58:56,350
we trying to optimize

1005
00:58:57,560 --> 00:59:00,860
complexities of our algorithm

1006
00:59:00,860 --> 00:59:03,990
use exact language that's the meaning of the word analysis

1007
00:59:04,040 --> 00:59:07,400
i think close enough whereas synthesis

1008
00:59:07,530 --> 00:59:13,030
has to do with reassembling signal reassembling function from its constituent parts

1009
00:59:13,140 --> 00:59:20,150
the signals from

1010
00:59:20,210 --> 00:59:22,440
its constituent parts

1011
00:59:24,550 --> 00:59:33,510
all right and the two things go together all right you know one one without

1012
00:59:33,510 --> 00:59:36,610
the other you want you want to break something up into its constituent parts and

1013
00:59:36,680 --> 00:59:37,860
just let it sit there

1014
00:59:37,880 --> 00:59:40,190
all these little parts and on the table with nothing to do

1015
00:59:40,220 --> 00:59:43,440
want to be able to take those parts may be modified those parts may be

1016
00:59:43,440 --> 00:59:45,740
see which parts are more important than other parts and then you want to put

1017
00:59:45,740 --> 00:59:49,290
it back together to get the to get the original signal or a new signal

1018
00:59:49,340 --> 00:59:51,800
and the process of doing those things the two

1019
00:59:51,810 --> 01:00:00,830
aspects of fourier analysis i use i use the word analysis there's sort more generic

1020
01:00:01,480 --> 01:00:06,430
the other thing to realize about both of these procedures analysis and synthesis is that

1021
01:00:06,430 --> 01:00:10,430
they are accomplished by linear operations

1022
01:00:10,470 --> 01:00:14,810
series and into rules are always involved here both analysis and synthesis

1023
01:00:14,870 --> 01:00:17,300
fourier analysis

1024
01:00:17,310 --> 01:00:22,620
analysis and synthesis

1025
01:00:26,300 --> 01:00:36,270
by linear operations

1026
01:00:36,270 --> 01:00:39,140
this is one of the reasons why the subject is so

1027
01:00:39,260 --> 01:00:46,140
so powerful because there's such a body of knowledge on and as such a deep

1028
01:00:46,140 --> 01:00:50,570
in advance understanding of linear operations linearity will make this a little bit more explicitly

1029
01:00:50,580 --> 01:00:53,950
go as we go on further but i want to point out now because i

1030
01:00:53,950 --> 01:00:58,370
won't always pointed out right because when i say linear operations one thing here in

1031
01:00:58,370 --> 01:00:59,980
real time series

1032
01:01:00,890 --> 01:01:04,010
e g i integral

1033
01:01:04,040 --> 01:01:08,180
and series

1034
01:01:08,190 --> 01:01:12,770
both of which are linear operations in all the sum is the sum of the

1035
01:01:12,770 --> 01:01:16,940
integrals in the real world of constantine's of functions of constantinople the function

1036
01:01:16,990 --> 01:01:21,890
and so on and similarly with some so i because of this one often says

1037
01:01:21,960 --> 01:01:25,240
one often things that fourier analysis is part of

1038
01:01:25,290 --> 01:01:30,180
the study of linear systems right in in engineering is there's there's there are courses

1039
01:01:30,180 --> 01:01:33,780
called linear systems and so on and sometimes fourier analysis is thought to be a

1040
01:01:33,780 --> 01:01:37,430
part of that because the operations involved in it are linear i don't

1041
01:01:37,460 --> 01:01:40,370
think of it that way and i think it somehow important enough on its own

1042
01:01:40,420 --> 01:01:44,550
but i think of it necessarily is subsumed in a larger subject but nevertheless the

1043
01:01:44,550 --> 01:01:46,790
fact that the operations are linear

1044
01:01:46,840 --> 01:01:50,320
r does put it in a certain context

1045
01:01:50,330 --> 01:01:53,650
in some in some ways in some cases the more general context that turns out

1046
01:01:53,670 --> 01:01:55,420
to be important for many ideas

1047
01:01:55,500 --> 01:01:58,270
right so often so you see

1048
01:01:58,360 --> 01:02:04,480
we often hear that fourier analysis

1049
01:02:04,490 --> 01:02:05,360
three a

1050
01:02:05,380 --> 01:02:09,560
analysis is part of

1051
01:02:09,610 --> 01:02:17,400
the subject of linear systems the study of linear systems so i don't think they

1052
01:02:17,420 --> 01:02:21,250
really does complete justice to for a analysis

1053
01:02:21,290 --> 01:02:24,420
because because the particular special things that are involved in but nevertheless you will you'll

1054
01:02:24,420 --> 01:02:27,670
hear that

1055
01:02:33,840 --> 01:02:36,350
let's get launched alright let's start with

1056
01:02:36,360 --> 01:02:38,070
the actual

1057
01:02:38,120 --> 01:02:42,240
subject of fourier series and the analysis of periodic

1058
01:02:42,280 --> 01:02:52,230
periodic phenomena

1059
01:02:52,240 --> 01:02:57,350
and for

1060
01:02:57,370 --> 01:03:01,250
as i said is certainly shouldn't be necessary

1061
01:03:01,250 --> 01:03:06,390
for me to sell the importance of periodic phenomena is something worth studying you see

1062
01:03:06,390 --> 01:03:07,840
it everywhere

1063
01:03:10,240 --> 01:03:14,440
the study phenomena is for us the mathematics and engineering or mathematics and science and

1064
01:03:14,440 --> 01:03:15,740
engineering of

1065
01:03:15,920 --> 01:03:22,370
regularly repeating phenomenon that's what always involves some pattern that repeats and repeats regularly right

1066
01:03:22,720 --> 01:03:24,650
so the mathematics

1067
01:03:24,750 --> 01:03:31,430
and engineering sciences and engineering course

1068
01:03:31,430 --> 01:03:33,930
out of that before science

1069
01:03:33,980 --> 01:03:38,870
maybe i won't even mention science mathematics and engineering of regularly repeating patterns

1070
01:03:42,690 --> 01:03:50,010
i'm leaving a couple of terms here i mean all these terms somewhat of a

1071
01:03:50,080 --> 01:03:53,420
what does it mean to be regular what does it mean repeating what is a

1072
01:03:53,420 --> 01:03:56,200
pattern in the first place but you know what you you know what i mean

1073
01:03:56,200 --> 01:03:58,870
you know it when you see it

1074
01:03:58,890 --> 01:04:03,720
and in fact you can mathematically analyse it is what makes the subject so useful

1075
01:04:04,330 --> 01:04:07,140
i think

1076
01:04:07,170 --> 01:04:10,720
although again

1077
01:04:10,740 --> 01:04:13,570
it's not ironclad she was the subject is so rich that every time i make

1078
01:04:13,570 --> 01:04:16,010
a statement i felt i had to qualify well it's often true but is not

1079
01:04:16,010 --> 01:04:19,510
completely true and sometimes not really true but most of the time it's true

1080
01:04:19,630 --> 01:04:23,290
that it's helpful but not always helpful but in most of the time application helpful

1081
01:04:23,290 --> 01:04:25,340
to classify

1082
01:04:25,360 --> 01:04:29,720
periodicity as either periodicity entire periodicity in space

1083
01:04:29,760 --> 01:04:35,080
all right you often see periodic phenomena as one type or the other type although

1084
01:04:35,110 --> 01:04:37,350
they can overlap see often

1085
01:04:37,390 --> 01:04:40,730
periodic phenomena

1086
01:04:47,140 --> 01:04:53,700
periodicity in in time

1087
01:04:53,750 --> 01:04:58,280
a pattern repeats in time over and over again you wait long enough and happens

1088
01:04:58,280 --> 01:05:04,770
again so for example harmonic motion so e g harmonic motion and on

1089
01:05:04,780 --> 01:05:06,750
o thing but on the string

1090
01:05:06,840 --> 01:05:09,600
harmonic motion

1091
01:05:09,740 --> 01:05:12,780
or periodicity is base

1092
01:05:12,790 --> 01:05:19,280
and every

1093
01:05:19,330 --> 01:05:39,220
it is the space

1094
01:05:39,280 --> 01:05:42,980
the city in space by now

1095
01:05:42,980 --> 01:05:47,830
because you have to make some approximations to solve the many body problem

1096
01:05:47,840 --> 01:05:52,340
so it means that you need to have an approximate inference which is adapted for

1097
01:05:52,360 --> 01:05:55,020
this approach is if you change your approach

1098
01:05:55,030 --> 01:05:57,480
we should the from that you have developed

1099
01:05:57,490 --> 01:06:01,350
it is OK for these new and better approach

1100
01:06:01,380 --> 01:06:05,820
so the different approximation i will mention tools of the show more because it was

1101
01:06:05,820 --> 01:06:10,020
the first approach developed for nuclear physics and the approach is based on the mean

1102
01:06:10,020 --> 01:06:14,050
field so they are quite different in the philosophy

1103
01:06:14,070 --> 01:06:20,690
so the other types like UBM interacting boson interactions like algebraic approaches

1104
01:06:20,720 --> 01:06:24,300
but for prediction of many many nuclear this one

1105
01:06:24,740 --> 01:06:27,980
to my mind the well suited

1106
01:06:27,990 --> 01:06:34,280
i recall you what we call because of what what are the nucleons in quantum

1107
01:06:35,420 --> 01:06:39,260
so they have access to discrete number of states

1108
01:06:39,290 --> 01:06:44,620
because they are quantum objects so there on the can have only some values of

1109
01:06:44,620 --> 01:06:46,520
the energy is

1110
01:06:46,530 --> 01:06:51,240
they are fairly and so that means that they cannot occupy the same quantum states

1111
01:06:51,260 --> 01:06:55,990
with all the same quantum numbers it's what we call the pauli principle

1112
01:06:55,990 --> 01:07:00,400
so that's why he had neutral and protons and here for example the difference in

1113
01:07:00,410 --> 01:07:03,930
the speed at the

1114
01:07:03,970 --> 01:07:06,250
so then the

1115
01:07:06,260 --> 01:07:10,490
historically part of the show model it was developed by get my year in nineteen

1116
01:07:10,490 --> 01:07:11,730
forty eight

1117
01:07:11,750 --> 01:07:13,000
and it's only

1118
01:07:13,010 --> 01:07:17,570
so what is it about for electrons in at all

1119
01:07:17,590 --> 01:07:22,320
so what you say during another conference in nineteen sixty three

1120
01:07:22,340 --> 01:07:28,380
if that in analogy with that atomic structure one may postulate that in the nucleus

1121
01:07:28,400 --> 01:07:33,650
the nucleons move fairly independently in individual orbits in an average potential

1122
01:07:33,670 --> 01:07:36,410
which we can assume to have a spherical symmetry

1123
01:07:36,420 --> 01:07:40,070
so what does it mean that you have the potential

1124
01:07:40,090 --> 01:07:44,110
that is seen by the media and so this is an example potential deduced from

1125
01:07:44,110 --> 01:07:46,650
experiments with this sort had this

1126
01:07:46,690 --> 01:07:49,800
died what's some potential return here

1127
01:07:49,830 --> 01:07:52,350
where you have here that some here

1128
01:07:52,710 --> 01:07:56,160
the range started there and air

1129
01:07:56,160 --> 01:08:01,020
to have an analytical solution of this potential is quite difficult so you can approximate

1130
01:08:01,030 --> 01:08:05,240
with this can where you are and when you later which are plotted here

1131
01:08:05,250 --> 01:08:08,780
so this is wrong minus fourteen anything

1132
01:08:08,800 --> 01:08:10,690
this is around two fairly so

1133
01:08:10,700 --> 01:08:13,690
you see that you have different shapes

1134
01:08:13,700 --> 01:08:18,600
you can say whatever of these potential that you want these three is seen in

1135
01:08:18,600 --> 01:08:20,730
our is so you can cannot

1136
01:08:20,740 --> 01:08:24,060
so that's so it's not so sensitive

1137
01:08:24,080 --> 01:08:30,450
two suppose should use here either what sex scale with our our facilitators

1138
01:08:30,460 --> 01:08:32,270
so then

1139
01:08:32,290 --> 01:08:34,990
you have different states

1140
01:08:35,000 --> 01:08:38,950
neutron on pretense of operator and you have the revision so it

1141
01:08:39,120 --> 01:08:41,000
hiring energy

1142
01:08:41,020 --> 01:08:44,200
these quantum states that characterized by

1143
01:08:44,260 --> 01:08:48,720
quantum numbers so principal quantum number big n

1144
01:08:48,730 --> 01:08:51,770
right quantum number small so

1145
01:08:51,800 --> 01:08:56,600
for the special expansion it really depends on the number of the beast members

1146
01:08:56,620 --> 01:08:59,570
azimuthal quantum number l spring

1147
01:08:59,650 --> 01:09:01,100
and so

1148
01:09:01,130 --> 01:09:03,200
feel these different

1149
01:09:03,270 --> 01:09:07,400
there are some rules and for example you have this relation

1150
01:09:07,400 --> 01:09:08,470
we introduce to

1151
01:09:09,020 --> 01:09:14,000
momentum which is all little argument implies the been so this is the total angular

1152
01:09:15,010 --> 01:09:16,590
so then

1153
01:09:16,610 --> 01:09:21,150
you you're single particle levels in the shell model when you start running an equation

1154
01:09:21,160 --> 01:09:25,170
with this potential so this is example for scareware

1155
01:09:25,180 --> 01:09:31,080
scott then you have these big n here and small n and l

1156
01:09:31,100 --> 01:09:35,010
from physics you need to introduce this binaural so

1157
01:09:35,020 --> 01:09:40,150
l stein is company and this is very important to find these

1158
01:09:40,170 --> 01:09:42,310
structure face so

1159
01:09:42,340 --> 01:09:45,850
and then you have all your here

1160
01:09:45,870 --> 01:09:49,010
and you see that you have some gaps

1161
01:09:49,020 --> 01:09:53,100
so these twenty eight especially his created by just been over here

1162
01:09:53,200 --> 01:09:58,200
but the other one created here so you have gaps for these major members

1163
01:09:58,220 --> 01:10:00,460
that i told you before

1164
01:10:00,480 --> 01:10:04,250
so you see that for example if you feel at this point here

1165
01:10:04,270 --> 01:10:06,540
you will have a very stable nuclides

1166
01:10:06,550 --> 01:10:09,360
so if you want to excited you will have to

1167
01:10:09,370 --> 01:10:12,790
two rules about the definitely put something here so

1168
01:10:12,800 --> 01:10:16,000
all these nuclear that's why they are very stable

1169
01:10:16,010 --> 01:10:18,960
because of these here in the energy

1170
01:10:23,510 --> 01:10:30,420
the historical independent body show more than has been improved a lot

1171
01:10:30,470 --> 01:10:37,650
because OK give very satisfying results for magic nuclei especially for the ground state

1172
01:10:37,670 --> 01:10:41,400
and low lying excited states where promotes nucleons

1173
01:10:41,420 --> 01:10:44,230
on different channels

1174
01:10:44,280 --> 01:10:47,300
but in fact in the nuclear you don't have only the

1175
01:10:47,320 --> 01:10:54,310
individual citations where only a few are promoted and two different shows you have also

1176
01:10:54,320 --> 01:10:58,570
corey around motion an awful lot of articles to get what we call so they

1177
01:10:58,570 --> 01:11:04,590
can can vibration can vibrate you can have richer nations of car and motion of

1178
01:11:04,590 --> 01:11:06,430
different nucleons

1179
01:11:06,430 --> 01:11:08,260
lots of those

1180
01:11:08,290 --> 01:11:10,870
and there will be some something very blurred

1181
01:11:12,510 --> 01:11:14,400
many of those units

1182
01:11:14,410 --> 01:11:17,610
as will be the result

1183
01:11:17,660 --> 01:11:19,130
and it's also clear that

1184
01:11:19,520 --> 01:11:20,620
if they are not

1185
01:11:20,630 --> 01:11:21,240
you know

1186
01:11:21,300 --> 01:11:27,450
doing the same thing and in parallel and everything then you don't see anything

1187
01:11:30,210 --> 01:11:32,950
with e g we can measure

1188
01:11:34,170 --> 01:11:38,440
at least ten thousand of the neurons are doing similar things

1189
01:11:38,450 --> 01:11:39,850
in parallel

1190
01:11:39,890 --> 01:11:47,000
and also there some geometrical issue in EEG so so if you have these little

1191
01:11:47,020 --> 01:11:49,440
so dipoles

1192
01:11:49,450 --> 01:11:53,020
we can are all of these

1193
01:11:53,040 --> 01:11:57,420
current dipoles then we cannot measure

1194
01:11:57,710 --> 01:12:02,210
things that don't have the right orientation to be measured with EEG

1195
01:12:02,230 --> 01:12:05,900
so you g is blind to some directions

1196
01:12:08,910 --> 01:12:10,070
things that are

1197
01:12:10,090 --> 01:12:11,270
no way

1198
01:12:11,290 --> 01:12:12,790
in the fold

1199
01:12:12,810 --> 01:12:14,750
on invisible to two

1200
01:12:14,760 --> 01:12:17,050
e g but

1201
01:12:17,100 --> 01:12:22,070
in with the MEGA measuring the magnetic field so things might be different e g

1202
01:12:22,600 --> 01:12:24,940
and m gene can measure

1203
01:12:25,660 --> 01:12:29,210
you can use it to measure so negatively

1204
01:12:29,230 --> 01:12:32,470
but in general images has a higher resolution

1205
01:12:35,150 --> 01:12:36,460
OK so

1206
01:12:36,490 --> 01:12:39,200
a single neuron

1207
01:12:41,120 --> 01:12:42,730
hands up

1208
01:12:42,870 --> 01:12:45,980
there are lots of neurons in parallel

1209
01:12:45,990 --> 01:12:50,450
add up to something mecca macroscopic the visible

1210
01:12:50,920 --> 01:12:53,730
and something visible with an

1211
01:12:53,750 --> 01:12:55,950
usually EEG device

1212
01:12:56,050 --> 01:12:59,210
and so

1213
01:13:01,230 --> 01:13:08,410
we will mostly be focusing on the somatosensory cortex which is not the red box

1214
01:13:08,410 --> 01:13:10,200
with some

1215
01:13:10,240 --> 01:13:12,650
taken tony jarrett box

1216
01:13:16,940 --> 01:13:22,860
so this is so to say the last stage

1217
01:13:22,870 --> 01:13:25,090
so you have this microscopic

1218
01:13:25,100 --> 01:13:32,240
electric field and you can sample the with EEG electrodes so he plays a number

1219
01:13:32,240 --> 01:13:35,150
of electrodes all over the place

1220
01:13:35,160 --> 01:13:40,670
say sixty four hundred twenty eight which is the standard

1221
01:13:40,690 --> 01:13:41,900
and you can measure

1222
01:13:41,910 --> 01:13:47,610
certain contributions of this electric field and of course you have more than one

1223
01:13:52,360 --> 01:13:53,220
and you see

1224
01:13:53,660 --> 01:13:55,170
in this picture

1225
01:13:55,710 --> 01:13:57,980
you see eugenia

1226
01:13:59,810 --> 01:14:01,960
this is the reference but you

1227
01:14:01,970 --> 01:14:04,910
clue and another young all but you can also

1228
01:14:04,950 --> 01:14:06,160
but you

1229
01:14:06,180 --> 01:14:10,720
you have to have one electrodes which is to say

1230
01:14:10,750 --> 01:14:18,010
the reference electrode with respect to which all of the electrodes measure

1231
01:14:20,400 --> 01:14:24,900
in fact you always have to fixate such an EEG cap

1232
01:14:24,910 --> 01:14:26,430
and you have the

1233
01:14:26,490 --> 01:14:29,650
quite uncomfortable robert thing

1234
01:14:29,670 --> 01:14:31,110
oppose it to you

1235
01:14:33,110 --> 01:14:36,960
because of the way the connection is not so good so the

1236
01:14:38,720 --> 01:14:45,160
the the gel electrodes essentially have an impedance of about five kilometres you do it

1237
01:14:45,820 --> 01:14:48,350
ten don't do it so well

1238
01:14:49,340 --> 01:14:50,460
or or more

1239
01:14:52,500 --> 01:14:58,620
and what you can typically measures are signals of the all the

1240
01:14:58,660 --> 01:15:02,340
five to fifty or sixty microblogging

1241
01:15:02,360 --> 01:15:03,320
each the two

1242
01:15:03,350 --> 01:15:06,480
just to give you an impression

1243
01:15:06,500 --> 01:15:12,280
with low impedance

1244
01:15:14,600 --> 01:15:18,190
so let's have

1245
01:15:18,190 --> 01:15:19,740
so over you

1246
01:15:19,770 --> 01:15:22,680
how things can be done

1247
01:15:23,450 --> 01:15:28,030
first of all there is the obvious thing

1248
01:15:28,090 --> 01:15:32,010
so you can implant sensors two brain surgeries

1249
01:15:32,030 --> 01:15:36,870
and place an electrode array into your brain

1250
01:15:39,140 --> 01:15:48,130
place areas of sensors on the brain say with electoral that the core technology

1251
01:15:48,340 --> 01:15:53,280
so noninvasively you could measure with e for example

1252
01:15:53,300 --> 01:15:58,400
and this is mostly not penetrating the skull in this sense

1253
01:15:59,290 --> 01:16:03,920
when you put the gel into these electrodes and occasionally scratch the skin a little

1254
01:16:03,920 --> 01:16:08,760
bit but that's the only invasive thing that you do with e g

1255
01:16:08,770 --> 01:16:15,300
but there's also other things like mhg you could use from i principle

1256
01:16:15,690 --> 01:16:17,210
or new years

1257
01:16:17,220 --> 01:16:19,190
near infrared spectroscopy

1258
01:16:19,200 --> 01:16:24,600
all these techniques have to have different time scales in different resolutions e g has

1259
01:16:24,600 --> 01:16:27,100
about it the resolution of one centimeter

1260
01:16:27,100 --> 01:16:36,600
image is slightly better news is even better they have a rather decent

1261
01:16:36,600 --> 01:16:40,840
o thing identified but this URI is the same thing is identified by a URI

1262
01:16:41,000 --> 01:16:46,660
so she went more discussion about the semantic service before the end of the tutorial

1263
01:16:51,660 --> 01:16:55,050
there are lots of property from folk which are very popular for just place data

1264
01:16:55,090 --> 01:16:58,290
together many people and then this

1265
01:16:58,640 --> 01:16:59,990
if you kind

1266
01:17:00,040 --> 01:17:01,800
properties which is a kind of

1267
01:17:01,880 --> 01:17:02,860
to sense

1268
01:17:02,940 --> 01:17:18,920
this with the list i compiled based on my own experience is not is not

1269
01:17:18,920 --> 01:17:21,050
grounds in

1270
01:17:21,280 --> 01:17:29,810
might have some data on that from the from the sun to spend the paper

1271
01:17:29,810 --> 01:17:33,040
about the precise usage from

1272
01:17:33,350 --> 01:17:36,000
this is really my

1273
01:17:37,460 --> 01:17:41,100
personally i brainstormed list stuff that people use

1274
01:17:42,560 --> 01:17:44,630
there are these

1275
01:17:44,660 --> 01:17:48,170
three properties of the bottom often kind of useful kind of glue properties just tying

1276
01:17:48,170 --> 01:17:55,020
stuff together and say five page to say that this the page particular page

1277
01:17:55,290 --> 01:17:58,560
so if you in this i was taught about we've got RDF document and then

1278
01:17:58,560 --> 01:18:02,760
you've got to an HTML page about the same thing you can use this property

1279
01:18:02,760 --> 01:18:04,670
to say in the RDF documents

1280
01:18:05,140 --> 01:18:08,400
the corresponding HTML page

1281
01:18:11,730 --> 01:18:15,850
so from the talk about second price if you're not talking on the web specify

1282
01:18:15,850 --> 01:18:16,600
what is

1283
01:18:16,800 --> 01:18:20,770
actually about you can use the property to do so and rdfs seealso is really

1284
01:18:20,770 --> 01:18:25,730
just the way of connecting to other related documents that state a particular user agent

1285
01:18:25,730 --> 01:18:27,160
might want to also

1286
01:18:29,340 --> 01:18:33,200
the reference and integrate with the same

1287
01:18:33,420 --> 01:18:35,100
same data releasing

1288
01:18:35,220 --> 01:18:39,380
so if we think back to the whiskey dotcom example i mean there's a number

1289
01:18:39,380 --> 01:18:43,120
of ways that we can type in the data and in the in the wiskii

1290
01:18:43,200 --> 01:18:47,180
com data set of data sets so

1291
01:18:47,500 --> 01:18:49,980
i i think each other distilleries to their

1292
01:18:50,080 --> 01:18:51,710
corresponding entries on the pedia

1293
01:18:51,780 --> 01:18:57,950
whiskey fans being quite quite fanatical of create lots and lots of useful information on

1294
01:18:58,110 --> 01:19:02,300
wikipedia about about whisky distilleries there's also information that we can link

1295
01:19:02,690 --> 01:19:09,370
some of the whisky distilleries independent companies owned by small families or private private individuals

1296
01:19:09,650 --> 01:19:15,770
some the majority by these big kind of multinational binge-drink companies so we might want

1297
01:19:15,770 --> 01:19:18,420
also link the individual stories to their

1298
01:19:18,740 --> 01:19:20,260
parent company

1299
01:19:20,410 --> 01:19:23,880
entries in in the period in which the company

1300
01:19:24,030 --> 01:19:27,040
and also onto whereabouts there actually

1301
01:19:27,190 --> 01:19:30,090
located you can use

1302
01:19:30,180 --> 01:19:33,050
you're the POG in this case to do that

1303
01:19:34,590 --> 01:19:38,880
we've got if her photos of these distilleries on on flickr via the flickr after

1304
01:19:38,880 --> 01:19:45,000
we can link together depictions of these distilleries with information whiskey

1305
01:19:45,700 --> 01:19:50,890
same with regions these things have representations in datasets we want to tie those those

1306
01:19:50,890 --> 01:19:53,800
things together and

1307
01:19:54,060 --> 01:19:55,000
we also

1308
01:19:55,050 --> 01:19:56,590
i want to be able to link

1309
01:19:56,660 --> 01:20:02,030
there is also potential link the brands individual brands in a data set to the

1310
01:20:02,030 --> 01:20:05,600
corresponding entries on wikipedia but we need to be

1311
01:20:05,950 --> 01:20:07,610
catholic in doing this

1312
01:20:07,740 --> 01:20:10,020
and the reason is because on

1313
01:20:10,120 --> 01:20:11,190
there there's some

1314
01:20:11,270 --> 01:20:15,440
whisky brands have where the brand is the name has the same name as the

1315
01:20:16,660 --> 01:20:19,120
and on wikipedia have differentiate between

1316
01:20:22,460 --> 01:20:26,660
not sure telescopes for example but the laphroaig distillery and the laphroaig brand has one

1317
01:20:26,660 --> 01:20:30,680
entry about both of those things so we just links to the

1318
01:20:31,290 --> 01:20:36,960
the laphroaig distillery and the from brands to the the frog entry on the pedia

1319
01:20:36,960 --> 01:20:41,600
then we basically saying that the brand and the distillery with the same thing which

1320
01:20:41,620 --> 01:20:46,750
is the case so this is a kind of nice generic example of how you

1321
01:20:48,620 --> 01:20:51,700
didn't work may careful about how you actually

1322
01:20:51,890 --> 01:20:57,230
the links the making understand the destination that data that the other to before you

1323
01:20:57,230 --> 01:21:02,390
created automatically can often come unstuck with these sorts of situations

1324
01:21:02,850 --> 01:21:08,500
and then want to link the brands and products intended to refute

1325
01:21:08,640 --> 01:21:14,230
so this is basically a schematic representation of this so is that that was look

1326
01:21:14,230 --> 01:21:16,710
on dataset and you can see the or

1327
01:21:17,100 --> 01:21:21,430
lot of potential for linking to external datasets but that's

1328
01:21:22,060 --> 01:21:24,460
the DP one carefully

1329
01:21:24,600 --> 01:21:26,580
in this particular example

1330
01:21:29,000 --> 01:21:30,330
the state of the art in india

1331
01:21:30,370 --> 01:21:35,290
link algorithms linked data is relatively basic there's lots and lots of an example based

1332
01:21:35,290 --> 01:21:40,850
on string matching so imagine to link book titles together there's lots of work with

1333
01:21:40,850 --> 01:21:45,460
just taking combinations of author name and string titles using them as the basis for

1334
01:21:45,460 --> 01:21:47,520
much across different datasets

1335
01:21:48,410 --> 01:21:55,410
things like musicbrainz are quite useful in the musicbrainz dataset for provides a bunch of

1336
01:21:55,960 --> 01:22:00,390
your eyes will be well basically do it which have been mapped into URI space

1337
01:22:00,600 --> 01:22:06,640
pretend fine artists and works contracts and so if other datasets used the same your

1338
01:22:06,640 --> 01:22:10,960
eyes internally because you can download the data set that is common key which can

1339
01:22:10,960 --> 01:22:12,870
be easily used for

1340
01:22:13,540 --> 01:22:19,370
merging expands another example the same there is a slight issue with lifespans in that

1341
01:22:19,660 --> 01:22:20,770
sometimes they been

1342
01:22:20,770 --> 01:22:25,700
OK that zero waste is more than thirty minutes so everybody could go either

1343
01:22:25,710 --> 01:22:30,820
mister actually OK if there was our pride can you don't have to even go

1344
01:22:30,820 --> 01:22:34,300
into the store use scan and you know it

1345
01:22:35,220 --> 01:22:37,760
that's the poll station

1346
01:22:37,810 --> 01:22:42,280
so that in general is this OK there are lots of readers

1347
01:22:42,310 --> 01:22:44,300
the reader or send signals

1348
01:22:44,320 --> 01:22:51,160
OK they reduce signal down who you know those commodities OK they have RFID tag

1349
01:22:51,220 --> 01:22:56,080
there were there were really flat they would say i'm here OK they even during

1350
01:22:56,080 --> 01:22:57,210
the RFID

1351
01:22:57,260 --> 01:23:00,160
but you get into the system you can match you can do a lot of

1352
01:23:00,930 --> 01:23:03,890
but with this

1353
01:23:03,910 --> 01:23:07,000
how will be the RFID could be are ready

1354
01:23:07,010 --> 01:23:09,960
because if you reading so many different things

1355
01:23:09,990 --> 01:23:12,140
and you put into the system

1356
01:23:12,150 --> 01:23:15,910
you want to construct a data warehouse you want the data mining the data is

1357
01:23:15,910 --> 01:23:17,590
really really huge

1358
01:23:18,250 --> 01:23:21,510
so with this one starting in

1359
01:23:21,550 --> 01:23:23,510
year two thousand two

1360
01:23:23,510 --> 01:23:31,450
after i came back from the ice the conference that conference to the oracle

1361
01:23:31,450 --> 01:23:37,090
vice president hubert talks said to find petabytes and how to handle the packet but

1362
01:23:37,090 --> 01:23:42,820
state and his most community argument actually is RFID he says

1363
01:23:42,820 --> 01:23:46,950
if you go to war are just a walmart that can just claim they want

1364
01:23:46,950 --> 01:23:51,130
to embrace are widely acknowledged this edit war marked

1365
01:23:51,140 --> 01:23:52,140
they have

1366
01:23:52,160 --> 01:23:53,260
you know if you

1367
01:23:53,260 --> 01:23:56,280
i have every commodity store on the desk

1368
01:23:56,300 --> 01:23:58,300
you know was all the traces

1369
01:23:58,370 --> 01:24:02,340
very can goes rule high order had

1370
01:24:02,350 --> 01:24:03,580
even now

1371
01:24:04,300 --> 01:24:07,740
many other policies so you can verify petabytes

1372
01:24:07,760 --> 01:24:14,270
so then had to actually african back actor discuss with me about his phd thesis

1373
01:24:14,270 --> 01:24:19,290
i said what about we do this RFID data warehouse data mining that could be

1374
01:24:19,290 --> 01:24:22,530
quite interesting to this thesis he got

1375
01:24:22,580 --> 01:24:26,460
you've probably see like i see the two thousand six he got the

1376
01:24:26,480 --> 01:24:28,460
best student paper award

1377
01:24:28,470 --> 01:24:29,950
in this conference

1378
01:24:29,970 --> 01:24:35,320
the warehousing and analyzing RFID data sets that are a lot of research papers surrounding

1379
01:24:35,320 --> 01:24:38,570
in different corners of the of his thesis

1380
01:24:39,480 --> 01:24:42,900
my first part centuries this ceases

1381
01:24:42,920 --> 01:24:48,040
you know abstraction because this is so long it serves would take about two and

1382
01:24:48,040 --> 01:24:54,730
half hours to prevent so our not discussed every corner but our discussed several metres

1383
01:24:54,730 --> 01:25:00,460
things one warehousing how to warehouse RFID and another is how to use a to

1384
01:25:00,460 --> 01:25:02,590
the flow mining traffic mining

1385
01:25:02,610 --> 01:25:05,560
many other things on their minds

1386
01:25:05,590 --> 01:25:09,700
so the first thing i would discuss RFID data warehouse

1387
01:25:11,070 --> 01:25:16,970
so the first thing we should say is the data generated by RFID system can

1388
01:25:16,970 --> 01:25:18,570
easily reach

1389
01:25:20,230 --> 01:25:24,560
that's why they call the state is really enormous y

1390
01:25:24,570 --> 01:25:25,750
they got this

1391
01:25:25,780 --> 01:25:27,240
the problem is

1392
01:25:27,270 --> 01:25:30,110
the reader keeps reading aloud of things

1393
01:25:30,360 --> 01:25:35,800
and that are fed each tag is not that long query thirty six bytes or

1394
01:25:35,800 --> 01:25:38,690
something like this or sixty four bytes

1395
01:25:38,700 --> 01:25:40,780
but if you read

1396
01:25:40,790 --> 01:25:42,550
lots of details

1397
01:25:42,570 --> 01:25:46,280
and many many times you get a lot of redundant

1398
01:25:46,290 --> 01:25:48,350
we so many

1399
01:25:49,360 --> 01:25:52,290
unique acumen two petabytes

1400
01:25:52,310 --> 01:25:56,790
but we found actually even you claim for example warmer

1401
01:25:56,830 --> 01:26:02,430
so they can generate every day they can use seven terrabytes are highlighted

1402
01:26:04,220 --> 01:26:06,320
there are lot redundancy

1403
01:26:06,320 --> 01:26:08,830
and also lots of low level of abstraction

1404
01:26:08,880 --> 01:26:11,540
so if we want warehouse

1405
01:26:11,560 --> 01:26:13,160
the RFID data

1406
01:26:13,200 --> 01:26:16,620
what we want to do is the first thing is we say

1407
01:26:16,660 --> 01:26:21,520
you can have a very highly compact summary for our

1408
01:26:21,540 --> 01:26:23,270
you don't lose anything

1409
01:26:23,310 --> 01:26:26,480
but you actually can make the data much smaller

1410
01:26:26,490 --> 01:26:28,320
that's the first of the age

1411
01:26:28,520 --> 01:26:32,900
another thing is you actually can play with this RFID

1412
01:26:32,910 --> 01:26:36,380
in the substantial scale we call all of this online

1413
01:26:36,400 --> 01:26:42,130
analytical processing music and toured are up on this RFID data in the market dimensional

1414
01:26:42,130 --> 01:26:46,210
space in a very efficient way you get get had about state

1415
01:26:46,270 --> 01:26:51,900
and you also can preserve a lot of information for example you can preserve the

1416
01:26:51,900 --> 01:26:54,340
past structure of RFID

1417
01:26:54,400 --> 01:26:57,860
actually the cost is not that high

1418
01:26:59,420 --> 01:27:03,670
that's the whole thing we think you do data mining and data warehousing with the

1419
01:27:03,740 --> 01:27:06,780
petabytes state is manageable

1420
01:27:06,800 --> 01:27:09,410
to some extent even on your PC

1421
01:27:09,420 --> 01:27:16,160
using may only have two hundred one twenty megabytes gigawatts how can handle petabytes state

1422
01:27:16,170 --> 01:27:18,660
after that you listen to

1423
01:27:18,670 --> 01:27:21,700
two my tutorial profile is not that hard

1424
01:27:24,290 --> 01:27:30,170
let's look the whole thing just this thinking at typical examples of the whole hour

1425
01:27:30,180 --> 01:27:32,200
RFID life cycle

1426
01:27:32,380 --> 01:27:33,920
the fact

1427
01:27:33,930 --> 01:27:39,500
we're generating lots of commodities and they put RFID tag on it

1428
01:27:39,530 --> 01:27:46,440
nowadays the RFID tag is still reason expensive for example the bigger RFID may take

1429
01:27:46,440 --> 01:27:50,170
about a dollar of fifty cents together while RFID tag

1430
01:27:50,180 --> 01:27:54,110
but the price dropping dramatically OK

1431
01:27:54,170 --> 01:27:59,350
now i think in some RFID tag is dropped to almost like cents

1432
01:28:02,350 --> 01:28:08,620
the size could be very small like this year or early this year scientific american

1433
01:28:08,630 --> 01:28:11,500
has one interesting picture is

1434
01:28:11,530 --> 01:28:14,190
the user test tube

1435
01:28:14,460 --> 01:28:18,930
then the test tube just get half of the test tube is

1436
01:28:20,600 --> 01:28:24,580
on the orange juice is they have some very small thing they enlarged it you

1437
01:28:24,580 --> 01:28:32,310
if you do not because it's just now

1438
01:28:32,330 --> 01:28:35,100
it is encouraging

1439
01:28:35,180 --> 01:28:36,970
is given

1440
01:28:37,000 --> 01:28:42,620
in this happening but it

1441
01:28:42,700 --> 01:28:46,910
what is happening which is going to be

1442
01:28:48,470 --> 01:28:52,020
i wanted to know exactly what

1443
01:28:54,560 --> 01:28:58,080
so things may be able to out

1444
01:28:58,080 --> 01:29:02,270
the thing that this is just graphs

1445
01:29:03,000 --> 01:29:04,250
it's the

1446
01:29:04,270 --> 01:29:08,620
examples you extend this this is going to be location

1447
01:29:08,680 --> 01:29:12,330
but you know that's the first

1448
01:29:15,080 --> 01:29:17,580
two months

1449
01:29:32,370 --> 01:29:39,640
so we're talking about you know need to the to

1450
01:29:39,680 --> 01:29:42,870
this is to show that it

1451
01:29:42,870 --> 01:29:47,040
this is example should

1452
01:29:47,080 --> 01:29:54,480
which is exactly the same as graph structure is true

1453
01:29:56,850 --> 01:29:57,750
that means that

1454
01:29:57,910 --> 01:30:00,020
so this becomes a problem

1455
01:30:00,040 --> 01:30:01,790
that's why was concerned

1456
01:30:07,160 --> 01:30:08,620
this makes

1457
01:30:11,580 --> 01:30:16,850
she said you know this is the next

1458
01:30:16,870 --> 01:30:18,040
my just

1459
01:30:18,100 --> 01:30:24,040
this that structures which nations should

1460
01:30:24,040 --> 01:30:26,700
according to the commission

1461
01:30:27,460 --> 01:30:29,450
he the same

1462
01:30:29,520 --> 01:30:36,580
this satisfies the basic idea is that the quality of given that it is and

1463
01:30:36,600 --> 01:30:39,270
it was so satisfied distribution

1464
01:30:40,450 --> 01:30:44,330
this is a structured list

1465
01:30:47,560 --> 01:30:53,600
so for example this is about the difference between infinity

1466
01:30:53,660 --> 01:30:56,040
this question is max

1467
01:30:56,100 --> 01:30:59,560
the question is

1468
01:30:59,640 --> 01:31:01,720
none of the max

1469
01:31:01,740 --> 01:31:04,480
so according to which is

1470
01:31:05,700 --> 01:31:08,410
this is the most likely sequence of states

1471
01:31:09,370 --> 01:31:15,470
to demonstrate the exact same semantics exact results right so he

1472
01:31:15,620 --> 01:31:18,520
according to his agent comes

1473
01:31:19,910 --> 01:31:21,250
exact same thing

1474
01:31:21,290 --> 01:31:26,040
right so what happens next

1475
01:31:26,060 --> 01:31:27,220
is that

1476
01:31:27,220 --> 01:31:31,470
here in the US and chinese x

1477
01:31:32,290 --> 01:31:34,910
we see the positive

1478
01:31:35,120 --> 01:31:37,450
max max c

1479
01:31:37,470 --> 01:31:40,350
it is sometimes a max

1480
01:31:42,060 --> 01:31:43,910
right so you've seen

1481
01:31:44,790 --> 01:31:50,220
that he so impressed essentially the same arguments

1482
01:31:51,180 --> 01:31:53,390
students so that

1483
01:31:53,450 --> 01:31:55,810
but if

1484
01:31:55,850 --> 01:31:59,830
that's the same thing you accuse them

1485
01:32:01,640 --> 01:32:07,080
so you have to be specified rights of this image is

1486
01:32:07,220 --> 01:32:10,850
just to see if it is positive

1487
01:32:12,620 --> 01:32:17,330
is it a max because he said exact information through

1488
01:32:19,700 --> 01:32:23,580
it's not see

1489
01:32:23,580 --> 01:32:26,980
web pages right so they created a graph it

1490
01:32:27,000 --> 01:32:30,700
and everything else is to be made you know how what they did to the

1491
01:32:30,700 --> 01:32:34,840
east everyone collective classification is another example where

1492
01:32:34,870 --> 01:32:39,510
link information knowing that things are not independent but actually quite connected helps us a

1493
01:32:41,560 --> 01:32:47,580
so many network they or many they actually can be represented very naturally as the

1494
01:32:47,580 --> 01:32:52,650
network rights social networks are the most obvious example we know that people in connections

1495
01:32:52,650 --> 01:32:57,280
and friendships or some kind of interaction between people collaboration networks

1496
01:32:57,310 --> 01:33:01,560
for example from the feeling that you can extract from from archive and the other

1497
01:33:01,630 --> 01:33:06,590
another different example where he connect to scientists if they call for the paper

1498
01:33:06,600 --> 01:33:10,920
in systems biology that a lot of networks

1499
01:33:10,930 --> 01:33:16,450
from gene regulatory networks and things like the web graph as i said and citation

1500
01:33:16,450 --> 01:33:21,810
networks are different example now i have papers in web pages as my knowledge and

1501
01:33:21,810 --> 01:33:27,180
connections that citations or hyperbolic internet meaning how

1502
01:33:27,280 --> 01:33:33,410
let's say help this one another in communication networks meaning email things like that here

1503
01:33:33,420 --> 01:33:37,550
know are people in the connection is if one person sentiment to the

1504
01:33:37,970 --> 01:33:40,440
so that's basically what we do

1505
01:33:40,490 --> 01:33:45,110
and what is interesting looking at the other this line that would be because somehow

1506
01:33:45,160 --> 01:33:49,750
it's it's a collective action of many orders of sort of many independent nodes in

1507
01:33:49,750 --> 01:33:54,000
some sense so we get we get to see some kind of merging phenomenon noticed

1508
01:33:54,000 --> 01:33:57,060
there are some kind of design that artifacts was somebody would sit down and say

1509
01:33:57,060 --> 01:34:00,910
this is how i want be but we think of networks of some kind some

1510
01:34:00,910 --> 01:34:06,160
kind of being organic some kind of they arise naturally out of out of these

1511
01:34:06,300 --> 01:34:07,920
local elections of the

1512
01:34:07,970 --> 01:34:13,350
so the question is what do we hope to get from analyse such network they

1513
01:34:15,210 --> 01:34:19,190
analysing such metadata data and so the first thing that just i want to show

1514
01:34:19,190 --> 01:34:23,420
you what how how we go about this is i'm blocking you hear the degree

1515
01:34:23,420 --> 01:34:28,410
distribution of and just simply means what is the number of connections to particular notepad

1516
01:34:28,700 --> 01:34:32,520
and the probability of seeing an another such connections and the point is if i

1517
01:34:32,520 --> 01:34:34,240
claudius on log log scales

1518
01:34:34,240 --> 01:34:38,520
i get this straight line so it means that the whole thing follows this power

1519
01:34:38,520 --> 01:34:43,460
law relationship of being the slope of this thing and what does this tell us

1520
01:34:43,460 --> 01:34:47,640
about the network it tells me that i should think of networks like that right

1521
01:34:47,640 --> 01:34:51,520
where every node has about the same degree i should think about them like this

1522
01:34:51,520 --> 01:34:54,770
right there scale free of species is called the right have

1523
01:34:54,770 --> 01:34:55,900
a lot of these

1524
01:34:56,200 --> 01:35:00,900
high degree copyright right you have so basically and they have these little nodes connecting

1525
01:35:00,920 --> 01:35:02,300
through the heart so

1526
01:35:02,330 --> 01:35:06,670
real networks are like they are not like right so for example this is one

1527
01:35:06,700 --> 01:35:10,610
the other point with that the data is that it spans many orders of magnitude

1528
01:35:10,610 --> 01:35:12,140
so here i just showing you

1529
01:35:12,170 --> 01:35:16,290
you know over the last you know here's span of five years how you know

1530
01:35:16,960 --> 01:35:22,050
networks of let's say five hundred nodes up to two hundred forty million six orders

1531
01:35:22,050 --> 01:35:26,590
of magnitude larger networks were examined in in a short period of a few years

1532
01:35:26,590 --> 01:35:27,990
and these are all you know

1533
01:35:28,080 --> 01:35:33,340
online communication for online social networks and here is the scale and the largest that

1534
01:35:33,360 --> 01:35:36,050
so far is two hundred forty million nodes

1535
01:35:36,080 --> 01:35:37,800
who talks to whom i would

1536
01:35:37,820 --> 01:35:40,390
is the message graph

1537
01:35:41,170 --> 01:35:44,550
people are the users and connections mean that one person but

1538
01:35:45,300 --> 01:35:49,200
and similarly as you can ask what is the structure of

1539
01:35:49,240 --> 01:35:52,230
let's static networks you can ask how does how the

1540
01:35:52,270 --> 01:35:57,890
statistics are global properties of networks change for work on the scale as the network

1541
01:35:58,770 --> 01:36:03,260
and the two examples here are the first one is the following one it's called

1542
01:36:03,270 --> 01:36:06,580
the densification power law with were what i'm showing you here is the size of

1543
01:36:06,590 --> 01:36:07,890
the network over

1544
01:36:07,920 --> 01:36:10,520
so this is the number of nodes in particular point in time

1545
01:36:10,520 --> 01:36:14,300
and the y axis is the number of edges that particular point in time so

1546
01:36:14,300 --> 01:36:19,300
every dot here is is the network of some particular snapshot or at some particular

1547
01:36:20,620 --> 01:36:24,420
and what is the point here is that the point first this is on the

1548
01:36:25,050 --> 01:36:27,490
the second point is that the slope of this line

1549
01:36:27,870 --> 01:36:31,730
is one point six which basically means that the number of edges

1550
01:36:31,740 --> 01:36:36,550
growth of number of nodes some of and this non so it may be greater

1551
01:36:36,550 --> 01:36:40,580
than one meaning that everybody is increasing over time and so for example this is

1552
01:36:40,600 --> 01:36:44,290
this is the case where i have my network and i'm asking what is going

1553
01:36:44,310 --> 01:36:47,980
on some the global statistics of the network as the network

1554
01:36:48,030 --> 01:36:54,190
another simple statistics that also has quite surprising behavior is that they are so some

1555
01:36:54,190 --> 01:36:58,310
some notion of what is the longest or every shortest path length in the networks

1556
01:36:58,310 --> 01:36:59,260
which how many pubs

1557
01:36:59,580 --> 01:37:02,910
this debate from their from around the world some other

1558
01:37:03,940 --> 01:37:09,700
here the x axis by this is the citation network from physics so basically what

1559
01:37:09,890 --> 01:37:14,140
eleven years and this is how the diameter what so basically the idea is that

1560
01:37:14,140 --> 01:37:18,470
even though my network grew from that for more than four orders of magnitude my

1561
01:37:18,480 --> 01:37:23,150
diameter actually show so basically i have this object is getting bigger but internally it's

1562
01:37:23,150 --> 01:37:29,080
getting smaller something and this is another example of how the some nepotistic scale with

1563
01:37:29,080 --> 01:37:30,640
the size of

1564
01:37:32,020 --> 01:37:34,730
the question then is OK why am i doing this what i want to do

1565
01:37:34,730 --> 01:37:37,580
really the output that you want to generate

1566
01:37:37,590 --> 01:37:39,430
how do you go about use

1567
01:37:39,440 --> 01:37:45,290
you know standard machine learning technology to solve these problems right most of the literature

1568
01:37:45,330 --> 01:37:53,230
is probably all binary classification or regression or or perhaps multiclass classification but a lot

1569
01:37:53,230 --> 01:37:59,340
of problems out there you have more complicated prediction problems the second class of problems

1570
01:37:59,340 --> 01:38:02,440
is where the outputs are not

1571
01:38:02,470 --> 01:38:05,100
structures in the strict sense of

1572
01:38:05,140 --> 01:38:07,770
a tree of graph sequence

1573
01:38:07,780 --> 01:38:13,970
but where you have multiple classification problems that are coupled together so we will also

1574
01:38:13,970 --> 01:38:15,960
see many examples of those

1575
01:38:15,970 --> 01:38:19,270
we're really there are multiple response variables

1576
01:38:19,280 --> 01:38:24,390
and the response variables are all interdependent k so you don't want to just predict

1577
01:38:26,090 --> 01:38:31,160
right for each example would the document or be an image or what it is

1578
01:38:31,160 --> 01:38:36,550
right you don't want to be independently predict the label but really you have a

1579
01:38:36,550 --> 01:38:39,770
large set of labels that are that all coupled some

1580
01:38:40,270 --> 01:38:46,670
and so then the question is right how can we extend machine learning techniques to

1581
01:38:47,540 --> 01:38:52,540
with this collective classification problem in the way that we are better than just independently

1582
01:38:52,540 --> 01:38:54,300
predicting individual

1583
01:38:54,310 --> 01:38:56,660
response right

1584
01:38:57,720 --> 01:38:59,600
so here are some

1585
01:38:59,620 --> 01:39:05,580
motivating example to start this so you get an idea of what types of problems

1586
01:39:05,580 --> 01:39:10,210
you will be able to tackle with these methods so we're not going to talk

1587
01:39:10,210 --> 01:39:14,540
about how we the full application here that's what stand but this is more the

1588
01:39:14,540 --> 01:39:20,190
motivation of the types of things i'm i'm talking about so

1589
01:39:20,210 --> 01:39:23,810
if you do things like for instance part of speech tagging

1590
01:39:23,820 --> 01:39:27,630
right then what you want to do is you want to take a sentence like

1591
01:39:27,630 --> 01:39:31,860
this sentence up their profits soared at at boeing blah blah blah

1592
01:39:31,910 --> 01:39:34,090
so this should be input acts

1593
01:39:34,120 --> 01:39:38,390
and what you would like to do is to annotate every

1594
01:39:38,420 --> 01:39:41,020
word in that

1595
01:39:41,030 --> 01:39:42,290
sentence here

1596
01:39:42,300 --> 01:39:44,630
with a particular label

1597
01:39:44,640 --> 01:39:48,940
from a set of part of speech tags so and would be on the would

1598
01:39:48,940 --> 01:39:54,670
be over he would be proposition against possessive adjectives and so on and so forth

1599
01:39:54,860 --> 01:39:56,030
so you see

1600
01:39:57,420 --> 01:40:04,040
output is the red hard here right is the augmented import by these attacks

1601
01:40:04,050 --> 01:40:09,080
why is this useful it's often useful for instance as the first step in the

1602
01:40:09,080 --> 01:40:12,530
syntactic analysis of the sentence when you know maybe at some point you want to

1603
01:40:12,530 --> 01:40:16,950
pass sentence often part of speech tagging is the first thing to do

1604
01:40:16,960 --> 01:40:19,650
to get there OK so you can see

1605
01:40:19,660 --> 01:40:24,940
you know why why is it not simply a multiclass to binary classification problem because

1606
01:40:24,940 --> 01:40:30,650
these things will become forthright right so for instance with u u label

1607
01:40:30,660 --> 01:40:35,900
you know certain things here let's say as nouns or verbs might have an impact

1608
01:40:35,900 --> 01:40:40,640
on what neighboring labels should be right because maybe certain sequences of labels are more

1609
01:40:40,640 --> 01:40:45,830
likely certain you know annotations on the whole sentence level are more likely

1610
01:40:45,890 --> 01:40:51,290
than others right so so you would like to take that into account

1611
01:40:51,330 --> 01:40:53,880
right and how can you do that

1612
01:40:55,810 --> 01:41:03,690
the second problem is related but is a bit different so i'm mentioning here independently

1613
01:41:03,690 --> 01:41:08,210
is the problem known as information extraction where this is really only

1614
01:41:08,260 --> 01:41:12,570
like a broader title for for a whole set of different problems

1615
01:41:12,580 --> 01:41:17,860
so the idea here is that we're not so much interested in tax for individual

1616
01:41:17,860 --> 01:41:21,920
words about what they are part of speech rule is but would be interested in

1617
01:41:21,920 --> 01:41:22,950
is really

1618
01:41:22,960 --> 01:41:24,750
to mark up

1619
01:41:24,790 --> 01:41:30,580
the document with named entities that are mentioned in the text and also to classify

1620
01:41:30,580 --> 01:41:36,880
these mentionings according to a particular you know set of types of entities that you

1621
01:41:36,880 --> 01:41:42,310
might that you might want to define so for instance an organisation country a person

1622
01:41:43,320 --> 01:41:49,930
and various other you know entities that types that you might want to define timidly

1623
01:41:49,930 --> 01:41:52,890
what you would like to get it is if if i have a paragraph like

1624
01:41:52,890 --> 01:41:58,250
this right i want to know that the WTO friends and an organisation of the

1625
01:41:58,250 --> 01:41:59,760
united states our country

1626
01:42:00,400 --> 01:42:04,170
richard aboulafia is the person name

1627
01:42:04,190 --> 01:42:07,180
and so on and so forth right and what i want to do is really

1628
01:42:07,180 --> 01:42:10,930
i want to add let's say one way of encoding this right i want to

1629
01:42:10,930 --> 01:42:16,560
add tags that identify segments of consecutive tokens

1630
01:42:16,570 --> 01:42:19,330
and give them a label that this is the personal name of this is an

1631
01:42:19,330 --> 01:42:23,440
organisation in right like like senior

1632
01:42:24,560 --> 01:42:26,820
and again in doing that right

1633
01:42:26,840 --> 01:42:31,800
things will not be completely independent in particular if you if you look at neighbouring

1634
01:42:31,800 --> 01:42:37,950
things and you know the segmentation senses the segmentation problem if you like for sequence

1635
01:42:37,950 --> 01:42:39,020
of words

1636
01:42:39,060 --> 01:42:42,760
you need to look at the overall segmentation

1637
01:42:42,770 --> 01:42:43,900
as a whole

1638
01:42:43,920 --> 01:42:46,740
in order to to do this already

1639
01:42:46,760 --> 01:42:52,290
sort of you know to identify as segment of rivaling right goes beyond like a

1640
01:42:53,150 --> 01:42:55,300
the independent classification

1641
01:42:55,380 --> 01:43:01,240
OK so the challenges here to predict the segmentation

1642
01:43:01,260 --> 01:43:06,520
OK and then taking it a step further in terms of complexity of structures and

1643
01:43:06,520 --> 01:43:08,580
also the type of

1644
01:43:08,640 --> 01:43:14,090
the problems we might want to look at is here's an example from natural language

1645
01:43:14,090 --> 01:43:15,020
parsing where

1646
01:43:15,420 --> 01:43:19,590
one of the input is again the sentence what symbols here

1647
01:43:19,620 --> 01:43:26,090
and what you want to predict is apostrophe like this so let's say you might

1648
01:43:26,090 --> 01:43:32,110
be given a context free grammar of some sort right that tells you about you

1649
01:43:32,110 --> 01:43:36,760
know what the types of constituents are that you can you can find here so

1650
01:43:36,760 --> 01:43:41,140
any difference that there are things like noun phrase and verb phrases and you're given

1651
01:43:41,140 --> 01:43:42,610
a little bit about

1652
01:43:42,660 --> 01:43:44,070
you know how

1653
01:43:44,090 --> 01:43:51,460
the set of production rules basically and how these nonterminals can be translated into other

1654
01:43:51,460 --> 01:43:57,450
sequences of nonterminals and then ultimately into the sequence of terminals which will be or

1655
01:43:57,460 --> 01:44:01,440
sentence but basically what you want to do is you

1656
01:44:01,550 --> 01:44:03,760
parse the sentence and identify

1657
01:44:04,340 --> 01:44:10,280
correct and among the usually you know large number of possible parse trees identify the

1658
01:44:10,280 --> 01:44:15,570
most likely the most plausible one that gives the correct interpretation to this set of

1659
01:44:15,570 --> 01:44:20,190
english it's right so and the question here is of course traditionally

1660
01:44:20,650 --> 01:44:26,910
if you look at this rate in in the nineties people have started using probabilistic

1661
01:44:26,910 --> 01:44:28,390
hi little t

1662
01:44:30,170 --> 01:44:32,190
this time the star

1663
01:44:58,860 --> 01:45:02,070
right so so high

1664
01:45:02,080 --> 01:45:07,210
OK so this is the sort of these two policies are only three running around

1665
01:45:07,230 --> 01:45:09,110
policy one

1666
01:45:09,120 --> 01:45:13,130
is this high which is going to be learned policy

1667
01:45:14,210 --> 01:45:17,090
all capital t time steps

1668
01:45:17,090 --> 01:45:18,430
policy to

1669
01:45:18,450 --> 01:45:20,170
is the optimal policy

1670
01:45:20,210 --> 01:45:23,140
for all cattle t time steps

1671
01:45:23,180 --> 01:45:25,310
and then this definition

1672
01:45:25,310 --> 01:45:29,130
is kind of it's it's mixing to policies

1673
01:45:29,140 --> 01:45:30,340
this kind of

1674
01:45:30,390 --> 01:45:34,320
hybrid policy so we have a set of hybrid policies

1675
01:45:35,020 --> 01:45:37,190
we act according to

1676
01:45:37,240 --> 01:45:38,870
pi for a little while

1677
01:45:38,900 --> 01:45:43,680
and then we are going to pakistan for a little while afterwards

1678
01:45:44,320 --> 01:45:46,250
i guess the index t

1679
01:45:46,310 --> 01:45:52,580
defines how long they according to pi how long x four and five star

1680
01:45:56,640 --> 01:45:58,670
so it is defined by

1681
01:45:58,690 --> 01:46:01,600
x according to h one the first time step back engaged with the same time

1682
01:46:01,600 --> 01:46:04,410
step and so forth

1683
01:46:04,440 --> 01:46:10,020
OK so this is actually

1684
01:46:10,070 --> 01:46:13,190
a very simple proof

1685
01:46:14,970 --> 01:46:18,660
other questions about this this is the

1686
01:46:18,660 --> 01:46:21,780
if you saw because it's the classification problems well

1687
01:46:21,810 --> 01:46:24,220
the any of reinforcement learning

1688
01:46:24,280 --> 01:46:28,730
it doesn't tell you how to solve question because the classification problems

1689
01:46:29,390 --> 01:46:34,870
because getting extreme to do that is pretty tricky but says that

1690
01:46:34,920 --> 01:46:36,270
these exist

1691
01:46:36,710 --> 01:46:38,390
which is maybe reassuring

1692
01:46:38,400 --> 01:46:42,510
so the proof is essentially just telescoping arguement

1693
01:46:42,570 --> 01:46:45,330
so you start with this difference

1694
01:46:45,380 --> 01:46:47,560
you write out the meaning

1695
01:46:47,610 --> 01:46:50,190
of the value of the optimal policy

1696
01:46:50,220 --> 01:46:51,420
and the value

1697
01:46:51,420 --> 01:46:54,370
of some of the policy pi

1698
01:46:54,380 --> 01:46:59,430
and then let's see

1699
01:46:59,480 --> 01:47:01,220
and the claim is

1700
01:47:01,230 --> 01:47:04,410
you can break down the difference

1701
01:47:04,450 --> 01:47:06,590
in two

1702
01:47:06,910 --> 01:47:09,650
a difference

1703
01:47:09,660 --> 01:47:11,090
and a bunch of

1704
01:47:11,110 --> 01:47:13,860
intermediate steps

1705
01:47:13,910 --> 01:47:17,250
so we have this

1706
01:47:17,500 --> 01:47:28,640
think about moment

1707
01:47:28,730 --> 01:47:42,380
so let's say that pi star is the same as pi

1708
01:47:42,380 --> 01:47:45,610
he said that one particular time step

1709
01:47:45,620 --> 01:47:48,710
and that it behaves differently

1710
01:47:50,630 --> 01:47:57,080
then it it's in this particular time step is just keep right

1711
01:47:59,680 --> 01:48:02,010
the difference in these two values

1712
01:48:02,020 --> 01:48:04,080
the difference between

1713
01:48:04,090 --> 01:48:05,820
it by serenaded by

1714
01:48:05,830 --> 01:48:08,880
is going to be the difference

1715
01:48:08,920 --> 01:48:10,920
that is incurred

1716
01:48:13,290 --> 01:48:20,430
those at that particular time step t prime

1717
01:48:20,480 --> 01:48:22,930
i mean no we think about this

1718
01:48:25,900 --> 01:48:26,860
this is

1719
01:48:26,870 --> 01:48:28,410
a particular

1720
01:48:29,420 --> 01:48:31,120
there's particular quantity

1721
01:48:31,170 --> 01:48:32,090
and i can

1722
01:48:32,100 --> 01:48:34,210
insert in between

1723
01:48:34,230 --> 01:48:37,360
these two quantities you could add subtract

1724
01:48:37,360 --> 01:48:38,740
this quantity

1725
01:48:39,490 --> 01:48:43,690
you could do that for all the two primes between

1726
01:48:43,710 --> 01:48:46,730
so i'm not explaining this well

1727
01:48:46,780 --> 01:48:52,490
OK so

1728
01:48:52,590 --> 01:48:54,110
about the thing to do

1729
01:48:54,160 --> 01:48:57,590
if you have something like the form a minus b is to make it a

1730
01:48:57,590 --> 01:49:00,620
minor secrecy must be

1731
01:49:00,670 --> 01:49:03,830
right because you just abstract c

1732
01:49:04,530 --> 01:49:05,820
this will be

1733
01:49:07,600 --> 01:49:09,440
and i have the same

1734
01:49:09,460 --> 01:49:13,460
i also have a d which correspond to different t prime

1735
01:49:13,470 --> 01:49:15,720
in general for all the difference between

1736
01:49:15,730 --> 01:49:16,870
one in t

1737
01:49:16,880 --> 01:49:18,230
all have

1738
01:49:19,170 --> 01:49:24,570
term that i put into the sun

1739
01:49:24,590 --> 01:49:29,970
right and the difference between these terms just how often we are going to high

1740
01:49:30,030 --> 01:49:35,900
and then how are you according to pi star

1741
01:49:35,910 --> 01:49:37,710
and then we can rewrite this

1742
01:49:37,730 --> 01:49:43,060
two where i have terms of the form minus the

1743
01:49:43,060 --> 01:49:44,000
i guess

1744
01:49:44,000 --> 01:49:49,040
or predicting which people are going to get to

1745
01:49:49,070 --> 01:49:52,390
well this the the five years before they got

1746
01:49:52,430 --> 01:49:53,560
and so on

1747
01:49:53,580 --> 01:49:57,790
we see that one-to-one interactions don't exist

1748
01:49:57,810 --> 01:50:00,680
but the patterns are informative

1749
01:50:00,680 --> 01:50:01,760
and there are

1750
01:50:02,000 --> 01:50:09,190
patterns and sub patterns that marked the individual states and their common

1751
01:50:09,520 --> 01:50:12,350
state patterns that are shared

1752
01:50:12,380 --> 01:50:16,490
in in health and disease so there

1753
01:50:16,490 --> 01:50:20,500
there's something that cuts across

1754
01:50:20,540 --> 01:50:25,700
individuality in the immune system part of the were born with part of that we

1755
01:50:27,210 --> 01:50:34,720
if we happen to share a particular diseases or propensities

1756
01:50:34,740 --> 01:50:37,540
a systems approach

1757
01:50:40,560 --> 01:50:42,020
the body

1758
01:50:43,380 --> 01:50:48,080
we can look at we can mine information from the immune system of the immune

1759
01:50:48,080 --> 01:50:52,280
system is mind from the body and we can get some

1760
01:50:52,760 --> 01:50:57,010
hints about going explaining this for therapy

1761
01:50:57,050 --> 01:50:59,010
a mention two kinds of

1762
01:50:59,010 --> 01:51:02,540
please developed again in my laboratory

1763
01:51:02,630 --> 01:51:04,960
in fact

1764
01:51:04,980 --> 01:51:08,860
as of today there should be

1765
01:51:08,920 --> 01:51:15,130
the announcement of the results of the double blind placebo-controlled trial in the united states

1766
01:51:15,200 --> 01:51:17,890
for something called t cell vaccination

1767
01:51:17,920 --> 01:51:21,050
in multiple sclerosis is the idea here

1768
01:51:21,080 --> 01:51:24,570
is that instead of trying to suppress

1769
01:51:24,590 --> 01:51:30,930
the systems attack against the brain multiple sclerosis is an autoimmune disease where the immune

1770
01:51:30,930 --> 01:51:37,380
system is attacking the brain instead of giving me in individual

1771
01:51:37,590 --> 01:51:40,680
immunosuppressant cortisone things that

1772
01:51:40,680 --> 01:51:43,460
damage the immune system

1773
01:51:43,510 --> 01:51:47,830
in t cell vaccination we vaccinate the patient

1774
01:51:47,860 --> 01:51:51,110
against the disease-causing cells

1775
01:51:51,130 --> 01:51:55,020
we use the elements of the system to

1776
01:51:55,510 --> 01:52:01,240
regulator system so that the t cells that cause the autoimmune disease in this case

1777
01:52:01,270 --> 01:52:06,100
it's an equivalent amount of in rats these dead rats

1778
01:52:06,140 --> 01:52:07,770
have t cells that

1779
01:52:07,790 --> 01:52:14,600
attack there have used their brains we can isolate those cells the cells that cause

1780
01:52:14,600 --> 01:52:18,390
the disease the paralysis that the rats

1781
01:52:18,420 --> 01:52:20,520
and vaccinate

1782
01:52:20,550 --> 01:52:22,450
these these of course

1783
01:52:22,560 --> 01:52:28,070
and brother are identical twins so we can vaccinate against the disease by taking the

1784
01:52:29,500 --> 01:52:31,140
and stimulating

1785
01:52:33,080 --> 01:52:36,690
of of regulation

1786
01:52:36,890 --> 01:52:39,710
in in the world and make them

1787
01:52:39,730 --> 01:52:45,010
resistant to the disease and as i said there are now studies

1788
01:52:45,030 --> 01:52:50,830
showing that this also works in humans these publications up until now not been got

1789
01:52:50,840 --> 01:52:57,170
blinded placebo-controlled the placebo controlled studies are coming out

1790
01:52:57,180 --> 01:52:58,790
this week

1791
01:52:58,820 --> 01:53:00,540
another type of

1792
01:53:00,550 --> 01:53:09,220
the activation of this system with new information is something we've developed peptide therapy diabetes

1793
01:53:11,520 --> 01:53:14,760
the microarrays

1794
01:53:14,780 --> 01:53:15,790
we can

1795
01:53:15,990 --> 01:53:17,500
in mice

1796
01:53:21,130 --> 01:53:31,460
resistance to diabetes from animals that are susceptible to diabetes and identify a peptide

1797
01:53:31,470 --> 01:53:36,380
two weeks reactivity is beneficial the of the month

1798
01:53:36,410 --> 01:53:42,120
that of neural activity this but it will not come down with the this and

1799
01:53:42,120 --> 01:53:44,370
this peptide is now

1800
01:53:44,390 --> 01:53:46,970
in phase three trials

1801
01:53:46,980 --> 01:53:50,730
in human beings and i in phase two

1802
01:53:50,750 --> 01:53:52,370
it appears

1803
01:53:53,780 --> 01:53:56,450
individuals who have been

1804
01:53:56,470 --> 01:54:01,760
treated with this peptide that the system itself is looking for

1805
01:54:01,780 --> 01:54:07,990
can maintain their a data cells to maintain the cells that produce

1806
01:54:08,010 --> 01:54:14,470
insulin and the individuals given the placebo treatment lose their activity

1807
01:54:18,040 --> 01:54:19,390
i think that

1808
01:54:19,410 --> 01:54:21,640
it it

1809
01:54:21,660 --> 01:54:24,430
it is one of the two


1
00:00:00,000 --> 00:00:04,330
were sent today a the hundreds if not thousands of email messages right waiting for

2
00:00:04,350 --> 00:00:11,100
us since we've seen that it's k so it would be great to also address

3
00:00:11,100 --> 00:00:18,450
that and my thought about what to do that is to build substantially more sophisticated

4
00:00:18,450 --> 00:00:20,910
systems than the ones we use today

5
00:00:20,930 --> 00:00:24,000
so today we have the web

6
00:00:24,010 --> 00:00:29,310
or other sources of text and we systems like google that i think of as

7
00:00:29,310 --> 00:00:34,260
information or before state graze over the web and then they regurgitate what they find

8
00:00:34,320 --> 00:00:36,360
in an indexable form

9
00:00:36,370 --> 00:00:41,240
and my suggestion is that we move up the information food chain and build information

10
00:00:41,240 --> 00:00:47,830
carnivores if you will more sophisticated engine so this is are not all icon so

11
00:00:47,880 --> 00:00:53,440
some kind of node we can ask questions about how is the ipad two in

12
00:00:53,440 --> 00:00:58,660
and get answers like well i found twenty eight thousand reviews eighty seven percent of

13
00:00:58,660 --> 00:01:02,950
which are positive the key features that people talk about our this that and the

14
00:01:02,950 --> 00:01:06,310
other thing is an electronics them and that's what

15
00:01:06,330 --> 00:01:12,180
decide outcome does in part but the show them and the second in the in

16
00:01:12,180 --> 00:01:16,620
the restaurant domain but but you see the idea right if we're able to operate

17
00:01:16,630 --> 00:01:22,210
at this high level then the interaction is much more satisfying of course to be

18
00:01:22,210 --> 00:01:23,160
able to

19
00:01:23,170 --> 00:01:29,520
analyse the text and summarize it this level we need much more sophisticated

20
00:01:30,700 --> 00:01:35,890
so let me show you this rather minor project which is something we've put together

21
00:01:35,890 --> 00:01:39,190
recently and by the way all the demos and going to show you today are

22
00:01:39,190 --> 00:01:42,250
available on the web so

23
00:01:42,250 --> 00:01:45,950
don't rush to try them as i'm doing it will probably slow them down these

24
00:01:45,950 --> 00:01:51,370
are research prototypes but feel free to try them after resistance etc that are of

25
00:01:51,370 --> 00:01:57,320
minor dot com and what it does is it extracts key attributes and opinions anything

26
00:01:57,320 --> 00:02:04,370
this review by what yelled in seattle so barber shops hotels restaurants and is based

27
00:02:04,370 --> 00:02:10,250
on the system which was done by maria myself way back when but now we're

28
00:02:11,500 --> 00:02:15,830
at a much larger scale and what really emphasise what i want to show you

29
00:02:15,830 --> 00:02:20,060
here is how an interface based on extraction

30
00:02:20,060 --> 00:02:25,440
can summarise information for you much more succinctly and easily then if you're having to

31
00:02:25,440 --> 00:02:30,110
do search and this is the point that was made extremely well by a tiny

32
00:02:30,110 --> 00:02:34,960
at all in the best paper attractors that they want to best paper award for

33
00:02:34,960 --> 00:02:39,560
an extractive interfaces just in this year's HCI

34
00:02:39,570 --> 00:02:41,580
so let's see what this looks like

35
00:02:41,620 --> 00:02:46,110
pacific in

36
00:02:46,120 --> 00:02:47,800
to my them so

37
00:02:47,810 --> 00:02:49,670
here's a reminder

38
00:02:49,680 --> 00:02:52,360
and i tell you that i'm looking for

39
00:02:52,370 --> 00:02:54,120
good sushi in seattle

40
00:02:56,460 --> 00:02:59,120
i will ignore the optimal resolution notification

41
00:03:00,140 --> 00:03:06,950
he gives me a bunch of restaurants where there's good sushi but interpreted the

42
00:03:06,960 --> 00:03:12,290
query for good sushi that literally basically it says i have a set of opinion

43
00:03:12,290 --> 00:03:19,060
words that have extracted from the reviews and i've rank them right from the darkest

44
00:03:19,070 --> 00:03:26,210
green is the most positive to read dhaka's roads is the most negative black is

45
00:03:26,210 --> 00:03:28,960
somewhere in the middle and

46
00:03:28,980 --> 00:03:32,850
i'm going to interpret good so she is good suger better so so

47
00:03:32,880 --> 00:03:39,320
excellent so she is going to be included as well and you see that it's

48
00:03:39,510 --> 00:03:44,190
providing us with something that according to the old reviews is probably the best sushi

49
00:03:44,190 --> 00:03:45,110
in seattle

50
00:03:45,800 --> 00:03:51,300
and it's also extracted a wide variety of other

51
00:03:51,770 --> 00:03:58,390
attributes and what people said about about those summarizes the reviews and we should probably

52
00:03:58,390 --> 00:04:02,860
cut down the number of adjectives but you can add this article going get a

53
00:04:02,860 --> 00:04:06,810
sense of how is the service in this place and if you say

54
00:04:07,140 --> 00:04:12,180
you know really interested in what people say about service one only go places where

55
00:04:12,200 --> 00:04:17,180
the service is i don't know amazing that might click on that and i'll see

56
00:04:17,180 --> 00:04:22,850
places where the service amazing and then i could go amigo two

57
00:04:23,080 --> 00:04:24,890
taste of india

58
00:04:24,910 --> 00:04:30,030
and see what people say say about that so you get a sense here right

59
00:04:30,030 --> 00:04:30,960
about how

60
00:04:31,240 --> 00:04:36,820
we're operating that at the level of reading reviews after reviews but at the level

61
00:04:36,820 --> 00:04:41,080
of this concise summary

62
00:04:41,100 --> 00:04:43,950
now again the the interface i showed you

63
00:04:45,530 --> 00:04:49,560
it is not

64
00:04:49,580 --> 00:04:56,730
optimized for mobile devices but again you can imagine how on a mobile device like

65
00:04:56,730 --> 00:05:01,040
this one right reader reviews and i think we've all had that experience become very

66
00:05:01,040 --> 00:05:05,900
tedious you could imagine looking in this and quickly at a glance seeing what people

67
00:05:06,730 --> 00:05:13,630
about about this issue about the service et cetera because we're extracting these with negative

68
00:05:16,680 --> 00:05:19,040
what have i done so far in the talk

69
00:05:19,050 --> 00:05:25,290
i hopefully motivated for two reasons information extraction right one is to solve the knowledge

70
00:05:25,290 --> 00:05:31,140
acquisition bottleneck and the other one is as a basis for new paradigm of search

71
00:05:31,140 --> 00:05:35,740
and interaction based on extractions what i'm going to do now is tell you more

72
00:05:35,740 --> 00:05:41,580
about machine reading and specifically focus on how we do information extraction so i'm going

73
00:05:41,580 --> 00:05:46,490
to get into some more detail here definitely not the level of detail for an

74
00:05:46,530 --> 00:05:51,950
NLP person but all refer to the papers for that so machine reading is really

75
00:05:51,950 --> 00:05:52,840
going to be

76
00:05:52,860 --> 00:05:58,780
information extraction or i e and inference give quick overview of that with the focus

77
00:05:58,780 --> 00:06:00,600
on the question of how do we scale

78
00:06:00,660 --> 00:06:02,920
i e to operate over the web

79
00:06:02,990 --> 00:06:07,910
all talk specifically about our approach which is called open a and i'll give you

80
00:06:08,300 --> 00:06:09,720
the second m

81
00:06:09,730 --> 00:06:13,420
and then the next part of the talk is all show you how much

82
00:06:13,510 --> 00:06:19,030
we're able to compute inferences over the extractions from from from the web

83
00:06:19,050 --> 00:06:24,010
and all all end up with some speculative remarks

84
00:06:24,020 --> 00:06:28,560
OK so so what is a basically think of it as a function that maps

85
00:06:28,560 --> 00:06:34,780
a sentence to relation instance and the probabilities of the sentences anderson was the inventor

86
00:06:34,780 --> 00:06:37,770
of the light bulb then

87
00:06:37,790 --> 00:06:41,740
i might come up with the relation invented events in the life ball with the

88
00:06:41,740 --> 00:06:47,380
probability of point nine that's that's what we're trying to do here and how do

89
00:06:47,380 --> 00:06:50,680
we do that well we go back to the fifties with the

90
00:06:50,700 --> 00:06:55,760
harris's distributional hypothesis first put it really really said you shall know word by the

91
00:06:55,760 --> 00:07:02,600
identifying candidates systems that will have this type of phase diagram and then they're very

92
00:07:02,600 --> 00:07:06,360
simple anybody three online one would come up with these rules

93
00:07:06,390 --> 00:07:07,120
if you

94
00:07:07,130 --> 00:07:10,700
i thought about it before you write everybody beat you to it so you can

95
00:07:10,700 --> 00:07:14,770
get the glory anymore but let's think about what would have to be the situation

96
00:07:14,770 --> 00:07:18,400
if the two metals a and b are going to mix in all proportions

97
00:07:18,430 --> 00:07:20,510
then they must be very similar so

98
00:07:20,560 --> 00:07:23,990
they must have similar crystal structures

99
00:07:24,020 --> 00:07:26,560
crystal structures that way

100
00:07:26,630 --> 00:07:30,240
you get a simple substitutional solid solutions

101
00:07:30,360 --> 00:07:36,020
and furthermore if they're going to substitute solid for solid they should have similar atomic

102
00:07:36,020 --> 00:07:41,450
dimensions right there no good to have two fcc metals mixing where one has

103
00:07:41,470 --> 00:07:46,540
a atomic radius that is so large that it has the force fed into the

104
00:07:46,920 --> 00:07:49,630
lattice of the other similar atomic

105
00:07:52,910 --> 00:07:54,930
similar atomic volumes

106
00:07:54,980 --> 00:08:00,350
and lastly bring in some chemistry we want them to mix and not chemically react

107
00:08:00,380 --> 00:08:03,920
so they should have a small

108
00:08:05,100 --> 00:08:10,530
in electronegativity difference if they're both the same size both crystal structure but they have

109
00:08:10,530 --> 00:08:13,500
a high electronegativity difference they're going to

110
00:08:13,550 --> 00:08:18,100
engaged in electron transfer so that's no good but i i think this set him

111
00:08:18,100 --> 00:08:22,310
robbery rules is nice to reflect upon the light everything else we've learned three o

112
00:08:22,310 --> 00:08:27,420
nine one because the phase diagrams have as i said earlier they have embedded in

113
00:08:27,420 --> 00:08:31,750
them a lot of basic chemistry which goes back to the electronic structure of the

114
00:08:31,750 --> 00:08:35,640
constituents so let's draw a schematic

115
00:08:37,100 --> 00:08:40,260
and the diagram for

116
00:08:40,310 --> 00:08:45,400
one such system called type one so plotting a versus b

117
00:08:45,480 --> 00:08:51,810
this is temperature on the vertical axis horizontal axis compositions on the left side have

118
00:08:51,810 --> 00:08:54,930
here a right side have here b

119
00:08:54,960 --> 00:08:57,560
and looking at solid liquid equilibrium so

120
00:08:57,580 --> 00:08:59,530
at this extreme pur

121
00:08:59,550 --> 00:09:03,410
this and member must be the melting point of pure a

122
00:09:03,420 --> 00:09:05,730
and the other extreme is pure b

123
00:09:05,740 --> 00:09:09,650
so this the melting point of pure b and i've drawn just arbitrarily well melting

124
00:09:09,650 --> 00:09:10,800
point of b

125
00:09:10,810 --> 00:09:13,510
happens to be higher than the melting point of a book

126
00:09:13,530 --> 00:09:16,460
it doesn't matter one has to be larger than the other

127
00:09:16,500 --> 00:09:20,490
and so now this is what the phase and going to answer the question how

128
00:09:20,490 --> 00:09:24,180
does melting point vary as a function of composition

129
00:09:24,240 --> 00:09:28,360
various like this it's not a straight line for two reasons

130
00:09:28,430 --> 00:09:33,720
the first one being that if when you take thermodynamics subsequently if you choose to

131
00:09:33,720 --> 00:09:35,790
do so you'll understand

132
00:09:36,900 --> 00:09:41,200
physical chemistry behind i want to tell you let me just stated without proof that

133
00:09:41,240 --> 00:09:43,600
if c is greater than one

134
00:09:43,640 --> 00:09:46,600
in other words if you're not in the pure material

135
00:09:46,620 --> 00:09:51,310
if you're in a multicomponent system if c is greater than one it's impossible to

136
00:09:51,310 --> 00:09:52,630
go from

137
00:09:52,710 --> 00:09:54,360
phase one

138
00:09:54,400 --> 00:09:57,370
to phase two

139
00:09:57,410 --> 00:10:01,330
cannot go from phase one to phase two

140
00:10:02,500 --> 00:10:04,290
a two phase

141
00:10:04,430 --> 00:10:07,640
region in between

142
00:10:07,700 --> 00:10:12,330
so we can go from all liquid to all solid memory said these mix in

143
00:10:12,330 --> 00:10:17,530
all proportions down here so solid you can mix any mix any ratio of a

144
00:10:17,530 --> 00:10:19,990
and b as solid any max

145
00:10:20,000 --> 00:10:22,350
of a and b is liquids but

146
00:10:22,400 --> 00:10:27,480
because we must go through two phases regime this opens up

147
00:10:27,510 --> 00:10:32,020
to give a two phase regime so up here this is all liquid down here

148
00:10:32,020 --> 00:10:37,130
this is all solid and in between these two phase regime of liquid and solid

149
00:10:37,130 --> 00:10:38,710
we can call it slush

150
00:10:38,720 --> 00:10:42,870
slash we've seen slash before we've seen ice

151
00:10:42,880 --> 00:10:45,020
slash in water

152
00:10:45,740 --> 00:10:51,860
two phase equilibrium for pyramids here this is now liquid plus solid and a multicomponent

153
00:10:53,810 --> 00:10:56,780
up here we have single phase

154
00:10:56,840 --> 00:11:00,840
liquid because the mixing in all proportions so this is the solution

155
00:11:00,890 --> 00:11:03,880
down here these are solid solutions

156
00:11:03,930 --> 00:11:06,580
and here we have

157
00:11:06,580 --> 00:11:10,920
there has to be a period because the formula is not symmetric

158
00:11:10,950 --> 00:11:14,900
the formula does not treat F and G equally

159
00:11:15,650 --> 00:11:18,630
and therefore this is not obvious

160
00:11:18,650 --> 00:11:22,100
that's not that's at least not obvious if you look at it that way

161
00:11:22,130 --> 00:11:25,960
but it is obvious if you look at it that way y

162
00:11:26,040 --> 00:11:31,910
In other words F star Energy

163
00:11:32,600 --> 00:11:39,630
is the guy whose will plus transform is f of x times here well what

164
00:11:39,630 --> 00:11:41,790
would start

165
00:11:41,810 --> 00:11:46,740
that would be the guys plus transform is g times that that have left times

166
00:11:46,740 --> 00:11:49,530
capital G is the same as capital g and capital

167
00:11:50,410 --> 00:11:57,690
so it's because all plus transform mutative ordinary multiplication is computed it follows that this

168
00:11:57,690 --> 00:12:03,350
has to be computed community to so I'll write that down since at times g

169
00:12:03,380 --> 00:12:09,130
incompetent G and and you have to understand that here I mean weasel plus transform

170
00:12:09,170 --> 00:12:10,310
of those guys

171
00:12:11,990 --> 00:12:15,370
but it's not obvious from the formula

172
00:12:15,380 --> 00:12:21,950
OK let's calculate all plus transform of sorry the convolution the let's do it by

173
00:12:21,950 --> 00:12:23,550
the formula

174
00:12:23,580 --> 00:12:30,690
by the formula I calculate integral 0 T I take the first function by changes

175
00:12:30,690 --> 00:12:34,710
variable to the dummy variable you so that you square

176
00:12:34,880 --> 00:12:39,930
take a 2nd function and replace its variable by you

177
00:12:39,950 --> 00:12:44,080
minus T so this is time

178
00:12:45,050 --> 00:12:49,720
the minus you start OK

179
00:12:50,450 --> 00:12:55,330
you see that this calculated this is where I have to write down that's what

180
00:12:55,330 --> 00:12:57,890
the formula becomes

181
00:12:58,960 --> 00:13:01,620
a request is anything wrong

182
00:13:05,330 --> 00:13:09,030
0 sorry that the integrations respect your point of view

183
00:13:16,760 --> 00:13:19,640
because there was a lot so it is

184
00:13:19,690 --> 00:13:26,690
use integral you squared members integrated perspective you so it's you Q over 3

185
00:13:28,170 --> 00:13:34,340
the rest of it is the integral of you Q which is uniform over for

186
00:13:34,340 --> 00:13:38,430
all this has to be evaluated between 0 and seek at the upper limit so

187
00:13:38,430 --> 00:13:43,450
I put you equal T I get even for over 3

188
00:13:43,480 --> 00:13:46,810
my to you before over 4

189
00:13:46,840 --> 00:13:50,730
Of course at the lower limit you is 0 so both of these are terms

190
00:13:50,840 --> 00:13:55,310
0 there's nothing there and the answer is therefore to you look for avoided or

191
00:13:56,070 --> 00:13:58,790
a 3rd my supporters 12

192
00:14:02,120 --> 00:14:05,820
so let's doing it from the formula but of course there's an easier way to

193
00:14:05,830 --> 00:14:10,960
do it and we can cheat and will plus transform instead of if I will

194
00:14:10,960 --> 00:14:16,840
plus transform it will plus transform t squared is what is

195
00:14:17,450 --> 00:14:22,770
2 factorial divided by sq

196
00:14:22,790 --> 00:14:25,450
will plus transform of 2 years

197
00:14:25,470 --> 00:14:28,080
1 divided by squared

198
00:14:28,870 --> 00:14:33,710
and so because this is the convolution of these should correspond to the product will

199
00:14:33,710 --> 00:14:40,130
plus transform which is to over estimate power

200
00:14:43,390 --> 00:14:49,030
not the same as this what will plus transform in other words what's the universal

201
00:14:49,030 --> 00:14:55,970
plus transform of to overestimate fish

202
00:14:56,850 --> 00:15:05,470
well the universal plus transform of 4 factorial over X the 5th is how much

203
00:15:05,480 --> 00:15:07,360
the 4th right

204
00:15:09,690 --> 00:15:13,760
now how does this differ well to turn that into that I should divide by

205
00:15:13,760 --> 00:15:19,170
4 times 3 so there should be 1 12

206
00:15:19,190 --> 00:15:23,240
moral 4 times 3 because this is 24 that's too

207
00:15:23,310 --> 00:15:26,760
so divided by 12 inches what constant

208
00:15:27,050 --> 00:15:29,210
so works at least in that case

209
00:15:29,210 --> 00:15:32,200
in one classifier is a linear classifier

210
00:15:32,790 --> 00:15:35,560
i have bounds for both of them

211
00:15:35,570 --> 00:15:40,100
if i take the best of of them then what they lose in my balance

212
00:15:40,120 --> 00:15:42,250
is a factor flock to

213
00:15:42,300 --> 00:15:45,180
so it's not much you know it

214
00:15:45,920 --> 00:15:48,910
and it also tells you how to trade

215
00:15:48,920 --> 00:15:52,970
sample size was size of the cluster for so if you lose this factor flocked

216
00:15:52,970 --> 00:15:54,870
to it means to get the same

217
00:15:54,880 --> 00:15:56,490
performance if you want

218
00:15:56,500 --> 00:15:57,720
you need to have

219
00:15:57,730 --> 00:15:59,780
an increase of the sample size

220
00:15:59,830 --> 00:16:02,050
that is equivalent to this factor

221
00:16:06,020 --> 00:16:10,390
it tells you how to trade sample size with complexity or at least complexity as

222
00:16:10,390 --> 00:16:13,430
measured by the club cardinality of the classes

223
00:16:15,890 --> 00:16:18,490
it happens that we can improve

224
00:16:18,540 --> 00:16:22,730
quite significantly these results so the first thing was

225
00:16:22,740 --> 00:16:24,540
as we said before

226
00:16:25,310 --> 00:16:29,430
these have things inequality may be losing certain cases

227
00:16:29,610 --> 00:16:35,050
in particular we used only the fact that the valuable is bounded but we do

228
00:16:35,060 --> 00:16:36,740
not use

229
00:16:36,750 --> 00:16:41,380
all the properties of the random bible for example the variance

230
00:16:41,490 --> 00:16:46,060
but with this we can already improved a little bit is this inequality

231
00:16:46,120 --> 00:16:50,100
said second most important point is that when we do this union bounds we do

232
00:16:50,100 --> 00:16:54,420
not care about what the functions where we just knew that we had

233
00:16:54,430 --> 00:16:59,100
capital and functions no matter what they are we said we just the problem by

234
00:16:59,100 --> 00:16:59,920
the sun

235
00:16:59,980 --> 00:17:04,920
overall probabilities and we got this factor log and

236
00:17:06,240 --> 00:17:08,270
and another

237
00:17:08,320 --> 00:17:11,930
direction into which you can improve this these kind of result is

238
00:17:13,120 --> 00:17:15,800
when you look at this quantity it's a bit crude two

239
00:17:15,810 --> 00:17:17,470
upper bound

240
00:17:17,480 --> 00:17:21,000
remember the supremum or coming from a poor bounding

241
00:17:21,020 --> 00:17:24,010
these differences which were the difference of pain for

242
00:17:24,030 --> 00:17:29,740
the the function returned by our algorithm and we replace that by the worst

243
00:17:29,790 --> 00:17:32,280
the difference in the class but maybe

244
00:17:32,320 --> 00:17:36,520
this does not always have things the worst difference

245
00:17:37,290 --> 00:17:41,390
by using this fact we can get all sorts of refined bounds

246
00:17:41,410 --> 00:17:44,060
but the main objective will be

247
00:17:44,110 --> 00:17:45,980
to refine the union bound

248
00:17:52,260 --> 00:17:57,370
it happens that for refining the union bound we first have to introduce

249
00:17:57,380 --> 00:18:03,450
the other refinement i was mentioning the refinement on the deviations

250
00:18:03,500 --> 00:18:04,880
so let's come back to

251
00:18:04,900 --> 00:18:09,680
what are random variables look like

252
00:18:11,160 --> 00:18:13,280
empirical average of

253
00:18:13,290 --> 00:18:15,130
the loss

254
00:18:15,150 --> 00:18:16,890
is what is called the binomial

255
00:18:17,160 --> 00:18:19,110
random variables

256
00:18:19,120 --> 00:18:21,240
and what does it mean it means that

257
00:18:22,700 --> 00:18:27,380
a sense of random bible that can add value zero one

258
00:18:27,400 --> 00:18:32,720
and there are n of them and they have value one with probability small p

259
00:18:32,760 --> 00:18:34,650
which is exactly

260
00:18:34,660 --> 00:18:37,360
the probability of their probability that we have

261
00:18:37,410 --> 00:18:39,710
that we make an error

262
00:18:41,360 --> 00:18:45,870
we know completely the distribution at least in the special case where we have binary

263
00:18:45,870 --> 00:18:49,770
classification we know completely the distribution of

264
00:18:49,780 --> 00:18:51,780
this one i

265
00:18:51,790 --> 00:18:55,910
and we can actually compute exactly the kind of inequality here

266
00:18:55,920 --> 00:18:57,120
the deviations

267
00:18:57,180 --> 00:18:59,230
of our

268
00:18:59,240 --> 00:19:03,660
random bible of interest again for a fixed function

269
00:19:03,740 --> 00:19:07,850
and it's equal to this quantity here

270
00:19:07,860 --> 00:19:11,050
it's essentially tells you that

271
00:19:11,060 --> 00:19:13,350
you have this you have these n

272
00:19:15,060 --> 00:19:17,220
you have zero one for each example you

273
00:19:17,270 --> 00:19:20,520
zero with probability one minus p and one with probability

274
00:19:24,580 --> 00:19:26,360
if you have k ones

275
00:19:26,370 --> 00:19:30,840
this happens with probability p to the k one minus p to n minus

276
00:19:30,890 --> 00:19:32,140
and there are

277
00:19:32,150 --> 00:19:33,150
n choose k

278
00:19:34,160 --> 00:19:36,040
two up k ones among

279
00:19:36,050 --> 00:19:38,090
an example

280
00:19:38,100 --> 00:19:42,350
and you do the sum for all values

281
00:19:42,400 --> 00:19:43,740
such that

282
00:19:43,790 --> 00:19:49,200
the sum of the once divided by n is less sorry is larger than g

283
00:19:49,250 --> 00:19:52,120
which is why we have this system

284
00:19:57,030 --> 00:19:59,930
and this is not always very convenient to work with

285
00:19:59,950 --> 00:20:01,920
so there are a bunch of

286
00:20:03,560 --> 00:20:08,110
approximations or actually there are upper bounds on this quantity

287
00:20:08,210 --> 00:20:10,100
that's simplified

288
00:20:10,120 --> 00:20:13,150
the simplest one is of things inequality

289
00:20:13,170 --> 00:20:16,950
and the important thing here is that it does not depend on

290
00:20:17,010 --> 00:20:18,410
the value of p

291
00:20:18,420 --> 00:20:23,090
so it's independent on the distribution which is nice in certain cases but which can

292
00:20:23,090 --> 00:20:26,810
be a bit clues in order to cases when we have information

293
00:20:26,910 --> 00:20:28,770
now if we

294
00:20:28,820 --> 00:20:30,920
go back this way

295
00:20:32,240 --> 00:20:36,350
bernstein inequality is already taking into account that the variance

296
00:20:36,420 --> 00:20:38,090
because actually

297
00:20:38,130 --> 00:20:42,670
p is a small pe is the expectation of the random variable and small p

298
00:20:42,670 --> 00:20:44,590
times one minus p

299
00:20:44,660 --> 00:20:46,310
is the variance

300
00:20:46,360 --> 00:20:49,210
of the random variable of interest

301
00:20:50,910 --> 00:20:56,650
actually in this special case again with binary random variables it doesn't matter really when

302
00:20:56,650 --> 00:21:01,410
you whether you talk about expectation or variance because they are more less related directly

303
00:21:01,460 --> 00:21:07,890
OK and then they are more refined bounds but which are a bit less easy

304
00:21:07,890 --> 00:21:09,970
to work with

305
00:21:09,980 --> 00:21:13,180
so we concentrate on on this or this

306
00:21:19,260 --> 00:21:20,230
if we look at

307
00:21:20,250 --> 00:21:23,480
bernstein's inequality for example

308
00:21:23,530 --> 00:21:25,120
we see that

309
00:21:25,140 --> 00:21:27,160
force small maltese

310
00:21:27,200 --> 00:21:29,560
this will be small here

311
00:21:29,570 --> 00:21:32,800
so we will have a term which is more or less

312
00:21:32,850 --> 00:21:34,960
of the same type as having

313
00:21:35,010 --> 00:21:37,470
which is e to the minus the square

314
00:21:37,470 --> 00:21:38,530
which is

315
00:21:38,550 --> 00:21:40,180
typical of

316
00:21:40,260 --> 00:21:43,080
states of gulshan random variables

317
00:21:47,050 --> 00:21:49,000
it to

318
00:21:49,150 --> 00:21:52,610
mean small b from the right yes yes

319
00:21:52,610 --> 00:21:55,720
you can but it it seems that

320
00:21:55,740 --> 00:21:58,930
p you need to be to know people to live in a way it is

321
00:21:58,930 --> 00:22:00,640
but we see that there is a trick

322
00:22:00,700 --> 00:22:02,550
to actually use this

323
00:22:02,560 --> 00:22:04,700
for estimating p

324
00:22:07,410 --> 00:22:10,310
so OK so forced multi

325
00:22:10,320 --> 00:22:12,600
these behaves like a gulshan tail

326
00:22:12,610 --> 00:22:13,790
like the

327
00:22:13,810 --> 00:22:15,410
four large t

328
00:22:15,470 --> 00:22:19,120
this term becomes dominant and we have e to the minus

329
00:22:19,130 --> 00:22:20,620
constant times t

330
00:22:20,630 --> 00:22:21,610
which means

331
00:22:21,610 --> 00:22:26,320
exponential data like west all random variables

332
00:22:27,630 --> 00:22:30,000
i mean if everything were gulshan it would be

333
00:22:30,140 --> 00:22:34,690
be simpler but it's not the case for change

334
00:22:34,710 --> 00:22:38,390
so that's what is said here

335
00:22:38,410 --> 00:22:40,320
gulshan behaviour

336
00:22:40,360 --> 00:22:41,440
where the

337
00:22:41,460 --> 00:22:44,340
variants of the gaussians more is the violence

338
00:22:44,380 --> 00:22:47,750
of the random bible

339
00:22:47,760 --> 00:22:50,500
i mean the tail of for the gaussians is exactly

340
00:22:50,510 --> 00:22:55,790
e to the minus the square divided by twice the violence that standard of on

341
00:22:58,280 --> 00:23:02,680
gulshan right so this is exactly the same as if we had the gumption

342
00:23:02,700 --> 00:23:05,240
variable with variance p one million

343
00:23:05,240 --> 00:23:08,510
but in addition to that we have also these

344
00:23:08,520 --> 00:23:11,690
heavy tail behaviour

345
00:23:13,940 --> 00:23:15,780
and the maximum

346
00:23:15,820 --> 00:23:18,600
the worst case if you want

347
00:23:18,660 --> 00:23:20,100
for this quantity

348
00:23:20,100 --> 00:23:22,730
will you know mostly already know how to do

349
00:23:22,740 --> 00:23:25,930
so is that there i do have some slides

350
00:23:26,100 --> 00:23:29,780
you know again that for those who want to see

351
00:23:29,800 --> 00:23:30,900
he later

352
00:23:30,970 --> 00:23:34,650
and the b in the upper don't slide to be on the conference so thank

353
00:23:34,650 --> 00:23:35,760
you very much

354
00:23:46,900 --> 00:23:52,940
so i think that after eleven years of semantic web industry

355
00:23:52,980 --> 00:23:59,100
industrial and service activities self-assessment is very well known from the far

356
00:23:59,100 --> 00:24:06,810
funding agencies but also has the responsibility interface for young researchers active in these domains

357
00:24:07,060 --> 00:24:08,720
and in that respect

358
00:24:09,970 --> 00:24:11,030
let's say

359
00:24:11,050 --> 00:24:13,770
levis that's the picture

360
00:24:13,820 --> 00:24:15,060
the layers

361
00:24:15,110 --> 00:24:19,890
OK you just presented also they correspond to the vision of the semantic web

362
00:24:20,090 --> 00:24:21,850
of the first

363
00:24:21,870 --> 00:24:26,090
so i think that this is more or less the question of what our vision

364
00:24:26,090 --> 00:24:27,470
tenacity picture

365
00:24:27,480 --> 00:24:32,340
that you discuss under the new light and i can

366
00:24:32,350 --> 00:24:33,900
after a

367
00:24:34,070 --> 00:24:35,810
three months

368
00:24:36,440 --> 00:24:40,980
how is to my mind

369
00:24:40,980 --> 00:24:45,300
i think that for the semantic web is the with that so the semantic and

370
00:24:45,300 --> 00:24:46,940
not the other way around

371
00:24:46,990 --> 00:24:49,730
OK as you pointed out

372
00:24:49,770 --> 00:24:51,720
the semantic web essentially

373
00:24:51,730 --> 00:24:56,150
became an issue on the web when he we forget all the stuff

374
00:24:57,600 --> 00:25:01,190
this is the success of the linked data

375
00:25:01,230 --> 00:25:09,100
and this is it's a profound changes on the way we perceive the whole world

376
00:25:09,180 --> 00:25:13,800
in addition to the standard

377
00:25:13,810 --> 00:25:14,940
that's been

378
00:25:14,940 --> 00:25:20,660
let's say design by researchers by a space space station

379
00:25:20,840 --> 00:25:25,690
well the formal semantics it is the case with essentially

380
00:25:25,760 --> 00:25:27,260
this so my

381
00:25:27,360 --> 00:25:34,270
in the semantic web and semantic web stack

382
00:25:34,340 --> 00:25:39,310
the results of the semantics which is the key is to start with

383
00:25:39,310 --> 00:25:44,890
of the four real use

384
00:25:44,890 --> 00:25:46,970
and even

385
00:25:47,030 --> 00:25:53,390
i would say that when i started editing here the university of

386
00:25:53,400 --> 00:25:57,020
by this entity relationship model

387
00:25:57,030 --> 00:26:00,200
at that time it was one

388
00:26:00,240 --> 00:26:05,430
still incapable of course but also have parts of some value

389
00:26:05,440 --> 00:26:08,950
that's what happens today with students

390
00:26:08,970 --> 00:26:10,320
it's in semantic web

391
00:26:10,980 --> 00:26:15,190
so this is because other people have be allowed

392
00:26:15,200 --> 00:26:20,690
the question is the vision of a particularly good well i mean it was sort

393
00:26:20,810 --> 00:26:24,440
do we have the right stuff in the standard which i'm going still say yes

394
00:26:24,440 --> 00:26:27,350
to some degree but it would take a long time so what i am saying

395
00:26:27,350 --> 00:26:31,640
yes and i have also criticized other aspects of that but the key thing i

396
00:26:31,640 --> 00:26:38,090
want to say is that anything that starts with we have to teach people to

397
00:26:38,130 --> 00:26:40,310
right fail on the web

398
00:26:40,360 --> 00:26:42,930
so you yourself said it was accepting the web

399
00:26:42,940 --> 00:26:46,850
but the web work with entity relationship models better than it will work with anything

400
00:26:47,810 --> 00:26:52,720
right into we fought until until the end users have that

401
00:26:52,730 --> 00:26:56,560
but we as an academic community which is what this talk was directed at remember

402
00:26:56,560 --> 00:26:57,270
it was

403
00:26:57,280 --> 00:27:02,100
i said lots of good things about the semantic web making money for people and

404
00:27:02,100 --> 00:27:06,440
being useful on the web and succeeding the we is an academic community

405
00:27:06,900 --> 00:27:09,600
i have lost some of the core

406
00:27:09,600 --> 00:27:14,260
and i think it's the finding the core to have the web stuff and have

407
00:27:14,270 --> 00:27:19,870
representation that and i'm very open to other things you are being part

408
00:27:19,970 --> 00:27:25,070
but the question becomes not we pretty much know there is no existing model that

409
00:27:25,110 --> 00:27:26,390
has solved this

410
00:27:26,490 --> 00:27:30,570
we have these communities start exploring these models again saying what we're really trying to

411
00:27:31,320 --> 00:27:34,110
and how these models help us so that really was my point is i'm not

412
00:27:34,110 --> 00:27:36,150
disagreeing with anything that

413
00:27:36,160 --> 00:27:37,600
i think the key is that

414
00:27:37,610 --> 00:27:40,230
anyone who wants to stand up and tell me

415
00:27:40,230 --> 00:27:44,940
technology access the right one including the technologies i felt men

416
00:27:45,050 --> 00:27:48,840
i'm not telling you i think we have to think are

417
00:27:55,220 --> 00:28:00,890
so sorry because as long as the question to you but then i'd really like

418
00:28:00,900 --> 00:28:05,180
to reply also took it produces

419
00:28:05,240 --> 00:28:09,310
i know we were the last statement that i mean students who are i mean

420
00:28:09,310 --> 00:28:15,300
that we are teaching them semantic web or ontology engineering are not is capable

421
00:28:15,310 --> 00:28:19,560
of models i think they are they are really comparable and we're teaching them i

422
00:28:19,560 --> 00:28:22,100
mean we are doing ontology and getting well

423
00:28:22,220 --> 00:28:26,370
we teaching them to reduce models which is something that normally you don't eat when

424
00:28:26,370 --> 00:28:31,100
you're doing entity relationship models only i think that i mean that there are many

425
00:28:31,100 --> 00:28:35,860
aspects there i mean i i really we fully with dl hybridize in trying to

426
00:28:35,860 --> 00:28:40,590
find ways where we can represent real problems and solve them i mean i think

427
00:28:40,590 --> 00:28:44,780
that's the most important thing that we have to to think of i mean that's

428
00:28:44,800 --> 00:28:50,440
that's as well you're right don't forget we're research community service where we're picking low

429
00:28:50,440 --> 00:28:51,720
hanging fruit

430
00:28:51,730 --> 00:28:56,310
we're competing with the growing startup world that we help create

431
00:28:56,360 --> 00:29:01,650
right so again it no longer needs needs everyone in this room

432
00:29:01,690 --> 00:29:05,630
to be helping to figure out how you let some other company and back in

433
00:29:05,630 --> 00:29:10,570
nineteen eighty six someone said something really changed my thinking is the expert system world

434
00:29:10,800 --> 00:29:15,020
you know the first guy to act build the expert system

435
00:29:15,030 --> 00:29:18,020
you know frameworks and things like that

436
00:29:18,060 --> 00:29:19,890
has publishable results

437
00:29:19,940 --> 00:29:21,520
the second guy

438
00:29:21,570 --> 00:29:26,570
so does it gets published will result in a further validating one for sky

439
00:29:26,690 --> 00:29:30,060
the first guy to do it in some new domain different in the first it

440
00:29:30,060 --> 00:29:33,560
has published results because they help show that except

441
00:29:33,560 --> 00:29:39,110
the DNA of the same is independent because all the information you already

442
00:29:39,270 --> 00:29:42,710
we're going to study this case

443
00:29:42,890 --> 00:29:46,020
you have a different situation because

444
00:29:46,090 --> 00:29:49,940
well yes the question are e being the then you not observed

445
00:29:49,970 --> 00:29:53,570
we are not conditionally on

446
00:29:53,600 --> 00:29:56,300
we're not conditionals using

447
00:29:56,440 --> 00:29:58,060
b c

448
00:29:58,080 --> 00:30:02,680
we not going to condition on c

449
00:30:02,700 --> 00:30:06,420
but still we ask the question in the independent

450
00:30:06,470 --> 00:30:11,340
and then if you do this your surprisingly ten yes the i the

451
00:30:11,410 --> 00:30:15,240
so how do we do that we we write this feel free use

452
00:30:15,250 --> 00:30:16,830
this is called

453
00:30:16,870 --> 00:30:19,650
o five musicals over time you be

454
00:30:19,710 --> 00:30:21,720
so we have you a b

455
00:30:21,770 --> 00:30:25,920
is equal to the marginalisation over c and p of c

456
00:30:25,930 --> 00:30:30,320
which is the model of the forces of these factorizations

457
00:30:30,320 --> 00:30:31,840
there are

458
00:30:31,860 --> 00:30:33,350
we just feel free

459
00:30:33,400 --> 00:30:34,930
times of be

460
00:30:34,950 --> 00:30:39,440
times p of the given maybe

461
00:30:39,620 --> 00:30:42,600
these factors

462
00:30:42,670 --> 00:30:47,090
and the spectre go outside because you to do logical dependency

463
00:30:47,100 --> 00:30:51,650
and you only have some overseas of p of the given name

464
00:30:51,700 --> 00:30:57,360
how much is this

465
00:30:57,450 --> 00:31:00,610
we've seen these already there

466
00:31:00,650 --> 00:31:03,750
this is equal to one

467
00:31:03,770 --> 00:31:10,970
because we never have conditional probability and a sum over the first five

468
00:31:11,080 --> 00:31:14,260
because this is the distribution on

469
00:31:15,650 --> 00:31:19,630
this is the probability distribution

470
00:31:19,690 --> 00:31:22,990
it is a function of general functional c of e and b

471
00:31:23,000 --> 00:31:30,880
with so you probability function of c the

472
00:31:30,880 --> 00:31:34,770
by then a and b we are not going to go into the normalisation with

473
00:31:34,900 --> 00:31:38,150
fixed in the history normalize y

474
00:31:38,210 --> 00:31:45,220
by varying c

475
00:31:45,260 --> 00:31:49,830
now let's conditional on c let's assume condition c

476
00:31:51,330 --> 00:31:52,310
we use

477
00:31:53,700 --> 00:31:56,660
represents fact the conditional on c

478
00:31:56,710 --> 00:32:01,880
all its conditional on c

479
00:32:01,920 --> 00:32:04,400
then obtain the interesting

480
00:32:04,400 --> 00:32:06,950
if we we condition on c

481
00:32:09,520 --> 00:32:13,450
don't become independent anymore

482
00:32:13,520 --> 00:32:16,120
then they become the

483
00:32:16,150 --> 00:32:19,270
so basically this conditional independence will

484
00:32:21,480 --> 00:32:25,200
four of the five position this graph from the

485
00:32:25,250 --> 00:32:27,990
so essentially what you

486
00:32:28,000 --> 00:32:32,620
what we what we learn he is the this let's try to look at technology

487
00:32:32,670 --> 00:32:36,830
assumed to find

488
00:32:36,830 --> 00:32:39,860
this is a chart

489
00:32:39,910 --> 00:32:41,610
if i don't tell you anything

490
00:32:41,650 --> 00:32:42,660
the graph

491
00:32:42,680 --> 00:32:46,710
so you don't have so far they observed the child you don't have some of

492
00:32:49,010 --> 00:32:52,000
i the father and the mother independent

493
00:32:52,010 --> 00:32:54,400
well the independent because any

494
00:32:54,470 --> 00:32:57,940
father can can be a anyone the mother

495
00:32:57,960 --> 00:33:02,870
i don't know

496
00:33:04,720 --> 00:33:07,920
all right so actually is independent

497
00:33:07,970 --> 00:33:10,700
of the

498
00:33:10,790 --> 00:33:14,210
but if i observe the child

499
00:33:14,220 --> 00:33:15,320
let's assume

500
00:33:15,320 --> 00:33:16,720
they observed

501
00:33:19,880 --> 00:33:21,380
you know

502
00:33:21,390 --> 00:33:23,940
let's assume i i also the child

503
00:33:23,960 --> 00:33:30,110
who has brown eyes

504
00:33:30,110 --> 00:33:34,400
so the child the child has grown

505
00:33:34,410 --> 00:33:37,020
they are the parents of ten

506
00:33:37,040 --> 00:33:42,730
they are not enough in particular i know they can not all the lies

507
00:33:42,790 --> 00:33:47,660
because it will have a wide range child like

508
00:33:47,720 --> 00:33:50,650
by the very fact that they will serve as a child i know something about

509
00:33:50,650 --> 00:33:51,680
the parents

510
00:33:51,700 --> 00:33:53,350
the connected

511
00:33:53,430 --> 00:33:59,380
are for example if a observed that the child is cocaine

512
00:33:59,610 --> 00:34:07,690
i don't know anything about the band but he felt that the child is OK

513
00:34:07,740 --> 00:34:10,810
it's very likely that the parents

514
00:34:10,810 --> 00:34:12,430
i'm going to be

515
00:34:14,080 --> 00:34:16,510
so i know something about that

516
00:34:18,570 --> 00:34:19,920
tell you what happened

517
00:34:19,970 --> 00:34:27,340
look at any one of you know i know a lot about

518
00:34:31,790 --> 00:34:40,290
well i mean there's defense between them

519
00:34:40,340 --> 00:34:44,900
yes exactly exactly

520
00:34:44,910 --> 00:34:49,910
i know that there is a dependence between this i know that knowledge from one

521
00:34:50,200 --> 00:34:56,050
thing would be morally on

522
00:34:56,080 --> 00:34:57,650
OK so

523
00:34:59,390 --> 00:35:04,650
this interesting things here

524
00:35:04,690 --> 00:35:05,700
seeing that

525
00:35:05,700 --> 00:35:07,220
of k

526
00:35:13,300 --> 00:35:17,200
score of

527
00:35:17,250 --> 00:35:18,570
y one

528
00:35:18,630 --> 00:35:21,010
to y k

529
00:35:21,120 --> 00:35:23,130
is a

530
00:35:27,640 --> 00:35:31,900
his my i equals one

531
00:35:38,670 --> 00:35:40,490
why i minus one

532
00:35:40,510 --> 00:35:42,420
why i

533
00:35:42,420 --> 00:35:44,490
my so

534
00:35:44,510 --> 00:35:46,160
for any particular

535
00:35:46,180 --> 00:35:49,660
sequence of tags y one through y k

536
00:35:49,700 --> 00:35:54,360
which is starting at the beginning of the input sequence but not going all the

537
00:35:54,360 --> 00:35:57,150
way to the end of the input sequence i can talk about the score of

538
00:35:57,220 --> 00:35:59,920
a sequence of tags

539
00:36:02,950 --> 00:36:06,850
my goal

540
00:36:06,860 --> 00:36:07,940
is to

541
00:36:07,970 --> 00:36:09,370
find the

542
00:36:09,380 --> 00:36:11,920
the best sequence of tags

543
00:36:11,940 --> 00:36:12,950
so far

544
00:36:12,960 --> 00:36:16,060
find the tag sequence with the best score

545
00:36:19,300 --> 00:36:21,650
sequence y one

546
00:36:21,650 --> 00:36:23,810
july and

547
00:36:23,830 --> 00:36:28,810
with max school

548
00:36:33,550 --> 00:36:36,660
to find

549
00:36:36,690 --> 00:36:38,190
you OK

550
00:36:42,130 --> 00:36:46,320
one of the best sequence

551
00:36:46,330 --> 00:36:49,550
y one to y k

552
00:36:52,270 --> 00:36:56,760
and the value of k column b

553
00:36:56,820 --> 00:36:59,110
is the school

554
00:36:59,160 --> 00:37:01,910
test sequence

555
00:37:01,960 --> 00:37:03,210
y one

556
00:37:03,250 --> 00:37:05,690
who i k

557
00:37:06,640 --> 00:37:07,740
where is it

558
00:37:07,760 --> 00:37:08,970
y k

559
00:37:08,980 --> 00:37:12,430
he calls the

560
00:37:14,120 --> 00:37:19,150
and so this UK AV is just a special case of UK around adding the

561
00:37:20,270 --> 00:37:22,980
on the last time

562
00:37:23,000 --> 00:37:27,760
and my actually my goal

563
00:37:27,860 --> 00:37:30,110
is to find

564
00:37:30,150 --> 00:37:32,630
u n plus one

565
00:37:32,650 --> 00:37:34,400
and then

566
00:37:34,400 --> 00:37:36,470
and so

567
00:37:36,530 --> 00:37:43,590
a lot

568
00:37:45,030 --> 00:37:46,720
going to

569
00:37:46,820 --> 00:37:48,380
i mentioned this before

570
00:37:48,400 --> 00:37:52,430
for convenience are going to extend my set of tags

571
00:37:52,430 --> 00:37:56,740
to include two special attacks called start and and then i'm going to

572
00:37:57,160 --> 00:38:02,680
just assert that the that the zero tag why zero is start and the n

573
00:38:02,700 --> 00:38:06,090
plus one tag y n plus one and

574
00:38:06,840 --> 00:38:09,860
now my goal is to find

575
00:38:09,900 --> 00:38:12,760
this the best sequence of tags

576
00:38:12,760 --> 00:38:18,130
the goes after tagging plus one way tagging plus one equals and

577
00:38:18,150 --> 00:38:20,200
so been to here

578
00:38:20,260 --> 00:38:23,070
just we defined

579
00:38:23,110 --> 00:38:26,470
just got different notation for the goal of the algorithm

580
00:38:26,490 --> 00:38:29,430
because remember the goal is to find the argmax

581
00:38:29,450 --> 00:38:31,380
over all sequences of

582
00:38:40,200 --> 00:38:48,220
well you have a good question so it is only as the last set up

583
00:38:48,220 --> 00:38:52,180
it leads me to think well can i find you want then you to then

584
00:38:52,180 --> 00:38:53,700
new three

585
00:38:53,740 --> 00:38:58,680
and the answer is that i can do that in the guaranteed way by using

586
00:38:58,680 --> 00:39:01,180
an idea called dynamic programming

587
00:39:15,970 --> 00:39:18,150
max o y one

588
00:39:18,200 --> 00:39:19,930
to y

589
00:39:19,930 --> 00:39:22,280
OK minus one

590
00:39:24,630 --> 00:39:31,180
some from i corps one

591
00:39:31,200 --> 00:39:33,530
OK minus one

592
00:39:33,590 --> 00:39:34,680
g i

593
00:39:35,800 --> 00:39:39,780
why i minus one y i

594
00:39:45,200 --> 00:39:48,470
why i whatever y is

595
00:39:48,490 --> 00:39:49,420
and then

596
00:39:50,430 --> 00:39:55,110
which is fixed because these the argument UK the

597
00:39:55,130 --> 00:39:59,550
and so now comes the interesting part

598
00:39:59,780 --> 00:40:04,030
i'm going to have a recurrence

599
00:40:04,860 --> 00:40:07,630
u KV

600
00:40:07,740 --> 00:40:10,630
is the

601
00:40:10,680 --> 00:40:12,430
max of y

602
00:40:12,430 --> 00:40:14,780
OK minus one

603
00:40:19,650 --> 00:40:22,180
OK minus one

604
00:40:22,220 --> 00:40:25,220
common like a minus one

605
00:40:30,130 --> 00:40:34,490
like a minus one

606
00:40:42,380 --> 00:40:45,880
so here

607
00:40:47,590 --> 00:40:52,110
let we just go back here and write correctly

608
00:41:02,090 --> 00:41:04,760
here is the definition of UK v

609
00:41:04,900 --> 00:41:10,950
it's the score the best sequence y one to y k with like equals b

610
00:41:11,610 --> 00:41:15,490
it's actually a maximal y one to y k minus one

611
00:41:15,490 --> 00:41:18,900
the sum of the g functions for all four

612
00:41:18,900 --> 00:41:21,430
i was one of the k minus one

613
00:41:21,430 --> 00:41:22,920
and then

614
00:41:22,950 --> 00:41:27,720
cluster g function for y k minus one and

615
00:41:30,570 --> 00:41:33,280
this is the definition of the UK the function

616
00:41:34,340 --> 00:41:38,150
with this definition of the UK v function i can

617
00:41:38,150 --> 00:41:40,930
i can write down a recursive way too

618
00:41:41,570 --> 00:41:43,780
evaluate new cave

619
00:41:45,650 --> 00:41:47,320
it's the

620
00:41:47,340 --> 00:41:51,610
so the macs here of the y one to y k minus one

621
00:41:53,660 --> 00:41:58,900
i get if we had some actual y one to y k minus two

622
00:41:58,920 --> 00:42:00,220
and then

623
00:42:00,240 --> 00:42:03,760
ending in like a minus one

624
00:42:07,090 --> 00:42:11,610
so here i have gk like it was one v that's the same so this

625
00:42:11,610 --> 00:42:14,050
approximately right

626
00:42:14,190 --> 00:42:18,110
he was about to report

627
00:42:18,180 --> 00:42:20,660
university of reinforcement

628
00:42:22,960 --> 00:42:27,560
thank you so

629
00:42:27,570 --> 00:42:33,150
my talk is going to have three parts one is about dynamic programming

630
00:42:34,130 --> 00:42:39,720
so we started that and i hope that will be able to finish

631
00:42:39,730 --> 00:42:40,360
and so

632
00:42:40,380 --> 00:42:41,750
let's start

633
00:42:41,770 --> 00:42:47,560
so first first of all what reinforcement learning

634
00:42:47,580 --> 00:42:52,130
and what i'm talking about dynamic programming is the of reinforcement learning

635
00:42:52,160 --> 00:42:53,450
the first place

636
00:42:53,460 --> 00:42:56,560
well reinforcement learning according to a

637
00:42:56,580 --> 00:42:59,200
to reach is also in the

638
00:42:59,210 --> 00:43:01,640
university of reinforcement learning

639
00:43:04,640 --> 00:43:10,920
every method that uses samples to solve optimal control problems can be considered very first

640
00:43:13,060 --> 00:43:17,360
so we take this is the definition and so therefore we are going to study

641
00:43:17,380 --> 00:43:19,610
first dynamic programming

642
00:43:19,610 --> 00:43:23,050
which is sort of the basis forms the basis for

643
00:43:23,640 --> 00:43:26,160
the solutions for optimal control problems

644
00:43:26,190 --> 00:43:27,190
so by the way

645
00:43:27,200 --> 00:43:32,800
OK again this is your chance to learn about reinforcement learning

646
00:43:32,810 --> 00:43:35,500
please stop me and b

647
00:43:35,520 --> 00:43:37,200
to ask questions

648
00:43:37,220 --> 00:43:38,440
i don't care

649
00:43:38,450 --> 00:43:42,250
as someone has also said

650
00:43:42,270 --> 00:43:44,470
there are no stupid questions

651
00:43:44,470 --> 00:43:47,060
the only maybe stupid answers

652
00:43:47,090 --> 00:43:52,190
so don't feel embarrassed if you don't understand something

653
00:43:53,690 --> 00:43:55,250
some people

654
00:43:55,270 --> 00:44:00,420
and and they told me that

655
00:44:01,750 --> 00:44:06,640
they don't have enough time to understand during lectures all this stuff and they want

656
00:44:06,640 --> 00:44:09,530
to look after lots of the slides

657
00:44:09,590 --> 00:44:13,860
they i want to study is the saying and that's not a good approach

658
00:44:13,880 --> 00:44:15,440
we are here to learn

659
00:44:15,470 --> 00:44:18,170
and this is your seeing the chance to learn it

660
00:44:18,190 --> 00:44:22,820
maybe if it if you're not asking those questions maybe this chance begun

661
00:44:22,830 --> 00:44:27,390
because you will be busy this other things and you will have time to

662
00:44:27,420 --> 00:44:29,520
a study in the test for this

663
00:44:29,540 --> 00:44:30,990
different fields

664
00:44:30,990 --> 00:44:35,610
just please stop me maybe one get to the end but

665
00:44:35,650 --> 00:44:39,300
but at least you will have a better foundation

666
00:44:41,640 --> 00:44:42,860
i hope it's clear

667
00:44:42,860 --> 00:44:45,670
then we can start

668
00:44:45,680 --> 00:44:48,400
so first of all

669
00:44:48,420 --> 00:44:53,330
why do we talk about reinforcement learning what's the excitement about reinforcement learning by why

670
00:44:53,330 --> 00:44:57,390
do i care about reinforcement learning so that's the first thing that i like to

671
00:44:57,390 --> 00:45:01,790
talk about and that the godfather the type of defining a i

672
00:45:02,640 --> 00:45:04,400
then we

673
00:45:05,300 --> 00:45:11,390
deal with some specifics which go under the name of MDP is funny programming and

674
00:45:12,170 --> 00:45:15,700
we do a little bit of approximate dynamic programming

675
00:45:15,710 --> 00:45:18,420
so far so good i i believe

676
00:45:18,480 --> 00:45:22,400
so we got in the literature there are basically two books

677
00:45:22,460 --> 00:45:26,300
which are a little dated this time

678
00:45:26,300 --> 00:45:31,320
so one book is by its southern and andy barto

679
00:45:32,300 --> 00:45:34,140
you can see the book over there

680
00:45:34,170 --> 00:45:37,040
and these are the guys who committed it

681
00:45:38,450 --> 00:45:45,400
so this is an introductory book target to the genetic code interns and doesn't require

682
00:45:45,400 --> 00:45:48,110
much of mathematical background

683
00:45:48,120 --> 00:45:53,510
the other book is is more like a devoted to the theory five

684
00:45:53,550 --> 00:45:57,430
and the title is neuro dynamic programming

685
00:45:57,450 --> 00:46:01,640
and you know this is just the start of this is really really reinforcement learning

686
00:46:01,640 --> 00:46:04,580
without talking about

687
00:46:04,610 --> 00:46:09,980
and those are assigned image back to and joins the thickness the the in theory

688
00:46:09,980 --> 00:46:12,420
of reinforcement learning

689
00:46:12,420 --> 00:46:16,080
and in particular choice image about across

690
00:46:16,110 --> 00:46:19,490
has worked on dynamic programming then or since

691
00:46:19,520 --> 00:46:21,600
many many years

692
00:46:21,640 --> 00:46:23,400
it's probably not born

693
00:46:23,420 --> 00:46:25,390
was already working

694
00:46:25,930 --> 00:46:33,050
so regarding journals and conferences the main channels such email IM she chair and the

695
00:46:33,050 --> 00:46:36,160
idea knows also

696
00:46:36,550 --> 00:46:39,440
i relevant but maybe a little bit less relevant

697
00:46:39,490 --> 00:46:43,100
regarding conferences visu shows that

698
00:46:43,100 --> 00:46:44,120
and that's it

699
00:46:44,130 --> 00:46:46,680
from those three axioms you can

700
00:46:46,690 --> 00:46:50,640
get everything all the normal part of properties of the probability function

701
00:46:50,670 --> 00:46:54,350
can be derived from those three axioms for example

702
00:46:54,370 --> 00:46:55,930
the probability that the

703
00:46:55,940 --> 00:47:02,010
the property that the probability of the null set is equal to zero or the

704
00:47:02,010 --> 00:47:07,250
the probability of the eigenvalue and the union of a and the complement of a

705
00:47:07,250 --> 00:47:09,610
is equal to one and so forth let's just take a quick look at this

706
00:47:09,630 --> 00:47:10,760
final one

707
00:47:10,790 --> 00:47:12,870
suppose i have

708
00:47:12,890 --> 00:47:14,740
two subsets a and b

709
00:47:14,780 --> 00:47:18,540
but i don't make any statement as to whether or not they are disjoint these

710
00:47:18,540 --> 00:47:21,770
are just any two subsets a and b

711
00:47:21,780 --> 00:47:25,210
then the probability that i associate with the union

712
00:47:25,260 --> 00:47:26,640
of a and b

713
00:47:26,660 --> 00:47:30,380
is equal to the probability of a plus the probability of the

714
00:47:30,390 --> 00:47:34,920
one minus the probability of the intersection of a and b

715
00:47:35,010 --> 00:47:38,840
so that that's that also holds the notice that that's not quite the same thing

716
00:47:38,840 --> 00:47:40,300
is this third axes

717
00:47:40,310 --> 00:47:43,830
the third axiom appears kind of is a special case of that

718
00:47:43,880 --> 00:47:45,880
when that term is zero

719
00:47:46,870 --> 00:47:50,300
i hope i'm not going to use that theory in any sort of sophisticated way

720
00:47:50,300 --> 00:47:52,610
i hope this notation is more or less clear

721
00:47:52,650 --> 00:47:56,310
we're not going to be using that too much i just wanted to impress upon

722
00:47:56,310 --> 00:47:59,050
you that there is an axiomatic definition

723
00:47:59,080 --> 00:48:00,790
of probability

724
00:48:00,810 --> 00:48:04,220
which may be a little bit different from the notion of probability that you normally

725
00:48:04,220 --> 00:48:06,280
carry around

726
00:48:06,290 --> 00:48:08,510
there's one more

727
00:48:08,510 --> 00:48:13,270
type of probability that not actually follow from those three axioms and that's what's called

728
00:48:13,280 --> 00:48:15,000
conditional probability

729
00:48:15,040 --> 00:48:19,260
sometimes what we want to do is to regard to say the set of possible

730
00:48:19,260 --> 00:48:26,630
outcomes of measurements as being some subset of the originally specified sample space

731
00:48:26,680 --> 00:48:30,750
right so i want to constrain the outcome to be in some

732
00:48:30,790 --> 00:48:32,720
subset b

733
00:48:32,770 --> 00:48:36,600
and i defined then the probability of a given b

734
00:48:36,610 --> 00:48:37,990
as the probability

735
00:48:38,000 --> 00:48:39,980
the intersection of a and b

736
00:48:39,990 --> 00:48:42,690
divided by the probability of b

737
00:48:42,780 --> 00:48:47,090
that doesn't follow from the three color of axioms that has to be taken effectively

738
00:48:47,090 --> 00:48:48,940
is the fourth axiom

739
00:48:50,520 --> 00:48:54,170
so here's what i mean by that suppose i want to know

740
00:48:54,180 --> 00:48:57,160
what is the probability when you when you rolling a die

741
00:48:57,220 --> 00:49:02,280
what's the probability to have the number that comes up less than three

742
00:49:02,360 --> 00:49:07,640
given that somebody has peaked and told you that it's an even number

743
00:49:07,650 --> 00:49:11,760
i suppose so the probability of rolling and less than three given that n is

744
00:49:12,720 --> 00:49:16,780
all right so what's the intersection of in less than three

745
00:49:18,300 --> 00:49:21,100
even well that can only be

746
00:49:22,140 --> 00:49:24,610
right so the probability of rolling a two

747
00:49:24,630 --> 00:49:28,040
the other six possibilities and therefore that's one six

748
00:49:28,190 --> 00:49:31,910
and then here in the denominator we have to have the probability

749
00:49:31,930 --> 00:49:37,040
of rolling even number so that's two four six out of six to three six

750
00:49:37,080 --> 00:49:41,190
so therefore you would get one thirty for the probability of and less than three

751
00:49:41,210 --> 00:49:43,360
given n is even

752
00:49:43,380 --> 00:49:48,180
OK so that's conditional probability that's a very important concept that we will continue to

753
00:49:50,160 --> 00:49:54,760
that is closely related to important property that will also

754
00:49:54,800 --> 00:49:58,710
the meeting and that is the property of independence

755
00:49:58,760 --> 00:50:00,970
so two subsets a and b

756
00:50:00,990 --> 00:50:03,340
are said to be independent

757
00:50:03,390 --> 00:50:08,080
if the probability for the intersection of a and b that is to say a

758
00:50:08,080 --> 00:50:09,990
and b

759
00:50:10,010 --> 00:50:14,510
it is equal to the probability of a times the probability of b

760
00:50:15,390 --> 00:50:17,750
so that's just the definition

761
00:50:17,800 --> 00:50:21,890
why should that be called independent the what's what's that have to do with independence

762
00:50:21,890 --> 00:50:24,930
you could call it i don't factorize ability or something

763
00:50:24,990 --> 00:50:26,550
but it's easy to see why

764
00:50:26,560 --> 00:50:28,580
what that has to do with independence

765
00:50:28,590 --> 00:50:30,520
if you look at for example

766
00:50:30,530 --> 00:50:34,610
what the probability of a given b is

767
00:50:34,650 --> 00:50:37,220
in the case when a and b are independent

768
00:50:37,330 --> 00:50:39,110
right so

769
00:50:39,130 --> 00:50:44,310
let's see from the definition of the conditional probability the probability of a given b

770
00:50:44,330 --> 00:50:46,510
that's just that expression here

771
00:50:46,520 --> 00:50:48,660
but if a and b are independent

772
00:50:48,680 --> 00:50:51,430
then that probability in the numerator

773
00:50:51,460 --> 00:50:55,040
is simply the product p of a times p of

774
00:50:55,060 --> 00:50:58,780
and the p of these cancelled and this is just p of a

775
00:50:58,790 --> 00:51:02,890
so what does that mean that means the imposing the condition of b

776
00:51:02,960 --> 00:51:06,260
has no effect on the probability

777
00:51:06,300 --> 00:51:10,510
and so that somehow motivates why one would call that independence

778
00:51:11,770 --> 00:51:15,240
and similarly you can show that py of given a would simply be equal to

779
00:51:15,240 --> 00:51:16,040
p of

780
00:51:16,300 --> 00:51:23,740
so don't confuse independent subsets with disjoint subsets that's that's completely different to subsets means

781
00:51:23,740 --> 00:51:26,860
that their intersection is is the null set

782
00:51:27,810 --> 00:51:33,670
OK so that's that's conditional probability

783
00:51:35,210 --> 00:51:38,830
so that's all very abstract and we didn't even really have to insist on what

784
00:51:38,840 --> 00:51:43,180
the elements of the sample space represented but in order to

785
00:51:43,210 --> 00:51:48,110
give some sort of meaning to what to probability and to to specify

786
00:51:48,160 --> 00:51:53,030
a prescription according to which we can assign numerical values to the probability i have

787
00:51:53,030 --> 00:51:55,090
to interpret it in some way

788
00:51:55,180 --> 00:51:56,550
and there are two

789
00:51:56,560 --> 00:51:58,690
commonly used interpretations

790
00:51:58,710 --> 00:52:01,860
probability so let's go through that quickly

791
00:52:01,860 --> 00:52:02,750
one is

792
00:52:02,770 --> 00:52:08,850
that the elements of the sample space are outcomes of some repeatable experiment

793
00:52:08,870 --> 00:52:14,320
and i say that the probability of a is interpreted as the fraction of times

794
00:52:14,340 --> 00:52:16,440
that the outcome is a

795
00:52:16,470 --> 00:52:19,370
in the limit that i repeat the experiment

796
00:52:19,370 --> 00:52:21,890
some very large number of times

797
00:52:21,970 --> 00:52:27,270
so i'm assuming here that this experiment can be repeated some arbitrarily large number of

798
00:52:28,070 --> 00:52:33,970
and i think mathematicians probably last when i write this the slim and ghost because

799
00:52:33,970 --> 00:52:39,050
this is not a well-defined limiting these any sort of mathematical sense

800
00:52:39,060 --> 00:52:43,250
but nevertheless we have this notion that if you if somehow you could repeat an

801
00:52:43,250 --> 00:52:49,400
experiment an infinite number of times the fraction of a certain outcome might just converge

802
00:52:49,400 --> 00:52:51,880
just to switch to a certain value

803
00:52:51,890 --> 00:52:55,140
that is the idea that we have in mind

804
00:52:55,160 --> 00:52:59,690
in the usual sort of copenhagen interpretation of quantum mechanics

805
00:53:00,420 --> 00:53:03,590
and it's certainly very appropriate for the type of work that we do

806
00:53:03,590 --> 00:53:08,250
because when we collide together protons we for one thing we do an awful lot

807
00:53:08,250 --> 00:53:12,410
of time to write ten to eleven protons in each bunch the LHC so we're

808
00:53:12,410 --> 00:53:13,930
certainly repeating that

809
00:53:13,950 --> 00:53:18,550
pp collisions a large number of times and there doesn't seem to be any fundamental

810
00:53:18,550 --> 00:53:22,750
limit to the number of times that we could do that so this frequency interpretation

811
00:53:22,750 --> 00:53:27,220
of probability seems very appropriate

812
00:53:27,230 --> 00:53:29,700
on the other hand there's certainly we others

813
00:53:29,800 --> 00:53:31,810
types of situations

814
00:53:31,870 --> 00:53:35,160
where you want to talk about the degree of uncertainty

815
00:53:35,160 --> 00:53:38,420
vision you might want to search over all pairs of images to find the one

816
00:53:38,420 --> 00:53:41,450
that best matches the debt between the two

817
00:53:41,460 --> 00:53:46,370
so those are more search problems when you have maximisation

818
00:53:47,990 --> 00:53:48,860
OK so

819
00:53:48,860 --> 00:53:52,370
both sets of problems are hard in general

820
00:53:52,420 --> 00:53:57,520
this one is hard because you have

821
00:53:57,530 --> 00:54:02,950
again an exponential number of summations or you have a very high dimensional integrals

822
00:54:03,030 --> 00:54:06,780
right intervals are very easy if there in one dimension or two but they rapidly

823
00:54:06,780 --> 00:54:12,030
become very hard if if you have a higher dimensional ones

824
00:54:12,070 --> 00:54:16,110
right so these are generalizations of the problems that i think are notable to spoken

825
00:54:16,110 --> 00:54:20,740
about he's probably spoke about the problem of filtering in the other sequence something like

826
00:54:20,740 --> 00:54:23,120
the time series evolving over time

827
00:54:23,210 --> 00:54:24,190
anyone who

828
00:54:24,200 --> 00:54:28,910
computer approximate the marginal distribution given all the data up to time t

829
00:54:29,160 --> 00:54:35,630
that would be this problem here this marginalization problem if you on the markov chain

830
00:54:35,700 --> 00:54:40,370
would be interested in it from more general graphs

831
00:54:40,370 --> 00:54:47,450
if i go back to this example so that that demo that i showed you

832
00:54:47,450 --> 00:54:52,230
what was i doing what was the approximately doing

833
00:54:52,240 --> 00:54:56,850
really there extra notes here you're observing noisy versions right you had to clean image

834
00:54:56,850 --> 00:54:59,080
that was sitting there you didn't see that

835
00:54:59,120 --> 00:55:01,730
you saw a noisy image to be some

836
00:55:01,770 --> 00:55:06,770
shaded nodes there that show what you observe and what that algorithm was doing was

837
00:55:06,770 --> 00:55:11,000
it was approximately something very quickly over all codewords

838
00:55:11,030 --> 00:55:11,920
that are

839
00:55:12,950 --> 00:55:16,870
and for every node it was finding out is more likely to be o one

840
00:55:16,870 --> 00:55:18,440
or to be zero

841
00:55:18,450 --> 00:55:21,820
right so is computing the marginal at every node

842
00:55:21,900 --> 00:55:25,200
and it was more likely to be one then declare one

843
00:55:25,210 --> 00:55:26,910
and vice versa

844
00:55:26,920 --> 00:55:31,240
so that's what that alan was doing it wasn't doing it exactly because somebody mentioned

845
00:55:31,240 --> 00:55:34,740
this this graph actually has cycles but if it had been tree the algorithm that

846
00:55:34,740 --> 00:55:39,780
would represent will do it exactly into it very efficiently

847
00:55:42,820 --> 00:55:45,240
OK so the problems would like to solve

848
00:55:46,980 --> 00:55:57,610
let me come back to this tomorrow

849
00:55:57,660 --> 00:56:00,310
about variational methods and we just started

850
00:56:00,310 --> 00:56:02,610
talking about the max product algorithm

851
00:56:02,630 --> 00:56:09,570
OK so the max product algorithm how many people know about the viterbi algorithm

852
00:56:09,580 --> 00:56:13,670
OK so to be of them as a special case of the max product algorithm

853
00:56:14,410 --> 00:56:20,280
one reason graphical models are useful is because they essentially generalize many classical algorithms there

854
00:56:20,280 --> 00:56:24,280
is listed at least ten to fifteen algorithms that are special cases of what we're

855
00:56:24,280 --> 00:56:25,320
gonna do now

856
00:56:25,490 --> 00:56:29,230
so if you've heard of the term be that's a special case forward backward is

857
00:56:29,240 --> 00:56:33,920
a special case alphabet beta a special case common filtering is a special case fast

858
00:56:33,920 --> 00:56:38,660
fourier transform is a special case you can essentially go down the name you know

859
00:56:38,660 --> 00:56:42,740
many influential algorithms are all to a special case of what we're gonna do now

860
00:56:42,790 --> 00:56:47,040
that's part of the utility of graphical models they somehow allowed you see what the

861
00:56:47,070 --> 00:56:50,280
key ideas in all of these problems are

862
00:56:50,280 --> 00:56:54,240
OK so max product

863
00:56:54,280 --> 00:57:00,490
what is it's an algorithm for trying to solve problem number three

864
00:57:00,660 --> 00:57:05,200
it's trying to solve this maximization problems we have what we like to do is

865
00:57:05,200 --> 00:57:09,910
to maximize overall the nodes of the graph this product of terms

866
00:57:10,000 --> 00:57:13,530
that's where it gets its name you'll see in a minute because it has the

867
00:57:13,530 --> 00:57:15,400
maximum product and

868
00:57:15,410 --> 00:57:18,990
the algorithm all it does is play games with those two terms

869
00:57:19,000 --> 00:57:25,570
OK so let's let me do this concrete examples

870
00:57:25,750 --> 00:57:39,250
OK so max product

871
00:57:39,310 --> 00:57:45,040
right so the simple example i'm showing you have got three nodes

872
00:57:45,060 --> 00:57:46,770
one two and three

873
00:57:46,780 --> 00:57:48,730
so that's three variables

874
00:57:48,850 --> 00:57:52,150
and so i know that i have a factorizations

875
00:57:52,200 --> 00:57:55,870
over these three variables on the right in certain way because it's useful to me

876
00:57:55,870 --> 00:58:02,410
later on the right is proportional to the product of three terms

877
00:58:02,450 --> 00:58:04,700
one for every node

878
00:58:05,040 --> 00:58:08,090
it should be necessary

879
00:58:08,090 --> 00:58:10,670
well are you

880
00:58:22,320 --> 00:58:23,110
issue here

881
00:58:33,020 --> 00:58:34,580
the right

882
00:58:40,030 --> 00:58:42,500
and you are

883
00:59:31,260 --> 00:59:32,280
and you

884
00:59:35,240 --> 00:59:36,350
you have

885
01:00:15,670 --> 01:00:17,110
and you it

886
01:00:23,470 --> 01:00:26,930
and here i

887
01:00:34,360 --> 01:00:36,510
and how

888
01:01:24,570 --> 01:01:25,860
the have

889
01:01:26,370 --> 01:01:27,750
we can see the

890
01:01:48,540 --> 01:01:54,130
you you

891
01:02:04,470 --> 01:02:06,130
you just

892
01:02:27,910 --> 01:02:28,780
in this in the

893
01:02:39,960 --> 01:02:43,020
thank you very much and will

894
01:02:48,560 --> 01:02:49,210
what you

895
01:02:52,050 --> 01:02:56,420
you can the

896
01:03:10,160 --> 01:03:11,370
i think

897
01:03:29,890 --> 01:03:31,130
he said well

898
01:03:41,670 --> 01:03:42,810
i think

899
01:04:20,900 --> 01:04:22,440
this question

900
01:04:51,670 --> 01:04:54,260
you use

901
01:05:04,900 --> 01:05:07,480
so how do you

902
01:05:37,780 --> 01:05:39,460
and you

903
01:06:15,870 --> 01:06:16,950
i think

904
01:06:28,770 --> 01:06:29,530
we can

905
01:06:49,120 --> 01:06:50,140
you get

906
01:06:59,560 --> 01:07:01,310
you want to more

907
01:07:05,670 --> 01:07:08,600
and was he would teach me how human

908
01:07:12,050 --> 01:07:12,890
i think ready

909
01:07:12,890 --> 01:07:14,490
y is male or female

910
01:07:14,510 --> 01:07:22,340
so this is a a call arms unfortunately in english there's no

911
01:07:22,430 --> 01:07:25,240
gender free version of this as far as i know

912
01:07:25,390 --> 01:07:27,820
parent child now

913
01:07:27,840 --> 01:07:31,490
uncle aren't showing you come up with one

914
01:07:31,510 --> 01:07:32,930
and i'm going to try

915
01:07:32,950 --> 01:07:35,070
it's going to sound that

916
01:07:37,590 --> 01:07:40,140
why do we care about why because i want to see if i can do

917
01:07:40,140 --> 01:07:46,430
is recovering step three coloring idea was well the grandparents let's say it's black if

918
01:07:46,430 --> 01:07:47,430
i can push

919
01:07:47,450 --> 01:07:52,740
the blackness of the pair the grandparent down into the two children

920
01:07:52,760 --> 01:07:56,550
then if both of these are read in other words then i'd be happy that

921
01:07:56,590 --> 01:08:00,990
push the problem of this guy is now read skies black sinister alright this one

922
01:08:00,990 --> 01:08:02,120
may violate the

923
01:08:02,180 --> 01:08:05,740
great-grandparents but will just keep going up and that

924
01:08:06,950 --> 01:08:08,180
if we're lucky

925
01:08:08,220 --> 01:08:10,120
why is red

926
01:08:10,180 --> 01:08:12,600
then we can just to recurrent

927
01:08:12,620 --> 01:08:17,720
if the color y

928
01:08:17,740 --> 01:08:20,590
was red

929
01:08:20,720 --> 01:08:23,140
and the

930
01:08:24,280 --> 01:08:28,740
we will recall color and i'm going to differ

931
01:08:28,740 --> 01:08:30,220
this took pictures

932
01:08:30,260 --> 01:08:33,780
called case one

933
01:08:33,780 --> 01:08:36,570
OK let me first time you how cases

934
01:08:36,620 --> 01:08:40,530
and then we'll see how they work

935
01:08:55,340 --> 01:08:57,430
for non in case one

936
01:08:57,450 --> 01:08:59,700
so this else should be aligned with that

937
01:09:02,160 --> 01:09:07,070
then are either in case two or three here is that the dichotomy

938
01:09:12,490 --> 01:09:15,410
it turns out we've actually seen all the cases

939
01:09:15,430 --> 01:09:17,410
maybe not a versus b

940
01:09:17,450 --> 01:09:21,530
we've seen the case in the very beginning we're just recall that's case one

941
01:09:21,550 --> 01:09:26,490
the next thing we saw is what well it's kind of annoying the grandparent and

942
01:09:26,490 --> 01:09:31,340
ten seven and ten were not straight there is exactly

943
01:09:31,340 --> 01:09:34,090
so case two is when there is exact

944
01:09:34,100 --> 01:09:35,300
so that's

945
01:09:35,300 --> 01:09:40,030
if x is the right of the page you x is the right child of

946
01:09:40,030 --> 01:09:41,370
its parent

947
01:09:41,370 --> 01:09:46,860
and the parent is the left child of the grandparents of the same so far

948
01:09:46,870 --> 01:09:48,840
that is case two

949
01:09:52,180 --> 01:09:58,280
OK the other case if x is the left child of its parent so

950
01:09:58,300 --> 01:10:02,550
then we have left chain expert of x grandparents

951
01:10:02,550 --> 01:10:04,390
that's case three

952
01:10:04,410 --> 01:10:09,490
i not write else here

953
01:10:09,510 --> 01:10:13,010
because what case two does is it reduces the case three

954
01:10:13,010 --> 01:10:15,320
so in case two are going to do this stuff that's here and and then

955
01:10:15,320 --> 01:10:18,760
we're going do stuff here very case we just do this stuff here or in

956
01:10:18,760 --> 01:10:21,780
case one we just in the stuff here

957
01:10:21,800 --> 01:10:25,740
and then that finishes three cases on the a-side

958
01:10:25,760 --> 01:10:31,430
then back to this if we say else

959
01:10:31,550 --> 01:10:33,640
this is case b

960
01:10:33,680 --> 01:10:38,120
which is the same as a

961
01:10:38,180 --> 01:10:44,470
by reversing the notions

962
01:10:44,470 --> 01:10:46,700
left and right

963
01:10:46,700 --> 01:10:54,300
in the natural

964
01:10:54,390 --> 01:10:59,600
natural way every time we write something we instead write or something and vice versa

965
01:10:59,620 --> 01:11:02,990
so this is really just looking everything over

966
01:11:03,280 --> 01:11:05,800
just focus on case on

967
01:11:05,840 --> 01:11:09,390
category a and let's see what we do in each of the three cases were

968
01:11:09,410 --> 01:11:10,870
seen in the example

969
01:11:10,890 --> 01:11:12,550
let's do it generically

970
01:11:17,470 --> 01:11:28,300
so there's little there's one more line to the graph

971
01:11:29,570 --> 01:11:32,410
aligned with here

972
01:11:34,860 --> 01:11:38,820
there's a chance when you do all of this the road becomes red we always

973
01:11:38,820 --> 01:11:40,510
wanted to be black

974
01:11:40,530 --> 01:11:44,760
if it's red we set to black at the very end of the algorithm

975
01:11:47,720 --> 01:11:49,470
this does not change

976
01:11:49,490 --> 01:11:50,990
the black eyed property

977
01:11:51,010 --> 01:11:52,600
everything will still be fine causes

978
01:11:52,620 --> 01:11:55,600
i mean every path either goes the record doesn't

979
01:11:55,620 --> 01:11:57,600
every x to leave

980
01:11:58,530 --> 01:12:01,720
changing the route from red to black is no problem

981
01:12:01,720 --> 01:12:04,840
it will increase the black everyone but they all say

982
01:12:05,090 --> 01:12:11,120
all the paths will still have the same value just it'll be one large

983
01:12:12,260 --> 01:12:14,180
let's look at the three cases

984
01:12:14,200 --> 01:12:25,450
and i'm going to use some notation remember we have triangles in order to denote

985
01:12:25,470 --> 01:12:29,510
arbitrary subtrees and we define retention

986
01:12:29,570 --> 01:12:32,160
i'm going to use triangle with the dot on top

987
01:12:32,180 --> 01:12:33,260
so to say

988
01:12:36,320 --> 01:12:38,140
this node the subtree

989
01:12:38,160 --> 01:12:40,950
has a black

990
01:12:42,030 --> 01:12:47,680
so this what i feel something like it means black because i'm on the blackboard

991
01:12:58,100 --> 01:13:01,050
and i also have the property that each of these triangles

992
01:13:01,050 --> 01:13:05,720
i have the same black i

993
01:13:06,640 --> 01:13:07,800
so this will let me

994
01:13:07,820 --> 01:13:11,180
make sure the black black-eyed property property for

995
01:13:11,200 --> 01:13:13,870
is being preserved

996
01:13:13,870 --> 01:13:18,950
generations of search which by conventional standards now it worthless like things like altavista anybody

997
01:13:18,950 --> 01:13:23,240
remembers that was this idea of pagerank where you rank web search it's not just

998
01:13:23,240 --> 01:13:26,180
based on the match the words on the page to the words in the courage

999
01:13:26,360 --> 01:13:29,500
but to some sense of how important the web pages how central it is in

1000
01:13:29,500 --> 01:13:33,740
the greater conductivity network of the web and google shows that you can compute a

1001
01:13:33,740 --> 01:13:36,500
sensible in very efficient notion of

1002
01:13:36,540 --> 01:13:42,120
authoritativeness centrality by taking basically the first principal component of the web conductivity matrix so

1003
01:13:42,120 --> 01:13:44,860
PCA and related techniques

1004
01:13:44,870 --> 01:13:46,700
massively influential

1005
01:13:46,730 --> 01:13:50,820
what's missing well again you've seen some of this in all the talks here and

1006
01:13:50,820 --> 01:13:55,450
i want to give you my take on what the serious study of cognition learning

1007
01:13:55,450 --> 01:14:00,430
and cognition more generally tells us how to go beyond this

1008
01:14:00,470 --> 01:14:04,470
this paradigm but also what kind of insights can we take from this paradigm and

1009
01:14:04,500 --> 01:14:07,400
what other stuff do we have to add we want we don't just want to

1010
01:14:07,400 --> 01:14:11,440
throw this out because this such a successful paradigm like in in physics or any

1011
01:14:11,440 --> 01:14:16,440
other successful science we want success paradigms to build on what was valuable and write

1012
01:14:16,440 --> 01:14:19,390
about alternate so the premise of this

1013
01:14:19,400 --> 01:14:22,530
summer school it's pretty clearly is that

1014
01:14:22,550 --> 01:14:26,750
there is some sense in which cognition is heavily dependent on learning and learning should

1015
01:14:26,750 --> 01:14:30,010
be described as a kind of statistical inference but the question is what kind of

1016
01:14:30,010 --> 01:14:33,290
statistics and how does it interact with the other important

1017
01:14:33,310 --> 01:14:38,460
pieces of the picture and cognition the kinds of symbolic representations for example the nyquist

1018
01:14:38,700 --> 01:14:44,880
OK so the outline for for this talk will be three parts of give you

1019
01:14:44,880 --> 01:14:48,450
my take on the big problems of cognitive science which may cause already hinted at

1020
01:14:48,480 --> 01:14:52,580
a course it's this is a personal view but it's one that's widely shared also

1021
01:14:53,150 --> 01:14:56,330
it's not the only problem though just to be clear then talk about how machine

1022
01:14:56,330 --> 01:15:00,180
learning in its modern form can help address this problem and then a very brief

1023
01:15:00,180 --> 01:15:04,930
introduction to cognition viewed through the lens of statistical inference and learning like what's an

1024
01:15:04,930 --> 01:15:06,980
example of the sort of experiment we might do

1025
01:15:07,090 --> 01:15:09,080
just give some insight into how

1026
01:15:09,320 --> 01:15:13,410
into your why we might want to view cognition as a kind of statistical inference

1027
01:15:13,420 --> 01:15:17,610
so here's the big question from my point of view you could put it like

1028
01:15:17,610 --> 01:15:22,420
this how does the mind get so much from so little all across cognition we

1029
01:15:22,420 --> 01:15:27,860
see the mind taking in data as a the senses and making generalizations abstractions going

1030
01:15:27,860 --> 01:15:29,220
beyond the data

1031
01:15:29,250 --> 01:15:34,930
given building models doing things that by saying some conventional standard in in statistics maybe

1032
01:15:34,930 --> 01:15:38,830
by the standard that earlier paradigm should be possible to get it and we want

1033
01:15:38,830 --> 01:15:41,280
to understand how that works

1034
01:15:41,300 --> 01:15:47,130
so we can illustrate this from starting from visual perception

1035
01:15:47,180 --> 01:15:49,810
the the i think it's

1036
01:15:49,910 --> 01:15:54,830
but again widely acknowledged that taking out even learning the study of vision is where

1037
01:15:54,830 --> 01:15:58,730
we made the most progress in understanding how the brain and the mind work how

1038
01:15:58,730 --> 01:16:02,660
cognition spans all these different levels this is a slide from david marr's books on

1039
01:16:02,660 --> 01:16:07,640
mars are not remembered famous these days for a number of reasons including these this

1040
01:16:07,640 --> 01:16:11,540
way to think about how cognitive system works at different levels of analysis is talked

1041
01:16:11,540 --> 01:16:15,800
about but he was also probably this is the main legacy one of the founders

1042
01:16:15,800 --> 01:16:19,430
of the field of computational vision a field which has also a long history of

1043
01:16:19,430 --> 01:16:22,460
interactions between the human and engineering side

1044
01:16:22,640 --> 01:16:27,550
and in his book that based on research program developed over brief time he died

1045
01:16:27,550 --> 01:16:29,340
tragically early from cancer

1046
01:16:29,450 --> 01:16:34,200
this research was mostly done in the nineteen seventies and the book was published around

1047
01:16:34,200 --> 01:16:37,970
nineteen eighty laid out of view of how the visual system might work it was

1048
01:16:37,970 --> 01:16:41,680
mostly speculation he didn't have time to really work it all out

1049
01:16:41,690 --> 01:16:44,130
but there's a lot we can learn by looking at

1050
01:16:44,140 --> 01:16:47,410
now this is this figure here is just meant to illustrate what makes the problem

1051
01:16:47,410 --> 01:16:51,650
of vision heart how in the in this context vision is the mind going beyond

1052
01:16:51,650 --> 01:16:52,750
the data that's given

1053
01:16:52,790 --> 01:16:57,760
so here's an image again this is you know circa nineteen eighty digital image very

1054
01:16:59,080 --> 01:17:03,310
low resolution low contrast but we can still see what it is right so what

1055
01:17:03,310 --> 01:17:04,680
is this

1056
01:17:09,190 --> 01:17:15,500
look at the plant life heard somebody else it's leaf

1057
01:17:15,550 --> 01:17:19,020
is that one only four how many leaves either

1058
01:17:19,030 --> 01:17:22,440
four what else is there

1059
01:17:22,530 --> 01:17:25,580
this is standing right there you can you can put put a number of words

1060
01:17:25,580 --> 01:17:28,470
on this but you can also talk about the geometry right like use your hands

1061
01:17:28,480 --> 01:17:32,270
to describe the shape of this plant these leads sort of like this one can

1062
01:17:32,300 --> 01:17:36,580
leave club folding over another one passing behind another one over here so just from

1063
01:17:36,580 --> 01:17:42,410
this image very low quality images is you can extract semantic context enriched services process

1064
01:17:42,760 --> 01:17:46,320
but what does it look like coming into your eye looks like this this is

1065
01:17:46,320 --> 01:17:49,210
just zoom in in that box there of the

1066
01:17:49,230 --> 01:17:52,900
pixel brightness is on a scale of zero to two fifty five roughly like what

1067
01:17:52,900 --> 01:17:57,810
might be coming into your the retinal ganglion cells you pulling inputs from photoreceptors in

1068
01:17:57,810 --> 01:18:03,360
your retina and you just yes have numbers here right where there are the surfaces

1069
01:18:03,360 --> 01:18:06,180
or the leaves or stems of the plant

1070
01:18:06,190 --> 01:18:09,940
that's the problem and this particular human is an interesting one because this is a

1071
01:18:09,940 --> 01:18:15,280
region here one leaf crosses over the other and perceptually we see abound between surfaces

1072
01:18:15,280 --> 01:18:17,410
there but there's no actual

1073
01:18:18,440 --> 01:18:23,480
or a sharp change the image brightness is here it's all numbers around in ohio

1074
01:18:23,480 --> 01:18:26,110
one sixty slow one seventy so that's

1075
01:18:26,140 --> 01:18:30,570
that's interpolated based on of course other data that's here but also rich knowledge about

1076
01:18:31,170 --> 01:18:36,030
the world and and that indeed the processes of image formation like works

1077
01:18:36,110 --> 01:18:41,650
as as sonic pointed out or showed some great illustrations of the study of visual

1078
01:18:41,650 --> 01:18:45,750
illusions places where our minds plays tricks on a city like has long been used

1079
01:18:45,750 --> 01:18:49,760
by cognitive scientists to understand how the problem or what makes it hard and what

1080
01:18:50,050 --> 01:18:53,570
kind of assumptions are constraints might enable the solution

1081
01:18:53,580 --> 01:18:59,470
so here's my favorite visual illusion it's a close second perhaps to the brighton solutions

1082
01:18:59,470 --> 01:19:03,190
that make showed this one is by roger shepherd who is one of the founders

1083
01:19:03,190 --> 01:19:07,040
of cognitive psychology one of the most important figures in cognitive science he is also

1084
01:19:07,040 --> 01:19:12,290
a very good artist besides being very creative scientists and so he drew number of

1085
01:19:12,290 --> 01:19:16,500
it's the whole universe so no further restrictions on the object on the right hand

1086
01:19:17,300 --> 01:19:18,900
and this

1087
01:19:18,920 --> 01:19:22,920
concept description then describes all those things

1088
01:19:22,920 --> 01:19:24,840
which appear which show up

1089
01:19:24,880 --> 01:19:26,650
on the left-hand side

1090
01:19:26,650 --> 01:19:29,710
of top of the head of relation

1091
01:19:29,710 --> 01:19:31,790
and what we're saying here is that

1092
01:19:33,460 --> 01:19:35,460
of objects on the left side

1093
01:19:35,460 --> 01:19:37,270
of head of tupels

1094
01:19:37,320 --> 01:19:39,400
are a subset of

1095
01:19:39,400 --> 01:19:48,650
the professors

1096
01:19:48,670 --> 01:19:51,860
now if you

1097
01:19:51,920 --> 01:19:55,230
take a minute and have a look at the chair

1098
01:19:55,230 --> 01:19:57,550
the concept x here

1099
01:19:57,610 --> 01:19:59,820
and then we see that

1100
01:19:59,880 --> 01:20:00,840
we know

1101
01:20:01,500 --> 01:20:06,610
chairs show up on the left-hand side of the head of tupels right because is

1102
01:20:07,090 --> 01:20:09,860
the restriction that we impose on all chairs

1103
01:20:09,880 --> 01:20:13,980
and since they impose they show up

1104
01:20:13,980 --> 01:20:17,290
as objects on the left-hand side ahead of

1105
01:20:17,300 --> 01:20:21,090
all chairs must be professor so all of a sudden

1106
01:20:23,590 --> 01:20:28,590
sub concept of professor and not only if you want all

1107
01:20:29,840 --> 01:20:34,750
first and then the rest is pretty much the same

1108
01:20:37,210 --> 01:20:41,610
you add an axiom and you introduce

1109
01:20:41,670 --> 01:20:48,070
concept subsumption relationship between concept names that are you see not directly related to the

1110
01:20:48,070 --> 01:20:50,790
extent that you have in your window

1111
01:20:50,800 --> 01:20:53,210
right that you know

1112
01:20:54,230 --> 01:20:59,500
it's apparent that you need reasoning techniques to find this out as you have seen

1113
01:20:59,500 --> 01:21:01,940
before you will be informed

1114
01:21:01,940 --> 01:21:05,520
about new subsumption relationships

1115
01:21:05,520 --> 01:21:09,360
which might be unexpected which might be unwanted even

1116
01:21:09,360 --> 01:21:13,710
so if it turns out that you don't want chairs to be professor you have

1117
01:21:13,710 --> 01:21:15,980
to somehow revise the model

1118
01:21:16,000 --> 01:21:20,630
and later on you will see how this can repair could be supported using reasoning

1119
01:21:31,210 --> 01:21:32,840
o thing

1120
01:21:32,900 --> 01:21:37,770
might be a very common modelling

1121
01:21:37,790 --> 01:21:47,670
take you technique and it is known as the domain restriction

1122
01:21:47,690 --> 01:21:50,630
for the head of

1123
01:21:50,710 --> 01:21:53,670
relation and so probably

1124
01:21:53,710 --> 01:21:54,670
you will

1125
01:21:54,690 --> 01:22:01,000
use an ontology language that provides a dedicated syntax to to make it more apparent

1126
01:22:01,000 --> 01:22:03,460
what you do right

1127
01:22:03,520 --> 01:22:07,480
impose the domain restriction on the

1128
01:22:07,520 --> 01:22:09,840
relation head off

1129
01:22:09,880 --> 01:22:13,900
but you see

1130
01:22:13,940 --> 01:22:20,670
concerning the semantics that we adopt this introduces implicit subsumption relationship no matter how you

1131
01:22:22,650 --> 01:22:24,480
this kind of restriction

1132
01:22:36,300 --> 01:22:38,090
the just two

1133
01:22:39,070 --> 01:22:43,320
i understand what is going on here we might use the

1134
01:22:43,360 --> 01:22:47,380
but how how do i reduce the

1135
01:22:47,420 --> 01:22:50,800
scale here the idea

1136
01:22:51,520 --> 01:22:56,400
so if this is new to me and from getting lost

1137
01:22:56,400 --> 01:23:00,320
OK thanks alot that's great and this is the point

1138
01:23:00,380 --> 01:23:03,030
great call no

1139
01:23:03,090 --> 01:23:09,150
been using this machine for quite some time know that but it's nodes not

1140
01:23:10,070 --> 01:23:11,440
i noted the

1141
01:23:17,090 --> 01:23:17,960
into this

1142
01:23:17,980 --> 01:23:22,460
raise the reason here and as you can see there are

1143
01:23:22,520 --> 01:23:23,900
this this is the

1144
01:23:23,900 --> 01:23:34,150
taxonomy that the system computes

1145
01:23:34,170 --> 01:23:37,550
you can using the interface you can

1146
01:23:39,630 --> 01:23:44,110
inspect the

1147
01:23:44,110 --> 01:23:49,270
concept definitions here and so on and so forth you can just interactively deal with

1148
01:23:49,270 --> 01:23:53,590
your concept either using proce or other tools

1149
01:23:53,610 --> 01:23:57,300
and you can select the

1150
01:23:57,360 --> 01:23:58,420
notes here

1151
01:23:58,440 --> 01:24:03,610
and you might then use these concepts for checking out whether there are instances of

1152
01:24:03,630 --> 01:24:08,130
chair so this will be dealt with later on now we focus on the class

1153
01:24:08,860 --> 01:24:11,130
we we might

1154
01:24:11,190 --> 01:24:16,250
just introduce a new concept work can do this year so you might just introduce

1155
01:24:21,020 --> 01:24:24,090
a person taking

1156
01:24:35,270 --> 01:24:39,250
for which there exists something that they take in this something that must be a

1157
01:24:44,520 --> 01:24:45,590
i will

1158
01:24:45,610 --> 01:24:47,710
increased the

1159
01:24:52,610 --> 01:24:56,130
so the idea is that

1160
01:24:56,150 --> 01:25:02,530
we might be tempted to introduce a new name person taking lectures into our model

1161
01:25:02,570 --> 01:25:09,920
and we define this name so we see this concept description person some takescourse chair

1162
01:25:09,920 --> 01:25:12,090
course sorry

1163
01:25:12,110 --> 01:25:15,270
some takescourse course

1164
01:25:15,270 --> 01:25:17,210
some that we would like to call

1165
01:25:17,230 --> 01:25:18,940
the person taking lectures

1166
01:25:19,020 --> 01:25:22,460
and that's okay for the system and i hope you can show this

1167
01:25:22,480 --> 01:25:25,000
then we should probably see this

1168
01:25:25,070 --> 01:25:26,520
you know it

1169
01:25:26,530 --> 01:25:28,020
in the

1170
01:25:28,020 --> 01:25:31,390
so this one plot on the x axis it plots sort of the levels of

1171
01:25:31,390 --> 01:25:35,120
the cascade right so this cascade here has four levels of c one two three

1172
01:25:35,120 --> 01:25:39,370
four right and what i'm blocking here is sort of the information gets farther away

1173
01:25:39,370 --> 01:25:45,820
from the source i'm i'm blocking them for example the black line here is objectivity

1174
01:25:45,840 --> 01:25:50,010
right and what this is trying to say is that cascades sort of usually they

1175
01:25:50,010 --> 01:25:55,870
started the relatively my sort of without any sort of this that the baseline sentiment

1176
01:25:55,930 --> 01:26:01,890
and then very quickly the opinions polarizer activities there is this increase in in

1177
01:26:01,910 --> 01:26:07,200
or decreasing objectivity which means people start using sick sentiment sentiment words more and more

1178
01:26:07,230 --> 01:26:11,260
and then and then the cascade cools off and sort of big gets more objective

1179
01:26:11,270 --> 01:26:15,730
so what seems to suggest that in the first two steps of information propagation there

1180
01:26:15,730 --> 01:26:20,930
is this let's a polarization that occurs and then as information gets older and propagate

1181
01:26:20,940 --> 01:26:24,510
even for the

1182
01:26:24,510 --> 01:26:28,880
opinions start to cool off and actually the language gets more objective than what was

1183
01:26:28,880 --> 01:26:30,330
the baseline of the

1184
01:26:30,340 --> 01:26:34,410
of the of the of the blogs that mentioning the things right so it's interesting

1185
01:26:34,410 --> 01:26:38,860
that you get this sort of good this could heating up of the cascade and

1186
01:26:38,870 --> 01:26:44,480
then sort of cooling off effects as the information gets for these are just two

1187
01:26:44,480 --> 01:26:48,670
examples what can be done with information flow and sentiment i think there are like

1188
01:26:48,980 --> 01:26:50,500
parts of others

1189
01:26:50,550 --> 01:26:52,820
interesting questions here that the

1190
01:26:52,860 --> 01:26:56,380
i haven't yet been answered by the the way the the enabling thing here is

1191
01:26:56,380 --> 01:27:00,690
to trace have blog blog posts place hyperlink so that we can see how it

1192
01:27:00,690 --> 01:27:04,670
for the the better which information flows and i'll start analyzing the sentiment as a

1193
01:27:04,670 --> 01:27:09,230
function of the shape of the cascade or the distance from the initiator of the

1194
01:27:09,230 --> 01:27:11,040
cascade and so on so

1195
01:27:11,090 --> 01:27:16,430
this is this is the first way how we can information through hyperlinks what is

1196
01:27:16,430 --> 01:27:20,370
so what is good about sort of right abstract up and see what is good

1197
01:27:20,370 --> 01:27:22,950
about this and what is not so good about so

1198
01:27:38,800 --> 01:27:42,810
exactly the color correlation gets to get so exactly so here is the

1199
01:27:42,820 --> 01:27:46,130
with the relation is positive and and sort of the slope is more than one

1200
01:27:46,130 --> 01:27:49,700
so here it seems that if the parent is subjective children are getting even more

1201
01:27:50,860 --> 01:27:54,450
right but then when you go high off sort of the correlation since the turn

1202
01:27:54,450 --> 01:28:00,020
around and says children get less objective than the pattern OK good so to say

1203
01:28:00,020 --> 01:28:02,900
to say some thoughts about this right so the first thing is why is why

1204
01:28:02,900 --> 01:28:07,390
slicing hyperlinks could for the thing is the first thing is it's very it's unambiguous

1205
01:28:07,390 --> 01:28:13,730
precise and explicit way to trace information to trace information flow right i we obtained

1206
01:28:13,810 --> 01:28:17,950
above the timing information that someone and we also painted the place of information so

1207
01:28:17,950 --> 01:28:22,460
we obtain the ground we obtain the cascade so we can start analyzing discussed what

1208
01:28:22,460 --> 01:28:25,910
is not so good about this is the basic idea making this assumption that whenever

1209
01:28:25,910 --> 01:28:31,290
someone creates link somewhere else there are some information from their transferred to me right

1210
01:28:31,320 --> 01:28:36,150
so there are many things that do not transmit information particular navigational links templates and

1211
01:28:36,150 --> 01:28:40,210
things like that the other important point is that for example mainstream media sites do

1212
01:28:40,210 --> 01:28:43,770
not create links to one another right so there are no links between washington post

1213
01:28:43,770 --> 01:28:47,190
the new york times even though they may be stealing stories from one another right

1214
01:28:47,190 --> 01:28:49,160
so the problem is

1215
01:28:49,500 --> 01:28:54,200
that sort of these database very let's to a very high high precision but low

1216
01:28:54,200 --> 01:28:57,900
recall right similar happens with bloggers who sort of forget to add the link to

1217
01:28:57,900 --> 01:29:02,960
the source right and this this this problem that people don't create hyperlinks so that

1218
01:29:02,980 --> 01:29:09,120
we often in online media given at who had implicit networks will motivate the the

1219
01:29:09,120 --> 01:29:13,120
later part of the of the story that was asking me for the networks of

1220
01:29:13,130 --> 01:29:18,610
image information spreads OK so this is this is the one important point the important

1221
01:29:18,610 --> 01:29:22,260
point that i want to more skin through the going to do this is really

1222
01:29:22,260 --> 01:29:27,260
the basically because we have a complete data when we collect this information flows especially

1223
01:29:27,260 --> 01:29:30,990
if you go online on the blogosphere the the problem becomes that our cascades will

1224
01:29:30,990 --> 01:29:34,570
become fun so what i mean by that is imagine that this is this is

1225
01:29:34,570 --> 01:29:38,820
a particular cascade truck is just a theory of how information spreads started red mullet

1226
01:29:38,880 --> 01:29:43,200
then it touched or this not so but then the problem is because i'm calling

1227
01:29:43,420 --> 01:29:48,930
online data may be a crawler somehow i missed the blocked both that here showing

1228
01:29:48,930 --> 01:29:51,220
great right so the problem is that

1229
01:29:51,360 --> 01:29:55,400
my data i have missing data some of my cascade being this kind of nice

1230
01:29:55,890 --> 01:30:00,720
binary tree or near a nearly binary tree it really really be some some strange

1231
01:30:00,720 --> 01:30:04,920
thing it would be like chain here and then sort of two more separated components

1232
01:30:04,920 --> 01:30:09,270
and so on right so the important thing here is fight let's have some at

1233
01:30:09,270 --> 01:30:15,450
and i have something propagating through the network some cascade this chain of length two

1234
01:30:15,450 --> 01:30:20,090
right and then for some reason maybe i didn't crawler somehow i'm missing data that

1235
01:30:20,090 --> 01:30:24,600
nodes are also mention this piece of information that might escape instead of looking like

1236
01:30:24,600 --> 01:30:28,780
this as it should look like just just as two isolated nodes in the finals

1237
01:30:28,850 --> 01:30:32,720
asking OK what are the properties of this thing was the properties of that thing

1238
01:30:32,720 --> 01:30:36,410
of course it's very different right so here i can say what is the depth

1239
01:30:36,410 --> 01:30:39,780
or one plus the depth of this cascade here and say three here and see

1240
01:30:39,970 --> 01:30:44,630
here and say sorry what is the size here is say three right i have

1241
01:30:44,630 --> 01:30:48,060
three notes here and say i have two nodes or if i start asking what

1242
01:30:48,060 --> 01:30:51,190
is the depth of the cascade here i would say that there is still here

1243
01:30:51,190 --> 01:30:55,270
and say that the zero right so that one problem is if i have a

1244
01:30:55,270 --> 01:30:59,360
few missing pieces in the in the case of information flow in the cascade microscope

1245
01:30:59,360 --> 01:31:05,510
can get disconnected and i have no clue how to what to do about so

1246
01:31:05,630 --> 01:31:10,000
here is here is what what one can do actually that it is possible to

1247
01:31:10,000 --> 01:31:13,200
correct for the effects of missing data on cascades right so the way you can

1248
01:31:13,200 --> 01:31:17,260
think about this is to say OK i want to find some properties of the

1249
01:31:17,260 --> 01:31:22,020
complete cascade c and property can mean what is the that what is the number

1250
01:31:22,020 --> 01:31:25,040
of nodes what is the number of leaf nodes and things like that so that's

1251
01:31:25,040 --> 01:31:28,130
what i'd like to do the problem is that i have missing data so i

1252
01:31:28,130 --> 01:31:31,200
don't get to see this real cascade but i just get to see some kind

1253
01:31:31,200 --> 01:31:37,330
of cascaded missing in right and it under the assumption that each node is missing

1254
01:31:37,360 --> 01:31:42,330
uniformly at random with some small probability that we can sort of have a paper

1255
01:31:42,330 --> 01:31:46,650
there is a paper whose main messages the following the first thing is that the

1256
01:31:46,970 --> 01:31:51,880
method that we put in the paper is because the effective about when more than

1257
01:31:51,880 --> 01:31:55,570
so i can represent my my graph is the matrix

1258
01:31:55,600 --> 01:31:57,050
now what is

1259
01:31:57,090 --> 01:31:59,340
special about this matrix

1260
01:31:59,340 --> 01:32:04,770
compared to the user like the general because problem first of all the input matrix

1261
01:32:04,770 --> 01:32:09,380
is symmetric because here we have the same label in both directions is an undirected

1262
01:32:10,160 --> 01:32:14,230
secondly the output of the clustering of the rows should equal the output of the

1263
01:32:14,230 --> 01:32:16,300
clustering of the columns is very similar

1264
01:32:16,360 --> 01:32:21,050
two what we required in the problem of classifying antibiotics

1265
01:32:21,200 --> 01:32:23,790
so i want to have a partitioning of the graph

1266
01:32:23,890 --> 01:32:28,090
so partitioning of the nodes will have the same here is here so i want

1267
01:32:28,090 --> 01:32:31,770
to have the same partitioning of the columns and the rows

1268
01:32:31,790 --> 01:32:36,360
and finally the requirements that

1269
01:32:36,370 --> 01:32:37,920
members of the same

1270
01:32:37,940 --> 01:32:41,090
block should have plus between them and of

1271
01:32:41,110 --> 01:32:45,930
different blocks to the minus one translates into the requirements when i look at this

1272
01:32:47,070 --> 01:32:51,110
it's not just that they want the block to be homogeneous but they wanted to

1273
01:32:51,110 --> 01:32:53,370
be a plus one

1274
01:32:53,920 --> 01:32:54,770
a lot

1275
01:32:54,860 --> 01:32:58,620
not because the one thousand eight those two

1276
01:32:59,870 --> 01:33:02,960
but this is come from the same block

1277
01:33:02,980 --> 01:33:05,770
so i want to have plus one

1278
01:33:05,780 --> 01:33:08,120
o minus one

1279
01:33:08,170 --> 01:33:12,710
so this gives us

1280
01:33:12,740 --> 01:33:15,030
a version of by clustering in which

1281
01:33:15,040 --> 01:33:20,390
we not only require homogeneity of each block but we also dictate

1282
01:33:20,390 --> 01:33:24,340
what is going to be the pattern of labels of the plot

1283
01:33:24,360 --> 01:33:27,980
in this case the patterns of the labels of the block should be

1284
01:33:28,010 --> 01:33:31,200
plus one along the diagonal and minus one

1285
01:33:31,290 --> 01:33:33,940
on block which of diagonal

1286
01:33:33,960 --> 01:33:37,660
so specific case of the clustering and you can think of it is not very

1287
01:33:37,660 --> 01:33:39,120
different because

1288
01:33:39,170 --> 01:33:44,480
then the total number of potential patterns of blocks is small we suspect the size

1289
01:33:44,490 --> 01:33:45,720
of the matrix

1290
01:33:45,750 --> 01:33:49,680
it's two to the l times k but that's very small compared to

1291
01:33:50,660 --> 01:33:53,440
we can consider we can view the

1292
01:33:53,460 --> 01:33:56,460
correlation clustering problem as

1293
01:33:56,470 --> 01:34:02,260
some twist on the biclustering problem and indeed the algorithm that we have phone

1294
01:34:02,510 --> 01:34:05,840
the biclustering problem also of

1295
01:34:05,840 --> 01:34:12,780
any problem like this and hardness results they also go both ways

1296
01:34:14,490 --> 01:34:17,460
let me get to the results

1297
01:34:17,500 --> 01:34:19,810
so that the is the

1298
01:34:19,840 --> 01:34:20,720
that i

1299
01:34:20,730 --> 01:34:26,460
the first one to describe the computational complexity results

1300
01:34:26,480 --> 01:34:29,210
and we could show for the minority buy myself

1301
01:34:29,300 --> 01:34:31,690
actually for all three

1302
01:34:31,690 --> 01:34:38,490
types of objective functions for the minority cost for the maximum cover mogeneous blocks and

1303
01:34:38,490 --> 01:34:44,650
for the minimum weighted by and we could show all these problems are NP hard

1304
01:34:44,900 --> 01:34:48,800
actually not only NP hard that you can show that there is no

1305
01:34:48,820 --> 01:34:54,190
the test but i mean it's even hard to approximate in some precise fence

1306
01:34:54,400 --> 01:34:59,200
and on the other hand we can have an approximation algorithm for those problems with

1307
01:34:59,200 --> 01:35:01,640
guaranteed approximations

1308
01:35:03,100 --> 01:35:04,750
success so

1309
01:35:04,770 --> 01:35:11,560
what we show here is that this is an approximation algorithm that finds in time

1310
01:35:11,560 --> 01:35:13,480
which is same

1311
01:35:13,500 --> 01:35:18,190
i want to get to for let's ignore this for a second so in this

1312
01:35:18,190 --> 01:35:24,700
time it computer clustering with because is no more than the optimal cost cost plus

1313
01:35:26,640 --> 01:35:31,120
the running time ten need is linear in the size of the matrix

1314
01:35:31,130 --> 01:35:35,350
but exponential in one of absence square

1315
01:35:35,430 --> 01:35:37,960
in the number of blocks

1316
01:35:37,970 --> 01:35:43,940
and in that it's a probabilistic algorithm in their probability of success

1317
01:35:43,980 --> 01:35:49,260
so we get an algorithm which is linear in the size

1318
01:35:49,270 --> 01:35:54,460
of the matrix by the exponential in the precision and accuracy

1319
01:35:54,460 --> 01:35:58,410
parameters and in the numbers of blogs and columns

1320
01:35:58,460 --> 01:36:01,790
and in fact i mean one could ask

1321
01:36:01,820 --> 01:36:03,590
this is

1322
01:36:03,590 --> 01:36:09,370
a quite satisfactory results it's almost matches the lower about we can prove in terms

1323
01:36:09,370 --> 01:36:12,410
of hardness one could that

1324
01:36:12,430 --> 01:36:13,530
is this

1325
01:36:13,560 --> 01:36:19,550
exponential depend on the exponential dependence of epsilon is the inevitable and we can show

1326
01:36:19,550 --> 01:36:24,810
to the hardness results but exponential dependence can analyse that is it really needed and

1327
01:36:24,810 --> 01:36:26,200
we could in fact show

1328
01:36:28,170 --> 01:36:31,120
it is the case that if you consider

1329
01:36:31,140 --> 01:36:31,940
so the

1330
01:36:31,950 --> 01:36:34,250
from the point of view of computational complexity

1331
01:36:34,270 --> 01:36:41,980
the two basic cases we can consider one is that it is

1332
01:36:42,430 --> 01:36:43,950
so case one

1333
01:36:43,960 --> 01:36:48,020
is that what i consider him OK in part

1334
01:36:50,380 --> 01:36:54,130
the input

1335
01:36:54,490 --> 01:36:57,620
the second case is knl

1336
01:37:00,820 --> 01:37:07,120
what we saw what we show here is the hardness of both cases so if

1337
01:37:07,120 --> 01:37:10,850
ten l a part of the input we can show how this of bi clustering

1338
01:37:12,010 --> 01:37:15,690
if you do not allow permutations of the rows and columns

1339
01:37:17,190 --> 01:37:21,310
i don't allow for the for the columns might task is very simple so i

1340
01:37:21,310 --> 01:37:24,000
keep the rules in the same order i keep the columns in the same order

1341
01:37:24,190 --> 01:37:27,920
i just want to know when to and my first block and start my second

1342
01:37:29,410 --> 01:37:31,870
well they can show is that this is already

1343
01:37:31,880 --> 01:37:36,660
np p hard if five you can tell us about this is i can not

1344
01:37:36,660 --> 01:37:39,810
be polynomial in k in

1345
01:37:39,860 --> 01:37:44,030
on the other hand if i you can and is fixed

1346
01:37:44,060 --> 01:37:49,470
then without computing the blocks just pounding to stop is of course

1347
01:37:50,200 --> 01:37:54,030
an easy task when windows of fixed

1348
01:37:54,050 --> 01:37:58,590
i mean it takes time and and to the k times and to help but

1349
01:37:58,590 --> 01:38:03,940
if k l are considered constant then this is one of the time and

1350
01:38:03,940 --> 01:38:06,320
if i don't allow limitations

1351
01:38:06,350 --> 01:38:10,200
but if i do allow limitations that's the hardness is unlikely

1352
01:38:10,220 --> 01:38:14,210
get here that if there are constants then it becomes NP hard

1353
01:38:14,220 --> 01:38:17,300
when you want to find the best permutation of the rows and columns

1354
01:38:17,320 --> 01:38:21,850
which is the kind of problem to consider is considered as viable

1355
01:38:21,850 --> 01:38:26,050
then even if you don't allow limitations is NP hard which means that

1356
01:38:26,090 --> 01:38:29,640
we cannot hope to get rid of this exponential dependence

1357
01:38:29,680 --> 01:38:32,200
on can

1358
01:38:32,220 --> 01:38:35,980
so we we have a hardness results for all those three

1359
01:38:36,030 --> 01:38:42,440
types of objective cost functions and we have an approximation algorithm

1360
01:38:42,440 --> 01:38:46,640
and what do you want to do now is to discuss little bit

1361
01:38:46,680 --> 01:38:52,930
idea behind the formation of so i hope that you are still

1362
01:38:52,940 --> 01:38:55,160
life and be interested

1363
01:38:55,180 --> 01:38:56,250
so here is

1364
01:38:56,250 --> 01:38:58,940
and not having spirit

1365
01:39:11,550 --> 01:39:14,840
this is

1366
01:39:14,920 --> 01:39:16,630
the last they're replying to

1367
01:39:18,540 --> 01:39:22,440
does not apply to become

1368
01:39:22,440 --> 01:39:23,840
in particular

1369
01:39:23,860 --> 01:39:27,430
this can be done the zero by good choice of classifier

1370
01:39:27,460 --> 01:39:30,080
that means that this can be done zero

1371
01:39:30,320 --> 01:39:32,950
could user classifier

1372
01:39:33,000 --> 01:39:40,570
another thing which is interesting about this is that a lot of people designing individual

1373
01:39:40,610 --> 01:39:41,990
learning our limbs

1374
01:39:41,990 --> 01:39:45,040
like for example support vector seems to

1375
01:39:45,100 --> 01:39:49,280
you have failed to generalize the multiclass case correctly

1376
01:39:49,340 --> 01:39:52,740
and says that there is a black box technique

1377
01:39:52,760 --> 01:39:55,300
generalizing the multiclass case

1378
01:39:55,350 --> 01:39:57,530
which always works

1379
01:39:57,550 --> 01:39:58,690
for any

1380
01:39:58,700 --> 01:40:02,560
good binary classification error

1381
01:40:02,620 --> 01:40:11,390
and there are things people to keep track of like consistency and so forth is

1382
01:40:11,390 --> 01:40:15,310
but i can see implies multiclass consistency

1383
01:40:15,670 --> 01:40:18,280
so also

1384
01:40:18,330 --> 01:40:21,710
so the square root is not great but

1385
01:40:22,690 --> 01:40:24,230
we subtract off this

1386
01:40:24,250 --> 01:40:25,440
this minimum

1387
01:40:25,450 --> 01:40:26,870
he says that

1388
01:40:26,930 --> 01:40:29,240
my we something pretty non-trivial

1389
01:40:29,290 --> 01:40:34,170
even when the and binary is point two five right so

1390
01:40:34,170 --> 01:40:35,650
it is point two five

1391
01:40:35,680 --> 01:40:37,290
twenty five

1392
01:40:37,350 --> 01:40:41,340
and this is zero mean is you must be doing

1393
01:40:41,390 --> 01:41:06,230
as well as anything

1394
01:41:07,690 --> 01:41:11,060
OK so

1395
01:41:11,120 --> 01:41:12,970
that's the same

1396
01:41:12,970 --> 01:41:16,430
in the course traditional try to prove it

1397
01:41:17,100 --> 01:41:20,480
the way to prove it is using the hadamard matrix

1398
01:41:20,530 --> 01:41:23,600
one way to prevent using hadamard matrix

1399
01:41:23,650 --> 01:41:26,340
the hadamard matrix has this property that

1400
01:41:26,390 --> 01:41:28,970
the distance between any two

1401
01:41:30,680 --> 01:41:32,940
is half of the number of rows

1402
01:41:39,860 --> 01:41:42,590
keep going

1403
01:41:42,700 --> 01:41:46,600
here i fast and so the recursive definition of the hadamard matrix

1404
01:41:46,610 --> 01:41:49,220
the way that it works recursively to take

1405
01:41:49,250 --> 01:41:50,320
in this game

1406
01:41:50,340 --> 01:41:54,950
stick and here and here and here and inverted sick here

1407
01:41:56,070 --> 01:41:57,650
and then take this guy

1408
01:41:57,700 --> 01:42:01,580
put it here and here and here in birds taken here

1409
01:42:03,560 --> 01:42:05,750
crazy last night

1410
01:42:05,790 --> 01:42:07,070
you gotta see this

1411
01:42:10,640 --> 01:42:17,040
it has patterns into it's it's very nice pattern

1412
01:42:17,090 --> 01:42:22,870
i i think i've actually seen this and drugs

1413
01:42:22,880 --> 01:42:24,050
never repeats

1414
01:42:24,060 --> 01:42:27,490
it's pretty cool

1415
01:42:27,530 --> 01:42:30,590
we could try everything he says

1416
01:42:30,650 --> 01:42:35,370
and it is using the software maybe lower learned

1417
01:42:35,420 --> 01:42:38,320
but i have little bits of it

1418
01:42:38,830 --> 01:42:47,200
i'm thinking that maybe very wary like this

1419
01:42:50,830 --> 01:42:56,790
here the hadamard matrix distance between any two columns is half the number of errors

1420
01:42:57,310 --> 01:43:02,210
let's let b be the number of rows over binary problems

1421
01:43:02,250 --> 01:43:06,580
the distance between any two codewords be over two

1422
01:43:06,600 --> 01:43:08,630
exactly b over two

1423
01:43:09,540 --> 01:43:12,650
that equality by the way is why reason hadamard

1424
01:43:12,680 --> 01:43:15,610
it it's actually quality

1425
01:43:15,690 --> 01:43:16,550
and then

1426
01:43:16,580 --> 01:43:18,250
we analyse this

1427
01:43:18,250 --> 01:43:20,460
OK so we're going to analysis

1428
01:43:20,470 --> 01:43:21,810
assuming that the

1429
01:43:21,830 --> 01:43:25,100
one in classifiers are perfect first

1430
01:43:25,150 --> 01:43:25,920
will do

1431
01:43:26,860 --> 01:43:30,470
imperfect case next

1432
01:43:30,470 --> 01:43:33,530
OK so assuming that are perfect

1433
01:43:38,980 --> 01:43:40,300
l one distance

1434
01:43:43,560 --> 01:43:45,180
by problems

1435
01:43:45,180 --> 01:43:47,210
of of of intelligence

1436
01:43:47,260 --> 01:43:52,180
the probability of a set containing here label

1437
01:43:52,190 --> 01:43:57,460
right probing is estimating the probability the labels in one set of the other

1438
01:43:57,470 --> 01:44:00,940
and if you know what that is

1439
01:44:00,950 --> 01:44:05,040
the only bits probabilistic estimate of that set

1440
01:44:05,140 --> 01:44:06,370
and that's thing that

1441
01:44:06,390 --> 01:44:09,240
this is actually pretty

1442
01:44:10,960 --> 01:44:12,450
you there

1443
01:44:12,510 --> 01:44:13,630
this some

1444
01:44:13,760 --> 01:44:15,870
for every label

1445
01:44:15,930 --> 01:44:19,080
the set containing

1446
01:44:21,120 --> 01:44:29,840
the probability that they will

1447
01:44:29,860 --> 01:44:34,290
and there's some sort of fancy switching of something going on here

1448
01:44:34,340 --> 01:44:35,530
you say look

1449
01:44:35,570 --> 01:44:39,020
whatever what reliable elder care about

1450
01:44:39,060 --> 01:44:42,020
it's going to my definition appearing every set

1451
01:44:42,020 --> 01:44:44,280
were were measuring the probability of

1452
01:44:47,120 --> 01:44:47,950
there's b

1453
01:44:47,950 --> 01:44:52,290
the set so we have b times the probability of that particular label

1454
01:44:52,340 --> 01:44:54,020
and every other label

1455
01:44:54,050 --> 01:44:55,560
appears half the time

1456
01:44:57,540 --> 01:44:59,320
because the difference between

1457
01:44:59,330 --> 01:45:04,680
comm does have

1458
01:45:04,750 --> 01:45:09,450
so the first half the time which means that

1459
01:45:10,360 --> 01:45:12,260
it happens half

1460
01:45:13,070 --> 01:45:15,320
the some of the other labels

1461
01:45:15,330 --> 01:45:17,800
the problem that label

1462
01:45:17,800 --> 01:45:22,480
and multiplying from the left that's why I call it the left nullspace

1463
01:45:25,100 --> 01:45:27,890
by making and putting it on the left I had to make it into a

1464
01:45:28,970 --> 01:45:31,080
instead of a column vector

1465
01:45:33,480 --> 01:45:39,250
my convention is I usually don't do that I usually stay with A transpose Y

1466
01:45:40,230 --> 01:45:44,690
OK and you might ask

1467
01:45:44,730 --> 01:45:47,970
how do we get a basis

1468
01:45:47,980 --> 01:45:52,910
or I might ask how do we get a basis for this for space this

1469
01:45:52,920 --> 01:45:57,260
left null space

1470
01:45:57,300 --> 01:45:59,290
OK under the example

1471
01:46:00,990 --> 01:46:04,330
as always I that

1472
01:46:04,680 --> 01:46:10,650
all right

1473
01:46:11,150 --> 01:46:15,190
the left null space is not jumping out at the hero

1474
01:46:17,800 --> 01:46:22,820
than I know which is a free for protect free variables the special solutions but

1475
01:46:22,820 --> 01:46:27,470
those special solutions to a x equals 0 and now I'm looking at A transpose

1476
01:46:27,470 --> 01:46:29,060
and I'm not saying here

1477
01:46:30,630 --> 01:46:36,190
but somehow you feel that the work that you did which simplified 82 art should

1478
01:46:36,190 --> 01:46:39,300
have revealed

1479
01:46:39,370 --> 01:46:41,950
the left null space to

1480
01:46:42,040 --> 01:46:44,950
and slightly less

1481
01:46:45,000 --> 01:46:47,190
immediate but it's there

1482
01:46:48,060 --> 01:46:50,480
from a to R

1483
01:46:50,520 --> 01:46:52,370
I took some steps

1484
01:46:52,520 --> 01:46:56,240
and I guess I'm interested in what were those steps

1485
01:46:56,300 --> 01:46:59,890
or what we call them together I don't I'm not interested in what

1486
01:47:00,990 --> 01:47:07,500
particular ones they were I'm interested in what was the whole matrix that took me

1487
01:47:07,500 --> 01:47:09,980
from 8 to

1488
01:47:10,840 --> 01:47:16,870
how would you find that

1489
01:47:16,910 --> 01:47:18,500
you remember gals Jordan

1490
01:47:19,510 --> 01:47:23,510
where attack on the identity matrix

1491
01:47:23,520 --> 01:47:27,910
that's do that again although it above here

1492
01:47:27,910 --> 01:47:29,180
so this is now

1493
01:47:30,140 --> 01:47:34,410
this is now this idea of

1494
01:47:34,410 --> 01:47:37,680
I take the matrix a

1495
01:47:37,750 --> 01:47:39,270
which is

1496
01:47:39,310 --> 01:47:46,390
In gas Jordan when we saw before a with a square invertible matrix and we

1497
01:47:46,390 --> 01:47:49,080
were finding its inverse

1498
01:47:49,140 --> 01:47:53,600
now the matrix is an square it's probably rectangular

1499
01:47:54,580 --> 01:47:58,410
I'll still tacked on the identity matrix and of course

1500
01:47:58,410 --> 01:48:02,290
since have length and it better be M by M

1501
01:48:03,110 --> 01:48:05,810
and now do

1502
01:48:05,850 --> 01:48:10,350
the reduced role echelon form of this

1503
01:48:16,060 --> 01:48:22,890
what I get back

1504
01:48:22,930 --> 01:48:27,980
the reduced row echelon form starts with these columns starts with the 1st columns works

1505
01:48:27,980 --> 01:48:32,850
like mad and produces are

1506
01:48:32,930 --> 01:48:36,850
Of course still the same size environment and we did before

1507
01:48:36,890 --> 01:48:37,930
and then

1508
01:48:38,430 --> 01:48:43,770
whatever it did to get our something else is going to show up here

1509
01:48:43,790 --> 01:48:45,020
and we call it the

1510
01:48:45,710 --> 01:48:47,870
in Miami

1511
01:48:47,930 --> 01:48:52,120
it's whatever you do you see that he just gonna contain a record of what

1512
01:48:52,120 --> 01:48:53,830
we did

1513
01:48:53,890 --> 01:48:59,370
we did whatever it took to get a need to become

1514
01:49:00,040 --> 01:49:05,620
and at the same time we were doing it to the identity

1515
01:49:05,640 --> 01:49:09,850
so we started with the identity matrix we buzzed along

1516
01:49:09,850 --> 01:49:11,700
so we took this is something

1517
01:49:11,720 --> 01:49:18,930
it all these roll reduce reduction amounted to multiplying on the left by some matrix

1518
01:49:18,970 --> 01:49:25,060
some series of elementary matrices that altogether gave us 1 matrix and that matrix is

1519
01:49:27,020 --> 01:49:30,200
so all reduction step

1520
01:49:30,220 --> 01:49:33,620
amounted to multiplying by how do I know that

1521
01:49:34,070 --> 01:49:37,910
it certainly amounted multiply by something

1522
01:49:37,950 --> 01:49:40,040
and that's something took on

1523
01:49:40,060 --> 01:49:42,930
so that something was

1524
01:49:43,100 --> 01:49:45,160
now look at the 1st part

1525
01:49:45,180 --> 01:49:50,900
e a is ah

1526
01:49:51,000 --> 01:49:51,620
no big deal

1527
01:49:52,450 --> 01:49:55,470
all I've said is

1528
01:49:55,480 --> 01:49:57,770
that v

1529
01:49:57,770 --> 01:50:01,020
role reduction steps that we all know well

1530
01:50:01,040 --> 01:50:03,930
taking data are

1531
01:50:04,220 --> 01:50:10,100
in some matrix and I can find out what that matrix is by just taking

1532
01:50:10,100 --> 01:50:13,060
ions and see what comes up

1533
01:50:13,100 --> 01:50:15,850
what comes out is the

1534
01:50:15,850 --> 01:50:17,180
but just review

1535
01:50:17,270 --> 01:50:19,620
the invertible square case

1536
01:50:19,640 --> 01:50:22,040
what happened there

1537
01:50:22,080 --> 01:50:25,600
because I was interested in chapter 2 also

1538
01:50:25,620 --> 01:50:28,020
when was square invertible

1539
01:50:28,080 --> 01:50:33,580
I took a I I did row elimination what what was the came out it

1540
01:50:33,580 --> 01:50:35,980
was I

1541
01:50:36,040 --> 01:50:40,140
so in chapter 2 in chapter 2

1542
01:50:41,070 --> 01:50:44,270
all our was not

1543
01:50:44,330 --> 01:50:51,330
the road with the reduced row echelon form of a nice invertible square matrix is

1544
01:50:51,330 --> 01:50:52,450
the identity

1545
01:50:53,020 --> 01:50:57,890
so if ah was Iike in that case then he was than he was

1546
01:51:02,770 --> 01:51:05,680
because he is

1547
01:51:06,600 --> 01:51:09,790
that's that was good and easy

1548
01:51:11,020 --> 01:51:14,270
what I'm saying is that there still is

1549
01:51:14,270 --> 01:51:19,060
it's not a inverse anymore because there is a rectangular hasn't gotten

1550
01:51:19,080 --> 01:51:22,040
but there is still some matrix eat

1551
01:51:22,470 --> 01:51:26,580
that this to this

1552
01:51:26,640 --> 01:51:29,580
0 I should have figured out in advance what it was

1553
01:51:29,830 --> 01:51:36,620
I didn't I did those steps in sort of erases I went

1554
01:51:37,550 --> 01:51:39,630
and the

1555
01:51:39,640 --> 01:51:42,790
I should have done them to the identity to accommodate the

1556
01:51:43,690 --> 01:51:47,470
can I do that cannot keep the identity matrix like I'm supposed to do and

1557
01:51:47,470 --> 01:51:50,300
at the level of what was delta y

1558
01:51:50,360 --> 01:51:52,090
minus the pressure

1559
01:51:52,200 --> 01:51:56,900
levelwise divided by delta y

1560
01:51:59,820 --> 01:52:02,720
it's that around so i bring this to the other side

1561
01:52:02,790 --> 01:52:05,090
equals minus

1562
01:52:07,520 --> 01:52:09,440
i was doing

1563
01:52:09,510 --> 01:52:11,630
and if i take the limiting case of this

1564
01:52:11,640 --> 01:52:14,710
for delta y goes to zero

1565
01:52:14,830 --> 01:52:16,770
then we will call this

1566
01:52:25,090 --> 01:52:26,760
and this tells you

1567
01:52:27,510 --> 01:52:30,550
when you go to increasing values of y

1568
01:52:30,610 --> 01:52:33,950
the pressure will go down to minus sign

1569
01:52:33,990 --> 01:52:37,140
very natural to go with decreasing values of y

1570
01:52:37,150 --> 01:52:38,720
the pressure

1571
01:52:38,800 --> 01:52:41,010
will go up and we call this

1572
01:52:41,050 --> 01:52:45,130
hi was static pressure

1573
01:52:51,560 --> 01:52:55,420
so it due to the fact that there is gravity

1574
01:52:55,430 --> 01:52:58,470
without gravity there is no hypothetical

1575
01:52:58,480 --> 01:52:59,920
almost fluids

1576
01:52:59,930 --> 01:53:01,450
most liquids

1577
01:53:02,110 --> 01:53:04,590
practically incompressible

1578
01:53:04,640 --> 01:53:07,170
in other words the density of

1579
01:53:07,180 --> 01:53:09,410
liquid cannot really change

1580
01:53:09,420 --> 01:53:10,720
so therefore

1581
01:53:10,730 --> 01:53:12,630
you could remove this

1582
01:53:12,680 --> 01:53:18,210
and simply always use the same density is exceedingly difficult takes renders the forces

1583
01:53:18,320 --> 01:53:20,410
pressures to change the density

1584
01:53:20,420 --> 01:53:22,180
over liquid unlike

1585
01:53:22,180 --> 01:53:24,440
the of gas gas is compressible

1586
01:53:24,450 --> 01:53:26,570
you can very easily change

1587
01:53:26,630 --> 01:53:32,020
the density of gas

1588
01:53:32,060 --> 01:53:33,770
so liquid

1589
01:53:37,410 --> 01:53:39,300
if i have here

1590
01:53:39,440 --> 01:53:42,160
this then and i have here

1591
01:53:43,690 --> 01:53:45,770
and i put in force on here

1592
01:53:45,810 --> 01:53:47,530
it would be impossible for me

1593
01:53:48,230 --> 01:53:49,310
make that

1594
01:53:49,320 --> 01:53:51,060
volume smaller even

1595
01:53:51,060 --> 01:53:53,330
by the fraction of a percent

1596
01:53:53,420 --> 01:53:56,440
it would be impossible if this however were gas

1597
01:53:56,490 --> 01:53:57,850
and will be very nice

1598
01:53:57,860 --> 01:53:59,320
for me to push that in

1599
01:53:59,380 --> 01:54:00,300
and two

1600
01:54:00,310 --> 01:54:03,740
change the volume of the small volume small and thereby

1601
01:54:03,760 --> 01:54:06,290
make the density of the gas go up

1602
01:54:06,380 --> 01:54:08,640
if i took a sledgehammer

1603
01:54:08,680 --> 01:54:09,830
and i would hit

1604
01:54:09,940 --> 01:54:12,400
plastic below

1605
01:54:12,440 --> 01:54:15,440
just saying that was fulfilled his heir

1606
01:54:15,540 --> 01:54:17,080
acts like a cushion

1607
01:54:17,090 --> 01:54:18,710
i could squeeze it

1608
01:54:18,770 --> 01:54:21,650
if i had the sledgehammer on the marble floor

1609
01:54:21,660 --> 01:54:24,300
i couldn't squeeze and the force

1610
01:54:24,340 --> 01:54:27,570
on the marble floor of the hammer will be way higher

1611
01:54:27,580 --> 01:54:32,190
because i don't have this caution action

1612
01:54:32,300 --> 01:54:35,040
if i take a break

1613
01:54:35,600 --> 01:54:37,210
we have one here

1614
01:54:37,230 --> 01:54:38,940
we have to

1615
01:54:38,980 --> 01:54:41,570
and this pain is fell to the brain

1616
01:54:41,760 --> 01:54:43,240
with water

1617
01:54:43,260 --> 01:54:44,550
and the other one

1618
01:54:44,560 --> 01:54:46,670
it's filled with air

1619
01:54:46,710 --> 01:54:48,840
and it was this last hammer

1620
01:54:48,900 --> 01:54:51,040
these acts like a caution

1621
01:54:51,050 --> 01:54:52,790
this one however

1622
01:54:52,820 --> 01:54:56,070
doesn't want the volume will decrease sort of force

1623
01:54:56,080 --> 01:54:59,610
like on the marble floor will be way higher

1624
01:54:59,680 --> 01:55:01,100
but remember

1625
01:55:01,160 --> 01:55:03,360
that force divided by area

1626
01:55:03,440 --> 01:55:05,900
expression and according to paul goal

1627
01:55:05,940 --> 01:55:07,900
the pressure

1628
01:55:07,910 --> 01:55:11,440
propagates on the minister in the whole through it

1629
01:55:11,480 --> 01:55:13,260
and so if i would

1630
01:55:13,310 --> 01:55:15,470
so the but still here

1631
01:55:15,530 --> 01:55:18,840
i get a huge force

1632
01:55:18,900 --> 01:55:21,280
extremely small area of the bullet

1633
01:55:21,300 --> 01:55:24,810
so the pressure inside the liquid will go up enormously

1634
01:55:24,860 --> 01:55:26,350
and the can might explode

1635
01:55:26,410 --> 01:55:30,710
provided that it's really filled to the brim with water because if there is an

1636
01:55:30,730 --> 01:55:34,410
left then you have this question action

1637
01:55:34,450 --> 01:55:38,260
i don't remember whether there's every year where this area in there

1638
01:55:38,340 --> 01:55:40,010
i'll leave you to decide

1639
01:55:40,020 --> 01:55:42,400
o five bought from this site

1640
01:55:42,440 --> 01:55:45,030
and then we'll see which can

1641
01:55:46,520 --> 01:55:48,730
and which does not

1642
01:55:48,840 --> 01:55:52,470
and the one that doesn't is the one that has ever in it

1643
01:55:52,480 --> 01:55:56,480
and the one that explodes

1644
01:55:56,590 --> 01:56:03,320
the water and it provided that we really feel that the brim

1645
01:56:05,570 --> 01:56:13,830
so something in the

1646
01:56:23,870 --> 01:56:27,200
i did something wrong it's OK

1647
01:56:27,260 --> 01:56:29,240
all right

1648
01:56:29,340 --> 01:56:33,510
because the bullet

1649
01:56:33,520 --> 01:56:35,320
OK ready for this

1650
01:56:35,380 --> 01:56:39,160
you tell me which can is filled with and which can is filled with

1651
01:56:39,240 --> 01:56:43,060
four three two one zero

1652
01:56:48,110 --> 01:56:49,460
this one is closest

1653
01:56:49,470 --> 01:56:52,180
as an ice hole i still there

1654
01:56:52,220 --> 01:56:55,080
this one has a whole year and hold a about

1655
01:56:55,140 --> 01:56:57,230
so sort of what we know which one

1656
01:56:57,290 --> 01:56:59,060
what i mean by the way

1657
01:56:59,100 --> 01:57:03,260
still there

1658
01:57:03,310 --> 01:57:04,670
these things are not so

1659
01:57:10,380 --> 01:57:12,380
i will assume from now on

1660
01:57:14,650 --> 01:57:17,440
i completely incompressible

1661
01:57:17,560 --> 01:57:20,110
in other words i can now use

1662
01:57:20,130 --> 01:57:21,920
this law that we have there

1663
01:57:22,030 --> 01:57:24,890
and they were very simple integration

1664
01:57:24,940 --> 01:57:27,010
i have now the

1665
01:57:27,100 --> 01:57:28,570
i can integrate

1666
01:57:28,630 --> 01:57:33,020
some value p one to p two

1667
01:57:37,580 --> 01:57:40,110
y two

1668
01:57:40,130 --> 01:57:41,740
what one

1669
01:57:41,790 --> 01:57:43,810
question one

1670
01:57:43,820 --> 01:57:45,930
in the liquid

1671
01:57:45,940 --> 01:57:47,630
and that equals now

1672
01:57:47,650 --> 01:57:50,440
minus rho g

1673
01:57:52,700 --> 01:57:54,400
and y one

1674
01:57:54,440 --> 01:57:58,320
right now it trivial the role because rho is constant rho is not a function

1675
01:57:58,320 --> 01:58:00,260
of y

1676
01:58:00,280 --> 01:58:02,670
with the atmosphere of the earth

1677
01:58:02,710 --> 01:58:07,190
that's more difficult because rho is a function of altitude the atmosphere not

1678
01:58:07,280 --> 01:58:08,430
with liquids

1679
01:58:08,490 --> 01:58:10,850
so we get the two

1680
01:58:10,940 --> 01:58:12,860
minus one

1681
01:58:12,980 --> 01:58:14,720
equals minus rho g

1682
01:58:14,780 --> 01:58:17,440
times y two

1683
01:58:17,540 --> 01:58:21,440
mine is why what is the scope of cultural

1684
01:58:21,450 --> 01:58:22,650
i prefer

1685
01:58:22,670 --> 01:58:24,640
right it's slightly differently

1686
01:58:24,680 --> 01:58:29,000
but it's the same thing i like sign your i which is around

1687
01:58:30,080 --> 01:58:32,920
and y two

1688
01:58:32,940 --> 01:58:36,880
why my one sort of means is i see immediately that if y two minus

1689
01:58:36,880 --> 01:58:38,140
one one

1690
01:58:38,180 --> 01:58:44,140
positive higher than this the pressure one is larger than the pressure to cause they

1691
01:58:45,620 --> 01:58:50,520
identical so this is the high dose radiation pressure

1692
01:58:50,580 --> 01:58:54,270
this has quite bizarre consequences

1693
01:58:54,330 --> 01:58:56,480
suppose i had a

1694
01:58:56,500 --> 01:58:59,140
the vessel that i filled with a liquid

1695
01:58:59,180 --> 01:59:01,440
how run change shape

1696
01:59:01,480 --> 01:59:03,000
like so

1697
01:59:03,050 --> 01:59:06,300
what is strange

1698
01:59:06,340 --> 01:59:08,230
i would feel it

1699
01:59:08,260 --> 01:59:14,240
we liquid this level

1700
01:59:14,260 --> 01:59:17,040
and the level years

1701
01:59:17,040 --> 01:59:20,320
so next time i give this talk it'll be in the right place and remember

1702
01:59:20,320 --> 01:59:24,220
we talked about all this stuff and we saw that we've got these things out

1703
01:59:24,220 --> 01:59:29,370
that looks sort of like topics human genome DNA genetic evolution evolutionary and so on

1704
01:59:29,440 --> 01:59:34,380
and we start with another article we had the the topic of high probability had

1705
01:59:34,410 --> 01:59:36,330
different words that co occur

1706
01:59:37,430 --> 01:59:41,600
so then i ask you to think about

1707
01:59:41,620 --> 01:59:43,930
why this happens

1708
01:59:43,980 --> 01:59:48,240
so does anybody think about that

1709
01:59:48,250 --> 01:59:50,490
the one person think about that

1710
01:59:50,500 --> 01:59:55,430
i am OK

1711
01:59:55,430 --> 01:59:58,640
it's not very well well-formed question

1712
01:59:58,690 --> 02:00:04,350
what i did these words come out that look like topics when we impose

1713
02:00:04,370 --> 02:00:09,100
these generative model this model

1714
02:00:09,110 --> 02:00:10,720
the first model

1715
02:00:31,250 --> 02:00:39,300
she why when we were in the vedas do we do we get this

1716
02:00:39,320 --> 02:00:41,040
these kinds of things out

1717
02:00:41,060 --> 02:00:42,300
he said co occurrence

1718
02:00:42,310 --> 02:00:49,320
within twenty min

1719
02:00:50,080 --> 02:00:54,260
yeah that's true

1720
02:00:54,550 --> 02:00:59,430
so this this has a lot to do with co occurrence why why would

1721
02:00:59,480 --> 02:01:03,240
why would the posterior distribution of the latent variables in this model

1722
02:01:03,250 --> 02:01:08,370
one place with high probability words that co occur

1723
02:01:09,280 --> 02:01:16,610
because say who who's talking i can see

1724
02:01:25,470 --> 02:01:26,750
OK that's

1725
02:01:26,760 --> 02:01:28,570
that's hopefully true

1726
02:01:28,720 --> 02:01:33,620
but we're just fitting this model to observed data

1727
02:01:34,510 --> 02:01:37,260
where have we

1728
02:01:37,280 --> 02:01:40,930
the what the question is that the simple question is

1729
02:01:40,940 --> 02:01:42,490
this is our model

1730
02:01:42,510 --> 02:01:48,280
and we've specified all of the distributions remember the dirichlet distribution here let's say that

1731
02:01:48,280 --> 02:01:52,330
there are dirichlet distributions here although don't worry about yet so much this is a

1732
02:01:52,330 --> 02:01:56,790
multinomial with parameter theta and this comes from looking up the

1733
02:01:56,830 --> 02:02:00,300
xe or z a topic in data

1734
02:02:00,310 --> 02:02:03,560
and drawing the word from that and so the question is why look at the

1735
02:02:03,560 --> 02:02:11,190
posterior of the latent variable, specifically the betas, why do co-occurring words have high probability

1736
02:02:11,200 --> 02:02:15,760
and so we're really just looking at the posterior we're at we have no future

1737
02:02:15,760 --> 02:02:19,190
data in our hands one would when we're making this computation

1738
02:02:19,200 --> 02:02:22,230
so maybe can you flesh out what what you mean

1739
02:02:25,310 --> 02:02:33,880
that's right that's right this of my higher point here my higher level point

1740
02:02:33,900 --> 02:02:35,350
it is

1741
02:02:36,580 --> 02:02:40,800
when you when you know i said the topic modeling really is just

1742
02:02:40,850 --> 02:02:44,680
case study of bayesian modeling with text

1743
02:02:44,730 --> 02:02:50,830
OK and when you're when you're engaging in the practice of bayesian modeling it's worth

1744
02:02:50,840 --> 02:02:52,420
thinking a little bit about

1745
02:02:52,460 --> 02:02:59,330
what you expect from the posterior or understanding why something is happening

1746
02:02:59,360 --> 02:03:02,910
trying to understand the least so

1747
02:03:02,930 --> 02:03:07,350
it's true that the bayesian machinery is working as expected and giving us the right

1748
02:03:07,800 --> 02:03:12,690
the things these these distributions over words but

1749
02:03:12,710 --> 02:03:13,890
i want to thank

1750
02:03:13,910 --> 02:03:18,700
again a little longer about why co occurring words come out of it

1751
02:03:18,710 --> 02:03:22,200
and i don't by the way i don't have an answer to i like my

1752
02:03:22,200 --> 02:03:26,170
answer but it's not i don't know three OK

1753
02:03:39,590 --> 02:03:51,560
OK so that so it has to do with word dependence

1754
02:03:52,680 --> 02:03:56,360
and that i see so that if two words come from the same topic then

1755
02:03:56,360 --> 02:04:00,770
they are dependent on each other and and co occurrence independence are somehow

1756
02:04:00,810 --> 02:04:03,220
are somehow linked

1757
02:04:03,280 --> 02:04:04,660
which they are

1758
02:04:08,790 --> 02:04:10,730
going from prior to

1759
02:04:11,050 --> 02:04:16,650
this is one of

1760
02:04:16,660 --> 02:04:23,560
this is not a power of one hundred

1761
02:04:29,180 --> 02:04:32,180
you this is too i missed last part i want to write down here thank

1762
02:04:32,180 --> 02:04:34,130
you said the last part again

1763
02:04:34,150 --> 02:04:35,790
so i

1764
02:04:35,800 --> 02:04:37,430
it was around this OK

1765
02:04:37,430 --> 02:04:41,060
i like are


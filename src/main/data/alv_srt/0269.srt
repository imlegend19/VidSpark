1
00:00:00,000 --> 00:00:06,640
for instance joint models in it in a way that is provably private there may

2
00:00:06,640 --> 00:00:11,520
be some opportunities in analyzing in the and the fact that we can analyse only

3
00:00:11,520 --> 00:00:16,910
small chunks of the data and still get globally relevant results and my hope is

4
00:00:16,910 --> 00:00:20,790
that that's going to provide some capabilities that if we could analyse as we do

5
00:00:20,790 --> 00:00:25,450
now small clusters of individuals to come up with a universally

6
00:00:25,500 --> 00:00:30,430
valid conclusions are at least conclusions that we feel comfortable generalizing the not to be

7
00:00:30,430 --> 00:00:34,720
possible to do analysis like that much in the same way that snow said we

8
00:00:34,720 --> 00:00:39,580
need to look at a few geographic districts to figure out whether whether drinking contaminated

9
00:00:40,350 --> 00:00:44,600
causes color i don't look at everyone in london

10
00:00:44,660 --> 00:00:50,350
we sometimes questions so just briefly some conclusions first i don't want to leave without

11
00:00:50,350 --> 00:00:53,040
telling you what happened in the end with john snow

12
00:00:53,100 --> 00:01:00,180
snow's analysis did not immediately convince the london board of health the miasma theory was

13
00:01:00,180 --> 00:01:05,680
flawed but within about a decade it was the predominant theory and snow's work was

14
00:01:05,680 --> 00:01:09,390
was represented and understood to be really quite groundbreaking

15
00:01:09,390 --> 00:01:16,370
it did fortunately at the time to convince people in his own neighborhood that they

16
00:01:16,370 --> 00:01:18,500
should remove the handle

17
00:01:18,520 --> 00:01:23,180
from pop which was the primary water supply for the neighborhood it's so well known

18
00:01:24,060 --> 00:01:27,850
in epidemiology circles and what

19
00:01:27,850 --> 00:01:29,950
not generally known

20
00:01:30,210 --> 00:01:35,180
that's not generally known is that first of all the cholera epidemic was winding down

21
00:01:35,330 --> 00:01:38,730
so many people have said oh well the prompted didn't really matter

22
00:01:39,350 --> 00:01:40,890
but also

23
00:01:40,910 --> 00:01:42,850
subsequent investigation

24
00:01:42,870 --> 00:01:49,730
identified a single household that had started the epidemic that had a sewer system that

25
00:01:49,730 --> 00:01:53,290
communicated directly with the water supply that part

26
00:01:54,640 --> 00:02:01,160
the day that the pump handle was removed another person in that household became ill

27
00:02:01,180 --> 00:02:05,520
with cholera and died several days later and so it's very likely if the panel

28
00:02:05,520 --> 00:02:12,140
had been removed the cholera epidemic would started all over again

29
00:02:12,160 --> 00:02:18,200
also just to conclude with the overall topic of the talk computational social science gives

30
00:02:18,200 --> 00:02:21,620
us some amazing opportunities to address important questions

31
00:02:21,640 --> 00:02:28,290
but also some really interesting i think research challenges moving from networks to analyzing whole

32
00:02:28,290 --> 00:02:33,660
social systems moving from looking at conditional patterns to joint models to take into account

33
00:02:33,660 --> 00:02:40,140
a wide variety of relational spatial and temporal information and moving from merely finding associations

34
00:02:40,140 --> 00:02:42,370
the fighting finding causal dependencies

35
00:02:42,560 --> 00:02:46,270
o also going to have to seriously engage with social scientists if we're going to

36
00:02:46,290 --> 00:02:49,930
do this kind of work and we're also going to have to take a more

37
00:02:49,930 --> 00:02:54,450
systematic approach trying to understand how to do this work in a way that preserves

38
00:02:56,850 --> 00:03:02,500
here's some people that i want to make sure i i acknowledge and some funding

39
00:03:02,500 --> 00:03:07,250
agencies provided generous support for this work and i would be happy to take questions

40
00:03:07,270 --> 00:03:16,750
thank you

41
00:03:16,830 --> 00:03:18,600
so you don't need for

42
00:03:19,160 --> 00:03:21,600
talk now for questions

43
00:03:21,680 --> 00:03:35,390
people ask questions if you could disrupt the microphone

44
00:03:35,410 --> 00:03:39,080
OK we be

45
00:03:39,230 --> 00:03:42,060
repeat the question

46
00:03:42,060 --> 00:03:44,700
he called

47
00:03:44,830 --> 00:03:52,680
and so i can hear you

48
00:03:59,770 --> 00:04:11,350
and the most promising

49
00:04:11,390 --> 00:04:20,390
special temporal reality and the difference is certainly in in time for all you know

50
00:04:20,390 --> 00:04:24,390
in the temple case was actually runs only one direction or

51
00:04:24,410 --> 00:04:28,290
at least in the physics we tend to think of you know at the at

52
00:04:28,290 --> 00:04:34,870
the macro level in last that physics works very differently than we think than than

53
00:04:34,980 --> 00:04:41,930
temporal information actually provides additional constraints on the possible causal models what is remarkable is

54
00:04:41,930 --> 00:04:45,680
that the work that has been done so far and causal discovery does not use

55
00:04:45,680 --> 00:04:49,910
temporal information it's amazing that we've been able to get as far as we have

56
00:04:50,180 --> 00:04:54,770
as well as a broad field by not explaining that kind of information because when

57
00:04:54,770 --> 00:04:59,370
social scientists go look causality that is absolutely one of the constraints that they they

58
00:04:59,370 --> 00:05:00,190
stable or unstable

59
00:05:01,500 --> 00:05:05,440
a little bit more unstable you this one also a little bit more unstable these

60
00:05:05,440 --> 00:05:06,350
ones are kind of in between

61
00:05:06,790 --> 00:05:09,020
so in a typical experiment we might show people

62
00:05:09,660 --> 00:05:14,040
but sixty different examples of these stacks ten blocks and the judge on a scale

63
00:05:14,040 --> 00:05:17,620
of one the seven how stable they are and then we build a model of

64
00:05:17,620 --> 00:05:20,350
what's going on in their head that looks just like what i showed you before

65
00:05:20,350 --> 00:05:23,040
r it i mean you could think about is one of these fancy kinds each

66
00:05:23,040 --> 00:05:26,790
man's but really what we've got is we've got some we are modelling that are

67
00:05:26,790 --> 00:05:28,350
saying they have some representation of the

68
00:05:28,960 --> 00:05:32,580
a be unable to not directly observable world state which is something like a cat

69
00:05:33,060 --> 00:05:34,270
description of these objects

70
00:05:35,430 --> 00:05:39,980
which they inferred with some kind of approximate bayesian inference from the image by inverting

71
00:05:40,080 --> 00:05:42,330
kind graphics simple graphics rendering model

72
00:05:43,140 --> 00:05:45,480
and then once you have actually description you can

73
00:05:45,890 --> 00:05:50,040
you can judge stability by just propagating forward something like a kind of a physics

74
00:05:50,040 --> 00:05:52,890
engine so so here using the way we actually build this

75
00:05:53,440 --> 00:05:57,330
this model people's mental models we use like simple game physics engines as there are

76
00:05:57,390 --> 00:06:03,000
no has probably pretty much everyone here knows fast and ready approximations to classical newtonian

77
00:06:03,910 --> 00:06:06,170
and so in this case you have these objects and you can say well now

78
00:06:06,290 --> 00:06:09,580
we turn on physics what happens well little fall in some pattern

79
00:06:10,390 --> 00:06:11,960
and because it's probabilistic

80
00:06:12,540 --> 00:06:13,670
this is just only one of

81
00:06:14,080 --> 00:06:17,980
a number of possible guesses right we can't where you the probabilities coming in various

82
00:06:17,980 --> 00:06:19,710
places but one place they come is that

83
00:06:20,120 --> 00:06:21,730
you can't exactly invert this

84
00:06:22,190 --> 00:06:25,890
this graphics model you can't from a single image guess exactly the

85
00:06:26,290 --> 00:06:27,440
it's certainly people can't

86
00:06:28,190 --> 00:06:31,690
exactly the precise data those three objects just from a quick glance to make some

87
00:06:31,690 --> 00:06:35,000
gas so here's another hypothesis of what underlying state could be and then you can

88
00:06:35,000 --> 00:06:37,210
run newtonian physics and then you get a different answer

89
00:06:38,060 --> 00:06:39,870
so in the particular models that we build

90
00:06:40,620 --> 00:06:44,410
uncertainty comes into these policies programs in just two places just keep it simple

91
00:06:44,930 --> 00:06:49,350
one is a state uncertainty that's the single parameter so how you know how much

92
00:06:50,170 --> 00:06:54,190
basically saying how precisely can you localize the objects the blocks from

93
00:06:54,770 --> 00:06:55,520
the image that you see

94
00:06:55,930 --> 00:06:59,890
and then there's some latent force uncertainty it's you know we put in certain basic

95
00:06:59,890 --> 00:07:04,230
forces into a physics engine like gravity and friction but we allow for the fact

96
00:07:04,230 --> 00:07:07,160
that could be other forces that you maybe you didn't know about like for example

97
00:07:07,160 --> 00:07:10,390
somebody could walk by not the table little better wind could blow

98
00:07:10,940 --> 00:07:14,520
in this first experiment that's not a big deal i'm rather we didn't tell anybody

99
00:07:14,520 --> 00:07:17,730
about forces so about parameter won't do anything but that's one of the things we

100
00:07:17,730 --> 00:07:18,730
can manipulate later on

101
00:07:19,390 --> 00:07:20,750
so here's an example of actually

102
00:07:21,160 --> 00:07:22,850
getting some predictive power of the small

103
00:07:23,690 --> 00:07:26,980
hand again i'm not going to go through the details experience but i'm gonna show

104
00:07:26,980 --> 00:07:30,210
you a bunch of scatterplots data because i want to emphasise how this is enabling

105
00:07:30,210 --> 00:07:35,710
us to make precise quantitative reverse engineering models these aspects of common sense which traditionally

106
00:07:35,710 --> 00:07:36,270
have not been

107
00:07:36,690 --> 00:07:38,460
the manifold quantitative analysis

108
00:07:39,080 --> 00:07:41,100
so in this plot here each

109
00:07:41,620 --> 00:07:45,500
each dot is one of these sixty towers and the model predictions are shown on

110
00:07:45,500 --> 00:07:47,600
the x-axis and people started from the axis

111
00:07:48,040 --> 00:07:50,910
and again what we're asking people the judges on a scale of one the seven

112
00:07:51,210 --> 00:07:54,980
how stable is this one is very unstable this one is judges very stable so

113
00:07:54,980 --> 00:07:56,000
those are two ends this

114
00:07:57,210 --> 00:08:01,620
and are basically ask are model same thing how does it work it just runs

115
00:08:01,620 --> 00:08:07,160
a few of these conditional simulations forming estimate the block posterior r but position because

116
00:08:07,460 --> 00:08:11,810
steering and propagating physics forward and then just inspects the output of the simulations to

117
00:08:11,810 --> 00:08:16,160
see just what fraction of the tower fell that's what gives us a quantitative measure

118
00:08:16,790 --> 00:08:20,020
and you can see that we do a pretty good job of capturing the the

119
00:08:20,020 --> 00:08:24,140
range a variation in people's inferences the correlation here is that is in the midpoint

120
00:08:24,160 --> 00:08:28,080
is about point five nonlinear correlation now there's parameters that we have to today but

121
00:08:28,080 --> 00:08:30,610
there's really only one parameter that has to be fit here which is that's state

122
00:08:30,610 --> 00:08:34,100
uncertainty because we have a model in detail how the visual system works

123
00:08:34,640 --> 00:08:38,830
and that's so that's in the parameter corresponds to you know a relatively small fraction

124
00:08:38,830 --> 00:08:40,480
of one as a small side of the block

125
00:08:41,940 --> 00:08:46,330
it's it turns out that that's actually very important fore modeling this if if you

126
00:08:46,560 --> 00:08:50,560
if you assume that people were able to localize the objects perfectly then it wouldn't

127
00:08:50,560 --> 00:08:51,330
fit nearly as well

128
00:08:53,580 --> 00:08:58,120
it certainly has some both by researchers and psychologists whenever we consider a very complex

129
00:08:58,120 --> 00:09:01,540
model like we're going to do probabilistic inference over a physics simulation

130
00:09:02,310 --> 00:09:06,910
we may also want to consider alternatives which a simpler approach is certainly in psychology

131
00:09:06,930 --> 00:09:10,520
many people would find it a little bit impossible this idea that you have something

132
00:09:10,520 --> 00:09:14,000
like a game physics engine in your head so we can consider many different simple

133
00:09:14,000 --> 00:09:17,310
heuristics that you could compute just on the images themselves are on some kind of

134
00:09:17,460 --> 00:09:21,770
geometric description without going to the dynamics like the height of the tower that something

135
00:09:21,770 --> 00:09:26,600
about the top heaviness various schemes i won't go into the details but i'll say

136
00:09:26,600 --> 00:09:28,690
that for a whole bunch of different judgments

137
00:09:29,140 --> 00:09:29,560
there are

138
00:09:30,040 --> 00:09:33,230
heuristics we can come up with which can do almost as well as these physics models

139
00:09:33,750 --> 00:09:36,430
but the key thing that shows you that you've really got some kind of intuitive

140
00:09:36,430 --> 00:09:40,270
theory or some kind of ability to run a rich physics simulation in your head

141
00:09:40,600 --> 00:09:43,190
is all the different kinds of things you can do with this model

142
00:09:43,580 --> 00:09:47,190
it's it's a kind overturning test if you like again it's kind of a core

143
00:09:47,190 --> 00:09:49,890
theme from today is lecture a kind of many train test

144
00:09:50,560 --> 00:09:54,930
here a bunch of questions that we that we got experiments i showed you one

145
00:09:54,930 --> 00:09:57,730
where the judgement is just you know will the tower fall but think about all

146
00:09:57,730 --> 00:10:01,160
the other questions you can ask about just this kind of stimulus so which way

147
00:10:01,160 --> 00:10:03,750
will the tower fall if it falls are how far will the blocks fall they

148
00:10:03,750 --> 00:10:05,350
go all the way over the table are just

149
00:10:05,830 --> 00:10:09,870
with this kind of crumble or suppose you bump the table so suppose you add another force now

150
00:10:10,560 --> 00:10:13,410
and you have blocks the different colours when you have more red or yellow blocks

151
00:10:13,670 --> 00:10:16,810
what if you bump this side the side or what if the blocks are different

152
00:10:16,810 --> 00:10:21,190
shapes and sizes or what about kind counterfactual reasoning adding the block of the thing

153
00:10:21,290 --> 00:10:24,770
fall off or what if we add other kinds of physical parameters like suppose the

154
00:10:24,770 --> 00:10:28,460
red blocks ten times heavier than yellow blocks what's gonna happen what turns out that

155
00:10:28,460 --> 00:10:28,710
we can

156
00:10:29,160 --> 00:10:31,600
we can do all these things here so for example we can

157
00:10:32,290 --> 00:10:37,250
we can get people to judge this is this is the actual snapshot of subject playing this little game

158
00:10:37,710 --> 00:10:39,480
where he simultaneously judging

159
00:10:39,960 --> 00:10:42,980
which way the blocks will fall and how far he didn't really get the direction

160
00:10:43,000 --> 00:10:44,940
very well but there was really a good answer

161
00:10:45,440 --> 00:10:49,930
consider this try this task in your head along with strider imagine which way the blocks are falling

162
00:10:50,690 --> 00:10:53,640
there's a little bit better trackers one more try before you see it

163
00:10:53,640 --> 00:10:55,450
so this logical expressions

164
00:10:55,470 --> 00:11:01,370
again we can have if then rules as we have discussed before

165
00:11:01,370 --> 00:11:05,250
and then no such a decision tree can be used for classification we we have

166
00:11:05,250 --> 00:11:11,110
a new weather situation like folksonomy temperature hard humidity high wing stock

167
00:11:11,120 --> 00:11:14,940
so what do we do we use the decision tree for classification

168
00:11:14,960 --> 00:11:18,290
if after his son we go here

169
00:11:18,320 --> 00:11:21,640
and then we look at humidity communities high

170
00:11:21,650 --> 00:11:28,110
we go here so the prediction will be that will not go to play tennis

171
00:11:28,150 --> 00:11:32,340
so decision tree learning

172
00:11:32,630 --> 00:11:33,890
we did

173
00:11:33,900 --> 00:11:38,310
this decision trees we want to classify new instances for which we don't know the

174
00:11:39,060 --> 00:11:43,570
into one of the discrete sets of possible categories and this is useful in medical

175
00:11:43,570 --> 00:11:48,840
diagnoses classifying low applicants and whatever other

176
00:11:48,860 --> 00:11:52,840
possible classification problem

177
00:11:52,850 --> 00:11:58,310
so how does the algorithm work and there are the data is

178
00:12:00,160 --> 00:12:02,950
has been developed in early

179
00:12:02,970 --> 00:12:09,520
in nineteen seventy nine that was the well known i these three algorithm developed by

180
00:12:09,520 --> 00:12:10,980
ross quinlan

181
00:12:11,020 --> 00:12:17,460
at the same time nearly there were statistically stations who have developed in nearly the

182
00:12:17,460 --> 00:12:22,600
same algorithm for decision tree learning but i'm who has developed

183
00:12:22,600 --> 00:12:23,940
britain cart

184
00:12:23,960 --> 00:12:29,440
and then these developments would further into the algorithm c four point five c five

185
00:12:29,460 --> 00:12:34,330
and they are also implemented in the wake of toolbox for data mining

186
00:12:34,980 --> 00:12:38,120
what do we do first we first create the route

187
00:12:38,140 --> 00:12:39,640
of the decision tree

188
00:12:39,640 --> 00:12:44,330
and then if all examples would be of the same class we wouldn't

189
00:12:44,350 --> 00:12:48,120
construct the c decision tree then we have stopped

190
00:12:49,250 --> 00:12:50,230
usually the

191
00:12:50,290 --> 00:12:52,980
examples are of different classes

192
00:12:54,120 --> 00:12:55,170
if not

193
00:12:55,190 --> 00:13:00,270
all the examples belong to the same class we select the most informative attributes we

194
00:13:02,310 --> 00:13:05,890
note with the club with the attribute names

195
00:13:05,940 --> 00:13:07,270
and then we split

196
00:13:07,290 --> 00:13:11,810
the set of examples into subsets according to the values of the attribute

197
00:13:11,830 --> 00:13:18,060
like that we have this this divide this training set into subsets and for each

198
00:13:18,060 --> 00:13:22,410
of these subsets we recursively build decision tree again

199
00:13:22,410 --> 00:13:28,410
at each step we again look whether all examples belong to the same class

200
00:13:28,460 --> 00:13:31,170
then we stop and label the the

201
00:13:33,060 --> 00:13:37,980
the node with the class labels and that becomes the leaf of the decision tree

202
00:13:37,980 --> 00:13:39,770
if not we split again

203
00:13:39,790 --> 00:13:45,480
so it is the so-called divide and conquer process in which we construct the decision

204
00:13:55,150 --> 00:14:11,210
logically logistic regression i think logistic regression doesn't have to deal with the class which

205
00:14:11,210 --> 00:14:14,420
is numeric attribute

206
00:14:15,370 --> 00:14:17,420
it is a binary

207
00:14:17,440 --> 00:14:24,040
OK so and the doesn't build the decision tree

208
00:14:24,100 --> 00:14:27,330
we get a ratio

209
00:14:27,350 --> 00:14:28,040
you know

210
00:14:35,020 --> 00:14:40,600
but then with the regression you typically have let's say values and then you have

211
00:14:40,600 --> 00:14:43,920
some coefficients and you do

212
00:14:43,920 --> 00:14:48,330
regression type of prediction

213
00:14:48,330 --> 00:14:53,290
so this would be the that the the main difference is here that you kind

214
00:14:53,290 --> 00:14:57,250
of split the set of all the instances into subsets

215
00:14:57,290 --> 00:14:58,920
until you have got

216
00:14:58,920 --> 00:15:03,230
clean subsets of instances so in terms of what you can use

217
00:15:04,250 --> 00:15:05,350
forty four

218
00:15:05,370 --> 00:15:06,390
it's the same

219
00:15:06,410 --> 00:15:10,600
so you can use it for prediction but the description you get from the two

220
00:15:10,600 --> 00:15:13,520
approaches is different

221
00:15:16,170 --> 00:15:18,920
it is to get the same

222
00:15:19,050 --> 00:15:23,060
the same result

223
00:15:23,080 --> 00:15:26,170
you can use it for the same purpose so the question is whether you will

224
00:15:26,170 --> 00:15:29,920
be able get the same classification refused the one or other

225
00:15:29,940 --> 00:15:34,460
so here the approach is that you would get this the

226
00:15:34,460 --> 00:15:37,730
i want to to have a look at

227
00:15:37,860 --> 00:15:42,510
particular application of logic

228
00:15:42,530 --> 00:15:43,840
and we're going to apply

229
00:15:43,850 --> 00:15:46,320
first order logic two

230
00:15:46,330 --> 00:15:49,920
reasoning about dynamic to make so what i mean by dynamic domains and domains in

231
00:15:49,920 --> 00:15:51,690
which we can have

232
00:15:51,730 --> 00:15:54,050
we have actions that at disposal

233
00:15:54,140 --> 00:15:57,640
and those actions change the environment in some way

234
00:15:57,660 --> 00:15:59,050
and we're gonna use

235
00:15:59,050 --> 00:16:01,210
first order logic for

236
00:16:02,510 --> 00:16:05,230
and furthermore i mean you

237
00:16:05,260 --> 00:16:08,230
you might have seen some other ways do so for instance you could use dynamic

238
00:16:08,980 --> 00:16:09,910
today is

239
00:16:09,910 --> 00:16:12,300
it is a whole lot of other different logics to do this

240
00:16:12,810 --> 00:16:17,040
some of this i'm guessing you probably have flavor from uses lecture

241
00:16:19,680 --> 00:16:21,180
i guess there is one

242
00:16:21,190 --> 00:16:24,090
at least one moral and i want to draw from

243
00:16:24,110 --> 00:16:25,310
this lecture

244
00:16:25,590 --> 00:16:27,810
i'm not going to give it away just yet have little might come as a

245
00:16:27,810 --> 00:16:29,050
bit of a surprise but

246
00:16:29,080 --> 00:16:32,690
the idea is that there's some moral to be taken here when you're going to

247
00:16:32,690 --> 00:16:36,340
use first order logic something in this case we can use it to

248
00:16:36,360 --> 00:16:39,850
reason about this dynamic system

249
00:16:39,960 --> 00:16:47,990
OK so it's like the point

250
00:16:47,990 --> 00:16:52,770
again i still a couple of slides from

251
00:16:52,850 --> 00:16:53,710
from the

252
00:16:55,010 --> 00:16:57,100
prec milbrooks textbook

253
00:16:57,660 --> 00:17:01,190
so one way to do this is the sort of strips way i think you

254
00:17:01,190 --> 00:17:05,130
see what covered street yesterday right

255
00:17:05,290 --> 00:17:08,960
so the basic idea is that when you perform an action you just have a

256
00:17:08,960 --> 00:17:10,410
knowledge base of facts

257
00:17:10,460 --> 00:17:13,040
if x ten you what true right now

258
00:17:13,100 --> 00:17:16,840
and the idea would be that you delete things that are no longer true and

259
00:17:16,840 --> 00:17:20,980
you add new things which things become true when you perform action

260
00:17:20,990 --> 00:17:23,070
so if i flicked the switch

261
00:17:23,130 --> 00:17:26,930
you know this which might have been in the down position it becomes no longer

262
00:17:26,930 --> 00:17:28,520
true so i deleted

263
00:17:28,690 --> 00:17:32,350
this which is now in the opposition so that becomes true and that to my

264
00:17:33,350 --> 00:17:38,240
and that's essentially the approach that strips takes two play

265
00:17:38,290 --> 00:17:42,270
but suppose we don't want to just talk about the current sort of state but

266
00:17:42,270 --> 00:17:45,450
we want to talk about states either in the past

267
00:17:45,490 --> 00:17:47,310
we visited previously

268
00:17:47,330 --> 00:17:50,650
all states in the future that we want to go to

269
00:17:50,710 --> 00:17:54,680
how can i do that

270
00:17:54,800 --> 00:17:59,210
so that's what we're going to have a look

271
00:17:59,300 --> 00:18:00,300
OK so

272
00:18:00,330 --> 00:18:02,120
let's try and actually

273
00:18:02,170 --> 00:18:04,200
let me go back to

274
00:18:04,310 --> 00:18:06,770
so then she by looking at the slides but

275
00:18:07,180 --> 00:18:12,050
as i suppose you've got this system that you want to describe and the thing

276
00:18:12,150 --> 00:18:16,180
is so we want to do is reason about the environment and what changes when

277
00:18:16,240 --> 00:18:18,370
when you do actions if pick up the cash

278
00:18:18,370 --> 00:18:21,050
i want to be able to describe you know what the environment looked like before

279
00:18:21,050 --> 00:18:25,770
it cup what looks like up become

280
00:18:25,770 --> 00:18:28,680
we need to write all this down in logic surprising i want to do this

281
00:18:28,680 --> 00:18:29,990
in first order logic

282
00:18:30,050 --> 00:18:34,300
so what what things we can write down

283
00:18:34,370 --> 00:18:36,990
i mean like specifically what things but what

284
00:18:37,020 --> 00:18:38,270
in general

285
00:18:38,310 --> 00:18:41,650
what sort of what sort of knowledge do we need to write down to do

286
00:18:41,650 --> 00:18:50,920
this task what i need to describe

287
00:18:51,050 --> 00:18:52,970
right stand

288
00:18:53,110 --> 00:18:57,330
right what's that's good as i don't want to necessarily get into the nitty gritty

289
00:18:57,330 --> 00:19:01,990
like positions of objects but positions of objects tell us something about one

290
00:19:02,270 --> 00:19:04,370
the environment state

291
00:19:04,420 --> 00:19:09,150
so we need to describe the state

292
00:19:09,200 --> 00:19:13,710
so that's first thing we need to do

293
00:19:13,720 --> 00:19:18,020
OK what else do we need to do

294
00:19:18,030 --> 00:19:20,550
every possible but in general like i'm going

295
00:19:20,560 --> 00:19:26,470
describe one state can describe we can describe all

296
00:19:27,100 --> 00:19:31,720
you could do that go i guess the goal to describe what god is perfect

297
00:19:31,770 --> 00:19:35,150
usually the goal i can say

298
00:19:35,150 --> 00:19:36,110
goals school

299
00:19:36,150 --> 00:19:39,860
what else we need to scrap

300
00:19:39,900 --> 00:19:41,150
actions right

301
00:19:43,120 --> 00:19:46,870
now he said something nice said like possible actions

302
00:19:46,970 --> 00:19:51,210
so when it comes actions what we need to say about actions

303
00:19:51,270 --> 00:19:53,400
you need to say when possible right

304
00:19:54,470 --> 00:19:55,650
we need to say

305
00:19:57,010 --> 00:20:00,440
so actions are a bit more complicated things because we need to sort of describing

306
00:20:00,440 --> 00:20:03,650
it when you cannot perform the action so for instance if

307
00:20:03,710 --> 00:20:06,130
if i include the cup to the table

308
00:20:06,140 --> 00:20:08,720
i go pick it up you know that that action is not possible because the

309
00:20:11,220 --> 00:20:18,400
what else do i need to know about actions

310
00:20:18,630 --> 00:20:23,850
what they do not just one

311
00:20:23,900 --> 00:20:29,590
anything else

312
00:20:29,650 --> 00:20:32,150
looks good to me

313
00:20:34,020 --> 00:20:37,080
OK initially what's to initial good

314
00:20:37,140 --> 00:20:39,830
you've done this before

315
00:20:39,880 --> 00:20:44,400
anything else

316
00:20:44,450 --> 00:20:47,080
OK this is what i put on

317
00:20:47,250 --> 00:20:49,280
said the state of the world

318
00:20:49,330 --> 00:20:54,220
actions that changes to the world and what changes they fit so what they do

319
00:20:54,270 --> 00:20:58,080
and you will see i didn't quite so there but we'll see them when they

320
00:20:58,220 --> 00:20:59,920
what when the possible

321
00:21:00,080 --> 00:21:07,110
in some cases you might want to describe constraints on legal scenarios so

322
00:21:07,140 --> 00:21:10,700
types of constraints might be for instance if i put my two cups together

323
00:21:10,710 --> 00:21:13,510
if i move this one then the other one comes along with so that might

324
00:21:13,510 --> 00:21:15,020
be constrained

325
00:21:16,270 --> 00:21:18,440
we're not going to talk to much about those constraints

326
00:21:18,470 --> 00:21:20,770
now he is the

327
00:21:20,900 --> 00:21:23,760
the question is what leads to the

328
00:21:23,770 --> 00:21:26,340
you know the the point that i want to make it in the lecture system

329
00:21:26,400 --> 00:21:29,750
got quite give you the answer to hopefully you see the light

330
00:21:30,580 --> 00:21:31,770
hands up

331
00:21:31,790 --> 00:21:33,630
if you think that this is

332
00:21:34,170 --> 00:21:41,270
sufficient this looks good

333
00:21:41,320 --> 00:21:43,920
OK if it doesn't look good why doesn't look good

334
00:21:43,940 --> 00:21:54,600
when he worried about

335
00:21:55,980 --> 00:21:59,780
that's a really good question but i guess at the moment i just want to

336
00:21:59,780 --> 00:22:05,070
reason about what's possible without reasoning about how might achieve something if i have a

337
00:22:05,910 --> 00:22:07,960
which is more what planning is about

338
00:22:08,400 --> 00:22:12,080
we can treat goals but we're not so worried about goals as saying well if

339
00:22:12,080 --> 00:22:14,850
i did this what would the world look like next

340
00:22:14,860 --> 00:22:19,070
so i don't really need to consider goals i just wanted to figure out

341
00:22:19,960 --> 00:22:22,940
and i personally think that's a good list

342
00:22:22,980 --> 00:22:25,090
and to me i would say that if i could

343
00:22:25,100 --> 00:22:27,170
describe all of these things in logic

344
00:22:27,200 --> 00:22:29,060
my job will be done i could

345
00:22:29,110 --> 00:22:32,340
say well if you told me that you execute executed this section followed by the

346
00:22:32,340 --> 00:22:34,650
section followed by the section i could

347
00:22:34,690 --> 00:22:38,630
OK in this study this would change this would change as we change in the

348
00:22:39,380 --> 00:22:41,500
i could tell you exactly what state

349
00:22:41,540 --> 00:22:43,280
looks like that you would end up

350
00:22:43,340 --> 00:22:45,310
that sort of my objective

351
00:22:45,330 --> 00:22:47,170
so i think this looks great

352
00:22:47,210 --> 00:22:51,340
and this looks good

353
00:22:51,350 --> 00:22:54,540
OK now what we're going to look at is this thing called the situation calculus

354
00:22:54,540 --> 00:22:57,810
in the situation calculus is just a particular

355
00:22:57,810 --> 00:23:01,190
one was on

356
00:23:01,200 --> 00:23:03,500
o one one o

357
00:23:11,350 --> 00:23:14,730
one one

358
00:23:14,740 --> 00:23:17,100
the one

359
00:23:19,560 --> 00:23:28,290
this year

360
00:23:44,430 --> 00:23:47,220
it would be

361
00:23:56,750 --> 00:24:01,100
o thing

362
00:24:30,980 --> 00:24:35,400
i like

363
00:24:54,100 --> 00:24:58,400
in the world

364
00:25:54,900 --> 00:25:57,430
very good

365
00:26:19,420 --> 00:26:22,320
in water

366
00:26:39,150 --> 00:26:44,630
being one of

367
00:27:00,570 --> 00:27:08,450
now you're you're you're

368
00:27:08,470 --> 00:27:10,880
all of them

369
00:28:35,770 --> 00:28:41,230
which leads me

370
00:28:41,230 --> 00:28:45,450
to cluster the data points and that we use k means is just for convenience

371
00:28:45,450 --> 00:28:49,220
we could use anything else but we just know came into that's what we do

372
00:28:50,770 --> 00:29:03,460
OK so i don't have a slide on this i guess somewhere now so one

373
00:29:03,460 --> 00:29:05,690
one big problem with k means is

374
00:29:05,710 --> 00:29:09,250
first of all it looks for classes which are on things right so if the

375
00:29:09,250 --> 00:29:12,630
the data set looks like this

376
00:29:12,650 --> 00:29:16,570
k means would probably put them in here but i mean you cut like this

377
00:29:17,330 --> 00:29:20,840
it doesn't work so spectral clustering does not make

378
00:29:20,860 --> 00:29:22,190
any assumptions

379
00:29:22,200 --> 00:29:25,850
like it doesn't make a strong modelling assumptions like asking is so in principle it

380
00:29:29,110 --> 00:29:33,090
in so spectral clustering the work very nicely on examples like that

381
00:29:33,140 --> 00:29:37,910
the second thing which is an advantage is that

382
00:29:37,920 --> 00:29:42,000
spectral clustering just also linear problem because this often i can the problem so there's

383
00:29:42,000 --> 00:29:43,210
nothing like

384
00:29:43,210 --> 00:29:47,330
we have a non convex optimisation problem we restart five hundred times and stop solution

385
00:29:47,330 --> 00:29:50,500
and one of the two thousand things to make sure we end up in local

386
00:29:50,500 --> 00:29:54,760
optimum which is or something close to the one we are interested

387
00:29:54,890 --> 00:29:57,820
but of course

388
00:29:58,500 --> 00:30:03,400
that's the because we i mean we just made the relaxation such that we end

389
00:30:03,400 --> 00:30:07,010
up with a linear problem so in principle we start with a very difficult problem

390
00:30:07,010 --> 00:30:09,650
and then relax so far that we just don't know what the the problem is

391
00:30:09,660 --> 00:30:13,230
just as one solution so they might get rid of it but it just turns

392
00:30:13,230 --> 00:30:14,530
out works

393
00:30:20,190 --> 00:30:21,940
this one

394
00:30:22,880 --> 00:30:26,590
one that i have

395
00:30:26,600 --> 00:30:29,630
so i mean it's actually OK

396
00:30:29,640 --> 00:30:34,720
so i don't want to say that spectral clustering is the only algorithm which can

397
00:30:34,720 --> 00:30:36,860
solve problems also

398
00:30:36,880 --> 00:30:39,940
i don't know if i don't say it's the best one it it's one of

399
00:30:39,960 --> 00:30:43,150
the islands and depending on what you want to do there might be many tests

400
00:30:43,150 --> 00:30:47,060
and we will see that i mean there's a huge variety of clustering algorithms

401
00:30:47,120 --> 00:30:51,390
i think they're just a few of them which model is working

402
00:30:51,410 --> 00:30:55,640
if you just need to apply them to the dataset they in many cases give

403
00:30:55,660 --> 00:31:00,840
reasonable results and k means and spectral clustering is one of the few communities might

404
00:31:00,840 --> 00:31:02,370
be another one

405
00:31:02,380 --> 00:31:07,860
so i don't i by no means i want to say that spectral clustering is

406
00:31:07,860 --> 00:31:11,630
better than anything else it's one of them but i mean i like it because

407
00:31:11,920 --> 00:31:16,870
but it's i mathematicians i'm mostly not working with real data it just like that

408
00:31:16,870 --> 00:31:20,530
it's very elegant writer and so on but i mean many people in practice also

409
00:31:20,530 --> 00:31:23,420
like it

410
00:31:28,880 --> 00:31:29,980
and this

411
00:31:37,300 --> 00:31:40,320
OK so i get so the question was whether it can happen that actually the

412
00:31:40,320 --> 00:31:43,750
data contains very clear clusters but after mapping in the

413
00:31:43,830 --> 00:31:47,970
in the spectral representation sort of messes up

414
00:31:47,990 --> 00:31:49,960
yes that can happen

415
00:31:50,040 --> 00:31:54,250
mainly it happens to choose from parameters and we'll talk about which parameters and so

416
00:31:54,250 --> 00:31:56,190
on to translate on

417
00:31:56,200 --> 00:31:59,670
it doesn't happen so easily so if you if you have a reasonable set of

418
00:32:01,250 --> 00:32:05,730
it usually doesn't happen but so i think spectral clustering is and i

419
00:32:05,790 --> 00:32:10,040
the data that's content clusters will usually find them but any other groups or to

420
00:32:10,040 --> 00:32:11,630
find the source of

421
00:32:11,660 --> 00:32:15,990
i mean that's usually not the pointer algorithms to further cases which are ambiguous and

422
00:32:15,990 --> 00:32:20,310
some of you might have just different models of what to do in those cases

423
00:32:20,330 --> 00:32:26,090
OK i really want to mention the second explanation

424
00:32:26,370 --> 00:32:30,670
but now i fear that not nearly nobody knows whether around market so i just

425
00:32:30,670 --> 00:32:32,760
want to give intuitions

426
00:32:34,190 --> 00:32:35,820
so we have to get more data

427
00:32:37,160 --> 00:32:42,910
so it looks like this

428
00:32:43,040 --> 00:32:44,460
so the random walk

429
00:32:44,480 --> 00:32:47,700
is a stochastic process which is which

430
00:32:47,710 --> 00:32:51,670
OK it's actually something which is very intuitive so you

431
00:32:51,700 --> 00:32:55,460
random walk is something to start with one vertex and then you randomly jump to

432
00:32:55,460 --> 00:32:56,680
another vertex

433
00:32:56,720 --> 00:33:00,340
and the way to see other vertex so you're allowed to jump to any other

434
00:33:00,340 --> 00:33:02,090
vertex which is connected to you

435
00:33:02,220 --> 00:33:06,840
original text the probability with which to jump from one vertex to the next depends

436
00:33:06,840 --> 00:33:08,880
on the weight so if we have like

437
00:33:10,410 --> 00:33:14,260
if the weights are normalized to have something like one-third here one

438
00:33:14,320 --> 00:33:15,330
and that's bad

439
00:33:15,340 --> 00:33:21,550
just make one for everyone on board so we started the vertex and then with

440
00:33:21,550 --> 00:33:25,460
probability one quarter jump to one of the neighboring vertices and we do that again

441
00:33:25,460 --> 00:33:28,410
and again so we start with one down to the next one then randomly jump

442
00:33:28,420 --> 00:33:32,200
to another one in this whole process is called random walk

443
00:33:32,210 --> 00:33:33,880
on the graph

444
00:33:33,890 --> 00:33:40,120
and random walks on the graph are so previously said that matrix is often can

445
00:33:40,120 --> 00:33:42,040
be a nice thing to explore

446
00:33:42,090 --> 00:33:46,280
or i can make this or whatever spectral graph theory to explore properties of graph

447
00:33:46,310 --> 00:33:47,960
invented often

448
00:33:49,880 --> 00:33:53,510
tools which can be very handy if you want to explore different properties of graphs

449
00:33:53,570 --> 00:33:56,500
so for example in clustering

450
00:33:56,560 --> 00:33:58,280
you could say

451
00:33:58,300 --> 00:34:03,000
OK i run random organising cellular to run very very long time

452
00:34:03,010 --> 00:34:06,690
and then you can't also has been any vertex

453
00:34:06,730 --> 00:34:10,120
or you can count how often the jump between two vertices

454
00:34:10,130 --> 00:34:11,830
something like that

455
00:34:11,920 --> 00:34:14,570
and so the intuition for random walks is often

456
00:34:14,590 --> 00:34:16,590
we want to find a cut through the graph

457
00:34:16,600 --> 00:34:19,810
that is that the random walk on one side of the cut it tends to

458
00:34:19,810 --> 00:34:21,500
stay on the side

459
00:34:21,510 --> 00:34:25,460
so that the random walk here and in most of the cases in runs around

460
00:34:25,490 --> 00:34:30,620
the cluster then OK occasionally it will jump to customer but then runs around in

461
00:34:30,620 --> 00:34:34,960
this class and doesn't jump back until i found itself later maybe terms but

462
00:34:35,000 --> 00:34:37,980
so we can use the random walk to

463
00:34:38,000 --> 00:34:41,690
you can you can sort of formalized clustering in terms of a random walk by

464
00:34:41,690 --> 00:34:43,950
saying i want that the

465
00:34:43,970 --> 00:34:47,960
clusters are objects such that the random walk stays inside them instead of hopping between

466
00:34:50,010 --> 00:34:54,780
and that's actually what has been observed for normalized spectral clustering

467
00:34:54,830 --> 00:34:57,250
so actually

468
00:34:57,280 --> 00:35:00,460
i don't want to go into the math but someone should get across what i

469
00:35:00,460 --> 00:35:02,760
mean so so

470
00:35:02,780 --> 00:35:06,330
by p a given b i mean the probability

471
00:35:06,340 --> 00:35:08,220
during group in group b

472
00:35:08,250 --> 00:35:11,310
and now you are and what makes one step

473
00:35:12,290 --> 00:35:15,380
then i want to compute the probability that after the step is it is in

474
00:35:15,470 --> 00:35:18,030
a way so i'm hearing be

475
00:35:18,050 --> 00:35:21,800
so what is the likelihood that after one step i am in

476
00:35:21,810 --> 00:35:25,590
now if somewhat average this the whole groups because i just don't look at individual

477
00:35:25,590 --> 00:35:28,110
points but the total

478
00:35:28,130 --> 00:35:30,700
and then you can show that

479
00:35:30,710 --> 00:35:35,510
the normalized cut like this creature and we wanted to optimise is exactly the same

480
00:35:36,830 --> 00:35:40,530
we look at the probability of a given b plus the probability of b given

481
00:35:40,530 --> 00:35:42,220
we we are in a

482
00:35:42,230 --> 00:35:45,860
and that only one to many that's the thing we want to minimize right so

483
00:35:46,100 --> 00:35:47,740
what this means is that

484
00:35:48,500 --> 00:35:51,740
instead of saying we want to minimize has been cut in the graph

485
00:35:51,750 --> 00:35:52,700
we could say

486
00:35:52,710 --> 00:35:54,590
we want to minimize

487
00:35:54,590 --> 00:35:58,230
this random walk expression may be just what i just as said we don't want

488
00:35:58,230 --> 00:36:00,760
to sound too often between the two

489
00:36:00,790 --> 00:36:02,490
and that's an intuition

490
00:36:02,510 --> 00:36:06,370
what it's all about intrusion so that's an intuition which helps me and other people

491
00:36:06,370 --> 00:36:10,940
probably don't get anything out

492
00:36:10,970 --> 00:36:16,040
OK so that's one more interpretation

493
00:36:16,090 --> 00:36:19,570
the other interpretation of has to do with random walks

494
00:36:19,810 --> 00:36:23,050
in terms of the commute distance saw

495
00:36:23,060 --> 00:36:27,480
the commute distance the first is a very elegant things so often you have the

496
00:36:28,700 --> 00:36:31,360
you given your data in form of a graph

497
00:36:31,450 --> 00:36:33,540
what you want to do is you want to

498
00:36:33,540 --> 00:36:37,620
a bit complicated that's actually very difficult to work out its it several pages of

499
00:36:38,190 --> 00:36:43,790
boring mathematics and you get an expression for the this mu four MU two are

500
00:36:43,790 --> 00:36:48,760
defined by this expression here this is the what's called the k th central moments

501
00:36:48,760 --> 00:36:54,310
of the distribution and this is the fourth and second central moment but anyway OK

502
00:36:54,310 --> 00:36:58,180
there so you have expressions for the bias and variance

503
00:36:58,190 --> 00:37:00,680
now for these two examples for the

504
00:37:00,690 --> 00:37:06,400
i mean and variance of a random variable it's relatively easy and obvious to just

505
00:37:06,400 --> 00:37:09,070
write down some function of the sample

506
00:37:09,190 --> 00:37:13,970
they can be used to estimate those parameters but we can do that in general

507
00:37:14,450 --> 00:37:17,470
sometimes the parameters that appear in in

508
00:37:17,480 --> 00:37:22,530
PDF might have some obscure interpretation and it will be at all obvious how to

509
00:37:22,900 --> 00:37:26,650
you know what function of the data can be used to estimate the values so

510
00:37:26,650 --> 00:37:27,860
we need to work

511
00:37:28,120 --> 00:37:30,820
general prescription procedure

512
00:37:30,840 --> 00:37:32,070
and in order to

513
00:37:32,160 --> 00:37:36,510
lead us to that i need to introduce a very important function called the likelihood

514
00:37:38,680 --> 00:37:45,060
suppose that we have done some measurements some some collection of individual measurements x one

515
00:37:45,060 --> 00:37:50,960
through x and of course that my my experiment right one experiment consists of observing

516
00:37:50,960 --> 00:37:52,560
that set of numbers

517
00:37:52,570 --> 00:37:55,810
and i can be model

518
00:37:55,820 --> 00:38:00,600
that outcome that set of outcomes has been described from a certain

519
00:38:00,660 --> 00:38:06,440
joint pdf f of x one through x n but suppose that this

520
00:38:07,310 --> 00:38:10,860
contains certain unknown parameters theta

521
00:38:12,070 --> 00:38:15,190
the idea is now to simply evaluate that function

522
00:38:15,200 --> 00:38:19,850
with the data that i obtained in my measurements and regard those measured values now

523
00:38:19,850 --> 00:38:21,710
as fixed

524
00:38:21,720 --> 00:38:26,670
and then this look at this function not as a function of x but as

525
00:38:26,670 --> 00:38:30,720
a function of the parameters and that's what i call it like the likelihood function

526
00:38:30,850 --> 00:38:34,650
it is essentially the same function as the joint pdf

527
00:38:34,670 --> 00:38:36,550
of the measurement

528
00:38:36,560 --> 00:38:40,610
but i do not regard it as a function of x i regarded as a

529
00:38:40,610 --> 00:38:43,560
function of the parameters

530
00:38:44,080 --> 00:38:49,220
so that's the likelihood function is an important special case which is the usual case

531
00:38:49,220 --> 00:38:52,820
in this type of problem that is that i have some pdf

532
00:38:52,840 --> 00:38:58,030
f of x for each value of x and i simply sample x number of

533
00:38:58,030 --> 00:39:05,160
times i have independent observations of x and each x is sampled from this pdf

534
00:39:05,160 --> 00:39:08,310
f x now we call what we said

535
00:39:08,320 --> 00:39:11,480
about independent random variables i think the first day a

536
00:39:11,490 --> 00:39:17,620
is that independence means that the joint pdf for all of the x values factorizes

537
00:39:17,640 --> 00:39:23,090
into the product of individual probabilities and so in that case the likelihood function would

538
00:39:23,090 --> 00:39:24,830
simply be given by the product

539
00:39:24,850 --> 00:39:29,890
over all elements of the data sample and here what i have the PDF four

540
00:39:29,890 --> 00:39:33,810
x each time evaluated with eye

541
00:39:33,870 --> 00:39:36,670
observed x value

542
00:39:36,690 --> 00:39:42,410
right so that's relatively simple to compute in a computer program obviously

543
00:39:43,140 --> 00:39:48,120
so now we have the likelihood function we can use that to two

544
00:39:48,150 --> 00:39:49,970
define a prescription

545
00:39:49,980 --> 00:39:52,670
four constructing estimators in the following way

546
00:39:52,680 --> 00:39:57,540
the idea is the following is that this is the parameter that i'm considering

547
00:39:57,580 --> 00:40:00,220
is is close to the true value

548
00:40:00,260 --> 00:40:03,770
then i expect that to give a high

549
00:40:03,790 --> 00:40:08,300
probability to to get data similar to the data that i actually found

550
00:40:08,310 --> 00:40:11,690
and i tried to illustrate here this here on the left hand plot

551
00:40:11,690 --> 00:40:15,360
but that's what i've done is i've generated some data points with a monte carlo

552
00:40:16,260 --> 00:40:19,020
according to accounts in distribution

553
00:40:19,030 --> 00:40:23,480
and take marks there on the x axis those represent the

554
00:40:23,570 --> 00:40:25,710
x values and

555
00:40:25,760 --> 00:40:30,900
for the true values of the parameters when i evaluate the likelihood function so the

556
00:40:30,920 --> 00:40:35,780
the function from the previous overhead i get a certain value typically by the way

557
00:40:35,780 --> 00:40:40,690
we don't report the likelihood function itself but rather the long it's more convenient to

558
00:40:40,690 --> 00:40:45,400
work with the logarithm of the likelihood function so you i happen to get log

559
00:40:45,400 --> 00:40:47,020
forty one

560
00:40:47,040 --> 00:40:51,480
that is actually very close to the if i try to adjust the value of

561
00:40:51,480 --> 00:40:56,120
the parameter so as to maximize the likelihood function is only a little bit higher

562
00:40:56,150 --> 00:41:01,560
OK so the point i want to make here is that the

563
00:41:01,570 --> 00:41:05,020
parameter which is true to the true parameter which is close to the true parameter

564
00:41:05,020 --> 00:41:07,860
values gives very high value for the likelihood

565
00:41:07,890 --> 00:41:11,900
one is it by the parameter far away from the true values of i try

566
00:41:11,920 --> 00:41:16,870
to shift the distribution over four if i try to make some distribution much broader

567
00:41:16,920 --> 00:41:22,410
than the true value then you get correspondingly lower values for the likelihood you can

568
00:41:22,410 --> 00:41:25,380
kind of see how that works from the formula because what you do is you

569
00:41:25,380 --> 00:41:28,920
you take each data point you evaluate the PDF

570
00:41:28,940 --> 00:41:30,590
and you take the product

571
00:41:30,800 --> 00:41:34,200
so here i evaluating higher number than i am saying

572
00:41:35,410 --> 00:41:42,540
so that's just motivation really what i don't want to say is the following definition

573
00:41:42,550 --> 00:41:43,910
we define

574
00:41:43,970 --> 00:41:49,830
the maximum likelihood estimators to be those values of the parameter or parameters

575
00:41:49,850 --> 00:41:53,570
for which the likelihood function is the maximum

576
00:41:53,580 --> 00:41:57,140
that seems like a very simple elegant statement and so you might be able to

577
00:41:57,140 --> 00:41:59,320
think that surely you can derive that's

578
00:42:00,370 --> 00:42:01,070
to be

579
00:42:01,080 --> 00:42:04,100
the correct estimator but it's not

580
00:42:04,170 --> 00:42:07,450
right there's is no there's no such thing as the correct estimator or the incorrect

581
00:42:07,550 --> 00:42:13,140
estimator i these maximum likelihood estimators are not guaranteed to have any

582
00:42:13,160 --> 00:42:16,410
optimal properties in fact in in practice they

583
00:42:16,440 --> 00:42:21,050
it very good properties in practice they are almost as optimal as you can get

584
00:42:21,440 --> 00:42:24,780
but that somehow nevertheless has to be taken as the definition

585
00:42:24,780 --> 00:42:27,190
you can make additional

586
00:42:28,260 --> 00:42:30,330
you can actually if you start the company

587
00:42:31,490 --> 00:42:32,990
micro computer

588
00:42:33,000 --> 00:42:34,840
the fact that you invest now

589
00:42:34,850 --> 00:42:40,050
four building it's another idea and so on open source you the option to actually

590
00:42:40,050 --> 00:42:42,320
do a second generation computer

591
00:42:42,330 --> 00:42:44,770
and that will open new scenario

592
00:42:44,820 --> 00:42:45,720
and so on

593
00:42:45,720 --> 00:42:47,690
scenarios have a probability

594
00:42:47,700 --> 00:42:50,340
which is significant of failing with zero

595
00:42:50,420 --> 00:42:53,990
again just cost but the fact that these are non-zero probability

596
00:42:53,990 --> 00:42:57,670
i can give actually gain that would be discounted back

597
00:42:57,760 --> 00:42:58,830
that's the real option

598
00:42:59,430 --> 00:43:01,570
opening opening

599
00:43:03,330 --> 00:43:06,490
was value and of course you can see that

600
00:43:06,500 --> 00:43:11,580
you can dream and these people were dreaming about the excessive riches

601
00:43:11,590 --> 00:43:12,530
that would come

602
00:43:12,550 --> 00:43:18,400
about due to the the evolution of the internet and could basically justify any prize

603
00:43:18,410 --> 00:43:22,650
that was actually the russian edition we have very good animals to rationalize things that

604
00:43:22,680 --> 00:43:26,490
we and to reconstruct stories after the fact

605
00:43:26,500 --> 00:43:34,170
especially story example that's a very nice example of of rationalization of which are now

606
00:43:34,170 --> 00:43:35,070
to be

607
00:43:36,320 --> 00:43:41,240
my own belief that it's all these arguments are correct it's simply a part time

608
00:43:41,240 --> 00:43:43,270
scale we know

609
00:43:43,310 --> 00:43:46,750
we know now that it takes time to actually exploded we can

610
00:43:46,760 --> 00:43:47,760
there's been

611
00:43:47,760 --> 00:43:52,260
but as for example in eighteen forty with the UK railway

612
00:43:52,280 --> 00:43:56,530
in the eighteen seventy with us railway system

613
00:43:56,560 --> 00:43:59,230
investors lost everything

614
00:43:59,230 --> 00:44:00,520
eventually actually

615
00:44:00,550 --> 00:44:02,220
let two extraordinary

616
00:44:02,230 --> 00:44:07,150
advantage in the country but it took some decades to actually get to fruition

617
00:44:07,260 --> 00:44:12,470
so i be continuing the discussion of the specific problem based on the fact that

618
00:44:12,470 --> 00:44:15,490
i want to stress here which is very interesting the fact that

619
00:44:15,520 --> 00:44:17,260
four inverse to

620
00:44:17,300 --> 00:44:21,260
that's interesting for an investor on the that's my

621
00:44:21,260 --> 00:44:25,700
the play a big role in all of that was studied and also the other

622
00:44:25,720 --> 00:44:28,990
historians of the study

623
00:44:29,020 --> 00:44:30,210
they come

624
00:44:30,260 --> 00:44:34,010
in a kind of second wave after the started see of

625
00:44:34,060 --> 00:44:35,060
good economy

626
00:44:35,250 --> 00:44:37,000
economic positions

627
00:44:37,010 --> 00:44:38,000
the come

628
00:44:38,030 --> 00:44:42,770
rather rather in form of herding investors

629
00:44:42,820 --> 00:44:47,530
i'm showing this quantitatively by showing you the net net

630
00:44:47,540 --> 00:44:50,550
capital flow influence in the US

631
00:44:50,580 --> 00:44:51,770
stock market

632
00:44:51,780 --> 00:44:54,260
going from four outside the country

633
00:44:54,270 --> 00:44:56,060
the forms of time

634
00:44:56,070 --> 00:44:57,540
now look at

635
00:44:57,550 --> 00:44:59,520
OK this is your baseline

636
00:44:59,540 --> 00:45:02,530
look at the acceleration of the inflow

637
00:45:02,540 --> 00:45:05,540
was of the order of you know of billions

638
00:45:05,560 --> 00:45:07,860
tens of billions

639
00:45:08,080 --> 00:45:11,580
two close to four hundred billion a year

640
00:45:12,420 --> 00:45:13,590
think of the

641
00:45:13,650 --> 00:45:17,120
the story of the importance of foreign investment

642
00:45:17,180 --> 00:45:21,000
it has been demonstrated very clearly in the asian crisis

643
00:45:21,010 --> 00:45:24,640
the above all in nineteen ninety four nineteen ninety seven

644
00:45:24,640 --> 00:45:30,150
is the story also behind the bubble community in nineteen twenty nine they showed you

645
00:45:30,240 --> 00:45:33,980
at the time the foreigners were europe and so on doing a lot of money

646
00:45:33,980 --> 00:45:37,830
in this new economy is the emerging market

647
00:45:37,890 --> 00:45:40,420
now if you go on and look at

648
00:45:40,440 --> 00:45:43,980
many bubbles and crashes this is one subset

649
00:45:44,000 --> 00:45:47,180
so we knew that we are dealing indeed with the

650
00:45:47,200 --> 00:45:50,940
repetitive phenomenon you just put together in different colors too

651
00:45:50,950 --> 00:45:53,900
i have some nice slide

652
00:45:53,920 --> 00:45:55,160
a different

653
00:45:55,210 --> 00:46:00,710
price trajectories that as i have translated in time so that they are all coincident

654
00:46:00,730 --> 00:46:03,950
on this graph in terms of the time of the crash which is not really

655
00:46:05,220 --> 00:46:07,070
all of these

656
00:46:07,090 --> 00:46:11,740
financial time series crashed this time and the time spent about a year and a

657
00:46:12,690 --> 00:46:15,860
and i just changed the order in a squeeze

658
00:46:15,890 --> 00:46:19,080
by some of the transformation the

659
00:46:19,150 --> 00:46:23,450
alternate which is of course always visible adjustment that i'm changing

660
00:46:23,640 --> 00:46:25,720
the monetary unit

661
00:46:26,460 --> 00:46:28,590
and i show here that these indeed

662
00:46:28,610 --> 00:46:32,270
some commonality at least visually between

663
00:46:32,290 --> 00:46:36,080
some of the crash is already discussed the others i did not discuss yet

664
00:46:36,250 --> 00:46:39,990
for example the crash in germany and the US

665
00:46:40,000 --> 00:46:41,680
associated with the

666
00:46:41,710 --> 00:46:46,680
russian before the devaluation of the ruble that we see not as an extension that's

667
00:46:46,680 --> 00:46:48,760
really linked with the global

668
00:46:50,000 --> 00:46:53,530
also this picture work for currency this is

669
00:46:53,540 --> 00:46:56,490
the above or if you like on the dalai lama community

670
00:46:56,490 --> 00:46:57,530
i mean

671
00:46:57,590 --> 00:47:01,050
maybe you would if you look at them you so i use that function

672
00:47:01,070 --> 00:47:04,440
but apparently not very many other people do because

673
00:47:04,450 --> 00:47:07,690
at this point somebody would have said hey we need that one

674
00:47:08,560 --> 00:47:10,190
all right

675
00:47:10,670 --> 00:47:16,300
now some people say oh why i do need that function

676
00:47:16,360 --> 00:47:19,980
i we get you messages to mailing list people complain all i can do my

677
00:47:19,980 --> 00:47:23,720
work because you don't you have provided for me this function

678
00:47:24,080 --> 00:47:29,200
OK well maybe you can write it and

679
00:47:29,690 --> 00:47:34,810
in a way that i was surprised to find that the overlap is very large

680
00:47:34,810 --> 00:47:37,240
but we're still missing you know some now

681
00:47:37,290 --> 00:47:40,930
i think that that's what happens is people do write the functions they need

682
00:47:40,930 --> 00:47:44,720
they care about the there and then

683
00:47:44,770 --> 00:47:47,560
i'm not surprised too much by the five hundred number and i'm not too worried

684
00:47:47,560 --> 00:47:49,380
about it i think that

685
00:47:49,440 --> 00:47:51,950
the idea that some group of people with

686
00:47:52,480 --> 00:47:56,130
decide what we have to go and knock out all of those functions and get

687
00:47:56,130 --> 00:48:00,920
them working so that people take us seriously and use our user software is kind

688
00:48:00,920 --> 00:48:01,830
of crazy

689
00:48:01,850 --> 00:48:05,070
so i'm not worried about it but i thought you should know that

690
00:48:05,170 --> 00:48:08,520
overlap is pretty big eight hundred functions is all functions i mean you do you

691
00:48:08,520 --> 00:48:10,670
can do some significant work with that

692
00:48:11,020 --> 00:48:14,270
but it's not for everyone

693
00:48:15,280 --> 00:48:18,870
there's octave forge in the package system we have so many other packages doing all

694
00:48:18,870 --> 00:48:20,060
kinds of things

695
00:48:20,250 --> 00:48:23,330
it's nice to have a tax system now because you can download it

696
00:48:23,510 --> 00:48:27,700
file and install it and it's all taken care of you don't have to decide

697
00:48:27,710 --> 00:48:29,520
or do i put these functions

698
00:48:29,550 --> 00:48:32,360
how do i install not just past what do i do

699
00:48:33,420 --> 00:48:37,590
the idea was also that octave forge which would become this huge sprawling

700
00:48:37,620 --> 00:48:42,030
collection of functions can be broken up into smaller pieces and distributed

701
00:48:42,060 --> 00:48:45,210
more i isolated

702
00:48:45,510 --> 00:48:49,660
could be

703
00:48:49,760 --> 00:48:51,270
you it's back

704
00:48:51,290 --> 00:48:53,700
OK well

705
00:48:55,170 --> 00:48:56,840
could be

706
00:48:56,860 --> 00:49:00,170
broken up into small pieces and

707
00:49:00,210 --> 00:49:01,710
maybe they could release

708
00:49:01,760 --> 00:49:05,600
individual packages on a different schedule than

709
00:49:05,620 --> 00:49:06,830
the entire

710
00:49:06,850 --> 00:49:10,920
collection of octave forge packages which was becoming hard to do

711
00:49:13,110 --> 00:49:16,710
parts of it would be ready for release but other parts were in and it

712
00:49:16,710 --> 00:49:20,220
was never never seem to be a time when all was ready to be released

713
00:49:20,220 --> 00:49:22,820
unfortunately it's really hasn't quite happened

714
00:49:22,850 --> 00:49:24,970
and and i'm hoping that it will

715
00:49:27,910 --> 00:49:30,880
if release management is what you like to do

716
00:49:30,920 --> 00:49:32,670
instead of documentation

717
00:49:33,450 --> 00:49:35,110
there's another job

718
00:49:35,160 --> 00:49:36,820
you can work on

719
00:49:37,350 --> 00:49:44,280
the next major release i i expect to see well but most of these things

720
00:49:44,280 --> 00:49:45,320
are actually done

721
00:49:47,450 --> 00:49:50,120
were released and then we'll find out what bugs are in

722
00:49:50,900 --> 00:49:55,950
so smart object oriented features i was another thing missing some people like to try

723
00:49:55,950 --> 00:49:57,030
to use that

724
00:49:57,040 --> 00:50:00,510
part of my life

725
00:50:01,780 --> 00:50:02,930
better looking

726
00:50:04,000 --> 00:50:08,520
open GL graphics they are open based graphics renderer is in the works but i

727
00:50:08,520 --> 00:50:11,180
don't think that's really going be ready for use by this time but it may

728
00:50:11,180 --> 00:50:15,240
be a sort of preview of what's coming in the future we plan is still

729
00:50:15,240 --> 00:50:18,160
the back-end for rendering graphs but it's not really

730
00:50:18,170 --> 00:50:21,310
it's not really built for doing what we're trying to use it for which is

731
00:50:22,090 --> 00:50:24,560
but the graph window on the screen

732
00:50:24,580 --> 00:50:27,050
you know the pretty pictures instead

733
00:50:27,060 --> 00:50:30,540
it's really you know it's a command line tool and so on and converting the

734
00:50:31,610 --> 00:50:33,650
handle graphics hierarchy

735
00:50:33,660 --> 00:50:35,200
in two

736
00:50:35,250 --> 00:50:37,240
calls to new plot is not

737
00:50:37,250 --> 00:50:38,680
particularly easy

738
00:50:39,000 --> 00:50:41,270
it doesn't work very well

739
00:50:43,770 --> 00:50:48,190
there's no single precision datatype if you want to save a little bit of memory

740
00:50:48,190 --> 00:50:52,440
improved array indexing this has always been that i implemented the original original re indexing

741
00:50:52,440 --> 00:50:57,010
stuff and i didn't do very good job so it was always slow and

742
00:50:57,020 --> 00:51:00,360
complicated and slow

743
00:51:00,400 --> 00:51:03,270
now you know it's his name is up here four times right

744
00:51:03,420 --> 00:51:05,840
he just showed up last

745
00:51:05,860 --> 00:51:08,240
february here january february

746
00:51:09,170 --> 00:51:14,540
this guy is another one i think he sleeps either OK and he

747
00:51:14,580 --> 00:51:19,080
these amazing is a lot of great work herself so

748
00:51:19,090 --> 00:51:24,200
he he he made it you know if you use malabar data types they don't

749
00:51:24,240 --> 00:51:27,490
actually lighter add subtract sixty four bit integer

750
00:51:28,250 --> 00:51:33,470
his his going to do that now which is good he he optimise expressions like

751
00:51:33,470 --> 00:51:36,630
a transpose a story transposed times b so that you

752
00:51:37,040 --> 00:51:40,710
you don't have to actually form the transpose of a in or before the multiplication

753
00:51:40,720 --> 00:51:46,720
he's doing that opposition he just recently added something on permutation matrix optimization so when

754
00:51:46,720 --> 00:51:51,670
not when you do something like diag of the vector not storing a bunch of

755
00:51:51,670 --> 00:51:54,680
zeros along with which is what i think about this

756
00:51:54,730 --> 00:52:02,510
and then i always there are additional improvements incompatibility because people always come and say

757
00:52:02,520 --> 00:52:05,330
OK i tried to my program and it didn't work

758
00:52:05,340 --> 00:52:07,850
many aspects

759
00:52:08,300 --> 00:52:11,910
but there's a lot left to do

760
00:52:11,920 --> 00:52:16,930
a lot of people seem to want to have an an interactive development environment they

761
00:52:16,930 --> 00:52:18,530
they want to be able to

762
00:52:18,620 --> 00:52:21,190
i have active when they started pop up

763
00:52:21,200 --> 00:52:23,170
graphical user interface and

764
00:52:23,180 --> 00:52:24,480
i don't understand why

765
00:52:24,500 --> 00:52:27,510
and you're out but they they wanted

766
00:52:27,940 --> 00:52:31,570
i mean these are people who are writing these are people who are either getting

767
00:52:31,570 --> 00:52:33,500
phd have phd

768
00:52:33,540 --> 00:52:37,740
you other smart people and they apparently are afraid of the problem

769
00:52:37,740 --> 00:52:39,580
i would ask them to type

770
00:52:40,990 --> 00:52:46,780
i'm not trying to do this my users but you know this this doesn't make

771
00:52:46,780 --> 00:52:48,540
a lot of sense to me but

772
00:52:48,570 --> 00:52:50,560
i can understand the

773
00:52:51,470 --> 00:52:55,680
it is convenient in way to have an interface that allows you to view the

774
00:52:55,680 --> 00:52:59,350
command history separate from having the typist

775
00:52:59,410 --> 00:53:00,970
but these are not to me

776
00:53:00,990 --> 00:53:04,870
major features means that really is i can put it over the top ring and

777
00:53:04,870 --> 00:53:09,910
take over the world because we have pain on the screen it has command history

778
00:53:09,910 --> 00:53:10,700
over here

779
00:53:10,790 --> 00:53:14,560
and the list of you know sometimes i think that if you if you just

780
00:53:14,560 --> 00:53:16,020
put up the window that said

781
00:53:16,110 --> 00:53:17,350
the that had

782
00:53:17,400 --> 00:53:19,070
file edit

783
00:53:19,100 --> 00:53:22,560
about are helper whatever you know that those three

784
00:53:22,610 --> 00:53:26,570
people say are going great now i can do now i can do i work

785
00:53:26,580 --> 00:53:31,120
things are more important to me are the graphics

786
00:53:31,130 --> 00:53:33,420
the profiler people always want to know

787
00:53:33,420 --> 00:53:36,010
which part of my code is spending the most time

788
00:53:36,020 --> 00:53:37,810
so that's really important to me

789
00:53:38,450 --> 00:53:42,240
some of really great to have a just-in-time compiler so we could improve the speed

790
00:53:44,280 --> 00:53:46,550
loops for loops are always bad

791
00:53:46,560 --> 00:53:48,060
you know very slow

792
00:53:48,080 --> 00:53:51,280
but this is the gigantic project so

793
00:53:51,330 --> 00:53:53,400
if you're a just-in-time compiler

794
00:53:54,800 --> 00:53:56,440
that's another job for you

795
00:53:56,440 --> 00:54:00,580
you know you don't like writing documentation are doing really smart and

796
00:54:00,810 --> 00:54:03,230
then you can do that would be great

797
00:54:03,270 --> 00:54:08,520
and but it if you're not of these things if you nice things interesting maybe

798
00:54:08,520 --> 00:54:11,490
you can tell a lot of people here too

799
00:54:12,330 --> 00:54:13,680
machine learning

800
00:54:13,680 --> 00:54:17,940
things like that so domain specific packages there's thing that you can do you can

801
00:54:17,940 --> 00:54:21,760
write some domain specific packages and make them available so

802
00:54:21,770 --> 00:54:25,870
so that improve active in that way active community in that way

803
00:54:25,870 --> 00:54:29,230
and you're so engaged with something that's going on your head you're on the way

804
00:54:29,890 --> 00:54:32,870
and your so wrapped up in some issues going on work you drive onto the

805
00:54:32,870 --> 00:54:35,170
from the path of your house is said

806
00:54:35,230 --> 00:54:37,160
get here

807
00:54:37,230 --> 00:54:41,270
you know that experience where time just goes by like that you're so engaged with

808
00:54:41,280 --> 00:54:45,430
the problem well when you create an environment like that people get into what they

809
00:54:45,430 --> 00:54:47,770
call flow it's like a resonance

810
00:54:47,830 --> 00:54:49,460
when they don't

811
00:54:49,460 --> 00:54:51,780
no this time go by

812
00:54:51,790 --> 00:54:56,430
where they actually enjoy their work where they engaged with the work and to engage

813
00:54:56,450 --> 00:54:57,990
with the leaders

814
00:54:57,990 --> 00:55:01,160
leaders who create that environment

815
00:55:01,170 --> 00:55:08,320
create an environment in which creativity thrives relationships are enhanced people work in flow productivity

816
00:55:09,320 --> 00:55:11,970
how do you do that in several ways

817
00:55:11,970 --> 00:55:16,470
if you're going to inspire people you better be able to communicate with them use

818
00:55:16,470 --> 00:55:18,110
the interesting thing

819
00:55:18,130 --> 00:55:21,550
the communication is not this sort of communication is not the i have been to

820
00:55:21,550 --> 00:55:26,200
the top of the mountain communication it's the quieter

821
00:55:26,200 --> 00:55:27,630
one on one

822
00:55:27,660 --> 00:55:29,920
interpersonal communication

823
00:55:29,940 --> 00:55:35,280
and i say that because you probably won't statistic are you would statistic

824
00:55:35,330 --> 00:55:40,360
this research done that says that the majority of people fear speaking in front of

825
00:55:40,370 --> 00:55:41,560
the group

826
00:55:41,580 --> 00:55:43,520
more than they fear death

827
00:55:43,520 --> 00:55:47,060
seen that they do the research every so often to give a list of things

828
00:55:47,630 --> 00:55:51,770
they ask people to rank in order of which they fear and always comes lower

829
00:55:51,770 --> 00:55:54,160
than speaking in front of a group of people

830
00:55:54,170 --> 00:55:58,220
and the implication of course is next time around the funeral

831
00:55:58,880 --> 00:56:03,810
this thing the guide up there making the eulogy would probably statistically prefer to be

832
00:56:03,810 --> 00:56:05,170
in the box

833
00:56:05,210 --> 00:56:10,050
rather than making the speech and i say this i say this point is important

834
00:56:11,560 --> 00:56:13,250
the sort of communication

835
00:56:13,290 --> 00:56:15,950
that is seen as being charismatic

836
00:56:15,960 --> 00:56:21,570
is really the one-on-one required communication what we remember well of course remember martin luther

837
00:56:21,570 --> 00:56:25,870
king's and john f kennedy is great speech makers we're really

838
00:56:25,890 --> 00:56:30,150
as they say in the states where the rubber meets the road we're really happens

839
00:56:30,150 --> 00:56:31,820
is one one

840
00:56:31,830 --> 00:56:35,690
i was in istanbul two or three weeks ago

841
00:56:35,700 --> 00:56:41,000
and i met a fascinating character in the the coffee break

842
00:56:41,010 --> 00:56:46,200
and his job was he was a freelance union negotiators

843
00:56:46,220 --> 00:56:50,580
OK so what but haney who was there with me called hired gun you know

844
00:56:50,580 --> 00:56:55,610
like a gunslinger and if you had a tough union negotiation you bring this guy

845
00:56:55,610 --> 00:56:57,910
and is very cynical really isn't

846
00:56:58,030 --> 00:57:01,480
you bring this guy and he does negotiation for you and he was that

847
00:57:01,840 --> 00:57:08,780
a guy with a legal background and humorist very interesting combination backgrounds very unassuming you

848
00:57:08,780 --> 00:57:12,170
didn't look at them say i can see where he would intimidate me in negotiation

849
00:57:12,340 --> 00:57:14,520
he didn't look like a heart as

850
00:57:14,520 --> 00:57:17,940
he he looks alright now said

851
00:57:17,950 --> 00:57:20,510
tell me about your job tell me about what you do

852
00:57:20,590 --> 00:57:23,500
and i give you the long after short version of his twenty minute version is

853
00:57:23,500 --> 00:57:26,510
that there are two phases in every negotiation to

854
00:57:26,550 --> 00:57:30,450
phase one they tell us what they're going to give my client

855
00:57:30,460 --> 00:57:33,700
extra productivity more hours more time whatever this

856
00:57:33,830 --> 00:57:35,050
phase two

857
00:57:35,060 --> 00:57:38,630
i tell them what my client is going to give them

858
00:57:38,640 --> 00:57:42,560
synthase two is the most important the most important thing the first thing i set

859
00:57:42,560 --> 00:57:43,970
out to do

860
00:57:44,000 --> 00:57:49,120
when i start phase two before anything else i want to get those negotiator so

861
00:57:50,190 --> 00:57:54,730
so crazy so angry and upset with me that they get up and kick the

862
00:57:54,740 --> 00:57:56,750
chair away and leave the room

863
00:57:56,780 --> 00:57:59,000
i want that to happen as soon as possible

864
00:57:59,050 --> 00:58:03,780
as early as possible i am one of them lower red in the face with

865
00:58:06,100 --> 00:58:07,030
as you know

866
00:58:07,200 --> 00:58:12,050
what's that i see are horrified faces i'm not subscribing to this i'm just reporting

867
00:58:12,280 --> 00:58:16,380
OK this is reported che can i see you know what what's the thinking is

868
00:58:16,380 --> 00:58:19,210
that they're going to come in and they're going to say i give you that

869
00:58:20,360 --> 00:58:22,940
and they're going to try and painted like it's size

870
00:58:22,950 --> 00:58:25,160
and i'm going to offer them that

871
00:58:25,160 --> 00:58:29,640
and he said all right let's suppose that you define as the measure of separation

872
00:58:29,680 --> 00:58:32,540
the difference between the two mean values

873
00:58:32,590 --> 00:58:36,390
divided by the sum of the two corresponding variances

874
00:58:36,430 --> 00:58:43,550
that's one possible definition of what you mean by having a large separation between two

875
00:58:45,660 --> 00:58:50,830
if you do that what the corresponding classifiers what's called the fisher discriminant and it

876
00:58:50,830 --> 00:58:53,350
this is this is widely used i'm sure you run into this in

877
00:58:53,370 --> 00:58:55,070
the analysis that you look at

878
00:58:55,110 --> 00:58:59,100
that leads to a linear

879
00:58:59,110 --> 00:59:02,130
decision boundary obviously i was going to give you a is going to the decision

880
00:59:02,130 --> 00:59:07,010
boundary will correspond to a hyperplane in this in dimensional space

881
00:59:07,010 --> 00:59:12,490
and there are few important cases where this decision boundary is in fact equivalent to

882
00:59:12,500 --> 00:59:17,520
the optimal decision boundary that you would obtain using the likelihood ratio

883
00:59:17,570 --> 00:59:20,170
the one that we would get from the neyman pearson lemma

884
00:59:21,290 --> 00:59:26,150
it is equivalent to the neyman pearson statistic if the signal and background pdfs happen

885
00:59:26,170 --> 00:59:28,590
to be a multivariate gaussians

886
00:59:28,650 --> 00:59:31,300
with equal covariance matrices

887
00:59:31,300 --> 00:59:32,310
so that's not

888
00:59:32,330 --> 00:59:34,220
it's not often going to be the case

889
00:59:34,280 --> 00:59:38,080
but it could be however that you might be able to a first transform your

890
00:59:38,080 --> 00:59:39,560
variables in such way

891
00:59:39,580 --> 00:59:42,200
that that criterion is at least approximately

892
00:59:43,810 --> 00:59:47,710
so it's not it's not that these things actually are quite useful you might be

893
00:59:47,710 --> 00:59:51,260
able to actually first transformed the variables in such way that it leads to the

894
00:59:51,260 --> 00:59:54,680
transformed variables they look like multivariate gaussians

895
00:59:54,910 --> 01:00:02,800
for which a linear decision boundary would work with work quite well

896
01:00:03,430 --> 01:00:07,390
in general however the optimal decision boundary will have to be some sort of the

897
01:00:07,410 --> 01:00:08,660
nonlinear things

898
01:00:08,670 --> 01:00:11,200
and this is this is the big industry and we don't have time to talk

899
01:00:11,200 --> 01:00:16,310
about this in these lectures much i gave a series of four lectures a few

900
01:00:16,310 --> 01:00:17,090
years ago

901
01:00:17,100 --> 01:00:20,310
on multivariate methods and i think the overheads are still on the web

902
01:00:20,310 --> 01:00:22,860
and it is if you look in those lectures you'll see a list of other

903
01:00:22,860 --> 01:00:27,270
references that you can find out more about

904
01:00:27,340 --> 01:00:31,560
these various strategies for constructing non-linear decision boundary

905
01:00:31,600 --> 01:00:35,120
you've probably heard of the number of the methods neural networks

906
01:00:35,130 --> 01:00:41,350
support vector machines kernel density density estimation methods things like boosted decision trees

907
01:00:41,390 --> 01:00:43,320
so these are all about

908
01:00:43,330 --> 01:00:47,370
with the exception of neural networks these are relatively modern innovations and

909
01:00:47,380 --> 01:00:53,740
and only in in the last few years have found wide application in particle physics

910
01:00:53,740 --> 01:00:58,390
in particular boosted decision trees for some reason have become extremely popular

911
01:00:58,400 --> 01:01:02,530
one of the reasons i think that these new methods have become popular is because

912
01:01:02,530 --> 01:01:09,460
there's new software available for particle physicists there's this program called TMVA to package

913
01:01:09,460 --> 01:01:11,110
it comes as part of route

914
01:01:11,130 --> 01:01:12,060
so t

915
01:01:13,200 --> 01:01:16,910
every package it has to start with the letter t right some rule

916
01:01:16,930 --> 01:01:20,760
and NVA stands for multivariate analysis and

917
01:01:20,770 --> 01:01:22,550
if you look at the problem sheet

918
01:01:22,600 --> 01:01:26,850
number seven that i mentioned on the the web page just at the beginning of

919
01:01:26,850 --> 01:01:30,580
the lecture that shows you a number of simple programs to show you how to

920
01:01:30,580 --> 01:01:31,920
set up TMVA

921
01:01:31,970 --> 01:01:36,410
and how to train a fisher discriminant or various other types of classifiers and so

922
01:01:36,410 --> 01:01:40,180
if you want to have a play with these multivariate methods and then that's the

923
01:01:40,180 --> 01:01:41,620
tool to use

924
01:01:41,720 --> 01:01:46,560
there's another also by the way this right up the describes the package is

925
01:01:46,570 --> 01:01:49,960
is good in two ways one it tells you how to run the program but

926
01:01:49,960 --> 01:01:54,720
in addition it describes the mathematics behind these different methods really in very readable way

927
01:01:54,780 --> 01:01:59,800
so i highly recommend this note that you can find in the archives

928
01:01:59,820 --> 01:02:04,850
there's another program called statpatternrecognition which is also very good and in many ways complementary

929
01:02:04,850 --> 01:02:05,910
to TMVA

930
01:02:05,920 --> 01:02:08,800
but i think the support for that piece of software is

931
01:02:08,810 --> 01:02:13,810
is is no longer is no longer being supported

932
01:02:13,830 --> 01:02:17,290
it might regain some support sure

933
01:02:17,290 --> 01:02:22,010
for many years amongst those those multivariate methods for many years the only sort of

934
01:02:22,010 --> 01:02:24,570
modern one that was in vogue in

935
01:02:24,610 --> 01:02:27,890
particle physics was the neural network so let me at least give show you an

936
01:02:27,890 --> 01:02:29,870
example of the neural network

937
01:02:29,920 --> 01:02:33,810
if you consider one of the things that we looked at the philip two program

938
01:02:33,810 --> 01:02:35,260
in the nineteen nineties

939
01:02:35,310 --> 01:02:39,340
was the reaction epoxy minus goes to w plus w minus

940
01:02:39,460 --> 01:02:44,200
and one of the cases is that each of the w bosons can decay into

941
01:02:44,210 --> 01:02:45,730
cork anticor

942
01:02:45,860 --> 01:02:48,000
if that happens you get four jets

943
01:02:48,010 --> 01:02:49,850
of hadrons coming out

944
01:02:49,900 --> 01:02:52,160
so we want to select events of that sort

945
01:02:52,210 --> 01:02:55,700
and then use them for further study we wanted to study the properties of the

946
01:02:55,700 --> 01:02:59,500
w boson and measure its mass and invariance properties

947
01:02:59,550 --> 01:03:04,770
now unfortunately that's not the only way you can get four jet events in epoxy

948
01:03:04,780 --> 01:03:08,790
minus collisions you can have the policy minus goes to cork county cork

949
01:03:08,840 --> 01:03:13,270
and then two more gluons get radiated and if that happens you also get four

950
01:03:14,570 --> 01:03:17,980
but on average the gluon jets tend to have sort of a smaller angle with

951
01:03:17,980 --> 01:03:21,710
respect to one of the core jets just the sort of distribution of energy and

952
01:03:21,710 --> 01:03:27,530
angles of the jets is different depending on which hypothesis i'm talking about

953
01:03:27,570 --> 01:03:31,330
so what we did is we cooked up a number of different variables that somehow

954
01:03:31,330 --> 01:03:33,950
allowed one to discriminate between

955
01:03:34,000 --> 01:03:38,830
the two hypotheses and they all have funny names like sri city and planarity in

956
01:03:38,840 --> 01:03:40,590
thrust and so forth

957
01:03:40,610 --> 01:03:45,020
and and here's what the distributions would look like for WWE events

958
01:03:45,020 --> 01:03:49,780
and the open histograms the the white histogram is what you get for the QQ

959
01:03:49,780 --> 01:03:54,090
gg events the other hypothesis and you can see that for any one of these

960
01:03:54,090 --> 01:03:55,960
variables if you had to make cuts

961
01:03:56,020 --> 01:04:00,850
you not get a very clean separation between the different classes of events

962
01:04:00,870 --> 01:04:04,960
so what we did is we used these as the input to a neural net

963
01:04:05,810 --> 01:04:10,060
and that works better that somehow give you a better separation

964
01:04:10,070 --> 01:04:14,280
so in any event to find out more about the mathematics of neural networks

965
01:04:14,300 --> 01:04:17,880
and all these other techniques i have to refer you to

966
01:04:19,110 --> 01:04:22,860
if the lectures i mentioned earlier or this right up here

967
01:04:22,870 --> 01:04:24,830
i think we'll have time to go into those

968
01:04:28,200 --> 01:04:32,150
OK let me go on to another aspect of statistical tests

969
01:04:32,210 --> 01:04:34,100
that is the following

970
01:04:34,130 --> 01:04:37,130
so a statistical test as i defined up to now

971
01:04:37,140 --> 01:04:40,680
it was simply a partition in the data space and depending on which

972
01:04:40,740 --> 01:04:42,260
side of that partition

973
01:04:42,270 --> 01:04:45,660
the data is observed you either accept or reject

974
01:04:45,720 --> 01:04:47,460
a given hypothesis

975
01:04:47,510 --> 01:04:51,410
but now suppose i simply say look i have a hypothesis

976
01:04:52,320 --> 01:04:55,540
it predicts a certain distribution for the data

977
01:04:55,580 --> 01:05:00,320
for some set of observations and now i make my observation i observe a single

978
01:05:00,320 --> 01:05:04,140
this processes which we call to station

979
01:05:04,160 --> 01:05:09,280
giving the excess energy into the lattice in the form of heat so we lose

980
01:05:09,350 --> 01:05:10,990
this energy

981
01:05:13,680 --> 01:05:16,100
photon energy into electricity

982
01:05:16,120 --> 01:05:20,370
and when we have a photon that has an energy less than the band gap

983
01:05:20,370 --> 01:05:21,690
then of course the

984
01:05:21,690 --> 01:05:24,800
let's excited electron cannot reach

985
01:05:24,820 --> 01:05:28,340
the allowed energy states so it falls down

986
01:05:28,350 --> 01:05:30,680
and this photo is not absorbed

987
01:05:30,680 --> 01:05:34,510
so we have two processes one is non absorption

988
01:05:35,540 --> 01:05:38,520
photons that has lower energy

989
01:05:38,560 --> 01:05:45,200
the band gap of the semiconductor and internalisation so actually losing the excess energy of

990
01:05:45,200 --> 01:05:46,370
the photon

991
01:05:46,390 --> 01:05:48,470
which is larger than the band gap

992
01:05:48,470 --> 01:05:49,930
and these two

993
01:05:49,940 --> 01:05:57,490
process is already accounted for about fifty five percent loss in conversion efficiency

994
01:05:57,710 --> 01:06:00,700
and we call these spectral mismatch

995
01:06:00,750 --> 01:06:03,300
between the band gap of the semiconductor

996
01:06:03,320 --> 01:06:08,590
and the spectral distribution of the radiant source that i was discussing at the beginning

997
01:06:08,590 --> 01:06:10,030
of this lecture

998
01:06:10,040 --> 01:06:13,190
so just due to the spectral

999
01:06:14,520 --> 01:06:15,640
we are losing

1000
01:06:15,660 --> 01:06:19,540
a lot of energy

1001
01:06:19,880 --> 01:06:25,120
now the transport i already mentioned that we have two mechanisms one is three

1002
01:06:25,130 --> 01:06:27,940
and one is

1003
01:06:29,980 --> 01:06:31,320
so you see

1004
01:06:31,340 --> 01:06:35,500
this is schematically using the band diagram

1005
01:06:35,510 --> 01:06:40,240
visualize the drift

1006
01:06:40,260 --> 01:06:41,520
and again

1007
01:06:41,530 --> 01:06:43,010
one important thing

1008
01:06:43,050 --> 01:06:46,010
when you look at the ben diagrams

1009
01:06:46,010 --> 01:06:47,200
up till now

1010
01:06:47,220 --> 01:06:50,330
these lines were straight

1011
01:06:50,750 --> 01:06:53,740
now you see that they have a certain slope

1012
01:06:53,780 --> 01:06:57,060
whenever you see have been diagram

1013
01:06:58,560 --> 01:06:59,770
let's say the

1014
01:07:00,950 --> 01:07:06,360
of the conduction band the minimum energy level of the conduction band and the maximum

1015
01:07:07,160 --> 01:07:10,830
of the valence band not straight lines but

1016
01:07:10,870 --> 01:07:13,310
there is some slope or shift

1017
01:07:13,330 --> 01:07:18,210
that means that you have electrical field in that area of

1018
01:07:18,260 --> 01:07:21,190
semiconductor or device

1019
01:07:22,140 --> 01:07:24,610
so when we talk about grief

1020
01:07:24,660 --> 01:07:25,770
it means

1021
01:07:25,770 --> 01:07:30,480
that's the motion of these particles in electric field

1022
01:07:30,490 --> 01:07:33,100
and you can see it by

1023
01:07:33,120 --> 01:07:34,800
looking at the

1024
01:07:36,390 --> 01:07:38,450
of these energy levels

1025
01:07:38,520 --> 01:07:43,530
it was then there is a slope there is electric field in this area of

1026
01:07:43,530 --> 01:07:46,060
the material or the device

1027
01:07:46,080 --> 01:07:49,240
very simple once you look at band diagram

1028
01:07:49,240 --> 01:07:53,060
and you do not see straight line you know in that part of the device

1029
01:07:53,340 --> 01:07:54,990
i have electric field

1030
01:07:55,030 --> 01:07:58,780
and then the carriers have to move by drift

1031
01:07:58,830 --> 01:08:04,600
and of course we can calculate so-called drift current which depends on the concentration mobility

1032
01:08:04,620 --> 01:08:05,510
and the

1033
01:08:05,530 --> 01:08:08,810
think of the electric field times

1034
01:08:08,850 --> 01:08:15,350
the unit of charge mobilities very important parameter i mentioned already

1035
01:08:15,380 --> 01:08:21,120
and the mobility depends on the phonon scattering so actually the vibrations of the lattice

1036
01:08:21,140 --> 01:08:26,990
then of course you can understand that when reading introduces impurities like doping items the

1037
01:08:26,990 --> 01:08:28,990
ionized them so they become

1038
01:08:29,950 --> 01:08:35,330
and of course this charge influences the movement of the particles when it is positively

1039
01:08:35,330 --> 01:08:36,930
charged it will somehow

1040
01:08:36,990 --> 01:08:44,430
attract electrons that move around and is negatively charged will somehow attract holes so then

1041
01:08:44,430 --> 01:08:48,760
we have a scattering these ionized impurities

1042
01:08:53,470 --> 01:08:55,780
you know the diffusion is the process

1043
01:08:55,800 --> 01:09:02,120
whereby particles tend to spread out from regions of high particle concentration into regions of

1044
01:09:02,120 --> 01:09:04,260
low particle concentrations

1045
01:09:06,950 --> 01:09:10,220
this process takes place

1046
01:09:10,220 --> 01:09:13,890
we understand

1047
01:09:13,930 --> 01:09:18,300
why when i say here we have ten to twenty

1048
01:09:19,580 --> 01:09:21,410
and here ten ten to ten

1049
01:09:21,430 --> 01:09:27,260
after some time we have ten to fifteen everywhere

1050
01:09:27,280 --> 01:09:28,850
OK but

1051
01:09:28,890 --> 01:09:30,370
that that's that

1052
01:09:30,410 --> 01:09:32,780
that's of course the force but

1053
01:09:32,830 --> 01:09:37,640
what is the mechanism behind it

1054
01:09:37,660 --> 01:09:39,450
so why they tend to go

1055
01:09:39,450 --> 01:09:42,540
that direction and all the other direction

1056
01:09:47,950 --> 01:09:49,620
but now

1057
01:09:49,620 --> 01:09:55,190
imagine we have a neutral particles so even though we have electric field the neutral

1058
01:09:56,310 --> 01:09:59,930
do not feel the electric field but still

1059
01:09:59,970 --> 01:10:02,620
they can diffuse

1060
01:10:03,330 --> 01:10:06,100
what is the motion

1061
01:10:06,680 --> 01:10:07,830
why today

1062
01:10:07,830 --> 01:10:12,010
not stay there fixed or fixed without motion

1063
01:10:12,060 --> 01:10:14,410
again we have this term emotions

1064
01:10:14,560 --> 01:10:18,680
as i was discussing was the vibrations of the lattice

1065
01:10:18,680 --> 01:10:20,410
not only

1066
01:10:20,430 --> 01:10:22,780
say the eight times

1067
01:10:22,780 --> 01:10:25,180
vibrate due to terminal

1068
01:10:25,240 --> 01:10:26,700
motion but also

1069
01:10:26,720 --> 01:10:28,310
these particles

1070
01:10:29,410 --> 01:10:32,660
there is still some kind of cultic

1071
01:10:32,720 --> 01:10:34,060
the movement

1072
01:10:34,100 --> 01:10:36,950
and of course this goes in all directions

1073
01:10:37,080 --> 01:10:39,030
but the ones i have

1074
01:10:39,100 --> 01:10:46,080
larger concentration than larger part due to the scouting movement will move in one direction

1075
01:10:46,080 --> 01:10:48,390
here then from this

1076
01:10:48,390 --> 01:10:50,810
small concentration here

1077
01:10:50,830 --> 01:10:52,260
so finally

1078
01:10:53,060 --> 01:10:55,700
two these celtic term motion

1079
01:10:55,720 --> 01:10:56,810
i will get

1080
01:10:56,810 --> 01:10:58,660
the uniform distribution

1081
01:10:58,680 --> 01:10:59,810
one of my

1082
01:10:59,810 --> 01:11:01,350
interior or device

1083
01:11:01,370 --> 01:11:03,740
so the term emotion is behind

1084
01:11:04,680 --> 01:11:08,350
transport and actually how quickly it goes

1085
01:11:08,350 --> 01:11:12,830
classification of legal documents and we found that

1086
01:11:12,850 --> 01:11:15,760
if you simply get

1087
01:11:15,850 --> 01:11:17,310
class of

1088
01:11:17,390 --> 01:11:23,160
document not based on the text but simply copy class of documents from other documents

1089
01:11:23,160 --> 01:11:25,560
that are linked with this document

1090
01:11:25,560 --> 01:11:27,370
you get the highest precision

1091
01:11:27,390 --> 01:11:32,240
so you can classify documents simply analyzing graph structured documents

1092
01:11:32,240 --> 01:11:37,120
not not that don't use any text features at all

1093
01:11:38,170 --> 01:11:44,740
links and hypertext graph is very useful when analyzing internet data

1094
01:11:44,760 --> 01:11:49,010
and we discussed in the first lecture that

1095
01:11:49,060 --> 01:11:54,760
our presentation of this type of data is some metrics as instance

1096
01:11:54,800 --> 01:11:57,930
matrix of links

1097
01:11:57,950 --> 01:12:03,410
well one is moving from one document to another

1098
01:12:04,350 --> 01:12:05,640
and this part

1099
01:12:05,660 --> 01:12:08,760
all the children born to discuss

1100
01:12:08,780 --> 01:12:11,810
how we can use this presentation

1101
01:12:13,450 --> 01:12:22,720
how we can prove present this metrics in men in our system

1102
01:12:22,780 --> 01:12:23,930
first of all

1103
01:12:23,990 --> 01:12:25,930
i want to remind you

1104
01:12:25,950 --> 01:12:28,930
that on the first lecture i said that

1105
01:12:28,950 --> 01:12:31,330
these metrics

1106
01:12:31,390 --> 01:12:32,580
once be the

1107
01:12:36,910 --> 01:12:41,590
it's obvious from this picture we have a lot of zero here or in the

1108
01:12:42,930 --> 01:12:46,850
but you can see that it's my example that i

1109
01:12:46,870 --> 01:12:52,890
draws include of the top of my head and in the real life maybe have

1110
01:12:52,930 --> 01:12:56,450
we're emailing graph of the internet

1111
01:12:56,470 --> 01:12:59,260
but it's not too true because

1112
01:12:59,280 --> 01:13:00,040
you know

1113
01:13:00,060 --> 01:13:01,950
that usually have

1114
01:13:01,950 --> 01:13:05,330
pretty small number of things from every page

1115
01:13:05,330 --> 01:13:06,800
and we have

1116
01:13:06,850 --> 01:13:12,100
power law distribution of number of links so there are some number of

1117
01:13:12,140 --> 01:13:17,240
pages that are extremely popular is a big number of incoming links

1118
01:13:17,260 --> 01:13:21,140
and we have a big number of pages that

1119
01:13:21,200 --> 01:13:26,200
i have a small number of things or don't have things at all

1120
01:13:26,220 --> 01:13:28,620
this is usually there is a lot of

1121
01:13:28,660 --> 01:13:30,600
the philosophy behind this

1122
01:13:30,620 --> 01:13:33,260
you can say that y

1123
01:13:33,260 --> 01:13:35,300
all this metrics of

1124
01:13:35,300 --> 01:13:36,870
so far

1125
01:13:36,890 --> 01:13:37,780
you can

1126
01:13:37,780 --> 01:13:38,990
talk about

1127
01:13:38,990 --> 01:13:42,220
physiology of human brain

1128
01:13:42,240 --> 01:13:48,330
that the always use this narrow that are connected with limited number of narrative that

1129
01:13:48,330 --> 01:13:49,310
looks like

1130
01:13:49,330 --> 01:13:53,510
the same model therefore are trying to build the same

1131
01:13:53,930 --> 01:13:58,640
the same type of graphs in the universe and we are trying always to repeat

1132
01:13:58,640 --> 01:14:03,430
the same words but really so we are trying to minimise actually number wrote that

1133
01:14:03,450 --> 01:14:07,140
we are using in real life so we're trying to repeating words but if you

1134
01:14:07,140 --> 01:14:09,140
use very small number of words

1135
01:14:09,160 --> 01:14:11,580
in this case it's hard to draw

1136
01:14:11,620 --> 01:14:13,100
distinguish them

1137
01:14:13,120 --> 01:14:18,870
therefore using such strange distribution of work the same situation is here

1138
01:14:18,910 --> 01:14:22,350
so we are trying to lean

1139
01:14:22,450 --> 01:14:26,510
as as less as possible at the same time trying to link to the same

1140
01:14:26,510 --> 01:14:31,140
important sites with the the same important page

1141
01:14:31,180 --> 01:14:36,530
and you can you can do a a lot of experiments try downloading part of

1142
01:14:36,530 --> 01:14:40,910
the web or using real document collections and you can see that this is always

1143
01:14:41,990 --> 01:14:45,660
just semantics is always very sparse

1144
01:14:45,660 --> 01:14:47,760
and you know how to present

1145
01:14:48,930 --> 01:14:50,760
sparse matrix

1146
01:14:50,810 --> 01:14:54,510
we can use the same inverted file with all this

1147
01:14:55,390 --> 01:14:58,220
started believe

1148
01:14:58,220 --> 01:15:01,300
compression methods

1149
01:15:02,160 --> 01:15:04,240
in this particular example

1150
01:15:04,240 --> 01:15:06,300
we create an inverted file

1151
01:15:06,350 --> 01:15:10,830
we're in dictionary actually it's ideas of our

1152
01:15:12,700 --> 01:15:17,010
and four in in posting lists for every for every

1153
01:15:17,030 --> 01:15:19,950
document we have documents

1154
01:15:20,800 --> 01:15:25,080
link to these are actually in this in this thread sorry i'm wrong in this

1155
01:15:25,080 --> 01:15:29,680
round documents that are linked from this document

1156
01:15:29,700 --> 01:15:35,430
and it's much more easier to be this inverted file this way because you

1157
01:15:35,430 --> 01:15:37,450
parsing documents

1158
01:15:37,470 --> 01:15:38,700
you get

1159
01:15:38,760 --> 01:15:42,100
for example HTML code of this document

1160
01:15:42,220 --> 01:15:44,140
extract all links

1161
01:15:45,260 --> 01:15:50,410
you are listening is key in some structure that returns ID's

1162
01:15:50,430 --> 01:15:52,740
so you

1163
01:15:52,780 --> 01:15:56,870
create current all the set of things to set of ideas

1164
01:15:56,890 --> 01:15:59,890
and for them into posting lists

1165
01:15:59,930 --> 01:16:02,120
and you can do

1166
01:16:02,160 --> 01:16:05,390
all ordinary compression that we discuss

1167
01:16:05,410 --> 01:16:08,260
because you can always start

1168
01:16:08,260 --> 01:16:09,740
this idea is

1169
01:16:09,760 --> 01:16:13,450
in increasing order it's against sequence of integers

1170
01:16:13,540 --> 01:16:17,800
that can be compressed extremely well

1171
01:16:17,810 --> 01:16:22,350
there is this open source project

1172
01:16:22,370 --> 01:16:23,240
and they

1173
01:16:23,260 --> 01:16:28,620
use this approach is is that called it's very onto their scores

1174
01:16:28,640 --> 01:16:31,760
very very close to make the call that we discussed

1175
01:16:31,810 --> 01:16:34,120
and they come kamprad

1176
01:16:34,140 --> 01:16:38,970
i just the semantics of a big part of the web using only about three

1177
01:16:39,390 --> 01:16:41,890
these apparently

1178
01:16:41,930 --> 01:16:42,560
so it

1179
01:16:43,910 --> 01:16:47,620
well compress information it can compress so

1180
01:16:47,620 --> 01:16:49,510
bridges small amount of

1181
01:16:49,510 --> 01:16:52,890
data multiply

1182
01:16:53,100 --> 01:16:54,540
so we have this

1183
01:16:54,600 --> 01:16:56,470
good presentation

1184
01:16:56,470 --> 01:16:57,810
so we have

1185
01:16:57,870 --> 01:17:01,310
we have the whole matrix of web

1186
01:17:02,600 --> 01:17:04,890
well compress files

1187
01:17:04,950 --> 01:17:10,760
and we can access from a document to all lanes that are going from this

1188
01:17:12,060 --> 01:17:15,560
because remember inverted file that going from g

1189
01:17:15,580 --> 01:17:22,540
posting lists only by every document can easily get all links from this document

1190
01:17:23,370 --> 01:17:24,410
i mean it

1191
01:17:24,450 --> 01:17:27,950
an example an example of such a link

1192
01:17:27,990 --> 01:17:31,760
graph analysis algorithm

1193
01:17:31,800 --> 01:17:35,620
and i wasn't there is i i decided to

1194
01:17:35,640 --> 01:17:40,510
take the most famous one because of good market one company

1195
01:17:42,160 --> 01:17:45,620
the most popular one is plagiarized

1196
01:17:47,260 --> 01:17:52,930
you can look into the this formula from different points of view

1197
01:17:52,950 --> 01:17:59,950
you can think of as the probability that some random walker who is visiting pages

1198
01:17:59,950 --> 01:18:01,640
on internet

1199
01:18:01,660 --> 01:18:03,800
the probability that

1200
01:18:05,780 --> 01:18:09,600
stop doing this

1201
01:18:10,760 --> 01:18:13,560
probability that a random walker

1202
01:18:13,600 --> 01:18:16,780
comes to some particular the internet

1203
01:18:16,780 --> 01:18:21,970
so you can things that if this page if this guy coming going from one

1204
01:18:21,970 --> 01:18:23,370
place to another

1205
01:18:24,680 --> 01:18:30,330
come to this page this page is more important there are much more

1206
01:18:31,180 --> 01:18:35,200
or or in our internet that comes to this page

1207
01:18:35,240 --> 01:18:38,410
or you can think about you can you can

1208
01:18:38,490 --> 01:18:41,450
think about this at the same time

1209
01:18:41,450 --> 01:18:44,280
using as as a markov process

1210
01:18:44,330 --> 01:18:49,470
is markov process because we're looking on into the previous patient going to the next

1211
01:18:50,470 --> 01:18:54,640
and in this case if you have a very good man to the ground to

1212
01:18:54,660 --> 01:19:01,810
consider all i see i can vector of our edges and symmetric on the internet

1213
01:19:01,810 --> 01:19:02,640
OK so

1214
01:19:02,660 --> 01:19:05,450
it's a very simple formula that

1215
01:19:05,450 --> 01:19:07,060
usually bar

1216
01:19:07,060 --> 01:19:10,080
a set of possibilities or some set

1217
01:19:10,100 --> 01:19:12,330
they can be thought of as an integration

1218
01:19:12,380 --> 01:19:14,060
that means you can just

1219
01:19:14,080 --> 01:19:16,440
kind of saint integral

1220
01:19:16,480 --> 01:19:19,850
so in some sense you can think about choosing

1221
01:19:19,900 --> 01:19:21,600
the set as

1222
01:19:21,650 --> 01:19:23,270
and the

1223
01:19:23,290 --> 01:19:25,480
probabilistic threshold p

1224
01:19:25,500 --> 01:19:28,420
together right and maybe even uniformly randomly

1225
01:19:28,420 --> 01:19:31,060
and there an or maybe going to greater whatever

1226
01:19:31,080 --> 01:19:33,330
but the point is that

1227
01:19:33,350 --> 01:19:34,960
this this principle

1228
01:19:36,210 --> 01:19:37,250
it all

1229
01:19:37,460 --> 01:19:41,310
the little information and a lot of places

1230
01:19:41,350 --> 01:19:42,350
it's better than

1231
01:19:42,370 --> 01:19:44,350
a lot of information in a few places

1232
01:19:44,520 --> 01:19:46,290
places in p

1233
01:19:46,310 --> 01:19:48,730
are places in as

1234
01:19:48,790 --> 01:19:50,540
it holds

1235
01:19:50,560 --> 01:19:53,560
and when use that to compute this

1236
01:19:57,020 --> 01:20:00,880
the number of runs of individual learning our

1237
01:20:00,920 --> 01:20:04,130
exit it turns out to be quite similar to the number of runs for if

1238
01:20:04,130 --> 01:20:14,460
you want some probably

1239
01:20:14,500 --> 01:20:18,650
somebody particularly getting an extreme version of this algorithm where

1240
01:20:18,690 --> 01:20:19,480
you take

1241
01:20:19,500 --> 01:20:23,270
a subset pick only one p subset

1242
01:20:23,330 --> 01:20:24,440
we learn

1243
01:20:24,440 --> 01:20:26,420
the different subsets

1244
01:20:26,880 --> 01:20:28,650
but the canopy

1245
01:20:28,670 --> 01:20:29,730
we learn

1246
01:20:29,850 --> 01:20:31,440
learn one

1247
01:20:31,460 --> 01:20:33,540
individual problem for p

1248
01:20:33,560 --> 01:20:36,480
in all these predictions school come together at the end

1249
01:20:36,500 --> 01:20:51,380
and compute that in

1250
01:20:55,250 --> 01:20:56,980
multiclass classification

1251
01:20:57,600 --> 01:21:02,210
now we have one last won the gold discusses the classification

1252
01:21:02,230 --> 01:21:03,110
this is the

1253
01:21:03,210 --> 01:21:05,900
penultimate one in a lot of ways because

1254
01:21:05,900 --> 01:21:08,920
because it's the classification can encode

1255
01:21:08,960 --> 01:21:09,880
since we

1256
01:21:10,560 --> 01:21:15,100
i think this kind of all in this way

1257
01:21:16,100 --> 01:21:19,730
because classification is defined by some measure

1258
01:21:19,770 --> 01:21:22,170
on tax cut

1259
01:21:22,190 --> 01:21:26,230
the vector of costs

1260
01:21:28,210 --> 01:21:31,040
there are some friends family discussed

1261
01:21:31,060 --> 01:21:32,750
but the it we evaluate

1262
01:21:32,770 --> 01:21:35,150
carlos is different

1263
01:21:45,420 --> 01:21:47,310
the station

1264
01:21:47,330 --> 01:21:49,020
a lot of stuff

1265
01:21:49,870 --> 01:21:52,080
we do that

1266
01:21:55,830 --> 01:21:59,560
this is vision

1267
01:21:59,980 --> 01:22:02,330
in this way

1268
01:22:02,330 --> 01:22:04,650
for this

1269
01:22:04,710 --> 01:22:06,230
these cells

1270
01:22:06,250 --> 01:22:08,060
it's all about

1271
01:22:22,500 --> 01:22:24,170
a two

1272
01:22:26,960 --> 01:22:28,690
well this is

1273
01:22:28,750 --> 01:22:30,920
it is

1274
01:22:33,170 --> 01:22:36,270
they have

1275
01:22:36,310 --> 01:22:37,790
lost in the first place

1276
01:22:37,810 --> 01:22:41,310
in the last section i

1277
01:22:41,330 --> 01:22:42,310
you can

1278
01:22:43,980 --> 01:22:46,830
and these two

1279
01:22:46,850 --> 01:22:47,830
and in one the

1280
01:22:47,830 --> 01:22:50,000
that is

1281
01:22:50,150 --> 01:22:52,210
only one

1282
01:22:54,380 --> 01:22:55,790
and each other the

1283
01:22:55,810 --> 01:22:58,230
optimizing the problem

1284
01:23:02,060 --> 01:23:04,560
we will all labels

1285
01:23:04,560 --> 01:23:06,210
what to do do

1286
01:23:06,250 --> 01:23:12,150
i think the whole

1287
01:23:12,170 --> 01:23:15,150
or in this case study

1288
01:23:20,170 --> 01:23:21,920
it is

1289
01:23:21,920 --> 01:23:24,080
was this

1290
01:23:24,100 --> 01:23:31,110
to make something like labels labels

1291
01:23:45,190 --> 01:23:47,310
how do

1292
01:23:47,370 --> 01:23:48,500
if you

1293
01:23:48,500 --> 01:23:51,960
the columns which i thing want to concentrate on the

1294
01:23:52,000 --> 01:23:57,630
relationship between the parameters

1295
01:24:03,030 --> 01:24:12,130
sorry that anybody slides

1296
01:24:12,210 --> 01:24:14,820
i'm i'm surprised as well

1297
01:24:18,250 --> 01:24:33,170
no this is and this is the lengthy mathematical proof which as i said

1298
01:24:36,840 --> 01:24:57,360
well yes but this is not is not to do with representing the space is

1299
01:24:57,360 --> 01:24:59,290
this to do with

1300
01:24:59,320 --> 01:25:02,820
how much bigger you need to make your network in order to achieve the same

1301
01:25:02,820 --> 01:25:06,320
level of reduction in some squares error

1302
01:25:06,370 --> 01:25:08,910
i'm not a hundred percent convinced by this

1303
01:25:08,990 --> 01:25:12,200
OK i many use to illustrate the

1304
01:25:12,200 --> 01:25:16,370
typically you will get away with much smaller

1305
01:25:16,370 --> 01:25:20,550
structures and you will infuse polynomial basis

1306
01:25:24,800 --> 01:25:27,670
the series RLC mean series

1307
01:25:28,040 --> 01:25:36,700
you might

1308
01:25:36,700 --> 01:25:41,040
it depends on how complex the function underlying function is of course is what to

1309
01:25:41,040 --> 01:25:44,040
do with how complex relationship is the

1310
01:25:44,830 --> 01:25:48,490
accurately representing the features in

1311
01:25:48,500 --> 01:25:49,700
and the date

1312
01:25:49,740 --> 01:25:51,120
but i i

1313
01:25:51,130 --> 01:25:55,160
i find this quite hard to to stomach exactly

1314
01:25:56,170 --> 01:25:59,240
it conveys the message

1315
01:26:02,800 --> 01:26:05,030
well yes so the

1316
01:26:05,080 --> 01:26:09,370
i i call it a malign relationship because the parameters

1317
01:26:09,380 --> 01:26:12,610
and now non linearly related to the output

1318
01:26:12,650 --> 01:26:13,940
hence the error

1319
01:26:13,950 --> 01:26:16,550
hence any function of error

1320
01:26:17,870 --> 01:26:22,150
rather more complicated than the nice bowl shaped function that we had

1321
01:26:22,200 --> 01:26:23,450
four hours

1322
01:26:23,790 --> 01:26:25,780
linear in the parameters model

1323
01:26:26,580 --> 01:26:29,200
the optimisation becomes much more difficult

1324
01:26:29,210 --> 01:26:34,480
this is not to do with neural networks it's to do with nonlinear optimization

1325
01:26:34,480 --> 01:26:38,780
in particular there are many possible solutions

1326
01:26:38,790 --> 01:26:40,740
that are mathematically

1327
01:26:41,920 --> 01:26:44,300
downward turning point

1328
01:26:46,760 --> 01:26:50,520
so yes so even with a linear output unit

1329
01:26:50,530 --> 01:26:53,650
the effect of the hidden weights in the output

1330
01:26:53,660 --> 01:26:55,050
is not linear

1331
01:26:55,340 --> 01:26:57,500
we're in trouble

1332
01:26:57,520 --> 01:27:01,900
his analysis this my peers to resist all aspects of

1333
01:27:04,120 --> 01:27:06,040
is the physical example

1334
01:27:06,040 --> 01:27:08,650
the nice linear in the parameters case k

1335
01:27:08,670 --> 01:27:13,280
one dimension we've got tonight quadratic error surface

1336
01:27:15,000 --> 01:27:18,830
if we rollerball down nice quadratic error surface

1337
01:27:18,840 --> 01:27:23,120
i was standing there when the accelerations and when the end

1338
01:27:23,120 --> 01:27:28,400
it rolls down it goes back to the for the but it gives up its

1339
01:27:28,400 --> 01:27:32,820
energy because the friction or whatever it comes to hold the only possible place come

1340
01:27:35,530 --> 01:27:40,030
so what does it sets off in the negative gradient direction

1341
01:27:44,080 --> 01:27:46,000
in reality

1342
01:27:46,080 --> 01:27:47,700
does a bit of this and then

1343
01:27:49,020 --> 01:27:51,110
at the point where

1344
01:27:51,160 --> 01:27:57,320
the gradient of j with respect to w is a good is there

1345
01:27:57,330 --> 01:28:03,320
we can mimic that everybody i hope those of gradient descent algorithm can resist

1346
01:28:03,370 --> 01:28:04,830
doing another one of these

1347
01:28:04,830 --> 01:28:08,370
OK we make the rate of change of the weights

1348
01:28:08,380 --> 01:28:10,660
with respect to time

1349
01:28:10,660 --> 01:28:14,660
proportional to the negative gradient directions so go downhill

1350
01:28:14,660 --> 01:28:16,980
and we step downhill

1351
01:28:16,990 --> 01:28:20,530
OK so we discretize the whole problem and

1352
01:28:20,540 --> 01:28:24,400
instead of rolling up the other side of it all this is just keep stepping

1353
01:28:24,400 --> 01:28:28,120
downhill until such time as it is unable to move

1354
01:28:28,550 --> 01:28:32,300
without going uphill and you stop there

1355
01:28:34,920 --> 01:28:39,550
we get a minimum point any real difficulty so even in the case when we

1356
01:28:39,550 --> 01:28:40,110
can't do

1357
01:28:41,860 --> 01:28:44,990
closed form solution we can still find these

1358
01:28:46,400 --> 01:28:49,200
quite easily with some iterative algorithm

1359
01:28:49,280 --> 01:28:52,990
given by something that looks like that

1360
01:28:55,520 --> 01:29:00,170
as soon as we have a non linear relationship between the weights and the

1361
01:29:00,190 --> 01:29:02,150
output then

1362
01:29:02,160 --> 01:29:07,280
everything changes and we wind up with cost surfaces that can look like this

1363
01:29:07,400 --> 01:29:11,410
very simple looking cost for the service here

1364
01:29:11,490 --> 01:29:15,870
i should say local minimum cut paste going

1365
01:29:15,920 --> 01:29:18,910
it is a local minima

1366
01:29:18,920 --> 01:29:23,150
OK here we have two downward facing turning points but actually there could be

1367
01:29:23,190 --> 01:29:24,410
any number of them

1368
01:29:24,420 --> 01:29:29,240
it could be any number of them all achieve global minimum as well as

1369
01:29:29,290 --> 01:29:31,020
a little bit tricky

1370
01:29:31,070 --> 01:29:34,150
so in this case

1371
01:29:34,200 --> 01:29:36,590
if we can only move downhill

1372
01:29:37,650 --> 01:29:42,660
wind up to at that point which is a local minimum not a global minimum

1373
01:29:42,740 --> 01:29:44,360
we start there

1374
01:29:44,370 --> 01:29:47,790
we wind up where we would like to be

1375
01:29:47,870 --> 01:29:51,740
if we start there we wind up we would like to be

1376
01:29:51,790 --> 01:29:53,160
and if we start there

1377
01:29:53,160 --> 01:29:55,410
we want what we don't want to be

1378
01:29:56,370 --> 01:29:57,450
the problem is

1379
01:29:57,450 --> 01:30:00,170
once again is being blind to all this

1380
01:30:00,230 --> 01:30:02,790
we have no idea where to start

1381
01:30:04,750 --> 01:30:06,550
this is a fundamental problem

1382
01:30:06,590 --> 01:30:13,830
nonconvex optimization are books and books departments devoted to people in the entire

1383
01:30:13,830 --> 01:30:15,940
research lines to the problem

1384
01:30:15,950 --> 01:30:18,410
it's fundamentally difficult

1385
01:30:18,410 --> 01:30:22,900
it's like trying to find your way down of the scottish highlands in the mist

1386
01:30:22,920 --> 01:30:24,700
without that

1387
01:30:25,040 --> 01:30:26,860
if you had the map

1388
01:30:26,870 --> 01:30:30,150
you know where the best answer was anyway and we can all go home you

1389
01:30:30,150 --> 01:30:33,030
wouldn't have to do any kind of optimization

1390
01:30:33,040 --> 01:30:35,660
we don't have the map

1391
01:30:36,870 --> 01:30:38,630
all of these

1392
01:30:39,290 --> 01:30:43,530
neural network all these multilayer perceptron things are

1393
01:30:43,550 --> 01:30:46,580
suffer from a slight problem that is you don't know whether you got the best

1394
01:30:49,330 --> 01:30:53,290
is the same thing in two dimensions i can make an animation that is the

1395
01:30:53,290 --> 01:30:57,050
same basic idea it looks a bit more like a mountain range now

1396
01:30:57,080 --> 01:31:00,610
when you start determines where you finish

1397
01:31:02,830 --> 01:31:05,940
a big problem

1398
01:31:06,520 --> 01:31:12,340
so i will assume that we're looking at minimisation

1399
01:31:12,400 --> 01:31:17,730
we assume that is analytically intractable problem which is for almost everything except for the

1400
01:31:18,460 --> 01:31:23,650
linear in the parameters sum of squares case

1401
01:31:23,690 --> 01:31:26,200
we step parameters downhill

1402
01:31:26,330 --> 01:31:28,530
that's the best we can do

1403
01:31:29,940 --> 01:31:33,620
basically a new set of weights is it which are also the weights plus a

1404
01:31:33,620 --> 01:31:35,900
step in the right direction

1405
01:31:35,910 --> 01:31:40,020
all of the techniques for doing this kind of optimisation error

1406
01:31:40,030 --> 01:31:43,280
matter of choosing a better step

1407
01:31:43,290 --> 01:31:46,200
the back propagation algorithm

1408
01:31:47,370 --> 01:31:53,280
one just takes steps that says what's what's the steepest direction to go in and

1409
01:31:53,280 --> 01:31:54,320
he was

1410
01:31:54,360 --> 01:31:56,740
discuss long before

1411
01:31:56,760 --> 01:32:00,030
the word wavelet ever got sort of

1412
01:32:00,090 --> 01:32:08,420
and nobody has paid any special attention or even probably noticed functions of one of

1413
01:32:09,320 --> 01:32:11,400
refinement equation with

1414
01:32:11,420 --> 01:32:14,970
nice numbers

1415
01:32:15,010 --> 01:32:16,550
but now

1416
01:32:16,570 --> 01:32:18,530
because we do notice

1417
01:32:18,530 --> 01:32:22,470
this with fixed a this line is

1418
01:32:22,510 --> 01:32:24,450
the solution to this

1419
01:32:24,740 --> 01:32:31,110
ways in with this with this very special or lowpass filter

1420
01:32:31,150 --> 01:32:34,050
so there's another example so all the

1421
01:32:34,110 --> 01:32:37,240
so the family of examples in other words

1422
01:32:40,220 --> 01:32:42,030
quadratic swine

1423
01:32:42,030 --> 01:32:43,380
q x y

1424
01:32:45,940 --> 01:32:47,680
we can do exactly

1425
01:32:47,820 --> 01:32:50,340
that's about the limit of

1426
01:32:50,360 --> 01:32:58,380
exact solutions i know less

1427
01:32:58,420 --> 01:33:02,610
well i just went by and said that what will work

1428
01:33:02,700 --> 01:33:04,970
what i'm after

1429
01:33:04,970 --> 01:33:07,470
have to

1430
01:33:09,700 --> 01:33:12,400
i would love to reason makes based system

1431
01:33:12,450 --> 01:33:16,680
to do that the idea think that an exercises professors

1432
01:33:16,740 --> 01:33:20,990
privilege right so i suppose i have

1433
01:33:21,110 --> 01:33:23,650
one lowpass filter

1434
01:33:24,780 --> 01:33:29,860
and the function field corresponds and just make a simple

1435
01:33:29,880 --> 01:33:32,950
keep the same coefficients

1436
01:33:33,010 --> 01:33:35,300
same function as well as

1437
01:33:35,340 --> 01:33:40,280
what about the coefficients come from convolution of this

1438
01:33:40,320 --> 01:33:42,550
my claim is that

1439
01:33:42,650 --> 01:33:44,340
the result was

1440
01:33:44,340 --> 01:33:46,450
from the convolution

1441
01:33:46,490 --> 01:33:49,030
was itself

1442
01:33:49,070 --> 01:33:49,860
so i

1443
01:33:49,910 --> 01:33:52,340
i'm not answer your questions

1444
01:33:52,380 --> 01:33:54,470
asking that you

1445
01:33:58,240 --> 01:34:01,650
there can no symmetry is built into this at all

1446
01:34:01,900 --> 01:34:05,340
although it's built into these examples

1447
01:34:05,400 --> 01:34:09,990
but do not make any assumptions about symmetry here

1448
01:34:15,070 --> 01:34:15,800
that's right

1449
01:34:15,900 --> 01:34:21,550
that's right and maybe i give away you might check prove first you could i

1450
01:34:21,570 --> 01:34:25,610
i pretty sure you to prove it directly

1451
01:34:25,650 --> 01:34:27,380
in the time domain

1452
01:34:27,400 --> 01:34:30,050
but probably

1453
01:34:30,090 --> 01:34:32,150
the convolution

1454
01:34:32,170 --> 01:34:35,070
better off get in the other domain right

1455
01:34:35,090 --> 01:34:38,170
in in frequency domain the multiplication

1456
01:34:38,220 --> 01:34:42,780
so let's see how i would get in the frequency domain good thing

1457
01:34:42,880 --> 01:34:48,170
all right so i could finish this formula

1458
01:34:48,180 --> 01:34:51,170
which would be the formula in the frequency domain

1459
01:34:51,180 --> 01:34:53,470
OK so let me finish

1460
01:34:53,860 --> 01:34:58,510
this is the product well who needs information from but

1461
01:34:58,550 --> 01:35:00,010
that's what it is

1462
01:35:01,320 --> 01:35:06,220
i mean the frequency domain so you will not be surprised to see the function

1463
01:35:06,240 --> 01:35:08,220
we called capital h

1464
01:35:08,260 --> 01:35:10,970
i make appear

1465
01:35:12,550 --> 01:35:16,510
remember when capitalize it was

1466
01:35:16,590 --> 01:35:19,570
it was the function

1467
01:35:19,610 --> 01:35:21,050
and all of them

1468
01:35:21,150 --> 01:35:22,650
which had

1469
01:35:22,740 --> 01:35:26,050
she says it's

1470
01:35:28,360 --> 01:35:34,780
capitalism and then you remember was

1471
01:35:34,840 --> 01:35:38,470
the size some of the coefficients

1472
01:35:38,490 --> 01:35:41,510
times either the minus j

1473
01:35:42,650 --> 01:35:46,470
using gene today j omega

1474
01:35:48,170 --> 01:35:49,550
finite series

1475
01:35:49,550 --> 01:35:54,880
this is a polynomial because soon thinking here if fire filters

1476
01:35:54,920 --> 01:35:56,880
remember a troublemaker

1477
01:35:57,450 --> 01:35:59,180
show me

1478
01:35:59,340 --> 01:36:00,650
the thing is

1479
01:36:00,670 --> 01:36:04,360
when i could take when i go into the frequency domain

1480
01:36:04,380 --> 01:36:07,170
OK to frequency scales

1481
01:36:07,840 --> 01:36:09,590
if have chance

1482
01:36:09,610 --> 01:36:11,320
for a transfer this skin

1483
01:36:11,340 --> 01:36:17,400
feeding on a free transfer this will involve the out of what

1484
01:36:17,420 --> 01:36:19,800
anybody know

1485
01:36:19,880 --> 01:36:22,720
it will be two omega

1486
01:36:22,760 --> 01:36:27,010
because somehow it flips the other way around it will be

1487
01:36:27,070 --> 01:36:29,920
feel out of over two

1488
01:36:31,090 --> 01:36:32,070
we can

1489
01:36:32,130 --> 01:36:36,070
we can easily do that and of course the book does

1490
01:36:36,090 --> 01:36:38,700
and so may or two and

1491
01:36:38,760 --> 01:36:39,570
and then

1492
01:36:39,670 --> 01:36:42,780
OK let me say it in words without

1493
01:36:42,800 --> 01:36:45,240
write it down but i'm willing to read

1494
01:36:45,260 --> 01:36:51,380
so the fourier transform of all right yes you're right with the fourier transform

1495
01:36:51,450 --> 01:36:54,840
that equation

1496
01:36:54,900 --> 01:36:58,860
the fourier transform of this equation is fantastic

1497
01:36:58,860 --> 01:37:00,130
put it in yellow

1498
01:37:00,470 --> 01:37:01,940
i like

1499
01:37:01,950 --> 01:37:06,050
so i'm taking the fourier transforms like the head my

1500
01:37:06,050 --> 01:37:07,220
on the left

1501
01:37:07,220 --> 01:37:12,060
speak to people you need on your personal scale of tend to do them just

1502
01:37:12,100 --> 01:37:18,450
the the the pay and the respect of just being as well turned out as

1503
01:37:18,450 --> 01:37:21,080
you possibly can just look the part

1504
01:37:21,130 --> 01:37:22,670
the second one is

1505
01:37:22,680 --> 01:37:25,850
i'm gonna touch and the moment a little bit more detail a little bit of

1506
01:37:25,850 --> 01:37:30,800
energy enthusiasm and here today to talk to you about christmas it's subject to really

1507
01:37:30,800 --> 01:37:32,140
gets me excited

1508
01:37:32,150 --> 01:37:38,420
and i've been excited by charisma for so long as i can remember god almighty

1509
01:37:38,420 --> 01:37:42,450
danny was saying to me in the break he said one of the most engaging

1510
01:37:42,450 --> 01:37:47,180
things when you meet a sales person who really believes in their product and around

1511
01:37:47,180 --> 01:37:52,440
the two thousand presentation you buy from almost just because of their belief

1512
01:37:52,500 --> 01:37:56,970
because of that enthusiasm because of that energy and where you walk on you better

1513
01:37:58,160 --> 01:38:01,000
like it's not the two thousand time you've done it even if you have you

1514
01:38:01,000 --> 01:38:06,260
have to give up some energy i've already touched on smiling just warming up again

1515
01:38:06,310 --> 01:38:09,390
keep it open if in doubt keep your hands out

1516
01:38:09,390 --> 01:38:11,720
so if you if you don't know what else to do with your hands just

1517
01:38:11,720 --> 01:38:12,230
keep them away

1518
01:38:12,780 --> 01:38:14,250
by the way

1519
01:38:14,310 --> 01:38:18,490
did anybody notice me breaking one of my rules during the break

1520
01:38:18,580 --> 01:38:22,290
one of the problems when you talk about body language is then people start watching

1521
01:38:22,300 --> 01:38:25,180
to see you actually practice what you preach

1522
01:38:25,190 --> 01:38:29,300
and what we are trying to get speakers sorted out over there was over here

1523
01:38:29,300 --> 01:38:34,590
and i found myself standing here way with my hands covering my genitals and i

1524
01:38:34,590 --> 01:38:36,750
looked around to see if anybody look

1525
01:38:36,800 --> 01:38:41,550
so i went back to a comfortable because one i'm in a room full of

1526
01:38:41,550 --> 01:38:44,410
people i've met many of you for the first time today

1527
01:38:44,440 --> 01:38:48,200
secondly i didn't know the technology was going to work and i was a little

1528
01:38:48,200 --> 01:38:50,450
bit nervous that the speakers wouldn't work

1529
01:38:50,510 --> 01:38:55,830
it even when you're aware of this stuff you can slip factor all too easily

1530
01:38:55,870 --> 01:39:00,090
so in the presentation if in doubt just keep your hands away from your body

1531
01:39:00,120 --> 01:39:05,690
is people have a clear view of the year solar plexus use eyes

1532
01:39:05,690 --> 01:39:09,990
just make eye contact with people make eye contact with the the the hardest person

1533
01:39:09,990 --> 01:39:11,760
to make eye contact with in the room

1534
01:39:11,810 --> 01:39:15,140
so find the person doesn't want to make eye contact and when you crack then

1535
01:39:15,140 --> 01:39:16,940
everybody else is easy

1536
01:39:16,940 --> 01:39:20,940
it feels easier honestly you get people just to give you this and i don't

1537
01:39:20,940 --> 01:39:23,270
care how long you look at me i'm not going to smile and they do

1538
01:39:25,190 --> 01:39:28,860
so given a little bit of what use positive language

1539
01:39:28,880 --> 01:39:33,930
i know it sounds terrible but you pick up a newspaper you switch on the

1540
01:39:33,930 --> 01:39:38,580
radio switch on the television in ireland there's as much negativity as you need to

1541
01:39:38,580 --> 01:39:40,260
last you a lifetime

1542
01:39:40,280 --> 01:39:44,740
you go to a presentation the last thing in the world you want is that

1543
01:39:44,740 --> 01:39:46,440
sort of negative language now

1544
01:39:46,450 --> 01:39:49,690
we live in a world where we have to deal with negative situations

1545
01:39:49,770 --> 01:39:52,260
use positive language to deal with it

1546
01:39:52,270 --> 01:39:58,140
get rid of the week native language speaking stories you've been spared so far i've

1547
01:39:58,150 --> 01:40:01,390
love stories about my father who was a little bit of

1548
01:40:01,400 --> 01:40:03,740
poor man's philosopher

1549
01:40:03,770 --> 01:40:09,470
and i like to use his stories to illustrate things people love points made in

1550
01:40:09,470 --> 01:40:15,360
stories love the made in quotations love the maiden similar the love the made indirectly

1551
01:40:15,360 --> 01:40:19,750
i think it may be appealed to the inner child or some such

1552
01:40:19,770 --> 01:40:21,980
how many people have

1553
01:40:22,020 --> 01:40:25,280
vision statement hanging in in the hall of the

1554
01:40:25,290 --> 01:40:27,460
the organisation they work for

1555
01:40:27,510 --> 01:40:29,740
it's not a trick question

1556
01:40:29,920 --> 01:40:31,770
OK a few

1557
01:40:31,920 --> 01:40:35,090
one of the things that i mean every organisation

1558
01:40:35,110 --> 01:40:36,890
it doesn't matter how small you are

1559
01:40:36,940 --> 01:40:41,200
it doesn't matter if you're one person organisation have some kind of vision statement says

1560
01:40:41,200 --> 01:40:45,540
that here's why i'm in this business here's what the long-term impact i want to

1561
01:40:45,540 --> 01:40:49,720
have on the world on myself here's why we exist

1562
01:40:49,730 --> 01:40:51,720
this is why we are here

1563
01:40:51,730 --> 01:40:54,440
and it's important because it helps you to define

1564
01:40:54,440 --> 01:40:58,310
well the organisation going to help you make decisions in terms of your mission and

1565
01:40:58,310 --> 01:41:04,340
how to make decisions in terms of goals but you should never delude yourself

1566
01:41:04,340 --> 01:41:09,470
that that vision statement motivate any more than the four or five people who put

1567
01:41:10,900 --> 01:41:15,060
those are the only people who in general are motivated by the guys walking to

1568
01:41:15,060 --> 01:41:19,510
work in the morning don't walk in signature after a and o

1569
01:41:19,540 --> 01:41:24,440
we will be the world's leading i feel much better now i'm ready to go

1570
01:41:24,440 --> 01:41:27,970
they don't care we don't care we don't care

1571
01:41:27,990 --> 01:41:30,030
until we know

1572
01:41:30,040 --> 01:41:31,040
what's in it

1573
01:41:31,080 --> 01:41:34,410
for us that's i said earlier when you

1574
01:41:34,430 --> 01:41:38,500
i want to share your vision of your department

1575
01:41:38,560 --> 01:41:41,000
the schools that you have for the year

1576
01:41:41,010 --> 01:41:46,620
what you expect from people and their contribution to it you better at the same

1577
01:41:46,620 --> 01:41:51,050
time as you tell them what you're looking to achieve the saying and here's what's

1578
01:41:51,050 --> 01:41:52,540
in it for you

1579
01:41:52,560 --> 01:41:55,100
and i talked about how you do that little bit more but let me just

1580
01:41:55,470 --> 01:41:56,470
go back

1581
01:41:56,480 --> 01:42:00,300
i think it's time that they were living at that particular time very everybody was

1582
01:42:00,300 --> 01:42:04,300
tremendously demoralized and when they come up with something is not only is that i

1583
01:42:04,300 --> 01:42:08,510
think about nineteen sixty two when he said in this decade

1584
01:42:08,530 --> 01:42:11,370
before the end of the sixties we put a man on the moon

1585
01:42:11,440 --> 01:42:13,340
now as it happens

1586
01:42:13,340 --> 01:42:22,160
the space program completely revitalized american industry and indeed the technological innovation had echoes for

1587
01:42:22,160 --> 01:42:26,310
thirty years after it i mean it just changed everything out of sight two things

1588
01:42:26,310 --> 01:42:28,810
he did their most important one is

1589
01:42:28,870 --> 01:42:32,430
he created something which was so big

1590
01:42:32,440 --> 01:42:38,910
so inspirational that it distracted people from the reality is around them at the time

1591
01:42:38,990 --> 01:42:44,290
henry ford said that obstacles are those terrible things you see

1592
01:42:44,300 --> 01:42:46,940
when you look down from your goals

1593
01:42:46,940 --> 01:42:50,730
and in the current climate people are looking down on all they see is obstacles

1594
01:42:50,940 --> 01:42:56,600
one rosalita first rule leaders one to create that picture

1595
01:42:56,610 --> 01:43:01,530
that very personal picture of a here's where it's going to be like

1596
01:43:02,520 --> 01:43:07,110
this problem here is where we're going to here's what we can achieve together but

1597
01:43:07,110 --> 01:43:11,840
then the second part is and what's in it for you

1598
01:43:11,840 --> 01:43:15,410
now in order to tailor your vision

1599
01:43:15,430 --> 01:43:20,050
for the people work for you you have to know that in some ways better

1600
01:43:20,050 --> 01:43:21,910
than they know themselves

1601
01:43:21,950 --> 01:43:24,290
you obviously have to know what the strengths

1602
01:43:24,370 --> 01:43:26,380
because you can not

1603
01:43:26,430 --> 01:43:30,350
talk to somebody about becoming all the people are becoming unless you know what the

1604
01:43:30,350 --> 01:43:33,750
people becoming you need to know what the development areas are

1605
01:43:33,810 --> 01:43:38,310
you need to know where they need to be buoyed up because if you know

1606
01:43:38,310 --> 01:43:42,060
that derek has a weakness in this by working with you in the service of

1607
01:43:42,060 --> 01:43:49,190
this particular goal that you're gonna races capabilities raises value raise his is general self-esteem

1608
01:43:49,190 --> 01:43:53,910
in general works well then he will engage what causes he had from self

1609
01:43:53,920 --> 01:43:55,400
is the bottom line

1610
01:43:55,420 --> 01:43:58,000
you need to know

1611
01:43:58,050 --> 01:44:04,400
every one of the people who work for you inside out because they don't care

1612
01:44:04,440 --> 01:44:06,170
about your vision

1613
01:44:06,210 --> 01:44:11,690
realistically they don't care about the vision of the organization b be on its capability

1614
01:44:11,690 --> 01:44:16,570
excel is already extremely complicated

1615
01:44:17,330 --> 01:44:18,640
let's just have a look at it

1616
01:44:18,770 --> 01:44:24,190
reversing the reductionist metaphore just to remind you that the main metaphor of the selfish

1617
01:44:25,310 --> 01:44:30,060
from his book in nineteen seventy six now they

1618
01:44:30,080 --> 01:44:36,070
j genes of course was in huge colonies safe inside gigantic lumbering robots that's you

1619
01:44:36,070 --> 01:44:36,770
and me

1620
01:44:36,780 --> 01:44:39,440
communicating with it by

1621
01:44:39,490 --> 01:44:45,070
tortuous indirect route sealed off from the outside world that the that is of course

1622
01:44:45,090 --> 01:44:49,030
the central dogma applied to the system as a whole

1623
01:44:49,050 --> 01:44:51,450
as actually show that's incorrect

1624
01:44:51,450 --> 01:44:56,480
they are in you and me that's the only empirical statement there and it's correct

1625
01:44:56,500 --> 01:45:00,540
they created us body and mind that the quote i used earlier on and their

1626
01:45:00,540 --> 01:45:05,060
preservation is the ultimate rationale for our existence and in case you didn't understand what

1627
01:45:05,060 --> 01:45:08,420
he wrote in his book the extended phenotype

1628
01:45:08,450 --> 01:45:13,440
just two or three years later he wrote the reader should imbibe the fundamental truth

1629
01:45:13,440 --> 01:45:15,570
that an organism is a tool of DNA

1630
01:45:15,580 --> 01:45:19,920
and not the other way round line going to carry out experiments on your

1631
01:45:19,930 --> 01:45:25,290
so very simple experiment except for the one statement that is an empirical state where

1632
01:45:25,560 --> 01:45:28,870
i'm going to turn those statements or upside down

1633
01:45:28,900 --> 01:45:32,370
and state opposite the experiment is this

1634
01:45:32,400 --> 01:45:35,100
this a challenge to you all

1635
01:45:35,110 --> 01:45:36,120
can you sing

1636
01:45:36,140 --> 01:45:42,180
of any biological experiment one could do any empirical test that would tell the difference

1637
01:45:42,180 --> 01:45:48,440
between these two statements services the alternative i call the alternative genes as prisoners now

1638
01:45:48,440 --> 01:45:54,410
they are trapped in huge colonies locked inside highly intelligent beings and then as you

1639
01:45:54,410 --> 01:45:54,640
and me

1640
01:45:55,050 --> 01:45:59,490
moulded by the outside world i reversed the central dogma

1641
01:45:59,920 --> 01:46:05,520
communicating with it by complex processes through which blindly as if by magic you don't

1642
01:46:05,520 --> 01:46:08,700
have to have that phrase in if you don't like it function emerges they are

1643
01:46:08,700 --> 01:46:13,050
in you and me as the only statements unchanged we are the system that allows

1644
01:46:13,050 --> 01:46:17,780
their code to be read the genome starts off in the next is the proteins

1645
01:46:17,780 --> 01:46:19,000
in the egg

1646
01:46:19,020 --> 01:46:24,390
initially coming across from the mother to initiate reading of the gene and their preservation

1647
01:46:24,390 --> 01:46:29,570
is totally dependent on the joy we experience in reproducing ourselves and incidentally is our

1648
01:46:29,570 --> 01:46:32,280
joy not theirs we

1649
01:46:32,290 --> 01:46:37,440
the ultimate rationale for their existence

1650
01:46:37,450 --> 01:46:42,530
and you can also reverse the statement in the extended phenotype fundamental truth is that

1651
01:46:42,530 --> 01:46:47,440
an organism is the only tool by which DNA can express functionality by which the

1652
01:46:47,440 --> 01:46:52,570
book of life if you like a particular metaphore can give DNA alone is in

1653
01:46:52,570 --> 01:46:53,710
fact dead

1654
01:46:53,720 --> 01:46:56,090
my point here

1655
01:46:56,110 --> 01:46:56,840
it's not

1656
01:46:56,860 --> 01:47:00,990
to convince you this metaphore is the better one

1657
01:47:01,050 --> 01:47:03,710
the selfish gene is that both matter falls

1658
01:47:03,720 --> 01:47:06,300
this is not biological science

1659
01:47:06,310 --> 01:47:13,160
there's nothing in biological sciences that justifies the centre selfish gene concept nothing in biological

1660
01:47:13,160 --> 01:47:17,550
science that justifies all the production is nonsense that we've heard

1661
01:47:17,820 --> 01:47:24,020
since that was published so let's have look at the question of unravelling complexity

1662
01:47:24,060 --> 01:47:27,490
i would suggest that we need to work in an integrative way

1663
01:47:27,520 --> 01:47:29,920
at all levels there is the original

1664
01:47:30,030 --> 01:47:32,320
reductionist this part

1665
01:47:32,340 --> 01:47:38,430
the bottom-up approach and what we've got to take into account causes the feed downs

1666
01:47:38,840 --> 01:47:44,820
as well as up between all these levels because systems levels control cell signaling

1667
01:47:44,840 --> 01:47:49,330
all levels control gene expression site reverse this arrow

1668
01:47:49,430 --> 01:47:51,930
it's the system that reads the you know

1669
01:47:51,940 --> 01:47:55,050
not the other way round

1670
01:47:55,070 --> 01:48:00,320
it's protein machinery of course that does that and very very important we're beginning to

1671
01:48:00,320 --> 01:48:06,810
understand the extent to which this as yet another dimension of complexity biological systems

1672
01:48:06,850 --> 01:48:10,840
and there is a genetic marking by all levels

1673
01:48:10,850 --> 01:48:12,890
so let's take an example

1674
01:48:12,910 --> 01:48:19,270
as the chairman said earlier on i've been involved in computing cardiac activity for many

1675
01:48:19,270 --> 01:48:20,350
many years

1676
01:48:20,360 --> 01:48:23,550
and what thing to do is take one of our models

1677
01:48:23,570 --> 01:48:25,450
of pacemaker is

1678
01:48:26,270 --> 01:48:31,920
and a cardiac cells is actually based on experiments done in rapid sign is now

1679
01:48:31,940 --> 01:48:38,460
and what we succeeded in doing is to reconstruct the electrical grid shown by

1680
01:48:38,500 --> 01:48:41,910
the pacemaker cells in the science of the rabbit

1681
01:48:41,930 --> 01:48:48,040
starting with equations representing some of the proteins involved potassium channel here which is also

1682
01:48:48,040 --> 01:48:53,420
lighting up and down in synchrony with the cell voltage the calcium channel was also

1683
01:48:53,430 --> 01:48:57,420
non-selective channels there are many others but shown three

1684
01:48:57,570 --> 01:49:04,530
for the sake of simplicity and being able to make the diagram comprehensive at all

1685
01:49:04,590 --> 01:49:06,800
it would look too complicated

1686
01:49:06,850 --> 01:49:09,310
when i showed this

1687
01:49:10,530 --> 01:49:14,280
a number of years ago to meetings of science

1688
01:49:14,700 --> 01:49:20,520
newspaper journalist in london in one of them for the following question to me and

1689
01:49:20,530 --> 01:49:27,650
said professor nevertheless beautiful reconstructions and indeed if you superimpose an experimental recording on

1690
01:49:27,650 --> 01:49:33,130
this theoretical reconstructions you can't put to tell the difference between them so you can

1691
01:49:33,130 --> 01:49:35,380
now tell us which is the gene

1692
01:49:35,390 --> 01:49:37,770
the pacemaker activity in the heart

1693
01:49:37,790 --> 01:49:39,950
so you

1694
01:49:39,950 --> 01:49:44,670
john too deep into the reductions agenda there's no such team

1695
01:49:44,690 --> 01:49:46,170
so we're it

1696
01:49:46,190 --> 01:49:51,050
the genes that code for each of these proteins

1697
01:49:51,190 --> 01:49:54,390
they also late in synchrony with the cell voltage

1698
01:49:54,410 --> 01:49:57,220
surely one or other of these or

1699
01:49:57,250 --> 01:50:00,520
a particular combination is driving the system

1700
01:50:00,530 --> 01:50:02,190
so you must be able all to

1701
01:50:02,200 --> 01:50:04,330
so now identified

1702
01:50:04,330 --> 01:50:10,700
the gene for pacemaker is in still haven't understood i'm going to carry out an

1703
01:50:10,700 --> 01:50:14,720
experiment to demonstrate why that way of thinking is wrong and can repeat the same

1704
01:50:14,720 --> 01:50:16,930
experiment performed for him

1705
01:50:16,930 --> 01:50:18,870
so let's start

1706
01:50:18,900 --> 01:50:23,330
before i start to talk to you about graphical models

1707
01:50:23,350 --> 01:50:28,050
we should first be aware there is material out there that very nice and covers

1708
01:50:28,050 --> 01:50:29,400
very well subject

1709
01:50:29,460 --> 01:50:33,290
so many good books for example i highly recommend chris bishop's book

1710
01:50:33,340 --> 01:50:37,890
it covers machine learning journal has a lot of the model

1711
01:50:37,940 --> 01:50:43,380
sold for introductory five for machine learning generally come in this book in particular that

1712
01:50:43,400 --> 01:50:44,760
the mothers as well

1713
01:50:46,790 --> 01:50:49,660
duty at scales book

1714
01:50:49,670 --> 01:50:53,110
it's a classic work in the field probably the first time the

1715
01:50:53,150 --> 01:50:54,090
that the

1716
01:50:54,100 --> 01:50:57,640
graphical models have been systematized in very

1717
01:50:57,690 --> 01:50:59,050
very nice work

1718
01:50:59,460 --> 01:51:01,360
also highly recommended

1719
01:51:01,410 --> 01:51:05,050
and the more theoretical book that covers the basics of the theory of graphical models

1720
01:51:05,050 --> 01:51:08,900
is defined more accessible

1721
01:51:09,940 --> 01:51:12,920
if it's free

1722
01:51:13,160 --> 01:51:17,890
the graphical model the graphical models chapter of this book is available

1723
01:51:17,940 --> 01:51:21,030
from chris bishop website

1724
01:51:21,920 --> 01:51:23,470
the charge OK

1725
01:51:23,480 --> 01:51:25,660
so but only the graphical model

1726
01:51:25,710 --> 01:51:30,030
chapter which for the purposes of these lectures of difficulty

1727
01:51:30,040 --> 01:51:31,620
so you can check

1728
01:51:31,670 --> 01:51:35,910
so there's also published material that people have been using a lot unfortunately is about

1729
01:51:35,910 --> 01:51:38,970
material not available in the one

1730
01:51:39,910 --> 01:51:41,480
have access to it

1731
01:51:41,520 --> 01:51:44,780
which is mike jordan's book called

1732
01:51:44,840 --> 01:51:49,080
book which i think has changed my life it's as well

1733
01:51:49,130 --> 01:51:53,160
and also there is plenty of useful if you can find videolectures

1734
01:51:53,240 --> 01:51:54,880
in particular recommends

1735
01:51:54,890 --> 01:51:58,710
some revised we do all sorts of being among the very nicely

1736
01:52:00,130 --> 01:52:01,390
you can check that

1737
01:52:01,400 --> 01:52:04,290
you know that don't

1738
01:52:04,310 --> 01:52:08,570
lots of good places to

1739
01:52:08,620 --> 01:52:09,980
to learn about

1740
01:52:13,770 --> 01:52:15,190
i did

1741
01:52:15,300 --> 01:52:17,430
an experiment just tried to

1742
01:52:17,530 --> 01:52:19,750
checked how many

1743
01:52:19,800 --> 01:52:23,520
pages that come up in google scholar search for

1744
01:52:23,570 --> 01:52:26,510
a bunch of different names

1745
01:52:26,520 --> 01:52:32,330
actually related to graph like come to EMI with hidden markov models

1746
01:52:32,390 --> 01:52:35,170
bayesian networks markov to form

1747
01:52:35,180 --> 01:52:36,940
it's quite a lot i mean this is

1748
01:52:36,950 --> 01:52:38,260
bit of data

1749
01:52:38,310 --> 01:52:39,330
because of this

1750
01:52:39,340 --> 01:52:40,470
it is like

1751
01:52:40,540 --> 01:52:42,050
not very recent so

1752
01:52:42,100 --> 01:52:44,920
so the numbers have probably was substantial

1753
01:52:44,970 --> 01:52:46,950
first question was not

1754
01:52:47,020 --> 01:52:48,740
heard any of these

1755
01:52:48,750 --> 01:52:51,940
any absolutely any of these

1756
01:52:55,070 --> 01:52:58,910
so we have one person who is and who hasn't heard of what what is

1757
01:52:58,910 --> 01:53:00,440
basically means is that

1758
01:53:00,490 --> 01:53:02,140
it's very

1759
01:53:02,150 --> 01:53:03,580
even though we have

1760
01:53:03,630 --> 01:53:09,320
and the thirty audience is is in general not familiar to

1761
01:53:10,810 --> 01:53:13,620
many many people have at least heard of

1762
01:53:13,810 --> 01:53:14,990
this one of these

1763
01:53:16,480 --> 01:53:17,740
although it's

1764
01:53:17,750 --> 01:53:23,810
good sign because actually all these things are very much for the the related

1765
01:53:23,820 --> 01:53:28,100
in fact many of these are examples of graphical models

1766
01:53:28,200 --> 01:53:29,520
so we'll just

1767
01:53:30,470 --> 01:53:32,210
in this course

1768
01:53:32,290 --> 01:53:34,090
all these

1769
01:53:34,140 --> 01:53:39,140
all these methods from a unique perspective from a unified perspective

1770
01:53:46,160 --> 01:53:47,590
no in fact

1771
01:53:47,600 --> 01:53:50,110
many of these are really

1772
01:53:50,310 --> 01:53:55,770
instantiations of modern examples of article it is

1773
01:53:55,850 --> 01:53:57,370
common field

1774
01:53:57,390 --> 01:54:00,970
hidden markov models bayesian networks markov random fields

1775
01:54:00,980 --> 01:54:09,950
and particle filters mixture models conditional random fields some of them like sampling

1776
01:54:10,180 --> 01:54:12,530
any other questions

1777
01:54:12,540 --> 01:54:15,460
please feel free to interrupt a time

1778
01:54:15,770 --> 01:54:20,110
so now why graph model so basically

1779
01:54:20,160 --> 01:54:21,360
it's amazing

1780
01:54:21,390 --> 01:54:24,970
the number of fields where this has been applied to k

1781
01:54:24,990 --> 01:54:29,250
image processing speech processing natural language processing

1782
01:54:29,310 --> 01:54:31,630
document process

1783
01:54:31,650 --> 01:54:37,130
but convinced by from computed in many fields outside of computer science

1784
01:54:37,180 --> 01:54:40,300
like economics physics social sciences

1785
01:54:42,180 --> 01:54:45,000
it seems to be quite general

1786
01:54:45,050 --> 01:54:49,120
mythological framework to actually analyse

1787
01:54:51,130 --> 01:54:52,140
in different

1788
01:54:52,160 --> 01:54:54,190
and i in different types

1789
01:54:54,240 --> 01:54:57,260
of the

1790
01:54:57,990 --> 01:55:02,490
before we actually start talking about graphical model is just show you pictures

1791
01:55:03,600 --> 01:55:06,830
of applications of graphical models what is this

1792
01:55:06,840 --> 01:55:10,460
so this this is this is an example in physics

1793
01:55:11,400 --> 01:55:14,690
it turns out that you can model how

1794
01:55:14,700 --> 01:55:18,510
materials behave using graphical models for example

1795
01:55:18,560 --> 01:55:21,530
here we have what they call a ferryman

1796
01:55:22,900 --> 01:55:26,610
in the left hand side is an example of the ising model

1797
01:55:26,650 --> 01:55:29,480
the ising model is essentially a model that

1798
01:55:30,900 --> 01:55:33,290
the fact that the joint

1799
01:55:33,330 --> 01:55:35,380
particles that are close

1800
01:55:35,390 --> 01:55:40,220
to each other they tend to have the same speed in particular type of material

1801
01:55:42,050 --> 01:55:45,360
it's been is basically orientation of the magnetic field

1802
01:55:45,490 --> 01:55:48,770
what's white not black here is essentially

1803
01:55:48,860 --> 01:55:54,270
atoms that have been one or money so that's basically saying

1804
01:55:55,460 --> 01:55:59,270
referring to be magnetized in one direction you action

1805
01:56:00,360 --> 01:56:04,370
what you can see on the left hand side essentially simulation

1806
01:56:04,410 --> 01:56:07,470
of the magnetisation of one of these materials

1807
01:56:07,490 --> 01:56:09,680
by using ising model

1808
01:56:09,740 --> 01:56:16,050
so what the ising model see essentially we have here in the bottom right-hand side

1809
01:56:16,120 --> 01:56:22,820
we for the representation of the magnetisation of every out which can be either up

1810
01:56:22,820 --> 01:56:24,390
or down

1811
01:56:24,440 --> 01:56:27,850
if you have a ferrimagnetic material which is

1812
01:56:27,860 --> 01:56:30,950
the example on the left it means that

1813
01:56:31,000 --> 01:56:33,040
this material will

1814
01:56:33,050 --> 01:56:35,360
three for

1815
01:56:35,460 --> 01:56:37,230
that neighboring

1816
01:56:37,240 --> 01:56:39,410
after all have the same

1817
01:56:39,430 --> 01:56:44,170
organization sort of words or or don't

1818
01:56:44,210 --> 01:56:46,750
that's why you can see this is what

1819
01:56:46,800 --> 01:56:48,710
in this image

1820
01:56:48,720 --> 01:56:51,440
this image is generated some kind of

1821
01:56:52,480 --> 01:56:54,450
let chance of leg

1822
01:56:54,500 --> 01:56:57,800
and contiguous chunks of white wine

1823
01:56:57,810 --> 01:57:01,390
because if one particular atoms wide

1824
01:57:01,400 --> 01:57:05,260
that the system will refer to the neighbor is also white

1825
01:57:05,270 --> 01:57:08,650
so that's why you have small

1826
01:57:08,770 --> 01:57:14,110
there's other the type material called ferrimagnetic material which is exactly the opposite

1827
01:57:14,160 --> 01:57:16,810
it's such material prefers

1828
01:57:16,820 --> 01:57:20,000
the neighbouring atoms have opposite spins

1829
01:57:20,050 --> 01:57:23,800
which is this case

1830
01:57:23,810 --> 01:57:25,800
so again please

1831
01:57:25,850 --> 01:57:27,520
these temperature

1832
01:57:28,690 --> 01:57:30,900
that's basically is

1833
01:57:30,910 --> 01:57:35,520
it's some models we are modelling basically how

1834
01:57:35,570 --> 01:57:37,650
we're using a graphical model

1835
01:57:37,720 --> 01:57:41,980
but we'll see later detail but essentially what you're doing is using a graphical model

1836
01:57:41,990 --> 01:57:44,380
to model the behavior of how

1837
01:57:44,390 --> 01:57:49,330
this means seen these materials they change according to the temperature if the temperature is

1838
01:57:49,330 --> 01:57:50,850
very very high

1839
01:57:50,900 --> 01:57:52,020
it doesn't matter which

1840
01:57:52,070 --> 01:57:53,650
what you have here

1841
01:57:53,690 --> 01:57:57,590
so any material inside the sun just evaporate right

1842
01:57:57,980 --> 01:58:01,610
so basically the more you become these are actually the more

1843
01:58:01,610 --> 01:58:03,900
objects in the images

1844
01:58:03,930 --> 01:58:08,240
and we get the size from the features section

1845
01:58:08,400 --> 01:58:13,050
is a using this example already these on the left here

1846
01:58:13,090 --> 01:58:15,590
this is recognised instances

1847
01:58:15,610 --> 01:58:17,030
of the object

1848
01:58:17,050 --> 01:58:19,220
OK found in these images

1849
01:58:19,240 --> 01:58:25,360
he is the same of model applied to the background sets OK so when we

1850
01:58:25,360 --> 01:58:31,150
apply the this motorbike model to the background we should find anything of high likelihood

1851
01:58:31,170 --> 01:58:33,820
and for the most part that's true

1852
01:58:33,840 --> 01:58:38,240
but there is one incorrect one somewhere here here's an interesting one

1853
01:58:38,740 --> 01:58:44,550
this as far as the models this configuration of detected regions look like a motorbike

1854
01:58:44,570 --> 01:58:47,610
in terms of spatial and appearance the other ones were

1855
01:58:47,670 --> 01:58:50,090
classified correctly

1856
01:58:50,110 --> 01:58:51,950
as background images

1857
01:58:52,010 --> 01:58:53,680
his face model

1858
01:58:53,760 --> 01:58:57,110
this is what i learnt across the faces in c

1859
01:58:57,230 --> 01:58:59,530
it learns are

1860
01:58:59,550 --> 01:59:01,300
some overlap

1861
01:59:01,800 --> 01:59:06,530
between the various parts here there's nothing to exploit that

1862
01:59:06,550 --> 01:59:11,680
aeroplanes you see this spatial model pulls out the fuse large type shape of the

1863
01:59:11,680 --> 01:59:13,680
aeroplane very nicely

1864
01:59:16,300 --> 01:59:20,430
red party it tends to correspond to the tail of the plane

1865
01:59:23,240 --> 01:59:27,220
now in the case of the spotted cats what's all-important is texture

1866
01:59:27,220 --> 01:59:30,400
if you see from the size of these ellipses the

1867
01:59:33,550 --> 01:59:37,550
aspect of the model is relevant larger structure part is irrelevant what's so important to

1868
01:59:37,550 --> 01:59:40,090
the texture

1869
01:59:40,200 --> 01:59:44,740
we in this example is an ordering constraint that's why on the in the extraction

1870
01:59:44,740 --> 01:59:49,360
that's why he's all aligned like this

1871
01:59:49,760 --> 01:59:53,340
and because we have a generative probabilistic model we can sample from

1872
01:59:53,360 --> 01:59:58,610
from models this is showing the same test motorbikes

1873
01:59:58,630 --> 02:00:00,090
some samples which

1874
02:00:00,340 --> 02:00:02,880
for the training images which were assigned to

1875
02:00:02,900 --> 02:00:07,990
each of these parts and sample of their various positions

1876
02:00:09,200 --> 02:00:13,450
some comparison with previous work so well

1877
02:00:13,510 --> 02:00:16,150
this is what his equal error rate

1878
02:00:16,170 --> 02:00:21,650
the various classes equal rate means we find many false positives false negatives so in

1879
02:00:21,650 --> 02:00:22,860
the case of faces

1880
02:00:22,880 --> 02:00:25,760
six percent of the background images

1881
02:00:25,780 --> 02:00:28,360
which had no faces in the set to have faces in the

1882
02:00:28,410 --> 02:00:31,450
and six percent of the foreground images which have faces

1883
02:00:32,240 --> 02:00:35,910
the faces were found again six percent means

1884
02:00:35,930 --> 02:00:40,820
and comparing this to around one thousand yes we do better

1885
02:00:41,340 --> 02:00:43,410
but that's just because we can deal with scale

1886
02:00:43,430 --> 02:00:50,200
you'd expect this was done a year later the would expect to be better

1887
02:00:51,340 --> 02:00:55,630
in some improvement over time on these algorithms

1888
02:00:55,650 --> 02:01:00,930
but in our case we using the same method recognised many different classes all the

1889
02:01:00,930 --> 02:01:04,220
same parameters

1890
02:01:05,510 --> 02:01:10,860
i want to give some idea of whether we benefit from having

1891
02:01:10,900 --> 02:01:15,280
the structure model which is explicit as well as the part model

1892
02:01:15,300 --> 02:01:20,360
experiences so these what is rather showing are where we learn

1893
02:01:20,410 --> 02:01:22,740
structure and the

1894
02:01:23,950 --> 02:01:25,170
so we learn

1895
02:01:25,180 --> 02:01:29,050
everything but then when we come to the recognition we switch off various terms

1896
02:01:29,050 --> 02:01:32,050
so in the case of the motorbikes if we

1897
02:01:32,090 --> 02:01:36,340
use the full model which has both the appearance of the parts and their spatial

1898
02:01:36,340 --> 02:01:38,880
distribution we get the best results

1899
02:01:38,900 --> 02:01:40,470
but most of the meat

1900
02:01:42,180 --> 02:01:45,400
into the recognition mister the bite comes from

1901
02:01:45,430 --> 02:01:50,180
the parents if we have the appearance only but no shape that's this blue curve

1902
02:01:51,470 --> 02:01:52,820
shape only

1903
02:01:52,860 --> 02:01:55,880
this integration so good we still do OK

1904
02:01:55,900 --> 02:02:01,090
contrast that with faces where if we don't have the appearance the result is just

1905
02:02:01,110 --> 02:02:04,400
pretty much the same as chance of the appearance is very important in the face

1906
02:02:04,550 --> 02:02:06,110
the i six

1907
02:02:06,220 --> 02:02:13,950
likewise in the left business spotted cats the position is is largely irrelevant we had

1908
02:02:13,950 --> 02:02:17,820
in additional information actually makes matters worse in this case because of this sort restraint

1909
02:02:17,820 --> 02:02:19,090
i mentioned

1910
02:02:19,110 --> 02:02:22,900
so we get some idea of the relative contribution of these parts

1911
02:02:23,280 --> 02:02:25,910
and the parent sorry in the confederations cup

1912
02:02:27,030 --> 02:02:33,470
because sort of half-hearted assessment and you've look you've learned

1913
02:02:36,200 --> 02:02:38,650
i know i mean the proper thing would be

1914
02:02:38,720 --> 02:02:42,720
which we haven't done yes we'll do is to both in the in the learning

1915
02:02:42,720 --> 02:02:49,150
just use parts and not the configuration and then in the recognition just use parts

1916
02:02:49,150 --> 02:02:51,530
of information really which we have to do that

1917
02:02:52,240 --> 02:02:56,680
probably the learning and recognition but what's going on here is well

1918
02:02:56,720 --> 02:03:00,090
we're just not taking when we fit the model when not taking any

1919
02:03:00,150 --> 02:03:01,820
account of say the

1920
02:03:01,820 --> 02:03:06,130
the appearance garcia that's what this means here

1921
02:03:06,900 --> 02:03:08,760
just giving some feel for

1922
02:03:08,780 --> 02:03:12,630
the contribution of the two parts of the model

1923
02:03:12,630 --> 02:03:17,430
obviously it's an interesting question how much the gain by having

1924
02:03:17,450 --> 02:03:21,380
the structure and this much has this tighter structure model which is what you can

1925
02:03:21,400 --> 02:03:22,860
talk about soft it

1926
02:03:38,430 --> 02:03:45,320
my understanding and this is what i focus and he

1927
02:03:45,320 --> 02:03:48,950
it is and that's what's done that you

1928
02:03:48,950 --> 02:03:52,550
you get the assignment of the parts to save so we just can use integration

1929
02:03:52,550 --> 02:03:55,630
as we assign the best part but we don't take into account the problem you

1930
02:03:55,630 --> 02:03:59,450
know it doesn't matter as if it when signed partners probability of how close it

1931
02:03:59,450 --> 02:04:03,860
is to the cluster centre we're not using that's happened on the assignment we just

1932
02:04:03,860 --> 02:04:05,820
use the configuration

1933
02:04:05,840 --> 02:04:07,990
we don't have accounts for

1934
02:04:08,010 --> 02:04:12,510
OK quickly going to talk about a couple of

1935
02:04:14,850 --> 02:04:16,260
all of this model

1936
02:04:16,340 --> 02:04:23,360
one is to loosen up the structure so so far we talked about it structure

1937
02:04:23,380 --> 02:04:27,300
which is a guassian jointly in the position of all parts

1938
02:04:28,470 --> 02:04:32,900
there's no reason why we can't have a slightly looser structure which is a star

1939
02:04:33,820 --> 02:04:37,450
where we only record the positions relative to some anchor point in this case x

1940
02:04:39,450 --> 02:04:41,670
now that there is no explicit

1941
02:04:43,150 --> 02:04:45,680
now model of the

1942
02:04:45,680 --> 02:04:47,050
gas gas

1943
02:04:47,070 --> 02:04:50,840
position between six one x five is already said this anchor point


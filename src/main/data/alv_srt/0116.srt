1
00:00:00,000 --> 00:00:03,310
so we've created a permanent magnet

2
00:00:03,310 --> 00:00:06,310
so in the location at the location e

3
00:00:07,650 --> 00:00:08,500
we have

4
00:00:08,560 --> 00:00:10,660
being vacuum

5
00:00:10,690 --> 00:00:12,850
is zero

6
00:00:12,850 --> 00:00:14,500
but b prime

7
00:00:14,550 --> 00:00:17,560
which is the result of those lines

8
00:00:17,570 --> 00:00:19,220
magnetic moments

9
00:00:19,310 --> 00:00:22,870
is still in this direction nothing is to scale of course

10
00:00:22,940 --> 00:00:25,610
so you still have a magnetic field

11
00:00:25,610 --> 00:00:27,610
now i reversed the current

12
00:00:27,620 --> 00:00:32,910
i go counter-clockwise so i'm creating a magnetic field back you know in this direction

13
00:00:33,080 --> 00:00:36,750
now what happened this curve i come up here

14
00:00:36,800 --> 00:00:38,160
look now here

15
00:00:38,300 --> 00:00:41,040
this location q what we have now

16
00:00:41,110 --> 00:00:43,160
i have something very bizarre

17
00:00:43,180 --> 00:00:44,920
i have now situation

18
00:00:44,970 --> 00:00:48,650
well by the vacuum field is in this direction but there is no magnetic field

19
00:00:50,260 --> 00:00:54,140
the materials the magnetic field inside is zero

20
00:00:54,170 --> 00:00:56,780
so when we have one q

21
00:00:56,820 --> 00:00:59,320
so we have the vacuum

22
00:00:59,330 --> 00:01:00,970
it is in this direction

23
00:01:01,030 --> 00:01:04,070
the inside the prime

24
00:01:04,120 --> 00:01:07,300
we're not primarily

25
00:01:07,320 --> 00:01:09,690
the total field inside is zero

26
00:01:09,750 --> 00:01:14,170
the reason being that b prime is still in this direction

27
00:01:14,210 --> 00:01:18,540
the reason being that the domains are still alive in this direction and so the

28
00:01:18,540 --> 00:01:19,710
vacuum field

29
00:01:19,720 --> 00:01:22,830
was the prime field which has to be externally at it

30
00:01:22,830 --> 00:01:25,070
that's up was in that field zero

31
00:01:25,190 --> 00:01:26,970
these are

32
00:01:27,000 --> 00:01:30,700
now i increase the current but i keep going counterclockwise

33
00:01:30,750 --> 00:01:33,390
and so the magnetic field vacuum

34
00:01:33,420 --> 00:01:35,690
this direction

35
00:01:35,750 --> 00:01:38,780
i go into saturation again

36
00:01:38,780 --> 00:01:42,290
in a similar way that went into saturation here

37
00:01:42,300 --> 00:01:43,870
now i stop here

38
00:01:43,890 --> 00:01:46,630
i don't want to lose my approach

39
00:01:46,680 --> 00:01:52,000
and i stop here and i say to the current go back to zero again

40
00:01:52,010 --> 00:01:55,080
so my current now goes back to zero

41
00:01:55,080 --> 00:01:56,570
there we go

42
00:01:56,630 --> 00:01:58,700
now i arrive here

43
00:01:58,720 --> 00:01:59,810
point as

44
00:02:00,540 --> 00:02:02,380
and again i have a situation

45
00:02:02,390 --> 00:02:05,130
that my vacuum field is zero

46
00:02:05,170 --> 00:02:08,040
i could take the material out of the solenoid

47
00:02:08,040 --> 00:02:12,110
just walk around with it the street it will be permanent magnet

48
00:02:12,950 --> 00:02:17,110
the magnetic field inside this material important people's in this direction

49
00:02:17,110 --> 00:02:19,640
if i take it out here that is necessary

50
00:02:19,650 --> 00:02:23,130
now some domains stay aligned in this direction

51
00:02:23,160 --> 00:02:27,960
the reason was that i had counterclockwise current so those domains flipped over and then

52
00:02:27,960 --> 00:02:32,580
all willing to flip back again so i've also made a permanent magnet here

53
00:02:32,590 --> 00:02:33,960
vacuum field zero

54
00:02:33,980 --> 00:02:35,620
the b prime

55
00:02:35,620 --> 00:02:37,650
now in the opposite direction

56
00:02:37,670 --> 00:02:38,910
and then

57
00:02:38,960 --> 00:02:40,760
if i continue now

58
00:02:40,840 --> 00:02:43,840
go clockwise current again and increase

59
00:02:44,790 --> 00:02:46,560
i and the there

60
00:02:46,570 --> 00:02:49,420
and and this is bizarre curve we call this the

61
00:02:49,480 --> 00:02:50,640
his stories

62
00:02:53,260 --> 00:02:55,700
if you look at this curve

63
00:02:55,750 --> 00:02:57,200
it's really

64
00:02:57,210 --> 00:02:59,160
amazing is that hard to

65
00:02:59,210 --> 00:03:01,630
to digest this you you have to give it

66
00:03:01,630 --> 00:03:03,460
a little bit of thought

67
00:03:04,480 --> 00:03:07,990
for one particular value of the current

68
00:03:08,000 --> 00:03:09,350
for instance

69
00:03:10,960 --> 00:03:15,810
one a particular value of the current i noted the vacuum is given

70
00:03:15,850 --> 00:03:17,710
i have two possibilities here

71
00:03:17,730 --> 00:03:19,150
for the magnetic field

72
00:03:19,210 --> 00:03:21,200
and for the current year

73
00:03:21,220 --> 00:03:23,070
i have two possibilities

74
00:03:23,070 --> 00:03:24,700
for the magnetic field

75
00:03:24,810 --> 00:03:25,600
and so

76
00:03:25,650 --> 00:03:29,690
i cannot even know when i take this material and i exposed to an external

77
00:03:29,690 --> 00:03:33,350
field i can even calculate what the magnetic field inside will be

78
00:03:33,400 --> 00:03:34,880
it depends on the history

79
00:03:34,900 --> 00:03:35,890
of this

80
00:03:44,210 --> 00:03:46,890
look at this point here

81
00:03:46,960 --> 00:03:48,550
and at this point there

82
00:03:48,550 --> 00:03:51,260
if i asked you what kappa

83
00:03:51,400 --> 00:03:53,470
it's almost ridiculous questions

84
00:03:54,400 --> 00:03:56,190
one is kept him

85
00:03:56,230 --> 00:03:57,940
i have

86
00:03:57,960 --> 00:04:00,720
i have the vacuum field

87
00:04:00,810 --> 00:04:04,310
but i have no field inside

88
00:04:04,360 --> 00:04:07,840
so the field inside which is b is zero

89
00:04:07,890 --> 00:04:11,930
back in field is non-zero so you would have to answer kappa and is zero

90
00:04:11,950 --> 00:04:13,640
the the only thing you could say

91
00:04:13,640 --> 00:04:15,030
quite bizarre right

92
00:04:15,040 --> 00:04:17,170
right here is vacuum field

93
00:04:17,280 --> 00:04:18,860
no field inside

94
00:04:18,890 --> 00:04:25,280
kappa amazonian kappa m is zero here and remember it was one thousand

95
00:04:25,290 --> 00:04:28,100
look at the situation take this point of the curve

96
00:04:28,170 --> 00:04:30,120
this point of the curve

97
00:04:31,140 --> 00:04:33,630
it's less than zero is negative

98
00:04:33,640 --> 00:04:37,080
because here the vacuum field is in this direction

99
00:04:37,100 --> 00:04:40,690
b prime is in that direction so in opposite direction sort the net

100
00:04:42,060 --> 00:04:46,690
it in that direction the vacuum is in this direction and he has also refers

101
00:04:46,750 --> 00:04:48,670
so the bizarre situation

102
00:04:48,720 --> 00:04:52,380
that you are effectively having situation to pi kappa m is zero

103
00:04:52,390 --> 00:04:54,010
kappa alpha and can also be

104
00:04:55,410 --> 00:04:56,380
for those

105
00:04:56,400 --> 00:04:58,990
points that i have there

106
00:04:59,090 --> 00:05:01,810
i can show you this hysteresis curve

107
00:05:01,820 --> 00:05:03,650
and i do it exactly the way

108
00:05:04,320 --> 00:05:07,980
i explained to you except that i will not be able to run

109
00:05:08,040 --> 00:05:12,110
this current very slowly up and down i do it with sixty hertz

110
00:05:12,130 --> 00:05:14,930
alternating current get out of the

111
00:05:14,960 --> 00:05:16,130
the wall

112
00:05:16,220 --> 00:05:18,290
so i run through this

113
00:05:18,300 --> 00:05:21,920
the solenoid and sixty hertz

114
00:05:21,940 --> 00:05:24,730
alternating current

115
00:05:24,780 --> 00:05:28,710
that means we got through this curve very quickly back and forth

116
00:05:28,760 --> 00:05:31,180
in this morning maximum current

117
00:05:31,190 --> 00:05:33,330
and this point maximum current

118
00:05:33,400 --> 00:05:38,870
current clockwise counter-clockwise clockwise counter-clockwise and we aims at sixty times a second

119
00:05:38,870 --> 00:05:42,040
then we see that there is a role not so very

120
00:05:42,740 --> 00:05:47,360
well you're the only very systematic and you see is that the thalamus pick speech

121
00:05:47,360 --> 00:05:49,600
much earlier than the

122
00:05:50,270 --> 00:05:52,320
the cortex

123
00:05:53,460 --> 00:06:01,080
that's what you see that there are not so very systematic differences between right brother

124
00:06:01,130 --> 00:06:03,540
point for instance typical point

125
00:06:05,740 --> 00:06:09,860
and now this

126
00:06:11,530 --> 00:06:18,960
another point is I have to be computed wouldn't response so far maybe thousands of

127
00:06:19,320 --> 00:06:23,330
points in the brain and I have shown only 4 of them but the question

128
00:06:23,330 --> 00:06:26,470
is how can we get a little bit more insight in the rest of the

129
00:06:26,470 --> 00:06:32,720
hemodynamic responses because well maybe I just selected the wrong 1 Soriano some of them

130
00:06:33,000 --> 00:06:39,070
the 1 just selected some points and I we don't have enough responses there but

131
00:06:39,070 --> 00:06:43,180
how can we visualize what's happening in all the other points of the brain

132
00:06:44,460 --> 00:06:51,560
now that was the problem we by applying theoretical clustering and very short of that

133
00:06:51,560 --> 00:06:55,260
most of you are very familiar with this but nevertheless

134
00:06:55,270 --> 00:06:59,490
are also very briefly through it's it's also an hour and a half an algorithm

135
00:07:00,590 --> 00:07:09,360
and implemented in C to do have a few two-dimensional points here could also be

136
00:07:09,360 --> 00:07:12,020
an n-dimensional but

137
00:07:12,030 --> 00:07:18,570
dimensions and that the difficult to work with them to draw drop them of these

138
00:07:18,570 --> 00:07:26,030
these items there are grouped by 1st selecting the 2 closest points and the

139
00:07:27,200 --> 00:07:31,820
of the remainder to look at to get the points toward and closest groups who

140
00:07:31,820 --> 00:07:33,640
were closest closest

141
00:07:33,980 --> 00:07:36,380
and then they are connected

142
00:07:36,900 --> 00:07:38,200
and so on

143
00:07:39,180 --> 00:07:46,540
and then finally you end up with a dendrogram which suggests that summer and you

144
00:07:46,580 --> 00:07:50,660
if you go to the value of 1 and 3 are in 1 group 2

145
00:07:51,060 --> 00:07:57,880
4 5 in 1 programs and tuition and separate that that's the algorithm that applied

146
00:07:57,920 --> 00:08:02,620
on the estimated permanent responses so we that for all these 10 thousand points

147
00:08:03,140 --> 00:08:09,180
and then we got something very systematic at least in the subject that show here

148
00:08:09,260 --> 00:08:14,840
so what I have so what we did is we applied this clustering algorithms on

149
00:08:14,840 --> 00:08:16,640
behalf of American responses

150
00:08:17,990 --> 00:08:24,290
the shape of the hemodynamic responses and I get this same goal or to all

151
00:08:24,290 --> 00:08:27,860
points uh well from the same cluster

152
00:08:29,800 --> 00:08:34,000
and and probably get and it is only of course for the for the most

153
00:08:36,680 --> 00:08:38,580
government responses

154
00:08:40,560 --> 00:08:47,640
now this year 2 clusters representing the activity of the eyes so for summary the

155
00:08:47,640 --> 00:08:54,180
motion of the I by assume that this is motion because it's been instantaneously and

156
00:08:54,580 --> 00:08:59,260
now from the motion of the items to be correlated to the to the alpha

157
00:08:59,760 --> 00:09:01,180
and therefore also to bold

158
00:09:01,960 --> 00:09:07,000
and the fire and here I probably have remember responses all these different regions and

159
00:09:07,000 --> 00:09:12,280
I ordered them but 1st I call this the positive ones and the negative ones

160
00:09:12,280 --> 00:09:14,260
and these ones are ordered in time

161
00:09:16,260 --> 00:09:22,520
and now we see here the first one corresponds to the Deuteronomists this 1 into

162
00:09:22,520 --> 00:09:30,440
corresponds to the ventricles and these are the ones that correspond to the cortex and

163
00:09:30,450 --> 00:09:33,160
if you look carefully at the order of the order of things

164
00:09:34,040 --> 00:09:46,580
the photos and is assumed 7 temporal order in these curves if you follow this

165
00:09:46,580 --> 00:09:51,680
course than it seems as if the pattern starting and spreading out from here to

166
00:09:51,680 --> 00:09:56,640
there but you should have more clearly in the next slide vertical account is chosen

167
00:09:56,720 --> 00:10:01,160
the bits that are usually the peak times over

168
00:10:01,290 --> 00:10:07,070
of the cluster that ranges from 6 to 12 seconds so dark means that it's

169
00:10:07,460 --> 00:10:13,740
speaking earlier and then it's so starts here and it spreads out from here or

170
00:10:13,740 --> 00:10:19,100
familiar to the outside of the cortex and here have another problem which starts here

171
00:10:19,100 --> 00:10:20,700
and and also spreads out

172
00:10:21,780 --> 00:10:27,080
so that we could interpret this as as a kind of wave which is traveling

173
00:10:27,390 --> 00:10:34,450
corporations vectors to to be algorithm however and this could also be used 1 and

174
00:10:34,450 --> 00:10:38,700
the potential could be adopted some of us really something to do with the alphabet

175
00:10:38,700 --> 00:10:44,180
geology patient could of course be just simply hemodynamic responses vary from point to point

176
00:10:44,180 --> 00:10:49,500
in the brain and there and you can and then the happened the shape of

177
00:10:49,500 --> 00:10:55,660
the responses also determined by the by the infrastructure the micro and anatomy of the

178
00:10:55,880 --> 00:11:01,160
of the blocks fossils in the cortex and if that's the explanation that this picture

179
00:11:01,640 --> 00:11:08,500
picture shows that we should be very careful in analyzing and interpreting time delays which

180
00:11:08,500 --> 00:11:10,600
you get from fumbled signals

181
00:11:12,320 --> 00:11:16,800
the ultimate test of course would be to determine heavily responses from

182
00:11:16,920 --> 00:11:21,890
sensory motor task and compare remark that for the same subject but there will be

183
00:11:21,890 --> 00:11:28,890
so that dominant responses of artificial of tasks so that you know what I but

184
00:11:28,990 --> 00:11:33,770
this is just a general relative something to do with the the the movement of

185
00:11:33,770 --> 00:11:34,610
the operator

186
00:11:36,170 --> 00:11:41,900
now being that these data there are recorded from Subject 3 hour for half an

187
00:11:41,900 --> 00:11:46,740
hour in the scanners eyes closed and where they were instructed not to fall asleep

188
00:11:47,260 --> 00:11:52,360
at the end that that was only an instruction and of course everybody says knowledgeable

189
00:11:52,360 --> 00:11:58,180
to probably don't know ahead of time uh that we recorded the heart beat the

190
00:11:58,980 --> 00:12:02,260
to correct the EEG signal

191
00:12:03,320 --> 00:12:10,700
and we also have used the heartbeat to correct for artifacts in the fMRI but

192
00:12:10,880 --> 00:12:15,000
and for that we use the method of universal that's that's what I want to

193
00:12:15,000 --> 00:12:22,230
stress here is that the heart of this not meeting regular marginal it's almost 1

194
00:12:22,230 --> 00:12:27,080
per 2nd but not extremely regular it's not extremely regular there are some variations in

195
00:12:27,080 --> 00:12:31,860
it even if the subject is lying in scanner eyes closed trying not to fall

196
00:12:31,860 --> 00:12:38,080
asleep you see here that the heart the intervals of hardly are high hired and

197
00:12:38,340 --> 00:12:43,680
in the fall so short review faster beating heart and and here we get to

198
00:12:43,680 --> 00:12:49,620
the 2nd part of the determined the heart rate so that are in the false

199
00:12:49,640 --> 00:12:54,560
over time for every 3 seconds to get a signal which looks like this problem

200
00:12:54,560 --> 00:12:58,760
leverage in this case subjected source 1 1 . 1 . 2

201
00:12:59,620 --> 00:13:03,840
and varies between 1 . 4 and and approximately

202
00:13:04,040 --> 00:13:08,820
if you have a very good memory for signals that have the right to recall

203
00:13:08,820 --> 00:13:11,560
on the longer side

204
00:13:17,680 --> 00:13:21,880
let's see

205
00:13:25,710 --> 00:13:28,980
this sort of one more piece that i want to show

206
00:13:29,030 --> 00:13:30,910
to get there i had to write down

207
00:13:30,950 --> 00:13:35,400
unfortunately large amounts of that this was postponed

208
00:13:50,060 --> 00:13:56,220
so the m step we want to maximize

209
00:13:56,260 --> 00:14:05,380
and all expectations are was where respect as you are drawn from the distribution q

210
00:14:05,380 --> 00:14:08,830
y sometimes i be sloppy just made this

211
00:14:19,650 --> 00:14:22,210
and now all on

212
00:14:22,780 --> 00:14:24,230
this distribution

213
00:14:24,320 --> 00:14:29,490
here's the i p x i give the i that is the calcium density

214
00:14:29,500 --> 00:14:35,010
because of its size differs e i

215
00:14:36,030 --> 00:14:40,320
this is calcium given by very new

216
00:14:40,690 --> 00:14:44,370
and covariance i

217
00:14:44,380 --> 00:14:48,320
and so on in this step in the derivation i will actually go ahead and

218
00:14:48,320 --> 00:14:49,640
substitute in

219
00:14:49,730 --> 00:14:53,570
the formula of the gaussians density so i will go ahead and take this and

220
00:14:53,570 --> 00:14:58,150
you can see here one of the key to be able to do

221
00:14:58,160 --> 00:15:02,100
on side interest you to

222
00:15:02,280 --> 00:15:03,600
so will go put the

223
00:15:03,630 --> 00:15:07,830
gas density and when you do that you find that you get

224
00:15:07,890 --> 00:15:13,240
on notation

225
00:15:18,480 --> 00:15:20,830
i forgot to say

226
00:15:20,850 --> 00:15:22,470
to maintain so the

227
00:15:22,560 --> 00:15:27,040
one of the two two two not make the derivation too complicated and actually just

228
00:15:27,040 --> 00:15:29,740
going to maximize this with respect to the parameters lambda

229
00:15:30,160 --> 00:15:31,510
it's so just another the

230
00:15:31,540 --> 00:15:35,470
so you want to maximize its respect along the side new but just to keep

231
00:15:35,490 --> 00:15:39,720
the amount of mapping saying just going to show how to maximise is

232
00:15:39,720 --> 00:15:43,730
respect to the matrix long pretend sign

233
00:15:43,750 --> 00:15:47,810
and so on it's such an accountant as you get some expert in expected value

234
00:15:47,810 --> 00:15:53,200
for constant on because i may depend on size but not on longer

235
00:15:53,210 --> 00:15:55,540
the mine is on

236
00:15:55,600 --> 00:16:01,800
this thing

237
00:16:02,120 --> 00:16:17,200
on and the quadratic terms essentially came from

238
00:16:17,330 --> 00:16:22,290
the exponent in your house in density when i take longer one

239
00:16:22,350 --> 00:16:25,820
they end up with this quadratic term

240
00:16:29,350 --> 00:16:32,400
and then

241
00:16:32,400 --> 00:16:35,400
and so if you take the derivative is

242
00:16:35,580 --> 00:16:41,720
the expression of

243
00:16:41,720 --> 00:16:50,690
with respect to the matrix longer

244
00:16:50,700 --> 00:16:55,760
and you said that zero

245
00:16:55,820 --> 00:17:01,200
right so we want to maximize this expression prospective parents longer

246
00:17:01,210 --> 00:17:04,040
so you take the derivative of disrespect along there

247
00:17:06,140 --> 00:17:08,220
one on

248
00:17:08,270 --> 00:17:11,080
this editor to visit expression

249
00:17:11,260 --> 00:17:16,630
of zero set there it is easier to maximizing

250
00:17:17,670 --> 00:17:19,730
when you do that to simplify

251
00:17:20,060 --> 00:17:23,460
you end up with the forward

252
00:17:48,100 --> 00:18:09,620
OK so that's the

253
00:18:09,630 --> 00:18:16,040
on the m step this is the value that does the value should get on

254
00:18:16,090 --> 00:18:19,730
that use of europe parameters lambda

255
00:18:19,750 --> 00:18:21,920
and again the expectations

256
00:18:22,040 --> 00:18:33,910
all i with respect to zeid drawn from the distributions q i

257
00:18:35,670 --> 00:18:40,230
the very last step of this derivation is are we need to work out

258
00:18:40,410 --> 00:18:43,970
what these two expectations are

259
00:18:44,020 --> 00:18:48,980
and so the very first term i

260
00:18:48,990 --> 00:18:59,540
again it's just mu of arms given x i transpose because because the QI distributions

261
00:18:59,540 --> 00:19:01,410
has mean given by the

262
00:19:05,930 --> 00:19:07,730
to work out the other term

263
00:19:09,770 --> 00:19:13,310
just remind you idea is that if

264
00:19:13,340 --> 00:19:16,550
if you have a random variables e

265
00:19:16,570 --> 00:19:20,260
this calcium music sick well

266
00:19:20,280 --> 00:19:24,740
the the covariance matrix the

267
00:19:24,760 --> 00:19:27,690
i minus e

268
00:19:29,530 --> 00:19:36,830
that you know one of the definitions of the covariance

269
00:19:36,850 --> 00:19:40,780
and so this implies that is easy transfer calls

270
00:19:40,820 --> 00:19:44,700
so what you see

271
00:19:50,850 --> 00:19:53,990
and so the second term here

272
00:19:56,340 --> 00:19:57,820
on becomes

273
00:20:01,050 --> 00:20:03,890
i i

274
00:20:03,950 --> 00:20:09,020
was so

275
00:20:17,550 --> 00:20:19,220
OK think

276
00:20:19,220 --> 00:20:22,380
multiplication that's required over and above what you would've

277
00:20:22,380 --> 00:20:24,780
done if you just done the com computatation anyway in the

278
00:20:24,780 --> 00:20:30,420
feature space so it's certainly not an overload of a of computation here you know

279
00:20:30,420 --> 00:20:33,400
this might be a D dimensional vector so you'd have to

280
00:20:33,400 --> 00:20:37,780
do D multiplications and D minus one additions anyway

281
00:20:38,120 --> 00:20:47,940
I'm always saying is do one more multiplication okay so it's a very minor additional load now what I

282
00:20:47,940 --> 00:20:50,780
can claim is this actually corresponds to an inner

283
00:20:50,780 --> 00:20:59,760
product in a in a complex feature space well why okay this is what I've written I'm now just using a different notation here X prime Z

284
00:20:59,760 --> 00:21:03,660
squared is just another way of expressing this but now

285
00:21:03,660 --> 00:21:09,040
I can actually swap one of these two round the order

286
00:21:09,040 --> 00:21:13,980
and change the bracketing and I get Z X X primed Z so

287
00:21:13,990 --> 00:21:20,160
X X prime is a matrix and so this is a a matrix

288
00:21:20,160 --> 00:21:28,400
with a row vector time to column vector and in fact this is now the frobenius in a product between

289
00:21:28,400 --> 00:21:32,860
two matrices or the inner product between two vectors where you

290
00:21:32,840 --> 00:21:42,460
vectorize the matrix Z Z primed and the matrix X X primed if you're you know if you're not sure that you're

291
00:21:42,450 --> 00:21:47,700
happy with that derivation here it's very easy just to write it out explicitly just write the

292
00:21:47,700 --> 00:21:50,640
sums down on the piece of paper and you'll see that it works out it's very

293
00:21:50,630 --> 00:21:56,760
easy this is just a a you know a slightly maybe slick away of showing it but if

294
00:21:56,760 --> 00:21:59,060
you're not happy just write out the sums and you'll see that

295
00:21:59,060 --> 00:22:02,480
it it actually words that this actually corresponds to an

296
00:22:02,500 --> 00:22:10,100
inner product between these this feature vector for X sorry this where I've gone this a wrong way around but anyway what whichever

297
00:22:10,100 --> 00:22:19,470
this feature vector for X and this feature vector for Z so what it what it corresponds to is taking instead of just say

298
00:22:19,460 --> 00:22:28,400
D components they're now D squared components where the components are the products of the features of

299
00:22:28,400 --> 00:22:33,550
the original feature vector so there's a feature for X I X J

300
00:22:33,900 --> 00:22:37,000
and there's actually another feature for X J X I so you are sort of double counting actually you get

301
00:22:37,280 --> 00:22:40,640
you know repeated features but there's certainly N

302
00:22:40,640 --> 00:22:46,840
choose two different or N plus one choose two different sorry N choose two

303
00:22:46,880 --> 00:22:50,320
different features here so the features space dimension has

304
00:22:50,320 --> 00:22:55,440
been significantly increased compared to the original input

305
00:22:55,440 --> 00:23:01,070
space and I'll make that explicit with an example of say

306
00:23:01,680 --> 00:23:05,880
doing a regression over a set of images so think of

307
00:23:05,890 --> 00:23:20,040
pixel vectors which might be thirty-two by thirty-two pixel images so the input space dimension is a thousand and twenty-four dimensions so D in this case is a thousand twenty-four if we use the quadratic kernel we're implementing

308
00:23:20,040 --> 00:23:28,700
regression in a million dimensional space right roughly thousand squared or well five thousand dimension if you take into

309
00:23:28,700 --> 00:23:34,140
account some of them are the same but certainly a very very high-dimensional space and the

310
00:23:34,140 --> 00:23:38,160
cost of doing it is actually lower than doing it in the

311
00:23:38,160 --> 00:23:42,150
original space because we're having to invert the thousand by

312
00:23:42,200 --> 00:23:46,940
thousand matrix that's the dimension of the training set as

313
00:23:46,940 --> 00:23:50,680
opposed to a thousand and twenty-four by a thousand twenty-four dimensional

314
00:23:50,680 --> 00:23:55,740
matrix which we would've had if we done the explicit computation in the input space so

315
00:23:55,740 --> 00:23:59,660
we're running ridge regression in a hugely more powerful space

316
00:24:00,060 --> 00:24:05,240
at no extra cost or in fact reduced cost compared to the doing

317
00:24:05,240 --> 00:24:10,880
a primal sort of normal ridge regression without the kernel trick

318
00:24:12,160 --> 00:24:25,340
okay there's a slight caveat to that that when your evaluating on a new test point it is gonna be more complex because you have to run over in order to compute the let

319
00:24:25,340 --> 00:24:29,160
me go back to the evaluation on a test point here in

320
00:24:29,160 --> 00:24:31,520
order to evaluate over the test point all of these alphas

321
00:24:31,520 --> 00:24:34,400
are gonna be nonzero and so you're gonna have to compute the inner

322
00:24:34,440 --> 00:24:39,700
products between the test point and each of the or the kernel function

323
00:24:39,710 --> 00:24:42,360
sorry which means the test point in each of the training data so

324
00:24:42,360 --> 00:24:45,690
it's gonna be a thousand of these to compute so it's a

325
00:24:45,680 --> 00:24:48,360
thousand times a thousand cause there are thousand dimensionals so that's a

326
00:24:48,360 --> 00:24:52,920
million computations to do this whereas in if we had an

327
00:24:52,920 --> 00:24:57,060
explicit vector in the input in in in primal

328
00:24:57,050 --> 00:25:00,520
space it would just be a thousand computations so that that

329
00:25:00,520 --> 00:25:11,820
is a slight caveat here but certainly in solving the the problem actually learning the alpha vector is less expensive than

330
00:25:11,820 --> 00:25:18,940
learning the primal vector in the original space okay so

331
00:25:19,400 --> 00:25:25,940
what are the implications so what we've actually done we've performed linear

332
00:25:25,940 --> 00:25:29,060
regression in a very high-dimensional and in fact even can be done in

333
00:25:29,060 --> 00:25:32,920
infinite dimensional spaces efficiently through

334
00:25:32,920 --> 00:25:37,260
this kernel trick it's equivalent to performing

335
00:25:37,260 --> 00:25:41,180
non-linear regression in the original input space so we've

336
00:25:41,180 --> 00:25:45,080
effectively moved to doing a non-linear regression in

337
00:25:45,060 --> 00:25:50,280
some sense in the sense that the final function that

338
00:25:50,280 --> 00:25:54,640
you're actually learning has a form in this case where

339
00:25:54,640 --> 00:25:59,180
we use the quadratic kernel this is the form it's a sum of

340
00:25:59,180 --> 00:26:03,060
alpha rhi inner product X I X squared so it's it's actually a

341
00:26:03,120 --> 00:26:08,060
non-linear function i's a quadratic polynomial function of the of

342
00:26:08,060 --> 00:26:11,800
the components of the input vector so we're actually doing

343
00:26:11,980 --> 00:26:19,040
non-linear regression but in a way that retains the attractive features of linear regression that

344
00:26:19,040 --> 00:26:23,780
there's a unique global solution we can find it fast by

345
00:26:23,810 --> 00:26:32,880
simple inversion of a of a matrix so it seems to be you know magic the best of all possible worlds

346
00:26:32,880 --> 00:26:37,720
in a sense but you know there must be some warnings there must be

347
00:26:37,720 --> 00:26:41,220
some problems here and clearly there is the curse of

348
00:26:41,220 --> 00:26:51,390
dimensionality working in high-dimensional spaces is dangerous and you are liable to overfit your data I kind of aluded to how that's overcome by

349
00:26:51,810 --> 00:26:55,440
controlling that weight vector norm is effectively controlling

350
00:26:55,440 --> 00:26:59,740
the complexity so it's sort of giving with one hand and

351
00:26:59,740 --> 00:27:04,940
taking back with the other you're giving lots and lots of dimensions wtih a kernel trick but you're

352
00:27:04,940 --> 00:27:10,040
actually trying to you know keep a tight control on

353
00:27:10,040 --> 00:27:14,750
their use trough the regularisation of the weight vector norm

354
00:27:15,500 --> 00:27:22,240
so it's a kind of a let's the data decide in a sense how much complexity is

355
00:27:22,230 --> 00:27:27,480
actually needed and that seems to be a very effective way of operating you

356
00:27:27,470 --> 00:27:41,240
you kind of don't try and a priori say how much complexity you need you give a lot of complexity but you try and keep a tight control on its use and hopefully that actually ends you up with the right

357
00:27:41,240 --> 00:27:49,660
level of usage of complexity for the problem that you're actually trying to solve so that's one of the ways in which the curse of

358
00:27:49,660 --> 00:27:52,600
dimensionality is handled within kernel methods generally and the

359
00:27:52,600 --> 00:27:55,940
same applies to support vector machines and and most of the

360
00:27:55,940 --> 00:27:59,300
other techniques that very similar approaches adopted in

361
00:27:59,300 --> 00:28:02,400
terms of controlling complexity so I'm doing a hand waving

362
00:28:02,400 --> 00:28:06,000
argument here I'll I'll give a little bit more of a concrete

363
00:28:06,000 --> 00:28:10,110
example of statistical analysis in the support vector case

364
00:28:10,110 --> 00:28:15,310
with respect to some information need and that's because relevant entities so

365
00:28:15,330 --> 00:28:16,050
you know

366
00:28:16,060 --> 00:28:22,150
we could think of concepts or topics categories are named entities or user interests are

367
00:28:22,150 --> 00:28:26,120
not directly observable but rather we can only indirectly

368
00:28:26,140 --> 00:28:27,790
in front them

369
00:28:27,810 --> 00:28:30,020
you know based on

370
00:28:30,190 --> 00:28:34,000
what what what's given say just text based on the text we we might be

371
00:28:34,000 --> 00:28:39,510
interested in identifying concepts and topics and things like this so the observable we will

372
00:28:40,190 --> 00:28:46,250
in industry and we can talk about text annotation document structure link structure user actions

373
00:28:46,250 --> 00:28:50,140
and so on and so forth and the idea is that just having the raw

374
00:28:50,140 --> 00:28:53,780
data is not enough to get to this more semantic level

375
00:28:53,800 --> 00:29:00,130
of information content OK so there's an inference problem here that you know how can

376
00:29:00,130 --> 00:29:04,730
we get away automatically inferring for information content based on

377
00:29:04,750 --> 00:29:07,160
raw data so this will be the the

378
00:29:07,170 --> 00:29:13,480
the topic of my tree OK and now to give you an overview of how

379
00:29:13,480 --> 00:29:17,930
the tree structured part one is today in part two is on friday

380
00:29:17,950 --> 00:29:23,910
so i will mainly deals just with what's called adhoc retrieval which just means search

381
00:29:23,920 --> 00:29:29,300
OK search engines if you like today and then with some supervised learning techniques in

382
00:29:29,300 --> 00:29:31,720
information retrieval on friday

383
00:29:31,740 --> 00:29:35,400
and this will not cover

384
00:29:35,430 --> 00:29:37,720
kind of everything but rather i'd like to

385
00:29:37,740 --> 00:29:39,090
pick a few

386
00:29:39,330 --> 00:29:42,650
topics and then go more in depth with these

387
00:29:42,670 --> 00:29:44,330
topics OK so

388
00:29:44,340 --> 00:29:46,700
so we start today with the

389
00:29:46,710 --> 00:29:50,000
the adhoc retrieval problems

390
00:29:52,280 --> 00:29:53,840
adhoc retrieval

391
00:29:54,430 --> 00:29:57,590
you know everyone is familiar with the situation

392
00:29:57,600 --> 00:30:02,630
we assume that you know there's some document collection we have some interface there's a

393
00:30:02,630 --> 00:30:06,700
user that has an immediate information need usually we don't assume that we know anything

394
00:30:06,700 --> 00:30:11,040
about the history of the user and the information need is expressed in terms of

395
00:30:11,040 --> 00:30:13,910
the query right so we have

396
00:30:13,930 --> 00:30:17,730
there's the magic here really in the talk retrieval

397
00:30:17,740 --> 00:30:23,170
that you know we have a search box like this and we type in very

398
00:30:23,180 --> 00:30:27,670
one or two key words very short incomplete ambiguous

399
00:30:28,560 --> 00:30:33,190
but still somehow you know based on the able to identify pull relevant documents and

400
00:30:33,240 --> 00:30:36,120
are able to identify what the user wants right

401
00:30:37,230 --> 00:30:37,970
this is

402
00:30:37,990 --> 00:30:40,340
this is the goal and you know of course

403
00:30:40,350 --> 00:30:44,910
if we look at the web nowadays search engines and

404
00:30:44,920 --> 00:30:48,600
you know finding information using

405
00:30:48,620 --> 00:30:53,350
these forms of search is very popular and and about a third of the internet

406
00:30:53,350 --> 00:30:57,380
users use search engines on a typical day

407
00:30:57,390 --> 00:31:02,230
OK and this is from two thousand two it's probably increased since then

408
00:31:02,280 --> 00:31:05,780
OK so

409
00:31:05,790 --> 00:31:09,740
so where the challenge you can certainly try to illustrate

410
00:31:09,760 --> 00:31:12,110
should be trivial so one of the

411
00:31:12,130 --> 00:31:17,150
major challenges has to do with what's known as the vocabulary mismatch problem OK so

412
00:31:17,160 --> 00:31:18,500
assume we have

413
00:31:18,510 --> 00:31:19,870
a document here

414
00:31:19,880 --> 00:31:22,010
CNN news

415
00:31:22,060 --> 00:31:26,890
germany tackles labour shortage and we have query saying

416
00:31:26,910 --> 00:31:30,630
consisting of three terms labour immigrants germany

417
00:31:30,640 --> 00:31:34,350
and we would you know interpret this in the standard way we would now to

418
00:31:34,350 --> 00:31:37,880
kind of the term by term matching right and we would find that all the

419
00:31:37,880 --> 00:31:39,840
three terms occurring in the document

420
00:31:39,890 --> 00:31:44,050
right and that the search engine like google or any other would basically be able

421
00:31:44,050 --> 00:31:47,700
to pull out this document as a rather you know relevant document to the query

422
00:31:48,380 --> 00:31:51,290
however we also know that as we

423
00:31:51,310 --> 00:31:52,750
very the query

424
00:31:52,760 --> 00:31:56,920
right in the way that the meaning of the query is really not changed at

425
00:31:56,920 --> 00:31:58,520
least not dramatically

426
00:31:58,540 --> 00:32:03,640
right we might run into problems so if we say german job market for immigrants

427
00:32:04,790 --> 00:32:10,420
you know job for instance does not occur here but the labour right and have

428
00:32:10,420 --> 00:32:15,680
the terms like economy here in terms like market over there and immigrants have matched

429
00:32:15,760 --> 00:32:20,140
and sometimes there are morphological variations germany german and so on and so forth so

430
00:32:20,230 --> 00:32:24,270
you know these are variations that show up of course and you can get worse

431
00:32:24,280 --> 00:32:28,870
right we can have things like foreign workers in germany or queries like german green

432
00:32:28,870 --> 00:32:32,350
card where there would be no overlap at all right so there is no term

433
00:32:32,350 --> 00:32:35,830
in the query that occurs in the document so the question is you know how

434
00:32:35,840 --> 00:32:39,410
how can we figure out that the document is relevant to the query but it

435
00:32:39,410 --> 00:32:40,950
can just be based on

436
00:32:41,100 --> 00:32:43,800
the term by term matching

437
00:32:43,810 --> 00:32:46,330
so then

438
00:32:46,830 --> 00:32:51,830
the way i'd like to think about information retrieval and that has actually become

439
00:32:51,850 --> 00:32:58,450
a more popular paradigm in the information retrieval community since nineteen ninety nine is i'd

440
00:32:58,450 --> 00:33:03,300
like to think of such as statistical inference problem or at least there is a

441
00:33:03,300 --> 00:33:09,640
statistical inference problem is part of the problem of search information search so

442
00:33:10,250 --> 00:33:14,270
to give you an example you know usually what people of course to information retrieval

443
00:33:14,270 --> 00:33:16,670
and we just you know do this here as well

444
00:33:16,680 --> 00:33:21,980
it is to ignore the syntax of the document and break it up into terms

445
00:33:21,980 --> 00:33:26,760
terms can be words or phrases so multi you know words say

446
00:33:26,770 --> 00:33:30,750
we here intellectual property for instance could two word phrase

447
00:33:30,770 --> 00:33:34,390
OK we represent so this could have been a document that would be represented as

448
00:33:34,390 --> 00:33:36,770
the set or bag

449
00:33:38,670 --> 00:33:42,650
four right now is the inference problem so

450
00:33:42,660 --> 00:33:45,820
if we have a document like that in the query

451
00:33:45,830 --> 00:33:48,390
so here you know there

452
00:33:48,440 --> 00:33:52,690
there is a query china-eu trade relations in the terms china trade and in their

453
00:33:52,950 --> 00:33:55,700
what we would be interested in somehow

454
00:33:57,630 --> 00:34:01,140
to estimate based on the context right so we

455
00:34:01,230 --> 00:34:02,890
the things you like beijing

456
00:34:02,910 --> 00:34:07,380
right where we know based on are you know in our knowledge geographic knowledge that

457
00:34:07,380 --> 00:34:10,850
that has of course to something to do with china right so that's beijing in

458
00:34:10,850 --> 00:34:16,020
the document in the query china right that you know some chances that that might

459
00:34:16,020 --> 00:34:17,500
data and

460
00:34:17,520 --> 00:34:19,130
so how do you make

461
00:34:19,310 --> 00:34:26,310
best use of

462
00:34:26,350 --> 00:34:29,980
OK i think move on

463
00:34:30,000 --> 00:34:31,750
i have

464
00:34:31,770 --> 00:34:34,170
so the next thing

465
00:34:34,210 --> 00:34:38,400
it starts out pretty solid and then kind of peters out into like things that

466
00:34:38,400 --> 00:34:40,420
don't work and we don't know how to get them work

467
00:34:40,440 --> 00:34:43,750
is this kind of training

468
00:34:45,420 --> 00:34:53,040
so this suggests the evolution of from generative to this kind of models as a

469
00:34:53,040 --> 00:34:54,850
little bit more about what i mean by that

470
00:34:54,880 --> 00:34:58,330
so the original statistical models for generative models

471
00:34:58,350 --> 00:35:02,540
but what we do nowadays is there's no error training

472
00:35:02,560 --> 00:35:05,230
so this one component the system

473
00:35:06,590 --> 00:35:11,060
and there's a big temptation to put more features into these models

474
00:35:13,150 --> 00:35:15,880
i think it's the way of introduction i should first say what i mean by

475
00:35:18,130 --> 00:35:22,880
so general models is the idea that you have a nice mathematical derivation how everything

476
00:35:22,880 --> 00:35:23,960
fits together

477
00:35:24,000 --> 00:35:29,290
so what do here you know you probability of for instance deciding to english sentence

478
00:35:29,290 --> 00:35:34,090
and you want to find new sentence as the maximum probability so those are max

479
00:35:34,090 --> 00:35:35,540
formulation here

480
00:35:35,560 --> 00:35:40,020
and you do things like you apply the bayes rule which is mathematically sound rule

481
00:35:40,060 --> 00:35:45,560
compliance you can ride this equation is true is a really call sign some made-up

482
00:35:45,560 --> 00:35:48,670
stuff so it's mathematically sound

483
00:35:49,590 --> 00:35:53,440
and then you kind of the original little bit from the past so when you

484
00:35:53,440 --> 00:35:58,580
say what is the probability of english sentence given for instance an alignment well you

485
00:35:58,580 --> 00:36:04,500
throw in some independence assumptions but mathematicians we have to do that you know that

486
00:36:04,610 --> 00:36:09,210
a one phrase is not independent of the transitional the phrase in the sentence but

487
00:36:09,210 --> 00:36:12,400
you can have considered that's about it so it's still fairly

488
00:36:12,480 --> 00:36:15,060
you know consistent story

489
00:36:15,110 --> 00:36:20,360
and this is a very straightforward formulation of the problem mathematically

490
00:36:20,460 --> 00:36:25,540
by just applying standard probability rules may be thrown in some pros some independence assumptions

491
00:36:25,540 --> 00:36:27,020
some point

492
00:36:27,040 --> 00:36:31,170
but even nice model that captures the whole thing and then you can

493
00:36:31,190 --> 00:36:35,830
basically fitting figure out how does this model applied to the data so you can

494
00:36:38,150 --> 00:36:43,230
for each sentence pair you can go with possible derivations can have and these formulas

495
00:36:43,230 --> 00:36:44,190
give you nice

496
00:36:44,210 --> 00:36:46,130
probabilities and these cases

497
00:36:46,130 --> 00:36:48,630
so there's things like the EM algorithm

498
00:36:48,630 --> 00:36:52,580
that you can use to discover automatically the alignments

499
00:36:52,590 --> 00:36:53,670
and all that

500
00:36:54,460 --> 00:36:56,210
that's generative model

501
00:36:56,960 --> 00:37:02,480
one thing you realise though is that OK you have a nice mathematical derivation where

502
00:37:02,480 --> 00:37:04,940
you should have a language model multiplied

503
00:37:04,960 --> 00:37:07,460
with the translation model certain based

504
00:37:08,290 --> 00:37:10,440
and the star model so it in there

505
00:37:10,440 --> 00:37:12,360
this maybe additional models

506
00:37:12,380 --> 00:37:14,330
it is part of the station one way

507
00:37:14,350 --> 00:37:17,310
but one thing we realize that we should wait these things

508
00:37:17,330 --> 00:37:21,860
we can basically given exponent to all these models

509
00:37:21,880 --> 00:37:26,310
for instance if we give the language model twice as much weight if you square

510
00:37:26,310 --> 00:37:30,730
all the language model probabilities all differences that exist language model scores of them

511
00:37:30,730 --> 00:37:32,090
you know even bigger

512
00:37:32,230 --> 00:37:35,810
so give more weight the language model we can get better station performance and we

513
00:37:35,810 --> 00:37:37,060
did that for a while

514
00:37:37,080 --> 00:37:41,090
you can handle all these magic numbers should be used as a smaller point five

515
00:37:41,130 --> 00:37:42,730
language model point seven

516
00:37:42,750 --> 00:37:47,360
well are the hallways and all that we just try different things

517
00:37:47,400 --> 00:37:50,080
so we did that for y

518
00:37:50,130 --> 00:37:56,540
and then maybe this is second and i which kind of showed well that's actually

519
00:37:56,540 --> 00:37:58,830
very principle thing to do is to

520
00:37:58,880 --> 00:38:03,590
these things are called log linear model so you have the product of all these

521
00:38:05,060 --> 00:38:06,960
each of them has

522
00:38:06,980 --> 00:38:09,080
waiting components lambda

523
00:38:09,080 --> 00:38:12,130
so if you take the lot because log linear models because if you take the

524
00:38:12,920 --> 00:38:16,610
the first is a linear equations the sum over

525
00:38:16,630 --> 00:38:20,690
the weights times the the log probability

526
00:38:20,810 --> 00:38:26,790
and that kind of man opens the door to throw all kinds of things

527
00:38:26,810 --> 00:38:31,440
so language model multiple language models reordering model

528
00:38:31,440 --> 00:38:35,990
we're in machine learning we'd like to make computers do this right and it's an

529
00:38:35,990 --> 00:38:39,740
interesting problem because it's saying that there is enough information in these two shifted copies

530
00:38:39,740 --> 00:38:41,370
free to recover debts

531
00:38:41,390 --> 00:38:45,650
how do you do this automatically and so what we discuss a bit later is

532
00:38:45,720 --> 00:38:49,650
you can actually formula is very naturally as as the problem in a markov random

533
00:38:51,030 --> 00:38:54,340
and it's a markov random field in which you measure the the shifts between the

534
00:38:54,340 --> 00:38:57,600
two images and you try and optimize those shifts

535
00:38:57,600 --> 00:39:01,470
and so we get a bit more details of this kind of model later this

536
00:39:01,620 --> 00:39:05,360
high level it's people use things like lattice models

537
00:39:05,380 --> 00:39:10,730
what's tricky is again trying to find the optimal shift trying to sort of shift

538
00:39:10,730 --> 00:39:13,460
things around to make the matching the best way

539
00:39:13,460 --> 00:39:18,470
this again is computationally intractable but we'll see later that people are in practice using

540
00:39:18,940 --> 00:39:23,500
message passing algorithms these are approximate methods here that are doing very well for this

541
00:39:25,590 --> 00:39:31,310
OK so just one last example before i move on

542
00:39:31,320 --> 00:39:38,880
this last example has to do with problems of communication and so some of you

543
00:39:38,880 --> 00:39:43,750
might be aware of this if if you study communication engineering you might be aware

544
00:39:43,750 --> 00:39:49,060
of these things but certainly all of you have i suspect experience with devices that

545
00:39:49,060 --> 00:39:54,540
use this kind of technology so as a sort of his matching yesterday someone asked

546
00:39:54,540 --> 00:39:59,410
about the killer application for graphical models this certainly is one killer application this this

547
00:39:59,410 --> 00:40:04,970
is an area where graphical models and message passing have really revolutionized the field in

548
00:40:04,970 --> 00:40:06,860
the last ten years

549
00:40:06,910 --> 00:40:12,630
so the basic problem here is you want to imagine that you're trying to communicate

550
00:40:12,630 --> 00:40:14,220
a source of information

551
00:40:14,230 --> 00:40:19,510
maybe you're just talking to a friend on the phone but we're going to idealise

552
00:40:19,510 --> 00:40:22,310
this is you're just trying to send let's say is zero

553
00:40:22,350 --> 00:40:25,160
you want to send your friend is zero or one that would be the simplest

554
00:40:25,160 --> 00:40:27,660
kind of communication you could do

555
00:40:27,730 --> 00:40:31,960
and the catch is that

556
00:40:32,010 --> 00:40:35,620
the channel that you have to buy channel we just mean something like a wireless

557
00:40:35,620 --> 00:40:40,960
phone that you speak over the channel doesn't work perfectly if if you send zero

558
00:40:40,960 --> 00:40:43,460
maybe will flip that zero to be one

559
00:40:43,520 --> 00:40:47,760
so your friends not quite sure what you send maybe center zero maybe one year

560
00:40:47,760 --> 00:40:49,070
she isn't quite sure

561
00:40:49,120 --> 00:40:53,980
the idea here is that what you'd like to do is be clever and start

562
00:40:54,000 --> 00:40:59,540
doing things like tom was actually mention these are called these are error correcting codes

563
00:40:59,560 --> 00:41:03,940
you'd like to add redundancy to what you transmit so the simplest thing to do

564
00:41:03,940 --> 00:41:06,920
would be to send zero five times

565
00:41:07,980 --> 00:41:11,620
as long as at most two of the bits got flipped then your friend could

566
00:41:11,620 --> 00:41:16,060
say well there's more zeros and ones and i can decode correctly

567
00:41:16,060 --> 00:41:20,070
so that's that's a very simple example of an error correcting code it's called the

568
00:41:20,070 --> 00:41:25,350
repetition code it's a very stupid example of error correcting code that's not what's used

569
00:41:25,350 --> 00:41:28,020
in practice that's a very bad thing to do

570
00:41:28,030 --> 00:41:34,160
but it illustrates the principle and this kind of problem of communicating like this has

571
00:41:34,160 --> 00:41:36,270
lots of applications

572
00:41:36,290 --> 00:41:40,750
the rovers they were sent to mars that were wandering around their using these codes

573
00:41:40,750 --> 00:41:43,010
to transmit information back to earth

574
00:41:43,030 --> 00:41:48,870
at berklee lots of people are working on sensor networks are nodes networks have lots

575
00:41:48,870 --> 00:41:53,820
of little devices and there's a lot of error control coding the goes into those

576
00:41:53,840 --> 00:41:57,820
your wireless card for those of of you are using

577
00:41:57,890 --> 00:42:03,100
wireless right now is using error correcting code in your hard drive is also using

578
00:42:03,100 --> 00:42:06,010
error correcting encoding so this this is all around you even if you don't know

579
00:42:06,010 --> 00:42:07,210
about it

580
00:42:08,680 --> 00:42:11,650
so i level the key thing is that

581
00:42:11,660 --> 00:42:13,520
shannon back in the forties

582
00:42:13,590 --> 00:42:16,610
sort of laid out of a very beautiful theory that said how well you can

583
00:42:16,610 --> 00:42:17,710
ever expect to do this

584
00:42:18,190 --> 00:42:23,460
but he was theorist he said in principle you can do this

585
00:42:23,470 --> 00:42:27,930
but he didn't give any indication how you could actually in practice do it and

586
00:42:27,930 --> 00:42:32,150
so what's exciting is the graphical models is work graphical models come in they really

587
00:42:32,150 --> 00:42:34,430
enabled people to

588
00:42:34,440 --> 00:42:37,780
so this kind of problem as near to optimally as possible

589
00:42:37,780 --> 00:42:43,150
and so graphical models are being used for instance in your wireless cards right now

590
00:42:43,180 --> 00:42:50,730
let me skip this just in the interests of time

591
00:42:50,780 --> 00:42:57,850
OK so that's sort of some illustrative examples of applications with graphical models arise it's

592
00:42:57,850 --> 00:43:02,560
by no means exhaustive i sort of chosen examples i think not intersect so much

593
00:43:02,560 --> 00:43:09,410
with other speakers but other people talking for instance about text about bioinformatics

594
00:43:09,470 --> 00:43:14,630
in all these applications again graphical models have have a role to play

595
00:43:14,670 --> 00:43:16,050
so any questions

596
00:43:16,070 --> 00:43:20,830
about those applications

597
00:43:20,880 --> 00:43:33,880
OK so let's move on to the basics of graphical models

598
00:43:34,030 --> 00:43:40,020
this again is reviewing but what's taught us over the past couple days

599
00:43:40,050 --> 00:43:45,190
so i'll be focusing mainly on undirected models or talk briefly about directed models that

600
00:43:45,190 --> 00:43:47,410
sam also spoke about

601
00:43:47,430 --> 00:43:52,930
but primarily about undirected models and i'll explain why in a couple of slides

602
00:43:52,940 --> 00:43:56,760
so again an undirected model that this means the graph that you're looking at it

603
00:43:56,760 --> 00:44:01,100
means the edges don't have arrows on them is no direction to them is just

604
00:44:01,130 --> 00:44:04,010
a link like that with no no directionality

605
00:44:04,610 --> 00:44:08,460
so again you want to think you have a graph a set of nodes circles

606
00:44:08,460 --> 00:44:09,360
and edges

607
00:44:09,380 --> 00:44:13,230
you've got random variables at each node

608
00:44:13,250 --> 00:44:15,510
and so what's important here is

609
00:44:15,520 --> 00:44:17,200
what turns out to be important is

610
00:44:17,730 --> 00:44:20,860
what are known as the cliques of the graph

611
00:44:20,890 --> 00:44:25,320
so cliques of the graph are just friends it's a clique is a set of

612
00:44:25,320 --> 00:44:28,950
nodes that all talk to each other they all share edges

613
00:44:28,970 --> 00:44:33,580
so for instance here one two three this is the a clique

614
00:44:33,580 --> 00:44:35,910
one two is also a clique

615
00:44:35,930 --> 00:44:38,880
one two three is the maximal clique because

616
00:44:38,890 --> 00:44:41,700
this is the biggest that that i can make things that all talk to each

617
00:44:42,930 --> 00:44:48,400
similarly for seven is the maximal clique four five six is a maximal clique

618
00:44:48,410 --> 00:44:52,480
so it's going to be important because cliques and define sort of the notion of

619
00:44:52,480 --> 00:44:56,300
locality what's scheme graphical models is what you mean by local

620
00:44:56,870 --> 00:44:58,710
on cliques tell you

621
00:44:58,730 --> 00:45:02,310
what it means to be local what's local to use what you can talk to

622
00:45:02,310 --> 00:45:04,850
an one step that's what's in your clique

623
00:45:05,160 --> 00:45:07,530
well it's related to what's in your creek

624
00:45:07,710 --> 00:45:12,590
something else that also important is what's known as the vertex cutset

625
00:45:12,610 --> 00:45:17,720
and this again is a very intuitive notion it's saying it's a subset of vertices

626
00:45:17,770 --> 00:45:21,620
that you usenet these that you took so in one step step step step step

627
00:45:21,620 --> 00:45:26,160
the statistically significant part of the weight function

628
00:45:26,170 --> 00:45:32,050
it was actually the weight functions where remember that we talked about taking

629
00:45:32,060 --> 00:45:34,870
the wave functions wearing it

630
00:45:34,890 --> 00:45:39,080
and the interpretation is the probability density

631
00:45:39,130 --> 00:45:44,290
that was what was critical to our understanding of what we are the electron

632
00:45:46,590 --> 00:45:48,650
so that's what we're going to do here

633
00:45:48,720 --> 00:45:50,850
we're going to take this

634
00:45:50,860 --> 00:45:55,150
sigma one molecular weight function now

635
00:45:55,270 --> 00:45:57,720
and we're going to square

636
00:45:57,890 --> 00:46:00,120
and the

637
00:46:00,750 --> 00:46:08,660
proportional to were interpreted as a probability density out just to create by p but

638
00:46:08,660 --> 00:46:13,490
this is the probability density remember that probability

639
00:46:15,170 --> 00:46:17,900
OK well if that's the case

640
00:46:18,060 --> 00:46:20,910
and i can multiply out

641
00:46:20,930 --> 00:46:22,040
right because

642
00:46:22,060 --> 00:46:23,860
sigma one

643
00:46:23,910 --> 00:46:25,400
right here

644
00:46:25,460 --> 00:46:27,660
that sigma one

645
00:46:27,710 --> 00:46:34,250
really equal to the linear combination of one s they want to be that sigma

646
00:46:36,280 --> 00:46:38,750
o let me take one as a

647
00:46:38,790 --> 00:46:41,070
what i wanna be

648
00:46:41,140 --> 00:46:43,960
multiplied by one as the

649
00:46:44,050 --> 00:46:46,100
plus one as we

650
00:46:46,110 --> 00:46:51,200
that's what sigma one hundred multiply the

651
00:46:51,220 --> 00:46:52,760
when i do the

652
00:46:52,840 --> 00:46:59,650
i'm going to get one as a square loss one has be

653
00:46:59,660 --> 00:47:06,840
we're close two times one as a one as the

654
00:47:07,230 --> 00:47:09,530
probability density

655
00:47:10,180 --> 00:47:14,760
to make this a little bit more real for you let's fly

656
00:47:14,860 --> 00:47:18,160
the plot the probability density

657
00:47:18,210 --> 00:47:22,880
as a function of the position along the body axis

658
00:47:22,960 --> 00:47:25,360
so in this case here

659
00:47:25,380 --> 00:47:26,920
the on

660
00:47:26,930 --> 00:47:28,740
nucleus is here

661
00:47:28,750 --> 00:47:33,040
in the nucleus their rights we have molecule now

662
00:47:33,050 --> 00:47:36,090
i'm just going to what the probability density

663
00:47:36,200 --> 00:47:39,110
the function of the position along the

664
00:47:39,160 --> 00:47:41,260
into nuclear assets

665
00:47:41,270 --> 00:47:44,230
what's it gonna look like well it's going to look like

666
00:47:45,600 --> 00:47:47,270
looks something like

667
00:47:49,410 --> 00:47:54,910
where the probability density is the highest right nucleus you say

668
00:47:54,960 --> 00:48:01,100
and the probability density is the highest right it will be because after all

669
00:48:01,110 --> 00:48:03,910
you know the wavefunction anyway function in the west

670
00:48:04,090 --> 00:48:05,930
the weight function

671
00:48:05,940 --> 00:48:11,400
the highest value that function is rated r is equal to zero right at the

672
00:48:14,190 --> 00:48:17,660
so that's what the probability density looks like

673
00:48:17,710 --> 00:48:19,090
and i just

674
00:48:19,110 --> 00:48:26,320
informed here that the zero thing and that particular figure turn out so well

675
00:48:26,340 --> 00:48:29,770
right but that's what it should read

676
00:48:32,340 --> 00:48:33,640
all right

677
00:48:34,580 --> 00:48:36,630
the reason i want to this here

678
00:48:36,770 --> 00:48:39,800
to contrast it with the following

679
00:48:39,880 --> 00:48:42,080
suppose i take

680
00:48:42,130 --> 00:48:44,600
just one nitrogen atom

681
00:48:44,650 --> 00:48:46,710
and the other hydrogen atom

682
00:48:46,730 --> 00:48:51,610
but i take those weight function i just where them

683
00:48:51,620 --> 00:48:53,860
and then i add them up

684
00:48:54,650 --> 00:49:01,370
so suppose i take the hydrogen atom with its function one SAIC swear it

685
00:49:01,380 --> 00:49:05,870
and then i take another wave function for another hydrogen atom

686
00:49:05,920 --> 00:49:08,710
one at the ice we're at

687
00:49:08,720 --> 00:49:10,930
and i and those who are

688
00:49:11,010 --> 00:49:12,670
in this case

689
00:49:12,720 --> 00:49:19,670
what we're doing is taking two hydrogen atoms just taking a wavefunction is wearing them

690
00:49:19,680 --> 00:49:22,010
in this particular case

691
00:49:22,090 --> 00:49:24,060
what i haven't done

692
00:49:24,070 --> 00:49:29,970
it is i haven't allowed any interference i haven't allowed

693
00:49:30,100 --> 00:49:32,510
functions two

694
00:49:32,570 --> 00:49:34,910
constructively interfere

695
00:49:35,850 --> 00:49:40,140
i didn't up these wave functions first

696
00:49:40,150 --> 00:49:42,310
before i swear

697
00:49:42,330 --> 00:49:45,350
i swear that i ended the model

698
00:49:45,370 --> 00:49:46,060
they have

699
00:49:47,410 --> 00:49:52,560
then taking those wavefunctions letting them constructively interfere

700
00:49:52,580 --> 00:49:55,220
and then squaring up

701
00:49:55,230 --> 00:49:57,790
and you can see the difference is

702
00:49:57,840 --> 00:49:59,180
when i was

703
00:50:00,890 --> 00:50:05,510
compare to that's all right from that apply now this

704
00:50:05,590 --> 00:50:09,500
what i do that it's going to work well it's going to look very much

705
00:50:09,500 --> 00:50:10,870
like this

706
00:50:10,880 --> 00:50:13,810
but then right at the centre right here

707
00:50:14,880 --> 00:50:18,290
the probability density

708
00:50:18,300 --> 00:50:20,450
right for this case

709
00:50:20,470 --> 00:50:21,920
four two

710
00:50:21,940 --> 00:50:24,290
hydrogen atoms which are now

711
00:50:24,340 --> 00:50:30,530
non binding or non-binding because i didn't let those two functions

712
00:50:30,580 --> 00:50:33,800
constructively interfere

713
00:50:33,810 --> 00:50:38,790
the result is that the probability density right in the centre here

714
00:50:38,800 --> 00:50:41,640
he probability density

715
00:50:41,640 --> 00:50:42,810
hearing this one

716
00:50:42,820 --> 00:50:45,240
so let's first start with a low frequency

717
00:50:45,250 --> 00:50:49,240
of about two hundred and fifty six words

718
00:50:50,530 --> 00:50:56,910
room anyone and you can not here in the room

719
00:50:56,920 --> 00:51:02,920
that's a good thing we might as well be right now

720
00:51:04,500 --> 00:51:06,050
the tone is quite low

721
00:51:06,060 --> 00:51:10,760
i love being and so these problems

722
00:51:10,810 --> 00:51:14,620
one of the tuning fork go back and forth two hundred fifty six times per

723
00:51:14,620 --> 00:51:17,310
second so fast you can see it

724
00:51:17,370 --> 00:51:22,040
this one is four hundred and forty it's higher simile of the piano

725
00:51:22,100 --> 00:51:24,620
the on

726
00:51:24,880 --> 00:51:27,360
merging ips

727
00:51:29,160 --> 00:51:30,880
and here is one

728
00:51:30,910 --> 00:51:32,810
that is four thousand

729
00:51:32,860 --> 00:51:38,410
very high

730
00:51:39,910 --> 00:51:43,780
even unpleasant isn't

731
00:51:43,790 --> 00:51:47,700
four thousand is the highest only the piano can produce three and goes from twenty

732
00:51:48,860 --> 00:51:51,360
the lowest key to the highest key

733
00:51:51,370 --> 00:51:52,480
which is four

734
00:51:52,490 --> 00:51:55,610
thousand words

735
00:51:56,530 --> 00:51:59,100
just to make you feel at home

736
00:51:59,130 --> 00:52:00,810
let me test you're hearing

737
00:52:00,860 --> 00:52:02,920
and see how good it is

738
00:52:02,930 --> 00:52:07,190
and for those of you who are all may be in for a surprise because

739
00:52:07,190 --> 00:52:08,690
you may not here

740
00:52:08,760 --> 00:52:11,870
all the way to the end so i'll start somewhere

741
00:52:11,930 --> 00:52:14,790
around forty or fifty sixty hertz

742
00:52:14,930 --> 00:52:18,410
it doesn't mean you cannot here twenty but it's very hard for us

743
00:52:18,420 --> 00:52:22,230
to produce twenty hertz strength not so easy

744
00:52:22,280 --> 00:52:24,410
so i will start a little higher than

745
00:52:24,440 --> 00:52:25,950
you may like

746
00:52:25,970 --> 00:52:28,200
so let's start at sixty

747
00:52:28,310 --> 00:52:34,490
required no

748
00:52:34,490 --> 00:52:37,920
we cannot hear this

749
00:52:37,970 --> 00:52:39,550
o heroes

750
00:52:39,560 --> 00:52:41,990
very loud it's not a course question

751
00:52:44,080 --> 00:52:45,950
that's the limitations of our

752
00:52:46,630 --> 00:52:47,490
this is

753
00:52:47,490 --> 00:52:49,240
sixty years

754
00:52:49,290 --> 00:52:50,860
number two hundred

755
00:52:50,870 --> 00:53:01,550
in the end this value

756
00:53:01,610 --> 00:53:03,300
four point is that

757
00:53:03,310 --> 00:53:05,970
we were

758
00:53:06,010 --> 00:53:17,020
i'm not sure

759
00:53:17,030 --> 00:53:20,720
two large or is

760
00:53:20,850 --> 00:53:27,780
on the whole o

761
00:53:28,000 --> 00:53:36,230
the other

762
00:53:40,810 --> 00:53:47,900
i could france

763
00:53:47,910 --> 00:53:54,930
now go to

764
00:53:54,940 --> 00:53:57,730
four thousand

765
00:53:57,860 --> 00:54:02,530
the this

766
00:54:02,540 --> 00:54:05,900
not just a single which we use

767
00:54:05,910 --> 00:54:09,690
same place places no you get into data

768
00:54:10,570 --> 00:54:15,810
it's as i can tell

769
00:54:15,880 --> 00:54:20,130
who can only list could use

770
00:54:22,560 --> 00:54:24,890
i don't care

771
00:54:24,940 --> 00:54:28,430
i can cannot it

772
00:54:28,440 --> 00:54:32,140
of course i in a position because creates so

773
00:54:33,270 --> 00:54:38,310
eight thousand that's it i can offer you a thousand

774
00:54:38,320 --> 00:54:40,540
so let's go to work

775
00:54:40,580 --> 00:54:43,810
to ten thousand

776
00:54:43,850 --> 00:54:46,430
o canal here ten thousand

777
00:54:46,480 --> 00:54:52,450
of the four here is that the way go

778
00:54:54,960 --> 00:54:57,430
twelve thousand

779
00:54:57,480 --> 00:55:02,150
you can hear it just raise your hand and then we'll know slower

780
00:55:02,190 --> 00:55:03,770
it's not a competition

781
00:55:03,780 --> 00:55:05,430
the winners

782
00:55:05,440 --> 00:55:07,440
fourteen thousand

783
00:55:07,500 --> 00:55:13,290
forty thousand again would overwhelm

784
00:55:13,310 --> 00:55:15,320
with respect to twelve

785
00:55:15,340 --> 00:55:18,320
sixty thousand

786
00:55:18,330 --> 00:55:22,640
so the whole

787
00:55:23,580 --> 00:55:24,680
about this

788
00:55:24,690 --> 00:55:27,950
you never hear never need sixteen thousand when you

789
00:55:28,000 --> 00:55:33,080
the bus ride to anything or television station never eighty thousand

790
00:55:33,140 --> 00:55:35,230
OK eighteen thousand

791
00:55:35,250 --> 00:55:38,400
very quiet

792
00:55:38,440 --> 00:55:40,310
OK here

793
00:55:40,320 --> 00:55:44,050
well adriana world

794
00:55:44,050 --> 00:55:49,050
can you twenty thousand

795
00:55:52,250 --> 00:55:59,420
i got twenty five thousand first roots

796
00:55:59,960 --> 00:56:02,580
twenty thousand now

797
00:56:02,600 --> 00:56:04,710
twenty thousand

798
00:56:04,720 --> 00:56:07,280
OK twenty thousand

799
00:56:07,630 --> 00:56:14,090
twenty five thousand

800
00:56:14,150 --> 00:56:16,010
are you sure

801
00:56:16,010 --> 00:56:19,050
so what i can do is i can say, well let's keep the conditional distribution

802
00:56:19,060 --> 00:56:23,140
let's throw away the prior, and make a new prior from above

803
00:56:23,140 --> 00:56:26,120
actually i'll make the new prior more powerful, 'cause i'll make it depend on the past

804
00:56:26,120 --> 00:56:28,260
states of these hidden units as well

805
00:56:28,270 --> 00:56:31,180
so it should work even better

806
00:56:31,180 --> 00:56:34,340
so that, so we stack models, and when we, when we

807
00:56:34,390 --> 00:56:37,510
make these the visible units, we can put in autoregressive connections

808
00:56:37,560 --> 00:56:41,830
those are between binary units now, so this is a logistic--this is a directed logistic belief

809
00:56:41,830 --> 00:56:43,340
net in time

810
00:56:43,390 --> 00:56:48,480
so now we can stack and every time you add another layer, it gets better

811
00:56:48,500 --> 00:56:54,190
we can even put in labels like i did in the digit model

812
00:56:54,220 --> 00:57:00,340
so we can have, we have data from CMU of a graduate student, a very brave graduate student walking

813
00:57:00,340 --> 00:57:02,080
many different styles

814
00:57:02,130 --> 00:57:05,430
we can put in explicitly the style and condition on it here

815
00:57:05,470 --> 00:57:09,510
it would be nicer to learn the styles, but for the time being we're conditioning on them

816
00:57:11,730 --> 00:57:15,840
so we just had this as an extra conditioning input which we trained with backprop

817
00:57:15,890 --> 00:57:18,210
so now we can take one model like this

818
00:57:18,210 --> 00:57:20,000
in fact exactly this model

819
00:57:20,090 --> 00:57:23,560
and train two hidden layers with style labels

820
00:57:23,650 --> 00:57:25,540
on many different styles of walking

821
00:57:25,580 --> 00:57:31,510
and then we can generate from the model

822
00:57:32,180 --> 00:57:37,470
so it's actually deciding which ways to turn and so on. it has a tendency to turn

823
00:57:37,470 --> 00:57:38,340
to the right

824
00:57:38,390 --> 00:57:48,170
it will just run forever

825
00:57:48,210 --> 00:57:49,120
but the

826
00:57:49,140 --> 00:57:52,390
student who provided the data also walked in different styles, like he was told to walk

827
00:57:52,390 --> 00:57:54,090
like a cat

828
00:57:54,140 --> 00:57:57,620
this is walking like a cat, and again, this is new data from the model, walking like

829
00:57:57,620 --> 00:57:59,220
a cat

830
00:57:59,260 --> 00:58:03,060
and you can see it's a distinctly different style of walking. now the interesting thing here is

831
00:58:03,100 --> 00:58:07,010
remember with the sort of 2's and the 8's? i just changed one label at the top

832
00:58:07,140 --> 00:58:08,790
and it changed

833
00:58:08,800 --> 00:58:11,040
the digits it generated, right?

834
00:58:11,040 --> 00:58:14,760
there i just changed one style label, completely changed what came out, even though all the other

835
00:58:14,760 --> 00:58:17,130
connections were the same

836
00:58:17,180 --> 00:58:20,960
so when it was dreaming of 2's and 8's, that looked a bit boring

837
00:58:21,010 --> 00:58:24,690
this is more interesting dreaming, because it's dreaming dynamic things and it's about people

838
00:58:24,720 --> 00:58:30,250
you can tell him to walk like a

839
00:58:41,680 --> 00:58:47,040
he's a very brave student

840
00:58:47,050 --> 00:58:51,080
you can tell him to walk like

841
00:58:51,120 --> 00:58:52,590
walk gracefully

842
00:58:52,640 --> 00:58:56,130
he's a computer science student, i'm fairly sure

843
00:58:56,140 --> 00:58:59,930
i think the only graceful walk he's ever seen is c-3po. that's definitely

844
00:59:02,690 --> 00:59:06,970
and notice the model gets fed up after a while. this generative model, it's too hard holding

845
00:59:06,970 --> 00:59:07,840
your hands up

846
00:59:07,890 --> 00:59:10,180
all the other things it's learned had the hands down

847
00:59:10,340 --> 00:59:12,260
so it just gives up on that after a while

848
00:59:12,550 --> 00:59:14,510
it overrides the style label

849
00:59:15,810 --> 00:59:22,430
you can tell him to walk like a gangly teenager, he's very good at that

850
00:59:22,440 --> 00:59:31,000
he looks really awkward right

851
00:59:31,000 --> 00:59:33,150
he's not quite sure what he's meant to be doing there

852
00:59:33,180 --> 00:59:40,600
you can tell him to walk like a drunk

853
00:59:40,650 --> 00:59:42,920
now the, the stumbling recovery

854
00:59:42,970 --> 00:59:46,800
wasn't because it understands physics. there must be something very similar to that in the

855
00:59:46,800 --> 00:59:48,960
training data, right?

856
00:59:48,980 --> 00:59:52,010
but one thing that never was in the training data was transitions from one kind

857
00:59:52,010 --> 00:59:54,130
walk to another

858
00:59:54,140 --> 01:00:00,470
so he knows how to walk in a sexy style

859
01:00:05,460 --> 01:00:07,010
it's all in the same weights

860
01:00:07,020 --> 01:00:08,970
just change the style label

861
01:00:09,010 --> 01:00:15,340
and then you can be really mean to him

862
01:00:15,390 --> 01:00:19,550
and you can say

863
01:00:19,560 --> 01:00:23,580
tell him to walk in a sexy style and halfway through you change the label to chicken

864
01:00:23,790 --> 01:00:26,720
and he's never seen transitions before, and he does a reasonable transition

865
01:00:26,760 --> 01:00:30,960
because it's all the same model

866
01:00:31,000 --> 01:00:33,230
OK that's the end

867
01:00:33,480 --> 01:00:53,480
i'm going to post the slides on my website

868
01:00:56,420 --> 01:00:59,810
i have to get them onto my website in toronto but i'll try and do it tonight, certainly by monday

869
01:01:00,010 --> 01:01:00,970
they'll be there

870
01:01:00,980 --> 01:01:05,480
and these readings which are still being updated, there's already readings there which are old readings

871
01:01:05,480 --> 01:01:07,380
i've got about fifteen new ones

872
01:01:07,390 --> 01:01:08,760
that i'm gonna put there

873
01:01:08,840 --> 01:01:09,810
well maybe

874
01:01:11,470 --> 01:01:13,400
i'll put those there over the weekend

875
01:01:13,440 --> 01:01:17,090
so by monday you'll be able to get all the papers i referred to will

876
01:01:17,090 --> 01:01:18,390
being here with little

877
01:01:18,440 --> 01:01:24,470
a very brief description what it's about

878
01:01:38,760 --> 01:01:46,590
right, i agree. so this was just for

879
01:01:46,600 --> 01:01:50,090
i mean we were motivated by the LSA people

880
01:01:50,100 --> 01:01:52,590
who were doing document retrieval by using

881
01:01:52,590 --> 01:01:56,220
getting vectors from documents and using them for other documents

882
01:01:56,250 --> 01:01:59,440
and claiming that, you know, we can do amazing things and we just want to

883
01:01:59,440 --> 01:02:03,290
say we can do much more amazing things, then we noticed that we could do this

884
01:02:03,290 --> 01:02:05,890
semantic hashing that is

885
01:02:05,940 --> 01:02:08,800
learn this hash function that respects similarity

886
01:02:08,800 --> 01:02:10,710
and therefore is a very fast thing

887
01:02:10,710 --> 01:02:14,770
i completely agree with you that what people really want to do

888
01:02:16,330 --> 01:02:19,850
given a short query, find the relevant documents, and for that i think you have

889
01:02:19,850 --> 01:02:23,270
to understand the meaning of the short query ultimately

890
01:02:24,540 --> 01:02:29,130
google quite liked this and gave us some money to more research on it

891
01:02:37,270 --> 01:02:55,840
we should probably talk about that offline because i'm not sure i understand what you're

892
01:02:55,840 --> 01:02:56,850
saying but

893
01:02:56,930 --> 01:03:00,300
as you probably realise my main interest in this was

894
01:03:00,300 --> 01:03:05,120
not actually solving the information retrieval problem but showing that this deep learning could do something neat

895
01:03:06,400 --> 01:03:11,210
i'm not an information retrieval person

896
01:03:37,230 --> 01:03:40,840
you mean skip-like connections

897
01:03:40,890 --> 01:03:44,310
you could do that even before the pre training. that is, there's no reason why

898
01:03:44,330 --> 01:03:49,080
when i train a layer, i shouldn't treat as data several previous layers

899
01:03:51,140 --> 01:03:53,400
the real answer to that is there's

900
01:03:53,420 --> 01:03:56,970
too many things to be explored and that's not one of the things we explored

901
01:03:57,020 --> 01:04:02,470
yoshua bengio's group has done a little bit of exploration of that and claims that it helps

902
01:04:02,520 --> 01:04:06,680
so it's a sensible idea. it's just one of those many things that

903
01:04:06,710 --> 01:04:10,340
needs to be investigated and occasionally one of those things turns out to be a big win

904
01:04:10,340 --> 01:04:12,400
so far as i know it's not a really big win

905
01:04:12,560 --> 01:04:14,680
my main motivation i guess was

906
01:04:14,730 --> 01:04:17,670
the inferior temporal pathway in the cortex

907
01:04:17,730 --> 01:04:22,800
doesn't look much like that although it does have some skip like connections

908
01:04:24,520 --> 01:04:28,010
so let's see if i can draw picture of what you're saying

909
01:04:28,010 --> 01:04:30,620
and then if i can learn this

910
01:04:31,930 --> 01:04:34,390
where all these are connected

911
01:04:34,470 --> 01:04:37,640
then a multilayer thing is just a version of that with a few missing connections

912
01:04:37,640 --> 01:04:43,890
in one dimension that has a local minimum right and a mountain and then another

913
01:04:43,900 --> 01:04:45,730
a global minimum OK

914
01:04:45,730 --> 01:04:50,120
in one dimension you can go through the mountain to go to this of immunity

915
01:04:50,160 --> 01:04:54,550
can go up so the great this algorithm not find it but it's dimension

916
01:04:54,600 --> 01:04:57,090
you may be able to go around the mountain

917
01:04:57,140 --> 01:04:59,830
so that picture this million dimensions

918
01:05:00,010 --> 01:05:01,990
i'm sure you can do that

919
01:05:04,670 --> 01:05:08,100
then there's going to be lots and lots of dimensions that will go to allow

920
01:05:08,100 --> 01:05:12,270
you to get around a local minima and in fact depending on the kind of

921
01:05:12,320 --> 01:05:15,310
basic elements of sample in the network

922
01:05:15,330 --> 01:05:19,790
it's very difficult to build the box right now you have a million dimensional stability

923
01:05:19,790 --> 01:05:21,820
buttermilk dimensions you need

924
01:05:21,830 --> 01:05:23,230
i have a lot of

925
01:05:25,930 --> 01:05:31,730
each neuron basically the point because it does have space so answers could be

926
01:05:31,810 --> 01:05:34,020
hardly complicated that

927
01:05:37,620 --> 01:05:41,590
right so you have flat areas of course because the the weights become very large

928
01:05:41,590 --> 01:05:45,120
something get saturated and a large so there was to compensate for this is just

929
01:05:45,120 --> 01:05:47,550
not to get there and you can do this is with decay so there's a

930
01:05:47,550 --> 01:05:50,340
few tricks like this to run the same with a lot of tricks if you

931
01:05:50,340 --> 01:05:53,770
want to make larger and efficient this entire which about this

932
01:05:55,270 --> 01:06:00,670
which means that means that expects was where we so

933
01:06:00,690 --> 01:06:05,610
yes there are tricks but there are not any more difficult and

934
01:06:05,830 --> 01:06:07,050
of instances

935
01:06:07,090 --> 01:06:10,550
so a problem of course is that if you sort of

936
01:06:10,560 --> 01:06:13,830
starting to play with things like this the first thing to try is you know

937
01:06:13,830 --> 01:06:19,780
it i you're not on the exclusive or and happens to be very unreliable

938
01:06:22,610 --> 01:06:25,080
so this idea of

939
01:06:25,090 --> 01:06:28,970
so basically nineteen fifty seven people sort of figured out the perceptron work that you

940
01:06:29,490 --> 01:06:35,270
the only new that convex optimisation and so with the figures that they

941
01:06:35,670 --> 01:06:40,760
they had to make this a really large with what i'm basically random functions random

942
01:06:40,840 --> 01:06:44,490
features and you know they is there was a good chance that the problem would

943
01:06:44,490 --> 01:06:46,690
be solved was nineteen fifty seven

944
01:06:46,730 --> 01:06:52,230
eighty five o o with backprop people forget women that you could on this is

945
01:06:52,230 --> 01:06:56,900
sort of works in both cases but there are situations where it doesn't work

946
01:06:56,920 --> 01:06:58,110
nineteen ninety two the

947
01:06:58,120 --> 01:07:00,010
the kernel machine

948
01:07:00,920 --> 01:07:04,850
sort of came out of the

949
01:07:04,870 --> 01:07:06,100
of the

950
01:07:06,120 --> 01:07:12,050
the bushes and said well if i said if i have one unit for each

951
01:07:12,050 --> 01:07:13,240
training sample

952
01:07:13,280 --> 01:07:17,990
smith's next to me this right

953
01:07:19,890 --> 01:07:23,130
actually the three offices next to me

954
01:07:23,330 --> 01:07:25,650
the was there

955
01:07:25,670 --> 01:07:30,570
is a big wheel invented that make but anyway

956
01:07:30,570 --> 01:07:35,560
if you if you say each unit to a training sample different training samples the

957
01:07:35,560 --> 01:07:37,820
ways of each in unit two different training sample

958
01:07:37,830 --> 01:07:41,170
but basically you've built around for your training set

959
01:07:41,850 --> 01:07:46,430
that's like a decoder for random access memory right to plug you plug inputs and

960
01:07:46,430 --> 01:07:51,220
then what going to it can recognise its its corresponding training sample and so you

961
01:07:51,220 --> 01:07:53,880
just the way to the output you want and you don't you know it's it's

962
01:07:53,880 --> 01:07:57,510
it's random access memory so you make the kind of smooth and then you can

963
01:07:57,510 --> 01:07:59,610
get smooth minimizes memory

964
01:07:59,630 --> 01:08:01,510
and the support vector machines

965
01:08:01,520 --> 01:08:05,480
regularizer at this

966
01:08:05,500 --> 01:08:11,510
so that's kind of you know

967
01:08:11,550 --> 01:08:13,220
it's not beyond the perceptron

968
01:08:13,230 --> 01:08:16,360
in fact there was several papers at the conference is one

969
01:08:16,590 --> 01:08:19,260
people at the conference there was sort of arguing for

970
01:08:20,220 --> 01:08:25,340
first layer is this is sort of drawing from theoretical results from compressed sensing which

971
01:08:25,340 --> 01:08:28,080
are really interesting mathematically

972
01:08:28,090 --> 01:08:32,450
so what's the problem with non convex learning

973
01:08:32,510 --> 01:08:35,580
so when you mentioned before is that none of what you read in the optimisation

974
01:08:35,580 --> 01:08:37,690
literature applied

975
01:08:38,110 --> 01:08:43,100
and encourage you to see which is tutorial either slides and video which hopefully will

976
01:08:43,100 --> 01:08:48,190
become available and that there was the next last year and the reason is you

977
01:08:48,190 --> 01:08:51,780
need to use stochastic methods to take advantage of redundancy in the data

978
01:08:52,950 --> 01:08:57,930
so stochastic methods are the methods were basically you the parameters after each sample instead

979
01:08:57,930 --> 01:09:02,820
of kind of computing an update over the entire training set k

980
01:09:02,830 --> 01:09:07,250
and that exploits the redundancy in the density of after this particular industry that's really

981
01:09:07,250 --> 01:09:11,560
what you want to use and they will produce theoretical results on this a few

982
01:09:11,560 --> 01:09:16,260
years ago that showed that we should talk about this tutorial that shows that you

983
01:09:16,260 --> 01:09:20,820
know even if this does not optimize the loss function on the training set perfectly

984
01:09:20,820 --> 01:09:23,330
this is as good as it's going to get on the test set anyway so

985
01:09:23,330 --> 01:09:25,890
you don't need to optimise more

986
01:09:25,910 --> 01:09:31,580
so the problem is that sort of of course stochastic methods of four balls and

987
01:09:31,970 --> 01:09:33,330
a synthetic

988
01:09:33,380 --> 01:09:38,800
asymptotics properties and so if you tell the musician person i'm going to use a

989
01:09:38,800 --> 01:09:42,740
stochastic gradient algorithm says for series of convergence proof or they are but after we

990
01:09:44,720 --> 01:09:47,250
and second you know the property are you know

991
01:09:47,270 --> 01:09:51,790
your linear or or even sublinear is really horrible OK but they all show that

992
01:09:51,790 --> 01:09:53,870
actually works really well

993
01:09:53,920 --> 01:09:57,930
many people so there's really well but they will explain why this class

994
01:10:00,420 --> 01:10:04,370
and the values of course is that the musician musician literature does not talk about

995
01:10:04,370 --> 01:10:08,520
stochastic methods at all you can find anything about this anywhere

996
01:10:08,530 --> 01:10:09,160
and so

997
01:10:09,220 --> 01:10:12,660
you know conjugate gradient stories project which is causing you to sort out the window

998
01:10:12,660 --> 01:10:16,420
you can use any of that any of those methods are quite anyway ordering two

999
01:10:17,550 --> 01:10:21,370
you know when the sun

1000
01:10:21,390 --> 01:10:25,300
so you start with simple methods you can publish papers prison complex methods because you

1001
01:10:25,300 --> 01:10:28,880
know the simple methods of the ones i work best

1002
01:10:28,890 --> 01:10:30,320
how disappointing

1003
01:10:30,330 --> 01:10:36,890
so what this kind of the same for the earlier

1004
01:10:36,900 --> 01:10:38,760
right so so so you also

1005
01:10:38,770 --> 01:10:41,410
this is kind of the point that sort of making the this is a very

1006
01:10:41,410 --> 01:10:42,830
large sort of

1007
01:10:42,890 --> 01:10:48,160
basically sort of you know using this did the trick that is the tallest of

1008
01:10:48,160 --> 01:10:52,110
its kind of a good way of avoiding the problem of local minima really being

1009
01:10:52,200 --> 01:10:53,410
the problem

1010
01:10:53,470 --> 01:10:58,530
so another problem also is sort of breaking the symmetry in the system there's is

1011
01:10:58,540 --> 01:11:02,770
a a local minimum due to the fact that you can for example interchange to

1012
01:11:02,820 --> 01:11:05,940
denote in neural nets and you get the same solution

1013
01:11:06,050 --> 01:11:06,800
and so

1014
01:11:07,280 --> 01:11:10,530
that means there are two local minima are equivalent due to a permutation and the

1015
01:11:10,530 --> 01:11:12,700
user is kind of a set point between them

1016
01:11:12,760 --> 01:11:18,480
and you know by the king's military you sort of reducing the the space

1017
01:11:18,490 --> 01:11:21,150
and that might be one of the reasons why things like on social network so

1018
01:11:21,150 --> 01:11:24,850
well because they even though they're very very deep that's one of the few instances

1019
01:11:24,910 --> 01:11:29,520
very deep architectures that work well with backprop and one reason is perhaps because not

1020
01:11:29,520 --> 01:11:33,980
only otherwise in terms of so what probably had to solve with known as you

1021
01:11:33,980 --> 01:11:34,840
can make the

1022
01:11:34,870 --> 01:11:37,240
the himalayas very wide because the

1023
01:11:37,240 --> 01:11:40,900
number of parameters was really quickly with the you know quadratically with the number of

1024
01:11:41,800 --> 01:11:46,790
and then you get killed by over privatisation so it had to find architectures where

1025
01:11:46,790 --> 01:11:49,900
that's not the case we can increase the size of the number of variables that

1026
01:11:49,900 --> 01:11:52,900
are manipulated but not the number of parameters that are being trained

1027
01:11:52,930 --> 01:11:54,990
and commercial that's the way of doing this

1028
01:11:54,990 --> 01:12:00,040
and the other activities this new symmetry is broken it so not every node is

1029
01:12:00,040 --> 01:12:07,250
connected to the same set of variables and so naturally they ten two different things

1030
01:12:07,250 --> 01:12:09,730
a couple of molecules

1031
01:12:09,780 --> 01:12:12,810
so this was one of the first ideas of

1032
01:12:12,860 --> 01:12:15,700
elements that come together to form

1033
01:12:15,710 --> 01:12:19,350
elements that come together to form molecules

1034
01:12:19,410 --> 01:12:22,990
and then there was this gentleman joseph priestley

1035
01:12:23,000 --> 01:12:26,140
yes what his occupation was

1036
01:12:26,190 --> 01:12:31,580
he was a priest of course and what did he do

1037
01:12:32,440 --> 01:12:35,190
he looked at reactions with

1038
01:12:35,230 --> 01:12:37,920
deeply just dictated e

1039
01:12:37,930 --> 01:12:44,400
people just the kadir reacting with material and what he observed was

1040
01:12:44,490 --> 01:12:49,520
these materials reacted more vigorously in the village is located in

1041
01:12:49,540 --> 01:12:53,460
well what's def which is located the role of course now we know the which

1042
01:12:53,460 --> 01:12:58,870
is the key to areas oxygen here with the nitrogen predominantly removed

1043
01:12:58,920 --> 01:13:03,250
but i really took this gentleman well what a

1044
01:13:03,280 --> 01:13:08,930
took this gentleman to really understand what previously was doing in his experiments

1045
01:13:08,950 --> 01:13:11,470
and what they realized

1046
01:13:11,490 --> 01:13:17,270
is that there is a deep logistic air was kept going to the material

1047
01:13:17,340 --> 01:13:19,950
when it did this reaction

1048
01:13:20,030 --> 01:13:24,450
and he made those observations are came to those conclusions

1049
01:13:24,470 --> 01:13:28,670
by doing some very careful measurements of the

1050
01:13:28,680 --> 01:13:33,280
before the reactions of the mass of the people just the airports the mass of

1051
01:13:33,280 --> 01:13:34,420
the material

1052
01:13:34,440 --> 01:13:40,380
and found that indeed the math after the reaction was equivalent to the before the

1053
01:13:42,130 --> 01:13:47,090
and so he was one of the first individuals realize that a chemical reaction can

1054
01:13:47,090 --> 01:13:48,630
be written down

1055
01:13:48,690 --> 01:13:51,350
analogous to writing a

1056
01:13:51,360 --> 01:13:54,300
algebraic equations

1057
01:13:54,340 --> 01:13:56,830
well what he also

1058
01:13:56,850 --> 01:14:04,290
did a lot of work isolating elements identified seventeen medals and nine none of those

1059
01:14:06,430 --> 01:14:12,030
well for all of his efforts we all know what happened to look twice yearly

1060
01:14:12,050 --> 01:14:16,900
because of his connection to the french monarchy

1061
01:14:16,950 --> 01:14:24,090
judge at his trial claimed that the republic has no use for so long

1062
01:14:24,100 --> 01:14:27,710
grant at the time the french mathematician

1063
01:14:27,720 --> 01:14:30,230
so it took but a moment to

1064
01:14:30,240 --> 01:14:35,380
cut through the head but it will require a hundred years to produce another like

1065
01:14:37,090 --> 01:14:41,620
but what there was another frenchman at that time gl proved he was a little

1066
01:14:41,620 --> 01:14:43,560
more politically savvy

1067
01:14:43,570 --> 01:14:46,920
so he high-tailed over two was spain

1068
01:14:46,930 --> 01:14:52,920
and let to long and healthful life is professor in madrid

1069
01:14:52,940 --> 01:14:56,260
but what is a get some experiments

1070
01:14:56,280 --> 01:15:02,000
and he observed that when two or more elements combine well they combined

1071
01:15:02,010 --> 01:15:08,960
to borrow compound they always combine in definite proportions by weight and it didn't matter

1072
01:15:09,010 --> 01:15:12,270
what the method of preparation ones

1073
01:15:12,280 --> 01:15:16,550
and so because he made this observation over and over all over again with many

1074
01:15:16,550 --> 01:15:19,390
different elements that became known as the

1075
01:15:20,150 --> 01:15:24,400
here of definite proportions again some indication they

1076
01:15:24,410 --> 01:15:28,220
matter was the head of the discrete nature to it

1077
01:15:28,230 --> 01:15:33,110
it wasn't just the continuance numbers were involved here

1078
01:15:33,320 --> 01:15:35,140
right but

1079
01:15:35,160 --> 01:15:37,630
it really took this guy

1080
01:15:37,680 --> 01:15:39,080
john dalton

1081
01:15:39,090 --> 01:15:40,840
english schoolteacher

1082
01:15:40,850 --> 01:15:43,710
with a lot of interest

1083
01:15:43,740 --> 01:15:45,360
he was aware

1084
01:15:45,370 --> 01:15:48,970
of the operations of oil and priestly

1085
01:15:49,010 --> 01:15:51,970
and love a improves

1086
01:15:52,020 --> 01:15:59,300
and what he realized is that he could begin to understand all those observations

1087
01:15:59,310 --> 01:16:01,010
if you went there

1088
01:16:01,030 --> 01:16:03,540
all the way to democratise

1089
01:16:03,550 --> 01:16:07,060
in democracies idea of animals

1090
01:16:07,070 --> 01:16:08,460
four the atoms

1091
01:16:08,500 --> 01:16:13,260
these individual discrete particles of matter

1092
01:16:13,450 --> 01:16:14,460
so he

1093
01:16:14,470 --> 01:16:15,580
that for

1094
01:16:15,590 --> 01:16:17,100
some postulate

1095
01:16:17,120 --> 01:16:22,950
some postulates which force now know are known as dawkins atomic theory

1096
01:16:23,000 --> 01:16:27,570
what he said is that each element is composed of atoms

1097
01:16:27,580 --> 01:16:32,240
he said that atoms of any given element are identical

1098
01:16:32,350 --> 01:16:36,990
he said they compound formed when atoms more than one element combined

1099
01:16:37,000 --> 01:16:38,640
and he realized

1100
01:16:38,650 --> 01:16:44,510
of course from love idea is that observations that atoms are neither created nor are

1101
01:16:44,510 --> 01:16:45,990
they destroyed

1102
01:16:46,180 --> 01:16:48,560
now just on the side

1103
01:16:48,560 --> 01:16:50,230
the very beginning

1104
01:16:50,240 --> 01:16:53,230
of the competition but it took us more than a year

1105
01:16:53,240 --> 01:16:54,720
to understand how to do

1106
01:16:54,740 --> 01:16:56,780
use something like this

1107
01:16:56,800 --> 01:16:58,730
it's not for it wasn't revealed

1108
01:16:58,740 --> 01:16:59,180
to get

1109
01:16:59,220 --> 01:17:03,000
the with exploited and this is another effect

1110
01:17:05,290 --> 01:17:08,120
and writing of movies

1111
01:17:08,130 --> 01:17:10,660
it carries over time for the same movie

1112
01:17:11,200 --> 01:17:17,860
some of the some reasons for this less about their housekeeper reasoning you can find

1113
01:17:17,860 --> 01:17:22,530
it in the paper about yes at the date of the individual is the average

1114
01:17:22,530 --> 01:17:25,390
school tend to be the lowest

1115
01:17:25,540 --> 01:17:27,970
i'm just trying to motivate

1116
01:17:27,980 --> 01:17:33,060
the interest of the interest in those dynamic

1117
01:17:33,110 --> 01:17:36,430
effect in the data

1118
01:17:36,510 --> 01:17:42,300
so while i can give the that explanation to those global effects let's talk about

1119
01:17:42,310 --> 01:17:46,080
because of such effects on the local level so

1120
01:17:46,100 --> 01:17:51,870
i will split two item side effects and use of side effects item side effects

1121
01:17:51,870 --> 01:17:54,300
as to have to do with the the fact that

1122
01:17:54,420 --> 01:17:58,570
item popularity evolve over time thus and all effects

1123
01:17:58,620 --> 01:18:03,840
well that that's out of popular in the fall might not be very popular

1124
01:18:03,850 --> 01:18:06,850
the way in the summer

1125
01:18:07,330 --> 01:18:13,430
if we talk again about movies if we have the new good movie by

1126
01:18:13,440 --> 01:18:15,310
eddie murphy then maybe

1127
01:18:15,330 --> 01:18:18,470
all these all movies come back into fashion

1128
01:18:18,480 --> 01:18:21,890
and things like this

1129
01:18:21,900 --> 01:18:28,030
and also we have use of side effects which probably more pronounced and more complicated

1130
01:18:28,030 --> 01:18:31,800
this now we talk about humans which show

1131
01:18:33,830 --> 01:18:37,540
creatures i would say and some of them

1132
01:18:37,750 --> 01:18:42,060
fundamental like the ability to change the taste

1133
01:18:42,070 --> 01:18:44,930
and and and preferences over time

1134
01:18:44,950 --> 01:18:48,000
and some just reflect noise

1135
01:18:48,010 --> 01:18:54,550
so those are the people can be a bit differently on different on different days

1136
01:18:54,560 --> 01:18:57,500
and there

1137
01:18:57,550 --> 01:19:05,940
and the made challenges that one needs to address is first set up several sources

1138
01:19:05,940 --> 01:19:07,970
to bolster paul dynamics

1139
01:19:07,980 --> 01:19:09,300
and the

1140
01:19:09,320 --> 01:19:12,320
we want to address all of them all at least

1141
01:19:12,340 --> 01:19:15,140
the most the more important ones

1142
01:19:15,330 --> 01:19:20,980
then you have a unique characteristics of this problem is that we have my multiple

1143
01:19:24,150 --> 01:19:28,380
the usual classification problem we are tracking

1144
01:19:29,200 --> 01:19:30,720
well blocking some

1145
01:19:30,750 --> 01:19:33,230
the found that we want to separate

1146
01:19:33,260 --> 01:19:37,220
but it is on the negatives and overall that can

1147
01:19:37,340 --> 01:19:40,800
can go all can go forward some

1148
01:19:40,840 --> 01:19:44,540
change we're talking really many

1149
01:19:44,560 --> 01:19:48,140
different targets you can say that it uses the forms

1150
01:19:48,210 --> 01:19:52,930
the soil on time series conservatism also about items

1151
01:19:54,380 --> 01:19:56,290
this way there

1152
01:19:56,300 --> 01:20:00,210
the signal peptide target is

1153
01:20:00,260 --> 01:20:04,910
israeli scouts you don't you don't get much information values

1154
01:20:04,920 --> 01:20:08,100
and the the challenge with which

1155
01:20:08,150 --> 01:20:09,380
might be

1156
01:20:09,430 --> 01:20:13,720
even more important is that we know that while we have many targets we must

1157
01:20:13,720 --> 01:20:16,290
relate all them that's there

1158
01:20:16,300 --> 01:20:22,390
essence of collaborative filtering sharing information among many users so even if the user

1159
01:20:22,430 --> 01:20:27,010
acted on different time frames we we still want to borrow information between them and

1160
01:20:27,010 --> 01:20:29,850
establish patterns causing them

1161
01:20:31,820 --> 01:20:35,030
this tool as mournful and rendell

1162
01:20:35,050 --> 01:20:37,770
methodologies coming to concept drift

1163
01:20:37,850 --> 01:20:41,450
two to be unappealing gail because

1164
01:20:41,470 --> 01:20:45,670
we can do things like just underweighting older instances

1165
01:20:45,680 --> 01:20:47,610
it will just

1166
01:20:47,630 --> 01:20:53,420
the event relating different users for example

1167
01:20:54,060 --> 01:20:55,480
let me show you

1168
01:20:55,510 --> 01:20:57,400
briefly there

1169
01:20:57,470 --> 01:21:02,340
the headlines of what we did was to techniques first one is the matrix factorisation

1170
01:21:02,340 --> 01:21:07,100
model which is one of the most popular methods in this field

1171
01:21:07,160 --> 01:21:09,090
we take the

1172
01:21:09,130 --> 01:21:10,910
rating matrix

1173
01:21:10,920 --> 01:21:16,450
well they are also scale represents the user item rating the composer two into two

1174
01:21:16,730 --> 01:21:20,270
and metastasis in as first and

1175
01:21:20,290 --> 01:21:21,800
but to estimate

1176
01:21:21,890 --> 01:21:25,760
the rating by use of five light into for example we look on the

1177
01:21:25,770 --> 01:21:28,330
responding again

1178
01:21:28,350 --> 01:21:32,020
in fact those taking the inner product and we have the

1179
01:21:32,060 --> 01:21:34,900
the age of eighteen

1180
01:21:34,960 --> 01:21:39,670
this is quite similar to us do just that we have many unknown lighting so

1181
01:21:39,670 --> 01:21:41,980
people come up with

1182
01:21:42,170 --> 01:21:44,770
more specialized algorithms to be this

1183
01:21:44,800 --> 01:21:48,060
don't of missing that

1184
01:21:48,070 --> 01:21:50,000
and also

1185
01:21:50,020 --> 01:21:54,980
globalization is is known to be critical here because we don't want to overfit the

1186
01:21:54,980 --> 01:21:57,400
view given

1187
01:21:57,450 --> 01:22:00,820
ratings but to generalize them to the unknown ones

1188
01:22:01,910 --> 01:22:06,090
in this context of modern pinball it it's very important to realize that

1189
01:22:06,110 --> 01:22:11,460
some main effects in that and they need to get separated

1190
01:22:13,680 --> 01:22:17,980
what we're finding is that there was variability in the that

1191
01:22:18,010 --> 01:22:19,750
maybe as expected

1192
01:22:19,800 --> 01:22:24,970
is explained by some main effects so then in in this

1193
01:22:25,000 --> 01:22:27,710
in the more in the movie rating example we want to

1194
01:22:27,760 --> 01:22:33,210
estimate jo jo's looking for the movie six then we

1195
01:22:33,220 --> 01:22:35,520
start with some mean writing for

1196
01:22:35,540 --> 01:22:36,590
any movie

1197
01:22:36,600 --> 01:22:38,070
it just it

1198
01:22:38,090 --> 01:22:43,130
well i because the sixth sense is better than average and then a bit lower

1199
01:22:43,130 --> 01:22:46,880
because joe tends to lead lo and come up with

1200
01:22:46,930 --> 01:22:49,550
some stopped going to fall styles

1201
01:22:49,560 --> 01:22:50,850
this would do

1202
01:22:50,860 --> 01:22:54,210
quite well in explaining variability in the data

1203
01:22:54,230 --> 01:22:58,040
and also much of the temple variability lies field

1204
01:22:58,100 --> 01:23:03,520
and then on top of it we model the interaction between between between

1205
01:23:03,530 --> 01:23:08,940
joe and in this particular movie like think joe like supernatural thrillers six sense is

1206
01:23:09,100 --> 01:23:12,150
one of the kind so is going to like in the movie

1207
01:23:12,170 --> 01:23:17,790
so and so this is just nonsense stuff and

1208
01:23:17,810 --> 01:23:19,180
then the

1209
01:23:19,190 --> 01:23:21,790
in late else it comes out this

1210
01:23:21,800 --> 01:23:27,760
the predicted rating for user u and itemize some baseline predictor capturing the overall average

1211
01:23:27,760 --> 01:23:32,800
to use of bias the item bias and some interaction them

1212
01:23:32,810 --> 01:23:37,920
taking the inner product between the fractals and women were and we minimize the squared

1213
01:23:37,930 --> 01:23:46,820
now what's so convenient about this is that this separation tool

1214
01:23:46,830 --> 01:23:48,390
use of bias

1215
01:23:48,410 --> 01:23:51,210
item bias interaction let us

1216
01:23:53,170 --> 01:23:57,000
this temple have effects separately

1217
01:23:57,050 --> 01:23:58,780
so we

1218
01:24:00,180 --> 01:24:01,800
we expect change us

1219
01:24:01,810 --> 01:24:03,210
so in

1220
01:24:03,230 --> 01:24:06,720
the rating scale of individual users is mostly

1221
01:24:06,720 --> 01:24:11,970
so in the end the network you do sampling distribution because you can propagate points

1222
01:24:11,970 --> 01:24:16,840
in the non-linear weighted sum propagate variance points non-linear way it's difficult

1223
01:24:16,890 --> 01:24:21,870
so that's what i think was the first one of the algorithm in this community

1224
01:24:21,870 --> 01:24:26,120
to deal with this sort of thing you use the sampling approach to that

1225
01:24:26,170 --> 01:24:28,460
in the generative topographic mapping

1226
01:24:29,440 --> 01:24:32,250
well see some results from later as well

1227
01:24:32,320 --> 01:24:34,410
uses group points

1228
01:24:36,850 --> 01:24:43,700
into space and then use points of means guassian distributions so two different ways

1229
01:24:43,720 --> 01:24:44,720
thank you

1230
01:24:44,750 --> 01:24:46,080
probabilistic model

1231
01:24:46,090 --> 01:24:49,070
which is quite effective

1232
01:24:49,080 --> 01:24:50,890
so in the GP LVM i

1233
01:24:50,900 --> 01:24:54,790
the process latent variable model we can take a different approach

1234
01:24:54,810 --> 01:24:59,210
that that's the normal probabilistic interpretation of PCA

1235
01:24:59,220 --> 01:25:02,930
this is what we had before

1236
01:25:02,950 --> 01:25:07,340
we've got an image of the latent variable space and replace the distribution of them

1237
01:25:07,340 --> 01:25:09,950
with maximizing with respect to w

1238
01:25:09,970 --> 01:25:12,190
to take this to be distribution

1239
01:25:12,330 --> 01:25:14,400
they doing that

1240
01:25:14,420 --> 01:25:18,420
i consider flip between so you can see the differences

1241
01:25:18,490 --> 01:25:21,340
we're going to do something else now

1242
01:25:21,360 --> 01:25:25,310
i don't believe in bayesian approaches but on a pragmatic basis i don't believe in

1243
01:25:25,310 --> 01:25:29,530
integrating everything i can find i try i stop when i have to start doing

1244
01:25:31,420 --> 01:25:33,060
so what

1245
01:25:33,070 --> 01:25:36,040
i was interested in his

1246
01:25:36,250 --> 01:25:38,840
integrated x now

1247
01:25:39,480 --> 01:25:45,400
if x is the variable but also w as a latent variable as well because

1248
01:25:45,420 --> 01:25:49,140
parameters are treated such to stochastic variables

1249
01:25:49,820 --> 01:25:54,660
and that's the definition of the disease treating approach to stochastic variable so you can

1250
01:25:56,330 --> 01:26:01,730
and you have this marginal likelihood but what you can place a prior distribution over

1251
01:26:01,740 --> 01:26:03,220
the great

1252
01:26:03,230 --> 01:26:04,870
to obtain

1253
01:26:04,890 --> 01:26:05,530
the four

1254
01:26:05,570 --> 01:26:08,000
you know you might be interested in p of y

1255
01:26:08,290 --> 01:26:14,180
the question is well why not try integrating w

1256
01:26:14,200 --> 01:26:15,450
if we being bayesian

1257
01:26:15,750 --> 01:26:19,390
optimizing with respect to x which is the reason why you might not want to

1258
01:26:19,390 --> 01:26:24,030
do that but let's ignore the moment led to see what happens

1259
01:26:24,040 --> 01:26:25,950
in this case

1260
01:26:26,270 --> 01:26:30,940
bayesian approach w which is of the same form as the prior use ever act

1261
01:26:30,960 --> 01:26:34,880
and using the same likelihood we had before

1262
01:26:34,900 --> 01:26:38,100
we obtain representation that can be viewed as the dual

1263
01:26:38,210 --> 01:26:41,110
the previous marginal likelihood so before

1264
01:26:41,300 --> 01:26:43,460
is where all the axes are

1265
01:26:43,480 --> 01:26:45,370
well that is why there are

1266
01:26:46,220 --> 01:26:48,310
so split between the two

1267
01:26:48,320 --> 01:26:50,060
you notice here

1268
01:26:50,070 --> 01:26:51,480
we had before

1269
01:26:51,500 --> 01:26:53,140
and we've got axes

1270
01:26:53,300 --> 01:26:56,240
the other difference is well before

1271
01:26:56,320 --> 01:26:57,500
the product was

1272
01:26:57,520 --> 01:27:00,430
the individual data points

1273
01:27:00,560 --> 01:27:04,380
this is of the design matrix math

1274
01:27:05,090 --> 01:27:10,990
design matrix now the distributions over the columns of design matrix of independent is different

1275
01:27:11,150 --> 01:27:14,650
this covariance matrix is different

1276
01:27:14,660 --> 01:27:15,920
when you this

1277
01:27:15,930 --> 01:27:19,740
and you want to maximize the effect with respect to x

1278
01:27:19,760 --> 01:27:25,960
and you've got something like this that someone else's maximize expected you are strong position

1279
01:27:26,280 --> 01:27:30,910
because you have to have a

1280
01:27:31,030 --> 01:27:36,380
so extremely similar to before the maximum likelihood solution to this you can obtain a

1281
01:27:36,380 --> 01:27:40,080
solution with respect to x

1282
01:27:40,700 --> 01:27:44,780
the dual form before we transpose right here

1283
01:27:44,790 --> 01:27:49,510
now we have what transpires that inner product matrix

1284
01:27:49,530 --> 01:27:54,920
again we have a little issue with some our content for this the prime here

1285
01:27:54,940 --> 01:28:00,610
another unusual notation for prime number in this case you q of the first q

1286
01:28:00,660 --> 01:28:02,280
factor vectors all

1287
01:28:02,300 --> 01:28:03,930
one of the times e

1288
01:28:04,060 --> 01:28:09,250
in the matrix before we had one n times to compare well with the covariance

1289
01:28:09,250 --> 01:28:12,440
matrix that and the corresponding eigenvalues are

1290
01:28:12,450 --> 01:28:13,720
lambda q

1291
01:28:13,730 --> 01:28:14,700
in fact

1292
01:28:14,760 --> 01:28:17,150
and is identical because of

1293
01:28:17,210 --> 01:28:24,070
relationship between the organ that value problem on the problem and the covariance matrix

1294
01:28:24,090 --> 01:28:27,630
so it turns out

1295
01:28:27,640 --> 01:28:31,820
then in fact these two formulations actually completely equivalent

1296
01:28:31,950 --> 01:28:33,910
the solution for the you

1297
01:28:33,920 --> 01:28:35,540
tipping and bishop PCA

1298
01:28:35,570 --> 01:28:39,380
is on the covariance matrix and nineteen inverse problem on the covariance matrix now the

1299
01:28:39,380 --> 01:28:41,960
the solution to the dual probabilistic PCA

1300
01:28:41,970 --> 01:28:45,320
in in the problem on the inner product matrix

1301
01:28:45,340 --> 01:28:50,820
the equivalence is from the fact that you can write set satellite vectors projection

1302
01:28:50,830 --> 01:28:52,280
of y

1303
01:28:52,300 --> 01:28:56,040
along the other side by convective times the i can values which is shed for

1304
01:28:56,040 --> 01:28:59,370
both problems

1305
01:28:59,480 --> 01:29:01,020
so this is not

1306
01:29:01,570 --> 01:29:06,180
and one show you have to derive a kernel PCA i'm not

1307
01:29:09,260 --> 01:29:13,200
nineteen because they see what transpires and that's an inner product matrix so this is

1308
01:29:13,220 --> 01:29:18,670
the starting to PCA which bernadette developed i guess seven years ago now

1309
01:29:20,530 --> 01:29:22,110
but we're not going to do that

1310
01:29:22,130 --> 01:29:25,970
one thing to do that because that i did before

1311
01:29:25,980 --> 01:29:30,290
and what we do is is now

1312
01:29:30,330 --> 01:29:35,270
process likelihood is of this form the probability of some of the observed data given

1313
01:29:35,270 --> 01:29:40,240
x is the gaussians with the kernel matrix zoubin showed us this on

1314
01:29:42,090 --> 01:29:44,810
so if we select the linear kernel

1315
01:29:44,820 --> 01:29:50,300
we notice the likelihood model for dual probabilistic PCA is the product of downstream processes

1316
01:29:50,790 --> 01:29:52,640
but here

1317
01:29:52,670 --> 01:29:57,790
is on the latent space not on the observed data space

1318
01:29:57,850 --> 01:30:01,850
so the joint probabilistic PCA is what i call

1319
01:30:01,850 --> 01:30:03,010
to be

1320
01:30:03,160 --> 01:30:06,660
you want to be banned as he said love to be to be right and

1321
01:30:06,660 --> 01:30:09,310
so on and so on you make it constant number of those changes you the

1322
01:30:09,310 --> 01:30:10,680
parents as well

1323
01:30:10,700 --> 01:30:14,470
it's only a constant number of links that are changing because number

1324
01:30:14,510 --> 01:30:17,060
assignments you need to do

1325
01:30:17,100 --> 01:30:21,260
OK you have probably seen partitions before

1326
01:30:21,290 --> 01:30:25,930
but we're going to use them

1327
01:30:25,950 --> 01:30:28,760
in a complicated way

1328
01:30:28,770 --> 01:30:42,080
so let's look at how to do insertions

1329
01:30:42,100 --> 01:30:45,470
we'll see it three times in some sense

1330
01:30:45,620 --> 01:30:53,720
first outside the basic idea which is pretty simple

1331
01:30:53,740 --> 01:30:57,470
mention some of it already and do it on an example feeling

1332
01:30:57,490 --> 01:30:59,970
in our bones and then we'll get the

1333
01:31:01,390 --> 01:31:04,740
so we go home and implemented if you want it

1334
01:31:04,850 --> 01:31:09,540
because this is i should say red black and search

1335
01:31:09,540 --> 01:31:13,270
in the book is called RB insert

1336
01:31:13,330 --> 01:31:14,600
not for repair

1337
01:31:14,600 --> 01:31:17,060
red black

1338
01:31:17,080 --> 01:31:23,350
OK so the first thing do is i said is binary search tree insert that

1339
01:31:23,350 --> 01:31:28,010
no so x now becomes the newly researcher x were supposed to go

1340
01:31:28,030 --> 01:31:29,350
we created new

1341
01:31:29,370 --> 01:31:31,330
should call leave now it's now

1342
01:31:31,760 --> 01:31:32,950
and node

1343
01:31:32,950 --> 01:31:37,180
hanging off an internal node hanging of one of the original nodes maybe we added

1344
01:31:37,200 --> 01:31:39,160
right here it now gets too

1345
01:31:39,200 --> 01:31:41,640
movies hanging on

1346
01:31:41,640 --> 01:31:43,990
it has no internal children

1347
01:31:44,040 --> 01:31:48,370
and we get to pick a color for

1348
01:31:50,080 --> 01:31:52,970
we will have the color red

1349
01:31:52,990 --> 01:31:55,990
why red

1350
01:31:56,010 --> 01:32:00,260
would like to request to college because for the coin that might work but it's

1351
01:32:00,260 --> 01:32:03,680
going to make our job even messier so

1352
01:32:03,700 --> 01:32:09,700
we're adding and you know because no relief presumably so we don't really need to

1353
01:32:09,700 --> 01:32:11,600
be blocked by property two

1354
01:32:11,620 --> 01:32:14,580
three three every right now has the black hair

1355
01:32:14,600 --> 01:32:16,410
might be a problem

1356
01:32:17,260 --> 01:32:20,450
problem is if it's apparent is red

1357
01:32:21,700 --> 01:32:24,100
then we violate property two

1358
01:32:24,100 --> 01:32:30,160
apparently read

1359
01:32:30,180 --> 01:32:36,290
thirty three

1360
01:32:36,310 --> 01:32:41,580
the good news is that property four is still true

1361
01:32:41,600 --> 01:32:46,030
because property forces counting numbers of blackman's down very sparse that's really the hard property

1362
01:32:46,040 --> 01:32:47,120
to maintain

1363
01:32:47,140 --> 01:32:51,640
we just added red now and the black eyed change and the number of black

1364
01:32:51,640 --> 01:32:53,810
nodes along the path changes

1365
01:32:53,810 --> 01:32:56,160
so this still has to hold

1366
01:32:56,180 --> 01:32:58,870
the only thing we can violate this property three

1367
01:32:59,850 --> 01:33:02,470
reasonable we know we've got to highlight something

1368
01:33:02,740 --> 01:33:07,580
at the beginning just we can just do a binary search tree insert

1369
01:33:10,910 --> 01:33:13,870
let's give it a try

1370
01:33:13,890 --> 01:33:18,450
this tree

1371
01:33:18,620 --> 01:33:22,180
she so we're

1372
01:33:22,260 --> 01:33:23,910
power going to fix this

1373
01:33:25,560 --> 01:33:26,600
how do we fix

1374
01:33:26,620 --> 01:33:27,970
property three

1375
01:33:28,040 --> 01:33:34,510
we're going to remove the violation of three

1376
01:33:34,580 --> 01:33:36,640
the tree

1377
01:33:36,700 --> 01:33:41,990
so we're going to start node x up towards the roof

1378
01:33:43,310 --> 01:33:49,160
this is via three coloring only thing initially will do is we're coloring

1379
01:33:49,180 --> 01:33:51,160
until we get some point

1380
01:33:52,700 --> 01:33:58,830
where we can fix the violation using rotation

1381
01:33:58,950 --> 01:34:12,790
and probably also three colouring

1382
01:34:12,850 --> 01:34:22,270
OK so let's see this algorithm in action

1383
01:34:22,290 --> 01:34:26,790
copy this tree and you're going to have to copy it to sort of

1384
01:34:26,810 --> 01:34:29,100
instead of modifying that

1385
01:34:29,100 --> 01:34:46,950
so we have this nice red black tree

1386
01:34:46,970 --> 01:34:53,140
and we'll try inserting any value of fifteen

1387
01:34:59,010 --> 01:35:01,140
twenty one

1388
01:35:01,140 --> 01:35:08,830
twenty two is the new black

1389
01:35:08,850 --> 01:35:13,060
OK should be the same tree

1390
01:35:13,060 --> 01:35:13,850
so now

1391
01:35:13,870 --> 01:35:18,450
i'm choosing the number fifteen to insert because that will show

1392
01:35:18,470 --> 01:35:23,080
fairly interesting insertion sometimes assertion doesn't take very much work we just rotation and we're

1393
01:35:24,450 --> 01:35:27,930
here i like to look at

1394
01:35:27,950 --> 01:35:31,830
an interesting case so insert fifteen fifteen is better than seven is less than eighteen

1395
01:35:31,830 --> 01:35:35,950
it's bigger than ten is bigger than levels fifteen goes here

1396
01:35:35,970 --> 01:35:37,410
so we add a new

1397
01:35:37,430 --> 01:35:38,430
red nodes

1398
01:35:39,680 --> 01:35:41,600
it has two

1399
01:35:41,620 --> 01:35:43,560
black leaves hanging off of it

1400
01:35:43,580 --> 01:35:47,370
replaced one likely now we have two

1401
01:35:50,830 --> 01:35:56,580
we violate property three

1402
01:35:56,600 --> 01:36:00,240
because we added in the right child of red now so now we have two

1403
01:36:00,240 --> 01:36:02,620
consecutive red nose in route to the past

1404
01:36:02,640 --> 01:36:06,160
we'd like to make this black but that would screw up the black kites because

1405
01:36:06,160 --> 01:36:10,540
now this node would have one black node over here and two black nodes this

1406
01:36:10,560 --> 01:36:13,390
so that's not good

1407
01:36:13,410 --> 01:36:17,740
what can we do well let's try to re color

1408
01:36:23,620 --> 01:36:27,080
this is always

1409
01:36:27,180 --> 01:36:31,220
for the last remember

1410
01:36:31,240 --> 01:36:33,760
six is going to be to re color

1411
01:36:33,770 --> 01:36:36,850
and the first thing that struck me which doesn't work is we try to recall

1412
01:36:36,910 --> 01:36:38,310
around here

1413
01:36:38,330 --> 01:36:40,120
doesn't look so good because

1414
01:36:40,140 --> 01:36:43,830
you know we've got red stuff down here we got black net over here so

1415
01:36:43,830 --> 01:36:47,160
we can make this one red and one black quite work

1416
01:36:47,180 --> 01:36:49,310
if we look at the little higher

1417
01:36:49,330 --> 01:36:51,890
at the grandparent of fifteen

1418
01:36:53,180 --> 01:36:56,680
we have a black cloud here and two red children

1419
01:36:56,700 --> 01:36:59,490
that's actually pretty good news because

1420
01:36:59,530 --> 01:37:01,410
we could instead make that

1421
01:37:01,430 --> 01:37:04,790
two black children and the red parent

1422
01:37:04,810 --> 01:37:06,830
he locally that's going to be fine

1423
01:37:06,850 --> 01:37:11,120
it's not going to change any black kites because any path that went through these

1424
01:37:11,120 --> 01:37:12,200
nodes before

1425
01:37:12,260 --> 01:37:15,950
will still go through the same number of black nodes instead of going through black

1426
01:37:16,160 --> 01:37:20,140
always here it will go through black either here or here because that has always

1427
01:37:20,140 --> 01:37:22,350
going to leaves

1428
01:37:22,350 --> 01:37:26,070
to this degree of membership to the set of normal people is point three noted

1429
01:37:26,250 --> 01:37:28,290
have to add up to point three

1430
01:37:28,930 --> 01:37:33,510
and for car power sitting because his car belongs to the set of medium

1431
01:37:33,530 --> 01:37:38,230
powered cars to point seven two high-powered cars to point four

1432
01:37:38,270 --> 01:37:41,810
you can combine these two things of course

1433
01:37:41,830 --> 01:37:46,010
you draw inferences and how true is this will miss a lot and will use

1434
01:37:46,110 --> 01:37:50,430
imax operator for example just nokia planes are

1435
01:37:50,450 --> 01:37:55,970
a whatever it was i think the numbers should probably not help yes

1436
01:37:56,010 --> 01:38:00,010
the point eight the point four you together using the minimum operator both of these

1437
01:38:00,010 --> 01:38:04,870
conditions have been true it's will says if age is young and car power is

1438
01:38:04,870 --> 01:38:09,290
high so the degree of fulfilment for this was point for how true is the

1439
01:38:09,290 --> 01:38:14,190
antecedent to what degree of membership doesn't belong to all these conditions that we have

1440
01:38:14,190 --> 01:38:15,810
in our antecedent

1441
01:38:15,830 --> 01:38:19,760
of the world one an awful again they are combining these two degrees of membership

1442
01:38:19,780 --> 01:38:23,050
and i think it was point three eight point seven so many more for those

1443
01:38:23,050 --> 01:38:26,870
who simply point three so this rule this is is also say this is the

1444
01:38:26,870 --> 01:38:31,030
degree of fulfilment for a specific rule this point the this is the degree of

1445
01:38:31,030 --> 01:38:33,650
fulfilment for rule one which is point four

1446
01:38:39,850 --> 01:38:44,710
OK so now we can go on

1447
01:38:44,730 --> 01:38:46,730
try to figure out what do we do

1448
01:38:46,770 --> 01:38:51,150
without consequences obviously since will is not fulfilled

1449
01:38:51,170 --> 01:38:57,170
two two degree of one this consequent shouldn't be part of the result of looking

1450
01:38:57,170 --> 01:39:03,590
at this entire will this fall the results so we do now is we

1451
01:39:03,630 --> 01:39:07,710
we restrict the consequence that you have you combine them

1452
01:39:09,310 --> 01:39:14,290
can so that using again our our minimum one sort of the degree of fulfilment

1453
01:39:14,890 --> 01:39:20,010
how much does this person belong to the and the consequent of the world

1454
01:39:20,170 --> 01:39:23,710
so the this is the membership function the sort of falls out of rule one

1455
01:39:24,170 --> 01:39:28,350
and this is the membership function solid red area of the faults of two

1456
01:39:28,430 --> 01:39:32,410
then we combined the two essentially using next norms using in our case he or

1457
01:39:32,410 --> 01:39:37,790
operator and this is the final fuzzy set but this will the school system produces

1458
01:39:38,030 --> 01:39:42,150
so this is the this is the fuzzy set for the risk of this particular

1459
01:39:42,150 --> 01:39:49,030
driver but has age a and try to get insurance for car power to be

1460
01:39:49,050 --> 01:39:53,190
this is of course nice and if you look now wanted to use that to

1461
01:39:53,190 --> 01:39:58,350
continue computations plug that into some sort of a premium calculator you may actually continue

1462
01:39:58,350 --> 01:40:03,110
using the fuzzy sets in our case now want an american value because our insurance

1463
01:40:03,110 --> 01:40:08,650
guys are instructed to reject everybody who is in risk ratio of eighty or higher

1464
01:40:08,650 --> 01:40:13,390
so we want to create a crisp crisp value out of this one and the

1465
01:40:13,390 --> 01:40:18,010
classical way of computing crisp values is

1466
01:40:18,510 --> 01:40:21,850
goes on the defensive occasionally want to go back from this fuzzy set to a

1467
01:40:22,010 --> 01:40:26,050
crisp number the classical way to do do that the centre of gravity

1468
01:40:26,170 --> 01:40:30,190
the centre of gravity just tries to find all the centre of gravity sort of

1469
01:40:30,200 --> 01:40:34,550
try to balance this thing with the fuzzy set stick it falls down and they

1470
01:40:34,550 --> 01:40:37,130
really do that is you've got interval

1471
01:40:37,150 --> 01:40:40,270
why times the degree of membership of the

1472
01:40:40,290 --> 01:40:45,430
resulting membership function and you need to normalise it is actually percent of gravity which

1473
01:40:45,430 --> 01:40:53,050
is of course nasty to compute slightly easier approximation all doing is i'm going to

1474
01:40:53,050 --> 01:40:57,930
look at the fuzzy sets that i have these politicians much pain

1475
01:40:59,990 --> 01:41:07,730
now i have one way of doing this is essentially just you this tool but

1476
01:41:07,810 --> 01:41:09,410
said that we combined

1477
01:41:09,630 --> 01:41:15,530
the centre of gravity tries to balance this sort of a stick it tries to

1478
01:41:15,530 --> 01:41:20,050
find out of system has a certain mass this absurd must so probably the centre

1479
01:41:20,050 --> 01:41:24,950
of gravity somewhere here for quite abundant in minute just project this

1480
01:41:25,500 --> 01:41:32,710
risk and that gives me my are built on fuzzy five dollars that's one way

1481
01:41:32,710 --> 01:41:36,290
of doing that but alternatively i can of course also say well if i knew

1482
01:41:36,360 --> 01:41:38,350
the centre of gravity for this one

1483
01:41:38,390 --> 01:41:40,830
this is my s j

1484
01:41:40,980 --> 01:41:41,750
the thank

1485
01:41:41,970 --> 01:41:45,750
and if i knew the centre of gravity for this one this is what it

1486
01:41:45,750 --> 01:41:47,810
was was not a statement

1487
01:41:47,850 --> 01:41:51,310
cool had another membership function here and this is

1488
01:41:53,430 --> 01:41:58,570
and then i also know the degree of fulfilment that that's used before i think

1489
01:41:58,570 --> 01:42:00,730
that this will too

1490
01:42:00,990 --> 01:42:08,290
twenty of my of my to point three i think that's really are

1491
01:42:09,230 --> 01:42:13,430
the first world movies the

1492
01:42:13,550 --> 01:42:18,450
i could simply multiply those and do a weighted sum which results in

1493
01:42:18,490 --> 01:42:20,950
almost the same value right

1494
01:42:20,970 --> 01:42:25,410
two authors of the movie get same value here and that's of course and that

1495
01:42:25,410 --> 01:42:28,530
is the compute because you don't have to do the integral to actually find out

1496
01:42:28,530 --> 01:42:30,810
what that is you want to compute that

1497
01:42:30,890 --> 01:42:34,250
in the machine if you want to implement the fuzzy inference is that all you

1498
01:42:34,250 --> 01:42:38,070
needed to do was pretty compute the centre of gravity s two and s three

1499
01:42:38,070 --> 01:42:41,470
which are always the same for these fuzzy sets and then you can use the

1500
01:42:41,470 --> 01:42:46,250
degrees of fulfilment multiply them to and it's great something about

1501
01:42:46,450 --> 01:42:51,130
why is that not entirely the same volunteered doing is of course you're this area

1502
01:42:51,780 --> 01:42:56,250
you're incorporating that twice computation this weighted sum

1503
01:42:56,270 --> 01:43:00,370
and if you do and which is of course not quite the same as doing

1504
01:43:00,410 --> 01:43:03,030
the centre of gravity just for this for the

1505
01:43:03,050 --> 01:43:04,730
he was area

1506
01:43:04,750 --> 01:43:08,830
but in most cases you don't really care it's funny after all anyway

1507
01:43:08,850 --> 01:43:12,090
that is another way

1508
01:43:12,670 --> 01:43:18,570
to go back from our fuzzy set to a crisp value

1509
01:43:18,590 --> 01:43:23,470
and we can look at sort of the fuzzy inference process once again my valuable

1510
01:43:23,500 --> 01:43:29,950
such sort of the summary you have three main steps into the classification try to

1511
01:43:29,950 --> 01:43:34,910
convert your measurement that you have into degrees of membership for fuzzy sets using inside

1512
01:43:35,050 --> 01:43:37,190
fuzzy rule systems

1513
01:43:37,210 --> 01:43:42,250
in the inference phase you're evaluating fuzzy rule systems and you're essentially computing degrees of

1514
01:43:42,250 --> 01:43:47,530
fulfilment three rules so this very basic rule system if temperature is called and we

1515
01:43:47,540 --> 01:43:51,690
open the vault of our heating system if temperature small management half the temperature is

1516
01:43:51,690 --> 01:43:54,070
hot and we'll

1517
01:43:54,090 --> 01:43:57,690
the degree of fulfilment for this particular measurement of point seven for the first rule

1518
01:43:57,700 --> 01:44:02,650
point two the second will so for the third rule we'll combine them creates a

1519
01:44:02,650 --> 01:44:06,150
so what do i find i have solved now

1520
01:44:06,160 --> 01:44:07,930
the general solution

1521
01:44:07,940 --> 01:44:10,120
i will find the x minus

1522
01:44:11,120 --> 01:44:13,370
is one half c

1523
01:44:13,390 --> 01:44:15,440
and have zero plus

1524
01:44:15,490 --> 01:44:18,840
it is also one half c which of course should not come

1525
01:44:18,890 --> 01:44:26,400
as a surprise to you

1526
01:44:26,450 --> 01:44:28,430
four let me right down now

1527
01:44:28,440 --> 01:44:31,400
the general solution that we have

1528
01:44:31,450 --> 01:44:34,670
for this specific initial conditions

1529
01:44:34,680 --> 01:44:36,250
so we know everything

1530
01:44:36,270 --> 01:44:39,650
we know x zero one lenox zero

1531
01:44:39,740 --> 01:44:43,900
one minus axial not one example my as we know it zero plus

1532
01:44:43,920 --> 01:44:47,220
we know five we know everything

1533
01:44:47,270 --> 01:44:50,250
so i'm going to write it down here

1534
01:44:50,260 --> 01:44:51,390
x one

1535
01:44:51,400 --> 01:44:56,490
it's going to be one half c

1536
01:44:56,540 --> 01:44:59,440
number one one

1537
01:44:59,480 --> 01:45:01,130
times the cosine

1538
01:45:01,160 --> 01:45:04,820
of omega t because phi zero

1539
01:45:05,600 --> 01:45:08,430
one half c

1540
01:45:10,200 --> 01:45:13,200
this is the miners by the way cosine omega minus two

1541
01:45:13,250 --> 01:45:16,800
cosine omega lost

1542
01:45:16,840 --> 01:45:17,520
that is

1543
01:45:17,530 --> 01:45:19,720
x one

1544
01:45:19,720 --> 01:45:22,130
and x two

1545
01:45:22,140 --> 01:45:24,320
one half the

1546
01:45:24,510 --> 01:45:27,730
the cosine omega minus two minus

1547
01:45:27,740 --> 01:45:29,600
one half c

1548
01:45:29,640 --> 01:45:31,000
and the the cosine

1549
01:45:31,060 --> 01:45:34,700
we got lost

1550
01:45:34,760 --> 01:45:38,430
they could be breath substituting that equals zero

1551
01:45:38,490 --> 01:45:41,500
you see immediately that ecstasy

1552
01:45:41,550 --> 01:45:43,980
and substitute equals here in the second

1553
01:45:43,990 --> 01:45:46,320
and you see that x was it

1554
01:45:46,370 --> 01:45:48,190
no surprise because that's my

1555
01:45:48,240 --> 01:45:51,700
initial condition

1556
01:45:51,700 --> 01:45:54,620
i remember from my schooldays at the cosine

1557
01:45:54,630 --> 01:45:55,600
o five

1558
01:45:55,720 --> 01:45:57,970
was the cosine of data

1559
01:45:57,980 --> 01:46:00,900
is twice the cosine of half the sum

1560
01:46:00,940 --> 01:46:02,960
times the cosine of half

1561
01:46:02,980 --> 01:46:04,300
the difference

1562
01:46:04,350 --> 01:46:06,150
so i can write down x one

1563
01:46:06,160 --> 01:46:10,500
as twice

1564
01:46:10,520 --> 01:46:13,030
the cosine of half the sum

1565
01:46:13,080 --> 01:46:16,370
times the cosine of half the difference so that tool that i get each of

1566
01:46:16,370 --> 01:46:17,890
these one house

1567
01:46:17,890 --> 01:46:19,470
so i get c

1568
01:46:19,480 --> 01:46:21,070
times the cosine

1569
01:46:21,090 --> 01:46:22,780
omega minor

1570
01:46:22,790 --> 01:46:24,080
was omega

1571
01:46:24,090 --> 01:46:26,770
was divided by two

1572
01:46:26,820 --> 01:46:28,270
i'm speak

1573
01:46:29,210 --> 01:46:30,670
the cosine

1574
01:46:30,720 --> 01:46:32,450
of omega minus

1575
01:46:32,480 --> 01:46:34,410
mine only of course

1576
01:46:34,420 --> 01:46:36,660
divided by two

1577
01:46:39,330 --> 01:46:42,800
i've just rewritten it in a different form

1578
01:46:42,850 --> 01:46:45,480
and x two

1579
01:46:45,540 --> 01:46:47,780
as a function of time

1580
01:46:47,790 --> 01:46:51,830
i know have the cosine of of minus the cosine of data

1581
01:46:51,880 --> 01:46:55,670
that's twice the sign after some time signed

1582
01:46:55,830 --> 01:46:57,880
half the difference

1583
01:46:57,880 --> 01:47:00,420
now i get you to sign

1584
01:47:00,430 --> 01:47:02,930
of omega minus

1585
01:47:03,890 --> 01:47:05,480
omega plus

1586
01:47:05,580 --> 01:47:07,830
divided by two

1587
01:47:09,050 --> 01:47:10,630
times the sign

1588
01:47:10,670 --> 01:47:13,510
omega minus minus omega plus

1589
01:47:13,570 --> 01:47:14,800
divided by two

1590
01:47:14,810 --> 01:47:19,930
thanks to

1591
01:47:22,730 --> 01:47:24,670
when t is zero

1592
01:47:24,790 --> 01:47:27,810
the sign of this one is zero

1593
01:47:27,850 --> 01:47:32,200
consistent with what our initial conditions x two zero remember

1594
01:47:32,240 --> 01:47:38,500
all their initial conditions all there was written in different for

1595
01:47:40,210 --> 01:47:43,600
imagine now in your mind

1596
01:47:43,660 --> 01:47:44,820
these two

1597
01:47:44,840 --> 01:47:49,980
frequencies are not too far apart

1598
01:47:51,030 --> 01:47:52,960
these equations

1599
01:47:52,970 --> 01:47:54,180
the smell

1600
01:47:54,190 --> 01:47:55,210
of what

1601
01:47:57,580 --> 01:48:01,210
this year is the faster

1602
01:48:01,240 --> 01:48:02,990
this one that one

1603
01:48:03,010 --> 01:48:04,220
this one

1604
01:48:04,260 --> 01:48:09,840
is this love

1605
01:48:09,910 --> 01:48:11,020
and so

1606
01:48:11,080 --> 01:48:12,940
if these two

1607
01:48:15,740 --> 01:48:20,040
and what you'll see is something quite remarkable

1608
01:48:20,160 --> 01:48:21,660
t equals zero

1609
01:48:21,670 --> 01:48:23,970
this one stand still

1610
01:48:24,020 --> 01:48:26,200
and this cosine terms

1611
01:48:26,200 --> 01:48:28,070
it's going to be one because these

1612
01:48:29,810 --> 01:48:33,250
this one is going to oscillate happily with this frequency

1613
01:48:33,260 --> 01:48:37,930
but this still cosine term is very gradually going to zero

1614
01:48:37,980 --> 01:48:40,910
and as the cosine term gradually goes to zero

1615
01:48:40,920 --> 01:48:43,640
this one will start oscillating

1616
01:48:43,690 --> 01:48:45,040
but design for

1617
01:48:45,060 --> 01:48:46,540
comes plus one

1618
01:48:46,610 --> 01:48:49,190
and so the other one will start to oscillate

1619
01:48:49,190 --> 01:48:51,190
and then a little later in time

1620
01:48:51,240 --> 01:48:53,700
the cosine term will become minus one

1621
01:48:53,730 --> 01:48:57,720
so it starts to oscillate but when that happens is assigned to zero again

1622
01:48:57,730 --> 01:48:59,140
so it's pop

1623
01:48:59,190 --> 01:49:01,740
so you see a beautiful beach phenomena

1624
01:49:02,960 --> 01:49:06,920
the first one gradually come to wall and the other one will pick up

1625
01:49:06,980 --> 01:49:09,890
and then the other one will come to hold and then

1626
01:49:13,230 --> 01:49:15,820
it is of course consistent with the conservation

1627
01:49:17,170 --> 01:49:20,500
mechanical energy

1628
01:49:20,590 --> 01:49:27,600
and i want to demonstrate that

1629
01:49:27,640 --> 01:49:30,490
we have here

1630
01:49:30,540 --> 01:49:32,790
all i have to do is offset

1631
01:49:32,800 --> 01:49:36,400
x one over this and see that we can choose

1632
01:49:36,400 --> 01:49:37,590
and then

1633
01:49:37,650 --> 01:49:41,210
released this one and zero speed and then we'll just watch

1634
01:49:41,260 --> 01:49:43,220
now you've got you should see that

1635
01:49:43,220 --> 01:49:45,830
strange phenomenon

1636
01:49:45,870 --> 01:49:47,480
ready for this

1637
01:49:47,580 --> 01:49:49,090
this one after

1638
01:49:49,140 --> 01:49:52,190
all place

1639
01:49:52,190 --> 01:49:58,520
the set of all sets

1640
01:50:03,220 --> 01:50:08,630
and you need

1641
01:50:15,360 --> 01:50:20,630
it is the

1642
01:50:20,640 --> 01:50:22,060
we're going

1643
01:50:27,200 --> 01:50:32,040
that's what i want

1644
01:50:32,060 --> 01:50:36,710
you can get

1645
01:50:36,840 --> 01:50:40,120
of the two

1646
01:50:58,660 --> 01:51:02,340
it's like

1647
01:51:02,350 --> 01:51:06,580
you have not heard

1648
01:51:11,200 --> 01:51:15,620
so far and

1649
01:51:31,170 --> 01:51:32,630
when used

1650
01:51:38,750 --> 01:51:41,750
he is very

1651
01:51:41,800 --> 01:51:46,570
the same year

1652
01:51:46,580 --> 01:51:49,580
seven of

1653
01:51:55,880 --> 01:51:58,950
he ran

1654
01:52:01,810 --> 01:52:03,010
so long

1655
01:52:40,690 --> 01:52:44,820
and as you

1656
01:52:45,520 --> 01:52:53,770
it's not for

1657
01:52:55,300 --> 01:53:02,080
this is

1658
01:53:11,250 --> 01:53:19,270
or is

1659
01:53:28,030 --> 01:53:30,040
i don't know how

1660
01:53:30,060 --> 01:53:38,190
that where are more

1661
01:53:39,270 --> 01:53:43,760
these are

1662
01:54:01,630 --> 01:54:12,950
the first part

1663
01:54:16,470 --> 01:54:26,720
here he is

1664
01:54:28,040 --> 01:54:30,800
so far

1665
01:55:02,590 --> 01:55:06,350
what we need

1666
01:55:09,970 --> 01:55:14,340
are you know i mean

1667
01:55:18,010 --> 01:55:19,370
it is

1668
01:55:19,400 --> 01:55:22,860
and also

1669
01:55:22,860 --> 01:55:24,870
OK now nearly as well

1670
01:55:24,890 --> 01:55:29,790
so this and becomes an in times square

1671
01:55:29,840 --> 01:55:34,090
since all are how can you every time window don't do nearly as well the

1672
01:55:34,090 --> 01:55:36,610
best role for that time window i mean

1673
01:55:36,620 --> 01:55:39,810
what about this thing costly for

1674
01:55:40,820 --> 01:55:44,880
nearly as well only make sense of the time windows big if

1675
01:55:45,030 --> 01:55:48,470
if the time when the sort and this is not a very interesting statement the

1676
01:55:48,480 --> 01:55:52,780
say in that time window i'm only doing this much worse than the best run

1677
01:55:52,960 --> 01:55:54,940
time and again

1678
01:55:55,110 --> 01:56:02,140
the time and was only alive responsive that's really not a very good guarantee at

1679
01:56:02,140 --> 01:56:04,770
all so this can be only make sense for

1680
01:56:05,330 --> 01:56:07,550
rules the fire

1681
01:56:07,560 --> 01:56:10,010
more than this many times

1682
01:56:10,060 --> 01:56:13,640
we think of as for only fires once or twice the now we're going to

1683
01:56:13,640 --> 01:56:16,820
really figure out whether it's a good rule or just

1684
01:56:16,930 --> 01:56:20,850
you know it just maybe if rules firing randomly and you know how to it

1685
01:56:20,850 --> 01:56:22,710
actually stock markets great example

1686
01:56:22,730 --> 01:56:26,860
you've got this mutual funds you know the millions of they also it will be

1687
01:56:26,860 --> 01:56:28,260
a great the last

1688
01:56:28,300 --> 01:56:32,020
you know the last ten months with great but if it is behaving randomly just

1689
01:56:32,020 --> 01:56:34,740
by chance some of them are going to great lengths to months

1690
01:56:34,840 --> 01:56:39,420
so it's their advanced instantiate many mutual funds they can

1691
01:56:39,460 --> 01:56:42,070
like hope one of them that's when they get

1692
01:56:43,420 --> 01:56:48,790
students to make more sense later on

1693
01:56:48,980 --> 01:56:51,940
they can be so

1694
01:56:55,690 --> 01:57:00,640
so anyway it's the same kind of thing here if the world is not fired

1695
01:57:00,640 --> 01:57:03,690
very much we really can't tell what really good rule

1696
01:57:03,710 --> 01:57:07,360
this is so there is no way to tell verses just by random chance you

1697
01:57:07,360 --> 01:57:08,860
know i happen to be walking

1698
01:57:08,940 --> 01:57:12,990
so here again even wireless many times in order for this rule to make it

1699
01:57:13,000 --> 01:57:15,880
to be meaningful meaningful

1700
01:57:15,940 --> 01:57:17,490
OK that's one way

1701
01:57:17,510 --> 01:57:19,310
and you can have this property

1702
01:57:19,350 --> 01:57:23,470
switching you can instantiate new rules that say

1703
01:57:23,520 --> 01:57:26,600
basically just that they start at some point in time the future and so i

1704
01:57:26,600 --> 01:57:28,680
think you should use

1705
01:57:31,780 --> 01:57:35,240
we talk about that then we talked about things

1706
01:57:35,280 --> 01:57:38,760
we talked about minimax optimality and we talked about

1707
01:57:38,880 --> 01:57:40,940
place names i also money

1708
01:57:41,030 --> 01:57:46,510
how about some more money today

1709
01:57:48,070 --> 01:57:49,690
we saw the minimax theorem

1710
01:57:49,700 --> 01:57:52,580
the minimax theorem says that

1711
01:57:52,600 --> 01:57:59,260
based on a zero sum game in your competing against someone it's competitive game and

1712
01:57:59,640 --> 01:58:06,180
so you think that you know if you have to reveal your randomized strategy first

1713
01:58:06,230 --> 01:58:09,510
using the information the minimax theorem says that

1714
01:58:09,590 --> 01:58:14,590
the there's every zero sum game has a unique value where the row player reveals

1715
01:58:14,590 --> 01:58:19,550
the randomized strategy first they can guarantee value is the

1716
01:58:19,590 --> 01:58:22,680
one of those games that was four point cents no matter what the other player

1717
01:58:22,680 --> 01:58:27,420
does and furthermore the other player in the my strategy they can reveal guarantees they

1718
01:58:27,420 --> 01:58:32,990
will not be well defined value the game in particular these regret minimising algorithms give

1719
01:58:32,990 --> 01:58:34,150
away to play

1720
01:58:41,170 --> 01:58:45,690
the case of the regret minimising out they in fact have the property

1721
01:58:45,730 --> 01:58:49,930
so you use one your guaranteeing to do nearly as well as the best fixed

1722
01:58:49,930 --> 01:58:53,020
which you could have made in hindsight is what that means is that if the

1723
01:58:53,050 --> 01:58:55,360
opponent is playing

1724
01:58:55,540 --> 01:58:58,690
the minimax optimal strategy well

1725
01:58:58,730 --> 01:59:01,850
there will be some choice in hindsight that gets you value the

1726
01:59:01,870 --> 01:59:03,830
you'll you'll be doing this as well as the

1727
01:59:03,940 --> 01:59:08,130
but upon is not playing very well maybe it's a complicated game maybe your about

1728
01:59:08,170 --> 01:59:11,350
business and the game well maybe not very good at what you you're going to

1729
01:59:11,490 --> 01:59:14,850
do is do nearly as well as the best fixed wrapped in hindsight that could

1730
01:59:14,850 --> 01:59:15,870
be even better

1731
01:59:16,080 --> 01:59:20,920
the the fear upon is not the kind of night nice things you could solve

1732
01:59:20,930 --> 01:59:23,290
minimax optimal strategy using

1733
01:59:23,410 --> 01:59:26,250
linear programming but if the user and minimizing strategy

1734
01:59:26,270 --> 01:59:27,490
you will

1735
01:59:27,500 --> 01:59:30,850
they released as well except for the last term

1736
01:59:30,850 --> 01:59:33,110
majority i think of problems that people

1737
01:59:33,190 --> 01:59:38,530
a study in applied fields are in some way supervised learning problem

1738
01:59:38,550 --> 01:59:39,290
the other

1739
01:59:40,400 --> 01:59:45,420
it's called unsupervised learning and the reason it's called unsupervised because there's no input so

1740
01:59:45,540 --> 01:59:48,730
is no output unit given the signal this is the output i want you to

1741
01:59:48,730 --> 01:59:53,130
match you just given a bunch of inputs and ask something vague like fine structure

1742
01:59:53,130 --> 01:59:59,890
in the data or cluster the data so unsupervised learning is it's

1743
01:59:59,940 --> 02:00:05,110
one of the sirens of applied statistics is very appealing in some way it's very

1744
02:00:05,110 --> 02:00:09,820
fun to work on in some sense it's kind of you feel like it's more

1745
02:00:09,820 --> 02:00:14,770
purely scientific and yet it has a serious problem that is very difficult to define

1746
02:00:14,770 --> 02:00:19,630
what we mean by success in unsupervised learning right in supervised learning it's very easy

1747
02:00:19,630 --> 02:00:26,160
to define a very sensible measures of success like classification well what fraction of the

1748
02:00:26,330 --> 02:00:30,060
inputs are you going to get right when i test you on some more data

1749
02:00:30,350 --> 02:00:34,200
seen before i will talk about that second in unsupervised learning it's not so clear

1750
02:00:34,200 --> 02:00:38,250
by show you some data and i say he was measurements of a thousand customers

1751
02:00:38,250 --> 02:00:42,350
from the supermarket please cluster them into three groups and you come back and you

1752
02:00:42,350 --> 02:00:46,350
say OK i cluster them into three groups and how to evaluate whether you really

1753
02:00:46,350 --> 02:00:47,830
did a good job

1754
02:00:47,840 --> 02:00:50,500
and that's the problem with unsupervised

1755
02:00:50,520 --> 02:00:55,610
a very simple form of unsupervised learning which is very popular in data mining is

1756
02:00:55,610 --> 02:00:56,950
called rule learning

1757
02:00:57,000 --> 02:01:00,210
in learning and trying to discover

1758
02:01:00,240 --> 02:01:05,730
very common joint settings of measurements in the database so maybe it's very common that you see

1759
02:01:05,740 --> 02:01:10,800
in a sense this database very common that you see someone who is say

1760
02:01:10,850 --> 02:01:12,870
you know over forty

1761
02:01:12,880 --> 02:01:16,290
has a university education and owns a car

1762
02:01:16,300 --> 02:01:19,590
that triple might be very common and so you might say have a rule which

1763
02:01:19,590 --> 02:01:22,920
says if you're over forty and you have a university education that are predicted very

1764
02:01:22,920 --> 02:01:24,530
likely to your car

1765
02:01:24,540 --> 02:01:32,500
and then the sort of ultimate artificial intelligence problem at some level is called reinforcement

1766
02:01:32,500 --> 02:01:34,980
learning and reinforcement learning is really the

1767
02:01:35,460 --> 02:01:39,970
the formal study of how do you get agents to act in an unknown environment

1768
02:01:40,250 --> 02:01:44,740
so that the general setup for reinforcement learning is that you have a world which

1769
02:01:44,740 --> 02:01:49,240
has a number of possible states could be huge number of possible states you have

1770
02:01:49,240 --> 02:01:55,060
an agent which can perform actions and every time the agent performs actions and action

1771
02:01:55,060 --> 02:01:59,320
it changes the state of the world in the age get either some punishment or

1772
02:01:59,320 --> 02:02:02,270
some reward for being in the various states

1773
02:02:02,290 --> 02:02:06,220
and now what you want to do is learn what's called the policy which is

1774
02:02:06,220 --> 02:02:11,290
the set of rules for the agent to take actions but i don't tell you

1775
02:02:11,300 --> 02:02:15,600
the entire i don't reveal to the inner workings of the world that i give

1776
02:02:15,600 --> 02:02:17,600
you the big carrot in a big stick

1777
02:02:17,610 --> 02:02:20,860
and you take actions in the world and when you do something that i don't

1778
02:02:20,860 --> 02:02:23,490
like i beat you over the head and say that was bad and when you

1779
02:02:23,490 --> 02:02:26,260
do something that i like to give you some cookies and so that was good

1780
02:02:26,260 --> 02:02:29,400
and you have to figure out how to act in the world so that's really

1781
02:02:29,410 --> 02:02:35,210
the kind of ultimate agent learning problem right you can imagine that you just take

1782
02:02:35,210 --> 02:02:37,980
a robot and you throw it out in the world and it just does random

1783
02:02:37,980 --> 02:02:42,390
things and then you know it gets this reinforcement and eventually learns to bring you

1784
02:02:42,390 --> 02:02:48,770
the facts and the facts machine cappuccino with it but it's it's difficult it's very

1785
02:02:48,770 --> 02:02:52,050
difficult general problem and i'm not going to talk about that and i don't think

1786
02:02:52,050 --> 02:02:55,440
that anyone on the schedule this year is going to others

1787
02:02:55,460 --> 02:02:57,330
OK great good so

1788
02:02:57,340 --> 02:03:01,890
i'll that to that's a very tough problems that on the site OK

1789
02:03:01,900 --> 02:03:06,650
so now want to get into some more technical things about machine learning and hopefully

1790
02:03:06,650 --> 02:03:09,760
we can we can make some progress and get two

1791
02:03:09,770 --> 02:03:12,370
get some some problems

1792
02:03:12,410 --> 02:03:17,600
we actually have to do with these graphical models little talk about so

1793
02:03:17,660 --> 02:03:21,410
one key issue in machine learning is visual representation

1794
02:03:21,430 --> 02:03:25,380
so when i told you that i wanted to take a picture of this this

1795
02:03:25,380 --> 02:03:30,470
image represents my face and have you write a computer program that says all that

1796
02:03:30,470 --> 02:03:33,490
sam roweis how are you going to

1797
02:03:33,490 --> 02:03:38,770
represent the image inside your computer program so every task that you want to do

1798
02:03:38,770 --> 02:03:44,560
it involves accepting some input from the real world and that input almost always originates

1799
02:03:44,950 --> 02:03:51,900
in some kind of mechanical censor or data recording device or a lot of some

1800
02:03:52,400 --> 02:03:53,760
computers somewhere

1801
02:03:53,770 --> 02:03:58,050
and then before you can actually process that input you need to convert it into

1802
02:03:58,050 --> 02:04:04,350
a particular numerical representation that computer programming and machine learning algorithm can attack

1803
02:04:04,370 --> 02:04:07,760
and one example


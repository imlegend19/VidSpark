1
00:00:00,000 --> 00:00:02,300
is some

2
00:00:03,790 --> 00:00:06,400
this sequence

3
00:00:06,410 --> 00:00:08,610
x y

4
00:00:08,620 --> 00:00:19,470
of the low-level feature function

5
00:00:19,560 --> 00:00:22,410
what little fj

6
00:00:29,160 --> 00:00:33,670
these low-level feature functions

7
00:00:33,680 --> 00:00:40,030
my often more into it when you talk about sequences the low-level feature functions can

8
00:00:40,030 --> 00:00:42,040
be more intuitive than the

9
00:00:42,230 --> 00:00:44,020
high level feature functions

10
00:00:44,910 --> 00:00:49,520
a lot

11
00:00:51,480 --> 00:00:53,400
well the

12
00:00:54,950 --> 00:00:58,040
i might have for example

13
00:00:58,090 --> 00:01:00,110
i have twenty eight

14
00:01:01,950 --> 00:01:05,400
why i minus one y i

15
00:01:05,410 --> 00:01:06,890
x y

16
00:01:08,410 --> 00:01:09,750
it would be

17
00:01:11,330 --> 00:01:14,000
why i minus one

18
00:01:14,020 --> 00:01:15,680
why are

19
00:01:18,720 --> 00:01:23,050
because zero zero

20
00:01:23,100 --> 00:01:26,910
and text i minus one x y

21
00:01:28,720 --> 00:01:32,230
t h

22
00:01:35,920 --> 00:01:39,450
if my problem my task was hyphenation

23
00:01:39,460 --> 00:01:43,580
and i had this is the low level feature function

24
00:01:43,680 --> 00:01:48,850
so to two consecutive tags is zero zero

25
00:01:48,860 --> 00:01:50,850
number zero means no hyphen

26
00:01:50,920 --> 00:01:55,450
and the two corresponding consecutive letters of t h

27
00:01:56,370 --> 00:01:57,410
so only

28
00:01:57,430 --> 00:01:58,650
this is

29
00:01:58,700 --> 00:02:02,000
an instance of this type of feature functions

30
00:02:02,030 --> 00:02:05,060
and and it satisfies the money

31
00:02:05,140 --> 00:02:09,340
destruction that i'm only referring to two consecutive attacks

32
00:02:10,730 --> 00:02:13,600
what's the summer

33
00:02:13,610 --> 00:02:15,790
by supposing

34
00:02:15,800 --> 00:02:18,200
that this was my low level feature function

35
00:02:18,240 --> 00:02:24,360
and this is my corresponding high-level feature function and this feature function had a on

36
00:02:24,380 --> 00:02:30,880
positive weight what would that be saying

37
00:02:34,270 --> 00:02:38,320
that when you have t h you don't usually

38
00:02:38,360 --> 00:02:42,570
you don't usually hyphenate

39
00:02:44,480 --> 00:02:46,100
yeah i guess you

40
00:02:46,120 --> 00:02:52,730
it just choose the convention does does the zero mean hyphen not allowed before this

41
00:02:52,730 --> 00:02:55,720
letter the zero mean high not allowed after this letter

42
00:02:55,820 --> 00:02:57,680
but if if

43
00:02:57,700 --> 00:03:02,280
by convention is that the attacks refers to the hive and after the latter

44
00:03:04,340 --> 00:03:07,670
zero zero means no hyphen after the t

45
00:03:07,690 --> 00:03:09,800
no hyphen after the h

46
00:03:12,850 --> 00:03:15,580
and you know most

47
00:03:15,590 --> 00:03:19,920
most english words that contain h they don't have a hyphen after the after the

48
00:03:21,330 --> 00:03:27,500
this is the feature function that you expect your training will give you a

49
00:03:27,560 --> 00:03:28,950
the positive weight

50
00:03:28,960 --> 00:03:30,760
for the

51
00:03:30,770 --> 00:03:33,020
the corresponding feature function began

52
00:03:33,990 --> 00:03:36,060
you see when you do this

53
00:03:36,070 --> 00:03:40,350
this is an indicator function is low level feature function is zero one function

54
00:03:40,350 --> 00:03:42,190
but when i summarise

55
00:03:42,230 --> 00:03:43,980
over the

56
00:03:43,990 --> 00:03:45,370
the whole input

57
00:03:45,380 --> 00:03:48,080
then it becomes a real valued

58
00:03:59,600 --> 00:04:03,580
you can

59
00:04:04,100 --> 00:04:06,890
the only restriction is that you can

60
00:04:06,920 --> 00:04:09,970
that you can't look at more than two labels at the time

61
00:04:09,980 --> 00:04:11,450
but i could

62
00:04:11,460 --> 00:04:13,380
for example say

63
00:04:14,500 --> 00:04:17,720
x i minus two

64
00:04:19,850 --> 00:04:22,600
x i minus one

65
00:04:23,570 --> 00:04:27,730
because t h and

66
00:04:36,380 --> 00:04:37,800
you can actually look

67
00:04:39,550 --> 00:04:42,970
because you can look at all of acts

68
00:04:42,970 --> 00:04:46,750
and you can look at two two wise

69
00:04:47,720 --> 00:04:50,460
you could

70
00:04:50,500 --> 00:04:53,310
you could look at my

71
00:04:54,020 --> 00:04:59,470
so you can get anywhere in acts

72
00:04:59,480 --> 00:05:02,000
well you can't do is look at more than two

73
00:05:02,010 --> 00:05:05,650
my tags at the time

74
00:05:05,700 --> 00:05:10,930
so if we work if you think back to the example of multi label

75
00:05:10,940 --> 00:05:13,260
using a log linear model for multi label

76
00:05:13,280 --> 00:05:18,580
the corresponding limitation would be that you can on you can look at anything to

77
00:05:18,580 --> 00:05:20,200
do with the document

78
00:05:20,210 --> 00:05:23,370
but you can't look at correlations between

79
00:05:23,380 --> 00:05:25,920
more than two labels

80
00:05:25,960 --> 00:05:26,780
and here

81
00:05:26,800 --> 00:05:30,120
we can't work

82
00:05:30,170 --> 00:05:34,390
look at work in his an example of something that would not be allowed

83
00:05:35,320 --> 00:05:38,050
after twenty nine

84
00:05:38,060 --> 00:05:40,640
why by exp

85
00:05:41,960 --> 00:05:44,260
why i minus two

86
00:05:44,270 --> 00:05:47,750
why i minus one y y equals

87
00:05:47,800 --> 00:05:50,730
zero one zero

88
00:05:50,760 --> 00:05:54,210
and x i minus two

89
00:06:01,060 --> 00:06:04,700
fits into the definition of the feature function in general

90
00:06:04,800 --> 00:06:07,370
and it's saying just looking at

91
00:06:07,430 --> 00:06:11,610
how many zero one zero sequences are there

92
00:06:13,210 --> 00:06:16,740
but but it's referring to more than two y

93
00:06:16,750 --> 00:06:20,030
two wives and so it's not fitting into this

94
00:06:21,470 --> 00:06:25,100
so but he is he has of his a low-level feature function that would be

95
00:06:25,100 --> 00:06:26,750
very useful

96
00:06:27,670 --> 00:06:30,700
why i minus one

97
00:06:30,700 --> 00:06:36,930
ten thousand megaparsec down to small scales of about a megaparsec today

98
00:06:36,990 --> 00:06:40,950
and everything's consistent with this power spectrum

99
00:06:41,220 --> 00:06:47,330
and the shape of this power spectrum depends upon Omega matter

100
00:06:47,370 --> 00:06:51,410
and using omega matter of point three

101
00:06:51,450 --> 00:06:54,810
is the result that's prefered

102
00:06:54,910 --> 00:07:00,310
now I didn't pick this up in a later lecture just let me show you

103
00:07:01,140 --> 00:07:03,740
things that I won't have time to talk about today

104
00:07:04,220 --> 00:07:10,390
one is the determination of omega baryons of big bang nucleosynthesis and from

105
00:07:10,390 --> 00:07:16,410
W map it's a omega baryon H squared is about point zero two

106
00:07:16,450 --> 00:07:19,910
H squared is one half so Omega baryon

107
00:07:19,950 --> 00:07:22,560
total is about four per cent

108
00:07:22,960 --> 00:07:28,330
I would talk in the dark matter lecture about neutrinos the contribution of neutrinos to

109
00:07:28,330 --> 00:07:30,910
the total energy density

110
00:07:30,930 --> 00:07:35,310
and the age of the universe I'll just mention here

111
00:07:35,350 --> 00:07:40,620
the age of the universe can be determined by white dwarf cooling and nucleo cosmo

112
00:07:40,620 --> 00:07:44,080
chronology and globular cluster evolution

113
00:07:44,080 --> 00:07:50,850
there is a lot of uncertainty but it's consistent with about thirteen billion years and

114
00:07:51,350 --> 00:07:52,930
if H naught is seventy

115
00:07:52,950 --> 00:07:57,890
predicted value of the age of the universe depends upon omega lambda as we

116
00:07:57,890 --> 00:08:02,280
saw from an earlier graph for a flat universe

117
00:08:02,950 --> 00:08:09,870
the age of a flat universe with H naught of seventy is nine point three gigayears

118
00:08:09,890 --> 00:08:12,280
which is smaller than the observed

119
00:08:12,490 --> 00:08:14,140
age of white dwarfs

120
00:08:14,140 --> 00:08:20,200
I think in consistent cosmology you want white dwarfs to be younger than the universe

121
00:08:20,680 --> 00:08:27,510
so this suggests that this model is not correct if you increase the cosmological constant you get an

122
00:08:27,850 --> 00:08:36,970
older universe the age of the universe is also evidence for a cosmological constant or dark energy

123
00:08:36,990 --> 00:08:45,160
so today we had an introduction of a little bit of theory discussing these cosmological parameters

124
00:08:45,160 --> 00:08:47,060
and the power spectrum

125
00:08:47,100 --> 00:08:51,160
and all of these fit together the precision measurements here

126
00:08:51,200 --> 00:08:57,950
the theoretical constructions of power spectre with the consistency of the Standard Model

127
00:08:57,970 --> 00:09:05,330
of lambda CDM and again in this standard model of lambda CDM most of

128
00:09:05,330 --> 00:09:11,560
the universe is cold dark matter and dark energy which will be the subject of the

129
00:09:11,700 --> 00:09:14,100
later lectures

130
00:09:14,100 --> 00:09:18,600
I have this talk of course is available on the Web I have some suggested

131
00:09:20,310 --> 00:09:26,950
that will help you in this introduction and tomorrow I will talk about inflation and

132
00:09:26,950 --> 00:09:29,100
on third Wednesday and Thursday

133
00:09:29,140 --> 00:09:35,530
about dark matter and dark energy thank you I'm happy to answer questions before lunch

134
00:09:42,910 --> 00:09:51,330
yes when did it really become clear that the expansion of the universe

135
00:09:51,470 --> 00:09:58,280
accelerating which was the decisive observation the question is when did it come become clear

136
00:09:58,280 --> 00:10:03,530
that the expansion of the universe is accelerating and what was the decisive observation

137
00:10:03,620 --> 00:10:10,560
now in the last lecture I will qualify little bit the statement that the universe is accelerating what's

138
00:10:10,560 --> 00:10:17,620
observed actually is that the Einstein de Sitter model does not fit the observation

139
00:10:17,660 --> 00:10:22,300
In other words that hot for instance high redshift supernovae are fainter than you would expect

140
00:10:22,310 --> 00:10:23,560
in that model

141
00:10:23,700 --> 00:10:25,950
I don't think

142
00:10:25,970 --> 00:10:27,180
there was any

143
00:10:28,160 --> 00:10:32,160
in hindsight the original evidence in nineteen ninety-eight

144
00:10:32,200 --> 00:10:38,850
was pretty good but it wasn't compelling to me in nineteen ninety-eight I think it is

145
00:10:40,390 --> 00:10:45,630
Over the years in the past ten years not by any one eureka observation

146
00:10:45,630 --> 00:10:52,300
saying that this really proves it but a series of many observations that give the consistency

147
00:10:52,350 --> 00:10:54,060
to this picture

148
00:10:54,060 --> 00:10:57,970
the lambda CDM model fits in

149
00:10:57,990 --> 00:11:03,510
again it's not just supernovae it's age of the universe structure formation and I'll talk

150
00:11:03,510 --> 00:11:09,700
later about baryon acoustic oscillations weak lensing all of these different methods

151
00:11:09,700 --> 00:11:16,430
With different uncertainties arrive at the same result so it's not any one observation

152
00:11:16,810 --> 00:11:23,180
it's a series of observati different types of observation that's all consistent with this cosmological

153
00:11:23,180 --> 00:11:25,990
standard model so

154
00:11:27,870 --> 00:11:33,510
for the first six thousand years of cosmology theory was held of ahead of observation that they

155
00:11:33,510 --> 00:11:36,560
had many more theories than we could exp

156
00:11:36,560 --> 00:11:41,600
test by observation and for the first time in the last six thousand years perhaps

157
00:11:41,600 --> 00:12:00,300
OK can you hear me

158
00:12:00,340 --> 00:12:02,840
it is better to check all this

159
00:12:02,940 --> 00:12:04,760
poster art equipment it's

160
00:12:04,770 --> 00:12:09,270
so much so many cables so many

161
00:12:09,300 --> 00:12:11,230
o devices OK

162
00:12:11,300 --> 00:12:17,060
now before going on with the genetic algorithms and genetic programming

163
00:12:18,610 --> 00:12:21,440
a bit of illustration of this

164
00:12:22,760 --> 00:12:25,940
now in

165
00:12:25,980 --> 00:12:28,660
discussing search and optimisation

166
00:12:28,770 --> 00:12:31,580
it's often

167
00:12:31,660 --> 00:12:42,800
described as searching to certain areas and usually use examples of test functions defined certain

168
00:12:42,800 --> 00:12:48,620
surfaces and here is one example of searching for a minimum of these

169
00:12:50,730 --> 00:12:52,580
so what

170
00:12:52,610 --> 00:12:56,610
i hope you can see this is

171
00:12:56,620 --> 00:12:59,720
certain shape and at certain points

172
00:12:59,750 --> 00:13:07,440
this is the starting population it's not important now what technique use its

173
00:13:07,480 --> 00:13:09,010
as we can see

174
00:13:09,030 --> 00:13:10,360
they are

175
00:13:10,390 --> 00:13:14,110
slowly converging to a certain point

176
00:13:14,280 --> 00:13:16,250
the idea is to

177
00:13:16,250 --> 00:13:18,670
read the value of zero here

178
00:13:21,340 --> 00:13:24,310
this is actually the lowest point in this

179
00:13:26,860 --> 00:13:28,390
and as you can see

180
00:13:28,420 --> 00:13:36,490
the points for the this population is exploring the space and converging to this value

181
00:13:36,510 --> 00:13:41,300
this is actually performed by genetic algorithms that use

182
00:13:41,300 --> 00:13:44,300
explain now this is just to show

183
00:13:44,380 --> 00:13:51,300
one property of stochastic algorithms related to the question we had before

184
00:13:51,400 --> 00:13:55,610
how do we set certain values of the algorithm

185
00:13:55,630 --> 00:14:01,790
one specific value set to this algorithm is the number of

186
00:14:01,800 --> 00:14:05,800
o points or the number of individuals that perform search

187
00:14:05,820 --> 00:14:09,770
it was set to nineteen

188
00:14:09,770 --> 00:14:13,540
in this case so if i

189
00:14:17,300 --> 00:14:18,680
let's say two

190
00:14:18,760 --> 00:14:21,150
fifty or forty nine

191
00:14:21,200 --> 00:14:24,520
OK fifty one it's not important we help

192
00:14:24,550 --> 00:14:26,330
and another and

193
00:14:26,360 --> 00:14:28,480
initial configuration now

194
00:14:28,480 --> 00:14:30,550
if i ran it again

195
00:14:30,570 --> 00:14:33,890
what do we see

196
00:14:33,960 --> 00:14:35,380
it was

197
00:14:35,390 --> 00:14:39,460
they they approach the optimal point foster they didn't didn't they

198
00:14:39,480 --> 00:14:40,480
so it's

199
00:14:40,510 --> 00:14:42,360
you see this is one

200
00:14:42,800 --> 00:14:45,010
question how to set

201
00:14:45,020 --> 00:14:46,830
the population size

202
00:14:46,920 --> 00:14:49,650
we saw that it was less

203
00:14:49,670 --> 00:14:54,980
that's a iterations but it's again higher number of individuals so

204
00:14:55,420 --> 00:15:00,200
this is rather quick here because this is a test function that is

205
00:15:00,240 --> 00:15:02,210
well specified analytically

206
00:15:02,700 --> 00:15:06,520
the evaluation of the single solution is done very quickly

207
00:15:06,540 --> 00:15:10,150
now you can imagine more difficult problem

208
00:15:10,180 --> 00:15:13,550
if you were optimizing something

209
00:15:13,580 --> 00:15:22,330
and it requires the computational processes that is not trivial it may take

210
00:15:22,330 --> 00:15:23,610
i mean it's ours

211
00:15:24,730 --> 00:15:32,180
evaluating solution would take that much time and it is then very important how to

212
00:15:32,200 --> 00:15:33,800
for the two

213
00:15:33,820 --> 00:15:39,540
converges quickly as possible will come to one such a practical example later

214
00:15:39,550 --> 00:15:41,810
and the other

215
00:15:41,850 --> 00:15:45,750
o thing to be illustrated here is the following

216
00:15:45,770 --> 00:15:48,130
this landscape is rather

217
00:15:50,010 --> 00:15:54,210
as you can see we can turn it around a bit now if we go

218
00:15:54,210 --> 00:15:56,640
to the more complicated functions

219
00:15:56,690 --> 00:15:58,290
like this one

220
00:15:58,340 --> 00:15:59,220
this is

221
00:15:59,320 --> 00:16:05,230
a good example of what we called multimodality at the beginning of this lecture that

222
00:16:05,230 --> 00:16:11,450
is a lot of local optima so this is really specially tailored function

223
00:16:11,460 --> 00:16:12,930
with many

224
00:16:12,940 --> 00:16:18,930
well misleading areas and if we

225
00:16:18,950 --> 00:16:20,640
position it like here

226
00:16:20,640 --> 00:16:23,150
we can see that there is a really

227
00:16:24,150 --> 00:16:29,370
the global minimum is at this point again the value zero

228
00:16:29,390 --> 00:16:32,090
so if we

229
00:16:32,140 --> 00:16:38,530
formal transition in this case i would start with a smaller population again a sixteen

230
00:16:38,530 --> 00:16:41,450
individuals or maybe

231
00:16:41,510 --> 00:16:44,100
twenty twenty one

232
00:16:44,140 --> 00:16:48,190
OK they go into the twenty so if we turn this around

233
00:16:48,240 --> 00:16:50,310
we can see that there are playing

234
00:16:50,320 --> 00:16:55,270
around that global optimum but it takes some time to reach it

235
00:16:55,270 --> 00:16:57,900
OK something is happening here

236
00:16:57,970 --> 00:17:00,580
and this is mentioned again reach

237
00:17:02,290 --> 00:17:04,940
but these goes rather slowly

238
00:17:04,950 --> 00:17:08,010
if i

239
00:17:08,080 --> 00:17:11,540
increase the population size

240
00:17:11,560 --> 00:17:15,070
let's say a

241
00:17:17,270 --> 00:17:19,840
sixty nine in this case

242
00:17:19,890 --> 00:17:21,640
we start

243
00:17:23,270 --> 00:17:25,500
that whole cluster and

244
00:17:25,510 --> 00:17:27,750
you can see that these very

245
00:17:27,760 --> 00:17:30,640
global minimum with a value of zero

246
00:17:30,710 --> 00:17:33,320
is approached foster again

247
00:17:36,410 --> 00:17:37,830
OK let's stop it

248
00:17:47,600 --> 00:17:49,490
the next family of

249
00:17:49,510 --> 00:17:54,710
algorithms this is genetic algorithms genetic algorithms are

250
00:17:54,720 --> 00:17:59,310
another representative of evolutionary algorithms may be the most popular

251
00:17:59,320 --> 00:18:06,560
one they were proposed or developed by john holland from the university of michigan in

252
00:18:06,560 --> 00:18:08,930
nineteen seventies

253
00:18:08,940 --> 00:18:11,240
and as

254
00:18:11,250 --> 00:18:15,330
we are a bit familiar evolution strategy we can

255
00:18:15,340 --> 00:18:19,640
described genetic algorithms

256
00:18:19,660 --> 00:18:26,010
in the way they differ from evolution strategies so the most remarkable differences that they

257
00:18:26,010 --> 00:18:32,740
usually use a stream based representation of solutions so it's not

258
00:18:32,750 --> 00:18:40,000
not always but the the initial approach was to use thing based representation usually binary

259
00:18:42,280 --> 00:18:52,150
these encoding or this representation is again motivated biologically this is done after the war

260
00:18:52,150 --> 00:18:54,220
meant to resemble the discrete

261
00:18:54,260 --> 00:18:58,160
nucleotide coding that we know from genetics

262
00:18:58,830 --> 00:19:00,440
so in this case

263
00:19:00,690 --> 00:19:04,210
again what other operators mutation is

264
00:19:04,240 --> 00:19:07,060
flipping bits with certain probability

265
00:19:07,070 --> 00:19:13,880
and the recombination is performed by an operator called cross-over

266
00:19:16,810 --> 00:19:22,020
you can imagine that if a string let's binary string enclose your solution it may

267
00:19:22,020 --> 00:19:29,860
the cosmoillogical constant so it's illogical for two reasons one is the magnitude of

268
00:19:29,860 --> 00:19:38,420
the cosmoillogical constant and you can think about contributions to the vacuum energy and contributions

269
00:19:38,420 --> 00:19:45,660
to the vacuum energy that you might imagine includes the zero point  energy of quantum

270
00:19:45,660 --> 00:19:52,060
fields all fields are harmonic oscillators with the zero point  energy so in field theory

271
00:19:52,060 --> 00:19:57,910
you can calculate the energy density of the vacuum you sum over all particles and

272
00:19:57,910 --> 00:20:03,700
it's plus or minus  depending upon whether it is a boson or a fermion and you just

273
00:20:03,700 --> 00:20:11,080
integrate over over a phase space of the integrate the energy over phase space now

274
00:20:11,080 --> 00:20:14,340
what you find of course is that if you don't have a cut-off the

275
00:20:14,340 --> 00:20:20,660
answer is infinite but relax it's field theory as we know from graduate school if

276
00:20:20,660 --> 00:20:25,160
you do not get infinity in the field theory calculation you haven't done the problem

277
00:20:25,160 --> 00:20:32,280
right so you introduce a cut-off and you introduce some cut-off here and you

278
00:20:32,280 --> 00:20:37,940
say the momentums cut-off  at the in the ultraviolet  and what cut-off might you put

279
00:20:37,940 --> 00:20:42,540
you might put the plont mass saying well we don't understand field theory in the presence

280
00:20:42,550 --> 00:20:47,610
of quantum gravity and if you do this you get ten to the hundred and twelve electron volts

281
00:20:47,610 --> 00:20:52,440
to the fourth the answer that you wanna get is ten to the minus

282
00:20:52,440 --> 00:20:58,050
sixteen electron volts to the fourth so you're off  this is the worst pre

283
00:20:58,060 --> 00:21:05,880
worst  calculation in history of being wrong so you might say aha you

284
00:21:05,880 --> 00:21:13,860
might invent a symmetry some crazy symmetry that would cancel between fermions and bosons

285
00:21:13,860 --> 00:21:21,520
and this crazy symmetry of course is supersymmetry but supersymmetry is not exact supersymmetry must be

286
00:21:21,920 --> 00:21:27,300
blo broken  so you might put in the supersymmetry breaking scale in here you have improved

287
00:21:27,300 --> 00:21:34,700
the calculation by sixty something orders of magnitude but you still have another  sixty orders

288
00:21:34,700 --> 00:21:39,800
of magnitude to go so we get you  halfway there in the logarithmic  sense

289
00:21:39,800 --> 00:21:45,860
but that's not the complete answer either so that's one of the reasons it's

290
00:21:45,860 --> 00:21:53,660
the cosmoillogical constant you can imagine contributions from zero point energy but they're just enormous

291
00:21:53,660 --> 00:22:00,640
you can  also imagine another contribution from spontaneous symmetry breaking energy of the vacuum we

292
00:22:00,640 --> 00:22:06,520
know in QCD in the electroweak theory the vacuum is a complicated object and there should

293
00:22:06,520 --> 00:22:13,170
be contributions to the vacuum energy from gut susybr from gut symmetry breaking

294
00:22:13,280 --> 00:22:19,440
ten to the hundred electron volts to the fourth susy  symmetry breaking electroweak symmetry breaking chiral

295
00:22:19,470 --> 00:22:26,420
symmetry breaking all of these are just enormous compared to the value that we

296
00:22:26,420 --> 00:22:35,780
need there's also  something that's rather odd that's the illogical timing this is a graph

297
00:22:35,780 --> 00:22:45,040
of various contributions to omega from matter and radiation and the cosmological constant so if

298
00:22:45,050 --> 00:22:50,740
we were astronomers in the far distant past we would not be able to deduce

299
00:22:50,740 --> 00:22:56,940
the existence of a cosmological constant because the matter in radiation energy density grows if

300
00:22:56,940 --> 00:23:01,690
you go back to earlier time and the vacuum energy does not so it would have

301
00:23:01,790 --> 00:23:10,500
been very dominant and in the far distant future lambda will dominate and  matter in radiation

302
00:23:10,500 --> 00:23:17,740
will be in will be insignificant isn't it a convenient time to be an astronomer

303
00:23:17,740 --> 00:23:22,680
it's the best of times because we're right now there where we can determine both

304
00:23:22,690 --> 00:23:29,120
of those and when I go to Washington I tell the politicians that we have

305
00:23:29,130 --> 00:23:35,460
to do astronomy now because in the future the these things we observe are expanding away

306
00:23:35,460 --> 00:23:39,300
from us we're not going to see them in the far distant future it's compelling

307
00:23:39,300 --> 00:23:50,260
to do it now that doesn't work  now so the evidence for dark energy

308
00:23:50,260 --> 00:23:59,660
is more than just the Hubble diagram  for every astronomical measurement there are uncertainties

309
00:23:59,660 --> 00:24:05,960
they're  observations they're not experiments and I think there's this sort of a difference between an

310
00:24:05,960 --> 00:24:11,200
observation and an experiment in an observation you just see what comes in an experiment you

311
00:24:11,200 --> 00:24:16,260
can go in and change triggers you can put your apparatus in a test beam you

312
00:24:16,260 --> 00:24:21,180
know you you have more control over what you measure than just observations so there

313
00:24:21,180 --> 00:24:27,740
are always systematic astronomical uncertainties that we're just not going to get around so it's

314
00:24:27,740 --> 00:24:33,060
important to have other information I won't talk about cosmic subtraction I did that in

315
00:24:33,060 --> 00:24:38,440
the first lecture that's indirect evidence today in a little while I'll talk about other

316
00:24:38,440 --> 00:24:45,620
emerging techniques baryon acoustic oscillations weak lensing galaxy clusters I won't talk about the

317
00:24:45,620 --> 00:24:50,100
information from the age of the universe but in the first lecture I showed that

318
00:24:50,100 --> 00:24:54,560
in order to fit the observed age of the universe it fits with the cosmological

319
00:24:54,560 --> 00:25:02,400
constant in this model and not without and also structure formation  comparing the simulations

320
00:25:02,400 --> 00:25:12,060
to the observations require a cosmological constant so let's step back a minute and ask how do

321
00:25:12,060 --> 00:25:20,180
we know dark energy exists I often hear my colleagues say we know that there

322
00:25:20,180 --> 00:25:25,620
is dark energy and whenever I hear a scientist use the word know I get sort of

323
00:25:25,620 --> 00:25:28,800
itchy I I don't think that we should ever do that I know we

324
00:25:28,800 --> 00:25:35,980
shouldn't so he here's the argument about how we know there is dark energy

325
00:25:35,980 --> 00:25:42,420
we assume a model cosmology the Friedmann Lemaitre Robertson Walker model leading to the Friedmann

326
00:25:42,420 --> 00:25:48,840
equation we assume an energy and pressure content of the universe and then we input or

327
00:25:48,840 --> 00:25:58,020
integrate over cosmological parameters we can calculate the observables luminosity distance angular diameter distance

328
00:25:58,020 --> 00:26:03,460
expansion rate as a function of redshift everything is fine so far then someone had the

329
00:26:03,460 --> 00:26:09,460
crazy idea to compare with observations when this was done it was discovered that this

330
00:26:09,480 --> 00:26:17,000
model cosmology fits with a cosmological constant but not without so it is important to

331
00:26:17,000 --> 00:26:24,780
keep in the back of your mind that all evidence for dark energy is indirect

332
00:26:24,780 --> 00:26:31,000
the only effect of dark energy is on the expansion rate of the universe and

333
00:26:31,000 --> 00:26:37,180
what is observed is that the expansion rate of the universe is not described by

334
00:26:37,180 --> 00:26:44,280
that calculated from the Einstein-de Sitter model again the spatially flat matter dominated model

335
00:26:44,280 --> 00:27:06,320
let me ask you something yes dark energy is behind the expansion rate behind the expansion of the universe itself I ask so the the  universe is the

336
00:27:06,320 --> 00:27:15,220
universe is expanding and the it's in the Friedmann Robertson Walker cosmology the expansion

337
00:27:15,220 --> 00:27:17,490
the one over our

338
00:27:17,530 --> 00:27:22,050
is an obvious thing is a consequence of the conservation of energy

339
00:27:22,130 --> 00:27:24,420
because the poynting vector

340
00:27:24,420 --> 00:27:26,130
is proportional

341
00:27:26,150 --> 00:27:30,010
to e square and because it proportional to e crosby

342
00:27:30,030 --> 00:27:35,050
for the poynting vector is proportional to its great

343
00:27:35,110 --> 00:27:38,470
so imagine now that you have a sphere with radius r

344
00:27:38,470 --> 00:27:41,880
you want to know all the energy that flows through that sphere we have to

345
00:27:41,880 --> 00:27:44,340
integrate over the entire sphere

346
00:27:44,420 --> 00:27:48,280
but if you double the radius the surface area of that sphere goes up by

347
00:27:48,280 --> 00:27:50,950
a factor of four

348
00:27:50,990 --> 00:27:54,920
so the only way to energy can be conserved at the same energy flows through

349
00:27:54,920 --> 00:27:58,340
this small small sphere then flows with large sphere is

350
00:27:58,740 --> 00:28:01,170
that the electric field dark

351
00:28:01,220 --> 00:28:02,610
by a factor of two

352
00:28:02,610 --> 00:28:07,320
so that the poynting vector goes down by a factor for the surface area increases

353
00:28:07,320 --> 00:28:08,940
by a factor of four

354
00:28:09,070 --> 00:28:12,320
the poynting vector goes down by a factor of four because e

355
00:28:12,360 --> 00:28:13,260
goes down

356
00:28:13,340 --> 00:28:14,800
by a factor of two

357
00:28:14,920 --> 00:28:17,260
we have here an eighty megahertz

358
00:28:17,280 --> 00:28:19,420
transmitter we've seen that before

359
00:28:19,420 --> 00:28:22,400
wavelength three point seven five meters

360
00:28:22,420 --> 00:28:26,200
and i demonstrated before show you that the radiation

361
00:28:26,220 --> 00:28:29,010
is linearly polarized

362
00:28:29,030 --> 00:28:32,800
and i demonstrated by having this receiving antenna

363
00:28:32,840 --> 00:28:35,970
and by rotating it like this when the lights went off and wrote it like

364
00:28:35,970 --> 00:28:38,280
this when the light goes on today

365
00:28:38,320 --> 00:28:40,090
that's not my objective

366
00:28:40,110 --> 00:28:45,490
today i'm interested in the sign square stayed room

367
00:28:45,530 --> 00:28:48,720
for which i need a little bit of assistance from someone

368
00:28:48,760 --> 00:28:52,950
so i want someone to hold this year

369
00:28:53,050 --> 00:28:56,050
and will see that the light will be on and then i will rotate to

370
00:28:56,880 --> 00:28:59,170
so that the angle of theta

371
00:29:00,320 --> 00:29:04,650
if i have a year i have maximum because the city did the charges

372
00:29:04,720 --> 00:29:07,280
i say accelerated in this direction

373
00:29:07,450 --> 00:29:11,840
so this angle estate on ninety degrees that's optimal

374
00:29:11,900 --> 00:29:13,340
the state is zero

375
00:29:13,360 --> 00:29:15,380
ninety degrees that optimum

376
00:29:15,530 --> 00:29:19,880
but the moment you rotated ninety degrees or that you wrote this ninety degree

377
00:29:19,880 --> 00:29:20,670
then it

378
00:29:20,670 --> 00:29:22,050
zero and that's

379
00:29:22,110 --> 00:29:23,990
exactly what i want to demonstrate

380
00:29:24,050 --> 00:29:26,130
so i need assistance can you help me

381
00:29:26,150 --> 00:29:29,990
material here if you don't get electrocuted

382
00:29:30,030 --> 00:29:31,820
OK so you have the choice

383
00:29:32,320 --> 00:29:41,090
all of the above your head

384
00:29:41,110 --> 00:29:43,650
OK now you see the light is on

385
00:29:43,650 --> 00:29:47,110
and so now

386
00:29:47,900 --> 00:29:52,380
this is the direction of acceleration and i'm going to want the direction of acceleration

387
00:29:52,380 --> 00:29:53,880
towards you

388
00:29:53,970 --> 00:29:58,050
if the exoneration is like this there's no radiation going in this direction and that

389
00:29:58,050 --> 00:29:59,820
light will go on the

390
00:29:59,940 --> 00:30:03,280
very slowly and carefully already deming

391
00:30:03,300 --> 00:30:04,490
so any dimming

392
00:30:04,510 --> 00:30:14,800
now we now get back what goes on that goes on so that

393
00:30:15,010 --> 00:30:19,090
become a little closer than the light is a little brighter more

394
00:30:19,130 --> 00:30:21,990
although the little further down a little down

395
00:30:22,010 --> 00:30:24,800
that's one of the once more

396
00:30:24,860 --> 00:30:29,050
i think the angle theta going down and out and

397
00:30:30,030 --> 00:30:33,450
good luck you survive this one some students don't

398
00:30:36,590 --> 00:30:39,010
so this was very qualitatively

399
00:30:39,050 --> 00:30:41,130
to show you the fact

400
00:30:41,150 --> 00:30:42,440
of the sign

401
00:30:42,450 --> 00:30:45,650
it's quesada relationship

402
00:30:47,780 --> 00:30:51,320
in order to calculate the total power

403
00:30:51,360 --> 00:30:53,340
that is

404
00:30:53,340 --> 00:30:55,340
produced by the

405
00:30:55,340 --> 00:30:59,700
total power in the electromagnetic wave that is produced by the

406
00:30:59,780 --> 00:31:01,630
oscillating charge

407
00:31:01,630 --> 00:31:06,880
you will have to integrate this poynting vector over one complete sphere

408
00:31:06,940 --> 00:31:10,820
which is not the total trivial integral because the the poynting vector changes was signed

409
00:31:10,820 --> 00:31:13,220
square theta

410
00:31:13,240 --> 00:31:15,490
so i'll leave you with that exercise

411
00:31:15,510 --> 00:31:19,260
but i will give you the results which is not so surprising at least it

412
00:31:19,260 --> 00:31:21,360
is not surprising that

413
00:31:21,380 --> 00:31:23,650
the quantities that you will see

414
00:31:23,670 --> 00:31:26,920
and most of you see this part of the record

415
00:31:28,610 --> 00:31:30,700
so that would be better there

416
00:31:30,700 --> 00:31:32,860
well i can raise some

417
00:31:33,060 --> 00:31:37,050
the re some here

418
00:31:37,110 --> 00:31:38,380
so this is now

419
00:31:38,420 --> 00:31:44,700
integration of the poynting vector over complete sphere i put around the charge

420
00:31:44,780 --> 00:31:46,700
and the result then is that

421
00:31:46,700 --> 00:31:50,990
the power which is no longer well prescribe metre per second but is simply now

422
00:31:50,990 --> 00:31:52,090
in what

423
00:31:52,110 --> 00:31:52,950
how many

424
00:31:52,950 --> 00:31:56,570
energy flows per second through sphere

425
00:31:56,610 --> 00:31:59,010
and that now becomes q squared

426
00:31:59,050 --> 00:32:01,240
it's no surprise because

427
00:32:01,240 --> 00:32:04,510
q is in a in the vector in q waiting to be vector so you

428
00:32:04,510 --> 00:32:06,490
get a q square

429
00:32:06,510 --> 00:32:10,380
you got a script you know surprise because the age is in the b and

430
00:32:10,470 --> 00:32:11,700
a is in the

431
00:32:11,720 --> 00:32:14,630
and then you get this divided by six by

432
00:32:14,700 --> 00:32:16,400
actually non-zero

433
00:32:16,420 --> 00:32:18,300
and i think it's safe to power

434
00:32:22,200 --> 00:32:23,880
but you see my hesitation

435
00:32:23,900 --> 00:32:27,440
finally arrived at c square

436
00:32:28,130 --> 00:32:32,990
it really is he to to power three sort of downstairs is not squared with

437
00:32:32,990 --> 00:32:34,900
c to the power three

438
00:32:34,990 --> 00:32:35,990
sorry for that

439
00:32:36,010 --> 00:32:42,050
so this is the famous larmor result

440
00:32:42,110 --> 00:32:43,320
it takes energy

441
00:32:43,340 --> 00:32:47,240
to accelerate single charts in vacuum

442
00:32:47,260 --> 00:32:52,030
and i'm not talking here about kinetic energy in terms of one half MV squared

443
00:32:52,050 --> 00:32:54,820
but i'm talking here about the creation

444
00:32:54,820 --> 00:32:58,470
of electromagnetic fields due to the motion

445
00:32:58,550 --> 00:32:59,680
of the

446
00:33:06,130 --> 00:33:10,070
now comes the question how do we accelerate charges

447
00:33:10,070 --> 00:33:12,920
and i thought about that for a few days how i was going to tell

448
00:33:12,920 --> 00:33:14,240
you that

449
00:33:14,380 --> 00:33:19,010
and that i have to give you a little bit embarrassing

450
00:33:19,050 --> 00:33:20,630
and and that is

451
00:33:20,670 --> 00:33:26,760
we accelerate charges by exposing them to electromagnetic radiation

452
00:33:26,840 --> 00:33:29,920
and then you say well is in this catch twenty two

453
00:33:30,010 --> 00:33:35,280
because you have to accelerate to create electromagnetic radiation how do you accelerating well you

454
00:33:35,280 --> 00:33:39,170
have to create after exposure to electromagnetic radiation

455
00:33:39,170 --> 00:33:41,700
for whatever that's worth

456
00:33:41,740 --> 00:33:44,110
cause there is electromagnetic radiation

457
00:33:44,130 --> 00:33:46,740
that comes out of all kinds of sources

458
00:33:46,800 --> 00:33:47,840
and so

459
00:33:47,860 --> 00:33:49,990
i'll show you now

460
00:33:50,010 --> 00:33:52,720
that if we take

461
00:33:52,820 --> 00:33:57,670
the electromagnetic wave with a convenient polarized travelling wave

462
00:33:57,670 --> 00:34:00,400
it would have been surprising up to

463
00:34:02,250 --> 00:34:09,910
my name is story great though i'm working for microsoft research in cambridge

464
00:34:09,930 --> 00:34:12,370
and a couple of years ago

465
00:34:13,610 --> 00:34:21,830
we started in the group there which involves the combination of machine learning and games

466
00:34:21,880 --> 00:34:28,220
originally the group was designed to deal primarily with computer games

467
00:34:28,230 --> 00:34:33,830
you know microsoft is engaged in the in the computer games market through flight simulator

468
00:34:33,830 --> 00:34:40,040
in PC games as well as x-box games that when i care came to the

469
00:34:40,040 --> 00:34:44,060
group we also started this other interests which is in

470
00:34:44,110 --> 00:34:47,640
general games and in particular in board games

471
00:34:47,650 --> 00:34:50,940
so that's basically we're coming from

472
00:34:50,950 --> 00:34:55,670
and so i'll talk about various at aspects of machine learning and games

473
00:34:55,720 --> 00:34:59,800
in fact you will not find very much material in the little booklet that you

474
00:34:59,800 --> 00:35:00,840
have because

475
00:35:00,890 --> 00:35:04,840
i just recently prepared a lot of stuff

476
00:35:07,060 --> 00:35:11,460
there's a very close relation between games and learning which i would like to point

477
00:35:11,460 --> 00:35:13,010
out to to start with

478
00:35:13,030 --> 00:35:18,190
of course people play a lot of games in order to learn stuff in particular

479
00:35:18,190 --> 00:35:23,510
children and you can also see it in the animal kingdom that the first basic

480
00:35:23,510 --> 00:35:27,790
skills learned by playing if you think about it

481
00:35:27,800 --> 00:35:32,570
most humans play for the first ten years of their lives if they are fortunate

482
00:35:32,570 --> 00:35:34,150
they play for another ten

483
00:35:34,160 --> 00:35:35,760
if they started they place

484
00:35:35,780 --> 00:35:37,360
possibly for another ten

485
00:35:37,520 --> 00:35:43,420
and so we will never stop playing maybe not such a bad thing

486
00:35:43,440 --> 00:35:48,920
so another aspect that some of you may have experiences that in order to master

487
00:35:48,920 --> 00:35:54,300
certain games that have developed over the centuries or in recent years you have to

488
00:35:54,300 --> 00:35:58,020
put in the lot of effort and you have to learn the game so there's

489
00:35:58,020 --> 00:35:59,780
another relation there

490
00:36:01,700 --> 00:36:07,940
another interesting aspect is of course that games are not just arbitrary sets of rules

491
00:36:07,970 --> 00:36:13,540
but what they usually constitute a little simulations of aspects of the game of the

492
00:36:13,540 --> 00:36:18,350
world so if you look at children's games you will always see you know if

493
00:36:18,350 --> 00:36:23,070
they try to catch each other that has hunting aspects to it if if they

494
00:36:23,070 --> 00:36:28,020
play simple games then usually there some kind of element of

495
00:36:28,720 --> 00:36:37,040
of spatial reasoning involved and there is in general this aspect of competition which often

496
00:36:37,040 --> 00:36:40,910
turns out to be quite important in life so

497
00:36:40,960 --> 00:36:46,230
the key idea here is that games are not arbitrary games are related to reality

498
00:36:46,260 --> 00:36:52,550
and that's makes the last point quite important we can study games and behavior in

499
00:36:52,550 --> 00:36:56,950
games and thereby learn about a lot about the real world but the nice thing

500
00:36:56,950 --> 00:37:00,830
is if we study these aspects in games then we can

501
00:37:00,890 --> 00:37:02,760
abstract them in no way

502
00:37:02,790 --> 00:37:08,790
away from the world we can ignore certain problems that we would encounter in real

503
00:37:08,790 --> 00:37:14,990
world learning and focus on the problems we've seen examples of that one thing for

504
00:37:14,990 --> 00:37:16,610
example is

505
00:37:16,700 --> 00:37:20,200
if you compare real world robotics

506
00:37:21,140 --> 00:37:27,480
the construction of robots or bots in games in real world robotics you have all

507
00:37:27,480 --> 00:37:31,950
the mess with the sensors and the signal processing and the noise while in games

508
00:37:31,950 --> 00:37:37,700
you can just focus on sensor readings that essentially come from your memory come from

509
00:37:37,700 --> 00:37:38,890
the simulation

510
00:37:38,930 --> 00:37:40,100
and thereby

511
00:37:40,110 --> 00:37:45,730
you have data available that you would never have available in this form in real

512
00:37:45,730 --> 00:37:48,420
world robotics that makes it easier

513
00:37:48,430 --> 00:37:51,570
to treat the problem in the simulation in the game

514
00:37:51,580 --> 00:37:55,050
but the hope is that you could still enough of the properties carry over to

515
00:37:55,050 --> 00:38:01,230
the real world and so maybe we first solve the problem of simulate simulating good

516
00:38:01,230 --> 00:38:04,610
behaviour in games than that may carry over to

517
00:38:04,640 --> 00:38:07,330
to real robotics for example

518
00:38:07,350 --> 00:38:12,730
so here's the structure for the course

519
00:38:12,740 --> 00:38:20,030
i start with a general introduction to machine learning in video games because that's one

520
00:38:20,030 --> 00:38:25,580
of the primary areas were working and i think that's a very interesting direction for

521
00:38:25,580 --> 00:38:30,710
future research because there's appears to be a lot of potential when i was preparing

522
00:38:30,710 --> 00:38:32,500
these lectures sitting

523
00:38:32,520 --> 00:38:37,760
more and more things were we're machine learning could usefully be applied to computer games

524
00:38:38,180 --> 00:38:42,540
and i think this is really sort of growing market that could be of interest

525
00:38:42,540 --> 00:38:44,190
for many of you

526
00:38:44,200 --> 00:38:53,020
in the subsequent three lectures i more into specific ideas and projects

527
00:38:53,100 --> 00:39:00,390
so on tuesday i'll be talking about bayesian ranking system that we developed another essentially

528
00:39:00,390 --> 00:39:06,460
trying to view the spirit of bayesian inference first using some simple examples

529
00:39:06,470 --> 00:39:09,330
and and then talk about

530
00:39:09,350 --> 00:39:14,180
the problem of ranking and matchmaking in games such as chess or in online computer

531
00:39:14,180 --> 00:39:22,140
games on wednesday i'll talk about the application of reinforcement learning to various games it

532
00:39:22,140 --> 00:39:27,900
turns out that games are you know way i mean maybe some people would wouldn't

533
00:39:27,900 --> 00:39:33,650
allow me to say but i know the only successful application of reinforcement learning i

534
00:39:33,650 --> 00:39:39,390
mean there been others but it's really been successful primarily in games and really only

535
00:39:39,390 --> 00:39:43,500
in very few games so we're talking about those and others

536
00:39:43,520 --> 00:39:49,080
and finally on thursday i would like to take the opportunity and

537
00:39:49,100 --> 00:39:56,150
let you give you a lesson in in the ancient chinese or

538
00:39:56,180 --> 00:39:58,720
later japanese game of go

539
00:39:58,750 --> 00:40:03,870
so we will kind split the session into two and during the first hour i

540
00:40:03,870 --> 00:40:08,200
would like to encourage you to to try out to play the game of go

541
00:40:08,240 --> 00:40:12,260
or if you already know it may be held few others to pick up the

542
00:40:12,260 --> 00:40:19,280
the addition of a second speaker is where a change on decision tree and instance

543
00:40:19,280 --> 00:40:21,330
based learning for label ranking

544
00:40:21,350 --> 00:40:23,610
OK i hello everybody

545
00:40:23,620 --> 00:40:27,560
and i'm here now talking about different kind of learning problem

546
00:40:27,580 --> 00:40:28,450
and then we

547
00:40:28,470 --> 00:40:32,100
i want to use is local learning approach to solve label ranking problem

548
00:40:32,150 --> 00:40:34,400
i will talk about how to use this century

549
00:40:34,420 --> 00:40:36,970
and extend this learning from a ranking

550
00:40:36,990 --> 00:40:41,740
OK and this is a joint work with my colleague is here and my advisor

551
00:40:41,740 --> 00:40:43,750
i can feel my

552
00:40:43,850 --> 00:40:48,640
OK let's get started so consider you have cost or new

553
00:40:48,670 --> 00:40:50,920
selling different types of cost

554
00:40:52,420 --> 00:40:56,400
you have different customers and the different customer we have different preferences different type of

555
00:40:59,090 --> 00:41:00,960
obviously that

556
00:41:00,990 --> 00:41:04,920
if you have a new customer you like to know that what is his preference

557
00:41:05,070 --> 00:41:07,240
this different types of cars

558
00:41:08,740 --> 00:41:11,870
so here the output is a ranking

559
00:41:12,520 --> 00:41:16,430
it's not like classification which we are only interested in the top

560
00:41:16,480 --> 00:41:19,590
but the interesting total ranking

561
00:41:21,810 --> 00:41:26,430
sometimes it's more convenient to present this problem

562
00:41:26,450 --> 00:41:29,350
in terms of computation

563
00:41:32,620 --> 00:41:34,290
this label ranking problem

564
00:41:34,310 --> 00:41:35,760
can be found in this way

565
00:41:35,780 --> 00:41:38,120
OK we have a set of training instances

566
00:41:38,130 --> 00:41:41,010
and a set of predefined finite

567
00:41:41,040 --> 00:41:42,980
the set of labels

568
00:41:42,990 --> 00:41:44,840
and for each training instance

569
00:41:45,620 --> 00:41:50,980
however set of pairwise preference that tells you which enables better than which later

570
00:41:51,760 --> 00:41:54,210
then the goal of this problem is

571
00:41:54,230 --> 00:41:56,280
we want to find a ranking function

572
00:41:56,290 --> 00:41:58,540
which is the mapping from this feature space

573
00:41:58,560 --> 00:42:01,570
to the right space that can maps each

574
00:42:01,590 --> 00:42:03,370
it turns to ranking

575
00:42:03,400 --> 00:42:05,310
of the labels

576
00:42:05,320 --> 00:42:06,340
and of course

577
00:42:06,350 --> 00:42:12,180
we like to generalize well in terms of pre-defined loss function on rankings

578
00:42:12,210 --> 00:42:19,650
OK with this talk we concentrate ourselves skeletal disorders

579
00:42:19,660 --> 00:42:23,150
and this is a rather interesting problem

580
00:42:23,160 --> 00:42:26,990
and there already work on this problem

581
00:42:27,030 --> 00:42:31,280
so here is a list of representative approaches

582
00:42:31,310 --> 00:42:34,460
and i want to go into details to of these metals

583
00:42:34,530 --> 00:42:36,210
i want to say is that

584
00:42:36,270 --> 00:42:40,390
all this might also works so the performance of comparable

585
00:42:41,830 --> 00:42:43,400
so far we all the three

586
00:42:43,650 --> 00:42:45,530
apologies reduces

587
00:42:45,550 --> 00:42:47,900
they were problem to classification

588
00:42:49,050 --> 00:42:49,740
this is

589
00:42:49,740 --> 00:42:51,810
quite efficient

590
00:42:52,050 --> 00:42:54,410
but may have some problems for example

591
00:42:54,430 --> 00:42:58,870
becomes always lost information due to his transformation

592
00:43:00,650 --> 00:43:04,410
most of the models most of these approaches

593
00:43:04,430 --> 00:43:07,030
has some holes from model assumptions

594
00:43:07,060 --> 00:43:08,930
so does come along with

595
00:43:08,960 --> 00:43:10,930
so let's by OK

596
00:43:10,970 --> 00:43:12,410
due this bias

597
00:43:12,580 --> 00:43:15,410
the lack of flexibility

598
00:43:15,430 --> 00:43:19,080
and last but not least that

599
00:43:19,090 --> 00:43:22,370
most of the parties of black box OK

600
00:43:23,490 --> 00:43:26,690
the what is black also sometimes have problems to in presence

601
00:43:26,750 --> 00:43:28,610
o say

602
00:43:28,620 --> 00:43:30,190
all right

603
00:43:30,560 --> 00:43:36,530
today i want to talk about you the local approach to solving this problem

604
00:43:36,550 --> 00:43:39,580
o talk about the mislabeled

605
00:43:39,590 --> 00:43:42,750
and as well as the dissident report which

606
00:43:42,860 --> 00:43:44,900
we don't create a global model

607
00:43:45,020 --> 00:43:47,660
instead of that the target function

608
00:43:47,680 --> 00:43:51,000
it's estimated a local way

609
00:43:51,020 --> 00:43:53,860
because we only consider a local region

610
00:43:53,870 --> 00:43:58,090
so we can assume that the distribution of the ranking that region

611
00:43:58,110 --> 00:44:00,430
o is constant

612
00:44:02,240 --> 00:44:06,370
the problem is how do you estimate is locally constant model

613
00:44:06,390 --> 00:44:08,930
so to be more precise

614
00:44:08,940 --> 00:44:11,500
and we consider the all the ranking

615
00:44:11,990 --> 00:44:14,240
instances generated

616
00:44:14,240 --> 00:44:17,740
according to an underlying distribution

617
00:44:17,750 --> 00:44:21,900
and this distribution is at least a possibility

618
00:44:21,930 --> 00:44:25,660
constant within the local region

619
00:44:26,890 --> 00:44:29,250
so other preference nearby

620
00:44:29,270 --> 00:44:32,010
also generated by the same distribution

621
00:44:32,020 --> 00:44:36,090
so basically we can just using the principle of the muscle like principle to solve

622
00:44:36,090 --> 00:44:38,360
this problem

623
00:44:41,480 --> 00:44:45,790
i said the there is the probability distribution over entries

624
00:44:46,880 --> 00:44:49,450
what should this distribution look like

625
00:44:49,460 --> 00:44:53,650
OK so here i would be more explicitly that to show this one particular way

626
00:44:53,650 --> 00:44:56,050
to model the distributions

627
00:44:56,090 --> 00:44:59,260
here we use the so-called models model

628
00:44:59,260 --> 00:45:01,040
that's right

629
00:45:01,170 --> 00:45:04,030
the main page

630
00:45:05,030 --> 00:45:07,140
then to describe this one

631
00:45:09,030 --> 00:45:12,710
is one

632
00:45:12,760 --> 00:45:16,410
so much is

633
00:45:21,990 --> 00:45:24,780
we will

634
00:45:26,160 --> 00:45:28,070
and we have probabilities

635
00:45:30,280 --> 00:45:35,980
so if there was a spot would have been

636
00:45:37,650 --> 00:45:39,670
great white

637
00:45:39,700 --> 00:45:45,340
and was low amateur might also in this section

638
00:45:47,160 --> 00:45:53,280
to describe

639
00:45:53,670 --> 00:45:55,110
well i think

640
00:45:59,170 --> 00:46:03,030
and actually this club

641
00:46:03,050 --> 00:46:05,360
the most

642
00:46:05,370 --> 00:46:08,920
the text image retrieval

643
00:46:08,950 --> 00:46:12,280
so here we all edges

644
00:46:13,070 --> 00:46:14,820
four has made

645
00:46:14,830 --> 00:46:15,300
i am

646
00:46:15,380 --> 00:46:18,060
it turns out

647
00:46:18,190 --> 00:46:24,130
some kind of the cosine derive

648
00:46:24,140 --> 00:46:27,510
of complex fluid and

649
00:46:27,930 --> 00:46:31,460
and the end of the first

650
00:46:31,470 --> 00:46:33,310
so this is

651
00:46:33,320 --> 00:46:34,600
and i

652
00:46:36,010 --> 00:46:37,310
on the this

653
00:46:38,110 --> 00:46:41,680
all possible steps to future the kids disease

654
00:46:41,920 --> 00:46:48,670
i guess you were going to try to describe the time so it

655
00:46:48,680 --> 00:46:53,260
talk about the most well-known one actually

656
00:46:56,400 --> 00:47:00,470
she popular which killed

657
00:47:03,100 --> 00:47:05,130
about ten years

658
00:47:06,850 --> 00:47:09,180
but the

659
00:47:09,370 --> 00:47:13,080
and many others system

660
00:47:14,150 --> 00:47:18,130
but recent research shows that

661
00:47:18,140 --> 00:47:20,470
to show that

662
00:47:20,510 --> 00:47:25,240
pictures like there's actually no more than one of the most popular ones

663
00:47:27,560 --> 00:47:30,240
and i don't have a little bit about

664
00:47:31,880 --> 00:47:32,970
so called

665
00:47:33,040 --> 00:47:36,120
i have a chance

666
00:47:36,220 --> 00:47:38,610
and we'll start

667
00:47:40,060 --> 00:47:42,210
to do this

668
00:47:42,250 --> 00:47:43,840
it's also

669
00:47:43,850 --> 00:47:48,420
like something from the discrimination texture

670
00:47:48,460 --> 00:47:49,440
as a

671
00:47:49,450 --> 00:47:52,670
i just don't know this because the

672
00:47:53,590 --> 00:47:57,520
so we we can quickly

673
00:47:57,580 --> 00:47:59,760
the people can quickly

674
00:47:59,840 --> 00:48:01,300
the first moment

675
00:48:02,220 --> 00:48:10,500
just or or the whole image or

676
00:48:10,520 --> 00:48:12,460
many of the image

677
00:48:12,470 --> 00:48:14,020
depends on which part of

678
00:48:16,940 --> 00:48:18,620
and the

679
00:48:18,640 --> 00:48:19,920
quite well

680
00:48:22,970 --> 00:48:26,840
well then the whole

681
00:48:28,720 --> 00:48:31,680
so for example one

682
00:48:31,720 --> 00:48:35,990
o thing

683
00:48:36,090 --> 00:48:38,580
equal whereas

684
00:48:38,620 --> 00:48:40,520
when it

685
00:48:40,580 --> 00:48:42,510
when all in the lead

686
00:48:47,070 --> 00:48:48,740
people to each other

687
00:48:51,170 --> 00:48:56,210
well you because it anywhere

688
00:48:56,220 --> 00:49:00,090
in the

689
00:49:04,230 --> 00:49:05,600
for many use

690
00:49:05,600 --> 00:49:09,060
the clothes are one

691
00:49:14,340 --> 00:49:16,500
histogram i

692
00:49:21,580 --> 00:49:27,560
they tend to level equally distributed according to a lot of

693
00:49:37,290 --> 00:49:41,100
so what

694
00:49:41,140 --> 00:49:43,590
this is because

695
00:49:43,600 --> 00:49:44,750
just to to remind you

696
00:49:45,170 --> 00:49:49,220
one hundred search

697
00:49:49,220 --> 00:49:49,920
and now

698
00:49:50,440 --> 00:49:54,600
one the

699
00:49:56,640 --> 00:50:00,260
that's parameters like average level

700
00:50:00,270 --> 00:50:02,880
all that she

701
00:50:03,050 --> 00:50:08,330
quite different from the previous section

702
00:50:08,340 --> 00:50:10,970
also in you

703
00:50:11,050 --> 00:50:13,180
and you can the really

704
00:50:13,220 --> 00:50:15,140
exchange is very close to

705
00:50:16,090 --> 00:50:20,460
and then have a lot of changes before that station

706
00:50:20,640 --> 00:50:23,000
is a little bit bigger

707
00:50:23,010 --> 00:50:27,690
and they all

708
00:50:30,320 --> 00:50:32,100
i was

709
00:50:38,750 --> 00:50:41,760
this was done

710
00:50:45,600 --> 00:50:47,040
so this don't

711
00:50:47,140 --> 00:50:50,260
so i'm just going completed texture

712
00:50:50,260 --> 00:50:54,260
factor of three and so you gain factor three in light of course you gain

713
00:50:54,270 --> 00:50:59,120
factor three three times more sources you get three times more likely to see there's

714
00:51:00,370 --> 00:51:04,150
violation of the conservation of energy here

715
00:51:04,210 --> 00:51:05,790
and i want to demonstrate

716
00:51:05,810 --> 00:51:10,850
this to you using a red laser which we have used before

717
00:51:10,900 --> 00:51:12,290
and i will use

718
00:51:12,320 --> 00:51:15,140
what we call a grading

719
00:51:15,230 --> 00:51:17,200
grading is a

720
00:51:17,230 --> 00:51:22,020
plate which is specially prepared to transparent plate which has grooves in it

721
00:51:22,070 --> 00:51:25,620
and the one that i will use has twice twenty five hundred

722
00:51:25,640 --> 00:51:27,980
grooves we call them lines

723
00:51:28,000 --> 00:51:29,770
per image

724
00:51:29,980 --> 00:51:33,080
that means the separation the

725
00:51:33,080 --> 00:51:34,980
between two adjacent groups

726
00:51:35,020 --> 00:51:39,520
in my case is about two point one six microns micron

727
00:51:39,540 --> 00:51:41,980
ten to the minus six meters

728
00:51:42,030 --> 00:51:45,570
and the wavelength that i'm going to use these are red laser

729
00:51:45,580 --> 00:51:47,450
which is about six point three

730
00:51:47,450 --> 00:51:51,300
times ten to the minus seven meters

731
00:51:51,310 --> 00:51:52,720
and i'm going to

732
00:51:52,780 --> 00:51:56,460
but the whole thing they're going to make you see the edit distance l

733
00:51:56,480 --> 00:51:59,080
which is about ten metres

734
00:51:59,100 --> 00:52:01,180
so there's a lot of me now

735
00:52:01,220 --> 00:52:02,510
to calculate

736
00:52:02,530 --> 00:52:07,050
where zero order fall where the first order and second order will fall

737
00:52:07,100 --> 00:52:08,110
we call

738
00:52:08,130 --> 00:52:09,480
when n is zero

739
00:52:09,490 --> 00:52:12,440
recall that zero order

740
00:52:12,480 --> 00:52:15,040
so this is zero order

741
00:52:15,210 --> 00:52:19,170
when n is one we call that first order

742
00:52:19,180 --> 00:52:20,430
and when n is two

743
00:52:20,440 --> 00:52:22,650
recall that second order

744
00:52:22,700 --> 00:52:25,950
and you have of course the first order also on this site and the second

745
00:52:25,950 --> 00:52:30,210
order also on this side everything that you have here you have to also think

746
00:52:30,210 --> 00:52:32,680
of it as being on the other side

747
00:52:32,700 --> 00:52:36,110
so i can predict now we had a zero order will be

748
00:52:36,170 --> 00:52:37,550
when n is zero

749
00:52:37,580 --> 00:52:39,220
that is zero degrees

750
00:52:39,280 --> 00:52:43,080
that immediately obvious i use that equation if ten is zero

751
00:52:43,130 --> 00:52:46,090
the zero order is always right at the center

752
00:52:46,100 --> 00:52:48,980
provided that all the sources are in phase

753
00:52:48,990 --> 00:52:52,160
and there will be in phase because they use plane waves

754
00:52:52,170 --> 00:52:56,290
so hogan's will tell you that they're going to oscillate exactly at the same time

755
00:52:56,570 --> 00:53:00,970
they produce the same frequency they produce the same wavelength and they're all in phase

756
00:53:00,970 --> 00:53:06,560
with each other so maximum one equals zero then there will be a maximum which

757
00:53:06,560 --> 00:53:10,500
i calculated to be three point five five degrees

758
00:53:10,560 --> 00:53:12,730
i calculated from this equation

759
00:53:12,750 --> 00:53:16,310
and then stayed at two will be roughly

760
00:53:16,320 --> 00:53:18,090
seven point one degree

761
00:53:20,950 --> 00:53:22,650
if you want to know

762
00:53:22,700 --> 00:53:26,700
how whites the width of this peak is going to be

763
00:53:26,770 --> 00:53:31,080
then you have to know how many lines of migrating i will be using

764
00:53:37,780 --> 00:53:39,880
it's like so

765
00:53:39,900 --> 00:53:41,800
you i have these lines

766
00:53:41,820 --> 00:53:45,360
not unlike degrading the you have new optics kit

767
00:53:45,370 --> 00:53:48,580
there are twenty five hundred of those lines per inch

768
00:53:48,620 --> 00:53:54,590
and my laser beam is roughly two millimeters in size

769
00:53:54,600 --> 00:53:58,240
but this is about two millimeters

770
00:53:58,310 --> 00:54:03,580
that tells me then that cover about two hundred lines

771
00:54:03,580 --> 00:54:05,840
and if i have two hundred lines

772
00:54:05,850 --> 00:54:07,690
i can now calculate

773
00:54:07,730 --> 00:54:09,820
how white line is going to be

774
00:54:09,860 --> 00:54:12,860
because this factor of and enters into which here

775
00:54:12,920 --> 00:54:14,490
and if i

776
00:54:14,510 --> 00:54:17,880
expressed in terms of that angle delta theta

777
00:54:17,940 --> 00:54:20,800
then the angle delta theta

778
00:54:20,820 --> 00:54:23,690
going back here

779
00:54:23,710 --> 00:54:26,790
so delta theta

780
00:54:26,800 --> 00:54:31,040
is that the three point five five degrees divided by three hundred

781
00:54:31,110 --> 00:54:33,450
that's an extremely small angle

782
00:54:33,500 --> 00:54:34,340
that angle

783
00:54:34,350 --> 00:54:36,580
it is approximately one

784
00:54:36,630 --> 00:54:38,820
arc minutes

785
00:54:38,860 --> 00:54:42,240
which is sixty times smaller than one degree

786
00:54:42,260 --> 00:54:44,780
and if you want to translate that in terms of

787
00:54:44,790 --> 00:54:47,920
how whites that spot will be

788
00:54:47,930 --> 00:54:49,990
if i see it on the screen

789
00:54:50,050 --> 00:54:53,630
ten meters away from the and if you want to call that delta x

790
00:54:54,340 --> 00:54:56,210
you wouldn't even to predict

791
00:54:56,220 --> 00:54:57,480
the delta x

792
00:54:57,490 --> 00:54:59,470
is something like three millimeters

793
00:54:59,530 --> 00:55:01,700
and the reason why i say naively

794
00:55:01,710 --> 00:55:05,820
because you will not see that three millimeters it will be extremely narrow but it

795
00:55:05,820 --> 00:55:10,620
will be more than three millimeters because the limiting factor is always the divergence of

796
00:55:10,660 --> 00:55:11,730
a laser beam

797
00:55:11,780 --> 00:55:14,830
so the divergence of my laser beam is more

798
00:55:14,840 --> 00:55:18,120
then one argument so i don't get down to the

799
00:55:18,160 --> 00:55:19,440
what i mean it

800
00:55:19,540 --> 00:55:21,440
narrow beam

801
00:55:21,450 --> 00:55:23,970
i'm not too far away from it though

802
00:55:23,990 --> 00:55:28,330
so this is what i want to show you first

803
00:55:28,340 --> 00:55:32,920
i will turn on the laser first

804
00:55:32,990 --> 00:55:35,740
and then make it very dark because we do need

805
00:55:35,810 --> 00:55:38,340
darkness so this has to come off

806
00:55:38,360 --> 00:55:39,820
that would obviously

807
00:55:39,830 --> 00:55:43,180
well i two and of the wrong laser with an expert on the wrong that's

808
00:55:43,180 --> 00:55:48,540
OK that's the second demonstration which i do is with a green laser this is

809
00:55:48,550 --> 00:55:49,960
the one that i need

810
00:55:50,060 --> 00:55:55,350
this is the red laser will come on very quickly

811
00:55:55,410 --> 00:55:57,030
that is

812
00:55:57,040 --> 00:56:00,110
if you could turn that off maybe that will help although everyone can see that

813
00:56:00,120 --> 00:56:01,470
would help

814
00:56:01,530 --> 00:56:03,450
so you see here very clearly

815
00:56:04,710 --> 00:56:08,060
zero order is that the that right in the middle

816
00:56:08,090 --> 00:56:10,030
this one's to is zero

817
00:56:10,070 --> 00:56:13,120
and if they don't want my three and half degrees is also three and half

818
00:56:13,120 --> 00:56:16,490
degrees this is the seven point one degrees and so on

819
00:56:16,500 --> 00:56:17,750
so you see his whole

820
00:56:17,780 --> 00:56:19,560
kind of

821
00:56:19,590 --> 00:56:21,100
the fraction

822
00:56:21,330 --> 00:56:24,500
for interference as a result of multiple

823
00:56:24,510 --> 00:56:27,470
so it so this is a these groups

824
00:56:27,480 --> 00:56:33,170
in a piece of plastics

825
00:56:33,260 --> 00:56:37,590
notice how small the whole never they are compared with the double slit interference so

826
00:56:37,590 --> 00:56:38,910
they don't have that

827
00:56:38,950 --> 00:56:42,550
theoretical minimum with this one over and that the approach that

828
00:56:42,560 --> 00:56:46,450
and the reason why they are not that narrow is because the divergence of the

829
00:56:46,450 --> 00:56:51,290
laser beam itself is larger than that one argument that calculated

830
00:56:51,330 --> 00:56:53,670
so you can never be that of course

831
00:56:53,690 --> 00:57:07,310
we did this experiment was white with red lights

832
00:57:07,320 --> 00:57:08,690
but keep in mind

833
00:57:09,650 --> 00:57:11,230
if i take red light

834
00:57:11,240 --> 00:57:13,920
here is the maximum zero order

835
00:57:13,930 --> 00:57:15,580
here is the maximum

836
00:57:15,590 --> 00:57:18,050
provided islam is islam therefore red

837
00:57:18,060 --> 00:57:21,620
here's the maximum provided that the land for red

838
00:57:21,680 --> 00:57:23,260
but if i white light

839
00:57:23,280 --> 00:57:25,530
then of course i deal with other colors

840
00:57:25,540 --> 00:57:29,130
and if i have blue lights in my white light it will also have the

841
00:57:29,130 --> 00:57:30,420
maximum here

842
00:57:30,440 --> 00:57:35,800
that's non-negotiable but has its first order maximum because the wavelength is shorter and the

843
00:57:35,800 --> 00:57:38,090
second order maximum year

844
00:57:38,150 --> 00:57:40,210
this will be the same distance

845
00:57:40,280 --> 00:57:42,230
so when you do this was white light

846
00:57:42,240 --> 00:57:47,660
you're going to see always zero order white light because all the columns of the

847
00:57:47,660 --> 00:57:51,960
maximum at zero order but at first and second high orders

848
00:57:51,960 --> 00:57:53,100
so actually

849
00:57:56,200 --> 00:57:57,720
the it's school also

850
00:57:57,730 --> 00:57:59,290
we like

851
00:57:59,350 --> 00:58:03,460
and if you find the directions perpendicular

852
00:58:03,710 --> 00:58:07,130
two hyper

853
00:58:07,150 --> 00:58:08,100
and the

854
00:58:08,240 --> 00:58:10,250
called by

855
00:58:10,250 --> 00:58:12,440
well the value

856
00:58:12,460 --> 00:58:13,930
that's how

857
00:58:16,220 --> 00:58:19,070
well to be alive

858
00:58:19,090 --> 00:58:22,120
two this line

859
00:58:22,130 --> 00:58:29,170
so our problem so

860
00:58:29,180 --> 00:58:34,530
so we can this that this function satisfies the point

861
00:58:34,580 --> 00:58:36,650
the flying high

862
00:58:36,730 --> 00:58:43,700
and we can also find the perpendicular from the height to

863
00:58:43,760 --> 00:58:48,040
the five live you know

864
00:58:48,070 --> 00:58:53,070
so they need it had this

865
00:58:53,080 --> 00:58:55,350
we can actually also

866
00:58:55,990 --> 00:58:59,120
we can apply to find this

867
00:58:59,150 --> 00:59:01,770
this morning

868
00:59:02,650 --> 00:59:07,060
from the hyperplane the support vectors of the positive examples

869
00:59:07,120 --> 00:59:08,750
and also this

870
00:59:09,290 --> 00:59:14,760
the support vectors of the negative examples

871
00:59:14,780 --> 00:59:17,470
but let's look at

872
00:59:18,970 --> 00:59:27,870
and the hypothesis

873
00:59:30,420 --> 00:59:33,880
very well put it is that the wrong

874
00:59:33,950 --> 00:59:36,990
so i thought i'd post the

875
00:59:38,240 --> 00:59:40,550
the class is lot

876
00:59:42,150 --> 00:59:46,160
thirty five creation w excitement he

877
00:59:46,170 --> 00:59:48,740
i creator of cluster

878
00:59:48,800 --> 00:59:52,340
o five

879
00:59:52,370 --> 00:59:56,620
w x i this is more than

880
00:59:57,760 --> 01:00:02,090
which we can combine in one quite

881
01:00:02,120 --> 01:00:04,360
and here i have always

882
01:00:04,370 --> 01:00:07,600
i can't find what i mean

883
01:00:07,710 --> 01:00:16,750
classification model

884
01:00:16,800 --> 01:00:18,700
but now to

885
01:00:18,700 --> 01:00:20,720
to find out

886
01:00:21,020 --> 01:00:23,150
this time

887
01:00:23,160 --> 01:00:24,980
the last one

888
01:00:25,030 --> 01:00:26,340
so this model

889
01:00:26,360 --> 01:00:29,180
of high level

890
01:00:29,260 --> 01:00:32,880
the hyperplane that defines one more

891
01:00:32,900 --> 01:00:34,380
it is defined by

892
01:00:34,400 --> 01:00:37,810
w x i b it's one

893
01:00:37,830 --> 01:00:42,460
and we can also find the perpendicular distance from the the origin

894
01:00:45,520 --> 01:00:47,410
one might

895
01:00:47,410 --> 01:00:51,690
divided by p that

896
01:00:51,740 --> 01:00:55,250
and similarly for how to find out more

897
01:00:55,910 --> 01:01:03,210
the final w x y mind one and we have also the perpendicular distance from

898
01:01:03,210 --> 01:01:08,670
the the origin minus minus one my behind by

899
01:01:09,750 --> 01:01:13,680
so if you have

900
01:01:13,730 --> 01:01:15,230
if we had

901
01:01:17,240 --> 01:01:20,570
this type of data

902
01:01:20,590 --> 01:01:22,580
i many you

903
01:01:25,580 --> 01:01:27,830
to the origin and also the

904
01:01:27,840 --> 01:01:29,610
this model to the ontology

905
01:01:29,620 --> 01:01:30,690
we can

906
01:01:30,940 --> 01:01:33,310
the distance

907
01:01:33,380 --> 01:01:36,790
of the margin

908
01:01:36,810 --> 01:01:38,740
which is

909
01:01:39,770 --> 01:01:46,470
well defined by you that so actually wants to maximize

910
01:01:47,990 --> 01:01:50,770
why do you

911
01:01:51,750 --> 01:02:01,510
this is considered to be innovation we actually minimising the role of of dutch

912
01:02:01,520 --> 01:02:02,690
subject to the

913
01:02:02,710 --> 01:02:04,980
three the equality constraints

914
01:02:04,990 --> 01:02:06,920
which is

915
01:02:09,490 --> 01:02:12,730
this is going to compute

916
01:02:15,860 --> 01:02:20,330
five of the nine to find the minimum value

917
01:02:20,340 --> 01:02:21,590
and the

918
01:02:21,610 --> 01:02:24,980
the dual representation

919
01:02:26,220 --> 01:02:31,020
is obtained by introducing lagrange multipliers lambda

920
01:02:31,050 --> 01:02:33,300
which is easy to solve

921
01:02:33,320 --> 01:02:38,020
so we have to maximize which includes things like

922
01:02:38,040 --> 01:02:39,490
the flyers

923
01:02:39,490 --> 01:02:42,630
which are lot of the year

924
01:02:42,660 --> 01:02:45,540
and when multiplied with the class labels

925
01:02:45,560 --> 01:02:50,610
of the training examples and training examples such

926
01:02:52,490 --> 01:02:55,260
now i think about how

927
01:02:55,280 --> 01:02:56,280
come to this

928
01:02:56,290 --> 01:02:58,110
two representations

929
01:02:58,120 --> 01:03:00,020
i just want to show you

930
01:03:05,290 --> 01:03:07,650
that's used in training

931
01:03:07,660 --> 01:03:09,510
that you want to maximize

932
01:03:10,620 --> 01:03:13,540
we've got what

933
01:03:13,590 --> 01:03:17,030
so what examples and training examples

934
01:03:17,040 --> 01:03:20,690
and you see in this country the inner product

935
01:03:21,830 --> 01:03:24,560
so the

936
01:03:24,630 --> 01:03:30,800
we take for each there examples this problem and this will come back later when

937
01:03:30,800 --> 01:03:35,200
you look at the kernel method

938
01:03:35,200 --> 01:03:36,170
so when we

939
01:03:36,400 --> 01:03:43,010
maximize the real thing actually the decision function

940
01:03:43,020 --> 01:03:47,260
the decision function is used to classify

941
01:03:47,260 --> 01:03:54,100
OK as you can see i have changed the style of my slides that's rather

942
01:03:54,100 --> 01:04:00,260
considers because there's some material that is joint work with julian gold and ralf herbrich

943
01:04:00,380 --> 01:04:06,650
at microsoft research and so this is an application of reinforcement learning to a computer

944
01:04:07,570 --> 01:04:12,430
and it turns out that carry some

945
01:04:12,450 --> 01:04:18,000
extra difficulties because some of the notions of reinforcement learning are not as easily transferred

946
01:04:18,000 --> 01:04:22,800
to computer games and there are also a lot of technical difficulties in

947
01:04:22,850 --> 01:04:30,310
in implementing something into an existing computer games because the code can be quite messy

948
01:04:30,370 --> 01:04:36,570
i give it a shot motivation and then explain how the algorithm works

949
01:04:36,580 --> 01:04:43,760
and then i'll give you some results for some visual results and

950
01:04:43,770 --> 01:04:49,810
then some numerical results and in particular address some implementation issues that arise if you

951
01:04:49,810 --> 01:04:51,900
don't happen to have a beautiful

952
01:04:51,990 --> 01:04:58,420
the simulated model about having messy code base of an existing computer game to work

953
01:05:02,080 --> 01:05:06,300
let's just remember

954
01:05:06,320 --> 01:05:12,230
this painful experience the right character there had when i was just using this gap

955
01:05:12,230 --> 01:05:19,300
in the finite state machine that drives that and showed this very flexible behaviour

956
01:05:19,320 --> 01:05:24,230
so that's something that's highly undesirable and of course we would hope that an adaptive

957
01:05:24,230 --> 01:05:28,040
agent would be able to avoid such behavior

958
01:05:28,060 --> 01:05:32,900
well i'm not saying that this work solves the problem but this work was an

959
01:05:32,900 --> 01:05:38,510
attempt to solve the problem and we've learned a few lessons

960
01:05:43,770 --> 01:05:54,600
we have discussed these problems that the policy of the policy of the non-playing characters

961
01:05:54,600 --> 01:05:58,660
fixed development time it consists of a huge rule set

962
01:05:59,200 --> 01:06:03,510
they call it the finite state machine that is really a bunch of if then

963
01:06:03,530 --> 01:06:11,500
statements that are very messy and and therefore hard to expand or maintain

964
01:06:11,510 --> 01:06:15,480
and of course it would be nice to have adaptive an emergent behavior which is

965
01:06:15,480 --> 01:06:18,180
hardly shown by this kind of system

966
01:06:20,940 --> 01:06:25,060
to put this in a very blunt way and in

967
01:06:25,680 --> 01:06:27,460
traditionally i

968
01:06:27,520 --> 01:06:33,110
used in in this kind of games the developer says exactly what it once the

969
01:06:33,640 --> 01:06:35,720
non-player character to do

970
01:06:35,730 --> 01:06:40,770
and the dream of using machine learning is really to give the tool to the

971
01:06:40,910 --> 01:06:42,450
game designer

972
01:06:42,460 --> 01:06:44,950
and that game designer would then

973
01:06:47,240 --> 01:06:53,940
learning algorithm what he wants the non-playing character to achieve certain kinds of behavior and

974
01:06:53,940 --> 01:06:59,790
then the learning algorithm will learn how to do that introduced the actions

975
01:07:00,040 --> 01:07:06,550
now here's the set up that we have with an agent and the game and

976
01:07:06,550 --> 01:07:13,140
reinforcement learning so we learning algorithm the game since the game state to the learning

977
01:07:13,140 --> 01:07:15,660
algorithm and to the agent

978
01:07:17,610 --> 01:07:19,960
the agent then takes an action which

979
01:07:20,000 --> 01:07:23,570
gets goes into the game as well as the learning algorithm

980
01:07:23,590 --> 01:07:29,100
and in this case now the game gives some kind of reward or punishment

981
01:07:29,150 --> 01:07:32,160
two of the learning algorithm

982
01:07:32,180 --> 01:07:37,890
and from that the learning algorithm generates the parameter update that then influences the policy

983
01:07:37,890 --> 01:07:40,070
of the agent

984
01:07:40,090 --> 01:07:45,130
so that's the theory but of course it's not so easy to represent the game

985
01:07:46,190 --> 01:07:52,110
and in fact you can only present an abstracted version of the game state and

986
01:07:52,110 --> 01:07:54,320
that's partly where the problems lie

987
01:07:54,340 --> 01:07:56,620
which effectively makes this

988
01:07:56,640 --> 01:08:01,670
this problem a partially observed

989
01:08:01,690 --> 01:08:06,640
markov decision process rather than a fully observed one we have the state description and

990
01:08:06,640 --> 01:08:10,960
we see it but it doesn't fully cold the actual state

991
01:08:13,240 --> 01:08:22,000
we consider two look two different learning algorithms q learning and the learning algorithm sarsa

992
01:08:22,050 --> 01:08:27,400
and the i don't know in how far dog has cover

993
01:08:27,440 --> 01:08:29,920
either of these both of these

994
01:08:29,940 --> 01:08:33,200
can anyone tell me with anyone at the lecture

995
01:08:33,250 --> 01:08:36,980
he mentioned both the

996
01:08:37,000 --> 01:08:44,710
so let's just take another look at these

997
01:08:44,720 --> 01:08:49,730
so this is the update equation for both of them if you like so we

998
01:08:49,730 --> 01:08:51,200
have that

999
01:08:51,250 --> 01:08:53,280
this q table and we

1000
01:08:53,300 --> 01:08:55,320
take the old q value

1001
01:08:55,340 --> 01:09:01,160
and adds a small fraction times something new to it and this something new is

1002
01:09:01,160 --> 01:09:02,330
the reward

1003
01:09:02,340 --> 01:09:07,870
class gamma time some function of the subsequent

1004
01:09:08,680 --> 01:09:12,570
q value minus the old q value

1005
01:09:12,590 --> 01:09:16,700
and just to get the terminology right again

1006
01:09:16,710 --> 01:09:22,820
so q represents this state action value alpha is the learning rate here

1007
01:09:23,010 --> 01:09:26,130
a is the actual

1008
01:09:26,140 --> 01:09:27,910
hours the rewards

1009
01:09:27,920 --> 01:09:30,410
this is the current state here

1010
01:09:30,420 --> 01:09:36,380
as prime is the state is subsequent state and gamma is the discount factor for

1011
01:09:36,380 --> 01:09:38,170
future rewards

1012
01:09:40,380 --> 01:09:46,310
these two learning algorithms q learning and sarsa only differ in what this particular term

1013
01:09:46,310 --> 01:09:47,710
here is

1014
01:09:47,760 --> 01:09:50,400
and in q learning that is

1015
01:09:50,420 --> 01:09:55,140
the best is the is the state action value

1016
01:09:55,160 --> 01:10:01,400
in the subsequent state given the best action you could take in that state

1017
01:10:01,410 --> 01:10:06,480
and in end this doesn't depend on the policy of currently running and therefore it's

1018
01:10:06,480 --> 01:10:08,970
called an off policy method

1019
01:10:09,050 --> 01:10:12,420
now in countries such as

1020
01:10:12,440 --> 01:10:14,860
in science this quantity

1021
01:10:14,890 --> 01:10:17,130
is the q value

1022
01:10:17,140 --> 01:10:19,760
often the subsequent state again

1023
01:10:22,120 --> 01:10:23,470
also with the

1024
01:10:23,480 --> 01:10:28,470
actual next action that you're taking so you it's the best one

1025
01:10:28,480 --> 01:10:31,290
and here's the actual one take

1026
01:10:32,450 --> 01:10:34,450
that makes quite a difference

1027
01:10:34,500 --> 01:10:38,800
in this particular problem we use a source

1028
01:10:38,810 --> 01:10:44,940
because in q learning UCF to perform this maximization here and in order to do

1029
01:10:44,940 --> 01:10:49,420
that you would have to know which actions you had available at that point in

1030
01:10:49,420 --> 01:10:56,490
time now it so happens that in messy computer games it's not entirely clear which

1031
01:10:56,510 --> 01:11:01,770
action constitutes a legal action at a given point in time and

1032
01:11:01,780 --> 01:11:07,080
what happens in the code in this particular game was that you had to submit

1033
01:11:07,140 --> 01:11:12,200
action and the code would check if that action was actually you could actually be

1034
01:11:12,200 --> 01:11:15,610
used and thereby change its state

1035
01:11:16,430 --> 01:11:21,770
use it if it could and rejected if it couldn't so we couldn't explicitly perform

1036
01:11:21,800 --> 01:11:28,010
this thing so that's why we chose stars where we could just observe which next

1037
01:11:28,010 --> 01:11:33,850
actually were then eventually allowed to take and therefore could evaluate this quantity and therefore

1038
01:11:34,030 --> 01:11:36,250
do this update here

1039
01:11:36,270 --> 01:11:38,630
now it's

1040
01:11:38,630 --> 01:11:41,350
of matrices so this is something we want

1041
01:11:41,360 --> 01:11:42,810
we would

1042
01:11:46,080 --> 01:11:51,390
and that property would be true all right for this from the sky

1043
01:11:54,370 --> 01:11:54,970
because it

1044
01:11:55,030 --> 01:11:58,000
it's it's just we're just a matrix

1045
01:11:58,050 --> 01:12:03,220
stretching it along vector so it's so far frobenius it's the same as the triangle

1046
01:12:03,220 --> 01:12:07,000
inequality for this and squared length vector

1047
01:12:10,230 --> 01:12:15,280
we could look what i don't discovered that i was going to say about determinants

1048
01:12:15,300 --> 01:12:19,520
one just before i got want to kill off determinants

1049
01:12:20,300 --> 01:12:26,010
in this sense that the determinant of a plus b like we

1050
01:12:26,010 --> 01:12:29,250
it could be sort of almost anything

1051
01:12:29,260 --> 01:12:33,230
so OK so let me follow you thought

1052
01:12:33,270 --> 01:12:35,830
and now tell me more

1053
01:12:35,840 --> 01:12:40,280
how do i look at what he does to a vector

1054
01:12:40,540 --> 01:12:45,010
i get another vector

1055
01:12:45,010 --> 01:12:49,700
which has no that's right so we're going to create normal of the matrix

1056
01:12:49,710 --> 01:12:51,130
out of

1057
01:12:51,130 --> 01:12:53,030
that decision on

1058
01:12:53,040 --> 01:12:56,010
so how should we do if we take a vector

1059
01:12:57,680 --> 01:12:59,360
you know its length

1060
01:12:59,370 --> 01:13:02,040
and what do we do we

1061
01:13:02,060 --> 01:13:03,990
we multiply by a

1062
01:13:04,010 --> 01:13:05,810
and we know the line

1063
01:13:05,870 --> 01:13:07,640
so in link to this

1064
01:13:07,660 --> 01:13:11,350
and i know the length of the original

1065
01:13:11,370 --> 01:13:12,900
so what do i do

1066
01:13:13,010 --> 01:13:17,040
come up with the size of a service

1067
01:13:18,210 --> 01:13:19,830
five divided by this

1068
01:13:19,840 --> 01:13:23,200
what if i if i look at this

1069
01:13:23,210 --> 01:13:27,720
so that these are both factors so we know what links that are

1070
01:13:28,590 --> 01:13:31,280
so take any vector x

1071
01:13:31,290 --> 01:13:35,970
i have multiplied by and i looked to see OK to grow

1072
01:13:36,010 --> 01:13:38,270
and this ratio will be

1073
01:13:38,280 --> 01:13:40,270
growth rate you right

1074
01:13:40,290 --> 01:13:44,150
i could normalized to say well it take unit vectors

1075
01:13:44,250 --> 01:13:48,010
i wouldn't have to divide by the one but either way it doesn't matter how

1076
01:13:48,010 --> 01:13:50,600
often you see it one way or the other

1077
01:13:52,460 --> 01:13:54,890
OK but now what's up here

1078
01:13:54,910 --> 01:13:59,170
i've been to maximize i'm looking for the worst x right

1079
01:13:59,300 --> 01:14:00,780
some vectors x

1080
01:14:00,790 --> 01:14:01,800
my it

1081
01:14:01,830 --> 01:14:04,630
might in the null space and i go to zero

1082
01:14:04,650 --> 01:14:07,720
but that doesn't mean the matrix is the zero matrix

1083
01:14:08,510 --> 01:14:11,680
good norm is

1084
01:14:11,710 --> 01:14:14,490
r max

1085
01:14:14,510 --> 01:14:15,710
o all

1086
01:14:15,750 --> 01:14:20,710
non-zero vectors x so the max of this

1087
01:14:21,010 --> 01:14:24,430
and as i said i could take the max

1088
01:14:24,460 --> 01:14:29,740
i've taken over i could make the denominator one that i would just be looking

1089
01:14:29,740 --> 01:14:30,640
at the new

1090
01:14:30,660 --> 01:14:35,180
so the question is how much can the matrix blow up

1091
01:14:35,200 --> 01:14:37,960
how much can increase the size of

1092
01:14:38,000 --> 01:14:42,740
that's that's a good measure of the norm now does well OK

1093
01:14:42,810 --> 01:14:44,510
because we are to check

1094
01:14:44,540 --> 01:14:47,470
this property but it it's it's easy

1095
01:14:47,490 --> 01:14:52,130
this property will come right out of the vector properties

1096
01:14:52,140 --> 01:14:55,810
actually another property of come out for the matrix normal

1097
01:14:55,920 --> 01:14:59,630
that the norm of times b

1098
01:14:59,640 --> 01:15:04,970
is less than the norm of a times the normal b

1099
01:15:04,980 --> 01:15:08,640
i can sort of say it in words why that will be true

1100
01:15:10,810 --> 01:15:14,020
what's the norm of a b

1101
01:15:14,030 --> 01:15:15,120
five by my

1102
01:15:15,130 --> 01:15:16,750
by my idea here

1103
01:15:16,770 --> 01:15:18,630
i take vectors x

1104
01:15:18,640 --> 01:15:20,490
i see how much they are blown up

1105
01:15:20,510 --> 01:15:22,380
by a b

1106
01:15:23,220 --> 01:15:26,270
well first of all i could look at that in two steps i could say

1107
01:15:26,270 --> 01:15:30,660
OK take the vector x how much is blown up by b

1108
01:15:30,670 --> 01:15:33,210
and then how much is bx blown up by the

1109
01:15:35,810 --> 01:15:39,880
well why so why don't i have just equality there

1110
01:15:39,910 --> 01:15:45,170
i get two shots you get two shots on the right that the worst acts

1111
01:15:45,170 --> 01:15:49,800
the exit gets one of the most by b might not

1112
01:15:49,830 --> 01:15:51,470
producer bx at the

1113
01:15:52,310 --> 01:15:53,300
i was strongly

1114
01:15:54,030 --> 01:15:55,900
so so

1115
01:15:56,200 --> 01:16:01,300
in other words it just comes from here is the proof that the length of

1116
01:16:01,300 --> 01:16:03,240
a BX

1117
01:16:03,280 --> 01:16:06,930
so this article will be kept low

1118
01:16:08,250 --> 01:16:10,640
that's how much

1119
01:16:10,680 --> 01:16:12,630
they can blow it up by

1120
01:16:12,650 --> 01:16:14,600
and now i'm down here

1121
01:16:14,610 --> 01:16:17,470
that's just the way

1122
01:16:17,490 --> 01:16:19,510
and px

1123
01:16:19,520 --> 01:16:24,300
can be candle wax up by more than it's not

1124
01:16:27,680 --> 01:16:33,050
now i've learned this this ABX can blow up more than

1125
01:16:34,660 --> 01:16:41,030
so that's why this is a very sad this is like called the sometimes called

1126
01:16:41,030 --> 01:16:43,250
the operator norm

1127
01:16:43,270 --> 01:16:50,030
because i'm thinking of a an operators acting whereas this is more a ray normal

1128
01:16:51,130 --> 01:16:53,880
often but it's got uses

1129
01:16:55,460 --> 01:17:00,750
like self so those are two important norms i guess i should

1130
01:17:00,760 --> 01:17:04,880
i admit that we can measure the length of vectors other ways

1131
01:17:04,890 --> 01:17:10,210
and if we did this would give us another measure of a how else could

1132
01:17:10,210 --> 01:17:11,920
i measure the norm of

1133
01:17:11,950 --> 01:17:13,840
the vector x

1134
01:17:13,860 --> 01:17:16,080
the length of the vector

1135
01:17:16,130 --> 01:17:20,400
it's just that i to write down policies think of other ways that we can

1136
01:17:20,400 --> 01:17:23,550
measure the size of

1137
01:17:24,630 --> 01:17:27,060
you change some of absolute values

1138
01:17:27,090 --> 01:17:32,380
right just just i need to take absolute value because i don't want any any

1139
01:17:32,380 --> 01:17:36,080
the the but in

1140
01:17:39,360 --> 01:17:41,030
so it's actually

1141
01:17:41,040 --> 01:17:42,970
three of this side here

1142
01:17:43,000 --> 01:17:44,680
is that of their

1143
01:17:44,700 --> 01:17:49,630
the difference between the square of good this time the and the square of the

1144
01:17:51,170 --> 01:17:54,430
and the reason why this is true is because this

1145
01:17:55,660 --> 01:17:59,030
of users is large and then i agree

1146
01:18:35,520 --> 01:18:37,370
i have no idea

1147
01:18:41,840 --> 01:18:44,560
i mean no i i no idea

1148
01:18:44,650 --> 01:18:49,360
i don't think that

1149
01:18:49,410 --> 01:18:55,110
i mean i together under competitive pressure maybe we can we can

1150
01:18:55,160 --> 01:18:58,880
can they make it better invertebrate

1151
01:18:59,590 --> 01:19:04,150
if that if you think about what you can do anything

1152
01:19:05,390 --> 01:19:07,250
so in this work in

1153
01:19:07,290 --> 01:19:09,630
the really curious

1154
01:19:12,590 --> 01:19:16,470
i guess you might believe this one out

1155
01:19:16,520 --> 01:19:20,510
and the other one the proof is just lines

1156
01:19:20,600 --> 01:19:22,860
if you're in doubt

1157
01:19:24,550 --> 01:19:36,200
you you know you don't see how to this one

1158
01:19:40,920 --> 01:19:42,370
if one

1159
01:19:42,510 --> 01:19:49,440
none of the mentioned is correct

1160
01:19:49,460 --> 01:19:50,500
one this is correct

1161
01:19:50,510 --> 01:19:52,860
so let's see

1162
01:19:52,880 --> 01:19:57,940
the is is this so i'm looking at

1163
01:19:57,990 --> 01:20:04,950
OK this is looking at the main thing

1164
01:20:06,930 --> 01:20:14,960
so you see this you write c is the difference between the difference between a

1165
01:20:16,680 --> 01:20:19,100
we really need

1166
01:20:23,360 --> 01:20:26,260
OK then i created

1167
01:20:26,260 --> 01:20:30,290
so i scraped it is greater plasticity where miners who

1168
01:20:30,340 --> 01:20:34,330
ACA these vectors and this is where the

1169
01:20:34,350 --> 01:20:38,290
it a OK this i can say something about this i know this because i

1170
01:20:39,180 --> 01:20:42,800
the english up another because i think

1171
01:20:44,000 --> 01:20:47,500
what can being

1172
01:20:50,560 --> 01:20:52,380
once believe this one

1173
01:20:59,460 --> 01:21:02,190
now we done because we can

1174
01:21:14,420 --> 01:21:17,070
because we can say that

1175
01:21:17,070 --> 01:21:20,400
so what we have now

1176
01:21:20,500 --> 01:21:23,500
we have that

1177
01:21:23,510 --> 01:21:25,670
this created his loss

1178
01:21:25,700 --> 01:21:28,990
because now we have we have no relationship

1179
01:21:29,000 --> 01:21:30,040
it is

1180
01:21:32,780 --> 01:21:34,870
this created the hinge loss

1181
01:21:34,890 --> 01:21:37,410
although there was some

1182
01:21:37,620 --> 01:21:41,530
i guess some across all of these because

1183
01:21:41,530 --> 01:21:45,710
when it doesn't take place so they lost the run time

1184
01:21:45,740 --> 01:21:47,420
this LP

1185
01:21:47,440 --> 01:21:50,380
WP nine once we have them

1186
01:21:51,410 --> 01:21:53,780
this is most

1187
01:21:53,780 --> 01:21:58,330
there big and using this relationship now

1188
01:21:58,340 --> 01:22:02,450
and you you see that that one is that

1189
01:22:02,600 --> 01:22:08,360
if i sum that the inequality over the left and side

1190
01:22:08,370 --> 01:22:12,830
what happens if that's if that's the right inside the political

1191
01:22:12,840 --> 01:22:15,010
and i can drop

1192
01:22:15,060 --> 01:22:19,040
the last term of the right

1193
01:22:19,360 --> 01:22:22,220
all the way so i x

1194
01:22:22,310 --> 01:22:25,190
i have this max

1195
01:22:26,200 --> 01:22:29,000
x the square

1196
01:22:29,010 --> 01:22:30,540
and i some

1197
01:22:30,550 --> 01:22:32,740
all that being on

1198
01:22:32,760 --> 01:22:35,290
w human one minus two

1199
01:22:35,300 --> 01:22:37,860
great minds w

1200
01:22:37,870 --> 01:22:40,600
b-minus you

1201
01:22:42,020 --> 01:22:47,050
so no using this telescope in the i can

1202
01:22:47,100 --> 01:22:48,630
i can get the

1203
01:22:48,660 --> 01:22:50,200
right down here

1204
01:22:50,280 --> 01:22:52,770
i get the w zero

1205
01:22:52,790 --> 01:22:54,030
nine you

1206
01:22:54,130 --> 01:22:55,250
where the

1207
01:22:55,250 --> 01:22:57,420
and the quantity

1208
01:22:57,440 --> 01:23:00,250
which is the last term here

1209
01:23:01,870 --> 01:23:04,350
that your because they

1210
01:23:04,350 --> 01:23:06,260
minus bad

1211
01:23:06,270 --> 01:23:10,390
richard can probably because i mean the thing upper bound the mind of the positive

1212
01:23:11,510 --> 01:23:15,490
then i know that is that it would be wrong

1213
01:23:15,500 --> 01:23:18,190
because this is the man

1214
01:23:18,400 --> 01:23:20,680
like or not like any more

1215
01:23:20,690 --> 01:23:24,880
because i thought out from the director

1216
01:23:24,890 --> 01:23:29,120
so now i want to get for the whole expression is an upper bound in

1217
01:23:29,120 --> 01:23:31,320
the normal way

1218
01:23:31,360 --> 01:23:33,340
well finally

1219
01:23:33,410 --> 01:23:36,660
get this going to be here

1220
01:23:37,590 --> 01:23:42,570
about the ones where is upper bounded by some quantity as

1221
01:23:42,570 --> 01:23:44,490
the process here

1222
01:23:44,530 --> 01:23:46,010
which is marked

1223
01:23:50,200 --> 01:23:51,700
and then

1224
01:23:54,930 --> 01:23:56,680
OK so all

1225
01:23:58,120 --> 01:23:59,820
is the same as the perceptron

1226
01:23:59,860 --> 01:24:02,120
it's actually a bit

1227
01:24:02,140 --> 01:24:04,760
something something stronger than percent because

1228
01:24:04,780 --> 01:24:09,360
this is the last created this because the function

1229
01:24:09,370 --> 01:24:13,390
that expressed in terms of the margins again this is the

1230
01:24:13,450 --> 01:24:14,550
the margin

1231
01:24:16,510 --> 01:24:19,240
but this is the mistake indicator function

1232
01:24:19,260 --> 01:24:24,340
and in the perceptron convergence theorem i had escorted the upper bound the number

1233
01:24:24,370 --> 01:24:26,140
but the controls

1234
01:24:26,140 --> 01:24:29,090
is the squared hinge loss is the function

1235
01:24:29,120 --> 01:24:30,570
that goes like this

1236
01:24:30,590 --> 01:24:33,570
this is the wrong

1237
01:24:33,720 --> 01:24:38,910
zero to one and then goes up but

1238
01:24:38,930 --> 01:24:42,660
the problem

1239
01:24:42,720 --> 01:24:46,640
so is an upper bound because again a convex good upper bound on the mistake

1240
01:24:46,640 --> 01:24:47,950
indicator function

1241
01:24:47,970 --> 01:24:50,640
so i'm showing that the

1242
01:24:50,660 --> 01:24:51,720
so what

1243
01:24:51,720 --> 01:24:56,890
upper bounds larger quantity than the first

1244
01:24:56,950 --> 01:24:58,300
but this is what

1245
01:24:58,320 --> 01:24:59,510
and of course

1246
01:24:59,530 --> 01:25:02,030
i can say that

1247
01:25:02,030 --> 01:25:06,800
product of the determinant is only land every square that story of the order of

1248
01:25:06,800 --> 01:25:08,640
UGV squares

1249
01:25:08,700 --> 01:25:13,200
therefore this can only happen if you have one huge and one tiny eigen values

1250
01:25:13,200 --> 01:25:15,180
so that the product comes out

1251
01:25:15,200 --> 01:25:21,540
roughly if UGV and therefore this explains to you very naturally why these masses come

1252
01:25:21,540 --> 01:25:25,130
out to be of the order of ten to the minus two electoral votes which

1253
01:25:25,130 --> 01:25:26,480
is what one

1254
01:25:26,530 --> 01:25:27,760
it is actually

1255
01:25:29,330 --> 01:25:35,640
so these are the three reasons the main reasons which make supersymmetry grand unification looks

1256
01:25:36,390 --> 01:25:41,920
this is some nice to theorists it sort of seems to have the correct scales

1257
01:25:41,920 --> 01:25:48,320
before neutrinos for unification of gauge couplings does fit very nicely in the article content

1258
01:25:48,350 --> 01:25:52,620
of the standard model and it within the sense

1259
01:25:52,670 --> 01:25:59,980
be very minor issues if there was not rules

1260
01:25:59,990 --> 01:26:04,880
now that's the nice part of the that's what is the grand unified theories what

1261
01:26:04,880 --> 01:26:11,310
is the lesson i spotted is that many of the detailed predictions depend actually on

1262
01:26:11,310 --> 01:26:17,300
the the little known details of the symmetry breaking sector or of this careless

1263
01:26:17,320 --> 01:26:25,050
what scalar field representations should we have with what potential and what yukawa couplings

1264
01:26:26,490 --> 01:26:31,330
is up for grabs you know that's very much more than independent and of course

1265
01:26:31,330 --> 01:26:36,340
you can play the game of excluding models by for instance checking that you get

1266
01:26:36,370 --> 01:26:41,250
or don't get the correct must make this is for quarks leptons or even more

1267
01:26:41,250 --> 01:26:48,040
seriously one of the canonical problems is called the core doublet triplet the doublet triplet

1268
01:26:48,050 --> 01:26:54,230
splitting in particular this means that the higgs doublet has forced alignment even if it

1269
01:26:54,230 --> 01:26:56,720
in a grand unified marketplace

1270
01:26:56,740 --> 01:27:02,510
the simplest one four five is the five collect the vector of first five

1271
01:27:02,530 --> 01:27:04,030
this has both

1272
01:27:04,050 --> 01:27:09,710
they're usually electroweak doublet and the core of triplet which you don't want actually you

1273
01:27:09,710 --> 01:27:14,550
want to really sounded very far up because it does all sorts of things including

1274
01:27:14,560 --> 01:27:20,530
mediating very rapid proton decay through these channels here proton decay on this

1275
01:27:20,810 --> 01:27:25,960
antineutrinos and this so-called doublet triplet splitting

1276
01:27:25,970 --> 01:27:30,690
problem is in your system in the specific models and you have to find human

1277
01:27:30,690 --> 01:27:33,510
and devise ways to get rid of the triplet

1278
01:27:33,520 --> 01:27:37,890
so this is in this sense the unknown sector that's where you know a lot

1279
01:27:37,890 --> 01:27:40,290
of model building fort was spent

1280
01:27:40,350 --> 01:27:44,220
in the eighties and seventies and eighties

1281
01:27:46,210 --> 01:27:52,460
to be different besides this triangle anomaly cancellation which in cases like a simultaneous

1282
01:27:52,480 --> 01:27:54,300
totally automatic actually

1283
01:27:54,330 --> 01:27:58,580
there is really no theoretical principles that guide the search

1284
01:27:58,790 --> 01:28:02,060
that's the state of affairs

1285
01:28:02,080 --> 01:28:06,600
so this is the undesirable the feature the second undesirable feature is that there is

1286
01:28:06,600 --> 01:28:12,560
this huge hierarchy of scales between the electroweak and the grand unified scale

1287
01:28:12,580 --> 01:28:17,990
this is stable to quantum corrections because of supersymmetry but it is by no means

1288
01:28:17,990 --> 01:28:20,780
explained by in theoretical

1289
01:28:20,840 --> 01:28:28,730
these are calculation and finally of course gravity is not part of the story

1290
01:28:30,130 --> 01:28:37,020
supersymmetric guts as i said capture manually non-trivial feature so far lower energy world a

1291
01:28:37,270 --> 01:28:43,470
they have also nice implications for cosmology the predict dark matter biogenesis in particular the

1292
01:28:43,480 --> 01:28:46,570
for for these reasons theorists believe it

1293
01:28:46,590 --> 01:28:52,790
that that's our best current for physics beyond the standard model

1294
01:28:52,850 --> 01:28:57,600
how has string theory changed the story well here is in a sense this small

1295
01:28:57,950 --> 01:29:03,920
checked debris and i'll try to go through the quickly now

1296
01:29:03,940 --> 01:29:04,950
the big

1297
01:29:04,960 --> 01:29:10,640
of course success and that's what motivates theories is that gravity is now family part

1298
01:29:10,660 --> 01:29:11,760
of the game

1299
01:29:11,780 --> 01:29:16,580
now if you agnostic and this could have messed things up completely you know many

1300
01:29:16,580 --> 01:29:21,860
of these features could have not worked actually they do seem to still work pretty

1301
01:29:22,890 --> 01:29:28,690
you do get correct gauge groups for grand unification you do get correct

1302
01:29:28,720 --> 01:29:34,630
representations for arxiv leptons and even moreso also to you you do get the coupling

1303
01:29:34,630 --> 01:29:38,160
unification that follows really very nicely in place

1304
01:29:38,470 --> 01:29:45,320
at least in large class of models including unification gravity so this is by all

1305
01:29:45,320 --> 01:29:49,260
means you know the most successful part of the story

1306
01:29:49,270 --> 01:29:51,160
the main ones are

1307
01:29:51,180 --> 01:29:54,050
less successful from the point of view

1308
01:29:54,080 --> 01:29:59,430
a and b but not totally desperate try out as you will see

1309
01:29:59,470 --> 01:30:05,630
for a second this string theory will have modified as i will explain the nature

1310
01:30:05,630 --> 01:30:07,610
of the gauge hierarchy problem

1311
01:30:07,640 --> 01:30:11,160
it has modified it in the sense that it is clearly now

1312
01:30:11,160 --> 01:30:15,870
the question of stability and gravitational interactions

1313
01:30:15,890 --> 01:30:20,640
this is not yet solved but at least we understand that we cannot hope to

1314
01:30:20,640 --> 01:30:24,320
solve the problem without understanding better graphics

1315
01:30:24,340 --> 01:30:27,440
and you may say this is progress even though though the problem is with that

1316
01:30:30,300 --> 01:30:33,990
string theory did changed the model building orders

1317
01:30:34,000 --> 01:30:35,450
there are

1318
01:30:35,460 --> 01:30:40,160
for instance the extra dimensions you can use extra dimensions to do some of the

1319
01:30:40,160 --> 01:30:42,780
symmetry breaking this theory

1320
01:30:42,810 --> 01:30:46,810
with new mechanisms you may say which are not field theoretic

1321
01:30:46,830 --> 01:30:53,020
not any representations are allowed and we can use these brains and the fluxes that

1322
01:30:53,190 --> 01:30:54,810
discussed yesterday

1323
01:30:54,820 --> 01:30:56,990
to do some new things

1324
01:30:57,680 --> 01:31:01,780
the model building rules have been modified by string theory

1325
01:31:01,810 --> 01:31:06,520
this helps a little bit actually even for model building for instance it's much easier

1326
01:31:06,520 --> 01:31:12,260
to solve this little nuisances like the doublet triplet splitting string theory the grand unified

1327
01:31:13,590 --> 01:31:15,510
however again to be fair

1328
01:31:15,520 --> 01:31:21,770
it doesn't really narrow down the possibilities we still have so many choices and possibilities

1329
01:31:21,850 --> 01:31:27,800
and the guiding ourselves through them need some principle is missing

1330
01:31:27,860 --> 01:31:33,170
finally how about experimental consequences well at first sight

1331
01:31:33,180 --> 01:31:34,850
those are not

1332
01:31:34,890 --> 01:31:40,380
you know at low demand i mean there are lots of them supersymmetry is one

1333
01:31:40,380 --> 01:31:41,640
proton decay

1334
01:31:41,660 --> 01:31:44,760
modifications of gravity cosmic strings

1335
01:31:44,830 --> 01:31:47,190
kind energy states

1336
01:31:47,190 --> 01:31:49,960
and much more actions and much more

1337
01:31:49,980 --> 01:31:54,560
but again the question is when will these manifest themselves at what scale we see

1338
01:31:54,560 --> 01:31:57,760
that actually and of course that's the big question

1339
01:31:57,810 --> 01:32:00,020
and the second question is

1340
01:32:00,020 --> 01:32:03,040
are any of those smoking gun

1341
01:32:03,120 --> 01:32:08,770
predictions in the sense that we couldn't get some cheap away

1342
01:32:09,060 --> 01:32:13,760
that's where these questions are by and large open as you'll see unless we have

1343
01:32:13,770 --> 01:32:19,070
so like it but that's really extremely low probability scenario as to see listings

1344
01:32:19,130 --> 01:32:23,490
in the LHC

1345
01:32:23,490 --> 01:32:29,320
OK so let's not discuss a bit more these things in a slightly more detail

1346
01:32:29,320 --> 01:32:35,880
so when one thinks about string theory unification grand unified theories come from string there

1347
01:32:35,890 --> 01:32:41,030
are two large categories of theories one this discusses those are the only ones that

1348
01:32:41,030 --> 01:32:44,120
can give weak coupling there but really

1349
01:32:45,680 --> 01:32:48,330
feel it for grand unification

1350
01:32:48,340 --> 01:32:53,950
one is the so-called heterotic string which i haven't discussed last time that was discussed

1351
01:32:53,950 --> 01:32:57,540
now and the other is the type one which is a close relative of the

1352
01:32:57,540 --> 01:33:00,760
type two strings and discussed yesterday

1353
01:33:00,800 --> 01:33:08,500
this have very different properties including for the experiment and report potential experiment manifestation so

1354
01:33:08,500 --> 01:33:11,090
let me discuss them down

1355
01:33:11,090 --> 01:33:16,940
equivalently say you can see that there is an negative value if and only the

1356
01:33:16,940 --> 01:33:21,920
determinant of the matrix in mind is that the identity zero

1357
01:33:21,940 --> 01:33:27,590
which means that a minus on that the density is not invertible

1358
01:33:33,040 --> 01:33:38,360
you say that these actions he's i vector associated to the you can value if

1359
01:33:38,890 --> 01:33:40,460
if to be

1360
01:33:42,340 --> 01:33:47,210
they are matrices of four days in which missus obviously the

1361
01:33:47,210 --> 01:33:54,190
again values the diagonal elements and it's not true for triangular matrices right

1362
01:33:55,650 --> 01:34:00,020
you is can value if and only if a is not invertible

1363
01:34:00,070 --> 01:34:06,340
and would say that a is diagonalizable if there exists a basis of a given

1364
01:34:06,360 --> 01:34:09,460
vector which can be written as

1365
01:34:09,460 --> 01:34:13,540
if you put your your i can vectors are

1366
01:34:14,730 --> 01:34:17,840
as columns of the matrix p

1367
01:34:17,860 --> 01:34:23,730
then the products p times the things he one actually actually equal to it

1368
01:34:23,750 --> 01:34:26,570
four if you could if you

1369
01:34:26,570 --> 01:34:28,920
i have this be transferred there

1370
01:34:28,940 --> 01:34:31,940
you can see that if you think it

1371
01:34:31,960 --> 01:34:35,520
six exactly p times the

1372
01:34:35,540 --> 01:34:39,800
and so if you think of a column vector of of

1373
01:34:39,820 --> 01:34:47,670
b here intensities column vector is exactly the same column vector of this matrix there

1374
01:34:47,670 --> 01:34:53,280
and as the they along this means that it then this victory excited is the

1375
01:34:53,300 --> 01:34:56,880
is exactly it's clear that is the

1376
01:34:57,300 --> 01:35:00,500
they are the term that the same effect

1377
01:35:02,480 --> 01:35:08,250
these this rating there is nothing more than saying that he

1378
01:35:09,460 --> 01:35:15,920
is the matrix of column vectors are the good effectors

1379
01:35:24,540 --> 01:35:26,230
there's no

1380
01:35:26,250 --> 01:35:30,570
there's is a special thing that happens when

1381
01:35:30,610 --> 01:35:32,800
your matrix is symmetric

1382
01:35:32,800 --> 01:35:38,050
if that if your matrix is symmetric then you're guaranteed to find an orthonormal basis

1383
01:35:38,050 --> 01:35:40,150
of eigen vectors

1384
01:35:40,170 --> 01:35:43,730
not only are you guaranteed to

1385
01:35:43,780 --> 01:35:49,340
that the matrix is they they realizable but also that you can find an orthonormal

1386
01:35:49,340 --> 01:35:53,780
basis that that is the basis of a good thing

1387
01:35:54,540 --> 01:35:57,500
this can be written as is he

1388
01:35:57,550 --> 01:36:02,170
things need to be transposed where p is a unitary matrix

1389
01:36:03,770 --> 01:36:05,070
in addition

1390
01:36:05,070 --> 01:36:09,610
with say that this matrix made a symmetric matrix

1391
01:36:09,670 --> 01:36:16,800
is semi definite positive if the dot product between x and x is always positive

1392
01:36:16,800 --> 01:36:18,570
for any vector

1393
01:36:20,020 --> 01:36:26,320
then you can values of the matrix a of positive and that would be true

1394
01:36:26,320 --> 01:36:34,820
four sorry for any diagonal matrix for which the diagonal elements are

1395
01:36:36,050 --> 01:36:43,750
negative and for any matrix that can be written as the b for matrix

1396
01:36:44,690 --> 01:36:49,670
and the matrix is said to be definite positive if this care for x is

1397
01:36:49,670 --> 01:36:53,690
zero only if x is itself is zero

1398
01:36:53,710 --> 01:36:57,340
then it means that

1399
01:36:57,340 --> 01:36:59,540
that is

1400
01:36:59,590 --> 01:37:01,980
this implies that has

1401
01:37:01,980 --> 01:37:04,480
only strictly positive

1402
01:37:04,960 --> 01:37:10,800
i guess values again the diagonal matrix with positive entries along with you

1403
01:37:10,820 --> 01:37:14,610
then is different positive and if

1404
01:37:15,960 --> 01:37:19,840
if it can be read as opposed to be transposed b

1405
01:37:19,840 --> 01:37:21,570
and is invertible

1406
01:37:21,570 --> 01:37:24,980
then it's definitely positive

1407
01:37:25,020 --> 01:37:27,380
those images are important

1408
01:37:27,400 --> 01:37:34,900
first of all because you can there is diagonalized them on

1409
01:37:35,050 --> 01:37:40,380
orthonormal basis and if in addition there are different inputs and then you can verify

1410
01:37:41,710 --> 01:37:43,520
this form ax

1411
01:37:43,520 --> 01:37:48,690
here the dot product if you use the usual dot products on x

1412
01:37:48,690 --> 01:37:54,750
and if x then it's defining a new that products which i i was users

1413
01:37:54,750 --> 01:37:57,590
who is an index a and

1414
01:37:57,630 --> 01:38:02,630
this form here is new know the product it gives you a new norm on

1415
01:38:03,820 --> 01:38:04,590
and so

1416
01:38:04,610 --> 01:38:07,860
you can think of everything

1417
01:38:07,900 --> 01:38:09,610
as you're just

1418
01:38:09,630 --> 01:38:13,090
you can think of your vector space

1419
01:38:13,360 --> 01:38:21,150
it recently this new non there

1420
01:38:21,170 --> 01:38:22,400
thank you

1421
01:38:22,460 --> 01:38:31,980
now if you don't have same matrix and a symmetric matrix

1422
01:38:32,000 --> 01:38:35,130
it may not be diagonalizable

1423
01:38:35,150 --> 01:38:40,400
it may also be that you matrix is not even square

1424
01:38:40,420 --> 01:38:45,230
but using the

1425
01:38:45,250 --> 01:38:48,250
using for example so

1426
01:38:48,270 --> 01:38:54,340
so let's see bees and and by matrix using for example the transpose be all

1427
01:38:54,340 --> 01:39:01,840
these things be transposed which we've seen are symmetric semi the semidefinite matrices then you

1428
01:39:01,840 --> 01:39:08,480
can find an interesting decomposition of b which is the singular value decomposition

1429
01:39:08,480 --> 01:39:12,030
different ontologies you know if the document is a

1430
01:39:12,040 --> 01:39:17,000
two classes tend to annotate the same set of documents that the probably related to

1431
01:39:17,000 --> 01:39:19,820
these types of techniques had some success

1432
01:39:20,720 --> 01:39:25,790
so for the external sources their approaches for example that

1433
01:39:25,810 --> 01:39:29,830
try to use other ontologies on the web to create the corresponding to that of

1434
01:39:29,830 --> 01:39:34,180
course the lexicon and desire is always very rich source of information so you know

1435
01:39:34,180 --> 01:39:40,090
if one uses ontologies car other the users automobile and have lexicon that says that

1436
01:39:40,090 --> 01:39:41,680
those two are synonyms

1437
01:39:41,690 --> 01:39:46,400
that's all this very good three so these types of resources usually help in finding

1438
01:39:46,400 --> 01:39:47,850
the correspondences

1439
01:39:48,030 --> 01:39:51,730
and then sort of any other form of background knowledge and in fact i think

1440
01:39:51,730 --> 01:39:52,190
one of the

1441
01:39:52,620 --> 01:39:53,580
as is

1442
01:39:53,600 --> 01:39:54,420
you see

1443
01:39:54,430 --> 01:39:55,810
the look at the

1444
01:39:55,870 --> 01:40:00,830
approaches to ontology matching over the years these use external resources one of the things

1445
01:40:00,830 --> 01:40:02,670
that has really grown

1446
01:40:02,710 --> 01:40:04,960
quite a bit in the last few years

1447
01:40:04,970 --> 01:40:06,970
and now

1448
01:40:06,980 --> 01:40:07,860
during the

1449
01:40:07,910 --> 01:40:10,210
and six

1450
01:40:10,230 --> 01:40:16,390
OK all this techniques so what we call basic techniques OK because their daily acts

1451
01:40:16,390 --> 01:40:22,340
on a specific part of the ontology but not generally on the ontology that's all

1452
01:40:22,400 --> 01:40:26,340
any matching system which can seriously compete

1453
01:40:27,530 --> 01:40:31,820
you use several of these techniques OK and they can

1454
01:40:31,830 --> 01:40:34,450
do this in in the in the following way

1455
01:40:35,790 --> 01:40:40,070
the basic idea is that they will use one method for example name matching

1456
01:40:40,120 --> 01:40:43,570
and they were use in parallel another one

1457
01:40:44,370 --> 01:40:48,390
i don't know maybe they will match the properties based on their domain and then

1458
01:40:48,440 --> 01:40:53,800
will match again the classes being done based on their name on their domain OK

1459
01:40:53,800 --> 01:40:57,690
so it means that you can use this method independently

1460
01:40:57,720 --> 01:41:00,570
and then of course when you want to match the entities that you find in

1461
01:41:00,570 --> 01:41:06,310
an ontology you will have to aggregate the results of all of these techniques

1462
01:41:06,320 --> 01:41:12,390
and after the aggregation usually what you want to do is to filter in values

1463
01:41:12,390 --> 01:41:17,780
with the result that you have because there are some matching matches which are not

1464
01:41:17,780 --> 01:41:23,560
really likely OK so basically you apply some threshold on of or some functions in

1465
01:41:23,560 --> 01:41:29,710
order to select what is really important in the result that you have obtained and

1466
01:41:29,710 --> 01:41:36,710
and and then basically what you've got after filtering is rather similarity and assessment of

1467
01:41:36,710 --> 01:41:42,920
the commonality between the entities and then you will use the method for extracting the

1468
01:41:42,920 --> 01:41:48,940
alignment from this kind of similarity and of course i guess OK it's it's not

1469
01:41:48,940 --> 01:41:52,840
here but in fact what you can do once you've got this is to input

1470
01:41:52,840 --> 01:41:59,600
this again and OK we'll talk look very soon about the evaluation of matter that

1471
01:41:59,600 --> 01:42:03,790
we do and so this year there are several matcher that really do that is

1472
01:42:03,790 --> 01:42:08,730
that the output and the input it again in the pipe and they iterate until

1473
01:42:08,950 --> 01:42:12,460
was established to something which is satisfying

1474
01:42:12,480 --> 01:42:16,200
so if i if i can summarize

1475
01:42:16,210 --> 01:42:20,950
of course you will use several basic matters and you can use them

1476
01:42:21,190 --> 01:42:24,760
in sequence so you will compose them and pass the result of one match to

1477
01:42:24,760 --> 01:42:28,670
the as the input of another one expects from or you can use them in

1478
01:42:30,230 --> 01:42:36,460
and then you will have the problem of aggregating the results and you can aggregate

1479
01:42:36,460 --> 01:42:40,950
them because these are matcher that considering different things

1480
01:42:41,050 --> 01:42:45,970
OK so basically you will add the evidence of each match if a matter of

1481
01:42:45,970 --> 01:42:49,280
phone based on name that this things are the same then you will keep this

1482
01:42:49,280 --> 01:42:55,400
result and if another form that some other entities are the same based on the

1483
01:42:55,400 --> 01:42:59,180
structure of the ontology for example you would keep this as well and but you

1484
01:42:59,180 --> 01:43:05,190
also can create competing matcher so basically you will take the average of all the

1485
01:43:05,190 --> 01:43:10,450
mean of the average of the results that have been given by order the matter

1486
01:43:10,460 --> 01:43:15,700
so there are plenty of techniques for doing the aggregation and depending on the kind

1487
01:43:15,700 --> 01:43:20,950
of matching is this kind of not to know which one to use

1488
01:43:20,960 --> 01:43:21,650
this is

1489
01:43:21,650 --> 01:43:26,390
kind of the same thing for the filtering result usually people use threshold but it

1490
01:43:26,390 --> 01:43:27,630
is very difficult to

1491
01:43:27,630 --> 01:43:30,610
OK so i'm told that

1492
01:43:30,630 --> 01:43:33,700
in this sort of environment people don't have enough questions but again i'd encourage you

1493
01:43:33,700 --> 01:43:36,650
to anyway if you're feeling brave

1494
01:43:36,670 --> 01:43:41,990
there's going to be in a much longer break and another time

1495
01:43:42,010 --> 01:43:43,450
so the end of the

1496
01:43:43,470 --> 01:43:46,860
the first hour i left you with this question

1497
01:43:46,900 --> 01:43:49,610
there are many possible things we could do we could pick up all sorts of

1498
01:43:49,610 --> 01:43:52,610
algorithms and we can sit down and we came up with to try them out

1499
01:43:52,610 --> 01:43:55,560
i encourage you to do that

1500
01:43:55,590 --> 01:44:00,160
but we'd really like seven guiding principles that tell us what we're doing

1501
01:44:02,620 --> 01:44:03,300
there were

1502
01:44:03,350 --> 01:44:06,760
there are various levels so that the first of which is

1503
01:44:06,780 --> 01:44:08,720
but if you're writing an algorithm

1504
01:44:08,760 --> 01:44:10,460
it in many

1505
01:44:10,470 --> 01:44:12,830
in the broad variety of circumstances

1506
01:44:12,830 --> 01:44:17,110
it's a good idea to ask what is my algorithm trying to achieve and to

1507
01:44:17,110 --> 01:44:21,860
do that formerly it's often good to identify what's called an objective function so rather

1508
01:44:21,860 --> 01:44:25,730
than just running it something of that looks good is good if it can spit

1509
01:44:25,730 --> 01:44:27,220
out and number

1510
01:44:27,260 --> 01:44:31,710
saying what goodness is this had this output to goodness of six point three

1511
01:44:32,550 --> 01:44:37,580
so i like to say that you should be optimizing an objective by your when

1512
01:44:37,580 --> 01:44:40,460
you run an algorithm you're trying to improve some objective function

1513
01:44:40,680 --> 01:44:42,490
other people are much less

1514
01:44:42,850 --> 01:44:47,350
optimistic and they say i'm going to minimize the cost function in know exactly the

1515
01:44:47,350 --> 01:44:50,410
same thing is just a minus sign in front

1516
01:44:50,410 --> 01:44:56,850
and as soon as you do that my things happened saying

1517
01:44:56,850 --> 01:45:01,360
if you have an iterative algorithm like the perceptron algorithm i shady which is moving

1518
01:45:01,360 --> 01:45:02,880
the weight vector around

1519
01:45:04,040 --> 01:45:07,190
if you have an objective function you can ask the question

1520
01:45:07,250 --> 01:45:10,690
is my objective improving at every step of my algorithm

1521
01:45:10,770 --> 01:45:16,540
so if you can prove that an algorithm is monotonically improving an objective function

1522
01:45:16,580 --> 01:45:20,490
then you have already prove something about the convergence of the algorithm

1523
01:45:20,680 --> 01:45:25,190
so an algorithm that can make your objective works as well as better

1524
01:45:25,290 --> 01:45:29,720
could potentially form loops it could cycle through the same set of weight vectors circuits

1525
01:45:29,720 --> 01:45:30,160
say a

1526
01:45:30,270 --> 01:45:33,440
i'm going to let you like this now against the like this now i'm going

1527
01:45:33,440 --> 01:45:36,380
to play like this again and it could just oscillate back and forth

1528
01:45:36,390 --> 01:45:40,620
if you've identified an objective function and can show that your algorithm never make that

1529
01:45:40,620 --> 01:45:45,750
objective worse than immediately proved that that sort of loop can never happen so that's

1530
01:45:45,750 --> 01:45:46,920
a good thing to do

1531
01:45:47,030 --> 01:45:49,870
if you've got

1532
01:45:49,880 --> 01:45:54,120
and objective that you can attach a number two you could maybe ask the question

1533
01:45:54,920 --> 01:45:59,670
is one algorithm better fitting that objective than another maybe one is able to get

1534
01:45:59,670 --> 01:46:03,630
the same objective faster maybe one is able to get better value of the objective

1535
01:46:03,820 --> 01:46:07,030
but unless you've got some quantitative score

1536
01:46:07,040 --> 01:46:11,570
and you in mind then there's no way that you can compare different sorts alternative

1537
01:46:14,510 --> 01:46:19,290
before we do anything we should really be thinking about what this objective function might

1538
01:46:19,290 --> 01:46:22,630
be how we can come up with the real number that says how well we're

1539
01:46:22,630 --> 01:46:24,810
doing if we're

1540
01:46:24,820 --> 01:46:27,340
ten one of these little machine learning tasks

1541
01:46:28,600 --> 01:46:30,070
there's an one answer

1542
01:46:30,070 --> 01:46:31,510
but here it is

1543
01:46:31,530 --> 01:46:32,980
a very common

1544
01:46:33,000 --> 01:46:35,410
so the way forward

1545
01:46:35,420 --> 01:46:38,170
what we do is we identify what's called the loss function

1546
01:46:38,340 --> 01:46:42,030
and the loss function takes two arguments it takes

1547
01:46:42,600 --> 01:46:45,750
true output in the problem so this is

1548
01:46:45,790 --> 01:46:49,980
this item in my training set actually is an orange

1549
01:46:50,000 --> 01:46:55,790
and it takes another argument which is what you're learning algorithm to predict so this

1550
01:46:57,190 --> 01:47:00,350
i'm going to predict the suleman given

1551
01:47:00,370 --> 01:47:03,970
and then this loss function says how bad is it that you said it was

1552
01:47:03,970 --> 01:47:06,340
eleven when actually it was an orange like

1553
01:47:06,350 --> 01:47:09,850
how much is the person you're writing assistant going to charge you for making that

1554
01:47:10,850 --> 01:47:15,470
so maybe the loss would be zero if these two arguments matched and it would

1555
01:47:16,130 --> 01:47:20,820
some positive about from mismatch that's sort of the common thing you could do that

1556
01:47:20,880 --> 01:47:22,280
the different problems

1557
01:47:22,320 --> 01:47:27,780
this function will take on different values for maybe if for regression problem we want

1558
01:47:27,780 --> 01:47:31,380
to have the square of the difference between the two

1559
01:47:31,390 --> 01:47:32,660
the two items

1560
01:47:32,660 --> 01:47:36,850
the whole lot of things that you could put in here and we're going to

1561
01:47:36,850 --> 01:47:37,940
talk about that

1562
01:47:37,950 --> 01:47:39,780
more because it's an important issue

1563
01:47:39,820 --> 01:47:43,120
but once we come up with this loss function l

1564
01:47:45,070 --> 01:47:49,270
we can say well what our objective really what our objective is

1565
01:47:49,320 --> 01:47:52,870
is that when it comes to test time when we deploy system and it sees

1566
01:47:52,880 --> 01:47:56,990
new input to stop spitting out out for them

1567
01:47:57,000 --> 01:47:59,420
we don't want to suffer too much loss

1568
01:47:59,440 --> 01:48:01,110
so a

1569
01:48:01,130 --> 01:48:05,120
in the ideal case we would like to come up with our group test time

1570
01:48:05,130 --> 01:48:06,890
on going to do too badly

1571
01:48:06,960 --> 01:48:10,840
and it's very hard to prove about an algorithm

1572
01:48:10,900 --> 01:48:14,300
what is the value of that loss will be

1573
01:48:14,310 --> 01:48:18,080
because we don't know what's going to happen in the future after all we have

1574
01:48:18,080 --> 01:48:23,190
in our hands on training set of examples that we've been given and so may

1575
01:48:23,190 --> 01:48:27,780
be pragmatic thing to do this before we think of anything else is

1576
01:48:27,820 --> 01:48:31,830
that we do what's called minimizing the empirical loss so

1577
01:48:31,840 --> 01:48:33,330
we look at what

1578
01:48:33,340 --> 01:48:38,570
our learning algorithm we do on the training set that we've got at hand and

1579
01:48:38,570 --> 01:48:41,440
we say well what's the total loss that we

1580
01:48:41,710 --> 01:48:46,380
on the training set and that's now a score that we could use

1581
01:48:47,550 --> 01:48:50,270
the least squares algorithm

1582
01:48:51,530 --> 01:48:54,060
find the best possible

1583
01:48:54,320 --> 01:49:00,390
empirical loss it minimizes squared error on the training set and the learning algorithm with

1584
01:49:01,150 --> 01:49:05,390
one line of k but you could imagine iterative algorithms that sort of move weight

1585
01:49:05,390 --> 01:49:07,900
vectors around trying to improve squared error

1586
01:49:08,760 --> 01:49:11,370
they are never going to do better than this one line of code the hot

1587
01:49:11,430 --> 01:49:16,880
right to the best possible expected squared loss so that objective function we know what

1588
01:49:16,880 --> 01:49:22,590
the best algorithm is it's use the numerical library that does this particular thing for

1589
01:49:28,950 --> 01:49:33,070
but depending on the application we can have different loss functions so

1590
01:49:33,450 --> 01:49:37,990
the classification we might have what's called the zero one loss so that was one

1591
01:49:37,990 --> 01:49:42,150
where we don't experience any loss if we got the right answer we experience the

1592
01:49:42,150 --> 01:49:43,130
loss of one

1593
01:49:43,180 --> 01:49:45,030
if we get the wrong answer and that's

1594
01:49:45,030 --> 01:49:49,060
we are

1595
01:50:03,930 --> 01:50:12,180
that year

1596
01:50:17,080 --> 01:50:21,900
it was great

1597
01:50:27,570 --> 01:50:29,360
it is

1598
01:50:46,510 --> 01:50:47,620
and so

1599
01:50:49,820 --> 01:50:51,150
try to wrap up they

1600
01:50:51,180 --> 01:50:56,170
cross validation situation so this is this is expression that we have in the last

1601
01:50:56,170 --> 01:51:02,510
slide where we get and cross validated estimate of risk that's that's what this notation

1602
01:51:02,510 --> 01:51:05,670
means and and

1603
01:51:05,720 --> 01:51:10,640
that is a function of the regularisation parameter

1604
01:51:10,650 --> 01:51:11,450
and so

1605
01:51:12,370 --> 01:51:17,510
we also had this this slide this picture a few slides back where

1606
01:51:18,250 --> 01:51:22,340
the value of the relaxation parameter and the actual treaty

1607
01:51:22,360 --> 01:51:24,870
that is optimal for that particular about it

1608
01:51:24,870 --> 01:51:26,250
precision parameter

1609
01:51:26,260 --> 01:51:30,590
go to like that and so if

1610
01:51:30,610 --> 01:51:32,140
what you end up doing this is

1611
01:51:32,540 --> 01:51:36,260
o what you end up getting is getting a picture like this this by the

1612
01:51:38,420 --> 01:51:43,010
what you get in our if you use are part which is there our implementation

1613
01:51:43,010 --> 01:51:44,010
of CART

1614
01:51:44,010 --> 01:51:50,520
and so at the top you have the tree size and and this made of

1615
01:51:50,520 --> 01:51:52,690
risk and again

1616
01:51:52,700 --> 01:51:56,110
i tried to emphasise here how the three size which is

1617
01:51:56,160 --> 01:52:02,410
they indicator here for complexity go hand in hand with the value of the relaxation

1618
01:52:02,420 --> 01:52:06,940
parameter and not since since we're doing

1619
01:52:06,950 --> 01:52:09,760
this and the idea we can also compute

1620
01:52:09,760 --> 01:52:15,110
it's standard errors for that you know the cross validation and that that's what is

1621
01:52:15,110 --> 01:52:19,050
illustrated here with the with the vertical bars

1622
01:52:19,080 --> 01:52:20,360
and so on

1623
01:52:21,230 --> 01:52:23,710
you can either find a minimum

1624
01:52:23,730 --> 01:52:28,410
in this plot remember we're trying to find the have for that

1625
01:52:28,440 --> 01:52:32,760
generates three there has the smallest prediction

1626
01:52:33,790 --> 01:52:40,570
and sometimes what you do is is you're you follow what called a one is

1627
01:52:40,570 --> 01:52:44,760
he rule one is found that oral where you find the minimum of the plot

1628
01:52:44,860 --> 01:52:50,080
here then you go up one standard error in the dual f until you cross

1629
01:52:50,080 --> 01:52:55,860
the picture again and that is statistically you cannot differentiate between those two points so

1630
01:52:55,860 --> 01:53:05,550
you take the more conservative answer which would be the smaller of of those trees

1631
01:53:08,570 --> 01:53:10,670
they they

1632
01:53:10,690 --> 01:53:16,070
as i mentioned earlier when we're doing cross validation we're taking an average of measures

1633
01:53:16,070 --> 01:53:21,360
of fit and so the first idea generalisation is well can can we

1634
01:53:22,380 --> 01:53:27,920
fitted value as opposed to measures of and and can these in which is what

1635
01:53:27,920 --> 01:53:32,890
we doing and symbols and candice have average compensate for their for

1636
01:53:33,540 --> 01:53:37,740
overly optimistic trees

1637
01:53:37,760 --> 01:53:43,440
so i guess i'm suggesting that the seeds of n symbols where there early on

1638
01:53:43,450 --> 01:53:51,450
in cross validation and cost complexity pruning of trees

1639
01:53:51,450 --> 01:53:52,920
OK so now

1640
01:53:54,460 --> 01:53:59,910
continent get model selection but we switch to two regularizations

1641
01:53:59,940 --> 01:54:03,530
yes rank and specifically the lasso

1642
01:54:03,560 --> 01:54:04,650
and so

1643
01:54:04,660 --> 01:54:09,380
this situation here setting here is a linear motor

1644
01:54:09,390 --> 01:54:15,780
this is straightforward in water and in the standard linear regression coefficient estimate of estimation

1645
01:54:15,780 --> 01:54:20,710
problem is this data like this we are trying to find the values of the

1646
01:54:20,710 --> 01:54:21,960
coefficients is j

1647
01:54:22,500 --> 01:54:27,890
that minimizes the risk and the reason is estimated by by the addition of the

1648
01:54:34,780 --> 01:54:39,850
a couple of reasons why one is often not satisfied with the ordinary linear regression

1649
01:54:42,060 --> 01:54:45,950
one of his body and so off and that is high variance in the coefficient

1650
01:54:45,950 --> 01:54:50,260
estimates and the other one is interpretation when went to as the number of articles

1651
01:54:51,070 --> 01:54:56,510
we would like if possible to get a subset of the variables that capture the

1652
01:54:56,510 --> 01:54:59,520
stronger effect and so on

1653
01:54:59,530 --> 01:55:01,140
there are

1654
01:55:01,140 --> 01:55:02,340
generally two

1655
01:55:02,370 --> 01:55:04,870
types of techniques to

1656
01:55:04,890 --> 01:55:06,210
deal with

1657
01:55:06,240 --> 01:55:08,550
one is a subset regulation

1658
01:55:08,940 --> 01:55:14,970
which is a discrete pulses so it itself can have integrity

1659
01:55:15,010 --> 01:55:21,260
like the tree growing algorithm integrity discrete processes that often times you

1660
01:55:22,320 --> 01:55:27,020
a sample of the data and you get different subset

1661
01:55:27,070 --> 01:55:31,740
on the other side we have some linkage techniques

1662
01:55:33,570 --> 01:55:37,300
which we can think of them as a second ten years

1663
01:55:37,340 --> 01:55:45,710
process and they darius version of that is reach regulation and so like in trees

1664
01:55:45,710 --> 01:55:49,130
their waste linkage work is that it adds

1665
01:55:49,140 --> 01:55:50,660
a penalty term

1666
01:55:50,690 --> 01:55:52,950
two there cost function

1667
01:55:52,960 --> 01:55:57,260
exactly or very analogous to what we doing in trees now

1668
01:55:57,280 --> 01:56:02,050
this penalty term can take different forms if we are adding

1669
01:56:02,060 --> 01:56:06,370
this squares of the coefficients that's what is called reach regulations

1670
01:56:07,400 --> 01:56:12,970
when we are adding the absolute values of the coefficients it what called the lasso

1671
01:56:13,050 --> 01:56:18,650
and you can think of having here as in or so so if we have

1672
01:56:18,650 --> 01:56:23,000
this enormous just counting the number of coefficients that

1673
01:56:23,050 --> 01:56:29,500
and then it's identical to what we doing with three where the penalty term was

1674
01:56:29,500 --> 01:56:33,560
counted the number of the size of the tree so we have here this see

1675
01:56:33,620 --> 01:56:36,930
don't know it's similar to that now

1676
01:56:39,370 --> 01:56:41,700
they in

1677
01:56:41,710 --> 01:56:45,600
as as we mentioned in the case of trees so by the way this is

1678
01:56:45,600 --> 01:56:47,820
where the lasso name comes from

1679
01:56:47,830 --> 01:56:50,100
because the idea is that you have this

1680
01:56:50,120 --> 01:56:56,320
additional force that is trying to bring new coefficients stores area right so they don't

1681
01:56:56,320 --> 01:56:58,440
go y and

1682
01:56:58,450 --> 01:56:59,450
and so

1683
01:56:59,450 --> 01:57:02,520
as in the case of the trees the penalty term

1684
01:57:02,530 --> 01:57:06,550
pro i tell deterministic it doesn't depend on the data that's what i mean by

1685
01:57:07,240 --> 01:57:10,160
it deterministic value

1686
01:57:10,570 --> 01:57:14,210
so it's a counteracting force

1687
01:57:18,320 --> 01:57:22,550
i forgot whether it in the introduction we we mention what they

1688
01:57:22,650 --> 01:57:24,520
lasso is two to four

1689
01:57:24,550 --> 01:57:28,660
so it's least absolute and now we know it comes from the because we the

1690
01:57:28,700 --> 01:57:34,430
absolute and then the next to us is strain gauge and selection operator

1691
01:57:34,450 --> 01:57:37,490
and i want to emphasise the second a selection

1692
01:57:37,490 --> 01:57:41,460
we can elicit startled looks very much like star level at the start of a

1693
01:57:41,460 --> 01:57:44,400
forty years i really can't tell the difference when we're listening

1694
01:57:44,650 --> 01:57:49,530
it even lists the reflex which was the put back so we can stimulate the

1695
01:57:49,530 --> 01:57:54,500
cochlear neurons in the connection between the character neurons in this middle snaps

1696
01:57:54,520 --> 01:57:58,790
and let's assume that when the light comes on the compared with the shock but

1697
01:57:58,790 --> 01:58:02,750
in one way other modulates transmission in this middle snaps

1698
01:58:02,760 --> 01:58:07,840
if we were to elicit start electrically here or here that is after that are

1699
01:58:07,840 --> 01:58:14,210
upstream from that point of modulation then start always electrically should be potentiated

1700
01:58:14,250 --> 01:58:19,830
on the other hand if another animal we implant electrodes down here

1701
01:58:19,870 --> 01:58:24,940
that is beyond the point where i'm assuming the modulation occurs with illicit startled but

1702
01:58:24,940 --> 01:58:27,300
it wouldn't be affected by the light

1703
01:58:27,360 --> 01:58:31,090
so that was the logic in exactly that's exactly what we found when we elicited

1704
01:58:31,100 --> 01:58:36,920
startle electrically here or here we can get potentiation about the list electrically listeners are

1705
01:58:36,940 --> 01:58:44,270
acoustically elicited but when we listed here we get potentiation of acoustically but not electrically

1706
01:58:44,290 --> 01:58:48,860
so we conclude then that the light in one way or the other efforts compare

1707
01:58:48,860 --> 01:58:55,070
the shop eventually modulates transmission at that point the pathway and then at that time

1708
01:58:55,070 --> 01:59:00,880
there are these wonderful new traces was called horseradish peroxidase that just come by hand

1709
01:59:00,880 --> 01:59:04,330
skype or i think he was one of the first people to do that and

1710
01:59:04,340 --> 01:59:08,590
we thought well this is a really neat technique is what it does is it

1711
01:59:08,730 --> 01:59:13,450
feels axons that project to a particular part of the brain and then it's a

1712
01:59:13,450 --> 01:59:18,730
protein goes backwards through jackson to end up in cell bodies so you can say

1713
01:59:18,730 --> 01:59:22,240
so we're interested in this part of the brain we can ask the question what

1714
01:59:22,250 --> 01:59:25,900
are the parts of the brain project to this area of the brain so what

1715
01:59:25,900 --> 01:59:30,120
we did is we infused a this horseradish peroxidase

1716
01:59:30,160 --> 01:59:33,750
and what we found is that they were a nice group of cells

1717
01:59:33,800 --> 01:59:38,050
in the central nucleus of the amygdala so that was a really nice day in

1718
01:59:38,050 --> 01:59:44,100
the laboratory because bruce capital been doing some very important studies showing that the amygdala

1719
01:59:44,100 --> 01:59:49,980
was critical for fear conditioning his case heart-rate conditioning using rabbits in joel do is

1720
01:59:49,980 --> 01:59:54,730
just preserve beginning to do his work which were seeing the posters he had published

1721
01:59:54,730 --> 01:59:59,610
anything so that's one of those really exciting days because you say well the central

1722
01:59:59,610 --> 02:00:03,490
nucleus which we know is involved in fear has a direct projections to the part

1723
02:00:03,490 --> 02:00:09,610
of the start of pathway that we've figured out that the light ultimately alters transmission

1724
02:00:09,620 --> 02:00:13,700
and sure enough when we took out the amygdala with the lesion or we put

1725
02:00:13,700 --> 02:00:18,020
drugs in that inactivated it did the same thing it didn't do anything to the

1726
02:00:18,020 --> 02:00:24,600
startle reflex but selectively decrease the feet and hands component and over the years we've

1727
02:00:24,600 --> 02:00:28,390
worked out a great deal of the circuitry here this is the start of pathway

1728
02:00:28,390 --> 02:00:33,030
over here this is the direct pathway from the amygdala there's an indirect pathway that

1729
02:00:33,030 --> 02:00:38,770
was first implicated by ed moloney now at harvard and there's another pathway from another

1730
02:00:38,770 --> 02:00:41,990
part of the amygdala they all converge at this part of the pond in particular

1731
02:00:42,000 --> 02:00:48,080
formation and we how the visual information and the shock information get into the amygdala

1732
02:00:48,080 --> 02:00:53,280
they converge there and with this convergence in the nervous system there is opportunity for

1733
02:00:54,410 --> 02:00:59,220
and we show that a particular receptor the talk about no while the NMDA receptor

1734
02:00:59,220 --> 02:01:02,920
in the middle the goal was critical for fear learning so if you block the

1735
02:01:02,940 --> 02:01:08,260
receptor the animal didn't want the association between the light and the shock

1736
02:01:10,140 --> 02:01:14,370
and now many labs joel do my fans slower air kendell

1737
02:01:14,870 --> 02:01:20,600
a whole number of labs are now looking at the cellular events that turning and

1738
02:01:20,600 --> 02:01:23,110
different genes in the amygdala two

1739
02:01:23,200 --> 02:01:27,150
account for fear conditioning

1740
02:01:27,460 --> 02:01:33,550
well that's a very detailed look at the much larger an important conclusion and that

1741
02:01:33,550 --> 02:01:38,810
is outputs from the central nucleus of the amygdala go to variety of target areas

1742
02:01:38,810 --> 02:01:41,440
in the hypothalamus and brainstem

1743
02:01:41,450 --> 02:01:46,560
and those areas are involved in the specific signs and symptoms of fear and anxiety

1744
02:01:46,930 --> 02:01:52,410
so the outputs the lateral hypothalamus that's involved in sympathetic activation during the state fair

1745
02:01:52,420 --> 02:01:57,550
that's because when you get your blood pressure up you sweat because there's sympathetic activation

1746
02:01:57,550 --> 02:02:01,070
shaken marry anybody was acceptable

1747
02:02:01,270 --> 02:02:03,790
and then I look at the smaller

1748
02:02:03,800 --> 02:02:07,630
the remaining n minus 1 problem and what's happening there

1749
02:02:08,690 --> 02:02:13,310
now every set of those girls well among used up 1 boys

1750
02:02:13,320 --> 02:02:17,720
and I I said in this case that I had room to maneuver so it's

1751
02:02:18,580 --> 02:02:24,240
I'm OK they are with that that's the easy 1

1752
02:02:24,280 --> 02:02:31,260
then the harder cases when the sunset and given this proof without writing here those

1753
02:02:31,290 --> 02:02:39,470
right that case 1 which I just dealt with was of k less than that

1754
02:02:39,830 --> 02:02:41,210
the every

1755
02:02:42,150 --> 02:02:45,470
subset has

1756
02:02:45,650 --> 02:02:48,090
subset and so on

1757
02:02:48,130 --> 02:02:51,300
have more and more room to maneuver

1758
02:02:53,250 --> 02:03:00,410
an extra 1 or more is is OK and then we can make an assignment

1759
02:03:00,410 --> 02:03:04,930
get to a smaller problem where OK now there's a harder cases some

1760
02:03:06,030 --> 02:03:07,470
sense of

1761
02:03:08,420 --> 02:03:10,210
the girls

1762
02:03:11,290 --> 02:03:14,130
some for some k less than

1763
02:03:14,190 --> 02:03:23,950
likes only on board only exactly and boys OK idea without paying for

1764
02:03:24,430 --> 02:03:26,250
deal with that case

1765
02:03:29,110 --> 02:03:35,250
and and still also uh the appeared on doing so I'm assuming is true so

1766
02:03:35,250 --> 02:03:41,010
all said it is none of the tetragonal signals and all sets like enough

1767
02:03:41,750 --> 02:03:46,670
and some pretty subset likes just barely enough

1768
02:03:48,740 --> 02:03:53,060
OK with the claim is that those k girls I can't match them to those

1769
02:03:53,060 --> 02:03:54,670
keyboards which I better do

1770
02:03:55,050 --> 02:03:57,250
now why am I able to do that

1771
02:03:58,590 --> 02:04:00,330
that's the induction step

1772
02:04:00,610 --> 02:04:03,670
that this is a smaller than group

1773
02:04:04,330 --> 02:04:05,760
and it's

1774
02:04:05,970 --> 02:04:09,000
hypothesis is satisfied so

1775
02:04:11,050 --> 02:04:17,040
so it's a smaller problem and I'm assuming that I've sold all smaller problems now

1776
02:04:17,040 --> 02:04:21,260
coming in the case of n boys and girls

1777
02:04:21,830 --> 02:04:28,390
OK so so a match them off

1778
02:04:30,210 --> 02:04:37,570
this was a smaller problem so already present themselves and now I have to

1779
02:04:38,310 --> 02:04:42,230
what I have to do now I to get the rest the other n minus

1780
02:04:42,230 --> 02:04:46,050
k other and minus came out deal with it

1781
02:04:48,530 --> 02:04:50,970
well I guess

1782
02:04:50,980 --> 02:04:53,920
I want use that as a smaller problem to

1783
02:04:55,950 --> 02:04:59,690
but I then I would have to check that this condition

1784
02:05:00,430 --> 02:05:03,130
but came the boys are now used

1785
02:05:03,790 --> 02:05:07,500
so I have to check the other n minus k i have to check that

1786
02:05:07,670 --> 02:05:15,350
this condition cannot colonists halls condition was that a guy named Paul also conditions

1787
02:05:15,370 --> 02:05:18,260
I have to check check

1788
02:05:18,560 --> 02:05:28,570
all aligned there these remaining on these on the on the unmarried 1

1789
02:05:29,410 --> 02:05:31,070
it is

1790
02:05:32,230 --> 02:05:37,750
let's see story

1791
02:05:38,490 --> 02:05:41,990
so much

1792
02:05:44,610 --> 02:05:46,170
for these other guys

1793
02:05:46,310 --> 02:05:53,470
let's see the thing is we all we can't match them off with boys that

1794
02:05:53,470 --> 02:05:58,150
were used by the 1st k so we have to be done sure

1795
02:05:58,370 --> 02:06:17,870
that these remaining girls like little boys and yet they're the picture yes I mean

1796
02:06:18,050 --> 02:06:21,220
but do I know that how do I know

1797
02:06:21,290 --> 02:06:24,490
that those remaining girls

1798
02:06:25,340 --> 02:06:28,630
the case

1799
02:06:29,350 --> 02:06:33,330
can I can't continue but I have to check that I have that somehow from

1800
02:06:33,330 --> 02:06:40,830
the original from knowing the original big set a and if she went anywhere what

1801
02:06:40,830 --> 02:06:46,630
I have to worry about is paid maybe some of these remaining only like those

1802
02:06:46,630 --> 02:06:50,610
same k boys

1803
02:06:50,960 --> 02:07:04,050
the enemy something well here we use the null I haven't I haven't but but

1804
02:07:04,050 --> 02:07:08,550
I think if necessary I could but I didn't have the evidence of the yet

1805
02:07:08,550 --> 02:07:25,170
we're we're right in the middle exactly consisting of 5 years would have violated every

1806
02:07:25,190 --> 02:07:28,910
day is here you're in luck

1807
02:07:29,630 --> 02:07:31,850
the whole

1808
02:07:31,890 --> 02:07:38,940
that's right that's it that's it including this condition and can hold for sets of

1809
02:07:38,950 --> 02:07:42,540
girls which included these k and some of

1810
02:07:43,860 --> 02:07:49,570
and it's clear that becomes fun I won't like spoil everybody's gonna here it's says

1811
02:07:49,610 --> 02:07:53,530
beautiful that works so that that if I if I look at the center some


1
00:00:00,000 --> 00:00:02,380
and that strings code

2
00:00:02,390 --> 00:00:04,270
of the original data

3
00:00:04,290 --> 00:00:08,870
and the following notation is crucial i always use this so if i want ever

4
00:00:09,760 --> 00:00:13,840
use notation l subsea of x to denote the number of bits needed to describe

5
00:00:13,840 --> 00:00:17,060
x satisfying codex x using the cold water five bits

6
00:00:17,090 --> 00:00:19,750
and this will be five for example if i use

7
00:00:19,780 --> 00:00:21,560
something seven bits

8
00:00:21,590 --> 00:00:24,710
it will be so right so this is not the culprit itself but only if

9
00:00:31,680 --> 00:00:33,670
now let's go back to

10
00:00:33,760 --> 00:00:37,610
so let's say something about probability distributions

11
00:00:37,630 --> 00:00:39,590
on a countable sets

12
00:00:41,310 --> 00:00:44,690
we know of course that the sum of outcomes of the probability of the out

13
00:00:44,910 --> 00:00:47,020
of that outcome must be one

14
00:00:48,540 --> 00:00:51,760
making it into weaker statements more equal in one

15
00:00:51,780 --> 00:00:54,580
this holds for every probability distribution

16
00:00:54,590 --> 00:00:58,400
so one way of thinking about that is that most outcomes must have very small

17
00:00:59,920 --> 00:01:01,330
what do i mean by that

18
00:01:01,340 --> 00:01:05,470
well you can have only two outcomes with probability at most one half

19
00:01:05,510 --> 00:01:09,130
you can have only four outcomes with probability at most one fourth you can if

20
00:01:10,020 --> 00:01:13,730
eight outcomes with probability at most one that's

21
00:01:13,740 --> 00:01:16,010
because otherwise you don't some two

22
00:01:16,730 --> 00:01:18,250
you don't sum to one

23
00:01:18,270 --> 00:01:21,690
if you have more than eight outcomes with probability one eighty some to something larger

24
00:01:21,690 --> 00:01:22,840
than one

25
00:01:22,850 --> 00:01:27,460
so if you have let's say thousand twenty four outcomes than

26
00:01:27,510 --> 00:01:30,740
almost all of them must have probability

27
00:01:30,750 --> 00:01:36,330
it's more equal in one of thousand twenty four

28
00:01:36,370 --> 00:01:37,830
so now

29
00:01:37,850 --> 00:01:39,290
if we look at code

30
00:01:39,310 --> 00:01:44,330
it turns out that a similar phenomenon occurs so suppose we want to encode sequences

31
00:01:44,330 --> 00:01:48,510
of some length as binary sequences so in this special case we met binary sequences

32
00:01:48,510 --> 00:01:50,240
to other binary sequences

33
00:01:50,250 --> 00:01:54,610
now of course there are two sequences of length one only for sequences of length

34
00:01:54,610 --> 00:01:57,080
two eight of length three etcetera

35
00:01:57,180 --> 00:02:00,130
but there are totally and sequences of length n

36
00:02:00,170 --> 00:02:03,720
so the fraction of sequences that can be compressed

37
00:02:03,740 --> 00:02:06,220
two encoding of length one

38
00:02:06,250 --> 00:02:10,290
is very small only two of the two to the sequences can be compressed and

39
00:02:10,290 --> 00:02:11,640
encoding length one

40
00:02:11,810 --> 00:02:14,880
only four can be compressed and encoding of length two

41
00:02:14,890 --> 00:02:19,860
it's so in general the fraction that can be compressed by more than k bits

42
00:02:19,870 --> 00:02:22,230
it's less than the number

43
00:02:22,240 --> 00:02:27,220
of sequences with mines k bits defined by the number of sequences with n bits

44
00:02:27,220 --> 00:02:31,460
it's two to the mines k so in this sense only very few symbols can

45
00:02:31,460 --> 00:02:34,030
have small code length

46
00:02:34,050 --> 00:02:38,380
so no that called in this talk

47
00:02:38,410 --> 00:02:42,630
and in any MDL and general culture always uniquely decodable codes

48
00:02:42,670 --> 00:02:45,900
so this means that if we have encoded something

49
00:02:45,920 --> 00:02:49,490
we must always be able to decode the original data

50
00:02:49,500 --> 00:02:54,180
from which the encoding k so you cannot have two different data sequences mapping to

51
00:02:54,180 --> 00:02:55,660
the same code works

52
00:02:55,680 --> 00:02:58,980
and therefore they can really be only two things

53
00:02:58,990 --> 00:03:00,670
with codeword one

54
00:03:00,690 --> 00:03:02,470
because you cannot meant different things

55
00:03:02,490 --> 00:03:04,740
to the same code

56
00:03:04,750 --> 00:03:09,640
so now i can also explain to you the reasoning of the very first light

57
00:03:09,790 --> 00:03:12,240
said that if you have a random sequence

58
00:03:12,250 --> 00:03:14,510
generated by tosses of a fair coin

59
00:03:14,560 --> 00:03:18,760
but you cannot compress it with very high probability is suppose you have a sequence

60
00:03:18,760 --> 00:03:20,530
of data sequence of length

61
00:03:20,710 --> 00:03:22,000
in binary

62
00:03:23,220 --> 00:03:27,340
if that is generated by fair coin tosses then the probability of each sequence will

63
00:03:27,340 --> 00:03:30,430
be the same will be true to the mines

64
00:03:30,440 --> 00:03:31,720
so then

65
00:03:31,760 --> 00:03:35,830
the probability of the subset of size two to minus k

66
00:03:35,840 --> 00:03:39,050
will be at most two to the mines k

67
00:03:39,080 --> 00:03:43,180
right because all of the two to the minus and if you take two to

68
00:03:43,180 --> 00:03:46,810
the a minor scale the the total probability of such a set will be to

69
00:03:46,830 --> 00:03:49,710
to the minus k so therefore

70
00:03:49,720 --> 00:03:51,370
the probability

71
00:03:51,390 --> 00:03:55,190
that the actual sequence you get is in set which you can compress like a

72
00:03:55,190 --> 00:03:58,380
bit more is at most two to the mines k

73
00:03:58,380 --> 00:04:00,330
so this is the likelihood of

74
00:04:00,520 --> 00:04:04,110
common in modelling the data

75
00:04:04,170 --> 00:04:06,190
can you see hopefully

76
00:04:06,340 --> 00:04:08,740
if i try to maximize this

77
00:04:08,820 --> 00:04:11,820
try and make the data look most probable

78
00:04:11,830 --> 00:04:13,430
by changing the way

79
00:04:13,440 --> 00:04:16,390
consider sigma scratch should say

80
00:04:16,440 --> 00:04:20,480
so if we look at maximizing this doing maximum likelihood with respect to the parameters

81
00:04:21,760 --> 00:04:26,800
i maximize this i get the same result as least squares

82
00:04:26,820 --> 00:04:29,400
and i can see that because by maximize this

83
00:04:29,480 --> 00:04:32,020
the same as maximizing the logarithm of it

84
00:04:32,050 --> 00:04:36,650
if i maximize the log for the against some of logs this

85
00:04:36,670 --> 00:04:41,280
and look at this obviously gets rid of that and that give we minus

86
00:04:41,320 --> 00:04:43,540
some of the minor squared error

87
00:04:43,580 --> 00:04:44,160
so o

88
00:04:44,170 --> 00:04:45,470
i minimize that

89
00:04:45,530 --> 00:04:47,370
take out the minus sign

90
00:04:47,430 --> 00:04:50,830
so maximize the herd is equal to least squares

91
00:04:50,880 --> 00:04:52,060
under this assumption

92
00:04:52,100 --> 00:04:56,860
all comes from the assumption of the gas in nine

93
00:04:56,920 --> 00:05:01,280
so sort of framed equivalently now to the square

94
00:05:01,350 --> 00:05:05,750
the interesting thing of course is the prior distribution

95
00:05:05,820 --> 00:05:07,410
so as i said before

96
00:05:07,480 --> 00:05:09,120
we had to specify prior

97
00:05:09,140 --> 00:05:14,330
which sort of encapsulates all believe in what values parameter should take before we start

98
00:05:16,260 --> 00:05:19,190
i might see there's a lot of thing there's a lot of the in how

99
00:05:19,310 --> 00:05:20,930
specify the priors

100
00:05:20,980 --> 00:05:25,270
and specifying prior sort of keep on this very important is a lot of expert

101
00:05:25,270 --> 00:05:26,260
knowledge and

102
00:05:26,330 --> 00:05:27,740
well actually we'll see

103
00:05:27,740 --> 00:05:29,640
another example

104
00:05:29,710 --> 00:05:31,620
and that we can assume

105
00:05:31,690 --> 00:05:33,310
perfectly flat prior

106
00:05:33,310 --> 00:05:34,570
in many cases

107
00:05:34,610 --> 00:05:38,520
and still gets really powerful results

108
00:05:39,650 --> 00:05:42,520
occam's razor actually will still work for you

109
00:05:42,560 --> 00:05:45,610
even in cases where you seem if i prior

110
00:05:45,720 --> 00:05:47,320
however in this case

111
00:05:47,330 --> 00:05:53,080
for i would be appropriate because we're actually looking to find smoother functions

112
00:05:54,060 --> 00:05:55,560
a conventional choice

113
00:05:55,600 --> 00:05:58,350
it is zero mean gas

114
00:05:58,360 --> 00:06:01,610
so instead of realizing lightweight as we did in the

115
00:06:01,620 --> 00:06:03,500
all conventional treatment

116
00:06:03,500 --> 00:06:06,260
we're actually going to make small weights more probable

117
00:06:06,310 --> 00:06:07,820
so is specified

118
00:06:08,300 --> 00:06:12,780
gas distribution over the weights that makes each weight individual weight

119
00:06:12,820 --> 00:06:14,900
independent for each weight

120
00:06:14,920 --> 00:06:18,100
but they share this parameter alpha

121
00:06:18,180 --> 00:06:21,190
it is an inverse variance parameter

122
00:06:21,230 --> 00:06:23,740
so from alpha very large

123
00:06:23,820 --> 00:06:27,540
i made that way prior very tight around zero

124
00:06:28,140 --> 00:06:29,460
land is large

125
00:06:29,460 --> 00:06:32,800
the apriori very certain the weights small

126
00:06:32,890 --> 00:06:34,790
settle on this very small value

127
00:06:34,910 --> 00:06:37,430
gaston becomes very flat

128
00:06:37,440 --> 00:06:42,890
and it's almost uniform and informative

129
00:06:42,940 --> 00:06:44,550
so we sort of now

130
00:06:44,550 --> 00:06:45,820
common analog

131
00:06:46,650 --> 00:06:48,500
regularisation hyperparameter

132
00:06:48,510 --> 00:06:49,540
in this

133
00:06:49,550 --> 00:06:50,710
bayesian treatment

134
00:06:50,720 --> 00:06:56,360
and we now have this inverse variance hyperparameter we need to consider

135
00:06:56,460 --> 00:07:00,190
let's consider how we do inference

136
00:07:00,210 --> 00:07:03,170
to finally bayes rule is

137
00:07:03,210 --> 00:07:05,940
so we take that likelihood function

138
00:07:05,980 --> 00:07:08,650
we take the prior we combine it

139
00:07:08,670 --> 00:07:10,400
in bayes rule

140
00:07:10,440 --> 00:07:13,080
gives the posterior distribution

141
00:07:13,090 --> 00:07:14,650
over the parameters

142
00:07:14,710 --> 00:07:18,020
conditioned on the data

143
00:07:18,020 --> 00:07:22,580
so this is written this here because bayes rule often appears in this form

144
00:07:22,590 --> 00:07:24,400
in bayesian calculation

145
00:07:24,460 --> 00:07:29,980
typically the multiple of likelihood which is the probability of the data conditional some parameters

146
00:07:29,980 --> 00:07:32,230
from the prior over the parameters

147
00:07:32,230 --> 00:07:34,060
over normalizing factor

148
00:07:34,090 --> 00:07:38,190
and the key point about the almighty factor is this term doesn't depend

149
00:07:39,560 --> 00:07:41,650
the weights of the parameters w

150
00:07:41,690 --> 00:07:45,750
so this is independent of

151
00:07:45,840 --> 00:07:48,650
so the posterior here

152
00:07:48,670 --> 00:07:50,920
because this is cast in this is captain

153
00:07:51,170 --> 00:07:54,730
so happens that the posterior is also guessing

154
00:07:54,770 --> 00:07:57,960
has mean given by

155
00:07:57,980 --> 00:07:59,420
this term here

156
00:07:59,440 --> 00:08:01,290
but also has

157
00:08:01,590 --> 00:08:06,130
a measure of spread has a measure of uncertainty the covariance matrix

158
00:08:06,440 --> 00:08:09,560
which is kind of expression of how to ensure the model is

159
00:08:10,790 --> 00:08:13,820
the values of the parameters having seen the data

160
00:08:13,860 --> 00:08:17,270
the idea is what will see practice

161
00:08:17,310 --> 00:08:18,710
for example

162
00:08:18,750 --> 00:08:20,540
is it the more data we see

163
00:08:20,590 --> 00:08:22,770
intuitively as you'd expect

164
00:08:22,770 --> 00:08:29,500
the smaller the narrow this covariance matrix get

165
00:08:29,590 --> 00:08:31,690
well OK so far with this

166
00:08:31,710 --> 00:08:35,770
can a little refresher slide on the rules of probability if anyone

167
00:08:35,810 --> 00:08:38,440
there's acknowledged they would like to see it

168
00:08:39,610 --> 00:08:45,860
right i mean to do that

169
00:08:45,940 --> 00:08:48,790
this may be good pointers to remind

170
00:08:48,790 --> 00:08:52,980
reminder refresh people about the basic rules of probability is all we need to know

171
00:08:53,290 --> 00:08:59,040
but doing manipulations in bayesian inference or a lot of the problem

172
00:08:59,090 --> 00:09:01,940
the following rule of probability

173
00:09:02,000 --> 00:09:03,610
the two variables

174
00:09:03,610 --> 00:09:06,500
the joint distribution of those variables

175
00:09:06,540 --> 00:09:08,400
is the condition of one

176
00:09:08,440 --> 00:09:09,840
on the other

177
00:09:09,860 --> 00:09:12,250
time the model of the other

178
00:09:12,290 --> 00:09:16,400
because this these two terms can be reversed the symmetric

179
00:09:16,460 --> 00:09:18,110
and form

180
00:09:18,130 --> 00:09:19,270
simply the

181
00:09:19,340 --> 00:09:22,460
that's what the two variables

182
00:09:22,480 --> 00:09:24,880
so typically a bayesian inference i

183
00:09:24,880 --> 00:09:26,980
you know

184
00:09:31,590 --> 00:09:33,080
my life

185
00:09:33,360 --> 00:09:35,100
so that

186
00:09:35,110 --> 00:09:39,270
what you do for you

187
00:09:39,280 --> 00:09:43,580
the people

188
00:09:43,590 --> 00:09:44,980
OK so

189
00:09:44,990 --> 00:09:47,180
and let g it's my first time

190
00:09:47,240 --> 00:09:48,490
thank you

191
00:09:48,820 --> 00:09:53,860
i realized this morning that kat playing along

192
00:09:53,910 --> 00:09:55,670
i was very impressed

193
00:09:55,770 --> 00:09:56,790
although they did

194
00:09:56,940 --> 00:10:00,850
on my hand like the one that might

195
00:10:00,870 --> 00:10:01,870
but anyway

196
00:10:01,890 --> 00:10:04,980
also see kingdom

197
00:10:05,100 --> 00:10:07,950
and the way that

198
00:10:08,350 --> 00:10:11,980
in fact i came from tokyo this time some i don't like it's not so

199
00:10:12,940 --> 00:10:16,790
and i will talk about the brain computer interface thing mainly

200
00:10:16,800 --> 00:10:23,910
i this is joint work with benjamin blankertz also from afar

201
00:10:24,370 --> 00:10:27,340
and dublin core will show the team

202
00:10:28,450 --> 00:10:33,010
goble is a medical doctor so

203
00:10:33,030 --> 00:10:38,510
and as you will see it as the lecture goals there's a big component that

204
00:10:38,510 --> 00:10:40,250
is physiology and

205
00:10:40,270 --> 00:10:42,570
that will try to

206
00:10:42,580 --> 00:10:45,020
delve into

207
00:10:45,070 --> 00:10:47,620
and this is due to him

208
00:10:53,930 --> 00:10:56,390
i was asked

209
00:10:56,410 --> 00:11:00,530
to say something about myself and my group

210
00:11:01,430 --> 00:11:05,820
but you know group intelligent data analysis group has

211
00:11:05,830 --> 00:11:07,230
about forty people

212
00:11:07,250 --> 00:11:10,700
so i'm i'm

213
00:11:10,720 --> 00:11:18,460
currently professor at university of oxford put some and also directing eleven in front of

214
00:11:18,480 --> 00:11:20,500
and founder of

215
00:11:20,550 --> 00:11:22,010
and as you might know

216
00:11:22,020 --> 00:11:27,170
has some constraints these constraints are that we have

217
00:11:27,190 --> 00:11:31,860
we can do some basic research but we wanted to be applied at some point

218
00:11:32,170 --> 00:11:34,390
and this means that we also

219
00:11:34,430 --> 00:11:35,440
need to get

220
00:11:36,100 --> 00:11:38,190
serious funding from industry

221
00:11:38,200 --> 00:11:41,690
and just

222
00:11:41,740 --> 00:11:46,120
so this means that we have some scientific and industrial corporations

223
00:11:46,130 --> 00:11:56,570
so from the scientific profile that might be most interesting to you there is a

224
00:11:56,570 --> 00:11:58,400
big part machine learning and

225
00:11:58,420 --> 00:11:59,310
i mean

226
00:11:59,670 --> 00:12:04,230
i don't know that was in berlin a while ago

227
00:12:04,240 --> 00:12:10,130
quite well and alex in fact as well and we

228
00:12:10,140 --> 00:12:13,690
studied some of the SVM business

229
00:12:15,870 --> 00:12:17,770
so this means that we have

230
00:12:17,790 --> 00:12:19,410
maybe it's too short

231
00:12:19,430 --> 00:12:25,070
well i'm to show the new so really so

232
00:12:25,080 --> 00:12:28,180
so we do work and SVM

233
00:12:28,750 --> 00:12:32,100
but also on unsupervised learning

234
00:12:32,120 --> 00:12:35,110
i would lead detection clustering

235
00:12:35,130 --> 00:12:36,740
feature extraction

236
00:12:36,880 --> 00:12:38,310
the whole

237
00:12:38,320 --> 00:12:39,790
a wide range of things

238
00:12:39,800 --> 00:12:43,340
on the other side

239
00:12:43,350 --> 00:12:44,310
we also

240
00:12:44,320 --> 00:12:48,220
working on blind source separation denoising methods

241
00:12:48,240 --> 00:12:53,230
and the third topic is time series analysis

242
00:12:54,250 --> 00:13:00,250
and maybe one thing that that is very characteristic for for my group is

243
00:13:00,270 --> 00:13:02,530
is that we do data analysis

244
00:13:03,120 --> 00:13:06,940
from the theory to really the practical

245
00:13:10,650 --> 00:13:13,290
principle and to the product

246
00:13:13,310 --> 00:13:21,020
but first this step before that and we like to pick stop there and if

247
00:13:21,020 --> 00:13:25,890
you do some theory then then you realize that this theory typically doesn't work

248
00:13:25,900 --> 00:13:28,620
you first iteration from

249
00:13:28,630 --> 00:13:32,830
theory to algorithm two application so you have to go

250
00:13:32,840 --> 00:13:37,460
around this article many times and this also requires a number of

251
00:13:37,540 --> 00:13:41,890
people with different backgrounds and different abilities and also the willingness to talk to each

252
00:13:41,890 --> 00:13:45,500
other and and go forward in this circle

253
00:13:45,510 --> 00:13:51,970
and ICT one smiling in the back because he's one of them and

254
00:13:51,990 --> 00:13:54,320
the chemistry background

255
00:13:54,330 --> 00:13:56,830
OK so

256
00:13:59,040 --> 00:14:03,340
i will mostly talk about brain computer interface thing in this series of lectures but

257
00:14:03,340 --> 00:14:04,250
i was set

258
00:14:04,300 --> 00:14:12,260
i asked to talk about independent component analysis as one part of the methods to

259
00:14:12,260 --> 00:14:16,310
so if you do that and then on the kernel matrix you just classical multidimensional

260
00:14:16,310 --> 00:14:21,060
scaling you get this visualization for the stick man data and this is really characteristic

261
00:14:21,060 --> 00:14:23,070
of envy you get these little

262
00:14:26,190 --> 00:14:28,780
may relate to the question early on euclidean

263
00:14:30,020 --> 00:14:32,690
distances actually because you're forcing this thing

264
00:14:33,100 --> 00:14:34,040
in isomap

265
00:14:35,330 --> 00:14:41,000
this thing is constrained positive definite as i say the paper stanford i haven't fully understood yet claims that the

266
00:14:41,720 --> 00:14:46,090
so this is the same as doing isomap with an additional constraint that these distances

267
00:14:46,090 --> 00:14:51,010
must all be euclidean and actually embeddings look very similar apart from these little zigzag

268
00:14:51,040 --> 00:14:53,810
you get which is not due to noise in the data because the data is

269
00:14:53,810 --> 00:14:54,650
very noisy free

270
00:14:55,190 --> 00:14:59,810
so i don't know about some so side effect by forcing the distances to be positive definite

271
00:15:00,970 --> 00:15:05,400
you can't do the oil data because the dog doesn't fully connect all these thirty

272
00:15:05,430 --> 00:15:07,750
neighbours are used and then this is

273
00:15:08,460 --> 00:15:08,950
too slow

274
00:15:09,330 --> 00:15:11,020
because as a semi definite programme

275
00:15:11,540 --> 00:15:15,240
to do this maximization haven't talked about how you do the maximization

276
00:15:16,020 --> 00:15:17,460
because a semi definite programme

277
00:15:17,960 --> 00:15:18,740
on the constraints

278
00:15:22,560 --> 00:15:24,600
and i didn't apply approximate version of the algorithm

279
00:15:25,200 --> 00:15:25,970
but you do get

280
00:15:27,250 --> 00:15:29,790
you know again reasonable visualization for thee

281
00:15:31,200 --> 00:15:32,140
great vows data

282
00:15:34,590 --> 00:15:37,850
and you know a makes that i find works generally quite well so that high

283
00:15:37,850 --> 00:15:42,300
quality embeddings with no negative igon values but it's slower than all the other methods

284
00:15:42,310 --> 00:15:45,300
so it's got if you don't like the negative igon values it's the sort of

285
00:15:45,300 --> 00:15:47,610
thing to go forward he got smaller datasets

286
00:15:49,870 --> 00:15:54,750
what i want and then present is inspired by maximum variance unfolding is a new

287
00:15:54,750 --> 00:15:58,820
perspective actually unifies these things into one framework okay

288
00:15:59,790 --> 00:16:03,870
so maximizing variances what's being done in order-disorder paul

289
00:16:04,400 --> 00:16:06,850
they manifold apart so these image that

290
00:16:07,300 --> 00:16:11,360
lawrence uses when he talks about this is if men pulling on a sort of

291
00:16:11,540 --> 00:16:13,620
i think it is like a tangle of mattress

292
00:16:14,230 --> 00:16:16,770
so you are pulling on the triangle mattress and then

293
00:16:17,520 --> 00:16:18,490
where the springs are

294
00:16:19,040 --> 00:16:21,540
you can't pull apart animosities just basically unraveling

295
00:16:23,550 --> 00:16:27,820
and they do this by maximising the variance but in this case what i'm suggesting

296
00:16:27,820 --> 00:16:30,690
is well let's do maximum entropy and the maximum variance

297
00:16:31,120 --> 00:16:36,330
because entropy and variance are quite closely related the maximum entropy leads to probabilistic model

298
00:16:37,520 --> 00:16:39,930
so i'm not gonna spend much time talking about maximum entropy

299
00:16:40,620 --> 00:16:45,220
but they're each spectral approach turns out to approximate maximum entropy unfolding in some way

300
00:16:45,400 --> 00:16:48,360
in fact locally linear embedding turns out to be

301
00:16:48,810 --> 00:16:54,130
a pseudo likelihood maximization and this algorithm siu and then laplacian i can maps just

302
00:16:54,130 --> 00:16:56,570
turned out to be i didn't bother setting the parameters

303
00:16:58,510 --> 00:17:00,520
so all these methods can then be seen

304
00:17:01,260 --> 00:17:02,770
from this probabilistic point-of-view

305
00:17:03,840 --> 00:17:06,390
and i should say this is sort of research per say

306
00:17:06,790 --> 00:17:10,360
but this is research that was entirely down to try and pull these methods together

307
00:17:10,680 --> 00:17:14,290
into a unifying framework not for any other motivation

308
00:17:15,430 --> 00:17:16,790
so maximum entropy

309
00:17:18,090 --> 00:17:20,620
constraints you'll find distribution

310
00:17:21,260 --> 00:17:24,890
um in maximum entropy it's a way of looking for distributions

311
00:17:25,310 --> 00:17:28,110
subject constraints on the moments are those distributions

312
00:17:28,550 --> 00:17:30,210
and the moments we're gonna use it

313
00:17:30,690 --> 00:17:33,090
are the expected squared distances

314
00:17:35,050 --> 00:17:39,280
so whereas before in maximum variance unfolding we just put up

315
00:17:39,740 --> 00:17:42,770
these distance constraints in this is the difference between these things

316
00:17:43,480 --> 00:17:48,110
can we not defining where the moments are coming from yet we just saying the

317
00:17:48,200 --> 00:17:52,620
expectation that the distribution which is appeal whites could be a probabilistic model

318
00:17:53,780 --> 00:18:00,080
why should be such that at the moment on the pier why give me the observed distances in the data

319
00:18:00,540 --> 00:18:01,290
all the neighbors

320
00:18:04,310 --> 00:18:06,240
we should pause at this point because it's kind crucial

321
00:18:06,970 --> 00:18:07,500
and i know

322
00:18:08,020 --> 00:18:12,820
time constraint for time i've got a little bit quicker than i really liked over the last little bit

323
00:18:14,820 --> 00:18:16,120
so we can look for

324
00:18:19,360 --> 00:18:25,240
such that's when we sample from the density the expected squared distance equals we observe squared distance

325
00:18:27,960 --> 00:18:30,190
they can be written in terms of the covariance

326
00:18:30,610 --> 00:18:31,430
of the density

327
00:18:31,950 --> 00:18:33,350
it doesn't matter what the density is

328
00:18:34,550 --> 00:18:38,200
it's always write a bill in terms of the covariance which is exactly the same

329
00:18:38,200 --> 00:18:42,730
constraint we've seen before whether that's a covariance matrix a similarity matrix or anything else

330
00:18:42,730 --> 00:18:46,920
you see the same theme emerging as we saw in canopy shimei so on forth

331
00:18:47,080 --> 00:18:48,370
which is in effect

332
00:18:49,260 --> 00:18:51,490
specifying we don't know what the covariance will be

333
00:18:53,110 --> 00:18:53,920
maximum entropy

334
00:18:54,360 --> 00:18:59,330
as defined by james is a really lovely sort framework where you just into include

335
00:18:59,350 --> 00:19:01,970
the grande multipliers on the distance constraints

336
00:19:04,100 --> 00:19:07,290
and she also need to include this thing is slightly annoying thing called the base

337
00:19:07,290 --> 00:19:11,360
distribution in continuous case so this uh

338
00:19:11,500 --> 00:19:12,170
this term

339
00:19:12,730 --> 00:19:13,720
here on the left

340
00:19:14,820 --> 00:19:16,390
it is called the bayes distribution

341
00:19:16,790 --> 00:19:18,770
and is actually in this case is just a guassian

342
00:19:20,070 --> 00:19:23,230
with a very large covariance spherical thing

343
00:19:23,740 --> 00:19:27,750
tried ignoring you can actually take nothing for zero and make it disappear but things

344
00:19:27,750 --> 00:19:30,250
aren't formally correct then but it still sort of works

345
00:19:31,260 --> 00:19:35,820
but what you do have is the grande multipliers associated with all the distance constraint

346
00:19:35,850 --> 00:19:37,700
services over the sum over jay

347
00:19:38,190 --> 00:19:39,640
four all neighbors um

348
00:19:40,710 --> 00:19:45,330
what changes each neighbour i and the sum over all i will grant multipliers on

349
00:19:45,430 --> 00:19:49,750
every distance constraints and this is just the formal writing down here is the

350
00:19:50,380 --> 00:19:52,630
the known solution for maximum entropy

351
00:19:53,340 --> 00:19:57,070
that emerges from applying moment constraints so you can look this up

352
00:19:58,280 --> 00:19:59,780
in maximum entropy textbooks

353
00:20:00,460 --> 00:20:02,860
what's nice about again is you can rewrite this

354
00:20:03,950 --> 00:20:07,400
in one of these forms with this is the matrix of all distances and this

355
00:20:07,400 --> 00:20:11,370
is lambda these are the grande multipliers which is sparse in fact it's the same

356
00:20:11,370 --> 00:20:13,360
as the adjacency matrix we had before

357
00:20:14,430 --> 00:20:18,990
so you end up with a spherical term this term from the base distribution and

358
00:20:18,990 --> 00:20:21,270
to neurons are close together in this grid

359
00:20:21,490 --> 00:20:25,000
that corresponds to neurons that are allowed to turn on and turn off together

360
00:20:25,250 --> 00:20:26,480
according to this penalty

361
00:20:27,030 --> 00:20:31,490
or the often represent slightly rotated or translated edge detectors

362
00:20:31,950 --> 00:20:34,320
so effectively what this penalty is done for us

363
00:20:34,520 --> 00:20:37,470
is shown how we can learn invariant features

364
00:20:38,160 --> 00:20:41,010
so normally with convolutional neural network

365
00:20:41,130 --> 00:20:45,830
or with pooling system in computer vision we hardwire the assumption that we want to look for

366
00:20:45,850 --> 00:20:47,220
translation invariance

367
00:20:47,390 --> 00:20:49,720
we hardwired the invariance that we want to look for

368
00:20:50,000 --> 00:20:53,470
but this algorithm actually grind through the data and figures out

369
00:20:53,700 --> 00:20:55,510
translating edges

370
00:20:55,800 --> 00:20:57,100
are very common

371
00:20:57,540 --> 00:21:00,670
transformations that you'll find the data and does this without video

372
00:21:01,160 --> 00:21:02,940
so the reason that this is possible

373
00:21:03,110 --> 00:21:04,380
and not to get into

374
00:21:04,500 --> 00:21:06,010
but roughly speaking

375
00:21:06,470 --> 00:21:09,370
the fact that you see edges translating in the world

376
00:21:09,570 --> 00:21:12,730
says that whenever i see an edge on the left an edge on the right

377
00:21:13,010 --> 00:21:14,450
there are also lots of edges between

378
00:21:15,060 --> 00:21:17,070
a and so what is algorithms able to figure out

379
00:21:17,280 --> 00:21:19,770
that that particular structure of my data

380
00:21:19,970 --> 00:21:20,740
is something i can

381
00:21:20,880 --> 00:21:22,870
i can i can exploit

382
00:21:23,130 --> 00:21:24,560
to build groups like this

383
00:21:25,530 --> 00:21:27,350
so even though we have talked about it too much

384
00:21:27,530 --> 00:21:29,100
you can make a fairly

385
00:21:29,280 --> 00:21:33,410
small tweaks these algorithms and get them to learn these invariant features

386
00:21:34,190 --> 00:21:35,860
so those kinds of tools

387
00:21:37,540 --> 00:21:39,760
you can actually try to stack these things up

388
00:21:39,890 --> 00:21:41,660
and learned high-level features

389
00:21:41,860 --> 00:21:45,460
which we sort of would hope that after two or three levels we should get

390
00:21:45,680 --> 00:21:47,970
really cool abstract high-level features like

391
00:21:48,290 --> 00:21:50,450
parts and objects and so on

392
00:21:50,660 --> 00:21:54,920
but it turns out this is pretty hard to do because if you don't know the task

393
00:21:55,070 --> 00:21:58,800
through hard to figure out what information you should keep what information should get rid of

394
00:22:01,110 --> 00:22:03,910
so it turns out to be pretty tough to do well in practice

395
00:22:04,150 --> 00:22:06,510
because these high-level features just are trained

396
00:22:06,790 --> 00:22:08,750
tune for exactly what you i want to do

397
00:22:09,100 --> 00:22:10,780
but pretty cool trick

398
00:22:11,040 --> 00:22:15,560
that turns out to work well is to use this unsupervised learning algorithms

399
00:22:15,770 --> 00:22:20,660
to train up a set of features and then use that network as a starting point

400
00:22:20,680 --> 00:22:21,960
for your supervised learning

401
00:22:23,460 --> 00:22:28,970
so even though the features might not be perfect for task use them as starting portier supervised learning

402
00:22:29,820 --> 00:22:31,680
which people also called supervised fine-tuning

403
00:22:31,910 --> 00:22:33,770
actually get pretty darn good results

404
00:22:34,030 --> 00:22:35,150
and in fact

405
00:22:35,960 --> 00:22:40,050
and this is the sort of procedure that was responsible for a lot of this renewed interest

406
00:22:40,300 --> 00:22:43,500
in deep learning is probably why hurdle heard about before

407
00:22:44,350 --> 00:22:46,170
so the basic procedure for this

408
00:22:46,350 --> 00:22:49,640
so we're going to train at each of these layers greedily like i said before

409
00:22:49,900 --> 00:22:51,610
using an unsupervised algorithm

410
00:22:51,900 --> 00:22:56,840
we're attack are little supervised classifier on top maybe we'll train by itself ahead of time

411
00:22:57,030 --> 00:23:00,220
but then we're just going to go back to the back propagation algorithm we start with

412
00:23:00,230 --> 00:23:02,810
a big at the beginning just train the whole neural network

413
00:23:02,990 --> 00:23:04,160
starting from that location

414
00:23:05,340 --> 00:23:07,510
and whether this actually matters

415
00:23:07,930 --> 00:23:10,070
is a little bit open still

416
00:23:10,200 --> 00:23:13,660
it turns out not always useful there are applications in the world

417
00:23:14,940 --> 00:23:17,380
where this doesn't work so well it turns out something like

418
00:23:17,530 --> 00:23:19,520
a large imagenet problem this can matter

419
00:23:19,880 --> 00:23:21,980
and monot almost out of time here i

420
00:23:22,290 --> 00:23:23,980
want to just wrap up by saying

421
00:23:24,130 --> 00:23:25,100
even when you don't

422
00:23:25,250 --> 00:23:26,810
care about supervised task

423
00:23:26,980 --> 00:23:28,560
there is some evidence

424
00:23:28,690 --> 00:23:32,080
that we can find high-level concepts like objects and so on

425
00:23:32,290 --> 00:23:36,630
in these architectures some maybe familiar with this is so from quocle a team google

426
00:23:36,760 --> 00:23:39,060
we actually find neurons in these high levels

427
00:23:39,220 --> 00:23:42,360
that select for objects even though they have no idea what an object is

428
00:23:43,000 --> 00:23:48,020
we have a another piece based on a different algorithm can do the same thing it's not just specific to

429
00:23:48,130 --> 00:23:48,860
those methods

430
00:23:49,340 --> 00:23:52,070
there are lots of other unsupervised learning criteria

431
00:23:52,880 --> 00:23:54,930
that are worth talking about

432
00:23:55,060 --> 00:23:57,890
so if you want to get to dig into the neural networks research

433
00:23:58,020 --> 00:23:59,520
learn a lot about unsupervised learning

434
00:23:59,730 --> 00:24:01,600
i've given you maybe three or four

435
00:24:01,790 --> 00:24:05,890
penalty functions that work out for unsupervised learning problems

436
00:24:06,020 --> 00:24:09,710
but there's a whole bunch of different ideas some of which is video for example

437
00:24:10,810 --> 00:24:14,020
and finally you may be familiar with things like rbms dbms

438
00:24:14,210 --> 00:24:15,770
this sort of here for reference

439
00:24:15,930 --> 00:24:18,660
and case you guys want to roll through the slides online

440
00:24:18,660 --> 00:24:24,180
i want to

441
00:24:24,260 --> 00:24:27,940
you know

442
00:24:27,990 --> 00:24:36,090
questions of the answers to the questions of what is the typical hypothesis will compete

443
00:24:36,090 --> 00:24:40,500
to be the function of other variables and so on and you sort of yes

444
00:24:40,500 --> 00:24:41,720
on the now

445
00:24:41,730 --> 00:24:43,430
just just for this purpose

446
00:24:43,440 --> 00:24:48,830
on you know learning are also about using the new hypothesis class of a little

447
00:24:48,830 --> 00:24:54,460
bit actually did this quarter was talk about much more complicated hypothesis classes and washed

448
00:24:54,460 --> 00:24:56,280
off the higher order functions as well

449
00:24:56,310 --> 00:24:58,540
a little bit later

450
00:25:05,290 --> 00:25:09,960
so for the learning problem then on how we we choose the parameters theta

451
00:25:09,970 --> 00:25:15,310
so that a hypothesis h one make accurate predictions about holding

452
00:25:15,360 --> 00:25:18,420
right so you know one reasonable thing to do

453
00:25:18,480 --> 00:25:23,900
seems to be that we have a training set so and just on the training

454
00:25:23,900 --> 00:25:27,100
set hypothesis one you know make some predictions

455
00:25:27,130 --> 00:25:30,930
predictions of the housing prices of the the

456
00:25:30,980 --> 00:25:35,420
prices of the houses in the training set so one thing we do is is

457
00:25:35,420 --> 00:25:37,180
just try to me

458
00:25:37,280 --> 00:25:40,160
on the predictions about running out of

459
00:25:40,160 --> 00:25:43,570
accurate on the training set for a given

460
00:25:43,590 --> 00:25:48,670
some features some correct process why you might want to make

461
00:25:48,890 --> 00:25:53,660
let's see the square difference between the prediction of the algorithm and the actual price

462
00:25:57,270 --> 00:26:01,720
titus ground to state someone to minimize the ground states are of the so of

463
00:26:01,720 --> 00:26:03,030
squared error

464
00:26:03,040 --> 00:26:05,530
between the predicted price and the actual price

465
00:26:07,020 --> 00:26:07,840
and so

466
00:26:07,850 --> 00:26:14,580
the reason we have m training examples of the sum from i was one of

467
00:26:14,580 --> 00:26:16,900
my m training examples

468
00:26:16,960 --> 00:26:22,620
price predicted on the ice holes in my training set on minus the you know

469
00:26:23,510 --> 00:26:27,530
target variable minus actual price on the i th training example

470
00:26:27,540 --> 00:26:32,470
on and by convention is the minimizing this

471
00:26:32,470 --> 00:26:37,000
so most swiss differences just like the one half their which

472
00:26:37,020 --> 00:26:39,560
which which will simplify some of them

473
00:26:39,570 --> 00:26:41,400
some of them that we do that

474
00:26:42,560 --> 00:26:47,270
so let me go ahead and to find j if they to be equal to

475
00:26:47,280 --> 00:26:49,510
just the one

476
00:26:49,530 --> 00:26:59,730
something like this one and on the number of training examples the value predicted by

477
00:26:59,730 --> 00:27:02,770
my hypothesis minus the actual value

478
00:27:02,790 --> 00:27:03,960
and so

479
00:27:03,960 --> 00:27:11,830
what what do they say is minimized

480
00:27:11,890 --> 00:27:16,590
as a function of the parameters of data this quantity j theta

481
00:27:18,070 --> 00:27:24,670
i say to those who taken linear algebra classes on or maybe to those

482
00:27:24,670 --> 00:27:29,040
basic statistics forces some of you may have seen things like these before

483
00:27:29,060 --> 00:27:35,240
on in and c colony only squares regression order release queries on many of you

484
00:27:35,240 --> 00:27:38,800
will not have seen this before i think some of you may have seen before

485
00:27:38,810 --> 00:27:43,240
but either way regardless of whether it's seen before this keep going and for we

486
00:27:43,240 --> 00:27:45,430
just to those you have seen before i say

487
00:27:45,810 --> 00:27:47,740
eventually you actually showed that

488
00:27:47,770 --> 00:27:52,990
this algorithm is a special case of a much broader class about obelisk going we

489
00:27:53,160 --> 00:27:56,530
will get there eventually on

490
00:27:57,200 --> 00:28:06,870
so i'm going to talk about the couple of different algorithms for performing that minimisation

491
00:28:06,870 --> 00:28:13,420
over theta j of data for several unsolved about is a search algorithm where the

492
00:28:13,420 --> 00:28:16,660
basic idea is we will start with some

493
00:28:21,050 --> 00:28:25,570
the value of my parameter vector theta

494
00:28:25,750 --> 00:28:32,730
maybe this may be initialized my parameter vector theta to be the vector of zeros

495
00:28:33,850 --> 00:28:36,990
and he's right

496
00:28:37,010 --> 00:28:41,740
right so right zero of an arrow on top to denote the vector of all

497
00:28:42,680 --> 00:28:43,940
and then on

498
00:28:43,980 --> 00:28:46,420
you keep changing

499
00:28:48,670 --> 00:28:50,400
my friend to vector theta

500
00:28:50,410 --> 00:28:55,210
to reduce

501
00:28:55,220 --> 00:29:01,420
j a terrible bit until we hopefully end up at the minimum with respect to

502
00:29:02,420 --> 00:29:03,710
j of theo

503
00:29:04,290 --> 00:29:06,390
so she the

504
00:29:06,400 --> 00:29:09,420
laptops they think know the big speed

505
00:29:09,430 --> 00:29:15,000
so let me go ahead and

506
00:29:15,050 --> 00:29:18,510
show you an animation of this first album

507
00:29:18,520 --> 00:29:20,780
for minimizing j of data

508
00:29:20,790 --> 00:29:23,470
which an album called gradient descent

509
00:29:26,690 --> 00:29:28,590
here's the idea you see

510
00:29:28,620 --> 00:29:33,040
on the display appliance on and the axes of the

511
00:29:33,060 --> 00:29:38,450
the horizontal axes are the even if the decision might minimise j of data which

512
00:29:38,450 --> 00:29:41,980
is represented by the by the height of this plot

513
00:29:42,030 --> 00:29:44,680
so the surface represented function j theta

514
00:29:44,680 --> 00:29:47,890
and the axes of the function of the inputs is function of the crown to

515
00:29:47,890 --> 00:29:51,070
save zero the the one written down here

516
00:29:51,150 --> 00:29:53,920
so here's the hungarian descent out of

517
00:29:54,460 --> 00:29:59,740
choose some initial point could be you know better about zero randomly chosen points useless

518
00:29:59,770 --> 00:30:03,520
we start from that point denoted by the by the cross by the by the

519
00:30:03,520 --> 00:30:06,040
staff by the cost of

520
00:30:06,060 --> 00:30:09,290
and now we should imagine that of

521
00:30:10,230 --> 00:30:15,640
display actually shows the media landscape ranges of the holy parker something and this is

522
00:30:15,640 --> 00:30:19,490
the three the shape of the hole in some part

523
00:30:19,550 --> 00:30:23,630
on some actually actually standing physically at the position

524
00:30:24,740 --> 00:30:26,750
that's part of that process

525
00:30:27,000 --> 00:30:30,740
and on imagine can stand on that hole

526
00:30:30,790 --> 00:30:35,920
right and look of free-thinking fantasy degrees around you and ask if i were to

527
00:30:35,920 --> 00:30:39,440
take a small step was allowed me to go down them

528
00:30:39,480 --> 00:30:43,970
imagine that this is physically whole you're standing there look around and ask if i

529
00:30:43,970 --> 00:30:45,290
take a small step

530
00:30:45,340 --> 00:30:48,700
well that's the direction of steepest descent they would take me down here as quickly

531
00:30:48,700 --> 00:30:50,280
as possible

532
00:30:50,280 --> 00:30:54,210
so first goal for our in the hot and i will be talking about how

533
00:30:54,210 --> 00:30:59,630
to trace the flow of information through networks and what kind of applications algorithms one

534
00:30:59,630 --> 00:31:03,420
can use for that that would be for the first hour and a half then

535
00:31:03,420 --> 00:31:09,230
at ten o'clock we have half an hour coffee break and then thirty twelve

536
00:31:09,240 --> 00:31:13,460
then the sort of the second part of the tutorial where we go

537
00:31:13,480 --> 00:31:15,960
and try to understand the sort of go beyond

538
00:31:15,960 --> 00:31:22,660
analysis of networks where always save the internal nodes indirect connections but start saying about

539
00:31:22,660 --> 00:31:26,830
what if we started singing how people are friends with one another what if you

540
00:31:26,830 --> 00:31:30,800
start reasoning about what is the strength of the connection how can you predict links

541
00:31:30,800 --> 00:31:34,560
in social networks and so on so this is the sort of briefly the outline

542
00:31:34,560 --> 00:31:38,840
of the tutorial so we're starting with the first part it should go away for

543
00:31:38,840 --> 00:31:43,200
an hour and a half feel free to stop me for questions of things are

544
00:31:43,230 --> 00:31:46,370
unclear and so on the other thing i should say

545
00:31:46,380 --> 00:31:51,520
the slides for for what i'm talking about are available on this website

546
00:31:51,550 --> 00:31:56,300
they don't link is also of the the tutorial web page from the conference site

547
00:31:56,310 --> 00:32:01,090
and if you go to my my homepage and on the WBC sort of search

548
00:32:01,090 --> 00:32:05,170
for social media analytics and there is a link to the victorian website where the

549
00:32:05,200 --> 00:32:09,220
slides of the first part in the second part of the life of the first

550
00:32:09,220 --> 00:32:11,480
part i think around ten megabytes so

551
00:32:11,500 --> 00:32:13,690
be patient with the network

552
00:32:13,700 --> 00:32:15,690
OK good thank you so

553
00:32:15,700 --> 00:32:20,710
good morning again so this is the story along social media analytics and i be

554
00:32:20,710 --> 00:32:24,860
sort of start so the first part we'll be about the flow of information in

555
00:32:24,860 --> 00:32:30,550
online networks right so here is how how we can start thinking about right so

556
00:32:30,550 --> 00:32:34,560
if you think about how information reaches us us as individuals like that sort of

557
00:32:35,120 --> 00:32:39,170
they got the most ways how we how we get information one is sort of

558
00:32:39,170 --> 00:32:43,840
through that's a personal influence of our social networks example of here hear stuff from

559
00:32:43,840 --> 00:32:48,310
our friends and the other way how information reaches us is through the transmission by

560
00:32:48,310 --> 00:32:52,190
by the media by the mainstream media the web and so on right now if

561
00:32:52,190 --> 00:32:57,090
i could and the social media one of the definitions what social media is it

562
00:32:57,090 --> 00:33:03,400
is medium is designed to be disseminated through social interaction right so what what is

563
00:33:03,400 --> 00:33:04,970
now the sort of the

564
00:33:04,970 --> 00:33:10,160
question here is how does information transmitted by the bite by the media interact with

565
00:33:10,160 --> 00:33:13,740
the personal influence of these arising from our social networks

566
00:33:13,750 --> 00:33:18,660
right and the idea here is the so-called there is tension between global effects of

567
00:33:18,690 --> 00:33:22,820
something that mainstream media it's pushing information on top of us and the local effects

568
00:33:22,820 --> 00:33:27,120
of coming from the from our social structure i thought only hear what our friends

569
00:33:27,770 --> 00:33:33,990
so because social media is is disseminated through social interactions and lots of these in

570
00:33:34,000 --> 00:33:37,750
social media is going on on the web right what this also makes a change

571
00:33:37,750 --> 00:33:41,060
to the web is the web is no longer a static library the people sort

572
00:33:41,090 --> 00:33:44,810
of passively browse but the web has become much more rights to the top of

573
00:33:45,000 --> 00:33:50,120
the web is a place where people consuming create content right and the other thing

574
00:33:50,120 --> 00:33:53,430
is they also interact with one another right here it's sort of list a long

575
00:33:53,430 --> 00:33:59,520
list of different places venues on the web where people create where people interacting create

576
00:33:59,520 --> 00:34:03,900
content right these are sort of on line four discussion forums blogs social networks to

577
00:34:03,900 --> 00:34:09,660
return to his slide sharing side bookmark sharing site product review sites commenting sites and

578
00:34:09,660 --> 00:34:13,100
so on the right and one of one of the important thing is that since

579
00:34:13,150 --> 00:34:19,130
march two thousand ten the amount of litter facebook traffic is bigger than the book

580
00:34:19,400 --> 00:34:22,970
right side of that is there is a lot a lot of people are a

581
00:34:22,970 --> 00:34:28,940
lot of data being transmitted on or through the social the social media sites and

582
00:34:29,270 --> 00:34:34,750
because any user can share and contribute content express opinions in creating links to other

583
00:34:34,750 --> 00:34:40,130
users this means that sort of data mine opinions and behaviors of millions or billions

584
00:34:40,130 --> 00:34:45,090
of users to gain again sort of actionable insights right to gain insights into human

585
00:34:45,090 --> 00:34:51,520
behavior of marketing analytics product sentiment so right sort of these are now the applications

586
00:34:51,520 --> 00:34:55,750
that that that we care about so here is really what how one can think

587
00:34:55,750 --> 00:34:59,320
about social media analytics right so the idea is that we have these consumer generated

588
00:34:59,320 --> 00:35:04,470
content sort of lots of the non edited not authenticated noisy and what we would

589
00:35:04,470 --> 00:35:07,430
like to get it would like to get some kind of actionable intelligence right so

590
00:35:07,430 --> 00:35:11,530
we'd like to get some some useful knowledge out of that that with that would

591
00:35:11,550 --> 00:35:14,890
help us and what they will do next is i will go through a few

592
00:35:14,890 --> 00:35:18,750
examples of what kind of applications or what what can one do with these kinds

593
00:35:18,750 --> 00:35:24,160
of things right so so one of the one of the most common applications of

594
00:35:24,160 --> 00:35:28,860
this is reputation and brand manager management right so you can start asking how what

595
00:35:28,860 --> 00:35:33,410
are people saying about my brain and this is this goes under the name of

596
00:35:33,410 --> 00:35:39,770
consumer brand analytics similar things you can do marketing communications were basically you can you

597
00:35:39,770 --> 00:35:44,520
can start asking about where should i spend my budget what people thinking about my

598
00:35:44,520 --> 00:35:49,840
products how how what what is the sentiment we my competitors how do i how

599
00:35:49,840 --> 00:35:55,320
people perceive my products and so on right and the last thing is again sort

600
00:35:55,320 --> 00:36:00,150
of mining product reviews because we can start asking her what are the product features

601
00:36:00,150 --> 00:36:03,860
that the people like about my products or what the new requests they have right

602
00:36:03,860 --> 00:36:08,220
so is my brother easy to use is it is it lightweight is it's certainly

603
00:36:08,220 --> 00:36:11,920
does do they think do they get a good money for the bus and so

604
00:36:11,920 --> 00:36:14,850
on that so these are sort of all the thing all kinds of things that

605
00:36:14,850 --> 00:36:19,660
i can mine from the social media data basically from this traces of human activity

606
00:36:19,660 --> 00:36:21,270
that is left on the web

607
00:36:21,280 --> 00:36:27,710
another another moving on the right so another important application here citizen response right so

608
00:36:27,710 --> 00:36:32,590
for example in for for politicians or four

609
00:36:32,590 --> 00:36:35,470
it may of help you very much if you choose the wrong look any loop

610
00:36:35,470 --> 00:36:36,520
is allowed

611
00:36:36,610 --> 00:36:38,890
you then attach an open surface

612
00:36:38,900 --> 00:36:40,020
two that

613
00:36:44,280 --> 00:36:46,020
i penetrate

614
00:36:46,020 --> 00:36:47,710
it is now the current

615
00:36:48,910 --> 00:36:50,250
its surface

616
00:36:50,260 --> 00:36:51,540
according to this

617
00:36:52,960 --> 00:36:55,280
and the direction of rotation

618
00:36:55,340 --> 00:36:58,500
it's free to you how you go around half

619
00:36:58,540 --> 00:37:00,070
it's your choice

620
00:37:00,160 --> 00:37:02,760
but that the fines and the sign of the

621
00:37:02,770 --> 00:37:04,460
penetrating of the curve

622
00:37:04,510 --> 00:37:07,660
of the of the current according to the right hand

623
00:37:10,340 --> 00:37:13,440
so now we can for the first time

624
00:37:13,450 --> 00:37:17,450
calculate the magnetic field inside a wire

625
00:37:17,500 --> 00:37:19,010
because the current

626
00:37:19,020 --> 00:37:21,460
using MP is long

627
00:37:21,480 --> 00:37:23,820
i have a wire

628
00:37:23,880 --> 00:37:26,960
as the radius capital are

629
00:37:27,010 --> 00:37:28,730
and the current is coming to me

630
00:37:30,010 --> 00:37:33,960
let's assume that the current is uniformly throughout the y

631
00:37:34,040 --> 00:37:36,030
it has a uniform

632
00:37:36,070 --> 00:37:38,210
current density

633
00:37:39,000 --> 00:37:43,950
i would like to know what the magnetic field is everywhere cylindrical symmetry i wanna

634
00:37:43,950 --> 00:37:45,440
know outside the wire

635
00:37:45,450 --> 00:37:47,770
and i want know inside the y

636
00:37:47,780 --> 00:37:51,890
let's first look at radius which is larger than or

637
00:37:51,900 --> 00:37:55,910
so here we have the cross section of the wire

638
00:37:55,960 --> 00:37:58,090
these are

639
00:37:58,150 --> 00:38:03,480
the current i is going through this surface

640
00:38:03,500 --> 00:38:05,220
i i have to choose a

641
00:38:05,280 --> 00:38:06,690
closed class

642
00:38:06,700 --> 00:38:08,780
since we have cylindrical symmetry

643
00:38:08,820 --> 00:38:09,980
it is clear

644
00:38:10,000 --> 00:38:11,360
that we will choose

645
00:38:11,370 --> 00:38:13,150
a circle

646
00:38:13,230 --> 00:38:15,560
this radius or

647
00:38:15,580 --> 00:38:18,400
so we can be sure that the magnetic field strength

648
00:38:18,440 --> 00:38:23,520
is the same everywhere because of reasons of symmetry

649
00:38:23,530 --> 00:38:25,350
since the current

650
00:38:25,400 --> 00:38:27,700
is coming towards me

651
00:38:27,780 --> 00:38:32,040
and i am free to choose in which direction i'm going to march

652
00:38:32,080 --> 00:38:35,450
i know that the magnetic field is in this direction so i might as well

653
00:38:35,470 --> 00:38:37,570
so margin is our actions

654
00:38:37,610 --> 00:38:39,360
sort of my dl

655
00:38:39,500 --> 00:38:42,800
all in this direction i don't have to do that i could march on the

656
00:38:42,800 --> 00:38:46,020
way around but if i march counterclockwise

657
00:38:46,070 --> 00:38:48,170
and both terms left and right

658
00:38:48,270 --> 00:38:51,780
of MP's law will be positive

659
00:38:51,820 --> 00:38:56,820
i now have to attach a open surface to my path well this will be

660
00:38:56,890 --> 00:38:59,870
the blackboard will be that open source

661
00:38:59,910 --> 00:39:03,020
so now i apply MP's law

662
00:39:03,070 --> 00:39:05,140
so i could be

663
00:39:05,150 --> 00:39:07,070
times to by the or

664
00:39:07,170 --> 00:39:12,650
the l and r and b are in the same direction so to trivial integral

665
00:39:12,750 --> 00:39:14,540
that now is called

666
00:39:14,660 --> 00:39:16,530
new zero times

667
00:39:16,580 --> 00:39:20,650
i would not penetrates my surface uniquely determined

668
00:39:20,700 --> 00:39:23,660
all these currents on this why comes to me

669
00:39:24,740 --> 00:39:26,020
by surfaces

670
00:39:26,810 --> 00:39:28,970
times i so b

671
00:39:29,020 --> 00:39:30,660
equals museo

672
00:39:30,700 --> 00:39:35,280
i divided by two pi r and that's the same result that we found last

673
00:39:36,650 --> 00:39:38,050
when we applied

674
00:39:38,110 --> 00:39:40,080
BIO and survive

675
00:39:40,130 --> 00:39:43,420
but it's no surprise that you see this

676
00:39:43,520 --> 00:39:44,910
now we have way

677
00:39:44,920 --> 00:39:46,070
of finding

678
00:39:46,810 --> 00:39:50,620
magnetic field also inside

679
00:39:51,520 --> 00:39:54,800
so here we have now the y again cross section

680
00:39:54,810 --> 00:39:57,300
current coming out of the blackboard

681
00:39:57,350 --> 00:40:01,270
and now i want radius which is smaller than capital are

682
00:40:01,280 --> 00:40:05,280
and of course my closed last again for reasons of symmetry

683
00:40:05,300 --> 00:40:06,930
it's going to be a circle

684
00:40:06,950 --> 00:40:08,600
with radius r

685
00:40:08,650 --> 00:40:10,690
and my surface that i catch

686
00:40:10,700 --> 00:40:12,470
the flat surface

687
00:40:12,520 --> 00:40:13,900
so here i go

688
00:40:15,350 --> 00:40:16,970
i'm compiling

689
00:40:17,800 --> 00:40:19,750
he called new zero times

690
00:40:19,760 --> 00:40:22,520
ah now i have to be careful

691
00:40:22,530 --> 00:40:27,780
because now not to fall current i is now penetrating my surface

692
00:40:27,820 --> 00:40:29,480
but it is only a fraction

693
00:40:29,490 --> 00:40:30,740
that penetrates

694
00:40:30,750 --> 00:40:31,760
the surface

695
00:40:31,780 --> 00:40:35,500
and the fraction that penetrates the surface is now the largest grant

696
00:40:35,540 --> 00:40:38,080
divided by kappa so are square

697
00:40:40,080 --> 00:40:43,070
you see because the total current comes

698
00:40:44,280 --> 00:40:45,500
capitol are but

699
00:40:45,510 --> 00:40:47,290
i only have now

700
00:40:47,330 --> 00:40:50,190
the circle was radius little or

701
00:40:50,250 --> 00:40:52,380
so i lose one are here

702
00:40:52,390 --> 00:40:56,790
so you get very different results you get now to the magnetic field

703
00:40:56,900 --> 00:40:58,740
because new zero

704
00:40:58,820 --> 00:41:00,230
and i

705
00:41:00,250 --> 00:41:02,550
it is nonlinear in the are

706
00:41:02,560 --> 00:41:04,880
divided by two pi

707
00:41:04,890 --> 00:41:07,510
capitol are square

708
00:41:07,540 --> 00:41:08,700
and this

709
00:41:08,730 --> 00:41:10,550
grows linearly with are

710
00:41:10,570 --> 00:41:12,380
whereas this falls off

711
00:41:12,400 --> 00:41:14,560
one of our

712
00:41:14,580 --> 00:41:17,950
and if you substitute in this equation are

713
00:41:17,970 --> 00:41:20,240
because capital are

714
00:41:20,250 --> 00:41:21,600
which then would be the

715
00:41:21,610 --> 00:41:26,170
magnetic field right at the surface of the wire you find exactly the same result

716
00:41:27,310 --> 00:41:29,450
they are becomes the capital are

717
00:41:29,510 --> 00:41:32,610
if there are becomes the capital are

718
00:41:32,650 --> 00:41:34,770
was one capital are you get

719
00:41:34,810 --> 00:41:36,000
same result

720
00:41:36,050 --> 00:41:38,250
so if you make a plot

721
00:41:38,260 --> 00:41:40,230
of the magnetic field

722
00:41:40,240 --> 00:41:44,020
as a function of little are

723
00:41:44,030 --> 00:41:46,820
that looks like

724
00:41:46,910 --> 00:41:49,530
like so so this is are

725
00:41:49,540 --> 00:41:51,560
this is capital our

726
00:41:51,570 --> 00:41:55,290
this is the magnetic field strength and we know that it is

727
00:41:55,350 --> 00:41:57,740
gential e to the circles

728
00:41:57,750 --> 00:41:59,310
it will be

729
00:42:00,140 --> 00:42:01,690
straight line

730
00:42:01,750 --> 00:42:02,750
and then here

731
00:42:02,760 --> 00:42:05,480
it falls off as one of four

732
00:42:05,520 --> 00:42:07,970
and the maximum value here

733
00:42:08,020 --> 00:42:11,610
is the value that you find there if you substitute are

734
00:42:12,700 --> 00:42:18,200
capital or

735
00:42:18,360 --> 00:42:22,130
i will show you that we can using MP as well

736
00:42:24,040 --> 00:42:27,280
come very close to calculating the magnetic field

737
00:42:27,290 --> 00:42:31,130
inside what we call a solenoid is a solenoid

738
00:42:31,170 --> 00:42:32,500
it's like a

739
00:42:34,770 --> 00:42:36,270
current that goes around

740
00:42:36,280 --> 00:42:40,050
in the spiral one loop after another

741
00:42:40,060 --> 00:42:42,970
i want to remind you that if we had a look

742
00:42:43,080 --> 00:42:44,510
nice currently

743
00:42:44,520 --> 00:42:46,520
coming out of the blackboard here

744
00:42:46,530 --> 00:42:48,780
and the current going into the blackboard

745
00:42:48,830 --> 00:42:52,610
so it is circular why am but i only show you the cross section

746
00:42:52,650 --> 00:42:54,140
i want to remind you that

747
00:42:54,150 --> 00:42:57,200
the magnetic field as we discussed last time

748
00:42:57,280 --> 00:42:59,880
would be clockwise here

749
00:42:59,970 --> 00:43:02,310
the counterclockwise here

750
00:43:02,330 --> 00:43:03,760
in the middle

751
00:43:05,030 --> 00:43:06,880
it was like this

752
00:43:06,890 --> 00:43:09,150
and then in between

753
00:43:09,250 --> 00:43:11,280
it was like so

754
00:43:11,310 --> 00:43:13,890
was sort of the magnetic field configuration

755
00:43:13,900 --> 00:43:15,740
in the vicinity of a

756
00:43:16,740 --> 00:43:19,320
which we have the current going

757
00:43:19,500 --> 00:43:23,020
now imagine that you put another loop here

758
00:43:24,190 --> 00:43:27,250
current again coming out of the blackboard going into the blackboard

759
00:43:27,250 --> 00:43:28,940
and the three i want to deal with

760
00:43:28,960 --> 00:43:34,150
the first one is whether this is a high-level or low-level language

761
00:43:34,170 --> 00:43:40,960
basically says how close or you've got to the machine a low-level languages to call

762
00:43:40,960 --> 00:43:45,280
this assembly program you're down at the level of your primitives are literally moving pieces

763
00:43:45,280 --> 00:43:49,690
of data from one location in memory to another through a very simple operation

764
00:43:49,690 --> 00:43:55,150
a high-level language the designers created a much richer set of primitive things

765
00:43:55,170 --> 00:43:57,150
in high level language square root

766
00:43:57,150 --> 00:44:00,030
might simply be primitive that you can use rather than you having to go over

767
00:44:01,260 --> 00:44:03,670
and the trade offs between both

768
00:44:03,690 --> 00:44:05,480
the second dimension

769
00:44:05,500 --> 00:44:07,880
it's whether this is in general

770
00:44:07,940 --> 00:44:11,650
verses are targeted language

771
00:44:11,690 --> 00:44:15,690
by that i mean to the set of primitive support a broad range of applications

772
00:44:15,690 --> 00:44:17,320
or is it really aimed

773
00:44:17,320 --> 00:44:21,080
and a very specific set of applications that argue the matlab is basically a targeted

774
00:44:21,080 --> 00:44:25,070
languages targeted matrices and vectors and things like that

775
00:44:25,070 --> 00:44:29,110
and the third one i want to point out is whether this is an interpreted

776
00:44:29,150 --> 00:44:33,000
verses are compiled language

777
00:44:33,030 --> 00:44:41,820
but that basically says is the following an interpreted language you take what's called the

778
00:44:41,820 --> 00:44:43,690
source called the thing you write

779
00:44:43,690 --> 00:44:47,090
in may go through a simple check about but it basically goes to the interpreter

780
00:44:47,090 --> 00:44:50,300
that thing inside the machine is going to control the flow going through each one

781
00:44:50,300 --> 00:44:51,500
of these instructions

782
00:44:51,570 --> 00:44:52,960
giving output

783
00:44:52,980 --> 00:44:57,980
so the interpreters simply operating directly on your code at runtime

784
00:44:58,000 --> 00:45:02,190
in a compiled language you have an intermediate step which you take the source code

785
00:45:02,300 --> 00:45:05,090
it runs who is called the checker compiler both

786
00:45:05,210 --> 00:45:07,440
and it creates what's called object code

787
00:45:07,530 --> 00:45:09,650
that does two things one

788
00:45:09,690 --> 00:45:11,110
it helps catch

789
00:45:11,110 --> 00:45:12,780
bugs in your code

790
00:45:12,820 --> 00:45:17,170
and secondly it often converted into one more efficient sequence of instructions

791
00:45:17,190 --> 00:45:19,610
before you actually go off and run

792
00:45:19,650 --> 00:45:24,130
this trade between both men interpreted language is often easier to debug because you can

793
00:45:24,130 --> 00:45:28,480
still see rocco there but it's not always is fast compiled language is usually much

794
00:45:28,480 --> 00:45:30,380
faster in terms of its execution

795
00:45:30,420 --> 00:45:33,440
it is one of the things you may want to trade off

796
00:45:33,460 --> 00:45:35,130
in the case of pi

797
00:45:35,130 --> 00:45:38,650
a high-level language

798
00:45:38,670 --> 00:45:40,300
i would argue

799
00:45:40,360 --> 00:45:45,610
john degrees means basically general-purpose languages happens to be better suited for manipulating strings the

800
00:45:45,610 --> 00:45:49,050
numbers for example but it's really a general purpose language

801
00:45:49,070 --> 00:45:50,520
and it's a

802
00:45:51,380 --> 00:45:53,710
should separate is an interpreted language

803
00:45:53,760 --> 00:45:55,090
OK i

804
00:45:55,090 --> 00:45:59,230
as a consequence is not as good at helping debug but it does let you

805
00:45:59,230 --> 00:46:01,860
try run was things not as good at catching some things

806
00:46:01,960 --> 00:46:07,000
before you run it is easier sometimes and debugging as you go on the fly

807
00:46:07,130 --> 00:46:09,050
OK so what is python look like

808
00:46:09,070 --> 00:46:11,800
in order to talk about life on

809
00:46:11,820 --> 00:46:12,900
do it

810
00:46:12,920 --> 00:46:19,570
we need to talk about how to write things apart again let me back up

811
00:46:19,570 --> 00:46:21,570
slightly and set the stage

812
00:46:21,650 --> 00:46:22,750
our goal

813
00:46:22,750 --> 00:46:24,320
to build recipes

814
00:46:24,340 --> 00:46:27,210
there going be great chefs by the time you don't here

815
00:46:27,460 --> 00:46:29,230
our goal is to take

816
00:46:29,280 --> 00:46:33,800
problems and break them down into these computational steps the sequence of instructions that allow

817
00:46:33,960 --> 00:46:36,030
to capture that process

818
00:46:36,050 --> 00:46:37,710
to do that we need to describe

819
00:46:37,760 --> 00:46:41,210
but only one of the primitives but how do we capture things legally in that

820
00:46:42,000 --> 00:46:44,980
and interact with the computer and so for that we need language

821
00:46:45,090 --> 00:46:47,780
we're about to start talking about the elements of the language but to do that

822
00:46:47,780 --> 00:46:53,750
we also need to separate out one last piece of distinction

823
00:46:53,860 --> 00:46:58,440
just like with the natural language going to separate out syntax versus semantics

824
00:46:58,500 --> 00:47:01,690
so what's syntax syntax basically says

825
00:47:01,690 --> 00:47:05,210
what are the legal expressions

826
00:47:05,230 --> 00:47:07,960
in this language

827
00:47:11,380 --> 00:47:21,400
my handwriting approaches and there's there's an english sequence of words

828
00:47:21,480 --> 00:47:23,400
it's not syntactically correct right

829
00:47:24,550 --> 00:47:28,670
it's never been there and you're sick was announced same thing in our languages we

830
00:47:28,670 --> 00:47:33,860
have to describe how do you put together legally formed expressions

831
00:47:34,710 --> 00:47:38,280
and as we had contracts to the language going to talk about that

832
00:47:38,360 --> 00:47:41,960
the second thing we want to talk about very briefly as we go along

833
00:47:41,980 --> 00:47:46,210
is the semantics of the language and here we're going to break two pieces static

834
00:47:46,210 --> 00:47:48,780
semantics and full semantics

835
00:47:48,800 --> 00:47:52,030
static semantics basically say is

836
00:47:52,050 --> 00:47:54,030
which programs

837
00:47:54,030 --> 00:47:59,530
are meaningful

838
00:48:01,400 --> 00:48:03,690
which expressions makes sense

839
00:48:03,860 --> 00:48:07,110
is an english sentence

840
00:48:13,300 --> 00:48:15,750
it syntactically correct

841
00:48:15,750 --> 00:48:18,630
i am phrase verb noun phrase

842
00:48:18,650 --> 00:48:22,980
i'm not certain it's meaningful unless you are in the habit of giving your furniture

843
00:48:22,980 --> 00:48:24,340
personal names

844
00:48:24,400 --> 00:48:30,230
what's the point again you can have things that are syntactically legal but not semantically

845
00:48:30,280 --> 00:48:34,630
meaningful and static semantics is going to be a way of helping us decide what

846
00:48:34,630 --> 00:48:38,210
expressions what pieces of code actually have real meaning to it

847
00:48:38,400 --> 00:48:40,780
the last piece of it is

848
00:48:40,820 --> 00:48:43,650
in addition to having static semantics

849
00:48:43,650 --> 00:48:45,030
we have

850
00:48:45,030 --> 00:48:46,530
full semantics

851
00:48:46,760 --> 00:48:51,500
what does the programming

852
00:48:51,520 --> 00:48:56,380
four different way what's going to happen

853
00:48:56,400 --> 00:48:59,280
when i run it

854
00:48:59,300 --> 00:49:07,300
it's the meaning of the expression that's what you want you want to know what's

855
00:49:07,320 --> 00:49:10,300
the meaning of this piece of code when i run what's going to happen that's

856
00:49:10,300 --> 00:49:11,860
what i want to build

857
00:49:11,920 --> 00:49:14,900
the reason for pulling this out is what you want to see

858
00:49:14,980 --> 00:49:18,520
is that in most languages and certainly in pi fun

859
00:49:18,520 --> 00:49:23,210
we get lots of help here

860
00:49:23,210 --> 00:49:28,900
python comes built-in with something that will check your static so yes your syntax for

861
00:49:29,940 --> 00:49:33,250
in fact is the sidebar if you turn in the problem set

862
00:49:33,300 --> 00:49:37,090
it is not syntactically correct there's a simple button you push

863
00:49:37,120 --> 00:49:40,760
i will check your syntax if you turn the program not syntactically correct is give

864
00:49:40,760 --> 00:49:41,980
you zero

865
00:49:42,020 --> 00:49:44,380
as i said you didn't even take the time to make sure the syntax to

866
00:49:44,400 --> 00:49:46,440
correct the system will help you find

867
00:49:46,460 --> 00:49:50,210
in python little find i think one but at the time john finds one syntax

868
00:49:50,210 --> 00:49:52,570
error time so you have to be a little patient do but you can check

869
00:49:52,590 --> 00:49:53,730
the syntax

870
00:49:53,750 --> 00:49:55,280
his is right

871
00:49:55,300 --> 00:49:59,260
you see that we get some help here

872
00:49:59,480 --> 00:50:04,980
on the static semantics unknown example in the second

873
00:50:05,000 --> 00:50:08,650
meaning that the system in some languages are better than others on it but it

874
00:50:08,650 --> 00:50:11,210
will try and help you catch

875
00:50:11,550 --> 00:50:13,570
some things that are

876
00:50:14,520 --> 00:50:16,980
semantically correct statically

877
00:50:17,030 --> 00:50:20,250
in the case of pi founded doesn't i think all around time look you can

878
00:50:20,250 --> 00:50:21,530
join i think there's no

879
00:50:21,590 --> 00:50:22,320
there's no

880
00:50:22,320 --> 00:50:24,250
every time jackson

881
00:50:24,300 --> 00:50:25,380
so i

882
00:50:26,400 --> 00:50:27,980
there is some OK

883
00:50:28,130 --> 00:50:31,610
most of them i think they are primarily can't run time and that's a little

884
00:50:31,610 --> 00:50:34,050
bit of a pain because you don't seem to be going run the code there

885
00:50:34,050 --> 00:50:37,040
are some are going to see an example of the kind of secondary find which

886
00:50:37,040 --> 00:50:38,800
you do get some help there

887
00:50:38,840 --> 00:50:40,730
the problem is

888
00:50:40,780 --> 00:50:42,340
things that you catch here

889
00:50:42,400 --> 00:50:43,230
are actually

890
00:50:43,250 --> 00:50:45,460
police were box

891
00:50:45,530 --> 00:50:46,860
easy to spot

892
00:50:46,860 --> 00:50:48,250
you can run the program

893
00:50:48,250 --> 00:50:51,360
with them there's not going to get weird answers

894
00:50:51,400 --> 00:50:53,710
not everything is going to get caught

895
00:50:53,730 --> 00:50:58,630
static semantics checking some things are going slide through and that's actually a boy

896
00:50:58,650 --> 00:50:59,610
the problem

897
00:50:59,670 --> 00:51:02,860
because it says your program will still give you a value

898
00:51:02,860 --> 00:51:06,430
what can we say about this transformed table well

899
00:51:06,450 --> 00:51:10,180
first of all the size of the table is unchanged

900
00:51:10,190 --> 00:51:15,910
by design we haven't allowed any rose disappear because if if shifting down would have

901
00:51:15,910 --> 00:51:17,710
led to arrive that was already there

902
00:51:17,730 --> 00:51:19,080
we didn't do it

903
00:51:19,090 --> 00:51:23,380
so we've got the same number of rows

904
00:51:23,390 --> 00:51:27,080
whenever secondly the VC dimension

905
00:51:27,090 --> 00:51:29,420
because increase

906
00:51:29,440 --> 00:51:31,170
OK so whenever we got

907
00:51:32,130 --> 00:51:36,740
when we got transformed table shattering some subset

908
00:51:37,560 --> 00:51:39,830
of x one to xn

909
00:51:39,890 --> 00:51:45,830
the original table must have shown some subset share the same subset

910
00:51:46,500 --> 00:51:47,490
and you can

911
00:51:47,500 --> 00:51:49,190
you can see that

912
00:51:49,200 --> 00:51:51,940
by thinking about what happens

913
00:51:51,960 --> 00:51:54,980
if we left with after

914
00:51:55,030 --> 00:51:57,370
after shifting in particular column

915
00:51:57,390 --> 00:52:02,430
right if we're left with a shattered set

916
00:52:02,450 --> 00:52:06,070
so so here we can see x four and x five right we have minus

917
00:52:06,070 --> 00:52:09,110
minus minus plus plus minus plus plus

918
00:52:09,180 --> 00:52:13,110
OK if after shifting this column we're left with a shattered set

919
00:52:13,110 --> 00:52:16,710
then we must have started with a shattered set that's you can see that by

920
00:52:16,710 --> 00:52:19,180
considering what we have a plus plus here

921
00:52:19,200 --> 00:52:21,590
we didn't shifted and all minus

922
00:52:21,630 --> 00:52:24,560
OK and so we must have the identical wrote

923
00:52:24,570 --> 00:52:26,650
below that in the table

924
00:52:26,720 --> 00:52:27,890
right and so

925
00:52:27,900 --> 00:52:32,050
you know we've got a plus

926
00:52:32,070 --> 00:52:37,770
everything and minus everything so we've got a shattered set before we shifted that right

927
00:52:37,790 --> 00:52:39,770
OK so so shifting

928
00:52:39,810 --> 00:52:43,500
if we have a shared that after shifted we must have had one before

929
00:52:44,580 --> 00:52:48,350
so we might decrease the VC dimension that we can increase it above its original

930
00:52:48,350 --> 00:52:51,890
value which was no more than

931
00:52:52,660 --> 00:52:58,770
OK so so the other property i mentioned already that we've got this close below

932
00:52:58,800 --> 00:53:03,320
property once we don't wish shifting every class that's in the table if we change

933
00:53:03,320 --> 00:53:06,500
it minus we get another of the table

934
00:53:06,550 --> 00:53:09,910
well this is probably the makes counting really easy

935
00:53:10,000 --> 00:53:12,530
OK we know we have an increase the VC dimension

936
00:53:12,530 --> 00:53:14,680
then a new table

937
00:53:14,700 --> 00:53:18,060
we've got the same number of rows but now we can count the number of

938
00:53:18,890 --> 00:53:22,340
OK because every row has no more than the ones

939
00:53:22,390 --> 00:53:25,280
why is that the VC dimension is no more than d

940
00:53:25,280 --> 00:53:27,490
so we can shatter set of size d

941
00:53:27,520 --> 00:53:28,900
suppose we had a row

942
00:53:28,930 --> 00:53:32,690
it had more than the ones in that we've got everything below the right

943
00:53:32,750 --> 00:53:34,810
right so those d ones

944
00:53:34,810 --> 00:53:37,250
that those that set of ones

945
00:53:37,270 --> 00:53:43,180
right indicates is appointed to a shattered set by find two what two plus one

946
00:53:45,350 --> 00:53:49,360
that indicates the next that the corresponding x is x four x five

947
00:53:49,410 --> 00:53:53,360
former shattered set because i've got everything below these two clusters so i got the

948
00:53:53,390 --> 00:53:54,880
two q

949
00:53:54,880 --> 00:53:57,350
OK so i can't possibly have

950
00:53:57,360 --> 00:54:00,750
a row with more than the ones because the VC dimension is no more than

951
00:54:02,220 --> 00:54:05,020
OK so how many rows can i have that have

952
00:54:05,030 --> 00:54:07,960
no more than the ones

953
00:54:07,980 --> 00:54:10,580
right when i've got everything below

954
00:54:10,690 --> 00:54:13,830
well just many rose can have that no more than the ones was just the

955
00:54:14,860 --> 00:54:19,800
up to the avengers i n two zero number of ways of choosing a row

956
00:54:19,820 --> 00:54:23,610
with zero ones with one one with all the way up to d once that's

957
00:54:23,610 --> 00:54:26,590
the number that's not upperbound on the number of rows

958
00:54:27,550 --> 00:54:29,520
and the even here is

959
00:54:29,540 --> 00:54:30,970
these are of about on the

960
00:54:30,990 --> 00:54:32,880
on the VC dimension

961
00:54:32,880 --> 00:54:36,710
OK so the number rose to synthesize the tables and change the number of rows

962
00:54:36,710 --> 00:54:38,620
in the original table

963
00:54:38,630 --> 00:54:41,130
it is no bigger than

964
00:54:41,140 --> 00:54:44,890
then this this summer

965
00:54:46,560 --> 00:54:56,600
with the VC and you can come up with an example i mean i i

966
00:54:56,600 --> 00:55:03,190
and going to present to you

967
00:55:03,230 --> 00:55:06,470
the main speaker of today

968
00:55:06,480 --> 00:55:10,040
it is professor mubarak shah is

969
00:55:10,060 --> 00:55:13,940
full professor at the university of central florida

970
00:55:14,010 --> 00:55:22,530
and the distinguished scientists in computer vision particularly he worked a lot on video analysis

971
00:55:22,530 --> 00:55:28,760
he is a fellow of simply SPI

972
00:55:28,760 --> 00:55:36,150
and he has received many awards here in full favor of words that he received

973
00:55:36,190 --> 00:55:38,220
so i will not list of

974
00:55:38,220 --> 00:55:43,980
and for probably more important is that he has been

975
00:55:45,520 --> 00:55:47,550
associate editor of people body

976
00:55:47,550 --> 00:55:53,050
transactions on family is currently associated ACM computing surveys

977
00:55:53,070 --> 00:55:57,980
and the editor-in-chief of machine vision and applications

978
00:55:57,980 --> 00:56:02,480
professor chen

979
00:56:02,570 --> 00:56:09,580
we use today a task which is feasible crowned survey and this is like

980
00:56:09,630 --> 00:56:15,040
hydro dynamics so challenging talk

981
00:56:15,050 --> 00:56:16,130
thank you

982
00:56:16,150 --> 00:56:26,120
thank you very much for the introduction

983
00:56:26,130 --> 00:56:28,430
place to be here

984
00:56:28,440 --> 00:56:33,980
i'm not going to show you these pictures of me when i was a young

985
00:56:33,980 --> 00:56:40,630
girl has made sure yesterday i was thinking about it but

986
00:56:40,690 --> 00:56:47,290
i don't find them in in most dangerous so one thing you will notice that

987
00:56:47,320 --> 00:56:47,850
you know

988
00:56:48,010 --> 00:56:50,370
i can be compared to

989
00:56:50,820 --> 00:56:59,690
ninety five students in the last year so that's kind of proportion OK so i'm

990
00:56:59,690 --> 00:57:03,520
going to talk about the visual surveillance

991
00:57:03,570 --> 00:57:05,200
in crowds

992
00:57:05,220 --> 00:57:11,260
and there's a bunch say this is going to be talking in computer vision which

993
00:57:11,280 --> 00:57:15,440
is called ventricles multimedia and in particular the talk about

994
00:57:15,440 --> 00:57:17,720
video analysis and so

995
00:57:17,750 --> 00:57:22,220
this is one of the most active in computer vision given to you

996
00:57:22,230 --> 00:57:25,070
these are the main steps so first you want to do that

997
00:57:25,100 --> 00:57:27,480
just interest and you want to

998
00:57:27,570 --> 00:57:33,390
training these objects from for free and then you want to many countries objects in

999
00:57:33,390 --> 00:57:38,020
their car power some basic and so on and anyone you want to look at

1000
00:57:38,020 --> 00:57:43,640
the of these objects actions that users and there's a lot of work in computer

1001
00:57:43,640 --> 00:57:47,670
vision from or through a lot of a lot of work

1002
00:57:47,690 --> 00:57:52,760
so for example in tracking you can train

1003
00:57:52,780 --> 00:57:54,760
one point on

1004
00:57:54,760 --> 00:57:57,110
apart like

1005
00:57:57,190 --> 00:58:03,920
images or you can take a bounding box where you look at the

1006
00:58:03,980 --> 00:58:10,350
it's change from previous frame and the background is change from frame to frame and

1007
00:58:10,380 --> 00:58:17,250
you can get their properties of the regions and so are you can train the

1008
00:58:17,260 --> 00:58:22,610
contour of objects which gives you much more information about the articulation of objects and

1009
00:58:22,610 --> 00:58:28,630
this is the case where actually the camera is moving similar example of the odometry

1010
00:58:28,640 --> 00:58:39,070
many tricks these cases next thing here is that you can shake actually the choice

1011
00:58:39,070 --> 00:58:39,950
of the person

1012
00:58:40,450 --> 00:58:42,480
and get to see

1013
00:58:42,730 --> 00:58:49,480
each of that now given all that then you can do that in the example

1014
00:58:52,070 --> 00:58:55,570
meeting in our and the object star

1015
00:58:55,570 --> 00:59:01,560
you know somebody is making us and share and somebody can push the sky away

1016
00:59:02,030 --> 00:59:10,110
simple events which are based on the occasion tracking information can do that also trajectories

1017
00:59:10,110 --> 00:59:16,350
you can get the trajectories by these and get some properties of that and is

1018
00:59:16,350 --> 00:59:23,150
what we construct the phase space of its trajectory cuties chaotic invariants

1019
00:59:23,150 --> 00:59:28,960
there's a wonderful writer mathematics but we in physics come things almost in the opposite

1020
00:59:28,960 --> 00:59:31,940
extreme you see i didn't show you a single table

1021
00:59:31,980 --> 00:59:37,770
i didn't make a single maximum likelihood estimate MLE or anything of that sort instead

1022
00:59:37,770 --> 00:59:43,960
we do things primarily using plots on the assumption that if we can see with

1023
00:59:44,050 --> 00:59:50,500
our eye it probably doesn't really exist just some artifact of the computer algorithm which

1024
00:59:50,500 --> 00:59:52,860
happened to be to be using

1025
00:59:52,880 --> 01:00:01,000
and and and in the case of economics the statistics community has been very successful

1026
01:00:01,860 --> 01:00:07,540
analyzing vast quantities of data but some of these properties and we've pulled out by

1027
01:00:08,570 --> 01:00:15,320
application to economics of ideas that work in statistical physics which is first and foremost

1028
01:00:15,540 --> 01:00:21,070
to analyse huge amounts of data if we're trying to find rare events and secondly

1029
01:00:21,070 --> 01:00:26,460
to look at those data i in such a fashion that we're not a perturbed

1030
01:00:26,650 --> 01:00:32,460
by strange properties such as crossing over from one distribution in the centre to another

1031
01:00:32,460 --> 01:00:35,750
distribution in the tail something that's hardly repugnant

1032
01:00:35,770 --> 01:00:40,900
too many decent humans particularly if there are mathematicians

1033
01:00:40,920 --> 01:00:45,690
so i think this is important take-home message and the most important take-home lesson of

1034
01:00:45,690 --> 01:00:50,310
this talk for me this is that one should start always with the simplest model

1035
01:00:50,310 --> 01:00:54,130
that comes to mind for example random walk in the case of both the part

1036
01:00:54,130 --> 01:00:58,860
of the problem and the stock price fluctuation problem but then immediately tried to build

1037
01:00:58,860 --> 01:01:02,290
in a systematic corrections to that in order to

1038
01:01:02,340 --> 01:01:06,520
c to to reproduce the data in the case of the part problem those corrections

1039
01:01:06,520 --> 01:01:12,670
have been built in and the model called the self avoiding random walk is perfectly

1040
01:01:12,670 --> 01:01:18,420
successful in describing to palmer's below four dimensions whereas the random walk model is not

1041
01:01:18,440 --> 01:01:23,540
and the case of finance problem we not yet found such a model and some

1042
01:01:23,540 --> 01:01:27,130
of you in this audience would like to work on that problem in particular if

1043
01:01:27,340 --> 01:01:31,090
you you want to come to boston a working with open arms thank you for

1044
01:01:31,090 --> 01:01:38,380
your attention

1045
01:02:22,210 --> 01:02:24,940
what the significance is not known at all

1046
01:02:24,940 --> 01:02:28,320
as of the same is true here i have no idea the significance of the

1047
01:02:28,320 --> 01:02:31,150
exponent minus three over the

1048
01:02:32,110 --> 01:02:38,170
this is a little embarrassing but again gets empirical fact after we don't have understanding

1049
01:02:38,170 --> 01:02:42,210
of the exponents occurrences simple physical laws like coulombs law

1050
01:02:42,440 --> 01:02:46,670
that's we particle physicist something else don't understand

1051
01:02:46,670 --> 01:02:50,380
so that's roughly where we are in economics can relate these exponent one to the

1052
01:02:50,380 --> 01:02:58,070
other can relate exponent of let's start price fluctuations exponent of five fluctuations of time

1053
01:02:58,070 --> 01:03:02,360
interval between trains and so forth but we don't really have better understanding of where

1054
01:03:02,360 --> 01:03:08,650
they come from that and probably never will certainly don't report from any understanding of

1055
01:03:08,860 --> 01:03:11,190
subject parameters that describe the system

1056
01:03:11,270 --> 01:03:12,500
or earthquakes

1057
01:03:12,540 --> 01:03:17,070
but we're so much is that the expert in the good repair laws not minus

1058
01:03:17,070 --> 01:03:19,130
three is for stocks

1059
01:03:19,190 --> 01:03:26,000
earthquakes but instead is roughly minus one million china knows better than i

1060
01:03:26,050 --> 01:03:29,190
we don't understand what it's like this one

1061
01:03:29,250 --> 01:03:33,550
the question

1062
01:03:33,570 --> 01:03:38,420
it's about that we know all of

1063
01:03:38,440 --> 01:03:46,550
but what is going to is weight

1064
01:03:53,110 --> 01:03:55,520
you can

1065
01:03:56,210 --> 01:04:00,270
more precisely in this one

1066
01:04:02,420 --> 01:04:04,920
one of first we need microscopic all

1067
01:04:05,750 --> 01:04:11,340
his friend is a great body of knowledge inspired primarily by kenneth g wilson

1068
01:04:11,380 --> 01:04:14,630
he was awarded the nobel prize for this in the early eighties

1069
01:04:14,650 --> 01:04:18,520
and that work involved building on the idea

1070
01:04:18,570 --> 01:04:20,420
the random walk

1071
01:04:20,440 --> 01:04:23,480
does not describe the real palmer

1072
01:04:23,500 --> 01:04:25,630
at all below four dimensions

1073
01:04:25,630 --> 01:04:29,810
and that's because the random walk intersect itself below four dimensions

1074
01:04:29,860 --> 01:04:34,420
building on that simple simple geometric idea wilson was able to

1075
01:04:34,440 --> 01:04:41,090
make a theory of exponent which i should describe cancer professor strikers question that you've

1076
01:04:41,090 --> 01:04:48,020
expert gave numerical values for exponent and but a real intuition for why they are

1077
01:04:48,020 --> 01:04:50,980
with the idea this few years no

1078
01:04:51,420 --> 01:04:54,750
but it certainly needs to explain why some bigger than others

1079
01:04:54,770 --> 01:05:00,940
susceptibility expert prevents this and so forth but i have the feeling that there is

1080
01:05:00,940 --> 01:05:02,320
one additional thing

1081
01:05:02,340 --> 01:05:07,280
in addition to wilson's work which is the concept it is important to expose students

1082
01:05:07,280 --> 01:05:12,380
who may not be familiar with which goes by very pretentious name of universality

1083
01:05:12,460 --> 01:05:14,440
and this is the idea that all

1084
01:05:14,440 --> 01:05:18,460
interact in complex systems comprise the view on the matter what they are

1085
01:05:18,520 --> 01:05:21,270
can be partitioned into a finite number

1086
01:05:21,270 --> 01:05:27,770
or a small number of classes usually called universality classes and the definition of the

1087
01:05:27,770 --> 01:05:30,500
classes that all the systems in that class

1088
01:05:30,540 --> 01:05:36,420
have numerically the same values of the so very dramatic example of that is the

1089
01:05:36,420 --> 01:05:44,460
universality class for simple one-dimensional space so called i see these experiments that class encompasses

1090
01:05:44,460 --> 01:05:45,790
not only

1091
01:05:45,880 --> 01:05:47,400
systems like flu

1092
01:05:47,420 --> 01:05:48,840
right described

1093
01:05:48,860 --> 01:05:54,520
the main idea that of fluid is model but also binary mixtures of binary alloys

1094
01:05:54,520 --> 01:06:00,190
and the number of all the complicated systems and similar two-dimensional order parameters like helium

1095
01:06:00,440 --> 01:06:05,340
are describe different universality class three three-dimensional another so

1096
01:06:05,540 --> 01:06:15,040
so so that this these two concepts the concept of renormalisation group universality together give

1097
01:06:15,040 --> 01:06:20,190
us about the state of understanding that we have in critical point phenomena present

1098
01:06:20,210 --> 01:06:23,480
i don't think that they has increased dramatically

1099
01:06:24,000 --> 01:06:25,110
in recent years

1100
01:06:25,130 --> 01:06:32,880
what is needed is in my opinion the scots proprietary question is somewhat analogous calculation

1101
01:06:32,960 --> 01:06:37,320
we need to consider all sorts who can make the model

1102
01:06:37,340 --> 01:06:39,650
for something that we saw

1103
01:06:39,670 --> 01:06:43,690
in way for her defects the facts

1104
01:06:43,710 --> 01:06:49,420
that is very very light that's a model but a bit more complex because interactions

1105
01:06:49,420 --> 01:06:54,750
so anyway so here's a little methodology to check yourself so as i mentioned the

1106
01:06:54,750 --> 01:06:56,700
reason this is so important

1107
01:06:56,740 --> 01:07:01,100
is because this is in practice the thing that you

1108
01:07:01,770 --> 01:07:06,690
most of the time you don't just use the data structure as given

1109
01:07:06,770 --> 01:07:11,660
if you take a data structure say i my own operations i one layer this

1110
01:07:11,680 --> 01:07:15,400
so really the methodology and what i do as we go along as well as

1111
01:07:16,360 --> 01:07:19,320
of order statistics trees

1112
01:07:19,430 --> 01:07:26,130
to illustrate the methodology

1113
01:07:26,160 --> 01:07:27,710
course steps

1114
01:07:27,760 --> 01:07:29,460
OK the first is

1115
01:07:29,490 --> 01:07:30,670
we choose

1116
01:07:30,690 --> 01:07:32,810
an underlying data structure

1117
01:07:37,610 --> 01:07:45,120
which in the case of order statistics trees was one

1118
01:07:45,140 --> 01:07:46,880
a red black tree

1119
01:07:54,010 --> 01:07:55,790
the second thing we do

1120
01:07:55,830 --> 01:07:59,670
is we figure out what additional information

1121
01:07:59,730 --> 01:08:03,340
we wish to maintain in that data structure

1122
01:08:06,850 --> 01:08:21,790
which in this case is

1123
01:08:21,830 --> 01:08:22,890
it's the

1124
01:08:22,920 --> 01:08:24,940
subtree sizes

1125
01:08:24,980 --> 01:08:28,410
subtree sizes what we keep for this one

1126
01:08:28,440 --> 01:08:35,240
and you know what we do is we could make

1127
01:08:35,260 --> 01:08:39,210
mistakes right because it always keep the rank

1128
01:08:39,230 --> 01:08:41,600
we start playing with discovery

1129
01:08:41,630 --> 01:08:45,140
well can do that just because really slowly

1130
01:08:45,160 --> 01:08:48,240
take some creativity to figure out what's the information is going to be able to

1131
01:08:49,310 --> 01:08:52,230
we're going to be of also to maintain the other

1132
01:08:52,240 --> 01:08:54,790
other properties that you want

1133
01:08:54,800 --> 01:08:57,880
there's that is verify

1134
01:08:59,070 --> 01:09:00,950
the information

1135
01:09:02,690 --> 01:09:04,700
can be maintained

1136
01:09:09,030 --> 01:09:12,850
for the modifying operations on the data structure

1137
01:09:20,390 --> 01:09:22,480
and so

1138
01:09:22,650 --> 01:09:26,620
in this case for

1139
01:09:26,670 --> 01:09:30,580
for a red black tree for OS trees

1140
01:09:30,590 --> 01:09:35,380
we were the modifying operations were insert and delete

1141
01:09:35,400 --> 01:09:39,840
and of course we had to make sure we dealt with rotations care

1142
01:09:46,080 --> 01:09:51,550
because rotations are part of that

1143
01:09:51,550 --> 01:09:55,850
we could break it down into the tree and search tree delete and rotations and

1144
01:09:55,850 --> 01:09:57,950
once we've done that everything was fine

1145
01:09:58,070 --> 01:10:01,710
we didn't for this particular problem have to worry about color changes

1146
01:10:01,730 --> 01:10:05,010
but that's another thing that under some things

1147
01:10:05,060 --> 01:10:07,620
OK you might have to worry about

1148
01:10:07,650 --> 01:10:09,560
OK for some reason the

1149
01:10:09,560 --> 01:10:11,680
the color difference

1150
01:10:11,710 --> 01:10:14,320
usually that doesn't make a difference

1151
01:10:14,350 --> 01:10:19,150
the fourth step is to develop new operations

1152
01:10:20,330 --> 01:10:28,950
there's only use the intro

1153
01:10:29,140 --> 01:10:32,380
you have now stored

1154
01:10:32,400 --> 01:10:34,760
and this was worse

1155
01:10:36,420 --> 01:10:42,290
o rank which give but which is there and which also a nice little puzzle

1156
01:10:42,290 --> 01:10:45,020
to figure out yourself how you would feel that was right

1157
01:10:45,030 --> 01:10:46,580
now hard code

1158
01:10:48,770 --> 01:10:54,850
so this is actually this methodology is not actually the way you do this

1159
01:10:54,860 --> 01:10:57,110
as one of these things where you know

1160
01:10:57,150 --> 01:11:00,360
this is more like a checklist because

1161
01:11:00,360 --> 01:11:01,590
you know

1162
01:11:02,290 --> 01:11:05,830
check is see whether or not you got some of you know when actually doing

1163
01:11:05,830 --> 01:11:08,730
this may be developed in new operations first

1164
01:11:08,750 --> 01:11:14,170
keep in mind the new operations way of verifying the information you can the storing

1165
01:11:14,170 --> 01:11:19,060
can be here maybe you're then go back and change this is sort through it

1166
01:11:19,130 --> 01:11:22,730
this is more checklist that when you're done

1167
01:11:23,540 --> 01:11:25,880
this is how you write it up

1168
01:11:25,920 --> 01:11:27,560
OK this is how you say

1169
01:11:27,810 --> 01:11:31,850
i document that we've done is in fact a good thing ever checklist say here's

1170
01:11:31,850 --> 01:11:33,730
my underlying data structure

1171
01:11:33,810 --> 01:11:37,150
here's the additional information i need to see i can still

1172
01:11:37,170 --> 01:11:41,540
support the modifying operations that this structure used to have an now here my new

1173
01:11:41,540 --> 01:11:43,110
operations and c

1174
01:11:43,130 --> 01:11:44,330
he with those are

1175
01:11:44,380 --> 01:11:46,170
this is really a checklist

1176
01:11:46,170 --> 01:11:48,080
not a prescription

1177
01:11:48,080 --> 01:11:50,210
the order in which you do things

1178
01:11:50,230 --> 01:11:52,000
you must do all these steps

1179
01:11:52,020 --> 01:11:53,980
not necessarily in this work

1180
01:11:53,980 --> 01:11:58,260
OK so this is a guide for your documentation so when we ask the augmented

1181
01:11:58,260 --> 01:12:03,130
data structure generally were asking you to tell us what the four steps are to

1182
01:12:03,130 --> 01:12:07,420
help organize things and also help make sure you don't forget some step along the

1183
01:12:08,420 --> 01:12:12,880
OK so i think people who added the information and determine the

1184
01:12:12,880 --> 01:12:13,970
roll outs

1185
01:12:13,990 --> 01:12:18,610
and monte carlo search as when used you want to value state in u

1186
01:12:18,690 --> 01:12:24,350
will sample many many games and as a solution to the famous curse of dimensionality

1187
01:12:24,350 --> 01:12:26,310
so let's look at that little bit

1188
01:12:26,320 --> 01:12:30,900
the initial thesis is just the power sample based search is under appreciated

1189
01:12:32,160 --> 01:12:34,970
tree search

1190
01:12:34,980 --> 01:12:39,840
roll outs you can you can get you can work with simulators and find out

1191
01:12:39,840 --> 01:12:43,470
about the values of states we can do without a model that's what call reinforcement

1192
01:12:43,470 --> 01:12:47,530
learning because you if if you can work with samples and you actually need them

1193
01:12:47,530 --> 01:12:49,050
all world you can just

1194
01:12:49,080 --> 01:12:52,450
two things and get samples from the world itself

1195
01:12:52,650 --> 01:12:59,040
this scales really nicely with computation and the accuracy is often unaffected by this size

1196
01:12:59,040 --> 01:13:02,510
in the space so this is where getting the curse of dimensionality so look at

1197
01:13:02,510 --> 01:13:06,770
that little bit more the quality of sample based estimates

1198
01:13:06,790 --> 01:13:11,690
can be independent of the size of the state space often they will depend on

1199
01:13:11,690 --> 01:13:17,180
the number of samples on this i think is one of the key sources of

1200
01:13:17,180 --> 01:13:18,300
of power

1201
01:13:18,320 --> 01:13:23,620
so the example really prominent now is roll outs and monte carlo search in computer

1202
01:13:24,540 --> 01:13:28,590
so in computer go our state space is effectively infinite

1203
01:13:28,610 --> 01:13:30,100
but it doesn't matter

1204
01:13:30,120 --> 01:13:33,840
it doesn't matter so if you want to do some if you come to position

1205
01:13:33,840 --> 01:13:34,560
and you

1206
01:13:34,610 --> 01:13:38,980
two bunch of sample games from that position so senior policy

1207
01:13:38,980 --> 01:13:43,300
and you have a single position interest you can play games from that position using

1208
01:13:43,300 --> 01:13:44,220
a policy

1209
01:13:44,270 --> 01:13:49,560
we call those rollouts

1210
01:13:49,570 --> 01:13:52,840
and so if you want to get even though the value that state in one

1211
01:13:52,840 --> 01:13:56,440
percent you could just have two thousand rollouts

1212
01:13:56,450 --> 01:13:59,660
and it doesn't really matter how big the state space is going on within one

1213
01:13:59,660 --> 01:14:04,320
percent because the outcomes are zeros or ones were lost if you just average the

1214
01:14:04,320 --> 01:14:09,470
outcomes you can you'll get high quality result we get independent of the state

1215
01:14:09,570 --> 01:14:14,150
so here are some slides are still from the coulomb was one of the originators

1216
01:14:14,180 --> 01:14:16,130
of monte carlo

1217
01:14:16,210 --> 01:14:17,460
research in

1218
01:14:17,470 --> 01:14:19,010
computer go

1219
01:14:19,030 --> 01:14:23,090
so here suggests the ideas of place in a state of interest and we can

1220
01:14:23,090 --> 01:14:26,970
consider possible successors and from each one we can do a bunch of simulations we

1221
01:14:26,970 --> 01:14:32,770
actually play out sample games and a lot of research goes into

1222
01:14:32,790 --> 01:14:36,410
what policy should be used in the sample game because you want to be quick

1223
01:14:36,410 --> 01:14:39,470
and you want to have it as some of the properties but you can actually

1224
01:14:39,470 --> 01:14:44,720
do very good if you actually in computer go and surprisingly many games many problems

1225
01:14:45,010 --> 01:14:47,180
if you just do random o

1226
01:14:47,180 --> 01:14:50,970
if you just two lots of random was all legal moves pick from the random

1227
01:14:50,970 --> 01:14:54,440
go to your opponent of the his legal was picked from the random and you

1228
01:14:54,440 --> 01:15:00,440
just play out you actually even that works works pretty well in national methods they

1229
01:15:00,440 --> 01:15:01,350
use not

1230
01:15:01,380 --> 01:15:06,930
tremendously more sophisticated because they want to be able to make the samples very efficiently

1231
01:15:06,950 --> 01:15:13,400
so then having done sample some then we win some them will be losers and

1232
01:15:13,400 --> 01:15:16,660
then this one is winning nine times out of ten which is better than the

1233
01:15:16,660 --> 01:15:18,970
others then that might be the action you pick

1234
01:15:19,120 --> 01:15:24,410
and can this a little bit further you can use them user statistics instead of

1235
01:15:24,410 --> 01:15:27,450
doing random

1236
01:15:27,450 --> 01:15:32,300
instead of fame considering all possible moves equally you favour the ones that are doing

1237
01:15:32,300 --> 01:15:36,550
better than the children and you develop the tree rather than just the simple rule

1238
01:15:37,790 --> 01:15:41,870
and this has revolutionized the game go you may have heard you may have heard

1239
01:15:42,120 --> 01:15:46,680
people talk about goal is like an impossible problem right computers can play chess but

1240
01:15:46,680 --> 01:15:47,680
they can't really

1241
01:15:47,680 --> 01:15:53,160
think like humans and they can they can solve goes store more complex and spatial

1242
01:15:54,750 --> 01:15:57,610
it turns out that's not true we just didn't have the right method you with

1243
01:15:57,610 --> 01:16:03,680
monte carlo tree search last few years has revolutionized the field of computer go

1244
01:16:03,690 --> 01:16:10,600
this is a rough diagram the situation if we look at scale

1245
01:16:10,630 --> 01:16:16,600
the program's first versus time for many years things were going up slowly these are

1246
01:16:16,600 --> 01:16:18,230
all really poor

1247
01:16:18,230 --> 01:16:21,130
players is really like you and me or something

1248
01:16:21,210 --> 01:16:26,650
and this you know is actually easy not too difficult to get better than really

1249
01:16:26,650 --> 01:16:31,990
poor players but it was things were really leveling off and people were very

1250
01:16:32,010 --> 01:16:34,770
discouraged or

1251
01:16:34,780 --> 01:16:39,650
not pessimistic about making getting anywhere and then in about

1252
01:16:39,730 --> 01:16:45,830
like two thousand four people started sample based search methods and and first i got

1253
01:16:45,830 --> 01:16:49,420
up to par and then things just kept me skip it better and better and

1254
01:16:51,580 --> 01:16:56,670
we can say that even this is nineteen by nineteen gulf rule full-bore go

1255
01:16:56,780 --> 01:16:59,850
the we have master level players

1256
01:17:01,100 --> 01:17:05,880
it's it's it's very striking change and it's really all these two different ways search

1257
01:17:05,900 --> 01:17:10,610
you can can spread your search around differently when you samples as opposed to traditional

1258
01:17:13,320 --> 01:17:14,500
thank you

1259
01:17:14,500 --> 01:17:17,110
questions reactions good

1260
01:17:21,320 --> 01:17:26,590
so this thing

1261
01:17:26,610 --> 01:17:27,670
it's partly

1262
01:17:27,690 --> 01:17:29,210
and extrapolation

1263
01:17:29,230 --> 01:17:33,480
well it is an extrapolation no this scales really well search so just with more

1264
01:17:33,480 --> 01:17:34,690
is law

1265
01:17:35,000 --> 01:17:39,010
we have a good idea about what the slope is so i mean there's no

1266
01:17:39,090 --> 01:17:45,000
slide that that david silver who i got this information from has where we just

1267
01:17:45,000 --> 01:17:48,360
take one is the top programs like mogo fuego

1268
01:17:48,380 --> 01:17:52,780
and we vary the amount of computer power thereafter how many samples per move

1269
01:17:52,800 --> 01:17:57,570
and if you tell it there's there's a clear relationship you have more more more

1270
01:17:58,550 --> 01:18:03,480
my computer power more some more rollouts performances just goes up goes up and goes

1271
01:18:03,480 --> 01:18:04,360
up in

1272
01:18:04,420 --> 01:18:07,210
and it looks pretty much like

1273
01:18:07,460 --> 01:18:09,550
the world champion

1274
01:18:09,570 --> 01:18:11,530
human is is

1275
01:18:11,530 --> 01:18:14,530
and the cosine of five point seven degrees

1276
01:18:14,620 --> 01:18:16,360
is one

1277
01:18:16,370 --> 01:18:18,550
four physicist at least

1278
01:18:18,620 --> 01:18:20,100
so therefore

1279
01:18:20,160 --> 01:18:24,510
for all systems of IQ is not absurdly low

1280
01:18:24,530 --> 01:18:26,220
you can say that q one

1281
01:18:26,240 --> 01:18:29,510
people's minus q max

1282
01:18:29,530 --> 01:18:32,800
output here we go

1283
01:18:32,820 --> 01:18:35,490
but it's an extremely good approximation

1284
01:18:35,550 --> 01:18:36,910
so therefore

1285
01:18:36,930 --> 01:18:38,640
my solution here

1286
01:18:38,660 --> 01:18:40,510
you can now be changed

1287
01:18:40,550 --> 01:18:42,820
by simply replacing

1288
01:18:42,870 --> 01:18:45,870
the q one

1289
01:18:48,660 --> 01:18:52,030
and through it should be in approximately

1290
01:18:52,030 --> 01:18:53,590
but the approximation

1291
01:18:53,600 --> 01:18:56,050
is extremely close

1292
01:18:56,090 --> 01:18:59,760
the pencil q

1293
01:18:59,840 --> 01:19:02,620
if not you want to plant this

1294
01:19:02,680 --> 01:19:06,910
you can of course something completely similar to what you have here

1295
01:19:07,970 --> 01:19:10,870
that you do not and up zero

1296
01:19:10,870 --> 01:19:16,640
the q is not zero but it's offset by this qx

1297
01:19:18,700 --> 01:19:20,740
if this is the

1298
01:19:20,740 --> 01:19:24,490
if this is zero

1299
01:19:24,530 --> 01:19:28,840
and this is qx

1300
01:19:28,890 --> 01:19:30,700
which is where ultimately

1301
01:19:30,740 --> 01:19:34,120
the charge will be if you wait long enough

1302
01:19:34,160 --> 01:19:36,050
then to plot now this

1303
01:19:42,840 --> 01:19:47,300
will then give me a group like this

1304
01:19:47,320 --> 01:19:49,870
very careful the period

1305
01:19:49,950 --> 01:19:54,050
is uniquely determined to area does not change

1306
01:19:54,100 --> 01:19:56,680
that's determined by that omega

1307
01:19:56,680 --> 01:19:59,930
two pi divided by this omega is the period

1308
01:19:59,970 --> 01:20:08,890
so you're going to get you started with q zero

1309
01:20:08,970 --> 01:20:10,180
and you see

1310
01:20:10,220 --> 01:20:13,120
if you wait long enough you end up with q max

1311
01:20:13,180 --> 01:20:14,760
it is this one

1312
01:20:14,800 --> 01:20:17,720
whereas in the case of the spring if you wait long enough

1313
01:20:17,740 --> 01:20:23,180
you end up with nothing x equals zero

1314
01:20:23,200 --> 01:20:24,530
and this is something

1315
01:20:24,570 --> 01:20:26,550
that i can

1316
01:20:26,590 --> 01:20:28,370
demonstrate to you

1317
01:20:28,430 --> 01:20:29,590
in very

1318
01:20:29,640 --> 01:20:33,620
very nice way i must say i find is one of the most

1319
01:20:33,660 --> 01:20:36,200
intriguing demonstrations

1320
01:20:36,220 --> 01:20:39,140
instead of having a battery

1321
01:20:39,200 --> 01:20:42,260
and throw better in which case you would only

1322
01:20:42,300 --> 01:20:47,280
for an extremely short amount of time

1323
01:20:47,320 --> 01:20:49,680
for the amount of time which is roughly

1324
01:20:49,700 --> 01:20:51,590
through divided by gamma

1325
01:20:53,370 --> 01:20:56,160
which may only be many seconds you would see

1326
01:20:56,200 --> 01:20:58,070
this thing

1327
01:20:58,100 --> 01:21:00,970
but we want to give you more than a few milliseconds

1328
01:21:01,010 --> 01:21:03,240
and therefore what we do

1329
01:21:05,050 --> 01:21:07,410
replace the battery

1330
01:21:10,090 --> 01:21:12,070
seventy seconds

1331
01:21:12,180 --> 01:21:15,620
constant voltage

1332
01:21:15,640 --> 01:21:17,370
and we repeat that

1333
01:21:17,470 --> 01:21:21,470
and every time

1334
01:21:21,490 --> 01:21:23,700
we show you this portion

1335
01:21:23,720 --> 01:21:28,450
so you will see it on the tectonics

1336
01:21:28,470 --> 01:21:32,200
we train with every time it comes up here and then it comes up here

1337
01:21:32,260 --> 01:21:34,780
and you will see that

1338
01:21:34,870 --> 01:21:38,300
this will be staring you in the face

1339
01:21:38,370 --> 01:21:42,680
i'm going to give you the values that i will be using so you can

1340
01:21:42,720 --> 01:21:45,490
digest that home exactly

1341
01:21:45,510 --> 01:21:47,930
what you are going to see

1342
01:21:47,970 --> 01:21:51,910
and what all the constants are in this problem

1343
01:21:51,950 --> 01:21:53,090
we are

1344
01:21:53,100 --> 01:21:56,720
it's going to be fifty ohms

1345
01:21:57,760 --> 01:21:59,510
it's going to be fifty

1346
01:21:59,570 --> 01:22:01,720
many at least

1347
01:22:01,720 --> 01:22:05,010
ten to the minus three

1348
01:22:05,010 --> 01:22:08,450
so that tells me that got my

1349
01:22:08,470 --> 01:22:14,510
is one thousand is are over l

1350
01:22:14,570 --> 01:22:16,140
that tells me that

1351
01:22:16,240 --> 01:22:20,120
two divided by got my which is the one of e decay time

1352
01:22:20,160 --> 01:22:22,720
it is then too seconds

1353
01:22:27,510 --> 01:22:30,160
it's going to be o point o six

1354
01:22:30,180 --> 01:22:32,800
micro for

1355
01:22:32,840 --> 01:22:34,590
that would give you a

1356
01:22:34,680 --> 01:22:38,740
omega zero if you interested in only garcia i never have a good feeling for

1357
01:22:38,740 --> 01:22:40,120
omega guys i like

1358
01:22:41,180 --> 01:22:44,320
it's much better but if you are interested in omega zero

1359
01:22:44,340 --> 01:22:46,930
which is one over the square root

1360
01:22:48,160 --> 01:22:52,660
that would be eighteen point three times ten two two thirds

1361
01:22:52,660 --> 01:22:55,680
and that is radians per second

1362
01:22:55,760 --> 01:22:59,260
the frequency in hertz

1363
01:22:59,280 --> 01:23:03,870
which is two pi lower is then twenty nine

1364
01:23:03,870 --> 01:23:05,950
o six hundred

1365
01:23:06,130 --> 01:23:10,680
so now you have also q

1366
01:23:10,700 --> 01:23:15,320
which is omega zero divided by gamma

1367
01:23:15,340 --> 01:23:16,470
and that q

1368
01:23:16,490 --> 01:23:18,740
is no eighteen point three

1369
01:23:18,820 --> 01:23:25,950
and that means q divided by pi

1370
01:23:25,950 --> 01:23:27,220
which is the

1371
01:23:27,220 --> 01:23:29,050
the problem i called

1372
01:23:29,070 --> 01:23:31,680
q divided by pi which is

1373
01:23:31,720 --> 01:23:35,240
the number of oscillations that you have to wait

1374
01:23:35,280 --> 01:23:39,320
for this function to go down by a factor of the men we did that

1375
01:23:39,320 --> 01:23:40,640
with the pendulum

1376
01:23:40,660 --> 01:23:42,100
that is now

1377
01:23:42,120 --> 01:23:44,220
about five point eight

1378
01:23:44,320 --> 01:23:50,280
so we're going to take a look at the kind of like that

1379
01:23:50,410 --> 01:23:52,600
and then we go into in the czech

1380
01:23:52,600 --> 01:23:53,960
and two or three

1381
01:23:53,980 --> 01:23:57,670
so let's go again because this is tricky

1382
01:23:57,730 --> 01:24:01,630
so let's look at this but here the first thing you should look at is

1383
01:24:01,630 --> 01:24:06,060
that if there an the tail to tail or head to tail

1384
01:24:06,110 --> 01:24:10,690
immediately these graph here has an observer tail to tail node

1385
01:24:10,750 --> 01:24:11,980
for this

1386
01:24:12,020 --> 01:24:15,610
so this is what we need

1387
01:24:15,730 --> 01:24:17,370
this is block

1388
01:24:17,440 --> 01:24:21,750
because you have these sorts of

1389
01:24:21,790 --> 01:24:27,900
these that look now let's assume that we didn't have because of for efficiency

1390
01:24:27,940 --> 01:24:29,750
i assume that you have full service

1391
01:24:30,920 --> 01:24:32,520
now these back here

1392
01:24:32,540 --> 01:24:34,100
it's not a black and white

1393
01:24:34,150 --> 01:24:37,480
any observation

1394
01:24:37,580 --> 01:24:42,130
so we can only be blocked if there is a had no

1395
01:24:42,170 --> 01:24:45,650
which is not observed in which is not observed

1396
01:24:45,650 --> 01:24:48,830
these are not observed and should not so

1397
01:24:48,850 --> 01:24:51,940
we assume that c not

1398
01:24:52,040 --> 01:24:56,170
so in that case it will people

1399
01:24:56,190 --> 01:25:03,020
you see is not well

1400
01:25:03,100 --> 01:25:05,000
ATC is not what

1401
01:25:05,870 --> 01:25:07,040
eight soon

1402
01:25:07,060 --> 01:25:08,520
there is only one

1403
01:25:09,650 --> 01:25:11,170
to be considered

1404
01:25:11,170 --> 01:25:13,040
which is this guy in the middle

1405
01:25:13,060 --> 01:25:16,360
you want to nodes in the middle of the that the ones in the in

1406
01:25:16,360 --> 01:25:17,980
the end you consider

1407
01:25:18,040 --> 01:25:23,600
because they only have one which once head back

1408
01:25:23,610 --> 01:25:28,980
and these is known for these that here there is no this one

1409
01:25:29,020 --> 01:25:32,460
which type of node is this one for this

1410
01:25:32,480 --> 01:25:35,630
page head to tail

1411
01:25:36,440 --> 01:25:39,500
forty four this sparsity block

1412
01:25:39,560 --> 01:25:43,650
i had to tails models need to be observed

1413
01:25:43,790 --> 01:25:45,540
is this absurd

1414
01:25:46,100 --> 01:25:48,960
sort of work

1415
01:25:52,830 --> 01:25:54,000
from a to b

1416
01:26:02,420 --> 01:26:05,560
depend on the path of particle which

1417
01:26:05,600 --> 01:26:07,230
from a to b

1418
01:26:07,250 --> 01:26:08,880
which that

1419
01:26:08,880 --> 01:26:11,960
so you have one had here

1420
01:26:11,980 --> 01:26:16,380
yes you have one from it to be

1421
01:26:16,400 --> 01:26:18,830
what's the questions

1422
01:26:21,580 --> 01:26:26,190
with respect to that that's thing with respect to this that here

1423
01:26:26,270 --> 01:26:27,440
noel e

1424
01:26:27,440 --> 01:26:28,920
his head tail

1425
01:26:28,960 --> 01:26:30,830
with respect to these that

1426
01:26:32,480 --> 01:26:35,500
note is head to head

1427
01:26:35,540 --> 01:26:40,190
so it is with respect to the back

1428
01:26:43,440 --> 01:26:47,100
so this is something new to

1429
01:26:50,230 --> 01:26:53,770
thinking about after the class

1430
01:26:57,560 --> 01:26:58,830
now we

1431
01:26:58,830 --> 01:27:00,730
come to the final concept

1432
01:27:00,750 --> 01:27:01,830
which is the cause

1433
01:27:01,830 --> 01:27:08,770
concept of the separation and i want to see the condition part the rules

1434
01:27:08,790 --> 01:27:09,830
we just say

1435
01:27:09,850 --> 01:27:13,520
that is a set of nodes if i have here

1436
01:27:13,560 --> 01:27:17,790
the set of old

1437
01:27:19,210 --> 01:27:20,940
is the

1438
01:27:20,940 --> 01:27:23,270
this is used to be

1439
01:27:23,420 --> 01:27:29,610
a wonderful wonderful

1440
01:27:29,650 --> 01:27:31,560
i say that

1441
01:27:31,650 --> 01:27:33,710
a and b

1442
01:27:33,750 --> 01:27:37,380
are separated by c

1443
01:27:43,560 --> 01:27:48,350
separated because of direct separation because this the

1444
01:27:48,350 --> 01:27:50,310
that's why we it

1445
01:27:50,310 --> 01:27:54,880
see that in your disappointed by c

1446
01:27:54,880 --> 01:28:00,580
but the feeling that there always is tangent to the curve because this curve is

1447
01:28:00,580 --> 01:28:04,330
trajectory is always supposed to be going in the direction

1448
01:28:04,350 --> 01:28:08,580
given by the way i feel that there

1449
01:28:08,600 --> 01:28:09,650
it follow

1450
01:28:09,760 --> 01:28:12,570
a trajectory means it is always

1451
01:28:14,350 --> 01:28:17,830
to the field that there and therefore always perpendicular

1452
01:28:17,850 --> 01:28:19,330
the the normal vector

1453
01:28:20,390 --> 01:28:23,670
it's equal to this is zero

1454
01:28:31,390 --> 01:28:35,110
died in is always zero

1455
01:28:35,200 --> 01:28:41,140
everywhere on the curve that it has be here

1456
01:28:41,180 --> 01:28:46,990
there is no flux of this field across the curve because the field is always

1457
01:28:47,050 --> 01:28:49,210
in the same direction as the curve

1458
01:28:49,260 --> 01:28:53,310
never perpendicular to it has no component perpendicular to

1459
01:28:55,130 --> 01:28:58,550
now let's do it the hard way let's use green's theorem

1460
01:28:58,570 --> 01:29:01,870
so by green's theorem says that the flux

1461
01:29:01,880 --> 01:29:03,060
across c

1462
01:29:03,130 --> 01:29:07,500
should be able to the double integral over the region of one of the divergence

1463
01:29:07,510 --> 01:29:09,150
of that

1464
01:29:09,220 --> 01:29:12,720
it's like grouses theorem in two dimensions this version of it

1465
01:29:12,740 --> 01:29:15,750
so the divergence of and that's the function

1466
01:29:15,770 --> 01:29:21,510
i double integrated over the regions and then that's the XTY relaxing a because you

1467
01:29:21,510 --> 01:29:24,140
might want to do in polar coordinates

1468
01:29:24,150 --> 01:29:28,830
and the problems that you certainly will want to do it in public or

1469
01:29:28,890 --> 01:29:29,660
i think

1470
01:29:31,220 --> 01:29:38,720
right how much is that

1471
01:29:38,770 --> 01:29:41,470
well we haven't yet use the hypothesis

1472
01:29:41,480 --> 01:29:45,140
well we don't set up the problem now the hypothesis was

1473
01:29:45,180 --> 01:29:49,480
the divergence is never zero anywhere in the

1474
01:29:49,550 --> 01:29:53,370
therefore the divergence is never zero anywhere in are

1475
01:29:55,720 --> 01:30:02,280
what i say is the divergence is either greater than zero

1476
01:30:05,210 --> 01:30:06,890
in are

1477
01:30:09,950 --> 01:30:11,550
less than zero

1478
01:30:11,570 --> 01:30:14,130
everywhere in our

1479
01:30:14,130 --> 01:30:20,100
but it cannot be sometimes europe posit and sometimes negative why not in other words

1480
01:30:20,100 --> 01:30:20,850
i say

1481
01:30:20,860 --> 01:30:26,360
it's not possible the divergence here is one here minus two

1482
01:30:26,370 --> 01:30:28,170
that's not possible

1483
01:30:28,180 --> 01:30:32,450
because if i draw a line from this point on

1484
01:30:32,460 --> 01:30:35,960
along that line the divergence would start positive

1485
01:30:35,980 --> 01:30:40,770
and up negative and therefore have to be zero sometime in between

1486
01:30:40,820 --> 01:30:44,620
because it's a continuous function

1487
01:30:44,660 --> 01:30:51,040
it's a continuous function i'm assuming that therefore sometimes positive sometimes negative has to be

1488
01:30:51,040 --> 01:30:53,540
zero in between

1489
01:30:53,600 --> 01:30:57,560
you can get continuously from plus one to minus two with that i think is

1490
01:31:02,630 --> 01:31:06,380
so the reason for this is since

1491
01:31:06,440 --> 01:31:09,260
since the divergence is

1492
01:31:09,290 --> 01:31:11,970
never zero

1493
01:31:12,020 --> 01:31:15,360
in or

1494
01:31:15,510 --> 01:31:19,140
therefore must always stay positive are always the negative

1495
01:31:19,190 --> 01:31:21,660
now if it always stays positive

1496
01:31:21,670 --> 01:31:23,310
the conclusion is

1497
01:31:23,330 --> 01:31:28,770
if is always positive then this double integral must be positive for this integral is

1498
01:31:31,680 --> 01:31:33,210
this double integrals

1499
01:31:33,220 --> 01:31:34,720
is either

1500
01:31:34,720 --> 01:31:38,740
greater than zero that's the divergence is always positive or

1501
01:31:38,750 --> 01:31:42,960
it's less than zero if the divergence is always negative but the one thing it

1502
01:31:42,980 --> 01:31:45,450
cannot be is not

1503
01:31:48,890 --> 01:31:53,000
well so the left hand side agrees theorem is supposed to be true

1504
01:31:53,100 --> 01:31:56,460
we've got to start with the same as the bedrock

1505
01:31:56,460 --> 01:32:00,470
eighteen o two would crumble without that so must be true

1506
01:32:02,660 --> 01:32:06,770
one way of calculating the left hand side is zero

1507
01:32:06,820 --> 01:32:11,280
we calculate the right hand side is not zero that's called the contradiction

1508
01:32:13,390 --> 01:32:19,230
with the contradiction arises from a contradiction arises from the fact that i suppose that

1509
01:32:19,260 --> 01:32:22,860
there were was closed trajectory in that region

1510
01:32:22,900 --> 01:32:27,410
so the conclusion is that cannot be closed trajectory that region because it leads to

1511
01:32:27,410 --> 01:32:33,380
a contradiction degrees here

1512
01:32:37,400 --> 01:32:40,970
let me see if i can give you some of the arguments for the other

1513
01:32:41,190 --> 01:32:43,860
well let let's at least eight other

1514
01:32:43,910 --> 01:32:55,060
criteria i want to you

1515
01:32:55,080 --> 01:32:57,960
suppose for example we use the

1516
01:32:58,000 --> 01:33:02,330
this is the next prime equals

1517
01:33:06,530 --> 01:33:27,760
the set limit cycles

1518
01:33:27,780 --> 01:33:36,270
there's that a limit cycles

1519
01:33:37,230 --> 01:33:44,000
but then

1520
01:33:45,390 --> 01:33:48,350
we calculate the divergence of the vector field

1521
01:33:49,370 --> 01:33:52,430
two x from the top

1522
01:33:52,450 --> 01:33:56,640
function the partial with respect to access to x the portion with the second function

1523
01:33:56,640 --> 01:34:03,430
with respect to y is negative to y

1524
01:34:03,480 --> 01:34:06,810
well that certainly can be zero in fact this is zero

1525
01:34:06,830 --> 01:34:10,410
along the entire line x equals y

1526
01:34:10,430 --> 01:34:13,040
it's divergence is zero here

1527
01:34:13,060 --> 01:34:17,750
along the whole line

1528
01:34:17,850 --> 01:34:20,620
so the best i could conclude was

1529
01:34:20,660 --> 01:34:24,230
i could conclude that there is no limit cycle like this

1530
01:34:24,250 --> 01:34:29,620
none is no limit cycle like this

1531
01:34:30,930 --> 01:34:32,180
there's nothing

1532
01:34:32,180 --> 01:34:34,120
and there is a whole

1533
01:34:34,160 --> 01:34:37,730
there's a whole suite of area is basically a loop of areas are connected in

1534
01:34:37,730 --> 01:34:42,280
the brain areas in the prefrontal cortex areas in the elements each of them if

1535
01:34:42,280 --> 01:34:46,610
you wish and you lose this habitual behavior so there seems to be a whole

1536
01:34:46,610 --> 01:34:52,220
group of areas that are involved in visual learning

1537
01:34:52,230 --> 01:34:56,490
on the other hand is another loop another host various

1538
01:34:56,550 --> 01:34:58,430
another group of various

1539
01:34:58,520 --> 01:35:01,560
the dorsal medial striatum in various there

1540
01:35:01,940 --> 01:35:06,120
related to its as a slightly different part of the strait where if you lesion

1541
01:35:07,480 --> 01:35:12,240
you get the opposite you get animals are always habitual right from the very beginning

1542
01:35:14,060 --> 01:35:16,730
this is the best part of it in the world because these are very both

1543
01:35:16,730 --> 01:35:20,080
of them are very well but the idea is the regular behaviour here after short

1544
01:35:21,190 --> 01:35:24,560
is this the difference between the developed and undeveloped

1545
01:35:24,570 --> 01:35:26,400
and there is no difference

1546
01:35:26,400 --> 01:35:30,360
after relation in the past year or so we go straight come in other experiments

1547
01:35:30,360 --> 01:35:34,310
these two words high is this one this experiment is

1548
01:35:34,360 --> 01:35:39,370
bad choice on my part but there are many experiments showing this

1549
01:35:39,550 --> 01:35:41,180
so the idea is

1550
01:35:42,910 --> 01:35:44,270
there's a whole

1551
01:35:44,310 --> 01:35:48,310
loop in the brain that is responsible for goal directed learning and if that doesn't

1552
01:35:48,310 --> 01:35:50,940
exist from the very beginning animals are habitual

1553
01:35:51,080 --> 01:35:54,560
or they don't show sensitivity to devaluation

1554
01:35:54,570 --> 01:35:59,890
right from the beginning of training

1555
01:35:59,900 --> 01:36:02,340
so what does all this mean

1556
01:36:02,360 --> 01:36:05,490
on one hand we have learned one thing we've learned the same action that we

1557
01:36:05,490 --> 01:36:07,900
look at we see the rat leverpressing

1558
01:36:07,910 --> 01:36:13,510
it can arise from two psychologically dissociable pathways so the fact that these leverpressing doesn't

1559
01:36:13,510 --> 01:36:15,410
tell us why he's leverpressing

1560
01:36:15,550 --> 01:36:19,750
until we test with evaluation we can see that he might be leverpressing in called

1561
01:36:19,750 --> 01:36:21,050
directed way

1562
01:36:21,060 --> 01:36:27,110
dependent on outcome representation putting that together with the contingencies or you may be pressing

1563
01:36:27,110 --> 01:36:31,440
in habitual way just because all this is the lover i press lovers

1564
01:36:31,490 --> 01:36:35,730
now because this slavers gonna give me food

1565
01:36:35,740 --> 01:36:39,760
same as tried right get into this car i get to the disjunction i take

1566
01:36:39,770 --> 01:36:42,270
the right to see stimulus response

1567
01:36:42,310 --> 01:36:49,150
that's the habitual and goal directed i'm going home so i take a right

1568
01:36:49,160 --> 01:36:55,940
and to complement this association the psychological dissociation there's also the lesions suggest that there

1569
01:36:55,940 --> 01:36:58,140
are too narrowly dissociable

1570
01:36:58,150 --> 01:37:03,520
parallel systems in the brain that support each type of this behaviour of behaviour and

1571
01:37:03,520 --> 01:37:07,700
they can support any stage of training if the other what isn't there the the

1572
01:37:07,700 --> 01:37:12,800
second one can if one is in their second one takes over

1573
01:37:12,850 --> 01:37:15,900
so what we asked here this is the study done by

1574
01:37:15,930 --> 01:37:17,400
my colleague nathaniel daw

1575
01:37:17,440 --> 01:37:23,980
myself peter that was can reinforcement learning help us make any sense

1576
01:37:23,980 --> 01:37:25,200
of this

1577
01:37:25,220 --> 01:37:29,520
behavioral mass

1578
01:37:29,550 --> 01:37:33,940
and this led us to think about reinforcement learning and the two main strategies in

1579
01:37:33,940 --> 01:37:37,060
reinforcement learning model based model free

1580
01:37:37,080 --> 01:37:39,660
so think of the task like this

1581
01:37:39,680 --> 01:37:44,480
set of leverpressing it's hard to draw the leverpressing MDP although it

1582
01:37:44,560 --> 01:37:48,570
it's not that difficult but it's easier to draw an MDP four

1583
01:37:48,650 --> 01:37:52,900
four so the right here is navigating the maze and tries to get the maximum

1584
01:37:52,900 --> 01:37:54,650
reward has to choose

1585
01:37:54,650 --> 01:37:59,900
what to go left or right the reward this rat-like moses cheese that's why worth

1586
01:38:00,690 --> 01:38:04,060
compared to carrots in water

1587
01:38:04,060 --> 01:38:07,030
and we know that there are two ways to solve this problem the model based

1588
01:38:07,030 --> 01:38:12,610
one is learned the map of the task learn the contingency plan the transition state

1589
01:38:12,610 --> 01:38:15,600
one take left you get to stay two groups

1590
01:38:15,610 --> 01:38:19,050
this should have been zero one two

1591
01:38:20,100 --> 01:38:23,060
and the values of the rewards and then

1592
01:38:23,120 --> 01:38:27,080
if you have these transitions this reward function you can use

1593
01:38:27,100 --> 01:38:30,220
your favourite model based methods

1594
01:38:30,270 --> 01:38:34,900
dynamic programming or any other method of look ahead of planning

1595
01:38:34,900 --> 01:38:38,440
and figure out what is the value of taking the left here and taking the

1596
01:38:38,440 --> 01:38:41,990
right here it's taking left to say

1597
01:38:42,940 --> 01:38:48,440
taking right so taking left the value before taking right the value would be too

1598
01:38:48,450 --> 01:38:50,430
so far the rest should

1599
01:38:50,430 --> 01:38:54,510
go left

1600
01:38:54,560 --> 01:38:56,260
and importantly this is

1601
01:38:56,280 --> 01:39:00,160
computed on the fly so the dynamic programming problem has to be solved on the

1602
01:39:00,160 --> 01:39:04,620
fly which means this computationally costly it can take a while especially if the maze

1603
01:39:04,620 --> 01:39:05,900
is bigger

1604
01:39:05,910 --> 01:39:08,150
but it's also flexible

1605
01:39:08,150 --> 01:39:11,980
and immediately sensitive to change because if the rat learns that

1606
01:39:11,980 --> 01:39:16,060
the reward function here has change it will immediately affect

1607
01:39:16,060 --> 01:39:20,030
the computed value of taking left in state

1608
01:39:20,080 --> 01:39:23,680
in the initial state here

1609
01:39:23,690 --> 01:39:26,870
so this is a model based reinforcement learning

1610
01:39:26,930 --> 01:39:30,870
on the other hand we can solve the same exact task with model free reinforcement

1611
01:39:30,870 --> 01:39:32,080
the so it

1612
01:39:32,080 --> 01:39:37,520
we ran the shape context things that i mentioned yesterday around them because high dimensional

1613
01:39:37,520 --> 01:39:39,790
description histogram based description

1614
01:39:39,810 --> 01:39:40,870
the shape

1615
01:39:40,910 --> 01:39:43,330
and then we vector quantized in that space

1616
01:39:43,350 --> 01:39:47,210
to get an output signal that we can use the advantages of this is that

1617
01:39:47,210 --> 01:39:51,730
when you extract silhouettes in real images you get sets attacked sometimes extraction method doesn't

1618
01:39:51,730 --> 01:39:54,390
work so pieces of the model missing

1619
01:39:54,440 --> 01:39:57,890
but if you only look locally this got past model right

1620
01:39:58,250 --> 01:40:04,160
and that can be signal that you can use to do the regression correctly

1621
01:40:04,730 --> 01:40:09,980
so this video to

1622
01:40:10,000 --> 01:40:14,350
so you can see also silhouette extraction is by no means perfect we still reasonably

1623
01:40:14,350 --> 01:40:17,390
convincing will commission from that

1624
01:40:17,850 --> 01:40:24,270
just ring is just the alignment process for the

1625
01:40:24,290 --> 01:40:27,710
and there is no space and

1626
01:40:27,850 --> 01:40:31,910
OK now you can also do this

1627
01:40:31,910 --> 01:40:36,440
what's images rather than so it's in there we use these guinness histogram of oriented

1628
01:40:36,440 --> 01:40:39,660
gradient descriptors to get a nice high dimensional representation

1629
01:40:39,710 --> 01:40:42,210
we had a nice novel

1630
01:40:42,250 --> 01:40:47,230
statements which is that if you do this thing and you've got for example tree

1631
01:40:47,230 --> 01:40:51,690
or pole or not sure if something in the background you get these spurious edges

1632
01:40:51,690 --> 01:40:52,640
and the model

1633
01:40:52,980 --> 01:40:54,980
which tend to study the regressor

1634
01:40:55,000 --> 01:40:59,000
so what we did to reduce that is that we learned anomaly to make matrix

1635
01:41:00,500 --> 01:41:02,060
of the dossier

1636
01:41:02,080 --> 01:41:05,690
i don't know if you guys know one the next matrix factorisation is OK so

1637
01:41:05,960 --> 01:41:08,140
you can think of about this is

1638
01:41:09,370 --> 01:41:12,060
but with the match these have to be both

1639
01:41:12,080 --> 01:41:14,520
make both sides have positive

1640
01:41:14,540 --> 01:41:19,460
so the positivity constraints so it doesn't give you orthogonal matrices out but it does

1641
01:41:19,460 --> 01:41:25,940
give you a nonnegative decomposition of the signal so all the basis vectors have two

1642
01:41:25,940 --> 01:41:29,540
positive and the coefficients positive so things can add

1643
01:41:29,560 --> 01:41:34,600
and what that means is that if you get all stuff that happens

1644
01:41:34,640 --> 01:41:36,020
only occasionally

1645
01:41:36,430 --> 01:41:39,080
the were basis vector devoted to it

1646
01:41:39,100 --> 01:41:42,390
so there's nothing that can add up to that thing and they forget suppressed from

1647
01:41:43,330 --> 01:41:45,940
it's only the things that happen consistently

1648
01:41:45,940 --> 01:41:50,660
they give basis vectors and therefore i think they will get non negative coefficients in

1649
01:41:50,660 --> 01:41:52,140
the final model

1650
01:41:52,270 --> 01:41:57,350
that's why that works with it

1651
01:41:57,430 --> 01:42:01,440
getting a lot of it yesterday

1652
01:42:01,440 --> 01:42:05,960
so we added artificial class here just to show the models quite resistant crops

1653
01:42:05,980 --> 01:42:16,040
because it's not perfect but it's it's at least a reasonable first approximation

1654
01:42:20,330 --> 01:42:24,520
on two trying to learn priors for human motion so humans too

1655
01:42:24,540 --> 01:42:26,430
all sorts of strange motions

1656
01:42:26,430 --> 01:42:29,410
even walking is an incredibly complicated motions

1657
01:42:30,290 --> 01:42:34,350
and if you want to capture that any kind of

1658
01:42:34,410 --> 01:42:38,430
system we want to use it to predict the motion person tracking

1659
01:42:38,460 --> 01:42:43,690
or to to do motion capture is made the movement in three d

1660
01:42:45,020 --> 01:42:48,890
you basically down to doing semantic because there's no other way to to to capture

1661
01:42:48,890 --> 01:42:50,940
the context the statistics

1662
01:42:51,250 --> 01:42:55,310
so this was an interesting model that came up fairly recently

1663
01:42:55,640 --> 01:42:59,600
he uses what's called casting process latent variable models

1664
01:42:59,910 --> 01:43:04,350
so you digestive processes that you to guessing process processes just

1665
01:43:04,430 --> 01:43:06,870
kind of regression methods

1666
01:43:06,890 --> 01:43:10,020
that gives you a probabilistic estimate

1667
01:43:10,060 --> 01:43:11,060
it's not for

1668
01:43:11,390 --> 01:43:15,730
latent variable models the model that has some hidden variables and

1669
01:43:15,750 --> 01:43:17,460
the way this works

1670
01:43:17,460 --> 01:43:20,140
is that it learns

1671
01:43:20,140 --> 01:43:22,290
the hidden variable model

1672
01:43:22,310 --> 01:43:24,690
so it's the kind of dimensionality reduction

1673
01:43:24,710 --> 01:43:30,640
in this reduced dimensional space is learned probability distribution for the kinds of motions kinds

1674
01:43:30,640 --> 01:43:35,430
of positions and movements that the first doing this reduced dimensional representation

1675
01:43:35,520 --> 01:43:40,390
and then to go to the high dimensional representation given by the visual signals uses

1676
01:43:40,430 --> 01:43:42,540
guassian process again you've got

1677
01:43:42,560 --> 01:43:44,270
a probabilistic model

1678
01:43:44,310 --> 01:43:48,670
both models fully probabilistic which gives you full probabilistic

1679
01:43:49,060 --> 01:43:53,830
characterisation the possible motions in high dimensional space in terms of two

1680
01:43:54,350 --> 01:43:59,670
relatively simple components these this simple because low dimensional and the gas prices you kind

1681
01:43:59,670 --> 01:44:02,790
of you know what the statistics are so

1682
01:44:02,890 --> 01:44:05,710
you kind of can control that side of things

1683
01:44:06,660 --> 01:44:12,430
so does this by a kind of expectation maximisation or optimisation procedure

1684
01:44:12,440 --> 01:44:13,690
the that

1685
01:44:13,730 --> 01:44:15,440
finds a good

1686
01:44:15,480 --> 01:44:18,540
low dimensional space in good positions in that space

1687
01:44:18,540 --> 01:44:22,060
nodes and you and can also so you see how to build up there

1688
01:44:22,080 --> 01:44:22,880
and then

1689
01:44:22,970 --> 01:44:24,980
the same time we can measure

1690
01:44:25,300 --> 01:44:27,620
the speed of sound

1691
01:44:27,640 --> 01:44:29,990
the only reason why we make this and

1692
01:44:31,190 --> 01:44:33,500
is that

1693
01:44:33,550 --> 01:44:34,990
as i move it

1694
01:44:34,990 --> 01:44:36,100
and bring the my

1695
01:44:36,130 --> 01:44:37,640
first and note

1696
01:44:37,650 --> 01:44:41,420
i can make sure that the link is just a resonance

1697
01:44:41,430 --> 01:44:43,340
and so that's just my beginning

1698
01:44:43,360 --> 01:44:49,170
to make sure that the node is as close to zero as possible can be

1699
01:44:49,170 --> 01:44:50,680
so if we know

1700
01:44:50,730 --> 01:44:55,460
get the

1701
01:44:55,470 --> 01:44:57,610
image up there

1702
01:44:57,640 --> 01:45:01,190
and i think we're going to get light situation

1703
01:45:01,220 --> 01:45:05,030
like this

1704
01:45:06,110 --> 01:45:09,000
going to

1705
01:45:09,100 --> 01:45:12,800
one of the sound

1706
01:45:12,810 --> 01:45:16,550
it is the sound

1707
01:45:16,560 --> 01:45:21,050
i can turn up the volume so you can use that

1708
01:45:21,060 --> 01:45:23,070
the school connected

1709
01:45:23,090 --> 01:45:25,150
are you of course thank you

1710
01:45:25,190 --> 01:45:29,790
i didn't connect the microphone as a

1711
01:45:29,840 --> 01:45:42,190
it's the first movie of twenty four nineteen ninety nine the better so let's first

1712
01:45:42,190 --> 01:45:48,690
moving around two in the first thing to note

1713
01:45:48,730 --> 01:45:50,710
born it's nothing left anymore

1714
01:45:50,730 --> 01:45:57,070
and now i'm going to change l

1715
01:45:58,590 --> 01:46:00,380
i think this is

1716
01:46:00,420 --> 01:46:02,690
i cannot do much better

1717
01:46:02,800 --> 01:46:06,190
so however it is not very important

1718
01:46:06,210 --> 01:46:10,110
i said al so that i think the system is that resonance

1719
01:46:10,110 --> 01:46:14,690
in a moment you can calculate if you know how many nodes are

1720
01:46:14,710 --> 01:46:16,610
i'm going to search for

1721
01:46:17,550 --> 01:46:21,570
you see and i notified we see that i'm moving it now i'm moving it

1722
01:46:21,570 --> 01:46:22,860
further that way

1723
01:46:22,880 --> 01:46:25,610
you get to another node

1724
01:46:25,650 --> 01:46:27,630
see that wonderful

1725
01:46:27,670 --> 01:46:29,730
i going into it and i know

1726
01:46:29,820 --> 01:46:32,960
here to another node

1727
01:46:33,000 --> 01:46:35,420
this node i'm going to measure the position

1728
01:46:35,550 --> 01:46:37,550
the rule in there

1729
01:46:37,590 --> 01:46:39,130
and the ruler

1730
01:46:40,190 --> 01:46:42,190
the position of the mind

1731
01:46:42,210 --> 01:46:48,150
and this one is fifty two point eight

1732
01:46:48,230 --> 01:46:49,920
o fifty

1733
01:46:49,960 --> 01:46:52,210
o point eight centimetres

1734
01:46:52,250 --> 01:46:57,920
is this position is somewhere and i can put market for to help you very

1735
01:46:58,590 --> 01:47:02,090
my accuracy is one millimeter and this is a very crude way

1736
01:47:02,130 --> 01:47:03,880
and i'm going to pull it back

1737
01:47:03,900 --> 01:47:05,500
because you and i know

1738
01:47:05,530 --> 01:47:13,320
here it is a very

1739
01:47:13,420 --> 01:47:15,170
no it's number one

1740
01:47:15,190 --> 01:47:18,170
no number two

1741
01:47:18,250 --> 01:47:22,460
no number three

1742
01:47:22,480 --> 01:47:27,590
no number

1743
01:47:30,530 --> 01:47:37,170
and and we'll all

1744
01:47:37,170 --> 01:47:40,750
now the reading in nineteen

1745
01:47:41,880 --> 01:47:44,570
four point three

1746
01:47:44,630 --> 01:47:46,290
time twenty four

1747
01:47:46,290 --> 01:47:49,000
o point three centimetres

1748
01:47:49,050 --> 01:47:50,940
by subtracting the five

1749
01:47:50,960 --> 01:47:55,530
twenty eight point five centimetres

1750
01:47:55,550 --> 01:47:59,150
this is film lab

1751
01:47:59,230 --> 01:48:02,210
and i know this really two i would say to women

1752
01:48:02,210 --> 01:48:07,300
certainly no worse than the disease and there is no uncertainty for sure in the

1753
01:48:08,110 --> 01:48:10,840
you can get your life back so i can now

1754
01:48:10,920 --> 01:48:15,840
calculate what the velocity of sound is for that is twenty eight point five

1755
01:48:15,860 --> 01:48:18,050
i divided by two

1756
01:48:18,110 --> 01:48:20,250
give me forty point two five

1757
01:48:20,250 --> 01:48:21,860
centimetres this was just

1758
01:48:21,900 --> 01:48:23,730
rough number that i gave you

1759
01:48:23,880 --> 01:48:25,550
now i multiply that

1760
01:48:25,570 --> 01:48:28,170
by the frequency twenty four or nine

1761
01:48:28,190 --> 01:48:31,900
and then i find three hundred and forty three

1762
01:48:31,920 --> 01:48:33,230
so v

1763
01:48:33,250 --> 01:48:35,900
three hundred and forty three

1764
01:48:35,920 --> 01:48:38,900
i would say plus or minus maybe two

1765
01:48:38,900 --> 01:48:40,820
meters per second

1766
01:48:40,860 --> 01:48:42,710
we measure the speed of sound

1767
01:48:42,770 --> 01:48:45,710
high degree of accuracy

1768
01:48:45,730 --> 01:48:48,110
and of course at the same time you've seen

1769
01:48:48,190 --> 01:48:49,650
it's wonderful

1770
01:48:49,670 --> 01:48:52,250
resonance normal mode behaviour

1771
01:48:52,270 --> 01:48:55,170
where you see them the nodes and i nodes

1772
01:48:55,190 --> 01:48:56,440
in this case

1773
01:48:56,460 --> 01:49:01,320
of pressure earlier you saw of year in terms of transverse motion now you've seen

1774
01:49:01,320 --> 01:49:03,320
them in terms of

1775
01:49:03,340 --> 01:49:07,290
longitudinal motion

1776
01:49:07,300 --> 01:49:09,190
there is

1777
01:49:09,190 --> 01:49:10,440
and the

1778
01:49:10,500 --> 01:49:12,500
in a

1779
01:49:12,500 --> 01:49:17,230
travelling wave


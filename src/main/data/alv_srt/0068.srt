1
00:00:00,000 --> 00:00:01,400
a positive integer

2
00:00:01,420 --> 00:00:04,960
so far those clusters then

3
00:00:04,980 --> 00:00:06,250
this thing is

4
00:00:06,290 --> 00:00:08,540
is finite so we have

5
00:00:08,540 --> 00:00:12,960
alfalfa k so k is very large integers so this public is going to be

6
00:00:12,960 --> 00:00:17,960
a very small number no plus a positive integer so this time is not going

7
00:00:17,960 --> 00:00:20,770
to be zero and that which is not going to be zero so this things

8
00:00:20,770 --> 00:00:22,880
perfectly well defined

9
00:00:22,900 --> 00:00:26,710
so what about forty and the clusters and also for the clusters for which there

10
00:00:26,710 --> 00:00:29,650
is actually no data associated with

11
00:00:29,710 --> 00:00:33,130
those clusters this and here was going to be zero

12
00:00:33,170 --> 00:00:37,150
right and of course we're going to be in trouble because we're going to have

13
00:00:37,150 --> 00:00:38,400
a problem

14
00:00:38,420 --> 00:00:40,690
alfalfa ketumile here

15
00:00:40,710 --> 00:00:45,380
this can be really small so the probability that

16
00:00:46,130 --> 00:00:51,380
it item being assigned to that particular class there will be arbitrarily small scale becomes

17
00:00:51,380 --> 00:00:52,590
very very large

18
00:00:52,650 --> 00:00:54,110
so what happens then

19
00:00:54,170 --> 00:00:58,080
well we can really do anything about what we can do is to say that

20
00:00:58,090 --> 00:01:00,380
if we lump all of this difference

21
00:01:00,400 --> 00:01:02,250
and the classes together

22
00:01:02,310 --> 00:01:03,730
right so this

23
00:01:03,750 --> 00:01:05,110
a lot of them

24
00:01:05,170 --> 00:01:10,150
and hopefully it'll council of this small probability alpha divided by k

25
00:01:10,190 --> 00:01:15,250
and it does happen so what's the you can work out the probability that they

26
00:01:15,250 --> 00:01:18,730
tied i being assigned to an empty cluster

27
00:01:18,810 --> 00:01:21,250
is going to be proportional to alpha alpha k

28
00:01:21,270 --> 00:01:25,310
multiplied by the number of clusters in a mixture model

29
00:01:25,360 --> 00:01:28,790
and case by is the number of occupied clusters

30
00:01:28,900 --> 00:01:32,110
and k minus case studies more-or-less k

31
00:01:32,170 --> 00:01:34,500
because k is much larger than that

32
00:01:36,270 --> 00:01:39,170
so this term here is going to be OK and that was going to be

33
00:01:39,170 --> 00:01:43,900
OK as well is this simply going to be the marginal probability of the data

34
00:01:43,900 --> 00:01:47,920
x y where we integrate out the parameters for the cluster

35
00:01:49,900 --> 00:01:52,400
as k goes to infinity and also

36
00:01:52,420 --> 00:01:54,400
let's see what happens so

37
00:01:54,580 --> 00:01:58,060
as big k goes to infinity this term is going to go to zero

38
00:02:01,060 --> 00:02:02,400
this term here

39
00:02:02,420 --> 00:02:04,170
it is going to go to one

40
00:02:05,080 --> 00:02:07,130
OK stylized funded by and

41
00:02:07,270 --> 00:02:11,440
and came in this case that over k is going to be more less one

42
00:02:11,960 --> 00:02:13,190
for large k

43
00:02:14,400 --> 00:02:20,480
this thing

44
00:02:20,500 --> 00:02:22,210
it doesn't account cannot be his

45
00:02:22,230 --> 00:02:25,250
they're all simply the marginal probability of the data

46
00:02:26,190 --> 00:02:29,340
no other data points

47
00:02:29,360 --> 00:02:31,860
now we

48
00:02:31,880 --> 00:02:33,730
we don't OK

49
00:02:33,770 --> 00:02:35,670
OK so

50
00:02:35,690 --> 00:02:38,170
we do that

51
00:02:38,400 --> 00:02:41,920
so that goes to zero this goes to one

52
00:02:41,940 --> 00:02:42,880
so now

53
00:02:42,940 --> 00:02:47,340
the probability of the data item i to cluster k

54
00:02:47,360 --> 00:02:49,380
you simply cannot be proportional to

55
00:02:49,400 --> 00:02:50,400
the cut

56
00:02:50,420 --> 00:02:54,080
the current number of data items there assigned to cluster k

57
00:02:54,080 --> 00:02:59,440
multiplied by the likelihood and divided by some of the normalisation constant

58
00:02:59,460 --> 00:03:01,580
and the probability of

59
00:03:01,630 --> 00:03:05,000
this data item be assigned to a an empty cluster

60
00:03:05,020 --> 00:03:08,770
so you can think of this as i guess i should call these components rather

61
00:03:08,770 --> 00:03:11,400
than clusters so the probability that

62
00:03:11,420 --> 00:03:14,750
the that if i is going to be assigned to

63
00:03:14,750 --> 00:03:18,360
and the component is going to be proportional to alpha

64
00:03:18,360 --> 00:03:21,000
times the probability of x i

65
00:03:21,480 --> 00:03:26,590
the marginal probability of x i will be have integrate out the parameters of the

66
00:03:26,590 --> 00:03:31,170
components and we have and minus one plus alpha ten

67
00:03:31,170 --> 00:03:33,860
now here this constant into not

68
00:03:33,900 --> 00:03:39,560
so we can think of this as introducing new components to explain the data

69
00:03:39,610 --> 00:03:40,900
and this

70
00:03:41,690 --> 00:03:46,150
basically reusing components to explain this particular data point

71
00:03:47,860 --> 00:03:53,590
of course they put the maximum number of components that this model uses and most

72
00:03:55,310 --> 00:03:56,980
so now we can

73
00:03:57,000 --> 00:03:59,960
go back to ODP them all

74
00:04:04,920 --> 00:04:07,960
do the same is exactly the same

75
00:04:07,980 --> 00:04:10,400
samples from the prior

76
00:04:10,400 --> 00:04:14,540
you can see that it is also has bumps of structures looks quite similar to

77
00:04:14,540 --> 00:04:16,810
define an action model

78
00:04:16,860 --> 00:04:20,860
at the two data points here we're going to have to have a lot more

79
00:04:20,860 --> 00:04:22,420
mass you know

80
00:04:23,110 --> 00:04:24,730
but of course we always have mass

81
00:04:24,750 --> 00:04:26,670
going also to

82
00:04:26,750 --> 00:04:28,270
so that that's

83
00:04:28,290 --> 00:04:31,480
try to create as many clusters as we can

84
00:04:31,480 --> 00:04:35,690
i'm not sure this will see

85
00:04:35,710 --> 00:04:38,860
so so it

86
00:04:38,880 --> 00:04:44,690
we need more data points because there's currently very few data points here so it

87
00:04:44,690 --> 00:04:51,310
becomes has decided that it doesn't really really need that many clusters to explain

88
00:04:51,310 --> 00:04:54,040
explain to you add more and more

89
00:04:54,090 --> 00:04:55,960
data points here hopefully

90
00:04:55,980 --> 00:04:57,710
creating cluster here

91
00:04:57,730 --> 00:05:02,500
OK and among these two clusters again it's

92
00:05:03,380 --> 00:05:06,190
saying that there's not enough data points here so i'm not going to use two

93
00:05:06,190 --> 00:05:09,840
clusters to explain you just use one of the cluster

94
00:05:09,840 --> 00:05:11,790
so this

95
00:05:12,790 --> 00:05:14,400
but two points here

96
00:05:14,520 --> 00:05:18,040
hopefully it will also create false cluster

97
00:05:18,060 --> 00:05:20,880
so you see that you know it's

98
00:05:20,880 --> 00:05:22,940
this editor useful clusters

99
00:05:22,960 --> 00:05:26,690
more point in the

100
00:05:26,710 --> 00:05:31,820
and hopefully will start to split this cluster into two

101
00:05:31,840 --> 00:05:39,690
seems to be working on so it was decided that the five classes you can

102
00:05:39,690 --> 00:05:43,750
as well as many classes as you want and you just keep on using more

103
00:05:43,750 --> 00:05:46,360
and more clusters as was

104
00:05:46,380 --> 00:05:51,630
so that's infinite mixture model

105
00:06:00,630 --> 00:06:05,790
well it's doing gibbs sampling the question is

106
00:06:05,790 --> 00:06:10,290
how do you control the trade went to introduce new clusters went to not introduce

107
00:06:10,290 --> 00:06:15,210
i see no reason shaking hands well it's close

108
00:06:15,230 --> 00:06:16,890
it's pretty close

109
00:06:16,910 --> 00:06:18,940
probably yes

110
00:06:18,950 --> 00:06:24,310
yes in that's what we call studios generalizations

111
00:06:24,330 --> 00:06:27,300
which is you get the response to

112
00:06:28,690 --> 00:06:29,970
civil war

113
00:06:31,380 --> 00:06:32,650
but suppose

114
00:06:32,670 --> 00:06:35,010
the edge of their abilities

115
00:06:35,060 --> 00:06:37,060
there is much higher

116
00:06:37,060 --> 00:06:38,720
or or much slower

117
00:06:38,750 --> 00:06:45,060
in that case we might get a reaction from the dog to dog is discriminate

118
00:06:45,080 --> 00:06:46,670
between the stimuli

119
00:06:46,680 --> 00:06:52,540
we call that stimulus discrimination so it's it's recognising that

120
00:06:52,580 --> 00:06:57,070
die or human being

121
00:06:57,090 --> 00:06:59,270
i will respond to

122
00:06:59,290 --> 00:07:01,090
similar one

123
00:07:02,100 --> 00:07:06,020
but that but that generalization will only go so far

124
00:07:06,040 --> 00:07:09,350
and then the organism will discriminate

125
00:07:09,380 --> 00:07:12,030
and will not respond to the stimulus

126
00:07:12,050 --> 00:07:16,160
is to do

127
00:07:16,180 --> 00:07:21,520
by by now you probably have seen that

128
00:07:21,530 --> 00:07:23,070
classical conditioning

129
00:07:23,090 --> 00:07:26,360
does not explained very complex

130
00:07:26,380 --> 00:07:30,300
it's rather so we can say the last conditioning

131
00:07:30,340 --> 00:07:34,360
explains only simple behaviors such as

132
00:07:34,380 --> 00:07:42,750
drawings such as primitive emotional reactions which is here or excitement

133
00:07:43,910 --> 00:07:47,430
we think of classical conditioning you should think about

134
00:07:47,500 --> 00:07:48,210
should be

135
00:07:48,230 --> 00:07:51,180
relatively simple here

136
00:07:51,430 --> 00:07:59,110
and yet as i said cluster is important because it tells us that neutral stimulus

137
00:07:59,160 --> 00:08:04,820
can evoke the same criminal behavior such as here has been natural systems

138
00:08:04,830 --> 00:08:07,450
organisms can make substitutions

139
00:08:07,460 --> 00:08:09,670
from the initial stimulus

140
00:08:10,450 --> 00:08:11,450
for this

141
00:08:11,500 --> 00:08:13,520
primitive response yes

142
00:08:13,530 --> 00:08:15,920
that stimulus substitution

143
00:08:15,960 --> 00:08:17,540
does occur

144
00:08:17,560 --> 00:08:19,630
so let's go going to the slide

145
00:08:22,070 --> 00:08:25,660
i don't know how long did his work in russia

146
00:08:25,680 --> 00:08:28,030
these concepts over two

147
00:08:29,040 --> 00:08:32,050
in the early part of the twentieth century

148
00:08:32,920 --> 00:08:34,880
a he

149
00:08:36,560 --> 00:08:39,580
very important in the history of psychology

150
00:08:39,630 --> 00:08:41,680
was john b

151
00:08:41,700 --> 00:08:44,530
what's what's it was a

152
00:08:44,550 --> 00:08:48,020
a faculty member at johns hopkins university

153
00:08:48,040 --> 00:08:49,210
that time

154
00:08:49,220 --> 00:08:53,970
johns hopkins either recently was the first

155
00:08:56,130 --> 00:08:57,500
united states

156
00:08:57,540 --> 00:08:59,690
offer doctorate

157
00:09:00,890 --> 00:09:03,360
we're really was a

158
00:09:03,380 --> 00:09:09,610
researchers are free to choose and john watson was active

159
00:09:10,700 --> 00:09:13,500
in the early days of psychology in america

160
00:09:13,510 --> 00:09:15,260
pushing a certain

161
00:09:15,280 --> 00:09:20,330
version psychology which is psychology as a scientific

162
00:09:20,350 --> 00:09:22,880
in our brain and

163
00:09:24,200 --> 00:09:29,580
you can imagine there you know other versions of psychology in europe for example

164
00:09:29,590 --> 00:09:33,360
they were less designed by right

165
00:09:33,450 --> 00:09:37,000
well what's and wanted a particular

166
00:09:37,010 --> 00:09:45,130
this version of psychology that focuses on observable behavior so he pushed the years to

167
00:09:45,230 --> 00:09:47,760
as the only legitimate

168
00:09:47,770 --> 00:09:51,260
or psychology

169
00:09:51,280 --> 00:09:53,450
his most famous experiments

170
00:09:53,470 --> 00:09:55,030
in involved

171
00:09:55,040 --> 00:09:59,310
a baby boy who has come to be known to us as

172
00:09:59,350 --> 00:10:02,430
little here is heard of little house

173
00:10:02,530 --> 00:10:07,520
that the nearest seen pictures of this video because allow

174
00:10:07,560 --> 00:10:10,650
very interesting stuff and watson is in those c

175
00:10:10,670 --> 00:10:12,930
in conditioning will

176
00:10:12,930 --> 00:10:13,470
well if you

177
00:10:14,540 --> 00:10:16,830
many of the story here

178
00:10:18,180 --> 00:10:22,780
our little however was not afraid of rats

179
00:10:22,790 --> 00:10:26,060
he would see a white rat and

180
00:10:28,100 --> 00:10:33,720
i want to touch you was shown evidence that here at all

181
00:10:35,580 --> 00:10:40,170
what's in a range of experiments in which

182
00:10:40,180 --> 00:10:43,430
when the white rabbit here

183
00:10:43,430 --> 00:10:46,570
and the first one i wanted to show you about

184
00:10:46,680 --> 00:10:48,740
there is an argument for

185
00:10:49,960 --> 00:10:56,340
you see

186
00:11:04,000 --> 00:11:08,490
just this one

187
00:11:08,500 --> 00:11:35,140
when can also show you this is this is also kind of this is a

188
00:11:38,010 --> 00:11:42,290
you get a few very

189
00:11:42,320 --> 00:11:43,470
if it works

190
00:11:43,570 --> 00:11:53,530
in this case

191
00:11:53,560 --> 00:11:59,410
OK i hope my computer hasn't lost more videos so here we have an interesting

192
00:11:59,410 --> 00:12:05,440
application of support vector regression possible to a program called implicit surface approximation

193
00:12:05,450 --> 00:12:08,710
so what's implicit surface approximation

194
00:12:08,760 --> 00:12:15,330
so the problem is you

195
00:12:15,350 --> 00:12:30,740
you've got some

196
00:12:30,770 --> 00:12:31,820
some data

197
00:12:31,850 --> 00:12:35,940
sampled from the object

198
00:12:42,760 --> 00:12:51,440
assume x is some three-dimensional object you have a set of surface points which you

199
00:12:51,440 --> 00:12:55,190
might have acquired for instance using laser scan of the object

200
00:12:55,210 --> 00:13:00,070
and you are trying to estimate a function with the property that it's zero on

201
00:13:00,070 --> 00:13:03,720
the surface of the object non-zero elsewhere

202
00:13:03,730 --> 00:13:05,840
so you have you want to function which is

203
00:13:05,860 --> 00:13:07,830
the above zero

204
00:13:07,920 --> 00:13:14,710
on this set and if you want on the on the component is non-zero and

205
00:13:16,860 --> 00:13:24,490
most specifically this one particular such a function which is particularly nice for football

206
00:13:24,490 --> 00:13:28,100
processing and this function is called the signed distance function

207
00:13:28,830 --> 00:13:33,170
so let's look at the two-dimensional surface of an object

208
00:13:33,180 --> 00:13:38,630
so the signed distance function has the property that at any given point in space

209
00:13:38,880 --> 00:13:41,570
its value modulus

210
00:13:41,600 --> 00:13:47,120
absolute value will be equal to the distance of that point from the surface of

211
00:13:47,120 --> 00:13:48,280
the object

212
00:13:48,280 --> 00:13:53,430
and the sign of the function will be positive outside the object negative inside the

213
00:13:54,830 --> 00:13:59,670
OK so this function is negative in here positive party out here and it crosses

214
00:13:59,670 --> 00:14:02,530
you're exactly on the surface of the object

215
00:14:02,610 --> 00:14:04,750
signed distance function

216
00:14:04,750 --> 00:14:11,020
and you can estimate the scientists function from the time in different ways and you

217
00:14:11,020 --> 00:14:16,730
can get representations like this you can represent such objects as the zero sets of

218
00:14:16,730 --> 00:14:23,290
support support the expansions the training algorithm is a modified form of support vector regression

219
00:14:23,320 --> 00:14:27,940
maybe i don't have to go into details on that you get such solutions and

220
00:14:27,940 --> 00:14:31,290
then one of the nice things is you can try to do

221
00:14:31,300 --> 00:14:34,700
so maybe i'll show you to your own this lines you can try to do

222
00:14:34,700 --> 00:14:37,170
things like more between objects

223
00:14:38,610 --> 00:14:40,890
take something

224
00:14:40,910 --> 00:14:55,550
might have it

225
00:14:55,570 --> 00:15:03,190
and with the help of better version of it

226
00:15:19,710 --> 00:15:25,790
so what's the problem of morphing suppose we have a for two different heads of

227
00:15:25,790 --> 00:15:27,260
a man and woman

228
00:15:27,270 --> 00:15:30,550
and you would like to compute the head which is somewhere in between so i'm

229
00:15:30,550 --> 00:15:33,280
assuming has given us three d objects

230
00:15:33,290 --> 00:15:37,760
and i would like to compute a three d object which is somewhere in between

231
00:15:37,870 --> 00:15:41,910
if i just take the linear combination of these two heads i won't get very

232
00:15:41,910 --> 00:15:47,430
good results because these objects are not in correspondence because i don't know where are

233
00:15:47,500 --> 00:15:49,810
the eyes well the noses and so on

234
00:15:49,890 --> 00:15:54,600
so what you would like to do is you would like to compute its solution

235
00:15:54,600 --> 00:15:56,580
which does something like this

236
00:15:56,600 --> 00:16:00,920
and i'll tell you how to do this hard to compute this kind of solution

237
00:16:00,920 --> 00:16:06,080
from signed distance function estimated from using support vector machines

238
00:16:06,090 --> 00:16:10,720
so the way it works is

239
00:16:10,720 --> 00:16:15,670
so if you have two different objects

240
00:16:15,690 --> 00:16:21,860
so it's a have one person which looks like this

241
00:16:21,920 --> 00:16:24,000
another person which

242
00:16:24,090 --> 00:16:26,570
he has like this

243
00:16:26,580 --> 00:16:33,220
you would like to estimate what people call wall field so that the mapping which

244
00:16:33,630 --> 00:16:35,470
given a point in this

245
00:16:35,990 --> 00:16:38,040
on this object will

246
00:16:38,070 --> 00:16:39,010
i tell you

247
00:16:39,020 --> 00:16:44,240
what's the corresponding point on this object so it's a mapping in this case from

248
00:16:45,170 --> 00:16:49,600
two r two

249
00:16:51,590 --> 00:16:54,750
of course this is if you

250
00:16:55,310 --> 00:17:00,430
just write like this you don't see it how you can solve this problem but

251
00:17:00,440 --> 00:17:02,350
the way we work is that

252
00:17:02,410 --> 00:17:05,590
first of all you would like this mapping to have the property of course that

253
00:17:05,590 --> 00:17:10,600
each surface point here will be mapped to a certain point over here really a

254
00:17:10,600 --> 00:17:15,230
little constraint but it turns out this is not enough it but if you enforce

255
00:17:15,230 --> 00:17:20,390
that warping not only maps surface points to service points but it actually keeps the

256
00:17:20,390 --> 00:17:23,590
value of the scientists function invariant

257
00:17:23,600 --> 00:17:26,870
then you're in business it turns out so what does that mean so you have

258
00:17:26,870 --> 00:17:32,020
assigned distance function for this subject you have one for this objective function which is

259
00:17:32,020 --> 00:17:37,830
negative and a positive out here simple there's been asking the signed distance function should

260
00:17:37,830 --> 00:17:40,240
be invariant means in particular

261
00:17:40,240 --> 00:17:44,030
points where the function is zero should be point not point about this function is

262
00:17:44,030 --> 00:17:46,440
zero points which are

263
00:17:46,490 --> 00:17:51,460
one centimeter outside of this object to be mapped to point out one centimeter outside

264
00:17:51,460 --> 00:17:55,830
of this subject and so on and if additionally you use just stand up support

265
00:17:55,830 --> 00:18:00,140
vector machine regularizer it turns out that this is something like it in the last

266
00:18:00,160 --> 00:18:01,690
of vector regression problems

267
00:18:01,700 --> 00:18:08,290
which we can solve and solving it we can get this fairly nice morphs between

268
00:18:08,290 --> 00:18:09,430
these objects

269
00:18:10,310 --> 00:18:14,060
let's see what i can show in terms of results i think i had a

270
00:18:14,060 --> 00:18:17,450
pretty nice one and here

271
00:18:17,470 --> 00:18:33,180
so here we've got them off computed between human and monkey

272
00:18:33,180 --> 00:18:37,770
and the state transition so pair of tags which are adjacent in the sentence

273
00:18:38,510 --> 00:18:43,150
now typically these feature vector representations will look at all kinds of features of the

274
00:18:43,150 --> 00:18:47,980
input sentence conjoined with these two tags so might for example be sensitive to the

275
00:18:47,980 --> 00:18:48,750
fact that cake

276
00:18:49,220 --> 00:18:51,770
it's being assigned the tag now

277
00:18:51,790 --> 00:18:56,010
or maybe the technologies here we have some surrounding context in the string and so

278
00:18:56,010 --> 00:18:57,880
on and so on

279
00:18:57,910 --> 00:19:01,740
and one of the nice things about crfs is the freedom with which you can

280
00:19:01,740 --> 00:19:05,400
define these feature vectors

281
00:19:05,470 --> 00:19:05,960
so the i

282
00:19:06,280 --> 00:19:09,250
for cns looks like the family so the optimal

283
00:19:09,280 --> 00:19:12,910
state sequence y staff particular input x

284
00:19:12,930 --> 00:19:16,290
is the right maximizes the sum of two terms

285
00:19:16,320 --> 00:19:20,570
so here i have some of the and positions in the sentence on something of

286
00:19:20,600 --> 00:19:22,050
position by position

287
00:19:22,060 --> 00:19:27,310
and in this position essentially state transition because so pair of labels just i showed

288
00:19:27,920 --> 00:19:30,510
and in the state transitions gets a score

289
00:19:30,510 --> 00:19:35,090
this an into the inner products between the vector w and the feature vector

290
00:19:35,160 --> 00:19:39,000
so you can think of these inner products as being a measure of the plausibility

291
00:19:39,000 --> 00:19:43,070
probability of this particular state transition this particular

292
00:19:43,330 --> 00:19:45,020
position in the sentence

293
00:19:45,900 --> 00:19:50,000
we can find the highest scoring state sequence using the viterbi algorithm

294
00:19:50,650 --> 00:19:51,560
because the

295
00:19:51,560 --> 00:19:55,850
the last decomposes in this way we can use dynamic programming to search through the

296
00:19:55,850 --> 00:19:58,190
space of possible structures efficiently

297
00:19:58,250 --> 00:20:00,130
because that's zero

298
00:20:01,270 --> 00:20:03,720
the big question is how do we know

299
00:20:03,730 --> 00:20:07,330
generalize the same style models to parsing

300
00:20:07,350 --> 00:20:10,520
so a couple of options one which has been explored

301
00:20:10,560 --> 00:20:14,360
it is to think about context free grammars

302
00:20:14,430 --> 00:20:19,910
the representations the context free grammars induce and how this can be leveraged within CRF

303
00:20:19,920 --> 00:20:22,760
the alternative which to talk about next

304
00:20:22,790 --> 00:20:25,810
is based on alternative tree adjoining grammars

305
00:20:25,830 --> 00:20:29,530
this work by arab and jewish in many of his colleagues

306
00:20:29,570 --> 00:20:33,560
OK so tags or the tree adjoining grammars

307
00:20:33,570 --> 00:20:38,340
so this was originally chinese these grammars like i can do anything close to justice

308
00:20:38,670 --> 00:20:43,560
for instead of going to describe a fairly simple tag like formalism that we've applied

309
00:20:43,570 --> 00:20:47,160
recently into this particular problem

310
00:20:47,210 --> 00:20:49,820
OK so in context free grammars

311
00:20:49,820 --> 00:20:53,810
the basic elements in the grammar set of these rewrite rules

312
00:20:53,820 --> 00:20:56,000
in tree adjoining grammars

313
00:20:57,750 --> 00:21:03,030
the grammar is essentially defined by a set of what are called elementary trees

314
00:21:03,070 --> 00:21:05,530
so these look like tree fragments

315
00:21:05,570 --> 00:21:11,840
and in this particular case the using elementary trees in the simple spine like structures

316
00:21:11,860 --> 00:21:16,550
so the structures and grammar look like lexical items

317
00:21:16,550 --> 00:21:18,910
which is often called the anchor of the tree

318
00:21:19,020 --> 00:21:20,720
some small

319
00:21:20,940 --> 00:21:24,030
substructure but some small fragmentary above it

320
00:21:24,080 --> 00:21:27,590
so for example may has a couple of levels going up to an MP

321
00:21:27,640 --> 00:21:29,470
it has a few more levels

322
00:21:29,470 --> 00:21:32,740
and so on so these are the basic units

323
00:21:32,750 --> 00:21:35,390
in tree adjoining grammars

324
00:21:35,500 --> 00:21:40,250
so the question is how we got larger pieces of syntactic structure

325
00:21:40,260 --> 00:21:42,920
and so in general they are

326
00:21:42,940 --> 00:21:49,210
basic operations which can be used to combine these military fragments into larger pieces of

327
00:21:50,370 --> 00:21:55,500
and the operation the news today is something called sister junction

328
00:21:55,540 --> 00:21:58,020
so sister junction basically takes

329
00:21:58,030 --> 00:22:00,610
two these spines that just showing

330
00:22:00,630 --> 00:22:06,600
and joins them together combines them to form a larger piece of the syntactic structures

331
00:22:06,670 --> 00:22:11,750
in particular and this disjunction operation takes one spine modifier

332
00:22:11,760 --> 00:22:14,080
which is the main spine here

333
00:22:14,130 --> 00:22:18,000
and the spine which is called the head that's the inspiron here

334
00:22:18,010 --> 00:22:22,830
in addition it takes the position at which the modifier spine

335
00:22:22,890 --> 00:22:25,160
attaches underneath that's fine

336
00:22:25,170 --> 00:22:27,530
so underneath this as position

337
00:22:27,530 --> 00:22:31,990
OK so this is a primitive upcoming operation that combines these two trains and essentially

338
00:22:31,990 --> 00:22:37,040
forms the rule goes to NP VP at this point in the tree

339
00:22:37,050 --> 00:22:38,750
so we can keep going

340
00:22:38,770 --> 00:22:42,340
and actually you can imagine a full parse tree for the sentence

341
00:22:42,360 --> 00:22:44,240
essentially being formed

342
00:22:44,240 --> 00:22:49,400
by a series of these kind of junction operations

343
00:22:49,460 --> 00:22:51,250
so let see the

344
00:22:51,270 --> 00:22:56,480
constraints on these production operations are the costs so regular grammars you might have some

345
00:22:56,480 --> 00:23:02,250
constraints on how these things can combine exactly with different elementary trees can join

346
00:23:02,270 --> 00:23:08,960
in that case we simply use costs essentially we should abandon CF style model

347
00:23:09,070 --> 00:23:14,190
so intuitively we can think about it for tree here we're not decomposing this into

348
00:23:14,190 --> 00:23:16,010
a set of the junction operations

349
00:23:16,060 --> 00:23:21,190
so parsing into tag intuitively looks like a bottom-up process when first for each word

350
00:23:21,190 --> 00:23:25,050
in the input to choose one of these elementary trees so you choose to the

351
00:23:25,060 --> 00:23:29,790
predicted structure and secondly you choose how these different pieces structure fit together to form

352
00:23:29,790 --> 00:23:32,120
a full parse tree

353
00:23:33,010 --> 00:23:38,430
so i might be what might be interested in these kind of grammars as an

354
00:23:38,430 --> 00:23:40,660
alternative site to see if cheese

355
00:23:40,690 --> 00:23:45,220
so i made a couple of advantages

356
00:23:45,260 --> 00:23:46,940
the first is the following

357
00:23:46,960 --> 00:23:50,070
if you think about the lexical entries in the grammar

358
00:23:50,080 --> 00:23:52,350
these quite naturally

359
00:23:52,360 --> 00:23:54,660
captures constraints

360
00:23:54,670 --> 00:23:56,830
associated with lexical items

361
00:23:56,880 --> 00:24:00,250
so basically constraint that this one source of

362
00:24:00,340 --> 00:24:03,380
we see this piece of tree fragment above it

363
00:24:03,440 --> 00:24:07,730
so this is quite natural way to capture the influence of individual words on the

364
00:24:07,730 --> 00:24:10,210
highest structure in the tree

365
00:24:10,210 --> 00:24:11,870
perhaps more properly

366
00:24:11,890 --> 00:24:17,600
we can start to associate probabilities all costs with this combination operations i just spoke

367
00:24:18,790 --> 00:24:22,280
so for example one operation might be to combine

368
00:24:22,290 --> 00:24:25,510
these fragments are associated with repeats and k

369
00:24:25,520 --> 00:24:27,420
to form the structure

370
00:24:27,490 --> 00:24:31,210
with the sister junction operations i additional

371
00:24:31,210 --> 00:24:33,710
and this can have probability of cost

372
00:24:33,860 --> 00:24:39,410
now essentially what we're doing here the form the structures with choosing the cake is

373
00:24:39,410 --> 00:24:41,640
the direct object of eats

374
00:24:41,660 --> 00:24:45,830
and by the parameters which can have access to this information

375
00:24:45,840 --> 00:24:49,380
actually this this kind of parameters have been shown time and time again to be

376
00:24:49,380 --> 00:24:55,970
very useful in disambiguating different structures of choosing between different parts

377
00:24:56,830 --> 00:25:03,220
in contrast to pcfgs like i said in tags we associate costs probabilities with these

378
00:25:03,230 --> 00:25:04,810
a junction operations

379
00:25:04,820 --> 00:25:10,060
this contrasts in cfgs we associate probabilities cost rules something quite different

380
00:25:10,070 --> 00:25:15,860
when parameterizing of thinking about the problem in these two cases

381
00:25:16,610 --> 00:25:19,070
the next trick is going to be too

382
00:25:19,080 --> 00:25:23,610
generalize ideas about feature vectors in conditional random fields

383
00:25:23,620 --> 00:25:25,760
two these junction operations

384
00:25:25,760 --> 00:25:28,870
so the models we have been using essentially

385
00:25:28,900 --> 00:25:31,820
matt these junction operations to feature vectors

386
00:25:31,820 --> 00:25:34,660
so now we have the feature vector mapping which looks as far as we have

387
00:25:34,660 --> 00:25:37,270
an input x which is the string

388
00:25:37,610 --> 00:25:42,180
and we have information which basically specifies everything i've shown you end up here

389
00:25:42,240 --> 00:25:46,740
so we have the indices of head word in the world

390
00:25:46,890 --> 00:25:49,040
participating in this relationship

391
00:25:49,050 --> 00:25:50,920
so three and five in this case

392
00:25:51,070 --> 00:25:52,280
the fifth

393
00:25:52,280 --> 00:25:59,530
one going however we consider case that this falling unit is receiving top down information

394
00:25:59,540 --> 00:26:02,280
intuitively if this top of

395
00:26:02,280 --> 00:26:06,740
top down information to know that he if is large that means that the probability

396
00:26:06,740 --> 00:26:10,250
of wiping activity is high

397
00:26:10,280 --> 00:26:15,510
so using the energy function we can also write down the conditional

398
00:26:15,520 --> 00:26:20,450
the probability that x saving one and it turns out that it can be simply

399
00:26:20,450 --> 00:26:22,650
written as softmax function

400
00:26:22,670 --> 00:26:25,570
similar way x off but

401
00:26:26,030 --> 00:26:33,010
we just at the top down and bottom up information together inside the exponential function

402
00:26:33,050 --> 00:26:43,850
and we can sample from this conditional distributions by simply using a multinomial distribution

403
00:26:43,860 --> 00:26:49,770
so i described above convolutional deep belief network and i'm going to disk

404
00:26:49,780 --> 00:26:51,490
so experimental results

405
00:26:52,660 --> 00:26:56,760
we evaluated our model two hundred ten digit data

406
00:26:56,800 --> 00:27:02,860
we trained a two layer convolutional deep belief network on unlabeled and the training data

407
00:27:02,910 --> 00:27:08,130
and it turns out that the first layer learns strokes and the second layer learned

408
00:27:08,220 --> 00:27:11,400
some groupings of the strokes

409
00:27:11,520 --> 00:27:15,100
and be computed the test error

410
00:27:15,110 --> 00:27:19,030
with different number of labelled examples

411
00:27:19,040 --> 00:27:20,860
in summary our

412
00:27:21,650 --> 00:27:31,370
performance very competitively compared to other state of the art models

413
00:27:31,410 --> 00:27:37,620
in the next experiment we trained to layer convolutional deep belief network representation from a

414
00:27:37,620 --> 00:27:40,600
set of natural images

415
00:27:40,610 --> 00:27:42,250
and the resulting

416
00:27:42,330 --> 00:27:45,430
representation is that in the first layer

417
00:27:45,440 --> 00:27:48,870
it learns localized oriented edges

418
00:27:48,910 --> 00:27:50,410
and in the second layer

419
00:27:50,430 --> 00:27:55,670
it combines the first layer resentation into a richer set of features

420
00:27:55,680 --> 00:28:01,560
for example contours onerous and parts surface boundaries

421
00:28:01,570 --> 00:28:06,150
and we evaluate our representation two

422
00:28:06,160 --> 00:28:10,760
caltech one of the classification task

423
00:28:12,510 --> 00:28:14,150
we can see that

424
00:28:14,160 --> 00:28:19,690
our first layer representation gives a fairly good results but after combining the first and

425
00:28:19,690 --> 00:28:21,600
second the representation

426
00:28:21,620 --> 00:28:25,790
the accuracy improves significantly

427
00:28:25,810 --> 00:28:32,270
and our final result is sixty five percent accuracy for thirty training images per class

428
00:28:32,370 --> 00:28:40,200
and this is very competitive results using other state-of-the-art features such as SIFT

429
00:28:40,230 --> 00:28:46,250
and considering that our presentation was trained from natural image which is completely unrelated to

430
00:28:46,250 --> 00:28:48,130
the caltech one on images

431
00:28:48,170 --> 00:28:53,120
this shows that our convolutional DBN representation learned

432
00:28:53,130 --> 00:28:59,080
fairly generic informative representation for images

433
00:28:59,110 --> 00:29:01,100
in the next experiment we

434
00:29:01,510 --> 00:29:08,000
trained in three layer convolutional deep belief network for multiple to cover images

435
00:29:08,010 --> 00:29:11,620
for example if the train from

436
00:29:11,630 --> 00:29:17,950
all images of faces in the second layer representation tend to learn all took part

437
00:29:17,950 --> 00:29:21,300
representation such as our eyes or nose

438
00:29:21,360 --> 00:29:23,400
and the third representation

439
00:29:23,520 --> 00:29:26,990
it combines the part based on their representation in into

440
00:29:27,000 --> 00:29:29,320
the concept of full of

441
00:29:29,380 --> 00:29:32,100
and our model can too

442
00:29:32,270 --> 00:29:35,480
we can discover similar object part an object

443
00:29:35,520 --> 00:29:38,160
our representation

444
00:29:38,300 --> 00:29:45,230
for many other classes such as cars elephants chairs

445
00:29:45,250 --> 00:29:48,390
in our quantitative evaluation

446
00:29:48,440 --> 00:29:55,020
we measure how informative each feature representation in the second or third layer is

447
00:29:55,060 --> 00:29:56,770
so going back to the

448
00:29:56,780 --> 00:29:58,160
previous slide

449
00:29:58,220 --> 00:30:02,860
we have trained forty of features in the second layer and twenty four features and

450
00:30:02,860 --> 00:30:05,000
the third layer

451
00:30:05,650 --> 00:30:07,900
we pick just one second layer feature

452
00:30:07,910 --> 00:30:13,140
and then compute the activation for the non

453
00:30:13,180 --> 00:30:15,480
activation for the

454
00:30:15,500 --> 00:30:17,250
cars based

455
00:30:17,270 --> 00:30:19,650
non face images

456
00:30:19,660 --> 00:30:21,470
and we can compute the

457
00:30:21,480 --> 00:30:24,630
precision recall curves and compute the area

458
00:30:24,640 --> 00:30:27,560
so called the average precision

459
00:30:27,570 --> 00:30:28,790
so we have

460
00:30:28,800 --> 00:30:34,280
forty thousand average precision values for the second there twenty four hours precision values for

461
00:30:34,280 --> 00:30:35,380
the third layer

462
00:30:35,580 --> 00:30:40,390
this is the distribution of average precision values

463
00:30:40,400 --> 00:30:45,410
you can see that the first layer bases overall has a fairly small are averaged

464
00:30:45,410 --> 00:30:51,860
precision values however as the layer goes up the second there has significantly higher average

465
00:30:51,860 --> 00:30:57,360
precision and third layer of features even at even higher average precision

466
00:30:57,430 --> 00:31:00,260
so this suggests that the higher the feature

467
00:31:00,350 --> 00:31:06,280
the lines are more informative for object class

468
00:31:06,290 --> 00:31:11,470
we also tested if our present patient can learn from some external objects so we

469
00:31:11,470 --> 00:31:16,310
train from images of faces cars and more like an airplane

470
00:31:16,380 --> 00:31:19,580
as a result our

471
00:31:19,600 --> 00:31:21,020
the second feature

472
00:31:21,060 --> 00:31:25,110
learn some mixture of object specific parts of shared parts

473
00:31:26,360 --> 00:31:28,790
and in the third layer by combining these

474
00:31:29,850 --> 00:31:31,730
the second feature representation

475
00:31:31,740 --> 00:31:39,820
it discovers more and more objects that's bigger presentation

476
00:31:39,900 --> 00:31:45,450
as of quantitative evaluation may be measured conditional entropy so

477
00:31:45,480 --> 00:31:46,780
conditional entropy

478
00:31:46,800 --> 00:31:52,520
keep of class labels given that features are active

479
00:31:54,780 --> 00:31:58,430
as in the previous six experiment we have forty

480
00:31:58,610 --> 00:32:03,600
conditional entropy values for the second there and twenty four conditional entropy values for the

481
00:32:03,600 --> 00:32:05,150
the third layer

482
00:32:05,160 --> 00:32:09,730
and here are the distribution of country conditional entropy values

483
00:32:09,780 --> 00:32:12,310
overall we see that the first layer

484
00:32:12,330 --> 00:32:18,490
features are have very high conditional entropy which means that even though they active it's

485
00:32:18,490 --> 00:32:21,710
not very specific to optical however

486
00:32:21,720 --> 00:32:23,740
that's the layer goes up the

487
00:32:23,750 --> 00:32:28,220
distribution for the conditional entropy values become more closer to one

488
00:32:28,310 --> 00:32:30,290
meaning that when you know that the first

489
00:32:30,550 --> 00:32:35,050
when you know that the third level features are active and it's very specific to

490
00:32:35,120 --> 00:32:37,380
to class

491
00:32:37,480 --> 00:32:43,340
so finally experiment we tested hierarchical probabilistic inference

492
00:32:43,370 --> 00:32:45,770
this experiment is inspired by

493
00:32:45,850 --> 00:32:48,770
the mumford paper

494
00:32:48,780 --> 00:32:54,580
as a motivating example we can consider OK situation where we observed images of faces

495
00:32:54,580 --> 00:32:59,470
the team for several one you've really got to meet my good colleague of mine

496
00:32:59,780 --> 00:33:02,360
my name is eric lander and

497
00:33:04,460 --> 00:33:08,880
but i will faculty here in the biology department in fact were both members over

498
00:33:08,880 --> 00:33:13,810
at the whitehead institute for biomedical research and we just for whole weekend together into

499
00:33:13,860 --> 00:33:18,030
tree and so above and i've been doing this course together for a number of

500
00:33:18,030 --> 00:33:24,060
years and very much love i and i taken a brief moment in introduce myself

501
00:33:24,060 --> 00:33:27,780
since time and they have to do so yes i am by training

502
00:33:27,830 --> 00:33:29,380
well actually

503
00:33:29,400 --> 00:33:34,140
i'm really a geneticist by training and actually pure mathematicians that was actually my undergraduate

504
00:33:34,140 --> 00:33:38,640
degree was in my phd was but then wandered into biology and for the last

505
00:33:38,650 --> 00:33:43,520
almost twenty years i have been doing genetics in some form or another style of

506
00:33:43,520 --> 00:33:48,320
genetics and look forward to talk a lot about genetics and it's really lovely with

507
00:33:48,320 --> 00:33:53,520
my first lecture today is actually going to be our first introduction to genetics i

508
00:33:53,520 --> 00:33:54,630
am i

509
00:33:54,650 --> 00:33:57,790
just for other background

510
00:33:57,810 --> 00:34:02,050
i direct this new brood institute that is

511
00:34:02,070 --> 00:34:06,540
here it's actually a joint institute between MIT and harvard and you will know it

512
00:34:06,550 --> 00:34:10,040
now is a hole in the ground next to legal sea seafood if you see

513
00:34:10,040 --> 00:34:14,500
a bunch of cranes and things opposite the biology building and absolute legal seafood next

514
00:34:14,500 --> 00:34:18,910
whitehead that the broad institute we have ambitions someday to be more than the hole

515
00:34:18,910 --> 00:34:24,160
in the ground but actually rise above the ground and the broder's about genomic medicine

516
00:34:24,160 --> 00:34:29,120
and using genomes and things like that and the broad institute includes

517
00:34:29,210 --> 00:34:31,140
this centre MIT

518
00:34:31,150 --> 00:34:35,620
that was one of the leading participants in the human genome project so that a

519
00:34:35,620 --> 00:34:39,740
lot of what i do with my day job in addition to teaching is work

520
00:34:39,740 --> 00:34:43,240
on things like the human genome project and now we actually have sequence the human

521
00:34:43,240 --> 00:34:46,030
genome figure out what the the world at all means and i hope i get

522
00:34:46,030 --> 00:34:50,230
a chance to tell you during the course of this this class about the human

523
00:34:50,230 --> 00:34:53,530
genome and about what's in it and things like that and is one of the

524
00:34:53,530 --> 00:34:59,300
exact tremendously love about teaching biology as opposed i can get in trouble to any

525
00:34:59,300 --> 00:35:05,880
of the other required introductory courses is that are curriculum changes every year because the

526
00:35:05,880 --> 00:35:09,650
field is moving so rapidly i look back at what we talk ten years ago

527
00:35:09,650 --> 00:35:14,040
in this course because of the teaching that long and all sorts of open questions

528
00:35:14,040 --> 00:35:17,350
now we know the answers to are part of the curriculum some of the things

529
00:35:17,350 --> 00:35:20,140
we thought we knew what we now know are false and we know new things

530
00:35:20,480 --> 00:35:24,180
and every year we get introduced new stuff and

531
00:35:24,200 --> 00:35:28,030
i know i mean with all due respect to calculus it's just not the case

532
00:35:28,030 --> 00:35:32,070
for calculus that that there's anything really new to introduce most of its order settle

533
00:35:32,120 --> 00:35:35,580
down about about three or four centuries ago and

534
00:35:35,590 --> 00:35:39,070
you know that's not the case with what we do anyway that's why

535
00:35:45,660 --> 00:35:50,130
so bob has been talking to

536
00:35:51,270 --> 00:35:53,710
biochemistry large

537
00:35:53,750 --> 00:35:57,450
i'm not sure to genetics but

538
00:35:57,500 --> 00:36:03,370
i want you to understand that there is an overarching framework that explains how all

539
00:36:03,370 --> 00:36:07,510
the materials you're going to see released in the first half or more of this

540
00:36:07,510 --> 00:36:12,360
course fit together and eventually but i mention it again

541
00:36:12,390 --> 00:36:15,940
i will use this following diagram

542
00:36:15,950 --> 00:36:19,070
it's kind of our roadmap for subway map of

543
00:36:19,080 --> 00:36:21,020
we're we're going in this course

544
00:36:21,030 --> 00:36:27,610
what we really want to do is understand biological function

545
00:36:27,710 --> 00:36:31,650
most how is it that an organism is able to

546
00:36:31,660 --> 00:36:35,610
breathing air and distributed to its cells how is it an organism is able to

547
00:36:35,610 --> 00:36:39,770
move its muscles how is it that organism is able to fight off in the

548
00:36:39,770 --> 00:36:44,930
invaders through its body microbes things like that how is it that an embryo develops

549
00:36:44,930 --> 00:36:49,170
into a full adult zillions of questions asked by biological function

550
00:36:51,020 --> 00:36:56,180
two complementary approaches to studying biological function over the course of the past

551
00:36:56,220 --> 00:36:59,530
century or so in biology have been the following

552
00:36:59,650 --> 00:37:02,860
there have been the biochemistry

553
00:37:07,670 --> 00:37:13,130
six to break down the organism into individual components and study them on their own

554
00:37:13,130 --> 00:37:14,150
and the test

555
00:37:14,160 --> 00:37:18,850
they will take an organism to a biochemist wishing to study the beauty of a

556
00:37:18,850 --> 00:37:24,170
butterfly flapping in the wind and understanding of the mechanics of of of how it

557
00:37:24,170 --> 00:37:28,210
could possibly flat those wings at all he was here she would start by taking

558
00:37:28,210 --> 00:37:31,020
the butterfly putting in blunder pressing pur

559
00:37:31,030 --> 00:37:35,060
and making an extract and try to purify individual components that would that would explain

560
00:37:35,060 --> 00:37:37,300
muscles moving back and forth and all that

561
00:37:37,310 --> 00:37:41,510
this is of course the geneticist point of view but it's all right you have

562
00:37:41,510 --> 00:37:46,150
to have bob whose whole represent biochemistry just fine and then what they want to

563
00:37:46,150 --> 00:37:49,840
purify at individual components

564
00:37:49,860 --> 00:37:51,800
individual components

565
00:37:51,810 --> 00:37:55,150
away from the audience

566
00:37:55,170 --> 00:38:03,240
and the most important individual type of components of a study of proteins

567
00:38:03,290 --> 00:38:06,670
because the resilience of proteins and they do all sorts of things in the body

568
00:38:07,010 --> 00:38:10,690
and so you could say in some sense that this whole theme of biochemistry which

569
00:38:10,710 --> 00:38:13,780
that started at the turn of the twentieth century really just just a few years

570
00:38:13,780 --> 00:38:18,050
before the turn of the twentieth century of writing up an organism studying its components

571
00:38:18,050 --> 00:38:22,130
in being able to find for example to understand how i can digest lunch

572
00:38:22,150 --> 00:38:27,350
well how you can digest the sugars trying to use fraction eight find some protein

573
00:38:27,350 --> 00:38:30,620
that's able to digest the sugar all by itself without the rest of the organism

574
00:38:30,620 --> 00:38:35,060
an enzyme to do that that's the logic of biochemistry

575
00:38:35,080 --> 00:38:38,330
genetics is the complementary point of view

576
00:38:38,340 --> 00:38:41,310
genetics is the study of organisms

577
00:38:41,390 --> 00:38:45,770
minus one component

578
00:38:47,430 --> 00:38:48,480
of course

579
00:38:48,490 --> 00:38:50,990
what i mean by that i mutants

580
00:38:51,000 --> 00:38:56,690
the geneticists who wants to understand the butterflies and how the butterfly can can can

581
00:38:57,420 --> 00:39:02,960
will isolate butterfly strains that have lost the ability to fly

582
00:39:02,970 --> 00:39:07,780
and ideally one is extremely close to related to the normal butterfly and but but

583
00:39:07,780 --> 00:39:12,230
for some reason ideally due to the mutation of a single component and alan able

584
00:39:12,230 --> 00:39:16,820
to fly and the geneticists within say a high that component must matter awful lot

585
00:39:16,820 --> 00:39:21,510
for the ability to fly because the butterfly lacks that components can fly

586
00:39:21,520 --> 00:39:26,540
it's totally complementary point of view and the objects the geneticists study in order to

587
00:39:26,540 --> 00:39:28,420
do that our genes

588
00:39:28,440 --> 00:39:32,740
now what is of course

589
00:39:32,790 --> 00:39:36,080
hard for you guys to understand but will form of structure for some of the

590
00:39:36,080 --> 00:39:40,450
lectures i'm going to give over the continuous part of course is that through most

591
00:39:40,450 --> 00:39:42,160
of the twentieth century

592
00:39:42,170 --> 00:39:47,980
the folks to study biochemistry try to understand proteins folks wants to study genetics and

593
00:39:47,980 --> 00:39:49,890
try to understand mutants

594
00:39:49,940 --> 00:39:52,600
i had nothing to say to each other

595
00:39:52,620 --> 00:39:56,520
they didn't speak the same language they had nothing to relate to each other by

596
00:39:56,890 --> 00:40:01,150
because there was no idea of how those genes stock

597
00:40:01,170 --> 00:40:06,130
which started as a totally abstract business could possibly related protein stuff

598
00:40:06,150 --> 00:40:10,620
which started as you know very practical and the best thing and they went for

599
00:40:10,620 --> 00:40:13,930
a very long time as if they were to ships sailing in the dark and

600
00:40:13,940 --> 00:40:18,950
where each other and i exaggerate but it's more true than not

601
00:40:19,000 --> 00:40:21,960
the great intellectual

602
00:40:23,290 --> 00:40:26,090
was the unification of these two points of view

603
00:40:26,100 --> 00:40:29,180
through the discipline of molecular biology

604
00:40:29,230 --> 00:40:37,900
molecular biology was the discipline that realize oh my goodness institute from queens of the

605
00:40:37,900 --> 00:40:42,540
stone inside the same like that in fact genes encode proteins proteins are encoded by

606
00:40:42,540 --> 00:40:44,800
genes hard

607
00:40:44,800 --> 00:40:49,490
and now they should this actually we want to deal with large amounts of data

608
00:40:49,540 --> 00:40:53,300
and want to deal with it using relational databases and one key should that that

609
00:40:53,340 --> 00:40:56,510
we don't want to move data around you don't want to take the data from

610
00:40:56,510 --> 00:41:00,300
the database and loaded for example in our reasoning main memory because it might not

611
00:41:00,300 --> 00:41:03,670
be possible we cannot go several gigabytes of data and deal with it in main

612
00:41:03,670 --> 00:41:08,220
memory so one key point here is to keep the data in the sources and

613
00:41:08,220 --> 00:41:10,030
not move it around

614
00:41:10,050 --> 00:41:15,260
and that's why we need to devise a suitable mechanisms and technology such that the

615
00:41:15,260 --> 00:41:19,390
ontology can map to the data the data is kept in the data sources and

616
00:41:19,440 --> 00:41:23,490
this is very much related to notions in data integration and is that they will

617
00:41:23,490 --> 00:41:26,530
go quite in detail about this part

618
00:41:27,610 --> 00:41:28,950
so the question is that we

619
00:41:28,990 --> 00:41:32,590
i want to do that we ask ourselves into which we try to provide an

620
00:41:32,590 --> 00:41:34,720
answer to tour the following

621
00:41:34,730 --> 00:41:37,550
first of all which is the right query language using in such a context to

622
00:41:37,550 --> 00:41:39,360
to address operations

623
00:41:39,430 --> 00:41:43,030
the second question is which is the right ontology language is a language that allows

624
00:41:43,040 --> 00:41:49,450
us to deal with data efficiently while still keeping to counter semantics and doing reasoning

625
00:41:49,480 --> 00:41:53,300
then how can we bridge the semantic mismatch that we have between

626
00:41:53,320 --> 00:41:58,920
the ontology where we have observed object and the data sources where we have values

627
00:41:58,930 --> 00:42:03,740
and so in in a relational database strings numbers we don't have objects so there

628
00:42:03,740 --> 00:42:05,740
is a mismatch which we need to bridge

629
00:42:05,740 --> 00:42:12,440
and all of these for all of these want support from two

630
00:42:12,450 --> 00:42:13,320
and so on

631
00:42:13,350 --> 00:42:18,290
the question then across this reaches is how can ontology based

632
00:42:19,180 --> 00:42:24,810
deal with accessing large amounts of data and integrating large amounts of data while taking

633
00:42:24,810 --> 00:42:26,950
into account here

634
00:42:26,970 --> 00:42:31,800
and we will try to provide some answers and some solutions to these questions in

635
00:42:31,800 --> 00:42:33,220
this tutorial

636
00:42:33,230 --> 00:42:38,420
let's let's start with the first question namely the query language

637
00:42:38,430 --> 00:42:43,140
so can include data through ontologies now if you look at which clear language use

638
00:42:43,360 --> 00:42:48,430
we can consider to extreme cases one case is the one that is deeply considered

639
00:42:48,430 --> 00:42:53,180
in knowledge representation so to use essentially classes and properties of the ontology

640
00:42:53,190 --> 00:42:57,470
two also to query so we ask for the instances of a class

641
00:42:57,510 --> 00:43:02,910
and this is what is called instance checking in description logics ontology languages

642
00:43:02,930 --> 00:43:07,110
the other extreme is to go towards full SQL

643
00:43:07,160 --> 00:43:09,560
OK what is used in databases which

644
00:43:09,570 --> 00:43:14,140
by the way amounts to using first order logic is a query language

645
00:43:14,260 --> 00:43:20,840
for those of you unfamiliar this SQL corvettes SQL is equivalent to first-order logic

646
00:43:22,680 --> 00:43:23,450
that's it

647
00:43:23,470 --> 00:43:26,030
because very briefly these two extremes now

648
00:43:26,610 --> 00:43:32,140
using just classes and properties is in general not really what we are that why

649
00:43:32,140 --> 00:43:38,190
because while ontology language i really tailored that good at capturing intensional knowledge not that's

650
00:43:38,190 --> 00:43:40,890
clearly the the because they are not able to

651
00:43:40,930 --> 00:43:42,280
essentially it

652
00:43:42,290 --> 00:43:46,500
so ontology language they don't use explicit verbose and that can be used in in

653
00:43:46,500 --> 00:43:48,410
first order logic to create joins

654
00:43:48,430 --> 00:43:53,350
to create a market connections from one object to other objects an ontology languages don't

655
00:43:53,350 --> 00:43:54,990
have this ability so

656
00:43:55,630 --> 00:44:00,800
they allow only for very restricted forms of joint essentially chaining individual that's what they

657
00:44:00,800 --> 00:44:04,060
can express but is in general sufficiently want to create data

658
00:44:04,070 --> 00:44:07,420
so ontology languages are not good query languages

659
00:44:07,430 --> 00:44:11,550
on the other hand going towards full SQL is problematic why

660
00:44:11,560 --> 00:44:15,230
because here in the context not you not answering queries on the database in the

661
00:44:15,230 --> 00:44:20,700
context of incomplete information we want to reason about data and using SQL of first

662
00:44:20,700 --> 00:44:25,940
order logic in while doing reasoning i mean we have to face the problem that

663
00:44:25,940 --> 00:44:31,280
this is essentially undecidable so we cannot use first-order logic why fully take into account

664
00:44:31,280 --> 00:44:36,690
the semantics having inference procedures that i have written to sound and complete with respect

665
00:44:36,690 --> 00:44:39,220
to the semantic problem is undecidable

666
00:44:40,720 --> 00:44:43,740
the solution is to look for something in between

667
00:44:44,980 --> 00:44:50,980
one good candidate as a query language are conjunctive queries and units of conjunctive queries

668
00:44:50,980 --> 00:44:55,640
why because this if disagree languages have already been considered in the context of incomplete

669
00:44:55,640 --> 00:45:03,110
information mainly in in information integration they are quite expressive they capture most of the

670
00:45:03,220 --> 00:45:05,440
features that users post

671
00:45:05,490 --> 00:45:11,870
and they correspond to a fragment of SQL relational algebra that this has been well

672
00:45:11,870 --> 00:45:15,190
studied and for which also database engine optimized

673
00:45:15,210 --> 00:45:19,790
so let me to select project join fragments

674
00:45:19,850 --> 00:45:24,270
also just as a market will just be discussed briefly conjunctive queries can also be

675
00:45:24,270 --> 00:45:28,780
written as sparql queries and using his part syntax so for those of you unfamiliar

676
00:45:28,780 --> 00:45:34,370
with sparql know already conjunctive queries effect show two late using will use precise spot

677
00:45:34,370 --> 00:45:36,630
the syntax conjunctive query

678
00:45:36,640 --> 00:45:38,810
now that conjunctive queries

679
00:45:38,820 --> 00:45:42,950
the conjunctive query can be written as a first order query so first or expression

680
00:45:42,950 --> 00:45:48,630
that just uses some operator first order logic namely just conjunction and the existential quantification

681
00:45:48,880 --> 00:45:51,900
so it's essentially conjunction of forms

682
00:45:51,920 --> 00:45:56,990
with variables that are either the one thing which really interested in all existentially quantified

683
00:45:56,990 --> 00:45:59,560
and they can also be constant various terms

684
00:45:59,580 --> 00:46:02,150
and now when we create an ontology design items

685
00:46:02,170 --> 00:46:03,200
can be the

686
00:46:03,220 --> 00:46:04,500
concepts and

687
00:46:04,600 --> 00:46:08,840
of the classes and properties of the ontology when we create databases are be just

688
00:46:08,840 --> 00:46:10,530
the database relations

689
00:46:10,590 --> 00:46:16,120
just validation purpose will also use the simpler notation where we drop this extension that

690
00:46:16,370 --> 00:46:19,490
because all that was that don't appear in what is called the head of the

691
00:46:19,490 --> 00:46:25,230
query i implicitly existentially quantified so it's not actually necessary to write explicitly these existential

692
00:46:25,230 --> 00:46:31,000
quantifier simplicity and we can recognise it in this expression

693
00:46:31,040 --> 00:46:34,000
and this is by the way what is called a datalog notation for which i

694
00:46:34,000 --> 00:46:37,520
think is very also use a common set of conjunction

695
00:46:37,530 --> 00:46:40,520
now let's look at an example

696
00:46:40,540 --> 00:46:44,190
if you simple example of an ontology

697
00:46:44,200 --> 00:46:45,410
which is our

698
00:46:45,640 --> 00:46:50,080
university domain so the running example we have used throughout the whole tutorial

699
00:46:50,100 --> 00:46:57,900
and it is actually design inclusion assertions between concepts disjointness assertions and they involve also

700
00:46:57,900 --> 00:46:59,370
properties now

701
00:46:59,370 --> 00:47:02,520
in some of the examples that i will use it will not use this notation

702
00:47:02,670 --> 00:47:07,120
use just graphically graphical notation which is equivalent to this one because i believe it

703
00:47:07,200 --> 00:47:09,500
easier to understand what we are talking about

704
00:47:09,530 --> 00:47:12,110
if we see a diagram like this instead of

705
00:47:12,120 --> 00:47:18,000
seeing a set of inclusion assertions like this notice that these that express exactly the

706
00:47:18,860 --> 00:47:24,040
it's a constraint on our domain as the set of inclusion assertions so get that

707
00:47:24,060 --> 00:47:28,250
it it for it to convey the the same information

708
00:47:28,500 --> 00:47:34,710
you know the main we have faculty member professors are a subclass of faculty so

709
00:47:34,710 --> 00:47:39,370
associate professors also faculty members we have associate professor and dean

710
00:47:39,380 --> 00:47:43,610
what professors by the way know as professor can be eighteen so these two classes

711
00:47:43,610 --> 00:47:46,660
are disjoint we also colleges

712
00:47:46,670 --> 00:47:47,960
a faculty member

713
00:47:47,990 --> 00:47:52,420
work for colleges deans and heads of colleges and by the way each college has

714
00:47:52,420 --> 00:47:57,000
exactly one unit each gene has exactly one college and each faculty members to work

715
00:47:57,000 --> 00:47:59,990
for one college and the college must have at least one

716
00:48:00,000 --> 00:48:04,270
a faculty member so this is essentially what is expressed in the set of inclusion

717
00:48:05,270 --> 00:48:08,820
use graphical notation and now

718
00:48:08,820 --> 00:48:15,660
starts on the second we have some laughs i see people at the pleasure for

719
00:48:15,660 --> 00:48:21,690
me to welcome olivier bousquet he is french so and he studied at all these

720
00:48:21,690 --> 00:48:23,640
big called sin

721
00:48:23,650 --> 00:48:29,820
paris in two thousand two he got his phd from the call polytechnic on concentration

722
00:48:29,820 --> 00:48:33,670
inequalities and empirical process theory for machine learning

723
00:48:33,680 --> 00:48:37,620
his thesis was awarded the best pieces of the quality

724
00:48:37,630 --> 00:48:43,470
quite political technique and he also won the best paper award at the conference on

725
00:48:43,470 --> 00:48:46,760
learning theory during his phd time

726
00:48:46,770 --> 00:48:52,820
after his phd he moved shortly the US and then came to the MPI here

727
00:48:52,820 --> 00:48:56,560
where he worked for three years of senior post doc

728
00:48:57,290 --> 00:49:01,800
and that was before he turned to the dark side then went industry back to

729
00:49:01,820 --> 00:49:05,390
france in paris he worked at NASA says the

730
00:49:05,400 --> 00:49:10,420
research manager and recently moved to call the insurrection

731
00:49:10,470 --> 00:49:16,350
in his research career he was mostly interested in learning theory but he also contributed

732
00:49:16,350 --> 00:49:19,740
to more applied things so i heard you are

733
00:49:19,910 --> 00:49:27,280
co-author on semi supervised learning paper of any so he also knows what theory is

734
00:49:27,280 --> 00:49:28,240
good for

735
00:49:28,350 --> 00:49:31,790
before i give the word two

736
00:49:31,810 --> 00:49:36,240
well if you just let me mention that he was also the organizer of the

737
00:49:36,240 --> 00:49:39,790
last machine learning summer school into being and so i guess

738
00:49:39,920 --> 00:49:42,870
the nice for him to speaker again i

739
00:49:42,880 --> 00:49:49,710
morning morning everyone thank you very much for this introduction and i wish to thank

740
00:49:49,710 --> 00:49:54,240
the organisers for fighting first and also parents

741
00:49:54,620 --> 00:49:56,230
it's kind of a

742
00:49:56,250 --> 00:49:59,560
an important moment for me because four years ago i was in this room and

743
00:49:59,560 --> 00:50:02,340
i was introducing the speakers

744
00:50:02,360 --> 00:50:05,200
and i know it's a lot of work in

745
00:50:05,970 --> 00:50:06,780
i mean it

746
00:50:06,830 --> 00:50:11,030
very difficult to organize such an event and to make it accessible and this one

747
00:50:11,030 --> 00:50:13,310
seems very successful so far

748
00:50:13,330 --> 00:50:16,880
so i won't be here at the end but i hope you will all

749
00:50:16,900 --> 00:50:23,460
give them a lot of applause at the end to congratulate the organiser for these

750
00:50:26,570 --> 00:50:31,340
OK so he was a bit i mean it was very nice dinner yesterday and

751
00:50:31,340 --> 00:50:32,500
a lot of drinks

752
00:50:33,280 --> 00:50:39,940
probably you were you would not be continuing what direction durational this talk so i

753
00:50:39,940 --> 00:50:43,570
will try to give you a very slow start this morning

754
00:50:43,580 --> 00:50:48,760
and hasbro and say that i have turned to the dark side

755
00:50:48,950 --> 00:50:51,670
which means that

756
00:50:51,720 --> 00:50:56,500
i started thinking about you know what is this all for the series the how

757
00:50:56,500 --> 00:50:59,780
does it help in practice and does it really make a difference in the real

758
00:50:59,780 --> 00:51:01,420
world when you're

759
00:51:01,900 --> 00:51:05,880
you know in the company and someone asked to design learning algorithms

760
00:51:05,900 --> 00:51:09,730
does it really helps to prevent hearing before

761
00:51:11,300 --> 00:51:12,950
so what we

762
00:51:12,970 --> 00:51:15,230
try to attempt in this lecture

763
00:51:15,270 --> 00:51:17,720
it is to show you that you know

764
00:51:17,830 --> 00:51:22,710
all the details mathematical details you can figure them out when you look at the

765
00:51:22,710 --> 00:51:28,880
papers you want you know enough of you know what the definition that you can

766
00:51:28,890 --> 00:51:31,570
more this figure out that details understand

767
00:51:31,580 --> 00:51:33,340
the proofs of the papers

768
00:51:33,700 --> 00:51:38,600
what is harder though is to understand the meaning behind the school or really

769
00:51:39,480 --> 00:51:43,580
you can infer from this series and what what you can do in practice and

770
00:51:43,580 --> 00:51:44,990
how does it help you

771
00:51:45,000 --> 00:51:49,620
or guide you towards building the right and so this really be really the goal

772
00:51:49,620 --> 00:51:51,290
of these pictures

773
00:51:51,550 --> 00:51:53,330
there was three parts of

774
00:51:53,340 --> 00:51:53,970
with a

775
00:51:53,980 --> 00:51:56,270
we will look into

776
00:51:57,310 --> 00:51:59,290
so what are what and why

777
00:51:59,360 --> 00:52:03,830
which is you know what is learning theory and why i was studying it

778
00:52:04,680 --> 00:52:09,740
what are the foundations and will in the second part of this picture with this

779
00:52:09,740 --> 00:52:12,030
person would not renounce theorem which is

780
00:52:12,220 --> 00:52:14,930
i think an important piece of it

781
00:52:14,980 --> 00:52:17,490
and tomorrow we go into the bounds

782
00:52:17,540 --> 00:52:21,920
and show i i will show you how to put some bounds on how to

783
00:52:21,940 --> 00:52:26,120
they around with the different techniques that exists

784
00:52:27,310 --> 00:52:28,640
they have to tomorrow

785
00:52:28,650 --> 00:52:32,320
i will discuss it with the implication and the consequences how to interpret these these

786
00:52:34,310 --> 00:52:35,310
so again

787
00:52:35,830 --> 00:52:37,960
the goal of this course is not really

788
00:52:38,050 --> 00:52:43,310
it's not really true

789
00:52:43,320 --> 00:52:46,620
you know give you a lot of the results a lot of but more you

790
00:52:46,860 --> 00:52:50,790
look the nation's keep things simple and really

791
00:52:50,810 --> 00:52:54,510
give insight that but i'm trying to do do most of the day i mean

792
00:52:54,510 --> 00:52:56,360
most of the picture

793
00:52:56,440 --> 00:52:58,680
and we of course cover

794
00:52:58,690 --> 00:53:02,980
i think that the story of the domain general results and advanced topics

795
00:53:03,000 --> 00:53:07,380
so let's start

796
00:53:07,430 --> 00:53:08,970
so before

797
00:53:08,990 --> 00:53:12,240
telling you what is learning here you have to tell you what is this here

798
00:53:12,260 --> 00:53:14,430
and what is the goal of

799
00:53:14,580 --> 00:53:16,100
you know

800
00:53:16,230 --> 00:53:18,180
finding serial

801
00:53:18,700 --> 00:53:19,390
this is

802
00:53:19,840 --> 00:53:22,330
i mean definition of what is the series

803
00:53:22,380 --> 00:53:25,830
and i have a slightly important words here

804
00:53:25,920 --> 00:53:29,800
important is that we are looking at the phenomenon and we try to explain this

805
00:53:30,910 --> 00:53:35,270
and we want to explain it in a repeatable way

806
00:53:35,290 --> 00:53:37,390
and also

807
00:53:37,400 --> 00:53:43,430
this explanation should help us to make predictions about this phenomenon that's the important point

808
00:53:43,440 --> 00:53:46,190
so in a way you can think of history as model

809
00:53:46,300 --> 00:53:48,390
something that kind of represents

810
00:53:48,650 --> 00:53:49,950
or describe

811
00:53:50,010 --> 00:53:51,870
some phenomena

812
00:53:53,040 --> 00:53:55,460
that's model helps us understand the

813
00:53:55,470 --> 00:53:57,150
you know the various

814
00:53:57,190 --> 00:54:01,200
things that happen when you want to experiment in this case it would be the

815
00:54:01,200 --> 00:54:03,790
phenomenon of running of course

816
00:54:03,870 --> 00:54:08,390
and of course predict what's going to happen later

817
00:54:08,410 --> 00:54:11,470
two more definitions that would be useful

818
00:54:11,690 --> 00:54:13,920
this lecture

819
00:54:13,940 --> 00:54:18,400
deduction and induction these are often opposed and actually they are of course if you

820
00:54:18,730 --> 00:54:19,530
look at the

821
00:54:20,600 --> 00:54:22,140
the deduction is really

822
00:54:22,190 --> 00:54:24,050
you go from there

823
00:54:24,070 --> 00:54:28,840
general axioms the general rules and to try to derive consequences

824
00:54:28,850 --> 00:54:33,340
so you go from the general to specific and specific is saying here so you

825
00:54:33,340 --> 00:54:35,870
go from the action and to right

826
00:54:35,890 --> 00:54:38,470
european approval

827
00:54:38,520 --> 00:54:39,580
this is really

828
00:54:39,590 --> 00:54:41,760
what mathematics is is all about

829
00:54:41,780 --> 00:54:45,610
induction is more what physics is all about which is

830
00:54:45,680 --> 00:54:50,120
you look at a specific examples you make observations about the nature and then you

831
00:54:50,120 --> 00:54:55,350
try to infer the the general principle that the actions of nature

832
00:54:55,390 --> 00:54:59,230
this is how you create is usually from observing nature

833
00:54:59,270 --> 00:55:02,380
there's also something in between the ages of action

834
00:55:02,430 --> 00:55:04,160
which should probably have heard of

835
00:55:04,170 --> 00:55:09,260
which is going from specific to specific without even mentioning model

836
00:55:09,360 --> 00:55:11,050
but these are

837
00:55:11,070 --> 00:55:12,450
two important things

838
00:55:12,490 --> 00:55:17,660
from general to specific of specific genome

839
00:55:17,710 --> 00:55:22,480
so what is a good theory series one that is

840
00:55:22,530 --> 00:55:27,520
you know intuitively makes sense for and which is simple and concise so you have

841
00:55:27,520 --> 00:55:29,340
a lot of observation and you can

842
00:55:29,770 --> 00:55:33,790
look outside of sort of a lot of natural phenomena and if you can explain

843
00:55:33,790 --> 00:55:36,600
pixels where white is positive and black is negative

844
00:55:36,670 --> 00:55:38,510
so you can see this guy here

845
00:55:38,570 --> 00:55:41,970
he has learned little feature like this he likes to be so destroyed and he

846
00:55:41,970 --> 00:55:44,270
really is this you don't have anything

847
00:55:44,290 --> 00:55:49,000
so if you turn this guy on the train generation image looks like that

848
00:55:49,020 --> 00:55:51,160
and if you turn on some subset

849
00:55:51,170 --> 00:55:52,890
about twenty of these guys

850
00:55:52,900 --> 00:55:56,390
it turns out if you turn on the sensible subset attractive generate images just like

851
00:55:56,390 --> 00:55:57,900
it two

852
00:56:01,530 --> 00:56:03,240
here's an example

853
00:56:04,230 --> 00:56:06,680
after learning i show it some more tombs

854
00:56:06,680 --> 00:56:08,690
but is never seen before

855
00:56:08,710 --> 00:56:14,830
and i ask you to reconstruct

856
00:56:15,100 --> 00:56:17,620
does a pretty good job reconstructing

857
00:56:17,670 --> 00:56:21,210
the reconstructions have been more regular in the real data

858
00:56:21,270 --> 00:56:25,180
but he we construct very well for a whole variety of tissues

859
00:56:25,220 --> 00:56:28,770
that's with only fifty feature vectors so you can think of is activated subset of

860
00:56:28,770 --> 00:56:32,440
them and then basically added together the weights that subset

861
00:56:32,450 --> 00:56:35,040
put on function and change the image

862
00:56:35,090 --> 00:56:38,220
and it does jolly good job reconstructing tissues

863
00:56:38,240 --> 00:56:43,890
it's not quite perfect when you get a very unusual feature like vertical tail

864
00:56:43,970 --> 00:56:48,280
very few twos have it makes it sort of messes up with it

865
00:56:49,580 --> 00:56:52,360
but it does quite a good job within fifty feature vectors now what we're going

866
00:56:52,370 --> 00:56:53,130
to do

867
00:56:53,140 --> 00:56:56,040
it is we going to take this model was trained on two is the police

868
00:56:56,060 --> 00:57:01,760
the whole world consists of two years and insurance threes

869
00:57:06,180 --> 00:57:12,180
it's a bit like showing george bush real data

870
00:57:12,200 --> 00:57:16,160
now it has opinions about what the world should be like

871
00:57:17,540 --> 00:57:20,010
this is what he sees be

872
00:57:20,020 --> 00:57:26,990
think about the difference in two thousand three is the difference is that you know

873
00:57:26,990 --> 00:57:28,840
threes don't join up there

874
00:57:28,840 --> 00:57:30,130
and they don't have the tail

875
00:57:30,140 --> 00:57:33,320
but we can fix that we just drop out of the input over here

876
00:57:33,340 --> 00:57:36,410
and hey presto we didn't change much in institute

877
00:57:36,420 --> 00:57:41,790
so it's easy to know if we turn on the learning it will very quickly

878
00:57:41,790 --> 00:57:46,000
learn to do that and we learn to deal with twos and threes

879
00:57:46,090 --> 00:57:51,170
OK so that's a little example of this algorithm runs to show it works

880
00:57:51,250 --> 00:57:54,930
this is sort of a bit of an aside but

881
00:57:54,980 --> 00:58:00,980
i want to distinguish a whole bunch of ways of combining probabilistic models

882
00:58:01,040 --> 00:58:04,840
so one thing we are all very familiar with is if you have

883
00:58:04,880 --> 00:58:07,350
kind of probabilistic model as a gaussians

884
00:58:07,360 --> 00:58:09,820
you can have a bunch of those

885
00:58:09,860 --> 00:58:13,890
on average the distributions together take some weighted average of those distributions that some action

886
00:58:15,150 --> 00:58:17,630
the problem with the mixture is

887
00:58:17,740 --> 00:58:23,180
the combined distribution can never be sharper than the sharpest of the individual distributions

888
00:58:23,230 --> 00:58:25,220
so i'm never gonna get very sharp

889
00:58:25,230 --> 00:58:27,390
representations of things that way

890
00:58:27,430 --> 00:58:32,360
an alternative is to take part in the distributions we normalize

891
00:58:32,360 --> 00:58:35,450
so i could take a whole bunch of guys into multiply them together

892
00:58:35,470 --> 00:58:36,530
if i takes a

893
00:58:36,540 --> 00:58:39,680
OK seeing here guessing here and i multiply them together

894
00:58:39,710 --> 00:58:41,530
what i get is

895
00:58:41,560 --> 00:58:44,570
something attainable goes in the middle

896
00:58:44,610 --> 00:58:45,870
that'll have

897
00:58:45,880 --> 00:58:48,110
half the variance of the gaussians and here

898
00:58:48,130 --> 00:58:52,760
and there's almost no probability mass there but when we normalise it turns into gas

899
00:58:52,920 --> 00:58:54,910
the middle

900
00:58:54,920 --> 00:58:58,120
one is the more multiply together the shopper things get

901
00:58:58,120 --> 00:59:03,630
so by having very vague individual models multiplying together get very short

902
00:59:03,710 --> 00:59:05,920
i can't do that with a mixture

903
00:59:05,930 --> 00:59:11,440
but i have this normalization to make slow difficult

904
00:59:11,460 --> 00:59:15,470
and you can think of restricted boltzmann machines as being a product model

905
00:59:15,490 --> 00:59:18,240
in fact is the product of mixtures

906
00:59:18,290 --> 00:59:21,820
so each of the hidden units is saying i mixture model

907
00:59:21,830 --> 00:59:22,900
if i

908
00:59:24,510 --> 00:59:27,040
then i believe in a uniform distribution

909
00:59:27,090 --> 00:59:28,960
if i'm all

910
00:59:28,980 --> 00:59:30,660
i believe in

911
00:59:31,400 --> 00:59:35,920
factorial distribution across visible units where the probability beta visible unit is

912
00:59:35,940 --> 00:59:39,180
the sigmoid of the weight of my connection

913
00:59:39,190 --> 00:59:42,790
so put weight on the connections are majestic that's the probability of each of the

914
00:59:42,820 --> 00:59:44,760
units for the independent

915
00:59:44,780 --> 00:59:46,910
and then when you turn on a bunch of these guys

916
00:59:46,910 --> 00:59:50,000
you get the products of all these distributions

917
00:59:50,060 --> 00:59:51,980
that's what you do when you add up all these

918
00:59:53,940 --> 00:59:56,650
restricted boltzmann machine is the product model

919
00:59:56,650 --> 01:00:01,750
each hidden unit is one little probabilistic model there be multiplied together

920
01:00:01,810 --> 01:00:04,760
and what we can do now is we can take this product models

921
01:00:04,790 --> 01:00:07,320
and we're going to compose

922
01:00:07,320 --> 01:00:11,040
that's another way to combine models where we take the hidden units one model

923
01:00:11,430 --> 01:00:14,360
we make the data for the next model

924
01:00:14,400 --> 01:00:15,680
so that the

925
01:00:15,690 --> 01:00:19,310
input to the next restricted boltzmann machine is the

926
01:00:19,320 --> 01:00:21,130
in units of the previous one

927
01:00:21,200 --> 01:00:23,850
so sort stuck in

928
01:00:23,920 --> 01:00:27,530
so you can think of one theme of this tutorial is these guys were better

929
01:00:27,530 --> 01:00:28,900
than those guys

930
01:00:28,950 --> 01:00:32,840
and in particular if you take these guys and you compose and together you get

931
01:00:32,840 --> 01:00:37,780
something really nice

932
01:00:37,900 --> 01:00:40,690
so the main reason is restricted boltzmann machines are interesting

933
01:00:40,750 --> 01:00:44,230
it's because you can compose that you construct come up

934
01:00:44,280 --> 01:00:46,810
and we're going to learn in the following way

935
01:00:46,840 --> 01:00:48,580
which i would justify minute

936
01:00:49,680 --> 01:00:53,420
we cannot regular features and just where i just showed you

937
01:00:53,420 --> 01:00:57,070
then when you take the activations of those features when the model being driven by

938
01:00:58,280 --> 01:01:01,680
and we could take the binding activations we could actually is real that use the

939
01:01:01,680 --> 01:01:05,740
theory is much cleaner if you say take binary activations he works but in practice

940
01:01:05,750 --> 01:01:10,290
if you take real values but all stick with the theory

941
01:01:11,090 --> 01:01:11,960
you take up

942
01:01:12,000 --> 01:01:13,590
you take data

943
01:01:16,100 --> 01:01:17,980
activate your feature vectors

944
01:01:18,000 --> 01:01:20,950
you take the binary states the feature vectors

945
01:01:20,960 --> 01:01:24,660
and then the data for training the next restricted boltzmann machines to the next level

946
01:01:25,440 --> 01:01:27,530
so it's kind of a simple as it could be

947
01:01:28,690 --> 01:01:31,160
the actual algorithm

948
01:01:31,180 --> 01:01:34,900
and what you can show is that we would like to show is that it

949
01:01:34,900 --> 01:01:35,930
takes some data

950
01:01:35,960 --> 01:01:39,100
they build a restricted boltzmann she model this data

951
01:01:39,140 --> 01:01:40,420
so far

952
01:01:40,430 --> 01:01:43,880
generate from my model generate stuff a bit like the data

953
01:01:43,920 --> 01:01:46,610
if i know i don't know the hidden load

954
01:01:46,650 --> 01:01:48,360
sufficient size

955
01:01:48,410 --> 01:01:50,200
and had in the right way

956
01:01:50,220 --> 01:01:52,170
i'd like to be able to guarantee

957
01:01:52,170 --> 01:01:55,410
in this sort of expected sense that i get a better model of the data

958
01:01:55,430 --> 01:01:58,210
about another layer can always improve the model

959
01:01:58,240 --> 01:02:00,620
this model really perfect

960
01:02:00,620 --> 01:02:02,960
and you can almost guarantee that

961
01:02:03,030 --> 01:02:05,480
we can't quite guarantee that the first time you do you can guarantee that you

962
01:02:05,490 --> 01:02:08,360
get a better model but in general as you add more layers what you can

963
01:02:08,360 --> 01:02:10,060
guarantee is that

964
01:02:10,090 --> 01:02:13,230
the more complicated models get with more

965
01:02:13,290 --> 01:02:14,370
it will be of

966
01:02:14,370 --> 01:02:18,000
i will have a better bound on the log probability of the data

967
01:02:18,030 --> 01:02:22,560
so you have a model the some variational bound this says the problems they must

968
01:02:22,560 --> 01:02:24,120
be at least as much

969
01:02:24,130 --> 01:02:26,270
when i add a new life

970
01:02:26,360 --> 01:02:28,660
and take the band for this deep model

971
01:02:28,680 --> 01:02:31,560
it's a better bound low probability will bigger

972
01:02:31,620 --> 01:02:33,730
necessarily model

973
01:02:33,750 --> 01:02:35,520
if you knew way

974
01:02:35,540 --> 01:02:44,000
so that's good enough you definitely sort of improving the travellers

975
01:02:44,020 --> 01:02:46,690
so let's suppose we do this

976
01:02:47,480 --> 01:02:48,460
three less

977
01:02:48,540 --> 01:02:52,020
so because i you take some data

978
01:02:52,060 --> 01:02:56,520
you learn a restricted boltzmann machine here so you learn these weights

979
01:02:56,540 --> 01:02:59,890
and they're kind of the same weights in both directions

980
01:02:59,910 --> 01:03:03,410
then you take the states of the hidden units

981
01:03:03,460 --> 01:03:04,770
that you've got by

982
01:03:04,790 --> 01:03:10,410
taking the data multiplying by these weights putting it through the majestic and sampling

983
01:03:10,410 --> 01:03:12,860
you say about the relative distances

984
01:03:12,880 --> 01:03:16,810
between this points

985
01:03:16,840 --> 01:03:21,190
they are also unique to

986
01:03:21,220 --> 01:03:26,870
what is means the falling if you have a set of points in the plane

987
01:03:26,880 --> 01:03:28,650
and you already know

988
01:03:28,670 --> 01:03:33,230
the distances that correspond to the edges of the graph

989
01:03:33,240 --> 01:03:35,400
then all the other distances

990
01:03:35,420 --> 01:03:40,600
are uniquely determined you can compute demonstration but you don't need to compute them to

991
01:03:40,600 --> 01:03:43,610
know that they are uniquely determined

992
01:03:46,020 --> 01:03:54,350
why this is important this is important for two reasons

993
01:03:57,130 --> 01:04:02,500
what's the maximal clique of a graph

994
01:04:02,600 --> 01:04:07,270
if you think the maximal clique of these graphs

995
01:04:08,290 --> 01:04:14,650
these on the picture

996
01:04:14,670 --> 01:04:21,940
the maximal clique of these graphs is four

997
01:04:22,000 --> 01:04:24,410
this is an example of a maximal clique

998
01:04:25,900 --> 01:04:27,360
in other words

999
01:04:27,410 --> 01:04:33,650
there are no five or more nodes in this graph that are only

1000
01:04:33,660 --> 01:04:36,770
the maximum number of

1001
01:04:36,810 --> 01:04:39,430
of nodes that are all neighbors

1002
01:04:39,490 --> 01:04:42,800
between themselves is four

1003
01:04:42,850 --> 01:04:47,170
for the maximal clique size of these graphs these peaks

1004
01:04:47,230 --> 01:04:51,370
it doesn't depend on the number of points

1005
01:04:51,380 --> 01:04:54,250
i can be as many as i want here

1006
01:04:54,270 --> 01:04:57,650
and the maximal clique is fixed

1007
01:04:57,710 --> 01:04:58,640
the first thing

1008
01:04:58,660 --> 01:05:00,000
the second thing

1009
01:05:00,010 --> 01:05:01,940
which is important about this graph

1010
01:05:01,990 --> 01:05:03,040
using graph

1011
01:05:03,100 --> 01:05:05,990
the and later or not

1012
01:05:06,030 --> 01:05:07,310
i think well

1013
01:05:07,320 --> 01:05:10,640
you'll find that the graph is already

1014
01:05:10,650 --> 01:05:13,660
because every cycle in the graph

1015
01:05:13,680 --> 01:05:15,720
as a course

1016
01:05:15,790 --> 01:05:17,890
if you think about this cycle here

1017
01:05:17,900 --> 01:05:23,370
has the score in a cycle of course when i see any cycle is any

1018
01:05:23,370 --> 01:05:27,510
cycle greater than three because the cycle of size three

1019
01:05:27,580 --> 01:05:32,760
by definition has no core

1020
01:05:32,800 --> 01:05:37,870
so the interesting thing about these graph is that it has very two properties that

1021
01:05:37,870 --> 01:05:40,750
are sufficient

1022
01:05:40,750 --> 01:05:43,630
to use the junction tree of

1023
01:05:43,660 --> 01:05:47,310
it is the three and later graph

1024
01:05:47,370 --> 01:05:50,710
that allows you to use the junction tree of

1025
01:05:50,720 --> 01:05:52,770
the size of the maximal clique

1026
01:05:52,790 --> 01:05:57,210
this fix it is independent of the number of moles independent on the problem in

1027
01:05:57,220 --> 01:05:58,590
the size of the

1028
01:05:58,610 --> 01:06:01,170
that makes the junction tree algorithm

1029
01:06:03,310 --> 01:06:06,270
so one thing allows you to use the junction tree algorithm

1030
01:06:06,340 --> 01:06:08,250
the other thing

1031
01:06:08,270 --> 01:06:11,020
it tells you that if you use the junction tree

1032
01:06:11,040 --> 01:06:11,960
you two have

1033
01:06:11,960 --> 01:06:13,630
only polynomial

1034
01:06:13,690 --> 01:06:15,630
complexity on the sizes

1035
01:06:15,690 --> 01:06:17,260
the graph

1036
01:06:17,270 --> 01:06:19,160
you can actually show

1037
01:06:19,170 --> 01:06:23,080
that these means basically

1038
01:06:23,100 --> 01:06:28,010
well you can generalize these results to any dimension actually

1039
01:06:30,900 --> 01:06:32,820
but let me just come back

1040
01:06:32,940 --> 01:06:35,160
a little bit

1041
01:06:35,320 --> 01:06:37,260
and show that

1042
01:06:37,260 --> 01:06:40,240
these graphs column globally rigid because there

1043
01:06:40,740 --> 01:06:46,650
the length of the edge is uniquely determined the lengths of the absence of edges

1044
01:06:46,650 --> 01:06:47,950
if you wish

1045
01:06:48,010 --> 01:06:50,530
is are globally rigid graph

1046
01:06:50,590 --> 01:06:52,550
we call this graph three three

1047
01:06:52,560 --> 01:06:54,070
this is the technical name

1048
01:06:54,090 --> 01:06:56,860
to call this graph

1049
01:06:56,880 --> 01:07:01,460
the generalisation of the three basically is the graph that you obtained by adding new

1050
01:07:02,160 --> 01:07:04,360
connected to

1051
01:07:04,420 --> 01:07:05,710
three previous

1052
01:07:05,740 --> 01:07:07,560
nodes which are

1053
01:07:07,590 --> 01:07:10,550
which is fully connected to each form strictly

1054
01:07:10,590 --> 01:07:12,150
and size of

1055
01:07:12,190 --> 01:07:14,190
clique sizes four

1056
01:07:14,210 --> 01:07:15,580
so originally

1057
01:07:15,610 --> 01:07:21,930
so in general you can prove that

1058
01:07:22,010 --> 01:07:24,190
k tree graph in other words

1059
01:07:24,200 --> 01:07:27,010
that one is true tree graph

1060
01:07:27,020 --> 01:07:31,930
so it has three reference note if you wish and the top

1061
01:07:31,930 --> 01:07:36,610
in general if you have a k tree graph so we came reference points in

1062
01:07:36,610 --> 01:07:39,180
the talk

1063
01:07:42,510 --> 01:07:46,090
you can solve the problem in i to came in well

1064
01:07:46,150 --> 01:07:48,300
so if you are in the plane

1065
01:07:48,320 --> 01:07:51,540
OK cayman on course to so k equals three so you need to keep the

1066
01:07:51,830 --> 01:07:53,560
tree three graph

1067
01:07:53,580 --> 01:07:58,360
if you are in this space three-dimensional space you need for reference point by the

1068
01:07:58,360 --> 01:08:00,970
that's exactly how GPS works

1069
01:08:00,980 --> 01:08:05,670
they're using this result

1070
01:08:05,680 --> 01:08:08,760
how do you know your position if you had distances

1071
01:08:08,770 --> 01:08:10,920
from yourself four satellite

1072
01:08:10,970 --> 01:08:14,220
you can determine

1073
01:08:14,230 --> 01:08:17,600
in the maximal clique size is fixed cables

1074
01:08:17,620 --> 01:08:20,170
so that's the case

1075
01:08:20,210 --> 01:08:22,040
i was talking before

1076
01:08:22,060 --> 01:08:24,620
that's the case

1077
01:08:24,670 --> 01:08:28,270
and basically the junction tree algorithm

1078
01:08:28,290 --> 01:08:31,440
if minimizing these things

1079
01:08:32,400 --> 01:08:35,010
OK tree graphical models

1080
01:08:35,020 --> 01:08:39,480
where these things is basically a sum over there

1081
01:08:39,480 --> 01:08:42,490
two the nuclear already here is the

1082
01:08:42,540 --> 01:08:46,720
i mean square ready depending on the neutron number four different

1083
01:08:46,770 --> 01:08:49,040
i said to be generic tree

1084
01:08:49,060 --> 01:08:51,260
gold platinum iridium so

1085
01:08:51,290 --> 01:08:54,520
you see you have these learned that you have some

1086
01:08:54,990 --> 01:08:58,020
so to structure here

1087
01:08:58,660 --> 01:09:03,690
just to mention that this experiment very precise experiment has been performed have been far

1088
01:09:03,690 --> 01:09:05,120
from here it's stand

1089
01:09:05,140 --> 01:09:10,690
using the eyes the practice of very precise measurement are proof from here from

1090
01:09:10,700 --> 01:09:13,830
ready masses etcetera

1091
01:09:14,470 --> 01:09:19,970
you see there are ways of this is the first experimental proof

1092
01:09:20,010 --> 01:09:21,100
of the lack of

1093
01:09:21,120 --> 01:09:22,910
accuracy of liquid drop

1094
01:09:22,930 --> 01:09:25,100
so the proof is they'll nuclei

1095
01:09:25,150 --> 01:09:29,560
so halo nuclei have been discovered and predicted by ten percent

1096
01:09:31,690 --> 01:09:35,160
and you see that this is for any equal eight isaac told you see the

1097
01:09:35,160 --> 01:09:39,290
different experimental results from root mean square

1098
01:09:39,340 --> 01:09:43,240
and you see that for each element new have very huge

1099
01:09:45,190 --> 01:09:48,030
so this is presented here where you have

1100
01:09:48,050 --> 01:09:50,830
you eleven which is very huge

1101
01:09:50,840 --> 01:09:55,460
using you have all their so far very light systems you don't follow

1102
01:09:55,510 --> 01:09:58,470
at all these these a one

1103
01:09:58,530 --> 01:10:02,310
law which is only an average

1104
01:10:02,360 --> 01:10:05,910
the second problem concerned the nuclear masses

1105
01:10:05,920 --> 01:10:11,240
so what is plotted here is the difference between experimental and theoretical masses calculated with

1106
01:10:11,240 --> 01:10:12,390
the liquid drop

1107
01:10:12,400 --> 01:10:15,340
in any v depending on the neutron number

1108
01:10:15,500 --> 01:10:18,550
and you see that you have an average very good

1109
01:10:18,570 --> 01:10:22,460
results are zero but you have some discrepancies here

1110
01:10:22,480 --> 01:10:23,560
some things

1111
01:10:23,580 --> 01:10:26,480
that can be applied to a few enemy

1112
01:10:26,500 --> 01:10:31,970
and it speaks appears for magic numbers eight twenty twenty eight fifty eighty two one

1113
01:10:31,970 --> 01:10:33,590
twenty six

1114
01:10:33,600 --> 01:10:35,250
it's always the same

1115
01:10:36,670 --> 01:10:42,300
whatever the isotopic see eye to set up to consider

1116
01:10:42,350 --> 01:10:46,510
so these numbers you can see that when you look at the

1117
01:10:46,520 --> 01:10:51,380
two neutron separation energy so two neutron separation energy the energy that you have to

1118
01:10:51,380 --> 01:10:54,800
put into the system to remove two neutrons

1119
01:10:54,810 --> 01:10:58,990
so you calculate that the difference between the binding energy of the nucleus you are

1120
01:11:00,240 --> 01:11:02,380
minus is the daughter nuclides

1121
01:11:02,400 --> 01:11:05,910
so if you look that as a function of the new numbers

1122
01:11:06,000 --> 01:11:09,430
so you see that you have a small c increase

1123
01:11:09,440 --> 01:11:10,810
and then ship

1124
01:11:10,840 --> 01:11:13,500
you have drops very sudden drops

1125
01:11:13,540 --> 01:11:15,220
so it means that

1126
01:11:15,270 --> 01:11:20,110
to remove so this proper sorry for magic nuclei

1127
01:11:20,120 --> 01:11:24,870
so it's it's show that this magic nuclei have very high

1128
01:11:25,730 --> 01:11:29,550
are very stable they have an increased particle stability

1129
01:11:29,560 --> 01:11:33,560
so if you want to extract particle from them you really have to

1130
01:11:33,580 --> 01:11:40,880
to put a lot of energy that cannot be reproduced by this liquid drop approach

1131
01:11:40,930 --> 01:11:45,820
third example of something which is not so good with this liquid drop is that

1132
01:11:45,820 --> 01:11:49,660
if you take a liquid then you want to have fish and you will only

1133
01:11:51,410 --> 01:11:56,710
symmetric fission that means fragment with the same mass in information improprieties

1134
01:11:56,730 --> 01:11:59,630
so but it's not the case experimentally

1135
01:11:59,680 --> 01:12:03,780
so these are very famous results of energy is saying germany

1136
01:12:03,830 --> 01:12:09,600
from this group so you have the fragment mass distribution for different fissioning system uranium

1137
01:12:09,600 --> 01:12:11,580
thorium opinion

1138
01:12:12,360 --> 01:12:15,100
you see them as distribution so what

1139
01:12:15,110 --> 01:12:18,920
if you have only one peak it means that the fragments

1140
01:12:18,950 --> 01:12:23,800
most probable fragments are identical so you have same fragments

1141
01:12:23,810 --> 01:12:27,010
but you see that it's not the case for all these nuclei

1142
01:12:27,150 --> 01:12:28,470
can here

1143
01:12:28,490 --> 01:12:31,950
two pick it means one small fragment one big

1144
01:12:31,960 --> 01:12:33,240
and most of these

1145
01:12:33,250 --> 01:12:35,450
i mean i said do have such

1146
01:12:38,130 --> 01:12:40,020
another important point here

1147
01:12:40,160 --> 01:12:44,500
that you are dealing with these then was one hundred thirty eight and eighty

1148
01:12:44,840 --> 01:12:48,570
proton and neutron so around two hundred forty nucleons

1149
01:12:48,580 --> 01:12:50,960
and you see that you change only one

1150
01:12:50,980 --> 01:12:53,300
and you completely changed features

1151
01:12:53,310 --> 01:12:55,440
that experimentally observed

1152
01:12:55,450 --> 01:12:57,440
so it means that

1153
01:12:57,490 --> 01:12:59,720
it's very difficult to treat something

1154
01:12:59,940 --> 01:13:02,030
as the war you really have to

1155
01:13:02,080 --> 01:13:05,810
to look carefully at the behavior of each

1156
01:13:08,540 --> 01:13:10,090
so because of that

1157
01:13:10,140 --> 01:13:12,210
it seems that

1158
01:13:12,260 --> 01:13:16,320
you can describe the system like these but you really have

1159
01:13:16,360 --> 01:13:20,340
to consider the nucleons and the interaction between them

1160
01:13:20,390 --> 01:13:23,020
so what i have shown before is that they are

1161
01:13:23,020 --> 01:13:26,650
cumulant generating function that's what we're computing there

1162
01:13:26,710 --> 01:13:31,980
you can in fact write it as some from x equals zero to one

1163
01:13:32,370 --> 01:13:37,000
of x times the probability of experts and expectation

1164
01:13:37,020 --> 01:13:40,350
and so it says this quantity here this is really just the probability that the

1165
01:13:40,350 --> 01:13:44,750
coin comes up heads that's the probability that x is equal to one

1166
01:13:44,810 --> 01:13:48,750
so that's a very special case of the mean parameter

1167
01:13:48,770 --> 01:13:52,080
and all i'm saying here is that this is true more generally that it doesn't

1168
01:13:52,080 --> 01:13:57,130
matter here the function i had was just x feedbacks is equal to x

1169
01:13:57,130 --> 01:14:00,770
but i could have any function in the same relation hold

1170
01:14:00,830 --> 01:14:08,790
so the the mean parameters are basically moments there's sort of moments of these profiles

1171
01:14:08,790 --> 01:14:11,750
actions that we started with the sufficient statistics

1172
01:14:11,770 --> 01:14:21,420
OK so what he here now is we we sort of seeing the

1173
01:14:21,440 --> 01:14:27,750
critical equation is whether or not we can choose status so the expectation of the

1174
01:14:27,750 --> 01:14:31,100
sufficient statistic is equal to the mu

1175
01:14:31,190 --> 01:14:34,540
new here just the fixed number that you're choosing

1176
01:14:34,560 --> 01:14:37,790
and we need to try and solve this equation we need to understand when that

1177
01:14:37,790 --> 01:14:43,110
equation has a solution

1178
01:14:43,170 --> 01:14:49,830
now what i'm doing here is is again just a more general version of what

1179
01:14:49,830 --> 01:14:51,500
i did before

1180
01:14:51,540 --> 01:14:56,310
so i didn't go into the details but it's not too hard to do

1181
01:14:56,330 --> 01:14:59,230
if you remember in the bernoulli case

1182
01:14:59,650 --> 01:15:03,400
when we assume that there was a solution to this equation

1183
01:15:03,420 --> 01:15:06,920
so that sort of the nice case when mu was in zero one

1184
01:15:06,920 --> 01:15:09,100
then you can go through a bit of algebra

1185
01:15:09,150 --> 01:15:13,940
and what we found is the dual function had the simple form

1186
01:15:13,980 --> 01:15:17,110
we found it was able to me a lot of music

1187
01:15:17,130 --> 01:15:21,920
i didn't go through his elder brother i encourage you to do it so it's

1188
01:15:21,920 --> 01:15:23,330
not hard

1189
01:15:23,350 --> 01:15:25,370
this is what we found is that

1190
01:15:25,370 --> 01:15:28,960
it has a nice form

1191
01:15:28,980 --> 01:15:32,310
when he was in

1192
01:15:32,350 --> 01:15:36,940
the zero one intro

1193
01:15:36,980 --> 01:15:44,080
and so for those of you who were familiar with entropy

1194
01:15:44,080 --> 01:15:48,210
you would have recognised this but for everyone else this turns out to be the

1195
01:15:49,230 --> 01:15:52,960
you can compute this with a little calculation this is the entropy of the distribution

1196
01:15:52,960 --> 01:15:57,650
it looks like this is actually the minus entropy the exact

1197
01:15:57,830 --> 01:16:01,520
so i'm doing here is is just more formally saying

1198
01:16:01,540 --> 01:16:05,770
o if i do have a solution i can go through some calculations and i'll

1199
01:16:05,770 --> 01:16:10,440
see that the dual function is minus entropy when you have a solution

1200
01:16:10,460 --> 01:16:12,560
so that that's not really anything new

1201
01:16:12,600 --> 01:16:16,770
and what this brings is really to the key thing this is something that i

1202
01:16:16,770 --> 01:16:18,500
hinted at before

1203
01:16:18,520 --> 01:16:20,650
and it's this question here

1204
01:16:20,670 --> 01:16:27,040
we really have to worry now about for which duties that equation has a solution

1205
01:16:27,060 --> 01:16:32,540
in this case we already worried about it and we sort of looked both analytically

1206
01:16:32,560 --> 01:16:39,290
and i geometrically and we solve this equation has solution when mu in zero one

1207
01:16:39,310 --> 01:16:42,290
but no solution otherwise

1208
01:16:42,330 --> 01:16:43,330
and so

1209
01:16:43,330 --> 01:16:49,190
otherwise was not zero one we saw before that we got plus infinity

1210
01:16:49,210 --> 01:16:52,690
right so this is the case when there was

1211
01:16:52,710 --> 01:16:57,270
no solution to the no stationary point

1212
01:16:59,920 --> 01:17:10,460
right so we need to sort of understand this question more generally

1213
01:17:10,480 --> 01:17:13,980
this example was very easy because

1214
01:17:15,210 --> 01:17:18,940
mu we've worked out is just the probability that the coin is one

1215
01:17:18,960 --> 01:17:22,500
so it makes perfect sense that you should be between zero and one if you

1216
01:17:22,500 --> 01:17:26,290
flip a coin the probability has been zero and one

1217
01:17:26,330 --> 01:17:30,330
when working with more complicated exponential families is not always easy and we'll see this

1218
01:17:30,330 --> 01:17:33,500
is actually very hard sometimes

1219
01:17:36,480 --> 01:17:38,810
so any questions so far

1220
01:17:39,150 --> 01:17:43,690
just to recap before i got question so we saw this example with

1221
01:17:44,130 --> 01:17:45,440
the bernouilli

1222
01:17:45,440 --> 01:17:48,830
we sort of what we can do this more generally and that's really just taking

1223
01:17:48,830 --> 01:17:52,630
the intuition we had from the special case and the same we can do it

1224
01:17:52,630 --> 01:17:54,560
in any exponential family

1225
01:17:54,600 --> 01:17:59,790
and we've argued so far that if this if we do have a stationary point

1226
01:17:59,870 --> 01:18:04,170
that in fact we get the dual function is negative entropy just like we had

1227
01:18:04,170 --> 01:18:05,750
over here

1228
01:18:05,770 --> 01:18:09,480
but now what we're worried about this is when we don't necessarily have a stationary

1229
01:18:09,480 --> 01:18:13,560
point what happens then we need to figure out what that means

1230
01:18:13,730 --> 01:18:23,520
they questions about that

1231
01:18:23,810 --> 01:18:27,940
so this is the word of encouragement we're almost there

1232
01:18:27,940 --> 01:18:35,130
implementation it's fast execution the fact the FFT the fast fourier transform

1233
01:18:35,170 --> 01:18:43,400
and if time permits i make some comments on the discrete cosine transform and

1234
01:18:43,410 --> 01:18:46,970
it's it also can be implemented by

1235
01:18:47,000 --> 01:18:48,410
the FFT

1236
01:18:48,430 --> 01:18:51,310
so it's equally fast

1237
01:18:51,570 --> 01:18:58,110
so actually this is pretty much to find whether were at the transition now short

1238
01:18:59,880 --> 01:19:02,550
so let's previous lecture was about

1239
01:19:02,560 --> 01:19:08,740
fourier transforms this one focuses on the discrete case and it's still in the applied

1240
01:19:09,510 --> 01:19:15,450
book section five is the fifteenth

1241
01:19:17,870 --> 01:19:20,440
and chapter four

1242
01:19:20,450 --> 01:19:25,310
as the material on fourier transforms in general

1243
01:19:27,090 --> 01:19:33,720
and of course you know that i'm going to give up matrix in its expression

1244
01:19:33,810 --> 01:19:37,170
to all to the main ideas

1245
01:19:37,170 --> 01:19:41,110
the main idea is being transformed

1246
01:19:41,140 --> 01:19:43,390
it's fast execution is

1247
01:19:44,880 --> 01:19:47,170
and the convolution

1248
01:19:47,300 --> 01:19:52,670
the central ideas of of the subject and familiar to many of you

1249
01:19:52,810 --> 01:19:59,080
you probably could get the a formula right more often than i

1250
01:20:00,440 --> 01:20:03,560
and in the second lecture today

1251
01:20:03,610 --> 01:20:07,080
will really to move into the way book

1252
01:20:07,090 --> 01:20:09,640
discussing filtering

1253
01:20:09,670 --> 01:20:15,330
actually in the same lecture i'm going to have filters in the time domain and

1254
01:20:15,330 --> 01:20:17,390
frequency domain in

1255
01:20:18,500 --> 01:20:20,170
the domain

1256
01:20:22,580 --> 01:20:23,360
the the

1257
01:20:23,360 --> 01:20:27,020
health care the basic tool of signal processing

1258
01:20:27,030 --> 01:20:28,360
OK so

1259
01:20:28,360 --> 01:20:32,170
here's a basic tool and i've written up

1260
01:20:32,220 --> 01:20:37,180
so we have to decide how many samples we have

1261
01:20:37,200 --> 01:20:39,080
capital and

1262
01:20:39,110 --> 01:20:43,670
and sometimes will run from zero to n minus one typically

1263
01:20:43,700 --> 01:20:50,980
and indices will go from zero to minus one so we have and samples

1264
01:20:51,010 --> 01:20:54,110
and we want to find and fourier coefficients

1265
01:20:54,140 --> 01:20:56,990
the discrete fourier coefficients that

1266
01:20:58,390 --> 01:21:02,370
so of so that the number

1267
01:21:02,390 --> 01:21:06,240
this complex number into the two pi over n

1268
01:21:06,270 --> 01:21:08,080
comes into the

1269
01:21:08,080 --> 01:21:12,920
everywhere here so let's be sure we've got that number pin down work in the

1270
01:21:12,920 --> 01:21:14,890
complex plane

1271
01:21:14,890 --> 01:21:15,770
and the drama

1272
01:21:15,890 --> 01:21:19,710
a circle of radius one the unit circle

1273
01:21:19,740 --> 01:21:22,050
so course this is the real axis

1274
01:21:22,070 --> 01:21:28,200
this is the imaginary axis so that that number right there would be i

1275
01:21:28,610 --> 01:21:32,200
and now wears the number w

1276
01:21:32,200 --> 01:21:34,800
is it on the circle

1277
01:21:36,980 --> 01:21:42,570
everything of modulus one absolute magnitude one is on the circle this is an e

1278
01:21:42,640 --> 01:21:43,240
the i

1279
01:21:44,540 --> 01:21:49,830
so say that the angle is two pi over n so where does it go

1280
01:21:49,870 --> 01:21:51,790
o one and

1281
01:21:51,800 --> 01:21:55,900
i mean the whole animal use two pi

1282
01:21:55,920 --> 01:22:00,270
and we will say the two pi and so we go

1283
01:22:00,270 --> 01:22:03,070
we take n to be eight

1284
01:22:03,080 --> 01:22:04,240
so that would be

1285
01:22:04,240 --> 01:22:06,450
either too high

1286
01:22:06,450 --> 01:22:08,800
i over eight

1287
01:22:08,830 --> 01:22:10,230
so let's w

1288
01:22:10,240 --> 01:22:13,450
maybe i should really call it w and

1289
01:22:13,460 --> 01:22:15,740
to indicate that it's

1290
01:22:15,770 --> 01:22:22,020
determined by the number and OK and now you're going to see powers of w

1291
01:22:22,020 --> 01:22:26,330
so let's just be sure we've got those down

1292
01:22:26,330 --> 01:22:29,850
why are we w squared for example

1293
01:22:29,860 --> 01:22:33,050
you notice i don't write the

1294
01:22:33,110 --> 01:22:37,920
rectangular the real and imaginary parts could

1295
01:22:37,930 --> 01:22:41,550
cosine and sine of two pi

1296
01:22:43,110 --> 01:22:45,880
when you multiply numbers

1297
01:22:46,880 --> 01:22:51,680
the this form is the polar form is much much better

1298
01:22:51,690 --> 01:22:54,540
and when those numbers are on the unit circle

1299
01:22:54,590 --> 01:22:58,040
so the polar are is one

1300
01:22:58,050 --> 01:23:01,900
then there's absolutely no question superior

1301
01:23:01,910 --> 01:23:06,610
this so our is one we just adding angles when we multiply so if i

1302
01:23:06,610 --> 01:23:09,600
swear that one what number again

1303
01:23:09,610 --> 01:23:16,680
i get i doubles the angle angle was two pi rate forty five degrees gobbles

1304
01:23:16,690 --> 01:23:17,800
two i

1305
01:23:17,800 --> 01:23:22,100
so that the cube that would be here and another

1306
01:23:22,110 --> 01:23:26,340
i take the cube by multiply by another

1307
01:23:26,360 --> 01:23:32,100
in two by over a dyad angle once more here's the fourth power

1308
01:23:32,110 --> 01:23:35,610
so this is w eight and

1309
01:23:35,610 --> 01:23:40,740
there's w eight square which is the same as w four and that's a big

1310
01:23:40,740 --> 01:23:47,410
deal actually the fact that w eights were does this same as w four and

1311
01:23:47,410 --> 01:23:51,090
in this example i

1312
01:23:51,110 --> 01:23:56,070
so i eventually if in the fast fourier transform i'm going to be interested in

1313
01:23:56,130 --> 01:24:00,350
the in the in in

1314
01:24:00,360 --> 01:24:04,050
and the half size transform

1315
01:24:04,070 --> 01:24:09,190
so this is anticipating what's coming that

1316
01:24:09,220 --> 01:24:13,320
here's an equal eight years

1317
01:24:13,350 --> 01:24:20,120
i am equal four and the point is the w and swearing is wm

1318
01:24:20,170 --> 01:24:22,710
and that's

1319
01:24:22,730 --> 01:24:24,400
trivial but

1320
01:24:24,400 --> 01:24:27,830
a row vector multiplying three by three matrix

1321
01:24:31,180 --> 01:24:33,120
what's the output

1322
01:24:33,140 --> 01:24:35,370
what's the product row

1323
01:24:39,340 --> 01:24:42,140
and OK it's a right

1324
01:24:42,160 --> 01:24:42,820
all right

1325
01:24:45,150 --> 01:24:49,530
sorry i matrix times column is the columns of matrix

1326
01:24:53,380 --> 01:24:55,180
times column

1327
01:24:55,230 --> 01:24:56,800
the column

1328
01:24:57,060 --> 01:24:59,860
and we know what column in it

1329
01:24:59,930 --> 01:25:04,040
over here i'm doing a road times the matrix and what and what is the

1330
01:25:04,320 --> 01:25:07,690
what the answer it's one of the first row

1331
01:25:07,700 --> 01:25:11,810
so it's one times one times rho one

1332
01:25:13,030 --> 01:25:15,430
two times wrote to

1333
01:25:16,220 --> 01:25:19,160
plus seven times wrote three

1334
01:25:19,220 --> 01:25:24,080
when as we do matrix multiplication

1335
01:25:24,090 --> 01:25:26,530
keep your eye on

1336
01:25:26,540 --> 01:25:29,570
what it's doing with all that

1337
01:25:29,580 --> 01:25:34,190
and what it's doing what what it's doing in this case is

1338
01:25:34,210 --> 01:25:37,580
it's combining the roles

1339
01:25:37,620 --> 01:25:41,320
we have a combination of a linear combination of the roles OK i want to

1340
01:25:41,320 --> 01:25:49,020
use that

1341
01:25:49,970 --> 01:25:54,830
so my question is what's the matrix that does this first

1342
01:25:54,860 --> 01:25:55,950
that takes

1343
01:25:55,970 --> 01:25:59,320
subtract three of equation one

1344
01:25:59,330 --> 01:26:00,590
from equation two

1345
01:26:00,600 --> 01:26:02,440
that's what i want to do

1346
01:26:02,460 --> 01:26:06,470
so this is going to be a matrix that going to subtract

1347
01:26:09,230 --> 01:26:13,790
time for a couple times wrote one

1348
01:26:19,680 --> 01:26:23,730
and leave the other rows the same just i mean the answer is going to

1349
01:26:23,730 --> 01:26:24,350
be there

1350
01:26:24,530 --> 01:26:28,450
so whatever matrix this is

1351
01:26:28,480 --> 01:26:32,340
and you're going to like tell me what matrix will do it it's the matrix

1352
01:26:33,370 --> 01:26:35,920
leave the first row and change

1353
01:26:35,940 --> 01:26:38,290
the the last row and train

1354
01:26:38,300 --> 01:26:42,920
but takes three of these away from this output zero there two there and minus

1355
01:26:45,310 --> 01:26:47,310
what matrix will do

1356
01:26:48,910 --> 01:26:52,170
it should be a pretty simple matrix

1357
01:26:52,210 --> 01:26:56,190
because we're doing a very simple steps

1358
01:26:56,210 --> 01:27:01,220
we're just doing this that that changes wrote two so actually rule one is not

1359
01:27:01,220 --> 01:27:02,570
changing so

1360
01:27:02,620 --> 01:27:07,110
do tell me how the matrix should begin

1361
01:27:08,980 --> 01:27:11,420
so the first row of the matrix

1362
01:27:11,520 --> 01:27:13,970
will be one

1363
01:27:14,060 --> 01:27:16,960
zero zero

1364
01:27:17,020 --> 01:27:22,070
because that's just the right thing that takes one of that and none of the

1365
01:27:22,070 --> 01:27:26,940
other rows and that's what we want what's the last row of the matrix

1366
01:27:27,030 --> 01:27:29,150
zero zero line

1367
01:27:29,210 --> 01:27:31,320
that takes

1368
01:27:31,350 --> 01:27:36,150
one of the third row and none of the other rows that's great OK

1369
01:27:36,210 --> 01:27:40,380
now suppose i didn't want to do anything at all

1370
01:27:40,430 --> 01:27:44,510
both my role well i guess maybe i had a case here when i already

1371
01:27:44,510 --> 01:27:46,280
had a zero

1372
01:27:46,290 --> 01:27:52,140
and i didn't have to do anything what matrix does nothing

1373
01:27:52,170 --> 01:27:53,670
i guess leaves

1374
01:27:53,690 --> 01:27:56,120
you were you were

1375
01:27:56,170 --> 01:27:58,310
if i put in

1376
01:27:58,320 --> 01:28:02,530
if i put and zero one zero that would be

1377
01:28:02,580 --> 01:28:05,130
that would be

1378
01:28:05,190 --> 01:28:08,220
that's the major what's the name of the matrix

1379
01:28:08,260 --> 01:28:11,030
the identity matrix right

1380
01:28:11,040 --> 01:28:15,040
so it does absolutely nothing it just multiplies everything and leaves and where it is

1381
01:28:15,040 --> 01:28:17,760
is like one like the number one

1382
01:28:17,770 --> 01:28:18,990
for matrices

1383
01:28:19,010 --> 01:28:22,530
but that's not what we want because we want to change this

1384
01:28:22,570 --> 01:28:23,890
rho two

1385
01:28:24,970 --> 01:28:26,840
what's the correct

1386
01:28:26,880 --> 01:28:29,070
what should i put it here now

1387
01:28:29,070 --> 01:28:32,420
to come out to do to do it right

1388
01:28:32,530 --> 01:28:38,400
i want to get what we want what i'm after trying to subtract might want

1389
01:28:38,430 --> 01:28:41,440
three all one to gets subtracted off

1390
01:28:41,450 --> 01:28:48,240
so what that role what's the right matrix the finished matrix for me

1391
01:28:48,400 --> 01:28:52,280
the negative three goes here

1392
01:28:52,300 --> 01:28:54,610
and what goes here that one

1393
01:28:54,620 --> 01:28:57,340
and what goes here the zero

1394
01:28:57,350 --> 01:28:59,120
that's the good night

1395
01:28:59,140 --> 01:29:01,360
that's the matrix that take

1396
01:29:01,420 --> 01:29:05,120
minus three of rho one was the road to

1397
01:29:05,150 --> 01:29:11,220
and gives the new road to should we just like sheikh

1398
01:29:12,440 --> 01:29:14,090
particular entry

1399
01:29:14,120 --> 01:29:17,570
how do i check a particular entry of the matrix

1400
01:29:17,580 --> 01:29:19,460
in matrix multiplication

1401
01:29:19,480 --> 01:29:21,870
like suppose i wanted to check

1402
01:29:21,880 --> 01:29:23,660
the entry here

1403
01:29:23,680 --> 01:29:24,480
that's the and

1404
01:29:25,940 --> 01:29:27,780
column three

1405
01:29:27,790 --> 01:29:32,220
so where does the entry in row two column three come from

1406
01:29:32,280 --> 01:29:35,930
i would look at road to of this guy

1407
01:29:35,940 --> 01:29:38,800
and column

1408
01:29:38,850 --> 01:29:40,920
three of this one

1409
01:29:40,980 --> 01:29:44,770
to get that number number comes from the second row

1410
01:29:44,770 --> 01:29:47,450
can be defined for

1411
01:29:48,070 --> 01:29:49,580
should be mindful

1412
01:29:49,610 --> 01:29:54,550
topological spaces very often represents

1413
01:29:54,560 --> 01:29:57,960
the top space

1414
01:29:57,980 --> 01:30:05,730
so what you see is an abstract this is what what this competition

1415
01:30:07,650 --> 01:30:12,560
one called the discrete representation spaces like this that's

1416
01:30:12,850 --> 01:30:18,790
points which is the primary means by this

1417
01:30:20,180 --> 01:30:23,430
so that's something sensational

1418
01:30:23,490 --> 01:30:28,040
which is a bit of neuron

1419
01:30:28,060 --> 01:30:30,190
the result using your

1420
01:30:30,210 --> 01:30:32,490
is to get better

1421
01:30:32,510 --> 01:30:35,550
the only thing to do

1422
01:30:35,560 --> 01:30:39,450
this disaster one

1423
01:30:40,370 --> 01:30:45,290
here's an example because not

1424
01:30:45,300 --> 01:30:49,340
you try to use

1425
01:30:49,450 --> 01:30:51,270
the example

1426
01:30:55,560 --> 01:30:56,690
so what is

1427
01:30:56,700 --> 01:30:59,140
it is

1428
01:30:59,150 --> 01:31:00,550
it was

1429
01:31:00,560 --> 01:31:01,890
be one

1430
01:31:01,940 --> 01:31:05,770
one is one

1431
01:31:05,790 --> 01:31:10,010
and what you find is seen

1432
01:31:10,030 --> 01:31:13,310
it is

1433
01:31:15,940 --> 01:31:18,440
because the vector space

1434
01:31:18,450 --> 01:31:20,300
so this easier

1435
01:31:20,320 --> 01:31:25,470
is the vector space one generation one b

1436
01:31:25,560 --> 01:31:27,580
but this

1437
01:31:27,590 --> 01:31:30,260
c one

1438
01:31:30,280 --> 01:31:33,910
is the vector space here is one

1439
01:31:34,010 --> 01:31:36,540
these features

1440
01:31:36,550 --> 01:31:43,190
and then use the users just want to

1441
01:31:43,420 --> 01:31:45,230
this is a

1442
01:31:45,240 --> 01:31:54,590
so and so that is this one this is the stationary bike so that in

1443
01:31:54,590 --> 01:31:56,240
this space

1444
01:31:56,270 --> 01:32:00,110
i think of it as just a collection of

1445
01:32:00,580 --> 01:32:01,670
so you

1446
01:32:01,690 --> 01:32:03,600
is that that

1447
01:32:03,620 --> 01:32:04,640
it is

1448
01:32:05,400 --> 01:32:06,770
we want to

1449
01:32:06,780 --> 01:32:10,830
so the first one

1450
01:32:10,890 --> 01:32:13,470
it's hard to do this and

1451
01:32:13,480 --> 01:32:15,460
five one

1452
01:32:15,520 --> 01:32:20,470
that is not going to be read as

1453
01:32:20,510 --> 01:32:22,350
seventy five

1454
01:32:22,560 --> 01:32:24,690
you will find

1455
01:32:27,730 --> 01:32:29,890
this is not the right

1456
01:32:29,940 --> 01:32:32,810
the red

1457
01:32:32,820 --> 01:32:34,060
just like

1458
01:32:34,270 --> 01:32:37,740
two seasons

1459
01:32:37,770 --> 01:32:39,080
his problems

1460
01:32:39,090 --> 01:32:44,040
now this is not just a relation is

1461
01:32:44,090 --> 01:32:47,400
very simple systems

1462
01:32:47,410 --> 01:32:49,900
so not just

1463
01:32:50,840 --> 01:32:52,930
what we are interested

1464
01:32:54,190 --> 01:32:56,620
this is something like this

1465
01:32:56,680 --> 01:32:59,200
this is used

1466
01:32:59,270 --> 01:33:03,210
the truth is that every vertex

1467
01:33:03,360 --> 01:33:08,140
incidence relations the system

1468
01:33:08,150 --> 01:33:09,120
this just too

1469
01:33:09,140 --> 01:33:12,320
is that exists

1470
01:33:14,610 --> 01:33:15,890
is on the verge

1471
01:33:15,900 --> 01:33:18,230
there is no

1472
01:33:18,260 --> 01:33:20,930
that's on who's written

1473
01:33:21,160 --> 01:33:23,540
so that was

1474
01:33:27,010 --> 01:33:29,100
the design

1475
01:33:29,120 --> 01:33:33,770
the difference between these

1476
01:33:33,770 --> 01:33:35,720
CR number two

1477
01:33:35,850 --> 01:33:37,660
because the force

1478
01:33:37,660 --> 01:33:39,420
and the position vector

1479
01:33:39,450 --> 01:33:43,010
make an angle of hundred eighty degrees with each other when the object is here

1480
01:33:43,010 --> 01:33:45,310
or here or here it makes no difference

1481
01:33:45,340 --> 01:33:46,540
and so to talk

1482
01:33:46,550 --> 01:33:48,090
relative to

1483
01:33:48,120 --> 01:33:52,650
is zero so i also know that the angular momentum is not changing a relative

1484
01:33:52,650 --> 01:33:53,850
to point c

1485
01:33:53,900 --> 01:33:58,780
but only relative to point c because any other point that you've chosen here here

1486
01:33:58,780 --> 01:33:59,800
or here

1487
01:33:59,850 --> 01:34:01,830
there would be no pork

1488
01:34:01,870 --> 01:34:07,050
and the annual omentum would be changing so something very special about this point c

1489
01:34:07,150 --> 01:34:10,530
angular momentum is only conserved in this case

1490
01:34:11,430 --> 01:34:16,220
o point c

1491
01:34:16,220 --> 01:34:18,680
now i take another example

1492
01:34:18,700 --> 01:34:21,470
by angular momentum is only conserved

1493
01:34:21,520 --> 01:34:25,170
relative to one point but not to any other point

1494
01:34:25,180 --> 01:34:27,290
i take

1495
01:34:27,340 --> 01:34:30,090
a ruler or rods

1496
01:34:30,140 --> 01:34:32,720
and the role have mass and

1497
01:34:32,830 --> 01:34:35,150
and length l

1498
01:34:35,200 --> 01:34:38,760
and c is the centre of mass of the world

1499
01:34:38,770 --> 01:34:42,460
but i force it to spin about point b

1500
01:34:42,530 --> 01:34:46,370
and this distance is d

1501
01:34:46,390 --> 01:34:48,120
think of this as a horizontal

1502
01:34:50,390 --> 01:34:52,550
and i'm rotating it

1503
01:34:52,560 --> 01:34:54,300
there's an angular velocity

1504
01:34:54,350 --> 01:34:57,650
let's say we rotated in this direction

1505
01:34:57,680 --> 01:35:01,710
four about that point he would have been in their perpendicular to the blackboard and

1506
01:35:01,710 --> 01:35:03,770
i rotated

1507
01:35:03,780 --> 01:35:05,140
i'd like to know

1508
01:35:05,180 --> 01:35:06,260
what the

1509
01:35:06,300 --> 01:35:08,780
magnitude is of the angular momentum

1510
01:35:08,790 --> 01:35:11,070
relative to point b in for that

1511
01:35:11,080 --> 01:35:14,070
i go immediately to equation five

1512
01:35:14,080 --> 01:35:17,160
but it tells me that it is the moment of inertia

1513
01:35:17,180 --> 01:35:19,330
about that axis will point p

1514
01:35:19,410 --> 01:35:21,880
times omega

1515
01:35:21,920 --> 01:35:24,960
i remember the parallel axis theorem

1516
01:35:25,040 --> 01:35:29,290
i know that the moment of inertia for rotation about the centre of mass

1517
01:35:29,300 --> 01:35:32,080
food is axis perpendicular to the blackboard

1518
01:35:32,090 --> 01:35:33,630
i know that one

1519
01:35:33,640 --> 01:35:36,270
he was one twelve

1520
01:35:36,280 --> 01:35:41,340
l square but i just looked it up in the table because i don't remember

1521
01:35:42,200 --> 01:35:45,310
so that would be the moment of inertia about this axis and then the parallel

1522
01:35:45,310 --> 01:35:47,940
axis theorem tells me i have to add

1523
01:35:47,950 --> 01:35:49,800
plus and the square

1524
01:35:49,860 --> 01:35:54,450
times omega

1525
01:35:54,510 --> 01:35:58,980
i'm not interested in the direction of l because it's immediately obvious if it's rotating

1526
01:36:00,290 --> 01:36:04,130
then the direction of the angular momentum will be perpendicular to the blackboard

1527
01:36:04,170 --> 01:36:06,930
and into the backward

1528
01:36:06,980 --> 01:36:07,940
i claim

1529
01:36:07,960 --> 01:36:09,920
but at this point p

1530
01:36:09,980 --> 01:36:13,490
there must be a force acting on this ruler

1531
01:36:13,500 --> 01:36:15,590
and the forces in this direction

1532
01:36:15,660 --> 01:36:18,590
and i can make you see that

1533
01:36:18,610 --> 01:36:19,780
the best way

1534
01:36:19,810 --> 01:36:21,040
my first

1535
01:36:21,090 --> 01:36:22,000
showing you

1536
01:36:22,010 --> 01:36:24,150
the case of a

1537
01:36:24,160 --> 01:36:25,960
mass was wrong

1538
01:36:26,010 --> 01:36:28,800
with two equal masses at both ends

1539
01:36:28,860 --> 01:36:30,900
i rotate about its axis

1540
01:36:30,910 --> 01:36:33,130
perpendicular to the blackboard

1541
01:36:33,160 --> 01:36:37,770
there is going to be a centripetal force and the centripetal force here

1542
01:36:37,810 --> 01:36:41,250
and the two equal they cancel each other out so there will be no force

1543
01:36:41,260 --> 01:36:44,520
on that page the point about which the to rotate

1544
01:36:46,860 --> 01:36:47,940
i had

1545
01:36:47,950 --> 01:36:49,150
the situation

1546
01:36:49,160 --> 01:36:51,570
such that this is my masters rolled

1547
01:36:51,650 --> 01:36:53,550
and you have added two equal masses

1548
01:36:53,560 --> 01:36:56,060
but now i rotate about this point

1549
01:36:56,790 --> 01:36:58,550
this centripetal

1550
01:36:58,560 --> 01:37:00,990
the forces larger than this one

1551
01:37:01,010 --> 01:37:02,890
so now i have a symmetry

1552
01:37:02,900 --> 01:37:04,340
so now there will be

1553
01:37:04,360 --> 01:37:07,400
the force on this been

1554
01:37:07,460 --> 01:37:11,040
the rule will push on the pin and actually my reaction to pin will push

1555
01:37:11,160 --> 01:37:15,240
the ruler and is because of the same asymmetry that you have here that there

1556
01:37:15,240 --> 01:37:18,230
will be a force from the beam on point p

1557
01:37:18,310 --> 01:37:23,460
however i don't care about that force because i'm going to take the talk relative

1558
01:37:23,460 --> 01:37:24,670
to point b

1559
01:37:24,730 --> 01:37:28,750
and when i think it or relative to point b any forceful through point p

1560
01:37:28,830 --> 01:37:32,370
has no effect because the position vector is zero

1561
01:37:32,410 --> 01:37:34,810
but i want you to appreciate that there is a force

1562
01:37:34,820 --> 01:37:36,700
so if i take that to work

1563
01:37:36,730 --> 01:37:38,460
relative to point b

1564
01:37:38,520 --> 01:37:39,240
i do

1565
01:37:39,250 --> 01:37:42,900
not worry about this

1566
01:37:44,070 --> 01:37:46,400
well the talk relative to that point p

1567
01:37:46,410 --> 01:37:48,510
is zero and so it's clear

1568
01:37:48,550 --> 01:37:51,370
that angular momentum relative to point p

1569
01:37:51,530 --> 01:37:53,420
must be conserved

1570
01:37:53,530 --> 01:37:56,860
angular momentum relative to point b is conserved

1571
01:37:56,880 --> 01:37:58,760
take any of the point

1572
01:37:58,800 --> 01:38:02,170
it doesn't matter which one you take this point q

1573
01:38:02,180 --> 01:38:07,030
take this point here take this point here and you momentum is not conserved

1574
01:38:07,060 --> 01:38:10,410
immediately see that if i take this point q here

1575
01:38:10,420 --> 01:38:11,260
that this

1576
01:38:11,270 --> 01:38:12,030
is the

1577
01:38:12,070 --> 01:38:13,440
position vector

1578
01:38:13,500 --> 01:38:18,640
and you see that are cross f is nonzero this talk relative to point q

1579
01:38:18,680 --> 01:38:22,000
you know momentum is not conserved only this point that point

1580
01:38:22,110 --> 01:38:23,030
it's very

1581
01:38:28,260 --> 01:38:30,430
i now take the same ruler

1582
01:38:30,480 --> 01:38:31,730
but i'm going to

1583
01:38:31,920 --> 01:38:37,270
make it rotate about the centre of mass

1584
01:38:38,340 --> 01:38:40,790
here is now the same

1585
01:38:40,840 --> 01:38:46,160
now i'm going to rotate

1586
01:38:46,160 --> 01:38:49,000
about the centre of mass

1587
01:38:50,080 --> 01:38:52,000
same direction

1588
01:38:52,040 --> 01:38:57,400
the stationary axes twenty six one hundred and is rotating about their

1589
01:38:57,410 --> 01:39:00,250
centre of mass is my centre of mass

1590
01:39:00,290 --> 01:39:02,620
now there is no force

1591
01:39:02,690 --> 01:39:06,800
on this page because of the symmetry which i just explained sort of pain is

1592
01:39:06,800 --> 01:39:08,260
not pushing on the

1593
01:39:08,270 --> 01:39:09,340
rather either

1594
01:39:09,370 --> 01:39:11,440
so there no force at all

1595
01:39:11,500 --> 01:39:12,930
if this is a frictionless

1596
01:39:14,130 --> 01:39:15,910
if there is no force at all

1597
01:39:15,910 --> 01:39:17,280
then the talk

1598
01:39:17,320 --> 01:39:22,430
relative to any point must be zero not only relative to this point but also

1599
01:39:22,430 --> 01:39:26,210
relative to this point and relative to this point because if the force is zero

1600
01:39:26,530 --> 01:39:29,710
then any cross product of rnf is zero

1601
01:39:29,730 --> 01:39:32,610
so now you see the special case that i alluded to

1602
01:39:32,620 --> 01:39:34,420
in equation number six

1603
01:39:34,480 --> 01:39:35,990
now you have the case

1604
01:39:36,010 --> 01:39:38,960
that the angular momentum

1605
01:39:38,980 --> 01:39:41,630
of this rotating object is the same

1606
01:39:41,650 --> 01:39:42,810
no matter which

1607
01:39:42,820 --> 01:39:45,540
o point you choose recall that the spin

1608
01:39:45,590 --> 01:39:48,670
angular momentum it is an intrinsic property

1609
01:39:48,680 --> 01:39:51,170
of a spinning object

1610
01:39:51,180 --> 01:39:54,510
and it is the same relative to any point that you choose

1611
01:39:54,540 --> 01:39:55,750
and if you want to know

1612
01:39:55,760 --> 01:39:56,930
larger this

1613
01:39:56,930 --> 01:40:01,300
be able to tell you about this is the simplest case and perhaps the most

1614
01:40:01,300 --> 01:40:04,240
fundamental case

1615
01:40:04,250 --> 01:40:10,100
and so most method estimate actually real from a real valued function are around two

1616
01:40:10,100 --> 01:40:12,250
and threshold

1617
01:40:12,270 --> 01:40:15,740
and and that's what produces the classification

1618
01:40:15,750 --> 01:40:21,630
so you really do classification to it so i will actually cool concentrate on getting

1619
01:40:21,630 --> 01:40:23,990
this real valued functions and the

1620
01:40:24,470 --> 01:40:30,290
in classification so he here some pictures

1621
01:40:30,340 --> 01:40:33,080
what you want to do is something like this

1622
01:40:33,120 --> 01:40:37,590
so let me show you this

1623
01:40:37,640 --> 01:40:41,000
OK so this is your data

1624
01:40:41,750 --> 01:40:44,610
so this x y use

1625
01:40:44,620 --> 01:40:49,010
and this so why one right so data point is an x y pair this

1626
01:40:49,010 --> 01:40:51,090
is x this is why

1627
01:40:51,140 --> 01:40:55,370
and given so what your goal given a new data point you might want to

1628
01:40:55,370 --> 01:40:56,780
predict y one

1629
01:40:56,800 --> 01:41:01,820
well as you can see the data is a little noisy it's kind of a

1630
01:41:01,820 --> 01:41:05,090
little all over the place but there is some pattern the pattern is something like

1631
01:41:06,360 --> 01:41:12,970
so noise is sort of a very persistent feature of the data i think it's

1632
01:41:12,970 --> 01:41:17,340
important to understand the noise is everywhere in the one thing you can say well

1633
01:41:17,340 --> 01:41:20,890
i can always tell an image of seven from an image of not first is

1634
01:41:20,890 --> 01:41:23,330
not eventually you can

1635
01:41:23,340 --> 01:41:27,150
there are some examples they especially like well some of them either to the another

1636
01:41:27,160 --> 01:41:31,370
but for nine can be extremely similar for example and sometimes you just don't know

1637
01:41:32,320 --> 01:41:35,590
they were trying to write than suppose how do you actually know what the labour

1638
01:41:35,630 --> 01:41:40,020
i made some guy inherited down and tries to label other things but this guy

1639
01:41:40,020 --> 01:41:43,930
will just make will make a mistake once in a while no matter what

1640
01:41:43,940 --> 01:41:49,260
and so no matter what you have here date is always nice almost

1641
01:41:49,270 --> 01:41:52,800
so you'll have to deal with the issue of notes and in some sense it's

1642
01:41:52,800 --> 01:41:54,650
a fundamental issue

1643
01:41:54,670 --> 01:41:57,980
so what do what you want to have

1644
01:42:00,250 --> 01:42:01,650
something like this

1645
01:42:01,660 --> 01:42:06,460
so this in some sense is the a function which fits this data very nice

1646
01:42:06,480 --> 01:42:11,180
and so given the new point eight just read the value of the function and

1647
01:42:11,180 --> 01:42:12,800
that's my project

1648
01:42:16,690 --> 01:42:18,890
in fact i can tell you

1649
01:42:18,910 --> 01:42:22,930
the secret but that's actually data was generated from this distribution

1650
01:42:22,940 --> 01:42:24,250
it's not

1651
01:42:24,930 --> 01:42:28,760
so this is in some sense the best to come

1652
01:42:28,810 --> 01:42:32,110
OK so

1653
01:42:32,120 --> 01:42:35,570
what about this

1654
01:42:35,580 --> 01:42:37,750
so this is a very nice

1655
01:42:37,800 --> 01:42:41,330
well behaved function but it doesn't seem to fit the data very well

1656
01:42:41,340 --> 01:42:44,310
this actually fitting something

1657
01:42:44,320 --> 01:42:46,880
well for this

1658
01:42:46,920 --> 01:42:51,380
it is something which underfits you're not fitting well enough it's some nice

1659
01:42:51,390 --> 01:42:56,630
pleasant function to delist it's almost like a straight line but unfortunately it doesn't work

1660
01:42:56,630 --> 01:42:58,050
very well

1661
01:42:58,060 --> 01:43:02,160
and now this

1662
01:43:02,170 --> 01:43:07,320
is also not nice function perhaps it fits the data perfectly however as you can

1663
01:43:07,320 --> 01:43:10,910
notice this is some polynomial of high degree which if it exactly to the data

1664
01:43:11,160 --> 01:43:13,850
so it fits the data perfectly however

1665
01:43:14,820 --> 01:43:17,460
if i have a data points you do i really think it's going to be

1666
01:43:17,460 --> 01:43:18,500
out there

1667
01:43:18,510 --> 01:43:24,310
well you may be not so this is in a an example of overfitting your

1668
01:43:24,310 --> 01:43:28,160
feet the data that you have perfectly but on the new points

1669
01:43:28,170 --> 01:43:31,370
you probably do very bad

1670
01:43:33,710 --> 01:43:34,440
you will

1671
01:43:34,790 --> 01:43:37,800
here you build the

1672
01:43:37,810 --> 01:43:41,680
basically as badly on the new point as you do on points here so it's

1673
01:43:41,800 --> 01:43:43,100
pretty badly here

1674
01:43:43,110 --> 01:43:46,570
but on the new point it will probably not do much more

1675
01:43:46,580 --> 01:43:48,830
so this is an underfit it

1676
01:43:48,880 --> 01:43:51,880
it works consistently but badly

1677
01:43:51,890 --> 01:43:58,940
this works very well on the data but we work about learning

1678
01:44:00,270 --> 01:44:03,810
this is perfect so i don't know what what what is perfect it's hard to

1679
01:44:03,810 --> 01:44:04,610
tell you why

1680
01:44:05,070 --> 01:44:08,490
i mean in this case this is actually the fourth

1681
01:44:09,030 --> 01:44:14,210
you would know that this is exactly the true

1682
01:44:14,260 --> 01:44:16,190
OK so

1683
01:44:16,260 --> 01:44:18,690
i hope this is so

1684
01:44:18,800 --> 01:44:22,210
one point to be made from all pictures is you never should try to fit

1685
01:44:22,210 --> 01:44:26,140
the data exact if it exactly fit all the noise which is in the day

1686
01:44:26,300 --> 01:44:27,940
that you will always have

1687
01:44:27,960 --> 01:44:34,240
and in some sense that you have to be careful as part of the thing

1688
01:44:34,250 --> 01:44:37,340
you have to be careful with

1689
01:44:37,340 --> 01:44:40,910
about other methods for blind source separation

1690
01:44:40,930 --> 01:44:45,300
so we began with the problem of blind source separation and then we'll talk i

1691
01:44:45,300 --> 01:44:49,640
see as the kind of the the method for

1692
01:44:50,060 --> 01:44:53,660
for solving the rights separation problem

1693
01:44:53,680 --> 01:44:55,050
and it is true that

1694
01:44:55,070 --> 01:44:58,410
most work on blind source separation well

1695
01:44:58,460 --> 01:45:05,030
the the the large majority of the work online separation is using ICA to do

1696
01:45:05,030 --> 01:45:09,050
that but there are also the source of the class of other kinds of methods

1697
01:45:09,050 --> 01:45:16,500
for blind source separation that are completely different completely but rather different from ICA

1698
01:45:18,390 --> 01:45:21,050
well so the basic point is that we have this

1699
01:45:21,070 --> 01:45:24,450
the same kind of of basic of linear mixture models

1700
01:45:24,470 --> 01:45:29,890
it's just that now we write the time index t here for all the option

1701
01:45:29,980 --> 01:45:32,940
by optical signals and the sourcing

1702
01:45:33,120 --> 01:45:37,050
because the point is that these signals in real time signals they are not we

1703
01:45:37,050 --> 01:45:41,710
don't just have a sample of a random vector but we really have time sequence

1704
01:45:41,710 --> 01:45:46,230
and timing that me

1705
01:45:46,280 --> 01:45:51,810
so this as we saw before this that we can estimate this kind of model

1706
01:45:51,810 --> 01:45:58,520
in general we can not estimate the the sourcing in general that basically if we

1707
01:45:58,520 --> 01:46:02,040
take a if we assume that the is i

1708
01:46:02,120 --> 01:46:06,630
gaussian random variables so when i say random variables i mean that they have no

1709
01:46:06,630 --> 01:46:08,470
time structure

1710
01:46:08,650 --> 01:46:13,540
so different time points they are just independent i mean a single

1711
01:46:13,550 --> 01:46:18,650
the signal will be such that the values in two different time points to subsequent

1712
01:46:18,650 --> 01:46:21,910
time points are independent from each other then

1713
01:46:21,930 --> 01:46:25,000
then we can there's nothing we can do

1714
01:46:25,020 --> 01:46:25,970
so what

1715
01:46:25,980 --> 01:46:30,070
there are two ways actually to get to get to be able to do something

1716
01:46:30,070 --> 01:46:31,180
that first

1717
01:46:31,190 --> 01:46:33,300
first is the method of ICA

1718
01:46:33,320 --> 01:46:38,100
which is why we assume that these into these components the the social signals on

1719
01:46:38,100 --> 01:46:43,350
nongaussian and then we can use these ideas of higher order statistics that is in

1720
01:46:43,480 --> 01:46:49,830
to basically not different measures of nongaussianity to give the information that we the extreme

1721
01:46:49,830 --> 01:46:51,180
information that we need

1722
01:46:51,200 --> 01:46:52,940
but the other way

1723
01:46:52,960 --> 01:46:56,840
is to assume that these is i are time dependent signals

1724
01:46:56,850 --> 01:47:02,240
that is they have some kind of meaningful bond structures like you know maybe something

1725
01:47:02,240 --> 01:47:06,300
like this kind of sinusoidal functions for example

1726
01:47:06,510 --> 01:47:09,960
and then we can use these correlations over time

1727
01:47:09,980 --> 01:47:11,940
to get more information

1728
01:47:11,960 --> 01:47:17,790
so something more and more information than is contained in the covariance matrix

1729
01:47:17,800 --> 01:47:19,720
well the simplest thing

1730
01:47:19,740 --> 01:47:23,780
two rule probabilities that well what could look at this is this kind of the

1731
01:47:23,780 --> 01:47:27,990
lagged covariance matrix so power here

1732
01:47:28,090 --> 01:47:33,030
is a small time lag maybe that could be equal to one

1733
01:47:33,050 --> 01:47:38,460
which means that we are here computing the covariances

1734
01:47:38,470 --> 01:47:41,150
we have computing covariances of

1735
01:47:41,160 --> 01:47:45,010
x y

1736
01:47:45,020 --> 01:47:46,640
x y

1737
01:47:46,650 --> 01:47:48,190
at timepoint t

1738
01:47:48,210 --> 01:47:51,090
and then of another signal x j

1739
01:47:51,100 --> 01:47:53,720
at timepoint t minus

1740
01:47:55,100 --> 01:47:59,280
one of the simplest case

1741
01:47:59,300 --> 01:48:04,480
so we get some more statistics and some more information and perhaps we can then

1742
01:48:04,660 --> 01:48:06,500
use that to estimate

1743
01:48:06,510 --> 01:48:08,580
estimate the

1744
01:48:08,630 --> 01:48:09,970
the model

1745
01:48:09,990 --> 01:48:13,960
and it turns out that this is really this is exactly what you can do

1746
01:48:13,970 --> 01:48:17,640
in the early nineties at the same time as people were working in this in

1747
01:48:17,640 --> 01:48:22,200
this area on the theory of ICA this proposed that we could do that if

1748
01:48:22,200 --> 01:48:27,600
we could use this i this method to separate sources

1749
01:48:27,620 --> 01:48:31,650
to the way of looking at this principle is that we could say that we

1750
01:48:31,650 --> 01:48:34,830
find that the correlating matrix w

1751
01:48:35,750 --> 01:48:38,180
that not only the whites are

1752
01:48:38,200 --> 01:48:40,630
are uncorrelated with the with

1753
01:48:40,670 --> 01:48:42,250
each other

1754
01:48:42,260 --> 01:48:44,440
in the ordinary sense

1755
01:48:44,450 --> 01:48:50,090
but also they are uncorrelated with black divisions so we have the covariances

1756
01:48:50,250 --> 01:48:53,420
why i t

1757
01:48:53,510 --> 01:48:57,670
and why i t minus one is zero

1758
01:48:57,680 --> 01:48:58,970
but then also

1759
01:48:59,000 --> 01:49:03,650
the same thing will be true if we take

1760
01:49:03,720 --> 01:49:05,800
lag series services j

1761
01:49:05,850 --> 01:49:14,350
j known as the image so not only these components these components are

1762
01:49:14,360 --> 01:49:19,430
uncorrelated when you look at them look at the same time point but also they

1763
01:49:19,430 --> 01:49:21,070
will be uncorrelated

1764
01:49:21,090 --> 01:49:22,340
when you

1765
01:49:22,360 --> 01:49:27,270
look at that and get them at slightly different time points

1766
01:49:27,280 --> 01:49:31,370
for example and with the lack of one

1767
01:49:31,420 --> 01:49:36,030
and so this will actually this will under certain assumptions solve this problem that we

1768
01:49:36,030 --> 01:49:37,040
don't have

1769
01:49:37,310 --> 01:49:40,920
enough information in the covariance matrix

1770
01:49:40,930 --> 01:49:45,330
OK well i had actually it here

1771
01:49:45,350 --> 01:49:50,320
so all of these pieces practices something actually extremely simple

1772
01:49:50,330 --> 01:49:54,580
so first we whiten the data we use any whitening matrix

1773
01:49:54,620 --> 01:49:57,740
z just like in in ICA the two of us

1774
01:49:57,750 --> 01:49:58,620
and now

1775
01:49:58,660 --> 01:50:04,550
well we find orthogonal transformation since we know that all widening transformations can be represented

1776
01:50:04,550 --> 01:50:07,490
by an orthogonal transformation of industrial

1777
01:50:07,500 --> 01:50:09,770
whitening transformation

1778
01:50:09,860 --> 01:50:15,980
and we find this orthogonal transformation not not not to maximize nongaussianity just ICA

1779
01:50:16,000 --> 01:50:17,220
but so

1780
01:50:17,230 --> 01:50:19,870
that's the lagged covariance

1781
01:50:19,890 --> 01:50:24,030
matrix of this thing equals idea

1782
01:50:24,040 --> 01:50:28,620
now it happens that this is actually computationally very easy thing to do

1783
01:50:28,820 --> 01:50:32,210
because if you look at this

1784
01:50:32,220 --> 01:50:36,610
if you look at the core of these lagged covariance matrix

1785
01:50:36,620 --> 01:50:41,880
then by definition where of when x equals a times is

1786
01:50:41,880 --> 01:50:49,120
choice he makes x is going to take a maximum 2 2

1787
01:50:49,140 --> 01:50:50,190
lawyers in the

1788
01:50:51,080 --> 01:50:58,000
calculations this is the calculation that are has to make this is the calculation of

1789
01:50:58,010 --> 01:51:01,300
the estimate so let's do it

1790
01:51:01,360 --> 01:51:05,860
dual so we could just think about ah so ah as think OK I'm going

1791
01:51:05,870 --> 01:51:08,140
to take the best text

1792
01:51:09,060 --> 01:51:13,680
but it has to be best against the worst

1793
01:51:17,200 --> 01:51:18,480
this is the

1794
01:51:18,660 --> 01:51:23,780
today the words from this point of view that's right the worst from his ways

1795
01:51:23,900 --> 01:51:31,880
OK now if I was strong enough we can work this out

1796
01:51:31,920 --> 01:51:34,620
we don't know what the

1797
01:51:34,680 --> 01:51:39,570
so that you can we can we try to see if we can do it

1798
01:51:39,700 --> 01:51:43,400
this is this is the payoff written out in full

1799
01:51:45,000 --> 01:51:50,900
so what basically what is x have to do it he has to presented y

1800
01:51:50,900 --> 01:51:56,620
with the with the what's the presented wi with with with 2 columns where

1801
01:51:57,260 --> 01:52:02,660
white otherwise no reason to go 1 way or the other

1802
01:52:02,660 --> 01:52:05,200
I think in this case

1803
01:52:08,210 --> 01:52:13,070
so what will why usually get when it went when why think about this way

1804
01:52:13,450 --> 01:52:16,920
suppose chooses column 1

1805
01:52:16,920 --> 01:52:18,940
what can we expect payoff to the

1806
01:52:19,460 --> 01:52:22,040
on on the average after zillions of play

1807
01:52:23,860 --> 01:52:27,160
for x 1 + 1 x 2 and

1808
01:52:28,180 --> 01:52:29,100
is that right

1809
01:52:29,530 --> 01:52:31,210
wise positions

1810
01:52:31,230 --> 01:52:39,730
we we've why the payoff y in choosing from 1 would be for 1 +

1811
01:52:39,730 --> 01:52:40,600
1 x 2

1812
01:52:41,840 --> 01:52:47,060
that's the payoff from column 1

1813
01:52:48,600 --> 01:52:51,180
the payoff from column until

1814
01:52:52,290 --> 01:52:54,060
2 X 1 and 7

1815
01:52:55,440 --> 01:53:04,820
and I think X wants to adjust those those of the same I think

1816
01:53:09,290 --> 01:53:10,560
that seems right to me

1817
01:53:13,750 --> 01:53:15,880
is provided this gives

1818
01:53:16,380 --> 01:53:21,660
non-native non negative axis so what does that tell us that tells us that 2

1819
01:53:21,660 --> 01:53:22,530
x 1

1820
01:53:25,010 --> 01:53:26,600
it's 6 x 2

1821
01:53:27,380 --> 01:53:30,940
is that what we get out of this this leads to

1822
01:53:31,080 --> 01:53:35,940
subtracting the 2 X 1 that gives us 2 X 1 in 6 excuse

1823
01:53:36,120 --> 01:53:38,770
and wants to me like this sort of B

1824
01:53:39,860 --> 01:53:44,920
some of the bigger ones 3 quarters and this should only be 1 quarter

1825
01:53:45,520 --> 01:53:47,800
I think that's the conclusion

1826
01:53:48,100 --> 01:53:56,720
do you like know other there's no reason for why the change because if

1827
01:53:56,730 --> 01:54:01,270
if we then do it that way why Welch

1828
01:54:02,070 --> 01:54:07,600
then the average payoff when X 1 is a physical is 3 quarters

1829
01:54:07,680 --> 01:54:12,400
and X 2 is 1 quarter is three-quarters 1 I get them for the for

1830
01:54:12,400 --> 01:54:14,290
those Member of just

1831
01:54:15,800 --> 01:54:18,780
1 quarter and that's makes ones

1832
01:54:19,220 --> 01:54:20,540
note 3

1833
01:54:20,550 --> 01:54:26,900
three-quarters terms there's really I think we get 3 in the quarter and I believe

1834
01:54:26,900 --> 01:54:28,270
that's the value of the game

1835
01:54:30,600 --> 01:54:34,660
you can say wait a minute I haven't figured out

1836
01:54:34,930 --> 01:54:37,790
strategy and and that's true

1837
01:54:38,560 --> 01:54:42,520
policy so let's figure out why strategy in the same reasoning

1838
01:54:43,760 --> 01:54:49,720
OK so why strategy will be

1839
01:54:51,460 --> 01:54:57,440
if you are an effective row 1 is chosen as the average payoff is more

1840
01:54:57,500 --> 01:54:58,970
y 1 plus 2

1841
01:55:00,520 --> 01:55:05,560
whereas in the 2nd row is chosen the average payoff will be wide 1 .

1842
01:55:05,560 --> 01:55:06,660
7 . 2

1843
01:55:07,220 --> 01:55:08,980
and if he makes those equal

1844
01:55:12,970 --> 01:55:17,160
there are will have no reason to choose 1 row or another so what would

1845
01:55:17,160 --> 01:55:21,380
that give us that'll was really that leads to

1846
01:55:21,480 --> 01:55:28,030
3 Y 1 is 5 white so there in the ratio of 5 to 3

1847
01:55:28,040 --> 01:55:28,710
so maybe

1848
01:55:29,420 --> 01:55:36,440
3 8 sense of 5 and 3 8 5 8 1 3 8

1849
01:55:37,580 --> 01:55:41,540
because then 3 times 5 does give 5 times 3

1850
01:55:41,790 --> 01:55:43,940
right now I think we've got

1851
01:55:47,460 --> 01:55:51,980
so there is a particular game that's solved

1852
01:55:52,200 --> 01:56:01,070
a particularly game itself so that we have and the so that the 1st and

1853
01:56:01,070 --> 01:56:05,660
most important point is this is the point we saw earlier that in in this

1854
01:56:05,660 --> 01:56:11,920
game and make strategies that that's a randomized make strategy if there is any patterns

1855
01:56:12,070 --> 01:56:14,360
the opponent will take advantage

1856
01:56:14,460 --> 01:56:20,530
here there's no patterns except the only pattern is this is for the time and

1857
01:56:20,530 --> 01:56:26,100
this is one-fourth of the time and then of et and as you plug those

1858
01:56:26,100 --> 01:56:30,420
numbers into the payoff you would get

1859
01:56:30,440 --> 01:56:32,900
3 quarter sure

1860
01:56:34,280 --> 01:56:37,040
we could agree yes

1861
01:56:37,640 --> 01:56:44,980
this is the best point with widest 1 chain yes

1862
01:56:45,400 --> 01:56:55,500
you I guess there is somehow yeah this is that's probably an and so this

1863
01:56:55,500 --> 01:56:59,840
is a remark it what the end result is

1864
01:56:59,880 --> 01:57:02,270
is the fact that

1865
01:57:02,290 --> 01:57:03,400
the best

1866
01:57:03,500 --> 01:57:06,230
X the best X X can be

1867
01:57:08,580 --> 01:57:12,220
is to guarantee himself this amount

1868
01:57:12,230 --> 01:57:15,790
and the best way I can do is to guarantee not pay more than that

1869
01:57:18,160 --> 01:57:21,810
is making a small they can against anything

1870
01:57:22,940 --> 01:57:26,520
and the beauty is this minimax theorem

1871
01:57:26,540 --> 01:57:33,640
that this minimax equals the maximum that that's that's is duality of course of the

1872
01:57:33,640 --> 01:57:37,490
2 players are somehow it locked in this

1873
01:57:38,130 --> 01:57:42,060
dual picture and

1874
01:57:42,060 --> 01:57:43,400
which what wanted

1875
01:57:43,720 --> 01:57:47,350
i just think about what you do if you're doing likelihood based inference here you

1876
01:57:47,500 --> 01:57:51,030
go away and calculate this distribution

1877
01:57:51,140 --> 01:57:53,350
so the data

1878
01:57:53,350 --> 01:57:58,270
and the stuff about the point history of very highly cover correlated in this calculation

1879
01:57:58,290 --> 01:57:59,510
be non-trivial

1880
01:57:59,520 --> 01:58:04,990
to be a certain amount of work presumably to calculate nothing if you could

1881
01:58:05,040 --> 01:58:08,350
so with the ABC approach you just change the metric

1882
01:58:08,410 --> 01:58:10,610
and you get different

1883
01:58:11,300 --> 01:58:20,610
and i said what's wrong with it could going to

1884
01:58:22,630 --> 01:58:24,510
thinking about it

1885
01:58:24,520 --> 01:58:32,000
OK so just to give you the punchline from the science story

1886
01:58:32,660 --> 01:58:40,820
the reason these problems interesting is big controversy surrounding this a paleontologist all certain that

1887
01:58:41,110 --> 01:58:46,510
primates diverged after the demise of the dinosaurs sixty five million years ago gave us

1888
01:58:46,670 --> 01:58:53,430
a certain that a large proportion of the system and what the geneticists using DNA

1889
01:58:53,430 --> 01:58:57,930
from other primates a fairly sure that the divergence times back here somewhere

1890
01:58:57,950 --> 01:59:03,510
so what our work is done as i looked at a reasonable model of evolution

1891
01:59:03,510 --> 01:59:05,240
from the paleontology literature

1892
01:59:05,290 --> 01:59:06,140
and actually

1893
01:59:06,200 --> 01:59:10,220
the inference of what we expect the average time to be given the data we

1894
01:59:10,220 --> 01:59:15,850
have available can although we can't say for sure is in the cretaceous

1895
01:59:15,910 --> 01:59:18,130
the primary dinosaurs alongside

1896
01:59:18,150 --> 01:59:23,420
it seems we call without even reason uncertainties by about here

1897
01:59:23,430 --> 01:59:26,590
so we put most on that over here

1898
01:59:26,590 --> 01:59:30,800
the prior distribution but it's actually fairly robust this prior

1899
01:59:32,420 --> 01:59:35,750
so using the fossil evidence alone you can't constrain

1900
01:59:35,760 --> 01:59:39,670
the primary difference time to the cretaceous

1901
01:59:40,610 --> 01:59:46,190
the back to the monte carlo the ABC there's a couple of extensions that may

1902
01:59:46,190 --> 01:59:48,360
or may not be possible

1903
01:59:48,380 --> 01:59:53,670
the first one has been suggested is that we can use the albums to do

1904
01:59:53,670 --> 01:59:55,360
model selection

1905
01:59:55,420 --> 02:00:01,460
so in theory the acceptance rate from these algorithms

1906
02:00:01,470 --> 02:00:03,670
approximates the

1907
02:00:03,680 --> 02:00:06,270
the normalizing constant

1908
02:00:06,270 --> 02:00:07,310
from you all

1909
02:00:08,530 --> 02:00:12,670
so no matter constant partition function evidence whatever you call it can

1910
02:00:12,700 --> 02:00:15,350
so this is the probability of the data given the model

1911
02:00:15,360 --> 02:00:20,200
so we can approximate that with acceptance rate from ABC

1912
02:00:22,670 --> 02:00:24,820
in practice i think we shown

1913
02:00:24,830 --> 02:00:26,610
it's fairly hopeless

1914
02:00:27,650 --> 02:00:32,570
so more both the choice of exile rho and so on

1915
02:00:32,580 --> 02:00:34,310
there's a few other methods something

1916
02:00:34,330 --> 02:00:37,920
this is fairly up to date but i know this is difficult to calculate because

1917
02:00:37,930 --> 02:00:39,770
i think it's also

1918
02:00:41,390 --> 02:00:47,110
course of these ABC albums only and any good if you can your simulators cheap

1919
02:00:47,110 --> 02:00:51,610
if it take you ten seconds to simulate a sample output from your model probably

1920
02:00:51,610 --> 02:00:57,450
no good never mind if you have to take two weeks like people can so

1921
02:00:57,510 --> 02:01:02,660
one option might be to emulate the stochastic models so we know something about emulating

1922
02:01:02,660 --> 02:01:04,300
deterministic models

1923
02:01:04,370 --> 02:01:09,580
and believe down the couple of other people the stuff on emulating stochastic models but

1924
02:01:10,350 --> 02:01:12,570
still work to be done there is

1925
02:01:12,610 --> 02:01:16,740
a paper by richard boys and darren wilkinson submission where they

1926
02:01:16,750 --> 02:01:23,830
approximated the output by some parametric family and later date parameter values guassian process to

1927
02:01:23,830 --> 02:01:30,520
the emulated math model for the stochastic simulator

1928
02:01:31,390 --> 02:01:33,450
it just to summarise again

1929
02:01:33,460 --> 02:01:39,420
no longer bound to do this they allowed to do inference in models for which

1930
02:01:39,430 --> 02:01:42,060
we would not otherwise be able to can we can

1931
02:01:42,070 --> 02:01:45,850
we can let the centre given whatever money they want and long as we can

1932
02:01:45,850 --> 02:01:50,750
see observations from a reasonably cheaply we can do some sort of inference for them

1933
02:01:50,760 --> 02:01:54,810
very easy to code relating to give it to take into account any problem can

1934
02:01:55,040 --> 02:01:59,370
i failure to adapt if you change your model anyway if you change your priors

1935
02:01:59,370 --> 02:02:02,760
if you want to add more data

1936
02:02:02,800 --> 02:02:05,050
the inference which is the same

1937
02:02:05,060 --> 02:02:07,810
with the MCMC if you change your model you often find you need to go

1938
02:02:07,810 --> 02:02:12,610
through the whole process of the tuning everything finding new proposal distributions setting mixing convergence

1939
02:02:12,610 --> 02:02:16,350
and so on the face simple as that


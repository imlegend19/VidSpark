1
00:00:00,000 --> 00:00:00,800
the second example

2
00:00:01,520 --> 00:00:02,090
will discuss

3
00:00:03,010 --> 00:00:04,600
is gonna be these unknown

4
00:00:09,380 --> 00:00:11,780
so i could tell you look i've got bent coin in my pocket

5
00:00:12,940 --> 00:00:16,120
it has been used to generate a great big file always and bees

6
00:00:16,860 --> 00:00:20,410
and that's all i'm telling you don't know what the bias is but you do

7
00:00:20,440 --> 00:00:21,900
know that it's a biased coin

8
00:00:22,390 --> 00:00:23,170
you just don't know

9
00:00:25,160 --> 00:00:25,870
he eh

10
00:00:26,430 --> 00:00:26,950
and people be

11
00:00:27,780 --> 00:00:28,470
are yet

12
00:00:29,550 --> 00:00:34,970
nevertheless on-the-fly i want you just start predicting just like the headline you didn't know what language are in

13
00:00:36,590 --> 00:00:39,740
you know what it is about and has we went along on the fly you

14
00:00:39,740 --> 00:00:42,040
started to figure out what sort of topic it was

15
00:00:43,880 --> 00:00:45,110
so an unknown then car

16
00:00:45,530 --> 00:00:49,880
and so are typical outcome might be a lot surveys in just a few days

17
00:00:49,880 --> 00:00:52,240
or it might be lots of these in just a few days and you don't

18
00:00:52,240 --> 00:00:53,410
know in advance which

19
00:00:53,880 --> 00:00:54,870
poses can be the case

20
00:00:56,860 --> 00:00:59,620
and the third task will discuss is the general

21
00:01:01,200 --> 00:01:03,850
situation where an article is available

22
00:01:05,610 --> 00:01:07,010
the oracles job is

23
00:01:07,490 --> 00:01:10,480
given any context x one x two

24
00:01:11,140 --> 00:01:13,980
x three text e minus one

25
00:01:15,100 --> 00:01:20,040
the article will supply you with the probability of the next character which you should

26
00:01:20,120 --> 00:01:23,980
assume is be correct distribution for the for the next character

27
00:01:24,550 --> 00:01:28,500
andy there will be an identical twin oracle at the other end who will produce

28
00:01:28,500 --> 00:01:30,940
exactly the same distribution in response to

29
00:01:32,510 --> 00:01:33,920
that's same context

30
00:01:34,670 --> 00:01:35,800
so this is any context

31
00:01:38,750 --> 00:01:42,280
and then the question is how should you compress when you've got the article

32
00:01:43,680 --> 00:01:45,290
the article is actually a complete

33
00:01:45,770 --> 00:01:49,150
completely general statement of the compression problem because the bent coin

34
00:01:49,710 --> 00:01:50,120
could be

35
00:01:51,760 --> 00:01:55,470
produced by the oracle he just ignore the context he said he has probability ninety

36
00:01:55,470 --> 00:01:57,850
nine percent and be has a probability one percent

37
00:01:58,780 --> 00:02:01,770
the this article has the trivial cases in it as well

38
00:02:02,510 --> 00:02:05,330
the way the article would do the bent coin thing is

39
00:02:05,770 --> 00:02:09,260
given the context he would look at how many a's and b's who have happened

40
00:02:09,400 --> 00:02:12,980
he would make an inference from what i think he and he might be

41
00:02:13,430 --> 00:02:16,040
and take into account uncertainty about pia pib

42
00:02:16,520 --> 00:02:18,640
in making his next prediction of weather

43
00:02:19,140 --> 00:02:22,180
i think that's one is and they are being so his first guess with no

44
00:02:22,180 --> 00:02:24,580
context at all would be well fifty fifty i don't know

45
00:02:24,980 --> 00:02:28,910
it could be biased his albeit at so fifty fifty then when he sees a day

46
00:02:29,430 --> 00:02:34,020
right now let's weak evidence for being biased towards aims and he'd give a slightly

47
00:02:34,020 --> 00:02:38,250
bigger probability to eight and his identical twin would behave in exactly the same way

48
00:02:40,830 --> 00:02:43,910
so that's the three tasks that we want to solve

49
00:02:46,430 --> 00:02:47,660
we are going to

50
00:02:48,350 --> 00:02:50,180
defined at

51
00:02:50,230 --> 00:02:50,770
but coding

52
00:02:56,480 --> 00:03:00,460
i should mention in passing the arithmetic coding is not the only other way of

53
00:03:00,460 --> 00:03:02,750
doing data compression apart from simple codes

54
00:03:03,210 --> 00:03:07,060
but in my view is the only other one that is really worth devoting lecture

55
00:03:07,060 --> 00:03:10,620
to there are many other algorithms some of which are quite elegant but for me

56
00:03:10,620 --> 00:03:12,680
after coding is is speaking

57
00:03:13,180 --> 00:03:14,270
of compression

58
00:03:15,370 --> 00:03:19,830
so do feel free to leave repeat the textbook knowledge you can learn about other

59
00:03:20,270 --> 00:03:21,000
compression methods

60
00:03:21,540 --> 00:03:23,250
so here's how arithmetic coding works

61
00:03:24,750 --> 00:03:26,910
many coding is based on this idea

62
00:03:28,770 --> 00:03:30,390
you can view any transmission

63
00:03:34,680 --> 00:03:35,620
in a binary

64
00:03:39,160 --> 00:03:41,270
as defining an interval on the real line

65
00:03:55,930 --> 00:03:57,540
zero one for example

66
00:03:58,500 --> 00:03:58,890
is a little

67
00:03:59,330 --> 00:04:00,460
as a binary string

68
00:04:01,350 --> 00:04:05,330
hand you can view them as corresponding to the interval from o point two five

69
00:04:05,890 --> 00:04:07,410
no point five in decimal

70
00:04:08,390 --> 00:04:09,580
one zero zero

71
00:04:10,480 --> 00:04:11,750
we can associate with

72
00:04:12,600 --> 00:04:14,080
involving no point five

73
00:04:14,730 --> 00:04:15,980
not by sixty five

74
00:04:16,960 --> 00:04:20,000
what we're doing is we're taking these simple coding supermarket

75
00:04:22,830 --> 00:04:23,440
and viewing

76
00:04:24,520 --> 00:04:27,350
the top of the supermarket as being the real numbers zero

77
00:04:27,850 --> 00:04:30,270
and the bottom of the supermarket is the real number one

78
00:04:31,060 --> 00:04:32,080
and any particular

79
00:04:32,480 --> 00:04:34,000
interval you can see zero one

80
00:04:34,680 --> 00:04:40,120
lived there it goes from a quarter of the way down the supermarket halfway down the supermarket right

81
00:04:40,600 --> 00:04:41,100
so we just

82
00:04:41,660 --> 00:04:45,140
taking the super the supermarket literally at a real

83
00:04:48,480 --> 00:04:52,330
and something you can notice about the supermarket is as you go to the right

84
00:04:52,410 --> 00:04:56,200
if u length and string from say zero one to zero one zero

85
00:04:57,020 --> 00:05:00,660
the interval associated with lincoln string is they subinterval interval

86
00:05:01,250 --> 00:05:01,540
they very

87
00:05:01,980 --> 00:05:03,680
interval you started from

88
00:05:04,100 --> 00:05:09,830
so as you length a binary string you're always defining a subinterval uri behaving this way or this way

89
00:05:10,250 --> 00:05:21,600
you get half of half neural ways ending up inside the place you were a moment before it

90
00:05:22,100 --> 00:05:23,000
so what i'm saying

91
00:05:24,140 --> 00:05:25,500
we're saying that you could imagine

92
00:05:26,140 --> 00:05:27,290
any binary file

93
00:05:27,710 --> 00:05:28,270
having a little

94
00:05:28,710 --> 00:05:29,770
dot in the front of it

95
00:05:30,460 --> 00:05:32,390
called the decimal point or binary point

96
00:05:33,850 --> 00:05:34,210
and then

97
00:05:35,060 --> 00:05:36,210
the remaining characters

98
00:05:37,480 --> 00:05:40,830
are the binary expansion of any real number

99
00:05:40,830 --> 00:05:43,950
is when the variance is maximized in the viruses maximise when you take a peek

100
00:05:43,950 --> 00:05:45,700
was have

101
00:05:45,720 --> 00:05:46,760
which means

102
00:05:46,770 --> 00:05:48,540
this is one four times two

103
00:05:48,560 --> 00:05:50,550
one half would gives

104
00:05:50,610 --> 00:05:53,510
have things

105
00:05:55,540 --> 00:05:58,340
it is this is just to illustrate

106
00:05:59,310 --> 00:06:00,580
this fact

107
00:06:00,610 --> 00:06:02,370
so here

108
00:06:03,160 --> 00:06:04,550
step function here

109
00:06:04,590 --> 00:06:06,040
is the

110
00:06:07,120 --> 00:06:11,270
the cumulative distribution function of the binomial two

111
00:06:11,520 --> 00:06:16,270
the binomial random variable to this is the exact computation with the some that they

112
00:06:16,270 --> 00:06:17,850
should before

113
00:06:18,570 --> 00:06:21,550
and these are the upper bounds

114
00:06:21,550 --> 00:06:23,340
the very suburban

115
00:06:23,350 --> 00:06:26,210
first then

116
00:06:28,560 --> 00:06:30,200
the binomial tail is

117
00:06:30,290 --> 00:06:33,550
one that we had

118
00:06:33,590 --> 00:06:35,390
it's the exponential

119
00:06:35,460 --> 00:06:39,070
what they call expenditure here

120
00:06:39,120 --> 00:06:40,780
and the best gaussians

121
00:06:40,790 --> 00:06:42,030
it is

122
00:06:43,210 --> 00:06:49,740
ignoring the extractor in bernstein's inequality so is like just using this

123
00:06:49,750 --> 00:06:53,480
OK and this is done for the worst case variance

124
00:06:53,530 --> 00:06:54,720
p equals

125
00:06:54,760 --> 00:06:56,210
the house

126
00:06:56,230 --> 00:06:58,300
so four people have more less

127
00:06:58,310 --> 00:07:02,290
they all being the same i mean you don't see a big difference

128
00:07:02,300 --> 00:07:04,710
well you know that it's quite

129
00:07:04,730 --> 00:07:09,210
significantly different from the step function itself especially when you are at the

130
00:07:12,130 --> 00:07:13,050
regions here

131
00:07:13,050 --> 00:07:15,990
we are very far from the value of the pub

132
00:07:16,000 --> 00:07:20,300
but actually if you were to increase the sample size you will not that

133
00:07:20,310 --> 00:07:22,890
this step function becomes closer and closer to

134
00:07:22,900 --> 00:07:25,100
these exponentials

135
00:07:25,110 --> 00:07:26,830
but it captures the right

136
00:07:28,300 --> 00:07:33,520
now if you have a small variance the pictures look different and in particular

137
00:07:37,500 --> 00:07:38,460
the the

138
00:07:38,470 --> 00:07:40,850
upper bounds that take into account the variance

139
00:07:40,880 --> 00:07:44,340
much sharper than those that do not take into account

140
00:07:44,390 --> 00:07:46,110
the virus

141
00:07:47,760 --> 00:07:49,920
here you see the heavy tailed behaviour

142
00:07:49,940 --> 00:07:56,030
like here i have drawn this graph here is the best gaussians

143
00:07:57,470 --> 00:08:01,560
so it's like ignoring one term in the first time inequality

144
00:08:01,620 --> 00:08:02,720
and you see that

145
00:08:02,720 --> 00:08:05,880
four large deviations so it this is assumed

146
00:08:05,910 --> 00:08:08,810
of these graph rainfall in this region

147
00:08:08,810 --> 00:08:11,090
so for large deviations

148
00:08:11,150 --> 00:08:16,170
the tail is no longer gaussians because you you cross this discussion above

149
00:08:16,190 --> 00:08:20,060
and it's better captured at least it's probably by the author

150
00:08:26,910 --> 00:08:29,580
how do we use these inequalities

151
00:08:31,190 --> 00:08:35,280
meaningful way

152
00:08:35,290 --> 00:08:37,330
so the the first thing to simplify

153
00:08:37,390 --> 00:08:40,480
we can keep the whole thing but to simplify

154
00:08:40,480 --> 00:08:42,450
we just replace the variance

155
00:08:42,460 --> 00:08:47,760
by the expectation which in this case is an upper bound on the right

156
00:08:47,770 --> 00:08:51,350
in general it may not very much a matter very much because the functions we

157
00:08:51,350 --> 00:08:55,160
are interested in a small error

158
00:08:55,220 --> 00:08:56,800
and since they have smaller

159
00:08:56,830 --> 00:08:59,090
this is what it's like one

160
00:08:59,110 --> 00:09:02,520
so if we don't lose much by doing this

161
00:09:03,490 --> 00:09:04,490
and if we

162
00:09:04,500 --> 00:09:08,330
use bernstein's inequality and do this inversion again

163
00:09:08,380 --> 00:09:10,360
same thing so instead of

164
00:09:10,380 --> 00:09:14,770
working with probabilities we work with deviations

165
00:09:14,810 --> 00:09:18,720
we get something like this so there are terms that are familiar

166
00:09:18,730 --> 00:09:22,110
the square root of law one of the that over and that's something we already

167
00:09:22,890 --> 00:09:24,890
we use having

168
00:09:26,660 --> 00:09:27,730
comes in

169
00:09:28,460 --> 00:09:29,440
the variance are

170
00:09:29,450 --> 00:09:31,770
upper bound on the variance

171
00:09:32,850 --> 00:09:33,990
which means

172
00:09:33,990 --> 00:09:35,380
the smaller the variance

173
00:09:35,420 --> 00:09:36,860
this model

174
00:09:36,870 --> 00:09:39,310
and we have an extract from that comes from these

175
00:09:39,310 --> 00:09:42,190
heavy tailed behaviour

176
00:09:42,650 --> 00:09:46,150
which is actually

177
00:09:46,170 --> 00:09:49,460
not very important because as the sample size increases

178
00:09:49,460 --> 00:09:50,990
the weight of

179
00:09:51,040 --> 00:09:55,380
this term becomes negligible compared to the weight of the history

180
00:09:55,940 --> 00:09:58,650
OK so no way this is also

181
00:09:58,670 --> 00:10:01,220
reminding you of this

182
00:10:01,920 --> 00:10:03,260
central limit theorem

183
00:10:03,270 --> 00:10:08,990
but in the end if you sum up enough independent random variables you will obtain

184
00:10:08,990 --> 00:10:11,640
always gaussians behaviour

185
00:10:12,480 --> 00:10:17,570
weight is you can see here this will disappear when n becomes large manger with

186
00:10:17,570 --> 00:10:21,260
be this one which comes from this gaussians e to the minus

187
00:10:21,280 --> 00:10:22,150
the square

188
00:10:27,900 --> 00:10:32,240
so we can ignore essentially determined just remember that

189
00:10:32,250 --> 00:10:35,100
the fact that we use the variance

190
00:10:35,160 --> 00:10:36,360
and these

191
00:10:37,440 --> 00:10:40,880
the main contribution

192
00:10:40,890 --> 00:10:45,060
so of course we can

193
00:10:45,110 --> 00:10:47,300
combine this with the union bound to get

194
00:10:47,310 --> 00:10:52,570
so like the trick right this for all individual functions in our class and sum

195
00:10:52,570 --> 00:10:53,660
up for

196
00:10:54,060 --> 00:10:56,800
a finite set of such functions

197
00:10:56,820 --> 00:10:59,050
and what we would think is

198
00:10:59,050 --> 00:11:00,940
same factor before

199
00:11:00,950 --> 00:11:04,520
we have this extra log n factor that comes

200
00:11:04,630 --> 00:11:05,910
here i am

201
00:11:05,980 --> 00:11:07,480
put them together for

202
00:11:07,490 --> 00:11:11,790
base that this is just log n plus one of them

203
00:11:11,790 --> 00:11:16,370
as a commercial center based on a single

204
00:11:16,390 --> 00:11:19,770
the first one is is in mount see this a single

205
00:11:19,770 --> 00:11:21,310
this other means

206
00:11:21,330 --> 00:11:24,560
here there is an incline being cleaned homes

207
00:11:24,580 --> 00:11:29,390
and the same is this building models

208
00:11:29,410 --> 00:11:34,980
the stimulus and the same scene in another way callers with the same distribution c

209
00:11:35,040 --> 00:11:36,870
horizontal beam is on

210
00:11:36,890 --> 00:11:44,940
a vertical beam always on an incline being this in is built

211
00:11:44,940 --> 00:11:50,190
and there is no still appear in the oncology center in here because they collect

212
00:11:50,370 --> 00:11:56,930
patients coming also from the south of the north sea so that's how sweden

213
00:11:57,020 --> 00:11:59,040
denmark and so on

214
00:12:00,080 --> 00:12:01,330
in europe

215
00:12:01,350 --> 00:12:03,580
there is a pleasant

216
00:12:03,620 --> 00:12:06,890
already under construction for

217
00:12:06,910 --> 00:12:08,390
carbon ions and

218
00:12:08,410 --> 00:12:11,160
heidelberg five

219
00:12:11,170 --> 00:12:12,660
now go thank you

220
00:12:12,660 --> 00:12:15,330
and then the police have made of straw

221
00:12:15,350 --> 00:12:22,230
under the direction of doctor benedict CSR is building a center for the knowledge that

222
00:12:22,230 --> 00:12:27,660
this sort of all students in this audience faces south towards the end it is

223
00:12:27,660 --> 00:12:31,830
based on the same design our teams they decided you can see

224
00:12:31,870 --> 00:12:38,500
single they're totally unique outside and the middle east has made an agreement with us

225
00:12:39,250 --> 00:12:41,480
now and the bald

226
00:12:41,500 --> 00:12:43,140
the design so would be

227
00:12:43,160 --> 00:12:47,710
reproducing the second which is being built in pavia finally

228
00:12:47,750 --> 00:12:54,460
in europe in fact final one for the last apology in low call it twice

229
00:12:54,480 --> 00:12:58,830
this is the place where a little bit in which is now

230
00:12:58,850 --> 00:13:00,640
by the end of the year

231
00:13:00,660 --> 00:13:06,870
choosing the constructed in between different constructors there to choose are constructed to start the

232
00:13:06,870 --> 00:13:11,870
project which also find of france we have a carbon ions percent

233
00:13:13,020 --> 00:13:15,080
there appointed clerk and

234
00:13:15,100 --> 00:13:16,600
it using

235
00:13:16,620 --> 00:13:18,750
coming in france

236
00:13:18,770 --> 00:13:20,620
which is based on the new

237
00:13:20,640 --> 00:13:26,160
superconducting cyclotron by being almost told for carbon ions

238
00:13:26,190 --> 00:13:30,710
is based on single because this is the standard way to go to accelerate to

239
00:13:30,710 --> 00:13:36,060
five thousand this company but i do you know that i just started a new

240
00:13:36,060 --> 00:13:41,480
project which is a very big one is superconducting cycle ways to seven hundred columns

241
00:13:41,480 --> 00:13:48,140
just feeling was six meters which is this form hundred the probabilities for

242
00:13:48,960 --> 00:13:50,520
maybe carbon ions

243
00:13:50,540 --> 00:13:53,660
which are extracted and come out

244
00:13:53,670 --> 00:13:55,160
together with support

245
00:13:55,170 --> 00:13:57,850
and then we start to believe this one as the

246
00:13:57,870 --> 00:14:00,370
it is finalized

247
00:14:01,310 --> 00:14:05,710
working on this activity is going on in the framework of what we call in

248
00:14:06,640 --> 00:14:09,210
would be an extra full i don't so

249
00:14:09,230 --> 00:14:13,500
which is not in phase in two thousand five and has been renewed

250
00:14:14,480 --> 00:14:18,640
as like platform JSI project we simulated tree

251
00:14:18,690 --> 00:14:23,810
the pair which is completing construction not going to feel sharing construction middle school which

252
00:14:23,810 --> 00:14:26,830
is pull it one which is the

253
00:14:26,830 --> 00:14:32,290
and we all remember of this platform which is coordinated by the nineteenth entries here

254
00:14:32,330 --> 00:14:33,600
by the way to this

255
00:14:33,620 --> 00:14:37,230
and this is producing programs for

256
00:14:37,230 --> 00:14:44,930
complimenting accelerators because there's a lot more than accelerator treatment following new moving organs

257
00:14:45,390 --> 00:14:51,350
measuring the doors making good images all that needs a lot of work

258
00:14:51,940 --> 00:14:56,000
activities new research and three project approved

259
00:14:56,020 --> 00:15:01,620
with this means for a total of ten billion euros

260
00:15:01,750 --> 00:15:06,370
well as subject so well that these two chapters and i go back a moment

261
00:15:06,370 --> 00:15:09,940
so that you make fools on the fly

262
00:15:09,960 --> 00:15:14,100
first use of accelerators for diagnostic

263
00:15:14,120 --> 00:15:16,040
and and of

264
00:15:16,040 --> 00:15:23,000
we're beginning and thank you very very much for inviting me and that it is

265
00:15:23,000 --> 00:15:27,720
a great honor that this book has been translated into civilian

266
00:15:27,850 --> 00:15:30,610
and I want

267
00:15:30,660 --> 00:15:34,270
To thank

268
00:15:34,750 --> 00:15:39,770
To think Moran with his book was written and unusually who did the pictures and

269
00:15:39,790 --> 00:15:46,360
I want to send a very very much regret women all organized all this events

270
00:15:46,360 --> 00:15:51,200
it probably harm and income that they think of the child

271
00:15:51,300 --> 00:16:01,130
and Simone was the words thank you very much and all copies of Boston Helfer

272
00:16:01,670 --> 00:16:08,550
Sotomayor's this picture and this picture is showing them something that an Amish enables people

273
00:16:08,560 --> 00:16:13,620
the 5 mothers and this is a picture but a strong

274
00:16:13,760 --> 00:16:19,260
so to tell us something about what we are and where we're asking ourselves here

275
00:16:19,260 --> 00:16:23,560
with our here I am a human being with certain features with certain characteristic how

276
00:16:23,560 --> 00:16:30,100
the company will play in what is it that makes me Walter and wit when

277
00:16:30,100 --> 00:16:34,180
were when we're asking this question there are all kinds of answers that we're giving

278
00:16:34,180 --> 00:16:34,960
to this

279
00:16:34,990 --> 00:16:40,870
and while think is there is this uniting the DNA our genes make us what

280
00:16:40,870 --> 00:16:46,200
we are doing here is the 1st novel and this is where the transmission of

281
00:16:46,200 --> 00:16:50,650
DNA the DNA is making sport but it's not just me and it's also what

282
00:16:50,660 --> 00:16:53,010
is in the fertilized egg

283
00:16:53,060 --> 00:16:56,870
what is the 1st to us that in addition to the inmate is also making

284
00:16:56,870 --> 00:17:02,210
that's what we are public and the differences in there in in the cytoplasm which

285
00:17:02,210 --> 00:17:07,990
make a difference to what would become the start of thinking about ourselves human beings

286
00:17:07,990 --> 00:17:12,570
mammals we have virus the warm and the environment of the war is also important

287
00:17:12,600 --> 00:17:19,630
in making us what we are and that there is a development very very important

288
00:17:19,730 --> 00:17:24,820
very important things happen to the baby during the development which makes it what it

289
00:17:25,690 --> 00:17:32,980
things that are transmitted to it from me for an early maternal here and that

290
00:17:33,050 --> 00:17:39,440
there is this hold huge saying the great novel for us is the symbolic of

291
00:17:39,440 --> 00:17:44,450
the mother culture and this is making that's also what we are so this when

292
00:17:44,450 --> 00:17:48,760
we're thinking about what that is how we become what we are done many things

293
00:17:48,760 --> 00:17:54,110
that we have to take into consideration many things which are important for our developed

294
00:17:54,110 --> 00:17:59,230
not very interesting thing is that this thing I'm not just important for our development

295
00:17:59,230 --> 00:18:04,420
that also important for our evolutionary and the resolve that are important for the part

296
00:18:04,420 --> 00:18:11,630
of emotion is that information from slated for all this different rules and variations in

297
00:18:11,630 --> 00:18:17,570
information transmitted for all this rules can be inherited from 1 generation to the next

298
00:18:18,040 --> 00:18:23,450
and if the variations a difference of different types of genetic

299
00:18:23,510 --> 00:18:32,350
every genetic here behavior symbolic can already transmitted from 1 generation to the next and

300
00:18:32,350 --> 00:18:38,420
variations can be transmitted that this can have revolutionary significance and when thinking about the

301
00:18:38,420 --> 00:18:45,280
very complex creature like ourselves humans we must take all this into consideration when we

302
00:18:45,280 --> 00:18:49,040
thinking about plants of course we don't think about culture but we have to think

303
00:18:49,040 --> 00:18:54,130
a lot not only about genetics but also about kitchen when thinking about plans for

304
00:18:54,130 --> 00:18:59,890
example and it when we're thinking about rats will not think about the symbolic system

305
00:18:59,890 --> 00:19:02,440
but we have to think about all the other aspects

306
00:19:02,540 --> 00:19:10,940
so they are able to for the way we can think about this 5 models

307
00:19:10,940 --> 00:19:16,950
of course Nova disrespect to fathers just below the picture because the storm watch

308
00:19:17,230 --> 00:19:22,300
so so we're think about the provider of the denying the provider of the novel

309
00:19:22,300 --> 00:19:27,580
The United out of there the provider of of enlargement in the case of an

310
00:19:27,720 --> 00:19:33,580
numbers woman built the provider of home in Qatar for social creatures were granted carries

311
00:19:33,580 --> 00:19:40,120
very important and the providers of social education with thinking about ourselves

312
00:19:40,380 --> 00:19:46,080
and again it's the same kind of things just said that a little bit differently

313
00:19:46,250 --> 00:19:52,290
with think about transmission from DNA from all that genetics of in hurricane systems

314
00:19:53,050 --> 00:20:01,520
reconstructions of development and this is transmitted not the guy but something in a way

315
00:20:01,520 --> 00:20:07,640
that soon wins the government's somewhat Osama calling for socially learned behavior are also somewhat

316
00:20:07,650 --> 00:20:11,110
to so much and symbolic culture

317
00:20:13,420 --> 00:20:17,350
that I will not talk very much about genetics because I'm sure that you all

318
00:20:17,350 --> 00:20:21,690
know a lot about it I just want to say something a few words about

319
00:20:22,100 --> 00:20:27,220
and that is the very naive notion that we can think about genes for this

320
00:20:27,220 --> 00:20:34,110
genes for obesity James forced stupidity Janesville Wis the genes for those genes for that

321
00:20:34,110 --> 00:20:39,990
this kind of native picture is no longer value there are of course genes which

322
00:20:39,990 --> 00:20:45,720
have a big effect on the traits that the difference in a June particular genes

323
00:20:45,720 --> 00:20:49,770
can make a big difference in the trade but in the majority of cases it

324
00:20:49,780 --> 00:20:55,030
is the G network that is important if will want to understand the trade traits

325
00:20:55,060 --> 00:21:00,280
the development of the trade how how this trade promised we would have to think

326
00:21:00,280 --> 00:21:07,290
about the whole network of Jews disability black pants and where there are interrupting together

327
00:21:07,290 --> 00:21:14,990
and also interrupting with environment to perform the development of developmental landscape this at the

328
00:21:14,990 --> 00:21:24,520
genetic landscape as Waddington hold how development work because all the cooperation and interruptions very

329
00:21:24,520 --> 00:21:30,430
complex interaction between all the genes so when we're thinking about genetics when we're thinking

330
00:21:30,430 --> 00:21:34,580
about how genes influence what we are we're not thinking about simply genes but not

331
00:21:34,590 --> 00:21:37,750
robots that toppled by the constraints with

332
00:21:37,790 --> 00:21:41,430
it is all concert of this

333
00:21:41,480 --> 00:21:45,970
collection of genes and there are a number of this way that are important in

334
00:21:45,970 --> 00:21:53,310
this way interrupt with them but I want to say just and and another thing

335
00:21:53,310 --> 00:21:56,540
and I will not all very much about it just want to point to it

336
00:21:56,600 --> 00:22:02,250
and we can discuss it later the usual way of thinking about mutations in genes

337
00:22:02,250 --> 00:22:09,610
from wherever this mutations are completely wrong but now there is an element of truth

338
00:22:09,980 --> 00:22:11,050
in this

339
00:22:11,690 --> 00:22:13,190
a bus

340
00:22:13,310 --> 00:22:14,110
we know

341
00:22:14,260 --> 00:22:20,080
that why however mutations will appear we know that under stress there is a bust

342
00:22:20,080 --> 00:22:27,540
of mutations of all kinds win all that whereas mutation we look for ways wheelchair

343
00:22:28,220 --> 00:22:31,430
this can also checked

344
00:22:31,480 --> 00:22:36,040
this that this can be very environment could have a very big effect on which

345
00:22:36,040 --> 00:22:37,310
thinks so

346
00:22:37,730 --> 00:22:43,460
when we're thinking about genetic variation regained have a very much more sophisticated view than

347
00:22:43,460 --> 00:22:47,730
the simple view that we used to have however we know quite a lot about

348
00:22:47,730 --> 00:22:49,160
Genentech's so

349
00:22:49,170 --> 00:22:50,240
and we know

350
00:22:50,240 --> 00:22:53,630
well one thing that you put them with this is that they use this

351
00:22:53,630 --> 00:22:55,690
as generic feature extractors they live

352
00:22:55,770 --> 00:22:59,210
essentially taken the overfeat system or other similar system top

353
00:22:59,210 --> 00:23:02,810
of the last layer and then we train the last layer to do other

354
00:23:02,820 --> 00:23:07,170
tasks use this sort of feature extractor so with this you can when

355
00:23:07,170 --> 00:23:09,390
competition that distinguish gas from dogs

356
00:23:10,190 --> 00:23:13,680
which means you if you are kept overdub over you can eliminate one

357
00:23:13,680 --> 00:23:17,510
of the other from your phys book the when suggested is facebook

358
00:23:17,520 --> 00:23:20,470
said if you take the caste like half the traffic goes so

359
00:23:24,080 --> 00:23:28,030
and this is team th that try a lot of different

360
00:23:28,320 --> 00:23:31,800
conclusion tasks datasets by using essentially the overfeat

361
00:23:31,870 --> 00:23:35,150
features chopping of the last layer training and got prima set

362
00:23:35,150 --> 00:23:38,200
of the performance just everything tried or slightly below

363
00:23:38,200 --> 00:23:42,190
the above except for one i was told yesterday to really just on

364
00:23:42,190 --> 00:23:45,550
this the also teams said the it's actually not working very well

365
00:23:45,550 --> 00:23:48,540
for the oxford dataset as a protocol used with appropriate so

366
00:23:48,540 --> 00:23:53,210
this is kind of application to classify to recognize buildings from

367
00:23:53,220 --> 00:23:57,320
in the oxford campus so it's kind specific object recognition

368
00:23:58,260 --> 00:24:00,200
so that works ok but great

369
00:24:02,300 --> 00:24:07,530
you can use to do similarity matching so this something we used

370
00:24:07,540 --> 00:24:10,330
to call saying these networks we can

371
00:24:10,810 --> 00:24:15,620
group this in name of embedding this idea as to get

372
00:24:15,640 --> 00:24:18,870
to know as to how much function doesn't matter where they are

373
00:24:18,880 --> 00:24:20,360
that are controlled the same

374
00:24:20,630 --> 00:24:24,630
parameters the same weights and feed to images that images are semantically

375
00:24:24,630 --> 00:24:27,540
identical so for example to pictures of the same person

376
00:24:28,610 --> 00:24:32,010
you train the system to produce vectors on the by on the output

377
00:24:32,220 --> 00:24:35,190
you'll specified vector just said to act as to the right

378
00:24:35,190 --> 00:24:38,230
and then if you show two images of different persons semantically

379
00:24:38,230 --> 00:24:41,200
different you push those vectors apart until they are a certain

380
00:24:41,200 --> 00:24:46,080
distance because this technique so several loss function you can

381
00:24:46,090 --> 00:24:48,900
use for this there is this one that we like

382
00:24:49,840 --> 00:24:52,850
this kind of margin bayes loss function the called dr lim

383
00:24:52,850 --> 00:24:55,580
that means dimension to reduction by learning an invariant

384
00:24:55,580 --> 00:24:58,770
mapping one of those cute acronyms so that but

385
00:24:59,400 --> 00:25:03,040
is used for rice applications and with this one thing like phase

386
00:25:03,050 --> 00:25:08,090
work which is embedding or pieces of

387
00:25:09,030 --> 00:25:11,990
media or whatever they are text images videos

388
00:25:12,340 --> 00:25:16,270
people into a vector space such that

389
00:25:16,270 --> 00:25:19,820
distance in that vector space of the products correspond to similarity

390
00:25:19,820 --> 00:25:23,440
some sort okay so for example you have a vector for user and vector

391
00:25:23,450 --> 00:25:24,190
for a piece of

392
00:25:26,210 --> 00:25:30,590
like piece of news or error or image is the product between the

393
00:25:30,600 --> 00:25:34,930
two vectors after mapping is large then that means this person

394
00:25:34,930 --> 00:25:37,630
is likely to be interested by that piece of content

395
00:25:37,630 --> 00:25:40,910
if you know piece of text and image and match that means probably

396
00:25:40,910 --> 00:25:43,480
the text corresponds so the image could be query for the image

397
00:25:43,480 --> 00:25:45,960
of the image could be a good answer to the to the text

398
00:25:45,960 --> 00:25:48,960
so things like this or you know the text similar to to text

399
00:25:48,960 --> 00:25:50,970
so low things you can do embedding and

400
00:25:51,190 --> 00:25:54,210
well things we're trying to do is basically and the world

401
00:25:55,030 --> 00:25:58,470
and what things we have we been using is embedding techniques for

402
00:25:58,470 --> 00:26:02,320
is case ok recognition so this is work not involved in

403
00:26:02,380 --> 00:26:04,600
although is taking place to look at my lab

404
00:26:04,630 --> 00:26:08,930
says any tag man and on mostly at to book

405
00:26:09,180 --> 00:26:11,560
yeah research and use a commercial net to

406
00:26:12,050 --> 00:26:13,690
to face recognition is a bit of

407
00:26:13,890 --> 00:26:17,540
f alignment of the face before and that's actually very sophisticated

408
00:26:17,980 --> 00:26:21,310
and then there is training of this thing as classifier and then

409
00:26:21,310 --> 00:26:23,990
there is another phase of sort of refining the representation by

410
00:26:23,990 --> 00:26:27,530
using embedding also using quiteria to produce embeddings are

411
00:26:27,530 --> 00:26:30,630
small dimension mostly binary so that you can store them on very

412
00:26:30,630 --> 00:26:35,410
compact are very compactly and we can source who

413
00:26:36,220 --> 00:26:39,590
you know hundreds of millions of faces very very quickly

414
00:26:40,200 --> 00:26:43,990
and on ten datasets probably datasets like the label face while

415
00:26:44,740 --> 00:26:46,800
this system is the performs human-level

416
00:26:47,140 --> 00:26:49,840
essentially so this is really exciting

417
00:26:50,560 --> 00:26:54,050
another very recent so as you less than other first people to care

418
00:26:54,050 --> 00:26:59,070
about this working to this slides we are participated

419
00:27:00,040 --> 00:27:01,840
so i had a is things to learn from

420
00:27:02,140 --> 00:27:06,020
from the code uri you reach on our and he the

421
00:27:07,930 --> 00:27:11,030
so fell into a habit of winning carol competitions

422
00:27:12,300 --> 00:27:15,370
and i was getting lab and say what what curvature can when

423
00:27:15,890 --> 00:27:19,120
well when you try this the stereo stuff so this kitti dataset

424
00:27:19,120 --> 00:27:23,460
which is a large dataset of so grant with a stereo images with light

425
00:27:23,470 --> 00:27:26,030
data and use the commercial that training course

426
00:27:26,200 --> 00:27:29,800
to run this similarity function between patches that's what you need

427
00:27:29,800 --> 00:27:32,290
to do is to matching you to find a patch in the

428
00:27:32,290 --> 00:27:35,420
left image correspond to the passion right image and you find

429
00:27:35,420 --> 00:27:38,380
it you have disparity in that one from that you can see that

430
00:27:38,380 --> 00:27:42,640
f and we train a pretty large commercial net about six hundred

431
00:27:42,950 --> 00:27:45,770
thousand parameters to basically tell it the

432
00:27:46,040 --> 00:27:49,770
similarity between two patches using the the want to some dataset

433
00:27:49,890 --> 00:27:53,220
and he managed to actually be the record so he's got to put six

434
00:27:53,220 --> 00:27:56,970
percent error this some measure of you know what percentage of points

435
00:27:56,980 --> 00:28:00,850
are discouraged as more you know more and pixels away from the

436
00:28:00,860 --> 00:28:06,470
real one and the runner-ups is the team from from to the intro

437
00:28:07,610 --> 00:28:11,050
spin around for a while and so that's a very impressive these are

438
00:28:11,050 --> 00:28:15,280
samples of results and data so this is you get stereo with

439
00:28:15,590 --> 00:28:19,170
relatively small baseline for those images are black and white

440
00:28:19,650 --> 00:28:23,070
says from car driving around and you get those really beautiful

441
00:28:23,140 --> 00:28:26,370
that images so he's going to talk about this that the worship

442
00:28:26,370 --> 00:28:30,560
of the to the set today i'm and it's a was invited today

443
00:28:30,980 --> 00:28:35,600
to come to the set of a because you just published results yesterday

444
00:28:35,610 --> 00:28:40,290
on the board so and things like this you can do like body with estimation

445
00:28:40,300 --> 00:28:43,410
stuff which may or may not show that if yeah

446
00:28:44,070 --> 00:28:47,450
i switch topic to show you a demo of this system

447
00:28:51,110 --> 00:28:52,940
c i might have to

448
00:28:52,940 --> 00:29:01,080
the first

449
00:29:01,100 --> 00:29:14,320
this presentation is delivered by the stanford center for professional development

450
00:29:15,070 --> 00:29:20,490
here is in a nutshell a reduced version of what's presented in hand out to

451
00:29:20,490 --> 00:29:22,190
this is the syllabus

452
00:29:22,210 --> 00:29:24,260
i have

453
00:29:24,280 --> 00:29:28,210
several languages available on the board and what just one concept c

454
00:29:30,770 --> 00:29:34,780
sequence one

455
00:29:37,510 --> 00:29:41,030
programming language that's just

456
00:29:45,330 --> 00:29:47,470
and then

457
00:29:47,520 --> 00:29:53,760
it's official i'm actually recover height from from now on one of seven

458
00:29:53,950 --> 00:29:56,360
people look at this and they go out i'm going to be able to legitimately

459
00:29:56,360 --> 00:29:58,680
put all these languages on my resume

460
00:29:58,780 --> 00:30:02,640
OK in this concept list of the bottom and it feels really good it isn't

461
00:30:02,640 --> 00:30:06,590
so much about that certainly when we want to give you some mileage in some

462
00:30:06,590 --> 00:30:12,210
very relevant languages that are very good for both research for industry but

463
00:30:12,220 --> 00:30:16,900
the real intellectual value in in learning all these languages is to really study the

464
00:30:16,900 --> 00:30:21,970
paradigms that they represent and i'll explain what that means in the second program in

465
00:30:21,970 --> 00:30:26,680
c or c plus plus it's actually almost the different thought your you're following a

466
00:30:26,680 --> 00:30:30,990
different thought process than you are when you program in scheme one pi

467
00:30:31,060 --> 00:30:33,390
OK you all know enough

468
00:30:33,400 --> 00:30:36,810
c plus plus and believe it or not you know let's see already just take

469
00:30:36,810 --> 00:30:41,630
out the object orientation from people's party more less likely see when you program in

470
00:30:42,300 --> 00:30:44,600
curacy and you have no classes

471
00:30:44,620 --> 00:30:51,650
you're very procedure procedure oriented think about the main function is being high-level outline of

472
00:30:51,660 --> 00:30:53,920
maybe five top functions to call

473
00:30:53,930 --> 00:30:57,760
and those five functions it types of functions and there some functions of subset functions

474
00:30:57,760 --> 00:30:58,670
et cetera

475
00:30:58,680 --> 00:31:01,090
and to make sense is like a bit like it's like

476
00:31:01,140 --> 00:31:05,920
i've outlined for history outlined notes for history class we have roman one in a

477
00:31:06,020 --> 00:31:09,850
one two and mineral three many small a and b and a little eyes and

478
00:31:09,850 --> 00:31:10,850
things like that

479
00:31:10,860 --> 00:31:12,740
still getting out OK

480
00:31:12,750 --> 00:31:15,330
your oriented around procedures OK

481
00:31:15,340 --> 00:31:19,480
you program with side effects you pasaran references and pointers with the idea of updating

482
00:31:19,480 --> 00:31:22,990
shared data OK you don't have both in c and c plus plus

483
00:31:23,090 --> 00:31:26,880
but as far as c is concerned this represents

484
00:31:27,130 --> 00:31:31,110
what's called procedural paradigm you also here called the imperative paradigm

485
00:31:31,130 --> 00:31:35,100
it is verb oriented in the sense that the first thing you ever see or

486
00:31:35,140 --> 00:31:37,070
do you typically see with the statement

487
00:31:37,080 --> 00:31:41,840
it is the function call with the function name is usually has some strong verb

488
00:31:41,840 --> 00:31:44,010
and its so i give you some idea as to what the function supposed to

489
00:31:44,010 --> 00:31:46,870
accomplish OK that makes sense to people

490
00:31:46,880 --> 00:31:48,890
when you study plus plus

491
00:31:48,980 --> 00:31:50,100
and all of a sudden

492
00:31:50,110 --> 00:31:54,630
rather than calling do this in passing the address of some object you do

493
00:31:54,650 --> 00:31:57,410
my object arrow do this

494
00:31:57,500 --> 00:31:58,640
that makes sense

495
00:31:58,660 --> 00:32:02,830
OK then also the first thing you see on that line is the data or

496
00:32:02,830 --> 00:32:06,910
the objects being manipulated and because the first thing you see is the object that's

497
00:32:06,910 --> 00:32:12,730
why it's object oriented as opposed to procedural procedurally oriented make sense people

498
00:32:15,060 --> 00:32:17,760
i think a lot of c plus plus programmers

499
00:32:17,800 --> 00:32:22,110
really program in c and just incidentally use the objects classes that are available to

500
00:32:22,110 --> 00:32:25,660
them which is a perfectly reasonable way to programme most people learn how to program

501
00:32:25,660 --> 00:32:26,360
and c

502
00:32:26,370 --> 00:32:28,340
but industry no c

503
00:32:28,350 --> 00:32:32,840
very very well and in spite of the fact that fifty million new languages that

504
00:32:32,840 --> 00:32:35,850
are better in many regards they still stick with what they know

505
00:32:35,880 --> 00:32:38,900
that's why c and c plus plus still such popular languages

506
00:32:39,090 --> 00:32:43,220
there's nothing wrong at all with programming and see if you really know very well

507
00:32:43,240 --> 00:32:48,650
and directly readable code it's just more difficult it's sorry way it's much easier to

508
00:32:48,650 --> 00:32:53,180
make memory errors in c because everything is exposed very little error checking going to

509
00:32:53,190 --> 00:32:55,760
see plus was a a little bit better about it

510
00:32:55,810 --> 00:33:00,320
in between here i have this thing called assembly i haven't decided whether going to

511
00:33:00,330 --> 00:33:03,050
go with what going on with the past seven or eight years which is this

512
00:33:03,050 --> 00:33:05,130
mark assembly language

513
00:33:05,140 --> 00:33:09,710
or i'm going to really take a step and teacher real not states

514
00:33:09,760 --> 00:33:12,770
it is a real assembly language although you don't see is in use very much

515
00:33:12,770 --> 00:33:16,960
but there's this assembly language called maps which is very easy as far as some

516
00:33:16,970 --> 00:33:21,500
languages go to learn i don't really care so much about teaching you how to

517
00:33:21,500 --> 00:33:25,940
program in assembly i uses the vehicle for showing you how c and c plus

518
00:33:25,940 --> 00:33:31,490
plus programs compile to dino and object files in the binary and eventually become executables

519
00:33:31,800 --> 00:33:37,380
and show you how line like i equals seven or j plus plus or fu

520
00:33:37,970 --> 00:33:42,850
x and y is a function call how that translates to assembly code

521
00:33:42,940 --> 00:33:46,440
OK this makes sense when you know that when you write code that you when

522
00:33:46,440 --> 00:33:50,600
you execute the program it's not supposed possibly more it's it's it's assembly code to

523
00:33:50,600 --> 00:33:54,470
all zeros and ones eventually i want to give you some insight as to how

524
00:33:54,480 --> 00:33:57,340
c is translated to assembly code how

525
00:33:57,350 --> 00:34:01,890
all the variables and function the object and all of that eventually get boiled down

526
00:34:01,890 --> 00:34:04,630
and hashed out to a collection of zeros and ones

527
00:34:04,640 --> 00:34:07,480
and i want to do the same thing for c plus plus

528
00:34:07,500 --> 00:34:12,260
it turns out that while c plus plus and c represent different paradigms that they

529
00:34:13,050 --> 00:34:17,520
also compiled zeros and ones and after you get enough experience with this assembly and

530
00:34:17,520 --> 00:34:21,740
the manual compilation process ever learn about how to look at c code figure what

531
00:34:21,740 --> 00:34:23,300
the semicolon look like

532
00:34:23,320 --> 00:34:25,790
you really going to see that c plus plus and c

533
00:34:25,810 --> 00:34:30,320
almost look like the same language as far as the zeros and ones are conserved

534
00:34:30,320 --> 00:34:34,230
we're really going to extend the compilation model we use for going from seeing assembly

535
00:34:34,270 --> 00:34:39,370
to accommodate c plus plus references and classes and templates and things like that are

536
00:34:39,370 --> 00:34:44,140
native language c and you have and i think very very good understanding of policy

537
00:34:44,140 --> 00:34:48,040
and c plus plus work after the first five weeks of the cause

538
00:34:48,060 --> 00:34:52,390
OK images so much better overseas suppose prospera we're going to demystify the whole point

539
00:34:52,390 --> 00:34:56,230
of thing i'm going to be able to do something like after castro percent after

540
00:34:56,230 --> 00:34:59,820
after p ro as protesters after people seven

541
00:34:59,830 --> 00:35:01,980
and you know exactly what it means

542
00:35:01,980 --> 00:35:05,180
and if i put in energy to put this

543
00:35:05,220 --> 00:35:09,650
electron one high-flying energy all

544
00:35:09,680 --> 00:35:12,730
right energy from here to

545
00:35:14,350 --> 00:35:15,350
o two

546
00:35:15,360 --> 00:35:18,240
plus plus an electron

547
00:35:19,000 --> 00:35:21,040
this physically

548
00:35:21,100 --> 00:35:23,380
is the ionisation energy

549
00:35:25,060 --> 00:35:31,030
right because the first ionisation energy is always the energy required to take off the

550
00:35:31,050 --> 00:35:32,950
most weakly

551
00:35:32,970 --> 00:35:37,840
the bound electrons are the electrons in that most

552
00:35:37,860 --> 00:35:39,440
high flying

553
00:35:39,460 --> 00:35:40,770
energy state

554
00:35:40,780 --> 00:35:43,420
the ionisation energy of o two

555
00:35:43,430 --> 00:35:46,960
it turns out to be about twelve point

556
00:35:46,970 --> 00:35:52,400
o one electron volts that's with that is the means

557
00:35:52,420 --> 00:35:54,170
in contrast here

558
00:35:54,180 --> 00:35:55,660
if i were to

559
00:35:55,680 --> 00:36:01,060
paul poland electron off of an oxygen atom these are the oxygen and state

560
00:36:02,040 --> 00:36:04,500
o one electron off the

561
00:36:04,600 --> 00:36:07,690
oxygen and so i will plus

562
00:36:07,700 --> 00:36:09,310
was an electron

563
00:36:09,320 --> 00:36:11,690
well this is the ionisation energy

564
00:36:11,710 --> 00:36:13,350
of oxygen

565
00:36:13,370 --> 00:36:14,660
this is

566
00:36:14,700 --> 00:36:19,800
a little bit larger than it is for molecular o two this is

567
00:36:19,820 --> 00:36:23,180
thirteen point five a

568
00:36:23,230 --> 00:36:25,120
and you can see the here

569
00:36:25,130 --> 00:36:28,770
these two p states are lower lying in energy

570
00:36:28,790 --> 00:36:29,880
then the

571
00:36:29,890 --> 00:36:35,160
five states in the molecular oxygen this isn't in your notes

572
00:36:37,920 --> 00:36:39,570
and likewise

573
00:36:39,590 --> 00:36:42,220
if i were to look at the

574
00:36:42,260 --> 00:36:44,960
i want to look at the electron affinity

575
00:36:47,560 --> 00:36:51,550
and now i'm just going to draw here the pie

576
00:36:51,560 --> 00:36:53,520
r two

577
00:36:53,530 --> 00:36:55,810
i don't know

578
00:36:55,980 --> 00:36:57,850
he y

579
00:37:00,010 --> 00:37:01,990
here's my atomic states

580
00:37:02,000 --> 00:37:02,760
the other two

581
00:37:02,780 --> 00:37:04,860
five years sigma

582
00:37:04,870 --> 00:37:06,320
here's oxygen

583
00:37:07,870 --> 00:37:09,500
if i were to look at the

584
00:37:09,520 --> 00:37:12,310
the electron affinity of oxygen

585
00:37:12,320 --> 00:37:16,120
molecular oxygen so way up here

586
00:37:16,140 --> 00:37:19,180
i have an old two molecule

587
00:37:19,450 --> 00:37:23,630
plus an electron

588
00:37:23,720 --> 00:37:28,440
putting an electron and i would have to put it in that state

589
00:37:28,470 --> 00:37:32,740
so the energy difference here from here to here

590
00:37:32,750 --> 00:37:35,290
minus the electron affinity

591
00:37:35,310 --> 00:37:40,680
which is in the case of molecular oxygen minus point zero for five

592
00:37:44,830 --> 00:37:48,660
so i just wanted to give you a feeling for what these energy is actually

593
00:37:48,660 --> 00:37:52,420
mean we are not planning on as function of energy here

594
00:37:52,440 --> 00:37:54,660
they physically mean something

595
00:37:54,670 --> 00:38:00,340
right in terms of for example the ionisation energy of molecular oxygen or the ionisation

596
00:38:01,290 --> 00:38:04,210
of atomic oxygen

597
00:38:04,260 --> 00:38:07,140
i can see the light the relative

598
00:38:07,190 --> 00:38:11,920
four hours of the energies of all of these different states

599
00:38:14,970 --> 00:38:18,920
this kind of diagram that we've been drawing here

600
00:38:18,940 --> 00:38:27,330
called sometimes called the molecular orbital energy diagram sometimes called the correlation diagram

601
00:38:27,340 --> 00:38:32,330
it's called the correlation diagram because it shows you by the means of these

602
00:38:32,380 --> 00:38:34,890
the dotted lines here

603
00:38:34,910 --> 00:38:36,290
it shows you

604
00:38:36,300 --> 00:38:41,100
how the atomic states correlate molecular state

605
00:38:41,110 --> 00:38:41,990
that's why

606
00:38:42,020 --> 00:38:48,080
it's it's called the correlation diagram again it shows you how those panic correlate

607
00:38:48,240 --> 00:38:50,420
the molecular states

608
00:38:55,590 --> 00:39:00,460
if not then i want to proceed there was one page and the lecture last

609
00:39:00,460 --> 00:39:02,510
time that i can finish

610
00:39:02,540 --> 00:39:03,960
i want to

611
00:39:04,010 --> 00:39:07,920
talk about it right now

612
00:39:07,930 --> 00:39:12,350
and that was drawing the molecular orbital diagram

613
00:39:12,400 --> 00:39:15,530
the correlation diagram

614
00:39:17,490 --> 00:39:21,090
heteronuclear diatomic molecules

615
00:39:21,110 --> 00:39:25,710
and that's

616
00:39:26,770 --> 00:39:30,380
in the case of the heteronuclear diatomic molecules

617
00:39:30,400 --> 00:39:31,820
we proceed

618
00:39:31,840 --> 00:39:37,180
in the same way as we do for a nuclear diatomic molecules

619
00:39:37,190 --> 00:39:42,440
that is we had the states of the individual atoms out here and now i'm

620
00:39:42,440 --> 00:39:44,140
just showing you

621
00:39:44,170 --> 00:39:46,030
i two p states

622
00:39:46,040 --> 00:39:50,360
two s are down here white as is down here lower in energy very and

623
00:39:50,360 --> 00:39:52,970
run at all

624
00:39:52,990 --> 00:39:54,920
and what you also see

625
00:39:54,940 --> 00:39:56,350
is that

626
00:39:56,370 --> 00:39:57,610
two pieces

627
00:39:57,620 --> 00:40:02,850
states and the oxygen atom here more energy than the two p states and higher

628
00:40:02,850 --> 00:40:06,530
pay and that's right remember we talked about

629
00:40:06,580 --> 00:40:11,260
the there is the nuclear charge gets larger

630
00:40:11,280 --> 00:40:13,590
those atomic state

631
00:40:13,630 --> 00:40:16,270
are more strongly bound

632
00:40:16,450 --> 00:40:20,510
because the coulomb interaction is greater

633
00:40:20,560 --> 00:40:25,620
so the atomic states of oxygen are lower in energy than those of carbon

634
00:40:25,640 --> 00:40:30,980
if you were to ask to draw the fano problem around you would have to

635
00:40:30,980 --> 00:40:33,450
show that the oxygen

636
00:40:33,470 --> 00:40:39,200
atomic states are lower in energy than those for carbon

637
00:40:41,580 --> 00:40:44,350
but we proceed much in the same way

638
00:40:44,360 --> 00:40:46,460
that is

639
00:40:46,460 --> 00:41:58,250
OK OK OK e talking to a thousand we ready to go up to a

640
00:41:58,260 --> 00:42:06,510
point where the frozen as a what are you doing I was only we 1 of those of

641
00:42:06,940 --> 00:42:16,240
the strategy we used for the 1st time the back results but we're making some substitutions is the case of the

642
00:42:16,240 --> 00:42:20,100
fact that we're not with real valued functions and Robin

643
00:42:20,100 --> 00:42:29,450
just making a finite set of of the of of this covering of sources of growth function number of

644
00:42:29,580 --> 00:42:39,100
our approximations when I'm going to have this covering of the functions which are accurate up to this gamma log amount to impact

645
00:42:39,640 --> 00:42:43,770
on the training examples of it so that's that's the from it

646
00:42:43,860 --> 00:42:47,000
appears to have a go at the stage 1 week we we going to

647
00:42:47,000 --> 00:42:49,300
make this assumption that the stress zero training are

648
00:42:49,300 --> 00:42:53,060
getting simplified things um well that this is going to

649
00:42:53,060 --> 00:42:55,620
have to be true going have this property which is the

650
00:42:55,720 --> 00:42:58,850
margin on the training set is bigger the rate of the Gamma

651
00:42:59,010 --> 00:43:02,220
nominal define the margin I think you've using that we

652
00:43:02,280 --> 00:43:10,680
learn how do with the other buttons tool console from and within a make this a further assumption that the

653
00:43:10,680 --> 00:43:14,860
error a um the true error of this function is Graham Repsol

654
00:43:14,960 --> 00:43:18,040
put in the here but it previously I left out the P but

655
00:43:18,040 --> 00:43:22,980
that's just the underlying probability of error of so it's

656
00:43:22,990 --> 00:43:27,480
the same thing as before so this is the thing that is exactly the same as we

657
00:43:27,480 --> 00:43:31,140
had before except but now we've got this condition that there's a

658
00:43:31,140 --> 00:43:34,440
margin on the training set and we're now looking at these

659
00:43:34,440 --> 00:43:38,900
real valued functions um and there's a but you know they

660
00:43:38,900 --> 00:43:41,720
could be very high dimensional so we're not total assuming

661
00:43:41,720 --> 00:43:46,820
a finite told will certainly not a small BC dimension of character so

662
00:43:46,820 --> 00:43:51,360
located we not using the double sample triplicated in the

663
00:43:51,360 --> 00:43:55,240
Cape here's the double sample trick when I'm looking at a

664
00:43:55,240 --> 00:44:03,580
double sample um and in place of this 1 on as before we just have an estimate of its error on the 2nd

665
00:44:03,580 --> 00:44:14,300
sample that it is the least half of the true error uh and we got to case of the usual tree and character now we can uh about

666
00:44:14,320 --> 00:44:17,360
making a different step and this is this is moving to the

667
00:44:17,360 --> 00:44:26,620
cover of know what's going to happen is of any functions and which has the property that we're going to find the

668
00:44:26,620 --> 00:44:30,280
function in the cover there's with being gamma on to so

669
00:44:30,280 --> 00:44:35,660
damn around to cover on the double sample of up so its

670
00:44:35,660 --> 00:44:40,560
output of is a function of a crime which is the in the

671
00:44:40,560 --> 00:44:44,920
cover the it is going to be within gamma on to effect on all of

672
00:44:44,920 --> 00:44:49,980
the training examples now that means that the margin on the

673
00:44:50,120 --> 00:44:54,600
1st part on the training sample may reduce but were

674
00:44:54,600 --> 00:44:59,580
introduced below gamma on to because the margin of the .

675
00:44:59,580 --> 00:45:03,480
before was at least gamma now we've they may change their

676
00:45:03,480 --> 00:45:08,490
value by a baby on to but it is still going to be gone to

677
00:45:09,760 --> 00:45:15,140
so it may reduce it may increase I mean because we don't know which way this the approximation

678
00:45:15,140 --> 00:45:18,870
works but at least we know that it's not the worst thing to our

679
00:45:18,880 --> 00:45:23,480
to compare so that's that's the 1st property of this

680
00:45:23,480 --> 00:45:28,520
function now the 2nd property that we know is the these guys that

681
00:45:28,520 --> 00:45:34,400
will misclassified before right they were on the wrong side of the mountain when

682
00:45:34,400 --> 00:45:37,540
they get a approximated with an accuracy gamelan to in my

683
00:45:37,540 --> 00:45:41,890
become correctly classified because the my that over the

684
00:45:41,820 --> 00:45:45,320
The playing but then not going to get to a margin of gamma

685
00:45:45,250 --> 00:45:50,420
around 2 on the other side so that um margin of denoted

686
00:45:50,430 --> 00:45:54,420
this by the the marginal wide brackets epsilon anova to

687
00:45:54,420 --> 00:45:59,440
what I media is need their epsilon over 2 points in the in

688
00:45:59,440 --> 00:46:03,630
the y sample of that have marginal less than gamma on to

689
00:46:04,080 --> 00:46:10,300
them for the function as time pay so you can imagine you know the approximation is the

690
00:46:10,280 --> 00:46:14,440
shrinking the gap that we had between what happens on the sample where we

691
00:46:14,440 --> 00:46:18,740
had nice high-margin an on the on the go sample we have seen a

692
00:46:18,740 --> 00:46:21,760
specifications but it's not going to shrink it so that they

693
00:46:21,760 --> 00:46:25,600
could be actually coffee indistinguishable so on the left

694
00:46:25,600 --> 00:46:31,940
hand side you got down to to on the right hand side of that the EP's on a over 2 points that were

695
00:46:31,940 --> 00:46:35,080
misclassified not have gamma but the less than the amount

696
00:46:35,080 --> 00:46:38,600
of into a game you can apply to use the translation

697
00:46:38,600 --> 00:46:43,020
arguments essentially used for being permutations and the point is

698
00:46:43,020 --> 00:46:49,800
that those points that were errors before cannot be moved to the left and to need to be moved to the

699
00:46:49,800 --> 00:46:52,940
left hand side because if they did they would have margin

700
00:46:52,950 --> 00:46:56,340
less than gallant 2 and this property would fail so these

701
00:46:56,340 --> 00:46:59,740
guys a game in order for this property the whole have to be

702
00:46:59,740 --> 00:47:05,040
kept on the on the right hand side and of gaining have the probability to to the minus that

703
00:47:05,060 --> 00:47:08,160
on the mid to if you think I mean I was talking in the

704
00:47:08,150 --> 00:47:11,120
break and some of you may be added to sort of make a clear

705
00:47:11,120 --> 00:47:14,520
enough with we assume a translation thing you don't think

706
00:47:14,520 --> 00:47:19,160
of generating remember we were generated probabilities would swaps cut

707
00:47:19,200 --> 00:47:23,120
uniformly the way we can be good during that is designed for each

708
00:47:23,120 --> 00:47:26,040
swap I'm going to choose to why this walk or not all the

709
00:47:26,040 --> 00:47:30,380
probability off independently and so if you think you're

710
00:47:30,420 --> 00:47:36,840
doing it that way and the probability of leaving or the bad guys on the wrong strong on the back on the go

711
00:47:36,840 --> 00:47:40,900
sample side is a half times the number of times to the

712
00:47:40,900 --> 00:47:43,730
o point has a neighborhood one of these centres

713
00:47:43,750 --> 00:47:49,950
and then you do that mean field iteration mean shift iteration for the selected set

714
00:47:49,950 --> 00:47:51,190
of points

715
00:47:53,080 --> 00:47:54,810
so you get clustering for those

716
00:47:54,830 --> 00:47:56,950
the point

717
00:47:58,020 --> 00:48:01,730
so each of each of the corresponding to be

718
00:48:01,750 --> 00:48:03,340
and then what to do

719
00:48:03,360 --> 00:48:04,450
yes i the

720
00:48:04,460 --> 00:48:05,900
the main point

721
00:48:06,050 --> 00:48:09,900
by looking at the nearest representative j

722
00:48:09,910 --> 00:48:11,910
and assigning them to the cluster

723
00:48:11,930 --> 00:48:16,030
corresponds to the

724
00:48:16,050 --> 00:48:18,000
yes so that don't

725
00:48:18,010 --> 00:48:22,890
i mean shift iteration which is selected point is nearest its nearest to in

726
00:48:22,900 --> 00:48:23,850
and put it in the same

727
00:48:29,270 --> 00:48:33,260
and this is much more efficient because the mean shift iteration is done with what

728
00:48:33,260 --> 00:48:34,950
you point

729
00:48:34,970 --> 00:48:41,060
of the fact that you can actually cover the whole data set of your

730
00:48:42,370 --> 00:48:46,900
now i common bodies out the

731
00:48:46,910 --> 00:48:48,150
mean shift

732
00:48:48,530 --> 00:48:50,590
first of all

733
00:48:50,630 --> 00:48:54,830
you guaranteed to converge to peak but this final the peak is not guaranteed to

734
00:48:54,830 --> 00:48:57,520
find the peaks

735
00:48:57,950 --> 00:49:01,920
i don't know of any counterexamples or i don't know of any product it would

736
00:49:01,930 --> 00:49:03,800
not find all the peaks

737
00:49:03,840 --> 00:49:07,930
if start to it every data point but this is not the project to find

738
00:49:07,930 --> 00:49:11,460
all the water distribution so if you are after all the peaks of the distribution

739
00:49:11,800 --> 00:49:15,490
then this doesn't may not help

740
00:49:15,680 --> 00:49:17,930
but it will probably find clusters

741
00:49:17,940 --> 00:49:20,390
also there are many other variants

742
00:49:20,400 --> 00:49:24,330
so you can think of several variation how to make it faster or how to

743
00:49:24,330 --> 00:49:26,540
find the hierarchical clustering

744
00:49:26,560 --> 00:49:29,430
and so on

745
00:49:29,440 --> 00:49:30,670
again this small

746
00:49:30,680 --> 00:49:35,940
parameter here the order parameter that is used in the current

747
00:49:35,990 --> 00:49:38,010
so it's a very

748
00:49:38,020 --> 00:49:41,690
and the kernel shape but that tradition around

749
00:49:41,710 --> 00:49:43,810
or cement so

750
00:49:43,820 --> 00:49:46,000
it's very carson parameters

751
00:49:46,050 --> 00:49:47,450
it could

752
00:49:47,460 --> 00:49:50,730
you don't put a lot of prior information in

753
00:49:50,780 --> 00:49:53,400
in your clustering so don't have higher of

754
00:49:54,370 --> 00:49:58,500
strong expectations about how the clusters should look like

755
00:50:07,280 --> 00:50:09,560
what do you mean the two men

756
00:50:09,610 --> 00:50:13,030
so you you to define what is men

757
00:50:13,250 --> 00:50:17,730
and then yes if you think it's too many classes then you should decrease in

758
00:50:17,940 --> 00:50:21,330
by the way there is another issue that

759
00:50:22,220 --> 00:50:22,890
that not

760
00:50:22,900 --> 00:50:26,540
current at output because that took many but

761
00:50:26,560 --> 00:50:27,850
there could be

762
00:50:27,860 --> 00:50:30,280
see here are

763
00:50:30,290 --> 00:50:32,510
you may find two pieces of

764
00:50:32,560 --> 00:50:34,260
so there is another

765
00:50:34,410 --> 00:50:35,970
that you may

766
00:50:36,020 --> 00:50:39,900
or something else that you may need to do to decide when these two peaks

767
00:50:40,020 --> 00:50:44,210
one or or two different different clusters

768
00:50:44,530 --> 00:50:47,200
and so they have matter common

769
00:50:47,210 --> 00:50:49,070
so i went to see what the people

770
00:50:50,120 --> 00:50:52,650
how do you evaluate and

771
00:50:52,810 --> 00:50:56,630
and in this case probably you decided valley is not

772
00:50:57,630 --> 00:50:59,180
and so

773
00:50:59,190 --> 00:51:01,060
make everything the cost

774
00:51:02,340 --> 00:51:06,030
the question that i it is so you need to have

775
00:51:08,340 --> 00:51:10,620
besides the clusters

776
00:51:10,630 --> 00:51:26,710
OK here is another interesting that

777
00:51:26,720 --> 00:51:33,100
is clear or is very successful in feels like image segmentation

778
00:51:33,110 --> 00:51:35,430
because it's fun

779
00:51:35,450 --> 00:51:40,090
it's called gossip gaussian blurring mean shift

780
00:51:40,140 --> 00:51:42,720
so it's just like

781
00:51:42,770 --> 00:51:46,900
the simple mean shift described before except that

782
00:51:50,980 --> 00:51:53,720
in the mean shift iteration

783
00:51:53,740 --> 00:52:03,180
in each iteration before in each iteration was just looking for piece of this fixed

784
00:52:03,190 --> 00:52:04,980
density estimate

785
00:52:05,000 --> 00:52:07,750
in this particular case

786
00:52:09,030 --> 00:52:13,210
what happens is that the rest of mean shift to move the data to the

787
00:52:13,210 --> 00:52:16,220
new location so you should they don't want to be

788
00:52:16,230 --> 00:52:23,270
and spend their technically the density estimation is that this is the history estimation

789
00:52:23,280 --> 00:52:25,720
so you get the message

790
00:52:26,070 --> 00:52:31,640
and because the data moving towards the people that they will have steeper peak before

791
00:52:31,660 --> 00:52:36,670
and you take another understand the points move again to what's the new peaks

792
00:52:36,720 --> 00:52:42,370
then you really committed in the peaks grow even more money more than point converge

793
00:52:43,200 --> 00:52:45,860
towards each other very fast

794
00:52:45,900 --> 00:52:50,700
and actually lower the further down the slide to see that for certain distributions if

795
00:52:50,700 --> 00:52:55,020
you put some assumptions about the distribution being calcium they converge the cubic feet which

796
00:52:55,020 --> 00:52:57,060
is extremely fast

797
00:52:57,070 --> 00:52:59,630
means the intensity of the

798
00:52:59,640 --> 00:53:06,780
here i haven't seen any method of all sorts of examples subsampling the data although

799
00:53:06,820 --> 00:53:11,250
we can think of some but all the data points you are going to be

800
00:53:12,580 --> 00:53:14,870
so here you have to do with all the

801
00:53:14,880 --> 00:53:16,140
but it fast

802
00:53:16,160 --> 00:53:20,190
so it's just model numbers

803
00:53:20,210 --> 00:53:23,790
and i think that is is an efficient algorithm actually to do so it's not

804
00:53:23,790 --> 00:53:29,010
as bad as you'd expect to hear organised so you have to take a have

805
00:53:29,010 --> 00:53:32,730
to compute all these kernels for all the data points for

806
00:53:32,750 --> 00:53:42,460
every iteration and it's not as bad as it looks so it can be

807
00:53:42,470 --> 00:53:44,700
OK so this is called to be

808
00:53:44,790 --> 00:53:48,510
and it's not only five

809
00:53:48,560 --> 00:53:53,560
empirically found to work fairly well for cases where

810
00:53:53,580 --> 00:53:59,590
again the cluster size very uneven and there are many small clusters of interest and

811
00:53:59,590 --> 00:54:01,470
so on

812
00:54:01,820 --> 00:54:03,610
but there is an issue here

813
00:54:03,690 --> 00:54:06,350
you should not introduce

814
00:54:08,480 --> 00:54:11,150
and the reason why is is that because

815
00:54:12,780 --> 00:54:16,250
as this is it's very easy to prove otherwise

816
00:54:16,300 --> 00:54:18,080
one week

817
00:54:18,170 --> 00:54:19,810
yes and so

818
00:54:20,250 --> 00:54:23,210
this article needs to be stopped when the points have

819
00:54:24,460 --> 00:54:26,580
cluster just enough to baseball

820
00:54:27,860 --> 00:54:33,700
it therefore there clusters but not before the class started to move to each other

821
00:54:33,700 --> 00:54:35,280
are the facts meat

822
00:54:36,080 --> 00:54:44,260
now there is a vast mythology surrounding eating animals but all these methods fall under what i refer to as

823
00:54:44,790 --> 00:54:47,240
the three ends up justification

824
00:54:47,870 --> 00:54:50,040
and i'm curious if you can guess what they are

825
00:54:51,120 --> 00:54:52,990
meat eggs and dairy is over

826
00:54:55,220 --> 00:54:55,490
i mean

827
00:54:56,470 --> 00:55:00,660
my god that's really fast i didn't start typing this with groups before i heard

828
00:55:00,660 --> 00:55:02,830
all three of them it's like within second

829
00:55:06,660 --> 00:55:09,350
and necessary yeah i think this is the fastest group

830
00:55:12,010 --> 00:55:14,260
say okay you get you get the points are saying

831
00:55:15,660 --> 00:55:16,280
i don't

832
00:55:16,720 --> 00:55:21,540
exercise with about that and people over the years and people always know the answers

833
00:55:22,080 --> 00:55:25,560
what do you think we always get and i'm not even people who read my blog

834
00:55:27,870 --> 00:55:30,540
and we've heard it we heard this all before r

835
00:55:31,010 --> 00:55:37,040
these same arguments have been used to justify violent practices throughout the course of human history

836
00:55:50,350 --> 00:55:53,830
now let's just briefly look at each of these myths turn

837
00:55:54,620 --> 00:55:55,120
he is

838
00:55:56,560 --> 00:56:02,740
what we call normal is really simply the beliefs and behaviors the dominant culture

839
00:56:03,160 --> 00:56:03,580
it is

840
00:56:04,120 --> 00:56:05,490
the current stick norm

841
00:56:06,370 --> 00:56:09,080
and parties and has a social norm is so

842
00:56:09,520 --> 00:56:13,040
in french but it's virtually impossible to seamlessly

843
00:56:13,450 --> 00:56:15,560
step outside of the current stick box

844
00:56:16,080 --> 00:56:17,220
stepping out of the box today

845
00:56:18,520 --> 00:56:22,910
to help you step outside the current stick box and what to do another exercise

846
00:56:23,390 --> 00:56:25,720
i want you to imagine again that are

847
00:56:26,410 --> 00:56:30,640
are you winger your house has just told you that you are eating a golden retriever r

848
00:56:31,160 --> 00:56:34,620
but now imagine that you tell you how how you feel

849
00:56:35,580 --> 00:56:38,560
in she replies by telling you not to worry

850
00:56:39,040 --> 00:56:40,010
i don't feel bad

851
00:56:40,660 --> 00:56:41,810
because the dog

852
00:56:42,080 --> 00:56:42,620
good life

853
00:56:43,470 --> 00:56:50,020
she was able to run away and she formed friendships with other golden retrievers and even some people

854
00:56:51,060 --> 00:56:52,180
before she was killed

855
00:56:52,680 --> 00:56:53,560
at six months old

856
00:56:54,740 --> 00:56:56,760
doesn't feel any better eating the golden retriever

857
00:56:59,080 --> 00:57:02,780
i had people sometimes say no another friend misheard

858
00:57:03,410 --> 00:57:03,930
feel worse

859
00:57:05,740 --> 00:57:06,810
ask yourself

860
00:57:07,790 --> 00:57:15,410
i would be opposed to a perfectly healthy golden retriever being killed simply because people like the way her

861
00:57:15,910 --> 00:57:16,870
legs taste

862
00:57:18,490 --> 00:57:21,790
you might not be opposed to the exact same thing

863
00:57:22,260 --> 00:57:24,040
being done by somebody else

864
00:57:25,390 --> 00:57:28,120
carnism has a social norms is so

865
00:57:28,540 --> 00:57:35,160
in french blinds us to the fact that humane need is a complete contradiction

866
00:57:35,620 --> 00:57:36,200
in terms

867
00:57:36,950 --> 00:57:38,810
humane meat is a man

868
00:57:39,390 --> 00:57:43,330
it is a mere constructed by those in the business violence

869
00:57:43,990 --> 00:57:49,290
to appeal to those above who would ordinarily never support such violence

870
00:57:51,680 --> 00:57:52,890
eating meat is natural

871
00:57:54,160 --> 00:58:02,680
well what we call natural is simply the dominant cultures interpretation of history it refers not to human history

872
00:58:03,280 --> 00:58:03,780
but to

873
00:58:04,240 --> 00:58:05,640
current stick history

874
00:58:06,310 --> 00:58:08,410
it references not are

875
00:58:08,850 --> 00:58:10,620
fruit eating investors

876
00:58:11,310 --> 00:58:11,790
but there are

877
00:58:13,140 --> 00:58:14,080
eating descendants

878
00:58:15,010 --> 00:58:15,870
in other words

879
00:58:16,350 --> 00:58:21,660
through partners and we only look as far back in history as we need to do to justify

880
00:58:22,200 --> 00:58:24,280
current artistic practices

881
00:58:25,490 --> 00:58:26,600
and to be fair

882
00:58:28,970 --> 00:58:31,220
and infanticide are are really

883
00:58:33,290 --> 00:58:34,660
and therefore it natural

884
00:58:35,410 --> 00:58:36,290
the animals

885
00:58:36,930 --> 00:58:42,810
and yet we don't invoke the longevity of these practices have the justification for them today

886
00:58:44,140 --> 00:58:46,990
in the words of the whole have control

887
00:58:47,780 --> 00:58:51,330
do we really want to use the behavior of the neanderthals

888
00:58:52,180 --> 00:58:55,660
as the yardstick by which to measure are current moral choices

889
00:58:58,060 --> 00:58:59,470
and finally we need needed

890
00:59:02,100 --> 00:59:10,370
when we we call necessary simply what is necessary to maintain the dominant culture to maintain the artistic status quo

891
00:59:11,060 --> 00:59:14,640
and here i'm going to let a picture speaks for itself

892
00:59:15,930 --> 00:59:16,870
can you see in the back

893
00:59:30,870 --> 00:59:31,390
get the idea

894
00:59:35,790 --> 00:59:36,450
are related

895
00:59:37,410 --> 00:59:38,180
is the protein

896
00:59:39,010 --> 00:59:42,780
you may have heard this before r it's one of the most entrenched vanessa me

897
00:59:42,930 --> 00:59:44,660
but it is a complete man

898
00:59:45,370 --> 00:59:45,910
in fact

899
00:59:46,510 --> 00:59:49,510
did you know that you could be strong enough to lift the car

900
00:59:49,990 --> 00:59:53,660
even if you've never been announced animal protein in your life

901
00:59:57,950 --> 00:59:58,560
i'm not kidding

902
01:00:01,680 --> 01:00:03,620
looking back on my own

903
01:00:05,970 --> 01:00:11,740
witnessing the truth about the animals i could see how the mets had a tremendous influence on me

904
01:00:12,390 --> 01:00:13,620
as they do on all the us

905
01:00:14,120 --> 01:00:19,620
i couldn't closed the gap in my consciousness until i was ready to make the

906
01:00:19,620 --> 01:00:22,600
behavioral change that would inevitably follow

907
01:00:23,700 --> 01:00:27,240
and i couldn't make change until i felt safe enough

908
01:00:27,660 --> 01:00:28,140
to do so

909
01:00:28,950 --> 01:00:31,510
i had a lot of fears aren't concerns

910
01:00:32,080 --> 01:00:32,760
what i

911
01:00:33,410 --> 01:00:33,870
get stuck

912
01:00:34,560 --> 01:00:38,740
what i go broke buying expensive vegetarian foods

913
01:00:39,390 --> 01:00:40,260
what i have to

914
01:00:40,720 --> 01:00:43,830
subsist on a diet coke fluent cardboard

915
01:00:44,780 --> 01:00:49,410
in this last issue was really a serious concern of mine because two of my

916
01:00:49,410 --> 01:00:52,370
greatest pleasures in life are cooking and eating

917
01:00:53,870 --> 01:01:00,740
and what about my relationship with my father was and he is today a charter captain my father's professional fishermen

918
01:01:01,830 --> 01:01:05,310
my uncle has been an avid hunter his entire life

919
01:01:06,330 --> 01:01:10,020
my jewish stepmother made the best marked evolves

920
01:01:10,580 --> 01:01:11,560
this side create

921
01:01:13,120 --> 01:01:14,120
italian now

922
01:01:14,890 --> 01:01:15,580
arrived on

923
01:01:16,240 --> 01:01:18,540
stopping us full articles on you more and are

924
01:01:18,540 --> 01:01:20,460
so a wide variety of

925
01:01:20,950 --> 01:01:22,270
of different problems here

926
01:01:27,060 --> 01:01:29,600
interesting seems like some of them are missing anyway

927
01:01:31,790 --> 01:01:33,420
maybe the rover here we go

928
01:01:34,090 --> 01:01:36,750
yes israel was one from the israeli air force

929
01:01:38,160 --> 01:01:38,640
i forget

930
01:01:39,780 --> 01:01:45,510
forestry planning problem i think it was africa with the shell oil company all kinds of different problems

931
01:01:47,320 --> 01:01:49,130
so i make a regression model

932
01:01:49,930 --> 01:01:53,570
end so the data that i just showed you as a bunch a valuesof

933
01:01:54,240 --> 01:01:58,970
the number of iterations which other no by number of constraints which are the nobody

934
01:01:58,980 --> 01:02:01,430
and the number of variables that not by end

935
01:02:01,850 --> 01:02:06,940
and those problems does the number of iterations computed using the parametric self dual simplex methods

936
01:02:07,450 --> 01:02:08,730
has programmed by me

937
01:02:10,430 --> 01:02:11,930
so i make a model here is the model

938
01:02:13,970 --> 01:02:15,120
when i say that the

939
01:02:15,550 --> 01:02:16,760
number of iterations

940
01:02:17,370 --> 01:02:20,960
some constant some positive constant which already to the alpha

941
01:02:21,870 --> 01:02:24,080
times the some employees and

942
01:02:24,570 --> 01:02:25,840
to the big power beta

943
01:02:26,320 --> 01:02:29,130
for some data and often better my unknowns here

944
01:02:30,580 --> 01:02:34,820
find the best approximation and what we do is we take the logarithm of both

945
01:02:34,820 --> 01:02:38,130
sides and we say that the log ti is equal to

946
01:02:38,670 --> 01:02:43,890
alpha times log to that's from not one plus data times larger than plus and

947
01:02:44,210 --> 01:02:46,940
that's that's when they are plus some absolute

948
01:02:49,140 --> 01:02:51,560
the absence not just random here

949
01:02:52,370 --> 01:02:55,940
the data is perfect i implemented the algorithm i counted the iterations

950
01:02:57,050 --> 01:02:57,900
but we don't really know

951
01:02:58,630 --> 01:02:59,490
what the world of

952
01:03:00,340 --> 01:03:01,740
i mean in some sense it's random

953
01:03:02,200 --> 01:03:04,860
those problems are drawn from the world

954
01:03:05,460 --> 01:03:06,710
i've real problems

955
01:03:07,200 --> 01:03:09,240
and i don't know what the probability distribution

956
01:03:09,880 --> 01:03:11,980
and the world problems is so i don't really know

957
01:03:12,480 --> 01:03:15,270
with the probability distribution is on this up so on

958
01:03:17,480 --> 01:03:19,420
there is this is our regression model

959
01:03:21,010 --> 01:03:22,060
and i have a budget data

960
01:03:22,830 --> 01:03:24,750
so we set this up like this

961
01:03:25,260 --> 01:03:27,680
i got all my data here are gonna call it be

962
01:03:28,670 --> 01:03:32,660
i've got my coefficients alpha and beta i'm call their acts

963
01:03:33,740 --> 01:03:34,850
because that's the way i am

964
01:03:35,540 --> 01:03:36,590
like linear programming

965
01:03:37,340 --> 01:03:38,450
variables have to be x

966
01:03:38,990 --> 01:03:43,810
statisticians dissolve differently i think they matrix is called that's very confusing to me

967
01:03:45,810 --> 01:03:47,010
he any matrix is

968
01:03:47,390 --> 01:03:51,190
this is the data but in my appears in my model it has

969
01:03:51,920 --> 01:03:56,440
log to for the first thing all the time and the and so that's the

970
01:03:56,440 --> 01:04:00,410
same constant everywhere in this column and then we have larger than one percent to

971
01:04:01,200 --> 01:04:03,740
sorry in one thousand one and two percent and so on

972
01:04:04,240 --> 01:04:08,940
so the the second column varies from problem to problem and then get is absolutely

973
01:04:08,940 --> 01:04:10,450
different so this is my model

974
01:04:10,870 --> 01:04:13,560
be equals x plus epsilon

975
01:04:13,920 --> 01:04:18,200
the problem is defined x that minimizes the abseil on in some sense i put

976
01:04:18,280 --> 01:04:21,310
minimizing quotes because there a variety of ways of doing this

977
01:04:28,410 --> 01:04:29,580
one way is to do

978
01:04:30,580 --> 01:04:32,160
standard least squares

979
01:04:32,850 --> 01:04:34,480
every statisticians best friend

980
01:04:35,910 --> 01:04:41,170
so we use least squares these were taking the euclidean distance the sum of the squares

981
01:04:41,870 --> 01:04:43,170
square root like

982
01:04:44,320 --> 01:04:50,310
so least squares is the square error the euclidean distance will find finally acts that minimizes

983
01:04:51,680 --> 01:04:52,680
some of the squares

984
01:04:53,970 --> 01:04:55,730
we can solve this problem with calculus

985
01:04:56,850 --> 01:04:57,840
just like we could with the me

986
01:04:58,970 --> 01:04:59,430
it's kind of

987
01:04:59,890 --> 01:05:01,080
useful to go through this

988
01:05:01,610 --> 01:05:02,850
little calculation

989
01:05:04,480 --> 01:05:06,730
so function we differentiate is

990
01:05:07,840 --> 01:05:11,840
some of squares which are running out of its gory detail here

991
01:05:13,340 --> 01:05:18,130
and differentiate this this is multi-parameter multidimensional so get

992
01:05:19,870 --> 01:05:21,450
x one x two et cetera

993
01:05:21,900 --> 01:05:24,060
actually my real problem i just have often baited so

994
01:05:24,470 --> 01:05:25,210
there's really only two

995
01:05:27,280 --> 01:05:27,920
variables and the

996
01:05:28,690 --> 01:05:32,500
problem was solved in general i have a lot to these variables looked at them

997
01:05:33,100 --> 01:05:34,640
so i differentiate this at

998
01:05:35,530 --> 01:05:36,840
with respect each other variables

999
01:05:38,630 --> 01:05:41,950
said equals zero and my i surgical the zero that's gonna give me the thing

1000
01:05:41,950 --> 01:05:44,690
that's the analog means so put a bar over it

1001
01:05:45,300 --> 01:05:48,310
so what i've solve this equation now give me

1002
01:05:50,080 --> 01:05:52,660
the least squares solution which are denoted by x barr

1003
01:05:53,610 --> 01:05:55,730
and it's a vector so x one b objects

1004
01:05:58,070 --> 01:05:58,320
what are

1005
01:06:05,220 --> 01:06:05,840
okay so

1006
01:06:09,060 --> 01:06:09,910
rearrange this

1007
01:06:10,560 --> 01:06:16,080
equations here so i'm certain signals are i can do that too i can divide both sides that goes away

1008
01:06:16,990 --> 01:06:17,280
and so

1009
01:06:18,270 --> 01:06:22,990
on the whole with the summer be i times they ikea

1010
01:06:24,070 --> 01:06:25,330
and has a minus sign

1011
01:06:26,700 --> 01:06:27,860
which is music and put it

1012
01:06:29,690 --> 01:06:31,740
on the other side of the equation if you like

1013
01:06:33,360 --> 01:06:35,140
and they part double sum

1014
01:06:35,750 --> 01:06:37,760
and double minus which makes it a plus

1015
01:06:38,380 --> 01:06:39,510
o and i j

1016
01:06:40,010 --> 01:06:40,650
they ikea

1017
01:06:41,260 --> 01:06:42,390
x jabar

1018
01:06:43,180 --> 01:06:46,540
so double sum ikea i j x j bar

1019
01:06:49,630 --> 01:06:50,500
end so

1020
01:06:51,700 --> 01:06:53,530
going back to matrix notation here

1021
01:06:58,400 --> 01:07:02,220
because i got a i can be i i really want have that i'd be

1022
01:07:02,220 --> 01:07:05,430
happy if this were taken by but it's not it's actually okay

1023
01:07:05,970 --> 01:07:10,830
so i think that this is actually the transpose matrix times the be vector so that's that's

1024
01:07:11,510 --> 01:07:12,670
this double

1025
01:07:13,110 --> 01:07:18,700
some if you think about it again i would like to have this be eight kay i but it's a-okay

1026
01:07:19,200 --> 01:07:22,040
story can will be kay i i j

1027
01:07:24,060 --> 01:07:25,950
so there would then be able

1028
01:07:25,950 --> 01:07:31,020
today we will discuss

1029
01:07:31,060 --> 01:07:37,220
what we call uniform

1030
01:07:40,360 --> 01:07:43,790
what is uniform circular motion

1031
01:07:46,220 --> 01:07:48,400
goes around in circles

1032
01:07:48,410 --> 01:07:52,190
has radius r

1033
01:07:52,200 --> 01:07:54,040
the objective here

1034
01:07:54,090 --> 01:07:57,520
this is the velocity

1035
01:07:57,530 --> 01:07:59,350
the vector

1036
01:08:01,850 --> 01:08:06,960
and later in time when the object is here

1037
01:08:07,970 --> 01:08:09,920
the velocity has changed

1038
01:08:09,940 --> 01:08:12,790
the dispute has not changed

1039
01:08:12,870 --> 01:08:14,230
we introduce

1040
01:08:14,930 --> 01:08:17,960
what we call the period

1041
01:08:18,000 --> 01:08:19,900
courses in seconds

1042
01:08:19,910 --> 01:08:22,790
which is the time to go around once

1043
01:08:22,810 --> 01:08:24,950
we introduce

1044
01:08:24,960 --> 01:08:26,990
the frequency s

1045
01:08:27,000 --> 01:08:30,650
which we call frequency

1046
01:08:30,700 --> 01:08:32,880
which is the number

1047
01:08:32,900 --> 01:08:35,630
of rotations per second

1048
01:08:35,640 --> 01:08:36,940
and so do you need

1049
01:08:36,960 --> 01:08:40,810
i e the second minus one the most

1050
01:08:40,990 --> 01:08:42,700
is call it hurts

1051
01:08:42,710 --> 01:08:44,490
so frequency

1052
01:08:44,540 --> 01:08:48,980
is one divided by t

1053
01:08:48,990 --> 01:08:51,680
we also introduce

1054
01:08:51,690 --> 01:08:54,220
angular velocity

1055
01:08:56,040 --> 01:08:57,580
which we call

1056
01:09:01,310 --> 01:09:05,580
the angular velocity means not how many meters per second

1057
01:09:05,720 --> 01:09:09,000
but how many radiance per second

1058
01:09:09,650 --> 01:09:11,010
since there are

1059
01:09:11,060 --> 01:09:12,150
two pi

1060
01:09:13,520 --> 01:09:15,580
in one city conference

1061
01:09:15,720 --> 01:09:17,310
one full circle

1062
01:09:17,320 --> 01:09:19,680
and it takes three seconds

1063
01:09:19,730 --> 01:09:21,400
to go around once

1064
01:09:21,440 --> 01:09:23,860
it is immediately obvious that omega

1065
01:09:24,850 --> 01:09:26,050
two pi

1066
01:09:26,080 --> 01:09:27,810
a divided by t

1067
01:09:27,860 --> 01:09:29,890
this is something that i would like you

1068
01:09:31,330 --> 01:09:32,690
OK go

1069
01:09:32,800 --> 01:09:33,930
close to pi

1070
01:09:34,020 --> 01:09:38,350
five i t

1071
01:09:38,360 --> 01:09:39,830
two pi radians

1072
01:09:39,880 --> 01:09:42,250
in capital t seconds

1073
01:09:43,640 --> 01:09:47,290
speed v

1074
01:09:47,300 --> 01:09:50,370
is of course this conference two pi r

1075
01:09:50,380 --> 01:09:54,490
divided by the time to go around once since two pi divided by t is

1076
01:09:55,720 --> 01:09:57,390
you can also write for these

1077
01:09:57,460 --> 01:09:58,920
omega are

1078
01:09:58,930 --> 01:10:00,600
this is also something

1079
01:10:00,610 --> 01:10:02,230
i want you to remember

1080
01:10:02,240 --> 01:10:03,870
these two things

1081
01:10:03,920 --> 01:10:06,860
i really want to know

1082
01:10:06,870 --> 01:10:08,330
the speed

1083
01:10:08,360 --> 01:10:09,860
is not changing

1084
01:10:09,870 --> 01:10:12,150
but the velocity vector is changing

1085
01:10:13,450 --> 01:10:17,990
there must be an acceleration that is non negotiable

1086
01:10:18,000 --> 01:10:21,240
you can derive all that acceleration

1087
01:10:21,300 --> 01:10:25,410
must be in terms of magnitude and in terms of direction is about five six

1088
01:10:25,410 --> 01:10:26,860
minutes derivation

1089
01:10:26,880 --> 01:10:28,700
you'll find it in your book

1090
01:10:28,710 --> 01:10:32,410
i have decided to give you the results that you read up on the book

1091
01:10:32,460 --> 01:10:35,880
so that we can more talk about the physics rather than on

1092
01:10:35,930 --> 01:10:37,800
the derivation

1093
01:10:38,890 --> 01:10:41,340
acceleration that is necessary

1094
01:10:41,350 --> 01:10:43,900
to make the change in the velocity vector

1095
01:10:43,910 --> 01:10:45,120
is always

1096
01:10:45,170 --> 01:10:48,240
pointing towards the center of the circle

1097
01:10:48,250 --> 01:10:50,630
we call it centripetal

1098
01:10:56,570 --> 01:11:00,050
pointing towards the centre

1099
01:11:00,130 --> 01:11:01,020
and here

1100
01:11:02,190 --> 01:11:03,950
also pointing towards the center

1101
01:11:03,970 --> 01:11:05,890
it's vector

1102
01:11:05,910 --> 01:11:07,330
and the

1103
01:11:08,950 --> 01:11:11,660
of the centripetal acceleration

1104
01:11:11,710 --> 01:11:15,320
called the squared divided by are which is this week

1105
01:11:15,370 --> 01:11:17,670
and therefore it also omega

1106
01:11:17,700 --> 01:11:18,630
square are

1107
01:11:18,830 --> 01:11:21,590
so now we have

1108
01:11:21,660 --> 01:11:23,130
three equations

1109
01:11:23,140 --> 01:11:24,690
and those are the only three

1110
01:11:24,700 --> 01:11:26,640
you really would like to

1111
01:11:30,000 --> 01:11:32,610
we can have a simple example

1112
01:11:32,840 --> 01:11:35,730
let's have a

1113
01:11:35,780 --> 01:11:41,120
vacuum cleaner which has a rotor inside which scoops the air out in whichever way

1114
01:11:41,120 --> 01:11:42,320
you look at it

1115
01:11:42,370 --> 01:11:46,530
let's assume that the vacuum cleaner these groups have radius are

1116
01:11:46,540 --> 01:11:48,500
of about ten centimeters

1117
01:11:48,550 --> 01:11:52,520
and that it goes around six hundred revolutions per minute

1118
01:11:52,570 --> 01:11:55,420
six hundred rt

1119
01:11:55,470 --> 01:11:59,890
six hundred rpm will translate into frequency f

1120
01:11:59,900 --> 01:12:02,180
of ten hertz

1121
01:12:02,190 --> 01:12:06,960
so it would translate into periods going around

1122
01:12:06,980 --> 01:12:08,340
in one tense

1123
01:12:08,390 --> 01:12:10,210
of the second

1124
01:12:10,220 --> 01:12:12,090
so omega

1125
01:12:12,100 --> 01:12:14,290
angular velocity

1126
01:12:14,330 --> 01:12:15,500
which just two pi

1127
01:12:15,520 --> 01:12:16,970
divided by t

1128
01:12:16,980 --> 01:12:19,090
is then approximately

1129
01:12:19,140 --> 01:12:20,690
sixty three

1130
01:12:23,720 --> 01:12:25,190
a second

1131
01:12:27,290 --> 01:12:29,850
speedy vehicles omega are

1132
01:12:29,900 --> 01:12:31,060
is then roughly

1133
01:12:31,070 --> 01:12:33,920
six point three meters per second

1134
01:12:37,460 --> 01:12:41,000
centripetal acceleration and that's really my goal

1135
01:12:41,020 --> 01:12:42,900
the centripetal acceleration

1136
01:12:42,950 --> 01:12:45,210
would be only square are

1137
01:12:45,220 --> 01:12:48,680
or if you prefer you can take the square over are you will get the

1138
01:12:48,680 --> 01:12:50,230
same answer of course

1139
01:12:50,250 --> 01:12:51,440
you will find

1140
01:12:51,450 --> 01:12:53,620
that is about four hundred

1141
01:12:54,400 --> 01:12:56,570
the second square

1142
01:12:56,580 --> 01:13:01,050
and that's huge that is forty times the acceleration due to gravity

1143
01:13:01,070 --> 01:13:02,290
it's phenomenal

1144
01:13:02,310 --> 01:13:04,320
acceleration simple

1145
01:13:04,330 --> 01:13:06,520
vacuum cleaner

1146
01:13:06,570 --> 01:13:10,970
notice that the acceleration the centripetal acceleration

1147
01:13:11,040 --> 01:13:12,420
is linear in are

1148
01:13:12,430 --> 01:13:16,500
i don't think that is inversely proportional which are that's a mistake

1149
01:13:16,550 --> 01:13:18,720
because the itself

1150
01:13:18,730 --> 01:13:21,370
it is the function of our if you're sitting here

1151
01:13:21,380 --> 01:13:23,600
then your velocity would be lower

1152
01:13:23,650 --> 01:13:24,910
since omega

1153
01:13:24,920 --> 01:13:26,780
is the same forty

1154
01:13:29,040 --> 01:13:33,220
you really have to look at this equation and you see that the centripetal acceleration

1155
01:13:33,230 --> 01:13:35,010
is proportional which are

1156
01:13:35,020 --> 01:13:36,440
therefore if you were

1157
01:13:36,510 --> 01:13:40,680
this were this which was rotating and you're at the centre of the disc

1158
01:13:40,970 --> 01:13:43,490
centripetal acceleration would be zero

1159
01:13:43,540 --> 01:13:45,800
and if you were to walk out further out

1160
01:13:45,850 --> 01:13:48,820
it would increase

1161
01:13:48,820 --> 01:13:51,420
and we look at the probability of being there

1162
01:13:51,440 --> 01:13:54,610
and then the probability to actually go to i depends on the degree of that

1163
01:13:54,610 --> 01:13:56,670
note the out degree

1164
01:13:56,710 --> 01:14:00,230
right so the we divide that one over the out degree because we pick an

1165
01:14:00,230 --> 01:14:05,630
arbitrary outgoing and then this is the part that comes from the random parts of

1166
01:14:05,630 --> 01:14:09,740
with one month of we pick a random node and then n here just denotes

1167
01:14:09,740 --> 01:14:14,440
the total number of web pages so probably one over and that we choose this

1168
01:14:14,440 --> 01:14:17,170
particular web page i right

1169
01:14:17,190 --> 01:14:21,750
so then it doesn't matter where we were coming from basically you know if we

1170
01:14:21,750 --> 01:14:25,180
just decide to make a teleportation

1171
01:14:25,190 --> 01:14:28,750
you know the woman's after we do that and then with probability one over and

1172
01:14:28,750 --> 01:14:31,500
we picked that particular page no matter where we've been before

1173
01:14:31,510 --> 01:14:35,530
OK we can just compile these into this p matrix now

1174
01:14:35,540 --> 01:14:36,820
i just collecting

1175
01:14:36,830 --> 01:14:39,130
you know these terms here so it's

1176
01:14:40,460 --> 01:14:43,010
times that one month of over and

1177
01:14:43,030 --> 01:14:46,070
if there is no link between

1178
01:14:47,130 --> 01:14:49,060
OK and then

1179
01:14:51,170 --> 01:14:55,410
there's something missing

1180
01:14:59,500 --> 01:15:05,950
so basically there are two ways now

1181
01:15:07,000 --> 01:15:11,890
to compute the pagerank right we really want to do that we will actually want

1182
01:15:11,890 --> 01:15:17,810
to compute it one way is the naive approach which is we simulate the random

1183
01:15:17,810 --> 01:15:20,820
walk for sufficiently long time

1184
01:15:21,750 --> 01:15:23,400
and we just count

1185
01:15:23,420 --> 01:15:26,430
how often we into particular page

1186
01:15:26,440 --> 01:15:28,180
divided by

1187
01:15:28,190 --> 01:15:31,460
you know the number of steps to we made so that's the fraction of time

1188
01:15:31,460 --> 01:15:34,300
that was spent at a particular page

1189
01:15:34,320 --> 01:15:38,600
and as t goes to infinity that hopefully converges to pu i mean that is

1190
01:15:38,600 --> 01:15:39,780
actually the case

1191
01:15:39,800 --> 01:15:43,320
the way we set up the markov chain since we make random

1192
01:15:43,330 --> 01:15:48,580
jumps from one page to every other page with some probability you know this is

1193
01:15:49,680 --> 01:15:54,170
an ergodic markov chain so this is actually this lecture tour OK so that's one

1194
01:15:54,170 --> 01:15:57,680
way we can do that so imagine you know will go crawls the web and

1195
01:15:57,700 --> 01:16:00,790
they could no basically tried to simulate this process

1196
01:16:01,600 --> 01:16:04,470
four just you know a long time to do i don't know you know several

1197
01:16:04,470 --> 01:16:07,800
billion steps and then they just look you know what

1198
01:16:07,980 --> 01:16:14,730
these numbers here and they could just compute pagerank from that what is more efficient

1199
01:16:15,250 --> 01:16:21,640
is the so-called power method because what we want to compute the principal eigen vector

1200
01:16:21,640 --> 01:16:25,760
right of this stohastic matrix p

1201
01:16:25,790 --> 01:16:28,050
and that is by using

1202
01:16:28,440 --> 01:16:31,120
you know exactly the iterations that i've shown before

1203
01:16:31,120 --> 01:16:33,140
it is taking some initial

1204
01:16:33,150 --> 01:16:39,470
probability distribution over the pages and multiplying it by through p and then doing it

1205
01:16:39,470 --> 01:16:41,350
again and again and again

1206
01:16:41,360 --> 01:16:47,910
right we just always modify with peace with increasing powers and we look at

1207
01:16:48,650 --> 01:16:52,300
basically the limit as n goes to infinity so it turns out that for the

1208
01:16:52,300 --> 01:16:57,540
web i think talking to google people i think that you know she something like

1209
01:16:57,540 --> 01:16:58,850
around a hundred

1210
01:16:58,850 --> 01:17:06,380
is often sufficient with the web graph do a finite number a relatively small number

1211
01:17:06,390 --> 01:17:12,370
of iterations with the power method you're very close to the stationary distribution the convergence

1212
01:17:12,370 --> 01:17:17,190
speed actually depends actually on how you choose i because that's kind of the controls

1213
01:17:17,190 --> 01:17:23,610
the mixing properties of this markov chain right being this random teleportation step if that

1214
01:17:23,610 --> 01:17:27,390
is large then it makes it very well right because we can jump from everywhere

1215
01:17:27,390 --> 01:17:31,340
to everywhere with very high probability if we make that very small then we only

1216
01:17:31,340 --> 01:17:35,910
allowed to basically follow was sorry if it's actually the weights defined if we set

1217
01:17:35,950 --> 01:17:38,390
close to one for one month of small

1218
01:17:38,410 --> 01:17:42,880
then we always have to follow the link structure and then it's just more difficult

1219
01:17:42,910 --> 01:17:45,010
in some places might be

1220
01:17:45,180 --> 01:17:49,960
almost disconnected and the mixing process properties are not

1221
01:17:49,970 --> 01:17:55,450
OK so so that's the way of one computer

1222
01:17:55,470 --> 01:17:59,060
many questions about this

1223
01:17:59,070 --> 01:18:05,060
the global school

1224
01:18:05,060 --> 01:18:09,540
so in the simplest case i mean like google one point o version what you

1225
01:18:09,560 --> 01:18:12,600
do is you would use the boolean retrieval model

1226
01:18:12,620 --> 01:18:13,760
these before

1227
01:18:13,790 --> 01:18:16,100
it defines the set

1228
01:18:16,110 --> 01:18:20,150
and then within that said you apply the global rank

1229
01:18:20,170 --> 01:18:23,440
so the nice thing about that is

1230
01:18:23,460 --> 01:18:28,760
william retrieval is very efficient is kind of very transparent in some sense right so

1231
01:18:28,760 --> 01:18:33,220
people you have have an idea what the results are really means how you how

1232
01:18:33,220 --> 01:18:34,670
you how you got it

1233
01:18:34,690 --> 01:18:40,120
and then use that scored the and this core doesn't depend on the query so

1234
01:18:40,120 --> 01:18:44,690
that's very convenient for google because what does it mean when they can precompute that

1235
01:18:44,690 --> 01:18:48,240
score right it's a global score they can do that whatever every two weeks so

1236
01:18:48,240 --> 01:18:58,750
the other

1237
01:18:58,860 --> 01:19:10,870
the e

1238
01:19:26,500 --> 01:19:31,870
in the following

1239
01:19:46,200 --> 01:19:49,100
the first

1240
01:19:51,500 --> 01:19:54,700
the usual

1241
01:19:55,110 --> 01:19:57,100
one of the

1242
01:19:57,230 --> 01:19:59,950
so that was that

1243
01:20:02,070 --> 01:20:04,920
there many places

1244
01:20:04,930 --> 01:20:08,510
there also the from the

1245
01:20:08,710 --> 01:20:10,940
she she

1246
01:20:10,950 --> 01:20:13,630
thank you

1247
01:20:13,770 --> 01:20:22,780
i want to thank professor pisanski and thank you for your kind invitation

1248
01:20:22,880 --> 01:20:24,940
to have me speak today

1249
01:20:25,010 --> 01:20:30,310
i'm going to speak as he said about the many faces of symmetry

1250
01:20:30,330 --> 01:20:33,190
in the work of MC asher symmetry

1251
01:20:33,200 --> 01:20:35,050
the word that

1252
01:20:35,300 --> 01:20:39,310
as many many things both personal and technical

1253
01:20:39,430 --> 01:20:47,560
and the work of the dutch graphical artist MC is a wonderful article to illustrate

1254
01:20:47,560 --> 01:20:55,230
these many different meanings symmetry is found and used in science and mathematics in order

1255
01:20:55,240 --> 01:20:56,740
to other aspects

1256
01:20:57,310 --> 01:21:00,350
and i'm hoping that i can cover many of these

1257
01:21:00,360 --> 01:21:05,460
and obviously i'm not going to cover all aspects of symmetry but i hope that

1258
01:21:05,460 --> 01:21:10,270
some of these ideas that was created through actual will get you thinking about still

1259
01:21:11,620 --> 01:21:20,700
we have shown the screen shot is that graphic artist who was born in eighteen

1260
01:21:20,700 --> 01:21:24,330
ninety eight and he died in nineteen seventy two

1261
01:21:24,380 --> 01:21:29,890
and his work has been extremely popular with the public

1262
01:21:29,960 --> 01:21:33,170
and especially with scientists and mathematicians

1263
01:21:33,180 --> 01:21:36,250
he's pretty much ignored by the for

1264
01:21:37,220 --> 01:21:39,260
world through the academy

1265
01:21:39,300 --> 01:21:48,100
his work has been used because he himself was interested in depicting

1266
01:21:48,120 --> 01:21:50,990
abstract concepts in his art

1267
01:21:51,000 --> 01:21:53,350
and so in really

1268
01:21:53,820 --> 01:21:57,880
mean can you think when you look at his art so i thought maybe you'll

1269
01:21:57,890 --> 01:22:00,520
discover some new things in his art today

1270
01:22:00,600 --> 01:22:06,840
it's is also true that was done in nineteen forty three and i especially like

1271
01:22:06,840 --> 01:22:10,020
this because those piercing eyes

1272
01:22:10,070 --> 01:22:11,740
i invite you

1273
01:22:11,750 --> 01:22:14,270
to look more closely

1274
01:22:14,280 --> 01:22:16,980
so now to symmetry

1275
01:22:17,040 --> 01:22:22,900
the first is that the symmetry is the one i think that is the most

1276
01:22:24,060 --> 01:22:26,480
i think most everyone will agree

1277
01:22:26,500 --> 01:22:30,740
that's quite symmetry has to do with balance

1278
01:22:30,790 --> 01:22:38,680
and usually when people talk of something being symmetric that balance is one of your

1279
01:22:38,750 --> 01:22:42,290
symmetry to perfect mirror-image halves

1280
01:22:42,380 --> 01:22:44,310
matching each other

1281
01:22:44,330 --> 01:22:45,350
this is a very

1282
01:22:45,400 --> 01:22:51,000
reprint of vasher nude reclining chair it was probably done when he was an art

1283
01:22:51,000 --> 01:22:56,260
student and it was probably done as some kind of an exercise in symmetry it

1284
01:22:56,260 --> 01:22:59,000
has absolutely perfect symmetry mirror symmetry

1285
01:22:59,390 --> 01:23:01,590
and of course it's very static

1286
01:23:01,640 --> 01:23:06,980
and that one of the aspects of mirror symmetry whips scuse me among the wrong

1287
01:23:08,850 --> 01:23:15,140
there's another thing we actually do it all again you can see it has perfect

1288
01:23:15,140 --> 01:23:18,880
mirror symmetry the trees and the schools and the birds

1289
01:23:19,110 --> 01:23:27,090
perfectly symmetric with respect to a vertical mill line right here at the centre

1290
01:23:27,370 --> 01:23:32,930
there's another kind of symmetry of matching has been is much more dynamic

1291
01:23:35,600 --> 01:23:40,650
excuse me before that about this is again one that has seen

1292
01:23:40,780 --> 01:23:46,560
will symmetry but not really this is not the symmetry but i would call me

1293
01:23:46,560 --> 01:23:48,070
an equilibrium

1294
01:23:49,740 --> 01:23:55,360
on either side of this view of paradise this is adam and eve in paradise

1295
01:23:55,850 --> 01:23:58,410
URI matching figures the

1296
01:23:58,420 --> 01:23:59,920
human figures

1297
01:23:59,940 --> 01:24:01,910
the large cats

1298
01:24:01,920 --> 01:24:04,510
the everything

1299
01:24:04,530 --> 01:24:05,840
is balanced

1300
01:24:05,850 --> 01:24:12,310
with essentially line so we have both a little mirror symmetry but we also

1301
01:24:12,610 --> 01:24:17,460
however in this case not literal but no equilibrium

1302
01:24:17,540 --> 01:24:22,150
this dynamic symmetry of equal halves

1303
01:24:22,350 --> 01:24:28,710
is with respect to symmetry instead of having matcher matching mirror images

1304
01:24:29,110 --> 01:24:35,740
you can also have to have we have the blacklisted and matching white was and

1305
01:24:35,740 --> 01:24:43,900
they're not mirroring each other about the centre point right there between the rows of

1306
01:24:43,980 --> 01:24:47,730
the turning around a hundred and eighty degrees

1307
01:24:47,740 --> 01:24:53,220
if you turn this upside down it would still look the same except for the

1308
01:24:53,220 --> 01:24:56,010
interchange of black and white

1309
01:24:56,170 --> 01:25:03,270
this is still an example of what are some crystallographic school anti symmetry

1310
01:25:03,290 --> 01:25:08,960
i don't like that very much it sounds like against symmetry but anti symmetry means

1311
01:25:08,960 --> 01:25:11,390
an interchange of black and white

1312
01:25:11,440 --> 01:25:12,700
and the

1313
01:25:13,070 --> 01:25:16,260
the textile people have much nicer term for it

1314
01:25:16,590 --> 01:25:19,470
they call counter change symmetry

1315
01:25:19,600 --> 01:25:26,040
so that after you've preferment in this case a one hundred eighty degree rotation black-and-white

1316
01:25:29,920 --> 01:25:35,820
here's another example of of symmetry in ashes work used to symmetry off in in

1317
01:25:35,820 --> 01:25:38,290
his compositions here you have the load

1318
01:25:38,380 --> 01:25:42,300
all sorts of schools of fish

1319
01:25:42,380 --> 01:25:49,060
this print is literally meant using this i have turned symmetry right the central europe

1320
01:25:49,310 --> 01:25:54,760
where you can see that the centre have turned symmetry it wouldn't matter how i

1321
01:25:54,760 --> 01:25:56,090
put this slide

1322
01:25:56,160 --> 01:26:02,290
in the machine it would look exactly the same right side up or upside down

1323
01:26:05,510 --> 01:26:08,240
this is very interesting

1324
01:26:08,250 --> 01:26:11,050
use the symmetry by measure

1325
01:26:11,130 --> 01:26:14,660
you have to kind of zero size

1326
01:26:14,800 --> 01:26:16,620
o really

1327
01:26:16,620 --> 01:26:23,360
it wasn't easy sciences already image it was decided scientists used to decide those components

1328
01:26:24,240 --> 01:26:32,000
who which elements of the variable to be selected to be modified it is be

1329
01:26:32,620 --> 01:26:39,810
what you have the whole procedure usually you want to have to the do

1330
01:26:39,970 --> 01:26:44,610
tedious in the coverage you want to prove that some of the sequence the sequence

1331
01:26:44,610 --> 01:26:50,910
of that you are changing eventually converges to the optimal solution of the dual problem

1332
01:26:50,920 --> 01:27:00,420
is only four four four optimisation studies late for coordinate wise minimisation the coverage studies

1333
01:27:00,450 --> 01:27:04,910
mainly focused on and constant situation or or force

1334
01:27:04,920 --> 01:27:10,970
four situations without linear constraint but now we have a linear constant transport have so

1335
01:27:10,980 --> 01:27:17,660
so even for the very simple situation like this economic selection so so there simple

1336
01:27:17,660 --> 01:27:23,140
decomposition method is it the first iteration you you were the first to the second

1337
01:27:23,140 --> 01:27:28,340
problem and then the next iteration will come the first entered service

1338
01:27:29,250 --> 01:27:31,040
the first and then force

1339
01:27:31,490 --> 01:27:38,360
the first OK so basically one-for-one shree one four one five and you want

1340
01:27:38,370 --> 01:27:42,540
two or three to four OK so that's the secret way of selecting working sets

1341
01:27:42,780 --> 01:27:47,830
so even for such a simple situation the these sympathetic coverage was just was only

1342
01:27:47,830 --> 01:27:49,360
recently approved

1343
01:27:51,970 --> 01:27:58,890
so so these issues and land in designing the the whole procedure then you have

1344
01:27:58,910 --> 01:28:06,260
to take care starting conditions and not only that coverage is open whole face to

1345
01:28:06,410 --> 01:28:11,090
cover his so far has been here before it is even basic or it is

1346
01:28:11,090 --> 01:28:18,040
and what is worse than linear convergence so companies is is another problem also quite

1347
01:28:18,040 --> 01:28:25,470
a few other numerical features in designing SVM so we actually quite a few optimisation

1348
01:28:25,470 --> 01:28:30,290
researchers are not interested in in the issues but i'm not going to talk about

1349
01:28:30,290 --> 01:28:35,750
any details because i don't think you want to know things only for people who

1350
01:28:35,750 --> 01:28:36,950
are interested in

1351
01:28:36,960 --> 01:28:45,210
as you something you dual problem they all of but get short course some transition

1352
01:28:45,510 --> 01:28:50,090
researchers in wrong i the set of slides sort of more

1353
01:28:50,280 --> 01:28:55,130
that touches more optimisation issues in something as you do so if you are interested

1354
01:28:55,130 --> 01:28:57,520
in those issues you want to look

1355
01:28:57,540 --> 01:29:00,700
most slides

1356
01:29:03,100 --> 01:29:08,810
four so in training linear SVM that's one of the things i want to mention

1357
01:29:09,000 --> 01:29:14,920
so they were quite effective techniques to speed up the decomposition this is what is

1358
01:29:14,920 --> 01:29:17,150
called patient

1359
01:29:17,160 --> 01:29:22,610
so the idea of caching is to store recently used kernel columns in computer memory

1360
01:29:22,820 --> 01:29:28,010
already said that for the composition this is a list of current occasionally you when

1361
01:29:28,010 --> 01:29:29,000
they are needed

1362
01:29:29,030 --> 01:29:36,840
but you still have some computer so it can locate some some space to store

1363
01:29:36,860 --> 01:29:42,130
recently used or or or or some colours and you think they are going to

1364
01:29:42,130 --> 01:29:43,650
be used in the future

1365
01:29:43,900 --> 01:29:48,230
so this is called occasion so the idea is is very similar to the real

1366
01:29:48,550 --> 01:29:51,180
the page

1367
01:29:51,200 --> 01:29:58,090
the reason for using stolen credit card instead the company is communication so we can

1368
01:29:58,090 --> 01:30:04,370
see how can you help so for for what they say if we use we

1369
01:30:04,690 --> 01:30:11,520
can only GK GK space for for a case to store kernel colours

1370
01:30:11,980 --> 01:30:17,830
then it takes you live six months but we if we look at more

1371
01:30:18,670 --> 01:30:22,510
like forty megabytes is about seven seconds

1372
01:30:24,170 --> 01:30:25,000
so you can

1373
01:30:25,070 --> 01:30:30,110
he you if you have a lot of memory that use this technique

1374
01:30:30,120 --> 01:30:32,980
then shrinking is another

1375
01:30:33,000 --> 01:30:36,120
quite quite effective me

1376
01:30:36,270 --> 01:30:38,520
it's said

1377
01:30:38,530 --> 01:30:44,640
the dual problem the problem is about above the constraints of i must be between

1378
01:30:44,640 --> 01:30:48,660
zero and see and we have said earlier that we hold a lot of actually

1379
01:30:48,660 --> 01:30:53,350
remain zero so you few support vectors and those training is faced

1380
01:30:53,360 --> 01:30:58,690
and not only the lower bound for but we also

1381
01:30:58,700 --> 01:31:03,940
components they eventually will become upper body so that i five is equal to c

1382
01:31:04,020 --> 01:31:13,070
follows for football of components it is possible that certain iterations led those components really

1383
01:31:13,070 --> 01:31:19,620
reach the optimal solution so you have an optimisation easier or should we see that

1384
01:31:19,620 --> 01:31:21,200
there are so many iterations

1385
01:31:21,320 --> 01:31:27,340
the are a lot of it is in the middle of a centurion change so

1386
01:31:27,340 --> 01:31:32,820
this is the enhanced vision procedure we don't really have to consider that and then

1387
01:31:32,820 --> 01:31:36,480
we can resize the hard the whole people problem was smaller one

1388
01:31:36,500 --> 01:31:40,590
so we just heuristic releasing all those those components

1389
01:31:40,600 --> 01:31:42,820
we already have fewer solutions

1390
01:31:42,840 --> 01:31:48,740
so we can will remove that we have a small smaller do optimisation problem caused

1391
01:31:48,740 --> 01:31:51,400
no i don't notice anything

1392
01:31:51,430 --> 01:31:54,570
that's the posterior dirichlet

1393
01:31:54,590 --> 01:31:56,130
OK and so

1394
01:31:56,130 --> 01:32:01,380
i notice that your instinct earlier that as the as the sum of alpha gets

1395
01:32:01,380 --> 01:32:07,660
larger get pq pq distribution that's mirror here as we see more and more observations

1396
01:32:07,660 --> 01:32:10,490
are posterior gets peak during peak year

1397
01:32:10,510 --> 01:32:12,010
and that's very intuitive

1398
01:32:12,030 --> 01:32:15,450
as i as i roll the die more and more and more my idea of

1399
01:32:15,450 --> 01:32:19,380
what the distribution of the faces are is going to become more and become more

1400
01:32:19,380 --> 01:32:22,630
and more confident about it and so it's the it's the whole idea of the

1401
01:32:22,630 --> 01:32:28,320
prior speaking so loudly in the data speaking loud as loud proportional to how much

1402
01:32:28,320 --> 01:32:32,660
data you saw as more data you become more and more confident in the estimate

1403
01:32:32,720 --> 01:32:35,150
that data gives

1404
01:32:36,650 --> 01:32:40,150
we totally diverged from topic modeling

1405
01:32:40,180 --> 01:32:43,130
so any questions about this now we can get back to it

1406
01:32:43,150 --> 01:32:46,610
for fifteen minutes

1407
01:32:49,880 --> 01:32:57,570
from one in the audience now close to zero they're going to be like point

1408
01:32:57,570 --> 01:32:59,360
o or one

1409
01:32:59,400 --> 01:33:00,820
you can see that are

1410
01:33:01,010 --> 01:33:07,300
i will turn the lights off

1411
01:33:07,320 --> 01:33:08,180
by the way

1412
01:33:08,300 --> 01:33:12,860
when you sample from years in order to do it well a ideally let's keep

1413
01:33:15,450 --> 01:33:16,510
OK go

1414
01:33:16,530 --> 01:33:17,340
we're back

1415
01:33:19,400 --> 01:33:23,450
i'm going to wait on one second

1416
01:33:23,450 --> 01:33:27,150
so here we go again we have the LDA model LDA some mixed it's called

1417
01:33:27,200 --> 01:33:33,110
mixed membership model in statistics and really builds on the work the seminal LSA work

1418
01:33:33,110 --> 01:33:40,090
latent semantic analysis deerwester at all and probabilistic latent semantic analysis from thomas hobbes

1419
01:33:44,530 --> 01:33:48,090
actually let's not go into details about this reason it's called the mixed membership model

1420
01:33:48,090 --> 01:33:51,780
is that you can think of the model where each document comes from a single

1421
01:33:51,780 --> 01:33:55,240
cluster as like that's a mixture model where we have

1422
01:33:55,380 --> 01:34:01,220
each document is associated with the singles e and here since documents are associated with

1423
01:34:01,220 --> 01:34:07,470
data distribution over clusters then each document can be associated with multiple components that what

1424
01:34:07,470 --> 01:34:12,260
that's what the mixed membership ideas so when you're reading the journal of bayesian analysis

1425
01:34:12,260 --> 01:34:16,090
of annals of applied statistics and you hear about mixed membership models of rank data

1426
01:34:16,090 --> 01:34:19,570
on this data and that data you can think about LDA is an instance of

1427
01:34:19,570 --> 01:34:23,700
a mixed membership model that's in statistics that this is called

1428
01:34:23,720 --> 01:34:31,280
and for document collections and other groups data bold that group data this is rather

1429
01:34:31,280 --> 01:34:34,950
than thinking of the document as a single data point it's really a group of

1430
01:34:34,950 --> 01:34:39,010
data points the data are the words in the document represents the group of words

1431
01:34:39,320 --> 01:34:44,050
for group data often the mixed membership assumption is more appropriate than a simple finite

1432
01:34:44,050 --> 01:34:47,070
mixture which is the natural alternative

1433
01:34:48,470 --> 01:34:55,030
and i should mention that in statistics the same model was invented for population genetics

1434
01:34:55,030 --> 01:34:59,320
analysis and had a lot of impact there by stephen temperature so

1435
01:34:59,340 --> 01:35:06,160
there they don't care about documents with a care about is real science and

1436
01:35:06,180 --> 01:35:13,970
they are modelling people as being mixtures of their various

1437
01:35:13,990 --> 01:35:16,490
ancestry so you know

1438
01:35:16,570 --> 01:35:20,610
so it my my cases back cases everybody is from the same small town in

1439
01:35:20,610 --> 01:35:29,450
hungary but my wife like her family mom's from denmark and dads from

1440
01:35:33,150 --> 01:35:37,010
he is pretty user character is from

1441
01:35:37,030 --> 01:35:40,970
canada basically let's say and

1442
01:35:42,180 --> 01:35:46,840
and so you know her genes are kind of a mixture of the very of

1443
01:35:46,860 --> 01:35:51,610
the different populations that she comes from its of it's a lovely combination i should

1444
01:35:51,610 --> 01:35:55,970
say that the video and

1445
01:35:55,990 --> 01:36:01,030
and so this model is a model for four looking at how people's genes makes

1446
01:36:01,030 --> 01:36:04,180
and then what are the results of it you can think of the populations as

1447
01:36:04,180 --> 01:36:08,900
the topics in the people as mixing over the topics OK so let's get on

1448
01:36:08,900 --> 01:36:11,420
before i make some kind of

1449
01:36:11,430 --> 01:36:12,610
marriage air

1450
01:36:15,220 --> 01:36:17,680
so again the

1451
01:36:17,700 --> 01:36:20,950
from the collection of documents

1452
01:36:20,970 --> 01:36:24,070
this is all nice story but we don't get to observe any of the stuff

1453
01:36:24,070 --> 01:36:28,050
we get to observe the topics or the topic proportions or the topic assignments and

1454
01:36:28,050 --> 01:36:30,840
that's really the central algorithmic goal

1455
01:36:30,860 --> 01:36:32,470
of of

1456
01:36:32,470 --> 01:36:35,740
working with the model like this you want to infer all of this nice structure

1457
01:36:35,740 --> 01:36:39,510
so we can use it so the idea is to infer the per word topic

1458
01:36:39,510 --> 01:36:45,180
assignments the the per document topic proportions theta d and the per corpus topic distributions

1459
01:36:45,180 --> 01:36:46,150
beta k

1460
01:36:46,160 --> 01:36:51,740
OK and then to use posterior expectations basically the expectation of

1461
01:36:51,760 --> 01:36:54,150
all those things

1462
01:36:54,180 --> 01:36:59,110
given the words here's the hidden variables here the word use the posterior expectations of

1463
01:36:59,110 --> 01:37:03,400
these things to perform whatever casket is we care about such as information retrieval document

1464
01:37:03,400 --> 01:37:06,530
similarity classification whatever it is you're doing

1465
01:37:07,380 --> 01:37:08,450
it was one

1466
01:37:10,420 --> 01:37:14,630
OK so there are a lot of approximate OK we will in the second part

1467
01:37:14,630 --> 01:37:16,320
of this talk we're going to see

1468
01:37:16,340 --> 01:37:20,700
how we can actually compute the exact posterior like we can hear this nice conjugate

1469
01:37:20,700 --> 01:37:24,930
model and so a lot of approximate posterior inference algorithms for this model have been

1470
01:37:24,930 --> 01:37:29,820
developed including mean field variational methods this is what we're going to describe later on

1471
01:37:30,180 --> 01:37:34,680
expectation propagation which i know you learned about it yesterday

1472
01:37:34,700 --> 01:37:39,020
collapsed gibbs sampling which i'll talk about later on in collapsed variational inference which is

1473
01:37:39,020 --> 01:37:41,690
very exciting but i will only allude to it later on

1474
01:37:41,730 --> 01:37:47,550
and there's also been some work on how to compare these different types of inference

1475
01:37:47,550 --> 01:37:51,420
algorithms and and and how well they do those great paper from

1476
01:37:51,480 --> 01:37:56,480
i see no this year comparing them and also some theoretical work about collapsed variational

1477
01:37:56,480 --> 01:38:01,640
inference versus mean field variational inference that i worked on with the students working together

1478
01:38:01,640 --> 01:38:04,380
to details of approximate posterior inference

1479
01:38:04,390 --> 01:38:08,770
later on i guess on thursday but for now i want to show you a

1480
01:38:08,770 --> 01:38:09,880
little bit of

1481
01:38:10,060 --> 01:38:14,400
let's assume we have an approximate posterior algorithm that we like and let's look at

1482
01:38:14,400 --> 01:38:17,760
some real data on what this model does with real data

1483
01:38:17,770 --> 01:38:22,690
any questions about this so this is the model only things that are observed in

1484
01:38:22,690 --> 01:38:25,160
other words and so we want to fill in the rest of us with approximate

1485
01:38:25,160 --> 01:38:26,730
posterior inference

1486
01:38:26,730 --> 01:38:28,350
the that

1487
01:38:28,390 --> 01:38:29,620
was j

1488
01:38:29,640 --> 01:38:31,270
the sign of

1489
01:38:31,310 --> 01:38:34,730
that is this article which is real

1490
01:38:34,770 --> 01:38:37,580
this is the sign of data because this is one

1491
01:38:37,580 --> 01:38:41,640
have to multiply that by g

1492
01:38:41,660 --> 01:38:43,770
this now

1493
01:38:43,830 --> 01:38:45,960
according to boiler

1494
01:38:45,980 --> 01:38:47,830
great mathematician

1495
01:38:47,850 --> 01:38:49,640
hoy oiler

1496
01:38:50,730 --> 01:38:53,710
after all this was also mention

1497
01:38:53,710 --> 01:38:58,060
already in seventeen forty eight

1498
01:38:58,100 --> 01:39:00,430
he proved that this is the same

1499
01:39:00,480 --> 01:39:02,850
as to power g

1500
01:39:04,520 --> 01:39:07,390
sorry state

1501
01:39:09,910 --> 01:39:14,830
this equality is mind boggling

1502
01:39:14,930 --> 01:39:18,730
and when i saw this inequality for the first time

1503
01:39:18,770 --> 01:39:21,060
i didn't believe number one

1504
01:39:21,060 --> 01:39:24,350
and i could hardly sleep that at night

1505
01:39:24,390 --> 01:39:26,520
because i couldn't prove it

1506
01:39:26,560 --> 01:39:29,660
so i hadn't had any taylor expansion

1507
01:39:29,710 --> 01:39:32,430
so i couldn't prove it just my teacher in high school said

1508
01:39:32,480 --> 01:39:33,200
this is

1509
01:39:33,200 --> 01:39:36,310
this is the the case and i said why is that

1510
01:39:36,330 --> 01:39:38,560
this is the way

1511
01:39:38,580 --> 01:39:42,210
but we now can prove this you can do to taylor expansion of the cosine

1512
01:39:42,210 --> 01:39:47,850
theta taylor expansion of the sign theta and the taylor expansion of e to power

1513
01:39:49,330 --> 01:39:51,700
it's exactly

1514
01:39:52,770 --> 01:39:55,930
not an approximation

1515
01:39:56,060 --> 01:39:58,940
so why would we ever want to use this well

1516
01:39:59,000 --> 01:40:01,750
if you break this thing go around

1517
01:40:01,790 --> 01:40:03,210
going back to my

1518
01:40:03,250 --> 01:40:05,730
uniform circular motion here

1519
01:40:05,790 --> 01:40:07,620
if i make a point go around

1520
01:40:07,660 --> 01:40:12,270
and i only look at the real part i have a simple harmonic motion

1521
01:40:12,370 --> 01:40:16,480
and so if i change theta into omega t

1522
01:40:16,480 --> 01:40:18,680
then i get that zy

1523
01:40:18,700 --> 01:40:20,580
all the cosine

1524
01:40:20,660 --> 01:40:22,290
of omega t

1525
01:40:22,350 --> 01:40:23,870
because j

1526
01:40:23,910 --> 01:40:25,750
five signed

1527
01:40:25,790 --> 01:40:27,370
of the getting

1528
01:40:27,390 --> 01:40:30,830
the real part of which is a simple harmonic motion

1529
01:40:30,890 --> 01:40:31,960
and of course

1530
01:40:31,960 --> 01:40:34,080
i'm not stuck to

1531
01:40:34,100 --> 01:40:36,060
in amplitude of

1532
01:40:36,080 --> 01:40:39,140
one i can easily make the amplitude

1533
01:40:39,210 --> 01:40:41,830
eight times larger

1534
01:40:41,870 --> 01:40:44,600
and of course there's nothing wrong depending upon

1535
01:40:44,660 --> 01:40:47,000
my initial conditions

1536
01:40:47,060 --> 01:40:48,540
to have here

1537
01:40:48,540 --> 01:40:50,370
the phase angle phi

1538
01:40:50,440 --> 01:40:56,770
this them

1539
01:40:56,830 --> 01:41:00,660
is a times e to the power j

1540
01:41:00,710 --> 01:41:02,430
only got to

1541
01:41:02,430 --> 01:41:06,500
plus five according to order

1542
01:41:06,560 --> 01:41:08,680
what that means is

1543
01:41:08,730 --> 01:41:11,290
but if you

1544
01:41:11,290 --> 01:41:13,750
use this as your trial function

1545
01:41:13,770 --> 01:41:15,980
to solve the differential equation

1546
01:41:16,000 --> 01:41:17,580
you can manipulate

1547
01:41:17,640 --> 01:41:24,040
this very easily you can take first derivative second derivatives of exponentials extremely easy

1548
01:41:24,100 --> 01:41:25,700
then when you're done

1549
01:41:25,710 --> 01:41:27,790
you take the real part of

1550
01:41:27,790 --> 01:41:29,330
an out output

1551
01:41:29,390 --> 01:41:30,810
x as a function

1552
01:41:30,830 --> 01:41:31,730
of time

1553
01:41:31,750 --> 01:41:33,410
you done

1554
01:41:33,480 --> 01:41:34,940
as i said

1555
01:41:34,960 --> 01:41:37,790
it's up to you when you want to use the next lecture i will give

1556
01:41:37,810 --> 01:41:41,730
you an example of why it's clearly the way to go i wouldn't even know

1557
01:41:41,750 --> 01:41:44,040
how to do it in any other way

1558
01:41:44,100 --> 01:41:47,520
but often you do have a choice

1559
01:41:47,520 --> 01:41:48,600
so we

1560
01:41:48,790 --> 01:41:51,310
interested the real part of that

1561
01:41:51,390 --> 01:41:55,710
which is then are acceptable solution

1562
01:41:55,750 --> 01:42:03,270
so if we have a complex number z equals a person to be

1563
01:42:03,290 --> 01:42:07,460
then we should always be able to write that as an amplitude times e

1564
01:42:07,480 --> 01:42:09,040
the power

1565
01:42:12,520 --> 01:42:14,770
and then the amplitude a

1566
01:42:14,810 --> 01:42:17,270
is the square root

1567
01:42:17,310 --> 01:42:19,040
of a square

1568
01:42:19,060 --> 01:42:21,310
with the square

1569
01:42:21,350 --> 01:42:25,020
and tensions of fatah

1570
01:42:25,060 --> 01:42:26,210
it's been

1571
01:42:26,270 --> 01:42:28,600
of follows immediately

1572
01:42:28,640 --> 01:42:31,910
from that figure

1573
01:42:32,000 --> 01:42:34,410
so in problem set one

1574
01:42:34,430 --> 01:42:36,460
you will get some

1575
01:42:36,520 --> 01:42:38,640
chance to practice

1576
01:42:38,730 --> 01:42:41,560
give you a few interesting cases

1577
01:42:41,600 --> 01:42:43,560
in the classic case

1578
01:42:43,600 --> 01:42:44,810
but all of you

1579
01:42:44,850 --> 01:42:48,520
your lifetime have been able to do once

1580
01:42:49,790 --> 01:42:51,660
the very intuitive

1581
01:42:51,680 --> 01:42:56,580
problem j two the property

1582
01:42:56,600 --> 01:43:00,750
well i saw for the first time data apology i said to myself what all

1583
01:43:00,750 --> 01:43:04,200
of us can be more complex than j two apologies

1584
01:43:04,250 --> 01:43:07,520
but israel

1585
01:43:07,560 --> 01:43:09,390
it is not complex

1586
01:43:09,460 --> 01:43:11,350
annual wrestle with this

1587
01:43:11,370 --> 01:43:16,600
there is an infinite number of solutions not one all of them are correct

1588
01:43:16,640 --> 01:43:19,140
and i will help you

1589
01:43:19,180 --> 01:43:21,060
a little

1590
01:43:21,120 --> 01:43:23,290
the first time want to be nice to

1591
01:43:23,330 --> 01:43:26,350
but only the first time

1592
01:43:26,350 --> 01:43:28,830
i can also write j

1593
01:43:28,870 --> 01:43:31,910
as he apology

1594
01:43:32,120 --> 01:43:34,660
by over to you great

1595
01:43:34,730 --> 01:43:37,250
because it simply means that the angle theta

1596
01:43:37,290 --> 01:43:38,680
this by over two

1597
01:43:38,750 --> 01:43:41,350
here so and up here

1598
01:43:41,390 --> 01:43:44,060
but that's changed

1599
01:43:44,120 --> 01:43:49,200
i'm not saying it's very nice way of expressing j but this change

1600
01:43:49,230 --> 01:43:51,290
but not only is this j

1601
01:43:51,350 --> 01:43:52,600
i can also

1602
01:43:52,620 --> 01:43:54,500
i rotate

1603
01:43:54,520 --> 01:43:56,200
and in the true number

1604
01:43:56,290 --> 01:43:58,250
three hundred sixty degrees

1605
01:43:58,250 --> 01:43:59,790
by n

1606
01:44:02,850 --> 01:44:04,940
two or three

1607
01:44:05,020 --> 01:44:09,810
i rotate clockwise or counterclockwise and is against

1608
01:44:09,870 --> 01:44:12,140
because if i rotate

1609
01:44:12,160 --> 01:44:13,600
ninety degrees

1610
01:44:14,680 --> 01:44:19,310
i rotate another three six degrees again what if i wrote it back three hundred

1611
01:44:20,640 --> 01:44:21,830
so you see

1612
01:44:22,910 --> 01:44:24,460
is also a

1613
01:44:28,600 --> 01:44:29,980
and that will help you

1614
01:44:30,500 --> 01:44:40,370
i will always have a five-minute break

1615
01:44:40,390 --> 01:44:44,520
during this eighty five minute lecture so you can stretch your legs

1616
01:44:44,540 --> 01:44:47,390
if you can manage to make it back and forth to do battle that's fine

1617
01:44:47,390 --> 01:44:49,100
that's your problem

1618
01:44:49,160 --> 01:44:52,390
i will start exactly after five minutes

1619
01:44:52,480 --> 01:44:54,960
however every tuesday

1620
01:44:55,000 --> 01:44:57,370
during part of these five minutes

1621
01:44:57,410 --> 01:45:00,250
we will have many queries

1622
01:45:00,290 --> 01:45:02,040
it's really

1623
01:45:02,060 --> 01:45:05,680
this small

1624
01:45:05,770 --> 01:45:10,430
we will collected after the lecture and you get some credit for that

1625
01:45:10,500 --> 01:45:12,660
before this only on tuesdays

1626
01:45:12,750 --> 01:45:14,430
not today

1627
01:45:14,480 --> 01:45:20,870
before we go into this five-minute break today

1628
01:45:20,870 --> 01:45:22,620
i wanted to see something

1629
01:45:22,620 --> 01:45:24,780
these would be zero

1630
01:45:24,830 --> 01:45:26,210
these one

1631
01:45:26,270 --> 01:45:28,280
that means the here

1632
01:45:28,280 --> 01:45:30,680
the average crossing

1633
01:45:30,680 --> 01:45:34,890
from zero to in from zero to one which has infinite

1634
01:45:37,010 --> 01:45:39,650
so the cost of this partition

1635
01:45:39,720 --> 01:45:41,380
is infinite

1636
01:45:41,420 --> 01:45:43,850
so it will not

1637
01:45:43,900 --> 01:45:44,730
come on

1638
01:45:44,770 --> 01:45:46,580
as you mean cost

1639
01:45:46,590 --> 01:45:51,360
partition the graph so any min cost partition this graph

1640
01:45:51,440 --> 01:45:53,510
will only

1641
01:45:54,360 --> 01:45:55,530
this fact

1642
01:45:55,660 --> 01:45:57,610
note once

1643
01:45:58,090 --> 01:46:00,260
once otherwise you have

1644
01:46:00,340 --> 01:46:02,110
the cost

1645
01:46:04,650 --> 01:46:06,960
that's the way you encode something like this

1646
01:46:07,020 --> 01:46:09,010
and it turns out

1647
01:46:12,780 --> 01:46:14,240
you can

1648
01:46:14,260 --> 01:46:16,340
solve the problem in this way

1649
01:46:17,400 --> 01:46:21,340
in fact the conditions very similar if you if you cost function

1650
01:46:21,450 --> 01:46:24,710
because function is form

1651
01:46:29,440 --> 01:46:34,570
i mean i mean things which in this case just functions as a single variable

1652
01:46:34,580 --> 01:46:38,360
what about the functions of two variables if you've got a function two variables which

1653
01:46:38,540 --> 01:46:41,340
the form the

1654
01:46:41,360 --> 01:46:43,380
x i

1655
01:46:45,360 --> 01:46:47,260
in our

1656
01:46:47,300 --> 01:46:50,230
x i x j

1657
01:46:50,240 --> 01:46:51,670
in l

1658
01:46:56,480 --> 01:47:00,150
it is the cost of various various

1659
01:47:00,190 --> 01:47:02,220
cliques of size two two so

1660
01:47:02,230 --> 01:47:05,830
individual functions a function of two variables

1661
01:47:05,880 --> 01:47:10,640
now this doesn't need to be quadratic or anything just function to variables

1662
01:47:10,650 --> 01:47:12,660
in that particular case

1663
01:47:15,940 --> 01:47:20,050
construction always lead to graph you can solve

1664
01:47:20,090 --> 01:47:23,720
in other words submodularity condition

1665
01:47:23,780 --> 01:47:28,400
well not submodular condition positive age weight condition

1666
01:47:28,460 --> 01:47:34,290
positive edges

1667
01:47:34,300 --> 01:47:38,210
if only if you have a condition b

1668
01:47:38,220 --> 01:47:40,650
a b a

1669
01:47:40,650 --> 01:47:42,890
class b

1670
01:47:42,940 --> 01:47:44,360
a plus one

1671
01:47:44,410 --> 01:47:46,590
the plus one

1672
01:47:46,630 --> 01:47:49,580
it will be less than or equal to b

1673
01:47:49,740 --> 01:47:51,660
plus one b

1674
01:47:54,280 --> 01:47:56,450
the first one

1675
01:48:00,320 --> 01:48:03,150
this looks very similar to the the

1676
01:48:03,150 --> 01:48:05,020
the submodularity condition

1677
01:48:05,230 --> 01:48:08,650
if this condition holds for any a b

1678
01:48:08,790 --> 01:48:09,960
in l

1679
01:48:10,210 --> 01:48:14,790
maybe you know might my to variable functions satisfy this

1680
01:48:15,960 --> 01:48:20,980
the edges in the graph is the positive and the absolutely as the minimum of

1681
01:48:20,980 --> 01:48:22,230
the cost function

1682
01:48:22,280 --> 01:48:23,190
using this

1683
01:48:23,200 --> 01:48:24,950
using this technique

1684
01:48:24,980 --> 01:48:26,610
there are of course

1685
01:48:28,830 --> 01:48:30,410
there are all sorts of edges

1686
01:48:30,440 --> 01:48:33,600
joining the nodes for x notes why

1687
01:48:33,610 --> 01:48:38,940
a lot of it against l squared edges in fact in general this possible

1688
01:48:40,080 --> 01:48:43,400
one other observation about this if if you fall

1689
01:48:43,470 --> 01:48:44,990
the a b

1690
01:48:45,030 --> 01:48:47,070
happens to be

1691
01:48:47,090 --> 01:48:48,990
of the form

1692
01:48:49,030 --> 01:48:52,440
depend only upon the this the difference between two no

1693
01:48:52,450 --> 01:48:55,890
the difference between the labels right so i got to

1694
01:48:55,920 --> 01:48:59,110
the two images by giving this one some label

1695
01:48:59,130 --> 01:49:02,440
OK i'm giving this one to know anything

1696
01:49:02,480 --> 01:49:06,200
the label and label the and there's some cost

1697
01:49:06,240 --> 01:49:07,940
associated with

1698
01:49:08,020 --> 01:49:13,960
if i make the assumption that depends only on the difference in the label values

1699
01:49:14,010 --> 01:49:16,980
according to some function e

1700
01:49:17,070 --> 01:49:20,080
it's actually pretty easy to see this gives you then

1701
01:49:21,490 --> 01:49:23,760
a minus b

1702
01:49:24,860 --> 01:49:26,650
a minus b

1703
01:49:26,730 --> 01:49:29,610
this list equal to g

1704
01:49:29,630 --> 01:49:30,970
a plus one

1705
01:49:30,980 --> 01:49:31,940
a minus b

1706
01:49:31,950 --> 01:49:33,690
or if you like

1707
01:49:33,780 --> 01:49:35,660
a minus b plus one

1708
01:49:35,710 --> 01:49:37,110
plus g

1709
01:49:37,130 --> 01:49:38,790
a minus b

1710
01:49:38,880 --> 01:49:41,520
minus one

1711
01:49:41,580 --> 01:49:43,840
so let's to g

1712
01:49:43,850 --> 01:49:45,670
it's less than GA b

1713
01:49:45,890 --> 01:49:48,990
it really means in fact that your functions

1714
01:49:50,740 --> 01:49:52,250
has to be

1715
01:49:53,560 --> 01:49:56,070
if the function g is convex function

1716
01:49:56,080 --> 01:49:58,440
you can always all things like this

1717
01:49:58,540 --> 01:50:00,060
is concave

1718
01:50:00,100 --> 01:50:01,880
you can't

1719
01:50:03,490 --> 01:50:06,490
so i'm going say about this is great but she column

1720
01:50:06,590 --> 01:50:08,740
which is done this gives

1721
01:50:08,800 --> 01:50:13,200
this gives a looks like that and that tells you what labels

1722
01:50:13,760 --> 01:50:14,960
pixel p

1723
01:50:21,260 --> 01:50:23,080
and i said if

1724
01:50:23,090 --> 01:50:24,800
the function is concave

1725
01:50:24,840 --> 01:50:28,040
convex like that she of

1726
01:50:28,050 --> 01:50:30,630
the difference between labels and convex

1727
01:50:30,760 --> 01:50:32,580
can solid

1728
01:50:32,620 --> 01:50:36,240
unfortunately a lot of the problems which are interested in

1729
01:50:36,250 --> 01:50:39,360
it's not like that so-called potts model

1730
01:50:39,370 --> 01:50:42,140
potts model says that there is a cost

1731
01:50:42,190 --> 01:50:44,790
associating different labels

1732
01:50:44,840 --> 01:50:48,550
but it doesn't matter what the labels allows if the difference is constant cost the

1733
01:50:48,550 --> 01:50:50,340
same there is no cost

1734
01:50:50,380 --> 01:50:52,110
that doesn't work

1735
01:50:52,160 --> 01:50:55,260
in this case the topic model

1736
01:50:55,270 --> 01:51:00,190
and is someone smooth version that doesn't always work so

1737
01:51:00,220 --> 01:51:04,180
obviously enough you expect to

1738
01:51:04,220 --> 01:51:05,410
you expect

1739
01:51:05,460 --> 01:51:07,520
it's probably difficult in general

1740
01:51:07,540 --> 01:51:10,100
just an example

1741
01:51:10,160 --> 01:51:12,970
here's an example of

1742
01:51:13,130 --> 01:51:17,550
some sort of segmentation multi label segmentation problem i've got

1743
01:51:17,680 --> 01:51:20,310
an image like that which is

1744
01:51:21,420 --> 01:51:23,120
the rectangles

1745
01:51:23,180 --> 01:51:26,000
and noise right

1746
01:51:26,020 --> 01:51:28,540
if you use the linear costs

1747
01:51:29,450 --> 01:51:30,520
which says

1748
01:51:30,550 --> 01:51:32,480
like this and says

1749
01:51:32,580 --> 01:51:33,980
the cost

1750
01:51:34,040 --> 01:51:35,800
of assign labels

1751
01:51:35,810 --> 01:51:38,750
two labels to generate adjacent pixels

1752
01:51:38,760 --> 01:51:40,370
depending just linearly

1753
01:51:40,380 --> 01:51:42,560
on the difference between those labels

1754
01:51:42,700 --> 01:51:46,310
then you get

1755
01:51:47,080 --> 01:51:50,120
something like that which is not a great result OK

1756
01:51:50,190 --> 01:51:53,140
if on the other hand you take the truncated linear

1757
01:51:53,200 --> 01:51:54,220
which is

1758
01:51:55,370 --> 01:52:00,000
we are merely forbidden then truncated if the labels are too far apart doesn't matter

1759
01:52:00,000 --> 01:52:01,960
how much differently

1760
01:52:01,960 --> 01:52:04,970
different is sufficiently different

1761
01:52:05,050 --> 01:52:09,190
doesn't matter that much more different than you get a much better result

1762
01:52:09,270 --> 01:52:12,680
but unfortunately council using she col

1763
01:52:12,690 --> 01:52:16,260
if you cannot find the exact solution in fact

1764
01:52:16,290 --> 01:52:18,720
in this case

1765
01:52:18,830 --> 01:52:22,460
the reason is i suppose

1766
01:52:22,470 --> 01:52:27,620
in a sense

1767
01:52:31,870 --> 01:52:34,250
does not convex it looks like this right

1768
01:52:34,250 --> 01:52:35,340
here is the

1769
01:52:35,340 --> 01:52:38,980
sort of scenario you could imagine happening in california

1770
01:52:42,100 --> 01:52:43,940
you come home and

1771
01:52:43,980 --> 01:52:46,680
you observe that the ground was wet

1772
01:52:46,750 --> 01:52:49,240
OK well outside your house

1773
01:52:50,380 --> 01:52:51,430
you find that

1774
01:52:51,440 --> 01:52:53,680
you're on is whether the ground is wet

1775
01:52:54,300 --> 01:52:57,730
you can infer two things one of them is that while you're working not paying

1776
01:52:57,730 --> 01:52:59,700
attention actually rains

1777
01:52:59,710 --> 01:53:02,440
so radio can cause the ground to the west

1778
01:53:02,440 --> 01:53:06,890
the other possibility is that your sprinkler came on and

1779
01:53:06,890 --> 01:53:07,500
you know

1780
01:53:07,520 --> 01:53:09,300
sprinkled water all over

1781
01:53:09,320 --> 01:53:10,790
all over the graph

1782
01:53:16,940 --> 01:53:18,680
and sprinkler

1783
01:53:18,680 --> 01:53:22,700
we're going to zoom are independent in other words what time the sprinkler comes on

1784
01:53:22,700 --> 01:53:27,090
is independent of whether it rained or not is not very intelligent sprinkler just goes

1785
01:53:27,090 --> 01:53:29,740
on some sort of time are they

1786
01:53:30,090 --> 01:53:35,930
but whether the ground is wet is dependent both on rain sprinkler

1787
01:53:36,790 --> 01:53:41,430
the following graph which is a directed graph and i'll talk about directed graph

1788
01:53:41,640 --> 01:53:46,730
in a many is a very natural way of representing the relationship between these variables

1789
01:53:46,730 --> 01:53:53,980
were saying that essentially what this graph says that rain sprinkler are marginally independent

1790
01:53:55,190 --> 01:54:01,220
there are some other variable grounding web which is dependent on rain sprinkler

1791
01:54:01,240 --> 01:54:08,770
OK now how do we represent this as a an undirected graph or factor graph

1792
01:54:09,530 --> 01:54:12,020
as the undirected graph

1793
01:54:12,030 --> 01:54:18,100
because the grounding web depends on rain sprinkler is a factor

1794
01:54:18,100 --> 01:54:21,480
that involve all three of these variables

1795
01:54:21,540 --> 01:54:22,640
and so on

1796
01:54:22,690 --> 01:54:25,580
we would have fallen together

1797
01:54:25,620 --> 01:54:29,480
and the fact that we were just put about a year and that of three

1798
01:54:29,610 --> 01:54:31,780
these things together

1799
01:54:31,800 --> 01:54:34,360
now the problem with that is that

1800
01:54:34,400 --> 01:54:38,390
all the possible causes some

1801
01:54:38,400 --> 01:54:39,890
the fact variable

1802
01:54:39,900 --> 01:54:44,190
i have to be connected to to each other to represent the conditional independence relationships

1803
01:54:45,320 --> 01:54:48,650
and that's really unsatisfactory so you can imagine

1804
01:54:49,150 --> 01:54:54,680
some variables may have many many different causes all of which are independent but when

1805
01:54:54,680 --> 01:54:57,150
you try is the graph you draw all of these

1806
01:54:57,170 --> 01:55:02,940
connections between them and that really doesn't represent the fact that those variables are marginally

1807
01:55:06,970 --> 01:55:09,770
the truth of the situation is that

1808
01:55:09,780 --> 01:55:11,510
rain sprinkler

1809
01:55:11,550 --> 01:55:18,170
are marginally independent i e given nothing their are independent but they are conditionally independent

1810
01:55:18,170 --> 01:55:19,490
given the variable

1811
01:55:19,750 --> 01:55:21,970
g the ground was wet

1812
01:55:25,930 --> 01:55:28,900
two things cannot be represented by

1813
01:55:28,940 --> 01:55:34,210
any undirected graph or factor graph over these three variables

1814
01:55:36,900 --> 01:55:38,110
let me just right

1815
01:55:38,140 --> 01:55:40,440
explain why

1816
01:55:40,480 --> 01:55:41,350
is there

1817
01:55:41,350 --> 01:55:42,920
john here

1818
01:55:42,970 --> 01:55:48,080
they use

1819
01:55:48,090 --> 01:55:49,440
in the jar

1820
01:55:49,500 --> 01:55:56,630
i can use this

1821
01:55:56,680 --> 01:56:05,980
in box

1822
01:56:06,100 --> 01:56:09,760
doesn't look like chocolate and approx

1823
01:56:10,820 --> 01:56:11,900
all right

1824
01:56:12,980 --> 01:56:15,600
let's try to do this let's say

1825
01:56:24,380 --> 01:56:29,920
and sprinkler well what does this represent this represents

1826
01:56:29,970 --> 01:56:36,490
that rain and sprinkler are dependent

1827
01:56:36,530 --> 01:56:40,150
because there is a path between

1828
01:56:40,220 --> 01:56:41,780
which is wrong

1829
01:56:41,820 --> 01:56:46,170
and it represents something else is wrong but given that the ground was wet rain

1830
01:56:46,170 --> 01:56:48,220
sprinkler are independent

1831
01:56:48,240 --> 01:56:49,990
so this is this is not

1832
01:56:49,990 --> 01:56:53,770
the basic idea is that you don't have just one weight vector but you one

1833
01:56:53,770 --> 01:56:55,870
weight vector for each class

1834
01:56:55,880 --> 01:56:58,150
and when you want to do classification

1835
01:56:59,020 --> 01:57:00,410
you just compute

1836
01:57:00,420 --> 01:57:02,150
the inner product with the

1837
01:57:02,160 --> 01:57:05,240
that's what you want to classify each one vector

1838
01:57:05,250 --> 01:57:08,930
and classify the example into the class that has the highest

1839
01:57:08,990 --> 01:57:11,770
you can think about this as this warning problem

1840
01:57:11,780 --> 01:57:18,490
and the fact that has the highest value get

1841
01:57:18,540 --> 01:57:21,010
this can be formulated against quadratic programme

1842
01:57:21,020 --> 01:57:24,940
and so

1843
01:57:25,000 --> 01:57:27,650
so the sun

1844
01:57:29,930 --> 01:57:31,580
so what you get is

1845
01:57:31,600 --> 01:57:33,870
for each training example

1846
01:57:33,900 --> 01:57:36,620
you get a set of constraints that that's all

1847
01:57:37,720 --> 01:57:44,870
class has to have a higher discriminant each of the integral

1848
01:57:44,910 --> 01:57:47,700
and you get that for every training example then you have the right to project

1849
01:57:49,440 --> 01:57:54,120
so it's again a convex quadratic programme

1850
01:57:55,130 --> 01:57:56,700
so if you wanted to

1851
01:57:56,750 --> 01:58:01,380
apply this method now to structured prediction we have to solve the problem

1852
01:58:01,390 --> 01:58:05,730
first how to predict efficiently can just enumerate all the

1853
01:58:05,770 --> 01:58:07,400
that's too bad

1854
01:58:08,520 --> 01:58:13,470
to learn efficiently eventually have to solve this type of optimisation problem

1855
01:58:13,520 --> 01:58:16,660
and so it

1856
01:58:16,720 --> 01:58:20,300
well how do we bring this down to a manageable number of parameters we can't

1857
01:58:20,300 --> 01:58:23,110
really afford weight vector for each class

1858
01:58:23,120 --> 01:58:25,140
after many classes

1859
01:58:25,150 --> 01:58:26,800
let's start with the last one

1860
01:58:26,860 --> 01:58:30,660
how do we bring it down to a manageable number of parameters

1861
01:58:31,420 --> 01:58:33,770
so what we're going to do

1862
01:58:33,780 --> 01:58:36,030
if anything one way back to class

1863
01:58:36,030 --> 01:58:38,410
going to reformulate the problem

1864
01:58:38,450 --> 01:58:42,240
and introduce a joint feature map

1865
01:58:44,360 --> 01:58:48,530
so the joint feature map takes input the act

1866
01:58:48,540 --> 01:58:52,810
and the label y be trying to set up the vector of features

1867
01:58:52,820 --> 01:58:55,180
and then we have a fixed size feature vectors

1868
01:58:55,190 --> 01:58:57,400
that we multiply

1869
01:58:57,440 --> 01:58:58,940
and then to make a prediction

1870
01:58:58,990 --> 01:59:02,440
we simply solve this argmax problem

1871
01:59:02,610 --> 01:59:04,170
we have now is

1872
01:59:04,280 --> 01:59:06,130
well if we pick

1873
01:59:06,140 --> 01:59:08,420
feature maps small

1874
01:59:09,490 --> 01:59:14,070
then the number of ways that you have to learn more

1875
01:59:16,100 --> 01:59:18,940
in this sense of our

1876
01:59:19,000 --> 01:59:23,900
first problem we know brought it down to a fixed number of parameters doesn't depend

1877
01:59:23,900 --> 01:59:25,990
on the number of that

1878
01:59:26,000 --> 01:59:29,940
well it was just kind of syntactic manipulations of right

1879
01:59:30,010 --> 01:59:36,050
really have to think about well how to actually build the p

1880
01:59:36,110 --> 01:59:39,000
so let's take a look that

1881
01:59:39,010 --> 01:59:43,550
again financial passing what i can do is i can take

1882
01:59:45,580 --> 01:59:47,810
the gram

1883
01:59:47,900 --> 01:59:51,190
let's assume there an underlying context free grammar

1884
01:59:52,280 --> 01:59:56,950
the way that constructive he is that essentially introduced one feature

1885
01:59:57,000 --> 01:59:59,690
for each grammar rule and featured in the

1886
01:59:59,740 --> 02:00:03,560
in the graph

1887
02:00:03,620 --> 02:00:08,040
and then to represent the feature vector for x y pair

1888
02:00:08,050 --> 02:00:09,800
i simply want

1889
02:00:09,860 --> 02:00:13,370
often was each grammar rule applied

1890
02:00:13,480 --> 02:00:18,350
and that the value of the future so as opposed npvp was applied one to

1891
02:00:18,350 --> 02:00:22,750
generate one this was their time this was one

1892
02:00:28,610 --> 02:00:29,770
if you squint

1893
02:00:29,810 --> 02:00:32,200
and think about this for a second

1894
02:00:32,260 --> 02:00:34,140
this is actually now

1895
02:00:34,150 --> 02:00:36,160
taking the inner product

1896
02:00:41,120 --> 02:00:45,900
probabilistic or more generally weighted context free grammar

1897
02:00:46,570 --> 02:00:47,770
you think about it general

1898
02:00:47,860 --> 02:00:51,730
context and these w here could be the log probability

1899
02:00:51,740 --> 02:00:54,610
and the inner product is just the

1900
02:00:54,620 --> 02:00:58,310
the probability that tree

1901
02:00:58,360 --> 02:01:01,190
what this means this

1902
02:01:03,540 --> 02:01:05,010
this argmax

1903
02:01:05,020 --> 02:01:08,810
we can now compute with a CKY parsing

1904
02:01:08,820 --> 02:01:11,150
we can do that efficiently

1905
02:01:11,160 --> 02:01:14,650
and in particular we can do it officially despite the fact that this argmax actually

1906
02:01:14,650 --> 02:01:16,930
goes over an exponential number of

1907
02:01:18,140 --> 02:01:19,520
you can just in the nick

1908
02:01:22,900 --> 02:01:27,580
what this means is that we solve our second problem right

1909
02:01:27,640 --> 02:01:30,700
we have

1910
02:01:30,770 --> 02:01:34,610
and by picking the characterization in a particular way

1911
02:01:34,650 --> 02:01:39,050
we can now do prediction efficient right once we know the weight vector

1912
02:01:39,110 --> 02:01:40,510
we can predict

1913
02:01:40,550 --> 02:01:43,870
given x one y

1914
02:01:43,870 --> 02:01:48,270
OK this is the most simplistic representation that can think you can come up with

1915
02:01:48,270 --> 02:01:55,720
much more complicated each as long as they fit into context

1916
02:01:58,020 --> 02:01:59,100
you can do that

1917
02:01:59,130 --> 02:02:02,570
but that non-lethal blast problems

1918
02:02:14,390 --> 02:02:16,820
the last problem how to actually do this

1919
02:02:16,840 --> 02:02:20,110
the learning machines

1920
02:02:21,580 --> 02:02:25,460
let's think about about the multi class classification problems

1921
02:02:26,390 --> 02:02:29,060
that was structured prediction

1922
02:02:29,140 --> 02:02:32,710
what essentially one is that for every training example

1923
02:02:32,710 --> 02:02:36,350
the correct parse tree has the highest them

1924
02:02:37,010 --> 02:02:39,550
each of these is the training examples here

1925
02:02:39,570 --> 02:02:41,780
i want to correct one the red one

1926
02:02:41,830 --> 02:02:45,260
to come up to the top want to tweak my weights in that way that

1927
02:02:45,260 --> 02:02:46,450
that's true and

1928
02:02:46,490 --> 02:02:48,060
that is true

1929
02:02:48,080 --> 02:02:50,490
i managed to do that then i zero

1930
02:02:57,490 --> 02:03:01,870
how can i know formally that as an optimisation problem well

1931
02:03:01,890 --> 02:03:04,990
becomes again a convex quadratic programme

1932
02:03:05,030 --> 02:03:07,760
i simply introduce constraints saying


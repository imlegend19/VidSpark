1
00:00:00,000 --> 00:00:03,610
and you can you have a map of what Delta T and then you can

2
00:00:03,610 --> 00:00:06,880
it forms a two sphere around us

3
00:00:06,920 --> 00:00:12,170
and you can expand this in terms of le jean denomious YLM

4
00:00:12,190 --> 00:00:15,060
just as you would for a radiation pattern

5
00:00:15,190 --> 00:00:19,130
and the coefficient of the YLMs

6
00:00:19,170 --> 00:00:20,770
is ALM

7
00:00:20,810 --> 00:00:24,770
and if you summon sum over the different Ms

8
00:00:24,810 --> 00:00:32,110
of ALM squared this is defined as C sub L it's the power in the

9
00:00:34,270 --> 00:00:36,540
on wave number L on

10
00:00:36,590 --> 00:00:38,290
multipole L

11
00:00:38,380 --> 00:00:46,980
now this will give us information about the total mass density of the universe

12
00:00:47,020 --> 00:00:51,540
because it's something known as baryon acoustic oscillations

13
00:00:51,610 --> 00:00:56,920
something very interesting occurrs around the time of recombination

14
00:00:56,960 --> 00:01:01,560
before well before combination the universe was ionized

15
00:01:01,940 --> 00:01:05,460
when the universe was ionized

16
00:01:05,500 --> 00:01:06,880
the photons

17
00:01:06,920 --> 00:01:10,840
provided enormous pressure in restoring force

18
00:01:10,880 --> 00:01:14,810
for if you would try to move a baryon around

19
00:01:15,040 --> 00:01:19,920
so any perturbations in baryons would've oscillated

20
00:01:20,040 --> 00:01:21,610
like acoustic waves

21
00:01:21,630 --> 00:01:30,540
after recombination the universe is neutral the photons travel freely they are decoupled from baryons

22
00:01:30,540 --> 00:01:35,020
and perturbations can grow leading to structure formation

23
00:01:36,420 --> 00:01:38,130
I have

24
00:01:39,400 --> 00:01:43,270
that wasn't supposed to start yet

25
00:01:43,340 --> 00:01:48,750
oh well let me start it over

26
00:01:48,940 --> 00:01:50,400
so this will show

27
00:01:50,460 --> 00:01:53,500
the evolution of the profile

28
00:01:53,540 --> 00:01:57,290
of perturbations in dark matter in black

29
00:01:57,340 --> 00:01:59,210
baryons in blue

30
00:01:59,230 --> 00:02:03,520
and photons in red and neutrinos in green

31
00:02:03,520 --> 00:02:08,130
so that's the end point let's start it over where we start with

32
00:02:09,610 --> 00:02:11,960
ok we started there

33
00:02:13,880 --> 00:02:19,610
dark matter stays behind but the photons around the time of recombination is dragging the gas

34
00:02:20,520 --> 00:02:24,110
the photons decouple and then travel to us

35
00:02:24,190 --> 00:02:30,170
the photons have a memory of the original perturbations and

36
00:02:30,400 --> 00:02:36,520
in particular there is a lens scale

37
00:02:36,560 --> 00:02:43,040
that's imprinted on this pattern of perturbation which is the sound travel distance

38
00:02:43,080 --> 00:02:47,360
so the sonic horizon the sound horizon

39
00:02:47,400 --> 00:02:55,060
is known it can be calculated very accurately in terms of per cosmological parameters

40
00:02:55,540 --> 00:02:57,090
so there is some

41
00:02:58,770 --> 00:03:02,500
sound horizon on the last scattering surface

42
00:03:02,540 --> 00:03:05,540
and today we can view this

43
00:03:05,580 --> 00:03:11,380
sound horizon responsible for the peak in the microwave background radiation

44
00:03:11,740 --> 00:03:17,790
and the value that we would get relating the angle that we observe it

45
00:03:17,840 --> 00:03:22,750
and the physical size depends upon the geometry of the universe

46
00:03:22,840 --> 00:03:25,310
for different geometries

47
00:03:25,340 --> 00:03:32,590
corresponding to different values of omega whether the universe is flat space of spherically curved or

48
00:03:32,610 --> 00:03:37,440
hyperbolically curved the peak of angular power spectrum

49
00:03:37,480 --> 00:03:41,580
would be at different values of L

50
00:03:41,940 --> 00:03:46,440
this is the result from

51
00:03:46,460 --> 00:03:48,980
the latest W map results

52
00:03:49,020 --> 00:03:54,310
showing this beautiful acoustic peaks first predicted by Sakharov a long time ago

53
00:03:54,460 --> 00:03:57,520
and from the position of this acoustic peak

54
00:03:57,560 --> 00:03:59,580
the value of L

55
00:03:59,590 --> 00:04:02,270
you can determine that omega total

56
00:04:02,310 --> 00:04:04,840
is one to about

57
00:04:05,020 --> 00:04:10,080
well to one per cent with an error of about five per cent

58
00:04:10,400 --> 00:04:14,840
and there are also other observations at larger angular scale

59
00:04:14,840 --> 00:04:19,460
that give us confidence that these acoustic oscillations are there

60
00:04:19,500 --> 00:04:24,460
there will be better data on larger angular scales

61
00:04:24,730 --> 00:04:29,750
a smaller angular scales larger multipole moment from Planck

62
00:04:31,460 --> 00:04:37,440
for the past 20 years the predicted launch date of Planck has been exactly the date

63
00:04:37,440 --> 00:04:41,770
when the first collisions will be seen in the LHC

64
00:04:41,860 --> 00:04:50,630
although the schedule change this tight coupling has remained constant so it will launch in two thousand and eight

65
00:04:50,630 --> 00:05:01,090
they think on exactly the date when the first collisions are seen in the LHC ok so let me go to cosmic subtraction Omega

66
00:05:01,090 --> 00:05:05,900
total is one it is determined by the CMB

67
00:05:06,590 --> 00:05:12,020
there are many methods to determine the total matter density in the universe

68
00:05:12,190 --> 00:05:17,090
you can look at the dynamics of galaxies and clusters of galaxies I'll talk about

69
00:05:17,090 --> 00:05:18,730
this in the third lecture

70
00:05:19,190 --> 00:05:22,610
look at the result of weak lensing

71
00:05:22,690 --> 00:05:26,580
the measure the temperature of x-ray gas in clusters

72
00:05:26,610 --> 00:05:30,250
CMB tells us something about omega matter

73
00:05:30,290 --> 00:05:36,460
compare large-scale simulations to observations or to look at the power spectrum

74
00:05:36,460 --> 00:05:41,210
all of these results are consistent with Omega matter of point three

75
00:05:41,360 --> 00:05:46,040
so here is the subtraction cosmic subtraction

76
00:05:46,040 --> 00:05:50,340
one minus point three is not equal to zero

77
00:05:50,440 --> 00:05:54,230
one minus point three is equal to point seven

78
00:05:54,290 --> 00:05:58,980
let me repeat that in case there are string theorists here

79
00:05:58,980 --> 00:05:59,770
no they're not used to

80
00:05:59,790 --> 00:06:05,420
numbers so this is the total this isn't matter that's not equal to

81
00:06:05,420 --> 00:06:10,420
zero this is exactly what is deduced by looking at

82
00:06:10,420 --> 00:06:12,590
the supernova results

83
00:06:12,670 --> 00:06:19,580
so there's evidence from cosmic subtraction that there is something in the universe other than

84
00:06:19,580 --> 00:06:25,380
matter and that is conveniently described in terms of dark energy

85
00:06:25,380 --> 00:06:27,490
usually lists of documents

86
00:06:27,490 --> 00:06:32,160
from one side we usually want to see the most relevant document from every side

87
00:06:32,260 --> 00:06:35,590
two was still in documents from one site

88
00:06:35,650 --> 00:06:37,820
so it can be a bit more

89
00:06:37,820 --> 00:06:42,610
smart martin began group documents not based on document idea but based

90
00:06:43,810 --> 00:06:45,840
and it more

91
00:06:45,850 --> 00:06:51,660
so in this case architecture of retrieval box is a bit more complex

92
00:06:51,680 --> 00:06:54,590
so what we do about doing in this case

93
00:06:56,480 --> 00:06:59,270
small search engine

94
00:06:59,310 --> 00:07:00,840
and it

95
00:07:00,890 --> 00:07:04,890
it does everything that we discussed in this lecture

96
00:07:04,930 --> 00:07:06,780
so it gets wearing

97
00:07:06,810 --> 00:07:09,940
doing this of course needs

98
00:07:09,980 --> 00:07:11,180
from index

99
00:07:11,180 --> 00:07:13,260
doing molecule a marriage

100
00:07:13,320 --> 00:07:14,640
can do

101
00:07:15,850 --> 00:07:18,390
you can still for example we know that

102
00:07:18,430 --> 00:07:20,970
we don't need more than ten thousand

103
00:07:20,980 --> 00:07:24,230
results from every walk because you combine

104
00:07:24,270 --> 00:07:26,020
so everybody

105
00:07:26,030 --> 00:07:31,260
has some upper limit not more than one thousand documents and resources

106
00:07:31,890 --> 00:07:35,060
everything is very good with box

107
00:07:35,140 --> 00:07:41,060
they're standing areas into result aggregator that this result aggregator is

108
00:07:41,110 --> 00:07:44,690
pretty complex piece of software because

109
00:07:44,690 --> 00:07:48,060
it's supposed to do supposed to do something

110
00:07:48,140 --> 00:07:51,810
version of this results based on ways to get

111
00:07:51,820 --> 00:07:53,940
from retrieval of

112
00:07:53,940 --> 00:07:57,090
but it's also very

113
00:07:57,100 --> 00:08:00,350
well it's also to go and i can

114
00:08:00,380 --> 00:08:05,230
show you the most of search engines right now are are using now the same

115
00:08:06,740 --> 00:08:09,520
very very close to this approach

116
00:08:09,520 --> 00:08:11,720
the disadvantage of this approach

117
00:08:14,060 --> 00:08:16,660
it means that every query

118
00:08:16,680 --> 00:08:20,730
we need to say to all of

119
00:08:20,760 --> 00:08:24,680
if we have all clusters of documents

120
00:08:24,730 --> 00:08:26,400
we divided into

121
00:08:26,430 --> 00:08:27,920
ten books

122
00:08:27,970 --> 00:08:31,740
of course the real time beautification because we need to let

123
00:08:31,760 --> 00:08:33,470
but you can for example

124
00:08:34,480 --> 00:08:40,090
this document not on one about and the number of books and doing some

125
00:08:40,090 --> 00:08:43,810
duplication or something like that but in any case

126
00:08:43,840 --> 00:08:45,160
every query

127
00:08:45,190 --> 00:08:47,850
should be sent to all

128
00:08:50,390 --> 00:08:52,880
we have documents and what's going on

129
00:08:52,890 --> 00:08:55,640
if you look into statistics

130
00:08:55,650 --> 00:08:57,640
of all queries

131
00:08:57,650 --> 00:09:00,270
usually it's not very uniform

132
00:09:00,270 --> 00:09:03,480
and what you will see this is

133
00:09:03,490 --> 00:09:08,190
you can balance cluster around

134
00:09:09,480 --> 00:09:11,350
queries are going to work

135
00:09:11,550 --> 00:09:16,730
and all boxes are doing the same in this century

136
00:09:16,780 --> 00:09:20,660
so it's linear scale so it's horizontal scale

137
00:09:21,650 --> 00:09:26,130
you need to use all computers in your class

138
00:09:26,130 --> 00:09:28,760
and maybe you can do your job

139
00:09:28,810 --> 00:09:32,380
i went to see if you can select in this way

140
00:09:32,390 --> 00:09:36,970
that you can send queries on the number of people

141
00:09:37,020 --> 00:09:39,480
and the way the you can do

142
00:09:39,520 --> 00:09:44,100
that based on this

143
00:09:46,340 --> 00:09:49,430
we can do partitioning

144
00:09:49,440 --> 00:09:52,110
the simplest example is

145
00:09:52,140 --> 00:09:55,920
what we can do begin decided OK

146
00:09:56,360 --> 00:09:58,480
it's an example

147
00:09:58,510 --> 00:10:04,310
there are two types of users users harder for queries and use for not porn

148
00:10:05,510 --> 00:10:08,720
and for queries summaries but if

149
00:10:08,730 --> 00:10:10,320
so what you can do

150
00:10:10,340 --> 00:10:11,270
you can

151
00:10:11,280 --> 00:10:17,030
create a classifier for in any case need to do classifier for queries if you're

152
00:10:17,030 --> 00:10:21,230
doing public internet search engine for unknown reasons

153
00:10:21,270 --> 00:10:25,030
also you have the same classifier for page

154
00:10:25,060 --> 00:10:26,770
and you can say OK

155
00:10:26,780 --> 00:10:29,060
this is a partition of

156
00:10:29,070 --> 00:10:30,640
for internet

157
00:10:30,640 --> 00:10:33,690
and this is a partition of normal increment

158
00:10:33,740 --> 00:10:36,190
so if user is that query

159
00:10:36,940 --> 00:10:38,550
many users are

160
00:10:43,530 --> 00:10:46,140
so they don't use four class

161
00:10:46,150 --> 00:10:51,890
so if you can default have saved search these family feuds or whatever

162
00:10:51,940 --> 00:10:53,950
so we created this

163
00:10:53,970 --> 00:10:56,600
partition of called the internet

164
00:10:56,650 --> 00:10:58,260
results for

165
00:10:58,270 --> 00:10:59,640
and reports

166
00:10:59,650 --> 00:11:04,480
two thousand boxes into this partition so we have a lot of redundancy and it's

167
00:11:04,480 --> 00:11:05,820
pretty fast

168
00:11:05,840 --> 00:11:06,720
and we have

169
00:11:06,740 --> 00:11:13,180
smaller palms partition where all water so much more lauded what quality of georgia's national

170
00:11:13,240 --> 00:11:14,970
not important here

171
00:11:16,010 --> 00:11:18,180
everything is much simpler than

172
00:11:19,390 --> 00:11:22,630
the greatest partitions and we divided it into

173
00:11:25,230 --> 00:11:29,240
this is example of partition by document quality

174
00:11:29,260 --> 00:11:30,310
so we can

175
00:11:30,320 --> 00:11:32,940
do this but usually we can support

176
00:11:32,940 --> 00:11:39,600
very good documents in one part waterfall system and by default standing query to this

177
00:11:40,650 --> 00:11:47,020
if you don't have good document high quality documents there is sending this query to

178
00:11:47,020 --> 00:11:50,060
bigger and slower partition of

179
00:11:50,690 --> 00:11:52,660
low quality documents

180
00:11:52,720 --> 00:11:59,270
but the intuition behind this is that if a user is doing collaboration he

181
00:11:59,280 --> 00:12:02,810
she is looking for a high quality documents

182
00:12:02,850 --> 00:12:08,060
and usually the internet there is no such exception of high quality documents there lot

183
00:12:09,240 --> 00:12:11,190
there lot of sizes

184
00:12:11,190 --> 00:12:12,720
low quality

185
00:12:13,640 --> 00:12:18,470
high quality documents are usually on a number of so you can you can create

186
00:12:18,470 --> 00:12:24,020
this partitioning don't send queries to all boxes in your in your class

187
00:12:24,020 --> 00:12:26,840
you can do it based on geography

188
00:12:26,940 --> 00:12:29,890
you can know from IP

189
00:12:29,900 --> 00:12:31,930
what like asians uniform

190
00:12:31,940 --> 00:12:34,840
and according to the whole cluster bomb

191
00:12:34,850 --> 00:12:38,350
divide the document that belongs to this

192
00:12:38,350 --> 00:12:40,600
and dad hopefully

193
00:12:40,610 --> 00:12:43,360
unless they're making a joke right

194
00:12:43,370 --> 00:12:45,510
so so how does that work i mean

195
00:12:45,510 --> 00:12:50,060
if you think of it as a math problem there's some infinite set of objects

196
00:12:50,060 --> 00:12:53,370
there's an infinite subset of those that set of courses and the child is able

197
00:12:53,370 --> 00:12:57,790
to mostly grass the boundaries of that subset from just a few points randomly sampled

198
00:12:57,790 --> 00:13:00,830
was and if you want to have a sense of what this is like

199
00:13:00,850 --> 00:13:03,210
as an adult

200
00:13:03,230 --> 00:13:06,030
you see we show you these objects here and then we give you a couple

201
00:13:06,030 --> 00:13:07,900
of examples in have two five

202
00:13:07,910 --> 00:13:11,460
this these are objects from an alien world and that's a word in alien language

203
00:13:11,730 --> 00:13:14,340
and i have a pretty good job are you can do a pretty good job

204
00:13:14,340 --> 00:13:16,520
of telling me which other things are two which are

205
00:13:16,580 --> 00:13:19,120
so let's try that have about this one yes or no

206
00:13:19,130 --> 00:13:24,890
this one

207
00:13:25,660 --> 00:13:34,460
more certainly there

208
00:13:35,030 --> 00:13:36,800
that's why you bayesian OK

209
00:13:36,810 --> 00:13:40,620
right so most people said no on that one but there was a brief still

210
00:13:40,650 --> 00:13:44,420
a little bit of hesitation which is one way behaviorally in the lab to diagnose

211
00:13:44,420 --> 00:13:46,350
uncertainty reaction

212
00:13:46,370 --> 00:13:49,840
so here you have a demonstration but again from just a few examples in this

213
00:13:49,890 --> 00:13:53,530
work basically the same if i give you one example you can get almost perfectly

214
00:13:53,530 --> 00:13:57,040
correct with a little bit of uncertainty kind at the edges of the concept how

215
00:13:57,040 --> 00:13:58,400
does that work

216
00:13:59,280 --> 00:14:03,020
to go back to the scene you raised

217
00:14:03,040 --> 00:14:06,890
you know that this is the slogan according to theory aerodynamics bumblebee can fly well

218
00:14:06,890 --> 00:14:11,180
you might say according to conventional statistical learning theory like you know that nick's theories

219
00:14:11,180 --> 00:14:18,130
of generalisation error or balance PAC learning theory this should be possible you should be

220
00:14:18,130 --> 00:14:21,820
able to learn a concept from just a few examples let alone just one positive

221
00:14:21,820 --> 00:14:26,130
example whereas all the negative examples where the masses of data that you know the

222
00:14:26,130 --> 00:14:30,620
positives and negatives that something like the perceptron needs to find the right maximum margin

223
00:14:32,050 --> 00:14:37,290
to take another example where i think we need to raise questions about our conventional

224
00:14:37,290 --> 00:14:42,020
theories learning think about the oldest problem in statistics learning about the causal structure of

225
00:14:42,020 --> 00:14:46,770
the world from evidence just so we learn the basic statistics class correlation doesn't imply

226
00:14:46,770 --> 00:14:53,490
causation it secured causation with in some cases saying the right randomized controlled experiments can

227
00:14:53,490 --> 00:14:58,880
identify causation but what people do do we go out and conduct randomized clinical trials

228
00:14:59,120 --> 00:15:04,040
with extensive datasets well you think about intuitively how you might make causal inference the

229
00:15:04,040 --> 00:15:07,270
kind of thing that's a clinical trial what do we know we are always trying

230
00:15:07,270 --> 00:15:09,960
to make inferences like this like you know i get called somebody tells you about

231
00:15:09,960 --> 00:15:13,490
some new herbal remedy does actually help you get over the cold more quickly or

232
00:15:13,490 --> 00:15:17,300
not well you know i might do a little informal experimenter might not even think

233
00:15:17,300 --> 00:15:20,440
about this consciously but sometimes i remember to take the drug in time other times

234
00:15:20,440 --> 00:15:24,710
i don't i can keep track of whether i had a short called along cold

235
00:15:24,710 --> 00:15:28,260
and i might make a data table like this you know unconsciously of course

236
00:15:28,340 --> 00:15:33,130
but people are going to be making inferences from very very sparse state i mean

237
00:15:33,130 --> 00:15:36,650
just a few examples just a few data points in each cell

238
00:15:36,740 --> 00:15:40,860
which you know if you compute kai square tried to do conventional statistical measure association

239
00:15:41,510 --> 00:15:45,570
it is going to give you anything particularly meaningful but we'll see tom griffiths we'll

240
00:15:45,570 --> 00:15:47,710
talk about this i believe later on in the

241
00:15:47,840 --> 00:15:49,800
in the course

242
00:15:49,820 --> 00:15:55,800
that people people's causal inferences from very little data are surprisingly rational and reliable might

243
00:15:55,800 --> 00:15:58,450
have something to do with how even a young child is able to learn about

244
00:15:58,450 --> 00:16:01,880
the causal structure of the world from not just

245
00:16:01,970 --> 00:16:05,680
this little data but you think about it to to take an example from human

246
00:16:05,860 --> 00:16:10,130
how does a child learn when they first touch a hot stove not to touch

247
00:16:10,140 --> 00:16:11,330
stove again

248
00:16:11,560 --> 00:16:13,730
but that was touching the stove burned them

249
00:16:13,760 --> 00:16:16,950
so do they do something like this do they keep track of all the times

250
00:16:16,950 --> 00:16:19,630
in which they came up to the stove in the either touch to didn't touch

251
00:16:20,010 --> 00:16:22,840
got burned didn't get burned no

252
00:16:22,880 --> 00:16:24,850
once is enough

253
00:16:25,080 --> 00:16:29,970
right or to take another example there is actually a button on the wall but

254
00:16:29,970 --> 00:16:32,770
let's say there was and i went over here in press it and just at

255
00:16:32,770 --> 00:16:34,780
the moment i pressed

256
00:16:34,790 --> 00:16:38,960
the screen started to go and so what we think well everybody here would think

257
00:16:39,130 --> 00:16:42,040
i guess this is what makes the screen go

258
00:16:42,060 --> 00:16:44,570
probably makes go down to present again

259
00:16:44,590 --> 00:16:48,400
or suppose i press the button and like all the lights in the auditorium go

260
00:16:48,710 --> 00:16:53,130
well then just that one suspicious coincidence combined with all the other stuff you know

261
00:16:53,130 --> 00:16:57,530
about how causal causality work somehow auditoriums work is enough to say OK i think

262
00:16:58,850 --> 00:17:02,510
that what makes the lights go off maybe turns back on again and this ability

263
00:17:02,510 --> 00:17:08,390
to infer new causal relation from one example this one suspicious coincidence is really quite

264
00:17:08,390 --> 00:17:12,630
powerful i mean almost to the point that you have a misguided or what potential

265
00:17:12,630 --> 00:17:16,590
for misuse of the power you think about all the causal relations you could infer

266
00:17:16,590 --> 00:17:19,370
from this suppose i oneof here in press this button

267
00:17:19,380 --> 00:17:22,810
and all of a sudden

268
00:17:22,810 --> 00:17:26,600
the two have the other terms are split and these and the chairs on the

269
00:17:26,900 --> 00:17:31,240
over here over there and underneath was revealed the swimming pool

270
00:17:31,260 --> 00:17:33,480
has anybody seen it's a wonderful life

271
00:17:33,510 --> 00:17:37,160
the gym is chemistry what actually happens very high school gym

272
00:17:37,420 --> 00:17:42,760
that's where i got the idea but you know these crazy italian architects they could

273
00:17:42,770 --> 00:17:43,790
think of anything

274
00:17:43,900 --> 00:17:47,980
i mean that's possible that happened ITO that's the button

275
00:17:48,040 --> 00:17:54,160
that makes the auditorium split in half to reveal the hidden something for us

276
00:17:54,160 --> 00:17:55,820
so from the terminal state

277
00:17:55,840 --> 00:18:01,090
so here everything about the terminal state would see the value that achieved

278
00:18:01,140 --> 00:18:04,440
at terminal a blackjack you only when i was in the end you don't get

279
00:18:04,460 --> 00:18:06,790
an immediate words

280
00:18:10,430 --> 00:18:14,270
and what you need to know anything on monte carlo methods is that

281
00:18:14,290 --> 00:18:17,130
these are typically independent of the

282
00:18:18,700 --> 00:18:23,990
the from one state is independent of the size of the state space right nice

283
00:18:24,040 --> 00:18:28,070
probably of among others however if you would a very state of course this upon

284
00:18:28,070 --> 00:18:28,960
the state space

285
00:18:32,240 --> 00:18:36,080
OK now i just talked about how to

286
00:18:36,120 --> 00:18:38,780
evaluate the policy using monte carlo methods

287
00:18:38,800 --> 00:18:42,790
but really blackjack you don't want to violate the policy you want to learn the

288
00:18:42,790 --> 00:18:43,860
best policy

289
00:18:43,900 --> 00:18:48,280
OK so how do do that it is a policy iteration framework for start with

290
00:18:48,280 --> 00:18:50,400
some current policy pi

291
00:18:50,450 --> 00:18:53,950
great evaluate the value of pi

292
00:18:53,970 --> 00:18:56,920
in there and try improve policy but we only have one problem we get an

293
00:18:56,920 --> 00:18:58,180
improvement steps

294
00:18:59,040 --> 00:19:04,020
what's more sampling let's say we don't have the condition function

295
00:19:04,230 --> 00:19:09,970
OK but the best example so it's in the general problem

296
00:19:10,020 --> 00:19:13,200
we don't tend to function could be robot

297
00:19:13,770 --> 00:19:22,550
if you only have the value function

298
00:19:23,540 --> 00:19:24,470
it is found

299
00:19:24,480 --> 00:19:30,550
so let's let's look at how we compute the policy earlier

300
00:19:30,640 --> 00:19:33,200
i said the policy

301
00:19:33,250 --> 00:19:35,240
with respect to some value function v

302
00:19:35,260 --> 00:19:36,550
state s

303
00:19:37,130 --> 00:19:39,860
is the argmax

304
00:19:39,910 --> 00:19:46,040
that is the argument a which maximizes the expression here

305
00:19:46,060 --> 00:19:48,040
the company

306
00:19:48,170 --> 00:19:51,930
are as a

307
00:19:52,090 --> 00:19:55,470
what i get for taking this action state

308
00:19:56,480 --> 00:19:58,890
discounted reward which is

309
00:19:58,900 --> 00:20:02,510
gamma time to some role next state

310
00:20:02,570 --> 00:20:04,860
the probability of getting the text states

311
00:20:04,900 --> 00:20:07,220
given the current state and actions

312
00:20:08,590 --> 00:20:10,570
policy undervalue v

313
00:20:10,620 --> 00:20:12,630
the value i

314
00:20:12,650 --> 00:20:15,000
i believe or no i can get

315
00:20:15,020 --> 00:20:19,320
that's fine

316
00:20:19,330 --> 00:20:21,370
OK this is just sort of that

317
00:20:21,390 --> 00:20:23,090
the back of the wrist

318
00:20:23,110 --> 00:20:25,010
working with

319
00:20:25,070 --> 00:20:27,920
we actually have a which maximizes

320
00:20:27,920 --> 00:20:29,210
this value

321
00:20:30,890 --> 00:20:34,770
as priors next day

322
00:20:37,300 --> 00:20:42,270
you get or to be in the current state

323
00:20:42,280 --> 00:20:46,090
OK and then you look at the best action OK

324
00:20:46,110 --> 00:20:52,390
then assuming actions sticks or that you evaluate max if police action in individually in

325
00:20:52,420 --> 00:20:55,080
action disperse their next state

326
00:20:55,140 --> 00:20:59,290
it's not for probability the text eight times the value to get the next

327
00:20:59,400 --> 00:21:01,810
and you would take the action a

328
00:21:01,890 --> 00:21:03,720
maximize is this

329
00:21:03,750 --> 00:21:07,640
this is what call these key values

330
00:21:07,650 --> 00:21:09,430
the quality

331
00:21:09,480 --> 00:21:11,720
of doing

332
00:21:11,750 --> 00:21:15,930
action a in state s so you can also see

333
00:21:15,980 --> 00:21:18,440
the policy as the argmax

334
00:21:18,450 --> 00:21:20,540
over a

335
00:21:20,570 --> 00:21:25,910
qs a

336
00:21:26,280 --> 00:21:33,910
now what's the problem if i don't know the transition function

337
00:21:33,980 --> 00:21:38,860
ten i computers five dollars transfer function

338
00:21:39,030 --> 00:21:42,620
first of all where the transition function here

339
00:21:42,670 --> 00:21:44,070
it's this thing right

340
00:21:44,200 --> 00:21:46,960
that's too

341
00:21:46,980 --> 00:21:50,390
how you get next is given you current take action

342
00:21:50,610 --> 00:21:53,650
so what's the problem if it if i don't know

343
00:21:53,670 --> 00:21:56,480
my transition function t

344
00:21:56,560 --> 00:21:58,310
calculate this policy

345
00:21:58,420 --> 00:22:03,320
right OK you you just don't know these probabilities

346
00:22:03,400 --> 00:22:05,570
OK so

347
00:22:05,630 --> 00:22:09,480
it's interesting when you come up with a solution to talk about values the

348
00:22:09,540 --> 00:22:11,630
when you look at

349
00:22:11,650 --> 00:22:16,010
are all solutions you most often talk about two that because you have to

350
00:22:16,070 --> 00:22:19,110
so here's the idea

351
00:22:19,110 --> 00:22:22,790
now look at the bottom equation the q value

352
00:22:22,810 --> 00:22:27,450
i'm not going to join the estimate the value of all actions from all states

353
00:22:27,530 --> 00:22:29,930
q that's under policy pi

354
00:22:29,940 --> 00:22:32,310
looks just like the pipe before

355
00:22:32,330 --> 00:22:37,140
the only additional constraint is that i'm sure the first actually i take

356
00:22:37,180 --> 00:22:40,050
actually a number actions in the policy pi

357
00:22:40,070 --> 00:22:44,270
which i take for articles one to infinity but t zero

358
00:22:44,320 --> 00:22:46,010
my initial action is a

359
00:22:46,060 --> 00:22:49,440
OK i see only given to that the definition of the q value

360
00:22:49,440 --> 00:22:53,190
take the given action then follow policy after that

361
00:22:53,240 --> 00:22:55,120
so that you get

362
00:22:55,130 --> 00:22:59,170
now it turns out that i can easily compute the q values as i did

363
00:22:59,170 --> 00:23:03,120
that i had added the state values

364
00:23:03,720 --> 00:23:06,710
this means that i sample now for every state and action

365
00:23:06,800 --> 00:23:10,260
and what about the q values you can see that you don't need a transition

366
00:23:10,260 --> 00:23:12,220
function you can just take

367
00:23:12,260 --> 00:23:14,460
the argmax actually ready to determine

368
00:23:14,500 --> 00:23:17,650
the policy pi

369
00:23:19,830 --> 00:23:30,370
OK so right i'm designing for simplicity probably that that they are functions given but

370
00:23:30,370 --> 00:23:35,010
you might want to ask if it was not given

371
00:23:35,740 --> 00:23:39,080
then you can also sample from that that's fine

372
00:23:39,320 --> 00:23:44,060
because in the mind of is the q value here you december from

373
00:23:44,120 --> 00:23:47,310
is it OK

374
00:23:47,480 --> 00:23:52,840
so again my two values is just sampling

375
00:23:52,860 --> 00:23:58,200
who wrote

376
00:23:58,210 --> 00:24:03,720
so far values assembled from this the value function just among states for q values

377
00:24:03,810 --> 00:24:08,360
december in this part thing which just includes the action the first action

378
00:24:09,550 --> 00:24:13,110
we can use monte carlo algorithm again just keep the average returns to see first

379
00:24:13,110 --> 00:24:14,170
team action

380
00:24:14,210 --> 00:24:16,320
and think the argmax

381
00:24:16,320 --> 00:24:17,550
where this one

382
00:24:18,300 --> 00:24:19,780
that's complete darkness

383
00:24:19,840 --> 00:24:21,860
and there was this spot

384
00:24:21,860 --> 00:24:25,670
the second starship full rights query on one

385
00:24:25,670 --> 00:24:28,760
has darkness if you bring them closer

386
00:24:28,820 --> 00:24:30,240
your brains will say

387
00:24:31,760 --> 00:24:34,650
no that's not sources that's really only one source

388
00:24:34,700 --> 00:24:36,070
and we call this

389
00:24:36,900 --> 00:24:40,510
the rayleigh criterion of resolution

390
00:24:40,510 --> 00:24:43,420
and that really criterion of resolution therefore

391
00:24:43,440 --> 00:24:47,300
is that the separation between the two

392
00:24:47,380 --> 00:24:50,860
light beams bars or the headlights from the car

393
00:24:51,630 --> 00:24:54,420
separation has to be larger than this angle

394
00:24:54,470 --> 00:24:58,400
and is the function of a if a is larger than

395
00:24:58,450 --> 00:24:59,380
that angle

396
00:24:59,400 --> 00:25:00,050
can be

397
00:25:00,130 --> 00:25:03,170
substantially smaller

398
00:25:03,180 --> 00:25:05,050
and this is what we call

399
00:25:05,050 --> 00:25:06,130
the diffraction

400
00:25:07,260 --> 00:25:08,940
on angular resolution

401
00:25:08,950 --> 00:25:11,320
it doesn't matter where you have the pinhole

402
00:25:11,320 --> 00:25:13,880
or whether you have a lenses

403
00:25:13,900 --> 00:25:18,970
circulants that we use these telescopes or whether you have concave mirrors which we use

404
00:25:18,970 --> 00:25:20,340
these telescopes

405
00:25:20,360 --> 00:25:22,070
in all cases

406
00:25:22,070 --> 00:25:23,950
you always stuck

407
00:25:23,970 --> 00:25:25,670
with the ideas

408
00:25:25,720 --> 00:25:28,380
at best that's the best you can ever do

409
00:25:28,380 --> 00:25:30,320
that is the angular separation

410
00:25:30,340 --> 00:25:32,070
that theta

411
00:25:32,090 --> 00:25:34,050
quality the fate of one

412
00:25:34,090 --> 00:25:36,450
is that one point two

413
00:25:37,050 --> 00:25:40,090
divided by a that is then

414
00:25:41,920 --> 00:25:44,300
if you take a lens

415
00:25:44,340 --> 00:25:46,780
which has a diameter a

416
00:25:46,840 --> 00:25:49,490
of about twenty centimetres

417
00:25:49,550 --> 00:25:51,470
then that translates

418
00:25:51,470 --> 00:25:53,260
in two with theta one

419
00:25:53,300 --> 00:25:57,010
of about half an hour second for five thousand angstroms

420
00:25:57,030 --> 00:25:58,200
so i take

421
00:25:59,360 --> 00:26:03,530
five thousand angstroms and from ten to the minus

422
00:26:03,590 --> 00:26:04,760
ten metres

423
00:26:04,780 --> 00:26:06,800
so if anyone then becomes

424
00:26:06,820 --> 00:26:08,530
half arc seconds

425
00:26:08,550 --> 00:26:10,990
o point five

426
00:26:11,050 --> 00:26:13,950
arc seconds

427
00:26:13,970 --> 00:26:17,030
the document is one sixty is over the art degree

428
00:26:17,050 --> 00:26:20,150
and our second is sixty times lower than that

429
00:26:20,220 --> 00:26:22,440
and so if a

430
00:26:23,300 --> 00:26:25,400
two point four metres

431
00:26:25,440 --> 00:26:29,090
telescope two point four meter telescope that's a real biggy

432
00:26:29,130 --> 00:26:30,650
then theta one

433
00:26:30,730 --> 00:26:32,470
would be

434
00:26:32,490 --> 00:26:35,550
approximately one twenty fifth

435
00:26:35,570 --> 00:26:38,110
of arc second

436
00:26:38,280 --> 00:26:43,510
so the larger you make your telescope the better angular resolution you would have

437
00:26:43,550 --> 00:26:46,670
this angular resolution is twelve times better

438
00:26:46,680 --> 00:26:47,650
then this one

439
00:26:47,740 --> 00:26:50,490
because a is twelve times larger

440
00:26:50,530 --> 00:26:54,110
so now you may think that if you take it to point four meter telescope

441
00:26:54,110 --> 00:26:56,700
on the ground and you look at stars

442
00:26:56,780 --> 00:27:00,970
the two stars equally bright you will be able to tell them apart

443
00:27:01,090 --> 00:27:02,240
if they are

444
00:27:02,300 --> 00:27:06,340
so far away from each other than one twenty fifth of an arc second that

445
00:27:06,340 --> 00:27:07,800
is not true

446
00:27:07,970 --> 00:27:12,300
contrary it's very bad you can even tell them apart often when they are half

447
00:27:12,300 --> 00:27:13,700
a second apart

448
00:27:13,700 --> 00:27:18,030
and the reason for that is not the the diffraction limitation is going to kill

449
00:27:18,030 --> 00:27:22,110
you but the reason is that the air is always turbulence

450
00:27:22,170 --> 00:27:24,570
and is the turbulence on the air

451
00:27:24,590 --> 00:27:25,780
that makes the

452
00:27:26,700 --> 00:27:32,740
the diffraction limited imitates itself is very small move around on new photographic plates it

453
00:27:32,740 --> 00:27:36,740
moved it around in a matter of ten seconds over an area which itself could

454
00:27:36,740 --> 00:27:40,650
be as large as one second astronomers call that seeing

455
00:27:40,670 --> 00:27:45,360
so when you look at your picture the whole story smeared out over an area

456
00:27:45,360 --> 00:27:48,110
which is in angular size one

457
00:27:48,130 --> 00:27:52,740
our second or maybe half an hour second best so you can never achieve this

458
00:27:52,740 --> 00:27:54,050
from the ground

459
00:27:54,090 --> 00:27:57,090
so all telescopes from the ground without exception

460
00:27:57,110 --> 00:28:01,070
i can do it best half an hour second they cannot do much better because

461
00:28:01,070 --> 00:28:04,380
of the air turbulence and this is not the great thing about the hubble space

462
00:28:05,570 --> 00:28:09,590
is up there may be down there whichever it is i don't know where maybe

463
00:28:09,590 --> 00:28:11,940
jeffrey knows what it is but it is somewhere

464
00:28:12,970 --> 00:28:15,010
hubble has no air

465
00:28:15,030 --> 00:28:16,490
and so

466
00:28:16,530 --> 00:28:19,360
doesn't suffer of the air turbulence

467
00:28:19,360 --> 00:28:20,200
and so

468
00:28:20,220 --> 00:28:23,820
hall of mirrors are indeed diffraction limited

469
00:28:23,840 --> 00:28:24,990
and humble

470
00:28:25,050 --> 00:28:29,530
has a mirror which is two point four meters diameter and indeed at five thousand

471
00:28:29,530 --> 00:28:35,610
angstrom i checked that yesterday was people table space telescope in the is diffraction limited

472
00:28:35,610 --> 00:28:40,630
and bubble has an angular resolution of five thousand angstroms which is about one twenty

473
00:28:40,630 --> 00:28:42,220
fifth of an arc seconds

474
00:28:42,280 --> 00:28:44,820
and at shorter wavelengths it's even better

475
00:28:44,820 --> 00:28:47,170
and the longer wavelengths it is a little

476
00:28:48,700 --> 00:28:52,950
and so i would like to show you least one picture of hubble without going

477
00:28:52,950 --> 00:28:54,260
into the details

478
00:28:54,300 --> 00:28:55,510
of what

479
00:28:55,510 --> 00:28:57,510
you're seeing of the astro

480
00:28:57,550 --> 00:29:00,670
if you astronomy and that's the one that is coming up it's a very famous

481
00:29:02,650 --> 00:29:04,130
hubble made

482
00:29:04,170 --> 00:29:06,470
several years ago

483
00:29:06,510 --> 00:29:10,800
this is a picture of a supernova explosion

484
00:29:10,840 --> 00:29:13,360
john if we can have the slide

485
00:29:15,070 --> 00:29:17,550
you're looking here at an explosion

486
00:29:17,550 --> 00:29:22,340
called supernova nineteen eighty seven a which occurred in february nineteen eighty seven

487
00:29:22,490 --> 00:29:26,300
this object is hundred fifty thousand light years away from us

488
00:29:26,320 --> 00:29:27,760
that means the explosion

489
00:29:27,780 --> 00:29:31,260
really took place to place on the fifty thousand years ago

490
00:29:31,360 --> 00:29:35,490
but we saw it for the first time in february eighty seven

491
00:29:35,550 --> 00:29:39,170
and without going into the details of what you're looking at which is of course

492
00:29:39,170 --> 00:29:42,450
very fascinating but that's not the objective today

493
00:29:42,510 --> 00:29:46,130
i wanted to appreciate that this distance here

494
00:29:46,150 --> 00:29:46,950
is one

495
00:29:46,970 --> 00:29:48,280
arc seconds

496
00:29:48,320 --> 00:29:51,090
and look at the incredible detail the table

497
00:29:51,760 --> 00:29:52,650
show you

498
00:29:52,650 --> 00:29:57,130
of those already but we'll we'll we'll obviously talk about some more such as the support

499
00:29:57,130 --> 00:30:01,750
vector machine and so on so this is the the the sort of big-picture

500
00:30:01,750 --> 00:30:09,870
we're aiming at it's sort of  plug and play approach to to analyzing data  I mean

501
00:30:09,880 --> 00:30:15,310
maybe I should also mention that you know there are many sort of  extensions of these ideas

502
00:30:15,310 --> 00:30:21,170
that are subjects of  current research for instance you might have multiple kernels how do

503
00:30:21,170 --> 00:30:28,430
you deal with that how do you combine kernels and learn a combination of kernels

504
00:30:28,430 --> 00:30:33,710
as part of a learning process how do you handle problems where your outputs are

505
00:30:33,730 --> 00:30:39,590
more complex than just a classification or a regression maybe there's some structure in your output how

506
00:30:39,610 --> 00:30:43,910
do you learn that and so on so there's you know a whole range of

507
00:30:43,910 --> 00:30:51,030
research going on that are extending these methods and you know using unlabeled data to enhance your learning

508
00:30:51,030 --> 00:30:57,830
and so on and so on but I'm not gonna talk about those I may just allude to them as we go through

509
00:30:57,830 --> 00:31:01,470
okay so what I wanted to  a little bit more about preprocessing now leading

510
00:31:01,470 --> 00:31:06,870
up to kernel PCA as an example of an algorithm preprocessing algorithm that can be

511
00:31:06,870 --> 00:31:13,220
run in a kernel defined feature space but this this really this slide is really

512
00:31:13,220 --> 00:31:19,190
a caveat and it's a general sort a caveat about kernel methods and if

513
00:31:19,190 --> 00:31:24,210
you like it's one of the key weaknesses of kernel methods in some sense the point

514
00:31:24,210 --> 00:31:28,790
is that actually doing feature selection in in a kernel defined feature space is not

515
00:31:28,790 --> 00:31:37,330
possible and the reason is that up to any orthogonal transformation of your feature space

516
00:31:37,330 --> 00:31:44,410
if there was any change of basis the the kernel is remains unchanged so your feature space is

517
00:31:44,410 --> 00:31:52,110
only determined by the kernel up to any orthogonal transformation of your representation of your

518
00:31:52,110 --> 00:31:55,770
of your basis and the reason for that is is very simple to see let's

519
00:31:55,770 --> 00:32:02,010
imagine we take a transformation of our representation by some orthogonal matrix U to

520
00:32:02,010 --> 00:32:07,590
create a new representation phi-hat so U is a transformation that satisfies U prime

521
00:32:07,600 --> 00:32:15,130
U is the identity well let's compute the kernel kappa hat corresponding to this new representation okay

522
00:32:15,130 --> 00:32:19,330
it's U phi of X U phi of X and if we just multiply that out

523
00:32:19,330 --> 00:32:24,150
of course U prime U disappears we end up with kappa so basically the kernel is

524
00:32:24,150 --> 00:32:30,550
only determined up to rotations of the coordinate system so in other words if there's

525
00:32:30,550 --> 00:32:34,990
something about you coordinate system that you like and you think is very

526
00:32:35,230 --> 00:32:38,910
you know tells you something about your data then you gonna loose it if

527
00:32:38,910 --> 00:32:44,290
you use a kernel method so this is a you know key weakness I think of kernel

528
00:32:44,290 --> 00:32:51,650
methods if you think about for instance language there's something very specific about words and they're very

529
00:32:51,650 --> 00:32:57,110
you  know informative if you now just make a vector space of a words and use

530
00:32:57,110 --> 00:33:01,670
a kernel method over that vector space you're throwing away that information as far

531
00:33:01,670 --> 00:33:05,970
as the kernel method is concerned  any linear combination of words is just as

532
00:33:05,970 --> 00:33:12,730
informative as  just a good as good a you know a basis

533
00:33:12,750 --> 00:33:19,950
as the basis in terms of words so you're losing information there indeed you may

534
00:33:19,950 --> 00:33:23,690
so well that's very strange I thought kernel methods were very good at doing topic classification

535
00:33:23,690 --> 00:33:28,610
and the are but the key to making that work is actually in some

536
00:33:28,610 --> 00:33:34,310
sense a bit of a clutch which is to re-weight the important words in

537
00:33:34,330 --> 00:33:38,830
relative to the unimportant words by this TF-IDF waiting which I'll I'll talk about

538
00:33:38,830 --> 00:33:43,010
later on in in the kernel section so in a way I think there's a you

539
00:33:43,010 --> 00:33:48,970
know there's a mismatch there which is sort of glossed over in that particular application

540
00:33:48,970 --> 00:33:54,010
but there is a real problem if you have something about your application that is

541
00:33:54,010 --> 00:33:58,030
telling you you know your representation that you feel is very informative and if that is the

542
00:33:58,030 --> 00:34:01,630
case and you think for instance there's likely to be a small number of

543
00:34:01,630 --> 00:34:07,430
features that are involved they're very special features and they've been chosen very cleverly then

544
00:34:07,430 --> 00:34:10,690
you know maybe kernel methods isn't for you and you should go for something like

545
00:34:10,690 --> 00:34:18,110
boosting or a one norm regularized learning where you're looking specifically for small sets of features

546
00:34:18,150 --> 00:34:22,570
that will actually do the job for you so it's just a caveat and but

547
00:34:22,570 --> 00:34:27,950
it's also good to be aware of that but you know doing feature selection in

548
00:34:27,950 --> 00:34:33,390
a kernel defining feature space is actually doing subspace selection because feature selection doesn't really

549
00:34:33,390 --> 00:34:38,750
mean anything so what we're really thinking about is finding a subspace of the feature

550
00:34:38,750 --> 00:34:43,870
space and projecting into that  subspace in this part of the preprocessing

551
00:34:43,950 --> 00:34:49,310
so there's several ways of doing that and just to mention a few principal

552
00:34:49,310 --> 00:34:54,090
components analysis I'll go into more detail that's the sort of the classical method and

553
00:34:54,090 --> 00:34:58,850
we can indeed do that it chooses directions that maximize variants we've already seen we

554
00:34:58,850 --> 00:35:02,260
can measure variance in the feature space so it makes sense so we'll  able

555
00:35:02,270 --> 00:35:07,750
to do it and indeed we can canonical correlation analysis is looking where you have

556
00:35:07,750 --> 00:35:13,550
two views  and you're trying to maximize choose a subspace in both views

557
00:35:13,750 --> 00:35:17,990
the correspond the maximize the correlation so this can be quite useful if you have

558
00:35:18,000 --> 00:35:22,710
two representations of your data and you want to somehow which may have different types

559
00:35:22,710 --> 00:35:26,330
of noise in them and you want to clean the noise away and focus in

560
00:35:26,330 --> 00:35:34,270
on the on the core representation that's a very effective way of doing that so this

561
00:35:34,270 --> 00:35:38,250
this again can be applied in a kernel defined or kernel defined feature spaces in

562
00:35:38,250 --> 00:35:45,390
this case Gram-Schmidt is a a sort of greedy approximation to principal components analysis that

563
00:35:45,390 --> 00:35:52,730
chooses vectors one  at the time there are also sparse versions of principal components analysis that

564
00:35:52,730 --> 00:36:00,310
that somehow in between these two that are better at optimizing the choice Gram-

565
00:36:00,330 --> 00:36:07,490
Schmidt actually corresponds just to to doing a Cholesky decomposition of the kernel matrix or a guided

566
00:36:07,490 --> 00:36:12,310
Cholesky decomposition of the kernel matrix so the you know the dual form of Gram-Schmidt is

567
00:36:12,310 --> 00:36:17,950
is is Cholesky the dual form of principle components  analysis we'll see  is actually

568
00:36:17,950 --> 00:36:27,450
principal components analysis but on a different matrix and canonical correlation analysis corresponds to a generalized

569
00:36:27,450 --> 00:36:33,810
eigen value problem partial least squares is a very interesting method that is somewhat similar to

570
00:36:33,810 --> 00:36:39,630
principal components analysis but uses labeling information to guide the search of the subspaces

571
00:36:39,630 --> 00:36:45,030
so whereas prinicipal components analysis doesn't use the labels it just uses the variants

572
00:36:45,030 --> 00:36:51,480
of the data itself to choose the directions partial least squares uses the labeling that information

573
00:36:51,480 --> 00:36:57,590
to to help inform the search and so that again is a method that can

574
00:36:57,590 --> 00:37:02,870
be kernelized and but I won't be talking about these three I'm just mentioning them

575
00:37:02,870 --> 00:37:10,470
I'll I'll just go into  this one  here okay so principal components analysis so what are

576
00:37:10,470 --> 00:37:16,290
we trying to do we're trying to find a subspace or or projection directions which

577
00:37:16,290 --> 00:37:24,810
maximize the variance now I'm gonna ignore the I'm gonna assume that the data

578
00:37:24,810 --> 00:37:29,910
is centered so that this we don't have to subtract the the mean square

579
00:37:29,920 --> 00:37:36,050
and so on so it makes things a lot simpler to to present so I'll

580
00:37:36,050 --> 00:37:41,760
quite nicely focused around the value had the optimal in the sense to stop and

581
00:37:41,760 --> 00:37:46,700
the actual spread the distribution which started to get to look quite OK

582
00:37:46,850 --> 00:37:52,010
now traditional statistics is actually concentrated on looking at me

583
00:37:52,010 --> 00:37:57,280
and the typical sort of consideration is

584
00:37:57,280 --> 00:38:04,100
the consistency of algorithm and the consistency of a classification algorithm a is defined to

585
00:38:04,100 --> 00:38:06,490
be the property that the limit

586
00:38:06,510 --> 00:38:11,350
as n tends to infinity of this so the sample size tending to infinity the

587
00:38:11,350 --> 00:38:17,240
expected value of this distribution of errors tends to what's known as the the bayes

588
00:38:19,330 --> 00:38:22,760
the bayes optimal function is essentially the best you could ever do

589
00:38:22,800 --> 00:38:27,350
in the classification algorithm because it simply classifies according to

590
00:38:27,370 --> 00:38:29,970
the label it is more likely

591
00:38:29,990 --> 00:38:32,200
so it covers the case where

592
00:38:32,220 --> 00:38:37,090
you might have noise in your data sets so that particular example might in some

593
00:38:37,090 --> 00:38:43,100
cases because if i both positively and negatively with different probabilities and in that case

594
00:38:43,100 --> 00:38:45,010
obviously you have to pick

595
00:38:45,010 --> 00:38:48,180
the label is most likely to and that's what place

596
00:38:48,200 --> 00:38:50,180
when does yes

597
00:39:03,640 --> 00:39:11,180
this should be the generalisation of the base sorry that you're right sorry that should

598
00:39:11,180 --> 00:39:15,780
be the loss of the base expected loss of the basis function this i thank

599
00:39:16,450 --> 00:39:18,800
well spotted i see that

600
00:39:18,800 --> 00:39:20,240
you might want that

601
00:39:20,370 --> 00:39:27,490
so you should say expected value of the loss of f based on x y

602
00:39:27,590 --> 00:39:29,330
what i meant was that the

603
00:39:29,350 --> 00:39:32,600
you know the the function essentially it converges to

604
00:39:32,620 --> 00:39:35,780
or you could just say you know the limit as n tends to infinity in

605
00:39:35,870 --> 00:39:39,680
ASR is based

606
00:39:39,720 --> 00:39:42,430
so that's the sort of

607
00:39:43,970 --> 00:39:48,410
the study that i think you know from the previous slides you can see if

608
00:39:48,430 --> 00:39:51,970
you know the problem with n tends to infinity is that

609
00:39:51,970 --> 00:39:55,050
it's as long as the piece of string you know i mean

610
00:39:55,070 --> 00:39:58,660
doesn't happen the million that's happened a billion you know i mean this this

611
00:39:58,780 --> 00:40:01,870
what we want to know is what happens on the finite sample

612
00:40:04,180 --> 00:40:06,450
finite sample generalization

613
00:40:09,870 --> 00:40:13,910
has the distribution depending on the algorithm function class and sample size

614
00:40:17,300 --> 00:40:20,970
as i indicated above the traditional statistics is looked to the mean of this distribution

615
00:40:20,970 --> 00:40:22,470
but i think we

616
00:40:22,490 --> 00:40:25,220
hopefully i have seen that it can be misleading

617
00:40:25,240 --> 00:40:29,370
across the local all cross validation is another example where

618
00:40:29,410 --> 00:40:34,260
you know you you can prove properties about the expected value cross-pollination

619
00:40:34,280 --> 00:40:39,780
the very nice but obviousy in practice you can see that if you take a

620
00:40:39,780 --> 00:40:42,640
low fold cross validation can get quite serious

621
00:40:42,680 --> 00:40:45,870
errors in what you do

622
00:40:45,910 --> 00:40:48,780
and that's due to this variance natural

623
00:40:50,620 --> 00:40:56,720
so what statistical learning theory has prefered to analyzes the tail of the distribution so

624
00:40:56,720 --> 00:41:02,510
rather than look for the main event distribution is focused on trying to estimate if

625
00:41:02,510 --> 00:41:03,600
you like

626
00:41:03,620 --> 00:41:05,120
the worst case

627
00:41:05,140 --> 00:41:07,570
but how far out you might go

628
00:41:07,620 --> 00:41:13,160
provided you're willing to throw away a certain amount of probability

629
00:41:13,180 --> 00:41:16,320
so let me go back to one of those pictures and i think it should

630
00:41:16,320 --> 00:41:17,140
be clear

631
00:41:17,200 --> 00:41:19,430
so what you might say in

632
00:41:20,390 --> 00:41:23,640
statistical learning theory is you want to bound says OK

633
00:41:23,660 --> 00:41:25,700
i'm willing to accept that

634
00:41:25,720 --> 00:41:28,600
one thousand or one hundred times

635
00:41:28,620 --> 00:41:29,640
i'm gonna

636
00:41:29,640 --> 00:41:31,280
completely messed up

637
00:41:31,300 --> 00:41:36,410
i just be unlucky training set will just be so weird

638
00:41:36,550 --> 00:41:38,990
i i will be able to learn

639
00:41:39,070 --> 00:41:42,720
but i want to be ninety nine percent confidence that i'm going to have an

640
00:41:42,720 --> 00:41:46,740
error about something so if we take that example here what we would say i

641
00:41:46,740 --> 00:41:48,140
mean this this is actually

642
00:41:48,160 --> 00:41:51,600
a thousand simulations so it cut off the top ten

643
00:41:51,620 --> 00:41:56,530
the best we could say it would be something like about point six five

644
00:41:56,550 --> 00:41:57,800
so you mentioned

645
00:41:57,820 --> 00:42:01,910
you know with will align ourselves the luxury of throwing away the the tale of

646
00:42:02,950 --> 00:42:08,300
sort of worst case it runs and then what is the best

647
00:42:08,330 --> 00:42:11,820
what is the worst error we can get o point six five so this is

648
00:42:11,820 --> 00:42:14,660
the kind of estimate that we might expect from

649
00:42:14,660 --> 00:42:19,820
the statistical learning analysis and clearly there is a very big difference between that and

650
00:42:19,820 --> 00:42:22,260
the expected value which is still there

651
00:42:22,300 --> 00:42:25,010
way in the o point three

652
00:42:25,010 --> 00:42:28,450
similarly you know if we go back one more

653
00:42:28,490 --> 00:42:30,530
maybe the top ten here might

654
00:42:30,550 --> 00:42:35,700
bring us to that point five but the expected value is still well well close

655
00:42:35,700 --> 00:42:38,180
to the to the true value o point two

656
00:42:40,280 --> 00:42:43,470
so you can see that there is a very great difference in what you actually

657
00:42:43,470 --> 00:42:48,410
doing in some concrete cases

658
00:42:48,450 --> 00:42:53,370
so in a way we can see it a bit like a statistical test

659
00:42:53,390 --> 00:42:58,700
it was significant at the one percent confidence that means in statistical tests that means

660
00:42:58,700 --> 00:43:04,620
that the chances that that data rose if the hypothesis is

661
00:43:04,620 --> 00:43:10,160
if you cut each time you get speech decide these but interesting enough it's a

662
00:43:10,160 --> 00:43:16,310
joint 2 words and section not just things tied these meetings tag beach in Thailand

663
00:43:16,310 --> 00:43:22,330
and again example combined structured unstructured data together you can do this in flicker you

664
00:43:22,330 --> 00:43:28,210
can if you like attack but most about tags just place names of spelled various

665
00:43:28,210 --> 00:43:32,910
variations of and and there's really no good way to do a join intersection search

666
00:43:32,920 --> 00:43:38,570
entitling separatist conjunction of words but if you actually know this and this is the

667
00:43:38,570 --> 00:43:43,330
destination this attack was the author of this is a date supporting the powerful Internet

668
00:43:43,330 --> 00:43:49,830
search and so this is our another way that pays off now a strike back

669
00:43:49,830 --> 00:43:54,770
a 2nd you know Daniel said I use Lotus in mind Web technologies I actually

670
00:43:54,770 --> 00:43:59,630
did need a lot technology from some members some of ideas but I really wish

671
00:43:59,630 --> 00:44:04,730
I could have used a lot of semantic Web technology

672
00:44:04,810 --> 00:44:09,450
I would say to me a lot of time and money and on the first

673
00:44:09,450 --> 00:44:12,190
one was why don't we have a standard

674
00:44:12,310 --> 00:44:20,370
our database of a destinations released an ontology for accessing such databases the being there's

675
00:44:20,370 --> 00:44:26,750
no proprietary advantage to have a particular version of the world dismissed knocking insisted that

676
00:44:26,750 --> 00:44:31,250
no 1 ever about the catalyze such a thing and the CIA in had reason

677
00:44:31,260 --> 00:44:34,170
get 1 day owning there that kind of loss that that is to be open

678
00:44:34,170 --> 00:44:37,690
source in some way and so we need some kind of a ontology they could

679
00:44:37,690 --> 00:44:40,970
say by the way this is where destination is what apparently is that it's not

680
00:44:40,970 --> 00:44:45,090
clear all by the way I mean there's those things like but thing is city

681
00:44:45,090 --> 00:44:49,890
is inside a state states a U.S. concept is administered district all kind of stuff

682
00:44:50,000 --> 00:44:53,430
is get worked out that someone worked about then we'd have a resource on the

683
00:44:53,430 --> 00:44:55,150
web we could all match on

684
00:44:55,390 --> 00:45:00,210
the other thing was you know with the demand that the destination database done right

685
00:45:00,210 --> 00:45:06,570
it would be cheaper for other say destination oriented Web sites snapped a bad grid

686
00:45:06,570 --> 00:45:11,410
and to make up their own so for instance we integrate with farmers just makes

687
00:45:11,410 --> 00:45:15,710
his travel guides and they give us all the content for free exchange for Ofarrell

688
00:45:15,710 --> 00:45:19,410
exceeds a good deal for us but they but we had to do the work

689
00:45:19,410 --> 00:45:27,230
to figure out of that our destinations various nations in suggesting same thing with advertisers

690
00:45:27,230 --> 00:45:31,090
where thing was tagging is not a core competency of a travel blogging site while

691
00:45:31,110 --> 00:45:35,250
I have to make up my own tagging structures crazy if we had a tagging

692
00:45:35,250 --> 00:45:41,610
ontology and tagging Mr. Web Web services at work was really done right and it

693
00:45:41,610 --> 00:45:45,550
would be that the economics of the thing would force would cause there to be

694
00:45:45,550 --> 00:45:52,540
a specialist players there would be tagging add-ons bijugatus mix into your site the a

695
00:45:52,540 --> 00:45:58,810
network of would cause them to discuss the adopted and and then even without even

696
00:45:58,810 --> 00:46:02,210
with those who still have the Google's and Yahoo's and we will play their own

697
00:46:02,210 --> 00:46:06,110
way of course because they won along mountain positions that's cool because if you have

698
00:46:06,110 --> 00:46:10,150
a status as would tag is so smart guys in the wall this is how

699
00:46:10,150 --> 00:46:14,210
Yahoo's notion tag maps to the standard way or this way and so on December

700
00:46:14,210 --> 00:46:20,470
rules motion numerous and then we get translation services as we evolve but also of

701
00:46:21,360 --> 00:46:22,970
this kind analysis

702
00:46:23,290 --> 00:46:26,990
now he is an example of stuff that really did help and maybe we should

703
00:46:26,990 --> 00:46:32,270
include from that I have the 7 people in the company and we have millions

704
00:46:32,270 --> 00:46:38,810
and millions of users enormous leverage and Internet start-up like this now they comes from

705
00:46:38,810 --> 00:46:43,970
the fact that we can build on the giant chosen Johnson powerful databases is raising

706
00:46:43,970 --> 00:46:48,310
you I libraries all the stuff no way we could ever do ourselves and is

707
00:46:48,320 --> 00:46:53,670
the culture of the social Web to do it this way which meet injected the

708
00:46:53,670 --> 00:46:59,490
culture it would be adopted there's no resistance to it's a culture reads their thing

709
00:46:59,490 --> 00:47:03,850
is not just for use of just Ross operability services a small motion of Web

710
00:47:03,850 --> 00:47:12,630
services the based on announcement below both forced make it happen tank so let me

711
00:47:12,630 --> 00:47:17,550
just a step back now they're gonna finish with a single a questions with proactively

712
00:47:17,550 --> 00:47:22,930
now I've given my Spears with that's where about can do some work stuff crew

713
00:47:22,970 --> 00:47:28,810
we get to do security to really contribute to collective knowledge systems ecosystems by mentioned

714
00:47:28,810 --> 00:47:35,000
text-based cost taxpayers syntactic reject this is kind of a no-brainer this hasn't been .

715
00:47:35,310 --> 00:47:38,050
com and by the way if we don't know if it will get done in

716
00:47:38,050 --> 00:47:44,670
some other way like performance because no about Mike value string URL it's a uses

717
00:47:44,670 --> 00:47:50,750
the syntax we were not the actual syntax of euro as as part of its

718
00:47:50,750 --> 00:47:56,650
semantics is you match the last string bits of the to stay with the tag

719
00:47:56,650 --> 00:48:02,370
it's attempt overcomes spam but a and this guy community is gonna processes that research

720
00:48:02,570 --> 00:48:07,670
the problem is that the it's not going to it is by solution will you

721
00:48:07,670 --> 00:48:11,510
or your eyes anyway and the Salonika so the goes on but is the whole

722
00:48:11,510 --> 00:48:17,540
point of my performances that expedient and they're looking for early adopted so network effect

723
00:48:17,540 --> 00:48:22,890
and so we log out there and do something else that's what should we win

724
00:48:23,090 --> 00:48:28,150
destination to corners anything it's as global data you could and since the thinking about

725
00:48:28,160 --> 00:48:33,300
as the the the symbolic machinery problem and that this thing about how able of

726
00:48:33,300 --> 00:48:40,530
global repository like the gym project Human Genome Project didn't happen without a standard for

727
00:48:40,530 --> 00:48:45,590
the data data and that by community is a meaty takes and but healthy they

728
00:48:45,610 --> 00:48:52,200
have their act together that's data exchange and use ontologies are another thing is portable

729
00:48:52,210 --> 00:48:56,610
identity reputation as a project that could this is a really important problem for the

730
00:48:56,610 --> 00:49:01,350
Web really important and that and if if we just leave a symbol of all

731
00:49:01,350 --> 00:49:07,330
agreements it's not going to solve the relating dig down say for an agents to

732
00:49:07,330 --> 00:49:12,890
be represented with some urbanity bag backpack they can carry around them in such a

733
00:49:12,890 --> 00:49:18,730
way that we've thought through the implications for privacy and everything that thing is really

734
00:49:18,730 --> 00:49:23,670
by my side has really no new Google has of adviser has written everybody has

735
00:49:23,670 --> 00:49:26,940
he is a relation

736
00:49:26,950 --> 00:49:37,400
so i went back

737
00:49:42,360 --> 00:49:43,170
the female

738
00:50:09,160 --> 00:50:16,850
that was a

739
00:50:44,430 --> 00:50:50,720
all of this is

740
00:50:56,610 --> 00:51:01,270
and you or i

741
00:51:04,460 --> 00:51:08,740
these are

742
00:51:12,610 --> 00:51:17,560
in he's

743
00:51:38,050 --> 00:51:41,670
well actually

744
00:51:41,970 --> 00:51:44,680
these are

745
00:51:52,320 --> 00:51:54,650
look on the

746
00:52:00,030 --> 00:52:03,800
and it really

747
00:52:20,040 --> 00:52:23,800
people are

748
00:52:25,620 --> 00:52:28,740
the rest of

749
00:52:28,740 --> 00:52:30,260
the one one of

750
00:52:30,260 --> 00:52:35,060
think of it as a memory but keep in mind that of course it extensively

751
00:52:35,080 --> 00:52:40,200
x direction and is everywhere the same x direction over the whole length eight i

752
00:52:40,200 --> 00:52:43,060
cannot change that i cannot make you see that

753
00:52:43,080 --> 00:52:44,530
and so for instance

754
00:52:44,540 --> 00:52:46,410
the two one mode

755
00:52:46,470 --> 00:52:48,910
i would then be

756
00:52:48,990 --> 00:52:52,680
if i make mary through and i make nancy one

757
00:52:52,700 --> 00:52:56,330
then in the y direction i would have

758
00:52:58,040 --> 00:53:00,390
the complete note surface

759
00:53:00,390 --> 00:53:03,330
which runs all the way from the box

760
00:53:03,330 --> 00:53:08,430
entirely sealed box no x x component of the field and this one would then

761
00:53:09,030 --> 00:53:13,200
these new direction and this will be built in this direction and will go like

762
00:53:14,680 --> 00:53:18,760
and then if you have the two to mold

763
00:53:18,760 --> 00:53:20,530
this is the two two mode

764
00:53:20,540 --> 00:53:22,450
so x is in this direction

765
00:53:22,540 --> 00:53:24,100
then you would get this

766
00:53:24,120 --> 00:53:27,600
you get one homolog surface you know component

767
00:53:27,660 --> 00:53:32,490
now x component of the vector no x component of the vector throughout the entire

768
00:53:33,600 --> 00:53:35,080
throughout complete x

769
00:53:35,080 --> 00:53:37,970
and then this will come to you this will come to you this would go

770
00:53:37,970 --> 00:53:43,990
away from you and it will be the standing of living way

771
00:53:44,040 --> 00:53:46,410
now independently

772
00:53:46,410 --> 00:53:50,100
i can now look at the y component of the field

773
00:53:50,140 --> 00:53:51,680
because i only looked at the

774
00:53:51,700 --> 00:53:53,100
x components

775
00:53:53,180 --> 00:53:55,990
let's now look into why direction

776
00:53:56,080 --> 00:53:57,160
and that's now

777
00:53:57,200 --> 00:54:01,950
ask what is the problem with you y value y also has to become zero

778
00:54:02,040 --> 00:54:03,540
when it

779
00:54:03,560 --> 00:54:06,390
in the plane becomes the tangential component

780
00:54:06,390 --> 00:54:10,010
and therefore y must be zero when x equals zero

781
00:54:10,060 --> 00:54:11,760
and when x equals h

782
00:54:11,770 --> 00:54:16,910
and one thing equal zero and one z equals c

783
00:54:16,930 --> 00:54:18,430
if you y

784
00:54:18,430 --> 00:54:20,200
in this direction

785
00:54:20,240 --> 00:54:22,620
must vanish when x equals zero

786
00:54:22,620 --> 00:54:27,510
it must twenty four x equals a and must also in this from place equal

787
00:54:27,540 --> 00:54:31,950
zero and in the back plate z equals

788
00:54:31,970 --> 00:54:34,680
so now you can come up immediately

789
00:54:34,720 --> 00:54:39,350
by by parallel you can immediately come up with a

790
00:54:39,410 --> 00:54:41,950
relationship i will call it now

791
00:54:41,970 --> 00:54:43,640
l as in lyon

792
00:54:43,700 --> 00:54:44,720
four x

793
00:54:44,830 --> 00:54:48,310
then for the i will keep the and nancy

794
00:54:48,310 --> 00:54:52,180
so don't get confused so that is no c

795
00:54:52,220 --> 00:54:54,600
i'll do it in terms of squares

796
00:54:54,620 --> 00:54:56,200
and then i'll get

797
00:54:58,510 --> 00:55:00,100
over eight

798
00:55:04,450 --> 00:55:07,430
overseas squared

799
00:55:07,450 --> 00:55:09,310
that's it

800
00:55:09,350 --> 00:55:11,870
for now i have another

801
00:55:11,930 --> 00:55:13,620
infinite families

802
00:55:13,620 --> 00:55:19,160
of values from aladdin lion and nancy which give me the resonance condition

803
00:55:19,910 --> 00:55:21,700
the y direction

804
00:55:21,760 --> 00:55:26,080
and so if i had linearly polarized radiation

805
00:55:26,140 --> 00:55:30,260
i could have in the x direction in the polarized radiation which would then have

806
00:55:30,260 --> 00:55:31,890
to obey

807
00:55:33,510 --> 00:55:38,560
i could have linearly polarized direct variation in the wind direction which would have to

808
00:55:38,560 --> 00:55:42,870
obey this sequence of frequencies and i could do one in the same direction which

809
00:55:42,890 --> 00:55:45,540
of course you can make up for yourself

810
00:55:47,580 --> 00:55:51,740
it is also possible in any linear combination of those would be fine but of

811
00:55:51,740 --> 00:55:53,850
course it is also possible

812
00:55:53,890 --> 00:55:55,970
that i have an effect or

813
00:55:56,030 --> 00:55:59,700
which has a component x y and z

814
00:55:59,700 --> 00:56:02,430
and that's simultaneously

815
00:56:02,490 --> 00:56:06,810
all boundary conditions are met so i don't just radiate

816
00:56:06,830 --> 00:56:11,990
polarized radiation only in the x direction and only in the same direction but now

817
00:56:11,990 --> 00:56:13,430
i say aha

818
00:56:13,450 --> 00:56:16,390
if no i make only guess crayons

819
00:56:19,200 --> 00:56:21,430
if that now see squared

820
00:56:24,680 --> 00:56:27,040
over a squared

821
00:56:27,060 --> 00:56:30,470
plus mary l mary y

822
00:56:30,490 --> 00:56:32,140
over b scribd

823
00:56:33,310 --> 00:56:35,160
plus nancy by

824
00:56:35,180 --> 00:56:37,910
over c square

825
00:56:37,910 --> 00:56:42,350
then i can have an effect which is in some random directions well maybe not

826
00:56:42,350 --> 00:56:44,740
too random because i have to beat

827
00:56:44,740 --> 00:56:46,240
this condition

828
00:56:46,240 --> 00:56:47,450
and now we have a whole

829
00:56:47,470 --> 00:56:51,530
family of infinite number of resonance frequencies

830
00:56:51,540 --> 00:56:57,580
which are not only defectors in x y or z direction did i make a

831
00:56:57,680 --> 00:57:00,700
slip thank you very much i this is clear downstairs right

832
00:57:00,720 --> 00:57:05,470
isn't one of actually non-zero museo

833
00:57:05,510 --> 00:57:07,270
thank you

834
00:57:07,290 --> 00:57:09,970
i appreciate it really i do because it's so nasty

835
00:57:10,060 --> 00:57:15,350
this led so we are or have been our ideas i

836
00:57:15,350 --> 00:57:17,450
all right

837
00:57:19,830 --> 00:57:21,580
i'm going to change gears

838
00:57:21,640 --> 00:57:23,490
because i want it

839
00:57:23,540 --> 00:57:26,490
to find a way to demonstrate this

840
00:57:26,540 --> 00:57:28,620
i'm going to change gears

841
00:57:28,680 --> 00:57:31,410
and i'm going to make this box

842
00:57:31,660 --> 00:57:35,120
going to ask myself what i do resonance frequencies

843
00:57:35,180 --> 00:57:37,010
for some

844
00:57:37,060 --> 00:57:39,740
sound is longer always

845
00:57:39,740 --> 00:57:41,410
so sound has no

846
00:57:41,410 --> 00:57:43,700
linear polarization

847
00:57:43,720 --> 00:57:45,830
and so now

848
00:57:45,890 --> 00:57:48,810
i can immediately right down

849
00:57:51,120 --> 00:57:56,260
the function of the overpressure be over and above all an atmosphere albedo and atmosphere

850
00:57:56,260 --> 00:57:57,640
because now i know

851
00:57:57,660 --> 00:57:59,140
that's at all

852
00:57:59,140 --> 00:58:00,200
for surfaces

853
00:58:00,200 --> 00:58:03,100
i must have pressure and notes

854
00:58:03,100 --> 00:58:06,830
artists also ninety six tool

855
00:58:06,840 --> 00:58:10,130
a single as the eighties

856
00:58:11,610 --> 00:58:15,730
tensor functor it to itself of october nineteen ninety six

857
00:58:17,580 --> 00:58:23,440
we took a hundred thousand documents from writers corpus so basically this would be roughly

858
00:58:23,440 --> 00:58:24,790
two thousand

859
00:58:24,810 --> 00:58:30,360
two thousand to three thousand news stories per place more-or-less complete corpus

860
00:58:30,670 --> 00:58:32,270
extracted the most

861
00:58:32,290 --> 00:58:38,580
frequent named entities so most tricking them into this would be in the proper names

862
00:58:38,580 --> 00:58:39,830
which occur

863
00:58:39,920 --> 00:58:41,790
most frequently

864
00:58:41,810 --> 00:58:48,400
so here you can see mainly the names of the countries plus maybe was three

865
00:58:48,420 --> 00:58:51,830
these are the bill clinton and maybe some

866
00:58:51,860 --> 00:58:54,670
other name but not too too many other names

867
00:58:54,690 --> 00:58:57,250
many countries plus the most popular

868
00:58:57,250 --> 00:59:04,270
fifteen obviously and what's three this because there's a good sector of

869
00:59:05,310 --> 00:59:09,420
good good good portion of reasons for using cyc

870
00:59:09,520 --> 00:59:15,380
OK what we can do with this method

871
00:59:15,400 --> 00:59:21,340
so again we can observe what are particular topics about

872
00:59:21,360 --> 00:59:25,060
so basically this area here would correspond to

873
00:59:25,110 --> 00:59:31,110
southern american pop this would be more like asian topics

874
00:59:31,170 --> 00:59:35,480
and this would be more like financial topics and here in the middle so this

875
00:59:35,670 --> 00:59:37,440
more like us and so

876
00:59:38,810 --> 00:59:41,250
one possible u

877
00:59:41,250 --> 00:59:43,940
would be

878
00:59:43,940 --> 00:59:47,940
showing the trace showed traces can see how

879
00:59:47,940 --> 00:59:51,250
one particular name entity moves through time

880
00:59:51,250 --> 00:59:53,100
so what does this mean

881
00:59:56,190 --> 00:59:58,130
it's the name entity which appears

882
00:59:58,150 --> 01:00:00,650
in many documents in these documents

883
01:00:00,670 --> 01:00:02,610
changing topics

884
01:00:03,060 --> 01:00:06,980
as much as well through the news topics change

885
01:00:07,020 --> 01:00:09,840
and also through time

886
01:00:09,860 --> 01:00:13,040
argentinos argentinos always described the

887
01:00:13,040 --> 01:00:14,270
news articles

888
01:00:14,380 --> 01:00:15,610
it appears

889
01:00:15,630 --> 01:00:20,400
this is this news articles are changing its focus also the profile of the typical

890
01:00:20,400 --> 01:00:26,110
profile of argentinos changing and this is you see that that's which go through time

891
01:00:27,040 --> 01:00:30,020
hall argentina travellers on this

892
01:00:30,830 --> 01:00:37,170
and since argentina's very covering very soft some american topics then you may need moves

893
01:00:37,190 --> 01:00:40,020
in this area of the men that china would

894
01:00:40,020 --> 01:00:43,270
move more on this

895
01:00:45,580 --> 01:00:51,730
upper part there are mainly asian topics that's a while the if was not

896
01:00:51,750 --> 01:00:52,670
in israel

897
01:00:52,790 --> 01:00:58,900
well it's in this area of france for me let's see

898
01:00:59,540 --> 01:01:05,580
it's more francis more generic topics so it covers the whole part of the map

899
01:01:05,580 --> 01:01:08,100
and so on it's a bit cleaned up

900
01:01:08,100 --> 01:01:11,040
was american president is involved in many

901
01:01:11,060 --> 01:01:12,690
many topics

902
01:01:12,730 --> 01:01:13,540
the film

903
01:01:13,560 --> 01:01:18,440
jump here and there are different in different parts of the map

904
01:01:18,460 --> 01:01:20,500
now if we move

905
01:01:20,520 --> 01:01:25,020
this slide there through time you see that's how this bill clinton really

906
01:01:25,040 --> 01:01:29,020
it's travelling so between ten and this is the point of the time it's

907
01:01:29,830 --> 01:01:30,520
and this

908
01:01:30,540 --> 01:01:31,360
part of this

909
01:01:35,860 --> 01:01:38,400
forbidden and you can also check

910
01:01:38,420 --> 01:01:41,080
relationships to other

911
01:01:41,080 --> 01:01:42,400
name entities

912
01:01:42,480 --> 01:01:47,230
now if you go with clinton and so on this line between bill clinton and

913
01:01:48,940 --> 01:01:51,110
this would get describe

914
01:01:51,110 --> 01:01:54,920
with a set of keywords so we take all the documents were

915
01:01:54,920 --> 01:01:57,670
the clinton and russia appears

916
01:01:57,690 --> 01:02:02,040
copious and so this would be sent three the

917
01:02:03,060 --> 01:02:06,480
a set of documents of section to this cluster

918
01:02:06,560 --> 01:02:11,520
and the typical keywords we describe this relationship will be cleaned clinton years in russian

919
01:02:11,520 --> 01:02:19,080
could always deliver teaching and so on very clear to the russian us-russian

920
01:02:19,130 --> 01:02:23,630
type of topics from mid nineties well let's see if we were to move

921
01:02:23,650 --> 01:02:28,630
if you check relationship between bill clinton and chicago

922
01:02:28,650 --> 01:02:35,290
we would see a completely different type of q likely to convention democrats republicans and

923
01:02:35,290 --> 01:02:38,150
so on so it was obviously the time of

924
01:02:38,170 --> 01:02:41,610
elections and then the this keywords

925
01:02:41,630 --> 01:02:48,080
this keywords of the election type of keywords would you and you can easily see

926
01:02:48,080 --> 01:02:49,920
that clinton appears

927
01:02:50,000 --> 01:02:54,020
with different name entities in different relationships let's see

928
01:02:54,040 --> 01:02:59,190
china it's about tobacco smoking whatever this was

929
01:03:03,110 --> 01:03:09,420
so this is one way how to how to visualize also the

930
01:03:09,440 --> 01:03:13,770
text corpus pretty large text corpus in very simple way

931
01:03:13,790 --> 01:03:16,060
and also visualize this time dimensions

932
01:03:16,080 --> 01:03:18,360
and also relationship to other

933
01:03:18,380 --> 01:03:26,170
other named to other and this in this particular case we had this name entities

934
01:03:28,110 --> 01:03:29,690
so much about this

935
01:03:29,770 --> 01:03:33,420
but this them on the this is roughly i would say

936
01:03:33,560 --> 01:03:37,460
type of software type of techniques reach

937
01:03:37,460 --> 01:03:43,880
i used also in all other most of the other more sophisticated exposition

938
01:03:43,900 --> 01:03:45,880
softer side

939
01:03:45,940 --> 01:03:50,500
this what we do may be just a few words so we take documents transforming

940
01:03:50,500 --> 01:03:54,250
them into this vector space model we perform

941
01:03:54,250 --> 01:04:00,810
clustering car this that it semantic indexing this is one one way how to perform

942
01:04:00,810 --> 01:04:02,400
physical clustering

943
01:04:02,420 --> 01:04:03,480
you use

944
01:04:03,500 --> 01:04:07,170
the whole corpus from these hundred thousand dimensions roughly

945
01:04:08,190 --> 01:04:10,960
one hundred two hundred dimensions and then we performed

946
01:04:10,980 --> 01:04:13,790
method called multidimensional scaling

947
01:04:14,670 --> 01:04:15,900
compresses this

948
01:04:16,060 --> 01:04:20,230
the two hundred dimensions down to two dimensions which you see here

949
01:04:20,650 --> 01:04:23,730
and we try to preserve regional

950
01:04:23,750 --> 01:04:26,310
original distances between the documents so

951
01:04:26,670 --> 01:04:27,980
if two

952
01:04:28,000 --> 01:04:31,330
methods were in original space

953
01:04:31,360 --> 01:04:34,080
in these proportions that we try to preserve his

954
01:04:34,110 --> 01:04:39,650
relationships also in the final features so this is a description of what do because

955
01:04:39,650 --> 01:04:44,150
so an outcome from a set aside that's if you give them all names obviously

956
01:04:44,760 --> 01:04:46,270
binary or link

957
01:04:47,200 --> 01:04:49,850
this outcome can be communicated in other to

958
01:04:56,980 --> 01:04:57,780
i will again

959
01:04:59,110 --> 01:04:59,470
this is

960
01:05:00,560 --> 01:05:01,800
based on battleships

961
01:05:02,620 --> 01:05:07,030
but slightly more building being game i have had to read than battleships

962
01:05:07,730 --> 01:05:08,460
it's called summary

963
01:05:09,520 --> 01:05:11,230
the separating wall

964
01:05:11,400 --> 01:05:14,790
submarine is hidden somewhere in the ocean and then you have to start firing at

965
01:05:14,790 --> 01:05:18,360
it just like in battleships to try and find long submarine

966
01:05:20,680 --> 01:05:22,600
so let's run submarine

967
01:05:24,690 --> 01:05:25,260
here it is

968
01:05:28,250 --> 01:05:29,390
let's have a game show

969
01:05:30,380 --> 01:05:34,860
i've built in some shannon right so we can see for every possible thing we

970
01:05:34,860 --> 01:05:36,560
could do you can find any square

971
01:05:37,470 --> 01:05:41,470
because it tells you what the probability of getting a yes is that you hit

972
01:05:41,490 --> 01:05:44,320
the submarine summary is just one square at sixty four

973
01:05:45,400 --> 01:05:48,780
and the problem sixty three over sixty four that's right hand

974
01:05:49,430 --> 01:05:50,980
sixty through sixty four of the square

975
01:05:51,580 --> 01:05:53,350
and sixty three six four for this one

976
01:05:53,770 --> 01:05:54,340
all right so

977
01:05:55,240 --> 01:05:56,040
the same

978
01:05:56,440 --> 01:05:58,220
because we don't know whether summary is okay

979
01:05:58,860 --> 01:06:00,880
so could actually find this square form

980
01:06:02,660 --> 01:06:06,500
it could interact with the probability of the outcome happened fired

981
01:06:06,990 --> 01:06:07,930
three which is now

982
01:06:08,320 --> 01:06:09,050
no discovery

983
01:06:11,360 --> 01:06:12,190
first outcome

984
01:06:18,780 --> 01:06:19,590
the probability

985
01:06:20,240 --> 01:06:21,660
that's response the

986
01:06:22,730 --> 01:06:23,340
was no

987
01:06:25,200 --> 01:06:26,450
sixty three hundred sixty four

988
01:06:27,480 --> 01:06:31,200
so the shannon information content of the first

989
01:06:33,470 --> 01:06:34,390
log base two

990
01:06:34,980 --> 01:06:37,140
o one over at which is always to sixty four

991
01:06:37,780 --> 01:06:38,660
over sixty three

992
01:06:40,000 --> 01:06:40,500
all right

993
01:06:42,130 --> 01:06:44,030
and that's slightly below are

994
01:06:45,350 --> 01:06:46,880
number had zero point

995
01:06:51,180 --> 01:06:52,670
so what's going on with the disorder

996
01:06:52,740 --> 01:06:57,730
trivial examples weighing problems where of-course you wanted to be a third third third one to think about it

997
01:06:58,310 --> 01:06:58,850
we looked at

998
01:07:00,010 --> 01:07:02,900
identifying underwear with binary strings all

999
01:07:03,530 --> 01:07:04,940
again for sixty three

1000
01:07:05,580 --> 01:07:10,750
every week on coming to fifty announcing what about the world with probability uneven

1001
01:07:11,520 --> 01:07:14,800
shannon says when you find that's where i got no

1002
01:07:16,270 --> 01:07:19,840
you've got this much information point o two two seven bits

1003
01:07:22,360 --> 01:07:23,770
it's not obvious that that's right is

1004
01:07:25,200 --> 01:07:27,120
so let's carry on playing and see what happens

1005
01:07:29,970 --> 01:07:30,700
so far the square

1006
01:07:31,350 --> 01:07:34,190
now the probability of getting yes is one over sixty three

1007
01:07:36,570 --> 01:07:39,550
and the is sixty two sixty three shells

1008
01:07:41,320 --> 01:07:41,990
what happened

1009
01:07:43,340 --> 01:07:44,760
the probability of getting a know

1010
01:07:45,180 --> 01:07:46,030
this is what happened

1011
01:07:48,820 --> 01:07:49,440
sixty two

1012
01:07:51,130 --> 01:07:53,570
sharing information content with long to

1013
01:07:56,590 --> 01:07:57,190
which was

1014
01:07:57,960 --> 01:07:59,170
slightly more

1015
01:08:03,590 --> 01:08:04,680
so i know point

1016
01:08:07,920 --> 01:08:12,860
three and the right hand column is keeping track of the total information we've gained so far let's

1017
01:08:13,930 --> 01:08:14,690
right now

1018
01:08:16,290 --> 01:08:16,950
and as well

1019
01:08:21,570 --> 01:08:23,350
so little information gain

1020
01:08:23,910 --> 01:08:24,540
so far

1021
01:08:25,370 --> 01:08:26,580
there is no basis in the

1022
01:08:30,330 --> 01:08:31,180
sixty three o

1023
01:08:32,380 --> 01:08:33,140
sixty two

1024
01:08:35,330 --> 01:08:36,450
we carry on playing

1025
01:08:37,370 --> 01:08:37,950
i can

1026
01:08:39,010 --> 01:08:40,670
so i write down all these

1027
01:08:42,670 --> 01:08:43,490
could have just

1028
01:08:44,150 --> 01:08:45,270
going for a while

1029
01:08:45,940 --> 01:08:50,310
we could go back and try and find the square the probability of getting a no is one

1030
01:08:50,890 --> 01:08:51,990
probably yes zero

1031
01:08:52,400 --> 01:08:56,130
now give us no information content so we can write and nothing happens

1032
01:08:58,500 --> 01:09:00,450
you can carry on doing that in

1033
01:09:01,600 --> 01:09:02,540
the problem that

1034
01:09:06,490 --> 01:09:08,690
okay what's happened a five at

1035
01:09:11,080 --> 01:09:12,170
half the squares

1036
01:09:13,620 --> 01:09:17,650
what's happened to the shannon information content when you add it all up so far

1037
01:09:18,110 --> 01:09:19,670
i got lots and lots nose

1038
01:09:20,310 --> 01:09:22,840
and the final one that just ask

1039
01:09:23,440 --> 01:09:24,720
as long as thirty three

1040
01:09:25,380 --> 01:09:26,240
over thirty two

1041
01:09:27,220 --> 01:09:31,790
semantic shared information content just got the total so far we still haven't found anything but

1042
01:09:32,220 --> 01:09:33,230
adds up to one

1043
01:09:35,850 --> 01:09:37,130
that's the one bit

1044
01:09:37,940 --> 01:09:38,580
what's going on

1045
01:09:41,200 --> 01:09:42,730
it's a bit like playing sixty three

1046
01:09:44,120 --> 01:09:46,670
achievement at question is the number one

1047
01:09:47,280 --> 01:09:52,440
so it is zero you want it to the three threshold going very silly strategy and sixty three

1048
01:09:52,850 --> 01:09:53,670
and we get right

1049
01:09:54,820 --> 01:09:55,890
and is

1050
01:09:56,170 --> 01:09:57,060
the thirty one

1051
01:09:57,900 --> 01:09:58,660
and the answer is

1052
01:09:59,130 --> 01:10:00,370
no it's not very well

1053
01:10:03,120 --> 01:10:07,200
got the great thing about this and that's just the same as asking it less recalled very well

1054
01:10:09,040 --> 01:10:09,890
which from bit

1055
01:10:10,810 --> 01:10:13,890
so this is consistent with what we already opposed completely obvious

1056
01:10:14,750 --> 01:10:16,040
all right so that's promising

1057
01:10:16,460 --> 01:10:17,990
this has added up to

1058
01:10:19,540 --> 01:10:21,130
he wanted it

1059
01:10:21,500 --> 01:10:24,650
very painfully acquired information content but it makes complete

1060
01:10:26,940 --> 01:10:30,270
okay shall carry on that they wanted to

1061
01:10:32,090 --> 01:10:32,700
from from from

1062
01:10:36,620 --> 01:10:37,340
so we did it

1063
01:10:38,240 --> 01:10:38,840
as a surprise

1064
01:10:41,460 --> 01:10:42,220
and what happened

1065
01:10:44,380 --> 01:10:45,570
last log

1066
01:10:47,580 --> 01:10:48,480
one plus

1067
01:10:48,970 --> 01:10:49,820
the band

1068
01:10:51,020 --> 01:10:53,610
attempt was that this actually happened at

1069
01:10:55,440 --> 01:10:59,920
who you would just about to expect another know which we had a probability

1070
01:11:00,510 --> 01:11:01,930
nineteen over twenty

1071
01:11:03,740 --> 01:11:04,820
the latest thing we just

1072
01:11:05,310 --> 01:11:06,330
did that god knows

1073
01:11:06,960 --> 01:11:07,950
the information content

1074
01:11:09,430 --> 01:11:10,360
twenty one or twenty

1075
01:11:12,210 --> 01:11:13,520
but then amazingly

1076
01:11:14,280 --> 01:11:18,460
we got some an enormous fall into bit according to show we got

1077
01:11:19,190 --> 01:11:22,040
o point three bits of information content or some

1078
01:11:28,360 --> 01:11:29,390
and not lot to

1079
01:11:29,390 --> 01:11:36,030
one is

1080
01:11:41,770 --> 01:11:43,360
the the

1081
01:11:48,240 --> 01:11:57,260
so i think the

1082
01:11:57,270 --> 01:11:59,520
rather than actually

1083
01:12:04,860 --> 01:12:10,090
this is something seems to be so

1084
01:12:10,110 --> 01:12:14,070
so in

1085
01:12:14,070 --> 01:12:15,600
this is a

1086
01:12:21,360 --> 01:12:24,280
it's a she

1087
01:12:28,520 --> 01:12:32,430
which is why do i really

1088
01:12:32,450 --> 01:12:35,270
so the we see

1089
01:12:37,190 --> 01:12:40,670
it lies to

1090
01:12:42,940 --> 01:12:47,860
g c u which is the

1091
01:12:48,010 --> 01:12:53,800
so that the sum

1092
01:12:55,120 --> 01:13:00,100
when he wants to

1093
01:13:03,660 --> 01:13:07,280
you can also look each

1094
01:13:31,360 --> 01:13:32,330
well we

1095
01:13:32,380 --> 01:13:34,490
this is a huge

1096
01:13:38,560 --> 01:13:41,310
it's very easy

1097
01:13:52,560 --> 01:13:58,350
and that some of the

1098
01:14:11,820 --> 01:14:17,460
it's like

1099
01:14:23,840 --> 01:14:27,050
he is also

1100
01:14:28,870 --> 01:14:30,270
i mean

1101
01:14:33,510 --> 01:14:36,090
it is

1102
01:14:38,860 --> 01:14:40,990
so t

1103
01:14:44,410 --> 01:14:51,090
this is

1104
01:15:00,010 --> 01:15:02,340
all of these two

1105
01:15:02,360 --> 01:15:05,140
fifty one

1106
01:15:05,160 --> 01:15:08,510
the team

1107
01:15:11,100 --> 01:15:15,110
the future

1108
01:15:17,080 --> 01:15:20,940
the change he said well

1109
01:15:21,080 --> 01:15:24,360
the only change

1110
01:15:27,840 --> 01:15:29,840
so there's

1111
01:15:29,850 --> 01:15:32,800
we need to do

1112
01:15:33,180 --> 01:15:39,850
so you to change your

1113
01:15:52,530 --> 01:15:54,830
well to

1114
01:15:54,970 --> 01:15:59,150
we do

1115
01:16:02,150 --> 01:16:03,330
that this

1116
01:16:17,280 --> 01:16:19,960
you want to

1117
01:16:23,540 --> 01:16:26,090
in two one is

1118
01:16:26,100 --> 01:16:27,370
one two

1119
01:16:36,630 --> 01:16:39,020
so what

1120
01:16:49,000 --> 01:16:50,750
this is

1121
01:16:50,770 --> 01:16:54,950
this is

1122
01:17:02,880 --> 01:17:07,720
it's difficult

1123
01:17:11,270 --> 01:17:13,120
also for

1124
01:17:14,620 --> 01:17:16,870
what is this

1125
01:17:16,870 --> 01:17:22,770
single gene called the SRY gene for sex determining region of the y chromosome which

1126
01:17:22,770 --> 01:17:25,370
will code for the development of the testis

1127
01:17:25,380 --> 01:17:29,540
in the absence of the gene and ovary will develop

1128
01:17:29,660 --> 01:17:37,570
subsequently the bone marrow phenotype will then determine the brain's phenotype by secreting steroids hormones

1129
01:17:37,570 --> 01:17:42,830
so the male testis will begin steroid production very early on in humans it will

1130
01:17:42,830 --> 01:17:48,120
actually occur during the second try master sometimes the woman doesn't even know she's pregnant

1131
01:17:48,310 --> 01:17:52,320
in the absence of steroids brain will develop as the female phenotype

1132
01:17:52,330 --> 01:17:54,170
in our role models

1133
01:17:54,190 --> 01:17:58,060
or in some circumstances of happen in humans we know that if we give the

1134
01:17:58,060 --> 01:18:03,330
former we can actually change the phenotype of the brain to the male

1135
01:18:03,350 --> 01:18:07,330
by giving male hormones i like to think of this as mother nature being rather

1136
01:18:07,330 --> 01:18:12,450
clever and saying i don't really care about the genetic sex of the organism i

1137
01:18:12,450 --> 01:18:16,990
want to make sure that the going have sex and the brain sex are well-matched

1138
01:18:17,010 --> 01:18:22,380
because the purpose of course is always to promote effective reproduction for transfer genes down

1139
01:18:22,380 --> 01:18:24,870
to the next generation

1140
01:18:24,870 --> 01:18:32,410
this changed to male versus female female phenotype of of the brain occurs very early

1141
01:18:32,420 --> 01:18:35,930
in development and as i said in humans it will begin doing the second try

1142
01:18:35,930 --> 01:18:41,300
mister very early on in our role models we know exactly when it occurs because

1143
01:18:41,300 --> 01:18:45,850
we can manipulate them and what you're looking at here is that the blue peaks

1144
01:18:45,850 --> 01:18:52,110
and valleys are testosterone circulating in the fetal circulation many people tend to think of

1145
01:18:52,120 --> 01:18:58,440
testosterone and estrogens is hormones that only appear at puberty but in fact the whole

1146
01:18:58,480 --> 01:19:02,370
hypothalamus pituitary canal axis is fully mature

1147
01:19:02,430 --> 01:19:03,550
in utero

1148
01:19:03,560 --> 01:19:11,080
and completely active so the male fetus will begin producing very copious quantities of testosterone

1149
01:19:11,410 --> 01:19:16,060
which begins in the rodent embryonic lee in the last couple days of pregnancy and

1150
01:19:16,060 --> 01:19:19,040
continues the first couple days after birth

1151
01:19:19,060 --> 01:19:25,090
in humans a newborn human male baby has the circulating testosterone of the twenty five

1152
01:19:25,090 --> 01:19:32,170
year-old adult that that testosterone will go away as that reproductive axis is silenced and

1153
01:19:32,170 --> 01:19:35,470
will remain silent hopefully for good

1154
01:19:35,490 --> 01:19:39,480
twelve to thirteen years until puberty re-emerges

1155
01:19:39,490 --> 01:19:45,330
we call this early period of hormone exposure the organisational period and it will determine

1156
01:19:45,590 --> 01:19:52,780
how the hormones post world war act on the brain the activation of period one

1157
01:19:52,780 --> 01:19:56,810
of the advantages of our own animal model is that this period does extend into

1158
01:19:56,810 --> 01:20:01,560
the postnatal period so after the animals are born and we can identify was called

1159
01:20:01,560 --> 01:20:07,930
the sensitive period for this organisation we identified by giving injections of testosterone to female

1160
01:20:07,930 --> 01:20:13,560
rats and asking if their brain has turned into a male rat brain once we

1161
01:20:13,560 --> 01:20:18,300
get outside of the sensitive period the female no longer response to this injection of

1162
01:20:18,300 --> 01:20:23,180
testosterone program will forever stay female

1163
01:20:23,210 --> 01:20:28,390
so how do we connect brain sex differences to sex differences in behavior

1164
01:20:28,480 --> 01:20:32,360
it's very challenging because we can manipulate the brain in the same way we can

1165
01:20:32,360 --> 01:20:37,640
do so peripheral organs but what we can do is determine the cellular mechanisms so

1166
01:20:37,640 --> 01:20:41,510
if we know that humans are causing brain changes and we think brain changes are

1167
01:20:41,510 --> 01:20:46,340
correlated with behavioral changes we want to identify what it is that the hormone is

1168
01:20:46,340 --> 01:20:52,790
regulating to change the brain and subsequently the behaviour just call that factor x because

1169
01:20:52,790 --> 01:20:57,650
it differ for every different brain regions and point it can be different factors and

1170
01:20:57,650 --> 01:21:01,110
one of the things that we can do once you've identified factor axes that we

1171
01:21:01,110 --> 01:21:06,160
can block and show that it blocked both the brain change and the behavioral change

1172
01:21:06,160 --> 01:21:12,510
and that's how we make our logical connections it's really strong convergence we can absolutely

1173
01:21:12,510 --> 01:21:16,280
prove or hypotheses were working in the brain in this

1174
01:21:16,300 --> 01:21:20,030
nature but we can use strong convergence

1175
01:21:20,190 --> 01:21:24,940
so to return to the type one of sex dimorphism carburetor behaviour in the rodent

1176
01:21:24,950 --> 01:21:30,300
is highly sexually dimorphic the males show amounting behaviour of the female and the female

1177
01:21:30,310 --> 01:21:36,990
debs sexually receptive posture called low doses so they show up very different motor response

1178
01:21:36,990 --> 01:21:39,140
when it comes time to copulate

1179
01:21:39,150 --> 01:21:43,540
and we know exactly what the brain area controls as in the male is called

1180
01:21:43,540 --> 01:21:48,590
the pre optic region has nothing to do with vision it's only names that because

1181
01:21:48,590 --> 01:21:53,290
of its proximity to the optic nerve this is the brain region where neurons are

1182
01:21:53,290 --> 01:21:58,610
full of receptors for steroids so they are very responsive to steroids and if we

1183
01:21:58,610 --> 01:22:04,530
lesion this brain region the male will lose all interest in sex if developmentally we

1184
01:22:04,530 --> 01:22:09,010
put the streets only in this brain region he will become asking lies in terms

1185
01:22:09,010 --> 01:22:16,020
of his sex behavior if we give females testosterone very early in life in adulthood

1186
01:22:16,040 --> 01:22:19,950
we can get them to mount i can mail when we give them activating levels

1187
01:22:19,950 --> 01:22:22,450
of testosterone a second time

1188
01:22:22,470 --> 01:22:27,790
so as i said some brain regions are larger than others but also the synapses

1189
01:22:28,070 --> 01:22:31,630
are different in males and females and one of the things in my laboratory has

1190
01:22:31,630 --> 01:22:36,840
focused on this particular type of synapse called the dendritic spine part of the reason

1191
01:22:36,840 --> 01:22:40,990
that we focus on it is because it's easy to measure easier to measure than

1192
01:22:40,990 --> 01:22:45,900
other types synapses because dendritic spines are what they sound like the these little tiny

1193
01:22:45,900 --> 01:22:51,050
protruding of of neurons and once we visualize the neuron we can actually just go

1194
01:22:51,050 --> 01:22:55,270
in and count them or we can use the quantification of proteins that are found

1195
01:22:55,270 --> 01:23:00,260
only in the spines and ask if are different in males and females

1196
01:23:00,280 --> 01:23:03,910
so what we did is we just as the very simple question is there are

1197
01:23:03,920 --> 01:23:07,530
sex differences in dendritic spines in the newborn brain

1198
01:23:07,540 --> 01:23:11,330
of rats and this is what that looked like when their newborn little pink is

1199
01:23:11,800 --> 01:23:15,330
so we collected them on the second and third day of life dissected out this

1200
01:23:15,330 --> 01:23:18,110
brain region and then quantified

1201
01:23:18,130 --> 01:23:22,920
and what we found is that the males had almost over twice as many dendritic

1202
01:23:22,920 --> 01:23:27,260
spines as the female were quantified this in two ways one is that we measure

1203
01:23:27,310 --> 01:23:32,360
protein in the spines called spinal filling foot spine loving what you're looking at here

1204
01:23:32,360 --> 01:23:36,850
is what's called the western blot each one of these little black dashes is the

1205
01:23:36,850 --> 01:23:40,950
pre optic area from a single animal so you can see they're all of the

1206
01:23:40,950 --> 01:23:46,380
males have much more this protein then all of the females we also visualize the

1207
01:23:46,380 --> 01:23:52,530
neuron through an ancient process called gold impregnation is actually develop the eighteen hundreds by

1208
01:23:52,530 --> 01:23:57,390
romani cahall and his colleagues his colleague old and what you see these little feathery

1209
01:23:57,390 --> 01:24:02,130
things coming off of this process those are the actual dendritic spines and we can

1210
01:24:02,130 --> 01:24:06,760
go into account and they match perfectly to the protein males have about twice as

1211
01:24:06,760 --> 01:24:08,470
many as females

1212
01:24:08,700 --> 01:24:12,860
so once we characterize the basic sex difference would like to ask how did it

1213
01:24:12,860 --> 01:24:19,310
come about and was regulated by hormones so if we treat the newborn female with

1214
01:24:19,340 --> 01:24:24,740
male hormone injections will she then have a male pattern of synopsis

1215
01:24:24,800 --> 01:24:27,940
so we treated her on the day of birth the next day and measured at

1216
01:24:27,940 --> 01:24:31,670
now which is usually the case

1217
01:24:33,350 --> 01:24:39,860
because for independent independent variables they are probabilities are simply the product of the probabilities

1218
01:24:40,010 --> 01:24:44,340
the definition of independence than what we have is this kind of

1219
01:24:44,360 --> 01:24:49,710
and this kind of a product of the probabilities for each observation

1220
01:24:49,770 --> 01:24:53,470
so for example let's say that we want to estimate

1221
01:24:53,490 --> 01:24:56,710
the this mean parameter u

1222
01:24:56,720 --> 01:25:03,050
for a gaussian distribution so then the probability of all of the sources of the

1223
01:25:03,050 --> 01:25:05,150
samples will be

1224
01:25:05,160 --> 01:25:07,010
the products

1225
01:25:07,060 --> 01:25:13,590
of these expensive is exponential function of x of the observation minus mu

1226
01:25:13,620 --> 01:25:17,940
the squared divided by two times and sigma

1227
01:25:17,950 --> 01:25:22,610
sigma squared and then we have a normalisation constant which is not important here

1228
01:25:22,620 --> 01:25:27,660
so now

1229
01:25:27,700 --> 01:25:36,000
now let me explain you so the point is that

1230
01:25:36,040 --> 01:25:39,420
the reason why we use what we want to use other things all the time

1231
01:25:39,560 --> 01:25:41,000
you simply that

1232
01:25:41,580 --> 01:25:43,920
now when we take the logarithm of that's

1233
01:25:43,940 --> 01:25:48,340
this probability of word given all of these samples

1234
01:25:48,340 --> 01:25:51,140
sorry all these observations

1235
01:25:51,150 --> 01:25:53,700
but it would be some

1236
01:25:53,700 --> 01:26:03,220
of the probabilities

1237
01:26:03,290 --> 01:26:06,640
now the point is that such a much simpler to work with them products for

1238
01:26:06,640 --> 01:26:11,280
example now so we have here parameter

1239
01:26:11,300 --> 01:26:15,590
the so much for example when we want to compute the derivative

1240
01:26:15,670 --> 01:26:18,780
so that we can find the maximum of course then the

1241
01:26:18,890 --> 01:26:20,390
well this thing

1242
01:26:20,390 --> 01:26:21,670
of the many people

1243
01:26:21,680 --> 01:26:25,170
of the sum is simply the sum of the derivatives

1244
01:26:25,630 --> 01:26:28,780
and so that's the story that's

1245
01:26:28,810 --> 01:26:33,150
that's it suffices life very much we basically just need to compute the derivative of

1246
01:26:33,150 --> 01:26:36,630
the log probability and then some of those together

1247
01:26:40,600 --> 01:26:42,530
and as we saw this is this

1248
01:26:42,560 --> 01:26:46,920
the situation becomes very very simple when we have a gaussian distribution because then the

1249
01:26:46,920 --> 01:26:51,380
logarithm is a quadratic form and when we take the derivative will actually get the

1250
01:26:51,380 --> 01:26:57,960
linear function is actually what we get is things like we get like linear equations

1251
01:26:58,040 --> 01:27:03,330
solve in the case of the estimated that this would go some variables are very

1252
01:27:03,330 --> 01:27:06,830
nice and popular and everybody likes them

1253
01:27:08,940 --> 01:27:10,200
so here

1254
01:27:10,200 --> 01:27:11,440
now were

1255
01:27:11,470 --> 01:27:15,940
we have taken the name and logo isn't it the sequel to one of those

1256
01:27:15,940 --> 01:27:17,530
articles is zero

1257
01:27:19,170 --> 01:27:23,810
taking the derivative well this just as this is even simpler because this is one-dimensional

1258
01:27:23,830 --> 01:27:27,720
so we don't have the quadratic form we seem to have a quadratic function

1259
01:27:27,750 --> 01:27:34,840
and while the derivative of the square will be simply the identity function is

1260
01:27:34,850 --> 01:27:37,940
you cite and we see that

1261
01:27:37,960 --> 01:27:44,470
yes the the we see that the maximum likelihood estimator formula it will simply

1262
01:27:44,490 --> 01:27:46,920
the the average

1263
01:27:46,930 --> 01:27:48,840
of the observations

1264
01:27:48,860 --> 01:27:51,330
which is reasonable because we knew that

1265
01:27:51,340 --> 01:27:57,130
new is is the mean value of its distribution so it's reasonable to approximate that

1266
01:27:57,140 --> 01:28:01,380
is estimated by the average of the observations

1267
01:28:06,110 --> 01:28:11,360
sorry i should go there so so that ends basically the

1268
01:28:11,410 --> 01:28:13,860
introduction part

1269
01:28:13,880 --> 01:28:18,330
and now i think i really

1270
01:28:18,350 --> 01:28:21,920
try to get some more slide so

1271
01:28:43,330 --> 01:28:51,290
same is the case then

1272
01:28:55,440 --> 01:28:56,590
yes mica

1273
01:28:57,970 --> 01:29:05,790
well i'm a bit confused about i should say that this is the first

1274
01:29:06,750 --> 01:29:11,360
few slides to show you that what is actually to be made

1275
01:29:11,510 --> 01:29:18,050
the basic idea of what is really difference between ICMP c is actually more if

1276
01:29:18,050 --> 01:29:21,010
you don't remember anything from this lectures

1277
01:29:21,020 --> 01:29:23,280
then one single sentence

1278
01:29:23,290 --> 01:29:29,990
which may be quite reasonable expectation given my my boring way of speaking well you

1279
01:29:29,990 --> 01:29:30,750
remember the the

1280
01:29:30,990 --> 01:29:35,040
this is really a very different thing from principal component analysis

1281
01:29:35,230 --> 01:29:37,950
it is well

1282
01:29:38,330 --> 01:29:43,530
the persons who first proposed ICA the kind of thought that well it's kind of

1283
01:29:43,530 --> 01:29:47,540
the same thing as principal component analysis so they gave the name that's rather the

1284
01:29:47,540 --> 01:29:52,590
similar body test it leads to a lot of confusion

1285
01:29:52,600 --> 01:29:56,630
it is really what this talk what these two techniques have in common is that

1286
01:29:56,630 --> 01:30:03,670
they are i mean that apart component analysis that is through both analyzing data into

1287
01:30:03,670 --> 01:30:07,690
components and actually i usually do it in a linear manner

1288
01:30:07,700 --> 01:30:12,980
but the way these components are computed and

1289
01:30:14,240 --> 01:30:21,110
uh the objectives in computing this components i mean the purpose of computing these components

1290
01:30:21,110 --> 01:30:26,460
are completely different and the principal components are good for certain things and independent components

1291
01:30:26,460 --> 01:30:33,970
are good for other things and the there's hardly any overlap between these two things

1292
01:30:36,160 --> 01:30:37,440
the way

1293
01:30:37,520 --> 01:30:40,870
i see it was considered in the first place it was in the context of

1294
01:30:40,870 --> 01:30:43,670
what is called blind source separation

1295
01:30:43,680 --> 01:30:45,190
so this is

1296
01:30:45,200 --> 01:30:48,890
and this is a problem and as you will see this has

1297
01:30:48,910 --> 01:30:55,460
nothing to do with the fundamental problem that we try to solve with big PCA

1298
01:30:55,510 --> 01:31:00,100
PCA we want to solve this problem at the estimation by a limited number of

1299
01:31:00,100 --> 01:31:04,270
components by the separation is has nothing at all to do with that kind of

1300
01:31:07,650 --> 01:31:11,730
there this this is a bit similar to this idea of to what i so

1301
01:31:11,760 --> 01:31:16,480
you know very very beginning well i had a different images that were mixed together

1302
01:31:16,480 --> 01:31:22,350
says that all have the same orientation at the injection site meaning of this site

1303
01:31:22,410 --> 01:31:27,740
it was a site that like vertical tuning than other cells that like particles

1304
01:31:27,860 --> 01:31:31,410
we are all connected to the site and you can show that this is the

1305
01:31:31,420 --> 01:31:34,570
key property for making pinwheels

1306
01:31:34,570 --> 01:31:36,330
in the auditory cortex

1307
01:31:36,340 --> 01:31:40,040
there is no vision in the normal animal and all cells

1308
01:31:40,080 --> 01:31:44,330
connect to each other that like the same sound frequency

1309
01:31:44,330 --> 01:31:49,080
cells that fire together wire together that's the principle by which

1310
01:31:49,110 --> 01:31:51,830
the word influences connection

1311
01:31:51,890 --> 01:31:57,470
in the rewired auditory cortex connections are much more like the visual cortex and not

1312
01:31:57,470 --> 01:32:00,070
at all like the auditory cortex

1313
01:32:00,110 --> 01:32:04,830
so as long as you have this substrates for transducing

1314
01:32:04,890 --> 01:32:08,550
electrical activity from the word interconnections

1315
01:32:08,590 --> 01:32:12,180
the brain uses that in order to form networks

1316
01:32:12,190 --> 01:32:13,870
this is the way it must be

1317
01:32:13,960 --> 01:32:17,480
because there are not enough genes to make every synapse

1318
01:32:17,510 --> 01:32:19,000
so my genome

1319
01:32:19,010 --> 01:32:23,750
it landed as me has about thirty two thirty five thousand genes

1320
01:32:23,770 --> 01:32:25,270
and the human genome

1321
01:32:25,280 --> 01:32:30,360
they have only about forty five thousand genes so only part more genes

1322
01:32:30,420 --> 01:32:35,070
in people compared to my eyes yet our brains have at least two thousand possibly

1323
01:32:35,070 --> 01:32:37,430
ten thousand more synopsis

1324
01:32:38,750 --> 01:32:40,660
genes cannot do it all

1325
01:32:40,680 --> 01:32:44,910
genes acting together with the world that we live in all the world that grew

1326
01:32:44,910 --> 01:32:46,910
up in or the environment

1327
01:32:46,960 --> 01:32:50,800
we must have a role in shaping

1328
01:32:50,850 --> 01:32:53,070
the networks that are made in the brain

1329
01:32:53,070 --> 01:32:56,320
and these networks

1330
01:32:56,330 --> 01:33:01,130
must be made by molecules that are sensitive to electricity

1331
01:33:01,160 --> 01:33:03,130
and electrical activity and the

1332
01:33:03,140 --> 01:33:05,040
and the pattern of activity

1333
01:33:06,300 --> 01:33:09,550
takes information from the world and cries brain

1334
01:33:09,560 --> 01:33:11,550
the only information

1335
01:33:11,560 --> 01:33:16,330
that auditory cortex has about the world is in the pattern of electrical activity in

1336
01:33:16,330 --> 01:33:19,030
its inputs OK it has no other information

1337
01:33:19,070 --> 01:33:21,580
and it uses the pattern of activity

1338
01:33:21,630 --> 01:33:26,090
given by vision make one kind of network driven by audition to make another kind

1339
01:33:26,090 --> 01:33:32,020
of network the same cortex but in a very different networks depending on what drives

1340
01:33:34,670 --> 01:33:35,490
so then

1341
01:33:35,490 --> 01:33:37,780
we've learned a little bit about how

1342
01:33:37,800 --> 01:33:39,620
the brain by itself

1343
01:33:39,670 --> 01:33:44,020
we have learned that that this to and from cortex associated molecules

1344
01:33:44,020 --> 01:33:46,730
and cortical networks shared by input activity

1345
01:33:46,740 --> 01:33:50,420
and how might be then two together with the media behaviour not going to tell

1346
01:33:50,420 --> 01:33:52,790
you a lot about this except to say

1347
01:33:52,840 --> 01:33:54,660
rewired animals

1348
01:33:54,670 --> 01:33:55,920
do we use

1349
01:33:58,140 --> 01:33:59,940
cortex to see

1350
01:34:00,050 --> 01:34:04,690
there are different kinds of experiments if you can demonstrate that

1351
01:34:04,750 --> 01:34:07,090
so the lesson from all of this

1352
01:34:07,130 --> 01:34:11,670
so so this is the picture of the rewired auditory cortex

1353
01:34:11,690 --> 01:34:14,630
and you can't tell it apart from normal cortex

1354
01:34:14,670 --> 01:34:17,630
this is also a picture of the dot like

1355
01:34:18,110 --> 01:34:23,460
grain that i told you about these other the kinds of pictures that romans used

1356
01:34:23,460 --> 01:34:25,690
to derive

1357
01:34:25,710 --> 01:34:29,750
his images of where might one part of the brain

1358
01:34:29,840 --> 01:34:33,520
i one function or another part might derive another function

1359
01:34:33,540 --> 01:34:34,860
but what

1360
01:34:34,900 --> 01:34:39,630
this work our work and the work of others in i feel suggests that cortical

1361
01:34:39,630 --> 01:34:43,360
activity the networks derived function from the inputs

1362
01:34:43,360 --> 01:34:47,520
the auditory cortex can function like visual cortex depending on the nature of input during

1363
01:34:47,520 --> 01:34:53,710
development that wired networks in order to process that

1364
01:34:53,750 --> 01:34:55,710
people can be what to

1365
01:34:55,770 --> 01:34:58,540
it's not simply that it's that the wire

1366
01:34:58,560 --> 01:35:02,170
but there are people who are congenitally blind

1367
01:35:02,170 --> 01:35:03,540
in in home

1368
01:35:03,570 --> 01:35:06,040
the visual cortex doesn't just said

1369
01:35:06,090 --> 01:35:08,500
it does other things processes

1370
01:35:08,500 --> 01:35:12,860
for example the this is the work from marc pallot and you the russian labs

1371
01:35:12,860 --> 01:35:18,610
so is the opposite of our experiments to complement about experiments if there are so

1372
01:35:18,710 --> 01:35:20,400
that is the dynamic

1373
01:35:20,420 --> 01:35:28,460
aspect of brain development where the inputs and pathways and networks are constantly being shipped

1374
01:35:28,540 --> 01:35:32,070
one by the other

1375
01:35:32,170 --> 01:35:34,130
if we can make networks

1376
01:35:34,330 --> 01:35:36,460
in the auditory cortex

1377
01:35:36,480 --> 01:35:39,400
become like visual

1378
01:35:39,420 --> 01:35:40,710
it is possible

1379
01:35:40,730 --> 01:35:42,170
that we might one day

1380
01:35:42,170 --> 01:35:44,110
the networks in a dish

1381
01:35:44,130 --> 01:35:48,400
if you can provide it the right kind of electrical stimulation

1382
01:35:49,500 --> 01:35:54,380
think that's the fantasy but not unrealizable

1383
01:35:54,380 --> 01:35:56,980
and so

1384
01:35:57,040 --> 01:35:58,360
these brain cells

1385
01:35:58,380 --> 01:36:02,770
from the visual cortex of rats growing in addition to the the synapse

1386
01:36:02,920 --> 01:36:05,670
and in my lab

1387
01:36:05,790 --> 01:36:07,860
in collaboration with barbed languor

1388
01:36:07,860 --> 01:36:11,650
we can make brain cells grown in microelectrodes are so now

1389
01:36:11,690 --> 01:36:15,980
that's not why is that are bringing the pattern of activity from vision into the

1390
01:36:15,980 --> 01:36:21,380
into the auditory cortex but electrodes that can be stimulating says that are growing on

1391
01:36:21,380 --> 01:36:25,070
them in order to help them self organised that

1392
01:36:25,090 --> 01:36:26,330
make networks

1393
01:36:26,340 --> 01:36:28,060
and here it is

1394
01:36:28,060 --> 01:36:31,210
a kind of network that is made by

1395
01:36:31,270 --> 01:36:34,170
cells that we are recording from here the cell

1396
01:36:34,190 --> 01:36:40,520
we record from it by by by catching onto it and here are stimulation sites

1397
01:36:40,590 --> 01:36:42,400
and in this

1398
01:36:42,630 --> 01:36:45,730
in this case it was certain pattern of stimulation given

1399
01:36:45,750 --> 01:36:48,210
and you can see that the cell

1400
01:36:48,210 --> 01:36:52,710
is driven much more by this electrode last but that not by that this is

1401
01:36:52,710 --> 01:36:55,130
what is called the cell's receptive field

1402
01:36:55,190 --> 01:36:58,340
and it's actually if it is affected by this

1403
01:36:58,400 --> 01:37:00,940
for its inputs to make it

1404
01:37:01,000 --> 01:37:02,960
and if what is called a low pass filter

1405
01:37:02,980 --> 01:37:08,460
but it is the most elementary of computations that we can create conditions

1406
01:37:08,520 --> 01:37:13,920
we can also lay down to is on biodegradable substrates

1407
01:37:13,960 --> 01:37:19,900
shown here and then lay down neurons and stimulate them and helped them organize into

1408
01:37:19,900 --> 01:37:24,900
networks so we can make pact with and networks in substrates and one day

1409
01:37:24,940 --> 01:37:31,090
it is possible that these will serve as implants for recovery from strokes

1410
01:37:32,110 --> 01:37:36,110
what do these experiments me i'm going to spend the last five minutes

1411
01:37:36,310 --> 01:37:37,420
talking about

1412
01:37:37,480 --> 01:37:39,710
why it is unlikely

1413
01:37:39,730 --> 01:37:42,560
so when i talk about this immediately as

1414
01:37:42,610 --> 01:37:43,830
you know i find

1415
01:37:43,840 --> 01:37:45,230
to create a brain

1416
01:37:45,270 --> 01:37:47,070
and with this being intelligence

1417
01:37:47,150 --> 01:37:48,670
and the answer is no

1418
01:37:48,670 --> 01:37:52,650
i don't think so and the answer has to do with the deep structure of

1419
01:37:52,650 --> 01:37:58,710
the brain and mind of cognition and in five minutes i'll take you through that

1420
01:37:59,360 --> 01:38:02,770
what does it mean to have in mind

1421
01:38:02,770 --> 01:38:05,270
and that's a hard question

1422
01:38:06,130 --> 01:38:08,420
the mind fundamentally

1423
01:38:08,460 --> 01:38:12,190
it has to do with extracting meaning from the work

1424
01:38:12,230 --> 01:38:14,440
and from the world of stimuli

1425
01:38:15,480 --> 01:38:18,060
there are two examples

1426
01:38:18,380 --> 01:38:23,560
the great examples of extracting meaning or semantics from the web so

1427
01:38:23,610 --> 01:38:27,270
four for a long time the part about how the brain creates the mind and

1428
01:38:28,330 --> 01:38:31,480
free knowledge just found just golf

1429
01:38:31,540 --> 01:38:32,750
fanciful idea

1430
01:38:32,750 --> 01:38:37,990
OK various ways to speed it up but also there's a problem with the fact

1431
01:38:37,990 --> 01:38:41,960
that you have multiple local minima so there isn't a unique global well maybe a

1432
01:38:41,960 --> 01:38:45,750
unique global solution but but there are lots of local minima

1433
01:38:45,760 --> 01:38:49,470
in the in the white space when you're looking to optimize

1434
01:38:49,480 --> 01:38:51,440
the performance of the network

1435
01:38:51,450 --> 01:38:54,550
so you're into quite difficult

1436
01:38:54,570 --> 01:38:56,900
situation in terms of

1437
01:38:56,920 --> 01:39:00,500
actually getting this thing to work in practice in reliable and

1438
01:39:00,550 --> 01:39:02,360
verifiable way and

1439
01:39:02,370 --> 01:39:06,840
correspondingly the statistics is also more complicated and less

1440
01:39:06,860 --> 01:39:09,220
less understood

1441
01:39:09,260 --> 01:39:14,640
so in contrast the kernel methods approach which was developed much later but well the

1442
01:39:14,640 --> 01:39:19,060
idea actually was in the sixties put forward in

1443
01:39:19,070 --> 01:39:20,810
papers in russia but

1444
01:39:20,830 --> 01:39:22,480
USSR but we're not

1445
01:39:22,490 --> 01:39:26,830
seen in the west or understood the potential is not fully understood

1446
01:39:26,880 --> 01:39:30,560
when they were first proposed but anyway believe that the site

1447
01:39:30,590 --> 01:39:35,380
as far as the sort of west is concerned these came to the fore in

1448
01:39:35,380 --> 01:39:37,010
the nineteen nineties

1449
01:39:37,060 --> 01:39:41,020
so it's a very different approach to solving the same problem so as i mentioned

1450
01:39:41,020 --> 01:39:42,720
the problem is capacity

1451
01:39:42,740 --> 01:39:44,770
how are you going to get

1452
01:39:47,280 --> 01:39:50,000
flexibility into your function class

1453
01:39:50,050 --> 01:39:54,620
and then you functions in the input space and not well

1454
01:39:54,640 --> 01:39:58,570
OK let's try and project the inputs into more complicated space

1455
01:39:58,590 --> 01:40:01,200
and the hope is that the

1456
01:40:01,250 --> 01:40:04,530
the more complicated space has a much higher dimension

1457
01:40:04,540 --> 01:40:08,810
in the input space and in high dimensions

1458
01:40:08,870 --> 01:40:11,180
linear functions have more flexibility

1459
01:40:11,190 --> 01:40:16,000
basically the flexibility of linear function class is actually proportional to its

1460
01:40:16,390 --> 01:40:22,260
dimensions so by putting yourself into a higher dimension you create more flexibility i mean

1461
01:40:22,590 --> 01:40:27,320
intuitively if you add extra features you can do more with by just combining them

1462
01:40:27,320 --> 01:40:28,360
in a linear way

1463
01:40:28,450 --> 01:40:31,130
i mean that's that's what we're trying to do

1464
01:40:31,140 --> 01:40:33,950
so this is a sort of you know

1465
01:40:33,960 --> 01:40:35,580
good idea let's try

1466
01:40:35,630 --> 01:40:38,830
so here's an example of what you might do

1467
01:40:39,550 --> 01:40:43,900
so we take our input vector which might be a two dimensional vector x one

1468
01:40:43,900 --> 01:40:44,940
x two

1469
01:40:44,950 --> 01:40:48,760
and we map have to more complicated vector which has x one squared x one

1470
01:40:48,760 --> 01:40:49,530
x two

1471
01:40:49,540 --> 01:40:53,440
x two x one of these two are the same it just that way to

1472
01:40:53,450 --> 01:40:56,740
to make it sort of easier when we come to look at something a bit

1473
01:40:57,480 --> 01:40:59,150
and x two square

1474
01:40:59,160 --> 01:41:03,110
now if we write a linear equation in this space

1475
01:41:03,130 --> 01:41:05,590
so this is the feature space now

1476
01:41:05,610 --> 01:41:11,020
we take this input method into something a bit more complicated four dimensional

1477
01:41:11,030 --> 01:41:16,170
let's take a linear function of it so a x one squared plus b x

1478
01:41:16,170 --> 01:41:18,000
two squared c

1479
01:41:18,010 --> 01:41:20,750
we have the equation of an ellipse

1480
01:41:20,770 --> 01:41:24,250
and that is not a linear shape in the input space so the input space

1481
01:41:24,250 --> 01:41:27,370
linear functions in the two dimensional space straight lines

1482
01:41:27,380 --> 01:41:29,930
so we managed to create a function

1483
01:41:29,980 --> 01:41:34,420
that is not a straight line in the input space by taking a linear function

1484
01:41:34,440 --> 01:41:36,130
in this

1485
01:41:36,140 --> 01:41:37,380
in this feature space

1486
01:41:37,400 --> 01:41:40,440
so we can see that we have actually increased are

1487
01:41:40,460 --> 01:41:43,850
flexibility by adding in these extra features

1488
01:41:43,870 --> 01:41:47,340
now i'm going to give you an example of how this might work

1489
01:41:47,360 --> 01:41:50,220
so this unfortunately doesn't seem to work when i do it

1490
01:41:50,230 --> 01:41:53,720
here in the

1491
01:41:53,830 --> 01:41:57,090
how point here again OK so

1492
01:41:57,110 --> 01:41:59,240
here's a little video to show how

1493
01:41:59,360 --> 01:42:02,540
here what you have to think is that you're trying to

1494
01:42:02,560 --> 01:42:04,790
do classification problems

1495
01:42:04,810 --> 01:42:09,340
these are very visible but these red dots in the middle these blue dots on

1496
01:42:09,340 --> 01:42:10,690
the outside

1497
01:42:10,710 --> 01:42:14,370
and you're going to try and separate the red dots from the blue dots

1498
01:42:14,390 --> 01:42:20,070
you know as a classification problem clearly with the straight line you can't do that

1499
01:42:20,080 --> 01:42:22,070
OK so

1500
01:42:22,090 --> 01:42:24,600
so what do you do have so

1501
01:42:24,610 --> 01:42:26,600
here the video show you

1502
01:42:26,620 --> 01:42:29,690
so you turn it into a three-dimensional problem

1503
01:42:29,710 --> 01:42:35,090
by projection you then do linear function in three dimensions which is now a plane

1504
01:42:35,110 --> 01:42:37,130
that cuts across

1505
01:42:37,170 --> 01:42:39,360
the three-dimensional structure

1506
01:42:39,380 --> 01:42:42,300
and when you go back to the input space

1507
01:42:42,320 --> 01:42:45,130
you've got a circle

1508
01:42:45,150 --> 01:42:51,150
so what was a straight you know linear function that feature space actually becomes nonlinear

1509
01:42:51,170 --> 01:42:55,040
in the input space and can do this more flexible job for you

1510
01:42:55,050 --> 01:42:58,540
i can try again now

1511
01:42:58,550 --> 01:43:00,060
OK so

1512
01:43:02,050 --> 01:43:04,950
o thing that gives you a flavour of the kind of

1513
01:43:05,230 --> 01:43:08,190
an intuition of what's happening

1514
01:43:10,200 --> 01:43:15,060
OK so what do we know what we know about capacity of of functions classes

1515
01:43:15,690 --> 01:43:17,240
i mean linear function classes

1516
01:43:18,080 --> 01:43:21,870
as i mentioned before the capacities is actually proportional to the dimension and there's this

1517
01:43:21,870 --> 01:43:24,250
theorem says OK given

1518
01:43:24,270 --> 01:43:26,130
and plus one examples

1519
01:43:26,140 --> 01:43:29,490
in general position in an n dimensional space

1520
01:43:29,510 --> 01:43:33,880
we can generate every possible classification the thresholded linear function so what i mean by

1521
01:43:33,880 --> 01:43:36,240
that is here is a two dimensional space

1522
01:43:36,250 --> 01:43:38,270
not very well

1523
01:43:38,290 --> 01:43:43,320
orthogonal these axes and all that isn't so that these these the hyperlinks like there

1524
01:43:43,320 --> 01:43:44,760
are three points here

1525
01:43:44,770 --> 01:43:49,330
and we're going to try and do a different classifications for instance let's say that

1526
01:43:49,330 --> 01:43:50,700
they are all positive

1527
01:43:50,710 --> 01:43:53,980
OK this hyperplane this line here

1528
01:43:54,010 --> 01:43:57,040
with this the positive side makes them more positive

1529
01:43:57,050 --> 01:44:00,870
the same one which is the positive side a small negative

1530
01:44:00,880 --> 01:44:04,550
OK well what other things could happen well this could be positive in these two

1531
01:44:04,550 --> 01:44:08,140
could be negative OK well this line does that for us

1532
01:44:08,150 --> 01:44:11,460
by just saying this is the positive side of the negative side and so on

1533
01:44:11,460 --> 01:44:13,850
every other combination there a possible

1534
01:44:13,860 --> 01:44:15,650
combinations that you might have

1535
01:44:15,660 --> 01:44:17,490
and these four

1536
01:44:17,680 --> 01:44:20,670
the lines will realise every possible combination

1537
01:44:20,690 --> 01:44:22,970
so you've got this flexibility there

1538
01:44:22,990 --> 01:44:27,750
to do whatever you like with three points in two dimensions three

1539
01:44:27,790 --> 01:44:31,120
you know n plus one examples in m dimensions two

1540
01:44:31,130 --> 01:44:32,730
and is two in this case

1541
01:44:32,750 --> 01:44:35,790
and we've got three examples and we can do what we like and that generalizes

1542
01:44:35,790 --> 01:44:36,950
up to

1543
01:44:37,400 --> 01:44:39,010
any and

1544
01:44:39,030 --> 01:44:41,180
so in other words

1545
01:44:41,190 --> 01:44:44,770
you know by by moving up to this high dimensional space we've shown sort of

1546
01:44:44,770 --> 01:44:48,060
with an example that we get more power and here's the theorem tells us yes

1547
01:44:48,060 --> 01:44:51,780
you do get definitely a lot more

1548
01:44:51,830 --> 01:44:57,300
and so yeah OK looks like we solve the problem that we started with that

1549
01:44:57,300 --> 01:45:01,060
was the problem of having too little capacity in in the input space

1550
01:45:01,080 --> 01:45:03,210
linear functions in input space

1551
01:45:03,230 --> 01:45:04,740
so that's good news

1552
01:45:04,750 --> 01:45:08,050
so what we're looking at is functions of this type

1553
01:45:08,050 --> 01:45:11,950
play by contrast could keep the ball for six point racing they also have five

1554
01:45:11,950 --> 01:45:15,480
losses four keepaway and had this distinction between the learning

1555
01:45:15,490 --> 01:45:20,390
and here is five was for people where really should get in another demo of

1556
01:45:20,390 --> 01:45:24,510
reinforcement learning problem and my against how do you think about how this is a

1557
01:45:24,510 --> 01:45:29,370
reinforcement learning problem and i think about what the senses are the actuators are what

1558
01:45:29,380 --> 01:45:36,640
the reward function is because the three basic elements reinforcement learning from sensors actuators reinforcement

1559
01:45:36,880 --> 01:45:40,840
serious texas we will play this is about one by

1560
01:45:41,110 --> 01:45:45,080
drew bagnell and jeff schneider and

1561
01:45:45,130 --> 01:45:46,770
i you should be able to see the

1562
01:45:46,780 --> 01:45:50,690
the block is falling but using the actions you seeing

1563
01:45:50,700 --> 01:45:54,180
the block the the where the block lands and so

1564
01:45:54,220 --> 01:46:01,520
the sensors in here are sensitive inform the the the agent about the shape and

1565
01:46:01,520 --> 01:46:05,550
the height of the blocks on the floor and the shape of the object the

1566
01:46:05,550 --> 01:46:10,420
location of the objects falling and the actions are to remove the object right left

1567
01:46:10,420 --> 01:46:12,570
the obvious falling or two

1568
01:46:12,580 --> 01:46:13,790
push it all the way down

1569
01:46:13,800 --> 01:46:17,980
my usual things that you would do it you play interest

1570
01:46:19,790 --> 01:46:24,990
the reward function would be for example one unit of reward for every time step

1571
01:46:25,040 --> 01:46:26,450
game not

1572
01:46:26,460 --> 01:46:33,440
so maximizing that would then lead to all these sort of optimisation

1573
01:46:34,840 --> 01:46:39,730
just take those problems can make reinforced concrete now let me step back and talk

1574
01:46:39,730 --> 01:46:43,060
a bit more about the history in place of reinforcement learning and i will dive

1575
01:46:43,060 --> 01:46:45,840
into the markov decision process framework

1576
01:46:46,490 --> 01:46:51,160
in some ways reinforcement learning has has

1577
01:46:51,210 --> 01:46:53,680
has had input from and

1578
01:46:53,700 --> 01:46:59,520
actually output ideas from multiple different disciplines analysis some of these here because i

1579
01:46:59,530 --> 01:47:00,660
it's actually touched on

1580
01:47:00,670 --> 01:47:04,450
some of these ideas come from these different disciplines what we talk about neuroscience let

1581
01:47:04,450 --> 01:47:07,830
me begin with that i would talk much about that so i mean

1582
01:47:07,850 --> 01:47:13,120
say a couple of sentences about it and then we want that this is particularly

1583
01:47:13,120 --> 01:47:16,840
over the last five years or so we have a great deal of excitement the

1584
01:47:16,840 --> 01:47:21,860
intersection of neuroscience reinforcement in particular there has been a

1585
01:47:21,880 --> 01:47:26,580
part of the brain the basal ganglia on the dopamine system in particular that has

1586
01:47:26,580 --> 01:47:28,670
been shown pretty convincingly now

1587
01:47:28,720 --> 01:47:33,310
to actually implement an algorithm tell you about today the temple different thing out

1588
01:47:33,350 --> 01:47:34,720
so the part of the brain

1589
01:47:34,740 --> 01:47:36,610
that's a fairly convincingly

1590
01:47:37,550 --> 01:47:40,730
is shown to be implemented the TTL

1591
01:47:40,770 --> 01:47:44,580
so as you can imagine this is very exciting for reinforcement learning researchers process being

1592
01:47:44,580 --> 01:47:50,110
very exciting neuroscience people because now they have a connection to all this wonderful i

1593
01:47:50,110 --> 01:47:53,410
think pieces of work and enforcement learning that they can

1594
01:47:53,420 --> 01:47:57,330
map their ideas by that i just want to a whole bunch of other working

1595
01:47:57,330 --> 01:48:02,450
in neuroscience that has ideas of reinforcement learning really want talk about if you're really

1596
01:48:02,450 --> 01:48:07,750
interested in that sort of that's direction i can mention the name

1597
01:48:07,770 --> 01:48:12,260
probably fall on the names petered and d year y and just two google search

1598
01:48:12,260 --> 01:48:14,330
to find and

1599
01:48:14,340 --> 01:48:17,400
from his papers you can make lot of connections

1600
01:48:17,520 --> 01:48:24,030
OK a very strong intersection exists between operations research in reinforcement learning in factored markov

1601
01:48:24,030 --> 01:48:29,530
decision process formulation the ponte formulation come from operations research was a very strong interplay

1602
01:48:29,530 --> 01:48:35,460
between operations research to reinforcement learning and so the researchers some very good researchers reinforcement

1603
01:48:35,490 --> 01:48:37,440
companies community and a bit

1604
01:48:37,450 --> 01:48:43,350
contributions back to this community from reinforcement obvious connection to artificial intelligence

1605
01:48:43,370 --> 01:48:47,540
much of the origin reinforcement learning actually started mathematical psychology

1606
01:48:47,550 --> 01:48:52,260
bush was stellar i can show you quote in a minute from mathematical psychology

1607
01:48:52,280 --> 01:48:54,580
has an idea of the reinforcement of the ideas

1608
01:48:54,590 --> 01:48:56,060
and finally

1609
01:48:56,070 --> 01:48:58,610
control theory properly control

1610
01:48:58,620 --> 01:49:03,580
intersects operations research and reinforcement learning because in some sense the reinforcement learning view of

1611
01:49:03,580 --> 01:49:07,520
the AI problem is that problems in optimal control

1612
01:49:07,580 --> 01:49:09,130
this is a very strong

1613
01:49:09,190 --> 01:49:11,610
and obviously into intersection that you'll see

1614
01:49:11,620 --> 01:49:15,760
develop some of this is the quote that i want to share with you this

1615
01:49:15,760 --> 01:49:22,330
is from thorndike law of effect and really from way back in nineteen eleven captures

1616
01:49:22,410 --> 01:49:23,350
the essence

1617
01:49:24,170 --> 01:49:28,130
the idea of reinforcement learning and i'll read it to you and of course is

1618
01:49:28,210 --> 01:49:32,180
fall on the screen and the basic idea of several responses made to the same

1619
01:49:32,180 --> 01:49:35,690
situation those which are followed by a company closely

1620
01:49:35,710 --> 01:49:37,240
in time

1621
01:49:37,270 --> 01:49:41,290
my satisfaction to the animal will other things being equal be more firmly connected with

1622
01:49:41,290 --> 01:49:42,390
the situation

1623
01:49:42,400 --> 01:49:47,080
so that in the same situation we could see the reaction is more likely to

1624
01:49:47,140 --> 01:49:49,490
and the opposite for the opposite

1625
01:49:49,510 --> 01:49:52,200
right so this idea of

1626
01:49:52,250 --> 01:49:58,430
temporal coincidence between the situation and effect for my satisfaction leads to strengthening of that

1627
01:50:01,350 --> 01:50:06,110
has been around for a long time and essentially is a foundational principle of the

1628
01:50:06,110 --> 01:50:10,680
of reinforcement learning and i'll and you know and i will develop this talk about

1629
01:50:10,690 --> 01:50:15,050
temple saying i want really believe much more about history but there's a whole lotta

1630
01:50:15,050 --> 01:50:18,450
history of

1631
01:50:18,450 --> 01:50:21,840
people building reinforcement learning ideas in

1632
01:50:21,860 --> 01:50:27,990
in the field of computer science and artificial intelligence starting during really all idea programming

1633
01:50:27,990 --> 01:50:32,540
can be learned by trial and error biscuits on and i what's what time this

1634
01:50:36,300 --> 01:50:39,110
i promise i'm going to get to some very far work very soon i want

1635
01:50:39,310 --> 01:50:44,930
to continue building the connection between reinforcement learning and other areas for a few more

1636
01:50:44,930 --> 01:50:49,460
slide so here we are trying to do is distinguish reinforcement learning from the other

1637
01:50:49,460 --> 01:50:53,340
is the machine learning that more people are familiar with which is supervised and unsupervised

1638
01:50:53,340 --> 01:50:57,950
learning so supervised learning and learning from examples

1639
01:50:57,950 --> 01:51:04,410
learning approaches to regression classification unsupervised learning our learning approach to most induction density estimation

1640
01:51:04,410 --> 01:51:05,900
and so on

1641
01:51:06,010 --> 01:51:12,130
in this context what reinforcement learning reinforcement learning is learning approaches to sequential decision making

1642
01:51:12,140 --> 01:51:14,480
learning from delayed reward

1643
01:51:14,490 --> 01:51:16,900
so let me explain this distinction

1644
01:51:16,910 --> 01:51:18,510
a key

1645
01:51:18,530 --> 01:51:22,230
key question the reinforcement learning asks that is not passed

1646
01:51:22,230 --> 01:51:24,710
by supervised and unsupervised learning is the following

1647
01:51:24,720 --> 01:51:26,530
imagine you play

1648
01:51:26,550 --> 01:51:28,560
the game of chess

1649
01:51:28,560 --> 01:51:33,370
o rules and you know it

1650
01:51:34,270 --> 01:51:36,270
is that

1651
01:51:50,850 --> 01:51:55,500
will be very small

1652
01:51:59,410 --> 01:52:05,640
what about half of all of

1653
01:52:07,810 --> 01:52:14,940
so that's what we already from UK

1654
01:52:14,960 --> 01:52:18,100
and that's what we observe

1655
01:52:24,460 --> 01:52:32,640
o you

1656
01:52:34,540 --> 01:52:40,600
i don't know

1657
01:52:40,620 --> 01:52:42,810
on the day

1658
01:52:54,910 --> 01:53:00,600
the number of all

1659
01:53:00,620 --> 01:53:06,540
and i i

1660
01:53:06,980 --> 01:53:11,640
this is the

1661
01:53:11,870 --> 01:53:14,660
the right of

1662
01:53:14,680 --> 01:53:15,270
it is

1663
01:53:16,600 --> 01:53:23,060
out of that

1664
01:53:32,080 --> 01:53:34,750
in fact

1665
01:53:36,710 --> 01:53:38,420
so do we

1666
01:53:42,500 --> 01:53:45,270
are not

1667
01:53:48,160 --> 01:53:50,710
and these factors

1668
01:53:50,710 --> 01:54:00,140
that a you may right

1669
01:54:00,560 --> 01:54:07,910
wrong that

1670
01:54:16,940 --> 01:54:19,480
and back

1671
01:54:29,270 --> 01:54:35,730
is that depends on what you do that all the variables

1672
01:54:36,040 --> 01:54:39,940
the data

1673
01:54:50,250 --> 01:55:01,390
very well with all the way back to the one

1674
01:55:01,420 --> 01:55:05,920
you need to do is read

1675
01:55:05,940 --> 01:55:07,850
by the way

1676
01:55:17,180 --> 01:55:19,060
that's not

1677
01:55:21,250 --> 01:55:23,850
and q

1678
01:55:23,870 --> 01:55:27,000
that the

1679
01:55:31,000 --> 01:55:33,330
so in order

1680
01:55:38,330 --> 01:55:53,440
and i want to move any does not the

1681
01:55:53,460 --> 01:55:55,980
all right

1682
01:55:56,160 --> 01:56:00,120
one that we use

1683
01:56:00,140 --> 01:56:03,190
about the

1684
01:56:20,940 --> 01:56:23,080
it's not really fair to

1685
01:56:26,790 --> 01:56:31,390
you know that they can actually

1686
01:56:31,460 --> 01:56:36,480
my name is one

1687
01:56:54,160 --> 01:57:03,350
all the the way we are

1688
01:57:03,370 --> 01:57:04,960
know are

1689
01:57:04,980 --> 01:57:08,420
are correct

1690
01:57:08,480 --> 01:57:11,060
there's no

1691
01:57:11,060 --> 01:57:14,880
that's what we want we want to be able to estimate that the thing that

1692
01:57:14,880 --> 01:57:16,250
it's called the input data

1693
01:57:16,260 --> 01:57:17,840
expected risk

1694
01:57:17,850 --> 01:57:23,480
so because it's unbiased let's try to to find the best function

1695
01:57:25,250 --> 01:57:28,540
all over our training set

1696
01:57:28,840 --> 01:57:34,820
according to the empirical risk this is called the empirical risk minimization principle

1697
01:57:34,840 --> 01:57:38,040
and there

1698
01:57:38,040 --> 01:57:39,400
in fact it's also

1699
01:57:39,420 --> 01:57:43,280
computing the value of the of the

1700
01:57:43,350 --> 01:57:48,270
the risk of the best function we could find on the same data

1701
01:57:48,290 --> 01:57:49,180
it's called

1702
01:57:49,210 --> 01:57:54,050
the training area so in general what we call the training error is

1703
01:57:54,750 --> 01:57:56,290
you have a training set of

1704
01:57:56,310 --> 01:58:01,570
for example you have a set of functions and you're searching for the best function

1705
01:58:01,590 --> 01:58:05,160
in the function space according to the training example set of examples that you have

1706
01:58:05,360 --> 01:58:09,660
so you minimize the error on your training set and you get

1707
01:58:09,690 --> 01:58:14,600
minimum error the air that you get is the the air of the best function

1708
01:58:14,600 --> 01:58:21,780
in the function space the best being the one that minimizes the loss function so

1709
01:58:21,780 --> 01:58:26,760
now the question is is that training are a good estimate of

1710
01:58:26,830 --> 01:58:32,080
the the expected risk because what we want is to estimate this

1711
01:58:32,100 --> 01:58:34,800
and unfortunately the answer is

1712
01:58:36,150 --> 01:58:41,760
it is not and in fact it is biased it is

1713
01:58:41,760 --> 01:58:46,550
optimus optimistically biased basically which means that the

1714
01:58:46,560 --> 01:58:50,430
the difference between the

1715
01:58:50,450 --> 01:58:56,560
the there is the the expected risk of the best function you found and the

1716
01:58:56,560 --> 01:58:58,330
training error

1717
01:58:58,340 --> 01:59:04,140
is positive so the expected risk of your best function is always going to be

1718
01:59:06,640 --> 01:59:10,700
than the the training or you've got so so if you just minimize friction over

1719
01:59:10,700 --> 01:59:16,730
your version space or a training example of examples you are going to think that

1720
01:59:16,730 --> 01:59:20,310
your function is great it's going to have a very small training error

1721
01:59:20,320 --> 01:59:24,590
great but in fact it's not going to be good according to the real data

1722
01:59:24,590 --> 01:59:26,570
that you have not seen so

1723
01:59:26,580 --> 01:59:32,740
this is the very important because otherwise learning would be easy basically

1724
01:59:36,040 --> 01:59:40,040
so that's the big problem and where we're not happy about that

1725
01:59:40,920 --> 01:59:45,900
fortunately there are people who try to to bound the difference between the two we

1726
01:59:45,900 --> 01:59:50,200
know that we the air that we made on the training example is going to

1727
01:59:50,200 --> 01:59:54,410
be much smaller than the real error of that function in example that we have

1728
01:59:54,410 --> 02:00:00,330
never seen but how bad is the difference between the two how big is it

1729
02:00:00,370 --> 02:00:03,830
the good thing is that we can bound it we can we can try to

1730
02:00:03,840 --> 02:00:06,060
bound on the difference between the two

1731
02:00:06,150 --> 02:00:11,880
and this bound be depends on some very important concept in statistical machine learning called

1732
02:00:11,880 --> 02:00:12,940
the capacity

1733
02:00:13,960 --> 02:00:16,590
of the set of functions

1734
02:00:17,410 --> 02:00:18,340
so two

1735
02:00:18,340 --> 02:00:23,660
explain you quickly what is the capacity of a set of functions

1736
02:00:25,910 --> 02:00:31,690
it has been defined for the classification case but it can be expanded to any

1737
02:00:31,690 --> 02:00:37,020
any possible OK so in the classification case we call the capacity

1738
02:00:37,020 --> 02:00:39,170
of the set of functions

1739
02:00:40,670 --> 02:00:43,090
the largest number and

1740
02:00:43,090 --> 02:00:48,750
such that you can sort out there exists training example training set of example of

1741
02:00:48,750 --> 02:00:51,960
size n such that

1742
02:00:51,980 --> 02:00:56,560
you can always find a function your function space which would give the correct

1743
02:00:57,090 --> 02:01:03,160
classification discriminate discrimination for any possible labeling

1744
02:01:03,190 --> 02:01:05,340
so what does that mean

1745
02:01:05,340 --> 02:01:09,550
it means that if ten is five

1746
02:01:09,560 --> 02:01:13,120
i can always five find high points

1747
02:01:13,140 --> 02:01:14,110
four which

1748
02:01:14,130 --> 02:01:19,710
all possible combination of labeling say class one one one minus one minus one or

1749
02:01:19,740 --> 02:01:24,430
minus one one minus one with all possible combinations for all of them there would

1750
02:01:24,430 --> 02:01:28,130
be a function the function space that sort of that task

1751
02:01:28,140 --> 02:01:31,820
so this is called the capitalist so it's the biggest number

1752
02:01:31,830 --> 02:01:38,320
that that would have this this characteristic

1753
02:01:38,340 --> 02:01:45,120
what we should understand more in general is this that this capacity reflects the the

1754
02:01:45,120 --> 02:01:49,990
size of the set of functions the complexity of the function you could find into

1755
02:01:49,990 --> 02:01:54,160
that set so the more the bigger is that function space say

1756
02:01:54,180 --> 02:02:00,440
compare the function space of polynomials of order five with a polynomial of order two

1757
02:02:00,450 --> 02:02:05,820
obviously the all the functions of polynomial of order five this percent is much bigger

1758
02:02:05,820 --> 02:02:11,630
and can solve more more task are more be happy with more training sets of

1759
02:02:11,630 --> 02:02:13,130
examples that and

1760
02:02:13,840 --> 02:02:16,260
but you know have set of order two

1761
02:02:16,940 --> 02:02:22,110
and in fact one is included to get one with the polynomials of order five

1762
02:02:22,110 --> 02:02:27,090
there's always this subset of polynomials of order two and that's very good you see

1763
02:02:27,600 --> 02:02:33,040
anyway what's important is that as soon as we have defined this capacity then there

1764
02:02:33,040 --> 02:02:39,870
are several theoretical scientists that were able to bound what we wanted so the difference

1765
02:02:39,870 --> 02:02:40,410
between the

1766
02:02:40,840 --> 02:02:44,080
expected risk what's going to happen to a given function

1767
02:02:44,100 --> 02:02:47,580
on the that we have never seen and the

1768
02:02:47,650 --> 02:02:52,360
the training area which is what we

1769
02:02:52,400 --> 02:02:57,380
what we expect we saw on the training data and we

1770
02:02:57,490 --> 02:03:02,170
we can bound that so the maximum value of the difference is going to be

1771
02:03:02,170 --> 02:03:04,510
borne by some complex

1772
02:03:04,510 --> 02:03:06,580
function here that includes

1773
02:03:06,600 --> 02:03:07,760
the capacity

1774
02:03:07,770 --> 02:03:11,900
the number of of examples sorry the number of examples

1775
02:03:11,930 --> 02:03:16,130
and some at the parameter which defines how

1776
02:03:16,140 --> 02:03:19,190
well how risky want this bound to be

1777
02:03:19,200 --> 02:03:24,980
so if you want to the predicted to exceed that bond is is the is

1778
02:03:24,980 --> 02:03:28,250
very high you can have a very very small value but of course this is

1779
02:03:28,250 --> 02:03:31,350
going to be very very high so

1780
02:03:31,360 --> 02:03:33,250
so what it means is that

1781
02:03:33,260 --> 02:03:38,340
the bound exists but unfortunately it's very very large in general is not

1782
02:03:38,360 --> 02:03:44,440
truly useful worse than that even if the bound exist it depends on that page

1783
02:03:44,450 --> 02:03:45,840
and and that h

1784
02:03:45,860 --> 02:03:46,860
the capacity

1785
02:03:46,880 --> 02:03:48,900
why it's easy to define

1786
02:03:48,940 --> 02:03:54,310
for some classes of function is in general impossible to compute precisely for most of

1787
02:03:54,330 --> 02:03:56,770
the interesting set of functions

1788
02:03:56,780 --> 02:04:01,120
not all of them so for some of them places for the linear a set

1789
02:04:01,120 --> 02:04:04,810
of function we can compute it but for most of the set of functions we

1790
02:04:04,810 --> 02:04:06,990
cannot compute compute that h so

1791
02:04:07,410 --> 02:04:08,560
this is only

1792
02:04:08,560 --> 02:04:14,420
mainly theoretical for most of the case but it helps to know that the difference

1793
02:04:14,420 --> 02:04:19,800
between the training error and test error the generalisation error is bounded and it bounded


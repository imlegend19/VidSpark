1
00:00:00,000 --> 00:00:01,790
so if indeed particles

2
00:00:01,810 --> 00:00:04,630
i ways you should be able to demonstrate that

3
00:00:04,710 --> 00:00:05,770
by having

4
00:00:05,860 --> 00:00:07,430
interference patterns

5
00:00:07,490 --> 00:00:12,010
after particles like the water waves and make it certain locations in space

6
00:00:12,020 --> 00:00:15,220
those particles disappear which turned out to be possible

7
00:00:15,230 --> 00:00:17,110
but that's very nonintuitive

8
00:00:19,630 --> 00:00:24,500
so we think of it two classically when we say well to particles cannot disappear

9
00:00:25,120 --> 00:00:28,290
quantum mechanics you can think in waves if you want to and then you have

10
00:00:28,290 --> 00:00:30,180
no problems with the interference

11
00:00:30,180 --> 00:00:34,960
that and the destructive interference at certain locations

12
00:00:35,010 --> 00:00:38,540
now there are remarkable consequences of quantum mechanics

13
00:00:39,520 --> 00:00:42,120
classical mechanics

14
00:00:43,340 --> 00:00:45,810
you and i are clever enough

15
00:00:45,820 --> 00:00:47,700
you think that we should be able to

16
00:00:48,480 --> 00:00:50,260
determine the position

17
00:00:50,270 --> 00:00:51,470
of an object

18
00:00:51,510 --> 00:00:53,820
for any accuracy that we require

19
00:00:53,880 --> 00:00:55,990
and at the same time

20
00:00:55,990 --> 00:01:00,610
the terminal also its momentum any explicitly we acquire the schematic of how clever we

21
00:01:04,320 --> 00:01:06,160
object is right there

22
00:01:06,340 --> 00:01:10,050
that is its mass and that is its speed

23
00:01:11,770 --> 00:01:13,560
the german

24
00:01:14,620 --> 00:01:17,330
i realized in nineteen twenty seven

25
00:01:17,400 --> 00:01:20,070
the consequence of quantum mechanics is

26
00:01:20,110 --> 00:01:22,530
this is not possible

27
00:01:22,580 --> 00:01:25,210
strange as it may sound to you

28
00:01:25,240 --> 00:01:28,610
i can work stated that the position and momentum

29
00:01:28,630 --> 00:01:30,660
of an object cannot be measured

30
00:01:30,710 --> 00:01:33,770
very accurately at the same time

31
00:01:33,830 --> 00:01:36,540
and i read to you

32
00:01:36,620 --> 00:01:39,810
heisenberg's uncertainty principle the way

33
00:01:39,860 --> 00:01:42,860
we know it says the very concept

34
00:01:42,880 --> 00:01:46,010
of exact position of an object

35
00:01:46,020 --> 00:01:51,940
and it's exact moment together have no meaning in nature

36
00:01:52,040 --> 00:01:55,860
it's a profound non-classical ideas and it is hard for anyone of us

37
00:01:56,920 --> 00:01:59,270
and me included to comprehend

38
00:01:59,320 --> 00:02:00,660
but is consistent

39
00:02:00,670 --> 00:02:03,780
with all experiments that we can do today i want to repeat it because it's

40
00:02:03,780 --> 00:02:05,150
going to be important

41
00:02:05,230 --> 00:02:07,200
of what follows

42
00:02:07,260 --> 00:02:10,970
the very concept of exact position of an object

43
00:02:11,010 --> 00:02:13,950
and it's exact momentum together

44
00:02:13,990 --> 00:02:15,330
i have no meaning

45
00:02:15,350 --> 00:02:18,230
in nature

46
00:02:18,300 --> 00:02:20,160
what does it mean

47
00:02:20,160 --> 00:02:21,730
first let me write down

48
00:02:21,830 --> 00:02:24,820
i books uncertainty principle

49
00:02:24,910 --> 00:02:27,760
delta p which is the uncertainty in the momentum

50
00:02:27,850 --> 00:02:31,430
multiplied by delta x which is in certain positions

51
00:02:31,470 --> 00:02:32,250
of that

52
00:02:34,920 --> 00:02:36,530
or approximately equal

53
00:02:36,620 --> 00:02:39,660
planks constant divided by two pi

54
00:02:39,810 --> 00:02:41,060
from physics

55
00:02:41,080 --> 00:02:42,920
recall that age bar

56
00:02:42,960 --> 00:02:44,190
it's four

57
00:02:44,230 --> 00:02:45,530
is approximately

58
00:02:45,550 --> 00:02:47,540
ten to the minus thirty four

59
00:02:47,590 --> 00:02:49,760
joel sachs

60
00:02:49,800 --> 00:02:52,230
you see eighty six point six

61
00:02:52,330 --> 00:02:54,020
ten to the minus thirty four

62
00:02:54,030 --> 00:02:56,280
if you find it divided by two pi

63
00:02:56,290 --> 00:02:57,860
you get about ten to the minus

64
00:02:57,880 --> 00:02:59,530
thirty four

65
00:02:59,610 --> 00:03:03,610
what does this mean now what it means that if the positions

66
00:03:03,680 --> 00:03:06,710
is known to an accuracy delta x

67
00:03:07,060 --> 00:03:08,910
will give you some examples

68
00:03:08,990 --> 00:03:11,570
that's the momentum

69
00:03:12,400 --> 00:03:15,300
the term is not determined

70
00:03:15,970 --> 00:03:18,260
the amount delta p

71
00:03:18,310 --> 00:03:19,730
larger equal

72
00:03:22,490 --> 00:03:23,930
five i don't

73
00:03:24,120 --> 00:03:25,990
that's what it means

74
00:03:26,040 --> 00:03:27,860
and i'll give you an example

75
00:03:27,870 --> 00:03:30,060
which i chosen from

76
00:03:30,080 --> 00:03:30,950
the book

77
00:03:30,980 --> 00:03:33,060
george kind

78
00:03:33,080 --> 00:03:35,740
come off wrote a book which he called

79
00:03:35,780 --> 00:03:37,510
mister tompkins in wonderland

80
00:03:37,550 --> 00:03:39,530
it's about dreams

81
00:03:39,540 --> 00:03:41,420
mister tomkins

82
00:03:41,420 --> 00:03:43,960
wants to understand the quantum world

83
00:03:44,010 --> 00:03:46,830
and is a professor you'll see a picture of the professor who takes him in

84
00:03:46,830 --> 00:03:48,290
his dreams

85
00:03:50,670 --> 00:03:53,950
remarkable nonintuitive effects of quantum mechanics

86
00:03:53,990 --> 00:03:56,510
any one of these dreams

87
00:03:56,630 --> 00:04:03,550
professor suggests that we make eight four one

88
00:04:03,600 --> 00:04:06,990
the professor takes triangle in the pool table

89
00:04:07,020 --> 00:04:08,560
and he put the triangle

90
00:04:08,570 --> 00:04:12,180
over one billion people

91
00:04:12,250 --> 00:04:14,840
so the billiard ball is constrained

92
00:04:14,920 --> 00:04:16,170
its position

93
00:04:16,210 --> 00:04:18,790
and the delta x

94
00:04:18,830 --> 00:04:22,420
is roughly say ten to thirty centimeters

95
00:04:22,430 --> 00:04:23,750
o point three metres

96
00:04:23,900 --> 00:04:27,060
that means that the

97
00:04:29,010 --> 00:04:32,520
is not determined

98
00:04:32,580 --> 00:04:35,200
not determined to an approximate

99
00:04:35,220 --> 00:04:37,220
value of one

100
00:04:37,270 --> 00:04:40,000
divided by o point three

101
00:04:40,040 --> 00:04:42,240
it's about three

102
00:04:42,240 --> 00:04:44,070
there many use

103
00:04:44,180 --> 00:04:46,760
a second if we give the

104
00:04:46,770 --> 00:04:50,090
a billion more mass of one kilogram

105
00:04:51,210 --> 00:04:52,720
delta p

106
00:04:52,730 --> 00:04:54,970
is and delta v

107
00:04:55,030 --> 00:04:57,020
so if n is one kilogram

108
00:04:58,060 --> 00:05:02,050
the speed of that billiard is undetermined according to

109
00:05:02,100 --> 00:05:04,330
i uncertainty principle

110
00:05:04,330 --> 00:05:08,370
and the first because the centers of the mind

111
00:05:08,480 --> 00:05:11,440
this is point in the k dimensional space

112
00:05:11,440 --> 00:05:16,190
that's the very efficient each dimension is the average value

113
00:05:16,210 --> 00:05:17,660
of all the customers

114
00:05:17,700 --> 00:05:20,600
in the clusters

115
00:05:21,080 --> 00:05:27,960
obviously all customers in the deviation in that cluster have some deviation from the centers

116
00:05:28,060 --> 00:05:31,210
but the otherwise having little division

117
00:05:31,310 --> 00:05:33,890
can be regarded as

118
00:05:33,940 --> 00:05:36,290
as well as more and more

119
00:05:36,310 --> 00:05:39,270
and have high

120
00:05:39,290 --> 00:05:42,770
i have high definition will be regarded as suspicious

121
00:05:42,830 --> 00:05:47,730
that vehicle could customer deviation which is which is the sum of all of it

122
00:05:47,730 --> 00:05:50,190
motivations for customers

123
00:05:50,190 --> 00:05:53,120
but the customers

124
00:05:53,140 --> 00:05:57,080
and then we call the cluster index

125
00:05:57,370 --> 00:05:58,890
which is the

126
00:05:59,290 --> 00:06:02,080
customer deviation divided by the

127
00:06:02,370 --> 00:06:05,680
this customer deviation in the clusters

128
00:06:06,890 --> 00:06:09,810
if the division is to for example

129
00:06:09,850 --> 00:06:13,060
then the if concentrations for that

130
00:06:13,230 --> 00:06:15,940
customer analytics for the right by

131
00:06:16,000 --> 00:06:18,210
a critical to

132
00:06:18,250 --> 00:06:23,830
then the customers started with the monkeys in the killing value of this animal index

133
00:06:24,100 --> 00:06:24,890
and this

134
00:06:25,440 --> 00:06:29,500
the lower part of this list will be one of usual part

135
00:06:29,600 --> 00:06:33,100
and i propose to be taken

136
00:06:33,120 --> 00:06:37,960
aside to the expected one

137
00:06:38,020 --> 00:06:43,960
this is a result from the index for example in the first column you receive

138
00:06:44,100 --> 00:06:45,370
the index

139
00:06:45,560 --> 00:06:48,850
which is five five point nine two is that

140
00:06:48,890 --> 00:06:53,540
and then here's

141
00:06:53,580 --> 00:06:57,540
we see the primary which which made

142
00:06:57,560 --> 00:07:00,640
this customer's unusual is there

143
00:07:01,100 --> 00:07:05,540
internet local knowledge

144
00:07:07,000 --> 00:07:09,020
and it's

145
00:07:09,060 --> 00:07:13,080
its inputs is we see and really contribution measures

146
00:07:13,250 --> 00:07:17,640
which is defined as the minimum deviation divided by the customer deviation

147
00:07:17,690 --> 00:07:19,140
so this means that

148
00:07:19,160 --> 00:07:21,330
if there

149
00:07:21,330 --> 00:07:25,000
total division is regarded as one hundred

150
00:07:25,160 --> 00:07:28,730
sixty two percent of the variation is explained by the

151
00:07:28,790 --> 00:07:30,020
why this very

152
00:07:30,020 --> 00:07:32,420
internet local numbers

153
00:07:32,440 --> 00:07:35,060
then the second very which is responsible

154
00:07:35,310 --> 00:07:38,910
to the end of this custom is the

155
00:07:39,080 --> 00:07:41,750
could come along of icons

156
00:07:41,790 --> 00:07:45,660
in turkish this

157
00:07:45,680 --> 00:07:47,920
for for the second customers

158
00:07:47,980 --> 00:07:51,520
the critical number of transactions division

159
00:07:51,540 --> 00:07:55,960
it's not like experience ninety six percent of them

160
00:07:56,000 --> 00:07:57,290
that means

161
00:07:57,310 --> 00:07:59,270
this is discussed

162
00:08:01,080 --> 00:08:02,750
made enormous

163
00:08:02,770 --> 00:08:06,060
number of the transactions in his car

164
00:08:06,100 --> 00:08:07,980
in the last

165
00:08:09,350 --> 00:08:12,420
this list is a useful tool for

166
00:08:14,190 --> 00:08:17,310
they can go over all the details of the

167
00:08:17,460 --> 00:08:19,660
customer or converts customers

168
00:08:19,660 --> 00:08:22,910
and starting with these very was indicators

169
00:08:23,060 --> 00:08:28,690
they can make this picture

170
00:08:30,060 --> 00:08:32,230
the move to the second phase

171
00:08:32,660 --> 00:08:35,710
which is the inferential data analysis

172
00:08:35,850 --> 00:08:37,540
he here

173
00:08:37,600 --> 00:08:40,890
we would like to use predicted data mining

174
00:08:41,750 --> 00:08:43,980
predict which customers

175
00:08:44,120 --> 00:08:47,210
i are laundering money

176
00:08:47,270 --> 00:08:51,370
in this thing that it would be nice to have it instead

177
00:08:51,420 --> 00:08:53,190
to learn

178
00:08:53,290 --> 00:08:55,890
to the to the model

179
00:08:55,910 --> 00:08:59,940
but unfortunately the monkeys is which i

180
00:08:59,940 --> 00:09:02,140
i have quite a few

181
00:09:02,210 --> 00:09:04,690
they have only seven

182
00:09:04,730 --> 00:09:07,350
confirmed cases which i

183
00:09:07,370 --> 00:09:09,460
one hundred years

184
00:09:11,160 --> 00:09:16,830
this is for real sufficient to form the training set and the local model

185
00:09:17,120 --> 00:09:19,120
then what we have is

186
00:09:19,160 --> 00:09:21,410
it's such as in a

187
00:09:21,460 --> 00:09:25,140
they will ask the help of these pictures

188
00:09:25,190 --> 00:09:29,040
and then will ask them to

189
00:09:29,940 --> 00:09:32,120
to investigate the result of this

190
00:09:32,140 --> 00:09:35,020
and detection face

191
00:09:35,040 --> 00:09:38,500
and we just have to decide which ones they

192
00:09:38,560 --> 00:09:44,390
they want to speak or they seem worth respecting

193
00:09:45,250 --> 00:09:48,500
and using this list

194
00:09:48,500 --> 00:09:50,830
we have an anomaly in the list which is

195
00:09:51,460 --> 00:09:53,370
which is coming from the first phase

196
00:09:53,480 --> 00:09:57,020
ten often working the expected data

197
00:09:57,040 --> 00:09:59,600
they're on the list that

198
00:09:59,640 --> 00:10:04,730
these persons customers should be can be best investigated

199
00:10:04,730 --> 00:10:11,830
then using this list will take this expect list as the first assembled training set

200
00:10:11,850 --> 00:10:16,480
and then we will develop team decision tree or something

201
00:10:16,560 --> 00:10:18,250
predictive model

202
00:10:18,310 --> 00:10:20,980
the one which

203
00:10:23,480 --> 00:10:25,500
should be expected

204
00:10:25,500 --> 00:10:28,030
so if you want to change just click here

205
00:10:28,040 --> 00:10:30,180
and the window opens

206
00:10:30,200 --> 00:10:31,880
like this

207
00:10:31,880 --> 00:10:36,250
you have here all these basic settings you can modify

208
00:10:36,270 --> 00:10:38,680
each of of them

209
00:10:38,710 --> 00:10:41,420
you have online help we can help here

210
00:10:41,430 --> 00:10:44,090
my asking for more information about this

211
00:10:45,790 --> 00:10:51,230
well you see it's it's it's very

212
00:10:51,240 --> 00:10:54,030
easy to use we have just changed here

213
00:10:54,430 --> 00:10:58,870
to use equal frequencies for discretisation

214
00:11:00,050 --> 00:11:01,580
we're going to do this

215
00:11:01,620 --> 00:11:03,650
this afternoon

216
00:11:03,710 --> 00:11:04,840
and apply

217
00:11:04,880 --> 00:11:06,000
the field

218
00:11:06,030 --> 00:11:07,240
when you apply

219
00:11:07,250 --> 00:11:08,370
the filter

220
00:11:08,380 --> 00:11:10,880
to the body of petulance

221
00:11:10,900 --> 00:11:14,080
you see it has been discretized

222
00:11:14,160 --> 00:11:18,470
this is not an histogram is just the collection of categories

223
00:11:18,480 --> 00:11:20,950
the video has been this capacity into

224
00:11:20,960 --> 00:11:22,490
and here you have

225
00:11:22,500 --> 00:11:24,850
they could points

226
00:11:24,860 --> 00:11:30,220
which these filtering voting has has chosen and the counts for each of the modalities

227
00:11:30,220 --> 00:11:33,900
of the categories

228
00:11:33,960 --> 00:11:36,420
you see here that work has changed

229
00:11:36,450 --> 00:11:38,290
the name of this relation

230
00:11:38,350 --> 00:11:41,650
now its name with real name which is i wish

231
00:11:41,710 --> 00:11:44,030
and the name of the field that has been

232
00:11:44,040 --> 00:11:45,610
applied to

233
00:11:45,620 --> 00:11:54,010
you can do this you can do almost everything by clicking immediately after

234
00:11:54,070 --> 00:11:55,770
the on the bottom

235
00:11:55,830 --> 00:11:59,170
we're not going to do it

236
00:12:00,610 --> 00:12:03,590
classify the second

237
00:12:03,600 --> 00:12:05,420
the second big window

238
00:12:05,480 --> 00:12:07,460
well here you can find

239
00:12:07,570 --> 00:12:13,900
everything that you could expect a decision trees decision lists instance based classifiers like these

240
00:12:13,900 --> 00:12:15,180
labels and

241
00:12:15,240 --> 00:12:18,170
so on SVM snow networks

242
00:12:18,220 --> 00:12:22,100
different kinds of regression based on its

243
00:12:22,540 --> 00:12:26,200
and also make the classifier

244
00:12:26,220 --> 00:12:28,750
the these ways of enhancing the classifier

245
00:12:28,790 --> 00:12:30,720
by combining several

246
00:12:30,760 --> 00:12:36,380
instances of the same classifier like bagging boosting stacking

247
00:12:36,380 --> 00:12:39,010
a long list

248
00:12:40,110 --> 00:12:42,470
can be combined with almost everything

249
00:12:42,510 --> 00:12:44,550
if not we can tells you

250
00:12:44,610 --> 00:12:45,590
i can do it

251
00:12:45,600 --> 00:12:46,930
but in principle

252
00:12:46,960 --> 00:12:48,570
it's very flexible

253
00:12:48,580 --> 00:12:50,340
so classified

254
00:12:50,380 --> 00:12:51,570
we just changed

255
00:12:51,580 --> 00:12:54,300
the main window to classify here you have

256
00:12:54,320 --> 00:12:56,090
to choose producer classifiers

257
00:12:56,100 --> 00:12:57,770
we're going to do it quickly

258
00:12:58,610 --> 00:13:00,250
this is

259
00:13:00,250 --> 00:13:04,610
this is a list of some directories because it's ever written in java and you

260
00:13:04,610 --> 00:13:06,700
know the the classes

261
00:13:06,710 --> 00:13:08,410
as of directories two

262
00:13:08,420 --> 00:13:13,530
so you can browse through the different classifiers

263
00:13:13,550 --> 00:13:15,960
like browsing through defensive of directories

264
00:13:15,970 --> 00:13:20,580
so we have here decision trees for example

265
00:13:20,600 --> 00:13:25,710
many of them from the idea three basic two g j forty eight which is

266
00:13:27,650 --> 00:13:30,040
c four five three

267
00:13:30,070 --> 00:13:33,030
and phi trees random forests random trees

268
00:13:33,050 --> 00:13:34,390
let's just this one

269
00:13:34,400 --> 00:13:36,920
c four five

270
00:13:36,980 --> 00:13:42,030
this is again the default parameters this is the confidence factor

271
00:13:42,090 --> 00:13:43,960
it's the level of pruning

272
00:13:43,970 --> 00:13:45,300
you ask

273
00:13:45,390 --> 00:13:51,920
the minimum number of instances leave all the things you can expect right decision trees

274
00:13:52,860 --> 00:13:54,380
if you want to change

275
00:13:54,380 --> 00:13:57,530
again opened the window

276
00:13:57,550 --> 00:14:01,230
change whatever you want if not OK

277
00:14:01,270 --> 00:14:02,000
then it

278
00:14:02,110 --> 00:14:04,000
we have a look here you can see it

279
00:14:04,010 --> 00:14:08,800
then we get to use the whole training set for inducing the decision tree

280
00:14:10,510 --> 00:14:13,750
besides doing this you can specify

281
00:14:13,780 --> 00:14:16,610
a further test set that will be used

282
00:14:16,620 --> 00:14:20,250
and all that after the end of the mall has been created

283
00:14:20,290 --> 00:14:25,020
you can use cross validation with the number of false here

284
00:14:25,030 --> 00:14:29,850
or you can simply use a the holdout technique just use

285
00:14:29,860 --> 00:14:31,450
in this case two thirds

286
00:14:31,460 --> 00:14:33,470
all the training sets for

287
00:14:33,490 --> 00:14:35,360
inducing the them and

288
00:14:35,380 --> 00:14:41,720
then the model and then using the remaining one-third for test whether

289
00:14:43,110 --> 00:14:46,970
in this case we're going to do this last thing

290
00:14:47,010 --> 00:14:49,160
more options

291
00:14:49,180 --> 00:14:52,890
this is just to tell we can what kind of output

292
00:14:52,900 --> 00:14:55,640
you need the model itself

293
00:14:55,660 --> 00:14:57,920
plus statistics

294
00:14:57,930 --> 00:14:59,990
the full confusion matrix

295
00:15:00,620 --> 00:15:03,700
and you can ask we get to store

296
00:15:03,720 --> 00:15:07,250
the whole set of predictions for later visualization

297
00:15:07,250 --> 00:15:09,110
this is nice we

298
00:15:09,120 --> 00:15:11,370
we're going to do it later

299
00:15:11,390 --> 00:15:13,130
anyway start

300
00:15:13,180 --> 00:15:15,450
and this is the result

301
00:15:15,460 --> 00:15:16,550
you can see here

302
00:15:16,580 --> 00:15:17,740
the inputs

303
00:15:17,760 --> 00:15:19,730
four the tree all your settings

304
00:15:19,730 --> 00:15:21,370
and this is the thing

305
00:15:21,380 --> 00:15:23,660
it's because you have to fight

306
00:15:23,680 --> 00:15:24,850
a training level

307
00:15:24,860 --> 00:15:29,390
this is better with less or equal than c o point six then sit also

308
00:15:30,420 --> 00:15:33,410
fifty instances fulfill this condition

309
00:15:33,430 --> 00:15:35,620
you all know what the decision trees

310
00:15:37,150 --> 00:15:41,920
scroll down to see the whole information this is the confusion matrix that we ask

311
00:15:42,850 --> 00:15:44,160
this is the the

312
00:15:44,200 --> 00:15:47,080
performance on test set

313
00:15:48,310 --> 00:15:49,730
which is what we ask it

314
00:15:52,900 --> 00:15:56,690
this is a list of all the models we have induced with the name with

315
00:15:56,690 --> 00:16:00,590
anglican it open it and the sum of things

316
00:16:00,590 --> 00:16:02,330
for example

317
00:16:02,350 --> 00:16:07,600
for the for the specific case of decision trees we can ask tweak to visualize

318
00:16:07,620 --> 00:16:09,860
more nice way

319
00:16:09,860 --> 00:16:11,740
nice way

320
00:16:11,880 --> 00:16:12,870
the same tree

321
00:16:12,880 --> 00:16:14,400
this is our tree

322
00:16:14,630 --> 00:16:16,030
we just

323
00:16:16,030 --> 00:16:23,020
induced of course we can say this figure that i j therefore some other format

324
00:16:25,790 --> 00:16:28,070
we can visualize the classifier errors

325
00:16:28,090 --> 00:16:30,140
which is nice

326
00:16:30,200 --> 00:16:32,540
there was some errors if you remember

327
00:16:37,270 --> 00:16:39,640
these are two errors

328
00:16:40,240 --> 00:16:42,060
two of out-of-town out

329
00:16:42,100 --> 00:16:44,550
of the confusion matrix so if you

330
00:16:44,560 --> 00:16:45,830
i want to see

331
00:16:45,880 --> 00:16:49,350
what instances of these two errors are these two

332
00:16:49,360 --> 00:16:51,670
this is here better alone

333
00:16:51,700 --> 00:16:53,580
on the horizontal axis

334
00:16:53,590 --> 00:16:55,550
against the with

335
00:16:55,550 --> 00:17:01,860
is associated exactly with a radius usually say yes five versus five space in strings

336
00:17:03,650 --> 00:17:08,670
the number of colors and is the same radius but in plant units

337
00:17:08,690 --> 00:17:13,320
so one of the input actions you see as quantum gravity corrections

338
00:17:13,360 --> 00:17:16,440
one of the allowed the corrections string

339
00:17:16,460 --> 00:17:19,300
like what actions

340
00:17:19,320 --> 00:17:24,730
the gauge invariant operators of this conformal field theory which can be written as the

341
00:17:24,740 --> 00:17:33,320
single trace of sum product operators become single string states in just five versus five

342
00:17:33,340 --> 00:17:39,650
this scaling dimensions of this separate we are in the conformal energy scale invariant regime

343
00:17:39,670 --> 00:17:45,420
so the relevant quantities of this scaling normalise dimensions of very very first

344
00:17:45,460 --> 00:17:49,360
become the energies of the string states

345
00:17:49,400 --> 00:17:56,170
renormalisation group flow of the theory if you turn on some relevant must perturbations for

346
00:17:57,400 --> 00:18:04,710
become basically extrapolating solutions between ages five versus five and some other geometry

347
00:18:04,710 --> 00:18:11,530
heavy external probes like quarks become strings stretching to the boundary of radius five and

348
00:18:11,550 --> 00:18:16,150
there are various other elements in this dictionary i want to go through the whole

349
00:18:17,880 --> 00:18:23,150
so there is no sharp precise dictionary and you notice in particular that when we

350
00:18:23,150 --> 00:18:28,940
have two sides here we can contemplate if you think about the string theory side

351
00:18:28,990 --> 00:18:34,490
well the hardest thing to try to compute that quantum gravity effects those are

352
00:18:34,610 --> 00:18:38,990
card because they require loop calculations in string theory

353
00:18:39,070 --> 00:18:43,710
but we can in the sense that north completely those by taking n to be

354
00:18:43,710 --> 00:18:47,420
infinitely large this is called the plane model image

355
00:18:47,420 --> 00:18:51,570
in real to see DNC's three we're not very close to the people in the

356
00:18:51,590 --> 00:18:55,650
limit but still it's well let's take an infinitely large

357
00:18:55,690 --> 00:19:00,820
then the correspondence tells us that the full and equal force prevent means is the

358
00:19:00,840 --> 00:19:04,840
classical theory although it's a classical string theorist

359
00:19:04,880 --> 00:19:12,990
we have to compute string quartets which

360
00:19:12,990 --> 00:19:16,420
now a word about and this if there actually and wanted this if there is

361
00:19:16,420 --> 00:19:18,730
a funny space and you have to

362
00:19:18,740 --> 00:19:22,280
contemplated for a while to get the lead to creation

363
00:19:22,300 --> 00:19:26,130
but here are a couple of relevant comments about it

364
00:19:26,130 --> 00:19:27,260
first of all

365
00:19:27,280 --> 00:19:32,490
it's a space which have an infinite blue shift at the boundary remember all have

366
00:19:33,440 --> 00:19:35,800
at of the throat of the black hole

367
00:19:35,820 --> 00:19:39,650
in nineteen theory or there was this infinite it's safe as you go out there

368
00:19:39,670 --> 00:19:44,630
is a blue shift and these blue shift becomes infinite at that because we kill

369
00:19:44,630 --> 00:19:49,380
yes in the arctic region we have the one if you remember the harmonic function

370
00:19:49,400 --> 00:19:53,380
so now we have an infinite blue shift so things that move out to the

371
00:19:54,900 --> 00:19:59,110
get more and more blue shifted and they have a tendency to fall back in

372
00:19:59,110 --> 00:20:02,470
because otherwise they don't have enough energy to make out

373
00:20:02,530 --> 00:20:07,780
so i this is the space looks like it actually it perhaps particles in the

374
00:20:07,780 --> 00:20:13,800
theory that's consistent with the fact that the energy spectrum is discrete

375
00:20:15,900 --> 00:20:21,880
officials here the correspondence tells you that the energy so various strings there are scaling

376
00:20:21,880 --> 00:20:32,420
dimensions and the spectrum of scaling dimensions should be discrete contin

377
00:20:32,460 --> 00:20:38,940
so that that's why we get the discrete spectrum anomalous dimensions this is the space

378
00:20:38,940 --> 00:20:43,830
is also unusually stable one funny geometric property of it is that if you draw

379
00:20:43,830 --> 00:20:45,300
a barber

380
00:20:45,360 --> 00:20:49,050
born here and you try to expand it out

381
00:20:49,080 --> 00:20:52,230
usually the area of the ball

382
00:20:52,250 --> 00:20:58,200
grows less quickly than the volume of girls like some small power of the volume

383
00:20:58,250 --> 00:21:01,670
was here the area grows like the volume and therefore

384
00:21:01,700 --> 00:21:05,500
this if there is more stable than usual space time

385
00:21:05,550 --> 00:21:08,580
because when you try safer nuclear the barber of

386
00:21:08,760 --> 00:21:14,880
right viking mushrooming during the vacuum this problem may not managed to make it out

387
00:21:14,880 --> 00:21:21,450
since the gain in energy in the video doesn't beat necessarily the surface energy you

388
00:21:21,550 --> 00:21:24,080
have to create the

389
00:21:24,120 --> 00:21:27,700
so it's stable space effects like crap

390
00:21:27,870 --> 00:21:31,540
and finally moving towards the interior of the

391
00:21:31,570 --> 00:21:34,650
looks like changing the energy scale

392
00:21:34,660 --> 00:21:39,370
so in this holographic duality you should think of the theory of the gauge theory

393
00:21:39,370 --> 00:21:41,190
leaving out here

394
00:21:41,240 --> 00:21:46,250
there is indeed the fifth dimension but that's really nothing else than the energy scale

395
00:21:46,250 --> 00:21:50,860
at which you are looking at the system there are no new degrees of freedom

396
00:21:50,870 --> 00:21:55,660
as you move in about and that's how it's called holographic somehow the whole theory

397
00:21:55,730 --> 00:22:03,410
is defined as the bunbury and by moving in you're just changing your energies here

398
00:22:03,420 --> 00:22:09,970
so of course very fascinating for theorists correspondences in the sense gives a very different

399
00:22:09,970 --> 00:22:14,970
way of thinking about energy scales and renormalisation and so on

400
00:22:14,990 --> 00:22:17,330
but you may ask of course

401
00:22:17,460 --> 00:22:20,410
you should always ask what is it really good for

402
00:22:20,540 --> 00:22:28,010
the can we do something with his

403
00:22:28,070 --> 00:22:30,090
so here are the three

404
00:22:30,120 --> 00:22:36,290
things which i think one could say want this question first of all what can

405
00:22:36,290 --> 00:22:41,750
use it to solve the strong coupling large n limit of certain gauge theories

406
00:22:42,500 --> 00:22:44,730
combined with

407
00:22:44,780 --> 00:22:52,210
methods of integrability some very powerful methods of two dimensional integrability one is actually close

408
00:22:52,790 --> 00:22:59,250
almost solving completely for some quantities the larger limit for any type of coupling

409
00:22:59,290 --> 00:23:05,660
four dimensions of seven operators also you transparency for these so far field theorists these

410
00:23:05,670 --> 00:23:09,740
would be an important achievement no we don't know if any

411
00:23:09,750 --> 00:23:15,880
four dimensional gauge theory or field theory at large where can calculate something exactly at

412
00:23:15,880 --> 00:23:20,690
all couplings and it would be of course very interesting for field theories is to

413
00:23:20,690 --> 00:23:23,080
be able to do things

414
00:23:23,110 --> 00:23:30,340
but QCD has any questions three that's far from infinity it also has quarks

415
00:23:30,800 --> 00:23:36,630
force young has no quarks and most importantly as i said it has both strong

416
00:23:36,630 --> 00:23:39,070
and weak coupling energy regime

417
00:23:39,080 --> 00:23:46,370
so it's strongly coupled in the infrared in the interior of the state space a

418
00:23:46,370 --> 00:23:52,040
user strong coupling but it is is weakly coupled asymptotically free in the UV region

419
00:23:52,040 --> 00:23:55,700
which correspond to going on

420
00:23:55,700 --> 00:24:00,950
so what we have is definitely not very similar to UCB and there is i

421
00:24:00,950 --> 00:24:03,610
think still a very long way to go

422
00:24:05,240 --> 00:24:12,290
there are some situations one situation the which is the quark gluon plasma were

423
00:24:12,300 --> 00:24:17,740
even in very rough qualitative model could be of help because there's nothing else you

424
00:24:17,740 --> 00:24:18,740
can use

425
00:24:18,780 --> 00:24:20,400
there is no interference

426
00:24:20,410 --> 00:24:26,190
and the reason is that the lattice gauge theory is basically of very little use

427
00:24:26,200 --> 00:24:31,650
if you want to do out of equilibrium real time calculations one doesn't really know

428
00:24:31,650 --> 00:24:35,700
how to do them by using lattice gauge theory which is in a very

429
00:24:35,700 --> 00:24:39,810
since i came in the field but a lot of the advances that came in

430
00:24:39,810 --> 00:24:42,610
the first ten years of that and i think a lot of what we're doing

431
00:24:42,610 --> 00:24:46,480
is dotting i's and crossing t's at the moment so i worry that we're becoming

432
00:24:46,480 --> 00:24:50,340
a bit too obsessed magical formalisms and this is the reason why that can be

433
00:24:50,340 --> 00:24:56,640
a problem so this is really stupid idea that aerodynamically a bumble bee can't fly

434
00:24:56,640 --> 00:25:00,800
and then the answer is well the bumblebee doesn't know that only he flies through

435
00:25:00,810 --> 00:25:04,540
the force of heart or something like that

436
00:25:04,560 --> 00:25:09,590
obviously that isn't it i mean dynamically bumblebee can fly you can see obama we

437
00:25:09,610 --> 00:25:13,410
flying you can see examples of all the time so what does this mean it

438
00:25:13,410 --> 00:25:20,670
means the mathematical formalism you're using to model what happens aerodynamically does not apply in

439
00:25:20,670 --> 00:25:21,770
these case

440
00:25:21,800 --> 00:25:25,510
it applies to jet aircraft it applies to jumbo jets

441
00:25:25,570 --> 00:25:29,160
it applies to fighter jets but it doesn't apply

442
00:25:29,180 --> 00:25:33,650
two other the bumblebees doing so it's clearly a limitation of the model

443
00:25:33,670 --> 00:25:37,850
rather than the fact now the problem is you can get these two things confused

444
00:25:37,850 --> 00:25:42,120
because the first thing you do is you say well this is the situation in

445
00:25:42,120 --> 00:25:47,360
real life i can't model everything in that sort of mathematical idealisation of study that

446
00:25:47,710 --> 00:25:51,500
but then you can spend so long study that the when you actually look back

447
00:25:51,500 --> 00:25:54,570
at the situation in real life usage itself

448
00:25:56,610 --> 00:26:01,650
the impossible things that things that happen are impossible and we hear examples of that

449
00:26:01,650 --> 00:26:07,130
things like well it's impossible for human vision problem is impossible because of the curse

450
00:26:07,130 --> 00:26:13,550
of dimensionality well problem is impossible because you're doing all the time it's difficult but

451
00:26:13,570 --> 00:26:15,720
we which just doing it wrong when we do

452
00:26:15,740 --> 00:26:20,310
on computers and we see advances in that direction as well so i think it's

453
00:26:20,310 --> 00:26:23,720
very dangerous to get lost in pure mathematical

454
00:26:23,730 --> 00:26:27,500
formalisms because you forget that there are things going on that humans can do for

455
00:26:27,500 --> 00:26:31,160
example that we want to recreate and that's why this link you know i think

456
00:26:31,170 --> 00:26:32,850
that is really

457
00:26:32,860 --> 00:26:36,140
interesting example that it's not good reason so

458
00:26:36,170 --> 00:26:39,860
statisticians will tell you that you can't fool

459
00:26:39,860 --> 00:26:45,270
here's things that also statisticians will say this that you can't infer causality from data

460
00:26:45,300 --> 00:26:52,410
and i think for any statistics it was quite important that this concept existed but

461
00:26:52,410 --> 00:26:53,350
you know

462
00:26:53,360 --> 00:26:57,370
why humans have the a concept of causality then if you can infer from data

463
00:26:57,480 --> 00:27:01,880
mining data is just what we see and doing causality is a really important aspect

464
00:27:01,880 --> 00:27:05,120
of that so you can get a little bit lost if you start proving these

465
00:27:05,120 --> 00:27:08,240
things in demonstrating these things

466
00:27:08,260 --> 00:27:11,160
and lose sight of what's actually really going on and what you really want to

467
00:27:12,990 --> 00:27:19,190
so mathematical foundations are very important though they help us understand the capabilities of our

468
00:27:19,190 --> 00:27:21,390
algorithms and i think the

469
00:27:21,390 --> 00:27:24,720
you know this is why this summer schools important because you have to actually keep

470
00:27:24,720 --> 00:27:27,170
in touch with both of these things

471
00:27:27,200 --> 00:27:31,950
it's really hard now i think to come in machine learning as an undergraduate well

472
00:27:31,950 --> 00:27:36,760
as graduating undergraduate as a graduate student compared to how it was when i came

473
00:27:36,760 --> 00:27:39,340
in so when i came in

474
00:27:39,350 --> 00:27:43,720
the mass you need to know was very complex thing known as the chain rule

475
00:27:43,750 --> 00:27:48,410
and you need to know that to derive an advance algorithm known as back propagation

476
00:27:50,700 --> 00:27:55,000
i still use the chain rule it's still quite useful there

477
00:27:55,010 --> 00:27:59,080
i do an enormous number of other things and you know when i think about

478
00:27:59,080 --> 00:28:01,290
what i'm trying to get my students to do

479
00:28:01,300 --> 00:28:04,690
and what i expect them to know quite quickly and it is far more than

480
00:28:04,690 --> 00:28:09,590
i knew when i came into machine learning in terms of say linear algebra

481
00:28:09,610 --> 00:28:11,350
probability theory

482
00:28:11,550 --> 00:28:18,320
in other areas should be talking about functional analysis is very complicated that makes it

483
00:28:18,320 --> 00:28:23,260
tough because i don't think it's the case that the undergraduate programs pushing people further

484
00:28:23,260 --> 00:28:26,750
than they used to so there is a steep learning curve to come into machine

485
00:28:26,750 --> 00:28:31,310
learning but it's important that people know that

486
00:28:33,360 --> 00:28:37,930
well that's all resentments not point humans give us inspiration to go beyond these mathematical

487
00:28:37,930 --> 00:28:41,700
formalisms so it's important that we don't get lost in the more advanced mathematics that

488
00:28:41,700 --> 00:28:45,720
would you doing i mean sometimes i think some in the computer science department but

489
00:28:45,910 --> 00:28:49,920
sometimes i feel it would be more appropriate to been applied maths problem because you

490
00:28:49,920 --> 00:28:53,760
know i don't see much difference between of applied mathematicians are doing what we do

491
00:28:54,180 --> 00:28:58,790
the main difference is that we consider a broader range of problems and it takes

492
00:28:58,790 --> 00:29:02,680
me a lot longer to work out the mast and some applied mathematicians

493
00:29:02,730 --> 00:29:05,170
OK so

494
00:29:05,190 --> 00:29:12,200
back to this question statistics so any statistics had really what statistics about an early

495
00:29:12,200 --> 00:29:15,970
statistics nothing you have to understand its origins he was different from machine learning and

496
00:29:16,360 --> 00:29:20,600
they had great success with this idea of a statistical proof and i think this

497
00:29:20,600 --> 00:29:24,790
is a really important concept you mustn't forget this concept but one must also ignore

498
00:29:24,790 --> 00:29:28,410
it as well in some sense in terms of looking to the future because there

499
00:29:28,410 --> 00:29:30,560
and it's done so

500
00:29:30,610 --> 00:29:33,990
there's a question i compute the mean of two tables of numbers which is the

501
00:29:34,010 --> 00:29:35,680
statistic right so

502
00:29:35,720 --> 00:29:40,720
that's what baseball statistics like and that's what it's really about studying statistics there are

503
00:29:40,720 --> 00:29:44,490
different does this prove anything does this mean anything and this is what people are

504
00:29:44,500 --> 00:29:50,200
interested in their social scientists early social scientists they were measuring poverty in manchester comparing

505
00:29:50,240 --> 00:29:53,890
to poverty in london and saying is the poverty different they didn't want to use

506
00:29:53,890 --> 00:29:57,390
models they just wanted to sum up numbers compute on

507
00:29:57,390 --> 00:30:02,150
so the answer would depend on what statistics discoveries it depends on how those numbers

508
00:30:02,150 --> 00:30:07,190
are generated with a randomized and what big difference how big the differences between these

509
00:30:07,190 --> 00:30:09,400
these two numbers

510
00:30:09,420 --> 00:30:14,720
that led to hypothesis testing but this is really restrictive because the questions you could

511
00:30:14,720 --> 00:30:19,130
then ask about your data that you can answer the statistical proof are really really

512
00:30:19,130 --> 00:30:24,960
limiting what's really interesting is people actually think that that's not onto what people think

513
00:30:24,960 --> 00:30:28,520
the philosophy of science is so if you work in biology people will tell you

514
00:30:28,760 --> 00:30:29,910
are your

515
00:30:29,950 --> 00:30:34,140
what's your hypothesis but then it's a hypothesis they mean what's your simple question that

516
00:30:34,140 --> 00:30:38,880
you can answer the statistic pop he's not talking about that he talked about hypothesis

517
00:30:38,880 --> 00:30:43,820
is much more complex things that often you could not answer the simple statistics so

518
00:30:43,820 --> 00:30:48,230
that can never really limiting effect on science as well but there were many successes

519
00:30:48,250 --> 00:30:53,040
in this and there are things that we we take

520
00:30:53,050 --> 00:30:57,110
for granted today the fact that we fertilize crops correctly the fact that you can

521
00:30:57,110 --> 00:30:59,140
get consistently brewed beer

522
00:30:59,150 --> 00:31:04,020
right you know they couldn't do that before statistical tests were invented invented statistical test

523
00:31:04,020 --> 00:31:08,650
to do that but there are many open questions we've already mentioned one causality so

524
00:31:08,650 --> 00:31:11,510
that is to say in a given at

525
00:31:11,950 --> 00:31:18,550
OK so each electron has a distinct set of quantum numbers 1st important idea so

526
00:31:18,550 --> 00:31:22,970
you can think of each electron is having its own social security number or IP

527
00:31:22,970 --> 00:31:29,070
address or something so that's important so we once we've chosen a certain mix of

528
00:31:29,070 --> 00:31:34,530
an element as it's used ones for that particular and that's the 1st point the

529
00:31:34,530 --> 00:31:38,210
2nd point of the Aufbau principle is just energetics

530
00:31:39,050 --> 00:31:43,830
electrons will occupy orbitals in order of descending energy

531
00:31:43,840 --> 00:31:51,150
occupy the lowest-energy 1st end up but clearly this an LMS sequence is different from

532
00:31:51,150 --> 00:31:56,960
the energy sequence once we get beyond that to 3 so there's something else going

533
00:31:56,960 --> 00:32:06,600
on so let's talk about the electrons electrons fill orbitals electron electron still orbitals from

534
00:32:07,320 --> 00:32:09,100
the lowest

535
00:32:09,340 --> 00:32:12,890
of energy to

536
00:32:13,220 --> 00:32:15,650
2 highest energy

537
00:32:17,270 --> 00:32:22,610
but there's a there's some there's a wrinkle here and that is that the energy

538
00:32:22,610 --> 00:32:25,070
levels themselves

539
00:32:25,080 --> 00:32:30,580
change with electron occupancy and as you go higher and higher levels those energy levels

540
00:32:30,580 --> 00:32:35,720
as you saw in the case of hydrogen the energy levels work more closely spaced

541
00:32:35,720 --> 00:32:41,580
the differences between those energy levels are becoming smaller and smaller as the end number

542
00:32:41,580 --> 00:32:44,770
rises and what the

543
00:32:44,830 --> 00:32:50,960
2nd point of of is that as the electrons begin to fill those levels the

544
00:32:51,240 --> 00:32:57,700
differences in energy may shift so that an unoccupied states certain levels may be in

545
00:32:57,700 --> 00:33:02,600
the inverse order from how they are in the occupied state so we have to

546
00:33:02,600 --> 00:33:10,270
recognize this lowest energy the highest energy and the function of occupancy seamlessly few examples

547
00:33:10,270 --> 00:33:16,360
of kind so that's the 2nd part of the island of the principle and the

548
00:33:16,360 --> 00:33:19,680
3rd 1 talks about the question of

549
00:33:19,740 --> 00:33:25,180
the generously and it's called the 100 points it talks about

550
00:33:26,530 --> 00:33:32,990
the generous on the final generosity generously areas where you have or orbitals of equivalent

551
00:33:33,000 --> 00:33:35,550
energy how do we put electrons into

552
00:33:36,940 --> 00:33:50,680
such as system orbitals of the equivalent energy we strive to strive for unpaired electrons

553
00:33:50,860 --> 00:33:58,910
strive for unpaired electrons what do I mean by that let's give a simple example

554
00:33:58,910 --> 00:34:03,820
of a simple example is the 1st look at the carbon if we look at

555
00:34:03,820 --> 00:34:10,360
carbon carbon and if you look at the periodic table you'll see this notation x

556
00:34:10,360 --> 00:34:12,710
2 carbon 1 s 2

557
00:34:12,930 --> 00:34:21,150
to ask you 2 p 2 OK so what we learned here this 1st number

558
00:34:21,150 --> 00:34:23,630
here it gives the value of

559
00:34:23,980 --> 00:34:29,200
and so this tells me that this is n equals 1 and S S is

560
00:34:29,200 --> 00:34:36,100
this lowercase notation that the spectroscopy used in place of

561
00:34:36,360 --> 00:34:41,620
the L number so this is an acid so s according to spectroscopy means that

562
00:34:41,620 --> 00:34:46,600
l equals 0 n equals 1 l equals 0 and the superscript 2 is an

563
00:34:46,600 --> 00:34:53,650
indication of the electron occupancy so in plain English this says that there are 2

564
00:34:53,650 --> 00:34:59,050
electrons in the 1 s orbital and then we can continue this is 2 electrons

565
00:34:59,050 --> 00:35:04,170
in the 2 s orbital and there are 2 electrons in the 2 p orbitals

566
00:35:04,200 --> 00:35:09,770
another way of displaying this is a box notation so here's 1

567
00:35:09,860 --> 00:35:14,080
if you like k shall here to ask

568
00:35:14,710 --> 00:35:20,410
L shell and then there's stupidity and we know from over here in the 2

569
00:35:20,410 --> 00:35:27,890
p has the possibility of 3 different about and numbers so as I showed you

570
00:35:27,890 --> 00:35:32,270
last day that this is 1 case where trying on a Cartesian space makes sense

571
00:35:32,470 --> 00:35:38,550
and equals 1 0 minus 1 indicates the 3 principal coordinate directions and the people

572
00:35:38,550 --> 00:35:43,220
refer to these as the 2 p x orbital the 2 p y orbital and

573
00:35:43,220 --> 00:35:47,790
the 2 p z orbital so now let's fill

574
00:35:47,810 --> 00:35:53,320
the orbitals let's occupy the orbitals and we're going to use the palace seclusion principle

575
00:35:53,320 --> 00:35:56,600
and we're going to use the fact that we feel from lower energy to higher

576
00:35:56,600 --> 00:36:01,930
energy so we go 1 go spin up and the other goes spin-down why spin

577
00:36:01,930 --> 00:36:08,050
up and spin down because the 4th quantum number is S and Power says no

578
00:36:08,050 --> 00:36:09,290
we will do that

579
00:36:09,310 --> 00:36:10,550
in a few weeks

580
00:36:10,560 --> 00:36:14,290
ourselves in a two

581
00:36:14,290 --> 00:36:17,080
in nineteen seventy nine which was the year that

582
00:36:17,130 --> 00:36:19,580
maxwell died

583
00:36:19,630 --> 00:36:22,290
the german physicist helmholtz

584
00:36:23,130 --> 00:36:24,950
one of his students hertz

585
00:36:24,950 --> 00:36:28,410
it was twenty two years at the time he was a junior

586
00:36:28,500 --> 00:36:33,350
try to demonstrate that radio waves indeed exists

587
00:36:33,390 --> 00:36:36,800
birds declined because he argued that the

588
00:36:36,810 --> 00:36:39,950
equipment that was available at the time of

589
00:36:39,980 --> 00:36:42,540
not good enough

590
00:36:42,590 --> 00:36:44,870
seven years later when new

591
00:36:44,880 --> 00:36:46,050
equipment had been

592
00:36:46,060 --> 00:36:48,500
developed accepted the challenge

593
00:36:48,570 --> 00:36:50,980
it took in two years

594
00:36:51,790 --> 00:36:54,400
i was able to demonstrate that radio waves

595
00:36:56,690 --> 00:36:59,280
imagine what victory that was

596
00:36:59,290 --> 00:37:02,010
someone like maxwell who predicts

597
00:37:02,050 --> 00:37:05,550
out of nothing that radio waves should exist

598
00:37:05,550 --> 00:37:11,180
you come someone who actually shows that they do exist

599
00:37:12,880 --> 00:37:15,270
died five years after

600
00:37:20,120 --> 00:37:23,110
he was thirty seven years old he was very young

601
00:37:23,150 --> 00:37:26,460
and he live ten more years there's no doubt in my mind

602
00:37:26,560 --> 00:37:30,090
he would have been awarded with the nobel prize for physics with the first nobel

603
00:37:31,050 --> 00:37:33,210
only given in nineteen o one

604
00:37:33,280 --> 00:37:36,700
he died just a little bit too early

605
00:37:36,780 --> 00:37:38,660
next also died very young

606
00:37:38,750 --> 00:37:42,530
h forty eight

607
00:37:42,550 --> 00:37:46,050
why did maxwell call that trains

608
00:37:46,060 --> 00:37:49,100
displacement current

609
00:37:49,150 --> 00:37:53,770
in the presence of the dielectric before the dielectric in there

610
00:37:53,790 --> 00:37:56,020
changing electric fields

611
00:37:56,040 --> 00:37:59,310
real in the course of the current

612
00:37:59,370 --> 00:38:00,950
in between the plates

613
00:38:00,950 --> 00:38:06,070
because the polarisation will change all the time you get to rearrange rearrangements

614
00:38:06,150 --> 00:38:09,140
of these induce charges or indeed

615
00:38:09,160 --> 00:38:10,650
a current

616
00:38:10,690 --> 00:38:12,960
but in vacuum

617
00:38:12,970 --> 00:38:15,120
there shouldn't be any career

618
00:38:15,140 --> 00:38:16,560
any electric field

619
00:38:16,570 --> 00:38:19,240
changing or not changing and of course the current

620
00:38:19,240 --> 00:38:20,720
in vacuum

621
00:38:21,950 --> 00:38:23,770
i believe the vacuum

622
00:38:23,780 --> 00:38:28,600
you know when behaves like any other dielectric just special dielectric happens to be a

623
00:38:28,600 --> 00:38:30,900
dialectic with kappa equals one

624
00:38:30,960 --> 00:38:32,630
and so he really believe

625
00:38:32,650 --> 00:38:34,880
that there was an actual current going

626
00:38:36,040 --> 00:38:38,770
the plates even though we now know of course that is

627
00:38:38,780 --> 00:38:40,390
not the case

628
00:38:40,410 --> 00:38:42,630
so the name displacement current

629
00:38:42,640 --> 00:38:44,580
well perhaps not very

630
00:38:44,640 --> 00:38:46,480
lucky ones

631
00:38:46,480 --> 00:38:48,450
but the term

632
00:38:48,460 --> 00:38:50,480
is a must

633
00:38:50,530 --> 00:38:52,270
and it completes

634
00:38:52,280 --> 00:38:56,930
the theory of electricity and magnetism

635
00:38:56,990 --> 00:38:59,830
the name is obviously of no consequence after all

636
00:38:59,860 --> 00:39:03,230
shakespeare set itself in rome we'll gillette

637
00:39:03,290 --> 00:39:05,820
what's in a name

638
00:39:06,910 --> 00:39:08,060
what's in a name

639
00:39:08,070 --> 00:39:12,260
that which we call a rose by any other name would smell as sweet

640
00:39:12,300 --> 00:39:13,780
those were the words

641
00:39:13,820 --> 00:39:16,790
by shakespeare

642
00:39:16,790 --> 00:39:18,710
i will abandon for now

643
00:39:18,720 --> 00:39:22,130
the displacement current but we will revisit later

644
00:39:22,150 --> 00:39:24,270
when we will be always radio waves

645
00:39:24,270 --> 00:39:25,830
and with the propagation

646
00:39:25,850 --> 00:39:27,990
of electromagnetic radiation

647
00:39:28,140 --> 00:39:29,810
i return out

648
00:39:29,870 --> 00:39:32,740
the good old power

649
00:39:32,790 --> 00:39:34,570
and i will return

650
00:39:36,940 --> 00:39:40,340
generators that ran our economy

651
00:39:40,390 --> 00:39:43,290
we've discussed this at length

652
00:39:43,330 --> 00:39:45,330
and i want to revisit that you

653
00:39:45,380 --> 00:39:48,040
with you

654
00:39:48,040 --> 00:39:49,770
remember that if you

655
00:39:49,820 --> 00:39:51,140
i rotate

656
00:39:51,150 --> 00:39:52,690
conducting look

657
00:39:52,790 --> 00:39:54,820
the magnetic field

658
00:39:55,700 --> 00:39:56,840
you create

659
00:39:56,870 --> 00:39:58,890
induced EMF

660
00:40:00,570 --> 00:40:04,550
and that keeps our economy going

661
00:40:04,560 --> 00:40:06,050
is again

662
00:40:06,090 --> 00:40:08,840
one of those loops

663
00:40:08,910 --> 00:40:12,460
conducting wire

664
00:40:13,490 --> 00:40:16,340
i don't care about the action of the magnetic field that you want to this

665
00:40:16,340 --> 00:40:17,750
way that's fine

666
00:40:17,800 --> 00:40:18,830
what matters is

667
00:40:18,840 --> 00:40:22,510
and we're going to rotate about its axis

668
00:40:22,550 --> 00:40:24,840
every rotate about its axis

669
00:40:24,850 --> 00:40:28,060
we're going to get an induced EMF

670
00:40:28,080 --> 00:40:30,480
and then use the method

671
00:40:30,480 --> 00:40:31,720
which we derive

672
00:40:31,770 --> 00:40:34,290
i think it will last lecture

673
00:40:34,380 --> 00:40:36,800
as a function of time

674
00:40:36,840 --> 00:40:41,210
will be assigned sort of or cosine could sort of curve

675
00:40:41,280 --> 00:40:42,780
and therefore

676
00:40:42,790 --> 00:40:48,970
will look something like this

677
00:40:48,970 --> 00:40:52,630
i call this world number one

678
00:40:52,690 --> 00:40:54,380
so this is the math

679
00:40:54,440 --> 00:40:58,220
produced by the number one

680
00:40:59,710 --> 00:41:01,650
i'm going to add

681
00:41:01,760 --> 00:41:02,860
two more no

682
00:41:02,970 --> 00:41:04,200
which are not

683
00:41:04,280 --> 00:41:06,790
electrically connected

684
00:41:06,810 --> 00:41:09,680
physically separate

685
00:41:09,730 --> 00:41:11,470
if you look from this direction

686
00:41:11,600 --> 00:41:14,490
you will see the following

687
00:41:14,550 --> 00:41:17,050
this would be the number one

688
00:41:17,060 --> 00:41:20,110
because you're looking in this direction you would only see

689
00:41:20,160 --> 00:41:22,980
conducting wire like so

690
00:41:22,980 --> 00:41:27,550
i have now second one which is rotated hundred and twenty degrees

691
00:41:27,580 --> 00:41:29,520
so in this picture

692
00:41:29,520 --> 00:41:32,700
you will see it like so

693
00:41:32,780 --> 00:41:35,010
the number two

694
00:41:35,020 --> 00:41:35,810
and this

695
00:41:35,840 --> 00:41:38,240
on the the twenty degrees

696
00:41:38,280 --> 00:41:41,260
physically on the twenty degree rotation

697
00:41:41,310 --> 00:41:45,830
and then i was one which is again one of the twenty degrees rotated

698
00:41:46,010 --> 00:41:47,190
like so

699
00:41:47,200 --> 00:41:48,990
so this angle

700
00:41:49,870 --> 00:41:52,030
there's also a hundred and twenty degrees

701
00:41:52,040 --> 00:41:53,310
so this angle

702
00:41:53,310 --> 00:41:55,520
i agree

703
00:41:55,540 --> 00:41:57,890
which is the main classes

704
00:41:57,900 --> 00:41:59,790
of MCMC

705
00:41:59,830 --> 00:42:05,550
agra is

706
00:42:06,910 --> 00:42:08,170
they is i

707
00:42:08,200 --> 00:42:09,720
tried to

708
00:42:09,740 --> 00:42:12,920
in two years yesterday night

709
00:42:12,960 --> 00:42:15,690
is that by using a markov chain

710
00:42:16,490 --> 00:42:18,420
you can do

711
00:42:18,470 --> 00:42:20,650
just as well as

712
00:42:20,670 --> 00:42:24,090
importance sampling or accept reject

713
00:42:24,100 --> 00:42:27,030
if you can produce a markov chain

714
00:42:27,040 --> 00:42:29,790
is that

715
00:42:31,610 --> 00:42:33,790
to the distribution of inter terest

716
00:42:33,810 --> 00:42:36,820
so here it is target distribution f

717
00:42:36,840 --> 00:42:41,290
and you want to book in into for instance all you need to do

718
00:42:41,320 --> 00:42:45,080
is constructing markov chains that is ergodic

719
00:42:45,100 --> 00:42:46,930
and therefore converges

720
00:42:46,940 --> 00:42:49,930
two have and serum

721
00:42:49,990 --> 00:42:53,310
e there to tell you that the empirical approximation

722
00:42:53,320 --> 00:42:54,860
to this integral

723
00:42:54,880 --> 00:43:00,330
in the convergence is to mayor

724
00:43:02,040 --> 00:43:03,060
so again

725
00:43:03,080 --> 00:43:06,770
if you want to have this idea of of of using a markov chain with

726
00:43:06,770 --> 00:43:09,080
stationary distribution f

727
00:43:09,130 --> 00:43:11,910
we can use it in many ways

728
00:43:13,000 --> 00:43:14,860
most naive way

729
00:43:14,890 --> 00:43:16,400
is to say that

730
00:43:17,870 --> 00:43:20,690
we have such a markov chain if we take xt

731
00:43:20,700 --> 00:43:22,630
forty large enough

732
00:43:22,650 --> 00:43:26,780
xt converges to f xt not

733
00:43:26,800 --> 00:43:28,230
fourteen at large

734
00:43:28,280 --> 00:43:29,790
will be roughly

735
00:43:29,810 --> 00:43:34,480
distance from a very bad idea because

736
00:43:35,310 --> 00:43:38,480
we need to have the chain converging

737
00:43:39,650 --> 00:43:41,440
we don't know too large

738
00:43:41,460 --> 00:43:42,600
we should take

739
00:43:44,550 --> 00:43:48,220
and the say and say that even if we can manage

740
00:43:49,670 --> 00:43:51,700
the right to not

741
00:43:51,730 --> 00:43:54,940
we have to do it all over again if you want to say point that

742
00:43:54,940 --> 00:43:57,060
you see me for

743
00:43:57,200 --> 00:43:58,580
so this is that

744
00:43:58,600 --> 00:44:00,360
but on the other hand

745
00:44:01,620 --> 00:44:03,590
most monte carlo

746
00:44:06,380 --> 00:44:08,050
all the point is not

747
00:44:08,990 --> 00:44:14,360
and so we can use the whole change for monte carlo approximation

748
00:44:14,420 --> 00:44:16,190
can we will never

749
00:44:16,200 --> 00:44:18,810
get back to this idea because it is this

750
00:44:18,850 --> 00:44:20,390
about eighty

751
00:44:20,580 --> 00:44:25,910
the that version of it is called perfect sampling

752
00:44:25,930 --> 00:44:27,890
and this is one of the last chapters

753
00:44:27,990 --> 00:44:30,270
in notes but over time

754
00:44:30,280 --> 00:44:32,310
to talk about it

755
00:44:32,330 --> 00:44:34,610
of course you can read

756
00:44:35,730 --> 00:44:39,970
here is the idea we minute to put the idea into practice

757
00:44:40,040 --> 00:44:41,080
the is

758
00:44:41,100 --> 00:44:43,060
to find a way to build

759
00:44:43,110 --> 00:44:44,360
markov chain

760
00:44:44,370 --> 00:44:45,440
which has

761
00:44:45,560 --> 00:44:47,090
the target

762
00:44:47,120 --> 00:44:52,030
distribution as the stationary distributions is of course the point

763
00:44:52,840 --> 00:44:54,930
we need to go over

764
00:44:55,750 --> 00:44:59,950
the idea of the metropolis hastings algorithm to use instead

765
00:45:01,120 --> 00:45:04,060
it's it's a and using the wrong

766
00:45:04,090 --> 00:45:07,850
distribution to get to the right distribution so many years

767
00:45:07,870 --> 00:45:10,370
instead of

768
00:45:10,420 --> 00:45:12,200
f as

769
00:45:12,220 --> 00:45:13,090
the target

770
00:45:13,310 --> 00:45:16,250
distribution we choose

771
00:45:16,330 --> 00:45:17,990
conditional distribution

772
00:45:18,010 --> 00:45:20,150
thirteen of the markov camels

773
00:45:20,160 --> 00:45:23,470
q of y given x that is

774
00:45:23,480 --> 00:45:26,560
almost totally arbitrary

775
00:45:26,570 --> 00:45:29,190
that we have have the choice of

776
00:45:29,210 --> 00:45:32,850
and one is q

777
00:45:32,870 --> 00:45:34,660
so this transition

778
00:45:36,310 --> 00:45:39,690
would simulate from this transition kernel

779
00:45:39,710 --> 00:45:44,060
and because are not using a camel that is a series f

780
00:45:44,070 --> 00:45:45,140
we just picked

781
00:45:45,790 --> 00:45:47,980
whatever can

782
00:45:47,990 --> 00:45:49,310
we wish to

783
00:45:49,320 --> 00:45:50,810
to see it from

784
00:45:50,830 --> 00:45:51,870
i don't think it is

785
00:45:51,890 --> 00:45:52,990
and it

786
00:45:53,000 --> 00:45:57,210
we collect for the wrong choice of kernel

787
00:45:57,260 --> 00:46:00,050
by adding to the simulation

788
00:46:00,070 --> 00:46:02,090
and acceptance step

789
00:46:02,100 --> 00:46:07,320
that is we y from q of y given x but we want to go

790
00:46:07,380 --> 00:46:08,400
two f

791
00:46:08,420 --> 00:46:10,530
as the stationary distribution

792
00:46:10,540 --> 00:46:16,730
and therefore sometimes accept y and sometimes we reject one

793
00:46:16,770 --> 00:46:22,050
and rejecting what it means that the markov chain doesn't change value so x t

794
00:46:22,050 --> 00:46:23,100
plus one

795
00:46:23,380 --> 00:46:29,130
the next step in the markov chain takes the same numerical value as xt

796
00:46:29,150 --> 00:46:35,440
so the markov chain goes from xt two xt plus one by either picking

797
00:46:35,460 --> 00:46:39,310
the new similarity value that has been generated from this

798
00:46:39,330 --> 00:46:41,170
conditional distributions

799
00:46:41,180 --> 00:46:45,520
all staying where it is and the whole

800
00:46:45,540 --> 00:46:46,790
thing that

801
00:46:46,830 --> 00:46:50,940
that make the algorithm works is only the right choice

802
00:46:51,740 --> 00:46:54,590
the acceptance probability

803
00:46:54,650 --> 00:46:57,900
OK if you write the acceptance probabilities that way

804
00:46:57,910 --> 00:47:00,500
that is for y and x values

805
00:47:00,510 --> 00:47:05,580
o f of x the current value divided by q one argument or q x

806
00:47:05,590 --> 00:47:07,430
given y

807
00:47:07,450 --> 00:47:10,220
this choice of acceptance probability

808
00:47:11,050 --> 00:47:12,130
this necessarily

809
00:47:12,140 --> 00:47:18,260
producer markov chain with stationary distribution f of the see in one or two fly

810
00:47:19,350 --> 00:47:24,000
the point is that this is one of the most universal

811
00:47:26,150 --> 00:47:28,270
in the sense that

812
00:47:28,930 --> 00:47:31,100
so far i have no restrictions

813
00:47:31,110 --> 00:47:32,240
on q

814
00:47:35,010 --> 00:47:39,920
and still it produces a markov chain with stationary distribution

815
00:47:43,280 --> 00:47:44,490
so the

816
00:47:46,300 --> 00:47:47,820
a few remarks

817
00:47:47,870 --> 00:47:50,270
on this algorithm

818
00:47:52,250 --> 00:47:53,990
as that is there is

819
00:47:54,060 --> 00:47:56,070
my name is

820
00:47:56,120 --> 00:47:58,200
of this ratio in one

821
00:47:58,220 --> 00:48:02,120
so in this ratio is larger than one

822
00:48:02,180 --> 00:48:06,310
the ability to accept is one and therefore we always move

823
00:48:06,370 --> 00:48:08,060
this new values

824
00:48:09,210 --> 00:48:14,270
if should think that as an exploration agreement of this kind of distribution

825
00:48:14,280 --> 00:48:17,150
for the distribution is always go up here

826
00:48:17,160 --> 00:48:21,510
if this value is larger than this value

827
00:48:21,520 --> 00:48:24,720
this will have meaning in the special case

828
00:48:24,740 --> 00:48:29,090
well i think that if you propose the values that is totally irrelevant for your

829
00:48:29,090 --> 00:48:31,500
target distribution you don't even

830
00:48:31,510 --> 00:48:35,980
you go there because if ever y zero the probability of moving there

831
00:48:38,110 --> 00:48:42,590
and thing that is related to this time the simulation algorithm is that because you

832
00:48:42,590 --> 00:48:43,770
have the ratio

833
00:48:43,780 --> 00:48:45,080
of as

834
00:48:45,090 --> 00:48:47,370
and the ratio of cues

835
00:48:47,390 --> 00:48:52,450
you don't need to know the normalizing constant therefore it is complicated and is missing

836
00:48:52,450 --> 00:48:55,010
the normalizing constant this doesn't matter

837
00:48:55,020 --> 00:48:58,490
for the implementation of this algorithm

838
00:49:00,200 --> 00:49:02,060
the invented that although

839
00:49:02,070 --> 00:49:05,960
we think of xt something that is roughly

840
00:49:05,980 --> 00:49:08,340
coming from the distribution

841
00:49:08,390 --> 00:49:12,400
and the sequence you don't have an i i d sample from after because x

842
00:49:12,410 --> 00:49:15,000
is a markov chain and in particular

843
00:49:15,010 --> 00:49:18,700
because of this stage where we accept or reject

844
00:49:18,710 --> 00:49:22,910
because you can reject means that xtlx plus one can be the same

845
00:49:22,930 --> 00:49:26,160
and you can have sample with identical values

846
00:49:26,170 --> 00:49:28,300
several in a row

847
00:49:29,360 --> 00:49:32,660
the the last point is totally and in the article

848
00:49:32,680 --> 00:49:35,420
it is the fact that y two itself is not

849
00:49:35,440 --> 00:49:37,930
markov chain in most cases

850
00:49:37,930 --> 00:49:40,510
what people thought of this idea of

851
00:49:40,530 --> 00:49:45,370
using actually physical process as the basis of a random physical process is the basis

852
00:49:45,390 --> 00:49:49,160
of the random numbers may be some sort of thermal noise in a resistor or

853
00:49:49,160 --> 00:49:52,780
radioactive decay or what have you you can imagine that if you're going to store

854
00:49:52,780 --> 00:49:55,780
the number in a computer with say thirty two bits

855
00:49:55,800 --> 00:49:59,740
you can say are the first bit toss the coin and if its heads around

856
00:49:59,740 --> 00:50:03,760
one and a half the point again it's tails iwriter zero and you do that

857
00:50:03,760 --> 00:50:05,950
thirty three times and you have your

858
00:50:06,120 --> 00:50:07,720
thirty two bit number

859
00:50:07,840 --> 00:50:11,010
and then if you were to divide that by the maximum possible number that you

860
00:50:11,010 --> 00:50:12,720
could store in thirty two bits

861
00:50:12,760 --> 00:50:15,780
that would give you a random value between zero and one

862
00:50:15,800 --> 00:50:17,640
and that would work that would be fine

863
00:50:17,740 --> 00:50:21,570
that would be very slow and some people don't do it that way so people

864
00:50:21,570 --> 00:50:27,970
use instead are deterministic computer algorithms deterministic in the sense that if you were to

865
00:50:27,970 --> 00:50:33,410
actually run the algorithm over again you would generate exactly the same sequence of random

866
00:50:34,390 --> 00:50:38,720
so you think well that's that's no good that's not random and deterministic but actually

867
00:50:38,720 --> 00:50:42,800
they are just as good as they could it would certainly look random and for

868
00:50:42,800 --> 00:50:45,200
all and to all of the purpose is that we are going to use them

869
00:50:45,200 --> 00:50:47,840
for they behave as if they were random

870
00:50:47,890 --> 00:50:51,010
and in fact there are better than random because you want to be able to

871
00:50:51,010 --> 00:50:56,050
reproduce the sequence because when you're you're doing monte carlo calculation very often you find

872
00:50:56,050 --> 00:50:59,410
some sort of unexpected behavior and you want to be able to try to reproduce

873
00:50:59,410 --> 00:51:04,010
that so it's very convenient in fact to be able to rerun the algorithm and

874
00:51:04,030 --> 00:51:10,390
to reproduce the exact same random looking sequence over again sometimes people call these therefore

875
00:51:10,390 --> 00:51:14,180
pseudo random numbers instead of random but for our purposes there are just as good

876
00:51:14,180 --> 00:51:16,430
as random or better

877
00:51:16,450 --> 00:51:23,530
OK so actually write a computer algorithm that does this efficiently and it produces really

878
00:51:23,530 --> 00:51:25,050
random numbers that

879
00:51:25,070 --> 00:51:30,220
ah behave as if they were truly random that's difficult but it's fairly simple to

880
00:51:30,260 --> 00:51:35,030
to give a sample algorithm that is

881
00:51:35,070 --> 00:51:39,700
almost as good and illustrates all the main points and so there's one called the

882
00:51:39,700 --> 00:51:43,840
multiplicative linear congruence shield generator

883
00:51:43,850 --> 00:51:46,490
so this initial and sub-zero

884
00:51:46,510 --> 00:51:49,510
two n one n two and so forth and so you get a sequence of

885
00:51:49,510 --> 00:51:52,350
numbers and then those

886
00:51:52,370 --> 00:51:55,620
that sequence will have some maximum value and then at the end of the day

887
00:51:56,340 --> 00:51:59,340
divide the numbers in this sequence by the maximum

888
00:51:59,390 --> 00:52:04,070
and that gives you a sequence of numbers distributed between zero and one so here's

889
00:52:04,070 --> 00:52:06,530
the way the the rule works you get there

890
00:52:06,530 --> 00:52:10,780
i plus one element of the sequence from the i th element in the sequence

891
00:52:11,050 --> 00:52:15,720
according to this formula you take and so by a new multiply by

892
00:52:15,720 --> 00:52:18,050
some number a called the multiplier

893
00:52:18,070 --> 00:52:21,160
and then you take that modulo n where

894
00:52:21,180 --> 00:52:23,590
m is is constant called the modulus

895
00:52:23,590 --> 00:52:24,620
right now this

896
00:52:24,660 --> 00:52:29,090
mod operator is the remainder so what you do is you take the integer division

897
00:52:29,090 --> 00:52:33,450
of whatever's before divided by whatever is after and then you take the remainder so

898
00:52:33,450 --> 00:52:37,050
for example twenty seven mod five that would be too

899
00:52:37,110 --> 00:52:38,800
because the remainder is two

900
00:52:38,820 --> 00:52:42,240
so so that's the rule that's the rule that tells you how to get and

901
00:52:42,240 --> 00:52:44,510
i plus one from and survive

902
00:52:44,530 --> 00:52:46,610
and it will produce a sequence of numbers

903
00:52:46,640 --> 00:52:48,800
now there's a catch

904
00:52:48,820 --> 00:52:53,350
and this catches is characteristic of all of these algorithms that are used to produce

905
00:52:53,350 --> 00:52:57,660
a pseudorandom numbers and that that is that the sequence is periodic

906
00:52:57,700 --> 00:53:01,200
so you think periodic how can that be you want these things to behave as

907
00:53:01,200 --> 00:53:05,180
with as if they were random what if they follow some period then that's no

908
00:53:05,180 --> 00:53:09,370
good at all we simply need the period to be very very very long and

909
00:53:09,370 --> 00:53:15,120
you only use a subset of the sequence that lies well within a single period

910
00:53:15,140 --> 00:53:18,110
so here is just to illustrate how that works if you look at the example

911
00:53:18,110 --> 00:53:21,240
from this book i mentioned yesterday by one

912
00:53:21,320 --> 00:53:24,340
a very very nice chapter on how these methods work

913
00:53:24,350 --> 00:53:29,460
now let's just to take for illustrative purposes multiplier of three and the modulus of

914
00:53:30,260 --> 00:53:33,510
normally you would take those numbers to be very very large OK but here just

915
00:53:33,510 --> 00:53:36,120
for illustrative purposes let's pick them small

916
00:53:36,180 --> 00:53:39,220
i think the and zero equal to one

917
00:53:39,260 --> 00:53:41,850
all right so therefore in one is equal to

918
00:53:41,950 --> 00:53:45,010
three times one month seven what's that three months seven three

919
00:53:45,050 --> 00:53:49,030
so then here and two is nine mod seven is two

920
00:53:49,050 --> 00:53:54,030
while the law we get down to some six is fifteen mod seven which is

921
00:53:54,930 --> 00:53:59,350
but that's where we started with so at that point the sequence will simply repeat

922
00:53:59,410 --> 00:54:04,320
right now that's a outrageously short period you would never use a random number generator

923
00:54:04,320 --> 00:54:08,200
that can only generate you know half a dozen random values

924
00:54:08,220 --> 00:54:11,700
so what you need to do is you need to pick something larger which i

925
00:54:11,700 --> 00:54:13,870
think i have in the next overhead

926
00:54:15,800 --> 00:54:20,320
well so first of all as i mentioned before you divide by the maximum value

927
00:54:20,320 --> 00:54:24,490
which are turns out to be essentially equal to the modules and and those with

928
00:54:24,490 --> 00:54:26,950
then uniform between zero and one

929
00:54:27,010 --> 00:54:29,530
and you then have to ask other random

930
00:54:29,590 --> 00:54:33,180
so what you do is you pick the multiplier and the modulus so that these

931
00:54:33,200 --> 00:54:38,680
are so by pass various tests of randomness and there's software packages that you can

932
00:54:38,680 --> 00:54:43,720
use the will detect whether or not the you the distribution is uniform and also

933
00:54:43,720 --> 00:54:49,140
whether or not there are any correlations between pairs of random values so here for

934
00:54:49,140 --> 00:54:54,370
example this in this paper by like we a he suggests using a equals forty

935
00:54:54,370 --> 00:54:58,340
thousand six hundred ninety two and some big number for m is a bit of

936
00:54:58,340 --> 00:55:02,260
black magic involved here but what you get is is a distribution that indeed is

937
00:55:02,260 --> 00:55:07,850
very uniform between zero and one and here is a scatterplot of neighbouring values in

938
00:55:07,850 --> 00:55:11,070
the sequence and here you see this is essentially there is no evidence of any

939
00:55:11,070 --> 00:55:15,200
sort of correlation between the neighbouring pairs that's what you want

940
00:55:16,390 --> 00:55:20,050
now this is a very simple algorithm that in fact is not very very widely

941
00:55:20,050 --> 00:55:24,240
used you know in the root package there's this class called t random and there's

942
00:55:24,240 --> 00:55:26,320
the generator called t random three

943
00:55:26,350 --> 00:55:30,260
which is based on what's called the mayor sent twister algorithm which is an amazing

944
00:55:31,160 --> 00:55:34,640
and it has a period of two to the almost twenty thousand

945
00:55:34,700 --> 00:55:37,910
which is like ten to the six thousand and if you think about it that's

946
00:55:37,910 --> 00:55:42,340
an astronomically that's not even an astronomically large number is only what's an astronomically large

947
00:55:42,340 --> 00:55:44,260
number like ten to the seventy s

948
00:55:44,320 --> 00:55:46,280
protons in the universe

949
00:55:46,300 --> 00:55:50,700
you're talking about ten to the six thousand so there's absolutely no danger you're ever

950
00:55:50,700 --> 00:55:55,950
gonna like run over the period and have repeat just could never happen

951
00:55:55,970 --> 00:56:01,110
so so if you use random number generators you should use to random three you

952
00:56:01,110 --> 00:56:05,240
might ask yourself how can this has had a long period what here

953
00:56:05,240 --> 00:56:06,150
but called

954
00:56:06,190 --> 00:56:11,710
let's call why star that winter here

955
00:56:11,740 --> 00:56:19,640
X star the winter here so I'll sort of introduce the notation starved for that

956
00:56:19,670 --> 00:56:21,500
optimizes the best

957
00:56:21,580 --> 00:56:26,780
then what someone might stop is still get to some X . you don't know

958
00:56:26,780 --> 00:56:33,040
that it's extra yet you look around but everywhere you look is worse

959
00:56:33,160 --> 00:56:39,550
ah yes yes this is the this is the minimum cost so I mean that

960
00:56:39,780 --> 00:56:46,710
that the fact that this is this the the this quantity that you're trying to

961
00:56:46,710 --> 00:56:48,860
maximize when you do it

962
00:56:49,800 --> 00:56:55,480
equals this quantity that in this other problem you're trying to minimise well you're and

963
00:56:55,490 --> 00:56:58,920
actually ask yourself what's the relation between these from

964
00:56:58,930 --> 00:57:01,040
so must be proved right away

965
00:57:01,090 --> 00:57:08,930
weak duality which with what's what's always easy and these problems

966
00:57:10,840 --> 00:57:14,200
it is to show that the maximum

967
00:57:15,120 --> 00:57:17,750
it is always below the minimum

968
00:57:18,300 --> 00:57:25,720
maximum in 1 problem that that looks good the right Max was a real man

969
00:57:25,720 --> 00:57:28,420
but this is the maximum in the dual

970
00:57:29,240 --> 00:57:33,800
is always less regular minimum in the prime we can show that right off the

971
00:57:33,800 --> 00:57:38,240
bat just from taking to to steps along the way

972
00:57:39,180 --> 00:57:45,040
but there was a different problems so as not to surprising and then uh

973
00:57:45,820 --> 00:57:53,260
and mandatory serious duality thing is that actually when you're this quantity you're trying to

974
00:57:53,260 --> 00:57:55,560
maximize hygiene it'll go

975
00:57:55,690 --> 00:58:00,830
and you call this quantity here trying to minimize this cost down as low as

976
00:58:01,200 --> 00:58:02,860
0 they

977
00:58:02,900 --> 00:58:05,570
and then you know you've got the answer

978
00:58:07,400 --> 00:58:14,280
pass each other according to this symbol at the latest through so that the maximum

979
00:58:14,280 --> 00:58:16,720
in the dual for a here so this

980
00:58:16,880 --> 00:58:18,440
thank you xxx

981
00:58:18,720 --> 00:58:24,700
I want to show that this quantity C transpose X is I want to show

982
00:58:24,700 --> 00:58:28,200
that C transpose X is always

983
00:58:29,160 --> 00:58:35,640
less or equal to speak the transforms what for for any for any allowable extra

984
00:58:35,660 --> 00:58:44,600
for this is for any allowable X and Y so the normal yes maybe now

985
00:58:44,600 --> 00:58:49,440
maybe have let's see what is that I'm just gonna reversed here's the thing I'm

986
00:58:49,440 --> 00:58:54,380
maximizing right the key thing I'm maximizing sorry

987
00:58:55,440 --> 00:59:02,050
take that off the OK The is B transpose Y that's the quantity that I

988
00:59:02,050 --> 00:59:03,440
maximize so I

989
00:59:04,120 --> 00:59:06,580
foreshadow up but it doesn't matter

990
00:59:06,800 --> 00:59:08,780
any that's acceptable

991
00:59:09,400 --> 00:59:11,160
will be below 0

992
00:59:11,320 --> 00:59:16,450
In the cost of many exits except thanks and now

993
00:59:17,000 --> 00:59:25,950
that's for for for any acceptable any official I use the right word feasible x

994
00:59:25,950 --> 00:59:27,310
and y

995
00:59:30,920 --> 00:59:33,460
any feasible x and y

996
00:59:33,640 --> 00:59:38,620
this little work OK can we just take it will take that step would say

997
00:59:38,760 --> 00:59:41,660
if if if y is feasible

998
00:59:45,810 --> 00:59:50,500
but the X is the right if x is feasible A X is B right

999
00:59:50,530 --> 00:59:56,420
so I know that is an argument going connect those problems if x is feasible

1000
00:59:56,430 --> 01:00:03,000
and a being so this is a taxi transpose Y right

1001
01:00:03,570 --> 01:00:05,340
because as a x

1002
01:00:07,550 --> 01:00:09,550
now what my

1003
01:00:12,810 --> 01:00:17,860
well anytime ICA X transpose like like 1 idea in my head

1004
01:00:18,940 --> 01:00:20,110
right it

1005
01:00:20,110 --> 01:00:23,630
he started studying the statistical distributions of these patterns

1006
01:00:23,650 --> 01:00:25,510
and that didn't go anywhere

1007
01:00:27,590 --> 01:00:30,050
but i want to give the talk in the old days of course was overhead

1008
01:00:30,070 --> 01:00:34,590
rights like transparency is and so he had a couple of transparency in set one

1009
01:00:35,470 --> 01:00:40,320
on the overhead projector and overhead these other transparency one was slightly on top of

1010
01:00:40,320 --> 01:00:45,320
the but rotated with respect to it and he noticed that when the when there

1011
01:00:45,320 --> 01:00:47,590
was a slight you transformation

1012
01:00:47,630 --> 01:00:50,450
some interesting visual effects started to appear

1013
01:00:50,510 --> 01:00:53,880
so i kind of simulated that what happened in this experiment were part of the

1014
01:00:53,880 --> 01:00:55,190
random dot patterns

1015
01:00:55,240 --> 01:00:57,110
as i move my mouse

1016
01:00:57,130 --> 01:00:59,700
i'm changing the scaling of

1017
01:00:59,720 --> 01:01:04,720
so basically matrix multiply operation on the random dot pattern but i'm doing it with

1018
01:01:04,720 --> 01:01:09,670
the scaling or contraction on the x or y axis and rotation some superimposing two

1019
01:01:09,670 --> 01:01:11,240
random dot patterns

1020
01:01:11,280 --> 01:01:13,880
and one of the things he observed is

1021
01:01:13,900 --> 01:01:17,340
you can basically get all of the different flow fields that you see from you

1022
01:01:18,300 --> 01:01:23,150
two the left of ordinary differential equations just by changing the scaling and rotation because

1023
01:01:23,150 --> 01:01:28,800
it's basically a flow field so this is just a little interactive application here

1024
01:01:29,860 --> 01:01:32,690
for doing these kinds of things in this kind of fun to play with

1025
01:01:32,700 --> 01:01:35,150
so i just found the

1026
01:01:35,200 --> 01:01:36,990
the mouse events here

1027
01:01:36,990 --> 01:01:38,780
this transformer class

1028
01:01:38,880 --> 01:01:43,220
well i find i can connect to the button press event

1029
01:01:43,260 --> 01:01:47,490
and i i register some called axon sort of a standard event handling model we

1030
01:01:47,490 --> 01:01:51,050
have a lot of examples like that

1031
01:01:51,050 --> 01:01:52,190
but i'll show you

1032
01:01:52,190 --> 01:01:55,010
basically the simplest how that would work

1033
01:01:55,050 --> 01:01:56,800
one two three

1034
01:01:56,820 --> 01:02:01,170
so canonical figure

1035
01:02:01,200 --> 01:02:10,150
going define a little function in my hometown show called on press

1036
01:02:11,170 --> 01:02:15,700
i said my history so that's going to speed up speeding up a little bit

1037
01:02:17,320 --> 01:02:19,880
one of the mouse president gone

1038
01:02:19,930 --> 01:02:23,740
the event to tell me what actually event occurred over what the x and y

1039
01:02:23,740 --> 01:02:28,070
and display coordinates and what the x and y into indeed according to the connect

1040
01:02:28,090 --> 01:02:30,200
to that event

1041
01:02:30,220 --> 01:02:34,780
to the motion notify events called on press is probably not the best name basically

1042
01:02:34,780 --> 01:02:35,050
when the

1043
01:02:35,450 --> 01:02:39,010
i think it detects motion these events are going to fire off

1044
01:02:39,030 --> 01:02:42,300
so as you go over through here you can actually your y coordinates in data

1045
01:02:42,400 --> 01:02:47,090
you x and y coordinates and display spaces i move out of the axes i

1046
01:02:47,090 --> 01:02:50,190
don't have data corner system anymore so i'm only you can see the

1047
01:02:50,200 --> 01:02:53,630
the pixel coordinates are still registering but there is no data according

1048
01:02:53,650 --> 01:02:56,670
so that's fairly easy to do

1049
01:02:56,690 --> 01:03:00,630
um and i'm just going to disconnect that event

1050
01:03:00,650 --> 01:03:04,950
what really is cool though is we're using matplotlib is

1051
01:03:04,950 --> 01:03:07,530
event handling mechanism so we support

1052
01:03:07,550 --> 01:03:11,260
four five six user interface toolkits gtk

1053
01:03:14,530 --> 01:03:21,200
city qwx pis on qt qt for cocoa on mac OSX native rendered so all

1054
01:03:21,200 --> 01:03:22,360
of these different

1055
01:03:22,530 --> 01:03:27,170
back in the math lib support our models they translate go events into our framework

1056
01:03:27,300 --> 01:03:29,110
so you can take these

1057
01:03:29,130 --> 01:03:31,030
for example here

1058
01:03:31,030 --> 01:03:34,400
this transformer class at the very end i call pipe plant

1059
01:03:34,420 --> 01:03:36,260
script here

1060
01:03:36,260 --> 01:03:40,670
but i can just take these two i have another piece of code here called

1061
01:03:46,740 --> 01:03:50,050
class starts

1062
01:03:50,070 --> 01:03:52,090
and i have this

1063
01:03:52,110 --> 01:03:53,760
wx application

1064
01:03:53,780 --> 01:03:56,950
we were very simple double the application

1065
01:03:57,010 --> 01:03:58,300
and just

1066
01:03:58,320 --> 01:04:01,430
make some simple lines and you can see the wx because we have these two

1067
01:04:01,430 --> 01:04:03,510
different figures and had

1068
01:04:03,530 --> 01:04:05,320
the environment here

1069
01:04:05,320 --> 01:04:10,650
so that there is nothing about pylab app ipod and sister to wx application

1070
01:04:10,720 --> 01:04:14,050
what we do is just going to grab this little piece of code here

1071
01:04:14,130 --> 01:04:16,590
this transformer bit

1072
01:04:16,700 --> 01:04:20,220
the goal my wx

1073
01:04:20,240 --> 01:04:27,550
tim played which is the one i just ran for you

1074
01:04:27,590 --> 01:04:30,630
i'm going to go to the power plants that line

1075
01:04:30,690 --> 01:04:33,380
comment that l

1076
01:04:33,400 --> 01:04:39,200
important transformer module that i was just showing you

1077
01:04:39,220 --> 01:04:43,240
pace in this little snippet of code is called ax one here right

1078
01:04:43,270 --> 01:04:50,300
on the justice instantiate with annexes instances does everything else self

1079
01:04:50,380 --> 01:04:55,650
every year on this thing

1080
01:04:55,670 --> 01:04:57,900
now just based on this for example

1081
01:04:57,920 --> 01:05:02,370
and is fully enabled with user events but president nelson and you can take the

1082
01:05:02,370 --> 01:05:07,010
same piece of code and plug it into or QTR so you know give people

1083
01:05:07,010 --> 01:05:11,490
the ability to write you know kind of useful little widgets

1084
01:05:11,510 --> 01:05:14,720
they don't depend on the underlying really toolkit

1085
01:05:14,720 --> 01:05:18,490
so we have some examples in here for last demos and

1086
01:05:18,550 --> 01:05:23,090
and the all these years maps of events which many automatically run for you

1087
01:05:23,150 --> 01:05:28,380
across a variety of user interface toolkit which is another problem is proliferation of languages

1088
01:05:28,780 --> 01:05:34,260
is a professional packages there's also proliferation of user interface toolkit people and developed so

1089
01:05:34,260 --> 01:05:38,700
the memory in this case is distributed physically distributed

1090
01:05:38,710 --> 01:05:44,660
but logically shared which means what we chose not to the physical memory it's there

1091
01:05:46,020 --> 01:05:49,440
we have a single global space

1092
01:05:50,160 --> 01:05:52,540
the distributed memory

1093
01:05:52,570 --> 01:06:04,210
these are also very popular nowadays

1094
01:06:04,220 --> 01:06:06,860
can this

1095
01:06:06,900 --> 01:06:11,850
so what happened in the last year that we have gained and scalability

1096
01:06:11,870 --> 01:06:14,440
moving the

1097
01:06:14,460 --> 01:06:19,690
this was approaches use the in the past and these are approaches used nowadays more

1098
01:06:19,690 --> 01:06:21,430
often nowadays

1099
01:06:22,520 --> 01:06:24,880
these are possible combination there

1100
01:06:24,890 --> 01:06:28,170
architecture classification we described before

1101
01:06:28,190 --> 01:06:31,930
but what it's easy to see now it's getting more on the side of distributed

1102
01:06:31,930 --> 01:06:34,480
computing cluster using

1103
01:06:34,490 --> 01:06:37,440
using distributed memory system

1104
01:06:37,460 --> 01:06:41,330
with multiple instruction multiple data

1105
01:06:50,630 --> 01:06:52,170
let's keep is OK

1106
01:06:52,190 --> 01:06:55,470
and i propose you five

1107
01:06:55,490 --> 01:06:56,970
programming model

1108
01:06:56,980 --> 01:07:00,180
how do we program part of the system

1109
01:07:00,520 --> 01:07:04,450
that as set out by the selected five of them which are

1110
01:07:04,460 --> 01:07:08,390
the most useful the most common the use

1111
01:07:08,400 --> 01:07:12,090
the first one is the just right out just space

1112
01:07:14,680 --> 01:07:17,360
we can think of these

1113
01:07:17,370 --> 01:07:21,630
system has a collection of trends

1114
01:07:24,390 --> 01:07:29,070
each train has got its own private viable

1115
01:07:29,170 --> 01:07:33,610
the prior to just space but there is a shared memory system behind so

1116
01:07:33,620 --> 01:07:38,540
we also have public space and these

1117
01:07:38,560 --> 01:07:44,540
space is used for communication to exchange information to synchronize

1118
01:07:44,560 --> 01:07:48,850
the different rights

1119
01:07:48,890 --> 01:07:56,830
programming system like these is exactly the same as programming concurrent to boost concurrent programming

1120
01:07:56,870 --> 01:07:59,480
like commodity trading

1121
01:07:59,480 --> 01:08:01,140
sequential machine

1122
01:08:01,170 --> 01:08:03,410
so if we do market trading

1123
01:08:03,410 --> 01:08:04,980
we use the same

1124
01:08:05,930 --> 01:08:10,960
program in parallel c so we shared memory space we don't need to go out

1125
01:08:11,640 --> 01:08:12,940
anything else

1126
01:08:12,960 --> 01:08:18,310
because the system will take care to distribute power treads in different processing

1127
01:08:20,290 --> 01:08:25,160
so let's say in this case the parallelism is quite transparent to the programmer

1128
01:08:25,210 --> 01:08:32,160
if the programming is using multi trades

1129
01:08:32,170 --> 01:08:34,350
message passing

1130
01:08:34,370 --> 01:08:37,520
also very popular because

1131
01:08:37,890 --> 01:08:42,410
let's say MPI which is the message passing interface is the library now

1132
01:08:42,520 --> 01:08:44,580
these freely available

1133
01:08:44,600 --> 01:08:47,190
which is the standard

1134
01:08:47,210 --> 01:08:48,540
and so on

1135
01:08:48,540 --> 01:08:55,140
if you write your code using MPI library your code is portable to any

1136
01:08:56,290 --> 01:08:59,890
returning to an systems

1137
01:08:59,910 --> 01:09:05,770
these these these programming model is based on a distributed memory

1138
01:09:05,790 --> 01:09:08,120
architecture so we have

1139
01:09:08,140 --> 01:09:11,390
independent machines

1140
01:09:11,500 --> 01:09:12,690
and they

1141
01:09:12,690 --> 01:09:14,410
copyright to sort

1142
01:09:14,540 --> 01:09:20,160
the problem of exchanging the explicit messages

1143
01:09:20,170 --> 01:09:21,540
it's a bit more

1144
01:09:21,560 --> 01:09:25,670
a complex than the previous one but this one is there

1145
01:09:25,690 --> 01:09:31,140
i is flexibility we can decide has programmers

1146
01:09:31,190 --> 01:09:34,480
a piece of the system was called it

1147
01:09:36,000 --> 01:09:37,830
seven zero

1148
01:09:37,850 --> 01:09:39,620
years ago actually a

1149
01:09:39,640 --> 01:09:41,830
he felt that one because of

1150
01:09:41,870 --> 01:09:43,890
still as better

1151
01:09:43,940 --> 01:09:45,390
features that by

1152
01:09:45,440 --> 01:09:52,390
unfortunately in that competition MPI was chosen for understanding

1153
01:09:52,440 --> 01:09:56,580
and you will find it for example in global distributions

1154
01:09:56,600 --> 01:10:03,940
you know blogs for grid computing MPI is part of the global distribution

1155
01:10:03,980 --> 01:10:07,350
data part is another model

1156
01:10:07,370 --> 01:10:12,310
these was still used by the disease was very popular for

1157
01:10:12,850 --> 01:10:16,710
single supercomputer single system

1158
01:10:18,480 --> 01:10:20,460
actually in data parallel

1159
01:10:20,460 --> 01:10:21,960
it's very simple

1160
01:10:21,980 --> 01:10:22,940
it's very

1161
01:10:22,960 --> 01:10:23,690
let's a

1162
01:10:23,710 --> 01:10:28,430
elegant and simple because we don't do any explicit programming for them

1163
01:10:28,440 --> 01:10:30,660
parallelisation we just

1164
01:10:30,660 --> 01:10:37,490
so in that sense the independent components are very well in line with its physiological

1165
01:10:41,720 --> 01:10:44,900
and then i will show some results on this

1166
01:10:44,920 --> 01:10:51,220
modeling of image and modelling of the visual cortex

1167
01:10:51,230 --> 01:10:54,060
so this is something very different from blind source separation

1168
01:10:58,220 --> 01:11:03,320
i think people and i see as are certainly not the only ones to develop

1169
01:11:03,320 --> 01:11:09,800
models to develop models of the sorry to develop statistical models of image data

1170
01:11:09,850 --> 01:11:14,640
because they they are they can be used basically what they very useful for

1171
01:11:14,650 --> 01:11:19,690
he's in the most general sense they are used for full bayesian inference

1172
01:11:19,830 --> 01:11:24,890
if you know the image is have typically are typically like something that is they

1173
01:11:24,890 --> 01:11:30,280
have the same prior distribution then you can use that in different methods of bayesian

1174
01:11:30,280 --> 01:11:32,280
inference for example

1175
01:11:32,300 --> 01:11:34,000
what you can do is denoising

1176
01:11:34,010 --> 01:11:35,830
so assume that you

1177
01:11:36,430 --> 01:11:41,390
you have an image and then it is forced to some noise on the image

1178
01:11:41,410 --> 01:11:44,380
now if you have a good set is the model of what you need is

1179
01:11:44,380 --> 01:11:49,100
really should apply when they have no noise then you can use this in in

1180
01:11:49,100 --> 01:11:52,690
bayesian inference actually i can show you what i mean

1181
01:11:54,550 --> 01:11:57,030
the formula is actually very simple in this case

1182
01:11:57,220 --> 01:12:04,880
so let us assume that we have an image

1183
01:12:04,960 --> 01:12:09,400
which is a very high dimensional vector but it's not my

1184
01:12:09,420 --> 01:12:14,680
noise and what we assume is only necessary what we all also is only this

1185
01:12:16,110 --> 01:12:18,050
so now if we we have

1186
01:12:18,060 --> 01:12:23,110
now what you can do is compute the posterior probability

1187
01:12:23,130 --> 01:12:25,020
of the original image

1188
01:12:25,040 --> 01:12:25,930
and even

1189
01:12:26,830 --> 01:12:29,910
distorted image

1190
01:12:29,930 --> 01:12:33,280
by the basic probability

1191
01:12:33,700 --> 01:12:38,090
the theory of i mean but basically by using the bayesian based formula that will

1192
01:12:39,570 --> 01:12:41,940
and probability of

1193
01:12:42,450 --> 01:12:44,870
the distorted image

1194
01:12:44,950 --> 01:12:47,360
in the original image

1195
01:12:47,380 --> 01:12:49,340
times the probability of

1196
01:12:49,350 --> 01:12:50,800
the prior probability

1197
01:12:50,830 --> 01:12:52,100
of the image

1198
01:12:52,110 --> 01:12:53,530
divided by

1199
01:12:53,550 --> 01:12:55,360
the probability

1200
01:12:55,380 --> 01:13:02,190
well can decide about the probability density so probability so let's say these probabilities

1201
01:13:02,200 --> 01:13:06,110
people probability of distorted image

1202
01:13:06,120 --> 01:13:08,630
so point is that

1203
01:13:08,650 --> 01:13:12,310
well you don't care about this to all

1204
01:13:12,330 --> 01:13:16,610
so what you have once you when you know what is the process of

1205
01:13:17,940 --> 01:13:23,610
distorted images are nice images from the original images and when you have prior models

1206
01:13:23,630 --> 01:13:28,640
of images then you can figure out what is for example the most probable

1207
01:13:28,670 --> 01:13:31,440
original image given this distorted image

1208
01:13:31,660 --> 01:13:34,680
so this is what image modeling gives you

1209
01:13:34,690 --> 01:13:39,360
and this is usually something very simple because for example if we assume that the

1210
01:13:39,820 --> 01:13:45,970
noise is an additive gaussian noise then this will be simply the square squared euclidean

1211
01:13:45,970 --> 01:13:51,950
distance between the distorted image and the original page so we maximize this you will

1212
01:13:51,950 --> 01:13:54,440
be basically

1213
01:13:54,490 --> 01:13:56,250
sorry this will be

1214
01:13:56,750 --> 01:13:58,970
minus minus

1215
01:13:59,190 --> 01:14:02,070
the next exponential

1216
01:14:02,090 --> 01:14:09,800
so this will be exponential expansion function of minus the euclidean distance

1217
01:14:09,810 --> 01:14:14,210
so you know image is then you want to find

1218
01:14:14,520 --> 01:14:20,320
some an image which is as close as possible to the distorted image but at

1219
01:14:20,340 --> 01:14:24,580
the same time it has has high a problem prior probability as possible

1220
01:14:24,600 --> 01:14:28,270
well basically the sum of the product of maximize

1221
01:14:34,890 --> 01:14:36,210
you think

1222
01:14:36,350 --> 01:14:40,550
so this this

1223
01:14:40,610 --> 01:14:43,850
so this observations of random vectors

1224
01:14:44,650 --> 01:14:48,450
the observation so that you can just take the

1225
01:14:48,460 --> 01:14:52,960
and that's exactly the same kind of ideas can be used for prediction regression for

1226
01:14:52,960 --> 01:14:57,540
example let's say that you have an image and some pieces some missing

1227
01:14:57,560 --> 01:15:01,240
for various reasons and you can use the same kind of ideas to infer the

1228
01:15:01,240 --> 01:15:03,980
missing pixels

1229
01:15:04,000 --> 01:15:08,030
so yes i see and related models are

1230
01:15:08,060 --> 01:15:09,430
seems to be quite

1231
01:15:09,460 --> 01:15:17,760
useful and i will explain how they are connected to a classical idea what's possible

1232
01:15:17,770 --> 01:15:20,400
oh sorry i not expect to get it there

1233
01:15:22,010 --> 01:15:27,920
so typically what we typically what people is linear models

1234
01:15:27,940 --> 01:15:34,660
all of images using something like a latent variable linear linear latent variable models which

1235
01:15:34,660 --> 01:15:38,750
is of course why you easily end up with something like ICA

1236
01:15:38,750 --> 01:15:42,460
OK the only obvious when i say these things and you just have to go

1237
01:15:42,460 --> 01:15:46,150
along that i actually do really big time right and i have no love for

1238
01:15:46,150 --> 01:15:49,560
me and that's why not perfect for teaching this class i had to be erected

1239
01:15:49,560 --> 01:15:52,540
more than any other class i taught at stanford in my time here

1240
01:15:52,920 --> 01:15:55,880
and that's because each core was that is going to give me a b give

1241
01:15:55,880 --> 01:16:00,320
me because there's no better forced to teach programming is just awesome

1242
01:16:00,330 --> 01:16:03,730
if you want programming i think there's almost nothing better to do in the world

1243
01:16:04,230 --> 01:16:07,700
you have the task trying to get their you're coding you're make stuff happen you're

1244
01:16:07,700 --> 01:16:11,760
testing you're already running it comes back around see stuff you build things right you

1245
01:16:11,760 --> 01:16:15,590
can when you're done you know works right you know that feeling writing paper like

1246
01:16:15,600 --> 01:16:18,990
wasn't good enough the following you could probably go

1247
01:16:19,020 --> 01:16:21,870
both run this argument like when you want the works like you know you like

1248
01:16:22,130 --> 01:16:26,210
that that was supposed to get the right answer it plays the game solve the

1249
01:16:27,010 --> 01:16:30,140
finding and fixing that last part of the body is kind of one of the

1250
01:16:30,140 --> 01:16:33,660
aspect of approach we want people moan about i i happen to think that if

1251
01:16:33,660 --> 01:16:38,870
you're driven by dividing like most possible detective stories ever right it's like trying to

1252
01:16:38,870 --> 01:16:41,510
figure out what happened when you when you do this when you move that y

1253
01:16:41,510 --> 01:16:42,370
one this way

1254
01:16:42,390 --> 01:16:45,910
and what this effect cause and then they want to make the fake how sexism

1255
01:16:46,000 --> 01:16:49,610
staying up late like there and i have stayed up late one night debugging than

1256
01:16:49,610 --> 01:16:52,580
anything else in my life and i'm not about that at all

1257
01:16:52,590 --> 01:16:54,930
so that means i'm in the right place

1258
01:16:54,950 --> 01:16:56,940
hopefully someone that resonate with you

1259
01:16:56,980 --> 01:17:01,610
it's a little bit if that only sounds really awful to you hopefully we can

1260
01:17:01,610 --> 01:17:05,010
change my little bit but that that is in some ways part of what drives

1261
01:17:05,010 --> 01:17:08,890
computer science because this kind of wanting to build things you know we are engineers

1262
01:17:08,890 --> 01:17:12,190
right part of the school of engineering right we had this computer science named just

1263
01:17:12,190 --> 01:17:17,930
remember any subject name is something science is not science but you know we're trying

1264
01:17:17,930 --> 01:17:23,070
to up but but but we do a lot of really great work right and

1265
01:17:23,090 --> 01:17:26,140
there are a lot of neat scientific principles and theory that appear what we do

1266
01:17:26,960 --> 01:17:29,250
but in the end i think what drives a lot of this is just the

1267
01:17:29,250 --> 01:17:32,280
engineering building stuff that is

1268
01:17:32,300 --> 01:17:37,920
really need it reminds me that my my happens in mechanical engineering so i used

1269
01:17:37,920 --> 01:17:40,840
to be envious because he was building his CVM is a week

1270
01:17:40,850 --> 01:17:45,270
total from core you know around the campus people bicycles and stuff like you know

1271
01:17:45,270 --> 01:17:48,600
they they build all these things but now having watched all things you don't like

1272
01:17:48,720 --> 01:17:54,190
it is really hard actually you know these materials in all these tools millions wavy

1273
01:17:54,210 --> 01:18:00,100
hot glue which burns back into fingers touch it and its ability to contribute to

1274
01:18:00,100 --> 01:18:04,200
show you need a compiler in a computer he five it's like it's an abstraction

1275
01:18:04,200 --> 01:18:07,860
we build our brains and there's is relatively small set of things that you need

1276
01:18:07,860 --> 01:18:11,710
to come master and then you can combine them in these very sophisticated interesting ways

1277
01:18:11,710 --> 01:18:15,110
to solve all sorts of problems but the kind of the very low overhead and

1278
01:18:15,130 --> 01:18:18,140
the range of things you can attack with the same set of skills is huge

1279
01:18:18,140 --> 01:18:22,580
like every domain out there can benefit from somebody applying computers and in a useful

1280
01:18:22,580 --> 01:18:27,410
way without fail you know there's also the problem for technology is part of the

1281
01:18:27,410 --> 01:18:31,560
answer the only answer but certainly something that you can take whatever interest you have

1282
01:18:31,560 --> 01:18:34,550
and combine of computer science and construction something call

1283
01:18:36,220 --> 01:18:41,440
i think what happened in the second course is amazing that the first cause you

1284
01:18:41,440 --> 01:18:44,640
kind of get up to speed and there's a lot of basic material and needs

1285
01:18:44,640 --> 01:18:47,930
to get covered and it does kind you on the right path but in this

1286
01:18:47,930 --> 01:18:52,980
course actually we really get the blossom beyond the basic things that there's a bunch

1287
01:18:52,980 --> 01:18:58,650
of really neat and very successful technique right that second-quarter student can understand and master

1288
01:18:58,650 --> 01:19:02,010
and do really cool things with the can learn how to do something like that

1289
01:19:02,270 --> 01:19:06,990
created database that has a million entries right and then ask for somebody by name

1290
01:19:06,990 --> 01:19:10,690
and be able to instantaneously find that not by looking at a million entries one

1291
01:19:10,690 --> 01:19:14,260
by one change the size to make it ten million making billions and still be

1292
01:19:14,260 --> 01:19:17,460
able to provide that kind of instantaneous axis you will learn how to do that

1293
01:19:17,780 --> 01:19:21,550
right in the technique is not you know some super-human thing is something very clever

1294
01:19:21,550 --> 01:19:27,200
admittedly but but it's very accessible taking that's a million thing in we had to

1295
01:19:27,200 --> 01:19:30,740
sort it efficiently what if you happen to know things about that's almost sort of

1296
01:19:30,750 --> 01:19:33,500
which a little bit of sort other ways you can actually make it even faster

1297
01:19:33,500 --> 01:19:34,950
to put in sorted order

1298
01:19:34,960 --> 01:19:40,180
there are techniques for example like recursion that take problems that you might not have

1299
01:19:40,180 --> 01:19:42,730
any idea when you first look at the problem how to solve but once you

1300
01:19:42,730 --> 01:19:47,100
and in matlab code there is only one line change in matlab code for learning

1301
01:19:47,100 --> 01:19:49,170
these models going from binary to real value

1302
01:19:49,810 --> 01:19:54,670
right and again the conditional probability he's just going is gonna be given by the product of gaussians

1303
01:19:55,270 --> 01:19:59,250
right but what you can learn is you can learn these kinds of features a

1304
01:19:59,250 --> 01:20:02,230
given you know you're looking at four million unlabelled images

1305
01:20:02,710 --> 01:20:05,040
just images random images downloaded from the web

1306
01:20:06,000 --> 01:20:09,100
this is the kind of structure that the model is discovering right

1307
01:20:09,730 --> 01:20:16,620
and you can see it sort of again and discovers these edges but also discovers interesting things like will colours

1308
01:20:19,170 --> 01:20:23,770
and again when i show these things to the neuroscientists they get excited because it

1309
01:20:23,770 --> 01:20:25,770
sort of looks will be possible from them

1310
01:20:26,600 --> 01:20:27,520
design standpoint

1311
01:20:28,770 --> 01:20:32,830
and the way you can think again is again just finds basis find slightly different

1312
01:20:32,830 --> 01:20:34,920
basis for four images if i show you a new image

1313
01:20:35,440 --> 01:20:38,920
again i can decompose that i can write it as a linear combination of these basis

1314
01:20:39,560 --> 01:20:43,190
and these bases again a very useful to have because you can use these basis

1315
01:20:43,190 --> 01:20:45,790
to recognize what's going on which is much better than

1316
01:20:46,310 --> 01:20:47,830
i just using pixels

1317
01:20:49,560 --> 01:20:53,980
now one way to think about these models may be just point this out is if

1318
01:20:54,440 --> 01:20:59,690
if you look at the marginal probability probability of the data you can write it as the

1319
01:21:01,040 --> 01:21:01,690
this way right

1320
01:21:02,170 --> 01:21:06,440
it's the conditional probability times the prior you summing over these latent variables

1321
01:21:08,250 --> 01:21:12,730
now what happens is that you can essentially interpret these models as mixture models so

1322
01:21:12,730 --> 01:21:15,900
in this case you can interpret them as mixture of gaussians and you're probably familiar

1323
01:21:15,900 --> 01:21:17,500
with mixture of gaussians models right

1324
01:21:18,020 --> 01:21:22,650
but the beauty of these models you can interpret them as a mixture of exponential number of galaxies

1325
01:21:24,120 --> 01:21:26,370
and the way to think about this is that let's say i have

1326
01:21:27,100 --> 01:21:28,420
three latent variables

1327
01:21:28,900 --> 01:21:31,230
right each one takes value zero one

1328
01:21:32,560 --> 01:21:38,620
so if you think about this representation and to the three possible configurations for the eight possible configurations

1329
01:21:39,170 --> 01:21:41,020
and it turns out that i can write this model

1330
01:21:41,560 --> 01:21:43,580
as a mixture of eight gaussians

1331
01:21:44,210 --> 01:21:50,250
right but with the mean and the covariance is gonna be shared across different subsets of hidden variables

1332
01:21:50,940 --> 01:21:54,960
so in particular if typically if i have hundreds or thousands of these latent variables

1333
01:21:54,960 --> 01:21:57,730
hidden variables there are two thousand possible configurations

1334
01:21:58,500 --> 01:22:02,100
right so you can think about is used to do thousand possible mixture components

1335
01:22:02,940 --> 01:22:05,420
so these models are you know in general

1336
01:22:06,170 --> 01:22:09,630
for a lot of different problems these models work much better than me should gaussians

1337
01:22:11,020 --> 01:22:15,350
you can also apply these models to again modeling other kinds of data so here

1338
01:22:15,350 --> 01:22:17,290
you're applying it to modeling count data

1339
01:22:18,170 --> 01:22:21,480
this very useful for modeling you know things like web pages text

1340
01:22:21,980 --> 01:22:23,270
bag-of-words representation

1341
01:22:23,890 --> 01:22:26,350
so here you can think of are you know let's say

1342
01:22:26,850 --> 01:22:31,170
you have different words in a document and kate is the vocabulary size

1343
01:22:31,710 --> 01:22:32,830
so you know in english

1344
01:22:33,400 --> 01:22:37,810
might be seventy thousand city might be seventy thousand and its particular web page might

1345
01:22:37,810 --> 01:22:41,350
contain let's say a thousand words would be a thousand here

1346
01:22:41,920 --> 01:22:44,440
and again it is defining these models as lights

1347
01:22:44,850 --> 01:22:49,080
some changes but roughly then you have these pairwise terms and you have these in terms

1348
01:22:49,730 --> 01:22:52,150
so there's nothing difficult of extending these models

1349
01:22:53,000 --> 01:22:57,830
the conditional distribution is gonna be given by something called softmax distribution is the distribution

1350
01:22:57,830 --> 01:22:59,960
of different words that appear in the document

1351
01:23:00,960 --> 01:23:03,460
fairly straightforward and these are the kind of our

1352
01:23:04,290 --> 01:23:08,580
latent variables the latent topics that the model is discovering right so again if you

1353
01:23:08,580 --> 01:23:11,620
apply to the reuters dataset you know it's sort of figures out that they should

1354
01:23:11,620 --> 01:23:12,190
be things like

1355
01:23:13,390 --> 01:23:16,960
the russians and then you're then the computers and and such

1356
01:23:17,440 --> 01:23:22,520
so what i'm showing and again the way to think about this model is that every single web page document

1357
01:23:22,960 --> 01:23:27,750
it is given by some linear combination of these topics as sparse linear combination of

1358
01:23:27,750 --> 01:23:29,650
these topics a few topics get activated

1359
01:23:30,080 --> 01:23:30,520
and that's how

1360
01:23:31,120 --> 01:23:32,210
the data is generated

1361
01:23:32,790 --> 01:23:37,350
so finds in interesting thing here is that you know when when you apply these

1362
01:23:37,350 --> 01:23:42,890
models to images you find these edges when you apply these models to words

1363
01:23:43,390 --> 01:23:44,440
it's sort find these

1364
01:23:44,960 --> 01:23:46,650
interesting meaningful topics

1365
01:23:48,440 --> 01:23:50,620
this is what it doesn't terms reconstructions

1366
01:23:51,900 --> 01:23:56,580
so this was trained on the flickr dataset in the second half of the tutorial

1367
01:23:56,580 --> 01:23:57,710
i'm gonna show you more of this

1368
01:23:58,230 --> 01:24:00,850
so this is if i if i give them all chocolate intake

1369
01:24:01,540 --> 01:24:07,210
i called chocolate intake and look at these distribution with hidden variables and then we reconstruct back the data

1370
01:24:07,690 --> 01:24:12,790
you know reckons it reckons for you reconstruct things like take chocolates we deserve cupcake

1371
01:24:12,790 --> 01:24:18,270
food sugar cream right so obviously captures some semantic similarity between different words

1372
01:24:18,900 --> 01:24:21,350
it's also interesting that's you know this guy flower high

1373
01:24:22,350 --> 01:24:25,830
and then the japanese sign that flow high japan's according

1374
01:24:26,480 --> 01:24:30,420
know what these mean but there was some talk to right so just picks up

1375
01:24:30,900 --> 01:24:31,850
you know these kinds of

1376
01:24:33,250 --> 01:24:36,900
you know some of multilabel legal things just by looking at correlations

1377
01:24:38,560 --> 01:24:40,600
between different between different words

1378
01:24:41,310 --> 01:24:43,920
it's very useful you know including text

1379
01:24:45,290 --> 01:24:49,390
the other thing is that you can apply these models exact same all you can apply to modeling

1380
01:24:50,170 --> 01:24:51,270
social network data

1381
01:24:52,600 --> 01:24:56,730
so this was done on the netflix dataset where you have users

1382
01:24:57,480 --> 01:24:58,330
and you have movies

1383
01:24:58,750 --> 01:25:02,420
and you can think of just in coding each user preference with the rating pattern

1384
01:25:02,900 --> 01:25:03,790
has been here

1385
01:25:04,750 --> 01:25:08,420
so you can think of these being multinomial random variables that affect all tell you

1386
01:25:08,750 --> 01:25:11,770
whether the user liked the movie they like the more you know the user ratings

1387
01:25:11,770 --> 01:25:12,480
twenty five

1388
01:25:14,210 --> 01:25:17,370
and the interesting thing about this model is that if you look at the latent

1389
01:25:17,420 --> 01:25:21,690
representations that the most discovering is sort of discovering these learned genre

1390
01:25:23,120 --> 01:25:25,170
you you know horror movies get grouped together

1391
01:25:27,040 --> 01:25:29,520
it's interesting michael moore's movies get grouped together

1392
01:25:29,920 --> 01:25:32,350
so just by looking at the patterns of how people

1393
01:25:32,920 --> 01:25:34,960
rate movies you can basically figure out

1394
01:25:35,890 --> 01:25:39,370
the people really like his movies are they really hate his movies and

1395
01:25:40,210 --> 01:25:43,370
actually somebody pointed to me that this is not my goal more is more

1396
01:25:44,670 --> 01:25:47,400
but it should be very close i guess i'm curious myself

1397
01:25:48,310 --> 01:25:49,250
actually watch that movie

1398
01:25:53,690 --> 01:25:58,770
exactly the same kind of model slight modification and then you can apply to are

1399
01:26:02,460 --> 01:26:04,290
you know social nets or netflix

1400
01:26:05,190 --> 01:26:07,230
product recommendation type of problems

1401
01:26:08,270 --> 01:26:11,770
so a lot of these different you can model these different modalities and from machine

1402
01:26:11,770 --> 01:26:13,850
learning perspective that's very exciting right

1403
01:26:14,330 --> 01:26:16,440
because you can apply and a lot of different domains

1404
01:26:18,770 --> 01:26:21,600
one of the beauty behind these models is that you get

1405
01:26:22,120 --> 01:26:26,000
it's easy to infer the states of the hidden variables right so if you show

1406
01:26:26,000 --> 01:26:29,440
me a particular pattern for a user can quickly tell you what movies is what

1407
01:26:29,480 --> 01:26:34,600
he's gonna like oficial mean image i quickly tell you the distributional features oral what

1408
01:26:34,650 --> 01:26:36,120
topics that you see in the data

1409
01:26:36,830 --> 01:26:41,620
right and that's very important for information retrieval four four classification type of problems

1410
01:26:43,210 --> 01:26:45,190
way to think about these models is

1411
01:26:46,770 --> 01:26:49,940
just give intuition is that you can think of them as product of expert sometimes

1412
01:26:49,940 --> 01:26:51,730
people call these models product of experts

1413
01:26:52,580 --> 01:26:56,150
and the way to think about these models is that if i look at the marginal distribution

1414
01:26:56,710 --> 01:26:57,370
over the data

1415
01:26:57,830 --> 01:27:02,600
it can be written as a product of these terms and sometimes people call them as products

1416
01:27:03,170 --> 01:27:05,920
right so unlike traditional mixture models

1417
01:27:06,560 --> 01:27:08,420
right we have a product of a bunch of things

1418
01:27:09,500 --> 01:27:12,460
maybe i can give you an intuition what that really means

1419
01:27:13,210 --> 01:27:17,080
let's say i have these different topics that the model discovering right

1420
01:27:17,600 --> 01:27:19,150
if i activate topics

1421
01:27:19,770 --> 01:27:21,650
like government corruption and oil

1422
01:27:22,920 --> 01:27:27,560
you have put in will have very high probability the history books if i'm gonna

1423
01:27:27,560 --> 01:27:30,830
tell you that this document is about government corruption and oil

1424
01:27:31,690 --> 01:27:32,540
put in should go up

1425
01:27:34,900 --> 01:27:37,400
and this is unlike traditional mixture models

1426
01:27:37,790 --> 01:27:39,480
right in the mixture model you pick a topic

1427
01:27:39,920 --> 01:27:42,650
and then january word like traditional topic models like

1428
01:27:43,150 --> 01:27:47,810
latent dirichlet allocation if you've heard about these these kinds of models so he can

1429
01:27:47,810 --> 01:27:53,600
make the distributions very precise because you're taking three different distributions you multiplying them together

1430
01:27:54,100 --> 01:27:57,400
and as soon as you take distributions and you look at the intersection you can

1431
01:27:57,400 --> 01:28:00,290
be very precise about what you're gonna see in document

1432
01:28:00,750 --> 01:28:01,890
what you're gonna see the data

1433
01:28:02,480 --> 01:28:04,600
and that's precisely what's going on with with

1434
01:28:04,600 --> 01:28:06,350
the second part

1435
01:28:07,140 --> 01:28:10,010
the solution has to have a zero from component

1436
01:28:10,240 --> 01:28:12,910
so let's look at the second part

1437
01:28:13,400 --> 01:28:20,110
since omega strictly monotonic we can do the following reasoning we rewrite this quantity

1438
01:28:20,810 --> 01:28:23,130
again we use this of problem decomposition

1439
01:28:23,150 --> 01:28:28,880
we can now use pythagoras these two things are no

1440
01:28:28,890 --> 01:28:34,760
and since the square root a strictly monotonic function and only got a strictly monotonic

1441
01:28:34,760 --> 01:28:39,340
function if we set this thing here to zero we actually decrease the value of

1442
01:28:41,040 --> 01:28:46,280
inequality because if and only if is a former part is exactly zero therefore the

1443
01:28:48,740 --> 01:28:55,380
objective function from theorem must have the property that the of of part is zero

1444
01:28:55,430 --> 01:28:58,910
this is the wrong policy or the only thing we left with is this part

1445
01:28:58,930 --> 01:29:03,340
which is an expansion in terms of the training points so the solution must have

1446
01:29:03,340 --> 01:29:05,020
such an expansion

1447
01:29:05,020 --> 01:29:11,560
and all the islands that you've seen so far fit into this scheme

1448
01:29:11,570 --> 01:29:12,580
simply by

1449
01:29:12,600 --> 01:29:16,630
thinking about how the cost function in that case the for instance for support vector

1450
01:29:16,630 --> 01:29:21,740
classifiers the cost function actually only it's just to sum over

1451
01:29:21,740 --> 01:29:23,570
terms that depend

1452
01:29:23,590 --> 01:29:28,050
on on these quantities are separate for each i

1453
01:29:28,120 --> 01:29:35,770
in this form the regularizers to the quadratic one but you can also do support

1454
01:29:35,770 --> 01:29:38,150
vector regression you can

1455
01:29:39,100 --> 01:29:41,570
based on maximum a posteriori estimates

1456
01:29:41,590 --> 01:29:48,750
which can be identified with support vector machines regularisation networks and you can also the

1457
01:29:48,750 --> 01:29:53,660
kernel PCA which may or may i may or may not show you below

1458
01:29:53,680 --> 01:29:57,270
in this case we need a slightly more complicated cost function

1459
01:29:59,810 --> 01:30:00,980
so that's

1460
01:30:00,990 --> 01:30:03,080
well a little bit on

1461
01:30:05,660 --> 01:30:08,960
to some further kernel algorithms

1462
01:30:08,980 --> 01:30:15,180
so now you seem to have seen regression classification and you've seen the representer theorem

1463
01:30:15,210 --> 01:30:18,670
and you can probably imagine that one can

1464
01:30:18,700 --> 01:30:22,330
construct a lot more different kinds

1465
01:30:22,330 --> 01:30:27,350
so the components of these algorithms always similarity measures

1466
01:30:27,400 --> 01:30:31,030
you can think of this as a kernel module

1467
01:30:31,030 --> 01:30:34,350
and learning modules of the kernel

1468
01:30:34,380 --> 01:30:39,980
and some learning algorithms such as classification regression or something else

1469
01:30:39,990 --> 01:30:43,060
the interesting thing about the kernel module is

1470
01:30:43,070 --> 01:30:44,530
we have now

1471
01:30:44,640 --> 01:30:50,410
seen different interpretations we've seen that the kernel place in several different roles in

1472
01:30:50,440 --> 01:30:53,090
kernel methods support vector machines

1473
01:30:53,100 --> 01:30:54,900
the first one being

1474
01:30:54,910 --> 01:30:57,520
when i introduced kernels informally

1475
01:30:57,530 --> 01:31:04,310
i call them similarity measures come some kind of similarity measures usually a nonlinear similarity

1476
01:31:05,920 --> 01:31:07,580
so one is that the kernel

1477
01:31:07,580 --> 01:31:13,000
induces a representation because i told you if you have such a kernel and if

1478
01:31:13,000 --> 01:31:14,650
it is positive definite

1479
01:31:14,670 --> 01:31:16,660
then will automatically

1480
01:31:16,670 --> 01:31:20,770
correspond to the product in some of the space so this can we induce the

1481
01:31:20,790 --> 01:31:25,410
reproducing kernel hilbert space and we've shown that the kernel computes the product in that

1482
01:31:26,740 --> 01:31:30,010
therefore using this kind of similarity measure

1483
01:31:30,010 --> 01:31:35,390
it is equivalent to saying i'm representing my data in such a vector space such

1484
01:31:35,390 --> 01:31:38,640
as the product space and and using

1485
01:31:38,700 --> 01:31:40,390
standard product

1486
01:31:40,410 --> 01:31:42,590
my similarity measures so in the way

1487
01:31:42,600 --> 01:31:46,900
the kernel is therefore also gives you the time representation

1488
01:31:46,920 --> 01:31:51,880
and finally i just showed you the representer theorem and show you that if you

1489
01:31:51,880 --> 01:31:53,480
have any

1490
01:31:53,490 --> 01:31:57,080
the general class of objective functions

1491
01:31:57,100 --> 01:32:00,580
so if you have a learning problem which can be cast in this form is

1492
01:32:00,580 --> 01:32:07,500
minimized such an objective function with regularizer which is for monotonic function of the norm

1493
01:32:07,500 --> 01:32:09,670
in a RKHS

1494
01:32:09,690 --> 01:32:11,600
then there

1495
01:32:11,600 --> 01:32:13,280
class of possible solutions

1496
01:32:13,320 --> 01:32:16,290
takes this form so all possible solutions are

1497
01:32:16,340 --> 01:32:19,330
expansions in terms of constituent training points

1498
01:32:20,060 --> 01:32:21,000
so therefore

1499
01:32:21,880 --> 01:32:24,710
if you want to also parameterized function class

1500
01:32:25,050 --> 01:32:27,650
which is being used in learning

1501
01:32:27,670 --> 01:32:30,300
so all these three issues are

1502
01:32:30,330 --> 01:32:32,610
central issues for machine learning

1503
01:32:32,640 --> 01:32:37,400
and one of the appealing things have gone machines is that are all these issues

1504
01:32:37,400 --> 01:32:42,130
are treated jointly if you like

1505
01:32:43,390 --> 01:32:46,740
let's look at a couple of other algorithms

1506
01:32:46,740 --> 01:32:48,300
so that's the random walk problem

1507
01:32:51,350 --> 01:32:53,610
we can analyze this a little bit more

1508
01:33:02,150 --> 01:33:02,560
another way

1509
01:33:03,690 --> 01:33:05,040
looking at this is

1510
01:33:06,080 --> 01:33:07,470
to make ourselves

1511
01:33:07,660 --> 01:33:09,650
the transition probability matrix

1512
01:33:10,660 --> 01:33:13,040
we have shown here multiplied by a hundred

1513
01:33:13,690 --> 01:33:17,690
so the chain that running in the top twenty one possible states

1514
01:33:18,220 --> 01:33:19,740
and the transition probability if

1515
01:33:20,280 --> 01:33:23,700
in a particular state at call and shows it

1516
01:33:23,870 --> 01:33:25,120
and if you don't want them

1517
01:33:28,620 --> 01:33:30,060
o thing where you are on the

1518
01:33:34,980 --> 01:33:35,350
we can now

1519
01:33:36,550 --> 01:33:39,120
but this not a simple problem we can actually

1520
01:33:39,550 --> 01:33:40,630
and the question one

1521
01:33:41,310 --> 01:33:46,260
really what precisely we can say well for any particular duration of the probability distribution

1522
01:33:46,270 --> 01:33:50,130
where you will have got its start and end zero

1523
01:33:50,870 --> 01:33:52,790
the question but any

1524
01:33:53,320 --> 01:33:54,170
starting position

1525
01:33:54,610 --> 01:33:58,050
and we can what the probability is where you will have a lot the

1526
01:34:00,670 --> 01:34:05,450
this is the answer to at the heroes that's what the probability distribution the answer

1527
01:34:05,450 --> 01:34:10,100
is what we do in the location ten year in nineteen seventeen weighs about it

1528
01:34:10,300 --> 01:34:11,700
and shown in yellow and blue

1529
01:34:13,560 --> 01:34:17,120
this mission was starting out with probability one being in the

1530
01:34:18,130 --> 01:34:20,320
more about one in seventy

1531
01:34:20,870 --> 01:34:21,730
to start finish

1532
01:34:22,380 --> 01:34:23,400
and then after one there

1533
01:34:24,330 --> 01:34:25,150
new york is

1534
01:34:25,690 --> 01:34:26,110
in these

1535
01:34:26,640 --> 01:34:28,280
that means yellow places

1536
01:34:29,160 --> 01:34:29,630
in the

1537
01:34:30,840 --> 01:34:32,150
you would make impressions

1538
01:34:33,450 --> 01:34:36,250
okay so the two steps this distribution

1539
01:34:37,450 --> 01:34:38,120
the phrase that's

1540
01:34:38,620 --> 01:34:39,470
that's a distribution

1541
01:34:40,650 --> 01:34:41,630
and you recognise this

1542
01:34:42,080 --> 01:34:42,330
on the

1543
01:34:42,970 --> 01:34:44,130
one three three one

1544
01:34:44,570 --> 01:34:45,080
i think that's

1545
01:34:50,160 --> 01:34:50,950
the both that's

1546
01:34:51,470 --> 01:34:52,780
is this one

1547
01:34:53,240 --> 01:34:54,310
well one

1548
01:34:54,840 --> 01:34:56,280
except the distribution

1549
01:34:57,560 --> 01:34:58,090
is one

1550
01:34:59,700 --> 01:35:06,900
the one got not one but let me just try to get twenty what will be will come back on

1551
01:35:08,090 --> 01:35:11,530
about one or one with the right hand one in blue is a little bit which

1552
01:35:13,360 --> 01:35:17,270
but that's the next wrote about triangle the right hand side of it

1553
01:35:17,590 --> 01:35:18,810
european is happening

1554
01:35:20,470 --> 01:35:22,450
after six iteration seven

1555
01:35:25,010 --> 01:35:27,670
like this and i'm going to stop every twenty five

1556
01:35:30,260 --> 01:35:31,540
twenty five that's

1557
01:35:32,220 --> 01:35:33,790
found that very jaguar

1558
01:35:34,800 --> 01:35:35,910
in yellow showing you

1559
01:35:36,400 --> 01:35:38,150
it is not enough twenty five

1560
01:35:39,040 --> 01:35:43,690
still quite likely have it a waterfall and given that you've made and all the

1561
01:35:43,750 --> 01:35:47,810
number of this very likely be all locations

1562
01:35:48,940 --> 01:35:49,840
then you even

1563
01:35:51,030 --> 01:35:52,420
if you have any chance of being

1564
01:35:53,850 --> 01:35:55,490
after that iterations

1565
01:35:58,170 --> 01:36:02,690
hasn't changed much if started with seventeen years will very likely to be right and i

1566
01:36:04,520 --> 01:36:08,480
you are more likely to be in the middle and the edges and very unlikely to be in

1567
01:36:10,410 --> 01:36:11,620
nine and eleven

1568
01:36:12,310 --> 01:36:14,870
on the next step on when the ones you want you know

1569
01:36:15,440 --> 01:36:19,990
what locations nine and eleven you're very unlikely to be like that

1570
01:36:20,650 --> 01:36:23,300
the memory at all and even that

1571
01:36:23,730 --> 01:36:26,710
only uses on and even memory whenever it on wall

1572
01:36:28,810 --> 01:36:29,940
seventy five iterations

1573
01:36:31,090 --> 01:36:32,080
one hundred iterations

1574
01:36:32,560 --> 01:36:34,710
so instead of being a hundred and up

1575
01:36:35,310 --> 01:36:37,550
you might look at this graph now and again

1576
01:36:38,060 --> 01:36:43,190
a few one hundred iterations every time other running around iterations but now the and again

1577
01:36:43,890 --> 01:36:44,370
from the middle

1578
01:36:45,160 --> 01:36:47,830
and another and then we can do no wrong

1579
01:36:48,230 --> 01:36:49,940
and that will be a sample what actually

1580
01:36:52,700 --> 01:36:53,640
logic and even

1581
01:36:54,690 --> 01:36:55,290
you're not gonna get

1582
01:36:55,740 --> 01:36:57,370
right action all numbers

1583
01:36:58,780 --> 01:37:00,200
one hundred is quite long enough

1584
01:37:01,260 --> 01:37:03,040
even if you start in the middle at hand

1585
01:37:04,370 --> 01:37:07,330
and definitely not long after the seventeenth before

1586
01:37:07,940 --> 01:37:12,380
you've got much lower than in your own opinion but there are around the

1587
01:37:13,100 --> 01:37:13,980
dying and

1588
01:37:15,480 --> 01:37:15,790
the they

1589
01:37:16,450 --> 01:37:17,300
hundred five

1590
01:37:18,190 --> 01:37:18,760
two hundred

1591
01:37:19,850 --> 01:37:20,390
okay getting

1592
01:37:20,790 --> 01:37:22,450
pretty uniform that's the rock

1593
01:37:23,300 --> 01:37:25,150
thank you could be pretty much anywhere

1594
01:37:25,670 --> 01:37:26,500
after two hundred

1595
01:37:27,130 --> 01:37:30,080
or at bottom say four hundred where we really

1596
01:37:31,740 --> 01:37:33,110
is becoming fairly the

1597
01:37:33,560 --> 01:37:34,380
and we know there

1598
01:37:34,380 --> 01:37:38,700
more influence of that same example if you see it again

1599
01:37:38,790 --> 01:37:44,330
but very roughly in this is this is what

1600
01:37:44,340 --> 01:37:48,070
this is what you can do in the simplest way to compute these weights

1601
01:37:48,200 --> 01:37:52,490
and the simple fact that you have you know this weighted sum of the examples

1602
01:37:52,490 --> 01:37:57,500
and that generates you know your weight vector makes it that you can

1603
01:37:57,570 --> 01:38:02,840
plugging in you know into this of f of x represents things in these two

1604
01:38:02,840 --> 01:38:04,620
different ways

1605
01:38:04,690 --> 01:38:10,570
this is an important consequence

1606
01:38:10,590 --> 01:38:13,050
this is

1607
01:38:13,070 --> 01:38:17,260
you can do it you know you can do it the other way around

1608
01:38:17,280 --> 01:38:22,700
if you go into the in that direction if you take the perception representation and

1609
01:38:22,700 --> 01:38:28,990
going to the kernel representation it's not that interesting right why would you do that

1610
01:38:28,990 --> 01:38:34,130
there might be some computational reason why you want to do that but generally

1611
01:38:34,130 --> 01:38:39,430
it doesn't buy you much because you've already computed these phi functions

1612
01:38:39,470 --> 01:38:45,750
for example you have the pattern recognition problem you have you know images and you

1613
01:38:45,750 --> 01:38:52,530
want to extract features like you know edges corners or a small you know arcs

1614
01:38:52,570 --> 01:38:54,830
in these all your phi of x

1615
01:38:54,910 --> 01:39:01,270
what is more interesting actually needs to go in the other direction

1616
01:39:01,280 --> 01:39:06,720
why is that well because you can define now instead of defining features you just

1617
01:39:06,720 --> 01:39:13,050
have a simple similarity measure between examples and known

1618
01:39:13,050 --> 01:39:16,640
examples that you have in your database

1619
01:39:16,730 --> 01:39:26,530
and similarity measures are very flexible features are OK extracting features will will be doing

1620
01:39:26,530 --> 01:39:30,320
that in in one of the class that seem nineteen measures are very powerful because

1621
01:39:30,320 --> 01:39:34,740
you can define also similarity measures between objects that are not vectors so you can

1622
01:39:34,740 --> 01:39:42,050
define similarity measures between say molecules that are of different shapes and or you can

1623
01:39:42,050 --> 01:39:50,090
define similarity measures between between

1624
01:39:50,090 --> 01:39:56,820
spoken words that the had are different length and i'm not necessarily easy to represent

1625
01:39:56,820 --> 01:39:59,680
as vectors

1626
01:39:59,730 --> 01:40:05,670
the interesting thing is that once you have the similarity measure like that you can

1627
01:40:05,670 --> 01:40:09,590
go back to the second four

1628
01:40:09,610 --> 01:40:13,510
and you may think you know why would we want to go back

1629
01:40:13,550 --> 01:40:20,950
well because we can find optimisation algorithms that we learned the problem

1630
01:40:20,970 --> 01:40:25,470
in this hopes start in this the phi space

1631
01:40:25,490 --> 01:40:33,370
and and optimise in some sense you know the

1632
01:40:33,410 --> 01:40:38,990
the the the the way the decision was is performed in that space and you

1633
01:40:38,990 --> 01:40:42,410
can do that without explicitly

1634
01:40:42,450 --> 01:40:44,130
computing the five

1635
01:40:44,170 --> 01:40:49,350
just by the mere fact that you know that you can define the k as

1636
01:40:49,350 --> 01:40:54,330
the fight and phi can be can remain implicit and find some cases can even

1637
01:40:54,330 --> 01:41:00,390
have infinite dimension so this is you know the so-called kernel trick that will be

1638
01:41:00,390 --> 01:41:01,750
hearing a lot about i think in

1639
01:41:02,550 --> 01:41:08,380
these two weeks in order to derive many kernel method algorithms

1640
01:41:08,470 --> 01:41:14,270
so what is the kernel also kernel is a similarity measure it's the dot product

1641
01:41:14,270 --> 01:41:16,350
in some space

1642
01:41:16,360 --> 01:41:22,090
and sometimes you don't know what the spaces the fire present unknown so here couple

1643
01:41:22,110 --> 01:41:23,660
examples of kernels

1644
01:41:23,670 --> 01:41:31,410
the gaussian kernel just computes the euclidean distance between two vectors

1645
01:41:31,430 --> 01:41:37,230
and the exponentially it's the this the square it so it's what it does is

1646
01:41:37,230 --> 01:41:39,550
that if you have an unknown example

1647
01:41:39,570 --> 01:41:43,840
it puts kind of the hat around it them

1648
01:41:43,860 --> 01:41:48,930
now take take an example to training example

1649
01:41:48,970 --> 01:41:55,450
and the key is you see two represents the unknown example

1650
01:41:55,530 --> 01:42:02,950
well the known example then the hand axes is and as is the unknown example

1651
01:42:02,950 --> 01:42:05,910
then as you go away from the known example

1652
01:42:06,410 --> 01:42:10,810
the k of of in t

1653
01:42:10,930 --> 01:42:15,670
case so this is what i explained you before that

1654
01:42:15,730 --> 01:42:17,710
as you go away

1655
01:42:17,750 --> 01:42:22,710
from the centre of the kernel there is the decay so you're going to be

1656
01:42:22,710 --> 01:42:24,470
able to use this kernel

1657
01:42:24,510 --> 01:42:31,930
two to vote and the voting power of the given pattern is going to be

1658
01:42:31,930 --> 01:42:38,230
less and less as you go away from the unknown example

1659
01:42:38,250 --> 01:42:43,050
but you have other kernels that i'm not like that not centred and decaying but

1660
01:42:44,030 --> 01:42:48,240
you can use the same type of learning algorithm and this is the case of

1661
01:42:48,240 --> 01:42:53,050
the put kernel and he because the weird shape you just just for the the

1662
01:42:53,050 --> 01:42:56,800
the dot product then you raise it to a given power so without going into

1663
01:42:56,800 --> 01:42:59,630
detail because you'll see that in other classes

1664
01:42:59,970 --> 01:43:07,010
using this kernel allows you to perform function which instead of being a linear function

1665
01:43:07,010 --> 01:43:12,530
is appalling and we'll function for number of with aspect to the inputs

1666
01:43:12,570 --> 01:43:19,090
and one last learning machine i would like to mention is the one second last

1667
01:43:19,410 --> 01:43:26,160
is not in which you just combine many neurons you put them you stack them

1668
01:43:26,180 --> 01:43:28,180
you know in in the structure

1669
01:43:28,230 --> 01:43:31,530
well you know there is one layer of neuron that is going to be the

1670
01:43:31,530 --> 01:43:38,910
input of another layer of neuron originally the not only are percent from was

1671
01:43:38,950 --> 01:43:45,730
designed to solve the so-called chessboard problem in which people showed that people understood that

1672
01:43:46,090 --> 01:43:51,930
when you have two classes that are arranged in this chessboard way

1673
01:43:51,970 --> 01:43:54,650
you cannot separate them with a single

1674
01:43:54,670 --> 01:43:57,990
linear decision boundary but if you have two

1675
01:43:58,030 --> 01:44:03,020
you know decision boundary then you can make a perfect separation

1676
01:44:03,110 --> 01:44:09,470
which is the how comes in the idea of of stacking several layers of these

1677
01:44:09,490 --> 01:44:12,650
well linear decision boundaries

1678
01:44:12,670 --> 01:44:20,990
now yet another important class of decision functions comes from tree closely fires

1679
01:44:21,170 --> 01:44:24,660
so it's very different from from the rest of what i've been explaining to you

1680
01:44:24,660 --> 01:44:30,130
so far but i cannot do without mentioning it

1681
01:44:30,890 --> 01:44:38,150
here and in no way representing again the same scalar plots in each box right

1682
01:44:38,190 --> 01:44:43,250
and so the way decision classify tree classify as work is that there are going

1683
01:44:43,260 --> 01:44:44,310
to try

1684
01:44:44,320 --> 01:44:47,030
progressively to

1685
01:44:47,260 --> 01:44:50,300
separate examples along

1686
01:44:51,800 --> 01:44:56,680
of the feature space so this is one feature one input for example the age

1687
01:44:56,680 --> 01:45:00,640
of a patient and here the weight of a patient in the other direction

1688
01:45:00,650 --> 01:45:05,210
and the different coloured dots represent two populations

1689
01:45:05,230 --> 01:45:10,080
for example you know the healthy and the diseased patients off with for the first

1690
01:45:10,080 --> 01:45:14,950
the first threshold threshold on feature f two you can pretty well separate the two

1691
01:45:14,950 --> 01:45:17,220
but if you get some things wrong here

1692
01:45:17,230 --> 01:45:20,740
in the overall functional class in the villages but actually have to spend a very

1693
01:45:20,740 --> 01:45:24,120
long time to figure out what's going on

1694
01:45:25,510 --> 01:45:27,810
the questions so far

1695
01:45:47,410 --> 01:45:50,700
so for instance protein interaction networks

1696
01:45:50,770 --> 01:45:52,910
something that you can overlay

1697
01:45:52,970 --> 01:45:55,520
in addition to all of this stuff

1698
01:45:55,580 --> 01:45:57,450
what happens then is that you've got

1699
01:45:57,470 --> 01:46:03,720
data from different entities of different types we might have missing information because you usually

1700
01:46:03,720 --> 01:46:07,210
if you know how to different proteins interact you have a pretty good idea what

1701
01:46:07,210 --> 01:46:09,050
they might actually do right

1702
01:46:09,870 --> 01:46:12,950
you might actually have this information only in parts

1703
01:46:13,060 --> 01:46:16,180
well actually get a little bit later to that in the context of

1704
01:46:16,250 --> 01:46:18,380
what you could call data fusion

1705
01:46:19,730 --> 01:46:22,300
this is actually one of the most exciting areas

1706
01:46:23,340 --> 01:46:26,390
if this is what you want to know about you spot on

1707
01:46:26,730 --> 01:46:28,090
this is pretty much

1708
01:46:28,100 --> 01:46:29,910
i guess what's happening in

1709
01:46:29,930 --> 01:46:35,650
conferences like UAI ICML nips where people actually and i seem be where people actually

1710
01:46:35,650 --> 01:46:41,200
worry about bringing start from different types together how to build good models

1711
01:46:41,210 --> 01:46:42,510
and a lot of that is

1712
01:46:42,520 --> 01:46:46,120
well good engineering it's sometimes a lot of experience

1713
01:46:46,130 --> 01:46:49,130
has something to do with statistics but at at the end of the day you

1714
01:46:49,130 --> 01:46:50,340
need to make it good

1715
01:46:50,380 --> 01:46:54,330
in that case biologically motivated model of how you think those

1716
01:46:54,380 --> 01:46:56,360
things interrelated

1717
01:46:56,380 --> 01:47:01,030
so for instance here a reasonable model might be that if substrings are similar

1718
01:47:01,170 --> 01:47:03,600
probably they do something similar

1719
01:47:03,630 --> 01:47:05,200
is that actually means to

1720
01:47:05,240 --> 01:47:07,350
similar sequences of proteins

1721
01:47:07,390 --> 01:47:11,900
and you can build a fairly good estimators based on that

1722
01:47:11,960 --> 01:47:14,720
so here the graph

1723
01:47:14,760 --> 01:47:17,480
that would actually be

1724
01:47:17,510 --> 01:47:21,600
i guess it actually would be a protein interaction model

1725
01:47:21,640 --> 01:47:25,750
another thing that you need to worry about

1726
01:47:25,810 --> 01:47:27,290
is missing there

1727
01:47:28,700 --> 01:47:29,750
it's not

1728
01:47:29,780 --> 01:47:34,720
a lot of data happens to be very well prepared

1729
01:47:34,760 --> 01:47:36,970
this is usually what you start out with

1730
01:47:37,870 --> 01:47:41,090
once you start working on real problems

1731
01:47:41,140 --> 01:47:45,290
you will realize that actually quite often you don't have all the above all the

1732
01:47:46,630 --> 01:47:50,960
well why is this so well sometimes in the measurement device fails

1733
01:47:51,630 --> 01:47:55,730
for instance if you have a cheap consumer camera

1734
01:47:55,730 --> 01:47:59,560
i mean OK you take a picture and you wouldn't notice it but quite often

1735
01:47:59,560 --> 01:48:01,740
some of the pixels of

1736
01:48:01,800 --> 01:48:06,350
so why don't you notice it because the camera manufacturer has used sneaky trick and

1737
01:48:06,350 --> 01:48:10,090
just interpolated the values from the adjacent pixels

1738
01:48:10,140 --> 01:48:12,800
into that pixel is missing

1739
01:48:12,860 --> 01:48:15,750
well why would they do that will simply because they want to throw away the

1740
01:48:16,660 --> 01:48:21,230
so what they've done is actually very very simple algorithm for

1741
01:48:21,240 --> 01:48:23,370
estimating missing variables

1742
01:48:23,390 --> 01:48:25,680
in an image

1743
01:48:25,690 --> 01:48:27,340
another example might be

1744
01:48:27,360 --> 01:48:30,150
so you have an microarray analysis experiment

1745
01:48:30,180 --> 01:48:35,770
and sometimes actually creating the substance that using analyse it can take years

1746
01:48:36,450 --> 01:48:38,820
let's say you will deny right

1747
01:48:38,840 --> 01:48:42,170
u for substance substance onto your i

1748
01:48:43,250 --> 01:48:46,710
well then just because some may be something went wrong when you wash theory in

1749
01:48:46,710 --> 01:48:51,120
which so there may be a few corners where the results are quite that good

1750
01:48:51,180 --> 01:48:55,400
well obviously you cannot go back to the biologist and say well sorry we screwed

1751
01:48:55,400 --> 01:48:56,600
up in the

1752
01:48:56,620 --> 01:49:01,460
in the experiment can use when another you getting that that substance again well

1753
01:49:01,470 --> 01:49:03,540
they will come back to you right

1754
01:49:03,560 --> 01:49:05,520
so you will have certain

1755
01:49:05,910 --> 01:49:08,140
genes whose expression is missing

1756
01:49:08,220 --> 01:49:10,410
you actually need to do analysis with that

1757
01:49:10,450 --> 01:49:13,780
there are various ways how you can deal with it

1758
01:49:15,110 --> 01:49:18,840
OK so the simplest way how you can deal with this is a simple mean

1759
01:49:20,510 --> 01:49:23,150
you think this is really tough to know you just take the average over all

1760
01:49:23,150 --> 01:49:25,590
the other pixels that you've seen

1761
01:49:25,650 --> 01:49:28,650
useful plant been

1762
01:49:28,980 --> 01:49:33,910
so actually on the camera people do something slightly smarter they just take the adjacent

1763
01:49:34,710 --> 01:49:37,550
not the average pixel value that we would have

1764
01:49:37,870 --> 01:49:41,220
it turns out that if you do this

1765
01:49:41,260 --> 01:49:43,980
i just try how well estimated forms

1766
01:49:45,010 --> 01:49:47,590
very close to being as good as having full

1767
01:49:48,490 --> 01:49:49,910
verbal information

1768
01:49:49,920 --> 01:49:54,110
so it's really frustrating if you want to design an algorithm which works better on

1769
01:49:54,110 --> 01:49:56,840
missing variables because you know

1770
01:49:56,890 --> 01:49:59,900
just in the simple mean imputation almost gets you to

1771
01:49:59,910 --> 01:50:02,940
the full results and then you know

1772
01:50:02,950 --> 01:50:07,780
you design a very complicated algorithm to get a slight improvement this can be extremely

1773
01:50:10,450 --> 01:50:14,750
just try simple mean imputation and only if that doesn't work

1774
01:50:14,760 --> 01:50:17,100
there's something fancier

1775
01:50:17,450 --> 01:50:23,030
the other thing maybe that sometimes measuring things can actually be very expensive

1776
01:50:23,050 --> 01:50:26,590
so let's say you're sick you go to see a doctor well what the doctor

1777
01:50:26,590 --> 01:50:29,570
is going to do first is he's going to talk to you

1778
01:50:29,620 --> 01:50:33,010
why is it going to talk to because that's pretty much the cheapest way of

1779
01:50:33,010 --> 01:50:35,190
actually of getting some data

1780
01:50:35,230 --> 01:50:39,010
the second thing is going through the is statement take attempt to measure blood pressure

1781
01:50:39,020 --> 01:50:40,240
and all that

1782
01:50:40,290 --> 01:50:41,660
well why

1783
01:50:41,700 --> 01:50:45,530
because these are very cheap measurements there might not be

1784
01:50:45,560 --> 01:50:48,770
the most effective measurements in order to diagnose

1785
01:50:48,780 --> 01:50:52,900
maybe the most effective way would be to just sticking to come into the cities

1786
01:50:54,010 --> 01:50:56,920
but that will cost thousands of dollars

1787
01:50:57,910 --> 01:51:02,050
therefore he actually in this case we have a process whereby he would go and

1788
01:51:02,050 --> 01:51:06,320
measure things might reformulate you have policies measure again

1789
01:51:07,150 --> 01:51:08,010
it has to

1790
01:51:08,050 --> 01:51:09,920
that's that actually

1791
01:51:09,950 --> 01:51:11,780
consumer more complicated so

1792
01:51:11,800 --> 01:51:15,510
maybe in and they will actually be talking about that within in the context of

1793
01:51:15,510 --> 01:51:17,150
game theory

1794
01:51:17,270 --> 01:51:21,060
are you going to talk about that and

1795
01:51:21,070 --> 01:51:23,980
not really OK sorry

1796
01:51:25,710 --> 01:51:31,890
so the other thing that could happen is that the bot is simply censor

1797
01:51:32,700 --> 01:51:34,370
for instance let's say

1798
01:51:34,390 --> 01:51:36,080
you are somebody to

1799
01:51:36,100 --> 01:51:42,000
well find information about some product asymmetric wilson and outside of the on the road

1800
01:51:42,100 --> 01:51:44,900
and you ask your question there

1801
01:51:45,000 --> 01:51:47,140
now the trouble with this is

1802
01:51:47,170 --> 01:51:50,790
the type of people who will actually stop and answer the questionnaire are not going

1803
01:51:50,790 --> 01:51:54,510
to be a representative sample of the population

1804
01:51:54,520 --> 01:51:57,500
so for instance seriously busy managers

1805
01:51:57,500 --> 01:51:59,420
well probably not stop

1806
01:51:59,520 --> 01:52:02,160
and people might not even give you the right answer

1807
01:52:02,200 --> 01:52:06,840
i mean maybe some people would be running around on the street at three PM

1808
01:52:06,990 --> 01:52:10,030
so maybe you'll find essentially students and housewives

1809
01:52:11,860 --> 01:52:12,820
you will have

1810
01:52:12,820 --> 01:52:16,670
the function has shifted in all direction

1811
01:52:16,720 --> 01:52:18,800
use your hands

1812
01:52:18,840 --> 01:52:20,990
all things in this election

1813
01:52:21,010 --> 01:52:23,240
o think it in this direction

1814
01:52:23,260 --> 01:52:24,920
but in this direction

1815
01:52:24,940 --> 01:52:26,150
so we'll see

1816
01:52:28,150 --> 01:52:30,130
also here

1817
01:52:30,170 --> 01:52:31,720
was doing

1818
01:52:31,970 --> 01:52:36,300
moving with speed v in that direction

1819
01:52:36,340 --> 01:52:41,970
now we're going to evaluate website

1820
01:52:41,990 --> 01:52:43,400
what happened

1821
01:52:43,420 --> 01:52:44,420
we now look

1822
01:52:44,420 --> 01:52:45,650
the function

1823
01:52:45,700 --> 01:52:49,200
a little less than later in time the length time

1824
01:52:49,220 --> 01:52:52,490
it has moved in this direction

1825
01:52:52,530 --> 01:52:53,760
it's moving

1826
01:52:57,240 --> 01:53:01,320
you can look through the meaning of this equation

1827
01:53:01,360 --> 01:53:04,950
you now understand why when i wiggle here

1828
01:53:05,010 --> 01:53:07,760
why this string had no choice

1829
01:53:07,760 --> 01:53:10,070
it must propagate

1830
01:53:11,200 --> 01:53:14,680
function that i generated and must propagate that

1831
01:53:14,700 --> 01:53:16,090
with the speed

1832
01:53:16,130 --> 01:53:18,420
square would have to define new

1833
01:53:18,550 --> 01:53:22,440
we derive the speed of propagation for that string

1834
01:53:22,440 --> 01:53:24,550
u is the mass per unit length

1835
01:53:24,610 --> 01:53:26,610
these tensions

1836
01:53:27,180 --> 01:53:31,860
if i ask you is obvious that the high tension gives you a higher speed

1837
01:53:33,050 --> 01:53:34,860
obvious to me

1838
01:53:34,920 --> 01:53:37,700
sort of not quite except that

1839
01:53:37,760 --> 01:53:41,950
is it obvious if i new large that i make it very thick

1840
01:53:41,990 --> 01:53:42,970
very heavy

1841
01:53:43,990 --> 01:53:47,400
that the propagation speed is lower

1842
01:53:48,880 --> 01:53:51,760
now they know the answer i was so it's quite obvious

1843
01:53:51,880 --> 01:53:55,200
but it's not so something

1844
01:53:55,200 --> 01:53:58,380
in any case we have derived two things

1845
01:53:58,380 --> 01:54:01,240
we had the right that there is such a thing as the speed that we

1846
01:54:01,240 --> 01:54:02,490
even have the right

1847
01:54:02,510 --> 01:54:06,400
the speed itself schroeder of the overview

1848
01:54:06,450 --> 01:54:10,860
so if we had done the experiment again with a high attention

1849
01:54:11,720 --> 01:54:15,070
oppose would move fast

1850
01:54:15,860 --> 01:54:18,510
something else that we have to explain

1851
01:54:18,550 --> 01:54:22,050
why on earth is mountain coming back as value

1852
01:54:22,110 --> 01:54:24,130
and why is that the coming back

1853
01:54:24,170 --> 01:54:25,900
this amount

1854
01:54:25,970 --> 01:54:27,490
that now

1855
01:54:27,490 --> 01:54:30,970
is the result of boundary conditions

1856
01:54:30,990 --> 01:54:32,030
some people

1857
01:54:32,050 --> 01:54:35,630
who have lectured at o three make a very simple state

1858
01:54:35,650 --> 01:54:36,570
they say

1859
01:54:36,610 --> 01:54:39,880
eight o three is only about two things

1860
01:54:39,940 --> 01:54:41,110
this equation

1861
01:54:41,260 --> 01:54:45,670
boundary conditions and all the rest follows

1862
01:54:45,680 --> 01:54:50,610
by that year

1863
01:54:50,650 --> 01:54:54,380
so we have the industry

1864
01:54:56,650 --> 01:54:57,950
because our

1865
01:54:59,240 --> 01:55:00,380
was the end

1866
01:55:00,400 --> 01:55:03,490
that's when he calls

1867
01:55:03,510 --> 01:55:06,590
what correctly

1868
01:55:06,630 --> 01:55:09,470
and we know that and

1869
01:55:09,530 --> 01:55:11,200
must stay a fixed

1870
01:55:11,220 --> 01:55:12,880
cannot move

1871
01:55:12,940 --> 01:55:17,340
put the line the

1872
01:55:17,450 --> 01:55:18,920
what is

1873
01:55:20,630 --> 01:55:24,090
this is the

1874
01:55:24,110 --> 01:55:26,360
and my post came in

1875
01:55:26,380 --> 01:55:32,110
this at the polls

1876
01:55:32,130 --> 01:55:34,720
and then evaluate them all the time

1877
01:55:34,780 --> 01:55:38,070
that this part of the world

1878
01:55:38,110 --> 01:55:40,490
just nicole

1879
01:55:40,570 --> 01:55:47,400
ready for that

1880
01:55:47,400 --> 01:55:51,720
so this part

1881
01:55:51,740 --> 01:55:59,900
and the part that

1882
01:55:59,950 --> 01:56:03,360
you to have

1883
01:56:06,360 --> 01:56:10,670
i have to make it a little bit to make it look like

1884
01:56:10,820 --> 01:56:14,880
little steeper

1885
01:56:18,260 --> 01:56:20,990
knows what happened is that

1886
01:56:21,050 --> 01:56:23,740
nicole knew very well

1887
01:56:23,760 --> 01:56:26,800
but this point cannot move

1888
01:56:28,780 --> 01:56:31,220
she very sneakily

1889
01:56:31,220 --> 01:56:33,260
without telling you need

1890
01:56:34,850 --> 01:56:36,700
oppose that came back to me

1891
01:56:36,760 --> 01:56:39,670
we make sure that all moments in time

1892
01:56:39,720 --> 01:56:43,990
this points to still so at this very moment in time she must have generated

1893
01:56:44,010 --> 01:56:44,990
the polls

1894
01:56:45,030 --> 01:56:46,440
which had this

1895
01:56:46,470 --> 01:56:49,300
displacement so that this part

1896
01:56:49,320 --> 01:56:53,470
exactly the same this sort of

1897
01:56:53,510 --> 01:56:56,380
but you must have done that at every moment in time

1898
01:56:56,380 --> 01:57:01,010
he must then that when this part arrived with this part arrived in this part

1899
01:57:01,010 --> 01:57:02,950
arrive when that part arise

1900
01:57:03,010 --> 01:57:05,650
so that means you must have generated

1901
01:57:05,670 --> 01:57:07,680
a poll on her side

1902
01:57:07,720 --> 01:57:09,300
that is of value

1903
01:57:09,320 --> 01:57:11,240
that now looks like this


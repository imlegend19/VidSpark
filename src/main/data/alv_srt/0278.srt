1
00:00:00,000 --> 00:00:01,540
of the pearson

2
00:00:01,580 --> 00:00:06,310
inside the given full profile so you say this is the profile this is what

3
00:00:06,310 --> 00:00:09,570
they want to know the name given to a given event

4
00:00:09,630 --> 00:00:15,060
and here you have that the last time i believe way to use a simple

5
00:00:15,060 --> 00:00:20,280
part which is you fix this subject to fix objective you ask for properties so

6
00:00:20,280 --> 00:00:26,520
what that what he's is very relationship between me and union down separate bodies nos

7
00:00:26,850 --> 00:00:30,900
so i know you're in

8
00:00:30,910 --> 00:00:34,500
so simple but can be combined

9
00:00:34,510 --> 00:00:38,880
in order to get more complex queries for instance

10
00:00:38,910 --> 00:00:40,140
we are asking

11
00:00:40,150 --> 00:00:42,200
to find the country

12
00:00:42,260 --> 00:00:46,120
they capital and a population so

13
00:00:46,170 --> 00:00:50,530
country is viable then you have to predicates the capital in the population and that

14
00:00:50,660 --> 00:00:51,940
you have to viable

15
00:00:52,890 --> 00:00:53,800
or here

16
00:00:53,940 --> 00:00:56,700
give me the full of yuri

17
00:00:56,730 --> 00:00:58,280
other pearson

18
00:00:58,290 --> 00:01:04,190
name and the name of the friends so this is my fourth profile wants to

19
00:01:04,190 --> 00:01:07,280
know my name what i know

20
00:01:07,280 --> 00:01:10,770
and given what i know you want to know the name

21
00:01:10,780 --> 00:01:13,600
OK so this is my answer we've

22
00:01:13,610 --> 00:01:19,380
one variablebinding year more people variablebinding because i am i know several persons

23
00:01:19,400 --> 00:01:21,940
and then

24
00:01:22,030 --> 00:01:25,650
what you

25
00:01:25,660 --> 00:01:31,420
and that

26
00:01:33,030 --> 00:01:39,140
OK so my name you've got the name of multiple binding here because i i

27
00:01:39,140 --> 00:01:42,780
know several person from these multiple binding

28
00:01:42,790 --> 00:01:45,260
each of them you want to know the name

29
00:01:45,270 --> 00:01:49,610
OK so this will answer in the guardian matthew that just enter room and so

30
00:01:49,610 --> 00:01:51,350
forth OK

31
00:01:51,400 --> 00:01:57,000
so these but there's basically go over database and extract all the people that match

32
00:02:03,120 --> 00:02:05,250
this is where the selected

33
00:02:05,270 --> 00:02:10,580
queries so a select query basically you give part and you get a table of

34
00:02:10,580 --> 00:02:15,520
data out there but there are other kind of creating you ask queries were you

35
00:02:15,520 --> 00:02:22,160
ever bullied answer so is this data inside the repository yes or no

36
00:02:22,180 --> 00:02:27,980
you constant query that gives as a result

37
00:02:27,990 --> 00:02:30,130
this is a graph

38
00:02:30,150 --> 00:02:33,300
that contains the bindings as triples

39
00:02:33,310 --> 00:02:38,450
so you can construct a new graph based on the information that you extract

40
00:02:38,620 --> 00:02:43,510
and the last one is described which is the way you got information even without

41
00:02:43,510 --> 00:02:46,660
knowing the triples the and the schema

42
00:02:46,770 --> 00:02:48,500
so you see

43
00:02:48,520 --> 00:02:50,830
this guy me these URL

44
00:02:50,850 --> 00:02:56,470
and the system can answer with RDF that describe the specific URL and from that

45
00:02:56,470 --> 00:02:57,920
you can learn the schema

46
00:02:57,970 --> 00:03:02,260
so you ask for a URL of my fourth profile and you learn that the

47
00:03:02,260 --> 00:03:08,750
reason name a side name and nickname and normal pages email and so you can

48
00:03:08,750 --> 00:03:11,520
start writing queries that use that schema

49
00:03:18,680 --> 00:03:19,920
all of these

50
00:03:19,930 --> 00:03:21,670
is there a way to write the query

51
00:03:21,730 --> 00:03:25,160
and the next thing is very is also way to send them

52
00:03:25,180 --> 00:03:28,260
this is a query language for the web so it's not just a way to

53
00:03:28,260 --> 00:03:33,570
express it clearly but also protocol to send the query to some engine and get

54
00:03:33,570 --> 00:03:34,690
the result back

55
00:03:34,890 --> 00:03:36,650
there is the protocol

56
00:03:36,670 --> 00:03:41,100
in the sparql means i guess

57
00:03:41,120 --> 00:03:43,790
simple protocol

58
00:03:43,850 --> 00:03:50,130
and query language something like that i forgot so in any case these protocol inside

59
00:03:50,150 --> 00:03:55,450
and the protocol is a way to send the query you can do it over

60
00:03:55,450 --> 00:03:57,420
HTTP like these

61
00:03:57,430 --> 00:04:01,260
so you are what you can see is very easy URL

62
00:04:01,270 --> 00:04:04,100
query i'm exposing the sparql endpoint

63
00:04:04,110 --> 00:04:07,810
and then i'm encoding using the

64
00:04:07,820 --> 00:04:15,090
the name beginning the new way of writing get queries in http or the other

65
00:04:15,090 --> 00:04:18,300
parameters so i'm saying query these graphs

66
00:04:18,320 --> 00:04:27,330
so that pdfs and use this query select all the excess and they artist

67
00:04:27,580 --> 00:04:32,040
i guess that if we here

68
00:04:32,050 --> 00:04:35,730
i hope so at least

69
00:04:35,740 --> 00:04:39,390
we're lucky get this comes from the

70
00:04:39,400 --> 00:04:43,380
you see the URL that i wrote in the area of the binding

71
00:04:43,410 --> 00:04:48,750
so i mean i've done something i send it to a sparql endpoint what i

72
00:04:48,750 --> 00:04:50,870
got as a result is table

73
00:04:50,910 --> 00:04:55,320
and the table contains all the artist better known inside the

74
00:04:56,380 --> 00:05:01,100
this is i believe something quite cool but was really to bolster his idea semantic

75
00:05:01,100 --> 00:05:05,380
web of creating multiple and points and so forth

76
00:05:05,420 --> 00:05:11,130
any question

77
00:05:11,140 --> 00:05:12,600
of course it is

78
00:05:12,640 --> 00:05:17,180
just the minimal you can really read a lot i put links here just for

79
00:05:17,410 --> 00:05:23,110
convenience in order to really is what i was trying

80
00:05:23,150 --> 00:05:25,020
so going back to

81
00:05:25,070 --> 00:05:26,420
our tutorial

82
00:05:26,430 --> 00:05:32,150
we get into even more boring part of the tutorial which is the implementation details

83
00:05:32,420 --> 00:05:39,280
of how you write code before we have really to design the last step which

84
00:05:39,280 --> 00:05:44,570
is the design of application so we designed ontology of application we designed and built

85
00:05:44,690 --> 00:05:49,470
the content we develop the simplest but we did not really design

86
00:05:49,490 --> 00:05:54,430
the application this of course we will not be done in detail because i'm not

87
00:05:54,430 --> 00:06:00,980
here to tell you about job i not about to java works actually i will

88
00:06:00,980 --> 00:06:05,630
try to emphasise or only the things that are really to semantic web address these

89
00:06:05,640 --> 00:06:09,580
java called you can download it and play with it if you really like to

90
00:06:09,580 --> 00:06:10,240
do so

91
00:06:10,420 --> 00:06:15,570
so designing the interface means two things means that

92
00:06:15,580 --> 00:06:22,530
designing good design their applications so remains designing all the components and the interfaces among

93
00:06:24,870 --> 00:06:27,240
and designing the

94
00:06:27,250 --> 00:06:29,930
what the way the application works inside

95
00:06:31,000 --> 00:06:36,660
first i will tell you about the interfaces the graphics user interfaces and interfaces to

96
00:06:36,660 --> 00:06:38,040
the that sources

97
00:06:38,050 --> 00:06:42,240
and then i will go into the design of mix as the program

98
00:06:42,250 --> 00:06:48,170
but as to deal with the user interface and external data sources

99
00:06:49,740 --> 00:06:52,270
more or less the disease

100
00:06:52,280 --> 00:06:53,140
a pretty

101
00:06:53,150 --> 00:06:56,320
straight representation of

102
00:06:56,360 --> 00:07:01,740
what is outside next to outside mexico ever use any browser and the fact that

103
00:07:01,740 --> 00:07:03,910
graphical model like the one on the right

104
00:07:04,120 --> 00:07:06,750
where you see each variable like x three

105
00:07:08,280 --> 00:07:10,520
being conditioned on all the previous ones

106
00:07:11,850 --> 00:07:15,910
so these kind of the compositions had been used

107
00:07:17,140 --> 00:07:22,180
before in the nineties in particular brand free in whose

108
00:07:22,590 --> 00:07:28,250
toronto his thesis ninety seven proposed a

109
00:07:28,650 --> 00:07:33,720
model that a essentially the has a logistic regression of each

110
00:07:33,730 --> 00:07:37,890
bit in a vector given the previous bits

111
00:07:38,120 --> 00:07:42,250
according to some order so you we're now not talking about sequences

112
00:07:42,260 --> 00:07:47,490
so there's no role natural order but we can still pick an order

113
00:07:47,630 --> 00:07:51,450
and then say we can model the conditional distribution of the aifb

114
00:07:51,780 --> 00:07:56,360
variable given the ones from i from one to i'm minus one

115
00:07:56,780 --> 00:07:58,930
and we just do a linear regression or

116
00:07:59,150 --> 00:08:02,350
logistic aggression to obtain those conditions abilities

117
00:08:02,990 --> 00:08:06,120
in in ninety nine with my brother semi we

118
00:08:06,510 --> 00:08:09,180
sort of extended this to a neural net

119
00:08:10,210 --> 00:08:13,940
where we said ok so that those conditional probabilities

120
00:08:15,380 --> 00:08:19,870
instead of being computed by a linear model we going to be using

121
00:08:19,870 --> 00:08:23,370
your net but instead of having a different neural net for each condition

122
00:08:23,370 --> 00:08:27,120
probability now because we have these hidden units we can share

123
00:08:28,480 --> 00:08:32,820
representation that we've learned for other earlier predictions

124
00:08:34,570 --> 00:08:39,240
incoming up with the next prediction so this is very different

125
00:08:39,240 --> 00:08:41,820
from normal recurrent net because in the normal recurrent net

126
00:08:41,820 --> 00:08:44,410
there's this kind of translation variance in other words

127
00:08:44,410 --> 00:08:48,240
we're assuming that what's you the parameters are good to predict

128
00:08:48,250 --> 00:08:55,530
the next timestep are also good to predict that the one after one after

129
00:08:55,530 --> 00:08:59,030
there is it doesn't matter we can take the data and then translated

130
00:08:59,030 --> 00:09:03,450
and and the properties of those conditions butions remain the same

131
00:09:03,650 --> 00:09:08,000
but here the the pixels could be yeah i mean that x one x two x

132
00:09:08,000 --> 00:09:10,800
could be anything like any random variable there's no

133
00:09:11,240 --> 00:09:15,500
there's no equivalent of i can translate and keep the semantics

134
00:09:15,790 --> 00:09:20,700
so the parameters of conditionals you know for predicting

135
00:09:20,700 --> 00:09:23,030
the third one would be different from the ones for taking

136
00:09:23,030 --> 00:09:29,780
the fourth one now here we have the same thing but we can share because

137
00:09:30,000 --> 00:09:32,600
when we makes a prediction for x three

138
00:09:33,060 --> 00:09:36,600
given x one and x to extract some intermediate features are hitting

139
00:09:36,600 --> 00:09:42,710
units and we could use these to predict x for a

140
00:09:43,160 --> 00:09:47,010
well should our here i'm going from to to

141
00:09:47,200 --> 00:09:50,470
p of x for yeah yeah so

142
00:09:53,850 --> 00:09:59,220
a little later in two thousand eleven hugo who've who you've heard

143
00:09:59,690 --> 00:10:03,130
monday a came up with a variation on this idea which

144
00:10:03,330 --> 00:10:04,640
makes the computation

145
00:10:06,790 --> 00:10:12,250
very efficient and also the statistical

146
00:10:12,560 --> 00:10:15,680
representation more efficient so there's less parameters to

147
00:10:16,700 --> 00:10:21,090
by introducing form of sharing that we didn't have so the idea here

148
00:10:21,100 --> 00:10:26,200
is that the weights that go from x one to the first group of

149
00:10:26,200 --> 00:10:29,290
hidden units will be the same as those go from x one to another

150
00:10:29,290 --> 00:10:32,430
group of it's corresponding to the pretty if you want to make

151
00:10:32,430 --> 00:10:38,240
in the future and so in this way have less parameters and

152
00:10:38,570 --> 00:10:41,530
you can also organized computation so that it's actually

153
00:10:41,700 --> 00:10:45,570
more efficient by reusing the computation that you've already made

154
00:10:45,580 --> 00:10:49,280
for the earlier timesteps and you just have to add new terms when

155
00:10:49,280 --> 00:10:52,410
we consider the next prediction say i now consider x three as an

156
00:10:52,410 --> 00:10:55,440
extra input i don't need to redo the additions corresponding

157
00:10:55,440 --> 00:10:59,120
to previous ones i just consider the new input and added

158
00:10:59,120 --> 00:11:02,190
extra term to the sum so competition can be very efficient

159
00:11:02,510 --> 00:11:05,740
now very efficient compared to previous models but it's still

160
00:11:05,890 --> 00:11:08,830
very inefficient on like gp you because

161
00:11:09,220 --> 00:11:11,910
this still very very sequential for each

162
00:11:12,170 --> 00:11:16,230
group for each input and reach output we have to do next a little

163
00:11:16,240 --> 00:11:19,500
bit of computation so it's kind of hard to paralyze but

164
00:11:19,760 --> 00:11:21,880
but these kinds of models actually quite

165
00:11:21,880 --> 00:11:25,400
work quite well and recently people have been using this style

166
00:11:25,410 --> 00:11:29,500
model images and they're called pixel rnn's

167
00:11:32,690 --> 00:11:36,270
and basically and these works surprisingly well so it's kind of

168
00:11:36,270 --> 00:11:38,890
disappointing for people like me you've been working on

169
00:11:38,890 --> 00:11:42,050
you know journ models with latent variables that these these

170
00:11:42,050 --> 00:11:44,940
graphical models with our any latent variables so it's just like

171
00:11:44,940 --> 00:11:47,340
a big recurrent net essentially our

172
00:11:47,370 --> 00:11:50,290
with a particular structure can generate the next pixel

173
00:11:50,320 --> 00:11:54,650
given the previously generated pixels so you can organize what's

174
00:11:54,650 --> 00:11:57,410
previously generated in various ways for example on the top left

175
00:11:57,410 --> 00:12:01,210
you see you just traverse you know all the rows and then you predict

176
00:12:01,220 --> 00:12:04,950
the next pixel given everything seen before maybe you can organize

177
00:12:04,960 --> 00:12:08,680
computation using this kind of triangle where use the information

178
00:12:08,690 --> 00:12:12,640
from the top or like the one right i mean there are various architectures

179
00:12:12,650 --> 00:12:15,820
you could use but the point as we define sequence

180
00:12:16,750 --> 00:12:19,190
and we have a little recurrent net

181
00:12:19,190 --> 00:12:22,790
which summarizes information you've seen in the path of the sequence

182
00:12:23,500 --> 00:12:27,730
and is used for the next pixel and it's very slow because you have

183
00:12:27,730 --> 00:12:29,980
OK so it doesn't make any difference

184
00:12:30,030 --> 00:12:35,080
whether you detect little usage j a from

185
00:12:35,090 --> 00:12:39,750
from the observation the subject a or whether you detect the vector

186
00:12:39,800 --> 00:12:41,610
the use of capital j

187
00:12:41,630 --> 00:12:45,190
from the whole set of of

188
00:12:45,280 --> 00:12:48,690
the output piece of one of the visa capital

189
00:12:48,700 --> 00:12:52,850
you get the same answer in both cases that you might say what happens in

190
00:12:52,870 --> 00:12:57,530
some of these likelihood ratios come out to be right on the borderline equal to

191
00:12:57,530 --> 00:13:01,550
one but doesn't make any difference because that's zero probability

192
00:13:01,570 --> 00:13:02,810
o thing

193
00:13:02,820 --> 00:13:06,100
if you want to worry about that you can worry about it and you get

194
00:13:06,100 --> 00:13:09,760
the same answer you just have to be a little more careful

195
00:13:09,780 --> 00:13:12,180
now here's something in the downside

196
00:13:12,190 --> 00:13:15,760
it's also fairly important

197
00:13:15,780 --> 00:13:20,570
here we're talking about the case where all these signals are independent of each other

198
00:13:20,580 --> 00:13:25,930
which is sort of what we want to look at and communication because because the

199
00:13:25,930 --> 00:13:30,750
most for what we're doing is we're taking is we're taking data some sort

200
00:13:30,770 --> 00:13:35,650
resource processing it to make the bits coming up the channel be independent of each

201
00:13:36,500 --> 00:13:38,570
and then we're going to be sending them

202
00:13:40,780 --> 00:13:44,620
well except now we want to say well i suppose that these inputs are not

203
00:13:44,640 --> 00:13:48,780
independent suppose for example we passed through an error correction

204
00:13:48,800 --> 00:13:52,370
encoding device before transmitting them

205
00:13:52,520 --> 00:13:55,510
the question is what happens then

206
00:13:55,520 --> 00:14:00,110
well the trouble is that you had to spend you have dependencies between you want

207
00:14:00,130 --> 00:14:01,940
a new subject i

208
00:14:01,960 --> 00:14:03,420
so you can

209
00:14:03,430 --> 00:14:06,310
you can still detect each of these

210
00:14:06,330 --> 00:14:10,790
just by looking at the single output

211
00:14:10,800 --> 00:14:15,740
and it's maximum likelihood detection based on that observations

212
00:14:15,760 --> 00:14:20,740
but if you look at the entire observation v one up to visit capital cai

213
00:14:20,760 --> 00:14:23,140
you get something better

214
00:14:23,150 --> 00:14:27,860
however you get something better

215
00:14:27,880 --> 00:14:32,380
well i know you get something better because in this case where you one of

216
00:14:32,380 --> 00:14:33,600
the use of j

217
00:14:33,650 --> 00:14:38,590
are dependent on each other these output variables these of one of the these capital

218
00:14:38,590 --> 00:14:42,440
j depend on each other they are irrelevant

219
00:14:42,450 --> 00:14:44,130
if you want to do the best

220
00:14:44,180 --> 00:14:49,450
job of maximum likelihood detection given the observation of these of one of the visible

221
00:14:49,450 --> 00:14:50,950
capital today

222
00:14:51,230 --> 00:14:54,630
then you're going to use all those variables in your detection

223
00:14:54,640 --> 00:14:56,270
and you're going to get better

224
00:14:56,340 --> 00:15:01,250
and you're going to get a better decision in other words smaller probability then you

225
00:15:01,250 --> 00:15:04,070
would have gotten otherwise

226
00:15:04,090 --> 00:15:07,080
but the important thing that comes out of here

227
00:15:07,090 --> 00:15:09,780
is that this simple-minded decision

228
00:15:09,790 --> 00:15:11,630
where you make a decision on

229
00:15:11,640 --> 00:15:16,450
i knew someone based just on visible on it's something you can do

230
00:15:16,490 --> 00:15:19,680
you can do the maximum likelihood decision

231
00:15:20,010 --> 00:15:24,640
can you know how it behaves you can calculate what the year probability is

232
00:15:24,690 --> 00:15:29,410
but you know now automatically the year probability is going to be greater than or

233
00:15:29,410 --> 00:15:34,260
equal to the air probability that you would get if you base that decisions on

234
00:15:34,260 --> 00:15:36,440
the whole set of inputs

235
00:15:36,490 --> 00:15:42,360
OK this is an argument that it seems hard for most people

236
00:15:42,380 --> 00:15:46,600
that seems hard for most people to think

237
00:15:46,620 --> 00:15:48,370
right at the beginning

238
00:15:48,570 --> 00:15:54,270
which is really decide if you're doing an optimal detection it is optimal

239
00:15:54,290 --> 00:15:58,090
in other words anything else and you do was worse

240
00:15:58,100 --> 00:16:01,170
and you can always count on that they get

241
00:16:01,190 --> 00:16:06,110
you know its count on that to get bounds between probabilities of severity you get

242
00:16:06,110 --> 00:16:11,480
doing something stupid and probabilities of there that you get doing something intelligent and the

243
00:16:11,490 --> 00:16:13,580
stupid thing is not only stupid this

244
00:16:13,600 --> 00:16:18,670
i mean this stupid thing is sometimes better because it's cheaper but the air probability

245
00:16:18,670 --> 00:16:23,120
is always worse there than if you do the actual optimum

246
00:16:23,130 --> 00:16:24,430
OK so

247
00:16:24,440 --> 00:16:27,210
so people in fact often do

248
00:16:27,470 --> 00:16:34,380
detection where they have coded systems baby code each received symbol separately based on the

249
00:16:34,380 --> 00:16:36,700
corresponding observation

250
00:16:36,710 --> 00:16:41,920
they wind up with the larger probability than they should that it passes through

251
00:16:42,300 --> 00:16:44,270
some kind of

252
00:16:44,280 --> 00:16:47,180
some kind of error correction device

253
00:16:47,230 --> 00:16:50,040
and they wind up with the system before that

254
00:16:50,080 --> 00:16:52,250
the the sort of performs

255
00:16:52,260 --> 00:16:57,070
reasonably and you as well what it would have performed better

256
00:16:57,090 --> 00:16:59,320
if in fact what you did

257
00:16:59,540 --> 00:17:04,280
was the way to make the final decision into that all the data

258
00:17:04,300 --> 00:17:08,510
so we talk a little bit about various kinds of error control later when one

259
00:17:08,510 --> 00:17:10,140
million to wireless

260
00:17:10,160 --> 00:17:13,480
will see that some kinds of coding systems

261
00:17:13,490 --> 00:17:18,700
can behave very easily and can make use of all this extra information

262
00:17:18,710 --> 00:17:20,170
in other words can

263
00:17:20,220 --> 00:17:24,620
algebraic kinds of schemes can seem to make use of the information

264
00:17:26,220 --> 00:17:29,850
and various other kinds of schemes can make use of it

265
00:17:30,240 --> 00:17:34,580
and if you want to understand what's happened in the year correction field

266
00:17:35,440 --> 00:17:40,040
for the last five years twenty six four fifty one will be given free will

267
00:17:40,040 --> 00:17:42,080
get all the details of this

268
00:17:42,130 --> 00:17:46,860
but but the simplest ones sentence statement you can say i

269
00:17:46,880 --> 00:17:52,990
is that the world has changed from algebraic coding techniques the probabilistic decoding techniques

270
00:17:53,000 --> 00:17:58,080
and the primary reason for it is you want to make use of all that

271
00:17:58,080 --> 00:18:04,850
extra information you get from looking at the full observation rather than just partial observations

272
00:18:07,820 --> 00:18:11,600
now back to

273
00:18:11,620 --> 00:18:14,100
fact the various signal sets

274
00:18:14,110 --> 00:18:16,350
but this slide up last time

275
00:18:16,370 --> 00:18:19,860
i what really talk about it this time

276
00:18:20,090 --> 00:18:21,790
because for

277
00:18:21,790 --> 00:18:24,630
for each number of degrees of freedom

278
00:18:24,930 --> 00:18:28,880
you can define what's called an orthogonal codes

279
00:18:28,900 --> 00:18:33,190
and the orthogonal codes for n equals two fram equals three

280
00:18:33,190 --> 00:18:34,270
are now

281
00:18:34,310 --> 00:18:35,600
so that's easy to do

282
00:18:35,600 --> 00:18:38,270
but what if you want to be sure that this

283
00:18:38,280 --> 00:18:43,630
bit string that with very high probability is irreducible has very little pattern what if

284
00:18:43,630 --> 00:18:46,360
you want to be sure that this individual bits in the two got by this

285
00:18:46,360 --> 00:18:47,610
hundred thousand

286
00:18:47,630 --> 00:18:50,070
independent of the fair coin in fact

287
00:18:50,130 --> 00:18:51,730
has very little pattern

288
00:18:51,740 --> 00:18:57,010
well you know that it's essentially organically structure rather than random and the answer is

289
00:18:57,010 --> 00:18:59,940
even though with overwhelming probability this is true

290
00:18:59,950 --> 00:19:01,740
you can prove it

291
00:19:01,770 --> 00:19:04,530
you really you can prove in individual cases

292
00:19:04,560 --> 00:19:09,010
in individual cases so a little bit like quantum mechanics where you can say that

293
00:19:09,010 --> 00:19:14,240
you know the short question with probabilities so to statistical theory and if i look

294
00:19:14,240 --> 00:19:20,760
at individual atom i cannot predict whether it's going to be you know vision

295
00:19:20,890 --> 00:19:23,650
i can only calculate the probabilities

296
00:19:25,450 --> 00:19:28,900
here's an area of mathematics which behaves a little bit like

297
00:19:28,910 --> 00:19:32,690
even though something is true with very high probability i can't be sure an individual

298
00:19:32,690 --> 00:19:36,050
cases so i have statistical laws but i don't have

299
00:19:36,100 --> 00:19:39,010
i can determine individual cases what's what's happening

300
00:19:45,150 --> 00:19:47,190
i should

301
00:19:47,240 --> 00:19:49,380
probably a good time to

302
00:19:49,390 --> 00:19:53,690
stop and take questions or criticisms but let me just say what do i intend

303
00:19:53,690 --> 00:19:56,640
to do in the in the next lecture in the second half

304
00:19:56,670 --> 00:19:59,690
well it depends if you ask a lot of questions i'll try to explain things

305
00:19:59,690 --> 00:20:03,930
better all over again but if it does if the things haven't gone bad we

306
00:20:03,930 --> 00:20:07,770
would like to do in the second half of this morning is talk about an

307
00:20:07,770 --> 00:20:13,180
even better example of lack of pattern or lack of structure or and algorithmic randomness

308
00:20:13,180 --> 00:20:17,440
in pure mathematics and that's number called omega the halting probability

309
00:20:17,530 --> 00:20:21,520
and that's my best example of lack of structure or something that notable in pure

310
00:20:22,890 --> 00:20:27,600
i give you my one example now which was elegant programs

311
00:20:27,670 --> 00:20:29,550
they have no structure bits

312
00:20:29,610 --> 00:20:31,520
but i want to give you a better example

313
00:20:31,550 --> 00:20:35,780
and that we and i'd i like to talk about

314
00:20:35,800 --> 00:20:40,260
o briefly about some questions about his q like biologists like physics you know are

315
00:20:40,270 --> 00:20:44,700
more philosophical questions like that but how about i stop now and take questions or

316
00:20:44,700 --> 00:20:46,440
criticisms or

317
00:20:46,470 --> 00:20:48,570
comments or whatever

318
00:20:51,090 --> 00:20:51,990
you say

319
00:20:55,770 --> 00:20:58,470
OK the all of these

320
00:20:58,530 --> 00:21:00,240
the UK

321
00:21:03,230 --> 00:21:06,940
on the

322
00:21:15,020 --> 00:21:16,530
the problem with

323
00:21:16,560 --> 00:21:18,440
so we

324
00:21:18,450 --> 00:21:22,430
small stream is going to be taken

325
00:21:22,440 --> 00:21:24,770
a program can hold

326
00:21:29,720 --> 00:21:31,940
because we can

327
00:21:37,650 --> 00:21:42,350
yes it's all connected it's all connected i agree

328
00:21:43,360 --> 00:21:46,350
so i think

329
00:21:46,360 --> 00:21:54,800
this is an information theoretic version of terms of the problem

330
00:21:54,820 --> 00:21:56,180
in the way

331
00:21:56,190 --> 00:21:57,630
that's the connectives

332
00:21:57,630 --> 00:22:01,480
the difference is that here you have the idea of looking at the size of

333
00:22:01,480 --> 00:22:02,530
the program

334
00:22:02,560 --> 00:22:05,020
and you don't do that in terms of general formulation

335
00:22:05,050 --> 00:22:07,470
but they're very strongly coupled

336
00:22:07,510 --> 00:22:08,220
i agree

337
00:22:28,730 --> 00:22:31,440
and you

338
00:22:44,560 --> 00:22:46,350
you want

339
00:23:06,820 --> 00:23:08,230
there is some connection

340
00:23:08,240 --> 00:23:10,890
as you point out because

341
00:23:10,910 --> 00:23:15,770
you're talking about a system

342
00:23:16,860 --> 00:23:21,890
r cannot be explained in the simplest system where you're getting complexity

343
00:23:21,940 --> 00:23:25,340
so in that sense what i'm doing is exactly the same thing

344
00:23:25,390 --> 00:23:30,470
but not really exactly the same because to prove theorems

345
00:23:30,510 --> 00:23:34,780
i deal with the grams and the size of programs and this is a very

346
00:23:37,020 --> 00:23:39,740
o thing but i can prove results now

347
00:23:39,760 --> 00:23:43,730
i don't know how to apply these ideas to the real world

348
00:23:44,520 --> 00:23:46,150
you know

349
00:23:46,170 --> 00:23:50,700
if you talk about biological complexity for example or emergence OF complexity about complexity of

350
00:23:50,700 --> 00:23:56,640
economic systems and complexity of social systems complex psychological complexity and these are all wonderful

351
00:23:56,640 --> 00:24:00,090
things and i agree the important to understand

352
00:24:00,140 --> 00:24:04,850
but i do not definitely do not claim that these ideas

353
00:24:04,850 --> 00:24:06,800
this notion of complexity

354
00:24:06,810 --> 00:24:10,490
that i've given here the size in bits of the program

355
00:24:11,390 --> 00:24:15,450
works very well in pure mathematics or metamathematics but i don't think it's the right

356
00:24:15,450 --> 00:24:21,360
notion from biology you know from looking at ants were looking human society or human

357
00:24:22,810 --> 00:24:26,990
you know my it's this is a very theoretical notion of complexity and that's why

358
00:24:26,990 --> 00:24:28,670
i can prove theorems

359
00:24:28,680 --> 00:24:32,440
now it seems to me that four different domains you probably need to have more

360
00:24:32,440 --> 00:24:36,670
practical notion of complexity that applies in that domain and one of the things you'd

361
00:24:36,680 --> 00:24:40,350
like it might be able to calculate the complexity in theory

362
00:24:40,380 --> 00:24:43,610
you know my notion of complexity i can never calculate what it is you say

363
00:24:45,180 --> 00:24:48,630
so i should apologize and say that i think this theory may be pretty but

364
00:24:48,630 --> 00:24:52,170
it limited in its domain of applicability

365
00:24:52,190 --> 00:24:55,230
i have to be honest about that this is not a theory of all possible

366
00:24:55,230 --> 00:24:58,680
the new memories go in the same hardware this using for everything else

367
00:25:00,990 --> 00:25:01,550
we don't know how

368
00:25:02,820 --> 00:25:04,090
they're stored in the same hardware

369
00:25:07,200 --> 00:25:08,230
andy importantly

370
00:25:13,550 --> 00:25:15,510
that brains are robust hardware

371
00:25:17,510 --> 00:25:18,850
so you can take a pigeon brain

372
00:25:19,280 --> 00:25:21,200
we can take your brain and you can damage

373
00:25:21,760 --> 00:25:24,160
many thousands of your neurons and you still

374
00:25:24,570 --> 00:25:25,100
the following day

375
00:25:25,850 --> 00:25:29,010
current functioning okay you do this whenever you drink alcohol

376
00:25:30,110 --> 00:25:32,890
you you kill of neurons but you still keep going

377
00:25:34,550 --> 00:25:38,610
craig in contrast if you reach into it and say well going destroy one per

378
00:25:38,610 --> 00:25:42,960
cent of the transistors in this craig is can refine isn't it you find that

379
00:25:42,960 --> 00:25:44,430
it is not fine

380
00:25:47,000 --> 00:25:48,080
here's the hypothesis

381
00:25:48,640 --> 00:25:49,720
the hypothesis is

382
00:25:54,950 --> 00:25:59,330
the difference in the performance of the pigeon and the craig on this sort of realistic

383
00:26:00,450 --> 00:26:02,290
real world image recognition task

384
00:26:04,650 --> 00:26:07,120
because a very difference in style of computation

385
00:26:10,160 --> 00:26:11,790
maybe the style computation

386
00:26:14,970 --> 00:26:15,320
is the key

387
00:26:19,240 --> 00:26:22,810
so maybe we should be getting away from serial if we are excited about being

388
00:26:22,810 --> 00:26:25,350
able to solve problems that computers are still useless at

389
00:26:25,930 --> 00:26:28,590
and maybe we should be going to genuinely parallel

390
00:26:30,660 --> 00:26:35,700
maybe we should be looking at ways of using hardware that you have high conductivity distributed

391
00:26:36,220 --> 00:26:37,610
and work in a completely different way

392
00:26:40,860 --> 00:26:45,170
so in the next lecture we will come back to the task of storing and

393
00:26:45,170 --> 00:26:48,240
recalling memories and will show a way of doing it

394
00:26:50,170 --> 00:26:51,420
with a simple neural network model

395
00:26:54,620 --> 00:26:55,780
i've just given you eh

396
00:26:56,520 --> 00:26:59,860
fifteen minutes motivation for why we should be interested in

397
00:27:00,450 --> 00:27:06,130
parallel distributed processing which is the name of one of the old bible the neural networks

398
00:27:16,910 --> 00:27:20,260
anderson parallel distributed processing and talk about is

399
00:27:21,670 --> 00:27:23,710
parallel-distributed-processing using

400
00:27:25,230 --> 00:27:27,710
elementary devices that will call neurons

401
00:27:28,860 --> 00:27:29,950
so we can have a single neuron

402
00:27:33,260 --> 00:27:34,910
which is gonna be a thing that has the inputs

403
00:27:38,360 --> 00:27:39,040
and output

404
00:27:40,150 --> 00:27:42,260
and then we're going to why them up in a variety of ways

405
00:27:48,520 --> 00:27:51,590
one way wiring them up is feedforward

406
00:27:56,060 --> 00:27:58,930
which looks like this do have some inputs going in

407
00:28:01,990 --> 00:28:02,690
some neurons

408
00:28:03,850 --> 00:28:05,550
and then they connect small neurons

409
00:28:06,140 --> 00:28:08,710
we can put arrows on these edges which way things go

410
00:28:11,970 --> 00:28:13,470
and then we have another neuron

411
00:28:13,960 --> 00:28:14,860
and then something comes out

412
00:28:15,520 --> 00:28:17,100
so that's a forward

413
00:28:19,280 --> 00:28:25,070
it's simple to describe because it's sort of deterministic just but in input these guys can compete these can

414
00:28:25,750 --> 00:28:28,080
compute is can compute and then up

415
00:28:30,270 --> 00:28:34,200
another way wiring these things up would be a feedback network where you say

416
00:28:35,300 --> 00:28:35,760
let's allow

417
00:28:37,120 --> 00:28:38,270
everyone outputs

418
00:28:39,370 --> 00:28:39,570
to be

419
00:28:40,910 --> 00:28:42,150
everyone else's inputs

420
00:28:49,400 --> 00:28:49,830
what about

421
00:28:52,610 --> 00:28:52,980
and then

422
00:28:53,520 --> 00:28:55,880
and the dynamics depend on exactly how you define

423
00:28:56,310 --> 00:28:56,500
the way

424
00:28:57,130 --> 00:28:58,690
all the neurons interact

425
00:28:59,350 --> 00:29:01,170
and maybe something more exciting happens

426
00:29:04,670 --> 00:29:06,880
let's tell you a bit more about the single neuron

427
00:29:07,470 --> 00:29:07,760
and then

428
00:29:08,320 --> 00:29:10,490
for today's lecture i'll talk to you about

429
00:29:12,210 --> 00:29:13,220
feedforward networks

430
00:29:15,260 --> 00:29:17,630
and the next lecture will look at feedback

431
00:29:41,140 --> 00:29:42,040
so here's how they

432
00:29:42,990 --> 00:29:44,170
single neuron works

433
00:29:46,390 --> 00:29:47,980
single neurons got inputs

434
00:29:48,460 --> 00:29:49,110
the output

435
00:29:54,150 --> 00:29:55,760
hand it's got some parameters

436
00:29:57,730 --> 00:29:59,560
and the parameters are commonly called

437
00:30:05,210 --> 00:30:08,600
and the parameters learned here between the inputs can be

438
00:30:09,000 --> 00:30:10,180
multi neuron

439
00:30:11,300 --> 00:30:12,890
and his works is very simple

440
00:30:14,500 --> 00:30:17,250
if the weights are w one w two

441
00:30:17,930 --> 00:30:18,960
not w

442
00:30:20,650 --> 00:30:21,560
and if the inputs are

443
00:30:27,070 --> 00:30:30,470
what the neuron does is it adds up though in weighted

444
00:30:31,150 --> 00:30:32,460
some of its inputs

445
00:30:33,340 --> 00:30:34,380
using its own weights

446
00:30:34,380 --> 00:30:37,890
in our case only twenty

447
00:30:40,260 --> 00:30:46,220
now some results for the in competition so just these results are going to be

448
00:30:46,230 --> 00:30:51,840
preliminary since the official results but i just want to give you some impression of

449
00:30:51,850 --> 00:30:53,630
this looks like

450
00:30:53,830 --> 00:30:55,870
so it

451
00:30:55,890 --> 00:31:00,160
their control competition conditions so there

452
00:31:00,180 --> 00:31:06,020
they took the c elegans genome and took only ten percent of the genome for

453
00:31:06,020 --> 00:31:10,230
training so they allowed only i mean they find what the training set is going

454
00:31:10,230 --> 00:31:13,960
to be in the test set is going to be so this was ten percent

455
00:31:14,090 --> 00:31:20,820
training ten percent for testing two cases one is a single predictions and then combining

456
00:31:20,820 --> 00:31:27,010
predictions so combine and combine the predictions of seventeen i'm try to find a consensus

457
00:31:27,010 --> 00:31:29,680
between seventeen typically

458
00:31:29,700 --> 00:31:31,410
i mean there

459
00:31:33,050 --> 00:31:38,670
but i haven't seen the results this just so that four categories one subunit two

460
00:31:38,670 --> 00:31:41,420
gene finding this what have survived

461
00:31:41,470 --> 00:31:47,930
then there is another category which can use other genome and see how much

462
00:31:47,990 --> 00:31:53,200
certain sequence part arkansas so if something is concerned this usually means it

463
00:31:53,220 --> 00:31:57,040
function and functional is probably part of x

464
00:31:57,060 --> 00:32:02,040
so this gives you some additional information on the gene finding

465
00:32:02,200 --> 00:32:03,420
OK so

466
00:32:03,470 --> 00:32:06,430
families can use

467
00:32:06,480 --> 00:32:15,380
sequences which provided and down this last category which can use any kind of relation

468
00:32:15,390 --> 00:32:19,760
OK so let me just show you walk everyone briefly

469
00:32:19,770 --> 00:32:24,990
so there are three evaluation category one is on the nucleotide level so we look

470
00:32:25,130 --> 00:32:29,320
nucleotide all this would classified right

471
00:32:29,570 --> 00:32:31,740
x x one in four orientations

472
00:32:32,770 --> 00:32:38,790
and we get like our system is called in team and we get the highest

473
00:32:38,790 --> 00:32:41,280
accuracy on the

474
00:32:41,330 --> 00:32:44,440
the difference and on the here but there no

475
00:32:44,450 --> 00:32:45,850
so much room

476
00:32:47,690 --> 00:32:52,120
so in this escorting excellent so we count on

477
00:32:52,140 --> 00:32:56,140
x the harmony express that identify correctly

478
00:32:56,870 --> 00:33:02,760
and the last four years on the front of many genes already transcripts have been

479
00:33:02,760 --> 00:33:04,710
predicted completely correct

480
00:33:04,750 --> 00:33:10,120
so what you see here is different systems and

481
00:33:10,140 --> 00:33:10,980
i mean

482
00:33:11,030 --> 00:33:16,560
our system was like version zero one version one wasn't really i mean almost ready

483
00:33:16,560 --> 00:33:22,730
to be submitted something so quite successful so we got the best result in a

484
00:33:22,730 --> 00:33:28,640
nuclear level according level but that's the levels of other systems

485
00:33:28,650 --> 00:33:29,980
and really

486
00:33:30,000 --> 00:33:35,170
later figure out this is spring this is due to the definition of the loss

487
00:33:35,210 --> 00:33:40,950
so we only had to incorporate incorporated losses on look at at heights and exons

488
00:33:40,950 --> 00:33:43,240
but not on the front

489
00:33:43,420 --> 00:33:47,770
and what you see is actually transcript of of of this is due to the

490
00:33:52,240 --> 00:33:57,490
there are some other the other category that uses conservation interesting

491
00:33:59,130 --> 00:34:03,700
the average performance in the category is actually worse than they had one even though

492
00:34:03,700 --> 00:34:09,860
it uses more information the average among the other so all the was slightly better

493
00:34:09,930 --> 00:34:12,770
than the category but the others here

494
00:34:12,780 --> 00:34:18,350
actually we're encountering one

495
00:34:18,370 --> 00:34:25,160
and the last one that uses some sequence information they can on

496
00:34:28,080 --> 00:34:29,140
OK so

497
00:34:29,270 --> 00:34:34,970
i discussed already so it's good on the nucleotide excision level suboptimal on the front

498
00:34:35,060 --> 00:34:38,920
level and the reason was that genes will converge

499
00:34:38,930 --> 00:34:43,380
so and this was because that's what i think

500
00:34:45,970 --> 00:34:48,480
there's some possible improvements

501
00:34:48,540 --> 00:34:53,210
we call over this would like to mention that typically

502
00:34:53,220 --> 00:34:56,780
nineteen prediction isn't as easy so we don't know exactly what i mean there might

503
00:34:56,780 --> 00:35:04,420
be several ways of splicing points for starting gene so this actually transcription one like

504
00:35:05,720 --> 00:35:10,740
and and in a few cases it might be that you have to click here

505
00:35:10,860 --> 00:35:14,150
except that in the middle there might be several very

506
00:35:14,150 --> 00:35:15,780
delta v

507
00:35:16,000 --> 00:35:17,640
cool three of five

508
00:35:17,650 --> 00:35:20,190
thank you all for your time

509
00:35:20,340 --> 00:35:21,640
and this one

510
00:35:21,680 --> 00:35:23,540
is often called

511
00:35:23,640 --> 00:35:25,490
there data is a cubicle

512
00:35:25,510 --> 00:35:28,970
expansion coefficient as opposed to the linear one

513
00:35:29,130 --> 00:35:30,930
so you will say well big deal

514
00:35:30,990 --> 00:35:35,050
BYU talking about data because if we have the values for all five

515
00:35:35,070 --> 00:35:37,490
all we have to do is we go to the volume

516
00:35:37,550 --> 00:35:38,690
to make that

517
00:35:38,740 --> 00:35:41,880
beta three all fine we're in business

518
00:35:41,880 --> 00:35:43,450
well we have liquids

519
00:35:43,510 --> 00:35:47,430
in general you don't find in the table values of

520
00:35:47,530 --> 00:35:52,110
so when you deal with liquid for instance mercury

521
00:35:52,110 --> 00:35:53,430
is one

522
00:35:53,450 --> 00:35:55,670
i want to use today

523
00:35:55,760 --> 00:35:56,860
then you find

524
00:35:56,860 --> 00:35:57,740
that the

525
00:35:57,740 --> 00:36:01,200
cubic expansion coefficient eighteen

526
00:36:01,220 --> 00:36:03,900
times ten to the minus five

527
00:36:03,950 --> 00:36:06,880
degrees centigrade

528
00:36:06,920 --> 00:36:10,190
by compared with pyrex

529
00:36:10,200 --> 00:36:13,340
you have to take three times this value

530
00:36:13,360 --> 00:36:17,550
so it's very roughly ten to the minus five

531
00:36:17,550 --> 00:36:22,240
o degrees centigrade

532
00:36:22,280 --> 00:36:23,170
so now

533
00:36:23,190 --> 00:36:25,360
you begin to smell the ideas

534
00:36:25,490 --> 00:36:27,630
of the mercury

535
00:36:31,220 --> 00:36:33,130
i put to mercury

536
00:36:33,130 --> 00:36:35,360
in pyrex glass

537
00:36:35,380 --> 00:36:39,070
and the pyrex glass is not going to explain very much

538
00:36:39,110 --> 00:36:42,420
mercury real

539
00:36:42,470 --> 00:36:44,110
and the mercury

540
00:36:44,130 --> 00:36:46,650
which is in an enclosed environment

541
00:36:46,700 --> 00:36:48,510
we have to expand

542
00:36:48,590 --> 00:36:51,570
and it expands into my thermometer

543
00:36:51,570 --> 00:36:53,090
and that's the way

544
00:36:53,320 --> 00:36:58,240
we read the temperature

545
00:36:58,260 --> 00:37:04,450
so here is the glass two which is very very narrow

546
00:37:04,490 --> 00:37:06,340
this is close here

547
00:37:06,400 --> 00:37:08,490
that's a really is here

548
00:37:08,510 --> 00:37:12,090
it is only o point one millimeter

549
00:37:12,170 --> 00:37:16,340
here is the reservoir

550
00:37:18,470 --> 00:37:20,220
mister working example

551
00:37:20,280 --> 00:37:22,150
and suppose we take

552
00:37:22,240 --> 00:37:24,070
one cubic centimeter

553
00:37:24,150 --> 00:37:25,420
the simple numbers

554
00:37:25,470 --> 00:37:26,780
i just want to show you the

555
00:37:26,840 --> 00:37:29,950
the basic idea behind the summer

556
00:37:29,990 --> 00:37:32,740
i'm going to increase the temperature of this

557
00:37:34,150 --> 00:37:36,650
say by ten degrees

558
00:37:36,780 --> 00:37:38,240
delta t

559
00:37:38,280 --> 00:37:42,420
then degrees centigrade

560
00:37:42,550 --> 00:37:43,970
so how much will this

561
00:37:43,990 --> 00:37:46,920
volume expension delta

562
00:37:47,050 --> 00:37:50,070
because beta

563
00:37:50,090 --> 00:37:52,530
eighteen times ten to the minus fit

564
00:37:54,060 --> 00:37:58,050
times the volume which is one cubic centimeter let me just put the volume in

565
00:37:58,050 --> 00:38:01,200
there you may want to do it in cubic metres only for the u

566
00:38:01,320 --> 00:38:02,610
times the delta t

567
00:38:02,650 --> 00:38:05,740
you'll find

568
00:38:05,740 --> 00:38:08,990
the expansion in terms of cubic centimeters

569
00:38:09,050 --> 00:38:10,450
is o point

570
00:38:10,470 --> 00:38:14,170
o one eight

571
00:38:14,190 --> 00:38:15,930
cubic centimeters

572
00:38:15,990 --> 00:38:18,030
three in cubic centimetres

573
00:38:18,050 --> 00:38:18,880
what you can do

574
00:38:18,950 --> 00:38:22,380
you get your answer also argued that if you do not always

575
00:38:22,420 --> 00:38:26,090
work after work and KS

576
00:38:26,130 --> 00:38:30,920
so it is is extraordinarily small increase in terms of volume

577
00:38:32,110 --> 00:38:33,450
the pyrex

578
00:38:33,530 --> 00:38:36,700
it's not expanding at all you can just forget that for now

579
00:38:36,720 --> 00:38:41,050
you want to calculate how much it is it's fine but is eighty times less

580
00:38:41,110 --> 00:38:43,700
so the fact that the vessel get the larger

581
00:38:43,720 --> 00:38:47,240
of course is important but i will just ignore that for now

582
00:38:47,340 --> 00:38:49,920
so i'll just assume that all these mercury

583
00:38:49,950 --> 00:38:52,860
will be driven up here

584
00:38:52,860 --> 00:38:54,590
and so if the mercury then

585
00:38:54,610 --> 00:38:56,720
changes its height

586
00:38:56,720 --> 00:38:58,920
by an amount delta h

587
00:38:58,920 --> 00:39:03,240
and if this is a tool with the radius point one millimetres

588
00:39:03,240 --> 00:39:08,970
and this amount of mercury must be the same as by are screened

589
00:39:08,990 --> 00:39:10,220
i fell for age

590
00:39:10,280 --> 00:39:12,320
which is the volume

591
00:39:12,340 --> 00:39:16,070
of the new colony increase in the column

592
00:39:16,070 --> 00:39:17,300
so you

593
00:39:17,360 --> 00:39:20,400
i take your point one millimetres

594
00:39:20,450 --> 00:39:23,430
and you'll find the delta h

595
00:39:23,450 --> 00:39:25,930
for this example that i chose

596
00:39:27,320 --> 00:39:30,280
five point seven centimetres

597
00:39:32,240 --> 00:39:33,990
that's a huge

598
00:39:34,150 --> 00:39:39,450
it's very easy to see for ten cents ten degrees centigrade in increasing temperature gets

599
00:39:39,450 --> 00:39:41,100
where else OK so

600
00:39:41,130 --> 00:39:43,270
one thing that's kind of starting to

601
00:39:43,270 --> 00:39:44,760
kind of

602
00:39:44,810 --> 00:39:47,220
matter which kind of conceit

603
00:39:47,280 --> 00:39:53,020
parents so let's call children as the descendants parents because of

604
00:39:53,070 --> 00:39:56,580
parents kind of mass there's an important

605
00:39:56,600 --> 00:39:58,530
children are are important

606
00:39:58,540 --> 00:39:59,640
they have the

607
00:39:59,690 --> 00:40:05,150
child parent is also important

608
00:40:05,160 --> 00:40:09,960
when you put all this together you get something called the markov blanket

609
00:40:10,690 --> 00:40:12,230
is a graphical model

610
00:40:12,270 --> 00:40:14,390
there was

611
00:40:14,390 --> 00:40:16,790
popularized but you apparel

612
00:40:16,810 --> 00:40:20,430
and later

613
00:40:20,530 --> 00:40:25,570
again the nodes are unbearable theatres indicate

614
00:40:25,620 --> 00:40:27,450
link causation

615
00:40:27,460 --> 00:40:30,530
quotation marks because it's not a causation

616
00:40:30,580 --> 00:40:33,040
OK so

617
00:40:33,090 --> 00:40:36,520
you know aliens come to earth the founders this device

618
00:40:36,520 --> 00:40:37,830
the device

619
00:40:37,840 --> 00:40:43,190
points in one direction to follow this direction and find the polar bear

620
00:40:45,440 --> 00:40:50,520
and then they repeat this experiment ninety percent ninety seven point eight percent of the

621
00:40:50,520 --> 00:40:53,980
times they followed this arrow define the polar bear

622
00:40:54,000 --> 00:40:57,070
and they concluded this is the full of air indicator

623
00:40:58,570 --> 00:41:02,980
correlations is not causation

624
00:41:05,340 --> 00:41:08,590
the device being in all the point

625
00:41:12,370 --> 00:41:14,980
the the semantic search we will have this

626
00:41:15,020 --> 00:41:18,970
that your variable will depend will be

627
00:41:18,980 --> 00:41:21,270
independent of the ancestors

628
00:41:21,280 --> 00:41:23,760
given the parent so-called

629
00:41:23,770 --> 00:41:24,960
given alarm

630
00:41:24,960 --> 00:41:26,270
using that

631
00:41:26,330 --> 00:41:30,330
it will be independent of all these variables

632
00:41:30,390 --> 00:41:33,570
if you know

633
00:41:33,620 --> 00:41:36,960
again there's of the situation is there's

634
00:41:37,000 --> 00:41:40,310
an earthquake recording you're driving home

635
00:41:40,320 --> 00:41:43,570
and in order to know whether an earthquake well you switch on the radio to

636
00:41:43,570 --> 00:41:44,720
know whether this

637
00:41:44,750 --> 00:41:47,770
the radio announcing an earthquake in l a or not

638
00:41:48,600 --> 00:41:51,630
if the alarm burglary goes off in your home

639
00:41:51,680 --> 00:41:53,900
and it calls yourself

640
00:41:54,130 --> 00:41:58,830
you get large so you also know that there's a chance that it could be

641
00:41:58,980 --> 00:42:03,080
so the alarm on your cell phone could either because because there was an earthquake

642
00:42:03,200 --> 00:42:06,980
the house shakes well because of the comes in

643
00:42:07,030 --> 00:42:09,970
and based on the alarm you gonna cell phone call

644
00:42:09,980 --> 00:42:12,980
and what you are trying to establish here is

645
00:42:13,020 --> 00:42:14,410
what's going on

646
00:42:14,460 --> 00:42:17,190
OK when when you receive this call

647
00:42:17,200 --> 00:42:19,000
OK so you receive this call

648
00:42:21,100 --> 00:42:23,330
so we can see this case

649
00:42:23,710 --> 00:42:26,830
the one case arising without knowing

650
00:42:26,840 --> 00:42:28,710
the status of the radio

651
00:42:28,770 --> 00:42:32,000
it would help you know there's an earthquake or burglary

652
00:42:32,030 --> 00:42:34,890
OK because if you switch on the radio

653
00:42:34,960 --> 00:42:38,700
and it tells you yes there's been an earthquake then you're kind of

654
00:42:40,190 --> 00:42:43,000
burglary is less problem

655
00:42:43,020 --> 00:42:44,270
so in particular

656
00:42:44,310 --> 00:42:45,770
suppose you have call

657
00:42:45,780 --> 00:42:48,600
so you shade shaded very with indicative of call

658
00:42:49,540 --> 00:42:55,520
we're computing the probabilities for doing inference here we just think the marginalisation task

659
00:42:55,530 --> 00:42:58,350
computing the probability of an earthquake

660
00:42:59,260 --> 00:43:03,270
that you've received a call the probability that the earthquake is true

661
00:43:03,310 --> 00:43:06,400
given that the you've received a call call true

662
00:43:06,410 --> 00:43:10,200
and in addition you might have their point one here and

663
00:43:10,210 --> 00:43:14,230
and you might have the probability of burglary being true beings are point seven because

664
00:43:14,230 --> 00:43:17,260
after all this is a like rather

665
00:43:18,130 --> 00:43:20,300
there's my brother is an earthquake

666
00:43:20,340 --> 00:43:23,500
so this is your prior status of the world then you serve

667
00:43:23,510 --> 00:43:25,930
the variable radio

668
00:43:25,940 --> 00:43:28,420
OK and the radio station

669
00:43:28,480 --> 00:43:30,470
everybody knows

670
00:43:30,490 --> 00:43:34,080
do whatever you can do this if you like there's an earthquake

671
00:43:34,160 --> 00:43:36,830
and based on that

672
00:43:38,300 --> 00:43:40,440
here we compute this probability

673
00:43:40,450 --> 00:43:43,590
the probability of an earthquake now that given that there was

674
00:43:43,630 --> 00:43:48,000
he received a call and given that the radio confirmed that there was an earthquake

675
00:43:48,050 --> 00:43:50,820
that goes to point ninety seven

676
00:43:50,860 --> 00:43:52,900
and that goes to o point one

677
00:43:52,950 --> 00:43:56,100
and i guess the reason why stochastic and it doesn't go to one is because

678
00:43:56,100 --> 00:43:58,720
the things might

679
00:43:59,100 --> 00:44:04,490
have hope their devices into the radio so that they could

680
00:44:04,500 --> 00:44:07,230
tamper with your home

681
00:44:07,280 --> 00:44:09,660
and this is called the sort of explaining away

682
00:44:09,670 --> 00:44:12,550
effect on seattle variable

683
00:44:12,630 --> 00:44:15,930
and that's what it's all about graphical models because you

684
00:44:15,970 --> 00:44:17,780
you will get this

685
00:44:18,180 --> 00:44:28,290
you will get the whole lecture on this next week

686
00:44:28,330 --> 00:44:47,220
and i need to go back to wonder cargo

687
00:44:49,550 --> 00:44:53,700
by the way if there's anything that's not clear which if any of these operations

688
00:44:53,700 --> 00:45:01,500
so it's not completely convincing that we really made any progress but the fact is

689
00:45:01,520 --> 00:45:06,120
we have by expanding i will beyond plain all repetition as a way of any

690
00:45:06,120 --> 00:45:11,390
redundancy we've got the error probability into places it couldn't get to before

691
00:45:12,500 --> 00:45:14,710
the next slide is going to show you

692
00:45:14,810 --> 00:45:16,520
where you can get to by

693
00:45:16,520 --> 00:45:19,120
inventing more block codes

694
00:45:20,790 --> 00:45:24,810
i'm not going to tell you your main homework problem for tonight you may homework

695
00:45:24,810 --> 00:45:29,890
problem is to invent another block code and the decoder for it and and added

696
00:45:29,910 --> 00:45:31,430
to this diagram

697
00:45:32,470 --> 00:45:34,950
invent a code

698
00:45:35,000 --> 00:45:40,230
the decoder

699
00:45:40,270 --> 00:45:44,270
work out what is our is

700
00:45:44,290 --> 00:45:49,660
and look at what is the probability that error work that

701
00:45:49,680 --> 00:45:51,250
and added to the diagram

702
00:45:51,330 --> 00:45:58,770
so that's a fun homework problem for you

703
00:45:59,370 --> 00:46:02,310
and these pluses shows where

704
00:46:02,330 --> 00:46:05,660
people have got to with a whole bunch of codes you can find in textbooks

705
00:46:05,660 --> 00:46:10,350
on coding theory the written in the sixties seventies and eighties and you can see

706
00:46:10,700 --> 00:46:12,560
all of those policies

707
00:46:12,560 --> 00:46:16,600
are to the right of way can get to with repetition codes remember where we

708
00:46:16,600 --> 00:46:21,480
want to be is lower probability and largest possible rate so this arrow showing where

709
00:46:21,480 --> 00:46:25,060
we want to get we like being in the bottom right-hand corner we'd love to

710
00:46:25,060 --> 00:46:29,660
have a coat with a huge rate like one and the probability of zero which

711
00:46:29,770 --> 00:46:31,310
log scale way down here

712
00:46:31,370 --> 00:46:32,850
we love this

713
00:46:32,870 --> 00:46:34,870
we don't like that

714
00:46:36,790 --> 00:46:39,680
OK this is the linear scale

715
00:46:39,730 --> 00:46:46,480
this is a log scale identical graphs but just on the right ones log scale

716
00:46:46,520 --> 00:46:48,500
OK so that's your homework problem

717
00:46:50,360 --> 00:46:54,190
the obvious question that this diagram is now raising who reason this exciting we can

718
00:46:54,190 --> 00:46:58,640
do better than repetition codes well how good can it get where can we get

719
00:46:59,400 --> 00:47:03,410
by being clever where we get to by generalizing the seven four hamming code and

720
00:47:03,410 --> 00:47:07,360
coming up with other ideas and you can see just vague sort of scatter of

721
00:47:07,360 --> 00:47:08,790
points and no

722
00:47:08,810 --> 00:47:13,030
a clear indication of where we can get but you might imagine

723
00:47:13,040 --> 00:47:17,430
but the answer to this question where is the boundary what's achievable

724
00:47:17,440 --> 00:47:19,640
where the boundary between achievable

725
00:47:19,650 --> 00:47:23,070
and knowledge she will point you might imagine that the answer to that question is

726
00:47:23,440 --> 00:47:26,970
well surely it's line of some sort

727
00:47:27,020 --> 00:47:29,700
the goes through the origin

728
00:47:33,070 --> 00:47:34,370
so maybe

729
00:47:34,450 --> 00:47:36,440
the question marks

730
00:47:37,820 --> 00:47:39,750
the boundary look something like this

731
00:47:39,770 --> 00:47:46,690
because that's what solves law would say would say you can't get something for nothing

732
00:47:46,690 --> 00:47:50,820
if you want the error probability to get lower and lower and lower you will

733
00:47:50,820 --> 00:47:55,900
be forced by this boundary to have rate the gets lower and lower as well

734
00:47:55,900 --> 00:47:59,430
that certainly is consistent with what happens with the repetition codes if you want to

735
00:47:59,430 --> 00:48:02,780
get the error probability down to the minors fifteen the rate had to go away

736
00:48:02,780 --> 00:48:06,700
down here if you wanted to get ten to the minus fifty the rate would

737
00:48:06,700 --> 00:48:11,660
have to get even lower so be push towards their that sort law that's the

738
00:48:11,660 --> 00:48:15,850
way normal life is you you want something really really good you have to pay

739
00:48:15,850 --> 00:48:21,140
for it and here the units you pay and with be rate and before

740
00:48:21,150 --> 00:48:26,860
shannon came along and i'm sure everyone in the field of communication imagine this was

741
00:48:26,860 --> 00:48:30,400
the case that the boundary between achievable

742
00:48:30,540 --> 00:48:38,440
and not achievable points

743
00:48:38,500 --> 00:48:42,070
it it was some sort of line

744
00:48:42,080 --> 00:48:43,480
going through the origin

745
00:48:43,480 --> 00:48:47,080
here is the most exciting results of the twentieth century

746
00:48:47,110 --> 00:48:51,440
the most exciting result is the boundary between achievable

747
00:48:51,490 --> 00:48:54,390
and ninety four points does not go through the origin

748
00:48:54,400 --> 00:48:57,230
it comes down here

749
00:49:00,870 --> 00:49:02,740
makes this axis

750
00:49:02,750 --> 00:49:04,740
at a non-zero value

751
00:49:04,790 --> 00:49:09,020
which is the property of the channel working with this property called the capacity of

752
00:49:09,020 --> 00:49:10,030
the channel

753
00:49:11,060 --> 00:49:13,030
is saying that

754
00:49:13,040 --> 00:49:17,540
it's possible to get the error probability as small as you like

755
00:49:17,570 --> 00:49:20,330
you get it down to ten five fifteen

756
00:49:20,360 --> 00:49:24,240
what defines eighteen or five fifty or as small as you want all

757
00:49:24,240 --> 00:49:28,820
at big rates and for this particular channel that we've been discussing today

758
00:49:28,820 --> 00:49:32,250
which bought move on to now have lost track

759
00:49:32,350 --> 00:49:33,930
it is

760
00:49:33,940 --> 00:49:40,600
so this binary symmetric channel

761
00:49:40,610 --> 00:49:43,030
the capacity is about half

762
00:49:48,040 --> 00:49:57,120
that's a tiny bit bigger

763
00:49:57,140 --> 00:50:01,820
and here's the formula for it is expressed in terms of the binary entropy function

764
00:50:01,830 --> 00:50:03,150
what does this mean

765
00:50:03,160 --> 00:50:08,320
this means a stunning fact it means that if you've got a totally lousy destroyed

766
00:50:08,350 --> 00:50:10,820
the flipping ten percent of the bits

767
00:50:10,820 --> 00:50:15,780
there exists an encoding and decoding system you can wrap around this this right such

768
00:50:15,780 --> 00:50:19,280
that if you just hide two describes inbox

769
00:50:20,070 --> 00:50:23,660
meaning that be working at a rate of one half

770
00:50:24,100 --> 00:50:27,890
which is below capacity you can get there probably down ten minus eighteen

771
00:50:27,890 --> 00:50:29,140
no problem

772
00:50:29,330 --> 00:50:32,890
down to ten to fifty to one hundred it's possible

773
00:50:32,930 --> 00:50:36,120
and all you need is to distracting in the box

774
00:50:42,370 --> 00:50:49,570
so that's a topic for another lecture so the the question is what's the complexity

775
00:50:49,600 --> 00:50:52,740
what i'm telling you is the theorem says there

776
00:50:52,740 --> 00:50:54,610
there exists an encoder

777
00:50:54,640 --> 00:50:57,640
the details

778
00:50:57,690 --> 00:51:00,950
you can slap around the channel

779
00:51:00,980 --> 00:51:05,410
and you can achieve any point on this diagram

780
00:51:05,430 --> 00:51:07,980
the theorem just says it exists

781
00:51:08,030 --> 00:51:12,530
and it's a very cheeky theorem because the proof is nonconstructive just says it exists

782
00:51:12,530 --> 00:51:18,390
because of

783
00:55:20,810 --> 00:55:28,300
what going

784
00:55:28,430 --> 00:55:31,750
you know

785
00:56:12,240 --> 00:56:14,260
or or

786
00:57:16,380 --> 00:57:25,070
i mean

787
00:57:46,370 --> 00:57:52,870
a four

788
00:59:20,180 --> 00:59:22,530
the reason

789
00:59:26,880 --> 00:59:31,180
i get

790
00:59:31,180 --> 00:59:36,600
i'm quickly going through these two examples supervised classification anomaly detection outlier detection in the

791
00:59:36,600 --> 00:59:40,550
talk after this dave weston is going to give you a detailed examination of the

792
00:59:40,550 --> 00:59:44,820
same name class of methods that we've been looking at computer analysis but he's an

793
00:59:44,820 --> 00:59:47,960
expert on that so can leave that one entirely to him

794
00:59:48,010 --> 00:59:52,180
so returning to the second method outlier detection

795
00:59:52,190 --> 00:59:55,880
the basic principle the build model for the norm for this customer

796
00:59:55,880 --> 00:59:57,680
and detect when

797
00:59:57,690 --> 01:00:02,140
transaction behavior begins to deviate from this norm

798
01:00:02,550 --> 01:00:07,810
the norm can be based on various based on various datasets built in various ways

799
01:00:07,810 --> 01:00:08,970
you can based on

800
01:00:09,020 --> 01:00:12,670
this customer compared with their own previous behaviour

801
01:00:12,810 --> 01:00:16,500
put jeanne jarring in brackets agenda are in is the

802
01:00:16,550 --> 01:00:19,590
the term they use to describe

803
01:00:19,640 --> 01:00:23,300
using different credit cards for different kinds of things so i might use a particular

804
01:00:23,300 --> 01:00:31,610
credit card for hotel transactions another one supermarket transactions another one for petrol gas transactions

805
01:00:31,640 --> 01:00:34,460
and not deviate from that sort of patterns

806
01:00:34,500 --> 01:00:35,600
and then of course

807
01:00:35,640 --> 01:00:36,680
if y

808
01:00:36,720 --> 01:00:38,590
petrol station

809
01:00:38,610 --> 01:00:42,670
credit card is used by connecticut or something

810
01:00:42,680 --> 01:00:47,190
that to raise the flag because the behavior on that particular credit card is abnormal

811
01:00:47,190 --> 01:00:52,210
so people practice can jarring and that's probably quite good take a message

812
01:00:52,230 --> 01:00:54,090
it does enable more effective

813
01:00:54,090 --> 01:00:56,710
for detection systems to be developed

814
01:00:56,720 --> 01:00:58,900
so that's something you might think about

815
01:00:58,930 --> 01:01:01,940
so that's one thing you can do you can build normal models based on the

816
01:01:02,930 --> 01:01:05,430
is the the previous behaviour the customer

817
01:01:05,460 --> 01:01:09,730
you can also build based on this customer compared with other customers

818
01:01:09,790 --> 01:01:11,900
life stage

819
01:01:11,930 --> 01:01:13,750
usage patterns

820
01:01:13,750 --> 01:01:17,090
people who just got there first credit card behave differently

821
01:01:17,100 --> 01:01:19,320
from people have been using cards

822
01:01:19,350 --> 01:01:20,610
thirty years

823
01:01:20,630 --> 01:01:25,210
you can segment customer financial behaviour types and of course you stick all these things

824
01:01:27,050 --> 01:01:31,360
as i said the basic advantage of the one class approaches you can detect new

825
01:01:31,360 --> 01:01:35,010
kinds of deviations from whatever you're norm

826
01:01:35,020 --> 01:01:36,930
which might of course mean that you've got more

827
01:01:37,800 --> 01:01:41,670
in a dynamic for the environment the you know one thing about this we know

828
01:01:41,670 --> 01:01:44,170
is that the environment distributions change

829
01:01:44,180 --> 01:01:46,220
so maybe these things

830
01:01:46,220 --> 01:01:48,350
are important

831
01:01:48,350 --> 01:01:49,560
the norm can be

832
01:01:49,580 --> 01:01:53,630
you can model the norm in various ways you can assume distributional form for the

833
01:01:53,630 --> 01:01:56,730
normal behaviour for example let's get very simple we can assume

834
01:01:57,140 --> 01:02:02,970
the multivariate normal distribution and use mahalanobis distance to measure the distance multivariate normal distribution

835
01:02:02,970 --> 01:02:08,270
for the transactions of the activity records measure distance using mahalanobis distance

836
01:02:08,300 --> 01:02:12,210
that's good because you get accurate probability estimates if you have a mate with a

837
01:02:12,210 --> 01:02:14,000
multivariate normal assumption

838
01:02:14,000 --> 01:02:18,480
and so it can be what you can do with relatively small sample sizes

839
01:02:18,510 --> 01:02:19,510
but of course

840
01:02:19,520 --> 01:02:25,760
for any upside there's the downside another very water very sensitive the thing sensitive to

841
01:02:25,770 --> 01:02:30,250
see this informative distribution skills this is probably not going to be terribly good

842
01:02:30,260 --> 01:02:35,350
and to outliers you can try to overcome that by robustifying the estimates you know

843
01:02:35,350 --> 01:02:40,050
whenever a problem occurs people try to solve it

844
01:02:41,800 --> 01:02:44,130
you can also relax these things

845
01:02:44,140 --> 01:02:50,680
we sacrifice some information about assumptions about the precise distributions you can measure relative distance

846
01:02:50,680 --> 01:02:51,630
from some

847
01:02:51,720 --> 01:02:57,390
center like mean in any direction using chebyshev inequality doesn't make distributional assumptions and so

848
01:02:58,010 --> 01:03:00,440
and of course you can use nonparametric approaches

849
01:03:00,460 --> 01:03:03,760
this is an example i'm going to give for example you can use kernel density

850
01:03:03,760 --> 01:03:06,470
estimation to estimate the

851
01:03:07,510 --> 01:03:12,100
probability density in any region the transaction or activity records space

852
01:03:12,140 --> 01:03:16,500
and if it prop that is very small and something because there is suspicious

853
01:03:16,510 --> 01:03:22,460
this sort of description if you like is the statistical description of these methods the

854
01:03:22,460 --> 01:03:26,050
computer science work in this area which is really equivalent to it

855
01:03:26,260 --> 01:03:29,250
often causes distance based methods but to just

856
01:03:29,250 --> 01:03:33,000
well as the reciprocal ways of looking at the same thing

857
01:03:33,010 --> 01:03:35,050
they can be subtle complications

858
01:03:35,060 --> 01:03:37,840
and many if any of you have worked in this sort of area of familiar

859
01:03:38,890 --> 01:03:41,810
you easily detect but this is

860
01:03:41,840 --> 01:03:46,730
lying in sparse region is anomalous unusual kind of transaction

861
01:03:46,760 --> 01:03:50,610
it's a long way from any other point it's different from any other point this

862
01:03:50,610 --> 01:03:54,790
transactional activity record is different from any other point

863
01:03:54,790 --> 01:03:58,400
but what about this one

864
01:03:58,420 --> 01:04:00,100
the distance between this

865
01:04:00,110 --> 01:04:01,510
o point and

866
01:04:01,520 --> 01:04:02,790
its nearest point

867
01:04:02,800 --> 01:04:06,340
is much the same as the distance between the so it probably wouldn't be flagged

868
01:04:06,340 --> 01:04:10,640
as being very fast suspiciously far from its nearest neighbour

869
01:04:10,680 --> 01:04:11,760
but of course

870
01:04:11,760 --> 01:04:14,510
relative to the local density of points here it is

871
01:04:14,520 --> 01:04:15,720
a long way away

872
01:04:15,890 --> 01:04:21,390
that suggests a problem of approach to overcoming this sort of problem you could the

873
01:04:21,390 --> 01:04:27,010
density estimate a particular transaction at point with that of nearby points rather than globally

874
01:04:27,010 --> 01:04:30,250
and of course people who extended these you know we could talk all day about

875
01:04:30,260 --> 01:04:32,930
these sorts of methods

876
01:04:32,980 --> 01:04:35,050
but i want to move on to the example

877
01:04:35,050 --> 01:04:39,810
another member of the team has been focusing on this this particular example

878
01:04:40,930 --> 01:04:42,750
forty four thousand accounts

879
01:04:42,760 --> 01:04:46,460
two point three million transactions

880
01:04:46,510 --> 01:04:51,630
three of three thousand of these were fraudulent fifty three thousand four hundred transactions three

881
01:04:51,630 --> 01:04:55,590
months of data so suddenly several variables remember between seventy and eighty in this case

882
01:04:55,590 --> 01:05:01,300
this particular banks several variables and we just chose these i think yes eight

883
01:05:03,430 --> 01:05:06,760
this to describe each transaction

884
01:05:06,770 --> 01:05:08,470
some of them are continuous

885
01:05:08,470 --> 01:05:10,010
some are

886
01:05:10,060 --> 01:05:13,190
discrete is and merchant category code again without

887
01:05:13,230 --> 01:05:15,430
around two thousand different categories

888
01:05:15,440 --> 01:05:18,970
so the high number of categories

889
01:05:19,000 --> 01:05:23,350
the merchant category code we the way we treat in this particular analysis we essentially

890
01:05:23,350 --> 01:05:27,230
converted it to a continuous variables

891
01:05:27,300 --> 01:05:31,650
what we did was we looked at each this this was ATM withdrawal data we

892
01:05:31,650 --> 01:05:33,750
looked at

893
01:05:33,760 --> 01:05:37,170
so cash machine withdrawals data we looked at each cash machine

894
01:05:37,180 --> 01:05:38,850
and i looked at

895
01:05:38,860 --> 01:05:41,170
which counts

896
01:05:41,180 --> 01:05:44,140
which people use that cash machine

897
01:05:44,140 --> 01:05:47,720
so that gives us a binary vector if you like

898
01:05:47,750 --> 01:05:50,180
or you can look at how often they use that accounts which would give you

899
01:05:50,190 --> 01:05:52,440
numbers are very sparse

900
01:05:52,510 --> 01:05:54,140
binary vector

901
01:05:54,150 --> 01:05:59,010
but nevertheless binary vector and you can define distances between the ATM machines

902
01:05:59,010 --> 01:06:00,420
a lot of the state with

903
01:06:00,430 --> 01:06:02,600
focus work with focal parts work

904
01:06:02,610 --> 01:06:06,650
they actually used they use their cameras

905
01:06:06,670 --> 01:06:10,480
and actually happens there is a sixty eight points they had thousands of points so

906
01:06:10,480 --> 01:06:13,530
they're actually doing this in a very small

907
01:06:13,550 --> 01:06:16,430
it's small about that would get very very good renderings

908
01:06:16,440 --> 01:06:20,520
but because we insist on doing this past and we're more interested in registration at

909
01:06:20,530 --> 01:06:22,030
the moment and synthesis

910
01:06:22,070 --> 01:06:25,570
but we do need some work and synthesis

911
01:06:26,230 --> 01:06:31,620
active appearance was actually we've got a we had an NSF project funded recently that

912
01:06:32,160 --> 01:06:34,570
gotta lotta love interest at all

913
01:06:34,660 --> 01:06:38,270
and it was doing some studies on human social dynamics

914
01:06:38,340 --> 01:06:43,890
what we're doing with was that we were actually we tracking people in real time

915
01:06:43,960 --> 01:06:49,680
and we make them having conversations with each other and so but the only the

916
01:06:49,680 --> 01:06:52,540
people couldn't see each other they could on the computer screen

917
01:06:52,550 --> 01:06:56,800
and what we would do we would animate and at the avatar of that person

918
01:06:56,840 --> 01:06:58,860
things but the cool thing with i

919
01:06:58,870 --> 01:07:01,770
is that because i can manipulate the appearance

920
01:07:01,780 --> 01:07:04,720
and the shape of things i can start playing

921
01:07:04,730 --> 01:07:09,170
with how the person looks so have the person perhaps even in sound so we

922
01:07:09,170 --> 01:07:11,940
actually did some studies in two world

923
01:07:11,950 --> 01:07:18,540
two people when a male male one mile and mile are in conversation

924
01:07:18,560 --> 01:07:21,940
is there any change of actually changed the sex of the male to female even

925
01:07:21,940 --> 01:07:23,240
though he a mild

926
01:07:23,260 --> 01:07:27,970
this distance warping something like that and so the active appearance model sort of allied

927
01:07:27,970 --> 01:07:34,580
to investigate these qualities school effects and also some things with voices and things in

928
01:07:34,650 --> 01:07:38,360
a different animations and we're going to be a bit about the but that's a

929
01:07:38,360 --> 01:07:42,900
little bit of it's kind of cool social experiment things so you can get

930
01:07:42,940 --> 01:07:46,830
there is a similar thing in audio visual speech we could we would really the

931
01:07:46,830 --> 01:07:49,260
researchers can really trying to look for

932
01:07:49,270 --> 01:07:50,740
something that analogous to

933
01:07:50,760 --> 01:07:53,560
the mcgurk effect is anyone ever had the mcgurk effect

934
01:07:53,570 --> 01:07:58,270
it's essentially with mcgurk effect it's

935
01:07:58,280 --> 01:07:59,530
the idea is this

936
01:07:59,540 --> 01:08:00,830
is that

937
01:08:00,990 --> 01:08:06,400
you could be sentence sounds alike by the classic like by god and

938
01:08:06,410 --> 01:08:10,170
and unsurprisingly if all i mix up

939
01:08:10,210 --> 01:08:13,150
so the sales and may visually

940
01:08:13,160 --> 01:08:16,670
actually the visual movements above and

941
01:08:16,710 --> 01:08:18,850
i oftentimes perceived neighbour

942
01:08:18,860 --> 01:08:21,270
so if i go back in audio

943
01:08:21,280 --> 01:08:23,370
god in video

944
01:08:23,390 --> 01:08:27,940
and merge them together sometimes people perceive that

945
01:08:27,990 --> 01:08:32,990
so it what's kind of indicating whatever it is that we don't necessary we rely

946
01:08:32,990 --> 01:08:37,010
on both modalities and so what we can't of this research was kind of trying

947
01:08:37,020 --> 01:08:38,110
to look for

948
01:08:38,140 --> 01:08:39,430
mcgurk effect

949
01:08:39,440 --> 01:08:44,410
with other other things towards say the face all six or or things like that

950
01:08:44,420 --> 01:08:47,800
so and so it's it's a promising avenue and so we're trying to kind of

951
01:08:47,950 --> 01:08:50,420
this together in this kind of more

952
01:08:53,460 --> 01:08:56,470
the rest of this lecture will be basically what how to build a name which

953
01:08:56,470 --> 01:09:00,810
i'm sure you guys wondering about how do you feel and name an image what

954
01:09:00,810 --> 01:09:02,220
is the general approach

955
01:09:02,300 --> 01:09:06,960
and how can we do it efficiently and we also talked about some extensions

956
01:09:06,970 --> 01:09:11,880
so the way we're building a in we're talking about this before about is that

957
01:09:12,170 --> 01:09:17,250
we actually have to sit lot unfortunately for you guys all the time the student

958
01:09:17,510 --> 01:09:20,280
that sit down and they have two

959
01:09:20,590 --> 01:09:23,580
the points in images and as i saying yesterday

960
01:09:23,600 --> 01:09:28,350
not just one or two images like thousands upon thousands upon thousands of images

961
01:09:28,400 --> 01:09:31,560
and you have to click these points consistent consistently

962
01:09:31,600 --> 01:09:35,170
and you can kind of see that it actually is kind of tough fast sometimes

963
01:09:35,170 --> 01:09:40,170
because OK sure enough i can probably reliably most people can reliably find the all

964
01:09:40,170 --> 01:09:42,950
i want to hear the icon here

965
01:09:42,950 --> 01:09:48,010
knows perhaps you the top and is here but you start getting into world

966
01:09:48,030 --> 01:09:50,780
where exactly should be putting this point in the jaw

967
01:09:50,790 --> 01:09:53,650
where exactly should be pointing this this point so

968
01:09:53,670 --> 01:09:56,540
a big part of this is not only the scan the points but have a

969
01:09:56,540 --> 01:10:01,890
good software package that can actually take care so in our software packages instead of

970
01:10:01,890 --> 01:10:07,260
looking for individual points we have we got a choice of labelling something whether it's

971
01:10:08,290 --> 01:10:13,370
circular contour along contour and we also have things in there so to say

972
01:10:13,430 --> 01:10:18,310
it probably isn't very clearly hear what about some of the points you raise

973
01:10:18,320 --> 01:10:22,370
and the primary points and their points that can be easily distinguished the collect anchor

974
01:10:22,370 --> 01:10:26,270
points and then you got the green points where you kind of approximately know where

975
01:10:26,280 --> 01:10:31,220
they are we let the algorithm also called make sure that they will interspersed well

976
01:10:31,220 --> 01:10:36,210
placed things and so what do we do from that is essentially get sixty points

977
01:10:36,210 --> 01:10:41,990
from the fact there's still a lot of open open questions and especially faces

978
01:10:42,000 --> 01:10:45,820
how many landmarks should have obviously the more landmarks the better

979
01:10:45,840 --> 01:10:51,170
but a problem occurs is that when i start adding more landmarks one seventy were

980
01:10:51,180 --> 01:10:55,540
actually place landmarks can increases so you think you must be pretty good but when

981
01:10:55,710 --> 01:11:00,310
stock going blog about sixty eight it becomes difficult because of course

982
01:11:03,300 --> 01:11:06,030
i can heal

983
01:11:06,040 --> 01:11:13,800
i'm sorry really going to pick up

984
01:11:13,830 --> 01:11:15,220
can you part

985
01:11:17,460 --> 01:11:19,330
what i mean

986
01:11:19,360 --> 01:11:22,430
you clicking on point here so i may talking about clicking on the point two

987
01:11:22,450 --> 01:11:26,560
active appearance models

988
01:11:26,600 --> 01:11:29,350
well in is this is about your questions yes

989
01:11:29,370 --> 01:11:33,330
so each should be they should be i mean i think there has been some

990
01:11:33,330 --> 01:11:36,820
there has been some work done with infrared cameras and other cameras and things like

991
01:11:36,820 --> 01:11:41,450
that so as long as you get a reasonable image and that the idea of

992
01:11:42,510 --> 01:11:47,060
and still still applies and i believe it should still apply although would be kinda

993
01:11:47,930 --> 01:11:49,220
with family images

994
01:11:49,640 --> 01:11:53,760
but you could try we have not any way that you have

995
01:11:54,840 --> 01:11:57,660
but it's the big thing is that

996
01:11:57,720 --> 01:12:02,730
so you can't just saying that's a like a video sequence of

997
01:12:02,740 --> 01:12:06,850
of the thermal image sequence whatever you actually have to make sure that the data

998
01:12:06,850 --> 01:12:11,420
sets maps you actually have to have a lot of one data of thermal images

999
01:12:11,420 --> 01:12:12,930
that have points click the

1000
01:12:12,980 --> 01:12:15,990
things such as usual there's some sort of match

1001
01:12:18,000 --> 01:12:20,360
and so

1002
01:12:20,420 --> 01:12:25,050
some of some the subject and then these all points were kind of physically clicked

1003
01:12:25,050 --> 01:12:29,950
on we one that we've got a lot of different datasets and

1004
01:12:29,960 --> 01:12:34,610
like i was talking about like the vocal the so the voltage and stop work

1005
01:12:34,610 --> 01:12:37,910
data drives this stuff so you can have the best album in the world but

1006
01:12:37,910 --> 01:12:39,360
if you don't have a lot of data

1007
01:12:39,420 --> 01:12:43,060
and this is like what you guys know machine learning when you don't know something

1008
01:12:43,060 --> 01:12:44,470
you make up for the data

1009
01:12:44,470 --> 01:12:47,500
and this is essentially what you have to do with a lot of this work

1010
01:12:48,610 --> 01:12:49,830
a lot of the leading

1011
01:12:49,860 --> 01:12:52,970
institutions that on this have a lot of this data set

1012
01:12:53,380 --> 01:12:56,990
that that's that's the real the real the real thing but it's a good reason

1013
01:12:56,990 --> 01:13:02,070
to question is that safer faces and for other objects whatever it's really well defined

1014
01:13:02,070 --> 01:13:05,340
because people are willing to consider and click on this point is a way that

1015
01:13:05,340 --> 01:13:06,850
we can kind

1016
01:13:06,870 --> 01:13:11,140
extend this work to other object classes were people willing to sit down can i

1017
01:13:11,140 --> 01:13:13,790
would like i do this in an unsupervised way

1018
01:13:13,820 --> 01:13:16,010
four different objects

1019
01:13:16,010 --> 01:13:19,150
and so we've actually been doing a little bit of work on that and we

1020
01:13:19,160 --> 01:13:21,770
call that unsupervised image alignment

1021
01:13:21,820 --> 01:13:27,250
and actually i don't have any so i might want to show you guys that

1022
01:13:27,300 --> 01:13:31,070
so this is basically equiv just because i have it up there

1023
01:13:34,270 --> 01:13:38,080
we refer to this as

1024
01:13:39,500 --> 01:13:42,860
seems to be here

1025
01:13:42,880 --> 01:13:46,160
we refer to this as

1026
01:13:46,210 --> 01:13:48,610
concealing and i to showing this before

1027
01:13:48,660 --> 01:13:52,410
essentially what the task is here is that they are OK to sell these these

1028
01:13:52,430 --> 01:13:56,500
digits here but to say i have and have-not class where i don't have a

1029
01:13:56,500 --> 01:14:00,360
lot of people who are willing to sit you click on sort of can i

1030
01:14:01,200 --> 01:14:05,490
o line and issue the problem is this

1031
01:14:05,490 --> 01:14:07,990
what if there are four dimensional vectors

1032
01:14:08,050 --> 01:14:13,580
so it's the column space of a is a is a subspace

1033
01:14:13,600 --> 01:14:18,150
one of our four here

1034
01:14:18,210 --> 01:14:20,230
because a one

1035
01:14:20,240 --> 01:14:21,170
four by

1036
01:14:21,200 --> 01:14:24,960
a four by three matrix tell me

1037
01:14:25,010 --> 01:14:28,710
how many rows there are how many components in the column

1038
01:14:28,710 --> 01:14:33,240
and so we're in our four OK now what's in that

1039
01:14:33,300 --> 01:14:38,690
what's so the column space of a it's a subspace of our four

1040
01:14:38,730 --> 01:14:42,980
i call it the column space make it like that

1041
01:14:43,040 --> 01:14:44,210
so that's my

1042
01:14:44,230 --> 01:14:45,660
little symbol

1043
01:14:45,670 --> 01:14:48,730
for some subspace of our four

1044
01:14:48,740 --> 01:14:51,630
what's in our what's in that subspace

1045
01:14:51,690 --> 01:14:54,300
well that culture

1046
01:14:54,340 --> 01:14:59,950
one two three four this problem is in this column is in and what

1047
01:15:00,000 --> 01:15:03,180
so it's got the columns of a in it

1048
01:15:03,190 --> 01:15:05,990
but that's not enough to

1049
01:15:06,000 --> 01:15:09,930
right i don't have a subspace of i just put in three vectors

1050
01:15:09,970 --> 01:15:13,350
so how do i feel that out to be a subspace

1051
01:15:13,370 --> 01:15:15,810
i take

1052
01:15:17,510 --> 01:15:20,250
comm linear combination

1053
01:15:20,260 --> 01:15:24,090
so the column space of a is all

1054
01:15:28,460 --> 01:15:33,710
combinations of the column

1055
01:15:33,710 --> 01:15:35,820
and that does give me

1056
01:15:35,950 --> 01:15:41,130
a subspace does give me a vector space because of i one linear combination multiply

1057
01:15:41,180 --> 01:15:42,490
by eleven

1058
01:15:42,540 --> 01:15:44,870
i've got another linear combination

1059
01:15:44,930 --> 01:15:48,560
if i have a linear combination i had to another linear combination again the third

1060
01:15:50,250 --> 01:15:54,490
so that this is like the smallest space

1061
01:15:54,510 --> 01:15:57,680
like it's got to have those three problems in

1062
01:15:57,720 --> 01:16:01,240
and has to have their combinations and that's where we stop

1063
01:16:03,310 --> 01:16:05,900
i'm going to be interested in that

1064
01:16:08,370 --> 01:16:11,740
sort of like to get some idea of what's in that place how big is

1065
01:16:11,740 --> 01:16:17,060
that space is that space the whole four dimensional space

1066
01:16:17,080 --> 01:16:19,500
or is it a subspace inside

1067
01:16:19,550 --> 01:16:20,450
ten years

1068
01:16:21,080 --> 01:16:24,350
made to see if you can

1069
01:16:24,370 --> 01:16:26,370
i i mean

1070
01:16:26,400 --> 01:16:30,530
we can get a yes or no answer sometimes without

1071
01:16:30,580 --> 01:16:36,810
without being ready for the complete proofs

1072
01:16:36,850 --> 01:16:39,340
what do you think is the subspace

1073
01:16:39,360 --> 01:16:44,070
i'm talking about here combinations of those three guys that

1074
01:16:44,080 --> 01:16:46,480
all four dimensional space

1075
01:16:46,490 --> 01:16:49,050
maybe yes or no on that one

1076
01:16:49,950 --> 01:16:53,110
no somehow our feeling is

1077
01:16:53,170 --> 01:16:54,880
and it happens to be right

1078
01:16:54,980 --> 01:16:59,290
that if we start with three victories and take their combinations we can get the

1079
01:16:59,310 --> 01:17:02,130
whole four dimensional

1080
01:17:04,810 --> 01:17:08,760
so somehow we get a smaller space but how much smaller

1081
01:17:08,780 --> 01:17:13,760
that's OK i'm going come up here not so media

1082
01:17:13,800 --> 01:17:16,350
ah let me let me

1083
01:17:18,030 --> 01:17:21,550
make this critical connection with it

1084
01:17:24,330 --> 01:17:26,210
linear great

1085
01:17:27,080 --> 01:17:28,800
behind our

1086
01:17:28,810 --> 01:17:31,560
abstract definition we have a purpose

1087
01:17:31,730 --> 01:17:34,750
that is to understand a sequel the

1088
01:17:34,780 --> 01:17:37,190
so suppose i make the connection

1089
01:17:41,210 --> 01:17:43,700
a and he will be

1090
01:17:43,710 --> 01:17:47,490
always have a solution for every b

1091
01:17:47,550 --> 01:17:48,420
i have a

1092
01:17:48,430 --> 01:17:50,800
have a

1093
01:17:52,450 --> 01:17:55,900
for every

1094
01:17:55,950 --> 01:17:58,450
right hand side

1095
01:17:58,880 --> 01:18:07,440
i guess that's going to be a yes or no question

1096
01:18:07,470 --> 01:18:10,810
and then i'm going to have wait

1097
01:18:10,850 --> 01:18:13,830
right hand sides are OK

1098
01:18:13,830 --> 01:18:16,490
that's really the question i asked

1099
01:18:17,650 --> 01:18:21,540
with the right hand side b

1100
01:18:22,260 --> 01:18:25,950
make up you can see from the way i'm speaking what the answer to this

1101
01:18:25,950 --> 01:18:28,020
question as it is

1102
01:18:28,070 --> 01:18:30,230
the answer is no

1103
01:18:30,480 --> 01:18:34,680
actually will be does not have a solution for every

1104
01:18:34,750 --> 01:18:38,550
why why you say why do i say no

1105
01:18:38,560 --> 01:18:41,200
because they actually will be is

1106
01:18:41,200 --> 01:18:43,360
it's really this is

1107
01:18:43,370 --> 01:18:46,730
like this is for equation

1108
01:18:46,810 --> 01:18:51,460
and only three and

1109
01:18:57,560 --> 01:18:58,650
let me let me

1110
01:18:58,650 --> 01:19:00,360
the way that the whole

1111
01:19:00,410 --> 01:19:02,650
but the whole thing looks like

1112
01:19:07,540 --> 01:19:10,310
right now they actually will be

1113
01:19:13,540 --> 01:19:16,430
these columns are one two three four

1114
01:19:16,460 --> 01:19:18,560
one one one one

1115
01:19:18,570 --> 01:19:20,800
one two three four five

1116
01:19:20,980 --> 01:19:26,990
and of course has three components x one x two x three

1117
01:19:27,010 --> 01:19:29,200
and i'm trying to get

1118
01:19:29,210 --> 01:19:31,270
the right

1119
01:19:31,290 --> 01:19:39,610
right hand side b one b two b three and e four

1120
01:19:39,650 --> 01:19:44,760
so my first point is i can always do it

1121
01:19:44,790 --> 01:19:45,960
in way

1122
01:19:45,970 --> 01:19:50,380
that just says again what you told me five minutes ago

1123
01:19:50,430 --> 01:19:52,630
that the combinations

1124
01:19:52,680 --> 01:19:56,840
of these columns don't fill the whole four dimensional space

1125
01:19:56,850 --> 01:19:58,880
there's going to be some vectors b

1126
01:19:58,890 --> 01:20:00,610
a lot of factors be

1127
01:20:00,660 --> 01:20:05,370
that are not combinations of those of the recall

1128
01:20:05,380 --> 01:20:10,310
was the combination those columns are likely to be just a little plain something inside

1129
01:20:10,310 --> 01:20:13,010
inside our goal

1130
01:20:14,240 --> 01:20:17,710
so you see that i do have four equation

1131
01:20:17,750 --> 01:20:19,440
and only three unknown

1132
01:20:19,450 --> 01:20:23,050
so like everybody is going to say no you

1133
01:20:23,090 --> 01:20:27,470
don't you can usually solve for equations with only three

1134
01:20:27,530 --> 01:20:29,800
but now i want to say

1135
01:20:29,810 --> 01:20:31,880
sometimes you can

1136
01:20:31,920 --> 01:20:33,970
for some right hand side

1137
01:20:34,030 --> 01:20:36,480
i can solve

1138
01:20:37,040 --> 01:20:42,870
that the that's the one the right hand side that i'm interested in right now

1139
01:20:42,910 --> 01:20:46,620
with the right hand side

1140
01:20:46,630 --> 01:20:48,530
allow me to solve

1141
01:20:48,550 --> 01:20:50,970
that is the question but it

1142
01:20:50,980 --> 01:20:54,470
it's going to have like a nice clear and

1143
01:20:54,490 --> 01:20:58,630
so my question is so my question is

1144
01:21:01,900 --> 01:21:03,440
which vector b

1145
01:21:03,460 --> 01:21:04,520
allow me

1146
01:21:07,810 --> 01:21:11,570
system to be solved

1147
01:21:15,180 --> 01:21:16,700
i want you

1148
01:21:16,720 --> 01:21:19,980
so that's like

1149
01:21:19,990 --> 01:21:22,480
get two question marks indicate

1150
01:21:22,490 --> 01:21:25,360
that is the important question OK

1151
01:21:25,360 --> 01:21:27,480
first before we

1152
01:21:27,500 --> 01:21:32,210
given that give total answer give me just a partial answer

1153
01:21:32,210 --> 01:21:35,360
the only one right hand side that i know of

1154
01:21:35,370 --> 01:21:36,570
i can solve this

1155
01:21:36,590 --> 01:21:39,130
all the

1156
01:21:39,190 --> 01:21:41,430
OK that's the like

1157
01:21:41,430 --> 01:21:43,180
something b

1158
01:21:43,200 --> 01:21:44,580
the into

1159
01:21:44,580 --> 01:21:49,140
you see that the most likely sequence of length one two four

1160
01:21:49,270 --> 01:21:54,410
and you see this should here they all have some published the meaning

1161
01:21:54,750 --> 01:22:00,310
you can use indeed and learning for interpretation

1162
01:22:02,120 --> 01:22:07,060
later i mean this this very which we did a while ago

1163
01:22:07,100 --> 01:22:08,490
later became

1164
01:22:08,580 --> 01:22:13,430
much nicer way of looking at the classifier

1165
01:22:13,450 --> 01:22:20,010
can he certainly much more features we can also see that maybe link

1166
01:22:20,160 --> 01:22:22,950
but hey mister link the one

1167
01:22:23,060 --> 01:22:27,600
he came blink one b and four

1168
01:22:28,680 --> 01:22:32,350
in this area there are some came or

1169
01:22:32,410 --> 01:22:35,700
but you have a much higher resolution to look

1170
01:22:37,240 --> 01:22:38,470
i wouldn't

1171
01:22:38,490 --> 01:22:42,950
necessarily suggest to to use some of the ending point of the patient if you

1172
01:22:42,950 --> 01:22:44,600
have the other choice

1173
01:22:44,600 --> 01:22:46,040
a few things

1174
01:22:46,060 --> 01:22:48,220
these position twenty equal

1175
01:22:48,490 --> 01:22:52,660
or at least these kind of

1176
01:22:55,700 --> 01:22:57,020
there but for

1177
01:22:57,100 --> 01:22:59,680
what interesting

1178
01:22:59,770 --> 01:23:13,270
this is the projection of the vector from what in india

1179
01:23:19,790 --> 01:23:22,410
you know what the way that we can

1180
01:23:22,450 --> 01:23:23,950
what's the

1181
01:23:23,970 --> 01:23:25,970
i mean what's the linear OK

1182
01:23:27,790 --> 01:23:34,640
in europe the best

1183
01:23:34,660 --> 01:23:39,390
my question is

1184
01:23:39,410 --> 01:23:45,060
the first course if this is whether the weight vector of the classifier

1185
01:23:45,080 --> 01:23:50,290
OK and what is the projection of the weight vector and

1186
01:23:50,970 --> 01:23:55,020
in that case the whether the classifier is linear or not

1187
01:23:55,080 --> 01:24:01,870
one is the kernel used here debating so this is our last example very typically

1188
01:24:01,870 --> 01:24:03,720
use the for

1189
01:24:03,740 --> 01:24:08,310
this is similar to this year

1190
01:24:08,640 --> 01:24:12,390
we optimize the weights in the baby

1191
01:24:14,370 --> 01:24:19,620
we get a similar picture qualitatively get similar but you see

1192
01:24:19,640 --> 01:24:20,910
why if you want to

1193
01:24:20,990 --> 01:24:23,660
in this country

1194
01:24:23,720 --> 01:24:30,120
i i wonder in this case the weight far regularized

1195
01:24:30,930 --> 01:24:33,200
because it's the weight of

1196
01:24:33,220 --> 01:24:38,520
i probably didn't understand exactly what projection of the weighted mean in in the weighted

1197
01:24:41,660 --> 01:24:44,510
kernel learning fitting you did regularized the

1198
01:24:44,520 --> 01:24:50,370
the weight of the kernel now also regularly are regularized by actually l one wrong

1199
01:24:51,720 --> 01:24:59,020
so named by the by the most weight and the other case

1200
01:24:59,040 --> 01:25:00,410
twenty plot here

1201
01:25:00,410 --> 01:25:03,330
something like the maximum wage

1202
01:25:03,370 --> 01:25:06,470
paul heymann position

1203
01:25:06,490 --> 01:25:09,740
so we take the maximum all

1204
01:25:10,080 --> 01:25:12,560
so it so

1205
01:25:12,580 --> 01:25:16,600
there might be a large number of being channelled important but is this may be

1206
01:25:16,700 --> 01:25:20,700
something as important hold on

1207
01:25:23,870 --> 01:25:25,620
and that this maybe of

1208
01:25:25,660 --> 01:25:32,180
yes endurance

1209
01:25:36,600 --> 01:25:44,200
so then i continue with structured output learning so

1210
01:25:44,220 --> 01:25:49,180
this is going to be about hidden markov models that support dynamic programming

1211
01:25:49,560 --> 01:25:51,990
and this community hold for learning

1212
01:25:52,020 --> 01:25:53,560
these like one

1213
01:25:53,580 --> 01:25:56,180
so what about dynamic programming

1214
01:25:59,810 --> 01:26:05,060
people who could be able to implement the program

1215
01:26:05,120 --> 01:26:09,250
OK let OK that i can go

1216
01:26:12,700 --> 01:26:14,970
what you see now is

1217
01:26:15,020 --> 01:26:17,490
he talked about

1218
01:26:17,510 --> 01:26:19,600
and this is

1219
01:26:19,930 --> 01:26:22,580
he says got a product the feature vector

1220
01:26:22,620 --> 01:26:25,240
now we can extend this in two ways to

1221
01:26:25,330 --> 01:26:29,770
we talked about this just of the kernel you can be extended by taking a

1222
01:26:29,770 --> 01:26:34,370
linear combination of other way of handling it is too

1223
01:26:34,450 --> 01:26:36,160
don't the label

1224
01:26:36,200 --> 01:26:38,410
in the future

1225
01:26:38,520 --> 01:26:43,220
not only the input example but also take the output cells

1226
01:26:43,270 --> 01:26:44,080
into the

1227
01:26:44,490 --> 01:26:51,520
OK so so far was maybe really useful because we only had two possible labels

1228
01:26:51,750 --> 01:26:55,580
but if you want to compute something more of it you want to something more

1229
01:26:55,580 --> 01:26:57,770
complicated than maybe you

1230
01:26:57,790 --> 01:27:01,060
it's more useful to compute y in

1231
01:27:03,640 --> 01:27:06,770
this is good for learning

1232
01:27:10,470 --> 01:27:15,100
generally the task is that we have some

1233
01:27:15,120 --> 01:27:19,930
labelled data and we would like to predict labels input would like about

1234
01:27:23,020 --> 01:27:27,750
OK so in multiclass we which simply not get too close to home twelve times

1235
01:27:27,750 --> 01:27:32,020
policy have been shown which basically means a large number of plans

1236
01:27:32,040 --> 01:27:39,950
and you and you and actually did do some interesting work region was bought improving

1237
01:27:40,210 --> 01:27:44,080
so basically starting with a

1238
01:27:44,160 --> 01:27:46,390
approximate global policy

1239
01:27:46,410 --> 01:27:48,640
and improving it i think

1240
01:27:50,560 --> 01:27:56,080
we look at a couple of details of these

1241
01:27:56,120 --> 01:28:01,600
the first one are learning dimensions influencing the benevolent so the idea is you get

1242
01:28:01,600 --> 01:28:06,310
a bunch of land and you want to example plans you try to explain for

1243
01:28:06,310 --> 01:28:09,210
example why these plans are correct

1244
01:28:09,230 --> 01:28:14,700
so what pieces of these plans make them correct for these problems and use that

1245
01:28:14,750 --> 01:28:17,640
to essentially known rules which say that ran

1246
01:28:17,640 --> 01:28:22,750
these are the initial state literacy initiative these other goals features these must be the

1247
01:28:22,750 --> 01:28:25,040
action sequences issues

1248
01:28:25,040 --> 01:28:29,180
OK the EBL part here actually occurred

1249
01:28:29,210 --> 01:28:32,060
in doing that in there

1250
01:28:32,080 --> 01:28:36,310
analysis given the planned essentially that explain why is kind

1251
01:28:36,970 --> 01:28:37,980
in an example

1252
01:28:38,000 --> 01:28:39,410
o that of

1253
01:28:39,450 --> 01:28:40,890
the kind of thing that they do

1254
01:28:40,890 --> 01:28:43,230
so here they are shown i

1255
01:28:43,230 --> 01:28:50,040
here's on a simple problem simple plan which involves robot going into a different room

1256
01:28:50,210 --> 01:28:53,290
we at that by ball becoming the rule one and dropping it

1257
01:28:53,290 --> 01:28:54,930
OK and the

1258
01:28:54,950 --> 01:29:00,600
look at that sequence of states and actions and they learn a little rules here

1259
01:29:00,680 --> 01:29:05,020
which basically says that when you have these goals and these kinds of things instead

1260
01:29:05,810 --> 01:29:08,250
this must be the sequence of actions whose

1261
01:29:08,310 --> 01:29:11,480
OK now you have a different way shown here

1262
01:29:12,100 --> 01:29:14,640
and that leads to a different

1263
01:29:14,700 --> 01:29:19,580
such rules and then that the what essentially is trying to make sure that

1264
01:29:19,600 --> 01:29:24,970
you kind of what these things into a more general which covers what

1265
01:29:25,930 --> 01:29:33,160
and in essence what they're doing in their way of computing the approximate policy of

1266
01:29:33,160 --> 01:29:38,120
state schools to actions through these rules this is the representation of the policy

1267
01:29:41,730 --> 01:29:44,700
so the other way of looking at it is to say that a policy can

1268
01:29:44,700 --> 01:29:47,480
be seen as the classifier and so we can learn it

1269
01:29:47,870 --> 01:29:53,020
so if you have access to an traces of an optimal policy

1270
01:29:53,040 --> 01:29:56,620
so if you assume that there is an optimal policy for this domain which basically

1271
01:29:56,620 --> 01:29:58,200
six smg

1272
01:29:58,210 --> 01:30:03,500
and that's what the action is viewed that policy and generating places

1273
01:30:03,500 --> 01:30:04,980
and you have these decided degrees

1274
01:30:05,000 --> 01:30:06,680
you can just say

1275
01:30:07,680 --> 01:30:10,770
in a sense you can see that

1276
01:30:10,830 --> 01:30:14,910
it tells you about the conditions what are the states with certain actions are applicable

1277
01:30:14,950 --> 01:30:18,330
each tragically you you've state action state action

1278
01:30:18,370 --> 01:30:22,730
so you have examples positive examples saying this states

1279
01:30:22,750 --> 01:30:24,480
you should be doing is actions

1280
01:30:24,580 --> 01:30:28,890
OK carbon actually looking back in nineteen ninety nine

1281
01:30:28,930 --> 01:30:34,230
looks that are inductive learning problem and learn conditionally

1282
01:30:36,390 --> 01:30:38,390
which however as i said

1283
01:30:38,430 --> 01:30:42,310
because of course that you have access the assumption that you have access to an

1284
01:30:42,310 --> 01:30:46,560
optimal policy that somebody is showing you examples

1285
01:30:49,160 --> 01:30:52,580
there is some new work actually i think this is also connected to some of

1286
01:30:52,580 --> 01:30:55,470
the one that

1287
01:30:55,560 --> 01:31:03,020
that are detrimental to that and you but this is one of the more familiar

1288
01:31:03,390 --> 01:31:07,020
with you don't have access to places from an optimal policy

1289
01:31:07,080 --> 01:31:12,330
so what you could lose about his combine induction and reinforcement learning together

1290
01:31:12,330 --> 01:31:13,600
OK so

1291
01:31:13,600 --> 01:31:16,620
you start me an approximate policy

1292
01:31:18,660 --> 01:31:20,230
i could be completely bad

1293
01:31:21,180 --> 01:31:23,430
you know policy improvement

1294
01:31:23,430 --> 01:31:25,560
and when you do policy improvement

1295
01:31:25,580 --> 01:31:30,910
and then so you have a policy iteration step and policy learning step the policy

1296
01:31:30,910 --> 01:31:33,330
learning step here is similar to to

1297
01:31:33,330 --> 01:31:34,980
what and that's

1298
01:31:35,000 --> 01:31:37,230
and the improved isolation step

1299
01:31:37,290 --> 01:31:43,180
is if you remember the lecture by setting that they basically this issue after that

1300
01:31:43,180 --> 01:31:47,870
you can follow new policy iteration to improve policy my presentation

1301
01:31:47,890 --> 01:31:49,330
the tricky part here

1302
01:31:49,350 --> 01:31:50,390
it is

1303
01:31:50,390 --> 01:31:56,040
to make it actually work the wind up not doing so if you remember the

1304
01:31:56,040 --> 01:32:00,500
way the policy improvement is done you can what the policy value function and they

1305
01:32:00,610 --> 01:32:03,060
can with the value function back into politics

1306
01:32:03,100 --> 01:32:07,770
but without doing that you will also actually just if you only have an access

1307
01:32:07,770 --> 01:32:09,500
to assimilate

1308
01:32:09,580 --> 01:32:13,660
would simulate this policy i using those trajectories

1309
01:32:13,660 --> 01:32:15,620
you can do approximate

1310
01:32:17,310 --> 01:32:22,430
policy iteration which is basically what

1311
01:32:22,450 --> 01:32:25,680
if you want to do this is by the way the planet that i was

1312
01:32:25,680 --> 01:32:28,000
mentioning yesterday which they

1313
01:32:28,160 --> 01:32:34,580
then there and stochastic planning competition for last years

1314
01:32:34,600 --> 01:32:38,230
the nation made

1315
01:32:38,270 --> 01:32:43,140
not one

1316
01:32:43,200 --> 01:32:44,480
you get

1317
01:32:44,500 --> 01:32:47,430
the idea of all

1318
01:32:47,450 --> 01:32:48,980
back c

1319
01:32:49,000 --> 01:32:55,700
not all i like to be able feature selection

1320
01:32:55,770 --> 01:32:59,620
and so i think using

1321
01:32:59,660 --> 01:33:00,330
and then you

1322
01:33:00,370 --> 01:33:02,710
propagating the truth

1323
01:33:02,730 --> 01:33:07,100
or secrets mentions which is much more likely

1324
01:33:08,230 --> 01:33:11,290
i think there are this connection

1325
01:33:11,310 --> 01:33:12,230
in fact

1326
01:33:12,250 --> 01:33:18,290
so long as you can see just i was taken but the people of ideas

1327
01:33:18,330 --> 01:33:25,160
take back when he was hard on and enforcement learning

1328
01:33:25,160 --> 01:33:28,290
this would be nineteen

1329
01:33:28,350 --> 01:33:30,250
the nineteen ninety nine

1330
01:33:30,600 --> 01:33:33,040
so you can look it up

1331
01:33:35,180 --> 01:33:41,310
so so what they doing here is in a sense generating the trajectories for the

1332
01:33:41,310 --> 01:33:45,180
improved policy that's the tricky part and the way they do do it is

1333
01:33:45,200 --> 01:33:49,040
i mean i'm not going to be able to work details but in a sense

1334
01:33:49,040 --> 01:33:53,660
this is a tragic that the generated but putting broad policy starting rate

1335
01:33:53,660 --> 01:33:56,770
all the

1336
01:33:56,850 --> 01:33:59,520
so starting with a current policy

1337
01:34:00,210 --> 01:34:05,850
do policy iteration step which sort of generates that trajectories for improved policy

1338
01:34:05,850 --> 01:34:08,750
and once you know that article is for the input policy you can learn an

1339
01:34:08,750 --> 01:34:15,040
approximation you can learn essentially a closed form of the traditional from the improved policy

1340
01:34:15,060 --> 01:34:17,390
which then goes back to this look

1341
01:34:17,390 --> 01:34:18,620
trying to improve the

1342
01:34:20,230 --> 01:34:22,000
and the idea

1343
01:34:22,020 --> 01:34:26,310
of doing that he had essentially is not starting from st

1344
01:34:26,350 --> 01:34:28,230
they consider doing

1345
01:34:28,370 --> 01:34:30,350
it's possible action

1346
01:34:30,370 --> 01:34:35,390
and then actually generating a simulation of the policy that they currently have

1347
01:34:35,390 --> 01:34:39,500
and if it doesn't end in you know in planning one of the problems is

1348
01:34:39,500 --> 01:34:41,230
in terms of looking at

1349
01:34:41,270 --> 01:34:45,430
planning problems where there are records of achievement as an MDP

1350
01:34:45,450 --> 01:34:47,750
the reward function is very sparse

1351
01:34:47,750 --> 01:34:52,780
all right so i guess i just like to begin by thanking the organisers for

1352
01:34:52,790 --> 01:34:57,720
the opportunity to be here is real pleasure to be part of this this summer

1353
01:34:57,720 --> 01:35:01,110
school have been enjoying myself to release

1354
01:35:01,540 --> 01:35:06,190
OK so i'll be talking in this part of the graphical models message passing algorithms

1355
01:35:06,190 --> 01:35:13,020
and variational methods and will be that of overlap with the talk of sam roweis

1356
01:35:13,200 --> 01:35:16,940
but also be moving on to some more advanced topics sort of building on the

1357
01:35:16,940 --> 01:35:20,350
foundation that sam built for over the past couple days

1358
01:35:20,460 --> 01:35:25,350
so for those of you interested if you look at my web page there's copies

1359
01:35:25,350 --> 01:35:28,210
of these slides

1360
01:35:28,220 --> 01:35:33,970
also fortunately copies of films of course lectures so much more detail than i give

1361
01:35:33,980 --> 01:35:39,090
here this will be some more high-level than that full-length course for obvious reasons

1362
01:35:39,160 --> 01:35:42,360
but if you are interested in more details you can have a look at this

1363
01:35:42,360 --> 01:35:45,030
web page there

1364
01:35:45,040 --> 01:35:50,970
so sort of reviewing part of what's sam said graphical models are are really framework

1365
01:35:50,970 --> 01:35:54,890
for describing systems that are statistical in nature

1366
01:35:55,320 --> 01:35:58,140
but there are also large scale and multivariate

1367
01:35:58,160 --> 01:36:02,690
so you want to think about how many random variables and all interacting in possibly

1368
01:36:02,690 --> 01:36:04,980
quite complex ways

1369
01:36:06,890 --> 01:36:09,510
graphical models are actually

1370
01:36:09,530 --> 01:36:11,760
this is my country by the way

1371
01:36:11,870 --> 01:36:14,710
you wanted to make people hear me properly

1372
01:36:14,720 --> 01:36:18,710
OK so actually used and studied in many fields

1373
01:36:18,890 --> 01:36:22,700
of course there are widely used in machine learning but historically at least they were

1374
01:36:22,700 --> 01:36:28,500
used much earlier in other fields primarily in statistical physics to model things like crystals

1375
01:36:28,500 --> 01:36:33,500
and magnets in gas is basically very large systems were lots of things are interacting

1376
01:36:34,060 --> 01:36:37,910
in it's only more recently they have proven very useful in other fields of of

1377
01:36:37,920 --> 01:36:40,000
engineering and computer science so

1378
01:36:40,020 --> 01:36:42,990
i'll talk a bit about applications in computer vision

1379
01:36:43,000 --> 01:36:45,490
many applications in machine learning

1380
01:36:45,510 --> 01:36:49,080
lots of bioinformatics and computational biology

1381
01:36:49,090 --> 01:36:54,170
and also to sort of illustrate other applications that you might not be aware of

1382
01:36:54,210 --> 01:36:59,610
but there are very relevant given you're using computers and wireless devices all talk about

1383
01:36:59,610 --> 01:37:03,800
about how graphical models play a role in communication systems

1384
01:37:05,620 --> 01:37:10,420
some broad questions before we get into details

1385
01:37:10,420 --> 01:37:13,320
i think it's useful to think there's is there are several kinds of questions or

1386
01:37:13,320 --> 01:37:18,260
issues to think about when you're considering using a graphical model

1387
01:37:18,270 --> 01:37:21,050
and will get into a bit of detail on each of these

1388
01:37:21,080 --> 01:37:25,210
the first caller representational issues

1389
01:37:25,260 --> 01:37:29,860
so it's really an issue of you're given some phenomenon might be an image it

1390
01:37:29,860 --> 01:37:31,170
might be a text database

1391
01:37:31,570 --> 01:37:34,080
you might be trying to track vehicle

1392
01:37:34,120 --> 01:37:38,950
what you really want to understand is what graphical models are useful for capturing or

1393
01:37:38,950 --> 01:37:42,460
modelling the particular phenomenon that you are interested in

1394
01:37:42,490 --> 01:37:47,620
so it's really representational issues trying to understand how does what classes of models are

1395
01:37:47,620 --> 01:37:50,590
useful for what purposes

1396
01:37:50,610 --> 01:37:54,490
basically there is a tautology that no model can be good for everything

1397
01:37:54,580 --> 01:37:59,210
if someone tells you this model is good for everything they're lying to you it's

1398
01:37:59,240 --> 01:38:01,110
probably useless in fact

1399
01:38:01,270 --> 01:38:05,660
models are generally good for specific purposes but you need to understand what the sort

1400
01:38:05,660 --> 01:38:08,710
of trade-offs between different models are

1401
01:38:08,730 --> 01:38:13,860
there are also statistical issues with these models they are essentially statistical models for

1402
01:38:13,860 --> 01:38:20,240
fitting random variables probabilistic systems and so sam spoke about one important issues is really

1403
01:38:20,240 --> 01:38:21,490
that of inference

1404
01:38:21,520 --> 01:38:25,480
at a high level you want to think about this is how you move from

1405
01:38:25,480 --> 01:38:30,110
data you observing some data in the real world and you like to somehow on

1406
01:38:30,110 --> 01:38:34,200
the basis of measurements you'd like to make inferences you'd like to draw conclusions about

1407
01:38:34,200 --> 01:38:38,900
some underlying hidden phenomenon and i'll give you some examples of that in the next

1408
01:38:38,900 --> 01:38:40,450
few slides

1409
01:38:40,510 --> 01:38:45,710
sam also spoke about there's issues of how you fit parameters how do you choose

1410
01:38:45,710 --> 01:38:47,820
the best model to fit your data

1411
01:38:47,830 --> 01:38:52,210
and somewhat more broadly the question of model selection how do you actually choose the

1412
01:38:52,210 --> 01:38:54,880
class of models it's appropriate

1413
01:38:54,890 --> 01:38:59,640
this is the third sort of interrelated issues is really computational one

1414
01:39:01,580 --> 01:39:04,280
that has to do with the fact is as i mentioned these models are typically

1415
01:39:04,280 --> 01:39:05,750
very large scale

1416
01:39:05,760 --> 01:39:11,270
you know interesting things with one two or three subcomponents interesting things with hundreds of

1417
01:39:11,270 --> 01:39:18,950
thousands possibly millions of interacting components so computation issues of storage and efficiency really become

1418
01:39:18,950 --> 01:39:22,880
critical and so we're going to see is that the graphical models really help to

1419
01:39:22,880 --> 01:39:28,040
clarify some of the links there some very deep a nice connections very powerful connections

1420
01:39:28,040 --> 01:39:33,450
between the structure of the graph that you use sand was mentioning last time chains

1421
01:39:33,450 --> 01:39:36,440
and trees will be talking about somewhat more general graphs

1422
01:39:36,530 --> 01:39:40,950
and we'll see the connections between the structure and sort of what the inherent computational

1423
01:39:40,950 --> 01:39:44,270
complexity of applying using these models is

1424
01:39:44,280 --> 01:39:48,090
so anyway

1425
01:39:48,120 --> 01:39:53,090
feel free to jump in with questions whenever you feel so inclined

1426
01:39:53,120 --> 01:39:54,900
do you think about speakers

1427
01:39:54,910 --> 01:39:58,940
you should try and control your speakers somewhat this is what i tell my students

1428
01:39:58,940 --> 01:40:02,270
if you speak go too quickly then you should throw questions in the way to

1429
01:40:02,270 --> 01:40:06,090
slow them down if you speak goes too slowly then you should fall asleep and

1430
01:40:06,510 --> 01:40:10,690
and start making noises that encourages people to go quickly

1431
01:40:10,730 --> 01:40:18,700
OK so this is just an outline again part of this is actually piggy-backing on

1432
01:40:18,700 --> 01:40:22,260
on what sam spoke about so i'm going to go through this part of it

1433
01:40:22,270 --> 01:40:28,350
a bit more quickly than i i would normally in particular this message passing samarati

1434
01:40:28,350 --> 01:40:32,890
spoke about on trees i'm actually going presented from a slightly different perspective so you'll

1435
01:40:32,890 --> 01:40:36,520
be seeing the same material but from a somewhat different view and i think that

1436
01:40:36,520 --> 01:40:40,010
can be useful to it often useful to see things from different points of view

1437
01:40:40,010 --> 01:40:41,830
it gives you a deeper understanding

1438
01:40:41,830 --> 01:40:45,980
can values we discarding the so basically what we're getting rid of this

1439
01:40:45,990 --> 01:40:48,920
it would be to add diagonal term

1440
01:40:49,030 --> 01:40:53,870
two the covariance matrix which would actually eliminate all those negative and these positives as

1441
01:40:54,670 --> 01:40:57,920
and then it would just leave by adding the diagonal terms with and i can

1442
01:40:58,280 --> 01:41:01,820
with the value of about there it would just eliminate all that i would have

1443
01:41:01,820 --> 01:41:06,070
a positive definite covariance matrix so it saying the negative and this is in the

1444
01:41:06,070 --> 01:41:11,300
noise of but it is a difficult thing to interpret and it isn't correct

1445
01:41:11,310 --> 01:41:15,610
and it comes up in these situations where you to specify a distance matrix or

1446
01:41:15,610 --> 01:41:21,820
dissimilarity which is not necessarily euclidean and you doesn't necessarily conform to things the euclidean

1447
01:41:21,820 --> 01:41:24,540
distance should conform to

1448
01:41:24,560 --> 01:41:26,320
so be careful

1449
01:41:27,070 --> 01:41:29,970
you can see and habitually statisticians

1450
01:41:30,030 --> 01:41:32,350
you have ignored these

1451
01:41:32,410 --> 01:41:34,580
two classical scale

1452
01:41:35,680 --> 01:41:39,600
in practice in machine learning with actually typically being a lot more worried about them

1453
01:41:39,600 --> 01:41:43,480
and also say why that is in the moment it relates to sort of kernel

1454
01:41:43,480 --> 01:41:45,190
methods and so on and so forth

1455
01:41:45,330 --> 01:41:49,690
OK so here's the reconstructions the distance matrix

1456
01:41:49,730 --> 01:41:53,530
the left is the original distance matrix and on the right is the reconstructed distance

1457
01:41:55,700 --> 01:41:57,940
now you can see that they look pretty good

1458
01:41:57,980 --> 01:42:02,080
there are some i think down here for example

1459
01:42:02,140 --> 01:42:06,340
so i thought so in something that i mean this structure is broadly speaking

1460
01:42:07,350 --> 01:42:12,530
so we've got a good reconstruction in the distance matrix using only two dimensions using

1461
01:42:12,530 --> 01:42:16,200
classical scaling approach

1462
01:42:18,160 --> 01:42:22,120
you can use the similarity you can either start from the similarity in the eigenvalue

1463
01:42:22,120 --> 01:42:24,800
problem directly online at all

1464
01:42:24,810 --> 01:42:30,220
you can take distance and convert using this the covariance interpretation

1465
01:42:30,270 --> 01:42:37,000
be aware of similarity must be positive semi definite for the distance to be euclidean

1466
01:42:37,060 --> 01:42:42,570
why we can immediately can see positive definite is sufficient from the covariance interpretation well

1467
01:42:42,570 --> 01:42:46,810
if it is positive definite we know that this the similarity positive definite we know

1468
01:42:46,810 --> 01:42:49,800
that the could that distances must be

1469
01:42:49,810 --> 01:42:54,720
valid because the covariance interpretation they were expected distances which are going to be valid

1470
01:42:55,900 --> 01:43:01,440
the expected squared distances but then to see the proof that this is euclidean nature

1471
01:43:01,440 --> 01:43:06,120
between the similarity which is positive definite and distance pages see my is a lot

1472
01:43:06,120 --> 01:43:10,810
more involved in the my covariance interpretation which is the sufficient condition is not necessarily

1473
01:43:10,990 --> 01:43:14,960
a necessary condition but i think it gives you much better intuition as so what's

1474
01:43:14,960 --> 01:43:19,020
going on between these included in distances and this covariance matrix

1475
01:43:19,070 --> 01:43:22,530
OK so

1476
01:43:22,540 --> 01:43:26,400
the point in doing this background i mean you probably not seen many papers about

1477
01:43:26,400 --> 01:43:30,440
classical scaling or anything else in machine learning well why

1478
01:43:30,450 --> 01:43:33,570
well you have actually perhaps but they don't tend to

1479
01:43:33,580 --> 01:43:37,320
highlight the fact that what they're doing is really classical scaling what the history of

1480
01:43:37,320 --> 01:43:40,830
it is what these things mean and so in some sense

1481
01:43:40,850 --> 01:43:43,020
this part of the talk up till now

1482
01:43:43,030 --> 01:43:46,950
has really been about trying to give you a background in classical scaling which tries

1483
01:43:46,950 --> 01:43:48,940
to let you understand a lot of

1484
01:43:48,980 --> 01:43:53,090
methods for dimension reduction that we see

1485
01:43:53,150 --> 01:43:57,470
i have been developed in the last few years a machine learning

1486
01:43:58,770 --> 01:44:03,550
here's the cluster similarities for vector data for you seem mercer kernels with colin campbell

1487
01:44:03,910 --> 01:44:06,320
and everything else is you

1488
01:44:06,330 --> 01:44:09,400
so all mercer kernels are positive semi definite

1489
01:44:09,420 --> 01:44:11,040
so all valid

1490
01:44:11,050 --> 01:44:12,700
covariance functions

1491
01:44:12,740 --> 01:44:16,870
so for example the squared exponential kernel the RBF against

1492
01:44:16,940 --> 01:44:19,370
has this form

1493
01:44:19,420 --> 01:44:24,250
if we use this is a similarity matrix it leads to kernel like value problem

1494
01:44:24,270 --> 01:44:26,500
and it's known as kernel PCA

1495
01:44:26,600 --> 01:44:28,920
but it is also classical scale

1496
01:44:28,960 --> 01:44:32,580
the elegant thing about the kernel interpretation of PCA

1497
01:44:33,330 --> 01:44:36,700
if you think about remember that kernel matrix i showed you before

1498
01:44:36,710 --> 01:44:39,140
it was the center in the product matrix

1499
01:44:39,150 --> 01:44:42,740
so that's a linear kernel PCA just PCA

1500
01:44:42,800 --> 01:44:45,580
here we're doing non-linear kernel PCA

1501
01:44:45,590 --> 01:44:48,490
so the good thing about kernel PCA which are not really going to talk about

1502
01:44:48,490 --> 01:44:52,080
is that it gives you a mapping from the data space to latent space is

1503
01:44:52,080 --> 01:44:56,680
well in none of these approaches we mention mapping so far there is one associated

1504
01:44:56,680 --> 01:44:58,400
with PCA but

1505
01:44:58,420 --> 01:45:02,140
in general is not with this distance approach

1506
01:45:02,210 --> 01:45:04,280
i can now give you mapping

1507
01:45:05,180 --> 01:45:09,290
any point reasoning there are many point in sort of the cities don't have y

1508
01:45:09,350 --> 01:45:12,920
point so i can't even give you a white point next point map

1509
01:45:12,930 --> 01:45:17,890
the concept doesn't exist and if you've got major distances concept of mapping from y

1510
01:45:17,890 --> 01:45:21,310
to x doesn't exist finding kernel PCA

1511
01:45:21,320 --> 01:45:24,900
and constructing my similarity

1512
01:45:24,920 --> 01:45:26,750
on the white space

1513
01:45:26,810 --> 01:45:29,890
and now i can think of a mapping from the white space to the x

1514
01:45:29,890 --> 01:45:32,430
space as well so that exists

1515
01:45:32,440 --> 01:45:35,940
and so i get that free out of the algorithm and the algorithm is known

1516
01:45:35,940 --> 01:45:38,750
as kernel PCA

1517
01:45:38,810 --> 01:45:41,360
i want to show you next is why

1518
01:45:41,420 --> 01:45:42,490
you should never

1519
01:45:42,500 --> 01:45:47,720
use kernel PCA for dimensionality reduction it's an interesting technique it's useful technique

1520
01:45:47,830 --> 01:45:51,740
but it does not to dimensionality reduction with that can

1521
01:45:51,750 --> 01:45:55,280
you can say that all these methods are type of kernel PCA with this kernel

1522
01:45:55,280 --> 01:46:00,120
and with many other interesting kind of it won't do dimensionality reduction

1523
01:46:00,140 --> 01:46:07,120
so the question is what the equivalent distance associated with this kernel

1524
01:46:07,150 --> 01:46:11,020
so this is the distance we trying to match allied space remember because of a

1525
01:46:11,020 --> 01:46:13,930
classical multidimensional scaling interpretation

1526
01:46:13,940 --> 01:46:16,990
so the equivalent distance if k i i

1527
01:46:17,000 --> 01:46:20,840
class kjj minus two k i j all square roots

1528
01:46:21,740 --> 01:46:25,040
in this kind of if these points are a long way apart relative to the

1529
01:46:25,040 --> 01:46:26,940
length scale

1530
01:46:26,980 --> 01:46:27,750
this guy

1531
01:46:27,780 --> 01:46:29,690
becomes negative and large

1532
01:46:29,710 --> 01:46:32,540
and the result of the kernel is zero

1533
01:46:32,540 --> 01:46:39,000
transitions with probability getting state crime state as prime was one x equals one given

1534
01:46:39,000 --> 01:46:39,880
that you took

1535
01:46:39,920 --> 01:46:45,540
that you were in state one technical staying which is point nine

1536
01:46:45,540 --> 01:46:54,900
OK so it's probably best particles two given that sickles one nickel stay

1537
01:46:54,900 --> 01:47:00,380
conditional probably had some to one of the left hand side

1538
01:47:00,420 --> 01:47:01,860
o point one

1539
01:47:02,000 --> 01:47:05,020
they so here's i'm going to stay at one

1540
01:47:05,040 --> 01:47:09,940
publishers particles to get the same condition is just point one

1541
01:47:09,940 --> 01:47:12,380
OK discount them

1542
01:47:12,420 --> 01:47:17,650
not only cameras missing years in this country between zero one

1543
01:47:31,020 --> 01:47:35,730
brilliant so there are two ways to ensure that you don't get reward one is

1544
01:47:35,730 --> 01:47:40,230
that previously two sons and discount factor last one but roughly right

1545
01:47:41,060 --> 01:47:45,380
with some probability you always will

1546
01:47:45,420 --> 01:47:47,560
transition to testicles two

1547
01:47:47,560 --> 01:47:51,250
so three geometries can again you can show that that the the

1548
01:47:51,270 --> 01:47:54,270
everything ever-rising even with chemicals one here

1549
01:47:54,290 --> 01:48:01,110
we were still finding this case that's another way to get reward

1550
01:48:12,290 --> 01:48:28,850
so so you're you're confused because you say well

1551
01:48:28,860 --> 01:48:33,650
i mean the one i take action but i get the rewards

1552
01:48:33,650 --> 01:48:38,000
based on whether stay in articles water transition icicles to write so you asking why

1553
01:48:38,000 --> 01:48:39,230
the ten

1554
01:48:39,310 --> 01:48:42,920
that rendition but two and i don't

1555
01:48:51,420 --> 01:49:00,980
so if you stay in state schools one in the transition state eagles two

1556
01:49:01,040 --> 01:49:09,460
if you reward ascent

1557
01:49:09,710 --> 01:49:11,250
but it gets to decide

1558
01:49:11,250 --> 01:49:13,000
that's the point

1559
01:49:13,060 --> 01:49:17,810
so you probably is a bit confusing the way that here i do apologize

1560
01:49:17,860 --> 01:49:21,630
i could we define it so that i we get reward two for staying matter

1561
01:49:21,630 --> 01:49:27,000
had no matter where in the cluster different models

1562
01:49:27,920 --> 01:49:32,590
now it's crucial in DP to know how you want to act right because in

1563
01:49:32,590 --> 01:49:34,110
the end my goal is

1564
01:49:34,170 --> 01:49:38,580
how do i access to optimize reward in this model

1565
01:49:38,580 --> 01:49:44,440
OK and act and policy so what they want they have introduced a policy pi

1566
01:49:44,480 --> 01:49:47,710
and this tells me given the current state and

1567
01:49:47,750 --> 01:49:49,460
which action should i take

1568
01:49:49,560 --> 01:49:54,270
it's just the function for every state tells you which actually take that culture policy

1569
01:49:58,330 --> 01:50:02,500
OK so taking notes circle right down pi to policy

1570
01:50:02,500 --> 01:50:07,730
can you see this throughout throughout lecture

1571
01:50:07,750 --> 01:50:11,190
OK so what's the best policy here now OK

1572
01:50:12,960 --> 01:50:14,650
you might notice this is

1573
01:50:18,080 --> 01:50:19,980
you know what

1574
01:50:43,060 --> 01:50:47,310
now i always get reward to for staying

1575
01:50:57,960 --> 01:51:01,980
only were two staying from state one

1576
01:51:01,980 --> 01:51:04,580
what i do that because next slide subsumption

1577
01:51:05,860 --> 01:51:07,440
so this is

1578
01:51:07,480 --> 01:51:10,310
this is the probabilistic finite state automata you

1579
01:51:12,210 --> 01:51:17,150
this is the same but a dynamic time view of showing each vertical slice at

1580
01:51:17,150 --> 01:51:18,360
different time

1581
01:51:18,380 --> 01:51:21,500
OK but to see if you can interpret this correctly the probabilities and so on

1582
01:51:21,520 --> 01:51:24,630
are still saying i deserved unfolded

1583
01:51:24,690 --> 01:51:28,150
the previous model to show the tensions over time

1584
01:51:28,790 --> 01:51:30,900
so again one

1585
01:51:30,900 --> 01:51:34,980
you take the actions change uterus against a to take action state

1586
01:51:35,000 --> 01:51:39,810
with point nine you which states one point one dollar line against a two

1587
01:51:39,830 --> 01:51:44,230
only give rewards of two for staying illegally whatever changes state one

1588
01:51:44,250 --> 01:51:47,420
you only get one zero state

1589
01:51:47,440 --> 01:51:51,330
but stains

1590
01:52:10,210 --> 01:52:14,560
now again we must define workers and optimize so gamma equals one point o

1591
01:52:14,580 --> 01:52:15,770
no discount

1592
01:52:15,880 --> 01:52:17,770
west seattle policy

1593
01:52:17,830 --> 01:52:21,500
five day one which i do

1594
01:52:21,500 --> 01:52:23,420
chemicals one not discounting

1595
01:52:23,420 --> 01:52:28,040
the sum of all future rewards

1596
01:52:28,060 --> 01:52:32,810
yeah i don't calculated but i think staying should give you enough reward expectation that

1597
01:52:32,810 --> 01:52:34,750
the best way to go

1598
01:52:34,750 --> 01:52:39,590
OK time and stayed till what's best action

1599
01:52:39,610 --> 01:52:43,460
OK you know it doesn't matter to zero here

1600
01:52:43,460 --> 01:52:48,310
OK but the point is a policy tells you state what actions now

1601
01:52:48,380 --> 01:52:52,670
it point one i really don't care much for future now what's the best policy

1602
01:52:52,670 --> 01:52:56,890
being done by hundreds thousands of images so it it's definitely a good deal you

1603
01:52:56,890 --> 01:53:00,700
should have cashing in their it also is really nice because it gives you

1604
01:53:01,110 --> 01:53:05,690
reduce query latency kept time for cash is much lower than the time for to

1605
01:53:05,700 --> 01:53:07,770
actually go out all the index servers

1606
01:53:07,770 --> 01:53:10,670
you do ranking and retrieval and return results

1607
01:53:10,690 --> 01:53:13,870
and it also tends to be the queries that hit in cache tend to be

1608
01:53:13,870 --> 01:53:16,970
the more expensive queries tend to be ones where

1609
01:53:17,030 --> 01:53:19,440
you know more popular words in them or

1610
01:53:19,450 --> 01:53:22,920
popular phrases that are

1611
01:53:24,250 --> 01:53:27,790
and they have a lot of documents to score so

1612
01:53:27,840 --> 01:53:31,400
even more than just casual read the cost about

1613
01:53:31,440 --> 01:53:35,140
i agree that hit me cash is larger than just the catcher

1614
01:53:35,520 --> 01:53:39,420
what is going to be aware of when you introduce cash the system is that

1615
01:53:39,420 --> 01:53:44,450
you can get big latency spikes or capacity hits when the cache is flushed for

1616
01:53:44,450 --> 01:53:45,960
example or when you

1617
01:53:46,000 --> 01:53:48,460
switchover index data two

1618
01:53:48,740 --> 01:53:51,980
so the cash no longer applies and you end up to cache missus

1619
01:53:51,990 --> 01:53:55,880
essentially all your cash rate will drop to zero and then start to work its

1620
01:53:55,880 --> 01:53:56,830
way steadily

1621
01:53:56,860 --> 01:54:02,390
back up but in the moments drops after drops to zero you can have a

1622
01:54:02,710 --> 01:54:06,480
kind of operational disasters they have to be kind of war

1623
01:54:06,670 --> 01:54:12,730
OK so the crawling system around you know ninety eight to ninety nine with a

1624
01:54:12,730 --> 01:54:15,270
fairly simple batch oriented crawling system

1625
01:54:15,310 --> 01:54:19,140
the idea is you start with a few else actually it turns out you need

1626
01:54:19,150 --> 01:54:20,320
remarkably few

1627
01:54:20,330 --> 01:54:23,730
ctrl because most things can be reached from

1628
01:54:23,770 --> 01:54:28,920
just places new cross some pages extract new links from those pages you into a

1629
01:54:28,920 --> 01:54:33,720
q and you stop when you have decided that you've your budget of whatever you

1630
01:54:33,720 --> 01:54:34,830
can index

1631
01:54:34,860 --> 01:54:39,130
there are a lot of concerns and only calling system can focus on them too

1632
01:54:39,130 --> 01:54:42,210
much but you did not hit any site too hard

1633
01:54:42,240 --> 01:54:47,230
you need to prioritize among the uncrawled pages so that if you have

1634
01:54:47,410 --> 01:54:49,290
it's been available you facts

1635
01:54:49,300 --> 01:54:52,830
something that you think is more useful than a random page

1636
01:54:52,850 --> 01:54:58,350
you need some way of maintaining this uncrawled URL q and efficiently because you're for

1637
01:54:58,350 --> 01:55:01,520
every page crawl your extracting you know perhaps twenty links

1638
01:55:01,560 --> 01:55:05,310
and having to insert them into the cube and you don't want to do secret

1639
01:55:05,310 --> 01:55:08,870
one of those and you have to have some way of dealing with machine failures

1640
01:55:08,890 --> 01:55:11,560
in the crawling system

1641
01:55:11,580 --> 01:55:13,270
the indexing system

1642
01:55:13,280 --> 01:55:16,310
in those days was a fairly simple batch

1643
01:55:16,330 --> 01:55:19,730
indexing system was based on fairly simple

1644
01:55:19,730 --> 01:55:25,300
the tools there wasn't really any check pointing so machine failures were pretty painful in

1645
01:55:25,300 --> 01:55:26,310
those days

1646
01:55:26,320 --> 01:55:33,780
the and not only did early machine that have ECC memory that parity which is

1647
01:55:33,820 --> 01:55:35,150
very painful

1648
01:55:35,160 --> 01:55:38,220
if you're trying to actually use

1649
01:55:38,220 --> 01:55:42,330
in particular if you sort of terrified of data on the machine without parity

1650
01:55:42,390 --> 01:55:44,400
and the mostly sorted

1651
01:55:44,410 --> 01:55:47,830
if you sort it again it's mostly sorted by the way

1652
01:55:47,980 --> 01:55:54,050
one of my colleagues like this to programming with adversarial memory

1653
01:55:54,070 --> 01:55:59,170
and so one of the things we did to help employers from the adversarial memory

1654
01:55:59,170 --> 01:56:02,390
was we developed a little file system abstraction that had

1655
01:56:02,440 --> 01:56:06,750
ability to write records and checksum some them women insert sort of re synchronisation markers

1656
01:56:06,750 --> 01:56:07,900
and there's so very if few

1657
01:56:07,990 --> 01:56:13,220
it would insert checksums the the record he could know if it was corrupted and

1658
01:56:13,220 --> 01:56:17,650
you could also then we synchronize to the next available record with every single innovation

1659
01:56:18,630 --> 01:56:23,690
and ignore the crappy records in

1660
01:56:23,720 --> 01:56:27,760
one of the nice things about web searches enough data redundancy in the world that

1661
01:56:27,760 --> 01:56:30,490
if you drop you know document here there

1662
01:56:30,500 --> 01:56:33,550
due to corruption is not a big a deal

1663
01:56:33,600 --> 01:56:34,870
and i

1664
01:56:34,910 --> 01:56:36,750
was something really important

1665
01:56:36,750 --> 01:56:45,220
so index updates in those days the basic while they happen infrequently thank goodness because

1666
01:56:45,270 --> 01:56:49,880
there a lot of work they happen about once per month so you basically wait

1667
01:56:49,880 --> 01:56:54,890
until traffic flow you take some replicas offline you copy new index replicas and then

1668
01:56:54,890 --> 01:56:58,800
you start new front ends pointing up these replicas and

1669
01:56:58,810 --> 01:57:02,870
person traffic from there and he gradually migrated more and more machines to serving the

1670
01:57:02,880 --> 01:57:05,670
no april and next that of the mark one

1671
01:57:05,740 --> 01:57:09,750
one of the things that important in this based index is you want to use

1672
01:57:09,750 --> 01:57:12,060
the outer part of disk is faster

1673
01:57:12,940 --> 01:57:16,860
the index whichever process is actually a little bit more complicated you start with you

1674
01:57:16,860 --> 01:57:29,470
on the right these things

1675
01:57:32,190 --> 01:57:35,240
usually about

1676
01:57:35,260 --> 01:57:42,440
the problem of c

1677
01:57:42,440 --> 01:57:46,050
number one seems to be what

1678
01:57:46,070 --> 01:57:49,550
it's can interesting just read

1679
01:57:55,170 --> 01:58:02,280
it lies

1680
01:58:07,530 --> 01:58:11,670
very of why small then y

1681
01:58:11,860 --> 01:58:13,280
it just

1682
01:58:34,130 --> 01:58:45,400
that's it that

1683
01:58:53,360 --> 01:59:00,970
there is low

1684
01:59:01,010 --> 01:59:03,470
the case

1685
01:59:08,900 --> 01:59:15,940
the representation of

1686
01:59:15,990 --> 01:59:18,970
thank you one

1687
01:59:18,990 --> 01:59:21,490
on the distribution on

1688
01:59:38,170 --> 01:59:41,300
the red

1689
01:59:41,530 --> 01:59:45,150
well one

1690
01:59:45,820 --> 01:59:49,300
all right

1691
01:59:52,010 --> 02:00:00,490
so small

1692
02:00:04,940 --> 02:00:06,990
or just under

1693
02:00:11,010 --> 02:00:12,510
all right

1694
02:00:12,530 --> 02:00:19,340
when we get through

1695
02:00:22,740 --> 02:00:25,650
is there

1696
02:00:26,190 --> 02:00:30,720
that's going to and

1697
02:00:31,880 --> 02:00:44,300
was red

1698
02:00:46,420 --> 02:00:51,720
so long as well

1699
02:00:55,170 --> 02:00:59,340
it belongs to me

1700
02:00:59,360 --> 02:01:01,090
just a small

1701
02:01:01,110 --> 02:01:06,220
number coordinates we information about what else

1702
02:01:06,240 --> 02:01:10,870
and that's what i need to be in the world

1703
02:01:12,840 --> 02:01:14,550
he netherlands

1704
02:01:16,990 --> 02:01:24,340
with the president of the parameters that describe the operations of

1705
02:01:24,380 --> 02:01:25,960
the problem

1706
02:01:25,970 --> 02:01:28,440
the median

1707
02:01:28,470 --> 02:01:29,720
from there

1708
02:01:37,460 --> 02:01:41,170
after change

1709
02:01:42,360 --> 02:01:45,590
what happened to be

1710
02:01:45,610 --> 02:01:51,860
like a flash of light it

1711
02:01:53,970 --> 02:01:57,510
next let's do

1712
02:01:57,510 --> 02:02:02,510
that is the most of the day by c

1713
02:02:02,530 --> 02:02:05,780
the result

1714
02:02:15,570 --> 02:02:16,050
this is

1715
02:02:18,630 --> 02:02:29,320
from the life of around for one one

1716
02:02:31,970 --> 02:02:35,280
first of all the traditions

1717
02:02:35,300 --> 02:02:37,260
it is often easier

1718
02:02:40,760 --> 02:02:46,360
the property that look like

1719
02:02:46,380 --> 02:02:47,740
so what would the

1720
02:02:47,760 --> 02:02:50,940
like today

1721
02:02:56,200 --> 02:02:57,150
the above


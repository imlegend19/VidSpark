1
00:00:00,000 --> 00:00:01,320
so now we have

2
00:00:01,490 --> 00:00:06,130
a difficult optimisation problem we want to minimize this function

3
00:00:06,150 --> 00:00:08,710
which is the approximation error

4
00:00:08,720 --> 00:00:10,850
expectation meaning

5
00:00:10,880 --> 00:00:17,010
and average over the whole of the dataset i hold data distribution and we have

6
00:00:17,010 --> 00:00:22,580
this is a constrained optimisation optimisation problem because we say that w

7
00:00:22,860 --> 00:00:26,400
has you need to know

8
00:00:26,540 --> 00:00:28,450
so the

9
00:00:28,460 --> 00:00:30,420
the information on own

10
00:00:30,450 --> 00:00:32,340
do this is given here

11
00:00:32,370 --> 00:00:37,020
so this was written by michael so i'm quite sure if i understand correctly myself

12
00:00:37,460 --> 00:00:39,630
but so let's try to go through it may be

13
00:00:39,670 --> 00:00:43,630
we can so the point is that

14
00:00:43,680 --> 00:00:49,720
first we define we make a change of variables basically instead of considering the variable

15
00:00:50,710 --> 00:00:52,900
we look at the orthogonal directions

16
00:00:52,970 --> 00:00:56,750
well it's simple here especially because we have only sold in two dimensions so once

17
00:00:56,750 --> 00:00:59,500
we define one the the dimension of w we can be

18
00:00:59,970 --> 00:01:02,740
uniquely define the orthogonal direction

19
00:01:03,050 --> 00:01:06,850
so now we transform this objective function

20
00:01:10,850 --> 00:01:14,280
only fine

21
00:01:14,280 --> 00:01:17,070
yes yes we express x

22
00:01:18,670 --> 00:01:21,250
so yes we expect it express x

23
00:01:21,260 --> 00:01:25,850
as the sum of the projections onto w and u

24
00:01:25,870 --> 00:01:30,200
because well that is equal to x because we all have two dimensions and then

25
00:01:30,210 --> 00:01:35,480
we have two orthogonal projections and then the approximation is just as given by the

26
00:01:35,550 --> 00:01:38,350
idea by the definition

27
00:01:38,360 --> 00:01:42,040
and so this and then these two terms cancel out and what we have is

28
00:01:42,040 --> 00:01:44,740
is this kind of thing now

29
00:01:44,750 --> 00:01:47,030
but just to express this no

30
00:01:47,130 --> 00:01:52,650
well known of vector is the square of the normal vector is simply the transpose

31
00:01:52,650 --> 00:01:56,370
of the vector times the vector itself so he was forced to that an object

32
00:01:56,370 --> 00:01:59,840
vector itself the point is that is that

33
00:01:59,920 --> 00:02:02,720
well first of all

34
00:02:03,350 --> 00:02:06,460
well we

35
00:02:06,480 --> 00:02:10,540
we try change the value change the order of these things

36
00:02:10,570 --> 00:02:15,630
i wonder if this is quite quite correct well

37
00:02:16,110 --> 00:02:26,840
OK so now we we

38
00:02:28,070 --> 00:02:30,590
communities two terms here

39
00:02:30,590 --> 00:02:34,690
and then we take the the expectation operator in here in the middle we can

40
00:02:34,690 --> 00:02:39,330
do that because you is you is a constant and random quantity so then what

41
00:02:39,330 --> 00:02:44,190
you get is the expectation of o x x x x transpose here in the

42
00:02:50,000 --> 00:02:52,110
yes i saw

43
00:02:52,130 --> 00:02:56,570
i don't like it but i i i have to fast that's correct i think

44
00:02:56,570 --> 00:02:57,480
there's an error

45
00:02:59,550 --> 00:03:12,290
yes some of these kinds of the i

46
00:03:12,310 --> 00:03:14,880
i somehow got the impression that

47
00:03:20,050 --> 00:03:23,900
OK yes so it has to go somewhere

48
00:03:25,650 --> 00:03:27,210
so that this

49
00:03:27,230 --> 00:03:29,730
is equal to x times

50
00:03:33,540 --> 00:03:36,500
t x

51
00:03:36,520 --> 00:03:39,070
and then we come in those x t

52
00:03:39,090 --> 00:03:40,670
thank you

53
00:03:40,690 --> 00:03:44,110
and then this thing will be

54
00:03:45,320 --> 00:03:47,610
multiply by

55
00:03:47,650 --> 00:03:51,750
you are ideas so now these things here cancel each other out

56
00:03:51,750 --> 00:03:53,250
conductivity of air

57
00:03:53,270 --> 00:03:54,670
so poor

58
00:03:54,750 --> 00:03:57,230
that he will stay there

59
00:03:57,310 --> 00:04:03,460
four hours

60
00:04:03,460 --> 00:04:05,060
and then i will do

61
00:04:05,080 --> 00:04:08,980
i will create ions in the vicinity of the electroscope

62
00:04:09,040 --> 00:04:11,080
let's first put some

63
00:04:11,080 --> 00:04:13,480
charge only electroscope

64
00:04:13,520 --> 00:04:18,660
if you're glass rolled

65
00:04:18,710 --> 00:04:26,060
outputs in charge on it

66
00:04:26,080 --> 00:04:30,210
OK that's sort of charge

67
00:04:30,270 --> 00:04:31,670
and the

68
00:04:31,850 --> 00:04:35,870
air is quite dry

69
00:04:36,960 --> 00:04:39,120
very very small

70
00:04:39,170 --> 00:04:39,850
and so

71
00:04:39,870 --> 00:04:42,460
b charts cannot go off through the air

72
00:04:42,520 --> 00:04:45,100
the surrounding studio

73
00:04:45,250 --> 00:04:48,710
now i'm going to create ions thereby meeting the

74
00:04:48,710 --> 00:04:50,520
and i decided to do that

75
00:04:50,580 --> 00:04:55,750
with the candle because the candle is very romantic as we all know

76
00:04:55,810 --> 00:04:59,690
you have the scandal

77
00:04:59,790 --> 00:05:02,670
colwell well the charges holding

78
00:05:02,790 --> 00:05:04,730
here's my candle

79
00:05:04,830 --> 00:05:06,770
now we're going to kendall

80
00:05:06,770 --> 00:05:09,230
well maybe twenty centimetres from

81
00:05:11,120 --> 00:05:14,620
we're going to look at it really going

82
00:05:14,690 --> 00:05:17,140
about fifteen centimeters away

83
00:05:17,170 --> 00:05:19,120
i think my can way

84
00:05:19,140 --> 00:05:21,640
stops again

85
00:05:21,690 --> 00:05:25,310
although affected by ionizing the air there

86
00:05:25,310 --> 00:05:29,830
creating free electrons as well as i was unable to participate now

87
00:05:29,850 --> 00:05:33,670
in the current and the charge can flow away from the electroscope

88
00:05:33,710 --> 00:05:35,500
were because the

89
00:05:35,520 --> 00:05:37,520
on the activity now is always high

90
00:05:37,580 --> 00:05:39,060
but again

91
00:05:39,100 --> 00:05:41,190
it's not

92
00:05:41,310 --> 00:05:45,350
from the eyes how important

93
00:05:45,370 --> 00:05:47,230
the temperature is

94
00:05:47,230 --> 00:05:49,170
in this case

95
00:05:49,250 --> 00:05:51,000
the presence

96
00:05:51,020 --> 00:05:59,440
of the ions in the air

97
00:05:59,440 --> 00:06:00,690
if i have a clear

98
00:06:00,690 --> 00:06:03,560
distilled water

99
00:06:03,580 --> 00:06:06,500
i mean clean water i don't mean the stuff that you get

100
00:06:08,230 --> 00:06:11,350
let alone that i mean the stuff that is in the charles river and clean

101
00:06:13,110 --> 00:06:15,080
has a ph of seven

102
00:06:15,290 --> 00:06:18,060
means one out of ten to to seven

103
00:06:18,100 --> 00:06:21,540
of the water molecules is iron age plus

104
00:06:21,620 --> 00:06:25,170
and always mind

105
00:06:25,230 --> 00:06:27,770
we call it emitted by the way

106
00:06:27,770 --> 00:06:31,020
it is not the result of the free electrons

107
00:06:31,140 --> 00:06:33,350
but really the result of these

108
00:06:33,400 --> 00:06:34,420
eight plus

109
00:06:34,460 --> 00:06:37,830
and always minds i one of the cases were by not

110
00:06:37,890 --> 00:06:39,750
electrons are made major

111
00:06:39,770 --> 00:06:42,560
responsibility for the current

112
00:06:42,580 --> 00:06:47,140
if i have three percent of salt in terms of weight

113
00:06:47,190 --> 00:06:50,830
and all that sold will ionize so you get

114
00:06:50,870 --> 00:06:54,420
so to employers and cl mind

115
00:06:54,420 --> 00:06:58,940
you increase the number of lines by an enormous factor

116
00:06:58,980 --> 00:07:02,440
and so the conductivity will store up

117
00:07:02,460 --> 00:07:04,540
by a factor of three hundred thousand

118
00:07:04,540 --> 00:07:09,920
one of two million because you increase the ions by denmark

119
00:07:09,940 --> 00:07:12,620
so it's no surprise that for you

120
00:07:12,640 --> 00:07:13,830
that the

121
00:07:13,890 --> 00:07:15,440
conductivity of

122
00:07:15,440 --> 00:07:19,790
seawater is a million times higher think about a million times higher

123
00:07:19,810 --> 00:07:21,230
then the conductivity

124
00:07:21,230 --> 00:07:23,290
of distilled water

125
00:07:23,290 --> 00:07:24,710
i would like to give you the

126
00:07:24,710 --> 00:07:26,040
number four

127
00:07:27,820 --> 00:07:30,020
this is distilled water

128
00:07:30,230 --> 00:07:36,480
it is about two times

129
00:07:36,480 --> 00:07:40,480
ten to the fifth of may use

130
00:07:40,540 --> 00:07:46,210
that is the

131
00:07:48,630 --> 00:07:50,390
two times than thirty

132
00:07:50,440 --> 00:07:55,230
five metres

133
00:07:55,250 --> 00:08:01,270
i have here a bucket of distilled water

134
00:08:01,290 --> 00:08:03,750
o make drawing for you

135
00:08:03,810 --> 00:08:09,270
on the blackboard there

136
00:08:09,350 --> 00:08:12,290
here's the bucket

137
00:08:12,350 --> 00:08:15,460
distilled water

138
00:08:15,460 --> 00:08:18,310
and in there

139
00:08:18,350 --> 00:08:19,790
the couple played

140
00:08:19,790 --> 00:08:21,770
another couple played

141
00:08:21,830 --> 00:08:24,710
was the light bulb

142
00:08:24,730 --> 00:08:31,810
and this will go straight

143
00:08:31,980 --> 00:08:35,000
three outlets

144
00:08:35,020 --> 00:08:38,810
it on the ten

145
00:08:38,830 --> 00:08:41,480
this light

146
00:08:41,480 --> 00:08:44,420
eight hundred resistance when it is hot

147
00:08:44,620 --> 00:08:51,060
you see the light bulb here

148
00:08:51,310 --> 00:09:00,420
you can calculate what this resistance between the plates that you have all the tools

149
00:09:01,250 --> 00:09:02,710
you know the distance

150
00:09:02,730 --> 00:09:04,230
about twenty centimetres

151
00:09:04,250 --> 00:09:08,310
are you know the surface area of the plates because remember the resistance is inversely

152
00:09:08,310 --> 00:09:11,660
proportional with eight you have to take that into account

153
00:09:11,710 --> 00:09:12,660
you're taking

154
00:09:12,670 --> 00:09:15,040
resistivity of water into account

155
00:09:15,100 --> 00:09:16,770
it's so trivial calculation

156
00:09:16,770 --> 00:09:20,790
you can calculate what the resistances of this portion

157
00:09:20,810 --> 00:09:21,940
and i found

158
00:09:22,040 --> 00:09:23,940
this resistance here

159
00:09:23,980 --> 00:09:26,330
is about two men on

160
00:09:26,980 --> 00:09:30,250
millions of years

161
00:09:30,290 --> 00:09:33,420
so when i put it into the wall

162
00:09:33,480 --> 00:09:37,870
the current that flows extremely low because it has to go forty eight hundred homes

163
00:09:37,890 --> 00:09:39,580
and the two mega

164
00:09:39,600 --> 00:09:44,330
so you won't see anything like will not show any light

165
00:09:46,060 --> 00:09:47,730
if five

166
00:09:47,770 --> 00:09:52,520
what sort here if i really meant to put three percent weight sold in here

167
00:09:52,520 --> 00:09:54,080
then this too may go home

168
00:09:54,140 --> 00:09:56,310
will go down to two on

169
00:09:56,350 --> 00:09:57,600
a million times

170
00:10:00,980 --> 00:10:04,730
the light bulb will be happy like claiming i type because two wrongs here

171
00:10:04,790 --> 00:10:07,940
forty eight hundred two insignificant

172
00:10:07,980 --> 00:10:09,660
and this is what i want to

173
00:10:09,690 --> 00:10:13,690
demonstrate to you know enormous importance of

174
00:10:13,710 --> 00:10:17,620
increasing ions i increase ions you buy in the air

175
00:10:17,640 --> 00:10:19,500
now i'm going to increase

176
00:10:19,560 --> 00:10:20,690
the ions by

177
00:10:20,710 --> 00:10:23,500
having sold

178
00:10:23,670 --> 00:10:26,210
so the first thing that i will do

179
00:10:26,270 --> 00:10:29,790
it is i will

180
00:10:29,790 --> 00:10:31,080
link is here

181
00:10:31,120 --> 00:10:34,520
there's a light bulb

182
00:10:34,560 --> 00:10:36,960
and i make it there prediction

183
00:10:37,000 --> 00:10:40,420
there you will see nothing

184
00:10:40,420 --> 00:10:42,560
there we go

185
00:10:44,080 --> 00:10:46,290
that amazing

186
00:10:46,290 --> 00:10:51,770
close to this optimal mathematical performance in this is joint work the ruin idea was

187
00:10:52,050 --> 00:11:00,110
chuck kalish who is in psychology tim rogers also psychology major issue in computer science

188
00:11:00,130 --> 00:11:05,790
so the idea was to investigate human active learning in tasks that is analogous to

189
00:11:05,790 --> 00:11:12,910
the one d threshold learning problem so here is the the set up we gave

190
00:11:12,910 --> 00:11:18,420
we presented subjects with tags and so they see one of these things this is

191
00:11:18,420 --> 00:11:23,970
an egg and these are different an x-ray area in their spikiness from real spiky

192
00:11:23,970 --> 00:11:30,370
eggs too much smoother eggs and these are just geometric shapes that can be regenerated

193
00:11:30,720 --> 00:11:36,330
have these these distinct characteristics of smooth this person spikiness and there's actually a single

194
00:11:36,330 --> 00:11:39,480
parameter which governs how

195
00:11:39,530 --> 00:11:44,210
the house spike or smooth at the object itself from zero to one

196
00:11:44,220 --> 00:11:48,370
they were told that these are alien eggs and the goal was to try to

197
00:11:48,370 --> 00:11:54,930
learn what the alien eggs hatch into the hatch into two different things and there

198
00:11:54,930 --> 00:11:59,620
are more probably going to hatch into birds of their spike your eggs and are

199
00:11:59,620 --> 00:12:02,170
more probably going to hatch into snakes

200
00:12:02,190 --> 00:12:05,090
if there are smooth smoother convex and so this is what they were told but

201
00:12:05,090 --> 00:12:08,180
what they were told is where exactly

202
00:12:08,580 --> 00:12:12,630
does it become more probably snake versus more probably bird

203
00:12:12,660 --> 00:12:18,270
so what else is some sequence of eggs and those eggs hatch and then after

204
00:12:18,270 --> 00:12:21,900
some point there as to try to make a determination of where they think this

205
00:12:21,900 --> 00:12:28,840
transition is built from more probably sneaked more probably bird in those eggs that seal

206
00:12:28,840 --> 00:12:34,350
either just be randomly chosen eggs that presented which can hatch or they can slack

207
00:12:34,360 --> 00:12:38,210
to say i like to see this character that catch so that's the difference between

208
00:12:38,210 --> 00:12:40,590
the passive and active learning

209
00:12:41,170 --> 00:12:44,560
so i think that's what i just said

210
00:12:44,590 --> 00:12:48,530
and so they all go through some of the data in a minute but the

211
00:12:48,530 --> 00:12:52,880
results are basically this that in theory we know that if you just passively seeing

212
00:12:52,880 --> 00:12:58,090
A's catching your ability to localize where this value theta is is going to decay

213
00:12:58,120 --> 00:13:02,130
like one over that if you the number of races are hatched the nearest to

214
00:13:02,130 --> 00:13:07,670
be about one of whereas if you are able to selectively pick which makes you

215
00:13:07,670 --> 00:13:12,130
want to see how it should do something like this bisection type of procedure then

216
00:13:12,130 --> 00:13:18,110
you should get this exponentially to carry in your localisation of data and in fact

217
00:13:18,110 --> 00:13:21,980
we see that humans at least when the noise level is too large to follow

218
00:13:21,980 --> 00:13:23,880
the same trends

219
00:13:23,900 --> 00:13:25,500
so here we are

220
00:13:25,520 --> 00:13:30,610
the data so there are thirty three subjects and they were split up among various

221
00:13:30,610 --> 00:13:34,990
conditions conditions were noise levels

222
00:13:35,020 --> 00:13:38,480
so there are different noise levels we like that so i epsilon zero in this

223
00:13:38,480 --> 00:13:43,770
case that means there's no noise effects once point four that means that the highest

224
00:13:43,770 --> 00:13:48,660
amount of noise point five would be complete no it's just flipping point so you

225
00:13:48,700 --> 00:13:52,030
ranging from what from no noise to almost

226
00:13:52,050 --> 00:13:58,080
complete randomness and then we looked at three different scenarios one where they're shown random

227
00:13:58,080 --> 00:13:59,220
eggs hatching

228
00:13:59,260 --> 00:14:03,820
one where they can select eggs that they'd like to see how much the active

229
00:14:03,820 --> 00:14:08,100
mode and then when we call machine you and this is where we took the

230
00:14:08,100 --> 00:14:10,980
optimal machine learning algorithm which was this

231
00:14:10,990 --> 00:14:16,780
probabilistic bisection procedure and it was choosing which ecstasy hatch and those were what were

232
00:14:16,780 --> 00:14:18,160
presented to the human soul

233
00:14:18,640 --> 00:14:21,210
the motivation for that was to c

234
00:14:21,230 --> 00:14:26,330
if we can improve her human performance by kind of coupling them to machine that

235
00:14:26,330 --> 00:14:31,520
maybe is helping to inform them about what data to select to look at

236
00:14:31,580 --> 00:14:36,660
so i guess you can count so what we see here so we see that

237
00:14:37,350 --> 00:14:43,840
the army traces point so in that totally random case you see that enough shows

238
00:14:43,850 --> 00:14:48,010
the average person maybe you see things tending to get a little bit better but

239
00:14:48,330 --> 00:14:52,730
as noise levels get higher things it more difficult for people you can see that

240
00:14:52,730 --> 00:14:54,220
things are much better

241
00:14:54,270 --> 00:14:59,230
at low noise levels when they can be active even here noises point one and

242
00:14:59,400 --> 00:15:03,820
point two years still seem much better performance than in the past the case once

243
00:15:03,830 --> 00:15:05,280
you get up to the noise of

244
00:15:05,320 --> 00:15:09,360
o point four things can fall apart people can make sense of things was not

245
00:15:09,360 --> 00:15:11,740
very good at managing all that uncertainty

246
00:15:11,800 --> 00:15:16,390
and then the machine your case people do very well and basically they're doing well

247
00:15:16,390 --> 00:15:21,120
because they're following exactly what the machine is telling them and it turns out this

248
00:15:21,120 --> 00:15:25,710
machine your case isn't super interesting and i can say more about that

249
00:15:25,730 --> 00:15:29,560
afterwards people are interested but we'll ignore that for the most part so

250
00:15:29,750 --> 00:15:36,440
here is the here the average person or average all the subjects together and so

251
00:15:36,480 --> 00:15:41,730
for example if we looked at this case right here is noise point one

252
00:15:41,740 --> 00:15:46,130
the blue is the passive learning the red is the active learning and the black

253
00:15:46,130 --> 00:15:49,740
is this your case which would pretty much be close to what the

254
00:15:49,770 --> 00:15:54,580
machine that optimal learning algorithm we're doing so what you see is a pretty big

255
00:15:55,820 --> 00:15:59,310
if people can be active that's getting close to the

256
00:15:59,320 --> 00:16:03,770
the kind of performance you'd expect out machine you still see a noticeable improvement here

257
00:16:03,770 --> 00:16:05,060
these are the

258
00:16:05,070 --> 00:16:10,800
the bars here like confidence interval of of of ninety five percent

259
00:16:10,810 --> 00:16:16,070
so it's statistically significant improvement and but once we get into this very high noise

260
00:16:16,070 --> 00:16:18,130
regime things kind get all

261
00:16:18,330 --> 00:16:23,140
the mixed up all the machines can still sort through all that randomness and do

262
00:16:23,140 --> 00:16:28,120
better in asia said that the the this axis here is as error gave i

263
00:16:28,120 --> 00:16:31,700
didn't say that before and this is the number of existing hatch

264
00:16:31,780 --> 00:16:36,510
so here goes down as you see more eggs and things get more and more

265
00:16:36,510 --> 00:16:41,960
difficult there's more noise so that is what we expect and here's an interesting way

266
00:16:41,960 --> 00:16:46,650
to look at the story of trends of how the areas are decaying so

267
00:16:46,660 --> 00:16:48,240
in the active

268
00:16:49,220 --> 00:16:54,070
the the circles here are data and plotting things on a log linear scale so

269
00:16:54,070 --> 00:16:56,240
the areas log in the

270
00:16:56,380 --> 00:17:01,080
a number of existing patches linear and if you fit a line to those data

271
00:17:01,080 --> 00:17:06,070
you see that it doesn't look unreasonable that they look fairly linear analog scale with

272
00:17:06,070 --> 00:17:11,230
that sort of slope that's getting flattened flatters increase noise level

273
00:17:11,350 --> 00:17:18,080
so this log linear plot with the linear kind of fit to the data suggests

274
00:17:18,080 --> 00:17:23,180
that the air really is going down exponentially as we do expect and that parameter

275
00:17:23,190 --> 00:17:26,380
of the exponential decay is getting worse

276
00:17:26,390 --> 00:17:27,690
were slower

277
00:17:28,030 --> 00:17:32,010
as you get more and more noise which is exactly what the theory would predict

278
00:17:32,020 --> 00:17:33,600
if we look at passive

279
00:17:33,640 --> 00:17:37,760
if you plotted on log linear scale it's not very interesting things are very flat

280
00:17:37,760 --> 00:17:41,280
but if you plot them on log log scale and you fit to the data

281
00:17:41,280 --> 00:17:42,500
you see you get

282
00:17:42,510 --> 00:17:44,480
kind of linear fits and that's

283
00:17:44,490 --> 00:17:49,610
suggesting again that you have a polynomial served decay rate in the past month so

284
00:17:49,610 --> 00:17:55,620
again we see this exponential versus polynomial air decay in human learning in this particular

285
00:17:55,620 --> 00:18:00,850
study any questions on that is i think just have

286
00:18:00,860 --> 00:18:05,450
wrap up room most close to lunchtime the questions of human learning

287
00:18:12,740 --> 00:18:20,610
so the wise your case not so interesting well what's happening is as the machine

288
00:18:20,610 --> 00:18:23,490
goes large and selecting a

289
00:18:23,500 --> 00:18:27,680
if we were to fight flip back to the picture of the eggs

290
00:18:27,690 --> 00:18:31,080
so what will happen is the machine would

291
00:18:31,090 --> 00:18:33,280
relatively quickly start

292
00:18:33,310 --> 00:18:38,510
homing in on this location of x and so towards the tail end of this

293
00:18:38,530 --> 00:18:43,910
learning process after ten or fifteen x so the machines just looking x-ray in this

294
00:18:43,910 --> 00:18:49,070
so the outcome is one one of the six phases which may show up but

295
00:18:49,070 --> 00:18:55,070
we assume that this price is not standardized and we don't know the probabilities

296
00:18:55,090 --> 00:18:58,730
of a certain phase showing up

297
00:18:58,740 --> 00:19:04,530
so the station is that there is a random variable theta and theta

298
00:19:04,990 --> 00:19:06,910
assumes that OK

299
00:19:06,920 --> 00:19:09,950
this means that the the face

300
00:19:09,960 --> 00:19:13,730
the top of the dice for decades

301
00:19:13,750 --> 00:19:17,240
so that came be one two three four five six

302
00:19:17,700 --> 00:19:22,260
and now we do a lot of tarsus independent process

303
00:19:22,280 --> 00:19:28,930
of the dies and and of them and in the end policies we observe

304
00:19:28,930 --> 00:19:29,850
a certain

305
00:19:29,870 --> 00:19:31,440
as i OK

306
00:19:31,520 --> 00:19:33,530
and k times

307
00:19:33,820 --> 00:19:36,530
so a reasonable estimate and for the

308
00:19:37,680 --> 00:19:42,060
that initial we see a certain results

309
00:19:42,090 --> 00:19:48,440
thing the dice is the number of observations divided by the total number of tosses

310
00:19:48,440 --> 00:19:52,700
so this seems very reasonable if i observe certain face

311
00:19:52,710 --> 00:19:54,180
they often

312
00:19:54,200 --> 00:19:57,390
correspondingly recovers likely

313
00:19:57,410 --> 00:20:00,240
if observe rarely then

314
00:20:00,290 --> 00:20:03,870
probability estimate to be over

315
00:20:03,870 --> 00:20:05,810
quite small

316
00:20:05,840 --> 00:20:08,120
so this is something

317
00:20:08,120 --> 00:20:15,540
OK now we have become a little bit more probabilistic so

318
00:20:15,590 --> 00:20:19,490
in this model the issuer multinomial sampling

319
00:20:19,500 --> 00:20:22,720
so we assume that is observed variables theta

320
00:20:22,730 --> 00:20:25,600
my how might have different state

321
00:20:25,620 --> 00:20:28,920
but i want to say there are so in the case of the the dice

322
00:20:28,920 --> 00:20:34,270
was six one to six and the likelihood function is given by

323
00:20:35,490 --> 00:20:38,190
probability of observing that

324
00:20:38,280 --> 00:20:42,920
died showed k given the parameters in the model is

325
00:20:42,930 --> 00:20:46,500
equals to the k th component of the parameter vector

326
00:20:48,650 --> 00:20:52,680
so g is director of

327
00:20:52,830 --> 00:20:55,230
really want to our the first

328
00:20:55,250 --> 00:21:01,450
the first entry is simply one minus the other entries so why might might debated

329
00:21:01,450 --> 00:21:07,140
this has are degrees are minus one degrees of freedom support and minus one free

330
00:21:07,140 --> 00:21:12,160
parameters because the last one is given by the normalisation constraint anyway so we just

331
00:21:12,160 --> 00:21:13,550
have a vector of

332
00:21:13,670 --> 00:21:16,230
number here and

333
00:21:16,250 --> 00:21:18,870
which i exactly the physical probabilities of of

334
00:21:18,990 --> 00:21:24,670
observing a certain result tossing the dice

335
00:21:24,680 --> 00:21:31,500
and these are numbers between a positive numbers greater than negative numbers and they should

336
00:21:31,500 --> 00:21:34,540
sum up to one that exactly the probability

337
00:21:34,570 --> 00:21:38,050
and these are of course point is we are interested in it we want to

338
00:21:39,230 --> 00:21:41,780
the slow down

339
00:21:41,840 --> 00:21:48,600
then we observe data as i said before and these are realizations of these random

340
00:21:48,600 --> 00:21:55,990
variables that one is one identical and and we simply calculate the sufficient statistics which

341
00:21:55,990 --> 00:21:59,340
in this case is the total number

342
00:21:59,370 --> 00:22:00,420
we observed

343
00:22:00,430 --> 00:22:05,180
the result so and one means the number of times we have observed that the

344
00:22:05,180 --> 00:22:09,020
dicer one and are in this case which reside

345
00:22:09,040 --> 00:22:15,770
it would be the number of times we have observed the six showing

346
00:22:16,420 --> 00:22:20,100
so d in the following list and gerald ford's of data

347
00:22:20,150 --> 00:22:28,320
then we calculate the likelihood term based on this and these assumptions and

348
00:22:28,370 --> 00:22:34,440
since of the probability of observing one of those results is just gk

349
00:22:34,460 --> 00:22:40,200
so will be the result of observing the OK and if we observe that and

350
00:22:40,210 --> 00:22:45,270
OK times that we just to calculate due to the power of k and you

351
00:22:45,270 --> 00:22:46,510
have to do that for all

352
00:22:46,730 --> 00:22:48,270
results so far

353
00:22:48,320 --> 00:22:53,490
throwing die so this is the likelihood function with this normalisation term in front which

354
00:22:53,490 --> 00:22:57,440
is not relevant for discussion

355
00:22:57,440 --> 00:23:04,030
but essentially just multiplying all the probability of observing the individual resides and officers from

356
00:23:04,050 --> 00:23:10,730
in the the maximum likelihood setting with an estimate the unknown parameter by finding the

357
00:23:10,730 --> 00:23:12,950
parameter values which maximise

358
00:23:12,960 --> 00:23:20,940
this expression and he would end up exactly with our plausible result that

359
00:23:20,950 --> 00:23:22,160
parameters which

360
00:23:22,180 --> 00:23:25,760
correspond to the experimental columns

361
00:23:25,790 --> 00:23:30,290
and this is fine if n is very large the number of states

362
00:23:30,310 --> 00:23:32,720
in particular is much like that smaller

363
00:23:32,970 --> 00:23:38,140
then and this is my give a good estimate but in cases where we don't

364
00:23:38,140 --> 00:23:43,510
have so much data to be observed assessment might be quite wrong and we might

365
00:23:43,510 --> 00:23:44,230
not have

366
00:23:44,260 --> 00:23:48,820
observe certain classes at all and this number would be zero

367
00:23:48,830 --> 00:23:52,220
which might be unreasonable in many situations so

368
00:23:52,220 --> 00:23:56,610
i should also warn you that this code include some type on concepts at least

369
00:23:57,890 --> 00:23:59,770
you have not yet seen

370
00:23:59,820 --> 00:24:02,020
will see it briefly today

371
00:24:02,040 --> 00:24:04,050
this is on purpose

372
00:24:04,090 --> 00:24:07,890
is one of the things i hope you have learned to do this semester

373
00:24:07,920 --> 00:24:11,410
is look up things you don't know and figure out what they do

374
00:24:11,460 --> 00:24:13,430
what they mean

375
00:24:13,440 --> 00:24:16,160
because we obviously cannot in any course

376
00:24:16,210 --> 00:24:19,500
or even any set of course tell you everything you ever want to know in

377
00:24:20,850 --> 00:24:25,750
so intentionally we've seeded some things in this program that will be unfamiliar

378
00:24:25,770 --> 00:24:28,380
so during the time you're starting the program

379
00:24:28,390 --> 00:24:31,710
get online look it up to figure out what they do

380
00:24:31,780 --> 00:24:35,030
if you have trouble we will be having office hours

381
00:24:35,050 --> 00:24:37,580
well you can go and get some help

382
00:24:37,590 --> 00:24:41,430
but the tea is will expect you at least tried to figure it out yourself

383
00:24:44,100 --> 00:24:48,200
final will be opened book open notes just like the quizzes

384
00:24:48,210 --> 00:24:51,740
it will be the first two hours of the allotted time we want good all

385
00:24:51,760 --> 00:24:54,070
three hours

386
00:24:56,020 --> 00:25:02,190
so i won't be usually longer than the quiz

387
00:25:02,210 --> 00:25:04,160
be a little bit longer

388
00:25:04,180 --> 00:25:09,860
again very much in the same style of the quizzes

389
00:25:09,870 --> 00:25:11,460
all right

390
00:25:11,470 --> 00:25:12,780
let's look at this

391
00:25:12,790 --> 00:25:16,780
let's assume that you have won the lottery

392
00:25:16,790 --> 00:25:18,640
and have serious money

393
00:25:18,680 --> 00:25:22,780
but you foolishly wish to invest in the stock market

394
00:25:22,850 --> 00:25:26,660
there are two basic strategy is to choose from

395
00:25:28,010 --> 00:25:33,190
you can either have what's called the indexed portfolios

396
00:25:36,720 --> 00:25:46,030
or a managed portfolio

397
00:25:55,240 --> 00:25:57,230
indexed portfolios

398
00:25:57,250 --> 00:26:01,520
you basically say i want to own all of the stocks that there are

399
00:26:01,570 --> 00:26:05,260
and if the stock market goes up by make money if the stock market goes

400
00:26:05,260 --> 00:26:06,760
down i lose money

401
00:26:06,840 --> 00:26:10,390
i'm not going to be thinking i'm clever and can pick winners and losers and

402
00:26:10,390 --> 00:26:13,580
is betting on the market as a whole

403
00:26:13,590 --> 00:26:15,110
there are attractive

404
00:26:15,160 --> 00:26:16,860
in the a

405
00:26:16,940 --> 00:26:19,350
they don't require a lot of thought

406
00:26:19,360 --> 00:26:22,530
and b they have what's called the low expense ratio

407
00:26:22,550 --> 00:26:26,630
since the are easy to implement you don't pay anyone to be brilliant implemented for

408
00:26:27,340 --> 00:26:30,770
so they're very low fees

409
00:26:30,790 --> 00:26:32,970
i managed portfolio

410
00:26:33,020 --> 00:26:36,150
you find somebody you think is really smart

411
00:26:36,200 --> 00:26:37,350
and you pay them

412
00:26:37,360 --> 00:26:38,830
a fair amount of money

413
00:26:38,840 --> 00:26:40,330
and in return

414
00:26:40,380 --> 00:26:43,700
they assert that they will pick winners for you

415
00:26:43,750 --> 00:26:47,120
and that in fact you will outperform the stock market

416
00:26:47,140 --> 00:26:51,210
and it goes up six percent well you'll go up ten percent or more

417
00:26:51,230 --> 00:26:56,050
and if it goes down don't worry i'm so smart your stocks will go down

418
00:26:58,890 --> 00:27:00,370
there's a lot of debate

419
00:27:00,380 --> 00:27:03,990
about which is the better of these two

420
00:27:06,530 --> 00:27:11,260
so now we're going to try and see if we can write a simulation

421
00:27:11,270 --> 00:27:14,110
it will give us some insight

422
00:27:14,160 --> 00:27:19,700
as to which of these might be better or worse

423
00:27:19,750 --> 00:27:20,560
all right

424
00:27:20,570 --> 00:27:24,470
so that's the basic problem

425
00:27:24,480 --> 00:27:25,780
as we know it

426
00:27:28,560 --> 00:27:31,310
and by the way we're not going to write perfect simulation here

427
00:27:31,330 --> 00:27:34,700
because we're going to try and do it forty minutes to thirty minutes

428
00:27:34,750 --> 00:27:39,760
and it would take at least an hour due to perfect simulation the stock market

429
00:27:39,770 --> 00:27:42,650
all right

430
00:27:42,700 --> 00:27:44,290
the first thing we need to do

431
00:27:44,310 --> 00:27:46,920
it have some sort of a theory

432
00:27:46,930 --> 00:27:49,510
we did this spring we had this theory

433
00:27:49,520 --> 00:27:53,450
of hoax law the told something and we built the simulation

434
00:27:53,460 --> 00:27:55,910
some tools around that theory

435
00:27:55,960 --> 00:28:01,150
now we need to think about a model of the stock market

436
00:28:01,190 --> 00:28:04,540
and the model we're gonna use

437
00:28:04,550 --> 00:28:08,160
is based on what's called the efficient

438
00:28:08,240 --> 00:28:10,010
market hypothesis

439
00:28:14,490 --> 00:28:16,150
so the moral here

440
00:28:16,190 --> 00:28:18,710
again is whenever you're doing

441
00:28:18,760 --> 00:28:22,740
implementation of simulation you do need to have some underlying

442
00:28:22,750 --> 00:28:25,550
theory about the model

443
00:28:25,560 --> 00:28:33,350
but this model asserts is that the markets are information only efficient

444
00:28:33,400 --> 00:28:47,440
that's just a current prices

445
00:28:47,510 --> 00:28:48,970
reflect all

446
00:28:48,980 --> 00:28:51,790
publicly known information

447
00:28:51,880 --> 00:28:54,650
about each stock

448
00:28:54,690 --> 00:28:57,160
and therefore unbiased

449
00:28:57,170 --> 00:29:00,590
the if people thought that the stock was underpriced

450
00:29:00,600 --> 00:29:04,740
well people will buy more of it the price would have risen already

451
00:29:04,780 --> 00:29:08,470
people thought the stock was overpriced for people to try to sell it and it

452
00:29:08,470 --> 00:29:10,480
would have come down

453
00:29:10,500 --> 00:29:15,110
so this is a very popular theory believed by many

454
00:29:15,120 --> 00:29:18,760
famous economist today and in the past

455
00:29:18,770 --> 00:29:20,560
and so it's OK

456
00:29:20,570 --> 00:29:22,450
that effectively means

457
00:29:22,460 --> 00:29:24,130
but the market is

458
00:29:27,410 --> 00:29:32,210
OK that it doesn't matter what the price of the stock was yesterday

459
00:29:32,270 --> 00:29:36,370
today its price given the best known information

460
00:29:36,370 --> 00:29:38,300
equivalent in some sense

461
00:29:38,390 --> 00:29:40,060
solving the overall

462
00:29:40,080 --> 00:29:42,700
reinforcement learning problem

463
00:29:42,870 --> 00:29:49,450
so what was the final

464
00:29:50,110 --> 00:29:53,850
this quantity is start he

465
00:29:53,860 --> 00:29:56,930
so this is quite is thirty is going to be

466
00:29:56,940 --> 00:30:00,230
and a conditional advantage so we're going

467
00:30:00,240 --> 00:30:02,920
assume that we actually get point

468
00:30:03,350 --> 00:30:09,020
we can assume that we act according to our learned policy

469
00:30:09,070 --> 00:30:12,710
for the first team at one time steps

470
00:30:12,760 --> 00:30:14,240
in fact according to

471
00:30:14,250 --> 00:30:17,100
i learned policy our new policy

472
00:30:17,110 --> 00:30:19,470
for the teeth time

473
00:30:19,510 --> 00:30:23,590
o act according to optimal policy afterwards right to this

474
00:30:23,600 --> 00:30:24,860
this temple

475
00:30:24,890 --> 00:30:27,110
is the policy for all time

476
00:30:28,420 --> 00:30:30,060
first react according to

477
00:30:30,070 --> 00:30:31,540
i learned policy

478
00:30:31,640 --> 00:30:33,620
and then we act according to

479
00:30:33,700 --> 00:30:37,930
the whole policy

480
00:30:37,970 --> 00:30:38,970
and the

481
00:30:38,980 --> 00:30:40,360
this is

482
00:30:40,380 --> 00:30:42,350
what this expected

483
00:30:42,350 --> 00:30:44,250
sum of rewards

484
00:30:44,280 --> 00:30:45,110
when we

485
00:30:45,110 --> 00:30:47,540
behave in this way

486
00:30:47,680 --> 00:30:51,760
was expected reward someone you start acting with high

487
00:30:51,790 --> 00:30:54,390
and then you want to see

488
00:30:54,410 --> 00:31:04,460
incomplete without policy

489
00:31:04,470 --> 00:31:05,790
so the claim is

490
00:31:05,820 --> 00:31:06,980
for every

491
00:31:06,980 --> 00:31:09,290
reinforcement learning problem

492
00:31:09,350 --> 00:31:11,990
for every policy

493
00:31:12,000 --> 00:31:15,200
the difference between the on policy

494
00:31:16,830 --> 00:31:18,980
some particular policy

495
00:31:20,150 --> 00:31:21,550
the sum

496
00:31:21,690 --> 00:31:26,760
from two eagles won the capital t

497
00:31:26,780 --> 00:31:28,420
of this

498
00:31:29,970 --> 00:31:33,050
so this differences

499
00:31:33,550 --> 00:31:39,280
this is how well conditioned on

500
00:31:39,330 --> 00:31:40,990
what you've done up to

501
00:31:43,820 --> 00:31:49,580
hello could you have done if you could optionally t

502
00:31:50,570 --> 00:31:52,720
how well you did

503
00:31:52,750 --> 00:31:54,440
according to

504
00:31:55,470 --> 00:31:58,060
have you measurement

505
00:32:00,280 --> 00:32:02,530
we learned seventeen

506
00:32:02,540 --> 00:32:04,780
the teeth time steps

507
00:32:05,790 --> 00:32:07,170
it's going to do

508
00:32:07,170 --> 00:32:09,060
maybe a little bit worse

509
00:32:09,080 --> 00:32:13,470
and that the best thing they could have worked

510
00:32:13,510 --> 00:32:15,530
and this difference here

511
00:32:15,640 --> 00:32:17,620
if you think about it

512
00:32:17,630 --> 00:32:19,250
it's just

513
00:32:19,610 --> 00:32:26,170
it's just the difference computing before right

514
00:32:26,170 --> 00:32:28,910
so computing this difference here

515
00:32:31,780 --> 00:32:35,940
OK so it's the difference was the other way because cost rather than rewards

516
00:32:35,940 --> 00:32:38,080
but this is

517
00:32:38,130 --> 00:32:39,950
this is how we could have done

518
00:32:39,960 --> 00:32:41,640
in terms of number of steps

519
00:32:41,650 --> 00:32:43,460
reach the next

520
00:32:43,570 --> 00:32:45,500
and this is how we did

521
00:32:45,570 --> 00:32:47,470
for whatever i learned

522
00:32:47,480 --> 00:32:54,190
action and stop

523
00:32:54,230 --> 00:32:55,520
so this is

524
00:32:57,050 --> 00:32:59,820
of course since two classes

525
00:32:59,840 --> 00:33:01,980
if we always act optimally

526
00:33:01,980 --> 00:33:04,010
then it's intuitive copi

527
00:33:04,030 --> 00:33:05,790
city start

528
00:33:05,810 --> 00:33:07,480
this difference will be zero

529
00:33:07,480 --> 00:33:11,180
and the policy we learn will be the optimal policy

530
00:33:11,190 --> 00:33:12,660
at each step

531
00:33:12,680 --> 00:33:14,010
if we mess up

532
00:33:14,030 --> 00:33:15,990
the mother we mess up

533
00:33:16,000 --> 00:33:22,560
increases the difference between the policy and the policy really

534
00:33:28,040 --> 00:33:32,130
that was

535
00:33:35,660 --> 00:33:39,850
right so so high is just act according to h one

536
00:33:39,910 --> 00:33:41,620
and that's going to h two

537
00:33:41,640 --> 00:33:43,180
according to its three

538
00:33:43,190 --> 00:33:44,210
each four

539
00:33:45,250 --> 00:33:50,050
and so on until a city minus one

540
00:33:50,100 --> 00:33:59,940
rights issue

541
00:33:59,990 --> 00:34:01,420
and this is same

542
00:34:01,420 --> 00:34:02,840
i will experience

543
00:34:04,490 --> 00:34:07,080
today i'm going to start

544
00:34:07,170 --> 00:34:13,220
talking about a particular class of algorithms called greedy algorithm going to do in the

545
00:34:13,220 --> 00:34:16,600
context of graphs so one review

546
00:34:16,680 --> 00:34:20,230
a little bit about

547
00:34:20,240 --> 00:34:22,180
about graphs

548
00:34:24,320 --> 00:34:27,600
mostly you can find in the textbook

549
00:34:27,810 --> 00:34:29,630
in appendix

550
00:34:29,640 --> 00:34:33,060
so if you have an

551
00:34:33,100 --> 00:34:35,910
reviewed appendix b recently

552
00:34:35,930 --> 00:34:38,380
please sit down and review appendix b

553
00:34:38,450 --> 00:34:42,660
will payoff especially during our take on quiz

554
00:34:42,680 --> 00:34:44,060
so i

555
00:34:44,190 --> 00:34:46,900
just a reminder digraphs

556
00:34:46,980 --> 00:34:50,990
what's the digraph

557
00:34:51,000 --> 00:34:52,980
was that short for

558
00:34:53,030 --> 00:34:55,000
directed graph OK

559
00:34:55,050 --> 00:34:57,910
directed graph equals

560
00:34:57,920 --> 00:35:06,410
OK has a set of the vertices

561
00:35:10,800 --> 00:35:15,290
i always get people telling me that i have one for c

562
00:35:15,340 --> 00:35:19,670
the singular is not per se it is vertex

563
00:35:20,550 --> 00:35:24,610
plural vertices singular is vertex it's one of those weird

564
00:35:24,630 --> 00:35:26,660
english words

565
00:35:26,680 --> 00:35:30,310
OK probably original like like french or something right

566
00:35:30,390 --> 00:35:31,250
i don't know

567
00:35:31,270 --> 00:35:32,760
OK anyway

568
00:35:32,800 --> 00:35:35,400
and we have a set

569
00:35:35,420 --> 00:35:38,900
which is a subset of the crosby

570
00:35:40,850 --> 00:35:48,600
that's the digraph undirected graph

571
00:35:48,610 --> 00:35:54,910
it contains

572
00:35:54,920 --> 00:35:58,270
on ordered pairs

573
00:36:13,200 --> 00:36:15,660
flag OK so probably

574
00:36:15,680 --> 00:36:17,720
pretty old man english

575
00:36:17,740 --> 00:36:20,180
i guess the vertex would be a little bit of

576
00:36:20,230 --> 00:36:23,260
to give away maybe it wasn't french

577
00:36:24,820 --> 00:36:28,250
started to be used in fifteen seventy OK

578
00:36:32,000 --> 00:36:35,340
good so

579
00:36:35,390 --> 00:36:39,580
OK so the number of edges

580
00:36:39,620 --> 00:36:43,630
he is it whether directed undirected

581
00:36:43,650 --> 00:36:46,090
he is called what

582
00:36:46,140 --> 00:36:54,420
the square

583
00:36:57,670 --> 00:37:01,480
and one of the conventions will have when we're dealing once we get into graphs

584
00:37:01,480 --> 00:37:03,100
with you lot sets

585
00:37:03,150 --> 00:37:05,040
we generally drop the

586
00:37:05,050 --> 00:37:07,720
the vertical bar notation

587
00:37:07,730 --> 00:37:11,840
within the rose just because it's implied it just makes it messier

588
00:37:11,890 --> 00:37:16,090
so once again another abuse of notation really should be water the size of the

589
00:37:17,170 --> 00:37:19,440
but it just messes up

590
00:37:21,170 --> 00:37:25,710
more stuff to write down you're multiplying these things and all those vertical bars

591
00:37:25,750 --> 00:37:29,860
since they don't even have a sense to the vertical bar

592
00:37:29,920 --> 00:37:32,820
it gets messy so we just drop the

593
00:37:33,050 --> 00:37:35,580
the vertical bars there

594
00:37:36,090 --> 00:37:38,440
one is an asymptotic notation

595
00:37:38,460 --> 00:37:42,070
so he is or the squared whether it's

596
00:37:42,080 --> 00:37:45,620
a set of pairs because it a set of pairs its most

597
00:37:45,640 --> 00:37:47,380
can choose to

598
00:37:47,390 --> 00:37:52,890
it is an square miles and square over to here is the most exciting player

599
00:37:52,890 --> 00:37:55,170
two hits must be square

600
00:37:55,210 --> 00:38:00,410
and then another probably sometimes comes up is if g is connected we have another

601
00:38:03,550 --> 00:38:07,950
implies that the size of the

602
00:38:07,970 --> 00:38:10,560
is the least the size of the

603
00:38:10,610 --> 00:38:11,890
minus one

604
00:38:16,160 --> 00:38:18,910
so if it's connected

605
00:38:18,930 --> 00:38:21,190
OK meaning what does it mean to have

606
00:38:21,240 --> 00:38:23,430
graph is connected

607
00:38:25,620 --> 00:38:28,790
there is a path from any vertex to any other vertex

608
00:38:28,800 --> 00:38:31,910
in the graph that's what it means to be connected

609
00:38:32,640 --> 00:38:36,310
so if that's the case then the number of vertices the number of edges at

610
00:38:36,310 --> 00:38:39,390
least the number of vertices minus one

611
00:38:40,700 --> 00:38:44,630
and so what that says so one of the things will get into

612
00:38:44,650 --> 00:38:49,370
that i that i just want to remember line you is that in that case

613
00:38:49,400 --> 00:38:53,340
if i look at what e

614
00:38:54,850 --> 00:38:56,920
log of the number of edges

615
00:39:01,000 --> 00:39:03,240
then by this is

616
00:39:03,260 --> 00:39:07,480
o of log b

617
00:39:07,490 --> 00:39:09,750
and by this

618
00:39:09,770 --> 00:39:12,180
his omega of log b

619
00:39:12,190 --> 00:39:15,110
so is equal to the data of log b

620
00:39:15,230 --> 00:39:22,250
basically the number of in the case of a connected graph the number of edges

621
00:39:22,320 --> 00:39:25,430
and the number of vertices are polynomially related so there

622
00:39:25,560 --> 00:39:28,730
their logs are comparable

623
00:39:28,730 --> 00:39:31,570
so my name is among the overlap

624
00:39:31,630 --> 00:39:36,490
i work for to feel and politecnico di milano which means i'm a professor in

625
00:39:36,490 --> 00:39:41,490
britain including milano and i also the is more research group in this research center

626
00:39:41,490 --> 00:39:42,960
which is named chief

627
00:39:43,020 --> 00:39:50,430
the purpose of sheffield is to try to realize innovation and we use these foraging

628
00:39:50,430 --> 00:39:54,890
innovation which means so we with a good ideas and we try to do applied

629
00:39:54,890 --> 00:39:59,730
research and bring it to the market so the rationale of why i am trying

630
00:39:59,730 --> 00:40:01,390
to give this tutorial

631
00:40:01,390 --> 00:40:07,140
which is about realizing a semantic web application that we dealing seven years of activities

632
00:40:07,140 --> 00:40:10,070
in the semantic web many many tried

633
00:40:10,080 --> 00:40:14,000
in realizing things but can be

634
00:40:14,000 --> 00:40:14,810
and so

635
00:40:14,820 --> 00:40:18,640
more or less this is a result which

636
00:40:18,650 --> 00:40:25,880
OK so a real application but it is developers pause the real application so it

637
00:40:25,890 --> 00:40:31,930
might sound as in several moments as an over because bringing software engineering texts

638
00:40:31,970 --> 00:40:37,570
in the we are thinking about multiple ontologies whereas to do these very simple application

639
00:40:37,650 --> 00:40:42,900
you need much much less but the point believe that following this made using this

640
00:40:42,900 --> 00:40:48,230
approach you can develop real semantic web application OK so

641
00:40:48,230 --> 00:40:54,780
i did this work jointly with that in which are not here but wait

642
00:40:54,920 --> 00:40:59,960
the theory and is at the conference i wanted to refer you can spot around

643
00:40:59,980 --> 00:41:07,010
we did it within an educational training cruise between plaintiff and we also wrote a

644
00:41:07,010 --> 00:41:11,010
book about it

645
00:41:11,060 --> 00:41:12,870
unfortunately in italian

646
00:41:13,340 --> 00:41:16,370
i mean if is anybody that understand

647
00:41:17,390 --> 00:41:20,640
good sir

648
00:41:21,290 --> 00:41:28,560
the tories don't like these i basically go through the entire development cycle of the

649
00:41:28,560 --> 00:41:30,420
web application

650
00:41:30,430 --> 00:41:35,070
taking into consideration the equally arities of the semantics

651
00:41:35,120 --> 00:41:39,830
OK so it would be really a way to to go through the entire development

652
00:41:39,830 --> 00:41:47,350
cycle not just implement so you don't have really to to implement anything not available

653
00:41:47,380 --> 00:41:53,420
by typing by understanding the development process that we follow in realizing this application and

654
00:41:54,170 --> 00:42:00,220
i will also put some slides but gives background in particular have slides about semantic

655
00:42:00,220 --> 00:42:04,570
web about RDF about how and unbiased

656
00:42:04,850 --> 00:42:08,520
some of you feel that this is used to just rise

657
00:42:08,570 --> 00:42:11,140
and say please keep this because we all know

658
00:42:11,160 --> 00:42:12,260
and then we do so

659
00:42:14,390 --> 00:42:17,190
good so

660
00:42:17,200 --> 00:42:22,160
the proposal is as a said to develop together these music

661
00:42:22,230 --> 00:42:24,390
so we're back

662
00:42:24,450 --> 00:42:29,260
but try to do what kind tool things

663
00:42:29,350 --> 00:42:33,950
are up to these days so you want to do a mash-up using database out

664
00:42:33,950 --> 00:42:35,300
there on the web

665
00:42:35,360 --> 00:42:39,820
you try to let them manage them and we use them anyway

666
00:42:39,850 --> 00:42:42,010
but in the end you can show

667
00:42:42,010 --> 00:42:46,550
to the user to the end user application through giving an edit the

668
00:42:46,570 --> 00:42:48,010
in this case

669
00:42:48,050 --> 00:42:49,420
what we want to do

670
00:42:50,470 --> 00:42:55,290
two let to the user said this time so i want to know about all

671
00:42:55,290 --> 00:42:57,970
events about folk music

672
00:42:58,010 --> 00:42:59,480
and you start to

673
00:42:59,540 --> 00:43:04,330
moving from one repository to not letting the information and then showing them to find

674
00:43:04,330 --> 00:43:05,260
the use

675
00:43:05,390 --> 00:43:09,230
the things that i will

676
00:43:09,240 --> 00:43:14,510
talk about the ingredients of these two have listed here so we have technology things

677
00:43:14,510 --> 00:43:17,490
like the idea of a great deal

678
00:43:17,540 --> 00:43:21,420
which are things that i suppose you know it instead

679
00:43:21,510 --> 00:43:30,190
partially has got many of you don't know about idea

680
00:43:30,200 --> 00:43:36,070
same words about ideas about it

681
00:43:36,070 --> 00:43:40,420
basic things about the now are

682
00:43:44,970 --> 00:43:47,940
this is mainly due to do something about the

683
00:43:47,960 --> 00:43:49,670
and then

684
00:43:49,670 --> 00:43:55,060
some framework or that i really dependent on the choice that we need for instance

685
00:43:55,060 --> 00:43:57,090
with gene

686
00:43:57,100 --> 00:44:01,740
as application framework which means that it's a java API that allows you to manipulate

687
00:44:02,960 --> 00:44:07,920
two story into repository and things like that can i will go for it in

688
00:44:07,920 --> 00:44:12,190
the entire description in the end when i'm talking about implementation

689
00:44:12,280 --> 00:44:15,270
d two rq is nice

690
00:44:15,290 --> 00:44:18,770
those used was a database so

691
00:44:18,980 --> 00:44:22,420
relational data as in the twilight RDF graph

692
00:44:22,490 --> 00:44:26,100
so you have a if you have to allow access to RDF we're out to

693
00:44:26,110 --> 00:44:29,330
translating it entirely which is called thing i guess

694
00:44:31,000 --> 00:44:34,600
how many of you know about spike

695
00:44:37,090 --> 00:44:39,360
so i mean that we also

696
00:44:39,380 --> 00:44:40,980
for example

697
00:44:41,830 --> 00:44:46,400
this is the query language of the semantic web so what we do this using

698
00:44:46,400 --> 00:44:51,250
it to whatever is possible to access the data instead of using program to the

699
00:44:52,860 --> 00:44:57,330
and then down here but other more geeky things like could to say k which

700
00:44:57,330 --> 00:44:59,210
is the way in inside of

701
00:44:59,630 --> 00:45:07,800
actually a sparql endpoint for anybody that wants to query the database i q which

702
00:45:07,800 --> 00:45:08,980
is way

703
00:45:10,150 --> 00:45:14,150
from the top program to invoke particle so it's clients

704
00:45:14,160 --> 00:45:15,160
he i

705
00:45:17,690 --> 00:45:23,630
we call figure nine or whether it was or for an the OWL reasoning

706
00:45:23,690 --> 00:45:24,920
o thing

707
00:45:24,940 --> 00:45:29,800
news show results to be is a very nice framework developed by this in my

708
00:45:29,800 --> 00:45:32,900
project at MIT which is called

709
00:45:32,910 --> 00:45:34,800
readings for

710
00:45:36,690 --> 00:45:37,650
going back

711
00:45:37,840 --> 00:45:39,440
what we have here too

712
00:45:40,980 --> 00:45:44,420
as i said the going through the entire development cycle so we start from the

713
00:45:44,420 --> 00:45:45,530
user needs

714
00:45:45,530 --> 00:45:47,050
ways of

715
00:45:47,090 --> 00:45:49,400
finding heuristics

716
00:45:49,420 --> 00:45:53,380
one of the first ones positions estimating

717
00:45:53,400 --> 00:45:56,710
not distances states by estimating

718
00:45:56,710 --> 00:45:58,090
for every

719
00:45:58,110 --> 00:46:00,110
state variable

720
00:46:00,150 --> 00:46:01,400
let's say everything there

721
00:46:02,320 --> 00:46:03,800
many access

722
00:46:03,820 --> 00:46:07,470
so we have a knowledge to make the

723
00:46:07,700 --> 00:46:10,720
even that has

724
00:46:10,800 --> 00:46:12,880
one of those

725
00:46:12,940 --> 00:46:17,820
and the idea have a simple example here

726
00:46:17,860 --> 00:46:19,670
this the planning problem

727
00:46:19,720 --> 00:46:20,780
attractor tractor

728
00:46:20,780 --> 00:46:23,090
that our

729
00:46:23,150 --> 00:46:24,840
convinced books

730
00:46:24,880 --> 00:46:26,490
and the goal

731
00:46:26,530 --> 00:46:28,590
well what the attractor can do is to

732
00:46:28,630 --> 00:46:33,690
look from this location that location so its locations

733
00:46:33,740 --> 00:46:35,970
and when weights in the given location with them

734
00:46:35,990 --> 00:46:39,570
one of the blocks can also block in which

735
00:46:39,570 --> 00:46:40,670
these are the

736
00:46:40,690 --> 00:46:42,380
actually this is

737
00:46:43,210 --> 00:46:44,900
also the track

738
00:46:44,920 --> 00:46:46,490
the detector

739
00:46:46,530 --> 00:46:47,880
it's like this one

740
00:46:47,900 --> 00:46:49,150
OK so

741
00:46:50,050 --> 00:46:52,030
one is the

742
00:46:52,070 --> 00:46:55,490
one people these factors is

743
00:46:55,510 --> 00:46:57,380
similarly we have

744
00:46:57,470 --> 00:46:59,650
the case location

745
00:46:59,650 --> 00:47:01,670
all of this is three

746
00:47:01,670 --> 00:47:02,740
what is

747
00:47:02,900 --> 00:47:05,070
this one source of what

748
00:47:05,130 --> 00:47:06,220
this section

749
00:47:06,220 --> 00:47:07,860
it describes the

750
00:47:07,860 --> 00:47:09,970
tractor pushing something so

751
00:47:10,030 --> 00:47:13,760
the project has been same location with the block

752
00:47:13,820 --> 00:47:15,440
and then

753
00:47:15,440 --> 00:47:17,260
attractive forces the block

754
00:47:17,300 --> 00:47:18,240
what is good one

755
00:47:19,320 --> 00:47:21,630
was going to be location one

756
00:47:21,650 --> 00:47:24,050
and then it be location

757
00:47:24,070 --> 00:47:25,150
all this is

758
00:47:25,190 --> 00:47:27,550
these people

759
00:47:27,570 --> 00:47:32,400
and what this table here describes the

760
00:47:32,450 --> 00:47:36,690
what seems to be in the possible values of all the state variables at different

761
00:47:36,690 --> 00:47:39,860
time points taking even more so

762
00:47:39,880 --> 00:47:41,550
i mean it's location

763
00:47:41,570 --> 00:47:44,800
factories is one

764
00:47:44,880 --> 00:47:48,110
both blocks location three

765
00:47:48,130 --> 00:47:53,690
what what is possible in the first one the only thing that happened is that

766
00:47:53,720 --> 00:47:57,710
the tractor pushes back tractable location

767
00:47:58,490 --> 00:48:01,400
o point one

768
00:48:01,420 --> 00:48:02,720
these are possible

769
00:48:02,740 --> 00:48:05,630
there values for p one p two

770
00:48:05,630 --> 00:48:10,010
so in the initial state he wants through people who are also lot

771
00:48:11,470 --> 00:48:16,840
attractor has more than what is actually seem to make it possible

772
00:48:17,940 --> 00:48:21,070
in this case point saw

773
00:48:21,110 --> 00:48:23,840
if the article has both values and this

774
00:48:23,840 --> 00:48:27,590
the variable can also

775
00:48:27,630 --> 00:48:32,860
and then we do the same again for someone look at what all the possible

776
00:48:32,860 --> 00:48:35,550
actually be taken and what have you

777
00:48:35,550 --> 00:48:38,300
state variable values that can be reached

778
00:48:38,360 --> 00:48:40,240
the only new thing is actually

779
00:48:40,480 --> 00:48:44,420
tractor will focus on three

780
00:48:44,470 --> 00:48:45,950
this new

781
00:48:45,970 --> 00:48:47,690
value that can be reached

782
00:48:47,690 --> 00:48:49,130
only only yesterday

783
00:48:49,150 --> 00:48:52,440
well you see three having value true

784
00:48:52,450 --> 00:48:53,170
the o

785
00:48:55,840 --> 00:48:58,990
from this point because think more interesting

786
00:48:59,880 --> 00:49:02,320
tractor would be point three

787
00:49:02,380 --> 00:49:04,760
location three

788
00:49:04,900 --> 00:49:08,380
in could be looking three

789
00:49:08,400 --> 00:49:09,360
you can

790
00:49:10,970 --> 00:49:13,050
these blocks

791
00:49:13,090 --> 00:49:16,570
location so that's why we get

792
00:49:16,740 --> 00:49:20,990
with these actions we get the school

793
00:49:21,010 --> 00:49:27,760
this is the variable values and with the other actions we get these two years

794
00:49:28,300 --> 00:49:35,710
now you notice how cutting corners here what is only approximation of the reason because

795
00:49:35,720 --> 00:49:39,380
i'm going to read you know saying

796
00:49:40,300 --> 00:49:41,670
he could be

797
00:49:41,670 --> 00:49:46,570
location to look a could be location but actually only one of these

798
00:49:46,610 --> 00:49:48,220
is possible

799
00:49:48,920 --> 00:49:53,450
what we have here is only an approximation of the one on the set of

800
00:49:53,510 --> 00:49:54,900
reasonable states

801
00:49:54,900 --> 00:49:57,220
one three

802
00:49:57,260 --> 00:49:59,490
and one these trips in this

803
00:49:59,490 --> 00:50:03,550
well anything about the dependencies between the variables values

804
00:50:04,090 --> 00:50:08,450
one dependencies three is that it was true

805
00:50:08,510 --> 00:50:10,610
then beta y equals

806
00:50:10,650 --> 00:50:14,240
because only one of those of operations

807
00:50:14,260 --> 00:50:16,760
and while these table here

808
00:50:16,840 --> 00:50:21,590
simply ignores all dependencies can also be considered any

809
00:50:21,610 --> 00:50:27,050
valuation which is compatible with these values here is you know the best course for

810
00:50:28,820 --> 00:50:31,220
any of the objects can be only

811
00:50:33,070 --> 00:50:37,650
and then i the last

812
00:50:37,710 --> 00:50:40,400
what seems that i'm one three

813
00:50:40,420 --> 00:50:42,630
tractor could be here

814
00:50:42,720 --> 00:50:45,740
what would be their

815
00:50:45,740 --> 00:50:47,090
the track which

816
00:50:47,150 --> 00:50:49,690
below the location

817
00:50:49,710 --> 00:50:52,740
same people six

818
00:50:52,760 --> 00:50:59,820
and now it seems that i'm one for every possible state is reachable so

819
00:50:59,820 --> 00:51:02,050
well separate users

820
00:51:02,070 --> 00:51:04,690
if you have more actions you can freeze anything

821
00:51:04,690 --> 00:51:07,030
everything is possible

822
00:51:07,110 --> 00:51:11,280
the only using these as a lower bound estimate the number of

823
00:51:11,280 --> 00:51:13,450
actually needed we think

824
00:51:13,510 --> 00:51:16,550
so for example the because this is our goal

825
00:51:16,550 --> 00:51:18,610
a b a one b one

826
00:51:19,260 --> 00:51:21,630
heuristic value we get for this state

827
00:51:21,650 --> 00:51:25,820
before the goal is that the reason the goals a one and b one

828
00:51:26,780 --> 00:51:28,110
four steps

829
00:51:30,440 --> 00:51:33,340
yes that we have seen ignored in

830
00:51:34,570 --> 00:51:35,950
tractor needs

831
00:51:38,090 --> 00:51:39,530
all three

832
00:51:43,090 --> 00:51:44,440
one two

833
00:51:49,800 --> 00:51:53,800
access to post all box location one

834
00:51:53,800 --> 00:51:55,760
this is simply because

835
00:51:55,820 --> 00:52:00,240
you have a sort of asking that can do everything simultaneously it is possible to

836
00:52:00,240 --> 00:52:04,090
in this case the cost is different

837
00:52:04,160 --> 00:52:09,550
some may be the cleaning is more powerful but takes longer some the cleaning is

838
00:52:09,550 --> 00:52:12,590
not so powerful that is quite cost less

839
00:52:12,610 --> 00:52:17,280
so the idea is to use data mining you actually character the cost estimate the

840
00:52:17,280 --> 00:52:23,160
cost you can add certain level you can use the first user low cost one

841
00:52:23,160 --> 00:52:28,430
you you get a rough thing then sings you want to go deeper you can

842
00:52:28,430 --> 00:52:30,850
use more expensive cleaning

843
00:52:30,870 --> 00:52:35,740
that's why we're not go quite deep even the slides has some more slides because

844
00:52:35,740 --> 00:52:36,570
of time

845
00:52:36,850 --> 00:52:41,010
another interesting thing is data flow analysis because you

846
00:52:41,030 --> 00:52:44,660
look at the whole idea you know the whole saying how they flow

847
00:52:44,720 --> 00:52:49,680
the interesting thing is you want to work out the rules how they really flow

848
00:52:49,680 --> 00:52:55,620
along this road are lot of you know the whole supply chain so we have

849
00:52:55,620 --> 00:53:00,260
roy tupels we have the stadio like this we actually can do

850
00:53:00,760 --> 00:53:06,640
a lot of things to construct week or past statements means you want to register

851
00:53:06,680 --> 00:53:07,910
what the

852
00:53:07,970 --> 00:53:12,490
no this is a different dimensions so that the product manufacturer price

853
00:53:12,510 --> 00:53:19,090
you have so many different tax this tax actually can form flowgraph

854
00:53:19,090 --> 00:53:23,840
so what we do is we are from the modern dimension upon you can consider

855
00:53:23,840 --> 00:53:24,950
the flow graph

856
00:53:24,950 --> 00:53:29,160
so you can think for example if you want to find out why

857
00:53:30,910 --> 00:53:36,090
jagger of milk goes wrong so you what you really see is you actually can

858
00:53:36,430 --> 00:53:39,800
have the whole flowgraph find those of the show

859
00:53:39,870 --> 00:53:43,850
so you well you really see is what's the probability you can construct it into

860
00:53:43,870 --> 00:53:46,990
the whole probability distribution flow graph

861
00:53:47,050 --> 00:53:52,390
OK the flowgraph what we did is using the previous data warehouse

862
00:53:52,410 --> 00:53:56,700
OK based on this data warehouse you actually can go back and try to construct

863
00:53:56,720 --> 00:53:58,450
the whole the whole flock

864
00:53:58,450 --> 00:54:00,470
and this whole flow graphs

865
00:54:00,490 --> 00:54:02,350
where were

866
00:54:03,820 --> 00:54:09,950
the gender distributions like three companions and the less became simply says you try to

867
00:54:09,950 --> 00:54:15,410
find where the media free chain of the of the flow of frequent patterns and

868
00:54:15,410 --> 00:54:21,390
what deviate from the major parts of the free compact so you think these should

869
00:54:21,530 --> 00:54:23,300
be qualified as all

870
00:54:23,390 --> 00:54:27,050
so you can actually worked out the whole transition pass

871
00:54:27,070 --> 00:54:32,840
based on the major flow information and then work out the all our information so

872
00:54:32,840 --> 00:54:37,280
that's the one we call the flow past can we have the flowgraph construct the

873
00:54:37,280 --> 00:54:38,220
flow q

874
00:54:38,240 --> 00:54:44,090
then you you basically the flowcube to idea is you can think the whole saying

875
00:54:44,470 --> 00:54:46,390
is according to

876
00:54:46,390 --> 00:54:48,320
two those things like

877
00:54:48,340 --> 00:54:53,070
you can think there are several dimensions like product category

878
00:54:53,070 --> 00:54:58,090
country the price of these as dimension with this damaging you see how since the

879
00:54:58,090 --> 00:55:01,390
floor where the major change where it is

880
00:55:01,950 --> 00:55:07,140
you can turn on up you know just try to watch out what is the

881
00:55:07,160 --> 00:55:11,840
major saying on this for example thinking about product category suppose you want to see

882
00:55:11,840 --> 00:55:18,110
the digital camera video camera have so many different prime brands of producers so they

883
00:55:19,320 --> 00:55:24,240
different dimensions and this damaging you see the whole seeing how they flow for each

884
00:55:24,240 --> 00:55:29,820
scene for them but can only see superpower shocked something you see this friend how

885
00:55:29,820 --> 00:55:34,340
they flow along the whole thing whereas the major trend was i love you can

886
00:55:34,340 --> 00:55:38,820
turn on up in a very nice way of our not give you the benefit

887
00:55:38,840 --> 00:55:40,840
one but you can see using this flow q

888
00:55:41,260 --> 00:55:47,300
you can find a lot of regularity and regularity in your whole RFID data you

889
00:55:47,300 --> 00:55:49,300
know transition and all those things

890
00:55:49,320 --> 00:55:56,180
of course when you construct this remember this flow graph you construct is always

891
00:55:56,200 --> 00:55:57,610
you know it's the last

892
00:55:57,620 --> 00:56:02,620
compression because well you've got is frequent pattern and all are you're miss something so

893
00:56:02,620 --> 00:56:07,260
what we did is using something we call iceberg cube means you find the major

894
00:56:08,990 --> 00:56:13,050
above this iceberg you can see the rewrites for that and the nice part is

895
00:56:13,050 --> 00:56:16,470
not so important ways to hide it because otherwise you try to get all the

896
00:56:16,470 --> 00:56:21,090
details you get too much detail so that's the way the

897
00:56:21,090 --> 00:56:24,470
an idea how to consider flow graphs

898
00:56:25,280 --> 00:56:27,570
and of course there are

899
00:56:27,590 --> 00:56:30,990
a lot of discussions for example you can

900
00:56:31,010 --> 00:56:36,370
encode a lot of things like a decade have product closing our decade the whole

901
00:56:36,370 --> 00:56:42,720
hierarchy became code into your stuff why study this flow graph you can have the

902
00:56:42,740 --> 00:56:45,490
other encode information transfer

903
00:56:45,510 --> 00:56:46,840
two your system

904
00:56:46,840 --> 00:56:49,570
OK so when you started flow you

905
00:56:49,590 --> 00:56:54,120
maximum get you the details of your product

906
00:56:54,140 --> 00:56:58,780
the the here our is in the paper or not to give you that you

907
00:56:58,780 --> 00:57:00,450
care about what you can see is you

908
00:57:00,990 --> 00:57:05,220
you can be very very efficient and was to work on this flow q

909
00:57:05,300 --> 00:57:09,890
i mean you basically this candidate once you can constantly q and with this cube

910
00:57:09,890 --> 00:57:12,990
you can find frequent patterns frequent past

911
00:57:13,050 --> 00:57:15,870
and was a frequent that you can go through one more time you can find

912
00:57:15,870 --> 00:57:17,090
lots of followers

913
00:57:17,090 --> 00:57:19,280
but in this process

914
00:57:19,300 --> 00:57:21,970
you could also use lot of graphics out there

915
00:57:23,720 --> 00:57:27,820
o thing that that that that all the stations are under represented in studies

916
00:57:27,840 --> 00:57:31,700
and that you know you have the phase pictures are worth a thousand words

917
00:57:31,700 --> 00:57:34,130
and essentially it's you know

918
00:57:34,180 --> 00:57:37,610
i see a lot of articles where they could really have had one or more

919
00:57:37,800 --> 00:57:40,450
diagrams and was really helped

920
00:57:41,930 --> 00:57:44,470
thing about that with his table quantitative

921
00:57:44,530 --> 00:57:48,360
and there's probably in qualitative research probably the best book

922
00:57:48,410 --> 00:57:50,400
out there for four

923
00:57:50,430 --> 00:57:53,430
graphics and excitations mars humans

924
00:57:53,470 --> 00:57:57,430
ninety four it's more than twenty years old yet it's

925
00:57:59,740 --> 00:58:04,200
twenty years of coaching and yet it's really really powerful and is probably one of

926
00:58:04,200 --> 00:58:06,380
the best quality the field

927
00:58:06,410 --> 00:58:09,050
she had that that's worth pursuing

928
00:58:09,090 --> 00:58:12,930
transform your data qualitizing quantizes said area

929
00:58:12,990 --> 00:58:14,840
b is the first step

930
00:58:14,860 --> 00:58:18,430
correlating quantitative and qualitative data

931
00:58:18,450 --> 00:58:21,610
i will be forced or you could consolidate

932
00:58:21,670 --> 00:58:24,780
the quantity and quality data to create a new

933
00:58:26,760 --> 00:58:29,260
you could compare

934
00:58:29,300 --> 00:58:30,340
the different

935
00:58:30,380 --> 00:58:34,740
data sources actually quality versus commentator you can integrate them

936
00:58:36,360 --> 00:58:38,840
and these are

937
00:58:38,950 --> 00:58:40,780
so when you have two faces

938
00:58:40,820 --> 00:58:42,220
you can have

939
00:58:42,700 --> 00:58:46,550
type of data consideration and type of analysis

940
00:58:46,680 --> 00:58:49,900
the first two there we you have either one

941
00:58:50,090 --> 00:58:54,700
type of data one type analysis that the top left that's long that's quantitative or

942
00:58:55,720 --> 00:58:57,490
that's not a mixed methods study

943
00:58:57,590 --> 00:58:59,530
now i was the second so there

944
00:58:59,570 --> 00:59:02,090
for the third and fourth cells are mixed

945
00:59:02,130 --> 00:59:05,950
the fourth one being too great degree because have two thousand eight at least

946
00:59:05,990 --> 00:59:08,090
we the have two thousand that's going on

947
00:59:08,150 --> 00:59:09,680
OK so those are the most

948
00:59:11,680 --> 00:59:15,220
no typology we've come out with this is looking at

949
00:59:16,010 --> 00:59:19,280
orientations you can have so when you do the analysis

950
00:59:19,550 --> 00:59:23,200
three orientations one notation is case oriented

951
00:59:23,240 --> 00:59:25,450
my do a study where you're interested

952
00:59:26,470 --> 00:59:29,220
politicians lead political leaders

953
00:59:29,220 --> 00:59:31,300
so you look at the case

954
00:59:31,340 --> 00:59:33,970
is your real emphasis

955
00:59:36,050 --> 00:59:39,470
so each case is really important in your study

956
00:59:39,490 --> 00:59:44,570
you might not even want to make generalizations beyond those cases

957
00:59:44,590 --> 00:59:47,030
so it's very well suited to qualitative research

958
00:59:47,050 --> 00:59:51,970
but you could also be quality because you have single study designs and so forth

959
00:59:51,990 --> 00:59:55,200
time series look at cases

960
00:59:55,240 --> 00:59:56,930
then you have

961
00:59:56,930 --> 00:59:58,860
variable oriented

962
00:59:59,570 --> 01:00:00,720
so in there

963
01:00:00,740 --> 01:00:03,950
your focus in our variables interest see

964
01:00:03,970 --> 01:00:06,910
how to more variables relate to one another

965
01:00:07,010 --> 01:00:10,930
so the case might just be incidental so you may have a large sample

966
01:00:10,970 --> 01:00:14,130
the case is still important but not to the level much more what what is

967
01:00:14,130 --> 01:00:17,950
much more important variables because you want to see what happens

968
01:00:18,380 --> 01:00:19,800
the variables

969
01:00:20,530 --> 01:00:23,050
so tend to lend of to qualitative research

970
01:00:23,070 --> 01:00:24,720
we can also

971
01:00:24,760 --> 01:00:27,340
the variables in qualitative research

972
01:00:28,630 --> 01:00:32,200
and in the first type process experience

973
01:00:32,240 --> 01:00:34,700
very very

974
01:00:34,720 --> 01:00:36,570
very very pertinent political

975
01:00:37,630 --> 01:00:39,030
we often interested in

976
01:00:39,110 --> 01:00:41,280
processes dynamics to go on

977
01:00:41,300 --> 01:00:43,700
among people nations and so forth

978
01:00:46,700 --> 01:00:47,930
you know process

979
01:00:47,950 --> 01:00:49,670
ten experiences

980
01:00:49,880 --> 01:00:54,360
persistently socially variables and experiences the folks of people

981
01:00:54,430 --> 01:00:56,590
so we come when you look at those three

982
01:00:56,610 --> 01:00:57,970
in a study

983
01:00:58,630 --> 01:01:03,510
one more of those may lead you to do what's called the meta inferences we

984
01:01:03,510 --> 01:01:05,630
combine your inferences

985
01:01:07,110 --> 01:01:09,780
and these are is the table

986
01:01:09,800 --> 01:01:12,800
again you have access to this article

987
01:01:12,820 --> 01:01:14,280
has is in there

988
01:01:14,880 --> 01:01:15,800
if you

989
01:01:15,820 --> 01:01:18,450
make it case they're able to process

990
01:01:18,590 --> 01:01:20,470
and in quality and quite a few

991
01:01:20,530 --> 01:01:23,930
that captures most of the of the major techniques that we we use in in

992
01:01:23,950 --> 01:01:25,380
both fields

993
01:01:27,930 --> 01:01:30,780
over the next couple of days

994
01:01:30,800 --> 01:01:32,360
introduce some of you

995
01:01:32,360 --> 01:01:34,980
to some of those qualities techniques that you may not have heard of a lot

996
01:01:35,030 --> 01:01:36,030
of people have heard of

997
01:01:36,050 --> 01:01:37,840
that's because comparison

998
01:01:37,880 --> 01:01:42,820
a few others but this conversation analysis disqualifier that

999
01:01:42,840 --> 01:01:45,820
you know as a as i do workshops a lot of people have heard of

1000
01:01:45,840 --> 01:01:48,800
i mean quite a silly ties analysis

1001
01:01:49,070 --> 01:01:50,700
it's really really exciting

1002
01:01:50,800 --> 01:01:53,700
most people know quantitative analysis you tend to have

1003
01:01:53,760 --> 01:01:56,220
in interface to this is books you have a lot of them in the same

1004
01:01:56,220 --> 01:01:58,530
book qualitative you often get them

1005
01:01:58,630 --> 01:02:00,260
you wanted to the book

1006
01:02:00,300 --> 01:02:03,360
but there are lots of different options you have there if you're looking at the

1007
01:02:04,470 --> 01:02:08,930
you might be looking at this get statistics of cluster analysis of q methodology

1008
01:02:08,950 --> 01:02:10,720
it's for the quantitative phase

1009
01:02:10,720 --> 01:02:12,860
the current FAC all the different

1010
01:02:12,900 --> 01:02:14,720
after that you have

1011
01:02:14,740 --> 01:02:17,910
this list is not exhaustive but pretty comprehensive i think

1012
01:02:17,970 --> 01:02:24,570
in this three-dimensional representation

1013
01:02:24,630 --> 01:02:26,300
again looking case

1014
01:02:26,300 --> 01:02:27,680
this is variable

1015
01:02:27,700 --> 01:02:30,200
this is process

1016
01:02:30,220 --> 01:02:33,430
i would argue for every single type of research pretty much

1017
01:02:33,490 --> 01:02:35,590
the light somewhere in that q

1018
01:02:36,550 --> 01:02:39,840
for example if your

1019
01:02:39,880 --> 01:02:42,680
if the if it's more opportunistic

1020
01:02:42,700 --> 01:02:46,720
interesting generalizing beyond is of interest in looking at the variables

1021
01:02:46,800 --> 01:02:50,950
relate to each other in the local context economy more the top n

1022
01:02:51,050 --> 01:02:52,260
the bottom end

1023
01:02:53,590 --> 01:02:55,430
when you come to the case so it it

1024
01:02:55,450 --> 01:02:57,760
you might be more interesting intrinsic

1025
01:02:57,800 --> 01:03:01,880
OK like it is cases each case really is important you chose johnny because you

1026
01:03:01,880 --> 01:03:05,680
want to find out out about johnny johnny's experience being unemployed

1027
01:03:05,740 --> 01:03:10,170
this is the instrumental

1028
01:03:10,220 --> 01:03:12,900
where you want to see natural phenomena

1029
01:03:12,970 --> 01:03:15,400
so that you which is the film being unemployed

1030
01:03:15,430 --> 01:03:17,990
so you choose to people because of the lot more than

1031
01:03:17,990 --> 01:03:21,610
that's why this doesn't always work

1032
01:03:21,630 --> 01:03:25,030
and what you do in that case

1033
01:03:25,900 --> 01:03:33,130
you find the hopefully small set of variables which if they were given their observed

1034
01:03:33,170 --> 01:03:35,760
would render the rest of the graph

1035
01:03:35,780 --> 01:03:37,400
to be singly connected

1036
01:03:37,450 --> 01:03:40,700
OK that's going to be what's called your cut set

1037
01:03:41,840 --> 01:03:44,820
but you condition on the kind of cut the multiple

1038
01:03:44,900 --> 01:03:47,380
has the having the graph

1039
01:03:48,070 --> 01:03:50,550
if you do that then we can do is

1040
01:03:51,110 --> 01:03:57,010
you can take those few variables and instantiate them at all the possible values

1041
01:03:57,060 --> 01:03:58,590
that they can take

1042
01:03:58,610 --> 01:04:02,820
and then for each of those instantiations run

1043
01:04:02,880 --> 01:04:09,010
belief propagation or factor graph propagation on the remaining signet singly connected graph

1044
01:04:09,030 --> 01:04:09,800
and then

1045
01:04:09,880 --> 01:04:12,680
compute the probability of any variable you have to

1046
01:04:12,720 --> 01:04:15,380
average over all of the

1047
01:04:15,430 --> 01:04:20,490
probability is computed for each of the ways you condition on that set

1048
01:04:20,490 --> 01:04:22,570
that's called cutset conditioning

1049
01:04:22,570 --> 01:04:24,360
it's not

1050
01:04:24,450 --> 01:04:29,820
it's not widely used as the standard method of of appearing

1051
01:04:31,150 --> 01:04:32,680
exact inference

1052
01:04:32,720 --> 01:04:35,950
the algorithm that is widely used as junction tree

1053
01:04:36,010 --> 01:04:39,360
and there are a whole bunch of other various algorithms one of them is also

1054
01:04:39,360 --> 01:04:45,950
called variable elimination is another way of doing exact inference some people have cleverly shown

1055
01:04:47,150 --> 01:04:51,340
these are all actually equivalent algorithms so we don't need to study all of these

1056
01:04:51,340 --> 01:04:58,010
things for different choices of cutsets are four different orders in which eliminate variables that

1057
01:04:58,010 --> 01:05:03,490
correspond to different ways of doing the junction tree algorithm basically

1058
01:05:05,590 --> 01:05:07,760
the other thing you can do

1059
01:05:07,800 --> 01:05:09,070
if you can

1060
01:05:09,070 --> 01:05:11,510
cross your fingers and you can say

1061
01:05:11,550 --> 01:05:15,260
i'm just going to ignore the fact that the graph is

1062
01:05:15,530 --> 01:05:17,900
well connected let me just run

1063
01:05:17,910 --> 01:05:20,470
belief propagation on the graph anyway

1064
01:05:20,470 --> 01:05:21,840
l initialize my

1065
01:05:22,650 --> 01:05:23,630
right one

1066
01:05:23,650 --> 01:05:26,570
and run belief propagation and

1067
01:05:26,570 --> 01:05:29,340
you know they'll will be loops in the graph so the messages will go around

1068
01:05:29,380 --> 01:05:31,180
loops but you know

1069
01:05:31,240 --> 01:05:33,860
it converges maybe it'll be a a good answer

1070
01:05:33,880 --> 01:05:36,970
OK if it doesn't converge then maybe i worry

1071
01:05:38,430 --> 01:05:44,430
so this sounds like a crazy idea this is called loopy belief propagation there's a

1072
01:05:44,450 --> 01:05:46,070
double meaning to loopy

1073
01:05:46,070 --> 01:05:49,220
he also been crazy

1074
01:05:49,760 --> 01:05:55,680
and it's also be because you're passing messages around the go around in loops forever

1075
01:05:57,510 --> 01:06:00,720
it sounds like a crazy idea

1076
01:06:00,720 --> 01:06:02,470
except that

1077
01:06:02,530 --> 01:06:05,320
it works incredibly well

1078
01:06:05,360 --> 01:06:07,380
on unlike the problems in fact

1079
01:06:07,400 --> 01:06:11,130
in the field of error correcting codes

1080
01:06:11,700 --> 01:06:15,260
which is a huge part of the you know that

1081
01:06:15,320 --> 01:06:18,680
the problem of coding and information theory

1082
01:06:18,840 --> 01:06:23,450
the standard algorithm used to decode these error correcting codes

1083
01:06:23,490 --> 01:06:24,320
can be

1084
01:06:24,340 --> 01:06:25,910
converted into

1085
01:06:25,950 --> 01:06:30,780
an inference problem in a book we connect the graph and the centre of and

1086
01:06:30,800 --> 01:06:33,800
they use is of the belief propagation

1087
01:06:33,820 --> 01:06:37,410
and it's the state of the art algorithms central

1088
01:06:37,430 --> 01:06:41,510
so given the evidence that it works incredibly well for the coding people even though

1089
01:06:41,510 --> 01:06:43,950
it's not provably correct

1090
01:06:44,050 --> 01:06:46,900
it's worth trying problem

1091
01:06:46,900 --> 01:06:53,010
and people have tried as an approximation algorithm and have analysed it in in great

1092
01:06:53,010 --> 01:06:55,090
detail there's lovely work by

1093
01:06:55,110 --> 01:06:56,070
you you're right

1094
01:06:57,800 --> 01:07:01,590
the freeman on the analysis of this algorithm

1095
01:07:01,650 --> 01:07:03,550
in the

1096
01:07:03,590 --> 01:07:08,700
but this really should follow the domain of approximate inference algorithm which i'll talk about

1097
01:07:08,720 --> 01:07:11,070
in in a couple of lectures

1098
01:07:11,090 --> 01:07:14,800
let me focus on the junction tree algorithm and this is going to be the

1099
01:07:16,280 --> 01:07:17,410
past this

1100
01:07:17,970 --> 01:07:22,930
introduction to the junction tree algorithm which is a bizarre and the

1101
01:07:22,950 --> 01:07:25,240
tricky algorithm that

1102
01:07:26,050 --> 01:07:30,470
i hope i give you least some idea if you have an encounter this out

1103
01:07:30,630 --> 01:07:34,030
before or why might possibly make any sense

1104
01:07:34,320 --> 01:07:37,570
so here's the junction tree algorithm

1105
01:07:37,590 --> 01:07:42,340
let's start with the directed acyclic graph if we started with an undirected graph the

1106
01:07:42,340 --> 01:07:44,360
first that can be

1107
01:07:44,360 --> 01:07:50,720
so the second step is it's called moralizing

1108
01:07:50,740 --> 01:07:53,030
so what we do is is we take

1109
01:07:53,450 --> 01:07:58,430
each node we look at the parents of the node if there are multiple parents

1110
01:07:58,430 --> 01:08:00,410
we married the parent

1111
01:08:01,470 --> 01:08:05,360
and that's called moralisation we make the graph more moral

1112
01:08:05,410 --> 01:08:07,400
by marrying a and b

1113
01:08:07,410 --> 01:08:10,400
and by marrying the in

1114
01:08:10,410 --> 01:08:14,740
we moralise the graph and we remove all the directions

1115
01:08:14,760 --> 01:08:20,010
and what this does is it results in an undirected graph with no additional conditional

1116
01:08:20,010 --> 01:08:21,550
independence relationships

1117
01:08:21,590 --> 01:08:26,340
remember the really risky thing is that we do some operation that

1118
01:08:26,380 --> 01:08:31,700
that induces additional conditional independence relationships and moralizing does not

1119
01:08:33,590 --> 01:08:36,900
so here's this sort of the last

1120
01:08:39,130 --> 01:08:43,400
description of the conditional independence relationships that we originally had

1121
01:08:45,990 --> 01:08:48,070
that step two

1122
01:08:48,090 --> 01:08:49,720
step three

1123
01:08:49,740 --> 01:08:50,880
it's called

1124
01:08:52,800 --> 01:08:54,760
and what that really does

1125
01:08:55,970 --> 01:09:00,450
you introduce additional edges

1126
01:09:00,450 --> 01:09:06,240
so that there is no loop of length greater than three without a chord

1127
01:09:06,300 --> 01:09:09,740
OK according to something that cut across the world

1128
01:09:09,780 --> 01:09:15,150
so let's look before we had the red edge we have the loop of length

1129
01:09:16,150 --> 01:09:19,930
that had no core cost cutting across the

1130
01:09:19,990 --> 01:09:23,200
when we introduce the edge between

1131
01:09:25,110 --> 01:09:27,280
we triangulate the graph

1132
01:09:28,010 --> 01:09:30,990
triangulation is not unique

1133
01:09:31,550 --> 01:09:36,090
i believe we could have triangulated as well

1134
01:09:36,110 --> 01:09:38,470
as that of the b

1135
01:09:38,470 --> 01:09:41,780
and that would result in a in a slightly different algorithm

1136
01:09:41,800 --> 01:09:47,180
finding a triangulation is not hard finding the optimal triangulation is NP hard

1137
01:09:48,700 --> 01:09:51,010
the triangulated

1138
01:09:53,970 --> 01:09:56,760
and the reason we triangulate it is

1139
01:09:56,800 --> 01:10:01,340
that this is necessary so that the final junction tree satisfies what's called the running

1140
01:10:01,340 --> 01:10:03,380
intersection property

1141
01:10:03,380 --> 01:10:05,820
it's basically you know

1142
01:10:05,830 --> 01:10:10,590
he the ratio of consumers to it's roughly a hundred to one

1143
01:10:11,690 --> 01:10:13,270
we think

1144
01:10:13,270 --> 01:10:16,600
you know with the promulgation of these technologies

1145
01:10:16,750 --> 01:10:20,900
i don't believe about one hundred percent but slide from bradley

1146
01:10:20,920 --> 01:10:26,480
and he is very compelling arguments why we're moving to a world where this gonna

1147
01:10:26,480 --> 01:10:28,880
help us is going to be a few billion publishers

1148
01:10:29,160 --> 01:10:32,850
and the way to think about is you know anyone the

1149
01:10:32,860 --> 01:10:34,790
keyboard can become and also

1150
01:10:34,840 --> 01:10:38,300
anyone with a camera can become a photographer and actually published images and have people

1151
01:10:38,300 --> 01:10:41,550
by the images and be interested in them and see them

1152
01:10:41,580 --> 01:10:46,660
the ipod is actually forced into very interesting dynamics in the long can

1153
01:10:46,680 --> 01:10:50,850
you actually becoming only that you have you have you make your own selection versus

1154
01:10:50,850 --> 01:10:55,760
passively listening to somebody else programming which is a shift that is very different shift

1155
01:10:55,840 --> 01:10:58,630
massive scale

1156
01:10:58,640 --> 01:11:01,120
so flickr let's talk about flickr for a couple of minutes because i

1157
01:11:01,160 --> 01:11:04,560
for example a few minutes later

1158
01:11:04,600 --> 01:11:07,540
it's site

1159
01:11:07,550 --> 01:11:10,970
this this is another lesson learned by the way i wanted to my thesis which

1160
01:11:12,030 --> 01:11:14,640
there's a lot of my own intuition

1161
01:11:14,670 --> 01:11:18,010
about things that may or may not work on the internet

1162
01:11:18,020 --> 01:11:21,050
when i first heard about the

1163
01:11:21,070 --> 01:11:22,500
we considering

1164
01:11:22,530 --> 01:11:24,690
acquiring this company

1165
01:11:24,720 --> 01:11:31,460
the idea was to decide lets you take photos for them share

1166
01:11:31,470 --> 01:11:33,490
my first reaction was

1167
01:11:33,510 --> 01:11:34,810
one of them

1168
01:11:36,510 --> 01:11:38,320
and boy

1169
01:11:38,400 --> 01:11:40,570
fifty million people

1170
01:11:40,580 --> 01:11:43,170
in less than a year in order to do that

1171
01:11:43,190 --> 01:11:44,150
fifty million

1172
01:11:44,160 --> 01:11:48,850
that's that's amazing a huge number and statistics on how many photos have been uploaded

1173
01:11:48,850 --> 01:11:50,820
to continued to to grow

1174
01:11:50,820 --> 01:11:53,440
is just incredible

1175
01:11:54,310 --> 01:11:58,040
what makes flickr special right this user generated content

1176
01:11:58,060 --> 01:12:02,780
it's not like system provides its users that actually putting it changed the world

1177
01:12:02,820 --> 01:12:08,290
it's actually very good you can find some amazing imagery on flickr i encourage you

1178
01:12:08,290 --> 01:12:12,560
to search for find photos from your friends actually

1179
01:12:12,560 --> 01:12:14,860
i happen to define

1180
01:12:14,960 --> 01:12:18,470
it's use organised like nobody

1181
01:12:18,510 --> 01:12:21,640
we know we use what's called the folksonomy right which is

1182
01:12:21,660 --> 01:12:23,710
the taxonomy just evolves

1183
01:12:23,710 --> 01:12:24,740
and actually in second

1184
01:12:25,040 --> 01:12:29,770
people tag on images search for

1185
01:12:30,140 --> 01:12:32,160
you look up whatever people that

1186
01:12:32,180 --> 01:12:34,180
right so you actually find matches

1187
01:12:34,190 --> 01:12:37,610
which are very hard to find otherwise it didn't

1188
01:12:38,650 --> 01:12:40,710
example one humans

1189
01:12:40,720 --> 01:12:41,330
and like this

1190
01:12:41,350 --> 01:12:44,730
again the images are critical

1191
01:12:44,740 --> 01:12:49,060
what is

1192
01:12:49,070 --> 01:12:55,520
you know people like promise which actually gives you a lot of knowledge about those

1193
01:12:55,520 --> 01:12:58,910
images come back to that human

1194
01:12:58,930 --> 01:13:01,760
it uses distributed

1195
01:13:03,790 --> 01:13:10,270
it's not through business deals or anything like that just to qualify musing ways

1196
01:13:10,280 --> 01:13:17,640
and use functionality because it's an open platform people actually end developing tools

1197
01:13:17,670 --> 01:13:21,320
to images all on the web

1198
01:13:21,320 --> 01:13:25,400
on the images on flickr because it's an open API and the ability to publish

1199
01:13:25,400 --> 01:13:27,380
these interfaces

1200
01:13:27,410 --> 01:13:29,330
so here's what you get

1201
01:13:29,380 --> 01:13:32,570
and i think the system

1202
01:13:32,580 --> 01:13:34,720
so think over fifty million people

1203
01:13:34,720 --> 01:13:37,370
he only the nineteen employees

1204
01:13:37,390 --> 01:13:39,440
and no more what

1205
01:13:40,070 --> 01:13:43,330
that is an amazing right new

1206
01:13:43,350 --> 01:13:44,920
that is

1207
01:13:44,940 --> 01:13:46,420
now we should

1208
01:13:47,220 --> 01:13:49,010
and as the question is this

1209
01:13:50,840 --> 01:13:53,350
we see this phenomenon all the web

1210
01:13:53,500 --> 01:13:56,830
and that's what i mean

1211
01:13:56,850 --> 01:13:58,570
we actually have

1212
01:13:58,580 --> 01:14:02,180
so if i ask questions like

1213
01:14:02,190 --> 01:14:05,020
you know you found something to know how do you know you can trust

1214
01:14:05,030 --> 01:14:07,280
you can believe that

1215
01:14:08,490 --> 01:14:09,760
he moved to

1216
01:14:09,760 --> 01:14:12,070
to which the question is compared

1217
01:14:12,080 --> 01:14:15,170
and from the people that you try to extract

1218
01:14:15,250 --> 01:14:21,250
relevant information that are more likely to your question

1219
01:14:21,960 --> 01:14:25,170
this is because we have little time

1220
01:14:26,570 --> 01:14:32,090
look at all the documents to to read all the documents that are determined by

1221
01:14:32,100 --> 01:14:33,460
three engines

1222
01:14:33,470 --> 01:14:38,510
so we would like it to be more intelligent and to find out really

1223
01:14:39,210 --> 01:14:40,770
two questions

1224
01:14:41,790 --> 01:14:43,670
question answering systems

1225
01:14:43,690 --> 01:14:47,450
i'm not not so successful commercially

1226
01:14:47,460 --> 01:14:51,500
also used to be quite easy

1227
01:14:51,540 --> 01:14:52,770
long query

1228
01:14:52,770 --> 01:14:54,700
along the

1229
01:14:54,710 --> 01:14:59,350
we think it if you type in keywords be intelligent enough

1230
01:14:59,380 --> 01:15:00,710
delete four

1231
01:15:00,770 --> 01:15:02,580
intelligent information

1232
01:15:02,670 --> 01:15:06,330
but this could change more multimodal

1233
01:15:07,270 --> 01:15:10,880
if speech recognizers

1234
01:15:12,030 --> 01:15:16,010
we can and especially when you have only

1235
01:15:16,310 --> 01:15:18,070
when you

1236
01:15:18,120 --> 01:15:20,810
access to the internet with your eyes

1237
01:15:20,840 --> 01:15:23,970
it would be very handy if you could drop

1238
01:15:24,000 --> 01:15:25,790
speaking your question

1239
01:15:25,840 --> 01:15:28,570
that's type in question

1240
01:15:28,580 --> 01:15:30,090
that would be much more

1241
01:15:30,120 --> 01:15:31,040
and as

1242
01:15:31,060 --> 01:15:34,150
in a way of life as we can

1243
01:15:34,210 --> 01:15:38,810
so then we get all of these types of information act

1244
01:15:40,170 --> 01:15:42,400
more more than

1245
01:15:46,160 --> 01:15:49,750
and also we do not think give around two

1246
01:15:49,760 --> 01:15:54,820
document collection sometimes our is not very well defined

1247
01:15:54,830 --> 01:15:58,420
one around her all

1248
01:15:58,470 --> 01:16:00,850
of the document collection

1249
01:16:00,870 --> 01:16:08,030
maybe visualize when see some parts of the information and you might think he is

1250
01:16:08,040 --> 01:16:13,450
select some parts of asia and go deeper into the ground

1251
01:16:13,580 --> 01:16:17,170
for information

1252
01:16:17,220 --> 01:16:20,220
and there are a number of the

1253
01:16:20,580 --> 01:16:27,700
among which information extraction so we could classify document text categorisation

1254
01:16:27,710 --> 01:16:31,520
we could create summary for instance of the output of

1255
01:16:33,120 --> 01:16:37,010
output of documents might summarise or you could you

1256
01:16:37,020 --> 01:16:39,200
and also in

1257
01:16:39,900 --> 01:16:42,330
profile of users

1258
01:16:42,370 --> 01:16:45,590
use of this information for that

1259
01:16:45,940 --> 01:16:48,780
for that are relevant computational

1260
01:16:50,020 --> 01:16:55,960
and also information extraction plays here so both the next generation

1261
01:16:55,970 --> 01:16:58,690
we might be more precise in their

1262
01:16:58,730 --> 01:17:03,750
i identify information of the

1263
01:17:03,760 --> 01:17:08,990
which is they got which by information extraction techniques

1264
01:17:09,030 --> 01:17:10,840
and also for the west

1265
01:17:10,860 --> 01:17:12,290
we refer to web

1266
01:17:12,360 --> 01:17:15,560
question three and class

1267
01:17:15,610 --> 01:17:23,020
information extraction techniques quite some important

1268
01:17:23,040 --> 01:17:25,170
and then i

1269
01:17:25,180 --> 01:17:29,500
and in general thing i also included the light

1270
01:17:29,510 --> 01:17:34,100
of the people who i very much

1271
01:17:34,110 --> 01:17:37,540
communications of the two thousand six

1272
01:17:37,790 --> 01:17:40,900
where he advocated access to

1273
01:17:40,990 --> 01:17:46,640
so as a better i just keywords

1274
01:17:46,660 --> 01:17:50,130
so that you know that our technology our information

1275
01:17:51,800 --> 01:17:53,040
they should focus

1276
01:17:53,050 --> 01:17:57,700
on the number of deaths that's really help you

1277
01:17:57,730 --> 01:17:59,840
in finding information

1278
01:17:59,850 --> 01:18:06,690
but not only finding information that will help you improve your problems comparing information integrating

1279
01:18:06,690 --> 01:18:09,970
information so more and more intelligent

1280
01:18:10,090 --> 01:18:13,380
agent of systems that could be built

1281
01:18:13,900 --> 01:18:16,600
so he spoke about look

1282
01:18:16,610 --> 01:18:18,700
and of course we need to think about

1283
01:18:20,040 --> 01:18:23,800
in fact text mining usually

1284
01:18:23,800 --> 01:18:28,760
now as you here on several occasions over the course semester on the philosopher what

1285
01:18:28,760 --> 01:18:31,240
that means is i don't really know a whole lot of facts

1286
01:18:31,820 --> 01:18:35,390
and so i'm about to tell you a story where i wish i knew the

1287
01:18:35,390 --> 01:18:39,170
facts and i don't know the facts it if it was

1288
01:18:39,250 --> 01:18:43,020
if if i could really do it right i don't open the door and bring

1289
01:18:43,020 --> 01:18:51,000
in our guest physiologist who then provide the fact that i'm what i'm about go

1290
01:18:51,000 --> 01:18:55,740
to measure but you know we have the physiologist coming to protect and he'd actually

1291
01:18:55,740 --> 01:18:57,370
tells these things

1292
01:18:57,380 --> 01:19:00,510
i don't know i don't know them i don't have that person but

1293
01:19:00,530 --> 01:19:03,990
take a look at what happens when the body dies

1294
01:19:04,000 --> 01:19:07,780
now i know that you can kill people a lot of different ways you can

1295
01:19:08,150 --> 01:19:14,050
you can poison them you can strangle them you can shoot them in the heart

1296
01:19:15,370 --> 01:19:22,060
causal patterns that result in death may start differently but but i presume that they

1297
01:19:23,560 --> 01:19:28,040
and you end up having this as a set of events take place now what

1298
01:19:28,040 --> 01:19:32,160
are those events this is this is exactly where i don't really know what

1299
01:19:32,210 --> 01:19:37,350
the details but i take it something like because of whatever the original input was

1300
01:19:37,410 --> 01:19:43,950
eventually the blood no longer circulating and oxygen is making its way around the body

1301
01:19:43,980 --> 01:19:49,220
and so the brain becomes oxygen star because of the lack of oxygen get into

1302
01:19:49,230 --> 01:19:55,540
the cells the cells are no longer able to carry on the various metabolic processes

1303
01:19:55,580 --> 01:20:00,660
because of this they can repair the various kinds of damage they need to create

1304
01:20:00,660 --> 01:20:04,090
the amino acids in proteins they need and so

1305
01:20:04,170 --> 01:20:09,310
the decay begins to set in the cell structures began to break down they don't

1306
01:20:09,310 --> 01:20:10,870
get repaired as they would normally do

1307
01:20:11,320 --> 01:20:16,270
so eventually have breakdown of the crucial cell structure boom the bodies that that's a

1308
01:20:16,270 --> 01:20:18,070
i don't really know

1309
01:20:18,080 --> 01:20:24,150
whether that's accurate below rough story editor with some story like that's probably right

1310
01:20:24,170 --> 01:20:29,310
and in typical philosophical fashion i draw on that story for you up here on

1311
01:20:29,310 --> 01:20:30,210
the board

1312
01:20:31,560 --> 01:20:36,210
the events that i don't really know the details of how we can just call

1313
01:20:36,230 --> 01:20:38,190
b one b two

1314
01:20:38,200 --> 01:20:39,280
b three

1315
01:20:39,300 --> 01:20:41,210
up through b and

1316
01:20:41,220 --> 01:20:45,200
so you know before b one begins you've got you know the body

1317
01:20:45,220 --> 01:20:51,160
working function in its bodily way respirator reproducing the cells and so forth and so

1318
01:20:51,910 --> 01:20:56,660
and at the end of the of the process by b and the body is

1319
01:20:58,530 --> 01:21:03,070
so you would be for bodily b one through bn

1320
01:21:03,120 --> 01:21:06,490
that's what this is a list of the death of the body is

1321
01:21:06,540 --> 01:21:09,920
this is a it's the sort of thing that somebody from the medical school or

1322
01:21:09,920 --> 01:21:15,010
biologist physiologist something could could describe for us

1323
01:21:15,020 --> 01:21:20,700
so here's the question then suppose we call that process

1324
01:21:20,720 --> 01:21:24,040
death of the body

1325
01:21:24,060 --> 01:21:31,460
paul what has occurred by the end of that sequence of events bodily death

1326
01:21:31,480 --> 01:21:34,040
now a question that we can still ask

1327
01:21:34,090 --> 01:21:37,270
o is it looks as though we can still ask it

1328
01:21:37,280 --> 01:21:41,880
my i or do all i still exist

1329
01:21:42,960 --> 01:21:45,400
the death of my body

1330
01:21:45,420 --> 01:21:50,560
might i still exist after bodily death

1331
01:21:51,570 --> 01:21:55,400
i don't mean to suggest in any way that we you know the answer to

1332
01:21:55,400 --> 01:22:00,020
that question but at least that's the question it seems as though we can coherently

1333
01:22:00,030 --> 01:22:01,430
raise there's no

1334
01:22:01,440 --> 01:22:04,490
obvious contradiction

1335
01:22:04,500 --> 01:22:13,890
in asking my i still exist after the death of my body

1336
01:22:13,900 --> 01:22:17,450
nature would turn out to be no

1337
01:22:17,480 --> 01:22:19,930
but at least it's not

1338
01:22:19,980 --> 01:22:21,560
obviously no

1339
01:22:21,580 --> 01:22:25,490
if the answer turns out to be no it's going to take some

1340
01:22:25,500 --> 01:22:27,770
some sustained argument

1341
01:22:27,780 --> 01:22:32,140
settled one way that answer could turn out to be yes for all we know

1342
01:22:32,150 --> 01:22:33,450
at this point

1343
01:22:33,500 --> 01:22:37,680
this was just brings us back to the thought that whether or not i could

1344
01:22:37,680 --> 01:22:40,370
still exist after the death of my body

1345
01:22:40,420 --> 01:22:44,320
looks like it should depend on what i am and so ornamented that's the question

1346
01:22:44,320 --> 01:22:47,110
that i'm going to turn to

1347
01:22:47,120 --> 01:22:52,600
but it's a bit cumbersome to constantly be asking you know my i still exist

1348
01:22:52,600 --> 01:22:55,210
after the death of my body

1349
01:22:55,230 --> 01:22:56,360
and so

1350
01:22:56,370 --> 01:23:00,570
no harm is done once we have clarified the question that we're trying to ask

1351
01:23:00,600 --> 01:23:01,600
if we

1352
01:23:01,610 --> 01:23:07,000
summarize that question in a bit of jargon or slogan we say instead of asking

1353
01:23:07,010 --> 01:23:10,810
might i survive might continue to exist after the death of my body we might

1354
01:23:11,600 --> 01:23:13,470
and i put it this way

1355
01:23:13,810 --> 01:23:15,520
i say for short

1356
01:23:15,540 --> 01:23:18,440
well i survived the death of my body

1357
01:23:18,460 --> 01:23:20,010
no harm done or

1358
01:23:20,020 --> 01:23:21,910
will i survive

1359
01:23:21,920 --> 01:23:23,160
my death

1360
01:23:23,210 --> 01:23:26,980
because what we just stipulating we mean when we talk about my death in the

1361
01:23:26,980 --> 01:23:30,670
context of this question is the death of my body no harm done we can

1362
01:23:30,670 --> 01:23:32,280
just say for short

1363
01:23:32,290 --> 01:23:36,920
you will i survive my death might i survived my death

1364
01:23:36,940 --> 01:23:38,420
or for that matter

1365
01:23:38,440 --> 01:23:41,650
no serious harm done if we ask is there

1366
01:23:42,710 --> 01:23:43,940
after death

1367
01:23:43,960 --> 01:23:47,840
as long as we understand that we're not asking about there is life of my

1368
01:23:49,260 --> 01:23:54,390
just another familiar way of trying to ask well i still be around after my

1369
01:23:54,390 --> 01:23:59,440
death will i still exist after my idea so i think is a perfectly legitimate

1370
01:24:01,050 --> 01:24:04,370
and that's the question we now want to turn to

1371
01:24:04,390 --> 01:24:08,940
now as i said it looks as though to answer the question you could i

1372
01:24:08,940 --> 01:24:11,890
continued to exist after the death of my body

1373
01:24:11,900 --> 01:24:15,800
is there life after death could i survive my death for short

1374
01:24:15,820 --> 01:24:17,970
to answer that question we need to get clear

1375
01:24:17,980 --> 01:24:21,610
about what exactly is it for something to be me

1376
01:24:21,620 --> 01:24:24,820
that's the question will turn to a couple of weeks

1377
01:24:24,830 --> 01:24:27,030
first we've got to get clear about

1378
01:24:28,260 --> 01:24:30,030
what am i

1379
01:24:30,050 --> 01:24:34,080
what kind of an entity

1380
01:24:34,090 --> 01:24:39,750
when i made in philosophical jargon this is of course a question from metaphysics so

1381
01:24:39,800 --> 01:24:45,720
last the metaphysical question what kind of thing is a person

1382
01:24:45,730 --> 01:24:49,620
is it seems plausible to think that whether or not

1383
01:24:49,710 --> 01:24:54,220
a person can survive or continue to exist after the death of his or her

1384
01:24:54,220 --> 01:24:59,430
body should depend on how he's built what he's made of what his or her

1385
01:24:59,690 --> 01:25:01,940
parts are

1386
01:25:03,810 --> 01:25:06,050
when the sketch for you

1387
01:25:07,230 --> 01:25:10,800
basic positions on this question

1388
01:25:10,840 --> 01:25:13,840
what is the person two basic positions

1389
01:25:13,860 --> 01:25:18,840
they're both i imagine a fairly familiar

1390
01:25:18,840 --> 01:25:22,200
you may ask me why didn't you give the error in the

1391
01:25:22,210 --> 01:25:26,120
diameter which ultimately of course translates into the air in the mass

1392
01:25:26,210 --> 01:25:30,090
the reason is that these are so precisely the way you buy them that the

1393
01:25:30,120 --> 01:25:35,210
uncertainty is completely negligible compared to the timing error that i make so i won't

1394
01:25:35,900 --> 01:25:39,410
take that into account

1395
01:25:39,450 --> 01:25:40,960
all right so now

1396
01:25:40,980 --> 01:25:43,190
we can start the

1397
01:25:45,340 --> 01:25:48,480
and i have to switch

1398
01:25:48,510 --> 01:25:50,660
two this unit here

1399
01:25:50,660 --> 01:25:54,390
here is this

1400
01:25:54,400 --> 01:25:56,590
container with the

1401
01:25:56,610 --> 01:25:59,520
carol sierra

1402
01:25:59,640 --> 01:26:03,890
it is very sticky indeed

1403
01:26:03,950 --> 01:26:07,940
you see that seven marks and just for my own convenience

1404
01:26:07,950 --> 01:26:10,160
i have put there

1405
01:26:10,180 --> 01:26:11,110
two black

1406
01:26:11,130 --> 01:26:14,570
mark so that i can easily see

1407
01:26:14,630 --> 01:26:16,740
the moment that i have to start my timer

1408
01:26:16,770 --> 01:26:20,360
and the moment that i stop it there's so many lines i may get confused

1409
01:26:20,370 --> 01:26:22,400
if i don't do that

1410
01:26:22,420 --> 01:26:26,600
and we going to time this together

1411
01:26:26,610 --> 01:26:30,110
and we'll see how these objects

1412
01:26:30,120 --> 01:26:32,360
how long it takes for them to go through

1413
01:26:32,370 --> 01:26:34,180
i will start with my one eight

1414
01:26:34,200 --> 01:26:37,480
of and in diameter

1415
01:26:37,540 --> 01:26:38,880
i have one here

1416
01:26:38,890 --> 01:26:42,840
trees are

1417
01:26:42,850 --> 01:26:45,260
i deleted zero

1418
01:26:45,320 --> 01:26:47,950
three all you can see that you should see that

1419
01:26:47,950 --> 01:26:51,120
three two one zero

1420
01:26:51,170 --> 01:26:54,690
look how beautiful it working its way through you seem to believe

1421
01:26:54,710 --> 01:26:56,340
so this using a knife

1422
01:26:56,380 --> 01:26:58,630
and but one of the top

1423
01:26:58,640 --> 01:27:02,480
going very slowly but just wait when it has broken through the surface

1424
01:27:02,500 --> 01:27:03,950
and also

1425
01:27:06,180 --> 01:27:07,360
one centimeter

1426
01:27:07,370 --> 01:27:08,490
two centimetres

1427
01:27:08,510 --> 01:27:10,210
three centimetres

1428
01:27:12,320 --> 01:27:13,590
what is that

1429
01:27:15,210 --> 01:27:18,730
what happened

1430
01:27:18,790 --> 01:27:22,460
i don't see it i wanted do another one

1431
01:27:22,510 --> 01:27:27,140
what i did i cleaned it i erase it

1432
01:27:27,220 --> 01:27:29,560
what was it

1433
01:27:29,590 --> 01:27:34,370
five point nine three

1434
01:27:34,380 --> 01:27:39,150
keep that in mind is nice to see whether they reproduce sexually

1435
01:27:39,200 --> 01:27:42,130
OK there goes

1436
01:27:43,410 --> 01:27:44,900
one centimeter

1437
01:27:44,950 --> 01:27:46,340
two centimetres

1438
01:27:46,420 --> 01:27:47,790
three centimetres

1439
01:27:49,120 --> 01:27:53,320
five point six six units shows you the uncertainty in my timing so we had

1440
01:27:53,320 --> 01:27:55,360
a five point nine three

1441
01:27:55,950 --> 01:27:58,000
and we have now five point six

1442
01:27:58,980 --> 01:28:02,460
it's not so bad five point nine five point seven

1443
01:28:02,480 --> 01:28:06,050
binding are tens of second my timing could be a little bit larger than the

1444
01:28:06,050 --> 01:28:08,710
tens of second you don't have very much time

1445
01:28:08,710 --> 01:28:10,820
so now we go to the

1446
01:28:10,890 --> 01:28:16,200
five thirty seconds

1447
01:28:17,620 --> 01:28:23,560
by thirty seconds

1448
01:28:23,620 --> 01:28:27,020
take some time to break through the surface and that funny because the thin film

1449
01:28:27,020 --> 01:28:29,470
has formed on the surface of the syrup

1450
01:28:29,500 --> 01:28:31,880
due to its exposure to air

1451
01:28:31,880 --> 01:28:33,980
wonderful had let's wait

1452
01:28:34,070 --> 01:28:36,010
patiently but now it goes

1453
01:28:36,060 --> 01:28:37,520
it goes now

1454
01:28:42,030 --> 01:28:44,710
three point eight zero

1455
01:28:44,710 --> 01:28:46,930
that which you have

1456
01:28:47,030 --> 01:28:52,300
it's going to be tougher and tougher for me

1457
01:28:52,530 --> 01:28:56,130
three sixteen to one inch

1458
01:28:56,170 --> 01:28:59,010
it's actually a good thing that it stays for a while at the surface so

1459
01:28:59,010 --> 01:29:00,390
that i can

1460
01:29:00,400 --> 01:29:05,340
get really

1461
01:29:05,350 --> 01:29:08,550
really that really helps us doesn't

1462
01:29:08,600 --> 01:29:10,650
if didn't want to go

1463
01:29:10,700 --> 01:29:14,410
you know even see it

1464
01:29:15,490 --> 01:29:16,270
here we go

1465
01:29:19,010 --> 01:29:22,210
now you see it's very hard for me and so i could easily

1466
01:29:22,210 --> 01:29:25,270
i have a substantial error two point six nine

1467
01:29:28,030 --> 01:29:29,240
and now we have the

1468
01:29:29,250 --> 01:29:31,150
a quarter inch

1469
01:29:31,170 --> 01:29:34,720
real big one

1470
01:29:34,780 --> 01:29:39,650
i have to do it again

1471
01:29:39,700 --> 01:29:41,280
i don't trust his at all

1472
01:29:41,350 --> 01:29:51,940
when it went to the surface too fast

1473
01:29:51,960 --> 01:29:56,450
i can do it very accurate was the first number by the way

1474
01:29:56,460 --> 01:29:58,350
one point

1475
01:29:58,390 --> 01:29:59,450
six eight

1476
01:29:59,470 --> 01:30:01,300
and this is one point four zero

1477
01:30:01,320 --> 01:30:03,440
one point six eight

1478
01:30:03,450 --> 01:30:05,170
and one point for zero

1479
01:30:05,180 --> 01:30:07,460
you see i wasn't kidding when i say that my

1480
01:30:07,480 --> 01:30:09,300
uncertainty could easily be

1481
01:30:09,310 --> 01:30:11,230
o point two now

1482
01:30:11,240 --> 01:30:13,300
come the acid test

1483
01:30:13,350 --> 01:30:14,870
and yes test this

1484
01:30:15,570 --> 01:30:16,700
if i'm

1485
01:30:16,710 --> 01:30:20,620
if the measurements were done correctly and if we really work in that regime

1486
01:30:20,630 --> 01:30:21,780
and if i plot

1487
01:30:21,800 --> 01:30:25,990
one hundred divided by the square resisting only the paper

1488
01:30:26,000 --> 01:30:27,570
then it should be

1489
01:30:27,620 --> 01:30:33,380
a straight line

1490
01:30:33,420 --> 01:30:35,620
all rights

1491
01:30:35,630 --> 01:30:36,930
he i have the plot

1492
01:30:36,940 --> 01:30:39,680
which i prepared

1493
01:30:39,730 --> 01:30:42,650
and i'm going to put these numbers in there

1494
01:30:42,690 --> 01:30:44,150
so first

1495
01:30:44,160 --> 01:30:46,120
we're going to get six points

1496
01:30:46,140 --> 01:30:49,420
five point lead forty five point eight seconds

1497
01:30:49,470 --> 01:30:51,410
for the

1498
01:30:51,450 --> 01:30:53,020
the smallest

1499
01:30:53,070 --> 01:30:54,150
ball bearings

1500
01:30:54,150 --> 01:30:55,950
this is the smallest one

1501
01:30:55,970 --> 01:30:59,850
don't be misled because this is one hundred divided by the square

1502
01:30:59,890 --> 01:31:02,130
but this is the smallest one

1503
01:31:02,180 --> 01:31:05,320
five point eight

1504
01:31:05,380 --> 01:31:08,460
so we are here on this line

1505
01:31:08,480 --> 01:31:10,860
and we are at five

1506
01:31:10,860 --> 01:31:13,770
o point eight somewhere here

1507
01:31:13,800 --> 01:31:16,500
that's it

1508
01:31:17,500 --> 01:31:19,790
the point is lower than you expected

1509
01:31:19,830 --> 01:31:21,880
the reason is the temperature went up

1510
01:31:21,940 --> 01:31:23,340
if the temperature went up

1511
01:31:23,360 --> 01:31:26,970
then the viscosity goes down and they go fast but that's okay

1512
01:31:27,030 --> 01:31:28,290
it doesn't worry me

1513
01:31:28,340 --> 01:31:29,410
the next one

1514
01:31:29,420 --> 01:31:32,850
three point eight o

1515
01:31:32,900 --> 01:31:34,920
four three point

1516
01:31:34,970 --> 01:31:36,230
eight o

1517
01:31:37,510 --> 01:31:39,190
you see that

1518
01:31:39,190 --> 01:31:43,290
i predicted that straight line

1519
01:31:43,350 --> 01:31:47,210
administrator straight-line

1520
01:31:47,260 --> 01:31:50,440
not a straight line

1521
01:31:50,480 --> 01:31:54,730
but from

1522
01:31:54,790 --> 01:31:56,820
OK will put in a point

1523
01:31:56,900 --> 01:32:00,760
o point six nine

1524
01:32:00,820 --> 01:32:04,240
to point

1525
01:32:04,290 --> 01:32:08,940
this is two point seven two point six nine

1526
01:32:08,950 --> 01:32:12,440
i can hardly put in the air of the time because it is not much

1527
01:32:12,440 --> 01:32:15,400
larger than the size of my dot

1528
01:32:15,410 --> 01:32:17,220
and now we have the last one

1529
01:32:17,280 --> 01:32:19,690
one point let's take the average

1530
01:32:19,760 --> 01:32:23,170
one four and five five

1531
01:32:23,220 --> 01:32:26,410
one point five five

1532
01:32:26,490 --> 01:32:28,650
is an area of about two two-tenths

1533
01:32:28,730 --> 01:32:31,710
the second this is an area of about two turns

1534
01:32:31,750 --> 01:32:33,450
of the second

1535
01:32:33,510 --> 01:32:35,700
all right there we go

1536
01:32:38,790 --> 01:32:40,740
is this a straight line

1537
01:32:40,790 --> 01:32:44,680
or is it not

1538
01:32:44,720 --> 01:32:48,250
gorgeous straight line so you see you are really working here

1539
01:32:48,260 --> 01:32:49,210
in the

1540
01:32:51,170 --> 01:32:53,440
one over

1541
01:32:53,460 --> 01:32:55,090
in enriching where the

1542
01:32:55,090 --> 01:32:56,570
terminal velocity

1543
01:32:56,630 --> 01:32:57,360
it is

1544
01:32:57,400 --> 01:33:00,090
proportional to the radius squared

1545
01:33:00,110 --> 01:33:04,470
OK we'll will give you the lights back

1546
01:33:04,500 --> 01:33:08,110
now comes the question which is relevant to this experiment

1547
01:33:08,110 --> 01:33:10,560
and that is how long does it take

1548
01:33:10,620 --> 01:33:12,000
for the

1549
01:33:12,020 --> 01:33:14,880
terminal speeds to be reached

1550
01:33:17,470 --> 01:33:19,290
the object has a certain mass

1551
01:33:19,300 --> 01:33:21,160
so does gravitational

1552
01:33:21,200 --> 01:33:23,970
the force on it

1553
01:33:23,990 --> 01:33:26,290
and the gravitational force equals

1554
01:33:26,350 --> 01:33:27,410
and g

1555
01:33:27,540 --> 01:33:30,970
and then there's is a resistive force

1556
01:33:30,970 --> 01:33:32,620
because the timings

1557
01:33:32,640 --> 01:33:37,130
so this this year the data matrix part and here we see here

1558
01:33:37,140 --> 01:33:39,110
if ten times as much data

1559
01:33:39,130 --> 01:33:40,870
and we need ten times

1560
01:33:40,920 --> 01:33:47,010
it's much computational time total time secs actually scared sublinear yourself is other stuff and

1561
01:33:47,010 --> 01:33:50,810
one of the actual solving the linear equation system

1562
01:33:50,860 --> 01:33:52,680
so that way we can

1563
01:33:54,420 --> 01:33:56,550
in opinion

1564
01:33:56,570 --> 01:34:01,130
and the results are quite quite pieces of about eighty five percent we the find

1565
01:34:01,130 --> 01:34:02,060
much other

1566
01:34:02,100 --> 01:34:05,070
he took this from from mother as it did for

1567
01:34:05,090 --> 01:34:09,510
and yes a support vector machine but we didn't find anything and only a bit

1568
01:34:09,520 --> 01:34:14,010
too much data for that

1569
01:34:14,020 --> 01:34:16,970
we did some comparison with other methods

1570
01:34:16,980 --> 01:34:23,410
these are all small datasets about things because as many fossils of cells and we

1571
01:34:23,410 --> 01:34:26,240
don't really think that's was there were that

1572
01:34:26,260 --> 01:34:29,840
small datasets the thing with this attribute views on that

1573
01:34:29,850 --> 01:34:31,540
but still there we

1574
01:34:33,420 --> 01:34:37,690
from good to bad so there's whole range is there

1575
01:34:37,710 --> 01:34:39,780
so what is still

1576
01:34:39,790 --> 01:34:41,340
o thing doing OK

1577
01:34:41,370 --> 01:34:43,220
could be bit better no walls

1578
01:34:43,230 --> 01:34:44,420
show now

1579
01:34:44,450 --> 01:34:46,580
some improvement recently that

1580
01:34:46,600 --> 01:34:52,230
what we do better didn't have redundant measurements for the classification have some regression examples

1581
01:34:52,230 --> 01:34:53,840
later on

1582
01:34:53,860 --> 01:34:57,690
we're doing much better in comparison to somerset

1583
01:34:57,910 --> 01:35:00,400
the reason we looked in that

1584
01:35:00,420 --> 01:35:05,270
the figure that we have some strange things in this of something strange assume there

1585
01:35:05,280 --> 01:35:06,490
is something wrong

1586
01:35:06,500 --> 01:35:07,880
and the

1587
01:35:07,900 --> 01:35:09,170
but look standard

1588
01:35:09,220 --> 01:35:12,130
realize the combination that actually can diverge

1589
01:35:12,140 --> 01:35:18,800
so this is simple problem two dimensions this function we just computed some samples

1590
01:35:18,820 --> 01:35:23,060
random data points

1591
01:35:23,070 --> 01:35:26,710
run the combination technique we have here is a realisation parameter ten to the minus

1592
01:35:26,710 --> 01:35:28,580
four he ten six

1593
01:35:29,530 --> 01:35:30,460
let's see you

1594
01:35:30,730 --> 01:35:36,360
it is the least square error the functional

1595
01:35:36,410 --> 01:35:38,990
the functional at some point afterwards

1596
01:35:39,110 --> 01:35:42,440
we can expect because these two terms and at some point we can't really get

1597
01:35:42,440 --> 01:35:47,070
close to him to be more refinement order of the same

1598
01:35:47,080 --> 01:35:51,040
so we can get closer to the function we would get closer to

1599
01:35:51,050 --> 01:35:53,830
continuous solution which is just message

1600
01:35:53,880 --> 01:35:57,340
the residual functional centre at some point

1601
01:35:57,380 --> 01:36:01,920
but what's bad if you look at times one of six original to get down

1602
01:36:01,960 --> 01:36:05,770
and then we said to it and then it get worse again so far higher

1603
01:36:05,770 --> 01:36:09,060
refinement level but we get worse results that can happen

1604
01:36:09,080 --> 01:36:10,170
it should have

1605
01:36:10,230 --> 01:36:12,610
the true rational approach

1606
01:36:12,660 --> 01:36:15,840
the better is the higher the refinement about better solution is

1607
01:36:15,850 --> 01:36:17,050
so we did

1608
01:36:17,070 --> 01:36:21,780
i had a bit closer look at that what essentially went down to a very

1609
01:36:22,870 --> 01:36:25,070
two space k so we only have two

1610
01:36:25,090 --> 01:36:26,450
space of

1611
01:36:26,470 --> 01:36:27,670
we want to be too

1612
01:36:27,680 --> 01:36:29,740
and joint space

1613
01:36:29,750 --> 01:36:34,020
we felt that because the combination technique is optimal

1614
01:36:34,040 --> 01:36:40,370
additive approximation methods such as additive approximation method combination that would have won one minus

1615
01:36:40,370 --> 01:36:41,930
one and we just OK

1616
01:36:43,020 --> 01:36:46,860
let's allow any c one c two c one two we could show that the

1617
01:36:46,870 --> 01:36:50,800
commission is optimal in the worst case sense

1618
01:36:50,820 --> 01:36:53,240
so only the worst case and the commissioning

1619
01:36:53,260 --> 01:36:54,310
i want to use

1620
01:36:54,330 --> 01:36:57,350
this combination technique introduced

1621
01:36:57,360 --> 01:37:00,200
and his son could show

1622
01:37:00,210 --> 01:37:01,430
skip is

1623
01:37:01,440 --> 01:37:05,190
was equipped contract could

1624
01:37:05,210 --> 01:37:10,600
thirteen optimised combination technique which goes back microsecond set in two thousand three

1625
01:37:12,920 --> 01:37:14,940
so the sea

1626
01:37:14,950 --> 01:37:17,890
norman sparse grid solution this is

1627
01:37:17,940 --> 01:37:19,340
combinations of

1628
01:37:19,360 --> 01:37:20,650
no we allow

1629
01:37:20,670 --> 01:37:22,360
these coefficients

1630
01:37:22,370 --> 01:37:26,180
this is a partial solution no we those the coefficients to vary

1631
01:37:26,190 --> 01:37:33,260
so we down uses coefficient before this alternating binomial coefficients but we actually computers coefficients

1632
01:37:33,340 --> 01:37:36,770
a simple expansion of the strongest

1633
01:37:36,790 --> 01:37:38,200
so we have to

1634
01:37:38,220 --> 01:37:42,690
one of these induce some properties of the system the system

1635
01:37:42,710 --> 01:37:46,620
the stem depends on the resolution but the minimum

1636
01:37:46,680 --> 01:37:48,610
of this

1637
01:37:48,630 --> 01:37:50,510
it doesn't depend on that

1638
01:37:50,520 --> 01:37:54,570
so we only have system that you can actually computers scalar product of

1639
01:37:54,620 --> 01:37:56,490
between the partial solutions

1640
01:37:56,500 --> 01:37:58,910
number of partial solutions

1641
01:37:58,910 --> 01:38:03,470
gamma distribution is the conjugate prior for it that's the one that gives an easy

1642
01:38:03,470 --> 01:38:09,970
sampling algorithm we lose you will we have a tougher sampling algorithm to generate if

1643
01:38:09,970 --> 01:38:11,630
it's if itself stable

1644
01:38:11,660 --> 01:38:15,480
and i just wanted to compare the fit because of use inverted gamma you end

1645
01:38:15,480 --> 01:38:20,160
up with the student t distribution for if you use this positive stable

1646
01:38:20,170 --> 01:38:23,370
and you end up with the alpha stable distributions so we found that we got

1647
01:38:23,370 --> 01:38:30,820
slightly better fit in the tails of the distribution using the office stable shown the

1648
01:38:30,820 --> 01:38:35,550
dotted line compared against the true data solid line so looked like we were reasonably

1649
01:38:35,550 --> 01:38:40,920
in business we're getting slightly better fit to the to the noise data using this

1650
01:38:40,940 --> 01:38:42,560
alpha stable model

1651
01:38:42,580 --> 01:38:47,210
and for symmetric stable distributions actually there's some really interesting stuff you can do for

1652
01:38:47,210 --> 01:38:50,580
nonsymmetric ones based on series of process

1653
01:38:50,600 --> 01:38:55,890
random variables something we've been looking at recently but for symmetric once we have this

1654
01:38:55,890 --> 01:38:59,450
basic result it says that

1655
01:38:59,450 --> 01:39:03,470
if you take the product of two alpha stable distributions and will take x one

1656
01:39:03,480 --> 01:39:05,480
to be gaussians

1657
01:39:05,530 --> 01:39:11,200
and x two to be a special positive stable random variable then the product of

1658
01:39:11,200 --> 01:39:12,000
the two

1659
01:39:12,020 --> 01:39:18,760
is an alpha stable random variable with the with taylor parameter tells the parameter alpha

1660
01:39:18,760 --> 01:39:21,960
one times offered to the individual offers

1661
01:39:24,710 --> 01:39:28,340
so basically as if we take

1662
01:39:28,400 --> 01:39:34,950
x one then to be galaxies understand the calcium standing outside you can either soak

1663
01:39:34,950 --> 01:39:39,020
up the scale parameter within the next two or the x one i think we

1664
01:39:39,020 --> 01:39:42,640
take it to be in in the x two so we take a stand calcium

1665
01:39:42,640 --> 01:39:50,060
for x one and multiply by perfectly skewed positive skewed stable random variable

1666
01:39:50,080 --> 01:39:52,520
with parameter alpha o two

1667
01:39:52,520 --> 01:39:57,560
then you end up with then you end up with an alpha stable random variable

1668
01:39:57,560 --> 01:40:01,440
for the product x one x two and that's what we need for

1669
01:40:03,030 --> 01:40:07,640
so given that x one is calcium next two is nongaussian

1670
01:40:07,750 --> 01:40:11,700
will augment the model with x one and x two at each timepoint is part

1671
01:40:11,700 --> 01:40:13,270
of the state vector

1672
01:40:13,280 --> 01:40:16,880
and then we have a conditionally gaussians model

1673
01:40:17,550 --> 01:40:19,550
x one conditional upon x two

1674
01:40:19,570 --> 01:40:26,730
linear and garcia that means we can apply the rare blackwellized particle filter to it

1675
01:40:26,850 --> 01:40:29,270
and then we have paper where we

1676
01:40:29,310 --> 01:40:34,090
it is for this type of model and it just garcia noise this is an

1677
01:40:34,090 --> 01:40:38,630
extension of the nongaussian case and well

1678
01:40:39,020 --> 01:40:45,540
a great deal to say about this is a synthetic example where we take this

1679
01:40:45,540 --> 01:40:50,780
sound waveform corrupted with stable noise and then reconstruct

1680
01:40:50,780 --> 01:40:52,130
the signal from it

1681
01:40:52,160 --> 01:40:54,610
works quite well sounds OK

1682
01:40:54,730 --> 01:40:59,940
we can construct

1683
01:40:59,980 --> 01:41:06,080
ninety five percent confidence intervals where the signal will be based on the filtering output

1684
01:41:06,080 --> 01:41:15,270
show we can just about see the dotted lines that

1685
01:41:15,300 --> 01:41:18,600
we can estimate the parameters of the model and see how the time varying are

1686
01:41:18,600 --> 01:41:26,560
parameters of the signal model very over time with quantiles on those as well

1687
01:41:26,630 --> 01:41:31,610
and we can also i haven't said very much about parameter estimation will also able

1688
01:41:31,610 --> 01:41:38,290
to make a fairly stable estimates for the constant parameter alpha was simply extended the

1689
01:41:38,290 --> 01:41:44,300
state space by one two of the state vector to include the alpha variable itself

1690
01:41:44,520 --> 01:41:50,140
and applied a time jeter on it so we that it's slightly random parameters that

1691
01:41:50,160 --> 01:41:53,830
there is a little bit from time to times that and we get some kernel

1692
01:41:53,850 --> 01:41:59,170
smooth density estimates for the posterior four alpha which says it's around about point one

1693
01:41:59,170 --> 01:42:02,320
one point for most of the time which seems reasonable

1694
01:42:02,330 --> 01:42:04,360
two us

1695
01:42:08,550 --> 01:42:15,270
and very little sort of time so probably skip past this example but another rare

1696
01:42:15,290 --> 01:42:22,140
blacklist filter example where we had some fun balls with nonlinear distortion correction so very

1697
01:42:22,140 --> 01:42:30,200
nonlinear observation function in this case so we basically now modelling

1698
01:42:30,220 --> 01:42:33,510
the the observed data

1699
01:42:33,520 --> 01:42:39,560
so as non-linear clipping or a non-linear clipping or quantization

1700
01:42:40,610 --> 01:42:46,160
the original signals and again quantization is something that get in in

1701
01:42:46,170 --> 01:42:52,360
audio signals when the idea you get overloaded on the digital sampler or that give

1702
01:42:53,100 --> 01:42:58,650
or else you get something that's too heavily quantized because the recording levels set too

1703
01:42:58,650 --> 01:43:03,730
low this is quite useful thing to be able to restore so

1704
01:43:05,320 --> 01:43:09,330
so the kind of this would be content appear quantisation function if this is your

1705
01:43:09,330 --> 01:43:14,220
input signal then this is what you observe the output according to the quantization step

1706
01:43:16,250 --> 01:43:17,290
and inverse

1707
01:43:17,300 --> 01:43:24,050
mapping really is one to many because for each observed y value there are many

1708
01:43:24,080 --> 01:43:26,650
z values signal values that could

1709
01:43:27,400 --> 01:43:33,820
and in terms of probability distributions we can think of a likelihood function which is

1710
01:43:33,820 --> 01:43:36,850
the dirac point mass centered upon the

1711
01:43:37,340 --> 01:43:39,800
clicked value of the unseen signal

1712
01:43:39,810 --> 01:43:43,780
z w that is our likelihood function for clipping

1713
01:43:43,900 --> 01:43:46,390
it's a deterministic

1714
01:43:46,450 --> 01:43:50,870
function we can still build that into the particle filter and we do exactly the

1715
01:43:50,870 --> 01:43:55,060
same thing with the signal process itself we assume that the underlying musical we're gonna

1716
01:43:55,080 --> 01:43:56,540
be clipping musical

1717
01:43:56,560 --> 01:44:02,960
audio signals is the time varying autoregressive process with one of these time varying evolving

1718
01:44:02,960 --> 01:44:05,480
parameters have to

1719
01:44:05,530 --> 01:44:07,710
this time

1720
01:44:07,720 --> 01:44:10,220
instead of using complicated nonlinear

1721
01:44:10,270 --> 01:44:14,130
parameterisation of the model i used precisely this i just have a galaxy in vector

1722
01:44:14,130 --> 01:44:15,560
random walk on the

1723
01:44:15,560 --> 01:44:19,900
also the in fission our written to implement

1724
01:44:20,710 --> 01:44:23,100
should land examples

1725
01:44:23,110 --> 01:44:26,100
it's actually the lambda point nine works better than lambda one

1726
01:44:26,150 --> 01:44:30,750
and to zero and the other ones

1727
01:44:30,760 --> 01:44:34,460
OK now that was the value approach to listen to the good let's look at

1728
01:44:34,460 --> 01:44:37,710
the source lambda which is the q value approach

1729
01:44:38,380 --> 01:44:40,090
again the policy is fixed

1730
01:44:41,340 --> 01:44:45,660
and again you still get different returns to average you still get l a way

1731
01:44:45,660 --> 01:44:48,740
to give you the eligibility trace

1732
01:44:48,750 --> 01:44:50,600
and weight update the q values

1733
01:44:50,620 --> 01:44:55,160
OK it's very interesting finding this you know it will take very little time

1734
01:44:55,170 --> 01:44:58,100
for support when

1735
01:44:59,730 --> 01:45:01,930
skip decides

1736
01:45:01,950 --> 01:45:06,770
so there is one slight problem with the eligibility trace

1737
01:45:06,870 --> 01:45:08,050
and that is

1738
01:45:08,090 --> 01:45:12,080
if you visit st lots of saying this example

1739
01:45:12,100 --> 01:45:17,140
estate eligibility to be updated can become greater than one

1740
01:45:18,530 --> 01:45:20,320
or q values

1741
01:45:20,370 --> 01:45:22,730
how do have typically become greater than one

1742
01:45:22,770 --> 01:45:24,830
so look at this example

1743
01:45:24,840 --> 01:45:28,160
why might be able to retrace be a bad idea

1744
01:45:31,900 --> 01:45:34,590
so what happens if i is in the middle stage

1745
01:45:34,620 --> 01:45:38,710
and i took the wrong move ten times

1746
01:45:38,750 --> 01:45:42,090
and then i mean that to the right to the end

1747
01:45:42,740 --> 01:45:48,140
effectively the ability of the of the cue value for doing state would be around

1748
01:45:49,070 --> 01:45:50,840
with some discounting

1749
01:45:50,890 --> 01:45:55,870
OK so you can see what was adopted it was they are doing wrong the

1750
01:45:55,870 --> 01:45:58,340
state really is the high value

1751
01:45:59,360 --> 01:46:05,050
in practice you do see sort of issues with the elderly trees so is simple

1752
01:46:05,090 --> 01:46:09,810
idea car replacing traces which is that instead of

1753
01:46:09,860 --> 01:46:13,250
before we the deal the of interest was it was it we just add one

1754
01:46:13,260 --> 01:46:14,960
to the current trace

1755
01:46:15,010 --> 01:46:18,140
here we just set to one so when you're like a great one

1756
01:46:18,170 --> 01:46:22,140
OK you find this actually leads to much better performance in practice

1757
01:46:22,180 --> 01:46:27,300
and you you will if you went to and you will run the problem is

1758
01:46:27,300 --> 01:46:31,410
that the students work on this recently and and after four days and we didn't

1759
01:46:31,420 --> 01:46:35,270
have the y that was working on wi-fi look at this was actually the problem

1760
01:46:35,280 --> 01:46:40,140
so this does happen to be did st where replacing traces

1761
01:46:40,200 --> 01:46:44,260
so this would probably ruin the equivalent of the four produced by in practice it

1762
01:46:44,260 --> 01:46:50,000
works like more efficiently

1763
01:46:50,000 --> 01:46:53,670
so here's replacing traces to learn a lower error

1764
01:46:53,690 --> 01:46:57,520
by function

1765
01:46:58,080 --> 01:47:02,150
so good summarize we had four to use the standard back review which is easy

1766
01:47:02,150 --> 01:47:04,760
to compute the equivalent

1767
01:47:04,800 --> 01:47:12,090
the the whole idea of this is just averaging estimators

1768
01:47:15,320 --> 01:47:17,540
pretty well actually

1769
01:47:17,590 --> 01:47:23,200
so let me cover

1770
01:47:23,210 --> 01:47:27,640
i've got a few slides here it just doesn't high-level issues with our own

1771
01:47:27,680 --> 01:47:30,730
what a great because it's actually not coffee

1772
01:47:30,760 --> 01:47:36,600
and then the cover function approximation which if you actually want to go out in

1773
01:47:36,600 --> 01:47:41,060
many evidence and in the world you can not tabulated value for every possible state

1774
01:47:41,080 --> 01:47:44,210
or the ivory coast in action at that you would see

1775
01:47:44,270 --> 01:47:49,130
trillion states just another way to do that can a hike around new approximate value

1776
01:47:49,130 --> 01:47:53,130
function properly the q function OK so in the world you have to use approximation

1777
01:47:53,130 --> 01:47:57,130
methods and then you can start to do things like this solution to a fellow

1778
01:47:57,520 --> 01:47:59,210
or the solution to backgammon

1779
01:47:59,230 --> 01:48:01,850
and what discussed briefly at the end of the day

1780
01:48:02,250 --> 01:48:06,640
i want to discuss that then essentially you've been through almost the entire are a

1781
01:48:07,940 --> 01:48:11,830
OK it's a lot of information you'll never ending tomorrow but i didn't even when

1782
01:48:11,830 --> 01:48:14,150
you read the book it should be like

1783
01:48:14,150 --> 01:48:18,020
you have to understand is already in a good book but it helps to be

1784
01:48:18,040 --> 01:48:19,710
if that's the information

1785
01:48:19,730 --> 01:48:21,810
multiple times

1786
01:48:22,050 --> 01:48:27,860
OK so let me quickly cover just some practical issues

1787
01:48:27,920 --> 01:48:34,040
now for model based in solutions i mean claim earlier there exists an awful deterministic

1788
01:48:35,830 --> 01:48:39,730
now i'm really curious actually that when you're doing sampling methods norelli

1789
01:48:39,750 --> 01:48:41,810
you cannot use that

1790
01:48:41,860 --> 01:48:45,540
you cannot use a drug a domestic policy

1791
01:48:48,080 --> 01:48:53,290
to endure recall one

1792
01:48:57,880 --> 01:49:02,380
and with the convergence of these evidence requires that to update every state

1793
01:49:02,400 --> 01:49:04,750
with non zero probability

1794
01:49:04,750 --> 01:49:09,710
now the problem is a deterministic policy especially if bad deterministic policy

1795
01:49:09,770 --> 01:49:12,150
you might not have been all states and actions

1796
01:49:12,230 --> 01:49:15,250
but some of his actions might actually be

1797
01:49:16,040 --> 01:49:17,440
the what you should take

1798
01:49:17,440 --> 01:49:19,690
so somehow you have to explore the whole

1799
01:49:19,710 --> 01:49:22,190
and explore more you you you you certainly

1800
01:49:23,270 --> 01:49:27,400
choose a deterministic policy some actions may not be some states so you have to

1801
01:49:27,400 --> 01:49:30,380
explore all options

1802
01:49:30,440 --> 01:49:34,630
OK so to do this we use a stochastic policy

1803
01:49:34,650 --> 01:49:39,540
which means that you typically stick to policy your current greedy policy with some probability

1804
01:49:39,890 --> 01:49:42,580
is some very small probability explore we

1805
01:49:42,590 --> 01:49:45,000
previous is the this earlier

1806
01:49:45,070 --> 01:49:50,090
then you can prove convergence starting to optimality in you can read then reduce over

1807
01:49:50,090 --> 01:49:51,730
time the next

1808
01:49:53,210 --> 01:49:54,420
of policy

1809
01:49:54,440 --> 01:49:55,940
and you can show that

1810
01:49:55,960 --> 01:49:59,560
either you read you converge to

1811
01:49:59,560 --> 01:50:03,600
we if i compute the gradient with respect to the pre-activation

1812
01:50:03,610 --> 01:50:07,550
here we can see that the loss directly only depends on all the

1813
01:50:07,560 --> 01:50:11,320
pre-activation computed here so then the only bit that means that

1814
01:50:11,330 --> 01:50:15,720
is missing is what is then gradient or they're they're a of

1815
01:50:15,720 --> 01:50:19,050
these intermediate results with respect to my quantity which in

1816
01:50:19,090 --> 01:50:22,590
in our next stage is going to be the activation of the layer below

1817
01:50:22,900 --> 01:50:26,020
so that is what we'll be invoking here for performing other

1818
01:50:26,020 --> 01:50:31,820
vations so if you want the derivative of my loss function

1819
01:50:32,180 --> 01:50:36,700
now which respect to the g f unit at some

1820
01:50:37,120 --> 01:50:42,240
hidden layer k any hidden layer k well invoke the chain rule

1821
01:50:42,720 --> 01:50:46,260
and by writing it as it's just going to be the sum

1822
01:50:46,570 --> 01:50:49,500
over the derivative of my loss function here

1823
01:50:50,170 --> 01:50:52,540
with respect to all pre-activation is

1824
01:50:52,940 --> 01:50:58,810
i for all units i at the layer above so just to the pre activation

1825
01:50:58,870 --> 01:51:01,670
at the layer above that's why i have to keep plus one

1826
01:51:02,220 --> 01:51:05,290
and multiply this by what is the derivative of

1827
01:51:06,060 --> 01:51:10,020
pre-activation the layer off cape one for the unit

1828
01:51:10,340 --> 01:51:13,750
with respect to the activation at the layer k

1829
01:51:14,620 --> 01:51:18,410
for the j with unit ok just applying the chain rule here

1830
01:51:19,260 --> 01:51:22,550
and so i'm going to assume that i've computed this already

1831
01:51:23,200 --> 01:51:25,270
i've shown before we all the to compute

1832
01:51:25,450 --> 01:51:28,460
the gradient of the pre-activation at the output layer

1833
01:51:29,540 --> 01:51:33,520
and now the only but that is missing is this part here what is

1834
01:51:33,530 --> 01:51:36,370
the derivative of my pre-activation the layer above

1835
01:51:36,570 --> 01:51:39,120
just picked some activation of some units

1836
01:51:39,480 --> 01:51:43,890
in the layer below well pre-activation is quite simple is

1837
01:51:43,900 --> 01:51:47,440
just a linear transformation i'm just taking a bias

1838
01:51:47,650 --> 01:51:51,070
loss the sum of all the way to contributions of all units in the

1839
01:51:51,080 --> 01:51:55,540
layer below so if i'm taking the derivative which respect to j

1840
01:51:55,550 --> 01:51:59,050
if unit so that there would respect to the

1841
01:51:59,910 --> 01:52:03,800
pre-activation wealth with respect to the bias that zero is

1842
01:52:03,800 --> 01:52:07,250
the biases different doesn't depend on the activation of the layer

1843
01:52:07,250 --> 01:52:10,370
below and i have some over all units j

1844
01:52:10,710 --> 01:52:12,750
of the weight times the activation

1845
01:52:13,180 --> 01:52:17,440
and so all these terms here the derivative respect to

1846
01:52:17,710 --> 01:52:22,160
specific unit is going to be zero if it's not that unit so if

1847
01:52:22,170 --> 01:52:26,840
this g here is not the same j as here and when it is well you get

1848
01:52:27,020 --> 01:52:30,300
yeah scalar times my variable with respect to which i'm taking

1849
01:52:30,300 --> 01:52:33,840
the derivative so i just going to be the scalar so ultimately this

1850
01:52:33,850 --> 01:52:35,860
will simplify where this sum goes away

1851
01:52:36,200 --> 01:52:41,260
and then a remove this so i get the scalar from my variable with

1852
01:52:41,260 --> 01:52:43,480
respect to which i'm taking the derivative

1853
01:52:43,630 --> 01:52:47,980
this is why this whole term here becomes just the weight between

1854
01:52:48,250 --> 01:52:52,530
the ai with a unit of the layer above and j are unit

1855
01:52:52,730 --> 01:52:53,550
at the layer k

1856
01:52:55,670 --> 01:53:02,210
and one other way of writing this i have some over all units i

1857
01:53:02,220 --> 01:53:07,600
in my layer k of the weights the weighted

1858
01:53:08,270 --> 01:53:11,340
partial derivative respect the pre-activation at the layer

1859
01:53:11,510 --> 01:53:14,600
cape loss one one thing i could do is actually

1860
01:53:15,490 --> 01:53:18,940
considered the whole gradients so the whole gradient of

1861
01:53:20,480 --> 01:53:24,280
with respect to the pre-activation layer k and multiply

1862
01:53:24,290 --> 01:53:28,920
that c indexing with respect to ice i'm indexing over rows

1863
01:53:29,090 --> 01:53:31,680
so multiplying this by the jf column

1864
01:53:32,120 --> 01:53:36,200
of my matrix w far too right instead i explicit some actually

1865
01:53:36,210 --> 01:53:39,870
write this linear algebra so i can just write this instead as

1866
01:53:40,260 --> 01:53:43,430
the gradient of my loss with respect to my

1867
01:53:43,790 --> 01:53:45,710
pre-activation that layer plus one

1868
01:53:46,170 --> 01:53:51,390
multiplied by the j with collen of my matrix w t plus one

1869
01:53:51,610 --> 01:53:53,600
so here the notation i'm using is

1870
01:53:53,790 --> 01:53:57,110
i'm using this dot to refer to all rose

1871
01:53:58,150 --> 01:54:03,260
at the column j and so because of this you can think of the slicing

1872
01:54:03,270 --> 01:54:06,670
matrix i'm taking all rows at the specific column so then this

1873
01:54:06,680 --> 01:54:11,830
would be a column vector and so to the have become a row vector that


1
00:00:00,000 --> 00:00:05,300
and if you want to have that you have to have a prearranged agreement on

2
00:00:05,300 --> 00:00:09,480
one and two and this is something which is completely missing in XML so there

3
00:00:09,480 --> 00:00:13,080
you have label tree and that's about

4
00:00:13,120 --> 00:00:15,260
this is feasible

5
00:00:15,280 --> 00:00:20,640
if you have a closed collaboration so for example if you have agent with let's

6
00:00:20,640 --> 00:00:25,400
say agents in small and stable community so for example the best example is one

7
00:00:25,400 --> 00:00:30,760
of the ontology editors there was the ontology is also in in an XML based

8
00:00:30,760 --> 00:00:37,540
format and we defined some domain specific vocabulary namely an XML schema for our own

9
00:00:37,540 --> 00:00:43,580
purpose but then this is hard coded into our tool and other tool without having

10
00:00:44,040 --> 00:00:48,980
more knowledge can make use out of that so there's those small and stable community

11
00:00:48,980 --> 00:00:55,640
namely our institute that knows what these domain vocabulary is about so the next step

12
00:00:55,760 --> 00:00:59,720
if you want to go to the web then this of course is not scalable

13
00:00:59,960 --> 00:01:09,620
so there's a small conclusion XML is not machine accessible meaning it's basically to put

14
00:01:09,620 --> 00:01:13,040
some brackets around what you have here

15
00:01:13,180 --> 00:01:14,260
but the

16
00:01:14,280 --> 00:01:19,040
this could be also written in greek letters so it's not understandable for computer what

17
00:01:19,130 --> 00:01:21,420
really standing there

18
00:01:21,440 --> 00:01:27,640
next step what we have now as the basic infrastructure is XML and name spaces

19
00:01:27,640 --> 00:01:32,060
but on top what we had with RDF and RDF schema is not the first

20
00:01:32,060 --> 00:01:37,340
set of ontological primitives where you have a prearranged agreement on so this is the

21
00:01:37,340 --> 00:01:40,760
next step in our hierarchy

22
00:01:40,780 --> 00:01:41,690
so what

23
00:01:41,720 --> 00:01:47,940
do you get out of RDF let's start with RDF well RDF provides so-called metadata

24
00:01:48,240 --> 00:01:51,480
about went sources so what are metadata

25
00:01:51,740 --> 00:01:56,320
a common definition is data about detail so you want to say something about something

26
00:01:56,320 --> 00:02:01,580
else and the RDF community basically has an idea that they want to say anything

27
00:02:01,580 --> 00:02:07,580
about anything other than everything else so there should be no restriction

28
00:02:08,260 --> 00:02:13,260
to achieve that they introduced the so-called attribute value tripled

29
00:02:13,420 --> 00:02:18,620
but basically it has an XML syntax so is serialised in XML

30
00:02:18,660 --> 00:02:24,300
and if you look from from my graphically oriented perspective of the chain triples form

31
00:02:24,330 --> 00:02:27,590
the graph so so let's make an example

32
00:02:27,700 --> 00:02:34,360
for example you have your work that object the attribute telephone or telephone number and

33
00:02:34,370 --> 00:02:39,100
you have the value which is which would be my telephone number so this would

34
00:02:39,820 --> 00:02:45,700
across the graph structure simple graph structure if you have the RDF description

35
00:02:45,720 --> 00:02:53,800
compared to html or XML it would look like this so you have the pre-arranged

36
00:02:53,800 --> 00:02:59,860
ontological ontological vocabulary you say that you have within the name space RDF you have

37
00:03:00,160 --> 00:03:01,520
the description

38
00:03:01,560 --> 00:03:03,120
and you say something

39
00:03:03,140 --> 00:03:05,480
about your work

40
00:03:05,500 --> 00:03:09,800
and what do you say well that the telephone number is about that looks very

41
00:03:09,800 --> 00:03:14,250
similar actually take some and that is due to the fact that it is serialised

42
00:03:14,250 --> 00:03:16,340
in XML

43
00:03:16,700 --> 00:03:20,180
so you can add more triples you can say well

44
00:03:20,200 --> 00:03:23,600
this guy has a home page on this home page has the side which would

45
00:03:26,020 --> 00:03:31,040
and for example i would explain RDF and RDF home page has at the site

46
00:03:31,050 --> 00:03:36,480
on the w three c something which is also quite common in the RDF community

47
00:03:36,520 --> 00:03:41,260
namely that you refer to certain resources by new artists that's why you need the

48
00:03:41,260 --> 00:03:46,580
URI so for example if you want to refer to RDF as the topic you

49
00:03:46,580 --> 00:03:51,580
could use the RDF website from the w three c that as you might know

50
00:03:51,810 --> 00:03:57,400
the difference between your eyes is that the URI as the union unique your resource

51
00:03:57,400 --> 00:04:04,240
identifiers so to be unique and you should address uniquely resources but it's not necessarily

52
00:04:04,240 --> 00:04:09,860
reachable in the in the web and the URL typically is a uniform resource locator

53
00:04:09,860 --> 00:04:14,720
so it's also accessible on the web at the different but you could also use

54
00:04:14,720 --> 00:04:20,840
some websites for example to uniquely identify certain topics like RDF this case

55
00:04:20,860 --> 00:04:26,150
but as you get by RDF schema

56
00:04:26,170 --> 00:04:32,320
well defined the vocabulary for RDF schema basically

57
00:04:32,440 --> 00:04:38,110
and this vocabulary is organised the so-called typed hierarchy so what you have here is

58
00:04:38,120 --> 00:04:42,620
a class you the top class of relationship you can say the type which would

59
00:04:42,620 --> 00:04:47,820
be an instance relationship so it's a little bit confusing because the RDF people have

60
00:04:47,980 --> 00:04:54,710
a slightly different notion of what they call the property we call the relationship of

61
00:04:54,710 --> 00:04:58,730
what they call the class we call the concept but in principle it's the same

62
00:04:58,950 --> 00:05:04,210
so you're property the property of so also within relations you could have some kind

63
00:05:04,210 --> 00:05:10,650
of hierarchy and for a property in relationship that the so-called domain in range with

64
00:05:10,650 --> 00:05:14,710
which would be the start and the ending point of such a relationship so if

65
00:05:14,710 --> 00:05:17,130
you look you are you have

66
00:05:17,150 --> 00:05:22,800
as the relationship of the property has supervised so the domain would be

67
00:05:22,860 --> 00:05:29,210
this class this concept york and the range would be here rudy

68
00:05:29,230 --> 00:05:34,120
so you have your car supervisor be as the chain triples these are the concepts

69
00:05:34,120 --> 00:05:38,630
of classes and this is the property of the relationship

70
00:05:38,670 --> 00:05:41,270
what do you get by RDF schema

71
00:05:41,410 --> 00:05:44,380
so now you can say that you actually

72
00:05:44,390 --> 00:05:47,100
the the type of phd student

73
00:05:47,100 --> 00:05:51,780
then type is similar to the instance of so you would be an instance have

74
00:05:51,890 --> 00:05:57,780
a phd student really on the other hand would be in type for instance of

75
00:05:57,780 --> 00:06:00,080
professor at UC

76
00:06:00,120 --> 00:06:05,280
the property has to provide the has the main phd student and has arranged professor

77
00:06:05,280 --> 00:06:10,280
now in fancy rate the schema by york has supervisor rule

78
00:06:10,300 --> 00:06:15,560
so this is the basic idea plus you have a typed hierarchy so for example

79
00:06:15,560 --> 00:06:21,650
phd students class of person and professors also classes of person

80
00:06:21,780 --> 00:06:26,190
what does it look like an idea but i don't want to bother you too

81
00:06:26,190 --> 00:06:31,560
much with that syntactical stuff but just to give you an impression so for example

82
00:06:31,560 --> 00:06:34,820
you could say that a motor vehicle is the class which would be the first

83
00:06:34,820 --> 00:06:39,530
OK so that's the that's the machinery that let's get

84
00:06:39,550 --> 00:06:44,200
let's get this relationship between the rademacher averages

85
00:06:44,260 --> 00:06:46,260
and the VC dimension

86
00:06:46,280 --> 00:06:50,660
OK the the rest of the expectation microbridge is no more than something like the

87
00:06:50,680 --> 00:06:53,760
square to VC dimension over n

88
00:06:55,450 --> 00:07:00,240
so we could throw that into the results that we saw

89
00:07:00,240 --> 00:07:01,780
last time

90
00:07:01,780 --> 00:07:03,610
in terms of

91
00:07:03,660 --> 00:07:07,990
the the uniform convergence results that i quoted just a moment ago

92
00:07:11,840 --> 00:07:16,450
if we're going to class that has this dimension d then whatever the probability distribution

93
00:07:16,450 --> 00:07:18,200
with high probability

94
00:07:18,220 --> 00:07:20,550
the maximal deviation between

95
00:07:20,570 --> 00:07:25,880
risk and the empirical risk between expectation of the loss incurred by s

96
00:07:25,930 --> 00:07:27,930
and the sample average about thing

97
00:07:27,970 --> 00:07:32,070
OK maximizing overall in the class capital

98
00:07:32,090 --> 00:07:35,660
it's no more than something like scritti over and

99
00:07:35,740 --> 00:07:36,780
load factor

100
00:07:36,800 --> 00:07:38,450
and some small to

101
00:07:38,470 --> 00:07:40,340
right this is like

102
00:07:40,360 --> 00:07:44,070
ah logbn one of adultery

103
00:07:44,070 --> 00:07:48,570
right and then using the same ideas as we saw

104
00:07:48,590 --> 00:07:52,470
at the end of the last lecture

105
00:07:52,490 --> 00:07:57,550
that means that if we minimize the sample average to minimize the empirical risk

106
00:07:57,610 --> 00:08:00,110
then the risk is is

107
00:08:00,110 --> 00:08:04,260
not much bigger than the is is no more than this class

108
00:08:04,280 --> 00:08:05,240
the minimal

109
00:08:06,180 --> 00:08:08,860
OK this is the best in a class

110
00:08:08,910 --> 00:08:11,320
and this is some sort of a complexity penalty

111
00:08:12,130 --> 00:08:19,010
you know additional an additional term that depends on the VC dimension d

112
00:08:19,050 --> 00:08:23,800
three something like square the over

113
00:08:23,820 --> 00:08:28,320
OK and going from uniform convergence to this thing is is very much the same

114
00:08:28,320 --> 00:08:29,800
as we saw last

115
00:08:29,800 --> 00:08:32,700
and i guess i've been a bit more cavalier with constant here

116
00:08:32,720 --> 00:08:35,110
right because

117
00:08:35,130 --> 00:08:37,530
because i get to give away a lot with constant when we go to the

118
00:08:37,530 --> 00:08:41,860
generality of the VC dimension

119
00:08:42,720 --> 00:08:48,030
OK so so we could say something about the behaviour of the empirical risk minimizer

120
00:08:48,030 --> 00:08:52,360
of some class of functions that has a finite VC dimension right its performance it's

121
00:08:52,360 --> 00:08:55,300
risk is no more than the best we could hope for from that class

122
00:08:55,320 --> 00:08:58,530
plus something of order of square the average

123
00:08:58,550 --> 00:09:04,050
OK so already mentioned you can remove this log in factor here

124
00:09:04,110 --> 00:09:07,110
you don't need that but you need more refined argument to

125
00:09:07,140 --> 00:09:08,610
to remove that

126
00:09:08,660 --> 00:09:10,360
and i'm looking

127
00:09:10,380 --> 00:09:15,010
so that the the more refined argument involves

128
00:09:15,140 --> 00:09:17,220
looking at covering numbers

129
00:09:17,220 --> 00:09:22,200
and some results due to two d double e

130
00:09:23,010 --> 00:09:24,970
OK so the the

131
00:09:25,010 --> 00:09:29,780
actual method that can concerned with the learning algorithm here is particularly simple right given

132
00:09:29,910 --> 00:09:32,820
class capital f which is minimizing empirical risk

133
00:09:32,820 --> 00:09:34,030
OK this is not

134
00:09:34,050 --> 00:09:39,530
not very complicated so very general result

135
00:09:39,720 --> 00:09:45,140
and there are lots of approximations made along the way but it turns out that

136
00:09:45,140 --> 00:09:51,030
the rate that we get here is minimax optimal right this this square root

137
00:09:51,030 --> 00:09:52,720
whatever and is the

138
00:09:52,740 --> 00:09:53,530
it is

139
00:09:53,550 --> 00:09:57,410
it is the right the right right in the minimax sense

140
00:09:59,130 --> 00:10:01,780
we'll have a look at that

141
00:10:11,360 --> 00:10:12,900
so he is the of

142
00:10:13,970 --> 00:10:18,530
first of all i guess you can get rid of the log factor and get

143
00:10:18,530 --> 00:10:21,240
a result that's the the

144
00:10:21,510 --> 00:10:25,840
rademacher averages and no more than some constant times the square root

145
00:10:25,860 --> 00:10:29,590
of the VC dimension of and you can refine that even

146
00:10:29,740 --> 00:10:32,260
and say that the

147
00:10:32,280 --> 00:10:35,240
this notation expectations of sigma

148
00:10:35,260 --> 00:10:37,530
means the conditional expectation

149
00:10:37,550 --> 00:10:42,110
right we just integrating out sick sick conditioning on x one through x n

150
00:10:42,160 --> 00:10:44,490
you could get on the rademacher averages

151
00:10:44,510 --> 00:10:48,910
the conditional expectation of these things in terms of the VC dimension of the restrictions

152
00:10:48,910 --> 00:10:50,410
of functions in f

153
00:10:50,410 --> 00:10:52,340
two x one to xn

154
00:10:52,360 --> 00:10:58,320
OK so we're saying something that's somehow incorporate information about the the distribution

155
00:10:59,590 --> 00:11:02,050
in this sort of results o

156
00:11:02,070 --> 00:11:05,180
you could also do that although it's

157
00:11:05,180 --> 00:11:07,160
not so easy to

158
00:11:07,180 --> 00:11:08,900
to get meaningful estimates of

159
00:11:08,910 --> 00:11:10,740
of these things

160
00:11:10,760 --> 00:11:16,530
so now let's look at when i said a moment ago

161
00:11:16,550 --> 00:11:19,510
that you know this is the minimax optimal right what i mean by that how

162
00:11:19,510 --> 00:11:24,760
do we set this up as as you know what's what's appropriate minimax sitting here

163
00:11:25,010 --> 00:11:27,220
we talking about so

164
00:11:27,220 --> 00:11:31,050
let's define the following notion of estimation error we've got

165
00:11:31,050 --> 00:11:35,190
within this subset is very low

166
00:11:37,380 --> 00:11:41,700
we're going to applied

167
00:11:41,700 --> 00:11:44,790
two their boating dataset

168
00:11:44,800 --> 00:11:48,050
and in this case the result is just one

169
00:11:48,070 --> 00:11:49,790
is one of the boats

170
00:11:49,810 --> 00:11:51,990
which is actually the number four

171
00:11:52,000 --> 00:11:53,450
this is the number of

172
00:11:53,540 --> 00:11:55,050
of the attributes

173
00:11:55,060 --> 00:11:56,560
and this is their there

174
00:11:56,600 --> 00:11:58,720
the rank which is number one

175
00:11:58,720 --> 00:12:05,480
it's what is the freezing or or not of these physicians

176
00:12:05,490 --> 00:12:08,410
now that's going to take on another one

177
00:12:08,470 --> 00:12:11,740
you all know how to do this just

178
00:12:11,790 --> 00:12:14,230
click and choose

179
00:12:17,880 --> 00:12:24,850
correlation by entropy or gain in entropy information gain

180
00:12:24,870 --> 00:12:28,770
and now we're going to use the ranking method we just ranks

181
00:12:28,810 --> 00:12:30,930
attributes by

182
00:12:30,930 --> 00:12:33,950
decrease in entropy

183
00:12:34,610 --> 00:12:36,760
increasing information gain

184
00:12:36,760 --> 00:12:42,450
this is not what i in general because it violates every variable alone

185
00:12:42,460 --> 00:12:45,180
in this it does not take interactions

186
00:12:45,200 --> 00:12:45,850
in two

187
00:12:45,870 --> 00:12:47,220
account anyway

188
00:12:47,230 --> 00:12:49,700
if you apply it

189
00:12:49,710 --> 00:12:51,490
this is the wrong

190
00:12:51,520 --> 00:12:52,550
then we just

191
00:12:54,880 --> 00:12:56,130
it is

192
00:12:56,150 --> 00:12:58,130
nice to see that the top

193
00:12:58,140 --> 00:13:00,860
in this list is the same variable as before

194
00:13:00,880 --> 00:13:01,690
but this

195
00:13:02,830 --> 00:13:07,700
completely random i mean it it it shouldn't be the case in general because they

196
00:13:07,700 --> 00:13:12,010
are quite different methods

197
00:13:13,520 --> 00:13:18,750
data visualization

198
00:13:18,760 --> 00:13:20,560
this is a different data set

199
00:13:20,590 --> 00:13:24,050
it's to identify kind of glass by

200
00:13:24,050 --> 00:13:28,780
the elements that are present so the magnitude aluminium

201
00:13:28,790 --> 00:13:30,550
that's it

202
00:13:30,580 --> 00:13:33,730
here we have a lot of classes

203
00:13:33,740 --> 00:13:34,870
as you can see

204
00:13:34,900 --> 00:13:38,050
by that diff by the number of different colors in the picture

205
00:13:38,060 --> 00:13:41,290
it's quite difficult task this is well known in the

206
00:13:41,310 --> 00:13:43,190
in the UCI

207
00:13:44,760 --> 00:13:47,270
this is the full

208
00:13:47,280 --> 00:13:54,190
collection of byproducts by pulitzer plot is a scatterplot of one variable against another viable

209
00:13:54,210 --> 00:13:58,960
so you have a quadratic number of my blocks

210
00:13:59,010 --> 00:14:00,370
you can

211
00:14:00,430 --> 00:14:04,860
have a look of each of them to have the first impression

212
00:14:05,190 --> 00:14:09,790
scrolling down to the right everything

213
00:14:09,820 --> 00:14:12,950
this is the full set of my blood

214
00:14:12,990 --> 00:14:14,040
this anyone know

215
00:14:14,050 --> 00:14:16,590
how to use this

216
00:14:17,820 --> 00:14:21,900
it's a lot of information but if you train your eye

217
00:14:21,950 --> 00:14:24,150
which is what human beings

218
00:14:24,180 --> 00:14:26,480
are good that the train the eyes

219
00:14:26,490 --> 00:14:28,910
well trained and their eyes stood

220
00:14:28,930 --> 00:14:31,850
the train the brain if you prefer but

221
00:14:31,900 --> 00:14:36,110
what can we say about this data set

222
00:14:36,120 --> 00:14:38,330
the different colors and different classes

223
00:14:38,340 --> 00:14:40,540
so you are seeing now for example

224
00:14:41,010 --> 00:14:42,730
i think this one

225
00:14:42,730 --> 00:14:45,100
here you have barrier against

226
00:14:45,130 --> 00:14:47,230
i don't know what this

227
00:14:47,270 --> 00:14:51,510
what you see here

228
00:14:51,530 --> 00:14:53,290
the yellow classes

229
00:14:53,340 --> 00:14:59,220
but if pretty quickly able identifiable by this combi nation

230
00:14:59,980 --> 00:15:02,790
there are no yellow visible here

231
00:15:02,810 --> 00:15:05,700
so you can just

232
00:15:05,740 --> 00:15:06,690
the this

233
00:15:06,710 --> 00:15:07,790
with the linear

234
00:15:07,800 --> 00:15:09,460
classifier quadratic

235
00:15:09,490 --> 00:15:10,750
if it fits better

236
00:15:10,770 --> 00:15:14,770
there are some errors but

237
00:15:16,470 --> 00:15:21,180
if you pick just one

238
00:15:21,230 --> 00:15:22,370
you can so

239
00:15:22,400 --> 00:15:24,120
on it and see the

240
00:15:25,240 --> 00:15:26,570
of the two barrels

241
00:15:26,590 --> 00:15:28,210
and the different classes

242
00:15:28,210 --> 00:15:30,040
in this case is same as

243
00:15:30,050 --> 00:15:33,050
you can't separate anything from these two variables alone

244
00:15:33,140 --> 00:15:34,190
as you can see

245
00:15:34,200 --> 00:15:36,740
not a single class

246
00:15:41,800 --> 00:15:46,290
you can zoom in more to see this mess

247
00:15:49,410 --> 00:15:50,640
this is what we see

248
00:15:50,650 --> 00:15:55,450
same as i mean

249
00:15:55,490 --> 00:15:58,290
it's nothing to do here

250
00:15:59,660 --> 00:16:03,550
so on further explore a quick look at the experiment

251
00:16:03,550 --> 00:16:05,650
i'll just show you

252
00:16:05,790 --> 00:16:07,140
the main we know

253
00:16:07,200 --> 00:16:10,370
neil experiment

254
00:16:10,400 --> 00:16:16,540
we select different datasets from our collection of fires i smoking

255
00:16:16,580 --> 00:16:17,510
and class

256
00:16:17,520 --> 00:16:20,220
the three that we have been using

257
00:16:20,230 --> 00:16:21,430
and we select

258
00:16:21,900 --> 00:16:24,340
three classification methods

259
00:16:24,450 --> 00:16:25,590
decision tree

260
00:16:25,760 --> 00:16:27,570
multilayer perceptron

261
00:16:27,610 --> 00:16:29,070
and the naive bayes

262
00:16:31,080 --> 00:16:32,350
we specify

263
00:16:32,370 --> 00:16:36,540
the number of false in cross validation specify the classification task

264
00:16:36,620 --> 00:16:39,220
ten repetitions

265
00:16:39,370 --> 00:16:41,410
many things here

266
00:16:41,430 --> 00:16:43,530
and run

267
00:16:43,590 --> 00:16:49,080
well this is of course this is separate compiler presentation it takes time

268
00:16:49,130 --> 00:16:51,030
in this case it took

269
00:16:51,150 --> 00:16:54,320
about three hours

270
00:16:54,330 --> 00:16:56,840
we case not to fast software

271
00:16:56,880 --> 00:17:04,150
but this is nice this and the classification error is

272
00:17:04,200 --> 00:17:11,510
we can what damien everything went well that's what you what it says here

273
00:17:11,530 --> 00:17:15,180
you can analyse we're going to split this quickly

274
00:17:15,190 --> 00:17:17,190
for example you can analyse

275
00:17:17,200 --> 00:17:18,870
in kind of

276
00:17:19,000 --> 00:17:25,050
cross table performance mean performance of different datasets the different methods

277
00:17:25,110 --> 00:17:27,870
and you can perform to take these tests

278
00:17:27,870 --> 00:17:30,390
kilometres per second yes that's what it is

279
00:17:36,640 --> 00:17:38,730
conservation of angular momentum

280
00:17:38,750 --> 00:17:41,490
that the product of QP

281
00:17:43,660 --> 00:17:45,730
must be the same as q

282
00:17:45,820 --> 00:17:49,840
times the a that's immediate consequence of the conservation

283
00:17:50,990 --> 00:17:52,230
and you momentum

284
00:17:52,280 --> 00:17:54,410
and when i had this up

285
00:17:56,170 --> 00:17:57,940
let's QP

286
00:17:57,990 --> 00:17:59,220
i better find

287
00:17:59,220 --> 00:18:01,430
two a which in our case

288
00:18:01,480 --> 00:18:02,840
is about

289
00:18:02,890 --> 00:18:04,590
on the thousand kilometres

290
00:18:04,620 --> 00:18:06,950
because able to fifty thousand kilometres

291
00:18:06,960 --> 00:18:08,550
so when you have these two up

292
00:18:08,570 --> 00:18:13,320
you must find very close to a hundred thousand and you need to do

293
00:18:13,520 --> 00:18:17,880
so now we know everything there is to be known about this ellipse

294
00:18:17,920 --> 00:18:19,440
that came from

295
00:18:19,450 --> 00:18:22,320
the initial conditions from the four numbers

296
00:18:22,340 --> 00:18:24,500
but i gave we don't periods

297
00:18:24,510 --> 00:18:27,540
we know winograd which is you know what marriage is

298
00:18:27,590 --> 00:18:29,150
we know the orbital period

299
00:18:29,150 --> 00:18:30,700
anything we want

300
00:18:30,750 --> 00:18:32,990
to know

301
00:18:32,990 --> 00:18:35,240
now i want to

302
00:18:35,300 --> 00:18:37,580
getting into is subject which is

303
00:18:37,600 --> 00:18:39,030
quite difficult

304
00:18:39,100 --> 00:18:40,430
and it has to do

305
00:18:44,730 --> 00:18:45,990
riding a rocket

306
00:18:45,990 --> 00:18:48,020
when you are in orbit

307
00:18:48,040 --> 00:18:51,160
and your

308
00:18:51,160 --> 00:18:53,130
or it will change

309
00:18:53,140 --> 00:18:55,650
and i will do it only four

310
00:18:55,660 --> 00:18:59,480
some simplified situations i start off with a

311
00:18:59,530 --> 00:19:02,960
circular orbit

312
00:19:02,960 --> 00:19:05,990
and i will fire the rockets

313
00:19:06,000 --> 00:19:07,890
in such a way

314
00:19:11,460 --> 00:19:13,260
i will only

315
00:19:13,280 --> 00:19:16,350
if i read in such a way that my velocity

316
00:19:16,390 --> 00:19:17,330
well either

317
00:19:17,350 --> 00:19:19,490
increase exactly

318
00:19:20,700 --> 00:19:21,920
video of it

319
00:19:21,970 --> 00:19:26,220
but increase in this direction or that it will decrease in this direction

320
00:19:26,240 --> 00:19:28,480
so if i'm going in orbit like this

321
00:19:28,490 --> 00:19:30,630
you know if i am i rocket like this

322
00:19:30,630 --> 00:19:32,890
or if i am i rocket like this

323
00:19:32,940 --> 00:19:35,840
that is difficult enough what we do now

324
00:19:35,900 --> 00:19:38,710
so this is our circular orbits

325
00:19:38,730 --> 00:19:40,530
radius or

326
00:19:40,550 --> 00:19:42,380
and at location x

327
00:19:42,380 --> 00:19:45,500
twelve o'clock that's where i fire

328
00:19:45,520 --> 00:19:49,570
my rocket

329
00:19:49,580 --> 00:19:53,050
the first thing i do i increase the kinetic energy

330
00:19:53,060 --> 00:19:56,650
so i my rocket i bless my rocket we go in this direction

331
00:19:56,650 --> 00:19:58,130
i lost my rock

332
00:19:58,150 --> 00:19:59,230
there's reaction

333
00:19:59,400 --> 00:20:01,680
so to speak which was originally

334
00:20:01,770 --> 00:20:03,550
this orbit

335
00:20:03,600 --> 00:20:05,500
the speed will now increase

336
00:20:05,550 --> 00:20:07,600
i had kinetic energy

337
00:20:07,650 --> 00:20:08,570
and now

338
00:20:08,640 --> 00:20:12,420
i have no speed which is higher

339
00:20:12,460 --> 00:20:14,640
if my speed is higher

340
00:20:14,660 --> 00:20:18,530
then my total energy has increased increase the kinetic energy

341
00:20:18,580 --> 00:20:21,580
the burden of the rocket is so short

342
00:20:21,600 --> 00:20:25,440
that i can consider after the birth the object is still intact

343
00:20:25,480 --> 00:20:27,640
a very brief

344
00:20:27,690 --> 00:20:31,210
so to kinetic energy has increased the potential energy is the same for the total

345
00:20:31,210 --> 00:20:32,630
energy is up

346
00:20:32,680 --> 00:20:34,690
and therefore

347
00:20:34,740 --> 00:20:36,700
the total energy

348
00:20:36,740 --> 00:20:38,350
now is larger

349
00:20:38,390 --> 00:20:40,800
and the total energy

350
00:20:40,850 --> 00:20:42,190
that i had

351
00:20:42,260 --> 00:20:44,490
in my circular orbit

352
00:20:44,530 --> 00:20:46,370
but if that's the case

353
00:20:46,370 --> 00:20:49,170
then clearly to a

354
00:20:49,180 --> 00:20:50,980
must be larger

355
00:20:51,020 --> 00:20:52,240
in two are

356
00:20:52,260 --> 00:20:54,260
i'm not going to elliptical orbit

357
00:20:54,350 --> 00:20:58,410
because the new velocity is no longer the right velocity for circular

358
00:20:58,450 --> 00:21:01,380
so what's going to happen i'm going to get

359
00:21:01,560 --> 00:21:03,890
elliptical orbit

360
00:21:03,900 --> 00:21:05,960
like so

361
00:21:06,120 --> 00:21:08,100
by two a must be larger

362
00:21:08,180 --> 00:21:09,210
then two are

363
00:21:09,240 --> 00:21:11,730
because my total energy is larger

364
00:21:11,780 --> 00:21:15,960
you see that immediately when you go to equation number five

365
00:21:15,960 --> 00:21:19,940
if you increase the total energy then you're a will

366
00:21:22,490 --> 00:21:26,230
OK so too is larger than two are

367
00:21:26,310 --> 00:21:29,310
it also means that the period t

368
00:21:29,320 --> 00:21:30,470
must be larger

369
00:21:30,540 --> 00:21:32,490
then the period

370
00:21:32,500 --> 00:21:36,310
in your circular orbit

371
00:21:36,390 --> 00:21:39,340
find so far so good

372
00:21:39,380 --> 00:21:40,760
my other option is

373
00:21:40,780 --> 00:21:43,010
i'm going to fire the rocket

374
00:21:43,030 --> 00:21:45,680
when i you are getting this direction

375
00:21:45,760 --> 00:21:48,190
so i take an adding energy out

376
00:21:48,230 --> 00:21:49,540
so after the birth

377
00:21:49,600 --> 00:21:50,690
my speed

378
00:21:50,700 --> 00:21:52,810
is lower

379
00:21:52,830 --> 00:21:56,060
my speech is now lower

380
00:21:56,120 --> 00:21:58,220
i taken kinetic energy out

381
00:21:58,260 --> 00:22:01,230
when i take an attic energy out the total energy is going to be less

382
00:22:01,230 --> 00:22:03,090
than the circular energy

383
00:22:03,220 --> 00:22:05,180
two a will be less than two are

384
00:22:05,230 --> 00:22:09,590
and the orbital period will be less than the circular orbital period and therefore my

385
00:22:09,590 --> 00:22:10,790
new ellipse

386
00:22:10,840 --> 00:22:16,580
looks like this

387
00:22:16,590 --> 00:22:19,450
so these are the three situations i want you to

388
00:22:19,490 --> 00:22:22,160
carefully look at because i'm going to need them

389
00:22:22,210 --> 00:22:25,650
in the next very dramatic story which has to do

390
00:22:25,690 --> 00:22:27,800
with the romance between peter

391
00:22:27,820 --> 00:22:29,710
and mary

392
00:22:30,780 --> 00:22:32,510
i two astronauts

393
00:22:32,520 --> 00:22:33,930
and they are

394
00:22:33,970 --> 00:22:35,690
both in orbit

395
00:22:35,730 --> 00:22:40,940
in one and the same orbit around the earth

396
00:22:40,970 --> 00:22:42,810
this is peter is at this moment

397
00:22:42,840 --> 00:22:44,550
at that location x

398
00:22:44,590 --> 00:22:47,570
and this is where mary is

399
00:22:47,620 --> 00:22:50,980
they are exactly the same way

400
00:22:51,080 --> 00:22:52,770
but different satellites

401
00:22:52,810 --> 00:22:55,190
you go around like this

402
00:22:56,470 --> 00:22:57,930
and they are

403
00:22:57,940 --> 00:23:00,200
edit distance from each other

404
00:23:00,280 --> 00:23:03,820
which i will express in terms of

405
00:23:03,830 --> 00:23:05,680
the fraction f

406
00:23:05,680 --> 00:23:07,530
of the total circumference

407
00:23:07,550 --> 00:23:09,010
this arc

408
00:23:09,020 --> 00:23:10,250
he calls off

409
00:23:10,330 --> 00:23:12,760
times two pi are

410
00:23:12,830 --> 00:23:15,000
that's how far apart

411
00:23:15,050 --> 00:23:16,070
and that means

412
00:23:16,080 --> 00:23:18,410
four mary

413
00:23:18,410 --> 00:23:21,590
to make it all the way back

414
00:23:21,650 --> 00:23:23,930
two point x would be one minus f

415
00:23:23,990 --> 00:23:26,640
times two pi r

416
00:23:26,690 --> 00:23:30,820
so far

417
00:23:30,870 --> 00:23:34,170
so good

418
00:23:34,220 --> 00:23:36,660
mary forgot to lunch

419
00:23:36,700 --> 00:23:40,320
radio speed and says peter i have no food

420
00:23:41,380 --> 00:23:42,560
very sorry for her

421
00:23:42,600 --> 00:23:44,170
there's no sweat

422
00:23:44,170 --> 00:23:46,570
i will throw you and

423
00:23:46,650 --> 00:23:50,270
so peter prepares and sends which and wants to throw it to mary

424
00:23:50,330 --> 00:23:53,750
in such a way that mary can make catch

425
00:23:54,570 --> 00:23:55,730
and feeder

426
00:23:56,840 --> 00:23:59,220
do this

427
00:24:02,750 --> 00:24:06,770
the best way the most obvious way to do do it

428
00:24:10,560 --> 00:24:13,560
to make an orbit for the

429
00:24:13,580 --> 00:24:16,050
hansen bridge

430
00:24:16,100 --> 00:24:20,090
whose orbital period is exactly the same as this time for mary

431
00:24:20,100 --> 00:24:22,470
to make it back to x

432
00:24:22,510 --> 00:24:26,590
and i'll be more specific by giving you some numbers then you can digest the

433
00:24:28,490 --> 00:24:29,980
they are in orbit

434
00:24:29,980 --> 00:24:31,590
all the action

435
00:24:32,610 --> 00:24:39,390
so that

436
00:24:44,460 --> 00:24:52,210
well i will tell you that

437
00:24:52,220 --> 00:24:58,440
tag like

438
00:24:58,450 --> 00:25:04,470
the nature and

439
00:25:04,490 --> 00:25:17,950
the time they can show that the kind of

440
00:25:19,210 --> 00:25:21,740
that i can't

441
00:25:21,760 --> 00:25:24,550
actually i

442
00:25:24,700 --> 00:25:28,420
the bad

443
00:25:57,980 --> 00:26:03,380
i can

444
00:26:03,400 --> 00:26:07,390
what is going on

445
00:26:10,960 --> 00:26:20,720
i can tell

446
00:26:20,740 --> 00:26:23,400
how you

447
00:26:38,960 --> 00:26:45,900
i'm going to

448
00:26:47,350 --> 00:26:52,980
five five

449
00:27:00,090 --> 00:27:05,190
five five

450
00:27:05,200 --> 00:27:08,520
now i

451
00:27:41,140 --> 00:27:51,420
how do i get back

452
00:27:51,430 --> 00:27:53,680
i just

453
00:27:56,170 --> 00:28:03,280
we have

454
00:28:07,110 --> 00:28:09,030
eight years

455
00:28:11,360 --> 00:28:15,330
and you

456
00:29:02,440 --> 00:29:13,010
i average i i i

457
00:29:13,060 --> 00:29:19,840
and i found that

458
00:29:29,140 --> 00:29:32,040
thank you

459
00:29:45,290 --> 00:29:54,350
i mean that

460
00:29:57,910 --> 00:30:05,990
i happen to

461
00:30:13,890 --> 00:30:16,370
thank you

462
00:30:30,180 --> 00:30:36,740
you can find

463
00:30:36,740 --> 00:30:41,270
it's it's intentionally offensive they're basically did in many ways trying to create these taste

464
00:30:41,270 --> 00:30:43,310
boundaries to keep out the people

465
00:30:43,380 --> 00:30:46,510
who can't deal with it

466
00:30:46,570 --> 00:30:49,890
OK we move on to study the ephemerality

467
00:30:49,930 --> 00:30:52,330
let me give you a sense of how health morality is actually implemented on four

468
00:30:53,010 --> 00:30:54,430
i'm going create a thread

469
00:30:54,450 --> 00:30:55,830
look something like this

470
00:30:55,870 --> 00:30:58,330
when i started that thread is going to go up to the top of four

471
00:30:58,330 --> 00:30:59,490
chan's first page

472
00:30:59,580 --> 00:31:03,430
as other people start posting new threads might read gets pushed farther and farther down

473
00:31:03,430 --> 00:31:04,870
just like any other form

474
00:31:04,950 --> 00:31:09,190
the difference is that there are only fifteen pages on four chan two hundred twenty

475
00:31:09,190 --> 00:31:10,260
five threads

476
00:31:10,270 --> 00:31:14,470
once the two hundred twenty six six thread shows up my three four o fours

477
00:31:14,790 --> 00:31:19,780
not found that means everything attached to it is completely deleted forever

478
00:31:19,830 --> 00:31:23,400
the only way to keep the content from getting deleted is for someone to come

479
00:31:24,200 --> 00:31:25,620
and reply

480
00:31:25,660 --> 00:31:29,070
if someone replies my friend gets pushed all the way back to the top

481
00:31:29,120 --> 00:31:30,560
therefore can

482
00:31:30,640 --> 00:31:32,270
this is a process known

483
00:31:32,270 --> 00:31:33,420
as bumping

484
00:31:35,170 --> 00:31:37,840
keeping this algorithm in a sense in mind

485
00:31:37,850 --> 00:31:40,000
we can turn to the data we collect it

486
00:31:40,040 --> 00:31:42,750
a complete data set of two weeks of slash b

487
00:31:42,780 --> 00:31:44,850
that's five and a half million posts

488
00:31:44,920 --> 00:31:47,250
almost a half-million france

489
00:31:47,290 --> 00:31:53,030
and if we replace the history to watch what is ephemerality really look like unfortunate

490
00:31:53,090 --> 00:31:55,810
here's what we found

491
00:31:55,840 --> 00:31:59,320
the median thread last less than four minutes

492
00:32:01,120 --> 00:32:04,760
i mean by the time you redefine hilarious try to tweet about it friends read

493
00:32:04,760 --> 00:32:07,890
it was probably already deleted

494
00:32:07,900 --> 00:32:13,000
shortest reign lasted just under half minute and the longest lived thread

495
00:32:13,030 --> 00:32:17,010
last no more than six hours a response to this was why

496
00:32:17,020 --> 00:32:20,730
the median thread here has one post and one reply

497
00:32:20,750 --> 00:32:24,470
the other forty three percent reply rate is actually consistent with other kinds of sites

498
00:32:25,760 --> 00:32:29,100
if you want to see what kinds of things get responses longest lived thread was

499
00:32:29,100 --> 00:32:33,630
something that really generated lot of reactions or was really entertaining this was a pagan

500
00:32:33,640 --> 00:32:37,780
who was actually offering to to answer questions about being a pagan whereas the short

501
00:32:37,780 --> 00:32:41,840
lived thread was someone who is simply just trying to get attention and no one

502
00:32:41,840 --> 00:32:43,670
was having

503
00:32:43,680 --> 00:32:46,030
now let's turn to the first page

504
00:32:46,040 --> 00:32:49,090
to understand what first page matter you need to you need to know that people

505
00:32:49,090 --> 00:32:53,810
unfortunate often sit on just the first page of results and refresh all the time

506
00:32:53,820 --> 00:32:56,780
so while for threads on the first page is the only chance has to get

507
00:32:58,130 --> 00:33:01,710
so now let's do the same analysis focusing just on the first page what we

508
00:33:02,800 --> 00:33:07,140
the median thread disappears from the first page across its whole life

509
00:33:07,140 --> 00:33:08,640
in five seconds

510
00:33:08,680 --> 00:33:10,380
that's it comes up

511
00:33:10,430 --> 00:33:12,190
goes down gets bombed

512
00:33:12,210 --> 00:33:13,260
goes away again

513
00:33:13,270 --> 00:33:15,000
five seconds

514
00:33:16,140 --> 00:33:21,660
when high activity periods less than one second maximum no more than thirty seven minutes

515
00:33:22,720 --> 00:33:25,070
there are ways to play with ephemerality

516
00:33:25,130 --> 00:33:27,780
one of them is called bumping i told you about being is but there is

517
00:33:27,780 --> 00:33:32,770
that there some people actually replied with the text bumper band something like that in

518
00:33:32,770 --> 00:33:36,010
order to push intentionally keep the threat from dying we see that about two percent

519
00:33:36,480 --> 00:33:37,460
post to this

520
00:33:37,470 --> 00:33:39,540
at the same time there's something on this stage

521
00:33:39,550 --> 00:33:41,440
where you reply but

522
00:33:41,460 --> 00:33:43,150
don't bob

523
00:33:43,160 --> 00:33:45,770
so this is this something built into four chan and we found that less than

524
00:33:45,770 --> 00:33:47,880
one percent of posts actually did this

525
00:33:47,920 --> 00:33:51,170
so we draw from this is that fourteen members

526
00:33:51,180 --> 00:33:55,520
to play around with the ephemerality of the site when it benefits them

527
00:33:55,570 --> 00:33:58,820
now turning the volume for a moment this means that there are about thirty five

528
00:33:58,820 --> 00:34:02,290
thousand threads four hundred thousand posts on on slash p per day

529
00:34:02,400 --> 00:34:05,690
contrast that with about seven thousand posts on today

530
00:34:06,640 --> 00:34:10,680
twenty five thousand usenet posts which their rolling was continuing to grow or sixty five

531
00:34:10,680 --> 00:34:13,640
thousand youtube videos per day so say more about it is the number of videos

532
00:34:13,640 --> 00:34:16,730
posted to youtube but imagine if the only way you can view youtube is to

533
00:34:16,730 --> 00:34:20,710
go to youtube come and see the last fifteen videos and just hit refresh a

534
00:34:20,710 --> 00:34:23,870
single feed that's what i'd like that's what it feels like to be on four

535
00:34:25,770 --> 00:34:29,660
people don't sit by idly they refer to having slashed the folders on the hard

536
00:34:29,660 --> 00:34:33,210
drive where they were they archive important content or things that they found hilarious that

537
00:34:33,210 --> 00:34:34,840
they want to post again later

538
00:34:34,860 --> 00:34:39,730
and for particularly memorable threads there's something honest for carbon fourteen are kind of or

539
00:34:39,730 --> 00:34:44,110
which is effectively museum highly entertaining i recommend it

540
00:34:45,170 --> 00:34:47,760
we can argue also that ephemerality

541
00:34:47,800 --> 00:34:49,230
plays a role

542
00:34:49,270 --> 00:34:51,470
in four chan meme creation

543
00:34:51,510 --> 00:34:55,040
fourteen lots of names for example here to aerial that you see in the upper

544
00:34:55,040 --> 00:35:00,360
i know

545
00:35:15,110 --> 00:35:19,260
i mean we all

546
00:35:22,150 --> 00:35:25,720
it is

547
00:35:43,770 --> 00:35:53,380
so i think the point of

548
00:35:53,420 --> 00:35:55,360
the this

549
00:36:05,840 --> 00:36:09,100
well you can also be used to

550
00:36:17,100 --> 00:36:18,330
and i

551
00:36:26,860 --> 00:36:30,690
it's very simple way

552
00:36:33,130 --> 00:36:34,790
one way

553
00:36:34,800 --> 00:36:42,450
great is

554
00:36:42,580 --> 00:36:44,730
and as you know

555
00:37:05,770 --> 00:37:07,630
it is assumed

556
00:37:13,530 --> 00:37:18,920
and also

557
00:37:18,930 --> 00:37:23,310
just a

558
00:37:29,410 --> 00:37:30,940
well the

559
00:37:30,960 --> 00:37:32,950
OK all the

560
00:37:33,260 --> 00:37:35,810
that we

561
00:37:35,820 --> 00:37:37,030
or in

562
00:37:41,290 --> 00:37:42,860
of course

563
00:37:48,770 --> 00:37:52,490
and i should

564
00:37:52,990 --> 00:37:55,450
two years later

565
00:38:01,650 --> 00:38:04,180
you know what i

566
00:38:05,900 --> 00:38:08,110
this approach

567
00:38:08,130 --> 00:38:11,220
so what i i call

568
00:38:11,260 --> 00:38:14,530
and the y

569
00:38:25,670 --> 00:38:27,150
o a

570
00:38:33,900 --> 00:38:35,620
these rules

571
00:38:35,640 --> 00:38:38,810
like piece of as where

572
00:38:59,900 --> 00:39:04,480
well why

573
00:39:07,040 --> 00:39:10,900
it's a lot

574
00:39:12,450 --> 00:39:15,090
the problem

575
00:39:17,230 --> 00:39:20,880
and the nation

576
00:39:33,620 --> 00:39:37,020
so when we use all

577
00:39:38,770 --> 00:39:41,300
call it

578
00:39:41,330 --> 00:39:43,280
well i mean

579
00:39:49,020 --> 00:39:51,800
o or one

580
00:39:51,800 --> 00:39:55,380
the following content is provided under creative commons license

581
00:39:55,390 --> 00:40:01,170
your support will help MIT opencourseware continue to offer high quality educational resources for free

582
00:40:01,170 --> 00:40:05,730
to make a donation or to view additional materials from hundreds of MIT courses visit

583
00:40:05,730 --> 00:40:11,510
MIT opencourseware OCW that MIT that EDU

584
00:40:14,300 --> 00:40:16,690
OK so i'd like to begin

585
00:40:16,740 --> 00:40:18,290
the second lecture

586
00:40:18,310 --> 00:40:22,390
by reminding you what we did last time

587
00:40:22,400 --> 00:40:25,580
so last time

588
00:40:25,670 --> 00:40:33,070
last time

589
00:40:34,050 --> 00:40:36,670
define the derivative

590
00:40:36,690 --> 00:40:43,650
as the slow

591
00:40:43,730 --> 00:40:47,640
the tangent line

592
00:40:54,480 --> 00:40:58,840
so that was our geometric point of view

593
00:40:58,890 --> 00:41:02,100
and we also did a couple of computations

594
00:41:02,200 --> 00:41:05,250
we worked out that the derivative

595
00:41:05,260 --> 00:41:08,180
of one over that

596
00:41:09,500 --> 00:41:11,860
i one x square

597
00:41:11,900 --> 00:41:14,030
and we also computed

598
00:41:14,080 --> 00:41:15,560
the derivative

599
00:41:15,580 --> 00:41:18,350
of activity and power

600
00:41:18,400 --> 00:41:20,520
for n equals one two

601
00:41:21,900 --> 00:41:23,960
and that turned out to be

602
00:41:24,070 --> 00:41:25,820
sorry next to to the

603
00:41:25,830 --> 00:41:28,790
and minus one

604
00:41:28,840 --> 00:41:35,650
so that's what we did last time

605
00:41:37,820 --> 00:41:39,560
i want to finish off

606
00:41:40,970 --> 00:41:43,230
other points of view

607
00:41:43,280 --> 00:41:46,230
on what the derivative is so

608
00:41:46,270 --> 00:41:50,350
this is an extremely important it's almost the most important thing of the same class

609
00:41:50,350 --> 00:41:52,240
but you have to think about it again

610
00:41:52,280 --> 00:41:54,680
when you start over and start using calculus

611
00:41:54,700 --> 00:41:56,370
in the real world

612
00:41:56,380 --> 00:41:59,650
so again we're talking about what is the derivative

613
00:42:03,910 --> 00:42:10,120
and this is just a continuation of last time

614
00:42:10,250 --> 00:42:16,550
so as i said last time we talked about geometric interpretations

615
00:42:16,600 --> 00:42:18,430
and today

616
00:42:18,450 --> 00:42:22,360
we're going to talk about is the rate of change

617
00:42:22,410 --> 00:42:26,030
as an interpretation

618
00:42:26,120 --> 00:42:31,750
of the derivative

619
00:42:31,770 --> 00:42:35,640
so remember we we graphs of functions

620
00:42:35,690 --> 00:42:37,940
why of back

621
00:42:37,980 --> 00:42:40,130
and we kept track

622
00:42:40,140 --> 00:42:42,340
the change in x

623
00:42:42,360 --> 00:42:44,460
here the change

624
00:42:44,470 --> 00:42:47,800
and while let's say

625
00:42:50,550 --> 00:42:53,060
from this new point of view a rate of change

626
00:42:53,070 --> 00:42:56,310
keeping track of the rate of change of x in the rate of change of

627
00:42:57,420 --> 00:43:00,170
it's the relative rate of change were interested in

628
00:43:00,180 --> 00:43:04,110
and that's delta y over delta act

629
00:43:04,120 --> 00:43:05,780
now has

630
00:43:05,800 --> 00:43:07,760
another interpretation

631
00:43:07,770 --> 00:43:09,730
this is the average

632
00:43:12,160 --> 00:43:18,100
usually we would think of that if if x were measuring time

633
00:43:18,150 --> 00:43:20,100
and so the average

634
00:43:20,500 --> 00:43:23,000
and that's when this becomes rate

635
00:43:23,060 --> 00:43:27,510
and the average is over the time interval delta x

636
00:43:27,530 --> 00:43:28,290
and then

637
00:43:29,290 --> 00:43:31,540
limiting value

638
00:43:32,360 --> 00:43:36,020
denoted d wide and that is

639
00:43:36,700 --> 00:43:38,380
so this one is the average

640
00:43:38,390 --> 00:43:42,950
the rate of change and this one is the instantaneous

641
00:43:51,620 --> 00:43:52,910
OK so that's

642
00:43:52,950 --> 00:43:55,480
the point of view that i'd like to discuss now give you just a couple

643
00:43:55,480 --> 00:43:58,010
of examples

644
00:43:58,090 --> 00:43:59,100
so let's see

645
00:44:06,680 --> 00:44:08,850
first of all

646
00:44:08,940 --> 00:44:12,600
so maybe some examples from physics here so q

647
00:44:12,650 --> 00:44:18,140
is usually the name for for a charge

648
00:44:18,190 --> 00:44:19,900
and then

649
00:44:19,920 --> 00:44:21,410
dq dt

650
00:44:23,030 --> 00:44:26,370
what is known as current so that

651
00:44:26,470 --> 00:44:30,340
one physical example

652
00:44:30,380 --> 00:44:35,600
the second example which is probably the most tangible one

653
00:44:35,610 --> 00:44:36,710
it is

654
00:44:36,960 --> 00:44:39,700
we could note the letter as by

655
00:44:41,420 --> 00:44:44,420
and then

656
00:44:44,430 --> 00:44:46,030
the rate of change

657
00:44:46,090 --> 00:44:49,760
this is what we call

658
00:44:50,240 --> 00:44:52,320
so those are the

659
00:44:52,330 --> 00:44:57,020
two typical examples and i just want to illustrate

660
00:44:57,030 --> 00:45:00,100
the second example a little bit more detail

661
00:45:00,110 --> 00:45:03,310
because i think it's important to have some visceral sense of

662
00:45:03,360 --> 00:45:05,290
of this notion of

663
00:45:05,340 --> 00:45:08,000
instantaneous speed

664
00:45:08,860 --> 00:45:11,770
i get to use the example of

665
00:45:11,820 --> 00:45:14,110
this very building to do that

666
00:45:14,120 --> 00:45:16,390
probably you know

667
00:45:16,400 --> 00:45:17,600
or maybe you don't

668
00:45:17,610 --> 00:45:20,160
that on how to win

669
00:45:20,250 --> 00:45:22,550
there's an event that takes place

670
00:45:22,600 --> 00:45:23,550
in this

671
00:45:23,640 --> 00:45:28,620
building really from the top of the building which is called the pumpkin drop

672
00:45:31,140 --> 00:45:33,240
so let's illustrate

673
00:45:33,290 --> 00:45:40,680
this idea of rate of change with the pumpkin drop

674
00:45:40,730 --> 00:45:42,650
so what happens is

675
00:45:42,710 --> 00:45:45,270
this building

676
00:45:45,280 --> 00:45:49,950
well let's see here's the building

677
00:45:50,020 --> 00:45:51,440
and here's the

678
00:45:51,460 --> 00:45:53,450
here's the dot that's the

679
00:45:53,470 --> 00:45:54,940
beautiful grass

680
00:45:54,940 --> 00:45:55,780
OK so

681
00:45:55,820 --> 00:45:57,010
i can go to the

682
00:45:57,090 --> 00:45:58,260
very quickly

683
00:45:59,420 --> 00:46:02,990
OK so here is the definition of a finite mixture models

684
00:46:03,010 --> 00:46:06,650
we see the point x i

685
00:46:06,650 --> 00:46:10,130
for each data point x i we

686
00:46:11,090 --> 00:46:13,360
but i which corresponds to

687
00:46:13,400 --> 00:46:16,800
which mixture component it x i came from

688
00:46:18,400 --> 00:46:23,030
the cluster indicator variable that are drawn from this distribution

689
00:46:23,050 --> 00:46:25,300
upon given by pi

690
00:46:25,320 --> 00:46:26,420
so this is

691
00:46:26,470 --> 00:46:29,280
by the mixing proportions

692
00:46:29,390 --> 00:46:33,860
being bayesian search and then given that i

693
00:46:33,920 --> 00:46:39,130
all the axis is drawn from the distribution parametrized by by of that i

694
00:46:39,150 --> 00:46:46,220
that being bayesian which takes place prior over all the making of options as well

695
00:46:46,440 --> 00:46:48,280
of the parameters

696
00:46:48,300 --> 00:46:49,950
by a

697
00:46:50,010 --> 00:46:53,110
so good model

698
00:46:53,530 --> 00:46:55,320
so the model selection

699
00:46:55,320 --> 00:46:57,670
o averaging problem here is

700
00:46:57,670 --> 00:46:59,740
we want to figure out what

701
00:46:59,820 --> 00:47:03,570
the hyperparameters in each one of the dirichlet parameter

702
00:47:04,760 --> 00:47:10,530
and most importantly what number of components in a finite mixture model

703
00:47:13,650 --> 00:47:15,450
if we take the bayesian approach

704
00:47:15,450 --> 00:47:18,110
we are not worry about overfitting

705
00:47:20,050 --> 00:47:24,220
we can imagine taking a number of clusters in a mixture model to be really

706
00:47:27,570 --> 00:47:32,360
notice that we can integrate out all parameters by and

707
00:47:32,380 --> 00:47:35,200
mixing proportions pi

708
00:47:35,220 --> 00:47:37,510
that we integrate out those who

709
00:47:37,530 --> 00:47:41,360
and those are the only latent variables that in our model

710
00:47:43,380 --> 00:47:47,510
the number of latent variables is if and where and is the number of data

711
00:47:48,420 --> 00:47:51,400
so if we take him to be really large

712
00:47:51,860 --> 00:47:53,780
the number of latent variables

713
00:47:53,820 --> 00:47:58,820
that we have this not actually grow in terms of k ones with integrated accross

714
00:47:58,820 --> 00:48:00,320
the components

715
00:48:00,340 --> 00:48:03,400
the mixture components

716
00:48:03,720 --> 00:48:08,680
so what this means is that they will not be over fitting in this model

717
00:48:08,700 --> 00:48:09,860
notice that

718
00:48:10,300 --> 00:48:14,380
there can be at most and components which

719
00:48:14,400 --> 00:48:18,530
active in the sense that the associated with data and of course

720
00:48:18,610 --> 00:48:23,110
the reason for that is and data points each being associated with one of the

721
00:48:25,280 --> 00:48:29,200
but it turns out that usually the number of such active component is much less

722
00:48:29,200 --> 00:48:30,320
than n

723
00:48:30,320 --> 00:48:34,570
even the put even though the the total number of mixture components

724
00:48:34,570 --> 00:48:35,670
he is

725
00:48:35,680 --> 00:48:38,220
to be infinite

726
00:48:38,800 --> 00:48:41,610
so this actually gives us an infinite mixture model

727
00:48:42,110 --> 00:48:43,800
now you can do

728
00:48:43,820 --> 00:48:46,610
we show that this thing actually what

729
00:49:32,670 --> 00:49:34,490
the book

730
00:49:34,490 --> 00:49:37,320
so this is is our

731
00:49:37,470 --> 00:49:42,150
the point of the the point and we have sampling from the posterior of

732
00:49:42,220 --> 00:49:45,360
during the infinite mixture model

733
00:49:46,420 --> 00:49:49,530
the ellipsis here corresponds to the

734
00:49:49,570 --> 00:49:53,760
mixture components which are actually active or associated with a

735
00:49:53,920 --> 00:49:57,720
and in fact that the number of mixture components

736
00:49:57,780 --> 00:49:59,280
within a model

737
00:49:59,280 --> 00:50:03,070
but most of the time we only the small number of mixture components which are

738
00:50:03,070 --> 00:50:05,940
actually associated with a

739
00:50:09,420 --> 00:50:16,920
OK so

740
00:50:16,950 --> 00:50:20,700
there's two issues which will have to address the issue is

741
00:50:20,720 --> 00:50:22,130
and we take this

742
00:50:22,150 --> 00:50:23,340
infinite limit

743
00:50:23,360 --> 00:50:25,610
there's a limit when it goes to infinity

744
00:50:25,630 --> 00:50:30,090
and the second issue is what is the corresponding limiting model

745
00:50:30,110 --> 00:50:34,200
so what we would like to do is just that starting with finite model and

746
00:50:34,200 --> 00:50:35,670
taking the limit

747
00:50:35,720 --> 00:50:39,450
we actually want to define our infinite model directly

748
00:50:39,470 --> 00:50:43,420
and then from that can see the relationship to the final

749
00:50:46,170 --> 00:50:47,360
many of so

750
00:50:47,450 --> 00:50:51,820
i guess everybody is familiar with some part of the by now

751
00:50:51,880 --> 00:50:54,680
it defines a distribution over functions

752
00:50:58,300 --> 00:51:01,880
trial of test it does this process

753
00:51:01,880 --> 00:51:06,860
if for any finite set of input points x one x and

754
00:51:07,200 --> 00:51:12,200
he invented the x one until you x x and this thing is the multivariate

755
00:51:12,200 --> 00:51:15,550
gaussians this defines the goals process

756
00:51:15,570 --> 00:51:17,590
so the concept of the has

757
00:51:17,590 --> 00:51:18,550
i mean

758
00:51:18,550 --> 00:51:20,220
and the covariance

759
00:51:22,510 --> 00:51:26,220
an important part of the property of the marginal distributions

760
00:51:26,260 --> 00:51:28,050
is that they are consistent

761
00:51:28,760 --> 00:51:30,630
what is meant by consistent here

762
00:51:30,630 --> 00:51:32,220
what matters is that

763
00:51:32,260 --> 00:51:34,550
if you take

764
00:51:36,650 --> 00:51:38,820
multivariate analysis

765
00:51:38,860 --> 00:51:41,740
and you integrate out x at thing

766
00:51:41,740 --> 00:51:46,700
that would just left with respect distribution over f of x one f of x

767
00:51:46,700 --> 00:51:48,050
and minus one

768
00:51:48,110 --> 00:51:49,470
and what's

769
00:51:49,510 --> 00:51:53,760
it is important here is that the distribution is again given by gauss in

770
00:51:53,800 --> 00:51:56,970
it with exactly the same form that

771
00:51:56,990 --> 00:52:01,180
it's only been just from x one to x minus one

772
00:52:05,800 --> 00:52:08,820
i think you see the sequence of inputs are

773
00:52:09,330 --> 00:52:10,800
this that

774
00:52:11,280 --> 00:52:12,530
visualizing because

775
00:52:12,550 --> 00:52:16,450
so you can visualize the gods process i think that refers draw out of that

776
00:52:17,400 --> 00:52:20,970
and we can draw perfect two given x one and x being given x one

777
00:52:20,990 --> 00:52:23,010
x two and so forth

778
00:52:23,530 --> 00:52:26,900
in if there are more because

779
00:52:26,950 --> 00:52:29,130
or do any of that

780
00:52:31,240 --> 00:52:35,130
we can actually do this because each of the conditional distribution is

781
00:52:35,150 --> 00:52:36,740
the gulf

782
00:52:36,800 --> 00:52:40,840
f of x y f x and

783
00:52:40,880 --> 00:52:43,070
moving on to a dirichlet process

784
00:52:45,130 --> 00:52:46,280
just as the

785
00:52:46,280 --> 00:52:48,970
process has now

786
00:52:49,050 --> 00:52:51,420
distributed marginal distribution

787
00:52:51,440 --> 00:52:55,840
a dirichlet process had reached distributed marginal distribution

788
00:52:55,860 --> 00:52:57,970
so people familiar with

789
00:52:57,970 --> 00:53:00,740
there is a distribution

790
00:53:00,800 --> 00:53:02,700
the rate of

791
00:53:02,760 --> 00:53:04,360
can be again

792
00:53:12,360 --> 00:53:15,990
dirichlet distribution is a distribution over

793
00:53:16,010 --> 00:53:18,420
the k dimensional probability simplex

794
00:53:19,130 --> 00:53:22,030
the k dimensional probability simplex is simply

795
00:53:22,030 --> 00:53:23,470
a set of factors

796
00:53:23,490 --> 00:53:25,860
i want to i

797
00:53:26,050 --> 00:53:27,950
it and its heart

798
00:53:27,970 --> 00:53:30,570
and it's fun to one

799
00:53:30,570 --> 00:53:33,650
they can also think of this as the distribution

800
00:53:33,740 --> 00:53:39,990
so this is because i want i e as the distribution as the discrete distribution

801
00:53:39,990 --> 00:53:41,320
over here

802
00:53:43,630 --> 00:53:46,200
being the probability of choosing

803
00:53:46,220 --> 00:53:48,670
of the case

804
00:53:48,720 --> 00:53:55,260
we see that the distribution is the distribution over the k dimensional probability simplex

805
00:53:55,360 --> 00:53:59,510
we say that i want it reached the distributed

806
00:53:59,530 --> 00:54:02,380
if it is the random vector where

807
00:54:02,380 --> 00:54:06,740
the then the look like has this form

808
00:54:06,740 --> 00:54:11,200
so that that's the of of interest the distribution

809
00:54:15,990 --> 00:54:17,650
show you that

810
00:54:17,670 --> 00:54:22,260
a lot of nice properties of distribution but just show you

811
00:54:22,260 --> 00:54:25,600
you wouldn't be breaking by pushing on your break

812
00:54:25,640 --> 00:54:28,260
you wouldn't be heating up your brakes

813
00:54:28,330 --> 00:54:30,560
but you would somehow convert

814
00:54:30,570 --> 00:54:31,530
this energy

815
00:54:31,540 --> 00:54:34,950
into the rotating disk and that would slow you down

816
00:54:35,010 --> 00:54:38,020
so to slow down the braking quote unquote

817
00:54:38,060 --> 00:54:39,050
it is now

818
00:54:39,060 --> 00:54:41,290
done because of the conversion from

819
00:54:41,300 --> 00:54:42,960
the linear speed

820
00:54:43,030 --> 00:54:45,390
which comes from gravitational potential energy

821
00:54:45,410 --> 00:54:49,490
to the rotation of the disc

822
00:54:49,520 --> 00:54:51,860
and when you need to the image

823
00:54:51,880 --> 00:54:56,280
you tap it so you should also be able to get the rotational kinetic energy

824
00:54:56,280 --> 00:54:59,030
out and converted again into

825
00:54:59,030 --> 00:55:00,250
forward motion

826
00:55:00,260 --> 00:55:04,180
and if you could really do this then you could go back uphill and you

827
00:55:04,180 --> 00:55:06,220
wouldn't have to use any fuel

828
00:55:06,280 --> 00:55:07,260
all you're

829
00:55:07,270 --> 00:55:08,820
five million rules

830
00:55:08,830 --> 00:55:11,410
can be consumed them in an ideal case

831
00:55:11,430 --> 00:55:13,300
and you wouldn't have to use any

832
00:55:16,680 --> 00:55:19,630
now you can ask yourself the question is this is the only useful in the

833
00:55:19,630 --> 00:55:23,180
mountains could you also uses in the city well of course you can use it

834
00:55:23,180 --> 00:55:24,010
in the city

835
00:55:24,050 --> 00:55:27,800
you wouldn't be breaking like this then which again you would slow down

836
00:55:27,810 --> 00:55:29,120
by taking out

837
00:55:29,140 --> 00:55:30,390
kinetic energy

838
00:55:30,440 --> 00:55:32,160
of linear forward motion

839
00:55:32,190 --> 00:55:35,560
don't that into kinetic energy of rotation of flywheel

840
00:55:35,600 --> 00:55:37,670
and that would slow down

841
00:55:37,690 --> 00:55:40,810
and when the light is to traffic light turns green

842
00:55:40,840 --> 00:55:42,120
you convert it back

843
00:55:42,160 --> 00:55:43,720
rotational kinetic energy

844
00:55:43,740 --> 00:55:47,720
in two linear kinetic energy and you keep going again

845
00:55:47,780 --> 00:55:50,690
now of course it is always easier said than done

846
00:55:50,720 --> 00:55:53,570
but it is not complete fantasy

847
00:55:53,640 --> 00:55:56,360
people have actually made some interesting studies

848
00:55:56,400 --> 00:55:58,300
and i would like to show you

849
00:55:58,320 --> 00:56:02,120
atleast one case that i'm aware of that i found on the web

850
00:56:02,150 --> 00:56:05,460
that shows you that the united states

851
00:56:06,470 --> 00:56:08,580
department is

852
00:56:08,600 --> 00:56:10,900
taking this quite seriously

853
00:56:10,960 --> 00:56:12,990
this is the view graph is also

854
00:56:12,990 --> 00:56:16,270
on the a two one home page

855
00:56:16,380 --> 00:56:19,960
so you see here the idea of mounting such a

856
00:56:20,010 --> 00:56:22,550
flywheel under the car here

857
00:56:22,620 --> 00:56:28,750
this says the location of the flywheel energy management plan wonderful world isn't it

858
00:56:28,790 --> 00:56:30,720
and you see close

859
00:56:30,740 --> 00:56:32,320
of this

860
00:56:33,280 --> 00:56:36,290
i didn't get any numbers on it i don't know which fraction

861
00:56:36,300 --> 00:56:38,500
of the energy can be stored

862
00:56:38,610 --> 00:56:43,490
in your flywheel but it's it's an attempt to people are seriously thinking about it

863
00:56:43,530 --> 00:56:45,000
and it may happen

864
00:56:45,030 --> 00:56:48,910
in the next decade the cars may come on the market

865
00:56:48,930 --> 00:56:50,510
well by some of you

866
00:56:50,550 --> 00:56:53,340
energy these can be

867
00:56:53,390 --> 00:56:56,930
can be salvaged instead of heating up the universe

868
00:56:56,970 --> 00:56:58,140
use it

869
00:56:58,220 --> 00:57:07,920
yourself which would be could be very economical

870
00:57:07,970 --> 00:57:09,630
i have here

871
00:57:12,740 --> 00:57:18,330
also is on TV first

872
00:57:18,340 --> 00:57:20,440
in this toy car

873
00:57:20,500 --> 00:57:23,200
as the flywheel

874
00:57:23,220 --> 00:57:25,350
is here

875
00:57:25,350 --> 00:57:27,160
the fly with itself

876
00:57:27,200 --> 00:57:28,750
is the wheel of the car

877
00:57:28,750 --> 00:57:30,210
but the idea is there

878
00:57:30,240 --> 00:57:32,420
in this case

879
00:57:32,500 --> 00:57:34,510
i cannot converge

880
00:57:34,550 --> 00:57:37,420
linear motion into the flywheel i could do that but i'm going to do it

881
00:57:37,420 --> 00:57:38,860
in the reverse way

882
00:57:38,870 --> 00:57:40,010
i'm going to

883
00:57:40,010 --> 00:57:41,810
this flywheel

884
00:57:41,850 --> 00:57:44,290
a lot of kinetic energy of rotation

885
00:57:44,300 --> 00:57:46,190
we will see shortly how i do that

886
00:57:46,220 --> 00:57:51,200
and then i will show you that that can be converted back into forward motion

887
00:57:51,210 --> 00:57:54,360
in this case very easy because the flywheel itself

888
00:57:54,360 --> 00:57:56,060
it is the real

889
00:57:57,380 --> 00:57:58,340
let me

890
00:57:58,340 --> 00:58:01,620
try to

891
00:58:01,680 --> 00:58:06,280
power this car

892
00:58:06,280 --> 00:58:09,430
i do that with this plastic

893
00:58:12,140 --> 00:58:17,100
so i'm going to put some energy into this we'll into this flywheel

894
00:58:17,100 --> 00:58:20,040
and then will see whether the car can use that

895
00:58:20,070 --> 00:58:21,260
to start moving

896
00:58:21,280 --> 00:58:26,240
great is my lecture notes with their

897
00:58:26,360 --> 00:58:28,070
you see it works

898
00:58:28,120 --> 00:58:30,060
and of course if you could

899
00:58:30,090 --> 00:58:31,990
reverse that idea

900
00:58:32,040 --> 00:58:34,350
that when the car before it stops

901
00:58:34,390 --> 00:58:38,030
getting back into the flywheel then you have the idea that

902
00:58:38,090 --> 00:58:40,350
i was trying to get across

903
00:58:40,360 --> 00:58:42,630
very economical and definitely

904
00:58:42,690 --> 00:58:44,710
that will happen sometime

905
00:58:44,810 --> 00:58:47,000
in the future

906
00:58:47,010 --> 00:58:48,850
fly reels are used

907
00:58:48,860 --> 00:58:51,700
more often than you may think

908
00:58:53,640 --> 00:58:54,420
at the

909
00:58:54,440 --> 00:58:56,360
magnet lab

910
00:58:56,380 --> 00:58:57,540
has two

911
00:58:57,580 --> 00:58:58,720
fly reels

912
00:58:58,750 --> 00:58:59,950
which are

913
00:59:01,530 --> 00:59:03,360
they have a radius

914
00:59:03,410 --> 00:59:07,030
i think of two point four meters that is correct

915
00:59:07,630 --> 00:59:11,040
and each one of those flywheel

916
00:59:11,090 --> 00:59:16,680
has this morning mass of eighty five tons eighty five thousand kilogram

917
00:59:16,770 --> 00:59:22,080
and they rotate

918
00:59:22,090 --> 00:59:23,580
at about six hundred

919
00:59:23,890 --> 00:59:26,770
you can calculate

920
00:59:26,810 --> 00:59:28,090
the moment of inertia

921
00:59:28,180 --> 00:59:30,360
rotate about their center

922
00:59:30,370 --> 00:59:31,890
axis perpendicular

923
00:59:31,910 --> 00:59:33,560
to the plane

924
00:59:33,600 --> 00:59:34,810
you know

925
00:59:34,860 --> 00:59:37,510
now what one half i omega square is

926
00:59:37,520 --> 00:59:39,630
and so you can

927
00:59:39,650 --> 00:59:42,300
calculate the kinetic energy of rotation

928
00:59:42,360 --> 00:59:45,670
the kinetic energy of rotation

929
00:59:45,680 --> 00:59:47,080
is there no warping

930
00:59:47,090 --> 00:59:49,360
two hundred million

931
00:59:50,270 --> 00:59:52,690
each of those rotating

932
00:59:52,710 --> 00:59:54,320
fly reels

933
00:59:54,330 --> 00:59:56,820
now the uses rotational kinetic energy

934
00:59:56,840 --> 00:59:59,340
to create very strong magnetic field

935
00:59:59,390 --> 01:00:02,850
on the time scale a short five seconds

936
01:00:02,890 --> 01:00:03,760
so they

937
01:00:05,260 --> 01:00:07,540
mechanical energy of rotation

938
01:00:07,590 --> 01:00:10,720
two magnetic energy which is not part of a to one so i will not

939
01:00:10,740 --> 01:00:11,130
go into

940
01:00:11,600 --> 01:00:14,100
how they do that this is part of a two and i'm sure all of

941
01:00:14,100 --> 01:00:15,830
you are looking forward to a two two

942
01:00:15,880 --> 01:00:17,600
that's when you will see

943
01:00:17,600 --> 01:00:22,570
how you can convert chemical energy into mechanical energy we have already seen the demonstration

944
01:00:22,570 --> 01:00:23,490
in class

945
01:00:23,550 --> 01:00:25,090
by we converted

946
01:00:25,100 --> 01:00:30,600
mechanical energy when someone was rotating into electric energy if it wasn't it and we've

947
01:00:30,600 --> 01:00:32,190
got these light bulbs although about

948
01:00:32,210 --> 01:00:34,000
you can also converted into

949
01:00:34,000 --> 01:00:35,740
magnetic energy

950
01:00:35,750 --> 01:00:39,350
and then when they have created a strong magnetic field that they do the research

951
01:00:40,530 --> 01:00:42,670
and when they want to get rid of them

952
01:00:42,690 --> 01:00:47,540
they going around and they don't that energy that magnetic energy back into the flywheel

953
01:00:47,550 --> 01:00:49,720
well then start spinning again

954
01:00:49,740 --> 01:00:53,170
at six hertz

955
01:00:53,270 --> 01:00:55,940
needless to say that you which amount

956
01:00:57,280 --> 01:00:59,240
rotational kinetic energy

957
01:00:59,250 --> 01:01:00,490
must be stored

958
01:01:00,500 --> 01:01:01,810
in planets

959
01:01:01,820 --> 01:01:02,760
and in

960
01:01:04,300 --> 01:01:08,620
and i would like to spend quite some time and that it's a very interesting

961
01:01:11,420 --> 01:01:13,100
i will first

962
01:01:13,140 --> 01:01:14,650
discuss with

963
01:01:16,070 --> 01:01:17,830
and the earth

964
01:01:17,840 --> 01:01:20,410
and see how much rotational kinetic energy

965
01:01:20,470 --> 01:01:22,100
it is stored in the

966
01:01:23,050 --> 01:01:24,790
and in the summer

967
01:01:24,840 --> 01:01:27,130
this is also on the to one home page

968
01:01:27,150 --> 01:01:28,200
so don't

969
01:01:28,240 --> 01:01:29,580
copied this

970
01:01:29,630 --> 01:01:33,380
let's first look at the sun we have the mass of the sun

971
01:01:33,470 --> 01:01:35,560
we have the radius of the sun

972
01:01:35,560 --> 01:01:37,920
this is the u i

973
01:01:37,980 --> 01:01:40,340
and that's take one photon that comes in

974
01:01:40,350 --> 01:01:43,680
which happens to be linearly polarized is directly

975
01:01:43,730 --> 01:01:48,480
we pick one photon but is unpolarized light because we're going to have so many

976
01:01:49,650 --> 01:01:54,340
on average there is no preferred direction but i think want to start with

977
01:01:54,350 --> 01:01:56,310
and now i ask myself the question

978
01:01:56,310 --> 01:01:57,570
if that photo

979
01:01:57,580 --> 01:01:59,940
it's kind of a new direction

980
01:01:59,960 --> 01:02:01,200
in this direction

981
01:02:01,210 --> 01:02:03,810
how is the vector oscillating here

982
01:02:03,840 --> 01:02:06,340
so this is now the position vector r

983
01:02:06,360 --> 01:02:08,400
and this is the direction h

984
01:02:08,450 --> 01:02:11,130
which the electrons are going to shake

985
01:02:11,180 --> 01:02:12,780
because the photon comes in

986
01:02:12,780 --> 01:02:17,500
which in the field taking lies this story going to shake like this

987
01:02:17,510 --> 01:02:22,100
you will immediately conclude that you like to go back to linear must be oscillating

988
01:02:22,100 --> 01:02:23,930
like this one

989
01:02:23,990 --> 01:02:26,100
because it has to be perpendicular to

990
01:02:26,120 --> 01:02:27,740
are which it is

991
01:02:27,780 --> 01:02:31,000
and it has to be in the plane of a an r is only one

992
01:02:31,000 --> 01:02:34,000
solution and this is the correct solution

993
01:02:34,010 --> 01:02:36,360
now the next photon coming in

994
01:02:36,420 --> 01:02:37,610
and the next photos

995
01:02:37,620 --> 01:02:39,310
i'll give the color just

996
01:02:39,310 --> 01:02:40,420
distinguish the two

997
01:02:40,440 --> 01:02:43,070
happen to be oscillating in this area

998
01:02:43,080 --> 01:02:47,710
and i asked myself the question if that photo is carried in your direction

999
01:02:47,730 --> 01:02:52,810
in one direction is the field oscillating you come to exactly the same conclusion in

1000
01:02:52,810 --> 01:02:53,890
this direction

1001
01:02:55,560 --> 01:02:58,400
it has to be perpendicular to are which it is

1002
01:02:58,420 --> 01:02:59,520
and it has to be

1003
01:02:59,520 --> 01:03:03,140
in the plane of an are that's the only solution

1004
01:03:03,240 --> 01:03:07,280
a little later there's another photon that comes in

1005
01:03:07,330 --> 01:03:08,430
how is that

1006
01:03:08,450 --> 01:03:09,940
electric field

1007
01:03:09,950 --> 01:03:13,840
we can observe here of course in this direction and so

1008
01:03:13,840 --> 01:03:15,620
no matter how they come in

1009
01:03:15,670 --> 01:03:18,400
unpolarized light you always see

1010
01:03:18,410 --> 01:03:20,260
that is the photon

1011
01:03:20,300 --> 01:03:25,840
is scattered over ninety degrees you will always see polarized in this direction and therefore

1012
01:03:25,850 --> 01:03:29,520
you have created linearly polarized light

1013
01:03:29,570 --> 01:03:31,810
so if you want to hear

1014
01:03:31,860 --> 01:03:36,210
ninety degrees angle or if you want to hear at ninety degrees angles but of

1015
01:03:36,210 --> 01:03:37,850
course it's the whole plane

1016
01:03:37,860 --> 01:03:43,370
then you end up with hundred percent linearly polarized light

1017
01:03:43,400 --> 01:03:48,080
if you go through the same exercise c and angle your forty five degrees and

1018
01:03:48,080 --> 01:03:49,100
you look here

1019
01:03:49,110 --> 01:03:51,440
it is only partially

1020
01:03:54,000 --> 01:03:58,000
indeed if you rotate in front of i for another

1021
01:03:58,010 --> 01:03:59,100
you will see

1022
01:03:59,160 --> 01:04:04,110
clearly light intensity changes but not from the percent polarize you couldn't turn it into

1023
01:04:05,090 --> 01:04:07,310
and if you look from above

1024
01:04:07,360 --> 01:04:10,060
you may want to go through the exercise for yourself

1025
01:04:10,060 --> 01:04:11,340
you will see that the light

1026
01:04:11,360 --> 01:04:14,210
remains completely unpolarized

1027
01:04:14,290 --> 01:04:17,960
so it is only the ninety degree angle that is very special

1028
01:04:18,020 --> 01:04:19,350
and that's what i'm going to

1029
01:04:19,370 --> 01:04:21,870
demonstrate to you

1030
01:04:21,910 --> 01:04:24,450
but before i demonstrate this there's something

1031
01:04:24,490 --> 01:04:27,210
that i have to tell you that i cannot hide from you i wish i

1032
01:04:27,210 --> 01:04:29,560
could but i can't

1033
01:04:29,560 --> 01:04:33,020
it's not something that is my goal during this lecture it has nothing to do

1034
01:04:33,020 --> 01:04:33,670
with this

1035
01:04:35,420 --> 01:04:37,830
but that's the fact that the probability

1036
01:04:37,880 --> 01:04:40,980
when you scatter light of very small particles

1037
01:04:41,020 --> 01:04:43,750
tens of micrometers of dust particles

1038
01:04:43,810 --> 01:04:45,560
that the probability

1039
01:04:45,580 --> 01:04:49,810
of scattering is way higher for blue light than it is for red light

1040
01:04:49,810 --> 01:04:53,030
so like co training so

1041
01:04:53,080 --> 01:04:55,470
ng and cardie

1042
01:04:55,670 --> 01:04:59,100
of human language technology two thousand three

1043
01:04:59,160 --> 01:05:03,090
they have tried see supervised learning here somewhere

1044
01:05:03,680 --> 01:05:10,030
you start with some examples to annotated examples trade

1045
01:05:10,050 --> 01:05:15,280
cool which means nutrients several in this case i think it was too late to

1046
01:05:16,980 --> 01:05:18,120
so you

1047
01:05:18,900 --> 01:05:22,370
two classifiers on your current example set

1048
01:05:23,520 --> 01:05:25,460
the for the examples

1049
01:05:25,470 --> 01:05:26,690
of which

1050
01:05:26,700 --> 01:05:30,650
the bulls classifiers for which both classifiers

1051
01:05:30,700 --> 01:05:33,760
i was very certain about the classification

1052
01:05:33,780 --> 01:05:37,490
they are added to the training set and intuitively

1053
01:05:37,500 --> 01:05:39,650
you reach system

1054
01:05:39,670 --> 01:05:42,730
until you can not improve the accuracy

1055
01:05:42,970 --> 01:05:46,630
upon some validation

1056
01:05:49,520 --> 01:05:51,500
recently we've in this

1057
01:05:51,520 --> 01:05:54,670
calling paper of two thousand

1058
01:05:54,680 --> 01:05:58,160
we see also kernel methods that are being used

1059
01:05:58,920 --> 01:06:03,410
forced of sentences compared to show

1060
01:06:03,430 --> 01:06:06,080
but this is a difficult task itself

1061
01:06:07,540 --> 01:06:09,700
the resolution of

1062
01:06:09,710 --> 01:06:11,490
of note use

1063
01:06:11,510 --> 01:06:15,410
finding out that bill clinton is former president

1064
01:06:15,430 --> 01:06:20,700
for these kinds of situations finding this equivalence relations in the text

1065
01:06:20,720 --> 01:06:22,200
they are quite difficult

1066
01:06:22,210 --> 01:06:25,040
you need to first of all you need

1067
01:06:25,060 --> 01:06:26,490
also knowledge

1068
01:06:26,500 --> 01:06:28,520
that the president is the person

1069
01:06:28,580 --> 01:06:32,080
so that all animals also that the clinton is the person which

1070
01:06:32,090 --> 01:06:34,210
the first one you can

1071
01:06:34,220 --> 01:06:40,690
we too are named entity recognition can find easy easily with some small weight

1072
01:06:40,730 --> 01:06:42,890
the second one to know

1073
01:06:42,910 --> 01:06:45,960
the semantic class of others

1074
01:06:45,970 --> 01:06:47,720
just common nouns

1075
01:06:47,740 --> 01:06:49,170
not proper nouns

1076
01:06:49,180 --> 01:06:51,320
it's much more difficult

1077
01:06:51,330 --> 01:06:54,160
course you can rely on all

1078
01:06:54,170 --> 01:06:56,180
lexical databases

1079
01:06:56,200 --> 01:06:57,630
like worst that

1080
01:06:57,650 --> 01:07:04,070
but still then you have the problem of word sense disambiguation because so many meanings

1081
01:07:04,070 --> 01:07:06,100
of the term in enrichment

1082
01:07:07,550 --> 01:07:08,790
well usually

1083
01:07:08,810 --> 01:07:11,560
we have about the same results if you take

1084
01:07:11,600 --> 01:07:13,810
the first meeting of it

1085
01:07:13,820 --> 01:07:16,990
because it's it's quite noisy so you

1086
01:07:17,010 --> 01:07:20,360
when you do word sense disambiguation

1087
01:07:21,240 --> 01:07:23,740
this relies the meaning of it

1088
01:07:24,660 --> 01:07:30,760
on the other words in the context of other words in the discourse and several

1089
01:07:30,810 --> 01:07:32,590
he excelled learning this

1090
01:07:32,630 --> 01:07:38,040
but to we like actually resources that somewhere have stories to this context so you

1091
01:07:38,040 --> 01:07:43,980
can easily compare with his context find out the exact meaning of

1092
01:07:44,030 --> 01:07:47,790
so this if you using these methods of using these

1093
01:07:47,810 --> 01:07:51,070
these databases

1094
01:07:51,110 --> 01:07:56,060
it's also introduces quite some noise

1095
01:07:56,110 --> 01:08:02,360
another task which we are doing here is when performed

1096
01:08:02,370 --> 01:08:04,310
process use

1097
01:08:04,350 --> 01:08:08,810
well i showed examples of mergers between companies for instance instances

1098
01:08:08,830 --> 01:08:12,310
an entity relation recognition task

1099
01:08:13,520 --> 01:08:18,290
we have here we use a lot of supervised learning

1100
01:08:18,390 --> 01:08:20,140
i showed two examples

1101
01:08:20,150 --> 01:08:22,980
kernel methods that you could use

1102
01:08:22,990 --> 01:08:28,140
f measure that if one measures

1103
01:08:28,180 --> 01:08:31,510
if you look at these measures i did not

1104
01:08:31,520 --> 01:08:32,770
posting here

1105
01:08:32,780 --> 01:08:34,730
this looked to away to a lot

1106
01:08:34,740 --> 01:08:37,690
you can go to these articles c

1107
01:08:37,740 --> 01:08:41,670
it depends only on the class that you are looking for

1108
01:08:42,680 --> 01:08:45,450
certain types of relationships

1109
01:08:45,470 --> 01:08:47,780
they are very easy to detect

1110
01:08:48,330 --> 01:08:51,330
they are very straightforward patterns

1111
01:08:51,380 --> 01:08:54,370
other ones are more difficult

1112
01:08:54,380 --> 01:08:58,530
to detect text causes ambiguity for instance

1113
01:08:58,540 --> 01:09:00,450
the features

1114
01:09:02,220 --> 01:09:04,980
and also the number of training examples

1115
01:09:07,060 --> 01:09:08,730
this is actually

1116
01:09:08,770 --> 01:09:12,240
well these are the two problems section

1117
01:09:12,250 --> 01:09:14,880
first of all you have to see

1118
01:09:14,960 --> 01:09:16,470
most of the patterns

1119
01:09:16,480 --> 01:09:18,620
in your training set otherwise

1120
01:09:18,670 --> 01:09:19,910
the system

1121
01:09:19,920 --> 01:09:26,620
that it's very difficult to them or to interfere with the other patterns

1122
01:09:27,290 --> 01:09:31,550
and secondly we have a problem so this is the problem of recall

1123
01:09:33,000 --> 01:09:37,360
and secondly we have a problem of lower precision when c

1124
01:09:37,420 --> 01:09:40,940
because features that we use so we cannot

1125
01:09:40,980 --> 01:09:46,060
which feature sets that language by which we describe our examples

1126
01:09:46,110 --> 01:09:48,410
might not be

1127
01:09:48,460 --> 01:09:49,670
good enough

1128
01:09:49,680 --> 01:09:51,540
to make the discrimination

1129
01:09:51,590 --> 01:09:55,110
between the different classes

1130
01:09:55,120 --> 01:09:58,680
another task

1131
01:09:59,640 --> 01:10:02,340
so entity relation recognition

1132
01:10:02,350 --> 01:10:05,390
the first two

1133
01:10:05,390 --> 01:10:10,520
so this should be pretty natural just from

1134
01:10:10,530 --> 01:10:15,790
statements even more natural if you'd rather picture so we we have some vertex u

1135
01:10:15,800 --> 01:10:20,560
we're using weekly lines to denote potentially long pants as opposed to edges

1136
01:10:20,570 --> 01:10:23,480
we have some intermediate point x

1137
01:10:23,490 --> 01:10:24,920
and we have

1138
01:10:24,940 --> 01:10:27,770
some target v

1139
01:10:27,860 --> 01:10:31,780
and we're considering these three shortest path is a shortest path from u to v

1140
01:10:31,790 --> 01:10:35,590
this is its weights this is a shortest path from u to

1141
01:10:35,600 --> 01:10:36,830
here's its way

1142
01:10:36,850 --> 01:10:41,020
it shows that xt this way and the point is

1143
01:10:41,030 --> 01:10:46,880
well this should be the shortest path for a shortest path from u to v

1144
01:10:46,950 --> 01:10:50,820
and in particular one such path is you go from u to x and then

1145
01:10:50,820 --> 01:10:52,280
you go from x to be

1146
01:10:52,300 --> 01:10:56,920
so i mean this sum is just measuring the length of this particular path take

1147
01:10:56,920 --> 01:11:00,660
shortest path here take shortest path here and this is supposed be the main over

1148
01:11:00,690 --> 01:11:05,520
all past so certainly this is that most of this particular part the sum of

1149
01:11:05,520 --> 01:11:06,910
these two guys

1150
01:11:06,930 --> 01:11:08,190
OK another person

1151
01:11:11,990 --> 01:11:13,290
OK this

1152
01:11:13,310 --> 01:11:15,110
this stuff is

1153
01:11:15,830 --> 01:11:17,090
so again two

1154
01:11:17,110 --> 01:11:19,590
so more exciting algorithms

1155
01:11:19,610 --> 01:11:22,810
well we're going to algorithms to which is always more exciting

1156
01:11:22,820 --> 01:11:26,910
today we're

1157
01:11:26,930 --> 01:11:30,610
look at a particular version of shortest paths

1158
01:11:35,640 --> 01:11:40,560
the shortest path problem called the single source shortest path problem

1159
01:11:40,710 --> 01:11:47,530
it's a little bit more general from go from a to b

1160
01:11:47,540 --> 01:11:50,470
the problem is you are given the

1161
01:11:50,490 --> 01:11:55,710
a source vertex and you want to know how to get from that source vertex

1162
01:11:55,710 --> 01:11:56,980
to everywhere else

1163
01:11:57,730 --> 01:12:05,530
so we have all closed source vertex s

1164
01:12:05,550 --> 01:12:07,050
and from that

1165
01:12:07,100 --> 01:12:08,930
the sources we want to find

1166
01:12:08,930 --> 01:12:12,430
let's say the shortest path weights

1167
01:12:12,580 --> 01:12:14,560
from s to everyone

1168
01:12:14,640 --> 01:12:18,700
in particular we also like to know the shortest paths but that isn't too much

1169
01:12:20,060 --> 01:12:28,760
so that's delta eskom of for all vertices v

1170
01:12:30,640 --> 01:12:37,650
OK so this is actually a little bit harder than the problem we started with

1171
01:12:37,650 --> 01:12:41,140
the getting from all around cambridge now we want to get from all around to

1172
01:12:41,140 --> 01:12:42,250
the entire universe

1173
01:12:42,710 --> 01:12:47,690
OK it turns out this sort of one of the weird things about shortest paths

1174
01:12:47,690 --> 01:12:50,420
according to the state of the art we know today

1175
01:12:50,440 --> 01:12:52,640
which seems to be

1176
01:12:52,650 --> 01:12:56,160
it seems like the from the following statement will remain true for all time but

1177
01:12:56,160 --> 01:12:57,710
we don't know

1178
01:12:57,730 --> 01:13:02,670
the best algorithm for solving the ADB problem given as given to you from s

1179
01:13:02,670 --> 01:13:04,790
to t is

1180
01:13:04,810 --> 01:13:07,720
no easier than this problem

1181
01:13:07,730 --> 01:13:10,980
the best ways we know how to solve going from a to b is to

1182
01:13:10,980 --> 01:13:14,770
solve how to go from a to everywhere else

1183
01:13:14,780 --> 01:13:19,600
so we we serve can help ourselves but to solve this problem turns out

1184
01:13:19,610 --> 01:13:24,630
today we're going to look further restriction this problem because this is a bit tricky

1185
01:13:24,640 --> 01:13:26,380
well so the next class

1186
01:13:26,400 --> 01:13:28,100
but today

1187
01:13:28,110 --> 01:13:29,960
we're going to get rid of the

1188
01:13:29,980 --> 01:13:31,920
a negative weight cycle issue

1189
01:13:32,120 --> 01:13:36,080
by providing negative weights

1190
01:13:36,100 --> 01:13:41,180
three and assume that all of the edge weights are nonnegative

1191
01:13:41,190 --> 01:13:43,900
for all vertices u and v

1192
01:13:43,920 --> 01:13:47,450
so in particular

1193
01:13:47,500 --> 01:13:53,190
shortest paths exists provided patterns exist

1194
01:13:53,300 --> 01:14:08,960
and we don't have to worry about these minus infinity is dealt

1195
01:14:10,060 --> 01:14:14,490
is always bigger than mine something we still might be plus infinity if there's no

1196
01:14:15,340 --> 01:14:19,380
but this will make life a lot easier and the algorithm will cover today really

1197
01:14:19,380 --> 01:14:21,680
requires this property can

1198
01:14:21,690 --> 01:14:23,400
get away with that

1199
01:14:23,420 --> 01:14:25,350
next class will

1200
01:14:25,370 --> 01:14:27,280
get away without it

1201
01:14:27,370 --> 01:14:33,370
with the fancier and slower

1202
01:14:39,830 --> 01:14:45,470
as i can see that the main idea we're going to be used for the

1203
01:14:45,740 --> 01:14:47,230
stay is

1204
01:14:50,580 --> 01:14:53,940
which should be faster than dynamic programming generally

1205
01:14:53,960 --> 01:14:56,120
and the tricky part would be

1206
01:14:56,150 --> 01:14:59,380
proving that the greedy algorithm actually works

1207
01:15:00,490 --> 01:15:03,740
i think this pretty much only one

1208
01:15:03,770 --> 01:15:06,710
natural way to go back

1209
01:15:07,630 --> 01:15:14,380
there's one with that works car about creating say maybe not the obvious one

1210
01:15:14,390 --> 01:15:17,030
so let me give you a little bit set up

1211
01:15:17,060 --> 01:15:20,900
the invariant we're going to maintain

1212
01:15:20,950 --> 01:15:25,440
is that at all times we have

1213
01:15:25,560 --> 01:15:29,090
estimates on the distances from the source to every

1214
01:15:29,100 --> 01:15:33,980
vertex might distance i mean shortest path weights i'm going to use weight and distance

1215
01:15:34,020 --> 01:15:37,590
interchangeably here for more intuition

1216
01:15:40,360 --> 01:15:43,890
and in particular i want to maintain the set of vertices where those

1217
01:15:43,900 --> 01:15:47,140
those estimates are actually the right answer

1218
01:15:52,930 --> 01:16:06,670
this is less as big as big as will be the set of all vertices

1219
01:16:06,670 --> 01:16:07,630
where i know

1220
01:16:07,640 --> 01:16:14,420
the answer what is the shortest path distance from less to that vertex in yes

1221
01:16:14,440 --> 01:16:19,130
so for starters which distance do i know

1222
01:16:23,600 --> 01:16:26,600
yeah i know the shortest path distance from s to s

1223
01:16:26,610 --> 01:16:33,400
all if i assume that all of my weights are nonnegative i really can get

1224
01:16:33,400 --> 01:16:37,960
from as any faster than not doing anything can have a negative weight cycle maybe

1225
01:16:38,310 --> 01:16:40,950
distance from s s is minus infinity

1226
01:16:40,980 --> 01:16:42,270
OK but

1227
01:16:42,280 --> 01:16:46,160
i can have negative weights so there's no way i can get from s to

1228
01:16:46,160 --> 01:16:49,470
s in any faster than zero time there might be longer path still has zero

1229
01:16:50,440 --> 01:16:53,440
but it can't be any better than zero

1230
01:16:53,490 --> 01:16:55,590
so in particular

1231
01:16:55,690 --> 01:16:58,150
i know that

1232
01:16:58,170 --> 01:17:00,910
so initially as same as

1233
01:17:00,920 --> 01:17:05,970
OK and the idea is and accumulate more and more vertices that we know that

1234
01:17:05,970 --> 01:17:09,680
some point we know some of the distances from some of the vertices

1235
01:17:09,700 --> 01:17:10,790
so we have this

1236
01:17:10,840 --> 01:17:15,970
we have some clout here this is as and this is everything else this is

1237
01:17:15,970 --> 01:17:17,270
the graph g

1238
01:17:17,350 --> 01:17:20,590
some of the vertices

1239
01:17:20,600 --> 01:17:23,090
and you know some edges go out from there

1240
01:17:23,190 --> 01:17:29,760
and so we have estimates of how to get to these vertices some of them

1241
01:17:29,770 --> 01:17:32,740
may not have been seen yet they may not be connected to the scope of

1242
01:17:32,740 --> 01:17:34,380
this portion of s

1243
01:17:34,400 --> 01:17:38,090
i mean not directly they might be connected by some longer path that might they

1244
01:17:38,090 --> 01:17:42,590
might be completely different connected component we don't know yet some of them we have

1245
01:17:42,590 --> 01:17:49,190
this optimal alignment I've plotted the sequence number of X J and the sequence number

1246
01:17:49,190 --> 01:17:56,830
of Y K okay and the the the lines represent the matches and the crosses re represent

1247
01:17:56,830 --> 01:18:03,190
the unmatched points in each configuration and this you know quite stunning to say there's no there's

1248
01:18:03,190 --> 01:18:08,150
no crosses none of this matches crossover each other

1249
01:18:08,290 --> 01:18:14,850
and that was not constraint in the in the model anyway so this is

1250
01:18:14,850 --> 01:18:21,250
optimal bayesian alignment happens to have found a matching optimal matching that's consistent with the

1251
01:18:21,250 --> 01:18:27,190
sequence order now of course you cou we now know now we've seen that that we

1252
01:18:27,190 --> 01:18:31,590
could've use that sequence order in our model and in our inference that we would've got

1253
01:18:31,590 --> 01:18:37,010
the answer very quickly because it would drastically reduced the such scale of the optimization

1254
01:18:37,010 --> 01:18:40,550
we wanted to do but it's it's interesting to know we didn't need to

1255
01:18:40,550 --> 01:18:45,210
do that and indeed in in this field there is some interest in structure

1256
01:18:45,210 --> 01:18:51,430
comparison that's independent of sequence order because it's possible in the evolution of proteins that

1257
01:18:51,430 --> 01:18:56,850
this sequence order is broken commonly it's conserved but not always so that that thing

1258
01:18:56,850 --> 01:19:01,910
is of some interest and this is another way of visualizing that sequence order so I've

1259
01:19:01,910 --> 01:19:07,430
taken the two configurations and coloured them in this rainbow sort of way so that you can

1260
01:19:07,430 --> 01:19:14,650
see you as you progress through the sequence order along each point cloud

1261
01:19:14,650 --> 01:19:20,370
you get this kind of correspondence it simply means how far is in

1262
01:19:20,430 --> 01:19:24,950
one end one end at the the sequence so I've used the  rainbow going from a rather

1263
01:19:24,950 --> 01:19:36,030
uninteresting rainbow going from red to how blue is it dark blue couple of extensions

1264
01:19:36,030 --> 01:19:40,450
other additional information sometimes these points are labeled in various ways for example we know

1265
01:19:40,450 --> 01:19:50,810
they know about things like hydrophobic and hydrophilic residues so you can imagine

1266
01:19:50,810 --> 01:19:57,510
the points carry marks or colors some sort of covariate information and we can we

1267
01:19:57,510 --> 01:20:02,030
can use that this is a particular form of that discrete version but you can

1268
01:20:02,030 --> 01:20:09,130
if you're willing to extend the model so that the generative model not only

1269
01:20:09,130 --> 01:20:15,450
chooses whether or not this hidden point is observed as X or Y or both or neither it also

1270
01:20:15,450 --> 01:20:21,370
chooses what color what what what what mark each point is going to have and if

1271
01:20:21,370 --> 01:20:27,370
you take this this this kind of form that joint distribution then really nothing much

1272
01:20:27,370 --> 01:20:32,130
changes and you can still make inference in the model in exactly the same kind

1273
01:20:32,130 --> 01:20:37,970
of way and then thing we've done is to look at multiple configurations so what

1274
01:20:37,970 --> 01:20:43,450
if there's more than two point clouds lots of point clouds and you can you

1275
01:20:43,450 --> 01:20:47,750
can extended it in a natural way you have a still have a single hidden

1276
01:20:47,760 --> 01:20:54,710
point configuration now you have a match so dramatical configuration for each of the observed configurations and

1277
01:20:54,710 --> 01:21:03,330
the more complicating matching structure so a particular hidden point can be observed in any subset

1278
01:21:03,330 --> 01:21:12,450
of the configuration of the data configurations that's an optimal matching

1279
01:21:12,740 --> 01:21:18,370
in one particular case I haven't got time to tell you about it the notations is cumbersome to expected

1280
01:21:18,370 --> 01:21:24,870
the the joint models still has the same general character and you have

1281
01:21:24,870 --> 01:21:31,150
because of this the generative model having to have probabilities of all patterns of the observation

1282
01:21:31,150 --> 01:21:37,230
there's there's some interesting extra premises to think about them so I mean one

1283
01:21:37,230 --> 01:21:43,680
simple idea is simply to say well each point is independently observed in the first

1284
01:21:43,680 --> 01:21:52,350
configuration second the third fourth the fifth but you may also build in some dependents you know for example if

1285
01:21:52,350 --> 01:21:56,910
if you're thinking about these these different proteins is being evolved from some common

1286
01:21:56,910 --> 01:22:04,010
one it may well be that the process of loss of structure takes place over

1287
01:22:04,040 --> 01:22:09,130
the evolutionary time and that will introduce some dependents in principle you could do that kind of thing

1288
01:22:09,250 --> 01:22:14,290
so we've we've compared to some extend we've compared freeway matching versus all the possible two

1289
01:22:14,290 --> 01:22:22,010
way matching and it's intuitively clear and indeed we we we can say

1290
01:22:22,010 --> 01:22:26,410
that even if you only care about a two-dimensional matching it's worth looking at figure

1291
01:22:26,410 --> 01:22:33,190
relations as well because there's always this borrowing strength from data okay so if you

1292
01:22:33,190 --> 01:22:37,150
just think about how that works as a result of observing extra configuration you have

1293
01:22:37,150 --> 01:22:43,970
a you've you've tied down more definitely where you I is and that's valuable information in

1294
01:22:43,970 --> 01:22:49,150
deciding if X J and Y K are matched so you know this is all based on

1295
01:22:49,150 --> 01:22:59,730
doing its job okay that's seminar one any quick questions about that and I'll do something completely different now

1296
01:22:59,790 --> 01:23:08,330
the second one is to do with tomography tomography is about mapping the

1297
01:23:08,330 --> 01:23:13,090
body without cutting it up this is emission tomography which means what you've done

1298
01:23:13,090 --> 01:23:22,190
has filled the patient with some sort of radioactive drug or gas or something injected

1299
01:23:22,190 --> 01:23:26,610
patient with something that then emits photons and you can record these photons

1300
01:23:26,680 --> 01:23:33,130
try and reconstruct something and I've worked on problems like this on and off over the years I

1301
01:23:33,200 --> 01:23:39,730
paper in the transactions a long time ago doing Bayesian reconstructions initially just

1302
01:23:39,730 --> 01:23:43,210
the map reconstruction based on the algorithm and later a student of mine

1303
01:23:43,210 --> 01:23:48,870
did a fully bayesian version but recently I've been working with Natalia Bochkina in

1304
01:23:48,870 --> 01:23:58,290
Edinburgh to examine some of the theoretical properties of the bayesianreconstructions so

1305
01:23:58,290 --> 01:24:02,790
pretty settle this is a medical technique medical imaging technique

1306
01:24:02,790 --> 01:24:08,490
called spect images function not form it's not looking for the shape of things it's

1307
01:24:08,490 --> 01:24:16,830
looking for what's going on because you choose a radioactive label that is attracted to

1308
01:24:16,830 --> 01:24:24,410
into into body tissue in a way that you can interpret it

1309
01:24:24,410 --> 01:24:31,730
the device for detecting the photons that come out is called a gamma camera and our objective is to collect these photons

1310
01:24:31,730 --> 01:24:38,210
outside the body and try and reconstruct the pattern of concentration whic are called X of where

1311
01:24:38,210 --> 01:24:48,690
that radioactively sub label substance lies in the body I think we've said all about that so that's

1312
01:24:48,690 --> 01:24:54,810
the model was a very nice almost completely believable likelihood model in this case very

1313
01:24:54,920 --> 01:25:02,570
very basically based on high school physics cause we can suppose we

1314
01:25:02,570 --> 01:25:10,810
have this poisson linear model and what does this represent what we have is X transformed by some matrix A

1315
01:25:10,810 --> 01:25:15,570
and then as as our vector of course I will what this means is

1316
01:25:15,570 --> 01:25:18,900
and start

1317
01:25:18,920 --> 01:25:22,080
OK so i'm going to talk about clustering

1318
01:25:22,140 --> 01:25:25,380
and i figured out that many people have you already know

1319
01:25:25,470 --> 01:25:29,950
the clustering so many people already know what he means as many you already implemented

1320
01:25:29,960 --> 01:25:31,040
and so on

1321
01:25:31,060 --> 01:25:34,530
but some of you don't so i really had to struggle the last week to

1322
01:25:34,530 --> 01:25:36,550
figure out where should start

1323
01:25:36,570 --> 01:25:40,300
i start with the boring stuff like you need something linkage

1324
01:25:40,450 --> 01:25:43,820
and half of those of or whether should start to something more interesting so i

1325
01:25:43,820 --> 01:25:47,980
decided for the interesting bit which means that the boring that comes later when it

1326
01:25:47,980 --> 01:25:50,650
comes to the total from the interesting bit

1327
01:25:50,660 --> 01:25:54,240
and was also means that the order of my slides not exactly one i designed

1328
01:25:54,240 --> 01:25:55,800
and so maybe

1329
01:25:55,810 --> 01:25:59,260
we see that there is no doubt

1330
01:25:59,270 --> 01:26:02,560
so i mean this but is not really up to them but essentially what i

1331
01:26:02,560 --> 01:26:06,600
want to do is now i want to start with the advanced algorithms section

1332
01:26:06,760 --> 01:26:11,290
because i think so and the i want to present in detail and spectral clustering

1333
01:26:11,300 --> 01:26:14,720
because this thing on the one hand it's a very interesting with and it also

1334
01:26:14,720 --> 01:26:18,200
shows that many things one has to take care of when one tries to design

1335
01:26:18,200 --> 01:26:22,460
a testing algorithms and many steps involved in the local school of them

1336
01:26:22,490 --> 01:26:24,450
in detail

1337
01:26:24,510 --> 01:26:27,910
OK we also have some other things which are partly

1338
01:26:27,990 --> 01:26:32,850
in the first section which i will present maybe later today or tomorrow

1339
01:26:32,900 --> 01:26:36,650
and then this is the

1340
01:26:36,730 --> 01:26:40,490
third and fourth lecture for tomorrow mainly will concentrate on issues which are more from

1341
01:26:40,490 --> 01:26:42,570
a theoretical science so

1342
01:26:42,570 --> 01:26:46,210
we want to ask the question what can be defined what clustering is or can

1343
01:26:46,210 --> 01:26:47,600
be defined

1344
01:26:47,600 --> 01:26:50,680
does it have anything to try to define what clustering is

1345
01:26:50,690 --> 01:26:54,480
does it had to look at i summer theoretical point of view one of the

1346
01:26:54,480 --> 01:26:56,650
questions we would like to look at and so on

1347
01:26:56,850 --> 01:26:59,710
and that's what i want to talk about tomorrow

1348
01:27:04,820 --> 01:27:06,740
so before we start

1349
01:27:06,760 --> 01:27:10,150
OK clustering most of you know what it is but intuition is

1350
01:27:10,160 --> 01:27:13,840
we are given some objects that can be whatever we want to be dated second

1351
01:27:13,840 --> 01:27:19,870
images can be added gene expression microarray data whatever so we have those objects and

1352
01:27:19,870 --> 01:27:23,180
what we also have some relations between those objects so what you want to do

1353
01:27:23,180 --> 01:27:26,540
in the end we want to say which are similar to each other and which

1354
01:27:26,540 --> 01:27:31,730
are sort of belong to the same web of objects which objects belong to different

1355
01:27:31,760 --> 01:27:33,040
groups some home

1356
01:27:33,080 --> 01:27:37,570
in order to do that we always need some information about relations between objects

1357
01:27:37,630 --> 01:27:41,880
and this information can either be we have something like a similarity function or distance

1358
01:27:42,950 --> 01:27:47,160
or it could also be something more abstract like a neighborhood relationship certain points are

1359
01:27:47,160 --> 01:27:52,260
neighbours of the science but we don't have to like a way of quantifying

1360
01:27:52,320 --> 01:27:53,630
something like that

1361
01:27:53,660 --> 01:27:56,720
and then OK the goal is to find groups in the state of points which

1362
01:27:56,720 --> 01:27:59,350
have something to do with each other

1363
01:27:59,360 --> 01:28:03,630
and intuitively summer it's clear what you want to achieve with that but practically it's

1364
01:28:03,630 --> 01:28:08,920
often very difficult to really get a grip on what exactly want to do

1365
01:28:08,950 --> 01:28:11,910
and one of the reasons is that actually there are

1366
01:28:11,920 --> 01:28:15,950
there might be very many different reasons why you would like to do clustering so

1367
01:28:16,000 --> 01:28:18,410
the first reason which is i think maybe the

1368
01:28:18,420 --> 01:28:20,130
the only reason is

1369
01:28:20,130 --> 01:28:25,040
you want just explore data so somebody just datasets like is setting

1370
01:28:25,070 --> 01:28:28,290
if the customer and he comes up with this data set in this city u

1371
01:28:28,310 --> 01:28:32,000
there no clue about the data is not such ever before and before you know

1372
01:28:32,030 --> 01:28:33,450
started of this

1373
01:28:33,470 --> 01:28:35,580
designing the most complicated model two

1374
01:28:35,630 --> 01:28:37,190
some data might

1375
01:28:37,200 --> 01:28:40,390
just try to play in the data and try to find their structure in the

1376
01:28:41,130 --> 01:28:42,690
which you should need

1377
01:28:42,700 --> 01:28:46,440
to know before you go off and do something more complicated

1378
01:28:47,730 --> 01:28:52,100
OK and what you can do this is clustering so just apply clustering procedure trying

1379
01:28:52,100 --> 01:28:55,760
to figure out the groups in the data which might have something in common and

1380
01:28:55,760 --> 01:28:58,850
maybe in later analysis you would like to treat those groups differently

1381
01:28:59,120 --> 01:29:00,510
that might be

1382
01:29:00,640 --> 01:29:04,450
so but here is really more it's it's really playing around it's not

1383
01:29:04,940 --> 01:29:06,880
you don't have to

1384
01:29:06,890 --> 01:29:11,920
like an objective go like minimizing the squared error loss whatever it's just

1385
01:29:11,940 --> 01:29:13,970
it's more fuzzy set

1386
01:29:14,780 --> 01:29:16,560
the second goal which is very

1387
01:29:16,570 --> 01:29:18,290
very important

1388
01:29:18,350 --> 01:29:20,410
and it becomes even more important as

1389
01:29:20,420 --> 01:29:22,380
the data element grows

1390
01:29:22,390 --> 01:29:24,480
but often so many data points

1391
01:29:24,500 --> 01:29:29,100
that is simply can't run out on your five million data points so you need

1392
01:29:29,100 --> 01:29:30,450
to do something about that

1393
01:29:30,540 --> 01:29:34,930
what people often do is the first of all cluster the data points

1394
01:29:34,950 --> 01:29:37,270
to some groups

1395
01:29:37,320 --> 01:29:40,580
and then they try to run the algorithm on the clusters instead so instead of

1396
01:29:40,580 --> 01:29:41,300
and because

1397
01:29:42,230 --> 01:29:42,620
this guy

1398
01:29:44,050 --> 01:29:44,930
was a calcium

1399
01:29:45,320 --> 01:29:48,380
with the mean which was w transpose x

1400
01:29:49,250 --> 01:29:50,310
um and the

1401
01:29:51,450 --> 01:29:54,570
spherical variance we could solve but now we're saying this is gonna be

1402
01:29:56,800 --> 01:29:58,170
the general linear function

1403
01:29:58,570 --> 01:30:01,240
we can't do the integral in general that's the point i was making

1404
01:30:01,660 --> 01:30:07,090
i want to map to nonlinearity calcium you can't solve the partition function which is is what you need here

1405
01:30:08,610 --> 01:30:09,280
okay so

1406
01:30:12,480 --> 01:30:13,050
that's nice

1407
01:30:13,970 --> 01:30:15,490
what we can do is um

1408
01:30:15,920 --> 01:30:16,550
we can sample

1409
01:30:21,310 --> 01:30:22,990
this is approximately equal to one

1410
01:30:27,190 --> 01:30:28,490
these samples from x

1411
01:30:32,700 --> 01:30:33,970
sample-based approximation

1412
01:30:35,570 --> 01:30:39,270
and we can even compute the posterior by a process known as importance sampling now

1413
01:30:39,270 --> 01:30:43,080
this is easy to compute because this is just a nonlinear mapping of some points

1414
01:30:44,100 --> 01:30:49,160
through the nonlinearity so you can compute this likelihood you can't compute compute this approximate

1415
01:30:49,160 --> 01:30:52,490
likelihood is an approximation to the likelihood you can't compute

1416
01:30:55,660 --> 01:31:02,190
real likelihood that you can park on compute this sample based approximations so this is like super mickey-mouse sampling

1417
01:31:03,460 --> 01:31:04,600
it's nothing like

1418
01:31:05,030 --> 01:31:06,370
what you've been seeing from mark

1419
01:31:07,450 --> 01:31:08,820
it's very very easy to do

1420
01:31:10,600 --> 01:31:12,170
and this is the type of idea that

1421
01:31:13,110 --> 01:31:13,750
we just take

1422
01:31:15,850 --> 01:31:16,720
some points here

1423
01:31:17,090 --> 01:31:20,180
in the one dimensional space we match them with the nonlinearity

1424
01:31:20,920 --> 01:31:25,340
to the two dimensional space and they disappear now as points in the two dimensional space

1425
01:31:25,990 --> 01:31:29,500
and then when you do the sampling basically what the model shows is you just

1426
01:31:29,500 --> 01:31:32,880
need the likelihood of these points these things corrupted by noise

1427
01:31:33,380 --> 01:31:36,830
so actually the density you're looking at is the sum of each of these points

1428
01:31:37,110 --> 01:31:38,610
with a little circle around it

1429
01:31:39,120 --> 01:31:40,110
a little gaussians circle

1430
01:31:40,370 --> 01:31:44,350
that's one way of looking at this density you've got these points which is sampled from your guassian

1431
01:31:44,930 --> 01:31:49,170
he's your sample points and map them to hear and they've got little gaussians density

1432
01:31:49,170 --> 01:31:50,700
is now the trick in on

1433
01:31:52,170 --> 01:31:53,080
density network is

1434
01:31:53,700 --> 01:31:54,420
he also share

1435
01:31:55,090 --> 01:31:58,700
you should really i mean in some sense you could sample separately for every

1436
01:31:59,620 --> 01:32:00,280
i am

1437
01:32:00,590 --> 01:32:01,380
piiv accent

1438
01:32:02,680 --> 01:32:07,310
but he share the samples for accents just have one set samples all the accent

1439
01:32:07,630 --> 01:32:11,450
i and then so this model where you've got i mean you can think about

1440
01:32:11,450 --> 01:32:12,020
pro in fact

1441
01:32:12,440 --> 01:32:15,970
as did etienne shows you can actually think of this just as the density in

1442
01:32:15,970 --> 01:32:20,150
itself some points mapped to the two dimensional space with little galson bumps around them

1443
01:32:20,680 --> 01:32:24,170
and then the likelihood optimization is kinda straightforward

1444
01:32:25,990 --> 01:32:29,630
i say straightforward there's a lot of little mafia but it's simple enough this is

1445
01:32:29,630 --> 01:32:34,450
the sample based approximation so i've used and hear instead invest as i did when

1446
01:32:34,450 --> 01:32:34,910
i draw it

1447
01:32:35,620 --> 01:32:36,990
but basically incentive

1448
01:32:37,670 --> 01:32:43,790
log-likelihood you've got the sum of the log this summer across the samples for the data yeah

1449
01:32:46,020 --> 01:32:46,900
and that's for sure

1450
01:32:46,990 --> 01:32:50,370
each data point is still using the same some so this is the idea of

1451
01:32:50,370 --> 01:32:53,320
sharing those samples and you can compute the gradients

1452
01:32:54,670 --> 01:32:57,050
the gradient of the log likelihood looks like this

1453
01:32:57,930 --> 01:32:59,380
this term appears because the

1454
01:32:59,860 --> 01:33:02,170
the differentiating on the log you get the gradient

1455
01:33:02,650 --> 01:33:05,120
one over the summer and various stuff popping out

1456
01:33:05,490 --> 01:33:06,010
and actually

1457
01:33:07,380 --> 01:33:12,660
can typically be written you can think of this pi hat this term here is the posterior probability

1458
01:33:13,300 --> 01:33:16,090
over data points coming from one of those samples

1459
01:33:16,740 --> 01:33:20,200
that's interesting because actually this is arising from importance sampling

1460
01:33:20,750 --> 01:33:25,410
but it's actually looks very similar to e expectation maximization and that turns out to

1461
01:33:25,410 --> 01:33:28,310
be a duality between these models that you can interview this

1462
01:33:28,770 --> 01:33:34,020
has importance sampling which is what guided or in the duty and this type of model is viewed as

1463
01:33:34,500 --> 01:33:39,290
an expectation expectation-maximization mixture of gaussians and i'll explain that when i explained duty and

1464
01:33:39,290 --> 01:33:41,350
because i was sort of a different interpretation

1465
01:33:41,980 --> 01:33:43,120
but the same basic idea

1466
01:33:46,100 --> 01:33:46,700
go back to

1467
01:33:50,350 --> 01:33:54,430
so also into really works the same way broadly speaking you start with these points

1468
01:33:54,430 --> 01:33:57,370
aim at them in a nonlinear way they lived on a two dimensional space

1469
01:33:58,090 --> 01:34:02,070
but they constrain the point still with the constraint alive on this manifold

1470
01:34:04,460 --> 01:34:04,950
okay so

1471
01:34:05,350 --> 01:34:09,080
this is the oil data and i'm not use many samples has already a hundred

1472
01:34:09,080 --> 01:34:11,210
points in the sample and has an effect

1473
01:34:11,830 --> 01:34:12,720
look at these they also

1474
01:34:13,220 --> 01:34:16,870
but it is going along here that's again the technical term for it because it

1475
01:34:17,650 --> 01:34:18,190
and also

1476
01:34:18,950 --> 01:34:19,880
these little things here

1477
01:34:21,070 --> 01:34:21,870
what's going on there

1478
01:34:22,430 --> 01:34:26,660
is i actually shown this i should probably have shown the samples in this space

1479
01:34:26,930 --> 01:34:30,330
is only a hundred samples space most which are over here what's going on over

1480
01:34:30,330 --> 01:34:32,530
here is about three samples from the gauss

1481
01:34:33,310 --> 01:34:38,600
being mapped to this space so when you try to understand where these data data points are

1482
01:34:39,420 --> 01:34:42,920
they they might they have to be a convex hull of the three data points

1483
01:34:42,920 --> 01:34:46,520
here and actually what they're saying is this one is halfway between one and one

1484
01:34:46,830 --> 01:34:49,500
and so they just leave on this line all these points living along this line

1485
01:34:49,570 --> 01:34:52,570
as a couple living on line there so you see that if you want a

1486
01:34:53,470 --> 01:34:55,440
in these cases and hundred samples

1487
01:34:55,910 --> 01:34:59,930
is actually quite a lot in two dimensions that is still undersampling you see these

1488
01:34:59,930 --> 01:35:02,820
sort effect so the blue is separating from the green and the

1489
01:35:04,820 --> 01:35:06,110
and be a red

1490
01:35:06,930 --> 01:35:07,490
but i'm

1491
01:35:08,040 --> 01:35:08,460
it's kind

1492
01:35:09,000 --> 01:35:12,410
corrupted visualization due to the sampling step now if we go

1493
01:35:12,920 --> 01:35:16,620
four hundred points in the sample localized visualization is yeah

1494
01:35:17,650 --> 01:35:20,950
the this doesn't work as you increase the number of data points this is i

1495
01:35:20,950 --> 01:35:25,400
would say the best visualization we've seen so far the oil data it separated the

1496
01:35:25,400 --> 01:35:26,550
were said

1497
01:35:28,520 --> 01:35:31,190
well i want ask i came up with it

1498
01:35:31,980 --> 01:35:37,210
that's to see that it's true how new ideas over-claiming

1499
01:35:37,270 --> 01:35:39,550
reclaiming that delta two

1500
01:35:41,000 --> 01:35:44,070
two delta two t and i would like to know

1501
01:35:44,090 --> 01:35:47,710
what does that mean

1502
01:35:47,780 --> 01:35:53,730
it's clear that both sides are zero away from the origin

1503
01:35:53,860 --> 01:35:55,550
are totally clear

1504
01:35:55,570 --> 01:36:01,540
it's clearly labeled blow up at the origin somehow whatever delta thing but what is

1505
01:36:01,770 --> 01:36:07,460
how could this me why don't know the factor two in the air and what's

1506
01:36:07,460 --> 01:36:09,630
what's going on

1507
01:36:09,710 --> 01:36:12,360
i could take elements

1508
01:36:12,650 --> 01:36:16,380
the same area that's true that's that's maybe that's o

1509
01:36:17,110 --> 01:36:22,150
the key insight that if i integrate

1510
01:36:22,210 --> 01:36:27,650
everybody knows the role of the delta function is

1511
01:36:28,570 --> 01:36:30,800
now suppose i agree to

1512
01:36:31,320 --> 01:36:33,400
delta two t

1513
01:36:33,420 --> 01:36:35,940
do i really get one

1514
01:36:35,940 --> 01:36:37,730
one of the rule

1515
01:36:37,770 --> 01:36:42,370
changed variables right i knew very well that you be two t

1516
01:36:42,420 --> 01:36:44,360
so use to t

1517
01:36:44,360 --> 01:36:47,860
and the you new in two c other two

1518
01:36:50,570 --> 01:36:55,650
so the areas of the same so that's sort of why factor two is in

1519
01:36:55,690 --> 01:36:58,460
and more generally some

1520
01:37:03,520 --> 01:37:05,340
direct question here

1521
01:37:06,020 --> 01:37:09,690
so the areas match

1522
01:37:09,710 --> 01:37:11,190
the two sides

1523
01:37:11,210 --> 01:37:17,540
but the the full match would be checked that only when you really know what

1524
01:37:17,550 --> 01:37:19,670
delta function is because really

1525
01:37:19,750 --> 01:37:24,820
function is that you know what it does to us move

1526
01:37:26,440 --> 01:37:29,690
what does it do to a smooth function you

1527
01:37:29,750 --> 01:37:34,070
if you take has a function in you multiply by this

1528
01:37:35,360 --> 01:37:37,400
and you have great

1529
01:37:37,420 --> 01:37:40,550
this is really the definition of the director

1530
01:37:40,570 --> 01:37:42,280
and you get what

1531
01:37:46,360 --> 01:37:48,460
that's really the definition

1532
01:37:48,460 --> 01:37:51,820
so much but that's okay

1533
01:37:51,840 --> 01:37:55,210
so that this is all the same and we should share

1534
01:37:55,230 --> 01:37:59,270
the same definition as you can see e

1535
01:37:59,320 --> 01:38:02,920
and multiply by this strange thing

1536
01:38:04,650 --> 01:38:08,750
and now do do i really get the same effort because it's a sure they

1537
01:38:08,750 --> 01:38:10,320
are the same

1538
01:38:10,440 --> 01:38:15,000
why do i get well we're not going to do here

1539
01:38:15,020 --> 01:38:20,630
the same change change of variables right to should be you

1540
01:38:20,650 --> 01:38:23,670
to date she is the u

1541
01:38:23,920 --> 01:38:26,750
question is you are to so

1542
01:38:26,800 --> 01:38:28,940
it's a little different

1543
01:38:30,190 --> 01:38:37,670
i'm taking this function defined by the time i would like to

1544
01:38:37,730 --> 01:38:39,110
i can get

1545
01:38:39,770 --> 01:38:42,230
the value of this

1546
01:38:42,500 --> 01:38:44,190
you equals

1547
01:38:44,250 --> 01:38:45,980
which is

1548
01:38:46,000 --> 01:38:47,960
good deal

1549
01:38:48,000 --> 01:38:50,960
so the two sides give the right thing

1550
01:38:51,750 --> 01:38:54,050
well so there is

1551
01:38:54,150 --> 01:38:58,770
successfully solved one more

1552
01:38:58,820 --> 01:39:00,630
refinement equation

1553
01:39:00,690 --> 01:39:04,000
one more very very special case

1554
01:39:04,280 --> 01:39:07,340
so we tackle another one

1555
01:39:07,400 --> 01:39:11,940
i mean for me to call one more that i know the answer to

1556
01:39:12,040 --> 01:39:14,650
o race this for delta

1557
01:39:14,670 --> 01:39:17,900
right up new special case

1558
01:39:23,730 --> 01:39:26,460
i i coefficients are going to be here

1559
01:39:26,500 --> 01:39:30,050
one four six four one

1560
01:39:30,090 --> 01:39:31,440
all over

1561
01:39:32,380 --> 01:39:35,090
add up to one

1562
01:39:36,590 --> 01:39:39,860
i don't have dealt more fifty

1563
01:39:39,920 --> 01:39:40,960
so i

1564
01:39:41,020 --> 01:39:42,940
OK if i raise this

1565
01:39:42,960 --> 01:39:50,300
this example and make space for the new ones

1566
01:39:50,380 --> 01:39:55,480
right this is the next example so the coefficients one four six four one

1567
01:39:55,500 --> 01:39:56,750
which is really

1568
01:39:56,770 --> 01:40:02,880
it's the convolution of one one with itself

1569
01:40:02,900 --> 01:40:06,280
well one two one over four x was

1570
01:40:06,300 --> 01:40:09,940
the convolution one two one with one two one with b one four six four

1571
01:40:09,940 --> 01:40:13,710
one how do i know that

1572
01:40:14,590 --> 01:40:16,940
multiplying polynomials

1573
01:40:16,960 --> 01:40:22,550
with coefficient one-to-one squaring is this one is the same one to one

1574
01:40:22,860 --> 01:40:28,960
i remember binomial numbers in pascal's triangle or something i see those numbers

1575
01:40:30,460 --> 01:40:37,440
it turns out that if i look at the equations it would be convolution of

1576
01:40:38,590 --> 01:40:41,380
i know this solution for

1577
01:40:41,380 --> 01:40:44,400
the solution for the

1578
01:40:44,570 --> 01:40:49,420
if i can involve the coefficients you could just check that kind of play

1579
01:40:50,770 --> 01:40:52,170
so what is

1580
01:40:52,170 --> 01:40:56,270
this can involved with the first of all tell me

1581
01:40:56,320 --> 01:41:00,090
how far it stretches

1582
01:41:00,110 --> 01:41:04,110
how far it is the head of the hat stretch

1583
01:41:04,130 --> 01:41:09,070
remember that we've already got a period stretches from zero to two

1584
01:41:09,070 --> 01:41:12,820
where will have like that with itself

1585
01:41:15,050 --> 01:41:16,190
go o to four

1586
01:41:16,210 --> 01:41:19,380
go to for zero one two

1587
01:41:21,820 --> 01:41:27,130
and the idea what it will look like now

1588
01:41:27,230 --> 01:41:29,150
is that's

1589
01:41:29,170 --> 01:41:32,420
doing convolution in your head is not a lot of

1590
01:41:33,380 --> 01:41:40,150
especially when the function different parts and you world have the convolution integral

1591
01:41:40,150 --> 01:41:45,400
after a keep track of which perjury and actually it's going to produce

1592
01:41:45,440 --> 01:41:47,360
four different parts here

1593
01:41:47,380 --> 01:41:50,520
well let me say what think you

1594
01:41:50,550 --> 01:41:52,920
it's the cubic flying but why

1595
01:41:52,940 --> 01:41:57,110
we think but it's the spiral

1596
01:41:57,130 --> 01:42:00,090
changes to some other cubic

1597
01:42:00,230 --> 01:42:02,590
changes to some other QB

1598
01:42:02,690 --> 01:42:04,750
changes some of the human

1599
01:42:05,770 --> 01:42:08,440
so why is zero

1600
01:42:08,460 --> 01:42:12,480
this fact has finite length is need

1601
01:42:15,000 --> 01:42:16,940
that's a very important function

1602
01:42:16,960 --> 01:42:19,340
and of course

1603
01:42:19,340 --> 01:42:21,920
this model is the product of r one r two

1604
01:42:21,940 --> 01:42:25,270
and it's argument it's angle

1605
01:42:25,270 --> 01:42:28,200
polar angle is the sum of the old two angles

1606
01:42:28,220 --> 01:42:32,360
and you add the angles

1607
01:42:32,370 --> 01:42:35,110
and you put down your books angles but

1608
01:42:35,120 --> 01:42:40,690
and being photographs under a argument

1609
01:42:49,520 --> 01:42:54,090
in other words it makes the geometric content the multiplication clear

1610
01:42:54,100 --> 01:42:56,300
in a sense in which

1611
01:42:56,330 --> 01:42:59,850
this is extremely unclear from this

1612
01:43:00,830 --> 01:43:03,960
you know blah blah blah blah blah whatever turns out to be

1613
01:43:04,030 --> 01:43:09,570
you have not the slightest intuition that this is true about complex numbers is

1614
01:43:09,610 --> 01:43:12,780
the first that first thing is just the formula

1615
01:43:12,820 --> 01:43:18,940
whereas this thing is an insightful representation of complex multiplication

1616
01:43:19,000 --> 01:43:23,100
now i'd like to use it for something but before we do that well let

1617
01:43:23,100 --> 01:43:24,690
me just indicate how

1618
01:43:26,460 --> 01:43:30,880
the the exponential notation enables you to do

1619
01:43:31,800 --> 01:43:37,050
things in calculus formulas that are possible to remember from calculus it makes them very

1620
01:43:37,050 --> 01:43:39,010
easy to derive

1621
01:43:39,100 --> 01:43:43,600
a typical example of that is all

1622
01:43:44,160 --> 01:43:48,510
suppose you want to for example integrated

1623
01:43:48,870 --> 01:43:53,800
negative x cosine x

1624
01:43:57,510 --> 01:44:01,060
number one you spend

1625
01:44:01,070 --> 01:44:04,800
a few minutes running to calculus textbook and try to find out the answer because

1626
01:44:04,800 --> 01:44:07,360
you know you're not going to remember how to do it

1627
01:44:07,450 --> 01:44:12,420
or you run a computer and type in matlab and something or or you to

1628
01:44:12,690 --> 01:44:16,870
your pocket calculator which will give you formula and so on

1629
01:44:19,640 --> 01:44:24,690
so you know you have AIDS but doing that but the way to do it

1630
01:44:24,740 --> 01:44:28,550
if you're on a desert island

1631
01:44:28,560 --> 01:44:31,150
and the way i always do it

1632
01:44:31,180 --> 01:44:34,910
because i never have any of these little is around

1633
01:44:35,520 --> 01:44:39,100
i trust and i cannot trust my memory

1634
01:44:39,150 --> 01:44:43,100
probably a certain number of you remember how you did in high school or how

1635
01:44:43,100 --> 01:44:45,420
you did in eighteen o one

1636
01:44:45,440 --> 01:44:46,910
if you took it here

1637
01:44:47,680 --> 01:44:51,390
you have to use integration by parts is one of the tricky things

1638
01:44:51,430 --> 01:44:56,680
it's not required on an exam because you have to use integration by parts twice

1639
01:44:56,690 --> 01:44:58,350
in the same direction

1640
01:44:58,350 --> 01:45:03,250
and then suddenly by comparing the end product with the additional products and writing in

1641
01:45:03,250 --> 01:45:05,420
equation somehow that falls

1642
01:45:05,450 --> 01:45:07,510
the value falls out

1643
01:45:07,580 --> 01:45:09,560
well that's tricky

1644
01:45:09,600 --> 01:45:12,060
and it's not the sort of thing you can

1645
01:45:12,100 --> 01:45:13,410
waste time

1646
01:45:13,430 --> 01:45:17,100
stepping into your head unless you're going to

1647
01:45:17,140 --> 01:45:19,220
the the integration be on

1648
01:45:19,270 --> 01:45:22,390
during IAP or something like that

1649
01:45:22,450 --> 01:45:27,040
instead use complex numbers is the way to do this

1650
01:45:27,120 --> 01:45:31,110
so i think of this cosine x what i do is i think that either

1651
01:45:32,600 --> 01:45:34,290
cosine x

1652
01:45:34,360 --> 01:45:39,130
is the real part

1653
01:45:39,930 --> 01:45:41,450
the real part of y

1654
01:45:41,460 --> 01:45:49,020
well cosine x is the real part of e to the INEX

1655
01:45:49,060 --> 01:45:50,310
so this thing

1656
01:45:50,320 --> 01:45:53,580
this is real

1657
01:45:53,630 --> 01:45:55,190
this is real too

1658
01:45:55,200 --> 01:45:58,770
but i'm thinking of it as the real part of

1659
01:45:58,810 --> 01:46:02,280
e to the i

1660
01:46:02,330 --> 01:46:04,120
now if i multiply these two

1661
01:46:04,140 --> 01:46:07,780
together this is going to turn out to be there for the real part of

1662
01:46:07,780 --> 01:46:09,380
the e two r

1663
01:46:09,540 --> 01:46:15,720
minus x rated very pompously and then i'll fix it i would never write this

1664
01:46:16,380 --> 01:46:17,530
you are you

1665
01:46:20,130 --> 01:46:22,860
it's either minus six times

1666
01:46:22,860 --> 01:46:25,110
and they once were

1667
01:46:25,120 --> 01:46:29,500
the idea of what we need to maximisation the case we need to

1668
01:46:29,560 --> 01:46:32,480
exponential families so it's

1669
01:46:32,500 --> 01:46:35,130
it's been a bit of an industry

1670
01:46:35,140 --> 01:46:37,640
but a simple case will be where phi

1671
01:46:37,680 --> 01:46:39,450
if x and y

1672
01:46:39,530 --> 01:46:40,540
it's just

1673
01:46:40,630 --> 01:46:41,880
five six

1674
01:46:43,660 --> 01:46:46,190
after product time you y

1675
01:46:46,200 --> 01:46:50,850
so in other words what i get is point of x and y

1676
01:46:50,890 --> 01:46:52,040
it's just

1677
01:46:52,070 --> 01:46:53,580
on objects

1678
01:46:54,460 --> 01:46:57,270
zero here

1679
01:46:57,310 --> 01:46:59,790
four of x two

1680
01:46:59,810 --> 01:47:00,860
will be

1681
01:47:03,860 --> 01:47:05,860
here here and here

1682
01:47:07,380 --> 01:47:10,850
and will fall exceed three

1683
01:47:13,850 --> 01:47:15,540
on fixed

1684
01:47:15,570 --> 01:47:17,300
you know

1685
01:47:17,360 --> 01:47:20,160
i guess i don't have to continue beyond that

1686
01:47:26,420 --> 01:47:30,050
will be a very simple way of encoding this

1687
01:47:30,130 --> 01:47:32,700
now delta wildlife crime

1688
01:47:32,730 --> 01:47:35,180
this is what i take to be the error

1689
01:47:36,230 --> 01:47:39,980
estimating what prime instead of y

1690
01:47:40,030 --> 01:47:42,940
this could be something like zero one loss

1691
01:47:43,030 --> 01:47:47,110
so for instance if i need to the optical character recognition

1692
01:47:47,240 --> 01:47:50,990
then for digit between o one and ten

1693
01:47:51,060 --> 01:47:52,360
once you know

1694
01:47:52,360 --> 01:47:56,960
well of course there is no specific preference if i get one thing wrong with

1695
01:47:56,960 --> 01:47:58,550
the other

1696
01:47:58,550 --> 01:48:02,250
in general if i have some annotations of documents

1697
01:48:02,270 --> 01:48:05,900
the in there will be annotations which are much worse than others and i definitely

1698
01:48:05,900 --> 01:48:09,110
need to be able to take care of that

1699
01:48:09,830 --> 01:48:11,430
and now what have seen as well

1700
01:48:11,450 --> 01:48:13,880
i want to ensure that my correct

1701
01:48:13,920 --> 01:48:16,080
label namely y

1702
01:48:16,080 --> 01:48:18,610
the inner product between topics and y and w

1703
01:48:18,700 --> 01:48:20,660
has to be great recording

1704
01:48:20,680 --> 01:48:22,530
the and i'm going to make

1705
01:48:22,530 --> 01:48:24,320
by predicting y prime

1706
01:48:24,330 --> 01:48:25,780
rather than y

1707
01:48:26,700 --> 01:48:31,330
now this will be the score that i'm getting for my incorrect label

1708
01:48:31,360 --> 01:48:33,210
for fixed and y fronts

1709
01:48:34,600 --> 01:48:38,170
minus sign the size of this lecture

1710
01:48:38,230 --> 01:48:41,600
without outside of the hard margin solution

1711
01:48:41,640 --> 01:48:43,070
or in other words

1712
01:48:43,100 --> 01:48:45,240
what i'm getting is

1713
01:48:48,290 --> 01:48:51,540
the difference between four x and y and w

1714
01:48:51,590 --> 01:48:54,140
when treated as a function of y

1715
01:48:54,170 --> 01:48:55,910
is an upper bound

1716
01:48:55,920 --> 01:48:58,380
on the error that making

1717
01:48:58,620 --> 01:49:01,080
if mean right inequality

1718
01:49:01,240 --> 01:49:03,640
so what does happen with this means

1719
01:49:05,390 --> 01:49:07,400
five x and y

1720
01:49:08,370 --> 01:49:11,070
off x and one prime

1721
01:49:13,020 --> 01:49:15,830
it has to be greater recall in delta

1722
01:49:15,850 --> 01:49:17,970
of y and y prime

1723
01:49:18,070 --> 01:49:22,670
one this site

1724
01:49:22,720 --> 01:49:24,990
so this really means that

1725
01:49:25,000 --> 01:49:27,070
the difference in this course

1726
01:49:27,070 --> 01:49:29,160
a of x and y w

1727
01:49:29,230 --> 01:49:31,240
and for the incorrect

1728
01:49:31,290 --> 01:49:34,970
this has a major i've the mistakes going to me

1729
01:49:35,030 --> 01:49:37,930
so what is happening now is that the marginal

1730
01:49:37,990 --> 01:49:39,810
it becomes adaptive

1731
01:49:39,810 --> 01:49:41,620
with regard to

1732
01:49:41,630 --> 01:49:45,340
while the labels to them predicting

1733
01:49:45,340 --> 01:49:48,450
it's just like well you know if you're driving along the road in the salt

1734
01:49:49,430 --> 01:49:52,280
you're not going to be that careful about not maybe

1735
01:49:52,280 --> 01:49:55,200
try a little bit of the boundary of the road

1736
01:49:55,320 --> 01:49:58,160
on the other hand if you drive somewhere in the mountains and there's a really

1737
01:49:58,160 --> 01:50:00,710
steep precipice he would

1738
01:50:00,730 --> 01:50:03,930
try as much to stay away from the boundary

1739
01:50:03,940 --> 01:50:06,610
because if you cross it you will just fall off

1740
01:50:06,690 --> 01:50:07,780
so i it

1741
01:50:07,820 --> 01:50:09,750
it's a similar thing happening here

1742
01:50:09,770 --> 01:50:13,940
we try to stay very far away from those labels which will give you a

1743
01:50:13,940 --> 01:50:15,300
catastrophic error

1744
01:50:15,530 --> 01:50:22,090
those which don't really hurt is so much well you don't care much about

1745
01:50:22,140 --> 01:50:26,230
and now what's happening is i just use exactly the same optimisation problem is what

1746
01:50:26,230 --> 01:50:27,870
was there before

1747
01:50:27,870 --> 01:50:32,290
namely just one half the square percy times politics II's

1748
01:50:32,340 --> 01:50:36,930
except that out constraints now are much more complicated

1749
01:50:37,020 --> 01:50:42,080
before that the constraints are just one constraint for observation

1750
01:50:42,090 --> 01:50:44,330
now i've got a thousand classes

1751
01:50:44,340 --> 01:50:47,110
i have a thousand constraints

1752
01:50:47,130 --> 01:50:50,300
so and i imagine have something like

1753
01:50:51,550 --> 01:50:53,220
million observations

1754
01:50:53,300 --> 01:50:55,800
maybe i've have got half a million classes

1755
01:50:55,810 --> 01:50:59,240
things like that can happen for instance level ontologies

1756
01:50:59,860 --> 01:51:04,830
writing up that constrained optimisation problem is utterly in fees

1757
01:51:04,880 --> 01:51:11,580
the only way i you can deal with this is by essentially going for subgradients

1758
01:51:11,630 --> 01:51:13,280
before we do that

1759
01:51:13,320 --> 01:51:14,230
let me show you

1760
01:51:14,280 --> 01:51:15,870
what the margin is

1761
01:51:15,920 --> 01:51:17,160
so here we can see

1762
01:51:17,280 --> 01:51:23,880
that would be the margin corresponding to multiclass

1763
01:51:23,880 --> 01:51:27,170
that's the real problem you can write about

1764
01:51:27,190 --> 01:51:32,320
you might want to do that exactly once in your life in the ranking

1765
01:51:32,640 --> 01:51:38,180
the interesting differences that before that we just set up front between the five fixes

1766
01:51:38,230 --> 01:51:41,980
but now it's inappropriate between differences of of x and y

1767
01:51:42,000 --> 01:51:44,780
i and y

1768
01:51:44,850 --> 01:51:46,650
thank you could for instance used

1769
01:51:46,710 --> 01:51:50,590
svm struct but also europeans there's also on methods all

1770
01:51:50,600 --> 01:51:54,090
and we should will be showing you how to use that one later on

1771
01:51:54,130 --> 01:51:57,200
which relies on a very very simple idea

1772
01:51:57,540 --> 01:52:01,360
but you can just to insist on the list instruct if you want to use

1773
01:52:02,630 --> 01:52:04,500
well they basically does

1774
01:52:04,520 --> 01:52:05,770
it just

1775
01:52:05,850 --> 01:52:09,880
finds the verse violated constraint it every time

1776
01:52:09,890 --> 01:52:14,890
and just as that the constraints of the now solves the optimisation problem

1777
01:52:14,910 --> 01:52:20,280
so rather than dealing with the brilliance of constraints all at once justifies the constraint

1778
01:52:20,280 --> 01:52:21,140
as it in

1779
01:52:21,220 --> 01:52:26,390
the results of problem at another constraint and we solve the problem

1780
01:52:26,400 --> 01:52:29,580
the key difference between what this is all the does

1781
01:52:29,670 --> 01:52:31,600
and what about the method does

1782
01:52:31,600 --> 01:52:35,020
obama takes the entire set of observations is one

1783
01:52:35,040 --> 01:52:39,830
at in one big fat constraint and keeps on doing this

1784
01:52:39,870 --> 01:52:43,100
and this can be paralyzed fill in as many machines

1785
01:52:43,120 --> 01:52:44,530
so that's why

1786
01:52:44,580 --> 01:52:47,120
you can actually get fast convergence that way

1787
01:52:47,130 --> 01:52:48,170
but we should

1788
01:52:48,180 --> 01:52:51,380
discussing that in a lot of detail

1789
01:52:51,380 --> 01:52:57,940
so don't worry about this is this is just going out of print public

1790
01:52:57,990 --> 01:52:59,550
so one way of

1791
01:52:59,620 --> 01:53:03,170
implementing it will be you take an existing also

1792
01:53:03,230 --> 01:53:05,480
you define a loss function

1793
01:53:05,540 --> 01:53:08,480
define a suitable feature map phi x and y

1794
01:53:08,500 --> 01:53:09,410
i'll show you

1795
01:53:09,420 --> 01:53:11,650
which ones are really useful

1796
01:53:11,710 --> 01:53:16,400
and then you need to find an algorithm which maximizes this expression

1797
01:53:16,420 --> 01:53:19,370
why does that matter

1798
01:53:19,380 --> 01:53:20,670
it matters

1799
01:53:21,500 --> 01:53:26,180
well how to get the first constraint the worst constraint i think it

1800
01:53:26,180 --> 01:53:26,840
w two

1801
01:53:29,740 --> 01:53:30,950
sum-of-squares weights

1802
01:53:33,220 --> 01:53:34,530
over the input weights only

1803
01:53:36,320 --> 01:53:37,510
andy w three

1804
01:53:40,140 --> 01:53:41,640
some of squared

1805
01:53:42,320 --> 01:53:43,180
summing over

1806
01:53:43,640 --> 01:53:45,490
these output weights

1807
01:53:46,340 --> 01:53:49,200
only now be a more dimensional valid thing to do

1808
01:53:49,720 --> 01:53:51,800
and then you can say my regularizer is

1809
01:53:52,390 --> 01:53:54,470
some over three go from one to three

1810
01:53:55,340 --> 01:53:58,510
alpha psi you w see and then you're doing something dimension invalid

1811
01:53:59,300 --> 01:54:01,470
rather than just pretending that they all have the same

1812
01:54:02,470 --> 01:54:04,120
regularization constant

1813
01:54:04,930 --> 01:54:06,840
so when you do that's like someplace

1814
01:54:09,200 --> 01:54:14,050
instead he data are going to have a smaller as you manage to perfectly fit the data

1815
01:54:15,120 --> 01:54:18,720
and the weights blowing up which is what just happened with no regularizer

1816
01:54:20,140 --> 01:54:24,530
you can add on you can set we alphas say to one just the start

1817
01:54:24,530 --> 01:54:27,390
off with so alpha one alpha two and alpha three rules that one

1818
01:54:28,070 --> 01:54:32,570
and i go downhill and the first iteration looks just like last time you keep on going downhill

1819
01:54:33,050 --> 01:54:33,720
just sit still

1820
01:54:34,160 --> 01:54:39,010
and you go for ten thousand iterations hand hasn't blown up and gone terribly weekly

1821
01:54:39,010 --> 01:54:40,890
to fit every detail of the nice

1822
01:54:42,160 --> 01:54:44,530
right you might say well maybe that's better

1823
01:54:45,370 --> 01:54:47,300
but you might still be a bit dissatisfied because

1824
01:54:47,760 --> 01:54:50,600
you know is that's really the answer to the question what was the question

1825
01:54:53,550 --> 01:54:57,140
anyway be objective function that we are now minimizing called em

1826
01:55:01,720 --> 01:55:02,910
and is equal to

1827
01:55:03,990 --> 01:55:05,640
multiple he did

1828
01:55:07,910 --> 01:55:08,870
some of our history

1829
01:55:09,260 --> 01:55:10,070
he w

1830
01:55:14,030 --> 01:55:18,080
that's what we're now minimizing that's objective function has gone down and settle down and

1831
01:55:18,080 --> 01:55:21,220
we found an optimum of it and the weights have blown up

1832
01:55:22,510 --> 01:55:23,950
okay what's next

1833
01:55:24,930 --> 01:55:31,280
i suspect what's next is an interpretation of what we're just doing so let's see yeah okay

1834
01:55:31,950 --> 01:55:33,340
let's go back to

1835
01:55:34,340 --> 01:55:35,140
the single neuron

1836
01:55:38,280 --> 01:55:39,530
so the single neuron

1837
01:55:41,340 --> 01:55:42,120
looked like grass

1838
01:55:43,030 --> 01:55:43,530
and i want to

1839
01:55:44,660 --> 01:55:46,620
encourage you to feel dissatisfied with this

1840
01:55:47,320 --> 01:55:48,860
hand feel dissatisfied with

1841
01:55:50,890 --> 01:55:51,680
this thing as well

1842
01:55:52,360 --> 01:55:53,570
that we just had a moment ago

1843
01:55:54,320 --> 01:55:56,070
and then we'll fix your dissatisfaction

1844
01:55:56,800 --> 01:56:02,780
so why should you feel dissatisfied with this outcome of having trained single neuron

1845
01:56:03,220 --> 01:56:05,490
as a replacement for the pigeon that discriminates

1846
01:56:06,320 --> 01:56:07,390
pebbles from reasons

1847
01:56:09,200 --> 01:56:09,890
have think

1848
01:56:10,410 --> 01:56:12,890
about what one source the dissatisfaction might just be

1849
01:56:13,280 --> 01:56:15,550
and on it all depends on the value alpha and d

1850
01:56:15,800 --> 01:56:20,260
has you set alpha to different value you get different answers here upset after point

1851
01:56:20,260 --> 01:56:21,820
one and you get a different solution

1852
01:56:22,360 --> 01:56:25,100
and he said after one get a different solution again so

1853
01:56:25,640 --> 01:56:28,760
the one issue is how do you have the damn regularization constant

1854
01:56:29,640 --> 01:56:34,260
but another issue even if you were happy with with some magic which is the center for this value

1855
01:56:34,760 --> 01:56:35,370
you might say

1856
01:56:38,090 --> 01:56:42,820
i'm willing to believe that the predictions here about so quite well calibrated to this

1857
01:56:42,840 --> 01:56:46,990
data i think it you know it looked reasonable saying it's a twenty percent share

1858
01:56:46,990 --> 01:56:51,740
an eighty percent share you that's okay but i don't believe this extrapolation overhead

1859
01:56:53,070 --> 01:56:54,910
if you look at points

1860
01:56:56,200 --> 01:56:57,620
called ayant be

1861
01:56:59,430 --> 01:57:00,760
are you happy with the idea

1862
01:57:01,510 --> 01:57:03,970
they would just as confident that eh is sort

1863
01:57:04,680 --> 01:57:07,070
ninety percent certain degree in the other class

1864
01:57:07,620 --> 01:57:10,700
hand be is also nineteen sensitivity in the other class

1865
01:57:11,180 --> 01:57:11,800
is reasonable

1866
01:57:13,240 --> 01:57:15,910
if you are dissatisfied you might be interested in

1867
01:57:16,950 --> 01:57:20,220
these view of learning has an inference

1868
01:57:22,220 --> 01:57:23,070
so we discussed

1869
01:57:23,660 --> 01:57:25,510
learning has communication

1870
01:57:26,320 --> 01:57:29,180
now going discuss learning with regularisation weight decay

1871
01:57:56,140 --> 01:57:57,840
so if someone minimizes something

1872
01:57:58,320 --> 01:57:58,990
i ten today

1873
01:58:01,160 --> 01:58:06,430
i will exponentially the thing you're minimizing and organ interpret as the probability whether you like it or not

1874
01:58:06,970 --> 01:58:08,600
so if someone takes and w

1875
01:58:09,300 --> 01:58:10,220
the history w

1876
01:58:11,050 --> 01:58:12,220
plus alpha w

1877
01:58:13,450 --> 01:58:14,220
minimize it

1878
01:58:14,930 --> 01:58:15,490
i will say

1879
01:58:16,430 --> 01:58:16,800
all right

1880
01:58:18,740 --> 01:58:21,320
i'm going interpret interpret that's in the following way

1881
01:58:22,090 --> 01:58:25,700
the posterior probability the weights given implicit assumptions you're making

1882
01:58:28,140 --> 01:58:29,530
in the minus and w

1883
01:58:30,490 --> 01:58:30,970
on z

1884
01:58:32,410 --> 01:58:34,410
and that's equal to the product of

1885
01:58:35,260 --> 01:58:36,510
the probability of the data

1886
01:58:37,910 --> 01:58:38,570
given w

1887
01:58:39,840 --> 01:58:41,090
and the prior probability

1888
01:58:41,590 --> 01:58:42,160
i've w

1889
01:58:42,720 --> 01:58:43,070
given all

1890
01:58:46,470 --> 01:58:49,570
this is your posterior distribution given the data and your other assumptions

1891
01:58:50,030 --> 01:58:51,840
and that's normalizing with something

1892
01:58:55,640 --> 01:59:00,760
implicitly if you minimize this thing u of finding the most probable w given these assumptions

1893
01:59:01,180 --> 01:59:05,090
the probability of the data given w is it to be gene

1894
01:59:09,860 --> 01:59:14,510
hand the probability w the prior probability is it minus alpha

1895
01:59:17,030 --> 01:59:17,680
on something

1896
01:59:24,090 --> 01:59:28,530
so this is an interpretation of what people are already doing it doesn't change anything

1897
01:59:28,800 --> 01:59:31,070
but it may add some useful perspectives

1898
01:59:31,510 --> 01:59:33,660
so if someone minimizes this objective function

1899
01:59:34,180 --> 01:59:35,820
they are implicitly assuming that

1900
01:59:36,550 --> 01:59:37,590
it really is the case


1
00:00:00,000 --> 00:00:02,840
when when when I have a regular network

2
00:00:02,940 --> 00:00:07,060
my clustering coefficient is lar large, for example

3
00:00:07,080 --> 00:00:11,340
in things like this, right, there are there are there are the triangles

4
00:00:11,360 --> 00:00:20,640
and as the network gets gets a more random, the triangles disappear and this gives you a nice way, how to interpo interpolate between something really

5
00:00:21,020 --> 00:00:23,310
regular and something really random

6
00:00:24,770 --> 00:00:26,130
so this is

7
00:00:26,140 --> 00:00:30,820
what I want to show, but there is a but to this model and the but is are

8
00:00:30,900 --> 00:00:35,620
the power-law degree distributions, right, so the heavy tail degree distribution we know that

9
00:00:35,660 --> 00:00:39,960
here all the nodes have the same degree distribution on this side again

10
00:00:39,980 --> 00:00:43,940
the degree distribution is concentrated at the mean, right, here we have a

11
00:00:44,360 --> 00:00:50,030
a poisson degree distribution end, but what we saw before is that in real life they are power-laws

12
00:00:50,660 --> 00:00:53,040
so how do we get to power-laws

13
00:00:57,690 --> 00:00:59,150
and I guess

14
00:00:59,190 --> 00:01:00,480
that you all heard

15
00:01:00,480 --> 00:01:02,590
of the of the first model that

16
00:01:02,640 --> 00:01:06,380
sort of started it all, it was called preferential attachment

17
00:01:06,400 --> 00:01:07,580
by barabasi

18
00:01:07,620 --> 00:01:09,720
and the idea was that

19
00:01:09,730 --> 00:01:12,460
so if you think how how how

20
00:01:12,460 --> 00:01:19,770
say how do people behave how cita how how are citations added to the papers, right, it turns out that

21
00:01:19,820 --> 00:01:43,580
I don't know you start and you want to write a paper then what turns out is that the probability that you're yo that some paper will get a new citation is proportional to the number of citations is it already has, right, so this is something that is called rich get richer, so the more citations you have, the more li the more likely you are to get a new citation, so so this is here is what we mean by that, right, and you know a new node will come and it will create M out-links

22
00:01:44,270 --> 00:01:45,860
and now

23
00:01:45,860 --> 00:02:08,520
all we say is what is the probability of linking to a node with particular degree is just proportional to the degree, right, I'm just like normalizing the sum of all the all the degrees, right, and this is based on a herbert simon's result where he called this cumulative advantage or rich get richer and the whole thing was observed in nineteen sixty-five where where they

24
00:02:08,540 --> 00:02:20,210
where people measured that that the number of new citations the paper gets it is proportional to the number it already has, right, and this is this is exactly what what the formula says so and what turns out is that this

25
00:02:20,230 --> 00:02:21,590
rich get richer

26
00:02:21,600 --> 00:02:27,440
preferential attachment type of process will give you power-law degree distributions with exponent minus three

27
00:02:30,730 --> 00:02:38,250
so there is still a problem with this mo this model that all the nodes have been constant out degree, right, because the way the model specifies it says a node comes

28
00:02:38,710 --> 00:02:48,860
and it will create M edges, now it needs to find targets for these edges and the way it finds the targets is that every node the probability of being selected is proportional to the number of edges it has

29
00:02:49,940 --> 00:02:53,240
but what is nice is that just this simple process

30
00:02:53,250 --> 00:03:00,900
gives you gi gives us the way that this large-scale property like the the the the power-law degree distribution emerges

31
00:03:06,710 --> 00:03:13,900
again there's, so as I said, in in preferential attachment all the all the nodes have the same out degree, so here is a way

32
00:03:13,900 --> 00:03:27,920
to to create power-law in degree and out degree distributions and also a way how to generate communities, right, as we said in in graphs, there's usually at least in social networks alright there is this notion of communities where communities are more densily linked

33
00:03:27,940 --> 00:03:33,040
inside the and they are sparsely linked to the rest of the graph, right, and

34
00:03:33,080 --> 00:03:34,720
a way, how to think about this

35
00:03:34,750 --> 00:03:36,860
is the edge copying model

36
00:03:37,520 --> 00:03:40,170
by kleinberg from ninety-nine

37
00:03:40,190 --> 00:03:43,610
and the idea is the, again, we have a network and a new node comes to it

38
00:03:43,620 --> 00:03:46,120
and so the

39
00:03:46,120 --> 00:03:51,140
that's just group is big

40
00:03:51,200 --> 00:03:54,080
we have this

41
00:03:57,180 --> 00:04:01,320
i see

42
00:04:02,300 --> 00:04:05,360
you might see

43
00:04:10,060 --> 00:04:12,710
and was a semiring

44
00:04:12,780 --> 00:04:14,670
might seem like

45
00:04:15,290 --> 00:04:17,370
season one

46
00:04:17,560 --> 00:04:18,990
the some

47
00:04:19,030 --> 00:04:22,630
see what was

48
00:04:22,650 --> 00:04:24,780
so that

49
00:04:24,890 --> 00:04:28,240
so your

50
00:04:28,390 --> 00:04:32,860
you seem like this

51
00:04:32,870 --> 00:04:38,980
my see

52
00:04:41,740 --> 00:04:42,850
this formulation

53
00:04:43,080 --> 00:04:46,430
again going from the the US right

54
00:04:46,450 --> 00:04:48,260
and i'm going to show

55
00:04:48,310 --> 00:04:50,570
then you get something that's

56
00:04:53,120 --> 00:04:54,750
this expression

57
00:04:56,060 --> 00:04:59,100
we we're going to

58
00:05:11,580 --> 00:05:13,790
it might seem like

59
00:05:13,830 --> 00:05:14,790
this is

60
00:05:19,850 --> 00:05:24,110
the humility right down the line and then we'll discuss it in

61
00:05:28,230 --> 00:05:40,340
so let me rephrase it so what you see is that if you use

62
00:05:40,840 --> 00:05:41,410
if you

63
00:05:41,470 --> 00:05:45,760
x minus to plus and you subtract x minus the mind think about when is

64
00:05:45,770 --> 00:05:50,270
this function positive with eventually this part is bigger than the other one which means

65
00:05:50,270 --> 00:05:54,350
if the point is further away from the positive and then from the negative zone

66
00:05:54,350 --> 00:05:56,170
so maybe it's not the other way around

67
00:05:56,670 --> 00:05:58,380
so i

68
00:05:58,470 --> 00:06:00,330
that's right

69
00:06:34,580 --> 00:06:37,670
up to you

70
00:06:37,680 --> 00:06:53,650
this section on the talk about whatever

71
00:07:15,060 --> 00:07:22,260
what of the

72
00:07:23,740 --> 00:07:27,090
design changes

73
00:08:03,180 --> 00:08:07,580
so i

74
00:08:10,010 --> 00:08:14,050
and the difference between

75
00:08:14,240 --> 00:08:16,890
c one

76
00:08:20,450 --> 00:08:24,330
minus one

77
00:08:25,830 --> 00:08:35,780
i that's

78
00:08:35,800 --> 00:08:38,660
i think of this is in boldface x that is using

79
00:08:38,760 --> 00:08:42,660
which at the top of the site is used as the

80
00:08:42,760 --> 00:08:47,280
shorthand by it's a little bit confusing so all these vectors are already living in

81
00:08:47,280 --> 00:08:49,700
the feature space that is using

82
00:08:52,950 --> 00:08:54,930
it right first

83
00:08:55,060 --> 00:08:58,160
does was my

84
00:08:58,280 --> 00:08:59,800
and we have to

85
00:09:04,930 --> 00:09:06,680
one year

86
00:09:06,800 --> 00:09:08,330
here we

87
00:09:08,370 --> 00:09:12,740
see what does it mean to see my doctor

88
00:09:12,820 --> 00:09:14,470
in this this

89
00:09:14,680 --> 00:09:16,680
as this

90
00:09:16,680 --> 00:09:18,350
the was

91
00:09:18,370 --> 00:09:20,450
darcy true

92
00:09:20,510 --> 00:09:21,640
and plus

93
00:09:21,660 --> 00:09:23,160
and then some ideas

94
00:09:23,200 --> 00:09:24,530
so we can

95
00:09:25,800 --> 00:09:28,180
it is the sequel

96
00:09:28,240 --> 00:09:29,700
so what

97
00:09:29,780 --> 00:09:33,140
i see my thoughts in mind

98
00:09:33,280 --> 00:09:37,180
the signs again i just one

99
00:09:37,300 --> 00:09:42,410
thank you very much

100
00:09:45,570 --> 00:09:50,560
different from what i expected but it also shows that the two formulations are the

101
00:09:51,470 --> 00:09:54,300
so it counts solution

102
00:09:56,200 --> 00:10:01,100
yes he's using some linear algebra just to show that the one formulation that i

103
00:10:01,100 --> 00:10:02,410
was suggesting originally

104
00:10:02,890 --> 00:10:07,200
here with the dot product in the distance formulations of the same of course i

105
00:10:07,200 --> 00:10:09,530
guess some of you may have just

106
00:10:09,580 --> 00:10:13,390
use this formula the starting point in directly plugging things

107
00:10:13,410 --> 00:10:14,600
and then

108
00:10:14,620 --> 00:10:18,740
that so we get to the solution here

109
00:10:18,830 --> 00:10:20,160
so maybe

110
00:10:20,240 --> 00:10:24,950
maybe i'll just briefly into it so that those people can also double checked that

111
00:10:25,010 --> 00:10:27,200
i did things correctly but

112
00:10:27,350 --> 00:10:31,240
meanwhile maybe right down to solve the the problem

113
00:10:32,240 --> 00:10:38,990
for name

114
00:10:42,120 --> 00:10:44,320
OK so one point for patrick

115
00:10:44,330 --> 00:10:52,240
maybe also one point for the guy who notice the sign change

116
00:10:56,300 --> 00:10:57,660
and so

117
00:11:04,390 --> 00:11:07,220
will be wearing the yellow jersey tonight

118
00:11:07,220 --> 00:11:11,990
OK so that the discrete do it the other way

119
00:11:11,990 --> 00:11:16,580
so if we if we directly use this formulation

120
00:11:17,700 --> 00:11:23,430
so just ignore all this in between

121
00:11:23,430 --> 00:11:26,180
and directly plug it in

122
00:11:26,300 --> 00:11:33,080
so this is the dot product between

123
00:11:33,100 --> 00:11:34,990
this vector and itself OK

124
00:11:36,470 --> 00:11:44,910
c minus

125
00:11:44,950 --> 00:11:50,990
the sum of all my negative points very and one over and two

126
00:12:06,660 --> 00:12:07,620
OK so

127
00:12:07,620 --> 00:12:10,770
if d is measured in very large units

128
00:12:10,790 --> 00:12:13,970
then the size of the neighborhood is essentially k equals one and if t is

129
00:12:13,970 --> 00:12:16,650
measured very small units and averaging over one

130
00:12:16,660 --> 00:12:21,280
but it will never be of course equivalent to k nearest neighbour

131
00:12:22,230 --> 00:12:27,220
so now the idea is to learn the metric by adjusting these these to maximize

132
00:12:27,220 --> 00:12:29,170
its expected performance

133
00:12:29,220 --> 00:12:33,130
and having done the simplest thing that could possibly do for the objective function i'm

134
00:12:33,130 --> 00:12:36,400
now going to do the simplest thing i could possibly do for the model

135
00:12:36,420 --> 00:12:40,530
so the simplest thing you could possibly do is just measure the distance between two

136
00:12:40,530 --> 00:12:42,440
points x i and x j

137
00:12:42,450 --> 00:12:46,900
by putting a positive semi definite matrix in

138
00:12:46,920 --> 00:12:52,000
so just go gaussians or quadratic metric

139
00:12:52,710 --> 00:12:54,490
q is some symmetric

140
00:12:54,540 --> 00:13:00,500
positive semi definite matrix and we're going to rewrite this distance using the square root

141
00:13:00,500 --> 00:13:01,300
of q

142
00:13:01,310 --> 00:13:05,730
so i just replaced q with eight transpose a there's many ways to do this

143
00:13:05,730 --> 00:13:07,010
they are unique

144
00:13:07,970 --> 00:13:11,880
any the square root of q will make the point here what is the distance

145
00:13:11,880 --> 00:13:15,930
turn out to be the distance turns out to just be euclidean distance

146
00:13:15,940 --> 00:13:18,600
in some transformed space

147
00:13:18,620 --> 00:13:22,940
so you can imagine is that i just found the transformation a

148
00:13:22,950 --> 00:13:24,860
after which

149
00:13:24,900 --> 00:13:28,580
the right distance metric to use is just euclidean distance

150
00:13:28,740 --> 00:13:32,400
so you can summarize everything i told you so far by the following find me

151
00:13:32,400 --> 00:13:35,570
a linear transformation of the original data

152
00:13:35,590 --> 00:13:39,710
so that when i look in that linear transformation and i do the euclidean k

153
00:13:39,710 --> 00:13:42,610
nearest neighbour things worked out well

154
00:13:42,620 --> 00:13:44,130
as estimated by

155
00:13:44,140 --> 00:13:48,180
leave one out cross validation or soft versions

156
00:13:48,200 --> 00:13:49,660
OK the questions

157
00:13:50,740 --> 00:13:51,910
with me

158
00:13:51,920 --> 00:13:53,400
that's bust-up

159
00:13:56,650 --> 00:14:02,610
this in regression this would be very close to parzen window

160
00:14:02,640 --> 00:14:07,740
with the exception of this normalisation is sort of point

161
00:14:13,500 --> 00:14:16,310
in the

162
00:14:16,330 --> 00:14:20,760
so you can think of this as sort of stealing the bandwidth trick from density

163
00:14:20,760 --> 00:14:25,120
estimation and trying to make it work for classification

164
00:14:25,130 --> 00:14:26,350
OK so

165
00:14:26,410 --> 00:14:29,390
this is probably

166
00:14:29,430 --> 00:14:32,840
too many equations on one slide but i just want to make a point here

167
00:14:32,840 --> 00:14:38,050
because you on touched on i think it's very very crucial if you just do

168
00:14:38,050 --> 00:14:39,420
what i told you

169
00:14:39,430 --> 00:14:42,210
you're going to end up with an algorithm is quadratic in the number of data

170
00:14:43,200 --> 00:14:45,760
and that's probably gonna make you unhappy

171
00:14:45,780 --> 00:14:49,000
so i'm going to try and tell you a little bit about how to approximate

172
00:14:49,000 --> 00:14:53,950
or sample to get around so here it is this is the expected classification performance

173
00:14:54,320 --> 00:14:58,690
so this is the average over all data points of the chance of getting that

174
00:14:58,690 --> 00:15:01,530
data point correct and the leave one out scheme

175
00:15:01,550 --> 00:15:06,400
OK so we take the derivative of this with respect to the distances

176
00:15:06,410 --> 00:15:10,700
where the distances are defined like this what we're really taking the derivative with respect

177
00:15:10,700 --> 00:15:15,110
to the transformation so adjusting the linear transformation

178
00:15:15,130 --> 00:15:17,810
so that the expected performance is

179
00:15:18,690 --> 00:15:23,640
now if you write down this expression for the gradient the exact expression it sort

180
00:15:23,640 --> 00:15:24,390
of quadratic

181
00:15:24,790 --> 00:15:28,120
you have to some of all the data points because each data point contribute to

182
00:15:28,120 --> 00:15:32,770
gradient term and in order to compute the gradient term of that data point exactly

183
00:15:32,770 --> 00:15:37,460
you need to consider the other datapoints first the ones in your class and then

184
00:15:37,460 --> 00:15:39,350
the ones not in your class

185
00:15:39,370 --> 00:15:42,130
OK so it would be quadratic if you did

186
00:15:42,930 --> 00:15:47,520
there's two observations here why this is just gradient descent

187
00:15:47,530 --> 00:15:51,370
so we don't really care about the exact gradient right it's not a holy artifact

188
00:15:51,370 --> 00:15:54,360
it's just the gradient we're just going to take it and adjust their parameters and

189
00:15:54,360 --> 00:15:55,340
drop it on the floor

190
00:15:55,380 --> 00:15:58,520
so we don't really need the gradient to be right we just need to be

191
00:15:58,520 --> 00:16:01,070
sort of right in fact we don't even need to be sort of right which

192
00:16:01,070 --> 00:16:04,260
is not needed to be not ninety degrees wrong

193
00:16:04,270 --> 00:16:09,480
OK so just subsample here just grab a few data points used to estimate the

194
00:16:09,480 --> 00:16:12,490
gradient nature parameters and started that would be fine

195
00:16:12,510 --> 00:16:13,980
i want to

196
00:16:15,040 --> 00:16:21,650
stochastic gradient optimisation perfectly legit OK the observation is that in these interiors sometimes you're

197
00:16:21,650 --> 00:16:27,940
weighting the other data points so

198
00:16:29,910 --> 00:16:32,060
it appeared back here on the screen

199
00:16:32,100 --> 00:16:33,890
OK good

200
00:16:34,900 --> 00:16:35,590
i guess

201
00:16:35,620 --> 00:16:38,830
the penalty for spending too long in the slide

202
00:16:38,840 --> 00:16:43,100
so you're weighting the other data points and there waiting no by

203
00:16:43,830 --> 00:16:48,410
neighborhood selection probability and most of these probabilities are almost zero

204
00:16:48,430 --> 00:16:52,010
right i have my little neighborhood my friends were around me and the probability of

205
00:16:52,010 --> 00:16:56,000
picking someone all the way over there is basically zero so you don't need to

206
00:16:56,000 --> 00:17:01,120
go through all these painful calculations you can keep inactive list of who's really ineffective

207
00:17:01,120 --> 00:17:05,320
neighborhood domain and then update that active list every few hundred iterations when you return

208
00:17:05,350 --> 00:17:09,030
to the premier so there are some tricks for approximation you don't want to get

209
00:17:09,030 --> 00:17:13,220
into them but if you just write down this equation it looks pretty nasty

210
00:17:14,480 --> 00:17:17,570
so this is the the algorithm the first one that i want to tell you

211
00:17:17,570 --> 00:17:21,010
about it called neighbourhood components analysis so was in a couple of years ago

212
00:17:21,690 --> 00:17:28,050
it learns a linear transformation of the input space after which nearest neighbour performs well

213
00:17:28,080 --> 00:17:33,320
so the transformation intuitively scales up directions which are useful for discrimination and tries to

214
00:17:33,320 --> 00:17:37,640
project out dimensions which are not informative about class

215
00:17:37,660 --> 00:17:39,730
and the algorithm is very simple

216
00:17:39,740 --> 00:17:42,580
right down this objective function

217
00:17:42,590 --> 00:17:46,080
and optimize that kind of

218
00:17:47,910 --> 00:17:52,390
and then you are you take this that you want a new project training set

219
00:17:52,390 --> 00:17:53,700
into that

220
00:17:53,890 --> 00:17:58,350
new feature space so for every training point exile you create a new training point

221
00:17:58,360 --> 00:18:03,030
why i by multiplying by this transformation and then you put the line rises as

222
00:18:03,030 --> 00:18:06,970
the training data a four-year-old k nearest neighbour code

223
00:18:06,980 --> 00:18:10,890
and at test time when you get a new test point you also multiplied by

224
00:18:10,890 --> 00:18:14,890
eight to get into the right test space and then you present that y test

225
00:18:14,950 --> 00:18:18,830
here consider really even have to write any new code for test

226
00:18:18,830 --> 00:18:24,000
so if you have kd trees and fancy data structures LSH that does you no

227
00:18:24,000 --> 00:18:26,260
retrieval for the neighbours and stuff you can

228
00:18:26,260 --> 00:18:28,140
using maximum likelihood

229
00:18:28,990 --> 00:18:33,120
parameter on the inverse covariance matrix with an l one penalty

230
00:18:33,140 --> 00:18:36,620
on the on the inverse covariance there it is of the year

231
00:18:36,620 --> 00:18:37,660
so this is

232
00:18:37,660 --> 00:18:41,490
this is a p by p covariance matrix and we put in our one penalty

233
00:18:41,490 --> 00:18:42,660
on all the

234
00:18:42,660 --> 00:18:44,990
all the parameters and the covariance matrix

235
00:18:44,990 --> 00:18:46,010
and this is just

236
00:18:46,030 --> 00:18:50,260
the partially maximise log likelihood for the gas in models

237
00:18:50,320 --> 00:18:51,700
and it turns out

238
00:18:51,700 --> 00:18:54,590
if you do blockwise coordinate descent

239
00:18:55,910 --> 00:18:59,890
you've got to p by the covariance matrix solving for

240
00:18:59,910 --> 00:19:02,680
a whole column of coefficients at the time it turns out

241
00:19:03,100 --> 00:19:05,430
solving that amounts to a kind of

242
00:19:05,450 --> 00:19:07,680
let's two regularisation problem

243
00:19:07,740 --> 00:19:12,120
so it's like a lasso regression problem and you can exploit coordinate descent so this

244
00:19:12,120 --> 00:19:14,620
too many details to go into

245
00:19:14,700 --> 00:19:17,260
but again we can do that very efficiently

246
00:19:17,280 --> 00:19:19,160
and we can compute the whole path

247
00:19:19,240 --> 00:19:20,800
as we vary lambda

248
00:19:20,820 --> 00:19:22,390
so for example

249
00:19:22,430 --> 00:19:25,300
we can solve moderately sparse graphs

250
00:19:25,300 --> 00:19:28,530
with a thousand nodes in under a minute

251
00:19:28,550 --> 00:19:30,430
and i'll give an example now

252
00:19:30,470 --> 00:19:33,200
this is a small problem eleven proteins

253
00:19:33,220 --> 00:19:35,330
measured on seven thousand

254
00:19:35,930 --> 00:19:37,700
training observations

255
00:19:37,720 --> 00:19:41,470
and so you know the graphical models you see the land is written about the

256
00:19:42,370 --> 00:19:43,950
when lambda zero

257
00:19:44,320 --> 00:19:47,220
land easier over the it's and and

258
00:19:47,280 --> 00:19:48,010
every year

259
00:19:48,030 --> 00:19:52,330
it's unregularized fit so there is an edge between every protein

260
00:19:52,390 --> 00:19:54,870
and then as you ramp up lambda

261
00:19:55,240 --> 00:19:58,410
the graph gets more sparse sparser and sparser

262
00:19:58,410 --> 00:20:02,780
so we can compute the whole path of solutions very efficiently

263
00:20:02,780 --> 00:20:05,830
the group lasso that's

264
00:20:05,930 --> 00:20:09,280
one and may invent again

265
00:20:09,330 --> 00:20:10,490
two different groups

266
00:20:10,590 --> 00:20:13,240
and others have worked on it too

267
00:20:13,300 --> 00:20:16,240
so each in that case each of the terms

268
00:20:16,300 --> 00:20:23,010
the penalty is referred to sets of parameters

269
00:20:23,030 --> 00:20:27,240
and you don't have one norm have some of our two norms

270
00:20:27,260 --> 00:20:31,390
and so this term over year is actually the l two norm of the vector

271
00:20:31,390 --> 00:20:37,280
of coefficients so that the variables are arranged in groups and each group has a

272
00:20:37,280 --> 00:20:39,100
set of linear coefficients

273
00:20:39,140 --> 00:20:40,820
and we we penalize

274
00:20:40,870 --> 00:20:44,120
the vector of coefficients for each group with an l two norm

275
00:20:44,120 --> 00:20:47,410
no it is not l two squared it's just too

276
00:20:47,410 --> 00:20:52,140
and what that does is it tends to select the whole group of variables or

277
00:20:52,140 --> 00:20:53,780
leave it out

278
00:20:53,850 --> 00:20:56,350
and if they in the or nonzeros

279
00:20:56,410 --> 00:21:00,850
and that's useful for example if you fit in linear models with categorical predictors

280
00:21:00,870 --> 00:21:03,800
with multiple levels and you represent each of those

281
00:21:03,820 --> 00:21:08,910
by dummy variable saliency of a group of coefficients you want at home

282
00:21:08,930 --> 00:21:11,370
categorical variables in or out of the model

283
00:21:11,430 --> 00:21:13,300
with all of its coefficients

284
00:21:13,350 --> 00:21:18,050
and coordinate ascent very useful for solving that problem

285
00:21:19,570 --> 00:21:22,390
something that we worked on a few years ago

286
00:21:22,850 --> 00:21:29,050
stands for comparative genome hybridisation modelling

287
00:21:29,070 --> 00:21:35,030
and we use we introduced well to and colleagues introduced something called the fused lasso

288
00:21:35,030 --> 00:21:35,930
so there

289
00:21:35,950 --> 00:21:37,850
in this particular example

290
00:21:38,600 --> 00:21:43,800
the coefficients actually former time series so they arranged a lot of time series series

291
00:21:43,800 --> 00:21:45,350
in genome order

292
00:21:45,350 --> 00:21:48,350
so these enabling this notion two coefficients

293
00:21:48,370 --> 00:21:52,550
so we've got a penalty that patients take the coefficients to zero

294
00:21:53,550 --> 00:21:55,720
and also constraints

295
00:21:55,760 --> 00:21:57,830
neighboring coefficients to be the same

296
00:21:57,850 --> 00:21:59,990
so trying to encourage piecewise

297
00:22:01,030 --> 00:22:02,300
in fact

298
00:22:02,300 --> 00:22:05,490
and yes the solution to get out

299
00:22:05,530 --> 00:22:09,620
again we use a coordinate descent method to solve the problem

300
00:22:09,700 --> 00:22:11,660
in this paper

301
00:22:11,680 --> 00:22:13,800
the website on that

302
00:22:13,850 --> 00:22:15,890
so finished

303
00:22:15,910 --> 00:22:20,370
so in summary then l one regularisation variance has become a powerful tool with with

304
00:22:20,390 --> 00:22:22,320
the advent of wide data

305
00:22:22,320 --> 00:22:26,540
infinitely down to try and make it work but never works

306
00:22:26,540 --> 00:22:30,670
but if you do the outer apply this and you find that when using in

307
00:22:30,670 --> 00:22:31,840
zero one

308
00:22:31,860 --> 00:22:35,310
then you get this nice function here

309
00:22:35,360 --> 00:22:40,500
so does anyone recognise this function here

310
00:22:40,560 --> 00:22:50,840
someone said entropy

311
00:22:50,900 --> 00:22:55,710
and that is entropy that's entropy for bernoulli random variables

312
00:22:55,840 --> 00:22:59,000
it's actually negative entropy to be to be exact

313
00:22:59,340 --> 00:23:03,880
so it could be a general relation will see this what happens is entropy comes

314
00:23:03,880 --> 00:23:05,270
out here

315
00:23:05,290 --> 00:23:09,500
and in some other cases you get plus infinity

316
00:23:09,630 --> 00:23:14,020
there's another thing you should think about this is going to be relevant later

317
00:23:14,480 --> 00:23:24,880
if you think about mu belonging to zero one

318
00:23:24,900 --> 00:23:30,880
right that's exactly the sort of set of possible probabilities that a coin flip can

319
00:23:32,150 --> 00:23:37,190
the probability that the coin is heads can be anywhere between zero and one

320
00:23:37,250 --> 00:23:39,630
but it can't be outside that interval

321
00:23:39,650 --> 00:23:44,880
and that's not a coincidence the fact that this guy is is nicely behaved where

322
00:23:44,880 --> 00:23:49,540
the coin flipping makes sense that mu is between zero and one it makes sense

323
00:23:49,540 --> 00:23:53,110
and the fact that plus infinity if the coin flip doesn't make sense

324
00:23:53,210 --> 00:23:57,360
that's not a coincidence that's going to come up with a bit more generally later

325
00:23:57,690 --> 00:24:03,380
OK so any questions about

326
00:24:03,440 --> 00:24:08,170
this basic concept is to duality as we discussed analytically here

327
00:24:08,210 --> 00:24:10,020
and we looked at it geometrically

328
00:24:10,040 --> 00:24:14,940
and now we've just on this particular example to a simple example would actually captures

329
00:24:15,000 --> 00:24:19,170
a lot of the intuition of the general case

330
00:24:19,190 --> 00:24:22,460
sure you all how

331
00:24:22,480 --> 00:24:27,520
and yes

332
00:24:27,540 --> 00:24:32,360
how do i feel all

333
00:24:32,380 --> 00:24:37,360
right so i didn't say that i said that that is always convex

334
00:24:37,420 --> 00:24:39,770
with no restrictions on that

335
00:24:39,790 --> 00:24:42,610
but when f is well behaved

336
00:24:42,630 --> 00:24:46,650
and well behaved means convex and lower semi continuous

337
00:24:47,520 --> 00:24:50,750
you're correct if i start with the non convex function

338
00:24:50,840 --> 00:24:52,150
i can't somehow

339
00:24:52,170 --> 00:24:55,820
take the dual twice and get a convex function back that's the that's the same

340
00:24:56,630 --> 00:24:57,790
so it's sort of key

341
00:24:57,790 --> 00:25:02,400
we're going to be applying this always one f is convex to start with

342
00:25:02,420 --> 00:25:08,690
this is just a somewhat technical condition that they're interesting behave well the boundary we

343
00:25:08,690 --> 00:25:17,980
won't worry about that here but that's a good question

344
00:25:18,020 --> 00:25:22,360
any other questions

345
00:25:28,400 --> 00:25:29,630
OK so

346
00:25:30,080 --> 00:25:36,270
so this example we did

347
00:25:36,320 --> 00:25:39,560
actually illustrates a lot of the general principles

348
00:25:39,590 --> 00:25:41,170
the more general of

349
00:25:41,790 --> 00:25:45,000
for the general case exponential families

350
00:25:45,060 --> 00:25:49,560
so let's go about doing this a bit more generally let's imagine that we have

351
00:25:49,560 --> 00:25:51,380
an exponential family

352
00:25:51,380 --> 00:25:54,670
and we're going to compute the dual of

353
00:25:56,080 --> 00:25:58,670
cumulant generating function here

354
00:25:58,710 --> 00:26:03,250
so this i already did a special case here i did the simple newly

355
00:26:03,270 --> 00:26:06,460
and i did the cumulant generating function not going to do it for

356
00:26:06,480 --> 00:26:08,440
any exponential family

357
00:26:08,440 --> 00:26:12,150
but the principles are going to be the same if you understand the case what

358
00:26:12,150 --> 00:26:16,110
i'm doing is destroying it with more abstract notation

359
00:26:16,130 --> 00:26:21,790
so i definition tells us to go off and solve this optimisation problem

360
00:26:21,810 --> 00:26:25,520
and we follow the same steps we take derivatives

361
00:26:26,080 --> 00:26:29,080
in order to try and find stationary point we get new

362
00:26:29,080 --> 00:26:32,970
and the derivative of this guy should be equal to zero this is a sort

363
00:26:32,970 --> 00:26:35,630
of key equation

364
00:26:35,650 --> 00:26:38,540
OK so

365
00:26:38,590 --> 00:26:41,130
he is a very useful fact

366
00:26:41,150 --> 00:26:47,860
the fact is that the function a it's actually what's known as the cumulant generating

367
00:26:48,960 --> 00:26:55,020
how many people have heard about moment generating functions and cumulant generating functions

368
00:26:55,040 --> 00:26:56,900
OK so very few

369
00:26:57,020 --> 00:27:01,710
how many people have heard of cumulants

370
00:27:01,810 --> 00:27:05,670
again roughly the same number that called not heard of cumulants

371
00:27:06,460 --> 00:27:08,190
OK so you understand

372
00:27:08,210 --> 00:27:11,320
how many people moment

373
00:27:11,360 --> 00:27:18,500
you all know moments are OK so humans are various combinations of moments

374
00:27:18,520 --> 00:27:23,210
well go into details now but there are just two different sets of combinations of

375
00:27:24,150 --> 00:27:26,310
and they have nice properties

376
00:27:26,310 --> 00:27:27,900
for certain functions

377
00:27:27,920 --> 00:27:31,520
what's important here is that this guy all we need to know is when you

378
00:27:31,520 --> 00:27:33,710
take one derivative of it

379
00:27:33,730 --> 00:27:39,710
what happens is is that you get what are known as mean parameters

380
00:27:39,710 --> 00:27:42,940
and what these mean parameters are remember this guy

381
00:27:43,790 --> 00:27:47,420
specified in terms of the sufficient statistics

382
00:27:47,440 --> 00:27:50,310
so the main parameters are the expectations

383
00:27:50,320 --> 00:27:55,540
of the sufficient statistic with respect to the distribution

384
00:27:55,560 --> 00:27:59,020
so these are very important things like let me just jump back to our earlier

385
00:28:00,360 --> 00:28:04,480
so we can see what what it means in this special case with bernoulli

386
00:28:04,710 --> 00:28:24,810
just describe this the bernoulli case here because

387
00:28:24,840 --> 00:28:27,230
so it's good concrete example to keep your

388
00:28:27,250 --> 00:28:33,270
keep your mind on a special case we can think about is this for newly

389
00:28:33,460 --> 00:28:43,130
and we saw that it's just the coin flipping random variable

390
00:28:43,940 --> 00:28:46,980
x here was just zero and one

391
00:28:47,000 --> 00:28:55,360
and we saw that this was the log normalisation constant had this form

392
00:29:01,380 --> 00:29:03,960
and what we computed before

393
00:29:04,150 --> 00:29:07,060
is we compute the gradient of this function

394
00:29:07,090 --> 00:29:08,520
it was equal to this

395
00:29:08,540 --> 00:29:13,460
even today over one policy to the data

396
00:29:13,520 --> 00:29:18,460
but all i'm saying now is the following that

397
00:29:47,590 --> 00:29:51,730
the only new thing i've said there is that in fact that derivative of the

398
00:29:51,730 --> 00:29:57,290
until another critical voltage and falls again another tube going even brighter and this is

399
00:29:57,290 --> 00:29:59,420
6 . 7 volts

400
00:29:59,680 --> 00:30:03,570
I just for your information you look on the periodic table today and it turns

401
00:30:03,570 --> 00:30:11,310
out that the ionisation voltage for mercury is about 10 . 4 10 . 4

402
00:30:11,310 --> 00:30:16,050
is the ionisation energy so this is below the ionization energy

403
00:30:16,070 --> 00:30:21,210
so what's going on here what they reason was that

404
00:30:21,230 --> 00:30:27,420
they were exciting bound electrons with this mercury and furthermore

405
00:30:27,460 --> 00:30:37,660
that there are critical voltages associated with critical energies conclusions there are quantized energy levels

406
00:30:37,660 --> 00:30:44,700
within mercury which is to say that the war postulate of quantization applies not only

407
00:30:45,420 --> 00:30:50,620
a 1 electron atom but it applies to multi electron atoms would have applies to

408
00:30:50,620 --> 00:30:58,050
multi electron atoms does not mean applies to everything so they concluded from this experiment

409
00:30:58,100 --> 00:31:12,620
quantization quantization of energy so quantization of energies of electrons in multi electron atoms

410
00:31:12,700 --> 00:31:13,830
thank you

411
00:31:14,050 --> 00:31:20,650
or model doesn't apply to multi electron atoms but the assumption that energy is quantizing

412
00:31:20,650 --> 00:31:23,140
multielectron atoms is

413
00:31:23,330 --> 00:31:28,880
the assumption of energy quantization extends to multi electron atoms so this is really really

414
00:31:28,880 --> 00:31:34,360
good war was writing very very high but all the things come to an end

415
00:31:34,600 --> 00:31:39,750
there are problems with the boar model to so now let's look at limitations wanna

416
00:31:39,760 --> 00:31:49,960
look at limitations of the boar model limitations of more OK 1st of all there's

417
00:31:49,960 --> 00:32:03,920
data out there there's data out there already 1st 1887 1887 Michaelson morally Michaelson morally

418
00:32:04,070 --> 00:32:07,350
This work was distinguished by the fact that was done in the United States you

419
00:32:07,350 --> 00:32:11,440
notice most of everything I've shown you up until now was done in Europe with

420
00:32:11,440 --> 00:32:18,140
1 exception the Milliken experiment in Chicago everything else is European science but Michael had

421
00:32:18,140 --> 00:32:23,270
immigrated to the United States and it was really really clever use a brilliant inventor

422
00:32:23,770 --> 00:32:29,490
was doing military research for the Navy's back in the early 18 eighties he invented

423
00:32:29,490 --> 00:32:34,750
the interferometry and he was the 1st to make accurate measurements of the speed of

424
00:32:34,750 --> 00:32:41,120
light Michaelson interferometry and he was I hear eventually worked at the case School of

425
00:32:41,120 --> 00:32:49,210
Applied Science in Cleveland which ultimately became Case Western Reserve University after a number of

426
00:32:49,250 --> 00:32:53,920
transitions and he was working at case in Cleveland and

427
00:32:54,010 --> 00:32:56,460
doing very very high and

428
00:32:56,460 --> 00:33:03,290
Precision spectroscopy that was his 48 he was a brilliant experimentalists knew how to make

429
00:33:03,360 --> 00:33:10,570
equipment that was highly accurate and what he found was that 1 of Armstrong's lines

430
00:33:10,810 --> 00:33:15,650
the line the line associated with the transition 3 2

431
00:33:16,310 --> 00:33:18,640
if you look really really carefully

432
00:33:20,320 --> 00:33:26,380
angstrom made the measurements by looking at like hitting a photographic plate and that like

433
00:33:26,400 --> 00:33:30,440
doesn't come down license shop there's a little bit of of

434
00:33:30,490 --> 00:33:32,790
scattering the data so you get this

435
00:33:33,040 --> 00:33:39,750
fact line but the positions of center-to-center underlines follow that set of 4

436
00:33:39,810 --> 00:33:44,990
the numbers that we were looking at yesterday now and Michaelson did the work member

437
00:33:44,990 --> 00:33:51,230
on stranded is experiments in 1853 Michaelson looks very very carefully and sees that it's

438
00:33:51,230 --> 00:33:56,100
not 1 line but it's 2 lines to lines very close together

439
00:33:56,180 --> 00:34:00,790
so the 3 2 line is in fact Dublin

440
00:34:01,100 --> 00:34:07,470
it's a double that is to say 2 lines very very close together but from

441
00:34:07,470 --> 00:34:12,800
a distance it looks like a line and then if you got really accurate instrumentation

442
00:34:12,820 --> 00:34:14,790
discover that it's a double

443
00:34:15,080 --> 00:34:20,550
that's a problem that's a problem because if you look at this term scheme here

444
00:34:21,430 --> 00:34:26,240
if we got a Dublin it means that you got to different transitions so the

445
00:34:26,450 --> 00:34:29,920
model was a goal from n equals 2 up to n equals 3 when you

446
00:34:29,920 --> 00:34:33,620
fall from 3 back down to 2 you give off a photon and that photon

447
00:34:33,630 --> 00:34:38,780
has a unique value of wavelength but they're measuring to but they're very close so

448
00:34:38,780 --> 00:34:44,060
what that suggests is that maybe there are 2 levels they're really really close together

449
00:34:44,200 --> 00:34:48,740
and sometimes the electron falls from the higher level and sometimes it falls from the

450
00:34:48,740 --> 00:34:52,940
lower level but in any event there must be more than 1 level but very

451
00:34:52,940 --> 00:34:58,340
close together sober is silent on the now the other possibility is that you know

452
00:34:58,340 --> 00:35:03,340
to is the problem we don't know maybe there maybe there maybe this is got

453
00:35:03,340 --> 00:35:05,280
to lies and this has what

454
00:35:05,290 --> 00:35:11,010
so that's the point 1st of all by the way I'm Michaelson was awarded the

455
00:35:11,010 --> 00:35:13,300
don't know

456
00:35:13,310 --> 00:35:18,250
all right

457
00:35:21,000 --> 00:35:22,910
you know

458
00:35:30,710 --> 00:35:34,490
know it

459
00:36:00,280 --> 00:36:01,680
at the time

460
00:36:04,530 --> 00:36:09,790
nine thousand five

461
00:36:09,810 --> 00:36:15,500
all aspects

462
00:36:15,510 --> 00:36:19,370
for example

463
00:36:19,390 --> 00:36:28,770
all right

464
00:36:28,780 --> 00:36:35,150
the consequences of this

465
00:36:35,160 --> 00:36:40,080
well the

466
00:36:46,540 --> 00:36:48,560
on the other

467
00:36:48,580 --> 00:36:50,410
this is

468
00:37:04,030 --> 00:37:09,620
consequently the soccer ball the company

469
00:37:09,640 --> 00:37:14,930
some of these are

470
00:37:22,750 --> 00:37:25,280
because of the way

471
00:37:25,300 --> 00:37:27,020
o who

472
00:37:32,180 --> 00:37:36,690
if you are you

473
00:37:36,700 --> 00:37:40,000
those who is the level world

474
00:37:40,010 --> 00:37:44,030
the problem

475
00:37:44,040 --> 00:37:46,570
the problem

476
00:37:58,830 --> 00:37:59,930
what we

477
00:38:00,010 --> 00:38:03,160
tomorrow the world

478
00:38:03,180 --> 00:38:05,510
one of the problem

479
00:38:08,720 --> 00:38:10,310
we have

480
00:38:11,450 --> 00:38:13,560
the match

481
00:38:14,120 --> 00:38:18,730
we're actually what are four

482
00:38:18,770 --> 00:38:20,540
the knowledge that

483
00:38:20,620 --> 00:38:25,740
our use of the the underlying yes one

484
00:38:26,500 --> 00:38:28,560
everything except one

485
00:38:31,790 --> 00:38:34,110
the world

486
00:38:40,680 --> 00:38:43,120
we don't always

487
00:38:44,230 --> 00:38:48,810
what is otherwise be resolved information

488
00:38:48,820 --> 00:38:51,780
is not very

489
00:38:51,990 --> 00:38:53,860
we are

490
00:38:53,870 --> 00:38:59,610
and that verification

491
00:39:05,310 --> 00:39:06,530
so we

492
00:39:06,550 --> 00:39:09,340
one of them

493
00:39:12,100 --> 00:39:14,720
o four one

494
00:39:14,740 --> 00:39:16,180
one of them

495
00:39:18,640 --> 00:39:22,220
but what

496
00:39:29,850 --> 00:39:37,100
what i will say well the question was

497
00:39:39,620 --> 00:39:43,690
i like

498
00:39:45,430 --> 00:39:52,200
the you what to do or what or

499
00:39:52,310 --> 00:39:58,890
there are three major

500
00:39:58,910 --> 00:40:03,620
one is come on

501
00:40:04,050 --> 00:40:07,260
transfer database

502
00:40:10,720 --> 00:40:16,960
that is pretty fine

503
00:40:28,810 --> 00:40:31,150
want to be able to

504
00:40:31,200 --> 00:40:33,050
also known as

505
00:40:34,960 --> 00:40:37,430
is something

506
00:40:37,440 --> 00:40:40,570
the rest was really

507
00:40:48,610 --> 00:40:51,170
u example

508
00:40:54,300 --> 00:40:58,210
for example

509
00:40:58,250 --> 00:41:01,230
you might ask

510
00:41:01,260 --> 00:41:05,710
written like

511
00:41:05,890 --> 00:41:07,730
in the beginning

512
00:41:07,740 --> 00:41:10,620
for a long

513
00:41:16,290 --> 00:41:19,040
if you like

514
00:41:19,060 --> 00:41:20,820
the loss

515
00:41:22,490 --> 00:41:23,480
what was

516
00:41:23,500 --> 00:41:25,310
like like

517
00:41:25,360 --> 00:41:27,800
all right

518
00:41:29,860 --> 00:41:34,040
four to be able to around

519
00:41:34,240 --> 00:41:36,420
if you ask what is the

520
00:41:41,570 --> 00:41:45,290
number three

521
00:41:49,540 --> 00:41:51,470
what want

522
00:41:51,490 --> 00:41:56,470
or low-balled

523
00:41:58,180 --> 00:41:59,110
if you are

524
00:42:00,380 --> 00:42:02,660
there is something one can

525
00:42:02,680 --> 00:42:08,420
the characteristics of war

526
00:42:08,440 --> 00:42:12,610
we don't know that

527
00:42:12,650 --> 00:42:17,140
the you know about it

528
00:42:17,150 --> 00:42:21,460
you might might be able to learn

529
00:42:21,530 --> 00:42:25,040
the number of players in the last five years

530
00:42:25,060 --> 00:42:27,820
the first was

531
00:42:34,230 --> 00:42:35,540
she was born

532
00:42:35,770 --> 00:42:37,350
four were

533
00:42:41,710 --> 00:42:46,140
born on player

534
00:42:46,150 --> 00:42:48,610
well one

535
00:42:49,850 --> 00:42:53,900
they don't want to be able to do something like the one

536
00:42:53,920 --> 00:42:57,280
were four

537
00:42:57,280 --> 00:43:04,780
because of its peculiar geometry

538
00:43:04,880 --> 00:43:07,320
only one explanation

539
00:43:07,380 --> 00:43:08,700
so to cyc recall

540
00:43:08,760 --> 00:43:10,820
if you haven't found one

541
00:43:10,860 --> 00:43:13,970
yourself here

542
00:43:14,010 --> 00:43:15,860
let me first

543
00:43:15,930 --> 00:43:18,160
come to is simple conclusion

544
00:43:18,180 --> 00:43:21,740
and all of you must have come to that conclusion

545
00:43:21,760 --> 00:43:25,090
that top when i showed it to you during my exam review

546
00:43:25,180 --> 00:43:28,030
was spending for more than an hour

547
00:43:28,070 --> 00:43:31,240
in fact it was spending the next day

548
00:43:31,260 --> 00:43:33,780
energy has to come from somewhere

549
00:43:33,830 --> 00:43:37,030
and so the only conclusion that you could have drawn that the energy came from

550
00:43:37,030 --> 00:43:38,380
inside the box

551
00:43:38,430 --> 00:43:42,550
there must be something inside the box clearly there must be a battery in that

552
00:43:43,510 --> 00:43:45,140
and there is

553
00:43:45,220 --> 00:43:47,320
it doesn't tell you how it works here

554
00:43:47,340 --> 00:43:50,910
and i can assure you i can admit that it took me quite a while

555
00:43:50,950 --> 00:43:52,680
before i fully understand

556
00:43:52,740 --> 00:43:54,160
how it works

557
00:43:54,200 --> 00:43:56,220
and i want to explain that to you

558
00:43:56,240 --> 00:43:59,820
and then i will demonstrate it to you again

559
00:44:01,340 --> 00:44:04,070
what it looks like

560
00:44:04,130 --> 00:44:08,380
in the top itself

561
00:44:08,450 --> 00:44:11,260
is a magnet

562
00:44:11,280 --> 00:44:14,050
he was the top

563
00:44:14,640 --> 00:44:16,470
north and south

564
00:44:16,490 --> 00:44:20,240
and this is that pop

565
00:44:20,300 --> 00:44:22,630
we rotating it was spending

566
00:44:22,630 --> 00:44:24,140
inside the box

567
00:44:24,160 --> 00:44:26,430
right at the centre of the box

568
00:44:26,470 --> 00:44:31,990
is the solenoid

569
00:44:33,570 --> 00:44:36,130
nine volt battery

570
00:44:36,180 --> 00:44:39,700
inside the solenoid is also a little bit of irony

571
00:44:39,720 --> 00:44:40,570
we have not

572
00:44:40,570 --> 00:44:44,070
discuss that in our course it's not important forty explanation

573
00:44:44,110 --> 00:44:46,280
related understand why there is also

574
00:44:46,300 --> 00:44:51,180
so my review makes the magnetic field build from

575
00:44:51,220 --> 00:44:56,090
this is right at the centre of the

576
00:44:56,140 --> 00:44:58,970
of the little platform on which i was running this

577
00:44:59,320 --> 00:45:01,590
concave platform

578
00:45:01,680 --> 00:45:02,780
here is a little

579
00:45:02,800 --> 00:45:04,680
best ignored so when the

580
00:45:04,720 --> 00:45:06,240
but that's it

581
00:45:06,300 --> 00:45:09,720
bonds is all

582
00:45:09,780 --> 00:45:12,910
imagine for now that is rotating in such a way

583
00:45:12,930 --> 00:45:14,260
at the north pole

584
00:45:14,300 --> 00:45:16,070
is approaching

585
00:45:16,110 --> 00:45:20,760
that's all i coming in from above

586
00:45:20,780 --> 00:45:22,590
what's going to happen now

587
00:45:22,640 --> 00:45:23,660
in this

588
00:45:23,660 --> 00:45:26,280
so know it in this court

589
00:45:26,360 --> 00:45:29,860
you're changing the magnetic flux through the surface of this course

590
00:45:29,880 --> 00:45:30,880
and so

591
00:45:30,880 --> 00:45:32,530
you're introducing

592
00:45:32,530 --> 00:45:34,240
induced EMF

593
00:45:34,280 --> 00:45:37,090
an induced currents

594
00:45:37,140 --> 00:45:39,070
and this current

595
00:45:39,070 --> 00:45:43,010
is sense by transistor which i have not reported here

596
00:45:43,030 --> 00:45:44,320
and the transistor

597
00:45:44,340 --> 00:45:45,900
throw the switch

598
00:45:45,930 --> 00:45:46,570
and now

599
00:45:46,570 --> 00:45:48,450
folks energy out of the battery

600
00:45:48,510 --> 00:45:51,950
and runs current very high current through this

601
00:45:52,860 --> 00:45:54,570
such that the top

602
00:45:55,530 --> 00:45:57,010
the south pole

603
00:45:57,070 --> 00:46:00,910
remember if you have a cordial

604
00:46:01,010 --> 00:46:03,220
you're on current through here

605
00:46:03,400 --> 00:46:05,030
you get the magnetic field

606
00:46:05,030 --> 00:46:06,510
like so

607
00:46:06,530 --> 00:46:08,800
in this case is the north pole

608
00:46:08,860 --> 00:46:11,360
this because if you reverse the current

609
00:46:11,400 --> 00:46:14,640
this is cells and this is more

610
00:46:14,680 --> 00:46:17,320
the magnetic field that comes out there

611
00:46:17,400 --> 00:46:20,430
is fanning out in all the erection three-dimensional

612
00:46:20,430 --> 00:46:21,720
it's going like this

613
00:46:21,740 --> 00:46:23,880
fanning out like this

614
00:46:23,990 --> 00:46:25,720
so when it approaches

615
00:46:27,010 --> 00:46:29,090
coral there is the change in

616
00:46:29,180 --> 00:46:32,510
magnetic flux and this becomes itself

617
00:46:32,570 --> 00:46:34,740
the north pole is being attracted

618
00:46:34,780 --> 00:46:39,200
by the south pole and make you look at this from above now

619
00:46:40,470 --> 00:46:43,550
the top scene from above spending in this direction

620
00:46:45,660 --> 00:46:50,410
and that's a year is this coral

621
00:46:50,430 --> 00:46:51,910
this is the north pole

622
00:46:52,010 --> 00:46:53,880
this is the south pole

623
00:46:53,930 --> 00:46:55,930
and i just discussed issue

624
00:46:55,990 --> 00:46:58,220
the current is going to flow

625
00:46:58,240 --> 00:46:59,820
from the battery

626
00:46:59,880 --> 00:47:02,930
will make this is south of the current can only flow

627
00:47:02,970 --> 00:47:07,160
in that call in one direction and that's just the way to design

628
00:47:07,180 --> 00:47:10,910
one of the current goes it's always this becomes the south pole

629
00:47:11,030 --> 00:47:14,110
the north pole is being attracted by the south pole

630
00:47:14,240 --> 00:47:18,280
notice is going to be talked up

631
00:47:18,280 --> 00:47:19,160
so far

632
00:47:19,180 --> 00:47:21,340
so good

633
00:47:21,360 --> 00:47:23,680
later in time

634
00:47:23,680 --> 00:47:25,900
looking from above

635
00:47:25,900 --> 00:47:27,930
the north pole of the year

636
00:47:27,970 --> 00:47:32,860
and the south pole will be there is rotated a little bit further

637
00:47:32,900 --> 00:47:34,950
and the

638
00:47:34,970 --> 00:47:38,090
coral is here

639
00:47:38,160 --> 00:47:40,010
now on the north pole is

640
00:47:40,010 --> 00:47:40,720
o thing

641
00:47:40,780 --> 00:47:46,160
it's receiving it's not approaching its receiving

642
00:47:46,220 --> 00:47:49,450
this work remain the south pole

643
00:47:49,510 --> 00:47:52,820
it would be disastrous because i was born in north pole that attracted to don't

644
00:47:52,820 --> 00:47:54,510
want that

645
00:47:56,880 --> 00:47:58,590
the transistor senses

646
00:47:58,590 --> 00:47:59,800
the EMF

647
00:47:59,820 --> 00:48:01,070
in the corals

648
00:48:01,110 --> 00:48:04,050
it reverses direction it has to reverse direction

649
00:48:04,860 --> 00:48:08,320
if the north pole comes then you may have is in one direction but when

650
00:48:08,320 --> 00:48:12,430
the north pole of the EMF course goes into action

651
00:48:12,470 --> 00:48:13,660
kind of reverse

652
00:48:13,680 --> 00:48:17,110
so the transistor that it opens the switch

653
00:48:17,240 --> 00:48:21,260
so there is no north pole here and there is no cycles

654
00:48:21,320 --> 00:48:23,110
so thing starts to

655
00:48:23,130 --> 00:48:26,610
go around further

656
00:48:26,660 --> 00:48:28,640
what happens now in the south pole

657
00:48:32,510 --> 00:48:35,070
OK here is the situation

658
00:48:35,180 --> 00:48:37,050
at the south pole

659
00:48:37,070 --> 00:48:38,470
is now approaching

660
00:48:38,470 --> 00:48:40,020
OK so

661
00:48:40,030 --> 00:48:41,910
can you hear me

662
00:48:41,930 --> 00:48:45,830
OK so it's not exactly by compressed sensing this

663
00:48:45,900 --> 00:48:50,260
lectures is more about an one minimisation and compressed sensing part of this

664
00:48:50,270 --> 00:48:52,250
a much bigger story

665
00:48:52,260 --> 00:48:57,110
so i'm going to try to give you an overview of an one minimisation

666
00:48:57,110 --> 00:49:03,110
and its connections of course with compressed sensing and and sparse signal recovery in statistics

667
00:49:03,130 --> 00:49:05,130
and so

668
00:49:05,130 --> 00:49:09,470
before i begin i just want to start with very simple things just to show

669
00:49:10,570 --> 00:49:15,440
that the l one norm is very different from the two norm and so

670
00:49:15,450 --> 00:49:21,060
in many problems that we have to deal with in an applied science we wish

671
00:49:21,060 --> 00:49:22,880
to solve x equals b

672
00:49:22,890 --> 00:49:28,940
approximately so in many problems of course we have made a data matrix a which

673
00:49:28,940 --> 00:49:30,200
is an by an

674
00:49:30,240 --> 00:49:34,120
we can assume for example that we have more observations and variables so that we

675
00:49:34,120 --> 00:49:38,880
have more columns and rows in this picture so that the system is what we

676
00:49:38,880 --> 00:49:40,990
call overdetermined

677
00:49:41,000 --> 00:49:45,750
and so on and so x equals b of course traditionally there's no solution there's

678
00:49:45,750 --> 00:49:50,030
no solution except that x equals b because it's overdetermined

679
00:49:50,050 --> 00:49:53,910
and so the way we approach this is by no minimisation and so of course

680
00:49:53,910 --> 00:49:57,690
everybody is familiar with least squares and the squares we're going to try to fit

681
00:49:57,690 --> 00:49:58,810
this kind of

682
00:49:58,920 --> 00:50:05,610
model with is by finding that x that minimizes such that minimizes the distance to

683
00:50:05,610 --> 00:50:07,140
be in l two sense

684
00:50:07,160 --> 00:50:12,000
and i'm sure as you are and when you learn in regression least squares puts

685
00:50:12,000 --> 00:50:13,970
a large weights on this

686
00:50:14,000 --> 00:50:19,110
on on a very small weight on small residual says whenever b-minus axis small

687
00:50:19,140 --> 00:50:20,660
you pay a very small way

688
00:50:20,670 --> 00:50:24,810
and when the miners x is large up a very large

689
00:50:24,830 --> 00:50:29,880
and i'm sure you've taken introductory classes in in in your question

690
00:50:29,890 --> 00:50:34,270
which you know that the least squares line for example is very sensitive to outliers

691
00:50:34,330 --> 00:50:38,330
because you you really do not want to see large residual

692
00:50:38,350 --> 00:50:40,390
so the first idea to fit

693
00:50:40,410 --> 00:50:45,560
data is to just minimize the least squares to solve the discrete problems and minimize

694
00:50:45,560 --> 00:50:49,430
the distance between b and x in l two

695
00:50:49,480 --> 00:50:55,370
something that happens actually is more natural would be to actually not minimize the sum

696
00:50:55,370 --> 00:50:58,000
of squared residuals but rather the some

697
00:50:58,030 --> 00:51:00,560
of the absolute values of the residual

698
00:51:00,590 --> 00:51:04,130
and that would be minimizing the l one norm i assume that everybody is familiar

699
00:51:04,130 --> 00:51:07,260
with the l one norm that is very important that you are

700
00:51:07,280 --> 00:51:10,290
if not i will write it on the board so are the people who don't

701
00:51:10,290 --> 00:51:14,250
know what is the one norm

702
00:51:14,280 --> 00:51:17,730
everybody knows OK so you may want to minimize the

703
00:51:17,750 --> 00:51:20,900
distance between b and the one sense now

704
00:51:20,910 --> 00:51:25,570
so now you would want to minimize the sum of absolute values of the residual

705
00:51:25,590 --> 00:51:30,470
and so this puts a much larger weight on small residuals and less weight on

706
00:51:30,470 --> 00:51:34,690
the on larger residuals because now they are not squared anymore

707
00:51:34,690 --> 00:51:37,810
OK so we have two proposals and it's

708
00:51:37,840 --> 00:51:40,370
i'm using to note that historically

709
00:51:40,380 --> 00:51:44,810
galson that class had long discussions about whether you should use l two and one

710
00:51:44,810 --> 00:51:48,210
and since the nineteenth century at least gulls prevail

711
00:51:48,220 --> 00:51:52,750
but what i want to show you in that they can read lead to very

712
00:51:52,750 --> 00:51:58,560
different solutions qualitatively so here i'm going to make a random problems were enemies

713
00:51:58,560 --> 00:52:02,380
five hundred so i have five hundred measurements and is one fifty some trying to

714
00:52:02,380 --> 00:52:07,380
fit a hundred and fifty dimensional parameters and i'm going to make a random problem

715
00:52:07,690 --> 00:52:10,220
and whether x minimizes scores

716
00:52:10,320 --> 00:52:11,680
l two

717
00:52:11,880 --> 00:52:15,210
the residual sum of squares of just the sum of the absolute values of the

718
00:52:15,210 --> 00:52:18,760
residual i get very different results

719
00:52:18,780 --> 00:52:21,250
so here's what i get if i minimize e

720
00:52:21,250 --> 00:52:24,780
l two norm and here is what i get if i minimise the one norm

721
00:52:24,780 --> 00:52:28,690
and you can see that it's not a question of whether we prefer l one

722
00:52:28,690 --> 00:52:34,210
l two four physical philosophical reason it's just like the lead to very different answers

723
00:52:34,500 --> 00:52:39,600
one particular aspect of the l one norm it that you see an enormous spike

724
00:52:39,690 --> 00:52:40,780
had zero

725
00:52:40,780 --> 00:52:46,590
which means that a lot of the residuals actually exactly zero

726
00:52:47,570 --> 00:52:49,530
and so this is kind of

727
00:52:49,530 --> 00:52:51,570
going back to thing that

728
00:52:51,590 --> 00:52:53,310
the l one norm puts

729
00:52:53,310 --> 00:52:57,930
a much very large weight on small residual is so large that it forces us

730
00:52:57,960 --> 00:53:00,540
a lot of residuals to be actually

731
00:53:00,570 --> 00:53:04,830
and you can prove it is not difficult that if you minimize your one

732
00:53:04,850 --> 00:53:09,830
a lot of the residuals will actually be exactly

733
00:53:09,840 --> 00:53:15,090
OK so but for the moment i want to is that we observe very different

734
00:53:15,110 --> 00:53:17,300
and so

735
00:53:17,450 --> 00:53:20,800
and they are both valid down on

736
00:53:20,830 --> 00:53:26,220
philosophical ground and not sure why we should minimize l two norm another one or

737
00:53:26,320 --> 00:53:28,780
perhaps because we have linear algebra

738
00:53:28,800 --> 00:53:30,280
but other than that

739
00:53:32,350 --> 00:53:38,510
here's another set another problem which we're going to be extremely concerned about in these

740
00:53:38,520 --> 00:53:42,400
lectures which is it's a slightly different problems in the sense that now is the

741
00:53:42,410 --> 00:53:47,890
system of linear equations is underdetermined so i wish to solve a x equals b

742
00:53:47,930 --> 00:53:52,240
but now it has fewer rows and columns so there are many solutions in general

743
00:53:52,240 --> 00:53:53,610
to the system

744
00:53:53,640 --> 00:53:55,590
so i need to solve x equals b

745
00:53:55,590 --> 00:54:00,390
but now i have fewer rows and columns of the matrix is is that

746
00:54:00,400 --> 00:54:02,780
and so i have many solutions

747
00:54:02,820 --> 00:54:07,530
and so we can discuss well if there's many solution we need to we're going

748
00:54:07,530 --> 00:54:11,820
to need to pick one and so if you open the literature of people would

749
00:54:12,470 --> 00:54:16,590
for example in the literature on inverse problems or even in statistics one with the

750
00:54:16,590 --> 00:54:21,680
ridge regression and that we should pick the solution that has minimum to no minimum

751
00:54:22,700 --> 00:54:24,070
so among all this

752
00:54:24,080 --> 00:54:26,660
candidates x feelings the data be

753
00:54:26,700 --> 00:54:31,090
the proposal would be to find that was minimum l two energy

754
00:54:31,100 --> 00:54:37,350
another related proposal would be a very similar it says OK models this solution

755
00:54:38,930 --> 00:54:41,330
satisfying aka x equals b

756
00:54:41,350 --> 00:54:44,170
pick the one with minimum l one norm instead

757
00:54:44,200 --> 00:54:45,460
right so this would say

758
00:54:45,470 --> 00:54:49,350
minimize energy and this would say minimize it one norm

759
00:54:49,390 --> 00:54:52,680
and again if we do this on the random problems

760
00:54:52,710 --> 00:54:53,860
we get

761
00:54:53,890 --> 00:55:00,620
very very different pictures so here is an underdetermined system of equations would have

762
00:55:00,950 --> 00:55:05,390
two hundred fifty equations but an unknown vector of dimension one hundred i want to

763
00:55:05,390 --> 00:55:09,600
make a random problems and when i look at the minimum energy solution and look

764
00:55:09,600 --> 00:55:12,020
and how did i draw these well

765
00:55:12,070 --> 00:55:16,600
guassian process is actually an infinite you know to prior on this infinite dimensional space

766
00:55:16,600 --> 00:55:20,570
right but i just discretize this

767
00:55:20,620 --> 00:55:22,980
between minus two into

768
00:55:23,000 --> 00:55:24,060
i drew

769
00:55:24,070 --> 00:55:30,670
but discretized into hundred bins and i drew one sample from hundred dimensional gaussians

770
00:55:30,670 --> 00:55:33,220
which has one a hundred by hundred covariance matrix

771
00:55:33,270 --> 00:55:37,550
this is one sample from a hundred dimensional guessing there's another sample another sample per

772
00:55:42,500 --> 00:55:46,300
it's the vector is one hundred dimensional vector and i just want the elements of

773
00:55:46,300 --> 00:55:50,060
the a hundred dimensional vector instead of labeling my

774
00:55:50,070 --> 00:55:54,130
access to go from one two hundred and labeling my access to go from minus

775
00:55:54,740 --> 00:55:55,800
the two

776
00:55:59,430 --> 00:56:09,570
guassian process should not be harder to understand than multivariate calcium distribution

777
00:56:09,640 --> 00:56:13,020
it's infinity in that

778
00:56:13,040 --> 00:56:15,430
a it's a process

779
00:56:15,780 --> 00:56:18,550
which means that

780
00:56:18,610 --> 00:56:20,250
the it's

781
00:56:20,280 --> 00:56:21,840
it's implicitly

782
00:56:21,840 --> 00:56:26,220
it's sort of the limit of the gas in distribution as you take the dimensionality

783
00:56:26,220 --> 00:56:28,710
to infinity if you now

784
00:56:29,190 --> 00:56:35,000
sample in any finite number of points you get a multivariate gaussians

785
00:56:35,090 --> 00:56:38,950
OK but i could have drawn the same thing

786
00:56:40,690 --> 00:56:41,710
you know

787
00:56:41,810 --> 00:56:44,160
grid that you know

788
00:56:44,200 --> 00:56:46,850
discretizing this with a million

789
00:56:48,170 --> 00:56:52,970
little steps right in with the look the same so imagine trying this discretizing with

790
00:56:52,980 --> 00:56:56,220
a million with a billion and so on in the limit where you get is

791
00:56:56,220 --> 00:56:57,770
a natural function

792
00:56:57,790 --> 00:56:59,380
OK that's sort of what

793
00:57:00,160 --> 00:57:03,610
the basic idea here is

794
00:57:03,620 --> 00:57:08,210
you wouldn't really be able to sample from that because computationally would be really hard

795
00:57:08,230 --> 00:57:08,810
to do

796
00:57:08,820 --> 00:57:11,250
but it because you know you can

797
00:57:11,300 --> 00:57:15,100
take determinant of and million by million matrix or something like that

798
00:57:15,220 --> 00:57:19,320
i mean we can draw anything on the discrete digital computer we can try anything

799
00:57:19,320 --> 00:57:21,100
continuous anyway

800
00:57:21,110 --> 00:57:25,660
we always have discretised but the beauty of it is that all those other

801
00:57:25,720 --> 00:57:29,390
million dimensions can be integrated out analytically

802
00:57:32,140 --> 00:57:37,670
so how do we use this for classification

803
00:57:37,720 --> 00:57:41,600
so here's our user for classification i hope you can see this this sort of

804
00:57:41,600 --> 00:57:44,390
red and blue island here OK

805
00:57:44,480 --> 00:57:47,400
imagine we have a binary classification problem

806
00:57:47,400 --> 00:57:50,000
so we given a data set d

807
00:57:50,840 --> 00:57:53,840
points in some input space x and then

808
00:57:53,860 --> 00:57:56,660
binary class labels plus or minus one

809
00:57:56,710 --> 00:57:59,160
and y space

810
00:57:59,210 --> 00:58:02,140
and our goal is to infer class probabilities

811
00:58:02,180 --> 00:58:04,650
that the data points

812
00:58:04,660 --> 00:58:06,810
so here's how we're going to do it

813
00:58:06,860 --> 00:58:08,350
we're going to have

814
00:58:12,340 --> 00:58:16,660
take our guassian process which is the prior on functions

815
00:58:16,690 --> 00:58:19,170
we're going to turn into prior on

816
00:58:21,490 --> 00:58:23,390
how do we do this we say

817
00:58:23,390 --> 00:58:27,930
every time i drive function

818
00:58:27,970 --> 00:58:29,560
in the inputs

819
00:58:29,570 --> 00:58:34,360
areas where the function is positive i'm going to call it the class plus one

820
00:58:34,360 --> 00:58:38,300
in the input areas where the function is negative i'm going to call class minus

821
00:58:41,710 --> 00:58:44,940
for example this function represents

822
00:58:44,950 --> 00:58:46,280
the idea that the

823
00:58:46,300 --> 00:58:48,640
positive class is this interval

824
00:58:48,640 --> 00:58:49,820
in this interval

825
00:58:49,840 --> 00:58:52,710
the negative class is this interval in this interval

826
00:58:53,600 --> 00:58:58,300
this is the one the picture in two d we might look like this

827
00:58:58,320 --> 00:59:01,730
this is under the prior before observed the data

828
00:59:01,750 --> 00:59:04,170
this is a typical sample of what i believe

829
00:59:05,170 --> 00:59:07,490
class boundaries would look like

830
00:59:09,650 --> 00:59:11,190
you know we have

831
00:59:11,250 --> 00:59:13,990
blue mountains in the red sea

832
00:59:14,090 --> 00:59:16,570
and zero is like sea level

833
00:59:16,590 --> 00:59:17,990
and wherever

834
00:59:18,040 --> 00:59:21,930
the function this is a draw from the function

835
00:59:21,940 --> 00:59:24,130
by the way this is a draw from the function

836
00:59:24,140 --> 00:59:26,470
in two dimensional space so this is

837
00:59:26,520 --> 00:59:31,120
we call it x one x two color why should be called one

838
00:59:31,160 --> 00:59:34,540
x one x two two dimensions of this function

839
00:59:34,560 --> 00:59:35,640
and then

840
00:59:38,340 --> 00:59:41,610
every time the function is greater than zero

841
00:59:42,410 --> 00:59:46,110
i think a priority that's in the positive class and if the function is less

842
00:59:46,110 --> 00:59:50,370
than zero we think that's in the negative class

843
00:59:50,410 --> 00:59:54,220
it's a weird way of thinking right we have been observed any data yet

844
00:59:54,240 --> 00:59:58,630
but we have beliefs about what we think are class boundaries are going to look

845
00:59:58,630 --> 01:00:03,260
like the class boundaries are going to look like a nice and smooth sort of

846
01:00:03,260 --> 01:00:05,710
regions like this

847
01:00:07,420 --> 01:00:10,840
so what happens when you observe sorry

848
01:00:10,890 --> 01:00:13,980
when you observe data

849
01:00:14,070 --> 01:00:17,720
then you have to do inference is about what you're underlying function is so let's

850
01:00:18,260 --> 01:00:20,960
let's say i observed data that said

851
01:00:22,030 --> 01:00:25,450
you know i observed a bunch of data points that were in the positive class

852
01:00:26,500 --> 01:00:29,560
and a bunch of the players so when the negative class here

853
01:00:29,600 --> 01:00:32,470
and clearly this function is not a good

854
01:00:32,490 --> 01:00:35,170
function because it would have predicted negative

855
01:00:35,170 --> 01:00:37,420
class data points here

856
01:00:37,470 --> 01:00:42,170
so essentially i would have to come up with a distribution over functions that are

857
01:00:42,170 --> 01:00:43,910
consistent with

858
01:00:43,950 --> 01:00:48,260
positive data here and negative data here so i would get a distribution over functions

859
01:00:48,260 --> 01:00:49,970
that locally

860
01:00:50,000 --> 01:00:55,810
like what i'm trying here you know

861
01:00:55,810 --> 01:00:59,650
used to build background palette but you know it's not that

862
01:00:59,690 --> 01:01:03,020
pleasing because that's quite a lot of work on the part of the user we

863
01:01:03,020 --> 01:01:06,190
were trying to get closer towards the idea of

864
01:01:06,230 --> 01:01:08,020
waving the magic wand

865
01:01:08,040 --> 01:01:10,320
and we know we can't get to

866
01:01:10,330 --> 01:01:13,230
so this is a kind of half-way house where all the user

867
01:01:13,250 --> 01:01:17,390
has to do with this interactive graphics system is to drag the blue rectangle around

868
01:01:17,390 --> 01:01:19,470
the object and and guaranteed

869
01:01:19,470 --> 01:01:20,670
the object in some way

870
01:01:20,690 --> 01:01:23,760
inside that's very much less work than

871
01:01:23,820 --> 01:01:26,830
drawing with a greasy pencil but what does that do in terms of

872
01:01:27,220 --> 01:01:30,030
providing training data

873
01:01:30,050 --> 01:01:32,810
we've lost now they

874
01:01:32,830 --> 01:01:38,270
the initial provision of training data that is implied by the greasy pencil happen

875
01:01:38,290 --> 01:01:39,620
well not entirely

876
01:01:39,620 --> 01:01:43,340
because you still have some material which is definitely in the background so that the

877
01:01:43,340 --> 01:01:48,130
thing has become asymmetrical now so outside the blue rectangle you've got material which is

878
01:01:48,130 --> 01:01:53,150
definitely the background we can build a background colour palettes from that material inside now

879
01:01:53,210 --> 01:01:54,910
kind of a bit ambiguous

880
01:01:55,890 --> 01:01:59,230
initially we don't have any so that we can point to and say that is

881
01:01:59,230 --> 01:02:02,450
definitely in the foreground so we're going to be a little bit messed up for

882
01:02:02,450 --> 01:02:07,230
building the foreground colour power but the solution to that is to

883
01:02:07,230 --> 01:02:13,960
use expectation maximisation station to build the colour palette iteratively and what you're seeing here

884
01:02:14,010 --> 01:02:18,890
it is a series of iterations in which the colour palette the foreground is initially

885
01:02:19,810 --> 01:02:25,830
crude polluted with background elements but gradually refined until

886
01:02:25,870 --> 01:02:30,900
we reach a good segmentation now we can play with this a little bit

887
01:02:31,450 --> 01:02:35,160
see that

888
01:02:41,790 --> 01:02:45,080
one i prepared earlier

889
01:02:48,320 --> 01:02:53,830
alright doing computer graphics and this angle is seriously because i can tell you

890
01:02:53,890 --> 01:02:56,150
OK so now

891
01:02:56,480 --> 01:03:02,830
back again

892
01:03:02,840 --> 01:03:05,980
now this is my colleague antonio criminisi

893
01:03:05,980 --> 01:03:08,270
and we're going to

894
01:03:11,790 --> 01:03:13,630
four in

895
01:03:13,730 --> 01:03:15,380
you can be segmented

896
01:03:15,520 --> 01:03:20,000
c so now i drawn my rectangle as the use i'm gonna release

897
01:03:20,020 --> 01:03:24,930
the mouse button and as soon as the math gets released some optimisation over that

898
01:03:24,930 --> 01:03:28,670
markov random field is going to get unleashed

899
01:03:28,710 --> 01:03:29,710
it is

900
01:03:29,720 --> 01:03:30,680
doing it

901
01:03:30,730 --> 01:03:31,870
it's done

902
01:03:31,870 --> 01:03:35,740
and i wasn't bad was we didn't quite get what we were

903
01:03:35,790 --> 01:03:37,170
hoping for

904
01:03:37,210 --> 01:03:41,120
so the poor guy has lost his head but

905
01:03:41,300 --> 01:03:43,600
we can put that right quickly before

906
01:03:43,630 --> 01:03:48,430
before you see any issues are also a little bit

907
01:03:48,450 --> 01:03:51,440
missing publishers back

908
01:03:51,500 --> 01:03:52,320
now we are

909
01:03:52,330 --> 01:03:56,830
a little bit of editing work here and when more back

910
01:03:56,930 --> 01:04:00,120
i could now

911
01:04:00,160 --> 01:04:04,130
copy and paste that that's the

912
01:04:04,200 --> 01:04:06,490
should be funding

913
01:04:06,500 --> 01:04:10,330
now there is another of my goodness

914
01:04:10,340 --> 01:04:15,550
he has a ghastly holding easier because somebody shot

915
01:04:15,560 --> 01:04:17,440
you guys really should have spotted that

916
01:04:18,490 --> 01:04:20,070
i think we can

917
01:04:20,100 --> 01:04:22,800
we can minimize the damage by

918
01:04:22,880 --> 01:04:27,940
by making him small is now only a very small hole no one really noticed

919
01:04:30,260 --> 01:04:31,060
there we are

920
01:04:31,180 --> 01:04:32,880
now that was actually

921
01:04:34,720 --> 01:04:36,500
and optimisation

922
01:04:37,900 --> 01:04:41,280
that works in in real time

923
01:04:41,330 --> 01:04:44,080
and so the rest of the lecture i'm just going to tell you what

924
01:04:44,090 --> 01:04:46,430
optimisation is

925
01:04:46,490 --> 01:04:48,130
this is the graph cut

926
01:04:48,240 --> 01:04:50,790
risation talking about before

927
01:04:52,750 --> 01:04:58,670
so there are as i said there are lots of ways potentially of solving this

928
01:04:58,670 --> 01:05:03,010
kind of problem and people have been looking at this year for you know

929
01:05:05,500 --> 01:05:09,670
what's that two decades we can say if we exclude simulated annealing which was really

930
01:05:09,670 --> 01:05:14,770
designed for nuking the world not solving computer vision problems

931
01:05:14,780 --> 01:05:18,250
metropolis rosenbluth rosenbluth teller and teller you know this paper

932
01:05:18,300 --> 01:05:21,030
this is a simulated annealing you know about this

933
01:05:21,040 --> 01:05:24,770
algorithm you know where you sort of simulate lowering the temperature

934
01:05:24,790 --> 01:05:26,440
in an optimisation problem

935
01:05:27,190 --> 01:05:32,740
the reason that it's rosenbluth rosenbluth teller and teller is because some of the work

936
01:05:32,740 --> 01:05:36,650
on this paper was done dinner party and the wives were present so they decided

937
01:05:36,650 --> 01:05:38,710
i want add them into the paper

938
01:05:38,720 --> 01:05:42,970
very very generous approach to science which you know we rarely seen at

939
01:05:44,510 --> 01:05:47,790
and that

940
01:05:48,260 --> 01:05:49,900
his brothers

941
01:05:49,900 --> 01:05:53,630
so people have been trying to do this for

942
01:05:53,640 --> 01:05:58,880
quite quite awhile i guess starting with

943
01:05:58,930 --> 01:06:00,000
b sag

944
01:06:00,760 --> 01:06:06,410
iterated conditional modes is a little bit like hill climbing on these rather complex posterior

945
01:06:06,730 --> 01:06:10,680
distributions that are not really sufficiently

946
01:06:10,730 --> 01:06:15,530
straightforward to help time on but you know you can do something i'll show results

947
01:06:15,530 --> 01:06:19,700
right at the end compares some of these classic methods with the method i'm going

948
01:06:19,700 --> 01:06:24,570
describe now loopy belief propagation i was referring to early on is the a kind

949
01:06:24,570 --> 01:06:28,810
of extension to belief propagation that you were you hearing about

950
01:06:28,810 --> 01:06:31,790
don't overlook the force but do appreciate the fact

951
01:06:32,770 --> 01:06:35,170
they don't do any work

952
01:06:36,420 --> 01:06:37,750
so now

953
01:06:37,770 --> 01:06:39,540
i'm going to show you

954
01:06:41,140 --> 01:06:43,140
which i find one of the most

955
01:06:43,140 --> 01:06:45,730
mind-boggling demonstrations

956
01:06:45,850 --> 01:06:47,690
i've ever seen we do have

957
01:06:47,690 --> 01:06:50,480
a circular track

958
01:06:50,520 --> 01:06:52,830
you have right in front of you

959
01:06:52,890 --> 01:06:56,520
that's circles although you may not think it is but it is

960
01:06:56,650 --> 01:06:58,650
and that circles

961
01:06:58,670 --> 01:07:00,290
has radius

962
01:07:00,310 --> 01:07:03,290
which according to many to the manufacturer

963
01:07:03,290 --> 01:07:06,540
is a hundred fifteen metres

964
01:07:06,560 --> 01:07:08,190
was an uncertainty

965
01:07:08,210 --> 01:07:10,290
of about

966
01:07:10,350 --> 01:07:15,520
i think it's about five meters sixteen difficult to measure and eventually transport you think

967
01:07:15,560 --> 01:07:17,020
it could change

968
01:07:17,140 --> 01:07:19,910
we tried to clean this a little better

969
01:07:19,910 --> 01:07:23,330
and so the radius of this

970
01:07:23,390 --> 01:07:25,730
the radius of curvature of our

971
01:07:25,790 --> 01:07:29,810
arc which is also in track record hundred fifty

972
01:07:29,810 --> 01:07:34,060
plus and minus five metres

973
01:07:34,100 --> 01:07:35,810
so we can calculate now

974
01:07:35,810 --> 01:07:38,830
what the period of oscillation is this

975
01:07:38,850 --> 01:07:41,350
the whole track is five meters long

976
01:07:41,370 --> 01:07:42,870
so half the track

977
01:07:42,920 --> 01:07:44,600
is about

978
01:07:44,650 --> 01:07:46,230
two and half metres

979
01:07:46,270 --> 01:07:48,440
so the angle theta maximum

980
01:07:48,460 --> 01:07:51,040
is approximately

981
01:07:51,060 --> 01:07:54,270
two and a half metres which is half the length of the track

982
01:07:54,290 --> 01:07:56,410
divided by hundred fifty

983
01:07:56,460 --> 01:07:58,790
and that is an extremely small angle

984
01:07:58,790 --> 01:08:01,580
that is about one point two degrees

985
01:08:01,640 --> 01:08:03,940
so this is in radiance and this is in degrees

986
01:08:03,980 --> 01:08:05,080
so the angle

987
01:08:05,080 --> 01:08:06,190
it's very small

988
01:08:06,190 --> 01:08:09,100
so we should be able to make a perfect prediction

989
01:08:10,190 --> 01:08:12,790
the period and i'm going to do that

990
01:08:12,830 --> 01:08:16,290
i take two pi times the square root of our over g and r is

991
01:08:16,290 --> 01:08:18,120
hundred fifteen

992
01:08:18,150 --> 01:08:21,190
hundred fifteen i divided by g

993
01:08:21,210 --> 01:08:22,870
i take the square root

994
01:08:22,870 --> 01:08:24,600
i multiply by two

995
01:08:24,600 --> 01:08:26,330
i multiply by pi

996
01:08:26,370 --> 01:08:28,100
and i get twenty one

997
01:08:28,140 --> 01:08:28,810
o point

998
01:08:31,830 --> 01:08:34,080
and this is the prediction

999
01:08:37,120 --> 01:08:38,080
he calls

1000
01:08:38,080 --> 01:08:42,020
twenty one point five

1001
01:08:42,170 --> 01:08:44,120
uncertainty in our

1002
01:08:44,170 --> 01:08:46,440
is about four point three percent

1003
01:08:46,460 --> 01:08:48,980
since we have this career of our

1004
01:08:49,000 --> 01:08:51,000
that becomes two point two percent

1005
01:08:51,060 --> 01:08:54,080
so if i multiply that by point o two two

1006
01:08:54,100 --> 01:08:58,210
i get an uncertainty of about o point four seven that's called is o point

1007
01:08:58,210 --> 01:08:59,810
five seconds

1008
01:08:59,830 --> 01:09:04,140
so this is a hard prediction

1009
01:09:04,140 --> 01:09:06,150
what the period of oscillation

1010
01:09:06,190 --> 01:09:08,080
should be twenty one and a half

1011
01:09:08,080 --> 01:09:10,790
plus and minus one half

1012
01:09:10,850 --> 01:09:12,650
now i'm going to observe it

1013
01:09:12,710 --> 01:09:14,140
i'm going to see

1014
01:09:14,870 --> 01:09:16,670
we're going to

1015
01:09:16,730 --> 01:09:18,620
how this compares

1016
01:09:18,690 --> 01:09:22,790
i don't know what i don't oscillate ten times that will take three four five

1017
01:09:22,790 --> 01:09:24,060
minutes that's too long

1018
01:09:24,100 --> 01:09:27,420
it's not really necessary because my reaction time

1019
01:09:27,440 --> 01:09:31,870
is o point one second so even if i did only one oscillation

1020
01:09:31,890 --> 01:09:33,750
there will be enough to see whether it

1021
01:09:33,770 --> 01:09:35,370
it's coincident with that

1022
01:09:35,480 --> 01:09:40,370
consistent with that number however it is such a beautiful experiment it's so much fun

1023
01:09:40,370 --> 01:09:44,750
to see that object go back and forth in twenty one seconds that i will

1024
01:09:44,750 --> 01:09:49,310
go for your pleasure and for my own pleasure i will go three oscillations not

1025
01:09:49,310 --> 01:09:53,730
that it is necessary but i will do it pretty is going to be something

1026
01:09:53,770 --> 01:09:56,440
closer minus and this is my reaction time

1027
01:09:56,480 --> 01:10:00,100
which is o point one second and then we can call

1028
01:10:00,140 --> 01:10:01,500
divided by three

1029
01:10:01,520 --> 01:10:05,140
and then of course the error will go down by a factor of three

1030
01:10:05,140 --> 01:10:07,920
we'll see whether this number agrees

1031
01:10:07,980 --> 01:10:09,270
with this one

1032
01:10:09,480 --> 01:10:13,040
all right you imagine someone making a track like this

1033
01:10:13,080 --> 01:10:14,020
air traffic

1034
01:10:14,040 --> 01:10:18,140
with a radius of one hundred fifty meters one is this

1035
01:10:18,190 --> 01:10:20,980
this may be a ctmeter hundred fifty meters

1036
01:10:21,020 --> 01:10:23,730
that is something like ten times higher

1037
01:10:23,790 --> 01:10:26,480
more fifteen times higher than this year

1038
01:10:26,600 --> 01:10:27,830
amazing that

1039
01:10:27,850 --> 01:10:30,040
people were able to do that in fact

1040
01:10:30,060 --> 01:10:32,330
nowadays you can even buy this anymore

1041
01:10:32,370 --> 01:10:35,670
this is probably some fifty years old if not all

1042
01:10:35,790 --> 01:10:39,600
i have to get the

1043
01:10:39,730 --> 01:10:42,330
air flowing

1044
01:10:42,330 --> 01:10:46,460
out of all these holes there are many many small holes in here

1045
01:10:46,580 --> 01:10:48,410
you can also see

1046
01:10:48,480 --> 01:10:50,210
areas is now blowing

1047
01:10:52,250 --> 01:10:54,480
this object

1048
01:10:54,560 --> 01:10:56,640
going report on here

1049
01:10:56,670 --> 01:10:58,370
and just because of gravity

1050
01:10:58,370 --> 01:10:59,790
it will go

1051
01:10:59,830 --> 01:11:01,480
that's all it is only gravity

1052
01:11:01,520 --> 01:11:02,710
we'll do work

1053
01:11:02,730 --> 01:11:04,710
he the time

1054
01:11:04,750 --> 01:11:08,500
and we're going to time i'll start off first

1055
01:11:08,520 --> 01:11:11,170
and then when it comes back to stop

1056
01:11:11,170 --> 01:11:15,640
i will start to time because that's for me very sharp criterion when object comes

1057
01:11:17,190 --> 01:11:20,120
i can still hold here it's very easy for me

1058
01:11:20,870 --> 01:11:23,020
start the timing

1059
01:11:23,020 --> 01:11:26,810
you may notice as you watch that some of the amplitude

1060
01:11:26,850 --> 01:11:31,580
will decrease because there is all the old

1061
01:11:31,600 --> 01:11:35,790
because there is of course a little bit of friction is very little

1062
01:11:35,830 --> 01:11:38,210
but it is not zero

1063
01:11:38,270 --> 01:11:39,830
i do it

1064
01:11:39,850 --> 01:11:42,000
just look at it is incredible

1065
01:11:42,040 --> 01:11:44,540
just goes simply by gravity

1066
01:11:44,540 --> 01:11:46,250
it's like a pendulum

1067
01:11:46,250 --> 01:11:51,990
I'm gonna be talking about inference and in particular bayesian inference

1068
01:11:52,040 --> 01:11:57,130
inference is different from data analysis inference is about learning about

1069
01:11:57,230 --> 01:12:00,860
not just the data you got but the data you will have or you might

1070
01:12:00,860 --> 01:12:05,700
have so it inevitably involves modeling it involves assumption

1071
01:12:06,270 --> 01:12:11,910
so inference is the process of discovering from the data something about tipically about mechanisms

1072
01:12:11,910 --> 01:12:17,640
that are they did might have caused the data or generated the data or if that's too much

1073
01:12:17,640 --> 01:12:24,180
at least mechanisms that might explain the data the goals of

1074
01:12:24,180 --> 01:12:29,500
doing this acquire can be quite varied and there's not one simple single thing we're

1075
01:12:29,500 --> 01:12:34,820
trying to do we may simply be trying to predict future data in many

1076
01:12:36,280 --> 01:12:40,250
commercial applications that's the main thing you want to do I guess but in

1077
01:12:40,250 --> 01:12:46,210
scientific applications is usually a little more we typically want to try and something

1078
01:12:48,240 --> 01:12:53,410
truth that's a bit of a overblown word but something about the scientific truth something

1079
01:12:53,410 --> 01:12:57,740
about scientific laws something about how society works whatever it is

1080
01:12:58,830 --> 01:13:02,770
if you're an applied mathematician you naturally think of that as an inverse problem

1081
01:13:02,770 --> 01:13:07,630
instead of going from assumptions towards data in inference we're going in the opposite direction we're

1082
01:13:07,630 --> 01:13:13,680
going from data back towards assumptions and trying to learn something and the

1083
01:13:13,680 --> 01:13:18,020
idea in bayesian inference is simply that we use probability to do all of that

1084
01:13:18,050 --> 01:13:22,540
OK we absolutely rigorously stick to the laws of probability and that's pretty much the

1085
01:13:22,540 --> 01:13:28,310
only thing we use to conduct all of our inferential processes

1086
01:13:30,520 --> 01:13:35,690
I'm gonna spend some minutes in these opening slides talking about the implications of

1087
01:13:35,690 --> 01:13:42,410
this but a key strength essentially is that all sources of uncertainty are simultaneously and coherently

1088
01:13:42,460 --> 01:13:43,690
accounted for

1089
01:13:44,470 --> 01:13:49,240
I in the in the old days of small data problems that wasn't terribly important

1090
01:13:49,240 --> 01:13:53,790
because it probably was and it was once source of uncertainty but nowadays we're dealing with

1091
01:13:53,810 --> 01:13:58,730
complex systems with many different sources of variation and is crucial to be able to properly

1092
01:13:58,730 --> 01:14:03,560
integrate all of those uncertainties and all of that randomness and the laws of probability make

1093
01:14:03,560 --> 01:14:09,850
that easy and possible and is about the best game in town for doing that

1094
01:14:09,900 --> 01:14:11,000
in my opinion

1095
01:14:11,780 --> 01:14:16,410
is model-based and in I think in the machine learning language we would call this

1096
01:14:16,410 --> 01:14:22,450
the generative models this are models that are capable of generating the data

1097
01:14:23,340 --> 01:14:28,450
a further strength of the bayesian approach is that models are not of course models have to be

1098
01:14:28,450 --> 01:14:33,250
assumed and and and so on and our analyses are conditional

1099
01:14:33,250 --> 01:14:37,030
on the on the truth of those models but also we can use bayesian methods

1100
01:14:37,030 --> 01:14:45,790
themselves to criticize those models so if you like it's internally self-criticizing which is which is quite important

1101
01:14:46,290 --> 01:14:49,820
OK so over the three talks today and the two tomorrow I'm gonna

1102
01:14:49,820 --> 01:14:52,720
cover various different things

1103
01:14:53,790 --> 01:14:59,350
and I'll tell you a little bit later about the actual program today's

1104
01:14:59,400 --> 01:15:05,060
lecture is quite introductory but we'll get on to some more difficult things

1105
01:15:07,160 --> 01:15:13,410
everything connects everything does connect the three other themes that at this summer

1106
01:15:13,410 --> 01:15:15,720
school that particulary connect with

1107
01:15:15,750 --> 01:15:20,840
my talks are these three here you've been hearing about

1108
01:15:20,910 --> 01:15:26,730
monte carlo methods from from arnold and he'll continue today the bayesian

1109
01:15:26,730 --> 01:15:31,730
non-parametrics theme on Monday and Tuesday is also very relevant and at the

1110
01:15:31,730 --> 01:15:36,630
end of next week the the graphical models theme from Martin von Wainwright is

1111
01:15:36,630 --> 01:15:41,600
also very important now if if they weren't I will probably be talking about

1112
01:15:41,600 --> 01:15:42,880
all of those things

1113
01:15:43,000 --> 01:15:51,000
in less detail so I'm gonna deliberately try and downplay those particular issues and relying on them

1114
01:15:51,010 --> 01:15:55,230
I'm sure they did it a lot better than I would but relying on them to cover those

1115
01:15:55,230 --> 01:15:57,170
those areas

1116
01:15:58,660 --> 01:16:02,340
now I'm not as you know I'm not a machine learner of any

1117
01:16:04,260 --> 01:16:10,050
so I was a little bit nervous coming here and I spent a little time browsing on the

1118
01:16:10,050 --> 01:16:15,170
way to find out what other people have done so and in doing so

1119
01:16:15,170 --> 01:16:21,260
I decided to steal two slides from two people I admire a lot I think they're very highly esteemed

1120
01:16:21,260 --> 01:16:24,960
both in the statistics and the machine learning community

1121
01:16:25,200 --> 01:16:29,490
I thought they might have an interesting perspective on

1122
01:16:29,540 --> 01:16:36,610
perhaps the connections between the subjects if they are indeed different discussed and also on

1123
01:16:36,610 --> 01:16:39,540
the role of bayesian methods

1124
01:16:41,200 --> 01:16:44,340
in them so this first one is Michael Jordan

1125
01:16:45,840 --> 01:16:50,790
and you can see what he says here he was trying to explain what machine

1126
01:16:50,790 --> 01:16:53,730
learning was to a statistician

1127
01:16:54,870 --> 01:16:58,060
you may disagree of course of what he says but what he says is this that's a

1128
01:16:58,060 --> 01:17:06,610
loose fede confederation of themes in statistical inference is a focus on prediction and

1129
01:17:06,610 --> 01:17:08,460
exploratory data analysis

1130
01:17:08,900 --> 01:17:14,430
a focus on computational methodologies and in particulary empirical evaluation

1131
01:17:15,430 --> 01:17:19,260
and sometimes frequentist and sometimes bayesian

1132
01:17:19,260 --> 01:17:25,190
let's say sigma is fixed they can also put a prior over sigma let's put

1133
01:17:25,190 --> 01:17:27,180
a prior over music only

1134
01:17:27,190 --> 01:17:32,060
and when i take the prior over mu as the calcium then everything becomes simple

1135
01:17:32,240 --> 01:17:35,410
if they don't do that everything is not so simple

1136
01:17:35,510 --> 01:17:41,010
that's why people have taken in priors over music

1137
01:17:41,450 --> 01:17:44,200
for simplicity so i want to know what

1138
01:17:44,410 --> 01:17:48,720
let's say i need a prior over new because mu is not known it's the

1139
01:17:49,650 --> 01:17:55,220
try to estimate so i just say well look here from you should be something

1140
01:17:55,220 --> 01:18:01,720
like e to the minus mu minus mu not squared over two

1141
01:18:01,740 --> 01:18:04,760
sigma naught squared and there's a constant i don't want

1142
01:18:04,900 --> 01:18:08,630
he that concern is just the the the normal

1143
01:18:09,080 --> 01:18:11,400
a couple of pies that you have

1144
01:18:12,390 --> 01:18:16,580
one is carried to hide things like that so it means well i believe somehow

1145
01:18:16,590 --> 01:18:19,970
what i'm looking for this mu is

1146
01:18:19,990 --> 01:18:24,680
in the vicinity of you not which i have to specify and

1147
01:18:24,700 --> 01:18:30,000
well known sort of more or less certain about this with sigma naught

1148
01:18:30,950 --> 01:18:36,880
so this is the prior it comes with two hyperparameters so high power

1149
01:18:40,550 --> 01:18:46,820
mu nought and sigma is i hyperparameters i have to supply

1150
01:18:47,940 --> 01:18:50,910
i just want to estimate one thing and i have to come up with two

1151
01:18:50,930 --> 01:18:58,120
well OK so what's the p of mu given the new given d according to

1152
01:18:58,120 --> 01:19:04,440
this it's the given mute times p speed mu divided by p fifty

1153
01:19:04,500 --> 01:19:10,710
don't calculate everything that p of the given mu is just the likelihood

1154
01:19:10,760 --> 01:19:13,050
of the data so it's

1155
01:19:13,830 --> 01:19:16,080
it's the product to fly

1156
01:19:16,280 --> 01:19:20,630
one of the spirit of two pi e to the minus

1157
01:19:20,710 --> 01:19:21,710
x y

1158
01:19:21,740 --> 01:19:24,700
minus new square

1159
01:19:24,710 --> 01:19:30,560
over two sigma was called was that of the introduce it's across

1160
01:19:30,580 --> 01:19:32,570
it was right

1161
01:19:33,890 --> 01:19:35,150
let's forget about it

1162
01:19:35,160 --> 01:19:36,240
too much right

1163
01:19:36,380 --> 01:19:40,490
so this is the likelihood

1164
01:19:40,530 --> 01:19:45,960
and i have to multiply by e to the minus mu minus mu nor critical

1165
01:19:45,960 --> 01:19:48,200
over to see my notes

1166
01:19:49,180 --> 01:19:51,520
and then divide by something

1167
01:19:51,550 --> 01:19:54,330
p of d the first of all we see

1168
01:19:54,340 --> 01:19:59,430
because he an exponent there's an exponent and everything i mean it goes up to

1169
01:19:59,430 --> 01:20:03,320
second order in mu in the exponent so it's going to be a galson as

1170
01:20:04,280 --> 01:20:07,400
right so let's just find out what the mean and the variance of the scouts

1171
01:20:07,550 --> 01:20:11,900
is and then the rest will be just follow from normalisation

1172
01:20:12,930 --> 01:20:13,890
i have to

1173
01:20:13,940 --> 01:20:16,100
get these two guys together

1174
01:20:16,120 --> 01:20:20,770
let's take the exponent so this is proportional to x

1175
01:20:21,950 --> 01:20:24,090
minus one over two

1176
01:20:24,100 --> 01:20:27,100
so what do i have i have first of all

1177
01:20:27,140 --> 01:20:29,740
because this product

1178
01:20:29,760 --> 01:20:33,950
goes into is something get about the eyes here

1179
01:20:33,970 --> 01:20:36,750
minutes of this product goes into some right

1180
01:20:36,800 --> 01:20:39,080
so if i multiply

1181
01:20:39,110 --> 01:20:42,910
i found collecting all the terms that go with mu square

1182
01:20:42,930 --> 01:20:46,270
i get the following i get new square i get

1183
01:20:46,280 --> 01:20:52,240
there's some here that some would give me probably and

1184
01:20:53,090 --> 01:20:57,740
because i have to sum up in terms from multiply to get

1185
01:20:57,770 --> 01:21:01,620
this is the a size clear minus two new

1186
01:21:01,710 --> 01:21:03,630
x y

1187
01:21:03,650 --> 01:21:06,600
new square in his

1188
01:21:06,610 --> 01:21:10,950
right so this some of this constant gives me an n times

1189
01:21:11,050 --> 01:21:17,270
new square and then i'll have this guy here which is a plus

1190
01:21:17,780 --> 01:21:21,320
plus one over sigma not square

1191
01:21:25,490 --> 01:21:30,700
now i have to collect all the terms that are linear in mu

1192
01:21:30,740 --> 01:21:34,680
everything that is linear in me was the following thing there is this mute times

1193
01:21:34,680 --> 01:21:39,540
x y so there's mu MUN a sum over high

1194
01:21:39,600 --> 01:21:43,530
this will be coming from that with this to those away

1195
01:21:43,570 --> 01:21:47,620
there will be this is another term linear here

1196
01:21:47,680 --> 01:21:49,240
and it's a plus

1197
01:21:49,480 --> 01:21:52,050
mu nought

1198
01:21:52,070 --> 01:21:56,350
divided by new node divided by

1199
01:21:56,370 --> 01:21:59,310
sigma not squared

1200
01:21:59,310 --> 01:22:02,100
listen to the details of the later lectures

1201
01:22:02,110 --> 01:22:05,760
so you start with a little problem from probabilities which is

1202
01:22:05,790 --> 01:22:09,210
which is the following you've got a red box in the blue box and inside

1203
01:22:09,210 --> 01:22:12,170
each box we've got some apples and oranges

1204
01:22:12,170 --> 01:22:17,930
depicted by some of the basic graphics i'm afraid that's left box we've got six

1205
01:22:17,930 --> 01:22:21,250
oranges and apples and i got both rappers one orange

1206
01:22:21,260 --> 01:22:26,550
and imagine the process by which somebody picks one of these boxes randomly with some

1207
01:22:27,540 --> 01:22:30,300
and then reaches into the box and select the piece of fruit

1208
01:22:30,310 --> 01:22:35,300
again random with equal probability of choosing any of those pieces of fruit

1209
01:22:36,840 --> 01:22:37,990
we can

1210
01:22:38,420 --> 01:22:41,980
ask the following question suppose that we don't know which box was chosen but we

1211
01:22:41,980 --> 01:22:45,350
do know a piece of fruit was an orange we can ask what's the probability

1212
01:22:45,750 --> 01:22:47,420
that the box was blue

1213
01:22:47,440 --> 01:22:51,170
so we're actually doing here is typical of what we're doing in machine learning problems

1214
01:22:51,170 --> 01:22:53,420
with sort of going in the opposite direction to

1215
01:22:53,460 --> 01:22:57,090
the physical process the physical processes you first which is the box and then you

1216
01:22:57,090 --> 01:23:00,250
choose the piece of fruit we want to sort of reverse that process we know

1217
01:23:00,250 --> 01:23:04,530
the piece of fruit if we want to infer the probability that we chose the

1218
01:23:04,530 --> 01:23:05,840
blue box

1219
01:23:05,880 --> 01:23:11,350
so because we do that using the rules of probability and it's very beautiful theory

1220
01:23:11,420 --> 01:23:14,540
just described by these two simple rules are really most of what we're gonna be

1221
01:23:14,540 --> 01:23:20,760
talking about just the consistent application of these these two very simple rules does anybody

1222
01:23:20,760 --> 01:23:25,040
would anyone seeking to derive the rules of probability or

1223
01:23:25,090 --> 01:23:29,760
mean everybody very happy with these i imagine from the the applicants we have this

1224
01:23:29,760 --> 01:23:34,560
summer school everybody is very comfortable with the OK and properties of course satisfy the

1225
01:23:34,560 --> 01:23:39,590
probably property properties be nonnegative and sum to one

1226
01:23:39,610 --> 01:23:42,930
and from the from the sum rule

1227
01:23:44,900 --> 01:23:47,000
from the product rule of probability

1228
01:23:47,030 --> 01:23:50,930
we can write the conditional probability of y given x

1229
01:23:50,940 --> 01:23:54,570
in terms of the ratio of the the joint the marginal we can write the

1230
01:23:54,570 --> 01:23:58,230
joint is the product of the conditional and the other marginal

1231
01:23:58,240 --> 01:24:00,920
which gives bayes theorem to bayes theorem provides way

1232
01:24:03,720 --> 01:24:07,930
the conditional probability of y given x in terms of the reverse conditional p of

1233
01:24:07,930 --> 01:24:09,490
x given y

1234
01:24:10,420 --> 01:24:14,780
from the product and some rule we can express the denominator in bayes theorem in

1235
01:24:14,780 --> 01:24:17,900
terms of the summation over the terms which appear

1236
01:24:17,920 --> 01:24:20,280
in the numerator

1237
01:24:20,320 --> 01:24:22,960
so if you look are apples and oranges then

1238
01:24:22,970 --> 01:24:29,030
and let's suppose that the probability of choosing the red boxes two-fifths so it's more

1239
01:24:29,030 --> 01:24:32,930
likely that we choose the blue box the the red box

1240
01:24:32,990 --> 01:24:34,050
and we

1241
01:24:34,100 --> 01:24:37,820
somebody shows box we don't know which one is chosen piece of afraid it's an

1242
01:24:38,900 --> 01:24:42,820
we first compute the denominator in bayes theorem which is the probability that the fruit

1243
01:24:42,820 --> 01:24:44,550
was orange that's

1244
01:24:44,560 --> 01:24:48,660
the fruit is orange given the boxes red well that's just the

1245
01:24:48,670 --> 01:24:53,430
fraction of pieces of fruit in the box to oranges times the probability that the

1246
01:24:53,430 --> 01:24:54,690
box red

1247
01:24:54,740 --> 01:24:56,040
which is two-fifths

1248
01:24:56,050 --> 01:24:58,290
and similarly for this

1249
01:24:58,340 --> 01:25:01,490
in this case the probability of the boxes blue is just one minus this was

1250
01:25:02,970 --> 01:25:04,620
in nineteen twenty s

1251
01:25:04,640 --> 01:25:06,470
and then use bayes theorem

1252
01:25:06,490 --> 01:25:07,700
to compute

1253
01:25:07,710 --> 01:25:08,850
the probability

1254
01:25:08,990 --> 01:25:12,950
boxer trade given the food was that comes out to be two-thirds which is bigger

1255
01:25:12,950 --> 01:25:13,910
than half

1256
01:25:14,910 --> 01:25:19,060
sort of the called with our intuition observing a piece of fruit and oranges some

1257
01:25:19,990 --> 01:25:24,230
that's stays is more towards the red box the the blue box because the proportion

1258
01:25:24,230 --> 01:25:29,560
of oranges is higher in the red box that is in the blue box

1259
01:25:29,570 --> 01:25:32,210
OK very comfortable with that

1260
01:25:32,230 --> 01:25:33,880
any questions and show

1261
01:25:38,660 --> 01:25:40,760
why did they pick two-fifths

1262
01:25:40,780 --> 01:25:43,690
it's just to tutorial examples i just wanted to achieve

1263
01:25:43,710 --> 01:25:48,590
well i chose the number basis of the numbers cannot simply and also because this

1264
01:25:48,590 --> 01:25:52,310
is this is less than half the saying that a priority

1265
01:25:52,320 --> 01:25:55,110
it was more likely that it shows the blue box but once i saw a

1266
01:25:55,110 --> 01:25:58,440
piece of fruit was an orange it becomes more likely that in fact it was

1267
01:25:58,460 --> 01:25:59,790
red box

1268
01:25:59,820 --> 01:26:03,640
was that slightly bigger than half that

1269
01:26:03,660 --> 01:26:10,490
there's nothing nothing deep and mysterious and of course we can also talk about probabilities

1270
01:26:10,490 --> 01:26:13,400
with respect to continuous variables x

1271
01:26:13,460 --> 01:26:17,630
is a continuous variable we can define a probability density shown by the red curve

1272
01:26:17,870 --> 01:26:19,360
here there ex

1273
01:26:19,370 --> 01:26:23,850
so the probability that x will lie in this little interval with delta x is

1274
01:26:23,850 --> 01:26:25,680
just equal to that the area

1275
01:26:25,690 --> 01:26:29,530
which is the product of delta x times the height of this curve

1276
01:26:29,620 --> 01:26:31,850
and so the probability that x will

1277
01:26:31,860 --> 01:26:35,600
lie within an interval a to b is the integral of the density over that

1278
01:26:37,310 --> 01:26:42,400
and if we integrate from minus infinity up to point z that density get something

1279
01:26:42,400 --> 01:26:47,260
called the the cumulative probability which is shown that the blue curve that starts zero

1280
01:26:47,260 --> 01:26:53,080
on the left and ends up the one on the right

1281
01:26:53,110 --> 01:27:00,340
and again these are nonnegative in this case the probability density integrates to one

1282
01:27:00,350 --> 01:27:04,400
so bayesian inference this is one of the the first of those three ingredients in

1283
01:27:04,400 --> 01:27:09,230
this sort of third generation framework that i'm talking about and

1284
01:27:09,240 --> 01:27:13,790
the idea of bayesian inference is really a consistent use of probability to quantify

1285
01:27:13,810 --> 01:27:22,020
uncertainty sources extending probability beyond the notion of frequencies repeatable events and using probability theory

1286
01:27:22,870 --> 01:27:25,220
the way we have uncertainty

1287
01:27:25,220 --> 01:27:29,350
of your friends have an ipod and then you can change your mind going by

1288
01:27:29,380 --> 01:27:31,060
OK so the question is

1289
01:27:31,080 --> 01:27:34,100
can reach which ones

1290
01:27:34,120 --> 01:27:35,310
and i think that allowed

1291
01:27:35,320 --> 01:27:38,530
you need lots of observations to be able to distinguish between

1292
01:27:38,570 --> 01:27:42,260
so if i show in the results for example for the DVD recommendations

1293
01:27:42,300 --> 01:27:44,040
when we had a point two million

1294
01:27:44,110 --> 01:27:45,640
recombination events

1295
01:27:45,680 --> 01:27:51,570
it's it's nice diminishing returns right so i'm blocking the number of recommendations received on

1296
01:27:51,570 --> 01:27:54,730
a particular DVD what's the probability of purchasing

1297
01:27:54,770 --> 01:27:56,290
and you can see that

1298
01:27:56,310 --> 01:28:01,480
probability and i think reason and saturates at around fifteen and what you can also

1299
01:28:01,480 --> 01:28:07,390
see that overall the the the probability basically the infection probabilities whitelaw a best it's

1300
01:28:07,390 --> 01:28:08,940
around five percent

1301
01:28:08,950 --> 01:28:10,950
and interesting

1302
01:28:10,960 --> 01:28:15,240
this this also holds for other types of behavior so for example for group membership

1303
01:28:15,240 --> 01:28:20,250
for the probability of communicating you make it some

1304
01:28:21,330 --> 01:28:25,630
so last part that i want to that here is basically the question of

1305
01:28:25,640 --> 01:28:29,520
if we know how things probably the question is how to find out the most

1306
01:28:29,520 --> 01:28:34,450
sort of inferential knowledge of how to do that these cascades as quickly as possible

1307
01:28:34,450 --> 01:28:36,200
and this comes

1308
01:28:36,210 --> 01:28:40,440
in many different flavours so for example on the blog for information cascades you can

1309
01:28:40,440 --> 01:28:45,630
ask one of the most influential or infectious blogs so which blocks should so that

1310
01:28:45,630 --> 01:28:47,690
i most up-to-date so that i know

1311
01:28:47,700 --> 01:28:49,310
the stories that happening

1312
01:28:49,700 --> 01:28:51,240
in the blood

1313
01:28:51,250 --> 01:28:52,680
environ marketing

1314
01:28:52,700 --> 01:28:55,010
the same question question can be asked

1315
01:28:55,230 --> 01:28:59,570
that is what the trendsetters who are the influentials people who should i given free

1316
01:28:59,570 --> 01:29:03,180
free products so they create cascades and everyone goes by

1317
01:29:03,190 --> 01:29:08,880
what spreading you can ask whether workplace by monitoring stations were replaced place sensors to

1318
01:29:08,880 --> 01:29:14,020
detect these epidemics as quickly as possible right even though these are different pressures these

1319
01:29:14,020 --> 01:29:16,340
are the and the same question

1320
01:29:16,360 --> 01:29:20,570
so here's here's here's the problem if i if i had network

1321
01:29:20,960 --> 01:29:25,270
i want want to detect epidemics as quickly as possible so the idea is if

1322
01:29:25,350 --> 01:29:28,700
we don't start here and spread over time this particular way

1323
01:29:28,700 --> 01:29:32,660
and there could be some other the start and spread this particular way the question

1324
01:29:32,660 --> 01:29:35,960
is whether i my sense my monitoring station

1325
01:29:36,880 --> 01:29:39,420
these epidemics as quickly as possible

1326
01:29:40,080 --> 01:29:42,900
and that would be like two parts to the problem so the first part is

1327
01:29:42,900 --> 01:29:44,430
the cost right so

1328
01:29:44,830 --> 01:29:50,240
monitoring of advertising to particular node in the network have we have a particular cost

1329
01:29:50,840 --> 01:29:54,040
just because there's some the

1330
01:29:54,050 --> 01:29:55,630
and then will also be only one

1331
01:29:56,980 --> 01:29:59,670
and for example for for detecting diseases

1332
01:29:59,680 --> 01:30:03,430
the one that makes lots of that is that we want to minimize the number

1333
01:30:03,430 --> 01:30:08,860
of affected nodes so you see that is a particular disease spread particular way

1334
01:30:08,920 --> 01:30:10,490
and these are the two

1335
01:30:10,770 --> 01:30:13,130
sense of monitoring stations the people

1336
01:30:13,180 --> 01:30:17,650
and what we get is basically the number of people safe from infection and infections

1337
01:30:17,650 --> 01:30:19,370
that can spread easily

1338
01:30:19,400 --> 01:30:22,610
we were detected here so this would be the people that will get infected because

1339
01:30:22,700 --> 01:30:23,920
there is lot

1340
01:30:23,920 --> 01:30:28,320
and there are also other reward functions are also makes sense which would mean like

1341
01:30:28,320 --> 01:30:31,830
you want to minimize time to detection or just say i want to do that

1342
01:30:31,830 --> 01:30:34,790
but i don't care how holland and so on

1343
01:30:34,840 --> 01:30:39,070
just to be a bit more formal way what the problem we are given a

1344
01:30:39,070 --> 01:30:42,730
graph in the budget and we have data on how cascades

1345
01:30:42,750 --> 01:30:46,600
propagate through the network rights of these data can be obtained from the blogosphere by

1346
01:30:46,600 --> 01:30:47,950
calling what you can have

1347
01:30:48,090 --> 01:30:52,880
someone or something related to the user's data on how what is possible propagation effects

1348
01:30:52,890 --> 01:30:54,790
events could spread through the network

1349
01:30:54,800 --> 01:30:55,980
and we want to

1350
01:30:56,020 --> 01:30:57,460
select the set of nodes

1351
01:30:57,470 --> 01:31:03,030
for maximizing the one right so i want to maximize expected reward subject to costa

1352
01:31:03,050 --> 01:31:05,950
and so i mean this is is hard

1353
01:31:07,850 --> 01:31:12,140
if you exploit the the problem structure that show in the next slide then you

1354
01:31:12,140 --> 01:31:15,100
can try to to the body to call itself

1355
01:31:15,150 --> 01:31:18,820
which is basically two independent runs of a light

1356
01:31:18,840 --> 01:31:24,250
well basically in the first round we just ignore and greedily optimize reward

1357
01:31:24,260 --> 01:31:29,250
in the second in the second independent i'm we optimize reward cost ratios

1358
01:31:29,260 --> 01:31:31,400
and then pick the best of the solution

1359
01:31:31,460 --> 01:31:35,350
and we can we can show that the following what function has disappointed that property

1360
01:31:35,350 --> 01:31:37,030
that i've shown in the next slide

1361
01:31:37,090 --> 01:31:39,250
our like neural

1362
01:31:39,940 --> 01:31:40,950
so what is now

1363
01:31:40,970 --> 01:31:44,880
the problem structure are trying to explain something to me the idea is the following

1364
01:31:44,880 --> 01:31:46,450
so if i have some

1365
01:31:46,470 --> 01:31:48,670
on some networks and i already

1366
01:31:48,670 --> 01:31:49,400
i mean

1367
01:31:51,060 --> 01:31:54,870
right but i want

1368
01:31:55,270 --> 01:32:02,790
i don't know who the role was wrong

1369
01:32:02,820 --> 01:32:06,150
that's why the

1370
01:32:08,240 --> 01:32:11,320
so no

1371
01:32:11,340 --> 01:32:13,830
part one three

1372
01:32:17,280 --> 01:32:23,990
roman five of going from memory and so on

1373
01:32:23,990 --> 01:32:27,480
o lord god

1374
01:32:27,500 --> 01:32:34,000
now we were not below

1375
01:32:38,880 --> 01:32:40,530
from her

1376
01:32:42,370 --> 01:32:49,800
OK so this is the

1377
01:32:55,830 --> 01:33:02,850
now to make it more or less

1378
01:33:02,860 --> 01:33:04,970
i mean

1379
01:33:07,280 --> 01:33:09,470
what are

1380
01:33:09,530 --> 01:33:11,210
i think one

1381
01:33:11,230 --> 01:33:13,650
same thing with

1382
01:33:14,820 --> 01:33:22,870
if you want to roll one

1383
01:33:26,520 --> 01:33:29,960
and now all over

1384
01:33:30,000 --> 01:33:32,440
or so

1385
01:33:35,390 --> 01:33:40,570
so the idea is a

1386
01:33:57,400 --> 01:34:00,150
they are

1387
01:34:00,820 --> 01:34:02,170
i mean to them

1388
01:34:02,180 --> 01:34:05,670
and the role of our

1389
01:34:06,750 --> 01:34:08,720
o o o

1390
01:34:13,040 --> 01:34:15,040
one one

1391
01:34:17,440 --> 01:34:18,400
and what

1392
01:34:18,420 --> 01:34:25,190
but rather

1393
01:34:25,200 --> 01:34:28,370
three or o

1394
01:34:28,540 --> 01:34:29,840
there all

1395
01:34:36,680 --> 01:34:39,690
one of the

1396
01:34:39,690 --> 01:34:42,540
and then mind

1397
01:34:42,570 --> 01:34:46,000
and in one go away

1398
01:34:46,010 --> 01:34:48,540
because you

1399
01:34:50,230 --> 01:34:52,970
but here

1400
01:34:52,980 --> 01:34:56,770
the main road

1401
01:34:56,780 --> 01:34:59,250
well you

1402
01:34:59,260 --> 01:35:01,420
what mean

1403
01:35:01,440 --> 01:35:05,230
he a new

1404
01:35:05,270 --> 01:35:09,000
where n is

1405
01:35:12,250 --> 01:35:15,520
i mean there's no more

1406
01:35:15,540 --> 01:35:16,590
the the

1407
01:35:16,610 --> 01:35:18,280
four fifty

1408
01:35:21,150 --> 01:35:25,300
so who don't

1409
01:35:30,700 --> 01:35:36,750
one hundred or one thousand

1410
01:35:40,290 --> 01:35:44,560
the above

1411
01:35:44,580 --> 01:35:46,550
i know

1412
01:35:48,190 --> 01:35:49,600
a lot more

1413
01:35:49,890 --> 01:35:53,860
and the so

1414
01:36:07,100 --> 01:36:08,490
in the

1415
01:36:08,500 --> 01:36:18,780
what want

1416
01:36:18,790 --> 01:36:22,300
the number of

1417
01:36:22,450 --> 01:36:26,340
and that the

1418
01:36:26,390 --> 01:36:29,570
and what we know

1419
01:36:53,100 --> 01:36:53,570
you go

1420
01:36:53,580 --> 01:36:55,760
early i the

1421
01:36:58,670 --> 01:37:03,460
you know your role

1422
01:37:06,260 --> 01:37:11,420
if you think of

1423
01:37:11,420 --> 01:37:14,370
through the calculation so you see the problem

1424
01:37:16,730 --> 01:37:18,810
first second and then

1425
01:37:18,850 --> 01:37:21,030
i have a

1426
01:37:21,040 --> 01:37:22,990
a break

1427
01:37:24,630 --> 01:37:28,900
yes so what what what would have to do for doing nothing like likelihood in

1428
01:37:28,900 --> 01:37:30,640
this case

1429
01:37:37,500 --> 01:37:41,390
right so maximum likelihood we go like that

1430
01:37:42,940 --> 01:37:45,200
so let's take two gaussians

1431
01:37:45,220 --> 01:37:47,270
and for simplicity

1432
01:37:47,280 --> 01:37:51,270
let's say all the segments are one

1433
01:37:51,290 --> 01:37:52,970
so just to simplify

1434
01:37:54,370 --> 01:37:59,120
and so i take the negative log likelihood so i take minus long

1435
01:37:59,130 --> 01:38:00,500
p d

1436
01:38:01,730 --> 01:38:06,370
well all the parameters theta and the parameters are now the two means the two

1437
01:38:06,370 --> 01:38:08,660
mixing coefficients

1438
01:38:08,700 --> 01:38:10,270
these are the unknowns

1439
01:38:10,290 --> 01:38:11,820
we don't know how

1440
01:38:12,020 --> 01:38:15,220
how strongly each component is mixed

1441
01:38:15,350 --> 01:38:16,650
in the set

1442
01:38:16,810 --> 01:38:19,320
so this would be

1443
01:38:19,330 --> 01:38:22,750
again since we have independent data

1444
01:38:22,780 --> 01:38:26,450
and then we would take the longer

1445
01:38:26,460 --> 01:38:28,190
and we would have

1446
01:38:28,200 --> 01:38:31,070
p one

1447
01:38:31,200 --> 01:38:35,340
of two pi so this is

1448
01:38:35,350 --> 01:38:36,780
this goes back to the

1449
01:38:38,790 --> 01:38:40,450
o thing

1450
01:38:40,630 --> 01:38:41,770
so i just

1451
01:38:41,860 --> 01:38:43,130
six months

1452
01:38:43,160 --> 01:38:45,870
two one e to the minus

1453
01:38:45,880 --> 01:38:50,270
why i minus mu one squared

1454
01:38:50,300 --> 01:38:52,720
over two

1455
01:38:53,620 --> 01:38:59,460
now comes the contribution from the second one

1456
01:38:59,470 --> 01:39:04,010
p two over scary to too high

1457
01:39:04,050 --> 01:39:05,880
e to the minus one i

1458
01:39:05,900 --> 01:39:08,660
minus two

1459
01:39:08,670 --> 01:39:13,120
question this is the object he would have to minimize

1460
01:39:13,220 --> 01:39:18,170
so for instance we are doing let's call this the

1461
01:39:18,190 --> 01:39:20,610
so if we do e

1462
01:39:20,730 --> 01:39:26,470
he mu one and set this equal to zero which is get

1463
01:39:26,620 --> 01:39:29,060
a minus

1464
01:39:29,100 --> 01:39:31,040
i from one to n

1465
01:39:32,220 --> 01:39:37,210
the figure

1466
01:39:39,770 --> 01:39:42,260
i want to see it would get

1467
01:39:42,340 --> 01:39:45,070
if you take the derivative of this

1468
01:39:45,080 --> 01:39:47,070
you would get the two

1469
01:39:48,610 --> 01:39:51,150
period two pi

1470
01:39:51,160 --> 01:39:53,870
e to the minus

1471
01:39:54,450 --> 01:39:58,840
once screened over two

1472
01:40:05,720 --> 01:40:12,430
mean two squared two and here you would actually differentiate only with respect to this

1473
01:40:15,150 --> 01:40:17,330
let's get rid of all these

1474
01:40:17,330 --> 01:40:21,570
here is too high

1475
01:40:21,610 --> 01:40:25,850
you have

1476
01:40:25,890 --> 01:40:27,820
p one

1477
01:40:27,830 --> 01:40:30,890
times e to the minus

1478
01:40:30,920 --> 01:40:34,660
you i minus one square

1479
01:40:36,870 --> 01:40:40,440
well if you take the derivative this

1480
01:40:40,450 --> 01:40:44,110
minus you get a y

1481
01:40:44,150 --> 01:40:46,680
i minus mu

1482
01:40:46,690 --> 01:40:51,100
one so this is actually what you would have to do

1483
01:40:51,110 --> 01:40:54,160
and set this equal to zero and then solve

1484
01:40:54,170 --> 01:40:59,850
you get a similar equation for the derivative with respect to two mu two

1485
01:40:59,920 --> 01:41:04,090
and yes if doesn't look so

1486
01:41:04,100 --> 01:41:08,230
it doesn't look so nice so

1487
01:41:08,840 --> 01:41:11,030
just let me write in a little

1488
01:41:11,050 --> 01:41:13,030
a different way

1489
01:41:13,030 --> 01:41:14,890
you know it's

1490
01:41:14,900 --> 01:41:17,640
it's not for me be the first time here

1491
01:41:17,730 --> 01:41:21,490
but you know after a while it's not funny anymore

1492
01:41:21,510 --> 01:41:23,650
you know it's it's deadly

1493
01:41:23,700 --> 01:41:25,090
it's very

1494
01:41:26,400 --> 01:41:29,330
what do you mean you teach which you don't believe

1495
01:41:29,350 --> 01:41:33,170
but i mean you know believe textbooks you use of this

1496
01:41:34,890 --> 01:41:36,820
this is shocking

1497
01:41:36,840 --> 01:41:40,040
but i believe all of its that's different

1498
01:41:40,090 --> 01:41:44,120
every single thing that i told you that these four disciplines

1499
01:41:44,160 --> 01:41:46,280
sir i believe all

1500
01:41:46,330 --> 01:41:47,930
this is the

1501
01:41:47,940 --> 01:41:50,590
there are only partially true

1502
01:41:50,610 --> 01:41:52,550
so at any rate

1503
01:41:52,790 --> 01:41:57,470
and by the way if you look at an introductory textbook in cognitive psychology

1504
01:41:57,480 --> 01:42:00,000
decision and how people make decisions

1505
01:42:00,020 --> 01:42:04,190
how people make choices usually chapter thirteen or fourteen

1506
01:42:04,200 --> 01:42:06,150
which means you never get

1507
01:42:07,390 --> 01:42:10,400
it's invariant anime news i mean always

1508
01:42:10,410 --> 01:42:14,320
and it always says that people allows decision makers and it shows you what the

1509
01:42:14,320 --> 01:42:16,380
rational actor model is wrong

1510
01:42:16,400 --> 01:42:20,840
and that it gives you some examples from common first and the story

1511
01:42:20,890 --> 01:42:23,240
every single one of

1512
01:42:23,550 --> 01:42:27,870
now if you look at a special course in psychology and cognitive decision on decision

1513
01:42:29,640 --> 01:42:31,920
like barons book

1514
01:42:32,010 --> 01:42:36,780
on decision making special course then you get a lot of very good

1515
01:42:36,790 --> 01:42:38,930
social theory and very

1516
01:42:38,980 --> 01:42:41,290
nuanced and careful work

1517
01:42:41,340 --> 01:42:44,660
but it's not part of the tacit knowledge in the profession

1518
01:42:44,670 --> 01:42:46,600
it specialized in that area

1519
01:42:46,620 --> 01:42:48,040
if you study

1520
01:42:48,060 --> 01:42:50,090
decision making

1521
01:42:50,140 --> 01:42:53,880
the second is what can be assumed in a disciplinary journal articles

1522
01:42:53,900 --> 01:42:55,160
what can you say

1523
01:42:55,170 --> 01:43:00,320
if you submit an article to journal looking say without some reviewer freaking out

1524
01:43:02,170 --> 01:43:04,020
OK in economics you can say

1525
01:43:04,030 --> 01:43:07,340
we're going to find some game perfect nash equilibria

1526
01:43:07,400 --> 01:43:08,530
this game

1527
01:43:08,540 --> 01:43:11,020
nobody for example

1528
01:43:11,030 --> 01:43:16,810
only need only i

1529
01:43:17,010 --> 01:43:23,330
or in sociology and mean you can imagine every field is all these things which

1530
01:43:23,350 --> 01:43:25,950
if you said in another field to push the button

1531
01:43:25,960 --> 01:43:27,420
and you get rejected

1532
01:43:27,430 --> 01:43:31,190
so when you work with other people on a paper from different disciplines

1533
01:43:31,200 --> 01:43:35,010
there's two things the other disciplines has to tell you because the guy tells you

1534
01:43:35,010 --> 01:43:37,570
what is what references you have to put in

1535
01:43:37,610 --> 01:43:39,500
because if you don't have the reference in

1536
01:43:39,550 --> 01:43:42,230
there's no way that publishes art

1537
01:43:42,240 --> 01:43:45,210
and the second is what words you have to take out

1538
01:43:45,230 --> 01:43:49,030
say because if a see this were going to go in and

1539
01:43:49,040 --> 01:43:53,810
OK this is the sound funny but it's actually quite distressing

1540
01:43:53,820 --> 01:43:56,440
this will not happen in the natural sciences

1541
01:43:56,490 --> 01:44:00,530
o physicists and chemists don't disagree about the nature of you know

1542
01:44:00,540 --> 01:44:04,870
the structure of proteins

1543
01:44:04,920 --> 01:44:06,930
can don't have their own rules

1544
01:44:06,950 --> 01:44:11,490
alternately they don't say what quantum mechanics is obviously wrong we have our own little

1545
01:44:13,390 --> 01:44:15,030
mechanics we

1546
01:44:15,140 --> 01:44:18,930
i mean this country

1547
01:44:19,940 --> 01:44:22,060
can therefore

1548
01:44:22,160 --> 01:44:25,040
at least three of them are wrong

1549
01:44:25,050 --> 01:44:28,690
and i argue that they are all wrong in the sense that they all include

1550
01:44:28,690 --> 01:44:30,690
fundamental insights

1551
01:44:30,710 --> 01:44:36,060
that must be incorporated into a unified basic model of human choice and strategic interaction

1552
01:44:37,370 --> 01:44:42,120
this may sound obvious but if you take an economics textbook go look in the

1553
01:44:42,120 --> 01:44:43,810
appendix goal the

1554
01:44:43,820 --> 01:44:46,270
table mountain cable car to go look in the

1555
01:44:46,320 --> 01:44:47,090
you know

1556
01:44:47,150 --> 01:44:48,360
but index

1557
01:44:48,370 --> 01:44:50,520
and see if you can find more like

1558
01:44:52,250 --> 01:44:53,440
or would like

1559
01:44:56,140 --> 01:44:58,010
you know even more like

1560
01:44:58,050 --> 01:44:59,100
this missile

1561
01:44:59,110 --> 01:45:02,720
it's missing workers not even the corruption

1562
01:45:02,770 --> 01:45:05,850
and conversely in biology

1563
01:45:05,890 --> 01:45:07,650
they don't actually things you

1564
01:45:07,720 --> 01:45:11,680
but the first time i ever do i get an article in the journal of

1565
01:45:11,680 --> 01:45:15,130
theoretical biology in in two thousand three

1566
01:45:15,150 --> 01:45:18,840
called the hitchhiker's guide to alter

1567
01:45:18,930 --> 01:45:24,120
and it was mostly you know genetics deployed that you know

1568
01:45:24,170 --> 01:45:26,170
my article is an

1569
01:45:26,220 --> 01:45:30,510
but the basic idea was that people are socialized and they have a certain genetic

1570
01:45:30,510 --> 01:45:34,550
structure that more makes some more or less open to being socialized to be to

1571
01:45:34,550 --> 01:45:36,690
internalizing norms

1572
01:45:36,800 --> 01:45:40,350
internalizing norms at the heart of sociological model

1573
01:45:40,350 --> 01:45:41,890
the active role models

1574
01:45:42,040 --> 01:45:45,690
well i showed this to my best friends and mike of the people i work

1575
01:45:46,960 --> 01:45:48,110
they actually

1576
01:45:49,860 --> 01:45:54,030
i got from biology side of this is just pop psychology there's no such thing

1577
01:45:54,030 --> 01:45:57,320
as internalisation this is just pop psychology

1578
01:45:57,330 --> 01:45:59,600
or we already captured this in

1579
01:45:59,610 --> 01:46:05,870
the grande coefficient the third order of you know some maximisation

1580
01:46:05,920 --> 01:46:10,350
and it took me a year to convince people what i want

1581
01:46:10,380 --> 01:46:14,480
that they could actually use this concept technologies here given some literature on to read

1582
01:46:14,480 --> 01:46:19,260
the literature is a huge literature and sociology on the internalisation of norms

1583
01:46:19,260 --> 01:46:21,190
it's very impressive

1584
01:46:21,200 --> 01:46:22,240
go read

1585
01:46:23,050 --> 01:46:24,520
they were convinced

1586
01:46:24,530 --> 01:46:25,850
my point is that

1587
01:46:25,860 --> 01:46:30,520
the discipline and by the way when you mention the sociologist the rational actor model

1588
01:46:30,540 --> 01:46:32,600
they go for their guns mostly

1589
01:46:32,670 --> 01:46:33,310
i mean

1590
01:46:33,330 --> 01:46:34,860
that some people here

1591
01:46:34,870 --> 01:46:38,720
but you know what if i wanted to care about the rational actor model i

1592
01:46:38,720 --> 01:46:41,830
want to become an economist what you need it

1593
01:46:44,400 --> 01:46:47,610
this is very general

1594
01:46:47,630 --> 01:46:51,970
now i can finally the monk of full copy OK

1595
01:46:51,980 --> 01:46:54,990
i want to give five principles for the

1596
01:46:56,800 --> 01:46:58,680
of the behavioral science

1597
01:46:58,720 --> 01:47:02,780
and what i mean by this is the following i don't mean that these five

1598
01:47:02,780 --> 01:47:05,160
principles the most important thing

1599
01:47:05,210 --> 01:47:06,490
i mean it

1600
01:47:06,510 --> 01:47:08,430
with the use of these

1601
01:47:08,430 --> 01:47:12,920
we can create a situation in which wherever two disciplines overlap in the sense that

1602
01:47:12,920 --> 01:47:15,510
they are describing the same phenomenon

1603
01:47:15,540 --> 01:47:16,800
the great

1604
01:47:16,810 --> 01:47:18,360
or if they do not agree

1605
01:47:19,340 --> 01:47:21,170
they have to fight it out

1606
01:47:21,210 --> 01:47:24,490
so you know you might have some of the most important things in economics are

1607
01:47:24,490 --> 01:47:26,230
not going to be and what i'm saying

1608
01:47:26,270 --> 01:47:29,260
or any other view but there what you need to

1609
01:47:29,810 --> 01:47:31,510
to bring them together

1610
01:47:31,520 --> 01:47:34,450
fitting together

1611
01:47:34,450 --> 01:47:35,640
here that the

1612
01:47:35,760 --> 01:47:38,260
so picky picky applications

1613
01:47:38,840 --> 01:47:45,040
2nd is an artifact and that is related to the heart each time the started

1614
01:47:45,040 --> 01:47:50,080
beating the subject is moving availability and because of this movement the amount of flux

1615
01:47:50,080 --> 01:47:56,280
which is sketched so wire that changes and you know that it's actually quite remarkable

1616
01:47:56,280 --> 01:48:02,980
because you are in a very very strong magnetic field movements are very small but

1617
01:48:02,980 --> 01:48:09,720
if you multiply this large magnetic fields this is very small and moving movements than

1618
01:48:09,720 --> 01:48:14,380
that for somewhere or another you you get the potential difference which is in the

1619
01:48:14,380 --> 01:48:19,840
same order of EEG so there there the top 10 times bigger and then you

1620
01:48:19,840 --> 01:48:22,620
can use it to which it's very very clearly

1621
01:48:24,680 --> 01:48:28,560
I not what you what we do to work to get rid of the year

1622
01:48:29,060 --> 01:48:31,180
of these artifacts we also report the

1623
01:48:31,820 --> 01:48:36,950
the EKG particles from finger

1624
01:48:37,080 --> 01:48:39,720
well then we get the

1625
01:48:39,730 --> 01:48:46,770
exact positions of the heartbeats heartbeats are and are not extremely regular they also vary

1626
01:48:46,770 --> 01:48:49,690
a little bit of time and that's the reason why we have to report the

1627
01:48:49,690 --> 01:48:53,530
signals that we know the events of the heartbeat weekend

1628
01:48:54,510 --> 01:48:58,480
what we can if the if you have these artifacts we can compute the average

1629
01:48:58,480 --> 01:49:00,840
artefact triggered by the

1630
01:49:01,100 --> 01:49:08,560
. ecology and you can and then the kind of President EEG signal which looks

1631
01:49:09,940 --> 01:49:18,880
that's so that we can start here at the equator think this experienced because they

1632
01:49:18,880 --> 01:49:25,920
relation all this happened because of they of think about what is more

1633
01:49:25,930 --> 01:49:30,560
at each year out that some of the

1634
01:49:32,600 --> 01:49:38,700
so the pulses of the recorded from the from the finger for this a cable

1635
01:49:38,700 --> 01:49:43,920
from here to here but it is not so much influenced by the magnetic field

1636
01:49:43,920 --> 01:49:48,970
inside a board ecology is recorded to here from the from the rest so that

1637
01:49:48,970 --> 01:49:53,880
this over much more the structure by also by the canadian fields and that's I

1638
01:49:53,880 --> 01:50:01,860
think the reason why signals that recorded from something are emerged much cleaner and much

1639
01:50:01,870 --> 01:50:10,010
more appropriate to to get to EKG triggers from ECG so much so that he

1640
01:50:10,040 --> 01:50:15,720
she wants us to believe it must be stated he is all the more

1641
01:50:16,420 --> 01:50:19,140
nowadays they have the media

1642
01:50:19,160 --> 01:50:25,760
the ecology and EEG there are almost the same amplitude so if you look here

1643
01:50:25,760 --> 01:50:28,570
at the at the signals

1644
01:50:29,220 --> 01:50:36,640
so this this is this is the ballistic artefact reduce these strings that are caused

1645
01:50:36,640 --> 01:50:40,140
by the emotional disappeared but that a bit surprising is that it is indeed of

1646
01:50:40,140 --> 01:50:48,700
the same order of magnitude of of the unit itself because of of the

1647
01:50:50,290 --> 01:50:53,280
this is

1648
01:51:13,700 --> 01:51:17,700
that is the name of the

1649
01:51:18,540 --> 01:51:22,400
what something happens yeah OK that's exactly what


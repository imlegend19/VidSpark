1
00:00:00,000 --> 00:00:02,250
to me

2
00:00:08,180 --> 00:00:14,050
we want do

3
00:00:14,060 --> 00:00:19,090
do it

4
00:00:23,900 --> 00:00:44,070
there is a

5
00:00:55,630 --> 00:00:58,090
but really the most

6
00:01:02,690 --> 00:01:09,750
so let's see

7
00:01:09,800 --> 00:01:12,230
this to

8
00:01:20,480 --> 00:01:23,180
she gives you a

9
00:01:29,060 --> 00:01:34,330
the school using the

10
00:01:43,430 --> 00:01:50,010
the relationship between space so you

11
00:01:50,090 --> 00:01:53,020
i think

12
00:02:03,770 --> 00:02:08,790
so we that

13
00:02:08,860 --> 00:02:12,190
here is we strive

14
00:02:14,810 --> 00:02:18,380
we that

15
00:02:19,800 --> 00:02:22,240
she was

16
00:02:29,820 --> 00:02:30,440
this a

17
00:02:30,450 --> 00:02:35,630
so there is

18
00:02:37,320 --> 00:02:39,380
is it one

19
00:02:39,430 --> 00:02:43,930
this one

20
00:02:43,940 --> 00:02:45,440
it is

21
00:02:46,560 --> 00:02:53,130
there are many

22
00:03:50,870 --> 00:03:55,650
set so easy

23
00:03:58,530 --> 00:03:59,870
which is

24
00:04:01,710 --> 00:04:02,770
well is

25
00:04:07,080 --> 00:04:08,940
this key to

26
00:04:09,010 --> 00:04:14,350
so for instance that

27
00:04:57,870 --> 00:05:00,080
one is set

28
00:05:04,060 --> 00:05:06,820
it two

29
00:05:15,450 --> 00:05:18,670
and in the formulation

30
00:05:33,640 --> 00:05:37,550
so that's

31
00:05:37,550 --> 00:05:38,240
i meant

32
00:05:40,720 --> 00:05:42,790
donor flickr busiest banker

33
00:05:43,340 --> 00:05:46,630
man in the centre long island when she was very elderly

34
00:05:47,030 --> 00:05:48,900
and she told me that when this happens

35
00:05:51,740 --> 00:05:55,350
had its opening party sort of a housewarming party

36
00:05:55,950 --> 00:06:00,620
she was ten years old and she began to slide down the ramp

37
00:06:01,130 --> 00:06:02,900
ah with another little girl

38
00:06:03,290 --> 00:06:07,710
screaming having great sensor pleasure going down the ramp

39
00:06:08,200 --> 00:06:10,680
and all the other results tried to stop them

40
00:06:11,300 --> 00:06:12,730
except for corbusier

41
00:06:13,780 --> 00:06:15,570
who said that his house was meant

42
00:06:16,000 --> 00:06:16,970
for people to live in

43
00:06:17,460 --> 00:06:18,790
for children to have fun

44
00:06:21,750 --> 00:06:22,350
la roche

45
00:06:23,060 --> 00:06:23,620
in his

46
00:06:24,190 --> 00:06:29,170
journal entries describes the number of times he had to rebuild the house

47
00:06:30,130 --> 00:06:34,820
the mechanical problems the flora that had to be replaced the heating that didn't work

48
00:06:35,130 --> 00:06:39,550
the plumbing that need to all the systems that failed and the budget went four

49
00:06:39,550 --> 00:06:41,560
times what it was supposed to be

50
00:06:42,750 --> 00:06:46,220
but he was still very proud of this beautiful building

51
00:06:48,920 --> 00:06:56,050
after the failure of these big house in switzerland then designed house that i referred

52
00:06:56,050 --> 00:07:02,210
to earlier that he made song forty his mother and father on the shores of

53
00:07:02,770 --> 00:07:03,830
lake geneva

54
00:07:04,780 --> 00:07:07,850
he allowed his mother however antiques fair

55
00:07:08,280 --> 00:07:11,230
it was a small house and de perfect space

56
00:07:11,640 --> 00:07:12,740
a wonderful place

57
00:07:13,370 --> 00:07:15,220
just to look at the sunshine

58
00:07:16,410 --> 00:07:19,230
he did of course in paris in the twenties these

59
00:07:19,950 --> 00:07:20,730
pavilion be

60
00:07:21,310 --> 00:07:23,470
has played in which many of you know

61
00:07:24,640 --> 00:07:25,140
he was

62
00:07:25,600 --> 00:07:29,180
furious at these seven civil authorities

63
00:07:29,620 --> 00:07:31,950
for the circumstances of his building

64
00:07:32,700 --> 00:07:33,100
is given

65
00:07:33,520 --> 00:07:35,990
the worst location in the fair

66
00:07:37,390 --> 00:07:40,140
and which is why he built the house around a tree

67
00:07:40,770 --> 00:07:43,000
which he had really intended to do

68
00:07:43,660 --> 00:07:44,290
but this

69
00:07:44,750 --> 00:07:47,220
pavilion gave him a chance on

70
00:07:48,930 --> 00:07:51,890
so his design for a city for three million

71
00:07:53,640 --> 00:07:58,850
again i assume that most you know more about the corbusier's urbanism and the

72
00:07:59,430 --> 00:08:01,410
project the city for three million

73
00:08:01,910 --> 00:08:02,470
then i do

74
00:08:03,390 --> 00:08:08,350
but what i discovered in his letters is something that you might not know about

75
00:08:08,390 --> 00:08:13,220
which i think is terribly important he wrote to several friends

76
00:08:14,430 --> 00:08:17,100
he intended only as an idea

77
00:08:18,140 --> 00:08:21,950
it was hypothetical he really did not favor

78
00:08:22,310 --> 00:08:24,910
the destruction about repairers paris

79
00:08:25,350 --> 00:08:28,000
he did not want to see them play

80
00:08:30,390 --> 00:08:31,060
to this day

81
00:08:31,890 --> 00:08:33,720
i encountered people who tell me

82
00:08:34,120 --> 00:08:37,140
on corbusier the man wanted to destroy paris

83
00:08:37,790 --> 00:08:42,700
that's what he's known fore he's the man who could entertain an idea

84
00:08:43,810 --> 00:08:48,250
but it doesn't mean that he didn't have great understanding and sympathy

85
00:08:48,680 --> 00:08:50,890
for the year regularity about the city

86
00:08:52,720 --> 00:08:55,120
here is in front of the famous planned

87
00:08:56,850 --> 00:08:59,450
in fact the way that he lived in paris

88
00:08:59,870 --> 00:09:02,540
was not the way most people picture this is it

89
00:09:03,370 --> 00:09:05,850
photographed by the side of the

90
00:09:06,680 --> 00:09:08,370
charlotte marshall i

91
00:09:09,520 --> 00:09:14,410
on the twenty shock up he lived in the seventeenth century house

92
00:09:14,930 --> 00:09:19,450
on the seventh forward one disfavor painters of

93
00:09:19,700 --> 00:09:23,270
was gaussian whose work is behind him here

94
00:09:23,580 --> 00:09:29,180
wasn't strict modernist he was above all else humanitarian he

95
00:09:30,330 --> 00:09:37,990
loved this primitive uneducated artist who he felt was wrong about the art establishment court

96
00:09:38,080 --> 00:09:44,850
was always helping gaussian financially and legally trying to organize and he was a man

97
00:09:45,230 --> 00:09:46,810
but key rate don't keynote

98
00:09:49,060 --> 00:09:51,220
by the way early in my research

99
00:09:52,140 --> 00:09:58,040
i told my wife that the corbusier's copy donkey hodie rather astonished me

100
00:09:58,580 --> 00:10:03,000
because it was founded in these high degree of historic has

101
00:10:04,180 --> 00:10:06,350
anne catherine thought that i was

102
00:10:07,060 --> 00:10:13,810
losing my mind until she went with me to be found out sooner corbusier in the library

103
00:10:14,310 --> 00:10:17,080
we pulled out his copy a documentary

104
00:10:17,750 --> 00:10:24,220
and indeed it is bound with the skin and fir of one is

105
00:10:25,160 --> 00:10:26,560
beloved characters

106
00:10:27,040 --> 00:10:30,390
there were different dogs name and so on there is some confusion

107
00:10:30,790 --> 00:10:31,660
on this issue

108
00:10:32,350 --> 00:10:35,370
i also learned from these taxidermist

109
00:10:36,500 --> 00:10:38,040
that he had some of

110
00:10:39,500 --> 00:10:40,930
pen so those are

111
00:10:41,140 --> 00:10:43,140
john bones including the job

112
00:10:43,990 --> 00:10:47,120
made into a sort of a paper holder that whispering gallery

113
00:10:47,720 --> 00:10:52,160
and he kept on his desk and the clampdown on papers and he would open

114
00:10:52,160 --> 00:10:57,730
and closed and open and close it when he was designing somebody entrances for shopping

115
00:11:00,730 --> 00:11:04,140
now in their twenties is when he began that would be gone

116
00:11:04,620 --> 00:11:09,950
but he kept a secret from modern-day you weren't supposed to living with a woman from monaco

117
00:11:10,500 --> 00:11:11,910
um in paris

118
00:11:13,160 --> 00:11:18,120
and have your swiss calvinist parents know about it so there are plenty in letters to we've gone

119
00:11:18,620 --> 00:11:19,160
telling are

120
00:11:19,640 --> 00:11:24,870
the way in which she had to address mail to him when he was fifteen and a lot of secrecy

121
00:11:27,250 --> 00:11:29,100
then his father died

122
00:11:30,580 --> 00:11:33,790
when you reach his account of his father's death

123
00:11:34,470 --> 00:11:40,970
u come to realize how deeply sensitive courtroom was as a human being

124
00:11:42,000 --> 00:11:45,140
i had the experience researching this one mile

125
00:11:45,410 --> 00:11:47,000
mother father was dying

126
00:11:47,660 --> 00:11:49,990
and that's something i could feel

127
00:11:50,410 --> 00:11:53,250
so much what court who had experienced

128
00:11:53,810 --> 00:11:58,750
the things against which he reacted as a young man the wanting to go further

129
00:11:58,910 --> 00:12:03,830
wanting to be different and then coming to realize as was his good fortune and

130
00:12:03,830 --> 00:12:04,890
my fortune

131
00:12:05,390 --> 00:12:07,120
that his father had been a man

132
00:12:07,640 --> 00:12:10,330
who is an example are kindness

133
00:12:10,930 --> 00:12:13,370
an example are straightforward this

134
00:12:13,870 --> 00:12:16,970
the court lucia couldn't stand corruption

135
00:12:17,470 --> 00:12:19,370
he couldn't stand the policy

136
00:12:20,000 --> 00:12:23,370
many people would say he aired on the side being part two

137
00:12:25,040 --> 00:12:27,250
opening in the things that he said

138
00:12:27,870 --> 00:12:31,930
but his father represented integrity and good to

139
00:12:33,450 --> 00:12:35,470
i also discovered in my region

140
00:12:37,330 --> 00:12:37,730
that year

141
00:12:39,020 --> 00:12:41,370
his father died he wrote a letter to his mother

142
00:12:43,640 --> 00:12:46,250
the situation of his father's death

143
00:12:46,890 --> 00:12:48,100
and referring to

144
00:12:49,160 --> 00:12:49,810
the needle

145
00:12:49,810 --> 00:12:51,000
how to

146
00:12:51,020 --> 00:12:53,350
gives insight

147
00:12:53,420 --> 00:12:56,690
why this issue shows that

148
00:13:03,670 --> 00:13:05,480
a within the

149
00:13:05,670 --> 00:13:06,940
well said

150
00:13:06,960 --> 00:13:08,710
interested in finding

151
00:13:08,790 --> 00:13:10,070
p of

152
00:13:10,130 --> 00:13:11,380
x i

153
00:13:11,400 --> 00:13:13,500
the rest

154
00:13:13,520 --> 00:13:18,130
all everything that i i

155
00:13:18,190 --> 00:13:20,150
the question is to show the four

156
00:13:20,170 --> 00:13:23,440
mark field for vision that the set

157
00:13:23,500 --> 00:13:25,330
is set of children

158
00:13:25,380 --> 00:13:39,310
of those parents was what they

159
00:13:39,350 --> 00:13:40,730
no everything

160
00:13:40,750 --> 00:13:42,870
everything is not

161
00:13:42,920 --> 00:13:45,980
so the probability of x i given the rest

162
00:13:45,980 --> 00:13:49,460
is equal to the probability of x i given something else

163
00:13:49,580 --> 00:13:54,000
what's the smallest something elsewhere which is correct

164
00:13:55,100 --> 00:13:58,600
and this is the answer

165
00:13:58,770 --> 00:14:01,980
well why is this well

166
00:14:01,980 --> 00:14:06,480
the first thing you should realize all these thing is just before the separation

167
00:14:09,330 --> 00:14:10,580
if you want

168
00:14:10,600 --> 00:14:13,500
to the separate

169
00:14:14,960 --> 00:14:17,330
is no

170
00:14:17,400 --> 00:14:19,940
from the remember this separation is

171
00:14:19,960 --> 00:14:23,040
it represents conditionally independent

172
00:14:24,110 --> 00:14:26,600
it is independent of the

173
00:14:26,650 --> 00:14:31,330
you can see in a directed graph in the sense that he separated from

174
00:14:33,230 --> 00:14:38,100
you want to find which is the minimal set separate

175
00:14:38,100 --> 00:14:39,460
x i

176
00:14:40,440 --> 00:14:41,670
the rest

177
00:14:42,480 --> 00:14:45,270
and it's obvious that band

178
00:14:45,290 --> 00:14:47,520
why because all the

179
00:14:47,560 --> 00:14:50,020
all the that's the goal

180
00:14:50,020 --> 00:14:53,790
they were the parents of the more exciting what

181
00:14:54,880 --> 00:14:56,500
those that be

182
00:14:56,500 --> 00:15:00,580
the field had the

183
00:15:01,000 --> 00:15:04,080
the children is also because any

184
00:15:04,080 --> 00:15:05,670
possible that

185
00:15:05,730 --> 00:15:07,710
that connect children

186
00:15:09,440 --> 00:15:11,210
with the

187
00:15:11,250 --> 00:15:13,440
with exercise

188
00:15:13,520 --> 00:15:14,690
which is

189
00:15:14,710 --> 00:15:20,540
how can you have two had or has failed if that fails it's OK

190
00:15:20,580 --> 00:15:23,480
if it were head to head

191
00:15:23,580 --> 00:15:26,690
and if you don't have to call council so

192
00:15:26,750 --> 00:15:28,940
that was

193
00:15:28,940 --> 00:15:30,500
well the block

194
00:15:30,560 --> 00:15:32,960
his whole

195
00:15:33,420 --> 00:15:38,020
those that people are so notable that we block to ensure

196
00:15:39,850 --> 00:15:41,850
CORP and also

197
00:15:42,540 --> 00:15:48,650
the minimal set due to conditional so that make sure that your conditional distributions to

198
00:15:48,670 --> 00:15:49,560
to the

199
00:15:49,560 --> 00:15:51,790
the conditional distribution

200
00:15:51,810 --> 00:15:53,500
the that's for the

201
00:15:55,690 --> 00:16:01,480
will be a simple way to explain the complicated explain just the algebra

202
00:16:02,330 --> 00:16:05,960
you know that p

203
00:16:07,060 --> 00:16:08,980
x y

204
00:16:13,060 --> 00:16:15,310
is equal to p

205
00:16:17,710 --> 00:16:19,290
x i

206
00:16:19,290 --> 00:16:21,460
x not i

207
00:16:21,560 --> 00:16:23,880
divided by p of x

208
00:16:29,460 --> 00:16:32,850
these nominator is the sum

209
00:16:33,900 --> 00:16:36,690
x y

210
00:16:36,730 --> 00:16:38,670
of the of x y

211
00:16:38,710 --> 00:16:42,370
next modernization

212
00:16:42,440 --> 00:16:44,870
but this thing has two factors

213
00:16:44,870 --> 00:16:46,420
one factor

214
00:16:46,440 --> 00:16:48,370
that he bowls

215
00:16:48,370 --> 00:16:49,170
to get

216
00:16:49,180 --> 00:16:53,520
as close as possible as a random sequence

217
00:16:53,570 --> 00:16:56,130
the answer for full seven

218
00:16:56,150 --> 00:16:57,810
if you do

219
00:16:57,830 --> 00:17:01,530
normal this chef was used as you show normal

220
00:17:01,600 --> 00:17:04,450
but if you can show in many other ways

221
00:17:04,460 --> 00:17:07,980
you can show for for for example just changing talk of

222
00:17:07,980 --> 00:17:09,510
so you have that here

223
00:17:09,570 --> 00:17:11,870
of cards

224
00:17:11,930 --> 00:17:13,600
it just allowed to

225
00:17:13,670 --> 00:17:16,380
shuffle talk right time

226
00:17:16,390 --> 00:17:18,500
so you would have

227
00:17:18,510 --> 00:17:19,850
to model this

228
00:17:19,850 --> 00:17:22,030
you have the probability

229
00:17:24,020 --> 00:17:26,240
i j

230
00:17:26,300 --> 00:17:30,490
different from zero

231
00:17:35,320 --> 00:17:36,600
all the rest

232
00:17:40,570 --> 00:17:44,400
anything that's not transposition of those two cards

233
00:17:44,420 --> 00:17:46,080
because you're

234
00:17:46,110 --> 00:17:49,480
so you only have all of the

235
00:17:50,750 --> 00:17:54,030
anything that's allowed fish to shuffle two cards

236
00:17:54,090 --> 00:17:56,950
and then you go operating with this

237
00:17:58,200 --> 00:18:00,930
this function

238
00:18:00,940 --> 00:18:04,080
you do many many in iterated

239
00:18:05,600 --> 00:18:06,950
operations of that

240
00:18:06,960 --> 00:18:11,510
and then you ask how close you are to the uniform distribution

241
00:18:11,530 --> 00:18:12,560
in the end

242
00:18:12,600 --> 00:18:14,780
so we have these norm there

243
00:18:14,840 --> 00:18:18,530
in this case norm is called the covariance distance

244
00:18:18,590 --> 00:18:19,920
you can prove

245
00:18:20,000 --> 00:18:22,220
this sort of

246
00:18:22,230 --> 00:18:24,480
the sort of statement like

247
00:18:24,480 --> 00:18:30,420
how many how many cases you have to apply this

248
00:18:30,440 --> 00:18:38,220
to get close to normal distribution to add up to a random distribution uniform distribution

249
00:18:38,270 --> 00:18:41,480
so this is in general what you can do with

250
00:18:41,480 --> 00:18:42,680
if that

251
00:18:42,690 --> 00:18:45,590
we are transform groups

252
00:18:46,140 --> 00:18:48,320
yes transitions so

253
00:18:48,340 --> 00:18:51,210
it flips it shuffle

254
00:18:51,840 --> 00:18:55,050
you're willing to bet that the convolution is this

255
00:18:55,070 --> 00:18:58,820
but the bottom line want to estimate convergence

256
00:18:58,990 --> 00:19:05,310
in this case here some more general statement you can use always use symmetry two

257
00:19:05,320 --> 00:19:07,020
reduce the number of variables

258
00:19:07,030 --> 00:19:09,850
like for example in the case of the cuba showed before you don't need to

259
00:19:10,690 --> 00:19:14,080
to work with all the space of the kids can use with

260
00:19:14,120 --> 00:19:15,830
much much smaller

261
00:19:18,490 --> 00:19:21,470
o job this part here this is

262
00:19:21,510 --> 00:19:25,140
fastest mixing markov chain you not only can

263
00:19:25,200 --> 00:19:26,590
as for

264
00:19:26,680 --> 00:19:31,960
the the

265
00:19:31,970 --> 00:19:34,560
you know you use how

266
00:19:34,580 --> 00:19:36,870
how you can count

267
00:19:36,920 --> 00:19:39,110
how how many operations you need

268
00:19:39,130 --> 00:19:40,750
in the mean

269
00:19:40,810 --> 00:19:42,770
the mean number of persons in need to

270
00:19:44,190 --> 00:19:46,380
the back of cards

271
00:19:46,440 --> 00:19:48,820
is it can model is a markov chain

272
00:19:48,880 --> 00:19:51,940
and you can ask as well what is the

273
00:19:51,960 --> 00:19:55,840
fastest mixing instead of establishing

274
00:19:55,880 --> 00:19:57,930
what what is your

275
00:19:58,720 --> 00:20:01,120
your procedure you're shuffling

276
00:20:01,130 --> 00:20:03,710
you can ask which shuffling will give me

277
00:20:03,720 --> 00:20:05,710
the fastest mixing

278
00:20:05,760 --> 00:20:09,450
how do i get there uniform transition as fast as they can

279
00:20:09,490 --> 00:20:12,600
you can use you can reduce the number

280
00:20:13,440 --> 00:20:17,610
of variables in the search space

281
00:20:17,630 --> 00:20:19,380
so you have

282
00:20:19,520 --> 00:20:24,720
an efficient way to calculate

283
00:20:24,730 --> 00:20:28,720
so here's the formula for the inverse

284
00:20:28,770 --> 00:20:31,890
of the transform this is the case now

285
00:20:31,890 --> 00:20:34,480
no it's OK it's written there as us

286
00:20:34,500 --> 00:20:37,510
as for continuous groups

287
00:20:37,560 --> 00:20:39,490
and i mean in in

288
00:20:39,500 --> 00:20:43,900
in my mind and the next steps will specialize was formal

289
00:20:43,900 --> 00:20:46,470
for the rotation

290
00:20:46,520 --> 00:20:48,390
which is by

291
00:20:48,480 --> 00:20:50,180
will use it

292
00:20:50,230 --> 00:20:53,840
representations of the rotation group

293
00:20:53,890 --> 00:20:54,720
you probably

294
00:20:54,740 --> 00:20:58,510
you can learn this with this naming

295
00:20:59,490 --> 00:21:02,750
sort of wording

296
00:21:02,770 --> 00:21:03,930
but they are

297
00:21:03,930 --> 00:21:08,720
representation i guess everybody knows what are the representations of the

298
00:21:08,730 --> 00:21:11,160
rotation group

299
00:21:11,200 --> 00:21:16,320
you guys probably know the spherical harmonics

300
00:21:16,370 --> 00:21:19,720
well the spherical harmonics

301
00:21:26,930 --> 00:21:29,240
no much this is right

302
00:21:33,790 --> 00:21:34,680
this for

303
00:21:34,680 --> 00:21:39,080
can you read that first probably be the

304
00:21:39,800 --> 00:21:45,070
so it actually when you look at the expansion of the function

305
00:21:46,550 --> 00:21:49,070
in terms of spherical harmonics

306
00:21:49,110 --> 00:21:51,010
which is these y

307
00:21:54,670 --> 00:21:57,970
this is actually a four-year spansion

308
00:21:58,050 --> 00:21:59,220
of the

309
00:21:59,220 --> 00:22:00,370
of the function

310
00:22:00,390 --> 00:22:01,480
and you get

311
00:22:01,490 --> 00:22:03,640
description efficient here

312
00:22:03,690 --> 00:22:06,370
f l and

313
00:22:06,390 --> 00:22:07,170
these are

314
00:22:08,980 --> 00:22:12,630
four here transform

315
00:22:12,670 --> 00:22:17,570
for set index unbiased representation

316
00:22:17,660 --> 00:22:19,680
it's you can read these

317
00:22:20,090 --> 00:22:23,680
no standard interest for you

318
00:22:23,690 --> 00:22:27,940
as the wave number you remember when you do a one-dimensional thing

319
00:22:28,010 --> 00:22:30,930
the composer signal into the

320
00:22:30,970 --> 00:22:32,420
and mornings

321
00:22:32,430 --> 00:22:34,670
which is the frequencies contained

322
00:22:34,680 --> 00:22:36,670
in that signal

323
00:22:36,720 --> 00:22:38,490
you have a sound

324
00:22:38,550 --> 00:22:43,480
you the composed these in all monarchs first harmonic second one

325
00:22:43,520 --> 00:22:45,070
and so on

326
00:22:45,080 --> 00:22:48,520
this index is in this case is indexed by just the number which is the

327
00:22:52,830 --> 00:22:53,950
but for the

328
00:22:53,950 --> 00:22:57,130
in the case of the text fea you have two indexes

329
00:22:57,210 --> 00:22:58,780
but still

330
00:22:58,830 --> 00:22:59,990
you know those

331
00:23:00,670 --> 00:23:02,700
the case of one dimensional thing

332
00:23:02,710 --> 00:23:08,220
you have the wave number it's associated with this and signed course of

333
00:23:08,270 --> 00:23:11,410
and here those indexes

334
00:23:11,820 --> 00:23:16,720
those indexes are related to these functions here

335
00:23:16,730 --> 00:23:19,360
which replaced the sine and cosine

336
00:23:19,400 --> 00:23:22,510
forty six c

337
00:23:22,530 --> 00:23:24,910
so you can always represent the function

338
00:23:24,910 --> 00:23:29,810
using this fourier components here

339
00:23:29,870 --> 00:23:31,180
this is the open

340
00:23:33,260 --> 00:23:36,490
if you opened this expression you have this thing here

341
00:23:36,500 --> 00:23:37,510
this is the

342
00:23:37,520 --> 00:23:40,380
fourier transform

343
00:23:40,380 --> 00:23:43,990
this is just what i world war

344
00:23:44,080 --> 00:23:45,810
but the

345
00:23:45,860 --> 00:23:48,680
this is the forward fourier transforms

346
00:23:48,690 --> 00:23:53,080
and this is things works right

347
00:23:53,310 --> 00:23:55,930
this here just explain what is the

348
00:23:55,930 --> 00:23:57,530
or am

349
00:23:57,550 --> 00:23:59,010
of the right

350
00:24:09,350 --> 00:24:12,180
so we see that

351
00:24:12,180 --> 00:24:13,950
can you imagine of x

352
00:24:13,950 --> 00:24:17,970
every node i just have to look at what the maximum here was the maximum

353
00:24:17,970 --> 00:24:22,090
here with the what's the high point of the interval

354
00:24:22,100 --> 00:24:24,200
which everyone one is those is largest

355
00:24:24,220 --> 00:24:26,910
that's the largest

356
00:24:27,160 --> 00:24:40,120
that's subtree

357
00:24:45,140 --> 00:24:46,910
modifying operations

358
00:24:46,970 --> 00:24:59,160
OK so let's first to insert

359
00:25:01,990 --> 00:25:06,100
how can i do insert

360
00:25:06,120 --> 00:25:07,910
OK so the two parts

361
00:25:07,930 --> 00:25:10,550
the first part is to do the tree insert

362
00:25:10,600 --> 00:25:23,050
just the normal insert into a binary search tree

363
00:25:23,100 --> 00:25:28,590
but i do

364
00:25:28,680 --> 00:25:47,160
concerning you have all

365
00:25:47,260 --> 00:25:49,350
through new are linear

366
00:25:49,350 --> 00:25:54,820
how can i fix up the ems

367
00:25:54,870 --> 00:26:05,050
that's right you just go down the tree

368
00:26:05,140 --> 00:26:06,280
go down the tree

369
00:26:06,280 --> 00:26:08,990
and look at my current interval

370
00:26:09,030 --> 00:26:13,530
and it's got bigger max this is something is going into that subtree

371
00:26:13,570 --> 00:26:15,720
xavier's high endpoint

372
00:26:15,740 --> 00:26:19,200
is bigger than the current max update the current max

373
00:26:19,260 --> 00:26:23,280
just do that as i'm going through the insertion wherever it happens to land in

374
00:26:23,280 --> 00:26:25,160
every subtree that is this

375
00:26:25,160 --> 00:26:28,930
we know that it's on the way down i just updated

376
00:26:30,470 --> 00:26:32,680
the the

377
00:26:32,680 --> 00:26:35,220
you know with the maximum wherever it happens to

378
00:26:35,240 --> 00:26:39,470
whatever happens to fall

379
00:26:41,820 --> 00:26:43,050
OK good

380
00:26:43,070 --> 00:26:47,220
so i suggest you just fix them on the way down

381
00:26:53,890 --> 00:26:57,850
but we also have to do the other second can also

382
00:26:57,870 --> 00:27:02,390
you we need to handle

383
00:27:13,470 --> 00:27:17,780
let's just see how we might do rotations

384
00:27:26,430 --> 00:27:30,830
so let's say this is an eleven fifteen

385
00:27:33,550 --> 00:27:45,200
that's a right rotation

386
00:27:45,280 --> 00:27:50,350
the school offers more

387
00:28:03,680 --> 00:28:05,370
this is still be the

388
00:28:05,390 --> 00:28:10,850
child has thirty that one has fourteen one has nineteen

389
00:28:12,140 --> 00:28:13,010
so now

390
00:28:13,030 --> 00:28:13,800
this is

391
00:28:13,800 --> 00:28:16,740
we wrote it this way so this is the last fifteen

392
00:28:16,780 --> 00:28:18,050
and this is the

393
00:28:18,070 --> 00:28:19,490
six one

394
00:28:22,720 --> 00:28:24,620
this one i look at

395
00:28:24,660 --> 00:28:27,510
this is my formula here

396
00:28:28,050 --> 00:28:32,240
is look here and say which is the biggest fourteen fifteen nineteen

397
00:28:33,820 --> 00:28:37,740
i look here which is the biggest thirty nineteen or twenty

398
00:28:38,890 --> 00:28:41,180
where once again it turns out

399
00:28:42,030 --> 00:28:43,240
not too hard to show

400
00:28:43,260 --> 00:28:45,600
it's always whatever

401
00:28:45,660 --> 00:28:48,990
was there because we're talking about the biggest thing in the subtree

402
00:28:49,010 --> 00:28:53,890
in the membership the subtree hasn't changed into the rotation

403
00:28:56,070 --> 00:29:01,280
so that just took or one time to fix up

404
00:29:01,280 --> 00:29:04,710
they are all generated at random

405
00:29:04,730 --> 00:29:11,940
independently with probability fate is being one of my claim is this is the formula

406
00:29:12,770 --> 00:29:16,250
the probability of the sequence b

407
00:29:16,270 --> 00:29:21,260
when theta is the parameter that generated the data well that's

408
00:29:21,280 --> 00:29:23,260
very simple

409
00:29:24,930 --> 00:29:26,610
what we have

410
00:29:26,620 --> 00:29:31,500
so first the most important thing is first of all these big product the product

411
00:29:31,500 --> 00:29:34,020
comes from the independent so one of the building

412
00:29:34,450 --> 00:29:39,680
blocks is always if you think that something is generated independently at random so you

413
00:29:39,680 --> 00:29:45,050
have to form a product of the individual probabilities so this should then be the

414
00:29:45,050 --> 00:29:49,590
probability that

415
00:29:49,610 --> 00:29:50,540
we have

416
00:29:50,550 --> 00:29:53,180
generated x i

417
00:29:53,930 --> 00:29:58,390
well what is this if x i is equal to one

418
00:29:58,400 --> 00:30:02,470
then this should be the probability of being one should be

419
00:30:02,520 --> 00:30:07,590
actually fate well to the power of one estate o one minus a ten to

420
00:30:07,590 --> 00:30:12,330
the power of zero is one any from the other hand we had

421
00:30:12,350 --> 00:30:14,060
x equals zero

422
00:30:14,080 --> 00:30:15,820
and this would be a one

423
00:30:16,040 --> 00:30:20,740
and we would have a one minus zero is zero so the probability for zero

424
00:30:20,740 --> 00:30:26,230
would be one minus status so it's just another way of writing that the probability

425
00:30:26,230 --> 00:30:26,760
for x

426
00:30:27,200 --> 00:30:30,170
being one

427
00:30:30,180 --> 00:30:33,440
it would be for a time in the probability for x

428
00:30:33,450 --> 00:30:40,660
i will zero would be one minus data suggest a simple way of writing that

429
00:30:40,670 --> 00:30:43,900
so this is the probability for the data

430
00:30:44,770 --> 00:30:46,430
the parameter theta

431
00:30:46,540 --> 00:30:50,110
so we can view this whole thing as a function of two objects we can

432
00:30:50,110 --> 00:30:52,520
view it as a function of the axes

433
00:30:52,570 --> 00:30:57,030
but let's say we have a fixed dataset so these axes are fixed numbers did

434
00:30:57,030 --> 00:31:00,690
not variables anymore fixed numbers but

435
00:31:00,750 --> 00:31:05,100
we can view this object as a function of status so it's a function of

436
00:31:05,100 --> 00:31:09,920
theta for fixed data and this function is called the likelihood function

437
00:31:10,540 --> 00:31:12,570
and we can use

438
00:31:14,130 --> 00:31:15,820
this likelihood function

439
00:31:15,830 --> 00:31:22,760
in order to try to estimate the parameter theta under which these data were generated

440
00:31:22,800 --> 00:31:27,070
because we don't know we just see that the data our model is that this

441
00:31:27,070 --> 00:31:31,770
is the generating mechanism for the data so the question is

442
00:31:31,780 --> 00:31:36,630
it has a free parameter theta what should be the right parameter so one assumption

443
00:31:36,650 --> 00:31:42,870
is a good estimator might be the maximum likelihood estimator and the maximum likelihood estimator

444
00:31:42,930 --> 00:31:50,400
is the one that is defined as making this likelihood of the entire sequence

445
00:31:50,450 --> 00:31:52,490
most probable

446
00:31:52,500 --> 00:31:55,670
sorry for making this data

447
00:31:55,720 --> 00:32:02,090
the probability for the data making these the observed data most probable so we tune

448
00:32:02,110 --> 00:32:03,080
this we

449
00:32:03,090 --> 00:32:10,880
take different values for fate and take the one that makes this probability largest so

450
00:32:10,930 --> 00:32:16,850
this would be considered as the most likely parameter having seen the data

451
00:32:17,010 --> 00:32:21,010
so of course it sounds very much like a principle and we should ask later

452
00:32:21,720 --> 00:32:24,040
in what sense might this be a good idea

453
00:32:24,050 --> 00:32:26,200
the first all sounds nice right

454
00:32:26,870 --> 00:32:29,660
what you see should be most probable

455
00:32:30,050 --> 00:32:34,680
otherwise it's not most probably would actually think what you see is very untypical right

456
00:32:34,680 --> 00:32:38,220
i mean so you believe you have to come up with the data that makes

457
00:32:39,390 --> 00:32:45,730
not an untypical event that very typical one i probability then so technically what you

458
00:32:45,730 --> 00:32:49,800
have to do is you have to maximize such an object usually would take the

459
00:32:49,800 --> 00:32:53,300
derivative with respect to data and set it equal to zero

460
00:32:53,320 --> 00:32:59,390
just to get a maximum or a local extremum and well typically well if you

461
00:32:59,390 --> 00:33:04,620
have a product it's usually with you differentiate it's much nicer to deal with some

462
00:33:04,620 --> 00:33:08,180
rather than products of people take the logarithm

463
00:33:08,640 --> 00:33:13,990
it's also nice for another reason because if you have a product you multiply things

464
00:33:14,360 --> 00:33:20,140
so things can be sort of becoming exponentially small in n or exponentially large well

465
00:33:20,340 --> 00:33:24,560
this is probability is probably becoming exponentially small so if you take the logo bit

466
00:33:24,900 --> 00:33:30,120
it's usually a manageable number so if i take a look at this object i

467
00:33:30,120 --> 00:33:31,250
would end up

468
00:33:31,260 --> 00:33:32,770
precisely with that

469
00:33:32,780 --> 00:33:36,340
line and if you think a little bit

470
00:33:36,390 --> 00:33:40,380
that these axes or zero and one

471
00:33:41,190 --> 00:33:46,390
if you have just if you count how many ones you have because the zeros

472
00:33:46,390 --> 00:33:50,480
are not counted at all if you just have zeros for axes in the summer

473
00:33:50,480 --> 00:33:56,130
the zeros are not counted up to zero but here it counts the ones

474
00:33:56,260 --> 00:33:58,340
so if you take the sum

475
00:33:58,410 --> 00:34:02,820
and then you get ten times logs data in one because in one is the

476
00:34:02,820 --> 00:34:04,890
number of ones in the sequence

477
00:34:05,030 --> 00:34:06,280
in this other

478
00:34:06,290 --> 00:34:13,390
objective one minus XI discounts to zeros because effect size zero then this counts one

479
00:34:13,530 --> 00:34:17,200
and so you get in minus and one which is the

480
00:34:17,240 --> 00:34:21,790
zero so this is your likelihood you log likelihood

481
00:34:21,800 --> 00:34:23,340
and he would like to

482
00:34:23,350 --> 00:34:29,420
sort of take the derivative of this object set it equal to zero

483
00:34:29,490 --> 00:34:32,570
and let's see that i do that probably in the next

484
00:34:35,060 --> 00:34:37,550
now let's do it

485
00:34:37,560 --> 00:34:40,300
there's an exercise so we just take

486
00:34:40,310 --> 00:34:42,570
in one

487
00:34:42,590 --> 00:34:45,820
ah logbn eight plus

488
00:34:46,530 --> 00:34:53,180
minus in one look one minus eight i take the derivative

489
00:34:53,190 --> 00:34:55,940
so i take the derivative with respect to theta

490
00:34:57,210 --> 00:35:00,430
the data so

491
00:35:00,440 --> 00:35:03,730
look for data gives me an innovative data

492
00:35:03,750 --> 00:35:07,320
and here i get in

493
00:35:07,340 --> 00:35:10,650
minus in one i get the minus sign from this

494
00:35:10,730 --> 00:35:16,260
and i get a one minus and this should be equal to zero so the

495
00:35:16,260 --> 00:35:19,310
only thing we have to do is we should

496
00:35:19,720 --> 00:35:27,830
solve this with respect to one minus with respect to data so

497
00:35:27,840 --> 00:35:31,280
well i could multiply this by data site would get

498
00:35:31,550 --> 00:35:33,810
ten times

499
00:35:34,600 --> 00:35:40,680
one time state is equal

500
00:35:41,020 --> 00:35:45,380
it is here that i multiply the whole thing by one minus eight

501
00:35:45,390 --> 00:35:50,800
so i should get this is equal to zero so let's collect all the theatres

502
00:35:50,850 --> 00:35:53,120
so what i haven't actually

503
00:35:53,130 --> 00:35:56,380
practice that but it should always come out

504
00:35:56,430 --> 00:36:03,600
so you get an and i get a

505
00:36:03,600 --> 00:36:06,810
measuring the magnetic field which is induced by that

506
00:36:07,360 --> 00:36:11,070
about by electrical currents in the in the brain

507
00:36:14,240 --> 00:36:15,860
yes it is

508
00:36:15,880 --> 00:36:17,680
pictures are taken from

509
00:36:18,340 --> 00:36:21,090
some article and i a bicycle what

510
00:36:21,100 --> 00:36:25,210
what what what what they're trying to represent that i'm sure is very deep

511
00:36:25,260 --> 00:36:29,620
but of course then the point is that when you have a single sentence at

512
00:36:29,620 --> 00:36:30,690
some point

513
00:36:30,710 --> 00:36:32,920
on the head then

514
00:36:32,970 --> 00:36:38,590
you can it is reasonable to assume that it receives signals from many different places

515
00:36:38,590 --> 00:36:41,400
in the brain and perhaps these

516
00:36:41,440 --> 00:36:46,250
this is activity in the brain is small less can always be divided into you

517
00:36:46,250 --> 00:36:49,640
know a limited number of discrete sources

518
00:36:49,650 --> 00:36:54,630
so you have a limited number of seats source signals mixed in the

519
00:36:54,900 --> 00:37:01,670
each of these measurements

520
00:37:02,410 --> 00:37:08,010
here's kind of illustration of what what this is an easy machine looks like it's

521
00:37:08,010 --> 00:37:12,250
like an extremely big tank and then use it on the on the input you

522
00:37:12,250 --> 00:37:14,150
hate there

523
00:37:14,200 --> 00:37:19,110
but it's the nice thing is that you don't like needed complicated preparations you just

524
00:37:19,110 --> 00:37:24,350
stick your head in there and then you start measuring and do the thing measures

525
00:37:24,360 --> 00:37:29,240
different kinds of stuff at at the each of the four it's of points actually

526
00:37:29,240 --> 00:37:32,680
i think it gives a three-dimensional signal in each of those

527
00:37:32,690 --> 00:37:35,320
in each of those two hundred twenty two

528
00:37:35,700 --> 00:37:39,910
sensors on the head actually there are now also measurement devices that have more than

529
00:37:39,910 --> 00:37:43,430
two hundred percent

530
00:37:43,440 --> 00:37:46,470
so this is the thing that i showed in the very beginning

531
00:37:46,480 --> 00:37:48,950
here is the number of measurements

532
00:37:49,000 --> 00:37:54,870
given by by immediately so here we have only a few of those not of

533
00:37:54,870 --> 00:37:58,590
the one hundred and so on but so what we can see is that clearly

534
00:37:58,590 --> 00:38:01,050
we have some kind of mixing happening here

535
00:38:01,430 --> 00:38:06,670
we have like these phenomena that like spikes like this and spikes like this they

536
00:38:06,670 --> 00:38:10,990
can be seen in many different senses

537
00:38:12,260 --> 00:38:17,030
and so it is reasonable to assume that you might have something like a linear

538
00:38:17,030 --> 00:38:22,130
mixing well actually there are physical reasons for thinking that the meeting is linear because

539
00:38:22,130 --> 00:38:27,260
in these electrical signals will be more-or-less some together

540
00:38:27,270 --> 00:38:29,540
and then when you do i see

541
00:38:29,570 --> 00:38:32,730
what you get is something like this

542
00:38:32,770 --> 00:38:38,340
well actually what happens is this

543
00:38:38,350 --> 00:38:42,660
a bit not not exactly what you expect it you will get some so signals

544
00:38:42,660 --> 00:38:49,300
that that's really do correspond to the seeds of certain has specific physicality

545
00:38:49,340 --> 00:38:54,130
signal sources but they are not usually they're actually in the brain they are something

546
00:38:54,130 --> 00:38:59,400
that's outside outside of the brain on the in the head or maybe somewhere for

547
00:39:00,550 --> 00:39:04,530
this is this signal here

548
00:39:05,560 --> 00:39:08,890
quite well separated by ICA

549
00:39:08,900 --> 00:39:12,000
and it is about eye movements

550
00:39:12,010 --> 00:39:16,420
the muscles in the eye when more they really do certain kinds of electrical signals

551
00:39:16,420 --> 00:39:18,230
that sensors to capture

552
00:39:18,240 --> 00:39:21,510
and then

553
00:39:21,530 --> 00:39:26,680
this thing down here it's also pretty well separated but it's actually signals coming from

554
00:39:26,680 --> 00:39:31,330
a digital watch that in the in the rest of the of the person

555
00:39:31,340 --> 00:39:32,650
of the subject

556
00:39:32,660 --> 00:39:34,440
and in the same way here

557
00:39:34,450 --> 00:39:37,860
it's actually the heart beat of the subject

558
00:39:37,900 --> 00:39:43,340
and there are a couple of signals which correspond to the activity of the jaw

559
00:39:43,340 --> 00:39:46,570
muscles because actually at this point of time

560
00:39:46,590 --> 00:39:50,540
the the subject was told to bytes

561
00:39:50,590 --> 00:39:55,810
and so these muscles suddenly started strong strongest of activity

562
00:39:55,820 --> 00:40:01,030
so what you see in the in the beginning of people wanted know like separate

563
00:40:01,030 --> 00:40:05,930
brain activity into different components but what happens is that you actually doing something some

564
00:40:05,930 --> 00:40:12,030
kind of perhaps something like noise reduction here so you get these signals like heartbeat

565
00:40:12,030 --> 00:40:16,430
but you are certainly not interested in analyzing with human brain and so but if

566
00:40:16,430 --> 00:40:20,200
you are able to make so separate them like this then it means that you

567
00:40:20,200 --> 00:40:22,030
can remove them from the data

568
00:40:22,040 --> 00:40:29,280
and then you have like with a measurements of brain act

569
00:40:29,360 --> 00:40:34,750
actually there are like this i artifacts for example they are very annoying because they're

570
00:40:35,230 --> 00:40:39,380
the amplitude is much larger than the amplitude of the brain activity so there are

571
00:40:39,380 --> 00:40:43,470
actually a number of methods developed for getting rid of them

572
00:40:43,510 --> 00:40:46,670
so i see it seems to do something rather it

573
00:40:46,960 --> 00:40:49,260
but what you can do is

574
00:40:49,280 --> 00:40:54,070
it's really you can actually get into the brain activity itself when you talk about

575
00:40:54,170 --> 00:40:59,020
when you measure evoked magnetic fields that means that there's some kind of stimulus that

576
00:40:59,070 --> 00:41:03,920
comes into the brain and then you measure the activity that is evoked by the

577
00:41:03,920 --> 00:41:09,390
stimulus just after the arrival so as demons means for example in order to be

578
00:41:09,770 --> 00:41:11,230
that you here

579
00:41:12,720 --> 00:41:17,080
it can be also you know some something happening on the video screen which received

580
00:41:17,080 --> 00:41:19,650
by your eyes

581
00:41:19,660 --> 00:41:23,720
so i'm going to be there's also because i know them so this is all

582
00:41:23,760 --> 00:41:28,790
work by by the kind of the big idea and co-workers

583
00:41:28,800 --> 00:41:35,960
but what you do get you we have some simple results were so for comparison

584
00:41:35,980 --> 00:41:43,310
they have computed the the principal components of this potentials and then the independent components

585
00:41:43,310 --> 00:41:44,970
of the potentials

586
00:41:44,990 --> 00:41:52,750
well one thing to notice that these principal components don't have any any physiological localization

587
00:41:52,750 --> 00:41:59,160
because after computed some components from the signal you can actually measure where

588
00:41:59,540 --> 00:42:04,330
that kind of signal should come from if it comes from a single if comes

589
00:42:04,330 --> 00:42:08,110
from a single single so single place in the brain and it happens that all

590
00:42:08,110 --> 00:42:10,760
principal components that doesn't really work

591
00:42:10,780 --> 00:42:13,260
they don't seem to come from any single

592
00:42:13,270 --> 00:42:18,120
a place in the brain is the independent components are localized in the sense that

593
00:42:18,120 --> 00:42:22,510
you can actually really show that the that that kind of fields

594
00:42:22,770 --> 00:42:26,710
that measured fields can be produced by activity in the scene

595
00:42:26,750 --> 00:42:28,770
small point in the brain

596
00:42:29,050 --> 00:42:33,160
and he said that well and is the working hypothesis of most of the brain

597
00:42:34,100 --> 00:42:35,320
in this area

598
00:42:35,340 --> 00:42:39,720
that's the that you actually have like small very small

599
00:42:39,730 --> 00:42:43,620
o point light source in the brain that are active now and

600
00:42:43,620 --> 00:42:45,020
the drivers

601
00:42:45,020 --> 00:42:50,640
this action potential is the energy has been stored up

602
00:42:50,670 --> 00:42:57,030
in these concentration gradients concentration gradient is a form of energy

603
00:42:57,030 --> 00:42:58,120
why is that

604
00:42:59,610 --> 00:43:01,780
if there was no membrane there

605
00:43:01,780 --> 00:43:02,840
what would be

606
00:43:02,900 --> 00:43:06,130
the concentration on the inside and the outside

607
00:43:06,140 --> 00:43:09,860
the same there would be inside and outside the not so expensive those edges drilled

608
00:43:09,860 --> 00:43:11,300
holes in the memory

609
00:43:11,310 --> 00:43:15,220
you know one july holes it'll all equally bright

610
00:43:15,890 --> 00:43:20,220
you know because just by diffusion there will will go to the instructor with no

611
00:43:20,220 --> 00:43:24,830
entropy will sit in it will be equal concentrations if i want to establish concentration

612
00:43:24,830 --> 00:43:29,550
gradient and i have to work against entropy that takes energy here

613
00:43:29,550 --> 00:43:33,760
and that is a form of energy that i had to put work into moving

614
00:43:33,760 --> 00:43:37,910
ions around in order to establish concentration gradient

615
00:43:38,870 --> 00:43:41,870
who's in charge of carrying out that work

616
00:43:41,920 --> 00:43:43,940
who is it that sets up

617
00:43:43,940 --> 00:43:46,800
these concentration gradients

618
00:43:46,810 --> 00:43:48,580
in the south

619
00:43:48,590 --> 00:43:54,040
membrane proteins

620
00:43:54,050 --> 00:43:56,250
certain membrane

621
00:43:57,540 --> 00:43:59,340
in particular

622
00:43:59,360 --> 00:44:02,280
membrane transporters

623
00:44:03,910 --> 00:44:07,810
involved so we're going to talk about transporters

624
00:44:07,850 --> 00:44:14,300
and then we'll talk about some channels

625
00:44:19,970 --> 00:44:23,780
the first one

626
00:44:23,870 --> 00:44:25,700
there is

627
00:44:25,700 --> 00:44:27,490
and a c

628
00:44:42,440 --> 00:44:49,280
any ideas what an ATP driven sodium potassium pumps does

629
00:44:49,290 --> 00:44:55,420
set of how does it set up a constellation gradient

630
00:44:55,450 --> 00:44:57,270
so what is the problem

631
00:44:58,740 --> 00:45:00,740
it pumps a sodium

632
00:45:00,900 --> 00:45:03,040
a proper sodium in or out

633
00:45:03,060 --> 00:45:05,190
pumps sodium out

634
00:45:05,260 --> 00:45:09,400
it comes

635
00:45:09,450 --> 00:45:11,250
potassium in

636
00:45:11,270 --> 00:45:14,700
and it does it as an even exchange

637
00:45:14,720 --> 00:45:19,770
what i would like to do it is an even exchange one sodium for potassium

638
00:45:19,800 --> 00:45:23,810
charge conservation exactly so there is no electrical work to be done if it's what

639
00:45:23,810 --> 00:45:25,030
someone for one

640
00:45:25,040 --> 00:45:30,630
and is there were no to be done yes there is because obama pumps sodium

641
00:45:30,640 --> 00:45:32,260
out of the cell

642
00:45:32,270 --> 00:45:36,420
i'm doing it against the concentration gradient from once i get going i'm doing it

643
00:45:36,420 --> 00:45:38,910
against the concentration gradient so

644
00:45:38,940 --> 00:45:43,020
energy is needed to move the sodium out of the cell against its concentration gradient

645
00:45:43,020 --> 00:45:48,160
energy is also needed to move a potassium into the cell against its concentration gradient

646
00:45:48,230 --> 00:45:50,840
and where do we get the energy

647
00:45:51,870 --> 00:45:55,500
so when ATP is burned

648
00:45:55,550 --> 00:46:02,530
in order to do that this guy gets called and pipe order sometimes

649
00:46:02,540 --> 00:46:07,610
because it's an entire transport something like OK

650
00:46:07,640 --> 00:46:11,110
the pump that is an ATP is to use the energy

651
00:46:11,120 --> 00:46:14,270
from an ATP to exchange this guy that

652
00:46:15,970 --> 00:46:21,150
there is an eighty

653
00:46:23,830 --> 00:46:26,100
calcium pump

654
00:46:26,150 --> 00:46:30,080
for transport

655
00:46:30,090 --> 00:46:32,250
and as you might imagine

656
00:46:36,020 --> 00:46:38,590
what does it do

657
00:46:38,620 --> 00:46:40,450
it transports

658
00:46:40,480 --> 00:46:42,750
a calcium

659
00:46:42,760 --> 00:46:44,170
i am

660
00:46:44,280 --> 00:46:45,720
out of the cell

661
00:46:45,770 --> 00:46:51,420
and it happens not to do that in exchange for any other i

662
00:46:51,470 --> 00:46:52,690
and it's too

663
00:46:52,700 --> 00:46:55,790
it is driven by ATP

664
00:47:00,380 --> 00:47:04,260
we'll pom-pom pom pom pom pom pom pom pop keep

665
00:47:06,440 --> 00:47:11,410
will this thing to be able to keep going forever set up arbitrarily large concentration

666
00:47:12,400 --> 00:47:13,210
when i

667
00:47:13,210 --> 00:47:21,570
well with nothing to back it can we could keep going

668
00:47:21,580 --> 00:47:25,240
it gets harder to put stuff actually working up against the bigger and and bigger

669
00:47:25,240 --> 00:47:27,100
concentration gradient

670
00:47:27,160 --> 00:47:30,050
and the ATP is only going to give you so much energy

671
00:47:30,050 --> 00:47:31,850
so to certain point

672
00:47:31,910 --> 00:47:37,240
the burning of that ATP or however many ATP's uses for a specific mechanism won't

673
00:47:38,190 --> 00:47:41,760
so there's gonna be some natural upper bound to how far it could go in

674
00:47:41,760 --> 00:47:45,820
setting up the gradient because there's an actual amount of energy can spent

675
00:47:45,840 --> 00:47:50,320
OK do useful to think about these gradients as you work that you've got to

676
00:47:50,330 --> 00:47:52,390
do in the whole gets steeper sleep

677
00:47:52,440 --> 00:47:55,100
all right so that could in principle

678
00:47:56,820 --> 00:48:02,190
electrical gradient the concentration change across the cell but there's one other important component we

679
00:48:02,190 --> 00:48:03,770
have to think about

680
00:48:03,770 --> 00:48:05,500
and that

681
00:48:05,520 --> 00:48:10,300
is something called a resting

682
00:48:10,310 --> 00:48:12,920
potassium channel

683
00:48:12,950 --> 00:48:20,760
so what is the resting potassium channel

684
00:48:20,770 --> 00:48:23,100
the resting potassium channel

685
00:48:23,120 --> 00:48:25,450
is protein

686
00:48:25,490 --> 00:48:27,450
it's it's the membrane

687
00:48:27,470 --> 00:48:30,490
and it's got a whole

688
00:48:30,490 --> 00:48:32,060
a poor

689
00:48:33,710 --> 00:48:37,860
and that poor here

690
00:48:37,890 --> 00:48:43,040
it is designed so that was sodium can't escape through that port

691
00:48:43,080 --> 00:48:46,870
and you can imagine that some little bit of clever molecular architecture to make their

692
00:48:46,890 --> 00:48:49,810
sodium atom not be able to get sodium ion up here we get out the

693
00:48:50,040 --> 00:48:53,900
potassium might be able to get out of potassium ion

694
00:48:53,950 --> 00:48:55,480
i can get out

695
00:48:55,500 --> 00:48:57,960
this is a completely open door

696
00:48:58,070 --> 00:49:02,380
that allows potassium ions to escape

697
00:49:02,390 --> 00:49:04,450
isn't this stupid

698
00:49:04,460 --> 00:49:07,170
we just spent all this ATP

699
00:49:07,190 --> 00:49:10,720
getting potassium and sodium out

700
00:49:10,730 --> 00:49:14,360
and here i go opening the door for potassium saying you're free to leave despite

701
00:49:14,360 --> 00:49:18,310
all the all the work we put into bring you into the cells

702
00:49:18,370 --> 00:49:19,820
it makes no sense

703
00:49:19,830 --> 00:49:29,650
all passengers going to rush out

704
00:49:29,710 --> 00:49:32,130
can alter as in russia

705
00:49:32,160 --> 00:49:35,100
the concentration leading because which way

706
00:49:35,120 --> 00:49:39,420
it's more inside more potassium inside less outside so the test was going to rush

707
00:49:40,860 --> 00:49:46,130
o one electrical gradient

708
00:49:46,140 --> 00:49:50,720
if there is an electrical grid so maybe the beginning there is no electrical gradients

709
00:49:50,840 --> 00:49:55,260
so potassium rushes out what does it do

710
00:49:55,340 --> 00:49:57,940
makes more positive on the outside

711
00:49:58,060 --> 00:50:01,020
now the next passing wants to rush out

712
00:50:01,060 --> 00:50:02,840
and it's going

713
00:50:02,860 --> 00:50:05,400
down its concentration gradient

714
00:50:05,400 --> 00:50:07,260
so there's no

715
00:50:07,260 --> 00:50:13,480
local minima as in there's no maximum cell points and there's no local minima for

716
00:50:13,480 --> 00:50:14,900
convex functions

717
00:50:14,920 --> 00:50:17,830
which means that as soon as the gradient is zero

718
00:50:17,860 --> 00:50:22,020
then you have a global minimum

719
00:50:32,120 --> 00:50:35,600
i don't know what's next

720
00:50:35,690 --> 00:50:40,490
right so what's next is there is

721
00:50:40,860 --> 00:50:46,830
not in minimizing problem that that the problem of immunization that you might

722
00:50:46,840 --> 00:50:50,650
find in classification

723
00:50:53,230 --> 00:50:56,280
so it's a little bit complicated

724
00:50:56,300 --> 00:51:00,250
when you see that first so we could try to go through the steps ones

725
00:51:00,250 --> 00:51:01,710
one by one

726
00:51:01,720 --> 00:51:04,620
and what i wanted to show you

727
00:51:04,640 --> 00:51:06,200
that's too many

728
00:51:06,200 --> 00:51:07,870
encounter problems

729
00:51:07,890 --> 00:51:10,330
minimisation problems that are

730
00:51:11,530 --> 00:51:13,980
but was going to constraints

731
00:51:14,000 --> 00:51:19,620
and you're going to be able to use lagrange multipliers to introduce the contraints constraints

732
00:51:19,620 --> 00:51:20,850
in your problems

733
00:51:20,900 --> 00:51:27,620
and they in turn for these kinds of problems the minimisation the minimisation of the

734
00:51:27,850 --> 00:51:29,710
functions in the

735
00:51:29,750 --> 00:51:34,200
in the original variable will be equivalent to maximizing

736
00:51:34,210 --> 00:51:36,330
another function

737
00:51:36,360 --> 00:51:38,090
the dual valuable so

738
00:51:38,110 --> 00:51:43,430
people will talk about about prime prime all in dual problems

739
00:51:43,430 --> 00:51:45,280
and i learned from the two players

740
00:51:45,290 --> 00:51:49,800
that's just an example and i won't go into the security of all that i

741
00:51:49,800 --> 00:51:52,180
just show you this example

742
00:51:55,650 --> 00:51:59,100
here is my favourite classification task

743
00:51:59,120 --> 00:52:00,810
i have some inputs

744
00:52:00,820 --> 00:52:07,690
which are a couple of examples labels y i x y y i was why

745
00:52:07,690 --> 00:52:10,280
is one

746
00:52:10,360 --> 00:52:16,040
my goal is to find an

747
00:52:16,080 --> 00:52:18,380
linear superior

748
00:52:18,470 --> 00:52:20,950
that is going to be predicting

749
00:52:22,580 --> 00:52:25,220
the values of the labels

750
00:52:25,280 --> 00:52:26,850
so what i'm gonna

751
00:52:26,900 --> 00:52:30,040
training to find the best w

752
00:52:30,050 --> 00:52:35,350
so that the function

753
00:52:36,090 --> 00:52:38,970
and w of x

754
00:52:38,970 --> 00:52:42,770
as w and b of x

755
00:52:47,120 --> 00:52:52,470
so i'm afraid i'm trying to optimize for four wnb so that this function as

756
00:52:52,470 --> 00:52:56,030
WB best predicts the

757
00:52:56,040 --> 00:52:59,800
the right so what i really want

758
00:53:00,350 --> 00:53:05,820
be my empirical research is going to be the son

759
00:53:05,880 --> 00:53:09,200
of y i

760
00:53:11,180 --> 00:53:16,030
so why is different from

761
00:53:16,040 --> 00:53:20,220
so to predict the label i'm actually going to take it assigns so maybe it

762
00:53:20,220 --> 00:53:21,610
would be better if y

763
00:53:21,620 --> 00:53:26,710
if y is clearly minus one

764
00:53:28,340 --> 00:53:33,350
to predict the label of the new why i'm going to say that my prediction

765
00:53:33,440 --> 00:53:35,580
is the sign

766
00:53:35,590 --> 00:53:39,100
of as w ax

767
00:53:39,150 --> 00:53:46,780
then when i want to make sure that the and the empirical risk on my

768
00:53:46,780 --> 00:53:48,580
data is small

769
00:53:48,610 --> 00:53:50,460
empirical risk here

770
00:53:50,470 --> 00:54:02,320
is the sum

771
00:54:13,370 --> 00:54:25,330
of the indicator of whether my prediction as the good sign or not

772
00:54:25,340 --> 00:54:33,710
i six i have now

773
00:54:44,370 --> 00:54:52,090
and we're going to be trying to find the values that are as small as

774
00:54:53,040 --> 00:54:58,890
so basically instead of any meaning minimizing this as we're gonna require a rigour it

775
00:54:58,930 --> 00:55:04,680
so real problem is going to be to minimize on w and b

776
00:55:04,720 --> 00:55:08,210
the empirical loss

777
00:55:08,230 --> 00:55:20,300
leicester regularisation which says that w shouldn't be too big

778
00:55:20,310 --> 00:55:23,300
you need that because if you replace w by

779
00:55:23,310 --> 00:55:29,030
lambda times w and if the words equal to zero then you always have the

780
00:55:29,030 --> 00:55:30,170
same answer

781
00:55:30,180 --> 00:55:32,460
here in in terms of the size

782
00:55:33,040 --> 00:55:37,890
you know if you want to avoid that w goes to zero

783
00:55:37,940 --> 00:55:41,780
chris infinity and you have you have to regularize that

784
00:55:42,490 --> 00:55:44,350
and now

785
00:55:44,370 --> 00:55:49,600
well the thing that you have a there is a little bit different

786
00:55:49,610 --> 00:55:52,120
because what happens is that

787
00:55:52,180 --> 00:55:54,520
this function here

788
00:55:54,530 --> 00:55:57,870
as a function of w is not convex

789
00:55:58,750 --> 00:56:02,120
and since it's not convex it's not so easy to

790
00:56:02,180 --> 00:56:03,650
to minimize

791
00:56:03,690 --> 00:56:07,260
so we're going to be replacing this function here

792
00:56:09,630 --> 00:56:12,540
the the lost which is there

793
00:56:13,750 --> 00:56:17,000
so what you want to think about is that

794
00:56:17,050 --> 00:56:20,630
what you want to think is that

795
00:56:20,640 --> 00:56:32,430
if i plot here

796
00:56:33,830 --> 00:56:38,180
the product y i

797
00:56:38,190 --> 00:56:40,940
times the sign

798
00:56:54,770 --> 00:56:58,610
so i want to move to

799
00:56:59,460 --> 00:57:04,630
pay nothing if it was was things are of the same size so if this

800
00:57:04,630 --> 00:57:07,170
product is positive

801
00:57:07,170 --> 00:57:11,410
and i want to be one if this product is is used to have a

802
00:57:11,410 --> 00:57:12,930
different site

803
00:57:12,940 --> 00:57:14,820
so this function

804
00:57:14,820 --> 00:57:17,000
this this is not

805
00:57:17,040 --> 00:57:20,580
question to answer

806
00:57:20,680 --> 00:57:22,680
in fact it is undecidable

807
00:57:25,370 --> 00:57:28,990
now before i

808
00:57:29,700 --> 00:57:32,960
the next thing is to assign credit for

809
00:57:33,000 --> 00:57:35,020
so again from last year has

810
00:57:35,070 --> 00:57:38,430
only two possible truthful

811
00:57:38,430 --> 00:57:41,280
and let's assume we

812
00:57:41,340 --> 00:57:45,530
you know how to do so we we have more already

813
00:57:45,680 --> 00:57:50,070
we want to know where the former is true more under particles

814
00:57:50,080 --> 00:57:52,990
assign a

815
00:57:54,060 --> 00:57:58,150
so given to assignments a and b

816
00:57:58,190 --> 00:57:59,610
so far eight

817
00:57:59,630 --> 00:58:00,840
i said that

818
00:58:00,850 --> 00:58:04,480
b is an experiment of a

819
00:58:04,690 --> 00:58:09,690
agree on all variables except possibly x

820
00:58:09,870 --> 00:58:13,760
so they assigned the same terrible the same value

821
00:58:13,950 --> 00:58:16,550
every variable except possibly

822
00:58:16,570 --> 00:58:24,520
they can assign the same value to it

823
00:58:24,760 --> 00:58:26,720
it's just to

824
00:58:26,720 --> 00:58:30,150
simple to say that this is an operation under

825
00:58:30,160 --> 00:58:32,760
this interpretation by

826
00:58:32,780 --> 00:58:34,980
so you can equally used

827
00:58:39,650 --> 00:58:43,670
so you can see this simple

828
00:58:45,410 --> 00:58:47,820
by for example

829
00:58:47,840 --> 00:58:53,400
it's just a function that takes three arguments

830
00:58:53,410 --> 00:58:54,610
return t

831
00:58:54,630 --> 00:58:56,440
interpretation i

832
00:58:59,920 --> 00:59:01,600
it's kind of

833
00:59:01,630 --> 00:59:05,440
i function because i so much

834
00:59:05,440 --> 00:59:07,150
a seven

835
00:59:07,170 --> 00:59:15,030
to higher order function that takes three arguments

836
00:59:15,750 --> 00:59:20,790
again we assign truth table for

837
00:59:20,810 --> 00:59:21,920
we do it by

838
00:59:21,920 --> 00:59:23,790
inductive the

839
00:59:23,820 --> 00:59:27,450
examining on the basis for

840
00:59:27,460 --> 00:59:33,310
in the base case when you have the atomic formula which is formulation symbol

841
00:59:33,370 --> 00:59:34,860
and terms

842
00:59:34,910 --> 00:59:39,250
and we know already how to calculate the value of change

843
00:59:39,300 --> 00:59:41,800
we just have to show that

844
00:59:41,840 --> 00:59:44,050
the japan the top

845
00:59:44,060 --> 00:59:46,870
t one tn is a

846
00:59:46,960 --> 00:59:48,730
interpretation of

847
00:59:48,800 --> 00:59:52,670
the relationship people

848
00:59:54,050 --> 00:59:58,050
gets computing to central

849
00:59:58,110 --> 01:00:00,030
and this is point six

850
01:00:00,380 --> 01:00:05,400
it does seem a bit pointless because because white wine

851
01:00:05,450 --> 01:00:07,280
well like guess said logic

852
01:00:07,340 --> 01:00:12,100
a big part of logic is really starting form the state

853
01:00:12,120 --> 01:00:14,950
particle and this

854
01:00:14,950 --> 01:00:17,760
to see what you like

855
01:00:17,780 --> 01:00:19,330
ninety four

856
01:00:21,730 --> 01:00:23,760
so the variance

857
01:00:23,810 --> 01:00:26,190
is fair and the

858
01:00:27,220 --> 01:00:30,270
it's an experts they agree on every

859
01:00:33,130 --> 01:00:35,830
the interpretation of form

860
01:00:35,840 --> 01:00:37,230
base case

861
01:00:38,290 --> 01:00:40,330
interpreting atomic

862
01:00:40,350 --> 01:00:43,700
one is just simply checking whether

863
01:00:43,740 --> 01:00:45,200
topples terms

864
01:00:45,220 --> 01:00:49,050
i is in into the vision mission

865
01:00:49,100 --> 01:00:53,760
and the other connectives to propositional connectives standard so

866
01:00:54,080 --> 01:00:58,520
of a and b is true for all n

867
01:00:58,590 --> 01:01:02,960
oppose to the following is the truth assignment

868
01:01:02,960 --> 01:01:04,100
now four

869
01:01:04,120 --> 01:01:07,110
universal and existential quantifier

870
01:01:07,120 --> 01:01:08,980
we basically

871
01:01:09,020 --> 01:01:11,350
i have to check so for example

872
01:01:11,370 --> 01:01:14,780
the interpretation of full of xt

873
01:01:14,790 --> 01:01:15,870
have to check

874
01:01:15,880 --> 01:01:19,950
whether g is true for all possible values of x

875
01:01:20,000 --> 01:01:21,450
this is the notion

876
01:01:23,730 --> 01:01:28,530
so we can for this time the data and experiment

877
01:01:28,560 --> 01:01:32,040
which means that degree on other values except possibly

878
01:01:33,240 --> 01:01:36,040
change the range of

879
01:01:39,420 --> 01:01:41,240
if you can use

880
01:01:41,250 --> 01:01:43,940
i just think that this is the standard for

881
01:01:43,960 --> 01:01:47,290
state all the students in the class

882
01:01:50,300 --> 01:01:56,250
existential quantifiers of course to find these things the sixties

883
01:01:56,250 --> 01:01:59,180
experiment feel

884
01:01:59,190 --> 01:02:02,950
he is

885
01:02:04,840 --> 01:02:06,940
it's a model

886
01:02:06,970 --> 01:02:10,750
a formula is true in the model

887
01:02:10,820 --> 01:02:12,690
it's true of

888
01:02:14,530 --> 01:02:18,990
so it's true for all possible values for x

889
01:02:19,060 --> 01:02:21,100
and it is valid

890
01:02:21,110 --> 01:02:23,910
is true in all possible model

891
01:02:23,910 --> 01:02:25,800
it is found in

892
01:02:25,930 --> 01:02:28,910
this it is true no matter

893
01:02:28,950 --> 01:02:32,070
one interpretation two functions

894
01:02:32,090 --> 01:02:34,620
predicate symbols and because

895
01:02:37,860 --> 01:02:40,280
a formula is satisfiable

896
01:02:40,290 --> 01:02:43,260
well there's an assignment

897
01:02:43,260 --> 01:02:45,830
that's the true

898
01:02:45,830 --> 01:02:52,990
four very fine authenticity and things like that

899
01:02:57,320 --> 01:03:01,620
just he is an example where you have to fingerprints and to match them up

900
01:03:01,620 --> 01:03:03,550
and you check whether they

901
01:03:03,560 --> 01:03:05,670
are really sufficiently similar

902
01:03:05,710 --> 01:03:08,530
because fires belong to the same individual

903
01:03:08,580 --> 01:03:11,240
so i think that is small

904
01:03:11,250 --> 01:03:13,520
this is a feature of the input

905
01:03:13,570 --> 01:03:17,450
specific locations of this image on the left hand side

906
01:03:17,500 --> 01:03:22,080
the effect features in the right hand side and then my task is to match

907
01:03:22,130 --> 01:03:24,620
the features here with the features that

908
01:03:24,640 --> 01:03:26,370
OK if this match

909
01:03:26,380 --> 01:03:29,210
is a union sufficiently small

910
01:03:30,300 --> 01:03:31,790
the match

911
01:03:31,800 --> 01:03:34,850
according to some property definition of smoothness

912
01:03:34,860 --> 01:03:37,500
it's likely that

913
01:03:37,550 --> 01:03:41,720
these two fingerprints belong to the same but otherwise it's not

914
01:03:41,730 --> 01:03:45,250
so how do it so this is not problem

915
01:03:45,260 --> 01:03:49,120
so it seems to to be able to problem is that these are coming from

916
01:03:49,120 --> 01:03:50,000
because you have

917
01:03:50,040 --> 01:03:53,690
many points here that can match many points five

918
01:03:53,700 --> 01:03:56,500
which he in that region

919
01:03:56,510 --> 01:03:58,740
and in fact you can

920
01:03:58,760 --> 01:04:03,140
use graphical models to represent to model this problem actually

921
01:04:03,150 --> 01:04:04,450
o thing

922
01:04:04,460 --> 01:04:08,110
the proper solution for

923
01:04:08,160 --> 01:04:10,300
same example just with all time

924
01:04:14,550 --> 01:04:16,320
same house with the

925
01:04:16,330 --> 01:04:21,870
images from different perspectives new to match features one image to another image

926
01:04:21,930 --> 01:04:24,400
to recognise the object

927
01:04:24,410 --> 01:04:29,950
here is yet another example in image processing

928
01:04:29,960 --> 01:04:32,940
so in the top left to have an original image

929
01:04:32,950 --> 01:04:37,600
and then in the top right you have that image with text

930
01:04:37,610 --> 01:04:39,060
proposed to

931
01:04:39,080 --> 01:04:42,710
basically have described the content of the image

932
01:04:42,760 --> 01:04:45,540
they b in the pixels

933
01:04:45,550 --> 01:04:47,950
that have been proposed about that

934
01:04:48,050 --> 01:04:50,530
the question is how do you

935
01:04:51,300 --> 01:04:53,790
only at the image in europe

936
01:04:53,840 --> 01:04:55,380
right side

937
01:04:55,470 --> 01:04:59,830
how do recall the original image to have good approximation

938
01:04:59,880 --> 01:05:02,810
how do we actually

939
01:05:04,290 --> 01:05:06,360
that image in the top right

940
01:05:06,400 --> 01:05:08,390
could be something close to the machine

941
01:05:08,400 --> 01:05:10,890
top left

942
01:05:10,910 --> 01:05:12,010
in the bottom

943
01:05:12,020 --> 01:05:15,560
you had two examples of constructions using graphical model

944
01:05:15,580 --> 01:05:17,250
so you don't

945
01:05:17,260 --> 01:05:20,530
you don't get to observe the pixels

946
01:05:21,310 --> 01:05:22,930
the white

947
01:05:22,940 --> 01:05:24,130
pixels in

948
01:05:24,210 --> 01:05:25,450
the text

949
01:05:25,460 --> 01:05:28,520
you just rely on those pixels that

950
01:05:29,790 --> 01:05:32,580
and you need to fill in the text with proper image

951
01:05:32,630 --> 01:05:35,460
and that's what you're saying which is quite

952
01:05:43,340 --> 01:05:46,240
no not at all

953
01:05:46,260 --> 01:05:50,180
not in fact scale there's absolutely

954
01:05:50,890 --> 01:05:53,240
that is just

955
01:05:54,420 --> 01:06:03,240
for arbitrary images i don't absolutely know that there is a wonderful

956
01:06:03,260 --> 01:06:06,830
i have the training process the rest of the world

957
01:06:07,280 --> 01:06:11,440
so another example

958
01:06:14,120 --> 01:06:16,990
we have an image on the left

959
01:06:17,000 --> 01:06:22,380
and here we have a corrupted version of that image with very severe noise

960
01:06:22,420 --> 01:06:24,230
and here you have

961
01:06:24,240 --> 01:06:27,500
one example solution of the denoising of

962
01:06:27,510 --> 01:06:28,950
this image

963
01:06:29,060 --> 01:06:32,650
in fact denied this image to them with approximation of the region in which which

964
01:06:32,650 --> 01:06:35,410
we never see

965
01:06:35,470 --> 01:06:39,020
so this is one of the first approximation kind of thing that one of the

966
01:06:39,020 --> 01:06:42,110
the few with what is it that one

967
01:06:42,120 --> 01:06:45,930
then you can obtain the the last approximation so remember the only thing you get

968
01:06:45,930 --> 01:06:48,870
to observe the noisy image

969
01:06:49,790 --> 01:06:53,170
that in which is the reconstruction

970
01:06:53,220 --> 01:06:56,290
that's the only thing you get to see you never get to the original

971
01:06:56,300 --> 01:06:58,260
and so that's pretty graph

972
01:06:58,270 --> 01:07:01,970
if you use any naive type forward new learning

973
01:07:02,020 --> 01:07:04,450
basic image processing cores

974
01:07:04,450 --> 01:07:07,060
you'll never be able to something like this

975
01:07:07,110 --> 01:07:09,690
you really need to go for more sophisticated

976
01:07:09,710 --> 01:07:11,730
why graph models

977
01:07:11,740 --> 01:07:13,070
the answer here

978
01:07:13,070 --> 01:07:15,780
because in graphical model since we analyse

979
01:07:15,820 --> 01:07:20,490
image as a graph we can consider the connection between that pixel and all its

980
01:07:24,660 --> 01:07:25,860
for all

981
01:07:25,870 --> 01:07:29,550
locations in the image we do these analysis and then

982
01:07:29,550 --> 01:07:34,390
every for every part of the image we have given preference of which value

983
01:07:34,460 --> 01:07:36,030
xo would like to

984
01:07:36,030 --> 01:07:38,270
all these

985
01:07:38,300 --> 01:07:41,530
nonparametric bayesian models seem to have the work

986
01:07:41,540 --> 01:07:44,020
process occurring somewhere because

987
01:07:44,040 --> 01:07:48,960
stochastic process is basically an infinite dimensional probability distribution

988
01:07:49,010 --> 01:07:53,060
so originally this this terminology was the process of course due you to due to

989
01:07:53,070 --> 01:07:57,680
the idea that you have some kind of sequential process observations which just continues to

990
01:07:58,760 --> 01:08:02,920
but then you look at the joint probability distribution of all these observations that you

991
01:08:02,920 --> 01:08:06,460
get all these these individual events that you have all the time

992
01:08:06,470 --> 01:08:11,600
and so you define to somehow have to to study infinite dimensional probability

993
01:08:11,640 --> 01:08:16,560
but more generally these these these could be infinite dimensional distributions which which have no

994
01:08:16,560 --> 01:08:20,150
notion of time what they don't need to be annexed by time is an expert

995
01:08:20,150 --> 01:08:23,620
something that could be annexed by points in space or whatever you like

996
01:08:23,720 --> 01:08:27,560
OK and one

997
01:08:27,620 --> 01:08:33,050
i mean probably the most important stochastic process of all the stochastic process

998
01:08:33,900 --> 01:08:36,660
is the typical definition that i that i

999
01:08:36,680 --> 01:08:38,210
at it some time

1000
01:08:38,220 --> 01:08:42,290
copied from i think some machine learning takes i don't know which one what it

1001
01:08:42,290 --> 01:08:43,500
says is

1002
01:08:43,950 --> 01:08:48,950
gaussianprocess is the probability distribution on an infinite collection of random variables and their indexed

1003
01:08:49,070 --> 01:08:51,230
by t suggestively four times

1004
01:08:51,250 --> 01:08:54,580
and such that the marginal distribution for each finite subset

1005
01:08:54,620 --> 01:08:56,460
of indices discussing so

1006
01:08:56,480 --> 01:09:00,980
that's what is this this definition that that karl discussed in this talk that you

1007
01:09:01,670 --> 01:09:05,760
something like that you can think of the function is something like an infinite infinite

1008
01:09:07,970 --> 01:09:13,040
you say that this function is distributed according to process if any subset of elements

1009
01:09:13,040 --> 01:09:15,460
of the vector you pick any finite subset

1010
01:09:15,500 --> 01:09:17,200
has a cost distribution

1011
01:09:19,460 --> 01:09:23,350
what's this definition does not tell us is whether such a thing exists right now

1012
01:09:23,370 --> 01:09:26,670
all it says if it exists we call it goes processes

1013
01:09:26,750 --> 01:09:30,460
but not whether it exists or not what we have done it does not tell

1014
01:09:30,460 --> 01:09:32,080
us you know what we have to

1015
01:09:32,160 --> 01:09:34,880
what kind of conditions we have to impose to make it unique

1016
01:09:34,930 --> 01:09:36,690
what about

1017
01:09:38,820 --> 01:09:45,300
it has to go in there in order to make it uniquely defined mathematical objects

1018
01:09:48,930 --> 01:09:54,360
now the next slides i guess are kind of technical

1019
01:09:54,380 --> 01:09:56,280
what is a

1020
01:10:02,430 --> 01:10:04,370
by exist

1021
01:10:05,320 --> 01:10:13,600
suppose you have the set of all

1022
01:10:14,890 --> 01:10:17,790
infinite dimension measures on on on

1023
01:10:17,800 --> 01:10:18,950
the space

1024
01:10:18,960 --> 01:10:21,610
on in which these functions like OK

1025
01:10:21,610 --> 01:10:25,310
to say OK there might be probability measures and look at the set of all

1026
01:10:25,310 --> 01:10:26,120
of them

1027
01:10:26,200 --> 01:10:28,460
and i want to impose imposing here

1028
01:10:28,520 --> 01:10:32,880
is is a condition that

1029
01:10:32,890 --> 01:10:37,320
all the margin that there is one of these probability measures were all the marginals

1030
01:10:37,320 --> 01:10:38,760
are gaussians

1031
01:10:38,820 --> 01:10:42,300
but they might not be right nothing guarantees in this really

1032
01:10:42,320 --> 01:10:43,750
it's the case

1033
01:10:43,760 --> 01:10:46,810
we might just end up if we if we look at if we look at

1034
01:10:46,810 --> 01:10:50,240
this as a set of constraints then we might have end was was it was

1035
01:10:50,240 --> 01:10:51,670
an empty feasible set

1036
01:10:51,870 --> 01:10:55,570
the new

1037
01:11:00,960 --> 01:11:05,140
one of the one

1038
01:11:05,190 --> 01:11:10,010
it would also be cast it should be

1039
01:11:10,120 --> 01:11:10,990
better be

1040
01:11:14,120 --> 01:11:17,730
it's exactly so

1041
01:11:17,750 --> 01:11:21,480
so we we make we can make this assumption

1042
01:11:21,520 --> 01:11:26,450
on certainly that that all these finite or this finite subsets of variables have some

1043
01:11:26,450 --> 01:11:27,960
girls in this tradition

1044
01:11:28,010 --> 01:11:31,750
but whether that whether or not there is an infinite dimension probability

1045
01:11:31,790 --> 01:11:34,470
that has these as its marginal

1046
01:11:35,220 --> 01:11:36,870
this is not a priority

1047
01:11:44,110 --> 01:11:46,330
but of course it works

1048
01:11:46,360 --> 01:11:51,680
good so far

1049
01:11:51,730 --> 01:11:53,510
so the the

1050
01:11:53,530 --> 01:11:55,020
the theorem that that

1051
01:11:55,040 --> 01:11:59,150
it tells us that that this actually works is called the congo extensions here

1052
01:11:59,430 --> 01:12:02,720
some people just call it the congo theorem but there a million and one can

1053
01:12:02,740 --> 01:12:06,080
go here and so there is a kind of extension here

1054
01:12:06,110 --> 01:12:08,380
and what it tells us is the following if you have

1055
01:12:08,430 --> 01:12:14,060
if you if you imagine you have an infinite dimensional probability distribution your stochastic process

1056
01:12:14,120 --> 01:12:15,800
and now we look at

1057
01:12:15,820 --> 01:12:20,080
at the finite dimensional subspaces of your space and take the marginals on those

1058
01:12:20,890 --> 01:12:25,260
then these marginals on arbitrary so if you take for example the five dimensional subspace

1059
01:12:25,260 --> 01:12:27,200
and you take the margin on that

1060
01:12:27,220 --> 01:12:30,980
and you take a different for a five dimensional subspace takes marginal and

1061
01:12:31,030 --> 01:12:35,680
you choose the subspace such that they share some dimensions if you marginalized both of

1062
01:12:35,680 --> 01:12:38,860
you five dimension that down to the shared subspace

1063
01:12:38,900 --> 01:12:42,050
we must end up with the same margin right because they're all marginals of one

1064
01:12:42,050 --> 01:12:44,650
it's the same stochastic process

1065
01:12:44,700 --> 01:12:49,120
so that's something that these marginals certainly will have to satisfy

1066
01:12:49,180 --> 01:12:52,540
and what's the commonwealth serum tell us is that is basically all also works the

1067
01:12:52,540 --> 01:12:53,860
other way around

1068
01:12:53,870 --> 01:12:58,160
if we have marginals this set of marginals all finite dimensional subspaces which are consistent

1069
01:12:58,160 --> 01:12:59,610
in this fashion

1070
01:12:59,620 --> 01:13:01,030
then they defined

1071
01:13:01,130 --> 01:13:04,720
stochastic processes and its unique exists and is unique

1072
01:13:04,720 --> 01:13:09,670
so it is kind of ones that we have to invest some work into the

1073
01:13:09,670 --> 01:13:11,180
like the technical setup

1074
01:13:11,230 --> 01:13:12,500
but once that is done

1075
01:13:12,540 --> 01:13:15,070
it's really appealing in its simplicity

1076
01:13:19,810 --> 01:13:21,200
good so

1077
01:13:21,600 --> 01:13:28,120
and the slide here is the technique itself that's what looks ugly so you

1078
01:13:28,140 --> 01:13:31,830
what we what we want to define is this is this measure

1079
01:13:31,850 --> 01:13:36,450
this is our stochastic processes so it is a stochastic process it sounds complicated but

1080
01:13:36,450 --> 01:13:38,220
it's really just the probability measure

1081
01:13:38,270 --> 01:13:40,630
and only its own pretty large

1082
01:13:42,720 --> 01:13:45,980
this is probability measure corresponds to random variable

1083
01:13:48,320 --> 01:13:52,160
which is again defined in abstract probability space and maps to some

1084
01:13:52,200 --> 01:13:54,060
o space

1085
01:13:54,080 --> 01:13:56,700
OK and and so what we have to do now is we have to set

1086
01:13:57,350 --> 01:13:58,650
this space here

1087
01:13:58,660 --> 01:14:02,030
and then we have to figure out what we mean by marginals

1088
01:14:03,620 --> 01:14:07,770
can the way the way we're doing that is the following so we start

1089
01:14:07,770 --> 01:14:10,980
formed by the two variables d

1090
01:14:11,010 --> 01:14:12,180
d c

1091
01:14:12,200 --> 01:14:14,890
c a and the b and that's what

1092
01:14:14,900 --> 01:14:19,230
i was here and similarly for the denominator now i see that distance

1093
01:14:19,990 --> 01:14:25,400
does not depend on b similarly for the standard default we can cancel them

1094
01:14:25,410 --> 01:14:28,970
and we obtain a function which is not dependent on c

1095
01:14:29,250 --> 01:14:34,030
so we demonstrate demonstrated that a b and c are indeed independent

1096
01:14:34,520 --> 01:14:38,980
given a and b so it's pretty easy way

1097
01:14:39,000 --> 01:14:41,480
four marker matter to understand

1098
01:14:43,710 --> 01:14:47,730
this is just what i i have shown before by graphically work

1099
01:14:47,740 --> 01:14:49,530
i cutting the leak

1100
01:14:49,560 --> 01:14:52,300
every time there is

1101
01:14:53,150 --> 01:14:54,900
and also

1102
01:14:54,900 --> 01:14:56,200
in the past

1103
01:14:56,210 --> 01:14:59,800
between the divided ball the time conditions

1104
01:14:59,860 --> 01:15:01,730
so in this case

1105
01:15:01,740 --> 01:15:06,150
so there is a viable here and i'm not conditioning unit

1106
01:15:06,160 --> 01:15:11,280
so the line will be maintained so in order to have independence we have to

1107
01:15:11,300 --> 01:15:14,710
again block or the part between our

1108
01:15:14,720 --> 01:15:16,310
my voice

1109
01:15:16,330 --> 01:15:20,740
is that clear

1110
01:15:20,740 --> 01:15:21,910
so on

1111
01:15:21,930 --> 01:15:29,760
these might actually give us another way of this or of inferring dependencies in

1112
01:15:29,850 --> 01:15:34,800
belief networks i one described here you can it later but the main idea is

1113
01:15:34,800 --> 01:15:39,050
to transform your belief two into the

1114
01:15:39,060 --> 01:15:40,520
an undirected graph

1115
01:15:40,540 --> 01:15:42,990
seven steps

1116
01:15:42,990 --> 01:15:51,540
and then use the independence matter that i just described and therefore more coming to

1117
01:15:51,560 --> 01:15:54,430
and method might be a bit easier than

1118
01:15:54,670 --> 01:16:00,230
the matter that's playing yes earlier really

1119
01:16:00,250 --> 01:16:02,760
they exactly the same site yes

1120
01:16:02,780 --> 01:16:05,920
but you might sometimes referred to use this

1121
01:16:05,920 --> 01:16:07,540
it's this

1122
01:16:07,680 --> 01:16:10,210
it's less

1123
01:16:11,710 --> 01:16:15,850
mister OK so

1124
01:16:15,880 --> 01:16:21,440
let's now i think i have described two type of

1125
01:16:21,490 --> 01:16:28,170
graphical models and how do they relate can we always this process

1126
01:16:28,210 --> 01:16:33,980
a metal with a markov network the answer is no like let's look at this

1127
01:16:33,980 --> 01:16:36,510
example you i have either

1128
01:16:36,540 --> 01:16:37,890
which means that

1129
01:16:37,890 --> 01:16:41,480
the the joint distribution with factorized this way

1130
01:16:41,490 --> 01:16:42,930
right because have

1131
01:16:42,930 --> 01:16:44,980
two routes and they

1132
01:16:44,990 --> 01:16:47,950
and the cause c which has two parts

1133
01:16:47,960 --> 01:16:51,390
now obviously i we want to form

1134
01:16:51,440 --> 01:16:54,010
march connector will ever put pen show

1135
01:16:54,030 --> 01:16:58,400
on all three valuable that means that they will have a link between all of

1136
01:16:59,470 --> 01:17:02,140
and the which means that now

1137
01:17:02,160 --> 01:17:03,160
a and b

1138
01:17:03,280 --> 01:17:05,720
not be independent anymore

1139
01:17:06,570 --> 01:17:09,260
in our region

1140
01:17:09,280 --> 01:17:11,800
a and b were independent

1141
01:17:11,820 --> 01:17:14,320
now we can also the obvious question

1142
01:17:14,340 --> 01:17:16,280
can we express any

1143
01:17:16,320 --> 01:17:20,650
mark on that tour we don't believe that and the answer is to gain or

1144
01:17:20,800 --> 01:17:22,730
lose we look at the

1145
01:17:22,750 --> 01:17:24,070
example in europe

1146
01:17:27,010 --> 01:17:28,880
to to have kind

1147
01:17:28,900 --> 01:17:32,460
to to transform it into believing that will have to one thing

1148
01:17:32,460 --> 01:17:34,760
kind of the same structure so we

1149
01:17:34,820 --> 01:17:39,340
we cannot have the link here between b and c and d a d

1150
01:17:39,340 --> 01:17:47,050
and also to ensure that the that the model is the graphical model is acyclic

1151
01:17:47,170 --> 01:17:48,250
we have two

1152
01:17:48,260 --> 01:17:50,990
related to collider

1153
01:17:51,010 --> 01:17:55,250
these are just point here a few point in the other direction we get a

1154
01:17:55,300 --> 01:17:56,710
cyclic graph

1155
01:17:56,710 --> 01:18:00,170
so that means that we will end up with a different set of

1156
01:18:00,170 --> 01:18:03,590
dependence independence relations for example

1157
01:18:03,610 --> 01:18:10,960
in the original graph b and and c were independent given indeed because i conditional

1158
01:18:10,980 --> 01:18:15,610
bought so i can't think here the catholic here while in this

1159
01:18:15,610 --> 01:18:19,490
OK is

1160
01:18:19,510 --> 01:18:23,940
then divided will be in c would be independent given a the

1161
01:18:23,940 --> 01:18:26,530
because if you look at the part

1162
01:18:29,190 --> 01:18:33,840
we have collider right in the park with the condition

1163
01:18:33,860 --> 01:18:37,210
is it could

1164
01:18:37,260 --> 01:18:40,300
c and we we do conditions sorry on this

1165
01:18:40,320 --> 01:18:42,670
on the collider the therefore we

1166
01:18:42,690 --> 01:18:46,030
we have dependency

1167
01:18:46,050 --> 01:18:47,340
please stop it

1168
01:18:47,360 --> 01:18:52,050
there is something that is not clear

1169
01:18:52,420 --> 01:18:56,210
nest now let's talk about the type of

1170
01:18:56,210 --> 01:18:58,230
graphical models

1171
01:18:58,260 --> 01:19:03,300
i want to see in this talk mainly the factor graph in a factor graph

1172
01:19:03,570 --> 01:19:04,960
in addition to

1173
01:19:04,960 --> 01:19:09,940
note we represent random variable with a square known

1174
01:19:10,380 --> 01:19:13,900
which represent nonnegative functions

1175
01:19:15,070 --> 01:19:21,010
its neighbour viable so for example if i want you to present the nonnegative functions

1176
01:19:21,030 --> 01:19:23,070
of a and b

1177
01:19:23,090 --> 01:19:25,340
and then we will have

1178
01:19:25,360 --> 01:19:28,840
here f two is a non negative function of b

1179
01:19:28,860 --> 01:19:33,050
c and d and so on and the john function is obtained by simply the

1180
01:19:33,050 --> 01:19:36,260
product of all these factors

1181
01:19:36,320 --> 01:19:38,190
so here

1182
01:19:38,210 --> 01:19:43,280
factor graph are mainly or use a lot of fun the sun

1183
01:19:43,300 --> 01:19:50,380
inference we will see later and you notice the talk about functions not through redistribution

1184
01:19:50,380 --> 01:19:53,190
because they're being used also for good

1185
01:19:53,250 --> 01:20:00,400
performing efficient computational just probability

1186
01:20:00,460 --> 01:20:04,800
so inference problem and i so far as they knew

1187
01:20:04,840 --> 01:20:11,340
out to understand i being different graphical models and how to understand the dependencies

1188
01:20:11,340 --> 01:20:13,940
as i told you graphical model also

1189
01:20:13,980 --> 01:20:20,300
use full because they enable us to develop efficient events i one so now i'm

1190
01:20:20,300 --> 01:20:24,380
going to explain a little bit about that

1191
01:20:24,400 --> 01:20:26,920
so if this correspond as we

1192
01:20:26,940 --> 01:20:33,550
you know by now operations such as computing marginal compute conditional distributions from the joint

1193
01:20:33,550 --> 01:20:36,460
distribution in general

1194
01:20:36,510 --> 01:20:42,860
inference is very difficult problems and also because we we a machine learning many many

1195
01:20:42,860 --> 01:20:46,550
valuable in you know our graphical model normally

1196
01:20:46,570 --> 01:20:51,800
the first single connected type of graph

1197
01:20:51,820 --> 01:20:53,920
there exist efficient i agree

1198
01:20:53,980 --> 01:20:58,300
based on the concept of missing that's what they do i mean by singly connected

1199
01:20:58,300 --> 01:21:02,710
graph is significant that the graph is a graph in which there is only apart

1200
01:21:02,710 --> 01:21:04,510
from one node to another

1201
01:21:05,320 --> 01:21:10,940
can you tell me if this party singly connected yes because i wrote it so

1202
01:21:10,940 --> 01:21:16,110
that OK so if i have a link from

1203
01:21:16,110 --> 01:21:17,190
the two

1204
01:21:17,210 --> 01:21:23,110
i will obtain more to the story from it to be a more typical

1205
01:21:23,130 --> 01:21:28,030
the graph is that because there is for example apart

1206
01:21:28,090 --> 01:21:29,610
from e to d

1207
01:21:29,900 --> 01:21:34,570
discipline going this direction or i can go also from me to the passing two

1208
01:21:34,590 --> 01:21:38,960
g so there are two parts

1209
01:21:38,980 --> 01:21:43,630
let's discuss about this out to perform inference

1210
01:21:43,630 --> 01:21:49,860
in in factor graphs and the concept of message passing let's suppose that we have

1211
01:21:51,670 --> 01:21:55,840
for binary body one a b c and d

1212
01:21:55,860 --> 01:21:57,840
and our distribution

1213
01:21:57,880 --> 01:22:01,150
is factorized this way the means that

1214
01:22:01,170 --> 01:22:03,670
i will have a factor graph representation

1215
01:22:03,690 --> 01:22:05,190
here where f one

1216
01:22:05,210 --> 01:22:10,860
connecting b in the four i factor for this and so on and here i

1217
01:22:10,900 --> 01:22:13,570
have only

1218
01:22:13,570 --> 01:22:15,080
so if you want to apply this to

1219
01:22:15,490 --> 01:22:17,050
during decision error

1220
01:22:18,400 --> 01:22:19,840
good to be

1221
01:22:21,010 --> 01:22:24,960
how can you really the number of mistakes make and the training set we did

1222
01:22:24,960 --> 01:22:28,350
the number of mistakes make on the

1223
01:22:30,150 --> 01:22:32,380
however addition problem here

1224
01:22:32,390 --> 01:22:34,940
the people that classifier

1225
01:22:34,960 --> 01:22:38,400
you have an algorithm that generates classifier

1226
01:22:38,440 --> 01:22:43,060
so you have to decide which is your classifier that we're going to

1227
01:22:43,110 --> 01:22:44,270
you have options

1228
01:22:44,320 --> 01:22:48,270
well one natural option is the last one

1229
01:22:48,310 --> 01:22:51,350
you cycle over the training set

1230
01:22:51,360 --> 01:22:56,910
and then you take the last one generated the last classified by the perceptron

1231
01:22:56,960 --> 01:23:00,440
and then you measure the of that one

1232
01:23:00,550 --> 01:23:03,280
but this is not good in statistical

1233
01:23:03,770 --> 01:23:09,090
because it's going to be robust enough because it would be very

1234
01:23:09,140 --> 01:23:10,950
a question on

1235
01:23:10,960 --> 01:23:15,640
not the error but it

1236
01:23:17,080 --> 01:23:21,490
i'm going to quickly to show how to get it deleted these in all i

1237
01:23:21,490 --> 01:23:23,400
get about the whole point wise

1238
01:23:23,450 --> 01:23:26,420
and i wanted to all the probability

1239
01:23:26,430 --> 01:23:29,210
so what do you

1240
01:23:29,230 --> 01:23:30,720
if it's wide

1241
01:23:30,730 --> 01:23:35,210
then it fine

1242
01:23:35,460 --> 01:23:37,720
the game

1243
01:23:37,770 --> 01:23:42,570
but there are few technicolor things that we'd like to check and see and then

1244
01:23:42,570 --> 01:23:46,780
it will be

1245
01:23:46,820 --> 01:23:49,020
but now

1246
01:23:49,070 --> 01:23:51,230
it's the

1247
01:23:51,280 --> 01:23:53,770
on line

1248
01:23:53,780 --> 01:23:56,830
the batch

1249
01:23:59,070 --> 01:24:05,650
so now

1250
01:24:09,400 --> 01:24:21,250
is drawn i i d

1251
01:24:21,300 --> 01:24:26,190
from a known

1252
01:24:27,230 --> 01:24:29,890
fixed the distribution

1253
01:24:30,050 --> 01:24:32,950
on the

1254
01:24:35,180 --> 01:24:37,430
b by the cartesian product of

1255
01:24:38,070 --> 01:24:40,040
this is based on the label

1256
01:24:40,050 --> 01:24:43,970
a little bit but but but

1257
01:24:47,080 --> 01:24:53,080
now whenever we have a classifier

1258
01:24:55,030 --> 01:24:58,420
we can measure the risk

1259
01:24:58,490 --> 01:25:02,710
i know that we are now ready

1260
01:25:02,760 --> 01:25:04,670
as a function of directly

1261
01:25:06,950 --> 01:25:11,740
this is just the probability began writing in different ways the probability that on a

1262
01:25:11,740 --> 01:25:13,070
random x y

1263
01:25:13,120 --> 01:25:14,340
drawn by the

1264
01:25:14,670 --> 01:25:18,830
prisoners can say that the margin

1265
01:25:24,590 --> 01:25:27,030
and no party

1266
01:25:27,080 --> 01:25:29,750
well this is the reason for this

1267
01:25:29,760 --> 01:25:33,500
the misclassification probability

1268
01:25:33,550 --> 01:25:35,370
all the classifiers

1269
01:25:35,380 --> 01:25:36,840
so now i would like to really

1270
01:25:37,390 --> 01:25:42,170
what what other things i would like to relate

1271
01:25:42,200 --> 01:25:47,250
i would like to relate to the

1272
01:25:47,820 --> 01:25:52,260
what we have what is that my all and me

1273
01:25:52,290 --> 01:25:58,340
well all the learning is me an example of the opposite the symbol of classifiers

1274
01:25:59,830 --> 01:26:08,600
so if i run for the prime suspect

1275
01:26:08,650 --> 01:26:10,430
my online classifier

1276
01:26:10,470 --> 01:26:12,540
perceptron he

1277
01:26:12,550 --> 01:26:14,000
twenty like

1278
01:26:14,010 --> 01:26:16,450
on any

1279
01:26:16,460 --> 01:26:23,660
dream you can will not taking into account cycling seriously new in a moment

1280
01:26:23,680 --> 01:26:27,010
wired for i'm think in extreme profanity

1281
01:26:27,060 --> 01:26:29,300
i'm running my online classifier

1282
01:26:29,320 --> 01:26:30,770
and i'm getting

1283
01:26:31,320 --> 01:26:36,550
at this time so that the classifier will have you found something about my very

1284
01:26:36,550 --> 01:26:40,120
well as he was funded by the many of these will be

1285
01:26:40,180 --> 01:26:43,780
the same is not distinct effect of classifiers

1286
01:26:43,910 --> 01:26:47,210
maybe w zero is good for forty one

1287
01:26:47,290 --> 01:26:48,600
will be the

1288
01:26:48,790 --> 01:26:51,250
OK but i want to do not

1289
01:26:51,290 --> 01:26:53,210
multiplicity here

1290
01:26:53,260 --> 01:26:56,720
so now i want to relate

1291
01:26:59,360 --> 01:27:04,640
i want to relate to the average risk of the classifier here

1292
01:27:04,690 --> 01:27:08,620
with the fraction of mistakes made by the online growing

1293
01:27:08,640 --> 01:27:11,550
as these five where

1294
01:27:12,930 --> 01:27:15,220
so i'll will show you that there

1295
01:27:15,270 --> 01:27:16,840
this one is

1296
01:27:16,890 --> 01:27:19,050
the average risk of these guys

1297
01:27:19,050 --> 01:27:23,290
and never miss beat fraction of mistakes to in be close to each other with

1298
01:27:27,050 --> 01:27:29,330
this was giving away

1299
01:27:29,390 --> 01:27:33,130
of relating a

1300
01:27:33,180 --> 01:27:35,190
useful quantities

1301
01:27:35,200 --> 01:27:36,700
at risk

1302
01:27:36,750 --> 01:27:39,120
with this statistics

1303
01:27:39,180 --> 01:27:43,460
an empirical quantity which is the mistakes if they can serve as around my i

1304
01:27:44,470 --> 01:27:47,360
usual way of computing the about

1305
01:27:47,550 --> 01:27:52,990
i want to get the takes good proxy for some property that we want to

1306
01:27:54,290 --> 01:27:56,460
this proxy is my

1307
01:27:56,610 --> 01:28:00,010
this exhibited by fraction of mister

1308
01:28:02,990 --> 01:28:06,520
i want to bound this quantity here

1309
01:28:10,240 --> 01:28:24,190
so i'm just going to get in this one and this one

1310
01:28:26,860 --> 01:28:29,830
and then i introduced this

1311
01:28:29,880 --> 01:28:32,090
random variable

1312
01:28:32,110 --> 01:28:33,360
he are

1313
01:28:33,410 --> 01:28:36,750
WP minus one minus

1314
01:28:36,820 --> 01:28:39,810
OK now i go back to my old the notation for

1315
01:28:43,450 --> 01:28:46,330
indicator function of b

1316
01:28:46,950 --> 01:28:51,500
then the deputy minister one may be on the here

1317
01:28:51,550 --> 01:28:53,020
example of the brain

1318
01:28:54,110 --> 01:28:56,410
look at these random variable

1319
01:28:56,470 --> 01:29:00,710
what's the expectation of a random variable

1320
01:29:00,730 --> 01:29:03,780
the expectation of the

1321
01:29:03,780 --> 01:29:10,490
we do that is look at the amortized cost of the i th operation

1322
01:29:10,550 --> 01:29:13,200
OK what's what's mts

1323
01:29:13,220 --> 01:29:16,950
emma tries cost

1324
01:29:16,950 --> 01:29:20,380
OK and then we'll make the argument which is the one you always make your

1325
01:29:20,380 --> 01:29:25,400
mark price cost down upper bound the true cross

1326
01:29:26,200 --> 01:29:29,170
the amortized cost is going to be easier to

1327
01:29:32,920 --> 01:29:40,340
OK so amortized cost is just see had to let me

1328
01:29:40,360 --> 01:29:43,610
tried lots around here on the right

1329
01:29:43,670 --> 01:29:45,400
this is by hand

1330
01:29:45,400 --> 01:29:50,130
which is equal to the true cost plus the change in potential

1331
01:29:55,010 --> 01:30:01,760
that's just definition of emma ties cost when given potential functions

1332
01:30:05,360 --> 01:30:06,950
what is

1333
01:30:07,170 --> 01:30:16,170
the cost of operation i

1334
01:30:17,070 --> 01:30:18,930
in this context here

1335
01:30:19,050 --> 01:30:21,570
we access x

1336
01:30:21,610 --> 01:30:28,490
what's the cost of operation i

1337
01:30:28,530 --> 01:30:33,280
two times the rank of x which is

1338
01:30:33,300 --> 01:30:34,240
two are

1339
01:30:34,300 --> 01:30:36,690
so two are

1340
01:30:36,700 --> 01:30:40,430
that part of the

1341
01:30:43,090 --> 01:30:47,110
well we have an upper bound on the change in potential

1342
01:30:47,130 --> 01:30:50,090
it says

1343
01:30:50,720 --> 01:30:52,530
so that's two

1344
01:30:54,170 --> 01:30:57,400
now it might cardinality

1345
01:30:57,450 --> 01:31:05,780
plus he supply

1346
01:31:05,780 --> 01:31:08,200
they are very with me

1347
01:31:08,590 --> 01:31:10,900
OK so let's not as good

1348
01:31:10,900 --> 01:31:13,340
OK that's equal to

1349
01:31:13,380 --> 01:31:15,880
two are

1350
01:31:18,030 --> 01:31:20,840
two of the size of a

1351
01:31:20,860 --> 01:31:22,530
minus OK

1352
01:31:22,570 --> 01:31:26,070
i want to plug in for b

1353
01:31:26,070 --> 01:31:28,110
it turns out very nicely

1354
01:31:28,150 --> 01:31:31,240
i have a

1355
01:31:31,260 --> 01:31:33,950
equation involving a b and are

1356
01:31:33,950 --> 01:31:36,650
get rid of the variable

1357
01:31:37,630 --> 01:31:38,650
size b

1358
01:31:38,670 --> 01:31:40,150
by just

1359
01:31:40,170 --> 01:31:41,670
plugging that

1360
01:31:42,530 --> 01:31:45,070
so what do i plug in here

1361
01:31:45,130 --> 01:31:50,990
would be equal to

1362
01:31:51,050 --> 01:31:52,490
or minus

1363
01:31:52,490 --> 01:31:55,530
the size of a minus one i wrote the other way

1364
01:31:58,170 --> 01:32:00,220
and then plus t i

1365
01:32:01,430 --> 01:32:05,380
in this sense

1366
01:32:05,530 --> 01:32:11,220
or as a plus

1367
01:32:12,470 --> 01:32:19,190
plus one

1368
01:32:19,220 --> 01:32:21,240
everybody with mister still

1369
01:32:21,490 --> 01:32:22,860
an algebra

1370
01:32:23,900 --> 01:32:26,030
make sure to the algebraic

1371
01:32:26,050 --> 01:32:29,550
OK so that's equal to its mode file this out now

1372
01:32:29,700 --> 01:32:30,840
two are

1373
01:32:32,300 --> 01:32:35,420
two a here minus

1374
01:32:35,510 --> 01:32:39,150
minus a so that for a

1375
01:32:39,200 --> 01:32:45,400
in two times my stars minus two are

1376
01:32:45,400 --> 01:32:48,240
two times minus one minus two

1377
01:32:48,240 --> 01:32:49,820
was minus minus two

1378
01:32:49,840 --> 01:32:51,840
plus two

1379
01:32:53,320 --> 01:32:57,280
and then i have to be i

1380
01:32:57,280 --> 01:33:02,570
that's just algebra

1381
01:33:05,860 --> 01:33:08,880
that's not bad we just got rid of another variable

1382
01:33:08,920 --> 01:33:11,340
but variables to europe

1383
01:33:13,570 --> 01:33:17,470
no matter what the rank was once i know what the number of

1384
01:33:17,590 --> 01:33:19,550
versions was here

1385
01:33:20,800 --> 01:33:21,930
so that's now

1386
01:33:21,950 --> 01:33:23,240
equal to

1387
01:33:23,360 --> 01:33:27,150
four a

1388
01:33:27,220 --> 01:33:28,300
class two

1389
01:33:28,320 --> 01:33:30,170
those two t

1390
01:33:30,340 --> 01:33:36,470
that's less than or equal to

1391
01:33:37,590 --> 01:33:40,590
four times

1392
01:33:40,650 --> 01:33:43,840
four star

1393
01:33:43,860 --> 01:33:45,610
STI i

1394
01:33:45,690 --> 01:33:51,800
using the fact that our star

1395
01:33:51,820 --> 01:33:54,630
is equal to the size of a

1396
01:33:54,650 --> 01:33:56,670
plus the size of c

1397
01:33:56,720 --> 01:33:57,920
plus one

1398
01:33:57,920 --> 01:34:01,030
and that's greater than or equal to

1399
01:34:01,090 --> 01:34:06,490
the size of a plus one

1400
01:34:06,570 --> 01:34:09,720
so by looking at this time basically

1401
01:34:09,740 --> 01:34:12,630
looking at

1402
01:34:12,740 --> 01:34:14,860
are a

1403
01:34:14,880 --> 01:34:16,430
the fact that

1404
01:34:16,700 --> 01:34:19,070
that a

1405
01:34:19,130 --> 01:34:21,720
when they do here

1406
01:34:21,740 --> 01:34:24,490
so we have our star is greater equal to

1407
01:34:24,490 --> 01:34:28,840
eight plus one

1408
01:34:28,860 --> 01:34:30,900
right so therefore

1409
01:34:31,030 --> 01:34:38,110
eight plus one good

1410
01:34:38,320 --> 01:34:42,860
yeah so this is basically less or equal to four a plus four

1411
01:34:42,880 --> 01:34:45,280
which is four times a plus one

1412
01:34:45,300 --> 01:34:47,880
i should put another out step here

1413
01:34:47,900 --> 01:34:51,130
OK because i can if i can verify it like this then then i get

1414
01:34:51,130 --> 01:34:52,380
nervous OK

1415
01:34:52,430 --> 01:34:54,700
this is basically most for

1416
01:34:54,800 --> 01:34:59,110
a plus four that's four times a plus one n plus one is less or

1417
01:34:59,110 --> 01:35:01,530
equal to our star

1418
01:35:01,550 --> 01:35:05,880
and then to t is at most forty i

1419
01:35:05,900 --> 01:35:09,010
so i got this

1420
01:35:09,090 --> 01:35:12,260
a so survey see where that came from

1421
01:35:12,300 --> 01:35:19,130
but what is our star plus t i

1422
01:35:19,150 --> 01:35:37,220
what is our star plus dr

1423
01:35:44,030 --> 01:35:46,820
that's just see i start

1424
01:35:46,920 --> 01:35:57,280
so the inner ties cost of the i th operation

1425
01:35:57,300 --> 01:36:01,700
is it most four times

1426
01:36:01,720 --> 01:36:08,820
ops costs

1427
01:36:10,200 --> 01:36:13,990
that's pretty remarkable

1428
01:36:14,010 --> 01:36:17,970
OK so it cost of the i th operation is just four times

1429
01:36:17,990 --> 01:36:20,720
because now course we have to now go through

1430
01:36:20,720 --> 01:36:22,950
and analyse the

1431
01:36:26,010 --> 01:36:27,090
analyse the

1432
01:36:27,110 --> 01:36:31,220
the total cost

1433
01:36:31,240 --> 01:36:34,820
but this is now

1434
01:36:34,820 --> 01:36:38,920
we basically the mean of each component are quite well separated

1435
01:36:38,940 --> 01:36:41,960
on the of similar weight on similar violence

1436
01:36:42,550 --> 01:36:45,010
so i want to is basically

1437
01:36:45,030 --> 01:36:49,110
part of the brain to sample from it so in this framework the way you

1438
01:36:49,110 --> 01:36:50,690
would do it for example

1439
01:36:50,710 --> 01:36:54,570
it you would consider sequence artificial target distribution

1440
01:36:54,590 --> 01:36:56,570
so that essentially

1441
01:36:56,650 --> 01:37:00,750
the target distribution is equal to the likelihood of race to the pole of phi

1442
01:37:01,800 --> 01:37:08,090
we're fine between zone one time supply or distribution OK so for

1443
01:37:08,090 --> 01:37:11,900
any called one then the target distribution is simply the player

1444
01:37:11,920 --> 01:37:17,210
OK on then you consider an increasing sequence of phi and so that will basically

1445
01:37:18,150 --> 01:37:23,150
five p define all official target distribution when you have actually phi p one one

1446
01:37:23,150 --> 01:37:26,420
o five p of the ties the like you to point out that is the

1447
01:37:28,610 --> 01:37:33,030
what you do when you do similar to talk to about it and bring it

1448
01:37:33,030 --> 01:37:36,840
to the two things you know the camel

1449
01:37:36,860 --> 01:37:38,340
but basically

1450
01:37:38,360 --> 01:37:40,340
so paul

1451
01:37:40,340 --> 01:37:41,710
for each

1452
01:37:41,940 --> 01:37:46,530
usual target distribution pi and on then you use those web move that's all you're

1453
01:37:46,530 --> 01:37:49,070
doing actually work on

1454
01:37:49,090 --> 01:37:53,880
but i don't musically is that for each of these like you basically MCMC kernel

1455
01:37:53,920 --> 01:37:59,440
two footballs like perturbation in the rule and i just used to store the image

1456
01:37:59,440 --> 01:38:04,070
processing arrays which is very nice i just use like

1457
01:38:04,150 --> 01:38:07,360
some kind of metropolis i think a for all this

1458
01:38:07,380 --> 01:38:08,980
these parameters OK

1459
01:38:08,990 --> 01:38:14,070
well i don't use these little in kelly's actually already done he doesn't use whatsoever

1460
01:38:14,090 --> 01:38:18,150
the geometry of the target distribution which i know is a mixture of twenty four

1461
01:38:18,650 --> 01:38:19,760
nodes OK

1462
01:38:20,710 --> 01:38:23,250
in proc

1463
01:38:23,260 --> 01:38:26,590
basically if i look at the MCMC

1464
01:38:26,590 --> 01:38:30,630
OK i told basically that targeted the distribution in the final

1465
01:38:30,650 --> 01:38:36,050
target distribution is the posterior distribution of interest then this MCMC kernel or if i

1466
01:38:36,050 --> 01:38:40,920
were to use it by itself basically gets taught in one of the local model

1467
01:38:40,920 --> 01:38:43,440
of the distribution OK so

1468
01:38:43,440 --> 01:38:45,780
if i were to use simple MCMC

1469
01:38:45,800 --> 01:38:47,460
these basically

1470
01:38:47,460 --> 01:38:52,840
move the MCMC can only not working at all which is like really get stuck

1471
01:38:52,840 --> 01:38:57,110
in one mode the distribution because the model very well separated one from each other

1472
01:38:57,260 --> 01:38:58,320
and the first

1473
01:38:58,340 --> 01:39:03,760
OK so what does it tell like basically using all this kind of artificial

1474
01:39:03,780 --> 01:39:07,090
basically target distribution using the sweat move

1475
01:39:07,110 --> 01:39:12,900
wait so is simple to devise a simple idea i think on quite powerful so

1476
01:39:12,900 --> 01:39:15,030
this is for example here

1477
01:39:15,710 --> 01:39:22,960
the marginal posterior distribution of the two of two means OK given up salvation all

1478
01:39:23,130 --> 01:39:28,300
i see that a recovery in this case the twelfth mode because i just project

1479
01:39:28,380 --> 01:39:32,480
the target distribution in two dimensions so basically

1480
01:39:32,480 --> 01:39:37,010
this kind of prior to bring type ideas can be quite willful to express very

1481
01:39:37,010 --> 01:39:42,480
naive with quite powerful to exploit actually to explore for sale distribution so that was

1482
01:39:42,480 --> 01:39:43,730
the basically

1483
01:39:43,800 --> 01:39:48,750
using so we are using over one million so important on you could tell me

1484
01:39:48,750 --> 01:39:54,110
i've been using thirty two thousand after distribution is called crazy actually works much less

1485
01:39:54,110 --> 01:39:59,050
than that i can use actually fine with more than enough so assume that this

1486
01:39:59,050 --> 01:40:02,750
is actually quite a nightmare code OK

1487
01:40:02,800 --> 01:40:06,630
well it turns out that this type of categories

1488
01:40:06,670 --> 01:40:08,360
can be very

1489
01:40:08,360 --> 01:40:10,360
well actually very suited

1490
01:40:10,380 --> 01:40:12,920
two GPU actually so

1491
01:40:12,920 --> 01:40:18,750
whereas for example what if were to implement this algorithm generate one million so important

1492
01:40:19,570 --> 01:40:24,440
of this by using the pilot ongoing algorithm using eight told an indemnity

1493
01:40:25,750 --> 01:40:30,010
the temperature of the CPU started you take like sixty minutes

1494
01:40:30,030 --> 01:40:33,860
on all the human plane that's on the GPU

1495
01:40:33,860 --> 01:40:36,730
it takes you basically two seconds

1496
01:40:36,760 --> 01:40:38,980
so it is an example where

1497
01:40:38,990 --> 01:40:43,320
basically type of ategories well basically do

1498
01:40:43,340 --> 01:40:44,780
use like the

1499
01:40:44,800 --> 01:40:50,650
you the GPU is actually quite short on make those secularism which were not necessarily

1500
01:40:50,650 --> 01:40:57,360
very interesting before actually really i competitive to state-of-the-art MCMC OK so even using that

1501
01:40:57,360 --> 01:41:03,550
by wal-mart thirty an intermediate target distribution it only took me twenty eight seconds to

1502
01:41:03,550 --> 01:41:08,190
one my algorithm on the GPU is very nice very power is a board because

1503
01:41:08,190 --> 01:41:11,990
now this box over here this acoustic event detector has nothing to do with the

1504
01:41:11,990 --> 01:41:16,080
site scientific hypotheses is just a black box we want to be able to feed

1505
01:41:16,100 --> 01:41:20,620
and features about the the mean rate of the of the impulses on the auditory

1506
01:41:20,620 --> 01:41:24,750
nerve we want to be able to feed and some estimate the perceptual salience of

1507
01:41:24,750 --> 01:41:29,250
what's happening and we want to get out some kind of estimate of whether the

1508
01:41:29,250 --> 01:41:34,560
order acoustic event was detected or not so we so so we put in whatever

1509
01:41:34,630 --> 01:41:38,750
pattern recognition algorithms we can we can and here we take a set of universal

1510
01:41:38,750 --> 01:41:43,760
approximators in this case adaboost fed into into a hidden markov model

1511
01:41:44,370 --> 01:41:49,700
we train the we train the adaboost hmm hybrid in order to detect events as

1512
01:41:49,700 --> 01:41:54,000
well as possible and then we see whether it whether it matches the performance of

1513
01:41:54,000 --> 01:41:58,510
human listeners and if so then we determined that in fact this this bar is

1514
01:41:58,510 --> 01:42:02,580
important for as an input for the algorithm

1515
01:42:02,610 --> 01:42:06,270
i think that's that's the the general structure of

1516
01:42:06,320 --> 01:42:07,150
in the center

1517
01:42:07,170 --> 01:42:10,850
that's that's in one slide overview that subscription of what i'm going to be talking

1518
01:42:10,850 --> 01:42:14,810
about today how do you how do you take a pattern recognition algorithm and applied

1519
01:42:14,820 --> 01:42:18,480
in order to answer questions about the real world and here if you the criteria

1520
01:42:18,480 --> 01:42:22,380
that you might use in order to choose those algorithms first of all is your

1521
01:42:23,810 --> 01:42:25,450
shallow or deep

1522
01:42:25,500 --> 01:42:32,400
in a sense a discriminative discriminative algorithm can pattern recognition algorithm is extremely useful if

1523
01:42:33,500 --> 01:42:36,170
your hypothesis can be written in closed form

1524
01:42:36,180 --> 01:42:40,020
because if it can be written in closed form then the then the error can

1525
01:42:40,020 --> 01:42:44,330
be minimized in closed form if not then you may need to invoke some kind

1526
01:42:44,330 --> 01:42:48,170
of into intermediate variables and if you need intermediate variables then you need some kind

1527
01:42:48,170 --> 01:42:54,480
of bayesian architecture second how much training data do you have in order to learn

1528
01:42:54,560 --> 01:42:59,960
the former hypothesis if you have a if you have a hundred thousand training examples

1529
01:43:00,310 --> 01:43:05,640
then number one structural risk minimisation is going to be too computationally expensive most of

1530
01:43:05,640 --> 01:43:08,850
the time and number two it doesn't make a big difference in fact we don't

1531
01:43:08,850 --> 01:43:13,790
see much difference beyond about ten thousand training examples between empirical risk minimization and structural

1532
01:43:13,790 --> 01:43:17,210
risk minimisation if on the other hand you have used fewer than a thousand training

1533
01:43:17,210 --> 01:43:21,610
tokens than with any good universal approximator you're going to overlap in the database

1534
01:43:21,650 --> 01:43:27,440
by by using straight empirical risk minimization

1535
01:43:27,500 --> 01:43:32,490
third does your hypothesis depend on time and that is does the past state of

1536
01:43:32,490 --> 01:43:37,010
the system contribute to the way it behaves in the future and second there is

1537
01:43:37,010 --> 01:43:42,940
is the output of the hypothesis real number or a or an integer and these

1538
01:43:42,940 --> 01:43:48,890
last two things dynamic state function range service of binary categorization of all the algorithms

1539
01:43:48,890 --> 01:43:52,730
in machine learning into four words that i'm going to use again and again for

1540
01:43:52,730 --> 01:43:57,320
the rest of the talk those are classification where the output is an integer and

1541
01:43:57,320 --> 01:44:01,440
it has no hidden state regression where the output is a real vector and there

1542
01:44:01,440 --> 01:44:06,050
is no hidden state recognition where the output is a series of integers and state

1543
01:44:06,050 --> 01:44:10,560
matters and tracking where the output is a series of real valued vectors and the

1544
01:44:10,560 --> 01:44:12,800
state of the system matters

1545
01:44:14,940 --> 01:44:16,830
and then we have to train them

1546
01:44:17,640 --> 01:44:19,480
taking the turn the previous

1547
01:44:19,500 --> 01:44:25,060
page and dividing the world into discriminative versus bayesian methods first of all we might

1548
01:44:25,060 --> 01:44:31,760
look discriminative methods because they're easy empirical risk minimization using discriminative methods has been was

1549
01:44:31,760 --> 01:44:35,960
was solved by the perceptron in the nineteen sixties we essentially to some kind of

1550
01:44:35,960 --> 01:44:38,500
universal approximator we

1551
01:44:38,520 --> 01:44:40,800
create an error metric and then we

1552
01:44:40,830 --> 01:44:47,370
minimize the error metric there at least three or four classes of universal approximator is

1553
01:44:47,370 --> 01:44:52,900
available to us so universal approximator is essentially a remand into greater

1554
01:44:52,960 --> 01:44:58,400
by the ryman integral theorem any function over any finite domain can be approximated by

1555
01:44:58,400 --> 01:45:01,140
an infinite number of tall thin boxes

1556
01:45:01,900 --> 01:45:05,760
the sigmoidal neural network actually doesn't model those that it is a series of tall

1557
01:45:05,760 --> 01:45:11,380
thin boxes models of this series of tall of tall thin step functions the

1558
01:45:11,390 --> 01:45:16,430
the gas mixture of gaussians models in this series of smooth tall thin boxes and

1559
01:45:16,700 --> 01:45:21,880
a piecewise constant or piecewise linear systems like classification trees and k nearest neighbors do

1560
01:45:21,880 --> 01:45:25,880
actually model functions a series of tall thin boxes

1561
01:45:25,890 --> 01:45:30,520
all right i'm going to be talking primarily about sigmoidal networks a mixture gaussians as

1562
01:45:30,520 --> 01:45:34,730
we go get the piece need for discriminative training is some kind of a

1563
01:45:34,750 --> 01:45:37,680
differentiable error metric and

1564
01:45:37,740 --> 01:45:42,430
most of the organs or talk about can be can be trained using either minkowski

1565
01:45:42,430 --> 01:45:46,460
norm or using some kind of likelihood function which is

1566
01:45:46,470 --> 01:45:53,000
in fact logarithmic minkowski norm so i think asking or so the the best norm

1567
01:45:53,020 --> 01:45:56,030
usually the one that we really want is the zero norm we really want to

1568
01:45:56,030 --> 01:46:01,290
find we really want to say that the the hypothesis it's the data is correct

1569
01:46:01,290 --> 01:46:04,540
if it's exactly equal to the labels that we're trying to get

1570
01:46:04,570 --> 01:46:11,750
the problem is that that's not very trainable parametric if in fact the hypothesis is

1571
01:46:11,750 --> 01:46:16,370
not exactly equal to the target label what do we do next

1572
01:46:16,380 --> 01:46:17,470
and so

1573
01:46:17,500 --> 01:46:23,090
and so we have a series of trainable error metrics for example the manhattan distance

1574
01:46:23,090 --> 01:46:25,070
in the euclidean distance

1575
01:46:25,120 --> 01:46:30,400
we're essentially if we train the neural network to minimize the to minimize manhattan distance

1576
01:46:30,400 --> 01:46:35,090
we wind up with a neural network that computes the that computes the ob posterior

1577
01:46:35,090 --> 01:46:40,220
or a median of the of the label distribution if we minimize the euclidean distance

1578
01:46:40,220 --> 01:46:47,920
we can recreate in neural network to compute the posterior mean of the label distribution

1579
01:46:47,930 --> 01:46:51,590
and then finally we apply the chain rule in order to minimize

1580
01:46:51,630 --> 01:46:56,370
that is for each of the training tokens until the area starts change stop changing

1581
01:46:56,610 --> 01:47:01,570
we take our parameter setting we adjusted in the negative direction of the gradient

1582
01:47:01,590 --> 01:47:06,650
we just eight as necessary in order to minimize the minimize the error along the

1583
01:47:06,650 --> 01:47:10,680
direction of the line was chosen with the direction of the line is computed can

1584
01:47:10,680 --> 01:47:14,730
be broken down because of the structure of the universal approximator so here's where ryman

1585
01:47:14,730 --> 01:47:19,490
actually comes in to help us to the universal approximator says that the the functional

1586
01:47:19,490 --> 01:47:24,050
approximation or creating is the sum of one of the very very large number of

1587
01:47:24,050 --> 01:47:28,630
tall thin boxes and each of those tall thin boxes adjusted only in order to

1588
01:47:29,040 --> 01:47:32,770
all in order to approximate the training samples the fall close to the tall thin

1589
01:47:32,770 --> 01:47:37,730
box so we compute the derivative of the error with respect to the hypothesis at

1590
01:47:37,730 --> 01:47:39,200
that particular

1591
01:47:39,210 --> 01:47:42,500
at that particular IP training sample

1592
01:47:42,830 --> 01:47:47,430
and then find the gradient of the that that particular hypothesis with respect to the

1593
01:47:47,430 --> 01:47:51,500
parameters set

1594
01:47:51,510 --> 01:47:56,700
all right see the applications of this in audio processing are so ubiquitous that haven't

1595
01:47:56,700 --> 01:47:59,480
so coming near the end of the course

1596
01:47:59,490 --> 01:48:02,970
this lecture

1597
01:48:02,980 --> 01:48:04,910
well be a mixture of

1598
01:48:06,160 --> 01:48:07,820
linear algebra

1599
01:48:07,840 --> 01:48:10,360
that comes with a change of basis

1600
01:48:10,380 --> 01:48:15,470
and the change of basis from one place to another basis is something

1601
01:48:15,480 --> 01:48:16,610
you really do

1602
01:48:16,630 --> 01:48:18,240
and applications

1603
01:48:18,250 --> 01:48:22,990
and i would like to talk about those applications i got a little bit involved

1604
01:48:22,990 --> 01:48:24,690
with compression

1605
01:48:24,700 --> 01:48:27,620
compressing the signal compressing an image

1606
01:48:27,660 --> 01:48:30,170
and that's exactly

1607
01:48:30,190 --> 01:48:31,870
change of basis

1608
01:48:31,880 --> 01:48:32,910
and then

1609
01:48:33,810 --> 01:48:36,530
the main theme in this chapter

1610
01:48:36,640 --> 01:48:41,690
is that the connection between a linear transformation

1611
01:48:41,700 --> 01:48:44,550
which doesn't have to have coordinates

1612
01:48:44,590 --> 01:48:46,980
and the matrix

1613
01:48:47,030 --> 01:48:50,740
that tells us that transformation with respect to

1614
01:48:51,860 --> 01:48:54,750
so the matrix is the based

1615
01:48:55,940 --> 01:48:58,780
of the of the linear transformation

1616
01:48:58,800 --> 01:49:03,190
let me start out with the nice part which is

1617
01:49:03,200 --> 01:49:06,520
so just to tell you something about image compression

1618
01:49:06,530 --> 01:49:10,330
i was of you well everybody's going to meet compression because

1619
01:49:10,330 --> 01:49:13,440
you know that the amount of data

1620
01:49:13,520 --> 01:49:15,500
that we're getting

1621
01:49:15,500 --> 01:49:18,530
well the these lectures are compressed

1622
01:49:18,830 --> 01:49:22,660
ah so that actually probably you see

1623
01:49:22,700 --> 01:49:28,250
my motion as chair jerking so i use that word have you have you looked

1624
01:49:28,250 --> 01:49:29,440
on the web

1625
01:49:30,780 --> 01:49:33,420
i would like to find a better word

1626
01:49:33,470 --> 01:49:36,410
compressed let's say so my

1627
01:49:36,440 --> 01:49:37,860
that the that

1628
01:49:37,880 --> 01:49:40,470
complete signal is of course in those

1629
01:49:40,530 --> 01:49:43,330
video cameras and in the video tape

1630
01:49:43,380 --> 01:49:46,360
but that goes to the bottom of building nine

1631
01:49:46,390 --> 01:49:48,830
and out of that comes

1632
01:49:48,870 --> 01:49:50,950
jumping motion

1633
01:49:51,000 --> 01:49:56,800
because it uses the standard system for compressing images

1634
01:49:56,800 --> 01:50:01,770
and you'll notice that the stuff that sits on the board

1635
01:50:01,770 --> 01:50:03,480
becomes very clearly

1636
01:50:03,540 --> 01:50:06,890
but it's my motion that that

1637
01:50:06,890 --> 01:50:09,950
that needs a lot of bits right

1638
01:50:09,980 --> 01:50:14,680
so and if i were to run up and back up there and back that

1639
01:50:14,680 --> 01:50:17,710
would be too many bits and they would be

1640
01:50:19,090 --> 01:50:20,640
even more

1641
01:50:20,640 --> 01:50:23,450
so what is compression mean

1642
01:50:23,510 --> 01:50:27,360
ten i mean just think of a still image

1643
01:50:27,370 --> 01:50:36,950
and four satellites all and computations of the climate computations of combustion that

1644
01:50:36,950 --> 01:50:44,540
computers and sensors of all kinds are just giving us overwhelming amounts of data

1645
01:50:44,580 --> 01:50:47,050
the web is to now

1646
01:50:47,070 --> 01:50:50,610
some compression can be done with no loss

1647
01:50:50,640 --> 01:50:53,790
lossless compression is possible just using

1648
01:50:53,800 --> 01:50:55,490
sort of the fact that

1649
01:50:55,860 --> 01:51:02,480
there is there are redundancies but i'm talking here about lossy compression so i'm talking

1650
01:51:03,670 --> 01:51:06,670
here is an image

1651
01:51:06,680 --> 01:51:12,510
and what is an image consist it consists of a lot of little pixels right

1652
01:51:12,540 --> 01:51:16,790
maybe five hundred twelve by five hundred twelve

1653
01:51:16,800 --> 01:51:19,950
due to the night by two to the ninth pixels

1654
01:51:19,950 --> 01:51:21,120
and each

1655
01:51:21,140 --> 01:51:22,580
so that this is

1656
01:51:22,600 --> 01:51:25,360
pixel number one one

1657
01:51:25,390 --> 01:51:27,990
so that's the pixel

1658
01:51:30,110 --> 01:51:32,080
if we're in black and white

1659
01:51:32,180 --> 01:51:35,420
the typical pixel would tell us

1660
01:51:35,480 --> 01:51:37,580
a scale

1661
01:51:37,600 --> 01:51:40,390
from zero to two fifty five

1662
01:51:40,400 --> 01:51:44,070
so the pixel is usually a value of

1663
01:51:44,080 --> 01:51:46,170
a one of the

1664
01:51:46,180 --> 01:51:47,080
x y

1665
01:51:47,080 --> 01:51:49,850
so this is the i th pixel

1666
01:51:49,980 --> 01:51:54,680
it's usually a real number on a scale from zero to two fifty five in

1667
01:51:54,680 --> 01:51:57,950
other words to totally eight possibilities

1668
01:51:57,980 --> 01:51:59,210
so usually

1669
01:51:59,210 --> 01:52:03,250
be again a set of values it may be

1670
01:52:03,350 --> 01:52:07,390
whatever the problem requires then

1671
01:52:07,440 --> 01:52:09,690
mutation is is

1672
01:52:09,700 --> 01:52:13,200
selecting random you certainly returned changing

1673
01:52:13,210 --> 01:52:16,390
from zero to one or vice versa

1674
01:52:16,410 --> 01:52:21,520
now draws over is believed to be the key operator genetic algorithms

1675
01:52:23,020 --> 01:52:28,150
again it mothers a certain processes known from biological

1676
01:52:30,460 --> 01:52:33,480
for our algorithm it is important

1677
01:52:33,510 --> 01:52:35,200
as it performs

1678
01:52:35,200 --> 01:52:39,160
exchange of information between individuals

1679
01:52:39,180 --> 01:52:43,050
now how this is done we have and

1680
01:52:43,070 --> 01:52:51,030
a simple example here this is the very end of the crossover record simple or

1681
01:52:51,030 --> 01:52:53,000
single point crossover

1682
01:52:53,030 --> 01:52:55,420
relation consists of

1683
01:52:55,430 --> 01:53:00,460
binary strings two of them are shown here as parents

1684
01:53:00,470 --> 01:53:03,790
the one on the red one

1685
01:53:03,830 --> 01:53:07,350
they are selected randomly in the population

1686
01:53:07,360 --> 01:53:08,340
the next

1687
01:53:08,350 --> 01:53:13,710
o thing that happens randomly is we select a certain point

1688
01:53:14,570 --> 01:53:16,830
crossing site

1689
01:53:16,850 --> 01:53:20,430
and what happens finally is that

1690
01:53:20,450 --> 01:53:22,610
these two substring

1691
01:53:22,620 --> 01:53:27,880
substrings are exchanged so from two parents you get

1692
01:53:27,940 --> 01:53:29,180
two offspring

1693
01:53:29,260 --> 01:53:31,970
as shown here

1694
01:53:31,990 --> 01:53:33,040
and these

1695
01:53:33,060 --> 01:53:34,300
two strings

1696
01:53:34,310 --> 01:53:39,260
present new points in the search space or new solutions

1697
01:53:39,290 --> 01:53:41,000
at this point

1698
01:53:41,070 --> 01:53:43,920
that is performing this operation

1699
01:53:43,940 --> 01:53:46,180
we didn't check

1700
01:53:46,320 --> 01:53:51,600
the quality of the solutions so this is performed syntactically

1701
01:53:51,620 --> 01:53:55,910
but just in the next step which would be the selection

1702
01:53:55,920 --> 01:53:59,500
bad solutions will be discarded and

1703
01:53:59,530 --> 01:54:01,670
good solutions will

1704
01:54:03,960 --> 01:54:06,810
to contribute to the next generation

1705
01:54:07,540 --> 01:54:10,830
the idea is to combine two

1706
01:54:10,840 --> 01:54:13,660
processes one is sort of

1707
01:54:13,670 --> 01:54:19,030
random exchange of information and mutating that

1708
01:54:20,220 --> 01:54:26,760
which is actually the exploration generating new points in the search space then we get

1709
01:54:26,780 --> 01:54:28,820
all the applied the second

1710
01:54:28,830 --> 01:54:35,120
step which is selection these models the principle of the survival of the fittest which

1711
01:54:35,120 --> 01:54:41,210
means solutions survive and multiply even just like in nature but

1712
01:54:41,410 --> 01:54:44,090
best solutions

1713
01:54:44,880 --> 01:54:46,610
left out today they

1714
01:54:46,930 --> 01:54:49,670
this card

1715
01:54:50,900 --> 01:54:52,960
regarding the selection

1716
01:54:53,840 --> 01:54:55,060
again many

1717
01:54:55,080 --> 01:55:01,620
versions of doing this procedure but the traditional approaches fitness proportionate

1718
01:55:01,650 --> 01:55:04,050
which actually means

1719
01:55:04,060 --> 01:55:08,460
probabilistic multiplication of solutions

1720
01:55:08,470 --> 01:55:15,980
according to their fitness values so fitness is actually a measure of goodness of solutions

1721
01:55:16,580 --> 01:55:22,220
again this is the i the objective functions used directly as given by our problem

1722
01:55:22,250 --> 01:55:28,460
or some modified form of the first of the dysfunction tailored to the needs of

1723
01:55:28,460 --> 01:55:31,350
our specific problems

1724
01:55:31,370 --> 01:55:33,440
and with him and so on

1725
01:55:33,460 --> 01:55:37,580
so one idea is to implement

1726
01:55:37,580 --> 01:55:44,280
these fitness proportionate solutions to the so-called roulette wheel models

1727
01:55:44,300 --> 01:55:45,830
what does it mean

1728
01:55:45,840 --> 01:55:47,050
first the

1729
01:55:47,440 --> 01:55:49,830
theoretical background

1730
01:55:49,830 --> 01:55:54,090
if had a population of n individuals

1731
01:55:54,110 --> 01:55:56,870
and solutions and strings with this every to

1732
01:55:59,050 --> 01:56:04,680
each solution is evaluated according to the fitness function let it be

1733
01:56:04,700 --> 01:56:06,320
the function f

1734
01:56:07,210 --> 01:56:11,450
if the sum of their fitness values is sigma s

1735
01:56:11,460 --> 01:56:15,980
and the average function average fitness is have average

1736
01:56:17,230 --> 01:56:19,080
according to this model

1737
01:56:19,090 --> 01:56:22,670
the expected number of copies of the

1738
01:56:22,940 --> 01:56:29,960
i individual would fitness f i because two this expression now what does it mean

1739
01:56:30,110 --> 01:56:34,010
and is the number of individuals in the population

1740
01:56:34,070 --> 01:56:36,780
this individual i

1741
01:56:36,830 --> 01:56:41,090
with the fitness of i is now

1742
01:56:42,030 --> 01:56:47,380
in the selection process we are trying to find how many copies of it will

1743
01:56:47,480 --> 01:56:49,690
result from this procedure

1744
01:56:49,960 --> 01:56:55,720
so this is divided by sigma after so if we take this two

1745
01:56:55,730 --> 01:56:57,410
terms and

1746
01:56:57,540 --> 01:57:00,480
or sigma have divided by and this is

1747
01:57:00,530 --> 01:57:02,830
just the average fitness so

1748
01:57:02,840 --> 01:57:04,400
comparing the

1749
01:57:04,410 --> 01:57:08,110
fitness of the particular individuals with the average

1750
01:57:08,120 --> 01:57:14,310
determines the probability of multiplication what does it mean

1751
01:57:14,310 --> 01:57:15,790
up to size five

1752
01:57:17,560 --> 01:57:19,700
unigrams would missing words

1753
01:57:19,710 --> 01:57:22,220
bi grams are not the words

1754
01:57:22,240 --> 01:57:25,190
three words fourgrams in five

1755
01:57:25,210 --> 01:57:32,540
and i think one example presence these fires

1756
01:57:32,560 --> 01:57:33,920
look like this

1757
01:57:33,930 --> 01:57:36,940
so we see karen makes community

1758
01:57:36,980 --> 01:57:39,040
px on the them

1759
01:57:39,060 --> 01:57:41,340
two hundred thousand times

1760
01:57:41,390 --> 01:57:46,480
or ceramics companies fifty three times and and so on

1761
01:57:46,490 --> 01:57:51,960
actually this is grammar school community

1762
01:57:51,980 --> 01:57:56,050
and in common because of the three d one

1763
01:57:56,080 --> 01:58:00,480
or serve as the inspiration for these are forward disappeared this

1764
01:58:00,490 --> 01:58:04,560
particular set of strings appear on the web or in the corpus index

1765
01:58:04,580 --> 01:58:06,430
seven hundred ninety

1766
01:58:08,750 --> 01:58:11,370
well as we have sixty gigawatts of such

1767
01:58:11,460 --> 01:58:15,250
frequency distributions in this is

1768
01:58:15,520 --> 01:58:20,500
quite valuable resource for any anybody working in

1769
01:58:21,450 --> 01:58:25,890
this is something which you can check

1770
01:58:25,940 --> 01:58:28,430
you can download these because simply

1771
01:58:28,440 --> 01:58:31,300
o thing is to be with you can order it and you get it for

1772
01:58:34,250 --> 01:58:44,680
another level of representation of text representation is part of speech

1773
01:58:44,680 --> 01:58:46,430
part of speech text

1774
01:58:46,440 --> 01:58:48,390
so here

1775
01:58:48,400 --> 01:58:52,490
we go one step ahead from the phrases

1776
01:58:54,870 --> 01:58:55,750
so basically

1777
01:58:55,750 --> 01:59:00,700
the task here is the following together texts and we would like to assign to

1778
01:59:00,700 --> 01:59:04,750
each word in the text that which

1779
01:59:04,780 --> 01:59:07,490
denotes type of the work

1780
01:59:12,850 --> 01:59:18,090
so maybe i can show the example so these are

1781
01:59:18,100 --> 01:59:21,000
types of the words which we usually do it so

1782
01:59:21,010 --> 01:59:25,500
we're now adjective adverb pronoun preposition conjunction

1783
01:59:25,500 --> 01:59:30,070
inter injection so these are

1784
01:59:31,780 --> 01:59:34,910
no no no no adjectives are

1785
01:59:35,050 --> 01:59:37,710
the features of the work

1786
01:59:37,720 --> 01:59:42,400
a four and so on so basically these are the main the main categories

1787
01:59:42,410 --> 01:59:46,240
and now the task of part of speech degrees

1788
01:59:46,250 --> 01:59:49,990
tool signed the right categories to each of the words and so this is an

1789
01:59:51,080 --> 01:59:53,250
let's see if we have

1790
01:59:53,430 --> 01:59:56,240
if you have a sentence

1791
01:59:56,300 --> 02:00:01,230
like she ran to the station quickly so that each

1792
02:00:01,310 --> 02:00:06,250
it gets its stuck pronouns were preposition adjective noun

1793
02:00:06,270 --> 02:00:10,270
usually we deal with the

1794
02:00:10,290 --> 02:00:16,750
well because we can have many many coded hand coded rules for

1795
02:00:16,990 --> 02:00:20,730
tagging such attacks but usually we do this by

1796
02:00:20,740 --> 02:00:22,500
with statistical techniques and

1797
02:00:22,520 --> 02:00:25,910
we learned attacker and this would be usually used

1798
02:00:25,920 --> 02:00:28,540
it's hidden markov models that link

1799
02:00:29,050 --> 02:00:31,010
this so this is something which

1800
02:00:31,600 --> 02:00:34,260
well at least next level of a

1801
02:00:34,270 --> 02:00:39,140
text representation why we would need this especially for tasks like

1802
02:00:39,350 --> 02:00:43,260
named entity extraction truancy and a little bit later

1803
02:00:46,060 --> 02:00:53,640
feature selection because the couple of dust which which would use these texts

1804
02:00:55,140 --> 02:00:57,740
OK another next level of

1805
02:00:58,490 --> 02:01:00,280
text presentation is

1806
02:01:00,310 --> 02:01:04,800
one using these taxonomies started designers

1807
02:01:04,900 --> 02:01:09,120
what is our desire probably you know from the

1808
02:01:09,160 --> 02:01:11,750
book this is

1809
02:01:12,190 --> 02:01:17,500
a sort of database which connects the different

1810
02:01:17,570 --> 02:01:19,860
the words or phrases

1811
02:01:19,870 --> 02:01:24,920
with the same meaning into the same sense and the senses are then interlink some

1812
02:01:24,920 --> 02:01:31,940
kind of a higher level structure which see written later on

1813
02:01:31,950 --> 02:01:36,870
and on the that the most commonly used general thesaurus is

1814
02:01:36,900 --> 02:01:41,430
wordnet which exists originally

1815
02:01:41,440 --> 02:01:47,820
it was made in english and now it exists in many other languages eurowordnet has

1816
02:01:47,980 --> 02:01:49,020
which covers a lot of

1817
02:01:49,480 --> 02:01:52,730
european languages i think check check

1818
02:01:53,470 --> 02:01:58,710
language has one things you have pretty strong with asian linguistic here

1819
02:01:59,750 --> 02:02:00,890
and so

1820
02:02:00,900 --> 02:02:02,890
many other languages have this is

1821
02:02:02,940 --> 02:02:09,500
and many many are still ongoing efforts to be so what is what

1822
02:02:09,520 --> 02:02:18,550
basically what it consist from four main databases so the database of nouns database of

1823
02:02:18,550 --> 02:02:21,330
verbs adjectives and adverbs

1824
02:02:21,450 --> 02:02:25,700
and each database consists from

1825
02:02:25,700 --> 02:02:28,300
many entries and each entry is

1826
02:02:28,320 --> 02:02:29,540
one sense

1827
02:02:29,560 --> 02:02:32,840
one senses one meaning of the word

1828
02:02:32,860 --> 02:02:33,730
it's a

1829
02:02:34,190 --> 02:02:39,500
in a sense because all the synonyms all different words which mean the same

1830
02:02:40,560 --> 02:02:45,400
it's a musician instrumentalist player so this would be the sense for

1831
02:02:45,430 --> 02:02:50,730
musicians of all these three words which would mean the same or person individual someone


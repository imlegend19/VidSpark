1
00:00:00,000 --> 00:00:01,790
hit rates and then we just

2
00:00:01,810 --> 00:00:04,420
the magic transforming it

3
00:00:08,250 --> 00:00:12,440
OK so prior distribution so we similar prior distributions to what i used in the

4
00:00:12,460 --> 00:00:16,900
simple analysis it slightly different because we're doing this induced prior by using the

5
00:00:16,920 --> 00:00:18,310
arc sin transformation

6
00:00:18,330 --> 00:00:22,370
but not informative prior just allows it to be anything so someone says i have

7
00:00:22,370 --> 00:00:23,580
no clue

8
00:00:23,640 --> 00:00:26,060
can be anything so we just put it

9
00:00:26,960 --> 00:00:29,620
than informative prior and you know real numbers

10
00:00:29,660 --> 00:00:32,660
and again you was meaning dark side transformed

11
00:00:32,670 --> 00:00:36,850
p is a weakly informative priors are like the open minded one so we use

12
00:00:36,850 --> 00:00:40,710
the median p is point two five and ninety five percent and ninety percent sure

13
00:00:40,710 --> 00:00:44,250
that falls between point one two o point four one and the reason for the

14
00:00:44,250 --> 00:00:48,460
odds are nonsymmetric interval around point two five because we're actually putting the prior to

15
00:00:48,540 --> 00:00:50,850
signing the arcs and transformed

16
00:00:51,690 --> 00:00:55,900
the believers prior again we use the median point three three and ninety percent sure

17
00:00:55,900 --> 00:01:00,690
that falls between point three o twenty six and the skeptics prior medium point two

18
00:01:01,370 --> 00:01:03,140
first ninety percent sure

19
00:01:03,140 --> 00:01:08,770
that median is between o point two four five point two five five

20
00:01:08,850 --> 00:01:12,060
and i don't expect to reduce the only reason is here

21
00:01:12,190 --> 00:01:15,790
is because and well up with this on my website and so if anyone wants

22
00:01:15,790 --> 00:01:19,170
to go look at the results and details can do so but i have summarized

23
00:01:19,170 --> 00:01:21,480
some of them for you

24
00:01:21,480 --> 00:01:25,520
OK so here some summary of the results so remember what we're doing is we're

25
00:01:25,520 --> 00:01:29,500
trying to get distribution for the possibilities for the medium

26
00:01:30,370 --> 00:01:33,190
and so the distribution of possibilities has its own

27
00:01:33,190 --> 00:01:35,660
fifty percent cut off its own medium

28
00:01:35,670 --> 00:01:40,060
and it has the first two point five percent nineteen ninety seven point five percent

29
00:01:40,060 --> 00:01:41,210
and and so on

30
00:01:41,230 --> 00:01:43,480
so here's what they are so

31
00:01:43,480 --> 00:01:45,690
basically what you can see is

32
00:01:45,690 --> 00:01:50,460
that we also frequentist analysis using maximum likelihood so in all these cases the median

33
00:01:50,460 --> 00:01:52,500
comes out about point three three

34
00:01:52,520 --> 00:01:56,790
the lower and the two point five percent happens at about point three and the

35
00:01:56,790 --> 00:01:58,960
other one about three six

36
00:01:58,980 --> 00:02:02,210
the believers still comes out about the same place in the middle

37
00:02:03,230 --> 00:02:04,500
as well

38
00:02:04,560 --> 00:02:08,890
maybe is slightly narrower book but the skeptics

39
00:02:08,920 --> 00:02:11,270
comes out still not convinced

40
00:02:11,330 --> 00:02:18,690
so point two five one is left shifted slightly but not by much

41
00:02:18,720 --> 00:02:21,640
if we try to look at the range for individual p so that was for

42
00:02:21,660 --> 00:02:22,690
the medium

43
00:02:22,770 --> 00:02:27,330
range for individual p is gets quite why the non informative prior one nine point

44
00:02:27,330 --> 00:02:32,020
four nine open-minded point one seven five one so very similar to the next likelihood

45
00:02:32,020 --> 00:02:34,810
estimate point one eight point five

46
00:02:34,810 --> 00:02:40,190
but then we get slightly narrower intervals for the believer especially for the skeptic by

47
00:02:40,190 --> 00:02:43,890
the way there's a typo in the proceedings for this just this very last one

48
00:02:43,920 --> 00:02:48,210
this is what should be doesn't say that proceedings

49
00:02:50,100 --> 00:02:55,580
what we found actually is suppose under the frequentist analysis and bayesian analysis of the

50
00:02:55,580 --> 00:02:59,350
data do indicate that there's is variation from study to study

51
00:02:59,370 --> 00:03:02,980
the difference in her right so just a binomial model may not be appropriate except

52
00:03:02,980 --> 00:03:06,460
for the null hypothesis under the null hypothesis

53
00:03:06,520 --> 00:03:10,690
so it looks like this five right here

54
00:03:10,750 --> 00:03:17,170
so comparing bayesian frequentist results results under frequentist bayesian noninformative and weakly informative open minded

55
00:03:17,170 --> 00:03:19,540
priors are actually pretty similar

56
00:03:19,540 --> 00:03:23,710
so the ninety five percent probability of median basically ranges from o point three o

57
00:03:23,710 --> 00:03:25,640
point three six

58
00:03:25,690 --> 00:03:28,730
but the bayesian analysis under informative priors

59
00:03:28,770 --> 00:03:33,190
is quite sensitive to the prior to the skeptics prior gives ninety five percent probability

60
00:03:33,190 --> 00:03:36,580
interval for median p is point two five hundred twenty six two

61
00:03:36,870 --> 00:03:40,560
the believers prior gives ninety five percent probability interval for median

62
00:03:40,640 --> 00:03:45,690
from point three o eight two o point three four five

63
00:03:45,730 --> 00:03:50,500
so can conclusions from the analyses the average rate for the population

64
00:03:50,560 --> 00:03:55,710
in other words hit rates if you look at possibly different rates for different studies

65
00:03:55,710 --> 00:04:00,420
it seems to be slightly above thirty percent whatever method is used except the skeptics

66
00:04:03,810 --> 00:04:08,170
binomial model with fixed p is too simple hit rates actually may change based on

67
00:04:08,170 --> 00:04:10,750
the number of factors

68
00:04:10,810 --> 00:04:16,060
so statistical models actually need to incorporate this additional information and variability may be put

69
00:04:16,060 --> 00:04:17,940
in information about participants

70
00:04:17,940 --> 00:04:22,960
conditions of the experiment the experimenter was and so on and for doing that bayesian

71
00:04:22,960 --> 00:04:26,100
approach actually like the most reasonable

72
00:04:26,100 --> 00:04:29,230
so teaching activities if you wanted to do this in your class what would you

73
00:04:29,230 --> 00:04:34,270
do well it's actually hate to tell you very difficult to do methodologically sound experiment

74
00:04:34,270 --> 00:04:36,960
in this area because you really do have to figure out how to rule out

75
00:04:36,980 --> 00:04:40,290
ordinary communication possible cheating

76
00:04:40,330 --> 00:04:43,500
if i wanted to say OK you're OK do an experiment

77
00:04:43,520 --> 00:04:47,770
i randomly selected target i want you to describe the show you four choices and

78
00:04:47,770 --> 00:04:49,730
you have to pick which one you think it is

79
00:04:49,750 --> 00:04:54,210
those independent sessions

80
00:04:55,900 --> 00:04:58,210
i think the same target for all of you

81
00:04:58,210 --> 00:05:03,170
and so the pair psychologists call this the stacking effect basically it's the non independence

82
00:05:03,170 --> 00:05:06,040
results from the fact that suppose i say you OK

83
00:05:06,060 --> 00:05:11,290
i have a picture drawn from national geographic picture randomly selected from national geographic possible

84
00:05:11,310 --> 00:05:12,540
pool target

85
00:05:12,560 --> 00:05:17,690
drop you think it is most of you are probably just something similar

86
00:05:17,690 --> 00:05:21,460
you would probably draw something i don't know with maybe an ocean trees or whatever

87
00:05:21,500 --> 00:05:24,940
what you've seen in national geographic magazine

88
00:05:25,000 --> 00:05:28,520
so when i have the right answer if it happens to be something

89
00:05:28,520 --> 00:05:31,140
the matches what you're most likely to draw

90
00:05:31,290 --> 00:05:34,040
you're all going to do really well if i have something that happens to not

91
00:05:34,040 --> 00:05:38,350
that we're all pretty likely to draw you into a simpler way to see this

92
00:05:38,890 --> 00:05:42,100
if i say OK randomly selected a number from one to ten

93
00:05:42,120 --> 00:05:45,020
because most of you picture yourself

94
00:05:45,020 --> 00:05:48,750
that happens to be a you'll do well if it doesn't you want so

95
00:05:48,750 --> 00:05:52,440
it's the not independent called the stacking effect so it's really hard to do this

96
00:05:52,920 --> 00:05:54,600
and ask for the the class

97
00:05:54,620 --> 00:05:58,350
i it's easier to assign projects for outside of class where individual sessions can be

98
00:05:58,350 --> 00:06:03,600
used actually did i understand our davis of four unit honors seminar

99
00:06:03,620 --> 00:06:08,870
it was called testing psychic claims from say answers to statistics and i trace the

100
00:06:08,870 --> 00:06:13,120
history of research in this area from when they used to use the sciences

101
00:06:14,600 --> 00:06:18,310
the more sophisticated statistical methods are are used and i had the students work in

102
00:06:18,310 --> 00:06:20,120
teams to do project

103
00:06:20,170 --> 00:06:23,370
and one of the team's actually did i dream study

104
00:06:23,390 --> 00:06:25,920
where they had people in their teens

105
00:06:25,920 --> 00:06:30,060
so when i an assistant and she would randomly selected target

106
00:06:30,080 --> 00:06:33,210
any given night and they would all try to dream about it

107
00:06:33,210 --> 00:06:37,020
in the morning they will be shown four choices and they would get together and

108
00:06:37,020 --> 00:06:40,480
try to figure out which of the four traces was and they actually did pretty

109
00:06:40,480 --> 00:06:44,790
well they had a signet statistically significant study at the end and so we published

110
00:06:44,790 --> 00:06:49,570
twenty percent of the data is missing and you can reconstruct cascades when you have

111
00:06:49,600 --> 00:06:53,000
even around ninety percent of the missing data so the idea is that even though

112
00:06:53,260 --> 00:06:57,360
you went online and collected incomplete data you can use some kind of model based

113
00:06:57,360 --> 00:06:58,500
techniques actually

114
00:06:58,800 --> 00:07:03,520
connected disconnected pieces of cascades and really reason about how the complete data would look

115
00:07:03,520 --> 00:07:08,010
like it's just something you have in mind when you do this kind of analysis

116
00:07:09,110 --> 00:07:13,290
this is the first way to trace information tracing hyperlinks a second way of tracing

117
00:07:13,290 --> 00:07:18,260
information with which is very popular lately is to use it right so it is

118
00:07:18,260 --> 00:07:22,600
an information and each user generates a stream of bits of sort of the hundred

119
00:07:22,600 --> 00:07:27,970
forty characters long messages and then also to the users can subscribe to follow streams

120
00:07:27,970 --> 00:07:32,240
of others and that sort of three ways how to track information flow in so

121
00:07:32,240 --> 00:07:36,670
the first way is to trace the spread of what is called hashtags i'll explain

122
00:07:36,670 --> 00:07:41,710
what hashtags are the second the next thing is similar to hashtags is particularly URL's

123
00:07:42,020 --> 00:07:47,130
and last option is sort explicit way how people can for interesting pieces of information

124
00:07:47,130 --> 00:07:52,430
through the mechanism called the tweets that i also described so the first what do

125
00:07:52,430 --> 00:07:59,880
i mean by hashtags right so here is about so i was preparing this slides

126
00:07:59,890 --> 00:08:03,270
i i sort of focused on the on the

127
00:08:03,280 --> 00:08:08,500
crisis or revolution in egypt right the things about the bottom right of the president

128
00:08:08,500 --> 00:08:12,530
right so the idea is that when people who about something they can put this

129
00:08:12,530 --> 00:08:17,550
hashtag infront of a particular keyword and now becomes like a bag for that for

130
00:08:17,550 --> 00:08:22,170
that for that for the person or something like somebody here used to hashtags one

131
00:08:22,180 --> 00:08:28,800
is cash obama the other cashmore barack right so many times discussion tags mean particular

132
00:08:28,800 --> 00:08:33,300
people sometimes they are very sort of culturally specific so for example the one of

133
00:08:33,300 --> 00:08:40,210
the most popular hashtags in january two thousand eleven was need new boyfriend right and

134
00:08:40,240 --> 00:08:45,010
the idea was that sort of people with exchanges sort of stories about their ex-boyfriends

135
00:08:45,010 --> 00:08:48,470
and they would that this kind of stories know you need what new boyfriend type

136
00:08:48,470 --> 00:08:52,580
of hashtag or there is another one that was called he grocery striking this is

137
00:08:52,580 --> 00:08:55,940
sort of a joke but instead of having a grocery list of things of i

138
00:08:56,340 --> 00:09:00,420
buy in a store you'd have a list of hip-hop artists and again right so

139
00:09:00,420 --> 00:09:04,970
we have this cash that could keep up groceries that people would put next to

140
00:09:04,980 --> 00:09:09,540
next to the streets right so this hashtags what is really about them is that

141
00:09:09,570 --> 00:09:14,180
they emerge naturally from inside the network so now we can place how they spread

142
00:09:14,180 --> 00:09:17,790
through the network right so the idea the way you can do this is to

143
00:09:17,790 --> 00:09:21,590
say hard because they had underlying network who follows home and if i make the

144
00:09:21,590 --> 00:09:27,230
assumption that hashtags only emerge through the inside the network then i can trace how

145
00:09:27,230 --> 00:09:33,200
information spreads right so so if b follows a and mentions cash the maximum product

146
00:09:33,200 --> 00:09:37,420
of a and b we mention it tomorrow and because b follows a i could

147
00:09:37,420 --> 00:09:42,700
make this assumption that this information about the product spread from a to to so

148
00:09:42,700 --> 00:09:46,610
that is the first way how we can do things the second way that is

149
00:09:46,610 --> 00:09:51,880
similar is because is you have tried so many times which contains URL school interesting

150
00:09:51,880 --> 00:09:55,300
articles that people want to talk about that so here is an example of

151
00:09:55,310 --> 00:09:59,790
of what that has a particular shortened URL in right so so now what we

152
00:09:59,790 --> 00:10:03,530
can do again we can use the same thing with betrays the appearances of this

153
00:10:04,700 --> 00:10:09,160
in the streets and in this way we can start making assumptions and starting to

154
00:10:09,160 --> 00:10:15,100
see how how this usage of these you as flows through the network one important

155
00:10:15,100 --> 00:10:18,520
thing would be to do what else is that this URL hash that shortened so

156
00:10:18,520 --> 00:10:24,130
that services like twitter because his own one that is it is popular already put

157
00:10:24,130 --> 00:10:28,160
in a long URL and to give you a very short URL and many times

158
00:10:28,160 --> 00:10:32,770
the short actually the cached versions of URL personalized so if i can show you

159
00:10:32,770 --> 00:10:36,310
what i get a different hash code if you had the URL so we can

160
00:10:36,310 --> 00:10:40,350
only then attribute who was the person that was spreading the URL through the network

161
00:10:40,350 --> 00:10:45,570
and sometimes of course that can also not be the case so these are two

162
00:10:45,570 --> 00:10:49,370
things that people have done a lot of studies about how information refuses to distributed

163
00:10:49,600 --> 00:10:53,610
through by studying adoption of hashtags or something adoption of

164
00:10:53,720 --> 00:10:54,600
u s

165
00:10:54,630 --> 00:11:00,670
and the second thing that is explicit about information is is a mechanism called it's

166
00:11:00,670 --> 00:11:03,650
he looks slightly perkier than you did

167
00:11:03,670 --> 00:11:08,040
yesterday because you're only halfway through the hours last time three quarters

168
00:11:08,050 --> 00:11:12,120
so this is what we were talking about last time

169
00:11:13,600 --> 00:11:16,720
markov model here remember defined over

170
00:11:16,740 --> 00:11:22,630
the graph of pixels with the simplest conductivity north south east and west

171
00:11:22,690 --> 00:11:29,330
and we were we had it in from your probabilistic form as as product of

172
00:11:29,330 --> 00:11:32,890
factors and then just for convenience i also wrote down in this form as the

173
00:11:32,900 --> 00:11:33,790
sum of

174
00:11:33,830 --> 00:11:36,110
the logs of those factors

175
00:11:36,120 --> 00:11:39,000
the negative log and

176
00:11:39,010 --> 00:11:42,400
that's convenient and you remember the kind of

177
00:11:42,400 --> 00:11:47,480
the business end of the of this prior distribution is this little expression here which

178
00:11:49,180 --> 00:11:54,980
in energy terms that is it or in probabilistic terms reduces the probability every time

179
00:11:55,000 --> 00:11:59,970
there's a pair of adjacent pixels with different labelings zero and the y and then

180
00:11:59,970 --> 00:12:00,800
we also

181
00:12:00,910 --> 00:12:04,120
is that aside about you know when you stop and think about it that actually

182
00:12:04,120 --> 00:12:07,900
equivalent to having a prior which

183
00:12:07,920 --> 00:12:10,640
many which says that

184
00:12:10,640 --> 00:12:13,330
the outline of the object is the more probable

185
00:12:13,340 --> 00:12:18,450
the shorter line is which is bizarre because it has become completely the truth because

186
00:12:18,450 --> 00:12:20,840
then the most probable outline would be you know

187
00:12:20,890 --> 00:12:22,590
vanishingly small so

188
00:12:23,190 --> 00:12:27,980
if we were really to sit down and construct exactly the prior we wanted that

189
00:12:27,980 --> 00:12:33,360
probably wouldn't be it on the other hand you know it's great to have tractable

190
00:12:33,360 --> 00:12:36,190
priors that do something for you

191
00:12:36,200 --> 00:12:40,110
and this prior we're going to see is is very tractable

192
00:12:40,110 --> 00:12:44,950
i did the thing that does do for us is that it

193
00:12:44,950 --> 00:12:50,280
it argues in favour of the smooth outline rather than a weekly outlining more or

194
00:12:50,280 --> 00:12:54,670
less the same place so you given two outlines that include the same more or

195
00:12:54,670 --> 00:12:57,890
less the same pixels as data the weekly one is going to have a lot

196
00:12:58,530 --> 00:13:00,830
a lot more length and so that's going to be down

197
00:13:00,840 --> 00:13:02,510
that's going to be

198
00:13:02,580 --> 00:13:06,690
get less probability in this in this prize

199
00:13:06,730 --> 00:13:10,110
so that's where we got to this parameter gamma which in energy terms is the

200
00:13:10,110 --> 00:13:12,860
penalty that levied for

201
00:13:12,880 --> 00:13:16,130
one unit of parameter length

202
00:13:16,140 --> 00:13:19,130
and so the problem is

203
00:13:19,730 --> 00:13:21,610
how do you maximise this

204
00:13:21,610 --> 00:13:26,980
and how do maximizing energy of this form some of the sum of terms expressed

205
00:13:26,980 --> 00:13:27,790
over this

206
00:13:27,820 --> 00:13:30,790
graph and that's what you know that's what this lecture is going to be all

207
00:13:31,490 --> 00:13:33,260
and i should this

208
00:13:33,290 --> 00:13:36,990
picture which was you kind of tease that i'm sure been keeping you awake at

209
00:13:39,890 --> 00:13:40,800
which was that

210
00:13:40,820 --> 00:13:46,290
you know if we do apply this penalty falling in

211
00:13:46,850 --> 00:13:51,420
manhattan distance then you tend to get these sorts of manhattan artifacts

212
00:13:53,200 --> 00:13:54,950
you know

213
00:13:55,080 --> 00:13:57,130
that's what you deserve

214
00:13:57,140 --> 00:14:00,420
measuring distance so crude

215
00:14:00,430 --> 00:14:02,180
and i wonder any of you have any

216
00:14:02,420 --> 00:14:06,110
and the great ideas what you might do to sort of

217
00:14:06,200 --> 00:14:08,420
make this work better any thoughts

218
00:14:15,860 --> 00:14:20,130
that sounds like a generically good thing to do i don't know what exactly him

219
00:14:20,130 --> 00:14:21,170
yes yes

220
00:14:24,110 --> 00:14:28,320
he was a lot more

221
00:14:28,330 --> 00:14:32,760
it's a good idea i mean the like yes i mean if weighted towards the

222
00:14:32,760 --> 00:14:35,920
likelihood we would certainly weight away from the prior it seems to be the prime

223
00:14:35,920 --> 00:14:38,880
doing the damage so i that's quite a good insight on the other hand if

224
00:14:38,880 --> 00:14:42,290
we if we wait all the way to the likelihood

225
00:14:43,330 --> 00:14:47,680
you know will be back in that's making individual decisions about pixels state and we

226
00:14:47,680 --> 00:14:48,670
know we don't want that so

227
00:14:49,140 --> 00:14:53,480
you know maybe there's a kind of a nice valley in between those two undesirable

228
00:14:58,790 --> 00:15:02,610
three years

229
00:15:02,700 --> 00:15:05,910
physical excel afterwards

230
00:15:05,980 --> 00:15:07,920
you think i think i do that

231
00:15:07,950 --> 00:15:09,420
but that's

232
00:15:09,480 --> 00:15:10,730
to hack that

233
00:15:12,100 --> 00:15:14,570
to good OK

234
00:15:14,580 --> 00:15:16,330
so not about idea

235
00:15:16,330 --> 00:15:18,860
any other thoughts before i

236
00:15:18,910 --> 00:15:23,750
what about you know what about attacking the root cause of the problem

237
00:15:25,120 --> 00:15:26,790
i think that's an excellent idea

238
00:15:26,790 --> 00:15:31,420
the man says diagonal connections so you know if we if we can have

239
00:15:31,420 --> 00:15:35,470
just increase the order of this markov random field to allow not only north south

240
00:15:35,470 --> 00:15:38,590
east west north east etcetera then

241
00:15:38,900 --> 00:15:40,590
effectively you be able to

242
00:15:40,610 --> 00:15:41,780
compose your

243
00:15:41,880 --> 00:15:45,290
instead of manhattan distance it will be barcelona distance

244
00:15:45,400 --> 00:15:49,800
you've been to barcelona you know have always have all those squares then they with

245
00:15:49,840 --> 00:15:53,420
the corners cut off diagonal if you noticed a sort of barcelona

246
00:15:53,470 --> 00:15:58,630
the barcelona thing to do this rather pretty improves the sight lines that they have

247
00:15:58,670 --> 00:16:02,660
the junction so it's been considered to be architecturally great thing to do so yes

248
00:16:02,660 --> 00:16:06,930
barcelona distance we could we could presumably get that if if we

249
00:16:07,340 --> 00:16:11,150
if we do that that's a very good idea people do that and you can

250
00:16:11,150 --> 00:16:12,680
even have high conductivity

251
00:16:12,690 --> 00:16:16,250
and that and that certainly helps

252
00:16:16,280 --> 00:16:17,530
another thing you can do

253
00:16:17,540 --> 00:16:19,110
which is perhaps more

254
00:16:19,130 --> 00:16:21,220
you know it is picking up to your

255
00:16:25,000 --> 00:16:27,620
this rather weird thing where we take the

256
00:16:27,630 --> 00:16:31,120
the icing term here here's the penalty as usual

257
00:16:31,130 --> 00:16:35,420
and we abated by term that depends on the data

258
00:16:35,430 --> 00:16:38,690
at this point you probably thinking a little bit dizzy and sick because you know

259
00:16:38,690 --> 00:16:40,440
this was supposed to be the prime

260
00:16:40,470 --> 00:16:42,870
part of the of the

261
00:16:42,900 --> 00:16:47,910
the model now somehow it's started depending on the data so that really is a

262
00:16:47,910 --> 00:16:53,050
little bit a little with you just suspend your your feelings and also just to

263
00:16:53,050 --> 00:16:54,280
have a little look at this

264
00:16:54,290 --> 00:16:58,660
this term what you see you see what's happening is that across the same pair

265
00:16:58,660 --> 00:17:02,500
of pixels where you're looking at the labels to see if the labels were different

266
00:17:02,570 --> 00:17:03,610
we are now

267
00:17:03,610 --> 00:17:07,790
looking at at the actual colors of the pixels and treating this

268
00:17:07,790 --> 00:17:13,050
penalty differently if the colour of the pixels across the boundary are also very different

269
00:17:14,460 --> 00:17:17,920
supposing i and j th pixel have very different colours so there

270
00:17:17,920 --> 00:17:26,610
the euclidean squared euclidean distance there is large compared with some mean that euclidean distance

271
00:17:26,610 --> 00:17:30,430
then what tends to happen is that this term get switched off this whole bracket

272
00:17:30,690 --> 00:17:32,120
will become something small

273
00:17:32,130 --> 00:17:32,880
and so

274
00:17:32,900 --> 00:17:35,130
the penalty will get abated

275
00:17:35,150 --> 00:17:38,810
so what that means is you pay a penalty in the new model everywhere there

276
00:17:38,850 --> 00:17:43,370
is a change of label except where this high contrast in the image

277
00:17:43,420 --> 00:17:47,060
because this difference of colours that there's going to the place where the contrast is

278
00:17:47,060 --> 00:17:50,610
high so it kind of you know he says OK you don't need to pay

279
00:17:50,660 --> 00:17:55,360
penalty here because the evidence is so strong it's a little strange this because it's

280
00:17:55,380 --> 00:17:56,070
sort of

281
00:17:56,690 --> 00:18:00,480
in a way double counting of evidence you might think we already said what the

282
00:18:01,340 --> 00:18:04,360
the term was going to be and that that's where all of the dependence on

283
00:18:04,360 --> 00:18:06,090
zee the data should be

284
00:18:10,590 --> 00:18:12,790
and now we kind of somehow

285
00:18:12,810 --> 00:18:14,160
cheated by

286
00:18:14,170 --> 00:18:17,930
bringing data into what was the prior to say for sure this is no longer

287
00:18:18,880 --> 00:18:20,870
and that's

288
00:18:20,970 --> 00:18:23,110
that's a little bit of something

289
00:18:23,120 --> 00:18:27,680
you know more hybrid enterprise and you might think well we actually don't have any

290
00:18:28,220 --> 00:18:32,070
decomposition into likelihood and prior and there kind of two

291
00:18:32,120 --> 00:18:34,520
attitudes to that one is to say well

292
00:18:34,530 --> 00:18:38,060
they you know that we have to have one it's just going to declare that

293
00:18:38,060 --> 00:18:41,670
this is the form of the posterior and if i have some free parameters in

294
00:18:41,670 --> 00:18:45,870
perhaps the biggest opportunities to learn the values of free parameters is not completely a

295
00:18:45,870 --> 00:18:48,990
god-given posterior

296
00:18:49,020 --> 00:18:51,170
and so that's that's the

297
00:18:51,170 --> 00:18:55,850
conditional random field idea which is a markov random field doesn't partition in any obvious

298
00:18:55,850 --> 00:18:57,530
this curve here

299
00:18:57,540 --> 00:19:00,060
and we have used for a variety

300
00:19:04,640 --> 00:19:08,490
solid wire so let's look at the top here this is hydrogen

301
00:19:08,540 --> 00:19:09,830
and you can see that the

302
00:19:09,870 --> 00:19:16,640
conductivity of excuse me diffusivity of hydrogen increases with temperature up to the temperature at

303
00:19:16,640 --> 00:19:22,330
which i and converts from BCC FCC and there's is an abrupt drop in the

304
00:19:22,330 --> 00:19:24,200
diffusivity of

305
00:19:24,220 --> 00:19:26,100
hydrogen what's happening

306
00:19:26,160 --> 00:19:31,790
what's happening what's the void fraction of BCC versus the void fraction of FCC

307
00:19:31,810 --> 00:19:35,640
FCC is more tightly packed so we see an abrupt for

308
00:19:35,640 --> 00:19:37,700
here's carbon same thing

309
00:19:37,720 --> 00:19:43,580
the diffusivity rises up to the transformation temperature falls then continues to rise and not

310
00:19:43,580 --> 00:19:45,120
the difference in this small

311
00:19:45,120 --> 00:19:49,830
the slope of carbon and BCC lions is gentler than the slope of carbon in

312
00:19:49,830 --> 00:19:55,140
FCC i what's that mean it means that the slope in FCC ion is this

313
00:19:55,140 --> 00:20:01,060
upper value the slope and BCCI's lower value of the pay for the formation of

314
00:20:01,060 --> 00:20:06,810
vacancies here's self diffusion of iron ion luca drops two orders of magnitude when it

315
00:20:06,810 --> 00:20:09,580
moves from BCC FCC

316
00:20:09,580 --> 00:20:13,240
and just to make the point this is carbon in graphite this self diffusion of

317
00:20:13,240 --> 00:20:14,740
carbon in graphite

318
00:20:14,760 --> 00:20:16,830
what's the problem

319
00:20:16,910 --> 00:20:19,100
where would we see that its operation

320
00:20:19,120 --> 00:20:24,580
well we said the delta h vacancy formation is related to one

321
00:20:24,600 --> 00:20:29,430
so you're here you see the comparison between metallic bonding which is what you have

322
00:20:29,430 --> 00:20:32,830
an ion source of diffusion of iron i to project this curve up to this

323
00:20:32,830 --> 00:20:35,100
temperature so we can compare

324
00:20:35,120 --> 00:20:37,770
at the same temperature we see

325
00:20:37,790 --> 00:20:43,790
seven eight orders of magnitude difference between self diffusion of iron iron that some metals

326
00:20:43,790 --> 00:20:48,770
intermetallic crystal versus carbon in graphite which is

327
00:20:48,830 --> 00:20:52,490
carbon in a covalent crystals so

328
00:20:53,200 --> 00:20:55,790
big difference in performance

329
00:20:55,790 --> 00:20:59,700
there are other ways of looking at let's look the facts how do other defects

330
00:20:59,700 --> 00:21:06,220
affect so here's a cartoon showing the diffusion of some solitude into a material only

331
00:21:06,220 --> 00:21:10,870
this real material to polycrystalline materials so there's a grain boundary

332
00:21:10,890 --> 00:21:13,930
and as you know grain boundaries have

333
00:21:13,970 --> 00:21:15,290
the more openness

334
00:21:15,310 --> 00:21:19,100
they have the ones the grain boundary have fewer nearest neighbours

335
00:21:19,100 --> 00:21:22,010
well if you what you're trying to do is to jump through that little narrow

336
00:21:22,010 --> 00:21:25,220
saddle point waiting for those atoms to policy

337
00:21:25,220 --> 00:21:27,200
going back of the way

338
00:21:27,240 --> 00:21:29,100
the answer four-under-par

339
00:21:29,100 --> 00:21:33,180
so this is like the difference between having to drive down an expressway

340
00:21:33,200 --> 00:21:35,950
drive down the narrow city streets you got

341
00:21:35,990 --> 00:21:39,660
got a much easier time moving quickly down expressway

342
00:21:39,680 --> 00:21:43,950
right so we can see what the cartoonist trying to show is that

343
00:21:43,970 --> 00:21:47,970
up at the top we see the rate of increase of the you

344
00:21:47,970 --> 00:21:51,060
through the ball or we say it's lattice diffusion

345
00:21:51,100 --> 00:21:52,990
classical lattice diffusion

346
00:21:53,010 --> 00:21:54,560
down the grain boundary

347
00:21:54,660 --> 00:21:59,640
at the same time we see a much deeper penetration because the material is able

348
00:21:59,640 --> 00:22:00,620
to move

349
00:22:00,660 --> 00:22:02,350
with less constrained

350
00:22:02,370 --> 00:22:09,080
well on the surface it can move very rough surface diffusion is very very rapidly

351
00:22:09,140 --> 00:22:10,370
here's some data

352
00:22:10,370 --> 00:22:15,620
these are three different investigations of diffusion of silver

353
00:22:15,640 --> 00:22:18,410
diffusion of self self diffusion

354
00:22:18,410 --> 00:22:20,890
OK this is silver diffusing through silver

355
00:22:20,890 --> 00:22:24,490
so this is classical what they call volume diffusion is what we would call letters

356
00:22:24,490 --> 00:22:29,700
diffusion or walk diffusion single crystal silver moving through silver how would you make these

357
00:22:31,290 --> 00:22:32,890
was the only way you could

358
00:22:32,930 --> 00:22:35,990
identify once silver from another

359
00:22:36,040 --> 00:22:37,700
after use radio tracer

360
00:22:37,720 --> 00:22:41,760
OK so using radio tracer there are able to get some diffusion coefficient and you

361
00:22:41,760 --> 00:22:45,220
see what they've done is the flip this around this is very wimpy this is

362
00:22:45,220 --> 00:22:48,310
this is so when we look at what they don't these people the people the

363
00:22:48,310 --> 00:22:50,120
plot of this are sold

364
00:22:50,140 --> 00:22:51,870
this axis is you know

365
00:22:52,810 --> 00:22:57,830
do you have any trouble figuring out the temperature is increasing in this direction and

366
00:22:57,830 --> 00:23:02,120
you can think in one over t space this is how i feel comfortable when

367
00:23:02,120 --> 00:23:06,240
i look an arrhenius plot i one negative slope in a straight line and what

368
00:23:06,240 --> 00:23:10,680
they did is look at the numbers see the numbers they're sending from right to

369
00:23:11,660 --> 00:23:16,990
because they were there so checking that they are afraid to have temperature rising from

370
00:23:16,990 --> 00:23:19,830
right to left so what they do is they planted

371
00:23:20,910 --> 00:23:27,470
the diffusion coefficient natural log diffusion coefficient but they've got one over t

372
00:23:27,510 --> 00:23:28,790
rising from

373
00:23:28,810 --> 00:23:33,620
right to left so that get positive looking slopes lines

374
00:23:33,640 --> 00:23:35,370
very girly and like this

375
00:23:35,390 --> 00:23:36,390
i don't like this

376
00:23:36,410 --> 00:23:37,540
OK so

377
00:23:37,560 --> 00:23:42,180
look at this here we have it first of all a very steep slope

378
00:23:42,200 --> 00:23:47,830
very steep slope so that indicates a higher activation energy because we have a higher

379
00:23:47,830 --> 00:23:50,970
lattice energy which would with which we have to deal

380
00:23:50,990 --> 00:23:55,430
here's the grain boundary the grain boundary first of all it several orders of magnitude

381
00:23:55,430 --> 00:24:01,470
higher and the slope is gentler indicating that we have less constrained and finally up

382
00:24:01,470 --> 00:24:04,740
at the top we have the surface diffusion which has

383
00:24:04,870 --> 00:24:06,810
i draw your attention to the values

384
00:24:07,410 --> 00:24:10,790
we're down around ten to the minus a ten to the minus nine ten minus

385
00:24:11,510 --> 00:24:16,370
in units of centimetres squared per second look at this surface diffusion

386
00:24:16,370 --> 00:24:19,080
ten to the minus five ten to the minus four

387
00:24:19,100 --> 00:24:24,100
here's diffusion in molten ferrous alloys ten to the minus five ten to the minus

388
00:24:24,100 --> 00:24:28,740
four so what we've got here is a diffusion across the surface

389
00:24:28,830 --> 00:24:31,930
it is on a par with diffusion in a liquid

390
00:24:31,950 --> 00:24:33,720
so it gives you a very

391
00:24:33,740 --> 00:24:37,990
a vivid demonstration of how a relationship between

392
00:24:38,060 --> 00:24:42,220
the physical constraints of the lattice and

393
00:24:42,220 --> 00:24:46,140
the diffusion coefficients so we can capture that by saying that the

394
00:24:46,160 --> 00:24:48,240
activation energy for

395
00:24:48,290 --> 00:24:52,430
what i've been calling both diffusion or lattice diffusion

396
00:24:52,430 --> 00:24:55,390
this is a classical vacancy stuff OK

397
00:24:55,410 --> 00:24:57,100
vacancy mechanism

398
00:24:57,160 --> 00:24:59,310
OK via vacancy

399
00:24:59,330 --> 00:25:07,100
this activation energy is much greater than the activation energy for diffusion along grain boundaries

400
00:25:07,120 --> 00:25:13,770
which is much greater than the activation energy across the free surface

401
00:25:13,850 --> 00:25:18,200
so what we see the trend in moving from left to right is

402
00:25:18,240 --> 00:25:20,700
decrease in coordination number

403
00:25:20,700 --> 00:25:23,700
decrease in coordination number which means

404
00:25:23,790 --> 00:25:25,510
more freedom

405
00:25:28,160 --> 00:25:29,830
as q goes down

406
00:25:29,850 --> 00:25:33,810
the value of the goes up so all other things being equal this is for

407
00:25:33,810 --> 00:25:37,410
let's compare apples to apples this for self diffusion

408
00:25:37,430 --> 00:25:39,760
silver and silver ion

409
00:25:39,830 --> 00:25:43,040
what have you the diffusion coefficient for

410
00:25:43,040 --> 00:25:45,880
what it is today

411
00:25:47,150 --> 00:25:50,280
i might say

412
00:25:50,400 --> 00:25:52,970
this using machine learning

413
00:25:53,020 --> 00:25:57,840
on pattern recognition and image analysis computer vision problem

414
00:25:58,310 --> 00:26:02,150
my background is is on electrical engineering

415
00:26:02,230 --> 00:26:03,820
searching physics

416
00:26:03,830 --> 00:26:06,040
and i is being

417
00:26:06,060 --> 00:26:07,570
computer science

418
00:26:08,570 --> 00:26:14,130
the gradient structured background sometimes

419
00:26:14,150 --> 00:26:15,740
make sure

420
00:26:16,050 --> 00:26:21,470
bring together the different

421
00:26:21,480 --> 00:26:25,750
the idea is entirely real ways but

422
00:26:25,790 --> 00:26:27,370
but that's

423
00:26:27,510 --> 00:26:31,400
that's basically what we are going to present day some all you can

424
00:26:31,410 --> 00:26:33,170
use ideas from

425
00:26:34,660 --> 00:26:41,760
ideas that have been floating around in in physics four hundred years

426
00:26:41,810 --> 00:26:44,190
how can use those ideas to

427
00:26:44,210 --> 00:26:47,850
solve pattern recognition problem

428
00:26:47,950 --> 00:26:53,390
more specifically getting into the

429
00:26:53,400 --> 00:26:56,950
the main topic of the long before

430
00:26:57,430 --> 00:26:59,060
the basic

431
00:26:59,080 --> 00:27:00,730
the theme of this talk

432
00:27:00,760 --> 00:27:01,970
is called

433
00:27:01,980 --> 00:27:03,230
i would call

434
00:27:03,280 --> 00:27:05,780
structural pattern recognition

435
00:27:05,790 --> 00:27:09,310
what some people call strong but the information

436
00:27:09,350 --> 00:27:13,630
usually when you are concerned about pattern recognition problems

437
00:27:13,640 --> 00:27:15,330
the basic

438
00:27:16,380 --> 00:27:18,060
is to classify

439
00:27:21,050 --> 00:27:23,040
some input

440
00:27:23,290 --> 00:27:27,680
image better some put pattern or whatever

441
00:27:27,720 --> 00:27:29,190
and you have

442
00:27:29,250 --> 00:27:33,430
into some class so the idea is basically labeling

443
00:27:33,460 --> 00:27:37,240
problem you want to assign labels

444
00:27:37,260 --> 00:27:38,970
two different parts

445
00:27:39,070 --> 00:27:42,440
so this is traditional pattern recognition problem

446
00:27:42,460 --> 00:27:45,880
there are however

447
00:27:45,900 --> 00:27:54,240
some particular types of problems especially in computer vision image analysis image understanding image processing

448
00:27:54,260 --> 00:27:56,380
where this is not quite enough

449
00:27:56,480 --> 00:27:59,610
it's not sufficient

450
00:27:59,630 --> 00:28:03,450
to give the labels to a given path

451
00:28:03,510 --> 00:28:05,440
what you actually need

452
00:28:05,480 --> 00:28:06,900
is to tell

453
00:28:06,920 --> 00:28:09,250
which part of this spot

454
00:28:09,270 --> 00:28:11,390
corresponds to each part

455
00:28:11,510 --> 00:28:13,590
another one

456
00:28:13,600 --> 00:28:15,690
so for example

457
00:28:15,740 --> 00:28:20,010
you have a face person can classify that as either the

458
00:28:21,080 --> 00:28:23,210
or not

459
00:28:23,220 --> 00:28:25,740
if i have for example

460
00:28:25,750 --> 00:28:28,550
one face of one person in one image

461
00:28:28,560 --> 00:28:31,100
one face of one person to another image

462
00:28:31,140 --> 00:28:32,720
i can ask the question

463
00:28:32,770 --> 00:28:36,660
whether these two faces come from the sum same person one

464
00:28:36,710 --> 00:28:38,040
is the typical

465
00:28:38,050 --> 00:28:42,560
pattern recognition question which is the traditional question that you would ask

466
00:28:42,570 --> 00:28:48,010
but you can ask a stronger question this stronger question can ask is the full

467
00:28:48,210 --> 00:28:53,580
here i have the left eye of this person

468
00:28:53,590 --> 00:28:58,200
what is the left eye the other person how we find the correspondent

469
00:28:58,270 --> 00:29:00,860
from every part of the first

470
00:29:02,460 --> 00:29:05,170
to for every part of the second part

471
00:29:05,180 --> 00:29:09,290
you might be wondering why this is important well try to convince you that there

472
00:29:09,290 --> 00:29:10,330
are some

473
00:29:10,350 --> 00:29:12,570
problem is important problems

474
00:29:12,620 --> 00:29:18,390
in image analysis and processing computers where this is not only important

475
00:29:18,440 --> 00:29:21,000
but this is actually essential

476
00:29:21,020 --> 00:29:23,490
you can actually solve the problem

477
00:29:23,500 --> 00:29:25,620
if you only give unlabelled

478
00:29:25,630 --> 00:29:27,480
you need action

479
00:29:27,530 --> 00:29:29,710
if you wish to give label

480
00:29:29,750 --> 00:29:31,560
which party

481
00:29:31,590 --> 00:29:34,160
of the body

482
00:29:34,180 --> 00:29:38,190
you need to give to each part of the face a label in the order

483
00:29:38,190 --> 00:29:39,440
in which which is

484
00:29:39,490 --> 00:29:41,430
which kind of the other face

485
00:29:41,440 --> 00:29:44,370
this part corresponds

486
00:29:44,390 --> 00:29:46,360
so some people call this

487
00:29:46,400 --> 00:29:49,880
the strong pattern recognition problem because

488
00:29:49,890 --> 00:29:56,000
it's more difficult in the sense that you also want to perform some classification

489
00:29:56,050 --> 00:30:00,400
but you have an inherently combinatorial problem to solve

490
00:30:00,420 --> 00:30:03,420
because he's your partners are not

491
00:30:03,430 --> 00:30:05,860
single part in the

492
00:30:05,900 --> 00:30:09,620
now understood as being set collection

493
00:30:09,640 --> 00:30:12,980
of small pieces of pottery

494
00:30:12,990 --> 00:30:14,290
you need to find

495
00:30:14,330 --> 00:30:15,490
correct sign

496
00:30:15,500 --> 00:30:17,730
between this spaces in one part

497
00:30:17,740 --> 00:30:20,040
the piece is in your court

498
00:30:20,060 --> 00:30:21,660
so you introduce

499
00:30:21,670 --> 00:30:24,770
a complex problem which is a combinatorial problem

500
00:30:24,810 --> 00:30:28,540
and what will be talking today is exactly how

501
00:30:28,590 --> 00:30:31,920
you can approach this combinatorial problem

502
00:30:31,930 --> 00:30:35,500
in such a way that makes it you can

503
00:30:35,540 --> 00:30:38,200
have your cake and eat it at the same time

504
00:30:38,250 --> 00:30:41,960
in other words used to can solve the problem

505
00:30:42,380 --> 00:30:45,490
without having

506
00:30:45,490 --> 00:30:50,120
hypothesis so other three might be negative and then maybe the third generation you might

507
00:30:50,120 --> 00:30:56,480
choose the second hypothesis again and so we have something to this up to two

508
00:30:57,050 --> 00:30:58,660
so just i mean trivial

509
00:30:58,670 --> 00:31:04,300
OK and then in the end you can compute but when you don t iterations

510
00:31:04,300 --> 00:31:06,790
you can compute all the weights for four

511
00:31:06,810 --> 00:31:11,850
four of us i mean all the others in the company

512
00:31:11,860 --> 00:31:14,060
just this formula

513
00:31:19,370 --> 00:31:23,900
let's assume i mean we always assume the base learner somehow minimizes this weighted training

514
00:31:24,590 --> 00:31:30,350
OK so let's assume that maximizes that this was equivalent to the rates and operators

515
00:31:30,350 --> 00:31:31,620
plus minus one

516
00:31:31,720 --> 00:31:34,050
OK so it maximizes this ex

517
00:31:34,270 --> 00:31:41,090
so it turns out that this is actually equivalent to finding the

518
00:31:41,100 --> 00:31:45,120
the hypothesis which has the maximum gradient

519
00:31:45,140 --> 00:31:46,000
OK so

520
00:31:46,010 --> 00:31:50,390
the maximum gradient so the derivative of g with respect to alpha so this is

521
00:31:50,390 --> 00:31:52,560
the gradient with respect to that direction

522
00:31:52,610 --> 00:31:54,110
is simply this one here

523
00:31:54,120 --> 00:31:59,820
so this is some so the the current d so the current waiting times hjx

524
00:31:59,820 --> 00:32:03,530
and so this is exactly the

525
00:32:03,550 --> 00:32:06,590
the edge of that hypothesis

526
00:32:06,610 --> 00:32:11,840
OK so when you select the hypothesis which has a smaller and smaller training and

527
00:32:11,920 --> 00:32:17,140
has the largest set that is actually the direction which has the largest creating component

528
00:32:17,260 --> 00:32:21,200
this is exactly what postings doing whatever she was doing

529
00:32:21,250 --> 00:32:23,540
gauss southwell method

530
00:32:23,560 --> 00:32:27,970
OK we somehow uses based on this kind of article

531
00:32:27,980 --> 00:32:31,260
to generate gradient directions

532
00:32:31,280 --> 00:32:35,260
so in that of course also works when you have enough i mean huge posse

533
00:32:35,260 --> 00:32:41,010
sets something like decision trees to tries to find one one hypothesis it hypothesis which

534
00:32:41,010 --> 00:32:45,000
has a small training error and finds the gradient

535
00:32:45,050 --> 00:32:46,390
we can

536
00:32:46,410 --> 00:32:52,160
we go in that direction

537
00:32:52,210 --> 00:32:53,440
OK so

538
00:32:53,540 --> 00:32:57,640
i have to make the charts so

539
00:32:57,650 --> 00:33:04,390
OK so in the general from the minimizer we minimize function and that function somehow

540
00:33:04,390 --> 00:33:09,720
depends on on these hypotheses on the process rates and they maybe on some linear

541
00:33:09,720 --> 00:33:15,030
terms so this is the most general setting going over here very quickly and essentially

542
00:33:15,030 --> 00:33:19,530
would like to understand when these algorithms converge so maybe there's some conditions on the

543
00:33:19,530 --> 00:33:25,930
on the function g here and maybe also some conditions on on the selection so

544
00:33:25,930 --> 00:33:28,650
we would like to prove something

545
00:33:28,670 --> 00:33:31,230
showing the convergence of that leveraging

546
00:33:34,240 --> 00:33:36,680
we only consider the finite hypothesis sets

547
00:33:38,950 --> 00:33:39,870
OK so

548
00:33:39,890 --> 00:33:45,110
i find some conditions you i go over that essentially the base learner doesn't need

549
00:33:45,110 --> 00:33:45,650
to produce

550
00:33:46,140 --> 00:33:51,490
the hypothesis which has the smallest to largest edge but maybe something which is related

551
00:33:51,820 --> 00:33:56,400
not so from not much worse than the largest at OK so

552
00:33:56,410 --> 00:33:58,540
maybe let's say a

553
00:33:58,690 --> 00:34:02,500
the largest which is this maximum here so it is

554
00:34:02,510 --> 00:34:07,190
it's taking the maximum over all hypotheses in the hypothesis that so and it is

555
00:34:07,190 --> 00:34:12,780
sufficient if the base learner adjacent iteration is just

556
00:34:12,800 --> 00:34:16,360
i mean not much smaller than the largest edge OK so then that is OK

557
00:34:16,380 --> 00:34:20,490
this condition is satisfied don't optimality

558
00:34:21,010 --> 00:34:22,720
then we have this theory

559
00:34:22,740 --> 00:34:28,700
given a training set of sample s and a

560
00:34:28,720 --> 00:34:35,350
five percent have which is computation close the plus and minus have forces and then

561
00:34:35,770 --> 00:34:39,920
if the gene function is strictly

562
00:34:39,930 --> 00:34:42,050
strictly convex

563
00:34:42,100 --> 00:34:45,330
and i can values are bounded from below

564
00:34:46,590 --> 00:34:52,980
then we can actually show that this leveraging i with converges to the optimal solution

565
00:34:52,980 --> 00:34:54,490
you know that

566
00:35:00,490 --> 00:35:06,170
all of the

567
00:35:11,640 --> 00:35:19,540
o thing going on

568
00:35:45,810 --> 00:35:49,160
i mean you know

569
00:36:48,640 --> 00:36:51,280
well need

570
00:37:46,390 --> 00:37:48,900
as the

571
00:37:59,820 --> 00:38:05,380
at all

572
00:38:05,400 --> 00:38:20,730
o hold

573
00:38:28,530 --> 00:38:30,690
i mean sure

574
00:38:33,440 --> 00:38:36,110
i have

575
00:39:10,090 --> 00:39:12,230
we are

576
00:39:47,780 --> 00:39:52,610
what i mean

577
00:40:02,360 --> 00:40:06,380
right right

578
00:41:02,440 --> 00:41:14,150
right or

579
00:41:33,780 --> 00:41:39,630
i mean

580
00:41:39,630 --> 00:41:41,250
one i wrote here

581
00:41:41,250 --> 00:41:46,470
if you look at this potentially this theorem is minimized on the circle where i

582
00:41:46,470 --> 00:41:52,780
squared plus square is fixed the square of energy but there is a small lifting

583
00:41:52,780 --> 00:41:58,570
of this circle degeneracy and the twelve IQ our one phi is plus or minus

584
00:41:58,570 --> 00:42:03,800
hanover square giochi zero shot has to like you and you can write down the

585
00:42:03,820 --> 00:42:05,090
kink solution

586
00:42:05,090 --> 00:42:09,050
that goes from one to the other and it has this particular form it doesn't

587
00:42:09,050 --> 00:42:15,230
matter so much more explicit form is but if you look at this field phi

588
00:42:15,230 --> 00:42:17,630
it goes from one vacuum

589
00:42:17,650 --> 00:42:22,070
crosses over to the second viking from left to right through the domain wall in

590
00:42:22,070 --> 00:42:25,630
this case is separating two

591
00:42:25,650 --> 00:42:28,150
now the important thing is that the we

592
00:42:28,190 --> 00:42:35,230
of this kind of object is basically determined by the inverse minus of the elementary

593
00:42:35,230 --> 00:42:38,960
quantum interference which one of them here

594
00:42:38,960 --> 00:42:43,820
but the tension of the mass is much higher at weak coupling if you computed

595
00:42:43,820 --> 00:42:49,210
here it's over g if g is small the coupling is small this is very

596
00:42:55,980 --> 00:43:00,670
suppose you have one of these solitons and you try to think about low-energy excitations

597
00:43:00,670 --> 00:43:02,840
in the background of this king

598
00:43:02,860 --> 00:43:06,820
what part of these first of all you have the field can i remember the

599
00:43:06,820 --> 00:43:11,380
phil kaye or you don't remember but you can see from the previous

600
00:43:11,400 --> 00:43:17,170
transparency the field guy had no my s if you put phi the vacuum

601
00:43:17,190 --> 00:43:23,020
this terms kill each other a exactly and there are only a guide to the

602
00:43:23,020 --> 00:43:29,170
four terms interaction terms but enormous surprise the massless field induced by and therefore if

603
00:43:29,170 --> 00:43:34,150
you to excite the system at very low energy you can of course

604
00:43:34,150 --> 00:43:36,940
excited the field guide far from

605
00:43:37,050 --> 00:43:38,550
this the main wall

606
00:43:38,570 --> 00:43:43,820
but there is a second kind of massless low-energy excitation namely you can take the

607
00:43:43,820 --> 00:43:50,460
king and moving very slowly or deform the domain wall had very long wavelengths and

608
00:43:50,460 --> 00:43:55,980
this is also arbitrarily low in energy so if you think about the systems you

609
00:43:55,980 --> 00:44:01,820
know they are at very low energies looking like the following thing some massless fields

610
00:44:01,820 --> 00:44:09,270
in the bulk of running around some muscle is very low energy excitations localized this

611
00:44:09,270 --> 00:44:13,050
domain wall and everything else is massive

612
00:44:13,070 --> 00:44:18,110
actually and cheating a bit here because if you really do the analysis in this

613
00:44:18,110 --> 00:44:24,840
particular model you will also find it acllon fields localized in the brain this corresponds

614
00:44:24,840 --> 00:44:28,610
to the fact that there is a lot of tension more stable domain wall it

615
00:44:28,610 --> 00:44:32,400
was a bit too complicated to write down that's why they're doing

616
00:44:32,400 --> 00:44:37,090
but it's something here but nine it's the brain by q of that can be

617
00:44:37,110 --> 00:44:42,190
curated by just stating the correct solution so

618
00:44:42,210 --> 00:44:47,400
the effective low energy action has a very simple form if you compute here it

619
00:44:47,400 --> 00:44:54,880
is some bulk massless field and some brain degrees of freedom here simply transverse fluctuations

620
00:44:54,880 --> 00:45:00,000
of the brain they may have some potential in which also the bulk fields and

621
00:45:00,000 --> 00:45:05,570
very few computed and plus everything else which is very massive

622
00:45:05,570 --> 00:45:10,800
now in this simple example if you really want to do it as an exercise

623
00:45:10,800 --> 00:45:15,860
you can of course do everything completely honestly you can just take the original field

624
00:45:15,860 --> 00:45:19,340
theory was started with everything derives from there

625
00:45:19,340 --> 00:45:24,780
sort of or write it in terms of diagonalized modes

626
00:45:25,170 --> 00:45:30,860
of the quadratic operator in the background of the king and then think of this

627
00:45:30,860 --> 00:45:34,590
as the new fields the you know i have to solve the equation for the

628
00:45:35,900 --> 00:45:42,820
according to hearing eigen modes of the quadratic operator that there is only longitudinal coordinate

629
00:45:42,820 --> 00:45:49,110
dependent remaining in the coefficients think of this as new fields do correctly you're expansion

630
00:45:49,110 --> 00:45:53,590
and you find exactly what you expect me this

631
00:45:53,610 --> 00:45:58,750
instinct theory unfortunately we don't know how to do this we don't have the analogue

632
00:45:58,750 --> 00:46:03,210
of this very simple starting point if only

633
00:46:03,230 --> 00:46:07,820
not but there but in lagrangian description of string field theory

634
00:46:07,840 --> 00:46:10,630
nevertheless it is consistent

635
00:46:10,650 --> 00:46:16,400
in every way people have checked to think of the closed and the open strings

636
00:46:16,420 --> 00:46:21,730
as the bulk and brane localized modes in the presence of fish

637
00:46:21,750 --> 00:46:25,570
and that's what will be doing in the next two lectures

638
00:46:25,590 --> 00:46:32,190
in particular the low energy excitations of additional brain described by open strings of very

639
00:46:32,190 --> 00:46:33,710
low minus

640
00:46:33,750 --> 00:46:38,420
let's finally nothing by thinking about what these are

641
00:46:38,420 --> 00:46:45,800
trying to automate the identification of this building on the right here has been born

642
00:46:45,820 --> 00:46:48,670
this is very difficult actually in three dimensions to two

643
00:46:48,810 --> 00:46:50,410
the pattern recognition

644
00:46:50,440 --> 00:46:52,370
but there's a change detection here

645
00:46:52,380 --> 00:46:56,500
it's much easier from higher up because you've got a problem of parallax

646
00:46:56,560 --> 00:47:01,250
so the satellite the camera on the satellite is not exactly the same position in

647
00:47:01,250 --> 00:47:06,570
the two pictures so you need to do a three d pattern match before you

648
00:47:06,570 --> 00:47:08,740
can pay say that change

649
00:47:08,840 --> 00:47:12,180
detection in the image

650
00:47:12,190 --> 00:47:15,440
and here we got the lead at the airport in beirut

651
00:47:15,480 --> 00:47:18,390
this is much easier to detect the bomb site

652
00:47:18,400 --> 00:47:21,570
it just shows how accurate the israeli bombing was because there

653
00:47:21,570 --> 00:47:26,650
hit every single intersection on the runway

654
00:47:26,680 --> 00:47:27,730
OK now

655
00:47:27,780 --> 00:47:31,890
before we get into the web mining techniques and so on i thought it would

656
00:47:32,030 --> 00:47:33,600
like to review

657
00:47:33,610 --> 00:47:35,070
the web

658
00:47:35,090 --> 00:47:38,090
now i think he will think we understand the internet

659
00:47:38,110 --> 00:47:39,010
but it's

660
00:47:39,040 --> 00:47:42,920
it's incredible when you realize just how

661
00:47:42,940 --> 00:47:45,360
new it is

662
00:47:45,370 --> 00:47:48,230
if you think of communication

663
00:47:48,260 --> 00:47:53,670
this is the diversion for about fifteen minutes

664
00:47:53,690 --> 00:47:57,850
in the nineteen twenties they in the phone was invented

665
00:47:57,860 --> 00:48:02,030
it basically it's still the case today people don't have phones

666
00:48:02,050 --> 00:48:06,900
the mobile phone revolution was the one brought phones into africa

667
00:48:06,930 --> 00:48:09,300
the the phone to

668
00:48:09,310 --> 00:48:12,540
a very long time before it was

669
00:48:12,630 --> 00:48:15,390
brought before it his adopted but worldwide

670
00:48:15,410 --> 00:48:19,680
and he has a particular thing it's a point-to-point connection it's basically you can talk

671
00:48:19,680 --> 00:48:22,820
to somebody at the distance that's all it is

672
00:48:22,860 --> 00:48:25,740
the next big revolution will be saved broadcasting

673
00:48:25,760 --> 00:48:31,110
radio before the war the radio not television radio

674
00:48:31,110 --> 00:48:33,440
i took off the slow way

675
00:48:33,470 --> 00:48:36,140
television came

676
00:48:37,340 --> 00:48:42,090
from the nineteen sixties and now everyone is television but it took let's say for

677
00:48:42,240 --> 00:48:45,070
forty years before diffused out into

678
00:48:45,110 --> 00:48:46,620
every home

679
00:48:48,070 --> 00:48:52,360
again the way to tell if it is important to realize the difference the way

680
00:48:52,360 --> 00:48:53,630
we communicate

681
00:48:53,650 --> 00:48:58,800
in fact we have a it's point-to-point connection were broadcasting

682
00:48:59,480 --> 00:49:01,490
one person decides the content

683
00:49:01,540 --> 00:49:04,990
and we'll sit there passively and look at it

684
00:49:05,050 --> 00:49:08,320
and this is a very good easy to control the government can control what is

685
00:49:08,320 --> 00:49:10,930
allowed on television et cetera et cetera

686
00:49:10,960 --> 00:49:14,590
and so the if you think of before the way

687
00:49:14,750 --> 00:49:19,460
it was very easy for governments to control what their people learned about it was

688
00:49:19,720 --> 00:49:20,840
it's very

689
00:49:21,090 --> 00:49:24,080
and for those who was easy to tap phone if you if you didn't if

690
00:49:24,080 --> 00:49:28,630
you mistrusted someone it was quite easy to get together for

691
00:49:28,650 --> 00:49:30,800
the web changed all that

692
00:49:31,490 --> 00:49:33,320
i remember

693
00:49:33,360 --> 00:49:37,640
seeing the web for the first time i think at the end of ninety two

694
00:49:37,650 --> 00:49:41,530
somebody downloaded mosaic from NC CSA's website

695
00:49:41,530 --> 00:49:45,550
and we looked at it and the impact of that first view

696
00:49:45,600 --> 00:49:50,910
was incredible i knew you saw immediately that there was something completely new

697
00:49:51,320 --> 00:49:56,820
and the the whole model of communication changed overnight so now

698
00:49:56,820 --> 00:49:59,260
it was possible for you to publish information

699
00:49:59,290 --> 00:50:03,660
and we had a situation where many people to publish information and there's a lot

700
00:50:03,660 --> 00:50:05,030
of other people who

701
00:50:05,070 --> 00:50:06,670
looked at it

702
00:50:07,890 --> 00:50:10,090
so around nineteen ninety three

703
00:50:10,100 --> 00:50:12,800
the web started to grow

704
00:50:12,810 --> 00:50:16,080
i knew it would happen when i saw URL london bus

705
00:50:16,100 --> 00:50:19,580
that was about two two years later before that was

706
00:50:19,590 --> 00:50:23,460
basically just university researchers in in the in the internet

707
00:50:25,140 --> 00:50:30,110
again it was basically a passive things web surfing the term web server with basically

708
00:50:30,630 --> 00:50:34,720
people looking at other people's content few people publishing

709
00:50:34,740 --> 00:50:40,400
then the say the commerce the dot dot net the dot com boom and bust

710
00:50:40,450 --> 00:50:45,170
they actually had already got most of the technology

711
00:50:45,190 --> 00:50:46,710
for e-commerce running

712
00:50:46,730 --> 00:50:49,650
but why did it all go bust

713
00:50:49,660 --> 00:50:52,890
the real reason was because they didn't have the band

714
00:50:52,980 --> 00:50:56,530
now we talk about this new buzzword thing web two

715
00:50:56,530 --> 00:51:00,210
what is it and you can read papers on the internet which will tell you

716
00:51:00,210 --> 00:51:04,560
OK web two is all about social networking it's all about

717
00:51:07,370 --> 00:51:08,640
it's say this new

718
00:51:08,650 --> 00:51:14,080
technology which is actually just javascript it was nothing new at all hx four special

719
00:51:14,080 --> 00:51:18,760
clients like google maps the and so on

720
00:51:18,780 --> 00:51:23,340
and easy syndication RSS there are three things that they kind of

721
00:51:23,420 --> 00:51:25,610
get lumped together in this web two

722
00:51:25,620 --> 00:51:32,000
connection which is a social network sites are assessed and hx

723
00:51:32,150 --> 00:51:33,780
all these things are nice

724
00:51:33,800 --> 00:51:36,730
but really what changed is

725
00:51:36,790 --> 00:51:42,070
what really changed was the widespread deployment of broadband

726
00:51:42,080 --> 00:51:45,890
because it only became possible at that moment for you to really get involved and

727
00:51:45,890 --> 00:51:48,030
published yourself so user

728
00:51:48,070 --> 00:51:53,320
user interaction on the internet only really became feasible when broadband was it's in everyone's

729
00:51:54,220 --> 00:51:57,260
today there about a billion users of the internet

730
00:51:57,280 --> 00:51:58,300
and then

731
00:51:58,420 --> 00:52:00,550
eighty percent got broadband

732
00:52:00,590 --> 00:52:01,390
so now

733
00:52:01,440 --> 00:52:08,030
is the that's why now this sudden boom in the in the web again

734
00:52:08,580 --> 00:52:13,630
an interesting fact there was a survey done in february this year and

735
00:52:13,650 --> 00:52:16,750
to estimate how much data is on the line

736
00:52:16,780 --> 00:52:19,950
and we came up with this this estimate which was done

737
00:52:19,980 --> 00:52:24,620
basically by sampling various sites and doing a rough estimate was came up with this

738
00:52:24,630 --> 00:52:27,820
figure one point six times ten to twenty bytes

739
00:52:27,850 --> 00:52:33,940
which is i believe one point six x but it's about a thousand million thousand

740
00:52:33,970 --> 00:52:35,990
it's about a billion

741
00:52:40,220 --> 00:52:44,850
it sounds huge number but if you if you think about avocados numbers

742
00:52:44,890 --> 00:52:45,880
which is

743
00:52:45,890 --> 00:52:48,870
three orders of magnitude bigger

744
00:52:48,890 --> 00:52:52,290
is the number of molecules in one gram of hydrogen

745
00:52:53,480 --> 00:52:57,570
it puts things in perspective because if you wanted to know if you wanted to

746
00:52:57,570 --> 00:52:58,590
the volume is

747
00:53:02,110 --> 00:53:04,300
i could play the song accounts were

748
00:53:09,260 --> 00:53:10,860
well i expose about

749
00:53:11,440 --> 00:53:12,740
synthetic bird to

750
00:53:13,380 --> 00:53:14,280
those stimuli

751
00:53:15,360 --> 00:53:18,010
using the sort of hierarchy that are just

752
00:53:20,070 --> 00:53:23,630
yes yes it does yeah it sounds like it's very

753
00:53:24,670 --> 00:53:28,730
famous sitting in the morning my garden but you sometimes hear these birds out there

754
00:53:28,730 --> 00:53:30,760
is you know it's quite compelling

755
00:53:31,440 --> 00:53:34,940
it is easy to actually just to freeze the right range and any

756
00:53:36,190 --> 00:53:37,380
so reasonably

757
00:53:37,780 --> 00:53:39,030
which normally counting

758
00:53:39,480 --> 00:53:44,010
dynamics will will actually sort produced one or vulnerable strata

759
00:53:45,070 --> 00:53:49,010
i would whistleblower the nervous about this right i did the

760
00:53:49,800 --> 00:53:50,820
so it's not quite the

761
00:53:53,150 --> 00:53:53,670
so this

762
00:53:54,360 --> 00:54:01,340
well done here is just plot the variables namely these prediction errors and come poster predictions as functions

763
00:54:01,900 --> 00:54:02,840
first this time

764
00:54:03,400 --> 00:54:08,050
after the president or during the presentation of the stimulus at different levels in this hierarchy

765
00:54:09,110 --> 00:54:14,130
at the top of the hierarchy must first furthest removed from these sensory input we

766
00:54:14,130 --> 00:54:17,530
have these representations in the hidden causes and the true hidden causes

767
00:54:18,780 --> 00:54:21,280
grey lines here some basically switching on the chair

768
00:54:21,860 --> 00:54:27,670
by inflating attractor it cycles away generates frequencies and amplitudes from point attracted to

769
00:54:28,110 --> 00:54:33,670
chaotic attractor here with true control parameters and the inferred control parameters are

770
00:54:34,110 --> 00:54:38,860
the blue and the green here with ninety percent confidence intervals and they are formed by

771
00:54:39,880 --> 00:54:43,480
the best explanation that minimizes the prediction error about the flow

772
00:54:44,010 --> 00:54:46,300
of hidden states of the lorenz attractor

773
00:54:47,000 --> 00:54:52,150
so this is the best explanation before all they accumulated changes in the flow of

774
00:54:52,150 --> 00:54:55,420
the hidden states and the blastula hidden states when where they

775
00:54:56,030 --> 00:54:59,800
called expectations about these flowers come from what they are

776
00:55:00,300 --> 00:55:03,530
the best explanation informed by prediction errors

777
00:55:04,010 --> 00:55:09,570
all of these actual dynamics of to those hidden states which are very

778
00:55:10,230 --> 00:55:14,440
the amplitude and the frequency the sensory input so we have this recursive message passing

779
00:55:14,440 --> 00:55:17,900
the has this separation temple scales has faster going on

780
00:55:18,260 --> 00:55:23,110
showing these fluctuations in expectation and we get a higher level at the very

781
00:55:24,170 --> 00:55:29,320
hierarchy here basically things we've lost the dynamics michaelmas perceptual categorization here

782
00:55:29,710 --> 00:55:32,240
the one

783
00:55:34,280 --> 00:55:35,630
this is the only one here

784
00:55:36,150 --> 00:55:37,940
this is a standard chaotic system

785
00:55:42,030 --> 00:55:43,300
there's a vast literature

786
00:55:43,860 --> 00:55:49,340
which i don't know deeply that people to so many articles from time-to-time modelling both

787
00:55:49,510 --> 00:55:53,650
these particular differential equations that show deterministic chaos at the level of these

788
00:55:54,150 --> 00:55:57,840
the steering she's the voice boxes lots of work in a very fast time-scale tr

789
00:55:58,320 --> 00:56:01,510
about the speech production but there's also a lot of interesting work in the high

790
00:56:01,760 --> 00:56:05,340
and they actually see the high vocal center of songbirds

791
00:56:05,800 --> 00:56:08,280
looking at sort of winner-take-all all sorts of

792
00:56:16,150 --> 00:56:17,300
yes you could get

793
00:56:18,050 --> 00:56:22,480
yeah there's nothing really special about that you know there's nothing really important about editors

794
00:56:22,480 --> 00:56:25,980
deterministic chaos is just more it's more produce more realistic stimuli

795
00:56:26,480 --> 00:56:29,650
the differential equations that seem to arise from

796
00:56:30,090 --> 00:56:32,190
the competitive dynamics between the

797
00:56:32,650 --> 00:56:36,030
distinct populations and high vocal center syncytia to show deterministic

798
00:56:37,670 --> 00:56:39,010
but now it's just for fun

799
00:56:39,900 --> 00:56:43,920
you could just use a and also switch on and off with this frequency and amplitude too

800
00:56:44,340 --> 00:56:44,980
two properties

801
00:56:46,570 --> 00:56:47,460
this is not

802
00:56:50,360 --> 00:56:55,190
it is exactly a very good point so i you know so this is using

803
00:56:55,190 --> 00:56:59,130
the grading the generalized bayesian filtering that presented in the first slide

804
00:56:59,740 --> 00:57:02,090
the in the special case in which would be

805
00:57:03,800 --> 00:57:04,610
kalman filtering

806
00:57:06,110 --> 00:57:07,820
pound interestingly if

807
00:57:08,610 --> 00:57:13,050
we replace block form of york of fewer of yours

808
00:57:13,650 --> 00:57:14,690
and particle filter

809
00:57:15,260 --> 00:57:16,050
with a single

810
00:57:16,500 --> 00:57:17,900
guassian distribution

811
00:57:18,780 --> 00:57:21,530
it would be i that this will be identical to what you're just as well

812
00:57:21,730 --> 00:57:24,260
because only have one particle must be anyone me

813
00:57:25,210 --> 00:57:30,920
expectation for having an arbitrary example from your point-of-view but mathematically we have a very similar form i think

814
00:57:31,380 --> 00:57:35,090
yeah so this is basically filtering based deconvolution predictive coding

815
00:57:36,280 --> 00:57:37,740
yeah yeah you

816
00:57:38,730 --> 00:57:43,340
so is coming is generalized bayesian filtering bayesian deconvolution

817
00:57:44,260 --> 00:57:49,530
this is predicated on the linear predictive coding device and he coding that have a

818
00:57:49,550 --> 00:57:52,940
direct mapping to message passing in the brain it's they're all the same thing

819
00:57:53,740 --> 00:57:59,070
absolutely so yeah what so this notion of all the helm the brain being helmholtz machine

820
00:57:59,820 --> 00:58:04,740
could be articulated as simply saying the brain is doing a bayesian deconvolution bayesian filtering

821
00:58:05,170 --> 00:58:06,030
all sensory input

822
00:58:06,880 --> 00:58:09,030
what have to do that we have to minimize these

823
00:58:09,550 --> 00:58:13,400
the difference between the free energy and surprise was happy about what has to

824
00:58:14,780 --> 00:58:18,480
it has to be able to mean price to minimize its special states what is

825
00:58:18,590 --> 00:58:21,210
actually about well because you have status

826
00:58:22,960 --> 00:58:23,550
in this

827
00:58:34,260 --> 00:58:34,730
all the

828
00:58:35,940 --> 00:58:37,420
well it was a good question

829
00:58:41,530 --> 00:58:42,480
it's your question

830
00:58:43,090 --> 00:58:46,670
there's your question so how does the brain do do do you know

831
00:58:47,380 --> 00:58:51,480
probability quasar i approximate bayesian inference on

832
00:58:51,960 --> 00:58:54,880
problems such as weather forecasting all markets that

833
00:58:58,110 --> 00:58:58,730
that's true

834
00:59:12,260 --> 00:59:12,570
you know

835
00:59:18,900 --> 00:59:22,760
you will well yes so there are two very good points first will how do

836
00:59:22,760 --> 00:59:25,170
you know and is the experiment and in fact

837
00:59:26,050 --> 00:59:29,260
i when looking attended my presentation but what i would have shown

838
00:59:29,760 --> 00:59:34,010
is that one can regard action has performing experiments to optimize the model

839
00:59:36,280 --> 00:59:38,360
i will speed through the slide show you about the

840
00:59:39,130 --> 00:59:43,010
but was was the case that we don't have time to do but the the the idea is that

841
00:59:43,440 --> 00:59:47,630
in order so so let me ask the first question and then i will explain why

842
00:59:48,340 --> 00:59:49,320
you can regard

843
00:59:49,820 --> 00:59:51,570
living as an experiment

844
00:59:52,090 --> 00:59:53,210
to optimize your model

845
00:59:54,630 --> 00:59:55,400
the best model

846
00:59:55,900 --> 01:00:01,670
is the one that has the most evidence as like bayesian model selection so usually when you got some data

847
01:00:02,190 --> 01:00:02,920
you want to

848
01:00:03,320 --> 01:00:08,260
compare different models of how u hypothesize of all those data are caused so you

849
01:00:08,260 --> 01:00:11,710
know if it was and whether forecasting could be deemed model with multiple you know

850
01:00:11,710 --> 01:00:12,260
with lots of

851
01:00:12,710 --> 01:00:16,510
hierarchical structure very simple you may want to bit sums variables

852
01:00:17,530 --> 01:00:21,650
carbon dioxide made by their or not and then compare models

853
01:00:22,050 --> 01:00:27,780
so the problem normally reduces all of statistics in terms of empirical data analysis reduces

854
01:00:27,780 --> 01:00:32,510
to one problem it's the comparison of different models or hypotheses that the same data

855
01:00:33,110 --> 01:00:37,840
those models are scored with the marginal likelihood of the basic model imprecise bayesian model selection

856
01:00:38,460 --> 01:00:40,280
because free energy bands

857
01:00:41,340 --> 01:00:46,240
the model evidence or marginal likelihood in ninety nine point nine a practical applications one

858
01:00:46,510 --> 01:00:50,610
cannot and does not use the marginal likelihood of the evidence one uses the variational

859
01:00:50,610 --> 01:00:51,320
free energy bound

860
01:00:52,780 --> 01:00:55,840
so what you do is use choral compare different models

861
01:00:56,550 --> 01:00:59,480
but may have a different form a different number of nodes and the number of

862
01:00:59,480 --> 01:01:01,340
edges for example in graphical models

863
01:01:02,090 --> 01:01:03,550
using these free energy

864
01:01:03,550 --> 01:01:07,770
so this is the schedule for my part of the spring school so just the

865
01:01:07,770 --> 01:01:11,650
first five days i don't know what's happening with

866
01:01:11,660 --> 01:01:14,660
it too when when you divide

867
01:01:14,680 --> 01:01:21,440
and some of you do biomolecular organisation and some of you do complex data analysis

868
01:01:21,480 --> 01:01:25,560
i think one group remains here of one group there's another lecture theatre that you

869
01:01:26,500 --> 01:01:28,230
but i'm not sure of the details

870
01:01:32,160 --> 01:01:34,240
so i think almost everyone is

871
01:01:34,400 --> 01:01:49,800
did everyone manage to eat some lunch

872
01:01:50,340 --> 01:01:59,520
OK so one of the things that i mentioned

873
01:02:00,060 --> 01:02:02,260
in the previous lecture fees

874
01:02:02,280 --> 01:02:05,900
i sort of referred to the the degree to which we can take inspiration from

875
01:02:05,900 --> 01:02:10,940
natural complex systems in our efforts to understand

876
01:02:10,980 --> 01:02:14,940
complexity but also to exploit complexity in engineering

877
01:02:14,960 --> 01:02:16,860
i like to here

878
01:02:17,500 --> 01:02:21,130
the end of is israeli to give you a sort of whistlestop tour

879
01:02:21,380 --> 01:02:22,850
through some of the more

880
01:02:22,880 --> 01:02:25,960
impressive feats of natural complexity

881
01:02:26,540 --> 01:02:30,140
and to talk a little bit about to what extent we can

882
01:02:30,220 --> 01:02:32,350
what it means to draw inspiration from

883
01:02:34,100 --> 01:02:40,220
so there are some

884
01:02:40,320 --> 01:02:42,260
complex systems

885
01:02:42,340 --> 01:02:45,020
by the way tomorrow we start to get to grips with what i'm meaning when

886
01:02:45,020 --> 01:02:47,440
i say words like complex so don't worry

887
01:02:47,660 --> 01:02:51,120
but i'm using them a sense today

888
01:02:51,140 --> 01:02:55,000
there are some things that people might think complex systems in nature to you gotta

889
01:02:55,010 --> 01:03:02,800
marine ecosystem species of fish and coral and plants here you've got a swarm of

890
01:03:02,800 --> 01:03:05,100
insects i believe they're locusts of some kind

891
01:03:05,720 --> 01:03:09,940
so you've got an image of the human brain

892
01:03:09,960 --> 01:03:11,800
got developing foetus

893
01:03:11,880 --> 01:03:17,600
here you've got a three to sort of physiological engineering

894
01:03:17,640 --> 01:03:22,460
here you've got a special kind of ornamental cauliflower

895
01:03:23,200 --> 01:03:28,540
about that well it was on the first page of things that you get when

896
01:03:28,540 --> 01:03:35,360
you talk complex natural systems into google images that i thought it was quite pretty

897
01:03:36,000 --> 01:03:42,320
it obviously sort of exhibit some kind of fractal results similar structure so

898
01:03:42,340 --> 01:03:45,520
i mean these systems are very very different

899
01:03:45,620 --> 01:03:48,580
i mean we're looking at different scales

900
01:03:49,460 --> 01:03:54,160
and in the case this is an organ within an organism this is an organism

901
01:03:54,160 --> 01:03:58,680
developing this is another organism this is the single organism but this is an ecosystem

902
01:03:58,780 --> 01:04:03,680
this is the agglomeration of organisms

903
01:04:03,700 --> 01:04:05,350
we're looking at very simple

904
01:04:05,380 --> 01:04:09,900
creatures looking at much more complicated creatures

905
01:04:09,960 --> 01:04:11,480
but we see

906
01:04:11,520 --> 01:04:13,600
complexity what we would

907
01:04:13,640 --> 01:04:16,100
i think of as complexity

908
01:04:16,140 --> 01:04:19,140
almost everywhere you look in nature

909
01:04:20,960 --> 01:04:25,780
i'm gonna concentrate on just a few examples and i'm going to that a bit

910
01:04:25,780 --> 01:04:29,220
of rough ordering over them which i'll try to make it clear as as we

911
01:04:29,220 --> 01:04:32,720
go on so for example the first example is gonna be termite mounds

912
01:04:33,080 --> 01:04:38,340
so guy in africa and he is the man and made of mud by a

913
01:04:38,340 --> 01:04:39,880
colony of termites

914
01:04:39,900 --> 01:04:42,140
and he said

915
01:04:42,160 --> 01:04:45,640
you know the more you think about these structures the more fearsome they look so

916
01:04:45,930 --> 01:04:49,620
and and you can't really make sense of them to start comparing them to

917
01:04:49,660 --> 01:04:53,840
the kind of structures that humans create

918
01:04:53,900 --> 01:04:58,880
nothing human has formed a group of humans has built

919
01:04:58,900 --> 01:05:04,880
approaches this would these i make the the large the the largest cathedrals built by

920
01:05:04,880 --> 01:05:11,360
humans were built over many generations they weren't built over hundreds of generations by millions

921
01:05:11,360 --> 01:05:12,690
of builders

922
01:05:12,760 --> 01:05:18,940
working together by comparison to the size of the termite build a man like this

923
01:05:18,940 --> 01:05:24,140
this is taller than is four times taller than the tallest building that humans

924
01:05:24,210 --> 01:05:29,060
successfully erected and they're not just i mean you can see that they're structured you

925
01:05:29,060 --> 01:05:35,700
can see that there are these veins running up and down the that structures just

926
01:05:35,740 --> 01:05:43,190
incidental or attractive there's lots of stuff going on inside these mounds and the structure

927
01:05:43,190 --> 01:05:47,470
of the mound is acutely involved in the ability of these mounds to the brain

928
01:05:47,470 --> 01:05:52,720
regulate so the temperature inside areas of the mound is kept within working limits for

929
01:05:52,720 --> 01:05:58,560
the termites the live there they also act as defence they practise some kind of

930
01:05:58,620 --> 01:06:03,680
horticulture within them so there are chambers where they grow fungi fungi

931
01:06:03,720 --> 01:06:08,280
they have to control not just the temperature but the climates within those chambers the

932
01:06:08,280 --> 01:06:14,100
humidity there is very important in order to grow this fungi that they organise their

933
01:06:14,340 --> 01:06:20,050
their young in crashes graveyards where they store the dead bodies or they move that

934
01:06:20,050 --> 01:06:24,320
is and there's even some evidence so if you if you go up to one

935
01:06:24,320 --> 01:06:29,770
of these termite mounds that's in use when you punch a hole in the outside

936
01:06:31,580 --> 01:06:36,240
i've actually a termite will arrive or maybe there will be termites there anyway and

937
01:06:36,560 --> 01:06:41,100
the first few of them instead of instead of trying to rebuild

938
01:06:41,120 --> 01:06:45,860
so instead of rushing away to warn the others what they do is they get

939
01:06:45,880 --> 01:06:49,240
when they but i think they detect it with because the the change in air

940
01:06:49,240 --> 01:06:53,980
pressure and they start banging their heads from the termite mound

941
01:06:54,020 --> 01:06:58,820
OK but it's been you know the sort of like wailing despair

942
01:06:59,000 --> 01:07:02,820
but really what they're doing is alerting other termites to the fact that there's been

943
01:07:02,820 --> 01:07:07,260
a breach in the wall of the and other termites are recruited to that area

944
01:07:07,260 --> 01:07:10,970
and very rapidly you'll see swarms of termites and they do all of the building

945
01:07:11,320 --> 01:07:13,350
there's even some evidence to suggest that the

946
01:07:13,520 --> 01:07:18,550
material properties and the organisational structure of the mound has to had to be optimized

947
01:07:18,550 --> 01:07:20,980
for its acoustic properties

948
01:07:21,800 --> 01:07:24,380
supporting this kind of alarm signal

949
01:07:25,820 --> 01:07:30,620
and then you look at the size of these tiny tiny little guys crazy

950
01:07:30,700 --> 01:07:34,680
there are able to do this said

951
01:07:38,080 --> 01:07:46,560
so there's not a lot of stuff that didn't make it into david attenborough's programme

952
01:07:46,700 --> 01:07:51,420
which i think is quite interesting so that just got some pictures here that i

953
01:07:51,420 --> 01:07:52,660
got from rupert's

954
01:07:52,980 --> 01:07:54,280
web page

955
01:07:55,680 --> 01:07:56,660
i mean

956
01:07:56,680 --> 01:07:58,220
the undertaking that

957
01:07:58,260 --> 01:08:02,400
the data got was pretty formidable i think they got

958
01:08:02,600 --> 01:08:10,200
to six tonnes of plaster of paris shipped from south south africa to namibia for

959
01:08:10,200 --> 01:08:15,700
free by some freight company that we've got some publicity out of that they had

960
01:08:15,700 --> 01:08:16,800
to hire

961
01:08:16,840 --> 01:08:21,240
you know tens of people on site to

962
01:08:21,280 --> 01:08:22,800
a wrecked this

963
01:08:25,220 --> 01:08:27,850
scanning and slicing machine

964
01:08:27,940 --> 01:08:31,840
i mean it was it was a huge undertaking from what they ended up with

965
01:08:33,880 --> 01:08:38,320
so that they revealed this three d structure obviously they there's the resolution there the

966
01:08:38,320 --> 01:08:43,380
plaster of paris couldn't they couldn't recover the very very fine tunnels for the termites

967
01:08:43,380 --> 01:08:47,280
use and they ended up with this CAD model

968
01:08:47,300 --> 01:08:52,700
of reconstructed from slices of this that they took away

969
01:08:52,900 --> 01:08:56,820
and really this structure is far too complicated for them to do anything with and

970
01:08:56,820 --> 01:09:01,180
that's the problem they can't simulate

971
01:09:01,400 --> 01:09:08,150
convection currents in it they can't explore its acoustic properties it's just too

972
01:09:08,150 --> 01:09:10,490
and you can also play soccer

973
01:09:10,520 --> 01:09:16,680
and these pages i got from the default is guy has countless animations and his

974
01:09:17,920 --> 01:09:22,550
i definitely recommend you look at this so you know particles represent the position of

975
01:09:22,580 --> 01:09:25,850
the ball in the position of the robot the robot to learning

976
01:09:25,880 --> 01:09:27,040
i wish

977
01:09:27,050 --> 01:09:29,400
trying to locate itself and marketable

978
01:09:29,480 --> 01:09:33,340
and more impressive publication also beta

979
01:09:33,340 --> 01:09:37,890
is the particle filter with the particle here represent an estimate of what the person

980
01:09:37,890 --> 01:09:40,730
is in the city of seattle

981
01:09:40,760 --> 01:09:41,850
i believe

982
01:09:41,880 --> 01:09:46,480
and then the particle filter also represents another state which is

983
01:09:46,530 --> 01:09:51,300
what it believes the person is guided to set to hierarchical setting with you know

984
01:09:51,300 --> 01:09:54,850
what the person goes it helps you with the tracking

985
01:09:54,880 --> 01:09:59,580
and then there's the sort of particles following the person and this detail was using

986
01:09:59,580 --> 01:10:01,960
to actually help people with

987
01:10:02,300 --> 01:10:06,200
some forms of dimensions on because you want to make sure to track them and

988
01:10:06,220 --> 01:10:08,650
have an idea of what they're doing and detective there

989
01:10:08,660 --> 01:10:13,900
maybe quarter on bus so that you can then intervene on the system

990
01:10:13,900 --> 01:10:17,760
it is sort of one intervene all the time because they can be very annoying

991
01:10:17,780 --> 01:10:19,430
and so you

992
01:10:19,460 --> 01:10:21,840
you need to get good estimates of what's going on

993
01:10:21,910 --> 01:10:25,160
and the type of model the that data has

994
01:10:25,200 --> 01:10:29,120
is this something that looks more like this where you have some observations that evolve

995
01:10:29,120 --> 01:10:30,170
over time

996
01:10:30,200 --> 01:10:34,740
there's some discrete states the purpose and the unknown location and then there's this sort

997
01:10:34,740 --> 01:10:39,530
of meta variable that indicates what the planets where this person trying to reach

998
01:10:39,530 --> 01:10:43,280
and this type of factor representations have been used a lot with

999
01:10:43,330 --> 01:10:48,300
particle filtering they use and also industrial set out in the negation

1000
01:10:48,630 --> 01:10:51,680
one important thing is when you have structure in the graph

1001
01:10:51,700 --> 01:10:54,840
should exploit structure as much as possible

1002
01:10:54,840 --> 01:10:58,160
and you should do analytical computations as much as possible

1003
01:10:58,210 --> 01:11:02,220
don't do monte carlo if you don't need to do it it's really and last

1004
01:11:04,260 --> 01:11:10,510
and indeed when we exploit structure these algorithms in terms of paris do incredibly better

1005
01:11:10,980 --> 01:11:12,950
the methods that are and will discuss

1006
01:11:13,010 --> 01:11:17,090
also applied to set perhaps in which number of nodes is changing over time

1007
01:11:17,100 --> 01:11:20,950
particle filters are very good for that they are able to estimate

1008
01:11:20,960 --> 01:11:27,720
the so called partition functions normalisation constant so we can do model selection relatively easy

1009
01:11:27,730 --> 01:11:28,840
compared to

1010
01:11:28,840 --> 01:11:33,780
how it's done with traditional methods like MCMC

1011
01:11:33,800 --> 01:11:38,530
the method is the real one really goes back to

1012
01:11:39,320 --> 01:11:42,970
the first paper of metropolis and column in nineteen twenty nine

1013
01:11:42,990 --> 01:11:47,510
it's like a four paper has so much and it was really worth reading every

1014
01:11:47,510 --> 01:11:49,970
sentence a few times

1015
01:11:49,980 --> 01:11:53,530
and of course there were interested in this kind of problems two

1016
01:11:54,650 --> 01:11:56,100
a lot of things

1017
01:11:56,130 --> 01:12:01,290
and this is the picture of the NES and the programs of the time

1018
01:12:01,320 --> 01:12:05,160
this kind of has changed over time

1019
01:12:05,170 --> 01:12:07,700
and and for moment actually

1020
01:12:07,710 --> 01:12:09,650
i needed someone to

1021
01:12:09,700 --> 01:12:14,340
according to algorithm invented importance sampling action is more later

1022
01:12:14,360 --> 01:12:18,610
she writes a note to someone and he says i believe one their computer should

1023
01:12:18,610 --> 01:12:20,650
be able to understand

1024
01:12:20,780 --> 01:12:25,840
these steps and inputs like line numbers and so on in the program

1025
01:12:25,860 --> 01:12:31,380
so some later he invented you know the architecture for these things

1026
01:12:31,390 --> 01:12:34,220
our computers

1027
01:12:34,510 --> 01:12:40,740
and many people have been involved with this starting with enrico fermi

1028
01:12:40,770 --> 01:12:47,040
for nine months or the metropolis who is actually the around metropolis with the code

1029
01:12:47,040 --> 01:12:47,430
that they

1030
01:12:47,970 --> 01:12:51,290
a young physicist they got the common cold is machine

1031
01:12:51,300 --> 01:12:54,070
and then became the famous metropolis in physics

1032
01:12:54,080 --> 01:12:57,850
a lot of them actually spend the rest of their lives campaigning for peace

1033
01:12:57,910 --> 01:13:03,720
and next

1034
01:13:04,020 --> 01:13:10,380
will start to the many people have worked on this matter and there's been incredible

1035
01:13:10,380 --> 01:13:15,790
amounts of work this in physics and in the world of phylogenetic trees in artificial

1036
01:13:15,790 --> 01:13:17,990
intelligence is really huge

1037
01:13:18,000 --> 01:13:23,960
the russians were too there is some of the redskins on the amazing things

1038
01:13:24,330 --> 01:13:28,880
over the last ten years artist and a lot of work in this manner

1039
01:13:28,880 --> 01:13:36,380
of the finally obtained dismayed feats can integrate which suggests that integration is part of

1040
01:13:36,380 --> 01:13:42,790
a unit did so is the ideal stimulus to keep an extension of the point

1041
01:13:42,790 --> 01:13:50,420
Delaney Clause space which is scored into the judge Jose Guillen and space where you

1042
01:13:50,720 --> 01:13:59,830
complex metrics although machinery parties with each additional missiles is you have to use updated

1043
01:13:59,830 --> 01:14:10,030
UHA which is something to hold so areas of as the state of symmetric matrices

1044
01:14:10,030 --> 01:14:15,770
so to an end mattresses on this and that he will produce a metrics and

1045
01:14:15,770 --> 01:14:22,460
other dimension to end on which the ways this relation and possible GM and is

1046
01:14:22,460 --> 01:14:25,570
equal to g with D which is due in the next

1047
01:14:26,340 --> 01:14:32,310
on the other are equivalent to the uh disease mattresses simply teach a week of

1048
01:14:32,310 --> 01:14:43,420
its 4 nation on in fact disease space is in value

1049
01:14:43,810 --> 01:14:50,400
by the loss of vision which is the fact that an extension of the modest

1050
01:14:50,400 --> 01:15:03,030
possible pitfalls of plant spaces uses it also may issue was 1 1 case of

1051
01:15:03,790 --> 01:15:09,480
gin artist will discuss permission that ABC on the hour Maddox on the longer Oscar

1052
01:15:09,480 --> 01:15:16,920
their value us all as he did last holds that exist literature is evaluated by

1053
01:15:16,920 --> 01:15:41,290
the fossil missions like just holds that also issuing on remove LZZ equipped groups relying

1054
01:15:41,290 --> 01:15:49,490
solely should stick to its but was able meanwhile is required to pay a housing

1055
01:15:49,490 --> 01:15:52,310
exactly is

1056
01:15:52,330 --> 01:16:08,850
she is not in fact Saluto makes is a party to offer case also this

1057
01:16:09,440 --> 01:16:16,510
of preach causes even if a white very interesting because you when you up is

1058
01:16:16,510 --> 01:16:27,010
to do everything E. Bush until that we reserve the only enough

1059
01:16:29,350 --> 01:16:47,380
pursuant to different was the role of general and factory ideas to Duke's disease can

1060
01:16:47,380 --> 01:16:55,420
be complex matrices on news expression of Yuan told computing is the distance between the

1061
01:16:55,420 --> 01:17:02,000
2 complex mattresses so we wouldn't get integrated they can you obtain Mr. result just

1062
01:17:02,000 --> 01:17:07,350
being operated by doing as well you also lose summation of the regarded logistic mission

1063
01:17:07,350 --> 01:17:14,160
where where are ads are in fact they begin value of this course facial his

1064
01:17:14,180 --> 01:17:22,000
club I should only older metrics said 1 the to computer again value on the

1065
01:17:22,000 --> 01:17:28,000
situation is a distant so when you have million notional a room in which is

1066
01:17:28,000 --> 01:17:33,550
different to you can said so again computers everyone on

1067
01:17:33,620 --> 01:17:42,110
you can compute the distance between the 2 which ignited the Xinhua that is there

1068
01:17:42,110 --> 01:17:49,050
is no room which is not there

1069
01:17:49,090 --> 01:17:56,640
so it is also which is scored a victory dormitory that would explain afterward we

1070
01:17:56,640 --> 01:18:00,240
use of Howie uses

1071
01:18:00,240 --> 01:18:09,160
this is a circuit on the that affect the symmetry could be deduced from deviation

1072
01:18:09,160 --> 01:18:14,500
of functions which is put on show in which is called the ghetto potential in

1073
01:18:14,550 --> 01:18:26,830
funding factories closing Quezon to showed that potential which are introduced direction of geometry aren't

1074
01:18:26,840 --> 01:18:31,550
you all cases we will use put on a show that in fact there's a

1075
01:18:31,980 --> 01:18:39,220
date most data winner of the metrics which is exactly is still Peters was position

1076
01:18:39,250 --> 01:18:45,470
who give idea is to give you can also use it as an extension of

1077
01:18:45,490 --> 01:18:56,250
the credit to transform the gods based extend the unity of injury he by register

1078
01:18:57,960 --> 01:19:04,640
for example if also point out that souls of more delegates which means a unique

1079
01:19:04,640 --> 01:19:18,790
ID and by its excretion fact Uganda take put on show at use log of

1080
01:19:18,960 --> 01:19:23,530
wouldn't to dig this would ensure and that you could do to help about 2

1081
01:19:23,530 --> 01:19:34,510
years the to put demanding which he is exactly the issue and the potential

1082
01:19:35,540 --> 01:19:40,640
please excuse to be the same case for the the property

1083
01:19:40,680 --> 01:19:51,830
so mystic space the branch of so lessons very simply do training that also called

1084
01:19:51,830 --> 01:19:59,160
on retrieve for example the local we aren't you from the complete with space so

1085
01:19:59,200 --> 01:20:05,550
near the use of the space of the symmetry visited the dignitaries is our citizens

1086
01:20:05,650 --> 01:20:13,160
distance is defined by December nation that you have a real introduced on all sorts

1087
01:20:13,200 --> 01:20:18,900
of ready space the complicated based on that verifies this certainly nominal

1088
01:20:19,540 --> 01:20:26,590
so inequality is pleased that I would just like to distance food as being produced

1089
01:20:26,610 --> 01:20:30,690
in 1972 by your country

1090
01:20:30,820 --> 01:20:36,000
I'll be displayed the bombs still owns the silly but still the dialog on the

1091
01:20:36,000 --> 01:20:42,180
suggested by the land will say is that fact the square are also died and

1092
01:20:42,180 --> 01:20:49,270
questions to devote all of innings most of

1093
01:20:50,980 --> 01:20:57,010
honors are demanding that educators and analyzes 123 colon

1094
01:20:57,030 --> 01:21:01,000
when it should be a magnitude to read 2 books

1095
01:21:01,070 --> 01:21:07,350
it's also from objects all former university but he's still the false 1 in English

1096
01:21:07,350 --> 01:21:15,070
with regard anyone and I want go oldest when 1 of is literal among must

1097
01:21:15,070 --> 01:21:21,900
only true written by strong and that these historical duty on the fact you have

1098
01:21:21,900 --> 01:21:29,570
closed in relation to all of during the course of because in fact out money

1099
01:21:29,570 --> 01:21:34,310
there is some loser could have predicted if democracy to be used in different amid

1100
01:21:34,360 --> 01:21:44,160
saloon number 2 reads was like what you know to really statistics and physics Stallings

1101
01:21:44,160 --> 01:21:48,960
a book of trouble you can see that work which is designed to use role

1102
01:21:49,220 --> 01:21:55,330
the following the chapter of include uses the characteristic function of according to cool in

1103
01:21:55,330 --> 01:22:02,850
the mind of missions so that you can use our opinions space at the university

1104
01:22:03,290 --> 01:22:08,180
said to be local entities speaks belongs to see on the numbers but you know

1105
01:22:08,200 --> 01:22:20,410
that makes didn't so it introduced a characteristic function which is this expirations which cheesy

1106
01:22:20,410 --> 01:22:25,770
and they were address space of 6 export not sure where are you know operates

1107
01:22:25,770 --> 01:22:29,850
but we at the end sort joint optimisation problem

1108
01:22:30,060 --> 01:22:34,240
when can find a consensus on the world is really sorry

1109
01:22:34,300 --> 01:22:41,050
part of the so that the final result is not only locally but also

1110
01:22:41,180 --> 01:22:49,510
it's a gaussian noise in the sky

1111
01:22:49,580 --> 01:22:51,510
with the pick survive

1112
01:22:52,590 --> 01:23:00,120
but i mean you can analyse what we want is always nice

1113
01:23:01,180 --> 01:23:02,880
bit more technically so

1114
01:23:02,900 --> 01:23:08,180
graphical models are essentially what call multi by probabilistic models why motivated because there are

1115
01:23:08,180 --> 01:23:09,450
many viable

1116
01:23:09,470 --> 01:23:13,630
in the case of the physics example i gave the many rivals were the many

1117
01:23:13,630 --> 01:23:19,130
atoms present in the material for every out have there's been was one or more

1118
01:23:19,130 --> 01:23:19,770
than one

1119
01:23:19,790 --> 01:23:21,300
in the case of an image

1120
01:23:21,320 --> 01:23:25,200
there are many variables are the many pixels are present in the image and they

1121
01:23:25,200 --> 01:23:27,250
interact in some way

1122
01:23:27,250 --> 01:23:29,610
but there is

1123
01:23:29,670 --> 01:23:33,060
that there is a structure in the dependency of these

1124
01:23:33,120 --> 01:23:34,520
of these variables

1125
01:23:34,530 --> 01:23:36,120
and this structure is given

1126
01:23:36,200 --> 01:23:43,410
in terms of article conditional independence they will see what conditional independence

1127
01:23:43,410 --> 01:23:47,290
morning formerly essentially the graphical model is

1128
01:23:47,350 --> 01:23:49,990
these are model that represents the system

1129
01:23:52,030 --> 01:23:54,470
it's part

1130
01:23:54,540 --> 01:23:57,170
and the possible relations

1131
01:23:58,310 --> 01:24:00,350
these but

1132
01:24:00,370 --> 01:24:08,530
in the probabilistic

1133
01:24:08,580 --> 01:24:13,690
in terms of which questions we would like to us when we have a repetition

1134
01:24:15,180 --> 01:24:17,210
there essentially four

1135
01:24:17,250 --> 01:24:20,430
at least four interesting question we would like to

1136
01:24:20,440 --> 01:24:22,460
two s

1137
01:24:22,470 --> 01:24:24,200
the first question is

1138
01:24:24,240 --> 01:24:28,850
usually will have a probabilistic model to get to the details later this they just

1139
01:24:28,850 --> 01:24:31,100
want to call it the big picture

1140
01:24:32,050 --> 01:24:38,010
will have a probabilistic model which will have some parameters like a statistical model with

1141
01:24:38,100 --> 01:24:41,770
and the goal one goal will be to estimate the parameters

1142
01:24:43,960 --> 01:24:45,250
we also

1143
01:24:45,260 --> 01:24:46,920
we collect from

1144
01:24:46,970 --> 01:24:50,020
real experience from real sense

1145
01:24:50,060 --> 01:24:53,240
real images that you think are real

1146
01:24:53,240 --> 01:24:56,280
gene expression

1147
01:24:56,340 --> 01:24:59,200
or real music

1148
01:24:59,200 --> 01:25:02,350
we want to estimate the parameters of far

1149
01:25:02,410 --> 01:25:04,180
this called the learning problem

1150
01:25:06,730 --> 01:25:12,160
the second question is interesting is that once we have these model how we all

1151
01:25:12,160 --> 01:25:14,080
things samples from that

1152
01:25:14,110 --> 01:25:16,200
i want to sample from model

1153
01:25:16,200 --> 01:25:20,470
well sampled from an image model is an image of sample from music

1154
01:25:20,680 --> 01:25:23,270
what is new is the song

1155
01:25:23,610 --> 01:25:25,550
sample from

1156
01:25:25,590 --> 01:25:29,460
a model basically is able to generate example

1157
01:25:30,310 --> 01:25:34,760
the dark side that it's actually model

1158
01:25:34,800 --> 01:25:41,110
thirteen that you would like to do is compute probabilities of particular outcomes

1159
01:25:41,120 --> 01:25:43,770
if you have a model that represents

1160
01:25:43,780 --> 01:25:45,190
how the weather

1161
01:25:45,190 --> 01:25:47,680
facing camera or

1162
01:25:47,700 --> 01:25:51,000
are useful wales region

1163
01:25:51,010 --> 01:25:55,270
you may be one question i would like to ask is what's the probability that

1164
01:25:56,270 --> 01:25:59,540
it will rain in camera and

1165
01:25:59,560 --> 01:26:00,700
will have

1166
01:26:00,700 --> 01:26:03,430
some into

1167
01:26:03,480 --> 01:26:05,580
so maybe you have created you have

1168
01:26:05,600 --> 01:26:09,950
you have once we have a probabilistic model of think of big databases

1169
01:26:09,950 --> 01:26:11,520
of probabilities

1170
01:26:11,580 --> 01:26:16,770
and then you can provide clear is that if are probabilistic and well you have

1171
01:26:16,790 --> 01:26:20,980
probability eighty percent of having trained camera

1172
01:26:20,980 --> 01:26:22,960
and so on

1173
01:26:25,840 --> 01:26:29,110
the type of of question that you may be interested in is find the most

1174
01:26:29,110 --> 01:26:31,000
likely outcome

1175
01:26:32,730 --> 01:26:36,450
again i can ask what's most likely to happen today

1176
01:26:38,710 --> 01:26:40,300
cloudy day

1177
01:26:40,360 --> 01:26:42,060
or sunny day

1178
01:26:42,110 --> 01:26:45,360
or rain what's the most likely

1179
01:26:45,420 --> 01:26:48,760
nothing to sing the probabilities i just want to know what the most likely

1180
01:26:48,810 --> 01:26:50,910
that's another type of query is

1181
01:26:50,910 --> 01:26:51,920
we want to

1182
01:26:51,930 --> 01:26:54,880
to perform

1183
01:26:54,950 --> 01:26:59,960
likewise in the case of the image denoising i have haven't noisy magical this was

1184
01:26:59,960 --> 01:27:02,290
the most likely

1185
01:27:02,340 --> 01:27:04,570
the noisy image

1186
01:27:04,610 --> 01:27:07,020
right because we want the only one

1187
01:27:07,070 --> 01:27:11,040
in which we want to see one corrected image and corrupted in

1188
01:27:11,050 --> 01:27:12,770
we could make sense maybe

1189
01:27:13,850 --> 01:27:18,150
i have a graphical model that represents the noisy versions of an image and that

1190
01:27:18,210 --> 01:27:23,200
we chose building noise the first thing is that the best noise version

1191
01:27:23,300 --> 01:27:25,200
that particular edge

1192
01:27:25,260 --> 01:27:32,260
also this fits into this find the most likely outcome

1193
01:27:33,550 --> 01:27:37,250
this is because of the four questions we are going to

1194
01:27:37,250 --> 01:27:40,620
mostly be interested when they have graphical up

1195
01:27:40,680 --> 01:27:42,260
i would just

1196
01:27:43,480 --> 01:27:47,150
make the connection with a very simple type one

1197
01:27:47,160 --> 01:27:50,430
and i will try to address those four questions

1198
01:27:50,500 --> 01:27:55,520
four a very simple kind of model which is not a graphical model or graph

1199
01:27:55,530 --> 01:27:58,580
which has a single line so it's not the multiply i

1200
01:27:58,600 --> 01:28:00,050
of facts

1201
01:28:00,060 --> 01:28:02,220
it doesn't

1202
01:28:02,290 --> 01:28:05,250
it doesn't

1203
01:28:06,800 --> 01:28:09,270
typical definition of graph

1204
01:28:12,170 --> 01:28:14,970
and is the model

1205
01:28:15,000 --> 01:28:16,190
this is

1206
01:28:16,250 --> 01:28:20,330
girl distribution

1207
01:28:20,380 --> 01:28:24,770
so this is a unified gaussian distribution

1208
01:28:24,770 --> 01:28:30,010
normalized means you don't have to

1209
01:28:30,670 --> 01:28:33,540
these expressions that you can see

1210
01:28:33,550 --> 01:28:35,190
it's basically the

1211
01:28:35,200 --> 01:28:37,200
expression for this function

1212
01:28:37,250 --> 01:28:39,980
you can see in the graph

1213
01:28:40,600 --> 01:28:41,550
you can

1214
01:28:41,560 --> 01:28:46,770
as those four question mentioned before for this particular very simple for

1215
01:28:46,810 --> 01:28:49,940
probably solution that you can estimate

1216
01:28:49,980 --> 01:28:51,370
for example

1217
01:28:51,400 --> 01:28:52,830
the mean

1218
01:28:52,950 --> 01:28:54,720
and the standard deviation

1219
01:28:54,770 --> 01:28:57,380
given the number of observations

1220
01:28:57,440 --> 01:29:00,120
if you know that the given process

1221
01:29:00,150 --> 01:29:04,670
the given to behave as function one viable

1222
01:29:04,720 --> 01:29:06,220
and you will attain

1223
01:29:08,860 --> 01:29:12,150
that process you can estimate mu

1224
01:29:12,150 --> 01:29:13,220
and sigma

1225
01:29:13,300 --> 01:29:15,690
and by the way you can do that is

1226
01:29:15,690 --> 01:29:19,130
some of you may remember how to do that actually that

1227
01:29:19,260 --> 01:29:21,280
estimate of

1228
01:29:21,350 --> 01:29:22,500
but i mean

1229
01:29:22,520 --> 01:29:26,360
is the maximum likelihood estimate for example mean

1230
01:29:26,360 --> 01:29:30,540
i think the smallest school and i wanted to be

1231
01:29:32,920 --> 01:29:35,230
so here for example

1232
01:29:36,730 --> 01:29:39,210
the black ones has to be wrong

1233
01:29:39,230 --> 01:29:41,400
and one

1234
01:29:42,670 --> 01:29:50,420
it should be clear that has nothing to do with who the position belongs to

1235
01:29:52,570 --> 01:29:54,420
it's completely out of the

1236
01:29:57,540 --> 01:30:00,540
colored by one

1237
01:30:00,710 --> 01:30:02,810
and like one

1238
01:30:04,000 --> 01:30:07,170
right so the question is

1239
01:30:07,880 --> 01:30:10,840
zero one circus

1240
01:30:11,770 --> 01:30:12,610
that's it

1241
01:30:15,560 --> 01:30:18,000
what this means it means that

1242
01:30:18,040 --> 01:30:20,290
so that whatever the other one

1243
01:30:23,880 --> 01:30:27,750
so is that

1244
01:30:28,020 --> 01:30:29,460
the choice

1245
01:30:30,900 --> 01:30:32,560
i don't know what you

1246
01:30:32,610 --> 01:30:34,810
will be made

1247
01:30:38,480 --> 01:30:42,230
but what about the MAP for young on

1248
01:30:44,630 --> 01:30:50,480
plus he so i want to play tool went to be system because it is

1249
01:30:50,670 --> 01:30:54,590
that the graffiti of analysis that the least one is even

1250
01:31:03,420 --> 01:31:05,150
this would question

1251
01:31:05,170 --> 01:31:07,230
if i take the columns

1252
01:31:07,440 --> 01:31:12,040
i think that this one either it's odd or even

1253
01:31:13,570 --> 01:31:15,860
know if it's even if they

1254
01:31:15,860 --> 01:31:17,810
zero who

1255
01:31:17,890 --> 01:31:20,140
i forgot sorry so

1256
01:31:21,020 --> 01:31:22,830
how the winner played

1257
01:31:22,840 --> 01:31:24,650
play one is

1258
01:31:25,750 --> 01:31:26,830
when the play

1259
01:31:26,840 --> 01:31:31,020
he says that the core or a is so that says that the least one

1260
01:31:31,020 --> 01:31:32,230
is even

1261
01:31:33,190 --> 01:31:34,790
that's the way

1262
01:31:35,840 --> 01:31:38,250
otherwise the play

1263
01:31:38,270 --> 01:31:41,610
it's not like this is also

1264
01:31:42,750 --> 01:31:44,360
players play one with

1265
01:31:44,360 --> 01:31:48,040
which we

1266
01:31:48,860 --> 01:31:51,460
so let's see what we have

1267
01:31:52,210 --> 01:31:55,110
here we go

1268
01:31:55,130 --> 01:31:56,340
so i feel

1269
01:32:01,270 --> 01:32:03,360
the phoenicians even on the slide

1270
01:32:04,190 --> 01:32:05,880
for the talk

1271
01:32:06,070 --> 01:32:09,540
you say OK so

1272
01:32:11,380 --> 01:32:13,710
i showed it to

1273
01:32:14,340 --> 01:32:19,560
partition will tell you more about this in the solution of the game being the

1274
01:32:22,400 --> 01:32:25,190
if i take for example

1275
01:32:28,420 --> 01:32:30,940
is set of nodes

1276
01:32:32,290 --> 01:32:33,340
i mean this set of

1277
01:32:34,280 --> 01:32:38,500
start from can choose any position

1278
01:32:41,960 --> 01:32:44,570
i have given you hear from so-called

1279
01:32:45,270 --> 01:32:46,900
a way to play

1280
01:32:46,900 --> 01:32:48,750
so when i'm here

1281
01:32:48,790 --> 01:32:50,190
my try to this

1282
01:32:51,070 --> 01:32:53,340
on this with the previous

1283
01:32:53,390 --> 01:32:56,060
so that's why it's so solid

1284
01:32:56,730 --> 01:32:59,520
i was OK

1285
01:33:02,250 --> 01:33:05,040
i have chosen be here and you have no interest

1286
01:33:07,270 --> 01:33:10,040
and here so i decided to go here

1287
01:33:10,060 --> 01:33:10,810
that's it

1288
01:33:11,730 --> 01:33:13,730
now you can check that

1289
01:33:14,840 --> 01:33:18,110
so from it

1290
01:33:18,940 --> 01:33:20,840
w zero

1291
01:33:20,860 --> 01:33:23,900
region four players zero

1292
01:33:24,860 --> 01:33:28,020
well we start

1293
01:33:28,770 --> 01:33:29,980
if i play

1294
01:33:29,980 --> 01:33:34,090
you know which is conformal to the strategy is small lanes world

1295
01:33:36,340 --> 01:33:43,940
have to check then you can trust me saying we started to come here

1296
01:33:44,840 --> 01:33:46,630
and then if he comes here

1297
01:33:46,630 --> 01:33:47,670
i come here

1298
01:33:47,770 --> 01:33:51,570
yes would be stupid to stick to this choice here

1299
01:33:52,560 --> 01:33:55,940
because i mean infinitely often the black

1300
01:33:57,020 --> 01:33:59,060
positions which is the one

1301
01:34:00,670 --> 01:34:03,730
so players you will win so player one

1302
01:34:03,750 --> 01:34:07,650
tourist play here so from time to time is a all over the place here

1303
01:34:09,510 --> 01:34:12,310
for a if you place here

1304
01:34:12,940 --> 01:34:15,150
it's easy for me to do

1305
01:34:15,150 --> 01:34:17,560
make of t plus

1306
01:34:17,580 --> 01:34:21,400
larger than fifty two mio by some margin

1307
01:34:21,420 --> 01:34:26,250
and we're going to train that by stochastic gradient descent try just

1308
01:34:26,280 --> 01:34:32,880
doing gradient updates with a given learning great for sampling triples around

1309
01:34:34,000 --> 01:34:37,560
i mentioned some prior work

1310
01:34:38,190 --> 01:34:44,610
using well actually using support vector machines perceptrons and even neural networks by chris burgess

1311
01:34:44,610 --> 01:34:47,510
and and co-workers where the user

1312
01:34:47,520 --> 01:34:48,980
hand coded features

1313
01:34:49,000 --> 01:34:54,600
in contrast here we're focusing just on using words and trying to find this representation

1314
01:34:54,800 --> 01:34:55,700
is also

1315
01:34:55,720 --> 01:35:03,130
several works on optimizing different loss functions like mean average precision in our CNN NDCG

1316
01:35:03,130 --> 01:35:08,870
and we're not looking at that here but you could train these models and presumably

1317
01:35:08,870 --> 01:35:11,170
with any kind of loss function

1318
01:35:11,190 --> 01:35:18,340
there's also other workers similar to this by a bengio called pami for retrieving images

1319
01:35:18,340 --> 01:35:19,300
we use

1320
01:35:20,760 --> 01:35:25,660
basically percent margin ranking perceptrons

1321
01:35:25,680 --> 01:35:30,640
with degree two features and they don't easily rank models

1322
01:35:30,660 --> 01:35:35,320
and there's also something called hash kernels more recently where

1323
01:35:35,340 --> 01:35:43,610
again the kind of degree two features are taken but they didn't into a smaller

1324
01:35:43,610 --> 01:35:46,880
set of features so things scalable

1325
01:35:46,900 --> 01:35:49,460
we can compare to that as well

1326
01:35:51,740 --> 01:35:57,480
this follows some experiments comparing some of these things we can use wikipedia so is

1327
01:35:57,490 --> 01:36:02,680
around two million documents and twenty five million links and this is what we're going

1328
01:36:02,680 --> 01:36:07,610
to use is going to pick a random document as a query

1329
01:36:07,660 --> 01:36:09,750
and then rank the other documents

1330
01:36:09,760 --> 01:36:14,960
and the documents the hyperlink to it should be highly ranked

1331
01:36:14,980 --> 01:36:18,940
so we're going to split the data into training and test

1332
01:36:18,960 --> 01:36:24,360
using that kind of preference relation can take two setups one where the whole document

1333
01:36:24,360 --> 01:36:28,610
is used as a query and one where phi ten or twenty words at random

1334
01:36:28,610 --> 01:36:34,500
from from the document used as a query to mimic keyword search

1335
01:36:34,510 --> 01:36:38,340
so here are some results on

1336
01:36:38,390 --> 01:36:44,600
document document ranking first first we limited our dictionary size to thirty thousand words so

1337
01:36:44,600 --> 01:36:49,160
that we can train the margin ranking perceptron on the degree to features because otherwise

1338
01:36:49,160 --> 01:36:53,540
the things too big to fit in memory

1339
01:36:53,560 --> 01:36:59,830
and you can see there are several types of error rate reported here but if

1340
01:36:59,830 --> 01:37:01,530
i just concentrate on the ranking loss

1341
01:37:01,950 --> 01:37:03,930
which is the percentage

1342
01:37:03,940 --> 01:37:07,180
of times that the preference relation

1343
01:37:07,220 --> 01:37:11,240
is the wrong way round a d minus is above the plus the test on

1344
01:37:11,240 --> 01:37:17,320
the test set of preference relations that we can see that the output TFIDF this

1345
01:37:17,320 --> 01:37:21,060
is this is like the cosine similarity

1346
01:37:21,070 --> 01:37:23,780
and then we have a list sorry

1347
01:37:26,320 --> 01:37:28,370
and the site where you add

1348
01:37:28,390 --> 01:37:35,660
where you don't just have the embedding space also the cosine similarity to in these

1349
01:37:35,670 --> 01:37:41,940
things are all inferior to supervised learning on this task so

1350
01:37:43,110 --> 01:37:45,410
the last two races of the

1351
01:37:45,490 --> 01:37:51,270
degree two degrees three neural network models but i showed and they

1352
01:37:51,280 --> 01:37:56,420
perform a little bit the margin ranking perceptron and

1353
01:37:56,430 --> 01:37:59,980
they also use much less parameters

1354
01:38:00,050 --> 01:38:01,460
so you can see

1355
01:38:01,720 --> 01:38:04,860
these are in like two hundred dimensional

1356
01:38:04,880 --> 01:38:06,560
embedding space

1357
01:38:06,580 --> 01:38:09,540
so that's the difference in the number of parameters

1358
01:38:09,560 --> 01:38:12,300
and then if we look at

1359
01:38:12,310 --> 01:38:14,650
training on

1360
01:38:14,660 --> 01:38:18,340
all the words in the dictionary two point five million

1361
01:38:18,360 --> 01:38:23,390
we can use the margin ranking perceptron any more but we do use hash kernel

1362
01:38:23,390 --> 01:38:26,650
approach and we get the same kind of

1363
01:38:26,660 --> 01:38:28,420
the results

1364
01:38:28,440 --> 01:38:34,660
and then we look at query document ranking this is where we picked either five

1365
01:38:34,660 --> 01:38:36,750
ten or twenty

1366
01:38:36,780 --> 01:38:40,740
keep k keywords at random

1367
01:38:40,760 --> 01:38:42,620
we have compared to everything there

1368
01:38:42,660 --> 01:38:46,900
but you can see what we get the same kind of

1369
01:38:46,930 --> 01:38:48,620
kind of observations

1370
01:38:48,630 --> 01:38:52,340
so it's not because we use the whole documents as the query

1371
01:38:52,370 --> 01:38:58,320
and then finally we have in our experiment in wikipedia you have lots of languages

1372
01:38:58,320 --> 01:39:05,880
actually so we thought it could be found to take silver cross language retrieval task

1373
01:39:05,880 --> 01:39:11,430
so you take a japanese query and then you trying to retrieve english documents that

1374
01:39:11,430 --> 01:39:16,120
should be relevant for that query if you had translated it well

1375
01:39:16,130 --> 01:39:17,870
so the the

1376
01:39:17,880 --> 01:39:23,540
the method has to do somehow implicit translate either explicit or implicit translation

1377
01:39:23,540 --> 01:39:26,720
so if you do explicit translation using

1378
01:39:26,730 --> 01:39:29,510
so good good good tall

1379
01:39:29,530 --> 01:39:35,520
and then the cosine similarity you get like four point seven percent

1380
01:39:35,550 --> 01:39:42,210
ranking loss on this task and there's a method called which is developed specifically for

1381
01:39:42,210 --> 01:39:50,060
this task has around three percent and then we have two versions of neural network

1382
01:39:50,850 --> 01:39:53,030
that we took from the slides before

1383
01:39:53,030 --> 01:39:56,820
it was trained actually just on the english

1384
01:39:56,850 --> 01:40:02,830
document english query task and we just use the translation tool and then and then

1385
01:40:02,840 --> 01:40:06,830
and then apply the function and is already better than the other methods but if

1386
01:40:06,830 --> 01:40:09,330
and they can over the observation

1387
01:40:09,350 --> 01:40:12,030
and now we have the decision problem

1388
01:40:12,060 --> 01:40:15,240
over an extended state which includes

1389
01:40:15,280 --> 01:40:18,600
the physical state transition counts

1390
01:40:18,620 --> 01:40:25,560
and the observation count

1391
01:40:25,580 --> 01:40:27,280
and so

1392
01:40:27,280 --> 01:40:29,510
we can set up a full

1393
01:40:30,390 --> 01:40:32,280
upon the model based on this

1394
01:40:32,300 --> 01:40:35,720
i have my extended state space

1395
01:40:35,740 --> 01:40:38,080
physical state counts

1396
01:40:38,100 --> 01:40:39,470
the other accounts

1397
01:40:39,490 --> 01:40:41,370
action observation

1398
01:40:41,370 --> 01:40:46,050
stay the same neck and define the joint observation action function which is defined in

1399
01:40:46,050 --> 01:40:47,530
a certain state

1400
01:40:47,530 --> 01:40:51,200
because certain actions as certain observation with my next state

1401
01:40:51,280 --> 01:40:54,390
the reward function stays the same

1402
01:40:54,390 --> 01:40:59,220
it's just another part of the problem where the goal is to maximize the return

1403
01:40:59,240 --> 01:41:02,220
under partial observability of my state

1404
01:41:02,240 --> 01:41:03,580
there's nothing different

1405
01:41:03,580 --> 01:41:06,530
in terms of formulating the model

1406
01:41:06,660 --> 01:41:15,200
is a little bit of the complication compared to the MDP state

1407
01:41:15,200 --> 01:41:16,930
so what's the complication

1408
01:41:16,950 --> 01:41:21,120
you have an infinite state MDP because my counts

1409
01:41:22,010 --> 01:41:24,220
the very big with a known model

1410
01:41:24,240 --> 01:41:25,850
you have an infinite state

1411
01:41:25,870 --> 01:41:29,680
MDP with a known model state is defined over the state of the finer over

1412
01:41:30,740 --> 01:41:34,430
in this case i every time step my state is observable

1413
01:41:34,430 --> 01:41:38,550
and my count phi is is updated and the party at every time step

1414
01:41:38,680 --> 01:41:40,970
this is not observable

1415
01:41:41,010 --> 01:41:43,490
so my counts are not observable

1416
01:41:43,510 --> 01:41:45,800
i don't know which state i went from two

1417
01:41:45,820 --> 01:41:48,680
so i don't know which count to update

1418
01:41:48,700 --> 01:41:52,060
that makes things a little bit tricky not in terms of the model the model

1419
01:41:52,060 --> 01:41:53,240
is super clean

1420
01:41:53,260 --> 01:41:56,240
but in terms of using this in practice we need to deal with that little

1421
01:41:56,240 --> 01:41:57,200
bit of complication

1422
01:41:57,660 --> 01:42:00,910
which is how can we be these counters how do we know

1423
01:42:00,930 --> 01:42:04,320
where to get the credit for certain transition

1424
01:42:04,330 --> 01:42:08,640
all we know is what action was taken on what observation was perceived but we

1425
01:42:08,640 --> 01:42:10,160
don't know the states

1426
01:42:10,180 --> 01:42:15,030
and i dirichlet distributions are defined based on the state

1427
01:42:15,080 --> 01:42:20,780
not to worry this is the classical problem for upon this is the reason learning

1428
01:42:20,780 --> 01:42:24,720
in palm piece is so much harder than learning in mdps and one lord of

1429
01:42:24,720 --> 01:42:28,430
the focus so far in the literature has been strictly on planning for the part

1430
01:42:28,450 --> 01:42:30,370
of the case

1431
01:42:34,330 --> 01:42:35,280
will just

1432
01:42:35,300 --> 01:42:39,850
turn out upon the machinery here instead of having a belief state only over the

1433
01:42:39,850 --> 01:42:44,080
original state space but also have initial counts

1434
01:42:44,120 --> 01:42:46,970
and we also use some

1435
01:42:46,990 --> 01:42:49,470
a way of monitoring the belief

1436
01:42:49,530 --> 01:42:54,740
and the belief now will be expressed over the states and over the counts

1437
01:42:54,760 --> 01:42:59,050
now to define the beliefs over these counts we need to sort of hypothesized that

1438
01:42:59,050 --> 01:43:00,510
when i see this

1439
01:43:00,530 --> 01:43:02,140
it could be because

1440
01:43:02,160 --> 01:43:05,600
this count needs to be updated in this case needs to be updated so we

1441
01:43:05,600 --> 01:43:10,350
need is a mixture of dirichlet models which tells you all of the different jewish

1442
01:43:10,350 --> 01:43:12,490
those which could happen

1443
01:43:12,510 --> 01:43:14,140
and that gives us the way to

1444
01:43:14,140 --> 01:43:15,240
update this

1445
01:43:15,260 --> 01:43:19,430
upon the model using standard bayesian inference

1446
01:43:19,450 --> 01:43:23,300
from a practical point of view maintaining that mixture is a little bit difficult because

1447
01:43:23,300 --> 01:43:26,200
the number of components in the mixture

1448
01:43:26,200 --> 01:43:28,660
grows quickly the more things you do

1449
01:43:28,680 --> 01:43:33,780
the more different ways your account could be updated so it doesn't clearly very elegantly

1450
01:43:33,780 --> 01:43:35,910
here t is you're planning horizon

1451
01:43:35,950 --> 01:43:39,390
so a little bit problematic in terms of

1452
01:43:39,410 --> 01:43:41,390
planning horizon

1453
01:43:41,530 --> 01:43:43,280
before i tell you

1454
01:43:43,300 --> 01:43:45,930
how we can make this tractable

1455
01:43:45,930 --> 01:43:53,800
i'll just mentioned two quick theoretical results that come with this probability model

1456
01:43:53,820 --> 01:43:56,550
this is the slide with a lot of complicated math

1457
01:43:56,560 --> 01:44:00,910
it's not really complicated result that slide says

1458
01:44:00,930 --> 01:44:06,080
assume that you are interested in estimating the value function for specific physical state

1459
01:44:06,120 --> 01:44:08,240
specific count vectors

1460
01:44:08,280 --> 01:44:11,910
and you want to compare to the same value function that same physical state but

1461
01:44:11,910 --> 01:44:14,640
slightly different count vectors

1462
01:44:14,660 --> 01:44:19,370
can you bound the error in the estimation of this difference

1463
01:44:19,390 --> 01:44:24,370
now here comes the complicated expression but those four parts to that complicated expressions

1464
01:44:24,390 --> 01:44:26,680
the first part says that

1465
01:44:27,850 --> 01:44:30,870
difference really depends on

1466
01:44:31,830 --> 01:44:34,450
expected value of the two count vectors

1467
01:44:34,450 --> 01:44:37,240
so i have my to dirichlet distribution

1468
01:44:37,260 --> 01:44:41,580
phi and phi prime in expectation are going to be a little bit different

1469
01:44:41,600 --> 01:44:45,970
that term an expectation the size are going to be a little bit different

1470
01:44:45,990 --> 01:44:49,280
and these two terms just says well that's all fine and dandy but in some

1471
01:44:49,280 --> 01:44:53,760
cases phi and phi prime are the same in expectation

1472
01:44:53,780 --> 01:44:58,890
but the magnitude of the number of counts is different and so that term just

1473
01:44:58,890 --> 01:45:03,760
deals with the uncertainty in the dirichlet distribution over the transition in certain in the

1474
01:45:03,760 --> 01:45:08,260
dirichlet distribution over the observations the estimates you have to have you as you have

1475
01:45:08,260 --> 01:45:10,350
more and more counts

1476
01:45:10,370 --> 01:45:14,600
this starts going away but for small numbers of counts you still need to put

1477
01:45:14,600 --> 01:45:16,180
that into play

1478
01:45:16,200 --> 01:45:18,680
so this is over the value function

1479
01:45:18,680 --> 01:45:23,450
so this is the first theoretical result this is something we can measure it seems

1480
01:45:24,140 --> 01:45:25,910
big complicated into

1481
01:45:25,930 --> 01:45:29,030
expression which isn't very useful

1482
01:45:29,050 --> 01:45:31,200
it turns out that expression

1483
01:45:31,220 --> 01:45:35,430
comes at the core of one of the approximation methods we use and being able

1484
01:45:35,430 --> 01:45:39,660
to bound the difference really helps us figure out how to approximate the mixture of

1485
01:45:40,990 --> 01:45:42,800
two more slide

1486
01:45:42,800 --> 01:45:48,030
the second theoretical result that comes with this framework is the following one

1487
01:45:48,050 --> 01:45:52,180
so so far i've told you that i can bound the difference in value function

1488
01:45:52,200 --> 01:45:54,120
when the physical state is the same

1489
01:45:54,140 --> 01:45:56,010
but the accounts are different

1490
01:45:56,030 --> 01:45:58,680
what i'm telling you here is

1491
01:45:58,680 --> 01:46:00,530
given that i have some

1492
01:46:00,620 --> 01:46:01,910
value function

1493
01:46:01,910 --> 01:46:03,700
at some state

1494
01:46:03,720 --> 01:46:08,010
count how different is that in terms of

1495
01:46:08,050 --> 01:46:09,950
the correct value function

1496
01:46:10,010 --> 01:46:14,640
and i've thrown in some projection operator here if you want a formal definition that

1497
01:46:14,640 --> 01:46:17,640
you can go in the paper the point here is that this is the case

1498
01:46:17,640 --> 01:46:21,390
where the counts are going to be bounded to some opera value

1499
01:46:21,410 --> 01:46:23,060
so we're interested in say

1500
01:46:23,080 --> 01:46:25,870
what five down my counts to sum up value

1501
01:46:25,890 --> 01:46:28,450
i compared to the case why don't the counts

1502
01:46:28,450 --> 01:46:31,680
because in the infinity for the counter and outfielder really well

1503
01:46:31,700 --> 01:46:34,930
practice you might not want to do that you minus one to stop early so

1504
01:46:34,930 --> 01:46:39,590
so it's a worthwhile for

1505
01:46:40,070 --> 01:46:46,050
asked to produce a white paper specifically talking about vocabulary mapping and

1506
01:46:46,130 --> 01:46:47,470
so stop

1507
01:46:49,530 --> 01:46:50,970
i wanted to show

1508
01:46:50,970 --> 01:46:55,800
as an example of the sort of coverage that you get some random called tag

1509
01:46:55,800 --> 01:46:57,970
decide terms not

1510
01:46:58,010 --> 01:47:03,660
not disambiguate bombers might mean submarine sandwich for example somewhere

1511
01:47:03,840 --> 01:47:10,070
but also might mean one plane which does

1512
01:47:10,300 --> 01:47:11,950
so now

1513
01:47:13,430 --> 01:47:15,430
large is going to

1514
01:47:15,450 --> 01:47:19,450
so you're better about how you represent this in

1515
01:47:19,510 --> 01:47:21,590
so it's meant to refer to as

1516
01:47:21,610 --> 01:47:30,510
this is not

1517
01:47:32,680 --> 01:47:35,090
it's not

1518
01:47:37,050 --> 01:47:38,110
it is

1519
01:47:42,130 --> 01:47:44,180
so that

1520
01:47:44,220 --> 01:47:46,970
but think

1521
01:47:46,990 --> 01:47:50,900
it is

1522
01:47:50,900 --> 01:47:53,740
it's like that

1523
01:47:53,820 --> 01:47:55,880
in some areas

1524
01:47:57,820 --> 01:48:01,300
you can get

1525
01:48:02,840 --> 01:48:05,490
it's something fairly

1526
01:48:05,550 --> 01:48:07,680
fairly wide coverage that had

1527
01:48:07,740 --> 01:48:11,300
the areas which are more didn't see there there are a few areas which has

1528
01:48:11,300 --> 01:48:12,950
no coverage whatsoever

1529
01:48:13,030 --> 01:48:17,010
but there are certainly areas which are densely covered in the areas where the first

1530
01:48:17,010 --> 01:48:19,900
part of it because we never

1531
01:48:19,920 --> 01:48:24,570
really had an opportunity to do something like that for

1532
01:48:26,320 --> 01:48:33,050
two and ingram list sorted by water and representatives that you know i would like

1533
01:48:33,050 --> 01:48:37,010
to have an opportunity to do that i would dearly like one of you to

1534
01:48:37,010 --> 01:48:38,590
take on the task

1535
01:48:38,610 --> 01:48:42,530
doing that would be very useful thing to do community

1536
01:48:42,550 --> 01:48:46,680
so it is very useful for

1537
01:48:49,930 --> 01:48:52,030
and means in wins

1538
01:48:53,030 --> 01:49:01,760
because of need to for was very it's kind and it's difficult to imagine

1539
01:49:01,760 --> 01:49:04,090
what need that's sold

1540
01:49:06,150 --> 01:49:09,420
because was not and you that's

1541
01:49:09,720 --> 01:49:12,360
that will be because

1542
01:49:12,360 --> 01:49:20,720
he then went

1543
01:49:20,760 --> 01:49:23,260
not show how the

1544
01:49:23,300 --> 01:49:26,920
content on the at page codes

1545
01:49:26,970 --> 01:49:30,660
the available as our or for some of us

1546
01:49:33,090 --> 01:49:37,070
one the things

1547
01:49:41,990 --> 01:49:42,840
if you go to

1548
01:49:42,880 --> 01:49:45,380
o was i got was that the org

1549
01:49:45,430 --> 01:49:49,220
and you would search for a left-handed person responsible for left-handed person this is the

1550
01:49:49,220 --> 01:49:50,610
page you get

1551
01:49:50,650 --> 01:49:51,570
it looks like

1552
01:49:51,590 --> 01:49:53,050
normal HTML page

1553
01:49:53,070 --> 01:49:54,610
but if you check the source

1554
01:49:54,610 --> 01:49:57,700
you would actually that's idea

1555
01:49:57,740 --> 01:49:58,490
with some

1556
01:50:01,240 --> 01:50:04,700
this formation applied to transform it into art

1557
01:50:04,760 --> 01:50:05,700
the whole thing

1558
01:50:05,720 --> 01:50:10,930
but as shown obvious how we go through this hard source actually look like

1559
01:50:10,950 --> 01:50:15,570
just to give some context so the page is about left the person

1560
01:50:15,680 --> 01:50:18,030
which is this personalisation of homo sapiens

1561
01:50:18,050 --> 01:50:19,630
an instance of

1562
01:50:19,680 --> 01:50:23,010
left-handed person is a human who favours

1563
01:50:23,030 --> 01:50:25,950
his or her left and so this would be

1564
01:50:27,360 --> 01:50:31,970
now if you open but

1565
01:50:32,010 --> 01:50:37,450
if you go to the internet in and out of the page

1566
01:50:37,510 --> 01:50:38,530
this is what you

1567
01:50:40,760 --> 01:50:43,590
so one

1568
01:50:44,340 --> 01:50:52,220
the works

1569
01:51:01,860 --> 01:51:04,550
OK so this is what you get if you go to the web page and

1570
01:51:05,630 --> 01:51:07,570
see the source of the left-handed person

1571
01:51:07,570 --> 01:51:08,570
that page

1572
01:51:08,590 --> 01:51:12,180
so what we do is we have that each concept in opencyc is assigned a

1573
01:51:12,180 --> 01:51:13,450
unique IP

1574
01:51:13,470 --> 01:51:16,760
so this would be

1575
01:51:16,860 --> 01:51:19,590
so this would be this

1576
01:51:19,610 --> 01:51:21,220
everything here

1577
01:51:21,300 --> 01:51:23,160
this is a unique idea

1578
01:51:23,260 --> 01:51:25,840
for this concept

1579
01:51:27,430 --> 01:51:35,180
OK so far and this is

1580
01:51:35,300 --> 01:51:37,610
was this song

1581
01:51:37,630 --> 01:51:39,630
the first to have some assertion about

1582
01:51:40,840 --> 01:51:42,820
it's an ontology from

1583
01:51:42,860 --> 01:51:45,430
so to cyc ontology concept

1584
01:51:47,630 --> 01:51:49,740
external ideas on

1585
01:51:49,820 --> 01:51:51,340
so what does so

1586
01:51:51,340 --> 01:51:53,860
this concept is a class

1587
01:51:53,880 --> 01:51:57,280
this thing so this is a left-handed person

1588
01:51:57,320 --> 01:51:58,950
and if you check the content

1589
01:51:58,990 --> 01:52:02,550
you see that it's has the labour left-handed common human

1590
01:52:02,570 --> 01:52:05,840
this is the common to the data before loudly

1591
01:52:05,880 --> 01:52:07,780
so that its

1592
01:52:07,800 --> 01:52:13,070
all instances of this personalisation homo sapiens is also this is just for humans

1593
01:52:13,130 --> 01:52:17,700
then have an increased level this would be the predictive text so before

1594
01:52:17,740 --> 01:52:22,260
it's a subclass of the thing as check what this thing actually is this

1595
01:52:22,280 --> 01:52:25,260
is a new idea of the

1596
01:52:25,320 --> 01:52:28,930
concept as concepts

1597
01:52:29,200 --> 01:52:30,930
many of these

1598
01:52:30,950 --> 01:52:34,380
and here we have links to other ontologies the same as

1599
01:52:34,380 --> 01:52:36,570
this concept in

1600
01:52:36,590 --> 01:52:38,430
number and

1601
01:52:38,610 --> 01:52:39,590
open circuit

1602
01:52:39,650 --> 01:52:41,950
it's the kind of also link it to

1603
01:52:41,950 --> 01:52:44,090
the total number

1604
01:52:44,110 --> 01:52:47,240
two side that come to wikipedia and so on so

1605
01:52:50,280 --> 01:52:53,880
this would be different

1606
01:52:56,150 --> 01:52:57,570
here are some more

1607
01:52:57,570 --> 01:53:00,740
transcripts of this can be set so it can be left

1608
01:53:01,820 --> 01:53:04,030
we live in a person

1609
01:53:04,150 --> 01:53:06,740
and then if you go down here

1610
01:53:06,740 --> 01:53:08,990
some more assertions about this

1611
01:53:08,990 --> 01:53:10,230
which is similar to

1612
01:53:10,240 --> 01:53:14,390
vocal that we're talking about and can is that these are the primary

1613
01:53:14,400 --> 01:53:17,570
representational channels each of us

1614
01:53:17,620 --> 01:53:21,750
has a preference it's only a preference we have all of them

1615
01:53:21,800 --> 01:53:24,220
we have a preference for one so

1616
01:53:24,240 --> 01:53:25,240
some of us

1617
01:53:25,240 --> 01:53:27,000
are visual

1618
01:53:27,030 --> 01:53:30,550
we have a preference for the visual sort of thinking some of us or auditory

1619
01:53:30,550 --> 01:53:33,500
where pressure or preference for sort of sounds

1620
01:53:33,540 --> 01:53:36,950
and some of us are can is that if we have a preference for feeling

1621
01:53:37,000 --> 01:53:40,530
i mean just take you through some of these

1622
01:53:40,550 --> 01:53:44,480
and then how you can use this when you communicating with people

1623
01:53:44,520 --> 01:53:45,940
so these are the three

1624
01:53:45,950 --> 01:53:52,020
that we're going to talk about three weaponisation channels visual auditory and can setting

1625
01:53:54,090 --> 01:53:57,340
if you're talking to a visual person

1626
01:53:57,370 --> 01:54:00,240
you should be using visual types of words

1627
01:54:00,280 --> 01:54:03,270
because this is how they think

1628
01:54:03,290 --> 01:54:06,210
so use words like well you see what i mean

1629
01:54:06,250 --> 01:54:08,920
does this look right

1630
01:54:08,940 --> 01:54:12,070
can you just picture this imagine

1631
01:54:12,080 --> 01:54:15,490
do you see what i'm going with this

1632
01:54:15,500 --> 01:54:18,030
if i'm talking to you in your visual

1633
01:54:18,850 --> 01:54:20,480
it will make more sense

1634
01:54:20,510 --> 01:54:24,030
and if i talked to another way now for those of you who chose number

1635
01:54:24,030 --> 01:54:25,740
one of course

1636
01:54:25,740 --> 01:54:28,380
in your preferences probably visual

1637
01:54:28,390 --> 01:54:30,240
because if you look at the description

1638
01:54:30,240 --> 01:54:35,050
how houches house is picturesque you can see that a lot of focus

1639
01:54:35,150 --> 01:54:38,200
has been put on the colourful paths in the garden area it a lot of

1640
01:54:38,200 --> 01:54:42,070
window space so you can enjoy the view is clearly

1641
01:54:43,120 --> 01:54:46,840
i've purposely injected a lot of visual words in there so if that was your

1642
01:54:48,400 --> 01:54:52,980
it's probably likely that you're visual sort of think you have the others as well

1643
01:54:53,000 --> 01:54:56,500
but this is probably your preference instead and then if you have a very strong

1644
01:54:57,600 --> 01:54:59,050
one two three

1645
01:54:59,140 --> 01:55:01,170
you have a strong preference here

1646
01:55:03,200 --> 01:55:06,860
right so you are number one and you have a very strong preference was this

1647
01:55:06,860 --> 01:55:11,840
is good this is a good for you to understand that you're probably strongly preference

1648
01:55:11,840 --> 01:55:13,650
to visual

1649
01:55:15,840 --> 01:55:19,050
if you're talking to an auditory person you want to be using

1650
01:55:19,110 --> 01:55:21,130
sound type the words

1651
01:55:21,140 --> 01:55:23,080
so does this sound right

1652
01:55:23,120 --> 01:55:25,480
the strike chord with does this resonate

1653
01:55:25,570 --> 01:55:27,400
we on the same wavelength

1654
01:55:27,410 --> 01:55:29,620
i'm very old tree

1655
01:55:31,740 --> 01:55:34,020
i was going to say this sounds right this

1656
01:55:34,030 --> 01:55:38,120
this makes more sense to me when someone says all we on the same wavelength

1657
01:55:38,970 --> 01:55:41,290
when someone says can you see where we're going

1658
01:55:41,320 --> 01:55:42,530
with this

1659
01:55:42,540 --> 01:55:44,580
that doesn't resonate with me

1660
01:55:44,600 --> 01:55:46,420
these these words to

1661
01:55:46,440 --> 01:55:49,830
so if you chose number two you'll probably

1662
01:55:49,870 --> 01:55:52,210
strongly preference toward auditory

1663
01:55:52,250 --> 01:55:55,070
the house is very soundly constructed

1664
01:55:55,080 --> 01:55:59,020
and situated isn't such a quiet area that all you here

1665
01:55:59,030 --> 01:56:03,010
when you walk outside of the sounds of the birds singing it's a story book

1666
01:56:03,010 --> 01:56:07,340
in terry tells us so much character you probably find yourself asking

1667
01:56:07,360 --> 01:56:11,330
how you could pass ever passed by

1668
01:56:11,400 --> 01:56:16,010
did anyone have a very strong preference for number two

1669
01:56:16,100 --> 01:56:19,380
a lot of not very strong but maybe a little bit so my mind would

1670
01:56:19,380 --> 01:56:22,730
have been mind would have been strong for the number and then the third disc

1671
01:56:25,210 --> 01:56:29,210
so this sort of words you be using when you're communicating took anesthetic person

1672
01:56:29,300 --> 01:56:32,890
i just feel for this does is describe

1673
01:56:32,950 --> 01:56:34,800
can you get a handle on this

1674
01:56:35,070 --> 01:56:37,660
to feel what

1675
01:56:37,710 --> 01:56:39,290
and if you chose number three

1676
01:56:39,310 --> 01:56:40,580
you probably

1677
01:56:40,600 --> 01:56:43,990
recently candes that because of the words i use the house has a really special

1678
01:56:43,990 --> 01:56:45,670
feel to it

1679
01:56:45,680 --> 01:56:49,590
it's not often you come into contact with the place that touches

1680
01:56:49,650 --> 01:56:54,010
on so many important features is spacious enough you to really feel like you can

1681
01:56:54,010 --> 01:56:57,750
move around freely and yet cosy enough that you want where

1682
01:56:57,780 --> 01:57:00,750
yourself and taking care of it

1683
01:57:00,760 --> 01:57:05,130
did anyone have a very strong preference for number three

1684
01:57:05,200 --> 01:57:07,890
not a lot of particularly i added OK

1685
01:57:12,270 --> 01:57:19,550
have a look at this picture

1686
01:57:19,600 --> 01:57:20,990
what strikes you

1687
01:57:21,900 --> 01:57:23,850
what strikes about this picture

1688
01:57:23,900 --> 01:57:25,940
she reckoned

1689
01:57:25,950 --> 01:57:27,310
and our friend bush

1690
01:57:27,330 --> 01:57:35,480
same gestures

1691
01:57:35,580 --> 01:57:41,350
they look as if they could be talking in same time what can't tell but

1692
01:57:41,350 --> 01:57:42,590
it does look

1693
01:57:42,640 --> 01:57:45,510
if you if you had to say yes or no

1694
01:57:45,520 --> 01:57:49,020
would you say that these two guys in this picture

1695
01:57:49,130 --> 01:57:52,570
look as though they have rapport

1696
01:57:59,250 --> 01:58:01,080
so if you look at the face

1697
01:58:01,100 --> 01:58:04,810
it doesn't look so i mean sure and looks a little bit

1698
01:58:04,850 --> 01:58:06,640
bush laughing is

1699
01:58:06,680 --> 01:58:11,430
it's not like hierarchies series and bushes laughing

1700
01:58:11,440 --> 01:58:16,610
there but slightly leaning slightly leaning towards each other

1701
01:58:16,670 --> 01:58:19,950
which is an interesting

1702
01:58:20,010 --> 01:58:24,440
interesting position to be in and of course the hands both of them are using

1703
01:58:24,440 --> 01:58:26,160
their hands

1704
01:58:26,160 --> 01:58:27,880
body language is important so

1705
01:58:27,890 --> 01:58:31,670
so far we've discussed is it's important to

1706
01:58:31,680 --> 01:58:34,520
the subject you're talking about is important

1707
01:58:34,540 --> 01:58:37,350
to have something in common

1708
01:58:38,000 --> 01:58:39,590
so if i were to

1709
01:58:39,590 --> 01:58:43,280
things like emcee see epee variational methods

1710
01:58:44,160 --> 01:58:45,600
and even another new

1711
01:58:46,060 --> 01:58:49,860
inference algorithms can be used on the same model

1712
01:58:51,590 --> 01:58:54,140
so you really need to have the toolbox of

1713
01:58:56,230 --> 01:59:03,350
four your models the understand and are comfortable with like calcium distribution plus on distribution are you know

1714
01:59:03,800 --> 01:59:07,660
an infinite mixture whatever components in your toolbox of components

1715
01:59:08,100 --> 01:59:11,720
you put them together in a way that makes sense fourier application

1716
01:59:13,340 --> 01:59:17,210
and then you say how do i do inference in this and then you go to

1717
01:59:17,650 --> 01:59:22,860
we are separate toolbox of inference methods and if one of them doesn't work try a different one

1718
01:59:24,510 --> 01:59:28,800
and i think it's sort of important to make this distinction just because sometimes

1719
01:59:30,870 --> 01:59:35,650
analyzing something is much more complicated if u mesh together the model and the algorithm

1720
01:59:38,780 --> 01:59:41,740
so you know i'll just get some points for discussion

1721
01:59:43,320 --> 01:59:45,680
so the first few points are

1722
01:59:46,170 --> 01:59:46,940
just kind-of

1723
01:59:48,800 --> 01:59:49,160
you know

1724
01:59:50,340 --> 01:59:51,160
my personal

1725
01:59:51,780 --> 01:59:54,900
views on some myths and misconceptions about bayesian methods

1726
01:59:56,940 --> 02:00:00,620
i don't wanna rant about this too long but i think it's useful to kind of

1727
02:00:01,140 --> 02:00:03,480
have them on the slide to be able to talk about them

1728
02:00:04,790 --> 02:00:05,800
one of them is that

1729
02:00:06,680 --> 02:00:08,830
you know i sometimes see people who are

1730
02:00:09,320 --> 02:00:13,810
mean perhaps a bit naive about modelling say something like i really like not comfortable

1731
02:00:13,810 --> 02:00:18,230
with bayesian methods because you're making all these assumptions i want methods that don't make

1732
02:00:22,920 --> 02:00:24,700
and i here this surprisingly often

1733
02:00:27,400 --> 02:00:31,130
and i mean the answer there is on methods make assumptions

1734
02:00:31,710 --> 02:00:33,420
in order to do anything

1735
02:00:34,140 --> 02:00:36,880
that involves predicting you have to make some sort of assumptions

1736
02:00:38,720 --> 02:00:41,230
if you don't make assumptions the only thing you can do

1737
02:00:42,850 --> 02:00:44,980
you get your dataset and you spit it back

1738
02:00:45,480 --> 02:00:47,870
you know you the identity map you know these

1739
02:00:48,640 --> 02:00:49,590
the same data

1740
02:00:50,310 --> 02:00:54,050
you say is it all up to you what my model is i saw this data

1741
02:00:54,560 --> 02:00:57,690
that's my model that's the only thing that doesn't make any assumptions okay

1742
02:01:00,450 --> 02:01:04,320
so without assumptions is impossible to predict with a bayesian

1743
02:01:04,760 --> 02:01:08,270
framework does is it forces

1744
02:01:10,440 --> 02:01:10,770
you know

1745
02:01:11,690 --> 02:01:13,110
almost obsessive

1746
02:01:13,900 --> 02:01:18,620
transparency in your assumptions you've to write down all the assumptions

1747
02:01:19,520 --> 02:01:21,340
in the language a probability theory

1748
02:01:24,520 --> 02:01:30,550
what that means is that then people look at it and your assumptions are so obvious they start questioning them

1749
02:01:31,160 --> 02:01:32,530
actually i think that's a good thing

1750
02:01:33,160 --> 02:01:37,160
right if if everybody had to be forced to write down their assumptions

1751
02:01:38,790 --> 02:01:42,360
common language then we could all question each other's assumptions

1752
02:01:42,830 --> 02:01:48,760
and that you know you would get different answers given the same data that's because people make different assumptions

1753
02:01:53,690 --> 02:01:58,340
so whenever i see a message that i don't understand i try to figure out

1754
02:01:58,340 --> 02:02:01,560
what are the assumptions that went into the math that what behavior with this meant

1755
02:02:01,560 --> 02:02:01,960
that have

1756
02:02:02,380 --> 02:02:02,640
and so on

1757
02:02:03,290 --> 02:02:05,120
okay here is the second misconception

1758
02:02:06,850 --> 02:02:10,150
which is something like if you know i don't it comes in the following form

1759
02:02:10,150 --> 02:02:13,470
and really like bayesian methods because i worry i don't have the right prior

1760
02:02:14,020 --> 02:02:15,240
if i don't have the right prior

1761
02:02:16,620 --> 02:02:16,950
you know

1762
02:02:18,760 --> 02:02:19,640
i want to very well

1763
02:02:20,650 --> 02:02:24,980
and it's certainly true that you can really badly abused bayesian methods

1764
02:02:25,440 --> 02:02:29,970
by putting in ridiculous priors but this and there's no such thing is the right

1765
02:02:29,970 --> 02:02:32,230
prior from a subjective bayesian point of view

1766
02:02:32,980 --> 02:02:34,350
certainly a poor model

1767
02:02:35,160 --> 02:02:38,630
any kind whether it's the prior part of likely apart whatever

1768
02:02:39,200 --> 02:02:41,360
aspect of your model if it's a bad model

1769
02:02:43,040 --> 02:02:45,220
then it's gonna make lousy predictions

1770
02:02:46,130 --> 02:02:48,260
so the point is how do we guard against their

1771
02:02:51,560 --> 02:02:52,290
the model

1772
02:02:52,800 --> 02:02:54,970
all components over the prior and likelihood

1773
02:02:55,390 --> 02:02:58,120
should capture a reasonable range a possibilities

1774
02:02:58,880 --> 02:02:59,560
and you can only

1775
02:03:00,210 --> 02:03:03,630
do that's perhaps by some introspection some

1776
02:03:04,060 --> 02:03:06,510
intuition about what these distributions are

1777
02:03:07,000 --> 02:03:09,210
and then some maybe sampling from your pryr

1778
02:03:10,750 --> 02:03:11,640
when in doubt

1779
02:03:12,160 --> 02:03:13,980
you can choose vague priors

1780
02:03:16,120 --> 02:03:17,800
it shouldn't stop you just because

1781
02:03:18,250 --> 02:03:18,820
you don't know

1782
02:03:19,200 --> 02:03:23,160
something you should stop you from saying was a reasonable range i'm sure you can

1783
02:03:23,160 --> 02:03:25,690
come up to a point where we say on that's unreasonable

1784
02:03:26,940 --> 02:03:28,010
i don't want to know

1785
02:03:29,600 --> 02:03:30,550
range from minus

1786
02:03:31,400 --> 02:03:34,370
ten million to ten plus ten million that's just silly

1787
02:03:34,840 --> 02:03:36,900
so at some point you will be able to

1788
02:03:37,320 --> 02:03:38,360
specify a range

1789
02:03:40,800 --> 02:03:43,720
here is another misconception a lot of people

1790
02:03:45,300 --> 02:03:48,190
associate bayesian methods with maximum a posteriori

1791
02:03:49,400 --> 02:03:52,080
so map is similar to regularisation

1792
02:03:52,460 --> 02:03:55,340
but really offers no particular bayesian advantages

1793
02:03:56,150 --> 02:03:59,050
in fact i would rather do regularization then map

1794
02:04:00,230 --> 02:04:03,860
because regularisation at least i can analyse within a nice

1795
02:04:06,210 --> 02:04:07,510
thinking about regularization

1796
02:04:11,900 --> 02:04:13,290
kind of unfortunate

1797
02:04:15,120 --> 02:04:16,510
aspect that u

1798
02:04:17,820 --> 02:04:20,570
might actually think that i'm trying to do something bayesians

1799
02:04:23,160 --> 02:04:24,490
in fact what they

1800
02:04:25,470 --> 02:04:28,560
troubling things about maximum posterior is the following

1801
02:04:29,880 --> 02:04:31,260
maximum likelihood

1802
02:04:31,810 --> 02:04:35,170
is invariant to re-parameterization okay if i take

1803
02:04:36,380 --> 02:04:38,800
maximum likelihood fit more calcium

1804
02:04:39,180 --> 02:04:39,630
and i say

1805
02:04:40,100 --> 02:04:46,140
instead of parameterizing it is mean and variance i'm gonna prime traded prime prime tries it mean

1806
02:04:46,620 --> 02:04:48,190
and log of standard deviation

1807
02:04:49,610 --> 02:04:50,930
the maximum likelihood fit

1808
02:04:51,390 --> 02:04:55,200
is still exactly the same it's it's invariant a re-parametrization

1809
02:04:56,210 --> 02:04:59,120
map is not invariant to re-parametrization

1810
02:05:00,630 --> 02:05:07,330
so whether i call that the variance or standard deviation log-variance actually matters when i do map

1811
02:05:07,720 --> 02:05:08,880
that's just seems terrible

1812
02:05:09,700 --> 02:05:12,680
right that's totally irrelevant information it shouldn't matter

1813
02:05:13,100 --> 02:05:13,840
in fact

1814
02:05:16,140 --> 02:05:16,590
give me

1815
02:05:17,180 --> 02:05:18,590
any simple problem

1816
02:05:19,550 --> 02:05:21,210
and any value for the parameter

1817
02:05:22,000 --> 02:05:23,970
and i can really re-parameterizes

1818
02:05:24,420 --> 02:05:27,840
the problem so that the map lies at that point

1819
02:05:30,020 --> 02:05:32,600
the way you do that's by the way if you try to think about it

1820
02:05:32,790 --> 02:05:35,100
is you re-parameterized in a nonlinear way

1821
02:05:35,480 --> 02:05:36,710
so you squeeze

1822
02:05:37,370 --> 02:05:42,760
the privatisation around point so you density your your your prior will have to go

1823
02:05:42,760 --> 02:05:46,450
up and your posterior will go up around the point and you stretch it out

1824
02:05:46,450 --> 02:05:47,130
everywhere else

1825
02:05:47,740 --> 02:05:49,750
and then my map now will be point

1826
02:05:50,200 --> 02:05:55,110
so this just seems perverse and you know for that reason we should be careful about map

1827
02:05:56,820 --> 02:06:02,870
and the importantly from a practical perspective it doesn't offer the advantages averaging over here uncertainty

1828
02:06:07,180 --> 02:06:11,720
o people don't seem to like bayesian methods because most bayesian papers

1829
02:06:12,190 --> 02:06:15,150
i don't have a lot of theorems and proofs that he ended them

1830
02:06:16,140 --> 02:06:17,150
therefore look like

1831
02:06:17,560 --> 02:06:20,900
i ran the same ciency and then i did this and then here's a plot

1832
02:06:21,370 --> 02:06:23,980
it just doesn't feel as hardcore math here whatever


1
00:00:00,000 --> 00:00:04,570
is you

2
00:00:06,690 --> 00:00:10,890
you have

3
00:00:20,540 --> 00:00:24,980
majors are

4
00:00:37,830 --> 00:00:43,840
these were released

5
00:00:48,900 --> 00:00:56,640
is the

6
00:01:22,340 --> 00:01:26,250
that's the

7
00:01:26,290 --> 00:01:31,440
and that

8
00:02:18,430 --> 00:02:25,960
the first

9
00:02:42,370 --> 00:02:45,580
our minds

10
00:02:45,580 --> 00:02:50,700
the following content is provided under a Creative Commons license your support will help MIT

11
00:02:50,700 --> 00:02:55,000
OpenCourseWare continue to offer high-quality educational resources for free

12
00:02:55,490 --> 00:02:59,780
to make a donation or to view additional materials from hundreds of MIT courses

13
00:03:00,360 --> 00:03:07,100
visit MIT OpenCourseWare at ocw . MIT . EDU

14
00:03:07,120 --> 00:03:12,260
let me start by basically listing the main things we've round of about 3 weeks

15
00:03:12,260 --> 00:03:16,880
or so and I had a few complement of information about that because there's a

16
00:03:16,880 --> 00:03:23,110
few more details that I didn't quite 5 and annotation food you know probably make

17
00:03:23,110 --> 00:03:31,750
it clear especially what happens at the very end of the of these classes so

18
00:03:32,250 --> 00:03:40,570
here is a list of things that should be on your user fees for the

19
00:03:42,110 --> 00:03:48,070
so the 1st thing we learned about the main topic of this unit is about

20
00:03:48,080 --> 00:03:58,410
functions of several variables so we've learned how to think of functions of 2 of

21
00:03:58,410 --> 00:04:03,890
the variables in terms of protein them in particular was not only the glass but

22
00:04:03,890 --> 00:04:10,210
also the Contel plots and how to lead control

23
00:04:12,460 --> 00:04:27,590
and we around how to study evaluations of these functions using partial derivatives so remember

24
00:04:27,590 --> 00:04:31,850
we've defined the partial of F with respect to

25
00:04:32,050 --> 00:04:36,860
some variables x to be the rate of change with respect to x when we

26
00:04:36,860 --> 00:04:42,050
hold off your valuables constant so if you have a function of X and Y

27
00:04:42,310 --> 00:04:47,270
symbol means to differentiate with respect to x tweeting y as a constant

28
00:04:54,460 --> 00:04:57,110
we've learned how to bake age

29
00:04:57,370 --> 00:05:05,690
partial derivatives into the vector of the gradient vector so for example if we have

30
00:05:05,690 --> 00:05:11,650
a function of the variables that's just the vector was components of a buffer derivatives

31
00:05:12,010 --> 00:05:17,930
and we've seen how to use the gradient vector of possibilities to divide various things

32
00:05:17,930 --> 00:05:29,330
such as approximation formulas so the change in energy when we change x y and

33
00:05:29,330 --> 00:05:32,930
z society is approximately equal to 1

34
00:05:33,950 --> 00:05:47,350
there's several times and can we write this in vector form as the gradient of

35
00:05:47,350 --> 00:05:52,450
the product the amount by which the position vector has changed

36
00:05:52,810 --> 00:05:57,450
OK so basically what causes to change is that I'm changing x y and z

37
00:05:57,450 --> 00:06:04,160
by small amounts and how sensitive is to each variable is precisely what the profitability

38
00:06:06,550 --> 00:06:14,270
and in particular we can use so this approximation is called the tangent plane approximation

39
00:06:14,270 --> 00:06:22,480
because it tells us in fact it amounts to identifying the graph of the function

40
00:06:22,490 --> 00:06:28,510
with its tangent place it means that we assume that the function of the smallest

41
00:06:28,510 --> 00:06:32,650
linearly on x y z and if we set these things or what we get

42
00:06:32,660 --> 00:06:39,030
is actually we're replacing the function by its linear approximation will replacing the glass by

43
00:06:39,030 --> 00:06:40,330
its attendant

44
00:06:40,610 --> 00:06:44,350
except of course we haven't seen the graph of the function of the variables because

45
00:06:44,350 --> 00:06:49,010
if you live in four-dimensional space so when we think of the profitability was a

46
00:06:49,010 --> 00:06:50,230
function of two variables

47
00:06:50,490 --> 00:07:01,070
but also tells us how to find the tangent planes to levels of faces so

48
00:07:01,070 --> 00:07:02,830
if you want

49
00:07:02,850 --> 00:07:04,240
so here's the first one

50
00:07:04,250 --> 00:07:07,180
OK so we built this whole set of vocabulary

51
00:07:07,210 --> 00:07:10,340
and a whole lot of them maybe even more than we like

52
00:07:10,350 --> 00:07:12,870
and not just the vocabulary

53
00:07:12,880 --> 00:07:14,200
but also

54
00:07:14,210 --> 00:07:15,220
the tools

55
00:07:15,240 --> 00:07:16,600
that we need

56
00:07:17,320 --> 00:07:22,790
to build these vocabularies the tools that we need to deploy these vocabularies and the

57
00:07:22,790 --> 00:07:27,960
applications in which reuses vocabularies bits of vocabularies are one of the city central pillars

58
00:07:28,330 --> 00:07:30,670
of what built

59
00:07:30,680 --> 00:07:32,470
the second thing that we build

60
00:07:32,500 --> 00:07:34,220
it is the a whole set of names

61
00:07:34,230 --> 00:07:36,350
OK so we gave names everything

62
00:07:36,360 --> 00:07:38,130
we call these names you're right

63
00:07:38,170 --> 00:07:40,050
this is the house is the tree

64
00:07:40,070 --> 00:07:44,350
this is my house is your house that we did this billions and billions we

65
00:07:44,350 --> 00:07:46,290
mean to millions of names

66
00:07:46,300 --> 00:07:49,210
first of that's the second key ingredient will we built

67
00:07:49,230 --> 00:07:53,680
and of course the third ingredient is that we struggle that those vocabularies and those

68
00:07:53,680 --> 00:07:56,780
names we strung together in a joint work

69
00:07:56,820 --> 00:08:02,500
OK so i think those three vocabularies names and the joint work of the essence

70
00:08:02,520 --> 00:08:05,280
the very high levels of what we

71
00:08:06,520 --> 00:08:09,000
and i said this in the introduction

72
00:08:09,010 --> 00:08:14,210
mostly we have been and we are thinking about what we are doing as engineering

73
00:08:15,030 --> 00:08:18,750
we're building this stuff and then were checking if it works

74
00:08:18,760 --> 00:08:20,670
anyway it's obvious that it works

75
00:08:20,700 --> 00:08:23,570
so i'm not going to spend a long time

76
00:08:23,620 --> 00:08:26,890
celebrating our success

77
00:08:26,900 --> 00:08:31,210
right so all you need to do is is i have the slide taken slideshare

78
00:08:31,240 --> 00:08:33,390
called semantic web good news

79
00:08:33,450 --> 00:08:37,220
and take a look at those lives and i i keep updating them every time

80
00:08:37,930 --> 00:08:42,000
there are there to stories about how the government are now using our technology and

81
00:08:42,000 --> 00:08:44,850
not just in the UK and the US only any more

82
00:08:45,140 --> 00:08:51,150
the BBC's running their world cup website with our technology howl the goodrelations ontology is

83
00:08:51,150 --> 00:08:55,400
changing the way the retail sector works out

84
00:08:55,450 --> 00:08:56,640
schema org

85
00:08:56,650 --> 00:08:57,790
he's pushed by the

86
00:08:57,870 --> 00:09:05,130
the large search engines how oracle is including RDF in its primary database product how

87
00:09:05,130 --> 00:09:06,290
the publishing industry

88
00:09:06,710 --> 00:09:12,230
is changing with the new york times one of the leading lights yesterday you know

89
00:09:12,240 --> 00:09:16,660
arcs explain to me your project is doing with the electricity to france where they

90
00:09:16,660 --> 00:09:22,590
are generating three hundred thousand personalized energy saving plans for people every day

91
00:09:23,230 --> 00:09:30,710
using semantic web technology so it's clear to that we have been an engineering success

92
00:09:31,110 --> 00:09:32,350
and the question is

93
00:09:32,360 --> 00:09:38,040
do we learn any site

94
00:09:38,070 --> 00:09:40,490
and how they're going to answer the question

95
00:09:40,500 --> 00:09:43,850
well the the thought experiment i'm going to run

96
00:09:43,930 --> 00:09:49,100
is the following

97
00:09:49,120 --> 00:09:50,740
so let's pretend

98
00:09:50,790 --> 00:09:54,040
that the last ten years or one giant experiment

99
00:09:54,070 --> 00:09:57,760
OK there were one large giant computer science experiment

100
00:09:57,860 --> 00:10:03,040
so is this is still what we came out of the test tube it was

101
00:10:03,090 --> 00:10:07,600
that it was giant experiment what would happen if you would run the experiment again

102
00:10:07,620 --> 00:10:14,370
so we did all this stuff we designed languages we build ontologies we build BP

103
00:10:14,610 --> 00:10:20,250
we built the linked open data cloud that's giant experiment now what would happen if

104
00:10:20,250 --> 00:10:22,700
you would set back the clock and we do it all again

105
00:10:22,710 --> 00:10:27,110
now then some things will turn out the same and some things which are different

106
00:10:27,150 --> 00:10:29,750
i mean it's exactly that difference i'm interested in

107
00:10:29,750 --> 00:10:34,970
so the things that turn out the same they must somehow be of crucial

108
00:10:34,980 --> 00:10:38,400
meaning that if you run the experiment again and again in some things are always

109
00:10:38,400 --> 00:10:43,740
the same and they they say something fundamental about the information universe

110
00:10:43,750 --> 00:10:48,210
some things are not very crucial i mean all are vision examples of all our

111
00:10:48,510 --> 00:10:52,650
ontology languages are full of angle brackets and i can imagine that we would run

112
00:10:52,650 --> 00:10:57,170
the whole thing again we wouldn't use angle brackets again so somehow

113
00:10:57,180 --> 00:11:01,460
the use of angle brackets doesn't strike me as a very fundamental of computer science

114
00:11:01,460 --> 00:11:03,600
is an example of

115
00:11:05,280 --> 00:11:07,260
perfect theoretical physics

116
00:11:07,280 --> 00:11:13,980
occasionally works somebody sees through all the drama and reveals the key way to bring

117
00:11:13,980 --> 00:11:15,630
the truth out

118
00:11:15,680 --> 00:11:19,330
very very rarely but what relevant is beautiful i thought you might enjoy it

119
00:11:20,430 --> 00:11:22,940
that's how well team discovered the

120
00:11:22,990 --> 00:11:25,730
that is at the heart of the atom that was the best resolution where they

121
00:11:25,730 --> 00:11:29,320
had those been turn the timeframe on

122
00:11:29,330 --> 00:11:30,710
fifty years

123
00:11:30,720 --> 00:11:35,790
and you have the discovery of the quantum approach on the same of idea qualitatively

124
00:11:35,790 --> 00:11:38,480
but different scale quantitatively

125
00:11:38,510 --> 00:11:39,930
here is the

126
00:11:39,940 --> 00:11:44,460
it was a three kilometre long electron accelerator at stanford in california

127
00:11:44,520 --> 00:11:49,230
the san andreas earthquake fault is about two hundred meters just beyond the back the

128
00:11:50,150 --> 00:11:53,100
good place to build an accelerator

129
00:11:53,130 --> 00:11:56,900
i mean wouldn't be replaced went through the middle of it actually is on the

130
00:11:57,940 --> 00:12:00,940
the folklore is that they separated be on the bedrock

131
00:12:01,730 --> 00:12:03,300
just move collectively

132
00:12:03,310 --> 00:12:07,200
when the earthquake happens but palo alto down by the bay was built on jello

133
00:12:07,230 --> 00:12:12,770
will wobble like anything it has been tested but the if that's what will happen

134
00:12:12,770 --> 00:12:17,240
but i'm going to next weaken hoping you won't but the same is also used

135
00:12:17,320 --> 00:12:18,910
have laser beam down

136
00:12:18,920 --> 00:12:20,850
so monitoring very subtle

137
00:12:20,880 --> 00:12:25,280
changes so this is the particle beam also being used for

138
00:12:25,290 --> 00:12:30,310
monitoring the movements in way that is the electron beam that's

139
00:12:30,330 --> 00:12:34,430
was three times as long as the target is the target of hydrogen which is

140
00:12:34,430 --> 00:12:38,820
where the protons are and the detector is a huge electronic detector

141
00:12:38,830 --> 00:12:43,180
and here is a picture of the thing being that fall of the left-hand corner

142
00:12:43,180 --> 00:12:46,270
the beam of electrons emerges target

143
00:12:46,300 --> 00:12:49,350
would be hidden behind this set of concrete

144
00:12:49,380 --> 00:12:50,810
and the text

145
00:12:50,820 --> 00:12:55,810
is there on the right and the little almost invisible figure down the bottom detector

146
00:12:55,830 --> 00:12:58,950
is myself that was taking a long long time ago

147
00:12:58,970 --> 00:13:02,670
and in those days there was a big detector today

148
00:13:02,720 --> 00:13:08,560
the small picture is remarkable but that the scale of the things are qualitatively the

149
00:13:08,560 --> 00:13:14,670
same idea electrons bouncing off the quarks revealed so electrons bouncing of the proton revealed

150
00:13:14,670 --> 00:13:17,570
the proton had hard it's inside

151
00:13:17,580 --> 00:13:22,420
and that's just the way that alpha particle scattering of atoms revealed the this is

152
00:13:22,420 --> 00:13:23,670
a hard inside

153
00:13:23,680 --> 00:13:24,630
the scale

154
00:13:24,650 --> 00:13:28,530
it's going to be different so from that we knew

155
00:13:28,550 --> 00:13:30,400
i discovered that the proton

156
00:13:30,420 --> 00:13:34,520
it's not fundamentally is made in its simplest form of three quarks

157
00:13:34,530 --> 00:13:37,700
together by will be called gluons

158
00:13:37,720 --> 00:13:40,890
gluons are massless

159
00:13:40,910 --> 00:13:47,680
particles with one unit of intrinsic spin just like photons are massless particles with one

160
00:13:47,680 --> 00:13:51,180
in the intrinsic spin as photons r two

161
00:13:52,070 --> 00:13:57,850
electromagnetic force so gluons are the force the quarks we'll learn more about tomorrow but

162
00:13:57,850 --> 00:14:04,540
i just mentioned that so you can get the sense that have the similarity energy

163
00:14:04,560 --> 00:14:09,110
now to make the proton and neutron requires two different varieties we call them flavours

164
00:14:09,940 --> 00:14:11,800
up and down the charges

165
00:14:12,560 --> 00:14:15,160
units where the protein charge class wall

166
00:14:15,230 --> 00:14:19,510
the up quark has plus two thirds down to minus one for the quarks that

167
00:14:19,520 --> 00:14:23,180
look like that as far as we know but it's used

168
00:14:23,230 --> 00:14:24,030
and so

169
00:14:24,050 --> 00:14:25,740
protons two ups and the downs

170
00:14:25,770 --> 00:14:27,510
and the new tries to down to

171
00:14:27,720 --> 00:14:32,950
so here is a picture of a hydrogen atom not to scale

172
00:14:33,580 --> 00:14:37,110
and i should say this

173
00:14:37,130 --> 00:14:39,090
to show that

174
00:14:39,150 --> 00:14:42,970
sometimes there obvious truth standard interface

175
00:14:42,980 --> 00:14:44,270
they don't

176
00:14:44,280 --> 00:14:48,540
so i've noticed probably do the following things in a little experiment that we take

177
00:14:48,540 --> 00:14:51,110
a deep breath from it and hold it and then read out again

178
00:14:54,070 --> 00:14:54,730
thank you

179
00:14:54,780 --> 00:14:58,670
right so you breathe in about a million million million million oxygen atoms which is

180
00:14:58,670 --> 00:15:01,240
of course a very small but we now know know

181
00:15:01,260 --> 00:15:05,280
since the data JJ thomson but there are negatively charged electrons in all those atoms

182
00:15:05,280 --> 00:15:07,940
so you breathe in a huge amount of negative charge

183
00:15:08,020 --> 00:15:13,980
and you go along these open days to university labs you're invited to stand on

184
00:15:13,980 --> 00:15:17,300
its data plate and a charge up to very high voltage your hair stand on

185
00:15:18,350 --> 00:15:21,570
and of course as you noticed my head in the sand and the

186
00:15:21,820 --> 00:15:25,860
the reason that might be different than the reason some of your head and so

187
00:15:25,940 --> 00:15:27,160
it's because

188
00:15:27,180 --> 00:15:31,180
in addition to receiving a huge amount of negative electric charges that the whole story

189
00:15:31,180 --> 00:15:35,170
what stood on and you breathe in a huge amount of positive as well

190
00:15:35,180 --> 00:15:37,390
in the atomic nuclei of those atoms

191
00:15:37,400 --> 00:15:39,740
and your has stayed in place

192
00:15:41,350 --> 00:15:44,440
the negative charge of the positive charge

193
00:15:44,460 --> 00:15:46,680
exactly counterbalance

194
00:15:46,890 --> 00:15:51,830
now this is the fact that we would accept but just think about this now

195
00:15:51,900 --> 00:15:58,810
the astonishing way that that balance was achieved as far as we know electrons and

196
00:15:58,810 --> 00:16:02,820
quarks basic letters of nature's alphabet

197
00:16:02,840 --> 00:16:03,730
if there is anything

198
00:16:03,760 --> 00:16:06,900
because it connects them we have yet to discover

199
00:16:06,940 --> 00:16:10,840
so how is the electron which is not made of quarks it's

200
00:16:10,860 --> 00:16:12,180
it's itself

201
00:16:12,240 --> 00:16:17,170
the negative charge counterbalance is the positive charge in protons

202
00:16:17,180 --> 00:16:20,030
because the positive charges come about

203
00:16:20,050 --> 00:16:21,540
because three

204
00:16:21,560 --> 00:16:26,710
who are carrying fractional charges of two-thirds and minus the

205
00:16:26,770 --> 00:16:28,860
not five or seven

206
00:16:29,920 --> 00:16:31,790
three quarters

207
00:16:31,810 --> 00:16:38,900
each carrying on the average one-third electrical charge combine to make plus long precisely counterbalancing

208
00:16:38,900 --> 00:16:44,210
the minus one of the electron that is telling us that there is something uniting

209
00:16:44,210 --> 00:16:46,570
these things which we have yet to understand

210
00:16:46,570 --> 00:16:51,590
so it's a vector of zeros and ones in the index

211
00:16:53,270 --> 00:16:54,110
and then

212
00:16:54,700 --> 00:16:58,580
everything else is the same but now once we get to

213
00:16:58,620 --> 00:17:02,650
the method f one x two that message

214
00:17:02,680 --> 00:17:04,250
corresponds to

215
00:17:04,250 --> 00:17:09,110
summing over the delta function at the value x one was a which is essentially

216
00:17:10,500 --> 00:17:15,590
back here with x one set the value a and then when we run through

217
00:17:15,590 --> 00:17:18,950
all these messages again we get just

218
00:17:20,460 --> 00:17:21,930
a different

219
00:17:21,950 --> 00:17:26,590
overall message coming in to explore and when that normalized that is the probability distribution

220
00:17:26,590 --> 00:17:27,610
over x four

221
00:17:27,650 --> 00:17:29,700
given that x one equals

222
00:17:30,410 --> 00:17:36,060
so that's how you incorporate evidence wherever you want and that's how you initialise

223
00:17:37,500 --> 00:17:41,390
messages and that you send them around i haven't told you how to schedule the

224
00:17:41,390 --> 00:17:44,170
messages but essentially weekend

225
00:17:44,450 --> 00:17:45,580
come up with

226
00:17:45,580 --> 00:17:50,610
a few different scheduling methods there are some ways of optimizing the scattering but you

227
00:17:50,610 --> 00:17:54,650
don't need to iterate this over and over again once every

228
00:17:55,730 --> 00:18:00,390
variable has sent a message to every factor in every factor has sent a message

229
00:18:00,390 --> 00:18:02,460
to every variable

230
00:18:02,510 --> 00:18:05,870
all of the probabilities have been computed

231
00:18:05,910 --> 00:18:12,180
so it's one we through all variables not factors in whatever order makes sense

232
00:18:12,240 --> 00:18:15,410
i will give us the correct

233
00:18:15,420 --> 00:18:18,950
any questions about that

234
00:18:18,970 --> 00:18:21,320
sure we

235
00:18:22,780 --> 00:18:29,410
we used to think that

236
00:18:29,520 --> 00:18:34,020
in fact the

237
00:18:34,260 --> 00:18:37,950
given that

238
00:18:48,210 --> 00:18:54,290
i haven't thought of that question i try to repeat the question which will give

239
00:18:54,290 --> 00:18:55,940
me a chance to think about it

240
00:18:55,960 --> 00:19:01,000
so the question is we had belief propagation

241
00:19:01,040 --> 00:19:06,130
for singly connected directed graphs and and we're back to graph propagation for singly connected

242
00:19:06,130 --> 00:19:07,630
factor graphs

243
00:19:07,650 --> 00:19:10,880
i cannot be that when you convert

244
00:19:11,670 --> 00:19:15,040
a directed graph to factor graph

245
00:19:15,060 --> 00:19:20,650
but you can get a multiple connected factor graph or vice versa in which case

246
00:19:20,650 --> 00:19:25,500
it would seem that one propagation method can do something exactly the other propagation that

247
00:19:25,500 --> 00:19:27,080
they cannot be exactly

248
00:19:27,100 --> 00:19:31,500
and without proof my feeling is that the answer is no

249
00:19:31,520 --> 00:19:33,250
i think there are equivalent

250
00:19:37,040 --> 00:19:42,600
i don't think there's a sleight-of-hand tricks that you can do to do this but

251
00:19:42,600 --> 00:19:43,940
i could be wrong

252
00:19:44,000 --> 00:19:46,830
we have to think about that for

253
00:19:47,880 --> 00:19:52,600
so that was factor graph propagation it very

254
00:19:52,600 --> 00:19:59,350
hidden markov models or linear gaseous state space models and you and if you've encountered

255
00:19:59,350 --> 00:20:05,040
algorithms like forward backward in common filtering kalman smoothing then the slide will be useful

256
00:20:05,040 --> 00:20:06,040
to you

257
00:20:06,100 --> 00:20:09,810
what we're talking about here are

258
00:20:10,580 --> 00:20:13,650
very old and well-known models or

259
00:20:14,540 --> 00:20:21,540
hi series where we have a hidden state evolving over time these are the axes

260
00:20:21,560 --> 00:20:26,520
and we have our observed variables otherwise evolving over time

261
00:20:26,540 --> 00:20:29,060
and the graphical model

262
00:20:29,080 --> 00:20:34,190
for both the hidden markov model and the state space model is identical to look

263
00:20:34,190 --> 00:20:35,060
like this

264
00:20:35,060 --> 00:20:36,630
it corresponds to

265
00:20:36,630 --> 00:20:39,270
factorisation of the joint probability

266
00:20:39,290 --> 00:20:42,020
over all the hidden variables

267
00:20:42,060 --> 00:20:47,000
and all the observed variables were time is going from left to right

268
00:20:48,980 --> 00:20:53,130
the main difference between hidden markov model and then you get this state space model

269
00:20:53,150 --> 00:20:57,310
are that the states are discrete in a hidden markov model and there going to

270
00:20:57,980 --> 00:21:04,330
continuous real valued vectors in state space model

271
00:21:04,330 --> 00:21:10,710
both humans and state space models can be represented represented as singly connected dags like

272
00:21:12,020 --> 00:21:14,500
and independently

273
00:21:15,600 --> 00:21:21,000
people develop the forward backward algorithm for doing inference in hidden markov models

274
00:21:21,000 --> 00:21:22,690
the then messages

275
00:21:22,710 --> 00:21:28,650
in the sequence forward and then backward to compute marginal probabilities of the hidden variables

276
00:21:28,670 --> 00:21:31,000
given the observed sequence

277
00:21:31,960 --> 00:21:35,960
people in the signal processing and control communities

278
00:21:36,370 --> 00:21:38,420
back in the fifties in fact

279
00:21:38,420 --> 00:21:40,810
i invented the common

280
00:21:40,810 --> 00:21:42,830
filtering in common smoothing out

281
00:21:43,630 --> 00:21:48,690
is which again sent messages forward and backward

282
00:21:48,710 --> 00:21:54,230
and these are both instances these two algorithms are both instances of the general

283
00:21:54,250 --> 00:21:57,940
family of belief propagation factor graph propagation of errors

284
00:21:57,960 --> 00:22:02,380
so if you learned about these special cases you can forget about that can just

285
00:22:02,380 --> 00:22:04,830
think about the more general case of

286
00:22:05,080 --> 00:22:06,850
factor graph propagation

287
00:22:06,870 --> 00:22:09,130
and this is definitely not how

288
00:22:10,130 --> 00:22:14,580
control engineers or single processing people with each

289
00:22:14,580 --> 00:22:18,000
common filtering for example but i think this

290
00:22:18,000 --> 00:22:22,290
in a clear way of doing this because it becomes immediately obvious how to generate

291
00:22:22,420 --> 00:22:26,790
generalized this trees or any other singly connected graph

292
00:22:26,810 --> 00:22:29,020
and how to generalize the two

293
00:22:29,150 --> 00:22:31,540
the different kinds of variables that

294
00:22:35,190 --> 00:22:38,040
let's talk about the hard problem

295
00:22:38,060 --> 00:22:41,170
so everything will be connected dags

296
00:22:44,380 --> 00:22:50,460
half the exact algorithm for doing inference is called the junction tree algorithm i have

297
00:22:50,460 --> 00:22:54,270
like a short one-paragraph description of it but i'll i'll

298
00:22:54,270 --> 00:22:57,940
describe it a little more detail over the next five minutes or so

299
00:22:57,960 --> 00:23:01,330
there are a couple of other things we can do it our graph is multiply

300
00:23:02,500 --> 00:23:05,460
one of them is called cutset conditioning

301
00:23:05,480 --> 00:23:08,520
which essentially involves the following

302
00:23:08,690 --> 00:23:10,960
if you have your monthly connected graph

303
00:23:11,000 --> 00:23:12,810
if you're lucky

304
00:23:12,810 --> 00:23:16,580
you're graph is not terribly well we connect connected is just a little bit more

305
00:23:16,580 --> 00:23:18,150
we connected

306
00:23:18,150 --> 00:23:22,410
and Y are drawn at the same time but if we permuted for instance the set

307
00:23:22,410 --> 00:23:26,010
of all Xs that we've seen then there is no longer a direct link between

308
00:23:26,010 --> 00:23:31,690
X and Y but we haven't change the marginals so that's also just a short remark if you

309
00:23:31,690 --> 00:23:36,990
don't follow this in detail don't worry but there's a nice way of constructing a

310
00:23:36,990 --> 00:23:42,650
sample from this given a sample from this and then we test the difference of these

311
00:23:42,650 --> 00:23:48,330
two so it will be tests just like in a kernel means embedding and testing problem and

312
00:23:48,330 --> 00:23:53,990
it's also nice to point out that this has another interpretation and will turn

313
00:23:54,010 --> 00:23:59,590
out to be formally identical to a different approach to independence testing which was

314
00:23:59,590 --> 00:24:07,240
started  originally by Bach and Jordan they call it kernel ICA or

315
00:24:07,240 --> 00:24:13,290
something like that  and there this is again this builds a classic

316
00:24:13,290 --> 00:24:16,670
result from probability theory which is similar to the one that I told you about

317
00:24:16,670 --> 00:24:21,590
before so this time the result is the following if I have two

318
00:24:21,590 --> 00:24:27,530
random variables that are independent then well ignore the functions F and G

319
00:24:27,530 --> 00:24:33,970
for the moment so if two random variables are independent then in particular their covariance is zero

320
00:24:33,970 --> 00:24:40,450
so this covariance is the first order of dependence now if the covariance between

321
00:24:40,460 --> 00:24:44,210
two random variables is zero it doesn't apply that the variables are

322
00:24:44,210 --> 00:24:50,190
independent however it turns out if required that the conveyance be zero not just

323
00:24:50,190 --> 00:24:54,830
for the variables X and Y but also for nonlinear transformations of X and of

324
00:24:54,830 --> 00:25:01,770
Y and if we require this for a sufficiently large class of nonlinear transformations so again

325
00:25:01,770 --> 00:25:08,030
all continuous all bounded continuous  functions then it turns out that this the implication

326
00:25:08,030 --> 00:25:12,090
goes the other way to sort of requiring this is sufficient for independence of X and

327
00:25:12,090 --> 00:25:18,930
Y so that's nice because it means again  we can use this simple criterion

328
00:25:18,940 --> 00:25:23,950
such a criterion we can check directly in the reproducing kernel hilbert space

329
00:25:23,950 --> 00:25:27,850
we can do this simple criterion but we have to do it over

330
00:25:27,850 --> 00:25:32,820
a large function class so in in the general philosophy of kernel methods is

331
00:25:32,820 --> 00:25:37,870
always you try to do something simple linear  in a large function class by

332
00:25:37,870 --> 00:25:42,010
doing in the RKHS and it turns out with this kind of statement it's

333
00:25:42,020 --> 00:25:47,890
then translates into a very nontrivial statement in the input domain so if you do

334
00:25:47,890 --> 00:25:53,390
this you would end up exactly with the same equations that you get if you

335
00:25:53,410 --> 00:25:58,890
directly test for difference of the means of this distribution and this one in the

336
00:25:58,920 --> 00:26:09,030
reproducing kernel hilbert space okay I'll skip this one and now we get to one

337
00:26:09,030 --> 00:26:15,730
of the simple theorems of kernel methods so-called the representer theorem so this one

338
00:26:15,730 --> 00:26:19,550
I want to prove the proof is not difficult and I think it's it's nice

339
00:26:19,550 --> 00:26:27,310
to see this so this theorem short version is that theorem tells us that all

340
00:26:27,310 --> 00:26:35,850
reasonable or large class of kernel algorithms has solutions that are very simple in

341
00:26:35,850 --> 00:26:40,690
the sense that they can be expanded in terms of kernels sitting on the training

342
00:26:40,690 --> 00:26:49,370
points okay so what are their assumptions of the theorem assumptions are we have a positive definite kernel

343
00:26:49,370 --> 00:26:57,650
we have a training set inputs and outputs  we have some a monotonic function sigma

344
00:26:57,700 --> 00:27:04,830
which will scale the value of this so-called regularizer and we have an

345
00:27:04,830 --> 00:27:11,630
arbitrary clust function C maybe look at this down here what does the clust

346
00:27:11,630 --> 00:27:18,570
function do it depends it can depend in a general way on the inputs outputs

347
00:27:18,850 --> 00:27:25,570
for whole training set and on what the function F produces as outputs so typical

348
00:27:25,570 --> 00:27:31,610
the clust function would be saying well I'll take the Y value and I'll compare it maybe

349
00:27:31,610 --> 00:27:36,410
I'll take the difference between the y the true Y value and the F of

350
00:27:36,410 --> 00:27:40,890
X value that's predicted by my learning machine maybe the squared difference or something like this

351
00:27:40,890 --> 00:27:45,840
and sum this up but this is a more general form that could also somehow

352
00:27:45,840 --> 00:27:54,030
depend jointly or or in very complicated nonlinear way whatever so so every

353
00:27:54,030 --> 00:28:00,670
function that minimizes this quantity here it makes the representation of this form so

354
00:28:00,670 --> 00:28:09,690
such a simple kernel representation and why is this surprising well this minimization

355
00:28:09,690 --> 00:28:13,750
it runs over the whole reproducing kernel hilbert space so for instance if we take

356
00:28:13,750 --> 00:28:20,470
a gaussian kernel that's an infinite dimensional hilbert space and so we are solving an optimization problem

357
00:28:20,470 --> 00:28:27,630
over an inifinite dimensional space but it turns out we can prove that any minimizer

358
00:28:27,630 --> 00:28:32,430
can be expressed in terms of this set of functions that are known

359
00:28:32,470 --> 00:28:38,390
a priori I have the training data so they live in this final dimensional subspace spent by

360
00:28:38,450 --> 00:28:44,510
kernel sitting on the training points so that makes the problem a lot easier because now

361
00:28:44,510 --> 00:28:51,530
the problem consists only of finding these alpha I rather than solving this infinite dimensional problem

362
00:28:52,410 --> 00:29:03,060
so how do we solve this  so this is a simple example of a

363
00:29:03,060 --> 00:29:11,010
simple loss function traditionally used loss function and this would be the standard kind of

364
00:29:11,010 --> 00:29:14,690
regularizer that's being used we'll get back to this one later when we talk about

365
00:29:15,120 --> 00:29:22,970
SVMs but it doesn't have to be that one so the proof is simple we decompose an arbitrary

366
00:29:22,970 --> 00:29:27,430
function from our hilbert space actually I think it was called HK in the

367
00:29:27,430 --> 00:29:34,470
previous slide into two  parts one  lives in the span of the training points mapped

368
00:29:34,470 --> 00:29:39,830
into the feature space and the other one is orthogonal to it so one part is in span

369
00:29:39,830 --> 00:29:46,690
the other one is orthogonal orthogonal  means in particular that they are all dot products between these parts

370
00:29:46,690 --> 00:29:53,770
and these vectors are zero okay so I can do this in hilbert space

371
00:29:53,780 --> 00:30:02,010
allow  orthogonal projections and if I then apply this does written function to

372
00:30:02,010 --> 00:30:03,290
b of x is zero

373
00:30:03,300 --> 00:30:05,260
and BOC is zero

374
00:30:05,300 --> 00:30:06,360
what now

375
00:30:06,420 --> 00:30:07,720
is the

376
00:30:07,810 --> 00:30:12,590
dot product and cross product a crosby

377
00:30:16,870 --> 00:30:19,540
you can apply that recipe

378
00:30:19,640 --> 00:30:21,860
but it's much easier

379
00:30:21,860 --> 00:30:23,380
go to the x y

380
00:30:24,510 --> 00:30:26,560
x is that we have here

381
00:30:26,610 --> 00:30:27,500
he was

382
00:30:27,530 --> 00:30:30,160
in the x direction the unit vector and b

383
00:30:30,160 --> 00:30:31,380
in the y direction

384
00:30:31,390 --> 00:30:36,200
i think in my hand i rotate over the smallest angle which is ninety degrees

385
00:30:37,140 --> 00:30:39,160
and my corkscrew will go up

386
00:30:39,210 --> 00:30:40,950
so i know the whole thing already

387
00:30:40,990 --> 00:30:43,600
i know that this cross product

388
00:30:43,600 --> 00:30:44,460
must be

389
00:30:46,240 --> 00:30:50,030
the magnitude must be one that's immediately clear but i mean have the direction by

390
00:30:50,030 --> 00:30:53,210
using the corkscrew

391
00:30:53,230 --> 00:30:56,320
now if you're very smart

392
00:30:56,370 --> 00:30:57,630
you may say

393
00:30:59,140 --> 00:31:01,260
you find places e

394
00:31:01,280 --> 00:31:04,130
only because you have used this coordinate system

395
00:31:04,140 --> 00:31:06,800
if this axis have been ex

396
00:31:06,940 --> 00:31:09,770
and this one had been y

397
00:31:09,870 --> 00:31:13,710
then the cross product in x and y would be in the minors the direction

398
00:31:13,730 --> 00:31:15,540
you're right

399
00:31:15,590 --> 00:31:17,120
but if you ever do that

400
00:31:17,130 --> 00:31:18,910
i will tell you

401
00:31:18,960 --> 00:31:23,210
you will always always have to work with what we call

402
00:31:23,230 --> 00:31:26,150
a right handed coordinate system

403
00:31:26,200 --> 00:31:32,660
a right-handed coordinate system by definition is one whereby the cross product of x with

404
00:31:33,390 --> 00:31:35,980
it's z and not why minus e

405
00:31:36,050 --> 00:31:40,990
so when we get in the future involved with cross product important angular momentum always

406
00:31:40,990 --> 00:31:44,220
make yourself x y z diagram

407
00:31:44,270 --> 00:31:46,010
for which x cross y

408
00:31:46,020 --> 00:31:50,900
is never ever make it such that x crosswise minus c

409
00:31:50,940 --> 00:31:52,250
you want to hang yourself

410
00:31:52,270 --> 00:31:55,340
before one thing that wouldn't work anymore

411
00:31:55,530 --> 00:32:00,210
very very careful must work if you use the right-hand court school

412
00:32:00,300 --> 00:32:01,530
make sure you work

413
00:32:01,540 --> 00:32:03,420
with the

414
00:32:03,420 --> 00:32:06,720
a right-handed coordinate system

415
00:32:06,740 --> 00:32:08,910
all right

416
00:32:08,960 --> 00:32:11,720
now the worst part is over

417
00:32:11,730 --> 00:32:12,500
and now

418
00:32:12,510 --> 00:32:16,730
i would like to

419
00:32:16,740 --> 00:32:18,130
right down for you

420
00:32:18,130 --> 00:32:19,940
you get to pick up some of the

421
00:32:20,070 --> 00:32:23,400
the fruits now although it will penetrate slowly

422
00:32:23,450 --> 00:32:25,980
i want to write down for you

423
00:32:27,350 --> 00:32:30,150
equations for a moving particle

424
00:32:30,230 --> 00:32:35,730
moving objects in three-dimensional space

425
00:32:35,740 --> 00:32:40,210
very complicated most which i

426
00:32:40,220 --> 00:32:42,760
i can hardly imagine what it's like

427
00:32:42,800 --> 00:32:44,350
it is the point

428
00:32:44,350 --> 00:32:46,310
that's going to move around

429
00:32:46,400 --> 00:32:49,340
in space and it is this point p

430
00:32:49,380 --> 00:32:50,740
this point p

431
00:32:50,790 --> 00:32:54,010
is going to move around in space

432
00:32:54,060 --> 00:32:56,380
and i call this vector o p

433
00:32:56,410 --> 00:32:58,680
i call that no vector are

434
00:32:58,690 --> 00:33:03,570
and i give you this up in the next scene which indicates changing with time

435
00:33:03,630 --> 00:33:05,280
i call this location

436
00:33:05,300 --> 00:33:07,660
they'll why i'm going to call that

437
00:33:07,700 --> 00:33:09,200
why of t

438
00:33:09,350 --> 00:33:10,700
changing with time

439
00:33:10,760 --> 00:33:12,460
i call these acts of t

440
00:33:12,460 --> 00:33:14,100
it's going to change with time

441
00:33:14,110 --> 00:33:16,720
and i call this point zero

442
00:33:16,750 --> 00:33:21,420
which is going to change with time because point he's going to move

443
00:33:21,460 --> 00:33:24,020
so i'm going to write down

444
00:33:24,030 --> 00:33:25,470
the factor are

445
00:33:25,620 --> 00:33:31,110
its most general form that i can do that are which changes with time

446
00:33:31,180 --> 00:33:32,870
is no x of t

447
00:33:32,950 --> 00:33:36,960
which is the same as a of x there before

448
00:33:37,020 --> 00:33:39,210
times x roof

449
00:33:40,460 --> 00:33:43,250
why of t

450
00:33:43,290 --> 00:33:44,960
why rules

451
00:33:44,960 --> 00:33:46,490
because the of key

452
00:33:48,180 --> 00:33:50,500
i've decompose decomposed my vector are

453
00:33:50,520 --> 00:33:51,850
in two three

454
00:33:51,880 --> 00:33:53,550
independent vectors

455
00:33:53,610 --> 00:33:55,150
it's one of those

456
00:33:55,240 --> 00:33:57,400
interest time

457
00:33:57,430 --> 00:33:59,950
one is the velocity of the particle

458
00:33:59,960 --> 00:34:01,450
well the velocity

459
00:34:01,460 --> 00:34:04,350
it's the first derivative

460
00:34:04,410 --> 00:34:06,280
of the position

461
00:34:06,340 --> 00:34:08,440
so that is the are

462
00:34:09,220 --> 00:34:11,500
but every

463
00:34:11,540 --> 00:34:13,560
the first derivative of this one

464
00:34:13,630 --> 00:34:15,290
which is the ex

465
00:34:16,880 --> 00:34:18,130
x rules

466
00:34:18,180 --> 00:34:20,570
i'm going to write for the xt

467
00:34:20,680 --> 00:34:23,610
x not because i'm lazy

468
00:34:23,650 --> 00:34:26,760
and i'm going to write for the two activity square

469
00:34:26,790 --> 00:34:32,870
x double it's often done but not in your book notation and i'll often use

470
00:34:32,880 --> 00:34:36,040
because i see equations look so clumsy

471
00:34:37,840 --> 00:34:39,150
white dots

472
00:34:39,170 --> 00:34:40,750
times y rules

473
00:34:40,810 --> 00:34:42,640
plus the dot

474
00:34:42,680 --> 00:34:46,700
time zero would be that is these EDT

475
00:34:46,760 --> 00:34:49,630
what is the acceleration as a function of time

476
00:34:49,630 --> 00:34:52,740
well the acceleration as a function of time

477
00:34:55,320 --> 00:34:57,960
so it is the second derivative of

478
00:34:57,990 --> 00:34:59,460
x versus time

479
00:34:59,490 --> 00:35:01,250
and so that becomes

480
00:35:01,290 --> 00:35:02,800
x got

481
00:35:02,810 --> 00:35:04,960
times x rule

482
00:35:04,970 --> 00:35:06,690
that's why don't dot

483
00:35:06,750 --> 00:35:07,780
why rule

484
00:35:07,840 --> 00:35:10,730
let's see double dog

485
00:35:14,400 --> 00:35:15,200
and look

486
00:35:15,210 --> 00:35:16,460
what we have now

487
00:35:16,460 --> 00:35:20,830
so there two phase one when the points get together and form clusters and the

488
00:35:20,830 --> 00:35:22,890
second phase one

489
00:35:22,930 --> 00:35:27,500
the point i really already clusters and very compact so compactly so and the cluster

490
00:35:27,500 --> 00:35:29,840
centers that to start moving to get

491
00:35:29,860 --> 00:35:32,060
and eventually they'll collapse in one

492
00:35:32,080 --> 00:35:34,820
and you want to find

493
00:35:34,840 --> 00:35:37,990
and the first phase but you don't want to go to the to the end

494
00:35:37,990 --> 00:35:40,270
of the second place

495
00:35:40,290 --> 00:35:44,010
because anyone see any clustering

496
00:35:44,090 --> 00:35:50,950
so to do that

497
00:35:51,410 --> 00:35:54,590
there is that is the a trickle

498
00:35:56,840 --> 00:35:59,310
it's intuitively well justified

499
00:35:59,320 --> 00:36:02,820
and it follows one way to start

500
00:36:02,890 --> 00:36:03,880
is two

501
00:36:03,910 --> 00:36:07,020
stop when the point move to watch

502
00:36:07,030 --> 00:36:09,020
i don't have any more

503
00:36:09,040 --> 00:36:15,140
and sometimes if you choose your and so this is the change from one step

504
00:36:15,320 --> 00:36:18,690
how much has the point of one point being shifted

505
00:36:18,710 --> 00:36:20,980
that you

506
00:36:22,020 --> 00:36:27,260
and so i stand stopping criteria would be the next

507
00:36:28,840 --> 00:36:33,700
shift divide that shift is more than some tolerance

508
00:36:34,490 --> 00:36:36,440
but that's not enough because

509
00:36:38,480 --> 00:36:42,450
it's largely because the clusters already moving together so every point is more that just

510
00:36:42,450 --> 00:36:43,790
don't moving

511
00:36:43,800 --> 00:36:45,940
two at each other they are moving

512
00:36:45,950 --> 00:36:47,630
together in the same direction

513
00:36:47,960 --> 00:36:52,020
and in that case is credited with what work so

514
00:36:52,060 --> 00:36:55,050
but also another rule that also

515
00:36:55,090 --> 00:36:57,260
which is

516
00:36:57,310 --> 00:37:00,190
when the entropy in the histogram doesn't change

517
00:37:00,210 --> 00:37:03,240
and i have to explain what and in the histogram

518
00:37:03,360 --> 00:37:06,790
i hope you know what the histogram but essentially

519
00:37:06,810 --> 00:37:11,850
so these are the points will be

520
00:37:11,860 --> 00:37:13,990
the density would be like this

521
00:37:17,060 --> 00:37:18,810
clusters here

522
00:37:18,820 --> 00:37:21,680
plot here

523
00:37:21,680 --> 00:37:23,820
and the clusters

524
00:37:30,340 --> 00:37:34,500
and the next step the clusters together so

525
00:37:34,560 --> 00:37:39,440
this with this much discussed this much and this is much

526
00:37:39,450 --> 00:37:41,790
this is much

527
00:37:41,870 --> 00:37:45,360
so if you look at the average movement of every point you're going to see

528
00:37:45,360 --> 00:37:48,650
that it's very large because everybody moved

529
00:37:49,000 --> 00:37:51,620
however because

530
00:37:51,780 --> 00:37:55,440
however if you look at the distribution of the powers

531
00:38:01,250 --> 00:38:03,860
you are the same for all the points

532
00:38:03,860 --> 00:38:08,010
and the same for all the points you see here and here is the change

533
00:38:08,010 --> 00:38:10,690
in the point is only for about this

534
00:38:10,750 --> 00:38:12,840
no matter how many points

535
00:38:12,880 --> 00:38:13,400
you can

536
00:38:13,410 --> 00:38:17,740
so o point there for this thing

537
00:38:17,800 --> 00:38:22,010
and it could have millions and millions points

538
00:38:22,310 --> 00:38:28,700
also if you move the cluster together after one step it was still have exactly

539
00:38:28,700 --> 00:38:33,190
four distinct so the number of distinct values of this e

540
00:38:33,210 --> 00:38:35,770
doesn't change

541
00:38:35,830 --> 00:38:41,210
and this is what this criterion express the entropy is

542
00:38:41,350 --> 00:38:43,360
talk about entropy

543
00:38:45,400 --> 00:38:49,880
and the only thing that is this weekend

544
00:38:49,960 --> 00:38:51,450
so when there

545
00:38:51,650 --> 00:38:54,980
o thing that doesn't change much from one iteration to another then it means that

546
00:38:55,000 --> 00:38:55,690
the average to

547
00:38:56,080 --> 00:38:59,220
clustering and you can stop

548
00:39:02,560 --> 00:39:07,000
so this rule is that they are going to

549
00:39:09,390 --> 00:39:14,650
so this is a very strange so this would be q here

550
00:39:14,660 --> 00:39:17,240
i don't know what

551
00:39:17,300 --> 00:39:19,440
so it

552
00:39:19,440 --> 00:39:23,410
this is what it what's meant by cubic convergence

553
00:39:25,240 --> 00:39:30,170
this was one of

554
00:39:31,530 --> 00:39:38,500
OK so this is the mean shift the

555
00:39:38,740 --> 00:39:43,900
the gaussian blurring mean shift that goes in is because you're using a gaussian curve

556
00:39:43,940 --> 00:39:46,720
which seems to be better because it's smarter

557
00:39:46,830 --> 00:39:52,120
and the learning because it means that only the task called learning

558
00:39:52,140 --> 00:39:57,020
there's not much so this is one of these ideas which are not yet analyzed

559
00:39:57,020 --> 00:40:02,450
well but probably will be because they seem to be interesting

560
00:40:28,000 --> 00:40:31,190
there was

561
00:40:31,200 --> 00:40:36,870
so what about the first

562
00:40:50,650 --> 00:40:54,420
so yeah i mean if this is a better algorithm than the previous one

563
00:40:54,430 --> 00:40:56,730
it is

564
00:40:56,760 --> 00:41:04,630
OK so i mean it is better than the other means

565
00:41:04,630 --> 00:41:08,310
the idea is that the meaning of logical connectives

566
00:41:08,390 --> 00:41:11,390
is just its role

567
00:41:11,400 --> 00:41:13,230
that plays

568
00:41:14,060 --> 00:41:15,380
a proof system

569
00:41:15,440 --> 00:41:20,320
so it's the rules that governed by the introduction of elimination rules in the natural

570
00:41:20,320 --> 00:41:22,830
deduction system missing a few minutes

571
00:41:22,880 --> 00:41:25,860
determine the meaning of the connector

572
00:41:25,870 --> 00:41:30,560
tells you what it means and this goes back to the work of the person

573
00:41:30,560 --> 00:41:32,740
who invented but natural deduction

574
00:41:35,000 --> 00:41:38,710
sequent calculus carried against

575
00:41:38,740 --> 00:41:44,980
and he talked about it and in philosophy came in the nineteen fifties

576
00:41:44,990 --> 00:41:49,910
it with the work of ludwig wittgenstein and you might be the philosophers saying and

577
00:41:49,910 --> 00:41:54,230
they can start his idea that the meaning of any concept

578
00:41:54,310 --> 00:41:55,860
is determined

579
00:41:55,900 --> 00:41:58,440
by how it's used

580
00:41:58,450 --> 00:42:01,310
and that's a very similar notion that use

581
00:42:01,380 --> 00:42:04,410
the connected here in the proof system

582
00:42:04,420 --> 00:42:11,990
determines what it means how we're supposed to understand so

583
00:42:13,650 --> 00:42:20,260
that between proof and it's proof theory and semantics as you proof from one side

584
00:42:20,270 --> 00:42:24,530
semantics and the other is a little bit artificial or little question they

585
00:42:24,610 --> 00:42:27,590
from philosophical point of view because

586
00:42:27,610 --> 00:42:31,590
you might think of the meanings in proof theoretic terms and

587
00:42:31,600 --> 00:42:34,100
although i'm not entirely convinced

588
00:42:34,110 --> 00:42:37,340
and old model theorist from way back

589
00:42:37,350 --> 00:42:41,120
i think that that

590
00:42:41,130 --> 00:42:47,930
direction needs to be taught in courses in university in because we tried to adopt

591
00:42:48,030 --> 00:42:51,870
everybody in model theory and then later on students read all this stuff proof theoretic

592
00:42:51,870 --> 00:42:55,420
siemens i can no one ever told me about because we doing all this proof

593
00:42:55,420 --> 00:42:58,860
theory you could have told me that that was could have been treated as the

594
00:42:58,870 --> 00:43:00,720
theory meaning

595
00:43:00,740 --> 00:43:05,860
OK now we're going to look at what that means because in different proof systems

596
00:43:06,100 --> 00:43:10,870
you get very different answers about the meaning of connectives

597
00:43:10,880 --> 00:43:14,620
and that's really weird and some of them just coming to

598
00:43:14,660 --> 00:43:18,840
i understand fully now people been telling me this for ages

599
00:43:21,420 --> 00:43:25,630
but that's one thing listening to people tell you that you know you and actually

600
00:43:25,630 --> 00:43:27,370
working through it and saying

601
00:43:27,890 --> 00:43:33,390
know this is really strange this isn't quite what i mentioned

602
00:43:33,970 --> 00:43:38,020
and we're going to see that OK

603
00:43:38,080 --> 00:43:40,110
now in the star

604
00:43:40,120 --> 00:43:42,010
with the more formal stuff

605
00:43:42,070 --> 00:43:46,490
it's not going to get hugely falcon because i'm right at the end of this

606
00:43:46,530 --> 00:43:48,680
i'm not going to do

607
00:43:48,850 --> 00:43:50,750
perhaps as much technical stuff

608
00:43:50,760 --> 00:43:54,380
as i thought it might do some i mean this this

609
00:43:54,530 --> 00:43:55,850
equivalence proof

610
00:43:57,080 --> 00:44:02,210
the fitch style in the sequent style systems i'm going

611
00:44:02,230 --> 00:44:05,550
sketch that prevent fourier it's a fun proof

612
00:44:05,610 --> 00:44:10,920
i love this equivalence for different proof there was to them with my students it

613
00:44:10,920 --> 00:44:17,240
comes from being model theorists actually has been transferred transplanted into proof theory because moral

614
00:44:17,240 --> 00:44:21,250
theories the first thing we do is completeness there is a complete list

615
00:44:21,270 --> 00:44:26,280
and call even as here's the post doc back in the late eighties

616
00:44:29,370 --> 00:44:33,530
he started his approval serious and you still have things that have been mapped structure

617
00:44:33,530 --> 00:44:37,910
any structures and to each other today in the because he got one structure

618
00:44:37,930 --> 00:44:41,950
which is a perfectly good you know one you have proof theory prove things about

619
00:44:41,950 --> 00:44:45,590
that forget about all this model here is that we have to build another structure

620
00:44:45,590 --> 00:44:48,550
and show that they are effectively the same right

621
00:44:48,610 --> 00:44:51,370
isn't that selling well i don't think so it's fun

622
00:44:52,510 --> 00:44:56,410
that's what i do for these structures into each other so they are effectively the

623
00:44:56,410 --> 00:44:59,470
same and feel better about things but

624
00:44:59,510 --> 00:45:01,760
this the reason why we do that right

625
00:45:01,980 --> 00:45:05,800
between model theory and proof theory is a very good reason why we do that

626
00:45:05,800 --> 00:45:07,630
we have

627
00:45:07,660 --> 00:45:13,500
certain proof theoretic intuitions about what sort of inferences are valid and we have

628
00:45:13,510 --> 00:45:15,450
and what sort of formulas of

629
00:45:15,470 --> 00:45:18,370
and we have a certain

630
00:45:18,390 --> 00:45:20,890
model theoretic intuitions about

631
00:45:20,950 --> 00:45:23,210
a theory of truth for that

632
00:45:23,250 --> 00:45:26,200
and we want those intuitions to match

633
00:45:26,210 --> 00:45:30,290
that's why we have to prove that they give us the same results

634
00:45:30,350 --> 00:45:33,000
because if they don't then we got to say which one do we have to

635
00:45:33,000 --> 00:45:34,220
give up

636
00:45:34,260 --> 00:45:36,750
in which intuitions do we have to amanda

637
00:45:36,750 --> 00:45:39,210
and that's i think it is

638
00:45:39,230 --> 00:45:42,040
the heart of what

639
00:45:42,050 --> 00:45:44,520
these completeness proofs are really about

640
00:45:44,580 --> 00:45:48,540
i mean there are also about that is that there are these from you know

641
00:45:48,540 --> 00:45:53,150
this is a philosopher talking about philosophy lecture so

642
00:45:53,160 --> 00:45:57,880
that's what i that's wrecked come from

643
00:45:57,930 --> 00:46:02,080
right the so that's what we're philosopher looks for a mathematician might say well look

644
00:46:02,370 --> 00:46:05,300
right when moral logic here's the nice thing

645
00:46:05,360 --> 00:46:07,470
you have these weird model logics

646
00:46:07,480 --> 00:46:13,600
people didn't understand cricket came along in the possible world semantics all certain model logic

647
00:46:13,620 --> 00:46:16,300
it begins to look like

648
00:46:16,370 --> 00:46:19,750
theory of binary relations we know about that

649
00:46:19,800 --> 00:46:23,670
right is also huge amount of mathematics about that and then we can go on

650
00:46:23,670 --> 00:46:26,150
and study this

651
00:46:26,210 --> 00:46:29,780
intensional logic we can study using an extension of language

652
00:46:29,790 --> 00:46:30,760
set theory

653
00:46:30,820 --> 00:46:32,710
and very relations

654
00:46:34,750 --> 00:46:36,260
even before that

655
00:46:36,280 --> 00:46:42,010
tarski showed that the logic s four in effect was the logic of

656
00:46:43,610 --> 00:46:49,040
topological logical open sets that also sells well here's the theory we know about

657
00:46:49,100 --> 00:46:53,210
open sets state apology for a long time because of their we don't know about

658
00:46:53,220 --> 00:46:54,130
so now

659
00:46:54,130 --> 00:46:55,930
we found that there are very much

660
00:46:55,950 --> 00:47:00,760
the same theory we can transfer results we know about one to the other

661
00:47:00,850 --> 00:47:04,590
and that's that's mathematically really important

662
00:47:06,710 --> 00:47:11,500
so philosophically mathematically is completely stands are good idea but anyway let's get away from

663
00:47:11,500 --> 00:47:13,290
the back

664
00:47:13,300 --> 00:47:15,090
OK so now we know

665
00:47:16,250 --> 00:47:21,060
so we want to non-classical logics all

666
00:47:21,220 --> 00:47:26,620
we've got classical logic that's one system or released a class of systems of natural

667
00:47:26,620 --> 00:47:31,380
deduction system hilbert style axiom system again a sequent calculus

668
00:47:31,390 --> 00:47:35,630
that are all related in the sense that they'll give you the same results really

669
00:47:36,290 --> 00:47:41,430
in the give the same valid formulas in the same valid inferences kind

670
00:47:41,430 --> 00:47:44,150
gradient methods

671
00:47:44,170 --> 00:47:50,020
these methods are also used the second derivative it's the derivative of the derivative so

672
00:47:50,020 --> 00:47:52,980
the gradient of the gradient

673
00:47:53,000 --> 00:47:57,960
and what that gives you is it's a measure of the curvature of the function

674
00:47:59,380 --> 00:48:03,300
in rough terms if you have a direct method

675
00:48:03,310 --> 00:48:07,150
you have to sample your function in many places and then you just try to

676
00:48:07,150 --> 00:48:09,680
move towards the samples that look better

677
00:48:10,660 --> 00:48:14,480
and that's for instance what evolutionary algorithms to

678
00:48:14,530 --> 00:48:18,020
as many many other methods simplex

679
00:48:18,040 --> 00:48:21,770
method and other methods that do this

680
00:48:22,780 --> 00:48:28,200
i should say the nelder mead simplex method right there's two simplex

681
00:48:28,210 --> 00:48:30,610
if you have gradient information

682
00:48:30,620 --> 00:48:35,380
you can actually look at a single point and know which direction is downhill and

683
00:48:35,420 --> 00:48:39,790
multi dimensions the gradient actually tells you the direction in which

684
00:48:39,840 --> 00:48:43,030
is you have the steepest slope downhill

685
00:48:43,080 --> 00:48:46,080
OK it gives you the steepest descent direction

686
00:48:46,100 --> 00:48:47,740
so that's very useful

687
00:48:47,760 --> 00:48:50,660
if you have a second order gradient information

688
00:48:50,680 --> 00:48:55,250
it not only tells you which direction is downhill but it also tells you the

689
00:48:55,250 --> 00:48:58,250
curvature of the function in that direction

690
00:48:58,300 --> 00:49:01,720
which tells you how far step you should be taking

691
00:49:02,500 --> 00:49:06,650
because if there's a high curvature and you take a step in the downward direction

692
00:49:06,650 --> 00:49:08,310
but you're going too far

693
00:49:08,360 --> 00:49:12,660
then you overshooting the minimum and you land on the opposite slope

694
00:49:12,710 --> 00:49:16,780
if you're not going far enough will well obviously you could take the biggest

695
00:49:16,790 --> 00:49:21,080
so the second order methods have the big advantage that they tell you also how

696
00:49:21,080 --> 00:49:23,160
far to go

697
00:49:23,170 --> 00:49:27,360
the first order gradient methods only tell you which direction to go in

698
00:49:27,450 --> 00:49:31,920
and the step size that you pick is then something that's very i talk that

699
00:49:31,920 --> 00:49:33,990
you have to worry about it

700
00:49:37,070 --> 00:49:46,720
we have all these possibilities so why hasn't anybody come up and sort of decided

701
00:49:46,720 --> 00:49:50,970
OK this is the best optimisation method period and we don't worry about the other

702
00:49:50,970 --> 00:49:52,540
ones anymore

703
00:49:53,010 --> 00:49:55,040
that is because

704
00:49:55,120 --> 00:49:59,760
it's sort of like different kinds of car that they're very cheap simple cars and

705
00:49:59,760 --> 00:50:02,520
they're very fancy expensive cars

706
00:50:03,750 --> 00:50:06,280
the direct method

707
00:50:06,330 --> 00:50:11,970
make no assumption about your function it doesn't have to be moved differentiable or anything

708
00:50:12,010 --> 00:50:14,710
right they always work

709
00:50:14,720 --> 00:50:18,900
that makes them very easy to use and that's one of the reasons why evolutionary

710
00:50:18,900 --> 00:50:21,270
algorithms for instance are so popular

711
00:50:21,310 --> 00:50:25,060
you don't need to know anything about what you are optimizing

712
00:50:25,110 --> 00:50:28,010
and you know you can just

713
00:50:28,060 --> 00:50:33,190
goal plug it into your like function into your code to minimize

714
00:50:34,670 --> 00:50:36,940
they're very very inefficient

715
00:50:36,960 --> 00:50:41,150
because they have no information about which direction is downhill

716
00:50:41,860 --> 00:50:45,140
the only way you can make progress is by sort of random

717
00:50:45,160 --> 00:50:50,450
mutations in recombination so you need a lot of cycles to to optimize the function

718
00:50:51,640 --> 00:50:56,890
nature does it hate a works works great but nature has had no five billion

719
00:50:57,660 --> 00:51:02,070
to do its job and so if you can wait that long

720
00:51:02,080 --> 00:51:06,720
and you know something about your function for instance that it's differentiable

721
00:51:06,730 --> 00:51:10,340
then you can get a huge speedups by actually

722
00:51:10,380 --> 00:51:13,290
giving you optimize the gradient information

723
00:51:13,400 --> 00:51:16,230
letting it work more efficiently

724
00:51:19,320 --> 00:51:23,980
we can express that in in order notation right something that computer scientists like to

725
00:51:23,980 --> 00:51:26,480
do i familiar with that we go

726
00:51:29,360 --> 00:51:31,220
who isn't

727
00:51:31,230 --> 00:51:32,290
somebody OK

728
00:51:32,300 --> 00:51:35,390
briefly explain if i say something

729
00:51:35,440 --> 00:51:36,950
it takes

730
00:51:36,960 --> 00:51:39,360
order and

731
00:51:39,370 --> 00:51:41,740
time to compute

732
00:51:41,750 --> 00:51:43,150
what i mean

733
00:51:43,170 --> 00:51:45,410
is there exists

734
00:51:45,430 --> 00:51:47,100
a finite

735
00:51:47,110 --> 00:51:49,160
constant k

736
00:51:49,170 --> 00:51:53,420
such that the actual time taken is k times and

737
00:51:54,730 --> 00:51:56,800
some other constant actually

738
00:51:58,570 --> 00:52:03,260
this is basically saying in roughly takes and time

739
00:52:03,280 --> 00:52:08,920
the actual time could be like any factor times and plus and the constant

740
00:52:08,930 --> 00:52:14,450
because obviously these factors and this constant they all depend on the implementation right you

741
00:52:14,450 --> 00:52:18,970
you might be right more efficient code you may have compiled code or or something

742
00:52:19,860 --> 00:52:23,010
but the important thing is that

743
00:52:23,030 --> 00:52:28,750
if two algorithms differ in the order of time or memory that they require

744
00:52:28,760 --> 00:52:33,820
then this will override any of these constants for large enough problems so if i

745
00:52:33,820 --> 00:52:39,120
have two algorithms and one is order and in one is ordained squared

746
00:52:39,130 --> 00:52:44,690
then you can see that no matter what k and c are since they finite

747
00:52:44,690 --> 00:52:45,920
this is this is

748
00:52:45,980 --> 00:52:47,060
typical search

749
00:52:48,400 --> 00:52:53,370
and if it just a game theoretic and i'm not going to present all the

750
00:52:53,370 --> 00:52:55,230
area such

751
00:52:55,290 --> 00:52:57,690
there are two approaches

752
00:52:58,330 --> 00:53:01,020
first approach is what we're going to do it

753
00:53:01,710 --> 00:53:05,580
we are going to divide our information to plant

754
00:53:05,600 --> 00:53:06,630
it's like

755
00:53:06,670 --> 00:53:10,480
correct classifications so we we have our key

756
00:53:10,480 --> 00:53:12,480
invest saying OK

757
00:53:12,480 --> 00:53:18,880
this he said that only the log to follow structural now come to part of

758
00:53:19,040 --> 00:53:20,750
this coarsely

759
00:53:20,770 --> 00:53:23,350
this is that the current branch and bound

760
00:53:23,420 --> 00:53:24,880
a lot of structure

761
00:53:24,920 --> 00:53:27,770
beginning from ordinary

762
00:53:27,770 --> 00:53:28,980
sorted array

763
00:53:29,000 --> 00:53:32,100
and ending to very complicated three

764
00:53:32,110 --> 00:53:34,500
another way is to my

765
00:53:34,500 --> 00:53:38,380
map the most important example of web cache

766
00:53:38,400 --> 00:53:42,770
the idea that we have to keep in this thing this is the address

767
00:53:42,830 --> 00:53:47,270
we can use this key directly to get information

768
00:53:49,150 --> 00:53:50,440
there is only two

769
00:53:50,440 --> 00:53:53,580
processes such that i know

770
00:53:53,630 --> 00:53:59,540
and the first the most simple ones structure sort iterates what sort the right

771
00:53:59,560 --> 00:54:00,710
this simply

772
00:54:00,750 --> 00:54:03,060
got all this work

773
00:54:03,080 --> 00:54:06,270
and for them sorted into a

774
00:54:06,940 --> 00:54:09,880
how they can judge this structure

775
00:54:10,520 --> 00:54:13,210
this structure is

776
00:54:15,500 --> 00:54:16,730
local garrisons

777
00:54:20,460 --> 00:54:22,750
you know what is binary search

778
00:54:22,750 --> 00:54:26,080
i think that everybody knows one and here we are trying to figure out in

779
00:54:26,110 --> 00:54:27,380
the middle

780
00:54:27,400 --> 00:54:30,150
if we are in the middle is more

781
00:54:30,170 --> 00:54:32,420
the OWL t then we

782
00:54:32,420 --> 00:54:35,270
then trying his upper part of the

783
00:54:35,290 --> 00:54:39,170
sorry if we less than their

784
00:54:39,210 --> 00:54:40,310
trying to

785
00:54:42,500 --> 00:54:45,100
the bottom part of this of this array

786
00:54:45,130 --> 00:54:49,920
and repeating this request olivia reduce it to one element so we

787
00:54:49,920 --> 00:54:52,730
i always believed this array

788
00:54:52,750 --> 00:54:54,790
what we have from this story

789
00:54:54,810 --> 00:54:58,210
by by by the current approach

790
00:54:58,250 --> 00:55:02,480
with the exception not so good because i

791
00:55:02,500 --> 00:55:06,170
i didn't support here that the first we need to do church

792
00:55:06,190 --> 00:55:11,350
because we usually always before insertion into the selection model in the most of this

793
00:55:12,900 --> 00:55:17,940
but the problem is that we need to move

794
00:55:17,980 --> 00:55:20,520
on average half of the story

795
00:55:21,940 --> 00:55:27,540
to create new slot which you can forward this information

796
00:55:29,040 --> 00:55:32,100
what are the advantages of this sort

797
00:55:32,110 --> 00:55:35,040
the advantages is that

798
00:55:35,100 --> 00:55:36,440
it's pretty complex

799
00:55:36,500 --> 00:55:41,770
we don't have any pointers or anything else that we don't need to have your

800
00:55:41,770 --> 00:55:47,600
data simply we have your about order data

801
00:55:47,600 --> 00:55:54,000
and what the disadvantage is that it's not good for

802
00:55:54,040 --> 00:55:57,460
from this point of view it it could be a very good structure for some

803
00:55:57,460 --> 00:55:58,850
fixed array

804
00:55:58,850 --> 00:56:00,710
something that is

805
00:56:00,710 --> 00:56:04,770
we have static information

806
00:56:04,830 --> 00:56:09,630
but it's not so good for dictionary definitions for outdoor search engine

807
00:56:11,060 --> 00:56:14,650
every assertion then it will be future dictionary

808
00:56:14,670 --> 00:56:15,980
going to

809
00:56:15,980 --> 00:56:19,170
half of his career somewhere

810
00:56:19,190 --> 00:56:23,330
and removal of memory so we definitely

811
00:56:23,330 --> 00:56:24,710
it doesn't feed

812
00:56:24,710 --> 00:56:26,040
in two thousand four

813
00:56:26,060 --> 00:56:27,400
CPU cache

814
00:56:27,420 --> 00:56:30,920
and have all these problems and its laws

815
00:56:30,960 --> 00:56:34,520
but first i think the show it's OK

816
00:56:41,440 --> 00:56:50,190
but for social cause because it is not very good locality here because are

817
00:56:50,210 --> 00:56:53,330
the film chicken always in the middle then

818
00:56:55,210 --> 00:56:58,980
the next step is not good for fish

819
00:56:59,000 --> 00:57:03,670
it is about what good for search that are always

820
00:57:03,670 --> 00:57:07,580
if that have been talking about CPU what is good that there are always

821
00:57:07,670 --> 00:57:11,330
actually at least in the beginning the chicken the same element

822
00:57:11,330 --> 00:57:14,750
and in in the middle elements in the quarter and so on

823
00:57:14,750 --> 00:57:16,850
and therefore

824
00:57:16,870 --> 00:57:21,900
lows of performance based on not like alex

825
00:57:21,980 --> 00:57:24,480
what started to is not so bad

826
00:57:24,520 --> 00:57:27,400
so it's is

827
00:57:27,420 --> 00:57:30,790
it's not so but structure people used to

828
00:57:30,810 --> 00:57:32,540
to think about it

829
00:57:32,560 --> 00:57:38,480
if you see plus plus programming by the way other than a plus plus programming

830
00:57:40,900 --> 00:57:43,380
java programmer

831
00:57:43,400 --> 00:57:44,810
i think the

832
00:57:44,880 --> 00:57:47,130
OK i think that

833
00:57:47,130 --> 00:57:53,060
you already have have a solution and you have named standard template library

834
00:57:53,110 --> 00:57:54,630
you have

835
00:57:54,670 --> 00:57:58,000
the same structure in java libraries

836
00:57:59,400 --> 00:58:00,630
usually it

837
00:58:00,670 --> 00:58:02,380
binary tree

838
00:58:02,560 --> 00:58:06,980
the idea of binary tree if you're looking for something to happen

839
00:58:07,000 --> 00:58:09,540
two point from every now

840
00:58:09,580 --> 00:58:11,080
one point

841
00:58:11,130 --> 00:58:12,790
is still

842
00:58:12,810 --> 00:58:16,210
bigger and all other pointers to small or not

843
00:58:16,230 --> 00:58:21,420
and when we had to at this thing our current northern with result moving

844
00:58:21,440 --> 00:58:24,500
right and left

845
00:58:24,540 --> 00:58:28,480
so it's good structure because force

846
00:58:28,540 --> 00:58:30,270
we need only

847
00:58:30,290 --> 00:58:33,400
on average lottery some of

848
00:58:33,480 --> 00:58:39,900
size for dictionary because the y every iteration divided by we divide by two

849
00:58:39,940 --> 00:58:45,460
four this institution actually is if it is only search

850
00:58:45,460 --> 00:58:46,520
when we

851
00:58:46,560 --> 00:58:53,100
church history and the search is unsuccessful and we want to add the already have

852
00:58:53,130 --> 00:58:54,040
and it only two

853
00:58:54,060 --> 00:58:56,290
an additional point

854
00:58:57,580 --> 00:59:00,730
of course if you are encouraged right

855
00:59:00,750 --> 00:59:04,000
i was a month ago and i was implemented one right

856
00:59:04,060 --> 00:59:05,980
project and they're needed

857
00:59:05,980 --> 00:59:11,790
some simple fast structure the church using map from

858
00:59:12,580 --> 00:59:17,170
structure from the point of view it's pretty reliable and it's a in all libraries

859
00:59:17,170 --> 00:59:18,830
and implementation

860
00:59:18,850 --> 00:59:22,170
another very good properties of this

861
00:59:22,230 --> 00:59:25,230
structure that you can

862
00:59:25,230 --> 00:59:31,020
iterate over it and get over it again in alphabetical order that is important for

863
00:59:31,080 --> 00:59:34,750
you think of index that are going to discuss tomorrow

864
00:59:37,350 --> 00:59:40,250
on almost all four four

865
00:59:40,250 --> 00:59:41,690
english language

866
00:59:41,710 --> 00:59:44,040
the average length of world

867
00:59:44,130 --> 00:59:45,440
why why

868
00:59:45,850 --> 00:59:52,190
and imagine that using out of date thirty two bit compute so we are using

869
00:59:52,190 --> 00:59:54,270
the writing to point

870
00:59:54,270 --> 00:59:56,330
two every word

871
00:59:56,380 --> 00:59:58,100
every point is

872
00:59:58,100 --> 01:00:00,610
how many bytes

873
01:00:00,630 --> 01:00:01,810
four right

874
01:00:01,810 --> 01:00:04,520
so for the world wide web

875
01:00:04,520 --> 01:00:08,330
you are eighty a white point more than that

876
01:00:08,330 --> 01:00:11,920
but again

877
01:00:12,440 --> 01:00:17,170
so like for maybe four

878
01:00:17,810 --> 01:00:21,690
but they tend be tells us

879
01:00:21,750 --> 01:00:28,350
the idea eventually running for space is very rare

880
01:00:28,440 --> 01:00:34,960
go to i know what's the probability go higher than log n

881
01:00:34,980 --> 01:00:39,730
the easy one competition

882
01:00:39,790 --> 01:00:43,420
this time have fifty percent probability going up

883
01:00:43,440 --> 01:00:46,440
one and the probability of going up log levels

884
01:00:46,500 --> 01:00:50,090
because i have to the power law again is one out of n

885
01:00:51,830 --> 01:00:53,110
it depends on them

886
01:00:53,110 --> 01:00:55,270
but i'm not going to get too high

887
01:00:55,330 --> 01:00:57,500
and intuitively this is

888
01:00:57,520 --> 01:00:59,080
you know not so bad

889
01:00:59,110 --> 01:01:03,610
so these are skip lists

890
01:01:03,670 --> 01:01:11,580
you know you have the ratios right in expectation

891
01:01:11,590 --> 01:01:15,710
pretty weak statement doesn't say anything about the length of these chains

892
01:01:15,710 --> 01:01:17,290
but intuitively

893
01:01:18,350 --> 01:01:19,810
it's pretty good

894
01:01:19,960 --> 01:01:25,690
that's a pretty good on average

895
01:01:25,710 --> 01:01:29,860
so i had to process into semi random processes going on here one is taking

896
01:01:29,860 --> 01:01:33,400
the numbers and that i don't want to assume anything about the numbers could be

897
01:01:33,400 --> 01:01:38,690
adversarially could be sequential could be reversed or it could be random i don't know

898
01:01:38,730 --> 01:01:40,420
so the matter what he said

899
01:01:40,420 --> 01:01:42,360
it shouldn't matter

900
01:01:42,460 --> 01:01:44,690
i mean it matters here don't

901
01:01:44,790 --> 01:01:47,190
still undecided twenty five cents

902
01:01:47,230 --> 01:01:51,540
have the what the argument cares about is the outcomes of these coins and the

903
01:01:51,540 --> 01:01:53,710
probability the statement this

904
01:01:53,710 --> 01:01:57,670
this data structure fast with high probability is only about the random quotes it doesn't

905
01:01:57,670 --> 01:01:59,940
matter what the adversary chooses for numbers

906
01:01:59,980 --> 01:02:03,540
as long as those claims are random and the adversary doesn't know the courts

907
01:02:03,560 --> 01:02:05,900
there's no the outcomes of the courts

908
01:02:05,920 --> 01:02:07,310
so in that case

909
01:02:07,330 --> 01:02:11,150
on average over all of the coin flips should be OK

910
01:02:11,190 --> 01:02:12,360
but the

911
01:02:12,450 --> 01:02:14,210
the claim

912
01:02:14,210 --> 01:02:20,290
it's not just that is pretty good average but it's really really good

913
01:02:20,350 --> 01:02:22,130
almost always

914
01:02:22,190 --> 01:02:29,350
it was really i probability

915
01:02:30,040 --> 01:02:33,380
it's log

916
01:02:33,400 --> 01:02:35,270
so for example with probability

917
01:02:35,270 --> 01:02:37,330
one minus one or and

918
01:02:37,360 --> 01:02:43,360
it's waterlogged with probability one minus one over and square it's probably one minus one

919
01:02:43,360 --> 01:02:46,230
over and so hundred it's sort of like

920
01:02:46,230 --> 01:02:50,060
all almost statements structure for any value of one hundred

921
01:02:53,060 --> 01:02:56,710
that's where we're going

922
01:02:56,810 --> 01:02:59,400
OK i should mention the lead to the how do you do we in a

923
01:02:59,400 --> 01:03:00,500
skip list

924
01:03:00,520 --> 01:03:03,880
finally element delete it all the way

925
01:03:04,020 --> 01:03:06,980
that's the way it is nothing fancy with we

926
01:03:07,000 --> 01:03:11,000
because we have all these independent random choices all these elements are sort of independent

927
01:03:11,000 --> 01:03:12,750
from each other we don't really care

928
01:03:14,230 --> 01:03:16,710
delete i want to throw away

929
01:03:16,770 --> 01:03:18,130
the tricky part is insertion

930
01:03:18,130 --> 01:03:21,860
when i insert an element and is going to randomly see how it should go

931
01:03:21,940 --> 01:03:26,330
probability one to the i'll go to high i

932
01:03:27,880 --> 01:03:29,790
right time

933
01:03:29,810 --> 01:03:34,310
and having too much fun here

934
01:03:34,380 --> 01:03:36,770
the girl in the faster

935
01:03:48,500 --> 01:03:55,040
so here's the theorem see exactly what we're programming first

936
01:03:55,110 --> 01:03:57,940
with high probability

937
01:03:59,310 --> 01:04:00,980
former national

938
01:04:01,130 --> 01:04:03,500
i will find in the second

939
01:04:03,500 --> 01:04:10,940
the second sample OK is another entire observation of my graph that many observations

940
01:04:10,940 --> 01:04:16,830
these stations assume that we observe the power all the virus in the graph

941
01:04:16,850 --> 01:04:23,940
so how do you do maximum likelihood estimation here

942
01:04:24,730 --> 01:04:29,960
we can do some guesses here so here's what guess

943
01:04:30,000 --> 01:04:32,920
one guess is that the maximum likelihood estimation

944
01:04:32,980 --> 01:04:36,390
estimate for

945
01:04:38,350 --> 01:04:41,170
variables x one x two and x three

946
01:04:41,230 --> 01:04:45,690
will be the empirical observations four x one x two

947
01:04:45,750 --> 01:04:51,920
and empirical observations for extreme next three divided by the empirical observation for so these

948
01:04:51,920 --> 01:04:54,020
are the peak of marginal

949
01:04:54,020 --> 01:04:56,830
observations so this is the doctor

950
01:04:56,850 --> 01:05:02,410
so this is the distribution one like this is the real doctor doctor i'm collecting

951
01:05:02,500 --> 01:05:04,290
so this the marginal

952
01:05:04,330 --> 01:05:07,710
doctor for one and two and the marginal distribution of words

953
01:05:07,810 --> 01:05:12,520
in the extreme

954
01:05:12,540 --> 01:05:18,040
although don't know that just making because gasoline for the guess is correct

955
01:05:18,190 --> 01:05:26,270
so that you can see that these problem to potential these potential is on the

956
01:05:26,890 --> 01:05:32,750
or you could put could put has been nominated for example the

957
01:05:33,520 --> 01:05:36,460
we can verify that these guess is a good guess

958
01:05:37,210 --> 01:05:41,600
because if you marginalize over x three

959
01:05:41,650 --> 01:05:43,020
what do you get here

960
01:05:43,020 --> 01:05:45,250
you get the marginal thanks to

961
01:05:45,330 --> 01:05:47,080
divided by

962
01:05:47,080 --> 01:05:48,420
the marginal fixture

963
01:05:49,710 --> 01:05:51,230
which is here

964
01:05:51,290 --> 01:05:53,850
if you marginalize this quantity

965
01:05:53,870 --> 01:05:58,710
with respect to x these

966
01:05:59,710 --> 01:06:03,000
to marginalize this quantity here with respect to x three

967
01:06:03,000 --> 01:06:03,940
you get

968
01:06:04,770 --> 01:06:08,120
max likelihood of x two and three which is this

969
01:06:08,210 --> 01:06:11,460
now we use when you sum over x one

970
01:06:11,500 --> 01:06:12,750
you obtain

971
01:06:12,750 --> 01:06:13,940
the marginal

972
01:06:13,960 --> 01:06:18,170
distribution pfx divided by which

973
01:06:18,210 --> 01:06:20,910
these councils and then we obtain these

974
01:06:20,960 --> 01:06:28,020
in other words if we use these as the maximum likelihood estimate for those three

975
01:06:28,080 --> 01:06:33,520
then we will obtain maximum likelihood estimates for the particles in the clique that indeed

976
01:06:33,520 --> 01:06:34,480
are there

977
01:06:34,480 --> 01:06:36,650
the solutions we know should be correct

978
01:06:36,670 --> 01:06:39,270
because we know that the marginals in the cliques

979
01:06:39,350 --> 01:06:40,790
needs to meet

980
01:06:40,870 --> 01:06:42,790
the marginals in the

981
01:06:42,810 --> 01:06:47,980
the maximum likelihood estimate should be should be such that the marginals in the cliques

982
01:06:47,980 --> 01:06:55,770
match the empirical marginals in the clicks that's what this saying

983
01:06:55,830 --> 01:06:57,870
that's what it is

984
01:06:57,920 --> 01:06:58,910
he is

985
01:06:58,920 --> 01:07:00,350
so far

986
01:07:02,190 --> 01:07:06,370
the expected value of the sufficient statistics which is the average

987
01:07:06,390 --> 01:07:10,230
of the distribution should be equal to the mean of the empirical

988
01:07:16,850 --> 01:07:19,890
so it seems that this is a good guess and we'll see this in fact

989
01:07:19,910 --> 01:07:22,350
is the case

990
01:07:22,350 --> 01:07:23,790
how the real thing

991
01:07:23,790 --> 01:07:27,790
these marks large maximum likelihood estimates india

992
01:07:27,810 --> 01:07:30,100
for every maximal clique

993
01:07:30,100 --> 01:07:35,250
you set the clique potential to its empirical margin so for every click you observe

994
01:07:37,540 --> 01:07:40,460
every click you observe some data

995
01:07:40,520 --> 01:07:42,250
and then you set

996
01:07:42,270 --> 01:07:44,210
the distribution of that

997
01:07:46,310 --> 01:07:47,960
facial for that

998
01:07:49,480 --> 01:07:54,420
has basically been it's empiricalmodel it's not going to be the solution it's going to

999
01:07:54,420 --> 01:07:57,290
be the first approximation

1000
01:07:57,330 --> 01:08:01,150
then for every intersection between different cliques

1001
01:08:01,210 --> 01:08:06,690
you associate the empirical marginals with the intersection and divided

1002
01:08:06,690 --> 01:08:08,940
into the potential of one of the clicks

1003
01:08:08,940 --> 01:08:10,540
because you cannot count

1004
01:08:10,620 --> 01:08:12,580
that observation one

1005
01:08:12,580 --> 01:08:17,790
you just include the observation of intersection one of the cliques

1006
01:08:19,060 --> 01:08:24,410
these will give max like estimates for decomposable graphical models are young laid graphical models

1007
01:08:24,410 --> 01:08:29,140
are called the graphical models these are all seen

1008
01:08:29,190 --> 01:08:33,100
it seems very simple but that's exactly what you

1009
01:08:33,440 --> 01:08:38,890
if you have a full observation

1010
01:08:39,500 --> 01:08:43,500
this is just a theory for the composable graphs

1011
01:08:46,310 --> 01:08:48,310
but if you have no decomposable

1012
01:08:48,330 --> 01:08:50,890
in other words what have non chordal graphs

1013
01:08:50,940 --> 01:08:55,770
well of course one technique is to make it chordal and then using junction tree

1014
01:08:55,770 --> 01:08:59,100
and basically we can learn using the same procedure

1015
01:08:59,100 --> 01:09:02,770
if not you need to use an iterative procedure

1016
01:09:02,830 --> 01:09:04,690
which essentially is

1017
01:09:04,690 --> 01:09:05,790
trying to

1018
01:09:05,790 --> 01:09:08,420
make sure that the marginal

1019
01:09:10,640 --> 01:09:14,140
with respect to every click

1020
01:09:14,170 --> 01:09:21,460
so that they is confined in as well

1021
01:09:21,520 --> 01:09:23,580
here's the really important

1022
01:09:23,670 --> 01:09:28,190
i will that unless told me went to see

1023
01:09:28,190 --> 01:09:31,810
the yemen with who has heard of the world

1024
01:09:31,870 --> 01:09:33,460
OK quite a few people

1025
01:09:33,500 --> 01:09:37,640
so let's look at the algorithm in its full generality

1026
01:09:37,710 --> 01:09:40,710
EMI with

1027
01:09:40,730 --> 01:09:45,500
so we saw how we can obtain maximum likelihood estimates in the case where

1028
01:09:45,520 --> 01:09:46,690
he is

1029
01:09:46,710 --> 01:09:48,580
virus are all so

1030
01:09:48,620 --> 01:09:52,580
if you happen to get doctor that actually tells you

1031
01:09:52,620 --> 01:09:55,100
or you observe all the viable

1032
01:09:55,120 --> 01:09:56,290
a few more

1033
01:09:59,250 --> 01:10:01,420
but that may not be the case

1034
01:10:02,080 --> 01:10:06,830
you may have what we call it inviable which are variables that correspond to some

1035
01:10:06,830 --> 01:10:11,830
abstract concept that you don't really matter in reality

1036
01:10:11,870 --> 01:10:17,060
well sometimes you may have idable that do don't represent abstract concepts they

1037
01:10:17,100 --> 01:10:22,560
the really exist but you just don't have access to measurement of of the bible

1038
01:10:22,650 --> 01:10:25,670
so in many cases basically you don't observe

1039
01:10:25,710 --> 01:10:27,410
some by

1040
01:10:27,420 --> 01:10:31,350
which for example in this case we don't observe this virus

1041
01:10:31,370 --> 01:10:36,190
we only observe variables x one and x two

1042
01:10:36,250 --> 01:10:38,460
how do you do learning in this case

1043
01:10:41,670 --> 01:10:44,940
now it's the last sort of mathematics of the day

1044
01:10:45,020 --> 01:10:48,500
use the rest of energy you've got your brain

1045
01:10:48,500 --> 01:10:51,790
try to foreclose because it is really beautiful

1046
01:10:51,810 --> 01:10:55,620
and also tired but since the so beautiful i will

1047
01:10:55,650 --> 01:10:58,440
drive all my images to flickr

1048
01:11:00,730 --> 01:11:06,620
this is one of the most used algorithms in computer science very

1049
01:11:06,670 --> 01:11:07,640
thousands of

1050
01:11:07,770 --> 01:11:11,480
citations of the original paper proposes these thirty

1051
01:11:11,500 --> 01:11:13,540
two years ago

1052
01:11:14,060 --> 01:11:15,370
so let's

1053
01:11:15,420 --> 01:11:17,540
let's take look

1054
01:11:17,560 --> 01:11:19,210
the first thing we do let's

1055
01:11:19,940 --> 01:11:21,480
those whatever that we observe

1056
01:11:21,480 --> 01:11:23,600
let's call them text

1057
01:11:23,640 --> 01:11:25,480
and those five that don't observe

1058
01:11:25,500 --> 01:11:26,420
call them

1059
01:11:28,560 --> 01:11:30,920
assume if we knew z

1060
01:11:30,960 --> 01:11:33,330
let's assume for a moment if we knew said

1061
01:11:33,330 --> 01:11:35,140
assemble charges

1062
01:11:35,160 --> 01:11:38,000
i have to do work we discussed earlier

1063
01:11:38,000 --> 01:11:42,620
and we call that the electrostatic potential energy

1064
01:11:42,680 --> 01:11:44,290
today i will look at

1065
01:11:44,300 --> 01:11:47,100
the energy content in different ways

1066
01:11:47,110 --> 01:11:52,370
i will evaluate the energy in terms of the electric field

1067
01:11:52,380 --> 01:11:57,440
suppose i have two parallel plates

1068
01:11:57,490 --> 01:12:01,290
and i charge this from the positive charge

1069
01:12:01,370 --> 01:12:04,970
which is the surface charge density times the area of the

1070
01:12:04,990 --> 01:12:07,850
this one's negative charge

1071
01:12:07,880 --> 01:12:10,630
which is the surface charge density negative times

1072
01:12:10,640 --> 01:12:13,500
the area of play

1073
01:12:13,560 --> 01:12:17,630
let's assume that the separation between these two h

1074
01:12:17,680 --> 01:12:20,060
so we have an electric field

1075
01:12:20,070 --> 01:12:22,420
which is approximately constant

1076
01:12:22,480 --> 01:12:24,130
two years

1077
01:12:25,130 --> 01:12:27,920
divided by

1078
01:12:27,980 --> 01:12:28,860
and now

1079
01:12:28,880 --> 01:12:30,750
i'm going to take the upper plate

1080
01:12:31,060 --> 01:12:33,170
the movement of

1081
01:12:33,240 --> 01:12:35,820
so as i do that

1082
01:12:35,840 --> 01:12:37,720
i have to apply for

1083
01:12:37,880 --> 01:12:39,970
with these two plates attract each other

1084
01:12:40,020 --> 01:12:42,220
so i have to do work

1085
01:12:42,270 --> 01:12:44,470
and as i move these up

1086
01:12:44,490 --> 01:12:45,710
i will move it up

1087
01:12:45,720 --> 01:12:47,920
of distance act

1088
01:12:47,940 --> 01:12:52,910
i am creating year electric field that wasn't there before

1089
01:12:52,910 --> 01:12:55,330
an electric field that i'm creating

1090
01:12:55,390 --> 01:12:57,470
has exactly the same strength

1091
01:12:57,520 --> 01:12:58,860
as this

1092
01:12:58,860 --> 01:13:02,390
because the charge on the plate is not changing when i'm moving

1093
01:13:02,440 --> 01:13:05,050
the surface charge density is not changing

1094
01:13:05,100 --> 01:13:07,710
all i do is i increase the distance

1095
01:13:07,720 --> 01:13:11,140
and so i am creating electrocute

1096
01:13:11,140 --> 01:13:12,920
in here

1097
01:13:12,940 --> 01:13:17,280
and for that i have to do work that's another way of looking at it

1098
01:13:17,330 --> 01:13:19,310
how much work so i have to do

1099
01:13:19,360 --> 01:13:20,830
what is the work

1100
01:13:20,950 --> 01:13:22,890
i want to do it has to do

1101
01:13:22,890 --> 01:13:25,690
a moving display over the distance act

1102
01:13:25,690 --> 01:13:28,500
well that is the force that i have to apply

1103
01:13:28,500 --> 01:13:30,560
over that distance x

1104
01:13:30,580 --> 01:13:32,390
the force is constant

1105
01:13:32,440 --> 01:13:34,220
so i can simply multiply

1106
01:13:34,270 --> 01:13:37,640
the force times the distance that will give work

1107
01:13:37,690 --> 01:13:39,490
so the question now is

1108
01:13:39,500 --> 01:13:41,620
one is the force that i have to apply

1109
01:13:41,640 --> 01:13:44,020
to move this plate up

1110
01:13:44,070 --> 01:13:46,550
and your first guess would be

1111
01:13:46,680 --> 01:13:47,670
the fourth

1112
01:13:47,740 --> 01:13:48,590
it would be

1113
01:13:48,610 --> 01:13:50,140
the chart on the plate

1114
01:13:50,150 --> 01:13:54,990
and the electric field strength completely reasonable guess because you would argue

1115
01:13:54,990 --> 01:13:58,140
well if we have an electric field e and we bring a charge q in

1116
01:13:58,150 --> 01:14:02,610
there than the electric forces q times e i have to overcome the force so

1117
01:14:02,610 --> 01:14:04,820
my forces q times e

1118
01:14:04,890 --> 01:14:06,830
yes that holds most of the time

1119
01:14:06,950 --> 01:14:10,230
but not in this case so little a bit more so

1120
01:14:10,240 --> 01:14:12,320
let me take this plate here

1121
01:14:12,490 --> 01:14:14,740
a large that played

1122
01:14:14,790 --> 01:14:18,110
so here's the plates so you see the thickness of the plate now

1123
01:14:18,110 --> 01:14:20,290
this is one place

1124
01:14:20,330 --> 01:14:23,080
we all agree that the press charges

1125
01:14:23,080 --> 01:14:23,710
at the

1126
01:14:23,740 --> 01:14:27,740
surface well but of course it has to be in the plate

1127
01:14:27,800 --> 01:14:31,960
and so on is here his layer of charge q

1128
01:14:32,020 --> 01:14:35,420
because at the bottom of the plate and the thinkers of that player may only

1129
01:14:35,420 --> 01:14:39,170
be one atomic thickness but it's not zero

1130
01:14:39,180 --> 01:14:40,510
and on this site

1131
01:14:40,550 --> 01:14:43,080
of the plates is that electric field

1132
01:14:43,120 --> 01:14:45,830
which is a modified by actually non-zero

1133
01:14:45,870 --> 01:14:50,370
but inside the plate which is a conductor the electric field is zero

1134
01:14:50,390 --> 01:14:51,520
and therefore

1135
01:14:51,520 --> 01:14:54,770
the electric field

1136
01:14:54,770 --> 01:14:58,610
it is in this charge q is the average between the two

1137
01:14:58,670 --> 01:15:00,740
and so the force on this chart

1138
01:15:00,740 --> 01:15:01,550
in this

1139
01:15:01,550 --> 01:15:05,670
there is not a few times e but is one half

1140
01:15:05,740 --> 01:15:10,180
two times so i take the average between these fields and this e

1141
01:15:10,200 --> 01:15:12,170
field is then this value

1142
01:15:12,230 --> 01:15:14,080
so now i can calculate

1143
01:15:14,120 --> 01:15:17,240
the work that i have to do

1144
01:15:17,290 --> 01:15:19,210
the work that i have to do

1145
01:15:19,210 --> 01:15:21,210
is not my force

1146
01:15:21,300 --> 01:15:22,870
which is one half

1147
01:15:24,210 --> 01:15:25,360
i in

1148
01:15:25,420 --> 01:15:27,450
and i move that over

1149
01:15:27,460 --> 01:15:30,320
the distance x

1150
01:15:30,330 --> 01:15:32,040
so what i can do no

1151
01:15:32,920 --> 01:15:34,900
replace q by

1152
01:15:34,950 --> 01:15:36,580
sigma a b

1153
01:15:36,620 --> 01:15:38,480
so i get one half

1154
01:15:38,490 --> 01:15:40,580
sigma h

1155
01:15:40,620 --> 01:15:42,460
times e

1156
01:15:42,550 --> 01:15:44,230
the exact

1157
01:15:44,240 --> 01:15:47,680
and i multiply upstairs and downstairs

1158
01:15:47,710 --> 01:15:49,210
i absolutely zero

1159
01:15:49,210 --> 01:15:51,040
multiplied by one

1160
01:15:51,100 --> 01:15:52,910
the reason why i do that is

1161
01:15:52,930 --> 01:15:56,870
because then i get another sigma divided by actually non-zero here

1162
01:15:56,910 --> 01:15:59,620
by the way films zero one that is e

1163
01:15:59,630 --> 01:16:00,770
and therefore

1164
01:16:00,780 --> 01:16:04,440
i now have the total work that i will tell you would have to do

1165
01:16:04,440 --> 01:16:06,340
has to do is one half

1166
01:16:06,390 --> 01:16:07,720
actually non-zero

1167
01:16:07,990 --> 01:16:09,890
the square

1168
01:16:09,950 --> 01:16:11,190
times a

1169
01:16:11,230 --> 01:16:12,530
i'm x

1170
01:16:12,580 --> 01:16:14,210
and look at this

1171
01:16:14,210 --> 01:16:16,270
if x is the normal volume

1172
01:16:16,420 --> 01:16:22,460
i have created it is the new volume in which i have created electric field

1173
01:16:22,470 --> 01:16:25,020
and this now

1174
01:16:25,080 --> 01:16:28,950
call for a

1175
01:16:31,500 --> 01:16:33,470
then by walter lewis

1176
01:16:33,500 --> 01:16:36,340
per unit volume

1177
01:16:36,350 --> 01:16:37,890
and that now

1178
01:16:37,950 --> 01:16:39,820
equals one half

1179
01:16:39,910 --> 01:16:41,410
actually non-zero

1180
01:16:42,560 --> 01:16:44,410
the square

1181
01:16:44,430 --> 01:16:45,710
this is the word

1182
01:16:45,710 --> 01:16:46,830
but i have done

1183
01:16:46,840 --> 01:16:48,020
per unit

1184
01:16:48,030 --> 01:16:50,080
volume and since this work

1185
01:16:50,090 --> 01:16:52,140
created electric fields

1186
01:16:52,200 --> 01:16:53,820
we call fields

1187
01:16:53,830 --> 01:16:55,780
energy density

1188
01:16:55,830 --> 01:16:57,330
and it is in jail

1189
01:16:57,390 --> 01:17:00,660
per cubic metre

1190
01:17:00,680 --> 01:17:03,560
and it can be shown that in general

1191
01:17:03,570 --> 01:17:06,060
the electric field energy density

1192
01:17:06,070 --> 01:17:08,830
is one half actually non-zero in squared

1193
01:17:08,850 --> 01:17:15,010
not only for this particular charge configuration with for any charge configuration

1194
01:17:15,020 --> 01:17:17,560
so now we have a new way of looking

1195
01:17:17,580 --> 01:17:21,150
at the energy that it takes to assemble charges

1196
01:17:21,200 --> 01:17:24,040
earlier we calculated the work that we have to do

1197
01:17:24,070 --> 01:17:26,140
to put the charges in place

1198
01:17:26,200 --> 01:17:28,310
now if it is more convenient

1199
01:17:28,320 --> 01:17:31,330
we could calculate that the energy

1200
01:17:31,330 --> 01:17:33,970
electrostatic potential energy

1201
01:17:34,020 --> 01:17:35,480
is the integral

1202
01:17:35,500 --> 01:17:36,950
of one half

1203
01:17:36,970 --> 01:17:39,340
absolute non-zero square

1204
01:17:39,350 --> 01:17:41,600
over all space

1205
01:17:41,620 --> 01:17:45,470
if necessary you have to go all the way down to infinity

1206
01:17:45,520 --> 01:17:46,720
and i have now

1207
01:17:48,010 --> 01:17:49,970
this is volume

1208
01:17:50,020 --> 01:17:54,180
it has nothing to do with potential between physical often run out of symbols

1209
01:17:54,220 --> 01:17:56,900
these sometimes potential in this case

1210
01:17:56,950 --> 01:17:58,730
it is volume

1211
01:17:58,780 --> 01:18:01,470
and the only reason why i chose eight there

1212
01:18:01,500 --> 01:18:05,090
yes i really have d year so i didn't want to do normally we take

1213
01:18:05,090 --> 01:18:07,480
the separation between the plates

1214
01:18:07,520 --> 01:18:08,850
and so this now

1215
01:18:08,900 --> 01:18:10,880
is another way of looking

1216
01:18:10,890 --> 01:18:13,470
at electrostatic potential energy

1217
01:18:13,570 --> 01:18:16,030
we look at it now only from the point of view of all the energy

1218
01:18:16,030 --> 01:18:18,230
being in the electric field

1219
01:18:18,280 --> 01:18:21,580
and we no longer think of it perhaps as the work that you have done

1220
01:18:21,590 --> 01:18:22,710
to assemble

1221
01:18:25,480 --> 01:18:27,470
i will demonstrate later today

1222
01:18:27,480 --> 01:18:29,140
that as a separate

1223
01:18:29,140 --> 01:18:30,440
the two plates

1224
01:18:30,450 --> 01:18:31,640
from these

1225
01:18:32,790 --> 01:18:36,130
planes that indeed i have to do work i will convince you

1226
01:18:36,180 --> 01:18:40,480
by creating an electric field that indeed i will be doing

1227
01:18:42,470 --> 01:18:43,790
so from our own

1228
01:18:44,000 --> 01:18:45,570
we have the choice

1229
01:18:45,580 --> 01:18:47,850
if you want to calculate multi

1230
01:18:47,910 --> 01:18:50,530
electrostatic potential energy

1231
01:18:50,540 --> 01:18:51,290
three years

1232
01:18:51,290 --> 01:18:56,680
my name is quantity that is the binding energy which depends on the

1233
01:18:56,710 --> 01:19:02,070
so first ever bounces then you want these mass of the nucleus lower than the

1234
01:19:02,070 --> 01:19:08,380
mass of the constituent so you want to have binding energy positive training energy

1235
01:19:08,440 --> 01:19:14,970
so in our age you have this binding energy which is close to eight immediately

1236
01:19:15,010 --> 01:19:18,610
so this is an average because more carefully if you look at that

1237
01:19:18,640 --> 01:19:22,650
so you have binding energy per nucleon depending on the mass number

1238
01:19:22,670 --> 01:19:24,560
so you have here

1239
01:19:24,750 --> 01:19:29,830
the term six very nine two i ran fifty six maximum

1240
01:19:29,860 --> 01:19:34,670
and then many points to uranium two hundred thirty eight and have

1241
01:19:34,720 --> 01:19:37,410
so here you have a me

1242
01:19:37,440 --> 01:19:41,750
but you see that you have an increased and then increase

1243
01:19:41,750 --> 01:19:43,560
and this is very important

1244
01:19:43,570 --> 01:19:49,540
pictures because from that you can understand many things concerning energy prediction concerning

1245
01:19:49,560 --> 01:19:51,410
a new search for

1246
01:19:51,430 --> 01:19:53,610
nuclear so

1247
01:19:53,630 --> 01:19:58,370
can you tell me from these care which nuclei could fission spontaneously

1248
01:19:59,160 --> 01:20:02,010
can you gain energy from these nuclei

1249
01:20:02,020 --> 01:20:07,330
in fact just consider the negative binding energy so minus the quantities of from zero

1250
01:20:07,640 --> 01:20:10,560
to so it is here you just minus

1251
01:20:10,570 --> 01:20:12,270
the previous slides

1252
01:20:12,270 --> 01:20:13,830
you have here

1253
01:20:14,400 --> 01:20:17,750
the most stable nuclei which is ironic

1254
01:20:17,790 --> 01:20:22,130
so if you wanted to efficient means that you have this if you do that

1255
01:20:22,130 --> 01:20:23,790
breaks into fragments

1256
01:20:23,840 --> 01:20:27,160
so if you want to gain energy you have

1257
01:20:27,990 --> 01:20:30,500
you have to start from having

1258
01:20:30,520 --> 01:20:31,590
and then having

1259
01:20:31,800 --> 01:20:33,800
like fragments here

1260
01:20:33,810 --> 01:20:35,500
because it consider

1261
01:20:35,650 --> 01:20:37,900
when you is here

1262
01:20:38,050 --> 01:20:39,720
sorry one nucleus here

1263
01:20:39,760 --> 01:20:41,790
that will be

1264
01:20:41,960 --> 01:20:44,500
fission into fragments it will go here

1265
01:20:44,520 --> 01:20:46,270
so you will lose energy

1266
01:20:46,290 --> 01:20:47,580
so the only way

1267
01:20:47,600 --> 01:20:50,920
to gain in energy is to start from one nucleus

1268
01:20:50,960 --> 01:20:54,470
after that i run here heavier than higher and

1269
01:20:56,410 --> 01:20:59,830
and is contrary for fish and you have to start from

1270
01:20:59,840 --> 01:21:02,570
nuclei very well

1271
01:21:02,580 --> 01:21:03,830
a small nuclei

1272
01:21:03,840 --> 01:21:06,740
here to go up to irony

1273
01:21:06,750 --> 01:21:11,730
so that's why formula one grand they are looking at fission of uranium plutonium of

1274
01:21:12,820 --> 01:21:15,030
it's because you can gain energy

1275
01:21:15,050 --> 01:21:19,020
and for fusion is contrary for example you have this either which i can get

1276
01:21:19,800 --> 01:21:22,370
so it they want to have to have a vision of the tree in place

1277
01:21:23,210 --> 01:21:28,290
just to to study the physics so that's why they are looking at this

1278
01:21:28,390 --> 01:21:32,660
systems that

1279
01:21:32,680 --> 01:21:34,670
so more precisely

1280
01:21:35,870 --> 01:21:37,330
i was numbers

1281
01:21:37,340 --> 01:21:38,730
so fission

1282
01:21:38,800 --> 01:21:41,670
is one frank when you is a

1283
01:21:41,690 --> 01:21:44,180
and then you have two to fragments b and c

1284
01:21:44,190 --> 01:21:46,830
and you have these energy

1285
01:21:46,840 --> 01:21:51,000
so far the energy balance if you consider the mass of the proton equals the

1286
01:21:51,000 --> 01:21:53,550
mass of the neutron economy and

1287
01:21:53,550 --> 01:21:56,920
you have this equation so it's time some

1288
01:21:56,940 --> 01:22:00,310
of the neutrons minus the bending energy of a

1289
01:22:00,310 --> 01:22:04,070
i equals p times the mass of the neutron minus the binding energy

1290
01:22:04,120 --> 01:22:04,930
of the

1291
01:22:04,940 --> 01:22:06,580
the same for c and these

1292
01:22:06,660 --> 01:22:09,820
so far the energy difference you see

1293
01:22:09,840 --> 01:22:11,290
that you should have

1294
01:22:11,330 --> 01:22:16,550
b b b b c bigger than me if you want to get energy

1295
01:22:16,570 --> 01:22:18,330
the same for fusion

1296
01:22:18,350 --> 01:22:22,600
so that's why four if you want to have energy during the fission

1297
01:22:22,620 --> 01:22:26,750
you need to have a vision of elements heavier than i ran

1298
01:22:26,750 --> 01:22:31,330
and and for fusion for elements lower than i one

1299
01:22:31,350 --> 01:22:37,750
so on and other things that can be deduced from these here if the

1300
01:22:37,760 --> 01:22:41,250
abundance of elements on the earth

1301
01:22:41,260 --> 01:22:42,720
in the universe

1302
01:22:42,740 --> 01:22:44,610
you have here the binding energy

1303
01:22:44,640 --> 01:22:45,610
in blue

1304
01:22:45,660 --> 01:22:47,570
depending on the atomic numbers

1305
01:22:47,570 --> 01:22:51,760
so this is the maximum for irony and here in abandoned

1306
01:22:51,800 --> 01:22:56,580
the elements in the universe and you see here that you have peak for i

1307
01:22:56,600 --> 01:22:58,220
and that correspond to these

1308
01:22:58,230 --> 01:22:59,830
maximum of finding

1309
01:22:59,880 --> 01:23:04,580
so it means that i won't do not want to recreate particles do not want

1310
01:23:04,590 --> 01:23:08,040
to emit particles because it's very very stable nuclei

1311
01:23:08,040 --> 01:23:09,120
so that's why

1312
01:23:09,150 --> 01:23:10,890
everything converge to

1313
01:23:13,070 --> 01:23:16,960
so i run is the most stable and abundant nucleus

1314
01:23:16,970 --> 01:23:21,670
and in the limit between the burning by fusion as i explained before

1315
01:23:21,690 --> 01:23:27,040
and red if capture neutrons so you have higher and then you can capture many

1316
01:23:27,040 --> 01:23:30,860
many neutrons

1317
01:23:30,870 --> 01:23:34,500
so what about lifetime so we talk about stable nuclei

1318
01:23:34,510 --> 01:23:36,880
so what about radioactive nuclei

1319
01:23:36,910 --> 01:23:41,850
those stable nuclei means their lifetime is infinite so bigger than the lifetime of the

1320
01:23:41,850 --> 01:23:45,790
proton together the support thirty three years

1321
01:23:45,790 --> 01:23:48,570
so the other ones are unstable

1322
01:23:48,600 --> 01:23:52,560
it means that they can transform into more stable nuclei

1323
01:23:52,560 --> 01:23:55,320
so what you want to have their lifetime

1324
01:23:55,330 --> 01:23:59,600
so is the statistical definition you are here the number of nuclei in the same

1325
01:23:59,930 --> 01:24:02,110
depending on the time here t

1326
01:24:02,170 --> 01:24:06,250
and you have this exponential decay here in pink

1327
01:24:06,260 --> 01:24:09,010
so you find the lifetime here

1328
01:24:09,030 --> 01:24:12,270
because he has the time for which you have only

1329
01:24:12,310 --> 01:24:15,100
if you're nuclei in your

1330
01:24:15,120 --> 01:24:16,140
so it's

1331
01:24:16,150 --> 01:24:21,540
very commonly used definition for exponential decay

1332
01:24:23,350 --> 01:24:26,420
there are different types of radioactivity so

1333
01:24:26,470 --> 01:24:31,330
and you can involve an image different particles so the most common one are these

1334
01:24:31,340 --> 01:24:32,730
one so

1335
01:24:32,780 --> 01:24:36,580
this is your nucleus in your somebody home

1336
01:24:36,610 --> 01:24:39,560
with is the proton and neutron

1337
01:24:39,570 --> 01:24:42,920
ganymede one neutron so that it like here

1338
01:24:42,930 --> 01:24:45,070
or any one credit

1339
01:24:45,070 --> 01:24:48,920
so you start from the and you have the minus one n

1340
01:24:48,970 --> 01:24:51,850
alpha particle is also very very common

1341
01:24:51,880 --> 01:24:54,980
so you lose two proton to neutron

1342
01:24:54,990 --> 01:24:56,940
you have the time and is to j

1343
01:24:57,070 --> 01:25:00,620
right that plays the king of electron capture

1344
01:25:01,120 --> 01:25:07,100
a few years ago exotic to what i read your activity has been discovered so

1345
01:25:07,100 --> 01:25:11,070
it means that it's not sequential two proton but i just ten times two protons

1346
01:25:11,070 --> 01:25:11,820
have been

1347
01:25:12,880 --> 01:25:16,570
so it's quite unusual but it has been

1348
01:25:17,410 --> 01:25:20,570
so they are looking now at protons are

1349
01:25:20,890 --> 01:25:25,690
other exotic radioactivity

1350
01:25:25,750 --> 01:25:30,010
so these are some examples that they can in the literature so just to see

1351
01:25:30,010 --> 01:25:31,810
you that you have

1352
01:25:31,830 --> 01:25:37,240
a lot of details but also for the same here you can have a and

1353
01:25:37,240 --> 01:25:38,540
i j

1354
01:25:38,540 --> 01:25:39,820
and finally shown

1355
01:25:39,830 --> 01:25:41,440
electron capture

1356
01:25:42,390 --> 01:25:46,230
it means that you have many many processing competition so when you are looking at

1357
01:25:46,230 --> 01:25:50,080
one case you have to consider all the neighbours to be sure

1358
01:25:50,100 --> 01:25:51,320
that i

1359
01:25:51,330 --> 01:25:54,050
when you calculate the lifetime

1360
01:25:54,070 --> 01:25:57,640
so you can get to the ground state are you can get to the excited

1361
01:25:57,640 --> 01:26:00,600
states of the ground state is the lowest energy state

1362
01:26:00,600 --> 01:26:01,830
of course

1363
01:26:01,850 --> 01:26:03,460
in the direction of play

1364
01:26:03,480 --> 01:26:06,870
it propagates with the speed of light

1365
01:26:06,960 --> 01:26:08,810
but this pattern

1366
01:26:08,850 --> 01:26:12,160
move away faster than the speed of light

1367
01:26:12,160 --> 01:26:13,770
and it can actually

1368
01:26:13,790 --> 01:26:15,160
get completely

1369
01:26:15,160 --> 01:26:20,790
out of hand it can be very very large

1370
01:26:22,250 --> 01:26:23,960
these raids

1371
01:26:24,140 --> 01:26:27,710
travel in the x direction

1372
01:26:27,710 --> 01:26:30,890
that means the red line will be vertical

1373
01:26:30,890 --> 01:26:33,790
that means l y will go to infinity

1374
01:26:33,830 --> 01:26:36,870
it means that k of y goes to zero

1375
01:26:36,910 --> 01:26:41,160
it means that the phase velocity goes to infinity

1376
01:26:41,160 --> 01:26:43,870
this pattern and here the intersection here

1377
01:26:43,870 --> 01:26:45,100
well then

1378
01:26:45,100 --> 01:26:47,690
goal was to speak which is infinitely high

1379
01:26:47,710 --> 01:26:50,460
and there is no violation of einstein's

1380
01:26:51,640 --> 01:26:55,390
of special relativity because no energy will flow

1381
01:26:55,390 --> 01:26:57,190
with that speed

1382
01:26:57,250 --> 01:26:58,690
and i can best

1383
01:26:58,810 --> 01:27:00,310
to ensure that

1384
01:27:00,310 --> 01:27:03,040
by showing that something similar

1385
01:27:03,060 --> 01:27:06,460
can happen with water

1386
01:27:06,480 --> 01:27:11,310
suppose we view shoreline

1387
01:27:11,460 --> 01:27:13,710
and we have someone away

1388
01:27:13,730 --> 01:27:17,000
coming in like this

1389
01:27:17,020 --> 01:27:20,660
maybe i should put him in red sort you begin to make the connection

1390
01:27:20,680 --> 01:27:22,660
between the electromagnetic waves

1391
01:27:22,710 --> 01:27:25,770
and what so here is a wave

1392
01:27:25,810 --> 01:27:27,330
rolling in

1393
01:27:29,850 --> 01:27:31,480
is by definition

1394
01:27:31,520 --> 01:27:33,080
the wavelength lambda

1395
01:27:33,140 --> 01:27:34,750
and all of that move

1396
01:27:34,770 --> 01:27:37,580
with velocity v

1397
01:27:37,620 --> 01:27:39,190
but the intersection

1398
01:27:39,210 --> 01:27:42,040
of these two ways here point eight

1399
01:27:42,060 --> 01:27:43,690
and here point b

1400
01:27:43,690 --> 01:27:45,640
i call this distance

1401
01:27:45,660 --> 01:27:49,600
alpha x i could have called it a lot of just as i did here

1402
01:27:49,600 --> 01:27:51,290
it's the intersection

1403
01:27:51,310 --> 01:27:54,960
this axis that i gave a symbol of why i called it there

1404
01:27:55,620 --> 01:27:59,440
of x

1405
01:28:02,890 --> 01:28:06,910
the difference in arrival time

1406
01:28:07,000 --> 01:28:09,600
between wave

1407
01:28:09,600 --> 01:28:11,330
and we have to

1408
01:28:11,370 --> 01:28:13,790
the the difference in arrival time between

1409
01:28:13,810 --> 01:28:16,040
we one and wave two

1410
01:28:16,080 --> 01:28:17,500
at point b

1411
01:28:17,580 --> 01:28:19,540
is the period of the way

1412
01:28:19,620 --> 01:28:24,770
it is simply land divided by the trivial but that's not only the case for

1413
01:28:24,770 --> 01:28:25,890
point b

1414
01:28:25,940 --> 01:28:29,180
that is also the case for point

1415
01:28:29,230 --> 01:28:30,710
this way form

1416
01:28:30,750 --> 01:28:34,810
reaches eight before it reaches the before two

1417
01:28:34,870 --> 01:28:38,440
which is point eight and this is the time in between

1418
01:28:38,440 --> 01:28:39,870
the arrival time

1419
01:28:39,870 --> 01:28:41,250
of wave one

1420
01:28:41,250 --> 01:28:43,040
and we have two

1421
01:28:43,060 --> 01:28:46,250
which is a completely different question

1422
01:28:46,270 --> 01:28:51,190
from what is the difference in arrival time of wave one alone

1423
01:28:51,230 --> 01:28:53,640
at a and b

1424
01:28:53,710 --> 01:28:56,460
that's the difference in arrival time

1425
01:28:56,520 --> 01:28:59,600
between one wave between point a and b

1426
01:28:59,600 --> 01:29:01,680
depends on this angle theta

1427
01:29:01,690 --> 01:29:06,660
and one thing that goes to zero that difference in arrival time goes to zero

1428
01:29:06,660 --> 01:29:09,810
both a and b will at the same moment in time

1429
01:29:09,890 --> 01:29:12,520
see that way

1430
01:29:12,560 --> 01:29:16,020
so that means that in that case when theta is zero

1431
01:29:16,080 --> 01:29:19,410
this al x becomes infinitely large

1432
01:29:19,410 --> 01:29:24,310
and so if you expressed that in terms of the phase velocity in this direction

1433
01:29:24,310 --> 01:29:28,270
the phase velocity then becomes infinitely high

1434
01:29:28,310 --> 01:29:30,350
so it is this pattern

1435
01:29:30,370 --> 01:29:34,180
that moves with the velocity that can be way larger than c

1436
01:29:34,230 --> 01:29:38,960
but no one will move with that last it's very clear there is no water

1437
01:29:38,960 --> 01:29:41,440
going from here to there

1438
01:29:41,460 --> 01:29:44,500
so this is not a violation of einstein's theory

1439
01:29:44,540 --> 01:29:48,180
of special relativity

1440
01:29:48,250 --> 01:29:52,410
so several very dedicated students wrote me email

1441
01:29:52,480 --> 01:29:56,690
after last lecture they could not sleep

1442
01:29:56,790 --> 01:29:59,730
and i didn't even feel guilty

1443
01:29:59,790 --> 01:30:02,790
and the reason why they couldn't sleep is that

1444
01:30:02,850 --> 01:30:06,000
we had this wonderful demonstration

1445
01:30:06,020 --> 01:30:09,520
whereby i have you an aluminum plate

1446
01:30:09,580 --> 01:30:12,890
and not all in one place

1447
01:30:12,960 --> 01:30:15,890
and this was the seat of action

1448
01:30:15,890 --> 01:30:19,730
and the separation between the plates was a

1449
01:30:19,790 --> 01:30:22,100
and we had

1450
01:30:22,120 --> 01:30:24,060
electromagnetic radiation

1451
01:30:24,100 --> 01:30:26,250
going in that direction

1452
01:30:26,250 --> 01:30:28,230
and we concluded

1453
01:30:28,290 --> 01:30:30,540
i will not go over the reasoning again

1454
01:30:30,560 --> 01:30:32,160
that the phase velocity

1455
01:30:32,180 --> 01:30:34,140
in the same direction

1456
01:30:34,160 --> 01:30:35,980
it was omega

1457
01:30:36,040 --> 01:30:38,040
divided by k of c

1458
01:30:38,060 --> 01:30:40,330
and that was larger than c

1459
01:30:40,390 --> 01:30:42,790
that's why you guys couldn't sleep

1460
01:30:42,850 --> 01:30:44,270
and in fact

1461
01:30:44,330 --> 01:30:47,540
i even demonstrated that if you

1462
01:30:47,580 --> 01:30:49,350
make the radiation

1463
01:30:49,370 --> 01:30:51,460
the frequency close to cut off

1464
01:30:51,460 --> 01:30:53,310
in this course we discussed

1465
01:30:53,320 --> 01:30:56,600
linear polarization of electromagnetic radiation

1466
01:30:56,620 --> 01:30:59,780
and i demonstrate this at seventy five megahertz

1467
01:30:59,810 --> 01:31:01,710
and ten gigahertz

1468
01:31:01,730 --> 01:31:03,830
today i will concentrate

1469
01:31:05,490 --> 01:31:07,530
on the polarisation

1470
01:31:07,550 --> 01:31:08,740
of light

1471
01:31:08,760 --> 01:31:10,330
which is a much

1472
01:31:10,350 --> 01:31:12,010
higher frequency

1473
01:31:12,030 --> 01:31:14,960
the light from the sun light from light bulbs

1474
01:31:14,990 --> 01:31:16,420
is not polarized

1475
01:31:16,420 --> 01:31:18,780
so i can ask myself the question

1476
01:31:18,800 --> 01:31:22,170
what does it mean when light is not polarized

1477
01:31:22,180 --> 01:31:25,170
let's think of individual light photons

1478
01:31:25,210 --> 01:31:26,840
as plane waves

1479
01:31:26,850 --> 01:31:28,890
was well defined direction

1480
01:31:28,890 --> 01:31:30,920
of polarisation

1481
01:31:30,950 --> 01:31:33,090
so each one is

1482
01:31:33,100 --> 01:31:34,890
linearly polarized

1483
01:31:35,810 --> 01:31:38,020
it's coming straight out of the blackboards

1484
01:31:38,030 --> 01:31:39,850
the first photon arrives

1485
01:31:39,860 --> 01:31:42,750
it's really polarized these are actually

1486
01:31:42,810 --> 01:31:48,110
the second photon arrives linearly polarized in this direction thirty electric field vector is also

1487
01:31:48,110 --> 01:31:55,000
leading like that another photon another photon from another photon another photon

1488
01:31:55,070 --> 01:31:56,970
what you see here very clearly

1489
01:31:57,970 --> 01:31:59,220
that there is no

1490
01:31:59,240 --> 01:32:00,600
preferred direction

1491
01:32:00,610 --> 01:32:02,600
when you average over time

1492
01:32:02,610 --> 01:32:06,250
and that's what we call call unpolarized light

1493
01:32:06,270 --> 01:32:09,550
it was edwin land who in nineteen thirty eight

1494
01:32:09,610 --> 01:32:11,640
developed material

1495
01:32:11,660 --> 01:32:13,170
that can turn this

1496
01:32:13,190 --> 01:32:14,250
in two

1497
01:32:14,300 --> 01:32:15,970
linearly polarized

1498
01:32:16,000 --> 01:32:20,190
light for which he became very famous in addition to these demonstrations

1499
01:32:20,220 --> 01:32:22,640
that i showed you last time

1500
01:32:22,690 --> 01:32:24,960
if i take one of

1501
01:32:25,000 --> 01:32:26,910
edwin land sheets

1502
01:32:26,940 --> 01:32:31,520
which will turn light into a polarisation in this direction

1503
01:32:31,580 --> 01:32:33,390
and i first

1504
01:32:33,410 --> 01:32:34,940
take one photo

1505
01:32:34,990 --> 01:32:38,000
for instance this one

1506
01:32:38,020 --> 01:32:41,300
that one comes in from the blackboards towards you

1507
01:32:41,330 --> 01:32:43,210
and so here it is

1508
01:32:43,300 --> 01:32:45,810
oscillating in fact like this

1509
01:32:45,850 --> 01:32:48,490
he zero is the maximum

1510
01:32:48,500 --> 01:32:51,860
the value of the electric field strength in that plane

1511
01:32:51,910 --> 01:32:53,860
electromagnetic waves

1512
01:32:53,940 --> 01:32:56,950
and this is direction

1513
01:32:57,000 --> 01:32:58,480
of the polarizer

1514
01:32:58,500 --> 01:33:00,850
but i have to do with this photon

1515
01:33:02,310 --> 01:33:04,130
i can now

1516
01:33:04,130 --> 01:33:06,590
make it simple calculation

1517
01:33:06,630 --> 01:33:09,120
by projecting this vector

1518
01:33:09,190 --> 01:33:10,230
on two

1519
01:33:10,870 --> 01:33:15,440
preferred direction of polarization

1520
01:33:15,470 --> 01:33:17,540
and there no easy victory

1521
01:33:17,570 --> 01:33:20,570
is now down by the cosine of data that

1522
01:33:20,570 --> 01:33:22,760
this angle to say that

1523
01:33:22,780 --> 01:33:24,040
this is a vector

1524
01:33:24,060 --> 01:33:24,970
is now is

1525
01:33:24,970 --> 01:33:26,010
he zero

1526
01:33:26,030 --> 01:33:27,350
and the cosine

1527
01:33:27,410 --> 01:33:28,700
of data

1528
01:33:28,760 --> 01:33:30,350
if you ask we know

1529
01:33:30,350 --> 01:33:33,030
whether the light is reduced in intensity

1530
01:33:33,030 --> 01:33:35,230
i would have to say yes of course

1531
01:33:35,280 --> 01:33:38,190
because light intensity

1532
01:33:38,230 --> 01:33:40,250
depends on the poynting vector

1533
01:33:40,250 --> 01:33:42,760
the poynting vector is always proportional

1534
01:33:42,780 --> 01:33:44,900
two is zero square

1535
01:33:45,070 --> 01:33:47,630
because the poynting vector

1536
01:33:47,680 --> 01:33:50,480
is the cross product between e and b

1537
01:33:50,500 --> 01:33:51,630
and if the

1538
01:33:51,630 --> 01:33:55,190
is reduced b is also reduced

1539
01:33:55,250 --> 01:33:58,930
so we get the cosine square reduction

1540
01:33:59,000 --> 01:34:02,280
if no i averaged over all incoming photons

1541
01:34:02,280 --> 01:34:06,470
so i think all of these which represent an unpolarized beam

1542
01:34:06,480 --> 01:34:09,720
so i get not only one like so when i get one likes o and

1543
01:34:09,720 --> 01:34:13,410
one like so o one like so o one like so

1544
01:34:15,350 --> 01:34:17,440
i have to calculate now

1545
01:34:18,780 --> 01:34:22,480
i mean value of cosine square state

1546
01:34:22,500 --> 01:34:26,570
and the mean value of cosine square theatre is one half

1547
01:34:26,620 --> 01:34:31,160
and so if the intensity of the unpolarized beam

1548
01:34:31,200 --> 01:34:35,200
unpolarized light was originally i zero

1549
01:34:35,220 --> 01:34:39,930
ones that come through this polarizer that edwin land gave me

1550
01:34:40,780 --> 01:34:43,660
i get one half i zero

1551
01:34:43,700 --> 01:34:44,760
but that is now

1552
01:34:44,810 --> 01:34:46,280
on the percent

1553
01:34:46,370 --> 01:34:47,500
all right

1554
01:34:47,510 --> 01:34:49,530
and it is hundred percent polarized

1555
01:34:49,570 --> 01:34:51,570
in this direction

1556
01:34:51,630 --> 01:34:53,030
and one half

1557
01:34:53,040 --> 01:34:54,180
it is the result

1558
01:34:55,500 --> 01:34:59,100
the average value of cosine square

1559
01:34:59,100 --> 01:35:01,010
if this were the case

1560
01:35:01,030 --> 01:35:04,030
would be an extremely ideal polarization

1561
01:35:04,030 --> 01:35:08,120
probably be reasonably confident that you have the because the solution is here so you

1562
01:35:08,810 --> 01:35:12,230
know if you saw the you know where you got it right or not so

1563
01:35:12,230 --> 01:35:13,790
there's no reason to be

1564
01:35:13,820 --> 01:35:16,030
we were involved in the world

1565
01:35:16,040 --> 01:35:20,440
like your chance to lecture the machine learning summer school

1566
01:35:20,480 --> 01:35:26,250
so you have done this before we usually always had one or two where

1567
01:35:26,260 --> 01:35:27,640
compared to

1568
01:35:27,660 --> 01:35:29,500
anyone courageous

1569
01:35:29,510 --> 01:35:35,090
i raised about to high

1570
01:35:39,200 --> 01:35:42,970
OK so this one myself i think you just want to see mister from the

1571
01:35:42,970 --> 01:35:47,920
bible here other this one myself but in the next problem someone will have to

1572
01:35:47,920 --> 01:35:50,230
do it so see shock

1573
01:35:50,240 --> 01:35:53,190
must be true because of the mathematics department

1574
01:35:55,020 --> 01:36:02,710
actually this

1575
01:36:02,720 --> 01:36:06,570
one which is the song song problems here are there

1576
01:36:08,770 --> 01:36:17,210
OK so we said we have to cheque whether the point is

1577
01:36:17,220 --> 01:36:18,330
closer to home

1578
01:36:18,350 --> 01:36:22,980
the positive meaning of closer to the negative meaning

1579
01:36:23,010 --> 01:36:25,800
this is the rule

1580
01:36:28,600 --> 01:36:36,490
should be easy in this is where we should be checking whether

1581
01:36:36,510 --> 01:36:43,410
artists find is closer to the positive or the negative media and

1582
01:36:45,130 --> 01:36:49,840
this is the right

1583
01:36:58,090 --> 01:37:07,960
and i'm sure make mistakes we have put interesting they also get a point because

1584
01:37:07,960 --> 01:37:12,130
i'm not usually lecturing i'm just a researcher at the max planck institute so we

1585
01:37:12,130 --> 01:37:18,590
don't have to have indicated lecture at universities so let's see if this is right

1586
01:37:19,270 --> 01:37:21,520
if the distance to the

1587
01:37:21,540 --> 01:37:25,200
if it's closer to the positive point and the distance to the naked to closer

1588
01:37:25,210 --> 01:37:29,930
to the positive mean means the distance the negative means larger which is this is

1589
01:37:29,930 --> 01:37:33,340
positive we assign the point of the positive class that to be the right way

1590
01:37:34,730 --> 01:37:38,270
so this work is art

1591
01:37:38,280 --> 01:37:43,170
so here we use the dot product is just part

1592
01:38:00,430 --> 01:38:02,220
the same thing

1593
01:38:02,360 --> 01:38:13,540
very negative

1594
01:38:22,720 --> 01:38:26,380
and then we have

1595
01:38:26,410 --> 01:38:29,530
the same thing over here

1596
01:38:31,220 --> 01:38:33,260
only with plus instead of

1597
01:38:33,280 --> 01:38:38,030
so OK of first is

1598
01:38:38,040 --> 01:38:41,050
the product of five x with

1599
01:38:51,640 --> 01:38:57,280
all this square is from OK so you have one point really actually the second

1600
01:38:57,280 --> 01:39:01,260
stage what

1601
01:39:01,270 --> 01:39:03,780
but point

1602
01:39:03,800 --> 01:39:04,800
as you

1603
01:39:05,660 --> 01:39:08,190
the man with the green teachers

1604
01:39:14,810 --> 01:39:19,270
a lot of people in the

1605
01:39:19,320 --> 01:39:21,460
only birds you want

1606
01:39:27,750 --> 01:39:28,520
so this

1607
01:39:28,540 --> 01:39:32,920
with this we've got through the complicated ones to some

1608
01:39:35,880 --> 01:39:44,060
here we always have done

1609
01:39:44,120 --> 01:39:48,110
three five x five j so

1610
01:39:48,120 --> 01:39:51,170
this can be

1611
01:39:54,020 --> 01:39:56,440
OK so

1612
01:39:56,460 --> 01:39:59,990
i think it should be obvious if it's not obvious to you

1613
01:40:00,090 --> 01:40:02,000
but one can

1614
01:40:02,000 --> 01:40:06,570
take the sum of the product and how these two sons combined to the single

1615
01:40:06,570 --> 01:40:11,530
or to this summons on think about it after the election because that's something you

1616
01:40:11,530 --> 01:40:15,940
you can calculate what is there a conservation

1617
01:40:15,950 --> 01:40:20,740
what is also interesting for this network to classical network is the property of small

1618
01:40:20,760 --> 01:40:24,660
world which means that the distance between nodes

1619
01:40:24,700 --> 01:40:26,120
in this network

1620
01:40:26,130 --> 01:40:29,770
is proportional to log n where n is the number of nodes so you can

1621
01:40:29,770 --> 01:40:34,100
see even if n increases very much larger still

1622
01:40:34,130 --> 01:40:39,080
reduces dramatically and makes it small and this is why we called networks small world

1623
01:40:39,080 --> 01:40:44,280
called also small world and it's related to the six degrees of separation that we

1624
01:40:44,390 --> 01:40:45,620
between people

1625
01:40:45,640 --> 01:40:50,200
in this concept of very important social sciences

1626
01:40:50,260 --> 01:40:56,710
but it was found in nineteen ninety nine that many real networks was on and

1627
01:40:56,710 --> 01:41:00,760
they don't not obey these degree distribution but there are there

1628
01:41:00,770 --> 01:41:07,630
the vision for example one kind of information can be represented by scale free skate

1629
01:41:07,630 --> 01:41:08,650
that is

1630
01:41:08,660 --> 01:41:11,390
power law distribution catered to minus land

1631
01:41:11,450 --> 01:41:16,750
the power of the case much slower than explanation that's why you can also in

1632
01:41:16,750 --> 01:41:22,160
this politics which can have also high degree nodes like you know which is then

1633
01:41:22,450 --> 01:41:25,090
but you can have also even if the book is very large you can have

1634
01:41:25,090 --> 01:41:29,440
a hundred thousand and many many a

1635
01:41:29,450 --> 01:41:35,160
links per node and this the suggests by by version of the nineteen ninety nine

1636
01:41:35,230 --> 01:41:40,140
they also gave presented to model what is the difference between the two one of

1637
01:41:40,140 --> 01:41:44,960
the different is that the former genesis in these networks of genes which means you

1638
01:41:45,660 --> 01:41:50,680
you see have the symmetry that almost all see the same labelled here it's not

1639
01:41:50,680 --> 01:41:53,660
the same from the see only very few

1640
01:41:53,680 --> 01:41:59,530
the nodes some notes in very many so these two engineers in this breaks physics

1641
01:41:59,530 --> 01:42:05,910
and all if you is symmetry translational symmetry is same every node it's not the

1642
01:42:05,910 --> 01:42:08,650
same so presentation of symmetry breaks

1643
01:42:08,670 --> 01:42:15,710
changes universality class changes properties and many many properties found to be different for such

1644
01:42:16,020 --> 01:42:18,300
complex network which are not

1645
01:42:18,320 --> 01:42:20,740
o mcginnis and for example

1646
01:42:20,750 --> 01:42:24,350
instead of being a PC to be one of the key average for this type

1647
01:42:24,350 --> 01:42:27,850
of network in the range between two and three

1648
01:42:29,060 --> 01:42:34,730
is a actually between two and three which for many many networks find the PC

1649
01:42:34,730 --> 01:42:38,730
approach goes to zero which means that even if you have a very you remove

1650
01:42:38,730 --> 01:42:44,390
almost all the nodes in the network still communication exist which does not carry that

1651
01:42:44,390 --> 01:42:49,710
explains many phenomena which are not clear before and they and they for example

1652
01:42:50,760 --> 01:42:56,510
this is constraint on the on the internet for so long time also called

1653
01:42:56,520 --> 01:43:01,510
people by the virus and put it so it was against this silly but if

1654
01:43:01,710 --> 01:43:06,140
the standard is so different network and you know that this is the only means

1655
01:43:06,140 --> 01:43:13,020
that even almost people by the was still the viruses can spread in the network

1656
01:43:13,050 --> 01:43:18,510
another property which is important for this network the distance which was your login

1657
01:43:18,520 --> 01:43:24,880
small world become even smell another look appeals look so it means they showing the

1658
01:43:24,880 --> 01:43:27,660
distance by these type of network scale free networks

1659
01:43:27,670 --> 01:43:32,910
and the logo was proved analytically in this paper with london between two so we

1660
01:43:32,910 --> 01:43:37,060
call it will be a small world and this is a soapbox who wants to

1661
01:43:37,070 --> 01:43:42,390
understand many and so many of the problems to just to indicate to

1662
01:43:42,400 --> 01:43:46,490
the country the between what sort the distribution

1663
01:43:46,510 --> 01:43:50,400
and scale free you can imagine they were not bald

1664
01:43:50,460 --> 01:43:56,300
they did not go forward in the united states which typical number of faults going

1665
01:43:56,300 --> 01:44:02,390
out from one node and almost the same number of them and today which is

1666
01:44:02,390 --> 01:44:08,120
very different sometimes have many lines sometimes have very low and indeed it was found

1667
01:44:08,120 --> 01:44:13,350
by this opinion and if go the that apologies vision also be an exponent close

1668
01:44:13,350 --> 01:44:17,070
to two full airline network which i will discuss later

1669
01:44:17,100 --> 01:44:20,260
now i want to show you some

1670
01:44:20,430 --> 01:44:27,870
which reminds but important in the field in which the networks are important in different

1671
01:44:27,870 --> 01:44:32,650
fields for example the first give an example of something that was one of the

1672
01:44:32,650 --> 01:44:37,940
first examples but they found also that the internet walk is also part it's a

1673
01:44:37,940 --> 01:44:42,410
degree part of the degree distribution is power law which means

1674
01:44:42,420 --> 01:44:47,610
you can have also on the a a computers which are connected to many many

1675
01:44:47,610 --> 01:44:50,910
computers and this is a y

1676
01:44:50,920 --> 01:44:56,300
we are also interested in now the question is why network study is very important

1677
01:44:56,390 --> 01:45:00,900
and and i will show you for the scene in biology and medicine

1678
01:45:00,920 --> 01:45:02,640
in the end you may be seen

1679
01:45:02,650 --> 01:45:08,420
in the nineteen eighties was founded the gene p fifty three is a very important

1680
01:45:08,430 --> 01:45:11,940
is the tumour suppressor mutation in this gene

1681
01:45:11,970 --> 01:45:13,880
the resulting cancer but still

1682
01:45:13,890 --> 01:45:17,850
it did not so if we know even the gene you the problem we could

1683
01:45:17,850 --> 01:45:21,260
not solve the problem and the reason was given by this three people

1684
01:45:21,260 --> 01:45:27,370
later the live in extreme with discovered the pieces the and they say the following

1685
01:45:27,370 --> 01:45:32,170
one is to understand the p fifty three network which is just like the into

1686
01:45:32,890 --> 01:45:37,390
this not concept supporting is an american actor control the activity of large and on

1687
01:45:37,620 --> 01:45:42,110
a number of other body which means that if we understand the point in itself

1688
01:45:42,110 --> 01:45:45,510
we know which fourteen called the scans so it's not enough we need to understand

1689
01:45:45,510 --> 01:45:49,360
the network and this is one of the reasons one of the main reasons why

1690
01:45:49,410 --> 01:45:54,630
people are very interested to understand better the network of protein local or in biology

1691
01:45:54,630 --> 01:45:58,620
and i like fixing one junction in all we know is not enough to fix

1692
01:45:58,620 --> 01:46:00,120
the traffic in the world

1693
01:46:00,160 --> 01:46:04,460
and for example paper that appeared in ninety two thousand five and immediately another that

1694
01:46:04,890 --> 01:46:11,530
they studied the mapping of human protein interaction network and this was done in order

1695
01:46:11,530 --> 01:46:14,450
so for the

1696
01:46:14,650 --> 01:46:19,260
and you can show that this this is a is also totally unimodular

1697
01:46:22,090 --> 01:46:23,280
by the way

1698
01:46:23,340 --> 01:46:28,400
the problem of the non bipartite matchings of the assisting molecule matching

1699
01:46:28,400 --> 01:46:29,450
there is no

1700
01:46:29,470 --> 01:46:33,300
linear programming formulation it looks very similar we have notes

1701
01:46:33,300 --> 01:46:36,450
and i want to get matching bright and i want to say concerning the degree

1702
01:46:36,450 --> 01:46:40,240
to build you know you are equal to one less than one returns after that

1703
01:46:40,240 --> 01:46:43,400
problem non bipartite matchings

1704
01:46:43,510 --> 01:46:47,130
the number of constraints need to add to the linear programme for it to actually

1705
01:46:47,130 --> 01:46:52,050
give you an internal solution is is exponential or these there is no known polynomial

1706
01:46:53,180 --> 01:46:55,550
you know for the last forty years so

1707
01:46:57,880 --> 01:47:01,720
that problem we're going have to talk with some other method to

1708
01:47:01,740 --> 01:47:05,860
this this kind of the method applies only to write down LP and the number

1709
01:47:05,860 --> 01:47:08,400
of constraints LP and the variables in LP

1710
01:47:08,510 --> 01:47:10,570
it is polynomial

1711
01:47:10,570 --> 01:47:13,300
OK so

1712
01:47:13,340 --> 01:47:14,610
the other piece of

1713
01:47:15,470 --> 01:47:20,400
piece of technology we need is is this duality that in out in the context

1714
01:47:20,400 --> 01:47:21,380
of stems

1715
01:47:21,400 --> 01:47:24,070
if this is our lt

1716
01:47:24,700 --> 01:47:29,610
in the primal the door that looks very similar to swap c and b

1717
01:47:29,700 --> 01:47:31,450
transpose the a

1718
01:47:32,470 --> 01:47:36,050
and and

1719
01:47:36,050 --> 01:47:38,780
so this is a mapping

1720
01:47:38,840 --> 01:47:41,070
because of the science

1721
01:47:44,260 --> 01:47:47,090
we wrote all the inference problems like this

1722
01:47:47,130 --> 01:47:50,720
now we can actually use this guy which is so

1723
01:47:51,950 --> 01:47:53,430
this problem is

1724
01:47:56,990 --> 01:48:01,180
this guy is going to be bounded so this value in this valley are equal

1725
01:48:01,380 --> 01:48:06,760
in more and more problems with considered this set of constraints always visible so now

1726
01:48:06,780 --> 01:48:10,800
we're in the in the case where the reality strong duality holds and we have

1727
01:48:10,860 --> 01:48:14,450
this max and this men are exactly so you can just plug in

1728
01:48:14,490 --> 01:48:17,180
then what i mean

1729
01:48:17,200 --> 01:48:19,760
in the change

1730
01:48:19,800 --> 01:48:24,660
OK so this was our formulation right we plug in the max discrete max all

1731
01:48:24,720 --> 01:48:27,990
going to do now is plug

1732
01:48:29,610 --> 01:48:31,240
continuous one

1733
01:48:32,130 --> 01:48:38,030
q i just abbreviated it's five and w class ally OK so

1734
01:48:38,050 --> 01:48:40,570
it's taking everything that kind of

1735
01:48:40,630 --> 01:48:42,260
hits why

1736
01:48:42,300 --> 01:48:46,950
and putting it into this matrix the now hit rate so there was w hitting

1737
01:48:46,950 --> 01:48:48,650
f x y

1738
01:48:48,650 --> 01:48:51,130
now we can write it down as the leading

1739
01:48:52,530 --> 01:48:55,510
OK in the same thing for for her loss

1740
01:48:55,530 --> 01:48:59,010
so that we had this and then heads e

1741
01:48:59,010 --> 01:49:00,930
OK and that gives score

1742
01:49:00,950 --> 01:49:01,840
and then

1743
01:49:01,900 --> 01:49:05,630
this is that gives you the loss

1744
01:49:05,840 --> 01:49:08,930
right so you see why loss was also important to be

1745
01:49:09,130 --> 01:49:13,630
decomposable because now it's can be a linear function of disease or disease vector in

1746
01:49:13,650 --> 01:49:15,220
this guy is a vector

1747
01:49:15,610 --> 01:49:19,180
and so that's going get you that computes

1748
01:49:19,200 --> 01:49:20,920
our loss for us

1749
01:49:20,930 --> 01:49:27,180
by LP duality these interchangeable so we can just

1750
01:49:27,200 --> 01:49:28,490
stick n

1751
01:49:28,490 --> 01:49:29,680
this guy

1752
01:49:29,700 --> 01:49:30,950
here the main

1753
01:49:32,760 --> 01:49:34,880
it turns out we can just move the men

1754
01:49:34,900 --> 01:49:39,030
of the activity was minimisation over everything in the same time

1755
01:49:39,050 --> 01:49:43,130
so that the only variables that appear in this minimisation appeared down below

1756
01:49:43,180 --> 01:49:45,200
so you might as well just move them in

1757
01:49:45,220 --> 01:49:46,610
out here

1758
01:49:46,660 --> 01:49:52,660
so now we have a joint w this lacks prominence slacks and these landers

1759
01:49:52,680 --> 01:49:57,760
which is basically the land this try to compute for us implicitly

1760
01:49:57,800 --> 01:50:04,820
what what sort of the most violated constraint is what is the the highest scoring

1761
01:50:04,820 --> 01:50:07,070
guy that's that's making us

1762
01:50:07,090 --> 01:50:10,240
look back right

1763
01:50:10,760 --> 01:50:13,730
and all that sort of

1764
01:50:13,740 --> 01:50:16,930
encoded into in this

1765
01:50:16,940 --> 01:50:19,970
because that's the dual of the max

1766
01:50:21,130 --> 01:50:23,070
that's it that's the whole track

1767
01:50:23,110 --> 01:50:26,440
you go from discrete to continue

1768
01:50:26,480 --> 01:50:30,230
take do all and you have a QP

1769
01:50:30,240 --> 01:50:35,560
there has finite number of variables that w is not the parameters lambda is in

1770
01:50:35,650 --> 01:50:40,160
numbers roughly corresponds to the number of constraints information which is

1771
01:50:40,200 --> 01:50:41,590
number of parts

1772
01:50:41,600 --> 01:50:43,160
this thing is


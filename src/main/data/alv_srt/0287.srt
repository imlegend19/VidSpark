1
00:00:00,000 --> 00:00:07,040
marginal as the voice of art may be it attempted to remind us that despite the

2
00:00:07,040 --> 00:00:13,480
optimism of certain metaphysicians there is something implacably and sadly

3
00:00:13,480 --> 00:00:17,980
malignant about this world

4
00:00:18,680 --> 00:00:22,960
my book concludes with the text by italo calvino

5
00:00:23,810 --> 00:00:28,640
a short story that

6
00:00:28,640 --> 00:00:30,930
springs from real experience

7
00:00:31,420 --> 00:00:37,140
the cottolengo in turin is a Catholic institution full of incurably ill

8
00:00:37,140 --> 00:00:45,160
people persons who cannot even feed themselves without assistance many of them born as monster

9
00:00:45,770 --> 00:00:49,330
like many of those we have talked about here

10
00:00:49,890 --> 00:00:53,830
not legendary monsters but monsters who live

11
00:00:54,160 --> 00:00:57,230
ignored alongside us

12
00:00:57,500 --> 00:01:04,540
the main character of the story is a scutratore man sent by a political

13
00:01:04,540 --> 00:01:08,310
party to control the elections

14
00:01:12,330 --> 00:01:17,210
the election because there is a polling station even in that hospital

15
00:01:17,250 --> 00:01:20,410
because those monsters are citizens too

16
00:01:20,750 --> 00:01:25,370
and according to the law they have the right to vote

17
00:01:25,390 --> 00:01:29,290
shocked by the side of these subhumanity

18
00:01:29,520 --> 00:01:32,250
the scutratore realizes that

19
00:01:32,290 --> 00:01:36,460
very many of the patient do not realize what they are going to do

20
00:01:36,460 --> 00:01:41,680
and that they will vote according to the will of their religious helpers

21
00:01:42,480 --> 00:01:47,320
belonging as it does to a leftist party would like to oppose what strikes him as

22
00:01:47,320 --> 00:01:48,960
a fraud

23
00:01:49,000 --> 00:01:50,930
but in the end

24
00:01:51,040 --> 00:01:54,730
against all his political convictions

25
00:01:54,750 --> 00:01:55,890
he concludes

26
00:01:55,930 --> 00:02:00,890
that those who have the courage to devote their life to those unfortunates

27
00:02:00,980 --> 00:02:06,770
have acquired the right to speak for them I would like to conclude even

28
00:02:06,770 --> 00:02:09,960
my speech in the same vein

29
00:02:10,000 --> 00:02:15,340
I have presented images that oblige us to recognize that ugliness can provoke either fear

30
00:02:15,510 --> 00:02:21,290
and disgust or amusement making us to laugh of many human miseries

31
00:02:21,660 --> 00:02:25,870
but after having witnessed of how unpleasant ugliness can be

32
00:02:26,270 --> 00:02:28,960
when it doesn't concern ourselves

33
00:02:29,310 --> 00:02:34,640
I think is wise to end with an appeal for compassion

34
00:02:34,660 --> 00:02:35,520
thank you

35
00:03:25,310 --> 00:03:32,890
so thank you very much that was really nice we are now ready for discussion

36
00:03:33,100 --> 00:03:35,560
a mamo kakšno vprašanje kakšen komentar

37
00:03:35,600 --> 00:03:38,810
but here with the microphone otherwise I miss half

38
00:03:38,910 --> 00:03:39,700
of the words

39
00:03:42,410 --> 00:03:50,460
if not important because I have prepared the answers so I can answer you are not that lucky

40
00:03:50,460 --> 00:03:52,820
and you want to be able to associate the best people

41
00:03:54,730 --> 00:03:55,890
if anybody tells you

42
00:03:56,450 --> 00:03:59,130
that phd doesn't and why you with news equals

43
00:03:59,730 --> 00:04:01,090
to explore a rusty

44
00:04:01,530 --> 00:04:02,980
to think level

45
00:04:03,230 --> 00:04:04,540
you could go to before so

46
00:04:04,800 --> 00:04:05,460
i think

47
00:04:07,550 --> 00:04:15,570
ok you're ok i'd like to point out something where in his fashion

48
00:04:15,820 --> 00:04:17,180
i think he ignored the data

49
00:04:17,370 --> 00:04:19,980
none of us here said they should not do a phd

50
00:04:20,160 --> 00:04:24,320
advice was get experience you do it faster better cheaper

51
00:04:25,670 --> 00:04:33,980
ok yeah point form please stop stop without claudia water the critical success factors for jobs science

52
00:04:34,000 --> 00:04:34,800
by startup

53
00:04:38,610 --> 00:04:39,660
first what i said is

54
00:04:39,790 --> 00:04:41,600
really make sure to product

55
00:04:41,830 --> 00:04:45,500
that's why something being on the sidelines as as mad the second is

56
00:04:46,050 --> 00:04:47,160
you need to have

57
00:04:47,510 --> 00:04:50,830
an amazing team that came before and you need people

58
00:04:51,260 --> 00:04:54,550
who can have covered space when they built things how to

59
00:04:56,170 --> 00:04:59,570
average on yeah excellent job program doesn't necessarily

60
00:05:00,730 --> 00:05:01,850
get you what you need

61
00:05:02,090 --> 00:05:02,890
building a good

62
00:05:03,110 --> 00:05:05,260
data science environment a scale

63
00:05:05,690 --> 00:05:07,350
that even program need around

64
00:05:07,650 --> 00:05:10,980
handling data so you need a team that has experience

65
00:05:12,960 --> 00:05:14,290
preferably standard before

66
00:05:16,860 --> 00:05:17,780
point home wrong

67
00:05:18,330 --> 00:05:25,360
so yeah i game i'm bringing vc perspective so what is very important is that

68
00:05:25,380 --> 00:05:28,350
you know it's the same mining play after all this

69
00:05:28,870 --> 00:05:33,410
this panel was about mining itself first is that the size of the addressable market

70
00:05:33,820 --> 00:05:37,300
if you say you have a startup that south to like know

71
00:05:37,610 --> 00:05:43,980
bookstores in chicago and how many bookstores in chicago to have one hundred probably not one

72
00:05:44,000 --> 00:05:44,780
million right

73
00:05:44,930 --> 00:05:46,620
so you're a your

74
00:05:47,120 --> 00:05:52,300
market you can south to is not that be so that's one thing another thing

75
00:05:52,670 --> 00:05:53,710
he is

76
00:05:54,760 --> 00:05:59,260
your goal to market strategy so how you actually start sailing to

77
00:05:59,770 --> 00:06:01,730
to co however your selling right

78
00:06:01,910 --> 00:06:04,460
and this third thing is that your pricing

79
00:06:04,610 --> 00:06:09,130
so if you south to a billion people and but the south for one many

80
00:06:09,330 --> 00:06:14,270
error you're making like ten million dollars a year which is not

81
00:06:14,280 --> 00:06:15,830
it's not very big success

82
00:06:16,850 --> 00:06:17,830
point four morn

83
00:06:18,360 --> 00:06:22,460
so we talked about team but i want to emphasize this is not all equal who's

84
00:06:22,480 --> 00:06:28,650
the most important players in the miami heat right brunch change who's the most important person on

85
00:06:28,670 --> 00:06:29,830
the team start-up

86
00:06:30,010 --> 00:06:31,170
it's the ceo

87
00:06:32,680 --> 00:06:34,520
or by orders of magnitude so

88
00:06:34,730 --> 00:06:37,060
look very carefully at the ceo

89
00:06:38,290 --> 00:06:43,020
point four yeah i agree with management but

90
00:06:44,710 --> 00:06:49,490
i also say i would add to to what was said by on i would that execution

91
00:06:50,090 --> 00:06:55,530
right so many people have great ideas great business models market size is there

92
00:06:55,930 --> 00:07:00,240
and ideas ideas are so so cheap and so easy to have

93
00:07:02,370 --> 00:07:04,680
is really distinguishing factors so

94
00:07:05,060 --> 00:07:05,520
it was

95
00:07:05,660 --> 00:07:07,380
a one off that said

96
00:07:08,210 --> 00:07:10,630
you know i'll i'll i'll invest in any

97
00:07:10,940 --> 00:07:13,540
boring idea would good execution any time

98
00:07:13,870 --> 00:07:18,060
over a good idea with no execution which i would never invested so

99
00:07:19,920 --> 00:07:24,820
ok so job down to question number three because the other was actually have been partially addressed they got a

100
00:07:24,840 --> 00:07:27,080
lot of down votes oxygen question number two now

101
00:07:28,480 --> 00:07:32,850
and it's very precise so we could probably get through its first new graduate soon

102
00:07:34,170 --> 00:07:37,080
which path is better for starting a company in the future

103
00:07:37,720 --> 00:07:41,540
are what go research lab and then start a company later

104
00:07:41,680 --> 00:07:43,540
right or go big company

105
00:07:43,860 --> 00:07:45,010
and start a company

106
00:07:45,450 --> 00:07:51,840
if your grid getting sued send your resume yeah ok

107
00:07:52,390 --> 00:07:57,140
kind of vision is ted's yeah i mean for trying to find the

108
00:07:58,940 --> 00:08:03,550
ideas and the advice is just don't start a company right away

109
00:08:04,210 --> 00:08:10,430
get experience whenever r as much as you can and then you will be a good

110
00:08:10,450 --> 00:08:11,730
shape to start a company

111
00:08:12,720 --> 00:08:16,000
so exactly what but foster but early on he faces and then i did

112
00:08:16,320 --> 00:08:21,930
we get good mentorship way going to learn the most and make the most of the next few years and

113
00:08:22,840 --> 00:08:23,470
let's not

114
00:08:23,700 --> 00:08:28,930
examine clear whether this industry not only it's a lab claims we could be back

115
00:08:28,950 --> 00:08:31,320
to back close look at who are going to work with and

116
00:08:31,600 --> 00:08:32,900
what you can help to learn

117
00:08:34,840 --> 00:08:37,890
ok yeah yeah and you know i mean

118
00:08:38,130 --> 00:08:39,770
accident points out that

119
00:08:40,280 --> 00:08:43,340
you know my great believe gradient descent

120
00:08:43,650 --> 00:08:46,640
so there are two major directions here

121
00:08:46,980 --> 00:08:50,930
in in learning right so learning you get from startup

122
00:08:51,140 --> 00:08:52,870
are almost orthogonal

123
00:08:53,730 --> 00:08:56,460
you know sociologically and so forth were choi's

124
00:08:56,680 --> 00:09:00,060
then what you learn from the company and both are extremely important

125
00:09:00,340 --> 00:09:03,020
so if you have the choice i completely agree with on don't

126
00:09:04,170 --> 00:09:07,420
do you start just like with a phd have a little bit of experience before

127
00:09:07,690 --> 00:09:08,530
with start up

128
00:09:09,090 --> 00:09:13,760
to a little bit of experience before because you do this start-up faster better cheaper

129
00:09:14,080 --> 00:09:22,690
and i remember in your career stochastic gradient descent yeah yeah unfortunately but that's the way it

130
00:09:23,700 --> 00:09:30,910
i said question remaining is sokolniki any tips to technical founder wants to get

131
00:09:31,200 --> 00:09:34,460
early-stage funding with skills from sama

132
00:09:36,680 --> 00:09:42,990
yeah quick tips if you're technical founder then get yourself a business co-founder preferably

133
00:09:43,010 --> 00:09:44,580
a very strong ceo

134
00:09:45,230 --> 00:09:49,980
and we say this all the time for for also get a lot of business people want to

135
00:09:50,000 --> 00:09:51,240
do a technology company

136
00:09:51,740 --> 00:09:55,640
and the first thing we tell them as you know we want talk until you go get yourself a

137
00:09:55,660 --> 00:09:56,770
technical co-founder

138
00:09:57,210 --> 00:10:02,110
and they usually just go and get themselves an employee and we know that doesn't count co-founder means

139
00:10:02,380 --> 00:10:03,790
they own a good chunk of the company

140
00:10:04,290 --> 00:10:06,590
so i think you know it's t we

141
00:10:06,590 --> 00:10:10,980
today and for the next two weeks we're going to study

142
00:10:11,020 --> 00:10:16,610
what for many engineers and a few scientists is the most popular method

143
00:10:16,650 --> 00:10:19,930
of solving any differential equation that they

144
00:10:19,950 --> 00:10:21,700
of the kind happened to me

145
00:10:21,720 --> 00:10:26,790
and that is to use the popular machine called plus transform

146
00:10:30,290 --> 00:10:34,310
you'll get proficient in using it by the end of the two weeks

147
00:10:34,350 --> 00:10:37,960
but there's always a certain amount of mystery that hangs around it

148
00:10:38,020 --> 00:10:41,700
people scratch their heads can figure out where it comes from

149
00:10:41,710 --> 00:10:44,660
and that bothers them alive

150
00:10:44,690 --> 00:10:48,230
in the past i've usually promise to tell you the the end of the

151
00:10:48,270 --> 00:10:52,170
student at the end of the two weeks but i almost never have time so

152
00:10:52,170 --> 00:10:56,510
i'm going to break the glorious tradition and tell you up front at the beginning

153
00:10:56,510 --> 00:10:57,870
where it comes from

154
00:10:57,880 --> 00:11:03,370
and then to look very fast for the rest of the period of OK

155
00:11:03,460 --> 00:11:09,760
a good way of thinking well plus transform comes from and way which i think

156
00:11:09,760 --> 00:11:11,620
this still some of its ministry

157
00:11:11,620 --> 00:11:14,090
is by thinking of power series

158
00:11:14,100 --> 00:11:19,400
i think virtually all of the study power series except possibly a few students

159
00:11:20,430 --> 00:11:25,200
from just had eighteen o one here last semester and probably should be taking eighty

160
00:11:25,370 --> 00:11:27,180
three anyway about but anyway

161
00:11:27,200 --> 00:11:34,460
a power series looks like this summation and actually and some that from let's say

162
00:11:34,480 --> 00:11:36,730
zero to infinity

163
00:11:36,770 --> 00:11:40,320
and the typical thing you want to do is add up to find out what

164
00:11:40,350 --> 00:11:43,790
some is now the only way all depart from tradition

165
00:11:43,810 --> 00:11:47,310
so i'm going to some some generic name like x

166
00:11:47,350 --> 00:11:52,900
in order to identify the sum with the coefficients a colony of x

167
00:11:53,070 --> 00:12:00,120
i want to make this one slight change in there

168
00:12:00,120 --> 00:12:06,770
slight change in this i want to use computer notation which doesn't use the subscript

169
00:12:06,770 --> 00:12:08,320
based event

170
00:12:08,320 --> 00:12:10,010
instead it

171
00:12:10,030 --> 00:12:13,790
this is the thing of the a function of the discrete variable and in other

172
00:12:14,630 --> 00:12:20,950
it's a function which assigns to an any equal zero one two three real numbers

173
00:12:21,010 --> 00:12:23,730
that's what the sequence of coefficients really is

174
00:12:24,480 --> 00:12:29,290
computer notation will look almost the same it's just that all right that's in functional

175
00:12:29,290 --> 00:12:34,170
notation is a event instead of a sub then but it still means the real

176
00:12:34,170 --> 00:12:39,280
number associated with the integer positive integer and

177
00:12:39,320 --> 00:12:41,130
and everything else is the same

178
00:12:45,660 --> 00:12:48,820
so what i'm thinking of this is doing is

179
00:12:48,830 --> 00:12:55,380
taking this discrete function which gives me the sequence of coefficients of the power series

180
00:12:55,390 --> 00:13:00,600
and associating with the sum of the powers

181
00:13:00,600 --> 00:13:04,510
let i think it's very simple examples of two very simple example which i think

182
00:13:04,510 --> 00:13:05,800
you know

183
00:13:05,860 --> 00:13:09,760
i suppose this is the function one now what i mean by that i mean

184
00:13:09,760 --> 00:13:16,550
it's the constant function one two every positive integer it assigns the number one

185
00:13:16,570 --> 00:13:21,230
OK what say that x

186
00:13:21,230 --> 00:13:24,260
what i'm saying is in other words this fancy

187
00:13:24,280 --> 00:13:27,820
this mystifying for if all these guys are one

188
00:13:27,850 --> 00:13:29,450
i say that

189
00:13:29,530 --> 00:13:32,350
one was experts x squared plus xq

190
00:13:32,360 --> 00:13:35,720
look you're supposed to be born knowing what that adds up to

191
00:13:35,760 --> 00:13:38,880
it adds up to

192
00:13:38,880 --> 00:13:43,000
one o one minus six

193
00:13:43,040 --> 00:13:47,830
except that's the wrong answer what's wrong about

194
00:13:47,880 --> 00:13:53,010
it's not true for every value of x that is only true when x

195
00:13:53,080 --> 00:13:57,920
is such that the series converges and that is only true when x lies between

196
00:13:57,920 --> 00:13:58,940
negative one

197
00:13:58,950 --> 00:14:00,380
and one

198
00:14:00,420 --> 00:14:06,470
so it's not this function if this function with domain restricted to to be like

199
00:14:06,480 --> 00:14:12,190
an absolute value

200
00:14:12,230 --> 00:14:13,800
what is that converge to

201
00:14:13,820 --> 00:14:17,390
if x is bigger than one the answer is it doesn't converge

202
00:14:17,470 --> 00:14:19,210
it's nothing there's nothing

203
00:14:19,620 --> 00:14:21,170
else you can put here

204
00:14:21,180 --> 00:14:25,730
OK let's take another function i suppose this is o

205
00:14:25,740 --> 00:14:27,930
let's see what over a you probably won't know

206
00:14:27,960 --> 00:14:31,790
let's take one you will know one or n factorial

207
00:14:31,890 --> 00:14:36,330
suppose a then is the function one over n factorial what's a of x

208
00:14:37,780 --> 00:14:40,850
so what i'm asking is what does this add up to

209
00:14:41,300 --> 00:14:45,040
when the coefficients here is one over n factorial

210
00:14:45,100 --> 00:14:49,360
what summation x to the end over n factorial is

211
00:14:51,340 --> 00:14:54,730
and this doesn't have to be qualified because this is true for all values of

212
00:15:00,500 --> 00:15:03,850
so in other words from this peculiar point of view i think of the power

213
00:15:03,860 --> 00:15:08,060
summing the operation of something power series as

214
00:15:08,080 --> 00:15:10,330
taking a discrete function

215
00:15:10,410 --> 00:15:13,770
fine for positive integers were nonnegative integers

216
00:15:13,780 --> 00:15:17,980
and doing this funny process now becomes continuous function

217
00:15:19,940 --> 00:15:23,830
and notice what goes in is the variable and

218
00:15:23,960 --> 00:15:26,840
what comes out is the variable x

219
00:15:26,850 --> 00:15:30,290
well that's perfectly natural that's way power series set

220
00:15:30,290 --> 00:15:33,180
so the question i ask is here

221
00:15:33,230 --> 00:15:37,460
this is the discrete situation discrete summation

222
00:15:37,500 --> 00:15:43,870
to get this function i suppose i made the summation continuous instead of discrete so

223
00:15:43,870 --> 00:15:47,230
i want the continuous analogue

224
00:15:49,150 --> 00:15:56,250
of what i did over there OK well with the continuous analog b well

225
00:15:56,290 --> 00:15:58,920
instead of all replace

226
00:15:58,940 --> 00:16:01,910
and zero one two

227
00:16:01,960 --> 00:16:06,230
that will be replaced by continue that the discrete variable

228
00:16:06,280 --> 00:16:09,580
all replaced by continuous variable t

229
00:16:09,590 --> 00:16:11,410
which runs from

230
00:16:12,440 --> 00:16:13,790
to infinity

231
00:16:13,870 --> 00:16:20,250
and is allowed to take every real value in between instead of being only allowed

232
00:16:20,270 --> 00:16:25,430
to take the values of the positive integers nonnegative integers

233
00:16:25,440 --> 00:16:29,210
OK well if i want to use t instead of then

234
00:16:29,250 --> 00:16:34,530
i clearly cannot sum in the usual way over all real numbers but the way

235
00:16:34,560 --> 00:16:39,800
the procedure which replaces summation over all real numbers is integration

236
00:16:39,830 --> 00:16:44,030
so we're going to do is replace that some by the integral

237
00:16:44,060 --> 00:16:48,890
from zero to infinity that's like the sum from one to zero to infinity of

238
00:16:49,650 --> 00:16:52,310
well of some function but now

239
00:16:52,340 --> 00:16:55,870
and is being replaced by the continuous variable t so this is going to be

240
00:16:55,870 --> 00:16:58,530
a function of t

241
00:16:58,600 --> 00:17:01,770
and how the rest of the rest of his copy

242
00:17:01,780 --> 00:17:05,560
to the end well but instead of and i have to write t

243
00:17:05,580 --> 00:17:07,920
and the t

244
00:17:07,970 --> 00:17:10,340
and what's the someone well called the sum

245
00:17:10,350 --> 00:17:12,350
what's the sum of function of

246
00:17:12,360 --> 00:17:16,480
i integrate out the t so that doesn't appear the answer all that appears is

247
00:17:16,480 --> 00:17:19,710
this number axis parameter x

248
00:17:19,750 --> 00:17:24,310
for each value of x like one two or twenty six point three

249
00:17:24,360 --> 00:17:28,870
this integral has a certain value and i can calculate so this is the end

250
00:17:28,870 --> 00:17:34,100
up as a function of x just before

251
00:17:34,230 --> 00:17:37,280
now i could leave it in four

252
00:17:37,360 --> 00:17:39,590
but it would be

253
00:17:39,920 --> 00:17:44,410
the mathematician would like to do that and very few engineers either

254
00:17:45,150 --> 00:17:47,210
the reason is in general

255
00:17:47,220 --> 00:17:51,850
well you do integration and differentiation you do not want to have as the base

256
00:17:51,850 --> 00:17:53,290
of an exponential

257
00:17:53,290 --> 00:17:56,800
acoustic articulatory data contains

258
00:17:56,860 --> 00:18:01,630
this electromagnetic articulography data in addition to

259
00:18:01,680 --> 00:18:06,070
data from various other various other sources

260
00:18:06,090 --> 00:18:07,410
so i

261
00:18:07,620 --> 00:18:10,590
so there's evidence so people had

262
00:18:10,610 --> 00:18:15,950
used these sort of partial articulatory measurements two

263
00:18:15,950 --> 00:18:22,210
improve the performance of what we might say are sort of traditional technology ASR systems

264
00:18:22,230 --> 00:18:26,220
so there's there's proof that we can do something with this stuff

265
00:18:28,480 --> 00:18:31,150
that's our motivation

266
00:18:31,160 --> 00:18:33,220
any questions so far

267
00:18:34,930 --> 00:18:38,780
the couple but asking questions you might embarrass himself in front of colleagues

268
00:18:38,810 --> 00:18:40,240
OK so

269
00:18:41,040 --> 00:18:47,450
the now the now the negative part one of the challenges here for

270
00:18:47,520 --> 00:18:55,220
trying to incorporate articulatory models well big challenge is if we've only got acoustic information

271
00:18:56,610 --> 00:18:58,160
the the

272
00:18:58,170 --> 00:19:01,680
articulatory information or even

273
00:19:01,690 --> 00:19:06,370
coming up with some notion of what the vocal tract shape is in association with

274
00:19:06,370 --> 00:19:08,670
the given acoustic output

275
00:19:08,690 --> 00:19:12,880
the other big challenges the nonlinear relationship between

276
00:19:12,890 --> 00:19:17,360
production acoustics and perception and we'll talk a little bit about that

277
00:19:17,410 --> 00:19:24,770
that is a very small changes in the position of articulators can result in dramatic

278
00:19:24,770 --> 00:19:26,520
changes in the acoustics

279
00:19:26,580 --> 00:19:28,300
and the and the

280
00:19:28,310 --> 00:19:34,700
in various different nonlinear discontinuity can have these effects

281
00:19:34,710 --> 00:19:41,500
finally the the coding of perceptually salient articulatory information is is also something it's that's

282
00:19:41,500 --> 00:19:45,760
difficult to deal with the now give an example of an experiment that shows what

283
00:19:45,760 --> 00:19:47,510
sort of problem that can be

284
00:19:47,530 --> 00:19:49,460
here's a

285
00:19:49,730 --> 00:19:56,070
to illustrate the difficulty of acoustic to vocal tract area mapping

286
00:19:56,110 --> 00:19:58,210
we basically

287
00:19:58,220 --> 00:20:02,490
can give an example of the sort of many

288
00:20:02,500 --> 00:20:11,640
are they like is one to many problems the property associated with inverted inverting the

289
00:20:11,650 --> 00:20:13,880
the acoustics two

290
00:20:14,690 --> 00:20:17,190
two vocal tract area mapping

291
00:20:17,300 --> 00:20:19,430
we got on the left

292
00:20:19,440 --> 00:20:22,280
is the set of vocal tract shapes

293
00:20:24,740 --> 00:20:27,510
terms of sort of area functions

294
00:20:27,560 --> 00:20:33,010
we can think along the horizontal axis were basically moving from the glottis to the

295
00:20:33,990 --> 00:20:39,740
and along the vertical axis is the vocal tract area so you can roughly think

296
00:20:39,740 --> 00:20:46,980
of yourself as looking sideways at vocal tract and the the

297
00:20:47,000 --> 00:20:52,450
the size of the you know the shape of the thing is sorted described by

298
00:20:52,450 --> 00:20:54,450
by these curves

299
00:20:54,450 --> 00:20:56,400
and so you see these are two

300
00:20:56,410 --> 00:21:00,400
significantly different shapes and then on the right

301
00:21:00,410 --> 00:21:03,200
we have associated with each of these things

302
00:21:03,430 --> 00:21:09,950
the corresponding form and frequency and bandwidth associated with a given vocal tract shape there's

303
00:21:09,950 --> 00:21:13,850
going to be a set of resonances peaks in the spectrum and refer to those

304
00:21:13,850 --> 00:21:20,030
peaks formants they're going to have a centre frequencies designated by the here in the

305
00:21:20,030 --> 00:21:26,010
top row and bandwidths associated with the b right so these are the formats frequencies

306
00:21:26,010 --> 00:21:29,010
and bad associated with this

307
00:21:29,030 --> 00:21:34,720
vocal tract area function and these are the following frequencies in the bandwidths associated with

308
00:21:34,720 --> 00:21:40,510
this one well if we look at these frequencies and bandwidth they're pretty much identical

309
00:21:40,530 --> 00:21:42,270
so with

310
00:21:42,280 --> 00:21:43,920
these identical

311
00:21:43,930 --> 00:21:51,720
the acoustic characteristics we get vastly different well vastly but much different vocal tract area

312
00:21:51,720 --> 00:21:54,760
functions so it goes to show the difficulty

313
00:21:54,760 --> 00:21:56,800
there was an experiment actually

314
00:21:56,800 --> 00:21:59,300
well i in the middle ages actually

315
00:21:59,380 --> 00:22:02,320
what we can do

316
00:22:02,340 --> 00:22:04,630
the first

317
00:22:05,760 --> 00:22:11,930
i think they tried to add more and more can here

318
00:22:11,950 --> 00:22:15,420
you can use the

319
00:22:17,470 --> 00:22:22,340
monarchs may like

320
00:22:22,360 --> 00:22:24,720
korean of the

321
00:22:24,780 --> 00:22:26,610
one of the best e

322
00:22:27,050 --> 00:22:29,990
the middle and somebody

323
00:22:30,030 --> 00:22:34,970
so we need some more until how

324
00:22:35,030 --> 00:22:39,340
the change in the case of the difference will be with

325
00:22:39,380 --> 00:22:43,550
and they don't depend on the

326
00:22:43,570 --> 00:22:45,950
because the density

327
00:22:45,950 --> 00:22:49,070
and why

328
00:22:49,090 --> 00:22:50,990
his life

329
00:22:52,070 --> 00:22:55,780
this not

330
00:22:55,860 --> 00:22:57,490
the great

331
00:22:57,570 --> 00:22:59,030
so this

332
00:22:59,900 --> 00:23:00,510
he was the

333
00:23:07,990 --> 00:23:10,950
because which describe this level

334
00:23:11,010 --> 00:23:16,300
every one of them

335
00:23:16,360 --> 00:23:17,720
this morning

336
00:23:18,740 --> 00:23:26,130
we can discriminate right and the high become community so

337
00:23:26,150 --> 00:23:28,670
what is that

338
00:23:29,820 --> 00:23:32,530
i wish had more like to distinguish

339
00:23:32,550 --> 00:23:33,630
after the

340
00:23:33,670 --> 00:23:34,670
in the middle

341
00:23:36,320 --> 00:23:40,450
and when is too high but also distinguish

342
00:23:40,470 --> 00:23:44,320
well the differences between

343
00:23:44,380 --> 00:23:46,900
one thing

344
00:23:46,950 --> 00:23:49,170
because to use this

345
00:23:56,650 --> 00:24:01,240
which is very

346
00:24:01,260 --> 00:24:03,800
o function

347
00:24:05,360 --> 00:24:08,860
how do you see the emulsion

348
00:24:08,880 --> 00:24:10,510
along this line

349
00:24:12,190 --> 00:24:17,200
around like the picture is that

350
00:24:17,490 --> 00:24:22,950
so you can see

351
00:24:22,950 --> 00:24:30,150
is it possible that this will have some peaks in but actually the like

352
00:24:30,150 --> 00:24:34,260
and i

353
00:24:34,510 --> 00:24:42,260
if experiment is kind of a change in the first

354
00:24:42,260 --> 00:24:45,900
right depends on

355
00:24:45,930 --> 00:24:47,590
all the things

356
00:24:48,990 --> 00:24:50,610
this is a

357
00:24:50,630 --> 00:24:51,700
with them

358
00:24:56,050 --> 00:24:57,610
let's that is and

359
00:24:57,610 --> 00:24:59,760
the right to the left

360
00:25:00,760 --> 00:25:04,530
actually all these in the

361
00:25:07,510 --> 00:25:08,400
the same

362
00:25:09,590 --> 00:25:17,090
because the line is on the one hand

363
00:25:17,110 --> 00:25:18,490
but he was

364
00:25:18,570 --> 00:25:21,070
this one is that is one

365
00:25:21,130 --> 00:25:28,700
just because you that there are quite

366
00:25:34,130 --> 00:25:38,650
how this color

367
00:25:39,050 --> 00:25:40,320
maybe someone

368
00:25:41,170 --> 00:25:44,170
the high court

369
00:25:44,170 --> 00:25:46,320
pro and con

370
00:25:50,170 --> 00:25:53,740
which which is like

371
00:25:53,760 --> 00:25:56,880
and actually we call it

372
00:25:58,430 --> 00:26:03,840
and that's what i call our which

373
00:26:04,260 --> 00:26:07,280
the plane

374
00:26:09,800 --> 00:26:11,110
this is

375
00:26:15,110 --> 00:26:16,920
the plane

376
00:26:16,970 --> 00:26:17,990
the way

377
00:26:22,900 --> 00:26:25,030
o two

378
00:26:25,070 --> 00:26:26,300
david see

379
00:26:26,300 --> 00:26:30,550
blue green red it is the combination of

380
00:26:34,090 --> 00:26:34,990
that's why

381
00:26:36,900 --> 00:26:37,860
the way

382
00:26:37,880 --> 00:26:45,280
color space which is used to represent challenges is really and

383
00:26:45,300 --> 00:26:51,950
actually all of space is most usually very calm me so there are three primary

384
00:26:54,970 --> 00:26:56,970
this column

385
00:26:56,990 --> 00:26:58,240
in which

386
00:26:58,340 --> 00:27:00,800
so called it

387
00:27:00,800 --> 00:27:03,190
o line

388
00:27:03,880 --> 00:27:07,170
i have a great week and will

389
00:27:08,240 --> 00:27:11,920
so that means that we have life of

390
00:27:11,920 --> 00:27:13,450
which have

391
00:27:14,360 --> 00:27:16,340
of y

392
00:27:16,360 --> 00:27:17,650
the length of

393
00:27:17,670 --> 00:27:19,360
chris my

394
00:27:21,360 --> 00:27:22,430
and also

395
00:27:25,530 --> 00:27:29,190
power so was some

396
00:27:30,280 --> 00:27:31,840
which reflect

397
00:27:31,920 --> 00:27:36,550
the light for

398
00:27:36,570 --> 00:27:38,220
but the club

399
00:27:38,220 --> 00:27:40,950
so that called

400
00:27:40,970 --> 00:27:45,170
abstract right so that the this

401
00:27:45,220 --> 00:27:47,450
like like

402
00:27:51,150 --> 00:27:55,360
right now the only one

403
00:27:55,380 --> 00:28:00,720
and this is one the primary colors usually imagine

404
00:28:00,740 --> 00:28:01,720
o and

405
00:28:06,360 --> 00:28:12,690
this red green blue and magenta yellow cycle

406
00:28:12,700 --> 00:28:15,110
nick nichols thorne

407
00:28:15,190 --> 00:28:16,650
they are

408
00:28:16,670 --> 00:28:17,900
they managed

409
00:28:17,970 --> 00:28:19,510
it was

410
00:28:19,570 --> 00:28:22,200
believe based on was

411
00:28:22,280 --> 00:28:25,070
by one right

412
00:28:25,110 --> 00:28:27,610
and like just it is better to

413
00:28:27,670 --> 00:28:32,280
present them as well as the best

414
00:28:32,340 --> 00:28:38,030
describe how like you describe with the rate

415
00:28:38,090 --> 00:28:40,490
they were the only

416
00:28:40,510 --> 00:28:43,590
we can tell

417
00:28:43,610 --> 00:28:44,970
however i

418
00:28:45,030 --> 00:28:45,900
what i can tell you

419
00:28:46,050 --> 00:28:47,530
you have

420
00:28:47,550 --> 00:28:48,720
and we can play say

421
00:28:49,780 --> 00:28:53,650
it is situated on the right column

422
00:28:53,670 --> 00:28:57,360
so it is close to agreeing on this

423
00:28:57,450 --> 00:29:04,320
great is if you

424
00:29:05,950 --> 00:29:08,650
to be able to drive car

425
00:29:08,670 --> 00:29:10,900
because somehow the

426
00:29:12,820 --> 00:29:15,470
o places that actually by

427
00:29:15,470 --> 00:29:17,360
visual perception

428
00:29:17,420 --> 00:29:19,880
if you know

429
00:29:20,570 --> 00:29:22,420
i was

430
00:29:30,150 --> 00:29:31,570
is called

431
00:29:31,590 --> 00:29:33,050
so we can measure

432
00:29:33,070 --> 00:29:35,300
this this and this is

433
00:29:35,490 --> 00:29:43,450
like what we usually denoted by and then so is this one although i was

434
00:29:44,610 --> 00:29:47,260
six of particular links

435
00:29:48,970 --> 00:29:53,970
and to make the the chromaticity coordinates

436
00:29:53,990 --> 00:29:58,010
just by normalizing this thing

437
00:29:58,030 --> 00:30:00,920
in nineteen eighty one

438
00:30:02,200 --> 00:30:04,490
by experiment was built such call

439
00:30:04,490 --> 00:30:09,890
the rest equals one and now we need to sweat about what the prior going

440
00:30:09,890 --> 00:30:11,620
to be in

441
00:30:11,640 --> 00:30:14,160
it is so subjective

442
00:30:15,640 --> 00:30:19,350
well i'm going to set the prior to fifty fifty

443
00:30:19,350 --> 00:30:22,140
so this is a half a

444
00:30:22,890 --> 00:30:24,080
the prior

445
00:30:24,100 --> 00:30:27,410
and the business end of this what it's all about in this problem is the

446
00:30:27,410 --> 00:30:32,330
likelihood function and so we want to know walks through this

447
00:30:32,370 --> 00:30:36,470
probably get the data that we did get it zero

448
00:30:36,490 --> 00:30:38,240
which appears twice

449
00:30:39,620 --> 00:30:44,080
probably would be under the other hypothesis and that's what this is all that

450
00:30:44,100 --> 00:30:48,540
and the answer to that is well the probability of getting zero one one when

451
00:30:48,540 --> 00:30:51,850
you send as equals zero is the

452
00:30:51,870 --> 00:30:56,260
the first bit would have to be not flipped

453
00:30:56,270 --> 00:30:58,120
so this is equal to

454
00:31:00,350 --> 00:31:03,020
one minus at times

455
00:31:03,040 --> 00:31:08,260
this is probably one minus have but it doesn't doesn't get flipped times because the

456
00:31:08,260 --> 00:31:11,060
second it would have had to be flipped times

457
00:31:11,060 --> 00:31:15,580
because it had to be that is the likelihood function is one minus after the

458
00:31:15,580 --> 00:31:18,640
power of the number of bits that didn't need to be flipped times after the

459
00:31:18,640 --> 00:31:20,810
power of the number that need to be flat

460
00:31:20,830 --> 00:31:23,160
and this one here

461
00:31:23,180 --> 00:31:27,770
comes to

462
00:31:27,830 --> 00:31:31,660
reflect the first one

463
00:31:31,680 --> 00:31:36,100
in order for this to happen on my z squared we have to not let

464
00:31:36,100 --> 00:31:37,850
the other two so that's the two

465
00:31:40,430 --> 00:31:41,600
when you then

466
00:31:41,640 --> 00:31:44,830
do the trivial algebra to finish off this calculation

467
00:31:44,830 --> 00:31:48,740
you find the answer comes out to

468
00:31:50,870 --> 00:31:55,310
OK so i skipped over the trivial algebra

469
00:31:55,370 --> 00:31:59,620
and the answer is but the ten percent chance that this was there was a

470
00:31:59,620 --> 00:32:03,810
ninety percent chance that someone so that's decoder is the majority vote because but it's

471
00:32:03,810 --> 00:32:06,330
quantified tells you how probable it is

472
00:32:06,330 --> 00:32:10,990
based there wonderful i commend it to you

473
00:32:15,520 --> 00:32:16,410
what's the

474
00:32:16,430 --> 00:32:20,240
big picture of what was going on here we're looking at alternative explanations and we're

475
00:32:20,240 --> 00:32:24,470
counting how many bits would have to be flipped and the most probable explanation is

476
00:32:24,470 --> 00:32:29,160
the the one the required the smallest number of flips so that's the general description

477
00:32:29,160 --> 00:32:34,450
of the majority vote because it says find the hypothesis that involve the smallest number

478
00:32:35,810 --> 00:32:38,990
here's another thing

479
00:32:41,560 --> 00:32:43,890
hypotheses about this

480
00:32:47,490 --> 00:32:49,930
it involves

481
00:32:51,990 --> 00:32:53,310
and that will be

482
00:32:53,310 --> 00:32:55,700
the maximum likelihood estimator

483
00:32:58,080 --> 00:33:00,520
also the most probable estimate for us

484
00:33:00,540 --> 00:33:02,600
if the prior is fifty fifty

485
00:33:02,660 --> 00:33:05,580
good on you can do that and here is what it looks like when you

486
00:33:05,580 --> 00:33:07,850
apply that to

487
00:33:07,870 --> 00:33:10,290
this particular file in this particular

488
00:33:11,870 --> 00:33:14,720
and you can probably see that what came out is still not the same as

489
00:33:14,720 --> 00:33:19,560
what went and because this code is still making errors

490
00:33:19,580 --> 00:33:24,180
OK so the suggestion is

491
00:33:24,200 --> 00:33:29,740
let's imagine changing the number of repetitions

492
00:33:30,790 --> 00:33:32,310
if we had

493
00:33:34,310 --> 00:33:36,160
repetitions only

494
00:33:36,180 --> 00:33:37,740
we would get

495
00:33:37,760 --> 00:33:41,470
nothing would get nothing habitat your neighbour

496
00:34:25,390 --> 00:34:27,470
what do you think

497
00:34:27,490 --> 00:34:32,520
to be willing to is really useless was the decoder going to do for these

498
00:34:32,540 --> 00:34:34,720
four locations here

499
00:34:34,720 --> 00:34:37,500
that would depend on what story we can tell them how we model it of

500
00:34:37,500 --> 00:34:39,450
course but once we

501
00:34:39,450 --> 00:34:42,870
managed to convince you that this is the right story to tell and then can

502
00:34:42,870 --> 00:34:45,390
say can we do it will come we do it

503
00:34:45,410 --> 00:34:48,140
so let's assume that we've agreed on what the story is

504
00:34:48,620 --> 00:34:53,740
we can estimate we get the observation distribution of the observable variables and we get

505
00:34:53,750 --> 00:34:55,740
this kind of causal query

506
00:34:56,020 --> 00:35:01,790
this is are these intervention variables modelled in the system as well

507
00:35:01,790 --> 00:35:04,640
this is the kind of thing we like to say something about how would why

508
00:35:04,660 --> 00:35:08,600
respond to an intervention at x and just for simplicity

509
00:35:09,770 --> 00:35:12,000
co y given x check

510
00:35:12,120 --> 00:35:13,560
six hatch

511
00:35:13,620 --> 00:35:16,770
OK i mean to intervene at x

512
00:35:16,810 --> 00:35:18,890
so when i how can this be done

513
00:35:18,970 --> 00:35:21,870
we've already one example of that we know

514
00:35:21,890 --> 00:35:27,950
missing variables this is the no confounder case all the and confounder these properties allow

515
00:35:27,950 --> 00:35:33,580
you to say the interventional distribution of y given you intervene indexes this formula and

516
00:35:33,580 --> 00:35:37,480
we had it as an integral before take everything discrete now that was the backdoor

517
00:35:37,480 --> 00:35:40,700
form that we can do that in that particular model

518
00:35:40,750 --> 00:35:42,290
as night

519
00:35:43,060 --> 00:35:49,470
you can do bad all formerly and more complicated models rather complicated case where

520
00:35:49,500 --> 00:35:51,450
and everything is observable

521
00:35:51,470 --> 00:35:57,250
i'm looking for variables that with these properties causes i can use it to apply

522
00:35:57,270 --> 00:36:01,870
the back door formula and you can check from the properties of that DAG that

523
00:36:01,870 --> 00:36:04,330
there's more than one choice which will work for you

524
00:36:04,540 --> 00:36:07,500
you can either use the pair z three and z four that work with the

525
00:36:07,500 --> 00:36:12,720
pairs that florence five that all although also work for the purposes of identifying the

526
00:36:13,430 --> 00:36:14,790
cause and effect

527
00:36:14,810 --> 00:36:18,240
it doesn't matter which you use if you want to be the most often say

528
00:36:18,240 --> 00:36:24,430
which is more efficient in terms of statistical efficiency that's a completely different story

529
00:36:24,480 --> 00:36:30,790
there's another another nice formula so-called front door formula and the of the model the

530
00:36:30,790 --> 00:36:36,540
model which is appropriate for that now it's got an unobserved variable u

531
00:36:36,560 --> 00:36:39,680
but this is rather important is missing our there

532
00:36:39,850 --> 00:36:45,660
so tell tell some story in terms of smoking and tar in the lungs and

533
00:36:46,790 --> 00:36:51,680
and some variable which can affect whether you smoke and often when he got cancer

534
00:36:51,680 --> 00:36:55,640
or not but doesn't otherwise affect how much time you get in your lungs it

535
00:36:55,640 --> 00:36:56,790
depends on

536
00:36:56,790 --> 00:36:57,830
when this man

537
00:36:57,830 --> 00:36:58,910
that's all

538
00:36:59,160 --> 00:37:04,120
and and it turns out one of a few grind on the assumptions implicit there

539
00:37:04,140 --> 00:37:07,790
play around with it and it's quite and the next thing you get out of

540
00:37:07,790 --> 00:37:12,740
formula for the distribution y if you interviewed on x in terms of the observation

541
00:37:12,850 --> 00:37:16,410
distributions form from x y and z

542
00:37:16,430 --> 00:37:21,370
it's all observations there's no way needed to show that the same the basically did

543
00:37:21,370 --> 00:37:24,390
using different languages to say the same thing

544
00:37:24,410 --> 00:37:28,680
conditional independencies equality of gaius different distribution so

545
00:37:30,330 --> 00:37:35,410
so these properties are actually equivalent to those properties so here for example that says

546
00:37:35,410 --> 00:37:39,890
if this property holds then it doesn't matter what is the deserved or intervened on

547
00:37:39,890 --> 00:37:42,640
i get the same distribution here

548
00:37:43,080 --> 00:37:46,790
now the importance of this is that i may be able to look at my

549
00:37:46,790 --> 00:37:50,700
DAG with all the variables in it and in in

550
00:37:50,750 --> 00:37:54,830
i interrogated to see whether these properties hold or not and then on the basis

551
00:37:54,830 --> 00:37:56,890
of that i can apply these rules

552
00:37:56,970 --> 00:38:00,720
by applying these rules i can i can get variables in and out so i

553
00:38:00,720 --> 00:38:01,410
can get

554
00:38:01,450 --> 00:38:04,700
these had checks on and off and with a little luck i can get down

555
00:38:04,700 --> 00:38:07,950
to something i want by applying these rules of succession

556
00:38:08,020 --> 00:38:14,250
well i want to get something which has got had gone it because it's in

557
00:38:14,250 --> 00:38:17,830
terms of things which don't because their observations and only involved

558
00:38:17,850 --> 00:38:19,970
observed variables

559
00:38:19,980 --> 00:38:28,520
and this is not very recently which pearl shpitser chan says if your problem is

560
00:38:28,520 --> 00:38:31,330
modeled by pearlian DAG

561
00:38:31,370 --> 00:38:34,450
so you can end up resorting to be in any way

562
00:38:34,520 --> 00:38:41,240
and the do calculus is complete again three rules any computable causal effect can be

563
00:38:41,240 --> 00:38:42,470
computed by

564
00:38:42,470 --> 00:38:46,780
among a hundred thousand

565
00:38:46,800 --> 00:38:51,340
here's another example in text filtering so feature selection is being used a lot in

566
00:38:51,930 --> 00:38:53,540
the biomedical domain

567
00:38:53,550 --> 00:38:54,870
but also

568
00:38:54,900 --> 00:38:57,210
in text processing

569
00:38:57,220 --> 00:38:59,030
and the authors of that paper

570
00:38:59,030 --> 00:39:00,990
use various

571
00:39:01,030 --> 00:39:05,970
non copyrighted in the writers the twenty news groups and web

572
00:39:05,980 --> 00:39:12,040
page database and for all of these they simple bag of word representation with about

573
00:39:12,040 --> 00:39:15,030
a hundred thousand features

574
00:39:15,040 --> 00:39:19,030
and again see on this particular data types of data

575
00:39:19,050 --> 00:39:22,100
we have an increase in performance as a

576
00:39:22,160 --> 00:39:23,970
number of features

577
00:39:23,980 --> 00:39:28,730
so the best we can expect in terms of performance is to not degrade too

578
00:39:28,730 --> 00:39:34,340
much performance on that significantly degrade while using a very small number of features

579
00:39:34,350 --> 00:39:39,730
that alone can be a big win both computationally and also from the point of

580
00:39:39,730 --> 00:39:42,120
view of the data understanding

581
00:39:42,150 --> 00:39:47,700
in this case here i'm showing as an example for the twenty news groups several

582
00:39:47,700 --> 00:39:53,680
examples of features that have been identified as very predictive of this particular newsgroup like

583
00:39:53,680 --> 00:39:58,720
for all that it is and not surprisingly you have these activists in reality

584
00:39:58,730 --> 00:40:06,860
more interestingly perhaps four different newsgroups that deal with religion you don't necessarily have

585
00:40:06,870 --> 00:40:12,360
the same the exact same keywords that are interesting

586
00:40:12,370 --> 00:40:17,220
so have got church in singapore sort the coalition the christian because jesus going into

587
00:40:17,220 --> 00:40:19,520
over four hundred queries and this

588
00:40:19,540 --> 00:40:22,380
so what are the details

589
00:40:22,390 --> 00:40:25,090
art that can be of interest

590
00:40:25,100 --> 00:40:32,920
so now other petitions have been tried like face recognition so in this application

591
00:40:33,320 --> 00:40:38,300
it is interesting to see that people have merely use the pixels they haven't done

592
00:40:38,340 --> 00:40:44,720
any offensive feature extraction and try to find which part of the image is informative

593
00:40:44,720 --> 00:40:47,670
for classifying male versus female

594
00:40:47,690 --> 00:40:52,200
and they tried to types of feature selection algorithms

595
00:40:52,360 --> 00:40:58,600
one called relief it's filter that does it all all ordering of the features in

596
00:40:58,600 --> 00:41:05,100
doesn't attempt to remove redundancy between features and the other one simbad they devised does

597
00:41:05,390 --> 00:41:10,800
take into account correlations between features and tries to find those features that are most

598
00:41:10,800 --> 00:41:12,980
complementary with one another

599
00:41:13,630 --> 00:41:18,960
you see the result of using a hundred features five hundred and one thousand top

600
00:41:18,960 --> 00:41:20,860
ranking features

601
00:41:20,870 --> 00:41:26,560
for the first algorithm that does not remove redundancy you have to kind of see

602
00:41:26,570 --> 00:41:29,470
symmetry between the two sides of the future

603
00:41:29,510 --> 00:41:33,610
so features that are redundant because for example they represent the two eyes

604
00:41:33,620 --> 00:41:39,820
they are being selected whereas with the second algorithm that removes redundancy only half

605
00:41:39,850 --> 00:41:47,000
of the features corresponding on one side of the image of being selected

606
00:41:48,850 --> 00:41:54,330
i just presented unit to give you a rough idea some examples of feature selection

607
00:41:54,340 --> 00:41:55,820
before moving into

608
00:41:55,830 --> 00:42:00,090
the meat of the talk i would like to give you some nomenclature i'll be

609
00:42:00,090 --> 00:42:03,250
talking about univariate methods

610
00:42:03,310 --> 00:42:05,440
as those messages that consider

611
00:42:05,450 --> 00:42:09,510
one variable one feature at the time

612
00:42:09,800 --> 00:42:16,510
by contrast multivariate method considers subsets of variables of features that together

613
00:42:16,640 --> 00:42:19,480
are good for making predictions

614
00:42:19,520 --> 00:42:22,070
filter methods ranked features

615
00:42:22,090 --> 00:42:27,100
of feature subsets independently of the predictor of the classifier the talking a lot about

616
00:42:27,100 --> 00:42:31,800
this application but i like to remind you that this also holds for regression problems

617
00:42:32,190 --> 00:42:40,210
and wrapper methods use a wrapper method uses a classifier to assess features or feature

618
00:42:41,630 --> 00:42:50,550
and therefore determines the usefulness of feature subsets with respect to give a prediction method

619
00:42:50,560 --> 00:42:59,470
first let me talk to you about the simplest methods the univariate filter methods

620
00:42:59,510 --> 00:43:01,140
the easiest

621
00:43:01,170 --> 00:43:05,050
is first to determine which feature irrelevance is

622
00:43:05,070 --> 00:43:09,840
by contrast will determine which feature relevance means

623
00:43:09,880 --> 00:43:18,420
feature irrelevance is that as it turns out is well defined mathematically

624
00:43:18,430 --> 00:43:20,690
imagine that we have a single variable

625
00:43:20,700 --> 00:43:22,450
x i

626
00:43:22,460 --> 00:43:28,370
and that we have to classification problem with the positive class y equals one and

627
00:43:28,510 --> 00:43:29,850
the negative class

628
00:43:29,860 --> 00:43:32,310
y equals minus one

629
00:43:32,320 --> 00:43:34,220
and i'm representing here

630
00:43:34,270 --> 00:43:38,470
the density of the examples on this one axis

631
00:43:38,470 --> 00:43:40,500
x i

632
00:43:40,560 --> 00:43:43,930
so if that particular feature is irrelevant

633
00:43:43,940 --> 00:43:48,810
which expect to see is that there is going to be two identical blobs for

634
00:43:48,820 --> 00:43:53,550
the two classes you won't be able to distinguish the distribution of the examples of

635
00:43:53,550 --> 00:43:54,760
class one

636
00:43:54,790 --> 00:43:57,640
with respect to the example of plus minus one

637
00:43:57,670 --> 00:44:03,760
mathematically this can be formalized as the joint probability of x sin y

638
00:44:03,810 --> 00:44:08,970
is equal to the probability of exact probability of y so there is independence between

639
00:44:08,970 --> 00:44:11,060
x i and y

640
00:44:11,100 --> 00:44:12,340
all right

641
00:44:12,390 --> 00:44:16,340
using bayes rule you can also said that p of x given y equals p

642
00:44:16,340 --> 00:44:17,770
of x i

643
00:44:17,790 --> 00:44:19,070
or again

644
00:44:19,170 --> 00:44:22,790
you can say that p of x i given y equals one

645
00:44:22,810 --> 00:44:26,360
the quality of x i given y equals minus one

646
00:44:27,370 --> 00:44:30,250
the distribution and the marginal distribution

647
00:44:30,270 --> 00:44:32,520
p of x y is the same thing

648
00:44:32,570 --> 00:44:34,630
a specific site conditions

649
00:44:34,750 --> 00:44:38,430
why call one and is also the same thing as felix i conditional on y

650
00:44:38,430 --> 00:44:40,520
equals minus one

651
00:44:40,540 --> 00:44:41,830
OK so how do we

652
00:44:41,850 --> 00:44:43,370
define now

653
00:44:43,390 --> 00:44:46,670
reference by contrast with irrelevance

654
00:44:46,680 --> 00:44:48,850
what we need to do is that we need to

655
00:44:48,870 --> 00:44:53,720
measure some displacement between these two distributions

656
00:44:53,730 --> 00:44:55,840
and this has long since been done in

657
00:44:55,850 --> 00:44:58,580
a wide variety of ways

658
00:44:58,760 --> 00:45:02,470
there is only one way of defining irrelevant but there are many many ways of

659
00:45:02,470 --> 00:45:06,050
defining relevance

660
00:45:06,070 --> 00:45:12,940
and one of the simplest way is to use this as simple parametric methods and

661
00:45:12,940 --> 00:45:18,100
parameterized distribution with just two parameters there are the mean and the standard deviation

662
00:45:21,070 --> 00:45:23,720
define the criteria

663
00:45:23,720 --> 00:45:25,180
of the relevance

664
00:45:25,190 --> 00:45:30,230
as the displacement between the means of the two distributions

665
00:45:30,270 --> 00:45:36,170
normalized somehow by the standard deviation to for example normalized by the average and the

666
00:45:36,210 --> 00:45:37,700
standard deviation

667
00:45:37,740 --> 00:45:41,860
so this criterion has been known as the signal to noise ratio criterion

668
00:45:42,010 --> 00:45:45,550
the community of DNA microarray analysis

669
00:45:45,560 --> 00:45:47,970
but as it turns out it's very similar

670
00:45:47,980 --> 00:45:51,710
to the the person correlation coefficient

671
00:45:51,740 --> 00:45:56,020
at least in the case where you have an equal number of examples of class

672
00:45:56,020 --> 00:45:58,710
so what's special about this particular one will

673
00:45:58,730 --> 00:46:02,120
i sing about this particular one is that there's nothing even close to it right

674
00:46:02,120 --> 00:46:04,360
so it's far away from all the data points

675
00:46:04,360 --> 00:46:05,940
all right so

676
00:46:05,960 --> 00:46:06,730
with this

677
00:46:06,750 --> 00:46:08,170
blue buffer area

678
00:46:08,170 --> 00:46:11,030
it's called the margin for that particular

679
00:46:11,090 --> 00:46:13,140
a hyperplane OK

680
00:46:13,960 --> 00:46:15,280
the number of features

681
00:46:15,290 --> 00:46:17,570
and learning does matter OK

682
00:46:17,570 --> 00:46:20,850
but it doesn't matter if the margin is white

683
00:46:20,900 --> 00:46:23,320
and the examples are somehow

684
00:46:23,330 --> 00:46:24,660
close to the origin

685
00:46:24,710 --> 00:46:27,720
all right so let's make it a little bit more concrete OK so if it's

686
00:46:27,740 --> 00:46:33,220
very very simple algorithm again this is perhaps simpler than naive bayes OK

687
00:46:34,420 --> 00:46:38,540
i'm just going to assume that two classes of called the positive one negative one

688
00:46:39,490 --> 00:46:44,130
and i want to start with a hypothesis which is just all zero vector OK

689
00:46:44,160 --> 00:46:47,460
every time i get example which members just to support vector

690
00:46:47,480 --> 00:46:50,740
and what i look at the end product of the example of the sort zero

691
00:46:51,710 --> 00:46:55,270
OK and i look at the side of that so the i'm will be positive

692
00:46:55,270 --> 00:46:58,030
or negative for this year the first time around

693
00:46:58,040 --> 00:47:00,100
OK if that's the right sign

694
00:47:00,280 --> 00:47:05,350
and then i will basically just incremental counter so every one of these recent case

695
00:47:05,360 --> 00:47:09,120
that i have every hypothesis is going to have a counter which will the number

696
00:47:09,120 --> 00:47:11,320
of times the correct prediction

697
00:47:11,330 --> 00:47:14,490
right now if it's not right that i'm just going to take the existing examples

698
00:47:14,550 --> 00:47:17,690
of vector what had

699
00:47:17,720 --> 00:47:20,830
the example that i got wrong or

700
00:47:20,830 --> 00:47:25,710
if it was a positive an example should be negative subtract example

701
00:47:25,740 --> 00:47:26,460
all right

702
00:47:26,470 --> 00:47:31,880
so will gradually over the course of hypotheses for an incremental could create new hypothesis

703
00:47:31,880 --> 00:47:36,780
to by adding an example or subtracting it with the new counter for this new

704
00:47:38,600 --> 00:47:41,610
so this is a very very simple i mean if you think about it kind

705
00:47:41,610 --> 00:47:45,940
of makes sense right so if you are continuing to to higher two well let's

706
00:47:45,940 --> 00:47:47,610
move things in the right direction

707
00:47:47,630 --> 00:47:50,460
can we remove them with this example

708
00:47:51,340 --> 00:47:53,640
and we don't want to classify

709
00:47:53,660 --> 00:47:57,120
by taking all these recent case i'm going to vote them and the number of

710
00:47:57,120 --> 00:47:59,010
votes each resupply is going to get

711
00:47:59,180 --> 00:48:01,170
is the number of times it was correct

712
00:48:01,190 --> 00:48:04,940
OK so the hypothesis that persist for a long time to get a lot of

713
00:48:04,940 --> 00:48:07,020
things right can have a high weight

714
00:48:07,090 --> 00:48:11,140
he got have an example of just sort of transient will get pretty low-wage

715
00:48:11,140 --> 00:48:14,450
so what can you say about this site so it turns out

716
00:48:15,360 --> 00:48:17,420
you can fairly easily say

717
00:48:17,430 --> 00:48:18,780
all right

718
00:48:20,190 --> 00:48:21,840
every example

719
00:48:21,880 --> 00:48:25,660
is close to the origin so what does that mean there's some number are the

720
00:48:26,540 --> 00:48:30,330
so the norm of the vector is less than or

721
00:48:30,330 --> 00:48:34,230
can just the two norm of the vector so it's it's it's within distance are

722
00:48:37,960 --> 00:48:42,440
there are some classifier dual OK so i think of one of these recent case

723
00:48:43,360 --> 00:48:46,890
if you if you can classify these things around the space then there's nothing we

724
00:48:46,890 --> 00:48:48,940
can say about but there is something

725
00:48:50,010 --> 00:48:53,020
all right this not too large exactly want say the norm is less than or

726
00:48:53,020 --> 00:48:54,200
equal to one

727
00:48:55,030 --> 00:48:56,510
and furthermore

728
00:48:56,570 --> 00:48:58,520
they get every example right

729
00:48:58,530 --> 00:49:01,260
OK i'm not only to get every example right

730
00:49:01,270 --> 00:49:02,880
OK if we look at this

731
00:49:02,890 --> 00:49:08,000
this number is here so this is inner product review in x right so the

732
00:49:08,000 --> 00:49:11,900
prediction would be the sign of that OK if we multiply that by the actual

733
00:49:11,900 --> 00:49:14,460
value which is either plus one minus one

734
00:49:15,160 --> 00:49:19,170
so this was class i multiply by plus i should get a positive number if

735
00:49:19,170 --> 00:49:23,520
it's negative and multiply by minus one or get a positive number k

736
00:49:23,540 --> 00:49:28,350
right so basically saying is greater than zero was saying that the prediction was correct

737
00:49:28,400 --> 00:49:31,470
saying is greater than some number delta

738
00:49:31,490 --> 00:49:34,690
it means that it was correct initial margin of delta

739
00:49:35,460 --> 00:49:38,670
so if there is some u that's not too large and gets right answer for

740
00:49:40,350 --> 00:49:44,180
what if there is a situation like

741
00:49:44,230 --> 00:49:47,100
this picture here where there is a wide margin

742
00:49:48,000 --> 00:49:52,870
then this particular algorithm is going to make a relatively small number of mistakes

743
00:49:53,720 --> 00:49:54,890
in the process

744
00:49:55,670 --> 00:49:59,880
covering these examples OK so the number of bits takes depends on the radius and

745
00:49:59,880 --> 00:50:00,900
the on

746
00:50:00,920 --> 00:50:03,770
the and the inverse of the margin

747
00:50:05,420 --> 00:50:09,250
that is making very relatively few mistakes it basically means is going to get most

748
00:50:09,250 --> 00:50:13,660
of these predictions correct in this online process

749
00:50:15,090 --> 00:50:16,620
OK so

750
00:50:16,630 --> 00:50:20,370
let's just can't take these mathematical things and translate them into

751
00:50:20,380 --> 00:50:22,900
four gary english for text OK

752
00:50:22,910 --> 00:50:27,420
so suppose we have text let's forget the frequencies for psychosis we just step binary

753
00:50:27,420 --> 00:50:28,950
features here one

754
00:50:30,530 --> 00:50:34,590
if that document has if every document has no more than one hundred words and

755
00:50:34,590 --> 00:50:35,910
obviously it's

756
00:50:35,940 --> 00:50:38,180
the two norm is less than one hundred

757
00:50:39,340 --> 00:50:43,220
and it's less than this is one hundred from the origin so immediately began radius

758
00:50:43,220 --> 00:50:45,120
by just saying the documents are short

759
00:50:45,130 --> 00:50:48,820
OK as i pointed out before this thing right here basically means the margin is

760
00:50:48,820 --> 00:50:49,950
at least delta

761
00:50:51,690 --> 00:50:55,590
this is a really nice result and for anyone who might want to think about

762
00:50:55,590 --> 00:50:59,070
is barred to really understand american when you look at the paper and look at

763
00:50:59,070 --> 00:51:02,040
the proof that the whole proof you can actually look at this in the slide

764
00:51:02,050 --> 00:51:04,710
when you go home not going step through it right

765
00:51:05,430 --> 00:51:09,360
it's it's something that you can really put on your head once and it's worth

766
00:51:09,360 --> 00:51:13,340
doing because it gives you into action as to why this curse of dimensionality

767
00:51:13,370 --> 00:51:14,800
doesn't hurt here

768
00:51:14,830 --> 00:51:18,260
OK so one of the lessons of this well the voted perceptron a very simple

769
00:51:19,180 --> 00:51:22,730
actually later i'll show you some experiments to show that in fact it's pretty competitive

770
00:51:22,730 --> 00:51:24,110
and lot of situations

771
00:51:24,340 --> 00:51:28,080
all right but basically what it shows you is that you can make few mistakes

772
00:51:28,080 --> 00:51:30,150
in incrementally learning OK

773
00:51:30,160 --> 00:51:34,970
right provided there is some u that small has a large margin OK so here's

774
00:51:34,970 --> 00:51:36,070
an idea

775
00:51:36,160 --> 00:51:39,850
all right this is kind of seems like a neat idea

776
00:51:39,870 --> 00:51:43,270
but it seems like kind of a silly way of coming up with that

777
00:51:43,290 --> 00:51:46,730
are approximating this number you will i just look that directly

778
00:51:46,770 --> 00:51:49,690
all right well i dislike about my books on

779
00:51:49,730 --> 00:51:53,850
optimisation and see if i can figure out how to get that you correct directly

780
00:51:53,850 --> 00:51:56,850
and in fact that's what you do when you're building the support vector machine OK

781
00:51:56,850 --> 00:52:01,850
so support vector machine you minimize the norm of view subject to some fixed margin

782
00:52:02,430 --> 00:52:07,040
not really the other way around you maximize the margin relative some bound on the

783
00:52:07,700 --> 00:52:11,160
OK so the best optimisation methods and what you do this

784
00:52:11,190 --> 00:52:14,050
i won't go into the details but they tend to work pretty well

785
00:52:14,070 --> 00:52:19,670
so again some nomenclature here so again this is a very simple idea

786
00:52:19,710 --> 00:52:24,890
but there are some fancy terms so when you're looking at

787
00:52:24,900 --> 00:52:26,630
that picture

788
00:52:26,650 --> 00:52:30,760
you should have like copy here the picture we got that big problems stripe with

789
00:52:30,760 --> 00:52:32,150
a hyperplane in the middle

790
00:52:32,150 --> 00:52:36,790
at more complex intentions this is not that clear to date

791
00:52:36,810 --> 00:52:42,060
so if you wonder who this is is obviously ten tom cruise

792
00:52:42,350 --> 00:52:48,470
and this is from the film minority report because minority report is movie that uses

793
00:52:48,470 --> 00:52:49,550
very similar

794
00:52:49,650 --> 00:52:51,110
the idea

795
00:52:51,140 --> 00:52:55,600
with the kind of different biological substrate obviously two

796
00:52:55,600 --> 00:53:00,600
predict crime and this is just here to remind people that the technical applications that

797
00:53:00,600 --> 00:53:05,430
you can get out of this this research model also something that

798
00:53:05,480 --> 00:53:11,360
it's possibly worth looking into but also has a specific ethical dilemmas raised with them

799
00:53:11,370 --> 00:53:13,300
but we could also talk about

800
00:53:14,900 --> 00:53:18,340
so if we how do we explain

801
00:53:18,420 --> 00:53:20,100
people's behavior

802
00:53:22,100 --> 00:53:25,140
especially in psychology there's a long history

803
00:53:25,160 --> 00:53:29,590
of trying to explain behavior based on conditioning for example

804
00:53:29,640 --> 00:53:35,030
stimulus response conditioning response stimulus conditioning and so on and so the idea is that

805
00:53:35,030 --> 00:53:41,290
what happens if mouse for example learns a route towards this target here the route

806
00:53:41,290 --> 00:53:48,840
is ultimately given to this animal by a sequence of stimuli that are associated with

807
00:53:48,840 --> 00:53:55,080
rewards and ultimately what the animal is doing is driven by the external sensory stimuli

808
00:53:55,080 --> 00:54:02,520
that cause specific rewards expectations possibly but this reward expectation wasn't mentioned in the papers

809
00:54:02,530 --> 00:54:06,100
and talk about that and then you ultimately under the control of your environment you're

810
00:54:06,100 --> 00:54:10,010
under control of the reward structure of the environment

811
00:54:10,540 --> 00:54:17,630
and obviously this is very impoverished way of explaining human behavior and so in the

812
00:54:17,630 --> 00:54:23,120
nineteen sixties miller galanter program came up with the rather different model this is kind

813
00:54:23,120 --> 00:54:30,190
of a related graph but the basic idea is that you don't understand trying to

814
00:54:30,190 --> 00:54:33,530
understand behavior based on the external stimulation

815
00:54:33,540 --> 00:54:38,970
but you try and understand behavior based on internal states and these internal states our

816
00:54:38,970 --> 00:54:43,290
goal states that them the organism is trying to pursue

817
00:54:43,300 --> 00:54:48,340
so you can think of this so some kind of feedback from higher order systems

818
00:54:48,420 --> 00:54:53,580
introduces the reference signal some kind of target signal and then what you do is

819
00:54:53,580 --> 00:54:59,020
you find out whether your system is in a different state than your desired goal

820
00:54:59,020 --> 00:55:04,990
state statement is absolutely trivial and then what you do is you perform an operation

821
00:55:06,110 --> 00:55:10,540
you have an effect on the environment and then you perceive the environment again and

822
00:55:10,540 --> 00:55:15,880
then you test again to see if your environment has changed towards the goal you

823
00:55:15,880 --> 00:55:20,490
want to have for example examples of the uses for example using a hammer

824
00:55:20,840 --> 00:55:23,490
and and then you have to for example if you want to put put the

825
00:55:23,500 --> 00:55:27,660
nail into the into the wood then you have to minimize the distance between the

826
00:55:27,660 --> 00:55:31,890
head of the nail and and and and and the bottom end of the wood

827
00:55:32,310 --> 00:55:35,680
and then you have to nail it in and then the distance gets minimize this

828
00:55:35,680 --> 00:55:39,570
is a very simple example but most motor movements of course related

829
00:55:39,580 --> 00:55:44,110
well the basic idea is now we've got this different approach which is an internal

830
00:55:44,110 --> 00:55:48,790
reference signal and the question is where all these internal reference signals these goals stored

831
00:55:48,790 --> 00:55:49,750
in the brain

832
00:55:49,770 --> 00:55:54,080
and i'll show you three different approaches but first let me just talk about the

833
00:55:54,080 --> 00:55:56,400
technique be using

834
00:55:56,420 --> 00:55:58,680
we use bold for my

835
00:55:58,700 --> 00:56:05,210
and classically people have used bullet for my to study the brain and the resolution

836
00:56:05,210 --> 00:56:09,590
of approximately three millimetres and the reason is you can't make these voxels much smaller

837
00:56:09,790 --> 00:56:14,920
you can make the box much smaller than say one millimetre is already pushing it

838
00:56:15,220 --> 00:56:21,540
and this is perfectly sufficient because classically psychology and you're psychologists think of the brain

839
00:56:21,610 --> 00:56:25,430
in terms of broad money areas they don't think of it in terms of cells

840
00:56:25,470 --> 00:56:30,910
or columns but they think of it the basic units of neuropsychology brotman areas and

841
00:56:30,910 --> 00:56:37,910
this brought areas have several cubic centimeters and obviously if you have a voxel that

842
00:56:37,910 --> 00:56:42,790
has three millimeter resolution you're pretty good if what you're interested in this problem areas

843
00:56:42,800 --> 00:56:44,990
but it seems that the information

844
00:56:45,010 --> 00:56:48,990
is not stored discourse level but it stored in a much finer level as i

845
00:56:48,990 --> 00:56:52,430
will talk about in the second and what you measure measuring each of these volume

846
00:56:52,430 --> 00:56:58,940
units here is the change in the oxygenation level of the blood that's ultimately

847
00:56:58,990 --> 00:57:04,460
is the consequent well leads to certain changes in the magnetic properties of the blood

848
00:57:06,530 --> 00:57:08,930
this was skip this

849
00:57:09,890 --> 00:57:14,160
the problem is that if you want to if you're interested in the storage of

850
00:57:14,160 --> 00:57:18,160
detailed content that are relevant for cognitive processes

851
00:57:18,180 --> 00:57:26,000
then electrophysiology and optical imaging have shown us that the storage of this fine grain

852
00:57:26,590 --> 00:57:32,160
the details of say for example visual objects that we recognise stored in the fine

853
00:57:32,160 --> 00:57:38,510
grained cortical pat tern colony patter with the resolution of say around half a millimetre

854
00:57:38,510 --> 00:57:40,370
or bit smaller

855
00:57:40,390 --> 00:57:42,420
and the problem now

856
00:57:42,430 --> 00:57:47,210
you find very similar topography is for example for object features in the temporal lobe

857
00:57:47,290 --> 00:57:52,040
and you find very similar structures also in the visual only visual cortex and the

858
00:57:52,040 --> 00:57:58,970
one of the famous boehm will pattern that describes the distribution of selectivity of cells

859
00:57:59,220 --> 00:58:03,650
to different orientations the release so these are the different orientations and each color here

860
00:58:03,700 --> 00:58:09,520
tells you where cells with a specific orientation preference

861
00:58:10,580 --> 00:58:18,540
this column in architecture the basic the basic anatomical hardware

862
00:58:18,560 --> 00:58:24,550
exists also in prefrontal cortex has begun to prefrontal cortex you find similar structures that

863
00:58:24,550 --> 00:58:27,680
so the from the is same sort of work that i do when i pushed

864
00:58:28,600 --> 00:58:31,490
i get back in terms of gravitational potential energy

865
00:58:31,500 --> 00:58:35,010
by lifting the car

866
00:58:35,020 --> 00:58:38,240
so if i wanted to move the car by one metre

867
00:58:38,280 --> 00:58:40,180
and if the ratios hundred to one

868
00:58:40,200 --> 00:58:42,800
i would have to move down by hunt me

869
00:58:42,810 --> 00:58:46,390
that's a little bit on practical so these hydraulic presses i designed in such a

870
00:58:47,100 --> 00:58:49,570
you can just check it like that every time

871
00:58:49,580 --> 00:58:51,020
to bring it up

872
00:58:51,070 --> 00:58:53,750
the liquid flows back in again into this

873
00:58:53,800 --> 00:58:56,010
the site of the hydraulic jack

874
00:58:56,010 --> 00:58:57,570
but in the end you have to go

875
00:58:57,570 --> 00:58:59,910
effectively a hundred meters then

876
00:58:59,960 --> 00:59:01,740
but it can't to go up

877
00:59:01,750 --> 00:59:05,070
by one if the ratio is hundred one

878
00:59:06,140 --> 00:59:08,380
no gravity of course has an effect

879
00:59:08,410 --> 00:59:10,380
on the pressure in the fluid

880
00:59:10,430 --> 00:59:12,780
if you go down into the oceans

881
00:59:12,800 --> 00:59:14,140
we know that the pressure

882
00:59:14,200 --> 00:59:16,000
will go up and that is the result

883
00:59:16,070 --> 00:59:18,950
of gravity

884
00:59:18,960 --> 00:59:21,760
and i would like to derive

885
00:59:22,520 --> 00:59:26,450
pressure increase

886
00:59:26,460 --> 00:59:27,440
this b

887
00:59:27,450 --> 00:59:31,010
the direction of increasing y

888
00:59:31,060 --> 00:59:33,710
and i choose a

889
00:59:33,720 --> 00:59:39,710
liquid elements of this is in the liquid itself

890
00:59:39,740 --> 00:59:43,080
i can choose in any shape that i want to i just taken nice horizontal

891
00:59:44,690 --> 00:59:46,310
and this is every eight

892
00:59:46,330 --> 00:59:49,070
so the bottom is also a

893
00:59:49,130 --> 00:59:51,510
and let this be at height

894
00:59:51,520 --> 00:59:53,890
white was delta y

895
00:59:53,910 --> 00:59:55,780
and this is the y

896
00:59:55,880 --> 00:59:58,520
and the pressure here

897
00:59:58,530 --> 01:00:00,510
his wife was built y

898
01:00:00,570 --> 01:00:03,550
and the pressure here

899
01:00:05,700 --> 01:00:08,040
and this object has amassed

900
01:00:08,050 --> 01:00:09,310
delta and

901
01:00:09,410 --> 01:00:10,450
in the liquid

902
01:00:10,460 --> 01:00:14,450
has a density rho which could be a function of y we leave it open

903
01:00:14,450 --> 01:00:16,470
for now

904
01:00:16,670 --> 01:00:17,870
and so

905
01:00:17,880 --> 01:00:19,150
this mass

906
01:00:19,200 --> 01:00:21,530
the math that i have here is the volume

907
01:00:21,570 --> 01:00:22,950
times the density

908
01:00:23,040 --> 01:00:24,780
the volume is n

909
01:00:25,800 --> 01:00:28,440
i don't know why

910
01:00:28,450 --> 01:00:33,430
then times the density which may be function y

911
01:00:33,440 --> 01:00:34,920
so if i put in

912
01:00:34,930 --> 01:00:37,230
all the forces at work here

913
01:00:37,420 --> 01:00:39,400
is gravity

914
01:00:39,410 --> 01:00:41,380
which is delta and

915
01:00:41,400 --> 01:00:42,870
i'm sitting

916
01:00:42,930 --> 01:00:44,880
in this direction

917
01:00:45,950 --> 01:00:46,830
i have

918
01:00:46,880 --> 01:00:48,630
four upwards

919
01:00:48,710 --> 01:00:52,870
due to the pressure of the fluid that's what we want to evaluate

920
01:00:52,880 --> 01:00:54,650
it's always perpendicular

921
01:00:55,450 --> 01:00:58,060
the services we talked about earlier

922
01:00:58,070 --> 01:01:01,770
so in this idea comes in like this year comes in like this the force

923
01:01:01,770 --> 01:01:03,830
from the bottom it comes in like this

924
01:01:03,840 --> 01:01:05,380
and from the top

925
01:01:05,400 --> 01:01:06,520
i call this

926
01:01:07,570 --> 01:01:08,490
i only

927
01:01:09,780 --> 01:01:11,090
the vertical direction

928
01:01:11,100 --> 01:01:13,540
because all forces in the horizontal plane

929
01:01:13,550 --> 01:01:17,590
will counsel for obvious reasons

930
01:01:17,610 --> 01:01:20,110
so now it has to be equally

931
01:01:20,170 --> 01:01:25,050
this fluid element is not going anywhere sitting still in the fluid

932
01:01:25,090 --> 01:01:27,840
and so i now have that everyone

933
01:01:27,920 --> 01:01:30,610
in this direction

934
01:01:30,670 --> 01:01:32,740
miners have two

935
01:01:32,800 --> 01:01:34,540
gold and

936
01:01:35,860 --> 01:01:37,330
it is zero

937
01:01:37,370 --> 01:01:39,180
only then is fluid element

938
01:01:39,210 --> 01:01:41,570
static equilibria

939
01:01:41,580 --> 01:01:43,120
but everyone

940
01:01:43,160 --> 01:01:46,120
is this pressure times the area

941
01:01:46,210 --> 01:01:47,400
what is the

942
01:01:47,450 --> 01:01:48,500
level why

943
01:01:48,530 --> 01:01:49,920
i'm ever

944
01:01:49,990 --> 01:01:51,340
f two

945
01:01:51,350 --> 01:01:52,570
it's the

946
01:01:52,570 --> 01:01:54,420
level was delta y

947
01:01:54,430 --> 01:01:59,180
times area

948
01:02:01,830 --> 01:02:03,690
delta is the delta

949
01:02:03,700 --> 01:02:05,810
y times role

950
01:02:05,820 --> 01:02:07,860
so i could minus eight

951
01:02:07,870 --> 01:02:09,950
and delta y

952
01:02:10,000 --> 01:02:11,330
which could be function

953
01:02:11,380 --> 01:02:13,810
could be function y g

954
01:02:13,950 --> 01:02:17,200
and that equals zero

955
01:02:17,210 --> 01:02:20,070
notice i lose my area

956
01:02:20,250 --> 01:02:25,170
i'm going to rearrange this slightly and divide by delta y

957
01:02:25,210 --> 01:02:27,350
so i get that

958
01:02:27,350 --> 01:02:33,170
with some positive L  H is just that there's no condition on H then you

959
01:02:33,170 --> 01:02:38,270
can show that prox the proximal gradient method converges and that

960
01:02:38,270 --> 01:02:45,290
the distance to the optimum decreases as one over K times something that depends on

961
01:02:45,290 --> 01:02:50,050
the distance of the starting point to the solution and then this L in the

962
01:02:50,390 --> 01:02:56,090
Lipschitz condition so this is much faster than the subgradient method in the subgradient

963
01:02:56,090 --> 01:03:02,890
method  I might have forgot to say this but when we had in the subgradient

964
01:03:02,890 --> 01:03:07,130
method as a convergence result was one over square root K instead of one over

965
01:03:07,140 --> 01:03:14,330
K so this is quite a bit faster than the subgradient method and it's less general

966
01:03:14,330 --> 01:03:20,270
because it applies only to problems that can be written like this with an inexpensive prox operator H

967
01:03:20,270 --> 01:03:34,060
this is clear so this is quite classic this approximate gradient method and

968
01:03:34,060 --> 01:03:38,230
then more recently in the last ten years or so people have studied faster

969
01:03:38,230 --> 01:03:46,350
versions of the proximal gradient method and they're  actually several different variations on these fast

970
01:03:46,350 --> 01:03:54,850
methods it goes back to work by Nestrov in the nineteen eighties who tried to

971
01:03:54,850 --> 01:03:59,610
improve on this one over K convergence of the gradient method or a proximal gradient method

972
01:03:59,850 --> 01:04:06,090
so he developed fast versions of the gradient projection method and the gradient method with a

973
01:04:06,090 --> 01:04:12,310
one over K squared convergence instead of the one over K convergence we

974
01:04:12,310 --> 01:04:20,890
had here and for the same conditions on G so that's very interesting

975
01:04:20,890 --> 01:04:26,070
in practice because it means that if you want an accuracy epsilon  for example

976
01:04:26,090 --> 01:04:35,600
there's a big difference between obtaining that in ov one  over epsilon iterations or

977
01:04:35,600 --> 01:04:40,810
one over a square root of one over epsilon right its diff difference between ten thousand

978
01:04:40,810 --> 01:04:47,110
iterations or a hundred iterations so increasing this from K to K squared is actually important in

979
01:04:47,110 --> 01:04:51,630
practice so that's what he did in the eighties and he also showed that again

980
01:04:51,640 --> 01:04:56,370
for the same category of problems it's not possible to improve this one over K

981
01:04:56,370 --> 01:05:01,330
squared so he called this an optimal method because this rate of convergence is optimal

982
01:05:01,330 --> 01:05:05,830
within this class of algorithms and this class of problems

983
01:05:06,670 --> 01:05:13,030
so  since the last ten years people have really worked on these methods

984
01:05:13,030 --> 01:05:18,770
very intensively so one popular method is called FISTA it stands for fast

985
01:05:18,770 --> 01:05:25,260
iterative shrinkage thresholding algorithm but it's actually quite general it's a fast proximal gradient method

986
01:05:25,270 --> 01:05:29,930
so it actually extends these methods one of these methods by Nestrov to the proximal

987
01:05:29,930 --> 01:05:36,110
gradient method and then there are several other versions that have similar complexity but different

988
01:05:36,110 --> 01:05:42,560
advantages so here are just a few things about this FISTA method so the FISTA method

989
01:05:42,570 --> 01:05:46,570
is very general it applies t it's very simple it applies to the same

990
01:05:46,570 --> 01:05:49,950
class of problems that we had before in the proximal gradient method you have a

991
01:05:49,950 --> 01:05:59,270
composite objective with the differentiable G and a non-differentiable H and again the only condition you need for

992
01:05:59,280 --> 01:06:05,110
H is that it has an inexpensive prox operator so the FISTA method is actually a

993
01:06:05,110 --> 01:06:09,910
simple extension so instead of one series of iterates X you have two X

994
01:06:09,910 --> 01:06:16,710
and Y and at each step you apply the standard proximal gradient update to Y and

995
01:06:16,770 --> 01:06:23,230
you call that X and then your next value of Y is an actually an extrapolated

996
01:06:23,240 --> 01:06:30,750
version of X so this is a standard proximal gradient update but at Y

997
01:06:31,290 --> 01:06:36,510
and then you use this X K  to construct your next Y K and K is the

998
01:06:36,510 --> 01:06:43,750
iteration number so you see that very soon this coefficient here in front goes to one right

999
01:06:43,750 --> 01:06:48,990
so that's the FISTA method so you can interpret it geometrically like this suppose these

1000
01:06:48,990 --> 01:06:55,330
are your iterates  X at iteration K minus  two at K minus one so

1001
01:06:55,950 --> 01:07:02,530
so at those iterations you would make this extrapolation so you'd take X K and you add to it a multiple

1002
01:07:02,530 --> 01:07:07,710
of the previous step a multiple that's almost equal to one so that's this you

1003
01:07:07,710 --> 01:07:12,090
take X K minus one you add to it previous step and that gives you a Y K

1004
01:07:12,090 --> 01:07:17,890
minus one then you apply the proximal the standard proximal gradient step to this point that gives you a

1005
01:07:17,890 --> 01:07:23,530
point here for example and that's where  you move from X that becomes your next X K

1006
01:07:23,570 --> 01:07:27,070
so it's sort of an a gradient step with extrapolation

1007
01:07:27,790 --> 01:07:36,330
and you can maybe intuitively interpret it as an a method for improving on this zig-zaging behavior in

1008
01:07:36,330 --> 01:07:39,610
the gradient method by this extrapolation

1009
01:07:39,630 --> 01:07:45,850
but there's a very  sort of interesting convergence theory for this method and the result

1010
01:07:45,850 --> 01:07:50,150
is that under the same conditions as for the proximal gradient method you get instead

1011
01:07:50,150 --> 01:07:57,110
of one over K in the   convergence rate you get one over K squared by just

1012
01:07:57,110 --> 01:08:05,550
using this simple extension of a proximate gradient method is that clear also in practice it turns out to

1013
01:08:05,550 --> 01:08:12,410
be actually  to work quite well so this is an example where you

1014
01:08:12,410 --> 01:08:19,350
just apply it to a differentiable function so just a gradient method and the fast gradient method

1015
01:08:19,690 --> 01:08:26,730
yes maybe this is not the best example but this the  blue curve would be the gradient method the green

1016
01:08:26,730 --> 01:08:32,470
dashed line is the proximal  the the fast gradient method to you see it actually converges much

1017
01:08:32,470 --> 01:08:38,310
faster and it reaches in this case a very good accuracy one difference is that the

1018
01:08:38,310 --> 01:08:42,920
FISTA is not a descent method like the gradient method so the convergence is not

1019
01:08:42,920 --> 01:08:48,040
each chapel contains confidence which means that the

1020
01:08:48,480 --> 01:08:55,260
people person names smith has a social security number one eighty five this event only

1021
01:08:55,260 --> 01:08:58,760
happened with confidence of forty percent

1022
01:08:58,800 --> 01:09:04,700
so we have one record it to represent each different the case in this social

1023
01:09:04,700 --> 01:09:06,280
survey data

1024
01:09:06,320 --> 01:09:09,910
and on top of that we have generation rules

1025
01:09:10,010 --> 01:09:16,590
because the person names mister can only have one correct social security numbers so between

1026
01:09:16,610 --> 01:09:20,290
t one and t two only one can be true

1027
01:09:20,340 --> 01:09:25,680
also because rock only has one correct social security number though

1028
01:09:25,690 --> 01:09:29,040
between t three and t four only one can be true

1029
01:09:29,050 --> 01:09:34,350
and also because one eighty five is assigned to smith and brian stable but we

1030
01:09:34,350 --> 01:09:35,660
know that one

1031
01:09:35,670 --> 01:09:40,730
correct number only belong to one person so we have a generation rule

1032
01:09:40,740 --> 01:09:43,660
between t one and t three as well

1033
01:09:43,710 --> 01:09:50,230
this is the how we describe the uncertainty in this example

1034
01:09:50,370 --> 01:09:56,830
as another example in the

1035
01:09:56,870 --> 01:10:02,920
o example we may two different things that we talk about in the first part

1036
01:10:03,040 --> 01:10:06,660
for example a very common method is to use record linkage

1037
01:10:06,670 --> 01:10:10,150
the associated this one with some external

1038
01:10:10,660 --> 01:10:16,960
sources to design that seventy four percent confidence to topple

1039
01:10:16,970 --> 01:10:24,980
so this is something we know that we describe it in their probabilistic table

1040
01:10:25,030 --> 01:10:28,300
so for example if the five NBA players

1041
01:10:28,330 --> 01:10:33,790
we know that has the capability of NBA players is crucial thing for selecting good

1042
01:10:33,800 --> 01:10:35,080
players for good

1043
01:10:35,120 --> 01:10:36,440
basketball teams

1044
01:10:36,480 --> 01:10:40,420
but how to evaluate the capability is quite difficult

1045
01:10:41,030 --> 01:10:47,730
typically we use the technical statistics of NBA players to estimate that capability

1046
01:10:47,780 --> 01:10:52,870
for example here we think about and two attributes number of rebounds and number of

1047
01:10:54,340 --> 01:11:03,670
so here one point represents the number of reponsible points in one game

1048
01:11:03,730 --> 01:11:07,830
so all in all points belong to the player brian

1049
01:11:07,840 --> 01:11:11,100
and already points belong to the player you

1050
01:11:11,190 --> 01:11:17,390
so you this data we know that the probability of you and the not certain

1051
01:11:17,400 --> 01:11:22,390
there a distribution on this to space

1052
01:11:22,420 --> 01:11:28,220
so this introduce another that another example of

1053
01:11:28,350 --> 01:11:32,660
uncertain data models this is called the uncertain up

1054
01:11:32,710 --> 01:11:36,670
so you example we know that you have is an object

1055
01:11:36,680 --> 01:11:40,440
and you can take different values so

1056
01:11:40,910 --> 01:11:43,860
we use a sample to represent object

1057
01:11:43,870 --> 01:11:49,540
and also for brand we use blue samples to represent this object

1058
01:11:49,680 --> 01:11:54,750
and this is different from the uncertain probabilistic table models

1059
01:11:54,800 --> 01:12:00,580
so here in uncertain objects and object is uncertain if you attributes like a number

1060
01:12:00,580 --> 01:12:02,920
of points and number of everybody

1061
01:12:02,960 --> 01:12:09,120
but we use to sample and or a probability density function to describe the uncertainty

1062
01:12:09,120 --> 01:12:13,560
on this object

1063
01:12:13,590 --> 01:12:15,560
another example

1064
01:12:15,610 --> 01:12:21,460
we know that nowadays it's quite useful to track the location of a moving object

1065
01:12:21,500 --> 01:12:27,090
that the famous i has built in GPS so that you can report the UK

1066
01:12:27,100 --> 01:12:28,850
report the location of

1067
01:12:28,920 --> 01:12:31,040
your current location

1068
01:12:31,040 --> 01:12:33,350
but due to the

1069
01:12:33,400 --> 01:12:38,400
pure radical reporting mechanism of the affection of other like tall buildings

1070
01:12:38,440 --> 01:12:43,930
so we are close to the tall buildings in location may not be precisely reported

1071
01:12:43,940 --> 01:12:45,870
so this

1072
01:12:45,920 --> 01:12:48,400
example we have formal the objects

1073
01:12:48,420 --> 01:12:50,600
a b c d and e

1074
01:12:50,610 --> 01:12:56,420
the location of the moving objects are not precise we can only know the possible

1075
01:12:56,430 --> 01:12:58,840
region of each object

1076
01:12:58,850 --> 01:13:03,990
so in this example each moving objects is set up to it

1077
01:13:04,000 --> 01:13:11,160
and that one point in the possible region it's possible instances of this sort of

1078
01:13:11,210 --> 01:13:18,890
and then we may use like uniform distribution on august distribution to describe their probability

1079
01:13:18,930 --> 01:13:24,060
and also in the example we can also use set up to model to describe

1080
01:13:24,060 --> 01:13:25,710
the incident

1081
01:13:25,750 --> 01:13:29,940
for example here we have two persons smith and abroad

1082
01:13:29,990 --> 01:13:34,060
each one can be modeled as one uncertain object

1083
01:13:34,070 --> 01:13:40,960
if we only consider name and social security numbers we know that because we can

1084
01:13:40,960 --> 01:13:42,430
this is the probability

1085
01:13:42,450 --> 01:13:44,930
one is the probability of the set

1086
01:13:46,020 --> 01:13:49,820
samples which satisfies this formula

1087
01:13:49,900 --> 01:13:52,460
but that does for the formalism

1088
01:13:52,520 --> 01:13:55,030
you may ignore it

1089
01:13:56,370 --> 01:14:01,150
anyway we rewrite this probability is the probability of this union of two events

1090
01:14:02,560 --> 01:14:04,930
then the right hand side we can rewrite

1091
01:14:05,460 --> 01:14:08,330
the probability of this union of these two invent

1092
01:14:08,380 --> 01:14:10,420
is equal to the probability

1093
01:14:10,460 --> 01:14:11,980
of the individual events

1094
01:14:12,020 --> 01:14:15,250
one minus the probability that both of them occur at the same time so this

1095
01:14:15,250 --> 01:14:16,650
is the standard

1096
01:14:16,710 --> 01:14:18,750
formula for probability theory

1097
01:14:18,890 --> 01:14:22,770
these probabilities are non negative we can throw with this term therefore get an upper

1098
01:14:22,770 --> 01:14:27,290
bound on the probability of the union so this is called the union bound but

1099
01:14:27,290 --> 01:14:29,150
it's just trivial thing for

1100
01:14:29,150 --> 01:14:30,880
probability theory

1101
01:14:31,820 --> 01:14:36,200
and you can see that this this is an upper bound and you're losing something

1102
01:14:36,200 --> 01:14:42,720
in this of aren't exactly when these events are not disjoint

1103
01:14:43,910 --> 01:14:46,710
we can plug in this upper bound

1104
01:14:46,720 --> 01:14:50,640
get an apology on the right-hand side which will look like this are probability of

1105
01:14:50,640 --> 01:14:54,960
interest is upper bounded by the sum of these two probabilities

1106
01:14:54,980 --> 01:14:58,620
now for these two probabilities we've only

1107
01:14:58,620 --> 01:15:03,670
i mean you to these events only depends on one fixed function only one function

1108
01:15:03,680 --> 01:15:06,370
so therefore for these we can use the channel islands

1109
01:15:06,460 --> 01:15:07,320
to them

1110
01:15:07,380 --> 01:15:09,960
so we get the same kind of long term here

1111
01:15:10,020 --> 01:15:13,660
only we have factor two in front of it

1112
01:15:13,700 --> 01:15:18,300
and you can probably see the same thing of course works for finite limit functions

1113
01:15:18,330 --> 01:15:21,540
we have a classifier functions we decompose

1114
01:15:21,770 --> 01:15:23,620
this event

1115
01:15:23,630 --> 01:15:24,750
the supremum

1116
01:15:24,780 --> 01:15:25,920
of these

1117
01:15:25,930 --> 01:15:30,180
differences in risks being larger than epsilon as a union

1118
01:15:30,220 --> 01:15:34,190
the probability of the union of a finite number of events

1119
01:15:34,200 --> 01:15:35,650
and then we can

1120
01:15:35,680 --> 01:15:39,740
apply the channel on the find finite amount of time so we get

1121
01:15:39,770 --> 01:15:44,680
despite the number appearing here

1122
01:15:46,360 --> 01:15:47,660
in this case we get

1123
01:15:49,450 --> 01:15:53,500
where we just have to factor in over here but it is a factor in

1124
01:15:53,530 --> 01:15:58,630
the size of the graph doesn't disturb us the least because we have exponentially

1125
01:15:58,630 --> 01:16:00,530
converges to zero here

1126
01:16:00,680 --> 01:16:05,790
so what happens if we have infinitely many functions

1127
01:16:05,820 --> 01:16:10,470
it's interesting case because if we put an infinite number here than the bound becomes

1128
01:16:11,950 --> 01:16:14,810
during the sense that it will not tell us any more

1129
01:16:15,650 --> 01:16:18,120
things go to zero

1130
01:16:18,130 --> 01:16:21,160
so in a way you could you could already receive

1131
01:16:21,180 --> 01:16:24,410
if we put a finite number here

1132
01:16:24,420 --> 01:16:26,960
and everything is easy in this will go to

1133
01:16:26,980 --> 01:16:29,450
zero exponentially fast

1134
01:16:29,570 --> 01:16:34,180
but you can see we could even put something here which is not a constant

1135
01:16:34,220 --> 01:16:36,460
something that increases with

1136
01:16:36,460 --> 01:16:38,820
with the number of of points that we've seen

1137
01:16:38,870 --> 01:16:41,520
so we could put something here that increases with a man as long as it

1138
01:16:41,520 --> 01:16:44,790
doesn't increase exponentially fast with him

1139
01:16:44,810 --> 01:16:49,510
we would still win because the this thing goes to zero exponentially fast

1140
01:16:49,550 --> 01:16:51,960
and we would like the function class

1141
01:16:52,740 --> 01:16:55,070
given n examples

1142
01:16:56,580 --> 01:16:57,890
to be

1143
01:16:57,930 --> 01:16:59,430
growing with n

1144
01:16:59,440 --> 01:17:05,230
sub exponentially

1145
01:17:10,470 --> 01:17:11,250
the trick

1146
01:17:11,270 --> 01:17:12,810
is the following

1147
01:17:12,860 --> 01:17:17,150
the empirical risk only refers to m points

1148
01:17:17,160 --> 01:17:19,470
so on these points the functions

1149
01:17:19,520 --> 01:17:21,020
the function class can

1150
01:17:21,030 --> 01:17:24,770
take at most two trillion dollars because i need to point the functions take values

1151
01:17:24,770 --> 01:17:27,780
plus one minus one

1152
01:17:27,850 --> 01:17:29,500
so on points

1153
01:17:29,520 --> 01:17:31,190
given only in points

1154
01:17:31,190 --> 01:17:32,720
then the function class

1155
01:17:32,780 --> 01:17:38,180
it has to take at least two possible values from this point so no matter

1156
01:17:38,180 --> 01:17:40,220
how big function class is

1157
01:17:40,240 --> 01:17:43,960
it's effective size is at most two to the

1158
01:17:43,980 --> 01:17:49,440
so the effective size which plugin here is administratively and of course to the bad

1159
01:17:49,450 --> 01:17:52,800
has to the and would be an exponential increase in here we have an exponential

1160
01:17:52,800 --> 01:17:55,970
decay and we don't know what's going to happen

1161
01:17:56,000 --> 01:17:57,720
however if the function class

1162
01:17:58,560 --> 01:18:01,660
growth more slowly than to to the

1163
01:18:01,700 --> 01:18:05,430
and we are only interested in the limit so we only interesting whether at some

1164
01:18:06,880 --> 01:18:10,740
will start growing more slowly than to to the if that's the case then we're

1165
01:18:10,740 --> 01:18:14,720
in business

1166
01:18:17,820 --> 01:18:23,500
so we almost find i've told you that

1167
01:18:23,510 --> 01:18:24,760
over here

1168
01:18:24,770 --> 01:18:27,540
we have something that's which effectively

1169
01:18:29,190 --> 01:18:31,480
at most it grows like to the

1170
01:18:31,490 --> 01:18:33,540
but maybe if we have some

1171
01:18:33,610 --> 01:18:36,570
i thought that might grow more slowly

1172
01:18:36,580 --> 01:18:38,530
over here we still have this

1173
01:18:38,540 --> 01:18:42,620
actual risk which depends on the whole distribution we don't like that so we would

1174
01:18:42,620 --> 01:18:43,700
like to

1175
01:18:43,850 --> 01:18:46,010
remove this thing here also

1176
01:18:46,070 --> 01:18:50,500
rewrite in terms of something that on a given sample with the finite

1177
01:18:50,560 --> 01:18:53,720
and the way to do this is to use something about the two things have

1178
01:18:53,720 --> 01:18:55,810
called symmetrisation

1179
01:18:55,870 --> 01:18:58,670
and this following

1180
01:18:58,680 --> 01:19:01,200
and i'm not going to spend too much time on this

1181
01:19:01,250 --> 01:19:05,080
here the idea is this quantity that we really interested in

1182
01:19:05,100 --> 01:19:06,730
can be upper bounded

1183
01:19:06,860 --> 01:19:09,280
in terms of another quantity

1184
01:19:09,360 --> 01:19:13,490
which no longer talks about the difference between the training error and test error but

1185
01:19:13,490 --> 01:19:16,720
it talks about the difference between two training errors

1186
01:19:16,750 --> 01:19:19,560
one two different examples

1187
01:19:19,610 --> 01:19:24,170
and you know we're heading the ones i have this upper bound this quantity

1188
01:19:24,190 --> 01:19:28,290
in terms of this quantity involving two training errors

1189
01:19:28,310 --> 01:19:32,440
once have this i can apply this modified chernoff bound which i showed you when

1190
01:19:32,440 --> 01:19:37,120
i first introduced the telephone modify channel one that was talking about the difference between

1191
01:19:37,120 --> 01:19:40,010
two empirical means

1192
01:19:40,060 --> 01:19:41,180
so i can then

1193
01:19:41,220 --> 01:19:45,920
by this modified telephone and here i have only this nice empirical quantities that depend

1194
01:19:45,940 --> 01:19:48,100
on n points each

1195
01:19:48,100 --> 01:19:49,800
and m points each

1196
01:19:49,820 --> 01:19:52,660
function class effectively finite

1197
01:19:52,660 --> 01:19:56,000
you can look like class of size two to the

1198
01:19:56,100 --> 01:20:03,460
but if we have a nice function maybe will look much smaller

1199
01:20:04,300 --> 01:20:09,550
i think we were almost end here but i'm just wondering whether i should just

1200
01:20:09,550 --> 01:20:12,600
give you the main idea i to years and then we can maybe go through

1201
01:20:12,600 --> 01:20:15,560
it again next time so i'll just give you an overview of

1202
01:20:15,620 --> 01:20:20,070
how things are going to work and then we will briefly review the next time

1203
01:20:20,130 --> 01:20:25,440
i think about how to get the remaining time in the next to so

1204
01:20:25,450 --> 01:20:27,410
roughly speaking work was

1205
01:20:27,420 --> 01:20:28,660
we will introduce

1206
01:20:28,680 --> 01:20:32,410
a the quantity called the shattering coefficient

1207
01:20:32,450 --> 01:20:36,760
which will be something like the maximum size of a function class

1208
01:20:36,820 --> 01:20:39,210
on a certain number of points

1209
01:20:39,220 --> 01:20:43,520
so let's call this thing calligraphy

1210
01:20:43,520 --> 01:20:45,470
down in the basement

1211
01:20:45,510 --> 01:20:48,240
so let's indicate that with

1212
01:20:48,280 --> 01:20:50,820
classical symbol and this

1213
01:20:50,870 --> 01:20:53,540
altogether put out about twenty volts

1214
01:20:53,560 --> 01:20:57,340
and then what he did as he was a professor of physics understood some electrical

1215
01:20:57,340 --> 01:21:00,720
engineering so he had choke coil here

1216
01:21:00,760 --> 01:21:03,800
so chill climate would take the the current

1217
01:21:03,820 --> 01:21:07,150
store up and eight times the second

1218
01:21:07,160 --> 01:21:09,670
eight times a second

1219
01:21:09,720 --> 01:21:11,000
it would discharge

1220
01:21:11,010 --> 01:21:12,760
and would discharge at

1221
01:21:12,770 --> 01:21:15,350
thirty five thousand volts

1222
01:21:15,370 --> 01:21:18,490
so he could take twenty volts and upper two

1223
01:21:18,620 --> 01:21:23,420
thirty five thousand by the use of this choke or so a times the second

1224
01:21:23,460 --> 01:21:27,180
he had thirty five thousand volts coming off

1225
01:21:28,220 --> 01:21:32,680
cathode here's you've got bam bam bam bam and speed up about eight times and

1226
01:21:32,680 --> 01:21:37,260
that's what that's what's going on and so with thirty five thousand volts he launches

1227
01:21:37,260 --> 01:21:41,690
electrons off the cathode and they go zooming across what is very very low pressure

1228
01:21:41,690 --> 01:21:44,650
gas and crash into the and

1229
01:21:45,840 --> 01:21:48,590
mean time to keep this thing dynamically

1230
01:21:48,610 --> 01:21:50,690
at low pressure this goes to

1231
01:21:50,700 --> 01:21:52,350
a vacuum pump

1232
01:21:53,030 --> 01:21:57,800
vacuum pump to keep this thing come down as low as it can

1233
01:21:58,930 --> 01:22:02,040
he was measuring what was going on inside the gas tube and so he had

1234
01:22:02,100 --> 01:22:05,890
detector and his detector was over here

1235
01:22:05,900 --> 01:22:08,080
the detector was off to the side

1236
01:22:08,100 --> 01:22:11,210
the detector consisted of either a piece of cloth

1237
01:22:11,250 --> 01:22:12,900
or paper towel

1238
01:22:12,910 --> 01:22:16,800
which had been painted with a chemical that would goal

1239
01:22:16,820 --> 01:22:18,540
what i was struck by

1240
01:22:18,560 --> 01:22:21,700
something what with the something b

1241
01:22:21,700 --> 01:22:23,960
something would be

1242
01:22:24,010 --> 01:22:25,570
electrons or

1243
01:22:25,590 --> 01:22:28,410
photons that have an energy

1244
01:22:28,450 --> 01:22:29,560
high enough

1245
01:22:29,580 --> 01:22:32,750
two corps x citation of something in

1246
01:22:35,090 --> 01:22:38,770
and then re emission in the visible doesn't do any good to excite

1247
01:22:38,780 --> 01:22:42,790
electrons in the detector have andrea outside the visible

1248
01:22:42,800 --> 01:22:46,890
OK so that's what's going on so this is this was a paper

1249
01:22:46,890 --> 01:22:49,120
four class

1250
01:22:49,180 --> 01:22:52,410
it was painted with an aqueous solution

1251
01:22:55,260 --> 01:22:57,430
flat no cyanide

1252
01:22:57,500 --> 01:23:02,310
yummy stuff very plateau of cyanide which glows green

1253
01:23:02,390 --> 01:23:04,000
glows green

1254
01:23:04,010 --> 01:23:05,910
when it's excited

1255
01:23:05,910 --> 01:23:09,290
and this is called a scintillation screen

1256
01:23:09,310 --> 01:23:12,010
scintillation screen

1257
01:23:12,020 --> 01:23:18,090
comes from the latin word for spark scintilla means parking lot so when the screen

1258
01:23:18,090 --> 01:23:20,400
is struck by some form of energy

1259
01:23:20,500 --> 01:23:22,210
it will glow

1260
01:23:22,230 --> 01:23:23,150
and so

1261
01:23:23,170 --> 01:23:25,070
he had dinner and was up and the

1262
01:23:25,210 --> 01:23:27,840
up the second floor cranking away after data

1263
01:23:27,860 --> 01:23:30,280
i was was dark was raining

1264
01:23:30,320 --> 01:23:34,650
at the windows open street was was coming and by the way to a ranking

1265
01:23:34,650 --> 01:23:39,090
suffered from dalton isn't he was red-green color blindness was the green screen

1266
01:23:39,100 --> 01:23:44,270
and with thirty five thousand volts even at reduced pressure given the capacity of those

1267
01:23:44,270 --> 01:23:49,020
days for vacuum pumps he still had a lot of global from the

1268
01:23:49,150 --> 01:23:50,390
the two

1269
01:23:50,400 --> 01:23:52,020
so the tube is going

1270
01:23:52,070 --> 01:23:55,420
he's got a street lighting the background so he decides

1271
01:23:55,500 --> 01:23:57,890
to close the drapes and

1272
01:23:57,980 --> 01:23:59,750
take out the street light

1273
01:23:59,760 --> 01:24:03,340
and further more he decides to darken

1274
01:24:03,350 --> 01:24:05,260
darken the room so

1275
01:24:06,440 --> 01:24:09,490
he puts a cardboard box over the

1276
01:24:10,780 --> 01:24:13,790
so now the tube is enclosed in a cardboard box what's

1277
01:24:13,800 --> 01:24:15,770
it's not going visibly to him

1278
01:24:15,780 --> 01:24:18,740
it's going inside the box and he continues to see

1279
01:24:20,220 --> 01:24:21,430
continues to see

1280
01:24:21,440 --> 01:24:23,160
things going

1281
01:24:23,170 --> 01:24:25,200
so he says

1282
01:24:25,260 --> 01:24:29,500
it's not something interesting the other thing that happened was kind of interesting his graduate

1283
01:24:29,500 --> 01:24:31,940
student who is prepared some of the apparatus

1284
01:24:31,950 --> 01:24:34,560
i guess he was practising painting the

1285
01:24:34,580 --> 01:24:37,910
scintillation screen so what the student had done

1286
01:24:37,930 --> 01:24:39,030
was too

1287
01:24:39,330 --> 01:24:42,190
the letter a

1288
01:24:42,240 --> 01:24:44,000
on a paper towel

1289
01:24:44,100 --> 01:24:46,580
he left the paper towel on the lab bench

1290
01:24:46,600 --> 01:24:48,650
so now rankin's got the

1291
01:24:48,660 --> 01:24:49,440
the two

1292
01:24:49,470 --> 01:24:51,420
enclosing cardboard

1293
01:24:51,470 --> 01:24:54,480
this things going he looks down and sees the letter a

1294
01:24:54,560 --> 01:24:56,490
the latter is school

1295
01:24:56,530 --> 01:24:59,080
it's going to this is crazy

1296
01:24:59,090 --> 01:25:02,680
so he says are right so he takes a piece of black paper

1297
01:25:02,720 --> 01:25:05,750
and he puts it here in between the two

1298
01:25:05,760 --> 01:25:08,750
and the screen and the screen continues to go

1299
01:25:08,840 --> 01:25:12,770
and then he says he takes only had a deck of playing cards is

1300
01:25:12,850 --> 01:25:18,650
in his lab so don't laugh home-and-away have discovered periodicity so so he takes the

1301
01:25:18,660 --> 01:25:22,770
playing card puts the playing card in front and the two continues to grow

1302
01:25:22,820 --> 01:25:26,290
and then he takes the book and he puts the book in between

1303
01:25:26,340 --> 01:25:28,500
and the two continues to goal

1304
01:25:28,530 --> 01:25:33,230
so please so then he grabs a piece of land foil puts the lead foil

1305
01:25:33,230 --> 01:25:34,000
and here

1306
01:25:34,050 --> 01:25:39,240
and what happens is that where the oil is the screen is not glowing

1307
01:25:39,290 --> 01:25:41,450
but then he sees the outline

1308
01:25:41,460 --> 01:25:43,340
of the bones of his hand

1309
01:25:43,400 --> 01:25:46,760
on the land holding land for you

1310
01:25:46,760 --> 01:25:50,570
so this stuff is going on and he just he just goes

1311
01:25:50,610 --> 01:25:54,270
goes to town he says you know what i've got i got it

1312
01:25:54,320 --> 01:25:58,210
this can be electrons because electrons cannot live on air

1313
01:25:58,250 --> 01:26:00,760
there will be stopped by air

1314
01:26:00,810 --> 01:26:04,820
soon he knew about radio waves from her he said could this be some form

1315
01:26:04,820 --> 01:26:08,230
of mysterious radiation that's capable

1316
01:26:08,290 --> 01:26:12,150
he was really afraid to say this is a form of radiation is capable of

1317
01:26:14,800 --> 01:26:17,970
it's eighteen ninety five you got to come out publicly and say i have the

1318
01:26:17,980 --> 01:26:21,480
form of radiation that can penetrate

1319
01:26:21,520 --> 01:26:25,670
so he gets a magnet out move magnet doesn't change

1320
01:26:25,710 --> 01:26:28,900
so this stuff is insensitive to magnetic field

1321
01:26:28,950 --> 01:26:31,900
but if you put some magnet here of course it gets changed

1322
01:26:31,950 --> 01:26:37,960
you can't see this stuff you can only see evidence of its mysterious

1323
01:26:37,970 --> 01:26:39,260
it's mysterious

1324
01:26:39,280 --> 01:26:41,100
so he calls it

1325
01:26:41,160 --> 01:26:45,250
access the unknown quantity it's x radiation

1326
01:26:45,340 --> 01:26:46,700
x radiation

1327
01:26:46,740 --> 01:26:49,210
this is november eight nineteen ninety five

1328
01:26:49,250 --> 01:26:52,500
and to show you what what a great scientist he was

1329
01:26:52,520 --> 01:26:58,590
rather than rushing to publication he spent all of november and december repeating the experiment

1330
01:26:58,590 --> 01:27:03,710
and trying it in different ways until he is convinced that the effect is real

1331
01:27:03,750 --> 01:27:09,050
and then around christmas time of eighteen ninety five he sends offer manuscript and published

1332
01:27:09,050 --> 01:27:13,020
in the first week of january of eighteen ninety six

1333
01:27:13,080 --> 01:27:15,450
and it takes the world by storm

1334
01:27:15,460 --> 01:27:21,350
he's announcing that is the form of radiation can penetrate matter and furthermore

1335
01:27:21,370 --> 01:27:23,460
he's got an x-ray

1336
01:27:23,460 --> 01:27:25,580
of the human hand

1337
01:27:25,640 --> 01:27:28,170
you know this is t ninety seven people or

1338
01:27:28,180 --> 01:27:31,930
you know very proved very private he's got to form of radiation that can look

1339
01:27:31,930 --> 01:27:34,120
inside the human body

1340
01:27:34,140 --> 01:27:37,430
this is really shocking stuff

1341
01:27:37,480 --> 01:27:38,640
so already

1342
01:27:38,650 --> 01:27:41,510
on january sixteen

1343
01:27:41,540 --> 01:27:44,420
january sixteen eighteen ninety six

1344
01:27:44,420 --> 01:27:46,410
this article in new york times

1345
01:27:46,460 --> 01:27:49,070
article new york times about this stuff

1346
01:27:49,090 --> 01:27:51,890
mysterious form of radiation

1347
01:27:51,890 --> 01:27:55,810
by the way you know he was doing is experiments housing recording his results his

1348
01:27:55,810 --> 01:28:00,660
recordings results on photographic film is photographic films foggy

1349
01:28:00,970 --> 01:28:05,160
photographic film stored in the cabinet of the other side of the lab

1350
01:28:05,220 --> 01:28:09,220
and half time it takes the photographic film was fired

1351
01:28:09,220 --> 01:28:11,100
so whatever the stuff is it's

1352
01:28:11,100 --> 01:28:15,080
its penetrating everything is penetrating the draws his file cabinet

1353
01:28:15,140 --> 01:28:19,200
they were still case there probably wouldn't file can

1354
01:28:20,060 --> 01:28:23,290
widespread widespread adoption

1355
01:28:23,290 --> 01:28:27,120
widespread adoption some of it

1356
01:28:28,410 --> 01:28:32,160
what's the some of the silly ones in london

1357
01:28:32,180 --> 01:28:36,640
there was a manufacturer announced remember this is prudish victorian england

1358
01:28:36,680 --> 01:28:43,470
so that he could sell you x-ray proof ladies' underwear

1359
01:28:43,490 --> 01:28:47,060
in france there was no such thing the french don't care about such matters so

1360
01:28:47,060 --> 01:28:53,530
just have to be

1361
01:28:53,580 --> 01:28:54,490
which ones

1362
01:28:54,490 --> 01:28:58,820
fourteen has to be unwise fourteen have to be

1363
01:29:03,250 --> 01:29:14,280
one fourteen three has to be in there

1364
01:29:14,290 --> 01:29:16,170
one of the minimum wage

1365
01:29:16,230 --> 01:29:24,220
no one has the overall smallest weight

1366
01:29:24,240 --> 01:29:32,510
so can somebody argued me the three has to be in the

1367
01:29:34,900 --> 01:29:36,820
what is

1368
01:29:36,910 --> 01:29:41,660
that's the moment the two which means that if i had a if you add

1369
01:29:41,660 --> 01:29:47,480
something he said was a minimum spanning tree include three

1370
01:29:48,390 --> 01:29:52,000
so therefore had to include fourteen

1371
01:29:52,920 --> 01:29:56,760
i could just delete this age fourteen put an edge three

1372
01:29:56,950 --> 01:30:00,040
something of lower weight

1373
01:30:01,210 --> 01:30:04,690
so three has to be in there

1374
01:30:04,780 --> 01:30:08,000
other edges have to be in

1375
01:30:08,010 --> 01:30:08,850
too little

1376
01:30:08,880 --> 01:30:12,300
little puzzle logic

1377
01:30:12,320 --> 01:30:18,250
six and five have to be in there were they have to be there

1378
01:30:30,770 --> 01:30:38,510
year well i mean it could be connected like through this or something

1379
01:30:38,550 --> 01:30:40,730
and as you have to go this way

1380
01:30:40,740 --> 01:30:43,870
six definitely has to be in there for the same reason the three had the

1381
01:30:45,030 --> 01:30:47,560
because we have two choices to connect up

1382
01:30:47,590 --> 01:30:48,650
this guy

1383
01:30:48,740 --> 01:30:51,860
so everything or connected but it works

1384
01:30:53,080 --> 01:30:56,730
twelve was in there i could always then say well let's connect up this way

1385
01:30:58,860 --> 01:31:04,750
OK so definitely that's in there

1386
01:31:04,760 --> 01:31:19,720
council on everything connected up

1387
01:31:19,730 --> 01:31:26,540
what else has to be in there for minimum spanning tree

1388
01:31:26,800 --> 01:31:31,890
seventy five and a y seven five in a

1389
01:31:38,850 --> 01:31:42,050
OK so can we argue that was one of the time

1390
01:31:42,050 --> 01:31:59,630
why is phi have to be in there

1391
01:32:04,220 --> 01:32:10,620
OK so we have for connected components can have this one

1392
01:32:10,630 --> 01:32:12,040
this one

1393
01:32:12,040 --> 01:32:14,380
we actually have this one here

1394
01:32:14,430 --> 01:32:16,320
and this one could

1395
01:32:18,450 --> 01:32:21,690
we need these three edges to connect them because each edge is going to reduce

1396
01:32:21,690 --> 01:32:24,780
the connected component by one

1397
01:32:25,410 --> 01:32:27,750
so we need three edges

1398
01:32:29,340 --> 01:32:31,640
those are the three cheapest ones

1399
01:32:31,660 --> 01:32:34,060
and they work

1400
01:32:34,060 --> 01:32:35,490
that works

1401
01:32:35,500 --> 01:32:38,050
right any other edges are going to be bigger so

1402
01:32:38,060 --> 01:32:39,800
that would good

1403
01:32:43,400 --> 01:32:48,860
so now we we have a spanning tree everything is we have one being

1404
01:32:48,880 --> 01:32:52,320
a connected graph here right

1405
01:32:52,420 --> 01:32:56,820
so i got a has the same right

1406
01:32:59,130 --> 01:33:05,730
life is predictable

1407
01:33:13,250 --> 01:33:16,920
so really the idea of what the minimum spanning tree is and how this OK

1408
01:33:16,920 --> 01:33:19,060
what what's going on

1409
01:33:19,060 --> 01:33:20,190
so let's

1410
01:33:20,310 --> 01:33:23,710
first of all make some observations about this

1411
01:33:24,190 --> 01:33:26,860
puzzle and what i wanna do is remind you

1412
01:33:26,900 --> 01:33:30,560
about the optimal substructure propery

1413
01:33:33,340 --> 01:33:38,940
because it turns out the minimum spanning tree is a great optimal substructure property

1414
01:33:43,560 --> 01:33:47,650
so this up is going to be wearing have some minimum spanning tree let's call

1415
01:33:47,650 --> 01:33:48,460
it t

1416
01:33:48,480 --> 01:33:54,690
and i'm going to show that with the other edges in the graph

1417
01:33:54,710 --> 01:33:59,690
i'm not going to show

1418
01:33:59,730 --> 01:34:03,650
so here's

1419
01:34:06,720 --> 01:34:08,480
the graph

1420
01:34:21,110 --> 01:34:26,270
OK here's a graph

1421
01:34:27,020 --> 01:34:30,920
looks like the one i have on my newspaper here

1422
01:34:32,090 --> 01:34:36,570
so the idea is this is some minimum spanning tree

1423
01:34:36,590 --> 01:34:39,560
now we want to look at

1424
01:34:39,650 --> 01:34:43,630
a property of optimal substructure and the way we get that going to remove some

1425
01:34:44,860 --> 01:34:49,460
we have an arbitrary edge u v

1426
01:34:49,480 --> 01:34:54,980
in the spanning tree so let's call this you

1427
01:34:54,980 --> 01:34:55,960
this the

1428
01:34:55,980 --> 01:34:57,670
so removing the search

1429
01:35:01,290 --> 01:35:04,670
so when i remove an edge in the tree

1430
01:35:04,690 --> 01:35:07,320
what happens to the tree

1431
01:35:07,340 --> 01:35:10,150
what's left

1432
01:35:10,190 --> 01:35:12,750
i have two trees left

1433
01:35:13,520 --> 01:35:15,480
five two trees left now

1434
01:35:15,500 --> 01:35:18,150
proving there

1435
01:35:18,170 --> 01:35:21,060
that's basically one of the properties

1436
01:35:21,060 --> 01:35:26,850
here are some examples of settings that are commonly used so the so-called line supervised

1437
01:35:28,120 --> 01:35:31,520
training pairs that are given to you and the goal is to produce a model

1438
01:35:31,520 --> 01:35:34,790
that predicts well on future instances

1439
01:35:34,810 --> 01:35:40,650
semi supervised learning you post training areas like x y and also unlabelled data

1440
01:35:40,710 --> 01:35:42,440
and you want to produce a model

1441
01:35:42,440 --> 01:35:43,770
that predicts well

1442
01:35:43,830 --> 01:35:47,630
you want to predict function that assigns a label to every

1443
01:35:47,690 --> 01:35:49,190
future incidents

1444
01:35:49,290 --> 01:35:51,480
trans activist like different

1445
01:35:51,480 --> 01:35:55,080
the same input string there's an labelled data

1446
01:35:55,130 --> 01:35:56,670
but goal is to

1447
01:35:56,670 --> 01:35:58,560
predicts well on

1448
01:35:58,580 --> 01:36:00,270
unlabelled examples

1449
01:36:00,310 --> 01:36:03,060
all the new x you want to predict the y

1450
01:36:03,080 --> 01:36:04,400
and the

1451
01:36:05,520 --> 01:36:10,460
so you have to predict the performance at each step whenever you get an example

1452
01:36:10,480 --> 01:36:15,350
i mean there are some variants that you've probably heard of like reinforcement learning where

1453
01:36:16,230 --> 01:36:20,650
predicting some labelled you want to take some action and then you get some reward

1454
01:36:20,790 --> 01:36:24,580
possibly not immediately but later on

1455
01:36:24,620 --> 01:36:26,120
so these are

1456
01:36:26,190 --> 01:36:29,520
what i call settings that's the way you set of the problem and i like

1457
01:36:29,520 --> 01:36:32,370
what you ask your question

1458
01:36:33,210 --> 01:36:37,020
if you're not going to confuse these settings with assumptions that

1459
01:36:37,040 --> 01:36:39,080
you put on top of that

1460
01:36:39,130 --> 01:36:44,460
usually the assumptions are about how the data is generated

1461
01:36:44,630 --> 01:36:47,620
in this case is go back

1462
01:36:47,650 --> 01:36:50,670
you know how do i assume

1463
01:36:51,420 --> 01:36:52,750
these data

1464
01:36:52,940 --> 01:36:54,980
generated training pairs or

1465
01:36:55,870 --> 01:36:59,210
the instances that come one at the time so

1466
01:36:59,230 --> 01:37:00,420
you know you've probably

1467
01:37:00,500 --> 01:37:04,100
i mean actual which is to say OK they are generated by some

1468
01:37:04,130 --> 01:37:08,920
probabilistic mechanisms of a random number generator or something like this

1469
01:37:08,920 --> 01:37:10,980
maybe they are denoted by

1470
01:37:10,980 --> 01:37:15,560
some natural phenomena observed in nature and so on

1471
01:37:15,600 --> 01:37:20,060
and this assumption that before they are only used if you want to prove anything

1472
01:37:20,060 --> 01:37:22,000
but otherwise you know

1473
01:37:22,000 --> 01:37:24,330
they don't really make sense in the country

1474
01:37:24,350 --> 01:37:26,310
justify any of those so

1475
01:37:26,350 --> 01:37:27,000
you know

1476
01:37:27,920 --> 01:37:34,150
the probability is more you know how you

1477
01:37:34,150 --> 01:37:36,750
he said the same this page of of your

1478
01:37:36,770 --> 01:37:41,980
learning problem and how you the instances are coming to you and what you get

1479
01:37:41,980 --> 01:37:45,020
to see all these distances and so on and this is really the relevant part

1480
01:37:45,040 --> 01:37:51,730
when you want to create algorithm because algorithm must have two feet with this problem

1481
01:37:52,670 --> 01:37:54,920
then there is this notion of success measure

1482
01:37:54,940 --> 01:37:57,350
which is how you would be

1483
01:37:57,400 --> 01:38:01,620
measuring success or when you say i'm satisfied with this algorithm

1484
01:38:03,420 --> 01:38:08,420
sometimes they are the stubs success measures are abstract like for example

1485
01:38:08,480 --> 01:38:12,650
the reward infinity in finite horizon like

1486
01:38:12,670 --> 01:38:16,670
how much will or the number of errors you will make

1487
01:38:17,060 --> 01:38:22,600
if you are infinitely many data points this kind of thing so these are target

1488
01:38:23,460 --> 01:38:26,850
but you can't really matter them never we love infinity

1489
01:38:26,850 --> 01:38:29,250
many data points

1490
01:38:29,250 --> 01:38:32,210
but they they help you ought to guide you towards

1491
01:38:32,250 --> 01:38:35,170
deriving the right algorithm

1492
01:38:35,230 --> 01:38:41,190
then there is what type of analysis you are doing in this you know given

1493
01:38:41,190 --> 01:38:43,040
the setting given

1494
01:38:43,310 --> 01:38:48,310
this success measure given you is how you will analyse it and what kind of

1495
01:38:48,310 --> 01:38:53,420
statement you are expecting to prove about this algorithm

1496
01:38:53,460 --> 01:38:58,230
and again that's relevant one that's only relevant within the certain

1497
01:38:58,250 --> 01:39:02,580
data generation generation mechanism

1498
01:39:02,600 --> 01:39:06,770
and sometimes also offers the respective assumption so you

1499
01:39:06,790 --> 01:39:10,580
and assume some regularity about the data or

1500
01:39:11,120 --> 01:39:18,420
you may assume that you're only looking at certain kinds of functions discounts

1501
01:39:18,480 --> 01:39:19,830
this again is not

1502
01:39:21,500 --> 01:39:25,420
i mean it's useful for designing algorithms because then you can respect rather the

1503
01:39:25,750 --> 01:39:34,420
i agree somewhat only work or would only provably work and there is this condition

1504
01:39:34,690 --> 01:39:39,170
the point here is that if you have an algorithm that has been designed under

1505
01:39:39,190 --> 01:39:40,690
certain set of

1506
01:39:40,730 --> 01:39:42,980
you know for certain protocol

1507
01:39:43,000 --> 01:39:46,230
we certainly limited limiting assumption

1508
01:39:49,080 --> 01:39:53,520
this algorithm may perform well under some other circumstances so my point here is that

1509
01:39:53,520 --> 01:39:54,400
you know

1510
01:39:54,500 --> 01:39:56,440
people will tell you OK

1511
01:39:57,060 --> 01:39:59,600
i presume that are based on a on

1512
01:40:00,730 --> 01:40:03,690
inference for example are working better

1513
01:40:07,330 --> 01:40:08,620
you know

1514
01:40:08,650 --> 01:40:09,730
the same is that

1515
01:40:09,730 --> 01:40:14,900
you can prove that within this restrictive framework within the right assumptions these can be

1516
01:40:14,900 --> 01:40:16,270
proved to be optimal

1517
01:40:16,980 --> 01:40:18,670
but then beyond that you don't know

1518
01:40:18,690 --> 01:40:20,150
you cannot prove anything

1519
01:40:20,170 --> 01:40:23,900
but still they can they can work well so you can't really

1520
01:40:23,920 --> 01:40:27,710
we use the fact that an aneurysm is proven to be optimal in certain context

1521
01:40:27,710 --> 01:40:30,750
to derive the fact that it would be good in another context but it may

1522
01:40:30,750 --> 01:40:34,600
just be because it's good

1523
01:40:34,670 --> 01:40:40,100
because it happens to its with these the assumption of these sort of context

1524
01:40:41,290 --> 01:40:43,500
another point is that you know i was

1525
01:40:45,080 --> 01:40:49,040
i have a proxy that trying to optimize which is not the real success measure

1526
01:40:49,040 --> 01:40:50,630
the thomson

1527
01:40:51,730 --> 01:40:57,620
so measure that hopefully will converge on the success measure

1528
01:40:58,040 --> 01:41:01,480
OK some examples of all these things

1529
01:41:01,520 --> 01:41:04,730
data generation mechanism

1530
01:41:04,820 --> 01:41:09,250
you can have several ways in which assume the data comes to you

1531
01:41:09,310 --> 01:41:15,530
in the kind of bayesian interpretation you can assume that the underlying function describing a

1532
01:41:15,530 --> 01:41:18,290
phenomenon is sampled from song

1533
01:41:20,000 --> 01:41:23,190
and that data are also examples of some of the

1534
01:41:23,210 --> 01:41:28,940
distribution so you put in probabilistic assumptions of probabilistic generation assumption

1535
01:41:29,000 --> 01:41:32,210
on both the function and the data

1536
01:41:32,480 --> 01:41:33,580
in the

1537
01:41:33,600 --> 01:41:35,560
i i d setting

1538
01:41:35,670 --> 01:41:39,440
i i d stands for independent identically distributed

1539
01:41:39,480 --> 01:41:41,130
you don't assume

1540
01:41:41,190 --> 01:41:42,730
that the function is sampled

1541
01:41:42,730 --> 01:41:44,540
approximate algorithm

1542
01:41:44,550 --> 01:41:48,440
so we can i mean you something called the MLP kernel like all of the

1543
01:41:48,440 --> 01:41:52,590
MLP kernel something chris williams derived which is an infinite

1544
01:41:52,760 --> 01:41:56,990
neural network with an infinite number of nodes the reason i like it is because

1545
01:41:57,150 --> 01:42:01,050
when you search already have problem with this

1546
01:42:01,090 --> 01:42:04,310
this is a

1547
01:42:11,310 --> 01:42:14,930
we're going to

1548
01:42:14,970 --> 01:42:22,910
so for example the current web data and we have a lot in regions where

1549
01:42:23,010 --> 01:42:24,550
the data of this sort of data and he

1550
01:42:24,780 --> 01:42:30,320
data outside this is observed data on the x space that

1551
01:42:30,330 --> 01:42:32,390
we'll do this ill-gotten non-zero

1552
01:42:32,410 --> 01:42:36,880
so i bx space as you move away from the data it it tells often

1553
01:42:36,930 --> 01:42:43,350
goes to zero to regions where data the the these comments is defined zero thing

1554
01:42:43,350 --> 01:42:46,130
about peak oil

1555
01:42:46,560 --> 01:42:51,490
is you my characteristic that's supported like this

1556
01:42:51,550 --> 01:42:54,700
rather than dropping the edges

1557
01:42:55,150 --> 01:42:58,590
like that it's going down and coming back to zero

1558
01:42:58,590 --> 01:43:00,320
it's sort of saturated

1559
01:43:01,800 --> 01:43:02,850
i think

1560
01:43:02,870 --> 01:43:08,150
published smith pointing that out to me that some characteristic he's made of used in

1561
01:43:08,150 --> 01:43:12,840
control applications and we'll see what kind of useful here as well

1562
01:43:12,840 --> 01:43:14,420
in some of the examples

1563
01:43:14,430 --> 01:43:19,010
so let's revisit data is to use the full training set in we use the

1564
01:43:19,010 --> 01:43:26,130
RBF kernel again the GPLVM and compare with the mapping i think that the problem

1565
01:43:26,130 --> 01:43:29,200
we have no real data by recreating the experiments

1566
01:43:29,660 --> 01:43:33,460
and something very similar to the thing in the original paper

1567
01:43:35,510 --> 01:43:38,660
on this grid of points and you can kind of see your point

1568
01:43:38,680 --> 01:43:42,340
how can tell what they done in the original paper you can even sort count

1569
01:43:43,860 --> 01:43:45,540
this characteristic

1570
01:43:45,550 --> 01:43:52,890
it's an easy algorithm this responsibility but has characteristic of the point responsibility saturate one

1571
01:43:52,900 --> 01:43:55,680
or close to once you get a a lot of different points depending on the

1572
01:43:55,680 --> 01:44:02,300
same space and points along lines you want to get an edge effect when

1573
01:44:02,400 --> 01:44:04,350
this is the end

1574
01:44:04,370 --> 01:44:08,520
bold where you've laid out the grid of points so these serviceable cluster along the

1575
01:44:09,360 --> 01:44:12,170
so it can be difficult to see some structure but

1576
01:44:12,200 --> 01:44:16,260
you have to be really careful i think what i'm saying things visualizations such as

1577
01:44:16,260 --> 01:44:18,800
this because

1578
01:44:18,810 --> 01:44:22,370
what do people realizations is getting people to look at it and if it's useful

1579
01:44:22,370 --> 01:44:27,730
sort of experts or whatever and i and that so this is hand-waving different characteristics

1580
01:44:27,730 --> 01:44:31,200
which might be better off or worse and you'll see in the roman army people

1581
01:44:31,200 --> 01:44:35,480
use may used PTM for clustering and this is better and may be in actual

1582
01:44:35,480 --> 01:44:39,830
fighting the costs associated with the point to show you some results in the DTM

1583
01:44:39,910 --> 01:44:43,680
favourite moments he quit from that

1584
01:44:44,410 --> 01:44:46,180
this latent variable models

1585
01:44:46,200 --> 01:44:51,660
you get to structure of the green somewhat separated but not to the point

1586
01:44:52,300 --> 01:44:54,000
reading on each other

1587
01:44:54,440 --> 01:44:55,760
you get some

1588
01:44:55,830 --> 01:44:58,120
it's not clear these

1589
01:44:58,150 --> 01:45:00,510
regular commitments of the former

1590
01:45:00,520 --> 01:45:02,120
check my defined them

1591
01:45:02,170 --> 01:45:04,660
it lies but it could be local minimum

1592
01:45:04,670 --> 01:45:07,280
and i think it looks pretty

1593
01:45:07,320 --> 01:45:11,740
that's about it

1594
01:45:11,780 --> 01:45:15,870
so to

1595
01:45:16,360 --> 01:45:17,960
the spectrum kernel

1596
01:45:17,980 --> 01:45:23,860
the QC is similar because the transition from PCA but this is completely rotationally symmetric

1597
01:45:24,040 --> 01:45:29,550
any rotation is applied to this data would be equally valid so that could be

1598
01:45:29,550 --> 01:45:33,360
upside down but it's not the same as you see many points similar to these

1599
01:45:33,360 --> 01:45:36,140
points is similar sort of structures up here

1600
01:45:37,840 --> 01:45:39,380
what more can i say

1601
01:45:39,400 --> 01:45:43,790
so becomes difficult to

1602
01:45:45,670 --> 01:45:49,830
i guess without experiments it's difficult to come up with what you might say is

1603
01:45:49,840 --> 01:45:54,410
a objective evaluation measure should be the sensible thing to do is to have these

1604
01:45:54,410 --> 01:45:55,990
different labels which

1605
01:45:56,000 --> 01:46:00,100
i should be taken account of the all in the fitting of visualisation newark new

1606
01:46:00,180 --> 01:46:04,210
politics class labels i should mention that first i apologize

1607
01:46:04,300 --> 01:46:05,960
seems sensible

1608
01:46:05,980 --> 01:46:12,100
in this two-dimensional space one i see how good spaces for classification how separated how

1609
01:46:12,100 --> 01:46:14,040
well separated the data i

1610
01:46:14,060 --> 01:46:19,710
so need to be sort of classification experiments that what you find is that you

1611
01:46:20,910 --> 01:46:25,600
that's all those previous models you know peaked at no

1612
01:46:25,700 --> 01:46:31,480
the kind of the DTM is that both of them so this grading

1613
01:46:31,480 --> 01:46:32,920
the GTM is

1614
01:46:32,940 --> 01:46:38,830
using the likelihood that is converging towards the situation is that the DTM because it's

1615
01:46:38,830 --> 01:46:44,000
better converge model it doesn't have to use the sparse approximation has said in capture

1616
01:46:44,000 --> 01:46:46,070
the manifold better

1617
01:46:46,080 --> 01:46:52,490
i mean we're not necessarily but it's actually the separation between james patterson so this

1618
01:46:52,620 --> 01:46:54,750
material is something that of course

1619
01:46:56,860 --> 01:46:59,580
measurement associated with it

1620
01:46:59,600 --> 01:47:01,840
should just a PCA

1621
01:47:01,850 --> 01:47:07,870
PCA the classification with linear PCA fourteen percent so far worse than the non-linear any

1622
01:47:08,120 --> 01:47:09,480
linear methods

1623
01:47:09,540 --> 01:47:12,910
kernel PCA

1624
01:47:12,930 --> 01:47:14,350
i can't to

1625
01:47:14,370 --> 01:47:16,190
because i can't

1626
01:47:16,210 --> 01:47:19,140
but parameters to select

1627
01:47:19,300 --> 01:47:22,460
so you this problem and so on and

1628
01:47:22,480 --> 01:47:27,880
doing it DTM that's not really the DTM because TTN selected remove the number of

1629
01:47:27,880 --> 01:47:29,360
grid points as well

1630
01:47:29,390 --> 01:47:31,930
but just months later in the paper

1631
01:47:31,950 --> 01:47:33,010
so can be

1632
01:47:33,270 --> 01:47:37,150
would probably do quite well as well and it's got a lot of advantages

1633
01:47:37,150 --> 01:47:38,080
so this

1634
01:47:38,080 --> 01:47:42,740
change this tool but fix this first so this is the identity

1635
01:47:42,810 --> 01:47:44,680
and this is written

1636
01:47:44,740 --> 01:47:47,870
in cyclic notation by

1637
01:47:47,910 --> 01:47:53,790
three four

1638
01:47:54,680 --> 01:47:56,330
so this is the

1639
01:47:56,350 --> 01:48:03,060
the subgroup and we are going to construct cosets of the subgroup

1640
01:48:04,530 --> 01:48:07,330
from here

1641
01:48:07,410 --> 01:48:09,530
we go

1642
01:48:09,580 --> 01:48:10,640
through green

1643
01:48:10,640 --> 01:48:18,010
green lines to see the green line

1644
01:48:18,060 --> 01:48:22,780
this is the identity

1645
01:48:24,180 --> 01:48:29,310
the order it doesn't change which the ranking

1646
01:48:31,100 --> 01:48:34,990
of course we leave will lead to the same

1647
01:48:35,030 --> 01:48:40,350
the same ranking single here the range sources

1648
01:48:51,060 --> 01:48:53,700
and the other one is is using

1649
01:48:53,700 --> 01:48:58,030
sigma one which is the identity right

1650
01:48:58,990 --> 01:49:04,660
is there are the elements of the to construct another set is

1651
01:49:04,740 --> 01:49:09,410
this is what we saw before the trivial coset

1652
01:49:10,510 --> 01:49:14,080
it is one here now

1653
01:49:14,120 --> 01:49:18,240
it is one here across

1654
01:49:19,350 --> 01:49:27,780
so these are in black here is the ranking

1655
01:49:27,790 --> 01:49:30,600
first position second position the position

1656
01:49:30,640 --> 01:49:32,180
four position

1657
01:49:32,220 --> 01:49:36,030
and the items that goes

1658
01:49:41,870 --> 01:49:43,930
you see i ten three goes here

1659
01:49:43,930 --> 01:49:47,200
i ten one goes here

1660
01:49:47,240 --> 01:49:50,260
and then i have flip

1661
01:49:50,280 --> 01:49:51,620
i tend to

1662
01:49:51,680 --> 01:49:53,010
an item four

1663
01:49:53,030 --> 01:49:55,280
those who

1664
01:49:55,330 --> 01:49:58,640
so you have

1665
01:49:58,640 --> 01:50:02,030
the final rank so that you have there

1666
01:50:02,050 --> 01:50:07,680
you're right

1667
01:50:10,080 --> 01:50:12,780
one is to prefer

1668
01:50:14,290 --> 01:50:16,910
over one

1669
01:50:16,950 --> 01:50:17,780
but now

1670
01:50:17,810 --> 01:50:19,010
two and four

1671
01:50:19,030 --> 01:50:20,950
i don't care

1672
01:50:21,010 --> 01:50:24,990
which rather they become

1673
01:50:24,990 --> 01:50:28,930
and these are

1674
01:50:28,950 --> 01:50:33,870
these are partial rankings

1675
01:50:42,490 --> 01:50:46,330
in this this is extremely useful because

1676
01:50:46,370 --> 01:50:49,620
press forms of course set

1677
01:50:49,640 --> 01:50:51,430
and you can always ask

1678
01:50:51,450 --> 01:50:55,600
among all possible choices

1679
01:50:56,330 --> 01:50:58,450
first k

1680
01:50:58,560 --> 01:50:59,830
it doesn't matter

1681
01:50:59,830 --> 01:51:02,830
like when you search in google you just get like ten

1682
01:51:02,870 --> 01:51:04,140
the first

1683
01:51:04,140 --> 01:51:04,950
and ten

1684
01:51:04,970 --> 01:51:08,530
that if you consider only

1685
01:51:08,550 --> 01:51:13,060
this subset only this guy and you disregard all the rest

1686
01:51:13,100 --> 01:51:19,100
you have all of space much more

1687
01:51:22,620 --> 01:51:27,180
you have some models made on permutation

1688
01:51:27,200 --> 01:51:30,470
and more recently you have probability models

1689
01:51:30,620 --> 01:51:32,140
based on

1690
01:51:32,180 --> 01:51:37,280
partial rankings

1691
01:51:37,330 --> 01:51:42,620
of course this has a generalisation this is just one example of partitions that you

1692
01:51:42,620 --> 01:51:46,740
might be interested in this case here you fix the first two

1693
01:51:46,760 --> 01:51:48,720
let the rest

1694
01:51:48,780 --> 01:51:49,950
you don't care

1695
01:51:50,050 --> 01:51:55,200
you can you can have many for for all partitions of and

1696
01:51:55,240 --> 01:51:56,740
you would have different

1697
01:51:56,760 --> 01:51:59,780
the core set

1698
01:51:59,780 --> 01:52:02,830
which is this generalizations with the here in

1699
01:52:02,870 --> 01:52:03,680
you read

1700
01:52:04,060 --> 01:52:08,060
the point

1701
01:52:08,060 --> 01:52:10,180
to go from there

1702
01:52:11,140 --> 01:52:12,390
i mean that

1703
01:52:18,760 --> 01:52:21,290
so this is written in and

1704
01:52:21,350 --> 01:52:23,640
the general but

1705
01:52:23,640 --> 01:52:25,950
the point here is that

1706
01:52:25,990 --> 01:52:31,700
each one of those

1707
01:52:33,030 --> 01:52:34,580
it's are

1708
01:52:34,580 --> 01:52:36,470
it's one core set

1709
01:52:36,510 --> 01:52:45,890
of the whole group g

1710
01:52:45,910 --> 01:52:51,010
now one calls set of this subgroup given by bipartition here

1711
01:52:51,060 --> 01:52:55,720
of the group of all permutations which hassan

1712
01:52:55,740 --> 01:52:56,930
indexed by

1713
01:52:56,930 --> 01:52:59,100
the permutation pi

1714
01:52:59,120 --> 01:53:00,870
and you see that all

1715
01:53:00,890 --> 01:53:04,790
rankings given by those

1716
01:53:04,850 --> 01:53:09,260
are consistent with the permutation but it keeps

1717
01:53:09,260 --> 01:53:11,180
the k first

1718
01:53:11,220 --> 01:53:14,990
preference don't stride

1719
01:53:15,100 --> 01:53:20,240
so if you're doing and a model on on the probability space

1720
01:53:20,280 --> 01:53:22,560
and then you have to check

1721
01:53:22,600 --> 01:53:24,410
if you're on

1722
01:53:24,410 --> 01:53:27,080
if you ordering are consistent

1723
01:53:27,080 --> 01:53:30,430
with the choice of the first k choice you have to search and in the

1724
01:53:30,430 --> 01:53:31,700
main space

1725
01:53:31,740 --> 01:53:33,450
so you can start

1726
01:53:33,470 --> 01:53:38,470
from you can start working from the stock with consistent

1727
01:53:38,510 --> 01:53:42,410
if consistent

1728
01:53:48,050 --> 01:53:49,450
what you can do

1729
01:53:49,470 --> 01:53:54,140
with this space both the space of the probabilities of the book both with the

1730
01:53:54,140 --> 01:53:57,550
space of all permutations

1731
01:53:57,600 --> 01:54:01,120
o with the smallest space of

1732
01:54:01,990 --> 01:54:06,580
permutations of the subgroup given by one particular

1733
01:54:06,580 --> 01:54:09,560
particular partition of the group

1734
01:54:09,560 --> 01:54:14,830
holding the distribution over the parameters fixed and the arms that i compute a distribution

1735
01:54:14,830 --> 01:54:17,310
over the parameters holding the distribution of the

1736
01:54:17,750 --> 01:54:22,940
in variables fixed in these equations characterize the general solutions

1737
01:54:23,400 --> 01:54:24,770
to coordinate ascent

1738
01:54:26,290 --> 01:54:27,610
of this objective function

1739
01:54:28,830 --> 01:54:32,080
so this is an expression for what the solutions look like yes

1740
01:54:32,610 --> 01:54:35,860
the question is is that the choice q only affect the speed

1741
01:54:37,130 --> 01:54:38,750
so the choice if q

1742
01:54:42,540 --> 01:54:45,040
the quality of the bound that we get as well

1743
01:54:45,460 --> 01:54:47,580
okay so let me try to explain this with a picture

1744
01:54:48,060 --> 01:54:49,670
can people see when i right here

1745
01:54:50,290 --> 01:54:50,790
sort of

1746
01:54:53,150 --> 01:54:54,980
the basic idea is

1747
01:54:58,150 --> 01:54:59,810
i'm going explain it with a picture

1748
01:55:00,790 --> 01:55:04,480
in the minutes okay let me go through the rest the slide because the picture will make more sense

1749
01:55:05,000 --> 01:55:05,330
in man

1750
01:55:07,310 --> 01:55:08,590
this is the algorithm

1751
01:55:09,520 --> 01:55:14,500
iterate between these two is now it is exactly that you algorithm

1752
01:55:17,170 --> 01:55:18,400
if i limit

1753
01:55:19,940 --> 01:55:22,850
the distribution on the parameters to be a delta function

1754
01:55:24,290 --> 01:55:27,770
so that you algorithm has an e step that is exactly like this

1755
01:55:29,670 --> 01:55:35,150
em step doesn't impede distributions over the parameters the end step optimizes the parameters right

1756
01:55:35,710 --> 01:55:36,080
if you

1757
01:55:36,690 --> 01:55:38,770
raise your hand if you are familiar with him algorithm

1758
01:55:39,580 --> 01:55:40,710
okay almost everybody here

1759
01:55:41,400 --> 01:55:45,270
in the the algorithm to optimize over the parameters

1760
01:55:46,350 --> 01:55:47,520
that's corresponds to

1761
01:55:48,130 --> 01:55:53,270
the special case in this way restricted the distribution over the parameters to be a delta function

1762
01:56:01,560 --> 01:56:03,210
but in the more general case

1763
01:56:03,770 --> 01:56:07,980
but i have a distribution over the hidden variables and the distribution over the parameters

1764
01:56:08,520 --> 01:56:09,610
what's going on

1765
01:56:10,000 --> 01:56:10,560
is there

1766
01:56:11,960 --> 01:56:15,960
the product these tools are approximate posterior q of data

1767
01:56:17,270 --> 01:56:23,270
time cube x would try to approximate the true posterior r p theta ant acts

1768
01:56:24,000 --> 01:56:24,580
given why

1769
01:56:29,520 --> 01:56:36,610
by maximizing the lower bound is equivalent to minimizing the scale divergence between the approximate distribution

1770
01:56:37,150 --> 01:56:38,250
and that should distribution

1771
01:56:38,960 --> 01:56:40,250
so now i can draw the picture

1772
01:56:45,270 --> 01:56:46,810
here's my true distribution

1773
01:56:47,690 --> 01:56:50,400
piiv access and data given why am

1774
01:56:56,610 --> 01:56:57,460
can use red

1775
01:56:57,980 --> 01:56:59,130
which color can i use

1776
01:57:00,460 --> 01:57:01,350
reds allowed okay

1777
01:57:09,580 --> 01:57:11,900
you don't have to like that of the board you can see it

1778
01:57:14,130 --> 01:57:16,540
this is my family of cues

1779
01:57:17,830 --> 01:57:23,210
family of distributions and what the variational bayes in yemen algorithm will end up doing

1780
01:57:23,460 --> 01:57:25,830
is they will find the distribution q

1781
01:57:29,290 --> 01:57:30,710
that minimizes

1782
01:57:32,360 --> 01:57:34,270
the cale divergence

1783
01:57:35,130 --> 01:57:36,290
scale qpi

1784
01:57:37,920 --> 01:57:42,230
the cale divergence between q and p e so it's basically going to

1785
01:57:42,670 --> 01:57:45,500
wander around the space until finds the point

1786
01:57:46,000 --> 01:57:47,650
that minimizes the kill divergence

1787
01:57:49,960 --> 01:57:52,150
and then kill divergence is asymmetric

1788
01:57:52,560 --> 01:57:53,770
cale peak u

1789
01:57:54,900 --> 01:58:00,690
is a more desirable thing to minimize but it is intractable to compute because you're averaging with respect to p

1790
01:58:01,210 --> 01:58:02,060
scale qpi

1791
01:58:04,290 --> 01:58:05,060
we can compute

1792
01:58:06,810 --> 01:58:08,040
and we can optimize efficiently

1793
01:58:12,110 --> 01:58:15,610
and in the limit you can show that this variational bound approach is the basic

1794
01:58:15,610 --> 01:58:18,420
criterion like you know everything sensible should

1795
01:58:21,060 --> 01:58:22,110
any questions about this

1796
01:58:24,630 --> 01:58:28,080
so the expectation propagation algorithm

1797
01:58:32,330 --> 01:58:37,110
different form of deterministic approximation for these kind of integrals

1798
01:58:42,130 --> 01:58:47,290
some people mistakenly say it tries to minimize scale peak u

1799
01:58:48,020 --> 01:58:55,130
kill beacuse impossible to minimize so actually what the epee algorithm doors which is in the appendix slides

1800
01:58:58,210 --> 01:59:00,980
for every term in the in the cayo

1801
01:59:01,560 --> 01:59:06,110
holding only others terms fixed it locally tries to minimize scale q

1802
01:59:07,080 --> 01:59:08,860
but globally doesn't achieve yeah

1803
01:59:10,040 --> 01:59:12,420
on the

1804
01:59:23,380 --> 01:59:27,170
so essentially what we're trying to find and not sure i completely understand the difference

1805
01:59:27,170 --> 01:59:29,440
between what you mean by double-sided are one-sided

1806
01:59:29,900 --> 01:59:32,400
there is only one optimization problem that we're doing here

1807
01:59:32,880 --> 01:59:33,560
we are

1808
01:59:34,020 --> 01:59:34,810
trying to

1809
01:59:37,130 --> 01:59:39,310
maximize this lower bound

1810
01:59:40,540 --> 01:59:43,230
that's equivalent to minimizing the scale

1811
01:59:43,790 --> 01:59:48,400
there's no gap between these two those things are equal to each other are maximizing

1812
01:59:48,400 --> 01:59:51,770
this term is equivalent to minimizing thee

1813
01:59:52,830 --> 01:59:55,380
the difference between these two terms which is the kale


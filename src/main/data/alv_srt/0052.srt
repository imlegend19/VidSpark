1
00:00:00,000 --> 00:00:05,330
so first question is to do any technical works and consumers must be quiet

2
00:00:05,400 --> 00:00:06,400
the person

3
00:00:06,530 --> 00:00:10,450
well i find that i have to do technical work to same so i i

4
00:00:10,450 --> 00:00:13,270
do programming from that point of view but also

5
00:00:13,310 --> 00:00:14,960
i find that there's some

6
00:00:15,020 --> 00:00:19,840
ideas which really you can explore and and and sometimes only explain to people by

7
00:00:19,840 --> 00:00:21,210
writing code itself

8
00:00:21,330 --> 00:00:24,070
that's why for example i started doing some

9
00:00:24,530 --> 00:00:28,870
last year i started doing some hx coding for making to make it RDF browser

10
00:00:28,870 --> 00:00:31,290
because i wanted to show the sort of

11
00:00:31,390 --> 00:00:33,690
things i meant by an RDF browser

12
00:00:33,710 --> 00:00:37,320
and it's been a lot of fun should students over the summer of two for

13
00:00:37,320 --> 00:00:39,090
a whole lot more work into it

14
00:00:39,160 --> 00:00:43,050
and so that's why i always like to try to find time to get back

15
00:00:43,060 --> 00:00:49,120
to it we also have various projects it's not quite large pieces i have lying

16
00:00:49,120 --> 00:00:51,350
around need need attention

17
00:00:51,360 --> 00:00:53,340
so they brought

18
00:00:53,430 --> 00:00:58,680
and we still using those and of course we using those in some cases systems

19
00:00:58,680 --> 00:01:00,520
which we use from day data

20
00:01:00,570 --> 00:01:03,340
so the lives so to keep this going

21
00:01:03,350 --> 00:01:08,520
very interesting to hear what about the people around the w three c that they

22
00:01:08,520 --> 00:01:11,400
all come competent in the same way

23
00:01:11,410 --> 00:01:13,030
so the culture

24
00:01:13,040 --> 00:01:18,990
who's the culture thanking i'm not everybody is a program but but but a lot

25
00:01:18,990 --> 00:01:19,920
of people are

26
00:01:19,960 --> 00:01:26,020
people tend to result make their own systems for

27
00:01:26,030 --> 00:01:29,720
i want to get any worse than the number of people who have made for

28
00:01:29,720 --> 00:01:34,720
example system for tracking time system for tracking

29
00:01:34,740 --> 00:01:41,410
the issues working group for steve reich who has

30
00:01:41,540 --> 00:01:47,560
the web browser he's produced a system for building slides in each making slideshows html

31
00:01:47,570 --> 00:01:53,020
and this of course is all kinds of things the validation which made by assistant

32
00:01:53,020 --> 00:01:54,640
team this part of the w three C's

33
00:01:57,610 --> 00:01:59,130
and so on

34
00:01:59,140 --> 00:02:03,440
now the question since you kind of consider this godfather

35
00:02:03,550 --> 00:02:09,220
that and so on so you must be trekking come from different sites o

36
00:02:09,240 --> 00:02:12,060
since everything is changing fast

37
00:02:12,250 --> 00:02:14,610
so that that

38
00:02:14,630 --> 00:02:16,990
two point zero semantic web

39
00:02:17,000 --> 00:02:20,790
kind of buzz words which might be quite difficult to track for the external communities

40
00:02:20,790 --> 00:02:25,480
so as a and the web itself changes the life quite a lot of our

41
00:02:25,480 --> 00:02:28,280
sociologist able to cope with these changes

42
00:02:28,500 --> 00:02:29,480
you must be

43
00:02:30,230 --> 00:02:31,490
having some contexts

44
00:02:31,500 --> 00:02:33,250
in this direction

45
00:02:33,410 --> 00:02:36,470
by sociologists able to cope well

46
00:02:36,520 --> 00:02:40,790
one of the things that we realize and one of the reasons with that we've

47
00:02:40,790 --> 00:02:45,640
learned launch this web science research initiative is it really when you look at the

48
00:02:45,640 --> 00:02:51,220
way we have to use of sociology and big economics and better computer science and

49
00:02:51,220 --> 00:02:56,060
mathematics and to some extent all mixed in together because these things come together so

50
00:02:57,820 --> 00:02:59,490
i think that one

51
00:02:59,510 --> 00:03:01,570
each discipline has got something to

52
00:03:01,600 --> 00:03:05,670
offer and in fact we have to put together the

53
00:03:05,690 --> 00:03:10,010
abilities of people in many different fields in order to really be able to build

54
00:03:10,080 --> 00:03:14,280
a better weapon understand how we have this one works

55
00:03:14,560 --> 00:03:17,510
so that's a

56
00:03:17,530 --> 00:03:22,700
the question the same line so sure that we all agree that changed life in

57
00:03:23,840 --> 00:03:27,960
but the aspects and very much positive side so everything got accessible and so on

58
00:03:27,960 --> 00:03:33,720
but also that's sort of like being tractable

59
00:03:33,730 --> 00:03:38,930
anonymity because getting lost here and there and so on can you comment on this

60
00:03:38,930 --> 00:03:43,790
whole probably see more of this from your site and how to tackle this kind

61
00:03:43,790 --> 00:03:44,980
of well

62
00:03:45,170 --> 00:03:49,440
the point of view of the work we do at MIT

63
00:03:49,440 --> 00:03:55,080
are some sample images from the dataset but it for each image to the right

64
00:03:55,080 --> 00:03:58,050
of the image into four regions and two two

65
00:03:58,330 --> 00:04:04,440
in training set in the testing so there is no for each of these

66
00:04:04,470 --> 00:04:06,170
classes than b

67
00:04:06,370 --> 00:04:11,160
with some somebody so not only from the actually don't publications or size of the

68
00:04:11,380 --> 00:04:15,690
features example some regions and then compute the covariance matrices

69
00:04:17,660 --> 00:04:24,180
the previous descriptive nine features a little bit that i shouldn't

70
00:04:24,220 --> 00:04:26,420
and the kind of

71
00:04:26,430 --> 00:04:32,510
recognition algorithm to compute the distance between the sample and the rules of classes and

72
00:04:34,940 --> 00:04:36,300
minimum distance

73
00:04:36,710 --> 00:04:43,700
well was some published results of this is our method throughout this is the performance

74
00:04:43,700 --> 00:04:45,190
of the the random covariance

75
00:04:45,240 --> 00:04:50,140
and what you see is a combination of thirty eight on is the tropic and

76
00:04:50,150 --> 00:04:53,300
is the topic if for despite being and malik

77
00:04:54,400 --> 00:04:57,520
the being competition it takes hours

78
00:04:57,550 --> 00:05:00,150
our method can is seconds

79
00:05:00,290 --> 00:05:01,800
the first round

80
00:05:01,860 --> 00:05:08,050
and this is the best performing arts rather than arts and

81
00:05:08,260 --> 00:05:12,610
maybe less than one percent of the competition commission about

82
00:05:12,620 --> 00:05:17,880
i wanted to there's in the data set is the example that i wanted to

83
00:05:17,880 --> 00:05:23,420
kind of a fine the correct class and this is the support of the training

84
00:05:23,420 --> 00:05:24,670
sample so

85
00:05:24,690 --> 00:05:26,750
wrote some things that all

86
00:05:26,930 --> 00:05:32,050
you should be similar to this but i find the other thing so this problem

87
00:05:32,070 --> 00:05:36,960
the other thing to solve difficult dataset is but this is in a different class

88
00:05:36,970 --> 00:05:40,870
activities are completely different images so the

89
00:05:40,880 --> 00:05:45,320
as it should be actually it is looks more similar than this to what i

90
00:05:45,320 --> 00:05:45,950
mean by that is

91
00:05:46,460 --> 00:05:53,120
these are not that significant on its own kind of kind of understood that we

92
00:05:53,130 --> 00:05:55,780
can compute distances on the manifold

93
00:05:55,790 --> 00:06:00,220
and you can outsource for this kind search operations that

94
00:06:00,230 --> 00:06:03,860
this ograms because you cannot

95
00:06:04,250 --> 00:06:08,170
some structure on the representation is available

96
00:06:08,180 --> 00:06:10,180
mention of representation

97
00:06:10,260 --> 00:06:17,520
i'm going to discuss about some clustering applications so the crossing is despite the balls

98
00:06:17,600 --> 00:06:20,190
in this in a given distribution

99
00:06:20,240 --> 00:06:23,460
can find these kind of different types of

100
00:06:23,470 --> 00:06:25,240
of images

101
00:06:25,370 --> 00:06:30,720
the first example is a three d motion estimation in this example we only know

102
00:06:31,000 --> 00:06:34,250
the future points at that some

103
00:06:35,740 --> 00:06:38,930
i we don't know how many different notion exists

104
00:06:38,950 --> 00:06:41,630
there are there are three different motions

105
00:06:41,680 --> 00:06:44,940
all differently but you know

106
00:06:44,970 --> 00:06:50,750
they are rigid body so is three of motion and because of that it is

107
00:06:51,090 --> 00:06:57,270
the structure and the class of the correct matches and the walls are of lives

108
00:06:57,270 --> 00:07:03,040
so that the correspondences are correct significant amount of into the example of going to

109
00:07:03,040 --> 00:07:09,010
estimate the number of different motions at the same time find the transformation is so

110
00:07:10,080 --> 00:07:13,660
very difficult problem you don't know how i mean all objects in the scene at

111
00:07:13,660 --> 00:07:17,500
the of the motion one to compete with them

112
00:07:17,640 --> 00:07:19,520
this analysis people by the

113
00:07:19,650 --> 00:07:22,460
the standard approach is some form

114
00:07:22,480 --> 00:07:23,040
the snowball

115
00:07:23,050 --> 00:07:25,430
forensic or something like

116
00:07:26,670 --> 00:07:32,300
so seeking most thinking but it does this it our distribution in in euclidean space

117
00:07:32,580 --> 00:07:38,120
i'm going to start at this point i'm going to compute a density

118
00:07:38,140 --> 00:07:43,800
and then i will take the mean of the density and i should like john

119
00:07:44,220 --> 00:07:50,900
means local neighborhood then i'm going to repeat myself until become

120
00:07:50,910 --> 00:07:51,950
the model

121
00:07:52,030 --> 00:07:53,620
any more in the long

122
00:07:53,620 --> 00:07:59,400
so for each point the same thing that you end up with a different

123
00:07:59,410 --> 00:08:05,590
because in points and combine those and see those are the mall's and this is

124
00:08:05,590 --> 00:08:08,250
what we do with desertification

125
00:08:08,510 --> 00:08:13,690
four since we want to compute the group is to take being three point correspondences

126
00:08:13,740 --> 00:08:17,450
and some of them are owned by the because there are no is that there

127
00:08:17,450 --> 00:08:24,470
is an element of lives we generate emotion hypotheses and the generic enough tools and

128
00:08:25,910 --> 00:08:31,260
in the samples from the multiple motion distribution or animals because i mean you don't

129
00:08:32,280 --> 00:08:36,830
was of the same object even if they are coming back so number of significant

130
00:08:36,830 --> 00:08:40,110
loss of the number of motion groups and the

131
00:08:40,590 --> 00:08:44,070
the motion parameters and this how it looks like

132
00:08:44,090 --> 00:08:45,720
that means

133
00:08:45,770 --> 00:08:50,090
OK i'm not going to do it on the manifold so these are my points

134
00:08:50,110 --> 00:08:59,890
the motion hypothesis but do not multiply it points say this point a and point

135
00:08:59,890 --> 00:09:03,840
of task performance transfers two

136
00:09:03,880 --> 00:09:09,020
identity and points on the manifold are mapped to the tangent space of the points

137
00:09:10,220 --> 00:09:16,480
i mean identical next to zero of and the points in the neighbourhood of the

138
00:09:17,650 --> 00:09:23,220
and it's is meant to zero since this hobby of being the identity in the

139
00:09:23,220 --> 00:09:27,130
first place so this is the first iteration i do now i mean the indian

140
00:09:27,150 --> 00:09:31,550
space in the space i can go compute in means

141
00:09:32,670 --> 00:09:39,050
but it seems that call big project the mean on the manifold and we know

142
00:09:39,070 --> 00:09:40,240
after today

143
00:09:40,340 --> 00:09:41,970
the stars again

144
00:09:41,990 --> 00:09:48,470
and the kind of explanation although operators that i mention a so some

145
00:09:49,430 --> 00:09:51,150
this is the

146
00:09:51,150 --> 00:09:52,900
motion and

147
00:09:52,920 --> 00:09:55,510
these traits ourselves until

148
00:09:57,010 --> 00:10:00,630
she doesn't become a very small

149
00:10:00,670 --> 00:10:05,510
it's usually takes maybe four or five iterations in this example and here are the

150
00:10:06,420 --> 00:10:08,280
so a

151
00:10:08,320 --> 00:10:12,690
to two point correspondences less than half the

152
00:10:15,990 --> 00:10:20,320
there are no outliers that are objects this but i'm trying to say and for

153
00:10:20,320 --> 00:10:25,720
each object may be rightmost two in correspondences so these are two images like these

154
00:10:25,720 --> 00:10:29,970
certain domains like medical imaging and other other cases where asuming that this different this

155
00:10:29,970 --> 00:10:33,380
nice itself and i is caution is not appropriate and again

156
00:10:33,810 --> 00:10:39,460
this is very standard integer genomes parts of most of the standard packages statistical packages

157
00:10:39,860 --> 00:10:44,100
that you find and you just quality element to fit the model four you just

158
00:10:44,100 --> 00:10:46,420
need to specify what kind of warning you're trying to fit

159
00:10:47,920 --> 00:10:52,700
just like in the case of classification there are two primary considerations one is optimization

160
00:10:52,720 --> 00:10:55,550
how do i figure out how to estimate w's

161
00:10:56,170 --> 00:10:58,310
and what kinds of statistical guarantees

162
00:10:58,730 --> 00:10:59,320
we can give

163
00:11:00,430 --> 00:11:05,180
the literature on least squares and ridge regression is more standard it's it's very old

164
00:11:05,370 --> 00:11:09,040
you can find it standard statistics books what kind of guarantees in terms of

165
00:11:09,610 --> 00:11:11,180
the bias variance analysis you can give

166
00:11:12,350 --> 00:11:17,060
this is people are working on this right now actively several of us are actively

167
00:11:17,060 --> 00:11:23,430
working on building the statistical guarantees far sparse regression models the optimization that is almost

168
00:11:24,480 --> 00:11:29,510
this is the statistical guarantees for sparse regression it's getting we are working on it

169
00:11:29,650 --> 00:11:31,100
and i'm going to show you some examples

170
00:11:32,750 --> 00:11:38,630
nonlinear models often don't make the clock right so if you're doing a linear classification and here regression

171
00:11:39,250 --> 00:11:44,390
so so the second level of complexity that people put in and this was not in that order

172
00:11:45,570 --> 00:11:48,350
is is is hierarchical linear models and and people

173
00:11:48,790 --> 00:11:53,050
started looking at hierarchical linear models in the seventies eighties definitely

174
00:11:53,500 --> 00:11:56,960
no decision trees neural networks and all these kinds of things came came into being

175
00:11:57,540 --> 00:12:02,720
and we now look back and we have a much better understanding of how those developments fitting the bigger picture

176
00:12:03,310 --> 00:12:05,050
but you know this is essentially wetlands

177
00:12:05,480 --> 00:12:07,730
you know decision tree this is the canonical example

178
00:12:08,730 --> 00:12:14,300
at any point you are just trying to make a single decision which can be considered as a linear model

179
00:12:14,880 --> 00:12:19,490
and then you have a hierarchy of them in this particular case it's it's it's

180
00:12:19,490 --> 00:12:23,490
a decision tree you can go with a neural network are related models as well

181
00:12:24,670 --> 00:12:28,720
classification regression trees are extremely popular and they are widely used in the industry for

182
00:12:28,720 --> 00:12:33,630
various purposes u u break your big problem into smaller chunks which are more tractable

183
00:12:33,630 --> 00:12:34,660
using a linear model

184
00:12:35,080 --> 00:12:36,330
so they are actually

185
00:12:36,890 --> 00:12:39,750
you know very nice packages for doing these kinds of things

186
00:12:40,350 --> 00:12:41,920
my perceptrons are

187
00:12:42,470 --> 00:12:46,410
there are very popular there still are used in many many different applications

188
00:12:46,870 --> 00:12:47,320
there were some

189
00:12:47,530 --> 00:12:51,240
some initial shortcomings that people realized in the nineties which have been fixed

190
00:12:51,700 --> 00:12:55,780
and these are the belief networks are more modern versions of some of these things

191
00:12:56,220 --> 00:13:02,640
they are also hierarchical models and data capture this systems at every level you have

192
00:13:02,640 --> 00:13:06,550
a simple model but you're building a hierarchy of them which led to capture something

193
00:13:06,550 --> 00:13:07,540
much more complicated

194
00:13:09,510 --> 00:13:11,390
has been and as i said before you know

195
00:13:11,880 --> 00:13:16,390
doing the learning and optimization and the statistical analysis for this class of models gets

196
00:13:16,390 --> 00:13:21,340
a little bit more difficult because quite simply because you have a hierarchy and the

197
00:13:21,340 --> 00:13:23,740
overall model has become a little bit more complicated

198
00:13:25,120 --> 00:13:29,650
this is i think both of these are very much ongoing there are good there

199
00:13:29,660 --> 00:13:33,970
are standard learning algorithms and optimization algorithms for each one of these things

200
00:13:34,710 --> 00:13:37,780
decision trees regression trees and so on

201
00:13:38,480 --> 00:13:43,390
the statistical guarantees we in some cases we we can see certain things about the

202
00:13:43,390 --> 00:13:47,780
performance of these methods particularly for decision trees we we do know what can we

203
00:13:47,780 --> 00:13:48,860
say about these methods

204
00:13:49,370 --> 00:13:53,470
but but it's it's in anything more difficult problem but the good news is that

205
00:13:53,470 --> 00:13:56,160
we are very well in practice in many many applications

206
00:13:57,160 --> 00:14:00,620
so so we love this class of models this is u u u like your

207
00:14:00,790 --> 00:14:04,900
linear models this is just really hierarchies of linear models by property mixing

208
00:14:05,400 --> 00:14:08,350
the outputs of individual layers of linear models

209
00:14:11,050 --> 00:14:12,190
this is an important slide

210
00:14:12,930 --> 00:14:17,160
right so because each one of us working on a different problem there has to

211
00:14:17,160 --> 00:14:20,290
be some guiding principle as to how you were about doing things

212
00:14:20,750 --> 00:14:21,910
the question is not whether

213
00:14:22,510 --> 00:14:26,880
you know cubic explains is better than linear regression or is it better than some

214
00:14:27,360 --> 00:14:32,110
conditional random fields or something like that's there has to be some guiding principle as to how you're doing things

215
00:14:33,610 --> 00:14:37,240
so this is an important slide because i'm going to try to illustrate an overview

216
00:14:37,810 --> 00:14:41,720
of of what the guiding principle is and if there is one big lesson we

217
00:14:41,720 --> 00:14:45,110
have learned in machine learning over the last maybe you twenty twenty five years

218
00:14:45,110 --> 00:14:50,250
and and you see that is exactly constricted tight constraints

219
00:14:50,250 --> 00:14:53,500
yeah that was a good idea to change the number should I change

220
00:14:53,810 --> 00:14:58,730
it is and different just solve the problem once more

221
00:14:59,910 --> 00:15:05,350
so let me go back to 14 here and that may change a few other

222
00:15:05,350 --> 00:15:12,490
numbers on the increases 1 2 3 and just doing this at random and reduce

223
00:15:12,500 --> 00:15:19,930
that to do all 1 and this 9 2 6 OK is it clear enough

224
00:15:20,890 --> 00:15:23,670
can you see what those numbers are

225
00:15:23,870 --> 00:15:30,280
that's still 1 of our I'm asking you to solve a problem on the fly

226
00:15:30,290 --> 00:15:40,750
here but then using 12 is now the minimum and which well where's the cut

227
00:15:41,450 --> 00:15:42,790
this 7th

228
00:15:44,880 --> 00:15:50,370
all right through down here through that 1 through that etc.

229
00:15:50,380 --> 00:15:52,730
through that too and that 1

230
00:15:52,800 --> 00:15:57,090
so 2 1 1 7 2 1

231
00:16:00,790 --> 00:16:07,350
and the effects of minimal cut then I can get 12

232
00:16:11,690 --> 00:16:17,830
the policy with this kind of money can get through 1 and 1 1 8

233
00:16:17,830 --> 00:16:22,870
1 3 1 1 0 I did I leave no I increase that yet so

234
00:16:22,880 --> 00:16:29,350
14 was that all of that but now I by reducing reducing

235
00:16:29,750 --> 00:16:33,590
reducing some of these others I would some other cut of

236
00:16:34,190 --> 00:16:37,910
12 which so that the theorem which says

237
00:16:37,920 --> 00:16:43,590
it and we don't see immediately how but with a little patience we would figure

238
00:16:43,590 --> 00:16:48,570
out a way to send 12 through that's really we consider more than 12 that's

239
00:16:48,570 --> 00:16:55,990
for sure because you've identified cut with capacity 12 and then we got something so

240
00:16:55,990 --> 00:17:01,430
we wouldn't we certainly know then we we got 2nd full amount across the cut

241
00:17:01,430 --> 00:17:05,110
we've got send you know we gotta start on the answer because we know that

242
00:17:05,110 --> 00:17:09,460
we have to send 7 that way and so forth and so on and you

243
00:17:09,460 --> 00:17:13,550
know off we know what all these points should be and then we can fix

244
00:17:13,550 --> 00:17:19,990
the others to supply them where there's extra

245
00:17:20,000 --> 00:17:28,730
that's a beautiful thing and it would follow from some general duality theorem of linear

246
00:17:28,730 --> 00:17:33,160
programming but then there would also be some special

247
00:17:33,550 --> 00:17:37,270
argument like holes

248
00:17:37,530 --> 00:17:46,000
conditions that would apply and and maybe I mentioned that this maxflow mincut is associated

249
00:17:46,000 --> 00:17:51,730
with forward and focus where the student can editorial

250
00:17:55,000 --> 00:17:58,500
identified that the

251
00:17:58,830 --> 00:18:08,130
problems so yes so that there would be right yes so the book which speak

252
00:18:08,130 --> 00:18:12,950
about that but I think we can look at the 1 way and say you

253
00:18:12,960 --> 00:18:17,850
I could write the whole thing is a linear programming uses simplex method

254
00:18:17,860 --> 00:18:23,650
but then somehow the simplex method should specialise to this problem and and

255
00:18:23,670 --> 00:18:28,550
that in your there was called because those corners and so on should have a

256
00:18:28,550 --> 00:18:44,360
specific meaning in terms of flows and that's yeah yeah this right yes

257
00:18:44,550 --> 00:18:55,690
well now think that I I'm out oil-and-gas uninsured portion of the previous incarnations yeah

258
00:18:55,690 --> 00:19:00,320
cause all yet got I'm getting natural gas off the goal of the Gulf of

259
00:19:00,320 --> 00:19:07,340
Mexico market pipelines going into the mainland and I've got refineries there with capacities

260
00:19:07,550 --> 00:19:16,230
and those pipelines a real network of pipes in yes yeah that's sending electricity believe

261
00:19:16,230 --> 00:19:22,820
what I mean by completely mapped is you would like all the ties, all the friendships to be observed and traditionally

262
00:19:22,850 --> 00:19:38,710
what social sociologists meant went for were the were the last two bullets, right, their their social networks were realistic they were completely mapped, right, they really spent time with people and inter interviewed them, so they had very rich knowledge about each particular node

263
00:19:38,750 --> 00:20:09,410
but they were not large-scale and now or today with, I don't know, emergence of web and all the social networking booksites and social networking websites, we can sort of approach having all three of these points and what I mean by that is for example we have logs of like myspace, facebook right has, myspace, I think has like seventy-five millions of users, facebook has like ten millions of users, we also have logs of like email, blogging, electronic markets, instant messaging and so on

264
00:20:10,290 --> 00:20:15,710
so we want to analyse large networks, the reason for that is that

265
00:20:15,730 --> 00:20:22,690
once we have enough of data, properties will start to emerge, right, statistics will start to work but there's also

266
00:20:24,730 --> 00:20:47,950
some some things one needs to be careful about, so what I show here is, for example, different scales of social networks like, for example, we ha here here I am showing like a five hundred node network of email ex email exchange in our corporate research lab, then, for example, a bit larger network is a similar email exchange over two years at some large university, right, that was almost like fifty thousand nodes for example

267
00:20:47,970 --> 00:20:48,930
if you look at the

268
00:20:48,950 --> 00:21:03,830
network of friendships on a large blogging community, you come to four four point four millions of nodes, but, for example, if you look at all the communication over the microsoft instant messenger, then you're working with basically the whole world, you're working with two hundred forty million people

269
00:21:03,850 --> 00:21:13,990
talking every, day exchanging more than a billion conversations a day and so on and this is something that I'll I'll talk about later, so

270
00:21:15,030 --> 00:21:33,950
how how does the this massive network data that I was just showing compare to like small small-scale studies, right, how does it compare to the karate club little network as we saw and there are we get more and we get less of something, right, we get more in a sense that we can observe glo global phenomena that are genuine and actually

271
00:21:33,970 --> 00:21:52,310
wouldn't be wouldn't be visible at when studying smaller networks, so this is what we get more right we can observe something with higher confidence or we can observe things that we wouldn't be able to observe when we would have too small too small network or too small number of people that we are observing, what we get less of is that we don't really know

272
00:21:52,330 --> 00:22:04,670
what the node or link means, right, we just see its strays ,right, we didn't really go and spend time with these people to really know the story of each one of them, so

273
00:22:04,710 --> 00:22:09,470
it's very easy to measure things, but it's very hard to que ask the right questions

274
00:22:10,890 --> 00:22:16,430
and what is the goal is to find some point where these two lines of research would meet, right, where we can have

275
00:22:16,450 --> 00:22:19,650
some of these good things of

276
00:22:19,670 --> 00:22:24,090
large networks and also we would like to know things about node and links in the network, so that

277
00:22:24,110 --> 00:22:26,730
we can make inference

278
00:22:26,770 --> 00:22:34,530
there are two things one can or at least two things one what what what one can think of when working with networks, so

279
00:22:34,570 --> 00:22:43,210
and this is also, how my tutorial will be structured, we can we can think about structure and there are many properties of the structure and for now

280
00:22:43,230 --> 00:23:02,330
there're just a lot of them and I'll explain them later and the other thing what one can think about is also the processes and dynamics of the network, what I mean, a process would be something that spreads over the graph or a changes a graph in some way and this would be like epidemics cascades, viral marketing is going on I don't know on social networks and so on

281
00:23:05,130 --> 00:23:08,090
for the structure of networks what we're interested in

282
00:23:08,110 --> 00:23:18,530
is what is the structure that the network has, I don't know, a network like this and how did it become to have to have such structure or why is this really there and then for diffusion, what we are interested is

283
00:23:18,550 --> 00:23:29,010
the spread of things over the network and, for example, here I have a picture of one of them is a product recommendations and the other one is the spread of tuberculosis and

284
00:23:29,030 --> 00:23:35,910
there we are interested in the properties of the network that, I don't know, will tell us whether the wireless will die or survive in in the network

285
00:23:35,930 --> 00:23:38,310
so here is what I'll talk about today

286
00:23:38,350 --> 00:24:08,790
so so this is the plan for the first hour and a half is to go through the structure and models of the networks, so basically, first we'll see what are the properties of large graphs and why do we care about them and then the second part will show, how do we model them and how do we think about them, then after the lunch I think, this will come will be, I'll talk about the dynamics of networks, which means is, how do things propagate the networks, how the viruses spread, how does the information spread, how do we detect viruses effectively and so on

287
00:24:08,820 --> 00:24:19,260
how do we model them and also and then the last part will be case studies, where I'll be talking about this microsoft ins instant messenger network and also

288
00:24:19,290 --> 00:24:22,890
how does the web look like, how do we find bad people on ebay and so on

289
00:24:22,930 --> 00:24:25,890
so okay, this is the first part now

290
00:24:27,490 --> 00:24:29,950
and again, the first part will have three parts

291
00:24:30,670 --> 00:24:38,170
so, and then I'll stop so I won't go deeper, so there will be like structure, models and how do we fit models to the data

292
00:24:38,190 --> 00:24:40,370
so okay, the structure

293
00:24:42,170 --> 00:24:46,530
let me so I I think i made this point clear already that traditionally

294
00:24:46,550 --> 00:24:47,710
we were

295
00:24:47,750 --> 00:24:57,550
we were analyzing, I don't know, networks of hundred nodes and if you ha take a traditional social networks book, there will be there will be appendix say that there will be table with the data and you would go

296
00:24:57,590 --> 00:25:01,450
type in type that data in your computer and start doing research on it right

297
00:25:01,490 --> 00:25:03,870
as the networks as we are interested in

298
00:25:03,890 --> 00:25:08,510
or the networks that are available today, obviously wouldn't fit in a single book so

299
00:25:08,550 --> 00:25:11,660
that's that's not something that that's

300
00:25:11,690 --> 00:25:40,210
appropriate, the other thing is that I also want to emphasise here is that the question types of questions we're asking changes a bit right, in traditional settings we would ask things like, what happens if a node is removed from the network, so we would really do like a node-centric type of analysis if you like, what we would ask today is like what percentage of nodes needs to be removed from the network, I don't know, to disconnect it so what num what number of computers do I need to remove from the internet to to break the network

301
00:25:41,530 --> 00:25:42,810
and as I said

302
00:25:42,830 --> 00:25:49,890
we are having these three goals where we have statistical properties, models that can help us understand and think about them and then

303
00:25:50,310 --> 00:25:57,810
ultimately what we'd like is to do some kind of predict behaviour, generate models, generate realistic synthetic graphs and so on

304
00:26:00,050 --> 00:26:06,910
the basic question that we'll be asking in the first part is how does the graph look like and how could we generate it and so

305
00:26:06,930 --> 00:26:29,130
let's think of what is the simplest way to generate a graph, right, and in this is called a random graph model or in erdos-renyi or poisson random graph model, so this was all developed in sixties and it's very nice and rich mathematical theory and let's think of it this way, so let's say that somebody gives us N nodes and the way we'll create a graph is that we'll we'll connect each pair of nodes

306
00:26:29,150 --> 00:26:39,050
independently with some probability P right, so we have a we put nodes on the table, now we pick two nodes at random and connect them and we keep doing this, until we added some number of edges in the network

307
00:26:40,110 --> 00:26:45,820
the question to ask is are real networks like this, so now let's see how real networks are like

308
00:26:48,170 --> 00:26:51,490
thing that is observed with graphs is they call it

309
00:26:51,490 --> 00:26:54,820
get approximate first of all by

310
00:26:54,850 --> 00:26:57,770
something on unit balls

311
00:26:57,780 --> 00:27:01,370
could do better on the half intervals

312
00:27:02,470 --> 00:27:04,140
down a little

313
00:27:04,180 --> 00:27:06,170
stop when

314
00:27:06,180 --> 00:27:07,280
and then i can do better

315
00:27:07,290 --> 00:27:11,690
four rules i would approach

316
00:27:11,700 --> 00:27:16,250
the limit is the scale gets finer and finer get the function

317
00:27:18,820 --> 00:27:21,270
i have to be integers

318
00:27:21,290 --> 00:27:24,690
OK should be in which all integers

319
00:27:24,720 --> 00:27:26,520
my infinity

320
00:27:29,400 --> 00:27:32,110
one minus one plus or minus two

321
00:27:34,040 --> 00:27:35,950
i'm working on the whole

322
00:27:35,970 --> 00:27:40,170
line here are not to far from my functions

323
00:27:43,190 --> 00:27:46,360
no i think

324
00:27:46,370 --> 00:27:49,200
i would have to take a look at its

325
00:27:49,300 --> 00:27:53,130
can i could write it as two

326
00:27:54,020 --> 00:27:55,990
two times

327
00:27:56,020 --> 00:28:01,290
so you could say that this could be one

328
00:28:01,350 --> 00:28:06,920
right let me just drop of two t minus one distribution

329
00:28:07,020 --> 00:28:14,780
so two t-minus here's what we're allowing the free of to belong which i belong

330
00:28:14,780 --> 00:28:16,020
draw from

331
00:28:16,060 --> 00:28:17,450
two t

332
00:28:17,480 --> 00:28:19,940
minus one is that's it

333
00:28:20,000 --> 00:28:23,250
just so we see one one

334
00:28:23,290 --> 00:28:26,590
at first glance looks like we're shifting in the unit interval

335
00:28:26,610 --> 00:28:30,020
but because it's too t minus one

336
00:28:30,040 --> 00:28:35,000
where does the two demons once

337
00:28:35,010 --> 00:28:37,890
i'm claiming it's it's right here

338
00:28:37,900 --> 00:28:39,360
right next

339
00:28:39,400 --> 00:28:42,760
it's a shift because you see when

340
00:28:42,800 --> 00:28:44,540
two years i have

341
00:28:44,550 --> 00:28:49,530
it seems to be zero and not the function be starting twenty years

342
00:28:51,340 --> 00:28:54,180
this will be one of the functional began being so sold

343
00:28:54,340 --> 00:28:55,810
so yes

344
00:28:56,020 --> 00:28:58,640
this is not by here

345
00:29:00,000 --> 00:29:02,130
this guy

346
00:29:02,400 --> 00:29:06,400
so it comes out right

347
00:29:08,950 --> 00:29:15,720
well welcome to i find point for finite point yes

348
00:29:15,890 --> 00:29:21,390
maybe i should allow infinite combinations

349
00:29:23,370 --> 00:29:24,160
but it's

350
00:29:24,180 --> 00:29:28,520
but but if you keep them with finite energy so the

351
00:29:28,910 --> 00:29:30,640
taylor fred infinity

352
00:29:32,230 --> 00:29:38,020
it's of course our entire focus is sort of function

353
00:29:38,030 --> 00:29:39,980
on a finite interval

354
00:29:39,990 --> 00:29:42,260
but if we want

355
00:29:42,270 --> 00:29:48,260
these spaces get all these functions on the whole line and probably better

356
00:29:48,300 --> 00:29:49,450
that there be

357
00:29:49,560 --> 00:29:51,990
inflammation combinations

358
00:29:52,030 --> 00:29:54,200
if lim many

359
00:29:54,260 --> 00:29:57,060
kernel combination

360
00:29:58,900 --> 00:30:11,320
you've hit on the central question that that's the key

361
00:30:11,340 --> 00:30:14,550
but it so that this sort of loneliness here

362
00:30:14,610 --> 00:30:19,020
the same year should be contained in the one but it was since the key

363
00:30:19,020 --> 00:30:20,320
to everything

364
00:30:20,410 --> 00:30:22,230
because it means

365
00:30:24,230 --> 00:30:25,840
the first guy

366
00:30:25,890 --> 00:30:29,070
in particular fifty which are like champion

367
00:30:29,100 --> 00:30:30,890
member of the zero

368
00:30:31,030 --> 00:30:34,160
all the other just shifts of it the first guy

369
00:30:34,260 --> 00:30:36,660
also in the one

370
00:30:36,740 --> 00:30:40,500
of all places on particular are

371
00:30:40,980 --> 00:30:45,240
person has to be one of

372
00:30:45,250 --> 00:30:49,640
what it remains is supposed to be a combination of these guys so that's the

373
00:30:49,650 --> 00:30:54,770
key so that these are only one

374
00:30:54,770 --> 00:30:56,550
it leads to

375
00:30:56,750 --> 00:30:58,770
leads immediately to

376
00:30:58,820 --> 00:31:01,050
the fact that have to be

377
00:31:01,070 --> 00:31:04,490
it's supposed to be the one want to be one

378
00:31:07,030 --> 00:31:10,740
with some coefficients column each of k

379
00:31:11,930 --> 00:31:14,070
the basis functions

380
00:31:14,120 --> 00:31:20,770
for a while

381
00:31:23,180 --> 00:31:28,490
i'm jumping the gun you could say

382
00:31:28,510 --> 00:31:31,640
or leading the way whatever

383
00:31:31,680 --> 00:31:36,900
by using

384
00:31:36,910 --> 00:31:42,740
notation h for the coefficients in fact old you going for all the major are

385
00:31:42,760 --> 00:31:46,140
OK so you have no doubt that

386
00:31:47,220 --> 00:31:52,090
those so is a link between

387
00:31:53,770 --> 00:31:54,890
set up

388
00:31:55,290 --> 00:31:56,930
bunch of spaces

389
00:31:56,950 --> 00:31:58,850
with the basis

390
00:31:59,260 --> 00:32:00,420
the previous

391
00:32:00,470 --> 00:32:02,270
discussion of

392
00:32:05,180 --> 00:32:09,470
particularly h

393
00:32:10,520 --> 00:32:13,300
so the answer is definitely yes

394
00:32:13,640 --> 00:32:15,370
in this

395
00:32:15,370 --> 00:32:19,550
this is what you could say the classical way

396
00:32:21,860 --> 00:32:24,660
in two thousand

397
00:32:24,680 --> 00:32:27,720
in two thousand one new century there's like

398
00:32:27,740 --> 00:32:29,150
you might try to us

399
00:32:29,170 --> 00:32:33,150
you might find this somewhat

400
00:32:34,680 --> 00:32:39,360
and you might be trying to create wavelets on spheres because you wanted to represent

401
00:32:39,360 --> 00:32:43,180
the geopotential is the combination of wavelet

402
00:32:43,220 --> 00:32:46,480
or wavelets on surfaces because

403
00:32:46,500 --> 00:32:48,950
he worked for pixar in there

404
00:32:50,700 --> 00:32:52,980
same toy story or other

405
00:32:54,310 --> 00:32:55,750
that's become of

406
00:32:55,910 --> 00:32:57,790
application out of

407
00:32:57,820 --> 00:33:03,000
computer-aided geometry and

408
00:33:03,110 --> 00:33:07,990
the surfaces are all but that's like second generation

409
00:33:08,050 --> 00:33:10,050
this is the

410
00:33:10,060 --> 00:33:11,740
place to start

411
00:33:11,950 --> 00:33:13,070
this is the

412
00:33:13,080 --> 00:33:15,640
equation to start with

413
00:33:16,620 --> 00:33:21,900
it's the function or functions here is the combination of

414
00:33:22,000 --> 00:33:26,610
we have two t-minus k and of course you saw what happened here

415
00:33:26,640 --> 00:33:31,460
and the coefficients one one and one

416
00:33:31,490 --> 00:33:35,290
coefficients were the full box

417
00:33:35,340 --> 00:33:37,750
is which is somewhere here

418
00:33:37,780 --> 00:33:44,030
it's obviously one of the works was one of the largest the coefficients or one

419
00:33:44,030 --> 00:33:48,590
and one in in particular example

420
00:33:48,640 --> 00:33:52,570
that's the easiest example

421
00:33:52,610 --> 00:33:56,660
so this is the of two t fifty

422
00:33:56,680 --> 00:33:58,390
i don't think raising

423
00:33:58,430 --> 00:34:00,250
for equation

424
00:34:00,300 --> 00:34:05,340
three members of box fifty is sensitive to t

425
00:34:05,340 --> 00:34:07,660
and in length

426
00:34:07,710 --> 00:34:09,690
i don't think it is

427
00:34:09,740 --> 00:34:12,400
i want you to think about why that is not correct

428
00:34:12,460 --> 00:34:16,370
look carefully where that al comes into my differential equation and you will probably come

429
00:34:16,370 --> 00:34:18,660
up with the right answer

430
00:34:18,720 --> 00:34:22,050
and i claim that the actual l that we should have taken

431
00:34:22,110 --> 00:34:24,760
is a little bit larger i don't know how much larger but it's a little

432
00:34:24,760 --> 00:34:27,140
bit larger so that also

433
00:34:27,150 --> 00:34:28,800
make the observed period

434
00:34:28,890 --> 00:34:31,850
become larger than the predicted

435
00:34:31,860 --> 00:34:33,850
so i'm not too optimistic that we will go

436
00:34:33,860 --> 00:34:34,840
and it is

437
00:34:34,890 --> 00:34:37,660
the way we want to hear it but that's good because that's where the physical

438
00:34:37,660 --> 00:34:38,960
eyes that you see

439
00:34:39,780 --> 00:34:42,740
there are other factors that have to be taken into account

440
00:34:42,810 --> 00:34:44,070
i'll turn this

441
00:34:44,120 --> 00:34:46,090
one of at all no

442
00:34:47,010 --> 00:34:49,370
make it completely dark in the classroom

443
00:34:49,490 --> 00:34:53,990
because you're going to see on the right you can see the liquid

444
00:34:54,040 --> 00:34:57,050
you see the liquid now

445
00:34:57,100 --> 00:35:00,460
i see these equations two

446
00:35:01,760 --> 00:35:03,950
it's zero

447
00:35:04,000 --> 00:35:05,500
so let me try to

448
00:35:05,510 --> 00:35:06,730
this is a

449
00:35:06,850 --> 00:35:07,960
the string

450
00:35:07,960 --> 00:35:10,640
large swing then so enormously that

451
00:35:10,690 --> 00:35:15,720
i really want to get a very large swing

452
00:35:15,760 --> 00:35:16,640
that's nice

453
00:35:29,630 --> 00:35:34,620
not bad

454
00:35:34,630 --> 00:35:37,260
twelve point one eight

455
00:35:37,260 --> 00:35:39,100
not bad

456
00:35:39,190 --> 00:35:41,930
a little bit of light

457
00:35:41,960 --> 00:35:44,240
twelve point one eight

458
00:35:44,290 --> 00:35:47,310
so observed

459
00:35:47,340 --> 00:35:49,250
ten t

460
00:35:51,370 --> 00:35:53,510
twelve point one eight

461
00:35:53,520 --> 00:35:56,650
OK my reaction time o point one

462
00:35:56,710 --> 00:35:59,300
so t observed

463
00:35:59,380 --> 00:36:00,540
is one point

464
00:36:02,470 --> 00:36:03,580
let's make it too

465
00:36:03,700 --> 00:36:06,190
wasn't mine is o point o one sec

466
00:36:06,300 --> 00:36:08,490
that's not bad

467
00:36:08,530 --> 00:36:11,530
it actually has an overlap if you have this one here you get one to

468
00:36:12,300 --> 00:36:15,300
and if you should check you could also want one

469
00:36:15,360 --> 00:36:19,020
so it's not that i expected it to be a little higher but

470
00:36:19,060 --> 00:36:21,820
close enough to be happy

471
00:36:21,940 --> 00:36:28,050
think about why l should have been taken with the words

472
00:36:28,930 --> 00:36:29,850
one more

473
00:36:29,870 --> 00:36:31,180
very interesting

474
00:36:32,540 --> 00:36:34,410
portional opened

475
00:36:34,470 --> 00:36:37,270
so while they are two-and-a-half meter steel wire

476
00:36:37,280 --> 00:36:40,040
hanging something on the bottom which we're going to offset

477
00:36:40,090 --> 00:36:42,220
and that's going to oscillate back and forth

478
00:36:42,300 --> 00:36:46,260
it's called torsion opened

479
00:36:46,280 --> 00:36:52,450
and we're going to calculate the period of oscillation they have wonderful properties

480
00:36:52,490 --> 00:36:54,620
there are no way like a spring

481
00:36:54,680 --> 00:36:56,530
like a one-dimensional spring

482
00:36:56,540 --> 00:36:59,060
remember the one-dimensional string

483
00:36:59,110 --> 00:37:00,450
that we have

484
00:37:00,450 --> 00:37:03,500
period which was independent of the

485
00:37:04,490 --> 00:37:07,130
well within reason of course

486
00:37:07,150 --> 00:37:08,850
make the amplitude too large

487
00:37:08,910 --> 00:37:11,490
and you get permanent deformation of the spring

488
00:37:11,540 --> 00:37:15,300
we never had to make any small angle approximation was the

489
00:37:15,360 --> 00:37:18,990
spring as we had to do with the pendulum

490
00:37:19,040 --> 00:37:20,930
here is the dependent

491
00:37:21,560 --> 00:37:24,270
portion opened

492
00:37:24,270 --> 00:37:25,940
is obama

493
00:37:26,030 --> 00:37:28,700
and it is the weight here in this way weighty i tell you more about

494
00:37:28,700 --> 00:37:30,530
that later

495
00:37:30,580 --> 00:37:34,640
hanging from the ceiling has a certain length l

496
00:37:34,650 --> 00:37:36,460
this is point

497
00:37:36,510 --> 00:37:38,500
we're going to twist it

498
00:37:38,550 --> 00:37:41,110
and then we'll all going to let it oscillate

499
00:37:41,120 --> 00:37:44,230
this bar in the horizontal plane

500
00:37:44,230 --> 00:37:45,860
when you look from above

501
00:37:46,750 --> 00:37:48,620
you will see the bar here

502
00:37:48,710 --> 00:37:51,620
o point here

503
00:37:51,760 --> 00:37:52,830
and then

504
00:37:52,890 --> 00:37:56,590
we can offset over an angle theta

505
00:37:56,600 --> 00:38:00,950
and then it will oscillate back and forth

506
00:38:05,310 --> 00:38:07,560
the port

507
00:38:07,610 --> 00:38:09,260
a relative to point b

508
00:38:09,310 --> 00:38:15,850
not very similar to what we had was a sprain

509
00:38:15,890 --> 00:38:18,220
we have a minus sign

510
00:38:18,260 --> 00:38:21,530
then that

511
00:38:21,640 --> 00:38:25,410
illustrates it is restoring instead of a

512
00:38:25,430 --> 00:38:27,950
OK now we have a cap

513
00:38:27,990 --> 00:38:30,620
which is what we call the portion of spring constants

514
00:38:30,680 --> 00:38:32,120
and now we have an angle

515
00:38:32,200 --> 00:38:33,280
which we call

516
00:38:34,560 --> 00:38:36,600
so we generally taught

517
00:38:36,660 --> 00:38:38,240
which is proportional

518
00:38:38,240 --> 00:38:42,370
angle very similar to the linear spring whereby we generate force

519
00:38:42,370 --> 00:38:44,830
which is proportional to the linear displacement

520
00:38:44,850 --> 00:38:47,080
now you generate torque which is

521
00:38:47,160 --> 00:38:50,510
linearly proportional to the angle

522
00:38:50,540 --> 00:38:51,490
and this is

523
00:38:51,490 --> 00:38:54,160
the moment of inertia about point p

524
00:38:54,180 --> 00:38:57,640
kinds of five of five stated about

525
00:38:57,640 --> 00:38:59,970
so we're going to get that data double dots

526
00:38:59,990 --> 00:39:02,910
cross cap

527
00:39:02,950 --> 00:39:04,310
time theta

528
00:39:04,330 --> 00:39:06,220
divided by of p

529
00:39:06,240 --> 00:39:07,950
equals zero

530
00:39:07,970 --> 00:39:09,600
captured by the way

531
00:39:17,850 --> 00:39:19,660
so we have a differential equation

532
00:39:19,660 --> 00:39:23,450
clearly that going to see a simple harmonic oscillation

533
00:39:23,490 --> 00:39:26,140
this is a constant

534
00:39:26,240 --> 00:39:28,810
three going to get theta

535
00:39:28,810 --> 00:39:31,030
you people will say to maximum

536
00:39:32,640 --> 00:39:35,470
omega was five getting boring

537
00:39:35,470 --> 00:39:37,620
angular frequency

538
00:39:37,620 --> 00:39:38,910
and the frequency

539
00:39:38,930 --> 00:39:42,040
and angular frequency histogram

540
00:39:42,100 --> 00:39:43,600
of kappa

541
00:39:43,620 --> 00:39:44,660
cited by

542
00:39:44,680 --> 00:39:46,120
the moment of inertia

543
00:39:46,180 --> 00:39:47,560
about point p

544
00:39:47,600 --> 00:39:49,030
and therefore the period

545
00:39:49,080 --> 00:39:51,680
which is by divided by omega

546
00:39:51,720 --> 00:39:53,640
close to pi

547
00:39:53,640 --> 00:39:56,220
i'm going to ask this question

548
00:39:56,240 --> 00:39:59,500
why are we here

549
00:39:59,510 --> 00:40:00,880
that is to say

550
00:40:01,540 --> 00:40:04,770
you know we all of us

551
00:40:04,870 --> 00:40:09,090
you want to study the ancient greeks

552
00:40:09,110 --> 00:40:10,960
i think it's reasonable

553
00:40:11,010 --> 00:40:12,020
four people

554
00:40:12,030 --> 00:40:13,390
who are considering

555
00:40:13,400 --> 00:40:16,860
the study of a particular subject college courses

556
00:40:16,870 --> 00:40:18,640
that's why they should

557
00:40:18,730 --> 00:40:19,940
what is it about

558
00:40:19,950 --> 00:40:23,500
the ancient greeks between the years that i mentioned two

559
00:40:23,510 --> 00:40:27,950
it deserves the attention of people in the twenty first century

560
00:40:28,010 --> 00:40:29,450
i think

561
00:40:29,500 --> 00:40:33,280
the answer is to be found or these one it's the truth is there are

562
00:40:33,280 --> 00:40:38,590
many edges and some of them is it's just terribly interesting

563
00:40:38,600 --> 00:40:41,310
but that's very much of a

564
00:40:41,320 --> 00:40:44,850
but somewhere along the opposite of object

565
00:40:44,860 --> 00:40:47,270
subjective observations by me

566
00:40:47,690 --> 00:40:51,680
so i would say are less subjective one is that i believe

567
00:40:52,070 --> 00:40:56,020
that it comes from their position that is to say the position of the greeks

568
00:40:56,060 --> 00:41:02,310
at the moment and the most significant starting point of western civilization

569
00:41:02,370 --> 00:41:07,110
which is the culture that most powerfully shapes not only the west

570
00:41:07,120 --> 00:41:09,540
but most of the world today

571
00:41:09,580 --> 00:41:13,880
it seems to me the evidence that whatever its other characteristics

572
00:41:13,920 --> 00:41:15,840
the west has created

573
00:41:17,890 --> 00:41:20,140
of government and law

574
00:41:20,150 --> 00:41:24,410
that provide unprecedented freedoms

575
00:41:24,460 --> 00:41:26,150
for its people

576
00:41:26,200 --> 00:41:34,680
it's also invented a body of natural scientific knowledge and technological achievements that together make

577
00:41:34,680 --> 00:41:36,420
possible a level

578
00:41:36,470 --> 00:41:37,600
of health

579
00:41:37,620 --> 00:41:39,840
and material prosperity

580
00:41:39,850 --> 00:41:41,470
on dreamed of

581
00:41:41,480 --> 00:41:43,270
in earlier times

582
00:41:43,310 --> 00:41:44,550
and i know

583
00:41:44,560 --> 00:41:49,150
outside the west and those places that have been influenced by the way

584
00:41:49,160 --> 00:41:54,310
i think the nobel prize laureate VS naipaul

585
00:41:54,420 --> 00:41:56,680
a man born in trinidad

586
00:41:56,690 --> 00:41:58,560
in paris

587
00:41:58,610 --> 00:41:59,960
i was right

588
00:41:59,970 --> 00:42:02,490
when he spoke of the modern world as

589
00:42:03,500 --> 00:42:06,270
universal civilization

590
00:42:06,290 --> 00:42:08,240
shape chiefly

591
00:42:08,250 --> 00:42:10,510
by the way

592
00:42:10,530 --> 00:42:13,520
most people around the world who know knows

593
00:42:13,530 --> 00:42:19,500
i want to benefit from the achievements of western science and technology

594
00:42:19,580 --> 00:42:26,080
many of them also want to participate in its political freedoms

595
00:42:26,090 --> 00:42:33,100
moreover experience suggests that a society cannot achieve the full benefits of western science and

596
00:42:34,390 --> 00:42:39,670
without a commitment to reason and objectivity

597
00:42:39,690 --> 00:42:42,760
as essential to knowledge

598
00:42:42,810 --> 00:42:46,060
and to the political freedom that sustains the

599
00:42:46,070 --> 00:42:48,870
and helps us to move forward

600
00:42:48,910 --> 00:42:53,760
the primacy of reason and the pursuit of objectivity therefore

601
00:42:53,770 --> 00:42:55,660
both characteristics

602
00:42:55,680 --> 00:42:57,650
of the western experience

603
00:42:57,690 --> 00:43:02,230
it seemed to me to be essential for the achievement of the desired goals

604
00:43:02,280 --> 00:43:04,520
almost anywhere in the world

605
00:43:05,720 --> 00:43:08,310
the civilization of the west however

606
00:43:08,380 --> 00:43:12,780
was not the result of some inevitable process

607
00:43:12,820 --> 00:43:16,730
through which other cultures will automatically pass

608
00:43:16,740 --> 00:43:19,430
it emerged from a unique history

609
00:43:19,480 --> 00:43:21,000
in which chance

610
00:43:21,020 --> 00:43:22,370
an accident

611
00:43:22,390 --> 00:43:25,080
often played a vital part

612
00:43:25,100 --> 00:43:29,660
the institutions and the idea is therefore that provide for freedom

613
00:43:29,670 --> 00:43:33,440
an improvement in the material conditions of life

614
00:43:33,460 --> 00:43:35,560
cannot take root and flourish

615
00:43:35,610 --> 00:43:38,470
without an understanding of how they came about

616
00:43:38,540 --> 00:43:42,520
and what challenges they have had to surmount

617
00:43:42,570 --> 00:43:47,790
non-western peoples who wish to share the things that characterizes modernity

618
00:43:47,830 --> 00:43:52,690
you will need to study the ideas and history of western civilization to achieve what

619
00:43:52,690 --> 00:43:54,080
they want

620
00:43:54,090 --> 00:43:56,570
and westerners i would argue

621
00:43:56,580 --> 00:43:59,340
who wish to preserve these things

622
00:43:59,390 --> 00:44:01,690
must be the same

623
00:44:01,730 --> 00:44:05,810
the many civilizations adopted by the human race

624
00:44:05,860 --> 00:44:09,440
have shared basic characteristics

625
00:44:10,420 --> 00:44:13,500
have tended towards cultural uniformity

626
00:44:13,520 --> 00:44:15,990
and stability

627
00:44:16,010 --> 00:44:22,100
the reason although it was employed for all sorts of practical and intellectual purposes in

628
00:44:22,100 --> 00:44:24,110
some of these cultures

629
00:44:24,130 --> 00:44:27,780
it still lacked independence from religion

630
00:44:27,830 --> 00:44:34,320
and like the highest data to challenge the most basic received ideas

631
00:44:34,410 --> 00:44:36,360
standard form of government

632
00:44:36,370 --> 00:44:39,300
has been monarch

633
00:44:39,320 --> 00:44:41,960
outside the west republics

634
00:44:41,970 --> 00:44:43,410
i have been on and

635
00:44:45,360 --> 00:44:51,540
have been thought to be divided or appointed spokesman for divinity

636
00:44:51,590 --> 00:44:56,970
religious and political institutions and beliefs have been thoroughly intertwined

637
00:44:56,980 --> 00:45:01,800
as a mutually supportive unified structures

638
00:45:01,920 --> 00:45:07,740
government has not been subject to secular reasoned analysis

639
00:45:07,790 --> 00:45:13,860
it is rested on religious authority tradition and power

640
00:45:13,860 --> 00:45:19,670
it represents what i think the problem since working data is most likely to be

641
00:45:20,740 --> 00:45:22,700
so given a training set s

642
00:45:22,710 --> 00:45:27,740
in the so the bayesian procedure we would

643
00:45:29,290 --> 00:45:38,710
have made the probability the posterior probability of by parameters given my training set

644
00:45:38,760 --> 00:45:40,570
hands on

645
00:45:40,580 --> 00:45:44,040
francis and export so my posterior

646
00:45:44,130 --> 00:45:51,410
well my parameters given my training set by bayes rule is proportional to the

647
00:45:51,430 --> 00:46:04,300
right so the by bayes rule

648
00:46:05,880 --> 00:46:10,440
holocaust here

649
00:46:11,600 --> 00:46:12,920
and this

650
00:46:12,940 --> 00:46:18,370
the distribution of represents my police about what data is often seen that

651
00:46:18,390 --> 00:46:22,850
and when i want to make a new prediction in the presence of new holes

652
00:46:24,170 --> 00:46:32,360
a new input x

653
00:46:32,370 --> 00:46:38,070
i would say that while the distribution over the possible housing prices for the for

654
00:46:38,070 --> 00:46:41,920
you for new housing trying with the price of say given the size of the

655
00:46:41,920 --> 00:46:46,760
house the features of the house x and the training set had previously

656
00:46:46,780 --> 00:46:48,970
it's going to be given by

657
00:46:57,970 --> 00:47:03,370
and integral over different states of y given x commentator

658
00:47:03,390 --> 00:47:05,100
and times the

659
00:47:05,140 --> 00:47:08,640
perceive distribution of data given the truth

660
00:47:11,310 --> 00:47:14,230
in particular one year prediction

661
00:47:14,240 --> 00:47:18,020
to be the expected value

662
00:47:18,070 --> 00:47:20,750
on y given

663
00:47:20,810 --> 00:47:22,740
input x and training set

664
00:47:22,760 --> 00:47:25,800
you would say integrate

665
00:47:25,850 --> 00:47:31,360
over y

666
00:47:34,340 --> 00:47:36,380
tons of hysteria

667
00:47:37,280 --> 00:47:40,980
you take an expectation of what i respect your posterior distribution

668
00:47:40,990 --> 00:47:49,930
and you know that when i was writing this down to what the bayesian formulation

669
00:47:49,930 --> 00:47:55,590
announced that you right here y given x common data because this formula now is

670
00:47:55,610 --> 00:47:59,760
the value of y conditioned on the values of the random variables x and data

671
00:47:59,760 --> 00:48:07,060
some no longer writing semicolons data rates commentator because i'm not treating theta on

672
00:48:07,070 --> 00:48:09,070
as a random variable

673
00:48:10,820 --> 00:48:13,390
this is somewhat abstract this on

674
00:48:13,410 --> 00:48:22,350
and it turns out the circle of questions about this

675
00:48:22,360 --> 00:48:28,450
this this stable concrete it turns out that

676
00:48:28,470 --> 00:48:32,300
for many problems of

677
00:48:32,350 --> 00:48:38,440
both of these steps in the computational difficult because of your hatred and this one

678
00:48:38,440 --> 00:48:41,820
dimensional vectors and this one dimensional parameter vector

679
00:48:41,830 --> 00:48:44,600
and this is an integral over inverse one-dimensional

680
00:48:44,620 --> 00:48:46,630
one of our employees one

681
00:48:46,650 --> 00:48:52,830
and this numerically very difficult to compute integrals over all of a very high dimensional

682
00:48:52,830 --> 00:48:54,540
spaces so

683
00:48:55,270 --> 00:49:01,020
usually this integral usually is hard to compute the posterior one theta and also hard

684
00:49:01,020 --> 00:49:04,080
to compute this in the ground state is very high dimensional

685
00:49:04,100 --> 00:49:06,360
on a few exceptions

686
00:49:06,430 --> 00:49:10,740
always this can be done in closed form for main many learning algorithms

687
00:49:10,750 --> 00:49:14,070
the bayesian logistic regression this this is hard to do

688
00:49:15,510 --> 00:49:20,280
and so was coming done is to take the posterior distribution

689
00:49:20,290 --> 00:49:25,920
and instead of actually computing the full posterior distributions here theta given us on

690
00:49:25,930 --> 00:49:27,170
well instead

691
00:49:27,180 --> 00:49:29,760
take this quantity on the right-hand side

692
00:49:29,770 --> 00:49:34,450
and just maximize discounted the right hand side so register

693
00:49:34,470 --> 00:49:36,900
and so on

694
00:49:36,920 --> 00:49:40,710
commonly instead of computing the full posterior distributions

695
00:49:40,720 --> 00:49:42,700
we will choose the following

696
00:49:45,650 --> 00:49:57,270
which is the was called the MAP estimate on the maximum posse or e

697
00:49:57,280 --> 00:50:01,980
as the data which is the most likely value of data most probable value of

698
00:50:01,980 --> 00:50:06,230
data on the posterior distribution and that this

699
00:50:15,330 --> 00:50:20,580
here theta

700
00:50:22,060 --> 00:50:24,690
and then we need to make a prediction

701
00:50:24,700 --> 00:50:34,150
you just predict

702
00:50:39,430 --> 00:50:51,960
using your usual hypothesis on and using using this map the value of data

703
00:50:51,970 --> 00:50:56,280
in place of this as as the front affected choose

704
00:50:56,280 --> 00:51:02,050
carbons on either side of that would be designated as follows or you want to

705
00:51:02,050 --> 00:51:03,970
see http

706
00:51:03,970 --> 00:51:07,590
two dots and this is called manfully

707
00:51:07,610 --> 00:51:10,430
this is called this the methylene radical

708
00:51:10,430 --> 00:51:13,640
and the only other one that i really care about in the

709
00:51:13,650 --> 00:51:17,060
is the one that comes from

710
00:51:17,120 --> 00:51:20,110
FAC two h six is

711
00:51:21,330 --> 00:51:24,040
so the radical from this would be c two

712
00:51:24,060 --> 00:51:27,300
h five and this is called the full

713
00:51:27,320 --> 00:51:30,400
radical one will come across some compounds

714
00:51:30,570 --> 00:51:32,210
one that

715
00:51:32,260 --> 00:51:35,440
we need socially is ethyl alcohol we put the

716
00:51:35,490 --> 00:51:37,940
alcohol functional group on the

717
00:51:37,960 --> 00:51:39,810
and of the full

718
00:51:39,840 --> 00:51:44,510
so that gives you an introduction to alkanes so now let's go back and look

719
00:51:44,510 --> 00:51:46,500
at the next

720
00:51:47,370 --> 00:51:49,420
colin that's the l keynes

721
00:51:49,420 --> 00:51:52,190
so now we look at unsaturated

722
00:51:54,680 --> 00:51:58,120
hydrocarbons and the first example is the

723
00:51:58,140 --> 00:52:02,580
now keynes and these are characterized by SP two

724
00:52:02,600 --> 00:52:06,900
hybridisation so that means at least in one place

725
00:52:06,910 --> 00:52:11,510
it only takes one released in one place in the molecule there's the carbon carbon

726
00:52:11,530 --> 00:52:12,760
o double bond

727
00:52:12,780 --> 00:52:15,620
and that will give you far we have is this one

728
00:52:15,730 --> 00:52:17,650
carbon carbon double bond

729
00:52:17,670 --> 00:52:19,910
it will give us

730
00:52:19,920 --> 00:52:23,640
the chemical formula c ten h two and

731
00:52:23,650 --> 00:52:25,990
and clearly and must be

732
00:52:26,000 --> 00:52:28,680
greater than equal to

733
00:52:28,680 --> 00:52:32,720
greater than or equal to two so the simplest one is

734
00:52:32,770 --> 00:52:35,780
c two h four which we've seen already

735
00:52:35,800 --> 00:52:37,390
we talked about

736
00:52:37,410 --> 00:52:41,700
sigma pi bonding this is ethylene

737
00:52:42,760 --> 00:52:45,290
and hydrogens here we have sp

738
00:52:45,310 --> 00:52:50,810
two hybridisation so we have one sigma bond and one pi bond so the carbons

739
00:52:50,810 --> 00:52:53,010
and the hydrogens line playing

740
00:52:53,060 --> 00:52:55,040
this is one hundred twenty degrees

741
00:52:55,050 --> 00:52:56,740
we've seen all four

742
00:52:56,820 --> 00:53:00,360
the ethylene is the common name for it but the the

743
00:53:00,430 --> 00:53:03,660
the name that's

744
00:53:03,780 --> 00:53:10,180
were regulated by the international union of pure and applied chemistry is following this

745
00:53:10,190 --> 00:53:12,480
nomenclature we take the

746
00:53:12,510 --> 00:53:18,120
ETH because seed numbers two and we have a and e so the formal name

747
00:53:18,120 --> 00:53:19,760
for this is FAC

748
00:53:19,760 --> 00:53:21,160
not ethylene but

749
00:53:21,160 --> 00:53:24,230
you can use either one was going to

750
00:53:25,360 --> 00:53:29,820
very agitated about it and then for n greater than two

751
00:53:29,890 --> 00:53:31,310
for n greater than two

752
00:53:31,330 --> 00:53:34,690
the position of the double bond is not fixed

753
00:53:34,690 --> 00:53:36,530
position o double bond

754
00:53:36,560 --> 00:53:38,240
not fit

755
00:53:38,240 --> 00:53:39,950
so we can show

756
00:53:40,000 --> 00:53:44,370
examples of that let's look at here's one beauty

757
00:53:46,710 --> 00:53:48,920
c four

758
00:53:48,930 --> 00:53:50,320
h a

759
00:53:50,340 --> 00:53:54,410
so one has to put the double bond very and

760
00:53:54,480 --> 00:53:57,820
so i just got one double bond and

761
00:53:57,870 --> 00:54:02,760
there's one hundred twenty degrees hydrogen hydrogen now one two three four

762
00:54:02,810 --> 00:54:08,590
one two three four one two three four so this is c four h eight

763
00:54:08,640 --> 00:54:11,010
and this is called one

764
00:54:11,020 --> 00:54:14,590
eugene because the double bond is off of the

765
00:54:14,640 --> 00:54:16,090
the first carbon

766
00:54:16,150 --> 00:54:17,970
or we can put

767
00:54:18,020 --> 00:54:21,940
the double bond somewhere along the line so we can do this

768
00:54:21,950 --> 00:54:25,950
so the double bond is not at the very end

769
00:54:25,990 --> 00:54:29,170
o five methyl group at the end

770
00:54:29,210 --> 00:54:32,020
one two three four one two three four

771
00:54:32,040 --> 00:54:35,490
so this would then be called two

772
00:54:35,510 --> 00:54:38,730
two beauty

773
00:54:38,770 --> 00:54:41,850
two beauty indicating the double bond comes off

774
00:54:41,900 --> 00:54:42,970
number two

775
00:54:45,070 --> 00:54:47,490
one beauty into beauty

776
00:54:47,500 --> 00:54:51,990
turn out to be constitutional isomers because they got the same chemical formula but they

777
00:54:51,990 --> 00:54:54,530
have a different mix of

778
00:54:54,620 --> 00:54:58,570
constituent groups so let's label this is constitutional

779
00:54:58,690 --> 00:55:01,430
these are both constitutional

780
00:55:01,440 --> 00:55:04,260
i some

781
00:55:04,340 --> 00:55:09,010
but we can zoom in a little bit more on two beauty and introduced yet

782
00:55:09,010 --> 00:55:13,140
this is this is only the total probability of these passes only the probability that

783
00:55:13,140 --> 00:55:17,810
i that set frames but given that i that sort of ice creams were interested

784
00:55:17,810 --> 00:55:22,310
in which of these powers was the best way of explaining that happens to be

785
00:55:24,880 --> 00:55:26,520
so if we want to know

786
00:55:26,530 --> 00:55:30,620
whether i am sorry whether the second it was hot weather we ended up at

787
00:55:30,620 --> 00:55:32,200
this stage

788
00:55:32,230 --> 00:55:35,300
so we can look at the total probability of all paths that go through here

789
00:55:35,300 --> 00:55:39,320
which will be very small because it's them explains the entire diary

790
00:55:39,370 --> 00:55:40,970
with the additional

791
00:55:40,990 --> 00:55:42,750
requirements that

792
00:55:42,770 --> 00:55:44,670
the second ever called

793
00:55:44,680 --> 00:55:47,580
and we look at the total probability of all of these

794
00:55:47,600 --> 00:55:53,320
also very small explains the whole diary with the additional requirement the second bihar and

795
00:55:53,320 --> 00:55:56,980
maybe this is the total probability powers that go through here

796
00:55:56,990 --> 00:55:59,150
as a hundred times greater

797
00:55:59,170 --> 00:56:03,030
the total probability has it go through their so that it would be

798
00:56:03,630 --> 00:56:06,150
the probability

799
00:56:06,170 --> 00:56:08,060
the second being how would be

800
00:56:08,070 --> 00:56:09,870
a hundred times as great

801
00:56:09,880 --> 00:56:13,290
as the second a being called

802
00:56:13,300 --> 00:56:14,220
all right

803
00:56:15,920 --> 00:56:20,080
how can we do this efficiently well i've given you a little head

804
00:56:20,100 --> 00:56:22,600
with the numbers that we've written here

805
00:56:23,770 --> 00:56:28,570
the basic idea is that if we want to know how many

806
00:56:28,580 --> 00:56:33,400
pads come through here let's start out by looking at the total probability of all

807
00:56:33,400 --> 00:56:35,970
paths that come to the

808
00:56:35,980 --> 00:56:39,640
actually let's look over here the probability of we've got more stuff to the left

809
00:56:39,650 --> 00:56:43,900
look so we want to know the total probability all has come through come to

810
00:56:46,470 --> 00:56:48,510
where every every path

811
00:56:48,520 --> 00:56:51,860
every path probabilities the productivity arcs

812
00:56:51,930 --> 00:56:55,320
there's two ways that you can get it right

813
00:56:55,380 --> 00:56:58,670
you can you can take flight through here applied through their

814
00:56:58,680 --> 00:57:00,660
there's only two rounds

815
00:57:00,700 --> 00:57:04,030
well of course to get here there are four ways to do two is to

816
00:57:04,030 --> 00:57:06,550
do it and get here there are two ways to do it

817
00:57:06,770 --> 00:57:08,600
but let's put that offer moment

818
00:57:08,660 --> 00:57:09,410
if we

819
00:57:09,430 --> 00:57:11,150
once we get here

820
00:57:11,170 --> 00:57:15,680
the total probability of all paths here the total probability pounds coming through here

821
00:57:15,740 --> 00:57:18,530
will call that alpha

822
00:57:18,550 --> 00:57:21,500
times the cost of getting from here to here

823
00:57:21,520 --> 00:57:25,180
right so that's all paths they get to here via the

824
00:57:25,400 --> 00:57:28,670
so it's out of this state total probability of all paths

825
00:57:28,690 --> 00:57:33,500
to hear time's point five six

826
00:57:34,920 --> 00:57:38,060
the total probability of all paths to hear that come through here

827
00:57:38,080 --> 00:57:42,490
which is alpha here times point o seven

828
00:57:42,700 --> 00:57:46,300
clear enough so the idea is we can get out of here if we know

829
00:57:46,310 --> 00:57:49,010
the office here and here

830
00:57:49,030 --> 00:57:51,630
how do we get over here

831
00:57:51,650 --> 00:57:55,150
by knowing the office from here to here how do we get out of here

832
00:57:55,150 --> 00:58:00,370
well that is OK because really coming from start so this is our base case

833
00:58:00,410 --> 00:58:03,820
total probability of all paths serious point of one

834
00:58:03,830 --> 00:58:07,870
similarly over here that alpha is point one now let's work forward

835
00:58:07,870 --> 00:58:09,490
over here we go

836
00:58:09,500 --> 00:58:11,810
probability of getting here is point of one

837
00:58:13,350 --> 00:58:19,120
o point o one

838
00:58:19,130 --> 00:58:24,640
times the cost of the story let's start over here point one the south

839
00:58:24,660 --> 00:58:28,260
total probability has here times point seven that's this

840
00:58:28,280 --> 00:58:30,880
plus this point one

841
00:58:30,890 --> 00:58:32,620
time point five six

842
00:58:32,630 --> 00:58:36,830
the pads coming from here and that's point o six three

843
00:58:36,840 --> 00:58:38,470
and similarly

844
00:58:38,520 --> 00:58:42,300
total probability will pass there is point oh

845
00:58:42,330 --> 00:58:45,370
now we also have at this stage

846
00:58:45,390 --> 00:58:48,010
we want to know the total probability of all patterns here

847
00:58:48,190 --> 00:58:53,290
we take that point o nine and we multiply by point seven

848
00:58:53,310 --> 00:58:56,430
and we take this point o six three so the total the sum of those

849
00:58:56,430 --> 00:58:57,770
two pounds

850
00:58:57,860 --> 00:58:59,590
this one

851
00:58:59,620 --> 00:59:01,660
and that one is point o six three

852
00:59:01,670 --> 00:59:05,630
we multiply by o point five six we get that and so we find point

853
00:59:05,730 --> 00:59:08,080
to point o three six

854
00:59:08,320 --> 00:59:13,330
so let's see how we actually computer this on the spreadsheet because we used to

855
00:59:13,510 --> 00:59:14,760
to compute the

856
00:59:16,710 --> 00:59:19,020
to compute the graph before

857
00:59:19,060 --> 00:59:23,010
so here we have

858
00:59:23,110 --> 00:59:28,170
OK so here the alpha numbers for the cold states

859
00:59:28,180 --> 00:59:32,630
we have a point o one point o nine point o o one three five

860
00:59:33,100 --> 00:59:36,270
and you saw this size these are exactly the numbers you saw on the diagram

861
00:59:36,270 --> 00:59:42,920
a moment ago and what's happening to these numbers as we go down

862
00:59:43,000 --> 00:59:45,570
again much much smaller how come

863
00:59:45,680 --> 00:59:52,770
well multiplying which makes things more but we're also adding i mean we're adding a

864
00:59:52,770 --> 00:59:55,380
lot of paths together so it's not obvious

865
00:59:55,440 --> 00:59:56,920
right away the

866
00:59:56,930 --> 00:59:59,840
they should get smaller

867
00:59:59,950 --> 01:00:08,030
it's gonna get smaller right but remember that every stage not only were multiplying but

868
01:00:08,030 --> 01:00:09,770
we're also adding

869
01:00:10,260 --> 01:00:11,690
so you know there's

870
01:00:11,740 --> 01:00:15,940
you have the thing from the cold state anything from heart

871
01:00:15,960 --> 01:00:21,980
OK how come

872
01:00:21,990 --> 01:00:26,030
OK but we're we're in some sense for not choosing between hot and cold right

873
01:00:26,030 --> 01:00:29,000
because we're adding those possibilities together

874
01:00:30,090 --> 01:00:34,600
that i think is the same answer i just give monica

875
01:00:34,610 --> 01:00:35,880
so over here

876
01:00:35,890 --> 01:00:37,800
when we ask about BLP here

877
01:00:37,810 --> 01:00:41,030
we're considering both the hot and cold possibilities here

878
01:00:41,040 --> 01:00:43,500
we consider going through here and going through here

879
01:00:43,530 --> 01:00:46,970
so the numbers are getting smaller we are making some choice for not choosing the

880
01:00:46,970 --> 01:00:50,410
the animation of the body that that argument if it doesn't work but now we've

881
01:00:50,410 --> 01:00:51,520
got a new one

882
01:00:51,540 --> 01:00:56,740
you need the soul in order to explain free will

883
01:00:56,760 --> 01:01:01,540
when we come back to that argument later to good arguments as that are well

884
01:01:01,540 --> 01:01:06,010
worth taking seriously let's come back to later first let's run through some other things

885
01:01:06,010 --> 01:01:11,160
that might be appealed to as candidates for feature

886
01:01:11,180 --> 01:01:14,060
suppose somebody said look you know it's true

887
01:01:14,810 --> 01:01:18,540
we don't need to appeal to solve in order to explain why bodies move around

888
01:01:18,540 --> 01:01:20,870
and non random fashion but

889
01:01:22,350 --> 01:01:27,190
i have a very special ability and so the argument goes that mere bodies couldn't

890
01:01:27,190 --> 01:01:31,020
have physical can explain that the ability

891
01:01:31,040 --> 01:01:32,600
to think

892
01:01:32,620 --> 01:01:33,910
it's the ability

893
01:01:33,930 --> 01:01:35,560
two reasons

894
01:01:35,600 --> 01:01:38,180
people have beliefs

895
01:01:38,200 --> 01:01:40,180
and desires

896
01:01:40,260 --> 01:01:43,870
and based on their beliefs about how to

897
01:01:43,890 --> 01:01:46,200
to fill their desires

898
01:01:47,760 --> 01:01:55,280
they they play they make plans to have strategies the reason about what to do

899
01:01:55,290 --> 01:02:00,260
this this this tightly connected set of facts about us

900
01:02:00,260 --> 01:02:02,510
beliefs desires reasoning

901
01:02:02,540 --> 01:02:06,560
strategizing planning

902
01:02:06,580 --> 01:02:11,510
you need to appeal to so the argument goes you need to appeal to us all

903
01:02:11,540 --> 01:02:13,450
to explain that

904
01:02:14,310 --> 01:02:17,080
mere machine

905
01:02:17,100 --> 01:02:18,290
could believe

906
01:02:18,310 --> 01:02:20,280
no mere machine

907
01:02:20,290 --> 01:02:21,740
has desires

908
01:02:21,760 --> 01:02:27,450
no mere machine could reason

909
01:02:29,350 --> 01:02:34,140
easy to see why you might think that sort of thing when you stick to

910
01:02:34,140 --> 01:02:36,430
sort of simple machines

911
01:02:36,450 --> 01:02:40,520
it's pretty clear that there are lots of machine that doesn't seem natural to ascribe

912
01:02:40,520 --> 01:02:43,450
beliefs desires or goals are reason

913
01:02:43,450 --> 01:02:46,680
my lawn mower for example

914
01:02:46,680 --> 01:02:47,760
it doesn't

915
01:02:48,830 --> 01:02:51,280
to cut the grass

916
01:02:51,810 --> 01:02:55,930
even though it does cut the grass doesn't have the desire it doesn't think to

917
01:02:55,930 --> 01:03:02,910
itself how shall i get that laid that's of graph has been eluding me

918
01:03:02,930 --> 01:03:06,060
so it's easy to see why we might be tempted to say

919
01:03:06,950 --> 01:03:08,660
mere machine

920
01:03:08,720 --> 01:03:13,450
could think or reason why have beliefs or desires

921
01:03:13,510 --> 01:03:17,010
that argument is much less compelling nowadays

922
01:03:17,870 --> 01:03:19,740
i think it would have been twenty

923
01:03:19,740 --> 01:03:21,600
forty years ago

924
01:03:21,600 --> 01:03:23,430
in an era of

925
01:03:25,390 --> 01:03:32,490
it seems with quite sophisticated computer programs it seems at least at the very least

926
01:03:33,970 --> 01:03:35,390
to talk about

927
01:03:37,870 --> 01:03:42,870
and reasoning and strategizing so suppose for example

928
01:03:42,890 --> 01:03:45,700
we've got a chess playing computer

929
01:03:45,720 --> 01:03:51,020
my computer at home i got a program that allows my chest to play computer

930
01:03:51,040 --> 01:03:52,430
i myself

931
01:03:52,450 --> 01:03:54,830
i think that just this

932
01:03:54,870 --> 01:03:58,260
this program can be me made know blind

933
01:04:00,020 --> 01:04:01,660
i move

934
01:04:02,760 --> 01:04:04,160
my bishop

935
01:04:04,200 --> 01:04:07,700
the computer moves its queens

936
01:04:07,760 --> 01:04:09,370
what we say

937
01:04:09,390 --> 01:04:15,850
about the computer why did the computer move its queen or virtual queen why computer

938
01:04:15,850 --> 01:04:16,970
move queen

939
01:04:16,990 --> 01:04:19,830
well the natural thing to say is

940
01:04:19,850 --> 01:04:24,910
it's worried about the fact that the king is exposed

941
01:04:24,910 --> 01:04:27,720
and it's trying to block me

942
01:04:27,740 --> 01:04:32,140
by capturing my fisher

943
01:04:32,160 --> 01:04:33,450
that is what we say

944
01:04:33,450 --> 01:04:36,720
about computer playing programmes

945
01:04:36,740 --> 01:04:38,830
think about what we're doing

946
01:04:38,850 --> 01:04:40,390
worst driving

947
01:04:40,390 --> 01:04:42,720
desires to the programme

948
01:04:42,740 --> 01:04:43,810
we're saying

949
01:04:43,830 --> 01:04:49,010
it's got an ultimate desire to win the game certain subsidiary desires to protect its

950
01:04:49,060 --> 01:04:54,510
king capture my king certain other subsidiaries are out to protect its various other pieces

951
01:04:54,510 --> 01:04:55,560
along the way

952
01:04:55,580 --> 01:05:01,040
it's got beliefs about how to do that by blocking certain patterns

953
01:05:01,060 --> 01:05:01,990
or by

954
01:05:02,010 --> 01:05:07,330
exposing make other pieces on my side vulnerable it's got beliefs about how to achieve

955
01:05:07,330 --> 01:05:08,540
its goals

956
01:05:08,600 --> 01:05:09,560
and then it's

957
01:05:09,580 --> 01:05:11,470
puts those

958
01:05:11,490 --> 01:05:17,020
combinations of beliefs and desires into action by moving in a way that a rational

959
01:05:18,490 --> 01:05:20,490
to my move

960
01:05:21,850 --> 01:05:23,780
it looks as though

961
01:05:23,780 --> 01:05:28,490
the natural thing to say about the chess playing computer is it does have beliefs

962
01:05:28,540 --> 01:05:35,060
it does have desires it does have intentions it does have goals it does reason

963
01:05:35,060 --> 01:05:38,040
it does all of this it

964
01:05:39,390 --> 01:05:40,640
to this

965
01:05:40,700 --> 01:05:45,470
limited extent only able to play chess but to that extent it's doing all these

966
01:05:45,470 --> 01:05:46,580
things and yet

967
01:05:46,620 --> 01:05:50,080
we're not tempted to say are we that are

968
01:05:50,080 --> 01:05:52,810
computer has a non-physical part

969
01:05:52,830 --> 01:06:00,290
we can explain how the computer does all this in strictly physical terms

970
01:06:00,310 --> 01:06:05,620
and of course once you start thinking about this way it's natural to talk this

971
01:06:05,620 --> 01:06:07,020
way and

972
01:06:07,100 --> 01:06:10,850
because of course the right across a variety of

973
01:06:10,890 --> 01:06:16,760
things that the computer maybe trying to do

974
01:06:16,810 --> 01:06:23,470
now because it's perfectly open to you as jules to respond by saying

975
01:06:23,490 --> 01:06:24,990
although we

976
01:06:27,450 --> 01:06:28,830
the computer

977
01:06:28,830 --> 01:06:32,240
we treat it as though it was the person

978
01:06:32,260 --> 01:06:34,600
as we know it had beliefs

979
01:06:34,600 --> 01:06:37,600
and desires and so forth

980
01:06:37,600 --> 01:06:41,150
coming back to the stuff we're talking about before with structured output

981
01:06:41,170 --> 01:06:46,970
the undirected ones actually got more commonly used than directed one so for example

982
01:06:47,050 --> 01:06:49,780
ground this thing into

983
01:06:49,790 --> 01:06:53,190
c natural language or some kind of

984
01:06:53,790 --> 01:06:58,150
it's sequences in bioinformatics same label

985
01:06:58,160 --> 01:06:59,730
introns exons

986
01:06:59,740 --> 01:07:04,160
one thousand miles in HMM right i have state variables

987
01:07:05,110 --> 01:07:08,520
generating some kind of observations so let's call these

988
01:07:08,530 --> 01:07:10,810
why is why

989
01:07:10,820 --> 01:07:13,570
no one x one

990
01:07:13,590 --> 01:07:15,330
y two

991
01:07:15,340 --> 01:07:16,250
thanks to

992
01:07:17,980 --> 01:07:22,000
so by the way the variable elimination algorithm

993
01:07:22,050 --> 01:07:23,640
will correspond to

994
01:07:23,650 --> 01:07:25,830
if you eliminate

995
01:07:25,850 --> 01:07:27,900
this way something like

996
01:07:27,950 --> 01:07:31,630
four it you need to backward if you want to get everything else back but

997
01:07:31,630 --> 01:07:36,560
i look forward backward or itterby algorithms will be exactly the

998
01:07:36,670 --> 01:07:40,420
instantiation of information about that but this is

999
01:07:40,620 --> 01:07:45,160
direct version of this there's a much more popular version of for doing this kind

1000
01:07:45,160 --> 01:07:50,330
of tasks that one so you building watson intron exon centre or enabling things like

1001
01:07:50,360 --> 01:07:54,860
part of speech or named entity recognition or whatever in natural language

1002
01:07:54,880 --> 01:07:58,730
so more common models of this year conditional random fields

1003
01:07:58,750 --> 01:08:00,470
that's the thing i talked about

1004
01:08:00,480 --> 01:08:05,210
in the first hour so you can think of it more as like that

1005
01:08:05,220 --> 01:08:13,390
right it's basically undirected edges these my my y max is very different but what

1006
01:08:13,390 --> 01:08:15,220
happens is we can

1007
01:08:15,340 --> 01:08:16,530
very subtle

1008
01:08:16,540 --> 01:08:22,210
i have different where we can learn this thing conditional to be conditional distribution which

1009
01:08:22,210 --> 01:08:27,900
is this p of y given x as opposed to the gay which stressed model

1010
01:08:28,800 --> 01:08:31,300
x come why both of them

1011
01:08:31,320 --> 01:08:36,500
and this is the standard of discriminative versus generative trade-off in

1012
01:08:36,520 --> 01:08:44,010
in supervised learning to compare something like bayes against the CMC

1013
01:08:44,030 --> 01:08:46,540
it doesn't do so well maybe by the way

1014
01:08:46,630 --> 01:08:50,940
just to be clear

1015
01:08:50,950 --> 01:08:53,960
its main base we have some class variable

1016
01:08:53,980 --> 01:08:55,330
and generates features

1017
01:08:55,350 --> 01:08:58,620
so it's one of the simplest bayes nets

1018
01:08:58,630 --> 01:09:00,090
and there is

1019
01:09:00,100 --> 01:09:04,320
so this doesn't do as well from when you have an opinion of data as

1020
01:09:04,320 --> 01:09:07,110
well as an SVM or something that's essentially

1021
01:09:07,120 --> 01:09:09,750
you pointing to on the other way

1022
01:09:10,070 --> 01:09:13,380
so these things are posterior estimates that the

1023
01:09:13,470 --> 01:09:15,350
kind of structured output stuff

1024
01:09:15,370 --> 01:09:16,850
built upon

1025
01:09:17,090 --> 01:09:20,280
OK so

1026
01:09:20,290 --> 01:09:24,030
directed models that are actually might be useful

1027
01:09:24,240 --> 01:09:27,570
in a lot of situations where we have

1028
01:09:27,580 --> 01:09:31,670
unlabelled data so we need since the generative models

1029
01:09:31,680 --> 01:09:33,150
in order to complete

1030
01:09:33,160 --> 01:09:38,280
complete hidden variables have a latent latent structure that we're trying to kind of used

1031
01:09:38,280 --> 01:09:39,540
to explain the data

1032
01:09:39,560 --> 01:09:44,400
in directed models are usually the best thing that

1033
01:09:44,960 --> 01:09:46,300
OK so

1034
01:09:46,770 --> 01:09:54,020
right so moralisation it's the term kind old-fashioned term what that means is basically

1035
01:09:54,030 --> 01:10:01,080
we're taking our business turning it into kind of an equivalent markov networks because of

1036
01:10:01,080 --> 01:10:03,320
the inference algorithms work on

1037
01:10:03,330 --> 01:10:05,250
markov networks so

1038
01:10:05,320 --> 01:10:07,240
five to here there is no

1039
01:10:07,320 --> 01:10:10,670
there's no question what to do in this district translates into this

1040
01:10:10,710 --> 01:10:12,930
we can basically take

1041
01:10:12,950 --> 01:10:16,450
this conditional probability table in color factor

1042
01:10:16,500 --> 01:10:18,740
you know there's some to anything

1043
01:10:18,750 --> 01:10:21,520
to factor factor to to

1044
01:10:22,290 --> 01:10:23,500
comes have

1045
01:10:23,520 --> 01:10:26,350
these structures

1046
01:10:26,360 --> 01:10:31,410
basically what's what's called american parents right so so you have to this that are

1047
01:10:31,410 --> 01:10:36,220
not connected OK so now i'm factor here that's over three variables x y and

1048
01:10:36,220 --> 01:10:41,260
z ratified just introduced too far too wise e and

1049
01:10:41,280 --> 01:10:43,460
x z

1050
01:10:43,510 --> 01:10:49,190
canada was reason full correlation between what i need is a factor over x y

1051
01:10:49,210 --> 01:10:57,510
and hands what we do is take this thing and map into market networks we

1052
01:10:57,520 --> 01:10:59,030
introduced edges

1053
01:10:59,050 --> 01:11:02,990
between unmarried and that's called moralisation

1054
01:11:03,010 --> 01:11:07,460
very simple things that allows you now makes clique there and then we can put

1055
01:11:07,460 --> 01:11:09,970
it we can kind of comedy are

1056
01:11:09,990 --> 01:11:12,530
cpt the conditional probability table

1057
01:11:12,690 --> 01:11:14,810
from the business science

1058
01:11:14,830 --> 01:11:17,100
this fact

1059
01:11:19,520 --> 01:11:20,480
OK so

1060
01:11:20,490 --> 01:11:26,080
is an example so here's our graphical model here

1061
01:11:26,090 --> 01:11:31,820
we have mary on the parents that that line vendor ones

1062
01:11:31,840 --> 01:11:37,630
OK and then once everything is moralize we just drop the direction

1063
01:11:37,640 --> 01:11:40,550
that's it so that's kind of one of preparation for

1064
01:11:45,510 --> 01:11:50,490
so now we have to be talking just mapped everything into undirected models now let's

1065
01:11:50,490 --> 01:11:54,970
look back at that variable elimination thing we did without any reference to graph structure

1066
01:11:54,980 --> 01:11:59,950
all we need needed there was conditional independencies right we do it without any definitions

1067
01:11:59,950 --> 01:12:03,670
of business or market that you can do it now

1068
01:12:03,710 --> 01:12:07,360
and this is my first sense in terms of graph OK so there are

1069
01:12:07,380 --> 01:12:10,690
this intermediate factors there are being created when you

1070
01:12:10,700 --> 01:12:13,190
eliminate things and they

1071
01:12:13,210 --> 01:12:16,060
essentially correspond to to

1072
01:12:16,070 --> 01:12:19,140
factors in reduced graphical model

1073
01:12:19,150 --> 01:12:21,870
so you can think of variable elimination as the way to

1074
01:12:21,880 --> 01:12:23,080
take a model

1075
01:12:23,090 --> 01:12:25,930
and then kind of some of one variable a time

1076
01:12:25,940 --> 01:12:28,050
you some

1077
01:12:28,120 --> 01:12:30,030
time what might happen is introduced

1078
01:12:30,040 --> 01:12:32,490
new correlation between the remaining variables

1079
01:12:32,500 --> 01:12:36,040
and so

1080
01:12:36,050 --> 01:12:42,850
that's exactly what we're not elimination is essentially variable elimination but just to conceive graphically

1081
01:12:42,850 --> 01:12:47,740
so you know and then you create mission clique which means you take

1082
01:12:47,770 --> 01:12:50,000
all of its neighbors

1083
01:12:50,020 --> 01:12:55,890
and and you know make the cliques so you connect all the neighbors ahead of

1084
01:12:55,890 --> 01:12:59,020
also an example basically all the neighbours of this node i'm not going to be

1085
01:12:59,020 --> 01:13:00,830
interconnected to whoever

1086
01:13:00,830 --> 01:13:05,060
things but i'm going to put my strongly entrenched things at the top

1087
01:13:05,080 --> 01:13:09,430
OK now as i said what entrenchment is essentially an ordering over the formulas in

1088
01:13:12,640 --> 01:13:16,370
if you remember back to the rationality properties that we had at the outset one

1089
01:13:16,370 --> 01:13:18,950
of the rationality properties so that if we got

1090
01:13:18,970 --> 01:13:21,140
a preference between any two formulas

1091
01:13:21,240 --> 01:13:24,540
you have to give one i prefer to give up the least preferred to the

1092
01:13:24,540 --> 01:13:25,510
most profound

1093
01:13:25,520 --> 01:13:27,600
so he was going to say that we're going to try and give up the

1094
01:13:27,600 --> 01:13:31,770
least entrenched over the most entrenched

1095
01:13:31,790 --> 01:13:35,600
i can as actually what this ordering looks like is as follows

1096
01:13:35,640 --> 01:13:37,750
the most important stuff

1097
01:13:37,810 --> 01:13:40,180
so the most deeply entrenched

1098
01:13:40,180 --> 01:13:42,100
which is the it is the top

1099
01:13:42,120 --> 01:13:43,660
the tautologies

1100
01:13:43,890 --> 01:13:46,830
things that are always true

1101
01:13:46,870 --> 01:13:48,520
then we've got

1102
01:13:48,520 --> 01:13:50,180
all of these levels

1103
01:13:51,600 --> 01:13:53,970
at the very bottom

1104
01:13:53,990 --> 01:13:55,950
i got all the formulas by

1105
01:13:55,970 --> 01:13:59,180
such that is not order

1106
01:13:59,200 --> 01:14:07,020
so these are all the non

1107
01:14:07,060 --> 01:14:09,930
can we got this entrenchment

1108
01:14:11,200 --> 01:14:13,370
between forms

1109
01:14:13,470 --> 01:14:17,270
so at the outset we said that you know in this belief change problem we

1110
01:14:17,270 --> 01:14:20,770
can use logical criteria line so essentially what we're going to do is we're going

1111
01:14:20,770 --> 01:14:22,490
to add to our logic

1112
01:14:24,720 --> 01:14:27,640
epistemic entrenchment this relation over formulas

1113
01:14:27,720 --> 01:14:32,430
which tells us how important performers are relative importance of one

1114
01:14:35,700 --> 01:14:37,200
OK so formally the

1115
01:14:37,200 --> 01:14:38,520
this relation

1116
01:14:38,540 --> 01:14:40,060
has the following properties

1117
01:14:40,080 --> 01:14:42,620
the first is that satisfies transitivity

1118
01:14:46,120 --> 01:14:48,390
you know

1119
01:14:49,060 --> 01:14:50,540
yes i should draw this this

1120
01:14:52,080 --> 01:14:53,310
one x

1121
01:14:53,370 --> 01:14:54,660
to be

1122
01:14:54,740 --> 01:14:56,430
do this in one x

1123
01:14:56,450 --> 01:14:59,100
even more important

1124
01:14:59,410 --> 01:15:04,160
so if x is more important than why why is more important than that of

1125
01:15:04,160 --> 01:15:05,290
course exist

1126
01:15:05,620 --> 01:15:08,410
transitivity holes

1127
01:15:08,750 --> 01:15:13,680
the second one says that

1128
01:15:13,740 --> 01:15:18,390
if size the conclusion of five follows from five

1129
01:15:18,430 --> 01:15:22,140
then size more important five

1130
01:15:22,270 --> 01:15:24,700
say what you think

1131
01:15:24,740 --> 01:15:25,930
OK why

1132
01:15:25,930 --> 01:15:27,560
why is that the case

1133
01:15:29,870 --> 01:15:32,040
let's put it this way that if

1134
01:15:32,040 --> 01:15:34,120
if i if i

1135
01:15:38,160 --> 01:15:43,270
and i want to remove side

1136
01:15:43,270 --> 01:15:48,140
do i have to refine

1137
01:15:48,200 --> 01:15:53,600
so a five three sign i one

1138
01:15:53,640 --> 01:16:04,220
is finding

1139
01:16:04,290 --> 01:16:06,990
and better not be because if it is

1140
01:16:06,990 --> 01:16:09,850
from the five precise going to get it back

1141
01:16:09,890 --> 01:16:13,370
so if i do retain five

1142
01:16:13,410 --> 01:16:16,870
when i want to give up so i was going to get syed back because

1143
01:16:16,870 --> 01:16:21,410
phi tells simon remember that came minus five deductively closed for us

1144
01:16:21,640 --> 01:16:26,180
so if i want to so i have to give up five i can not

1145
01:16:26,180 --> 01:16:29,120
give up five because it violated there's going entail

1146
01:16:30,990 --> 01:16:34,290
on the other hand if i want to give five

1147
01:16:34,350 --> 01:16:36,810
but there's no reason for me to give up side

1148
01:16:36,830 --> 01:16:39,200
can retain sci-fi really want to

1149
01:16:39,240 --> 01:16:42,450
OK so that tells me that size is going to be at least as important

1150
01:16:42,450 --> 01:16:43,180
as far

1151
01:16:44,140 --> 01:16:46,620
i have to i have to always give up five

1152
01:16:46,620 --> 01:16:48,350
but in some cases

1153
01:16:48,410 --> 01:16:51,290
can retain i can retain side

1154
01:16:51,410 --> 01:16:58,640
OK now is the second possible tells us that we know that phi

1155
01:16:58,740 --> 01:16:59,660
and so i

1156
01:16:59,680 --> 01:17:00,970
tells phi

1157
01:17:01,040 --> 01:17:02,830
that also entails psi

1158
01:17:02,890 --> 01:17:04,490
so by this first

1159
01:17:04,490 --> 01:17:08,430
this image is what are the dominant orientation so the picture

1160
01:17:08,440 --> 01:17:12,830
so the jews what they call the manhattan greedy assumption is many human images that

1161
01:17:12,830 --> 01:17:16,850
contain only basically two dominant axis and the only thing that you want to know

1162
01:17:16,850 --> 01:17:21,330
is what is the invention of the camera relative to the axis

1163
01:17:21,350 --> 01:17:22,830
so here

1164
01:17:22,850 --> 01:17:26,450
all the parameters that you need to know is what is the the elevation of

1165
01:17:26,450 --> 01:17:27,920
the ground

1166
01:17:27,930 --> 01:17:31,110
and then what is the relative orientation of the camera with respect to the

1167
01:17:31,120 --> 01:17:32,620
to the great

1168
01:17:32,650 --> 01:17:36,870
and because that's very limited is very few information that you need to collect the

1169
01:17:37,240 --> 01:17:40,560
very few parameters that define the camera you can do that but you've obviously from

1170
01:17:40,560 --> 01:17:44,200
the image so this information that you can get very is from the picture

1171
01:17:44,330 --> 01:17:48,370
and once you've done that then you can label different edges in the image as

1172
01:17:48,370 --> 01:17:52,170
belonging to one of the dominant orientation in this great

1173
01:17:52,300 --> 01:17:56,120
which is basically all you need to start getting some simple for

1174
01:17:56,130 --> 01:18:01,610
so here the new images receiving in-depth are marked in red and then vertical lines

1175
01:18:01,620 --> 01:18:02,740
are marked in blue

1176
01:18:02,750 --> 01:18:06,730
but alas the camera in green

1177
01:18:06,750 --> 01:18:09,650
another thing that they can do then is once you had these you can try

1178
01:18:09,650 --> 01:18:13,790
to see which of just violate great which have just outside of the manhattan great

1179
01:18:14,170 --> 01:18:17,660
so here is an example in which they had this scene and it is this

1180
01:18:17,660 --> 01:18:22,030
bicycle here and edges of the bicycle don't aligned with the great so they are

1181
01:18:22,030 --> 01:18:26,700
able to pop out this bicycle some parts of the bicycle has been something that

1182
01:18:26,700 --> 01:18:28,910
violates the manhattan greedy assumptions

1183
01:18:28,930 --> 01:18:32,830
also the three here seems to imagine that

1184
01:18:34,200 --> 01:18:38,920
there is this interesting paper about community c and system and all single view metrology

1185
01:18:39,320 --> 01:18:42,830
which is an interesting read if you want to know about most of the things

1186
01:18:42,830 --> 01:18:47,880
that you need to know in order to solve a simple geometric problems from single

1187
01:18:49,420 --> 01:18:52,040
and of course you can also just stereo vision

1188
01:18:52,200 --> 01:18:56,430
but you monocular images is also very interesting because many of the images on the

1189
01:18:56,430 --> 01:18:58,880
web are always going to be monocular

1190
01:18:58,900 --> 01:19:03,230
and also most of the time even for humans you are using monocular cues most

1191
01:19:03,230 --> 01:19:07,310
of the time stereo is good for short range things but as soon as things

1192
01:19:07,320 --> 01:19:12,740
get far away stereo become so weak real monocular cues are dominant

1193
01:19:12,860 --> 01:19:18,600
and so there is this work OK thank you and

1194
01:19:18,690 --> 01:19:22,720
there is this this this work by

1195
01:19:22,780 --> 01:19:28,240
and there are k first anniversary in which they also very simple geometric information about

1196
01:19:28,240 --> 01:19:33,730
the scene in order to provide context information from detections so in this case again

1197
01:19:33,740 --> 01:19:38,160
they company image if you know what the camera is i you know what the

1198
01:19:38,160 --> 01:19:43,380
ground plane is you know what i suspected sizes of objects in the picture you

1199
01:19:43,380 --> 01:19:47,500
also know what should be the relative locations with respect to the ground plane

1200
01:19:47,520 --> 01:19:52,210
so for instance here if you have all these just here and you know that

1201
01:19:52,250 --> 01:19:56,330
all discussion of this people they are sitting on the ground therefore they should be

1202
01:19:56,330 --> 01:19:58,690
aligned with the right online

1203
01:19:58,710 --> 01:20:02,470
and you can infer with ISO online is by just looking at this very simple

1204
01:20:02,470 --> 01:20:04,560
perspective patterns from image

1205
01:20:04,560 --> 01:20:09,620
so once you have that information can be like a book review of this image

1206
01:20:09,620 --> 01:20:13,590
and once hundred detections you can know what are the three locations of objects in

1207
01:20:13,600 --> 01:20:18,360
image and this is all done from a single view there's no stereo images here

1208
01:20:18,420 --> 01:20:23,290
so here is an example of how you can use this to improve detection so

1209
01:20:23,290 --> 01:20:28,190
this will be the actions don without integrating any information about geometry so here you

1210
01:20:28,190 --> 01:20:31,020
we have a bit of detectors can detect errors

1211
01:20:31,030 --> 01:20:34,570
if you have also just happened st and there are some false alarms over there

1212
01:20:34,760 --> 01:20:38,360
two was you know what the ground plane is

1213
01:20:38,490 --> 01:20:41,800
and you know that i online is here that can help you to remove most

1214
01:20:41,800 --> 01:20:44,600
of the false alarm so all the false alarms that were on top of the

1215
01:20:44,600 --> 01:20:46,490
building are

1216
01:20:46,500 --> 01:20:50,370
then the detections that were maybe two weeks before now become more confidence and i

1217
01:20:50,370 --> 01:20:52,690
do know that all these are all pedestrians

1218
01:20:52,720 --> 01:20:55,850
there are so many false alarms that like this one here the

1219
01:20:55,870 --> 01:20:58,460
there is not really understand or here

1220
01:20:58,490 --> 01:21:02,250
but again it's detection of what's cooking with context i got hands

1221
01:21:02,390 --> 01:21:07,480
so in this in this case that using an explicit representation of the information but

1222
01:21:07,500 --> 01:21:08,720
is very simple

1223
01:21:08,720 --> 01:21:11,650
three the information is just the actual line

1224
01:21:11,670 --> 01:21:14,830
it's is very very basic human need to have a full three d reconstruction of

1225
01:21:14,830 --> 01:21:15,890
the image

1226
01:21:15,940 --> 01:21:20,150
there's another piece of work also do seem for the information in this case they

1227
01:21:20,150 --> 01:21:22,980
also introduced earlier

1228
01:21:22,990 --> 01:21:26,900
and they have a car driving on the street and the goal is to reconstruct

1229
01:21:26,900 --> 01:21:31,480
the straight into indentified or just within so again you can have a kind of

1230
01:21:31,720 --> 01:21:33,600
shows the many false alarms

1231
01:21:33,620 --> 01:21:37,220
one is integrated information to get rid of most of the four times and you

1232
01:21:37,220 --> 01:21:42,370
can even put a small for the cubes around just to have detected

1233
01:21:42,380 --> 01:21:46,540
and you can also have a more restricted eighty three d representation not just the

1234
01:21:46,540 --> 01:21:51,710
ground plane and but try to actually get a moral discourse representation of what the

1235
01:21:51,710 --> 01:21:53,790
three d of the picture is

1236
01:21:53,790 --> 01:21:57,750
so there is a bunch of water that now have appeared on the community but

1237
01:21:57,750 --> 01:21:58,740
have recently

1238
01:21:58,790 --> 01:22:05,600
trying to give a single image get simple representation of the three the picture is

1239
01:22:05,660 --> 01:22:10,170
and that representation can be something like joe's into names with the ground plane and

1240
01:22:10,170 --> 01:22:14,720
if you were to planes that percent like buildings and so on and so there

1241
01:22:14,730 --> 01:22:19,100
is this work again by of in which given an image

1242
01:22:19,130 --> 01:22:21,030
the first segment the image and now

1243
01:22:21,030 --> 01:22:25,220
it's segment you have to decide if it is some segment or a vertical segment

1244
01:22:25,240 --> 01:22:30,540
and you can do that quite reliably again because general trying to do very fine

1245
01:22:30,540 --> 01:22:34,630
you know attracted to the sum directors for example

1246
01:22:34,670 --> 01:22:38,290
it's not a joke i

1247
01:22:39,750 --> 01:22:44,810
at the end

1248
01:22:50,150 --> 01:22:54,920
i would like to share

1249
01:22:54,960 --> 01:22:57,270
is much more much astronomy the

1250
01:23:00,310 --> 01:23:04,560
for real

1251
01:23:04,580 --> 01:23:07,060
hi temple

1252
01:23:07,110 --> 01:23:10,210
the long tail to be brought to the didn't have before

1253
01:23:10,230 --> 01:23:13,190
the creation those are much stronger

1254
01:23:13,290 --> 01:23:16,750
did on sets of the nodes that have been changed

1255
01:23:16,770 --> 01:23:18,850
so is it was more swing

1256
01:23:18,860 --> 01:23:22,360
more string and the input so all these are

1257
01:23:22,380 --> 01:23:26,630
decisions taken by the system and actually implement

1258
01:23:26,690 --> 01:23:30,710
i don't understand what

1259
01:23:47,230 --> 01:23:49,730
the is lower frequency than

1260
01:23:49,730 --> 01:23:53,500
and how you can not just tool

1261
01:23:59,420 --> 01:24:03,540
noticeable and

1262
01:24:03,560 --> 01:24:08,460
slower tempo will always much more

1263
01:24:08,480 --> 01:24:13,630
the just OK so

1264
01:24:13,630 --> 01:24:21,330
now a few words about the tempoexpress one lesson we learned from this exit system

1265
01:24:21,330 --> 01:24:24,130
is that the effect of the temple

1266
01:24:24,150 --> 01:24:29,130
on this facility was crucial was extremely extremely important

1267
01:24:29,150 --> 01:24:34,520
then with its leader the church search and we found several papers and we have

1268
01:24:34,540 --> 01:24:35,690
to our surprise

1269
01:24:35,710 --> 01:24:43,710
we found that there was some controversy about the effect of of temple in music

1270
01:24:43,850 --> 01:24:48,560
for example there is a well known well cited worldwide

1271
01:24:50,130 --> 01:24:54,270
he says that uniform time stretching is enough

1272
01:24:54,290 --> 01:24:59,750
to change from one template to another temple uniform time stretching means that for example

1273
01:24:59,750 --> 01:25:04,500
if you have two hundred and ninety bpm

1274
01:25:04,500 --> 01:25:08,830
this discriminative temple two hundred so increase by twenty percent

1275
01:25:08,850 --> 01:25:11,420
well you you just what you have to do

1276
01:25:11,580 --> 01:25:15,830
want to the temple after the duration decreases by twenty five percent

1277
01:25:16,150 --> 01:25:18,960
one divided by zero point eight

1278
01:25:18,980 --> 01:25:24,270
there are other people however publish papers

1279
01:25:24,350 --> 01:25:28,040
again is that because the human contributions

1280
01:25:28,090 --> 01:25:33,810
that uniform time stretching may work in some particular situations but in general is not

1281
01:25:33,850 --> 01:25:38,900
used up to that in works so you lose you lose lots of musicality of

1282
01:25:38,920 --> 01:25:45,060
musical quality maybe not sound quality different sound quality can be very good but musical

1283
01:25:45,060 --> 01:25:46,230
quality not

1284
01:25:46,270 --> 01:25:52,060
music qualities is more associated with specific so very well known people and peter hunting

1285
01:25:52,150 --> 01:25:55,460
from kth or undigested back

1286
01:25:55,540 --> 01:25:58,730
they provide counter evidence on some cases and

1287
01:25:58,770 --> 01:26:04,520
on the other hand said the listeners are capable to distinguish above chance level between

1288
01:26:04,520 --> 01:26:09,540
a recording of a performance that has been uniformly time restriction to temple from my

1289
01:26:09,540 --> 01:26:13,290
system but i know the original recording of the target temple

1290
01:26:13,310 --> 01:26:18,750
and this formation by peter hunting is that expressivity is a result of the conception

1291
01:26:18,750 --> 01:26:22,730
of the music by the performer and this conception changes with tempo

1292
01:26:22,770 --> 01:26:25,580
when you are told to play of the of even tempo

1293
01:26:25,590 --> 01:26:26,420
you do

1294
01:26:26,440 --> 01:26:30,580
you some expressive resources and when you multiply it another temple

1295
01:26:30,610 --> 01:26:31,480
if it is

1296
01:26:31,500 --> 01:26:33,540
of course significant difference

1297
01:26:33,540 --> 01:26:36,000
construction is different in your play

1298
01:26:36,000 --> 01:26:40,250
this is only in terms of a specific so what we did is let's see

1299
01:26:40,650 --> 01:26:45,110
well actually uses this shows an example of how the onset

1300
01:26:45,130 --> 01:26:50,480
the onset of the nodes drastically changes from a slower tempo too fast temple for

1301
01:26:50,560 --> 01:26:56,210
faster temple much more nodes are anticipated than slower tempo for the saying the same

1302
01:26:58,640 --> 01:27:01,190
this is the same happens with all the other

1303
01:27:01,190 --> 01:27:10,020
although expressive services like ornamentation consolidations implementations of nodes that was you know what

1304
01:27:10,040 --> 01:27:13,610
so many things change as a function of temple so what we did was the

1305
01:27:13,610 --> 01:27:15,270
goal is to

1306
01:27:16,540 --> 01:27:19,080
i said that was should the selfless

1307
01:27:19,090 --> 01:27:21,560
how to automatically change the temple

1308
01:27:21,560 --> 01:27:24,080
of the performance

1309
01:27:24,090 --> 01:27:29,580
preserving expressivity or adopting this specifically so that at the target tempo

1310
01:27:29,650 --> 01:27:31,790
that's still does in meet the

1311
01:27:31,810 --> 01:27:34,230
the musicality of the performances

1312
01:27:34,250 --> 01:27:35,060
it is

1313
01:27:35,060 --> 01:27:37,770
at least as good as the source temple

1314
01:27:37,790 --> 01:27:43,080
and i was in the context of jazz standards not only just ballots success maybe

1315
01:27:43,080 --> 01:27:47,110
i didn't say that but just sex is limited right now to jazz ballads it

1316
01:27:47,480 --> 01:27:48,790
to just

1317
01:27:48,860 --> 01:27:53,960
and this has a very interesting application by the way and we had to we

1318
01:27:53,960 --> 01:28:01,210
had contact with with with new post processing company the software company

1319
01:28:01,270 --> 01:28:04,460
my nose the manly

1320
01:28:04,480 --> 01:28:07,540
is done mainly in commercial farming TV commercials

1321
01:28:07,560 --> 01:28:12,190
the commercial how limited the very limited number of seconds

1322
01:28:12,210 --> 01:28:18,920
the commercial very expensive right and then the video constrains the only

1323
01:28:18,980 --> 01:28:22,520
maybe you have a beautiful view that google very well with this story with these

1324
01:28:22,520 --> 01:28:27,040
images but it is a slightly longer do you don't want just look at it

1325
01:28:27,040 --> 01:28:31,040
like this drastically you would like to know to stretch it or to make it

1326
01:28:31,040 --> 01:28:35,330
shorter or longer depending on the on the original temple OK

1327
01:28:35,350 --> 01:28:40,150
so that it will fit the the fifteenth second order and the second iteration of

1328
01:28:40,150 --> 01:28:45,330
the commercial so these instead of being done manually takes hours and hours

1329
01:28:45,380 --> 01:28:46,130
with the

1330
01:28:46,210 --> 01:28:49,170
tempoexpress it can take minutes following

1331
01:28:49,170 --> 01:28:54,050
that the city and again if that fraction is relatively high then it turns out

1332
01:28:54,080 --> 01:28:56,850
i can actually compute the probability

1333
01:28:58,160 --> 01:29:02,950
barcelona's city based on the tax one important caveat is when we do these counts

1334
01:29:03,100 --> 01:29:08,810
it's important to do those over independent sentences often write sentences are repeated over the

1335
01:29:08,810 --> 01:29:13,740
web other quoted and we don't want to count we have a variety of ways

1336
01:29:13,740 --> 01:29:18,760
of determining that two sentences are likely to be independent of each other in this

1337
01:29:18,760 --> 01:29:24,330
work that doug downey did we actually formalise this very specifically just to show you

1338
01:29:24,850 --> 01:29:30,020
know we don't just build systems we actually as the precise question if an extraction

1339
01:29:30,020 --> 01:29:35,070
x appears k times in a set of n distinct sentences what is the probability

1340
01:29:35,070 --> 01:29:39,340
that x is a member a particular class classier particular relation are

1341
01:29:39,360 --> 01:29:44,610
and it turns out that we were able to derive using combinatorial model a closed

1342
01:29:44,610 --> 01:29:51,940
form solution for for exactly this this probability and this closed form solution was fifteen

1343
01:29:51,940 --> 01:29:53,980
times as accurate as

1344
01:29:54,010 --> 01:30:00,420
previous work so it turns out that using combinatorial techniques we can actually formalise a

1345
01:30:00,420 --> 01:30:06,580
lot of what's going on in these extraction processes and what's happening with with redundancy

1346
01:30:06,610 --> 01:30:11,770
so so here the key ideas in textrunner first of all open a over the

1347
01:30:11,770 --> 01:30:16,910
web is actually possible we can take arbitrary sentences and extract in english and extracting

1348
01:30:16,910 --> 01:30:19,120
meaningful information from that secondly

1349
01:30:19,580 --> 01:30:24,740
we've been able to identify a tractable subset of english it's not the case that

1350
01:30:24,740 --> 01:30:30,050
we can take any arbitrary english sentence and find meaningful extraction from an but we've

1351
01:30:30,050 --> 01:30:34,650
been able to identify tractable subset of english which is interesting in and of itself

1352
01:30:35,090 --> 01:30:39,150
and lastly where we have a bunch of ideas that i just quickly alluded to

1353
01:30:39,150 --> 01:30:43,540
of using macro reading of using redundancy over literally

1354
01:30:43,540 --> 01:30:48,490
hundreds of millions and billions of sentences to help us identify errors and to help

1355
01:30:48,490 --> 01:30:52,830
us quantify the probability that are extractions are correct

1356
01:30:52,840 --> 01:30:54,650
so the next thing we did

1357
01:30:54,700 --> 01:31:01,510
is in error analysis of textrunner relations and again even with the mechanism described there

1358
01:31:01,510 --> 01:31:06,120
are plenty of errors and operating over the entire web here are some examples of

1359
01:31:06,120 --> 01:31:10,990
incoherent relations that we found the sentence for example the guide contains that links and

1360
01:31:10,990 --> 01:31:17,570
amid sites in in the CRF labeling process it decided that the relation here's contains

1361
01:31:17,570 --> 01:31:23,470
a minutes remember has no domain specific no relation specific knowledge and we actually found

1362
01:31:23,470 --> 01:31:29,220
out about thirteen percent of the time this was occurring so that's pretty significant we

1363
01:31:29,220 --> 01:31:30,780
also found that

1364
01:31:30,780 --> 01:31:37,890
about seventy percent of the time textrunner was extracting uninformative relations would

1365
01:31:37,920 --> 01:31:42,910
extract is as the relation between two entities were really the relation was is an

1366
01:31:42,910 --> 01:31:48,600
album by or is the author of or is a city and and really problematic

1367
01:31:48,600 --> 01:31:53,550
right because it might extract something like barcelona is spain as opposed to barcelona is

1368
01:31:53,550 --> 01:31:55,150
a city in spain

1369
01:31:55,170 --> 01:32:00,730
that's not what we want so the next system we build which is just coming

1370
01:32:00,730 --> 01:32:04,590
out we have a paper in the proceedings describes and also tony fader is the

1371
01:32:04,600 --> 01:32:11,880
paper to appear shortly in EMNLP was called reverb and it said for identifying relations

1372
01:32:11,880 --> 01:32:18,040
from river from from birds and the remarkable thing about reverb is it's incredibly incredibly

1373
01:32:19,600 --> 01:32:25,560
OK and actually to to do a quick great to one of my pet peeves

1374
01:32:25,760 --> 01:32:29,690
we actually have a hard time publishing this work because we were semantic offers people

1375
01:32:29,690 --> 01:32:34,980
say well you've got very nice results reverb actually the area under the precision precision

1376
01:32:34,980 --> 01:32:39,620
recall curve for river is two hundred percent higher than for textrunner right so it's

1377
01:32:40,140 --> 01:32:45,580
easily doable and people said give various empirical but this is so simple right we

1378
01:32:45,580 --> 01:32:49,470
cannot accept this and say no no when there's a problem and somebody had a

1379
01:32:49,470 --> 01:32:54,130
complex mechanism and we come up with something incredibly simple that's interesting

1380
01:32:54,990 --> 01:32:59,570
so if you're one of the reviewers of the paper please come and see me

1381
01:32:59,570 --> 01:33:04,450
after the talk we need to have some some words here but i i really

1382
01:33:04,450 --> 01:33:09,390
think it's important and i urge all of you except simple papers right if they

1383
01:33:09,390 --> 01:33:12,850
have demonstrated what what they're trying to show you because that's one of the ways

1384
01:33:12,850 --> 01:33:17,310
that the field advances not always this by creating more complicated mechanism

1385
01:33:17,320 --> 01:33:23,380
so we describe to this ridiculously simple mechanism the first step is you find the

1386
01:33:23,380 --> 01:33:28,000
longest phrase well we assign parts of speech to the sentence right using a part

1387
01:33:28,000 --> 01:33:32,460
of speech tagger that standard NLP technology right so we know what the verbs and

1388
01:33:32,460 --> 01:33:36,600
nouns and so on are but then we find the longest phrase matching a simple

1389
01:33:36,600 --> 01:33:42,490
syntactic constraint system regular expression that has three parts either we have ever

1390
01:33:42,570 --> 01:33:48,170
or we have the verb followed by a particle which is typically proposition or we

1391
01:33:48,170 --> 01:33:54,840
have ever followed by maybe noun adjective adverb pronoun and then by particle

1392
01:33:54,870 --> 01:33:56,230
that's it

1393
01:33:56,230 --> 01:34:01,650
that is are syntactic model of relations and this is based on empirical analysis of

1394
01:34:01,650 --> 01:34:03,890
text we've had a

1395
01:34:03,920 --> 01:34:09,370
virtually all the binary relations actually map to this form so why do we just

1396
01:34:09,370 --> 01:34:14,140
look for it explicitly it's the bias for the learning system the one refinement that

1397
01:34:14,140 --> 01:34:19,150
we had to have because we're looking for the maximum phrases that length sometimes phrases

1398
01:34:19,200 --> 01:34:23,520
grow out of control so we get relations like is offering only modest greenhouse gas

1399
01:34:23,780 --> 01:34:25,300
reductions at

1400
01:34:25,340 --> 01:34:30,370
that's that's not an appropriate relations so we add one more statistical constraint over the

1401
01:34:30,370 --> 01:34:35,200
corpus we said OK if you have something explaining to bear relation to make sure

1402
01:34:35,220 --> 01:34:40,230
that you see distinct argument pairs for this relation more than k times in case

1403
01:34:40,230 --> 01:34:44,540
the parameter of the algorithm we could learn and we just set to twenty by

1404
01:34:44,540 --> 01:34:49,320
hand work great a large corpus that's

1405
01:34:49,340 --> 01:34:55,040
these two constraints essentially some small twiddles but essentially are river

1406
01:34:55,060 --> 01:34:58,330
OK and we get relations like

1407
01:34:58,340 --> 01:35:03,490
inhibits tones tumor growth and voted in favor of mastered the art of

1408
01:35:03,490 --> 01:35:08,950
wrote the book on its centre a huge variety of relations across all domains and

1409
01:35:08,950 --> 01:35:13,070
if you look at how the richness compares to previous systems you see the previous

1410
01:35:13,070 --> 01:35:18,180
systems the number relations was in the in the hundreds even learning systems like no

1411
01:35:18,520 --> 01:35:23,060
on the order of five and relations some manual efforts go up to the few

1412
01:35:23,060 --> 01:35:28,900
thousands text writer had maybe on the order of one hundred thousand reverb has easily

1413
01:35:28,900 --> 01:35:32,390
more than one point five million

1414
01:35:32,440 --> 01:35:37,030
of of these relations is really a former successful if we look at the precision

1415
01:35:37,030 --> 01:35:43,220
recall curve now at low levels of recall we're approaching point nine or even you

1416
01:35:43,220 --> 01:35:45,820
and that's essentially variational bayesian model comparison

1417
01:35:46,320 --> 01:35:53,740
so that you're acquired data through experiments so that you can actually score your model with reference to the data

1418
01:35:54,190 --> 01:35:58,740
and then you can adjudicate very complex models are very sophisticated models and very simple

1419
01:35:58,740 --> 01:36:01,940
models and sometimes with noisy data the simple models with

1420
01:36:02,400 --> 01:36:05,860
you know there's no point in trying explain and they cannot be explained

1421
01:36:07,650 --> 01:36:09,780
that's how you actually practically do it

1422
01:36:12,610 --> 01:36:13,760
the question then is why

1423
01:36:14,690 --> 01:36:17,220
well and the then the new asked you know

1424
01:36:18,210 --> 01:36:22,760
do you need to experiments and in the sense that if the objective of the brain is to

1425
01:36:23,240 --> 01:36:24,380
optimise its model

1426
01:36:25,070 --> 01:36:28,840
that has defined a model with the highest evidence or the lowest free energy

1427
01:36:29,550 --> 01:36:32,130
which means it has to go out there and acquired data

1428
01:36:33,240 --> 01:36:35,050
the confirmed its hypotheses

1429
01:36:35,490 --> 01:36:36,210
so the very

1430
01:36:36,690 --> 01:36:40,760
the way that we behave could be construed as the way that we explore basically

1431
01:36:41,110 --> 01:36:45,820
the way that we did our lines has is curious balance of trying to maintain

1432
01:36:45,820 --> 01:36:46,820
a home eustace is

1433
01:36:47,340 --> 01:36:53,130
was the same time exploring model spaces to evaluate the evidence or the free energy

1434
01:36:53,860 --> 01:36:54,690
and then choosing

1435
01:36:55,260 --> 01:36:57,220
those are choosing data

1436
01:36:57,630 --> 01:36:59,260
that will confirm or disconfirm

1437
01:37:00,550 --> 01:37:06,300
your particular model hypotheses and then elect lecting together with those models i have the greatest free energy

1438
01:37:07,130 --> 01:37:08,090
so you have

1439
01:37:13,760 --> 01:37:14,220
this fine

1440
01:37:14,900 --> 01:37:17,670
and i often find more interesting than of

1441
01:37:19,280 --> 01:37:20,220
well they you well that's

1442
01:37:22,090 --> 01:37:25,170
well what i just just go to what i would have said

1443
01:37:25,720 --> 01:37:29,900
so you know you you know you're missing or you're what she was missing and

1444
01:37:29,900 --> 01:37:33,340
then we will recover conversation what i would then done is

1445
01:37:33,760 --> 01:37:35,050
give you an example of action

1446
01:37:35,900 --> 01:37:41,530
just in terms of cued reaching western trying to work at solver using optimal control

1447
01:37:41,530 --> 01:37:45,280
control theory in the conventional sense i we just created

1448
01:37:47,190 --> 01:37:50,050
a model in which agents believe that there

1449
01:37:50,550 --> 01:37:55,900
fingers are attached to a target with an invisible elastic band and then when the

1450
01:37:56,010 --> 01:37:57,490
when the chalk it changes colour

1451
01:37:57,940 --> 01:37:59,740
be elastic band becomes stiff

1452
01:38:01,050 --> 01:38:05,170
given those police i would have predictions both about what i would see my hand

1453
01:38:05,170 --> 01:38:09,170
doing and what feel my hands during which my reflexes would fulfill

1454
01:38:09,840 --> 01:38:12,070
hand basically what it would look like it was

1455
01:38:12,490 --> 01:38:13,010
what we call

1456
01:38:13,530 --> 01:38:14,380
cued reaching

1457
01:38:15,670 --> 01:38:20,630
in in in in your neuroscience so that i can simulate simply by giving an

1458
01:38:20,630 --> 01:38:22,300
agent's prior beliefs very much like

1459
01:38:23,090 --> 01:38:24,800
bayesian thermostat again here

1460
01:38:25,860 --> 01:38:28,070
i can prescribe movement

1461
01:38:28,740 --> 01:38:32,010
simply by prescribing prior beliefs about

1462
01:38:33,920 --> 01:38:36,920
what about movement should feel like and the sensory consequences

1463
01:38:37,380 --> 01:38:38,070
and if i

1464
01:38:38,570 --> 01:38:39,150
i can

1465
01:38:40,190 --> 01:38:41,690
take neural dynamics

1466
01:38:43,650 --> 01:38:48,320
i can prescribe those prior beliefs i've using point attractors four

1467
01:38:48,840 --> 01:38:54,030
using the rent attractors or itinerant attractors produce not only

1468
01:38:54,490 --> 01:38:55,610
reached the target

1469
01:38:56,670 --> 01:38:57,820
but also values

1470
01:38:59,150 --> 01:39:03,570
that's prior beliefs that have an itinerant wandering form with carefully chosen

1471
01:39:06,130 --> 01:39:09,050
the biologically plausible when this competition

1472
01:39:11,400 --> 01:39:17,300
i actually visited succession apart unstable point attractors i can prescribe behaviors that look

1473
01:39:17,720 --> 01:39:20,550
very much like handwriting i can then go on

1474
01:39:21,490 --> 01:39:24,760
and examine those used plants classical experiments

1475
01:39:25,240 --> 01:39:29,110
looking at the movement cause i believe by myself and

1476
01:39:29,610 --> 01:39:30,610
then cutting

1477
01:39:32,150 --> 01:39:36,170
movements sensations and examine in terms that watching somebody else move

1478
01:39:37,070 --> 01:39:41,280
and then finally what we would have talked about it this is the sort of notion that's

1479
01:39:42,690 --> 01:39:46,530
why why do i explore where do i expect to look on the coming back

1480
01:39:46,530 --> 01:39:48,170
to to to your point about

1481
01:39:51,190 --> 01:39:53,300
the harvesting sensory information

1482
01:39:53,760 --> 01:40:01,340
essentially being conceived of has perception experiments that are there to to optimize my internal model of the world

1483
01:40:01,760 --> 01:40:03,240
and this can be formalized

1484
01:40:04,760 --> 01:40:06,360
in terms of so where do i look

1485
01:40:07,400 --> 01:40:09,360
you can actually formalize quite easily

1486
01:40:11,090 --> 01:40:12,300
in terms of

1487
01:40:12,720 --> 01:40:14,380
suppressing the joint

1488
01:40:15,340 --> 01:40:19,420
entropy of sensory inputs on the hidden causes and all requires you to do is

1489
01:40:19,420 --> 01:40:26,720
to supplement the minimization of all maximization marginal likelihood on minimization of surprise here

1490
01:40:27,210 --> 01:40:29,240
with minimizing your uncertainty

1491
01:40:30,920 --> 01:40:34,130
the sensory inputs all the hidden causes of the sensory inputs

1492
01:40:34,510 --> 01:40:36,300
which means i can absorb accidentally

1493
01:40:36,760 --> 01:40:37,950
free energy minimization

1494
01:40:38,420 --> 01:40:39,780
just by having the belief

1495
01:40:40,510 --> 01:40:44,990
but i will go and sample data that confirm my hypotheses

1496
01:40:45,840 --> 01:40:47,420
and if you plug that into

1497
01:40:47,990 --> 01:40:51,880
one those predictive coding schemes that simulations such as before

1498
01:40:53,420 --> 01:40:54,470
you can then produce

1499
01:40:55,130 --> 01:40:58,510
quite realistic well this is the architecture i would have used

1500
01:40:59,380 --> 01:41:02,440
you can produce quite realistic you can't you see this book

1501
01:41:02,970 --> 01:41:03,970
the movie was shown

1502
01:41:04,420 --> 01:41:09,130
after categorized the exploring visual input on the basis of

1503
01:41:09,530 --> 01:41:11,130
but now we can this is actually what

1504
01:41:12,780 --> 01:41:18,800
this is purely deterministic as randomness is a deterministic exploration of a static visual field

1505
01:41:18,800 --> 01:41:26,520
this projection here of x two on on your eye plain is exactly

1506
01:41:26,520 --> 01:41:28,770
what is it exactly

1507
01:41:28,780 --> 01:41:30,540
so the the projection

1508
01:41:30,570 --> 01:41:33,760
of x

1509
01:41:34,650 --> 01:41:38,550
on onto your hyperplane xy is exactly x

1510
01:41:40,000 --> 01:41:43,880
the projection on on your talk not which is

1511
01:41:43,910 --> 01:41:45,310
of dimension one

1512
01:41:45,430 --> 01:41:51,390
so it's for action only on the wall and the y coordinate

1513
01:41:59,530 --> 01:42:01,790
so if you have hyperplane

1514
01:42:02,100 --> 01:42:07,090
computing the projection on the vector of vector on that is very easy because you

1515
01:42:07,090 --> 01:42:09,540
just have to compute the projection on its

1516
01:42:09,580 --> 01:42:12,090
on excessive promontory

1517
01:42:12,110 --> 01:42:18,200
which is which is here the do

1518
01:42:18,200 --> 01:42:24,020
the y axis and you have only once carrier product compute right what if i

1519
01:42:24,020 --> 01:42:28,620
was to give you think about it if you were in

1520
01:42:28,650 --> 01:42:34,050
if you if i want to give you only two vector this and that's sandy

1521
01:42:34,050 --> 01:42:38,050
a propane here that that span displaying you have to

1522
01:42:38,090 --> 01:42:41,960
the products to compute their to find its projection

1523
01:42:43,740 --> 01:42:48,300
if you're in r and then the hyperplanes of dimension and minus one you may

1524
01:42:48,300 --> 01:42:52,410
find the basis vector that's of that is of legs and minus one but then

1525
01:42:52,410 --> 01:42:55,160
you have and minus one the products to compute

1526
01:42:55,190 --> 01:42:58,320
to compute the projection of x on the hyperplane

1527
01:42:58,380 --> 01:43:02,680
it's easier to go to the supplementary which is of dimension only one and compute

1528
01:43:02,680 --> 01:43:04,540
only one the product

1529
01:43:04,540 --> 01:43:05,970
to compute the projection

1530
01:43:06,630 --> 01:43:11,740
on top of it you can see that because you have this nice property that

1531
01:43:12,570 --> 01:43:17,120
the square of the norm two

1532
01:43:17,140 --> 01:43:18,490
do some up

1533
01:43:18,530 --> 01:43:21,070
then the distance

1534
01:43:21,130 --> 01:43:24,800
of x so my approach in h

1535
01:43:24,810 --> 01:43:28,090
it is squared

1536
01:43:28,140 --> 01:43:31,190
plus the product of its

1537
01:43:31,200 --> 01:43:33,860
on the y coordinate square

1538
01:43:33,890 --> 01:43:38,040
is exactly the norm of x squared

1539
01:43:38,050 --> 01:43:40,990
now if i want to find distance

1540
01:43:40,990 --> 01:43:44,060
i just think in all of us and i and minus the

1541
01:43:44,090 --> 01:43:47,110
square of the coefficient of the orthogonal subspaces

1542
01:43:51,710 --> 01:43:53,510
and the last to do

1543
01:43:53,590 --> 01:43:59,130
the last thing that is written this transparency which is actually the first thing is

1544
01:43:59,290 --> 01:44:03,120
because it when it is in the pain then

1545
01:44:03,260 --> 01:44:09,280
using its supplementary you may find an equation of of h which is really easy

1546
01:44:09,300 --> 01:44:10,510
just said that

1547
01:44:10,590 --> 01:44:14,810
any victories in eight is the vector that is orthogonal

1548
01:44:14,830 --> 01:44:15,930
two you

1549
01:44:15,930 --> 01:44:17,000
when you

1550
01:44:17,030 --> 01:44:23,910
is the vector that spans the supplementary of g i be right

1551
01:44:23,940 --> 01:44:25,280
it's actually more

1552
01:44:25,300 --> 01:44:27,720
it's actually more difficult to say that that

1553
01:44:27,730 --> 01:44:28,510
two c

1554
01:44:28,530 --> 01:44:34,360
if you if you are in there are two and you're a hyperplane is

1555
01:44:34,380 --> 01:44:37,580
the line that is orthogonal to the vector u

1556
01:44:37,600 --> 01:44:41,550
then you have this equation of therefore the hyperplane

1557
01:44:41,570 --> 01:44:46,280
the the distance

1558
01:44:46,280 --> 01:44:49,630
actually that that was really wrong

1559
01:44:49,650 --> 01:44:52,540
if you said yes but that it was really

1560
01:44:52,580 --> 01:44:56,800
OK so come back to that and you know it this distance of it's your

1561
01:44:56,800 --> 01:45:01,880
hyperplane exists that given by the absolute value of the dot product of x with

1562
01:45:01,880 --> 01:45:05,300
x was you and the projection is this one

1563
01:45:09,350 --> 01:45:13,910
actually this would be the norm of the projection

1564
01:45:20,360 --> 01:45:21,540
of x

1565
01:45:21,540 --> 01:45:25,060
on hyperplane there

1566
01:45:25,080 --> 01:45:27,040
and the distance of

1567
01:45:28,260 --> 01:45:31,620
so you are the hyperplane is easily

1568
01:45:31,720 --> 01:45:34,730
this this distance there right so

1569
01:45:34,750 --> 01:45:38,960
here in my in my drawing there

1570
01:45:38,980 --> 01:45:41,030
this is the projection

1571
01:45:46,310 --> 01:45:48,110
the projection of x

1572
01:45:48,130 --> 01:45:54,370
unmarried poor pain

1573
01:45:54,390 --> 01:45:56,720
and that would be the distance

1574
01:45:56,900 --> 01:46:01,950
and the time

1575
01:46:02,100 --> 01:46:07,960
this ranks here is the edit distance of x to my hyperplane which is exactly

1576
01:46:08,040 --> 01:46:14,000
the length of this is the product of the projection on the y axis right

1577
01:46:20,930 --> 01:46:23,530
now if you have

1578
01:46:23,580 --> 01:46:30,640
now we go from from subspaces two linear set of equations matrices

1579
01:46:30,640 --> 01:46:33,680
so let's assume that you have

1580
01:46:33,700 --> 01:46:39,080
several hyperplanes and you want to find the index section of these these places

1581
01:46:39,140 --> 01:46:44,030
then you end up with that so you have an hyperplanes then you have an

1582
01:46:45,240 --> 01:46:49,310
so x is in the intersection if those in the equations of true at the

1583
01:46:49,310 --> 01:46:55,370
same time so it gives you a sense of and and the linear equation

1584
01:46:55,390 --> 01:47:01,160
with the unknowns which are you dx one x two x

1585
01:47:01,910 --> 01:47:08,470
and the set of linear equations may be written as matrix vector product

1586
01:47:08,490 --> 01:47:10,390
which is right here

1587
01:47:12,560 --> 01:47:17,280
if you forget about a hyperplane then you just have a set of linear equations

1588
01:47:17,280 --> 01:47:21,970
you may have a single here which yields a non-zero vector

1589
01:47:22,640 --> 01:47:33,450
so the main matrices matrices are

1590
01:47:33,470 --> 01:47:37,870
with the rules in the core of the columns

1591
01:47:37,870 --> 01:47:44,930
it is an array of numbers of real numbers it's actually an array may made

1592
01:47:46,720 --> 01:47:49,700
and we vectors or equivalently the

1593
01:47:49,720 --> 01:47:52,010
the column vectors

1594
01:47:52,030 --> 01:47:55,310
and you can can see matrix vector product

1595
01:47:55,310 --> 01:48:05,440
the demanded objects industry namely faces cars digits letters and we have not getting to

1596
01:48:07,720 --> 01:48:13,380
these details since the focus of today's lecture is about graphical models not about surveying

1597
01:48:13,380 --> 01:48:19,040
the entire computer vision literature for this but actually here in CMU we should be

1598
01:48:19,040 --> 01:48:23,840
very proud some of the best algorithms for these for these

1599
01:48:24,000 --> 01:48:31,860
categorisation come from CMU for example schneiderman is face recognition and

1600
01:48:31,880 --> 01:48:34,480
and we have a in one

1601
01:48:34,500 --> 01:48:40,080
i think a TNT bell as you could propose one of the best to do

1602
01:48:40,120 --> 01:48:42,520
recognition systems and so on

1603
01:48:43,610 --> 01:48:45,840
we want to go back to this problem

1604
01:48:45,860 --> 01:48:53,870
we want to instead of nose nose algorithms that categorize faces or digits are cars

1605
01:48:53,980 --> 01:48:54,830
tend to

1606
01:48:55,680 --> 01:48:58,180
tend to be very domain specific

1607
01:48:58,200 --> 01:49:01,050
and the designer has pumped into a lot of

1608
01:49:01,060 --> 01:49:07,120
human knowledge about the specific class of object but now that we want to actually

1609
01:49:07,120 --> 01:49:08,290
look at

1610
01:49:08,300 --> 01:49:13,070
the other side of the problem is generic object recognition had only

1611
01:49:13,080 --> 01:49:16,930
how do we find some kind of expression that we could hope

1612
01:49:16,980 --> 01:49:22,560
to begin to learn now hundreds of thousands of classes of objects

1613
01:49:22,620 --> 01:49:25,190
and on top of that

1614
01:49:25,200 --> 01:49:32,200
we may even want to put them into a meaningful hierarchy objects do have taxonomy

1615
01:49:32,540 --> 01:49:40,780
in nature we have animals that comes into families and groups species and so the

1616
01:49:40,780 --> 01:49:47,630
question is goes beyond just classifying individuals groups of objects we may even want to

1617
01:49:47,670 --> 01:49:51,820
put them together in some meaningful way or

1618
01:49:51,880 --> 01:50:01,680
there are there are context of in certain contexts that object recognition requires actually contextual

1619
01:50:01,680 --> 01:50:03,490
knowledge for example

1620
01:50:03,500 --> 01:50:05,420
what is the

1621
01:50:05,440 --> 01:50:07,170
a blob

1622
01:50:09,690 --> 01:50:10,850
but now

1623
01:50:10,860 --> 01:50:16,040
you probably have an idea what this object is we would for the first top

1624
01:50:17,020 --> 01:50:19,590
the image it might be

1625
01:50:19,600 --> 01:50:27,320
a wine bottle were plate for here in my b shoes so sometimes can recognition

1626
01:50:27,320 --> 01:50:34,240
and classification of objects are facilitated by the global recognition more our understanding of the

1627
01:50:34,250 --> 01:50:37,540
scene context so

1628
01:50:37,590 --> 01:50:39,970
OK let me just give this so

1629
01:50:39,980 --> 01:50:43,200
OK so i hope have basically

1630
01:50:43,220 --> 01:50:49,930
illustrated or or given to give a very brief introduction introduction about what is the

1631
01:50:49,930 --> 01:50:52,550
question of object categorisation

1632
01:50:52,560 --> 01:50:58,630
and then i've shown you some of the challenges of object categorisation and then they

1633
01:50:58,660 --> 01:51:05,010
went briefly over the history of object categorisation now let's put this language into us

1634
01:51:05,030 --> 01:51:14,070
to statistical will viewpoint so what is the task of object categorisation here we can

1635
01:51:14,090 --> 01:51:16,290
we can write down the probability

1636
01:51:16,310 --> 01:51:19,170
or write down this

1637
01:51:19,260 --> 01:51:21,340
this task in the following way

1638
01:51:21,350 --> 01:51:23,570
given an image

1639
01:51:23,580 --> 01:51:25,610
we want to understand

1640
01:51:25,630 --> 01:51:27,410
whether it contains

1641
01:51:27,420 --> 01:51:29,540
and in particular class

1642
01:51:29,550 --> 01:51:33,860
of object or not in this case we use zebra as an example

1643
01:51:33,910 --> 01:51:38,300
so this classification task becomes

1644
01:51:38,340 --> 01:51:40,980
a comparison between two

1645
01:51:40,990 --> 01:51:46,010
probability scores basically the first one is given the image

1646
01:51:46,030 --> 01:51:50,760
it was the probability of having the zebra the second one is given an image

1647
01:51:51,080 --> 01:51:53,660
what's the probability of not having

1648
01:51:53,710 --> 01:51:56,050
and as emperor

1649
01:51:57,540 --> 01:52:00,640
everybody is familiar with bayes rule

1650
01:52:00,650 --> 01:52:06,390
we are here to setting up some terminology here let's take one equation o well

1651
01:52:06,390 --> 01:52:07,870
one number here

1652
01:52:07,890 --> 01:52:13,280
probability of image given a given image probability of zebra

1653
01:52:13,320 --> 01:52:20,100
it can be expanded into probably the probability of

1654
01:52:20,140 --> 01:52:21,620
image given zebra

1655
01:52:21,640 --> 01:52:24,620
times the probability of zebra

1656
01:52:24,640 --> 01:52:27,110
over some normalisation factor

1657
01:52:27,130 --> 01:52:30,530
and now the same thing goes for this

1658
01:52:30,540 --> 01:52:33,450
and we also can expand this

1659
01:52:34,420 --> 01:52:40,200
here so here is the terminology this is called post-imperial ratio

1660
01:52:40,210 --> 01:52:45,500
this is called the likelihood ratio of this term is very important limit to elaborate

1661
01:52:45,500 --> 01:52:50,060
one more time the likelihood means given some kind of model

1662
01:52:50,090 --> 01:52:56,090
of the object class what is low likelihood of this particular instance

1663
01:52:56,140 --> 01:53:01,620
and this is the prior ratio so you'll see there's quite a bit in computer

1664
01:53:01,620 --> 01:53:05,890
vision papers dealing with this problem domain

1665
01:53:05,910 --> 01:53:09,850
OK so i rewrote what we've just seen here

1666
01:53:09,890 --> 01:53:13,260
so there are two big class if you want to

1667
01:53:13,260 --> 01:53:19,020
really and put them in groups of techniques that people are using

1668
01:53:19,030 --> 01:53:26,640
right now to solve this problem of object categorization and we we love them into

1669
01:53:26,740 --> 01:53:30,520
discriminative methods or generative methods

1670
01:53:30,580 --> 01:53:38,180
discriminative methods tend to do look at the poster directly and try to find boundaries

1671
01:53:38,180 --> 01:53:40,660
between these two classes or or

1672
01:53:40,670 --> 01:53:48,490
and classes well as generative methods try to go from models that could describe

1673
01:53:49,560 --> 01:53:52,610
or or even better generate images

1674
01:53:54,660 --> 01:54:01,210
the hero i'm going to repeat again it's in the more visual way that discriminative

1675
01:54:01,210 --> 01:54:03,210
missus look at

1676
01:54:03,230 --> 01:54:09,590
the direct boundary between the posterior probability of a given an image to we have

1677
01:54:09,590 --> 01:54:11,550
as above or not

1678
01:54:13,900 --> 01:54:18,930
generative methods really look at the likelihood probability

1679
01:54:18,980 --> 01:54:22,890
the likelihood probability if given the model

1680
01:54:22,920 --> 01:54:27,570
how likely is that image so in this case let's suppose

1681
01:54:28,060 --> 01:54:33,270
we have what we have in mind here is a model of zebra and what

1682
01:54:33,270 --> 01:54:34,920
we have in mind is


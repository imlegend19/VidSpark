1
00:00:00,000 --> 00:00:03,210
last lecture my throat is about so i

2
00:00:03,950 --> 00:00:07,670
and just a little bit tired so let's see how we get on

3
00:00:09,870 --> 00:00:13,340
so let's just re cup we started off with

4
00:00:13,350 --> 00:00:16,460
trying to define a linear models

5
00:00:16,550 --> 00:00:22,350
and look at ways of identifying these linear models

6
00:00:25,730 --> 00:00:34,410
arbitrary functions and then yesterday we looked at using again a linear model to define

7
00:00:34,410 --> 00:00:38,660
a function which was basically the log odds ratio

8
00:00:38,700 --> 00:00:42,120
i mean we looked at how logistics regression

9
00:00:42,120 --> 00:00:48,330
and we started off with what appeared to be an arbitrary loss function are an

10
00:00:49,560 --> 00:00:51,120
i mean squared error

11
00:00:51,120 --> 00:00:53,190
and that led to

12
00:00:53,930 --> 00:00:55,940
least squares solution

13
00:00:55,950 --> 00:01:01,910
and we then moved on to look at the likelihood framework can be lifted probabilistic

14
00:01:01,910 --> 00:01:03,900
representation of these linear models

15
00:01:04,490 --> 00:01:09,710
and then we could start to characterize are levels of certainty or uncertainty

16
00:01:09,770 --> 00:01:11,850
in our estimates of the parameters

17
00:01:11,870 --> 00:01:17,960
and our levels of certainty and uncertainty in subsequent productions that we were making

18
00:01:17,960 --> 00:01:24,130
and then moved on to adopt a bayesian framework

19
00:01:24,150 --> 00:01:27,650
and we were able to see that

20
00:01:27,820 --> 00:01:31,570
again for linear model linear regression model

21
00:01:34,580 --> 00:01:40,240
posterior distribution over the parameters that came out and they closed form

22
00:01:40,320 --> 00:01:44,180
and likewise with the predictive distributions

23
00:01:44,190 --> 00:01:48,120
they all came out in the very nice closed form but when we were attacked

24
00:01:48,120 --> 00:01:51,520
logistic regression when trying to do classification

25
00:01:51,540 --> 00:01:55,320
over two classes then we had a problem

26
00:01:55,320 --> 00:01:57,960
and that the

27
00:01:58,020 --> 00:02:03,160
marginalisation they required to do was no longer analytic

28
00:02:03,210 --> 00:02:07,100
and we therefore had to resort to

29
00:02:07,330 --> 00:02:12,200
numerical methods such as monte carlo markov chain monte carlo or

30
00:02:12,280 --> 00:02:14,800
use some sort of approximations

31
00:02:14,810 --> 00:02:16,740
the approximation that we were tired

32
00:02:17,090 --> 00:02:19,390
i was using

33
00:02:19,400 --> 00:02:23,020
a lot plus approximation where we would find the

34
00:02:23,030 --> 00:02:27,390
the point in parameter space which was most likely a posterior on a and b

35
00:02:27,390 --> 00:02:33,300
then place the goes in at that point and the covariance about ghosts in adopted

36
00:02:33,300 --> 00:02:34,710
the carpet shark

37
00:02:34,740 --> 00:02:37,830
of the joint likelihood surface

38
00:02:37,830 --> 00:02:43,080
and we played with that yesterday in the lab we don't clue today in love

39
00:02:43,120 --> 00:02:46,960
but yesterday in the laboratory we looked at

40
00:02:46,970 --> 00:02:48,800
function approximation

41
00:02:48,800 --> 00:02:52,020
using camera functions

42
00:02:52,050 --> 00:02:57,390
OK so we're doing probabilistic candle based regression

43
00:02:59,370 --> 00:03:00,550
in essence

44
00:03:00,560 --> 00:03:02,580
if you remember

45
00:03:02,590 --> 00:03:05,300
we are trying to model some function

46
00:03:05,300 --> 00:03:07,490
over attributes x

47
00:03:08,270 --> 00:03:13,150
the linear form that we been adopting

48
00:03:13,150 --> 00:03:16,030
is a linear expansion

49
00:03:17,090 --> 00:03:18,990
some basis functions

50
00:03:19,030 --> 00:03:20,460
applied to

51
00:03:24,770 --> 00:03:27,620
what we used yesterday

52
00:03:27,740 --> 00:03:34,120
and florence was was getting are very a

53
00:03:34,150 --> 00:03:37,930
description of what is happening with this

54
00:03:37,970 --> 00:03:39,740
cannot function

55
00:03:39,750 --> 00:03:41,430
which we used

56
00:03:41,450 --> 00:03:46,300
which was the

57
00:03:46,310 --> 00:03:48,650
additionally myself

58
00:03:48,810 --> 00:03:57,270
which is the radial basis

59
00:03:57,300 --> 00:03:59,090
can not

60
00:04:00,830 --> 00:04:02,960
what you found

61
00:04:02,970 --> 00:04:06,150
and what we did in the laboratory was that

62
00:04:06,170 --> 00:04:09,960
if you remember we place the priors

63
00:04:09,970 --> 00:04:12,990
all in all of our

64
00:04:12,990 --> 00:04:16,730
this is the coefficients of the basis functions

65
00:04:17,960 --> 00:04:20,380
and so we had

66
00:04:20,400 --> 00:04:23,210
the prior variance too to think about

67
00:04:23,220 --> 00:04:25,820
and then in addition to that

68
00:04:25,830 --> 00:04:28,210
we introduced this additional

69
00:04:29,830 --> 00:04:36,310
it's associated with the the camera function or the basis said that we were using

70
00:04:36,440 --> 00:04:38,590
and what we found

71
00:04:39,450 --> 00:04:46,780
and some of you produce some really beautiful surfaces showing that the predictive performance as

72
00:04:46,780 --> 00:04:50,470
a function of values of alpha and beta

73
00:04:50,520 --> 00:04:51,920
what's that

74
00:04:51,940 --> 00:04:53,210
we know that the

75
00:04:53,220 --> 00:04:54,880
prior variance

76
00:04:54,890 --> 00:05:00,530
give us a way of controlling the capacity of the complexity of the model by

77
00:05:01,940 --> 00:05:04,810
shrinking some of these here

78
00:05:04,850 --> 00:05:10,050
OK so in essence we would be using a reduced set to a small number

79
00:05:10,050 --> 00:05:15,260
of basis functions to describe the function that we are trying to model

80
00:05:15,310 --> 00:05:18,380
but then we also saw that we had this

81
00:05:18,420 --> 00:05:23,100
this is because the parameters in the define the basis set and if we made

82
00:05:23,100 --> 00:05:27,190
that quite wide and then we found that the class of functions that we were

83
00:05:27,190 --> 00:05:28,020
able to

84
00:05:29,530 --> 00:05:32,440
to devise was very smooth

85
00:05:32,500 --> 00:05:37,030
and likewise if made this value very small then we found that they were very

86
00:05:37,030 --> 00:05:40,960
expressive highly nonlinear

87
00:05:40,980 --> 00:05:44,610
a set of functions that we can define so if you remember we were trying

88
00:05:44,610 --> 00:05:47,400
to model the set the same function

89
00:05:47,440 --> 00:05:51,690
and depending on the values of alpha and beta we could have

90
00:05:51,710 --> 00:05:54,440
i representations which was either

91
00:05:54,460 --> 00:05:57,660
overly smoothed

92
00:05:57,980 --> 00:06:00,590
on one which was

93
00:06:00,640 --> 00:06:04,160
but nick the excitable sort of

94
00:06:10,210 --> 00:06:11,630
OK so

95
00:06:11,640 --> 00:06:17,520
we we eventually had to use things like leave one out cross validation to identify

96
00:06:17,560 --> 00:06:20,690
with these alpha and beta parameters where

97
00:06:20,730 --> 00:06:21,770
but of course

98
00:06:21,770 --> 00:06:26,130
for those of you who want to adopt a bayesian framework

99
00:06:26,170 --> 00:06:31,250
you know that really all that you want to do is just

100
00:06:31,270 --> 00:06:32,980
a team

101
00:06:33,000 --> 00:06:35,390
this distribution

102
00:06:35,400 --> 00:06:40,040
and then average over all possible offers and all possible betas

103
00:06:40,060 --> 00:06:43,600
but this of course is not straightforward

104
00:06:46,360 --> 00:06:52,460
well that's great we can model really quite arbitrarily complex functions

105
00:06:52,470 --> 00:06:58,110
and today in the laboratory will be working with logistic regression and we'll be looking

106
00:06:58,110 --> 00:07:03,760
what you do is you go you try to show to ask a database events

107
00:07:03,760 --> 00:07:04,850
about two if

108
00:07:04,930 --> 00:07:09,170
will then so is these artists performing where in one

109
00:07:09,260 --> 00:07:13,800
and you have information and then move to the next one is performing when OK

110
00:07:14,170 --> 00:07:16,790
so this is what we want to the application to do

111
00:07:16,850 --> 00:07:22,560
given the music style we wanted to explore the web and get events out

112
00:07:22,580 --> 00:07:25,260
if i do it manually

113
00:07:25,300 --> 00:07:31,340
what i do is going to things like music mods

114
00:07:31,390 --> 00:07:38,750
which is something like this

115
00:07:38,790 --> 00:07:40,900
it's nice what publications

116
00:07:40,910 --> 00:07:45,860
basically it stores information about the movie sense

117
00:07:45,870 --> 00:07:51,510
you can always do something like these so you will hear you say

118
00:07:51,510 --> 00:07:57,190
i interesting for music

119
00:07:57,220 --> 00:08:05,080
the band announced this

120
00:08:05,130 --> 00:08:08,030
as you can see there are many so you have lots of these

121
00:08:08,130 --> 00:08:09,480
we to enter

122
00:08:09,540 --> 00:08:12,660
the a b

123
00:08:12,680 --> 00:08:15,190
OK you got to you before

124
00:08:15,210 --> 00:08:18,050
artists that performs folk music

125
00:08:18,080 --> 00:08:23,050
under b and the mean of others and that letters OK

126
00:08:23,360 --> 00:08:25,860
if you like one of these

127
00:08:25,900 --> 00:08:30,790
whether this guy is OK you can move here and you have information about it

128
00:08:30,870 --> 00:08:32,760
in and if you like you can also see

129
00:08:32,800 --> 00:08:38,290
support it in a different archive like musicbrainz

130
00:08:38,300 --> 00:08:41,840
there should be somewhere you a link to musicbrainz

131
00:08:41,860 --> 00:08:42,900
i don't know if

132
00:08:54,300 --> 00:08:56,850
what they did the which is very cool

133
00:08:56,930 --> 00:08:59,240
is a sharing their identifiers

134
00:08:59,250 --> 00:09:03,990
so these two websites are really sharing the identifier of the artists so you can

135
00:09:03,990 --> 00:09:10,010
move from one database to another using the same identifier actually what what was done

136
00:09:10,010 --> 00:09:11,980
was musicmoz

137
00:09:12,000 --> 00:09:14,680
using the musicbrainz identifier

138
00:09:14,690 --> 00:09:20,240
integrating with the music style is the information so you have the description and you

139
00:09:20,240 --> 00:09:25,880
might learn about good now what would you do that

140
00:09:25,890 --> 00:09:30,010
here so you have all the information of all these people from are you choose

141
00:09:30,010 --> 00:09:32,610
one because it's too difficult to exploit it for me

142
00:09:33,130 --> 00:09:38,010
you go on database like upcomming or event the database

143
00:09:38,010 --> 00:09:41,390
and there you ask for these artists to

144
00:09:41,510 --> 00:09:47,080
what you do is basically you go here

145
00:09:47,090 --> 00:09:54,740
you have another very web two o style interface that allows you to query for

146
00:09:54,860 --> 00:09:58,350
then you can

147
00:09:58,370 --> 00:10:09,520
just right here somebody

148
00:10:09,560 --> 00:10:14,190
and you go with

149
00:10:14,240 --> 00:10:16,840
all the event actually

150
00:10:16,920 --> 00:10:17,990
i guess

151
00:10:18,060 --> 00:10:25,180
you should go here

152
00:10:25,210 --> 00:10:32,210
so you have all the events OK

153
00:10:32,220 --> 00:10:34,760
so the next step is of course

154
00:10:34,770 --> 00:10:35,610
look through

155
00:10:35,630 --> 00:10:36,550
find one

156
00:10:36,560 --> 00:10:37,930
let's say in germany

157
00:10:37,940 --> 00:10:43,800
maybe somebody somewhere close to hear and understand where wearing and say i can i

158
00:10:43,800 --> 00:10:48,090
go there are not so in the last step is really to use google maps

159
00:10:48,130 --> 00:10:54,370
or any other maps application and to find a path to the final point so

160
00:10:54,370 --> 00:10:57,460
i put in the slides these are two

161
00:10:57,470 --> 00:11:00,460
this is a music model

162
00:11:00,510 --> 00:11:02,580
catalogue of their

163
00:11:02,590 --> 00:11:03,720
of this style

164
00:11:03,730 --> 00:11:05,750
and then he you have page

165
00:11:05,760 --> 00:11:08,290
the next video detail about

166
00:11:09,350 --> 00:11:14,270
the events of one of these performance and here i was looking in june four

167
00:11:14,620 --> 00:11:18,050
in event close to my house i live in italy actually live the north so

168
00:11:18,050 --> 00:11:22,220
i support these events here which is in the government

169
00:11:22,230 --> 00:11:26,760
so i mean i look up in a google map cell fires it from my

170
00:11:26,760 --> 00:11:31,300
home so it's one hour in something which is not true because these traffic but

171
00:11:31,300 --> 00:11:35,770
this is different

172
00:11:35,780 --> 00:11:37,100
right so

173
00:11:37,230 --> 00:11:39,980
what we want really is a mashup

174
00:11:39,990 --> 00:11:44,600
and measure like you've seen before web two o technologies

175
00:11:44,640 --> 00:11:49,650
and we want it done using semantic web technology and of course we also want

176
00:11:49,650 --> 00:11:55,900
to show that this this war so is f send doesn't bring some more computational

177
00:11:55,900 --> 00:11:59,740
problems seen and is also way to solve the problem

178
00:11:59,790 --> 00:12:03,610
which is just different from web two o technology but still a good way to

179
00:12:03,610 --> 00:12:08,280
solve the problem OK so the rest of the to is about our using semantic

180
00:12:08,280 --> 00:12:11,940
web technology to solve this problem

181
00:12:12,040 --> 00:12:17,190
so going back to evan hammonds lights which are

182
00:12:17,210 --> 00:12:19,020
introduction to the topic

183
00:12:19,040 --> 00:12:24,680
what we have here is the standard semantic problem we have data available

184
00:12:24,770 --> 00:12:29,330
they are available for machine because actually all the series but i i d showing

185
00:12:29,330 --> 00:12:32,630
also at the machine interface musicmoz

186
00:12:32,680 --> 00:12:36,130
gives you a dump of the data in XML you can

187
00:12:36,150 --> 00:12:44,610
downloads them and whatever you like with musicbrainz you've done for the databases in and

188
00:12:44,680 --> 00:12:46,660
was four months so you can

189
00:12:46,710 --> 00:12:50,790
lot them in a positive that obeys and put all the layers on top until

190
00:12:50,790 --> 00:12:53,830
you have the data out in their semantic web way

191
00:12:53,830 --> 00:13:00,870
and the events that obeys at rest API so you can put to rest request

192
00:13:00,900 --> 00:13:03,110
on on a

193
00:13:03,840 --> 00:13:04,630
browser there

194
00:13:04,650 --> 00:13:07,060
and what i got out of the response in XML

195
00:13:07,060 --> 00:13:11,810
OK so the first point is data are out there and it's available so this

196
00:13:11,810 --> 00:13:16,960
is fine now the the problem is we want to combine and and what we

197
00:13:16,990 --> 00:13:20,730
found that web scale and the problem but i'm sure it's almost at web scale

198
00:13:20,730 --> 00:13:23,340
i mean it's about three different website

199
00:13:23,390 --> 00:13:28,200
but still in his website that outside our control we can not really

200
00:13:28,220 --> 00:13:33,810
change OK they are outside then we have to cope with venezuela and so

201
00:13:33,820 --> 00:13:37,410
what we're going to do is this we bring in these data

202
00:13:37,460 --> 00:13:40,690
and try to collaborate so

203
00:13:40,880 --> 00:13:44,900
most of the examples that were done in the early days of semantic web we

204
00:13:44,900 --> 00:13:49,800
always thought could about meta data so we have a page and make description of

205
00:13:49,800 --> 00:13:51,720
any major limited description

206
00:13:51,810 --> 00:13:56,520
so is a couple of years these idea web of data came which is more

207
00:13:56,560 --> 00:14:00,710
moving exactly in the direction of sharing data and not the data about fifty to

208
00:14:00,730 --> 00:14:05,240
not make it but in many in any case i believe that what i'm showing

209
00:14:05,240 --> 00:14:07,830
works also for metadata is not that

210
00:14:07,830 --> 00:14:11,240
water seems like it could react with water

211
00:14:11,290 --> 00:14:13,020
and your reaction

212
00:14:13,060 --> 00:14:15,780
this up here

213
00:14:15,790 --> 00:14:20,510
so if you had water acting as an acid in water acting as the base

214
00:14:20,520 --> 00:14:25,650
you could be forming a conjugate acid thrown in my own and also the conjugate

215
00:14:25,650 --> 00:14:28,250
base hydroxide

216
00:14:28,260 --> 00:14:30,740
so this raises the question then

217
00:14:30,800 --> 00:14:34,250
if you have a glass of water

218
00:14:34,270 --> 00:14:36,430
how much h two o

219
00:14:36,530 --> 00:14:39,430
are you going to happen that glass of water

220
00:14:39,450 --> 00:14:44,970
and how much i hate roney and iron and how much hydroxide ion

221
00:14:44,980 --> 00:14:45,900
it would be

222
00:14:45,940 --> 00:14:49,560
in in water

223
00:14:49,610 --> 00:14:54,040
so we can consider that

224
00:14:54,050 --> 00:14:56,760
how much water is and what

225
00:14:56,810 --> 00:15:01,030
OK so so here's our equation again

226
00:15:01,070 --> 00:15:04,630
and what we're really asking

227
00:15:04,690 --> 00:15:06,160
is what is k

228
00:15:06,180 --> 00:15:08,820
so for at equilibrium conditions

229
00:15:09,490 --> 00:15:11,240
we want to know

230
00:15:11,250 --> 00:15:15,650
how do the ratios ratio of products

231
00:15:16,800 --> 00:15:18,620
two reactor

232
00:15:18,700 --> 00:15:23,860
so how much of these ionized species do you have how much product

233
00:15:23,880 --> 00:15:26,650
over the liquid water

234
00:15:26,660 --> 00:15:28,550
that's OK

235
00:15:28,590 --> 00:15:33,350
so how do we figure this out how do we find how do we find

236
00:15:34,110 --> 00:15:37,540
for this particular reaction

237
00:15:37,590 --> 00:15:42,620
well here's some of our are all familiar ways of relating

238
00:15:42,660 --> 00:15:45,230
terms rather involving k

239
00:15:45,240 --> 00:15:49,680
so we have delta g not because minus are t times the natural log of

240
00:15:50,760 --> 00:15:52,040
so if we know

241
00:15:52,070 --> 00:15:55,520
delta g not then we can find k

242
00:15:55,530 --> 00:15:57,610
at a particular temperature

243
00:15:57,620 --> 00:16:00,210
knowing the gas constant

244
00:16:00,220 --> 00:16:04,260
so we can rearrange this expression here

245
00:16:04,270 --> 00:16:06,070
two all for k

246
00:16:06,080 --> 00:16:08,720
in terms of delta g not

247
00:16:08,730 --> 00:16:11,400
and we're going to do this at room temperature

248
00:16:11,420 --> 00:16:17,770
and this reminder that the gas constant

249
00:16:17,790 --> 00:16:19,610
so first we need

250
00:16:19,620 --> 00:16:21,540
delta g not

251
00:16:21,580 --> 00:16:27,470
so there's a couple of different ways one can calculate delta g

252
00:16:27,480 --> 00:16:31,700
and you might want to just sort of thinking ahead per minute what are those

253
00:16:32,470 --> 00:16:38,250
because that's an important useful thing to know on wednesday

254
00:16:38,260 --> 00:16:42,530
so this is one of the possible ways if you know something

255
00:16:42,600 --> 00:16:47,930
about the delta g not of formation of products minus reacted

256
00:16:47,940 --> 00:16:51,540
what is the other equation that you might use to find

257
00:16:51,590 --> 00:16:59,030
delta g

258
00:16:59,310 --> 00:17:01,590
i heard it

259
00:17:01,640 --> 00:17:05,210
so this one that one should look familiar to you as well

260
00:17:05,250 --> 00:17:10,480
this will be on on wednesdays or this is material on wednesdays example i've seen

261
00:17:10,500 --> 00:17:16,070
example that's certainly something you should to look familiar to you for for that exam

262
00:17:16,120 --> 00:17:20,130
and it also shows the connection between the material that was covered on exam two

263
00:17:20,130 --> 00:17:21,940
and material that we're doing now

264
00:17:22,010 --> 00:17:23,280
so everything they

265
00:17:23,360 --> 00:17:24,910
learning for example two

266
00:17:24,920 --> 00:17:27,930
it will be useful in the future

267
00:17:27,980 --> 00:17:30,690
all right so just calculate this one way

268
00:17:30,700 --> 00:17:34,160
so all i have done the math out here for you

269
00:17:34,200 --> 00:17:37,030
so if we look up all of these values

270
00:17:37,050 --> 00:17:38,840
and we plug them in

271
00:17:38,850 --> 00:17:41,540
we find that this delta g nine

272
00:17:41,560 --> 00:17:42,750
it is plausible

273
00:17:42,760 --> 00:17:47,070
seventy nine point eight nine killer tools per mole

274
00:17:47,120 --> 00:17:52,590
so it's fairly large positive numbers

275
00:17:52,640 --> 00:17:58,420
so if we have a fairly large positive number for delta g nine

276
00:17:58,440 --> 00:18:01,060
what do we predict about the size

277
00:18:02,660 --> 00:18:06,120
they're going to be a big number small numbers

278
00:18:06,170 --> 00:18:08,130
it'll be a small number

279
00:18:08,170 --> 00:18:09,950
and so

280
00:18:10,010 --> 00:18:15,220
you could actually calculate that from this equation or just sort of remember the relationship

281
00:18:15,220 --> 00:18:18,750
if you're just ask qualitatively if it should be large

282
00:18:18,760 --> 00:18:19,850
four small

283
00:18:19,860 --> 00:18:21,740
we can actually go through

284
00:18:21,750 --> 00:18:24,160
and calculate what they would be

285
00:18:24,170 --> 00:18:26,160
at room temperature

286
00:18:26,170 --> 00:18:31,160
and the answer is one point zero times ten to the minus fourteen at room

287
00:18:31,160 --> 00:18:34,940
temperature and this number of you'll see a lot in

288
00:18:35,050 --> 00:18:36,100
the next

289
00:18:36,150 --> 00:18:41,170
for quite a quite well next on so many many lectures that will become

290
00:18:41,200 --> 00:18:43,970
a familiar number two you

291
00:18:43,980 --> 00:18:47,500
all right so that means this is a fairly small number

292
00:18:47,510 --> 00:18:49,470
so that means that

293
00:18:49,480 --> 00:18:52,610
most of the water is actually aged two

294
00:18:52,610 --> 00:18:58,090
a very small percentage of water is ionized at room temperature so there isn't that

295
00:18:58,090 --> 00:19:02,280
much in terms of hydro near minus hydroxide ions

296
00:19:02,340 --> 00:19:03,700
in your water

297
00:19:03,750 --> 00:19:10,490
a small percentage of the water molecules are ionized sorin in this charge four

298
00:19:10,500 --> 00:19:12,920
so not much of this at equilibrium

299
00:19:13,010 --> 00:19:16,680
compared to this

300
00:19:16,760 --> 00:19:19,360
lots of water in a glass of water

301
00:19:20,260 --> 00:19:25,350
all right so this the equilibrium constant has a special name which is why it's

302
00:19:25,350 --> 00:19:29,000
going to become very familiar to us as lectures go on

303
00:19:29,060 --> 00:19:31,400
and this name is kate w

304
00:19:31,440 --> 00:19:33,060
w for water

305
00:19:33,110 --> 00:19:36,950
so the equilibrium constant for water

306
00:19:37,030 --> 00:19:40,620
and pretty much all of the at the base

307
00:19:40,620 --> 00:19:44,680
the things that we will be doing or room temperature to make your life easier

308
00:19:44,720 --> 00:19:48,030
so that's why don't you come particularly familiar

309
00:19:48,060 --> 00:19:49,810
right so w

310
00:19:49,820 --> 00:19:53,170
can be expressed in terms of the concentration

311
00:19:53,210 --> 00:19:55,220
of hydrogen ions

312
00:19:55,260 --> 00:19:57,360
times hydroxide

313
00:19:58,930 --> 00:20:01,010
and i just wanted to

314
00:20:01,020 --> 00:20:04,820
make appointing you we talked a little about this more perhaps

315
00:20:06,680 --> 00:20:09,830
we're not including this autumn term so

316
00:20:09,910 --> 00:20:12,430
we don't have the water down here

317
00:20:13,850 --> 00:20:15,600
it's just equal to

318
00:20:15,610 --> 00:20:17,630
these two not over

319
00:20:17,650 --> 00:20:22,690
the other two water molecules in liquid and that's because if you have the material

320
00:20:22,690 --> 00:20:24,580
that's nearly pure

321
00:20:24,600 --> 00:20:30,740
you don't include in your equilibrium expressions so if it's something solvent the concentration

322
00:20:30,810 --> 00:20:35,070
water is the solvent is just not changing very much

323
00:20:35,070 --> 00:20:36,950
this is where

324
00:20:39,640 --> 00:20:42,740
this is not

325
00:20:43,550 --> 00:20:47,850
OK it's hard to see

326
00:20:47,890 --> 00:20:49,530
OK so

327
00:20:49,550 --> 00:20:54,410
you which you would choose the bandwidth in this case as follows

328
00:20:54,430 --> 00:20:55,620
you would go

329
00:20:58,050 --> 00:21:01,030
so i mean what you want is that basically you're

330
00:21:01,050 --> 00:21:02,850
he lost

331
00:21:02,950 --> 00:21:06,450
the expected value of loss is well approximated

332
00:21:06,450 --> 00:21:12,970
so you need to make a certain smoothness assumption on loss induced function class

333
00:21:13,010 --> 00:21:15,620
and so it's a good idea to choose

334
00:21:15,660 --> 00:21:16,840
a similar

335
00:21:16,850 --> 00:21:18,200
kernel width

336
00:21:18,260 --> 00:21:24,740
for getting the weights as it what you will be choosing afterwards we estimator

337
00:21:24,850 --> 00:21:27,570
so in other words if you choose the kernel of with five

338
00:21:27,580 --> 00:21:30,070
for regression and classification afterwards

339
00:21:30,080 --> 00:21:32,780
it's probably a good idea to pick something like that

340
00:21:32,780 --> 00:21:35,240
for getting the weights right

341
00:21:35,300 --> 00:21:39,950
just because a lot of function class often is rather similar to

342
00:21:40,010 --> 00:21:42,070
the original function class

343
00:21:42,080 --> 00:21:44,640
in terms of scale

344
00:21:44,640 --> 00:21:47,950
i mean that's precisely what we did

345
00:21:47,970 --> 00:21:50,570
now doing cross validation here

346
00:21:50,620 --> 00:21:53,430
these are not always easy i mean what you would have to but what you

347
00:21:53,430 --> 00:21:56,160
do is i mean you have to take a subset of

348
00:21:56,260 --> 00:22:01,550
i think doing proper model selection with cross for cross validation or you can do

349
00:22:01,550 --> 00:22:03,410
it anymore

350
00:22:03,430 --> 00:22:04,760
that's really hard

351
00:22:04,820 --> 00:22:08,570
but at least you can still use cross validation to assess the performance and then

352
00:22:08,570 --> 00:22:11,820
you would just take subsets and then

353
00:22:11,820 --> 00:22:14,820
check the performance on the test set

354
00:22:21,430 --> 00:22:24,140
what's it

355
00:22:27,950 --> 00:22:30,720
well i would

356
00:22:30,780 --> 00:22:32,350
go and take it as the

357
00:22:32,410 --> 00:22:33,550
the medium

358
00:22:34,780 --> 00:22:37,200
pairwise distances

359
00:22:37,240 --> 00:22:39,370
that that will be the quantity

360
00:22:39,390 --> 00:22:42,740
i mean it actually turns out that you can define an interesting band space by

361
00:22:42,740 --> 00:22:46,050
optimizing the the the bandwidth of the kernel itself

362
00:22:46,220 --> 00:22:48,510
at the moment we are working on this and

363
00:22:48,530 --> 00:22:52,740
it might be possible to get slightly better sources in this way directly

364
00:22:52,760 --> 00:22:57,640
but we don't completely understand the problem yet

365
00:22:57,660 --> 00:23:01,970
i can show you some notes and then afterwards

366
00:23:01,970 --> 00:23:04,760
any question

367
00:23:04,800 --> 00:23:10,350
it is

368
00:23:30,470 --> 00:23:33,300
how to use

369
00:23:33,660 --> 00:23:34,970
OK well

370
00:23:34,970 --> 00:23:40,490
this is what you do is you just replace those expectations by currently averages

371
00:23:40,550 --> 00:23:42,700
so that means if you

372
00:23:43,260 --> 00:23:44,970
i don't have too much data

373
00:23:44,970 --> 00:23:47,740
this is about the for loop so it could at a time

374
00:23:47,760 --> 00:23:51,700
OK now there's a simple way how you can get something that's almost as good

375
00:23:51,700 --> 00:23:54,600
as this in linear time

376
00:23:54,600 --> 00:23:59,970
so basically what you do is you just essentially block pairs

377
00:24:00,010 --> 00:24:01,160
of well

378
00:24:01,180 --> 00:24:06,140
well block two pairs of variables together and just average of that

379
00:24:06,180 --> 00:24:08,450
you can interpolate between those two

380
00:24:08,450 --> 00:24:10,490
you will get similar

381
00:24:10,660 --> 00:24:14,430
statement i mean that is actually for the asymptotic normality you just need a lot

382
00:24:14,430 --> 00:24:15,660
lot large numbers

383
00:24:15,740 --> 00:24:17,050
so it's

384
00:24:17,320 --> 00:24:18,370
bit easier

385
00:24:18,510 --> 00:24:21,910
and we've actually written this up the the problem is

386
00:24:21,910 --> 00:24:25,120
you really have a rather severe trade of

387
00:24:25,180 --> 00:24:28,950
computational complexity versus quality of it taste

388
00:24:29,950 --> 00:24:31,640
there people

389
00:24:31,660 --> 00:24:32,530
we do

390
00:24:32,930 --> 00:24:38,220
they they don't have to subsample it's just double full of you trust

391
00:24:39,870 --> 00:24:44,620
this so for instance i mean for this i mean you're just pick some

392
00:24:45,370 --> 00:24:47,490
x i y i

393
00:24:47,640 --> 00:24:49,070
and then i will take

394
00:24:49,100 --> 00:24:50,430
the average overall

395
00:24:50,450 --> 00:24:51,890
xj y j

396
00:24:51,910 --> 00:24:53,220
not being

397
00:24:53,240 --> 00:24:58,160
x i y i and take the average

398
00:24:58,200 --> 00:25:01,140
and then you just where this

399
00:25:01,160 --> 00:25:03,970
and what this requires that you can compute

400
00:25:03,990 --> 00:25:05,350
once and for all

401
00:25:05,370 --> 00:25:09,370
well actually what you do is you just square this out directly and then you

402
00:25:09,370 --> 00:25:13,220
can dig to both things in the same falling

403
00:25:13,240 --> 00:25:17,510
so i can show you the pseudocode for that in our paper

404
00:25:17,740 --> 00:25:21,220
any further questions

405
00:25:25,140 --> 00:25:28,930
OK how much time do actually have left half an hour

406
00:25:28,970 --> 00:25:31,950
fifteen minutes

407
00:25:31,970 --> 00:25:35,280
while OK good

408
00:25:35,370 --> 00:25:36,340
will be OK

409
00:25:36,470 --> 00:25:44,470
we just give some parts

410
00:25:44,510 --> 00:25:46,910
now this is we're trying to work with arthur gretton

411
00:25:46,910 --> 00:25:47,970
le song

412
00:25:47,970 --> 00:25:51,990
but it took off and olivier bousquet contribute to the sum of their parts

413
00:25:54,350 --> 00:25:57,580
so what we've been doing so far was looked at

414
00:25:58,570 --> 00:25:59,890
min operators

415
00:25:59,930 --> 00:26:03,260
and now we're going to look at the covariance operator

416
00:26:03,300 --> 00:26:06,340
we're going to use the very same tools that we use the the mean operator

417
00:26:06,570 --> 00:26:08,840
for covariance operator

418
00:26:08,850 --> 00:26:12,100
now why would that be interesting

419
00:26:12,120 --> 00:26:14,850
because you can do

420
00:26:14,870 --> 00:26:17,240
independent component analysis with it

421
00:26:17,240 --> 00:26:20,120
you can do feature selection

422
00:26:20,160 --> 00:26:24,950
and for independent component analysis you want the covariance operator between two sets of

423
00:26:24,970 --> 00:26:26,950
right to vanish

424
00:26:26,990 --> 00:26:28,430
for feature selection

425
00:26:28,450 --> 00:26:31,660
you want the current operator very large

426
00:26:31,660 --> 00:26:33,680
we use the same criteria

427
00:26:34,410 --> 00:26:37,140
this gives you the best i see i was in this gives you the best

428
00:26:37,140 --> 00:26:39,350
features of later

429
00:26:41,220 --> 00:26:45,030
problem is welcome some set of observations x and y has now

430
00:26:45,080 --> 00:26:48,350
and you want to find out whether distribution factorizes

431
00:26:48,390 --> 00:26:50,660
and more specifically what to have some

432
00:26:50,700 --> 00:26:52,990
measure of dependence

433
00:26:53,070 --> 00:26:56,570
you can use it for ICA

434
00:26:56,580 --> 00:26:57,990
you could differences

435
00:26:58,050 --> 00:27:00,160
this estimate

436
00:27:00,210 --> 00:27:04,740
then check whether this factorizes we can just go for it directly

437
00:27:04,780 --> 00:27:06,640
and in that of doing the latter is

438
00:27:06,660 --> 00:27:09,820
it work much better

439
00:27:11,760 --> 00:27:13,320
he is very very simple

440
00:27:13,320 --> 00:27:17,120
linear case in all we do is we just make that non-linear

441
00:27:17,140 --> 00:27:20,350
so we take some linear function say

442
00:27:20,350 --> 00:27:20,990
and what i get

443
00:27:21,480 --> 00:27:21,990
is this

444
00:27:23,420 --> 00:27:24,650
so i've done a legitimate

445
00:27:25,020 --> 00:27:26,790
s primal simplex

446
00:27:28,580 --> 00:27:32,800
on the primal problem and improve my objective function from zero to three has

447
00:27:33,300 --> 00:27:36,120
i did corresponding pivot on the dual

448
00:27:36,680 --> 00:27:39,290
which was not motivated by anything other than being

449
00:27:39,700 --> 00:27:43,990
analogous to what i was doing the primal and look what the beautiful thing that just happened here

450
00:27:45,090 --> 00:27:47,590
i still have the negative transpose property

451
00:27:48,290 --> 00:27:52,330
minus three has minus three force minus three s three has three reversed through force

452
00:27:53,730 --> 00:27:57,360
every role here is the negative rhetoric corresponding column here

453
00:27:57,840 --> 00:27:59,410
the negative transpose property

454
00:27:59,820 --> 00:28:00,880
is preserved

455
00:28:02,730 --> 00:28:04,640
doing he analogous pivots

456
00:28:06,750 --> 00:28:08,450
this is a very important fact

457
00:28:09,790 --> 00:28:11,920
and even on not running down a proof

458
00:28:12,450 --> 00:28:13,190
trivial proof

459
00:28:13,600 --> 00:28:17,660
just have a look at those few lines by matlab code understand exactly what's happening

460
00:28:17,660 --> 00:28:21,260
in the pivot and show that you have this property so we do the second

461
00:28:21,260 --> 00:28:21,710
period here

462
00:28:22,230 --> 00:28:25,880
obsession said this we the second that so x three lander

463
00:28:27,070 --> 00:28:31,890
o after a few iterations here this is three going three going around one

464
00:28:32,300 --> 00:28:35,690
and i so w one must be believing variable i guess i said that down here

465
00:28:36,140 --> 00:28:36,750
so what

466
00:28:38,580 --> 00:28:42,100
the nine force as they number that a key

467
00:28:42,870 --> 00:28:47,140
so i look for the ninety fourth the negative nine force down here so i click on this button

468
00:28:47,620 --> 00:28:53,290
and click on the button and i compare are and the prison and i still have the negative transpose property

469
00:28:53,840 --> 00:28:55,710
so now this dictionary here

470
00:28:56,530 --> 00:28:57,210
is optimal

471
00:28:57,610 --> 00:28:58,710
i've solved the problem

472
00:29:02,830 --> 00:29:04,370
i also solve the dual problem

473
00:29:06,100 --> 00:29:08,940
so by clearing all the purple entries here

474
00:29:09,630 --> 00:29:10,260
and the primal

475
00:29:10,690 --> 00:29:13,580
i've managed a clear all the purple entries here

476
00:29:14,110 --> 00:29:14,590
on the dole

477
00:29:16,580 --> 00:29:18,090
so i've solve the dual problem

478
00:29:23,380 --> 00:29:26,580
so we apply the simplex methods in the primal problem

479
00:29:27,900 --> 00:29:30,610
which i just to illustrate in this particular example

480
00:29:31,250 --> 00:29:34,380
and we can do both the two phases with that's not very well we can

481
00:29:34,380 --> 00:29:38,110
do the whole thing we can apply the primal we apply the simplex methods

482
00:29:38,750 --> 00:29:42,410
to the primal problem in two phases if you can sort of feasible

483
00:29:42,920 --> 00:29:45,790
and do the analogous pivots on the dual side

484
00:29:46,830 --> 00:29:47,690
we are done

485
00:29:48,670 --> 00:29:50,140
you'll have some both the primal

486
00:29:50,680 --> 00:29:51,740
in the dual problem

487
00:29:53,390 --> 00:29:55,130
both the primal and the dual problem

488
00:29:55,900 --> 00:30:01,150
and furthermore you have this negative transpose property so that if i o five thirds

489
00:30:01,160 --> 00:30:03,490
here i have minus five thirty here

490
00:30:04,050 --> 00:30:10,260
but don't forget all but i should point out this minus five third is ignoring one important thing

491
00:30:12,260 --> 00:30:14,700
it's ignoring the minus sign right there

492
00:30:15,370 --> 00:30:20,070
so the actual dual has this extra minus sign that might pivotal doesn't show

493
00:30:23,150 --> 00:30:24,130
i suppose power

494
00:30:25,960 --> 00:30:26,430
next year

495
00:30:27,100 --> 00:30:28,980
probably put a minus sign right there are

496
00:30:29,800 --> 00:30:30,170
so that

497
00:30:30,650 --> 00:30:33,030
the pivot tool shows that the dual is the minus

498
00:30:34,930 --> 00:30:39,640
so anyway we all we have this negative transpose properties or whatever they are negative

499
00:30:39,640 --> 00:30:42,430
would be fair but this is the negative of the dual objective

500
00:30:43,130 --> 00:30:44,300
so what does this tell us

501
00:30:46,140 --> 00:30:48,630
o and get to that later i forgot my order here

502
00:30:50,850 --> 00:30:52,030
think about what that tells you

503
00:30:55,240 --> 00:30:56,050
we'll get back to work

504
00:31:01,490 --> 00:31:03,920
so this suggests another

505
00:31:05,290 --> 00:31:06,250
simplex methods

506
00:31:07,390 --> 00:31:07,790
the dual

507
00:31:08,210 --> 00:31:09,440
simplex methods

508
00:31:11,100 --> 00:31:14,090
the dual simplex method is exactly what i just illustrated here

509
00:31:18,900 --> 00:31:21,970
we are doing this on a problem that had purple

510
00:31:22,650 --> 00:31:24,240
only here and not there

511
00:31:27,700 --> 00:31:28,740
and we ended up going

512
00:31:29,470 --> 00:31:30,900
and finding an optimal solution

513
00:31:32,230 --> 00:31:33,150
to this problem

514
00:31:35,160 --> 00:31:36,950
so what are primal problem had

515
00:31:37,650 --> 00:31:38,750
purple only here

516
00:31:39,730 --> 00:31:41,660
end no purple affair

517
00:31:42,750 --> 00:31:45,700
in my mind i could think about the dual that's

518
00:31:46,280 --> 00:31:48,520
think about applying the simplex methods to it

519
00:31:49,830 --> 00:31:51,010
that's what we want to do here

520
00:31:55,950 --> 00:31:58,100
so the dual simplex methods as

521
00:31:58,980 --> 00:32:01,360
applies when the dual problem is feasible

522
00:32:01,360 --> 00:32:04,770
then the wavelength follows immediately

523
00:32:04,790 --> 00:32:09,730
so you see here are a few examples that i've calculated for you

524
00:32:09,790 --> 00:32:11,650
if you start out with a

525
00:32:11,770 --> 00:32:15,360
low frequency of thousand hertz you get the wavelength

526
00:32:15,360 --> 00:32:17,310
of three hundred kilometres

527
00:32:17,310 --> 00:32:18,810
radio waves

528
00:32:18,810 --> 00:32:21,020
megahertz still

529
00:32:21,070 --> 00:32:24,340
talk about radio waves when you go up in frequency

530
00:32:24,340 --> 00:32:27,250
wavelengths of course gets shorter and shorter

531
00:32:27,270 --> 00:32:28,840
we call these

532
00:32:32,420 --> 00:32:33,250
if you go to ten

533
00:32:33,270 --> 00:32:35,570
fourteen to two to fifteen words

534
00:32:35,590 --> 00:32:38,250
you get into the domain of infrared

535
00:32:38,340 --> 00:32:40,710
visible light and ultraviolet

536
00:32:40,730 --> 00:32:42,480
and if you go even higher

537
00:32:42,480 --> 00:32:47,150
then you end up with x-rays and ultimately all of these are members of the

538
00:32:51,190 --> 00:32:57,670
electromagnetic waves this a with a non-zero there stands for angstroms

539
00:32:57,730 --> 00:33:00,790
that means ten to the minus ten years

540
00:33:01,360 --> 00:33:04,540
so the whole family of electromagnetic waves

541
00:33:04,570 --> 00:33:06,560
and we give the name so that

542
00:33:06,560 --> 00:33:08,270
we can talk about them

543
00:33:08,270 --> 00:33:13,610
without ever mentioning the specific frequency already what wavelengths

544
00:33:13,730 --> 00:33:15,130
so given the fact that

545
00:33:15,130 --> 00:33:17,250
electromagnetic waves and travel

546
00:33:17,380 --> 00:33:20,570
with three hundred thousand kilometres per second

547
00:33:20,610 --> 00:33:21,920
one food

548
00:33:22,020 --> 00:33:24,290
you take one nano-second

549
00:33:24,340 --> 00:33:27,360
twenty six one hundred thirty metres deep

550
00:33:27,420 --> 00:33:28,330
the light

551
00:33:28,380 --> 00:33:31,630
from me to professor pathology all the way at the end

552
00:33:31,630 --> 00:33:36,340
it would take about o point one microsecond

553
00:33:36,400 --> 00:33:38,040
one second

554
00:33:38,940 --> 00:33:41,630
radio waves to the all

555
00:33:41,630 --> 00:33:44,480
eight minutes takes the light from the sun

556
00:33:44,520 --> 00:33:46,520
to reach us

557
00:33:46,520 --> 00:33:51,090
the light from the nearest stars will take five years

558
00:33:51,090 --> 00:33:54,420
and the nearest large galaxy studios

559
00:33:54,460 --> 00:33:57,480
we take two million years for that light

560
00:33:57,540 --> 00:34:00,420
richard so when you look at that galaxy

561
00:34:00,500 --> 00:34:05,210
and you see the galaxy the way it was two million years ago

562
00:34:05,210 --> 00:34:06,630
in astronomy we

563
00:34:06,630 --> 00:34:07,670
users are

564
00:34:09,520 --> 00:34:12,770
a light here which is the distance that light travels

565
00:34:12,790 --> 00:34:17,840
in one year which is about ten to sixteen meters

566
00:34:17,900 --> 00:34:22,540
if you study galaxy which is at a distance of ten billion light years

567
00:34:22,590 --> 00:34:24,340
you're looking at the universe

568
00:34:24,380 --> 00:34:26,020
the way it was ten

569
00:34:26,880 --> 00:34:28,270
years ago

570
00:34:28,340 --> 00:34:29,860
in astronomy

571
00:34:29,880 --> 00:34:31,610
you can look back

572
00:34:32,710 --> 00:34:33,920
you can look back

573
00:34:33,920 --> 00:34:37,020
yes you can look back millions of years

574
00:34:37,020 --> 00:34:39,460
you can also look back in time

575
00:34:39,500 --> 00:34:44,310
billions of years

576
00:34:45,420 --> 00:34:49,610
forms of electromagnetic radiation certainly light and radio waves from radar

577
00:34:49,630 --> 00:34:54,830
can reflect off surfaces at least to some degree it depends on the surface

578
00:34:54,840 --> 00:34:59,400
and this is the basis behind the distance determination

579
00:34:59,520 --> 00:35:01,860
you send a reader pulse

580
00:35:01,920 --> 00:35:07,170
two an airplane or two were rainstorm some of the radiation comes back at you

581
00:35:07,230 --> 00:35:08,860
you know the speed

582
00:35:08,880 --> 00:35:10,920
and so that allows you to calculate

583
00:35:11,060 --> 00:35:13,360
the distance

584
00:35:13,360 --> 00:35:14,670
if the distance

585
00:35:14,670 --> 00:35:16,560
to the plane is the

586
00:35:16,560 --> 00:35:18,940
you send a brief pulse

587
00:35:18,940 --> 00:35:20,040
and it comes back

588
00:35:20,060 --> 00:35:21,360
quality echo

589
00:35:21,420 --> 00:35:25,250
it takes a certain amount of time to come back which you can measure

590
00:35:25,310 --> 00:35:26,690
and that

591
00:35:26,790 --> 00:35:29,340
signal has to travel twice the distance

592
00:35:29,340 --> 00:35:31,830
that is the speed of light

593
00:35:31,860 --> 00:35:35,420
times t this is what you measure

594
00:35:35,420 --> 00:35:36,440
the distance in

595
00:35:36,460 --> 00:35:39,380
time from the moment you send the signal to you

596
00:35:39,440 --> 00:35:43,150
get the reflection back and so you can calculate the distance

597
00:35:43,280 --> 00:35:46,540
the distance

598
00:35:46,590 --> 00:35:50,020
two demos can be measured this way

599
00:35:50,040 --> 00:35:52,090
five corner reflectors

600
00:35:52,110 --> 00:35:55,290
on the moon three were left by the americans into

601
00:35:55,340 --> 00:36:00,730
so we're left by the soviets they said was still the soviet union

602
00:36:00,880 --> 00:36:04,040
and optical telescopes from earth

603
00:36:04,110 --> 00:36:06,810
can send a very brief

604
00:36:08,420 --> 00:36:09,940
laser pulse

605
00:36:09,980 --> 00:36:11,840
police corner reflectors

606
00:36:11,900 --> 00:36:14,130
all the time

607
00:36:14,150 --> 00:36:17,480
length of time of these polls is only one quarter

608
00:36:17,520 --> 00:36:19,000
over nano-second

609
00:36:19,040 --> 00:36:21,150
imagine light only travels

610
00:36:21,210 --> 00:36:23,710
seven centimetres in one quarter

611
00:36:23,790 --> 00:36:26,880
of a nine seconds

612
00:36:26,880 --> 00:36:30,660
because of the

613
00:36:38,390 --> 00:36:41,720
the that are

614
00:36:41,730 --> 00:36:42,640
that's all

615
00:36:54,740 --> 00:37:00,030
and i want to throw it

616
00:37:08,020 --> 00:37:11,270
in fact

617
00:37:24,020 --> 00:37:28,760
the are called

618
00:37:28,860 --> 00:37:34,650
the fact that are

619
00:37:34,760 --> 00:37:39,540
what you

620
00:38:23,960 --> 00:38:25,320
but in fact

621
00:39:13,930 --> 00:39:18,190
of course one

622
00:39:18,440 --> 00:39:22,400
OK call

623
00:39:22,740 --> 00:39:29,730
so that

624
00:39:56,070 --> 00:39:57,940
the best

625
00:39:57,960 --> 00:40:00,680
the one

626
00:40:04,150 --> 00:40:09,230
we are talking about the

627
00:40:09,410 --> 00:40:11,420
but that

628
00:40:16,830 --> 00:40:19,780
that's the one

629
00:40:22,330 --> 00:40:25,570
one of the

630
00:40:25,650 --> 00:40:27,120
we are now

631
00:40:27,830 --> 00:40:40,900
i don't want my account for

632
00:40:40,900 --> 00:40:44,640
the following content is provided under creative commons license

633
00:40:44,670 --> 00:40:51,380
your support will help MIT opencourseware continue to offer high quality educational resources for free

634
00:40:51,390 --> 00:40:56,200
to make a donation or view additional materials from hundreds of MIT courses

635
00:40:56,220 --> 00:40:58,040
this MIT opencourseware

636
00:40:58,060 --> 00:41:00,040
OCW MIT

637
00:41:00,080 --> 00:41:01,510
that u

638
00:41:01,520 --> 00:41:05,440
thermodynamics alright let's start

639
00:41:05,470 --> 00:41:07,740
the more dynamic

640
00:41:11,900 --> 00:41:14,170
the flow of heat

641
00:41:14,230 --> 00:41:16,560
for more

642
00:41:16,600 --> 00:41:19,730
dynamics of emotion

643
00:41:19,740 --> 00:41:25,490
thermodynamics was developed

644
00:41:27,030 --> 00:41:30,300
beginning in the eighteen hundreds

645
00:41:30,380 --> 00:41:33,570
at the time of the industrial revolution

646
00:41:33,590 --> 00:41:35,770
the taming of this of steel

647
00:41:35,780 --> 00:41:37,420
the beginning of

648
00:41:39,020 --> 00:41:42,810
power by burning fossil fuels

649
00:41:42,850 --> 00:41:44,800
the beginning of the problems with

650
00:41:44,810 --> 00:41:45,780
sio two

651
00:41:45,820 --> 00:41:48,260
global warming in fact

652
00:41:48,320 --> 00:41:51,230
it's interesting to note that the first articulation

653
00:41:52,650 --> 00:41:55,010
the impact of sio two

654
00:41:55,060 --> 00:41:57,070
on climate

655
00:41:57,120 --> 00:42:01,100
it was done in the late nineteen hundreds by reading

656
00:42:01,150 --> 00:42:03,780
beginning of the

657
00:42:03,790 --> 00:42:06,670
generation of power moving it for

658
00:42:06,680 --> 00:42:08,620
fossil fuel generating energy

659
00:42:08,620 --> 00:42:11,760
o locomotives etcetera

660
00:42:11,840 --> 00:42:13,740
three calculated what happen

661
00:42:14,850 --> 00:42:17,420
burning of fossil fuels and

662
00:42:17,430 --> 00:42:22,870
he decided in has speculation basically got the calculation right

663
00:42:22,870 --> 00:42:26,510
he came out in two thousand years from the time to do the calculations humans

664
00:42:26,510 --> 00:42:29,180
would be in trouble

665
00:42:29,260 --> 00:42:33,540
well since cystatin mission we had an exponential growth in the amount of CO two

666
00:42:33,540 --> 00:42:38,460
and if you go through calculations of people have done this populations through

667
00:42:38,480 --> 00:42:40,230
since arrhenius

668
00:42:40,320 --> 00:42:43,710
the time they were in trouble two thousand years and the population

669
00:42:43,810 --> 00:42:46,950
has gone like our

670
00:42:46,980 --> 00:42:49,120
now really in trouble

671
00:42:49,240 --> 00:42:51,520
so four different lecture

672
00:42:51,580 --> 00:42:55,090
so anyway thermodynamics dates from the same period

673
00:42:55,140 --> 00:43:00,020
as as well as getting fossil fuels out of the ground

674
00:43:00,080 --> 00:43:01,800
it's universal

675
00:43:01,810 --> 00:43:02,840
turns out

676
00:43:02,900 --> 00:43:08,930
everything around us energy around one or the other for biological system you're burning calories

677
00:43:08,970 --> 00:43:10,690
bring eighty two

678
00:43:12,900 --> 00:43:18,460
there are warm-blooded animals need energy to move your arms around move around

679
00:43:18,500 --> 00:43:22,500
mechanical systems obviously cars built

680
00:43:23,150 --> 00:43:27,460
even in astrophysics when you talk about stars black holes that you're moving energy around

681
00:43:27,460 --> 00:43:28,930
you moving around

682
00:43:29,020 --> 00:43:31,370
new changing matter through

683
00:43:33,390 --> 00:43:36,680
and the concepts of thermodynamics have even been applied to

684
00:43:38,060 --> 00:43:40,020
systems out of equilibrium like

685
00:43:40,060 --> 00:43:42,210
the companies like enron

686
00:43:42,250 --> 00:43:43,890
completely out of equilibrium

687
00:43:43,930 --> 00:43:45,800
crash and burn

688
00:43:46,830 --> 00:43:49,840
the more dynamic or nonequilibrium thermodynamics two

689
00:43:49,900 --> 00:43:52,210
two economics

690
00:43:52,280 --> 00:43:55,090
it was developed before people knew about

691
00:43:55,140 --> 00:44:02,360
atoms and molecules so to science based on macroscopic properties of matter

692
00:44:02,370 --> 00:44:03,840
since the

693
00:44:03,860 --> 00:44:06,300
since we know about and molecules now

694
00:44:06,310 --> 00:44:09,870
we can rationalize the concepts of thermodynamics

695
00:44:09,900 --> 00:44:11,930
using microscopic

696
00:44:13,120 --> 00:44:14,390
and if you are

697
00:44:14,400 --> 00:44:18,960
five sixty two that's what you want about learn about statistical mechanics and how the

698
00:44:19,020 --> 00:44:20,720
mister concepts

699
00:44:22,300 --> 00:44:24,960
what makes it doesn't prove it

700
00:44:25,090 --> 00:44:28,650
but it helps to gain more intuition about

701
00:44:29,060 --> 00:44:34,330
the consequences of thermodynamics

702
00:44:34,370 --> 00:44:37,740
so it applies to macroscopic systems that are in equilibrium

703
00:44:37,840 --> 00:44:40,060
how to go from one equilibrium state

704
00:44:40,110 --> 00:44:42,710
one of the sequences

705
00:44:42,710 --> 00:44:46,710
and it's entirely empirical science foundation

706
00:44:46,780 --> 00:44:51,780
people have done experiments three ages and the accumulated the knowledge from these experiments

707
00:44:51,870 --> 00:44:55,000
it synthesizes experiments were a few

708
00:44:56,310 --> 00:44:59,350
empirical rules empirical laws

709
00:44:59,360 --> 00:45:01,840
which other laws of thermodynamics

710
00:45:01,910 --> 00:45:05,380
and then they taking these laws added a

711
00:45:05,410 --> 00:45:07,500
structure math upon it

712
00:45:07,510 --> 00:45:09,900
to build the edifice which is

713
00:45:10,010 --> 00:45:11,480
very solid

714
00:45:11,510 --> 00:45:13,630
because of the dynamics is the science

715
00:45:15,080 --> 00:45:17,830
equilibrium systems

716
00:45:17,860 --> 00:45:21,710
so these empirical observations and

717
00:45:22,830 --> 00:45:26,730
summarizing for law

718
00:45:26,750 --> 00:45:27,880
OK so

719
00:45:28,210 --> 00:45:30,410
these laws are

720
00:45:30,460 --> 00:45:32,210
really deep colours

721
00:45:33,390 --> 00:45:34,650
not proven

722
00:45:36,130 --> 00:45:40,190
not wrong there are very unlikely to be wrong

723
00:45:40,230 --> 00:45:41,910
let's just go through these laws

724
00:45:41,920 --> 00:45:43,960
very quickly is the zeroth law

725
00:45:46,090 --> 00:45:47,200
the zeroth law

726
00:45:47,210 --> 00:45:50,900
every one of these laws basically defines the quantity of thermodynamics and then define the

727
00:45:52,200 --> 00:45:54,660
the zeroth law defines temperature

728
00:45:54,670 --> 00:45:56,250
that's fairly

729
00:45:56,260 --> 00:45:58,200
common sense

730
00:45:59,010 --> 00:46:01,480
but it's important to define

731
00:46:01,590 --> 00:46:03,780
and i call that the common sense law

732
00:46:03,850 --> 00:46:08,210
this is the common sense

733
00:46:11,050 --> 00:46:12,210
the first lord

734
00:46:12,230 --> 00:46:18,150
hands up defining energy

735
00:46:18,200 --> 00:46:20,080
what we're going to call you

736
00:46:23,420 --> 00:46:29,710
the concept of energy conservation energy can be lost or gained

737
00:46:29,770 --> 00:46:32,520
and i'm going to call this you can read

738
00:46:32,520 --> 00:46:35,250
and the brain

739
00:46:35,260 --> 00:46:39,780
they don't lose energy

740
00:46:39,840 --> 00:46:40,840
and then

741
00:46:42,910 --> 00:46:43,880
the second law

742
00:46:43,900 --> 00:46:49,970
is going to define entropy

743
00:46:50,080 --> 00:46:53,960
and it's going to tell us about the direction of time something that conceptually

744
00:46:53,970 --> 00:46:56,000
fairly understand

745
00:46:56,010 --> 00:46:59,440
it is going to put a mathematical foundation on

746
00:46:59,510 --> 00:47:01,110
which way this time

747
00:47:01,140 --> 00:47:02,110
clearly if i

748
00:47:02,270 --> 00:47:05,400
chocolate this one here

749
00:47:05,400 --> 00:47:07,900
four on the ground in britain the pieces

750
00:47:07,960 --> 00:47:09,780
if i run the movie backwards

751
00:47:09,780 --> 00:47:12,880
it doesn't make sense right we have a concept of time going forward in a

752
00:47:12,880 --> 00:47:14,260
particular way

753
00:47:14,280 --> 00:47:20,110
that is and should be play into that concept

754
00:47:20,130 --> 00:47:22,070
and i'm going to call this the

755
00:47:22,450 --> 00:47:24,840
you can break

756
00:47:29,350 --> 00:47:31,280
zero degrees kelvin more

757
00:47:31,390 --> 00:47:34,440
can only do it is zero risk

758
00:47:34,470 --> 00:47:35,900
the third law

759
00:47:35,960 --> 00:47:41,960
is going to give a numerical value

760
00:47:44,610 --> 00:47:50,030
two billion entropy

761
00:47:51,540 --> 00:47:54,520
the third law is gonna be the depressing one

762
00:47:54,520 --> 00:47:59,940
the high energy phosphate from ATP ATP and transfers it

763
00:47:59,960 --> 00:48:02,060
two tyrosine amino acids

764
00:48:02,080 --> 00:48:04,320
that are present on substrates

765
00:48:04,330 --> 00:48:07,300
so here's an amino acid sequence

766
00:48:07,320 --> 00:48:10,170
in the single

767
00:48:10,220 --> 00:48:14,540
letter code and if we admit that why is that is the code for piracy

768
00:48:15,900 --> 00:48:19,060
if is the protein that functions as the substrate

769
00:48:20,090 --> 00:48:25,880
tyrosine kind is a terracing kind eyes will add a phosphate group

770
00:48:25,890 --> 00:48:30,090
to the side chains of the terracing which i'm not crying here but had terracing

771
00:48:30,090 --> 00:48:35,960
has a hydroxyl group on its side chain and therefore it will phosphorylates tyrosine

772
00:48:36,190 --> 00:48:39,390
that is to say at phosphate groups to it

773
00:48:39,400 --> 00:48:45,070
it will phosphorylates this c

774
00:48:45,140 --> 00:48:51,470
so these two rectangles here are fat tire seen kind aces and what happens after

775
00:48:51,470 --> 00:48:56,460
the two subunits of the receptor have been brought together is thereafter what one finds

776
00:48:57,680 --> 00:49:02,080
each of these receptor subunits becomes multiple phosphorylated

777
00:49:02,090 --> 00:49:07,880
in each of these lollipops indicating here are sites where there is a tyrosine residue

778
00:49:07,880 --> 00:49:10,800
has become phosphorylated

779
00:49:10,850 --> 00:49:14,180
in fact there's a tale of the pdf receptor that extends even further to the

780
00:49:14,180 --> 00:49:19,180
cytoplasm which also acquires a number of different phosphates on it

781
00:49:19,300 --> 00:49:26,450
and again i remind us this phosphoryl ation really is what often called coltrane's phosphorylation

782
00:49:26,630 --> 00:49:29,250
because each receptor molecule

783
00:49:29,270 --> 00:49:32,430
phosphorylates tyrosine residues on the other

784
00:49:32,480 --> 00:49:37,750
obviously when these two receptor molecules are far apart in the plane of plasma membrane

785
00:49:37,870 --> 00:49:43,270
this trends phosphorylation can not occur but once the two tyrosine kind is residence at

786
00:49:43,270 --> 00:49:46,670
the time wanted to terracing kind is have been brought together

787
00:49:46,730 --> 00:49:53,280
pulled together by the dimerisation of the receptor now this cross phosphoryl ation one each

788
00:49:53,280 --> 00:49:55,880
phosphorylated other can occur

789
00:49:55,930 --> 00:50:01,600
and soon the receptors are more highly phosphorylated all these phosphate groups

790
00:50:01,640 --> 00:50:07,780
to repeat myself being attached to tyrosine residues in their cytoplasmic domains

791
00:50:07,840 --> 00:50:15,490
and this in turn creates interesting docking sites for a variety of other cytoplasmic signalling

792
00:50:15,490 --> 00:50:20,680
proteins and we'll talk about some today and next time but what i want to

793
00:50:20,680 --> 00:50:26,550
leave you with is the following impression that after this phosphoryl ation actually occurs there

794
00:50:26,550 --> 00:50:33,460
are a number of of molecules in the cytoplasm signaling molecules that have affinity for

795
00:50:38,230 --> 00:50:41,850
when i say phosphotyrosine obviously i'm referring to the

796
00:50:41,850 --> 00:50:45,520
phosphorylated form of tyres

797
00:50:45,610 --> 00:50:49,540
it's been created by a higher sekine kind is an enzyme

798
00:50:49,560 --> 00:50:51,940
so here's one molecule that can bind

799
00:50:51,990 --> 00:50:57,350
this molecule a combined one of these phosphates another one combined to this phosphate

800
00:50:59,370 --> 00:51:06,370
and each of these molecules once they are attracted to this phosphorylated receptor can then

801
00:51:06,370 --> 00:51:08,790
emit downstream signals

802
00:51:08,840 --> 00:51:11,350
so the the variety of signals into the cell

803
00:51:11,360 --> 00:51:15,260
but ultimately end up in persuading the cell to proliferate

804
00:51:15,270 --> 00:51:16,320
and so

805
00:51:16,340 --> 00:51:21,440
these effects year of growth factors in the g one phase of the cell cycle

806
00:51:21,440 --> 00:51:24,570
are mediated by this transmembrane signaling

807
00:51:24,580 --> 00:51:32,260
by the activation of these of this receptor for example and by the resulting

808
00:51:32,340 --> 00:51:35,820
the release of downstream signals into the cell

809
00:51:35,870 --> 00:51:39,690
which persuaded the cell to proliferate or not to proliferate

810
00:51:39,710 --> 00:51:41,200
to be sure

811
00:51:41,210 --> 00:51:47,340
the c one platelets clot platelet aggregation and they released ptgs they also release other

812
00:51:47,340 --> 00:51:52,670
kinds of growth factors inference there's is another growth factor that's called IGF one insulin

813
00:51:52,670 --> 00:51:56,980
like growth factor and that has its own receptor on the surface of cells and

814
00:51:56,980 --> 00:52:01,310
there are on the cell hundreds to thousands of these pgf receptors

815
00:52:01,310 --> 00:52:04,650
they're IGF receptors their EGF receptors

816
00:52:04,860 --> 00:52:11,480
a cell often will require several distinct kinds of growth factor activations in order to

817
00:52:12,810 --> 00:52:18,880
so this is only a minor part of the entire exposure the cell experiences in

818
00:52:18,880 --> 00:52:21,880
the g one phase of the cell cycle

819
00:52:22,380 --> 00:52:25,930
to elaborate on the point that i made last time

820
00:52:25,990 --> 00:52:32,660
an important biological distinction between normal cells and cancer cells is the fact that cancer

821
00:52:32,660 --> 00:52:37,580
cells require relatively little growth factors in the medium in order to proliferate

822
00:52:37,790 --> 00:52:43,180
normal cells have very strong requirement for growth factors in the media and therefore what

823
00:52:43,180 --> 00:52:47,580
we can already imagine is the following kind of scenario

824
00:52:48,910 --> 00:52:50,870
the cancer cells have somehow

825
00:52:50,880 --> 00:52:53,880
deregulated this signaling pathway

826
00:52:53,890 --> 00:52:56,590
somehow they become independent

827
00:52:56,630 --> 00:53:02,390
all the stimulation that is normally required usually required for cells to proliferate

828
00:53:02,430 --> 00:53:06,120
and in fact we know of several different ways

829
00:53:06,120 --> 00:53:10,810
by which cancer cells can acquire this independence

830
00:53:10,820 --> 00:53:15,510
one of the most important ways it's it's and really interesting on here's a cancer

831
00:53:17,460 --> 00:53:21,680
which we'll talk about very shortly and what you find in certain kinds of cancer

832
00:53:22,580 --> 00:53:24,910
is it the cancer cells

833
00:53:24,970 --> 00:53:28,860
themselves release growth factors in the media

834
00:53:29,200 --> 00:53:32,610
so there are certain kinds of cancer cells that will release

835
00:53:32,630 --> 00:53:38,650
let's say a growth factor this like EGF into the medium around around them so

836
00:53:38,660 --> 00:53:41,050
well you say that's kind of amusing but so what

837
00:53:41,430 --> 00:53:43,130
the important part here

838
00:53:43,160 --> 00:53:45,530
is it the same cancer cells

839
00:53:46,400 --> 00:53:49,700
receptors for TG four EGF

840
00:53:49,710 --> 00:53:54,550
on the surface they producing growth factor and they can also respond to the same

841
00:53:54,550 --> 00:53:57,990
growth factor and therefore this EGF once it's released

842
00:53:58,040 --> 00:54:00,080
can swim over here

843
00:54:00,800 --> 00:54:02,410
activate receptor

844
00:54:02,430 --> 00:54:05,420
and persuade the cell to start proliferating

845
00:54:05,530 --> 00:54:07,120
this is

846
00:54:07,160 --> 00:54:12,320
in if you will positive feedback loop but no here importantly that the growth of

847
00:54:12,320 --> 00:54:16,690
the cell is not being controlled by growth factors coming from cells elsewhere in the

848
00:54:16,690 --> 00:54:17,920
tissue of the body

849
00:54:17,940 --> 00:54:22,870
here we're not talking about different cells talking to one another here we're talking about

850
00:54:22,870 --> 00:54:27,240
a monologue where this cell is talking to itself this is sometimes called on to

851
00:54:27,240 --> 00:54:30,270
try and save and refers to the fact

852
00:54:30,430 --> 00:54:35,360
certain kinds of cancer cells are able to make growth factors to which they can

853
00:54:36,390 --> 00:54:39,190
in fact in normal tissues

854
00:54:39,200 --> 00:54:40,350
it's rare

855
00:54:40,350 --> 00:54:42,810
for a single cell type in normal tissue

856
00:54:42,820 --> 00:54:45,370
to be able to make a growth factor

857
00:54:45,380 --> 00:54:49,830
and two recent be able to respond to the same growth factor why can normally

858
00:54:49,830 --> 00:54:53,850
not respond to the growth factor because it will make the receptor for the growth

859
00:54:54,840 --> 00:54:55,950
for example

860
00:54:55,970 --> 00:55:00,860
epithelial cells like the cells in your skin the cells lining the gut

861
00:55:00,860 --> 00:55:04,150
they can release pdg f

862
00:55:04,210 --> 00:55:08,560
but they don't have pdf receptor on the surface and therefore even though they release

863
00:55:08,610 --> 00:55:14,540
copious amounts of PDF that will not result in this order the military proliferation and

864
00:55:14,540 --> 00:55:18,940
therefore you don't have this d control cell proliferation that you see often in cancer

865
00:55:18,940 --> 00:55:21,180
cells this awful crime loop

866
00:55:21,230 --> 00:55:26,120
in many kinds of cancer cells you have another alteration of this growth factor signaling

867
00:55:27,080 --> 00:55:29,550
and here what we see is the following

868
00:55:29,550 --> 00:55:32,920
they followed synonym antonym links

869
00:55:33,210 --> 00:55:36,610
and then they judge the opinions strength

870
00:55:36,620 --> 00:55:38,120
with respect to

871
00:55:38,890 --> 00:55:40,560
the reference set

872
00:55:40,580 --> 00:55:43,710
so they follow the links but then they had this other so that they could

873
00:55:43,710 --> 00:55:47,960
use to say well how close to to judge how good it is so they

874
00:55:47,960 --> 00:55:53,140
don't just indiscriminately follow links they have a leash on that

875
00:55:53,170 --> 00:55:59,200
two to four there and then they expanded further with the naive bayes classifier

876
00:55:59,740 --> 00:56:03,990
too much information can have e

877
00:56:04,060 --> 00:56:05,340
yes o

878
00:56:05,360 --> 00:56:09,860
another thing that they did

879
00:56:11,210 --> 00:56:14,310
i still think this is a good idea we started doing this

880
00:56:14,320 --> 00:56:16,120
i guess

881
00:56:16,170 --> 00:56:20,120
in two thousand one or something and i mean

882
00:56:20,140 --> 00:56:22,430
different people use to wear

883
00:56:22,440 --> 00:56:25,320
it's going to be noisy but

884
00:56:25,360 --> 00:56:27,330
editorials for example

885
00:56:27,340 --> 00:56:31,960
are more likely to have are more likely to be associated with subjectivity than for

886
00:56:31,960 --> 00:56:37,290
example hard news and the wall street journal and other documents come with without metadata

887
00:56:37,430 --> 00:56:41,200
so that if you go to the treebank it has many different reviews letters to

888
00:56:41,200 --> 00:56:42,080
the editor

889
00:56:42,090 --> 00:56:48,710
news and so on and so you can score word and say

890
00:56:49,420 --> 00:56:52,070
if the word occurs more often

891
00:56:52,090 --> 00:56:55,230
then you'd expect from chance in reviews

892
00:56:55,290 --> 00:56:58,920
then in use then that could be evidence that its objective

893
00:56:58,960 --> 00:57:03,980
so that it's it's kind of noisy we found we so we found boost the

894
00:57:03,980 --> 00:57:08,580
performance from doing that but it some information and the good thing is that you

895
00:57:08,580 --> 00:57:13,320
have lots of things out there that are labeled as reviews and letters that editor

896
00:57:14,350 --> 00:57:16,290
other categories

897
00:57:16,300 --> 00:57:21,000
anyway so they used they use that to build up

898
00:57:22,480 --> 00:57:25,250
a lexicon for their purpose

899
00:57:26,460 --> 00:57:30,090
and then they combine those and they also combine them together with

900
00:57:30,100 --> 00:57:36,430
hatzivassiloglou and q and attitudes and then they use that to classify sentences as objective

901
00:57:36,430 --> 00:57:38,960
or subjective

902
00:57:39,000 --> 00:57:41,690
OK so it's still in service the army

903
00:57:41,700 --> 00:57:44,950
this is their first paper on this

904
00:57:44,960 --> 00:57:48,500
i believe and they use scene sets

905
00:57:48,510 --> 00:57:52,540
they want to find the semantic orientation of turns and there they were the first

906
00:57:52,540 --> 00:57:58,850
ones to do class classification to use the gloss of the wordnet sense is to

907
00:58:01,760 --> 00:58:06,260
so you see sets and they start with positive and negative seeds sets and then

908
00:58:06,260 --> 00:58:07,340
they follow

909
00:58:07,350 --> 00:58:14,120
the pads the lexical relations that are in wordnet like synonymy

910
00:58:14,130 --> 00:58:15,380
so for example

911
00:58:15,390 --> 00:58:19,330
going from brilliant to brainy to intelligent smart

912
00:58:19,340 --> 00:58:24,130
this is me brilliant following antonym linked to unintelligent and then you can get stupid

913
00:58:24,130 --> 00:58:25,700
brainless and all that

914
00:58:25,710 --> 00:58:30,590
and then extended the sets iteratively

915
00:58:30,590 --> 00:58:35,850
they use the final sets the gold standard to train the classifier

916
00:58:35,860 --> 00:58:37,830
and then as long as

917
00:58:37,840 --> 00:58:38,880
as long as

918
00:58:38,960 --> 00:58:45,040
and then she has sentiment words then you can use the classifier to train

919
00:58:45,050 --> 00:58:47,050
then they moved on

920
00:58:47,070 --> 00:58:52,000
and in two thousand six they had a couple papers they use the best systems

921
00:58:52,000 --> 00:58:53,890
of the two thousand five paper

922
00:58:53,910 --> 00:58:58,180
and they had we thought this is interesting because they had the additional goal of

923
00:58:58,180 --> 00:59:05,750
distinguishing mutual from positive negative in our terminology finding subjective versus objective and then breaking

924
00:59:05,750 --> 00:59:11,830
down the subjective into positive and negative and they found they found that the subjective

925
00:59:11,830 --> 00:59:17,680
objective parties harder this several groups actually who report back in in different levels of

926
00:59:17,680 --> 00:59:22,470
analysis that doing the subjective objective phase

927
00:59:22,580 --> 00:59:23,620
is hard

928
00:59:23,630 --> 00:59:27,810
and it's important and if you can do that can make your life easier in

929
00:59:27,810 --> 00:59:32,990
then subsequently annotating things as positive and negative

930
00:59:33,050 --> 00:59:37,820
i think there's also they have later we're too there's a new paper from two

931
00:59:37,820 --> 00:59:41,940
thousand seven with a they moved on to a new approach

932
00:59:43,230 --> 00:59:51,260
this is the key at all application in semi supervised learning to evaluate expression classifiers

933
00:59:51,260 --> 00:59:55,210
now she learning can actually do more for and the best way to think about

934
00:59:55,210 --> 01:00:00,910
this is just learning discriminative features what features actually carry more information

935
01:00:01,480 --> 01:00:03,030
so let's look at that

936
01:00:03,700 --> 01:00:07,900
so i'm trying to find some categories here so this is a panda bear this

937
01:00:07,900 --> 01:00:08,590
is the

938
01:00:08,650 --> 01:00:11,900
rules what that is more informative

939
01:00:11,900 --> 01:00:16,960
and the goal of the algorithm would be to not with all the features equally

940
01:00:17,010 --> 01:00:18,030
but wait

941
01:00:18,040 --> 01:00:24,980
the radio indicates there's a matlab kind of a sort of visualization thing that more

942
01:00:24,980 --> 01:00:28,250
important feature blue means less important feature

943
01:00:29,790 --> 01:00:32,580
so what we're going to do is illustrated here

944
01:00:32,670 --> 01:00:33,670
going to try

945
01:00:33,680 --> 01:00:36,110
to find these distance functions

946
01:00:36,200 --> 01:00:38,690
but the distance function will be

947
01:00:38,700 --> 01:00:40,150
will be learned

948
01:00:40,190 --> 01:00:43,980
and the goal is is to tweak the distance function such that the distance is

949
01:00:43,980 --> 01:00:46,300
within one category

950
01:00:46,350 --> 01:00:49,200
you know from airplanes to airplanes are small

951
01:00:49,550 --> 01:00:52,630
but from airplanes to giraffes large

952
01:00:52,640 --> 01:00:56,910
so we'll take the machine learning paradigm between june the distance function

953
01:00:57,000 --> 01:01:01,270
so how do we do that so simple setting this up this is an image

954
01:01:01,270 --> 01:01:05,130
i the images jnk we know that

955
01:01:05,140 --> 01:01:10,290
the distance i i and j are in the same category and get into different

956
01:01:10,290 --> 01:01:13,130
categories so my goal is to make the subject

957
01:01:13,140 --> 01:01:15,220
greater than the subject

958
01:01:15,240 --> 01:01:19,830
and note that we have tried we'll always have to work in this paradigm that

959
01:01:19,910 --> 01:01:24,740
an image or any object can never be characterized by using a fixed link

960
01:01:24,830 --> 01:01:26,760
parts of images can be

961
01:01:26,770 --> 01:01:29,990
but they made it to the one image may have

962
01:01:30,000 --> 01:01:33,000
and it featured entertainment and seventy features

963
01:01:33,020 --> 01:01:35,360
we always have to work with that problem

964
01:01:36,990 --> 01:01:39,860
so then this is kind of more of the details

965
01:01:39,920 --> 01:01:43,740
so we have various features and for each feature will try to find the best

966
01:01:43,740 --> 01:01:45,750
matching feature another view

967
01:01:45,830 --> 01:01:49,420
and so on using big d

968
01:01:50,770 --> 01:01:55,720
that's fall distance function but that distance function is made up of weights

969
01:01:55,750 --> 01:01:59,940
and elementary distance function which facing features

970
01:01:59,990 --> 01:02:01,890
and so we have

971
01:02:01,910 --> 01:02:05,270
so we have a whole bunch of features here and then we had the distances

972
01:02:05,270 --> 01:02:09,400
of each of those features by some the little these

973
01:02:09,460 --> 01:02:14,400
and here is another image and then the distance of the idea

974
01:02:14,420 --> 01:02:15,420
for each other

975
01:02:17,240 --> 01:02:20,000
and so these features are all

976
01:02:20,020 --> 01:02:24,720
focused on the distances and in the the future image i

977
01:02:24,730 --> 01:02:27,390
so that defines the dimensionality of the space

978
01:02:27,400 --> 01:02:32,150
is that which i equal because there are defined with respect to the local image

979
01:02:32,200 --> 01:02:33,680
and now

980
01:02:33,690 --> 01:02:37,000
what we want to do is to make sure that the key

981
01:02:37,020 --> 01:02:39,380
which is a different category is

982
01:02:39,380 --> 01:02:41,720
and the larger distance than

983
01:02:41,780 --> 01:02:42,920
same category

984
01:02:42,920 --> 01:02:47,860
the distance between images and so essentially this becomes the question the weights

985
01:02:47,890 --> 01:02:51,250
dot product should be larger than these

986
01:02:51,280 --> 01:02:55,480
i can see the difference vector this guy must be greater than zero

987
01:02:56,320 --> 01:02:57,580
so far so good

988
01:02:57,630 --> 01:03:01,570
and now we just throwing the usual SVM mumbo-jumbo

989
01:03:02,460 --> 01:03:05,990
so we want to get this guy greater than zero but we want to have

990
01:03:05,990 --> 01:03:07,900
some regularisation so

991
01:03:07,920 --> 01:03:09,780
i apologise for that

992
01:03:09,840 --> 01:03:13,440
leaving behind through this thing so this turns out to be

993
01:03:13,440 --> 01:03:15,570
it's really i can do

994
01:03:15,570 --> 01:03:17,650
some mediation on that the u

995
01:03:17,670 --> 01:03:21,240
you get a minimisation problem with their weight vector and then this is kind of

996
01:03:21,240 --> 01:03:22,360
the penalty term

997
01:03:22,380 --> 01:03:24,570
we want to not too many of these guys

998
01:03:27,030 --> 01:03:30,070
the machine he goes through OK

999
01:03:30,090 --> 01:03:33,460
so let's see the results of this so what this enables us to do is

1000
01:03:33,530 --> 01:03:35,420
i learned distance function

1001
01:03:35,480 --> 01:03:38,280
when you put more weight on list weights

1002
01:03:38,300 --> 01:03:43,190
on features which are more distinct they are less distinct they were category that's what

1003
01:03:43,190 --> 01:03:44,670
you learn then

1004
01:03:45,730 --> 01:03:48,860
so here is the talented dataset which

1005
01:03:48,860 --> 01:03:51,210
it was developed about

1006
01:03:51,210 --> 01:03:53,340
you know for so that some four years ago

1007
01:03:53,340 --> 01:03:56,530
and when it does it came out in two thousand four

1008
01:03:56,550 --> 01:04:00,710
people thought that this is this is horribly challenging problems

1009
01:04:00,880 --> 01:04:05,500
because that recall that in two thousand three or two thousand four the problem that

1010
01:04:05,510 --> 01:04:08,130
we thought we solve was digits

1011
01:04:08,760 --> 01:04:12,530
i mean i could be also solve the problem of face detection

1012
01:04:12,530 --> 01:04:14,050
that's where we went out

1013
01:04:14,070 --> 01:04:17,500
we could do it you could do faces and all this group of

1014
01:04:17,510 --> 01:04:24,590
their own opinions on what they did was they collected images of hundred different categories

1015
01:04:25,340 --> 01:04:26,230
the web

1016
01:04:26,260 --> 01:04:30,380
so these are images of pianos and media's anime then

1017
01:04:30,400 --> 01:04:33,280
i think this stop so the pianos

1018
01:04:35,230 --> 01:04:39,110
a sort of a flower

1019
01:04:40,170 --> 01:04:46,090
the cell phones etc cetera so that quite natural categories for each category they collected

1020
01:04:46,730 --> 01:04:50,010
maybe fifty or sixty examples

1021
01:04:50,010 --> 01:04:55,010
by doing so search based on text queries and then having a graduate student go

1022
01:04:55,010 --> 01:04:58,200
ah so we'll see what else you go that i will however short i will

1023
01:04:58,200 --> 01:05:00,180
not answer the world email

1024
01:05:00,310 --> 01:05:04,700
right i will answer emails from the class

1025
01:05:04,750 --> 01:05:07,720
but i will not answer and i i think i speak for the asia TI

1026
01:05:07,720 --> 01:05:12,550
is neither will answer the world email on how we're going to keep the world

1027
01:05:12,550 --> 01:05:16,580
out of our inboxes i'm unsure exactly where this going to be a problem or

1028
01:05:16,580 --> 01:05:19,370
not at any rate that's what's happening

1029
01:05:20,190 --> 01:05:25,330
all right any questions about any questions about the mechanics of the course or what

1030
01:05:25,330 --> 01:05:30,990
your expectations should be what my expectations of you are

1031
01:05:31,910 --> 01:05:34,480
right now i would like to take an informal poll

1032
01:05:34,490 --> 01:05:38,100
actually when we started this class of the number of times now and it's always

1033
01:05:38,100 --> 01:05:41,280
been a mixed crowd and i think that's one of things that track about this

1034
01:05:41,280 --> 01:05:47,090
class let me ask with these in this class or lecture engineering undergraduate graduate

1035
01:05:47,110 --> 01:05:50,560
are so it's pretty strong show of hands but let me also as for the

1036
01:05:50,560 --> 01:05:53,770
non he's in this class

1037
01:05:53,780 --> 01:05:58,820
i that's also pretty strong show of hands these are as is typical the majority

1038
01:05:58,820 --> 01:06:02,500
of the students in the class but there's also a pretty strong group of students

1039
01:06:02,500 --> 01:06:06,600
in this class who are not allowed to engineers by training by desire by anything

1040
01:06:06,660 --> 01:06:10,280
are and they usually come from all over the place i was looking at the

1041
01:06:10,280 --> 01:06:13,990
web was one of the classes before the classification people from chemistry to something from

1042
01:06:16,000 --> 01:06:19,640
chemist there's somebody on the back there are i and others and people from earth

1043
01:06:20,840 --> 01:06:25,140
somebody from somebody was talking actually for science this morning before science OK

1044
01:06:25,150 --> 01:06:28,020
well so i think it was an amicable and these may be

1045
01:06:28,400 --> 01:06:30,160
all right now

1046
01:06:30,210 --> 01:06:31,690
it's important to know

1047
01:06:31,720 --> 01:06:39,140
i think the cause is very rich in material alright region applications rich in content

1048
01:06:39,140 --> 01:06:41,730
and appeals

1049
01:06:41,800 --> 01:06:45,250
many people from many different reasons OK

1050
01:06:45,300 --> 01:06:49,870
for these and they were taking the class you have probably seen

1051
01:06:49,880 --> 01:06:52,620
a certain amount of this material i want to say most of the material that

1052
01:06:52,620 --> 01:06:57,260
you probably seen a fair amount of this material scattered over many different classes

1053
01:06:57,310 --> 01:07:02,420
but it's been my experience that one of the advantages of this class for electrical

1054
01:07:02,420 --> 01:07:07,250
engineering students either undergraduate or graduate students is to see it all in one

1055
01:07:07,940 --> 01:07:12,600
right to put it all in your head at one time at least once right

1056
01:07:12,600 --> 01:07:17,050
because the subject does have a great amount of coherence it really does hang together

1057
01:07:17,050 --> 01:07:22,150
beautifully for all the different and varied applications there are core ideas and core methods

1058
01:07:22,150 --> 01:07:25,830
of the class that it is very helpful to see all ones are so if

1059
01:07:25,830 --> 01:07:28,060
you've seen the material before

1060
01:07:28,070 --> 01:07:33,130
that's fine i mean is i mean that you can you can draw on that

1061
01:07:33,130 --> 01:07:36,340
and draw in your experience but don't deny yourself the pleasure

1062
01:07:36,480 --> 01:07:40,210
trying to synthesize the ideas as we go along and there's nothing so pleasurable was

1063
01:07:40,220 --> 01:07:42,260
thinking about something you already know

1064
01:07:42,410 --> 01:07:44,890
try to think about from a new perspective think about it from a new point

1065
01:07:44,890 --> 01:07:48,510
of view trying to try to folded into some of the newer things you you'll

1066
01:07:48,510 --> 01:07:52,570
be learning so i've i've heard this from electrical engineering students many times in the

1067
01:07:52,570 --> 01:07:56,370
past that it's it's a pleasure for them to see the material altogether once it

1068
01:07:56,370 --> 01:07:59,020
may seem like a fair amount of review in in some cases it will be

1069
01:07:59,020 --> 01:08:03,170
but not in all cases and even if it is a review there are often

1070
01:08:03,170 --> 01:08:07,340
slightly different twists are slightly new takes on things that you may not have seen

1071
01:08:07,340 --> 01:08:11,060
before may not have thought of quite in quite that way so so so that

1072
01:08:11,060 --> 01:08:14,340
is my advice to the to engineering students for the students who

1073
01:08:14,350 --> 01:08:19,000
i have not seen this material before the other coming out from different fields

1074
01:08:19,010 --> 01:08:21,010
and maybe only heard you know

1075
01:08:21,030 --> 01:08:24,850
secret tales of the fourier transform and its use is well i hope you enjoy

1076
01:08:24,850 --> 01:08:28,900
the ride because it's gonna be alright or right

1077
01:08:28,950 --> 01:08:31,730
as we go along all right now

1078
01:08:31,780 --> 01:08:35,330
for every one i sort of feel like at the issue and call this of

1079
01:08:35,330 --> 01:08:38,580
warning or just sort of statement of principle or whatever this is a very mathematical

1080
01:08:39,460 --> 01:08:43,290
this is one of the sort of holy trinity of classes in the information systems

1081
01:08:43,290 --> 01:08:47,360
lab electrical engineering molecular genetics very broad department is split up into a number laboratories

1082
01:08:47,660 --> 01:08:52,020
or research lines i am in information systems lab which is sort of the mathematical

1083
01:08:52,020 --> 01:08:57,220
part of the subject of signal processing coding theory imaging and so on and this

1084
01:08:58,350 --> 01:09:02,010
has been for a number of years taught by faculty sort of thought of as

1085
01:09:02,020 --> 01:09:06,010
a cornerstone in the signal processing although has a lot of different applications a lot

1086
01:09:06,010 --> 01:09:11,080
of different areas the other courses in the holy trinity or two sixty three dynamical

1087
01:09:11,110 --> 01:09:16,580
linear dynamical systems and two seventy eight statistical signal processing centers is actually master so

1088
01:09:16,580 --> 01:09:19,050
because is also very common thing sixty three

1089
01:09:19,140 --> 01:09:24,020
the class also a strong majority anything to seventy eight

1090
01:09:24,460 --> 01:09:28,180
OK so there's available little if you have a little bit less but still number

1091
01:09:28,180 --> 01:09:28,870
of people

1092
01:09:28,870 --> 01:09:29,780
OK maybe

1093
01:09:29,780 --> 01:09:34,620
we start right on time and i have a tight schedule today because my flight

1094
01:09:34,620 --> 01:09:36,480
back to munich is

1095
01:09:36,490 --> 01:09:37,720
tonight today

1096
01:09:37,760 --> 01:09:40,280
eight PM

1097
01:09:40,960 --> 01:09:46,330
i am sorry with a little bit so welcome to the auditorium outlier detection techniques

1098
01:09:46,670 --> 01:09:48,240
my name is a clue that

1099
01:09:48,260 --> 01:09:53,210
i present this chart for you on behalf of has been my boss and

1100
01:09:53,210 --> 01:09:55,710
in order to make it was also around here

1101
01:09:55,790 --> 01:10:01,220
but she is involved in workshop this afternoon so that he will stay

1102
01:10:01,230 --> 01:10:05,150
the other day so if you have any questions come to your mind afterwards not

1103
01:10:05,150 --> 01:10:07,940
today than just

1104
01:10:07,970 --> 01:10:08,910
i hope you

1105
01:10:08,940 --> 01:10:10,120
i will show up

1106
01:10:10,120 --> 01:10:11,440
these shortly

1107
01:10:11,450 --> 01:10:13,440
the coffee break so

1108
01:10:13,440 --> 01:10:15,190
you see his face

1109
01:10:15,200 --> 01:10:16,400
talk to him

1110
01:10:16,410 --> 01:10:17,970
i don't have what so

1111
01:10:18,040 --> 01:10:23,330
someone has to watch clock because i think it three we should make all right

1112
01:10:23,450 --> 01:10:25,790
maybe one of you could

1113
01:10:25,930 --> 01:10:28,920
of course i have an eye on this

1114
01:10:29,720 --> 01:10:35,030
OK so some generations before we start please feel free to

1115
01:10:35,030 --> 01:10:37,840
ask any questions at any time i want to

1116
01:10:38,050 --> 01:10:39,750
little bit casual so you can

1117
01:10:39,750 --> 01:10:43,670
you can discuss issues here if you have questions just

1118
01:10:43,720 --> 01:10:45,160
interrupt me

1119
01:10:45,170 --> 01:10:49,560
and the general aim of this tutorial is you to get

1120
01:10:49,590 --> 01:10:53,660
more or less the big picture of the detection which is brought

1121
01:10:53,700 --> 01:10:55,620
area of research so

1122
01:10:55,640 --> 01:10:57,170
cover all

1123
01:10:57,220 --> 01:11:01,450
details all methods of islands here but we try to give you a kind of

1124
01:11:01,450 --> 01:11:03,860
big picture of works

1125
01:11:03,860 --> 01:11:06,080
and the big picture is not in terms of

1126
01:11:06,090 --> 01:11:08,500
listing some methods and algorithms

1127
01:11:08,530 --> 01:11:12,420
you will get a list of methods and algorithms

1128
01:11:12,420 --> 01:11:16,860
the main point here is in terms of getting the picture in terms of basic

1129
01:11:16,860 --> 01:11:18,620
approaches to modeling

1130
01:11:18,640 --> 01:11:21,200
the approaches followed by detection

1131
01:11:21,530 --> 01:11:25,550
and as i said some some will also be provided

1132
01:11:25,560 --> 01:11:26,890
but so

1133
01:11:26,950 --> 01:11:31,640
this selection is quite arbitrary so if you favourite algorithm is not on the list

1134
01:11:32,060 --> 01:11:33,370
please don't

1135
01:11:36,780 --> 01:11:39,870
and well usually these slides should be

1136
01:11:39,900 --> 01:11:46,130
made available for the KDD website but i heard about some problem so i just

1137
01:11:46,130 --> 01:11:50,490
visit our website maybe a skip to the first page here

1138
01:11:50,500 --> 01:11:52,590
the website

1139
01:11:55,540 --> 01:12:00,090
for these systems is to define the semantics the

1140
01:12:01,410 --> 01:12:03,690
and then you will see

1141
01:12:04,770 --> 01:12:06,340
so we're pages

1142
01:12:06,530 --> 01:12:10,720
the later slides hopefully at the end of this week or

1143
01:12:10,720 --> 01:12:13,150
being an expert

1144
01:12:14,780 --> 01:12:16,660
so let's start

1145
01:12:19,820 --> 01:12:26,880
just navigate to up two of my personal website you will find personal website on

1146
01:12:26,880 --> 01:12:28,340
this on the side

1147
01:12:28,340 --> 01:12:29,070
and then

1148
01:12:29,090 --> 01:12:31,530
four artists to homepage and then

1149
01:12:32,810 --> 01:12:34,280
i will try to make it

1150
01:12:34,340 --> 01:12:36,960
very clearly

1151
01:12:36,970 --> 01:12:42,220
OK so let's start with a short discussion on what is an outlier what's what's

1152
01:12:42,220 --> 01:12:43,570
all about you

1153
01:12:43,620 --> 01:12:48,030
and mostly any paper that these about section

1154
01:12:48,040 --> 01:12:51,340
the site the definition of hawkins

1155
01:12:51,380 --> 01:12:55,530
most simply says that out there is an observation which deviates so much from the

1156
01:12:55,530 --> 01:12:57,940
other observations as to arouse suspicions

1157
01:12:57,960 --> 01:12:59,940
that it was generated by

1158
01:12:59,960 --> 01:13:03,180
a different mechanism so hawkins statistics

1159
01:13:03,220 --> 01:13:04,380
so we had

1160
01:13:05,690 --> 01:13:09,120
in statistics based traditional on this

1161
01:13:09,130 --> 01:13:11,560
task and

1162
01:13:11,560 --> 01:13:14,190
if we take a closer look on this

1163
01:13:14,210 --> 01:13:17,930
this definition we see that he or

1164
01:13:17,970 --> 01:13:22,370
colleagues also assume that the normal data

1165
01:13:22,380 --> 01:13:25,280
not the outliers usually follow

1166
01:13:25,340 --> 01:13:29,520
special mechanisms to generates these normal data points

1167
01:13:30,530 --> 01:13:36,000
for example some given statistical process and the outliers of those objects that deviate from

1168
01:13:36,940 --> 01:13:38,280
generating mechanism

1169
01:13:39,690 --> 01:13:41,630
maybe are generated by

1170
01:13:41,630 --> 01:13:43,780
tracer methodology because he

1171
01:13:43,800 --> 01:13:47,480
no it's not computers working budget six hundred dollars

1172
01:13:47,490 --> 01:13:50,260
three days later

1173
01:13:50,270 --> 01:13:56,480
trillions of dollars in information technology investments we have resources to the

1174
01:13:56,500 --> 01:13:58,370
ten the plot was

1175
01:13:58,370 --> 01:14:00,530
and you can see some examples

1176
01:14:00,550 --> 01:14:04,590
just distribution of microsoft i am thinking about this

1177
01:14:04,650 --> 01:14:06,940
it's on under right

1178
01:14:06,950 --> 01:14:10,780
which to me just say this

1179
01:14:10,810 --> 01:14:13,900
what is the question because it forced

1180
01:14:14,050 --> 01:14:19,920
the tracer methodology usually people to perform much more intense in the first round to

1181
01:14:21,180 --> 01:14:22,880
how is it that way

1182
01:14:22,890 --> 01:14:27,370
no global social or people can less tunnel

1183
01:14:27,440 --> 01:14:30,630
five shortly after the start sitting somewhere in

1184
01:14:30,650 --> 01:14:32,560
and please to

1185
01:14:32,590 --> 01:14:34,660
try some kind

1186
01:14:34,660 --> 01:14:35,770
mathematical models

1187
01:14:35,800 --> 01:14:37,480
so the first thing

1188
01:14:37,670 --> 01:14:41,830
thank you so very much information no a little the target

1189
01:14:41,860 --> 01:14:47,470
trying to reach you can construct visual thousand sets a distributed

1190
01:14:47,490 --> 01:14:51,000
and it's not time as

1191
01:14:52,220 --> 01:14:58,520
there was a revival of interest in the small problems separation thanks to about colleagues

1192
01:14:58,550 --> 01:15:04,330
colonel duncan watts and steven strogatz who essentially suppose we think social networks using random

1193
01:15:04,330 --> 01:15:09,860
graphs right in particular structure in this which we have some kind of reference for

1194
01:15:09,860 --> 01:15:11,050
you know some of the

1195
01:15:11,410 --> 01:15:14,040
random restaurant to make small

1196
01:15:15,550 --> 01:15:17,990
they have to think about following very simple model

1197
01:15:18,000 --> 01:15:20,460
in which we mention know

1198
01:15:20,460 --> 01:15:22,160
three and again training

1199
01:15:22,240 --> 01:15:24,200
the simplest model we can see the

1200
01:15:24,210 --> 01:15:25,410
before the GRR

1201
01:15:28,150 --> 01:15:29,280
we have an to

1202
01:15:29,310 --> 01:15:31,280
right so the reason you you know

1203
01:15:31,290 --> 01:15:34,830
one explanation is that very small world if we only knew people the next as

1204
01:15:35,340 --> 01:15:36,490
well based on this

1205
01:15:36,650 --> 01:15:40,130
she and when ships that we have the ones to reach across the country half

1206
01:15:40,130 --> 01:15:43,760
way around the world a story or so

1207
01:15:44,070 --> 01:15:46,760
world spam links social ties to make

1208
01:15:46,780 --> 01:15:49,810
make the world smaller and

1209
01:15:49,870 --> 01:15:52,070
so think that to

1210
01:15:52,090 --> 01:15:54,260
random access the screen which in turn

1211
01:15:55,330 --> 01:15:58,300
probably indicating the strength of the

1212
01:15:58,320 --> 01:16:01,230
exponent of the the k

1213
01:16:01,230 --> 01:16:03,300
travel experiences physical space

1214
01:16:03,310 --> 01:16:08,810
in which you probably something do something like myself one thirty square

1215
01:16:08,820 --> 01:16:09,750
thank you

1216
01:16:10,770 --> 01:16:12,210
this be actually

1217
01:16:12,210 --> 01:16:17,690
next model for thinking about not just a small world for the experiment so because

1218
01:16:17,730 --> 01:16:22,730
you want to model the something you already know something about the world but not

1219
01:16:22,760 --> 01:16:24,640
you try to use what you know

1220
01:16:24,640 --> 01:16:27,700
green actually later start

1221
01:16:28,520 --> 01:16:36,240
actually the model is simple and yields surprise so in particular has to decide

1222
01:16:36,930 --> 01:16:39,180
so very small

1223
01:16:39,190 --> 01:16:42,180
completely world you're looking be independent of the distance

1224
01:16:43,210 --> 01:16:44,480
recent report

1225
01:16:44,770 --> 01:16:46,070
one of

1226
01:16:48,510 --> 01:16:51,150
thirty nine to clandestine very short

1227
01:16:51,160 --> 01:16:55,050
that is the nature your different people who are very close to

1228
01:16:55,080 --> 01:16:56,650
so what

1229
01:16:56,650 --> 01:17:00,040
these two ran and on the other hand will not be the

1230
01:17:00,060 --> 01:17:02,380
four times in fact

1231
01:17:02,380 --> 01:17:02,890
the actually

1232
01:17:04,030 --> 01:17:05,650
one for search

1233
01:17:06,200 --> 01:17:07,390
the simplest where

1234
01:17:08,640 --> 01:17:15,830
it's very quick essentially social network reaches itself in not to support very very to

1235
01:17:15,830 --> 01:17:19,490
distant targets essentially following the best way possible

1236
01:17:19,500 --> 01:17:21,230
the system which was to let

1237
01:17:22,450 --> 01:17:24,420
because the roads

1238
01:17:24,770 --> 01:17:30,800
and we need to remain in office buildings finding if you simply want this work

1239
01:17:30,820 --> 01:17:32,950
to be the irishman area

1240
01:17:32,970 --> 01:17:34,380
but maybe i'm five

1241
01:17:34,520 --> 01:17:38,320
some of those

1242
01:17:38,380 --> 01:17:40,820
the fundamental issue here about building

1243
01:17:40,880 --> 01:17:42,890
really this two-dimensional grid

1244
01:17:42,900 --> 01:17:44,460
was deleted pretty

1245
01:17:44,480 --> 01:17:45,520
it was released

1246
01:17:45,650 --> 01:17:50,510
to see how the structure constrains friendships are based on principles of the collection

1247
01:17:52,900 --> 01:17:54,460
connections to phase transition

1248
01:17:54,480 --> 01:17:58,780
phenomenon physics and actually think that is

1249
01:17:58,790 --> 01:18:04,080
there is one of the basic questions of course is well so what is the

1250
01:18:04,090 --> 01:18:05,410
real exponent in

1251
01:18:05,420 --> 01:18:08,820
human social networks and for

1252
01:18:08,860 --> 01:18:14,930
say well of course we want to create a random trying to come that with

1253
01:18:14,940 --> 01:18:16,810
first there was something to that person

1254
01:18:16,830 --> 01:18:18,230
after all

1255
01:18:18,250 --> 01:18:22,220
the question is the standard this is a approximation to the world

1256
01:18:22,220 --> 01:18:24,690
does the approximate x y

1257
01:18:24,730 --> 01:18:29,290
square and again something even in two thousand they couldn't to me

1258
01:18:29,310 --> 01:18:31,070
much traction i mean

1259
01:18:31,080 --> 01:18:32,870
well nineteen sixty seven

1260
01:18:32,900 --> 01:18:35,710
but as

1261
01:18:35,730 --> 01:18:37,800
six seven years

1262
01:18:37,820 --> 01:18:41,150
you see these sites were

1263
01:18:41,240 --> 01:18:41,870
twenty two

1264
01:18:41,890 --> 01:18:47,390
measuring this it's it's sort of tree namely u two million people to to

1265
01:18:47,450 --> 01:18:49,890
systems with friends are really

1266
01:18:49,910 --> 01:18:51,430
so we can measure

1267
01:18:51,450 --> 01:18:56,280
sex and actually some supplies money

1268
01:18:56,300 --> 01:18:57,930
most are now

1269
01:18:58,110 --> 01:19:01,860
a couple years ago delivered now ravikumar just

1270
01:19:01,870 --> 01:19:03,680
provide right into tokens

1271
01:19:04,290 --> 01:19:05,530
ten want

1272
01:19:06,330 --> 01:19:09,220
an online learning community that has featured so

1273
01:19:09,220 --> 01:19:13,480
it has be so time

1274
01:19:13,590 --> 01:19:16,050
he was the systems by the

1275
01:19:17,070 --> 01:19:18,000
we're looking

1276
01:19:19,000 --> 01:19:20,460
that's exactly what happened

1277
01:19:20,460 --> 01:19:21,970
probably decrease distance

1278
01:19:23,060 --> 01:19:25,370
girls actually

1279
01:19:25,370 --> 01:19:30,670
novel because the the random variable is not seen you see something as which depends

1280
01:19:30,670 --> 01:19:36,340
on the heating

1281
01:19:36,360 --> 01:19:41,480
so what do we have basically in in hidden markov models where you first decide

1282
01:19:41,730 --> 01:19:46,930
on hominid values the random variable can take at any time step and this is

1283
01:19:46,950 --> 01:19:48,920
in the terminology of the

1284
01:19:48,930 --> 01:19:53,790
hmm it's called the number of states so you decide that your HMM is going

1285
01:19:53,790 --> 01:19:57,600
to have to and state so at each time step it could be in one

1286
01:19:57,600 --> 01:20:02,360
of the n possible state is discrete to qt can only be

1287
01:20:02,380 --> 01:20:06,100
say want to tree up to n and that's all that's the only values it

1288
01:20:06,100 --> 01:20:09,600
can take that you're u we'll never know which value it was you just decide

1289
01:20:09,600 --> 01:20:12,340
how many values it could

1290
01:20:12,360 --> 01:20:15,380
then you have to define

1291
01:20:15,400 --> 01:20:18,230
what we call a transition probability

1292
01:20:18,340 --> 01:20:22,610
which says that if i was in the state j

1293
01:20:22,620 --> 01:20:24,840
at time t minus one

1294
01:20:25,180 --> 01:20:29,930
the protein to be in state i at time t is equal to that

1295
01:20:29,950 --> 01:20:35,190
so this is this defines basically how you can move in the random variable but

1296
01:20:35,200 --> 01:20:40,400
without seeing it this is something that you need to estimate without never having seen

1297
01:20:40,430 --> 01:20:43,970
qt for true it's something happening behind

1298
01:20:43,980 --> 01:20:45,040
the c

1299
01:20:45,060 --> 01:20:48,820
and then you have the emission probability so this is really what you see

1300
01:20:48,840 --> 01:20:53,110
and you're going to decide that there going to be a distribution over what you

1301
01:20:53,110 --> 01:20:58,930
observe that is going to depend on which take your that's why because interesting so

1302
01:20:58,930 --> 01:21:01,450
let's suppose that you have and state in your

1303
01:21:01,460 --> 01:21:04,950
a random variable

1304
01:21:04,990 --> 01:21:08,740
for each of the state there is what we call an emission distributions

1305
01:21:08,750 --> 01:21:12,840
which could have emitted your data so now you have your data

1306
01:21:12,850 --> 01:21:17,240
and it has been emitted by one of the state you don't know which one

1307
01:21:17,250 --> 01:21:20,050
if you knew which one it was then

1308
01:21:20,060 --> 01:21:22,700
its distribution would be this one

1309
01:21:22,720 --> 01:21:27,600
so the pretty to image given that you are in that state

1310
01:21:27,620 --> 01:21:30,920
and the the thing you need to to to connect all that is to have

1311
01:21:30,920 --> 01:21:36,400
an initial state probabilities which says basically where do we start this this process how

1312
01:21:36,400 --> 01:21:38,130
how does it start

1313
01:21:38,160 --> 01:21:42,560
this is how you start the process first decide that there was an initial probably

1314
01:21:42,560 --> 01:21:45,000
due to start in that random

1315
01:21:45,020 --> 01:21:49,930
or hidden state are another one another one from there you can now

1316
01:21:50,150 --> 01:21:51,880
the goal

1317
01:21:51,900 --> 01:21:55,790
with the initial and transition probabilities

1318
01:21:55,800 --> 01:21:57,600
for all these three

1319
01:21:57,610 --> 01:22:00,180
probability models have parameters

1320
01:22:00,310 --> 01:22:05,060
that defines the parameter space that defines a family of functions

1321
01:22:05,110 --> 01:22:08,070
and we're going to need to estimate the

1322
01:22:08,590 --> 01:22:10,140
to maximize some

1323
01:22:10,160 --> 01:22:15,100
some like you don't have nice some cost

1324
01:22:15,110 --> 01:22:18,220
there are several things that you are interested in doing when you have in nature

1325
01:22:18,350 --> 01:22:19,860
in your hand

1326
01:22:19,910 --> 01:22:23,570
and the basic three problems that were defined

1327
01:22:23,580 --> 01:22:25,050
ten fifteen years ago

1328
01:22:25,060 --> 01:22:27,090
are the following

1329
01:22:27,110 --> 01:22:31,500
let's suppose i give you an HMM with some parameter

1330
01:22:31,510 --> 01:22:36,260
and that i give you a sequence of data and i ask you

1331
01:22:36,280 --> 01:22:41,930
what is the probability that the sequence was generated by this HMM so what is

1332
01:22:41,940 --> 01:22:45,760
the protein sequence p of x one could be given

1333
01:22:45,780 --> 01:22:48,520
this HMM which is parametrized by a set of

1334
01:22:48,540 --> 01:22:51,050
peter parameters

1335
01:22:51,070 --> 01:22:54,640
this is very useful it's like computing the probability of the goshen or a mixture

1336
01:22:54,640 --> 01:22:56,090
of gaussians you need that

1337
01:22:56,110 --> 01:22:58,580
that's the first problem

1338
01:22:58,630 --> 01:23:01,700
the second problem is

1339
01:23:01,740 --> 01:23:06,480
you decide that you have an HMM with these sets of parameters

1340
01:23:06,580 --> 01:23:11,400
lots of transition probabilities emission priorities and his initial probabilities

1341
01:23:11,530 --> 01:23:14,650
now i give you a training set of several sequences

1342
01:23:14,700 --> 01:23:19,190
and i ask you what are the best value of the the

1343
01:23:19,200 --> 01:23:20,800
the parliamentarian

1344
01:23:20,810 --> 01:23:26,380
suggesting it we maximize the likelihood of your training set this is training if you

1345
01:23:26,380 --> 01:23:31,350
remember this is very similar to a training set process caution mixture model because you

1346
01:23:31,350 --> 01:23:36,230
are searching for the parameters that maximize the likelihood of the product over all the

1347
01:23:36,230 --> 01:23:37,730
sequences you may have

1348
01:23:38,780 --> 01:23:42,670
probability of that sequence given the model of course to do that you first need

1349
01:23:42,670 --> 01:23:44,330
to be able to do this

1350
01:23:44,340 --> 01:23:47,360
this is the first then you can do that

1351
01:23:47,380 --> 01:23:49,620
this training

1352
01:23:49,640 --> 01:23:51,810
and then in some cases

1353
01:23:51,830 --> 01:23:54,130
you may even want to know

1354
01:23:54,150 --> 01:23:59,210
OK i assume that this sequence has been generated by these hmm but we all

1355
01:23:59,210 --> 01:24:01,360
know that this HMM is in fact

1356
01:24:01,400 --> 01:24:07,210
the combination of a random hidden process and some of the process not what i

1357
01:24:07,210 --> 01:24:09,780
would like to know is what

1358
01:24:09,830 --> 01:24:14,640
i assuming that each observation was only generated by one of the state

1359
01:24:14,650 --> 01:24:18,920
i would like to know the path we followed into the state space so at

1360
01:24:18,920 --> 01:24:22,170
each time step i would like to know in which state i was at that

1361
01:24:22,170 --> 01:24:26,870
time for some problems it might be useful in fact in speech recognition is very

1362
01:24:27,850 --> 01:24:32,360
in some cases you don't care about that in some cases you do care and

1363
01:24:32,360 --> 01:24:34,390
this is the third problem you

1364
01:24:34,420 --> 01:24:38,370
you would like to know whether what is the

1365
01:24:38,420 --> 01:24:39,570
the best

1366
01:24:39,610 --> 01:24:44,140
past so q being the best true it in space

1367
01:24:44,160 --> 01:24:49,620
that that would maximize the one that maximizes the joint probability of your data

1368
01:24:49,620 --> 01:24:50,520
the is

1369
01:24:50,540 --> 01:24:57,020
the bible

1370
01:24:57,040 --> 01:25:01,830
so what can we do it with HMM if we are able to

1371
01:25:01,850 --> 01:25:05,330
to solve these three problems the first one is that in fact it's the generative

1372
01:25:06,010 --> 01:25:11,410
it's distribution and as such you can generate new sequences using it so how do

1373
01:25:11,410 --> 01:25:13,690
you generate the sequence using an HMM

1374
01:25:14,960 --> 01:25:20,050
we use three blocks that we have the initial probabilities emission probabilities the transition probabilities

1375
01:25:20,390 --> 01:25:27,440
so first we have our initialisation initial probability state we select one of the state

1376
01:25:27,540 --> 01:25:29,970
as being the initial state

1377
01:25:31,880 --> 01:25:33,010
this set of

1378
01:25:33,090 --> 01:25:36,640
models the initial pretty well and then

1379
01:25:36,660 --> 01:25:38,130
we're going to to

1380
01:25:38,140 --> 01:25:39,170
two loop

1381
01:25:39,190 --> 01:25:42,540
and basically using the transition probabilities

1382
01:25:42,550 --> 01:25:45,090
two to decide

1383
01:25:45,110 --> 01:25:46,430
what's the next day

1384
01:25:46,450 --> 01:25:49,590
and when we in the next eight we're going to

1385
01:25:49,610 --> 01:25:54,370
it according to the distribution of the emission distribution of that state and then we're

1386
01:25:54,370 --> 01:25:55,710
going to

1387
01:25:55,730 --> 01:25:57,900
the transition to the next

1388
01:25:57,940 --> 01:26:03,020
the image transition in and eventually we are going to reach estate which would have

1389
01:26:03,020 --> 01:26:08,710
labelled as the file state state of which if you get into that one you

1390
01:26:10,290 --> 01:26:13,700
and in that case you stop and you have your sequence you have generated the

1391
01:26:13,700 --> 01:26:15,240
sequence according

1392
01:26:15,300 --> 01:26:21,320
two your model

1393
01:26:22,980 --> 01:26:28,010
in order to be able to train an HMM so to try to solve the

1394
01:26:28,010 --> 01:26:34,480
values three tasks that we have neither even computing the likelihood computing the

1395
01:26:34,490 --> 01:26:39,630
the best set of parameters of finding the best path

1396
01:26:39,680 --> 01:26:44,070
the very nature agent that has already been trained we are only going to be

1397
01:26:44,070 --> 01:26:47,540
able to do that if we make a lot of assumptions and they're all based

1398
01:26:47,540 --> 01:26:56,460
on the on these markovian assumptions like first-order things saying that for instance it basically

1399
01:26:56,460 --> 01:27:02,640
the first one says that the brain is deprived to have emitted a single

1400
01:27:03,820 --> 01:27:07,110
at time t

1401
01:27:07,110 --> 01:27:11,440
in theory should depend on everything that passes before so all the input

1402
01:27:11,470 --> 01:27:16,130
previous values and even the current one of the state variable and even of what

1403
01:27:16,130 --> 01:27:20,150
was observed that the true probability of what could happen if it all depends on

1404
01:27:20,150 --> 01:27:26,310
building my my application and finally to engineer some of these resources then this step

1405
01:27:26,370 --> 01:27:32,210
is to plan the ontology developers development as we do with that we should be

1406
01:27:32,210 --> 01:27:34,920
doing in any civil engineering projects

1407
01:27:34,970 --> 01:27:37,350
so in that case in in

1408
01:27:37,370 --> 01:27:43,170
you already know there are several ontology seminar life cycle models in the engineering so

1409
01:27:43,170 --> 01:27:48,530
what we did inside the project is to about these life cycle models to the

1410
01:27:48,530 --> 01:27:53,140
ontology development and for that we can say that we can use the water for

1411
01:27:53,140 --> 01:27:58,500
life cycle more the incremental motherly iterative model despite one and after that because i

1412
01:27:58,500 --> 01:28:02,000
know the requirements and i did this preliminary study i can say

1413
01:28:02,040 --> 01:28:03,490
OK the

1414
01:28:03,490 --> 01:28:09,770
for my ontology i i will instantiate one of these more than they will create

1415
01:28:10,190 --> 01:28:13,550
by ontology life cycle model and it is important to say that there is no

1416
01:28:13,580 --> 01:28:16,750
you unique life cycle more than four

1417
01:28:16,760 --> 01:28:21,590
four for all the the ontology development projects i mean in some cases you could

1418
01:28:21,590 --> 01:28:25,100
use incremental motherlode tentative or water

1419
01:28:25,160 --> 01:28:26,900
so so in that case

1420
01:28:26,920 --> 01:28:28,390
because we

1421
01:28:28,410 --> 01:28:29,830
we found in the

1422
01:28:29,850 --> 01:28:31,010
when we search

1423
01:28:31,020 --> 01:28:37,830
four sources we found several sources in HTML and the internet of the organisations also

1424
01:28:37,830 --> 01:28:39,520
forced the

1425
01:28:39,530 --> 01:28:44,690
the ontology development process was scheduled as follows so so first we have the requirements

1426
01:28:44,690 --> 01:28:50,790
information then we consider the reuse and reengineering of resources after that we do this

1427
01:28:50,800 --> 01:28:55,460
item on monday and then they implementation and what we did was to create a

1428
01:28:55,460 --> 01:29:00,340
kind of like this one in which you can see here in the middle that

1429
01:29:00,340 --> 01:29:06,570
ontologies or ontology reuse and and an ontological

1430
01:29:06,720 --> 01:29:14,040
so the use and reengineering comes before the competition the ontology concept but it should

1431
01:29:14,040 --> 01:29:19,510
be possible for foreigners to create this kind of gantt charts you know the two

1432
01:29:19,510 --> 01:29:20,760
two two two two

1433
01:29:20,760 --> 01:29:26,720
to visualise graphically the order in which we plan to do the activities when

1434
01:29:26,760 --> 01:29:27,490
and how

1435
01:29:27,500 --> 01:29:30,220
is the relationship between the different

1436
01:29:31,150 --> 01:29:34,080
so big because we

1437
01:29:34,140 --> 01:29:37,260
five so because we

1438
01:29:37,290 --> 01:29:41,980
we have selected we did this specification with the planet and we already know the

1439
01:29:41,980 --> 01:29:45,680
resources we plan to reduce at this point i'm going to explain very quickly some

1440
01:29:45,680 --> 01:29:51,190
guidelines for non ontological resource reuse and reengineering so the idea is that at this

1441
01:29:51,190 --> 01:29:53,700
point we can use information

1442
01:29:53,710 --> 01:30:01,230
about that appears in glossary dictionary lexicon classification schema the saudis son and folksonomies and

1443
01:30:01,230 --> 01:30:05,490
then in the case of classification scheme we can find the

1444
01:30:05,500 --> 01:30:11,060
the the classification scheme i'm in different in different formats i mean someone could use

1445
01:30:11,060 --> 01:30:15,000
about the nomination that essentially is the snowflake the

1446
01:30:15,020 --> 01:30:19,070
the flat and it a more than a set of four representing the taxonomy so

1447
01:30:19,070 --> 01:30:22,950
maybe the idea is that if you have one i could have several data models

1448
01:30:22,950 --> 01:30:26,350
for this does not mean so you can see here two of them for one

1449
01:30:26,350 --> 01:30:30,520
of the neck could have that astronomy implemented in different languages in that case i

1450
01:30:30,520 --> 01:30:32,800
have a spreadsheet and also

1451
01:30:32,870 --> 01:30:34,890
in in XML

1452
01:30:34,890 --> 01:30:36,710
so the idea is that

1453
01:30:36,730 --> 01:30:42,530
probably for when we have engineering all these resources we need to integrate we need

1454
01:30:42,530 --> 01:30:46,660
to we need some kind of rappers went to transform does not this information into

1455
01:30:46,970 --> 01:30:51,080
the ontology is we could stand some part of the ontology we could integrate other

1456
01:30:51,080 --> 01:30:56,540
part we could we could cut off part of the parts of the of the

1457
01:30:56,560 --> 01:31:01,640
of the model that we we we already transform and then we need to integrate

1458
01:31:01,690 --> 01:31:06,650
into a coherent model so in our case this is an example of how

1459
01:31:06,650 --> 01:31:12,300
we have an engineer one i is always stand about that provides information about countries

1460
01:31:12,300 --> 01:31:17,020
and then that of a that also provide information about the different regions in this

1461
01:31:17,020 --> 01:31:20,700
space so based on that what we did was to create the ontology more than

1462
01:31:20,700 --> 01:31:26,200
what would we talk about country subclassof location years so class of location and then

1463
01:31:26,200 --> 01:31:31,290
the relationship between the country and so based on that we can transform the content

1464
01:31:31,290 --> 01:31:35,620
from these two resources in two instances of the ontology and then to generate the

1465
01:31:36,010 --> 01:31:37,740
the RDF

1466
01:31:37,770 --> 01:31:43,960
so for for ontologies are used in that case there are several possibilities and they

1467
01:31:43,960 --> 01:31:50,310
appear invisible in the in the neon project so you can reuse general common ontologies

1468
01:31:50,640 --> 01:31:51,720
as they are

1469
01:31:51,730 --> 01:31:55,220
you can reuse domain ontologies

1470
01:31:55,230 --> 01:32:01,170
or you could have the situation in which you only want to use the model

1471
01:32:01,170 --> 01:32:01,990
of the

1472
01:32:02,030 --> 01:32:07,120
ontologies i mean because you don't need let's say one hundred thousand concerts in one

1473
01:32:07,120 --> 01:32:08,420
and this will be

1474
01:32:08,440 --> 01:32:09,870
so the joint talk

1475
01:32:10,560 --> 01:32:15,630
i hundreds and after the talk tears will take over

1476
01:32:15,640 --> 01:32:18,900
the task we will consider this talk is

1477
01:32:18,910 --> 01:32:20,840
we want to measure natural images

1478
01:32:20,850 --> 01:32:22,060
natural images

1479
01:32:22,320 --> 01:32:24,330
he noted by u

1480
01:32:24,350 --> 01:32:26,350
think of them as the long vectors

1481
01:32:26,350 --> 01:32:30,620
normally the matrix structure but they are not long vector having an components

1482
01:32:30,640 --> 01:32:32,000
and we want

1483
01:32:32,010 --> 01:32:35,640
to reconstruct them from noisy linear measurements

1484
01:32:36,370 --> 01:32:40,420
y contains the noisy linear measurements x

1485
01:32:41,110 --> 01:32:42,820
the design matrix

1486
01:32:42,840 --> 01:32:44,560
every row of x

1487
01:32:44,570 --> 01:32:45,640
corresponds to

1488
01:32:46,360 --> 01:32:48,900
too little food applied to the image

1489
01:32:48,960 --> 01:32:52,140
and then there is some noise to edit

1490
01:32:52,380 --> 01:32:56,140
this talk their applications in digital photography

1491
01:32:56,140 --> 01:32:57,610
and also in

1492
01:32:57,630 --> 01:32:59,950
magnetic resonance imaging

1493
01:32:59,960 --> 01:33:02,530
it's an interesting problem two

1494
01:33:02,540 --> 01:33:07,850
from given a fixed measurement architecture x to reconstruct the image what you

1495
01:33:09,110 --> 01:33:12,670
the problem are going to take over here is how to choose the

1496
01:33:12,680 --> 01:33:14,900
the measurement designs

1497
01:33:14,900 --> 01:33:18,680
if you look at the linear and if you inform them in some way you

1498
01:33:19,280 --> 01:33:20,710
at this

1499
01:33:20,730 --> 01:33:25,350
before you see that there some some structures and sparsity structure

1500
01:33:25,370 --> 01:33:29,480
and the theory of of compressed sensing suggests that

1501
01:33:29,540 --> 01:33:30,370
if you

1502
01:33:30,390 --> 01:33:32,310
do a reconstruction

1503
01:33:32,340 --> 01:33:35,540
with the sparseness and forcing penalty then

1504
01:33:35,560 --> 01:33:36,460
you should

1505
01:33:36,480 --> 01:33:39,500
use randomized measurement architecture

1506
01:33:41,040 --> 01:33:43,540
if you look closer to the image then you see that

1507
01:33:43,590 --> 01:33:47,900
most of the energy is concentrated at some some some point and if you have

1508
01:33:47,900 --> 01:33:49,180
the PCT than

1509
01:33:49,230 --> 01:33:51,930
the concentration of energy is also very striking

1510
01:33:53,030 --> 01:33:58,370
researchers from computer vision and low level television vision their argument

1511
01:33:59,230 --> 01:34:02,140
random x maybe it's not

1512
01:34:02,150 --> 01:34:03,030
not so good

1513
01:34:03,040 --> 01:34:04,710
no contributions here

1514
01:34:04,730 --> 01:34:07,010
we from study

1515
01:34:07,030 --> 01:34:09,090
on several natural images

1516
01:34:09,140 --> 01:34:10,700
and we propose

1517
01:34:10,700 --> 01:34:11,900
fully bayesian methods

1518
01:34:11,930 --> 01:34:13,260
for optimizing

1519
01:34:13,540 --> 01:34:18,430
the measurement design namely we want to tackle the problem of learning compress and really

1520
01:34:18,430 --> 01:34:19,780
want to investigate

1521
01:34:19,780 --> 01:34:25,250
how the design affects the reconstruction

1522
01:34:25,270 --> 01:34:28,380
OK what what properties of the going to exploit

1523
01:34:28,900 --> 01:34:32,370
you know the image is sparse what does it mean if you look at the

1524
01:34:32,370 --> 01:34:36,330
pics of this is the this is the gradient of the image means you take

1525
01:34:37,150 --> 01:34:39,030
the neighbouring differences and

1526
01:34:39,030 --> 01:34:40,900
at this whereas

1527
01:34:40,930 --> 01:34:44,340
you see that many of them is zero the means in the histogram it's

1528
01:34:44,560 --> 01:34:48,000
center zero and it's really a sharp peak and many of them are zero but

1529
01:34:49,130 --> 01:34:51,240
there edges then they can also

1530
01:34:51,250 --> 01:34:56,000
and they are allowed to take bigger value that means the black histogram has heavier

1531
01:34:57,150 --> 01:34:57,900
then say

1532
01:34:57,930 --> 01:34:59,590
since a goes

1533
01:34:59,590 --> 01:35:01,900
and all model we are concentrating on

1534
01:35:01,900 --> 01:35:02,960
well plus

1535
01:35:03,030 --> 01:35:04,240
potential which

1536
01:35:04,270 --> 01:35:06,120
is a reasonable fit to

1537
01:35:06,120 --> 01:35:08,000
the histogram

1538
01:35:08,020 --> 01:35:12,910
i would whole the optimisation go we were applied greedy strategy

1539
01:35:13,770 --> 01:35:15,110
optimize one

1540
01:35:16,090 --> 01:35:17,560
of these measurements

1541
01:35:17,590 --> 01:35:20,490
matrix after the other means we the

1542
01:35:20,500 --> 01:35:25,710
we could compute bayesian posterior over over the image and then we'll select

1543
01:35:25,740 --> 01:35:30,870
the rule which maximizes the uncertainty that means the direction of maximum variance and the

1544
01:35:30,870 --> 01:35:32,960
idea is to really shrink

1545
01:35:32,990 --> 01:35:35,310
the entropy of the distribution

1546
01:35:35,340 --> 01:35:38,900
and the algorithm we only uses expectation propagation

1547
01:35:38,910 --> 01:35:43,090
i mean give many details which i suppose that if you really interested in the

1548
01:35:43,090 --> 01:35:44,310
algorithm and how we

1549
01:35:44,330 --> 01:35:46,190
we make it fast and so

1550
01:35:46,210 --> 01:35:50,780
then i invite you to come to the poster session

1551
01:35:50,830 --> 01:35:53,090
to get an intuition on how this

1552
01:35:53,110 --> 01:35:57,930
this procedure is sequential procedure works we've got a video

1553
01:35:57,940 --> 01:36:00,660
you have three three different panels

1554
01:36:00,680 --> 01:36:02,150
on the upper left you see

1555
01:36:02,660 --> 01:36:05,990
o expectation propagation algorithm

1556
01:36:06,000 --> 01:36:07,080
at work

1557
01:36:07,090 --> 01:36:11,220
this means that the reconstruction is done by by expectation propagation

1558
01:36:11,240 --> 01:36:15,530
and the design of the measurement architectures from expectation operation in the middle

1559
01:36:15,550 --> 01:36:19,870
you see random measurements on by the way the measurement for those of in those

1560
01:36:19,870 --> 01:36:21,530
windows here

1561
01:36:23,200 --> 01:36:29,160
this is like the standard way of compressed sensing through your sparsity enforcing penalty

1562
01:36:29,200 --> 01:36:31,520
and it's like the like the last so

1563
01:36:31,550 --> 01:36:34,250
and on the right you see this heuristic

1564
01:36:34,260 --> 01:36:35,190
in the

1565
01:36:35,200 --> 01:36:38,560
the wavelet decomposition of the image and we just measure

1566
01:36:38,560 --> 01:36:41,480
wavelet coefficients top-down from from course

1567
01:36:41,490 --> 01:36:43,600
two to find scale

1568
01:36:43,610 --> 01:36:45,230
and when fourteen years

1569
01:36:45,240 --> 01:36:47,620
the reconstruction error over

1570
01:36:47,660 --> 01:36:49,770
the number of measurements the images are

1571
01:36:49,800 --> 01:36:53,140
sixty four by sixty four pixels

1572
01:36:53,170 --> 01:36:55,740
and what can you see

1573
01:36:55,750 --> 01:37:00,150
first of all you see like the top down localised nature of these benefits measurement

1574
01:37:00,150 --> 01:37:00,830
that means

1575
01:37:01,270 --> 01:37:04,170
they have also scaling behaviour

1576
01:37:04,220 --> 01:37:04,810
you see

1577
01:37:04,830 --> 01:37:07,740
these are the optimized

1578
01:37:07,740 --> 01:37:11,680
measurement for this and they also change their scaling and in the beginning there really

1579
01:37:11,680 --> 01:37:15,330
course scale and then they go to to find scale and these

1580
01:37:15,380 --> 01:37:17,220
these random measurement they don't

1581
01:37:17,230 --> 01:37:21,800
i don't really change OK looking at the reconstruction error we have

1582
01:37:21,810 --> 01:37:22,850
in the

1583
01:37:23,880 --> 01:37:28,310
random measurement architecture has the quite high reconstruction

1584
01:37:28,310 --> 01:37:34,120
the simple baseline heuristic we just measuring the wavelet coefficients reflecting the

1585
01:37:34,140 --> 01:37:37,230
the knowledge we have of images performs better

1586
01:37:37,240 --> 01:37:40,220
however they come close in the end

1587
01:37:40,240 --> 01:37:41,270
if you really go

1588
01:37:41,290 --> 01:37:43,260
and designed

1589
01:37:43,290 --> 01:37:44,600
the measurement for us

1590
01:37:44,610 --> 01:37:45,770
then you can

1591
01:37:45,790 --> 01:37:46,850
you can get

1592
01:37:47,120 --> 01:37:58,000
this like

1593
01:37:58,020 --> 01:37:59,500
and we can only look at that

1594
01:37:59,510 --> 01:38:01,070
and one in which we have

1595
01:38:01,100 --> 01:38:04,000
database of seventy five images which you can see

1596
01:38:04,010 --> 01:38:05,810
you see them

1597
01:38:07,240 --> 01:38:08,580
the curves

1598
01:38:08,600 --> 01:38:10,060
average over those

1599
01:38:10,060 --> 01:38:12,750
of those seventy five images you see

1600
01:38:12,770 --> 01:38:14,680
the little shade corresponds to the

1601
01:38:14,720 --> 01:38:16,180
it was standard

1602
01:38:16,230 --> 01:38:21,110
if for a given the blue curve is the bayesian learning

1603
01:38:21,120 --> 01:38:24,880
as proposed by jean-pierre last year i see no

1604
01:38:24,880 --> 01:38:27,070
it's difficult to attain

1605
01:38:27,080 --> 01:38:30,910
so in that case where we need to do is reduced to binary problem

1606
01:38:30,920 --> 01:38:34,610
so that we can use the kind of tricks they around talked about yesterday for

1607
01:38:34,610 --> 01:38:39,160
reducing to binary in fact joint work with one

1608
01:38:39,210 --> 01:38:42,960
and so the idea is really simple maybe don't even look at the slide the

1609
01:38:42,960 --> 01:38:48,130
really ideas really simple what we can do is we can come up with so

1610
01:38:48,400 --> 01:38:53,550
when you're trying to predict the class of a particular example

1611
01:38:53,550 --> 01:38:57,620
where you have let's say five classes as we do here we can do is

1612
01:38:57,620 --> 01:39:01,180
we can come up with by binary questions which say

1613
01:39:01,260 --> 01:39:05,900
is this example in class a or not is in class b or not

1614
01:39:05,960 --> 01:39:07,020
and so on

1615
01:39:07,040 --> 01:39:09,500
so that's the most straightforward way

1616
01:39:09,520 --> 01:39:13,880
of taking a multi class problem and reducing it to a binary problem

1617
01:39:13,980 --> 01:39:18,510
leads to a person of adaboost called adaboost on MH

1618
01:39:18,510 --> 01:39:23,010
and we can generalize the air bound that we had before like the training year

1619
01:39:23,790 --> 01:39:27,540
is upper bounded by the same product of that we had before

1620
01:39:27,550 --> 01:39:29,660
but now multiplied by

1621
01:39:29,690 --> 01:39:33,130
this number k which is the number of classes which

1622
01:39:33,180 --> 01:39:36,110
not so happy about

1623
01:39:36,130 --> 01:39:39,290
OK there are other techniques for more interesting ways of multi

1624
01:39:39,480 --> 01:39:41,510
reducing multiclass two

1625
01:39:42,600 --> 01:39:47,250
so one of them is to use output coding this is the technique

1626
01:39:47,250 --> 01:39:50,170
you should say up their detrick and they carry this is the technique that was

1627
01:39:50,170 --> 01:39:52,470
developed by detrick trick and they carry

1628
01:39:52,480 --> 01:39:53,830
and the idea here

1629
01:39:53,870 --> 01:39:56,590
is to take each one of your labels

1630
01:39:56,640 --> 01:39:59,000
a b c d e in this case

1631
01:39:59,030 --> 01:40:05,080
and associated codeword with a sequence of pluses and minuses in the matrix like this

1632
01:40:05,110 --> 01:40:07,710
and then what you do is you train

1633
01:40:07,720 --> 01:40:12,420
on each one of these in this case for binary problems

1634
01:40:12,480 --> 01:40:14,660
so in binary problem one

1635
01:40:14,680 --> 01:40:20,210
all of these examples which were labeled c or d get labeled as positive examples

1636
01:40:20,280 --> 01:40:24,400
and all of the examples which were labeled a b here he get labeled as

1637
01:40:24,400 --> 01:40:27,710
negative examples in this alternate binary

1638
01:40:28,910 --> 01:40:33,790
OK new trained separately for each one of these four problems

1639
01:40:33,850 --> 01:40:36,690
OK so we for binary problems

1640
01:40:36,720 --> 01:40:41,080
and then classify a new example what we do is we evaluate

1641
01:40:41,100 --> 01:40:45,750
each of the classifiers which a train for each of these four binary problems get

1642
01:40:45,810 --> 01:40:49,310
sequence predictions sequence of pluses and minuses

1643
01:40:49,320 --> 01:40:54,600
we choose the core the label the row of this matrix

1644
01:40:54,620 --> 01:40:56,210
which is closest

1645
01:40:56,220 --> 01:40:57,840
to the predictions

1646
01:40:57,860 --> 01:40:59,570
which we've got four

1647
01:40:59,590 --> 01:41:04,160
each of the four binary classifiers

1648
01:41:04,240 --> 01:41:07,330
and this is a nice technique because it's more robust

1649
01:41:07,380 --> 01:41:12,970
to mistakes that are made by the individual binary classifiers

1650
01:41:13,340 --> 01:41:16,690
so what we do is we can show that we can also prove training error

1651
01:41:16,690 --> 01:41:19,580
bounds but those bounds and being independent

1652
01:41:19,640 --> 01:41:21,360
of the number of classes

1653
01:41:21,370 --> 01:41:23,730
which seems like a great thing

1654
01:41:23,770 --> 01:41:28,570
but the catch is that the binary problems they are constructing

1655
01:41:28,650 --> 01:41:33,590
here might be much more complicated and much more difficult to get good air raids

1656
01:41:39,620 --> 01:41:42,160
OK so what i want to talk about next

1657
01:41:44,330 --> 01:41:47,750
our confidence rated predictions which are way

1658
01:41:47,760 --> 01:41:51,630
a practical way of dramatically speeding up adaboost

1659
01:41:51,650 --> 01:41:53,400
and practical problems

1660
01:41:53,420 --> 01:41:54,530
so so far

1661
01:41:54,530 --> 01:41:58,610
we have assumed that the weak classifiers are giving us hard predictions

1662
01:41:58,630 --> 01:42:00,830
in other words for every example

1663
01:42:00,840 --> 01:42:04,340
predict either positive or negative

1664
01:42:04,350 --> 01:42:06,330
so what's wrong with doing that

1665
01:42:07,080 --> 01:42:08,560
the problem

1666
01:42:08,830 --> 01:42:13,240
comes up an example in in an example like this one

1667
01:42:13,250 --> 01:42:17,480
so here we've got a bunch of positive and negative points

1668
01:42:17,520 --> 01:42:23,300
and suppose that are weak learning algorithm has identified a rectangle like this rectangle are

1669
01:42:23,310 --> 01:42:27,870
where nearly all the points inside the rectangle are positive

1670
01:42:27,890 --> 01:42:30,160
which seems like an important pattern

1671
01:42:30,210 --> 01:42:32,790
but all these points outside the rectangle

1672
01:42:32,800 --> 01:42:38,410
are roughly equally positive and negative things practically random outside of the rectangle

1673
01:42:39,240 --> 01:42:41,860
how is this weak classifier going to predict

1674
01:42:41,880 --> 01:42:43,750
in a case like this

1675
01:42:43,750 --> 01:42:46,510
well with the weak classifier would really like to do is i would like to

1676
01:42:47,680 --> 01:42:50,320
positive inside the rectangle

1677
01:42:50,330 --> 01:42:53,350
but i would really like to abstain it would really like to say

1678
01:42:53,390 --> 01:42:58,320
i just don't know what the answer is if i'm outside of the rectangle

1679
01:42:58,320 --> 01:43:03,920
so the problem is that if you require hard predictions plus one minus one predictions

1680
01:43:03,920 --> 01:43:07,820
you have no way of expressing this idea of not knowing what the answer is

1681
01:43:07,820 --> 01:43:11,980
you have no way of abstaining on particular predictions

1682
01:43:12,000 --> 01:43:14,760
and in fact if you need to predict

1683
01:43:14,810 --> 01:43:18,270
plus one or minus one outside of this rectangle

1684
01:43:18,340 --> 01:43:21,880
then you clearly going to be making a whole lot of mistakes

1685
01:43:21,900 --> 01:43:23,990
on these points outside here

1686
01:43:23,990 --> 01:43:27,000
so if you predict positive outside the rectangle then you'll be wrong and all the

1687
01:43:28,030 --> 01:43:29,050
if you predict

1688
01:43:29,060 --> 01:43:32,040
negative outside here you'll be wrong in all the positive

1689
01:43:32,090 --> 01:43:36,400
so in either case you're going to be introducing a lot of areas outside of

1690
01:43:36,400 --> 01:43:38,500
this rectangle

1691
01:43:38,540 --> 01:43:43,090
and the problem is that means that you end up with a lot of examples

1692
01:43:44,080 --> 01:43:48,130
a lot of mistakes which need to be cleaned up on later rounds would later

1693
01:43:48,130 --> 01:43:50,320
rounds of boosting you need to correct

1694
01:43:50,360 --> 01:43:51,780
those mistakes

1695
01:43:51,780 --> 01:43:53,970
you've made on these earlier rounds

1696
01:43:53,980 --> 01:43:58,630
in practice this dramatically increases the time to convergence

1697
01:43:58,650 --> 01:44:03,210
so instead what we can do is we can allow our weak learning algorithm to

1698
01:44:03,210 --> 01:44:06,210
use confidence rated predictions

1699
01:44:06,220 --> 01:44:09,800
predictions which have been rated with the confidence

1700
01:44:09,820 --> 01:44:13,640
so on your own talk about this a little bit last time as well

1701
01:44:13,660 --> 01:44:19,020
so before we clas sifier always at output predictions which were either plus one minus

1702
01:44:19,920 --> 01:44:22,800
so now we're allowing are weak classifiers

1703
01:44:22,820 --> 01:44:27,090
output predictions which are just arbitrary real numbers

1704
01:44:27,140 --> 01:44:31,940
and the intuition is that the sign of that prediction positive or negative

1705
01:44:31,970 --> 01:44:36,770
is our prediction are actual prediction as to whether the positive and negative examples

1706
01:44:36,790 --> 01:44:39,060
and the magnitude of prediction

1707
01:44:39,130 --> 01:44:41,500
is a measure of confidence

1708
01:44:41,500 --> 01:44:45,290
so now you just want to abstain as we did this last example

1709
01:44:45,310 --> 01:44:47,790
the weak classifier to with zero

1710
01:44:47,790 --> 01:44:52,540
in this case indicate that doesn't know the answer

1711
01:44:52,590 --> 01:44:53,770
OK and so

1712
01:44:53,790 --> 01:44:58,730
these confidence rated predictions it turns out that you can use the exact same update

1713
01:45:00,820 --> 01:45:05,000
but the question remains of how to choose the alpert's in each design on each

1714
01:45:06,310 --> 01:45:09,310
and here we can go back to the that training aircrew for the that notion

1715
01:45:09,310 --> 01:45:12,250
of minimizing exponential loss

1716
01:45:13,040 --> 01:45:14,080
and so

1717
01:45:14,090 --> 01:45:18,080
we want to do on every round is you want to choose

1718
01:45:18,090 --> 01:45:24,670
alpha teenage their product which always appears together in such a way as to minimize

1719
01:45:24,670 --> 01:45:27,290
in the case that the

1720
01:45:27,300 --> 01:45:28,830
nonlinearities in the

1721
01:45:28,840 --> 01:45:34,360
it is in the observation model sorry as i just described then the

1722
01:45:34,370 --> 01:45:36,640
the prediction process looks

1723
01:45:36,800 --> 01:45:40,640
it consists of the diffusion just as it did with the gas process the gas

1724
01:45:40,640 --> 01:45:42,040
in filter

1725
01:45:42,080 --> 01:45:48,880
so the whole distribution drifts bodily according to the deterministic part of the aggressive filter

1726
01:45:49,030 --> 01:45:53,360
and then the random part of the autoregressive field sort of smears it out by

1727
01:45:53,360 --> 01:45:57,910
literally blowing it is literally a guassian is what happens to the probability

1728
01:45:57,930 --> 01:46:01,590
distribution and then finally the reactor effective

1729
01:46:01,610 --> 01:46:04,540
of measurements superimposed at the end of the cycle

1730
01:46:04,590 --> 01:46:09,330
so let's see what happens when we actually run this striking against clutter

1731
01:46:11,090 --> 01:46:12,040
here is an

1732
01:46:12,050 --> 01:46:14,950
certain girl dancing around my laboratory

1733
01:46:14,960 --> 01:46:17,880
two strains violin music we just off the right

1734
01:46:17,920 --> 01:46:20,100
she would dance until violence

1735
01:46:20,110 --> 01:46:21,430
was played

1736
01:46:22,340 --> 01:46:23,510
funnily enough

1737
01:46:23,520 --> 01:46:26,830
the best kalman filter that we could designed to do this with the same dynamical

1738
01:46:26,830 --> 01:46:29,830
model lasted only a second before

1739
01:46:29,880 --> 01:46:34,220
there was a momentary confusion i'm not sure how picture this between the outline of

1740
01:46:34,220 --> 01:46:37,730
the head and the outline of the screen it was

1741
01:46:37,740 --> 01:46:41,490
you know just a momentary aberration at that point it look like i the hypothesis

1742
01:46:41,490 --> 01:46:45,970
had reasonable support and randomly the kalman filter with its validation gate and so on

1743
01:46:46,180 --> 01:46:51,310
when for the wrong type of having once made the mistake it can never recover

1744
01:46:51,320 --> 01:46:56,660
in the particle filter is not the same mistake wasn't made these ambiguity arose at

1745
01:46:56,660 --> 01:47:04,310
the same moment the distribution spread out to reflect ambiguity but and also later supporting

1746
01:47:04,660 --> 01:47:11,140
evidence comes in for the main hypothesis and the ephemeral hypothesis vanishes and everything is

1747
01:47:11,140 --> 01:47:15,840
back on track so the robustness of being able to consider multiple hypotheses under these

1748
01:47:15,840 --> 01:47:19,030
multimodal likelihoods is a huge advantage

1749
01:47:19,040 --> 01:47:21,780
and here's even more extreme example where

1750
01:47:21,790 --> 01:47:23,990
we're tracking the motion of the leaf

1751
01:47:24,070 --> 01:47:28,220
where the cluster now is as vicious as can be in that every element of

1752
01:47:28,220 --> 01:47:33,830
clutter looks like a foreground object

1753
01:47:33,860 --> 01:47:37,730
here's the tracking it's thing lying around and we're zooming leaf is going to pass

1754
01:47:37,730 --> 01:47:42,120
in front of the PC really fast in front of the leaf and you know

1755
01:47:42,120 --> 01:47:45,490
there's of momentary aberration if i were to show you the distribution of particles in

1756
01:47:45,490 --> 01:47:51,580
there you see it spread out instantaneously to represent that ambiguity so but then the

1757
01:47:51,580 --> 01:47:54,400
ambiguity gets resolved that that's what these things are really

1758
01:47:56,230 --> 01:47:59,300
and of course as i have already said with reference to juggling

1759
01:47:59,310 --> 01:48:04,570
having the particle filter being able to deal with non guassian distributions also gives you

1760
01:48:04,570 --> 01:48:09,350
more freedom to be creative without the dynamical model so in the particle filter this

1761
01:48:09,350 --> 01:48:10,360
was done by

1762
01:48:10,380 --> 01:48:11,820
in the juggling

1763
01:48:11,830 --> 01:48:16,260
the problem was done by switching between states the different phases of juggling is an

1764
01:48:16,260 --> 01:48:17,860
even more extreme paul

1765
01:48:18,620 --> 01:48:22,690
we're tracking the ball to bounce off hard surface and

1766
01:48:25,560 --> 01:48:29,880
the way the ball behaves at the instant of bouncing is is unlike as possible

1767
01:48:29,880 --> 01:48:34,750
its behavior when it's in freefall also be ridiculous to try to

1768
01:48:34,980 --> 01:48:39,480
press those two kinds of dynamics to cover them with one model model that you

1769
01:48:39,480 --> 01:48:41,830
learn to view insisted on doing that would be very weak

1770
01:48:42,930 --> 01:48:47,760
sure enough his a picture of what happens when the ball bounces on the on

1771
01:48:47,760 --> 01:48:49,260
the hard surface which is here

1772
01:48:49,280 --> 01:48:53,700
and we with a model this is supposed to encompass all kinds of behavior that

1773
01:48:53,700 --> 01:48:55,970
the ball just drops through the table

1774
01:48:57,520 --> 01:49:02,180
in the case where we model explicitly the bounce and this can be done with

1775
01:49:02,320 --> 01:49:07,040
a sequence of a sequence of random variables even including such details as exactly when

1776
01:49:07,040 --> 01:49:12,400
the bounce occurred because there's a video frame time elapses here and the actual instant

1777
01:49:12,400 --> 01:49:18,170
about could be anywhere in the video frame time actually allowing uniformly random variable that

1778
01:49:18,170 --> 01:49:22,520
within the bounds turns out really makes a difference and you see what happens here

1779
01:49:22,550 --> 01:49:25,390
the instant of the balance is that some particles

1780
01:49:25,410 --> 01:49:27,120
carry on with the old behavior

1781
01:49:27,140 --> 01:49:32,320
extrapolating the dynamics and falling through the table and other particles

1782
01:49:32,330 --> 01:49:36,750
generated by the other branches this dynamic model which has in which there is a

1783
01:49:36,750 --> 01:49:42,050
finite probability bounds and the coefficient of restitution and all that are included in the

1784
01:49:42,760 --> 01:49:44,880
and finally of course the evidence

1785
01:49:44,900 --> 01:49:48,560
gets resolved on

1786
01:49:48,610 --> 01:49:49,570
on this

1787
01:49:49,990 --> 01:49:55,570
the alternative hypothesis which happens to be the correct one

1788
01:49:55,580 --> 01:49:57,760
and we tried also

1789
01:49:57,780 --> 01:49:59,880
using this kind of technique for

1790
01:49:59,890 --> 01:50:02,040
an interactive

1791
01:50:02,050 --> 01:50:07,460
process for cutting up objects from images where we replace time with space so

1792
01:50:07,480 --> 01:50:10,900
now we're filtering along the curve as it were

1793
01:50:10,910 --> 01:50:13,120
and i got to

1794
01:50:18,520 --> 01:50:19,960
so now

1795
01:50:19,970 --> 01:50:22,040
i'm going to try and

1796
01:50:22,050 --> 01:50:25,150
cut out this chap

1797
01:50:25,250 --> 01:50:30,080
and so i'm going to i'm going to fourth time forwards and backwards by spinning

1798
01:50:30,080 --> 01:50:31,950
the wheel on my mouse

1799
01:50:31,990 --> 01:50:34,950
so here it is time is going forward

1800
01:50:35,970 --> 01:50:37,480
you see it

1801
01:50:37,530 --> 01:50:39,840
there's observation likelihood

1802
01:50:39,900 --> 01:50:47,130
which knows about high contrast and the likelihood of the desired edge following aligned by

1803
01:50:47,130 --> 01:50:48,280
contrast but there's also

1804
01:50:48,680 --> 01:50:50,140
dynamical priors

1805
01:50:50,160 --> 01:50:52,860
which prefers smooth curves

1806
01:50:56,150 --> 01:51:00,360
but the action is a bit like a regularizer if you like and then finally

1807
01:51:00,360 --> 01:51:04,940
there's an observation likelihood associated with the user whatever the user chooses to do so

1808
01:51:05,170 --> 01:51:10,110
the user can act as an oracle and supply extra information like i just did

1809
01:51:10,150 --> 01:51:13,930
to correct behavior i didn't like and what you also here see here

1810
01:51:13,980 --> 01:51:18,640
it is a kind of trace of all of the hypothesis that were entertained along

1811
01:51:18,640 --> 01:51:22,070
the way so this martian blood been spilt here

1812
01:51:22,140 --> 01:51:24,790
across the tuna of this guy

1813
01:51:24,800 --> 01:51:27,840
it's kind of track

1814
01:51:28,100 --> 01:51:31,350
you don't have the explicit track because that would be too confusing for a user

1815
01:51:31,350 --> 01:51:34,720
but you see this area all of the areas to be considered so now

1816
01:51:35,170 --> 01:51:36,470
actually as a user

1817
01:51:36,490 --> 01:51:37,670
i can pick up

1818
01:51:37,690 --> 01:51:42,090
any point in the the spill area and say no continue from one of those

1819
01:51:43,390 --> 01:51:46,510
and now i'm just spinning the mouse wheel i i can even look at you

1820
01:51:46,510 --> 01:51:49,510
guys while i do it doesn't take much cognitive effort

1821
01:51:49,530 --> 01:51:51,470
every now and again i have to go in and

1822
01:51:51,480 --> 01:51:53,180
right now it's done

1823
01:51:53,200 --> 01:51:54,880
it's completed and

1824
01:51:54,900 --> 01:51:57,030
you know i could

1825
01:51:58,400 --> 01:52:00,750
another one somewhere here

1826
01:52:07,500 --> 01:52:08,870
get rid him

1827
01:52:08,870 --> 01:52:17,280
one of problem when recursive problem size and number two was constant time to do

1828
01:52:17,320 --> 01:52:20,940
the the dividing work here is divided by two

1829
01:52:20,940 --> 01:52:25,420
and the combination work is doing one or possibly two multiplications

1830
01:52:25,430 --> 01:52:28,920
this is the logo

1831
01:52:28,940 --> 01:52:35,490
and allowed to do is multiply numbers logan is the best you can do

1832
01:52:37,330 --> 01:52:42,160
a simple but powerful way

1833
01:52:42,170 --> 01:52:46,340
and every one computer power number you know what to do

1834
01:52:52,830 --> 01:52:55,700
is anyone not know the definition of nineteen numbers

1835
01:52:55,710 --> 01:52:57,110
and is willing to admit it

1836
01:52:57,180 --> 01:53:02,060
OK so this is a good old friends lower than the definition of

1837
01:53:02,080 --> 01:53:05,120
reminder in particular the base cases

1838
01:53:14,930 --> 01:53:16,930
september nineteen numbers i will claim

1839
01:53:16,940 --> 01:53:19,820
are very important because

1840
01:53:19,940 --> 01:53:23,630
here's throughout nature you look at certain fruits you see the actually sequence you count

1841
01:53:23,630 --> 01:53:27,160
the number of little bumps around each ring if you look at this this and

1842
01:53:27,160 --> 01:53:30,520
in the beach and how the waves hits have been actually sequence

1843
01:53:30,540 --> 01:53:35,230
i'm told you look all over the place actually sequences there so how does nature

1844
01:53:35,230 --> 01:53:37,330
computer maybe not just sequence

1845
01:53:39,230 --> 01:53:45,280
different classes and how we can compute seven actually sequence as fast as possible

1846
01:53:45,310 --> 01:53:50,010
you've probably seen two algorithms are called them

1847
01:53:50,020 --> 01:53:51,530
so the

1848
01:53:51,540 --> 01:53:56,250
the most naive algorithm is a recursive algorithm

1849
01:54:00,560 --> 01:54:01,850
three say OK

1850
01:54:01,860 --> 01:54:05,600
f of and say well if ten is zero returns are venice one return one

1851
01:54:05,600 --> 01:54:06,750
otherwise return

1852
01:54:06,790 --> 01:54:10,710
recursively compute f of ten minus one and f of n minus two and them

1853
01:54:12,600 --> 01:54:13,320
how much

1854
01:54:13,370 --> 01:54:16,190
time does this algorithm to

1855
01:54:16,250 --> 01:54:18,040
those who have seen it before

1856
01:54:18,070 --> 01:54:21,950
it's not obvious to guess

1857
01:54:22,010 --> 01:54:23,640
not to be exact

1858
01:54:23,660 --> 01:54:30,920
how many people have seen something before

1859
01:54:30,950 --> 01:54:32,750
and analyse it

1860
01:54:32,760 --> 01:54:34,520
also running time

1861
01:54:34,580 --> 01:54:39,730
really really long ago get any more precise answers just one

1862
01:54:39,740 --> 01:54:41,910
was sent

1863
01:54:41,930 --> 01:54:43,570
exponential yes

1864
01:54:44,520 --> 01:54:48,780
also correct and more precise

1865
01:54:48,860 --> 01:54:50,340
even more precise

1866
01:54:50,630 --> 01:54:52,730
maybe you've seen this analysis before

1867
01:54:52,790 --> 01:54:54,420
its feeder and

1868
01:54:54,470 --> 01:54:56,850
where is the golden ratio

1869
01:54:56,880 --> 01:55:00,690
again the golden ratio appears throughout

1870
01:55:00,690 --> 01:55:04,880
the world in mathematics but this is probably the only time in this class very

1871
01:55:04,880 --> 01:55:08,540
very very minute cameo

1872
01:55:08,560 --> 01:55:09,880
we're happy

1873
01:55:10,020 --> 01:55:13,550
OK this is called exponential time this is bigger than one that's all you need

1874
01:55:13,550 --> 01:55:14,670
to know

1875
01:55:15,070 --> 01:55:18,170
this is exponential time

1876
01:55:18,190 --> 01:55:23,430
meaning it exponential time means basically some constants the power and

1877
01:55:23,480 --> 01:55:27,260
exponential time is a very long time

1878
01:55:29,080 --> 01:55:32,780
OK polynomial time is good

1879
01:55:32,990 --> 01:55:35,730
it's so

1880
01:55:35,750 --> 01:55:41,640
this is what we want are polynomial time algorithms this class basically entirely about polynomial

1881
01:55:41,640 --> 01:55:43,060
time the question

1882
01:55:43,080 --> 01:55:50,930
say what the algorithm does again so it just f then so define function the

1883
01:55:50,970 --> 01:55:52,110
actually n

1884
01:55:52,120 --> 01:55:56,680
i checked for the base cases and otherwise i recursively calls actually and minus one

1885
01:55:56,710 --> 01:56:00,020
i request look often actually be nice to add these two numbers together to you

1886
01:56:00,020 --> 01:56:05,600
get this branching tree something to some problems of almost the same size additively smaller

1887
01:56:05,690 --> 01:56:09,330
by one or two so you have i mean you almost not reducing the problem

1888
01:56:09,330 --> 01:56:11,790
size at all so that's intuitively white

1889
01:56:11,810 --> 01:56:13,010
exponentially you can

1890
01:56:13,020 --> 01:56:15,980
draw to recursion tree you see how big it gets

1891
01:56:15,980 --> 01:56:18,740
how quickly i mean by over two levels

1892
01:56:18,760 --> 01:56:21,270
you've only reduced on one branch the problem

1893
01:56:21,280 --> 01:56:23,800
from and to and over two

1894
01:56:23,860 --> 01:56:26,640
the other one maybe you've gotten from and down to one but none of the

1895
01:56:26,640 --> 01:56:30,830
branches have stopped after an over two levels have the least to the power and

1896
01:56:30,830 --> 01:56:31,960
over two

1897
01:56:31,970 --> 01:56:35,210
which is like square root of two to the power and which is

1898
01:56:35,250 --> 01:56:36,390
getting close to


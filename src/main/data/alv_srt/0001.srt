1
00:00:00,000 --> 00:00:01,150
no way

2
00:00:01,210 --> 00:00:02,530
really is saying

3
00:00:02,550 --> 00:00:07,590
this application should be able to access this file to another

4
00:00:07,610 --> 00:00:13,930
design of this system was in the mainframe operating system back in the nineteen sixties

5
00:00:13,950 --> 00:00:17,890
but sort of disappeared someone simple

6
00:00:17,910 --> 00:00:22,870
so we want things again semantics so that's my website was trying to write the

7
00:00:22,940 --> 00:00:27,640
password file something bad has happened even if the mission saying that i really like

8
00:00:27,880 --> 00:00:30,110
not happen

9
00:00:30,130 --> 00:00:34,910
and to be able to constrain things build models what service are expected to access

10
00:00:34,910 --> 00:00:36,950
to the act as anything else

11
00:00:36,960 --> 00:00:40,870
no it's not going to happen

12
00:00:40,920 --> 00:00:42,100
and a of

13
00:00:42,120 --> 00:00:45,900
stuff was done fast locking

14
00:00:45,910 --> 00:00:49,420
because parallelism is great to spend all your time

15
00:00:49,430 --> 00:00:54,530
trying to stop two friends doing the wrong thing at the same moment

16
00:00:54,570 --> 00:00:56,330
so some might be empty people

17
00:00:56,370 --> 00:00:59,670
and rusty russell created think for taxes

18
00:00:59,700 --> 00:01:04,330
which is the whole thing is the basis of the post lock

19
00:01:04,370 --> 00:01:06,370
that's nice about the

20
00:01:06,390 --> 00:01:09,780
you can't just look at the current on its

21
00:01:09,820 --> 00:01:12,780
and the idea behind this basically

22
00:01:12,820 --> 00:01:16,840
just have law which you can take entirely in user space

23
00:01:16,860 --> 00:01:18,920
where there is no contention

24
00:01:18,930 --> 00:01:19,700
so thank make

25
00:01:19,720 --> 00:01:24,400
system calls saying this look at some of the law

26
00:01:24,410 --> 00:01:27,060
at the same time you want to be able to sleep

27
00:01:27,800 --> 00:01:30,360
the lock is in use

28
00:01:30,380 --> 00:01:32,680
that's hard to do entirely useful

29
00:01:32,700 --> 00:01:36,060
because user space don't have enough information

30
00:01:36,060 --> 00:01:38,910
so the way the way these locks were used

31
00:01:38,970 --> 00:01:40,920
new space you take a lot

32
00:01:41,000 --> 00:01:43,040
but if you fail to play a lot

33
00:01:43,060 --> 00:01:44,920
there is a kernel space public

34
00:01:44,940 --> 00:01:46,780
he worked with the space

35
00:01:46,780 --> 00:01:53,740
which then deals with the weighting case and the like

36
00:01:53,760 --> 00:02:00,100
the security which is what is really interesting thing which is persuaded particularly business better

37
00:02:00,120 --> 00:02:03,050
is the notion of liability

38
00:02:03,060 --> 00:02:09,650
the notion that you might actually be your fault if you don't secure systems

39
00:02:09,750 --> 00:02:16,110
this has led to remarkable in rest the management level systems which are actually secure

40
00:02:16,450 --> 00:02:20,050
system which pretend to be sick

41
00:02:20,070 --> 00:02:24,020
unfortunately for the rest of the world sales one of the very good at telling

42
00:02:24,020 --> 00:02:29,610
management people things ask you would not

43
00:02:29,640 --> 00:02:33,630
going with that we see system which fails site

44
00:02:33,650 --> 00:02:36,780
so the practice on especially if this does go wrong

45
00:02:36,790 --> 00:02:39,090
can really make it go wrong in

46
00:02:39,110 --> 00:02:42,030
preferred manner

47
00:02:42,030 --> 00:02:44,630
there's a lot of interesting compartmentalisation

48
00:02:44,990 --> 00:02:50,340
this place by fertilization the pollen working capital time to work

49
00:02:50,350 --> 00:02:51,890
we would like to ask questions like

50
00:02:51,900 --> 00:02:54,890
if i want people these things you

51
00:02:54,910 --> 00:02:57,070
one my credit card database

52
00:02:57,070 --> 00:02:58,620
and my web server

53
00:02:58,710 --> 00:03:02,110
well i think one of the things that exposed to each other while they are

54
00:03:02,110 --> 00:03:05,820
two different virtual machines when they divided up

55
00:03:05,860 --> 00:03:09,240
how can a separate machine shop

56
00:03:09,240 --> 00:03:13,580
and develop system which is much more secure

57
00:03:13,600 --> 00:03:19,300
there's been real interest in natural strong encryption as opposed to make

58
00:03:19,310 --> 00:03:28,300
crystallographic encryption as anybody with the DVD player all HD players there exist

59
00:03:30,330 --> 00:03:33,100
on the other side a lot of interest to smart cards

60
00:03:33,120 --> 00:03:35,460
no i think every for home users

61
00:03:35,550 --> 00:03:40,160
although this not possible uses a smart card machines like keeping some of your password

62
00:03:40,160 --> 00:03:45,360
safe and stuff

63
00:03:45,380 --> 00:03:47,280
the legal side is also interesting

64
00:03:47,310 --> 00:03:52,410
those that were temporarily outside the u

65
00:03:52,440 --> 00:03:55,920
the european union has made it clear that it wants to do something about the

66
00:03:55,960 --> 00:03:58,150
fact every software licenses

67
00:03:58,200 --> 00:04:03,950
if this kills your grandmother your car blows up it's software not fall

68
00:04:03,970 --> 00:04:08,470
but if the CV scratched will send you new destroys your business your ten new

69
00:04:08,500 --> 00:04:10,570
nuclear facility well

70
00:04:12,720 --> 00:04:18,150
the european union decided this is a bad idea i want to fix it

71
00:04:18,170 --> 00:04:19,580
and therefore

72
00:04:19,590 --> 00:04:23,790
they want to fix it and then we just need encourages people to write software

73
00:04:23,790 --> 00:04:25,090
which were

74
00:04:25,140 --> 00:04:26,420
the idea being that

75
00:04:26,440 --> 00:04:29,610
if some people are able to to sell and ship

76
00:04:29,610 --> 00:04:31,350
john software

77
00:04:31,360 --> 00:04:35,710
without liability they'll never actually be the

78
00:04:35,720 --> 00:04:37,570
that is likely to lead to

79
00:04:37,570 --> 00:04:38,720
three things

80
00:04:38,740 --> 00:04:42,720
one of the standards for designing software

81
00:04:42,750 --> 00:04:46,210
another standard operating software

82
00:04:46,240 --> 00:04:49,850
and so is properly stating software is fit

83
00:04:49,870 --> 00:04:54,030
which is the last one particular will received free software

84
00:04:54,030 --> 00:04:56,320
what would be you can distinguish between

85
00:04:56,340 --> 00:05:00,820
this school had right next i wrote last wednesday you might like this

86
00:05:02,600 --> 00:05:07,570
his five thousand euros what licence for piece of software we wrote last wednesday we

87
00:05:07,570 --> 00:05:14,260
think is incredibly dodgy but we don't get a software with my

88
00:05:14,270 --> 00:05:18,010
so the idea of let's say this software has been written to the problems that

89
00:05:18,110 --> 00:05:20,490
this software is suitable for

90
00:05:20,490 --> 00:05:24,290
the following content is provided under creative commons license

91
00:05:24,320 --> 00:05:30,970
your support will help MIT opencourseware continue to offer high quality educational resources for free

92
00:05:31,000 --> 00:05:35,760
to make a donation or view additional materials from hundreds of MIT courses

93
00:05:35,780 --> 00:05:37,690
this MIT opencourseware

94
00:05:37,690 --> 00:05:39,630
OCW MIT

95
00:05:39,650 --> 00:05:41,760
but you

96
00:05:41,810 --> 00:05:45,830
now this is not a quick clicker questions you actually need to maybe write something

97
00:05:45,830 --> 00:05:49,560
down to figure out the answer is that if you have and i have clicked

98
00:05:49,560 --> 00:05:52,650
any other if you want to change answer keep in mind that you may need

99
00:05:52,650 --> 00:06:20,370
to jot down for example lewis structure before you can answer this question

100
00:06:20,390 --> 00:06:22,510
the and getting your final answer to the question

101
00:06:23,520 --> 00:06:27,330
after the you just walking in now you might not have a chance to get

102
00:06:27,330 --> 00:06:30,710
all of the dark bros the that you need in on this clicker question because

103
00:06:30,710 --> 00:06:34,160
it is based on lewis structure so we will go over

104
00:06:34,180 --> 00:06:37,760
but for those of you that have been here for you thirty seconds or longer

105
00:06:37,760 --> 00:06:41,410
see if you can get the right answer in here are a cell

106
00:06:41,430 --> 00:06:43,630
OK looks like we have

107
00:06:43,690 --> 00:06:48,930
a very mixed response in terms of the answer the other questions today raise your

108
00:06:48,930 --> 00:06:52,830
hand if you didn't have time to figure out the lewis structure

109
00:06:52,850 --> 00:06:55,190
OK so that accounts for some of you

110
00:06:55,210 --> 00:06:58,540
let's go over the correct answer to this question so

111
00:06:58,550 --> 00:07:01,270
we got the right answer thirty one percent of us

112
00:07:01,350 --> 00:07:07,160
this is not the kind of percentages were looking for so let's go over there

113
00:07:07,210 --> 00:07:09,800
on class i and class on monday

114
00:07:09,800 --> 00:07:15,800
we did go over the geometry and the geometry themselves are very straightforward once you

115
00:07:15,800 --> 00:07:19,990
know what the lewis structure is remember you can't just always look at the molecule

116
00:07:19,990 --> 00:07:24,910
and automatically notable structure we actually need to think about those valence electrons so here

117
00:07:24,910 --> 00:07:28,930
we're dealing with william hyde right so as he h two

118
00:07:28,960 --> 00:07:34,460
i told you that there are six valence electrons in so we have the there

119
00:07:34,480 --> 00:07:36,800
plus one for each of the hydrogen

120
00:07:36,810 --> 00:07:41,400
so what we should have a eight valence electrons in our lewis structure

121
00:07:41,420 --> 00:07:44,110
how many electrons we need to have a full

122
00:07:44,240 --> 00:07:46,460
valence shells

123
00:07:46,520 --> 00:07:48,620
twelve that's right we need

124
00:07:48,680 --> 00:07:52,400
eight or it's twelve or full shell

125
00:07:52,530 --> 00:07:56,210
that means that we need twelve excuse me

126
00:07:56,490 --> 00:07:57,990
that means that we need

127
00:07:57,990 --> 00:08:00,180
need twelve minus eight

128
00:08:00,250 --> 00:08:03,890
four four bonding electrons

129
00:08:03,900 --> 00:08:05,270
in our structure

130
00:08:05,280 --> 00:08:08,960
so i try to give you one you can draw pretty quickly just has hydrogens

131
00:08:08,960 --> 00:08:11,580
and so we have as e

132
00:08:11,620 --> 00:08:13,150
h two

133
00:08:13,170 --> 00:08:14,870
we can do our four

134
00:08:14,890 --> 00:08:19,270
bonding electrons how many valence electrons to we have left

135
00:08:19,280 --> 00:08:25,110
four that's right so we need to tell for selenium so one two three four

136
00:08:25,150 --> 00:08:30,020
so this is our lewis structures here hopefully you can see why it's not linear

137
00:08:30,030 --> 00:08:34,020
if it were linear which thirty two percent of you seem to have thought that

138
00:08:34,020 --> 00:08:34,680
would have meant that

139
00:08:36,800 --> 00:08:38,430
i had no pairs

140
00:08:38,450 --> 00:08:43,490
right that that's not the case we have two lone pair so we thought about

141
00:08:43,490 --> 00:08:47,270
what the bonds were everywhere would be one o nine point five

142
00:08:47,330 --> 00:08:51,270
but it's that's because we're only looking at the bonds were not counting the lewis

143
00:08:51,270 --> 00:08:54,900
structures in naming geometry but they do affect the angles

144
00:08:54,960 --> 00:08:58,680
and it turns out that it's actually less than one o nine point five because

145
00:08:58,680 --> 00:09:02,090
those lone pairs are pushing the bond even further away

146
00:09:02,990 --> 00:09:05,870
does this make sense to everyone if you think about it

147
00:09:05,900 --> 00:09:07,930
this way

148
00:09:07,990 --> 00:09:09,360
pretty much OK so

149
00:09:09,370 --> 00:09:13,520
well try i will try another question like this way there are some of the

150
00:09:13,610 --> 00:09:17,610
questions that look very straightforward just naming the geometry have to remember to do the

151
00:09:17,610 --> 00:09:19,680
first step before you jump in

152
00:09:19,680 --> 00:09:23,210
and go ahead with the naming so you'll get plenty of practice with the linear

153
00:09:23,210 --> 00:09:26,030
problems that if you haven't already

154
00:09:26,240 --> 00:09:30,870
right so before we started with today's note i do want to mention that this

155
00:09:30,870 --> 00:09:33,750
morning the nobel prize in chemistry was announced

156
00:09:33,830 --> 00:09:38,500
this is an exciting week in science in general because we get to hear another

157
00:09:38,500 --> 00:09:41,660
nobel prize every morning pretty much

158
00:09:41,720 --> 00:09:44,370
so let

159
00:09:44,430 --> 00:09:47,220
but settled down for a second start listening itself

160
00:09:47,240 --> 00:09:51,430
today we're going to be talking about molecular orbital theory but first i wanted to

161
00:09:51,430 --> 00:09:55,000
just mentioning his some of you didn't here with the nobel prize was

162
00:09:55,070 --> 00:09:59,970
this morning in this way in chemistry one to three different cameras osama

163
00:10:00,010 --> 00:10:06,060
she mu moreau who is the excuse me a lot of that name she mamoru

164
00:10:06,180 --> 00:10:09,010
the japanese camera and then martin b

165
00:10:09,420 --> 00:10:13,310
was at columbia and robert chan was at UC san diego

166
00:10:13,370 --> 00:10:18,030
the three of these chemists with the nobel prize this morning for their discovery

167
00:10:18,420 --> 00:10:22,060
and or other application of using green fluorescent protein

168
00:10:22,090 --> 00:10:26,540
which is also called GFP how many of you have heard of GFP before so

169
00:10:26,540 --> 00:10:30,440
great that many of you have heard of GFP for of that have enough to

170
00:10:30,450 --> 00:10:35,310
say that it is it's the protein two hundred thirty eight amino acid which means

171
00:10:35,310 --> 00:10:35,980
that a

172
00:10:36,030 --> 00:10:40,990
about a thousand actually more than one thousand patterns in size and this protein is

173
00:10:40,990 --> 00:10:47,430
four athens the protein was first discovered in first isolated from this jellyfish here this

174
00:10:47,430 --> 00:10:48,560
was done

175
00:10:48,560 --> 00:10:53,370
nodes so we can really see clearly what's going on and the of zero five

176
00:10:53,370 --> 00:10:55,890
one just as i had before now

177
00:10:55,910 --> 00:10:58,950
g i j of zero one

178
00:10:58,960 --> 00:11:03,000
and g i j one zero somehow all had to sit on the stage so

179
00:11:03,080 --> 00:11:07,360
a bit funny is happening here because i'm only allowed to describe one costa this

180
00:11:07,360 --> 00:11:11,040
ed ge and yet the gene function is the two by two tables

181
00:11:11,080 --> 00:11:14,550
and so the second of four numbers then how can i get all of these

182
00:11:14,550 --> 00:11:18,650
four numbers onto this one edge something doesn't fit here well there are various ways

183
00:11:18,650 --> 00:11:20,150
of dealing with that which are all

184
00:11:20,170 --> 00:11:25,600
equivalent is just a matter of choosing a canonical form if you like so

185
00:11:25,600 --> 00:11:29,720
the canonical form i'm going to go with the moment is that g i j

186
00:11:29,720 --> 00:11:34,000
one zero has the same value of j i j i j zero one that

187
00:11:34,000 --> 00:11:36,590
sits on an undirected edge here

188
00:11:36,630 --> 00:11:40,510
and what about zero zero zero and one one values of g

189
00:11:40,520 --> 00:11:44,660
well there's no way to put those and so happily in the canonical form they

190
00:11:44,660 --> 00:11:46,020
have value zero

191
00:11:47,740 --> 00:11:54,390
i think that's not just sort of skewing this beautiful model by making all these

192
00:11:54,390 --> 00:11:58,560
restrictions on g but it turns out not that this is actually without loss of

193
00:12:04,720 --> 00:12:06,690
next so we we all agree

194
00:12:08,100 --> 00:12:11,470
a particular cut of this graph is the particular assignment of ones and zeros the

195
00:12:11,470 --> 00:12:15,130
x's and also immediately gives you a particular

196
00:12:15,150 --> 00:12:18,840
energy any problems with that because this is rather important yes

197
00:12:23,890 --> 00:12:25,350
sorry what any gene

198
00:12:25,370 --> 00:12:27,520
five to find

199
00:12:27,530 --> 00:12:30,950
well she

200
00:12:30,970 --> 00:12:32,620
reverend wright

201
00:12:34,510 --> 00:12:39,380
well actually f is the log likelihood for assigning a single pixel

202
00:12:39,400 --> 00:12:41,510
to foreground background

203
00:12:41,510 --> 00:12:44,650
without considering any of the other pixels just you know you look at the properties

204
00:12:44,650 --> 00:12:49,350
of that pixel harris colours they fit you know evaluate them under the colour model

205
00:12:49,460 --> 00:12:54,220
foreground the probabilistic you know the gas mixture models are going to use evaluate them

206
00:12:54,220 --> 00:12:58,350
under the and the foreground model about the background model the negative log of those

207
00:12:58,940 --> 00:13:02,880
those two probabilities of what goes on go on the f

208
00:13:03,600 --> 00:13:07,360
the GRR can that was the one that came from the ising model

209
00:13:07,370 --> 00:13:08,900
so remember g

210
00:13:08,920 --> 00:13:11,950
that was the thing where you get a penalty gamma

211
00:13:11,970 --> 00:13:18,530
if if two adjacent pixels have different assignment one is one one zero and actually

212
00:13:18,530 --> 00:13:19,630
in our model

213
00:13:19,640 --> 00:13:20,750
you will recall

214
00:13:20,760 --> 00:13:24,100
we gave the same penalty gamma whether it was one zero or zero one that's

215
00:13:24,100 --> 00:13:26,850
good because that was one of the things i want to assume in this canonical

216
00:13:26,850 --> 00:13:29,930
form that's the problem and when

217
00:13:29,950 --> 00:13:33,270
the two adjacent pixels have the same value that's g one one let's say or

218
00:13:33,540 --> 00:13:37,280
zero zero also we were giving zero penalty also have actually that's good that was

219
00:13:37,280 --> 00:13:41,920
also fitting within the canonical model but with the current canonical form but as i

220
00:13:41,920 --> 00:13:45,800
say actually the canonical form is not it there is no restriction

221
00:13:45,800 --> 00:13:49,750
is work is clear so carry on

222
00:13:50,580 --> 00:13:53,350
so that you also

223
00:13:56,610 --> 00:13:59,910
so one where there is also

224
00:13:59,930 --> 00:14:06,390
yes so just just to recap that there is a probabilistic model for colour in

225
00:14:06,390 --> 00:14:07,400
the foreground

226
00:14:07,510 --> 00:14:13,050
a probabilistic model for colour in the background you take a particular hypothesis like this

227
00:14:13,050 --> 00:14:18,130
pixel is in the foreground and you evaluate the probability of that color under the

228
00:14:18,130 --> 00:14:19,840
foreground colour models

229
00:14:20,140 --> 00:14:25,510
so it's the probability distribution you simply evaluate that problem distribution for that particular color

230
00:14:25,510 --> 00:14:30,120
now the negative log of that is what defines if i have one want

231
00:14:30,150 --> 00:14:36,170
one reason why you want this and what you

232
00:14:36,190 --> 00:14:38,780
growth wastrels

233
00:14:39,420 --> 00:14:42,930
the reason i'm not sure if it's right to call the loss function it's it's

234
00:14:42,930 --> 00:14:46,470
like is the negative log likelihood

235
00:14:46,520 --> 00:14:50,300
this is not this is not something like that is not something i plucked out

236
00:14:50,300 --> 00:14:53,630
of the you know the cost function is in some sense subjective thing you know

237
00:14:53,970 --> 00:14:57,400
already sort of outside the problem you say OK here's what i care about you

238
00:14:57,400 --> 00:15:02,370
know here's my probability distribution over over hidden states here's what is going to cost

239
00:15:02,370 --> 00:15:06,140
sure enough it's a straight line

240
00:15:07,070 --> 00:15:10,510
right three

241
00:15:10,530 --> 00:15:11,390
that's right

242
00:15:14,030 --> 00:15:15,470
that's true

243
00:15:15,530 --> 00:15:17,910
when you when i moved my little bit

244
00:15:17,930 --> 00:15:20,800
the difference has to be greater equals zero

245
00:15:20,800 --> 00:15:25,850
but then what's next crucial step that when i look at the linear eyes

246
00:15:25,860 --> 00:15:30,160
are part of the just multiply v alone

247
00:15:30,180 --> 00:15:32,170
that has to be zero

248
00:15:32,220 --> 00:15:33,560
and that's the

249
00:15:33,560 --> 00:15:35,030
the tricky point

250
00:15:35,570 --> 00:15:37,170
that's the tricky point that

251
00:15:37,200 --> 00:15:40,820
the higher order stuff

252
00:15:40,830 --> 00:15:43,330
can be forgotten because

253
00:15:43,380 --> 00:15:47,210
because of because i look at very small v

254
00:15:50,610 --> 00:15:52,170
so i'm just

255
00:15:52,400 --> 00:15:56,660
describing the whole characters are very sincere in this tiny corner of the board the

256
00:15:56,660 --> 00:15:58,620
main point is that it's

257
00:15:58,620 --> 00:16:02,470
the general case of which this is the best example

258
00:16:05,050 --> 00:16:08,850
are we ready for finite elements

259
00:16:10,550 --> 00:16:13,530
and i work with the same example

260
00:16:13,580 --> 00:16:18,320
so what's the finite element method

261
00:16:18,370 --> 00:16:20,640
the finite element method

262
00:16:20,690 --> 00:16:23,890
makes its problems

263
00:16:23,890 --> 00:16:26,700
finite dimensional

264
00:16:26,730 --> 00:16:28,330
why not

265
00:16:28,380 --> 00:16:31,630
allowing every function u

266
00:16:31,740 --> 00:16:33,000
and every

267
00:16:33,060 --> 00:16:35,290
move move on to the

268
00:16:35,300 --> 00:16:37,870
but only

269
00:16:37,880 --> 00:16:40,200
a finite family of u

270
00:16:40,220 --> 00:16:41,290
and the

271
00:16:41,290 --> 00:16:43,660
so that's the that's the key idea

272
00:16:43,790 --> 00:16:46,050
finite elements and

273
00:16:46,090 --> 00:16:49,810
and that's the big decision is all what

274
00:16:52,010 --> 00:17:02,210
so now i'm ready for finite elements

275
00:17:02,390 --> 00:17:04,560
here come finite element

276
00:17:04,600 --> 00:17:08,350
or the galerkin method in general galerkin

277
00:17:10,600 --> 00:17:15,280
we want to get a finite problem

278
00:17:15,320 --> 00:17:18,690
and how do i do it

279
00:17:18,710 --> 00:17:23,000
i only allow

280
00:17:23,010 --> 00:17:25,600
these use which are

281
00:17:25,600 --> 00:17:27,970
combinations of

282
00:17:27,990 --> 00:17:30,450
with unknown coefficients

283
00:17:31,930 --> 00:17:36,140
basis functions

284
00:17:36,210 --> 00:17:40,560
and of

285
00:17:40,560 --> 00:17:42,340
so i only

286
00:17:42,350 --> 00:17:47,780
i only minimize you see i'm uncertain down to the finite dimensional space

287
00:17:47,830 --> 00:17:51,870
instead of minimizing over every u

288
00:17:51,880 --> 00:17:56,680
which led me to this differential equation for the absolute winner

289
00:17:56,730 --> 00:17:58,880
i'm not going to take

290
00:17:58,920 --> 00:18:01,550
subspace winner

291
00:18:01,550 --> 00:18:03,680
a limited winner

292
00:18:03,710 --> 00:18:06,980
by choosing just a few functions

293
00:18:06,990 --> 00:18:09,440
or maybe a hundred function

294
00:18:09,450 --> 00:18:11,640
but not all function

295
00:18:11,690 --> 00:18:15,900
and i will only allow those winners so now

296
00:18:15,900 --> 00:18:20,120
these are chosen

297
00:18:20,130 --> 00:18:23,960
we hope chosen we hope well

298
00:18:24,030 --> 00:18:25,610
that's the big

299
00:18:25,670 --> 00:18:26,740
big decision

300
00:18:26,760 --> 00:18:29,340
it's so much of applied masses

301
00:18:30,560 --> 00:18:37,230
what are the good trial functions these are the trial

302
00:18:37,260 --> 00:18:41,200
because those are the ones we're going to try

303
00:18:41,210 --> 00:18:43,330
and other functions

304
00:18:43,340 --> 00:18:44,480
if there

305
00:18:44,500 --> 00:18:46,690
if the absolute winner has

306
00:18:46,740 --> 00:18:49,600
they could be like

307
00:18:49,640 --> 00:18:54,280
sin x sin two x sin three accept sign

308
00:18:54,280 --> 00:18:55,640
one hundred

309
00:18:55,640 --> 00:18:59,830
of what this heuristic idea was just trying to find a decision boundary and then

310
00:18:59,850 --> 00:19:05,350
collecting samples near the perceived decision boundary and this is what actually happens in the

311
00:19:06,640 --> 00:19:08,950
what i'm doing here is the

312
00:19:09,140 --> 00:19:15,860
applying the number of viable hypotheses the size of the version space versus the number

313
00:19:15,860 --> 00:19:20,500
of sensors that you query so when you start off you have about ten thousand

314
00:19:20,520 --> 00:19:28,890
possible hypotheses of ten thousand different separations of these one hundred sensors after

315
00:19:28,910 --> 00:19:31,810
one query you eliminate half of them

316
00:19:31,830 --> 00:19:35,580
after two queries you've eliminated about seventy five percent and so on and so forth

317
00:19:35,740 --> 00:19:40,160
really are limiting roughly half of all of the hypotheses at each step and if

318
00:19:40,160 --> 00:19:44,250
you plot this on large scale you see on a linear decrease which is this

319
00:19:44,250 --> 00:19:49,720
or geometric reduction in the size of the version space you select these

320
00:19:49,790 --> 00:19:51,870
sensors for query

321
00:19:53,770 --> 00:19:58,180
now say more about that kind of idea this afternoon so active learning for regression

322
00:19:58,180 --> 00:20:02,470
so classification is just one way that you can use active learning in regression suppose

323
00:20:02,470 --> 00:20:04,910
we're trying to estimate a function

324
00:20:05,600 --> 00:20:07,790
what i'm showing here

325
00:20:07,790 --> 00:20:13,910
and if we're going to take samples what you might think is that you might

326
00:20:13,910 --> 00:20:16,410
want take more samples in

327
00:20:17,560 --> 00:20:19,100
where you're

328
00:20:19,980 --> 00:20:21,370
the target function is

329
00:20:22,180 --> 00:20:27,180
more difficult to predict the was wiggling faster changing more rapidly so in this case

330
00:20:27,180 --> 00:20:33,160
is actual jumper edge in that signal you focus your sampling in some adaptive way

331
00:20:33,160 --> 00:20:36,770
to try to localize where those discontinuity is happening

332
00:20:36,830 --> 00:20:39,390
and so that's

333
00:20:39,390 --> 00:20:43,620
the idea here is that image processing example reveals a little bit more about this

334
00:20:43,620 --> 00:20:46,160
later but if we are just going to

335
00:20:46,980 --> 00:20:48,950
satellite image like this

336
00:20:48,950 --> 00:20:54,140
it's a scan number of points uniformly at random we might be able to get

337
00:20:54,140 --> 00:20:57,540
a reconstruction light so at the bottom there

338
00:20:57,540 --> 00:21:00,890
if we use the same number of samples but allow ourselves to do kind of

339
00:21:00,890 --> 00:21:05,450
two-step process where the first step we can take a bunch of random samples uniformly

340
00:21:05,590 --> 00:21:07,830
and the second step we identify

341
00:21:07,850 --> 00:21:13,870
interesting locations and then sample more densely in those regions we can get a much

342
00:21:13,870 --> 00:21:16,220
higher resolution

343
00:21:16,250 --> 00:21:19,770
version of that image was better better localisation of

344
00:21:19,790 --> 00:21:24,220
the boundaries of this lake and so forth and so the idea again is to

345
00:21:24,220 --> 00:21:26,370
try to adaptively focus

346
00:21:26,410 --> 00:21:30,970
on regions of the target function that are most interesting where there's the most difficult

347
00:21:31,000 --> 00:21:33,310
in predicting the value

348
00:21:33,310 --> 00:21:37,410
and you can also do it for fun are so this is the guess who

349
00:21:37,410 --> 00:21:43,240
game i play this with my son and the idea is you just keep guessing

350
00:21:43,250 --> 00:21:49,100
what your opponents player looks like this have had does it have blue eyes and

351
00:21:49,100 --> 00:21:53,470
and so on and so forth and you saw earlier chipping away at the hypothesis

352
00:21:53,470 --> 00:21:54,640
space just like

353
00:21:54,700 --> 00:22:01,290
in this scale are GBS type of algorithm and the difficulty of and the difficulty

354
00:22:01,290 --> 00:22:03,140
playing with my son is that he

355
00:22:03,140 --> 00:22:04,790
he likes to win

356
00:22:04,810 --> 00:22:07,220
and you can be a bit unreliable so

357
00:22:07,220 --> 00:22:11,370
he'll tell you that the person has blue eyes when in fact they are brown

358
00:22:11,370 --> 00:22:15,680
and things like that so i one one interesting challenges and active learning is how

359
00:22:15,680 --> 00:22:19,850
do you deal with unreliable responses to your queries and so forth and this is

360
00:22:19,850 --> 00:22:22,720
just another example of noise

361
00:22:22,750 --> 00:22:24,270
OK so

362
00:22:25,410 --> 00:22:30,930
so the the service framework and that we're looking at is we have some feature

363
00:22:30,970 --> 00:22:33,540
or query space called ax

364
00:22:33,660 --> 00:22:40,740
could be for example the unit cube in d dimensions or are key euclidean d

365
00:22:40,740 --> 00:22:46,580
dimensional space who have some output space label space zero one plus one minus one

366
00:22:46,580 --> 00:22:52,680
in the case of binary classification could just be the real line in regression problems

367
00:22:52,740 --> 00:22:56,450
and we're going to use collect features and labels

368
00:22:56,470 --> 00:22:57,740
there are going to be

369
00:22:57,750 --> 00:22:59,450
they typically

370
00:22:59,450 --> 00:23:02,750
coming from some unknown distribution px y

371
00:23:02,770 --> 00:23:05,740
and the goal construct predictive and which

372
00:23:05,750 --> 00:23:08,020
is a mapping from the

373
00:23:08,060 --> 00:23:13,640
feature to label space input output space that minimizes sum x some expected loss of

374
00:23:13,640 --> 00:23:16,870
the last is a function which measures

375
00:23:16,890 --> 00:23:20,660
how well your prediction is relative to the correct label

376
00:23:20,680 --> 00:23:22,040
and then your

377
00:23:22,040 --> 00:23:27,310
typically something that's nonnegative and takes a larger positive value the more disagreement there is

378
00:23:27,310 --> 00:23:30,470
between your prediction in the true label then you're looking at the average of that

379
00:23:30,540 --> 00:23:32,250
loss that's called the

380
00:23:32,270 --> 00:23:35,120
expected loss or risk

381
00:23:35,120 --> 00:23:37,470
of your and this should be

382
00:23:37,470 --> 00:23:38,600
this is a type of

383
00:23:38,620 --> 00:23:40,370
there should be a chair

384
00:23:40,540 --> 00:23:45,270
have here something you can try to minimize

385
00:23:45,330 --> 00:23:51,600
so the optimal prediction rule ph star which would be the hypothesis for predictor in

386
00:23:51,600 --> 00:23:52,580
you're set

387
00:23:52,580 --> 00:23:59,910
h that minimizes the expected loss unfortunately this would generally depend on px y which

388
00:23:59,910 --> 00:24:03,960
you don't know the joint distribution of x and y and so the idea and

389
00:24:04,800 --> 00:24:10,350
course to take some training sample which gives you a glimpse at this unknown distribution

390
00:24:10,870 --> 00:24:13,370
and then use the training sample two

391
00:24:13,390 --> 00:24:14,850
learner produced

392
00:24:14,870 --> 00:24:20,060
a classification rule or a predictor h at

393
00:24:21,250 --> 00:24:22,520
one of the

394
00:24:22,540 --> 00:24:23,890
things it's

395
00:24:23,890 --> 00:24:27,890
you received a lot of attention over recent years is the fact that we have

396
00:24:27,890 --> 00:24:31,200
a lot of unlabelled data in in many cases and labels can be very expensive

397
00:24:31,200 --> 00:24:32,810
and there are two

398
00:24:32,830 --> 00:24:37,080
approaches that are popular one is semi supervised learning

399
00:24:37,100 --> 00:24:42,450
so in semi supervised learning the idea is that we have a large pool of

400
00:24:42,450 --> 00:24:47,120
unlabeled examples of unlabelled examples and then usually

401
00:24:47,140 --> 00:24:50,600
a much smaller pool of of labelled examples

402
00:24:50,640 --> 00:24:52,500
and so there will be

403
00:24:52,950 --> 00:24:57,350
ten million examples that are unlabelled and maybe a thousand that are labelled in the

404
00:24:57,370 --> 00:25:02,350
like to somehow combine both the labeled and unlabeled data to help you design a

405
00:25:02,350 --> 00:25:06,540
better predictor hypothesis and

406
00:25:06,600 --> 00:25:12,540
the basis for this is that there's usually either explicit or implicit assumption that somehow

407
00:25:13,330 --> 00:25:19,910
conditional distribution of the label given the feature or labeling distribution is linked in some

408
00:25:20,700 --> 00:25:21,770
to the

409
00:25:21,790 --> 00:25:27,330
the marginal distribution of x itself so one example andronicus we're not trying to maximize

410
00:25:27,330 --> 00:25:28,430
learning too much

411
00:25:28,450 --> 00:25:31,830
published talked about yesterday or other times but you know if you have

412
00:25:31,870 --> 00:25:37,560
clusters and each cluster the labeling is this kind of homogeneous of one cluster maybe

413
00:25:37,560 --> 00:25:42,060
labour plus one another label minus one if you can learn that cluster structure was

414
00:25:42,060 --> 00:25:45,400
before we begin i just want to make sure you guys all remember about the

415
00:25:45,400 --> 00:25:48,680
quiz on friday so

416
00:25:48,720 --> 00:25:50,730
the quiz is going to be in walker

417
00:25:50,740 --> 00:25:52,870
two PM everybody goes to walker

418
00:25:52,920 --> 00:25:54,880
the quiz open book

419
00:25:55,150 --> 00:25:59,830
you can bring your own notes bring class notes bring greetings from class

420
00:25:59,850 --> 00:26:05,170
you can bring a calculator please don't bring any computers phones PDA is things like

421
00:26:05,170 --> 00:26:10,260
that make sure you have all your stuff redoubt before a show you taking notes

422
00:26:13,950 --> 00:26:18,090
we're going to do today is just quickly what we're going to do an introduction

423
00:26:18,090 --> 00:26:21,880
to networking but quickly i just want to finish the topic of caching

424
00:26:21,930 --> 00:26:25,140
that we began last that i sort of introduced at the very end of the

425
00:26:25,140 --> 00:26:26,450
lecture last time

426
00:26:28,740 --> 00:26:30,140
if you guys remember

427
00:26:30,170 --> 00:26:34,230
we were talking about our our pipeline web server system

428
00:26:34,240 --> 00:26:39,360
they consisted of these three stages

429
00:26:39,450 --> 00:26:44,610
networking stage

430
00:26:44,660 --> 00:26:49,410
connected up to your HTML stage

431
00:26:49,410 --> 00:26:51,420
connected up are

432
00:26:51,440 --> 00:26:52,920
this stage

433
00:26:55,470 --> 00:26:59,890
and we talked about the performance we did a little performance analysis the system we

434
00:26:59,890 --> 00:27:02,880
look at what the cost of each of these stages in terms of what the

435
00:27:02,890 --> 00:27:05,380
sort of throughput in each one of these stages is

436
00:27:05,440 --> 00:27:09,160
we said that as long as if we split this networking module up into ten

437
00:27:09,160 --> 00:27:14,160
submodules we can get the throughput of this thing to be about a hundred

438
00:27:14,330 --> 00:27:16,250
o requests per second

439
00:27:16,330 --> 00:27:21,350
we said the delay of this guy was one that latency this one millisecond semin

440
00:27:21,470 --> 00:27:22,580
can process

441
00:27:22,690 --> 00:27:25,880
thousand requests per second with a latency of the disc

442
00:27:25,890 --> 00:27:31,240
was ten milliseconds so that means it can also process hundred requests per second

443
00:27:31,250 --> 00:27:34,140
and we said remember that when we're looking at a pipeline

444
00:27:34,360 --> 00:27:37,470
these are the throughput of the entire pipeline is going to be bottleneck by the

445
00:27:37,470 --> 00:27:39,530
slowest agent system

446
00:27:39,580 --> 00:27:43,860
and so if we look at this we see these two stages are both are

447
00:27:43,860 --> 00:27:47,370
both running at one hundred hundred requests per second

448
00:27:49,420 --> 00:27:53,120
we have a very simple way of making this first network stage

449
00:27:53,300 --> 00:27:57,710
be able to process more requests per second because we simply can replicate the number

450
00:27:58,520 --> 00:28:02,480
networking sort of the number of threads that are sending data out over the network

451
00:28:02,480 --> 00:28:07,830
so for example if we went from ten nodes here two hundred nodes we could

452
00:28:07,990 --> 00:28:12,240
up increase the throughput of this stage two thousand requests per second

453
00:28:12,240 --> 00:28:16,020
which means that now the bottleneck states that we have is simply the this stage

454
00:28:16,020 --> 00:28:19,820
so the question is is there something we can do to increase the throughput of

455
00:28:19,830 --> 00:28:20,860
the disc stage

456
00:28:20,950 --> 00:28:24,240
and you think about at first it may seem like well there's probably no way

457
00:28:24,240 --> 00:28:28,450
that we can do anything because the disc politics ten milliseconds to you know every

458
00:28:28,450 --> 00:28:32,340
page text and the second street and so what we do about that

459
00:28:32,360 --> 00:28:35,960
and there's a very sort of standard answer to that that you guys have all

460
00:28:35,960 --> 00:28:41,390
seen before that answers caching

461
00:28:41,400 --> 00:28:43,710
so the simple idea is

462
00:28:45,800 --> 00:28:49,620
we're going to take this i o state this stage with its disc runs of

463
00:28:49,620 --> 00:28:54,170
ten milliseconds and what i've shown here is a very simple piece of pseudocode might

464
00:28:54,170 --> 00:28:55,730
correspond to what this

465
00:28:55,820 --> 00:28:59,790
sort of the reader they get page i function for this is that for this

466
00:28:59,790 --> 00:29:01,180
i o stage does

467
00:29:01,330 --> 00:29:04,990
it's simply called summary function that reads page idea of the disk and then returns

468
00:29:05,040 --> 00:29:06,080
the page

469
00:29:06,890 --> 00:29:10,150
if we have a cash to this system suppose we have an in memory cache

470
00:29:10,150 --> 00:29:13,860
they can retrieve that page in point one millisecond

471
00:29:14,420 --> 00:29:17,740
in that case the way that we can use that cash just before every time

472
00:29:17,740 --> 00:29:20,550
we go to the disk we can check and see if the page we're trying

473
00:29:20,550 --> 00:29:21,860
to load is in the cache

474
00:29:21,920 --> 00:29:24,010
and then only if it's not in the cache

475
00:29:24,020 --> 00:29:27,210
we need to actually go to the desks and we get masonic actually go check

476
00:29:27,230 --> 00:29:29,550
the desk and see if the page is available

477
00:29:29,550 --> 00:29:32,020
we can extend the code in a very simple way

478
00:29:32,050 --> 00:29:34,400
to take advantage of this we simply say

479
00:29:34,870 --> 00:29:37,830
we look up and the cash first and then if the page is no empty

480
00:29:37,830 --> 00:29:41,550
or whatever we can find it in the cache then we go ahead and look

481
00:29:41,550 --> 00:29:43,050
it up on the disk

482
00:29:43,080 --> 00:29:45,240
and then we have the result of the cash

483
00:29:45,340 --> 00:29:49,580
so there's a couple of little details that we need to work through but let's

484
00:29:49,580 --> 00:29:53,050
first look at what the performance of the system is going to be or how

485
00:29:53,050 --> 00:29:55,830
this is going to impact the performance of what we're doing

486
00:29:58,890 --> 00:30:01,890
if we come over here

487
00:30:01,950 --> 00:30:06,750
we think about what the cost of accessing the page and the system would be

488
00:30:06,790 --> 00:30:09,010
well the cost is going to be we're always going to have to check the

489
00:30:09,010 --> 00:30:13,220
cash right that's the first thing we do so it's right c

490
00:30:13,230 --> 00:30:15,870
the cost of accessing the cache

491
00:30:15,880 --> 00:30:19,040
where cost is in this case can be expressed in something like the number of

492
00:30:19,040 --> 00:30:21,210
milliseconds to do up in the cash

493
00:30:21,270 --> 00:30:22,710
and then class

494
00:30:22,710 --> 00:30:25,630
the cost of looking up in the disk but we only have to look up

495
00:30:25,630 --> 00:30:29,390
on the disk some of the time it so there is some probability

496
00:30:29,430 --> 00:30:31,250
of getting this

497
00:30:31,400 --> 00:30:35,100
times the cost

498
00:30:35,210 --> 00:30:38,280
that in this

499
00:30:38,280 --> 00:30:43,630
from all this is the same as the red one so maybe we should classify

500
00:30:43,630 --> 00:30:45,380
this is

501
00:30:45,400 --> 00:30:47,900
so with this knowledge

502
00:30:47,940 --> 00:30:49,410
and finally

503
00:30:49,470 --> 00:30:50,200
you know

504
00:30:50,210 --> 00:30:54,500
i have something like this i don't actually have to know the underlying

505
00:30:54,510 --> 00:30:58,510
i just need to know some points on the contract set

506
00:30:58,550 --> 00:31:02,740
so the graph to the graph can be something about the geometry of the

507
00:31:09,110 --> 00:31:14,390
so you can use unlabelled little geometry tells us something about this the classification or

508
00:31:14,390 --> 00:31:19,290
regression and unlabelled data can be used to estimate geometry

509
00:31:19,290 --> 00:31:20,410
so that

510
00:31:20,470 --> 00:31:25,940
so he here is the sound of his to example that allow

511
00:31:25,950 --> 00:31:29,050
this is was of course a sphere

512
00:31:30,290 --> 00:31:31,490
you have

513
00:31:32,760 --> 00:31:35,630
you know the SVM was just like this

514
00:31:35,640 --> 00:31:39,240
it would be good morning this point but if you

515
00:31:39,250 --> 00:31:40,280
you know

516
00:31:40,390 --> 00:31:43,510
you know if you have some parameter which can take

517
00:31:43,530 --> 00:31:46,930
can become level they can

518
00:31:46,940 --> 00:31:48,240
you can do that

519
00:31:48,250 --> 00:31:51,990
o but again i mean of course we don't know if this is one class

520
00:31:52,000 --> 00:31:54,270
and this is not the concepts our village

521
00:31:58,140 --> 00:31:59,780
so now

522
00:31:59,910 --> 00:32:04,410
i will talk about some sort of

523
00:32:06,020 --> 00:32:08,420
formal notion of what

524
00:32:09,280 --> 00:32:11,580
the formalism

525
00:32:11,630 --> 00:32:16,110
more formally a more formal version of the manifold assumption can be put in the

526
00:32:16,120 --> 00:32:23,290
following way for functions of interest which i classification regression function so this is not

527
00:32:23,290 --> 00:32:25,820
very well on the data

528
00:32:25,830 --> 00:32:31,440
so that's sort of small with respect to the underlying probability distribution

529
00:32:37,150 --> 00:32:40,430
you we have for example for classification with

530
00:32:40,450 --> 00:32:46,290
it's conditional probability right probability of being relevant given point x

531
00:32:46,440 --> 00:32:48,380
this is a quantity

532
00:32:48,420 --> 00:32:53,440
right foot point which the probability that this point is right and this was actually

533
00:32:53,440 --> 00:32:55,940
where small along

534
00:32:57,820 --> 00:33:00,270
well on probabilities

535
00:33:00,280 --> 00:33:06,680
know how to formalize notion well so suppose we have a function

536
00:33:06,690 --> 00:33:09,170
and i want to say that the function of small

537
00:33:09,190 --> 00:33:14,690
what does mean well means well can mean several things but one of very natural

538
00:33:14,690 --> 00:33:18,430
thing it's very very little

539
00:33:18,490 --> 00:33:20,000
around this point

540
00:33:20,080 --> 00:33:25,240
so when i integrate all around that basically this value should be close to zero

541
00:33:26,270 --> 00:33:29,150
so the formalisation of

542
00:33:29,170 --> 00:33:32,690
so in the growth in a all

543
00:33:32,700 --> 00:33:38,380
well think this is small one thousand very much

544
00:33:38,390 --> 00:33:40,300
this quantity should be small

545
00:33:40,310 --> 00:33:44,170
and this quantity just a gradient of a function of the maps

546
00:33:44,180 --> 00:33:49,920
and well sort of the corporation of function is something like the integral of the

547
00:33:49,920 --> 00:33:56,290
gradient it's right a gradient point is how much the function this point and the

548
00:33:56,300 --> 00:33:59,490
first of all racial if

549
00:33:59,540 --> 00:34:04,190
in the middle of the graph and maybe you take this the probability of which

550
00:34:04,200 --> 00:34:04,780
it's a

551
00:34:07,400 --> 00:34:11,660
OK well it turns out that when you actually great

552
00:34:11,680 --> 00:34:14,020
gradient it's the same

553
00:34:14,030 --> 00:34:16,040
the cluster

554
00:34:16,060 --> 00:34:20,360
so laplace operator so this by this by the way mean two

555
00:34:20,360 --> 00:34:23,060
integral to its integral

556
00:34:25,170 --> 00:34:33,050
so as to the approach so this is the first when of class separate comes

557
00:34:33,050 --> 00:34:36,020
in local also operates basically tells you

558
00:34:36,020 --> 00:34:37,910
that catechism

559
00:34:37,910 --> 00:34:42,210
or because systematic theology center manual of religion

560
00:34:42,270 --> 00:34:44,950
despite the fact that a much later time

561
00:34:45,000 --> 00:34:50,730
very complex systems of theology are going to be spun from particular interpretations of biblical

562
00:34:51,760 --> 00:34:53,970
and there's nothing in the bible that really

563
00:34:54,030 --> 00:35:00,050
corresponds to prevailing modern western notions of religion what we call religion and indeed there's

564
00:35:00,050 --> 00:35:05,780
no word for religion in the language of biblical hebrew this just doesn't work religion

565
00:35:05,820 --> 00:35:08,390
with the rise of christianity

566
00:35:08,400 --> 00:35:14,050
western religion came to be defined to a large degree by the confession over the

567
00:35:14,050 --> 00:35:16,920
intellectual assent to

568
00:35:16,970 --> 00:35:23,000
certain doctrinal points of belief religion became defined primarily as a set of beliefs the

569
00:35:23,000 --> 00:35:27,820
catechism of beliefs or truth required your assent what i think of the catechism kind

570
00:35:27,820 --> 00:35:33,170
of notion of religion that's entirely alien to the world of the bible

571
00:35:33,210 --> 00:35:37,970
it's clear that in biblical times and in the ancient near east generally religion was

572
00:35:38,140 --> 00:35:41,180
a set of doctrines that you ascribe to

573
00:35:42,350 --> 00:35:44,370
to become an israelite

574
00:35:44,450 --> 00:35:48,520
later on june the word jew doesn't isn't something we can really historically use until

575
00:35:48,520 --> 00:35:49,560
about this time

576
00:35:49,630 --> 00:35:52,650
so most of our period we're going to be talking about the ancient israelites to

577
00:35:52,650 --> 00:35:54,150
become an israelite

578
00:35:54,200 --> 00:35:58,870
you simply joined the israelite community you lived in israelite life died in his real

579
00:35:58,870 --> 00:36:04,440
identity will be it's right law and custom you revered israelite lore lore

580
00:36:04,490 --> 00:36:09,550
you enter into the historical community of israel by accepting their fate yours should be

581
00:36:09,550 --> 00:36:14,200
the same sort of the process of naturalization what we think of today as naturalization

582
00:36:14,250 --> 00:36:17,740
so he bible just isn't a theological textbook

583
00:36:17,780 --> 00:36:21,570
it contains a lot of narratives and its narrative materials or an account of the

584
00:36:21,570 --> 00:36:23,350
odyssey of the people

585
00:36:23,390 --> 00:36:24,730
the nation of israel

586
00:36:24,750 --> 00:36:28,250
they're not an account of the of the divine which is what theology

587
00:36:28,270 --> 00:36:30,830
i mean account of the divine

588
00:36:30,840 --> 00:36:33,080
however having said this

589
00:36:33,090 --> 00:36:37,720
i should add that although the bible doesn't contain formal statements of religious belief for

590
00:36:37,720 --> 00:36:39,410
systematic theology

591
00:36:39,430 --> 00:36:43,670
it true issues many moral issues and from existential issues

592
00:36:43,750 --> 00:36:47,490
that are central to the later discipline of theology

593
00:36:47,500 --> 00:36:51,610
but it treats them very differently in its treatment of these issues is in direct

594
00:36:51,610 --> 00:36:56,880
its implicit it uses the language of story and song and poetry and paradox and

595
00:36:56,880 --> 00:37:01,720
metaphore it uses the language and style that's very far from the language and style

596
00:37:01,720 --> 00:37:06,870
of of later philosophy and abstract theology

597
00:37:09,750 --> 00:37:11,510
on our miss count

598
00:37:11,530 --> 00:37:13,240
i would point out

599
00:37:13,260 --> 00:37:16,380
well don't really need to cross is that this is something to discuss i would

600
00:37:16,380 --> 00:37:19,640
point out that the bible was formulated

601
00:37:19,650 --> 00:37:22,690
and assembled and edited modified

602
00:37:22,720 --> 00:37:23,810
and sensors

603
00:37:23,810 --> 00:37:25,450
and transmitted

604
00:37:25,470 --> 00:37:27,670
the first orally and in writing

605
00:37:27,710 --> 00:37:30,980
by human beings

606
00:37:31,000 --> 00:37:34,580
the bible itself doesn't claim to have been written by god

607
00:37:34,610 --> 00:37:38,550
that belief is the religious doctrine of a much later age and even then one

608
00:37:38,550 --> 00:37:42,060
wonders how literally it was met interesting to go back and look at

609
00:37:42,070 --> 00:37:47,030
some of the earliest claims about the origin of the biblical text similarly the so-called

610
00:37:47,030 --> 00:37:51,930
five books of moses genesis exodus leviticus numbers deuteronomy the first five books we call

611
00:37:51,940 --> 00:37:54,010
the pentateuch of moses

612
00:37:54,030 --> 00:37:58,400
nowhere claimed to have been written in their entirety by moses that's not something they

613
00:37:58,400 --> 00:37:59,860
say themselves

614
00:37:59,860 --> 00:38:03,210
some laws enacted this the the book of the covenant if you think the says

615
00:38:03,210 --> 00:38:08,930
moses wrote those down but not the whole five books that traditions later will ascribe

616
00:38:09,140 --> 00:38:14,370
to him the bible clearly had many contributors over many centuries

617
00:38:14,420 --> 00:38:20,680
and the individual styles and concerns of those writers their political and religious motivations betray

618
00:38:23,680 --> 00:38:27,240
i leave aside here the question of divine inspiration

619
00:38:27,260 --> 00:38:32,500
which is an article in many biblical religions it's no doubt an article of faith

620
00:38:32,500 --> 00:38:35,510
for people in this very room

621
00:38:35,520 --> 00:38:36,550
but there is no

622
00:38:36,570 --> 00:38:38,390
basic incompatibility

623
00:38:38,400 --> 00:38:40,670
between believing on face

624
00:38:40,690 --> 00:38:43,010
in the divine inspiration of the bible

625
00:38:43,090 --> 00:38:47,800
and acknowledging the role that human beings have played in the actual formulation and editing

626
00:38:47,800 --> 00:38:53,110
and transmission and preservation of that thing bible and since this is a university course

627
00:38:53,160 --> 00:38:57,560
and not perhaps a theological course within the theological setting

628
00:38:57,560 --> 00:39:05,080
it's really only the latter the demonstrably human components that will concern

629
00:39:05,090 --> 00:39:06,590
it's very easy for me

630
00:39:06,610 --> 00:39:08,420
to assert

631
00:39:08,440 --> 00:39:11,950
that our interest in the hebrew bible will be

632
00:39:11,990 --> 00:39:16,280
centered on the culture and history in the literature and the religious thought of ancient

633
00:39:16,280 --> 00:39:18,760
israel in all its diversity

634
00:39:18,770 --> 00:39:22,400
rather than quite questions of faith and theology

635
00:39:22,440 --> 00:39:25,710
but the fact remains that the document is the basis for the religious faith of

636
00:39:25,710 --> 00:39:29,720
many millions of people and some of them are here now

637
00:39:29,760 --> 00:39:31,210
it is inevitable

638
00:39:31,230 --> 00:39:35,210
that you will bring what you learn in this course into dialogue with

639
00:39:35,260 --> 00:39:37,990
your own personal religious beliefs

640
00:39:38,000 --> 00:39:41,550
and for some of you i hope all of you that will be enriching and

641
00:39:42,880 --> 00:39:44,690
for some of you it may be difficult

642
00:39:44,710 --> 00:39:46,300
you know that

643
00:39:46,300 --> 00:39:50,150
and i want you to rest assured that no one in this course

644
00:39:50,170 --> 00:39:54,240
which is to undermine or malign religious faith any more than they wish to promote

645
00:39:54,240 --> 00:39:56,640
or proselytize religious faith

646
00:39:56,670 --> 00:39:59,310
religious faith simply isn't the topic

647
00:39:59,310 --> 00:40:00,560
of this course

648
00:40:00,600 --> 00:40:06,000
the rich history and literature and religious thought of ancient israel as preserved for us

649
00:40:06,000 --> 00:40:07,420
over millennia

650
00:40:08,170 --> 00:40:10,270
the pages of this remarkable volume

651
00:40:10,280 --> 00:40:14,870
that's our topic and so our approach is going to be necessarily academic

652
00:40:14,870 --> 00:40:19,050
especially given the diversity of people in this room that's really all that can be

653
00:40:19,050 --> 00:40:21,130
so that we have common ground in

654
00:40:21,180 --> 00:40:23,530
and common goals for discussions

655
00:40:23,550 --> 00:40:26,500
but it has been my experience that from time to time

656
00:40:26,560 --> 00:40:31,340
students will raise a question or ask question

657
00:40:31,350 --> 00:40:33,490
that is prompted by

658
00:40:33,510 --> 00:40:36,610
a commitment prior commitment to an article of faith

659
00:40:36,610 --> 00:40:41,300
molecules that have atomic masses of or million

660
00:40:41,380 --> 00:40:43,890
grams per mole

661
00:40:43,900 --> 00:40:45,650
these are huge

662
00:40:45,650 --> 00:40:49,780
these are huge

663
00:40:49,790 --> 00:40:51,770
so we call this an

664
00:40:51,780 --> 00:40:56,530
i'm using and now in a new way and is called the polymerization index

665
00:40:56,540 --> 00:40:59,710
and as the polarisation index

666
00:40:59,720 --> 00:41:06,020
represents the number of repeats of the murder and the murders the repeat unit

667
00:41:07,280 --> 00:41:11,060
what's the length of this thing let's let's get a sense of this suppose we

668
00:41:11,060 --> 00:41:14,530
had something that was also a ten thousand units long

669
00:41:14,540 --> 00:41:15,850
so let's say

670
00:41:15,910 --> 00:41:17,620
and it's ten thousand

671
00:41:18,530 --> 00:41:20,890
that might give me all

672
00:41:20,930 --> 00:41:23,670
something on the order of about a million grams from

673
00:41:23,690 --> 00:41:26,630
we do that we do the calculation in a different way

674
00:41:26,640 --> 00:41:31,080
let me say suppose i had something that had an atomic mass of a hundred

675
00:41:31,080 --> 00:41:33,450
thousand years

676
00:41:33,570 --> 00:41:37,950
a hundred thousand grams from all this is the atomic masses palmer

677
00:41:38,010 --> 00:41:41,490
and divided by the atomic mass of

678
00:41:41,530 --> 00:41:46,390
part of ethylene ethylene is twenty eight grams per mole so this is the mass

679
00:41:46,390 --> 00:41:49,290
of c two h four of four

680
00:41:49,300 --> 00:41:53,490
and this is the mass of of the polyethylene one molecule

681
00:41:53,540 --> 00:41:55,520
so that would give us that a

682
00:41:55,570 --> 00:41:57,670
polarization index

683
00:41:57,830 --> 00:42:00,630
three thousand five hundred and seventy one

684
00:42:01,810 --> 00:42:03,280
thirty six hundred

685
00:42:03,360 --> 00:42:07,130
and if we estimate the carbon carbon bond distance

686
00:42:07,890 --> 00:42:10,320
about one and a half angstroms four

687
00:42:10,770 --> 00:42:12,780
the carbon carbon bond distance

688
00:42:12,860 --> 00:42:17,450
that gives us something that's on the order of about half a micron

689
00:42:17,510 --> 00:42:19,860
have micron in length

690
00:42:22,030 --> 00:42:24,050
one molecule

691
00:42:24,060 --> 00:42:26,790
and to give you a sense of what that really means

692
00:42:26,800 --> 00:42:28,570
i want to show you a demo here

693
00:42:28,630 --> 00:42:31,040
what i've got is pull chain

694
00:42:31,080 --> 00:42:32,700
it uses an

695
00:42:32,800 --> 00:42:35,100
o downstairs in grandma's house two

696
00:42:35,120 --> 00:42:36,190
turn on the lights

697
00:42:36,200 --> 00:42:38,400
so this is a whole bunch of these

698
00:42:40,880 --> 00:42:42,980
balls that are held together by

699
00:42:45,190 --> 00:42:46,100
so let's

700
00:42:46,140 --> 00:42:51,380
have each of these represent carbon and this one is about three thousand units long

701
00:42:51,390 --> 00:42:52,950
it's about forty feet

702
00:42:53,010 --> 00:42:56,100
forty feet and about three thousand of these

703
00:42:56,110 --> 00:42:57,450
units here

704
00:42:57,510 --> 00:43:00,320
so let's get a sense of how

705
00:43:00,410 --> 00:43:02,140
think this is

706
00:43:04,630 --> 00:43:22,020
this is one molecule

707
00:43:22,030 --> 00:43:24,650
this is one molecule

708
00:43:29,550 --> 00:43:31,620
so imagine what happens when this

709
00:43:31,630 --> 00:43:33,790
in the melt states flowing

710
00:43:33,910 --> 00:43:35,740
what happens when melt

711
00:43:35,780 --> 00:43:39,030
decreases in temperature in this attempts to solidify

712
00:43:39,100 --> 00:43:41,410
what are the chances that this is going to

713
00:43:41,420 --> 00:43:44,530
come out in one of the fourteen gravity lattices

714
00:43:44,580 --> 00:43:46,920
vanishingly small isn't it

715
00:43:46,930 --> 00:43:49,290
this is one molecule

716
00:43:49,300 --> 00:43:53,680
i feel like i just came back from new orleans

717
00:43:53,700 --> 00:43:57,180
then you have to with my shirt with all this stuff

718
00:43:57,190 --> 00:43:58,750
is terrific

719
00:43:58,790 --> 00:44:01,220
so that's one molecule

720
00:44:02,390 --> 00:44:05,290
if we imagine we imagine what happens

721
00:44:05,370 --> 00:44:10,020
let's say that it's pretty clear that that's solid

722
00:44:10,070 --> 00:44:14,160
let's call this macromolecules solid macromolecules

723
00:44:19,720 --> 00:44:25,280
favor being amorphous

724
00:44:25,280 --> 00:44:32,820
the amorphous state is the notion of pure crystallisation

725
00:44:32,880 --> 00:44:34,190
is not

726
00:44:34,320 --> 00:44:36,530
and we can imagine for example

727
00:44:36,700 --> 00:44:39,080
all of the rules that we learned for

728
00:44:39,100 --> 00:44:43,970
the inorganic glasses the silicate applied to organic glasses so let's look at say

729
00:44:43,980 --> 00:44:50,520
volume versus temperature for something like polyethylene so i'm going to call this p

730
00:44:54,360 --> 00:44:58,800
we can imagine more appearing amount state we cool down we go through the normal

731
00:44:58,810 --> 00:45:00,790
melting point and then we

732
00:45:01,770 --> 00:45:04,010
a cylinder fication

733
00:45:04,050 --> 00:45:09,490
some glass transition temperature let's say this is that a slow cooling rate

734
00:45:09,530 --> 00:45:11,760
so this is changing slow

735
00:45:11,800 --> 00:45:15,110
and maybe another occasionally cool at a fast rate

736
00:45:15,150 --> 00:45:20,550
so we will have a different glass transition temperature and it will be higher

737
00:45:20,650 --> 00:45:22,490
would be higher

738
00:45:23,280 --> 00:45:26,570
let's say this over here at

739
00:45:26,700 --> 00:45:28,350
room temperature

740
00:45:28,400 --> 00:45:30,860
so there's room temperature

741
00:45:30,900 --> 00:45:34,550
so what do i find i have two different volumes you've seen this before

742
00:45:34,560 --> 00:45:37,690
so if i have constant constant mass

743
00:45:37,700 --> 00:45:41,070
constant for constant mass equal masses

744
00:45:41,130 --> 00:45:43,040
the one with the higher volumes

745
00:45:43,060 --> 00:45:48,260
has lower density so this one should be low density

746
00:45:48,270 --> 00:45:50,990
this is let's let me just put the fast cooling rate

747
00:45:51,010 --> 00:45:53,860
fast cool this slow cool

748
00:45:53,870 --> 00:45:58,160
so this will be low density polyethylene formed here

749
00:45:58,220 --> 00:46:01,160
and this will be high-density polyethylene simply by

750
00:46:01,170 --> 00:46:03,540
the different rates of cooling

751
00:46:03,640 --> 00:46:07,350
constant mass means then that you have density

752
00:46:07,450 --> 00:46:09,720
as of volumes of the one

753
00:46:09,740 --> 00:46:12,430
higher volume gives us the power

754
00:46:12,440 --> 00:46:17,140
so we can see how by different processing we have the ability to change

755
00:46:18,440 --> 00:46:21,500
the high density and low density polyethylene

756
00:46:21,510 --> 00:46:24,670
as a function of the cooling rate

757
00:46:24,680 --> 00:46:28,440
other things can happen if we go at a very low rate of cooling we

758
00:46:28,440 --> 00:46:31,860
you can see if you burn off

759
00:46:31,920 --> 00:46:34,070
these flower

760
00:46:34,480 --> 00:46:38,480
i mean there different these are all of the

761
00:46:38,500 --> 00:46:40,520
so the very

762
00:46:40,540 --> 00:46:42,000
you can see

763
00:46:42,020 --> 00:46:45,960
it just using it for the US

764
00:46:45,980 --> 00:46:52,340
you to work of similarity in a smart way one of

765
00:46:52,360 --> 00:46:54,980
this one of the networks

766
00:46:56,670 --> 00:46:57,440
of course

767
00:46:57,540 --> 00:46:58,630
get this

768
00:47:02,070 --> 00:47:03,860
since very interesting

769
00:47:03,880 --> 00:47:05,190
for example

770
00:47:06,690 --> 00:47:07,340
know that there

771
00:47:09,840 --> 00:47:13,710
that is the agent of the

772
00:47:13,840 --> 00:47:18,690
but its application of the top eight

773
00:47:18,710 --> 00:47:22,800
but not how does not support

774
00:47:22,940 --> 00:47:24,000
it is

775
00:47:24,040 --> 00:47:26,000
so if you look at it

776
00:47:26,020 --> 00:47:26,800
the the difference

777
00:47:26,860 --> 00:47:31,280
thank you everyone for example we CDATA

778
00:47:31,300 --> 00:47:32,690
well something

779
00:47:32,710 --> 00:47:35,020
this ship on office

780
00:47:35,040 --> 00:47:37,770
what you're seeing this

781
00:47:39,300 --> 00:47:40,940
actually if you

782
00:47:40,940 --> 00:47:44,280
use all passenger this is on

783
00:47:44,300 --> 00:47:45,840
we get some

784
00:47:45,880 --> 00:47:46,550
one and

785
00:47:46,550 --> 00:47:50,210
that's why you were once

786
00:47:50,270 --> 00:47:54,360
it's not the same as those conferences

787
00:47:54,360 --> 00:47:56,650
the same thing

788
00:47:56,670 --> 00:48:05,130
people can get out of policies because the disease is about one is

789
00:48:05,190 --> 00:48:07,460
that's one a one

790
00:48:07,480 --> 00:48:09,250
remember the interesting thing

791
00:48:10,500 --> 00:48:14,280
this that's actually you're best

792
00:48:14,320 --> 00:48:17,670
that is patient

793
00:48:17,690 --> 00:48:18,980
this is a very

794
00:48:18,980 --> 00:48:23,250
the authors most to europe in batch

795
00:48:24,380 --> 00:48:25,750
because now

796
00:48:25,770 --> 00:48:28,210
the reason very agent

797
00:48:28,230 --> 00:48:30,730
also sent back to europe

798
00:48:30,750 --> 00:48:35,250
people said to about the distribution

799
00:48:35,270 --> 00:48:38,000
of course this but they

800
00:48:38,170 --> 00:48:42,770
here you see a lot of published in the second part this is shown in

801
00:48:42,780 --> 00:48:45,750
the comic authors there

802
00:48:45,900 --> 00:48:50,440
even once twice in asia you find the similarity of that

803
00:48:50,460 --> 00:48:52,190
but will find hard

804
00:48:52,210 --> 00:48:53,880
this is the one just because

805
00:48:53,940 --> 00:48:56,270
who here

806
00:48:56,340 --> 00:48:58,190
it's very

807
00:48:58,460 --> 00:49:00,090
about this

808
00:49:01,610 --> 00:49:03,820
but if you use

809
00:49:03,840 --> 00:49:07,130
have personalized pagerank also

810
00:49:07,150 --> 00:49:08,380
you this

811
00:49:08,420 --> 00:49:10,150
what you find is

812
00:49:10,150 --> 00:49:12,650
that's the most i e

813
00:49:12,940 --> 00:49:17,360
the so what happens is you for this is the

814
00:49:17,380 --> 00:49:18,820
so if you want

815
00:49:18,840 --> 00:49:21,980
opt not use it

816
00:49:22,000 --> 00:49:26,170
what was the first time just

817
00:49:26,170 --> 00:49:28,360
you see of the the original

818
00:49:28,420 --> 00:49:31,360
so as i said he was

819
00:49:31,750 --> 00:49:34,780
one slide here

820
00:49:34,880 --> 00:49:36,250
you can see that

821
00:49:37,090 --> 00:49:42,050
this is very similar groups that this is most

822
00:49:42,070 --> 00:49:47,590
OK so that the passengers are said to be

823
00:49:47,590 --> 00:49:50,920
so far that the first place

824
00:49:53,860 --> 00:49:56,770
you can use it for

825
00:49:58,050 --> 00:49:58,860
this is

826
00:49:58,860 --> 00:50:00,280
to many

827
00:50:00,300 --> 00:50:02,920
like this one this one many

828
00:50:02,940 --> 00:50:04,690
so for example should

829
00:50:04,690 --> 00:50:07,440
it's very

830
00:50:07,460 --> 00:50:10,090
for example if you

831
00:50:10,110 --> 00:50:13,300
he was this past

832
00:50:13,320 --> 00:50:15,650
going further and

833
00:50:15,800 --> 00:50:20,000
this is more like a home page friend

834
00:50:20,000 --> 00:50:21,770
people have proposed that

835
00:50:25,670 --> 00:50:29,330
if people don't want to get into this too much but if you're familiar with

836
00:50:29,390 --> 00:50:34,290
with the with exact methods for solving pomdps there's this thing called alpha vectors that

837
00:50:34,290 --> 00:50:39,730
represent pieces of the value functions big continuous value function what they showed in this

838
00:50:39,730 --> 00:50:45,210
paper is that the the analogue of alpha vectors for these continuous space upon please

839
00:50:45,210 --> 00:50:50,190
are alpha functions but on the good news there only multinomial polynomials

840
00:50:50,250 --> 00:50:51,870
they could be worse

841
00:50:51,920 --> 00:50:56,690
it could be some arbitrary functions but know they're just multivariate polynomials so there are

842
00:50:56,690 --> 00:51:00,600
smooth in the max over them it's basically they worked at the form of the

843
00:51:00,600 --> 00:51:04,480
value function and it wasn't as bad as it could have been and they approximate

844
00:51:04,500 --> 00:51:08,290
various ways and throw in some point based value iteration but the fact the matter

845
00:51:08,290 --> 00:51:12,230
is there being able to derive a pretty good approximation of the value function

846
00:51:12,870 --> 00:51:18,590
some some small problems like this five state combination lock like environment which they solve

847
00:51:18,590 --> 00:51:21,690
really really close to optimal so actually able to find

848
00:51:21,750 --> 00:51:24,120
the bayesian optimal strategy

849
00:51:24,170 --> 00:51:28,350
or something very close to it for this world so like explorers perfectly

850
00:51:28,460 --> 00:51:30,460
it's pretty

851
00:51:30,480 --> 00:51:34,790
they have a bigger problem which has to do with using soap apparently

852
00:51:34,790 --> 00:51:38,620
some kind of self care monitoring system

853
00:51:39,830 --> 00:51:43,290
you want to say that that's exactly what it is the answer for monitoring people

854
00:51:43,290 --> 00:51:47,790
to make sure that they're actually staying on task if they have cognitive deficits and

855
00:51:47,790 --> 00:51:52,500
even at this at this size we went from like five states to

856
00:51:52,520 --> 00:51:58,560
nine their approximations are starting to really break down so they even nice it example

857
00:51:58,560 --> 00:52:02,560
they couldn't find the bayes optimal effect the thing they found was really close it

858
00:52:02,560 --> 00:52:07,290
still lead to decent exploration but you could tell it was not a whole other

859
00:52:07,290 --> 00:52:10,620
heuristics are actually doing as well sometimes even better

860
00:52:11,390 --> 00:52:16,580
yes sort of less optimal this bayes optimal into being less optimal if the world

861
00:52:16,580 --> 00:52:20,310
this is sufficiently big can you approximating

862
00:52:20,330 --> 00:52:25,830
yeah sure of

863
00:52:32,440 --> 00:52:37,580
i'm not sure i could i could speculate about that so i think he was

864
00:52:37,580 --> 00:52:40,480
he was sitting down under tree

865
00:52:40,500 --> 00:52:42,480
and appl

866
00:52:42,580 --> 00:52:46,960
well we're cambridge seem fair so

867
00:52:46,980 --> 00:52:50,730
so what happened was the co-authors i should have listed as some of the courses

868
00:52:50,730 --> 00:52:54,440
but ppoplp part was working on with some other people who are also solving pomdps

869
00:52:54,540 --> 00:52:59,100
generalize their tools to continuous pompey's is they're working on just continues honey in the

870
00:52:59,120 --> 00:53:04,270
general sense and i imagine they got together the competition something and said well

871
00:53:04,290 --> 00:53:08,650
bayesian reinforcement learning is a continuous palm p and then they realize that it was

872
00:53:08,650 --> 00:53:13,460
a very special continuous ponte people have these extra features to it and i imagine

873
00:53:13,460 --> 00:53:16,100
it just kind of stumbled that

874
00:53:17,390 --> 00:53:20,830
i've actually as the that but it's that was my rational reconstruction i was i

875
00:53:20,830 --> 00:53:23,560
was i had the same question and that was that was my answer in my

876
00:53:23,560 --> 00:53:25,750
own head

877
00:53:25,770 --> 00:53:26,850
therefore it's

878
00:53:26,900 --> 00:53:31,000
i don't know know if it's right or wrong or so

879
00:53:32,400 --> 00:53:33,190
i think

880
00:53:33,210 --> 00:53:36,940
many people in the field and me for a while but not me right now

881
00:53:36,980 --> 00:53:42,100
have basically taken this bayes optimal behavior as being the ideal and everything else is

882
00:53:42,150 --> 00:53:44,020
some kind of poor approximation of it

883
00:53:44,040 --> 00:53:49,150
and i think there is an argument that would say that that's true especially i

884
00:53:49,150 --> 00:53:54,040
would say that very gently around the billions and stuff because because you know based

885
00:53:54,040 --> 00:53:58,600
on basis optimal so it's got to be perfect but the fact that matter is

886
00:53:58,600 --> 00:53:59,520
that you

887
00:53:59,540 --> 00:54:03,230
i could see that maybe isn't exactly what you want and i'll explain why but

888
00:54:03,230 --> 00:54:06,370
it's going to take two steps really get so bear with me for a moment

889
00:54:06,420 --> 00:54:11,390
so remember yesterday we talked about the PAC MDP

890
00:54:11,400 --> 00:54:12,390
so goal

891
00:54:12,400 --> 00:54:15,170
so so one thing one goal of

892
00:54:15,230 --> 00:54:19,190
how do you try to learn reinforcement learning problem is this bayes optimal one that

893
00:54:19,190 --> 00:54:23,710
says well it's not really about learning and then acting it's about just always maximizing

894
00:54:23,710 --> 00:54:30,580
rewards smooth continuous everything is just one unified problems is one big hard unified problem

895
00:54:30,600 --> 00:54:31,730
the PAC MDP

896
00:54:31,750 --> 00:54:35,920
model says something different PAC MDP model says what we really want to do is

897
00:54:36,250 --> 00:54:39,500
to be able to generate behaviour that is nearly optimal

898
00:54:39,520 --> 00:54:40,810
with high probability

899
00:54:40,830 --> 00:54:43,770
but we're allowed to make a small number of mistakes along the way they were

900
00:54:43,770 --> 00:54:46,940
allowed to try things that are not going to count against us the actual reward

901
00:54:46,940 --> 00:54:50,400
we get in those in those cases doesn't matter it just was no good and

902
00:54:50,400 --> 00:54:53,020
we can we limit the number of no goods that we can have a number

903
00:54:53,020 --> 00:54:58,040
of mistakes OK so that was the PAC MDP model

904
00:54:58,060 --> 00:55:01,920
you can combine these ideas in various ways to one night when they came up

905
00:55:01,920 --> 00:55:07,120
recently is the idea of near bayesian optimal and what this means is instead of

906
00:55:07,120 --> 00:55:11,250
defining mistakes to be taking an action that is not

907
00:55:11,350 --> 00:55:14,920
nearly the right action according to the true q function

908
00:55:14,920 --> 00:55:19,390
here mistake is now taking action is what the bayes optimal thing would have taken

909
00:55:19,390 --> 00:55:21,810
the bayes optimal approach would have taken

910
00:55:21,830 --> 00:55:23,290
all right well that's

911
00:55:23,330 --> 00:55:26,460
that seems closer to being right so it's not only is it is it trying

912
00:55:26,460 --> 00:55:29,960
to distinguish actions that are

913
00:55:29,980 --> 00:55:30,870
for the real

914
00:55:30,900 --> 00:55:35,040
model correct not correct but actions that in the bayesian sense are correct and i

915
00:55:35,060 --> 00:55:38,830
corrected actually take towards gaining information in the right way

916
00:55:40,420 --> 00:55:44,620
got PAC MDP we got near bayesian culture and in

917
00:55:44,670 --> 00:55:49,020
showed that they can they came up with an algorithm called bayesian at the bayesian

918
00:55:49,020 --> 00:55:52,870
exploration bonus algorithm all it does is

919
00:55:53,940 --> 00:55:58,290
keep track of UNDP the MDP experience so far by counting up live in in

920
00:55:58,290 --> 00:56:01,980
the state i took this action here states and i ended up in you keep

921
00:56:01,980 --> 00:56:02,900
counts on

922
00:56:02,920 --> 00:56:06,940
on how many times each of those things that appeared but when you've solve out

923
00:56:08,000 --> 00:56:11,750
value function for this you added bonus to any state

924
00:56:11,810 --> 00:56:15,000
on the order of one over and where n is the number of times that

925
00:56:15,000 --> 00:56:19,060
state was visited so in the beginning when you have this issue have visitor who

926
00:56:19,060 --> 00:56:21,810
visited once you get a bonus of one

927
00:56:21,890 --> 00:56:25,750
but as you visited state more often it starts to traylor

928
00:56:25,890 --> 00:56:29,790
so intuitively this is a reasonable thing right this is saying that the more i've

929
00:56:29,790 --> 00:56:33,940
been to estate unless i have to boost it up to make an optimistic

930
00:56:33,960 --> 00:56:37,120
and in the limit as n gets really really big it's going to take on

931
00:56:37,120 --> 00:56:38,980
whatever true value is

932
00:56:39,000 --> 00:56:42,290
this is a very reasonable thing to do in fact i think people have proposed

933
00:56:42,290 --> 00:56:46,060
stuff a lot like this kind of ad-hoc but what these guys showed is that

934
00:56:46,060 --> 00:56:50,210
if you do that if you run an algorithm and no fancy planning in belief

935
00:56:50,210 --> 00:56:55,310
space or or posterior based on like that all you do just straight up

936
00:56:55,330 --> 00:56:58,850
while based MDP but with this bonus defined that way

937
00:56:58,920 --> 00:57:04,890
then also very computationally simple it actually achieves this near bayesian property

938
00:57:04,900 --> 00:57:09,270
so in all but polynomial number of time steps it takes the same action that

939
00:57:09,270 --> 00:57:12,460
bayesian optimal algorithm taken

940
00:57:12,480 --> 00:57:15,250
that's kind of cool

941
00:57:15,270 --> 00:57:17,020
here's the other than they showed

942
00:57:17,020 --> 00:57:19,540
in spite of that it's not PAC MDP

943
00:57:19,540 --> 00:57:23,160
so the main

944
00:57:23,170 --> 00:57:26,300
and they just

945
00:57:26,310 --> 00:57:27,340
two days

946
00:57:28,370 --> 00:57:32,160
so they have in common those

947
00:57:32,170 --> 00:57:34,730
from another

948
00:57:34,790 --> 00:57:37,130
during the whole way

949
00:57:39,180 --> 00:57:41,800
so they are

950
00:57:44,000 --> 00:57:46,890
for the query

951
00:57:46,920 --> 00:57:50,120
number of iterations

952
00:57:52,810 --> 00:57:55,520
right now

953
00:57:55,540 --> 00:57:56,230
i mean

954
00:58:04,070 --> 00:58:05,680
it is not

955
00:58:05,720 --> 00:58:08,040
i always like

956
00:58:08,050 --> 00:58:09,430
it's not something

957
00:58:09,470 --> 00:58:16,170
also works in other words the point men desert

958
00:58:18,500 --> 00:58:19,870
having only your

959
00:58:20,990 --> 00:58:22,420
the also

960
00:58:25,100 --> 00:58:29,380
this this one

961
00:58:29,410 --> 00:58:31,550
the rangers

962
00:58:36,590 --> 00:58:39,390
the most relevant to our work

963
00:58:39,410 --> 00:58:45,330
if is no interest seam on the position of the

964
00:58:45,410 --> 00:58:47,640
the image it is

965
00:58:47,700 --> 00:58:55,590
we can also evidence of already

966
00:58:59,040 --> 00:59:01,550
so we have have lots of images which

967
00:59:01,560 --> 00:59:04,720
relative to each other

968
00:59:04,830 --> 00:59:07,090
we can equally

969
00:59:08,270 --> 00:59:11,070
just to belong to to the class

970
00:59:11,090 --> 00:59:12,370
it will be

971
00:59:12,390 --> 00:59:16,510
and that's what

972
00:59:16,640 --> 00:59:18,180
this the case

973
00:59:18,220 --> 00:59:20,890
and the fact that

974
00:59:20,920 --> 00:59:23,590
this was later

975
00:59:23,600 --> 00:59:25,040
one year

976
00:59:25,090 --> 00:59:28,090
we have

977
00:59:28,310 --> 00:59:30,800
well it doesn't

978
00:59:30,850 --> 00:59:33,540
mean just to make system

979
00:59:33,550 --> 00:59:35,960
big n is the total amount of the images

980
00:59:36,000 --> 00:59:37,230
this is a

981
00:59:37,290 --> 00:59:38,220
and for every

982
00:59:38,390 --> 00:59:39,860
we have

983
00:59:42,000 --> 00:59:45,190
which actually number of said that

984
00:59:45,200 --> 00:59:48,000
this image is relevant to the query

985
00:59:48,920 --> 00:59:52,510
in this case that we have a lot of

986
00:59:55,770 --> 00:59:58,930
so the ones that have

987
00:59:58,950 --> 01:00:02,420
seven judges for every image collection

988
01:00:02,430 --> 01:00:04,710
and of course ability

989
01:00:04,760 --> 01:00:08,480
this is a very well

990
01:00:08,760 --> 01:00:12,490
not to the should be

991
01:00:13,740 --> 01:00:16,240
more sophisticated than previous one

992
01:00:16,340 --> 01:00:19,800
you can also see that we have to

993
01:00:19,820 --> 01:00:25,910
is that all images that are alleged but in this case it seems that have

994
01:00:28,430 --> 01:00:31,070
but in fact

995
01:00:31,080 --> 01:00:32,590
so for every query

996
01:00:32,610 --> 01:00:38,160
you have several users who made the answer and who

997
01:00:38,170 --> 01:00:44,130
select the most people the the most was requires the next one infinite

998
01:00:44,170 --> 01:00:45,940
so we right

999
01:00:45,950 --> 01:00:47,610
for every

1000
01:00:47,630 --> 01:00:49,700
according to use that

1001
01:00:49,720 --> 01:00:53,230
and after a

1002
01:00:53,980 --> 01:00:55,440
the picture

1003
01:00:55,510 --> 01:00:58,270
the percentage of people

1004
01:01:00,260 --> 01:01:03,260
think the which is a

1005
01:01:03,280 --> 01:01:06,850
should be performed on the budget

1006
01:01:07,780 --> 01:01:10,860
these queries queries

1007
01:01:11,930 --> 01:01:12,730
and the

1008
01:01:16,790 --> 01:01:19,450
well these

1009
01:01:23,870 --> 01:01:25,600
the range which is done

1010
01:01:25,610 --> 01:01:30,370
and think it is the standard deviation

1011
01:01:30,550 --> 01:01:36,390
first we have judge and they have some

1012
01:01:36,410 --> 01:01:38,030
every frame

1013
01:01:38,990 --> 01:01:40,810
these which is the answer

1014
01:01:41,790 --> 01:01:45,610
and that doesn't follow the standard deviation of users that

1015
01:01:45,650 --> 01:01:47,950
so for example query one

1016
01:01:47,950 --> 01:01:52,100
again the cumulant function was thing

1017
01:01:52,120 --> 01:01:56,240
make sure that the distribution of normalized

1018
01:01:56,260 --> 01:02:01,020
then the expected expected value of the instances include two

1019
01:02:01,040 --> 01:02:02,450
the idea of data

1020
01:02:02,520 --> 01:02:06,290
which is the derivative of the cumulant function

1021
01:02:06,310 --> 01:02:08,150
so no

1022
01:02:08,200 --> 01:02:11,900
whenever you work with this kind of thing

1023
01:02:11,910 --> 01:02:17,560
you always have the notion of duality so this section second convex function

1024
01:02:17,620 --> 01:02:22,980
called the convex concave conjugate function you can write in terms of so

1025
01:02:23,600 --> 01:02:25,970
martin wainwright did that was

1026
01:02:25,980 --> 01:02:30,770
here i'm in the differential case so i don't need the super can write down

1027
01:02:30,770 --> 01:02:32,640
an explicit formula

1028
01:02:32,660 --> 01:02:37,340
this second functions f of mu which is the terms mean minus

1029
01:02:37,360 --> 01:02:40,410
g of theta

1030
01:02:40,550 --> 01:02:42,320
OK these are

1031
01:02:42,330 --> 01:02:45,960
convex conjugate

1032
01:02:47,780 --> 01:02:51,770
again little denotes the gradient of capital s and then

1033
01:02:51,790 --> 01:02:54,530
these two are inverses of each other

1034
01:02:54,550 --> 01:02:56,750
in in more

1035
01:02:56,760 --> 01:03:00,550
overview type picture

1036
01:03:00,570 --> 01:03:03,660
he sort of has two parameters

1037
01:03:03,680 --> 01:03:07,770
primal and dual parameters natural in expectation parameters right

1038
01:03:07,780 --> 01:03:09,760
everything comes in pairs

1039
01:03:09,800 --> 01:03:11,170
it's always

1040
01:03:11,180 --> 01:03:14,500
how these things work and i'm going to go for example in the moment and

1041
01:03:14,500 --> 01:03:17,830
this is also why it's confusing but want to get a handle on it

1042
01:03:17,840 --> 01:03:21,260
it's actually quite elegant

1043
01:03:22,620 --> 01:03:24,340
the natural parameter

1044
01:03:24,400 --> 01:03:28,480
is mapped we have the little g function which is the derivative of this function

1045
01:03:28,480 --> 01:03:31,380
to the expectation parameter which is mapped

1046
01:03:31,420 --> 01:03:34,730
we have a little function which is the derivative of

1047
01:03:34,780 --> 01:03:35,870
back to the

1048
01:03:35,880 --> 01:03:38,040
natural parameters

1049
01:03:38,060 --> 01:03:39,750
so the two tool parameters

1050
01:03:39,760 --> 01:03:43,210
and here the transformation

1051
01:03:43,230 --> 01:03:48,720
OK so this is sort of the overview picture

1052
01:03:53,100 --> 01:03:57,510
the simplest example is the gaussians and now i i do the gaussians even simpler

1053
01:03:57,510 --> 01:04:01,270
than alex it yesterday i do it for the experience

1054
01:04:02,910 --> 01:04:06,000
the distribution is e to the minus

1055
01:04:07,580 --> 01:04:10,000
the tragic you can rewrite it this way

1056
01:04:10,010 --> 01:04:11,590
this is the reference density

1057
01:04:11,610 --> 01:04:15,940
this is the energy function this is the linear park

1058
01:04:15,950 --> 01:04:18,350
so here's the cumulant function

1059
01:04:19,940 --> 01:04:21,790
now in this case

1060
01:04:21,810 --> 01:04:23,480
if you take the derivative

1061
01:04:23,490 --> 01:04:25,850
this function you get the identity function

1062
01:04:25,860 --> 01:04:29,580
and the inverse of the identity function is again the identity function so this is

1063
01:04:29,580 --> 01:04:32,650
one of the simplest case this is the case

1064
01:04:32,660 --> 01:04:34,830
it corresponds to

1065
01:04:34,840 --> 01:04:40,230
representer theorem corresponds to kernelizable algorithm everything sort of very simple knows the link function

1066
01:04:40,230 --> 01:04:41,690
is the identity function

1067
01:04:41,750 --> 01:04:45,240
and the dual convex function

1068
01:04:47,110 --> 01:04:49,360
if you plug in the formula now

1069
01:04:49,470 --> 01:04:55,860
also the same function in terms of the other variables

1070
01:04:56,630 --> 01:05:00,990
the log likelihood of this function is simply the square loss

1071
01:05:01,010 --> 01:05:03,690
so let me go back again and generality

1072
01:05:03,710 --> 01:05:07,440
two parameters natural parameter expectation parameter

1073
01:05:08,430 --> 01:05:12,470
the maps to hear the left maps back those the derivatives

1074
01:05:12,480 --> 01:05:15,950
of the corresponding functional these two functions are convex conjugate

1075
01:05:16,070 --> 01:05:20,160
first example

1076
01:05:21,460 --> 01:05:23,150
you rewrite it

1077
01:05:23,160 --> 01:05:25,460
linear part human and function

1078
01:05:25,470 --> 01:05:30,050
you take the derivative see everything is the identity function the two convex conjugate functions

1079
01:05:30,050 --> 01:05:33,380
are identical this one and this one the article

1080
01:05:45,540 --> 01:05:47,550
the very basic issues

1081
01:05:47,570 --> 01:05:49,660
it's the newly

1082
01:05:49,680 --> 01:05:54,210
density look like this

1083
01:05:56,690 --> 01:05:58,080
remove is

1084
01:05:58,090 --> 01:06:00,510
the probability

1085
01:06:01,520 --> 01:06:03,500
of it is a coin

1086
01:06:03,510 --> 01:06:07,290
and it's the probability of the outcome of the one

1087
01:06:07,310 --> 01:06:12,450
the natural parameter happens to be this actually moves the expectation parameters you will see

1088
01:06:13,080 --> 01:06:15,550
this is the natural parameter

1089
01:06:15,570 --> 01:06:18,720
now i can write my density as

1090
01:06:18,770 --> 01:06:21,210
p theta x

1091
01:06:21,260 --> 01:06:24,460
minus lenses just straightforward algebra

1092
01:06:24,470 --> 01:06:25,910
which i didn't show

1093
01:06:25,920 --> 01:06:27,410
so hard

1094
01:06:28,090 --> 01:06:29,780
if you have some time

1095
01:06:29,800 --> 01:06:34,180
it's linear minus the function this of course is a

1096
01:06:34,740 --> 01:06:40,090
convex function

1097
01:06:41,730 --> 01:06:42,570
and then

1098
01:06:42,580 --> 01:06:48,130
you take the derivative of this you get the softmax

1099
01:06:48,180 --> 01:06:49,320
as the little g

1100
01:06:49,330 --> 01:06:50,350
and this still

1101
01:06:50,370 --> 01:06:54,180
and you get this function

1102
01:06:54,200 --> 01:06:55,560
you can also

1103
01:06:55,570 --> 01:06:57,850
plugin and compute the dual

1104
01:06:57,860 --> 01:07:02,300
and you get this

1105
01:07:02,310 --> 01:07:05,370
the negative entropy

1106
01:07:10,650 --> 01:07:12,360
if you

1107
01:07:12,380 --> 01:07:16,180
take the log of this function and write it in the data domain it looks

1108
01:07:16,180 --> 01:07:17,300
like this

1109
01:07:17,310 --> 01:07:20,130
if you write it using the new parameter

1110
01:07:20,140 --> 01:07:21,370
it looks like this

1111
01:07:21,370 --> 01:07:22,980
and if you do this

1112
01:07:22,980 --> 01:07:27,010
o thing by solving this linear programme

1113
01:07:27,030 --> 01:07:28,640
progress on in hungary

1114
01:07:28,910 --> 01:07:34,560
the nice thing is you can actually solve this in cubic time

1115
01:07:34,600 --> 01:07:36,200
this is the linear programme

1116
01:07:36,230 --> 01:07:40,250
and you can just throw this at the standard LP solvers

1117
01:07:40,280 --> 01:07:41,670
or you could go

1118
01:07:41,670 --> 01:07:45,700
and you some specific code for that and there's nothing to three code available on

1119
01:07:45,700 --> 01:07:46,900
the net

1120
01:07:46,950 --> 01:07:50,440
thirty easy

1121
01:07:50,460 --> 01:07:52,550
now what we did is

1122
01:07:52,690 --> 01:07:55,660
we through exactly that's over

1123
01:07:55,780 --> 01:07:57,500
the the linear assignment problem

1124
01:07:57,510 --> 01:08:04,140
but these terms came from our distribution case

1125
01:08:05,750 --> 01:08:06,940
and then

1126
01:08:06,990 --> 01:08:08,750
it actually work much better

1127
01:08:08,800 --> 01:08:15,950
so we almost all of the time got everything right

1128
01:08:15,970 --> 01:08:18,520
so adding this external knowledge

1129
01:08:18,550 --> 01:08:21,750
but we know that you have to match the turns up somehow

1130
01:08:21,900 --> 01:08:27,550
really improved testament

1131
01:08:28,890 --> 01:08:32,870
now sample bias correction

1132
01:08:32,900 --> 01:08:34,120
so this is where

1133
01:08:34,140 --> 01:08:34,980
you have

1134
01:08:35,000 --> 01:08:35,980
one set of

1135
01:08:36,000 --> 01:08:37,750
observations for the training set

1136
01:08:37,760 --> 01:08:40,210
another one for the test it

1137
01:08:40,210 --> 01:08:42,550
and some are you training set has been biased

1138
01:08:42,780 --> 01:08:45,810
he would like to recover from that

1139
01:08:45,870 --> 01:08:51,100
following question so far

1140
01:08:51,120 --> 01:08:53,330
everything clear

1141
01:08:53,510 --> 01:08:55,040
very fast asleep

1142
01:08:55,570 --> 01:08:58,100
OK good

1143
01:09:00,160 --> 01:09:03,400
what's the problem

1144
01:09:03,400 --> 01:09:04,840
the problem is that

1145
01:09:04,870 --> 01:09:08,190
we have our training data drawn from some distribution

1146
01:09:08,190 --> 01:09:09,280
on the x and y

1147
01:09:09,340 --> 01:09:12,670
and the they start story from another one

1148
01:09:12,680 --> 01:09:16,770
going to make one simplifying assumption

1149
01:09:16,790 --> 01:09:21,290
and going to assume that only distribution on the axis differs

1150
01:09:21,340 --> 01:09:24,340
but the conditional distributions are the same

1151
01:09:24,390 --> 01:09:26,420
that's a fairly realistic assumption

1152
01:09:26,530 --> 01:09:28,340
for instance if you're

1153
01:09:28,390 --> 01:09:30,900
let's get back to the breast cancer example

1154
01:09:31,750 --> 01:09:35,550
if you actually have specific microarray measurements

1155
01:09:35,600 --> 01:09:37,220
then well

1156
01:09:37,220 --> 01:09:39,550
you have to assume that the biology

1157
01:09:39,600 --> 01:09:43,910
will be sufficient to tell you whether that person is healthy or sick

1158
01:09:44,000 --> 01:09:48,860
so while the distribution over the micro measurements might be different

1159
01:09:48,890 --> 01:09:50,490
once you have it

1160
01:09:50,510 --> 01:09:53,220
that should be all that you really need in order to assess whether that person

1161
01:09:53,220 --> 01:09:56,390
is healthy

1162
01:09:56,550 --> 01:09:58,740
it may not always be the case

1163
01:09:58,750 --> 01:10:04,480
but that's for the moment assumed

1164
01:10:04,530 --> 01:10:06,480
you could use it for active learning

1165
01:10:06,480 --> 01:10:08,860
you could use it experimental design as well

1166
01:10:08,920 --> 01:10:11,890
you could use it for brain computer interfaces

1167
01:10:11,930 --> 01:10:13,830
or adoption to new users

1168
01:10:13,860 --> 01:10:16,250
well those cases are actually quite interesting

1169
01:10:16,330 --> 01:10:20,240
so for instance when you put one of the brain computer interfaces on

1170
01:10:20,250 --> 01:10:24,870
and you do the test you work with the system ministers train for whatever very

1171
01:10:24,920 --> 01:10:26,430
you work with initially

1172
01:10:26,440 --> 01:10:30,160
and eventually actually do those tasty guitar

1173
01:10:30,210 --> 01:10:31,640
as you get tired

1174
01:10:31,650 --> 01:10:34,150
the distribution of the signals coming

1175
01:10:34,200 --> 01:10:35,770
out of your brain

1176
01:10:36,690 --> 01:10:38,550
getting different

1177
01:10:40,210 --> 01:10:41,730
while you still might be

1178
01:10:41,740 --> 01:10:44,300
thinking in a similar way

1179
01:10:45,470 --> 01:10:48,190
you might not be able to concentrate sunlight and all that

1180
01:10:48,200 --> 01:10:51,470
so you don't have a different distribution you would want to adapt on the

1181
01:10:51,490 --> 01:10:53,680
that it on the fly

1182
01:10:53,690 --> 01:10:56,650
in this system actually could do it

1183
01:10:57,270 --> 01:11:01,160
you want to adapt to new users like for instance here microsoft and you want

1184
01:11:01,160 --> 01:11:03,150
to train handwritten character recognise

1185
01:11:03,440 --> 01:11:06,680
if god database of fifty users

1186
01:11:06,730 --> 01:11:08,990
and the training system for that

1187
01:11:09,010 --> 01:11:11,010
and then at the end of the day

1188
01:11:11,060 --> 01:11:12,070
as the ship it

1189
01:11:12,080 --> 01:11:14,590
he would like to adapt to the distribution

1190
01:11:14,600 --> 01:11:18,900
that user uses inputs

1191
01:11:18,900 --> 01:11:19,430
i i d

1192
01:11:22,210 --> 01:11:26,180
and this is exactly if you will this is exactly the term that we have seen here

1193
01:11:26,990 --> 01:11:27,850
in the base equation

1194
01:11:28,730 --> 01:11:29,300
takes a prior

1195
01:11:30,400 --> 01:11:31,440
template parameter from it

1196
01:11:31,990 --> 01:11:33,010
and then we get a product

1197
01:11:36,720 --> 01:11:38,330
okay so what this theorem says is

1198
01:11:40,600 --> 01:11:43,220
if and only if the data is exchangeable this whole this whole idea

1199
01:11:43,860 --> 01:11:45,670
data is power plus noise makes sense

1200
01:11:46,190 --> 01:11:46,950
and the pattern

1201
01:11:47,480 --> 01:11:48,100
in general

1202
01:11:48,550 --> 01:11:50,350
is expressed by a probability distribution

1203
01:11:50,870 --> 01:11:51,750
and if we do something

1204
01:11:52,170 --> 01:11:53,200
like saying

1205
01:11:53,630 --> 01:11:57,510
on the previous slide here or a pattern is really a straight line this is

1206
01:11:57,510 --> 01:12:01,960
not a probability distribution then that would mean that we choose set of probability distributions

1207
01:12:01,960 --> 01:12:03,760
that are parameterized by straight lines

1208
01:12:10,330 --> 01:12:11,440
the cabinet you is

1209
01:12:13,660 --> 01:12:14,700
what this does not mean

1210
01:12:17,180 --> 01:12:18,070
you start with some

1211
01:12:19,260 --> 01:12:21,410
bayesian model very like you'd say goes

1212
01:12:22,660 --> 01:12:26,540
and now we say okay my data is exchangeable and therefore this assumption makes sense

1213
01:12:27,300 --> 01:12:28,270
because in general

1214
01:12:29,150 --> 01:12:29,630
this year

1215
01:12:30,690 --> 01:12:34,410
this district probability distribution here's an arbitrary probability distribution

1216
01:12:34,840 --> 01:12:38,020
and that means a set in which these probability distributions lived

1217
01:12:38,430 --> 01:12:40,170
is an infinite dimensional set

1218
01:12:40,690 --> 01:12:44,530
and the set of all probability distributions on a given space is an infinite-dimensional set

1219
01:12:46,880 --> 01:12:50,790
in general we have to put a prior on infinite dimensional space you from from

1220
01:12:50,790 --> 01:12:53,390
an abstract perspective this is a key motivation for

1221
01:12:54,090 --> 01:12:56,660
before being nonparametric and bayesian models if you want to really

1222
01:12:57,290 --> 01:13:00,750
if you want to really exploit the statement of this theorem if you want to use it

1223
01:13:01,260 --> 01:13:05,180
then you have to be nonparametric okay after using an infinite dimensional parameters

1224
01:13:14,960 --> 01:13:16,600
it has already mentioned clustering earlier

1225
01:13:18,450 --> 01:13:22,830
basically the very simple thing this this is just a cartoon cartoon picture of clustering

1226
01:13:26,590 --> 01:13:27,160
yeah so

1227
01:13:28,320 --> 01:13:29,980
this data was course generated by

1228
01:13:30,530 --> 01:13:31,670
sampling from constant

1229
01:13:32,130 --> 01:13:32,630
mixture model

1230
01:13:34,780 --> 01:13:36,690
can i can i just ask who who has seen

1231
01:13:37,090 --> 01:13:39,110
who has not seen a finite mixture model before

1232
01:13:40,420 --> 01:13:41,670
okay very good thank you

1233
01:13:44,540 --> 01:13:45,780
we're going to assume that the

1234
01:13:45,890 --> 01:13:47,950
we have observations x one x two and so on

1235
01:13:49,680 --> 01:13:51,770
the modelling assumption we make and clustering is

1236
01:13:52,850 --> 01:13:53,950
they the data is

1237
01:13:54,820 --> 01:13:56,010
subdivided into groups

1238
01:13:56,510 --> 01:14:00,470
partition into groups and that means each data point belongs to exactly one cluster

1239
01:14:03,610 --> 01:14:08,190
these in this case they pattern that i was talking before so i will feed you will

1240
01:14:08,690 --> 01:14:11,180
are not pattern is a partition of the data

1241
01:14:12,720 --> 01:14:13,090
in two

1242
01:14:13,620 --> 01:14:14,740
disjoint groups yeah

1243
01:14:15,350 --> 01:14:16,870
and if you now think of if

1244
01:14:17,350 --> 01:14:18,300
if you think of this

1245
01:14:19,160 --> 01:14:22,850
as an infinite sequence here than it has indices one two three four and so on

1246
01:14:23,410 --> 01:14:25,690
we can partition it by partitioning the instances

1247
01:14:26,670 --> 01:14:29,170
and so what we're looking for in that case is a partition

1248
01:14:29,580 --> 01:14:31,280
of an are if we only see

1249
01:14:31,850 --> 01:14:35,430
a finite number of data points one threatened then we look at the poor partition of

1250
01:14:37,330 --> 01:14:37,950
and d

1251
01:14:39,160 --> 01:14:40,770
you're on on the side i am

1252
01:14:42,520 --> 01:14:45,390
i have a very simple application of clustering so what i did here is

1253
01:14:45,910 --> 01:14:47,920
i just took a very simple image it

1254
01:14:49,500 --> 01:14:50,180
it's basically

1255
01:14:50,890 --> 01:14:51,430
the night sky

1256
01:14:51,980 --> 01:14:54,470
with with some trees down here and so we see this guy

1257
01:14:55,610 --> 01:14:56,600
moon and some trees

1258
01:14:57,320 --> 01:14:59,080
and now we want to segment the image

1259
01:15:00,690 --> 01:15:01,490
using clustering

1260
01:15:02,090 --> 01:15:03,770
and the way this is being done here is

1261
01:15:04,190 --> 01:15:05,940
we take a small sliding window

1262
01:15:06,610 --> 01:15:07,610
passes over the image

1263
01:15:08,190 --> 01:15:09,180
we slide over the image

1264
01:15:09,720 --> 01:15:11,320
and at each location where the window

1265
01:15:11,740 --> 01:15:15,190
is is positioned we extract the pixel values within that window

1266
01:15:15,830 --> 01:15:16,910
and write them into a histogram

1267
01:15:17,430 --> 01:15:21,170
and so we get a histogram associated with each other with each location in the window

1268
01:15:21,690 --> 01:15:22,140
of the window

1269
01:15:23,290 --> 01:15:23,780
and that's it

1270
01:15:24,130 --> 01:15:25,920
gives us a mapping from this image

1271
01:15:26,450 --> 01:15:26,850
in two

1272
01:15:27,470 --> 01:15:28,920
set of histograms into space of

1273
01:15:29,480 --> 01:15:30,710
vectors of histograms basic

1274
01:15:31,550 --> 01:15:32,700
and then we're going to

1275
01:15:33,100 --> 01:15:35,210
apply clustering on this histogram space

1276
01:15:37,770 --> 01:15:41,780
so we get clusters the histograms get sorted into clusters and then what i've done

1277
01:15:41,910 --> 01:15:44,470
is i've taken the first cluster of histograms

1278
01:15:46,830 --> 01:15:49,910
colour each location where one of these histograms was positioned group

1279
01:15:50,550 --> 01:15:51,430
right then

1280
01:15:51,880 --> 01:15:54,230
the other one in green and red so that induces

1281
01:15:54,820 --> 01:15:56,600
basically clusters in feature space

1282
01:15:57,640 --> 01:15:59,020
correspond to segment an image

1283
01:15:59,830 --> 01:16:01,160
there's a very simple application of

1284
01:16:02,760 --> 01:16:05,840
the other clustering methods and what we see here is so there's been talked about

1285
01:16:05,980 --> 01:16:09,160
the number of clusters early on about model selection in this case you

1286
01:16:09,630 --> 01:16:13,400
here we have three clusters and here we have two clusters now image segmentation is

1287
01:16:13,400 --> 01:16:15,500
an ill posed problem and actually people

1288
01:16:16,080 --> 01:16:21,020
if you let people segment images and they totally disagree on how many segmentation usually should be an image

1289
01:16:22,470 --> 01:16:26,110
i think in this case you pretty much everybody would agree that it should probably

1290
01:16:26,130 --> 01:16:28,900
be three segments are that at least the moon should be

1291
01:16:29,500 --> 01:16:30,440
like in with the trees

1292
01:16:31,530 --> 01:16:32,500
so this is probably

1293
01:16:33,230 --> 01:16:35,100
not as good as solution this one

1294
01:16:38,220 --> 01:16:40,520
okay so the way we're going to think about clustering

1295
01:16:42,990 --> 01:16:43,740
in terms of

1296
01:16:44,430 --> 01:16:45,150
mixture models

1297
01:16:47,860 --> 01:16:49,840
mixture model in general looks like this so

1298
01:16:50,380 --> 01:16:51,430
this here is in

1299
01:16:55,800 --> 01:17:00,730
o makes our distribution the distribution given by the mixture model yes so this is the distribution of data

1300
01:17:01,900 --> 01:17:02,440
some have

1301
01:17:04,080 --> 01:17:08,350
the end is something called the mixing measure so this is that are mixing distribution yeah

1302
01:17:08,800 --> 01:17:11,640
so is a measure against which we integrate some component

1303
01:17:12,190 --> 01:17:15,710
think of this for example has got distribution p e of x given theta is

1304
01:17:15,710 --> 01:17:17,210
a gaussian distribution with parameter theta

1305
01:17:17,740 --> 01:17:19,780
and then we have a distribution over theta here

1306
01:17:21,020 --> 01:17:24,540
and there's various things that you can do with for example if you said this to gamma

1307
01:17:25,600 --> 01:17:29,300
and theta is scale parameter of the girls and then you get a student distribution

1308
01:17:30,580 --> 01:17:33,860
but the way we are going to use and clustering is always going to look at

1309
01:17:34,360 --> 01:17:36,600
at a specific form of mixture r this year is

1310
01:17:37,250 --> 01:17:41,030
the distribution of i ninety many or sometimes infinitely many delta spikes

1311
01:17:43,620 --> 01:17:46,430
what mixture models in general always express

1312
01:17:47,740 --> 01:17:50,720
and what i think everybody should always keep in mind when they look mixtures is

1313
01:17:51,350 --> 01:17:52,900
they expressed two-stage sampling

1314
01:17:53,380 --> 01:17:55,440
and so what this mixture model expresses is

1315
01:17:56,220 --> 01:17:58,160
we sample x from this model you

1316
01:17:58,860 --> 01:18:00,720
by first sampling feeder

1317
01:18:01,210 --> 01:18:02,150
from this distribution

1318
01:18:03,590 --> 01:18:04,540
then we plug it into

1319
01:18:05,190 --> 01:18:06,270
into this distribution

1320
01:18:06,690 --> 01:18:07,660
and sample x from that

1321
01:18:10,620 --> 01:18:12,350
so mixture models are two stage sampling

1322
01:18:14,490 --> 01:18:15,800
now a finite mixture model

1323
01:18:16,360 --> 01:18:17,880
in this formulation looks like this

1324
01:18:18,600 --> 01:18:22,780
that's again simply a mixture model but we have a specific form of this mixing measure

1325
01:18:23,200 --> 01:18:24,330
and that's it some

1326
01:18:25,000 --> 01:18:26,540
over delta spikes at

1327
01:18:27,270 --> 01:18:28,630
okay possible locations

1328
01:18:29,070 --> 01:18:30,840
yeah so this a finite number case here

1329
01:18:31,280 --> 01:18:34,940
we have a k eight different values theta on some parameter space

1330
01:18:37,220 --> 01:18:39,750
place delta spike in each of them and then we wait them

1331
01:18:40,160 --> 01:18:43,170
with convex coefficients as a convex combination of delta spikes

1332
01:18:43,170 --> 01:18:46,100
so this is joint work these categories

1333
01:18:46,120 --> 01:18:48,140
i was opposed to ca

1334
01:18:48,160 --> 01:18:52,550
in our lab for one year and and

1335
01:18:54,200 --> 01:18:57,760
here is the problem we are going to address

1336
01:18:57,800 --> 01:19:00,860
so let's think about

1337
01:19:00,890 --> 01:19:03,340
protein protein interaction network

1338
01:19:03,920 --> 01:19:06,190
and you have

1339
01:19:06,210 --> 01:19:09,400
the graph which is partially known

1340
01:19:09,410 --> 01:19:10,830
and this graph

1341
01:19:10,830 --> 01:19:12,080
we present

1342
01:19:12,090 --> 01:19:13,570
physical interactions

1343
01:19:13,590 --> 01:19:15,660
between two proteins

1344
01:19:17,440 --> 01:19:18,600
so you know that

1345
01:19:18,620 --> 01:19:24,980
that's former nodes and another animals point of view you are able to describe your

1346
01:19:24,980 --> 01:19:27,900
pretty by different kind of features

1347
01:19:27,920 --> 01:19:32,420
or a description for instance we are able to say

1348
01:19:32,440 --> 01:19:34,830
what is the function of the protein

1349
01:19:34,870 --> 01:19:36,320
you are able to say

1350
01:19:36,320 --> 01:19:38,210
in in which

1351
01:19:39,660 --> 01:19:42,690
in which place is localized protein

1352
01:19:42,700 --> 01:19:43,820
you also

1353
01:19:43,840 --> 01:19:47,960
going to be able to do you some

1354
01:19:47,980 --> 01:19:50,990
the expression of the gene that

1355
01:19:51,000 --> 01:19:53,290
on code is pretty

1356
01:19:53,390 --> 01:19:55,940
so if you can

1357
01:19:55,960 --> 01:19:57,490
in fact actually rate

1358
01:19:57,500 --> 01:20:01,870
values district of supporting and what we want to do

1359
01:20:01,900 --> 01:20:04,830
we want to use this

1360
01:20:04,840 --> 01:20:08,300
in order to be able to complete the network

1361
01:20:08,350 --> 01:20:10,270
these new proteins

1362
01:20:10,270 --> 01:20:13,240
that have not that have not been used

1363
01:20:13,260 --> 01:20:15,580
in the learning process

1364
01:20:15,600 --> 01:20:17,480
and we want to

1365
01:20:17,720 --> 01:20:24,090
to predict euro between the test data but also between

1366
01:20:24,090 --> 01:20:26,160
the learning

1367
01:20:28,320 --> 01:20:29,870
is it

1368
01:20:38,870 --> 01:20:43,080
they're just interaction physical interaction so there is an edge

1369
01:20:43,090 --> 01:20:50,670
is the two processes can be physically can physically interact with seems that the protein

1370
01:20:50,900 --> 01:20:53,480
can be

1371
01:20:54,820 --> 01:20:56,640
OK to give

1372
01:20:56,700 --> 01:20:59,650
and it's sometimes you have

1373
01:20:59,810 --> 01:21:03,160
of course everyone

1374
01:21:03,190 --> 01:21:06,940
for things that can from big complex

1375
01:21:07,000 --> 01:21:08,500
OK so this is the

1376
01:21:08,540 --> 01:21:09,790
mean the edge

1377
01:21:10,830 --> 01:21:11,480
is there

1378
01:21:11,490 --> 01:21:13,730
a physical interaction between the two

1379
01:21:13,750 --> 01:21:17,120
michael cos on not

1380
01:21:26,070 --> 01:21:32,320
OK i understand

1381
01:21:35,020 --> 01:21:41,320
you go into deeper detail and it's interesting here we just one could the fact

1382
01:21:44,070 --> 01:21:48,180
it's possible to have in fact the physical interaction

1383
01:21:48,240 --> 01:21:53,830
OK but for instance we are not saying that we have in the in the

1384
01:21:53,830 --> 01:21:58,920
sense in fact these four days we will be always three of them

1385
01:21:58,940 --> 01:22:03,430
will be always interacting together so there is no meanings the interesting

1386
01:22:03,440 --> 01:22:04,550
but just

1387
01:22:04,560 --> 01:22:09,640
two of them are OK so what you're saying is interesting if you have the

1388
01:22:09,670 --> 01:22:12,650
point of view

1389
01:22:12,680 --> 01:22:15,570
this is the behavior of the cell

1390
01:22:15,570 --> 01:22:20,690
but here it's it's already a step which interest is about

1391
01:22:20,710 --> 01:22:23,480
we looking at

1392
01:22:23,560 --> 01:22:25,730
the feasibility in fact iterations

1393
01:22:30,820 --> 01:22:37,490
well and not only the physical interaction that is the interactions that that

1394
01:22:37,500 --> 01:22:42,590
so will be meaningful but only one to one another

1395
01:22:42,610 --> 01:22:43,740
we don't

1396
01:22:43,760 --> 01:22:46,090
speak about so the dates

1397
01:22:46,110 --> 01:22:47,550
this abstraction

1398
01:22:47,560 --> 01:22:50,360
so this is a good question

1399
01:22:50,380 --> 01:22:54,100
OK so i know what i'm going to do

1400
01:22:54,110 --> 01:22:55,830
i'm going to

1401
01:22:55,870 --> 01:23:00,790
talk about the tools that we're we are going to use supervised learning can analyse

1402
01:23:00,810 --> 01:23:03,410
output spaces so alpha going to

1403
01:23:03,450 --> 01:23:06,700
so again and again treatment in a new context

1404
01:23:06,710 --> 01:23:09,350
so that going to give you

1405
01:23:09,390 --> 01:23:11,780
one way to solve this problem

1406
01:23:11,810 --> 01:23:15,320
the interest of this this method

1407
01:23:15,350 --> 01:23:22,140
is that it is based on english and so it has some explanatory and interpretability

1408
01:23:22,140 --> 01:23:23,800
of properties

1409
01:23:23,980 --> 01:23:27,140
then we speak a little bit about ensemble methods

1410
01:23:27,160 --> 01:23:31,890
and it's closely related to to that here winning bets closely related to the talk

1411
01:23:31,900 --> 01:23:33,120
the first talk

1412
01:23:33,140 --> 01:23:35,830
the first two don't talk that we had

1413
01:23:35,840 --> 01:23:38,140
a second

1414
01:23:39,820 --> 01:23:42,370
so i'm sorry i remember the name

1415
01:23:42,930 --> 01:23:49,020
he spoke about gradient proscenium thermometer so it's it's related to

1416
01:23:49,040 --> 01:23:52,070
this kind of miss then going to

1417
01:23:52,080 --> 01:23:53,710
directly show you

1418
01:23:53,840 --> 01:23:57,680
experiments with the combination of biological networks

1419
01:23:58,120 --> 01:24:03,020
i don't know if i will stand getting a very much detail to the gradient

1420
01:24:03,020 --> 01:24:09,610
boosting and then i

1421
01:24:09,690 --> 01:24:12,210
OK so here's the problem we want to study

1422
01:24:12,230 --> 01:24:15,370
we have some training sample of object

1423
01:24:15,400 --> 01:24:16,680
o i

1424
01:24:16,690 --> 01:24:18,310
from i equals

1425
01:24:18,320 --> 01:24:19,980
one to n

1426
01:24:20,070 --> 01:24:22,600
it's drawn from a fixed but unknown

1427
01:24:22,630 --> 01:24:24,520
probability distribution

1428
01:24:24,520 --> 01:24:28,090
and what we are going to assume that

1429
01:24:28,110 --> 01:24:29,400
we have to

1430
01:24:29,410 --> 01:24:32,120
representation of the subjects

1431
01:24:32,170 --> 01:24:35,160
one of the condition of the subject

1432
01:24:35,170 --> 01:24:38,080
it's called x

1433
01:24:38,080 --> 01:24:43,570
and it's you can think of expenses as input feature

1434
01:24:43,580 --> 01:24:45,180
vector representation

1435
01:24:45,270 --> 01:24:49,930
and we also assume that we have another representation of the subject which is called

1436
01:24:51,240 --> 01:24:54,910
and why is not necessary vector space

1437
01:24:54,930 --> 01:24:56,350
for instance y

1438
01:24:56,380 --> 01:24:58,590
can be

1439
01:24:58,600 --> 01:25:02,330
so fine but huge set of glass

1440
01:25:02,340 --> 01:25:04,810
of size p

1441
01:25:05,670 --> 01:25:09,230
can be the set of

1442
01:25:11,110 --> 01:25:13,070
we some hierarchical

1443
01:25:13,070 --> 01:25:19,550
relation between classes and and so on so you can imagine any set of

1444
01:25:20,780 --> 01:25:23,850
but that could be interesting for for your application

1445
01:25:25,830 --> 01:25:30,710
this is not the the case in classic supervised learning classic supervised learning usually you

1446
01:25:31,590 --> 01:25:34,760
why which is just

1447
01:25:34,810 --> 01:25:36,090
the discrete set

1448
01:25:36,100 --> 01:25:37,990
of possible classes

1449
01:25:38,000 --> 01:25:39,800
or just

1450
01:25:39,810 --> 01:25:41,400
so the real continued

1451
01:25:41,500 --> 01:25:49,100
all eventually vector space so some zero output is some vector

1452
01:25:50,440 --> 01:25:54,000
so the goal is the same as classic supervised learning

1453
01:25:54,010 --> 01:25:59,790
you want to find some function that is able to predict y from x

1454
01:25:59,850 --> 01:26:01,530
you're going to do this

1455
01:26:01,570 --> 01:26:06,740
the principle is that you want to mine minimize expectation of some loss function that

1456
01:26:06,740 --> 01:26:08,340
you're going to define

1457
01:26:08,360 --> 01:26:14,990
and this is the expedition of the loss taken over the joint distribution of x

1458
01:26:14,990 --> 01:26:15,650
and y

1459
01:26:15,670 --> 01:26:17,490
but as usual

1460
01:26:17,500 --> 01:26:21,800
you're going to replace its expectation by some ontological

1461
01:26:23,950 --> 01:26:26,350
i mean

1462
01:26:26,350 --> 01:26:31,610
and you going to use a different kind of methods and this kind of criteria

1463
01:26:31,700 --> 01:26:33,550
usually based on

1464
01:26:33,640 --> 01:26:38,060
so the top of the complexity of the sister of the function that you want

1465
01:26:38,060 --> 01:26:39,260
in some way

1466
01:26:39,280 --> 01:26:43,150
now maybe do it very quickly and we only need

1467
01:26:43,180 --> 01:26:48,440
we better only need and log comparisons because we know that it's possible

1468
01:26:48,960 --> 01:26:54,060
so the death the tree may not be too big but it has to have

1469
01:26:54,060 --> 01:26:55,980
a huge number leads down there

1470
01:26:56,000 --> 01:26:59,500
mister branch enough to get an factorial leaves because it has to give the right

1471
01:26:59,500 --> 01:27:02,830
answer in all possible inputs

1472
01:27:02,840 --> 01:27:06,370
so this is in some sense counting the number of possible inputs that we have

1473
01:27:06,370 --> 01:27:10,120
to distinguish

1474
01:27:12,310 --> 01:27:16,390
this is an unreleased what we care about is the height of the tree

1475
01:27:16,410 --> 01:27:20,370
so let's call the height of the tree h

1476
01:27:20,390 --> 01:27:24,550
now if i have a tree of height h how many leaves could it have

1477
01:27:24,550 --> 01:27:30,380
is the maximum number of these that could have

1478
01:27:40,370 --> 01:27:45,460
two the h exactly because this is a binary tree and i spelling it correctly

1479
01:27:45,520 --> 01:27:49,640
because we have a binary tree compression trees are always have

1480
01:27:49,670 --> 01:27:51,440
branching factor of two

1481
01:27:51,450 --> 01:27:54,670
number of it has to be announced to the age

1482
01:27:54,790 --> 01:27:58,270
if i have a height h tree

1483
01:27:58,270 --> 01:28:01,390
now this gives me a relation number of these has to be

1484
01:28:01,410 --> 01:28:04,880
great equal to n factorial and the number of this has to be less recall

1485
01:28:04,880 --> 01:28:10,670
the to the age therefore and factorial is less than or equal to the edge

1486
01:28:10,690 --> 01:28:13,810
i got the right

1487
01:28:17,580 --> 01:28:24,020
now again we care about h in terms of factorial so we solve this by

1488
01:28:24,020 --> 01:28:25,680
taking logs

1489
01:28:25,850 --> 01:28:32,590
and i'm also going to

1490
01:28:32,640 --> 01:28:36,420
websites and h is at least log base two

1491
01:28:36,430 --> 01:28:39,190
this is the two over here of then tactoids

1492
01:28:39,210 --> 01:28:41,960
has the property that i'm using here in order to derive

1493
01:28:41,970 --> 01:28:45,110
this inequality from this inequality

1494
01:28:45,130 --> 01:28:48,780
this is the technical side but it's important that you realize there's a technical issue

1495
01:28:56,120 --> 01:29:04,900
the general principle of applying as i have

1496
01:29:05,700 --> 01:29:06,600
the quality

1497
01:29:06,600 --> 01:29:08,720
i do the same thing to both sides

1498
01:29:08,750 --> 01:29:11,980
and hopefully that inequality should still be true but in order for that to be

1499
01:29:11,980 --> 01:29:12,920
the case

1500
01:29:12,940 --> 01:29:15,760
i need the property about that

1501
01:29:15,770 --> 01:29:18,820
operation performance

1502
01:29:19,060 --> 01:29:23,650
has to be a monotonic transformation so here what i'm using is that log is

1503
01:29:23,650 --> 01:29:26,070
monotonically increasing function

1504
01:29:26,090 --> 01:29:34,040
it's important i multiply both sides by minus one which is a decreasing function

1505
01:29:34,060 --> 01:29:38,350
the inequality we have to get flipped so the fact that the article not flipping

1506
01:29:38,350 --> 01:29:39,810
here i need to

1507
01:29:39,820 --> 01:29:42,770
no the log is monotonically increasing efficiency in log

1508
01:29:42,790 --> 01:29:44,170
that's true

1509
01:29:44,190 --> 01:29:46,940
it to be careful here

1510
01:29:49,360 --> 01:29:54,040
we need some approximation of factorial or to figure out what it's log is anyone

1511
01:29:54,040 --> 01:29:59,230
know a good approximation for factorial not necessarily equation but the name

1512
01:29:59,250 --> 01:30:02,370
stirling's formula good all remember sterling

1513
01:30:04,250 --> 01:30:09,650
i just need in some sense of the highest order terms

1514
01:30:09,670 --> 01:30:13,580
i the is that

1515
01:30:13,580 --> 01:30:18,370
so and factorial is at least an hour e to the power

1516
01:30:19,370 --> 01:30:22,710
that's all we need here now i can use properties of logs to bring the

1517
01:30:22,710 --> 01:30:24,160
and outside

1518
01:30:24,180 --> 01:30:28,790
this is and times logo

1519
01:30:28,820 --> 01:30:30,400
and over the

1520
01:30:30,420 --> 01:30:39,840
and then log every i can simplify

1521
01:30:47,130 --> 01:30:52,010
just log of n minus log

1522
01:30:52,020 --> 01:30:55,390
so this is an

1523
01:30:55,470 --> 01:31:00,780
on log n minus log p log p is a constant

1524
01:31:01,560 --> 01:31:05,880
so it's really tiny compared to log which is growing with that

1525
01:31:05,900 --> 01:31:10,410
so this is america among all we care about is that

1526
01:31:10,500 --> 01:31:12,250
leading to

1527
01:31:12,250 --> 01:31:15,960
it's actually fata and morgan but the only interest because we have a greater than

1528
01:31:15,960 --> 01:31:18,300
or equal to all we care about is the

1529
01:31:18,390 --> 01:31:22,850
omega theta here wouldn't give us anything stronger course not all algorithms

1530
01:31:22,850 --> 01:31:24,370
i have an organ

1531
01:31:24,400 --> 01:31:28,620
running time make an organic process some of them do some of them are worse

1532
01:31:28,640 --> 01:31:31,060
we have this proves that all of them

1533
01:31:31,060 --> 01:31:33,030
require high to the reason

1534
01:31:33,040 --> 01:31:35,560
very easy proof once you observe

1535
01:31:35,610 --> 01:31:39,780
the fact that the number of leaves and if you remember sterling one

1536
01:31:39,800 --> 01:31:41,510
so you should know this for

1537
01:31:41,520 --> 01:31:43,250
you can

1538
01:31:43,270 --> 01:31:47,150
show that all sorts of problems require and log time with this kind of technique

1539
01:31:47,450 --> 01:31:49,900
provided you in some kind of decision tree

1540
01:31:49,900 --> 01:31:52,260
here you see

1541
01:31:53,000 --> 01:31:54,870
topics that will be covered by

1542
01:31:54,870 --> 01:31:57,340
this exam

1543
01:31:57,400 --> 01:32:01,680
twice as much material as last time

1544
01:32:01,740 --> 01:32:05,750
and of course the material is also more difficult

1545
01:32:05,750 --> 01:32:09,630
i'll touch upon most of these topics today not all

1546
01:32:09,630 --> 01:32:10,810
and i can go

1547
01:32:10,830 --> 01:32:12,810
into two great depth

1548
01:32:12,830 --> 01:32:15,610
for obvious reasons we don't have the time

1549
01:32:15,650 --> 01:32:18,970
i want to emphasise that what is not covered today

1550
01:32:19,020 --> 01:32:21,080
does not mean at all that it will not be

1551
01:32:21,100 --> 01:32:24,030
on the example

1552
01:32:24,040 --> 01:32:27,680
i want to ask your attention for

1553
01:32:27,690 --> 01:32:28,900
these two

1554
01:32:30,650 --> 01:32:36,180
the work energy theorem tells you that isn't even object moves from a to b

1555
01:32:36,360 --> 01:32:38,570
the work done on that object

1556
01:32:38,640 --> 01:32:42,920
is the kinetic energy at point b minus the kinetic energy at point eight is

1557
01:32:42,920 --> 01:32:44,540
always applies

1558
01:32:45,620 --> 01:32:51,230
four conservative forces like gravitational in spring forces but it also

1559
01:32:51,290 --> 01:32:52,530
all four

1560
01:32:52,560 --> 01:32:54,390
non-conservative forces

1561
01:32:54,400 --> 01:32:56,110
such as friction

1562
01:32:56,200 --> 01:33:00,480
the fraction can remove the kinetic energy

1563
01:33:00,480 --> 01:33:02,730
it turns kinetic energy into heat

1564
01:33:02,730 --> 01:33:07,060
and that is perfectly fine into work energy theorem

1565
01:33:07,060 --> 01:33:10,700
however the conservation of mechanical energy

1566
01:33:10,720 --> 01:33:13,620
only holds for conservative forces

1567
01:33:13,620 --> 01:33:14,700
there you have

1568
01:33:14,720 --> 01:33:19,110
conservation of the sum of potential energy and kinetic energy and now of course you

1569
01:33:19,110 --> 01:33:20,620
cannot afford

1570
01:33:20,720 --> 01:33:22,840
to lose kinetic energy through heat

1571
01:33:22,890 --> 01:33:23,830
because then the

1572
01:33:23,840 --> 01:33:25,640
conservation of mechanical energy

1573
01:33:25,650 --> 01:33:26,810
but not all

1574
01:33:26,830 --> 01:33:30,780
and so that can only be used exclusively in the case

1575
01:33:30,870 --> 01:33:33,560
of conservative forces

1576
01:33:33,590 --> 01:33:34,810
let's start

1577
01:33:34,860 --> 01:33:36,430
with a simple example

1578
01:33:36,480 --> 01:33:39,590
of a inclined

1579
01:33:39,620 --> 01:33:42,060
at an angle theta

1580
01:33:42,700 --> 01:33:46,450
i have here an object's mass and

1581
01:33:46,500 --> 01:33:49,400
friction coefficient kinetic is mu k

1582
01:33:49,420 --> 01:33:51,620
and the static friction coefficient

1583
01:33:52,870 --> 01:33:54,760
u s

1584
01:33:54,840 --> 01:33:58,170
this point here let me point eight

1585
01:33:58,210 --> 01:34:01,050
and at the bottom of the incline can be

1586
01:34:03,040 --> 01:34:04,830
that the distance between them

1587
01:34:04,940 --> 01:34:07,790
along the slope the

1588
01:34:07,850 --> 01:34:11,290
and the first thing that you want to do with a problem like this

1589
01:34:11,350 --> 01:34:14,480
you want to make what we call a free body diagram

1590
01:34:14,540 --> 01:34:19,110
that means you want to draw all the forces on that object

1591
01:34:19,160 --> 01:34:23,390
clearly there is gravity which is mg

1592
01:34:23,440 --> 01:34:24,570
and and then

1593
01:34:24,570 --> 01:34:26,130
there is the

1594
01:34:26,140 --> 01:34:29,790
normal force perpendicular to the surface

1595
01:34:29,880 --> 01:34:32,260
surface pushes up

1596
01:34:32,320 --> 01:34:33,360
we call this

1597
01:34:33,360 --> 01:34:35,190
and the normal force

1598
01:34:35,360 --> 01:34:37,360
object wants to slide down

1599
01:34:37,480 --> 01:34:39,040
friction hold it up

1600
01:34:39,040 --> 01:34:40,520
so us also

1601
01:34:40,610 --> 01:34:42,730
a fictional

1602
01:34:42,790 --> 01:34:44,940
and these are the only three forces

1603
01:34:44,980 --> 01:34:48,540
there are on it so were free body diagram you want know more

1604
01:34:49,490 --> 01:34:51,760
i want you to appreciate the fact

1605
01:34:51,830 --> 01:34:57,420
that the force from the surface onto this object is of course the vectorial some

1606
01:34:57,420 --> 01:34:59,210
between these two

1607
01:34:59,230 --> 01:35:02,360
and that's what's called normally to contact force

1608
01:35:02,410 --> 01:35:08,730
and that contact force better be exactly the same as mg but the opposite direction

1609
01:35:08,730 --> 01:35:11,020
otherwise could never be equilibria

1610
01:35:11,140 --> 01:35:15,160
of course we always permitted in two perpendicular directions

1611
01:35:15,200 --> 01:35:16,540
because of the way

1612
01:35:16,550 --> 01:35:20,100
that we analyse this there is no acceleration in the y direction

1613
01:35:20,140 --> 01:35:21,200
only in

1614
01:35:21,260 --> 01:35:23,990
x direction when it starts moving and that's why

1615
01:35:24,010 --> 01:35:26,380
we played but of course

1616
01:35:26,390 --> 01:35:27,920
the vectorial some

1617
01:35:27,950 --> 01:35:33,490
is really the force with which the surface pushes on to that object

1618
01:35:33,540 --> 01:35:36,960
all right let's suppose now that we increase the angle theta

1619
01:35:37,100 --> 01:35:40,740
until the object starts to slide

1620
01:35:40,760 --> 01:35:41,830
so now

1621
01:35:41,850 --> 01:35:45,770
i'm going to decompose these forces

1622
01:35:45,980 --> 01:35:49,540
x direction IFTM g

1623
01:35:49,550 --> 01:35:50,940
sin theta

1624
01:35:50,980 --> 01:35:54,070
and the component of

1625
01:35:55,200 --> 01:35:58,050
in the y direction equals MG

1626
01:35:58,110 --> 01:36:01,940
cosine phase things there is no acceleration in the y direction

1627
01:36:01,950 --> 01:36:03,490
the normal force

1628
01:36:03,540 --> 01:36:05,160
must be also ng

1629
01:36:05,180 --> 01:36:07,060
cosine theta

1630
01:36:07,100 --> 01:36:08,810
i lifted up the

1631
01:36:08,850 --> 01:36:12,410
inclined to the point that it is just about to start sliding

1632
01:36:12,500 --> 01:36:13,510
and so

1633
01:36:13,570 --> 01:36:15,880
that means that the frictional force

1634
01:36:15,890 --> 01:36:18,390
is the maximum value possible

1635
01:36:18,450 --> 01:36:19,300
which is

1636
01:36:19,320 --> 01:36:21,440
the static friction coefficient

1637
01:36:21,470 --> 01:36:22,890
times and

1638
01:36:22,990 --> 01:36:24,340
and therefore that is

1639
01:36:24,350 --> 01:36:25,430
u of s

1640
01:36:25,440 --> 01:36:26,800
times MG

1641
01:36:26,810 --> 01:36:28,130
i'm the cosine

1642
01:36:28,160 --> 01:36:30,580
off a

1643
01:36:30,630 --> 01:36:34,000
and when will that happened when the frictional force g

1644
01:36:34,010 --> 01:36:38,160
sin theta exactly equal if i go golden one they are further it will start

1645
01:36:38,160 --> 01:36:39,140
to slide

1646
01:36:39,190 --> 01:36:40,630
so that's the case

1647
01:36:40,710 --> 01:36:42,710
then this equals and

1648
01:36:42,760 --> 01:36:44,070
i data

1649
01:36:44,130 --> 01:36:45,900
and so you lose UMG

1650
01:36:45,910 --> 01:36:47,010
and you find

1651
01:36:48,700 --> 01:36:52,510
and the think that's wonderful

1652
01:36:52,510 --> 01:36:53,370
this is the way

1653
01:36:53,460 --> 01:36:58,620
you can measure the static friction coefficient alternatively if you notice static friction coefficient you

1654
01:36:58,620 --> 01:37:00,330
can predict what angle

1655
01:37:00,430 --> 01:37:03,390
that will occur

1656
01:37:05,050 --> 01:37:06,960
at that situation that

1657
01:37:07,010 --> 01:37:08,910
it's just hanging

1658
01:37:08,940 --> 01:37:12,560
by its own so to speak by fingernails

1659
01:37:12,600 --> 01:37:15,680
we touch it very likely would blow on it

1660
01:37:15,720 --> 01:37:18,090
and it starts to slide

1661
01:37:18,140 --> 01:37:18,810
and now

1662
01:37:18,820 --> 01:37:22,890
i'm interested in knowing what the acceleration is downhill

1663
01:37:22,890 --> 01:37:27,550
the reason why it will be accelerated that this

1664
01:37:27,560 --> 01:37:32,370
friction coefficient goes down now to UK so now to the net force

1665
01:37:32,380 --> 01:37:34,700
along the slope into plus x direction

1666
01:37:34,700 --> 01:37:36,400
so i can write down now

1667
01:37:36,490 --> 01:37:38,930
newton's second law and then

1668
01:37:38,970 --> 01:37:39,760
which is

1669
01:37:39,760 --> 01:37:42,770
force the net force in the positive x direction

1670
01:37:42,830 --> 01:37:44,900
would be equal and g

1671
01:37:44,990 --> 01:37:47,150
times the sign of the data

1672
01:37:48,200 --> 01:37:50,630
the frictional force now this comes

1673
01:37:55,400 --> 01:37:57,890
also there

1674
01:37:57,940 --> 01:37:59,210
i lose my

1675
01:37:59,220 --> 01:38:04,490
and so the acceleration in the positive x direction that's the way i find positive

1676
01:38:04,490 --> 01:38:05,700
x direction

1677
01:38:09,010 --> 01:38:10,750
the sign of the data

1678
01:38:11,930 --> 01:38:13,200
u of k

1679
01:38:14,380 --> 01:38:15,280
the cosine

1680
01:38:15,330 --> 01:38:22,010
that's acceleration and now a natural question would be

1681
01:38:22,020 --> 01:38:23,570
one is the speed

1682
01:38:23,570 --> 01:38:26,990
and which is reaches point b

1683
01:38:27,020 --> 01:38:29,750
well we would have done early on in the course

1684
01:38:29,760 --> 01:38:31,010
we would have said

1685
01:38:31,070 --> 01:38:33,180
well finally acceleration

1686
01:38:33,220 --> 01:38:36,570
and i know to distance and i note initial speed is zero

1687
01:38:36,620 --> 01:38:38,870
and clearly the distance l

1688
01:38:38,870 --> 01:38:41,740
the most popular database servers

1689
01:38:41,830 --> 01:38:42,430
and the

1690
01:38:42,450 --> 01:38:46,510
because of course we know that this conference

1691
01:38:47,310 --> 01:38:48,490
you see them

1692
01:38:48,930 --> 01:38:51,160
his ranking authority

1693
01:38:51,180 --> 01:38:54,140
with this goal much be for example

1694
01:38:54,180 --> 01:38:57,930
this one we show you all the right answers for XML

1695
01:38:58,080 --> 01:39:03,950
within the more sub articles XML exploring accepted

1696
01:39:03,990 --> 01:39:07,980
so we have the other are to be able to be on some of the

1697
01:39:07,980 --> 01:39:09,790
world's proper and offers

1698
01:39:09,790 --> 01:39:14,180
this is interesting is this one of the first time i chose this was the

1699
01:39:14,180 --> 01:39:16,680
and i see the end result

1700
01:39:16,700 --> 01:39:20,740
accident they by the third of the people

1701
01:39:20,760 --> 01:39:23,080
give you know speech

1702
01:39:23,080 --> 01:39:29,350
the web search can handling where is my last before the data mining those are

1703
01:39:30,310 --> 01:39:33,040
so all this time but you

1704
01:39:33,540 --> 01:39:40,930
but these are the guys at number one x and that's why we fight

1705
01:39:40,930 --> 01:39:42,120
of course sources

1706
01:39:44,910 --> 01:39:50,790
with this approach a lot of changes not only rank

1707
01:39:51,240 --> 01:39:53,620
like the paper

1708
01:39:53,640 --> 01:39:57,990
this one you can also read is that

1709
01:40:00,350 --> 01:40:01,270
if not for

1710
01:40:02,600 --> 01:40:03,930
well you're

1711
01:40:03,970 --> 01:40:05,560
get three clusters

1712
01:40:06,200 --> 01:40:07,970
the members the system

1713
01:40:09,640 --> 01:40:14,370
image processing we don't know anything about them

1714
01:40:14,390 --> 01:40:17,470
but we know the past take back

1715
01:40:17,470 --> 01:40:18,810
who is the

1716
01:40:18,810 --> 01:40:21,140
according to

1717
01:40:21,720 --> 01:40:24,450
this is the wrong way is by

1718
01:40:25,120 --> 01:40:26,260
i don't know whether you

1719
01:40:27,830 --> 01:40:32,350
by different boxes what is by a famous i think it's something

1720
01:40:32,350 --> 01:40:34,830
then you

1721
01:40:35,810 --> 01:40:37,100
one our

1722
01:40:37,150 --> 01:40:42,560
and this one is likely to remain so this is capital lot buildings

1723
01:40:43,930 --> 01:40:50,370
this rally and to some of the stuff that i don't know but at least

1724
01:40:52,310 --> 01:40:54,220
partition the brain

1725
01:40:54,220 --> 01:40:58,180
so we have to put this one system

1726
01:40:58,330 --> 01:40:59,450
what is it

1727
01:40:59,580 --> 01:41:01,430
all i next

1728
01:41:02,760 --> 01:41:05,010
according to the rescue

1729
01:41:05,200 --> 01:41:08,100
then use tools of it by

1730
01:41:08,120 --> 01:41:10,510
the interesting thing about c

1731
01:41:10,540 --> 01:41:18,510
as you can read authors or with different keywords a on this article saying know

1732
01:41:18,510 --> 01:41:22,660
what is interesting offers conferences so some

1733
01:41:24,060 --> 01:41:25,350
this is

1734
01:41:25,370 --> 01:41:32,530
we put it on the web if you have internet access google like i do

1735
01:41:32,720 --> 01:41:37,490
i remember last year hector garcia molina who was

1736
01:41:37,540 --> 01:41:39,430
stanford prison

1737
01:41:39,430 --> 01:41:43,970
well he was invited talk speaker UIC

1738
01:41:44,010 --> 01:41:46,620
it possible to my office was

1739
01:41:46,720 --> 01:41:50,640
so we got physical system or something like

1740
01:41:50,640 --> 01:41:52,720
says you can afford

1741
01:41:52,740 --> 01:41:58,580
he said i wasn't that stands for all the data that is

1742
01:41:58,600 --> 01:42:00,970
he had theories

1743
01:42:00,990 --> 01:42:03,060
eleven one

1744
01:42:03,080 --> 01:42:08,600
that means that black man said something pretty interesting but trust

1745
01:42:08,720 --> 01:42:15,200
one is because the stanford professor so you know

1746
01:42:15,260 --> 01:42:18,310
exactly what this this is not enough

1747
01:42:18,350 --> 01:42:19,140
this is not

1748
01:42:19,140 --> 01:42:21,180
nothing about them

1749
01:42:23,220 --> 01:42:31,370
this is about that class was also a paper published by joan she be last

1750
01:42:31,370 --> 01:42:33,490
year's conference

1751
01:42:33,510 --> 01:42:35,010
it was not

1752
01:42:36,760 --> 01:42:41,350
with this heterogeneous networks can be very interesting

1753
01:42:41,370 --> 01:42:43,970
now i'm going to do

1754
01:42:44,030 --> 01:42:48,430
but things on the homogeneous then these before

1755
01:42:48,490 --> 01:42:52,370
actually there are lots of people across networks

1756
01:42:52,370 --> 01:42:53,640
these are about

1757
01:42:53,660 --> 01:42:55,390
homogeneous network

1758
01:42:55,410 --> 01:42:59,850
show you a few interesting one

1759
01:42:59,870 --> 01:43:03,290
one interesting one there's is only one

1760
01:43:03,930 --> 01:43:08,370
the cost of actually started with this

1761
01:43:08,370 --> 01:43:10,470
was jennifer widom

1762
01:43:10,490 --> 01:43:12,160
OK stand for

1763
01:43:12,660 --> 01:43:16,010
she was on and just

1764
01:43:16,040 --> 01:43:20,100
this changed about a month ago

1765
01:43:20,790 --> 01:43:22,010
she got paper

1766
01:43:22,010 --> 01:43:26,650
this is all of this conference was a conference proceedings

1767
01:43:27,910 --> 01:43:29,990
OK based on this new

1768
01:43:31,060 --> 01:43:32,330
no computation

1769
01:43:32,350 --> 01:43:34,350
you the cluster as well

1770
01:43:34,510 --> 01:43:41,680
but is one problem with this is very expensive like i said it

1771
01:43:41,700 --> 01:43:42,370
you know

1772
01:43:42,390 --> 01:43:45,290
the generalized is this one

1773
01:43:45,310 --> 01:43:46,470
the former pharmacist

1774
01:43:46,490 --> 01:43:49,700
two of the system similar of the judges similarity

1775
01:43:49,720 --> 01:43:51,660
if you look at the edits

1776
01:43:51,700 --> 01:43:52,600
if they one

1777
01:43:52,600 --> 01:43:54,490
common is of course a similar

1778
01:43:54,510 --> 01:43:55,720
if you look at this

1779
01:43:55,720 --> 01:43:57,720
link of that

1780
01:43:57,740 --> 01:44:00,160
there a link out there

1781
01:44:00,200 --> 01:44:02,700
similar to keep going

1782
01:44:02,720 --> 01:44:03,330
you know

1783
01:44:03,330 --> 01:44:05,240
further and further

1784
01:44:05,330 --> 01:44:07,080
also have a company

1785
01:44:07,080 --> 01:44:09,370
but the problem for this algorithm

1786
01:44:09,430 --> 01:44:12,930
you just want to use a and b

1787
01:44:12,930 --> 01:44:14,700
but expensive

1788
01:44:14,700 --> 01:44:17,580
because you computer and the similarity

1789
01:44:17,600 --> 01:44:21,220
you look at the end of the

1790
01:44:21,850 --> 01:44:24,790
this is the whole sigma

1791
01:44:24,810 --> 01:44:29,060
what about sigma is the only thing is that many of the fact that many

1792
01:44:29,060 --> 01:44:31,200
of the things we look for everybody

1793
01:44:31,220 --> 01:44:32,600
we have them today

1794
01:44:32,830 --> 01:44:37,390
that's quite categorically don't think about it one more level one level

1795
01:44:38,810 --> 01:44:41,080
if you look at this one all

1796
01:44:41,100 --> 01:44:43,720
this is not very efficient

1797
01:44:43,770 --> 01:44:45,760
was very expensive

1798
01:44:45,760 --> 01:44:47,620
then the problem is

1799
01:44:47,640 --> 01:44:51,030
how can we make it cheaper without using

1800
01:44:51,040 --> 01:44:52,200
without using

1801
01:44:52,220 --> 01:44:53,930
the accuracy of what

1802
01:44:53,950 --> 01:44:55,910
but that's the problem

1803
01:44:55,930 --> 01:44:59,450
the problem was first hand before joining

1804
01:45:00,600 --> 01:45:02,720
it was first attacked by the

1805
01:45:03,970 --> 01:45:06,200
he got sick he

1806
01:45:06,220 --> 01:45:07,850
it was the

1807
01:45:07,910 --> 01:45:11,410
he served one

1808
01:45:12,620 --> 01:45:14,740
that year first year

1809
01:45:16,810 --> 01:45:18,120
this one

1810
01:45:18,870 --> 01:45:20,830
this is one of these were later

1811
01:45:20,830 --> 01:45:22,370
just in this lecture

1812
01:45:23,290 --> 01:45:28,830
to our approach four five is very interesting is just one of them

1813
01:45:28,850 --> 01:45:32,220
what is of the nation is

1814
01:45:34,140 --> 01:45:36,100
if you want to study makes

1815
01:45:36,220 --> 01:45:42,270
one study leave all the objects or the objects what want to study is something

1816
01:45:42,290 --> 01:45:42,450
you know

1817
01:45:43,510 --> 01:45:50,310
for example you may go by another five year-old btselem similarity between this so you

1818
01:45:50,310 --> 01:45:51,470
in the results

1819
01:45:51,480 --> 01:45:54,880
here is the asymptotic

1820
01:45:55,000 --> 01:45:57,280
i mean square in role

1821
01:45:57,340 --> 01:46:01,790
the expectation of the difference the square difference

1822
01:46:03,820 --> 01:46:08,500
what is what is important in this relation is that i have this

1823
01:46:08,510 --> 01:46:14,040
two dams the bias term and defiance down the first one is the variance expansion

1824
01:46:14,470 --> 01:46:16,450
the basic pension

1825
01:46:16,450 --> 01:46:23,240
i don't want to comment at all each what is inside each but the important

1826
01:46:23,240 --> 01:46:26,070
thing is to check

1827
01:46:26,160 --> 01:46:32,420
the kind of rates of convergence we have football clubs so k is the kernel

1828
01:46:32,430 --> 01:46:37,070
function and sigma and is the band's parameters using parameter

1829
01:46:37,100 --> 01:46:41,620
that appears when you apply some kind of estimation

1830
01:46:41,700 --> 01:46:49,890
and you see that for the barbarians them we have one over NC nine rate

1831
01:46:49,890 --> 01:46:55,340
of convergence and for the bias then we have a rating in sigmund to support

1832
01:46:56,340 --> 01:46:58,500
so if we compare

1833
01:46:58,510 --> 01:47:04,480
that's this rate is the rate of ten for the estimated conditional expectation to the

1834
01:47:04,480 --> 01:47:09,480
true one use in particular that he said was gain in defiance

1835
01:47:09,570 --> 01:47:16,550
usually for the conditional expectation you have wait in one over in the main square

1836
01:47:16,580 --> 01:47:17,400
so by

1837
01:47:17,700 --> 01:47:21,490
solving the differential equation you have lost square here

1838
01:47:21,520 --> 01:47:25,580
and you have this and this and wait for the basis to

1839
01:47:25,620 --> 01:47:31,790
so there is a again in the bias that appears very quickly and is again

1840
01:47:31,800 --> 01:47:34,580
is due to the fact that

1841
01:47:37,330 --> 01:47:41,440
you can transform your initial function and

1842
01:47:41,450 --> 01:47:45,700
which depends on two arguments into a function that depends on only one argument so

1843
01:47:45,700 --> 01:47:53,720
there again dimension and find is getting dimension in this in this way convergence

1844
01:47:56,870 --> 01:47:59,310
it's really quality

1845
01:47:59,730 --> 01:48:01,980
you can do for you

1846
01:48:01,990 --> 01:48:05,440
you have the depend on

1847
01:48:07,540 --> 01:48:11,490
you know differential equation which is one

1848
01:48:11,490 --> 01:48:18,150
i have a very very very very low resolution one of the major

1849
01:48:20,240 --> 01:48:23,020
it's a be done

1850
01:48:23,730 --> 01:48:30,080
you can see that the end of its life just exists for so long that

1851
01:48:30,090 --> 01:48:32,740
we love each sequel to fix

1852
01:48:33,380 --> 01:48:37,660
so lambda fixistas into one and c

1853
01:48:37,670 --> 01:48:46,150
so then you have a well-defined meaning of what it means is right in this

1854
01:48:46,150 --> 01:48:50,180
result i assume that n one depending on both arguments

1855
01:48:50,230 --> 01:48:53,570
OK for you to confirm that

1856
01:48:53,620 --> 01:48:55,480
i i suppose

1857
01:48:55,490 --> 01:48:59,990
the front and dependency in london

1858
01:49:00,600 --> 01:49:05,740
if of course and the land that it seems a lot of minor phonetic and

1859
01:49:05,890 --> 01:49:11,880
just want to

1860
01:49:11,890 --> 01:49:16,640
OK so this is for these if this first

1861
01:49:16,660 --> 01:49:22,850
expansion and this the second result going to show

1862
01:49:24,370 --> 01:49:26,770
uses the

1863
01:49:26,820 --> 01:49:30,970
the fact that i also have the game in regularity

1864
01:49:30,970 --> 01:49:32,990
since lambda should be

1865
01:49:33,600 --> 01:49:39,480
since then and since i solid differential equation and i expect to obtain these game

1866
01:49:39,480 --> 01:49:40,820
in the bias term

1867
01:49:40,840 --> 01:49:46,070
so the idea is to assume that instead of having the classical canon of order

1868
01:49:46,810 --> 01:49:49,940
i can assume that i have the kind of all the free

1869
01:49:49,980 --> 01:49:54,720
and without imposing some further and stronger assumptions on the form of an

1870
01:49:54,750 --> 01:49:58,100
i can go further in the taylor expansion of the body there

1871
01:49:58,120 --> 01:50:05,820
to get to achieve better rate of convergence so that's subjective of next

1872
01:50:05,840 --> 01:50:07,320
one of i things

1873
01:50:09,030 --> 01:50:12,040
the next result

1874
01:50:12,150 --> 01:50:22,980
so this is again i mean square there are expansion we i would still have

1875
01:50:24,950 --> 01:50:29,930
audience them in the biased and what's changes that is that they assume that it

1876
01:50:31,160 --> 01:50:33,440
mike cannot function is of all the free

1877
01:50:33,460 --> 01:50:37,180
so obviously if you have a function of all the free

1878
01:50:37,230 --> 01:50:40,170
cannot function of all the way you can go further

1879
01:50:40,190 --> 01:50:44,710
in the taylor expansion for the bias down but normally you have to impose some

1880
01:50:44,710 --> 01:50:51,680
stronger assumptions on your initial function and that's not the case here it's simply due

1881
01:50:51,680 --> 01:50:53,680
to to the fact that i sort of

1882
01:50:53,690 --> 01:51:01,660
and i differential equations so i have improved the way improves gravity and

1883
01:51:01,670 --> 01:51:03,980
the result is that i have

1884
01:51:04,020 --> 01:51:08,230
the rate of convergence for the bias term in sigma politics

1885
01:51:08,230 --> 01:51:11,100
so i have i can

1886
01:51:11,750 --> 01:51:18,960
sure this game in regularity in this by the by this extension

1887
01:51:18,990 --> 01:51:23,290
so to summarize article

1888
01:51:23,300 --> 01:51:28,050
this is the results

1889
01:51:28,070 --> 01:51:33,560
what about this change to the estimation of the conditional expectation what this change in

1890
01:51:33,560 --> 01:51:35,420
solving this

1891
01:51:35,620 --> 01:51:37,940
initial reports this problem

1892
01:51:37,950 --> 01:51:40,630
first i have

1893
01:51:40,750 --> 01:51:46,430
i have shown you that there is game mentioned by applying the integral right

1894
01:51:46,450 --> 01:51:48,700
and also we can prove game

1895
01:51:50,600 --> 01:51:54,760
we are able to expand the bias them as if

1896
01:51:54,780 --> 01:51:58,060
we were

1897
01:52:01,620 --> 01:52:03,600
continuously differentiable of all the free

1898
01:52:03,620 --> 01:52:06,550
without imposing it initially

1899
01:52:06,920 --> 01:52:09,880
and that leads to

1900
01:52:12,640 --> 01:52:14,140
this last


1
00:00:00,000 --> 00:00:00,750
multiple of

2
00:00:04,020 --> 00:00:05,170
so this is an integer

3
00:00:06,020 --> 00:00:06,250
and so

4
00:00:07,150 --> 00:00:08,170
at any given point

5
00:00:09,610 --> 00:00:10,420
would be an integer

6
00:00:11,860 --> 00:00:12,460
it's a very good

7
00:00:14,230 --> 00:00:16,040
we want to show it is because zero

8
00:00:16,860 --> 00:00:21,070
it would be sufficient to show that it is less than one in absolute value

9
00:00:23,690 --> 00:00:25,690
like in this case can do a bit more

10
00:00:27,270 --> 00:00:29,170
we can select a good ground point

11
00:00:30,300 --> 00:00:31,320
and then it is easy to show

12
00:00:31,840 --> 00:00:34,190
that in this case has this morning

13
00:00:34,860 --> 00:00:36,090
should be an even number

14
00:00:38,880 --> 00:00:41,420
and so in order to show that this is in fact zero

15
00:00:42,730 --> 00:00:45,520
it would be sufficient to show that is an absurd vandalism

16
00:00:48,670 --> 00:00:49,340
how to do it

17
00:00:53,210 --> 00:00:54,000
we start from some

18
00:00:54,500 --> 00:00:55,270
good green point

19
00:00:56,900 --> 00:00:57,520
next point

20
00:00:58,050 --> 00:00:58,840
might be known gold

21
00:00:59,320 --> 00:01:00,550
and we need to make some shift

22
00:01:01,940 --> 00:01:03,670
next points could be but also

23
00:01:04,860 --> 00:01:08,230
but sooner or later will find another group with important

24
00:01:09,520 --> 00:01:10,070
and in fact

25
00:01:10,610 --> 00:01:11,360
there you really

26
00:01:11,840 --> 00:01:12,770
the good ground points

27
00:01:13,710 --> 00:01:14,730
because of and so

28
00:01:15,300 --> 00:01:15,690
we really

29
00:01:16,400 --> 00:01:18,170
this is other small number

30
00:01:21,110 --> 00:01:21,650
and here

31
00:01:22,190 --> 00:01:22,610
is a man

32
00:01:23,250 --> 00:01:24,020
idea of children

33
00:01:24,840 --> 00:01:25,980
he was able to one

34
00:01:26,670 --> 00:01:27,400
the value of x

35
00:01:28,020 --> 00:01:29,110
from up from below

36
00:01:31,090 --> 00:01:31,400
why is

37
00:01:32,070 --> 00:01:33,780
his version of little theorem

38
00:01:34,650 --> 00:01:35,550
last this

39
00:01:36,050 --> 00:01:36,860
additional summons

40
00:01:39,550 --> 00:01:41,500
if you like and they are small

41
00:01:42,170 --> 00:01:45,400
what if you listen to give greater than minus two

42
00:01:50,210 --> 00:01:51,360
the idea was that

43
00:01:52,070 --> 00:01:54,800
originally had to very different techniques

44
00:01:56,270 --> 00:01:59,730
for calculating the number of zeros in the rectangle and on the critical line

45
00:02:00,800 --> 00:02:03,000
in two and found it is in the competition

46
00:02:04,090 --> 00:02:05,090
is a computationally

47
00:02:06,480 --> 00:02:08,570
how to use the same shift age

48
00:02:09,590 --> 00:02:12,730
four bounding in the numbers zeros inside the tender

49
00:02:22,150 --> 00:02:23,090
this was the

50
00:02:23,780 --> 00:02:24,420
content of his

51
00:02:26,110 --> 00:02:27,440
the first part of his statement

52
00:02:28,520 --> 00:02:29,780
and the second part

53
00:02:30,750 --> 00:02:32,570
is a report about the competition

54
00:02:33,880 --> 00:02:35,170
the second part is nowadays

55
00:02:35,730 --> 00:02:37,130
i mean of historical interest

56
00:02:38,050 --> 00:02:40,840
but nevertheless it is of interest it interesting to see

57
00:02:41,590 --> 00:02:43,020
conditions in which

58
00:02:43,820 --> 00:02:44,250
during the

59
00:02:46,340 --> 00:02:48,270
she gives a lot of people about how

60
00:02:48,770 --> 00:02:49,710
computation was done

61
00:02:50,500 --> 00:02:51,500
because that time

62
00:02:52,650 --> 00:02:53,820
it was a new zealand

63
00:02:54,770 --> 00:02:55,380
he wrote

64
00:02:56,400 --> 00:02:59,090
that if you fix momentum if the that

65
00:02:59,210 --> 00:03:00,770
documentation is the in this book

66
00:03:02,860 --> 00:03:03,730
he describes the

67
00:03:06,460 --> 00:03:07,400
this there's a mission

68
00:03:08,110 --> 00:03:08,960
as of two kinds

69
00:03:09,500 --> 00:03:11,820
moments electronic and magnetic storage

70
00:03:13,250 --> 00:03:15,940
the electronic storage consisted of four pages

71
00:03:16,590 --> 00:03:19,610
issues sorted the length of forty binary digits

72
00:03:20,670 --> 00:03:21,800
the average consisted

73
00:03:22,610 --> 00:03:23,770
of a certain number of the

74
00:03:24,770 --> 00:03:26,690
issue of the pages of similar capacity

75
00:03:27,550 --> 00:03:29,770
all of items is that it's available

76
00:03:30,170 --> 00:03:31,670
but is it the funds conditions

77
00:03:33,460 --> 00:03:36,340
you can calculate how many pages you will be able to put

78
00:03:36,840 --> 00:03:37,540
on the left

79
00:03:37,920 --> 00:03:38,840
memory in your book

80
00:03:43,340 --> 00:03:46,250
she gives a detailed description of how the memory was used

81
00:03:47,400 --> 00:03:49,320
one page four categories maturity and

82
00:03:50,170 --> 00:03:51,900
four pages for table flickr reasons

83
00:03:53,380 --> 00:03:55,840
two page authority for calculating such terms

84
00:03:57,710 --> 00:03:58,610
one the pages

85
00:03:59,170 --> 00:03:59,820
important in

86
00:04:01,170 --> 00:04:02,780
two pages four out thirteen

87
00:04:04,020 --> 00:04:05,750
appellate court is interest and

88
00:04:10,210 --> 00:04:13,360
the present result consisted mainly of numbers

89
00:04:13,860 --> 00:04:15,320
in the scale of thirty two

90
00:04:16,380 --> 00:04:19,480
not this amount of time that we see this among but thirty two

91
00:04:21,520 --> 00:04:25,920
do not found it necessary to use a table of correspondence between the words and symbols

92
00:04:26,980 --> 00:04:28,090
but in to the printer

93
00:04:28,820 --> 00:04:30,820
somehow the distance used for themselves

94
00:04:32,540 --> 00:04:33,020
and here right

95
00:04:34,130 --> 00:04:36,090
the right the student himself

96
00:04:36,540 --> 00:04:39,690
with content to see the results of the scale of the two

97
00:04:40,540 --> 00:04:42,210
this species sufficiently formula

98
00:04:44,230 --> 00:04:48,340
that is not as it all was because the punched tape was five

99
00:04:49,000 --> 00:04:49,610
roles and so

100
00:04:58,730 --> 00:05:02,820
it seems that student was not satisfied with other computations

101
00:05:07,050 --> 00:05:08,000
although the details

102
00:05:08,770 --> 00:05:09,750
all the out

103
00:05:10,540 --> 00:05:11,090
and this light

104
00:05:12,840 --> 00:05:13,520
they told

105
00:05:13,940 --> 00:05:16,770
thousand four hundred fourteen thousand dealers

106
00:05:17,880 --> 00:05:19,170
thousands from date

107
00:05:20,090 --> 00:05:21,420
was investigated and ship

108
00:05:22,300 --> 00:05:25,020
but unfortunately at this point the machine broke down

109
00:05:26,250 --> 00:05:27,630
and no further work was done

110
00:05:29,300 --> 00:05:31,960
furthermore this interval was subsequently followed

111
00:05:32,400 --> 00:05:33,380
there have been around

112
00:05:33,710 --> 00:05:34,090
is that on

113
00:05:35,960 --> 00:05:39,480
and the most that can be consequently be asserted with certainty

114
00:05:41,320 --> 00:05:43,690
the zeros lie on the critical line

115
00:05:44,380 --> 00:05:45,420
after equal to

116
00:05:46,860 --> 00:05:47,710
five hundred forty

117
00:05:48,590 --> 00:05:50,230
this was given instigated itself

118
00:05:50,960 --> 00:05:51,400
as far

119
00:05:51,960 --> 00:05:54,000
as thousand four hundred sixty eight

120
00:05:55,610 --> 00:05:56,730
and during cold

121
00:05:57,540 --> 00:05:59,210
there no visible advance

122
00:06:02,940 --> 00:06:03,750
if you look

123
00:06:04,520 --> 00:06:05,150
the table

124
00:06:06,050 --> 00:06:07,110
really not impressive

125
00:06:09,670 --> 00:06:10,190
he after

126
00:06:10,690 --> 00:06:11,170
the kitchen

127
00:06:11,170 --> 00:06:12,010
in the

128
00:06:12,020 --> 00:06:14,220
computation in the rest of you

129
00:06:15,480 --> 00:06:18,860
i consider the value of the input

130
00:06:18,900 --> 00:06:20,520
in front

131
00:06:21,760 --> 00:06:23,880
i am i consider here

132
00:06:23,940 --> 00:06:28,340
what's the ultimate and me OK you can for example

133
00:06:32,680 --> 00:06:34,730
q prime good and here too

134
00:06:34,740 --> 00:06:40,000
few seconds that was what the ultimate and here OK i may have

135
00:06:41,290 --> 00:06:43,260
other labels

136
00:06:43,340 --> 00:06:46,870
in order to keep moving here you have to check with the automaton allows me

137
00:06:46,870 --> 00:06:49,530
to do and i could try

138
00:06:52,370 --> 00:06:55,430
so the game i'm gonna

139
00:06:55,430 --> 00:06:59,850
for requests in a way that

140
00:07:01,430 --> 00:07:04,810
i will be for the moment is not necessarily finite state

141
00:07:06,140 --> 00:07:09,720
but if i assume that that's my game will be fine

142
00:07:10,960 --> 00:07:15,140
so let's take entity penetrate the following

143
00:07:21,360 --> 00:07:22,580
in the way

144
00:07:22,600 --> 00:07:24,560
there will be put together

145
00:07:24,690 --> 00:07:28,400
so there was a sense that

146
00:07:29,790 --> 00:07:33,150
four player zero position

147
00:07:34,250 --> 00:07:37,170
in both trees have been three

148
00:07:39,590 --> 00:07:41,560
so i mean position w

149
00:07:42,570 --> 00:07:45,430
on the left

150
00:07:46,720 --> 00:07:48,730
which is here

151
00:07:48,780 --> 00:07:51,240
and that is called king

152
00:07:54,390 --> 00:07:59,180
so what has a position in the game is OK

153
00:08:00,590 --> 00:08:06,940
in position while you know w in my dream i have the input

154
00:08:09,540 --> 00:08:14,560
and also the current state of mind this is my might not play zero he

155
00:08:14,560 --> 00:08:16,790
has to make a choice

156
00:08:18,080 --> 00:08:19,700
which is the

157
00:08:21,790 --> 00:08:24,860
to choose one possible

158
00:08:24,870 --> 00:08:26,580
the tournament

159
00:08:28,330 --> 00:08:29,470
the automaton

160
00:08:29,480 --> 00:08:32,490
he has so this is q right in my room

161
00:08:33,610 --> 00:08:36,900
so when you have q and you need a you may

162
00:08:36,950 --> 00:08:40,260
also do something else like q two

163
00:08:41,440 --> 00:08:46,680
ten i don't know ways to choose the transition so players you would choose the

164
00:08:51,710 --> 00:08:53,130
she would take

165
00:08:53,130 --> 00:08:56,520
the transition from the automaton which is given here

166
00:08:57,850 --> 00:09:02,170
when you're going to q you read this one you may the left child to

167
00:09:02,170 --> 00:09:04,730
this state and go down to the light chain

168
00:09:05,910 --> 00:09:08,910
the right the basically to the transition

169
00:09:10,190 --> 00:09:11,640
that might be many

170
00:09:14,480 --> 00:09:16,350
two position

171
00:09:16,390 --> 00:09:17,940
the other player

172
00:09:18,000 --> 00:09:22,820
the same spirit as before so what you have here is you choose

173
00:09:24,090 --> 00:09:28,700
what i mean w

174
00:09:28,750 --> 00:09:33,000
so that's the position in europe if him

175
00:09:34,220 --> 00:09:36,940
nine which are the

176
00:09:38,090 --> 00:09:44,110
so you remember where you are the label and transition you choose so it's q

177
00:09:45,360 --> 00:09:48,210
and one of the most successful

178
00:09:49,480 --> 00:09:53,770
OK you rewrite w but i mean we can forget about it in a way

179
00:09:54,000 --> 00:09:58,390
to get i mean it's the it's irrelevant transition it's an entire transition

180
00:09:59,560 --> 00:10:01,900
automaton so that's really

181
00:10:03,170 --> 00:10:07,080
and elements of the transition state of the art and that's one of europe and

182
00:10:07,080 --> 00:10:08,510
so you're like this

183
00:10:10,430 --> 00:10:13,470
and this is one maybe many

184
00:10:14,670 --> 00:10:15,740
as many

185
00:10:17,040 --> 00:10:19,220
i mean positions you may find

186
00:10:20,490 --> 00:10:24,110
from state q one you read labelled t of w

187
00:10:25,340 --> 00:10:28,010
and here it's open to play

188
00:10:28,070 --> 00:10:30,400
and he was OK choose

189
00:10:31,600 --> 00:10:33,400
to go down to the US

190
00:10:34,370 --> 00:10:37,100
so true so it will take you to

191
00:10:38,280 --> 00:10:41,850
if he chooses to go down to the left subtree players zero

192
00:10:43,130 --> 00:10:45,460
you're in

193
00:10:50,930 --> 00:10:54,010
right left on this

194
00:10:55,290 --> 00:10:56,520
cross fingers

195
00:11:00,270 --> 00:11:03,460
so we go down if he chooses this here

196
00:11:03,600 --> 00:11:07,180
we go down here the label that we have

197
00:11:08,310 --> 00:11:09,430
and it's again

198
00:11:09,480 --> 00:11:13,850
the players you want to do something but you're one of those which is this

199
00:11:14,840 --> 00:11:18,180
this sorry i primal

200
00:11:19,370 --> 00:11:20,900
that's why you are

201
00:11:21,000 --> 00:11:24,710
so and i have to say is all from q prime with reading the labels

202
00:11:24,710 --> 00:11:28,720
get by just something together the values of this thing here in this in this

203
00:11:28,720 --> 00:11:33,220
case is going to be a piecewise cubic because these things are cubic in the

204
00:11:33,230 --> 00:11:35,820
in the in the test case

205
00:11:37,140 --> 00:11:42,090
so there's a little that's slight caveat here and that is that the regularizer if

206
00:11:42,100 --> 00:11:46,300
you look at the regularizer that we start with the regularizer here actually has the

207
00:11:46,320 --> 00:11:49,790
radio station coefficient of zero for all linear functions

208
00:11:49,830 --> 00:11:53,440
right so it doesn't it doesn't penalise linear functions at all

209
00:11:53,490 --> 00:11:57,770
so actually it doesn't what we want to do is we want to think of

210
00:11:57,770 --> 00:12:01,620
this as being an energy function and say well what is the prior that corresponds

211
00:12:01,630 --> 00:12:05,850
to the energy function of course that's not normalizable because it doesn't say anything about

212
00:12:05,850 --> 00:12:07,560
the linear functions

213
00:12:07,570 --> 00:12:11,900
so we just add the linear functions that there's a little bit of algebra involved

214
00:12:11,900 --> 00:12:13,690
in that not worry about that

215
00:12:13,720 --> 00:12:15,510
here's an example

216
00:12:15,520 --> 00:12:18,030
so here are some some data points

217
00:12:18,080 --> 00:12:21,790
and then i just plug into the casting process

218
00:12:21,790 --> 00:12:25,460
OK and then i can make my predictions and the mean prediction is piecewise cubic

219
00:12:25,990 --> 00:12:30,160
polynomial but i get something extra here i get to get out of us

220
00:12:30,190 --> 00:12:34,110
i'd like can say something about my my confidence and also like get way of

221
00:12:34,110 --> 00:12:35,880
figuring out what land should be

222
00:12:35,930 --> 00:12:40,100
which is usually something that blind model wouldn't tell you

223
00:12:40,150 --> 00:12:44,850
you know how to trade off the regularizer in the and the data fit but

224
00:12:44,850 --> 00:12:50,390
here this is the best way of doing that by just optimizing the marginal likelihood

225
00:12:50,740 --> 00:12:55,170
there's something slightly odd about this kind of process and that is that the the

226
00:12:55,170 --> 00:13:00,580
individual functions if you draw a function from from this prior because it's the composition

227
00:13:00,580 --> 00:13:01,550
of these little

228
00:13:01,560 --> 00:13:05,980
these little random functions then those functions are actually

229
00:13:07,750 --> 00:13:10,270
nondifferentiable with probability one

230
00:13:10,440 --> 00:13:15,150
so these are quite strange functions it just happens when you average overall and then

231
00:13:15,150 --> 00:13:16,630
you get a polynomial

232
00:13:16,750 --> 00:13:20,490
so the mean function is a very simple function but actually the

233
00:13:20,500 --> 00:13:25,610
the the individual functions from the posterior distribution over functions are quite strange functions and

234
00:13:25,610 --> 00:13:30,220
also it it if you think of then you know what my assumption about the

235
00:13:30,220 --> 00:13:34,490
problem when i start with my prior distribution on my prior distribution is a big

236
00:13:34,490 --> 00:13:37,330
universe of functions that all very very strange

237
00:13:37,680 --> 00:13:40,390
so probably you wouldn't really want to do this

238
00:13:40,420 --> 00:13:46,100
this is only government

239
00:13:48,570 --> 00:13:52,320
also just interpreting as process computed what they the

240
00:13:52,340 --> 00:13:57,020
the covariance function with the covariance function was right and then just plugin

241
00:13:57,030 --> 00:13:59,110
this into my covariance function

242
00:13:59,130 --> 00:14:01,960
right and it only has one parameter

243
00:14:02,000 --> 00:14:03,530
gamma here

244
00:14:03,550 --> 00:14:05,560
and i just optimize with respect to that

245
00:14:05,570 --> 00:14:08,260
gamma and then my predictive error bars

246
00:14:08,270 --> 00:14:10,050
you know follow automatically

247
00:14:10,060 --> 00:14:13,760
searches for me

248
00:14:15,810 --> 00:14:22,160
if you're you're using some of the process of the one norm

249
00:14:22,180 --> 00:14:25,100
the island is only going

250
00:14:25,140 --> 00:14:31,150
absolutely not i just i just plug into the covariance function just like we did

251
00:14:31,170 --> 00:14:34,060
a few days ago here like i do i do functions like this right i

252
00:14:34,060 --> 00:14:38,690
just plug in the function has just this form right it just depends on k

253
00:14:38,760 --> 00:14:40,660
but point here

254
00:14:41,840 --> 00:14:43,720
here there is no noise

255
00:14:43,730 --> 00:14:47,340
well OK in this in this part of the noise that is that so small

256
00:14:47,340 --> 00:14:49,470
that you can see it

257
00:14:49,520 --> 00:14:52,940
in your case there's also no noise so there are two reasons why

258
00:14:53,430 --> 00:14:55,120
your posterior distribution

259
00:14:55,140 --> 00:14:58,710
is a distribution and not just the functions one of them is that there is

260
00:14:58,710 --> 00:15:03,620
noise so it could be that the true function is somewhere else because of noise

261
00:15:03,670 --> 00:15:08,040
another another source of uncertainty is is ignorance

262
00:15:08,040 --> 00:15:10,800
it's because you don't know what the function is doing the function and even if

263
00:15:10,810 --> 00:15:13,230
the function is deterministic

264
00:15:13,240 --> 00:15:17,050
if you've only seen a finite number of data points then you still unsure about

265
00:15:17,050 --> 00:15:18,650
what the function is doing

266
00:15:18,670 --> 00:15:22,890
and the error bars contain both the

267
00:15:22,980 --> 00:15:28,460
both the uncertainty due to ignorance and also that the uncertainty due to the noise

268
00:15:28,460 --> 00:15:30,390
so in this case there is actually a little bit of noise you can see

269
00:15:30,390 --> 00:15:35,940
that because the the the the point deviate from from the mean height but it

270
00:15:35,940 --> 00:15:40,480
would look much the same even if you didn't have noise

271
00:15:40,490 --> 00:15:43,160
OK that's slightly slide as ideas

272
00:15:50,530 --> 00:15:52,860
so how do we actually in practice too

273
00:15:53,260 --> 00:15:58,550
the optimisation well i i just read as black box i just say well i

274
00:15:58,550 --> 00:16:02,590
have a function which is a function of the punisher parameters

275
00:16:02,620 --> 00:16:03,820
and then i just two

276
00:16:03,820 --> 00:16:08,840
so i was tries to achieve the margin which is at least as you

277
00:16:08,860 --> 00:16:13,190
and maybe maybe to achieves a little bit higher margin so but it tries to

278
00:16:13,190 --> 00:16:18,650
achieve margin which has listed so now we have this margin target role

279
00:16:18,690 --> 00:16:23,250
and if you increase the this tries to achieve margin of at least role

280
00:16:23,340 --> 00:16:26,050
may i mean the margin might not be

281
00:16:26,070 --> 00:16:29,800
OK so the maximum margin might be smaller than this role then test fails but

282
00:16:29,800 --> 00:16:32,130
if the margin is actually larger than this rule

283
00:16:33,210 --> 00:16:37,590
this was the confederate past two that the marginal

284
00:16:37,610 --> 00:16:42,780
OK his some theory which relates

285
00:16:42,880 --> 00:16:50,960
essentially role with the performance of the base learner and over the max margin

286
00:16:51,000 --> 00:16:54,920
OK so the idea is OK then let's say you have the

287
00:16:55,400 --> 00:16:58,590
so let's say rosier

288
00:16:58,690 --> 00:16:59,920
this one here

289
00:17:00,190 --> 00:17:04,940
this is the edge of the basin so essentially in an optimal case you would

290
00:17:04,940 --> 00:17:07,860
like to have that the margin the at the margin bound

291
00:17:07,880 --> 00:17:11,280
what the maximum margin is equal to the minimum wage

292
00:17:12,020 --> 00:17:14,780
but this bound shows you that

293
00:17:14,800 --> 00:17:18,130
this is the red line here OK this postponed

294
00:17:18,170 --> 00:17:23,380
and the blue line is a simple approximations and the web on this so this

295
00:17:23,380 --> 00:17:25,110
is essentially

296
00:17:25,760 --> 00:17:30,460
the maximum margin this is the parameter of the algorithm and this is this

297
00:17:30,480 --> 00:17:35,110
parameters of the out of the base learner OK so if OK in the in

298
00:17:35,110 --> 00:17:40,530
the optimal case so let's say gamma is equal to the max margin and max

299
00:17:40,530 --> 00:17:45,710
margin is equal to the role to to discover because when you come out as

300
00:17:45,920 --> 00:17:52,820
the quality i mean if it based on returns hypotheses which have at least cover

301
00:17:52,820 --> 00:17:55,050
OK then the maximum margin this rule

302
00:17:55,070 --> 00:17:56,530
it is equal to go

303
00:17:56,570 --> 00:18:03,020
OK and then let's say we use articles role with choice then gamma could draw

304
00:18:03,020 --> 00:18:03,880
then here

305
00:18:03,940 --> 00:18:06,900
we just have the maximum margin so that

306
00:18:06,900 --> 00:18:12,530
the asymptotically chief margins at least the maximum margin so that's the perfect said situation

307
00:18:12,840 --> 00:18:15,940
OK so usually you don't know and this is optimal

308
00:18:15,960 --> 00:18:20,800
martin so therefore we choose just use some of the rule which is smaller than

309
00:18:20,800 --> 00:18:22,050
the maximum margin

310
00:18:22,110 --> 00:18:25,170
so then we get that

311
00:18:25,190 --> 00:18:29,750
the asymptotically achieved margin is at least the average of these two

312
00:18:29,800 --> 00:18:34,480
OK this is this line here so let's say we set rho two zero then

313
00:18:35,130 --> 00:18:40,980
asymptotically achieve margin is at least half of the possible much use the possible margin

314
00:18:40,980 --> 00:18:42,360
and here's the margin bounds

315
00:18:42,360 --> 00:18:46,820
but if he set rules your three for instance and the margin is really that

316
00:18:47,130 --> 00:18:48,260
large so

317
00:18:48,280 --> 00:18:52,800
if it's smaller than than zero three the maximum margin and we don't even anything

318
00:18:52,960 --> 00:18:55,090
but if it's larger than we

319
00:18:55,130 --> 00:18:57,820
we get a much larger and so

320
00:18:57,840 --> 00:19:02,130
so it's important to set this parameter rho correctly

321
00:19:02,190 --> 00:19:08,530
OK and essentially the idea of adaboost star is that we adaptively tuned this parameter

322
00:19:10,190 --> 00:19:13,860
OK so somehow we have to choose it in the right way that is also

323
00:19:13,860 --> 00:19:15,340
the idea of TV

324
00:19:15,440 --> 00:19:21,300
essentially it sets the this parameter role as the maximum over all margins has it

325
00:19:21,300 --> 00:19:25,530
has achieved so far so it just looks at the combined forces of the last

326
00:19:26,530 --> 00:19:29,320
and caesar which was to maximize the margin

327
00:19:29,320 --> 00:19:32,340
OK then just sets role to this

328
00:19:32,530 --> 00:19:34,710
max margin

329
00:19:34,730 --> 00:19:40,320
so it is easy to show convergence using the setting just using this bound however

330
00:19:40,340 --> 00:19:43,610
there's no convergence rate

331
00:19:47,650 --> 00:19:50,480
OK so

332
00:19:50,500 --> 00:20:00,210
let me try to illustrate this again so i have few the maximum margin on

333
00:20:00,210 --> 00:20:04,340
the x axis k and t is the chief margin of adaboost

334
00:20:04,460 --> 00:20:11,840
after after a really large number of iterations more like an asymptotic setting so this

335
00:20:11,840 --> 00:20:16,030
is the blue line is this bone which shown in the last iteration

336
00:20:16,090 --> 00:20:21,170
and the blue this blue line is the maximum margin which is achievable rate because

337
00:20:21,170 --> 00:20:24,190
i mean it can achieve larger margin than the maximum wage

338
00:20:24,380 --> 00:20:26,980
OK now we let right under article right

339
00:20:27,030 --> 00:20:31,020
and we have two different kinds of base learners one is the corporate of one

340
00:20:31,020 --> 00:20:36,710
so really selects based on which is maximizing the so it's best can do

341
00:20:36,820 --> 00:20:38,570
these are the green points

342
00:20:38,610 --> 00:20:40,230
so we said okay so we

343
00:20:40,230 --> 00:20:45,030
every point is essentially are generated dataset which has a certain maximum margin OK so

344
00:20:45,030 --> 00:20:46,000
this margin here

345
00:20:46,130 --> 00:20:48,860
and then we simply round

346
00:20:49,280 --> 00:20:54,210
i most and see how large the margin is after running ten thousand iterations for

347
00:20:54,210 --> 00:20:56,590
instance OK these are the green points here

348
00:20:57,590 --> 00:21:01,840
we see that these are the the idea of boosting margin is almost as large

349
00:21:01,840 --> 00:21:03,750
as the maximum margin

350
00:21:03,760 --> 00:21:06,300
if the based on its corporate

351
00:21:06,340 --> 00:21:12,070
if on the other hand the based on it's just getting returning process which is

352
00:21:12,070 --> 00:21:19,110
slightly larger than the maximum margin that means i mean it returns hypotheses which is

353
00:21:19,130 --> 00:21:24,070
has edge which is larger than government government suggested this maximum margin is just one

354
00:21:24,070 --> 00:21:26,170
has to achieve so it's not corporate

355
00:21:26,250 --> 00:21:30,630
just performing as good as it should be then we just get the performance of

356
00:21:30,630 --> 00:21:32,860
this bound which we ask

357
00:21:32,920 --> 00:21:36,610
slide so these are the red dots records

358
00:21:36,630 --> 00:21:40,440
OK it really depends on the choice of the base and how good is actually

359
00:21:40,440 --> 00:21:43,570
performing so that means hollywood

360
00:21:43,570 --> 00:21:44,630
got it

361
00:21:44,650 --> 00:21:49,710
using traditional instruments and then you can use these

362
00:21:49,730 --> 00:21:52,230
the goal is to get

363
00:21:52,250 --> 00:21:54,190
so this is for example

364
00:21:54,210 --> 00:21:57,230
and in fact

365
00:21:57,500 --> 00:22:02,650
but of this particular university of come of this

366
00:22:02,670 --> 00:22:08,790
so this was the first person then co-workers was applied is exactly for is a

367
00:22:08,790 --> 00:22:15,040
tremendous energy you want to tell you what for one spectrometer spectrum of the sun

368
00:22:15,040 --> 00:22:20,690
and then it for instance on statistical tests for a comparison

369
00:22:20,750 --> 00:22:22,000
which is the not

370
00:22:22,000 --> 00:22:27,920
fifty to derive its you can of the basis to the something which is useful

371
00:22:27,920 --> 00:22:31,610
knowledge which is that he can be crossed

372
00:22:31,690 --> 00:22:34,710
here is that instead strings

373
00:22:34,730 --> 00:22:37,230
your input space that's more grass

374
00:22:37,750 --> 00:22:42,590
and what makes the between graphs is to say that

375
00:22:42,610 --> 00:22:47,440
given the graph can connect around the long walks on the graph which generates sequence

376
00:22:47,810 --> 00:22:53,750
came together be sequences and when human rights can all of sequences with respect to

377
00:22:53,750 --> 00:22:57,270
the random walk on on the graph you've taken grass

378
00:22:57,290 --> 00:23:01,360
so you to come in with the rest of us otherwise

379
00:23:01,400 --> 00:23:02,590
and the

380
00:23:02,590 --> 00:23:05,330
it was published in

381
00:23:05,340 --> 00:23:11,250
also been applied on when you know people like this whole circus called for convention

382
00:23:11,400 --> 00:23:15,150
is when you have several sequences which was released in the UK

383
00:23:15,460 --> 00:23:17,980
it doesn't matter how they are

384
00:23:18,000 --> 00:23:20,900
and when you want to compare to multiple alignments

385
00:23:20,920 --> 00:23:25,940
you can somehow try to infer what the common ancestor was the only person some

386
00:23:26,130 --> 00:23:27,460
of the model

387
00:23:27,480 --> 00:23:30,900
what was necessary given the current alignment

388
00:23:30,960 --> 00:23:32,960
and if you can between

389
00:23:33,220 --> 00:23:40,130
they consist also you can marginalize over it gets a kernel between sets of sequences

390
00:23:40,190 --> 00:23:43,130
to be in the multiple alignment

391
00:23:43,150 --> 00:23:45,210
OK so there are many examples

392
00:23:45,230 --> 00:23:46,440
and very

393
00:23:46,560 --> 00:23:51,770
related to to the documents

394
00:23:51,770 --> 00:23:56,750
so we now turn to the last there's no question

395
00:24:03,400 --> 00:24:07,690
so is

396
00:24:08,360 --> 00:24:09,400
this is

397
00:24:10,000 --> 00:24:13,150
callers is

398
00:24:20,310 --> 00:24:23,000
i don't know what to do

399
00:24:23,090 --> 00:24:30,210
i think most efficient way so here it is in the position to you can

400
00:24:30,210 --> 00:24:34,230
say OK i don't assume anything we a special kind of that

401
00:24:34,290 --> 00:24:36,110
or i assume

402
00:24:36,110 --> 00:24:38,810
the imagine that you know

403
00:24:38,810 --> 00:24:39,540
i don't

404
00:24:39,540 --> 00:24:42,900
one also places that the most can is that

405
00:24:42,960 --> 00:24:44,360
this probably

406
00:24:44,880 --> 00:24:49,690
it is better than the

407
00:24:49,710 --> 00:24:51,810
the question

408
00:24:51,830 --> 00:24:54,650
so and we can also directly by

409
00:24:55,000 --> 00:25:01,860
generative models

410
00:25:01,880 --> 00:25:05,560
so i'm not sure about the final approach

411
00:25:05,560 --> 00:25:10,070
i wanted to cover the can which is how you derive can from some prior

412
00:25:10,070 --> 00:25:12,130
your mutual

413
00:25:12,420 --> 00:25:16,500
so i would say well that's want say

414
00:25:16,500 --> 00:25:23,070
give me a teenager i constructed it all the way similarities between my sequence visionary

415
00:25:23,070 --> 00:25:25,540
and is used as a feature vector

416
00:25:25,630 --> 00:25:32,400
and i just mentioned the so what works that a

417
00:25:32,420 --> 00:25:38,860
i mean that's interesting because you can prove you see that it was the channels

418
00:25:38,880 --> 00:25:42,710
also in practice this means that

419
00:25:42,790 --> 00:25:46,630
but i would like to tell you what you need to make the numbers that

420
00:25:46,790 --> 00:25:51,630
intended to that but that's about all i wanted to show you some theory

421
00:25:51,650 --> 00:25:57,270
on how to change it can deposit account numbers into the pacific

422
00:25:58,150 --> 00:26:02,310
here is that we can all streams now

423
00:26:02,310 --> 00:26:05,620
other we get interesting feature from images

424
00:26:05,640 --> 00:26:07,640
the express them

425
00:26:07,690 --> 00:26:08,420
o the

426
00:26:10,170 --> 00:26:13,100
sect of features

427
00:26:13,120 --> 00:26:15,840
and finally our present the images

428
00:26:15,860 --> 00:26:18,810
by using the problem

429
00:26:19,590 --> 00:26:20,960
the idea is that

430
00:26:20,970 --> 00:26:26,940
we should move we should find some marketing in some markets in the image

431
00:26:26,960 --> 00:26:30,060
and in computer vision

432
00:26:30,090 --> 00:26:33,390
rather than using just pixels

433
00:26:33,410 --> 00:26:34,760
we want to find

434
00:26:36,290 --> 00:26:39,780
interesting points

435
00:26:41,440 --> 00:26:47,550
structure for reasons when the structure or to the structure or flat regions

436
00:26:48,440 --> 00:26:50,050
in computer vision

437
00:26:50,060 --> 00:26:51,340
we categorise

438
00:26:51,400 --> 00:26:54,530
this is interesting points in three groups

439
00:26:54,530 --> 00:26:56,120
all foreigners

440
00:26:56,150 --> 00:26:58,340
blobs and that's

441
00:26:58,350 --> 00:27:00,030
and essentially

442
00:27:00,030 --> 00:27:02,540
what we are looking for is

443
00:27:03,210 --> 00:27:06,250
i responded this continuity

444
00:27:06,260 --> 00:27:07,790
in one direction

445
00:27:08,540 --> 00:27:10,030
we are looking for

446
00:27:11,690 --> 00:27:13,190
that divides

447
00:27:13,460 --> 00:27:19,010
two different regions for instance because they are are different in statistical pictures

448
00:27:19,940 --> 00:27:21,450
we are looking for

449
00:27:21,460 --> 00:27:22,960
a big so

450
00:27:22,970 --> 00:27:24,700
where delta correlation

451
00:27:24,710 --> 00:27:28,000
indicate that there are two the discontinuity

452
00:27:28,020 --> 00:27:29,550
o we're looking for

453
00:27:29,570 --> 00:27:30,820
it's so where

454
00:27:30,840 --> 00:27:34,400
around the peaks is that is an emerging region

455
00:27:34,410 --> 00:27:35,370
and yes

456
00:27:35,420 --> 00:27:38,280
and most of the bag of visual words all the

457
00:27:38,310 --> 00:27:40,310
was watched by using

458
00:27:40,360 --> 00:27:42,410
blob detector

459
00:27:43,760 --> 00:27:49,190
this pixels this this kind of this gives us a useful to indentify objects at

460
00:27:49,190 --> 00:27:50,530
different scales

461
00:27:50,550 --> 00:27:53,090
in the right way

462
00:27:53,110 --> 00:27:54,850
and after

463
00:27:56,090 --> 00:28:00,230
after looking for this market is this markets

464
00:28:00,270 --> 00:28:02,880
describe discovered some way

465
00:28:02,900 --> 00:28:05,510
and in computer vision usually

466
00:28:05,520 --> 00:28:06,320
we use

467
00:28:06,360 --> 00:28:09,120
histogram of oriented gradients

468
00:28:09,150 --> 00:28:10,560
or SIFT

469
00:28:10,580 --> 00:28:13,300
and after looking for some markets

470
00:28:13,310 --> 00:28:15,410
in the image like an edge

471
00:28:15,440 --> 00:28:16,270
we can

472
00:28:16,610 --> 00:28:20,500
s rocks the orientation of the edge in match

473
00:28:20,510 --> 00:28:21,740
we can be

474
00:28:22,210 --> 00:28:25,120
each of orientation by waiting

475
00:28:25,170 --> 00:28:27,540
with the strength

476
00:28:27,550 --> 00:28:29,370
and we can be so

477
00:28:29,390 --> 00:28:32,150
representation four point

478
00:28:33,550 --> 00:28:37,030
four point detector with an edge effect

479
00:28:38,360 --> 00:28:43,030
in the case of safe SIFT is an histogram

480
00:28:43,040 --> 00:28:51,440
orientation histogram based representation of the local patch around about the detector so in the

481
00:28:51,440 --> 00:28:52,840
case of the sea

482
00:28:52,860 --> 00:28:57,250
we can embed in this picture information on scale

483
00:28:57,250 --> 00:28:58,710
and so on

484
00:28:58,750 --> 00:29:01,200
the main direction of the patch around

485
00:29:01,220 --> 00:29:02,920
an interesting point

486
00:29:02,950 --> 00:29:05,150
and this can be very useful to

487
00:29:05,170 --> 00:29:07,330
make it environments

488
00:29:07,340 --> 00:29:11,160
rotation translation and so on

489
00:29:12,360 --> 00:29:16,850
what we do is we first find some markers in the image

490
00:29:16,870 --> 00:29:17,850
we find

491
00:29:17,870 --> 00:29:20,170
for instance one the structure

492
00:29:20,840 --> 00:29:22,810
to this structure on this

493
00:29:23,770 --> 00:29:26,070
flat region of the right scale

494
00:29:26,100 --> 00:29:27,440
after that

495
00:29:27,450 --> 00:29:31,080
we take in consideration of which around

496
00:29:31,100 --> 00:29:32,350
this markets

497
00:29:32,370 --> 00:29:33,560
we describe

498
00:29:33,570 --> 00:29:36,350
with respect to content the of this page

499
00:29:38,310 --> 00:29:40,320
the building the ball the block

500
00:29:41,170 --> 00:29:43,310
of the image

501
00:29:43,320 --> 00:29:49,310
of course there are many descriptors that have been proposing computer vision literature

502
00:29:49,400 --> 00:29:51,600
and some of the are listed here

503
00:29:51,610 --> 00:29:53,550
just as references

504
00:29:54,820 --> 00:29:56,950
this this picture sometimes

505
00:29:56,990 --> 00:29:59,100
depends of the application

506
00:29:59,780 --> 00:30:03,630
of what people are working on for instance

507
00:30:03,640 --> 00:30:05,710
he said come on flow

508
00:30:05,710 --> 00:30:07,350
i use it in

509
00:30:07,410 --> 00:30:10,100
in the application where

510
00:30:10,110 --> 00:30:11,960
we work with vs

511
00:30:12,810 --> 00:30:14,030
we can

512
00:30:14,040 --> 00:30:17,810
being a kind of histogram over the floor

513
00:30:17,830 --> 00:30:19,120
of of

514
00:30:20,360 --> 00:30:24,450
to understand present position options in a video

515
00:30:24,490 --> 00:30:28,570
or we can information on shape recognise

516
00:30:28,960 --> 00:30:32,950
object and so on

517
00:30:32,990 --> 00:30:36,450
another important cues inspection

518
00:30:36,460 --> 00:30:39,220
and in this shape texture arise

519
00:30:40,210 --> 00:30:45,040
a large number of small objects like some grass or less

520
00:30:46,140 --> 00:30:47,170
the sexual

521
00:30:47,190 --> 00:30:48,900
can be

522
00:30:48,920 --> 00:30:52,950
summarized by a bunch of theatre

523
00:30:52,950 --> 00:30:54,660
by a set of officers

524
00:30:54,720 --> 00:30:57,310
by using a convolution operation

525
00:30:58,830 --> 00:31:05,660
there is this idea to use filters from their visual system where

526
00:31:05,670 --> 00:31:08,360
there are simple cells

527
00:31:08,410 --> 00:31:11,160
that have arisen dressed in the field

528
00:31:11,340 --> 00:31:13,160
of two forms

529
00:31:13,350 --> 00:31:16,130
oriented and lottery and

530
00:31:17,350 --> 00:31:19,350
their response to a small region

531
00:31:19,360 --> 00:31:20,730
so we can use

532
00:31:20,790 --> 00:31:22,030
as set field trip

533
00:31:22,040 --> 00:31:23,190
capture some

534
00:31:24,220 --> 00:31:25,770
or edge

535
00:31:25,780 --> 00:31:27,360
on the average

536
00:31:27,390 --> 00:31:30,310
four out of the patch

537
00:31:30,310 --> 00:31:32,640
and i describe

538
00:31:33,860 --> 00:31:37,510
describe texture

539
00:31:37,520 --> 00:31:38,750
we can use

540
00:31:38,820 --> 00:31:41,590
concatenation of the responses of of

541
00:31:42,620 --> 00:31:43,780
which makes sense

542
00:31:44,520 --> 00:31:48,360
well above the filters we used the officer of the image

543
00:31:48,410 --> 00:31:51,040
and for each pixel so we have

544
00:31:51,040 --> 00:31:52,670
a long vectors

545
00:31:53,210 --> 00:31:56,240
in which each bubble is a response to

546
00:31:56,290 --> 00:31:58,780
the filters as is

547
00:31:58,800 --> 00:32:01,580
filters sculptural structure like

548
00:32:01,600 --> 00:32:03,120
or in the case

549
00:32:03,140 --> 00:32:05,000
average bowl and so on

550
00:32:05,010 --> 00:32:08,270
there are not enough to believe in new some

551
00:32:08,320 --> 00:32:09,630
some changes

552
00:32:10,960 --> 00:32:13,040
some changes in the images

553
00:32:13,200 --> 00:32:14,890
he didn't

554
00:32:14,900 --> 00:32:15,950
the way

555
00:32:15,960 --> 00:32:19,450
that the image look like

556
00:32:19,460 --> 00:32:21,730
so far we have discussed it just

557
00:32:22,000 --> 00:32:25,060
two how to extract

558
00:32:26,500 --> 00:32:27,790
from images

559
00:32:27,800 --> 00:32:30,660
after that we should be the vocabulary

560
00:32:30,690 --> 00:32:32,640
and at this point

561
00:32:32,660 --> 00:32:34,740
but the recognition

562
00:32:35,090 --> 00:32:38,540
i use it

563
00:32:38,550 --> 00:32:40,540
and specifically

564
00:32:40,550 --> 00:32:44,700
we use clustering algorithm two

565
00:32:45,940 --> 00:32:47,040
our representatives

566
00:32:47,040 --> 00:32:52,260
i see at university of southern california and they have system

567
00:32:52,340 --> 00:32:56,040
what summarised in colombia there is

568
00:32:56,060 --> 00:32:59,930
also very active research group

569
00:32:59,950 --> 00:33:02,390
and that means is the system

570
00:33:02,440 --> 00:33:05,200
from the university of michigan

571
00:33:05,300 --> 00:33:06,160
and then

572
00:33:06,530 --> 00:33:09,590
at the dark conferences the document

573
00:33:09,710 --> 00:33:16,220
understanding conference there has been a continual effort in organizing summary

574
00:33:16,230 --> 00:33:24,460
evaluation summary evaluation activities there are many systems presented and and work on the same

575
00:33:24,470 --> 00:33:26,300
tasks and c

576
00:33:26,320 --> 00:33:31,070
what which approach perform better

577
00:33:31,440 --> 00:33:35,100
and these these different systems

578
00:33:35,170 --> 00:33:38,860
all uses extractive methods

579
00:33:38,900 --> 00:33:39,870
i the

580
00:33:39,890 --> 00:33:48,230
dominant approach but sometimes augmented by the use of lexical resources for example in summaries

581
00:33:48,360 --> 00:33:52,650
their work working that resources are used

582
00:33:54,660 --> 00:33:55,820
the problem

583
00:33:57,590 --> 00:34:02,310
finally in the literature is that all these systems including this

584
00:34:02,550 --> 00:34:10,710
very organised and coordinated systematic evaluation efforts are heavily focused on news text

585
00:34:10,810 --> 00:34:12,730
while in the way

586
00:34:12,750 --> 00:34:16,110
understandable the good news text are

587
00:34:16,200 --> 00:34:18,990
a relatively short and and

588
00:34:19,240 --> 00:34:26,130
in a way it's easier to find organize human judgement charges two to charge the

589
00:34:26,140 --> 00:34:28,800
output summaries

590
00:34:28,850 --> 00:34:33,030
and also of course there's also the need to follow up

591
00:34:33,180 --> 00:34:39,800
current you and are reported in news articles were not much work has been

592
00:34:40,010 --> 00:34:41,650
forty eight

593
00:34:41,950 --> 00:34:44,260
summarizing the type of

594
00:34:45,740 --> 00:34:48,100
and for example

595
00:34:48,150 --> 00:34:52,230
for example like very long economic reports

596
00:34:52,250 --> 00:34:56,550
comment report and business reports these things we

597
00:34:57,610 --> 00:35:01,190
so many times every day

598
00:35:02,630 --> 00:35:05,420
and then some background information about me

599
00:35:05,700 --> 00:35:07,800
and this is

600
00:35:08,190 --> 00:35:11,510
extractive summarisation system that you can use it

601
00:35:11,650 --> 00:35:12,830
to do

602
00:35:12,840 --> 00:35:17,500
to summarize multi documents we can also use it

603
00:35:17,510 --> 00:35:19,240
a single document

604
00:35:19,280 --> 00:35:22,860
and it's open source system that you can

605
00:35:22,880 --> 00:35:24,940
download freely

606
00:35:25,150 --> 00:35:27,120
where the system

607
00:35:27,140 --> 00:35:28,750
has included

608
00:35:28,760 --> 00:35:30,380
several summarisation

609
00:35:30,400 --> 00:35:31,920
and you can explore

610
00:35:31,940 --> 00:35:36,770
and the kind of confidence flexibility

611
00:35:36,810 --> 00:35:41,910
and then there are also a group of summary evaluation methods

612
00:35:41,940 --> 00:35:43,840
very close to five

613
00:35:43,850 --> 00:35:47,080
forty five functional components in the system

614
00:35:47,090 --> 00:35:52,260
you need to do pre processing and you need to

615
00:35:52,280 --> 00:35:59,390
calculate the feature scores for each sentences in the documents and then you use quite

616
00:35:59,660 --> 00:36:03,070
classifier to to combine different features

617
00:36:03,110 --> 00:36:11,470
and the reranker to rerank the significance score obtained from classifiers and then post processing

618
00:36:11,470 --> 00:36:18,890
to make the contents more readable today and these

619
00:36:18,980 --> 00:36:21,540
then these are some of the method

620
00:36:21,650 --> 00:36:24,670
sentence extraction methods in MEAD

621
00:36:25,340 --> 00:36:29,310
i think the centroid method is like

622
00:36:29,450 --> 00:36:32,310
in the centre of the mid systems

623
00:36:33,840 --> 00:36:38,470
and it calculates as it does as that is that the average of

624
00:36:38,560 --> 00:36:45,180
all the sentences in the documents to be summarized and this so that these citizens

625
00:36:45,330 --> 00:36:47,680
is regarded as the centroid

626
00:36:47,750 --> 00:36:51,930
four represent the key contents of this document

627
00:36:52,040 --> 00:36:59,040
and then another each sentence is compared with his citizens to see how similar they

628
00:36:59,040 --> 00:37:01,710
of course now they don't use boats any more

629
00:37:01,720 --> 00:37:06,250
they basically fly around the world to different places

630
00:37:06,270 --> 00:37:09,320
so when it came to say to him OK now you are in the business

631
00:37:09,320 --> 00:37:12,740
now you can really do what you want with this business

632
00:37:12,830 --> 00:37:15,780
what are you going to change

633
00:37:15,780 --> 00:37:19,030
you look just for a long time

634
00:37:19,060 --> 00:37:22,250
this array wanted

635
00:37:23,540 --> 00:37:24,550
we said to

636
00:37:24,600 --> 00:37:28,620
due to take people run by boat any more

637
00:37:28,670 --> 00:37:30,300
he said no no cost

638
00:37:30,300 --> 00:37:32,720
for the first

639
00:37:32,730 --> 00:37:34,230
the boat is the past

640
00:37:34,240 --> 00:37:39,580
i've been tracked by the past

641
00:37:39,590 --> 00:37:41,900
then he

642
00:37:41,910 --> 00:37:45,150
he took it out and here ran one more of so

643
00:37:45,160 --> 00:37:48,520
rather sweetly put in a bottle of wine

644
00:37:48,550 --> 00:37:51,660
he said has been in the back of my head for a long time you

645
00:37:51,660 --> 00:37:56,040
said that actually wine spirituality together rather well

646
00:37:56,090 --> 00:38:00,740
so we're going to combine yards spiritual places

647
00:38:00,750 --> 00:38:05,550
and then interestingly he moved into the centre

648
00:38:05,650 --> 00:38:08,630
one of these little japanese trees

649
00:38:09,820 --> 00:38:12,380
it only group is hard

650
00:38:12,450 --> 00:38:14,160
when they reach the full-sized

651
00:38:15,330 --> 00:38:16,490
one is actually

652
00:38:16,500 --> 00:38:23,220
and he said because i want my organization to be upon xi organization

653
00:38:23,230 --> 00:38:25,630
these are the thing about once a tree

654
00:38:25,720 --> 00:38:29,310
once it reaches its full size you still have to look after you have to

655
00:38:29,310 --> 00:38:33,310
prove that you have to shape you have to take great care but it never

656
00:38:33,320 --> 00:38:38,240
grows any big it's slightly changes its shape was never going

657
00:38:38,320 --> 00:38:43,700
my organisation has thirty people i know the more intimately

658
00:38:43,710 --> 00:38:45,200
my challenge

659
00:38:45,220 --> 00:38:47,400
it is not to grow bigger

660
00:38:47,510 --> 00:38:49,070
but to grow better

661
00:38:50,590 --> 00:38:51,620
what i

662
00:38:51,710 --> 00:38:53,420
now convinced

663
00:38:53,510 --> 00:38:57,040
this little exercise has taught me to do

664
00:38:58,350 --> 00:39:00,390
and so suddenly is values

665
00:39:00,410 --> 00:39:03,260
suddenly appeared in the form xi trees

666
00:39:03,260 --> 00:39:05,200
with the book on

667
00:39:05,210 --> 00:39:08,960
so many of us in our organisations and indeed how schools are trapped in the

668
00:39:08,960 --> 00:39:11,720
past we need to remove the mode

669
00:39:11,770 --> 00:39:14,300
from our institutions

670
00:39:14,310 --> 00:39:16,620
we need to see what we're going to put in

671
00:39:16,640 --> 00:39:17,720
in this place

672
00:39:17,720 --> 00:39:20,760
so many of our organisations are consumed with the idea

673
00:39:21,300 --> 00:39:22,510
the only way

674
00:39:22,510 --> 00:39:24,190
to succeed is to grow

675
00:39:24,210 --> 00:39:27,110
but you don't have to grow bigger

676
00:39:27,160 --> 00:39:29,490
you could grow better

677
00:39:29,500 --> 00:39:31,700
you could be on site

678
00:39:31,710 --> 00:39:33,090
it seems to me

679
00:39:34,390 --> 00:39:35,340
that would be

680
00:39:35,350 --> 00:39:36,710
indeed nice

681
00:39:39,140 --> 00:39:41,700
we have done this exercise

682
00:39:41,700 --> 00:39:44,230
with more i think probably

683
00:39:44,240 --> 00:39:46,600
over one hundred people

684
00:39:46,620 --> 00:39:53,230
of all sorts including young couples who are about to get married very good exercise

685
00:39:53,310 --> 00:39:58,040
what is your life to be able to be like but it is our way

686
00:39:58,050 --> 00:40:03,860
of getting into the why question what is important to like why are you doing

687
00:40:03,860 --> 00:40:08,050
what you do we had a very moving moment of the day

688
00:40:08,710 --> 00:40:10,410
last week in madrid

689
00:40:10,500 --> 00:40:14,560
when we had a workshop for people

690
00:40:14,610 --> 00:40:16,320
on the cusp of life

691
00:40:16,330 --> 00:40:19,410
on those curves people who

692
00:40:19,420 --> 00:40:21,860
four we wanted a weekend

693
00:40:21,870 --> 00:40:26,030
went away to to talk about how their lives needed to change

694
00:40:26,030 --> 00:40:31,010
these are people of the age around about forty so far had been very successful

695
00:40:31,170 --> 00:40:33,550
mostly in business small business in fact

696
00:40:33,560 --> 00:40:36,380
but wanted something more out of life

697
00:40:36,400 --> 00:40:41,690
and the major exercise we gave them was to do is alive

698
00:40:41,690 --> 00:40:43,880
which they found absolutely fascinating

699
00:40:43,940 --> 00:40:45,980
one man

700
00:40:46,000 --> 00:40:49,650
came along he was a partner in the sciences

701
00:40:49,730 --> 00:40:52,320
in holland

702
00:40:56,280 --> 00:40:58,960
very strong

703
00:40:59,120 --> 00:41:01,060
dominating character

704
00:41:01,100 --> 00:41:02,700
tall good-looking

705
00:41:04,540 --> 00:41:06,210
in charge of whatever he

706
00:41:06,230 --> 00:41:10,360
because know is the kind of guy you knew it was there is in the

707
00:41:13,650 --> 00:41:14,880
he said

708
00:41:14,900 --> 00:41:18,270
a piece of nature is said to fly which would ask them to do is

709
00:41:18,270 --> 00:41:21,440
that that's some nonsense he said i don't like flowers

710
00:41:21,500 --> 00:41:25,690
but i know breaks the rules library and i suppose that

711
00:41:25,770 --> 00:41:31,670
that's a piece of nature at least achilles is not least you know the seeds

712
00:41:31,790 --> 00:41:35,840
grow in other countries but there is nothing and for all these objects it was

713
00:41:35,840 --> 00:41:39,440
very interesting because you produced one for his father

714
00:41:39,460 --> 00:41:44,130
this apparent cufflinks he said my dad has dominated my life

715
00:41:44,150 --> 00:41:47,420
my dad is a man who says make money

716
00:41:47,440 --> 00:41:51,400
that's the answer to success i want my son to build the family fortune i

717
00:41:51,400 --> 00:41:55,270
wanted to work hard and build a company

718
00:41:55,270 --> 00:41:56,590
and get rich

719
00:41:56,670 --> 00:41:58,150
on the other side

720
00:41:58,290 --> 00:42:03,460
had this sort of the death notice of his grandfather he said my grandfather was

721
00:42:03,460 --> 00:42:05,860
a totally different

722
00:42:05,900 --> 00:42:08,670
he believed in history in education

723
00:42:08,670 --> 00:42:12,340
in philosophy he was a gentleman

724
00:42:12,380 --> 00:42:13,690
he said

725
00:42:13,730 --> 00:42:16,190
i'll put them on either side because i

726
00:42:16,190 --> 00:42:19,920
i am torn between these two people

727
00:42:20,040 --> 00:42:22,940
in their values

728
00:42:23,070 --> 00:42:24,790
and in the middle he push

729
00:42:24,790 --> 00:42:26,630
a rather

730
00:42:26,650 --> 00:42:29,040
ugly little hierarchy

731
00:42:30,710 --> 00:42:34,360
one these only cheap things and i said what's that

732
00:42:34,420 --> 00:42:36,670
he said that's my work

733
00:42:36,690 --> 00:42:38,880
well i said the two from mckinsey business

734
00:42:38,880 --> 00:42:40,590
i'm not very good

735
00:42:40,610 --> 00:42:43,480
he said well

736
00:42:43,480 --> 00:42:45,460
that that's what it is

737
00:42:45,460 --> 00:42:50,920
and then we can that the objects in elizabeth said

738
00:42:50,940 --> 00:42:54,820
but you've got you've got its objects and the apple you're only allowed five

739
00:42:54,860 --> 00:42:58,710
is said i don't care i'm right the rules that's me

740
00:42:58,730 --> 00:43:02,570
so we can't break these rules that elizabeth my

741
00:43:02,670 --> 00:43:05,090
you've got to remove one of these objects

742
00:43:05,110 --> 00:43:09,400
i mean it sounds trivial game what i have to tell you got very emotional

743
00:43:11,270 --> 00:43:16,670
he stood for a long time and they want to the table these six arranged

744
00:43:16,750 --> 00:43:20,130
for his photograph and it picked up the hat

745
00:43:20,170 --> 00:43:21,250
mister away

746
00:43:21,250 --> 00:43:25,080
that tell you that given the certain function you can

747
00:43:25,090 --> 00:43:27,640
construct an algorithm that will

748
00:43:28,770 --> 00:43:30,930
such and such distance

749
00:43:30,950 --> 00:43:36,280
or produce functions that are certain sections social distance from the true function but again

750
00:43:36,280 --> 00:43:38,700
you make assumptions and

751
00:43:38,750 --> 00:43:40,690
you're trying to do something that

752
00:43:40,710 --> 00:43:44,230
is not useful in practice you don't want to find the function in practice you

753
00:43:44,230 --> 00:43:47,660
just want to make good prediction so

754
00:43:47,810 --> 00:43:49,410
again the point of view

755
00:43:49,430 --> 00:43:53,340
but i think more interesting is where you try to minimize the errors that you

756
00:43:54,160 --> 00:43:57,310
and not try to identify something that

757
00:43:57,320 --> 00:44:00,790
you actually don't know that whether it exists or not

758
00:44:00,810 --> 00:44:03,210
i mean is there any truth functional

759
00:44:03,400 --> 00:44:05,580
you never know

760
00:44:05,590 --> 00:44:08,580
so that's why i

761
00:44:08,590 --> 00:44:12,700
better to think about this point of view

762
00:44:12,710 --> 00:44:16,500
which as well competitive which i call competitive approach or

763
00:44:16,510 --> 00:44:22,810
you can call it also the it's sometimes called the regret approach where

764
00:44:22,820 --> 00:44:24,590
what you do is

765
00:44:24,600 --> 00:44:26,070
you don't want to

766
00:44:28,260 --> 00:44:29,870
you find an algorithm that

767
00:44:31,800 --> 00:44:32,940
the error

768
00:44:32,980 --> 00:44:35,870
but the worst case error in the class

769
00:44:35,880 --> 00:44:38,330
you allow all possible problems

770
00:44:38,350 --> 00:44:40,260
but what you restrict

771
00:44:41,060 --> 00:44:43,310
the set of comparisons

772
00:44:43,330 --> 00:44:48,260
i present so you see

773
00:44:48,290 --> 00:44:50,750
you have a set of functions

774
00:44:50,780 --> 00:44:52,800
or a set of algorithms

775
00:44:54,340 --> 00:44:55,190
you look at

776
00:44:55,210 --> 00:44:56,110
the best

777
00:44:56,120 --> 00:44:57,370
such functions

778
00:44:57,400 --> 00:44:59,570
for the problem at hand

779
00:44:59,600 --> 00:45:00,750
and this gives you

780
00:45:00,760 --> 00:45:02,190
this quantity here

781
00:45:02,210 --> 00:45:04,700
now you compare this to the air

782
00:45:04,760 --> 00:45:07,480
but you make with your

783
00:45:07,490 --> 00:45:09,200
and you want

784
00:45:09,210 --> 00:45:10,920
to be an organism

785
00:45:10,940 --> 00:45:13,620
that is such that

786
00:45:13,680 --> 00:45:16,450
and at the worst possible problem

787
00:45:16,460 --> 00:45:17,960
i will minimize

788
00:45:17,970 --> 00:45:23,920
these different or this this is sometimes called the regret because it means

789
00:45:23,960 --> 00:45:25,430
if i had known

790
00:45:25,460 --> 00:45:30,100
what was the problem i would have chosen this reference which is the best one

791
00:45:30,110 --> 00:45:33,550
maximizing minus the loss means minimizing the loss

792
00:45:33,570 --> 00:45:37,720
so i would have chosen this reference but i didn't do it i chose instead

793
00:45:37,900 --> 00:45:39,490
a predictor

794
00:45:40,440 --> 00:45:44,170
i'm a bit sad about it's not having to this one and the sadness is

795
00:45:44,170 --> 00:45:48,400
measured or the regret is measured by the difference in those two losses

796
00:45:49,970 --> 00:45:54,460
in this way i'm not making any assumptions about how the data is generated where

797
00:45:54,460 --> 00:46:00,000
the where the target function lies and so on and just saying well

798
00:46:00,030 --> 00:46:02,840
how can i compare how do i compare

799
00:46:02,860 --> 00:46:03,960
we use

800
00:46:03,970 --> 00:46:08,130
this class of functions

801
00:46:08,790 --> 00:46:12,090
the thing is that often the results look like the same

802
00:46:12,860 --> 00:46:15,080
bounds on this kind of quantity

803
00:46:15,100 --> 00:46:19,360
our model is the same as bound on the minimax

804
00:46:19,400 --> 00:46:22,090
quantity of the previous slides

805
00:46:22,100 --> 00:46:23,860
if you

806
00:46:23,880 --> 00:46:26,830
take the maximum over the problems

807
00:46:26,960 --> 00:46:30,870
such that the target function is in the reference class

808
00:46:31,900 --> 00:46:33,950
if you if you have a set of functions

809
00:46:33,970 --> 00:46:36,260
and you look at

810
00:46:36,280 --> 00:46:38,100
the worst possible error

811
00:46:38,110 --> 00:46:40,580
when the target function is in this class

812
00:46:40,590 --> 00:46:44,380
you're paying more than the same result as if you

813
00:46:45,380 --> 00:46:48,290
and at the worst possible data generation

814
00:46:48,300 --> 00:46:50,560
the loss of another reason with the loss

815
00:46:50,580 --> 00:46:51,730
of this function

816
00:46:51,930 --> 00:46:55,430
one of the functions in this class

817
00:46:55,840 --> 00:47:01,060
OK so it's more or less a matter of taste but i think it's

818
00:47:01,070 --> 00:47:02,530
important too

819
00:47:04,360 --> 00:47:06,580
this kind of quantities in the right way

820
00:47:07,710 --> 00:47:11,070
and i think this way is kind of going in the direction of avoiding as

821
00:47:11,070 --> 00:47:13,360
much as possible assumptions about

822
00:47:13,370 --> 00:47:15,540
what's your problem is

823
00:47:15,580 --> 00:47:21,650
and OK of course what you do once you've defined such quantities is to prove

824
00:47:21,680 --> 00:47:25,360
story once you've defined such quantities to prove upper and lower bounds

825
00:47:25,380 --> 00:47:31,500
and you these is this explains how you would prove such files to put on

826
00:47:31,500 --> 00:47:32,460
an upper bound

827
00:47:33,820 --> 00:47:35,180
taken algorithm

828
00:47:35,200 --> 00:47:36,450
and you want to

829
00:47:36,460 --> 00:47:40,360
prove abound and the difference of the laws of the losses that is independent on

830
00:47:40,930 --> 00:47:44,220
of the data generation maxima mechanism

831
00:47:44,280 --> 00:47:45,700
and that gives you an upper bound

832
00:47:45,710 --> 00:47:47,820
and to prove lower bound

833
00:47:47,830 --> 00:47:52,780
you have to show that for every learning algorithm you can exhibit construct

834
00:47:52,790 --> 00:47:54,230
data generation

835
00:47:54,250 --> 00:47:56,750
mechanism of probability distribution if if you will

836
00:47:56,780 --> 00:48:01,030
that will maximally mislead your algorithm

837
00:48:02,280 --> 00:48:05,180
OK now

838
00:48:08,450 --> 00:48:10,850
i was trying now to

839
00:48:10,870 --> 00:48:13,650
formalise it's what i have said so far

840
00:48:13,660 --> 00:48:15,420
and a few definitions and

841
00:48:15,430 --> 00:48:20,980
of course by doing so i will restrict myself to specific setting in this case

842
00:48:20,990 --> 00:48:22,620
it would be the IID setting

843
00:48:22,690 --> 00:48:27,580
not because i think i is to write assumption but it's just that it's convenient

844
00:48:27,740 --> 00:48:31,250
and you can actually obtain the same one is the same result if you remove

845
00:48:31,260 --> 00:48:33,050
completely decided the assumptions

846
00:48:35,010 --> 00:48:38,250
so because of the classical notation x input space

847
00:48:38,260 --> 00:48:40,330
why is the outputs

848
00:48:40,330 --> 00:48:44,550
usually we take binary classification so it's just zero and one

849
00:48:44,560 --> 00:48:47,580
and the sample size number of training examples

850
00:48:47,580 --> 00:48:49,190
which are of the form

851
00:48:49,240 --> 00:48:51,960
x i y i

852
00:48:51,980 --> 00:48:57,280
and l is the loss function that measures the distance between

853
00:48:57,290 --> 00:48:58,980
the predicted

854
00:48:59,000 --> 00:49:01,540
label and the true labels usually

855
00:49:01,570 --> 00:49:05,290
just the indicator that the labels are not the same

856
00:49:05,390 --> 00:49:08,440
OK so now

857
00:49:08,480 --> 00:49:09,910
with this notation

858
00:49:09,920 --> 00:49:15,910
what they call the expected loss would be denote written like this expectation

859
00:49:15,930 --> 00:49:17,290
with respect to

860
00:49:17,290 --> 00:49:18,500
if there are no

861
00:49:18,510 --> 00:49:23,940
what to expect from the functions within the function before we can sort of see

862
00:49:23,950 --> 00:49:29,660
i function bit boring the green the green line because it only has a single

863
00:49:31,280 --> 00:49:33,820
in contrast the the people functions

864
00:49:33,840 --> 00:49:37,320
allows you to have action at different at different scales

865
00:49:37,340 --> 00:49:42,270
the same action going on at the sort of small area also some global

866
00:49:42,320 --> 00:49:45,150
i'm actually going on along the length scale

867
00:49:45,980 --> 00:49:50,450
maybe you think for some datasets that's more appropriate

868
00:49:50,470 --> 00:49:54,280
that's more appropriate model for your data

869
00:49:54,300 --> 00:49:55,720
and if you don't know

870
00:49:55,760 --> 00:49:57,210
then you can try both of them

871
00:49:57,250 --> 00:49:58,480
and then you can

872
00:49:58,780 --> 00:50:01,310
as the marginal likelihood which one

873
00:50:01,340 --> 00:50:05,560
you can learn something about what you did looks more like this or it looks

874
00:50:05,570 --> 00:50:06,640
more like that

875
00:50:06,970 --> 00:50:11,130
but you just optimise the problem here

876
00:50:11,130 --> 00:50:15,510
let's try another one

877
00:50:15,550 --> 00:50:19,060
now i've been talking about function

878
00:50:19,760 --> 00:50:22,190
you can also get

879
00:50:22,190 --> 00:50:26,010
a function on smooth here the covariance function

880
00:50:26,500 --> 00:50:28,180
it consist

881
00:50:28,340 --> 00:50:34,270
again the stationary covariance functions depend only on x minus five

882
00:50:34,330 --> 00:50:36,940
the power of the semantic prime

883
00:50:36,980 --> 00:50:39,160
the normalizing constant

884
00:50:39,200 --> 00:50:42,890
and then this is the modified bessel function

885
00:50:42,910 --> 00:50:45,020
but if you don't know what those are

886
00:50:45,120 --> 00:50:46,570
i can't remember what they are

887
00:50:46,580 --> 00:50:52,260
but just some functional form you can do that evaluate things

888
00:50:53,010 --> 00:50:58,340
and the and the some interesting properties here is this has also length scale parameter

889
00:50:58,340 --> 00:50:59,080
l here

890
00:50:59,130 --> 00:51:01,150
as an extra parameter new here

891
00:51:01,160 --> 00:51:02,510
it turns out that

892
00:51:02,530 --> 00:51:07,580
this government formed and the cover the that the function that you get

893
00:51:07,590 --> 00:51:11,040
newman one times differentiable

894
00:51:11,090 --> 00:51:14,270
OK so the functions were looking forward infinity french

895
00:51:14,280 --> 00:51:16,600
that means they were very smooth function

896
00:51:16,650 --> 00:51:18,700
maybe sometimes you have

897
00:51:18,780 --> 00:51:21,790
you have you want to model that is that we don't think the thing that

898
00:51:22,480 --> 00:51:23,500
everything you have

899
00:51:23,510 --> 00:51:26,200
there continues to be some of you think that is differentiable

900
00:51:26,300 --> 00:51:27,810
they don't have you know

901
00:51:27,870 --> 00:51:31,930
primitive of of arbitrary order

902
00:51:32,520 --> 00:51:34,640
and this some special cases these are

903
00:51:34,740 --> 00:51:36,430
if you have integer

904
00:51:36,440 --> 00:51:42,430
then there is much to simple expressions the correct don't involve is best option that's

905
00:51:42,430 --> 00:51:43,800
enough to look at

906
00:51:43,870 --> 00:51:46,400
so this is similar plot before

907
00:51:46,400 --> 00:51:49,660
again now parameterized by the new

908
00:51:49,670 --> 00:51:50,800
and again a new

909
00:51:50,820 --> 00:51:52,090
new goes to infinity

910
00:51:52,180 --> 00:51:55,090
get back the the calcium response

911
00:51:55,100 --> 00:51:57,660
and then you get smaller and smaller

912
00:51:57,730 --> 00:51:59,310
then the covariance function

913
00:51:59,810 --> 00:52:05,740
o has a different behavior here particularly zero

914
00:52:05,740 --> 00:52:10,500
function that drawn again the colours

915
00:52:10,550 --> 00:52:12,290
on the other

916
00:52:12,310 --> 00:52:14,570
again we have all the green line

917
00:52:14,580 --> 00:52:17,810
is that function which is infinitely differentiable

918
00:52:17,890 --> 00:52:19,550
and the

919
00:52:19,610 --> 00:52:24,520
the black line here is once differentiable but not vice principal

920
00:52:24,600 --> 00:52:26,240
what you see here

921
00:52:27,020 --> 00:52:28,130
and the

922
00:52:28,430 --> 00:52:35,960
well line here correspond temple function is not differentiable at all

923
00:52:37,370 --> 00:52:40,430
so again we can we can try to learn whether

924
00:52:40,440 --> 00:52:44,980
functions have some of these properties

925
00:52:45,150 --> 00:52:50,080
it's kind of covariance functions

926
00:52:50,100 --> 00:52:53,500
grant went on for four move

927
00:52:53,580 --> 00:52:55,180
periodic function

928
00:52:55,190 --> 00:53:00,090
here's a little construction you can you can you can do to try to model

929
00:53:00,160 --> 00:53:02,650
periodic function

930
00:53:02,810 --> 00:53:04,480
instead of looking at x itself

931
00:53:04,490 --> 00:53:05,380
you can map

932
00:53:05,880 --> 00:53:09,490
x on the signing call sign of that

933
00:53:10,190 --> 00:53:14,000
and then you can do you look at squared exponential kernel

934
00:53:14,020 --> 00:53:15,980
in the two dimensional space

935
00:53:16,140 --> 00:53:22,490
given by signing because if you do that then you get something which is periodic

936
00:53:22,640 --> 00:53:27,330
because if you change you add subtract two pi from x then you get the

937
00:53:28,280 --> 00:53:31,790
sin x and cos x

938
00:53:31,850 --> 00:53:36,020
but still it will be because it will be measuring the distance is now

939
00:53:36,030 --> 00:53:40,140
on the on the unit circle so it points to be close to each other

940
00:53:40,150 --> 00:53:42,890
and also be close in this two-dimensional space

941
00:53:44,030 --> 00:53:45,570
if you do that then you're

942
00:53:45,580 --> 00:53:46,930
and then you can use them

943
00:53:47,300 --> 00:53:53,780
three the parameter functions can write that the rest of the being

944
00:53:53,810 --> 00:53:56,710
he manage to times square

945
00:53:56,740 --> 00:53:59,150
high times next time

946
00:53:59,150 --> 00:54:01,510
over length scales again in this

947
00:54:01,540 --> 00:54:03,620
in this two dimensional space you can measure

948
00:54:03,620 --> 00:54:06,740
distance is the length scale

949
00:54:06,750 --> 00:54:08,650
so here have

950
00:54:08,650 --> 00:54:12,480
you have chosen his words more

951
00:54:12,560 --> 00:54:15,760
and you got get different periodicities by multiplying

952
00:54:15,810 --> 00:54:18,970
i everybody but the period length

953
00:54:19,010 --> 00:54:21,040
we used to think of one

954
00:54:21,050 --> 00:54:22,160
these three

955
00:54:23,080 --> 00:54:26,140
samples from the periodic function

956
00:54:26,180 --> 00:54:29,560
and you can see that there can be no article should be

957
00:54:32,120 --> 00:54:35,690
the idea the length scale of one

958
00:54:35,740 --> 00:54:41,570
i think that when you change things by on the order of one in this

959
00:54:41,580 --> 00:54:42,750
in the space of

960
00:54:42,810 --> 00:54:45,170
one of the points on the unit circle

961
00:54:45,210 --> 00:54:50,240
that means at its base at the distance can be much more than one

962
00:54:50,250 --> 00:54:52,700
because all the underlying on the unit circle

963
00:54:52,730 --> 00:54:55,780
get the maximum to be true

964
00:54:56,760 --> 00:55:01,020
that gives rise to a very smooth function

965
00:55:01,070 --> 00:55:05,470
here i used a much smaller periodic length scale

966
00:55:05,470 --> 00:55:06,170
it is

967
00:55:06,190 --> 00:55:14,130
know i better not say anything about this because otherwise it would stay talk during

968
00:55:14,130 --> 00:55:17,760
one hour

969
00:55:17,760 --> 00:55:22,670
which is not which is not going to be possible OK so i'll skip this

970
00:55:22,670 --> 00:55:26,360
part and i'll talk about kernels for graphs

971
00:55:26,380 --> 00:55:29,820
so here

972
00:55:29,880 --> 00:55:36,700
are different sets of graphs those disease and directed labeled graph

973
00:55:37,090 --> 00:55:38,470
this is

974
00:55:39,400 --> 00:55:41,050
label tree

975
00:55:41,110 --> 00:55:44,720
disease labelled undirected graph

976
00:55:44,760 --> 00:55:47,190
this is

977
00:55:47,940 --> 00:55:51,190
edge label for

978
00:55:51,200 --> 00:55:53,240
it is a labeled graph

979
00:55:53,280 --> 00:55:54,690
and directed

980
00:55:54,700 --> 00:55:59,720
so you have labelled on the edges you have labels on the nodes

981
00:55:59,800 --> 00:56:05,510
so those are different kinds of graphs and those are graphs that you may encounter

982
00:56:16,380 --> 00:56:21,700
all the more reason is

983
00:56:21,720 --> 00:56:23,150
this is

984
00:56:31,510 --> 00:56:33,360
yeah sure

985
00:56:33,380 --> 00:56:35,670
so the price very

986
00:56:35,690 --> 00:56:38,340
three four

987
00:56:40,240 --> 00:56:41,990
and again

988
00:56:41,990 --> 00:56:43,760
there's something very

989
00:56:43,800 --> 00:56:48,780
i don't there's something very difficult i think on fisher kernels in in addition if

990
00:56:48,780 --> 00:56:49,610
you look

991
00:56:49,610 --> 00:56:50,610
if you

992
00:56:50,630 --> 00:56:54,760
go read the paper on fisher kernel you'll see that

993
00:56:55,170 --> 00:56:57,010
deriving using

994
00:56:57,010 --> 00:56:59,420
these feature vector

995
00:56:59,440 --> 00:57:05,170
and doing inference and dot products with this feature vector feature vector is not exactly

996
00:57:05,220 --> 00:57:08,340
the the proper way to do that there is

997
00:57:08,380 --> 00:57:09,840
he then matrices

998
00:57:09,860 --> 00:57:14,650
matrix here which is the fisher information matrix that you should use

999
00:57:15,440 --> 00:57:18,530
those which makes things even more

1000
00:57:22,970 --> 00:57:26,630
but i say that i never practiced fisher kernels if

1001
00:57:26,650 --> 00:57:29,970
maybe it is is it's easy

1002
00:57:33,460 --> 00:57:40,510
a quick very quick reminder on graphs i think that you already has had something

1003
00:57:40,510 --> 00:57:42,960
like that yesterday with

1004
00:57:42,970 --> 00:57:45,630
we're sitting

1005
00:57:46,420 --> 00:57:52,760
four and directed undirected labeled graphs you have

1006
00:57:52,820 --> 00:57:59,090
labeled vertices or nodes and labeled edges and you don't have there's no directions on

1007
00:57:59,130 --> 00:58:03,170
the edges so they are not arcs the edges

1008
00:58:03,240 --> 00:58:08,990
there's the go if you want to go in both both directions for instance

1009
00:58:09,010 --> 00:58:15,400
for chemical compounds you have a set of of of nodes for a set of

1010
00:58:15,400 --> 00:58:20,360
labels for the nodes which are

1011
00:58:23,470 --> 00:58:26,570
oxygen hydrogen

1012
00:58:26,590 --> 00:58:31,840
and here you have different labels for for the bonds

1013
00:58:31,880 --> 00:58:33,360
like simple

1014
00:58:33,360 --> 00:58:34,300
the ball

1015
00:58:35,010 --> 00:58:37,920
i don't remember aromatic

1016
00:58:37,920 --> 00:58:43,030
and heuristic molecule the molecule of of

1017
00:58:44,860 --> 00:58:48,610
the notation that we used to

1018
00:58:49,360 --> 00:58:51,690
to show you some

1019
00:58:51,700 --> 00:58:54,470
graph kernels are the following

1020
00:58:55,630 --> 00:58:57,940
the graph is going to be defined by

1021
00:58:57,960 --> 00:59:02,670
a a set of vertices a set of edges and the set of labels us

1022
00:59:03,030 --> 00:59:08,420
with that go with that both the nodes and the edges

1023
00:59:11,760 --> 00:59:18,590
those are the labels of the nodes and those are the labels of the edges

1024
00:59:18,630 --> 00:59:23,700
he is going to be the adjacency matrix of of

1025
00:59:23,720 --> 00:59:30,070
of of the graph meaning that there is a one in these graphs if i

1026
00:59:30,070 --> 00:59:36,690
and j are connected in the graph and there is zero otherwise and

1027
00:59:38,360 --> 00:59:39,630
and or

1028
00:59:39,650 --> 00:59:44,400
i is equal to one if n of only if label the label of the

1029
00:59:44,400 --> 00:59:46,010
eyes equal to

1030
00:59:48,780 --> 00:59:51,110
the label of of of

1031
00:59:51,130 --> 00:59:52,240
of nodes

1032
00:59:52,260 --> 00:59:54,800
OK here's an example

1033
00:59:54,820 --> 01:00:00,880
it's going to be easier to look at these molecules have five atoms of carbon

1034
01:00:01,470 --> 01:00:04,090
so the set of

1035
01:00:04,130 --> 01:00:10,070
eight the set of labels for a is is a we consider that DCM all

1036
01:00:10,380 --> 01:00:11,400
the set of

1037
01:00:12,510 --> 01:00:16,990
o bonds use these as DTN are they are

1038
01:00:17,220 --> 01:00:22,460
and this molecule is i don't know how to pronounce it in english but let's

1039
01:00:22,460 --> 01:00:25,240
say inference reading

1040
01:00:25,690 --> 01:00:28,190
and you have the set of edges

1041
01:00:28,200 --> 01:00:31,010
so you see here you have you mention that

1042
01:00:31,110 --> 01:00:35,740
here is the first node is if you want here is the second what FT

1043
01:00:35,760 --> 01:00:39,630
two and you see that there's a connection between one and two

1044
01:00:39,650 --> 01:00:43,260
so you look at the first line and the second column

1045
01:00:43,300 --> 01:00:46,010
and you see that is a one

1046
01:00:46,510 --> 01:00:51,340
i think that there's something missing here

1047
01:00:51,360 --> 01:00:53,670
there should be a one here

1048
01:00:53,690 --> 01:00:56,670
because one is connected to six

1049
01:00:56,690 --> 01:00:58,740
but never mind

1050
01:00:58,760 --> 01:01:04,630
and then if you want to look at the labels of the nodes you have

1051
01:01:04,990 --> 01:01:10,820
here you have the the the first line you have

1052
01:01:10,840 --> 01:01:13,050
three different types of labels

1053
01:01:13,070 --> 01:01:14,720
which correspond to

1054
01:01:14,780 --> 01:01:16,320
the three rules

1055
01:01:16,320 --> 01:01:21,400
and then you hear from this matrix matrix you see that the first notice of

1056
01:01:21,400 --> 01:01:24,050
type one type one is c

1057
01:01:24,090 --> 01:01:26,150
the second is of type one

1058
01:01:26,190 --> 01:01:27,550
is c

1059
01:01:27,570 --> 01:01:32,150
let's go to the forty fourth one the fourth one is of a type

1060
01:01:33,090 --> 01:01:36,280
it is the second world single was the

1061
01:01:36,360 --> 01:01:37,820
the story is an

1062
01:01:37,820 --> 01:01:41,510
and you see that the fourth one is x

1063
01:01:41,570 --> 01:01:44,840
this is actually of that

1064
01:01:44,860 --> 01:01:47,760
and is the matrix

1065
01:01:48,170 --> 01:01:55,150
and what did i say OK i say very simple i simplifying thing is that

1066
01:01:55,150 --> 01:02:01,110
all the labels on the edges are the same

1067
01:02:01,150 --> 01:02:03,030
so another example

1068
01:02:03,050 --> 01:02:05,280
it is these molecules

1069
01:02:05,300 --> 01:02:09,920
this is x almost the same as before except that he here you have

1070
01:02:09,970 --> 01:02:12,050
only five items

1071
01:02:12,170 --> 01:02:15,630
and instead of fun and you have it all

1072
01:02:15,630 --> 01:02:19,900
and mike seeks to compose accordingly

1073
01:02:19,910 --> 01:02:21,640
so what does that mean

1074
01:02:21,720 --> 01:02:25,210
it means that can write this big summation here

1075
01:02:25,230 --> 01:02:30,470
as the summation over a whole bunch of factors which are independent neighbouring terms so

1076
01:02:30,470 --> 01:02:35,700
i can push this summation inside the product

1077
01:02:35,740 --> 01:02:39,730
so i can basically pushed the summation over the whiteys up to

1078
01:02:39,740 --> 01:02:42,030
the very end

1079
01:02:42,120 --> 01:02:45,870
next summation one further and so on

1080
01:02:45,870 --> 01:02:48,040
it's just like with an antenna your

1081
01:02:48,060 --> 01:02:49,820
pulling it out

1082
01:02:51,920 --> 01:02:53,650
what the values of this

1083
01:02:53,660 --> 01:02:56,430
now this summation here is really simple

1084
01:02:56,440 --> 01:02:58,160
because i have

1085
01:02:58,170 --> 01:03:03,520
well after all if the white as plus minus one got basically

1086
01:03:03,860 --> 01:03:05,890
two by two object here

1087
01:03:05,890 --> 01:03:06,890
and and we do

1088
01:03:08,280 --> 01:03:09,910
two of the terms here

1089
01:03:09,950 --> 01:03:15,140
same reducing so to say a matrix into the victor

1090
01:03:15,190 --> 01:03:18,860
then summing over the last term then only get something that depends on the white

1091
01:03:18,860 --> 01:03:21,780
people minus one

1092
01:03:21,800 --> 01:03:23,990
now then i can multiply this

1093
01:03:24,010 --> 01:03:26,770
by the next term in the back

1094
01:03:26,820 --> 01:03:31,250
which is the two by two object multiplied by two by one object

1095
01:03:31,350 --> 01:03:36,330
again mean he can some of the y t one once

1096
01:03:36,480 --> 01:03:40,920
and push it further back y t ones twos and so on

1097
01:03:40,930 --> 01:03:42,910
but this allows me to do is

1098
01:03:42,930 --> 01:03:44,700
reduce potentially

1099
01:03:44,710 --> 01:03:46,960
exponential number of terms

1100
01:03:47,010 --> 01:03:48,970
because they're only there

1101
01:03:49,030 --> 01:03:50,230
two to the t

1102
01:03:50,250 --> 01:03:54,300
to the capital t many different sequences here

1103
01:03:54,320 --> 01:03:56,230
into an operation

1104
01:03:56,240 --> 01:03:57,160
which is

1105
01:03:58,050 --> 01:04:03,150
in the length of the sequence thirty times and what they have to do here

1106
01:04:03,190 --> 01:04:04,920
well i have to some

1107
01:04:04,970 --> 01:04:07,970
all four terms

1108
01:04:08,120 --> 01:04:10,790
it's basically for times t

1109
01:04:10,840 --> 01:04:11,970
as opposed to

1110
01:04:11,970 --> 01:04:13,500
two to the t

1111
01:04:13,510 --> 01:04:15,970
was the dramatic improvement

1112
01:04:16,010 --> 01:04:18,450
it's just that then programming

1113
01:04:18,460 --> 01:04:21,000
so anybody who's

1114
01:04:21,090 --> 01:04:23,900
in the forward backward algorithm is essentially

1115
01:04:23,940 --> 01:04:27,360
should have seen that before

1116
01:04:27,380 --> 01:04:32,610
now with computer do you say to given

1117
01:04:32,620 --> 01:04:36,150
in order to actually optimise all parameters

1118
01:04:36,200 --> 01:04:37,810
and in order to perform inference

1119
01:04:37,840 --> 01:04:40,730
we may have to compute p of y t

1120
01:04:40,750 --> 01:04:42,290
given x and theta

1121
01:04:42,300 --> 01:04:46,080
or p of y t and y t plus one given x theta

1122
01:04:46,130 --> 01:04:52,030
and we might also have to compute well the base possible sequence of the wise

1123
01:04:52,050 --> 01:04:56,400
given a particular set of theta and x

1124
01:04:57,470 --> 01:05:02,660
so the best sequence i can compute in the same way through dynamic programming just

1125
01:05:02,660 --> 01:05:06,820
like you in in a hidden markov model you find the best annotation of the

1126
01:05:07,800 --> 01:05:10,610
it's exactly the same structure

1127
01:05:10,640 --> 01:05:14,130
now for the p of y t given x and theta

1128
01:05:14,170 --> 01:05:17,790
just go back

1129
01:05:17,820 --> 01:05:20,420
it said this guy here

1130
01:05:20,450 --> 01:05:23,710
it means i have to sum up with this very set of variables

1131
01:05:23,720 --> 01:05:28,750
now after some or all the variables from the other side

1132
01:05:28,770 --> 01:05:29,930
it turns out now

1133
01:05:29,930 --> 01:05:34,170
that for this big product i can push the summation through from the right

1134
01:05:34,180 --> 01:05:35,260
to here

1135
01:05:35,550 --> 01:05:38,610
i can push the summation through from the left up to here

1136
01:05:38,630 --> 01:05:44,320
and they get terms which only depend on this variable y t

1137
01:05:44,380 --> 01:05:50,300
and this allows me to get the conditional probabilities very easily

1138
01:05:50,320 --> 01:05:52,230
in fact

1139
01:05:52,230 --> 01:05:54,560
if i do although summations

1140
01:05:54,660 --> 01:05:58,150
because i can push it up to any particular point

1141
01:05:58,160 --> 01:06:03,190
installed in the mid intermediate values i can get all those conditional probabilities p of

1142
01:06:03,190 --> 01:06:04,420
y t

1143
01:06:04,630 --> 01:06:11,460
by just one forward and one backward pass

1144
01:06:11,480 --> 01:06:13,520
so as the forward backward algorithm

1145
01:06:13,540 --> 01:06:15,470
sum over all

1146
01:06:15,480 --> 01:06:18,030
those products here

1147
01:06:18,050 --> 01:06:19,940
at a certain point

1148
01:06:19,940 --> 01:06:22,040
same from the but on the other side

1149
01:06:22,220 --> 01:06:26,860
and this allows you to get the prior probability for a particular entry

1150
01:06:26,870 --> 01:06:29,910
but if you store already what you got up to here

1151
01:06:29,930 --> 01:06:34,190
new store what you get by going one step further you get the same quantity

1152
01:06:34,190 --> 01:06:37,860
for this entity so it doesn't really cost to anything more

1153
01:06:37,880 --> 01:06:43,460
except for extra storage to get all the conditional probabilities at one

1154
01:06:43,470 --> 01:06:45,950
they you might think well what you actually need them

1155
01:06:46,060 --> 01:06:50,750
well you do need them in order to perform inference

1156
01:06:50,810 --> 01:06:51,950
it is actually

1157
01:06:51,950 --> 01:06:53,360
as it will turn out

1158
01:06:53,370 --> 01:06:57,870
these are exactly the qualities that you will need to optimize for in where to

1159
01:06:57,870 --> 01:07:04,400
find the parameters theta that will give you good annotation

1160
01:07:06,560 --> 01:07:07,920
now here's the diff

1161
01:07:08,690 --> 01:07:14,060
so remember this with the objective function here

1162
01:07:14,180 --> 01:07:18,330
this piece of them

1163
01:07:19,740 --> 01:07:24,090
i know it's convex and let's assume i have some optimisation procedure which can make

1164
01:07:24,090 --> 01:07:26,970
do with only the first reverted

1165
01:07:26,970 --> 01:07:28,000
the second ones are

1166
01:07:28,030 --> 01:07:32,550
sometimes quite nasty but let's assume i have some magic procedure for that

1167
01:07:32,560 --> 01:07:37,140
so the first derivative of this expression here

1168
01:07:37,140 --> 01:07:39,510
and the question is which one is more likely to join so i have no

1169
01:07:40,310 --> 01:07:41,600
that has

1170
01:07:41,610 --> 01:07:45,630
that has the connections to the inside the group but none of these three three

1171
01:07:45,630 --> 01:07:50,880
nodes into groups connected among themselves and you have a different situation where this all

1172
01:07:50,940 --> 01:07:54,640
his friends know each other so the question is is x more likely to join

1173
01:07:54,640 --> 01:07:55,720
the y

1174
01:07:56,000 --> 01:08:02,400
and there are two competing social theory so the first one is called the information

1175
01:08:02,400 --> 01:08:04,700
i need my grand so

1176
01:08:04,740 --> 01:08:06,260
this is the next

1177
01:08:06,880 --> 01:08:09,650
how to think about this is that for example if

1178
01:08:11,370 --> 01:08:12,850
you want to buy

1179
01:08:12,850 --> 01:08:16,630
and you get something that he would say OK you can actually to get

1180
01:08:16,760 --> 01:08:20,810
independent sources of recommendation so if i hear from training

1181
01:08:20,830 --> 01:08:24,710
the friends who don't know each other so from the independent sources that you know

1182
01:08:24,710 --> 01:08:29,700
you should go by this thing then maybe i trust i trust that recombination more

1183
01:08:29,700 --> 01:08:33,390
than you know if i get recommendations from the same part of the network or

1184
01:08:33,390 --> 01:08:35,210
from the same community

1185
01:08:35,220 --> 01:08:39,820
some information on say x is more likely to join because he gets get more

1186
01:08:39,820 --> 01:08:44,760
independent information or more independent recommendations to go join on the other hand

1187
01:08:44,950 --> 01:08:48,670
there is a social capital arguement the same the y is more likely to write

1188
01:08:48,670 --> 01:08:53,450
while because then densely connected sets of friends in the network so when he joins

1189
01:08:53,450 --> 01:08:57,650
his feel very well i you have a lot of people or a lot of

1190
01:08:57,650 --> 01:09:01,320
people to kind of this people already know each other so confusing

1191
01:09:01,900 --> 01:09:07,350
right so basically that stress safety is what makes white joined

1192
01:09:07,350 --> 01:09:11,180
and actually if you go measure that it turns out that that's the best explanation

1193
01:09:12,920 --> 01:09:17,420
what's important here is the proportion of best but the adjacent basically proportion of my

1194
01:09:17,420 --> 01:09:21,690
friends were members of the group and adjacent to one another meaning that connected with

1195
01:09:21,700 --> 01:09:25,560
the probability of of thinking and you can see there is something that the more

1196
01:09:25,560 --> 01:09:29,310
the connections between my friends in the group the more likely i am to join

1197
01:09:31,340 --> 01:09:34,420
the social capital arguement is basically the one that seems to be in place for

1198
01:09:34,420 --> 01:09:36,940
the larger that

1199
01:09:37,870 --> 01:09:40,800
what so just to recap what show

1200
01:09:40,850 --> 01:09:42,840
so far i've shown that

1201
01:09:42,870 --> 01:09:43,750
so far

1202
01:09:43,760 --> 01:09:48,090
the results seem to suggest that this network groups tend to be tightly connected that

1203
01:09:48,180 --> 01:09:51,080
said that you're more likely to join you have lots of friends in there and

1204
01:09:51,230 --> 01:09:55,350
his friends are connected that that like so

1205
01:09:55,370 --> 01:09:59,120
just this was sort of like the motivation for why do you think of network

1206
01:09:59,180 --> 01:10:02,900
groups are classed as being then connected right so the idea is that i be

1207
01:10:02,900 --> 01:10:04,090
talking about

1208
01:10:04,110 --> 01:10:07,260
let's call the communities clusters groups modules

1209
01:10:07,270 --> 01:10:11,480
what they're right i'm using these words changing and i don't want to make any

1210
01:10:12,240 --> 01:10:13,620
notation about

1211
01:10:14,050 --> 01:10:18,250
are the new york clusters story of social groups and and so when i use

1212
01:10:18,250 --> 01:10:21,140
distance from it just means sets of nodes with

1213
01:10:21,190 --> 01:10:24,990
relatively lots of connections from the inside the two connections to the outside OK so

1214
01:10:24,990 --> 01:10:27,200
this is what i mean by now

1215
01:10:27,240 --> 01:10:31,940
and the first question you can go and ask okay how can automatically going to

1216
01:10:31,940 --> 01:10:33,350
find such

1217
01:10:33,370 --> 01:10:35,900
and when i say GO and you know

1218
01:10:35,920 --> 01:10:40,750
ultimately find what i would like the idea is that this clusters that they extract

1219
01:10:40,750 --> 01:10:45,930
with correspond to somebody looks like so for example in social networks they would correspond

1220
01:10:45,930 --> 01:10:50,480
to real social communities in you know biological networks i would hope they would correspond

1221
01:10:50,480 --> 01:10:55,840
to you know function functional modules in the cell so that that's the

1222
01:10:55,880 --> 01:11:00,850
and let me show you two in two examples of where is so

1223
01:11:00,860 --> 01:11:06,290
this is probably the most famous example it's called seconds karate club right in the

1224
01:11:06,320 --> 01:11:10,940
one here is that when secretary was during his phd in nineteen seventy

1225
01:11:10,960 --> 01:11:13,600
he was observing social ties

1226
01:11:13,610 --> 01:11:15,970
in a university karate club

1227
01:11:16,590 --> 01:11:21,680
and during the course of his study there were some disagreements in the karate club

1228
01:11:21,680 --> 01:11:24,800
speed so basically took the club for

1229
01:11:25,770 --> 01:11:27,100
so i could join

1230
01:11:27,590 --> 01:11:29,950
the one club and

1231
01:11:30,150 --> 01:11:33,950
square sort of the shared nodes joined into the

1232
01:11:35,250 --> 01:11:39,470
and then the question is how can we explain this and it turns out that

1233
01:11:39,470 --> 01:11:43,350
the the mean of these networks became an almost perfect you know with a single

1234
01:11:43,450 --> 01:11:46,370
mistake here explains how people

1235
01:11:46,630 --> 01:11:49,090
introduced new uniforms

1236
01:11:49,230 --> 01:11:52,350
right so this is not a a nice example where you know network structure actually

1237
01:11:52,350 --> 01:11:54,020
tells me use me

1238
01:11:54,850 --> 01:11:56,000
o explains

1239
01:11:56,010 --> 01:11:57,190
how these two new

1240
01:11:57,200 --> 01:12:00,940
good article i got four right so that that's the ideal case what we would

1241
01:12:00,940 --> 01:12:03,970
like to to get from find clusters of communities

1242
01:12:03,970 --> 01:12:07,000
a different example comes from the web search

1243
01:12:07,060 --> 01:12:12,890
it's so in the web search i have the sort keywords and advertising advertisers bidded

1244
01:12:12,930 --> 01:12:16,630
saying you know when i was watching i want my at the show

1245
01:12:16,640 --> 01:12:20,210
and what we would like to do is we like to partition is this bipartite

1246
01:12:20,210 --> 01:12:26,610
graph will find you know this is no adjacency matrix finds thence their some blocks

1247
01:12:27,270 --> 01:12:32,350
which corresponds to micro markets being that you know what this advertisers tend to be

1248
01:12:32,360 --> 01:12:33,900
done the same

1249
01:12:34,240 --> 01:12:37,220
and you know then maybe you could try to exploit the structure

1250
01:12:37,230 --> 01:12:40,380
by knowing that you know that is set of people who tend to be on

1251
01:12:40,380 --> 01:12:42,610
the on the same type of you

1252
01:12:42,670 --> 01:12:46,380
so these are like two examples what we what we hope to to get from

1253
01:12:48,090 --> 01:12:50,850
and that is like a lot of methods to the right

1254
01:12:50,870 --> 01:12:55,120
not going through all of them but you know my data is nice i can

1255
01:12:55,120 --> 01:12:58,020
just use some lower-end

1256
01:12:58,040 --> 01:13:02,580
approximation so you know linear methods if i data is not so nice but it's

1257
01:13:02,580 --> 01:13:06,990
still a low dimensional manifold in this country as i can use article methods were

1258
01:13:06,990 --> 01:13:08,770
in the top down

1259
01:13:08,850 --> 01:13:14,170
or i can graph partitioning to find discussed where basically defined some

1260
01:13:14,210 --> 01:13:18,310
let's call it edge counting measure like you know conductance modularity but there are and

1261
01:13:18,310 --> 01:13:19,650
then optimize

1262
01:13:19,680 --> 01:13:21,670
this measure

1263
01:13:21,740 --> 01:13:23,350
find cluster

1264
01:13:23,360 --> 01:13:28,270
so just to give you a flavour of how these things work here

1265
01:13:28,560 --> 01:13:33,940
o away all the items from basic developed by physicists it's very intuitive how it

1266
01:13:34,820 --> 01:13:40,710
so they depend on this notion of edge betweenness and between is just the number

1267
01:13:40,710 --> 01:13:42,080
of shortest that

1268
01:13:42,080 --> 01:13:43,290
but to go from

1269
01:13:43,310 --> 01:13:47,590
right so for example this search here on this example has between the forty nine

1270
01:13:47,750 --> 01:13:50,210
right because they have seven notes here and

1271
01:13:50,240 --> 01:13:53,450
for every of the seminoles if they want to want to get to any of

1272
01:13:53,450 --> 01:13:57,480
the seminoles here the shortest path as the growth of his

1273
01:13:57,530 --> 01:14:02,450
the highest betweenness edge in our writing by similar to many such between this be

1274
01:14:02,580 --> 01:14:07,190
because there are eleven edges here eleven notes here in three here and whenever i

1275
01:14:07,190 --> 01:14:10,360
want to get from this the when you see them and i have to crunch

1276
01:14:10,380 --> 01:14:12,660
so that if short goes

1277
01:14:12,660 --> 01:14:14,260
minors of

1278
01:14:14,310 --> 01:14:16,210
of infor

1279
01:14:16,230 --> 01:14:17,190
times l

1280
01:14:17,200 --> 01:14:19,810
time delta t

1281
01:14:19,830 --> 01:14:22,340
what is the difference matters

1282
01:14:22,900 --> 01:14:23,940
the difference

1283
01:14:23,960 --> 01:14:27,240
is seventeen minus one hundred sixteen

1284
01:14:27,250 --> 01:14:30,220
times ten to the minus six

1285
01:14:30,270 --> 01:14:31,270
times l

1286
01:14:31,320 --> 01:14:34,160
delta t

1287
01:14:34,200 --> 01:14:35,630
and if i take

1288
01:14:35,660 --> 01:14:38,750
the length of ten centimetres

1289
01:14:38,770 --> 01:14:44,070
and i increase the temperature

1290
01:14:44,120 --> 01:14:47,020
five hundred degrees centigrade

1291
01:14:47,040 --> 01:14:48,400
then this difference

1292
01:14:48,410 --> 01:14:52,820
but you can easily calculate is point one six millimetres

1293
01:14:52,860 --> 01:14:54,420
o point one

1294
01:14:57,120 --> 01:14:59,490
very little

1295
01:14:59,520 --> 01:15:01,100
and yet

1296
01:15:01,110 --> 01:15:03,460
this one will curve

1297
01:15:06,290 --> 01:15:08,080
for those of you

1298
01:15:08,170 --> 01:15:10,190
well mathematically oriented

1299
01:15:10,200 --> 01:15:13,580
i would advise you to make an attempt to calculate

1300
01:15:13,650 --> 01:15:14,800
so you have

1301
01:15:14,960 --> 01:15:18,610
you assume that a perfect circle reasonable approximation

1302
01:15:18,690 --> 01:15:22,180
so you have an outer circle

1303
01:15:22,230 --> 01:15:23,550
which is longer

1304
01:15:23,550 --> 01:15:25,940
five point one six millimetres in the in one

1305
01:15:26,150 --> 01:15:28,710
try to solve and find with that these

1306
01:15:28,760 --> 01:15:30,900
and i went through that exercise

1307
01:15:30,900 --> 01:15:34,190
and you want to do that to perhaps and i found that for many for

1308
01:15:34,220 --> 01:15:36,390
these dimensions

1309
01:15:36,430 --> 01:15:37,810
for many years

1310
01:15:37,810 --> 01:15:39,470
that substantial

1311
01:15:39,630 --> 01:15:42,990
so this thing is being used for thermostats

1312
01:15:45,710 --> 01:15:49,240
you break and make contact heating system

1313
01:15:49,290 --> 01:15:52,950
which could for instance be as follows

1314
01:15:52,970 --> 01:15:55,190
he would be anywhere by metal

1315
01:15:55,200 --> 01:15:57,210
very schematically

1316
01:15:57,220 --> 01:16:01,050
plug in the wall hundred temples

1317
01:16:02,380 --> 01:16:08,820
you know that's it like that

1318
01:16:08,910 --> 01:16:10,840
and when it's cold

1319
01:16:10,890 --> 01:16:12,840
this is down

1320
01:16:14,130 --> 01:16:15,900
and the works

1321
01:16:15,910 --> 01:16:18,680
and then the room temperature goes up

1322
01:16:18,730 --> 01:16:20,420
this starts to curl

1323
01:16:20,430 --> 01:16:21,640
it breaks

1324
01:16:21,640 --> 01:16:25,170
and that's the so much that that is the basic idea behind the so that

1325
01:16:25,210 --> 01:16:29,260
and you have the new cars have them at home and central

1326
01:16:29,340 --> 01:16:30,520
heating system

1327
01:16:31,850 --> 01:16:34,940
you use all over the place

1328
01:16:34,990 --> 01:16:38,420
they also being used for safety device

1329
01:16:38,430 --> 01:16:41,160
if you have a gas holder either

1330
01:16:41,170 --> 01:16:44,700
in the pilot light in the flame of the pilot light

1331
01:16:44,750 --> 01:16:46,560
is a bimodal

1332
01:16:46,590 --> 01:16:48,660
and when that by metal is hot

1333
01:16:48,760 --> 01:16:50,450
the gas valve is opened

1334
01:16:50,500 --> 01:16:53,890
when that by metal gets called it shuts off the gas valve

1335
01:16:53,920 --> 01:16:55,810
this is a safety device

1336
01:16:55,810 --> 01:16:59,570
in fact in europe all guests i've protected

1337
01:16:59,580 --> 01:17:00,400
that way

1338
01:17:00,420 --> 01:17:01,130
by law

1339
01:17:01,140 --> 01:17:03,830
strangely enough not in the united states

1340
01:17:03,840 --> 01:17:06,410
it is very surprising if i open my

1341
01:17:06,470 --> 01:17:08,470
gas well home my style

1342
01:17:08,510 --> 01:17:11,010
the gas will just come out

1343
01:17:11,060 --> 01:17:14,160
just like that is no prevention of that happening

1344
01:17:14,210 --> 01:17:15,990
you know that's not possible

1345
01:17:16,000 --> 01:17:19,070
there's always the pilot light somewhere with by bimodal

1346
01:17:19,110 --> 01:17:22,820
it senses that there is flame nearby to ignite the gas

1347
01:17:22,870 --> 01:17:24,520
and if that claim is out

1348
01:17:24,550 --> 01:17:26,500
the gas valve will be closed

1349
01:17:26,520 --> 01:17:32,070
so by metals can also be used very effectively for safety devices

1350
01:17:32,070 --> 01:17:34,840
i have you're by bimodal

1351
01:17:34,890 --> 01:17:38,490
one side i believe we believe is aluminum

1352
01:17:38,510 --> 01:17:41,630
on the other side we believe is i

1353
01:17:41,670 --> 01:17:43,170
and when i did that

1354
01:17:43,220 --> 01:17:46,540
you will see that it starts to

1355
01:17:53,870 --> 01:18:09,420
it will

1356
01:18:25,040 --> 01:18:32,720
you get the idea

1357
01:18:32,840 --> 01:18:34,650
the thermometer

1358
01:18:34,700 --> 01:18:44,390
very crude from the this the idea of someone so of course

1359
01:18:44,390 --> 01:18:46,080
mark the set

1360
01:18:46,180 --> 01:18:47,570
was the person

1361
01:18:47,610 --> 01:18:51,690
who was preparing always these demonstrations in the fabulous way

1362
01:18:51,740 --> 01:18:53,810
told me he had at home a

1363
01:18:53,850 --> 01:18:55,770
coffee make

1364
01:18:55,830 --> 01:18:59,090
and the coffee maker is designed in such a way

1365
01:18:59,140 --> 01:19:01,160
that there is a bimodal

1366
01:19:01,170 --> 01:19:04,590
the bottom of the water reservoir you the water reservoir

1367
01:19:04,590 --> 01:19:08,370
and when the water reaches a certain temperature by mental opens in the water comes

1368
01:19:09,130 --> 01:19:10,580
and go to the coffee

1369
01:19:10,600 --> 01:19:20,360
i like to show that he was really cute

1370
01:19:20,370 --> 01:19:24,000
he was the coffee machine it's not working anymore it's a very old one

1371
01:19:24,070 --> 01:19:28,740
but i want to show you with these that by metal

1372
01:19:28,760 --> 01:19:31,420
this is that by metal strips

1373
01:19:31,430 --> 01:19:34,900
what goes on here you heat it when it's hard enough

1374
01:19:34,910 --> 01:19:37,560
by metal lifts up

1375
01:19:37,640 --> 01:19:41,370
you can see there's a whole there is that the whole

1376
01:19:41,410 --> 01:19:45,570
what comes out environmentalist closed close

1377
01:19:45,690 --> 01:19:48,870
the amazing simple idea

1378
01:19:48,920 --> 01:19:52,400
criterion for letting the water goes through the coffee is simply

1379
01:19:52,400 --> 01:19:55,170
when the water reaches the temperature close to boiling

1380
01:19:55,270 --> 01:19:56,350
and you

1381
01:19:56,420 --> 01:19:57,990
have your by metal

1382
01:19:58,010 --> 01:19:58,980
control it

1383
01:19:58,990 --> 01:20:00,310
so by metals

1384
01:20:00,310 --> 01:20:02,600
in many ways control matters

1385
01:20:02,640 --> 01:20:05,420
the most as in this case they act like

1386
01:20:05,540 --> 01:20:09,630
like if l

1387
01:20:09,640 --> 01:20:11,770
by metals can be used

1388
01:20:14,160 --> 01:20:15,960
in fact the one that you see

1389
01:20:15,970 --> 01:20:19,660
right here

1390
01:20:19,660 --> 01:20:21,860
it's driven exclusively by

1391
01:20:21,890 --> 01:20:23,720
by metal

1392
01:20:23,790 --> 01:20:24,920
if you look in the back

1393
01:20:24,940 --> 01:20:30,630
this thermometer analysis showed it to you shortly because i broke one open for you

1394
01:20:30,630 --> 01:20:34,210
then it looks like this

1395
01:20:34,260 --> 01:20:36,690
as the core

1396
01:20:36,820 --> 01:20:41,900
this and of the choral is attached to the plastic casing

1397
01:20:41,930 --> 01:20:43,410
and here

1398
01:20:43,410 --> 01:20:44,000
so i think

1399
01:20:44,020 --> 01:20:47,240
state action distribution the next state europe

1400
01:20:49,840 --> 01:20:51,330
you're trying to learn

1401
01:20:51,970 --> 01:20:58,220
learn mapping so i think perhaps where you're getting to is the fact that there

1402
01:20:58,240 --> 01:21:04,790
is obviously a notion of latent learning notion of learning as you're experiencing the world

1403
01:21:05,150 --> 01:21:09,590
without being driven by reinforcement learning let me come back to that addressing that i'm

1404
01:21:09,590 --> 01:21:10,630
going to try to

1405
01:21:10,650 --> 01:21:13,010
o address so that i'm building up

1406
01:21:13,130 --> 01:21:16,370
and building up the foundations second get the more

1407
01:21:16,390 --> 01:21:23,920
interesting material eventually so little often that

1408
01:21:24,920 --> 01:21:25,890
that's too

1409
01:21:25,900 --> 01:21:30,150
o i should say some something more slightly more about this so long

1410
01:21:30,160 --> 01:21:33,580
this is obviously a dumb way of doing things right i mean you

1411
01:21:33,590 --> 01:21:35,390
you can't do use in chess

1412
01:21:35,500 --> 01:21:39,270
countries in any real problem so what do people do instead

1413
01:21:39,530 --> 01:21:45,980
people obvious thing the parametric models of function approximation based model the transition probabilities and

1414
01:21:45,980 --> 01:21:48,910
what functions rather than lookup table

1415
01:21:48,930 --> 01:21:50,850
and this is not

1416
01:21:50,900 --> 01:21:55,650
a talk on civilised learning or that sort of thing i'm not going to spend

1417
01:21:55,650 --> 01:22:01,690
much time in that direction talk about function approximation somewhere down the road but you

1418
01:22:02,540 --> 01:22:06,220
all of you know about function approximation method supervised learning methods you can plug in

1419
01:22:06,220 --> 01:22:11,110
any method you want right to estimate the model from the data

1420
01:22:11,120 --> 01:22:15,400
they just a supervised learning problem and pick your favourite so i learning method do

1421
01:22:15,400 --> 01:22:19,610
it so clearly people in general parametric models neural networks

1422
01:22:19,630 --> 01:22:23,540
all these sorts of things rather than building lookuptable things my goal is to give

1423
01:22:23,540 --> 01:22:28,930
you a conceptual idea OK let's number one whether the more interesting contribution

1424
01:22:28,940 --> 01:22:29,830
really now

1425
01:22:29,850 --> 01:22:32,550
what about describe now is really the

1426
01:22:33,100 --> 01:22:35,370
up until now all of this

1427
01:22:35,390 --> 01:22:36,750
what i talked about

1428
01:22:36,800 --> 01:22:41,210
more or less comes from outside of forced comes operations research now what about to

1429
01:22:41,210 --> 01:22:45,360
describe you the first

1430
01:22:45,380 --> 01:22:52,040
exciting contribution that generated much excitement within the field of modern reinforced warning that the

1431
01:22:52,050 --> 01:22:56,290
outcome called q learning a bit about the OK

1432
01:22:57,980 --> 01:22:59,530
we're going to have direct method

1433
01:22:59,580 --> 01:23:04,050
for solving the optimal control problem that is we can learn a good estimate

1434
01:23:04,100 --> 01:23:05,310
a good policy

1435
01:23:05,360 --> 01:23:09,810
without ever learning disabilities that without ever learning the reward function

1436
01:23:09,820 --> 01:23:11,100
is all we do it

1437
01:23:11,150 --> 01:23:12,740
you have

1438
01:23:12,760 --> 01:23:16,280
the same objective experience

1439
01:23:16,320 --> 01:23:18,970
let's look at the unit of experience which is the state

1440
01:23:18,980 --> 01:23:21,720
and k actually going to work on k

1441
01:23:21,740 --> 01:23:24,100
mister time keepers one

1442
01:23:24,120 --> 01:23:28,020
what we're going to do is going to maintain an estimate

1443
01:23:28,040 --> 01:23:31,340
of the q value of every state action pair

1444
01:23:31,440 --> 01:23:34,290
and every time step

1445
01:23:34,360 --> 01:23:37,300
update that q value function

1446
01:23:37,350 --> 01:23:38,410
at time k

1447
01:23:38,430 --> 01:23:42,850
i will update the state action pair that we see at time k

1448
01:23:42,860 --> 01:23:44,300
it's q values

1449
01:23:44,310 --> 01:23:46,740
to be a mixture of all q value

1450
01:23:46,750 --> 01:23:49,800
and then you guess

1451
01:23:49,810 --> 01:23:51,460
this is the or q value

1452
01:23:51,510 --> 01:23:53,490
out by the step size let's say it

1453
01:23:53,500 --> 01:23:58,420
o point one so it's point nine thousand or q value plus point one times

1454
01:23:58,420 --> 01:23:59,490
this new guess

1455
01:23:59,510 --> 01:24:00,820
what's the new guess

1456
01:24:00,830 --> 01:24:04,310
and you get the immediate reward you see

1457
01:24:04,320 --> 01:24:06,350
plus the discounted

1458
01:24:06,400 --> 01:24:07,960
best value

1459
01:24:07,990 --> 01:24:12,450
of the actual next state you happen to see

1460
01:24:12,460 --> 01:24:19,990
so i'm taking k AKR KSK plus one playing it in here right skk skk

1461
01:24:20,990 --> 01:24:23,120
escape is one

1462
01:24:23,200 --> 01:24:29,020
i'm using the experience and updating the q value for state action pair

1463
01:24:29,070 --> 01:24:31,140
this algorithm is called q learning

1464
01:24:31,160 --> 01:24:32,070
developed by

1465
01:24:32,080 --> 01:24:34,880
chris watkins in nineteen eighty eight

1466
01:24:37,420 --> 01:24:38,980
is the

1467
01:24:39,030 --> 01:24:41,060
and it provably convergent

1468
01:24:41,110 --> 01:24:45,570
under certain conditions of describe to the optimal q value function from which the optimal

1469
01:24:45,570 --> 01:24:47,640
policy then the right

1470
01:24:47,690 --> 01:24:54,200
it was the first big prior to this came the album called temporal difference TD

1471
01:24:54,350 --> 01:24:58,640
not going to describe because you can think of temporal difference in as really the

1472
01:24:58,640 --> 01:25:02,580
same algorithm but applied to the policy evaluation problem

1473
01:25:02,660 --> 01:25:05,890
rather than the optimal control problem so i'm going to focus on the optimal control

1474
01:25:05,890 --> 01:25:06,860
problem just here

1475
01:25:06,960 --> 01:25:09,900
we should let me show this algorithm to you

1476
01:25:09,950 --> 01:25:15,700
let me point out several features of south talk about converting first observe that this

1477
01:25:15,700 --> 01:25:19,560
algorithm only update the state action pairs as they visited

1478
01:25:19,570 --> 01:25:23,750
my only update thing that happened

1479
01:25:24,870 --> 01:25:26,390
now what i'm about to show you

1480
01:25:29,340 --> 01:25:31,230
in one slide

1481
01:25:31,340 --> 01:25:32,750
the high level

1482
01:25:32,760 --> 01:25:35,430
why this algorithm converges

1483
01:25:35,470 --> 01:25:38,500
the same thing that q value iteration

1484
01:25:38,550 --> 01:25:40,570
converges to

1485
01:25:41,410 --> 01:25:45,660
so let's look at the algorithm again it's on top

1486
01:25:45,670 --> 01:25:47,230
here the critical observation

1487
01:25:47,240 --> 01:25:52,650
if you look at the thing inside the square brackets

1488
01:25:52,670 --> 01:25:55,210
and take expectation

1489
01:25:55,220 --> 01:25:59,100
expectation or what what's the random variable inside here that i have ever said his

1490
01:25:59,100 --> 01:26:01,810
around the next state

1491
01:26:02,000 --> 01:26:04,420
the expectation of the next state

1492
01:26:04,470 --> 01:26:05,600
you get the

1493
01:26:05,620 --> 01:26:08,490
and the random variable here is the is the reward

1494
01:26:08,500 --> 01:26:11,490
because the world depends on the next state happen to draw

1495
01:26:11,660 --> 01:26:13,430
so the expectation of this

1496
01:26:13,440 --> 01:26:16,830
square brackets quantity is the media expected reward

1497
01:26:16,880 --> 01:26:18,510
plus the discounted

1498
01:26:20,060 --> 01:26:25,700
the best value of the next day

1499
01:26:25,710 --> 01:26:27,680
and this quantity

1500
01:26:27,690 --> 01:26:31,830
is exactly the quantity q value iteration users

1501
01:26:31,880 --> 01:26:33,500
what it does is iteration

1502
01:26:33,510 --> 01:26:37,810
so we talked about is converging by contraction

1503
01:26:37,820 --> 01:26:38,780
so if

1504
01:26:38,790 --> 01:26:43,180
we could use the expected value

1505
01:26:43,230 --> 01:26:44,920
we would be contracted

1506
01:26:44,980 --> 01:26:46,700
instead what we're getting

1507
01:26:46,710 --> 01:26:53,030
is in noisy quantity that is the expected that that is essentially adding means noise

1508
01:26:53,040 --> 01:26:53,750
to this

1509
01:26:53,800 --> 01:26:56,920
q value iteration like quantity

1510
01:26:56,970 --> 01:27:01,450
so instead of contracting at every step

1511
01:27:01,460 --> 01:27:03,590
you can think of we started one

1512
01:27:03,610 --> 01:27:05,820
q value iteration would have taken you this too

1513
01:27:05,830 --> 01:27:10,430
instead of going to this two we're going to some noisy version of two

1514
01:27:10,430 --> 01:27:12,470
about and services push push me

1515
01:27:13,010 --> 01:27:17,570
after a while you learn what you can actually do is move the air over

1516
01:27:17,580 --> 01:27:21,720
the thing and then click on the button and that somehow corresponds to push the

1517
01:27:21,730 --> 01:27:24,430
physical buttons there are actually used

1518
01:27:24,440 --> 01:27:29,310
OK finally you can figure that operated device if you have knowledge about how it

1519
01:27:29,310 --> 01:27:32,630
works this is often called mental model

1520
01:27:33,650 --> 01:27:38,140
one of the best examples i know of this comes from the star trek movies

1521
01:27:38,160 --> 01:27:39,120
which may

1522
01:27:39,130 --> 01:27:45,230
c where scotty figures out how to operate the cling on starship

1523
01:27:45,240 --> 01:27:47,320
even though

1524
01:27:47,330 --> 01:27:49,750
he's never been one before apparently

1525
01:27:49,760 --> 01:27:53,930
and that he does that because he knows how star ships work so he knows

1526
01:27:53,950 --> 01:27:59,160
he's able to figure out the controls humans

1527
01:27:59,170 --> 01:28:03,190
normally if we don't do very well with this sort of thing and is the

1528
01:28:03,190 --> 01:28:06,370
technologies developed it becomes harder and harder

1529
01:28:06,410 --> 01:28:12,120
to know how the thing works you could build a computer from ships yourself

1530
01:28:12,130 --> 01:28:16,680
you could have that knowledge but if i give you a digital device there's a

1531
01:28:16,680 --> 01:28:22,010
very good chance that unless it follows some simple pattern you've seen before you will

1532
01:28:22,010 --> 01:28:26,810
not be able to figure out how to operate based on your knowledge of how

1533
01:28:26,820 --> 01:28:32,320
digital systems work depends on the arbitrary programming that somebody else did

1534
01:28:32,340 --> 01:28:38,290
OK so this is actually very weak form of knowledge for inferring out of device

1535
01:28:39,490 --> 01:28:46,520
psychologists like to distinguish the knowledge that's relevant here to declarative knowledge and procedural knowledge

1536
01:28:46,660 --> 01:28:51,130
because the knowledge is knowledge of facts it's the kind of knowledge that we should

1537
01:28:51,130 --> 01:28:56,170
have used to learning all the time procedural knowledge is knowledge of what to do

1538
01:28:56,180 --> 01:29:02,260
knowledge of procedures there's some specific ideas about how to represent this one these are

1539
01:29:02,260 --> 01:29:07,900
relevant to interacting with a device entity concept here is that

1540
01:29:07,910 --> 01:29:13,300
the knowledge that is required to interact with the device successfully the harder is going

1541
01:29:13,300 --> 01:29:16,390
to be to learn how to use and the harder is going to be to

1542
01:29:16,390 --> 01:29:17,450
actually use

1543
01:29:17,470 --> 01:29:22,260
OK even if you already know how to use it to the steps involved in

1544
01:29:22,260 --> 01:29:24,370
mental steps you have to go through

1545
01:29:24,380 --> 01:29:29,710
procedural steps you have to go through correlates with how much of the knowledge there

1546
01:29:29,750 --> 01:29:35,850
still are so the classical distinction between system could be easy to be hard to

1547
01:29:35,850 --> 01:29:41,690
use actually does not hold systems that are easy to learn almost always are also

1548
01:29:41,690 --> 01:29:44,220
easy to use and vice versa

1549
01:29:44,240 --> 01:29:49,540
OK this historical accident that we early in the history of

1550
01:29:49,560 --> 01:29:53,130
computer systems encountered systems were that was not true

1551
01:29:53,210 --> 01:29:57,560
OK but by and large is of learning and ease of use go together

1552
01:30:00,870 --> 01:30:04,660
OK important principles of

1553
01:30:04,680 --> 01:30:07,350
that has been that can be applied here

1554
01:30:07,470 --> 01:30:11,320
it's called the rationality principle when people are acting

1555
01:30:11,340 --> 01:30:13,740
one people trying to get something done

1556
01:30:13,780 --> 01:30:17,590
a good first approximation is they're trying to rationally

1557
01:30:17,610 --> 01:30:19,650
deal with the situation

1558
01:30:19,690 --> 01:30:24,580
the trying to meet their goals and what determines how well they can do that

1559
01:30:24,580 --> 01:30:29,250
is the characteristics of the task what it is they have to do what's possible

1560
01:30:29,250 --> 01:30:35,260
actions can be done what input information they have what knowledge they have their processing

1561
01:30:37,630 --> 01:30:44,260
he have limited ability to process information that plays a role in how they figure

1562
01:30:44,260 --> 01:30:48,720
out how to get something done key point here is that the goal it the

1563
01:30:48,720 --> 01:30:53,830
tasks and the operators don't depend on the characteristics of the individual person or function

1564
01:30:53,840 --> 01:31:00,210
of the objective physical situations you can often define the optimum performance in these terms

1565
01:31:00,210 --> 01:31:04,970
like what's the fastest way to do certain things with a system that has this

1566
01:31:04,970 --> 01:31:10,290
design in this situation what's the best way to delete it word for example

1567
01:31:10,300 --> 01:31:13,230
you point out and double click on

1568
01:31:13,240 --> 01:31:19,480
for example or drag overall driving over nominating delete more than double clicking on the

1569
01:31:21,950 --> 01:31:26,230
and in the middle east he seemed to find optimum ways to get things done

1570
01:31:26,980 --> 01:31:33,280
OK rationality principle and say that with practice people try to optimize if possible we

1571
01:31:33,280 --> 01:31:38,010
have to have the required knowledge and work within processing limits but

1572
01:31:38,030 --> 01:31:43,440
to the extent that they can do this you can actually predict behavior surprisingly well

1573
01:31:43,460 --> 01:31:44,790
for example

1574
01:31:44,810 --> 01:31:46,770
i can produce

1575
01:31:46,790 --> 01:31:48,320
given what i know about it

1576
01:31:48,330 --> 01:31:50,700
these factors in the situation

1577
01:31:50,710 --> 01:31:52,270
and way most people

1578
01:31:52,280 --> 01:31:53,930
but optimize things

1579
01:31:56,950 --> 01:31:59,810
approximately twenty five minutes from now

1580
01:31:59,820 --> 01:32:03,370
almost all of you are are not going to be in this room

1581
01:32:04,310 --> 01:32:09,090
how do i know how to do it very specific prediction behavior and not normally

1582
01:32:09,090 --> 01:32:14,750
used to thinking and behavior has been predictable but a lot of situations it one

1583
01:32:14,750 --> 01:32:19,870
of the concepts of psychology in HCI is to take advantage of the fact that

1584
01:32:19,870 --> 01:32:24,730
under certain conditions you can actually predict what people will do if you can predict

1585
01:32:24,730 --> 01:32:30,210
what people will do anything to predict whether a particular design work well

1586
01:32:31,320 --> 01:32:38,590
OK so basically is try to modify the subjective especially the situation to allow people

1587
01:32:38,590 --> 01:32:40,620
to get their work done better

1588
01:32:42,030 --> 01:32:43,420
the small picture

1589
01:32:43,430 --> 01:32:48,710
in nineteen eighty three card moran and newell and the famous book of there's which

1590
01:32:48,710 --> 01:32:53,980
were having a session on later in the conference to celebrate twenty fifth year that

1591
01:32:53,980 --> 01:33:00,050
particular set of ideas from psychology the last hundred years or so of and recast

1592
01:33:00,050 --> 01:33:01,390
it maybe that's good

1593
01:33:01,640 --> 01:33:03,900
distribution to explain my data

1594
01:33:03,920 --> 01:33:08,360
for example the first order markov chain so now what happens is the distribution might

1595
01:33:08,360 --> 01:33:12,320
fit the particular data you have more or less well

1596
01:33:12,330 --> 01:33:14,210
and basically

1597
01:33:14,280 --> 01:33:17,250
if you change the distribution to coat

1598
01:33:17,260 --> 01:33:19,830
then the better distribution fits the data

1599
01:33:19,860 --> 01:33:24,460
shorter the corresponding code length will be so every distribution gives you a prescription and

1600
01:33:24,460 --> 01:33:27,580
how to make a certain code and that code

1601
01:33:27,600 --> 01:33:30,880
i will give a short code length to does things

1602
01:33:30,910 --> 01:33:32,450
which have a high likelihood

1603
01:33:32,460 --> 01:33:34,700
on the distribution

1604
01:33:38,320 --> 01:33:40,350
note once again

1605
01:33:40,390 --> 01:33:44,560
i keep saying it there's no assumption here the data are sampled from any distribution

1606
01:33:44,560 --> 01:33:50,250
this is a purely formal correspondence between two different mathematical notions

1607
01:33:50,250 --> 01:33:55,810
namely probability distributions but here a probability distribution is simply a function on the space

1608
01:33:55,920 --> 01:33:57,030
which is

1609
01:33:57,370 --> 01:33:59,980
always nonnegative which sums to one

1610
01:34:00,040 --> 01:34:03,350
and code length functions

1611
01:34:03,420 --> 01:34:06,640
the second thing is you can also do this

1612
01:34:06,660 --> 01:34:11,130
if you have continuous outcomes spaces by discretizing the appropriate way

1613
01:34:12,140 --> 01:34:15,350
i will gloss over all the details there and from now on this talk and

1614
01:34:15,350 --> 01:34:20,580
that refer to a distribution are actually mass function i will sometimes also mean density

1615
01:34:20,580 --> 01:34:21,850
by that

1616
01:34:21,860 --> 01:34:26,370
and then note that in the last slide

1617
01:34:26,390 --> 01:34:28,110
i forgot about this

1618
01:34:28,110 --> 01:34:32,510
integer requirement so i didn't run up to the nearest integer

1619
01:34:32,530 --> 01:34:37,410
and this is something that is usually done that can be justified

1620
01:34:37,430 --> 01:34:41,540
because usually if n is not one but a little bit larger than the probability

1621
01:34:41,550 --> 01:34:47,020
suicide to sequences that tend to decrease exponentially and so the minus log of the

1622
01:34:47,020 --> 01:34:49,340
probability increases linearly

1623
01:34:49,350 --> 01:34:52,520
and then if you neglect this round of

1624
01:34:54,800 --> 01:34:58,980
then the area make is at most one bit which will typically be negligible compared

1625
01:34:58,980 --> 01:35:00,870
to the total length

1626
01:35:00,900 --> 01:35:04,450
and if you do that you get a much nicer mathematical theory and also you

1627
01:35:04,450 --> 01:35:08,210
get this theory which becomes independent of the alphabet in which encode things so you

1628
01:35:08,210 --> 01:35:10,210
would like a theory where

1629
01:35:11,940 --> 01:35:17,170
always easy mapping between coding things in binary according things are turning alphabet

1630
01:35:17,220 --> 01:35:19,320
and for this reason from now on

1631
01:35:19,330 --> 01:35:22,520
we will neglect the integer requirement

1632
01:35:22,530 --> 01:35:25,220
and we'll talk about idealised code

1633
01:35:25,250 --> 01:35:27,000
so these are coats

1634
01:35:27,020 --> 01:35:31,530
we start if we start from arbitrary distribution of call

1635
01:35:31,580 --> 01:35:35,250
this still code functions even if it is non integer lengths this is a common

1636
01:35:35,250 --> 01:35:40,530
thing in information theory actually if you read information theory papers you sometimes see that

1637
01:35:40,530 --> 01:35:44,610
people use the word cold and distribution simply interchangeably

1638
01:35:44,620 --> 01:35:45,630
and when they

1639
01:35:45,660 --> 01:35:48,000
talk about codes and they speak about

1640
01:35:49,180 --> 01:35:53,250
and they refer to distributions the mean the distribution

1641
01:35:53,250 --> 01:35:59,910
which is connected to the code by this quality

1642
01:35:59,980 --> 01:36:06,960
so this is about the correspondence between probability distributions and code length functions

1643
01:36:07,010 --> 01:36:09,120
and now i'm going to use it to define

1644
01:36:09,140 --> 01:36:10,620
universal models

1645
01:36:10,630 --> 01:36:14,620
and to define universal models we start with universal codes

1646
01:36:16,360 --> 01:36:18,220
for the time being forget

1647
01:36:18,250 --> 01:36:21,180
forget that this is the talk about machine learning rule only be

1648
01:36:21,200 --> 01:36:25,100
talking about data compression for a few slides now

1649
01:36:25,110 --> 01:36:31,890
and we'll talk basically about the method underlying most modern lossless data compressors which is

1650
01:36:31,890 --> 01:36:33,470
called universal coding

1651
01:36:33,480 --> 01:36:36,700
and the idea is as follows

1652
01:36:36,720 --> 01:36:38,360
so i suppose

1653
01:36:38,360 --> 01:36:40,670
you one encodes some data

1654
01:36:40,680 --> 01:36:44,480
and you have a set of different codes available for doing that

1655
01:36:44,500 --> 01:36:47,770
and you want to compress the data as much as possible that your goal

1656
01:36:47,830 --> 01:36:51,400
you think that some of the code in the set career l the set of

1657
01:36:51,400 --> 01:36:56,050
candidate codes will actually do a good job they will compress the data a lot

1658
01:36:56,060 --> 01:36:59,930
so now the the goal is to encode the data using the minimum possible number

1659
01:36:59,930 --> 01:37:01,100
of bits

1660
01:37:01,110 --> 01:37:03,910
based on the set of candidate codes

1661
01:37:04,930 --> 01:37:07,310
so i should be doing it will be obvious

1662
01:37:08,470 --> 01:37:10,940
is to simply called the data

1663
01:37:11,860 --> 01:37:13,520
the code instead of

1664
01:37:14,570 --> 01:37:17,610
which minimizes the code length of that particular data

1665
01:37:17,620 --> 01:37:21,830
so no that's because i'm not interested in how the actual encoding is done identified

1666
01:37:21,830 --> 01:37:24,620
the CO is their length functions so

1667
01:37:24,650 --> 01:37:27,090
this is the discrete l is

1668
01:37:27,090 --> 01:37:30,390
i call it a set of course but we is it's set of linear functions

1669
01:37:30,390 --> 01:37:34,440
corresponding to these codes which each outcome give you the number of bits needed to

1670
01:37:34,440 --> 01:37:36,230
encode the outcome

1671
01:37:36,260 --> 01:37:40,770
so the of is idea to pick the code which minimizes the length doesn't work

1672
01:37:40,770 --> 01:37:43,160
why doesn't it work well to see that

1673
01:37:43,180 --> 01:37:47,270
if realize that coding and decoding can always be viewed as a game between the

1674
01:37:47,270 --> 01:37:52,500
encoder and the decoder what encoder and the decoder me before seeing any data to

1675
01:37:52,500 --> 01:37:56,580
be encoded and they agree on the protocol a drug agree on their called

1676
01:37:56,590 --> 01:38:00,860
so after they've agreed on that they split again and the encoder sees the data

1677
01:38:00,860 --> 01:38:05,970
he coated any sense the encoded string to the decoder decoder has to decode it

1678
01:38:08,880 --> 01:38:10,900
if you think of it that way

1679
01:38:10,920 --> 01:38:14,750
then if the encoder will simply pick the code which minimizes the code length of

1680
01:38:14,750 --> 01:38:16,110
the given data

1681
01:38:16,110 --> 01:38:18,420
it's clear that the decoder wouldn't be able

1682
01:38:18,470 --> 01:38:22,600
to decode the data because the decoder gets encoded strings

1683
01:38:22,610 --> 01:38:26,090
but the decoder doesn't know what could be in color used

1684
01:38:26,110 --> 01:38:29,660
so if he doesn't know what could be in carter used in the decoder also

1685
01:38:29,670 --> 01:38:32,810
said curly ali might have agreed on that before seeing the data

1686
01:38:33,080 --> 01:38:36,610
but he doesn't know the element of l it's best for the data because

1687
01:38:36,620 --> 01:38:39,610
the decoder doesn't know the data that's why you need to decode it

1688
01:38:39,620 --> 01:38:41,500
so therefore the decoder

1689
01:38:41,520 --> 01:38:42,480
can not

1690
01:38:42,510 --> 01:38:44,890
decode the message if the encoder

1691
01:38:44,920 --> 01:38:46,640
encoded like this

1692
01:38:46,660 --> 01:38:50,820
so now the question is well apparently we can do as well as this but

1693
01:38:50,820 --> 01:38:53,120
can be used nearly as well

1694
01:38:53,130 --> 01:38:55,100
and the answer is yes

1695
01:38:55,110 --> 01:38:59,140
so there exist codes such that no matter what data you get

1696
01:38:59,200 --> 01:39:02,320
you always encode sequence

1697
01:39:02,330 --> 01:39:07,520
nearly as well as the best particular call for that particular sequence

1698
01:39:07,530 --> 01:39:13,410
and could intuitively give a formal definition later what intuitively coach with this property

1699
01:39:13,440 --> 01:39:15,530
are called universal codes

1700
01:39:15,540 --> 01:39:20,780
so universal it's a bit strange because universal means universal relative to the universe curly

1701
01:39:21,780 --> 01:39:26,460
so clearly is your universe you set of codes to which you compare yourself you

1702
01:39:26,460 --> 01:39:29,060
want avenue called which is as

1703
01:39:29,070 --> 01:39:30,840
no matter what they do you get

1704
01:39:30,860 --> 01:39:32,380
as good as

1705
01:39:32,400 --> 01:39:34,690
are almost as good as the best coach

1706
01:39:34,710 --> 01:39:38,950
in truly l

1707
01:39:38,970 --> 01:39:44,880
so here's a simple code suppose a simple example suppose curly l is finite

1708
01:39:44,890 --> 01:39:48,670
and then you always have some code

1709
01:39:48,680 --> 01:39:51,300
such that no matter what data you get

1710
01:39:51,330 --> 01:39:53,830
the number of bits needed to encode the data

1711
01:39:53,880 --> 01:39:58,060
it's more equal than the number of bits needed any codes in the sets

1712
01:39:58,070 --> 01:39:59,590
plus comes

1713
01:40:00,350 --> 01:40:02,210
if n is large

1714
01:40:02,330 --> 01:40:07,410
this constant will be negligible compared to this because this is we set typically increases

1715
01:40:08,850 --> 01:40:11,540
so then you actually doing a good job

1716
01:40:11,540 --> 01:40:16,920
these objects these examples and then the labels are these wise plus minus one and

1717
01:40:16,940 --> 01:40:22,250
the end of those examples OK for instance samples are points in rd

1718
01:40:22,270 --> 01:40:28,030
and there is some unknown function of x which would like to estimate

1719
01:40:28,050 --> 01:40:31,570
and that's that generating the labels given given x

1720
01:40:31,590 --> 01:40:38,210
OK there is some unknown distribution holidays examples look like and the objective is essentially

1721
01:40:38,210 --> 01:40:41,530
to predict y given x

1722
01:40:41,630 --> 01:40:45,400
the problem of course is that the probability distribution is unknown so p of x

1723
01:40:45,400 --> 01:40:46,760
and y is not

1724
01:40:46,800 --> 01:40:52,010
so this is of course in the ideal case this is really a deterministic function

1725
01:40:52,010 --> 01:40:53,260
so it might be just

1726
01:40:53,280 --> 01:40:59,190
OK so

1727
01:40:59,770 --> 01:41:03,260
so this is the model we have a hypothesis class

1728
01:41:03,310 --> 01:41:06,200
so we have a set of functions h

1729
01:41:06,240 --> 01:41:10,590
and other this function class we have to pick functions

1730
01:41:10,610 --> 01:41:11,850
that somehow would

1731
01:41:12,010 --> 01:41:17,630
and we also have the loss function that measures how good our laws our function

1732
01:41:17,630 --> 01:41:21,650
h mediation is point

1733
01:41:21,660 --> 01:41:27,740
OK so here we have this loss function l that measures how good one that

1734
01:41:27,750 --> 01:41:33,400
we we are all public this difference between y and h x are prediction that

1735
01:41:33,400 --> 01:41:37,000
could be for instance just zero one loss so if y is not equal h

1736
01:41:37,160 --> 01:41:42,700
and you're lost otherwise not so the goal is that we would like to try

1737
01:41:42,700 --> 01:41:48,080
to find the function of this country class h that has a small expected loss

1738
01:41:48,760 --> 01:41:53,200
if any i mean given data from from the distribution you would like to find

1739
01:41:53,200 --> 01:42:00,250
the function that minimizes the expected loss of everything take expectation of x and y

1740
01:42:01,140 --> 01:42:04,500
so the problem of course is that we only have a data sample and p

1741
01:42:04,500 --> 01:42:08,870
of x and y is unknown therefore what you can do with this we can

1742
01:42:08,870 --> 01:42:13,060
try to find empirical minimiser of the loss function here

1743
01:42:13,080 --> 01:42:16,560
so we have indeed points of the approximate this

1744
01:42:16,600 --> 01:42:18,730
expectation with empirical

1745
01:42:18,750 --> 01:42:20,110
version of the

1746
01:42:20,130 --> 01:42:26,360
so the question is how can we efficiently construct complex hypotheses with small generalisation error

1747
01:42:26,500 --> 01:42:27,610
so over the small

1748
01:42:27,850 --> 01:42:32,020
expected loss

1749
01:42:32,030 --> 01:42:33,090
OK so

1750
01:42:33,130 --> 01:42:34,940
let's go back to our example

1751
01:42:35,000 --> 01:42:39,750
we have all training set what might look like this for the first examples of

1752
01:42:39,750 --> 01:42:42,370
one class since examples of the other class

1753
01:42:43,380 --> 01:42:48,820
of course we need to have some properties of these applets and OK i guess

1754
01:42:49,140 --> 01:42:53,850
trivial OK so let's say you have both these these apples you have two properties

1755
01:42:53,850 --> 01:42:56,870
of each of these samples so how rare they are and how happy they are

1756
01:42:56,870 --> 01:43:00,710
for instance or how like they are actually and then you can just place it

1757
01:43:00,710 --> 01:43:04,380
is built in this coordinate system and then you could come up for instance with

1758
01:43:04,390 --> 01:43:10,550
a very simple process of classifying the samples to this this axis linear cut

1759
01:43:10,560 --> 01:43:13,730
classifies most most

1760
01:43:13,800 --> 01:43:18,390
it has benefit is just a very simple hypothesis class so that the function class

1761
01:43:18,390 --> 01:43:24,890
would look like all axis parallel cuts which be function i mean every

1762
01:43:24,980 --> 01:43:29,230
every axis is cut would be one punch OK so they're not so many here

1763
01:43:29,240 --> 01:43:32,120
so yours may be here

1764
01:43:32,140 --> 01:43:35,110
OK so it's quite small hypothesis class

1765
01:43:35,120 --> 01:43:44,130
OK so this is of course has been formalized so this is the

1766
01:43:44,150 --> 01:43:51,750
so called PAC learning theory and that's that's the organisms more notation here so we

1767
01:43:51,760 --> 01:43:56,930
are given the sample here we have this set of examples x one y one

1768
01:43:57,090 --> 01:44:00,510
two x and y in any given this hypothesis class

1769
01:44:00,530 --> 01:44:06,300
initially we have given an accuracy parameter and confidence parameter efficiently we have an article

1770
01:44:06,300 --> 01:44:14,300
with that given the training sample generates a function from the hypothesis class OK so

1771
01:44:14,590 --> 01:44:19,240
it essentially this algorithm generates given the training sample

1772
01:44:19,360 --> 01:44:24,460
it generates a function out of that hypothesis class h so the output is this

1773
01:44:24,460 --> 01:44:28,520
function so and we would like to have that

1774
01:44:28,600 --> 01:44:32,390
with very high probability this function has a low our OK

1775
01:44:32,400 --> 01:44:34,630
so that is

1776
01:44:34,650 --> 01:44:39,080
this probably approximately correct

1777
01:44:40,190 --> 01:44:45,770
so the probability that the loss of our estimator tension

1778
01:44:45,840 --> 01:44:51,880
minus the loss of best function is greater than excellent should be smaller than that

1779
01:44:51,900 --> 01:44:53,800
OK so with high probability

1780
01:44:56,580 --> 01:45:02,480
with small probability of this difference should be large means that the high prodigy the

1781
01:45:02,480 --> 01:45:04,540
difference is small

1782
01:45:04,560 --> 01:45:08,460
OK and eight stars just the best function you can be estimated

1783
01:45:08,560 --> 01:45:12,890
and there should be some so this should hold but on the other hand you

1784
01:45:12,890 --> 01:45:16,350
would like to have this algorithm somehow efficient so

1785
01:45:16,370 --> 01:45:19,840
we would like to have a polynomial running time in the number of examples in

1786
01:45:19,840 --> 01:45:22,090
one of the one about

1787
01:45:26,160 --> 01:45:29,030
OK so

1788
01:45:29,050 --> 01:45:33,340
so i started this is the best function of course class

1789
01:45:34,070 --> 01:45:39,120
essentially given the process that we just pick one which is best HP that is

1790
01:45:39,430 --> 01:45:44,170
the best function which we can pick it also the bayes optimal classifier

1791
01:45:44,190 --> 01:45:48,890
OK so where the hypothesis class essentially unrestricted

1792
01:45:48,900 --> 01:45:53,220
so there are three levels of generality so i want to see restricted setting where

1793
01:45:53,350 --> 01:45:59,630
we assume that the bayes classifier is equal to the best classifier the forces set

1794
01:45:59,770 --> 01:46:05,860
so that we would like to have the loss of our estimator function goes in

1795
01:46:05,860 --> 01:46:09,250
probability to the loss of the best knowledge

1796
01:46:09,260 --> 01:46:15,250
in agnostic setting we don't assume anything about hp but we about the bayes optimal

1797
01:46:15,400 --> 01:46:19,030
function but we require that the

1798
01:46:19,050 --> 01:46:22,850
our estimate the loss of the estimated goes to the

1799
01:46:22,900 --> 01:46:27,790
loss of the best function in the most general setting the initial setting we assume

1800
01:46:27,790 --> 01:46:30,860
nothing about HP and we require that the loss

1801
01:46:30,880 --> 01:46:35,910
of our estimate function goes to the loss of the basis function k and this

1802
01:46:35,910 --> 01:46:40,320
is what we department is going to talk about in the research talk so he

1803
01:46:40,320 --> 01:46:44,330
chose i think that posting is universally consistent setting

1804
01:46:44,340 --> 01:46:46,440
essentially this property

1805
01:46:46,460 --> 01:46:48,330
but i present

1806
01:46:51,770 --> 01:46:55,940
OK so we we consider the simplest setting so we just talk about the universe

1807
01:46:56,310 --> 01:47:00,630
that i'm going to talk only about the restricted setting so is essentially the space

1808
01:47:00,640 --> 01:47:04,050
optimal function is in the past

1809
01:47:04,090 --> 01:47:08,660
so i would like to the final two terms that is the so-called strong PAC

1810
01:47:08,660 --> 01:47:10,630
learning and compact

1811
01:47:10,650 --> 01:47:12,890
OK so strong PAC learnable

1812
01:47:12,940 --> 01:47:19,360
they you can specify any delta and x that means we can be arbitrarily small

1813
01:47:19,900 --> 01:47:26,000
and the and you get these done excellent without and then generates maybe it's the

1814
01:47:26,000 --> 01:47:32,110
computing time maybe needs a lot of examples but can come up with a hypothesis

1815
01:47:32,190 --> 01:47:35,340
which is very close to bridge which has the loss which is very close to

1816
01:47:35,340 --> 01:47:36,790
the optimum lost

1817
01:47:36,880 --> 01:47:37,840
the best action

1818
01:47:37,860 --> 01:47:40,700
and that holds for any x on any any day

1819
01:47:41,450 --> 01:47:47,990
and in the week the meatpacking and so that we demand only that this equation

1820
01:47:47,990 --> 01:47:50,720
only holds for some choices of that

1821
01:47:50,740 --> 01:47:52,330
so not for every choice

1822
01:47:53,190 --> 01:47:54,430
so for example

1823
01:47:54,470 --> 01:48:00,910
in binary classification we could require that the classification error is more than half

1824
01:48:00,910 --> 01:48:05,590
it is simply a sum of left moving the right moving

1825
01:48:05,590 --> 01:48:07,310
waves which

1826
01:48:07,320 --> 01:48:11,320
separate you know in more than two dimensions waves can move in all sorts of

1827
01:48:11,320 --> 01:48:16,470
directions in one space and one time dimension waves go either left or right you

1828
01:48:16,470 --> 01:48:24,100
don't have much choice and actually the two shorter waves are therefore independent there's something

1829
01:48:24,100 --> 01:48:29,820
more which usually with the right if you had you know the electromagnetic field namely

1830
01:48:29,830 --> 01:48:33,950
something that grows linearly with tau here

1831
01:48:33,970 --> 01:48:40,840
but remember this is not really a wave in just flat ten dimensional spacetime this

1832
01:48:40,840 --> 01:48:45,110
is a wave on a string if this thing is closed or small in the

1833
01:48:45,110 --> 01:48:50,550
way it can have some overall momentum it may itself move in space time

1834
01:48:50,550 --> 01:48:54,760
and he knew the thing that appears in front of the linear theorem which shows

1835
01:48:55,090 --> 01:49:03,420
the value of this equation is simply the momentum of the average centre of mass

1836
01:49:03,420 --> 01:49:05,790
of these objects

1837
01:49:05,810 --> 01:49:10,490
so this is a very simple solution actually

1838
01:49:10,510 --> 01:49:16,200
it's convenient to think of the xingu those as some function of l minus sigma

1839
01:49:16,200 --> 01:49:21,810
this takes care of all the right moving waves and some other functional plastic that's

1840
01:49:22,100 --> 01:49:28,590
all the left moving waves where f and fifteen them you independent functions for closed

1841
01:49:29,460 --> 01:49:33,420
if you want to think about the open strings and we'll have to think about

1842
01:49:33,420 --> 01:49:38,670
them in a little while then on an open string that are is standing waves

1843
01:49:38,670 --> 01:49:43,650
because the wave goes to one and then reflects back to show you only have

1844
01:49:43,650 --> 01:49:48,310
standing waves and this translates to the fact that new is if you feel that

1845
01:49:48,320 --> 01:49:54,110
new up to assign plus or minus the sign depends on the precise choice of

1846
01:49:54,110 --> 01:50:01,350
boundary conditions at the two ends the two simplest boundary conditions are free and point

1847
01:50:01,350 --> 01:50:06,010
namely the point of this thing moves freely in space time that's called the only

1848
01:50:06,010 --> 01:50:11,720
one or fixed point like the violin string i showed you before and that's called

1849
01:50:11,720 --> 01:50:15,850
dirichlet and the different just baseline

1850
01:50:15,870 --> 01:50:22,830
OK so this is the solution in a sense of this very simple classical theory

1851
01:50:22,930 --> 01:50:26,890
now what do we want to do well we have either closed string or an

1852
01:50:26,890 --> 01:50:28,240
open string

1853
01:50:28,250 --> 01:50:32,400
and we want to think of them as seen from very very far away as

1854
01:50:32,400 --> 01:50:34,350
point particles right

1855
01:50:34,370 --> 01:50:38,640
so if you have some string very far away it will look to you like

1856
01:50:38,640 --> 01:50:44,900
a point particle and the various properties of point particles which we used to think

1857
01:50:44,900 --> 01:50:49,080
of as quantum numbers associated with particles mass

1858
01:50:49,080 --> 01:50:51,050
so in charge

1859
01:50:52,060 --> 01:50:53,720
a color and so

1860
01:50:53,810 --> 01:50:58,790
would have to be understood now as being due to the

1861
01:50:58,840 --> 01:51:02,930
the motion of this thing right since there is not the structure here this thing

1862
01:51:02,930 --> 01:51:09,300
is structural less all these characteristics have to arise from the way thing moves at

1863
01:51:09,300 --> 01:51:15,060
very short scales so for instance the mass can only be vibration energy this thing

1864
01:51:15,060 --> 01:51:19,760
when you see from far away it looks like energy of course mass you don't

1865
01:51:19,760 --> 01:51:23,430
know what it comes from but if you had huge loop and you could look

1866
01:51:23,430 --> 01:51:27,090
at this thing you would see the string vibrating around and that's why it has

1867
01:51:27,090 --> 01:51:33,200
a mass this being is simply angular momentum but it's some sort of intrinsic angular

1868
01:51:33,200 --> 01:51:35,420
momentum of the loop

1869
01:51:35,450 --> 01:51:42,060
the chargers talk next time has to be momentum in some he them directions

1870
01:51:42,100 --> 01:51:47,400
and so on and so forth

1871
01:51:47,490 --> 01:51:52,000
now let's be slightly more precise suppose we want to compute the mass of this

1872
01:51:52,000 --> 01:51:54,010
string what do we have to do

1873
01:51:54,060 --> 01:51:58,920
well let me go back to this solution i showed you where x and you

1874
01:51:58,950 --> 01:52:04,410
remember was a linear there plus f plus if you feel that actually have persisted

1875
01:52:04,410 --> 01:52:08,000
that had absorbed the linear term in there

1876
01:52:09,260 --> 01:52:14,520
remember that we had to be in the conformal gauge the conformal gauge was telling

1877
01:52:14,520 --> 01:52:19,610
us that the politics and the sigma x y are orthogonal and of equal length

1878
01:52:19,620 --> 01:52:25,260
you can rewrite them very easily as the conditions that the derivative of f has

1879
01:52:25,260 --> 01:52:32,020
a zero length that remember a lawyer lawrence in lancashire it can be zero it

1880
01:52:32,030 --> 01:52:36,960
has to be like like simply the derivative of fifty there has to be of

1881
01:52:36,960 --> 01:52:42,730
zero land and these are in a sense the only remnant of non-linear editing this

1882
01:52:42,730 --> 01:52:47,340
very simple system you know the system look at first non-linear of square roots and

1883
01:52:47,350 --> 01:52:50,850
so on but in the end of the day we so it simply freeway is

1884
01:52:50,850 --> 01:52:52,240
pretty simple

1885
01:52:52,290 --> 01:52:57,330
but there is still a little the amount of nonlinearity which sees in this

1886
01:52:57,340 --> 01:53:03,440
conformal gauge conditions now this conditions such simply constraints from the phase space namely they

1887
01:53:03,450 --> 01:53:09,380
tell you what is only allowed initial debate that classically for stream once you have

1888
01:53:09,380 --> 01:53:12,850
imposed them at some initial time they are forever

1889
01:53:12,860 --> 01:53:15,830
satisfied you don't have to work more

1890
01:53:15,840 --> 01:53:20,360
so it's a very benign small nonlinearity but it is still there and

1891
01:53:20,390 --> 01:53:22,920
it tells you what kind of strings are allowed

1892
01:53:23,080 --> 01:53:29,870
emotions are allowed and this can actually be solved very easily in a very particular

1893
01:53:29,890 --> 01:53:35,150
choice of gauge which is so-called light cone gauge now the light cone gauge is

1894
01:53:35,150 --> 01:53:42,570
simply a conformal gauge where we utilize one small remnant of freedom to make it

1895
01:53:42,570 --> 01:53:46,920
even simpler what is the element of freedom well remembered

1896
01:53:47,690 --> 01:53:51,440
x like all other or the coordinates x

1897
01:53:51,450 --> 01:53:52,800
there were some

1898
01:53:52,810 --> 01:53:57,430
the function of r minus sigma plus a function of tau plastic more

1899
01:53:57,490 --> 01:54:01,400
right now you can check and they want to this to you that if you

1900
01:54:01,510 --> 01:54:07,580
a parametrized felt blessed by some other out the blessing might feel that a function

1901
01:54:07,580 --> 01:54:14,840
only of doppler signal and likewise for the minor this is called the conformal parametrisation

1902
01:54:14,840 --> 01:54:21,210
then gauge conditions at realistic satisfied that's pretty obvious because is were only function a

1903
01:54:21,210 --> 01:54:22,910
member of domain sigma

1904
01:54:22,940 --> 01:54:26,440
therefore i can take one particular according

1905
01:54:26,460 --> 01:54:31,560
i decided to write it down as minus sigma delta sigma

1906
01:54:31,600 --> 01:54:36,930
linear and you know it some arbitrary functions i can just use this area is

1907
01:54:36,950 --> 01:54:41,710
enjoyed freedom and it is convenient to do this not for the coordinate x is

1908
01:54:41,710 --> 01:54:46,890
zero as you might be tempted but rather for according to which one course explores

1909
01:54:46,900 --> 01:54:50,000
which is x zero plastics one

1910
01:54:50,010 --> 01:54:51,640
therefore you define

1911
01:54:53,260 --> 01:54:56,420
it out to be simply express plus

1912
01:54:56,440 --> 01:54:58,130
in this light cone gauge

1913
01:54:58,140 --> 01:55:03,660
now why is this nice because x in the text the minkowski inner product becomes

1914
01:55:03,660 --> 01:55:10,300
minus six plastics minus plus x transverse square and therefore one x plus

1915
01:55:10,330 --> 01:55:13,880
is linear the derivative is constant

1916
01:55:13,900 --> 01:55:19,050
so this becomes a constant that can solve now easily this conformal gauge conditions for

1917
01:55:19,050 --> 01:55:20,340
x minus

1918
01:55:20,350 --> 01:55:26,810
and there is only something left in the end which are this transverse oscillation modes

1919
01:55:26,850 --> 01:55:32,280
so that's how you solve the problem and actually when you write down this equation

1920
01:55:33,080 --> 01:55:37,690
the zeromode remember these functions there is a for all four years series but when

1921
01:55:37,690 --> 01:55:43,710
you're right down to zero mode of this you discover the so-called mass extra conditions

1922
01:55:43,710 --> 01:55:48,600
OK and then you have to sort of replace the sum by an integral

1923
01:55:48,610 --> 01:55:51,370
OK let's think for a moment now

1924
01:55:51,400 --> 01:55:55,830
it's the sort of move on

1925
01:55:55,850 --> 01:56:01,140
you can actually consider joint probabilities between pairs of variables

1926
01:56:01,210 --> 01:56:04,610
so what is the probability that that i measure

1927
01:56:04,620 --> 01:56:07,670
one meter eighty and today's sun

1928
01:56:09,400 --> 01:56:12,390
if things are correlated variables

1929
01:56:12,440 --> 01:56:15,580
and not expand when it's hot

1930
01:56:15,590 --> 01:56:21,970
OK let's let's just go through the through the notation one one important one very

1931
01:56:21,970 --> 01:56:25,250
important prob property is that of

1932
01:56:25,790 --> 01:56:30,040
marginalisation so if i have the joint distribution between two events

1933
01:56:31,090 --> 01:56:34,540
in a certain way i can i can sort of recover the marginal one

1934
01:56:37,150 --> 01:56:39,380
so p of x by basically

1935
01:56:39,400 --> 01:56:42,610
plugging in here all the possible values and why could take

1936
01:56:42,630 --> 01:56:44,670
and just adding up

1937
01:56:44,690 --> 01:56:46,160
all right now we

1938
01:56:46,170 --> 01:56:48,260
going example of this

1939
01:56:48,330 --> 01:56:54,120
if these were continuous random variables that have to be replaced by an integral OK

1940
01:56:54,470 --> 01:56:58,380
so very very important rule that i'm sure you all know and we're gonna we're

1941
01:56:58,380 --> 01:57:01,520
going to derive it in a very very intuitive way in a couple of slides

1942
01:57:01,520 --> 01:57:04,010
is is bayes rule

1943
01:57:04,050 --> 01:57:08,280
now things that using bayes rule makes bayesian

1944
01:57:11,430 --> 01:57:14,850
it doesn't right i mean people have been using bayes rule for for very very

1945
01:57:14,850 --> 01:57:16,470
long to simple

1946
01:57:16,490 --> 01:57:19,830
the rules of probability is and it has nothing to do with being

1947
01:57:19,880 --> 01:57:24,060
bayesian OK we talk about being bayesian later on

1948
01:57:24,090 --> 01:57:25,740
so what this base would say

1949
01:57:25,760 --> 01:57:29,440
this rule says that the joint probability

1950
01:57:29,460 --> 01:57:31,040
of x and y

1951
01:57:31,910 --> 01:57:35,880
can be computed in two different ways that are very very similar i could first

1952
01:57:35,880 --> 01:57:39,960
observe some value of x OK and then i ask myself now that i've observed

1953
01:57:39,960 --> 01:57:44,160
x now that the it's sunny what is and what is the probability you know

1954
01:57:44,160 --> 01:57:47,260
that i want to it or whatever

1955
01:57:47,270 --> 01:57:50,920
and then have to multiply that by the probability that it was in the first place

1956
01:57:51,830 --> 01:57:55,560
and i can do this both ways around OK

1957
01:57:55,620 --> 01:57:58,650
now once of written this

1958
01:57:58,710 --> 01:58:00,030
i can actually

1959
01:58:00,040 --> 01:58:01,310
the rival

1960
01:58:01,340 --> 01:58:10,370
this OK from this from this equality here

1961
01:58:10,400 --> 01:58:11,970
i guess everybody's

1962
01:58:12,010 --> 01:58:21,010
perfectly consonant with this thing so far

1963
01:58:24,140 --> 01:58:25,110
so bayes rule

1964
01:58:25,130 --> 01:58:29,010
and being very important when you're doing probabilistic modeling

1965
01:58:29,050 --> 01:58:31,430
because often

1966
01:58:31,440 --> 01:58:35,230
in this equation here for example

1967
01:58:35,240 --> 01:58:37,520
you may want to know

1968
01:58:37,580 --> 01:58:40,870
what effects was your input and why was the output you may want to know

1969
01:58:42,080 --> 01:58:46,000
what the probability of the output is given your input right or very often

1970
01:58:46,010 --> 01:58:49,020
x is actually going to be parameters of your models and you want to get

1971
01:58:49,020 --> 01:58:58,140
you're going to want to build the predictive distribution

1972
01:58:58,140 --> 01:58:59,830
so quantities that people

1973
01:58:59,910 --> 01:59:01,720
very often compute

1974
01:59:01,760 --> 01:59:06,430
and very often you need to actually summarize

1975
01:59:06,490 --> 01:59:11,520
a probability distribution by some by some sort of a small set of numbers of

1976
01:59:11,520 --> 01:59:15,620
quantities that people can sort of understand and relate to write like if you switch

1977
01:59:15,620 --> 01:59:20,290
on the news they always simplify things actually they never go beyond the average really

1978
01:59:20,920 --> 01:59:21,850
i mean

1979
01:59:21,940 --> 01:59:24,030
maybe sometimes they give

1980
01:59:24,040 --> 01:59:25,180
sort of

1981
01:59:25,230 --> 01:59:27,910
confidence intervals that's very rare and then when they do

1982
01:59:27,920 --> 01:59:29,000
chances are

1983
01:59:29,010 --> 01:59:31,900
it's sort of wrong

1984
01:59:31,960 --> 01:59:36,110
so if you had if you had some crazy continuous distribution so if this were

1985
01:59:38,510 --> 01:59:40,340
and these were

1986
01:59:40,380 --> 01:59:42,280
the density

1987
01:59:42,300 --> 01:59:43,970
so x could sort of have

1988
01:59:43,980 --> 01:59:45,430
you know some

1989
01:59:45,490 --> 01:59:48,550
some sort of shape what we know is that the integral of this thing is

1990
01:59:48,630 --> 01:59:49,880
is equal to one

1991
01:59:50,910 --> 01:59:54,810
but if this was the height distribution of people or whatever

1992
01:59:54,940 --> 01:59:58,160
you may want to report something about it so

1993
01:59:58,210 --> 02:00:01,230
a fundamental quantity is the expectation

1994
02:00:01,250 --> 02:00:02,520
the mean OK

1995
02:00:02,530 --> 02:00:05,410
you can sort of see how it works right i take i take

1996
02:00:05,470 --> 02:00:07,040
every possible

1997
02:00:07,060 --> 02:00:10,080
the height of the person and then multiplied by

1998
02:00:10,090 --> 02:00:15,100
by how often it actually happens right and since this is already normalised

1999
02:00:15,640 --> 02:00:20,080
i'm actually doing some sort of convex combination of all possible values right

2000
02:00:20,090 --> 02:00:21,990
that's what i mean

2001
02:00:22,000 --> 02:00:24,850
now the variance gives you an idea

2002
02:00:24,890 --> 02:00:29,330
of the spread of the distribution OK is it very concentrated or is it very

2003
02:00:30,100 --> 02:00:31,140
all right

2004
02:00:31,160 --> 02:00:33,460
so how does how does the variance work

2005
02:00:33,510 --> 02:00:37,640
well what i do is i i go to the mean wherever i wherever it

2006
02:00:37,640 --> 02:00:42,630
it ended up being the mean of this distribution might actually be here for example

2007
02:00:42,650 --> 02:00:46,270
and then i sort of and then a sort of measures

2008
02:00:46,280 --> 02:00:50,940
for every possible access of switch to go through the through the space i compute

2009
02:00:50,940 --> 02:00:53,300
these little distance here square it

2010
02:00:53,350 --> 02:00:56,210
and then i sort of and sort of weighted by

2011
02:00:56,260 --> 02:00:58,600
by the corresponding height at this point

2012
02:00:58,610 --> 02:01:00,290
OK and this gives me

2013
02:01:00,300 --> 02:01:04,190
an idea of how concentrated distribution is

2014
02:01:04,210 --> 02:01:06,300
now if i have actually

2015
02:01:06,300 --> 02:01:08,880
if i have actually two random variables

2016
02:01:09,670 --> 02:01:12,420
one thing i could one thing i could sort of compute is how much do

2017
02:01:12,430 --> 02:01:15,130
the covariance list let's draw picture

2018
02:01:26,520 --> 02:01:29,880
so let me draw two two possible pictures this would be one

2019
02:01:29,890 --> 02:01:31,120
what this is x

2020
02:01:31,120 --> 02:01:32,320
and this is why

2021
02:01:32,330 --> 02:01:35,730
and then in the sort of axis goes out of the bore you have the

2022
02:01:37,830 --> 02:01:39,920
and another picture could go would be

2023
02:01:39,950 --> 02:01:41,270
sort of this one

2024
02:01:41,280 --> 02:01:45,230
again sort of the contour line of the distribution

2025
02:01:45,250 --> 02:01:47,440
now in which of these distributions

2026
02:01:47,460 --> 02:01:48,530
this thing

2027
02:01:48,570 --> 02:01:50,200
x and y could very

2028
02:01:51,540 --> 02:01:54,980
who votes for right

2029
02:01:55,090 --> 02:01:57,020
who votes for blue

2030
02:01:57,040 --> 02:02:01,220
then as

2031
02:02:01,290 --> 02:02:03,410
OK so so

2032
02:02:03,430 --> 02:02:07,520
o i i did actually skip over this if if the mean of x is

2033
02:02:07,520 --> 02:02:12,430
zero then then it's quite clear that that computing the variances disparities

2034
02:02:16,730 --> 02:02:20,450
maybe this afternoon we can actually prove this OK i can someone to prove that

2035
02:02:20,450 --> 02:02:21,240
if two

2036
02:02:21,250 --> 02:02:25,370
if two random variables are independent the first thing is that you can write there

2037
02:02:25,370 --> 02:02:27,240
you can write the joint distribution

2038
02:02:27,380 --> 02:02:30,500
as as the product of the two right so for example if i wanted to

2039
02:02:30,500 --> 02:02:34,940
know what the probability is that i am one eighty tall and today's sun

2040
02:02:35,000 --> 02:02:39,020
i would actually independently compute with the probability of being son is today and with

2041
02:02:39,020 --> 02:02:41,450
the probability of me being one it is today

2042
02:02:41,490 --> 02:02:44,140
and then we just multiply the two and all right

2043
02:02:44,320 --> 02:02:47,830
if there was a relationship between the two i couldn't do that

2044
02:02:47,850 --> 02:02:50,620
all right

2045
02:02:53,120 --> 02:02:57,350
so one thing i could do now

2046
02:02:57,380 --> 02:02:59,220
is i could go to that links manually

2047
02:02:59,310 --> 02:03:04,580
and i could be is now a joint probability distribution OK by counting right so

2048
02:03:04,580 --> 02:03:08,810
i no longer have two random variables x and y and

2049
02:03:08,860 --> 02:03:12,600
and i think them in such a way that i first go and pick an

2050
02:03:12,600 --> 02:03:17,230
x and then look at what the immediately following letter was right and they call

2051
02:03:17,230 --> 02:03:18,160
that y

2052
02:03:18,270 --> 02:03:22,950
and i can i can be build this matrix and i just count again right


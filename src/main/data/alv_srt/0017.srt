1
00:00:00,000 --> 00:00:02,120
company i can remember what it is

2
00:00:02,210 --> 00:00:07,230
it you know and and you know in two years after the first computer anymore

3
00:00:07,330 --> 00:00:08,700
be something else

4
00:00:08,720 --> 00:00:13,280
even faster scales just unbelievable things just

5
00:00:13,330 --> 00:00:14,960
you seem to scale

6
00:00:15,000 --> 00:00:19,460
we're learning how to better distribute management you know the kind of the innovation of

7
00:00:19,460 --> 00:00:24,240
the of the domain naming scheme again was that not only did distributed data but

8
00:00:24,240 --> 00:00:26,670
it distributed the management you cant

9
00:00:26,810 --> 00:00:30,550
and information systems you cannot escape maintenance

10
00:00:30,630 --> 00:00:34,420
so being able to distribute that kind of load is critical to have a lot

11
00:00:34,420 --> 00:00:38,600
of applications and is what makes things like knowledge acquisition on the on the web

12
00:00:40,910 --> 00:00:44,680
if you don't know the story of captures a strongly encourage if this maybe if

13
00:00:44,680 --> 00:00:47,980
this time at the end i can quickly go into a different for those of

14
00:00:47,980 --> 00:00:49,950
you have never heard the story of how

15
00:00:50,130 --> 00:00:55,060
spammers broke the the captures these all images on web pages that are supposed to

16
00:00:55,060 --> 00:00:56,220
test if your

17
00:00:56,320 --> 00:00:58,240
potter of person

18
00:00:58,250 --> 00:01:00,570
but a great example of how

19
00:01:00,660 --> 00:01:06,910
you know the human gray matter on the web make certain problems solvable

20
00:01:06,930 --> 00:01:12,460
and then you know other approaches imperfect approaches that use heuristics or statistics or things

21
00:01:12,460 --> 00:01:14,910
to just guess at an answer

22
00:01:14,960 --> 00:01:17,680
you know in in the absence of

23
00:01:17,700 --> 00:01:21,410
something perfect that will scale to the size of the web

24
00:01:21,430 --> 00:01:26,020
i heuristic search fine i mean that's what people use

25
00:01:26,160 --> 00:01:31,580
i again i never cease to be amazed at the extent to which

26
00:01:32,000 --> 00:01:35,130
this is happening on the web the sharing of knowledge

27
00:01:35,150 --> 00:01:38,250
we need

28
00:01:38,260 --> 00:01:40,300
we need somehow to

29
00:01:40,340 --> 00:01:45,510
you know to manage that you it's great that this is happening but you can't

30
00:01:45,510 --> 00:01:48,320
ignore the fact that

31
00:01:48,370 --> 00:01:51,000
most people are it's

32
00:01:51,490 --> 00:01:55,130
so these kinds of things seem to work is not enough you know we need

33
00:01:55,130 --> 00:01:59,870
notions of trust people are working on all this i think is very important

34
00:02:03,280 --> 00:02:07,480
what time is

35
00:02:07,530 --> 00:02:11,460
o i

36
00:02:11,510 --> 00:02:13,490
thank you

37
00:02:13,560 --> 00:02:17,340
this is a this is a completely personal view

38
00:02:17,370 --> 00:02:19,450
what i see the promising trends

39
00:02:19,500 --> 00:02:20,840
first of all

40
00:02:20,860 --> 00:02:25,660
almost back to where we were when i symbolic was machine on my desk

41
00:02:26,990 --> 00:02:29,160
not quite there yet

42
00:02:29,180 --> 00:02:30,150
but some of the

43
00:02:30,180 --> 00:02:32,550
software development environments today are

44
00:02:32,550 --> 00:02:34,470
almost there

45
00:02:34,520 --> 00:02:40,430
the kind of knowledge engineering i can do today is almost at the speed

46
00:02:40,500 --> 00:02:43,770
what i missed my was which

47
00:02:43,820 --> 00:02:49,010
there is right there control super hypermedia bought

48
00:02:49,060 --> 00:02:51,550
those great days

49
00:02:53,110 --> 00:03:00,410
i really like this idea of using wikis to do knowledge acquisition i think it

50
00:03:00,430 --> 00:03:01,740
knowledge acquisition

51
00:03:01,760 --> 00:03:06,220
i think it really fits in nicely with the way that non

52
00:03:06,220 --> 00:03:08,930
expert knowledge engineers

53
00:03:08,950 --> 00:03:15,140
express themselves i mean most people outside of this community express their knowledge in text

54
00:03:15,240 --> 00:03:20,640
they write things down and in the in the business world actually wikis are really

55
00:03:20,640 --> 00:03:26,970
catching on if not already caught on and established technology that people within organisations used

56
00:03:26,970 --> 00:03:28,060
to share

57
00:03:28,140 --> 00:03:29,930
the sort of knowledge of the group

58
00:03:30,030 --> 00:03:33,760
to make proposals and to criticize and so forth

59
00:03:33,830 --> 00:03:37,680
it's really very actively used within within businesses

60
00:03:37,740 --> 00:03:41,030
and integrating that into the

61
00:03:41,060 --> 00:03:45,410
in two and knowledge acquisition process i think it's a fantastic idea i saw

62
00:03:45,490 --> 00:03:47,660
tripoli i this year demo

63
00:03:47,680 --> 00:03:51,780
from the underworld guys markets and

64
00:03:53,120 --> 00:03:57,490
that was funded by the halo two project to do

65
00:03:57,530 --> 00:04:00,470
knowledge acquisition in the semantic media wiki

66
00:04:00,510 --> 00:04:03,580
so i hope you guys can expose that to the to the rest of the

67
00:04:03,580 --> 00:04:06,430
world i think that's really cool

68
00:04:06,550 --> 00:04:13,200
so i i i thought i really think the powerset ideas are great when i

69
00:04:13,200 --> 00:04:17,600
don't know if it's going to succeed but not going to predict the future anymore

70
00:04:17,600 --> 00:04:20,890
but i really think it's really think it's a nice idea and i hope it

71
00:04:20,890 --> 00:04:25,660
works in one of the great things i see there see happening all over the

72
00:04:25,660 --> 00:04:27,100
place actually

73
00:04:27,120 --> 00:04:28,700
very recently

74
00:04:28,720 --> 00:04:35,580
is that the knowledge represent representation in natural language processing communities which split sometime in

75
00:04:35,580 --> 00:04:39,330
the mid seventies to go focus on their own problems

76
00:04:39,390 --> 00:04:42,780
we are starting to come back together again like like never before in the time

77
00:04:42,780 --> 00:04:45,580
really seems right both community seem

78
00:04:45,640 --> 00:04:47,140
to be mature enough

79
00:04:47,160 --> 00:04:52,240
so that they can actually make use of the established work in the other fields

80
00:04:52,240 --> 00:04:54,700
and really that was not happening

81
00:04:54,700 --> 00:04:57,620
in a big way up until very recently

82
00:04:57,800 --> 00:05:00,660
i think that's incredibly promising

83
00:05:00,720 --> 00:05:02,490
i love the pedia

84
00:05:02,580 --> 00:05:07,680
and and limited experience for free freebase but it also looks like a really nice

85
00:05:09,160 --> 00:05:12,850
again pushing this collaborative open

86
00:05:12,870 --> 00:05:14,970
but with a little bit of control

87
00:05:14,970 --> 00:05:17,530
the idea of of

88
00:05:17,720 --> 00:05:19,910
developing knowledge bases

89
00:05:19,910 --> 00:05:21,180
and so

90
00:05:21,200 --> 00:05:24,720
you know that's how you scale and let's not forget these are are the first

91
00:05:24,720 --> 00:05:28,300
ones i mean one that's been around for while IMDB is

92
00:05:28,350 --> 00:05:29,530
really big

93
00:05:29,550 --> 00:05:32,330
collaboratively developed database

94
00:05:32,350 --> 00:05:35,140
of knowledge about

95
00:05:35,240 --> 00:05:36,490
the entertainment

96
00:05:36,530 --> 00:05:39,080
the main and you know site

97
00:05:39,660 --> 00:05:42,830
i started doing this twenty years ago course

98
00:05:42,890 --> 00:05:46,140
they are done it all already

99
00:05:46,160 --> 00:05:50,410
it's kind of a different idea site but there's analogies here

100
00:05:50,450 --> 00:05:54,620
so i would have rejected the dbp paper for example things like the the twenty

101
00:05:55,800 --> 00:05:58,140
but i think it's great i really think it's great to use it all the

102
00:05:58,140 --> 00:06:00,740
time hey shameless

103
00:06:00,740 --> 00:06:01,800
kind of

104
00:06:01,800 --> 00:06:04,740
not really promotion but

105
00:06:04,760 --> 00:06:08,220
you know these people IBM research built the scalable

106
00:06:08,720 --> 00:06:13,220
OWL DL reasoning which is really cool you should check it out it's it you

107
00:06:13,220 --> 00:06:18,080
know it's not complete all the time but it's incredibly fast for what it does

108
00:06:18,120 --> 00:06:20,780
and it makes certain reasoning problems

109
00:06:20,820 --> 00:06:23,370
possibly even if it's not perfect

110
00:06:23,430 --> 00:06:26,390
and hey a totally shameless

111
00:06:26,410 --> 00:06:28,280
the rules

112
00:06:28,320 --> 00:06:30,600
working group has released

113
00:06:33,600 --> 00:06:35,680
time a

114
00:06:37,120 --> 00:06:42,660
for the basic logic dialect rule language which was edited by harold believe here somewhere

115
00:06:42,660 --> 00:06:44,680
and michael kifer was not

116
00:06:44,850 --> 00:06:48,870
i encourage you really would like to get feedback here so i encourage you all

117
00:06:48,870 --> 00:06:50,120
to check it out

118
00:06:50,160 --> 00:06:54,080
and you asked to brown who here somewhere which was here

119
00:06:54,100 --> 00:06:59,680
i wrote a companion document for this describing how RDF can be used

120
00:06:59,760 --> 00:07:00,780
with this

121
00:07:00,800 --> 00:07:02,760
rules dialect so

122
00:07:02,760 --> 00:07:04,800
check it out rules are

123
00:07:04,800 --> 00:07:06,300
the rules are going to be

124
00:07:06,320 --> 00:07:11,620
the next thing on the web based on the semantic web i think

125
00:07:11,620 --> 00:07:17,100
plus you know as well but this is the story of the reason for beta

126
00:07:17,120 --> 00:07:19,660
the contribution of its response to to

127
00:07:19,660 --> 00:07:20,540
one know

128
00:07:20,560 --> 00:07:23,020
and then if you want to know what the

129
00:07:23,040 --> 00:07:24,080
the other

130
00:07:24,100 --> 00:07:28,430
no the output of the amplifier they said you just have to feel it seems

131
00:07:28,660 --> 00:07:32,540
which if you look at the formula it go to infinity of course it's not

132
00:07:32,540 --> 00:07:34,120
possible under and also

133
00:07:34,870 --> 00:07:38,500
just because you have limitations on the query

134
00:07:39,500 --> 00:07:44,850
have to do with the notion that if you look some sort of the

135
00:07:44,890 --> 00:07:46,370
once you know in in

136
00:07:46,500 --> 00:07:50,350
but if you know that you are not interested in looking at all the frequency

137
00:07:50,350 --> 00:07:53,870
of your signal so in certain frequency on

138
00:07:53,890 --> 00:07:55,980
and this is what we do is shaper

139
00:07:56,000 --> 00:07:58,140
so we just kept

140
00:07:58,160 --> 00:08:02,680
the frequency so that would have just the notable conclusion which is in this particular

141
00:08:02,680 --> 00:08:05,330
frequency of windows three

142
00:08:05,330 --> 00:08:08,080
so to do that you know if you don't

143
00:08:08,100 --> 00:08:10,680
lowpass filter on hypersphere

144
00:08:10,690 --> 00:08:14,960
so long as is just campus don't series so that

145
00:08:14,960 --> 00:08:17,230
plus is still the see all

146
00:08:17,250 --> 00:08:20,310
so just very very similar new

147
00:08:20,620 --> 00:08:22,510
so this is the goal

148
00:08:22,620 --> 00:08:23,620
deposit to

149
00:08:23,680 --> 00:08:26,930
and decorations just as it was shown on

150
00:08:26,930 --> 00:08:28,180
on the indie

151
00:08:29,310 --> 00:08:33,390
the capacity to hold and then you can put a number of them so they

152
00:08:33,520 --> 00:08:34,580
can have

153
00:08:34,600 --> 00:08:38,660
you if you doing so what is it

154
00:08:38,660 --> 00:08:43,560
to know is is that you can optimize quite alot you you know

155
00:08:43,580 --> 00:08:44,730
we that

156
00:08:46,460 --> 00:08:47,730
in the nineteen

157
00:08:47,730 --> 00:08:52,600
it is that there will be a lot of work in the past about making

158
00:08:52,600 --> 00:08:54,270
optimal text

159
00:08:54,290 --> 00:08:59,250
no today because of the ability that we have to make

160
00:08:59,270 --> 00:09:03,640
did not have to detect conversion quite early and quite fast

161
00:09:03,660 --> 00:09:08,830
all of these a lot of this filtering is done in fact in these stanford

162
00:09:16,410 --> 00:09:17,850
from anything but

163
00:09:17,870 --> 00:09:21,450
what is important is that this formula is shown what is the

164
00:09:21,930 --> 00:09:26,210
output of the function of the capacitance of the

165
00:09:26,210 --> 00:09:31,410
the band capacitance which is the sum of the detector capacitance the input capacitance of

166
00:09:32,710 --> 00:09:38,060
the preamplifier the time shipping so the township in this

167
00:09:38,100 --> 00:09:40,310
the time of maximum size that the users

168
00:09:40,310 --> 00:09:43,270
the response of the filter uses

169
00:09:43,480 --> 00:09:45,960
the want

170
00:09:45,960 --> 00:09:51,710
in the late on slows in these cells is peaking time

171
00:09:51,730 --> 00:09:54,580
don't thought

172
00:09:54,640 --> 00:09:58,500
at that point and what is now is that you will find an optimum so

173
00:09:58,500 --> 00:09:59,480
which is

174
00:09:59,500 --> 00:10:06,580
for small value of between them this is not mostly contributing

175
00:10:06,600 --> 00:10:10,950
four i of fifteen times but i don't know if this is mainly contributing and

176
00:10:10,950 --> 00:10:14,140
you've got to humans

177
00:10:14,160 --> 00:10:19,580
so that was for for for an application is to otherwise you know

178
00:10:19,600 --> 00:10:21,350
signal to noise

179
00:10:21,410 --> 00:10:27,680
what is important also to know is the most dominant demand is the capacitance to

180
00:10:27,680 --> 00:10:32,980
detect soviet bloc data shows what the film between the

181
00:10:33,020 --> 00:10:35,750
the technology in terms of knowing that you see

182
00:10:37,250 --> 00:10:42,350
the is the value of the capacitance and i have a sort the noise is

183
00:10:42,410 --> 00:10:45,160
whatever technology

184
00:10:45,520 --> 00:10:49,430
in case you want to make design is the most important causes that you have

185
00:10:49,430 --> 00:10:52,230
to make also optimisation

186
00:10:52,250 --> 00:10:54,910
to define the size size

187
00:10:54,980 --> 00:10:58,350
this is very much detail and they will

188
00:10:58,370 --> 00:10:59,980
shortly finished

189
00:11:00,000 --> 00:11:02,270
the new hall

190
00:11:02,310 --> 00:11:07,480
design would be made directly to design would be made

191
00:11:07,500 --> 00:11:10,350
when you so you are but in application where you know that you have to

192
00:11:11,520 --> 00:11:14,950
charge preamplifier with you know what is that

193
00:11:14,960 --> 00:11:18,830
the capacitance you know what does the word is again you won't accept

194
00:11:18,850 --> 00:11:22,680
so you will have to to use some kind blocks of

195
00:11:22,770 --> 00:11:29,290
using transistors in terms of amplification which is common basic common emitter or common credit

196
00:11:29,580 --> 00:11:32,690
i don't coincide that and then you make

197
00:11:32,710 --> 00:11:35,460
you have to make a first schematics to to

198
00:11:35,500 --> 00:11:37,750
to see what it is

199
00:11:38,750 --> 00:11:44,000
you can say i think the schematic of an open fire upon existing and just

200
00:11:44,000 --> 00:11:47,600
compute but in fact you can simplify to it so you can you make your

201
00:11:48,580 --> 00:11:50,950
and then you have to start

202
00:11:50,960 --> 00:11:52,600
thinking about

203
00:11:52,620 --> 00:11:56,210
what can one do i want to have mean because the challenge is important we

204
00:11:56,210 --> 00:11:59,520
have seen because of the short knows what

205
00:11:59,580 --> 00:12:04,810
again do i won't accept i on and then you will be fine

206
00:12:05,560 --> 00:12:07,870
this three main elements

207
00:12:07,890 --> 00:12:13,660
you can make your home which is not very difficult to replace the tallest told

208
00:12:13,660 --> 00:12:17,330
by the equivalence between so of week on

209
00:12:17,370 --> 00:12:19,120
which are just

210
00:12:19,640 --> 00:12:22,950
which are driven by

211
00:12:23,000 --> 00:12:24,480
by page

212
00:12:24,500 --> 00:12:27,060
and then we define

213
00:12:28,790 --> 00:12:34,710
convolutional neural audio amplifier on the which

214
00:12:34,730 --> 00:12:39,850
things you can then you have to make aliens complete schematics which is that

215
00:12:39,870 --> 00:12:41,640
in addition

216
00:12:41,660 --> 00:12:44,640
in addition to these

217
00:12:44,710 --> 00:12:48,910
this is the tallest of this one and this one which are just about over

218
00:12:49,000 --> 00:12:54,850
the amplifier itself you have to have some chance sources selection bias everything

219
00:12:54,910 --> 00:12:59,640
and then you want what you want to this systematic in

220
00:13:00,500 --> 00:13:02,140
in this by simulator

221
00:13:02,160 --> 00:13:05,620
and then you can you can then make a full and the simulation of the

222
00:13:05,620 --> 00:13:07,100
system so so

223
00:13:07,100 --> 00:13:10,500
money they took me out to dinner that's thank you very much you double by

224
00:13:10,500 --> 00:13:15,450
earning capacity but that that's not what i was trying to be

225
00:13:15,460 --> 00:13:19,540
training consultant manages now

226
00:13:21,870 --> 00:13:24,580
let me means that we share with you now

227
00:13:24,590 --> 00:13:29,190
one but i think is

228
00:13:29,210 --> 00:13:32,010
we should have been doing first of all

229
00:13:32,020 --> 00:13:34,980
let me say that

230
00:13:34,990 --> 00:13:38,380
i think the business education

231
00:13:38,440 --> 00:13:41,410
is an extreme things

232
00:13:41,480 --> 00:13:46,030
two good in fact to be wasted just on those who want to claim

233
00:13:46,110 --> 00:13:47,750
a business career

234
00:13:48,140 --> 00:13:51,900
i remember

235
00:13:51,920 --> 00:13:55,560
my son coming back from school aged sixty

236
00:13:55,580 --> 00:13:59,020
and they just being done as a foundation course in

237
00:13:59,040 --> 00:14:00,790
business studies

238
00:14:00,880 --> 00:14:03,490
and he said that

239
00:14:03,510 --> 00:14:07,490
last week we heard about opportunity cost

240
00:14:07,940 --> 00:14:08,660
he said

241
00:14:08,670 --> 00:14:13,200
that's how can anybody liver proper life without understanding opportunity cost

242
00:14:13,220 --> 00:14:18,330
and i said this a very good question i know an awful lot of people

243
00:14:18,480 --> 00:14:22,910
who through their lives away doing what they call a secure job the opportunity cost

244
00:14:22,910 --> 00:14:28,360
of which was never get around to doing what they want to do opportunity cost

245
00:14:28,370 --> 00:14:30,250
absolutely vital

246
00:14:30,270 --> 00:14:35,990
in life was thinking about anything to do with the future and he learned from

247
00:14:35,990 --> 00:14:38,060
business studies at the age of sixty

248
00:14:38,100 --> 00:14:39,110
very good

249
00:14:39,130 --> 00:14:43,790
i like to think that have more about politicians have been educated in business studies

250
00:14:43,880 --> 00:14:49,840
both here and in america and they might have understood about the concept of theory

251
00:14:49,850 --> 00:14:54,150
you might wonder why on earth was sensible

252
00:14:54,210 --> 00:14:58,750
to allow laymen brothers borrow thirty five times their assets

253
00:14:58,910 --> 00:15:03,500
when we normally consider it unwise to borrow more than four times around his salary

254
00:15:03,500 --> 00:15:05,570
to buy a house

255
00:15:05,590 --> 00:15:08,090
i don't think they understood the concept

256
00:15:08,110 --> 00:15:11,740
i don't think any of them could we balance sheet

257
00:15:11,750 --> 00:15:13,990
so when they talk about you know

258
00:15:14,000 --> 00:15:15,370
we tuning

259
00:15:15,370 --> 00:15:19,760
of re correcting the balance sheet i don't think most of our politicians have actually

260
00:15:20,040 --> 00:15:21,500
talking about

261
00:15:21,520 --> 00:15:26,540
i actually think the business education should be for everyone

262
00:15:27,760 --> 00:15:32,980
but business education is not the same as management development

263
00:15:33,140 --> 00:15:35,700
it's unnecessary

264
00:15:36,630 --> 00:15:39,200
management but it's not enough

265
00:15:39,210 --> 00:15:42,110
it's not even the important stuff

266
00:15:42,120 --> 00:15:43,500
in the web

267
00:15:43,510 --> 00:15:47,380
but we should give it to everybody that we we can find

268
00:15:47,390 --> 00:15:48,850
because it makes life

269
00:15:48,860 --> 00:15:54,830
much more exciting even such simple little things like the eighty twenty rule of thumb

270
00:15:54,870 --> 00:15:59,920
eighty percent of your success comes from twenty percent of your efforts the work is

271
00:15:59,920 --> 00:16:03,370
a wonderful way to stop people wasting a hell of a lot of the time

272
00:16:03,370 --> 00:16:04,830
if they're to genoa

273
00:16:05,700 --> 00:16:09,700
they don't teach those things in our schools only

274
00:16:09,710 --> 00:16:12,220
in our business schools

275
00:16:12,230 --> 00:16:14,450
i'd like to see therefore

276
00:16:14,460 --> 00:16:19,910
everybody taught business education earlier on in life i'm delighted

277
00:16:19,920 --> 00:16:22,840
the most popular study

278
00:16:22,860 --> 00:16:28,820
in our british universities and business studies at the undergraduate level

279
00:16:28,830 --> 00:16:32,480
and i have a horrible thing to confess to but i actually think

280
00:16:32,520 --> 00:16:33,830
an NBA

281
00:16:33,840 --> 00:16:35,450
is a compressed version

282
00:16:35,470 --> 00:16:39,010
three year undergraduate course in business studies

283
00:16:39,020 --> 00:16:44,860
compressed and delivered and told to people who are already graduates something else

284
00:16:44,870 --> 00:16:46,840
there's nothing wrong with that

285
00:16:46,850 --> 00:16:48,290
better late than never

286
00:16:49,190 --> 00:16:51,740
they needed my goodness me

287
00:16:51,740 --> 00:16:53,170
business education

288
00:16:53,200 --> 00:16:57,010
you know it doesn't come to about thirty five is very valuable

289
00:16:57,070 --> 00:16:59,760
but it just isn't about management

290
00:17:00,770 --> 00:17:04,270
it's about analysing business problems

291
00:17:09,240 --> 00:17:17,200
did the real thing that i believe in to be honest is executive education

292
00:17:17,230 --> 00:17:20,540
particularly if executive education

293
00:17:20,560 --> 00:17:24,360
it is in this sense of the part-time right

294
00:17:24,370 --> 00:17:25,790
that the course

295
00:17:25,810 --> 00:17:30,240
the institution of i'm proudest of in my life is the open business school in

296
00:17:30,240 --> 00:17:32,330
england which i helped to start

297
00:17:32,340 --> 00:17:35,960
well basically everything that is told

298
00:17:36,670 --> 00:17:38,410
not in the classroom of course

299
00:17:38,420 --> 00:17:39,910
and the open university but

300
00:17:39,960 --> 00:17:42,670
through the internet and television

301
00:17:42,740 --> 00:17:44,360
is actually practiced

302
00:17:44,370 --> 00:17:48,840
by them in their own organisations and the essays in the papers so the right

303
00:17:48,960 --> 00:17:53,890
based on putting the theory into practice as they say no hard

304
00:17:54,010 --> 00:17:55,770
because actually

305
00:17:55,790 --> 00:17:58,210
i think

306
00:17:58,250 --> 00:18:02,000
the education

307
00:18:02,020 --> 00:18:04,000
it's best to find

308
00:18:04,060 --> 00:18:06,260
for people of mature age

309
00:18:06,360 --> 00:18:08,110
this experience

310
00:18:08,150 --> 00:18:10,110
finally understood

311
00:18:10,120 --> 00:18:12,720
in tranquility

312
00:18:12,730 --> 00:18:14,970
because i have to tell you

313
00:18:15,010 --> 00:18:19,110
you can have experience but if you don't understand that experience means

314
00:18:19,120 --> 00:18:20,810
you can't repeated

315
00:18:20,830 --> 00:18:22,780
the best place to understand

316
00:18:22,910 --> 00:18:24,340
it is in tranquility

317
00:18:24,360 --> 00:18:26,790
in a place like a college or school

318
00:18:26,810 --> 00:18:29,360
with the aid of concept

319
00:18:29,370 --> 00:18:31,730
i like to say

320
00:18:31,740 --> 00:18:35,940
the only thing that i learned the sloan school at MIT

321
00:18:35,990 --> 00:18:38,600
was that i didn't need to go there

322
00:18:39,540 --> 00:18:42,540
because i already knew it

323
00:18:44,100 --> 00:18:47,500
the only trouble was that i had to go there to find out that i

324
00:18:47,500 --> 00:18:48,910
already knew

325
00:18:48,980 --> 00:18:52,810
to me it is a great compliment when somebody comes up to me

326
00:18:52,870 --> 00:18:56,570
having read one of my books listen into one of my told

327
00:18:56,660 --> 00:18:57,770
and said

328
00:18:57,790 --> 00:19:01,120
i knew all that you know i knew all that

329
00:19:01,140 --> 00:19:03,450
the thing was i didn't know i knew

330
00:19:03,480 --> 00:19:05,750
until you tell me how i knew

331
00:19:07,750 --> 00:19:10,380
the concepts can be very exciting

332
00:19:10,400 --> 00:19:12,430
but actually this

333
00:19:12,530 --> 00:19:16,640
the allied to experience it doesn't really work

334
00:19:16,700 --> 00:19:20,370
let me see if i can make this work

335
00:19:20,380 --> 00:19:22,350
i spend an awful lot of my time

336
00:19:22,350 --> 00:19:24,810
drawing that line

337
00:19:24,870 --> 00:19:27,890
of businesses and for people

338
00:19:27,920 --> 00:19:29,450
which is of course

339
00:19:29,540 --> 00:19:34,560
line of everything you see it gets the first because in order to get anything

340
00:19:34,560 --> 00:19:39,730
one way to interpret this presenting these things called informational links

341
00:19:39,740 --> 00:19:48,520
there's this we'll connections the world maybe laws of nature are things like that between

342
00:19:48,530 --> 00:19:51,120
to consequent

343
00:19:51,130 --> 00:19:55,300
causal connections or other but

344
00:19:55,470 --> 00:20:01,940
inference is not always need such really or

345
00:20:01,980 --> 00:20:04,410
certain connections

346
00:20:04,460 --> 00:20:07,300
ross thought that like

347
00:20:07,320 --> 00:20:09,670
they will be

348
00:20:09,710 --> 00:20:15,500
the situation is and i think the situation c is the the whole meaning containment

349
00:20:16,910 --> 00:20:22,530
it's a wonderful book called and you so larger brain he's at latrobe university

350
00:20:24,170 --> 00:20:27,010
a lot of relevant are developed in science

351
00:20:27,460 --> 00:20:31,100
and nationalistic thing to study

352
00:20:32,310 --> 00:20:36,960
but he said well let's just do it this way

353
00:20:38,080 --> 00:20:41,200
i mean come here means or

354
00:20:41,230 --> 00:20:43,850
so if you remember sequent calculus like

355
00:20:43,870 --> 00:20:47,340
the call on the right-hand side of the turnstile

356
00:20:47,360 --> 00:20:54,260
forensic com on the left-hand side a turnstile today as well

357
00:20:54,330 --> 00:20:56,230
when we get to greg restall

358
00:20:57,680 --> 00:21:02,100
from literature

359
00:21:02,120 --> 00:21:07,060
i used so the idea here is that so is we start off with a

360
00:21:07,060 --> 00:21:08,090
or b

361
00:21:09,150 --> 00:21:14,450
they were the two cases one which is true it is

362
00:21:14,820 --> 00:21:21,020
the end of the century one which should be is contained in let's do them

363
00:21:22,600 --> 00:21:26,970
and there's all sorts of restrictions on things on how you do this that needed

364
00:21:26,970 --> 00:21:31,670
to make that's come right we won't talk about this i give you a flavor

365
00:21:31,710 --> 00:21:37,520
this all these things two different strings per so we're going to them in parallel

366
00:21:37,520 --> 00:21:39,510
with one another

367
00:21:40,460 --> 00:21:44,860
OK so let's look at this is supposed we start a or and

368
00:21:45,510 --> 00:21:46,310
b or c

369
00:21:49,000 --> 00:21:50,860
from that we can infer

370
00:21:55,860 --> 00:22:01,580
OK just by

371
00:22:01,600 --> 00:22:03,410
and elimination

372
00:22:11,200 --> 00:22:15,020
it's what he calls or elimination

373
00:22:15,070 --> 00:22:20,760
that's his new for eliminations look it's here than that

374
00:22:21,950 --> 00:22:27,620
that is both of these in so it's in the same stream and its we

375
00:22:27,620 --> 00:22:29,490
can use

376
00:22:29,620 --> 00:22:34,420
previous caesarean and

377
00:22:41,830 --> 00:22:44,410
should not using them

378
00:22:44,430 --> 00:22:46,690
which line numbers and

379
00:22:46,710 --> 00:22:49,530
this is what

380
00:22:49,550 --> 00:22:53,010
now what do we do we do something we do in the sequent calculus we're

381
00:22:53,010 --> 00:22:57,870
trying to prove distribution and if that always seems a bit silly these you might

382
00:22:57,870 --> 00:22:58,850
say yourself

383
00:22:58,860 --> 00:23:03,610
here we just limit or that we probably could but

384
00:23:03,630 --> 00:23:10,960
here's the rule he is this is the same as the sequent calculus

385
00:23:11,010 --> 00:23:29,600
using or introduction twice

386
00:23:31,460 --> 00:23:33,490
we can

387
00:23:33,540 --> 00:23:36,590
and were working on parallel right we and

388
00:23:36,610 --> 00:23:41,060
this is a list and destroying that to that

389
00:23:41,080 --> 00:23:45,110
OK already do in secret can and with

390
00:23:45,130 --> 00:23:47,310
how to get rid of one of them

391
00:23:47,320 --> 00:23:48,050
well what

392
00:23:48,060 --> 00:23:50,830
you just get rid of that we call

393
00:23:52,510 --> 00:23:55,650
other the contraction

394
00:23:55,700 --> 00:24:06,260
but it is a contraction wrong

395
00:24:06,350 --> 00:24:09,160
he calls upon the national

396
00:24:09,160 --> 00:24:10,470
so many have

397
00:24:10,510 --> 00:24:15,290
in the first

398
00:24:15,380 --> 00:24:17,160
so this proof

399
00:24:17,200 --> 00:24:19,090
it is it's much nicer

400
00:24:19,190 --> 00:24:24,400
then you have seen proof the proof in

401
00:24:24,450 --> 00:24:32,200
the proof of this kind of

402
00:24:34,120 --> 00:24:38,170
of the distribution is horrible it's huge

403
00:24:38,170 --> 00:24:42,170
holger he really inside

404
00:24:43,390 --> 00:24:45,070
so you see

405
00:24:45,110 --> 00:24:47,460
john one

406
00:24:48,650 --> 00:24:52,210
these improvements

407
00:24:52,230 --> 00:24:55,930
reaches the also

408
00:24:55,990 --> 00:24:59,080
i would say well received

409
00:25:00,180 --> 00:25:03,030
and as you can see

410
00:25:03,090 --> 00:25:07,580
see idea you in the

411
00:25:09,670 --> 00:25:11,990
remember there is no

412
00:25:13,070 --> 00:25:17,060
one the things that

413
00:25:17,070 --> 00:25:19,620
but he's really

414
00:25:19,730 --> 00:25:21,640
they tend be

415
00:25:21,650 --> 00:25:25,330
a host to

416
00:25:31,470 --> 00:25:34,430
the two

417
00:25:36,490 --> 00:25:41,560
so c

418
00:25:47,490 --> 00:25:48,350
and this

419
00:25:48,550 --> 00:25:51,300
right approach to

420
00:25:51,310 --> 00:25:59,140
so we have something to say

421
00:25:59,150 --> 00:26:01,820
and he said

422
00:26:04,300 --> 00:26:05,840
we do

423
00:26:05,850 --> 00:26:08,440
choose a lot

424
00:26:08,470 --> 00:26:09,580
the project

425
00:26:09,580 --> 00:26:12,570
well as a whole

426
00:26:12,590 --> 00:26:15,310
we will be

427
00:26:15,320 --> 00:26:18,720
well said

428
00:26:18,740 --> 00:26:23,070
in recognition use

429
00:26:23,080 --> 00:26:25,140
right this

430
00:26:37,230 --> 00:26:42,860
so is this is i the see

431
00:26:45,190 --> 00:26:48,380
we also

432
00:26:48,460 --> 00:26:49,820
and so

433
00:26:50,890 --> 00:26:52,480
so since

434
00:26:52,650 --> 00:26:57,410
so you

435
00:27:01,520 --> 00:27:04,640
that is

436
00:27:04,780 --> 00:27:08,060
so so

437
00:27:10,300 --> 00:27:15,880
one this projection you'd

438
00:27:15,920 --> 00:27:19,850
this is a region in which it was to

439
00:27:19,850 --> 00:27:24,220
it goes without saying that the

440
00:27:26,880 --> 00:27:35,610
here is this

441
00:27:35,620 --> 00:27:37,130
right approach

442
00:27:37,150 --> 00:27:39,320
for was the

443
00:27:39,350 --> 00:27:41,810
so you know

444
00:27:45,890 --> 00:27:50,570
the rows in the ropsm

445
00:27:52,480 --> 00:27:55,630
the positive

446
00:27:59,480 --> 00:28:02,640
this is

447
00:28:05,160 --> 00:28:08,550
so this

448
00:28:13,210 --> 00:28:15,620
that's you know the

449
00:28:20,180 --> 00:28:21,920
during the two

450
00:28:28,710 --> 00:28:31,690
so that's really

451
00:28:32,630 --> 00:28:34,570
it seems that

452
00:28:34,790 --> 00:28:41,490
the surface of the ball

453
00:28:48,310 --> 00:28:52,040
then we

454
00:29:28,180 --> 00:29:31,140
so what there

455
00:29:32,080 --> 00:29:36,440
you will have to be

456
00:29:38,770 --> 00:29:40,730
until two

457
00:29:41,690 --> 00:29:43,130
is the

458
00:29:43,140 --> 00:29:49,180
four d

459
00:29:50,820 --> 00:29:53,650
on set

460
00:29:55,880 --> 00:29:57,930
we must have

461
00:29:57,960 --> 00:30:01,030
two keep

462
00:30:01,030 --> 00:30:05,830
the minimum is 5 I can't do it with less how how you see that

463
00:30:05,830 --> 00:30:08,810
I cannot cover those with 5

464
00:30:09,510 --> 00:30:11,200
because of

465
00:30:14,430 --> 00:30:18,630
that's right my line will have to my lines have to cover all 5 of

466
00:30:18,630 --> 00:30:22,330
those those circle but I don't even care about

467
00:30:22,760 --> 00:30:26,810
just a cover those 5 circle ones is going to take the 5 lines

468
00:30:28,770 --> 00:30:31,620
so that's why that's the weak duality

469
00:30:31,730 --> 00:30:35,420
that the number of matches is always glossary

470
00:30:37,130 --> 00:30:42,370
the number of lines with any time I've got a match I've got someone's that

471
00:30:42,370 --> 00:30:48,070
I need that many lines except those aligned can cover to NMF right there a

472
00:30:48,070 --> 00:30:51,630
lot no line could cover 2 of these at once

473
00:30:52,080 --> 00:31:00,240
aligned can only cover 1 marriage and maybe some extra stuff but it's 5 lines

474
00:31:00,240 --> 00:31:02,270
security 5 matches

475
00:31:02,290 --> 00:31:08,050
you see the weak duality then it easy argument but the equation the fact that

476
00:31:08,060 --> 00:31:15,840
the number of assigned made made a statement the current change this problem by changing

477
00:31:15,840 --> 00:31:19,550
some of these 2 zeros does that now

478
00:31:19,570 --> 00:31:27,750
is that now prevent 5 matches for role occasionally make that is 0 also

479
00:31:31,970 --> 00:31:33,650
the class

480
00:31:34,050 --> 00:31:42,570
right so what else do I wanted to know is that this 1

481
00:31:42,580 --> 00:31:44,530
the environment

482
00:31:44,530 --> 00:31:46,050
make that is 0

483
00:31:46,070 --> 00:31:53,810
it is half time right so tell

484
00:31:53,820 --> 00:32:01,050
what to make is 0 all of what is 0 there yet but everybody and

485
00:32:01,050 --> 00:32:07,230
you add up for 1 somewhere else well do 1 and then you'll tell me

486
00:32:07,230 --> 00:32:10,270
that there's not enough arise

487
00:32:10,650 --> 00:32:15,210
that is definitely not alright alright so

488
00:32:15,230 --> 00:32:18,180
you say that's not enough

489
00:32:19,600 --> 00:32:26,580
and get there I'm I'm removing them

490
00:32:26,640 --> 00:32:29,310
yeah this this right

491
00:32:29,340 --> 00:32:40,920
OK is that is a match possible there is still it's instant handling match the

492
00:32:41,010 --> 00:32:43,050
can't take another 1 away

493
00:32:46,550 --> 00:32:52,730
well which would I'll take 1 of these away like that when I didn't like

494
00:32:52,730 --> 00:33:00,250
that 1 4 are now again OK now we believe that only the 4 the

495
00:33:00,550 --> 00:33:03,340
we can only marry off for right

496
00:33:04,490 --> 00:33:06,250
but now how do we prove

497
00:33:07,210 --> 00:33:12,900
because you're gonna find for lines that cover everybody

498
00:33:12,920 --> 00:33:15,530
and that would say

499
00:33:15,530 --> 00:33:22,570
no water for lines way doesn't says question what no I won't buy it so

500
00:33:22,580 --> 00:33:27,570
if I find 4 lines and cover everybody then there can only be for matches

501
00:33:27,590 --> 00:33:31,290
because if there were 5 matches I could not cover all of us alright now

502
00:33:31,290 --> 00:33:46,320
you really what for very 1st 2 columns and rows OK and that left me

503
00:33:46,320 --> 00:33:51,770
a matrix of zeros submatrix of zeros which should should tell me that trouble where

504
00:33:51,770 --> 00:33:53,080
the trouble

505
00:33:53,270 --> 00:34:00,620
this this matrix of zeros tells me that girls girls and 1 2 and 4

506
00:34:03,110 --> 00:34:08,270
uh don't obviously tells me that boys 3 4 and 5 are no good

507
00:34:08,550 --> 00:34:11,870
are not acceptable and therefore

508
00:34:13,940 --> 00:34:16,170
so the only boys that acceptable

509
00:34:16,410 --> 00:34:20,630
far I have 3 girls and the only boys are acceptable and the remaining 1

510
00:34:20,630 --> 00:34:30,550
and 2 here which is was this 1 2 5 1 arose when

511
00:34:32,880 --> 00:34:39,480
I thought these heroes and the zeros and the zeros referred altogether refers to girls

512
00:34:39,480 --> 00:34:46,360
want to far from work for 1st 1 2 5 and they will not

513
00:34:47,690 --> 00:34:52,970
match boys 3 4 fiive only Match . 1 2 and here I have a

514
00:34:52,970 --> 00:34:55,430
set of 3 girls and only 2 boys

515
00:34:56,110 --> 00:34:58,150
1 2 and 5

516
00:34:58,270 --> 00:35:08,670
the only 2 boys released to avoid yes yes yes I could express this in

517
00:35:08,710 --> 00:35:16,020
graph language to that's right that's right yeah so it's it's yeah it's it's a

518
00:35:16,270 --> 00:35:22,230
bit that's what the problem sounds like a joke problem but it appears all over

519
00:35:22,230 --> 00:35:27,650
the place as a very quite a fundamental matching so that's right matching is the

520
00:35:28,130 --> 00:35:34,610
or assigning sometimes assignment problem is were used matching is not a perfect matching is

521
00:35:34,610 --> 00:35:37,800
complete yet so it's

522
00:35:39,110 --> 00:35:41,270
so let's matching problem

523
00:35:41,310 --> 00:35:46,460
so maybe I could go on and it connects to this type of bipartite 2

524
00:35:46,460 --> 00:35:52,000
parts graph ok so that it can I

525
00:35:52,020 --> 00:35:59,630
go to a 2nd problem but any question on this would

526
00:35:59,670 --> 00:36:01,650
but 3 groups

527
00:36:01,710 --> 00:36:06,560
yes yesterday that so a tripartite graph I don't know

528
00:36:08,380 --> 00:36:13,400
you know I mean it's so that you're thinking like a graph here this is

529
00:36:13,400 --> 00:36:19,310
how this subject grows and and the

530
00:36:19,360 --> 00:36:24,310
and some directions lead to a beautiful theory of they're all going lead to some

531
00:36:24,320 --> 00:36:29,100
duality if you give me a linear programs uh but uh

532
00:36:29,650 --> 00:36:37,550
so as I say I could have formulated this problem as a linear programming problem

533
00:36:37,610 --> 00:36:41,500
but and what's special about it is the corners would have turned out to be

534
00:36:41,520 --> 00:36:48,860
images so that I only really had to look at images and the microsatellite OK

535
00:36:49,150 --> 00:36:54,440
but I try to tell you about this max-flow problem

536
00:36:54,460 --> 00:36:59,650
take them take the example shown on network

537
00:36:59,650 --> 00:37:04,640
in the general english SMT because most assertions are

538
00:37:04,670 --> 00:37:08,330
applicable across dialects of english but

539
00:37:08,350 --> 00:37:11,540
strictly speaking that probably should be american english seventy

540
00:37:11,560 --> 00:37:18,760
it is possible to have two

541
00:37:21,470 --> 00:37:24,020
normally they would be

542
00:37:24,030 --> 00:37:26,160
in different microtheories

543
00:37:26,170 --> 00:37:28,920
we have common english misspellings mt

544
00:37:32,850 --> 00:37:36,710
things go in there

545
00:37:36,870 --> 00:37:42,220
OK so we have these language and we also have lexicon he's

546
00:37:42,260 --> 00:37:45,840
the lexicon and is used for

547
00:37:45,850 --> 00:37:50,240
establishing an infrastructure for defining the language so

548
00:37:50,290 --> 00:37:54,720
predicates that are specific to certain language will be defined

549
00:37:54,730 --> 00:37:56,340
in a lexicon entry

550
00:37:56,390 --> 00:37:58,600
like slovene has to all

551
00:37:58,650 --> 00:38:02,850
and english doesn't so to always be defined in the

552
00:38:02,910 --> 00:38:04,740
in the slavic

553
00:38:05,040 --> 00:38:06,990
any other slovene

554
00:38:08,080 --> 00:38:09,660
mexican mt

555
00:38:09,700 --> 00:38:14,540
and you don't use the lexicon MTV's for making

556
00:38:15,700 --> 00:38:18,870
the concept were mapping so that's something you have to know

557
00:38:19,030 --> 00:38:21,670
lexicographer OK

558
00:38:22,260 --> 00:38:26,910
so much for microtheories forward

559
00:38:26,920 --> 00:38:29,110
shall we

560
00:38:29,150 --> 00:38:34,970
look at the key be a little bit

561
00:38:37,290 --> 00:38:43,930
just see things

562
00:38:47,900 --> 00:38:50,470
so we have

563
00:38:51,410 --> 00:38:54,300
the english lexicon and t

564
00:38:54,310 --> 00:38:58,220
is a constant in the cave here

565
00:39:03,080 --> 00:39:07,650
it's constant like every other constant

566
00:39:11,280 --> 00:39:16,050
as i said it's the empty for defining predicate specific to english

567
00:39:16,930 --> 00:39:18,460
and they're all

568
00:39:18,470 --> 00:39:20,620
all these

569
00:39:21,120 --> 00:39:24,350
is organised in this hierarchy

570
00:39:28,120 --> 00:39:33,970
english lexicon and t what's two english-language nt that's maybe a better example

571
00:39:40,760 --> 00:39:47,260
american english to

572
00:39:55,010 --> 00:39:58,930
american english and he

573
00:39:58,970 --> 00:40:00,870
is underneath

574
00:40:00,890 --> 00:40:07,100
english MT in this hierarchy and as indicated with this general ante assertion

575
00:40:07,300 --> 00:40:11,950
american english antigen on t

576
00:40:11,960 --> 00:40:13,210
english seventy

577
00:40:13,300 --> 00:40:15,010
so this general and t

578
00:40:15,020 --> 00:40:17,290
predicate relates to microtheories

579
00:40:21,820 --> 00:40:24,660
let's look at the the comment for general and t

580
00:40:24,660 --> 00:40:28,640
so we can see it will how it's

581
00:40:29,700 --> 00:40:32,780
so channel and t

582
00:40:33,230 --> 00:40:43,910
comment is is reflexive and transitive

583
00:40:43,990 --> 00:40:46,700
if so have every MT

584
00:40:46,750 --> 00:40:49,700
general antees to itself intransitive

585
00:40:49,750 --> 00:40:52,540
binary predicate relates to microtheories

586
00:40:52,550 --> 00:40:54,190
it means that the

587
00:40:54,230 --> 00:40:59,830
the first arguement is a specialisation or extension of the second

588
00:41:00,760 --> 00:41:04,570
this means that everything that's true in the general and t

589
00:41:04,610 --> 00:41:06,190
is true and this

590
00:41:06,200 --> 00:41:07,900
spec mt

591
00:41:08,340 --> 00:41:14,080
and this is expressed from both in the second he sees general and t

592
00:41:15,770 --> 00:41:17,540
the most general

593
00:41:17,550 --> 00:41:22,050
microtheory inside his is based KB and every other microtheories

594
00:41:23,230 --> 00:41:25,990
all of these assertions and base KB which means that

595
00:41:26,450 --> 00:41:30,110
the number of assertions in this cave is very small

596
00:41:30,130 --> 00:41:34,760
because of those only the ones that everybody wants to see so if you have

597
00:41:34,760 --> 00:41:36,320
an assertion in general

598
00:41:36,370 --> 00:41:37,820
english and

599
00:41:37,910 --> 00:41:43,280
all of the spec entities general english and you will see that

600
00:41:43,320 --> 00:41:47,300
the solution

601
00:41:48,450 --> 00:41:54,460
so we want to say so american english MT

602
00:41:54,490 --> 00:41:55,750
and if you

603
00:42:01,710 --> 00:42:05,330
well we can just sort of

604
00:42:05,340 --> 00:42:09,270
go along so english MT

605
00:42:09,370 --> 00:42:12,240
it's more general than that

606
00:42:14,540 --> 00:42:15,160
if you

607
00:42:15,170 --> 00:42:16,950
if you click here

608
00:42:16,960 --> 00:42:20,930
on the left-hand panel and look for the things

609
00:42:22,210 --> 00:42:25,670
if i click on this this will give me everything

610
00:42:25,680 --> 00:42:28,270
every assertion in which

611
00:42:28,310 --> 00:42:32,280
he was and he is the second arguement of about relations

612
00:42:34,790 --> 00:42:38,040
so this will give me all of the spec anti-social

613
00:42:38,090 --> 00:42:39,040
two there

614
00:42:39,050 --> 00:42:40,590
quite a

615
00:42:42,010 --> 00:42:46,500
it's quite a large number and OK computer is lexical and he

616
00:42:46,520 --> 00:42:49,170
cyclists MT the

617
00:42:49,300 --> 00:42:53,650
see for the contents of cyclists and hikers for

618
00:42:55,810 --> 00:43:00,230
clicking on microtheory constants k

619
00:43:00,440 --> 00:43:03,000
the closed to bugs l above report

620
00:43:05,940 --> 00:43:07,680
let's the

621
00:43:07,740 --> 00:43:09,290
it's funny

622
00:43:16,910 --> 00:43:19,280
well you can see these are all technical

623
00:43:19,360 --> 00:43:21,160
so the technical

624
00:43:21,160 --> 00:43:24,300
things about i see

625
00:43:24,310 --> 00:43:28,660
the cyc system symbol

626
00:43:31,120 --> 00:43:34,500
this is an assertion in the site question TV cyc system

627
00:43:34,540 --> 00:43:41,260
symbol to what multiwordstring and everything mean but that's just illustrate that

628
00:43:41,270 --> 00:43:43,120
the lexical knowledge is

629
00:43:43,130 --> 00:43:44,830
organised in these

630
00:43:44,890 --> 00:43:46,290
and entities

631
00:43:46,310 --> 00:43:53,020
the graph

632
00:43:54,010 --> 00:43:56,000
general and reflexive

633
00:43:56,040 --> 00:43:58,610
and transitive predicate

634
00:43:58,650 --> 00:43:59,670
so we

635
00:44:03,330 --> 00:44:05,040
that's the question

636
00:44:09,990 --> 00:44:13,920
it's this

637
00:44:19,620 --> 00:44:22,120
that allows for cycles

638
00:44:22,250 --> 00:44:24,710
empty circles are

639
00:44:24,730 --> 00:44:26,940
to be avoided

640
00:44:28,680 --> 00:44:31,320
i think an empty cycle leads to

641
00:44:31,590 --> 00:44:35,730
so that the outside my

642
00:44:35,800 --> 00:44:38,620
it's pretty well

643
00:44:44,050 --> 00:44:47,590
so that was an o microtheories now i'm going to talk about the kinds of

644
00:44:47,590 --> 00:44:49,210
semantic predicates

645
00:44:52,980 --> 00:44:55,240
all dog and quote

646
00:44:55,260 --> 00:44:57,490
and concepts like

647
00:44:58,250 --> 00:44:59,880
castello dog

648
00:44:59,970 --> 00:45:02,530
there are two

649
00:45:02,540 --> 00:45:05,400
possible routes

650
00:45:05,660 --> 00:45:12,020
predicate like namestring relates string to a concept directly

651
00:45:16,500 --> 00:45:17,670
elizabeth coppock

652
00:45:17,670 --> 00:45:18,950
OK so now

653
00:45:18,960 --> 00:45:21,430
we are really going to move on to something else

654
00:45:25,960 --> 00:45:27,560
factor analysis PCA

655
00:45:27,600 --> 00:45:29,790
gaston in distributions are

656
00:45:29,810 --> 00:45:32,800
simple to understand their easy to use

657
00:45:35,780 --> 00:45:40,010
there have been there have been limited in what they can do right

658
00:45:40,850 --> 00:45:44,890
we can we can summarize all of them

659
00:45:44,900 --> 00:45:49,320
in thinking that what we're really assuming is that the data comes from a multivariate

660
00:45:49,320 --> 00:45:53,280
distribution that's basically the common thing two or three right

661
00:45:53,290 --> 00:45:54,480
and now

662
00:45:56,280 --> 00:46:01,490
data doesn't need to data there's need to come from from a multivariate gaussian distribution

663
00:46:01,490 --> 00:46:05,810
right so they could be organised in different clumps right so you may

664
00:46:05,820 --> 00:46:09,480
you may need more complicated models right

665
00:46:10,490 --> 00:46:14,960
in order to to to get there i'm going to try and interest you four

666
00:46:18,240 --> 00:46:19,320
i was fast

667
00:46:20,060 --> 00:46:22,180
look at this

668
00:46:24,350 --> 00:46:29,680
this is borrowed from your standing about who go very nice NIPS tutorial

669
00:46:29,730 --> 00:46:35,980
that's here

670
00:46:35,990 --> 00:46:37,200
thank you wonder how

671
00:46:37,200 --> 00:46:40,450
images of horses looked computer they probably look

672
00:46:40,460 --> 00:46:44,590
the same as this things here looked to new

673
00:46:44,630 --> 00:46:47,230
OK so here's a little exercise

674
00:46:47,260 --> 00:46:48,840
we we label

675
00:46:48,850 --> 00:46:50,460
three of these things

676
00:46:50,480 --> 00:46:53,590
and we call them too fast

677
00:46:53,620 --> 00:46:55,730
OK i know my question to you

678
00:46:58,010 --> 00:46:59,090
think about

679
00:46:59,100 --> 00:47:13,630
how many more two fires there are in this slide

680
00:47:17,040 --> 00:47:20,460
OK OK OK OK OK OK OK OK

681
00:47:25,610 --> 00:47:34,070
process three

682
00:47:34,130 --> 00:47:37,450
who says for

683
00:47:37,510 --> 00:47:39,850
who says five

684
00:47:41,630 --> 00:47:53,070
ss six

685
00:47:56,730 --> 00:48:05,640
who says seven

686
00:48:05,670 --> 00:48:09,760
forces eight

687
00:48:09,760 --> 00:48:12,160
OK so i

688
00:48:12,250 --> 00:48:13,800
does anyone similar night

689
00:48:13,820 --> 00:48:17,390
not really

690
00:48:17,420 --> 00:48:18,950
interesting distribution

691
00:48:19,920 --> 00:48:23,800
all right so let's come here

692
00:48:25,130 --> 00:48:30,450
so in this role here is only to find these a so we are searching

693
00:48:30,450 --> 00:48:35,010
for for the extra ones are right so it's not not for the circuit ones

694
00:48:35,010 --> 00:48:38,360
so is there any need to find this role here

695
00:48:38,380 --> 00:48:41,980
OK who says yes

696
00:48:42,040 --> 00:48:45,410
all right so where is it starting from the left

697
00:48:45,420 --> 00:48:47,730
this guy here

698
00:48:47,730 --> 00:48:50,690
OK and why heard someone said there wasn't too far

699
00:48:50,700 --> 00:48:51,570
that's fine

700
00:48:51,570 --> 00:48:55,050
i don't know if it's too far enough

701
00:48:55,170 --> 00:48:59,080
but can be you know it has a sort of flat thing in the in

702
00:48:59,080 --> 00:49:02,070
the bottom it has like a little

703
00:49:02,170 --> 00:49:04,190
stick and then some

704
00:49:04,200 --> 00:49:09,450
o thing on top and what about in this role of the two thousand israel

705
00:49:09,470 --> 00:49:13,820
OK with which the fourth is going to go anymore to first

706
00:49:13,880 --> 00:49:18,000
what about this road

707
00:49:18,880 --> 00:49:23,540
OK so it doesn't guy anymore to first

708
00:49:23,600 --> 00:49:26,050
what about this right here

709
00:49:27,290 --> 00:49:28,320
the guy here

710
00:49:28,320 --> 00:49:32,790
what about this one coming two phases in this role

711
00:49:32,790 --> 00:49:33,630
which ones

712
00:49:34,210 --> 00:49:37,260
OK so this one two three four

713
00:49:37,280 --> 00:49:39,630
so one two three four

714
00:49:39,640 --> 00:49:41,830
five and six

715
00:49:41,890 --> 00:49:43,890
maybe there six

716
00:49:43,910 --> 00:49:47,310
maybe not i don't know

717
00:49:47,320 --> 00:49:52,020
some of you guys said there were five when you want to change your vote

718
00:49:52,050 --> 00:49:55,160
OK so which one of them do you disagree with

719
00:49:55,210 --> 00:49:59,010
this one here is the metaphor for you OK

720
00:49:59,010 --> 00:50:00,070
fair enough

721
00:50:00,080 --> 00:50:02,630
OK so why why were you able to

722
00:50:02,640 --> 00:50:06,110
to actually have a strong opinion on the number of two fuzzy that are in

723
00:50:06,110 --> 00:50:08,390
this picture

724
00:50:08,570 --> 00:50:10,260
well the reason is

725
00:50:11,450 --> 00:50:13,200
you sort of see in the universe

726
00:50:13,250 --> 00:50:14,450
here OK

727
00:50:14,450 --> 00:50:17,300
and in different objects in this universe right

728
00:50:17,310 --> 00:50:20,370
and then you using how different things can be so you have

729
00:50:20,390 --> 00:50:22,760
an internal representation for

730
00:50:22,820 --> 00:50:26,140
metric or similarity they have immediately built right

731
00:50:26,320 --> 00:50:27,840
and they have decided

732
00:50:27,860 --> 00:50:30,620
to do some clustering in your mind

733
00:50:30,630 --> 00:50:31,970
and that's the reason why

734
00:50:32,000 --> 00:50:34,660
you've found that they were actually

735
00:50:35,570 --> 00:50:37,280
a number of additional

736
00:50:37,450 --> 00:50:39,490
two fires in the picture

737
00:50:39,620 --> 00:50:49,280
but you need you need the metric unit the metric i'm sure that at this

738
00:50:49,280 --> 00:50:52,610
point you already have made up your mind about

739
00:50:52,630 --> 00:50:54,580
i just i just sort of

740
00:50:54,690 --> 00:50:57,950
i just sort of assumed that you had done this clustering just give you name

741
00:50:57,950 --> 00:50:59,710
for for some of the things in it

742
00:51:06,300 --> 00:51:15,720
OK i'm really scared of going into psychology here or perception or anything else

743
00:51:17,050 --> 00:51:19,210
OK OK

744
00:51:20,760 --> 00:51:24,140
but but when you but you

745
00:51:24,150 --> 00:51:27,450
OK some sort of assuming that

746
00:51:27,460 --> 00:51:30,940
so so one can of course the clustering in a hierarchical manner right because sort

747
00:51:31,950 --> 00:51:35,240
i can sort of say OK make two groups or i could say make three

748
00:51:35,240 --> 00:51:40,360
groups make for groups and you would sort of divide things differently

749
00:51:44,950 --> 00:51:50,640
OK but let's not do because we are running a bit late i

750
00:51:50,760 --> 00:51:54,760
OK so that's that's clustering so now

751
00:51:56,310 --> 00:52:01,930
let's sort of

752
00:52:01,940 --> 00:52:06,160
formalise things a little bit so the idea is that

753
00:52:06,200 --> 00:52:10,700
you want to put an objects into into k groups that we're within each of

754
00:52:10,700 --> 00:52:14,090
the k groups objects are similar to one another right

755
00:52:15,630 --> 00:52:18,950
i think it's quote from david mackay's book you know things at the wrong runway

756
00:52:18,950 --> 00:52:23,870
and think that are agreement on runway actually in david mackay's book this is nice

757
00:52:23,900 --> 00:52:26,150
example of this sort of

758
00:52:28,070 --> 00:52:32,430
picture where he sort of says imagine two scientists talking to each other and they

759
00:52:32,430 --> 00:52:34,210
found some very interesting animals

760
00:52:34,260 --> 00:52:36,840
and one of the most explained to the other it is

761
00:52:36,860 --> 00:52:38,430
any sort of says

762
00:52:38,440 --> 00:52:41,070
you have to walk that way and you go past

763
00:52:41,090 --> 00:52:42,800
the big thing that has

764
00:52:42,820 --> 00:52:47,240
a brown stand and lots of little

765
00:52:47,250 --> 00:52:50,970
green objects that are of this certain shape and then you move on to new

766
00:52:50,970 --> 00:52:55,140
places of the one that has a much thinner brown stem and that one has

767
00:52:55,140 --> 00:53:00,070
also little red balls and it also houses green flat things would be different and

768
00:53:00,070 --> 00:53:03,880
so on and like that three or four times and enough to pass he describes

769
00:53:03,880 --> 00:53:06,210
the force of the concerns there

770
00:53:06,220 --> 00:53:08,300
and it would have been a lot easier to say

771
00:53:08,330 --> 00:53:10,240
it's after the fourth street

772
00:53:11,070 --> 00:53:16,180
but that means that you have to define the concept of tree

773
00:53:16,260 --> 00:53:18,800
OK so

774
00:53:18,820 --> 00:53:23,650
a better description of of of of the data right being able to name trees

775
00:53:23,650 --> 00:53:29,120
in in communications of course of k means is called vector quantization really

776
00:53:29,210 --> 00:53:34,120
and it so it's a way of compressing the data

777
00:53:34,130 --> 00:53:35,700
you can also

778
00:53:35,720 --> 00:53:39,690
you can also sort of do it to detect novelty something doesn't really fall in

779
00:53:39,690 --> 00:53:42,430
any of the classes you have you can sort of say oh here an anomaly

780
00:53:42,430 --> 00:53:43,890
or something like that

781
00:53:44,760 --> 00:53:50,220
and this one here is a little bit farfetched perhaps always has probably thinking about

782
00:53:50,260 --> 00:53:53,760
you know

783
00:53:53,760 --> 00:53:55,680
but that's actually a sort of

784
00:53:56,840 --> 00:54:01,060
but i think the same because how do you know we data raised before you put your basis functions

785
00:54:02,210 --> 00:54:07,510
so what's the solution to this well there's a lovely elegant solution which is u sprinkle

786
00:54:07,960 --> 00:54:09,760
and i mean sprinkled in the technical sense

787
00:54:10,180 --> 00:54:13,780
i use sprinkle your basis functions across the entire

788
00:54:14,210 --> 00:54:14,830
space and why

789
00:54:15,960 --> 00:54:20,080
and how many sprinkles put when you put down infinity of them okay

790
00:54:21,910 --> 00:54:23,660
if it was a cake that would be difficult

791
00:54:24,120 --> 00:54:24,970
but this is mass

792
00:54:25,370 --> 00:54:26,100
so it's possible

793
00:54:28,120 --> 00:54:29,230
this leads the kernel methods

794
00:54:31,280 --> 00:54:36,100
well this is loose outline what you do in order to do this what you can show you're doing

795
00:54:38,560 --> 00:54:45,120
if you decide to start putting a basis functions any and then you start placing the interval delta mu

796
00:54:45,880 --> 00:54:48,200
so basically this is across the real line

797
00:54:49,300 --> 00:54:51,970
in fact we can do this in a high dimensional space but for the moment

798
00:54:52,110 --> 00:54:56,260
the high dimensional space is one-dimensional so this just to be clear that's the schematic

799
00:54:56,260 --> 00:55:00,830
this is a one-dimensional input in practice this will be high dimensional input function you

800
00:55:01,140 --> 00:55:06,200
but i can't plot so easily on the slides i'm doing one dimensional plot but

801
00:55:06,200 --> 00:55:07,140
also for this process

802
00:55:07,580 --> 00:55:08,760
using one-dimensional

803
00:55:09,570 --> 00:55:13,610
if we have the location parameters in effect said the thought that some point hey

804
00:55:13,610 --> 00:55:17,760
and then add a little bit in each time so we basically uniformly spacing these

805
00:55:17,760 --> 00:55:22,140
basis functions out is also worked a few randomly distributed them as galcians you get

806
00:55:22,140 --> 00:55:22,910
the same result

807
00:55:25,480 --> 00:55:30,630
because the distances in feature space depend only on the inner product between two basis functions

808
00:55:31,170 --> 00:55:36,110
it turns out that you can decrease delta mu to increase the number of basis

809
00:55:36,110 --> 00:55:39,920
functions and then you can also take the limit where you put these basis functions

810
00:55:39,920 --> 00:55:40,610
to infinity

811
00:55:41,740 --> 00:55:45,020
and you end up with the kernel so the bit that i haven't sorry

812
00:55:47,930 --> 00:55:48,420
that you can

813
00:55:50,320 --> 00:55:51,640
you know the key trick

814
00:55:52,040 --> 00:55:52,510
he says

815
00:55:53,930 --> 00:55:54,600
the third

816
00:55:57,270 --> 00:55:57,960
is the

817
00:55:58,690 --> 00:56:00,130
those distances in

818
00:56:02,460 --> 00:56:08,530
the expected distance between two data points in the function space is always given by the inner product yeah

819
00:56:09,090 --> 00:56:10,620
these basis functions vectors

820
00:56:11,280 --> 00:56:16,300
and what's going on is this is the standard trick is the length of these guys is becoming infinity

821
00:56:18,070 --> 00:56:18,610
but because

822
00:56:20,140 --> 00:56:21,050
they're both infinity

823
00:56:22,130 --> 00:56:26,690
and you're only evaluating things in terms a product you're rewrite what was by

824
00:56:27,960 --> 00:56:28,480
if x

825
00:56:30,660 --> 00:56:31,420
transpose phi

826
00:56:31,980 --> 00:56:32,550
x jay

827
00:56:33,410 --> 00:56:34,330
you can rewrite it

828
00:56:34,820 --> 00:56:35,790
as a kernel function

829
00:56:36,220 --> 00:56:36,780
now that's

830
00:56:37,150 --> 00:56:41,050
one way of introducing the kernel trick that you may hear more about when john

831
00:56:41,050 --> 00:56:44,990
cunningham talks about guessing processes and you're also a little bit more about for me

832
00:56:46,180 --> 00:56:48,090
so that's what's going on with the kernel trick

833
00:56:48,740 --> 00:56:52,230
and that's a more a guassian process perspective on what the kernel trick is

834
00:56:55,830 --> 00:56:56,110
so now

835
00:56:56,490 --> 00:56:57,420
we've got kernels

836
00:56:57,930 --> 00:57:02,650
and what goes on in the kernel trick is actually this scandal has interpretation as

837
00:57:02,650 --> 00:57:06,800
being the covariance those functions we're computing the director variance

838
00:57:09,180 --> 00:57:10,830
and the reference missing there is that

839
00:57:11,390 --> 00:57:14,650
shall come from smaller but this is sometimes known as the kernel trick moving from

840
00:57:14,650 --> 00:57:17,290
this to this so i u x when i wrote it on the

841
00:57:17,760 --> 00:57:20,260
because i'm used inputs being experts had there actually why

842
00:57:21,380 --> 00:57:22,090
so this is the

843
00:57:22,730 --> 00:57:23,080
okay why

844
00:57:23,590 --> 00:57:28,440
hatch all the properties of a mercer kernel and is also positive definite actually has

845
00:57:28,450 --> 00:57:32,560
all the properties what we call the covariance function so can function is a function

846
00:57:32,560 --> 00:57:34,840
that can be used to generate a covariance matrix

847
00:57:35,870 --> 00:57:38,620
and in fact what's going on here is instead of

848
00:57:40,110 --> 00:57:44,370
this is against gaussianprocess point-of-view instead of talking about functions like this

849
00:57:46,140 --> 00:57:47,860
and then putting a prior over w

850
00:57:49,550 --> 00:57:50,620
what we're actually doing

851
00:57:52,650 --> 00:57:54,040
is putting a prior

852
00:57:54,580 --> 00:57:56,010
on this guy directly

853
00:57:58,820 --> 00:58:02,820
we don't need specifies a guassian process because we only need the covariance event

854
00:58:03,920 --> 00:58:07,910
which is why i think people in the capital community don't tend to like

855
00:58:08,610 --> 00:58:10,020
specify guassian process

856
00:58:10,450 --> 00:58:14,670
because they're not means you're saying something about the other moments which you don't in some sense need say

857
00:58:15,360 --> 00:58:16,810
just look can appreciate

858
00:58:17,320 --> 00:58:21,170
you can just talk about the second moment the second moment being a kernel

859
00:58:22,780 --> 00:58:27,340
there is some utility saying is calcium because you can do a lot more calculations only uncertainty

860
00:58:27,730 --> 00:58:32,820
but let's except that it doesn't need to be galcians for the rest of what i say to be true

861
00:58:34,610 --> 00:58:40,200
so the mapping from data distance is now a guassian process and if we sample from this calcium process

862
00:58:41,530 --> 00:58:44,600
what we see is now we've got these basis functions over infinite space it doesn't

863
00:58:44,600 --> 00:58:47,450
matter where you sample you will see movement you will see wiggle

864
00:58:48,100 --> 00:58:52,020
because we sprinkle these basis functions everywhere and now the distances between

865
00:58:52,550 --> 00:58:53,520
three and minus three

866
00:58:54,270 --> 00:58:58,460
well give something reasonable on average there will be far apart on average to close

867
00:58:58,460 --> 00:59:02,010
things will be close together and that's because the function mapping is a mapping from

868
00:59:03,120 --> 00:59:05,210
to this at space in a smooth way

869
00:59:07,300 --> 00:59:08,540
so there is some other samples

870
00:59:10,490 --> 00:59:12,990
okay so what she doesn't come out very clearly

871
00:59:13,410 --> 00:59:14,900
but then gives us now

872
00:59:15,480 --> 00:59:18,390
our distance matrix so we can use the kernel trick

873
00:59:19,780 --> 00:59:23,990
what i've in some sense introduced in around about hopefully where you haven't seen before

874
00:59:24,560 --> 00:59:26,190
is that the kernel trick

875
00:59:27,560 --> 00:59:28,650
on distances

876
00:59:33,950 --> 00:59:36,270
so this is the distance in the feature space

877
00:59:40,660 --> 00:59:41,420
this form here

878
00:59:41,740 --> 00:59:43,540
why i why i

879
00:59:44,310 --> 00:59:44,940
minus two

880
00:59:46,380 --> 00:59:47,470
why i

881
00:59:48,350 --> 00:59:49,120
comma why jay

882
00:59:51,620 --> 00:59:52,840
so i plus plus

883
00:59:54,630 --> 00:59:55,240
why jay

884
00:59:55,240 --> 00:59:57,480
i've been losing my voice over the last few days

885
01:00:00,060 --> 01:00:01,190
hopefully by the end of the

886
01:00:01,700 --> 01:00:03,480
two hours of still have some voice

887
01:00:04,730 --> 01:00:06,400
the magic microphones l

888
01:00:06,670 --> 01:00:10,420
help that okay i'm gonna be talking about bayesian modeling

889
01:00:12,260 --> 01:00:15,530
first of all i just want to mention i put the slides online just right

890
01:00:15,530 --> 01:00:20,080
now it's an analogy dot and you can see that you can start

891
01:00:22,190 --> 01:00:24,440
lacked one based on pedia

892
01:00:25,470 --> 01:00:29,780
so if you all downloaded now then nobody will be able to use the internet probably

893
01:00:30,630 --> 01:00:31,380
the rest of the day

894
01:00:34,200 --> 01:00:36,960
so i'm going be talking about bayesian modeling and i'm

895
01:00:37,570 --> 01:00:40,600
i know that you've had quite a lot of advanced materials so far

896
01:00:42,750 --> 01:00:44,390
you know especially following from

897
01:00:44,780 --> 01:00:47,960
you know yesterday talking about humans coalesce and things like that

898
01:00:48,320 --> 01:00:50,560
it's gonna seem very basic what i'm gonna say

899
01:00:51,210 --> 01:00:52,960
but i think it's still very important to

900
01:00:53,430 --> 01:00:54,930
start from the basics

901
01:00:55,490 --> 01:00:59,970
and try to really understand what's going on why do

902
01:01:01,660 --> 01:01:05,060
you know bayesian machine learning people do things the way they do

903
01:01:06,280 --> 01:01:08,860
with the philosophy behind it what is the formal

904
01:01:09,830 --> 01:01:11,880
the theoretical foundations behind it

905
01:01:13,190 --> 01:01:15,800
how does it relate to the rest of machine learning

906
01:01:16,990 --> 01:01:21,530
so in particular i'm talking about bayesian modeling and i wanna focus on these two words

907
01:01:23,640 --> 01:01:29,390
modeling and bayesian inference at the beginning and tried it just very clearly described you

908
01:01:29,390 --> 01:01:33,720
what i mean by these things and then i'll talk about more specific and more

909
01:01:33,720 --> 01:01:37,530
and more technical material as i go on through i think i have maybe six

910
01:01:37,530 --> 01:01:38,440
hours of lectures

911
01:01:42,880 --> 01:01:44,020
this usually happens

912
01:01:51,410 --> 01:01:52,470
just as motivation

913
01:01:52,990 --> 01:01:55,080
it's a really exciting time to be doing

914
01:01:55,690 --> 01:02:01,050
machine learning or modeling where in the middle of an information revolution there's huge amounts of data everywhere

915
01:02:01,720 --> 01:02:02,910
affecting society

916
01:02:03,780 --> 01:02:05,470
the way sciences are done

917
01:02:05,980 --> 01:02:07,250
the way business is done

918
01:02:09,250 --> 01:02:13,630
you know all this will hopefully have nice jobs because there's a lot of demand more

919
01:02:14,100 --> 01:02:15,680
what we are trying to do

920
01:02:16,750 --> 01:02:19,060
but of course with huge amounts of data

921
01:02:19,530 --> 01:02:25,060
we really need tools for dealing with data and it's not not gonna focus on these large and this

922
01:02:25,760 --> 01:02:26,540
quantity to

923
01:02:27,060 --> 01:02:28,840
other data i'm going to focus on

924
01:02:29,500 --> 01:02:31,220
be interesting things that we can do

925
01:02:31,660 --> 01:02:32,320
with the data

926
01:02:32,850 --> 01:02:37,220
so we need tools for modeling searching visualizing and understanding large datasets

927
01:02:39,130 --> 01:02:39,980
end up

928
01:02:40,620 --> 01:02:45,320
are modeling tools need to i feel be able to do certain things

929
01:02:48,100 --> 01:02:53,280
modelling tools should be able to capture some form of uncertainty about our model structure

930
01:02:53,820 --> 01:02:54,850
they should be able to capture

931
01:02:57,370 --> 01:02:57,650
in the

932
01:02:59,250 --> 01:03:03,660
in the data and the noise processes in the data data especially stuff that you

933
01:03:03,660 --> 01:03:08,320
get nowadays on the web is very clean experimental data it's incredibly messy

934
01:03:09,530 --> 01:03:12,150
we want tools that are automated that adapt

935
01:03:12,680 --> 01:03:15,060
there are robots that scale well et cetera

936
01:03:18,090 --> 01:03:23,130
the framework i'm going to be talking about is probabilistic modeling framework

937
01:03:23,780 --> 01:03:27,220
so let me focus on the word model what some model to me

938
01:03:28,780 --> 01:03:30,090
to me a model is

939
01:03:31,030 --> 01:03:33,600
the description of possible data

940
01:03:34,190 --> 01:03:35,730
one could observe from a system

941
01:03:37,840 --> 01:03:42,340
it's a funny way of describing a model but i've come to sort of like this way thinking about models

942
01:03:44,510 --> 01:03:45,280
so model

943
01:03:45,750 --> 01:03:48,320
is a way of describing possible data you could observe

944
01:03:49,260 --> 01:03:51,060
in any kind of domain you're trying to

945
01:03:53,600 --> 01:03:56,510
and if it's not there then i don't understand what a model could be

946
01:03:58,130 --> 01:03:59,820
if the model can predict

947
01:04:01,380 --> 01:04:02,660
then there's no way of

948
01:04:03,100 --> 01:04:06,680
o five buying model there's no way of telling whether mall it's good or bad

949
01:04:07,160 --> 01:04:08,160
because ultimately

950
01:04:08,560 --> 01:04:10,800
we have to evaluate models with respect to

951
01:04:11,440 --> 01:04:13,130
our real world data

952
01:04:14,190 --> 01:04:16,670
of-course models have served other purposes

953
01:04:17,140 --> 01:04:18,630
models might also be

954
01:04:19,250 --> 01:04:23,340
much more interpretable are understandable that the raw data

955
01:04:23,870 --> 01:04:29,810
and those are kind of side benefits of models but ultimately their descriptions are possible data one could observe

956
01:04:30,750 --> 01:04:38,210
now the framework we're going to take it sees the mathematics of probability theory to express all forms of uncertainty

957
01:04:38,770 --> 01:04:40,640
i don't know is that we have in our model

958
01:04:42,770 --> 01:04:47,750
if we do that's the nice thing is then we can use the same rules probability theory

959
01:04:50,260 --> 01:04:55,890
what used to be called you know over a hundred years ago inverse probability or bayes rule

960
01:04:56,480 --> 01:04:59,260
but it's basically application of the rules the probability theory

961
01:04:59,680 --> 01:05:04,870
to allow us to infer unknown quantities adapt our models learn parameters

962
01:05:05,330 --> 01:05:07,460
learn from data etcetera make predictions

963
01:05:10,950 --> 01:05:13,260
now what i want to draw an analogy for u

964
01:05:15,480 --> 01:05:16,790
you know a few hundred years ago

965
01:05:18,290 --> 01:05:20,200
dunedin lightness and people like that

966
01:05:20,860 --> 01:05:22,170
developed calculus

967
01:05:22,690 --> 01:05:27,590
calculus was a mathematical language fore talking about rates of change

968
01:05:29,310 --> 01:05:32,750
probability theory is a mathematical language for talking about uncertainty

969
01:05:33,260 --> 01:05:34,560
okay so it's basically

970
01:05:36,190 --> 01:05:36,860
all right

971
01:05:37,000 --> 01:05:38,870
way of expressing uncertainty

972
01:05:41,130 --> 01:05:45,580
okay so this is the probabilistic modeling framework that i'm gonna take and you know

973
01:05:45,580 --> 01:05:47,820
you've seen this stuff death but basically

974
01:05:51,110 --> 01:05:53,790
you know that's probably not base as

975
01:05:54,810 --> 01:05:55,870
you said that

976
01:05:56,300 --> 01:05:57,140
i think in this talk

977
01:05:58,370 --> 01:06:00,810
there are some arguments is the only image obeys that

978
01:06:01,930 --> 01:06:03,940
anybody claims could be a bayes but

979
01:06:04,380 --> 01:06:05,760
there is some dispute about it

980
01:06:09,820 --> 01:06:13,990
famous bayes rule is just a basic rule of probability theory

981
01:06:15,020 --> 01:06:15,820
but when u

982
01:06:15,820 --> 01:06:19,820
but nonconvex there's uh more to worry about

983
01:06:24,490 --> 01:06:24,810
if at

984
01:06:25,390 --> 01:06:27,690
hash matrix is not positive semi definite

985
01:06:30,610 --> 01:06:35,020
that's basically the the definition being convex because the hessian matrix was

986
01:06:36,430 --> 01:06:42,150
the same eight matrix was the hash novi objective function minus the sum why i

987
01:06:42,150 --> 01:06:46,220
times the hash and to thee constraint functions and so on

988
01:06:46,490 --> 01:06:47,200
if the thing is

989
01:06:48,540 --> 01:06:55,790
is is is is is and is nonconvex than one of those things is not positive semi definite and so

990
01:06:57,080 --> 01:06:58,110
this might fail

991
01:07:01,700 --> 01:07:04,480
o nine messing up my notations hold on a second

992
01:07:06,910 --> 01:07:09,470
and they go back to refresh my own memory what ages

993
01:07:11,040 --> 01:07:13,450
yes that's the right so is this

994
01:07:14,850 --> 01:07:18,210
and if it's not positive if the problem is not convex

995
01:07:19,390 --> 01:07:22,060
something here is not positive semi definite

996
01:07:30,800 --> 01:07:33,980
and if so if age is not positive semi definite the net

997
01:07:34,520 --> 01:07:38,810
normal matrix and the dual matrix might fail to be positive definite

998
01:07:39,300 --> 01:07:42,400
might not but it might not get two pieces to it

999
01:07:43,640 --> 01:07:46,300
this here is positive semi definite

1000
01:07:47,020 --> 01:07:47,460
this is

1001
01:07:48,450 --> 01:07:51,530
that's always positive semi definite i guess that's an important point

1002
01:07:55,910 --> 01:07:57,790
eight transposed times dy

1003
01:07:58,510 --> 01:08:00,870
times eh is always positive semi definite

1004
01:08:01,370 --> 01:08:02,150
the way you see it

1005
01:08:02,640 --> 01:08:04,880
is to multiply by any vector call see

1006
01:08:06,380 --> 01:08:08,730
on the left multiplied by sea transpose

1007
01:08:09,710 --> 01:08:11,720
this is i checked positive semi definiteness

1008
01:08:12,450 --> 01:08:18,010
and this matrix d is a diagonal matrix with all nonnegative entries so i can take

1009
01:08:18,950 --> 01:08:21,680
and right is one-half do one half squared

1010
01:08:23,940 --> 01:08:24,610
and so this is

1011
01:08:25,040 --> 01:08:27,180
now all this can be factored this is basically

1012
01:08:28,500 --> 01:08:29,230
do you

1013
01:08:29,410 --> 01:08:30,350
to the one half

1014
01:08:30,910 --> 01:08:31,590
times a

1015
01:08:32,160 --> 01:08:32,950
time see

1016
01:08:34,540 --> 01:08:39,470
times the transpose that's so this is the norm of the vector squared is equal to this

1017
01:08:40,230 --> 01:08:42,500
and so the this is greater than or equal to zero

1018
01:08:44,140 --> 01:08:44,590
and so

1019
01:08:45,510 --> 01:08:47,790
when so the matrix eight transpose

1020
01:08:48,660 --> 01:08:51,460
times day diagonal positive entries times eight

1021
01:08:51,900 --> 01:08:52,610
is always

1022
01:08:53,730 --> 01:08:57,800
positive semi definite so this matrix is being added on

1023
01:08:58,800 --> 01:09:03,370
is positive semi definite so the passions here that this linear combination versions

1024
01:09:03,850 --> 01:09:07,740
this may not be positive definite but that might not be a problem because you've

1025
01:09:07,740 --> 01:09:10,310
also got these terms here adding helping you out

1026
01:09:13,130 --> 01:09:17,200
hands and so sometimes a non convex problem is is okay

1027
01:09:17,970 --> 01:09:18,180
you know

1028
01:09:19,350 --> 01:09:21,300
but you have to worry about when it's not okay

1029
01:09:28,710 --> 01:09:28,990
all right

1030
01:09:30,460 --> 01:09:32,390
so what are we gonna do if it's not okay

1031
01:09:35,520 --> 01:09:36,400
if if the

1032
01:09:37,060 --> 01:09:38,690
normal a matrix is

1033
01:09:39,780 --> 01:09:41,350
the dual norm a matrix is

1034
01:09:42,140 --> 01:09:43,930
not positive semi definite

1035
01:09:44,710 --> 01:09:48,640
then we lose the conditions that the conclusions in the previous theorem

1036
01:09:49,720 --> 01:09:52,510
and so we don't have descent directions

1037
01:09:52,970 --> 01:09:55,660
so feasible is not going to improve

1038
01:09:56,590 --> 01:09:58,800
always we got feasible because we are lucky

1039
01:10:00,710 --> 01:10:05,010
we won't necessarily a closed optimally because it's no longer going in the right direction

1040
01:10:05,630 --> 01:10:06,470
that's really bad

1041
01:10:07,730 --> 01:10:10,570
but you can regain those properties and having at least

1042
01:10:10,980 --> 01:10:13,200
going in the right direction descent properties

1043
01:10:14,270 --> 01:10:16,140
in a very simple manner i have to do

1044
01:10:16,650 --> 01:10:20,320
is perturbed the hash and with the diagonal perturbation lambda

1045
01:10:20,900 --> 01:10:22,230
if you can come up with a

1046
01:10:22,910 --> 01:10:25,130
a scheme for estimating a good lambda

1047
01:10:27,040 --> 01:10:28,160
then the nearer than here

1048
01:10:29,510 --> 01:10:30,980
get the descent properties back

1049
01:10:31,550 --> 01:10:32,630
again easily

1050
01:10:33,480 --> 01:10:34,850
and so you perturb there

1051
01:10:35,300 --> 01:10:39,370
age with this lambda you replace it with age this age till the in the

1052
01:10:39,370 --> 01:10:43,350
computation step directions and you can show that you have all the properties

1053
01:10:44,090 --> 01:10:45,350
a descent that you needed

1054
01:10:47,570 --> 01:10:47,980
and so

1055
01:10:48,900 --> 01:10:49,680
just a precise

1056
01:10:50,200 --> 01:10:51,220
if we let until the

1057
01:10:52,040 --> 01:10:55,270
dual normal matrix associated with age told instead of the

1058
01:10:55,500 --> 01:10:56,610
one is with age

1059
01:10:57,120 --> 01:11:02,850
then we have the same kind of result as we had before r if this do this perturbed dual normal

1060
01:11:03,630 --> 01:11:05,120
matrix is positive definite

1061
01:11:05,540 --> 01:11:09,540
the step directions are descent direction for the primal feasibility

1062
01:11:10,150 --> 01:11:14,350
end all the theorem slightly different actually and for the non complementarity

1063
01:11:15,300 --> 01:11:19,560
so the deviation from complementarity as measured w transpose why

1064
01:11:23,370 --> 01:11:26,340
so this the second stage is a little bit different from before it's not be

1065
01:11:26,740 --> 01:11:27,830
barrier function

1066
01:11:28,950 --> 01:11:32,260
going in the right direction but it's this going in the right direction but duality

1067
01:11:32,260 --> 01:11:34,180
theory tells us if we are feasible

1068
01:11:34,780 --> 01:11:35,690
end we

1069
01:11:36,070 --> 01:11:38,090
i have no complementarity the more optimal

1070
01:11:40,340 --> 01:11:43,850
it turns out that in this case that's exactly what you need so having these

1071
01:11:43,850 --> 01:11:45,040
things going in the right direction

1072
01:11:46,500 --> 01:11:48,700
o i'm sorry i forgot one thing

1073
01:11:49,240 --> 01:11:49,800
my mistake

1074
01:11:50,350 --> 01:11:54,000
we also have to have dual feasibility and we don't necessarily

1075
01:11:55,930 --> 01:11:59,350
stem direction uh improvement in the dual feasibility

1076
01:12:02,910 --> 01:12:03,280
and so

1077
01:12:03,700 --> 01:12:06,660
we have to do a line search to prefer to find a value of lambda

1078
01:12:07,280 --> 01:12:08,040
this within a factor

1079
01:12:08,750 --> 01:12:13,690
so what we do is a line search to find the value of land within a factor to the smallest

1080
01:12:16,060 --> 01:12:17,260
perturbation because you don't wanna

1081
01:12:17,940 --> 01:12:20,570
you know obviously got a big lambda times identity and make it

1082
01:12:22,270 --> 01:12:23,300
positive semi definite but

1083
01:12:24,040 --> 01:12:24,350
then you've

1084
01:12:25,260 --> 01:12:26,380
distorted too much

1085
01:12:27,180 --> 01:12:28,340
things will converge slowly

1086
01:12:31,720 --> 01:12:34,110
there wasn't bad enough even more things can go wrong

1087
01:12:35,490 --> 01:12:36,750
convex optimization

1088
01:12:40,930 --> 01:12:42,750
so if the problem is convex

1089
01:12:42,750 --> 01:12:44,170
the size of the semantic web

1090
01:12:46,800 --> 01:12:49,020
if i have network

1091
01:12:49,170 --> 01:12:51,480
i can give it to you arrive at least

1092
01:13:04,130 --> 01:13:11,940
what's the point of about the publishing process and some

1093
01:13:12,090 --> 01:13:14,650
that's not at all

1094
01:13:15,000 --> 01:13:18,250
is i house data that is you show

1095
01:13:18,340 --> 01:13:21,670
not just one which is of the

1096
01:13:25,960 --> 01:13:29,500
systems that present the semantic web client library

1097
01:13:29,670 --> 01:13:34,210
as an example of how and applications use of consuming data

1098
01:13:34,280 --> 01:13:35,940
on the web

1099
01:13:35,960 --> 01:13:40,770
in the following couple of minutes i will be introduction describe how the lab folks

1100
01:13:40,770 --> 01:13:44,210
how you get into a how you can use the command line interface of the

1101
01:13:44,230 --> 01:13:48,770
library and how we can integrate the lighting applications

1102
01:13:48,920 --> 01:13:53,250
before i go into the details and let me show you an example of that

1103
01:13:55,230 --> 01:13:58,550
say we want to know the the interests of people tunnels

1104
01:13:58,650 --> 01:14:03,420
we can represent this question by parker clear like this

1105
01:14:05,270 --> 01:14:07,130
and so this can be

1106
01:14:07,190 --> 01:14:11,980
we need several RDF documents from being tons full five

1107
01:14:12,250 --> 01:14:13,940
the about us contact

1108
01:14:14,000 --> 01:14:17,070
and we need the full phase of the reference desk

1109
01:14:17,170 --> 01:14:19,900
the persons a interest

1110
01:14:21,820 --> 01:14:28,900
given that all the data is published following the linked data principles and applications automatically

1111
01:14:29,050 --> 01:14:30,400
retrieved this

1112
01:14:30,550 --> 01:14:33,230
documents from the that and

1113
01:14:33,770 --> 01:14:38,360
process query over the whole set of documents

1114
01:14:38,440 --> 01:14:40,050
for this could be

1115
01:14:40,070 --> 01:14:42,940
the semantic web client library tree twenty nine

1116
01:14:43,020 --> 01:14:44,440
documents on the web

1117
01:14:46,000 --> 01:14:48,520
if this results

1118
01:14:48,550 --> 01:14:51,960
so what's the main features of the library

1119
01:14:52,050 --> 01:14:56,670
it was used to create the basically the whole weight of data using sparql queries

1120
01:14:56,690 --> 01:15:02,280
of find SP all queries which are simple triple pattern queries

1121
01:15:04,670 --> 01:15:06,670
the library retrieves

1122
01:15:06,730 --> 01:15:11,020
relevant RDF documents during query execution

1123
01:15:11,210 --> 01:15:19,380
and in order to discover these documents references http URI as follows see also link

1124
01:15:19,650 --> 01:15:25,570
follows links and HTML headers and a curious this image is

1125
01:15:25,750 --> 01:15:28,250
retrieved documents are the or

1126
01:15:28,270 --> 01:15:30,110
the local graph set

1127
01:15:30,130 --> 01:15:34,550
and later q executions can use these local copies

1128
01:15:34,690 --> 01:15:37,610
instead of retrieving this data

1129
01:15:37,730 --> 01:15:42,210
furthermore the library supports crystal

1130
01:15:42,380 --> 01:15:47,270
OK so for the introduction that describe how the library works or more precisely how

1131
01:15:47,270 --> 01:15:50,250
preprocessing the

1132
01:15:50,440 --> 01:15:54,090
first of all communities as it

1133
01:15:54,250 --> 01:15:56,630
into single triple patterns

1134
01:15:56,710 --> 01:15:58,610
our sample

1135
01:15:59,310 --> 01:16:03,730
now some query consists of triple patterns as

1136
01:16:03,960 --> 01:16:05,920
this one

1137
01:16:06,020 --> 01:16:09,550
each triple pattern evaluated separately by the library

1138
01:16:10,460 --> 01:16:13,550
the results are joined in streaming manner

1139
01:16:13,650 --> 01:16:17,020
for each prepared to let

1140
01:16:17,140 --> 01:16:19,570
eleven executes

1141
01:16:19,730 --> 01:16:21,880
directed browsing i got the

1142
01:16:21,960 --> 01:16:23,860
which iteratively

1143
01:16:23,980 --> 01:16:29,920
retrieves relevant RDF graphs from them and finds matching triples

1144
01:16:30,090 --> 01:16:32,020
the following show you

1145
01:16:32,090 --> 01:16:34,040
and execution as i them

1146
01:16:34,130 --> 01:16:36,610
before this trip

1147
01:16:36,650 --> 01:16:41,480
as the first step the algorithm looks up a URI is that our sample code

1148
01:16:41,480 --> 01:16:44,110
and we have to you as you have put on

1149
01:16:44,320 --> 01:16:48,300
you have two and the fourth knows URI

1150
01:16:48,480 --> 01:16:50,300
but this fulfills property

1151
01:16:50,360 --> 01:16:52,900
tom's URI

1152
01:16:53,000 --> 01:16:55,960
we wish an HTTP GET request

1153
01:16:56,050 --> 01:17:01,710
receive a response which redirects to the document which is an HTML document in this

1154
01:17:01,710 --> 01:17:04,090
document defined

1155
01:17:04,320 --> 01:17:10,380
reference to an alternative representation finally from this year i retrieve an RDF graph

1156
01:17:10,610 --> 01:17:13,730
and at this graph drawing graphs

1157
01:17:13,840 --> 01:17:16,630
looking at the fourth knows

1158
01:17:16,690 --> 01:17:19,730
you i follow a similar procedure and we find

1159
01:17:19,840 --> 01:17:24,610
and the RDF graph from this URI

1160
01:17:24,860 --> 01:17:26,000
the second step

1161
01:17:26,040 --> 01:17:30,960
we follow see also links which means we

1162
01:17:34,090 --> 01:17:36,550
for for each of the

1163
01:17:38,400 --> 01:17:42,460
what you see also troopers and all of the graphs that the subject

1164
01:17:42,750 --> 01:17:46,230
is one of the URI sonata pattern

1165
01:17:46,320 --> 01:17:49,650
we must look at the object of the strip

1166
01:17:49,800 --> 01:17:55,090
so far for example we had talks here i the fourth knows property URI

1167
01:17:55,280 --> 01:17:57,420
which means we must fight

1168
01:17:57,540 --> 01:18:02,320
troopers that match this all this pattern in our local graph set

1169
01:18:02,480 --> 01:18:09,730
and all these attributes we must look up the eyes and object position

1170
01:18:10,960 --> 01:18:15,020
now we have some RDF graphs local graphs

1171
01:18:15,250 --> 01:18:16,940
next step is

1172
01:18:19,250 --> 01:18:22,050
our triple pattern against all graphs in the set

1173
01:18:22,250 --> 01:18:27,250
in order to find matching triples which are solutions to our

1174
01:18:27,520 --> 01:18:29,860
a triple pattern t

1175
01:18:30,020 --> 01:18:33,110
for this could be the retrieved

1176
01:18:33,210 --> 01:18:34,800
the set of

1177
01:18:34,920 --> 01:18:37,110
matching triples

1178
01:18:37,150 --> 01:18:40,940
upon the trip which states

1179
01:18:41,040 --> 01:18:42,520
OK you can read this

1180
01:18:42,550 --> 01:18:46,770
the strip it's those richard

1181
01:18:46,960 --> 01:18:48,730
all of these

1182
01:18:49,980 --> 01:18:51,210
matching triple

1183
01:18:51,270 --> 01:18:53,730
and the next step

1184
01:18:57,230 --> 01:19:00,340
we iterate in all of these matching propose

1185
01:19:00,440 --> 01:19:03,360
for each matching triple the first look at

1186
01:19:03,550 --> 01:19:06,570
the new UI is in the strip

1187
01:19:06,820 --> 01:19:10,070
let's take for example it is tom knows which true

1188
01:19:10,190 --> 01:19:16,380
and the new URI is a trip to new i'm representing richard in the semantic

1189
01:19:16,380 --> 01:19:17,800
web dot org

1190
01:19:18,050 --> 01:19:19,250
it does

1191
01:19:19,360 --> 01:19:21,570
looking at this URI

1192
01:19:21,610 --> 01:19:28,070
retrieve RDF data from semanticweb org of which can this graph to local graphs

1193
01:19:28,340 --> 01:19:30,540
and second for each matching triple

1194
01:19:31,270 --> 01:19:34,400
again follows the also things

1195
01:19:34,460 --> 01:19:36,730
for the u so

1196
01:19:36,770 --> 01:19:39,840
the district had this new year i

1197
01:19:39,960 --> 01:19:41,980
and following this

1198
01:19:44,110 --> 01:19:47,050
following see also links with this here i

1199
01:19:47,110 --> 01:19:51,380
we find tom's foaf document which has been retrieved on the first

1200
01:19:51,630 --> 01:19:54,690
in this document we have a see also link

1201
01:19:54,730 --> 01:19:59,210
for this URI refers to richard for five

1202
01:19:59,590 --> 01:20:01,880
looking up this year i

1203
01:20:01,960 --> 01:20:07,300
we find richards for and at this graph to our progress

1204
01:20:09,880 --> 01:20:16,670
since the the fourth step iterates over all matching triples form step three

1205
01:20:16,900 --> 01:20:21,320
not just in this tunnels which trip

1206
01:20:22,300 --> 01:20:23,610
the library tree

1207
01:20:23,650 --> 01:20:25,980
in this case twenty one years

1208
01:20:26,040 --> 01:20:29,780
graphs from the from the web

1209
01:20:29,900 --> 01:20:31,710
and in the next step

1210
01:20:31,710 --> 01:20:36,920
no don't worry toward work and i'm saying that if you want to align

1211
01:20:36,950 --> 01:20:40,760
x one and x i and y one to y and senators y one to

1212
01:20:40,760 --> 01:20:45,730
y is the entire string this time then there are two possibilities it even this

1213
01:20:45,730 --> 01:20:47,180
last letter here

1214
01:20:47,200 --> 01:20:51,380
is matched with one of these and that it is the oxford is giving us

1215
01:20:51,380 --> 01:20:56,480
because we use ox to compute that or is this i is not aligned with

1216
01:20:56,480 --> 01:20:59,470
any one but in that case i can get rid of it i'm saying the

1217
01:20:59,470 --> 01:21:01,810
number of the kernel of this

1218
01:21:01,830 --> 01:21:06,610
this is the same as the kind of i minus one and so i've got

1219
01:21:07,500 --> 01:21:09,770
my formula

1220
01:21:09,900 --> 01:21:13,580
this is the algorithm i'm leaving it can slide so that people can look at

1221
01:21:13,580 --> 01:21:16,960
it is not the most to say i just think there is this

1222
01:21:17,450 --> 01:21:20,580
this outer loop for the inner loop

1223
01:21:20,600 --> 01:21:23,130
ox is computed little by little

1224
01:21:23,140 --> 01:21:26,990
and then i'm looking to see if these last letters coincide which is the only

1225
01:21:26,990 --> 01:21:31,450
case where it's interesting to actually do these new computations in which case i must

1226
01:21:31,450 --> 01:21:32,840
make sure my ox

1227
01:21:32,890 --> 01:21:37,110
is is augmented is is is a bit larger and then what i've got to

1228
01:21:37,110 --> 01:21:38,900
do here is just the a

1229
01:21:38,920 --> 01:21:43,640
computation that just shown in the last slide which is the kernel of i and

1230
01:21:43,640 --> 01:21:46,750
j is the kernel of i minus one and j

1231
01:21:46,760 --> 01:21:49,490
we so why we had that plus

1232
01:21:49,500 --> 01:21:54,880
ok subject to say all possibilities where we want to match the IRS letter with

1233
01:21:54,880 --> 01:21:57,150
one of the preceding ones

1234
01:21:58,880 --> 01:22:02,280
i think that's this

1235
01:22:02,290 --> 01:22:05,810
and here is the running example served as you want to look at it

1236
01:22:05,820 --> 01:22:07,260
how does it go

1237
01:22:07,260 --> 01:22:11,260
the idea is in the same table i have put the k is

1238
01:22:11,270 --> 01:22:12,580
which are here

1239
01:22:12,610 --> 01:22:15,280
and ox values that are here

1240
01:22:15,320 --> 01:22:18,070
so if i take something like what could know

1241
01:22:18,120 --> 01:22:21,840
this is in this case here five is the result of four plus one six

1242
01:22:21,840 --> 01:22:24,310
plus one basically using the

1243
01:22:24,340 --> 01:22:27,050
the values we compute for

1244
01:22:29,210 --> 01:22:30,900
and hundred more

1245
01:22:30,920 --> 01:22:34,520
so as i said before why not try something that's why can't we think of

1246
01:22:34,520 --> 01:22:39,740
doing you know the all substrings instead of just the substrings of length something like

1247
01:22:39,740 --> 01:22:43,530
a pseudo an enumeration of all the strings and you wanted to count how many

1248
01:22:43,530 --> 01:22:48,310
times z each substring appear in the in the in the coastal city sounds nice

1249
01:22:48,310 --> 01:22:53,120
you if the all subsequences work with the weighting scheme we wanted to be able

1250
01:22:53,140 --> 01:22:57,990
to say that when the strings are closer than of this was important when can

1251
01:22:57,990 --> 01:23:02,250
try this by the reason is with the police i haven't reached and the book

1252
01:23:02,250 --> 01:23:08,110
doesn't mention any so i'm not sure they reached either any nice satisfy factory formula

1253
01:23:08,110 --> 01:23:11,770
to be able to calculate it so so you turn into a certain number of

1254
01:23:11,770 --> 01:23:15,680
choices because of what the

1255
01:23:15,700 --> 01:23:21,810
the combinatorics of the strings tell you need to say that what is truly with

1256
01:23:21,810 --> 01:23:25,790
strings is even more true with the case of the surface

1257
01:23:25,800 --> 01:23:31,080
is even more true with the case of trees or graphs where as soon as

1258
01:23:31,080 --> 01:23:35,710
you're trying to think in terms of finding some sort of nice kernel something that

1259
01:23:35,980 --> 01:23:40,480
you know intuitively you would like to use your face the fact that you just

1260
01:23:40,480 --> 01:23:42,640
can't computer

1261
01:23:42,660 --> 01:23:47,850
all i could do that as an exercise exercise shows session to try and do

1262
01:23:48,560 --> 01:23:54,410
an alternative edit kernel notice in this edit kernel of the thing the closest to

1263
01:23:54,410 --> 01:23:59,660
the edit distance we've just seen here with the all subsequences we're counting the number

1264
01:23:59,660 --> 01:24:04,480
of alignments but when we doing edit distance is not the number of alignments were

1265
01:24:04,480 --> 01:24:08,990
interested in interesting the best alignment so could we have something to with counting the

1266
01:24:08,990 --> 01:24:12,790
number of best alignments of could we have something that we just say what is

1267
01:24:12,790 --> 01:24:15,360
the length of the best in alignment

1268
01:24:15,380 --> 01:24:19,570
OK and the longer the alignment you know the the higher the value

1269
01:24:19,570 --> 01:24:25,140
well those things corresponds to so yes finding the number of possible much better sort

1270
01:24:25,140 --> 01:24:26,550
of finding the best

1271
01:24:26,570 --> 01:24:30,660
alignment is not going to be computationally difficult but we do know how to do

1272
01:24:31,090 --> 01:24:38,300
that we're facing another problem which is almost as conditions for the truth

1273
01:24:38,320 --> 01:24:43,110
the one saying know we saw yesterday that the metrics has to be respecting a

1274
01:24:43,110 --> 01:24:48,800
certain number of rules were to become so so really facing three way challenge we

1275
01:24:48,850 --> 01:24:54,230
wanting the kernel two two means something something that is appealing to us appealing to

1276
01:24:54,230 --> 01:24:57,300
the problem we're interested in we wanted to be

1277
01:24:57,740 --> 01:25:00,140
algorithmically interesting

1278
01:25:00,160 --> 01:25:04,960
right and want to be able to compute well i wanted to be mathematically correct

1279
01:25:04,960 --> 01:25:10,340
and it's hard to be able to fit the three things at the time

1280
01:25:10,390 --> 01:25:15,260
this is just another idea of one of counting substrings only once

1281
01:25:15,270 --> 01:25:21,520
here were also counting where the substrings how many times we can match them but

1282
01:25:21,520 --> 01:25:27,510
we're really interested in avoiding having to counter a counting it varies times letters being

1283
01:25:27,510 --> 01:25:31,910
user and if you if you pass it with an automaton for example you really

1284
01:25:32,070 --> 01:25:36,430
count how many times you go through the automaton without going back every time counting

1285
01:25:36,450 --> 01:25:42,210
all the combinatorics but same thing all these ideas don't don't seem to work in

1286
01:25:43,460 --> 01:25:48,590
OK so the very important well i mean i suppose you or what does the

1287
01:25:48,590 --> 01:25:55,400
tory machine learning labs will have it around the shorter christian book and in the

1288
01:25:55,400 --> 01:26:00,880
case of strings there's been some interesting things done by alex class and chris watkins

1289
01:26:01,160 --> 01:26:06,230
the authors in the last two years because they've been trying to use these string

1290
01:26:06,230 --> 01:26:07,350
kernels two

1291
01:26:07,810 --> 01:26:09,570
to define languages

1292
01:26:09,630 --> 01:26:12,380
and the to learn languages thanks to shrink

1293
01:26:12,390 --> 01:26:17,010
OK so the names or alex clark and chris watkins

1294
01:26:21,020 --> 01:26:26,290
right so here i'm just going to quickly go through two

1295
01:26:26,400 --> 01:26:32,580
as the alternative objects that we find in theoretical computer science and that or also

1296
01:26:32,580 --> 01:26:36,600
becoming of increasing importance in the case of

1297
01:26:36,660 --> 01:26:46,620
in the case of machine learning because the data is more and more structured so

1298
01:26:46,620 --> 01:26:49,830
you want more and more to be able to manipulate it's not perfect

1299
01:26:49,970 --> 01:26:54,210
the idea of just extracting features and then playing for the features is not always

1300
01:26:54,210 --> 01:26:57,600
the next one will be the pair

1301
01:26:57,680 --> 01:27:00,960
x two

1302
01:27:00,970 --> 01:27:02,150
x three

1303
01:27:02,170 --> 01:27:05,520
and so on

1304
01:27:05,520 --> 01:27:09,420
and then what you do is compute sufficient statistics phi

1305
01:27:09,450 --> 01:27:10,960
of those past

1306
01:27:11,010 --> 01:27:14,570
they do inference

1307
01:27:14,610 --> 01:27:17,030
and how to do this

1308
01:27:17,160 --> 01:27:20,000
how to get the gene functional explained

1309
01:27:27,870 --> 01:27:32,170
no that would be an extremely well

1310
01:27:32,190 --> 01:27:35,370
there is one case where c decomposes

1311
01:27:35,380 --> 01:27:40,840
which is when you have truly independent subsets of random variables

1312
01:27:41,790 --> 01:27:43,670
in this case the

1313
01:27:43,710 --> 01:27:45,170
can be computed by

1314
01:27:45,180 --> 01:27:48,860
computing disease on the subsets of the random variables

1315
01:27:48,900 --> 01:27:51,130
however in most cases

1316
01:27:51,140 --> 01:27:52,870
you will have a certain dependent

1317
01:27:52,880 --> 01:27:57,220
but you know exactly on the right track insofar as

1318
01:27:58,830 --> 01:28:04,010
graphical model is nice intractable so if it decomposes quite nicely in computing z

1319
01:28:04,060 --> 01:28:05,880
will be easy

1320
01:28:05,910 --> 01:28:08,630
but if the graphical model is

1321
01:28:10,080 --> 01:28:12,150
so if it is intractable

1322
01:28:13,110 --> 01:28:16,120
well computing xe will be

1323
01:28:16,150 --> 01:28:20,050
complicated or next impossible

1324
01:28:20,700 --> 01:28:26,790
and that essentially the question of dynamic programming in

1325
01:28:26,810 --> 01:28:30,800
will get examples

1326
01:28:30,820 --> 01:28:37,760
OK forget about the proof of this decomposition it's basically just using orthogonality

1327
01:28:38,400 --> 01:28:44,230
let's look at the specific example first

1328
01:28:44,770 --> 01:28:48,860
so let's take normal distributions

1329
01:28:49,720 --> 01:28:55,460
we know that for normal distribution are sufficient statistics for fixed just x and x

1330
01:28:55,460 --> 01:28:57,610
six transpose

1331
01:28:59,650 --> 01:29:06,030
now by the clifford hammersley theorem we know that topics must decompose into subsets involving

1332
01:29:06,030 --> 01:29:08,840
only the variables from each maximal clique

1333
01:29:12,840 --> 01:29:16,800
by the very form of the sufficient statistics

1334
01:29:16,940 --> 01:29:17,920
i know

1335
01:29:19,460 --> 01:29:25,680
well the only term that can cause interactions is the inner product between x

1336
01:29:25,700 --> 01:29:28,100
x transposed

1337
01:29:28,140 --> 01:29:33,000
and some parameters theta two

1338
01:29:33,010 --> 01:29:37,070
so in here

1339
01:29:37,120 --> 01:29:39,380
i can only have

1340
01:29:39,430 --> 01:29:41,000
i mean these are all

1341
01:29:41,010 --> 01:29:44,620
this only contains monomials of degree two

1342
01:29:44,650 --> 01:29:50,020
so it has any terms x i x j

1343
01:29:50,160 --> 01:29:55,100
so basically what they will get is that this equals the sum over i and

1344
01:29:56,050 --> 01:29:57,390
x i x j

1345
01:29:57,410 --> 01:30:00,880
times some coefficient data two

1346
01:30:00,900 --> 01:30:01,750
i j

1347
01:30:06,350 --> 01:30:12,330
that's just by the very construction of the normal distribution

1348
01:30:14,250 --> 01:30:18,830
i know that i cannot have any such terms theta i j

1349
01:30:18,880 --> 01:30:24,420
we're well i don't have an edge in the graph

1350
01:30:24,500 --> 01:30:26,880
just by the construction of

1351
01:30:26,930 --> 01:30:29,170
the maximal cliques and all that

1352
01:30:29,180 --> 01:30:30,370
so therefore

1353
01:30:30,370 --> 01:30:33,500
it means that the graph to them getting

1354
01:30:33,510 --> 01:30:35,380
corresponds to the graph

1355
01:30:35,430 --> 01:30:40,950
of nonzero entries in the corresponding curves covariance matrix

1356
01:30:40,960 --> 01:30:43,360
as the inverse covariance matrix

1357
01:30:43,370 --> 01:30:46,550
so this a very direct link between

1358
01:30:46,590 --> 01:30:48,480
sparse matrices

1359
01:30:49,540 --> 01:30:53,300
well independence of random variables

1360
01:30:54,760 --> 01:30:57,050
let's have a look at

1361
01:30:57,090 --> 01:30:58,980
the next slide that

1362
01:30:59,040 --> 01:31:00,780
shows it in a bit more detail

1363
01:31:00,820 --> 01:31:02,700
that's a that's why graphical models

1364
01:31:05,450 --> 01:31:08,090
and these are the terms here

1365
01:31:08,100 --> 01:31:12,860
and the data is the inverse covariance matrix

1366
01:31:13,940 --> 01:31:18,350
i can only have that any of those terms i j here is nonzero

1367
01:31:18,350 --> 01:31:21,870
if i and j share an edge

1368
01:31:21,890 --> 01:31:23,390
so this

1369
01:31:23,410 --> 01:31:30,140
graph here corresponds to a nonzero entries exactly in those parts

1370
01:31:30,190 --> 01:31:33,350
OK the mind of you have something anyway because

1371
01:31:33,350 --> 01:31:37,790
and of course connects with itself but everything else

1372
01:31:37,820 --> 01:31:40,840
really corresponds to where you have an it

1373
01:31:40,860 --> 01:31:44,190
and i can already see that depending on

1374
01:31:44,220 --> 01:31:46,630
hierarchical model looks like

1375
01:31:46,650 --> 01:31:47,550
you can

1376
01:31:47,560 --> 01:31:49,500
do matrix manipulations here

1377
01:31:49,510 --> 01:31:51,730
more or less efficiently

1378
01:31:51,850 --> 01:31:53,320
so if use

1379
01:31:53,390 --> 01:32:00,570
had to suffer through any well special matrix factorizations lectures in numerical analysis

1380
01:32:00,690 --> 01:32:05,630
like well what do we do with templates matrices with try diagonal matrices and what

1381
01:32:05,630 --> 01:32:06,910
have you

1382
01:32:06,930 --> 01:32:12,270
you've probably learned various ways how to solve for them

1383
01:32:12,310 --> 01:32:14,670
and it turns out these

1384
01:32:14,730 --> 01:32:16,080
map directly

1385
01:32:16,080 --> 01:32:19,730
into inference methods for graphical models

1386
01:32:19,750 --> 01:32:24,530
he would for instance go and start peeling away on this parable then you only

1387
01:32:24,530 --> 01:32:27,780
get these to live then you push it through here and so on and so

1388
01:32:29,580 --> 01:32:35,220
and so this is pretty direct mapping between what you can do in america analysis

1389
01:32:35,250 --> 01:32:38,550
and graphical models

1390
01:32:43,180 --> 01:32:45,100
two and three

1391
01:32:45,100 --> 01:32:49,000
well there's no age

1392
01:32:52,430 --> 01:32:58,350
whoa wait wait so one and two are connected OK good

1393
01:32:58,360 --> 01:33:00,640
yeah but

1394
01:33:00,670 --> 01:33:03,610
but both two and three times nigeria

1395
01:33:04,750 --> 01:33:07,590
yes sorry industry

1396
01:33:07,650 --> 01:33:10,480
he is this is your right

1397
01:33:10,830 --> 01:33:13,950
OK that's wrong and very good

1398
01:33:14,160 --> 01:33:18,320
OK so the

1399
01:33:20,050 --> 01:33:23,100
maybe i shouldn't do that now in the for

1400
01:33:23,110 --> 01:33:25,610
we have the evidence that the

1401
01:33:25,610 --> 01:33:31,400
the fact is that people are watching without any complete rubbish

1402
01:33:31,460 --> 01:33:32,870
very good

1403
01:33:33,000 --> 01:33:37,040
very good

1404
01:33:45,080 --> 01:33:47,450
does that make reasonably since the most of you

1405
01:33:48,360 --> 01:33:51,940
so you get the district mapping between nonzero entries

1406
01:33:52,050 --> 01:33:54,180
this term here

1407
01:33:54,200 --> 01:33:57,850
is it has to decompose allow hammersley clifford

1408
01:33:57,860 --> 01:34:00,660
and the graphical model

1409
01:34:06,930 --> 01:34:11,670
the next step is so we done the graphical models are to some extent now

1410
01:34:11,670 --> 01:34:15,300
we look at this conditioning

1411
01:34:17,610 --> 01:34:22,540
this was normal density

1412
01:34:22,550 --> 01:34:27,030
this is the conditional density p of y given x parameters theta

1413
01:34:27,110 --> 01:34:30,860
well the log partition function here

1414
01:34:30,860 --> 01:34:36,060
exactly the same expression again but just that this XML becomes so say

1415
01:34:36,100 --> 01:34:37,870
variable with which i can

1416
01:34:37,880 --> 01:34:41,920
what if i'm the original expression

1417
01:34:42,670 --> 01:34:44,040
it would

1418
01:34:45,160 --> 01:34:48,320
if p of x and y parameterized by state is a member of the exponential

1419
01:34:49,180 --> 01:34:52,770
to get that expression but doesn't actually have to be

1420
01:34:52,890 --> 01:34:54,190
this is one of the

1421
01:34:54,200 --> 01:34:55,650
advances over

1422
01:34:55,660 --> 01:34:59,300
building a joint model in x and y

1423
01:34:59,300 --> 01:35:03,380
so here just to show that it's not one note just

1424
01:35:03,390 --> 01:35:06,260
so they were all the words that there is a complete

1425
01:35:06,490 --> 01:35:07,960
so you know

1426
01:35:07,990 --> 01:35:09,790
so just about works

1427
01:35:09,810 --> 01:35:11,710
if there was a same match

1428
01:35:11,720 --> 01:35:16,660
they're not enough much together and for every word senses have exactly

1429
01:35:16,660 --> 01:35:21,420
you can find a note in the

1430
01:35:26,140 --> 01:35:30,790
and so here as is you know to the right

1431
01:35:30,840 --> 01:35:32,990
these are heuristics no

1432
01:35:33,010 --> 01:35:37,050
this planet together

1433
01:35:37,060 --> 01:35:41,790
this is why i used for the opening the part of speech tags

1434
01:35:41,810 --> 01:35:46,380
so something that you can download job

1435
01:35:46,380 --> 01:35:48,450
opened p

1436
01:35:48,460 --> 01:35:50,050
so there is more than the text

1437
01:35:50,060 --> 01:35:52,880
open up so it's something

1438
01:35:52,890 --> 01:35:55,920
everyone use

1439
01:35:55,920 --> 01:35:58,800
well not

1440
01:35:58,800 --> 01:36:01,310
deep syntactic analysis the rituals

1441
01:36:01,420 --> 01:36:04,960
a second say this

1442
01:36:05,850 --> 01:36:12,050
well marksmanship the process which was trained on i don't know on which they

1443
01:36:12,130 --> 01:36:14,370
strange so

1444
01:36:14,410 --> 01:36:22,160
discriminant machine learning where you decided part of speech of words based on the context

1445
01:36:23,340 --> 01:36:24,870
so this is what

1446
01:36:41,130 --> 01:36:48,780
it's all about words there's nothing more to

1447
01:36:48,790 --> 01:36:54,310
there is some parts of

1448
01:36:54,330 --> 01:36:55,850
no no

1449
01:36:57,250 --> 01:36:58,910
you know it makes sense

1450
01:36:58,970 --> 01:37:03,430
what's the problem so it makes sense to assume that when you go and use

1451
01:37:03,920 --> 01:37:09,080
so the named entity recognizer practical what you also get a bunch of mistakes and

1452
01:37:09,080 --> 01:37:13,500
then those mistakes they always propagate so we have state and on the part of

1453
01:37:13,500 --> 01:37:18,090
speech level you would definitely get mistaken this is that if you have mistaken systems

1454
01:37:18,090 --> 01:37:20,660
are getting more mistakes the semantic

1455
01:37:20,890 --> 01:37:24,460
there is always a trade-off between accuracy what

1456
01:37:24,460 --> 01:37:26,800
what do you expect to get

1457
01:37:29,490 --> 01:37:33,040
so here is the result from activity in would

1458
01:37:33,100 --> 01:37:38,330
get the state is actually if you you look at a combination of the

1459
01:37:38,330 --> 01:37:42,660
grammaticality much easier to be this big

1460
01:37:42,670 --> 01:37:44,450
the extended version of the

1461
01:37:44,460 --> 01:37:46,470
shortest approach from this

1462
01:37:46,500 --> 01:37:47,890
that would be

1463
01:37:48,630 --> 01:37:52,370
they to be the same person

1464
01:37:53,280 --> 01:37:58,170
just to wrap up this very quickly what i've just been talking about sentence compression

1465
01:37:58,170 --> 01:38:00,470
in the context of matter excitation

1466
01:38:01,240 --> 01:38:02,350
so here

1467
01:38:02,380 --> 01:38:04,200
can be applied to

1468
01:38:04,590 --> 01:38:08,340
this theory to non system

1469
01:38:08,350 --> 01:38:11,330
an online system online service that use

1470
01:38:13,140 --> 01:38:14,840
i don't

1471
01:38:14,910 --> 01:38:16,760
different languages only

1472
01:38:16,790 --> 01:38:18,090
with joe MIT

1473
01:38:18,550 --> 01:38:24,130
that for require simulation spanish english there is also well known

1474
01:38:24,140 --> 01:38:28,640
this is a very good given all this information is used to give you don't

1475
01:38:28,660 --> 01:38:34,500
know anything about named entities that we don't know anything about since about

1476
01:38:34,510 --> 01:38:37,000
semantic information still the results

1477
01:38:37,000 --> 01:38:38,390
if you have to be pretty

1478
01:38:40,430 --> 01:38:42,460
OK so now

1479
01:38:42,470 --> 01:38:44,760
if there are no question about

1480
01:38:44,970 --> 01:38:58,370
sorry which is the

1481
01:38:58,380 --> 01:39:01,500
no i haven't done it also

1482
01:39:01,500 --> 01:39:04,030
see huge difference in the course

1483
01:39:04,080 --> 01:39:07,030
reporting in nineteen ninety nine dollars

1484
01:39:07,040 --> 01:39:08,100
but the

1485
01:39:08,110 --> 01:39:10,160
above all else

1486
01:39:10,240 --> 01:39:12,320
we can see that we had

1487
01:39:12,360 --> 01:39:13,610
eight hundred

1488
01:39:13,620 --> 01:39:17,880
floating point operations per second you should by you

1489
01:39:17,890 --> 01:39:19,990
while today we have we have

1490
01:39:23,130 --> 01:39:28,490
floating point operations saying on the laptop

1491
01:39:28,540 --> 01:39:30,180
do we have the limit

1492
01:39:30,190 --> 01:39:36,010
can we continue again we go on with the increasing their power computational power of

1493
01:39:36,010 --> 01:39:37,930
our machines

1494
01:39:37,940 --> 01:39:41,260
yes we have the limits of course it's a physical limit

1495
01:39:41,290 --> 01:39:42,160
if we

1496
01:39:42,170 --> 01:39:43,830
what is this linear

1497
01:39:43,880 --> 01:39:47,070
well let's assume we want to build the

1498
01:39:47,090 --> 01:39:49,750
and machine a sequential machine

1499
01:39:49,760 --> 01:39:52,810
which can issue one that flops

1500
01:39:52,860 --> 01:39:54,910
can we do that

1501
01:39:54,950 --> 01:39:57,630
OK let's try to understand how it works

1502
01:39:57,680 --> 01:39:59,950
if the microprocessor central

1503
01:39:59,960 --> 01:40:02,000
processing unit

1504
01:40:02,040 --> 01:40:05,510
as to issue one that i flocks

1505
01:40:05,530 --> 01:40:11,300
which means one one one there floating point operations per second we need to

1506
01:40:11,380 --> 01:40:14,990
the same amount of data to be lauded in the CPU

1507
01:40:15,040 --> 01:40:19,040
so we need to one by the data

1508
01:40:19,060 --> 01:40:21,610
somewhere near by the CPU

1509
01:40:21,680 --> 01:40:24,770
and we need to know the so much data

1510
01:40:24,820 --> 01:40:27,120
a second in the cebu to be

1511
01:40:28,070 --> 01:40:30,170
just distractions or maybe there

1512
01:40:30,180 --> 01:40:33,380
o pounds of the our operation

1513
01:40:33,400 --> 01:40:36,100
so let's assume that we can

1514
01:40:36,190 --> 01:40:41,280
in one by we can represent the operation of their organs and everything

1515
01:40:41,300 --> 01:40:43,420
and now we need to

1516
01:40:44,720 --> 01:40:48,020
the main memory around the CPU

1517
01:40:48,070 --> 01:40:50,330
and these must be

1518
01:40:50,380 --> 01:40:51,350
this is the

1519
01:40:51,360 --> 01:40:52,920
the main memory must

1520
01:40:54,030 --> 01:40:55,670
as close as possible

1521
01:40:55,740 --> 01:40:59,000
because of to transmit to move data

1522
01:40:59,020 --> 01:41:00,350
we can do better

1523
01:41:00,360 --> 01:41:03,840
let's assume that the speed of the light which is the maximum speed we can

1524
01:41:03,840 --> 01:41:08,550
you imagine is not true because we know that even the light in the medium

1525
01:41:08,550 --> 01:41:12,850
of doesn't go that fast it's a bit slower

1526
01:41:12,870 --> 01:41:14,390
but let's assume

1527
01:41:14,430 --> 01:41:18,030
but we can use the speed of light to move these data

1528
01:41:18,050 --> 01:41:21,860
so i'll be will be

1529
01:41:21,880 --> 01:41:25,410
the memory we have to use the space we have to use

1530
01:41:25,430 --> 01:41:27,470
it's simple if only assume

1531
01:41:27,480 --> 01:41:30,530
and infinity feat they seem

1532
01:41:31,630 --> 01:41:33,410
the centre of the sequel

1533
01:41:33,430 --> 01:41:34,840
let's see

1534
01:41:34,860 --> 01:41:36,180
how is

1535
01:41:36,200 --> 01:41:38,050
there are there

1536
01:41:38,060 --> 01:41:42,400
well because d this sequel around the cebu containing one terror

1537
01:41:42,420 --> 01:41:46,000
one petabytes

1538
01:41:46,020 --> 01:41:48,920
so we do them as they for you

1539
01:41:48,930 --> 01:41:51,370
and we find out we need the

1540
01:41:51,390 --> 01:41:55,160
a zero point three million square millimeters

1541
01:41:55,170 --> 01:41:56,240
an idea

1542
01:41:56,260 --> 01:41:59,320
so small c seems reasonable right

1543
01:41:59,340 --> 01:42:03,350
if we are able to put in such an idea one petabyte

1544
01:42:03,360 --> 01:42:06,050
we have the machine which can deliver

1545
01:42:06,070 --> 01:42:08,260
exactly one petaflops

1546
01:42:08,280 --> 01:42:09,930
the second

1547
01:42:09,950 --> 01:42:14,150
the problem is that we need to compute how much space we have first single

1548
01:42:14,150 --> 01:42:15,160
by the

1549
01:42:15,180 --> 01:42:20,440
it turns out what we need needed to represent one by the industry

1550
01:42:20,460 --> 01:42:23,330
and strong square and strong which is

1551
01:42:23,340 --> 01:42:24,760
more or less the size

1552
01:42:24,770 --> 01:42:27,690
a very small after

1553
01:42:27,700 --> 01:42:29,250
so there is a problem

1554
01:42:29,290 --> 01:42:31,990
sequential machine cannot reach

1555
01:42:32,010 --> 01:42:37,960
such performance will never accept such former please i believe in our life

1556
01:42:38,010 --> 01:42:43,810
this may be so these the quantum computing will change these scenarios but with the

1557
01:42:43,830 --> 01:42:45,720
current technology

1558
01:42:45,770 --> 01:42:49,780
we can not reach this performance

1559
01:42:52,340 --> 01:42:56,510
more say in nineteen sixty five

1560
01:42:56,550 --> 01:43:02,610
by way is he was the co-founder of intel corporation

1561
01:43:03,690 --> 01:43:06,130
after a few years he was working there

1562
01:43:06,140 --> 01:43:10,240
he noticed that

1563
01:43:10,280 --> 01:43:12,280
was very simple

1564
01:43:12,420 --> 01:43:14,490
a statement he made

1565
01:43:14,540 --> 01:43:16,430
because he noticed the

1566
01:43:16,450 --> 01:43:18,660
this is in the

1567
01:43:18,670 --> 01:43:20,870
o many devices

1568
01:43:21,160 --> 01:43:22,360
use the

1569
01:43:22,380 --> 01:43:25,140
in their components

1570
01:43:25,150 --> 01:43:28,320
they were building and sending

1571
01:43:28,340 --> 01:43:30,960
it means that in fifty nine days

1572
01:43:30,980 --> 01:43:32,770
something of his

1573
01:43:32,930 --> 01:43:36,440
in written scale scaling

1574
01:43:36,500 --> 01:43:41,050
but you know this there was a very strange relationship

1575
01:43:41,060 --> 01:43:42,480
among these points

1576
01:43:42,490 --> 01:43:47,790
OK they only five he was so brave brave enough at least to make this

1577
01:43:47,790 --> 01:43:49,260
statement he said

1578
01:43:50,830 --> 01:43:54,810
the complexity and for complexity meant

1579
01:43:54,830 --> 01:43:57,230
the number of votes

1580
01:43:57,250 --> 01:43:58,860
o devices

1581
01:43:58,880 --> 01:44:01,960
ten sisters for example used

1582
01:44:01,980 --> 01:44:05,670
in a tiny components like appeal

1583
01:44:08,920 --> 01:44:13,790
the number of these divided these new eyes so the complexity

1584
01:44:15,280 --> 01:44:16,850
and meanwhile

1585
01:44:16,870 --> 01:44:19,500
combined cost so far

1586
01:44:20,140 --> 01:44:22,750
combines the way building which was

1587
01:44:22,760 --> 01:44:26,290
where they were getting a revenue so which was convenient to being they were building

1588
01:44:26,290 --> 01:44:29,190
and selling

1589
01:44:29,210 --> 01:44:33,450
these complex as increasing at the rate of roughly

1590
01:44:33,460 --> 01:44:35,280
a factor of two

1591
01:44:35,290 --> 01:44:38,650
they so every year when they were

1592
01:44:38,670 --> 01:44:42,700
doubling the number of transistors in the components

1593
01:44:42,720 --> 01:44:43,850
so i said OK

1594
01:44:43,870 --> 01:44:45,670
i guess i better

1595
01:44:45,680 --> 01:44:50,560
that the in nineteen seventy five and we will have to do the other sixteen

1596
01:44:50,570 --> 01:44:53,770
ten sisters in our CPU

1597
01:44:53,780 --> 01:44:59,290
OK you got very close was he sixty five sixty five thousand

1598
01:44:59,400 --> 01:45:02,310
that's impressive

1599
01:45:02,330 --> 01:45:04,850
in nineteen

1600
01:45:04,870 --> 01:45:06,520
seventy five

1601
01:45:06,540 --> 01:45:09,410
he made a little correction please law

1602
01:45:09,450 --> 01:45:11,680
we say that the now on

1603
01:45:11,700 --> 01:45:13,790
the complexity we double

1604
01:45:13,800 --> 01:45:17,140
every eighteen months not twelve months

1605
01:45:17,150 --> 01:45:19,520
OK let's see what happens after

1606
01:45:19,530 --> 01:45:21,270
thirty years

1607
01:45:21,290 --> 01:45:22,340
it's true

1608
01:45:22,360 --> 01:45:23,550
these are

1609
01:45:23,560 --> 01:45:26,830
it up in the last thirty years still opinion

1610
01:45:26,850 --> 01:45:28,400
so here we have all day

1611
01:45:28,420 --> 01:45:33,380
intensive use here we have their memory components

1612
01:45:33,380 --> 01:45:38,700
the trouble with most realistic games as the number of pure strategies this could have

1613
01:45:38,700 --> 01:45:43,880
been a 3 by 3 matrix if if it's of course could 3 by 5

1614
01:45:43,880 --> 01:45:48,960
matrix we could have given are 3 choices and C 5 choices

1615
01:45:48,980 --> 01:45:54,750
and poker of course and number of different strategies would be of overwhelming

1616
01:45:55,180 --> 01:45:58,840
because we have to have a strategy for each situation

1617
01:45:59,740 --> 01:46:05,920
but generally speaking it pokers like this and that you might block

1618
01:46:07,840 --> 01:46:13,080
so bluff would be um yeah

1619
01:46:13,120 --> 01:46:14,360
bluff would be

1620
01:46:14,480 --> 01:46:17,890
maybe in the case of seeing going this way

1621
01:46:18,080 --> 01:46:22,740
so know and taking a chance that

1622
01:46:26,600 --> 01:46:35,920
yeah but anyway that taking that for a some fraction of the time of are

1623
01:46:35,980 --> 01:46:40,580
will be used making this choice and you only have to pay

1624
01:46:40,870 --> 01:46:45,170
so what I wanna know X and Y and the average payoff

1625
01:46:46,240 --> 01:46:53,010
so what's it what's the average payoff here event maybe I call these better these

1626
01:46:53,020 --> 01:46:57,700
X 1 and X 2 because there could have been 7 of them and I'll

1627
01:46:57,700 --> 01:47:02,550
call these y 1 and y 2 so the point is of course that the

1628
01:47:02,550 --> 01:47:07,580
sum of the X is if 1 and that all the all the exits of

1629
01:47:07,620 --> 01:47:12,770
costs greater or equal 0 and they had to 1 the probabilities of choosing different

1630
01:47:12,770 --> 01:47:21,050
rows and similarly the Wise are all non-negative add to 1 that's that's clear

1631
01:47:23,720 --> 01:47:27,620
but now what is the

1632
01:47:28,990 --> 01:47:36,080
if if I decided on playing these fractions the rows and see is decided on

1633
01:47:36,080 --> 01:47:41,870
those fractions of the columns what's that we well how often does a former get

1634
01:47:41,870 --> 01:47:44,550
chosen how often is the payoff for

1635
01:47:46,050 --> 01:47:47,750
x 1 y 1

1636
01:47:47,790 --> 01:47:49,790
receiver independent decisions

1637
01:47:49,920 --> 01:47:51,520
so the payoff

1638
01:47:53,920 --> 01:47:55,400
would be

1639
01:47:58,380 --> 01:48:02,520
x 1 y 1 that would that would account for the fraction of the time

1640
01:48:02,520 --> 01:48:06,040
the fraction of the time that that that we have a choice of X 1

1641
01:48:06,040 --> 01:48:10,040
and Y 1 times the war that you pay and then 1 of the other

1642
01:48:10,040 --> 01:48:14,460
terms well there's a to move from X 1 right

1643
01:48:15,100 --> 01:48:20,220
the payoff of 2 workers in the fraction x 1 y 2

1644
01:48:20,440 --> 01:48:25,710
and the payoff of one's occurs in the fraction x to y 1 and a

1645
01:48:25,800 --> 01:48:30,480
payoff of 7 occurs in the fraction X 2 Y 2 and I'd like to

1646
01:48:30,480 --> 01:48:32,600
have a nice

1647
01:48:32,620 --> 01:48:36,170
the mice matrix form for that

1648
01:48:37,860 --> 01:48:40,340
and I think it would be just

1649
01:48:40,370 --> 01:48:47,410
Y transpose A X and I can I write that wiped that's why 1 right

1650
01:48:48,120 --> 01:48:50,290
multiplying the

1651
01:48:50,360 --> 01:48:58,440
2 1 7 over know multiple about delegates X X transpose wives and as I

1652
01:48:58,440 --> 01:49:05,750
better get x choosing rose have to multiply the rows and these have to multiply

1653
01:49:05,750 --> 01:49:08,150
the call

1654
01:49:09,100 --> 01:49:13,290
is that right that if I do them multiplication X 1 multiply the foreign the

1655
01:49:13,300 --> 01:49:17,550
Y 1 X 1 multiply the 2 and the wife to not get the 4

1656
01:49:17,550 --> 01:49:24,030
terms and that's the and just getting a nice notation

1657
01:49:26,940 --> 01:49:30,240
so what is the job of the job of law

1658
01:49:35,640 --> 01:49:37,890
the person who's choosing the rows

1659
01:49:37,990 --> 01:49:43,320
what is the person is going to payoff so he's trying to maximize the place

1660
01:49:43,510 --> 01:49:47,440
so maximize this payoff

1661
01:49:47,460 --> 01:49:49,650
X transpose A 1

1662
01:49:56,980 --> 01:50:02,370
which you in choose that students you economists say it in words

1663
01:50:03,700 --> 01:50:07,790
are you more work to choose

1664
01:50:08,360 --> 01:50:13,290
here is is choosing there's his 0 0

1665
01:50:17,470 --> 01:50:20,250
maximize the payoff

1666
01:50:20,500 --> 01:50:23,820
X transpose A what

1667
01:50:31,030 --> 01:50:33,120
but now

1668
01:50:33,130 --> 01:50:36,130
and of course the constraint that is

1669
01:50:36,420 --> 01:50:43,720
it is fractions should that the 1 that's clear but is what's really constraining in

1670
01:50:45,150 --> 01:50:47,630
what is and this what is he actually

1671
01:50:52,130 --> 01:50:55,270
when he chooses the next what will

1672
01:50:57,900 --> 01:51:00,480
because after a year 2

1673
01:51:01,000 --> 01:51:05,940
Y is going to notice what those fractions arming and the thing about the big

1674
01:51:05,940 --> 01:51:13,980
picture again we we decided that you have to decide on fractions and randomized

1675
01:51:13,990 --> 01:51:20,620
but after a thousand 2000 million plays that x is going to be known to

1676
01:51:20,640 --> 01:51:22,200
why is

1677
01:51:23,270 --> 01:51:28,940
pretty quite closely what the fractions are so there should be known otherwise so what

1678
01:51:28,940 --> 01:51:34,110
will we do know is that once that's known to why what would why then

1679
01:51:34,140 --> 01:51:38,770
do this season and the common choice of columns

1680
01:51:39,050 --> 01:51:41,680
would minimized

1681
01:51:42,500 --> 01:51:47,600
yeah so why is gonna minimize show

1682
01:51:47,680 --> 01:51:55,290
so he has maximizes this but but

1683
01:51:55,550 --> 01:52:00,160
but has to recognize that why is it then the show you what's up here

1684
01:52:01,020 --> 01:52:05,800
it at the old 1 of them is trying to maximize over all the axis

1685
01:52:05,800 --> 01:52:14,160
is the minimum over the is of the payoff and the other is trying to

1686
01:52:14,160 --> 01:52:19,160
save money is trying to minimize the otherwise but as the realize that whatever you

1687
01:52:19,160 --> 01:52:22,940
when one has a set of pairs chrome it's one of the properties has to

1688
01:52:22,940 --> 01:52:24,720
go to one side one to the other

1689
01:52:24,740 --> 01:52:31,080
that itself is in principle also an error prone mechanism or error prone process it

1690
01:52:31,210 --> 01:52:32,980
mistakes could be made

1691
01:52:32,990 --> 01:52:38,770
and indeed in cancer cells where many of these processes down sometimes one has both

1692
01:52:38,770 --> 01:52:42,740
chrome and it's going to one or the other side and as you can into

1693
01:52:42,740 --> 01:52:48,770
it from that that leads obviously to disruption of the normal make-up of the chromosomes

1694
01:52:48,770 --> 01:52:54,190
that are eventually allocated to each of the two daughter cells in fact this allocation

1695
01:52:54,190 --> 01:53:00,280
happens here t phase the last of the four major sub phases of mitosis here

1696
01:53:00,280 --> 01:53:01,850
you see the what's happened

1697
01:53:01,870 --> 01:53:05,590
is that these properties have now been pulled apart and the moment that they are

1698
01:53:05,590 --> 01:53:10,630
pulled apart no longer paired up one with the other they now are recognised once

1699
01:53:10,630 --> 01:53:16,090
again to be card-carrying chromosomes so now you here you see the nomenclature is change

1700
01:53:16,130 --> 01:53:17,640
now the chromosomes

1701
01:53:17,650 --> 01:53:22,840
they're being pulled pulled apart obviously one wants an identical sets of chromosomes in both

1702
01:53:22,840 --> 01:53:23,980
daughter cells

1703
01:53:24,000 --> 01:53:25,280
and once they

1704
01:53:25,300 --> 01:53:28,820
allocated to the two future daughter cells

1705
01:53:28,830 --> 01:53:35,370
the entire mitotic spindle dissolves and as you can imagine there's a reef formation as

1706
01:53:35,370 --> 01:53:39,050
indicated here schematically and not very clearly

1707
01:53:39,100 --> 01:53:40,440
in the nuclear membrane

1708
01:53:40,500 --> 01:53:46,060
now the whole cell is reconstructed and now each of the two daughter cells is

1709
01:53:46,060 --> 01:53:49,600
able in principle to split off one from the other and to go off on

1710
01:53:49,600 --> 01:53:51,260
his merry way

1711
01:53:51,270 --> 01:53:54,490
and this looks like a really neat process and

1712
01:53:54,500 --> 01:53:59,530
in some eukaryotic cells it happens much more rapidly than twenty four hours that i

1713
01:53:59,530 --> 01:54:04,480
just indicated to you there are indications that in some lymphocyte populations it only takes

1714
01:54:04,480 --> 01:54:06,220
three or four hours

1715
01:54:06,240 --> 01:54:13,440
and some early embryonic cell populations where there's absolutely frenetic pace of cell growth and

1716
01:54:14,610 --> 01:54:18,790
it may happen every thirty minutes rather than the twenty four hours i just talked

1717
01:54:18,790 --> 01:54:23,230
about and you'll say also what that's who cares about that but thirty minutes for

1718
01:54:23,230 --> 01:54:25,020
replicating entire

1719
01:54:25,030 --> 01:54:28,900
six point four billion bases in DNA

1720
01:54:28,910 --> 01:54:33,970
and then allocating into two daughter cells is actually quite an achievement and we don't

1721
01:54:33,970 --> 01:54:35,160
really understand

1722
01:54:35,170 --> 01:54:36,880
how that happens

1723
01:54:36,890 --> 01:54:41,570
i've talked to implicitly about the process of cell growth and division

1724
01:54:41,620 --> 01:54:46,010
and what i mean to say in more detail about that is the following after

1725
01:54:46,010 --> 01:54:51,270
one gets these two initial daughter cells they're obviously only half the size of the

1726
01:54:51,270 --> 01:54:56,610
previously existing mother cell and therefore what must happen in the subsequent cell cycle

1727
01:54:56,660 --> 01:55:01,330
is that each of these daughter cells must actually physically grow in size so that

1728
01:55:01,330 --> 01:55:04,410
once again becomes a big momma over here

1729
01:55:04,430 --> 01:55:06,010
after the next cell cycle

1730
01:55:06,030 --> 01:55:08,670
and so that growth begins immediately

1731
01:55:08,680 --> 01:55:13,240
and much of it occurs just through the generation of new sets of riva songs

1732
01:55:13,290 --> 01:55:20,280
new proteins membranes in the cell all the complex constituents himself need to be duplicated

1733
01:55:20,280 --> 01:55:25,500
for the next cell cycle including obviously all of these organelles the small structures in

1734
01:55:25,500 --> 01:55:29,030
the cytoplasm and including indeed the mitochondria

1735
01:55:29,050 --> 01:55:33,870
so imagine now the complexity of this because not only is the eukaryotic cell is

1736
01:55:33,870 --> 01:55:41,050
so complex but its entire contents must be faithfully replicated during the subsequent cell cycle

1737
01:55:41,190 --> 01:55:47,270
and that obviously implies the intervention the involvement of very complex control mechanisms about which

1738
01:55:47,270 --> 01:55:50,220
we understand almost nothing

1739
01:55:51,760 --> 01:55:57,190
how let's get back to this from on because what i've been talking about over

1740
01:55:57,190 --> 01:56:01,760
the last sixty minutes is simply mitosis the m phase here

1741
01:56:01,770 --> 01:56:07,690
in fact in many of these early embryonic cell cycles

1742
01:56:07,700 --> 01:56:11,850
what happens is that cells from face directly into s phase

1743
01:56:11,860 --> 01:56:16,150
and from face to work directly in the and in other words they don't indulge

1744
01:56:16,150 --> 01:56:17,810
themselves in a period

1745
01:56:17,820 --> 01:56:21,920
over here long period in some cultures million cells this can be twelve or fourteen

1746
01:56:21,920 --> 01:56:25,160
hours of getting set getting prepared

1747
01:56:25,210 --> 01:56:26,780
for DNA replication

1748
01:56:26,790 --> 01:56:31,920
similarly after cells have replicated their DNA and as we just said for example

1749
01:56:31,970 --> 01:56:38,200
converted one chromosome into two paired incremented after they get through as face also another

1750
01:56:38,200 --> 01:56:43,000
for five hours most cultured mammalian cells before they go back in m phase these

1751
01:56:43,000 --> 01:56:44,620
two gap periods

1752
01:56:44,670 --> 01:56:50,470
well how do we actually know how long to these gaps takes will as usual

1753
01:56:50,480 --> 01:56:53,300
i'm glad i asked that question

1754
01:56:53,310 --> 01:56:55,760
and one way we can do so is the following

1755
01:56:55,830 --> 01:57:00,320
what we can do is

1756
01:57:00,320 --> 01:57:10,470
and here appears in well her hair braided into wrapped around her head fanciful virginal

1757
01:57:11,050 --> 01:57:16,290
kindly safely out of fashion full of

1758
01:57:16,300 --> 01:57:21,180
a kind of civic virtue the embodiment of a certain kind of popular idea of

1759
01:57:21,180 --> 01:57:22,550
poetry you

1760
01:57:22,570 --> 01:57:25,820
you can read it but there's a kind of stamp of approval here from the

1761
01:57:25,820 --> 01:57:27,950
governor nelson rockefeller

1762
01:57:27,980 --> 01:57:34,380
think of how far away this is from ezra pound in saint elizabeth's hospital

1763
01:57:34,380 --> 01:57:37,990
this is another image of modern poetry

1764
01:57:38,040 --> 01:57:42,580
but more hair was not always done up

1765
01:57:42,590 --> 01:57:51,080
this is the image of a child also named mary more with delicious prodigious blocks

1766
01:57:51,100 --> 01:57:58,810
it reveals maybe a little bit of the power and extravagance and glory that you

1767
01:57:59,720 --> 01:58:06,800
in her poems but that she preferred always to restrain and bind in control

1768
01:58:06,800 --> 01:58:10,330
in extraordinary ways

1769
01:58:10,380 --> 01:58:13,100
not always to hide

1770
01:58:13,100 --> 01:58:16,890
one of the enduring works

1771
01:58:16,910 --> 01:58:20,090
written in nineteen twenty two

1772
01:58:20,340 --> 01:58:26,840
the amazing year that the wasteland and ulises appeared in the criterion started his publications

1773
01:58:26,850 --> 01:58:33,000
one of the most amazing works is a merrie morris home called poetry

1774
01:58:33,020 --> 01:58:36,790
you've got a sample of it on your hand

1775
01:58:38,920 --> 01:58:41,340
revised your palms

1776
01:58:41,380 --> 01:58:45,200
just the same way she ended up finding her hair

1777
01:58:45,230 --> 01:58:49,420
republished this palm eventually in short form

1778
01:58:49,440 --> 01:58:51,040
very short

1779
01:58:51,080 --> 01:58:55,090
we're three pages were reduced to

1780
01:58:55,130 --> 01:58:56,670
two sentences

1781
01:58:56,690 --> 01:58:59,110
the first two sentences UCI two

1782
01:58:59,120 --> 01:59:00,880
dislike it

1783
01:59:00,900 --> 01:59:04,670
there are things important beyond all fill

1784
01:59:04,690 --> 01:59:08,490
reading it however with the perfect contempt for it

1785
01:59:08,550 --> 01:59:11,160
one discovers in it after all

1786
01:59:11,180 --> 01:59:12,350
a place

1787
01:59:12,390 --> 01:59:14,660
for the genuine

1788
01:59:14,710 --> 01:59:18,870
some of what she cut out of the palm coast cut out of its later

1789
01:59:20,330 --> 01:59:23,950
is the list of what she had in mind is the genuine as examples of

1790
01:59:23,950 --> 01:59:29,650
it which is the first quotation there again on your hand out the back holding

1791
01:59:29,650 --> 01:59:34,030
on upside down and so on a flea

1792
01:59:34,050 --> 01:59:36,940
the baseball fan the statistician

1793
01:59:37,000 --> 01:59:43,600
nor is it valid to discriminate against business documents and schoolbooks

1794
01:59:43,640 --> 01:59:45,280
all of these phenomena

1795
01:59:45,280 --> 01:59:47,540
are important

1796
01:59:47,590 --> 01:59:50,430
the drive to include the world

1797
01:59:50,750 --> 01:59:54,750
more is on the response claim for poetry

1798
01:59:54,850 --> 01:59:59,790
all the subjects that she mentions here and indeed many many more

1799
01:59:59,810 --> 02:00:01,870
all these are new

1800
02:00:01,880 --> 02:00:06,960
modern subjects because they represent dimensions of experience

1801
02:00:07,000 --> 02:00:09,140
formally excluded from the

1802
02:00:09,160 --> 02:00:12,370
elevated idealised discourse

1803
02:00:12,370 --> 02:00:13,850
it is poetry

1804
02:00:13,900 --> 02:00:16,730
dimensions of experience excluded as

1805
02:00:18,620 --> 02:00:26,470
more is quoting here in that phrase business documents and schoolbooks as she tells us

1806
02:00:26,470 --> 02:00:28,420
from tolstoy

1807
02:00:28,440 --> 02:00:30,100
prose writer

1808
02:00:30,110 --> 02:00:36,040
but it goes further than tolstoy in her commitment to the seemingly non poetic she

1809
02:00:36,040 --> 02:00:42,940
will not only include tolstoy's prose she will not even discriminates against business documents and

1810
02:00:44,860 --> 02:00:51,000
more exemplifies in this way a kind key aspect of modern poetry

1811
02:00:55,000 --> 02:01:03,520
it will to mix many kinds of materials and discourses to make poetry reach out

1812
02:01:03,520 --> 02:01:10,920
from the rarefied and limited domain of the poetic two

1813
02:01:10,940 --> 02:01:14,980
keep including more and more of the world

1814
02:01:15,020 --> 02:01:19,520
the next quotation on your hand

1815
02:01:19,520 --> 02:01:23,560
this is another example of this

1816
02:01:23,570 --> 02:01:24,930
i want to sing for you

1817
02:01:24,960 --> 02:01:31,350
or or give you my italian but this this famous lines london bridge is falling

1818
02:01:31,350 --> 02:01:33,880
down falling down

1819
02:01:33,880 --> 02:01:35,070
falling down

1820
02:01:35,080 --> 02:01:37,780
and so on these

1821
02:01:37,820 --> 02:01:40,520
come from the conclusion to the waste land

1822
02:01:41,850 --> 02:01:45,470
they thrust together different

1823
02:01:45,520 --> 02:01:53,540
different text different languages writing from different historical periods all their compressed in that remarkable

1824
02:01:54,120 --> 02:01:58,360
song that concludes the poem

1825
02:01:58,370 --> 02:02:00,370
in the next quotation

1826
02:02:00,380 --> 02:02:03,020
elliot tells us that

1827
02:02:03,040 --> 02:02:07,570
a various and complex civilizations such as ours produces

1828
02:02:07,580 --> 02:02:08,500
he says

1829
02:02:08,530 --> 02:02:12,680
various and complex results as if inevitably

1830
02:02:12,700 --> 02:02:15,780
unless we think that there's anything particularly

1831
02:02:15,820 --> 02:02:23,200
forced or outlandish or willful about his remarkable

1832
02:02:23,230 --> 02:02:29,500
poetry in lines such as those i just quoted frame

1833
02:02:29,550 --> 02:02:35,430
well it was there in that essay on the metaphysical poets i'm quoting from defending

1834
02:02:35,430 --> 02:02:37,310
as necessary

1835
02:02:37,320 --> 02:02:43,150
what is the primary characteristic not only of his own poetry but really of modern

1836
02:02:43,150 --> 02:02:45,570
poetry generally what is

1837
02:02:45,610 --> 02:02:49,270
often called its difficulty

1838
02:02:49,280 --> 02:02:50,960
whatever else it may be

1839
02:02:51,000 --> 02:02:54,630
everyone's always agree that modern poetry is difficult

1840
02:02:54,640 --> 02:02:56,580
you will probably two

1841
02:02:56,610 --> 02:03:02,570
by difficult it is meant i think well first of all that is in some

1842
02:03:02,570 --> 02:03:06,580
sense set apart from common speech

1843
02:03:07,300 --> 02:03:12,410
a specialized and highly self-conscious use of language

1844
02:03:12,430 --> 02:03:16,880
well it would go further and say that there is no common

1845
02:03:16,900 --> 02:03:20,120
form of modern speech and that's the problem

1846
02:03:20,200 --> 02:03:24,310
according to elliot the modern world lacks the centre a kind of a set of

1847
02:03:24,310 --> 02:03:28,730
collective beliefs and commitments that would

1848
02:03:28,750 --> 02:03:31,880
enable communication between us

1849
02:03:31,900 --> 02:03:34,530
modernity for elliot as for more

1850
02:03:34,540 --> 02:03:39,310
as for pound is marked by a profusion of languages

1851
02:03:39,330 --> 02:03:45,630
both national languages such as french or russian which turn up in the wasteland

1852
02:03:45,640 --> 02:03:53,570
also a bewildering array of specialized types of discourse technicals honours varieties of speech business

1853
02:03:53,570 --> 02:03:55,640
documents and schoolbooks

1854
02:03:55,640 --> 02:03:59,760
the basic gist of it i think is still very relevant and some of you

1855
02:04:00,220 --> 02:04:03,990
who saw the talk of hot lips and actually worldview reminded of what he did

1856
02:04:03,990 --> 02:04:10,760
in two thousand seven we also had genetic programming essentially plus regularizer which enforced short

1857
02:04:10,760 --> 02:04:14,530
codes as opposed to long collins and then

1858
02:04:14,620 --> 02:04:17,860
i think during his talk he said

1859
02:04:17,870 --> 02:04:21,950
the crucial thing was that you had different models for certain parts of the space

1860
02:04:21,950 --> 02:04:22,780
and then

1861
02:04:24,490 --> 02:04:29,550
focused on those where there are different opinions of these models as opposed to

1862
02:04:29,570 --> 02:04:34,070
looking at the other parts of the state space where there was no different opinions

1863
02:04:34,090 --> 02:04:36,950
so that's the very simple

1864
02:04:36,970 --> 02:04:40,930
that was two thousand two and and what you can be doing is we are

1865
02:04:40,930 --> 02:04:45,120
using just three d simulation of the

1866
02:04:45,140 --> 02:04:46,990
of the icub robot

1867
02:04:46,990 --> 02:04:50,670
the icub robot to be like robots which has a face like that of a

1868
02:04:50,670 --> 02:04:55,870
stereo camera on top and then we have a three d simulation of the icon

1869
02:04:56,030 --> 02:05:01,570
and using stereo camera you can improve this east simulation which you can use it

1870
02:05:01,590 --> 02:05:06,870
to predict but just incorporating the stuff that the the camera sees here using some

1871
02:05:06,870 --> 02:05:12,840
vision algorithm so you suddenly get little objects in the environment of the cycle and

1872
02:05:12,870 --> 02:05:17,910
and by having these objects here the simulation becomes more complex which means you need

1873
02:05:17,910 --> 02:05:21,160
more bits two stripes simulation however

1874
02:05:21,160 --> 02:05:26,760
it also becomes more powerful as a predictor it become it gets more predictive power

1875
02:05:27,030 --> 02:05:31,120
he has certainly you can for example predict that if you to move your hands

1876
02:05:31,120 --> 02:05:36,590
like that your eyes legs and then you will see that in that

1877
02:05:36,640 --> 02:05:41,570
the object is now in there in the simulation and now again you can use

1878
02:05:41,570 --> 02:05:45,050
the same principle you look at the number of bits used to describe the history

1879
02:05:45,050 --> 02:05:48,680
so far which is essentially the number of bits in the fall of the polygons

1880
02:05:48,680 --> 02:05:54,530
in the simulation plus the extra bits you need to encode the deviations of the

1881
02:05:54,530 --> 02:05:59,080
entire street you're trying to learn new motor skills just like a little baby we

1882
02:05:59,080 --> 02:06:02,010
have little baby here which over time

1883
02:06:02,030 --> 02:06:06,780
focuses focuses its attention on those parts

1884
02:06:06,800 --> 02:06:10,200
of the one which can make learning progress which in the beginning will be very

1885
02:06:10,200 --> 02:06:15,220
stupid simple things so it will be very limited scientist trying just doing very simple

1886
02:06:15,220 --> 02:06:16,840
experiments as opposed to

1887
02:06:18,030 --> 02:06:20,700
more complex patterns that lead to

1888
02:06:20,720 --> 02:06:25,300
in science like the general theory of relativity however the principle i think is only

1889
02:06:25,320 --> 02:06:29,930
that's all the same thing that led to the general theory of relativity

1890
02:06:29,950 --> 02:06:33,740
and the fun that you have in motor learning motor skills

1891
02:06:33,760 --> 02:06:37,780
that is just

1892
02:06:37,780 --> 02:06:42,820
well i mean why should anybody why should anybody learn juggling

1893
02:06:42,840 --> 02:06:45,390
it's useless in the however it's fine

1894
02:06:45,390 --> 02:06:50,550
because it's very and you get a lot of everyone just by creating this new

1895
02:06:50,570 --> 02:06:53,970
sequence which is

1896
02:06:55,200 --> 02:07:00,030
because it leads to a new type of regular pattern for your compressor for prediction

1897
02:07:00,030 --> 02:07:04,510
machine such that you can certainly save a lot of bits because it's

1898
02:07:04,640 --> 02:07:08,370
it's new to you pattern recognizer which first need to look at this and then

1899
02:07:08,370 --> 02:07:12,780
shrinks it down and that's how you get progress and we have now this european

1900
02:07:12,780 --> 02:07:20,590
programme project which is called intrinsically motivated cumulatively line once don't ask me who invented

1901
02:07:20,600 --> 02:07:25,970
the acrimony i'm clever without but that's what the name of the project is and

1902
02:07:25,970 --> 02:07:29,720
i hope i can keep you updated on the progress of so i don't have

1903
02:07:29,720 --> 02:07:35,340
time to talk about their low complexity what maximizes themselves i don't have time to

1904
02:07:35,340 --> 02:07:41,950
show you low complexity we can facts programmed by universal before you transformation based languages

1905
02:07:42,280 --> 02:07:45,220
i don't even have shined time to show you movies here

1906
02:07:45,240 --> 02:07:47,200
instead i should

1907
02:07:47,200 --> 02:07:52,620
instead i should just focus on the take-home message to take on messages

1908
02:07:52,640 --> 02:07:54,740
that for

1909
02:07:54,760 --> 02:08:00,720
intrinsic reward is the change of the number of bits you need to encode data

1910
02:08:00,720 --> 02:08:02,030
novel patterns

1911
02:08:02,050 --> 02:08:06,430
and you measured by looking at how many bits can you before and after learning

1912
02:08:06,450 --> 02:08:12,070
and you take the time into account the time to contact you automatically take into

1913
02:08:12,070 --> 02:08:16,360
account by having a limited compression machine which is only so good at discovering certain

1914
02:08:16,360 --> 02:08:21,200
patterns and is not good at is coming out of other patterns even if additional

1915
02:08:21,200 --> 02:08:26,070
patterns and and and the rest of it is down because you still have the

1916
02:08:26,070 --> 02:08:31,340
standard itself towards that you have in addition to the intrinsic reward and you

1917
02:08:31,370 --> 02:08:37,180
you have some evolution and i have more reinforcement learning algorithm or other programs such

1918
02:08:37,180 --> 02:08:41,320
techniques for maximizing the future expected reward

1919
02:08:41,320 --> 02:08:46,430
and i believe playing explains all the essential

1920
02:08:46,450 --> 02:08:50,720
things that are defining our behavior like attention why do we look here

1921
02:08:50,760 --> 02:08:55,780
i'm not science in general which is just very focused type of attention on various

1922
02:08:55,780 --> 02:09:00,570
very selective experiments where you can then formally named down what's happening and you can

1923
02:09:00,570 --> 02:09:05,570
formally down here compression progress but also the music as we

1924
02:09:06,320 --> 02:09:09,140
as we talked about

1925
02:09:09,180 --> 02:09:14,300
i wish to thank the organisers for doing a great job and

1926
02:09:14,300 --> 02:09:18,590
and also for the czech which i'm going to invest into the education of my

1927
02:09:20,260 --> 02:09:24,720
i wish to thank my mom and my dad without whom all of this wouldn't

1928
02:09:24,720 --> 02:09:26,590
even have been possible

1929
02:09:27,970 --> 02:09:30,680
and i wish i wish to thank my kids without whom


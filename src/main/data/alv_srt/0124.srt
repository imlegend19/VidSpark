1
00:00:00,000 --> 00:00:04,720
to the thirty second different patterns available to me to map to whatever subset of

2
00:00:04,720 --> 00:00:08,750
the full integer range i want the easiest thing to do is just go from

3
00:00:08,750 --> 00:00:12,630
to the negative thirty first feature the positive thirty first minus one

4
00:00:12,640 --> 00:00:16,250
OK zero in the middle that's why breaks it symmetrical a little bit

5
00:00:16,260 --> 00:00:20,250
when i go

6
00:00:20,380 --> 00:00:27,120
concern myself with floats idea probably more used to doubles but this just a small

7
00:00:27,120 --> 00:00:30,060
small version of doubles

8
00:00:30,070 --> 00:00:31,470
i have

9
00:00:31,470 --> 00:00:34,090
four bytes available to me to represent

10
00:00:34,120 --> 00:00:39,020
floating point numbers integers with that small part following anyway i want to do this

11
00:00:39,020 --> 00:00:42,410
is way really works for me just invent an idea here

12
00:00:42,430 --> 00:00:44,560
pretend this is how it works

13
00:00:46,000 --> 00:00:50,770
but i strongly boxes yet

14
00:00:50,790 --> 00:00:52,170
i could do

15
00:00:52,190 --> 00:00:58,330
let's say i have assigned it all represent that appears cluster minus

16
00:00:58,340 --> 00:01:01,370
and if i have thirty two bits you by default

17
00:01:01,380 --> 00:01:09,030
think about being some contribution to the thirtieth two the twenty nine ground career contribution

18
00:01:09,030 --> 00:01:13,420
of two to zero and is describing all the things that can adopt zeros or

19
00:01:13,420 --> 00:01:15,850
ones to represent some numbers

20
00:01:15,860 --> 00:01:19,380
OK but i want to close to be able to have fractional parts to be

21
00:01:19,380 --> 00:01:24,000
moving the fractional direction and so you know what what my sacrifice

22
00:01:24,000 --> 00:01:25,610
to the thirtieth

23
00:01:28,750 --> 00:01:36,630
and like the one that actually the contribution of the negative first

24
00:01:36,650 --> 00:01:39,520
i'm just making this up i wanna make it up opposite the weight of the

25
00:01:39,520 --> 00:01:43,810
last seven times topics but i'm moving table will really be the that the representation

26
00:01:43,810 --> 00:01:46,170
for floating point numbers

27
00:01:46,190 --> 00:01:49,130
if i happen to have thirty two bits right here

28
00:01:52,040 --> 00:01:54,960
i lay down this right here

29
00:01:55,880 --> 00:02:01,920
that's not the number seven hundred number number number fifteen anymore now it's number seven

30
00:02:01,920 --> 00:02:03,750
point five

31
00:02:03,790 --> 00:02:05,230
so it makes sense

32
00:02:05,250 --> 00:02:09,040
OK well thought-out very useful if now all you have are integers and half integers

33
00:02:09,560 --> 00:02:11,960
so what i'm going to do

34
00:02:11,980 --> 00:02:16,460
as i'm going to stop trying things about that britain was just assume that rather

35
00:02:16,460 --> 00:02:20,810
than the last bit being contrary into the negative first let me let that be

36
00:02:20,810 --> 00:02:26,250
a contribution to the first and that that the convolution of two the negative two

37
00:02:26,290 --> 00:02:29,250
so now i can go down quarter fractions

38
00:02:29,310 --> 00:02:30,630
does that make sense

39
00:02:30,630 --> 00:02:32,210
what i could do

40
00:02:32,230 --> 00:02:38,440
as i could make this right here because two zero

41
00:02:38,440 --> 00:02:39,840
the negative ones

42
00:02:39,860 --> 00:02:43,290
two the negative two three four five six seven eight

43
00:02:43,330 --> 00:02:46,480
two the ninety nine

44
00:02:46,540 --> 00:02:48,520
and if i wanted to represent

45
00:02:49,730 --> 00:02:53,110
i'm not going to run works on the shoulders of another this part would be

46
00:02:53,860 --> 00:02:57,960
then i would use the remaining

47
00:02:57,980 --> 00:03:01,360
nine bits that are available to me

48
00:03:01,380 --> 00:03:06,380
OK to do a good job using two contributions to the negative first into thirty

49
00:03:06,400 --> 00:03:11,460
two seventh to close as possible to point one four one five whatever is

50
00:03:12,360 --> 00:03:13,880
make sense of

51
00:03:13,920 --> 00:03:18,090
it is actually point to remember that because using a finite amount of memory you're

52
00:03:18,090 --> 00:03:19,840
not going to do a proper job

53
00:03:19,840 --> 00:03:24,270
cut representing all numbers in the infinite and infinitely dense

54
00:03:24,500 --> 00:03:25,790
the real number domain

55
00:03:26,500 --> 00:03:30,290
but you just assume that there is enough bits dedicated to fractional parts that you

56
00:03:30,290 --> 00:03:34,340
can come close enough well without not really impacting we're trying to do

57
00:03:34,360 --> 00:03:37,380
OK i put up four at some places are something that just looks like a

58
00:03:38,480 --> 00:03:40,230
OK that makes sense

59
00:03:40,330 --> 00:03:43,310
it turns out if i do it that way in addition

60
00:03:43,750 --> 00:03:48,270
works fine so i had two point five contributions in ripples to give me a

61
00:03:48,270 --> 00:03:51,710
one night carrier one it just works exactly the same way

62
00:03:51,750 --> 00:03:53,420
that make sense

63
00:03:53,440 --> 00:03:58,460
OK it turns out that this is not the way it represented but it is

64
00:03:58,460 --> 00:04:02,090
technically original way to do it and when they came up with the standard for

65
00:04:02,090 --> 00:04:06,170
representing forty four numbers they could have gone this way they just elected not to

66
00:04:06,170 --> 00:04:10,540
so what do now is going to show you what it really does look like

67
00:04:10,540 --> 00:04:15,920
it's very weird thing whenever they can interpret the thirty two bit pattern anyway they

68
00:04:15,920 --> 00:04:19,840
want to as long as the protocols clearance done exactly the same way every single

69
00:04:20,840 --> 00:04:24,790
so could i attended a draw figure

70
00:04:24,810 --> 00:04:25,960
and leave it

71
00:04:26,250 --> 00:04:28,900
organiser for rectangle

72
00:04:28,940 --> 00:04:31,340
because i'm not subdivided by perfectly

73
00:04:31,360 --> 00:04:34,150
i'm going to make this

74
00:04:34,230 --> 00:04:38,360
assigned i you want to represent

75
00:04:38,400 --> 00:04:42,290
i want negative numbers and positive numbers are floating point to have an equal shot

76
00:04:42,290 --> 00:04:44,460
of being represented kind

77
00:04:44,480 --> 00:04:48,630
that's one of the thirty two bits

78
00:04:48,650 --> 00:04:51,190
to make sense

79
00:04:51,190 --> 00:04:52,250
the next

80
00:04:52,270 --> 00:04:53,520
eight that's

81
00:04:53,960 --> 00:04:59,110
are actually taken to be a magnitude

82
00:05:02,090 --> 00:05:06,540
i said that we should discard an unsigned integer

83
00:05:06,630 --> 00:05:09,380
from here

84
00:05:11,440 --> 00:05:14,750
and the remaining

85
00:05:14,750 --> 00:05:17,530
unfortunately it really doesn't work unless

86
00:05:17,950 --> 00:05:19,390
the images

87
00:05:19,450 --> 00:05:22,330
very simple so for example in this image

88
00:05:23,030 --> 00:05:25,880
you have these sort of two

89
00:05:25,880 --> 00:05:32,000
triangles and upper triangle lower triangle well separated by boundary except for this weakness and

90
00:05:32,110 --> 00:05:34,520
weakness is sufficient to

91
00:05:34,530 --> 00:05:40,570
because a garbage result from from region growing likewise if you have a black circle

92
00:05:40,570 --> 00:05:42,910
like background

93
00:05:42,940 --> 00:05:47,840
you can get fine segmentation with region growing but once you add noise

94
00:05:47,890 --> 00:05:51,130
you're in all sorts of problems even small amount

95
00:05:51,140 --> 00:05:58,630
more recently the graph cuts approach has been developed for seeded segmentation

96
00:05:58,680 --> 00:06:03,080
it's great it's fast has a probabilistic interpretation

97
00:06:03,700 --> 00:06:08,130
but there are some problems with the for for example

98
00:06:09,120 --> 00:06:13,820
the goal of graph cuts is to find the minimum boundary

99
00:06:13,830 --> 00:06:15,970
so for example with the same

100
00:06:16,000 --> 00:06:17,870
image so we looked at what the

101
00:06:17,880 --> 00:06:19,820
upper triangle the lower triangle

102
00:06:19,830 --> 00:06:25,410
if you just input a small number of seats the minimum boundary separating blue from

103
00:06:25,410 --> 00:06:28,990
green or blue from red is just this little

104
00:06:29,030 --> 00:06:32,300
boundary surrounding the blue c

105
00:06:32,380 --> 00:06:34,550
if you have enough

106
00:06:34,560 --> 00:06:36,560
seeds in order to

107
00:06:37,030 --> 00:06:40,330
such that the surface area exceeds this weakness

108
00:06:40,350 --> 00:06:42,270
you can

109
00:06:42,330 --> 00:06:44,830
actually recover the weak boundary but

110
00:06:44,880 --> 00:06:47,860
when you have four connected lattice

111
00:06:47,890 --> 00:06:49,750
in particular you get these

112
00:06:49,760 --> 00:06:54,300
these metrication artifacts reason being that the cut going

113
00:06:54,330 --> 00:06:57,580
down over is the same as going over down

114
00:06:57,590 --> 00:07:00,080
or even going down diagonally

115
00:07:00,100 --> 00:07:01,840
and for connected graph

116
00:07:01,880 --> 00:07:05,640
this problem can be improved by adding more edges but that increases the complexity in

117
00:07:05,640 --> 00:07:07,900
the memory

118
00:07:07,940 --> 00:07:14,290
additionally with graph cuts you are somewhat limited to two labels you can have more

119
00:07:14,290 --> 00:07:15,870
labels but

120
00:07:15,880 --> 00:07:20,380
your ability to get an exact solution is erased when you have more than two

121
00:07:21,260 --> 00:07:24,600
so it it's

122
00:07:24,640 --> 00:07:28,740
into this gap that i introduced this random walker idea

123
00:07:30,000 --> 00:07:33,350
the idea was basically two

124
00:07:33,390 --> 00:07:40,900
capture the good properties of graph cuts segmentation algorithm overcoming these difficulties

125
00:07:41,900 --> 00:07:46,360
and now i'm going to go through it in detail starting with the the concept

126
00:07:48,550 --> 00:07:50,030
so given

127
00:07:50,050 --> 00:07:56,060
a set of seeds to indicate in this image of four objects green yellow red

128
00:07:56,060 --> 00:07:56,940
and blue

129
00:07:57,010 --> 00:07:58,910
the idea is

130
00:07:59,160 --> 00:08:00,660
we could ask

131
00:08:00,670 --> 00:08:02,780
and now we want to label every other pixel

132
00:08:02,940 --> 00:08:07,750
we can ask so for this pixel we want label it with one of these

133
00:08:09,670 --> 00:08:11,100
we could ask if we

134
00:08:11,150 --> 00:08:13,870
release the random walker from this pixel

135
00:08:14,080 --> 00:08:16,260
o to wander all of the image

136
00:08:16,260 --> 00:08:19,380
with some probability will first arrived at green

137
00:08:19,420 --> 00:08:21,760
some probability will first write yellow

138
00:08:23,800 --> 00:08:25,640
and then if we knew the probabilities

139
00:08:25,660 --> 00:08:29,330
we can assign this pixel to the colorful which is most likely to send random

140
00:08:30,430 --> 00:08:33,610
the impact of the image in this case

141
00:08:33,620 --> 00:08:39,630
is to affect the walk and tobias the walker to avoid crossing intensity gradients or

142
00:08:39,640 --> 00:08:41,300
some kind of feature gradient

143
00:08:41,360 --> 00:08:47,980
for those of you ruined by hollywood i put a little movie together

144
00:08:48,000 --> 00:08:51,990
if you have a wide circle of black background and you put to sea to

145
00:08:51,990 --> 00:08:56,760
blue and red one and you want to query this pixel

146
00:08:56,800 --> 00:09:01,680
he released this particles in brownian motion or random walk

147
00:09:01,690 --> 00:09:04,210
and you'll see that it may

148
00:09:04,220 --> 00:09:06,510
come against the boundary the circle

149
00:09:06,520 --> 00:09:09,370
i would be very unlikely to cross into it

150
00:09:09,510 --> 00:09:15,470
therefore eventually annulled it may take a very long time this walkers almost certainly

151
00:09:15,510 --> 00:09:18,610
going to arrive at red before arrives blue

152
00:09:18,650 --> 00:09:22,220
consequently this pixel will be labelled red

153
00:09:23,730 --> 00:09:26,430
you probably should have a feeling of this based on some of the other talks

154
00:09:26,430 --> 00:09:27,410
that we've seen

155
00:09:27,420 --> 00:09:31,120
but these probabilities can actually be computed analytically

156
00:09:31,130 --> 00:09:34,090
with an deterministically without any

157
00:09:34,100 --> 00:09:38,220
simulation of random walks any kind of money carling

158
00:09:38,230 --> 00:09:40,100
so just so we're clear about what

159
00:09:40,230 --> 00:09:42,000
the album is doing we input

160
00:09:43,150 --> 00:09:46,370
image with seeds to indicate

161
00:09:46,590 --> 00:09:48,300
we want for objects

162
00:09:48,360 --> 00:09:50,420
green red yellow and blue

163
00:09:50,510 --> 00:09:54,910
and then we would like to produce the labeling for every pixel

164
00:09:55,020 --> 00:09:57,480
of one of those four types

165
00:09:57,490 --> 00:10:00,420
so what we do is we compute the probability that each pixel

166
00:10:00,430 --> 00:10:02,360
send the random walker green

167
00:10:02,370 --> 00:10:05,280
first we compute the proper the

168
00:10:05,290 --> 00:10:08,150
probability for each pixel at its centre and market red

169
00:10:08,160 --> 00:10:13,030
first to yellow and then to blue and then we assign these labels based on

170
00:10:13,030 --> 00:10:14,250
whether or not

171
00:10:15,420 --> 00:10:17,220
we color the pixel with

172
00:10:17,230 --> 00:10:21,050
whichever label it's most likely to send random walk

173
00:10:26,230 --> 00:10:28,270
in practice it looks like this

174
00:10:28,670 --> 00:10:31,860
a user would input an image

175
00:10:31,870 --> 00:10:33,460
paint some seeds

176
00:10:33,540 --> 00:10:36,440
and then in real time you can iteratively

177
00:10:36,470 --> 00:10:38,490
calculate these probabilities

178
00:10:38,520 --> 00:10:40,190
this is the real time

179
00:10:40,210 --> 00:10:41,480
screen capture

180
00:10:41,490 --> 00:10:43,760
and the

181
00:10:43,770 --> 00:10:45,940
segmentation looks like this

182
00:10:45,960 --> 00:10:50,380
which can be corrected by adding more seeds decide

183
00:10:52,180 --> 00:10:56,170
that's the concept behind the organ but why random walks

184
00:10:56,330 --> 00:10:57,970
what's the value

185
00:10:57,980 --> 00:10:59,630
taking this approach over

186
00:10:59,640 --> 00:11:02,210
some other method for assigning labels

187
00:11:02,230 --> 00:11:04,310
and there are basically two

188
00:11:04,330 --> 00:11:08,760
reasons one is we boundary detection and the other is noise robustness

189
00:11:08,840 --> 00:11:11,210
so this

190
00:11:11,230 --> 00:11:14,880
it's hard to see here what this is supposed to show

191
00:11:14,900 --> 00:11:16,710
it is a solid

192
00:11:18,400 --> 00:11:22,490
and a solid circle except for a gap here

193
00:11:24,390 --> 00:11:26,260
is is missing

194
00:11:26,260 --> 00:11:28,560
and what i was trying to show

195
00:11:28,590 --> 00:11:32,180
it is if you were trying to label this pixel just on the other side

196
00:11:32,180 --> 00:11:33,170
of the gap

197
00:11:33,190 --> 00:11:35,340
new release the random walker there

198
00:11:35,500 --> 00:11:36,960
even though

199
00:11:36,970 --> 00:11:38,690
there's a gap in the

200
00:11:38,730 --> 00:11:40,390
random walker

201
00:11:40,400 --> 00:11:43,410
it is more likely to get inside the circle

202
00:11:43,420 --> 00:11:46,210
here than without the gap

203
00:11:46,230 --> 00:11:50,730
because of the motion of the random walk and the wiggling jiggling

204
00:11:50,770 --> 00:11:51,980
of the walker

205
00:11:51,990 --> 00:11:53,290
it's still

206
00:11:53,350 --> 00:11:54,970
more likely to

207
00:11:55,000 --> 00:11:59,400
arrive at the red sea than it is to get inside the circle to the

208
00:11:59,470 --> 00:12:01,620
and so

209
00:12:01,620 --> 00:12:05,870
with sampling so the idea is you always re-arranging variables so you only sample the

210
00:12:05,870 --> 00:12:07,620
low dimensional variables

211
00:12:07,670 --> 00:12:09,310
and then you integrate out

212
00:12:09,330 --> 00:12:10,400
the other ones

213
00:12:10,420 --> 00:12:12,140
in mapping that's what we do

214
00:12:12,160 --> 00:12:14,620
we only sample the location of the robot

215
00:12:14,640 --> 00:12:17,960
which is a six dimensions it's small thing

216
00:12:18,020 --> 00:12:23,140
and then the map which is this humungous or one thousand dimensional variable

217
00:12:23,190 --> 00:12:25,900
we integrate out analytically

218
00:12:25,960 --> 00:12:28,940
so there's no error introduced

219
00:12:29,080 --> 00:12:30,710
another application of this

220
00:12:30,730 --> 00:12:34,140
was quite popular especially when as was an english strawberries

221
00:12:34,170 --> 00:12:40,160
it was diagnosis where you have a continuous signal that describes how the

222
00:12:40,160 --> 00:12:42,210
you know internal states of the robot

223
00:12:42,270 --> 00:12:43,730
and then you have

224
00:12:43,790 --> 00:12:50,520
discrete signals which indicate like my left we'll is broken miraculous programs that whatever

225
00:12:50,560 --> 00:12:51,710
and then there's some

226
00:12:51,770 --> 00:12:54,330
observations of the robot makes

227
00:12:54,330 --> 00:12:58,000
like what it is with respect to this

228
00:12:59,250 --> 00:13:04,640
in the morning

229
00:13:06,080 --> 00:13:11,000
the type of models are what people will jump markov linear systems

230
00:13:11,000 --> 00:13:12,020
well you have

231
00:13:12,040 --> 00:13:17,040
a discrete distribution that tells you how the discrete states evolve over time

232
00:13:17,690 --> 00:13:19,560
let me just actually retrieve that

233
00:13:19,600 --> 00:13:22,210
so you have these continuous operations

234
00:13:22,270 --> 00:13:23,040
you have

235
00:13:23,100 --> 00:13:27,850
continuous internal states like your car you current voltages et cetera

236
00:13:27,870 --> 00:13:30,330
which are the states x xt

237
00:13:30,350 --> 00:13:32,830
which could be a very high dimensional vector

238
00:13:32,870 --> 00:13:37,920
and then you have these discrete states like you know my my will was that

239
00:13:37,920 --> 00:13:40,370
go on supporting evidence and so on

240
00:13:40,500 --> 00:13:44,560
and the goal is to come up with an estimate of the discrete state

241
00:13:45,390 --> 00:13:50,290
for example might try to diagnose with that i i have

242
00:13:50,420 --> 00:13:52,370
hard problem or not

243
00:13:53,250 --> 00:13:57,270
if i'm sitting on my if i'm just sitting here on my chair you looking

244
00:13:57,270 --> 00:13:58,690
at the support

245
00:13:58,710 --> 00:14:01,640
and my heart beating very fast

246
00:14:01,690 --> 00:14:04,620
then i probably want to diagnose and i have a hard problem

247
00:14:04,640 --> 00:14:07,870
if i happen to be catching waves there

248
00:14:07,920 --> 00:14:12,270
and my heart is beating faster and you probably have from so knowing the in

249
00:14:12,290 --> 00:14:15,190
terms of internal state

250
00:14:15,190 --> 00:14:21,520
no internal state like the heartbeat that you're trying to estimate from whatever environmental variables

251
00:14:21,540 --> 00:14:24,790
one predict and your chest helps to

252
00:14:24,810 --> 00:14:27,810
come up with the discrete state which in this case is

253
00:14:27,870 --> 00:14:34,460
yes i have a hard problem or no i don't

254
00:14:34,600 --> 00:14:35,670
and so

255
00:14:35,730 --> 00:14:38,540
that's how the system this model

256
00:14:38,600 --> 00:14:42,120
and in fact the same is used here for slam

257
00:14:42,140 --> 00:14:44,750
so you have these discrete states

258
00:14:44,770 --> 00:14:48,520
that he it could be in a state and slums that actually happens to be

259
00:14:48,520 --> 00:14:49,710
the location

260
00:14:49,890 --> 00:14:52,230
x happens to be the man

261
00:14:52,290 --> 00:14:54,370
and then you make observations

262
00:14:55,770 --> 00:14:59,290
we have a switching space because what happens you have a linear system of linear

263
00:14:59,290 --> 00:15:01,250
gaussians this system

264
00:15:01,270 --> 00:15:03,170
but the matrix is that you have

265
00:15:03,230 --> 00:15:05,140
the transition matrices

266
00:15:05,160 --> 00:15:08,230
depends on the variables that she

267
00:15:09,120 --> 00:15:13,310
it that is binary then you have two possible ways

268
00:15:13,330 --> 00:15:17,190
and one day might mean that the players running for another a means that the

269
00:15:17,210 --> 00:15:19,830
player running slow

270
00:15:20,500 --> 00:15:22,770
and then you need to be able to estimate

271
00:15:22,790 --> 00:15:25,270
x for both of those conditions

272
00:15:26,400 --> 00:15:27,480
the matrix

273
00:15:27,500 --> 00:15:31,900
the parameters are usually assumed to be known but there's sort of some ways some

274
00:15:31,900 --> 00:15:34,310
e ways of estimating these

275
00:15:37,540 --> 00:15:41,120
the naive algorithm would be to sample z

276
00:15:41,170 --> 00:15:46,420
the sample x and then to use the likelihood of a given accents

277
00:15:46,480 --> 00:15:51,060
first my part that not that the trivial particle filter

278
00:15:51,100 --> 00:15:54,420
and that's really bad because

279
00:15:54,560 --> 00:15:57,080
sampling from a very high dimensional space

280
00:15:57,100 --> 00:15:59,040
and you get into trouble

281
00:16:01,850 --> 00:16:05,960
what we try to do is exploit the conditional independencies that i mentioned before that

282
00:16:05,960 --> 00:16:08,980
if you have access not and not

283
00:16:09,000 --> 00:16:12,460
given the observations you can rewrite it

284
00:16:12,520 --> 00:16:15,580
in this form can pull the conditioning arguement

285
00:16:15,620 --> 00:16:18,100
and so on so that

286
00:16:18,120 --> 00:16:20,420
given the set

287
00:16:20,460 --> 00:16:24,020
and given the why it's possible to compute the y

288
00:16:24,060 --> 00:16:26,870
so all you have to do is to estimate

289
00:16:26,920 --> 00:16:28,670
p of z given one

290
00:16:28,670 --> 00:16:29,730
in particular

291
00:16:32,140 --> 00:16:35,580
how many of you have seen kalman filtering

292
00:16:35,580 --> 00:16:41,040
so common fault is what you do in this model when everything is calcium

293
00:16:41,080 --> 00:16:43,850
so common filters as an exact

294
00:16:43,870 --> 00:16:47,000
numerical so the analytic solution

295
00:16:48,190 --> 00:16:51,000
dynamic system when everything is gone

296
00:16:51,020 --> 00:16:53,160
linear and gas

297
00:16:53,190 --> 00:16:57,590
so in this case the reason why things are not linear because of that he

298
00:16:59,000 --> 00:17:00,690
but if we knew zt

299
00:17:00,750 --> 00:17:03,250
if you knew city then you would know a and c

300
00:17:03,270 --> 00:17:06,770
and in your back to only having these two equations so you have a linear

301
00:17:06,770 --> 00:17:08,210
constant system

302
00:17:08,230 --> 00:17:09,420
so that's the trick

303
00:17:09,420 --> 00:17:14,000
you condition on something that makes your problem simple

304
00:17:14,210 --> 00:17:20,500
so if we exploit that fact then

305
00:17:20,560 --> 00:17:23,980
this guy is nasty because we don't know the set but once you know this

306
00:17:24,000 --> 00:17:28,270
that so if you have to compute that sample the sets from this distribution then

307
00:17:28,270 --> 00:17:33,460
you would have observations and set and this we know how to compute analytically

308
00:17:33,480 --> 00:17:37,460
it's just the kalman filter equations

309
00:17:37,520 --> 00:17:42,730
and and that's pretty much what do we do monte carlo approximation of the z

310
00:17:42,770 --> 00:17:47,400
and then we get the distribution of the axes

311
00:17:47,620 --> 00:17:54,150
we know that again using margin condition marginalizations just this distribution and then we think

312
00:17:54,150 --> 00:17:57,230
this multicolour system and replace it here

313
00:17:57,250 --> 00:17:58,330
and we get

314
00:17:58,350 --> 00:18:03,000
an estimate of the effects not to t which is an analytical

315
00:18:03,020 --> 00:18:06,460
in this section mixture of gaussians

316
00:18:06,480 --> 00:18:09,960
because bridge that you get different graphs

317
00:18:12,500 --> 00:18:16,390
basically what our looks like this if you haven't seen coming of this approach is

318
00:18:16,390 --> 00:18:17,960
very very scary

319
00:18:17,960 --> 00:18:24,080
you say the labels and you give you a nice XML representation saying this website

320
00:18:24,080 --> 00:18:29,370
is about ontologies it is about the semantic web it is about RDF knowledge representation

321
00:18:29,370 --> 00:18:33,350
in artificial intelligence conferences and

322
00:18:33,370 --> 00:18:36,120
well many of the things

323
00:18:36,140 --> 00:18:37,100
this is

324
00:18:37,180 --> 00:18:39,110
of what is important

325
00:18:39,150 --> 00:18:42,770
but this is starting to be useful i mean there are

326
00:18:42,790 --> 00:18:47,500
very nice applications you can show you already thinking of five or six application you

327
00:18:47,500 --> 00:18:53,510
can already use can already built just using this simple URL into your javascript one

328
00:18:54,100 --> 00:19:00,380
one application which is called semantic jornal which is a very simple thing whenever you

329
00:19:00,600 --> 00:19:05,890
you writing an article for john all of blog anything you can add the semantic

330
00:19:05,890 --> 00:19:06,940
search button

331
00:19:06,960 --> 00:19:10,650
he's writing an article about

332
00:19:10,660 --> 00:19:12,890
the art of war elephants and

333
00:19:13,190 --> 00:19:19,840
and whenever he this is but then it sends a request to this API semantic

334
00:19:19,840 --> 00:19:24,840
i can find the categories so here we get literature is the out of one

335
00:19:25,760 --> 00:19:27,710
what are literature since two

336
00:19:28,870 --> 00:19:30,380
if you don't get it

337
00:19:30,570 --> 00:19:32,660
action i mean it

338
00:19:33,180 --> 00:19:38,140
and from this category since it is what categories you can get into web directory

339
00:19:38,440 --> 00:19:43,630
and find documents that would complement your article documents back and you can use as

340
00:19:43,630 --> 00:19:48,150
reference or you can use to add additional information to write your article is overly

341
00:19:48,150 --> 00:19:52,000
simple and i would bet the guy didn't take more than fifteen minutes to actually

342
00:19:52,000 --> 00:19:53,690
write application

343
00:19:53,790 --> 00:19:56,520
the second

344
00:19:56,530 --> 00:20:01,510
sort of a like this i would like to show is open calais semantic proxy

345
00:20:01,590 --> 00:20:06,640
it is one is very very famous and is the guy will be presented they

346
00:20:07,290 --> 00:20:10,490
we don't say this is the semantic web

347
00:20:10,510 --> 00:20:11,930
but we say

348
00:20:11,940 --> 00:20:16,990
this is an overview of is is the a preview of what may look like

349
00:20:17,760 --> 00:20:22,170
a few years using these services are very simple or

350
00:20:22,190 --> 00:20:28,150
kind of name entity recognition service you give it the the URL of a web

351
00:20:29,370 --> 00:20:30,810
and it is you

352
00:20:30,830 --> 00:20:33,930
what sort of person there

353
00:20:34,370 --> 00:20:39,720
what technology can recognise what event what cities places these companies

354
00:20:40,780 --> 00:20:43,590
organisation even medical conditions

355
00:20:44,110 --> 00:20:51,610
this one i run it bit before it is finally this wasn't supposed to happen

356
00:20:51,630 --> 00:20:56,750
so basically if you go to you can see anything like if you could do

357
00:20:57,390 --> 00:20:59,350
particular web page

358
00:20:59,370 --> 00:21:02,770
here again i put the URL of

359
00:21:02,830 --> 00:21:05,240
this is the web site of this tutorial rooms

360
00:21:05,260 --> 00:21:06,880
and what i get is about

361
00:21:06,890 --> 00:21:08,610
this is true it seems

362
00:21:08,630 --> 00:21:10,310
it recognizes many people

363
00:21:10,470 --> 00:21:11,610
can i join

364
00:21:11,670 --> 00:21:13,550
five are shown here

365
00:21:13,560 --> 00:21:15,510
and again jamie

366
00:21:15,560 --> 00:21:16,830
jerome euzenat

367
00:21:16,830 --> 00:21:17,830
in the

368
00:21:17,930 --> 00:21:20,230
in the coming ice technology

369
00:21:20,240 --> 00:21:28,920
that semantic web technologies knowledge management RDF industry terms many of neuron

370
00:21:30,540 --> 00:21:34,440
if you want to use it programmatically in the same principle as the older you

371
00:21:34,440 --> 00:21:36,190
get the particular you rarely get the key

372
00:21:36,690 --> 00:21:40,340
but you get from when you registered to the service you can say

373
00:21:41,230 --> 00:21:43,630
nine using this but it's fun

374
00:21:44,280 --> 00:21:46,760
but you want RDF as the result

375
00:21:46,780 --> 00:21:50,030
and then you put the URL of the service in that case i change i

376
00:21:50,030 --> 00:21:51,450
put my webpage

377
00:21:51,490 --> 00:21:54,040
and then you get a list of

378
00:21:54,250 --> 00:21:55,580
died things

379
00:21:55,590 --> 00:22:01,210
it recognise person like for example kind come out as someone recumbent

380
00:22:01,210 --> 00:22:08,190
organisation university of nancy open university technologies like artificial intelligence fuzzy logic

381
00:22:08,210 --> 00:22:14,320
the country's france united kingdom company is going to be made in the journal of

382
00:22:14,320 --> 00:22:15,790
logic and computation

383
00:22:15,800 --> 00:22:21,750
and mechanical condition can so i don't have cancer be reassuring

384
00:22:23,770 --> 00:22:24,970
of course it is not

385
00:22:24,980 --> 00:22:28,350
in fact you can see here for example but it

386
00:22:28,370 --> 00:22:31,220
recognise milton keynes as being a person

387
00:22:31,230 --> 00:22:35,920
why actually it's easy to see the thing which makes me very upset about it

388
00:22:35,960 --> 00:22:37,540
and recognise me as person

389
00:22:37,590 --> 00:22:39,140
i mean my web page

390
00:22:39,150 --> 00:22:44,360
could actually have for me that was the minimum you could do some other things

391
00:22:44,360 --> 00:22:46,140
are not particularly good

392
00:22:46,180 --> 00:22:49,030
but this is a very good starting point and the nice thing is that you

393
00:22:49,030 --> 00:22:51,160
don not only have

394
00:22:52,000 --> 00:22:55,540
set of entities it even give you back the text

395
00:22:56,290 --> 00:23:01,290
annotation within the text of what it does recognise so whenever i mentioned that we

396
00:23:01,290 --> 00:23:02,820
come untied states

397
00:23:02,830 --> 00:23:08,710
the bits of text in your text is the person can find relations like this

398
00:23:08,720 --> 00:23:11,740
one showing application for this one because there are many

399
00:23:11,780 --> 00:23:16,210
and they actually have a gallery of all the applications that have been built on

400
00:23:16,210 --> 00:23:19,760
top of open calais framework from which semantic proxy

401
00:23:19,780 --> 00:23:21,500
is about

402
00:23:21,510 --> 00:23:23,040
and i get directed to

403
00:23:23,050 --> 00:23:26,350
the second category of things which is even all

404
00:23:26,430 --> 00:23:29,280
about using the semantic web

405
00:23:29,600 --> 00:23:32,770
the second category is about this then

406
00:23:32,790 --> 00:23:34,820
that goes to the web

407
00:23:34,830 --> 00:23:41,130
crawley it to find out if document RDF data and different elements index it to

408
00:23:41,130 --> 00:23:45,300
provide you with the ability to access it and to exploit it

409
00:23:45,320 --> 00:23:48,900
that's why i put a nice lighting things around there

410
00:23:48,920 --> 00:23:50,190
that means that

411
00:23:50,200 --> 00:23:51,700
whenever this

412
00:23:51,720 --> 00:23:54,340
since then i've done what we have to do

413
00:23:54,390 --> 00:23:59,310
and your application can use keywords can send queries in park can ask for the

414
00:23:59,310 --> 00:24:01,030
metadata about the data

415
00:24:01,050 --> 00:24:03,470
can i ask for structured query

416
00:24:03,520 --> 00:24:05,610
and obtain

417
00:24:05,630 --> 00:24:10,370
location of RDF documents where they are can obtain actually is the content of the

418
00:24:10,370 --> 00:24:14,200
RDF document can explore all the semantic that is on the web

419
00:24:14,200 --> 00:24:15,180
to your typical set

420
00:24:16,840 --> 00:24:20,740
all right so there was they ridiculous weighted decompression it in all the very large

421
00:24:20,880 --> 00:24:24,670
bin bags full of tickets that you wrote things on the two sides of the

422
00:24:24,850 --> 00:24:27,390
our compression hand and compression algorithm

423
00:24:28,730 --> 00:24:30,480
for the next two lectures we're going to discuss

424
00:24:32,090 --> 00:24:34,360
data compression how would we compress

425
00:24:34,890 --> 00:24:35,470
bent coin

426
00:24:36,620 --> 00:24:40,920
practically well that's actually a homework exercise i said boyish i'd like you to work

427
00:24:40,920 --> 00:24:45,040
on that but will carry on working on other approaches to

428
00:24:45,550 --> 00:24:48,410
related problems and i'm going to talk today about

429
00:24:48,970 --> 00:24:51,550
they methods doing data compression called symbol

430
00:24:53,820 --> 00:24:55,030
and the idea a simple code

431
00:24:55,540 --> 00:24:58,590
is it something you could apply for example the english

432
00:24:59,250 --> 00:24:59,900
or to

433
00:25:00,510 --> 00:25:06,330
any language that involves an alphabetic characters were some characters are more probable than others

434
00:25:07,070 --> 00:25:11,380
and to make life especially simple to start with i'm going to pretend that the

435
00:25:11,380 --> 00:25:15,590
probability distribution for every character is the same every time and that we know the

436
00:25:17,130 --> 00:25:22,580
andy will usually assume that non uniform so here is what the distribution could look like

437
00:25:22,960 --> 00:25:27,580
here's an alphabet of twenty six characters plus space twenty seven in all

438
00:25:28,080 --> 00:25:32,410
and a probability distribution over those and you can see space is the most probable

439
00:25:32,410 --> 00:25:38,400
character and we've got eighty aiello iron age are sachdeo all that's sort of

440
00:25:38,910 --> 00:25:42,430
stuff so it's that this is like an english-language distribution

441
00:25:43,510 --> 00:25:44,300
and the task now

442
00:25:45,990 --> 00:25:46,500
to give

443
00:25:47,120 --> 00:25:48,800
a codeword to each

444
00:25:50,600 --> 00:25:52,060
symbols in the alphabet which

445
00:25:52,830 --> 00:25:53,230
of these

446
00:25:53,800 --> 00:25:54,900
elements of the alphabet

447
00:25:55,310 --> 00:25:59,720
and here's an example of what those codewords could look like we're going to encode into binary

448
00:26:00,300 --> 00:26:05,960
andrew given you a codeword four zeros andrew c z the code one one zero one the

449
00:26:06,420 --> 00:26:08,380
one spaces got zero one

450
00:26:09,570 --> 00:26:14,000
that's an example the code and the way users symbol code is you take the

451
00:26:14,000 --> 00:26:18,350
source file and to replace it by the corresponding code words in order

452
00:26:18,740 --> 00:26:26,100
concatenated with no punctuation at all so the receiver won't be able to see where the boundaries between the codewords

453
00:26:36,690 --> 00:26:38,620
a simple code is going to be a man

454
00:26:40,560 --> 00:26:42,010
from each symbol

455
00:26:46,320 --> 00:26:47,630
x in your alphabet

456
00:26:49,550 --> 00:26:50,350
we call it see

457
00:26:51,700 --> 00:26:54,330
x and see if x is a binary string

458
00:27:00,540 --> 00:27:01,660
that's can see here can be

459
00:27:02,280 --> 00:27:02,920
any length

460
00:27:03,340 --> 00:27:06,020
and the way you write in set notation

461
00:27:08,090 --> 00:27:11,040
zero one is the set with zero and one and it

462
00:27:11,520 --> 00:27:16,450
and zero one set the plus means the set of all strings of any length

463
00:27:17,010 --> 00:27:18,450
made of zeros and ones

464
00:27:20,510 --> 00:27:24,210
but may be familiar to those who have with computer scientists

465
00:27:25,170 --> 00:27:27,200
let me give you another example zero

466
00:27:29,180 --> 00:27:30,040
the the power to

467
00:27:30,580 --> 00:27:33,900
is the same as the set of strings are zero zero one

468
00:27:34,360 --> 00:27:34,570
on the

469
00:27:35,620 --> 00:27:36,480
and one one

470
00:27:37,380 --> 00:27:39,300
okay so that's just a little bit about station

471
00:27:40,280 --> 00:27:41,550
a simple code is

472
00:27:42,300 --> 00:27:43,570
a mapping from symbols to

473
00:27:44,030 --> 00:27:44,900
binary strings

474
00:27:45,640 --> 00:27:46,120
and then

475
00:27:47,030 --> 00:27:49,450
the way symbol code works is we encode

476
00:27:52,670 --> 00:27:54,850
the string about complex one x two x three

477
00:27:58,480 --> 00:28:00,820
by concatenate thing without punctuation

478
00:28:04,510 --> 00:28:06,220
because the correct one and the code

479
00:28:06,460 --> 00:28:08,490
thanks to the to the registration

480
00:28:19,110 --> 00:28:19,970
i just give you an example

481
00:28:22,830 --> 00:28:23,790
if we gave

482
00:28:24,310 --> 00:28:25,560
eight codeword

483
00:28:27,780 --> 00:28:29,180
he the candidate zero zero

484
00:28:29,930 --> 00:28:31,560
and see one zero one

485
00:28:33,950 --> 00:28:39,740
the file containing be would encoded has one zero one zero one zero

486
00:28:45,510 --> 00:28:46,620
so that's a fairly simple idea

487
00:28:47,020 --> 00:28:51,350
but now we need to get our head around this symbol codes understand and theoretically

488
00:28:51,350 --> 00:28:56,100
ant understand them practically and these are quite important because they're quite widely

489
00:28:56,520 --> 00:28:57,830
used especially in

490
00:28:58,260 --> 00:28:59,010
in history

491
00:29:04,540 --> 00:29:07,750
so the questions we want today other theoretical question

492
00:29:08,260 --> 00:29:11,120
how well might pay symbol code before

493
00:29:21,620 --> 00:29:22,950
and what anticipating here

494
00:29:22,950 --> 00:29:26,590
a sort of computer windows systems that lived on your desk rather than on the

495
00:29:26,590 --> 00:29:32,130
screen so you would have overhead camera and projector mounted on the roof and then

496
00:29:32,130 --> 00:29:35,880
your desk as real objects on a piece of paper and pens and all sorts

497
00:29:35,880 --> 00:29:39,310
of things that you keep passports apparently that you keep on your desk

498
00:29:40,260 --> 00:29:43,770
you will be able to we use your hands to mix the real and virtual

499
00:29:43,770 --> 00:29:49,870
objects for example you might have replicated the effect of having scissors photocopier glue and

500
00:29:49,870 --> 00:29:53,560
so on and make up the news letter of two departure and so you might

501
00:29:53,560 --> 00:29:58,160
be making this newsletter past and electronic content partly real content be nice to be

502
00:29:58,160 --> 00:30:01,820
able to get a paper copy of something and just sort of do that with

503
00:30:01,820 --> 00:30:05,790
your hand to delineate the picture then slide the picture of

504
00:30:05,860 --> 00:30:07,010
the newspaper

505
00:30:07,020 --> 00:30:11,820
the source newspaper onto the thing that you can positive and then

506
00:30:11,830 --> 00:30:16,630
all of this is my friend mike is art exercising some of the software that

507
00:30:16,630 --> 00:30:22,250
he designed that was supposed to follow hands effortlessly and you see it's i'm going

508
00:30:22,250 --> 00:30:26,020
to explain you know sort of two lectures down the line what that was actually

509
00:30:26,020 --> 00:30:31,080
doing but you see we've got something quite robust here that works on the desk

510
00:30:31,080 --> 00:30:31,670
and in

511
00:30:31,690 --> 00:30:34,730
free space and so on

512
00:30:34,750 --> 00:30:37,610
another idea that i think is going to become more and more important i mean

513
00:30:37,610 --> 00:30:39,780
there's technology out there for

514
00:30:39,800 --> 00:30:43,330
having meetings across the web where you

515
00:30:43,340 --> 00:30:47,070
can talk to somebody with

516
00:30:47,170 --> 00:30:52,090
audio but they can also see you and you can also manipulate documents you might

517
00:30:52,090 --> 00:30:52,980
be talking to

518
00:30:53,010 --> 00:30:54,830
several people simultaneously

519
00:30:56,220 --> 00:31:01,410
it would be good to maximize the visual real estate that you have been real

520
00:31:01,410 --> 00:31:06,260
estate you have on your on your computer and the bandwidth for transmitting that so

521
00:31:06,260 --> 00:31:12,680
here supposedly if for eager graduate students chatting to me about the latest idea

522
00:31:13,900 --> 00:31:17,030
if i use a conventional webcam

523
00:31:17,050 --> 00:31:18,680
this might be what they see

524
00:31:18,700 --> 00:31:23,770
and actually will be this picture reduced in size using current technology anyway by perhaps

525
00:31:23,810 --> 00:31:25,330
half or even worse

526
00:31:25,350 --> 00:31:29,940
so wouldn't it be great if i could track if a sufficiently well to make

527
00:31:29,940 --> 00:31:34,160
an automated cameraman so this is the scene on the right is made from exactly

528
00:31:34,160 --> 00:31:37,070
the same raw material that you saw on the left

529
00:31:37,120 --> 00:31:41,350
but with automatic framing digital zooming panning pan and tilt

530
00:31:44,320 --> 00:31:48,780
whatever you do it's got to be reliable enough to operate not just for a

531
00:31:48,780 --> 00:31:53,630
few seconds like i'm illustrating here but over several minutes and this is something we're

532
00:31:53,630 --> 00:31:59,700
working on in the cambridge microsoft lab we have a project recall i which is

533
00:31:59,700 --> 00:32:06,510
using stereo vision because stereo is so robust that separating foreground and background it's not

534
00:32:06,550 --> 00:32:09,930
say that you can't do this without stereo what i'm showing you here the results

535
00:32:09,930 --> 00:32:14,780
of a program that does this without stereo at the moment we are also working

536
00:32:14,780 --> 00:32:17,240
both on stereo and mono

537
00:32:17,250 --> 00:32:20,410
face detection and tracking to do the same job and we're kind pitting them against

538
00:32:20,410 --> 00:32:24,250
one another we know the stereo will work on the other hand are we going

539
00:32:24,250 --> 00:32:28,350
to be able to get the world to start buying stereo webcam maybe we can

540
00:32:28,470 --> 00:32:33,420
but if we can do the same thing monocular then that will make me feel

541
00:32:33,570 --> 00:32:35,170
like for the marketing men

542
00:32:35,220 --> 00:32:40,070
a lot easier because then we just need to provide software downloads that have the

543
00:32:40,130 --> 00:32:41,760
tracking embedded in them

544
00:32:41,780 --> 00:32:47,710
we played also in the same context with putting speech vision together so he is

545
00:32:47,840 --> 00:32:52,680
a couple of my colleagues who are working on this technology in a different kind

546
00:32:52,680 --> 00:32:56,230
of track at this time tracking the head in a way

547
00:32:56,240 --> 00:33:01,190
it actually takes cues from the speech so as well as a camera a pair

548
00:33:01,190 --> 00:33:06,780
of stereo microphones and the might the microphones are using effectively time of flight to

549
00:33:06,780 --> 00:33:09,610
work out what is the bearing of the person who's talking

550
00:33:09,660 --> 00:33:14,380
and using probabilistic fusion of the two kinds of information the audio

551
00:33:14,390 --> 00:33:20,030
bearing and the visual information we can make quite a robust system that will

552
00:33:22,010 --> 00:33:25,850
the picture of the person who's talking

553
00:33:25,860 --> 00:33:29,770
yes if we had sound you'd be able to hear the conversation but the conversation

554
00:33:29,860 --> 00:33:32,730
turned out to be somewhat fatuous they didn't realize i was going to record them

555
00:33:32,730 --> 00:33:34,950
so they much prefer that i don't show

556
00:33:34,970 --> 00:33:39,230
that you hear what they were saying

557
00:33:39,240 --> 00:33:45,480
and another application is surveillance would be very useful if you could keep track of

558
00:33:45,480 --> 00:33:50,410
people moving around car parks and alert some security man who has a hundred cameras

559
00:33:50,410 --> 00:33:54,330
to monitor when there was something interesting one of the screens and many people are

560
00:33:54,600 --> 00:33:56,440
interested in this idea

561
00:33:58,780 --> 00:34:03,470
important application is like reading it's well known that for humans

562
00:34:03,600 --> 00:34:11,140
your accuracy in understanding speech is enhanced by having the motion available a program by

563
00:34:11,140 --> 00:34:13,850
some berkeley researchers

564
00:34:14,200 --> 00:34:19,120
while again now that i was able to track moving lips and get back to

565
00:34:19,190 --> 00:34:21,650
the idea of the track

566
00:34:21,690 --> 00:34:24,510
OK so i thought i begin by

567
00:34:24,530 --> 00:34:26,480
sort of positing a rather dull

568
00:34:26,490 --> 00:34:30,890
method for tracking and we can you know for it away and replace it with

569
00:34:30,890 --> 00:34:34,830
something better so you know what's the dumbest thing you might do too

570
00:34:35,570 --> 00:34:40,220
to track a moving object will

571
00:34:40,230 --> 00:34:42,460
this idea can be so down because it's

572
00:34:42,550 --> 00:34:47,380
in nineteen eighty one it was considered quite reasonable thing to propose because in canada

573
00:34:47,740 --> 00:34:53,820
people still use it in various forms but the idea is that you have

574
00:34:53,840 --> 00:34:56,930
and image i fx that you just saw

575
00:34:56,940 --> 00:35:01,810
and some templates tnx supposed to be a prototype for the object that you're you're

576
00:35:01,810 --> 00:35:05,550
looking for and so you can imagine trying to do some simple

577
00:35:05,600 --> 00:35:07,870
direct matching of the

578
00:35:08,000 --> 00:35:10,950
image that you just saw with the with the template

579
00:35:10,960 --> 00:35:11,700
and so

580
00:35:11,710 --> 00:35:13,890
if i

581
00:35:13,900 --> 00:35:19,210
take this image i have x and then expand i x plus the two first

582
00:35:19,210 --> 00:35:24,850
order where the is a small displacement and i now compare that with the with

583
00:35:25,460 --> 00:35:26,600
template in the

584
00:35:26,610 --> 00:35:30,490
a position that i currently believe it should be which is you know so i

585
00:35:30,490 --> 00:35:34,930
think these being a small displacement value is not necessarily small and now supposing i

586
00:35:34,930 --> 00:35:36,090
minimize this

587
00:35:36,320 --> 00:35:43,650
sum of squared errors which is summed across the actual colours or intensities of pixels

588
00:35:43,670 --> 00:35:46,630
and then i can

589
00:35:46,640 --> 00:35:49,210
get simple

590
00:35:49,220 --> 00:35:53,510
closed form solution to this minimisation

591
00:35:53,570 --> 00:35:54,730
and of course

592
00:35:54,740 --> 00:35:58,890
i'm exploring an energy landscape which is somewhat out of my control so i don't

593
00:35:58,890 --> 00:36:04,220
know whether the methods the previous talk can help here because you can't talk about

594
00:36:04,470 --> 00:36:08,660
whether or not this problem is convex i mean i can easily invent templates and

595
00:36:08,660 --> 00:36:13,400
images for which the problem is in combat complex imagine template of of stripes and

596
00:36:13,400 --> 00:36:16,260
an image of stripes and is going to be a kind of click every time

597
00:36:16,260 --> 00:36:20,140
the stripes in the image can side the stripes template so you can you can

598
00:36:20,140 --> 00:36:23,850
see it's going to be very easy to make numerically nasty

599
00:36:25,430 --> 00:36:26,700
problems out of this

600
00:36:27,720 --> 00:36:29,620
but in any case to solve the

601
00:36:29,640 --> 00:36:34,400
local minimisation problem is not difficult it turns out that i take the

602
00:36:34,440 --> 00:36:35,980
these gradient

603
00:36:35,990 --> 00:36:40,010
i had this great either axis is the intensity gradient of the point in the

604
00:36:40,010 --> 00:36:41,600
image computed every

605
00:36:41,620 --> 00:36:45,400
o point x in the image how would you actually do that practically well you

606
00:36:45,400 --> 00:36:50,110
might think of doing it with a finite difference approximation just taking the difference between

607
00:36:50,110 --> 00:36:55,160
neighboring pixels but everybody knows that who does this that that's not a good way

608
00:36:55,160 --> 00:37:00,210
to proceed because of sampling artifacts the real world is continuous and the images just

609
00:37:00,210 --> 00:37:04,490
to sample version of it so what safer is to filter the image first with

610
00:37:04,490 --> 00:37:07,410
is OK then the probabilities would be one of the thirty two

611
00:37:07,440 --> 00:37:10,670
and i would gain five bits of information if i observe the outcome of that

612
00:37:10,670 --> 00:37:13,860
of that run of our OK

613
00:37:13,910 --> 00:37:16,090
so what you can now see is that

614
00:37:16,100 --> 00:37:19,350
you can now see is that

615
00:37:19,360 --> 00:37:21,630
unlikely events

616
00:37:21,710 --> 00:37:24,670
i'm going to make this a number large

617
00:37:24,730 --> 00:37:30,120
and therefore going give me more information according to this rule than than likely events

618
00:37:30,930 --> 00:37:33,420
so this is shannon information content

619
00:37:33,430 --> 00:37:34,930
now what is the entropy

620
00:37:34,990 --> 00:37:36,780
well the entropy is simply

621
00:37:36,790 --> 00:37:38,670
the average

622
00:37:38,680 --> 00:37:40,320
shannon information

623
00:37:41,100 --> 00:37:42,740
that's what it is

624
00:37:42,750 --> 00:37:44,170
so how do i computed

625
00:37:44,180 --> 00:37:46,820
well i basically observed

626
00:37:46,870 --> 00:37:47,670
OK i

627
00:37:47,680 --> 00:37:49,750
and then i sort of say OK but how many times and my going to

628
00:37:49,760 --> 00:37:54,010
observe a i a well i'm going to observe BPI times roughly right and so

629
00:37:54,010 --> 00:37:56,000
on and i just and i just performed

630
00:37:56,010 --> 00:37:57,520
the average OK

631
00:37:57,540 --> 00:38:00,470
and then you just you know you just take the minus here and then you

632
00:38:00,470 --> 00:38:07,700
get the usual the usually familiar form for the entropy that you're all familiar with

633
00:38:07,720 --> 00:38:13,700
sometimes we write the entropy in that if you take the natural logarithm

634
00:38:13,720 --> 00:38:17,590
but i find it confusing

635
00:38:17,650 --> 00:38:21,770
so how does the entropy look like

636
00:38:23,100 --> 00:38:26,670
here's another figure sum from david mackay's book it's really worth reading if you're interested

637
00:38:26,670 --> 00:38:29,760
in information theory

638
00:38:30,590 --> 00:38:34,910
so let's take a coin

639
00:38:34,950 --> 00:38:38,540
let's take a look going OK that doesn't have a fifty percent chance of falling

640
00:38:38,540 --> 00:38:41,920
on each side imagine we could sort of loaded on one side with with heavier

641
00:38:41,920 --> 00:38:45,210
metal plate or whatever and we can sort of because sort of

642
00:38:45,220 --> 00:38:48,680
i just the probability that is going to come out hence OK and we consider

643
00:38:48,690 --> 00:38:53,650
making range from zero to one missing from zero percent to one hundred percent

644
00:38:54,330 --> 00:38:58,730
for all these values we can compute the what the when the shannon information is

645
00:38:58,730 --> 00:39:00,870
of observing the outcome

646
00:39:01,460 --> 00:39:03,390
heads right

647
00:39:03,410 --> 00:39:08,130
so if the switch were with the here now

648
00:39:08,140 --> 00:39:16,900
i think i've done this or this is sort of the other way around if

649
00:39:16,910 --> 00:39:18,420
basically if it's

650
00:39:18,430 --> 00:39:21,410
if it's very likely if it's very unlikely that is going to be heads and

651
00:39:21,410 --> 00:39:22,720
they observe heads

652
00:39:22,730 --> 00:39:27,280
then i get a lot of negative a lot of information here OK

653
00:39:27,300 --> 00:39:29,670
and if it's fifty fifty

654
00:39:29,690 --> 00:39:31,530
i get the least information

655
00:39:31,570 --> 00:39:35,170
not surprisingly if i compute the average compute the entropy

656
00:39:35,210 --> 00:39:39,300
actually the entropy behaves the opposite way around it doesn't behave that way and you

657
00:39:39,300 --> 00:39:42,760
can intuitively why right this some sort of trade-off

658
00:39:42,780 --> 00:39:47,370
if something extremely unlikely is very informative that's very nice if i observe it but

659
00:39:47,370 --> 00:39:50,880
if i'm interested in the entropy i'm interested in the average amount of information i'm

660
00:39:50,880 --> 00:39:54,200
going to get the then that very informative things

661
00:39:54,220 --> 00:39:57,800
is going to come in very very seldom right so when i perform my average

662
00:39:57,800 --> 00:40:01,060
is going to sort of varnish is going to be sold in it

663
00:40:01,080 --> 00:40:02,670
OK so that's sort of the

664
00:40:02,670 --> 00:40:06,640
the confusion earlier with what's more informative zero point one was your point five it

665
00:40:06,640 --> 00:40:08,430
depends on whether you're talking

666
00:40:08,450 --> 00:40:13,370
average information or whether you're talking sort of the information you got that instant condition

667
00:40:13,410 --> 00:40:15,970
on the fact that you observe the unlikely event OK

668
00:40:17,090 --> 00:40:18,520
entropy is

669
00:40:18,530 --> 00:40:21,420
the average information and you can sort of see that if

670
00:40:21,460 --> 00:40:23,280
if you know that the coin

671
00:40:23,290 --> 00:40:24,470
you know

672
00:40:24,480 --> 00:40:25,440
sort of

673
00:40:25,470 --> 00:40:27,310
is very bias either way

674
00:40:27,330 --> 00:40:31,050
then then the entropy is going to be very very low the uncertainty is going

675
00:40:31,050 --> 00:40:32,230
to be very small

676
00:40:32,450 --> 00:40:35,080
the answer the the entropy is maximum

677
00:40:35,590 --> 00:40:41,340
when when the probability of heads is zero five

678
00:40:41,400 --> 00:40:44,000
so this sort of satisfies

679
00:40:44,010 --> 00:40:47,670
the two first axioms right

680
00:40:47,760 --> 00:40:52,310
one of them is if we observe an event that certain OK

681
00:40:52,370 --> 00:40:54,140
we knew already OK

682
00:40:54,150 --> 00:40:58,670
it sort of it always rains in britain so i go out and it's raining

683
00:40:58,720 --> 00:41:01,510
no nugget of information

684
00:41:01,550 --> 00:41:05,910
now the day i got inside i'm going to take global warming seriously

685
00:41:05,920 --> 00:41:09,930
and then the other thing is that in general the maximum information

686
00:41:09,950 --> 00:41:22,880
on average is carried by uniformly probable events

687
00:41:22,930 --> 00:41:24,570
OK so let's now

688
00:41:24,580 --> 00:41:28,120
that's now think about the third axiom the axiom was

689
00:41:28,130 --> 00:41:29,940
about the additivity

690
00:41:29,960 --> 00:41:34,050
all of the information given by independent sources OK

691
00:41:37,870 --> 00:41:39,370
i can actually compute

692
00:41:39,380 --> 00:41:44,230
the joint entropy so if i have if i can again be the joint distribution

693
00:41:44,230 --> 00:41:47,730
between two random variables and i can ask myself

694
00:41:47,750 --> 00:41:49,660
how much information does that

695
00:41:49,670 --> 00:41:53,190
those observing the outcome of these two random variables give me

696
00:41:53,200 --> 00:41:56,970
on average OK that's going to be the that's going to be the entropy

697
00:41:57,170 --> 00:42:01,690
now what you can see that if we start by looking at the shannon information

698
00:42:01,690 --> 00:42:04,710
content again so we don't take the average it OK

699
00:42:04,730 --> 00:42:07,930
i was simply use this equation all right

700
00:42:07,950 --> 00:42:11,530
now what you see is we scenario that if x and y are independent i

701
00:42:11,530 --> 00:42:13,410
can actually read them as the problem right

702
00:42:13,450 --> 00:42:17,770
i can p of x of y and therefore i can actually be composed

703
00:42:18,330 --> 00:42:23,330
shannon information into the sum of the individual shannon information OK

704
00:42:23,340 --> 00:42:24,940
so basically

705
00:42:24,960 --> 00:42:26,290
shannon was a clever guy

706
00:42:26,300 --> 00:42:30,200
he came up with an equation that satisfies all axioms OK so it's not an

707
00:42:30,200 --> 00:42:34,460
arbitrary thing to take the logarithm of one of the problem the probability there's there's

708
00:42:34,460 --> 00:42:36,130
there's a number of powerful reasons why

709
00:42:36,550 --> 00:42:40,250
you want that equation and not just any other equation

710
00:42:41,500 --> 00:42:44,190
now quite trivial if you were to take the average if you were to take

711
00:42:44,190 --> 00:42:47,780
the entropy you would have to take the average over the joint p of x

712
00:42:47,780 --> 00:42:51,980
come y OK of this quantity here now you can see that if it decomposes

713
00:42:52,330 --> 00:42:55,560
you first you get sort of two averages here and

714
00:42:56,600 --> 00:43:00,810
the distributions can be factorized or the independent then

715
00:43:01,200 --> 00:43:02,530
you're going to sort of have

716
00:43:02,570 --> 00:43:04,560
here the sort of

717
00:43:04,570 --> 00:43:07,870
the integral of p of x p y times the ceremony to p of x

718
00:43:07,870 --> 00:43:11,900
y ten that term but because in each of the cases you have one of

719
00:43:11,900 --> 00:43:15,590
the variables that is only in the distribution it is not in the term integrating

720
00:43:16,080 --> 00:43:17,670
then you can just

721
00:43:17,680 --> 00:43:19,830
take it outside and killing

722
00:43:19,850 --> 00:43:21,430
so basically the

723
00:43:21,430 --> 00:43:25,510
the previous space that is it's when cells were over here

724
00:43:25,550 --> 00:43:30,260
if the cell was over here

725
00:43:30,630 --> 00:43:34,650
and we have articles and there won't be any it will be radioactive labeled so

726
00:43:34,650 --> 00:43:37,640
what we're really gonna that's now is the following

727
00:43:37,660 --> 00:43:42,130
these cells are all advancing through like this they're dancing in the n phase

728
00:43:42,160 --> 00:43:45,700
when does the first radio labelled cell

729
00:43:45,720 --> 00:43:49,590
get after we release the hydroxyl when does it get

730
00:43:49,620 --> 00:43:51,760
when we first seeing cells like this

731
00:43:52,020 --> 00:43:57,320
and the fact is after five or six hours after release space then we begin

732
00:43:57,320 --> 00:43:58,940
to see cells like this

733
00:43:58,980 --> 00:44:04,880
which have chromosomes on which there is radio with which the israeli activity associated

734
00:44:04,920 --> 00:44:15,660
well keep in mind that when cells move through the s phase here

735
00:44:15,770 --> 00:44:19,060
this is when they incorporated traded finally into the DNA

736
00:44:19,090 --> 00:44:21,930
cells can incorporate finding here

737
00:44:21,950 --> 00:44:23,840
they can incorporate incorporated here

738
00:44:23,870 --> 00:44:30,440
you can incorporate it here

739
00:44:33,590 --> 00:44:37,060
so we can allow ourselves to incorporate a little bit of trade finally we can

740
00:44:37,060 --> 00:44:38,820
freeze them in here

741
00:44:38,920 --> 00:44:42,580
well given the little belt but it really is commonly get into the DNA here

742
00:44:42,770 --> 00:44:47,190
and then we'll have ibrox area very shortly thereafter and freeze the cells right like

743
00:44:47,190 --> 00:44:52,050
this so will be the doubly radioactive by virtue of having dwelt here different pi

744
00:44:52,050 --> 00:44:55,690
times in the s phase and we have hydroxy area then

745
00:44:55,700 --> 00:45:00,260
the cells that are already in s phase and incorporated benefited finally will remain as

746
00:45:00,260 --> 00:45:04,750
face all the other cells which were when we have the hydroxy urea over here

747
00:45:05,080 --> 00:45:08,130
they will go all the way around here

748
00:45:08,160 --> 00:45:11,340
they will move all the way around the cell cycle they might have happened to

749
00:45:11,440 --> 00:45:16,930
cooperate with but finally before we have the hydroxyl real they'll get trapped over here

750
00:45:17,050 --> 00:45:20,600
so the only so the cells that have pretty and finally they will be scattered

751
00:45:20,600 --> 00:45:24,630
at various points in the s phase we remove the hydroxy urea

752
00:45:24,670 --> 00:45:27,900
that allows the cells to escape from this phase and move all the way around

753
00:45:27,900 --> 00:45:31,930
the here and then we begin to look for seeing when cells get radio labelled

754
00:45:33,310 --> 00:45:34,760
is clear now

755
00:45:34,830 --> 00:45:38,270
a little clearer

756
00:45:43,750 --> 00:45:46,970
let's begin to ask how this is all

757
00:45:46,980 --> 00:45:49,440
coordinated what determines

758
00:45:49,570 --> 00:45:52,120
how cells when cells will grow

759
00:45:52,130 --> 00:45:55,400
and when cells will not grow so let's go back to war depiction of the

760
00:45:55,400 --> 00:45:56,510
cell cycle

761
00:45:58,010 --> 00:46:10,660
how what controls all this

762
00:46:10,690 --> 00:46:14,070
what determines when cells can move around the cell cycle

763
00:46:14,130 --> 00:46:16,320
in our bodies

764
00:46:16,360 --> 00:46:20,210
so we have roughly three times ten to the thirteenth cells

765
00:46:20,230 --> 00:46:22,740
i don't know that number i mentioned before

766
00:46:22,750 --> 00:46:26,070
it's a pretty interesting number it's probably the not

767
00:46:26,080 --> 00:46:27,950
the most interesting number

768
00:46:28,950 --> 00:46:32,430
by now far more people are interested in the number of how many games

769
00:46:32,450 --> 00:46:36,580
the red sox have won or lost but it's to number anyhow

770
00:46:36,610 --> 00:46:42,950
how many cell divisions to we go through in lifetime ever talk about that

771
00:46:42,970 --> 00:46:46,990
how many times with the cell growth and division cycle in human lifetime

772
00:46:47,010 --> 00:46:52,230
life time and the answer is a human lifetime there are about

773
00:46:52,280 --> 00:46:57,460
ten to the sixteenth cell divisions it's staggering number

774
00:46:57,480 --> 00:47:02,280
ten to the sixteenth in one human body in human lifetime and if you figure

775
00:47:02,280 --> 00:47:07,450
out what that amounts to i think it's something like and you figured out yourself

776
00:47:07,450 --> 00:47:10,800
i think it's month something like ten to the seventh

777
00:47:10,820 --> 00:47:12,090
cell divisions

778
00:47:12,130 --> 00:47:13,590
in each second

779
00:47:13,680 --> 00:47:17,180
so each time i'm talking with you i'm going to go already gone through any

780
00:47:17,180 --> 00:47:22,660
one of my sentences and by the time my long-winded sentences finish i probably already

781
00:47:22,660 --> 00:47:26,010
had a hundred million mitosis happening inside me

782
00:47:27,590 --> 00:47:28,930
maybe even more

783
00:47:28,930 --> 00:47:31,840
because sometimes my senses are really long

784
00:47:31,880 --> 00:47:35,010
so imagine that tend to the seven

785
00:47:35,050 --> 00:47:38,430
per second you can figure out the number of this is the lifetime of let's

786
00:47:38,430 --> 00:47:40,450
say you live seventy years

787
00:47:40,450 --> 00:47:43,050
you can do the math how many per second

788
00:47:43,050 --> 00:47:46,300
a lot of that's going on by the way in the bone marrow and in

789
00:47:46,300 --> 00:47:47,340
the gut

790
00:47:47,380 --> 00:47:52,340
because in the bone marrow constantly replacing a lot of your red blood cells you

791
00:47:52,340 --> 00:47:56,150
have lots of them but they only last for one hundred twenty days so after

792
00:47:56,150 --> 00:47:58,420
one hundred twenty days of red blood cells

793
00:47:58,430 --> 00:48:03,360
is is broken down into getting red blood cell in its place but obviously have

794
00:48:03,360 --> 00:48:07,030
more than one red blood cell in your body the same thing happens in the

795
00:48:07,700 --> 00:48:09,680
the cells lining

796
00:48:09,740 --> 00:48:14,590
the got those are called epithelial cells that line the surface of the guys and

797
00:48:14,590 --> 00:48:16,610
they are constantly

798
00:48:16,650 --> 00:48:19,630
being slapped on the wall of the

799
00:48:19,650 --> 00:48:23,360
why because it's not so nice to live on the wall of the is not

800
00:48:23,380 --> 00:48:29,090
very pleasant environment and the cells are therefore costly got gotten rid of because they

801
00:48:29,090 --> 00:48:33,220
have a hard time surviving for extended periods of time those cells live only three

802
00:48:33,220 --> 00:48:36,470
or four days on the wall of the

803
00:48:36,490 --> 00:48:39,510
so when you go to the bathroom and i don't mean to be too graphic

804
00:48:39,510 --> 00:48:44,220
but number two a significant proportion of what comes out

805
00:48:44,220 --> 00:48:48,320
the bottom is actually cells been sloughed off

806
00:48:48,340 --> 00:48:52,800
from the epithelial lining of the gut and what the proportion is it something like

807
00:48:52,800 --> 00:48:58,360
twenty or thirty percent about half of what comes out is actually bacterial

808
00:48:58,630 --> 00:49:01,050
in the in the feces

809
00:49:01,090 --> 00:49:05,740
we're not going on now so you can can absorb all is right about half

810
00:49:05,740 --> 00:49:10,820
of that almost none of the bulk of the feces actually ends up being what

811
00:49:10,820 --> 00:49:12,220
you eight

812
00:49:12,950 --> 00:49:17,240
most of what's right and left ends up getting compressed to a very small amount

813
00:49:17,240 --> 00:49:22,610
of solid matter so most of what comes out is is not with what came

814
00:49:23,680 --> 00:49:29,360
is not the process exposing food but things as i just mentioned

815
00:49:29,360 --> 00:49:33,700
and by the way here's another unsettling statistic

816
00:49:33,740 --> 00:49:37,780
it's not so graphic but it's unsettling if you think about it there are more

817
00:49:37,780 --> 00:49:40,760
bacterial cells in your gut

818
00:49:40,820 --> 00:49:44,930
then the rest then there are a million new carrier cells the rest your body

819
00:49:45,320 --> 00:49:47,160
they're taking over

820
00:49:47,180 --> 00:49:51,320
more than there are bus in each one of our bodies

821
00:49:51,340 --> 00:49:53,360
go figure that out

822
00:49:55,920 --> 00:49:58,280
why am i going on this long excursions

823
00:49:58,340 --> 00:50:00,490
well only he knows

824
00:50:00,530 --> 00:50:01,820
he's not telling but

825
00:50:01,930 --> 00:50:03,700
there was a reason behind it

826
00:50:03,700 --> 00:50:07,530
the reason why i'm going in this is to impress on you the fact that

827
00:50:07,530 --> 00:50:11,970
it's really important that the advance of cells through their growth and division cycle that

828
00:50:11,970 --> 00:50:13,860
we just talked about here

829
00:50:14,760 --> 00:50:21,010
very carefully controlled because each one of these growth cell growth and division cycles is

830
00:50:21,760 --> 00:50:27,070
the opportunity for disaster what kind of disaster well if the cell makes a mistake

831
00:50:27,070 --> 00:50:29,300
in its chromosomes it might die

832
00:50:29,300 --> 00:50:33,090
the death of the cell in our body is not a disaster

833
00:50:33,130 --> 00:50:34,820
i just indicated you there were

834
00:50:34,840 --> 00:50:39,320
we're making ten to the seventh new sells every second but

835
00:50:39,360 --> 00:50:43,800
hopefully we're making exactly the same number of cells that die

836
00:50:43,800 --> 00:50:47,070
go back to the beginning

837
00:50:47,160 --> 00:50:52,510
draw this parallel to be and so here's the and again just the line of

838
00:50:53,320 --> 00:50:57,030
that same slope and now what you should use

839
00:50:57,050 --> 00:51:01,680
as the simplest improvement on oil is that it is to take the average of

840
00:51:01,680 --> 00:51:04,890
these two because that's more likely to occur

841
00:51:04,990 --> 00:51:06,530
then a and will

842
00:51:06,530 --> 00:51:09,490
which is sure to be too low if the curve is convex

843
00:51:09,590 --> 00:51:13,760
in other words use this instead use that

844
00:51:13,760 --> 00:51:16,340
so this is our better slope

845
00:51:16,340 --> 00:51:27,070
OK what will we call that slow we call it anything with the equations

846
00:51:27,130 --> 00:51:29,050
for the method b

847
00:51:29,090 --> 00:51:32,390
well n plus one is

848
00:51:32,430 --> 00:51:36,510
done by adding the step size so here's my step size just as it was

849
00:51:38,820 --> 00:51:42,000
just as it was before the new thing is how to get the new value

850
00:51:42,000 --> 00:51:43,240
of y

851
00:51:43,260 --> 00:51:47,430
so y n plus one should be the all the y and

852
00:51:47,430 --> 00:51:49,410
plus h times

853
00:51:49,430 --> 00:51:52,390
not this crummy slope a and

854
00:51:52,410 --> 00:51:54,780
but the better the pink slope

855
00:51:54,780 --> 00:51:57,430
what's the formula for the pink flow well

856
00:51:57,450 --> 00:52:00,630
let's do it in two steps it's the average

857
00:52:00,680 --> 00:52:04,970
of a and b and

858
00:52:05,720 --> 00:52:09,410
i didn't tell me or i didn't tell you would be was so you now

859
00:52:09,410 --> 00:52:12,160
must tell the computer oh yes by the way

860
00:52:12,200 --> 00:52:15,610
if you remember the day and was what it always was

861
00:52:15,610 --> 00:52:18,740
the interesting thing is what is b and well

862
00:52:18,800 --> 00:52:25,390
to get BN BN is the slope of the line element at this new point

863
00:52:25,430 --> 00:52:29,160
i would like to call the new point i don't want to cause y value

864
00:52:29,160 --> 00:52:32,800
y n plus one because that's is this

865
00:52:32,840 --> 00:52:36,890
a period is going to be the y n plus one all this is temporary

866
00:52:38,010 --> 00:52:40,760
used to make another calculation

867
00:52:40,780 --> 00:52:46,340
which will then be combined with the previous calculations to get the right value

868
00:52:46,390 --> 00:52:50,550
therefore given the temporary name

869
00:52:50,610 --> 00:52:52,010
that point

870
00:52:52,010 --> 00:52:55,320
will call it is not going to be the final the real y n plus

871
00:52:55,320 --> 00:52:59,840
one we'll call y n plus one twiddles y n plus one temporary

872
00:53:00,570 --> 00:53:02,320
what's the formula for it

873
00:53:02,340 --> 00:53:06,800
well it's just going to be what the oiler formula original oil formulas can be

874
00:53:06,800 --> 00:53:11,510
y and what you would have gotten if you were calculated

875
00:53:11,550 --> 00:53:15,260
in other words the point that the oiler method produced

876
00:53:15,260 --> 00:53:19,490
but it's not finally the point that we want

877
00:53:19,530 --> 00:53:24,340
now want have to say anything else i didn't tell the computer would be and

878
00:53:24,340 --> 00:53:25,550
was OK

879
00:53:25,550 --> 00:53:26,700
b and

880
00:53:28,260 --> 00:53:29,740
the slope

881
00:53:29,760 --> 00:53:37,720
of the direction field point and was one the computer knows what that is and

882
00:53:37,760 --> 00:53:45,090
this point y n plus one temporary

883
00:53:45,160 --> 00:53:45,990
so you

884
00:53:45,990 --> 00:53:51,240
make a temporary choice of this calculate that number and then go back and as

885
00:53:51,240 --> 00:53:59,800
they were correct that value for this value by using this better slope

886
00:54:00,660 --> 00:54:04,050
that's all there is to the method except that give you its name

887
00:54:04,070 --> 00:54:08,240
well it has three names for names in fact

888
00:54:09,360 --> 00:54:10,720
which one so i give you

889
00:54:14,090 --> 00:54:18,140
if the shortest name is point

890
00:54:18,240 --> 00:54:21,030
but nobody knows

891
00:54:21,110 --> 00:54:22,660
announces that correctly

892
00:54:23,610 --> 00:54:25,240
so it's always method

893
00:54:25,760 --> 00:54:30,720
it's called also the improved oiler methods

894
00:54:30,950 --> 00:54:36,300
it's called modified boiler

895
00:54:36,320 --> 00:54:40,220
very expressive word

896
00:54:40,260 --> 00:54:42,240
modified oilers method

897
00:54:42,240 --> 00:54:44,610
and it's also called

898
00:54:44,640 --> 00:54:46,180
or k two

899
00:54:46,930 --> 00:54:52,160
i'm sure you like that best it has the star wars sort of sound

900
00:54:52,240 --> 00:54:57,550
rk stands for rock kind of

901
00:54:57,550 --> 00:55:00,700
and the reason for the tool

902
00:55:00,700 --> 00:55:04,740
it's not that it uses to well it is that it uses two slopes

903
00:55:04,800 --> 00:55:09,800
but the real reason for the two is that in a second order method so

904
00:55:09,800 --> 00:55:13,390
let's that's the most important thing to put down

905
00:55:13,390 --> 00:55:19,110
if the second order method whereas oilers was only first-order methods so this is a

906
00:55:19,110 --> 00:55:21,390
so why is method

907
00:55:21,490 --> 00:55:27,240
four RK two let's write the shortest in the right is the second order methods

908
00:55:29,870 --> 00:55:31,180
that the error

909
00:55:31,180 --> 00:55:34,450
varies with the step size

910
00:55:34,450 --> 00:55:39,220
like some constant there will be the same as the concert royal about that

911
00:55:39,240 --> 00:55:42,800
times age square

912
00:55:42,840 --> 00:55:48,450
that's a big savings because it now means that if you have the step size

913
00:55:48,490 --> 00:55:50,590
you're going to decrease the error

914
00:55:50,590 --> 00:55:53,260
by a factor of one quarter

915
00:55:53,300 --> 00:55:54,430
you will

916
00:55:54,450 --> 00:55:56,220
a quarter of the year

917
00:55:56,280 --> 00:56:02,470
now this is the great why should anyone using the well

918
00:56:02,540 --> 00:56:03,950
i think a little second

919
00:56:03,950 --> 00:56:07,200
the real thing which determines how slowly

920
00:56:07,260 --> 00:56:09,740
one of these methods run is

921
00:56:09,780 --> 00:56:13,370
you look at the hardest step of the method and ask how long does the

922
00:56:13,370 --> 00:56:16,890
computer take how many of those hard steps are there

923
00:56:16,910 --> 00:56:19,300
now the answer is the hardest step

924
00:56:19,360 --> 00:56:24,780
is always the evaluation of the slow evaluation of the function

925
00:56:24,820 --> 00:56:28,890
because you know i the functions that are in common use not x squared minus

926
00:56:28,890 --> 00:56:33,840
why square they take at the page and have this coefficient you know ten vessel

927
00:56:33,890 --> 00:56:35,610
place numbers

928
00:56:35,630 --> 00:56:37,140
whatever the guy

929
00:56:37,160 --> 00:56:42,360
the engineers doing it you know whatever their accuracy was

930
00:56:42,410 --> 00:56:47,800
so the thing that controls how long method runs is how many times the slope

931
00:56:47,820 --> 00:56:51,030
the function must be evaluated

932
00:56:51,050 --> 00:56:56,740
four boiler i only have to evaluate it once

933
00:56:56,760 --> 00:57:01,860
here i have two evaluate it twice

934
00:57:02,530 --> 00:57:06,140
roughly speaking the number of function evaluations

935
00:57:06,930 --> 00:57:09,640
each will give you the exponent

936
00:57:09,700 --> 00:57:14,820
the method that's called run kind of fourth order will require four

937
00:57:14,860 --> 00:57:16,910
evaluations of slope

938
00:57:16,910 --> 00:57:20,840
but the accuracy will be like age to the force

939
00:57:20,860 --> 00:57:26,340
very accurate you have the step size goes down by a factor of sixteen

940
00:57:27,340 --> 00:57:28,990
but you had to

941
00:57:29,030 --> 00:57:34,570
do it for you to evaluate the slope four times suppose instead

942
00:57:34,610 --> 00:57:36,780
you had

943
00:57:36,800 --> 00:57:38,860
i have

944
00:57:38,910 --> 00:57:43,390
four times this thing what would you do that you would decrease it to one

945
00:57:43,390 --> 00:57:46,340
sixteen what it was

946
00:57:47,640 --> 00:57:48,570
you would

947
00:57:48,610 --> 00:57:53,090
increase the number of functions evaluation need to

948
00:57:55,530 --> 00:57:56,340
you would have

949
00:57:56,360 --> 00:57:58,820
decrease the by sixteen so

950
00:57:58,840 --> 00:58:00,220
in some sense

951
00:58:00,220 --> 00:58:04,220
it really doesn't matter whether user very fancy that there

952
00:58:04,220 --> 00:58:08,450
which requires more function evaluations studio goes down faster

953
00:58:08,450 --> 00:58:11,800
find theta i can replace by the cosine of the the one

954
00:58:11,820 --> 00:58:15,200
and so i get you know detentions of data one

955
00:58:15,250 --> 00:58:17,190
and so if this is the tangent

956
00:58:17,240 --> 00:58:18,970
of data one

957
00:58:19,020 --> 00:58:20,810
that is under these conditions

958
00:58:21,480 --> 00:58:22,640
we have met

959
00:58:22,650 --> 00:58:27,090
the condition that i was looking for that and that was on the percent

960
00:58:27,150 --> 00:58:29,110
linearly polarized light

961
00:58:29,150 --> 00:58:30,350
so this

962
00:58:30,400 --> 00:58:31,510
is the secret

963
00:58:31,520 --> 00:58:33,660
getting hundred percent polarized light

964
00:58:33,660 --> 00:58:35,100
and this angle

965
00:58:35,120 --> 00:58:37,670
it's called the brewster angle

966
00:58:41,850 --> 00:58:44,990
so if we for instance look at the transition

967
00:58:44,990 --> 00:58:48,260
from air to glass

968
00:58:48,330 --> 00:58:50,450
glass has a index

969
00:58:50,480 --> 00:58:52,000
of refraction

970
00:58:52,020 --> 00:58:54,070
approximately one point five

971
00:58:54,080 --> 00:58:56,850
fans on the kind of glass that you have

972
00:58:56,860 --> 00:58:58,350
if i go from

973
00:58:58,400 --> 00:59:02,250
air to glass which is what i was doing my demonstration

974
00:59:02,300 --> 00:59:06,370
and the tangent of the angle is and two divided by n one

975
00:59:06,390 --> 00:59:09,010
this is class there's one point five

976
00:59:09,020 --> 00:59:10,390
and one is one

977
00:59:10,390 --> 00:59:13,190
and you will find that the brewster angle

978
00:59:13,310 --> 00:59:15,060
they have rooster

979
00:59:15,070 --> 00:59:18,940
it turns out to be about fifty six degree

980
00:59:18,970 --> 00:59:24,180
i can also make linearly polarized light by going from glass to air bouncing out

981
00:59:24,180 --> 00:59:25,120
of this way

982
00:59:25,180 --> 00:59:27,260
and of course i have to invert this

983
00:59:27,280 --> 00:59:29,020
and then you get a brewster angle

984
00:59:29,040 --> 00:59:33,790
which is smaller which is thirty four degrees but since i will do it was

985
00:59:33,800 --> 00:59:35,280
from air to glass

986
00:59:35,290 --> 00:59:38,190
i wanted to concentrate on the fifty six

987
00:59:38,220 --> 00:59:42,180
degree angle

988
00:59:42,300 --> 00:59:44,650
the way i'm going to demonstration

989
00:59:44,660 --> 00:59:48,770
it's right set up here

990
00:59:48,790 --> 00:59:50,250
we have light

991
00:59:50,250 --> 00:59:51,660
like being

992
00:59:51,740 --> 00:59:55,930
that strikes a piece of plane parallel glass that's all of this is nothing special

993
00:59:55,930 --> 00:59:58,190
about this piece of glass

994
00:59:58,240 --> 01:00:01,930
so the light comes in like so

995
01:00:01,940 --> 01:00:03,000
and here

996
01:00:03,020 --> 01:00:06,710
i have a piece of glass

997
01:00:08,350 --> 01:00:11,280
it is the angle of incidence they one

998
01:00:11,360 --> 01:00:14,180
so it's going to be reflected in this direction

999
01:00:14,190 --> 01:00:18,510
by this and is also state along and something will go immediately is angle theta

1000
01:00:18,510 --> 01:00:20,050
two which i don't worry about

1001
01:00:20,180 --> 01:00:22,110
i want you to see that this

1002
01:00:22,270 --> 01:00:25,730
become the percent polarized as this light comes in

1003
01:00:27,290 --> 01:00:30,530
this component this component of equal strength

1004
01:00:30,580 --> 01:00:35,440
if they don't want is fifty six degrees or somewhere in that vicinity

1005
01:00:35,510 --> 01:00:38,000
this slide is now on the percent for

1006
01:00:38,010 --> 01:00:40,600
and i'm going to projected onto the screen

1007
01:00:40,610 --> 01:00:44,460
and i'm going to convince you that it is indeed polarized

1008
01:00:44,460 --> 01:00:47,460
you cannot use your own polarizes to see that

1009
01:00:47,510 --> 01:00:49,800
because the lights in this being

1010
01:00:49,860 --> 01:00:50,930
is going to be

1011
01:00:50,930 --> 01:00:53,100
one hundred percent polarized

1012
01:00:54,240 --> 01:00:58,140
once it reflects off the screen it no longer is so you cannot you should

1013
01:00:58,140 --> 01:01:00,570
polarimeter so i have to use my own parameter

1014
01:01:00,590 --> 01:01:02,530
to show you this

1015
01:01:02,570 --> 01:01:06,930
so we can turn the light of their of the overhead thank you very much

1016
01:01:06,970 --> 01:01:08,020
i will

1017
01:01:08,040 --> 01:01:11,450
turn on the

1018
01:01:11,450 --> 01:01:12,660
the life of my

1019
01:01:12,670 --> 01:01:16,450
like being there this and i'm going to make it very dark for you

1020
01:01:16,460 --> 01:01:19,930
so that we can see that very well

1021
01:01:20,000 --> 01:01:21,510
so to light

1022
01:01:21,580 --> 01:01:23,840
comes it is direction hits the glass

1023
01:01:23,930 --> 01:01:27,470
and the angle of incidence is now about forty five degrees

1024
01:01:27,480 --> 01:01:29,950
i purposely didn't make it fifty six yet

1025
01:01:29,960 --> 01:01:34,840
i view a large sheet of polarized one of edwin land or arises and i'll

1026
01:01:34,860 --> 01:01:36,900
rotate it in this b

1027
01:01:36,910 --> 01:01:42,250
you'll see this partially polarized not yet on the percent but it's already partially polarized

1028
01:01:42,340 --> 01:01:47,490
so is already in balance between the two perpendicular and parallel components

1029
01:01:47,540 --> 01:01:49,180
so if whole it into being

1030
01:01:49,220 --> 01:01:50,970
and i rotated

1031
01:01:50,980 --> 01:01:52,640
you will clearly see now

1032
01:01:52,650 --> 01:01:55,260
it it is much fainter

1033
01:01:56,620 --> 01:01:58,580
and it is now

1034
01:01:58,600 --> 01:02:03,510
now i will go for the fifty six angle fifty six degree angle roughly

1035
01:02:03,550 --> 01:02:05,180
so now

1036
01:02:05,210 --> 01:02:06,490
i rotate my

1037
01:02:08,980 --> 01:02:11,410
notice i can kill them like complete

1038
01:02:11,460 --> 01:02:16,500
one the percent linearly polarized i may not have the angle perfect but that's okay

1039
01:02:16,510 --> 01:02:19,120
you get the idea very close

1040
01:02:19,180 --> 01:02:22,660
totally dark

1041
01:02:22,670 --> 01:02:25,900
now you see the light

1042
01:02:25,910 --> 01:02:27,600
all rights in this election

1043
01:02:27,660 --> 01:02:30,410
now i can kill it

1044
01:02:30,500 --> 01:02:32,660
so it is quite remarkable thing

1045
01:02:32,680 --> 01:02:36,240
that if we reflect light of the dielectric

1046
01:02:36,260 --> 01:02:37,450
that we can

1047
01:02:37,690 --> 01:02:39,990
one angle in one language only

1048
01:02:40,000 --> 01:02:41,550
which is the brewster angle

1049
01:02:41,580 --> 01:02:47,490
we can turn it into a hundred percent linearly polarized light

1050
01:02:49,710 --> 01:02:51,790
does not apply to conductors

1051
01:02:51,840 --> 01:02:56,470
the behaviour of conductors is very different from dielectric success such as water

1052
01:02:56,470 --> 01:02:58,270
and glass

1053
01:02:58,340 --> 01:03:01,330
you can use maxwell's equations of course to study

1054
01:03:01,340 --> 01:03:04,390
reflection of electromagnetic waves

1055
01:03:06,590 --> 01:03:08,850
but you get very different results

1056
01:03:08,900 --> 01:03:13,940
so never expect to get linearly polarized light responses of metals

1057
01:03:13,950 --> 01:03:15,760
i have you for your pleasure

1058
01:03:15,820 --> 01:03:17,710
the metal sphere and i have

1059
01:03:17,800 --> 01:03:19,050
glass sphere

1060
01:03:19,110 --> 01:03:22,180
and if you still have a linear polarizer is at hand

1061
01:03:22,220 --> 01:03:26,250
you can now our little later just hold them in front of your eyes

1062
01:03:26,290 --> 01:03:28,080
and rotate them around

1063
01:03:28,120 --> 01:03:32,230
of course you're not seeing the light at the brewster angle the chances i

1064
01:03:32,240 --> 01:03:35,850
that some of the light that is reflected of this class that you can clearly

1065
01:03:35,850 --> 01:03:39,010
see this partially polarized you can see it

1066
01:03:39,080 --> 01:03:43,470
the difference in light intensity as you rotate it not going to see that of

1067
01:03:43,470 --> 01:03:47,930
this metal

1068
01:03:48,600 --> 01:03:50,550
i come to a very

1069
01:03:54,720 --> 01:03:58,810
there is a third way that we can make on percent linear polarized light

1070
01:03:58,870 --> 01:04:02,620
by the scattering of unpolarized light

1071
01:04:02,670 --> 01:04:06,510
we have to scan of very fine particles preferably

1072
01:04:06,600 --> 01:04:08,260
tens of micron

1073
01:04:08,270 --> 01:04:11,330
dust particles will work very well

1074
01:04:11,340 --> 01:04:14,590
the theory of light scattering is extremely complicated

1075
01:04:14,600 --> 01:04:16,980
but i will be able to convince you

1076
01:04:17,020 --> 01:04:18,920
that if i scatter the light

1077
01:04:18,930 --> 01:04:23,480
over an angle of ninety degrees or comes in like this this carries over an

1078
01:04:23,480 --> 01:04:24,960
angle of ninety degrees

1079
01:04:24,980 --> 01:04:26,280
that it becomes

1080
01:04:26,300 --> 01:04:28,300
one hundred percent linearly

1081
01:04:30,430 --> 01:04:33,410
i will stay on the centre board

1082
01:04:33,490 --> 01:04:35,410
suppose i have light coming in

1083
01:04:35,460 --> 01:04:37,240
like so

1084
01:04:37,250 --> 01:04:39,620
and i one light photons

1085
01:04:39,640 --> 01:04:41,080
concentrate on one

1086
01:04:41,110 --> 01:04:44,590
to start with and it happens to be that light photon

1087
01:04:44,640 --> 01:04:47,210
is linearly polarized in this direction

1088
01:04:47,310 --> 01:04:50,840
so in effect it was also like this

1089
01:04:50,900 --> 01:04:55,540
later we're going to have all the directions that we want to just pick one

1090
01:04:55,590 --> 01:04:56,590
and here

1091
01:04:56,600 --> 01:04:58,460
i am i find dust particles

1092
01:04:58,670 --> 01:05:01,870
and these dust particles of electrons

1093
01:05:01,910 --> 01:05:03,320
and the electric field

1094
01:05:03,350 --> 01:05:04,830
passers-by by

1095
01:05:04,840 --> 01:05:06,900
these electrons which charged

1096
01:05:06,910 --> 01:05:09,350
i going to oscillate in this direction

1097
01:05:09,420 --> 01:05:11,910
they're going to experience acceleration

1098
01:05:11,920 --> 01:05:16,500
which is the force that they experience divided by the mass

1099
01:05:16,500 --> 01:05:19,430
and therefore that is the charge that they have

1100
01:05:19,710 --> 01:05:22,580
the electric field divided by the mass

1101
01:05:22,600 --> 01:05:25,020
so as the electric field vector

1102
01:05:25,110 --> 01:05:30,010
this electric field component oscillating with frequencies omega

1103
01:05:30,100 --> 01:05:33,030
passing by these electrons they themselves

1104
01:05:33,040 --> 01:05:34,900
i going to oscillate

1105
01:05:34,930 --> 01:05:37,070
with the frequency omega

1106
01:05:37,090 --> 01:05:38,480
and this is the force

1107
01:05:38,510 --> 01:05:42,010
they will experience this acceleration

1108
01:05:42,030 --> 01:05:46,720
notice that the electrons will experience away high acceleration than the protons

1109
01:05:46,720 --> 01:05:48,840
because the protons have amassed which is

1110
01:05:48,910 --> 01:05:52,830
more than eighteen hundred times larger than the electrons so whatever follows

1111
01:05:52,870 --> 01:05:56,290
it's really electrons that do the job and not the

1112
01:05:57,780 --> 01:05:59,250
so we have

1113
01:05:59,250 --> 01:06:01,800
charges that move up and down

1114
01:06:01,850 --> 01:06:03,470
and now comes the question

1115
01:06:03,510 --> 01:06:06,700
which we have discussed earlier this is just simply too

1116
01:06:06,700 --> 01:06:11,120
and not a lot of this is again trying to take us towards concept which

1117
01:06:11,120 --> 01:06:14,970
are in some ways more natural are interesting how would you know which which to

1118
01:06:14,970 --> 01:06:19,830
us doesn't necessarily mean higher dimensional data although it might but often means datasets with

1119
01:06:19,830 --> 01:06:24,020
more interesting structure the kinds of things that that human cognition is really good but

1120
01:06:24,020 --> 01:06:27,700
traditional statistics is is not really but i mean to be basically the same kind

1121
01:06:27,700 --> 01:06:29,720
of thing that jeff was talking about

1122
01:06:29,740 --> 01:06:36,200
so here's here's an example of a more natural dataset that you might use to

1123
01:06:36,200 --> 01:06:42,930
study human concept learning categorisation and generalization we have a bunch of animal categories here

1124
01:06:42,930 --> 01:06:49,180
and here along the columns we have a bunch of properties these are not really

1125
01:06:49,180 --> 01:06:52,350
perceptual features of the kinds of things that you know if you go with your

1126
01:06:52,370 --> 01:06:56,020
child going around the zoo or reading a picture book or something you know you

1127
01:06:56,040 --> 01:06:59,860
these are the sorts of things that you can notice in your perceptual data and

1128
01:06:59,860 --> 01:07:03,720
the adults will often point out and say look about one that one eats bugs

1129
01:07:03,720 --> 01:07:10,970
or something eats bugs and so this this matrix represents one naive subjects

1130
01:07:10,990 --> 01:07:15,830
semi naive subjects judgments of

1131
01:07:15,850 --> 01:07:17,970
for each of these

1132
01:07:18,020 --> 01:07:22,450
species whether or not they have each of these properties and there's actually i think

1133
01:07:22,450 --> 01:07:26,760
i've only label every other property there's something like one hundred twenty properties in

1134
01:07:26,770 --> 01:07:29,260
and a lot of

1135
01:07:29,270 --> 01:07:33,270
a lot of cognitive science work on categorization has been done with animal species both

1136
01:07:33,270 --> 01:07:38,870
categorize categorizing things into species but also categorizing species into higher categories just so what

1137
01:07:38,870 --> 01:07:42,640
happens if we take this data set and just run regular mixture model on it

1138
01:07:42,840 --> 01:07:46,680
will just try to discover an unsupervised way the categories that are here

1139
01:07:46,700 --> 01:07:52,630
well this is the result of running CRP mixture basically a dirichlet process mixture where

1140
01:07:52,630 --> 01:07:55,180
we get we don't have to know how many categories are around we discovered these

1141
01:07:55,180 --> 01:08:00,180
four categories which we've just reorganized the rose to group them the animals according to

1142
01:08:00,180 --> 01:08:05,160
the categories discovered by the mixture model have also reorganized the columns so that the

1143
01:08:05,160 --> 01:08:09,160
ones which are cleanest are over here on the left those of those are also

1144
01:08:09,160 --> 01:08:14,140
the ones which have the highest likelihood basically under the model because the

1145
01:08:17,370 --> 01:08:22,560
the multinomial which in this case is the binomial basically wants to have features clean

1146
01:08:22,560 --> 01:08:26,160
within categories and essentially what it's doing here is it's looking for a way of

1147
01:08:26,160 --> 01:08:28,740
chopping up the the objects

1148
01:08:28,790 --> 01:08:33,640
into categories such that as many features as possible are as clean as possible and

1149
01:08:33,640 --> 01:08:37,890
it's making a trade-off between wanting to put things into smaller smaller number of categories

1150
01:08:37,890 --> 01:08:41,970
that's coming from the chinese restaurant process prior and won in the categories to be

1151
01:08:41,970 --> 01:08:45,390
as clean as possible and that depending on exactly how you set the parameters of

1152
01:08:45,390 --> 01:08:48,060
the prior you can get very straight as you can you can always make the

1153
01:08:48,060 --> 01:08:52,200
categories really clean by making them really small or you can if you can make

1154
01:08:52,200 --> 01:08:55,160
them really begin to have a few categories if you're willing to tolerate some amount

1155
01:08:55,160 --> 01:08:59,470
of messina and how the features are spread spread out within the category this is

1156
01:08:59,470 --> 01:09:03,330
this is a pretty reasonable compromise so you can see that forms the four categories

1157
01:09:03,330 --> 01:09:07,830
are these large taxonomic categories like the kind of things the biologist my talk about

1158
01:09:07,890 --> 01:09:12,680
who's interested in in evolution or categorizing species these ones are all mammals

1159
01:09:12,680 --> 01:09:14,160
including things that are

1160
01:09:14,180 --> 01:09:16,910
somewhat atypical animals like bats and seals

1161
01:09:16,930 --> 01:09:18,540
these ones here are

1162
01:09:18,560 --> 01:09:21,100
reptiles and amphibians these are birds

1163
01:09:21,120 --> 01:09:23,560
these ones are insects and invertebrates

1164
01:09:23,560 --> 01:09:27,120
and that way of organizing the animals makes a fair amount of sense of the

1165
01:09:27,200 --> 01:09:30,370
of the features you can see also the features that come out clean are the

1166
01:09:30,370 --> 01:09:31,870
ones that do that

1167
01:09:31,890 --> 01:09:36,240
you know traditional biologists would use in trying to classify species of things like having

1168
01:09:36,240 --> 01:09:40,990
a peak have having bones has long has tasks is the k nine is officially

1169
01:09:41,020 --> 01:09:43,390
road and is warm-blooded

1170
01:09:43,620 --> 01:09:45,560
sort of deep anatomical

1171
01:09:45,600 --> 01:09:47,770
physiological properties

1172
01:09:48,490 --> 01:09:49,830
the course

1173
01:09:49,830 --> 01:09:53,290
about just wouldn't take is a k nine as a feature that would be kind

1174
01:09:53,290 --> 01:09:56,430
of a little bit too you know to achieve learning these things those that might

1175
01:09:56,430 --> 01:09:59,680
be something that somebody might come our is official something

1176
01:09:59,700 --> 01:10:03,700
so those are just treated as data here now there's all these other features over

1177
01:10:03,700 --> 01:10:08,810
here which are not the ones of traditional taxonomic interest in biology like lives in

1178
01:10:08,810 --> 01:10:15,160
the grass or makes loud noises or is large or is yellow and so on

1179
01:10:16,810 --> 01:10:21,640
when you organize the the animals taxonomic lee these just look like noise that's what

1180
01:10:21,640 --> 01:10:26,450
biologists don't pay attention to so biologist might who's interested in classifying things in this

1181
01:10:27,080 --> 01:10:30,580
you might know the the the whole point is to do a kind of model

1182
01:10:30,580 --> 01:10:33,370
based feature selection and to be able to say well

1183
01:10:33,390 --> 01:10:38,240
these features over here are interesting maybe somebody but they are not informative about the

1184
01:10:38,240 --> 01:10:43,720
most useful way to categorize these objects and acquire basic question though that confronts us

1185
01:10:43,720 --> 01:10:47,140
when we do a lot of interesting certainly i problems for a lot of real-world

1186
01:10:47,140 --> 01:10:51,680
machine learning problems we have all these features we might measure another anyway one way

1187
01:10:51,680 --> 01:10:55,850
of organizing the domain the objects many of the features are going to look like

1188
01:10:55,850 --> 01:10:59,370
noise and so the real question is are these really nice or maybe there's some

1189
01:10:59,370 --> 01:11:03,970
structure there but it's just not the structure and by finding a single clustering like

1190
01:11:03,970 --> 01:11:05,580
this were missing that

1191
01:11:05,580 --> 01:11:08,390
so we we propose to model which we try to

1192
01:11:08,410 --> 01:11:14,870
if you like assessed whether there are other forms of structure maybe maybe maybe

1193
01:11:14,930 --> 01:11:18,140
one of the way of clustering is things are any number of ways that that's

1194
01:11:18,140 --> 01:11:24,660
actually a nonparametric model where it's going to consider ways of incense grouping the features

1195
01:11:25,020 --> 01:11:29,270
into subdomains each of which might support a different way of grouping the object of

1196
01:11:29,270 --> 01:11:32,950
the rows so i will tell you about the the math too much of this

1197
01:11:32,950 --> 01:11:35,720
but i'll just show you a picture and talk qualitatively about the matter if you're

1198
01:11:35,720 --> 01:11:39,180
interested you can you can look at the paper by pat shafto and others

1199
01:11:39,200 --> 01:11:44,290
the model is called cross cap for cross categorization and the idea it's and it's

1200
01:11:44,350 --> 01:11:46,870
interesting kind of nested nonparametric

1201
01:11:46,930 --> 01:11:51,120
model in which at the top level you have this

1202
01:11:51,180 --> 01:11:57,410
this nonparametric mixture over the columns of the features so it's again it is there's

1203
01:11:57,410 --> 01:12:01,180
probably some version of the dirichlet process that this corresponds to

1204
01:12:03,260 --> 01:12:05,410
we do we just use the chinese restaurant

1205
01:12:05,430 --> 01:12:07,080
process combinatorial

1206
01:12:07,080 --> 01:12:11,990
prior over these guys to basically consider all consider all possible ways of grouping the

1207
01:12:11,990 --> 01:12:17,100
columns into subsets which tends to prefer a small number of subsets for this

1208
01:12:17,120 --> 01:12:20,160
dataset here the model finds usually there are two or three

1209
01:12:20,180 --> 01:12:25,290
systems of categorization or two or three clusters of features where each feature each cluster

1210
01:12:25,290 --> 01:12:30,830
feature is then exposed explained by different way of clustering the animals so within each

1211
01:12:30,830 --> 01:12:35,600
one of the partitions of features the model defines the different dirichlet process mixture over

1212
01:12:35,600 --> 01:12:40,040
the the objects of the rows so it's like one high-level one that goes by

1213
01:12:40,040 --> 01:12:45,580
column and then within each cut of the columns a different one by road

1214
01:12:45,600 --> 01:12:51,180
so what we can see that the model finds here is it finds the kind

1215
01:12:51,180 --> 01:12:55,020
of the biggest set of features that the dominant position is just the one that

1216
01:12:55,020 --> 01:13:00,930
the regular mixture model finds its taxonomic organisation and again it's it's being supported by

1217
01:13:00,930 --> 01:13:04,930
features like having bones are laying eggs are being warm-blooded are being a mammal

1218
01:13:04,950 --> 01:13:10,060
but then there's there's two other subsets of let's talk about this one first

1219
01:13:10,080 --> 01:13:11,080
this one here

1220
01:13:11,100 --> 01:13:15,240
well will look at the work of the organization the animals so one category has

1221
01:13:15,240 --> 01:13:17,640
leopard alligator pie

1222
01:13:17,790 --> 01:13:23,020
another one has seal dolphin frog jellyfish octopus penguins

1223
01:13:23,060 --> 01:13:26,830
then you have a pinch single owl eagle dragonfly back

1224
01:13:26,890 --> 01:13:31,700
grasshopper and PC monkey gone austria so this is this is pretty interesting right can

1225
01:13:31,700 --> 01:13:33,390
you see what's going on here

1226
01:13:33,410 --> 01:13:36,970
how would you describe this

1227
01:13:41,080 --> 01:13:44,890
what is very much not taxonomic right because you have a mammal a bat and

1228
01:13:44,890 --> 01:13:46,410
insect dragonfly

1229
01:13:46,410 --> 01:13:47,600
a birdie eagle

1230
01:13:48,720 --> 01:13:52,370
or you have here you have a seal and dolphin are mammals in their with

1231
01:13:52,370 --> 01:13:53,990
invertebrates and

1232
01:13:54,040 --> 01:13:56,200
birds like penguins

1233
01:13:56,200 --> 01:14:00,910
basically where they live right so these are all things that live in the water

1234
01:14:00,910 --> 01:14:04,930
if a given probability distribution respects

1235
01:14:04,950 --> 01:14:07,450
conditional independence statements

1236
01:14:07,450 --> 01:14:09,950
that are given by graph separation

1237
01:14:09,970 --> 01:14:11,640
in some

1238
01:14:11,690 --> 01:14:13,670
graph g

1239
01:14:13,680 --> 01:14:16,290
then the distribution will

1240
01:14:17,660 --> 01:14:21,590
according to the graph g as given by the problem over the clique

1241
01:14:21,610 --> 01:14:25,320
of arbitrary non negative potential function calls

1242
01:14:31,360 --> 01:14:33,690
and also why this is important well

1243
01:14:33,710 --> 01:14:37,390
it is important for the same reason that it was important to with bayesian networks

1244
01:14:37,390 --> 01:14:38,440
over here

1245
01:14:39,210 --> 01:14:45,110
conditional independence statements are usually what is known by the expert by the domain expert

1246
01:14:45,110 --> 01:14:49,430
is usually what you can see from

1247
01:14:49,460 --> 01:14:52,610
and the expert needs the model in order to compute things in order to be

1248
01:14:52,610 --> 01:14:53,290
able to

1249
01:14:53,310 --> 01:14:58,600
perform creates on the probability distribution p of that

1250
01:14:58,640 --> 01:15:05,250
right and in order

1251
01:15:05,330 --> 01:15:09,740
for both types of graphical models

1252
01:15:09,750 --> 01:15:13,080
bayesian networks and markov random field

1253
01:15:13,490 --> 01:15:18,630
we have a relationship between the conditional independence statements

1254
01:15:19,930 --> 01:15:24,570
some simplified algebraic structure of the probability distribution

1255
01:15:24,610 --> 01:15:26,070
in terms of

1256
01:15:27,680 --> 01:15:30,460
it can be represented in in terms of ground

1257
01:15:30,470 --> 01:15:31,970
so in both cases

1258
01:15:31,990 --> 01:15:33,100
we have

1259
01:15:36,330 --> 01:15:38,130
classes of

1260
01:15:38,160 --> 01:15:42,190
probit models

1261
01:15:42,380 --> 01:15:47,690
that are obtained from conditional independence statements that are mapped the two

1262
01:15:47,720 --> 01:15:49,940
lack of edges if you will

1263
01:15:50,970 --> 01:15:54,740
in a bayesian network in the directed graph or

1264
01:15:54,800 --> 01:15:56,860
in america from the field

1265
01:15:56,880 --> 01:15:59,580
because you precisely how

1266
01:15:59,630 --> 01:16:03,080
conditional independence statements when you pull off

1267
01:16:03,130 --> 01:16:04,580
and the edge

1268
01:16:06,050 --> 01:16:08,050
one of these drugs

1269
01:16:08,190 --> 01:16:11,970
and the particular type of

1270
01:16:11,980 --> 01:16:14,950
the simplified algebraic structure is the factories

1271
01:16:15,840 --> 01:16:20,040
it's related to local pieces of the graph at what are the local pieces in

1272
01:16:20,060 --> 01:16:22,090
the case of bayesian networks

1273
01:16:22,130 --> 01:16:24,310
the child the

1274
01:16:24,350 --> 01:16:25,690
in the past

1275
01:16:25,690 --> 01:16:30,760
the local piece in the case of markov random fields is the clique

1276
01:16:30,820 --> 01:16:32,120
right so

1277
01:16:32,130 --> 01:16:35,720
the factorisation of probabilistic model

1278
01:16:35,720 --> 01:16:37,570
four patient approaches

1279
01:16:37,570 --> 01:16:40,700
these effects precision over

1280
01:16:41,620 --> 01:16:43,030
factors of

1281
01:16:43,070 --> 01:16:45,910
that depends on the trophy fish set of

1282
01:16:47,880 --> 01:16:55,160
the markov and feels it depends on all the virus initially

1283
01:16:55,170 --> 01:16:59,480
but there are also important differences and should mention them here

1284
01:16:59,500 --> 01:17:02,120
let's keep them in mind all the time

1285
01:17:02,160 --> 01:17:05,100
first and this is something we have already

1286
01:17:05,100 --> 01:17:06,750
such previously

1287
01:17:06,780 --> 01:17:11,440
this set of probability distributions that can be represented

1288
01:17:12,380 --> 01:17:17,780
actually as a perfect map is rule system as a marketing tool is different from

1289
01:17:17,780 --> 01:17:21,160
that so that people can be represented as the vision as

1290
01:17:25,190 --> 01:17:30,440
they both are expressed in terms of factorizations but you have noted that in the

1291
01:17:30,440 --> 01:17:31,600
case of

1292
01:17:31,660 --> 01:17:33,620
a marker were killed we have

1293
01:17:33,630 --> 01:17:35,200
and normalisation

1294
01:17:35,220 --> 01:17:36,910
constant c

1295
01:17:36,920 --> 01:17:43,260
that needs to be included in the factorisation because we want to allow for arbitrary

1296
01:17:44,190 --> 01:17:46,040
c of xy

1297
01:17:46,130 --> 01:17:49,060
so we need in the case of markov random fields

1298
01:17:49,090 --> 01:17:51,450
is normalisation function

1299
01:17:53,470 --> 01:17:57,650
he is also not a major problem learning for example

1300
01:17:57,690 --> 01:18:01,600
they want to actually perform learning on market hill because you need to estimate this

1301
01:18:02,820 --> 01:18:03,950
for some

1302
01:18:03,970 --> 01:18:07,320
complex macromolecules estimating this one is very

1303
01:18:07,380 --> 01:18:12,850
very tissue

1304
01:18:14,250 --> 01:18:19,090
the local pieces of the vision that according local factors

1305
01:18:19,100 --> 01:18:22,760
they are probability distributions themselves remember that

1306
01:18:22,780 --> 01:18:24,450
in the vision all

1307
01:18:24,460 --> 01:18:30,360
you have as each factor the probability of a child given parent

1308
01:18:30,410 --> 01:18:32,870
but for microphone it's

1309
01:18:32,920 --> 01:18:36,720
it's a non negative function as well like probability function

1310
01:18:36,790 --> 01:18:40,310
but it's not necessarily normalized to one

1311
01:18:40,330 --> 01:18:45,110
it's just a function that gives you some number which is negative number

1312
01:18:45,110 --> 01:18:46,580
so for each tissue

1313
01:18:46,590 --> 01:18:47,640
we have

1314
01:18:47,650 --> 01:18:49,830
measured some expression of

1315
01:18:49,830 --> 01:18:52,480
of proteins so for example let's say

1316
01:18:52,720 --> 01:18:54,480
on the on the tissue

1317
01:18:54,840 --> 01:18:56,180
let's say for the

1318
01:18:56,700 --> 01:18:58,080
healthy tissue

1319
01:18:58,130 --> 01:19:01,200
this is the healthy tissue we measured

1320
01:19:01,250 --> 01:19:06,110
g one the expression was low that means protein protein

1321
01:19:06,160 --> 01:19:10,670
expressed as a result of a group of gene one was low

1322
01:19:10,800 --> 01:19:12,150
gene two is high

1323
01:19:12,160 --> 01:19:13,580
the gene three is low

1324
01:19:13,580 --> 01:19:15,280
and for gene four is high

1325
01:19:15,320 --> 01:19:19,110
so so that's how it's all expressed in i know we have to start

1326
01:19:19,160 --> 01:19:20,820
so so what you can see

1327
01:19:20,830 --> 01:19:22,590
in this example is that

1328
01:19:22,650 --> 01:19:24,600
i hope you can see the colours

1329
01:19:24,610 --> 01:19:27,660
there is this one this box

1330
01:19:27,680 --> 01:19:29,310
this shows you

1331
01:19:29,310 --> 01:19:31,240
these these

1332
01:19:31,270 --> 01:19:33,070
this tissue and this tissue

1333
01:19:33,080 --> 01:19:33,890
i have

1334
01:19:33,900 --> 01:19:37,290
common pattern of expression low high and low

1335
01:19:38,420 --> 01:19:39,330
and that

1336
01:19:39,340 --> 01:19:42,340
combination never appears in the one

1337
01:19:42,340 --> 01:19:46,840
so what you can say is that now i observed a contrast pattern which says

1338
01:19:46,910 --> 01:19:48,050
gene one

1339
01:19:48,070 --> 01:19:49,570
expression is low

1340
01:19:49,580 --> 01:19:51,360
gene two expression is high

1341
01:19:51,410 --> 01:19:53,580
gene three group of expression is low

1342
01:19:53,580 --> 01:19:55,840
so that we see

1343
01:19:55,910 --> 01:19:58,800
fifty percent of the tissues that we look at

1344
01:19:58,810 --> 01:20:00,560
i'm never happens here

1345
01:20:00,570 --> 01:20:02,510
so therefore we conclude that

1346
01:20:02,520 --> 01:20:06,890
g one equal to ldt equal to g equal to l

1347
01:20:07,620 --> 01:20:11,470
is an emerging pattern because somehow

1348
01:20:11,500 --> 01:20:14,050
what differentiates these two groups

1349
01:20:14,100 --> 01:20:15,600
can not in each case

1350
01:20:15,620 --> 01:20:21,840
but there is insufficient evidence to believe this is an interesting pattern

1351
01:20:21,850 --> 01:20:23,490
so this is the real data

1352
01:20:23,820 --> 01:20:27,580
so this is that it comes from one of the published

1353
01:20:28,230 --> 01:20:32,390
that in nineteen ninety nine in colon cancer datasets

1354
01:20:32,440 --> 01:20:33,770
there are forty

1355
01:20:33,770 --> 01:20:36,270
cancerous tissues and twenty normal

1356
01:20:36,320 --> 01:20:40,950
so these are all gene expressions somehow the gene expressions are grouped into

1357
01:20:40,970 --> 01:20:43,470
i to these things there's about two thousand

1358
01:20:43,490 --> 01:20:46,020
genes and then they were reduced to

1359
01:20:46,090 --> 01:20:49,580
something like two hundred fifty or three hundred groups

1360
01:20:50,030 --> 01:20:53,970
because what they found is some genes were expressing together

1361
01:20:53,980 --> 01:20:56,070
so so for example

1362
01:20:56,080 --> 01:21:01,310
a groups of genes which labeled as you know one

1363
01:21:01,310 --> 01:21:02,420
one last

1364
01:21:02,440 --> 01:21:03,980
four miners

1365
01:21:03,990 --> 01:21:07,850
one two plus one thirteen plus the appears

1366
01:21:07,870 --> 01:21:09,160
a hundred per cent

1367
01:21:09,180 --> 01:21:12,500
in the colon cancer and never appeared in the

1368
01:21:12,590 --> 01:21:14,150
in the other case

1369
01:21:14,250 --> 01:21:19,730
so so you see that these patterns are incredibly dominant in the colon cancer and

1370
01:21:19,730 --> 01:21:20,660
this is

1371
01:21:21,070 --> 01:21:23,770
in in the in the in the cancer case

1372
01:21:24,240 --> 01:21:25,800
and in the normal case

1373
01:21:25,970 --> 01:21:28,070
these are the dominant features

1374
01:21:28,120 --> 01:21:31,130
so you can see that there are quite quite substantial

1375
01:21:31,180 --> 01:21:32,690
and these patterns

1376
01:21:32,700 --> 01:21:34,950
might actually indicate something to do

1377
01:21:34,990 --> 01:21:39,030
the disease and that's the kind of conclusion you could make here

1378
01:21:39,080 --> 01:21:42,370
so what you want to do is to find the minimum set

1379
01:21:42,380 --> 01:21:44,140
the minimal patterns

1380
01:21:45,990 --> 01:21:48,470
that appear so for example it's say a

1381
01:21:48,470 --> 01:21:50,220
you find the minimal

1382
01:21:51,660 --> 01:21:53,510
in the normal tissue that means

1383
01:21:53,510 --> 01:21:58,660
this pattern appeared only in the normal tissues and never appeared in the cancerous ones

1384
01:21:59,680 --> 01:22:02,320
so it so this could be an indication for

1385
01:22:02,320 --> 01:22:03,680
you know somebody

1386
01:22:03,700 --> 01:22:05,700
trying to come up with a drugs

1387
01:22:05,780 --> 01:22:07,010
to see that

1388
01:22:07,050 --> 01:22:10,550
properly expressed gene groups important for normal

1389
01:22:10,570 --> 01:22:12,300
so functioning

1390
01:22:12,320 --> 01:22:14,070
but they are destroyed

1391
01:22:14,070 --> 01:22:15,160
in the case of

1392
01:22:15,180 --> 01:22:16,620
colon cancer

1393
01:22:17,510 --> 01:22:21,010
so you make a hypothesis if i can restore them some

1394
01:22:21,010 --> 01:22:26,820
can i can i cure cancer that is the kind of hypothesis that could have

1395
01:22:26,850 --> 01:22:28,550
or the other way

1396
01:22:28,550 --> 01:22:32,010
that is we follow a group of genes

1397
01:22:32,070 --> 01:22:34,840
very active in the case of

1398
01:22:34,850 --> 01:22:36,820
patients with cancer

1399
01:22:36,820 --> 01:22:40,820
these are the bad genes some of turned on the should not

1400
01:22:40,840 --> 01:22:43,910
is there a way you can suppress is there

1401
01:22:43,950 --> 01:22:48,430
why do that can either the things

1402
01:22:48,430 --> 01:22:52,740
now the interesting thing is that you know in medicine you know they

1403
01:22:52,740 --> 01:22:57,510
you already have a good knowledge of how to turn on certain genes how to

1404
01:22:57,510 --> 01:23:00,470
turn off by using drugs

1405
01:23:00,700 --> 01:23:03,510
because what happens is they might have studied

1406
01:23:03,510 --> 01:23:06,820
some drugs in the context of some other diseases

1407
01:23:06,820 --> 01:23:12,700
and they find that same patterns of genes are common between diseases so therefore

1408
01:23:12,740 --> 01:23:16,120
sometimes it is quite easy for them said well we know that

1409
01:23:16,200 --> 01:23:21,350
this particular drug certainly can turn on this gene i'm going to block the particular

1410
01:23:22,120 --> 01:23:26,220
so we know that we have already gone the child and we have good evidence

1411
01:23:26,220 --> 01:23:31,300
here we're going to mister straighter and so for example in the FDA in the

1412
01:23:32,300 --> 01:23:34,410
no food and drug administration

1413
01:23:34,450 --> 01:23:36,240
you know this is the body

1414
01:23:36,260 --> 01:23:37,320
it has two

1415
01:23:37,350 --> 01:23:38,490
give approval

1416
01:23:38,550 --> 01:23:41,490
before medication is available for large population

1417
01:23:41,530 --> 01:23:44,930
so generally what happens is from the discovery

1418
01:23:44,970 --> 01:23:46,410
to the properties

1419
01:23:46,450 --> 01:23:48,370
could be ten to fifteen years

1420
01:23:49,840 --> 01:23:52,800
and the and the two and there's a lot of hope here is that if

1421
01:23:52,820 --> 01:23:57,470
there is already drugs that have been approved by the FDA

1422
01:23:57,490 --> 01:24:01,780
the clearances are much much easier because they already have studied these drugs

1423
01:24:01,800 --> 01:24:07,410
then all side effects so therefore they know what the safety margin for these studies

1424
01:24:07,410 --> 01:24:11,120
so they have very quickly they can administer these drugs

1425
01:24:11,160 --> 01:24:12,220
and then

1426
01:24:12,240 --> 01:24:13,890
if the drugs were

1427
01:24:13,890 --> 01:24:17,340
they can bring the drugs very very quickly to the

1428
01:24:17,450 --> 01:24:18,910
to the practice

1429
01:24:19,620 --> 01:24:23,760
so people are incredibly happy with this kind of model so if you know exactly

1430
01:24:23,760 --> 01:24:24,760
what's happening

1431
01:24:24,850 --> 01:24:27,840
and if you have a prior approval for these drugs

1432
01:24:28,870 --> 01:24:30,780
the daily medication is

1433
01:24:30,800 --> 01:24:36,500
very short and also the expenses that don't require you know sit typically they say

1434
01:24:37,140 --> 01:24:39,820
if you discover a drug that works

1435
01:24:39,870 --> 01:24:43,970
usually need you know how to build a billion dollars

1436
01:24:45,450 --> 01:24:48,370
before the track could be a problem

1437
01:24:48,470 --> 01:24:53,260
and that's why medications could be incredibly expensive because the the long period of waiting

1438
01:24:53,260 --> 01:24:56,530
lot of money and still there is a lot of risk sometimes

1439
01:24:56,640 --> 01:24:58,660
they go to the whole scheme

1440
01:24:58,680 --> 01:24:59,320
and then

1441
01:24:59,370 --> 01:25:04,510
five years later they find that the hormone replacement therapy

1442
01:25:04,530 --> 01:25:06,580
it has very high

1443
01:25:06,640 --> 01:25:08,600
correlation to cause cancer

1444
01:25:08,620 --> 01:25:09,510
know then

1445
01:25:09,530 --> 01:25:13,850
all these billions of dollars this painting studying and millions

1446
01:25:14,700 --> 01:25:17,050
of women having these

1447
01:25:17,100 --> 01:25:18,600
you know

1448
01:25:18,930 --> 01:25:20,800
this the this therapy

1449
01:25:20,850 --> 01:25:24,350
probably would go class action against the companies because

1450
01:25:24,370 --> 01:25:27,740
they have not done a proper job so lots of

1451
01:25:29,390 --> 01:25:34,030
conservative so this can this could kind of health

1452
01:25:34,070 --> 01:25:38,070
and also was talking to some of the volunteers they say that you know when

1453
01:25:38,800 --> 01:25:40,850
try to study these things

1454
01:25:41,160 --> 01:25:42,470
they don't

1455
01:25:42,530 --> 01:25:46,680
you know like for example a lot of nice they can actually manufacture

1456
01:25:47,990 --> 01:25:51,390
with a different kind of genes they can knock off exactly

1457
01:25:51,450 --> 01:25:55,800
what kind of gene to knock off and watertight on and so forth and sometimes

1458
01:25:55,800 --> 01:25:57,580
they can turn them by giving

1459
01:25:57,600 --> 01:25:58,970
some drugs

1460
01:25:58,970 --> 01:26:04,120
so so they can study very carefully but the question is before they run experiment

1461
01:26:04,200 --> 01:26:05,970
they don't really know which

1462
01:26:05,970 --> 01:26:09,790
adding to that which is not to bayesian problem by itself

1463
01:26:09,820 --> 01:26:11,940
if you start using a complex

1464
01:26:11,960 --> 01:26:13,750
prior distribution

1465
01:26:13,770 --> 01:26:16,400
which may be the result of

1466
01:26:16,420 --> 01:26:21,050
previous observations that are too numerous to compute the prior

1467
01:26:21,060 --> 01:26:23,310
which is the posterior then i had

1468
01:26:23,330 --> 01:26:25,260
to the to the complexity

1469
01:26:32,780 --> 01:26:37,030
this information and using it makes more sense

1470
01:26:37,440 --> 01:26:42,820
crisis as you can see how

1471
01:26:43,050 --> 01:26:44,480
trying to do so

1472
01:26:44,800 --> 01:26:48,150
thank you

1473
01:26:51,590 --> 01:26:53,870
you know

1474
01:27:04,980 --> 01:27:12,860
patients when you want

1475
01:27:16,050 --> 01:27:20,900
she that

1476
01:27:26,620 --> 01:27:30,590
OK let me ask you questions and google scholar

1477
01:27:37,230 --> 01:27:41,080
no no one

1478
01:27:45,750 --> 01:27:48,680
the difficulty

1479
01:27:48,700 --> 01:27:50,450
when you a zero

1480
01:27:50,470 --> 01:27:54,150
to do inference is that

1481
01:27:54,180 --> 01:27:56,580
you have want here one

1482
01:27:56,600 --> 01:27:58,880
he use a european

1483
01:27:58,920 --> 01:28:02,410
for the the only thing you want

1484
01:28:02,490 --> 01:28:07,690
and when i was mentioning this competition of problem

1485
01:28:07,740 --> 01:28:10,780
the point

1486
01:28:10,820 --> 01:28:13,320
that's block inference

1487
01:28:13,340 --> 01:28:16,700
from the

1488
01:28:16,730 --> 01:28:17,890
all that

1489
01:28:17,920 --> 01:28:22,110
first we work on the parameter space here the

1490
01:28:22,130 --> 01:28:25,500
nothing like the regular euclidean

1491
01:28:25,510 --> 01:28:26,870
or the

1492
01:28:28,090 --> 01:28:29,690
we have three

1493
01:28:29,710 --> 01:28:34,420
that are either composed by kind of very weak information

1494
01:28:34,550 --> 01:28:37,710
although the model itself and

1495
01:28:38,030 --> 01:28:41,510
always c they're easy area

1496
01:28:42,320 --> 01:28:45,220
model autoregressive before he

1497
01:28:45,240 --> 01:28:46,910
but where

1498
01:28:50,590 --> 01:28:53,200
the truncation of the space which is totally

1499
01:28:53,210 --> 01:28:54,610
normally do

1500
01:28:54,620 --> 01:28:56,350
so first you may have to

1501
01:28:56,360 --> 01:29:01,670
to do inference with a lot of of barriers so when you go your space

1502
01:29:01,670 --> 01:29:05,460
you blocked very quickly if you go straight

1503
01:29:05,480 --> 01:29:06,930
to take an example

1504
01:29:07,020 --> 01:29:13,280
the second difficulty is f of x given seed itself you're given models

1505
01:29:14,200 --> 01:29:17,280
the model is the result of several

1506
01:29:17,440 --> 01:29:23,320
integration of and or interpolation or simplification but actually

1507
01:29:23,340 --> 01:29:28,790
complex ification rate rather for censoring is one example you don't have the data itself

1508
01:29:28,860 --> 01:29:33,820
but some bits of today and so itself is integral

1509
01:29:37,220 --> 01:29:41,410
mean that that you know that is in the part state

1510
01:29:41,430 --> 01:29:45,510
so maybe an integral in dimensions

1511
01:29:45,520 --> 01:29:48,120
y one hundred to one thousand

1512
01:29:48,220 --> 01:29:54,160
the difficulty when you use this object is that upon

1513
01:29:55,560 --> 01:29:56,840
you pick by

1514
01:29:56,850 --> 01:29:59,810
the bayesian but if you

1515
01:29:59,830 --> 01:30:03,790
i did indeed and you want to use spread information so your prior information

1516
01:30:03,800 --> 01:30:05,030
the induced

1517
01:30:05,050 --> 01:30:06,530
already complexity

1518
01:30:06,540 --> 01:30:08,220
in pile

1519
01:30:08,240 --> 01:30:11,210
the first example was the constrained parameter space

1520
01:30:11,220 --> 01:30:15,550
if your prior information tell you that cedar is there and not there

1521
01:30:15,600 --> 01:30:21,120
but of course we have several levels of information on one level of prior information

1522
01:30:21,130 --> 01:30:23,280
is that you may have

1523
01:30:23,300 --> 01:30:24,950
earlier observations

1524
01:30:24,960 --> 01:30:27,370
and your prior observations

1525
01:30:27,390 --> 01:30:29,020
prior distribution maybe

1526
01:30:29,310 --> 01:30:31,200
already the posterior

1527
01:30:31,220 --> 01:30:34,490
and so it may be complex based

1528
01:30:34,510 --> 01:30:40,280
another level of complexity is that you will use this as the truth

1529
01:30:40,530 --> 01:30:42,670
probability distribution

1530
01:30:42,770 --> 01:30:48,840
so you will have to compute quantities based on this distribution

1531
01:30:48,930 --> 01:30:53,680
so we want to compute for instance in expectation based on the for show

1532
01:30:53,700 --> 01:30:55,160
and its expectation

1533
01:30:55,170 --> 01:31:01,850
if you are not mention friends and maybe just not computable because either the numerator

1534
01:31:01,850 --> 01:31:03,590
is complex or

1535
01:31:03,610 --> 01:31:07,540
we cannot compute the denominator

1536
01:31:07,590 --> 01:31:08,990
and this is just

1537
01:31:09,140 --> 01:31:10,070
is just

1538
01:31:10,090 --> 01:31:12,010
example but after

1539
01:31:12,020 --> 01:31:16,820
if you want to do testing in a bayesian setting use bayes factor is a

1540
01:31:16,820 --> 01:31:20,440
basic tool in bayesian inference and bayes factors

1541
01:31:20,450 --> 01:31:24,600
if you can use the the

1542
01:31:24,600 --> 01:31:27,740
and i've got a little problem because

1543
01:31:27,790 --> 01:31:32,030
because i only graph something real

1544
01:31:34,540 --> 01:31:35,930
or they

1545
01:31:35,960 --> 01:31:40,490
i think a little bit better more about these to see what graph OK well

1546
01:31:40,510 --> 01:31:44,960
my graph what what what is that if this is the input what's the output

1547
01:31:44,990 --> 01:31:46,350
that's my question

1548
01:31:46,420 --> 01:31:48,040
that's really my question

1549
01:31:48,070 --> 01:31:50,740
if if if my inputs

1550
01:31:50,870 --> 01:31:53,580
this is the vector of is is

1551
01:31:53,660 --> 01:31:55,340
this is pure

1552
01:31:55,350 --> 01:31:56,600
pure frequency

1553
01:31:57,560 --> 01:32:00,100
what's the output

1554
01:32:00,150 --> 01:32:02,700
well i just like in the formula

1555
01:32:02,710 --> 01:32:05,130
and figure out the output

1556
01:32:05,140 --> 01:32:06,140
this work

1557
01:32:06,190 --> 01:32:08,140
is easy right

1558
01:32:08,160 --> 01:32:11,330
OK XML

1559
01:32:11,380 --> 01:32:13,360
is either omega

1560
01:32:13,470 --> 01:32:15,860
taking up your frequency

1561
01:32:18,770 --> 01:32:23,650
and what's x of n minus one

1562
01:32:23,760 --> 01:32:26,160
eight the omega

1563
01:32:26,180 --> 01:32:27,780
and minus one

1564
01:32:28,940 --> 01:32:34,870
what the filters sewing

1565
01:32:34,880 --> 01:32:36,780
to this peer frequency

1566
01:32:36,790 --> 01:32:40,060
and now how do i want to write that will how do i want to

1567
01:32:42,820 --> 01:32:48,830
could estimate the images can be the only again out of it first

1568
01:32:48,880 --> 01:32:49,660
so what

1569
01:32:49,670 --> 01:32:56,530
what do i get times in the the omega and

1570
01:32:56,530 --> 01:32:59,180
well one half

1571
01:32:59,210 --> 01:33:02,470
and with the other one

1572
01:33:02,570 --> 01:33:06,620
half of

1573
01:33:10,570 --> 01:33:12,350
i only

1574
01:33:12,370 --> 01:33:15,680
well there is the most important functions

1575
01:33:15,700 --> 01:33:18,050
that's functions got it

1576
01:33:18,060 --> 01:33:21,170
it's got the total information about the filter

1577
01:33:21,200 --> 01:33:22,350
it's got because it's

1578
01:33:22,370 --> 01:33:24,790
shows us the half-and-half

1579
01:33:24,800 --> 01:33:26,420
and this is the

1580
01:33:32,340 --> 01:33:36,630
and i call it h using the same letter h

1581
01:33:36,660 --> 01:33:38,550
of omega

1582
01:33:38,550 --> 01:33:39,740
well actually

1583
01:33:42,280 --> 01:33:45,470
i use capital x of omega

1584
01:33:46,720 --> 01:33:48,370
the transformed

1585
01:33:48,470 --> 01:33:51,740
of the

1586
01:33:51,780 --> 01:33:53,630
discrete xis

1587
01:33:53,660 --> 01:33:57,810
is my notation consistent i believe it actually is

1588
01:33:57,850 --> 01:34:00,660
this a troublemaker

1589
01:34:00,690 --> 01:34:02,360
is this is

1590
01:34:02,360 --> 01:34:05,180
nothing but

1591
01:34:05,240 --> 01:34:08,150
troublemaker is nothing about the song

1592
01:34:08,200 --> 01:34:12,560
of the feature case the mind's i k

1593
01:34:20,890 --> 01:34:28,370
jumping from example whereas i happen to have been doing really clear

1594
01:34:30,300 --> 01:34:32,130
what would be four

1595
01:34:32,270 --> 01:34:38,630
different for any set of numbers

1596
01:34:38,710 --> 01:34:47,120
can i say what i'm trying to say in all one sentence what's up

1597
01:34:47,120 --> 01:34:48,740
what's up is

1598
01:34:48,760 --> 01:34:51,400
this formula

1599
01:34:52,790 --> 01:34:54,670
this convolution

1600
01:34:54,690 --> 01:34:56,660
in time domain

1601
01:34:56,680 --> 01:34:58,340
goes into

1602
01:34:58,340 --> 01:35:00,880
a multiplication

1603
01:35:01,630 --> 01:35:04,220
in the frequency domain

1604
01:35:04,280 --> 01:35:08,830
there is the a big deal

1605
01:35:08,850 --> 01:35:15,830
that's the most important formula in the set

1606
01:35:15,840 --> 01:35:19,950
so in the time domain we have little access we have little h is an

1607
01:35:19,950 --> 01:35:21,990
outcome little the wise by

1608
01:35:24,080 --> 01:35:30,570
in the frequency domain we're making axes features we multiply ordinary multiplication

1609
01:35:30,580 --> 01:35:31,600
because we

1610
01:35:31,680 --> 01:35:34,900
in the transform domain and outcomes big y

1611
01:35:34,910 --> 01:35:38,990
and of course this is the way to understand the filter

1612
01:35:39,010 --> 01:35:42,920
and often times but would never have

1613
01:35:42,940 --> 01:35:47,070
matrix at all

1614
01:35:47,110 --> 01:35:48,370
this is that

1615
01:35:48,420 --> 01:35:51,860
like sensible

1616
01:35:51,870 --> 01:35:54,490
what what is this

1617
01:35:54,510 --> 01:35:55,790
i mean

1618
01:35:55,800 --> 01:36:00,970
the first page of or the first two or three pages of the wavelet but

1619
01:36:00,970 --> 01:36:02,700
check this

1620
01:36:04,990 --> 01:36:09,530
i just checked that if

1621
01:36:09,530 --> 01:36:11,380
we started in the time domain

1622
01:36:11,430 --> 01:36:16,090
and we define

1623
01:36:17,620 --> 01:36:21,020
transformed the capital extrapolate capital y

1624
01:36:21,160 --> 01:36:26,800
the convolution in the time domain gives us some location and frequency

1625
01:36:27,700 --> 01:36:30,290
most important foreign certainly

1626
01:36:36,230 --> 01:36:40,120
so this is what we ought to graph this is this is what we graphs

1627
01:36:40,120 --> 01:36:42,340
but it's complex

1628
01:36:42,340 --> 01:36:43,900
here it was

1629
01:36:43,930 --> 01:36:45,440
it's complex numbers so

1630
01:36:45,450 --> 01:36:48,620
what's the best do

1631
01:36:48,630 --> 01:36:50,620
great graphics make it

1632
01:36:50,630 --> 01:36:54,630
so that now we finally say what are we graphing i'm going to grasp the

1633
01:36:54,630 --> 01:36:59,400
once one stage will have the full sample the other state subsample

1634
01:37:00,210 --> 01:37:03,000
so you may have a situation where the quite a face as the four

1635
01:37:03,000 --> 01:37:04,270
number of participants

1636
01:37:04,290 --> 01:37:05,920
and then you select

1637
01:37:05,940 --> 01:37:07,040
is one of those

1638
01:37:07,060 --> 01:37:09,540
selection for random on random

1639
01:37:09,540 --> 01:37:11,380
people to go in your

1640
01:37:11,590 --> 01:37:16,500
qualitative phase we interviewed him focus groups can have as well

1641
01:37:17,960 --> 01:37:20,650
when you have those for combinations in you

1642
01:37:20,670 --> 01:37:23,790
combine it with with its concurrent sequential

1643
01:37:23,830 --> 01:37:26,110
you get eight different

1644
01:37:26,170 --> 01:37:28,440
types of relationships you can have

1645
01:37:28,670 --> 01:37:33,000
and featured those you select your your sampling scheme

1646
01:37:33,000 --> 01:37:35,210
you have the twenty four

1647
01:37:35,230 --> 01:37:38,840
OK so that's a really quick created action to make it stop

1648
01:37:38,840 --> 01:37:42,940
research design philosophies design probably the most developed area in mixed methods there lots of

1649
01:37:42,940 --> 01:37:44,040
designs out there

1650
01:37:44,090 --> 01:37:45,650
people like john crystal

1651
01:37:45,670 --> 01:37:47,920
having great works are

1652
01:37:50,790 --> 01:37:54,940
tajik always teddlie and several others jennifer greene

1653
01:37:54,980 --> 01:37:59,170
this is what can

1654
01:37:59,210 --> 01:38:00,900
again couple of this manuscript

1655
01:38:00,900 --> 01:38:01,880
this article

1656
01:38:01,940 --> 01:38:03,380
if you're interested

1657
01:38:03,730 --> 01:38:06,170
the basic you look at level to make sense

1658
01:38:06,170 --> 01:38:09,860
time orientation emphasises three key points

1659
01:38:09,960 --> 01:38:11,860
so whether it's partially mixed

1660
01:38:11,920 --> 01:38:15,480
well you mix because sometimes people will collect quantitative data

1661
01:38:15,480 --> 01:38:16,960
quality data

1662
01:38:17,060 --> 01:38:21,290
analyzed separately but then makes them at the end that's more partially mixed might be

1663
01:38:21,290 --> 01:38:24,210
fully mixed with the is very interactive all across

1664
01:38:24,310 --> 01:38:26,480
most of the phase of the study

1665
01:38:26,590 --> 01:38:31,610
time orientation have you seen before concurrent sequential and weights

1666
01:38:31,650 --> 01:38:34,380
emphasis is equal or o one is dominant

1667
01:38:34,490 --> 01:38:36,670
khalid to that with the

1668
01:38:36,690 --> 01:38:39,880
a different combinations so you can have

1669
01:38:40,040 --> 01:38:44,210
the collection in birkenau

1670
01:38:44,250 --> 01:38:46,920
his wife lisa have come up with six

1671
01:38:46,940 --> 01:38:50,750
major data collection strategies for example you can mix open and close and

1672
01:38:50,790 --> 01:38:52,460
death threats interviewing

1673
01:38:52,520 --> 01:38:54,670
a priory imagine flowing

1674
01:38:54,730 --> 01:38:57,500
standardised open and close any questions

1675
01:38:59,400 --> 01:39:01,230
that's the first four

1676
01:39:01,270 --> 01:39:06,060
standardised confirmatory less explored started to explore observation

1677
01:39:06,060 --> 01:39:09,840
you can also combine numeric make documents

1678
01:39:10,770 --> 01:39:13,060
ten is actually going there in their hand in there

1679
01:39:13,060 --> 01:39:14,900
latest book

1680
01:39:14,900 --> 01:39:16,630
i have extended further

1681
01:39:16,650 --> 01:39:18,790
they come out with thirty six

1682
01:39:18,790 --> 01:39:21,480
different data collection combinations

1683
01:39:21,570 --> 01:39:25,060
that's a really actually really really good chapters were in chapter if you if you

1684
01:39:25,190 --> 01:39:26,440
if you're interested

1685
01:39:26,560 --> 01:39:28,500
research design because

1686
01:39:28,630 --> 01:39:31,560
data collection because that's really cut it

1687
01:39:31,610 --> 01:39:33,790
the stuff that they have in their

1688
01:39:33,790 --> 01:39:35,880
so then we want to start nine

1689
01:39:35,920 --> 01:39:37,610
which is data analysis and

1690
01:39:37,610 --> 01:39:40,520
and doing this week is what we're going to focus most on this is one

1691
01:39:40,520 --> 01:39:43,880
of the is to determine the most struggle with

1692
01:39:43,900 --> 01:39:46,270
to do data analysis

1693
01:39:46,290 --> 01:39:50,610
had the analyse have called data have chordata what i do with a lot of

1694
01:39:50,610 --> 01:39:54,400
time you might be strong alignment but not strongly of and that's my one promise

1695
01:39:54,400 --> 01:39:56,270
you have

1696
01:39:58,790 --> 01:40:02,330
quite qualitative was mixed methods analysis

1697
01:40:04,040 --> 01:40:07,540
we combine concurrently or sequentially

1698
01:40:07,540 --> 01:40:09,420
the analysis of quantitative

1699
01:40:09,460 --> 01:40:11,130
and qualitative data

1700
01:40:11,230 --> 01:40:15,340
might be in the power law way might be sequential said might be integrated

1701
01:40:15,400 --> 01:40:18,170
so that's the fundamental principle of data analysis

1702
01:40:19,290 --> 01:40:21,480
and in two major goals for

1703
01:40:22,380 --> 01:40:26,170
folk and for that mixed methods one might be legitimation

1704
01:40:26,270 --> 01:40:27,560
so when there

1705
01:40:27,570 --> 01:40:29,730
we use what about the other

1706
01:40:29,730 --> 01:40:32,110
the second of the representation

1707
01:40:32,170 --> 01:40:33,920
we want to get more at your data

1708
01:40:33,980 --> 01:40:37,250
we might use both in the same study

1709
01:40:37,270 --> 01:40:41,790
there's a couple of times you have a lot of literature quantitizing one

1710
01:40:41,790 --> 01:40:45,460
and that's where you convert quantitative data

1711
01:40:45,480 --> 01:40:49,940
to call quality site is we collect qualitative data to qualitative codes

1712
01:40:50,000 --> 01:40:53,360
so you might have themes and you count the themes or you do all kinds

1713
01:40:56,130 --> 01:40:59,460
based on your qualitative information

1714
01:40:59,500 --> 01:41:01,880
or you could have quantitized qualitizing

1715
01:41:01,980 --> 01:41:05,250
which you go the other way so you have quite a data

1716
01:41:05,250 --> 01:41:06,330
and from there

1717
01:41:06,340 --> 01:41:08,110
images qualitative data

1718
01:41:08,130 --> 01:41:09,980
and findings

1719
01:41:10,020 --> 01:41:15,000
so for example you could you could form a profiles conati profiles

1720
01:41:15,900 --> 01:41:17,040
that's where you

1721
01:41:17,060 --> 01:41:19,770
based on numbers that you get from quite a phase

1722
01:41:19,840 --> 01:41:25,000
you build the picture story of the person or group of people

1723
01:41:25,060 --> 01:41:27,020
so you have the load profile

1724
01:41:27,060 --> 01:41:31,840
and this is ten tuchikoi in the book and ninety eight we have detailed narrative

1725
01:41:32,980 --> 01:41:35,830
of course people based on the most frequently occurring

1726
01:41:35,840 --> 01:41:39,020
we may be based on the average

1727
01:41:39,060 --> 01:41:40,560
number of attributes

1728
01:41:40,570 --> 01:41:43,290
you get from the quantitative data

1729
01:41:43,420 --> 01:41:46,060
could be you do more realistically

1730
01:41:47,790 --> 01:41:49,440
comparative profiles

1731
01:41:49,440 --> 01:41:53,400
it is where you compare one analysis to another

1732
01:41:53,400 --> 01:41:56,480
o normative where you might have some normative data

1733
01:41:56,500 --> 01:41:59,610
so you have an instrument that yields norms

1734
01:41:59,670 --> 01:42:02,810
and from there you compare them to the norms and then you build the picture

1735
01:42:02,810 --> 01:42:03,670
from them

1736
01:42:04,520 --> 01:42:08,000
so if you do in forensic psychology and so forth

1737
01:42:08,210 --> 01:42:11,650
you might use normative profiles if you're trying to build the profile of a serial

1738
01:42:13,920 --> 01:42:16,920
then you might be using such techniques

1739
01:42:17,880 --> 01:42:21,460
within five seven steps major steps in the mixed methods

1740
01:42:21,480 --> 01:42:23,340
they do not process

1741
01:42:23,730 --> 01:42:26,710
you use your data it is the quality of qualitative data

1742
01:42:26,770 --> 01:42:29,670
he might use things like this gives statistics for your qualitative

1743
01:42:29,730 --> 01:42:32,340
what factor analysis

1744
01:42:32,340 --> 01:42:35,560
and the quality may use export market analysis

1745
01:42:35,570 --> 01:42:37,230
a memory

1746
01:42:37,230 --> 01:42:42,420
i also started we got funding from three different foundations to do a small study

1747
01:42:42,460 --> 01:42:44,500
this and we're trying to get

1748
01:42:44,540 --> 01:42:50,040
bigger finding out of a large scale study but in this study we took veterans

1749
01:42:50,070 --> 01:42:51,730
who are obese

1750
01:42:52,670 --> 01:42:57,020
we attempt attempted to get them to lose one pound per week for sixteen weeks

1751
01:42:57,040 --> 01:42:58,420
that's our goal

1752
01:42:58,480 --> 01:43:04,210
and every month they returned to the lateral connections they kind

1753
01:43:04,230 --> 01:43:07,340
four way and that's very important to explain why

1754
01:43:07,340 --> 01:43:11,540
so if three conditions with the control condition where they go to the

1755
01:43:11,540 --> 01:43:16,630
nutritionists and they get advice about how to control the rate that's all

1756
01:43:16,650 --> 01:43:18,020
and we have to

1757
01:43:18,020 --> 01:43:20,840
experimental incentive conditions

1758
01:43:20,860 --> 01:43:24,860
in both of these conditions they monitor their weight every day and every day in

1759
01:43:24,860 --> 01:43:28,340
the morning the phone in the weight to our administrators

1760
01:43:28,360 --> 01:43:33,630
and in the evenings we send them back we every each guest pages

1761
01:43:33,940 --> 01:43:38,420
text pager in the evening we send them message telling them

1762
01:43:38,440 --> 01:43:40,980
OK telling them

1763
01:43:41,000 --> 01:43:42,750
what's happening

1764
01:43:42,840 --> 01:43:48,360
and we have two conditions of lottery incentive condition on the positive incentive condition

1765
01:43:48,380 --> 01:43:50,150
in the lottery condition

1766
01:43:50,170 --> 01:43:50,920
it's the

1767
01:43:50,940 --> 01:43:53,250
the same scheme as for warfarin

1768
01:43:56,420 --> 01:44:01,060
this slide is missing but i imagine a graph it starts with subject's way

1769
01:44:01,070 --> 01:44:03,460
and you see the line where there is

1770
01:44:03,460 --> 01:44:05,040
one week

1771
01:44:05,060 --> 01:44:08,880
and both of these conditions as long as they stay on the line every day

1772
01:44:08,940 --> 01:44:10,230
they get payoff

1773
01:44:10,230 --> 01:44:14,110
they go over the line not losing as much weight as there supposed to and

1774
01:44:14,110 --> 01:44:16,130
they don't get a so

1775
01:44:16,150 --> 01:44:19,860
in the lottery condition they only receive lottery payment if first they called in the

1776
01:44:19,860 --> 01:44:20,840
way that they

1777
01:44:20,840 --> 01:44:24,210
and second at below daily weight loss goal

1778
01:44:24,230 --> 01:44:28,210
and we transmit the message about whether they won or whether they would have won

1779
01:44:28,210 --> 01:44:29,170
the lottery

1780
01:44:29,190 --> 01:44:31,420
based on whether they are weight is low

1781
01:44:31,440 --> 01:44:35,090
every month they come in and check we weigh them on the laboratory scale

1782
01:44:35,110 --> 01:44:39,250
and if if their weight isn't what they told us it was at the end

1783
01:44:39,250 --> 01:44:41,920
of the month they get nothing so that's how

1784
01:44:41,940 --> 01:44:44,170
make sure that lie to us

1785
01:44:44,190 --> 01:44:48,230
in the second that we also decided to try and new incentive condition was called

1786
01:44:48,290 --> 01:44:50,560
positive deposit contracts

1787
01:44:50,570 --> 01:44:54,130
in this they can put money down toward weight loss the beginning of the month

1788
01:44:54,170 --> 01:44:56,110
we match them one to one

1789
01:44:56,130 --> 01:44:59,610
they can put anything from penny down to three dollars a day

1790
01:44:59,630 --> 01:45:04,040
so they put three dollars a day and every day that they are below weight

1791
01:45:04,110 --> 01:45:08,020
below the target way they get back six dollars but there but the target weight

1792
01:45:08,210 --> 01:45:11,790
they lose their freedom so we're trying to plan loss aversion

1793
01:45:16,540 --> 01:45:20,480
and here are the results so far in the first month

1794
01:45:20,590 --> 01:45:22,880
the control condition not the

1795
01:45:22,920 --> 01:45:24,750
one seven six pounds

1796
01:45:24,770 --> 01:45:28,630
in the addition they lost five point seven pounds in the past

1797
01:45:28,650 --> 01:45:32,150
contract condition they lost seven pounds

1798
01:45:33,150 --> 01:45:36,670
if you look at the percentage attaining the first monthly weight loss goal was to

1799
01:45:36,670 --> 01:45:40,070
lose four and seventy one percent in the water conditions

1800
01:45:40,090 --> 01:45:41,250
one hundred percent

1801
01:45:41,270 --> 01:45:45,920
and the deposit in this you can see that are

1802
01:45:45,940 --> 01:45:49,190
initial conditions

1803
01:45:50,170 --> 01:45:51,750
only seven percent

1804
01:45:51,770 --> 01:45:53,940
achieve the weight loss goals

1805
01:45:53,960 --> 01:45:56,630
we're now four months into the study

1806
01:45:56,630 --> 01:46:03,020
and the results continue to look very easily average weight loss over a four-month period

1807
01:46:03,070 --> 01:46:06,210
still writer one to control

1808
01:46:06,230 --> 01:46:07,920
it's an average

1809
01:46:07,940 --> 01:46:11,770
four thousand four pounds four pounds per week

1810
01:46:12,000 --> 01:46:15,040
sorry for lottery conditions and

1811
01:46:15,060 --> 01:46:19,730
also found with the possible conditions

1812
01:46:19,750 --> 01:46:20,860
and the

1813
01:46:22,230 --> 01:46:25,340
meeting the goal is those figures are similar

1814
01:46:25,400 --> 01:46:29,400
i think i'm going to not tell you about

1815
01:46:29,420 --> 01:46:32,840
save the savings plans and less

1816
01:46:38,090 --> 01:46:40,610
it's not my fault

1817
01:46:44,630 --> 01:46:47,770
a while ago i was at a investments

1818
01:46:48,020 --> 01:46:50,420
bank and they said

1819
01:46:50,440 --> 01:46:53,420
why do people not safe for retirement

1820
01:46:53,440 --> 01:46:58,750
how can we have we make retirement real to people can we get them to

1821
01:46:58,750 --> 01:47:03,960
realise you're going to have a miserable retirement they don't save money for retirement

1822
01:47:04,920 --> 01:47:09,360
so this can be seen should we scare them should be presented with gruesome images

1823
01:47:09,360 --> 01:47:10,820
of for retirement

1824
01:47:10,840 --> 01:47:16,940
or should we show that like wonderful images and after retirement i said that you

1825
01:47:16,940 --> 01:47:19,570
just think you are totally wrong lines

1826
01:47:19,570 --> 01:47:20,650
what you need to do

1827
01:47:20,670 --> 01:47:24,560
is easy get daily incentives for saving money

1828
01:47:24,730 --> 01:47:28,500
is the announcer familiar themes say

1829
01:47:31,250 --> 01:47:33,290
it's amazing that is

1830
01:47:33,290 --> 01:47:35,320
that the median family

1831
01:47:35,880 --> 01:47:39,980
united states zero stars even in retirement plans

1832
01:47:40,000 --> 01:47:42,070
and but the average

1833
01:47:42,150 --> 01:47:46,920
family in the united states spans across four thousand dollars

1834
01:47:48,570 --> 01:47:51,710
so the average distance four thousand dollars gambling

1835
01:47:51,730 --> 01:47:53,860
it doesn't take into account to get back

1836
01:47:53,860 --> 01:47:57,110
i was putting i did this i was put in

1837
01:47:58,240 --> 01:48:00,880
later or the not so i was pretty

1838
01:48:00,940 --> 01:48:03,210
what does there's no room for

1839
01:48:05,990 --> 01:48:11,090
at a certain point is if you use it can be put in because size

1840
01:48:11,090 --> 01:48:12,250
already in there

1841
01:48:13,440 --> 01:48:16,160
so you would edit inconsistencies

1842
01:48:17,280 --> 01:48:18,930
along stage

1843
01:48:18,950 --> 01:48:23,310
and every stage was kept constant union is also considered

1844
01:48:26,100 --> 01:48:27,970
what's the canonical

1845
01:48:29,170 --> 01:48:31,410
the canonical model

1846
01:48:31,590 --> 01:48:34,710
the set of all maximal consistent what do i do

1847
01:48:35,890 --> 01:48:38,400
i say

1848
01:48:38,420 --> 01:48:41,900
remember this was wanting me to get one

1849
01:48:43,100 --> 01:48:48,420
x star which was a maximal consistent extension of gamma rule enumeration and compute all

1850
01:48:48,420 --> 01:48:51,870
maximal consistent extension of gamma which just means

1851
01:48:54,200 --> 01:48:57,260
all permutations of your formula

1852
01:48:58,250 --> 01:49:02,830
it's not empty white lace one that's the whole point of the investment in existing

1853
01:49:02,830 --> 01:49:04,630
steer there's at least one

1854
01:49:05,800 --> 01:49:08,420
let them be the set of your world

1855
01:49:09,550 --> 01:49:12,730
so my worlds

1856
01:49:13,910 --> 01:49:17,090
maximal consistent

1857
01:49:18,880 --> 01:49:22,920
in this

1858
01:49:24,030 --> 01:49:28,440
so i'm going to draw them

1859
01:49:29,680 --> 01:49:31,550
i'm going to draw them like this

1860
01:49:31,590 --> 01:49:34,450
the world in the old days it was the point

1861
01:49:35,800 --> 01:49:38,590
now it's an infinite set forth

1862
01:49:40,380 --> 01:49:43,440
it's got nothing to do with constructive

1863
01:49:44,680 --> 01:49:46,100
i'm going to say

1864
01:49:47,600 --> 01:49:50,970
OK let's use the notation that i'm using

1865
01:49:51,080 --> 01:49:53,350
wn one is a

1866
01:49:54,420 --> 01:49:58,000
i've got a set of nonempty set of world now i

1867
01:49:59,260 --> 01:50:00,730
on the

1868
01:50:00,780 --> 01:50:06,620
what is it what does wrcv jumbo say when can i put an arc

1869
01:50:07,840 --> 01:50:09,620
from here to here

1870
01:50:09,650 --> 01:50:11,960
in working mumbo-jumbo

1871
01:50:13,230 --> 01:50:22,460
and this is the whole point of the construction

1872
01:50:24,930 --> 01:50:28,090
you can say is one sentence

1873
01:50:29,090 --> 01:50:30,720
to the brain

1874
01:50:33,660 --> 01:50:35,720
the condition is up

1875
01:50:35,790 --> 01:50:37,710
it's conditioning work

1876
01:50:41,830 --> 01:50:47,120
sorry so

1877
01:50:51,470 --> 01:50:56,260
you're using words like true and necessary i want notation

1878
01:50:57,550 --> 01:50:59,940
one in in terms of set membership

1879
01:50:59,950 --> 01:51:11,810
because i don't have notions of necessary at the moment right on defining the model

1880
01:51:15,700 --> 01:51:20,610
no that's not true

1881
01:51:25,210 --> 01:51:28,480
you're on the right track and being a bit other people to pick up on

1882
01:51:28,590 --> 01:51:31,580
you're on the right track

1883
01:51:44,660 --> 01:51:50,310
are being boxed

1884
01:51:52,560 --> 01:51:57,040
this sentence matches that definition

1885
01:51:58,280 --> 01:52:01,120
it's being a set of formulae using

1886
01:52:02,460 --> 01:52:03,970
what's the set of formulae

1887
01:52:03,980 --> 01:52:05,720
the set of all five

1888
01:52:06,990 --> 01:52:09,410
the guys are in

1889
01:52:09,450 --> 01:52:12,380
but what i have a they're all they have to be so in other words

1890
01:52:12,380 --> 01:52:16,400
all it says is you find all the box formulae that are in here

1891
01:52:17,810 --> 01:52:21,930
although there in their box which is what you're saying that all the things which

1892
01:52:21,930 --> 01:52:24,560
are necessary to

1893
01:52:24,560 --> 01:52:29,490
how the support region is moving and we cannot have that before that local regions

1894
01:52:29,520 --> 01:52:33,600
do tend to move in a similar way and if you if you can parameterise

1895
01:52:33,600 --> 01:52:36,860
had moving semi-final or even translation

1896
01:52:36,920 --> 01:52:42,970
if you parameterize the moving then you can come get and m heads are better

1897
01:52:42,970 --> 01:52:44,750
than one thing going on so

1898
01:52:44,820 --> 01:52:47,230
maybe one or two of the pixels are noisy but if you look at enough

1899
01:52:47,300 --> 01:52:51,680
the pixels you can get a pretty good idea of where the areas move

1900
01:52:51,800 --> 01:52:54,680
so let's let's walk through the solid

1901
01:52:55,350 --> 01:52:57,100
what essentially i have here

1902
01:52:57,110 --> 01:53:00,320
is my source image

1903
01:53:01,460 --> 01:53:05,740
and i've got to the ground truth so the ground truth

1904
01:53:05,800 --> 01:53:08,680
is p plus delta p so

1905
01:53:08,690 --> 01:53:11,630
most likely change notation here so p

1906
01:53:12,340 --> 01:53:16,650
in terms of lucas kanade a is my initial guess

1907
01:53:16,670 --> 01:53:20,980
actually this would be more instructive to do this way so p is this i

1908
01:53:20,980 --> 01:53:24,350
run from my apologies in space and time and i'm not going to get an

1909
01:53:24,350 --> 01:53:28,090
approximate idea where the object is but i know exactly where it is likely to

1910
01:53:28,090 --> 01:53:33,090
have a good ballpark region for the lucas kanade have guys from says OK

1911
01:53:33,110 --> 01:53:36,130
it's approximately here but i know there's a lot of noise there's a lot of

1912
01:53:36,130 --> 01:53:38,030
what error in this estimate

1913
01:53:38,040 --> 01:53:41,180
so what i what i actually do

1914
01:53:41,210 --> 01:53:42,590
so going back to this

1915
01:53:42,670 --> 01:53:46,980
is that i see that i can approximate what the truth

1916
01:53:47,040 --> 01:53:50,610
aligned image looks like this is my starting this why

1917
01:53:50,630 --> 01:53:52,100
i noise EP

1918
01:53:52,160 --> 01:53:55,470
things and i want to find the delta p which will essentially

1919
01:53:55,500 --> 01:53:57,980
refine or improve

1920
01:53:57,990 --> 01:53:59,610
my current IP

1921
01:53:59,610 --> 01:54:04,430
OK so what i did to try and so this is essentially i i assume

1922
01:54:04,430 --> 01:54:10,300
that approximate this ideal and image five

1923
01:54:10,300 --> 01:54:12,570
the roughly misaligned image

1924
01:54:12,620 --> 01:54:14,280
and obviously

1925
01:54:14,670 --> 01:54:17,920
a rule of thumb with this is again we go back to the pixel coherence

1926
01:54:18,790 --> 01:54:20,280
you might say well how

1927
01:54:20,300 --> 01:54:21,960
well one doesn't have to be

1928
01:54:21,970 --> 01:54:26,910
and you can't obviously there has to be some pixels within that implied that are

1929
01:54:26,920 --> 01:54:32,010
in a better in a spatially local area so not all the pixels so you

1930
01:54:32,010 --> 01:54:36,460
don't have to have been entire template perhaps like what someone has two pixels one

1931
01:54:36,520 --> 01:54:40,120
but they have to be some pixels in there that can actually have a region

1932
01:54:40,120 --> 01:54:45,420
that can be reasonably predicted in terms of movement selected so rotational scale and things

1933
01:54:45,420 --> 01:54:51,120
like that some of those pixels have to overlap so obviously translations roughly wrong here

1934
01:54:51,240 --> 01:54:55,630
the aspect ratio is wrong here the scale is from here but the pixels to

1935
01:54:55,630 --> 01:55:01,470
overlap with what the true alignment to understand what the true trawlermen i one element

1936
01:55:01,530 --> 01:55:02,710
the next thing i do

1937
01:55:02,720 --> 01:55:04,160
it is essentially

1938
01:55:04,170 --> 01:55:05,090
i is

1939
01:55:05,100 --> 01:55:08,300
again i look to the first order taylor series expansion

1940
01:55:08,380 --> 01:55:12,720
but instead of just applying it straight i apply a

1941
01:55:12,760 --> 01:55:16,490
since reagan high school maths again on the train

1942
01:55:16,500 --> 01:55:18,590
and essentially allowed to

1943
01:55:18,600 --> 01:55:23,830
it is i get the gradient of the image we already covered that there a

1944
01:55:23,830 --> 01:55:25,820
different number of different ways of doing this

1945
01:55:25,840 --> 01:55:30,420
and this notation here might seem a little bit strange you guys you might want

1946
01:55:30,430 --> 01:55:33,000
to know what's going on here i know what's going on here

1947
01:55:33,010 --> 01:55:34,870
this is the source image

1948
01:55:34,880 --> 01:55:36,060
this is

1949
01:55:36,080 --> 01:55:39,950
i mean warping being the source image for my currently which is kind noisy which

1950
01:55:39,950 --> 01:55:43,780
is which is with which is noisy and then i've got this part and the

1951
01:55:43,780 --> 01:55:45,280
name of the group

1952
01:55:45,380 --> 01:55:51,300
and essentially this part is essentially just the x and y components and every pixel

1953
01:55:51,320 --> 01:55:53,400
but the x and y components of every pixel

1954
01:55:53,410 --> 01:55:56,650
from the source with respect to the source image

1955
01:55:56,680 --> 01:56:00,820
so what i'm really saying here is that when tackling these gradients

1956
01:56:00,880 --> 01:56:02,490
i don't

1957
01:56:02,500 --> 01:56:06,170
so there are two ways to calculate gradient if you kind of being heuristic what

1958
01:56:06,170 --> 01:56:08,340
i could do look at the source image

1959
01:56:08,460 --> 01:56:10,470
i could what

1960
01:56:10,490 --> 01:56:13,720
here such that my images i like to invite

1961
01:56:14,640 --> 01:56:16,720
architect gradients

1962
01:56:16,780 --> 01:56:18,680
but what i'm saying here

1963
01:56:18,740 --> 01:56:22,840
is that i want to calculate gradient of the image with respect to the original

1964
01:56:22,840 --> 01:56:26,350
source image so what i have to do actually is i have to take the

1965
01:56:26,350 --> 01:56:30,370
gradient on the source image first so take the gradient of the source image for

1966
01:56:30,750 --> 01:56:35,550
in the x direction gradient and sourced in the source image in the y direction

1967
01:56:35,630 --> 01:56:40,420
and then i will both gradients and this is actually very you have to get

1968
01:56:40,420 --> 01:56:44,600
the story right because if you can't i mean it's very tempting to say well

1969
01:56:44,650 --> 01:56:48,600
you want cheaper from a computationally just to kind of what is fact great here

1970
01:56:48,600 --> 01:56:49,380
and here

1971
01:56:49,400 --> 01:56:54,220
but actually the grid would be completely wrong and will go over what's the case

1972
01:56:54,220 --> 01:56:55,420
and actually

1973
01:56:55,640 --> 01:56:59,260
there's some advantages to doing that disadvantages but you'd actually have

1974
01:57:00,420 --> 01:57:03,440
partial derivative with respect to the wall of z

1975
01:57:03,490 --> 01:57:08,280
zero because there is no p they're all because you have removed p because he

1976
01:57:09,810 --> 01:57:11,800
this is something very special here so

1977
01:57:11,820 --> 01:57:16,270
is it is economically and you guys will come and go over that a lot

1978
01:57:16,300 --> 01:57:20,950
in the original lucas kanade i was extremely important that you took the derivative of

1979
01:57:20,950 --> 01:57:25,840
the source image first then what rather than actually

1980
01:57:25,900 --> 01:57:30,670
warping the source image thing getting gradients so that's the first

1981
01:57:30,710 --> 01:57:36,880
now the second step is you've also so essentially got gradients for every single pixel

1982
01:57:36,880 --> 01:57:37,890
in the image

1983
01:57:37,920 --> 01:57:42,990
but again we saying well individual pixels are really noisy so i need some way

1984
01:57:43,010 --> 01:57:47,080
so to say this is an by an image

1985
01:57:47,100 --> 01:57:51,330
i've essentially got two in square degrees of freedom in terms of where the pixels

1986
01:57:52,300 --> 01:57:58,690
so obviously one nice thing to do would be to constrain

1987
01:57:58,710 --> 01:58:03,700
and this is the constraints of how all these pixels so to say i've got

1988
01:58:03,700 --> 01:58:06,850
it is defined

1989
01:58:06,860 --> 01:58:08,090
as the integral

1990
01:58:08,130 --> 01:58:10,570
of f

1991
01:58:10,680 --> 01:58:13,620
dg during a certain amount of time

1992
01:58:13,680 --> 01:58:15,670
that's a from zero

1993
01:58:15,680 --> 01:58:17,590
two delta t

1994
01:58:17,600 --> 01:58:19,540
now every because i made

1995
01:58:22,800 --> 01:58:25,320
which is also

1996
01:58:25,420 --> 01:58:30,110
dp dt we've seen is now several times

1997
01:58:30,120 --> 01:58:34,040
the rate of change of momentum and so i can substitute that in here

1998
01:58:34,080 --> 01:58:35,670
and so i find them

1999
01:58:35,690 --> 01:58:36,860
the integral

2000
01:58:36,870 --> 01:58:39,280
one zero to delta t

2001
01:58:41,010 --> 01:58:42,940
the community

2002
01:58:43,070 --> 01:58:44,500
the team

2003
01:58:44,560 --> 01:58:47,460
and that makes me move to the

2004
01:58:47,540 --> 01:58:49,600
domain of

2005
01:58:49,610 --> 01:58:50,480
so i have

2006
01:58:50,490 --> 01:58:52,590
now simply the integral

2007
01:58:52,590 --> 01:58:54,790
over the from some

2008
01:58:55,730 --> 01:58:58,510
momentum p i do some final

2009
01:58:58,530 --> 01:59:01,860
well meant and f

2010
01:59:01,870 --> 01:59:03,050
so that is

2011
01:59:04,220 --> 01:59:07,230
the final momentum

2012
01:59:08,310 --> 01:59:12,090
the initial moment so what and imposed does

2013
01:59:12,130 --> 01:59:13,450
it changes

2014
01:59:13,490 --> 01:59:16,340
the momentum

2015
01:59:16,350 --> 01:59:17,960
there is a force that acts

2016
01:59:17,960 --> 01:59:21,110
on something for a short amount of time could be a little longer as you

2017
01:59:21,110 --> 01:59:26,580
will see was rockets and that gives it a change in a moment

2018
01:59:26,590 --> 01:59:27,590
if we

2019
01:59:27,690 --> 01:59:30,070
i have an object that we drop on the floor

2020
01:59:30,220 --> 01:59:33,720
so we have an object mass and

2021
01:59:33,730 --> 01:59:35,870
and we drop it on the floor

2022
01:59:35,960 --> 01:59:39,170
and we let it fall over the distance h

2023
01:59:39,210 --> 01:59:41,700
that is going to hit the floor

2024
01:59:41,780 --> 01:59:43,190
with a certain

2025
01:59:43,240 --> 01:59:46,230
speed we know it's down to velocity

2026
01:59:46,240 --> 01:59:47,870
and that equals

2027
01:59:47,930 --> 01:59:49,030
the square root

2028
01:59:49,080 --> 01:59:52,080
of two gh

2029
01:59:52,090 --> 01:59:54,560
if this were a completely

2030
01:59:54,570 --> 01:59:56,240
elastic collisions

2031
01:59:56,300 --> 01:59:58,210
which depends of course on the quality

2032
01:59:58,210 --> 02:00:01,200
of the object and it depends on the quality of the flow maybe it's super

2033
02:00:01,200 --> 02:00:04,040
bowl on marble will be almost

2034
02:00:04,050 --> 02:00:05,460
completely elastic

2035
02:00:06,130 --> 02:00:09,760
the ball would bounce back with that same

2036
02:00:12,310 --> 02:00:15,510
and if that would be a completely elastic collisions

2037
02:00:15,530 --> 02:00:18,070
then you can see that the impulse

2038
02:00:18,180 --> 02:00:22,460
that's the ball is given

2039
02:00:23,070 --> 02:00:25,930
that is given to the ball as the ball hits the floor to floor is

2040
02:00:25,930 --> 02:00:27,710
giving an impulse to the ball

2041
02:00:27,750 --> 02:00:33,670
and that involves equals two and three

2042
02:00:33,740 --> 02:00:36,090
the ball changes its momentum

2043
02:00:36,100 --> 02:00:38,180
it was first

2044
02:00:38,190 --> 02:00:42,090
MV in this direction and out and in this direction so change

2045
02:00:42,100 --> 02:00:42,860
it's too

2046
02:00:42,880 --> 02:00:45,090
and the solar impulse is given

2047
02:00:45,100 --> 02:00:46,460
to the ball

2048
02:00:46,490 --> 02:00:47,310
now if the

2049
02:00:47,320 --> 02:00:49,800
collision were completely inelastic

2050
02:00:49,820 --> 02:00:51,690
then the ball will just say

2051
02:00:51,750 --> 02:00:54,880
like a tomato i throw tomato on the floor goes

2052
02:00:54,890 --> 02:00:59,070
no speed anymore when it hits the ground then of course the impulse would only

2053
02:00:59,070 --> 02:01:01,180
be and

2054
02:01:01,220 --> 02:01:04,510
because then it doesn't come back up so there's no the change in momentum is

2055
02:01:08,410 --> 02:01:09,960
we have here too

2056
02:01:10,000 --> 02:01:12,070
balls that look like

2057
02:01:12,100 --> 02:01:16,100
they have a mass of o point one kilogram

2058
02:01:16,110 --> 02:01:17,070
so and

2059
02:01:17,110 --> 02:01:21,140
equals o point one kilogram

2060
02:01:21,190 --> 02:01:22,860
and i will drop them

2061
02:01:22,920 --> 02:01:25,590
from the height of about one and a half metres

2062
02:01:25,600 --> 02:01:29,120
and that gives them the speed when it hit the floor

2063
02:01:29,130 --> 02:01:31,070
of about five and a half

2064
02:01:31,110 --> 02:01:33,730
meters per second

2065
02:01:33,790 --> 02:01:35,170
so the momentum

2066
02:01:35,190 --> 02:01:37,470
changes to envy

2067
02:01:37,530 --> 02:01:40,800
so the impulse

2068
02:01:40,810 --> 02:01:42,590
equals two and

2069
02:01:42,600 --> 02:01:44,830
is about one point one

2070
02:01:44,870 --> 02:01:46,640
and that would be

2071
02:01:49,960 --> 02:01:52,450
a second

2072
02:01:52,480 --> 02:01:53,910
that means that

2073
02:01:53,920 --> 02:01:56,500
if the collision time

2074
02:01:56,550 --> 02:01:58,230
isbell thirty seconds

2075
02:01:58,240 --> 02:02:00,500
that the average force

2076
02:02:00,510 --> 02:02:02,580
actor camborne this ball

2077
02:02:02,620 --> 02:02:05,180
during the collision was the floor

2078
02:02:06,780 --> 02:02:08,630
in impulse divided by

2079
02:02:08,640 --> 02:02:12,760
delta t because remember that what i definition of impulse

2080
02:02:12,870 --> 02:02:16,510
so i only impose we get a feeling for average force

2081
02:02:16,560 --> 02:02:20,180
and for the ball that i will drop on the floor we done fast photography

2082
02:02:20,180 --> 02:02:21,250
i'll show you

2083
02:02:21,280 --> 02:02:25,240
some results of the fast photography with the different ball but nevertheless

2084
02:02:25,300 --> 02:02:28,310
we did it was the ball that i will drop on the floor very shortly

2085
02:02:28,310 --> 02:02:29,310
which is this one

2086
02:02:29,400 --> 02:02:33,460
that in fact i was only two millisecond it's hard to believe in full millisecond

2087
02:02:33,510 --> 02:02:35,960
entire collision occurs

2088
02:02:36,090 --> 02:02:39,080
and so if you substitute in you know too many seconds

2089
02:02:39,120 --> 02:02:40,170
you get forty

2090
02:02:40,170 --> 02:02:41,370
average four

2091
02:02:43,100 --> 02:02:44,710
fifty newtons

2092
02:02:44,750 --> 02:02:46,130
just imagine

2093
02:02:46,140 --> 02:02:47,100
this ball

2094
02:02:47,110 --> 02:02:49,490
has a mass of o point one kilogram

2095
02:02:49,510 --> 02:02:50,990
weight is one newton

2096
02:02:51,000 --> 02:02:55,600
and during the impact it weighs five hundred fifty times more

2097
02:02:55,660 --> 02:02:57,870
what an incredible weight increase

2098
02:02:57,880 --> 02:03:05,520
and the average acceleration their experiences during the impact is five hundred fifty times g

2099
02:03:05,550 --> 02:03:07,310
people play tennis

2100
02:03:07,320 --> 02:03:10,910
and they have species of hundreds of miles per hour

2101
02:03:10,970 --> 02:03:14,160
these are way higher than we have here ten times higher

2102
02:03:14,180 --> 02:03:15,520
and so the

2103
02:03:15,580 --> 02:03:17,030
weight increase

2104
02:03:17,090 --> 02:03:19,570
is even more

2105
02:03:19,650 --> 02:03:21,340
now if we

2106
02:03:21,360 --> 02:03:23,820
collision were completely inelastic

2107
02:03:23,830 --> 02:03:24,900
so that if

2108
02:03:24,910 --> 02:03:26,260
it would tomato

2109
02:03:26,260 --> 02:03:28,800
or nag and this one wouldn't come up

2110
02:03:28,850 --> 02:03:30,600
the average force

2111
02:03:30,620 --> 02:03:34,630
would still be approximately the same the reason being that

2112
02:03:34,640 --> 02:03:37,060
impose will be half

2113
02:03:37,060 --> 02:03:39,580
but if the impact time also half

2114
02:03:39,590 --> 02:03:41,980
and we impose one half that of course

2115
02:03:42,020 --> 02:03:44,300
the force the average force will be the same

2116
02:03:44,310 --> 02:03:45,370
very high

2117
02:03:45,450 --> 02:03:49,170
but for a short amount of time

2118
02:03:49,180 --> 02:03:52,150
so i want to show first want to show you now the

2119
02:03:52,190 --> 02:03:55,260
these two balls one is almost complete

2120
02:03:55,260 --> 02:03:57,880
elastic collision with the floor

2121
02:03:57,970 --> 02:04:01,680
whether this is a complete elastic collision depends not only on this ball whether this

2122
02:04:01,680 --> 02:04:04,580
is super bowl it also depends on the condition of the fraud this is not

2123
02:04:04,580 --> 02:04:07,120
a very good fraud is not marked

2124
02:04:07,180 --> 02:04:09,010
so when i drop this one

2125
02:04:09,090 --> 02:04:11,320
it doesn't come up to this point here

2126
02:04:11,330 --> 02:04:13,430
so it's not completely elastic collisions

2127
02:04:13,470 --> 02:04:17,270
but it bounces pretty much showed somewhere in completely inelastic

2128
02:04:18,050 --> 02:04:19,540
completely elastic

2129
02:04:19,550 --> 02:04:20,880
it's not bad

2130
02:04:20,900 --> 02:04:22,630
right it's not bad

2131
02:04:22,640 --> 02:04:24,330
now this one

2132
02:04:24,400 --> 02:04:26,670
what it

2133
02:04:26,700 --> 02:04:28,130
looks like

2134
02:04:28,180 --> 02:04:29,240
but they don't

2135
02:04:29,240 --> 02:04:32,080
this one is completely inelastic goes to the floor

2136
02:04:32,090 --> 02:04:33,920
and it goes clunk

2137
02:04:34,000 --> 02:04:35,470
this is a small one

2138
02:04:35,490 --> 02:04:38,030
but that's it

2139
02:04:38,080 --> 02:04:40,290
and sorry impact times


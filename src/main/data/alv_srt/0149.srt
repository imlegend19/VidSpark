1
00:00:00,000 --> 00:00:01,590
on the open market

2
00:00:01,610 --> 00:00:05,400
whereas if an editors should repeal is worth three

3
00:00:05,480 --> 00:00:10,170
and by the time we add up all the NADH is that had that have

4
00:00:10,210 --> 00:00:11,380
been generated

5
00:00:11,440 --> 00:00:13,860
by the cycling

6
00:00:13,900 --> 00:00:17,520
and the carbon dioxide released at the end of the cycle here we start with

7
00:00:17,540 --> 00:00:21,520
two carbons added to four we get six carbon molecules

8
00:00:21,540 --> 00:00:26,840
we we spew up some carbon dioxide here go back to four carbon sugar

9
00:00:26,900 --> 00:00:28,900
and another two

10
00:00:28,940 --> 00:00:32,670
go up to six carbon go around again spin around the wheel and each time

11
00:00:32,670 --> 00:00:36,150
we do that we generate a lot of NADH is we generate a lot of

12
00:00:36,150 --> 00:00:39,460
effort ages is and we generate a lot of ATP

13
00:00:39,480 --> 00:00:45,770
in all cases these are highly profitable reactions simply because the NADH is

14
00:00:45,790 --> 00:00:51,290
and f eighty eight can be used in the mitochondria to generate ATP so let's

15
00:00:52,040 --> 00:00:54,460
at the energy profile of the entire

16
00:00:54,500 --> 00:00:57,590
put it all together

17
00:00:57,610 --> 00:01:00,210
this is where we started out

18
00:01:00,230 --> 00:01:01,420
at the beginning

19
00:01:01,480 --> 00:01:04,000
and this is as far as

20
00:01:04,060 --> 00:01:08,570
the end this is the end the glycolysis OK so now we're adding up

21
00:01:08,630 --> 00:01:15,250
the energy profiles of the whole sequence of reactions that constitute glycolysis which begins up

22
00:01:15,250 --> 00:01:18,920
here and and right here because pyruvate as you recall

23
00:01:18,980 --> 00:01:23,880
is the product of glycolysis the first

24
00:01:23,920 --> 00:01:28,070
the krebs cycle happens or sometimes is called the citric acid cycle

25
00:01:28,090 --> 00:01:33,150
so let's let's just get these words straight citric acid cycle because it happens to

26
00:01:33,150 --> 00:01:34,290
be one of the

27
00:01:34,300 --> 00:01:38,400
cycle or sometimes called the krebs cycle

28
00:01:38,420 --> 00:01:42,860
after the person who really discovered krebs

29
00:01:44,840 --> 00:01:49,400
the krebs cycle begins here you see how the shading changes from pyruvate

30
00:01:49,440 --> 00:01:51,560
and here we go all the way down there

31
00:01:51,570 --> 00:01:55,840
and let's now look at what happens in terms of energy exchange

32
00:01:55,860 --> 00:01:59,770
recall the early on we need to invest ATP's two

33
00:01:59,790 --> 00:02:03,650
kick up the energy state up to a year

34
00:02:03,670 --> 00:02:08,360
we invested ATP's at this stage right here and then we began to get some

35
00:02:09,570 --> 00:02:13,520
we've got these two NADH is one NADH coming from each of the three carbon

36
00:02:14,860 --> 00:02:19,460
we we you we got some more ATP's here we got some more ATP senior

37
00:02:19,480 --> 00:02:23,790
and but these NADH is could not be used productively

38
00:02:23,820 --> 00:02:26,570
before generating ATP

39
00:02:26,630 --> 00:02:28,360
in the absence of oxygen

40
00:02:28,380 --> 00:02:30,250
but in the presence of oxygen

41
00:02:30,250 --> 00:02:33,610
now we can begin to use these very profitably we can use these to these

42
00:02:33,610 --> 00:02:35,340
makes three ATP's

43
00:02:35,360 --> 00:02:39,820
and each of these obviously makes ATP's and then let's look at what happens in

44
00:02:39,820 --> 00:02:41,300
the mitochondria

45
00:02:41,360 --> 00:02:46,220
keep in mind here is the borderline between the cytosol the cytoplasm and mitochondria and

46
00:02:46,690 --> 00:02:50,090
here's where the oxygen is actually used

47
00:02:50,090 --> 00:02:53,070
and here we generate all these NADH is

48
00:02:53,090 --> 00:02:55,860
here here and here f eighty ages is

49
00:02:55,880 --> 00:02:59,020
and i keep saying it's still true just cut in spite of the fact that

50
00:02:59,020 --> 00:03:03,820
keeps saying that these NADH is can be converted to ATP is on the ATP

51
00:03:03,820 --> 00:03:08,800
is going to be diffused transmitted throughout the entire cell where they are then used

52
00:03:08,970 --> 00:03:11,790
invested in organic reactions

53
00:03:12,020 --> 00:03:14,980
here here we see all these NADH is

54
00:03:15,020 --> 00:03:18,690
and look at the overall change in free energy

55
00:03:18,690 --> 00:03:24,170
the initial steps in glycolysis didn't really take advantage glucose has inherent in it

56
00:03:24,190 --> 00:03:28,790
almost six hundred eighty killer calories from all that it's pretty high up here

57
00:03:28,840 --> 00:03:31,590
but by the time we get from here down here

58
00:03:31,650 --> 00:03:35,150
there's an enormous release of energy

59
00:03:35,170 --> 00:03:37,940
it's harvested in the form of these molecules which are then

60
00:03:37,940 --> 00:03:43,730
reinvested in the absence of oxygen this entire procedure can only go from here down

61
00:03:43,770 --> 00:03:47,710
here and a lot of this drop from here six to seven

62
00:03:47,750 --> 00:03:52,630
is futile because we have to reinvest these and it this can be used actually

63
00:03:52,630 --> 00:03:56,650
to generate more ATP as i've said repeatedly

64
00:03:56,650 --> 00:03:58,130
so this means

65
00:03:58,130 --> 00:04:01,750
in the end that we can generate an enormous amount of

66
00:04:01,750 --> 00:04:05,460
different kinds of knowledge can be brought to bear on this task now psychologist will

67
00:04:05,460 --> 00:04:06,460
do things like

68
00:04:06,480 --> 00:04:10,290
compare how people rate the strength of arguments or compare pairs of arguments and say

69
00:04:10,290 --> 00:04:14,730
which is stronger which is the better generalisation and say if we compare these three

70
00:04:15,080 --> 00:04:17,400
people typically think this is stronger

71
00:04:17,440 --> 00:04:22,770
generalisation that knowing the gorilla seals and scrolls have some arbitrary biological property provide better

72
00:04:22,770 --> 00:04:27,270
evidence for thinking that horses do that for thinking that flies do or and also

73
00:04:27,270 --> 00:04:30,870
better evidence for thinking courses do than if you were told that say this property

74
00:04:30,870 --> 00:04:34,120
was true of gorillas chimps monkeys baboons in which case you might think it's just

75
00:04:34,120 --> 00:04:39,540
something specific to primates and explain this with a more-or-less informal notions of similarity in

76
00:04:40,520 --> 00:04:42,520
but we want to get a bit more formal

77
00:04:42,540 --> 00:04:43,830
well a lot more formal

78
00:04:43,850 --> 00:04:46,750
and so how are you going to do this well here's a way to render

79
00:04:46,770 --> 00:04:48,440
the computational problem

80
00:04:50,770 --> 00:04:53,940
there's a bunch of objects in the domain that we know something about

81
00:04:53,980 --> 00:04:55,670
and what we know about

82
00:04:55,690 --> 00:04:59,670
this domain will start off with a most concrete level of knowledge will just be

83
00:04:59,710 --> 00:05:04,350
various features we know about these things so for example again psychologists have collected a

84
00:05:04,350 --> 00:05:07,210
lot of data on what features people will

85
00:05:07,210 --> 00:05:10,900
i will know for different animals so there's that we're in this case you're going

86
00:05:10,900 --> 00:05:15,660
to use of a matrix of objects feature judgments but has eighty five features for

87
00:05:15,660 --> 00:05:19,310
fifty animals and a bunch of subjects rated how

88
00:05:19,330 --> 00:05:23,000
how much each feature is associated with each animal and these features are just sort

89
00:05:23,000 --> 00:05:28,640
of basic are observable anatomical behavioral ecological properties the kind of things that child walking

90
00:05:28,640 --> 00:05:33,810
around as you're reading your kids books about animals might learn so for example the

91
00:05:33,810 --> 00:05:37,170
features that are strongly associated with elephant are

92
00:05:37,190 --> 00:05:40,190
things like being gray hairless toughskin

93
00:05:40,190 --> 00:05:43,370
big bulbous body shape long legs

94
00:05:43,380 --> 00:05:45,920
tasks walking being slow

95
00:05:45,920 --> 00:05:49,120
living in the jungle that kind of thing being strong

96
00:05:49,150 --> 00:05:53,080
so there's this matrix of of sort of known facts about these animals and there

97
00:05:53,150 --> 00:05:56,790
some new properties like say having t nine hormones that is less observable that we're

98
00:05:56,790 --> 00:05:59,870
interested in if you think it's a little bit weird to be reasoning about having

99
00:05:59,870 --> 00:06:01,600
t nine hormones

100
00:06:01,650 --> 00:06:05,670
i think of a more naturalistic task where you're reasoning about whether something is good

101
00:06:05,670 --> 00:06:09,190
to eat or whether it's poisonous or whether it wants to you these are very

102
00:06:09,190 --> 00:06:13,710
ecologically important reasoning task which again we typically get very sparse data on you want

103
00:06:13,710 --> 00:06:16,140
to be able to infer if some you know which things are going to be

104
00:06:16,140 --> 00:06:19,020
poisonous from as little data as possible

105
00:06:19,370 --> 00:06:24,600
but here psychologists have used the so-called plain predicates to be is in some sense

106
00:06:24,650 --> 00:06:29,960
knowledge free is possible except the fact that they drawn some more abstract knowledge about

107
00:06:29,960 --> 00:06:34,120
biological species and properties hence something like having t nine hormones and the idea is

108
00:06:34,120 --> 00:06:37,020
we just observe that new property for a couple of objects and we want to

109
00:06:37,020 --> 00:06:41,420
know how likely to other things have this property so somehow we need to in

110
00:06:41,420 --> 00:06:45,580
a sense bridge from a lot of features that we can observe more densely to

111
00:06:45,580 --> 00:06:48,900
some new features which are less densely observed again you can think of this as

112
00:06:48,920 --> 00:06:53,190
a kind of transfer learning problem but now where these objects instead of being independent

113
00:06:53,190 --> 00:06:58,380
draws from a bag are actually related in some interesting way to each other and

114
00:06:58,380 --> 00:07:01,080
you can also think of this is a kind of semi supervised learning problem and

115
00:07:01,080 --> 00:07:04,580
that there's a few labeled examples and a lot of unlabelled data and we want

116
00:07:04,580 --> 00:07:08,560
to learn some inductive bias to generalize to new property as as well as we

117
00:07:09,230 --> 00:07:11,730
from all the unlabelled data

118
00:07:11,750 --> 00:07:16,250
and i think the techniques that we're developing here we have applications for semi supervised

119
00:07:16,250 --> 00:07:20,060
learning in fact an earlier version of this i think in this it when not

120
00:07:20,170 --> 00:07:24,370
injuries use some semi supervised learning tutorial yesterday he talked about an early version of

121
00:07:24,370 --> 00:07:28,520
this with the tree based prior so here's the idea of of the model it

122
00:07:28,540 --> 00:07:32,580
again a hierarchical bayesian model where the lowest level or call the level of the

123
00:07:32,580 --> 00:07:36,580
data is the stuff i already told you about features you can observe these animals

124
00:07:36,580 --> 00:07:39,790
and new features that you want to generalize from sparse data

125
00:07:39,810 --> 00:07:40,940
and then we're gonna

126
00:07:40,960 --> 00:07:41,940
we're going to

127
00:07:41,960 --> 00:07:46,940
try to address that problem with two levels of a higher level background knowledge of

128
00:07:47,620 --> 00:07:50,900
hi the most immediate level of what we call the structure

129
00:07:50,980 --> 00:07:56,810
it's just some kind of relational system over these object categories which which we we

130
00:07:56,810 --> 00:08:01,580
so this is nothing else but the gradient and when they integrate gradient

131
00:08:01,640 --> 00:08:05,100
i actually get the love plus well i don't get the lot less in itself

132
00:08:05,290 --> 00:08:10,200
but if i integrate gradient squared of function which was that for relational it's still

133
00:08:10,580 --> 00:08:16,450
the for the famous taking the inner product between f and love plus of

134
00:08:16,510 --> 00:08:20,450
so plants have basically controls how small

135
00:08:20,470 --> 00:08:21,810
the function

136
00:08:21,810 --> 00:08:23,560
this is

137
00:08:24,600 --> 00:08:26,990
i don't want to access connections

138
00:08:29,970 --> 00:08:32,140
so this quantity

139
00:08:32,180 --> 00:08:36,260
is actually contrary to smooth the quantity leads directly to the plus so in some

140
00:08:36,260 --> 00:08:37,680
sense alive plus

141
00:08:37,870 --> 00:08:41,740
is a very natural formulation of this notion of more

142
00:08:41,930 --> 00:08:47,470
and what you believe this well you can build algorithms based on that

143
00:08:47,490 --> 00:08:54,140
two different things and those organisms actually work pretty well in practice

144
00:08:54,330 --> 00:08:58,790
OK so let me again should gives a little bit

145
00:08:58,850 --> 00:09:03,430
so this is a kind of semisupervised learning so

146
00:09:03,430 --> 00:09:06,450
i hope i have convinced you that the

147
00:09:06,450 --> 00:09:13,990
that the geometry isn't near intrinsically natural to semi supervised learning learning and

148
00:09:14,080 --> 00:09:18,160
the laplacian is one of the natural objects to come out of this if you

149
00:09:18,160 --> 00:09:21,910
formulate the problem in this way

150
00:09:21,930 --> 00:09:23,100
which is

151
00:09:23,180 --> 00:09:27,200
the only way but it's certainly one of the natural

152
00:09:27,220 --> 00:09:28,660
ways to formulate

153
00:09:35,140 --> 00:09:42,180
let me talk about clustering

154
00:09:44,100 --> 00:09:51,450
so what can we say about clustering so this kind of rounds up the main

155
00:09:51,450 --> 00:09:54,080
topics of

156
00:09:55,140 --> 00:09:55,930
o four

157
00:09:56,010 --> 00:09:59,740
this tutorial so what can we say

158
00:09:59,760 --> 00:10:02,100
about cluster

159
00:10:02,100 --> 00:10:08,950
and i'll talk about clustering and i'll talk about spectral clustering in the connection to

160
00:10:08,950 --> 00:10:10,770
the geometry pass

161
00:10:10,810 --> 00:10:13,290
business spectral clustering

162
00:10:13,410 --> 00:10:19,260
so first question is the falling so the the fifth kind of it's interesting because

163
00:10:19,260 --> 00:10:25,120
this is actually if you think about clustering around clustering is the mainstream

164
00:10:25,140 --> 00:10:27,890
you know statistical computer science

165
00:10:27,910 --> 00:10:33,600
problem in fact it's practically extremely important in a lot of applications

166
00:10:33,600 --> 00:10:37,030
but the clustering but you have some data you have to do something with it

167
00:10:37,040 --> 00:10:40,390
well i cluster look at what again

168
00:10:40,580 --> 00:10:44,540
for one way to actually look at putting in some sort of dimensionality reduction right

169
00:10:44,560 --> 00:10:50,950
you reduce information obtained from the data so instead of looking at the milan points

170
00:10:50,950 --> 00:10:54,370
i just have maybe twenty classed as well that season

171
00:10:54,390 --> 00:10:56,220
some summary of the

172
00:10:57,060 --> 00:11:01,850
but here is a sort of mathematical question

173
00:11:01,870 --> 00:11:08,140
right so i suppose you have points sampled from a probability distribution

174
00:11:08,140 --> 00:11:13,440
as in most statistical setting what we have and if points are sampled from a

175
00:11:13,440 --> 00:11:15,910
probability distribution

176
00:11:16,100 --> 00:11:21,510
what is the clustering of the data

177
00:11:21,560 --> 00:11:26,200
and the remarkably or what is a good clustering mean obviously not every day that

178
00:11:26,200 --> 00:11:29,720
i don't want to go into which they can be clustered which cannot but obviously

179
00:11:29,720 --> 00:11:33,620
this is a list is the natural question right i sample from from the probability

180
00:11:36,290 --> 00:11:40,930
college with a cluster this point well if you sort of abstract from the point

181
00:11:40,930 --> 00:11:45,620
itself support there already knows the probability distribution how should i just cluster the probability

182
00:11:45,620 --> 00:11:51,060
distribution and if it's a mixture of two gaussians for example which is separated we

183
00:11:51,060 --> 00:11:54,720
would expect the gaussians with the clusters

184
00:11:57,680 --> 00:12:01,930
interestingly enough there is almost there is very little work on this in the statistical

185
00:12:01,930 --> 00:12:04,120
literature there are some

186
00:12:04,160 --> 00:12:06,990
results and consistency of clustering

187
00:12:07,010 --> 00:12:13,100
from the eighties but very few those all of things

188
00:12:13,120 --> 00:12:15,720
hartigan also

189
00:12:15,740 --> 00:12:20,310
consistency of k means and some single linkage but

190
00:12:20,330 --> 00:12:24,220
but basically the question is what clusters how if i just give you a probability

191
00:12:24,220 --> 00:12:29,390
distribution what are the clusters of the probability distribution there is probably no single answer

192
00:12:29,390 --> 00:12:30,390
to that

193
00:12:30,430 --> 00:12:34,870
and about the question needs to be considered

194
00:12:40,260 --> 00:12:44,910
oh yeah and very importantly how does one estimate this cluster scheme find the data

195
00:12:45,060 --> 00:12:47,930
and i'm going to make a suggestion

196
00:12:48,060 --> 00:12:53,120
about what this clusters maybe in fact maybe should discuss

197
00:12:58,270 --> 00:13:00,450
so let's consider to set

198
00:13:00,470 --> 00:13:02,120
one setting

199
00:13:02,120 --> 00:13:06,270
is when i have

200
00:13:08,060 --> 00:13:12,140
the image is given the example of what

201
00:13:12,160 --> 00:13:28,680
let me just give an example of

202
00:13:28,740 --> 00:13:34,290
two situation when i think there is no clear clustering which agrees with our intuition

203
00:13:36,080 --> 00:13:40,530
this kind of geometry is clearly going to help us to understand what it

204
00:13:40,540 --> 00:13:44,540
OK so one situation is the following

205
00:13:44,560 --> 00:13:46,810
one situation

206
00:13:48,260 --> 00:13:50,720
mixture of gaussians

207
00:13:50,740 --> 00:13:54,060
OK so suppose they have to gauss in distribution

208
00:13:54,060 --> 00:13:58,080
so imagine i have to go sometimes like this one like that

209
00:13:58,100 --> 00:14:02,200
and the density is the sum of this two girls it's

210
00:14:02,990 --> 00:14:04,870
in fact this is one of the

211
00:14:06,760 --> 00:14:11,450
is actually one of the all the questions that this this model in fact is

212
00:14:11,450 --> 00:14:14,410
one of the oldest things in statistics

213
00:14:14,970 --> 00:14:19,680
from nineteen century mixture of gaussians

214
00:14:19,700 --> 00:14:24,310
so here's the question well when the gaussians are separated presumably

215
00:14:24,330 --> 00:14:27,740
a good clustering so you kind of have

216
00:14:27,760 --> 00:14:28,680
you know

217
00:14:28,700 --> 00:14:34,910
o point here the points here maybe a few points in between

218
00:14:34,930 --> 00:14:41,760
presumably good clustering should be something which separates nicely those girls it's that's very clear

219
00:14:41,760 --> 00:14:43,870
somehow everyone would agree

220
00:14:46,350 --> 00:14:48,540
let's look at that picture

221
00:14:48,540 --> 00:14:52,160
and this is partially obscured by this

222
00:14:52,180 --> 00:14:56,810
access connections menu

223
00:15:10,790 --> 00:15:15,330
let's look at this picture so suppose i have two spheres

224
00:15:15,410 --> 00:15:24,200
so suppose might be probability distribution is the following i have two large spheres

225
00:15:25,270 --> 00:15:27,030
so imagine just two

226
00:15:27,040 --> 00:15:29,830
so you can see there are two things which you can imagine let's just imagine

227
00:15:29,850 --> 00:15:33,350
the simple one when the balls not holding field

228
00:15:33,350 --> 00:15:37,490
essentially they are

229
00:15:37,540 --> 00:15:42,620
about two important livestock

230
00:15:42,670 --> 00:15:47,610
one is the good news and the other one is the bad news

231
00:15:47,690 --> 00:15:51,200
and simultaneously you have bought

232
00:15:51,210 --> 00:15:54,310
the good news is that the

233
00:15:54,360 --> 00:15:55,140
if you

234
00:15:55,150 --> 00:15:59,470
get the problem for example classification

235
00:16:01,450 --> 00:16:04,860
increasing the sample size to infinity

236
00:16:04,910 --> 00:16:06,300
and the

237
00:16:06,810 --> 00:16:13,850
hard already complicate the classification problem can be solved

238
00:16:13,900 --> 00:16:18,070
which means that there are classification rules

239
00:16:18,080 --> 00:16:19,130
four reach

240
00:16:19,140 --> 00:16:23,120
the error probability of the classification rule

241
00:16:23,170 --> 00:16:25,800
to the best possible

242
00:16:25,810 --> 00:16:29,430
smallest possible error probability

243
00:16:29,440 --> 00:16:34,380
if the sample by the we know any condition on the problem

244
00:16:34,390 --> 00:16:35,870
this is the good news

245
00:16:35,880 --> 00:16:37,650
university college

246
00:16:37,660 --> 00:16:39,510
the bad news

247
00:16:40,320 --> 00:16:44,560
that there is no non-trivial rate of convergence

248
00:16:44,570 --> 00:16:49,940
which means that maybe you come up with a good classifier are you have a

249
00:16:49,940 --> 00:16:52,400
program very many experiments

250
00:16:53,370 --> 00:16:57,210
and there you are very proud of its successful

251
00:16:57,260 --> 00:17:04,670
and you would like to sell these programs to make and you say that

252
00:17:04,690 --> 00:17:08,280
let's see if you have a sample of size n

253
00:17:08,290 --> 00:17:10,970
then the rate of convergence

254
00:17:10,980 --> 00:17:12,250
our each other

255
00:17:12,260 --> 00:17:15,390
you're the you are probably of your classifier goes to the

256
00:17:15,400 --> 00:17:17,620
smaller error probability

257
00:17:17,670 --> 00:17:24,650
the rate of convergence cannot be smaller than one of the local or global

258
00:17:24,700 --> 00:17:26,640
then i can show you

259
00:17:28,420 --> 00:17:30,780
one dimension of feature

260
00:17:30,830 --> 00:17:31,830
and why

261
00:17:31,840 --> 00:17:36,490
four reach although property goes to the smallest one

262
00:17:36,610 --> 00:17:39,160
but the difference between the

263
00:17:39,190 --> 00:17:41,580
you're you're are probably the and

264
00:17:41,590 --> 00:17:42,810
smallest one

265
00:17:42,820 --> 00:17:49,700
it these difference is larger than this one overall

266
00:17:49,740 --> 00:17:52,600
the the one hand you can discover any

267
00:17:52,620 --> 00:17:55,380
complex and hard part of the world

268
00:17:55,390 --> 00:17:57,690
but the price to be paid for it

269
00:17:57,740 --> 00:18:00,100
could we have a very high

270
00:18:00,210 --> 00:18:07,970
so if you get there and medical screening project huge huge grand

271
00:18:10,190 --> 00:18:16,790
on the one hand neglecting the the expert knowledge

272
00:18:16,950 --> 00:18:21,290
physicians for example at a screening

273
00:18:21,340 --> 00:18:28,420
of four brady being the possible hard rock within a year or something like that

274
00:18:28,600 --> 00:18:30,860
then we all the

275
00:18:31,070 --> 00:18:34,550
using the expert knowledge the physician knowledge

276
00:18:34,560 --> 00:18:42,250
you can generate classifiers such that if the sample size infinity you achieve the

277
00:18:42,320 --> 00:18:46,310
the best possible our probability

278
00:18:46,320 --> 00:18:51,360
but the rate of convergence can be arbitrary slow

279
00:18:51,380 --> 00:18:56,230
which means that in order to have trivial

280
00:18:56,250 --> 00:19:03,640
the rate of convergence you have less human being on the distribution

281
00:19:03,690 --> 00:19:05,600
which means that you have to do

282
00:19:05,620 --> 00:19:08,680
because the experts of the problem

283
00:19:08,690 --> 00:19:09,610
we have

284
00:19:09,620 --> 00:19:10,960
go over with

285
00:19:11,010 --> 00:19:15,500
physician but it was too too much sorry

286
00:19:17,050 --> 00:19:18,900
the definition is here

287
00:19:18,910 --> 00:19:21,460
i think that the top you the right people

288
00:19:21,470 --> 00:19:23,480
nothing of it

289
00:19:23,530 --> 00:19:27,300
it my my wife could come up with an idea

290
00:19:27,430 --> 00:19:34,740
the four fifty and we have a definition

291
00:19:35,740 --> 00:19:37,570
it could be bad or good

292
00:19:38,410 --> 00:19:40,720
i don't know

293
00:19:40,730 --> 00:19:42,030
we call these

294
00:19:42,050 --> 00:19:45,450
elementary portfolios the

295
00:19:45,460 --> 00:19:56,070
portfolio the choice of or audio has two parameters k and al

296
00:19:56,120 --> 00:20:00,900
this is that repetition of the of the procedure

297
00:20:00,950 --> 00:20:06,790
maybe you can

298
00:20:06,840 --> 00:20:08,810
and then

299
00:20:08,810 --> 00:20:12,750
so i don't quite know how they're behaving and it's quite possible that they are

300
00:20:12,750 --> 00:20:15,350
actually using additional information so

301
00:20:15,370 --> 00:20:19,910
for example a to the doctors using this additional information which will be part of

302
00:20:19,910 --> 00:20:21,770
your strategy

303
00:20:21,830 --> 00:20:26,210
which you don't have to observe in order to choose a two

304
00:20:26,210 --> 00:20:28,020
as well as all everything else

305
00:20:28,040 --> 00:20:32,160
so got the dotted line because it's not there when you actually applies strategy but

306
00:20:32,160 --> 00:20:35,810
in the ideal regime where you just observing in my view there

307
00:20:35,980 --> 00:20:37,810
there are other things that might be there

308
00:20:37,910 --> 00:20:41,500
might be other so this is a very special case

309
00:20:41,750 --> 00:20:45,850
but let's suppose that we can model it that way and what is it for

310
00:20:46,660 --> 00:20:49,460
is that into that again

311
00:20:49,480 --> 00:20:55,210
by d separation moralisation it says various things one thing it says

312
00:20:55,270 --> 00:21:02,210
is that l this additional patient variable variables the response is the patient's blood count

313
00:21:02,210 --> 00:21:07,940
after you've given so many cc's of this injection it says that this is independent

314
00:21:07,940 --> 00:21:10,230
of the strategy in particular

315
00:21:10,250 --> 00:21:17,180
how you came to choose to give that doesn't matter that there is a sort

316
00:21:17,180 --> 00:21:21,940
of natural modular components irrespective of what you do and how you decide what to

317
00:21:21,940 --> 00:21:24,910
do which says howell depends on a one

318
00:21:24,960 --> 00:21:28,160
likewise it says the response y

319
00:21:28,180 --> 00:21:31,040
if i tell you a one a two and l one

320
00:21:31,060 --> 00:21:36,810
the model for how why depends on those again is going to be the same

321
00:21:36,810 --> 00:21:38,660
in all possible regimes

322
00:21:38,750 --> 00:21:42,910
again this is a story which might or might not be a true story

323
00:21:42,960 --> 00:21:46,810
and you have to think about whether you can justify it before you use that

324
00:21:46,810 --> 00:21:52,690
picture to work out its consequences but it's interesting to do the analysis might a

325
00:21:52,730 --> 00:21:56,870
part of work i recommend you very highly utterly wonderful but where i think he

326
00:21:56,870 --> 00:22:00,870
falls down to is he doesn't pay enough attention to getting started

327
00:22:00,890 --> 00:22:04,410
he says once we got it we do these great things with which is perfectly

328
00:22:05,600 --> 00:22:10,250
but once you DAG a big step you've got to say why is this the

329
00:22:10,270 --> 00:22:16,600
appropriate representation of my problem and then his context argument

330
00:22:16,640 --> 00:22:26,520
typically yes the there this the additional variables i mean this is an intermediate outcome

331
00:22:26,520 --> 00:22:28,770
which represents the patient's progress

332
00:22:32,190 --> 00:22:36,750
well these are the two actions i take but

333
00:22:36,770 --> 00:22:41,440
i'm i might depending the might be about this some random coin flipping i might

334
00:22:41,440 --> 00:22:46,980
or might not be able to reproduce alpha most probably not

335
00:22:46,980 --> 00:22:51,790
this is this could be binary things just stop going various circumstances could be continuous

336
00:22:53,330 --> 00:22:56,750
so yes to the question what do we need only answer is my story that

337
00:22:56,750 --> 00:23:00,230
i'm telling here we need to

338
00:23:00,250 --> 00:23:03,370
so the point is to say that

339
00:23:03,410 --> 00:23:07,420
even though sort of go back even though you is in that picture

340
00:23:09,330 --> 00:23:15,020
diagram represents these conditional independencies in which you does not make is not mentioned

341
00:23:15,080 --> 00:23:19,120
so that picture even with the u allows me to say this is and when

342
00:23:19,120 --> 00:23:22,910
i can say those things i can do quite a lot but other pictures will

343
00:23:22,910 --> 00:23:27,180
not allow me to do that if for example this additional variable had an effect

344
00:23:27,180 --> 00:23:28,750
on the response

345
00:23:28,770 --> 00:23:33,250
then you could use the d separation moralisation

346
00:23:33,290 --> 00:23:35,910
to deduce that from the picture

347
00:23:35,920 --> 00:23:40,500
so my to my not hold depends on the exact assumptions you make that if

348
00:23:40,520 --> 00:23:43,410
if you're lucky enough that doesn't hold

349
00:23:43,410 --> 00:23:48,250
you can argue in favor of that story then you're have cost

350
00:23:48,270 --> 00:23:53,500
what i care about is the distribution of the predictive distribution of the outcome when

351
00:23:53,500 --> 00:23:56,040
i operator particular strategy

352
00:23:56,100 --> 00:24:00,230
so i decided my strategy was sort of outcomes and i'm going to get

353
00:24:00,270 --> 00:24:05,480
i haven't ever observed data doing that i've only got my observation about

354
00:24:05,540 --> 00:24:10,620
so i'm i'm making this bold induction but what i do is i actually get

355
00:24:10,690 --> 00:24:16,020
joint distribution for all the stochastic variables i integrate out these three so that's what

356
00:24:16,020 --> 00:24:20,830
these gone and the joint distribution a one distribution by one

357
00:24:20,850 --> 00:24:22,290
given sigma

358
00:24:22,310 --> 00:24:26,180
that's fine because i told you what the strategy is so you know exactly how

359
00:24:26,180 --> 00:24:27,290
anyone will

360
00:24:27,310 --> 00:24:33,000
be chosen in that strategy possibly deterministically possibly with the coin tossing

361
00:24:33,540 --> 00:24:36,230
then i consider the l given a one

362
00:24:36,290 --> 00:24:40,290
really it should be l given sigma and a one should in principle depend on

363
00:24:40,290 --> 00:24:44,980
the strategy but i have we don't care about the strategy because l is independent

364
00:24:44,980 --> 00:24:47,560
of strategy saying the ones i know i one

365
00:24:47,830 --> 00:24:49,850
again we come to a two

366
00:24:49,850 --> 00:24:51,440
that's the end

367
00:24:51,460 --> 00:24:53,620
conditional on the part of a one and now

368
00:24:53,640 --> 00:24:58,680
and that will probably will depend on the strategy sigma notice that

369
00:24:58,690 --> 00:25:03,520
the strategy sigma is an interventional strategy so this dotted arrows going away

370
00:25:04,040 --> 00:25:08,690
the in these strategies only going to depend on the observed variables

371
00:25:08,980 --> 00:25:11,960
and i know i've told you what that is that's written down my piece of

372
00:25:14,520 --> 00:25:19,580
and finally this last is why should be given sigma but once again because of

373
00:25:19,580 --> 00:25:23,790
this property it doesn't matter and i get that from the observation regime so by

374
00:25:23,830 --> 00:25:28,020
combination of ingredients from ingredients from the observational regime

375
00:25:28,020 --> 00:25:31,350
and some ingredients which are written down on a piece of paper which tells me

376
00:25:31,350 --> 00:25:36,830
what my strategy is i competed altogether and what was so sometimes you can do

377
00:25:36,830 --> 00:25:41,000
this when you can get these properties sometimes you can't it all depends on the

378
00:25:41,000 --> 00:25:43,850
exact assumptions that you can actually make

379
00:25:48,620 --> 00:25:55,660
you isn't so the question is you've been integrated out yes and no universal you

380
00:25:55,660 --> 00:25:59,920
is not observed by in is not part of your strategy allowed to observe the

381
00:26:00,890 --> 00:26:06,580
you're observing maybe using he may be observing if you don't have been integrated in

382
00:26:06,580 --> 00:26:11,180
a sense yes but not directly has spinning in an integrated by being ignored this

383
00:26:11,180 --> 00:26:14,640
is the law of property so forget the picture this is the property of the

384
00:26:14,640 --> 00:26:17,640
four variables l a one a two and y

385
00:26:18,580 --> 00:26:21,190
you i could mention you as well but i don't have to because i don't

386
00:26:21,190 --> 00:26:25,980
care about it and now i sort of immediately restricted to the distribution of these

387
00:26:26,680 --> 00:26:31,680
and has these properties and i just use that

388
00:26:31,730 --> 00:26:34,580
so this is this is to get there are many many problems that you can

389
00:26:34,580 --> 00:26:38,790
approach with this technology this is to give you flavor some

390
00:26:47,520 --> 00:26:48,940
thank you very much

391
00:26:54,100 --> 00:26:59,730
so the question is if it is a latent variables connected to order stochastic variables

392
00:26:59,730 --> 00:27:04,480
are you in love from the is generally it generally you are in trouble

393
00:27:04,550 --> 00:27:12,710
generally in the presence of unobserved latent variables which for you can't get the complete

394
00:27:12,920 --> 00:27:17,100
joint distribution and you can related to the cross generally you're in trouble and there's

395
00:27:17,100 --> 00:27:18,630
almost the same class, so--

396
00:27:18,650 --> 00:27:20,290
so you can have classes merging.

397
00:27:20,330 --> 00:27:23,900
it's just a much better way of handling data with multiple manifolds.

398
00:27:23,940 --> 00:27:27,400
you go up in dimensionality and then squeeze out the excess freedom

399
00:27:27,460 --> 00:27:29,630
by doing this kind of learning.

400
00:27:29,690 --> 00:27:35,400
o thing

401
00:27:39,770 --> 00:27:41,600
OK, two layers work better.

402
00:27:41,600 --> 00:27:45,400
so there's empirical results for this. i'll show some more empirical results later.

403
00:27:45,460 --> 00:27:47,460
i can give you

404
00:27:47,460 --> 00:27:50,420
a rationalisation rather than an intuition

405
00:27:50,600 --> 00:27:53,920
here's a rationalization. suppose i wanted a generative model.

406
00:27:53,960 --> 00:27:56,000
in this RBM here

407
00:27:56,020 --> 00:28:00,790
by using pairwise interactions, can create these ravines

408
00:28:00,810 --> 00:28:05,440
you can't create ravines by pairwise interactions here 'cause the interactions won't do what you want.

409
00:28:05,460 --> 00:28:07,060
but you can do it up here

410
00:28:07,130 --> 00:28:10,670
and then we need a layer of hidden units to map these things to

411
00:28:11,690 --> 00:28:13,980
so if you view it that way 'round, it's just

412
00:28:14,020 --> 00:28:15,790
you somehow create the ravines here

413
00:28:15,810 --> 00:28:19,170
and then you map them nonlinearly to the image

414
00:28:19,190 --> 00:28:21,060
that sort of justifies that architecture,

415
00:28:21,080 --> 00:28:21,630
a bit.

416
00:28:21,650 --> 00:28:23,960
well, at least rationalizes it

417
00:28:25,040 --> 00:28:27,540
i also did some fine tuning of this

418
00:28:27,540 --> 00:28:30,150
to make it be a better generator

419
00:28:30,150 --> 00:28:33,380
and i'm not going to sort of focus on the fine tuning in this tutorial

420
00:28:33,420 --> 00:28:37,170
it turns out we can now learn these things without any fine-tuning and have them work

421
00:28:37,190 --> 00:28:38,500
just about as well

422
00:28:38,560 --> 00:28:43,210
certainly without this kind of generative fine tuning

423
00:28:45,100 --> 00:28:47,730
this is in the tutorial so you can go read it if you want

424
00:28:47,830 --> 00:28:50,670
and maybe in question time you can ask me more about this, but i'm not going to

425
00:28:50,670 --> 00:28:52,830
dwell on it now

426
00:28:53,170 --> 00:28:57,190
so now i want to show you is what happens if we

427
00:28:58,040 --> 00:29:03,730
layers to model the images like that

428
00:29:04,830 --> 00:29:07,500
so there is the same network

429
00:29:07,540 --> 00:29:11,480
i actually programmed all of this except the interface. the very cool-looking interface was done by

430
00:29:11,480 --> 00:29:15,850
an undergraduate who looked at my demo and said, i can make your demo look much cooler

431
00:29:15,870 --> 00:29:22,460
so here's the image, here's 500, binary features, 500, 2000. here's the ten labels

432
00:29:22,460 --> 00:29:25,440
here's the identities of the labels: nought, one, two, and so on

433
00:29:25,480 --> 00:29:28,290
here's some images that we can feed to the network

434
00:29:28,290 --> 00:29:32,380
so let's first get it to do some perception, some recognition

435
00:29:32,420 --> 00:29:35,420
we feed in a four

436
00:29:35,440 --> 00:29:38,710
and now what we can do is just run it: boing boing boing boing like

437
00:29:39,530 --> 00:29:40,960
and see what it thinks

438
00:29:41,000 --> 00:29:47,630
is--and we're gonna run it as a stochastic binary network

439
00:29:47,670 --> 00:29:51,350
so you see these keep changing, these keep changing, and these keep changing, each time we do

440
00:29:52,270 --> 00:29:53,690
but this never changes.

441
00:29:53,730 --> 00:29:56,540
it's very sure that that's a four.

442
00:29:56,540 --> 00:30:00,290
now if i run it faster, you'll see there's a subset of these that don't change much like that

443
00:30:00,290 --> 00:30:01,520
one there,

444
00:30:02,080 --> 00:30:04,610
and you can see that if i run fast

445
00:30:04,630 --> 00:30:08,770
your visual systems will do nice things for you

446
00:30:08,810 --> 00:30:11,310
you see this sort of static subset popping out

447
00:30:11,830 --> 00:30:17,370
i have training in psychology, so we need to do a control experiment to make sure it

448
00:30:17,370 --> 00:30:20,230
doesn't always see a four

449
00:30:20,230 --> 00:30:26,610
so it saw a five almost all the time there.

450
00:30:26,630 --> 00:30:29,850
of course we can now be mean to it

451
00:30:29,900 --> 00:30:32,980
and give it things where it's not quite clear what they are.

452
00:30:40,190 --> 00:30:43,480
you'll see it spends most of its time oscillating between four and eight,

453
00:30:43,500 --> 00:30:45,230
which seems pretty appropriate there.

454
00:30:45,230 --> 00:30:47,380
occasionally thinks it's a six or something.

455
00:30:47,420 --> 00:30:52,290
let me give it one more because i like it so much

456
00:30:52,400 --> 00:30:54,790
that's clearly either one or seven

457
00:30:54,810 --> 00:30:56,960
or just possibly two

458
00:30:56,980 --> 00:31:00,440
and since i programmed it and it's my baby, i want to point out that it's

459
00:31:00,440 --> 00:31:05,560
not so unreasonable that it occasionally thinks it's a four, 'cause a four could be like that, right?

460
00:31:12,150 --> 00:31:15,020
most of the time it thinks seven or one.

461
00:31:15,060 --> 00:31:18,350
that was one and that was seven, and it ends up on seven. the fact that it ends up there doesn't

462
00:31:18,350 --> 00:31:19,730
mean anything

463
00:31:19,730 --> 00:31:22,630
the fact that this example is in this row

464
00:31:22,650 --> 00:31:25,100
means that if you learn it a long time on average

465
00:31:25,100 --> 00:31:30,100
then seven is the most likely bet

466
00:31:30,940 --> 00:31:37,420
so that's the net during recognition where we just go chong chong chon

467
00:31:37,420 --> 00:31:41,790
it turns out you can do that stochastically and average here,

468
00:31:41,920 --> 00:31:45,150
or you can just do a mean field version, that is, you compute the real values here,

469
00:31:45,150 --> 00:31:49,650
and then the real values here from those real values, then the real values here and the real values here.

470
00:31:49,650 --> 00:31:54,420
so we

471
00:32:01,980 --> 00:32:05,900
all right

472
00:32:06,110 --> 00:32:09,420
this is due to

473
00:32:09,530 --> 00:32:14,970
this with the

474
00:32:20,770 --> 00:32:28,590
you're wrong

475
00:32:32,150 --> 00:32:34,900
so i think

476
00:32:36,300 --> 00:32:38,150
so c

477
00:32:38,350 --> 00:32:43,150
we what

478
00:33:37,170 --> 00:33:42,110
this work

479
00:33:42,140 --> 00:33:43,900
we should

480
00:34:09,650 --> 00:34:11,990
three days

481
00:34:12,010 --> 00:34:14,400
well i

482
00:34:16,530 --> 00:34:19,510
thank you

483
00:34:46,250 --> 00:34:50,930
to give you some

484
00:35:00,840 --> 00:35:08,490
on the

485
00:35:28,500 --> 00:35:39,600
i don't you want to find

486
00:36:21,130 --> 00:36:22,950
this very simple model

487
00:36:30,620 --> 00:36:33,340
more four

488
00:36:39,930 --> 00:36:40,920
the team

489
00:36:40,930 --> 00:36:44,660
so just design problem

490
00:36:58,990 --> 00:37:06,520
one each

491
00:37:06,720 --> 00:37:10,380
to this

492
00:37:31,380 --> 00:37:32,960
well we do

493
00:37:33,270 --> 00:37:38,460
try to find out more

494
00:37:50,090 --> 00:37:53,790
well does mean

495
00:37:53,810 --> 00:37:58,460
it's the

496
00:38:01,990 --> 00:38:04,760
the man who knows

497
00:38:14,850 --> 00:38:18,540
to the

498
00:38:18,560 --> 00:38:23,060
he invented

499
00:38:23,060 --> 00:38:27,170
image tagging or by due to the same very quickly is because been

500
00:38:27,180 --> 00:38:31,000
doing it for months so there's a commercial base image tagging

501
00:38:31,600 --> 00:38:34,720
it is google baidu and not other companies as well actually

502
00:38:35,090 --> 00:38:37,430
soever on version of this commercial nets

503
00:38:37,550 --> 00:38:40,990
we've got this really only a few months after or the total people

504
00:38:40,990 --> 00:38:44,180
within participate in the original competition this is called

505
00:38:44,180 --> 00:38:48,290
the overfeat system that overfeat where you google you'll

506
00:38:48,300 --> 00:38:50,990
find it is a piece of code you can download and run

507
00:38:51,300 --> 00:38:54,510
you show it to image from a camera our from file and it will

508
00:38:54,710 --> 00:38:57,990
produce classification on the output

509
00:38:57,990 --> 00:39:00,730
the feature vector that you level you want you can use this as

510
00:39:00,730 --> 00:39:02,790
input to whatever system you want to do

511
00:39:04,520 --> 00:39:08,590
this saluted better than this just to network is a successor so

512
00:39:08,600 --> 00:39:11,700
this this to my work on this last year someone a

513
00:39:11,950 --> 00:39:17,630
join google months ago and the participated in the the latest imagenet

514
00:39:17,640 --> 00:39:20,690
competition two thousand or fourteen

515
00:39:20,990 --> 00:39:26,660
and k his team well on essentially all three of the competitions

516
00:39:26,670 --> 00:39:29,970
are classification detection and localisation

517
00:39:31,080 --> 00:39:33,930
also in the case localisation on the if they use extra

518
00:39:34,130 --> 00:39:34,730
extra data

519
00:39:37,560 --> 00:39:41,470
so kind of that the curve is googlenet which is

520
00:39:42,490 --> 00:39:46,520
world on words and it's the performance of this is using

521
00:39:48,910 --> 00:39:50,810
so this other filters on the system

522
00:39:51,380 --> 00:39:56,960
me skip over some learning details and go to how can we localisation

523
00:39:56,970 --> 00:40:01,530
objects localisation is we can use this idea of replicating

524
00:40:01,820 --> 00:40:04,400
network over over field so actually we take

525
00:40:04,840 --> 00:40:08,130
the image we scary down multiple sizes and then we run the

526
00:40:08,130 --> 00:40:11,020
commercial that this sliding window over all scales so here we

527
00:40:11,020 --> 00:40:14,320
only have one in here we have number of different frames those

528
00:40:14,320 --> 00:40:17,290
are the yellow squares if you want and for each of those where

529
00:40:17,290 --> 00:40:20,520
we get an answer whether what's the object what's score instead of

530
00:40:20,520 --> 00:40:24,250
the square but what we do in addition to this so we get so keep

531
00:40:24,260 --> 00:40:27,980
maps for each category and we can do some sort of voting mechanism

532
00:40:27,980 --> 00:40:31,220
maximum suppression but allowed to figure out what the dominant object

533
00:40:31,220 --> 00:40:33,270
in the image if you want to localize

534
00:40:35,480 --> 00:40:39,270
what you need to do is also predict what about boxes so in fact

535
00:40:39,280 --> 00:40:41,940
what are part is the show showing is the

536
00:40:42,170 --> 00:40:46,550
the bounding boxes the predicted value boxes are are produced

537
00:40:46,550 --> 00:40:49,450
by the system so this the system is looking at a particular

538
00:40:49,450 --> 00:40:53,210
window in the image and is trained to classify what it sees

539
00:40:53,210 --> 00:40:56,670
in the window the main object in the window is also trying to produce

540
00:40:56,670 --> 00:40:59,410
a prediction for numbers indicate the position of the on both

541
00:40:59,410 --> 00:41:03,200
so object scene so you could be looking at just the head of that

542
00:41:03,210 --> 00:41:07,300
there are this where this size but if it sees the head and neck

543
00:41:07,300 --> 00:41:10,600
knows where there is a predicts where learning about sort of actually

544
00:41:10,600 --> 00:41:14,730
what what you see here are the put predictions of all windows regardless

545
00:41:14,740 --> 00:41:18,570
of where they are in the original image so and so this easy

546
00:41:18,570 --> 00:41:21,990
to do kind of voting mechanisms here are the dominant object here

547
00:41:21,990 --> 00:41:24,060
is there that you do localisation

548
00:41:26,560 --> 00:41:29,450
and or really well for animals of various kinds

549
00:41:31,860 --> 00:41:35,510
words you know so you can use this for detection as well so detection

550
00:41:35,510 --> 00:41:38,210
is exactly the same system except now you allow the system to

551
00:41:38,210 --> 00:41:42,560
produce multiple answers per image basically highest-scoring objects

552
00:41:42,570 --> 00:41:46,080
overlap to much so a to process groundtruth and that's

553
00:41:46,680 --> 00:41:50,400
and the system here's another one with burrito works really well

554
00:41:50,400 --> 00:41:51,090
burrito those

555
00:41:54,200 --> 00:41:59,080
these are makes mistakes so the correct is a person yeah and it says

556
00:41:59,090 --> 00:42:03,760
it is and doesn't detect person apparently he two ties but these

557
00:42:03,770 --> 00:42:09,010
are the system as we can which is a

558
00:42:11,060 --> 00:42:15,160
this is most but also at the time of of the competition we actually

559
00:42:15,170 --> 00:42:19,020
got what this is a measure called mean average precision we

560
00:42:19,020 --> 00:42:22,370
were ninety percent of this to teams from use of a sudden and you

561
00:42:22,370 --> 00:42:25,450
see also using a convnet work so you better than us and then we

562
00:42:25,450 --> 00:42:27,200
need to reach after we had a more

563
00:42:27,200 --> 00:42:29,800
time which learning we got twenty four percent and then

564
00:42:29,800 --> 00:42:33,190
cmos later roscoe actually from berkeley also the commercial net

565
00:42:33,710 --> 00:42:36,940
and if you other tweaks with sort of attention to thirty four

566
00:42:36,940 --> 00:42:41,350
percent and now the rule net technique is that for the something

567
00:42:42,020 --> 00:42:43,720
so it's progressing really quick

568
00:42:46,730 --> 00:42:52,020
so that's and googlenet again is a direct descendant of that system

569
00:42:52,030 --> 00:42:55,920
is the same guy basically summoner so that you know

570
00:42:56,090 --> 00:42:58,630
detection people and sunglasses and babies and

571
00:42:59,460 --> 00:43:03,890
dogs and whatever this is

572
00:43:07,440 --> 00:43:13,450
mistakes to it thinks that's a corkscrew that actually stage

573
00:43:14,110 --> 00:43:18,730
doesn't like greece robberies but i x green strawberries either so

574
00:43:18,730 --> 00:43:20,270
there are five

575
00:43:21,650 --> 00:43:25,670
hands of five point five eight

576
00:43:27,130 --> 00:43:30,860
so it takes me about to their that's a

577
00:43:30,860 --> 00:43:33,210
five do to a

578
00:43:33,230 --> 00:43:36,690
it takes make continues around takes me up to about

579
00:43:36,710 --> 00:43:41,250
we're about will pass three

580
00:43:41,310 --> 00:43:43,130
that there

581
00:43:43,290 --> 00:43:45,750
two a

582
00:43:45,810 --> 00:43:48,610
three a

583
00:43:48,630 --> 00:43:51,600
six me around

584
00:43:51,610 --> 00:43:56,600
two somewhere like about their

585
00:43:56,670 --> 00:43:57,960
so each time i

586
00:43:59,310 --> 00:44:01,710
multiply by

587
00:44:01,770 --> 00:44:05,730
if i may add another way it's taking me another

588
00:44:05,730 --> 00:44:07,560
these distance around

589
00:44:07,600 --> 00:44:09,290
the idea is that

590
00:44:09,360 --> 00:44:10,480
that if

591
00:44:10,520 --> 00:44:14,790
a is for example on and it's not too close to power of

592
00:44:14,810 --> 00:44:16,750
two or

593
00:44:17,560 --> 00:44:20,290
then what's happening is that sort of

594
00:44:20,290 --> 00:44:24,830
throwing it into is another slot on the different things to find out around five

595
00:44:24,830 --> 00:44:26,770
k being very big

596
00:44:26,770 --> 00:44:30,940
then k times a is going around k times where does it end up it's

597
00:44:30,940 --> 00:44:33,500
like spinning wheel of fortune something

598
00:44:33,520 --> 00:44:35,880
the unions somewhere

599
00:44:35,940 --> 00:44:39,290
OK so that's basically the notion

600
00:44:39,290 --> 00:44:42,940
OK that's basically motion it's going to end up in some

601
00:44:42,980 --> 00:44:46,770
place so basically awareness k and

602
00:44:46,810 --> 00:44:50,790
well sort of the world around and ends up at some point

603
00:44:50,810 --> 00:44:53,210
OK so that's why that's

604
00:44:53,210 --> 00:44:54,190
you know

605
00:44:54,190 --> 00:44:58,630
it tends to be a fairly good but these heuristic methods for hash for any

606
00:44:58,630 --> 00:44:59,830
hash function

607
00:44:59,880 --> 00:45:01,170
you can always

608
00:45:01,190 --> 00:45:04,080
find is that it is can make it operate

609
00:45:04,130 --> 00:45:07,290
so the question is what do you use in practice

610
00:45:07,340 --> 00:45:11,360
OK the second

611
00:45:18,310 --> 00:45:23,080
topic that i wanna

612
00:45:25,730 --> 00:45:28,020
so we talked about resolving

613
00:45:28,040 --> 00:45:30,920
collisions by changing

614
00:45:31,900 --> 00:45:34,360
is another way of resolving collisions

615
00:45:34,400 --> 00:45:37,750
which is useful

616
00:45:38,250 --> 00:45:40,040
resolving collisions

617
00:45:40,110 --> 00:45:44,900
i what's called opened

618
00:45:48,880 --> 00:46:02,460
and the idea is in this method is we have no storage

619
00:46:02,480 --> 00:46:03,360
four links

620
00:46:03,830 --> 00:46:10,440
so i was my training i need an extra links

621
00:46:11,270 --> 00:46:12,150
in each

622
00:46:13,670 --> 00:46:14,380
in order to be able

623
00:46:16,330 --> 00:46:19,880
that's not necessarily a big overhead for some applications

624
00:46:19,960 --> 00:46:24,250
i don't have to touch those records all

625
00:46:24,620 --> 00:46:26,690
and for those

626
00:46:26,790 --> 00:46:30,230
an open addressing is a useful way to

627
00:46:30,900 --> 00:46:35,310
but to resolve collisions

628
00:46:35,360 --> 00:46:39,270
so the idea is with open addressing is

629
00:46:39,400 --> 00:46:42,810
five has two given slot

630
00:46:42,810 --> 00:46:45,830
in this slide is full

631
00:46:45,900 --> 00:46:47,190
what i do is

632
00:46:47,190 --> 00:46:49,460
it is actually

633
00:46:49,500 --> 00:46:52,690
with the different hash functions

634
00:46:52,790 --> 00:46:55,920
my second hash check that's why

635
00:46:55,980 --> 00:46:58,670
that's what is for

636
00:46:58,690 --> 00:47:01,020
OK then i actually

637
00:47:01,040 --> 00:47:03,100
i keep this probe sequence

638
00:47:03,100 --> 00:47:06,080
which hopefully is a permutation so i'm not

639
00:47:06,110 --> 00:47:10,270
going back and checking things i've already checked until i find a place to put

640
00:47:11,560 --> 00:47:15,560
and if i got a good probs sequence so hopefully then find a place to

641
00:47:15,560 --> 00:47:18,150
put it fairly quickly

642
00:47:18,270 --> 00:47:21,080
and then to search

643
00:47:21,130 --> 00:47:24,480
i just follow the same probe sequence

644
00:47:24,500 --> 00:47:29,710
so can express and so the idea here is problem

645
00:47:31,130 --> 00:47:40,670
just that way

646
00:47:41,730 --> 00:47:44,630
still an empty slot

647
00:47:44,630 --> 00:47:49,610
but the two observed mean two plotted here have very low value

648
00:47:49,630 --> 00:47:53,480
so this is quite reasonable and maybe

649
00:47:53,480 --> 00:47:59,360
quite expected but this is an interesting plot over here which

650
00:47:59,380 --> 00:48:04,170
it's not so expect me so this is usually vision with numbers which are slightly

651
00:48:06,340 --> 00:48:11,170
smaller than one so remember this is only have positive but they can be smaller

652
00:48:11,170 --> 00:48:12,010
than one

653
00:48:12,030 --> 00:48:16,420
and we still have to implement our prior belief that we are dealing with a

654
00:48:16,420 --> 00:48:22,400
fair dice because all the probabilities of these numbers here a sort of identical but

655
00:48:22,550 --> 00:48:28,820
what not happens if these numbers become smaller smaller than one that the probability is

656
00:48:28,820 --> 00:48:30,630
an extreme values

657
00:48:32,190 --> 00:48:33,630
they like

658
00:48:33,880 --> 00:48:35,860
so although we've sort of implementing

659
00:48:35,880 --> 00:48:41,010
and expected sense anyway so we are dealing with a fair dice any sample he

660
00:48:41,010 --> 00:48:45,550
dies generated by this prior distribution becomes more and more

661
00:48:45,570 --> 00:48:50,730
load and if we make these numbers even smaller than we will

662
00:48:50,760 --> 00:48:54,650
almost exclusively observed these extreme points

663
00:48:54,670 --> 00:48:57,150
and this

664
00:48:57,170 --> 00:49:03,610
a little bit surprising when observe the first and we also have a very important

665
00:49:03,860 --> 00:49:09,900
effect later in usually processes because the sort of explanation why these processes will lead

666
00:49:09,900 --> 00:49:13,090
to very clustered solutions

667
00:49:13,110 --> 00:49:18,490
the prior sort of essentially says on average i believe this is the a fact

668
00:49:18,490 --> 00:49:24,150
that but every single dies i'm producing this is extremely unfair

669
00:49:24,170 --> 00:49:29,070
least this is sort of the bias implemented by by this usually prior distribution if

670
00:49:29,070 --> 00:49:33,090
these numbers become smaller and smaller

671
00:49:37,510 --> 00:49:43,900
so this is the set of them of the model and to do inference in

672
00:49:44,210 --> 00:49:45,210
this model

673
00:49:45,210 --> 00:49:51,210
later on in the day usually processes it's important to consider how to generate samples

674
00:49:51,210 --> 00:49:54,210
from this model models

675
00:49:54,230 --> 00:50:00,780
so let's look at maybe first look a graphical representation of the situation so

676
00:50:01,130 --> 00:50:06,130
what i mean by generating sentences we start with some i find not i

677
00:50:06,150 --> 00:50:12,610
parameters could but also put together five star and based on these

678
00:50:12,630 --> 00:50:17,960
the parameters describing the prior distribution we generate a sample of g

679
00:50:17,980 --> 00:50:24,880
using the dirichlet distribution and then given g we generate samples from

680
00:50:24,900 --> 00:50:28,010
the different sizes of the dice

681
00:50:28,110 --> 00:50:32,670
in this case we do and experiments with through the eyes and patterns and observe

682
00:50:32,860 --> 00:50:34,280
in different areas

683
00:50:34,280 --> 00:50:36,530
of the results of the dice

684
00:50:36,550 --> 00:50:42,380
and there's more compact representation of this is this dependency is sort of repeated n

685
00:50:42,380 --> 00:50:46,510
times one simply draws square around this

686
00:50:46,530 --> 00:50:51,760
note over here indicates how often the process is repeated this is called the plate

687
00:50:51,760 --> 00:50:58,300
representation is just a shorthand notation for the situation here on the left so the

688
00:50:58,300 --> 00:51:04,650
generating samples essentially means we have a factory of disassembly and we produce unfair dices

689
00:51:04,650 --> 00:51:05,940
according to our

690
00:51:05,940 --> 00:51:09,110
prior assumptions about

691
00:51:09,190 --> 00:51:16,590
the probability of the edge in g then take this emphasizes and the diocese and

692
00:51:18,380 --> 00:51:20,880
the data below a given

693
00:51:29,840 --> 00:51:35,650
so the first approach is to do exactly what i have described the first generate

694
00:51:35,650 --> 00:51:40,760
a sample of g of this of the parameters of the diocese and then you

695
00:51:40,780 --> 00:51:48,210
generate this talk is that it's not straightforward to generate samples for g but there

696
00:51:48,210 --> 00:51:53,030
are different approaches and i don't want to get too much into detail how this

697
00:51:53,030 --> 00:51:57,230
is done but if you look at the literature there are different ways of doing

698
00:51:57,230 --> 00:52:02,590
it here is this describing descended from independent gamma distributions to use in certain shape

699
00:52:02,590 --> 00:52:06,530
parameters and normalize the service but i don't want to get into a lot of

700
00:52:06,530 --> 00:52:12,320
detail here in the late NDP case and you post case this is more interesting

701
00:52:12,320 --> 00:52:15,340
and the leaders to the stick breaking representation

702
00:52:15,530 --> 00:52:19,090
but given that we have generated the sample from initially

703
00:52:19,110 --> 00:52:24,380
distribution is a simple of course to generate samples of the of of the tosses

704
00:52:24,840 --> 00:52:29,730
because this jesus simply the probabilities of observing a certain result

705
00:52:32,130 --> 00:52:40,490
so this is the first approach the second approach is also very interesting we never

706
00:52:40,510 --> 00:52:46,490
generate the sample of g directly but we directly generate samples of the results of

707
00:52:46,490 --> 00:52:49,510
the of the of the diocese

708
00:52:49,530 --> 00:52:53,800
and to do that we use the equation we have observed we have used before

709
00:52:53,800 --> 00:52:55,760
before we set even

710
00:52:55,780 --> 00:53:01,750
past observations of the results of of of process we want to predict the result

711
00:53:01,750 --> 00:53:04,400
of the next to us and we use we came up with this formula over

712
00:53:04,400 --> 00:53:07,900
here we can also use exactly the same formula two

713
00:53:07,920 --> 00:53:10,880
generate samples

714
00:53:10,880 --> 00:53:13,460
off and specific but unknown

715
00:53:13,480 --> 00:53:17,880
and the lord that

716
00:53:17,900 --> 00:53:23,840
so in this sense we have generated some samples to put them the condition and

717
00:53:23,840 --> 00:53:28,630
use exactly the same formula to estimate the probability of the probability of observing the

718
00:53:29,380 --> 00:53:31,760
the result of the next

719
00:53:35,900 --> 00:53:40,170
the advantage here is that we never have to transcend from g a particular gene

720
00:53:40,440 --> 00:53:45,510
might become late on infinite dimensional and it's not very easy to of she this

721
00:53:45,650 --> 00:53:50,090
very nice equation because we never have to do that we can directly sample from

722
00:53:50,090 --> 00:53:56,210
the results of the of the diocese hospital

723
00:53:56,230 --> 00:54:01,030
because interpret this and in this way with probability proportional to n

724
00:54:01,050 --> 00:54:04,650
he was severed from the distribution with empirical counts

725
00:54:04,670 --> 00:54:10,260
and with probability proportional to alpha not generated sample according to the

726
00:54:10,260 --> 00:54:15,940
distribution implied by the advocates the size of a nice interpretation of this i again

727
00:54:16,230 --> 00:54:18,170
with very weak we will

728
00:54:18,400 --> 00:54:23,050
by the way a from the empirical data from the empirical estimates of the probabilities

729
00:54:23,050 --> 00:54:25,030
matches because it or every

730
00:54:27,570 --> 00:54:32,520
i OK changed my definition event since the beginning of the lecture never mind if

731
00:54:32,930 --> 00:54:37,070
for all of the n pixels made and million pixels in this image we have

732
00:54:37,070 --> 00:54:37,960
to consider

733
00:54:37,980 --> 00:54:42,090
and he was in in this if you have british billion again that

734
00:54:42,090 --> 00:54:47,770
creativity men hoping physical constraints that make this a little bit easier

735
00:54:47,780 --> 00:54:51,370
and sure enough there are good geometric constraints

736
00:54:51,550 --> 00:54:52,610
if i take

737
00:54:52,610 --> 00:54:53,860
two images like

738
00:54:53,880 --> 00:54:58,860
here are very apparent i set one up on stage for didactic purposes

739
00:54:59,810 --> 00:55:06,920
it turns out that i can preprocess the images mildly preprocessing being a mile wall

740
00:55:07,180 --> 00:55:08,060
the image

741
00:55:08,140 --> 00:55:13,620
projective walking patterning upper right to be squeezing in that it is quite mild

742
00:55:13,710 --> 00:55:14,660
i promise you

743
00:55:14,670 --> 00:55:21,340
which then brings the rows of the image images in correspond to the words for

744
00:55:21,340 --> 00:55:27,580
this is a given the smiled warm or equivalently given cameras pointing straight or i

745
00:55:27,580 --> 00:55:32,110
is the point spread you don't do that too easily arise because you need to

746
00:55:32,110 --> 00:55:36,850
follow birds them on what you're looking at but suppose you look at infinity

747
00:55:36,900 --> 00:55:38,010
the horizon

748
00:55:38,010 --> 00:55:39,520
then the that geometry

749
00:55:39,530 --> 00:55:43,980
horizontal lines in one i'm at horizontal lines and they have that already that because

750
00:55:43,980 --> 00:55:46,260
now that means all the m squared

751
00:55:46,270 --> 00:55:50,230
pixels in the middle of the n pixels in the image on you need to

752
00:55:50,230 --> 00:55:54,360
look at only square root of n pixels in the writing just one lie on

753
00:55:54,400 --> 00:55:55,820
the corresponding lie

754
00:55:55,900 --> 00:55:58,040
so that's only an american billion

755
00:55:58,040 --> 00:56:00,140
of possible matches too

756
00:56:00,160 --> 00:56:04,110
look at the already an improvement

757
00:56:04,570 --> 00:56:07,870
so the problem is

758
00:56:07,890 --> 00:56:11,290
to look at these pairs of so-called epipolar lines

759
00:56:11,300 --> 00:56:13,710
and restrict attention to the excel

760
00:56:13,780 --> 00:56:15,560
like one of those lines

761
00:56:15,580 --> 00:56:16,820
and explore

762
00:56:16,830 --> 00:56:20,120
the goodness of match between pairs of pixels in those

763
00:56:20,730 --> 00:56:24,280
in those lines and actually it turns out

764
00:56:24,290 --> 00:56:29,150
that you only need to consider not the square all possible match point but only

765
00:56:29,170 --> 00:56:30,970
a triangle matching point

766
00:56:31,020 --> 00:56:35,690
why would only be slower trying not the upper triangle bearing in mind that this

767
00:56:35,690 --> 00:56:38,550
is equivalent to the geometry in which you're

768
00:56:38,600 --> 00:56:41,690
i pointing straight ahead

769
00:56:41,710 --> 00:56:47,500
why is it only the love triangle

770
00:56:52,400 --> 00:56:53,880
it's because

771
00:56:53,890 --> 00:56:55,170
thank you

772
00:56:55,190 --> 00:56:56,360
it because

773
00:56:56,360 --> 00:56:57,860
in the love triangle

774
00:56:57,880 --> 00:57:00,130
the coordinates in

775
00:57:00,140 --> 00:57:05,120
which everybody it is greater than the coordinates in the other thing that corresponds to

776
00:57:05,400 --> 00:57:07,550
rays which are con

777
00:57:07,620 --> 00:57:11,700
that's the point you're making a point in front of the opposite condition will be

778
00:57:11,700 --> 00:57:13,620
diverging rays that we like

779
00:57:13,660 --> 00:57:16,580
trying to image something which is invisible because it behind you

780
00:57:16,580 --> 00:57:17,940
clearly one does not

781
00:57:17,970 --> 00:57:21,010
on ground visibility need to consider this upper triangle

782
00:57:21,050 --> 00:57:24,350
so we need to do is to consider the the lower triangle and what you

783
00:57:24,350 --> 00:57:27,590
see plotted here is according to some measure of how well

784
00:57:28,010 --> 00:57:33,580
because the color of particular excel points in this image met matter particularly excel

785
00:57:33,630 --> 00:57:37,780
at a point on the line and the other that's done for all possible

786
00:57:37,780 --> 00:57:40,010
visible pairings of pixels

787
00:57:40,030 --> 00:57:41,860
and so bright in this

788
00:57:41,870 --> 00:57:44,770
array corresponds to things that match well

789
00:57:44,770 --> 00:57:45,650
and dark

790
00:57:45,670 --> 00:57:48,430
the things that don't match well now what you see is

791
00:57:48,480 --> 00:57:51,560
actually this sort of bright street here

792
00:57:51,600 --> 00:57:53,060
corresponding to

793
00:57:53,070 --> 00:57:55,700
the background plane actually

794
00:57:56,130 --> 00:57:58,590
as bit cheating going on because although i

795
00:57:58,600 --> 00:58:00,690
drawn it as if it was array

796
00:58:00,750 --> 00:58:05,190
along here actually to write cut through the base which i got the

797
00:58:05,210 --> 00:58:07,980
and the goodness of match function here

798
00:58:08,020 --> 00:58:10,640
separating cuts through the place what you see is

799
00:58:11,690 --> 00:58:14,550
track follows the background followed by

800
00:58:14,550 --> 00:58:17,520
the track goes across the head and i mean you know you and i can

801
00:58:17,520 --> 00:58:21,920
see it because we have incredible pattern recognition machines in our brains which

802
00:58:21,980 --> 00:58:25,750
actually doing something non-trivial with this triangle of

803
00:58:25,790 --> 00:58:29,970
good is but if you ask you know what can you do if we ask

804
00:58:30,540 --> 00:58:32,050
trajectory through this

805
00:58:33,000 --> 00:58:35,260
following the best matches it's clearly

806
00:58:35,270 --> 00:58:38,520
a more typical recognition problem because you know local locally

807
00:58:39,410 --> 00:58:41,640
optimality is clearly not enough

808
00:58:41,680 --> 00:58:42,960
you know there bits

809
00:58:42,970 --> 00:58:45,160
bits of the trace that rather

810
00:58:45,210 --> 00:58:48,980
you know quite ambiguous background here

811
00:58:49,030 --> 00:58:50,700
so it's going to be

812
00:58:50,750 --> 00:58:55,020
more difficult than just marking the highest scoring points in the right

813
00:58:55,060 --> 00:58:56,530
it's going to be much more like

814
00:58:56,540 --> 00:58:58,290
a path finding problem

815
00:58:58,340 --> 00:59:00,600
that tracks through the right

816
00:59:00,610 --> 00:59:02,150
the park which is both

817
00:59:02,210 --> 00:59:08,650
coherence in some sense the corresponding to prior expectations about coherence in the physical world

818
00:59:08,670 --> 00:59:13,640
coupled with the tendency of pixels to match with similar colours

819
00:59:13,690 --> 00:59:16,330
in the opposite

820
00:59:16,330 --> 00:59:20,810
they have the same problem in of more schematic here is

821
00:59:21,950 --> 00:59:24,610
epipolar line from each

822
00:59:24,610 --> 00:59:30,440
the two stereo images the right image tells pixels are and that in itself land

823
00:59:30,460 --> 00:59:31,420
and the

824
00:59:31,440 --> 00:59:38,020
zero disparity line so-called is actually the line of four objects at infinity

825
00:59:38,020 --> 00:59:39,050
and so

826
00:59:39,070 --> 00:59:40,750
you know lines where

827
00:59:40,770 --> 00:59:43,030
the absolute image coordinates

828
00:59:43,080 --> 00:59:44,550
in one

829
00:59:44,610 --> 00:59:47,260
image is equal to the absolute on the

830
00:59:48,390 --> 00:59:53,360
four image that arises because the rays were parallel rays parallel that must be because

831
00:59:53,360 --> 00:59:55,060
the object is in

832
00:59:55,060 --> 00:59:57,300
that makes it doesn't and then the

833
00:59:57,400 --> 00:59:59,720
the disparity axis

834
01:00:02,320 --> 01:00:04,410
in this direction and

835
01:00:04,460 --> 01:00:08,320
or you could a psychologist in the audience this definition of disparity is slightly different

836
01:00:08,320 --> 01:00:12,660
from the psychological definition this one computer science

837
01:00:12,670 --> 01:00:17,120
and yes sort of disparity axis if you allow allowed yet another axis of the

838
01:00:17,120 --> 01:00:19,220
diagram which already has two axes

839
01:00:19,230 --> 01:00:21,080
and the disparity axis

840
01:00:21,090 --> 01:00:23,800
is is in this direction

841
01:00:23,840 --> 01:00:29,510
and you can see that greater disparity is going to correspond to more conversion rate

842
01:00:29,520 --> 01:00:34,070
so presumably to an object which is closer to use the disparity is in some

843
01:00:34,070 --> 01:00:37,020
way varying inversely with that

844
01:00:37,030 --> 01:00:37,800
in fact

845
01:00:37,810 --> 01:00:41,930
the disparity varies in proportion to that you read out the disparity

846
01:00:42,360 --> 01:00:45,330
and take the reciprocal in principle that

847
01:00:45,340 --> 01:00:47,310
gives you the distance two

848
01:00:47,360 --> 01:00:51,140
a little fragment of the scene looking at you do this over the whole scene

849
01:00:51,140 --> 01:00:57,130
and you can recover the shape of the heart in the in the variogram

850
01:00:57,140 --> 01:01:02,010
so now to actually recover this part one way of doing it would be

851
01:01:02,040 --> 01:01:06,730
define a cost over the park itself

852
01:01:09,000 --> 01:01:11,680
so the cost is going to consist of two components

853
01:01:11,780 --> 01:01:15,360
component to do with kx now

854
01:01:15,420 --> 01:01:17,140
is encoding

855
01:01:18,410 --> 01:01:20,050
pair of coordinates

856
01:01:20,050 --> 01:01:24,170
the match that k is the k point along this

857
01:01:24,250 --> 01:01:26,090
the case point along with

858
01:01:26,130 --> 01:01:28,560
as coordinates x x

859
01:01:28,560 --> 01:01:29,680
as i defined it

860
01:01:29,710 --> 01:01:31,610
they're consists of two

861
01:01:31,610 --> 01:01:34,860
all right you did well

862
01:01:34,880 --> 01:01:37,000
on the exam

863
01:01:37,020 --> 01:01:39,500
class seventy four sixty two

864
01:01:39,540 --> 01:01:42,820
always a sixty five very happy

865
01:01:42,880 --> 01:01:44,290
eleven students

866
01:01:44,300 --> 01:01:46,830
he scored a hundred

867
01:01:46,890 --> 01:01:50,190
i believe that my exam review was extremely fair

868
01:01:50,230 --> 01:01:52,140
according to some instructors

869
01:01:52,190 --> 01:01:55,190
perhaps even too close for comfort

870
01:01:55,190 --> 01:01:58,640
i did the problem with parallel resistors in the battery

871
01:01:58,690 --> 01:02:02,600
i applied gauss law enforcement ical symmetry

872
01:02:02,620 --> 01:02:05,020
i spent quite a bit of time discussing

873
01:02:05,040 --> 01:02:06,690
we charge

874
01:02:06,730 --> 01:02:08,450
orcas which are

875
01:02:08,510 --> 01:02:11,260
cannot be located on conductors

876
01:02:11,270 --> 01:02:16,630
and i hate the idea of capacitors and dielectrics also quite hard

877
01:02:16,690 --> 01:02:19,040
i prefer not to think about rigid

878
01:02:19,050 --> 01:02:21,510
division between pass and fail

879
01:02:21,550 --> 01:02:23,340
but i'd rather tell you

880
01:02:23,400 --> 01:02:24,760
that all of you

881
01:02:24,760 --> 01:02:27,700
who scored less than forty seven

882
01:02:27,720 --> 01:02:31,220
in my book i sort of in the danger zone but it doesn't mean you're

883
01:02:31,220 --> 01:02:33,020
going to fail the course

884
01:02:33,080 --> 01:02:35,400
nor does it mean that you will pass the course

885
01:02:35,410 --> 01:02:37,140
he scored seventy

886
01:02:37,150 --> 01:02:38,470
those people

887
01:02:38,480 --> 01:02:40,010
and the danger zone

888
01:02:40,030 --> 01:02:42,030
i think you should talk to your instructor

889
01:02:42,050 --> 01:02:44,530
and advise those people so too

890
01:02:44,530 --> 01:02:46,000
make frequent use

891
01:02:46,010 --> 01:02:48,050
of course

892
01:02:48,060 --> 01:02:49,890
two attempts to go

893
01:02:49,920 --> 01:02:53,670
plus the final

894
01:02:53,700 --> 01:02:55,580
today i'm going to uncover

895
01:02:55,590 --> 01:02:58,010
a whole new world for you

896
01:02:58,030 --> 01:03:00,950
and you will see how a two

897
01:03:01,010 --> 01:03:04,150
comes in there a very natural way

898
01:03:04,170 --> 01:03:07,670
the romans force at

899
01:03:07,690 --> 01:03:09,760
is the charge

900
01:03:09,780 --> 01:03:12,860
and the cross product

901
01:03:12,910 --> 01:03:15,220
of the velocity of the charge

902
01:03:15,280 --> 01:03:19,750
and the b field that the charge experiences

903
01:03:19,810 --> 01:03:21,280
if i have here

904
01:03:21,310 --> 01:03:24,670
a positive charge plus q

905
01:03:24,720 --> 01:03:27,830
and it has velocity v

906
01:03:27,870 --> 01:03:30,560
in this direction

907
01:03:30,580 --> 01:03:32,830
and the magnetic field

908
01:03:32,840 --> 01:03:34,560
it would be uniform

909
01:03:34,610 --> 01:03:36,610
and coming out of the blackboards

910
01:03:36,650 --> 01:03:38,120
going to be a force

911
01:03:38,230 --> 01:03:41,910
on this charge according to this relationship

912
01:03:41,910 --> 01:03:43,220
and the force

913
01:03:44,490 --> 01:03:46,440
like so

914
01:03:46,470 --> 01:03:48,190
perpendicular to v

915
01:03:48,250 --> 01:03:51,060
opened it cannot be

916
01:03:51,150 --> 01:03:54,970
in this case

917
01:03:54,970 --> 01:03:59,060
the charged particle is going to go around in circles

918
01:03:59,090 --> 01:04:00,810
the romans forces

919
01:04:00,820 --> 01:04:02,620
i cannot change the speed

920
01:04:02,620 --> 01:04:07,870
you cannot change the kinetic energy because the force is always perpendicular to the velocity

921
01:04:07,910 --> 01:04:10,740
but it can change the direction of the velocity

922
01:04:10,780 --> 01:04:13,380
so we're going to see a

923
01:04:14,440 --> 01:04:15,990
charged particle

924
01:04:16,000 --> 01:04:17,870
well go around

925
01:04:17,880 --> 01:04:19,590
into a perfect circle

926
01:04:20,900 --> 01:04:22,650
the magnetic field

927
01:04:22,650 --> 01:04:25,710
o is constant throughout

928
01:04:25,770 --> 01:04:29,470
the radius of the circle can very easily be calculated

929
01:04:29,490 --> 01:04:30,410
using some

930
01:04:30,430 --> 01:04:33,130
of our knowledge of eight o two

931
01:04:33,150 --> 01:04:34,520
the force

932
01:04:34,530 --> 01:04:35,910
is q b

933
01:04:36,530 --> 01:04:40,290
because i chose to be also perpendicular to v

934
01:04:40,340 --> 01:04:43,930
so there is no sign sin of the angle between them

935
01:04:43,970 --> 01:04:45,190
this one

936
01:04:45,250 --> 01:04:46,440
and this now

937
01:04:46,460 --> 01:04:48,810
has to be the centripetal force

938
01:04:48,930 --> 01:04:50,940
we encountered in a new one

939
01:04:50,970 --> 01:04:53,680
which is and histogram provided by are

940
01:04:53,720 --> 01:04:57,150
and now being the mass of this article

941
01:04:57,160 --> 01:04:58,930
so you'll find no

942
01:05:00,820 --> 01:05:02,900
he calls and he

943
01:05:03,000 --> 01:05:05,620
divided by b

944
01:05:05,660 --> 01:05:09,650
and this by the way i want to remind you

945
01:05:09,710 --> 01:05:11,120
is the momentum

946
01:05:11,220 --> 01:05:15,870
of that article

947
01:05:15,910 --> 01:05:20,780
if you look at this equation it's sort of pleasing if the charge is high

948
01:05:20,790 --> 01:05:23,780
and the roman forces high sort of radius is small

949
01:05:23,820 --> 01:05:25,660
if the magnetic field is high

950
01:05:25,680 --> 01:05:27,340
the lawrence forces high

951
01:05:27,340 --> 01:05:28,960
sort of a small

952
01:05:28,970 --> 01:05:32,970
if the mass of the particle is high there is a lot of inertia

953
01:05:32,970 --> 01:05:35,160
so it is very difficult

954
01:05:35,220 --> 01:05:39,060
to make it go around so to speak so very high mass

955
01:05:39,060 --> 01:05:41,150
you expect a very high rate

956
01:05:41,220 --> 01:05:42,600
so it looks all

957
01:05:42,620 --> 01:05:46,470
intuitively quite pleasing

958
01:05:46,490 --> 01:05:55,680
let's do a numerical example

959
01:05:55,700 --> 01:05:57,840
i think the proton

960
01:05:57,890 --> 01:05:59,400
the central protons

961
01:05:59,460 --> 01:06:01,720
and i think one MTV proton

962
01:06:01,740 --> 01:06:04,640
the same i took during my tests

963
01:06:06,130 --> 01:06:09,860
one MTV means that the kinetic energy

964
01:06:09,900 --> 01:06:12,030
is one MTV

965
01:06:12,050 --> 01:06:13,790
is the charge

966
01:06:14,030 --> 01:06:19,780
find the potential difference over which this proton was accelerated in this case

967
01:06:19,830 --> 01:06:23,330
delta v vd one million volts

968
01:06:23,340 --> 01:06:24,910
and this is now

969
01:06:24,920 --> 01:06:26,200
was one half

970
01:06:26,220 --> 01:06:28,630
times the mass of the proton

971
01:06:28,640 --> 01:06:31,720
i'm the velocity squared

972
01:06:31,730 --> 01:06:33,150
in this case

973
01:06:33,210 --> 01:06:35,390
if i have a one MTV

974
01:06:35,400 --> 01:06:37,320
it is million volts

975
01:06:37,360 --> 01:06:38,850
you will find

976
01:06:38,860 --> 01:06:44,280
this is one point six times ten to the minus fifteen joules

977
01:06:44,280 --> 01:06:46,780
i gave you the charge of the proton

978
01:06:46,830 --> 01:06:48,830
you multiplied by million

979
01:06:48,840 --> 01:06:51,210
and this is the energy

980
01:06:51,260 --> 01:06:55,150
so now you can calculate the velocity because you know the mass of the proton

981
01:06:55,150 --> 01:06:56,780
i give you that there

982
01:06:56,800 --> 01:07:00,570
so you will find exactly what we found during my test review

983
01:07:00,630 --> 01:07:02,430
one point four

984
01:07:02,450 --> 01:07:04,380
times ten to seven

985
01:07:04,420 --> 01:07:07,030
i just second which is five percent

986
01:07:07,070 --> 01:07:09,350
of the speed of light

987
01:07:11,020 --> 01:07:13,220
low so we don't have to make any

988
01:07:13,220 --> 01:07:15,840
relativistic corrections

989
01:07:15,860 --> 01:07:17,460
if this proton

990
01:07:17,510 --> 01:07:20,510
now enters the magnetic field b

991
01:07:20,550 --> 01:07:23,280
which is one test flight

992
01:07:25,350 --> 01:07:28,710
by using the equation have been you know the mass of the proton you we

993
01:07:28,720 --> 01:07:30,590
just calculated the velocity

994
01:07:30,610 --> 01:07:33,660
you know the charge of the proton and you know to be fields

995
01:07:33,670 --> 01:07:35,720
you will find that are

996
01:07:35,910 --> 01:07:38,860
o point one five metres

997
01:07:38,910 --> 01:07:40,200
which is fifteen

998
01:07:42,260 --> 01:07:45,960
numerical examples

999
01:07:46,020 --> 01:07:48,590
it is more common

1000
01:07:48,650 --> 01:07:51,240
or at least often does

1001
01:07:51,890 --> 01:07:55,630
and then eight out of that equation there

1002
01:07:55,650 --> 01:07:56,860
the velocity

1003
01:07:56,880 --> 01:07:58,670
and replaced it

1004
01:07:59,390 --> 01:08:02,400
the potential difference capital v

1005
01:08:02,410 --> 01:08:06,240
over which we accelerate these particles

1006
01:08:06,280 --> 01:08:07,860
and so

1007
01:08:07,880 --> 01:08:10,780
what you can do you can replace this thing

1008
01:08:10,860 --> 01:08:12,220
by using

1009
01:08:12,220 --> 01:08:16,150
creation i have their the one of these square

1010
01:08:16,200 --> 01:08:18,980
so we have that one half

1011
01:08:19,280 --> 01:08:20,830
the square

1012
01:08:22,240 --> 01:08:26,430
few times delta v but i right for that just the capital the

1013
01:08:26,450 --> 01:08:29,860
and i substituted this view now in here

1014
01:08:29,910 --> 01:08:32,230
so i no longer see the velocity

1015
01:08:32,240 --> 01:08:33,350
but i now see

1016
01:08:33,360 --> 01:08:38,330
this potential difference in the case of the proton is v will be a million

1017
01:08:38,360 --> 01:08:42,020
and you'll find that are

1018
01:08:42,110 --> 01:08:44,340
then the square root

1019
01:08:44,390 --> 01:08:48,160
of two and times that capital v

1020
01:08:48,170 --> 01:08:49,950
divided by q

1021
01:08:50,030 --> 01:08:52,160
the square

1022
01:08:52,220 --> 01:08:54,910
so the two equations and of course

1023
01:08:54,970 --> 01:08:56,460
the same physics but

1024
01:08:56,480 --> 01:09:00,540
different representation

1025
01:09:00,550 --> 01:09:02,740
if you put in

1026
01:09:02,790 --> 01:09:05,040
four v now ten two six

1027
01:09:05,070 --> 01:09:08,650
mass of the proton charges of the proton and one test light field

1028
01:09:08,660 --> 01:09:16,010
of course you find exactly the same point one five metres

1029
01:09:16,030 --> 01:09:18,530
so this is all my and then the

1030
01:09:18,530 --> 01:09:22,320
and actually have to be very aware about don't confuse them and think they just

1031
01:09:22,320 --> 01:09:25,290
doing the same thing with two different philosophically distinct

1032
01:09:26,720 --> 01:09:30,880
any questions about the i think that's important point it took me a long time to realize actually

1033
01:09:37,050 --> 01:09:38,380
programs around

1034
01:09:43,120 --> 01:09:44,180
all right

1035
01:09:45,330 --> 01:09:48,880
that's an interesting lovely question good i'm glad you said so the question is along

1036
01:09:48,880 --> 01:09:51,500
the lines and let's look at the probability for all classifiers

1037
01:09:54,140 --> 01:09:56,230
and i also because i exactly so this to

1038
01:09:57,720 --> 01:09:58,310
i am

1039
01:10:00,100 --> 01:10:04,990
so you're saying that there should be high probability for classifiers living here high probability classifiers living here

1040
01:10:06,500 --> 01:10:07,790
and then like that's you

1041
01:10:10,710 --> 01:10:13,000
okay so because the likelihoods log concave

1042
01:10:15,270 --> 01:10:17,100
i know that this is a convex problem

1043
01:10:17,550 --> 01:10:18,960
has a unique maximum

1044
01:10:19,860 --> 01:10:21,460
so they can't be bimodal in this way

1045
01:10:22,440 --> 01:10:25,790
so this would be a bimodality across the threshold that somehow

1046
01:10:26,280 --> 01:10:26,790
i am

1047
01:10:30,650 --> 01:10:33,740
we've got two possible thresholds and this threshold unlikely yeah

1048
01:10:34,310 --> 01:10:37,320
and in fact was true that would be great but it can't be true

1049
01:10:37,820 --> 01:10:39,250
because the likelihood is

1050
01:10:39,980 --> 01:10:44,790
log-concave so we know that whatever the posteriors over the threshold that will be some

1051
01:10:44,950 --> 01:10:49,290
corrupted union model distribution and what actually happens is the most likely location

1052
01:10:49,790 --> 01:10:50,520
it is in the middle

1053
01:10:51,260 --> 01:10:51,840
now the question

1054
01:11:02,170 --> 01:11:04,700
you know was just as

1055
01:11:08,430 --> 01:11:10,430
it is used in the world

1056
01:11:18,440 --> 01:11:20,330
and you you

1057
01:11:25,280 --> 01:11:27,920
yet the answer be like fifty fifty

1058
01:11:28,780 --> 01:11:30,700
so you might as well not around the model you

1059
01:11:34,650 --> 01:11:38,430
well you don't have you don't quite know because this nasty situations where you might

1060
01:11:38,430 --> 01:11:41,810
start becoming confident let me give you an example where you become confident back for

1061
01:11:41,810 --> 01:11:42,690
the regression case

1062
01:11:44,130 --> 01:11:48,560
so this is this is actually the easier examples see where this problem arises with bayesian inference

1063
01:11:49,760 --> 01:11:51,320
here i have eh um

1064
01:11:53,630 --> 01:11:55,700
nonlinear function and i'm gonna fit with a linear

1065
01:11:56,250 --> 01:11:58,280
model mismatches problems occur

1066
01:11:58,980 --> 01:12:01,790
so i i think with a linear function one my error bars

1067
01:12:03,690 --> 01:12:04,750
for this linear function

1068
01:12:10,690 --> 01:12:14,740
so what am about the gradient if i wanted the gradient this all i wanna

1069
01:12:14,820 --> 01:12:17,490
be i am and see for this function

1070
01:12:19,590 --> 01:12:23,040
i might hope the answer the bayesian inference gives me is like this

1071
01:12:25,630 --> 01:12:28,830
there's a lot of uncertainty and i don't know why i am and see is an

1072
01:12:29,230 --> 01:12:30,890
you know will do with a few data points

1073
01:12:32,700 --> 01:12:35,490
but what it will also happen is it was i increase the

1074
01:12:36,020 --> 01:12:36,560
number data

1075
01:12:37,060 --> 01:12:39,050
the use it becomes really obvious

1076
01:12:40,730 --> 01:12:44,340
this is a non linear functions on the unit circle

1077
01:12:45,520 --> 01:12:47,950
becomes completely obvious that this is a nonlinear function

1078
01:12:48,710 --> 01:12:50,120
what happens with the error bars

1079
01:12:51,630 --> 01:12:56,530
there are bars are actually only dependent in the linear regression case on these number data

1080
01:12:57,710 --> 01:12:58,390
the error bars for

1081
01:12:59,470 --> 01:13:01,380
the gradient and-or offset

1082
01:13:02,030 --> 01:13:05,940
and so you end up with a collapsed uh posterior that

1083
01:13:06,390 --> 01:13:07,340
collapses at

1084
01:13:08,200 --> 01:13:10,700
the value of this gradient and it becomes completely confident

1085
01:13:11,200 --> 01:13:15,720
that's the right gradient and offset it will have a noise that says that and

1086
01:13:15,720 --> 01:13:17,030
there's noise because that's the bit

1087
01:13:18,370 --> 01:13:20,520
the responsibility for the mismatch between

1088
01:13:21,700 --> 01:13:24,270
the model and data is with the noise but

1089
01:13:25,110 --> 01:13:29,120
as we saw earlier so the noise will correctly say and there's something weird going

1090
01:13:29,120 --> 01:13:31,430
on here but you will you see more data

1091
01:13:31,860 --> 01:13:35,000
instead becoming a bimodal or something so in this case here

1092
01:13:36,290 --> 01:13:39,880
as you see more data and the same thing happens what incentive you know full

1093
01:13:40,020 --> 01:13:42,640
data you actually cover these two possibilities

1094
01:13:43,060 --> 01:13:47,550
but you see more and more data you become massively confident that right threshold for

1095
01:13:47,550 --> 01:13:48,770
this thing is right in the middle

1096
01:13:49,930 --> 01:13:53,450
now you will you write okay depends on the all if you use a sigmoid

1097
01:13:53,450 --> 01:13:56,220
what you're saying is if you use a sigmoid the sigmoid

1098
01:13:56,850 --> 01:13:59,050
class conditional densities if you look along here

1099
01:13:59,520 --> 01:14:00,280
well on

1100
01:14:01,360 --> 01:14:04,560
it will be very so diffuse in fact there might even be fifty fifty

1101
01:14:05,220 --> 01:14:06,670
but if we get an even worse model

1102
01:14:07,120 --> 01:14:11,450
i don't know like a threshold we don't allow it have the flexibility you could get massively

1103
01:14:11,880 --> 01:14:13,980
confident about the wrong answer

1104
01:14:14,670 --> 01:14:15,790
as far as your model goes

1105
01:14:27,480 --> 01:14:28,120
good question

1106
01:14:31,090 --> 01:14:34,700
i have to think about it more but i think that that's quite a good question and there

1107
01:14:36,580 --> 01:14:38,470
i m i jordan once explain this to me

1108
01:14:39,210 --> 01:14:42,010
in about twenty minutes and all made sense but i can't remember

1109
01:14:44,180 --> 01:14:48,930
he the way he talked about is philosophically in the statistical learning theory framework you're

1110
01:14:48,930 --> 01:14:52,200
doing the expectations over all across all possible datasets

1111
01:14:52,930 --> 01:14:53,950
i think his point was

1112
01:14:55,460 --> 01:15:00,030
in the statistical learning theory you're doing expectations across all possible datasets

1113
01:15:00,720 --> 01:15:03,890
and in bayesian theory you're doing expectations across all possible models

1114
01:15:10,050 --> 01:15:14,270
on see when up with if you do both i think this is point is the bayes risk

1115
01:15:15,370 --> 01:15:18,820
and that's including the loss as well but i'm a bit shaky on their

1116
01:15:19,390 --> 01:15:22,850
but it did make a lot of sense when termites described as a split the

1117
01:15:22,860 --> 01:15:26,860
actually can be reconciled and he doesn't in so the thing to do is not

1118
01:15:26,860 --> 01:15:29,280
to listen to me but turns a video lectures where

1119
01:15:29,820 --> 01:15:30,960
the cambridge summer school

1120
01:15:31,350 --> 01:15:34,880
where might there and actually think he does it in a lecture

1121
01:15:35,340 --> 01:15:38,100
and describes what happens if you integrate out both

1122
01:15:39,320 --> 01:15:40,840
and then you recover i think

1123
01:15:41,350 --> 01:15:44,640
these claims that's the bayes risk and it's a nice clear explanation

1124
01:15:45,460 --> 01:15:46,080
but i don't wanna

1125
01:15:47,820 --> 01:15:50,040
re-created without having to look through it

1126
01:15:50,710 --> 01:15:53,250
so the right thing is somehow to do both you typically

1127
01:15:54,260 --> 01:15:56,210
so the the bayes bayesian choice

1128
01:15:56,210 --> 01:16:00,670
OK let's continue

1129
01:16:03,160 --> 01:16:07,010
so now i come

1130
01:16:07,030 --> 01:16:10,340
two powerful take the kernel trick

1131
01:16:10,430 --> 01:16:16,420
and what it does is it reduces the function minimisation problem so

1132
01:16:16,480 --> 01:16:21,550
when you have a large class of functions for reasonable functions to optimize over them

1133
01:16:21,570 --> 01:16:26,000
how to reduce it to finite dimensional optimisation problem

1134
01:16:26,010 --> 01:16:28,770
displaying regression was already some instance of it

1135
01:16:28,830 --> 01:16:32,650
but let more generally consider any loss function so you have your y will you

1136
01:16:32,650 --> 01:16:34,800
every function

1137
01:16:37,180 --> 01:16:41,020
if you don't have a small one last four years for very large one and

1138
01:16:41,020 --> 01:16:42,110
then you need some

1139
01:16:42,230 --> 01:16:47,290
regularizer it's college a of and you minimize

1140
01:16:47,590 --> 01:16:49,480
the loss

1141
01:16:49,490 --> 01:16:51,970
the total loss plus some penalty terms

1142
01:16:51,980 --> 01:16:54,690
which is the bias a towards most functions

1143
01:16:54,690 --> 01:16:57,450
like the

1144
01:16:57,480 --> 01:16:59,260
like minimizing to

1145
01:17:01,600 --> 01:17:04,980
and i make no assumptions about the loss function

1146
01:17:04,990 --> 01:17:06,650
so the important part

1147
01:17:06,910 --> 01:17:11,070
but the penalty function needs to be quadratic in f

1148
01:17:11,120 --> 01:17:14,260
so when you have such as minimisation problem of the class of all functions you

1149
01:17:14,260 --> 01:17:17,680
can show that the solution has the following form

1150
01:17:17,690 --> 01:17:18,850
f of x

1151
01:17:19,740 --> 01:17:25,850
a weighted average over these so-called kernels

1152
01:17:25,870 --> 01:17:27,430
and the kernel

1153
01:17:27,440 --> 01:17:28,730
OK i j

1154
01:17:28,740 --> 01:17:31,820
it's just the function of x i and x j

1155
01:17:31,930 --> 01:17:36,150
which can easily be computed from the penalty

1156
01:17:36,210 --> 01:17:38,570
and the output the coefficients

1157
01:17:39,040 --> 01:17:41,120
other ones with minimize

1158
01:17:42,740 --> 01:17:44,270
expression here

1159
01:17:44,320 --> 01:17:46,370
so this is a simple function

1160
01:17:46,380 --> 01:17:52,880
which just depends on a finite dimensional vector a of finite dimensional optimisation problem

1161
01:17:52,880 --> 01:17:55,330
so you used the functional optimisation problem

1162
01:17:56,290 --> 01:18:00,520
finite dimensional one and in case the loss function is quadratic

1163
01:18:00,930 --> 01:18:06,430
this expression is quadratic in have closed form expression if it's not quadratic then you

1164
01:18:06,430 --> 01:18:09,810
need some numerical tools to solve

1165
01:18:12,370 --> 01:18:13,970
OK that was the kernel trick

1166
01:18:13,990 --> 01:18:16,110
in brief

1167
01:18:16,150 --> 01:18:18,710
maximize margin classifier

1168
01:18:18,720 --> 01:18:21,170
so i mentioned that

1169
01:18:21,240 --> 01:18:24,740
if you have such a classification problem

1170
01:18:24,750 --> 01:18:27,360
so for instance i mean this as spam point

1171
01:18:27,370 --> 01:18:30,150
many messages on them

1172
01:18:30,170 --> 01:18:34,080
if so label plus one label minus one

1173
01:18:34,090 --> 01:18:35,740
if you do a linear regression

1174
01:18:36,370 --> 01:18:37,640
points far away

1175
01:18:37,650 --> 01:18:42,680
from the decision boundary so is what's critical have high influence and

1176
01:18:43,080 --> 01:18:45,020
they will be

1177
01:18:45,030 --> 01:18:48,830
too bad results they cause the line

1178
01:18:50,650 --> 01:18:55,000
to be not so good at so what you really want i mean you want

1179
01:18:55,000 --> 01:18:59,090
to separate the spam from the long span so somehow i mean if it if

1180
01:18:59,090 --> 01:19:00,710
you can separate the linear

1181
01:19:00,720 --> 01:19:03,330
a line like nicely

1182
01:19:03,340 --> 01:19:05,870
between these points if that's possible

1183
01:19:07,370 --> 01:19:14,030
this is called vmax so OK that's the

1184
01:19:14,090 --> 01:19:17,620
OK so what does it mean it lies not between point i mean this line

1185
01:19:17,620 --> 01:19:21,680
points lie close to the will also line between what we have a feeling that

1186
01:19:21,680 --> 01:19:22,710
OK i mean

1187
01:19:22,740 --> 01:19:24,800
forty points you may be

1188
01:19:24,810 --> 01:19:26,680
the plane which is far away

1189
01:19:27,670 --> 01:19:31,210
all these points is are good plane and you can formalise that in the core

1190
01:19:31,270 --> 01:19:34,960
maximum margin classifier so what you want is

1191
01:19:35,310 --> 01:19:36,740
so first

1192
01:19:36,770 --> 01:19:39,520
so you make your

1193
01:19:39,530 --> 01:19:43,180
the feature transformation phi or not so then you find here

1194
01:19:46,870 --> 01:19:50,930
weight vector which is the normal on this plane

1195
01:19:50,950 --> 01:19:53,080
the number should be have norm one

1196
01:19:53,090 --> 01:19:54,700
so this year

1197
01:19:54,710 --> 01:19:57,460
i will give the distance from

1198
01:19:57,750 --> 01:20:01,180
the distance of the plane

1199
01:20:01,240 --> 01:20:03,180
from a data point

1200
01:20:03,180 --> 01:20:05,170
phi fire rex

1201
01:20:05,210 --> 01:20:06,550
so this is the distance

1202
01:20:06,550 --> 01:20:09,300
the signed distance then you want that the

1203
01:20:09,310 --> 01:20:12,690
positive points lie on one side and negative light points lie on the other side

1204
01:20:12,690 --> 01:20:14,410
so you multiply the label

1205
01:20:14,540 --> 01:20:16,000
the same as

1206
01:20:16,020 --> 01:20:19,140
roughly the same as taking absolute by

1207
01:20:19,980 --> 01:20:24,350
then you look for the points which are closest to this plane

1208
01:20:24,400 --> 01:20:27,060
in this case this this and this

1209
01:20:27,110 --> 01:20:29,260
and you want to find

1210
01:20:29,350 --> 01:20:30,820
plane w

1211
01:20:30,830 --> 01:20:33,070
which maximizes this distance

1212
01:20:33,110 --> 01:20:37,100
so which is maximally away from the closest points and that is called the maximum

1213
01:20:37,100 --> 01:20:41,200
margin classifier

1214
01:20:43,770 --> 01:20:46,030
this plane is determined completely

1215
01:20:47,160 --> 01:20:51,030
the so called support vectors of the points which are closest to the plane and

1216
01:20:51,030 --> 01:20:54,420
all these other points they have no influence over here the data point here or

1217
01:20:54,450 --> 01:20:56,210
here you very far away

1218
01:20:56,250 --> 01:20:58,320
they don't influence the result all

1219
01:20:58,460 --> 01:21:04,310
quite contrary to the linear regression case already reduced classification two linear regression really have

1220
01:21:04,330 --> 01:21:08,130
heavy influence on display typically better

1221
01:21:09,700 --> 01:21:13,830
if it's not separable so i mean sometimes if i mean overlapping

1222
01:21:15,880 --> 01:21:20,360
and then the margin might i mean you can be there

1223
01:21:23,470 --> 01:21:26,520
OK this is the linear case of the boring case

1224
01:21:27,460 --> 01:21:30,590
with this feature transformation phi already indicated here

1225
01:21:30,920 --> 01:21:32,010
you can

1226
01:21:32,260 --> 01:21:33,330
to some

1227
01:21:33,390 --> 01:21:37,730
impressive classification task for instance i mean if you know the blue crosses the red

1228
01:21:38,830 --> 01:21:41,160
you have that in some feature space

1229
01:21:42,780 --> 01:21:51,660
do either the maximum margin classifiers before

1230
01:21:52,210 --> 01:21:56,660
the support vector machine

1231
01:21:57,960 --> 01:22:07,230
so what did i want to say

1232
01:22:07,250 --> 01:22:10,630
OK so in general you have non-linear boundary

1233
01:22:10,650 --> 01:22:13,190
so then we take this feature map

1234
01:22:13,200 --> 01:22:14,520
you can show

1235
01:22:15,210 --> 01:22:18,460
solution is a weighted average over features

1236
01:22:18,470 --> 01:22:20,830
for some weight a

1237
01:22:20,890 --> 01:22:22,850
and then the function

1238
01:22:23,600 --> 01:22:27,420
simply i mean this scalar product between the weight and the feature vectors so that

1239
01:22:27,420 --> 01:22:28,630
the estimator

1240
01:22:28,690 --> 01:22:31,400
which can again be just like that in

1241
01:22:31,400 --> 01:22:35,160
be written as the weighted average of the weights are a

1242
01:22:35,210 --> 01:22:36,970
and here you fly

1243
01:22:36,980 --> 01:22:40,220
times y

1244
01:22:41,310 --> 01:22:43,460
you pull the sum in

1245
01:22:43,470 --> 01:22:45,150
and what you get

1246
01:22:45,150 --> 01:22:46,650
that is five times five

1247
01:22:46,660 --> 01:22:47,820
some over

1248
01:22:47,830 --> 01:22:48,880
and the bees

1249
01:22:48,890 --> 01:22:51,100
and give this kernel here

1250
01:22:51,160 --> 01:22:54,460
so i mean you have to plug it in and pull one summer

1251
01:22:54,510 --> 01:22:59,350
and you get this expression here which is called the kernel

1252
01:22:59,900 --> 01:23:02,520
so what you see is once you have this curve

1253
01:23:02,600 --> 01:23:06,230
you just have some here or in

1254
01:23:06,280 --> 01:23:09,130
and this sum be is

1255
01:23:09,140 --> 01:23:14,000
in this kernel and maybe computer implicitly defined is going directly

1256
01:23:14,010 --> 01:23:17,260
so if d is much larger than n

1257
01:23:17,290 --> 01:23:21,520
you save of computation time if you just feel the current directly and is called

1258
01:23:21,520 --> 01:23:23,350
the kernel trick

1259
01:23:23,980 --> 01:23:31,780
OK here's some example kernels

1260
01:23:32,900 --> 01:23:38,960
the whole lecture and actually the next lecture about content

1261
01:23:39,020 --> 01:23:41,950
OK now we come to model selection assessment

1262
01:23:41,950 --> 01:23:45,260
it comes the function of the group

1263
01:23:46,660 --> 01:23:48,990
and outcome something

1264
01:23:49,010 --> 01:23:53,820
which is just a bunch of matrices right so this is the weighted sum of

1265
01:23:55,260 --> 01:24:00,820
each representation is going to have a corresponding fourier component and each fourier component is

1266
01:24:00,820 --> 01:24:05,220
going to be a matrix so the fourier transform it just a bunch of matrices

1267
01:24:05,220 --> 01:24:07,370
of different sizes

1268
01:24:07,390 --> 01:24:12,700
set aside this seems like a very different object than what you started out like

1269
01:24:12,700 --> 01:24:17,320
a function on the original space but it turns out that this is just a

1270
01:24:17,320 --> 01:24:19,490
manifestation of a deeper

1271
01:24:21,160 --> 01:24:24,590
between groups and sets of

1272
01:24:24,610 --> 01:24:27,890
in equivalent irreducible representations

1273
01:24:27,910 --> 01:24:32,180
i was told that

1274
01:24:32,470 --> 01:24:37,430
they should take a break after sixty minutes so what about fifteen more minutes that

1275
01:24:37,430 --> 01:24:41,660
should be just about enough to

1276
01:24:41,700 --> 01:24:46,120
to finish this general part the

1277
01:24:46,140 --> 01:24:48,840
one on the math and then we can start with the

1278
01:24:49,110 --> 01:24:52,570
machine learning applications in the second half of the lecture

1279
01:24:52,590 --> 01:24:53,410
thank you

1280
01:24:55,030 --> 01:24:57,340
so much for the structure of the

1281
01:24:57,350 --> 01:25:01,930
fourier transform how about its properties

1282
01:25:02,640 --> 01:25:04,260
and in particular

1283
01:25:04,340 --> 01:25:06,660
i mentioned translations

1284
01:25:06,720 --> 01:25:10,820
what did you even mean by the translator function

1285
01:25:18,160 --> 01:25:20,160
so the idea here is very simple

1286
01:25:20,180 --> 01:25:26,910
we have a function f from complex number

1287
01:25:29,430 --> 01:25:30,840
if you think about

1288
01:25:30,870 --> 01:25:34,390
generalizing the idea of translation in the real line

1289
01:25:34,390 --> 01:25:36,620
which takes

1290
01:25:38,280 --> 01:25:45,180
in two dash so that after a few translate by the dashed line is it

1291
01:25:45,280 --> 01:25:50,200
is going to be original function text

1292
01:25:50,590 --> 01:25:56,120
today the natural definition of translating of functions on the group

1293
01:25:56,390 --> 01:25:59,280
is translated by f

1294
01:25:59,280 --> 01:26:00,970
sorry translated by c

1295
01:26:01,090 --> 01:26:10,930
at location x equal to either zero the x value functions in inverse six

1296
01:26:12,450 --> 01:26:20,870
the value of the function at x being

1297
01:26:20,930 --> 01:26:22,970
so again

1298
01:26:22,990 --> 01:26:28,740
noncommutative playing tricks with us we're going to have to distinguish between two cases depending

1299
01:26:28,740 --> 01:26:31,870
on where we translate on the left translate on the right

1300
01:26:31,890 --> 01:26:35,070
but apart from that it's a very similar kind of idea to what we had

1301
01:26:35,070 --> 01:26:39,620
on the real life every and all that happens is that what you expected to

1302
01:26:39,620 --> 01:26:43,570
find that x is now going to happen and a set of x and then

1303
01:26:43,570 --> 01:26:46,990
you find the translator function or in the case of right translation is going to

1304
01:26:47,180 --> 01:26:48,760
happen at x z

1305
01:26:48,780 --> 01:26:50,530
and the translator function

1306
01:26:50,550 --> 01:26:53,180
and if you look at this formula into the

1307
01:26:53,200 --> 01:26:57,930
the formula for the fourier transform trying to compute

1308
01:26:57,950 --> 01:27:05,910
the fourier transform of such translated function at particular representation write down formula

1309
01:27:05,970 --> 01:27:08,850
it's going to be sum over

1310
01:27:09,800 --> 01:27:14,660
the group of

1311
01:27:14,720 --> 01:27:19,720
have said x

1312
01:27:19,720 --> 01:27:25,030
four percent of x i substituted the definition of the two

1313
01:27:25,050 --> 01:27:28,220
it's going to be

1314
01:27:29,320 --> 01:27:32,340
so the inverse

1315
01:27:35,050 --> 01:27:36,740
it changed variables

1316
01:27:41,640 --> 01:27:47,700
by the group properties summing over x is the same as something this new variable

1317
01:27:48,840 --> 01:27:52,530
so this is going to be some why

1318
01:27:52,620 --> 01:28:00,950
of the of x which is just going to be z z one new variables

1319
01:28:06,010 --> 01:28:13,640
but now we use the definition of defining property of representations and replace this rule

1320
01:28:14,260 --> 01:28:17,180
why by rules to align

1321
01:28:17,180 --> 01:28:18,990
two new last

1322
01:28:19,010 --> 01:28:20,950
and we looked at

1323
01:28:20,990 --> 01:28:22,660
the nearest ferry

1324
01:28:22,680 --> 01:28:24,580
so this is the process

1325
01:28:24,580 --> 01:28:25,760
to expand

1326
01:28:28,600 --> 01:28:32,910
the problem is

1327
01:28:32,910 --> 01:28:35,200
after suppose that i have seen

1328
01:28:35,200 --> 01:28:36,140
one and the

1329
01:28:38,600 --> 01:28:39,870
i can

1330
01:28:39,890 --> 01:28:41,640
the fifty mind

1331
01:28:41,680 --> 01:28:44,140
which variables defined

1332
01:28:45,760 --> 01:28:47,280
and expand

1333
01:28:47,300 --> 01:28:49,100
based on

1334
01:28:50,080 --> 01:28:51,680
this is very

1335
01:28:51,720 --> 01:28:53,490
but this is problematic

1336
01:28:53,510 --> 01:28:56,640
because i suppose

1337
01:28:56,680 --> 01:28:59,890
the distance between the two

1338
01:28:59,890 --> 01:29:05,430
variables that we find the diameter is zero point five

1339
01:29:06,570 --> 01:29:08,510
the second used

1340
01:29:09,120 --> 01:29:12,490
zero point four ninety nine

1341
01:29:12,510 --> 01:29:15,450
if i'm using a greedy strategy

1342
01:29:16,780 --> 01:29:20,180
cedar point five is greater than zero point

1343
01:29:20,200 --> 01:29:21,370
four ninety nine

1344
01:29:21,390 --> 01:29:22,530
so why

1345
01:29:22,580 --> 01:29:24,080
go away

1346
01:29:24,100 --> 01:29:27,140
this is problematic because if

1347
01:29:27,600 --> 01:29:32,080
after if i see one example for more than example

1348
01:29:33,160 --> 01:29:35,660
of the distance

1349
01:29:35,700 --> 01:29:37,570
called sex

1350
01:29:40,160 --> 01:29:41,450
home c

1351
01:29:42,070 --> 01:29:43,830
the problem is

1352
01:29:43,850 --> 01:29:46,910
i i will expand lead if

1353
01:29:48,260 --> 01:29:49,830
in the

1354
01:29:49,830 --> 01:29:51,720
information and s

1355
01:29:51,740 --> 01:29:54,180
in favour of a particular

1356
01:29:54,200 --> 01:29:56,280
the choice of variables

1357
01:29:56,350 --> 01:29:58,910
and this charge must be

1358
01:30:04,070 --> 01:30:05,990
this is why

1359
01:30:07,010 --> 01:30:09,280
of born to decide

1360
01:30:09,370 --> 01:30:12,030
if the information that i have

1361
01:30:12,120 --> 01:30:14,530
from data seen so far

1362
01:30:14,620 --> 01:30:16,370
is enough

1363
01:30:17,510 --> 01:30:19,050
but it

1364
01:30:19,070 --> 01:30:20,620
tools to support

1365
01:30:20,640 --> 01:30:23,490
the choice of

1366
01:30:25,760 --> 01:30:29,030
if we suppose that the one is the

1367
01:30:29,050 --> 01:30:30,550
distance between the

1368
01:30:31,600 --> 01:30:33,890
corresponding to the diameter of the cluster

1369
01:30:33,970 --> 01:30:37,120
and p two is second five

1370
01:30:37,300 --> 01:30:42,370
what they must guarantee is the difference between d one and d two

1371
01:30:42,370 --> 01:30:45,160
it is greater than c

1372
01:30:45,180 --> 01:30:48,780
is so

1373
01:30:48,800 --> 01:30:50,030
we consider

1374
01:30:52,530 --> 01:30:54,800
this is the

1375
01:30:54,830 --> 01:30:56,280
the the difference

1376
01:30:56,300 --> 01:31:01,350
is greater than x one where x comes from the off the ball

1377
01:31:01,370 --> 01:31:04,950
because there is information in that

1378
01:31:04,970 --> 01:31:06,280
to do so

1379
01:31:06,280 --> 01:31:07,640
in favour two

1380
01:31:10,430 --> 01:31:13,800
best to do so splitting variable

1381
01:31:14,070 --> 01:31:16,100
you think about it

1382
01:31:16,140 --> 01:31:17,220
the have

1383
01:31:17,240 --> 01:31:19,390
it is the language

1384
01:31:19,410 --> 01:31:22,100
of the random variable

1385
01:31:22,950 --> 01:31:27,180
to proposed probability level this is use for

1386
01:31:27,200 --> 01:31:28,100
the limit

1387
01:31:28,200 --> 01:31:31,470
the user can help i want system

1388
01:31:31,510 --> 01:31:33,700
with ninety five percent

1389
01:31:33,780 --> 01:31:38,890
i the idea that he has a one

1390
01:31:38,930 --> 01:31:41,410
and the degrees we

1391
01:31:41,450 --> 01:31:43,310
number of places

1392
01:31:43,370 --> 01:31:47,050
so if for a given that the given point

1393
01:31:49,510 --> 01:31:51,430
that's all

1394
01:31:51,450 --> 01:31:53,990
we don't expand class

1395
01:31:54,030 --> 01:31:55,930
we need to see

1396
01:31:59,300 --> 01:32:02,600
it off when we

1397
01:32:03,910 --> 01:32:08,850
with increasing number of situations the

1398
01:32:09,160 --> 01:32:12,660
so this is the

1399
01:32:14,410 --> 01:32:15,720
the main point

1400
01:32:15,720 --> 01:32:16,740
is that

1401
01:32:16,760 --> 01:32:19,180
you are not using pvt

1402
01:32:21,180 --> 01:32:23,120
we want to have a stable

1403
01:32:30,260 --> 01:32:31,410
in fact

1404
01:32:31,430 --> 01:32:32,740
what about doing

1405
01:32:32,800 --> 01:32:37,050
the evolution of system

1406
01:32:39,680 --> 01:32:41,850
at each node

1407
01:32:41,870 --> 01:32:42,910
closed form

1408
01:32:43,160 --> 01:32:46,720
have done using time window

1409
01:32:46,720 --> 01:32:49,050
o for the study

1410
01:32:49,120 --> 01:32:55,050
at the beginning the first set of examples

1411
01:32:55,100 --> 01:32:56,410
we'll fit

1412
01:32:58,470 --> 01:33:02,760
after split this set of examples will

1413
01:33:02,780 --> 01:33:06,550
they the sufficient statistic this level

1414
01:33:08,570 --> 01:33:10,810
first place is

1415
01:33:10,870 --> 01:33:14,890
they are sufficient statistics at these

1416
01:33:14,930 --> 01:33:16,990
it is the

1417
01:33:19,450 --> 01:33:23,180
discourse forms to a kind of it's not as

1418
01:33:23,330 --> 01:33:25,510
but the last time window

1419
01:33:26,800 --> 01:33:31,030
data streams

1420
01:33:32,470 --> 01:33:33,680
another one

1421
01:33:34,760 --> 01:33:36,470
check that

1422
01:33:41,580 --> 01:33:42,890
if they

1423
01:33:42,910 --> 01:33:44,970
this special

1424
01:33:46,700 --> 01:33:48,640
hopefully but

1425
01:33:49,080 --> 01:33:52,530
we'll apply is the expansion

1426
01:33:54,280 --> 01:33:57,010
but you know that sinks sanctuary

1427
01:33:57,010 --> 01:33:59,640
so that during time

1428
01:34:00,600 --> 01:34:02,720
correlation between variables

1429
01:34:02,720 --> 01:34:04,300
can set

1430
01:34:04,600 --> 01:34:07,910
o can we do that something

1431
01:34:07,970 --> 01:34:10,370
was sacked

1432
01:34:10,390 --> 01:34:12,280
the splitting criteria

1433
01:34:13,410 --> 01:34:15,030
that we can prove that

1434
01:34:15,080 --> 01:34:16,720
every time the

1435
01:34:17,120 --> 01:34:19,450
an expansion of

1436
01:34:22,080 --> 01:34:23,220
of the

1437
01:34:32,720 --> 01:34:37,990
fresh data the most recent data plates the information that

1438
01:34:38,030 --> 01:34:39,700
i believe

1439
01:34:40,600 --> 01:34:43,550
any point in time we also

1440
01:34:43,550 --> 01:34:47,830
three is not from the same distribution as the y twelve

1441
01:34:48,820 --> 01:34:51,960
in particular they are not independent so

1442
01:34:52,210 --> 01:34:58,060
it's it's important to realize that the this model specifies the distribution over the entire

1443
01:34:58,060 --> 01:34:59,310
sequence y

1444
01:34:59,370 --> 01:35:04,770
not just individual models why this is the comment about plates which i forgot to

1445
01:35:04,770 --> 01:35:08,590
take out because we didn't cover the plate notation but don't worry about that

1446
01:35:09,770 --> 01:35:13,870
so just as the conditional

1447
01:35:13,890 --> 01:35:18,730
markov models like conditional random fields and maximum entropy markov models

1448
01:35:18,750 --> 01:35:22,130
which had the arrows instead of going down they had there's going up

1449
01:35:22,150 --> 01:35:25,700
just like those models you can think of these models in two ways you can

1450
01:35:25,700 --> 01:35:30,820
think of this as a markov chain on the hidden state variables with stochastic measurements

1451
01:35:31,250 --> 01:35:35,190
so that there markov chain going on in the background but i hide the markov

1452
01:35:35,190 --> 01:35:38,980
chain from your output available in front of of probabilistic output and you can only

1453
01:35:38,980 --> 01:35:43,160
see the wise you can think of it as a mixture model

1454
01:35:43,450 --> 01:35:47,450
the state of the mixture the choice that the mixture model makes is coupled across

1455
01:35:48,460 --> 01:35:51,760
right if you got these links here

1456
01:35:51,780 --> 01:35:56,320
these horizontal axis this would exactly be a mixture model of a discrete random variable

1457
01:35:56,320 --> 01:35:57,920
which you can see

1458
01:35:57,930 --> 01:36:01,970
and based on that you select an output distribution and you make an output

1459
01:36:01,990 --> 01:36:07,170
so this is exactly just mixture model with choice of which mixture component to use

1460
01:36:07,180 --> 01:36:09,150
is coupled across time

1461
01:36:09,190 --> 01:36:13,700
so you can see that if i ask you please tell me

1462
01:36:13,710 --> 01:36:17,990
which mixture component you think was used to generate y three

1463
01:36:18,000 --> 01:36:21,350
it's no longer entirely trivial calculation

1464
01:36:21,370 --> 01:36:26,360
because there is some evidence about which mixture component was used based on the data

1465
01:36:26,360 --> 01:36:27,380
like three

1466
01:36:27,420 --> 01:36:31,650
but there's also some effect from the previous mixture component and you need to somehow

1467
01:36:31,650 --> 01:36:38,100
incorporate all the observations when making that decision so this inference problem is very very

1468
01:36:38,100 --> 01:36:40,670
hard and that's what we're going do

1469
01:36:40,690 --> 01:36:44,090
a study in this in this class

1470
01:36:45,680 --> 01:36:48,080
that is

1471
01:36:48,130 --> 01:36:52,620
the search for hidden markov models and then i'm just going to go to the

1472
01:36:53,060 --> 01:36:54,780
other notes

1473
01:36:54,790 --> 01:36:56,920
in which we talk about inference

1474
01:36:56,970 --> 01:37:03,110
hmm some kind of motivation to study more general inference problem than than the one

1475
01:37:03,120 --> 01:37:05,710
we studied in the last class we really

1476
01:37:05,730 --> 01:37:10,060
as inference formerly is the problem because it was so easy we could always just

1477
01:37:10,060 --> 01:37:11,560
write down the ratio

1478
01:37:11,580 --> 01:37:14,780
which correspond to bayes rule and then we're done but now we really want to

1479
01:37:15,070 --> 01:37:17,540
examine the problem that more carefully so

1480
01:37:17,550 --> 01:37:19,290
here is the sort of formal

1481
01:37:19,330 --> 01:37:24,030
set up for the problem of probabilistic inference we partition the random variables in our

1482
01:37:24,030 --> 01:37:27,710
domain into three disjoint subsets

1483
01:37:27,730 --> 01:37:31,890
one of them x e

1484
01:37:31,920 --> 01:37:34,190
is going to be

1485
01:37:35,590 --> 01:37:40,390
know that we observe so e stands for evidence those are the evidence nodes OK

1486
01:37:41,090 --> 01:37:46,100
at the query nodes the nodes that we would like to know something about their

1487
01:37:47,170 --> 01:37:52,020
and the remainder are the nodes that we're going to marginalize out nodes we don't

1488
01:37:52,020 --> 01:37:55,550
care about we're just going to sum over them during the course of our of

1489
01:37:55,550 --> 01:37:58,040
our calculations okay

1490
01:37:58,060 --> 01:38:04,490
so if the joint distribution is represented as a huge table the inference is actually

1491
01:38:05,820 --> 01:38:07,910
now of course

1492
01:38:07,920 --> 01:38:13,000
no such table could ever fit into memory but if somehow magically you managed to

1493
01:38:13,000 --> 01:38:17,600
fit this table into memory the inference really trivial just be lookup

1494
01:38:17,620 --> 01:38:24,360
right you just index into a table along the dimensions x e and slides along

1495
01:38:24,360 --> 01:38:27,060
the values that you actually observed

1496
01:38:27,660 --> 01:38:31,820
and that would leave you with a smaller table they only had the dimensions x

1497
01:38:31,820 --> 01:38:36,850
fnx are left many would say x are

1498
01:38:36,870 --> 01:38:40,440
and what would be must be a table that had only dimensions of x then

1499
01:38:40,440 --> 01:38:41,880
that would be your answer

1500
01:38:41,900 --> 01:38:43,490
so in principle

1501
01:38:43,510 --> 01:38:45,760
inference is if you could write down the hall

1502
01:38:45,770 --> 01:38:51,320
joint distribution explicitly is the big multidimensional array in matlab inference would be easy you

1503
01:38:51,320 --> 01:38:55,570
just selected based on the evidence so the

1504
01:38:55,580 --> 01:39:01,320
marginalisation notes and what would be left would be the distribution you want after renormalized

1505
01:39:01,340 --> 01:39:07,170
OK but of course storing a joint distribution in memory is completely ridiculous in doing

1506
01:39:07,170 --> 01:39:10,910
this sum for the marginalisation would be very hard and during the last some for

1507
01:39:10,920 --> 01:39:15,140
renormalisation will also be very hard causes a huge tables so we can really consider

1508
01:39:15,140 --> 01:39:23,540
that the best approach here is to try and take advantage of the structure in

1509
01:39:23,540 --> 01:39:28,240
the models of the joint distribution is represented by graphical model we can do inference

1510
01:39:28,240 --> 01:39:33,600
much much more efficiently and that's what we're going to study today so before diving

1511
01:39:33,620 --> 01:39:36,870
i want to convince you that the trickster going to learn today are not very

1512
01:39:36,870 --> 01:39:43,170
hard and i want to convince you that by showing you a two line formula

1513
01:39:43,190 --> 01:39:48,690
and here is the question how many multiplications

1514
01:39:48,730 --> 01:39:54,070
does it take to compute this quantity

1515
01:39:54,090 --> 01:39:55,580
one right

1516
01:39:59,440 --> 01:40:07,140
OK if you understand how i seem to work by going from here to here

1517
01:40:07,140 --> 01:40:11,120
you understand everything you need to know about belief propagation

1518
01:40:11,140 --> 01:40:13,400
that's all there is to right

1519
01:40:13,420 --> 01:40:18,990
seems like magically i went from two multiplications one multiplication how did i do that

1520
01:40:18,990 --> 01:40:23,310
because there's some very particular distribution of property of these operations and i can rearrange

1521
01:40:23,310 --> 01:40:26,900
them in a clever way to get the same result that's what's going on in

1522
01:40:26,900 --> 01:40:28,960
belief propagation so

1523
01:40:28,970 --> 01:40:33,260
when we started to get into like these equations and stuff don't panic just remember

1524
01:40:33,260 --> 01:40:39,340
that this is that happening is no magic it's just distributing rearranging operations in in

1525
01:40:39,340 --> 01:40:42,320
a clever by taking advantage of some properties

1526
01:40:42,330 --> 01:40:46,010
that's the trick and now we're going to try and set it up for a

1527
01:40:46,030 --> 01:40:47,760
three is more

1528
01:40:47,830 --> 01:40:53,560
complicated models so review the simple case which we have been doing all along kind

1529
01:40:53,560 --> 01:40:58,620
of without formalizing it which is just a brute force application of basal so up

1530
01:40:58,620 --> 01:41:01,750
until now we've we're really looking at the simple

1531
01:41:01,760 --> 01:41:07,330
graphical models here and imagine a graphical model like this one where there is no

1532
01:41:07,330 --> 01:41:13,430
x is unobserved and this nodewise observed in the joint distribution here is can be

1533
01:41:13,430 --> 01:41:19,020
written as the probability that that would be like the mixing coefficients times the probability

1534
01:41:19,020 --> 01:41:23,010
of y given x o to be like the class conditional model

1535
01:41:23,030 --> 01:41:27,830
and now if i want to write down the probability of x given y

1536
01:41:27,850 --> 01:41:31,750
i just use bayes rule right i just wrote down bayes rule and i noticed

1537
01:41:31,750 --> 01:41:34,260
that in the denominator involved this summer

1538
01:41:34,370 --> 01:41:37,900
that's because this was just a single random variable

1539
01:41:37,900 --> 01:41:44,340
an architecture function approximation architecture that the weights

1540
01:41:44,360 --> 01:41:47,440
so what those architectures look like

1541
01:41:47,480 --> 01:41:52,150
so you have the rights and those of modern applied some basis functions

1542
01:41:52,210 --> 01:41:53,670
the fire facts

1543
01:41:53,690 --> 01:41:55,590
it returns the vector

1544
01:41:57,590 --> 01:42:00,610
so i can ride this i can expand this

1545
01:42:00,650 --> 01:42:01,940
twenty two

1546
01:42:01,940 --> 01:42:04,420
make it more there

1547
01:42:04,460 --> 01:42:05,840
so you can

1548
01:42:05,860 --> 01:42:06,750
just right

1549
01:42:06,770 --> 01:42:08,130
some here

1550
01:42:08,170 --> 01:42:08,900
two the

1551
01:42:08,920 --> 01:42:15,250
i and phi of i think that's where i was from one to be so

1552
01:42:15,250 --> 01:42:18,210
theta and phi rt dimension of

1553
01:42:18,300 --> 01:42:20,860
just stating the product of the guys

1554
01:42:20,920 --> 01:42:24,880
so you have your business functions so maybe you're business functions like bombs in this

1555
01:42:27,290 --> 01:42:31,380
and you have the state acts OK so what do do

1556
01:42:31,400 --> 01:42:34,900
you need the values of of these basis functions so this will be

1557
01:42:34,920 --> 01:42:38,730
maybe this is five live so this is phi one x

1558
01:42:38,750 --> 01:42:40,290
this is phi t

1559
01:42:40,300 --> 01:42:41,480
so this is

1560
01:42:41,500 --> 01:42:43,050
phi two x

1561
01:42:43,070 --> 01:42:44,300
and this is

1562
01:42:44,320 --> 01:42:46,130
five three attacks

1563
01:42:46,150 --> 01:42:48,570
easier ways combine is that

1564
01:42:48,570 --> 01:42:51,030
the universe that

1565
01:42:51,150 --> 01:42:56,590
OK if you compute the gradient of this so what you get

1566
01:42:56,650 --> 01:42:59,500
so if you compute the gradient of this land

1567
01:43:00,190 --> 01:43:02,960
one of the key here is just an oriented

1568
01:43:05,520 --> 01:43:08,360
taking the derivative of something that

1569
01:43:08,380 --> 01:43:09,340
it turns you

1570
01:43:09,360 --> 01:43:13,020
something that doesn't depend on the guy so it should return

1571
01:43:13,070 --> 01:43:17,500
the graph should be just fine effects it is indeed justify attacks

1572
01:43:17,520 --> 01:43:22,150
so if you want to spell out this particular are given for this case

1573
01:43:22,180 --> 01:43:24,750
i think this very very simple form

1574
01:43:24,800 --> 01:43:26,800
so the

1575
01:43:26,820 --> 01:43:28,900
is still see here

1576
01:43:40,670 --> 01:43:42,940
the the the update is

1577
01:43:42,960 --> 01:43:44,730
all forty times

1578
01:43:44,750 --> 01:43:47,750
after pleasant common themes

1579
01:43:47,770 --> 01:43:49,880
the next

1580
01:43:49,940 --> 01:43:52,630
value the next day

1581
01:43:52,730 --> 01:43:53,900
due that

1582
01:43:55,810 --> 01:44:01,790
one hangar space

1583
01:44:01,820 --> 01:44:06,730
minus the value of the current state

1584
01:44:06,730 --> 01:44:12,210
times the gradients was gravity and just can't it just five weeks

1585
01:44:12,270 --> 01:44:15,550
so that

1586
01:44:15,590 --> 01:44:17,340
first easier

1587
01:44:17,380 --> 01:44:18,630
this linear

1588
01:44:18,630 --> 01:44:21,190
function approximation

1589
01:44:21,230 --> 01:44:26,270
OK and you can have a similar good forty land are using this as the

1590
01:44:26,270 --> 01:44:28,690
long long returns

1591
01:44:28,710 --> 01:44:30,840
the game that's the

1592
01:44:30,920 --> 01:44:35,500
before but you so that's an argument and this not so easy to calculate

1593
01:44:35,500 --> 01:44:39,050
st london was this infinite sum

1594
01:44:39,070 --> 01:44:43,070
so again if you use this linear function approximation and

1595
01:44:43,070 --> 01:44:46,820
OK i want talk about that

1596
01:44:48,360 --> 01:44:51,750
and if you want to generalize

1597
01:44:51,800 --> 01:44:53,190
the back to you

1598
01:44:53,210 --> 01:44:56,300
so the previous target

1599
01:44:56,400 --> 01:44:58,630
for t lambda two

1600
01:44:59,790 --> 01:45:02,090
function approximation

1601
01:45:03,340 --> 01:45:07,360
it turns out that you have to turn the adage traces

1602
01:45:07,380 --> 01:45:09,270
to be vectors

1603
01:45:09,270 --> 01:45:10,860
of the same dimension

1604
01:45:10,880 --> 01:45:13,000
as the

1605
01:45:13,070 --> 01:45:19,380
the dimensionality of the parameter vector trying to estimate and you have to do something

1606
01:45:19,420 --> 01:45:24,070
so the good thing about this is that this is a straightforward generalisation of td

1607
01:45:24,070 --> 01:45:27,380
lambda also in this a specific choice

1608
01:45:27,440 --> 01:45:29,170
the basis functions

1609
01:45:29,190 --> 01:45:30,380
you get back

1610
01:45:30,420 --> 01:45:33,230
the original graph

1611
01:45:34,440 --> 01:45:36,290
so the chances that

1612
01:45:37,020 --> 01:45:40,570
these are getting really does something

1613
01:45:42,550 --> 01:45:47,570
it converges in particular your imagine you're following policy pi and this is some nice

1614
01:45:48,690 --> 01:45:52,170
this target is converging to some value function v

1615
01:45:53,570 --> 01:45:56,050
well we start here is the

1616
01:45:56,070 --> 01:46:00,570
value function underlying policies that you're following so

1617
01:46:00,570 --> 01:46:02,320
notation is maybe not

1618
01:46:02,340 --> 01:46:06,230
what effect so the difference between the

1619
01:46:06,250 --> 01:46:08,210
and this target

1620
01:46:08,230 --> 01:46:09,880
is less than

1621
01:46:11,170 --> 01:46:12,880
the difference between

1622
01:46:12,900 --> 01:46:14,000
the target

1623
01:46:14,000 --> 01:46:18,570
and the projection of the target function space so by the projection of a part

1624
01:46:18,630 --> 01:46:23,670
of the target function space is the best approximation of the function

1625
01:46:23,670 --> 01:46:28,290
given a function space so you have your basis functions you have chosen

1626
01:46:28,380 --> 01:46:29,630
you have chosen them

1627
01:46:29,630 --> 01:46:34,500
and you just compute the best place in retrospect so of course you cannot

1628
01:46:34,550 --> 01:46:38,550
however it is born in practice but it's good to know

1629
01:46:38,570 --> 01:46:43,520
that if you have function space is rich enough so that this projection

1630
01:46:43,520 --> 01:46:46,590
is very close to the original function

1631
01:46:46,650 --> 01:46:49,530
and that there is going to be really small

1632
01:46:49,590 --> 01:46:51,690
OK so what you want to do

1633
01:46:51,730 --> 01:46:53,340
is you want to have

1634
01:46:54,440 --> 01:46:57,360
really big

1635
01:46:58,610 --> 01:47:00,980
approximation architecture

1636
01:47:01,000 --> 01:47:04,360
that is able to capture a lot of features

1637
01:47:04,380 --> 01:47:08,070
and then you can run these are

1638
01:47:08,130 --> 01:47:09,340
OK so

1639
01:47:09,360 --> 01:47:14,610
again this was just for weighting of policy and question to consider is if you

1640
01:47:17,000 --> 01:47:18,710
learning controller

1641
01:47:18,710 --> 01:47:21,400
and it can in a state for that matter

1642
01:47:21,420 --> 01:47:28,630
generalise or these to to learning good controller just using action value function

1643
01:47:28,670 --> 01:47:30,770
OK so this is

1644
01:47:30,770 --> 01:47:34,550
just generalisation of TV zero

1645
01:47:35,980 --> 01:47:41,550
for this action value functions

1646
01:47:41,590 --> 01:47:44,270
and this is the way it should work

1647
01:47:44,500 --> 01:47:49,110
this eligibility traces

1648
01:47:49,130 --> 01:47:51,650
i don't have much time

1649
01:47:53,730 --> 01:47:59,110
so he here some results for this to term to mean that you will see

1650
01:47:59,110 --> 01:48:00,980
a lot if you

1651
01:48:01,050 --> 01:48:05,070
studied reinforcement learning that surely someone think of the main

1652
01:48:05,090 --> 01:48:08,150
you have an under-par card it should go to the goal

1653
01:48:08,170 --> 01:48:11,130
but it's on the part so it starts from what

1654
01:48:11,150 --> 01:48:15,920
it can i just actually two years ago and the attention is not strong enough

1655
01:48:16,530 --> 01:48:20,650
so what it has to do that he has to collect some energy by going

1656
01:48:20,650 --> 01:48:24,710
for lot it and then going backwards

1657
01:48:24,710 --> 01:48:28,790
so it forms an edge into into some the system

1658
01:48:28,790 --> 01:48:31,520
and then once it's the

1659
01:48:31,530 --> 01:48:35,710
it can use its potential energy just curious

1660
01:48:35,710 --> 01:48:39,960
so this is a non-trivial problem for traditional controllers

1661
01:48:39,980 --> 01:48:44,300
try to reach the goal very high so that proportionally

1662
01:48:44,320 --> 01:48:47,070
so there are increasing the force proportional to

1663
01:48:47,090 --> 01:48:50,790
the distance to the goal so that one for here

1664
01:48:50,840 --> 01:48:52,030
at all

1665
01:48:52,090 --> 01:48:53,210
and so

1666
01:48:53,230 --> 01:48:55,670
these are the results of using

1667
01:48:58,150 --> 01:49:00,790
for learning the value function

1668
01:49:00,790 --> 01:49:04,340
the children of a may be reversed

1669
01:49:04,390 --> 01:49:06,880
but it's just the same picture

1670
01:49:06,970 --> 01:49:18,750
this because in case two we care

1671
01:49:18,770 --> 01:49:21,510
the case one we didn't really care

1672
01:49:21,520 --> 01:49:24,500
in case two we say well

1673
01:49:24,830 --> 01:49:26,290
cases of there

1674
01:49:26,300 --> 01:49:29,840
is x the right child of the parent for the left child if it's the

1675
01:49:29,840 --> 01:49:31,710
right child or in case two

1676
01:49:31,720 --> 01:49:35,350
so now i really know the next year

1677
01:49:35,380 --> 01:49:40,580
his b is the right child of before i don't know i i didn't care

1678
01:49:41,250 --> 01:49:42,930
i'm assuming that this way

1679
01:49:42,980 --> 01:49:45,970
OK why still here

1680
01:49:47,230 --> 01:49:50,010
now we know that y is black

1681
01:49:50,010 --> 01:49:51,220
why over here

1682
01:49:51,230 --> 01:49:56,630
the black nodes so self-guided the contraction trick all these nodes a b and c

1683
01:49:57,050 --> 01:49:59,050
with conglomerate into one

1684
01:49:59,090 --> 01:50:01,180
now we have four children and actually looks

1685
01:50:01,190 --> 01:50:05,670
pretty good why not involved because it's black

1686
01:50:07,760 --> 01:50:11,410
so in this case we're going to do less portation

1687
01:50:11,430 --> 01:50:15,350
on a

1688
01:50:20,120 --> 01:50:21,930
so we take the search

1689
01:50:21,960 --> 01:50:24,330
we turn ninety degrees

1690
01:50:24,370 --> 01:50:26,840
what we get is a

1691
01:50:26,850 --> 01:50:28,250
and the last

1692
01:50:28,250 --> 01:50:33,420
the on the right still preserve the inorder traversal c on top still

1693
01:50:33,430 --> 01:50:37,130
otherwise hanging office before

1694
01:50:37,180 --> 01:50:41,050
we have one of the subtrees are the other subtrees hanging up the in the

1695
01:50:41,050 --> 01:50:43,140
other two now paying

1696
01:50:43,170 --> 01:50:48,440
this is just the generic traditional picture applied to the search

1697
01:50:48,470 --> 01:50:53,130
OK that does this before we had to zigzag between x and its grandparent now

1698
01:50:53,140 --> 01:50:54,420
we have the zigzag

1699
01:50:54,460 --> 01:50:55,520
we have this straight

1700
01:50:55,550 --> 01:50:56,600
path between

1701
01:50:57,300 --> 01:51:01,590
so x is still here not changing x in this case because after i do

1702
01:51:01,590 --> 01:51:04,330
case two i immediately do case three

1703
01:51:04,340 --> 01:51:07,680
so this is what case we will look like and now continue on

1704
01:51:07,680 --> 01:51:09,080
k street

1705
01:51:09,200 --> 01:51:25,470
so finally

1706
01:51:25,480 --> 01:51:29,970
there's case three and this was finally complete the insertion of the

1707
01:51:30,050 --> 01:51:32,350
we have about black c

1708
01:51:32,370 --> 01:51:33,830
we have

1709
01:51:34,680 --> 01:51:36,870
the left child from c

1710
01:51:36,880 --> 01:51:41,420
we have already left grandchild which is x

1711
01:51:41,460 --> 01:51:46,260
and then we have these black subtrees all the same kind

1712
01:51:46,290 --> 01:51:48,430
hanging off

1713
01:51:53,380 --> 01:51:57,050
which is exactly what we had at the end of the case two

1714
01:51:57,090 --> 01:51:59,380
so that definitely connects over

1715
01:51:59,390 --> 01:52:05,010
and remember this is the only case left in category a category we assumed to

1716
01:52:05,650 --> 01:52:06,680
it was that you know

1717
01:52:06,710 --> 01:52:10,920
parent of x was left child the grandparent here c

1718
01:52:10,950 --> 01:52:13,520
so we know that

1719
01:52:13,540 --> 01:52:17,430
we are in the case when y over here is red that was case one

1720
01:52:17,440 --> 01:52:19,410
so assuming wise black

1721
01:52:20,270 --> 01:52:23,840
we look at whether x y is the left child and right child if it

1722
01:52:23,840 --> 01:52:27,670
was the right child we made it into the left child

1723
01:52:27,670 --> 01:52:33,020
x actually did change here before x has been now acts an

1724
01:52:33,050 --> 01:52:36,150
OK and then case three finally is when x is the left child of the

1725
01:52:36,150 --> 01:52:38,930
parents who is the left child of the rev

1726
01:52:39,910 --> 01:52:41,830
we have to worry about

1727
01:52:45,690 --> 01:52:53,340
what we do is another rotation just like the last rotation we did in example

1728
01:52:54,420 --> 01:52:55,420
in this case three

1729
01:52:56,550 --> 01:52:59,340
so we're going to do the right rotate

1730
01:53:06,670 --> 01:53:09,850
and we're going to recover

1731
01:53:21,150 --> 01:53:24,260
what do we get well now becomes the rule

1732
01:53:24,260 --> 01:53:26,210
and i'm going to make it black

1733
01:53:26,220 --> 01:53:29,510
remember that this is the root of the subtree there's other stuff

1734
01:53:29,550 --> 01:53:31,790
thank you for your relation draw

1735
01:53:31,800 --> 01:53:33,790
next appearance in

1736
01:53:33,790 --> 01:53:36,430
all these pictures are somewhere in the middle of the tree

1737
01:53:36,460 --> 01:53:40,230
i don't know where could be a right branch could be left branch

1738
01:53:40,260 --> 01:53:41,590
we don't know

1739
01:53:41,600 --> 01:53:44,830
c becomes the child to be i'm going to make it to read child

1740
01:53:44,870 --> 01:53:46,080
a becomes

1741
01:53:46,130 --> 01:53:48,040
child b as it was before

1742
01:53:48,050 --> 01:53:50,080
keep reading

1743
01:53:50,080 --> 01:53:53,860
but this current will be seen from above clockwise

1744
01:53:53,920 --> 01:53:56,820
sort of it produces a magnetic field in this direction

1745
01:53:56,860 --> 01:53:59,860
to oppose the change in magnetic flux

1746
01:53:59,880 --> 01:54:04,610
and we call these currents any currents

1747
01:54:04,630 --> 01:54:11,810
any occurrence

1748
01:54:11,810 --> 01:54:13,130
any current

1749
01:54:13,150 --> 01:54:14,340
produces heat

1750
01:54:14,360 --> 01:54:15,810
in here

1751
01:54:16,540 --> 01:54:18,250
is the product

1752
01:54:18,270 --> 01:54:19,710
joules per second

1753
01:54:21,090 --> 01:54:22,290
the power

1754
01:54:22,360 --> 01:54:24,980
times i

1755
01:54:25,040 --> 01:54:29,110
i agree are always comes down to the same

1756
01:54:29,110 --> 01:54:31,420
so this this clearly not a little bit

1757
01:54:31,480 --> 01:54:34,840
the resistance now is the resistance there

1758
01:54:34,880 --> 01:54:36,500
and that means

1759
01:54:36,610 --> 01:54:40,500
that this will slow down at the expense of kinetic energy

1760
01:54:40,520 --> 01:54:41,730
it is produced

1761
01:54:41,750 --> 01:54:43,000
and in one go

1762
01:54:43,020 --> 01:54:46,210
as far as feel

1763
01:54:46,210 --> 01:54:49,420
then the situation would be if there were no fields

1764
01:54:49,440 --> 01:54:54,610
and we call that magnetic braking

1765
01:54:54,650 --> 01:54:57,040
you can easily convince yourself

1766
01:54:57,090 --> 01:54:59,250
what you should do it home

1767
01:54:59,250 --> 01:55:03,340
but if you look at the current right here coming out of the blackboard

1768
01:55:03,400 --> 01:55:06,170
you calculate the lawrence force right there

1769
01:55:06,190 --> 01:55:10,060
you will see that the lawrence forces in this direction it's pushing it out it

1770
01:55:10,060 --> 01:55:18,270
opposes the motion

1771
01:55:18,310 --> 01:55:20,480
and i can demonstrate that the u

1772
01:55:20,560 --> 01:55:22,500
i have here

1773
01:55:22,520 --> 01:55:25,190
a pendulum

1774
01:55:25,190 --> 01:55:26,310
the pendulum

1775
01:55:26,320 --> 01:55:28,420
his conducting copper plate

1776
01:55:28,420 --> 01:55:30,150
like so

1777
01:55:30,170 --> 01:55:32,170
which i'm going to swing

1778
01:55:32,210 --> 01:55:34,750
between magnetic poles which are here

1779
01:55:34,770 --> 01:55:36,980
when you swing it in this direction

1780
01:55:36,980 --> 01:55:38,480
i've two pendulums

1781
01:55:38,520 --> 01:55:41,400
one way this is solid copper

1782
01:55:41,420 --> 01:55:43,290
and have another one

1783
01:55:44,420 --> 01:55:46,170
it is slowly

1784
01:55:46,230 --> 01:55:50,250
like teeth

1785
01:55:50,290 --> 01:55:54,270
if i'm going to also made this one in the magnetic fields

1786
01:55:54,320 --> 01:55:56,320
you're going to get

1787
01:55:57,290 --> 01:56:02,940
there any current sometimes clockwise sometimes counterclockwise depending upon how the magnetic flux that surface

1788
01:56:02,940 --> 01:56:04,170
is changing

1789
01:56:04,290 --> 01:56:08,110
where it it moves into the magnetic field will have moved out of the magnetic

1790
01:56:09,650 --> 01:56:12,090
always oppose its motion

1791
01:56:12,150 --> 01:56:15,480
and so it will then you will see that

1792
01:56:15,520 --> 01:56:18,230
and it's at the expense of kinetic energy

1793
01:56:18,270 --> 01:56:21,650
he will be produced in this copper

1794
01:56:21,730 --> 01:56:26,500
if you do it with something like this the damping will be substantially less

1795
01:56:26,500 --> 01:56:29,770
not zero but substantially less

1796
01:56:29,810 --> 01:56:32,340
because now if there is an EMF

1797
01:56:32,420 --> 01:56:34,500
i want to drive the current

1798
01:56:34,520 --> 01:56:37,900
this current has to go through these openings which is and which has a huge

1799
01:56:39,960 --> 01:56:41,400
and remember

1800
01:56:41,440 --> 01:56:45,920
power is times i and if there and his i square or any of the

1801
01:56:45,980 --> 01:56:50,090
if the kernel is extremely low because the resistance is so absurdly high

1802
01:56:50,110 --> 01:56:52,460
you don't dissipate much power

1803
01:56:52,500 --> 01:56:55,420
and sort of not much them p

1804
01:56:55,480 --> 01:56:57,420
and i can show that to you

1805
01:56:57,590 --> 01:57:02,290
by the way this is damping this magnetic damping is used sometimes for scale that

1806
01:57:02,290 --> 01:57:03,690
you will use cellphone

1807
01:57:03,690 --> 01:57:10,170
so it doesn't also late for too long to the dems very quickly

1808
01:57:10,170 --> 01:57:14,520
we're going to see the oscillations there

1809
01:57:14,590 --> 01:57:16,630
it's going to be a little dark

1810
01:57:16,650 --> 01:57:18,610
that's the best way

1811
01:57:18,650 --> 01:57:21,520
i can make you see it

1812
01:57:21,540 --> 01:57:23,670
and on the power

1813
01:57:25,190 --> 01:57:30,630
so you see there the look give you the lights

1814
01:57:30,650 --> 01:57:31,630
and first

1815
01:57:31,650 --> 01:57:34,000
i will oscillate it without

1816
01:57:34,040 --> 01:57:36,710
any magnetic field like in politics

1817
01:57:36,750 --> 01:57:40,820
magnet because the solenoid

1818
01:57:40,840 --> 01:57:43,590
so this oscillated no magnetic field

1819
01:57:43,630 --> 01:57:45,790
if you feeling i would also

1820
01:57:45,810 --> 01:57:49,610
what you see on the left is the reflection by the way against the magnetic

1821
01:57:50,440 --> 01:57:53,520
to give you an idea of how it oscillates

1822
01:57:53,540 --> 01:57:56,710
and now i will turn on the magnetic fields

1823
01:57:59,090 --> 01:58:03,540
it's like going into one of the it again

1824
01:58:04,250 --> 01:58:07,710
hitting the magnetic poles we don't want that

1825
01:58:09,630 --> 01:58:13,480
amazing isn't it and then when it goes into when it goes out

1826
01:58:13,520 --> 01:58:17,020
and now i'll use the one with the teeth

1827
01:58:17,060 --> 01:58:18,820
and you will see there's is damping

1828
01:58:18,880 --> 01:58:21,110
but substantially less

1829
01:58:21,170 --> 01:58:23,690
so this is without

1830
01:58:23,750 --> 01:58:25,840
the magnetic field

1831
01:58:25,880 --> 01:58:29,560
and now with now

1832
01:58:29,610 --> 01:58:32,130
because you is them being but it's

1833
01:58:32,170 --> 01:58:33,900
know nearly as much

1834
01:58:33,940 --> 01:58:35,580
as there was

1835
01:58:35,690 --> 01:58:37,340
on the

1836
01:58:37,340 --> 01:58:39,210
one that was

1837
01:58:39,310 --> 01:58:51,090
then that is

1838
01:58:51,130 --> 01:58:53,940
i have here a remarkable example

1839
01:58:53,940 --> 01:58:55,090
of how

1840
01:58:55,190 --> 01:58:57,860
our economy is run

1841
01:58:57,900 --> 01:58:59,650
i have their some

1842
01:58:59,650 --> 01:59:02,480
mining is not just some

1843
01:59:02,540 --> 01:59:05,130
we don't even know how many thousands

1844
01:59:05,190 --> 01:59:09,320
copper wire going around going around going around going around one wire

1845
01:59:09,340 --> 01:59:11,630
and then there's the light bulb

1846
01:59:11,690 --> 01:59:13,290
in that

1847
01:59:14,940 --> 01:59:16,880
here the magnet

1848
01:59:16,920 --> 01:59:19,650
we don't know the strength but

1849
01:59:19,690 --> 01:59:23,750
i would say is not more than the kilogram probably little less

1850
01:59:23,840 --> 01:59:26,060
and when i moved this

1851
01:59:26,080 --> 01:59:28,880
between these poles

1852
01:59:28,940 --> 01:59:33,130
magnetic field let's say is going in this direction i don't know what this that

1853
01:59:33,130 --> 01:59:34,520
i don't know to color code

1854
01:59:34,520 --> 01:59:37,670
but there is no magnetic field going through here for is the change in the

1855
01:59:38,590 --> 01:59:40,020
flux through the surface

1856
01:59:40,040 --> 01:59:44,610
very crazy surface if there are thousands why is this the goes multiplied by the

1857
01:59:46,710 --> 01:59:49,820
and then there is going to be an induced EMF

1858
01:59:49,840 --> 01:59:52,730
and i'm going to be an induced current

1859
01:59:52,730 --> 01:59:53,810
and this light

1860
01:59:55,080 --> 01:59:57,230
if i going very slowly

1861
01:59:57,230 --> 01:59:58,250
the sea

1862
01:59:58,270 --> 02:00:01,290
he really wanted to go very fast

1863
02:00:01,360 --> 02:00:03,580
and the magnetic flux changes high

1864
02:00:04,840 --> 02:00:06,060
a lot of light

1865
02:00:06,110 --> 02:00:07,590
so make it dark

1866
02:00:09,170 --> 02:00:13,060
so you can see that

1867
02:00:13,110 --> 02:00:17,090
but we don't want this to

1868
02:00:17,110 --> 02:00:19,310
we don't need that

1869
02:00:19,310 --> 02:00:20,560
little all

1870
02:00:20,610 --> 02:00:24,960
so if you can see me

1871
02:00:24,980 --> 02:00:26,110
i have no

1872
02:00:26,110 --> 02:00:29,810
and i'm going to bring in the magnetic poles and i go very slowly

1873
02:00:29,880 --> 02:00:32,170
i do we know

1874
02:00:33,610 --> 02:00:35,610
what about a little bit of light

1875
02:00:35,670 --> 02:00:37,900
going a little bit of lights

1876
02:00:37,920 --> 02:00:39,000
i'm writing now

1877
02:00:39,000 --> 02:00:43,190
holding it steady nothing happens why because there's no exchange

1878
02:00:43,210 --> 02:00:45,380
magnetic field is very strong now

1879
02:00:45,400 --> 02:00:46,880
thirty slope

1880
02:00:46,920 --> 02:00:50,610
i don't care about how small it is the only cares about the change

1881
02:00:52,440 --> 02:00:56,470
flight within a little bit of life but i pull in what i pull out

1882
02:00:56,470 --> 02:00:57,900
doesn't matter

1883
02:00:57,920 --> 02:01:00,080
if i do it very fast

1884
02:01:00,130 --> 02:01:02,810
i may be able to generate so much current

1885
02:01:02,820 --> 02:01:08,040
both even blow trying because i know you like the idea of breaking things

1886
02:01:08,080 --> 02:01:09,540
well the

1887
02:01:09,590 --> 02:01:11,420
you and know alone

1888
02:01:11,480 --> 02:01:13,790
let's see what i managed

1889
02:01:13,790 --> 02:01:16,520
yes i did broken now

1890
02:01:16,590 --> 02:01:22,460
so you got something for your money then you

1891
02:01:22,560 --> 02:01:27,040
that's runs our economy

1892
02:01:28,190 --> 02:01:31,960
conducting windings that are being moved forcefully

1893
02:01:31,980 --> 02:01:35,920
through magnetic fields

1894
02:01:36,000 --> 02:01:39,460
i was once interviewed by reporters

1895
02:01:39,520 --> 02:01:40,540
when he

1896
02:01:40,560 --> 02:01:41,980
i came up with this

1897
02:01:42,960 --> 02:01:44,380
and they said to him

1898
02:01:44,400 --> 02:01:46,130
so what

1899
02:01:46,170 --> 02:01:50,500
so fine so you move the winding through the magnetic field and so you get

1900
02:01:50,500 --> 02:01:53,360
a little bit of electricity so what

1901
02:01:53,360 --> 02:01:54,900
and his answer was

1902
02:01:54,920 --> 02:01:57,020
someday you will taxes

